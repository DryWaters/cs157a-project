Comparison of Heuristic Rule Weight Specification Methods Hisao Ishibuchi and Takashi Yamamoto Department of Industrial Engineering Osaka Prefecture University 1-1 Gakuen-cho, Sakai Osaka 599-8531 Japan hisaoi yama}@ie.osakafu-u.ac.jp Abstract  We examine the performance of heuristic methods for rule weight specification in fuzzy systems for pattern classification problems. Each heuristic method is defined by the confidence measure used in the field of data mining for evaluating association rules Simulation results show that a proposed heuristic method outperforms existing ones I INTRODUCTION We have already demonstrated that rule weights have a 
significant effect on the classification performance of fuzzy rule-based systems  11 This means that the classification performance strongly depends on the specification of the rule weight of each fuzzy rule. The aim of this paper is to propose new methods for rule weight specification and compare them with exiting ones. We use fuzzy rules of the following form for an n-dimensional pattern classification problem Rule R If x1 is A,1 and  and x is A then Class C with CF  1 where x  XI  x 
 is an n-dimensional pattern vector A,i is an antecedent fuzzy set for the i-th attribute C is a consequent class and CF is a certainty grade i.e rule weight Various types of fuzzy rules have been used for pattern classification problems For example Cordon et al 2 examined three types of fuzzy rules One has a single consequent class with no rule weight, another is the same as l and the other has multiple consequent classes where a different certainty grade is assigned to each class In this paper we first describe two exiting methods 2 3 for rule weight specification using the terminology in data 
mining We use fuzzy versions 4 of two measures of association rules in data mining confidence and support 5 Next we propose two heuristic methods for rule weight specification. Differences among the four heuristic methods are visually demonstrated through computer simulations on an artificial test problem. Then we examine the classification performance of fuzzy rule-based systems designed by each heuristic method through computer simulations on wine data with 13 continuous attributes Simulation results show that one of the proposed methods clearly outperforms the exiting ones Finally we discuss the interpretability of fuzzy rule based systems Simulation results show that a small number of simple fuzzy rules with rule weights have high interpretability and high classification ability 11 HEURISTIC RULE WEIGHT SPECIFICATION 
A Rule Evaluation Measures in Data Mining In the field of data mining two measures i.e Confidence and support are frequently used for evaluating association rules. The fuzzy rule in 1 can be viewed as an association rule A a C where A Aq1   A   We first briefly explain fuzzy versions 4 of these two rule evaluation measures Let us assume that m labeled patterns xp xpl  xpn  p=1,2  m are given from M classes for 
an n-dimensional pattern classification problem We denote the set of these training patterns as D  XI   x   The cardinality of D is denoted by I D I where 1 DI=m Let D\(A  and D\(C  be the sets of compatible training patterns with A and C  respectively Then the confidence of A a C is written as follows 5 The confidence can be viewed as measuring the validity 
of A C is defined as follows C  On the other hand the support of A The support can be viewed as measuring the coverage of training patterns by A 3 C  From 2 and 3 the following relation holds ID\(A  ID1 s\(Aq sCq  4Aq cq   4 When the antecedent A is defined by non-fuzzy concepts, the calculations in the above definitions are simple We can easily calculate the confidence and the support by simply counting the number of training patterns that are 
compatible with A and with both A and C When A is fuzzy we have to take into account the compatibility grade of each training pattern with A 4 As in our former studies on fuzzy rule-based classification systems l 3 we define the compatibility grade of each training pattern xp with the antecedent A by the product operation as q PAq xp  xpI  xpl 1 5 0-7 803-728O-8/02/$10.00 02002 IEEE 908 


where pA    is the membership function of the antecedent &zy set Aqi  Thus the total compatibility grade with the antecedent A is calculated as We define the compatibility grade of each training pattern xp with the fuzzy rule R i.e with both the antecedent A and the consequent C  as xP  if PE Class C  7 Thus the total compatibility grade with both A and C is calculated as m p=l 222 The confidence in 2\and the support in 3\can be calculated using 6 and 8 B Heuristic Methods for Rule Weight Specification We assume that a set of antecedent fuzzy sets i.e linguistic values is given for each attribute. The antecedent A is constructed by combining antecedent fuzzy sets for n attributes The corresponding consequent C is determined by finding the class with the maximum confidence or support\for the antecedent A  c\(A aC  A Classh h=1,2  M 9 Note that the same consequent C is obtained from the support s  9  instead of the confidence c    in 9 because ID\(A in 4 is independent of C When the consequent C cannot be uniquely determined in 9 we do not generate any fuzzy rule with the antecedent A  The confidence c\(A 3 C  can be used as the rule weight CF of the fuzzy rule A zC as in Cordon et a1.[2 That is, one definition of the rule weight is as follows where the superscript 223I\224 shows that CFd is the fist definition of CFq  In our former studies on fuzzy rule-based pattern classification l 3 we used a different definition of rule weights Our former definition can be rewritten as where cAve is the average confidence over fuzzy rules with the same antecedent A  but different consequent classes 0-7803-7280-8/02 10.00 02002 IEEE 909 12 We propose a more intuitive definition of the rule weight CF which is based on the difference between the largest confidence and the second largest confidence. That is CFF c\(A Cq 13 where cSec is the second largest confidence for the antecedent A  csec max{c\(A Class h I h=1,2  M h#C  We also examine the following definition 14 CFF c\(A 3Cq  15 where cs is the sum of the confidence over fuzzy rules with the same antecedent A  but different consequent classes from C  M h=l cSum Cc\(A Classh A C 16 While CF is always positive in the first three definitions CF can be negative even when the consequent C is uniquely determined in 9 We do not use fuzzy rules with negative certainty grades in our fizzy rule-based system Thus some fuzzy rules may be removed from fuzzy rule based systems when we use the last definition of rule weights Note that the third and fourth definitions in 1 3\and 1 5 are the same as the second definition in 1 1\when our pattern classification problem involves only two classes i.e when M=2 In ths case cAve cSec cSum in 12 14 and 1 6 The difference among these definitions becomes significant when the number of classes is large As we will show later, the second definition becomes similar to the first definition when the number of classes is very large Let S be a set of fuzzy rules of the form in 1 The rule set S can be viewed as a fuzzy rule-based classification system We use a single winner rule method for classifying new patterns by the rule set S See 6 for other fuzzy reasoning methods for pattern classification The single winner rule Rw is determined for a new pattern xp  N Xpl 7.\222 Xpn  as PA xp Max{PA xp IRq ES 17 That is the winner rule has the maximum product of the compatibility grade and the certainty grade. If multiple fuzzy rules have the same maximum product but different consequent classes for the new pattern x  the classification of xp is rejected The classification is also rejected if no 


fuzzy rule is compatible with the new pattern xp  C Characteristic Feature of Each Definition For visually illustrating the characteristic feature of each definition of rule weights, let us consider a two-class pattern classification problem on the unit interval 0 11 We assume that an infinite number of training patterns are uniformly distributed in the pattern space 0 11 We also assume that each training pattern xp belongs to Class 1 or Class 2 depending on its location as shown in Fig 1 If xp I I9 then xp belongs to Class 1 otherwise xp belongs to Class 2 In Fig 1 threshold value I9 is specified as 8  0.47 For generating fuzzy rules we use three antecedent fuzzy sets in Fig 2 i.e small medium and large Class 1 Class 2 0.0 e  0.47 1.0 Pattern space Fig 1 Distribution of training patterns in an artificial test problem 0.0 0.0 0.5 1.0  Pattern space Fig 2 Three antecedent hzzy sets Using the uniform distribution of training patterns in Fig. 1 and the three antecedent fuzzy sets in Fig 2 we can generate the following fuzzy rules RI  Ifx is small then Class 1 with CFI   If x is large then Class 2 with CF3  18 20 R 2  If x is medium then Class 2 with CF2  R 19 Rule weights of these fuzzy rules are calculated from the uniform distribution of training patterns as CF 0.996 CF 0.558 CF  1.000 21 CF 0.993 CF  0.116 CF  1.000 22 CF  0.993 CFF  0.1 16 CF  1 OOO 23 CF,'v 0.993 CF2N 0.116 CF 1.000 24 Since our test problem is a two-class problem \(i.e A4  2  the second definition is exactly the same as the third and fourth definitions We can observe a large difference in the rule weight CF2 of the second fuzzy rule R2 between the first definition and the other definitions The confidence of this fuzzy rule is not so different from that of the fuzzy rule medium 3 Class 1 with the same antecedent and the different consequent c medium 3 Class 1  0.442 25 c medium Class 2  0.558 26 Thus the rule weight CF2 of the fuzzy rule  R2  medium Class 2 is very small in the last three definitions. On the other hand the rule weight CF2 is not small in the first definition because the confidence is directly used as the rule weight Using the three fuzzy rules in 18 20 we estimate the class boundary between two classes The estimated class boundary 6 is calculated as follows 6  0.320 by the first definition and 6 0.448 by the other definitions The estimated class boundary I9 has a large error in the case of the first definition while it is close to the actual threshold 0.47 in the case of the other definitions. The large error in the case of the first definition is due to the large rule weight CF of the second rule R2 Since the rule weight CF is not negligible the second hzzy rule R2 has a significant effect on the classification of new patterns around the center of the pattern space 0 13 That is the second fuzzy rule R2 has a significant decision region in which R2 is selected as the winner rule As a result the estimated class boundary 6 is pushed to 6  0.320 On the other hand the rule weight CF2 is very small when we use the other definitions Thus the second rule R2 has a small cecision region As a result the estimated class boundary I9 is close to the boundary between the two dominant rules RI and R3 i.e 0.5 In the same manner we calculated the estimated class boundary I9 between two classes for our test problem with various specifications of the actual threshold value B We examined 51 versions of our test problem with different values of 0  0  0.25 0.26, 0.27  0.75  Simulation results are summarized in Fig 3 This figure shows the relation between the actual threshold I9 and the estimated class boundary e The line in this figure shows the case of 6 I9  From this figure we can see that the difference between I9 and 6 is very large in the case of the first definition On the other hand, the estimated class boundary 6 is almost the same as the actual threshold I9 when we use the other definitions This figure suggests that the direct use of the confidence c\(A 3 C  as the rule weight CF i.e the first definition CF6  may lead to large classification errors 0-7803-7280-8/02/$10.00 02002 IEEE 910 


0 lstdefinition 0 2nddefinition Actual threshould B Fig 3 Simulation results by the four definitions of rule weights for the two-class artificial test problem in Fig 1 Results by the least three definitions are the same T J 0.25 0.5 0.75 Actual threshould 8 Fig 4 Simulation results by the second definition of rule weights for M-class test problems Let us extend our test problem in Fig 1 to an M-class problem  M  2  For simplicity of discussion we assume that the unit interval 0 11 in Fig 1 is a part of a larger entire pattern space We also assume that training patterns from the other classes i.e Class 3  Class M exist in the other region of the pattern space. From those assumptions we can discuss the specification of rule weights locally in the unit interval 0 11 In this situation, the increase in the number of classes has no effect on the rule weight specification except for the second definition Only the second definition depends on the number of classes A4 as shown in 12 Thus the second definition is not the same as the thrd and fourth definitions when pattern classification problems involve more than two classes For example, the rule weights of the three fuzzy rules in 20 is calculated from the second definition for the case of A4  5 and 0  0.47 as CF  0.996 CF  0.448 CFf  1.000 27 The class boundary between two classes is calculated as 6  0.345 by the second definition while the actual threshold is B  0.47. Note that the class boundary was calculated as 6  0.448 when A4  2 This result suggests that the increase in the number of classes has a bad effect on the classification perfonnance of fuzzy rule-based systems constructed by the second definition of rule weights In the same manner as Fig 3 we calculated the estimated class boundary 6 using the second definition of rule weights for three specifications of A4 i.e M  2 5 10  Simulation results are summarized in Fig 4 From this figure we can see that the difference between the actual threshold 8 and the estimated class boundary 6 increases as the value of M increases This is because the rule weight CF of the second fuzzy rule R2 becomes unnecessary large when our test problem involves more than two classes as shown in 27 111 PERFORMANCE EVALUATION We compare the four definitions of rule weights with one another through computer simulations on wine data This data set is available from the UC Irvine machine learning database The wine data set is a 13-dimensional pattern classification problem with 178 samples from three classes We chose this data set because it involves many continuous attributes. In our computer simulations we first normalized each attribute value into a real number in the unit interval 0 11 Thus the pattern space of the wine data was normalized into the 13-dimensional unit hypercube 0 l]I3 Then we calculated average classification rates on test patterns as well as training patterns All the given samples were used as training patterns when we examined the classification performance of fuzzy rule-based systems on training data. On the other hand we used the leaving-one-out LVl technique  when we examined the classification performance on test data In the LVl technique 178 samples were divided in a single test pattern and 177 training patterns A fuzzy rule based system designed from training patterns was evaluated by a single test pattem The design-and-test procedure was iterated 178 times so that all the given samples were used as test patterns once Since we did not know an appropriate fuzzy partition for each of the 13 attributes in the wine data we used four fuzzy partitions in Fig 5 for each attribute That is we used 14 fuzzy sets in Fig. 5 and 223don 222t care\224 as antecedent fuzzy sets Thus the total number of combinations of antecedent fuzzy sets is 15 l3  It is impractical to examine all combinations of antecedent fuzzy sets Thus we only generated short fuzzy rules of the length three or less. Note that the rule length is defined by the number of antecedent conditions. Fuzzy rules 0-7803-7280-8/02/$10.00 02002 IEEE 911 


of the length three or less for the 13-dimensional wine data include at least ten don't cure conditions. When all the 178 samples were used as training patterns 71 1727 fuzzy rules  of rules No weight 1st Def 2nd Def 3rd Def 4th Def were generated 3 89.89 89.89 89.89 89.33 89.33 6 80.34 83.15 85.96 84.83 85.39 9 88.76 91.57 92.13 93.26 93.26 12 93.26 93.26 92.70 93.26 93.26 15 88.76 91.57 91.57 94.38 93.26 18 88.20 89.89 89.89 92.13 91.01 21 89.33 89.33 89.33 91.57 91.01 0.0 1 o 0.0 1 o 24 88.20 89.33 89.33 91.57 91.01 27 88.20 89.89 90.45 92.70 91.57 30 90.45 90.45 91.01 93.26 92.13 Table 2 Classification rates on test patterns The best result in each row is indicated by boldface 0.0  Best result in this table 0.0 Dc>c>a rlKxxN In these tables no weight means that rule weights were not 0.0 1 o 0.0 1.0 taken into account in the single winner classification method M w Ths situation was simulated by assigning the same rule weight to all fuzzy rules i.e CFq  1 for Vq  From Table Fig 5 Four fuzzy partitions used in computer simulations The generated fuzzy rules were divided into three groups according to their consequent classes Fuzzy rules in each group were sorted in a descending order of a rule selection criterion We used the product of the confidence c    and the support s    as the rule selection criterion in this paper see 4 for other rule selection criteria: the confidence c    and the support s     When multiple fuzzy rules had the same value of the rule selection criterion, they were randomly sorted \(i.e random tiebreak We constructed a fuzzy rule based system by choosing the first N fuzzy rules from each group. Using various values of N i.e N  1 2 lo we examined the classification performance of fuzzy rule-based systems with different sizes Simulation results on training data and test data are summarized in Table 1 and Table 2 respectively In these tables the best result in each row is indicated by boldface On the other hand, the best result in each table is indicated by  Table 1 Classification rates on training patterns The best result in each row is indicated by boldface  of rules No weight 1st Def 2nd Def 3rd Def 4th Def 3 89.89 89.89 89.89 89.33 89.89 6 91.01 91.57 91.01 92.13 91.01 9 93.26 93.82 92.13 93.82 93.82 12 93.26 93.82 92.70 94.94 94.94 15 88.76 92.70 92.13 94.94 94.94 18 91.01 91.57 92.70 94.94 94.38 21 91.01 91.57 92.70 94.38 93.82 24 92.13 92.13 92.70 94.38 93.82 27 90.45 92.13 92.70 94.38 93.82 30 90.45 92.13 92.70 94.94 93.82  Best result in this table 1 and Table 2 we can see that the use of rule weights improved the classification performance of fuzzy rule-based classification systems Among the four definitions of rule weights the best results were obtained from the third definition \(i.e., difference between the largest and the second largest confidence Iv INTERPRETABILITY OF FUZZY SYSTEMS Let us demonstrate that very simple fuzzy rules with rule weights have high classification ability. For selecting a small number of fuzzy rules with high classification ability we used a rule selection method based on a three-objective genetic algorithm SI This algorithm can find a number of non-dominated rule sets with respect to three objectives to maximize the classification ability to minimize the number of fuzzy rules and to minimize the total rule length In our computer simulations we first chose 900 fuzzy rules from the generated 711727 rules for the wine data in the previous section using the rule selection criterion as in the previous section. Then the three-objective genetic algorithm was used for find non-dominated rule sets. In this computer simulation all the 178 samples in the wine data were used as training data. The rule weight of each fuzzy rule was specified by the third definition Examples of obtained non-dominated rule sets are shown in Fig 6 and Fig. 7. Each fuzzy rule in Fig 6 has only a single antecedent condition Since antecedent fuzzy sets are not adjusted each fuzzy rule can be easily understood by human users. While fuzzy rules in Fig. 7 have two or three antecedent conditions they are still easy to understand For the wine data, Setnes  Roubos reported a 98.3 classification rate on training data by three fuzzy rules. While 0-7803-7280-8/02/$10.00 02002 IEEE 912 


we used simple homogeneous fuzzy partitions with no membership tuning our fuzzy rule-based system with a 100 classification rate in Fig 7 outperformed the reported result in 9 Castillo et al lo reported a 96.76 average classification rate on test data 30 of the wine data where the average number of fuzzy rules was 5.2 over five independent trials Since their SLAVE algorithm used a union i.e disjunction of multiple linguistic values as a single antecedent fuzzy set fuzzy rules in IO are more complicated than our fuzzy rules in Fig 6 and Fig 7 That is more fuzzy rules with higher complexity were obtained in lo than our fuzzy rule-based systems in Fig 6 and Fig 7 From computer simulations using the LV1 procedure we obtained a 96.1 average classification rate on test data by three fuzzy rules of the average length 2.33 and a 97.2 average classification rate on test data by three fuzzy rules of the average length 2.67 I I XI x7 47 lconseauent I Fig 6 Three fuzzy rules with a 94.9 classification rate Fig 7 Three fuzzy rules with a 100 classification rate V CONCLUSIONS In this paper we examined four heuristic definitions of rule weights in fuzzy rule-based classification systems First we proposed two heuristic definitions using the confidence of fuzzy association rules Next we described the characteristic feature of each definition Through computer simulations on an artificial test problem we illustrated the drawback of each of the two existing definitions Then we compared the four definitions with one another through computer simulations on the wine data We also examined the case with no rule weights by assigning the same rule weight to all fuzzy rules Simulation results showed that the use of rule weights improved the classification performance of fuzzy rule-based systems Among the four definitions the best results were obtained from a proposed one where the rule weight of each fuzzy rule was defined by the difference between the largest and the second largest confidence Finally we demonstrated that very simple fuzzy des with rule weights have high classification ability as well as high interpretability We used a genetic algorithm-based rule selection method for finding non-dominated rule sets with respect to three objectives to maximize the classification accuracy to minimize the number of fuzzy rules and to minimize the total rule length Since the number of fuzzy rules and the total rule length were minimized very simple rule sets were obtained by a three objective genetic algorithm While those rule sets were very simple, they had high classification ability This is because an appropriate rule weight was specified for each fuzzy rule by the proposed definition Reference I H Ishibuchi and T Nakashima 223Effect of rule weights in fuzzy rule-based classification systems,\224 IEEE Trans on Fuzzy Systems vol 9 no 4 pp 506-5 15 August 2001 2 0 Cordon M J del Jesus and F Herrera 223A proposal on reasoning methods in fuzzy rule-based classification systems,\224 International Journal of Approximate Reasoning vol 20 pp 21-45 January 1999 3 H Ishibuchi K Nozaki and H Tanaka 223Distributed representation of fuzzy rules and its application to pattem classification,\224 Fuzzy Sets and Systems vol 52 no 1 pp 2 1-32 November 1992 4 H Ishibuchi, T Yamamoto and T Nakashima 223Fuzzy data mining Effect of fuzzy discretization,\224 Proc of 1st IEEE International Conference on Data Mining pp 000400 November 2001 5 R Agrawal and R Srikant 223Fast algorithms for mining association rules,\224 Proc of 20th International Conference on Very Large Data Bases pp 487-499 September 1994 Expanded version is available as IBM Research Report RJ9839 June 1994 6 H Ishibuchi T Nakashima and T Morisawa 223Voting in fuzzy rule-based systems for pattem classification problems,\224 Fuzzy Sets andsystem vol 103 no 2 pp 223-238 April 1999 7 S M Weiss and C A Kulikowski Computer Systems That Learn Morgan Kaufmann Publishers San Mateo 1991 8 H Ishibuchi T Nakashima and T Murata 223Three-objective genetics-based machine learning for linguistic rule extraction,\224 Information Sciences vol 136 no 1-4 pp 109-133 August 2001 9 M Setnes and H Roubos 223GA-based modeling and classification Complexity and performance,\224 IEEE Trans on Fuzzy Systems vol 8 no 5 pp 509-522, 2000 IO L Castillo A Gonzalez and P Perez 223Including a simplicity criterion in the selection of the best rule in a genetic hzzy learning algorithm,\224 Fuzzy Sets and Systems vol 120 vol 2 pp 309-32 1,200 1 0-7803-7280-8/02/$10.00 a2002 IEEE 913 


    f      I i    0 0 m m 100 10 am 1m 1110 lam m am m n am a0 la0 IBO Eo Im 1100 am a minl  10 b mind  20 Figure 6 Performance on Connect-4 11 Figure 7 shows the running time of the three algorithms on the mushroom and pumsb datasets with K set to 500 and mind ranges from 0 to 25 For the mushroom dataset when minl is less than 6 all three algorithm have simi lar low running time TFP keeps its low running time for the whole range of mind and starts to outperform CHARM when minl is as low as 6 and starts to outperform CLOSET when minl is equal to 8 Pumsh has very similar results as connect-4 and mushroom datasets i 1 m j i s 21 di I 2 U  0 I IO I3 1 1 I IO I I 1l ndWRI YUdWR a Mushrwm b Pumsb Figure 7 Performance on Mushroom and Pumsb Sparse Dataset Experiments show that TFP can effi ciently mine sparse datasets without minsupport It has comparable performance with CHARM and CLOSET for low mid and outperforms both on higher mind Figure 8a shows the running times of TFP CHARM and CLOSET on T1014D100K with K fixed at 100 and minl ranges from 1 to 10 Again it demonstrates TFP's strength in dealing with long minl At minl  8 the performance of CHARM and CLOSET starts deteriorating while TFP re tains its good performance Figure 8b shows the perfor mance on the same dataset but with minl fixed at 8 and varying K from 200 to 2000 The curves show that when K is above 400 the running times of CHARM and CLOSET are around 3 times slower than TFP The experiments on the gazelle dataset are shown in Fig ure 9 For smaller K TFP outperforms both CHARM and CLOSET for minl greater than or equal to 5 For K  500 TFP continues to outperform CLOSET for mind greater than or equal to 5 and has similar performance as CHARM Rom this performance study we conclude that TFP has good overall performance for both dense and sparse datasets Its running time is nearly constant over a wide range of K and mind values for dense data Unlike CHARM and CLOSETwhose performance deteriorates as mind increases b L=8 Figure 8 Performance on T1014D100K a K  inn b K  500 Figure 9 Performance on Gazelle TFP's running time stays low The reason is inherent from the mining strategy of TFP CHARM and CLOSET In mast time the support for long patterns is lower than that of short patterns Thus even with the optimal support given both CLOSET and CHARM are unable to prune short fre quent patterns early thus causing much time spent on min ing useless patterns On the other hand TFP is able to use the minl length restriction to cut many short frequent patterns early thus improves its running time instantly In addition TFP does not include any nodes that reside above minl level to participate in the mining process As mind increases more nodes reside above the minie level of the tree means that less conditional FP-trees need to he built thus keeps the running time low Besides the good performance over long minl values the performance of TFP over short minl values even when mind  1 i.e no length constraint is still comparable to that of CLOSET and CHARM In such cases the run ning times between the three do not differ much and both CLOSET and CHARM were run with the optimal support threshold while TFP was not given any support threshold Scalability Test Our performance tests showed that the running time of TFP increases linearly with increased dataset size 5 DISCUSSION In this section we discuss the related work how to gener ate association rules from the mined topk frequent patterns and how to push constraints into the mining process 5.1 Related work Recent studies have shown that closed patterns are more desirable 5 and efficient methods for mining closed pat 217 


terns such as CLOSET 7 and CHARM B have been de veloped However these methods all require a user-specified support threshold Our algorithm does not need the user to provide any minimum support and in most cases runs fater than two efficient algorithms CHARM and CLOSET which in turn outperform Apriori substantially 7 81 Fu et al Z studied mining N most interesting item sets for every length 1 which is different from our work in several aspects 1 they mine all the patterns instead of only the closed ones  2 they do not have minimum length constraintssince it mines patterns at all the lengths some heuristics developed here cannot be applied and 3 their philosophy and methodology of FP-tree modification are also different from ours To the best of our knowledge this is the first study on mining topk frequent closed patterns with length constraint therefore we only compare our method with the two best known and well-performed closed pattern mining algorithms 5.2 Generation of association rules Although topk frequent itemsets could he all that a user wants in some mining tasks in some other cases sjhe wants to mine strong association rules from the mined topk fre quent itemsets We examine how to do this efficiently Items in the short transactions, though not contributing to the support of a topk itemset of length no less than mind may contribute to the support of the items in it Thus they need to be included in the computation which has minimal influence on the performance To derive cor rect confidence we have the following observations 1 The support of every Liternset is derived at the start of min ing 2 The set of topk closed itemsets may contain the items forming subsetjsuperset relationships and the rules involving such itemsets can be automatically derived 3 For rules in other forms, one needs to use the derived topk itemsets as probes and the known minsupport as threshold and perform probe constrained mining to find the support only related to those itemsets 4 As an alternative to the above one can set mind 2 which will derive the patterns readily for all the combinations of association rules 5.3 Pushing constraints into TFP mining Constraint-based mining 14.61 is essential to topk mining since users may always want to put constraints on the data and rules to be mined We examine how different kinds of constraints can be pushed into the topk frequent closed pattern mining deep into the TFP-mining process he succint constraints should be pushed deep to select only those itemsets hefore mining starts and the anti-monotonic Constraint should be pushed into the iterative TFP-mining process in a similar way as FP-growth Second for monotone constraints the rule will also be similar to that in traditional frequent pattern mining is if an itemset mined so far e.g okd satisfies a constraint sum 2 loo adding more items such as e still satisfies it and thus the constraints checking can be avoided in further expansion Third for convertible constraints one can arrange items in an appropriate order so that the constraint can be trans formed into an anti-monotone one and the anti-monotone constraint pushing can he applied First succinct and anti-monotone constraints can be pushed Interested readers can easily prove such properties for top k frequent closed pattern mining 6 CONCLUSIONS We have studied a practically interesting problem mining top-k frequent closed patterns of length no less than mind and proposed an efficient algorithm TFP with several opti mizations 1 using closednodexcount and descendantsum to raise mindupport before tree mining 2 exploring the topdown and bottom-up combined FP-tree mining to first mine the most promising parts of the tree in order to raise rninsupport and prune the unpromising tree branches and 3 using a special indexing structure and a novel closed pattern verification scheme to perform efficient closed pat tern verification Our experiments and performance study show that TFP has high performance In most cases it out performs two efficient frequent closed pattern mining algo rithms CLOSET and CHARM even when they are running with the best tuned minsuppwt Furthermore the method can be extended to generate association rules and to incor porate user-specified constraints Based on this study we conclude that mining topk fre quent closed patterns without minsupport should be more preferable than the traditional minsuppwt-based mining for frequent pattern nuning More detailed study along this direction is needed including further improvement of the performance and flexibility at mining topk frequent closed patterns as well as mining topk frequent closed sequential patterns or structured patterns Acknowledgements We are grateful to Dr Mohammed Zaki for providing the code and data conversion package of CHARM and promptly answering many questions 7 REFERENCES I R Agrawal and R Srikant Fast algorithm for mining 2 A W.-C. Fu R W.-W Kwong and J Tang Mining 3 J Han J Pei and Y Yin Mining frequent patterns 4 R Ng L V S Lakshmanan J Han and A Pang association rules VLDB'94 n-most interesting itemsets ISMIS'W without candidate generation SIGMOD'OO Exploratory mining and pruning optimizations of constrained esociations rules SIGMOD'SR Discovering frequent closed itemsets for association rules ICDT'99 161 J Pei J Ha and L V S Lakshmanan Mining frequent itemsets with convertible constraints ICDE'O1 7 J Pei J Han and R Mao CLOSET An efficient algorithm for mining frequent closed itemsets DMKD'OO 8 M J Zaki and C J Hsiao CHARM An efficient algorithm for closed itemset mining SDM'O2 5 N Pasquier Y Bastide R Taouil and L Lakhal 218 


I Plenary Panel Session J Future Directions in Database Research  456 Chair Surajit Chaudhuri Microsoft Corporation Panelists Hector Garcia-Molina Stanford University Hank Korth, Bell Laboratories Guy Lohman IBM Almaden Research Center David Lomet Microsoft Research David Maier Oregon Graduate Institute I Session 14 Query Processing in Spatial Databases I Chair Sharma Chakravarthy University of Florida Processing Incremental Multidimensional Range Queries in a Direct Manipulation Visual Query Environment  458 High Dimensional Similarity Joins Algorithms and Performance Evaluation  466 S Hibino and E Rundensteiner N Koudas and K.C Sevcik Y Theodoridis E Stefanakis and T Sellis Cost Models for Join Queries in Spatial Databases  476 Mining Association Rules Anti-Skew Algorithms  486 J.-L Lin and M.H Dunham Mining for Strong Negative Associations in a Large Database of Customer Transactions  494 A Savasere E Omiecinski and S Navathe Mining Optimized Association Rules with Categorical and Numeric Attributes  503 R Rastogi and K Shim Chair: Anoop Singhal AT&T Laboratories S Venkataraman J.F Naughton and M Livny Remote Load-Sensitive Caching for Multi-Server Database Systems  514 DB-MAN A Distributed Database System Based on Database Migration in ATM Networks  522 T Hara K Harumoto M Tsukamoto and S Nishio S Banerjee and P.K Chrysanthis Network Latency Optimizations in Distributed Database Systems  532 I Session 17 Visualization of Multimedia Data I Chair Tiziana Catarci, Universita di Roma 223La Sapienza\224 W Chang D Murthy A Zhang and T.F Syeda-Mahmood Global Integration of Visual Databases  542 X 


The Alps at Your Fingertips Virtual Reality and Geoinformation Systeps  550 R Pajarola l Ohler P Stucki K Szabo and P Widmayer C Baral G. Gonzalez and T.C Son Design and Implementation of Display Specifications for Multimedia Answers  558 1 Session 18 Management of Objects I Chair: Arbee Chen National Tsing Hua University P Boncz A.N Wilschut, and M.L. Kersten C Zou B Salzberg, and R Ladin 0 Wolfson S Chamberlain S Dao L Jiang, and G. Mendei Flattening an Object Algebra to Provide Performance  568 Back to the Future Dynamic Hierarchical Clustering  578 Cost and Imprecision in Modeling the Position of Moving Objects  588 ROL A Prototype for Deductive and Object-Oriented Databases  598 A Graphical Editor for the Conceptual Design of Business Rules  599 The Active HYpermedia Delivery System AHYDS using the M Liu W Yu M Guo and R Shan P Lang W Obermair W Kraus and T Thalhammer PHASME Application-Oriented DBMS  600 F Andres and K. Ono S Chakravarthy and R Le S Mudumbai K Shah A Sheth K Parasuraman and C Bertram ECA Rule Support for Distributed Heterogeneous Environments  601 ZEBRA Image Access System  602 Author Index  603 xi 


11  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02  data bindings domain-specific metric for assessing module interrelationship  interface errors errors arising out of interfacing software modules  Porter90 Predicting software  faults 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 From decision trees to association rules  Classifiers  223this and this\224 goes with that \223class\224  conclusions \(RHS\ limited to one class attribute  target very well defined  Association rules  223this and this\224 goes with \223that and that\224  conclusions \(RHS\ may be any number of attributes  But no overlap LHS and RHS  target wide open  Treatment learning  223this and this\224 goes with \223less bad and more good\224  223less\224,  \223more\224: compared to baseline  223bad\224, \223good\224: weighted classes Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


12  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Association rule learning  www.amazon.com  Customers who bought this book also bought  The Naked Sun by Isaac Asimov  The Caves of Steel by Isaac Asimov  I, Robot by Isaac Asimov  Robots and Empire by Isaac Asimov 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Support and confidence  Examples = D , containing items I  1: Bread, Milk 2: Beer Diaper Bread, Eggs 3: Beer Coke, Diaper Milk 4: Beer Bread, Diaper Milk 5: Coke, Bread, Diaper Milk  LHS  RHS = {Diaper,Milk  Beer  Support       =   | LHS U RHS|  / | D |       = 2/5 = 0.4  Confidence  =   | LHS U RHS |  / | LHS |    = 2/3 = 0.66  Support-based pruningreject rules with s < mins  Check support before checking confidence Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


13  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Example of supportbased pruning 4 Bread 1 Eggs 4 Diaper 3 Beer 4 Milk 2 Coke Count 1Item 3 Beer,Diaper 3 Milk, Diaper 2 Milk,Beer 3 Bread, Diaper 2 Bread,Beer 3 Bread,Milk Count 2Item 2 Milk, Diaper Beer 3 Bread,Milk Diaper Count 3Item Support-based pruning 225 Min support =3 Ignore subsets of items of size N 225 only if N-1 support > min-support Without pruning 6 C 1  6 C 2  6 C 3 41 With pruning: 6 + 6 + 2 = 14 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Classifiers versus Association rules \(again  Classifiers  Assume entire example set can fit into RAM  Association rule learners  can handle very big data sets  Agraw  t he APRIORI alg o r i t h m   very large data sets  10,000,000 examples  843MB Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


14  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 The Data Mining Desiderata Bradley  Require one scan \(or less\ of the database if possible  On-line \223anytime\224 behavior  223best\224 is always available, with status information on progress, expected remaining time, etc. provided  Suspendable, stoppable, resumable  incremental  progress saved to resume a stopped job  Ability to incrementally incorporate additional data with existing models efficiently  Work within confines of a given limited RAM buffer  Ooops, good-bye traditional classifiers e.g. C4.5  Argued against by some  223Memory is cheap\224: [W A R2 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Conf1  outlo o k overc a s t   1 0   82  40    84  40   4 0 0  Treatment learning sunny, 85 86 false none \(2 1 2 sunny, 80 90 true none sunny, 72 95 false none rain 65 70 true,          none rain, 71 96 true none rain 70  false some \(2 2 4 rain, 68 80 false,  some rain, 75 80 false some sunny,      69 70 false lots    \(2 3 8 sunny,      75 70 true lots overcast,     83  false lots overcast,     64  true lots overcast,     72  true lots overcast,     81 75 false lots outlook temp humidity wind hours on course A good attribute range 225 More frequent in good that bad 225 Weighted by 223distance\224good to bad 225 Normalized by total count 225 Summed for all good/bad class pairs Lots  none Lots  some Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


15  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 sunny, 85 86 false none \(2 1 2 sunny, 80 90 true none sunny, 72 95 false none rain 65 70 true,           none rain, 71 96 true none rain 70  false some \(2 2 4 rain, 68 80 false,  some rain, 75 80 false some sunny,      69 70 false lots    \(2 3 8 sunny,      75 70 true lots overcast,     83  false lots overcast,     64  true lots overcast,     72  true lots overcast,     81 75 false lots 0 1 2 3 attribute ranges with deltaf 4-2024681 conf1 225 treatments 002 attribute.range.conf1 > X 225 treatments|=N 225TAR2 = O\(2 N  225 fails for large N outlook temp humidity wind hours on course Conf1  outlo o k overc a s t   1 0   82  40    84  40   4 0 0  Lots  none Lots  some 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Treatments for golf 0 1 2 3 4 none some lots I f outl ook o verc as t Th en l o t s o f go l f  4 4  0 Least monitor watch the humidityalert if rising over 90 Least change pick a vacation location with overcast weather I f h u m i d i t y  90  97 Th en l o t s o f go l f  1 4  0 1 2 3 none some lots 0 1 2 3 4 5 6 none some lots If n o ch an ge Th en l o t s o f go l f  6 6 3 5  3  Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


16  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 6.7 <= RM < 9.8 And 12.6 <= Ptratio 15.9 BEST ACTION 0.6 <= NOX < 1.9 and 17.16 <= LSTAT < 39 WORST ACTION BASELINE 500 examples  of bad--, bad, ok, good Stop staring at the scenery and tell me where to steer or what to dodge 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Require overall require2 require3 require5 require4     action1 action1, action2, action3,  \205   Cost,    Benefit 1 Y              Y             N,        \205   23200,  250 2           N              N             Y ,       \205   11400,  150 205..       \205             \205            \205        \205   \205         \205 action2 fault2 fault3 fault1 JPL requirements Feather&Menzie Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


17  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study 99 proposed actions for deep space satellite design; 2 99 10 30 options Each row is one project plan action1, action2, action3,  \205   Cost,    Benefit 1 Y              Y             N,        \205   23200,  250 2           N              N             Y ,       \205   11400,  150 205..       \205             \205            \205        \205   \205         \205 Learnt 225 Do 16 225 Don\222t do 14 225 Ignore 66 options 225 c.f. genetic algorithms Each dot  is one randomly generated project plan 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Pr of tampering 0.02 Pr of fire 0.01 Pr of smoke  given [fi  0.90 Pr of smoke  given [fi  0.01 Pr of report given [exodus=ye 0.75 Pr of report given [exodus=no 0.01 Pr of exodus given [alarm=yes 0.88 Pr of exodus given [alarm=no 0.001 etc tampering fire alarm smoke exodus run away report hello, operator I want to report a fire 0.02 0.01 Use Bayesian analysis to update probabilities given new information Use Bayesian analysis to update probabilities given new information Bayesian Tuning Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


18  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 tampering fire alarm smoke NO exodus report YES 0.50 was 0.02 0.03 was 0.01 Q1: What if there is a report, but no smoke Q1: What if there is a report, but no smoke Q2: What if there is a report, and smoke Q2: What if there is a report, and smoke tampering fire alarm smoke YES exodus 0.03 was 0.02 0.97 was 0.01 report YES Example from : [Poole98   p37 1 Source = http:// www.swi.psy.uva.nl/projects/SWI-Prolog/download.html http://www.cs.ubc.ca/spider/poole/ci/code.tar.gz Files    = code/acp/bnet.pl code/acp/bnet_t1.pl Bayesian Tuning 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Non-na\357ve model bayesian network Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


19  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Low testing effort EXPLAINS 1\ some observed operational defects  and 2\ low pre-release defects 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02  Ancestors  ancestor\(X,Y\:-parent\(X,Y  ancestor\(X,Y\:-parent\(X,Z\ancestor\(Z,Y  Lists  member\(X,[X|Z   member\(X,[Y|Z me mb er X Z   append X X   append\([X|X Y s X Z s  a ppe nd X s Ys Z s  Example Example action action hypothesis hypothesis p\(b,[b add clause p\(X,Y   specialize p\(X,[V p\(x,[a specialize p\(X,[X p\(b,[a add clause p\(X,[X p\(X,[V p\(X W Inductive Logic Programming Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


20  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 East-West trains 1. TRAINS GOING EAST 2. TRAINS GOING WEST 1 2 3 4 5 1 2 3 4 5 1. TRAINS GOING EAST 2. TRAINS GOING WEST 1 2 3 4 5 1 2 3 4 5 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 ILP representation  Example eastbound\(t1  Background theory car\(t1,c1\      car\(t1,c2\       car\(t1,c3\.      car\(t1,c4 rectangle\(c1\  rectangle\(c2\     rectangle\(c3\.   rectangle\(c4 short\(c1\      long\(c2\.          short\(c3\       long\(c4 none\(c1\.        none\(c2\.          peaked\(c3\.      none\(c4 two_wheels\(c1\  three_wheels\(c2\two_wheels\(c3\two_wheels\(c4 load\(c1,l1\.     load\(c2,l2\       load\(c3,l3\    load\(c4,l4 circle\(l1\      hexagon\(l2\       triangle\(l3\    rectangle\(l4 one_load\(l1\  one_load\(l2\.      one_load\(l3\    three_loads\(l4  Output ne\(C Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


21  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Predicting Correctness Almei NewID CN2 C4.5 C4.5_rule FOIL Accuracy 52 54 66 68 73 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 FOIL\222s best rule high\(A executable\(A,B maximum_statement_nesting_depth\(A,C lines_of_comments\(A,B commentsdivsize\(A,E n1\(A,F n2\(A,G less_or_equal\(E,F not less_or_equal\(B,G C <> 4 C <> 43 less_or_equal\(C,D High faults when comment density <= #operators and executable statements > #operators and max nesting <= number of lines of comments and max nesting is not 4 or 43 High faults when comment density <= #operators and executable statements > #operators and max nesting <= number of lines of comments and max nesting is not 4 or 43 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


22  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Inside  some learners  neural nets  genetic algorithms  decision tree learners  association rule learners  treatment learners  bayesian tuning  inductive logic programming 225 sub-symbolic locally guided descent symbolic, global search 225 recursive diversity reduction 225 this goes with that CLASS 225 this goes with that 225 asses 225 a little model goes a long way 225 Horn clauses  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case studies predicting effort \(45 predicting faults \(51 model-based ML \(54 early lifecycle project planning \(60 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


23  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study How can we estimate earlier in the life cycle  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Predicting development times in months\Srinivasan95 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


24  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Bayes for effort Chulani99  The COCOMO-II project  Open-source software cost estimation  Reuse vs effort XH : multiple product lines VH : across product lines H : across program N : across project L  : none  Regression over data from 83 software projects  Regression conflicted with \223Delphi values\224  Tune regression values using Delphi expectations 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5 1.6 Low N H VH XH Delphi Regression Adjusted Da ta   reus e low e rs effo r t Ex pe ct e d  reus e incre a se  effo r t    251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 COCOMO-II \(1998\COCOMO-II \(1997 Pred\(30 Pred\(25 Pred\(20 Pred\(X 52 49 46 83 projects 63 59 54 161 projects 7561 68 55 63 48 161 projectsbased on Bayesian 161 projectsbased on Delphi Percentage of estimated effort within X of actual Conclusion data + delphi tuning\a Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


25  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Neural Network Count the wi dge ts in the I n te r f ace to es ti m a te e f f o r t  Labels Edit Boxes Grid Boxes Check Boxes Buttons 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Neural Network Subsystem Pred\(25 MARE Buyer Admin 80 17.6 Buyer Client 80 14.6 Distribution Server 20 96.7 Supplier Client 90 12.2  12 Different Widgets Counted and associated with effort Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


26  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study: Predicting software 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Predicting software  faults Khoshgoftaar99 Whi c h d o g s di d not ba r k  225 42 attri b ute s  in dat a s e t 225 Only 6 in the l e arnt th e o ry Diffe re nt attri b ute s than b e fore 225 223c au se s f a u l t 224  do m a in s pec i f i c 225 Me thod for fin d ing fa ult s  gen e r a l Whi c h d o g s di d not ba r k  225 42 attri b ute s  in dat a s e t 225 Only 6 in the l e arnt th e o ry Diffe re nt attri b ute s than b e fore 225 223c au se s f a u l t 224  do m a in s pec i f i c 225 Me thod for fin d ing fa ult s  gen e r a l Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


27  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Issue of generality  Specific conclusions may not apply to general projects  Proposal one  Intra-project learning  Lessons should generalize across the same developer methodology, application and tool set  Proposal two  Inter-project learning  Need larger training set  COCOMOII uses 161 projects  Note: two = N * one Khoshgoft good bad Tia bad good  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Model-based ML Bratko89,Pearc Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


28  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Model-based ML simple e.g sum\(X,  Y Z sum   sum   sum\(0 0 0 sum 0  sum 0  sum\(0   sum\(0   sum  Any sum  Any if X >0 X\222=      if X < 0 0 if X= 0  switch\(State,Volts,Amps switch\(on,       0,     Any switch\(off,      Any,   0 blub\(Mode,Light,Volts,Amps bulb\(blown,dark, Any 0 bulb\(ok,     light   bulb\(ok,    light   bulb\(ok,    dark 0 0 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 A qualitative circuit go  :tell\('circ.data'\ go1, told go1 :functor\(X,circuit,9\ forall\(X, example\(X example\(circuit\(Sw1,Sw2,Sw3,B1,B2,B3,L1,L2,L3\classification\(B1,B2,B3,Class format\('~a,~a,~a,~a,~a,~a,~a~n Sw1,Sw2,Sw3,L1,L2,L3,Class  classification\(B1, B2, B3,Class needs 2 our of three bulbs working classification\( ok, ok, B3,   good classification\( ok, B2, ok,   good classification\( B1, ok, ok,   good classification\( B1, B2, B3,   bad Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


29  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Results from > 700 examples circ.names good,bad switch1: on, off switch2: on, off switch3: on, off bulb1: light, dark bulb2: light, dark bulb3: light, dark Command line c4.5 -f circ -m 2 W a t c hing bulb1 tells us th e rest Insight f ul  Or dull W a t c hing bulb1 tells us th e rest Insight f ul  Or dull 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 More Model-based ML Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


30  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 ca n we r e v i s i t thos e warranti e s   Run 1 35,000 tions  Learn 1  Run 2 if Sw2c=off then 3264 tions  Learn 2  Run 2 if Sw2c=off n then 648 tions  Learn 3 Ca n\222t clos e  Sw3c warranty issu es No b u d g e t  for e x p e ns i v e ha rd wa r e 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 3 \223tunings\224 5 SLOC guesstimates 150,000 runs Treatments for software projects Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


31  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 flex=1 pmat=3 sced=2 rest anything from kc1 150,000 runs 150,000 runs Treatments for software projects \(ii 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 pmat=2 acap=2 sced=2 rest anything from kc1 30,000 runs 30,000 runs Treatments for software projects \(iii Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


32  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 ons discussion \(64 downloads \(69 further reading \(71 references \(72 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Will you try ML  Have we motivated you  Will you rush home and do ML on your data  Clearly  ML algorithms work  Caution  you may find it harder than you think Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


33  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Many ways to learn numerous case studies but there is still a problem Theme Learning is a solved problem \(sort of Data collecting and modeling is not 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Be warned match your ML goals to your software process level Project metrics coarse-grain conclusions Product metrics product learning Process metrics process learning Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


34  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Also, match your tool to task Task ML Tool Assembly line robot deciding what to reject Decision tree learner Repair robot trying to do the least to fix the rejected parts Treatment learner Predicting the life of a robot Neural Network Optimizing the assembly line Genetic Algorithm If clustering when no classes iation rule learning If simple background knowledge Bayesian If complex relational background knowledge ILP 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Have we learnt enough  Not yet  But wait Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


35  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Cost = $0  WEKA  E.g. http://www.cs.waikato.ac.nz/~ml/weka/: ML in JAVA 003 decision tree inducers,rule learners, naive Bayes, decision tables locally weighted regression  GDB_Net  http://nas.cl.uh.edu/boetticher/gdb_net.zip  TAR2  http://www.ece.ubc.ca/twiki/bin/view/Softeng/TreatmentLearner  APRIORI  http://fuzzy.cs.uni-magd eburg.de/~borgelt/apriori/apriori.html#download  And many others  E.g. ML  A public domain \223C\224 library of common algorithms  Naive Bayes, ID3, MC4 , Decision Tables ,   Holte's OneR CN2,\205  http://www.sgi.com/tech/mlc/utils.html 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Cost > $0  C4.5  Comes with the book Quinlan  C5.0  http://www.rulequest.com/download.html  Microsoft SQL SERVER 2000\231  Comes with numerous machine learning tools  Proprietary algorithms  Etc  223data mining\224 \223commercial software\224 in Google  3,340 links  223data mining consultancy\224 in Google  850 links Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


36  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Further reading  Mendonca  great rev i e w art i cl e on ML  Large list of available tools  All the things you can do with a decision tree [Menzies0  Treatment learning: [Menzies01a  Michalski\222s excellent survey of ML types [Michalski  Neural nets: [Boetticher01  Special issue SEKE journal, knowledge discovery Morasca99  Inductive logic programming [Bergadano95,Cohen95  Come by IJCAI 2011 and I\222ll tell you all about it\222s applications  Genetic algorithms: [Goldberg8  Bayesian learning [Cheeseman88 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 References  Agrawal  Agrawal, R., and T.Imeilinski and A.Swami \223Mining Association Rules between Sets of Items in Large Databases,\224 Proceedings of the 1993 ACM SIGMOD Conference Washington DC, USA  Bergadan  Bergadano, F., and D.Gunetti Inductive Logic Programming: From Machine Learning to Software Engineering The MIT Press, 1995  B  Berry, M. J. A., and G., Linoff Data Mining For Marketing, Sales, and Customer Support John Wiley Sons, Inc., New York, 1997  Boetticher01  Boetticher, G., "An Assessment of Metric Contribution in the Construction of a Neural Network-Based Effort Estimator Second International Workshop on Soft Computing Applied to Software Engineering  Enschade, NL, 2001 Available from http://nas.cl.uh.edu/boetticher/publications.html  Boetticher01  Boetticher, G., "Using Machine Learning to Predict Project Effort: Empirical Case Studies in Data-Starved Domains First International Workshop on Model-based Requirements Engineering San Diego, 2001 Available from http://nas.cl.uh.edu/boetticher/publications.html  Bradley  Bradley, P., U. Fayyad, and C. Reina. \223Scaling clustering algorithms to large databases\224. In KDD'98  B  Bratko, I., I. Mozetic, and N. Lavrac KARDIO: a Study in Deep and Qualitative Knowledge for Expert Systems MIT Press, 1989  Breim  Breiman, L., J. Friedman, R. Olshen, C. Stone, \223Classification and Regression Trees,\224 Wadsworth International Group, 1984 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


37  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 References  Burgess  Burgess, C.J., and Martin Lefley. \223Can genetic programming improve software effort estimation? A comparative evaluation,\224 Information and Software Technology er 2001  Cheesem  P. Cheeseman, D. Freeman, J. Kelly, M. Self, J. Stutz, and W. Taylor. \223Autoclass: a bayesian classification system,\224 In Proceedings of the Fifth International Conference on Machine Learning  Morgan Kaufman, 1988  Chulani  S.Chulani,  B. Boehm, and B. Steece 223Bayesian analysis of empirical software engineering cost models,\224 IEEE Transaction on Software Engineering 25\(4\ly/August  1999  Cohe  W. W. Cohen, \223Inductive specification recovery: Understanding software by learning  from example behaviors,\224 Automated Software Engineering 2:107-129, 1995  DeJon  DeJong, K.A., and Spears, W.M. "An Analysis of the Interacting Roles of Population Size and Crossover in Genetic Algorithms Proc. First Workshop Parallel Problem Solving from Nature  Springer-Verlag, Berlin, 1990  Dietteric  Dietterich, T. G., \223Machine Learning  Research: Four Current Directions,\224 AI Magazine 18 \(4\97 Pp. 97-136. Available from ftp://ftp.cs.orst.edu/pub/tgd/papers/aimag-survey.ps.gz  s  Feather, M.S., and T. Menzies: \223Converging on the Optimal Attainment of Requirements IEEE Joint Conference On Requirements Engineering  ICRE'02 and  RE'02 9-13th September, University of Essen, Germany, 2002. Available from http://tim.menzies.com/pdf/02re02.pdf 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 References  Fenton00  Fenton, N., and  M. Neil \223Software Metrics: A Roadmap,\224 International Conference on Software Engineering, 2000. Available from http://www.dcs.qmul.ac.uk/~norman/papers/metrics_roadmap.pdf  Goldberg  Goldberg, D.E Genetic Algorithms in Search, Optimization, and Machine Learning Addison-Wesley Reading, Massachusetts, 1989  Khoshgoftaar  Khoshgoftaar, T.M., and E.B. Allen. \223Model software quality with classification trees,\224 in H. Pham, editor 223Recent Advances in Reliability and Quality  Engineering\224, World Scientific, 1999  Mendonc  Mendonca, M., and N.L. Sunderhaft, \223Mining Software Engineering Data: A Survey,\224 A DACS State-ofthe-Art Report September 1999. Available from http://www.dacs.dtic.mil/techs/datamining  Menzie  Menzies, T., \223Practical Machine Learning for Software Engineering and Knowledge Engineering,\224 ftware Engineering and Knowledge Engineering volume 1, 2001\vailable from http://tim.menzies.com/pdf/00ml.pdf  Menzies01a  Menzies, T., and Y. Hu, \223Reusing models for requirements engineering,\224 First International Workshop on Model-based Requirements Engineering 2001. Available from http://tim.menzies.com/pdf/01reusere.pdf  Menzies01b  Menzies, T., and Y. Hu, \223Constraining discussions in requirements engineering,\224 First International Workshop on Model-based Requirements Engineering San Diego, 2001. Available from http://tim.menzies.com/pdf/01lesstalk.pdf  Menzie  Menzies. T., and J. Kiper, \223Better reasoning about software engineering activities,\224 Automated Software Engineering 2001. Available from http://tim.menzies.com/pdf/01ml4re.pdf Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


38  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02  Michalski90   Michalski, R.S., \223Toward a unified theory of learning,\224  In B.G. Buchanan and D.C. Wilkins, editors 223Reading in Knowledge  Acquisition and Learning\224, pages 7--38. Morgan Kaufmann, 1993  Mitchell  Mitchell, T Machine Learning McGraw-Hill, 1997  Morasca99  Morasca, S., and Gunther Ruhe, Guest editors' introduction of the Special issue on \223Knowledge Discovery from Software Engineering Data,\224 International Journal of Software Engineering and Knowledge Engineering October, 1999  Pearce  Pearce, D., \223The induction of fault diagnosis systems from qualitative models,\224 in Proc. AAAI-88 1988  Poole9  Poole, D. L.,  A. K. Mackworth, and R. G. Goebel Computational Intelligence: A Logical Approach  Oxford University Press, New York, 1998  Porter9  Porter, A.A., and R.W. Selby  \223Empirically guided software development using metric-based classification trees,\224 IEEE Software Pp. 46-54, March 1990  Quinla  Quinlan, R C4.5: Programs for Machine Learning Morgan Kaufman, 1992  Srinivasa  Srinivasan, K., and D. Fisher,  \223Machine learning approaches to estimating software development effort,\224 IEEE Transactions on Software Engi neering Pp. 126-137, February 1995  Tian9  Tian, J., and M.V. Zelkowitz 223Complexity measure evaluation and selection,\224 IEEE Transactions on Software Engineering 21\(8\p. 641-649,  August 1995  Webb0  Webb, G., \223Efficient search for association rules,\224 Proceeding of KDD-2000 Boston, MA,  2000  Zhang0  Zhang, Du, \223Applying Machine Learning Algorithms in Software Development,\224 Modelling Software System Structures in a fastly moving scenario Santa Margherita Ligure, Italy, 2000 References Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 



Yin Li Chuang Lin Tsinghua National Laboratory for Information Science and Technology TNList Tsinghua University Beijing China Email yinli chlin csnet1.cs.tsinghua.edu.cn 
  
PipeFlow Engine Pipeline Scheduling with Distributed Workîow Made Simple 
Distributed computing system is considered as a fundamental architecture to extend resources such as computation speed storage capacity and network bandwidth which are limited for a single processor Emerging big data processing techniques like Hadoop take advantages of distributed servers to accomplish scalable parallel computations Large 
Abstract 
scale processing jobs can run on different servers or even different clusters interdependently and be combined together as a workîow to provide meaningful outputs In this paper we analyze the common demands of big-data processing and distributed big-data workîow processing According to that we design PipeFlow Engine that has the matching features to meet each of these demands It orchestrates all involved jobs and schedules them in a batched pipeline mode We also present two online ranking algorithms that make use of the PipeFlow sharing the experience and best practice of using PipeFlow I I 
PipeFlow workîow pipeline performance 
Keywords 
NTRODUCTION Scalable systems give more focus on distributed architecture as both CPU clock speed storage and network I/O bandwidth for a single machine form a bottleneck when dealing with large scale of data Parallel tasks are either mapped or sharded to different server nodes taking advantages of distributed resources Google cluster combines more than 15,000 commodity-class PCs to run their web search engine Some of the distrib uted processing and storage softwares Google has built have already become successful open-stack cloud frameworks such as Hadoop MapReduce GFS HBase These tools split a single job or set of data into several parts that are mapped to different servers For jobs that are scheduled as a whole without sharding they are also 
assigned to different nodes for performance considerations To obtain a desired result it usually requires fetching and processing a large set of data and run several interdependent jobs Google has 1 PB of new data every 3 days not to mention the total data amounts The data needs to be fetched from thousands and hundreds of sites parsed to structured data sets and indexed for search All these jobs are bonded together to make the outputs searchable and run in a distributed way A workîow engine is a tool to monitor and coordinate the job executions Without an automatic tool to handle the complicated orchestration of correlated jobs operators need to check whether it is the right time to launch 
a job by manually monitoring the progress of the workîow In addition the limitation appears when users need to deìne workîows using the metrics operators cannot easily observe such as the performance of the jobs in a workîow In the distributed system environment a controller is responsible for scheduling jobs in the cluster according to each jobês requirement and system status Jobs are submitted to the controller requesting for arbitration The controller is viewed as a master in our system and the result of arbitration is a speciìc slave that is allocated to the submitted job The large volumes of data and tasks are usually processed within several rounds In each round a small part of them is fetched and processed to produce a small set of results 
The reasons that the whole data set is divided into several pieces are threefold 1 the cost of one-round failure will be amortized to be low 2 the output of each round can immediately be obtained as the input of another job therefore jobs can be formed a pipeline and run in parallel 3 users usually desire interactive data processes as they can check the progress and validity of the intermediate outputs PipeFlow Engine is designed to meet these requirements It is a distributed workîow engine that consists of both the master node and slave nodes The master runs as an arbitrator and scheduler while slave nodes respond it to handle each job PipeFlow is extensible and exible Users 
can add slave nodes either before the engine starts or at run-time PipeFlow Engine can process each job in three different modes mode mode and mode mode is the simple processing way that takes the whole data set as the input set Users can use mode if they need to divide the data set into several and run one of them in each round mode takes all the segments 
run run-one run-all Run run-one segments Run-all 
currently available and gathers them together as the whole input data set Users can specify the running mode of each job in a workîow To use PipeFlow users need to deìne a workîow in a conìguration le containing the information of each job in the workîow such as how to execute the job the input/output paths the related jobs it depends on Users also need to specify the orchestration of the jobs in another le using the provided APIs and then submit workîows as the same as using a single-node server workîow engine which makes the interface transparent to users 
2013 19th IEEE International Conference on Parallel and Distributed Systems 1521-9097/13 $26.00 © 2013 IEEE DOI 10.1109/.30 142 
2013 19th IEEE International Conference on Parallel and Distributed Systems 1521-9097/13 $31.00 © 2013 IEEE DOI 10.1109/.30 142 
2013 19th IEEE International Conference on Parallel and Distributed Systems 1521-9097/13 $31.00 © 2013 IEEE DOI 10.1109/.30 142 
2013 19th IEEE International Conference on Parallel and Distributed Systems 1521-9097/13 $31.00 © 2013 IEEE DOI 10.1109/.30 142 
2013 19th IEEE International Conference on Parallel and Distributed Systems 1521-9097/13 $31.00 © 2013 IEEE DOI 10.1109/.30 142 
2013 International Conference on Parallel and Distributed Systems 1521-9097/13 $31.00 © 2013 IEEE DOI 10.1109/ICPADS.2013.31 142 


PipeFlow Engine provides a rich set of APIs that users can use to achieve complicated workîow orchestration For example DAG-styled can be deìned using job-dependency API Jobs can run periodically with or without being checked whether the previous rounds of them are nished or not A job can be speciìed to run on a certain machine or dynamically assigned to the very server with the most idle resources Another goal of our design is to tackle performance issues PipeFlow engine monitors the system status as well as the performance of each job Users can deìne their workîow scheduling policy according to these performance metrics and let the workîow engine make scheduling decisions at run-time By using the performance information users can make better use of the cluster and obtain more desirable results We consider the scenarios of master failures slave failures as well as client failures for fault tolerance By designing schemes to handle these scenarios we make PipeFlow recoverable and able to continue processing from the checkpoint set before the workîow user deìnes fails PipeFlow Engine supports both user-deìned jobs and Hadoop MapReduce jobs It can allow I/O operations of both local lesystems and HDFS Users can deìne MapReduce jobs in a workîow and mix them with ordinary jobs The APIs to different sorts of jobs are identical The goal of PipeFlow Engine is to make the deìnition of distributed workîow with pipeline scheduling simple It is extensible and exible that users can easily implement their own add-ons such as various job triggers We design two online ranking algorithms to demonstrate why PipeFlow Engine is useful for building batched scheduling workîow II R ELATED W ORK Workîow management systems are used in many elds aiming at integrating jobs with temporal relations or other relations of cause and effect There are different categories of workîow systems according to the elds they are designed for such as business process workîow and scientiìc workîow systems Many previous work focused on the composition of workîow tasks by constructing a set of composition models including Map Reduce Tree  Amazon Simple W orkîo w Service Amazon SWF 5 is a workîow service coordinating tasks to build scalable resilient applications in public cloud Google developed MapReduce system to process big data applications on lar ge clusters MapReduce divides a job into bunch of tasks which are mapped and processed on distributed servers The intermediate outputs are collected by Reducer tasks which gather the records with the same keys Hadoop is a popular open-source version of MapReduce and GFS used in the industry to process large-scale data To make MapReduce programming simple Hive 10 and Pig  12 are b uilt on top of Hadoop as script languages which are compiled and translated into workîows consisting of MapReduce jobs There are several workîow systems integrated with Hadoop assembling several jobs as a whole workîow Users can specify relations between jobs using either DAG or scripting languages Oozie is a workîow scheduler system to manage Apache Hadoop jobs Job can be triggered by timer or data availability using Oozie It provides scalability security multi-tenancy and operability  Azkaban 15 used internally at Link edIn achie v es the similar functions However traditional workîows are unsophisticated to handle jobs running on a cluster while peripheral workîow systems of MapReduce are built with singular purpose These systems do not seek to provide a pipeline model to process big data applications leaving the pipelined scheduling to users themselves In addition jobs can only be timer or data triggered in spite that the effects of system and job performance are signiìcant to workîow scheduling Moreover when a workîow fails in the middle of the execution users are hard to restart it from a safe point which causes inconsistency issues and wastes resources III W ORKFLOW P ROGRAMMING M ODEL PipeFlow Engine requires users to register jobs before calling them in the workîow deìnitions Users then deìne the processing logics using PipeFlow script APIs This section describes several steps required to deìne a workîow Users need to notice the workîow engine the information of all the jobs before they are called in the workîow deìnition Job registration and workîow deìnition are two separate steps In doing so the job information can be reused by more than one workîows It also beneìts the workîow consistency since no duplicate jobs will be registered twice or more times by different workîows Once users register a job its information will be available to all the workîows deìned afterward As for PipeFlow Engine jobs are registered through sending a YAML conìguration le to the master  A YMAL conìguration le may consists of several jobs each of which has the following elds represented by YAML key-value map  The Name eld can be quoted to call the registered jobs in workîow deìnitions The Host eld is where the job handler is positioned and should be invoked The master will allocate the right server to the job according to it The Host can be either user-deìned or dynamic assigned For example if the user wants to schedule the job to the most under loaded server node when it is invoked he can put CPU to the Host eld to specify this job favors fast CPU processing 
Workîow system Big data workîow system 
A Job registration Name Host Inputs Outputs Commands 
143 
143 
143 
143 
143 
143 


B Pipeline modes seg 0 seg 1 set 2    run runone runall C PipeFlow APIs check nished True condition closure lambda exec depend 
Even though big data tools like Hadoop is good at processing large scale of data by dividing large job into many small tasks which are processed in a distributed way the data scale at big companies like Google is still gigantic comparative to its cluster size Depending on the job type the incomplete result may lead to inconsistent states or useless outputs if a job fails in the middle of the execution For jobs that run long time it is unacceptable and wastes a lot of computing resources Therefore developers tend to run their jobs round by round For each round only relatively small amounts of data inputs are injected and processed In case a small job comes to a failure it can be restarted without sacriìcing a lot of time and efforts The beneìt that this round-by-round way also brings about is that it enables pipeline processing Whenever a round of sub-job is completed its outputs can be used immediately as the inputs to other jobs An additional advantage enabled by the round-by-round processing is that a job can be run interactively and reports periodically the partial outputs of processed data In other word it makes intermediate data visible to users which can be used to implement feedback systems and help run-time debugging Streaming like Storm is an alternati v e method of pipeline and is highly interactive However it cannot take advantages of batch processing so that it wastes resources such as I/O bandwidths The core feature of big data analytic tools is to use batching mechanism PipeFlow engine automates the round-by-round execution and pipeline in a workîow In the job registration le users can specify if the input is fetched and processed in a pipeline mode and if the result is output in a separate segment for pipelined execution of other jobs or just appended to the existed outputs In pipeline mode inputs or outputs are fetched processed or generated in the form of segments which are subdirectories of the main input or output directory For example an input of a job may consist of  so does an output A job can read and process just one segment in a round or process all currently existed segments ready to read Users can use the following syntax to deìne the processing modes InputName is the input name used by workîow deìnitions InputFS is the source le system where the job can read input data Currently PipeFlow engine supports both local le system and HDFS InputPath is the input directory path It can be either absolute or relative to the PipeFlow home path The option that follows is the speciìcation of process modes If the option is empty the job is in the mode where the data is not in the form of segments If a single equal sign is speciìed in the option the job runs in the mode where the input data is in the form of segments a single one of which is read and processed in each round Similarly a single equal sign in the outputs means the output data is stored in a newly generated segment If for inputs two equal signs are speciìed the job will run in the mode where all segments currently existed and ready to read will be processed in a single round For outputs it is not allowed to have two equal signs deìned Note that each one of the inputs or outputs is independent so different inputs for a job can have different modes speciìed PipeFlow Engine provides rich and exible APIs for users to deìne their workîows Users can deìnes workîows using script language like Python There are three categories of APIs provided by PipeFlow Engine APIs for executing jobs i.e job trigger APIs for obtaining data information for datatriggered jobs and APIs for acquiring the performance of jobs and cluster status Job execution APIs are listed in Table I Every operations Table I J OB E XECUTION API S API Description exec job Execute  If it is set to be which is the default PipeFlow will rstly check whether the job is already in running status e.g the previous round is not nished If the job is in running status the engine will skip the execution operation The can depend on run-time status by passing a  Users can deìne a condition using either function or common function deìnition The condition can be viewed as a trigger to launch a job Triggers include data availability performance driven factors or any other userdeìned boolean functions Timer-triggered execution has already been implemented as APIs Users can specify when to start a job and can also run a job at intervals Users can use API to implement DAG execution plans It is convenient to use it to deìne a workîow with job dependency PipeFlow Engine provides sufìcient data lookup APIs as data availability triggers Every data lookup API is 
Inputs InputName=InputFS::InputPath     Outputs OutputName=OutputFS::OutputPath     
job job cond cond job interval cond job clock job dep job 
exec cond job cond Execute if is True exec cond wait job cond Wait until is True then execute exec period job interval Execute in every secs exec period cond job cond interval Execute if is True periodically exec delay\(job clock Execute at time exec depend job dep job Execute if is nished listed in the table has a optional parameter 
144 
144 
144 
144 
144 
144 


provided with two types lookup in the local le system and lookup in the distributed le system e.g  The same set of lookup APIs is also deìned for outputs The latter two ops are deìned for pipelined jobs They count the number or the size of unìnished or buffered segments for a job The unìnished segments include the running job scheduled by the master while the buffered segments result excludes the currently running job and only count the pending jobs waiting to be scheduled Another useful set of APIs aims at monitoring job and system performance e.g  For the job statistics we currently monitor three metrics job duration throughput and job input arrival rate These three metrics are all calculated as moving average using EWMA method Users can deìne workîows using these monitored metrics e.g users can run a job more frequently whenever the throughput of its dependent job is high We will show a case study in the following section to demonstrate how useful it is to schedule jobs according to their performance The server metrics include CPU speed memory and disk usages Users can use API to nd the best sever node a job can be executed on according to the speciìed criteria such as CPU memory and disk usage Workîow deìnition using PipeFlow Engine is as simple as writing scripts to run jobs in the local machine The only thing users need to do is to create a PipeFlow proxy and invoke PipeFlow APIs to orchestrate jobs registered at PipeFlow master The following template is a simple example of workîow deìnition This workîow deìnes two jobs A and B It rstly execute under the condition user deìned in the class can be launched after is completed If has not nished within 10 mins quits waiting unilaterally Note that although we use sequential script to deìne a PipeFlow instance the execution of the workîow is concurrent PipeFlow Engine does not guarantee all-or-nothing atomic transaction of workîows The fundamental reason is that our design aims at big data analysis which cares less about strong transaction semantics In addition redo/undo operations waste a lot of time and resources on rolling back or regenerating large amount of output data which is inappropriate in the big-data processing elds The more desirable semantic is to support restart operations from where jobs failed and continue processing from the right checkpoints Eventually it will achieve the same goal of original transaction semantic We call this weakened transaction  The following code shows an example of implementing eventual transaction The primitives PipeFlow deìnes execution blocks that enables restoration are and  The code piece deìned between these two primitives is called a  which is stateful The PipeFlow engine keeps the running state of the workîow If the workîow fails in the middle of the checkblock PipeFlow can restart it from where it fails last time Note that checkblock cannot contain operation as this type of operation is stateless Users can always restart this type of job execution from any state In the above example if the workîow failed when Job A was nished but Job B was not it would only execute Job B when recovered IV S YSTEM D ESIGN This section describes the core design of PipeFlow Engine After presenting the overview of PipeFlow design we focus on illustrating three main challenges in the design segment management failure recovery and performance measurement Figure 1 shows the overall infrastructure of the PipeFlow workîow management system PipeFlow Engine consists of one process and many distributed processes More slave processes can be launched at run-time even after master has already started When a slave is started it registers itself to the master which then adds the slave to the worker group and heartbeats to all the slaves periodically If a slave fails or quits from the group it removes the slave from the worker group Users register jobs by sending conìguration information to the master The master receives and parses the conìguration does some transformation For example if the 
get input size job get unìnished  buffered  input seg num job get unìnished  buffered  input seg size job get job stat job metric get server stat job metric nd dynamic host criteria nd dynamic host D Workîow deìnition Job A PipeFlowDef Job B Job A Job A Job B E User-deìned checkblock and restoration eventual transaction begin checkblock end checkblock checkblock exec period A Overview master slave Host 
class PipeFlowDef PipeFlow.Client def condition self job  args  kw if satisfied job return True else return False proxy  PipeFlowDef server_address proxy.exec_cond Job A proxy.condition proxy.exec_dep Job B Job A  timeout  600 class PipeFlowDef PipeFlow.Client pass proxy  PipeFlowDef server_address proxy.exec Job A proxy.exec_dep Job B Job A 
proxy.begin_checkblock CHECK_BLOCK proxy.end_checkblock CHECK_BLOCK 
145 
145 
145 
145 
145 
145 


or  it creates a led and sets it to  Afterwards it lls the elds with the proper resource address The master then shards the job conìguration according to the eld and sends the parsed conìgurations to the corresponding slaves in its worker group If the host of is speciìed as  the information of is sent to  For dynamic jobs their information is sent to all slaves existed in the working group because every time the dynamic job is scheduled it may run on any of the slaves Whenever a new slave is launched after it registers to the master the master will synchronize all the job information to the slave so that the slave can catch up with other slaves In PipeFlow Engine the job conìguration information is persisted in the master node using LevelDB by serializing the job information to key-value form while slaves store the information in memory without being persisted By this way slaves are extensible and maintain consistency with no efforts Users run their workîow deìnitions as client stubs which contact to the master node by RPC calls The master does not hand over clients requests to the corresponding slaves but only accepts job information lookups as similar as DNS After clients obtain the positions where the workîow operations should run they invoke the corresponding slave nodes directly to execute the operations through several other RPC calls The master is also responsible for two other types of requests one is to monitor and get statistics of the cluster status PipeFlow runs on i.e the status of each slave node the other is to nd the appropriate slaves dynamic jobs should be executed on using the statistics Clients adopt asynchronous RPC calls to invoke operations on the slaves whose information the master returns Asynchronous RPC enables clients to register callback functions invoked on the reply of the completion messages without busy waiting for the execution results Slaves implement some basic primitives of workîow operations including job execution data and performance metric lookups Slave only implements the raw operation Other extensions of such as are implemented in the client library The reason we do this is because if is implemented on the slave process it is hard for clients to stop the executions unilaterally even if it could it will cost another RPC call The slave process keeps track of the running jobs when they are scheduled in order to make each job as a singleton if ag is set to the execution operations It is like acquiring a lock for each job Only after the job is nished can another instance of the same job be launched We also implement a distributed lock to guarantee the isolation of two distributed job executions if users specify that two jobs cannot be executed concurrently The distributed lock can be run as an independent process We put it along with the master process For data lookup operations the slaves implement two sets of primitives one for local le system and one for distributed le system By wrapping HDFS APIs it supports Hadoop File System lookups and Hadoop jobs Using PipeFlow APIs as well as Dumbo which is a p ython interf ace of Hadoop users can also deìne workîows with Hadoop MapReduce jobs The client library wraps some operations of slave to implement more complex workîow operations such as  Usually each of these operation contains more than one RPC calls to the slaves One of the main features of PipeFlow is to support pipeline execution by segment management The job input is split using user-assisted method Users only need to split the source input of the rst job in their deìned workîow Then PipeFlow takes over the control of the split segments The segment management component is implemented in both slave process and client library It consists of two-phase tags Before a slave executes a job PipeFlow nds the rst or all buffered segments or unìnished segments if concurrency of the same job is not allowed the job will read inputs from according to the input mode user sets PipeFlow tags these segments as  After the job completes PipeFlow tags them as  These tags enable PipeFlow to nd the right segments to process They are persisted in the input information The process of nding segments and tagging them should be atomic especially if ag is not set for the job so that two or more instances of the same job can be executed concurrently Even for two different jobs it is still possible to have race condition if these jobs operate the same inputs For this case distributed lock service is needed to make sure two distributed jobs with the same input directory are isolated In addition another set of tags is created to indicate whether jobs start or not When a job starts executing PipeFlow tags the job as  which is removed after 
CPU MEM Dynamic true Host Host Job A Host 1 Job A Host 1 exec exec exec period exec period stop check nished exec period B Segment management STARTED FINISHED check nished STARTED 
Figure 1 The overall infrastructure design of the PipeFlow workîow management system eld is speciìed as 
002\003\004\005\006\007  010\005\011\005\003\012\013 014\015\016\017 002\015\006\020\021\022\023\024\007\004\015\006 025\015\023\026\027\015\030\017 012\005\020\006\004\007\004\015\006 031\005\032\015\011\005\023\033\017 010\015\021 034\012\035\036 010\015\032\024\003 035\036 037\005\024\023\007\016\005\024\007 \017 033\006\032 023\005\021\004!\007\005\023\017"\015\016 \017 004\006\011\015\026\005 005#\005\032\022\007\005 \017 021\005\007$\004\006%\022\007$& \017 021\005\007$!\007\024\007 024\032'\022\004\023\005 023\005\003\005\024!\005 002\003\004\005\006\007 036\003\024\011\005 036\003\024\011\005 036\003\024\011\005 036\003\024\011\005 024!\007\005\023 010\015\032\026\017 036\005\023\011\005\023 
146 
146 
146 
146 
146 
146 


the job is nished The nish status is also kept in the slave process as to implement operation indicating the jobs that depend on it is ready to run This set of tags is also used to restart unìnished jobs if slave process failed accidentally They are persisted in the job meta information PipeFlow adopts the atomic output mechanism to handle output data When a job is running PipeFlow redirects its output data to a temporary directory After the job is nished successfully PipeFlow automatically links the temporary directory to the real destination This mechanism guarantees the integrity of output data In addition the atomicity of output segments helps PipeFlow to nd the next segment as output destination and prevent it from overlapping the positions of unìnished segments There are three types of failures in the PipeFlow system master failure slave failure and client failure Since the master only implements job information lookups it only needs to restore job information after failure without caring about job execution states LevelDB has its own failure recovery mechanism that uses logs to persist the data to be restored We design slave and client failure recovery mechanisms as follows Since slave does not record any state of job execution it references the tags PipeFlow persists to recover from failure When slave restarts from failure it checks the started but unìnished jobs and the corresponding segments through parsing from job tags It then restarts these jobs and restores them into the running group that keeps track of all the running jobs Clients keep retrying to connect to that failed slave once in a while The retry process will not block the subsequent operations in the workîow deìnition since all the operations deìned in the PipeFlow are concurrent logically The master will detect failed slaves through heartbeat timeout For dynamically scheduled job the master will choose another slave after the originally assigned slave fails The master will also alter the host information for this job The master notices the new slave to recover and restore the unìnished jobs and corresponding segments that failed in the middle of executions When the original slave wakes up it ignores the unìnished dynamically scheduled jobs that have tags unlike other jobs which are not dynamically scheduled If client fails instead of slave the workîow will enter an inconsistent state where part of operations are sent to the corresponding slaves and the others are not PipeFlow tries to achieve eventual transaction semantic by implementing at-most-once semantic of job invocation Before actually invoking and executing each job deìned in the workîow PipeFlow logs the job in the database indicating the job has been invoked and then sends RPC call to the slave When restarting the workîow from failures PipeFlow engine loads the log and skips the logged job to avoid duplicated execution For operations PipeFlow logs them no matter what values the conditions are so that it will not be executed again in the future As for operations PipeFlow logs them only if they have ever valued such that PipeFlow can retry executing the corresponding jobs when recovering from failures Performance metrics such as execution duration and throughput are measured for every successful jobs and calculated as moving averages We only brieîy explain the relative arrival rate PipeFlow measures This metric indicates how many segments are appended to a job between the period two rounds of the job are executed If this metric is greater than one the arrival rate is beyond the processing rate which means a lot of segments will be pending in the system PipeFlow updates this metric whenever a job is nished and whenever the timely updated metric has already been beyond the value measured since last job has been nished even though this round of the job is still running V O NLINE R ANKING A LGORITHMS U SING P IPE F LOW Online ranking is used to rank online data dynamically with input data arriving in batches in any time Unlike ofîine ranking online ranking cannot rank all the inputs in strict order since it cannot predict what data comes in the future The online ranking algorithm should strike balance between ranking performance and throughput We design two different algorithms using PipeFlow in this section to maximize the throughput while trying to achieve better ranking performance We take AdWork workîow as an example to illustrate the online ranking algorithm AdWork is an advertisement bidding system AdWork workîow is a process to rank the online batch arrival advertisement bids select the ads from high bids to low tag them by keywords and send them to a lter that checks the legality of the ads and archive them to the subsequent processing The archive le should try to adjust the ads with high bids to move as high as possible on the nal results In short the AdWork workîow includes the following jobs RankSelect Tag Filter and Archive RankSelect gathers all unselected ads and sorts them to generate ads with highest bids and puts the other ads in a le which contains unselected les The selected ads are tagged by the Tag job and passed to the lter which fetches and checks the web pages of these ads according to the URLs they provide The lter parses the pages and checks their legality according to the contents Finally the legal ads go to the archive le through the Archive job 
MILESTONE exec dep C Failure recovery STARTED STARTED exec cond exec cond wait True D Performance measurement A AdWork workîow top-N 
147 
147 
147 
147 
147 
147 


          2 
002 003 
The ads arrive in batch In order to make the workîow form a pipeline PipeFlow splits each job in segments and schedules it round by round Each batch of the ads generates a new segment RankSelect reads all the segments every time sorts and selects the ads which are collected as a segment output The Tag and Filter jobs both fetch and generate one segment in each round Archive collects all output segments of Filter and merges them to a single le online To maximum the throughput we should keep the job that is the bottleneck of this workîow as busy as possible In this case Filter is the slowest job since it needs to crawl and parse data from Internet We need to guarantee that Filter always have pending input segments PipeFlow makes the workîow run in pipeline so all the jobs run periodically in parallel We deìne the AdWork workîow as follows The interval of periodical execution is set to 0.1 sec Each job waits to start a new round till the buffered input segment number of its subsequent job becomes 0 We can prove that this algorithm guarantees whatever the bottleneck job is it is kept as busy as possible After the workîow is executed each upstream job of the slowest job gradually saves up one buffered segment and is blocked Once the last buffered segment begins to process its upstream jobs are unblocked successively and begin to execute in parallel almost at the same time Since their processing time is less than that of the bottleneck when the bottleneck job nishes running this round each upstream jobs already generates a new segment So the pipeline keeps running without stopping The sliding window based pipeline algorithm only controls the launch of the rst upstream job to keep the pipeline running without stopping By controlling this job we guarantee there are enough but not too many buffered segments between this job and the bottleneck job to keep the bottleneck job busy The condition to trigger RankSelect job is as follows 1 This condition means that the total number of segments pending at and before the bottleneck job needs to be greater than the ratio of the total duration of upstream jobs over the duration of the bottleneck job Before the metric is available we use the upper bound instead which is the number of the upstream jobs It is derived since the duration of every job is less than that of the slowest job This indicates that the worst case using sliding window based pipeline is the same as using queue feedback based pipeline For long pipeline consisting of many upstream jobs whose duration is much less than that of the slowest job this algorithm is superior to the queue feedback based algorithm because of less in-îight pending segments VI E VALUATION We conìgure the AdWork workîow to run on 4 different servers with NFS setup Each job runs on a different slave The ads bids are generated in batch mode Each batch consists of 1000 ads bids The interval between two batches is exponentially distributed with the average interval set to 2 seconds RankSelect selects ads in a round which can be nished in less than half second as well as the Tag job Filter is the bottleneck processing each ad in 50 ms We tested the two pipeline algorithm using PipeFlow Figure 2\(a compares the average of top-N result collected in the archive le generated by Archive The sliding window algorithm obtains higher average value for top-N bids whatever N values No-control gives the worst results It is because RankSelect without any control selects many bids too early regardless of the higher bids coming in the future The sliding window algorithm is superior because of its strict control with more performance information being considered It enlightens us that with performance metrics involved as the job triggers workîow scheduling can be more efìcient The comparison of standard variance is shown in Figure 2\(b which proves the same results Figure 3 shows the throughputs of the workîow and the relative arrival rate of Filter under three pipeline algorithms The throughputs only have slight different The reciprocal of the throughput is nearly the same with the duration of Filter which is the bottleneck This means the workîow achieves highest throughput we can get under all the three pipelines The relative arrival rate of the input segments for Filter is 10 without any control while the segments are not piled up under queue-feedback and sliding-window control We randomly shut down the slaves and restarted them after a few seconds The workîow continued executing to the normal state We also tested a single round of workîow execution forcefully terminated between Tag and Filter 
class PipeFlowDef PipeFlow.Client def fire\(self job  args  kw return self.get_buffered_input_seg_num   1 proxy  PipeFlowDef\(server_address proxy.exec_cond_period\(èRankSelect 0.1 proxy.fire dep  Tag proxy.exec_cond_period\(èTag 0.1 proxy.fire dep  Filter proxy.exec_cond_period\(èFilter 0.1 proxy.fire sep  Archive proxy.exec_period\(èArchive 0.1 
B Queue feedback based pipeline top-N C Sliding window based pipeline T top-100 
B Tag B F ilter T RankSelect T Tag T F ilter  
002 
148 
148 
148 
148 
148 
148 


002\003\003\003\003 002\002\004\003\003 005\004\003\003\003 006\007\004\003\003 010\003\003\003\003\003 010\003\003 011\003\003 004\003\003 002\003\003 006\003\003 012\013\014\015\016\017\015\020\016\021\022\023\015\024\025\026\027 030\016\021\022\023 023\016\015\031\016\032\020\033\016\034 035\036\037\036\037\015 \037\037\026\024 034\025\026\025\032\014\015%\025\032\026\016 003 004\003\003\003 010\003\003\003\003 010\004\003\003\003 007\003\003\003\003 010\003\003 011\003\003 004\003\003 002\003\003 006\003\003 026'\015\016\017\015\030\016\021\022\023\015\024\025\026\027 030\016\021\022\023 023\016\015\031\016\032\020\033\016\034 035\036\037\036\037\015 \037\037\026\024 034\025\026\025\032\014\015%\025\032\026\016 
 vol 23 no 2 pp 22Ö28 Mar 2003  Making sense of big data in the petabyte age A v ailable http://www.cognizant.com/InsightsWhitepapers/MakingSense-of-Big-Data-in-the-Petabyte-Age.pdf  X Fei and S Lu  A dataîo w-based scientiìc w orkîo w composition framework  vol 5 no 1 pp 45Ö58 Jan 2012  V ie w Scientiìc w orkîo w online Online A v ailable http://www.viewsystem.org  Amazon swf Online A v ailable http://aws.amazon.com/swf  J Dean and S Ghema w at Mapreduce simpliìed data processing on large clusters in  ser OSDIê04 Berkeley CA USA USENIX Association 2004 pp 10Ö10  Apache hadoop Online A v ailable http://hadoop.apache.org  S Ghema w at H Gobiof f and S.-T  Leung The google le system in  ser SOSP 03 New York NY USA ACM 2003 pp 29Ö43  Apache hi v e Online A v ailable http://hi v e.apache.or g  A Thusoo J S Sarma N Jain Z Shao P  Chakka S Anthony H Liu P Wyckoff and R Murthy Hive a warehousing solution over a map-reduce framework  vol 2 no 2 pp 1626Ö1629 Aug 2009  Apache pig Online A v ailable http://pig.apache.or g  A F  Gates O Natk o vich S Chopra P  Kamath S M Narayanamurthy C Olston B Reed S Srinivasan and U Srivastava Building a high-level dataîow system on top of map-reduce the pig experience  vol 2 no 2 pp 1414Ö1425 Aug 2009  Apache oozie Online A v ailable http://oozie.apache.or g  M Islam A K Huang M Battisha M Chiang S Srinivasan C Peters A Neumann and A Abdelnur Oozie towards a scalable workîow management system for hadoop in  ser SWEET 12 New York NY USA ACM 2012 pp 4:1 4:10  Azkaban  Available https://github.com/azkaban/azkaban  Y aml wiki Online A v ailable http://en.wikipedia.org/wiki/YAML  Storm-project Online A v ailable http://storm-project.net  Le v eldb   Available http://code.google.com/p/leveldb  Dumbo Online A v ailable http://klbostee.github io/dumbo 
IEEE Micro IEEE Trans Serv Comput Proceedings of the 6th conference on Symposium on Opearting Systems Design  Implementation Volume 6 Proceedings of the nineteenth ACM symposium on Operating systems principles Proc VLDB Endow Proc VLDB Endow Proceedings of the 1st ACM SIGMOD Workshop on Scalable Workîow Execution Engines and Technologies 
a Average value of Top-N bids b Standard variance of Top-N bids Figure 2 Comparison of the Top-N bids under three different algorithms Figure 3 The relative arrival rate of Filter and execution interval 1/throughput of the workîow After we restarted the workîow it started executing right from Filter without repeating the RankSelect and Tag job VII C ONCLUSION Workîow engine automates the orchestration of correlated jobs that are triggered to execute according to some rules PipeFlow provides a distributed workîow engine that supports the pipeline execution of workîows The convenient APIs and fault tolerant mechanism enable users to deìne and control complex workîow in few lines of code clearly presenting the logic of their workîow A CKNOWLEDGMENT This work is supported in part by the National Basic Research Program of China under Grant No 2010CB328105 2009CB320504 the National Natural Science Foundation of China NSFC under Grant No 60932003 R EFERENCES  L A Barroso J Dean and U H  olzle Web search for a planet The google cluster architecture 
003 011  006 010\007 023\016\015\031\016\032\020\033\016\034 035\036\037\036\037\015 \037\037\026\024 034\025\026\025\032\014\015%\025\032\026\016 003 010'\004 011   037\034!\020\025\013\037\015!\033\033\025\013!\034\015\033!\020\037\015+\027\037\014\027 037"\036\020\025\016\032\015\025\032\020\037\033\013!\034\015/\015\0100\0301\033\016\036\0141\021\036\020\015+\027\037"\027 037\034!\020\025\013\037\015\012\033\033\025\013!\034\015*!\020\037 010\0150\015\0301\033\016\036\0141\021\036\020 
149 
149 
149 
149 
149 
149 


        


  


Bottom Top A B 
Figure 15 Figure 16 
messages seen for all workers in a superstep \(Figures 10 and 13\. When looking at the messages sent by workers in a superstep for METIS, we see that there are message load imbalances within work ers in a superstep, caused due to concentration of vertices being traversed in that superstep in certain partitions This variability is much more pronounced in CP as compared to WG \(Figures 11 and 14\ E.g. in superstep 9 for CP, twice as many messages \(4M\ are generated by a worker compared to another \(2M\.  For Pregel BSP, the time taken in a superstep is determined by the slowest worker in that superstep. Hence increase d variability in CP causes even çgoodé partitioning strategies to cause an increase in total execution time wh en using the Pregel/BSP model VIII A NALYSIS OF E LASTIC C LOUD S CALING  Cloud environments offer elasticity Ö the ability to scale-out or scale-in VMs on-demand and only pay for what one uses [28   On th e f l i p s i de  on e en ds u p  paying for VMs that are acquired even if they are underutilized. We have already shown the high variation in compute/memory resources used by algorithms like BC and APSP across different supersteps. While our earlier swath initiation heuristics attempt to flatten these out by overlapping swath executions, one can consider leveraging the cloudês elasticity to, instead, scale up and down the concurrent workers \(and graph partitions\ allocated in each superstep The peak and trough nature of resource utilization combined with Pregel/BSPês synchronous barrier between supersteps offers a window for dynamic scaleout and Öin at superstep boundaries. Peak supersteps can greatly benefit from additional workers, while those same workers will contribute to added synchronization overhead for trough supersteps We offer an analysis of the potential benefits of elastic scaling by extrapolating from observed results for running BC on WG and CP graphs, using four and eight workers.  To provide a fair and focused comparison, we turned off swath heuristics in favor of fixed swath sizes and initiation intervals Figure 15 \(Bottom\ plots the speedup of BC running on eight workers when normalized to BC running on four workers, at corresponding supersteps.  The number of workers does not impact the number of supersteps We also plot the number of active vertices \(i.e. vertices still computing for a given swath\these supersteps which is a measure of how much work is required \(Fig 15 \(Top\. We find that we occasionally get superlinear speedup spikes \(i.e. >2x\ that shows a strong correlation with the peaks of active messages, for both WG and CP graphs. At other times, the sp eedup is sublinear or even a speed-down \(i.e. <1\responding to inactive vertices.  The superlinear speedup is attributable to the lower contention and reduced memory pressure for 8 workers when the active vertices peak \(similar to what we observed for the swath initiation heuristics Similarly, the below par speedup during periods of low activity is contributed by the increased overhead of barrier synchronization across 8 workers. Intuitively, by dynamically scaling up the number of workers for supersteps with peaking active vertices and scaling them down otherwise, we can leverage the superlinear speedup and get more value per worker Using a threshold of 50% active vertices as the threshold condition for between 4 and 8 workers in a superstep, we extrapolate the time per superstep and compared this to the fixed 4 and 8 worker runtimes. We also compute the best-case run time using an çoracleé approach to i.e. for each superstep, we pick the minimum of the 4 or 8 workerês time.  Note that these projections do not yet consider the overheads of scaling, but are rather used to estimate the potential upside if we had an ideal or an automated heuristic for scaling. The total time estimates for running BC on WG and CP graphs, normalized to  
 plot shows speedup of 8 workers relative to 4 workers, for each superstep, when running BC on WG and CP graphs plot shows the number of vertices active in that superstep Estimated time for BC using elastic scaling, normalized to time taken for 4 workers. Normalized cost is shown on secondary Y axis WG graph shown on left CP graph shown on right. Smaller is better 
022\011 022\010 022\007 022\002 006 002 007 006 002 007 010 011 012 013 014 015 006 006\003\002 006\003\007 006\003\010 006\003\011 006\003\012 006\003\013 006\003\014 006\003\015 006\003\016 002 027\031\030\037\020#@\020"\031\030\027\020\035 0201!2#\024$#\015#5\024",\020"#\017\003"\003\031\003#\011#5\024",\020"\035 024"'\033\026\0309\0201#\\031\020 2 035#\032\020"#+!\034 017\020\021\022\023\024\024\025\026\020 027\030\031\022\032\033\031\020\034\031\035 017\020\021\022\023\024\024\025\026\020#?#/\027\031\030\037\020#@\020"\031\030\027\020\035 027\030\031\022\032\033\031\020\034\031\035#?#/\027\031\030\037\020#@\020"\031\030\027\020\035 036\030\034\020\033"#\\0201!2 006 006\003\007 006\003\011 006\003\013 006\003\015 002 002\003\007 006 006\003\002 006\003\007 006\003\010 006\003\011 006\003\012 006\003\013 006\003\014 006\003\015 006\003\016 002 011#5\024",\020 B\034\0267 015#5\024",\020 B\034\0267 1\0332\031\030\037\020 030\034\025 1\0332\031\030\037\020 036\024\017\020 024!\0341 024\035\031#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#.\024\035\031 017\020\021\022\023\024\024\025\026\020#+!\034\022&\030'\020#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#&\030'\020 011#5\024",\020"#&\030'\020 015#5\024",\020"#&\030'\020 024\035\031 006 006\003\007 006\003\011 006\003\013 006\003\015 002 002\003\007 002\003\011 002\003\013 006 006\003\002 006\003\007 006\003\010 006\003\011 006\003\012 006\003\013 006\003\014 006\003\015 006\003\016 002 011#5\024",\020 B\034\0267 015#5\024",\020 B\034\0267 1\0332\031\030\037\020 033\026\030\034\025 1\0332\031\030\037\020 036\024\017\020 024!\0341 024\035\031#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#.\024\035\031 027\030\031\022\032\033\031\020\034\031\035#+!\034\022&\030'\020#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#&\030'\020 011#5\024",\020"#&\030'\020 015#5\024",\020"#&\030'\020 024\035 031 
 
dynamically scaling ideal scaling 
Our hypothesis is that an intelligent adaptive scaling of workers can achieve a similar performance as a large, fixed number of workers, but with reduced cost 
213 


Nature Nature Ecological Applications Nature ACM International Conference on Management of Data \(SIGMOD In Parallel Object-Oriented Scientic Computing \(POOSC Science Communications of the ACM ACM Workshop on Mining and Learning with Graphs Communications of the ACM HotCloud Proceedings of the 19th ACM International Symposium on High PErformance Distributed Computing HPDC Knowledge and Information Systems KAIS International Conference on Computational Science IEEE International Conference on Cloud Computing Technology and Science ACM/IEEE Conference on Advances in Social Network Analysis and Mining \(ASONAM IEEE International Parallel and Distributed Processing Symposium \(IPDPS International Conference on Distributed Computing and Networking Journal of Mathematical Sociology International Conference on Parallel Processing Communications of the ACM 
 
observed time taken using 4 workers, are plotted in Figures 16\(A\ and 16\(B We see that our dynamic scaling heuristic using the percentage of active vertices achieves nearly the same CP\ or better \(WG\ performance as a fixed 8 worker approach. Clearly there is benefit of using fewer workers for low utilization su persteps to eliminate the barrier synchronization overhead. Also, the dynamic scaling heuristic performs almost as well as the ideal scaling. Finally, when we consider the monetary cost of the proposed approaches, assuming a pro-rata normalized cost per VM-second plotted on the secondary Y axis, we see that dynamic scaling is comparable \(CP\ or cheaper \(WG\ than a 4 worker scenario while offering the performance of an 8 worker deployment IX C ONCLUSION  In conclusion, we introduce optimization and heuristics for controlling memory utilization and show they are critical to performance.  By breaking computation into swaths of vertices and using our sizing heuristics we achieve up to 3.5x speedup over the maximum swath size that does not cause the a failure.  In addition overlapping swath executions can provide a 24% gain with automated heuristics and even greater speedup when a priori knowledge of the network characteristics is applied This evaluation offers help to eScience users to make framework selection and cost-performancescalability trade-offs. Our he uristics are generalizable and can be leveraged by other BSP and distributed graph frameworks, and for graph applications beyond BC. Our work uncovered an unexpected impact of partitioning and it would be worthwhile, in future, to examine the ability to pred ict, given certain graph properties, a suitable partitioning model for Pregel/BSP It may also be useful to perform such evaluations on larger graphs and more numbers of VMs. At the same time, it is also worth considering if non-linear graph algorithms are tractable in pr actice for large graphs in a distributed environment B IBLIOGRAPHY  1  F  L i lj er os C   Ed l i n g L  A m a r a l H  S t an ley   and Y    berg The web of human sexual contacts 
vol. 411, pp. 907908, 2001   H Je o n g  S   Ma so n A  L   B a ra b s i  a nd Z   Oltva i  L e t ha l i t y  and centrality in protein networks vol. 411, pp. 41-42 2001   O. B o din and E   E s t r ada    U s i n g n e t w ork c e nt r a l i t y  m e a s ures t o  manage landscape connectivity vol 18, no. 7, pp. 1810-1825, October 2008   D. W a ts s  and S  S t r ogat z  C olle c t i v e  d y nam i cs of  s m a ll-w orl d   networks vol. 393, no. 6684, pp. 440Ö442, June 1998   G  Ma lew i c z   M A u s t er n A   Bik  J   Dehn er t I  Hor n   N. L e i s er and G. Czajkowski, "Pregel: A system for large-scale graph processing," in 2010   D. G r egor  and A  L u m s dain e  T h e  pa r a llel  B G L  A gen e r i c  library for distributed graph computations," in 2005   B. S h a o  H. W a n g  and Y  L i T he T r init y G r aph E n g i n e    Microsoft Research, Technical Report MSR-TR-2012-30, 2012   A  F ox  C lo ud c o m putin g w h at  s  in it for m e  as  a  s c i e n tis t     vol. 331, pp. 406-407, 2011   S. G h e m a w a t  and J  De an   Map re duc e s i m p lifi e d data  processing on large clusters vol 51, no. 3, pp. 107-113, 2008   J  L i n and M. S c hat z   Des i g n  patt er n s  for eff i ci ent gr aph algorithms in MapReduce," in 2010   L   Va l i ant   A b r id g i n g m o d e l f or pa r a llel com putati o n  vol. 33, no. 8, pp. 103-111, 1990 12 a c h e  Ha ma    O n l i n e    http://hama.apache.org   13 Ap a c h e  Ha d o op    O n l i n e    http://hadoop.apache.org     M Z a h a r i a, M. Ch ow dhu ry M F r ank l in S  S h e n k e r, and I   Stoica, "Spark: Cluster Computing with Working Sets," in 2010   J  Ekana y ak e e t a l     T w i st er A  r untim e f o r it er ati v e  MapReduce," in Chicago, 2010, pp. 810-818   U. K a n g  C  T s o u rakakis   and C. F a l outs o s  Peg a s us   Minin g  Peta-scale Graphs," in 2010   M. P a c e  B S P vs  MapR e duc e    in vol. 103.2081, 2012   S. Seo  E  Yoo n, J  K i m  S  J i n  J-S. K i m   and S   Ma e n g HAMA: An Efficient matrix computation with the MapReduce framework," in 2010, pp. 721-726   S. S a l i h ogl u  and J  W i d o m  G PS A G r a ph P r oc e s s i n g Sy s t em    Stanford University, Technical Report 2011   R L i cht e n w a l t e r and N   Cha w la D is Ne t  A fr am ew ork for  distributed graph computation," in  2011   K  Maddu r i  D. E d i g er K   J i an g  D. Bad e r  and D  Cha v a r riaMiranda, "A faster parallel algorithm and efficient multithreaded implementations for evaluating betweenness centrality on massive datasets," in 2009   E  K r e p s k a, T  K i el m a nn, W  F o kkink, H   Ba l, "A  hi g h level framework for distributed processing of large-scale graphs," in 2011, pp. 155-166   L   Pa ge  S  B r in R. M o t w ani and T  W i nogr ad  T h e P a geRank citation ranking: Bringing order to the web," Stanford InfoLab Technical Report 1999-66, 1999   U  Brand  s  A f a s t er  a l gor ith m for  b e t w eenn e s s c e nt r a l i t y    vol. 25, no. 2, pp. 163-177 2001   Stan fo r d  Net w or k A na l y s is Pro j e c t  O n l in e    http://snap.stanford.edu    I  S t ant o n and G  K l i o t, "S t r e a m i n g G r aph P a rtiti o n in g  for L a rge Distributed Graphs," Microsoft Corp., Technical Report MSRTR-2011-121, 2011   G   K a ry pis and V   K um a r A fas t and hi g h qua l i t y m u l t i l evel scheme for partitioning irregular graphs," in 1995, pp. 113-122   M. A r m b r u s t e t  a l   A v i ew of  c l o u d  c o m putin g    vol. 53, no. 0001-0782, pp. 50-58 April 2010  
214 


  13  or gani c  c he m i s t r y  i n our  Sol ar  Sy s t e m       Xi a n g  L i r e c e i v e d h i s B  S   m is tr y  fr o m  th e  P e k in g  U n iv e r s ity  C h in a  in  2 0 0 3  and P h D   i n P hy s i c al  C he m i s t r y  f r om  t he  J ohns  H opk i ns  Un i v e r s i t y  i n  2 0 0 9   He  h a s  b e e n  a  R e s e a r c h  A s s o c i a t e  wi t h  a  j o i n t  a p p o i n t m e n t  a t  t h e  U n i v e r s i t y  o f  M a r y l a n d   Ba l t i m o r e  C o u n t y  a n d  N AS A G o d d a r d  S p a c e  Fl i  Ce n t e r  s i n c e  2 0 1 1   H i s  r e s e a r c h  f o c u s e s  o n  t h e  d e t e c t i o n  of  t r ac e  e l e m e nt  and as t r obi ol ogi c al l y  r e l e v ant  or gani c  mo l e c u l e s  i n  p l a n e t a r y  s y s t e ms   l i k e  M a r s   He  i s  es p eci a l l y i n t er es t ed  i n  t h e d evel o p m en t  o f  T i m e of  and I on T r ap m as s  s pe c t r om e t e r s w i t h v a r i o u s i o n i z a t i o n  ng te c h n iq u e s   Wi l l  B r i n c k e r h o f f  sp a c e  sc i e n t i st  i n  t h e  Pl a n e t a r y  En v i r o n m e n t s  La b  a t  N A S A  s  G o d d a r d  Spac e  F l i ght  C e nt e r  i n Gr e e n b e l t   M D w i t h  pr i m ar y  r e s pons i bi l i t y  f or  th e  d e v e lo p m e n t o f th e  L D TO F  m a s s  s p e c t r o  th is  p r o je c t H e  h a s  fo c u s e d  re c e n t l y  o n  t h e  d e v e l o p m e n t  o f  m i n i a t u re  l a se r d ma s s  s p e c t r o me t e r s  f o r  f u t u r e  p l a n e t a r y  mi s s i o n s  a l o n g  wi t h  b a s i c  e x p e r i m e n t a l  r e s e a r c h  i n  a s t r o b i o l o g y  a n d  p r e bi ot i c  s y nt he s i s   D r   B r i nc k e r hof f  i s  i nv ol v e d i n t he  de v e l opm e nt  of  m as s  s pe c t r om e t e r  f or  bot h t he  2011 Ma r s  S c i e n c e  L a b o r a t o r y  a n d  t h e  2 0 1 8  E x o Ma r s  mi s s i o n s   


  14   


Copyright © 2009 Boeing. All rights reserved  Issues and Observations Initial load of one day of data ~ 7 hours Optimizations  Write data in batches  Use a mutable data structure to create data strings  Deploy a higher performance machine  Use load instead of insert  Use DB2 Range-Partitioned tables  Database tunings Time reduced from 7 hours to approx 30 minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Use a mutable data structure to create data strings  Original application created the SQL statement by appending elements to a Java String  It was taking five hours \(of the seven hours Strings  Instead Java StringBuilder used  Java Strings immutable  Time savings of 71.4 


Copyright © 2009 Boeing. All rights reserved  Optimizations Deployed on a higher-performance machine  Application ported from IBM Blade Center HS21 \(4GB of RAM and 64-bit dual-core Xeon 5130 processor to Dell M4500 computer \(4GB of RAM and 64-bit of quad-core Intel Core i7 processor  Reduced the time to thirty minutes Bulk loading instead of insert  Application was modified to write CSV files for each table  Entire day worth of data bulk loaded  Reduced the time to fifteen minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Range-Partitioned tables \(RPT  To limit the size of tables, the original code created multiple tables per table type  This puts burden on the application to query multiple tables when a range crosses several tables  With RPT, user is not required to make multiple queries when a range crosses a table boundary  Increased the time to thirty minutes  Additional fifteen minute cost per day of partitioning enabled time savings during queries 


Copyright © 2009 Boeing. All rights reserved  Optimizations Database tunings  Range periods changed from a week to a month  Automatic table space resizing changed from 32MB to 512KB  Buffer pool size decreased  Decreased the time to twenty minutes Overall, total time savings of 95.2 


Copyright © 2009 Boeing. All rights reserved  20 IBM Confidential Analytics Landscape Degree of Complexity Competitive Advantage Standard Reporting Ad hoc reporting Query/drill down Alerts Simulation Forecasting Predictive modeling Optimization What exactly is the problem What will happen next if What if these trends continue What could happen What actions are needed How many, how often, where What happened Stochastic Optimization Based on: Competing on Analytics, Davenport and Harris, 2007 Descriptive Prescriptive Predictive How can we achieve the best outcome How can we achieve the best outcome including the effects of variability Used with permission of IBM 


Copyright © 2009 Boeing. All rights reserved Initial Analysis Activities Flights departing or arriving on a date Flights departing or arriving within a date and time range Flights between city pair A,B Flights between a list of city pairs Flights passing through a volume on a date. \(sector, center, etc boundary Flights passing through a volume within a date and time range Flights passing through an airspace volume in n-minute intervals All x-type aircraft departing or arriving on a date Flights departing or arriving on a date between city pair A,B Flights departing or arriving on a date between a list of city pairs Flights passing through a named fix, airway, center, or sector Filed Flight plans for any of the above Actual departure, arrival times and actual track reports for any of the above 


Copyright © 2009 Boeing. All rights reserved  Initial SPSS Applications Show all tracks by call sign 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case For a given Airspace Volume of Interest \(AVOI compute distinct traffic volume at some point in the future  Aim to alert on congestion due to flow control areas or weather if certain thresholds are exceeded  Prescribe solution \(if certain thresholds are exceeded Propose alternate flight paths  Use pre-built predictive model  SPSS Modeler performs data processing Counts relevant records in the database \(pattern discovery Computes traffic volume using statistical models on descriptive pattern Returns prediction with likelihood 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  24 Pulls in the TRACKINFO table of MAIN using SQL Limits the data to database entries which fall inside the AVOI Combines the SOURCE_DATE and SOURCE_TIME to a timestamp that can be understood by modeler Computes which time interval the database entry falls in. The time interval is 15 minutes Defines the target and input fields needed for creating the model Handles the creation of the model Produces a graph based off of the model results Final prediction 


Copyright © 2009 Boeing. All rights reserved  Initial Cognos BI Applications IBM Cognos Report Studio  Web application for creating reports  Can be tailored by date range, aircraft id, departure/arrival airport etc  Reports are available with links to visuals IBM Framework Manager  Used to create the data package  Meta-data modeling tool  Users can define data sources, and relationships among them Models can be exported to a package for use with Report Studio 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 1 of 3 Report shows the departure date, departure and arrival locations and hyperlinks to Google Map images DeparturePosition and ArrivalPosition are calculated data items formatted for use with Google Maps Map hyperlinks are also calculated based on the type of fix 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 2 of 3 DeparturePosition, Departure Map, ArrivalPosition and Arrival Map are calculated data items \(see departure items below DepartureLatitude DepartureLongitude DeparturePosition Departure Map 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 3 of 3 


Copyright © 2009 Boeing. All rights reserved  Conclusion and Next Steps Current archive is 50 billion records and growing  Approximately 34 million elements per day  1GB/day Sheer volume of raw surveillance data makes analytics process very difficult The raw data runs through a series of processes before it can be used for analytics Next Steps  Continue application of predictive and prescriptive analytics  Big data visualization 


Copyright © 2009 Boeing. All rights reserved  Questions and Comments Paul Comitz Boeing Research & Technology Chantilly, VA, 20151 office Paul.Comitz@boeing.com 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  31 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  32 Backup Slides 


Copyright © 2009 Boeing. All rights reserved  Initial Approach Initial Investigations  Apache Solr/Lucene  Data Warehouse Evaluate Hadoop in the future 


Copyright © 2009 Boeing. All rights reserved  Using SOLR Uncompress Track Information Messages To use with Solr  Transforming track messages from their  original schema to Solr required building a ìkey, valueî list using an XSTL  Queries made against this list of ìkey, valueî pairs Transformation Process  One day of data ~ 4.5 hours Once transformation complete search/query performance very good Geo spatial queries using  unique query language 


Copyright © 2009 Boeing. All rights reserved  Representation Aviation data is frequently represented in more than one form 



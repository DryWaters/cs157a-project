iSocialMash: Convergence of Social Ne tworks and Services Composition on a Mashup Framework Xuanzhe Liu*  Ning Jiang  Qi Zhao  Gang Huang Key Laboratory of High Confidence Software Technolog ies \(Peking University\Ministry of Education, PRC Beijing, China email: {liuxzh,jiangning09, zhaoqi06,huanggang }@sei.pku.edu.cn  Abstract Facilitated by advanced Web technologies, service mashups are currently popular for composing new valueadded applications. Mashup developers might often struggle to locate the relevant and appropriate services to satisfy their dynamic and personalized requirements   This paper proposes the concept of iSocialMash a framework that assists the rapid on-demand and intuitive composition of service mashups, by 
leveraging social networks. There two key observations guiding the development of iSocialMash On the one hand, social networks can capture both common interests and personal preferences of different users in the same or similar application contexts; they might use similar candidate services and glue them together in similar manner. On the other hand social networks can identify potential value-added composition of mashups; different users might have complementary collaboration opportunities for newly emergent goals iSocialMash exploits the successful experiences of social networks to provide users with useful composition recommendations \(such as missing or potentially proper services as well as connections between them\ Capturing such 
composition knowledge, the users are presented by a set of ranked recommendations from which they can choose for their personalized needs. In iSocialMash the data model leverages the social tagging to enrich the semantics and simplify the presentation and extraction of composition knowledge. We model the composition knowledge into some mashup patterns to accommodate different social networks interactions, and generate on-the-fly recommendations according to user personal requirements. We also experimentally evaluate the efficiency of our approach and present the current status of the prototype Keywords-services composition social networks, mashups I   I NTRODUCTION 
 With the wide adoption of Services Computing and recent innovations of Web 2.0, it promotes the newly emerging applications that are called service mashups 1 or mashups, over the World Wide Web. Generally speaking service mashups compose existing Web resources by utilizing a set of Web-delivered services, such as SOAP Web services, RESTful Web services and RSS/Atom feeds Mashups often aims at meeting situational requirements, and it encourages a light-weight and quick-rollout development lifecycle [2  T h e r ef o r e   it i s  a s i g n i f i can t is s u e t o m a k e  mashup development as simple as possible, particularly for those less/none professional programmers or even end-users     
corresponding to liuxzh@sei.pku.edu.cn  The key steps of mashup development remain the same as in traditional service composition: how to discover appropriate services with respect to user’s needs, and how to compose them correctly and quickly. In recent years, there has been a large body of research works for mashup development. Some promising solutions have been made, in terms of enabling end-user development process as well as providing easy-of-use tools 4  w e ve r  i n o u r opinion, these efforts might not fully accommodate the latest trend of Web. The Web is now undergoing a change towards the “user-centric” environment, where millions of users can participate and collaborate for their own interests and 
benefits. Particularly, social networks tremendously encourage the user’s proactivity and promote the popularity of Web applications. Both providers and end users \(including non-expert users\ can easily and freely share interests, advice and experience over the Web, which in turn improves the efficiency and quality of Web resource creation. We argue that, it brings us a new perspective for facilitating mashup development: social networks can serve as an additional ingredient to current mashup development. Two important observations can be found.  Firstly, social networks can capture some useful and reusable knowledge or experiences in the same or similar application contexts. Different users might use the same or similar candidate services and glue 
them together in the similar manner. For example, when making a travel plan, most of users might compose services such as Hotel, Airline, Restaurant and Maps Secondly, some potential composition might be found considering the complementary collaborations between users.  For example when a user shares a mashup including services PhotoPublish and Maps which can display the picture of a place \(such as a park\and locates the place on the map Another user \(who might be a friend\ight add the PostTwtitter service to this mashup, which provides valueadded information In this direction, we aim at weaving social elements and factors into service mashups development. In our previous 
work, we proposed the iMashup 6  n a nut she l l   iMashup provides mashup toolkit including component model, composition model and a browser-based composition runtime iMashup integrates the tag-based semantics for simple and flexible annotations of services  B a s e d o n  iMashup this paper proposes the iSocialMash framework Leveraging experiences from social networks iSocialMash  extracts the knowledge about services that have been successfully selected in existing mashups by other users \(i.e the information about the contexts in which certain 


combination of services were considered most appropriate and also attempts to retrieve potential composition opportunities \(i.e, the complementary collaboration information from users iSocialMash categorizes and represents the knowledge within some mashup patterns, and recommends the ranked relevant candidate services in the mashup development In this paper, we focus on the definition and modeling of iSocialMash framework. More specifically, we make the following contributions  We propose a novel mashup development perspective by converging services computing and social computing, and present meta-data model for representing composition information with social tagging  We specify the types of composition knowledge according to different social interaction context  We describe mechanisms to extract the composition knowledge into a set of mashup patterns  We present an empirical evaluation on the effectiveness and efficiency of the proposed framework, and briefly discuss the current status of the implementation The paper is organized as follows. Section 2 describes the concepts, principles and preliminaries of iSocialMash framework. Section defines the meta-data model of composition knowledge in mashup applications. Section 4 explains how to extract the knowledge into a set of mashup patterns. Section 5 evaluates the proposed framework with empirical experiments. Section 6 shows the current status of implementation. Section 7 ends the paper with concluding remarks II  C ONCEPTS   P RINCIPLES AND P RELIMINARIES  A  Concepts and Principles of iSocialMash  Mashups usually aim at the situational problems that require quick-rollout development process. Most of mashup developers are non-professional programmers or even endusers. They often benefit from mashups that are created by others. In this way, mashup developers are very typical prosumers One observed fact is that, there have been more than 5,000 mashups published and shared on the ProgrammalbeWeb, which is the most famous mashup portal As shown in Figure 1 iSocialMash can be viewed as a convergence of services computing and social computing research. The core principle of iSocialMash is to apply knowledge from social networks to improve mashup development. Two views are held in iSocialMash On the one hand iSocialMash emphasizes on harvesting more accurately labeled data \(e.g., social tagging\ and deriving metadata from both previous mashups and social interactions around mashups. Then composition knowledge will be consolidated into some mashup patterns \(e.g., data-mapping and co-occurrence of services/components\ and used to recommend candidate services or solutions to users. On the other hand iSocialMash also focuses on the social behavior and dynamics over the mashup development. We can perform the social networks analysis based on collaboratively annotated tags of mashups. For example consider the case that Lucy and Mike are friends with common interests such as travel. When another user, e.g Tony, adds a new service PostTwitter and some new tags over Lucy’s existing mashup, can we conclude that Tony might be a friend of Mike? If so, can we find some potential collaboration opportunities between them to develop a new value-added application   iSocialMash  In this paper, we mainly focus on the first view of iSocialMash which aims at social-empowered mashup development. The basic tasks are of two aspects: \(1 extracting and representing the useful composition knowledge by leveraging social networks; \(2\ applying knowledge to assist mashup development for a given partial application in a specific context B  Preliminaries Before introducing iSocialMash we present some background concepts used in the remainder of the paper namely mashup component model, mashup composition model, composition runtime and tag-links to make the paper self-contained In our previous work, we develop the iMashup toolkit which provides the concepts above as well as their implementations Mashup component model is a unified model that specifies common properties and behaviors of popular Web-delivered services, including SOAP/REST Web services, RSS/Atom feeds, at both application and presentation level Such a component model alleviates developers from tedious work on dealing with heterogeneity in ad-hoc manner. Particularly, mashup component model allows the tag-based annotations to describe the programmatic inputs and outputs. For example, the WeatherForecast component may be annotated by tags city, state as inputs and temperatureF, humidity, sunny, rainy, windy as outputs. Such tag-based annotations enrich the semantics and provide a simple manner to understand service capabilities. How to associate the tag-based semantics to mashup component model is defined in [7  


Mashup composition model specifies the composition logics for a set of mashup components With the tag-based semantics, when the tags one component produces, are semantically equivalent to those another components can consume, there might be a composition opportunity in terms of ‘‘tag-based data flow, which is called tag-link For example, the LocalSearch component can generate tags address postcode as outputs, which the WeatherForecast  component can consume as inputs. Here we assume that the composition semantics are determined by predefined tag-based ontologies \(which are usually named ‘‘folksonomies’’ in social networks III  M ETA D ATA M ODEL OF T HE F RAMEWORK  As mentioned above, mashup composition model only describes the services that are composed in a mashup application, as well as their relationships. However, for the same mashup applications, different users might have different preferences and application context \(i.e., for a travel mashup, the user’s timezone, geographical position, local currency, type of Web browser, may be relevant\.  We argue that, in the social networks environment, such information might be very helpful to assist mashup development We introduce the concept of mashup task a data structure which captures the information about the preferences and contexts of a mashup application that have been successfully used   To keep the consistency with iMashup toolkit, the meta-data is also annotated by tags in iSocialMash Formally, we can represent a mashup task in the tuple mashup_task, user, time, tags which means that the task is created by a user at some time \(since the user and time are very important information in social networks\, and can be described by a set of tags Mashup task can be consistently transformed into the mashup composition model  of iMashup or vise-versa\,  and  the composition logics are described in terms of tag-links  A  Composition Information of  Mashup Tasks The information of mashup task can be specified as follows. The service_seletected attribute presents the components or services that are selected to compose the mashup task. For example, the Milan_Travel_Plan _ John_July072011 mashup task consists of services Yahoo!  HotelSearch  Yelp FoodSearch Yahoo!LocalTraffic and GoogleMap For each service/component, we also express the inputs  outputs as a set of pairs <inputs/outputs t 1 t 2  where t i is a tag belonging to a predefined tag-based ontology T defined in 6   Suppose that there are two mashup tasks for the same goal \(travel plan in Milan city Milan_Travel_Plan _ John_July072011 and Milan_Travel_Plan _ Lucy_Aug022011 are created by John and Lucy respectively.  As John and Lucy might have their own preferences and contexts, they select very preferred services to compose the mashup tasks. The composition logics might be slightly different. For example, after finding the hotel and restaurant, John prefers to locating their driving direction by Yahoo! LocalTraffic and publishing his own travel experiences by WordPressBlog while Lucy prefer to visiting some spots \(e.g., the Church of Duomo  Yahoo LocalSearch and viewing the pictures by flickrPhotoSearch  However, some useful information should also be identified These two tasks have some shared services \(e.g Yelp FoodSearch and GoogleMap hich might reflect the common interests for they are often selected simultaneously Some services are mutually substitutable e.g., the Yahoo LocalSearch and HotelSearch as they provide equivalent functionalities B  Social  Information of  Mashup Tasks To help the search for the mashup task we propose the notion of context_annotations which identifies the context information of a mashup task The context might be the actual values of the specific inputs/outputs e.g Milan for the city name\; or an environmental context \(e.g., hardware and software characteristics of the user’s devices Context_annotations attribute is also specified in a pair of tags, <context t 1 t 2  With simple tag-based search other users can query personalized mashups that have been executed and shared by others in a certain context Social information is a specific type of contextual information. We enrich some social informational attributes around the mashup task The social_relaionthip attribute represents a group of users with whom a single user maintains some social relationships, for example, friend business colleague, family, competitor, common interest The reputation identifies the ranking level of a specific user whose shared mahsup task is published on iSocialMash For example, Mike is a friend and business colleague of John but Lucy holds closer relationship. We can simply conclude that Lucy’s mashup taks might take heavier weight when Mike plans a trip in Milan Considering the social_relationships above, \(partial mashup tasks can be assigned with some social interaction  policies by their owners. The social interaction policy can be represented as policy  with_user, goal, scope which means the policy is assigned to the designated users under a specific goal \(e.g., travel plan\ The scope attribute allows the task owners to identify the policy with partial some services or some fragments of the task\ or full the whole task\. The social interaction policies might include sharing  competition and collaboration   Sharing the sharing policy means that the mashup task can be shared with other users for the goal  Competition the competition policy means that the mashup task might compete against other users for the goal in case of selection. Most of time competition implies that the services or tasks might be functionally similar and substitutable with one another  Collaboration the collaboration policy means that the mashup task might collaborate with other users for an emergent goal For example, when Mike plans a trip to Milan, he might add the flickrPhotoSearch used by Lucy\or finding some 


pictures of the Duomo Church and submit the picture to WordPressBlog used by John IV  C OMPOSITION K NOWLEDGE R ETRIEVAL FOR M ASHUP P ATTERNS  We put forward to the concept of mashup patterns which are extracted from different perspectives.  Patterns are structured composition knowledge that can be reused Patterns can be delivered to the users as recommendations for completing given partial mashup applications A  Frequent Data Value Pattern The Frequent Data Value pattern is common and simple in most cases. IT indicates the most possible value of given inputs/outputs parameter of a service. For instance, the AirChina will always generate the flight information like airline company name” \(CA plus number and Yahoo LocalTraffic might often use the current location as the default origin.  In iSocialMash we find that the frequent data values of a service are very relevant to the users’ context. So we can easily investigate the context_annotations and generate such pattern using statistical approaches B  Co-occurence Pattern Co-occurrence pattern indicates the pairs of components or services. For instance, most of time Yelp FoodSearch  and GoogleMap are often selected in travel plan task. To retrieve the co-occurrence pattern, we firstly leverage the service mining techniques defined in previous work  t o  find association rules of services and mashup tasks. We similarly use such definition to annotating a service like  service, user, time, tags Here the tags might be from service_selected and context_annotations We then apply the association rules to find the co-occurrence of two services Let 12     m I tt t  be a set of tags. To reflect the cooccurrence, we then apply data mining approaches to discover tag association rules. The association rule of tags can be represented asm ij tt  where both i t and j I t   To achieve this goal, we apply the following steps. For each mashup task we generate all possible tag pairs i t  j t  where i t and j t are two tags annotating two different services used by the mashup task Assume that i t is annotated to one service and j t is annotated to the mashup task itself. We construct a base of all generated tag pairs Each pair is assigned a count, representing the number of mashup task where the pair is encountered. These counts are used to calculate support and confidence metrics for each pair. By repeating this process for each mashup task we have all extracted tag pairs. This enables us to calculate the support and confidence for each pair by tracking its repeatability. When we get all the tag pairs in such bottomup manner, we apply the hierarchical tag-based taxonomy T  derived in [6 to  d e term i n e th e se m a n tic co n cep ts o f ta g s   For example, tags such as maps  mapping  gmap  are clustered into the same concept. Finally, we generate association rules. Each association rule discovered between these concepts is an indication of how frequently users integrate the concepts into mashups  The co-occurrence pattern may have significant benefits when there are a large number of services and mashups to select. We can use the discovered patterns in recommending mashup candidates from a set of services, based on their tags For each two services in the set, we can generate a list of tag pairs from all semantically shared tags annotating the two services. With the knowledge of association rules, we can assign a co-occurrence score to the two services, based on the collective support and confidence values of their generated tag pairs. In this way, when a user chooses a service we can recommend a list of services to use in mashups, ranked by their co-occurrence score  C  Data Mapping Pattern The Data Mapping Pattern indicates the data dependency of two services. Such a pattern can match two services both syntactically and semantically. We mainly focus on the semantic level mapping. In our previous work 7  w e h a v e p r o pos e d a t a g bas e d s e rv i c e m odel  w h i c h  associates the service input/output parameters with a set of tags. The tag-based data mapping pattern is defined simply as the result of creating a sequence of tags, namely Tag Link   TL s follows TL Each service is represented as a tag-basd tuple  io kk TT  where i k T and o k T are tags representing the inputs and outputs of a service respectively. For  k the following two contraints should be promised  The above definition indicates the data mapping between services: subsequent services may use the outputs produced by preceding services as inputs. Such data dependencies are described in terms of tags. The first precondition ensures the semantic mapping and propagation between services, where  t t means that t is a sub-class of t i.e IBM  company  The second precondition ensures that no extra parameters are left The co-occurrence pattern only indicates the two services are usually selected together, but does not identify their relevance at composition level. However, the data mapping pattern can assist the users to find the services that can be composed given the current outputs. In   w e  ha ve  prop o s ed a graph-based,  forward-backward search algorithm. It allows the users to represent their desired outputs given their initial inputs, and retrieves all tag-links from a large number of services D  Substitution Pattern The substitution pattern indicates that two services are mutually substitutable, for example, the Yahoo LocalSearch and HotelSearch  in Section 3   Most of the time, the substitution pattern implies the two services are functionally equivalent. With this pattern, when one service fails, the other service can replace for continuously functioning.  In [6 e ha ve  p r opo sed a n app r oa c h t o  


determining whether two services are similar, by investigating their operation, inputs/outputs at semantic level V  E MPERICAL AND E XPERIMENTAL E VALUATIONS  In this section, we will evaluate the effect and efficiency of the mashup patterns. We select tags of Programmableweb as our data set. Progrmmableweb is a well-known mashup portal, which has hosted more than 5,200 mashup applications together with over 2,100 services or APIs until July, 2011. We have crawled 32,345 tags and filtered those redundant ones. Finally we had a data set of 18,051 different tags. Applying the annealing algorithm for tag clustering and the EM processing, we have attained 522 clusters such as hotel, geography, weather, search, map, etc A  Evaluation of Co-Occurrence Pattern Firstly, we evaluate the co-occurrence pattern. We generate the association rules of tag pairs and consider their semantic relationships. Figure 2 illustrates the co-occurrence frequency of all services crawled. Each vertex represents a service. The size of the vertex implies the service popularity For example, in our experiment study GoogleMap and Twitter are much bigger than others, which is consistent with the fact on Programmableweb. Once an edge exists between two services, it means these two services have cooccurred at least once. The distance between two vertices implies their co-occurrence frequency. In our experiment we find that GoogleMap is often coupled with Yahoo Search and flickr   Figure 2 Regular Co-Occurrence Pattern Although results in Figure 2 can help users find the most popular service as well as their most frequently co-occurring services, we argue that, there are yet some troubles when browsing such a large size of services. Therefore, we further consider the social informat ion around the mashups. We consider the users to control the distribution. We utilize 934 member profiles that have complete information on Programmablweb. We try to study the relationships of user services, and tags. Figure 3 shows the results. We can clearly see that the distribution converges that in Figure 2 More specifically, we find that, users with similar background \(for example, from the same area recorded in the profile\may have similar preferences or behaviors to choose services that co-occur. For example, when selecting GoogleMap as the initial service, 137 of 222 users from US choose flickr at the same time, while 29 of 52 users from Korea choose eCommerce such as Amazon Therefore, such the result is consistent with the fact that people, who have similar ideas in groups, are most likely to have similar behavior and tend to have the common favorite services and mashups  Figure 3 Co-Occurrence Pattern with Social Analysis  B  Evaluation of Data-Mapping Pattern To evaluate the data-mapping pattern, we conduct experiment by testing the outputs produced given a user inputs. We attach tag-based semantics to 200 services in the dataset. Then we set up a series of experiments to evaluate the concept coverage of tags. Tw enty users arbitrarily search their outputs on our system, and we check how many of their desired outputs or relevant interested ones are captured by the data-mapping pattern  Figure 4 Data-Mapping Pattern Evaluation Top-k in Figure 4 means the k ranked solutions including their desired outputs sorted by the descending order. We can clearly see that in the Top-5 curve, about 80% of all users have all their desired or relevant outputs in the Top-3 recommendations, and about 10% users have more than 90% desired or relevant outputs. The same observation holds for the Top-5 plot where 78% of the users can discover more than 90% of their desired or relevant outputs covered by the our data-mapping. Although only 68% of all users are satisfied with 75% results from Top-10 returned plans, we argue that the results are acceptable, for the users are more likely to prefer less than five options C  Evaluation of Substitution Pattern The efficiency of substitution pattern is determined by the function similarity of two services, in aspects of operation, inputs and outputs. We choose the keyword search and schema matching approach for comparison. Figure 5 illustrates the R-P curve of the three approaches. Obviously our approach beat the other two. In iSocialMash we try to attach the underlying semantic concepts to the input/output based on the derived tag-based taxonomy, and evaluate the 


concepts to improve the results. Schema-matching also has very low precision, for it only considers the XML structure and the distance between nodes in the tree, while lack of the underlying semantics. Keyword-based approach, is the lowest, for it only matches the keyword from the user’s requests, and the results are coarse  Figure 5 Substitution Pattern Evaluation VI  S YSTEM D ESIGN AND I MPLEMENTATIONS  The overall architecture of iSocialMash framework is presented in Figure 6. There are three components respectively named as iSocialMash Infrastructure  Service Advisor and iMashup toolkit As mentioned above iSocialMash  is built upon our previous work, the iMashup  Toolkit iMashup has provided a browser-based visual environments supporting mashup development. The users are allowed to drag-and-drop services on canvas, make some configurations and execute the application. The browser-based runtime can interpret the composition logics and display the on-the-fly results  Figure 6 System Architecture of iSocialMas  Currently we mainly focus on the issues of  iSocialMash Infrastructure including the repository of mashup tasks mashup patterns and social networks management  iSocialMash  Infrastructure provides interfaces for users to publish and share services and applications. The mashup tasks repository keeps track of all services and mashup tasks to facilitate the search of resources. The Tag-based Taxonomy is derived from the tags of mashup tasks and facilitates the generation of mashup patterns  Social networks management records the users registered on iSocialMash and their relationships. Currently, we assume that the initial relationships among social network agents are formed through invitations. The social networks management performs two main tasks: \(i\ building and maintaining the list of users with their mashup tasks metadata; \(ii\ forwarding the request by the Service Advisor  collecting the results and relaying them Service Adviso r facilitates the users to retrieve the composition recommendations for their desired goals. The User Agent captures the current contexts in given partial mashup and dynamically recommends candidate solutions based on mashup patterns by Composition Planner  Coordinating with the iMashup Toolkit  Service Advisor can result in the changes of user interface. Such process can be iteratively performed until the user finishes his desired mashup VII  C ONCLUSION R EMARKS  In this paper, we propose the iSocialMash framework by weaving social elements and factors into service mashups development. We propose a novel mashup development perspective by converging services computing and social computing, and present meta-data model for representing composition information with social tagging. We specify the types of composition knowledge according to different social interaction context, and describe mechanisms to extract the composition knowledge into a set of mashup patterns. Empirical and experimental evaluation shows the efficiency and effects of our approach A CKNOWLEDGEMENT  This work was supported by the National Basic Research Program \(973 of China under Grant No. 2009CB320703; the National Natural Science Foundation of China under Grant No. 60821003 and 61003010. The authors would like to appreciate Prof. M. Blake from Notre Dame University, for kind and valuable suggestions R EFERENCES  1  J. Yu, B. Benatallah, F. Casati, and F. Daniel, “Understanding mashup development,” IEEE Internet Computing, vol. 12, no. 5, pp 44–52, 2008 2  S.Balasubramaniam, G. Lewis, and S. Simanta, “Situated software concepts, motivation, technology, and the future,” IEEE Software, pp 50–55, November–December 2008 3  J. Wong and J. I. Hong, “Making mashups with marmite: Towards end-user programming for the web,” in Proceeding of ACM 2007 SIG Conference on Computer/Human Interaction \(CHI’07\, May 1624 2007, pp. 1435–1444 4  P. S. Rattapoom Tuchinda and C. A. Knoblock, “Building mashups by example,” in Proceedings of 2008 Intelligent User Interfaces IUI’08\, January 13-16 2008 5  E. Bouillet, M. Feblowitz, Z. Liu, A. Ranganathan, and A. Riabov A tag-based approach for the design and composition of information processing applications,” ACM SIGPLAN Notices, vol. 43, no. 10 pp. 585–602, September 2008 6  Xuanzhe Liu, Gang Huang, Hong Mei. Discovering homogeneous web services community in the user-centric web environment,” IEEE Transactions on Services Computing, vol. 2, no. 2, pp. 167–181 April-June 2009 7  Xuanzhe Liu, Qi Zhao, Gang Huang, Teng Teng, Hong Mei Composing data-driven services mashups with tag-based semantics 2011 International Conference on Web Services. July 4-9, 2011 Washington DC, USA  


represents this naming convention Id  0 IV Editor 0 96 000\000\000 Id  0 F igure 0 H  IV EditorF igure 95 000\000\000 Id  0 IV Editor 0 H  IV EditorF igure 95 000\000\000 Id  0 IV Editor 0  Id  0 F igure 0 The 002rst rule expresses that if a class contains the identi\002er IVEditor it most likely contains Figure as well The other rules express that classes in the hierarchy of IVEditorFigure should follow the naming convention Note that while these three rules have a high con\002dence there exists a single exception to these rules Further inspection of the rules revealed that one class IVEFigureRootCollection  did not obey the regularity and was therefore corrected to IVEditorFigureRootCollection  2 FreeCol Similar to the IntensiVE case study we identi\002ed a number of interesting naming conventions within FreeCol One example is the following group Id  0 Action 0  Im  getID  H  F reeColAction H  F reeColAction  Id  0 Action 0 H  F reeColAction  Im  actionP erf ormed  Id  0 Action 0 H  F reeColAction  Im  shouldBeEnabled  Id  0 Action 0 FreeCol implements a hierarchy of classes that represent user interface actions In addition to the fact that all of these actions belong to the hierarchy FreeColAction  they all share the naming convention that they contain the identi\002er Action in their class name Note that this group does not include a rule that concludes the hierarchy from the identi\002er as this is not the case in the source code For example there exist classes like ActionManager that  while they contains the proper identi\002er  do not implement a user interface action B Complementary methods The second kind of regularity that was identi\002ed by our approach are groups of methods that all contribute to the implementation of a particular concept These rules represent regularities of the form If a class implements a method named M then it should also implement a method named N 1 IntensiVE a Compilation One instance of this kind of regularity that we identi\002ed in IntensiVE was the saving mechanism Crosscutting the entire implementation of IntensiVE there are classes that represent objects that can be compiled To achieve this IntensiVE offers a small framework that is customized by each compilable object Our approach identi\002ed a fairly large group of 21 implication rules that demonstrate the use of this framework Some of the rules that were part of this group are Im  compileF ooterOn   Im  compileDef initionOn  Im  compileCachingOn   Im  save  Im  compileHeaderOn   Im  compileF ooterOn   Im  compileSpecif icsOn  Im  f ullname  Im  save  Im  generateSelector    This regularity describes the set of methods that need to be overridden by an object in order to be compilable If a developer overrides one of these methods then most likely all others should also be overridden b Undo The actions that can be performed within the user interface of IntensiVE are implemented by means of a Command design pattern A subset of these actions are undoable This is indicated in the source code by the fact that these actions implement the method isUndoable  However in such cases the undoable action should also implement the method undoAction that performs the actual undo Furthermore undoable actions are allowed to implement the optional redoAction method in order to perform a redo Our approach identi\002ed a group with two rules hinting at the above regularity Im  isU ndoable  Im  undoAction Im  redoAction  Im  name Im  undoAction 2 FreeCol Within FreeCol we identi\002ed a group that contains a single association rule In particular this group expressed that Im  readF romXM LImpl 96 000\000\000 Im  getXM LElementT agN ame A closer inspection of the source code identi\002ed that FreeCol offers serialization of game objects to XML 002les In order to properly work an object needs to implement both the readFromXMLImpl and getXMLElementTagName methods There were two exceptions to this rule which represent abstract classes that implement readFromXMLImpl  but that require their concrete subclasses to specify getXMLElementTagName  Note that this regularity could not be captured by a Java interface it does not suf\002ce for a class to inherit an implementation of getXMLElementTagName  each class that implements readFromXMLImpl should implement its own getXMLElementTagName method C Interface de\002nitions The third kind of regularity that we identi\002ed are interface de\002nitions These are represented by association rules of the form If a class belongs to hierarchy C then it should implement methods named M and N 1 IntensiVE IntensiVE is implemented in the dynamic language Smalltalk which does not offer the language construct of an interface As such some of the best-documented regularities in IntensiVE are interface de\002nitions Our approach was able to extract some of these interface de\002nitions automatically from the source code For example IntensiVE offers the concept of fuzzy quanti\002ers These are quanti\002ers such as almost all most and many Within the implementation of IntensiVE these fuzzy quanti\002ers have to implement a particular interface to indicate that they are a fuzzy quanti\002er and to calculate their truth degree One of the groups of association rules that was identi\002ed by our approach contained the following implication rule that expresses this interface de\002nition H  F uzzyQuantif ier  Im  crispQuantif ier  Im  holdsW ithT ruth  total  Im  f uzzyDegreeW ithT ruth  total  The above rule describes the exact intent of the regularity in IntensiVE namely that all classes in the hierarchy of FuzzyQuantifier should implement the correct interface 
28 


2 FreeCol The colonization game contains the concept of Locations  the various kinds of tiles in the game such as colonies settlements and so on Internally in the implementation this concept is represented by an interface de\002nition named Location that speci\002es that locations need to provide an implementation for methods getGoodsContainer and getLocationName  While this regularity is therefore explicitly veri\002ed by the Java language itself our approach was able to identify it in the source code More speci\002cally we found a group containing amongst others the following rules H  Location 80 000\000\000 Im  getGoodsContainer H  Location 80 000\000\000 Im  getLocationN ame Notice that this rule has a con\002dence of only 80 because there exist an abstract class in the implementation of FreeCol that delegates the implementation of the methods to its subclasses Our approach did not mine the opposite rule where the implementation of the methods concludes the interface because of the presence of sub-interfaces of Location that require additional methods to be implemented D Discussion 1 Grouping of rules One of the contributions of our approach is the fact that we propose to group rules of which the matches show a signi\002cant amount of overlap In both case studies this grouping of rules offered next to condensing the amount of information that needs to be processed by a developer the added bene\002t of allowing the evaluation of association and implication rules in a particular context Section V-B1a presents an example of this We discussed the regularity that in order to correctly compile an entity that entity's class needs to implement a set of methods This regularity was described by means of a large number of association rules If the association rules would have been inspected individually it would have been easy to miss that all of these rules actually belong together and describe the implementation of a particular concept In other words the groups aid in discovering the intent of a particular regularity by grouping all of its properties 2 Heterogenous versus homogenous groups Most of the identi\002ed groups were heterogenous meaning that the rules in these groups did not exclusively describe a naming convention an interface de\002nition or complementary methods This is not that surprising since our technique groups together rules based on their matches Consequently a group reported by our approach does often not align with a single regularity but rather consists of multiple regularities that are applicable to the same set of entities 3 Finding violations and improvements using the mined rules One of the strengths of association rule mining  which motivated our choice for this technique  is its resilience to deviations in the data set In other words in order for a regularity to be discovered by our approach it is not necessary that this regularity is strictly obeyed throughout the entire source code During our analysis we found that most of these imperfect regularities were caused by the fact that the regularity itself is not always applicable i.e there exist exceptions to the general rule we were also able to identify a number of violations of the regularities For example as we discuss in section V-A1b our approach amongst others identi\002ed a violation of one of the naming conventions within IntensiVE While not discussed above in the FreeCol case study we identi\002ed a refactoring opportunity in the graphical interface where a dedicated subclass of JPanel was used For no apparent reason some classes in the interface did not use this dedicated class but extended the JPanel class directly 4 Choice of properties and in\003uence on mined regularities Since it was our goal to demonstrate the feasibility of our approach for now we restricted our analysis to classes and opted to only include three simple properties of classes As a consequence the different kinds of regularities that can be discovered based on these properties is rather limited We can observe that most of the reported rules describe the vocabulary that is used in the application While this provides interesting information regarding the application for example to novice developers a wide range of regularities are currently not mined by our approach For example calling relationships usage of particular classes framework specialization constraints and so on are not found We plan further experimentation where we will not restrict our analysis to classes but also include methods Furthermore we will investigate the use of properties such as calling relationships method overrides typing information and statement ordering 5 Amount of manual effort Possible scalability issues of our approach are not caused by the complexity of computing the actual association rules but rather by the manual analysis of the resulting groups While our approach aims at minimizing the amount of effort that needs to be invested by a developer by extensive 002ltering and grouping of rules it still requires a considerable effort to extract the rationale behind the grouping In order to identify the intent of a group a developer needs to inspect the various rules in that group along with the source code entities that match the rule and the exceptions to this rule Especially in the case of an unfamiliar system this can be time consuming Although such a manual analysis has to be performed only once for a particular system we plan to further circumvent this problem in future work by allowing the mining and analysis to be done in a more incremental way during the development process We envision a tool that extends a standard IDE in such a way that when browsing a particular source code entity the developer is also shown the groups and association rules in which this source code entity is involved either as a match to a rule or as a deviation This way a manual post-processing step of the results of our approach is no longer necessary but the analysis can be done incrementally during development 6 Correctness of the results From a technical point of view all rules mined by our approach are correct with respect to the system that is analyzed Nevertheless without the 002ltering that is offered by our approach the use of association rule mining can still result in a large number of trivial 
29 


rules Since we restrict our rules to those that are supported by a suf\002cient number of matches and that exhibit a high con\002dence and low degree of error we are able to prune a signi\002cant number of these trivial rules This however does not provide any insights into the quality of the mined results from a usability perspective are the groups of rules identi\002ed by our tool of interest to developers While we were able to identify interesting regularities in both case studies such an analysis of the usefulness of our approach is highly subjective In future work we will validate our approach by mining for regularities in a number of open-source systems and involve the original developers of these systems in a user study 7 Comparison with known regularities in IntensiVE For the IntensiVE tool a fairly large number of regularities were already documented While our approach was not able to 002nd all of these regularities due to restricted scope of our experiment we were able to identify a majority 10 out of 15 of the documented naming conventions complementary methods and interface de\002nitions For example the compilation scheme the undoable actions and the quanti\002er naming convention discussed above were all documented already using the IntensiVE tool Furthermore eight interesting regularities such as the fuzzy quanti\002er interface and part of the user interface protocol were identi\002ed by our approach but were not previously documented Our approach however failed to identify the naming conventions and interface de\002nitions related to the implementation of a Factory design pattern within IntensiVE The reason for this is the fact that due to the small number of classes that have to respect these regularities association rules that involved the classes implementing the factory were removed from the result by our pruning 002lters 8 Choice of thresholds Our approach can result in false negatives as consequence of the aggressive 002ltering scheme where we expect at least 4 matches for the rule a con\002dence of 70 and a degree of error lower than 45 While this 002ltering strategy allows us to limit the amount of noise it can result as illustrated in the previous point that certain interesting regularities are 002ltered out First our choice for expecting at least 4 matches for a rule was inspired by the observation that a lower threshold would include casual correlations of properties therefore increasing the amount of noise produced by our approach Second we experimented with different con\002dence and degree of error thresholds Both these thresholds have an impact on the number of entities that get reported by our tool and were determined after experimentation For example using a con\002dence threshold of 50 on the IntensiVE case study only resulted in 40 more association rules and 2 extra groups However we observed that this lower threshold resulted in the introduction of random association rules in the groups that were caused by seemingly unrelated properties Although the con\002dence of these rules was higher than the threshold both condition and conclusion exhibited a large number of exceptions Similar observations can be made for the degree of error While a lower degree would result in less groups/rules and a number of interesting regularities would be eliminated too high a degree of error would allow for rules that are too generic coincidental While experiments resulted in the same thresholds for both case studies this does not imply that these thresholds are optimal for the analysis of any system We hypothesize that since the size of both systems is similar the same thresholds yielded satisfying results in spite of the fact that the systems were written in different languages VI R ELATED WORK A Approaches using association rule mining Our work is not the 002rst one to propose the use of association rule mining for extracting knowledge from source code For example Michail uses association rules to mine library reuse patterns library components that are reused together Similar to our approach this work analyzes classes and basic relationships between these classes Furthermore this approach also proposes some heuristics to 002lter rules that are not adding information Thummalapental and Xie mine association rules obtained from exception handling code The association rules that are obtained by their approach are composed of sequences of method calls that occur together Bruch et al propose the use of frequent itemset analysis and association rule analysis to remove irrelevant recommendations in code completion PR-Miner by Li and Zhou use association rules to identify violations to correlations between function calls Similar to our approach they offer a grouping mechanism theirs is based on the antecedent of the rules The above approaches are similar to our approach in that they use the same mining technique and similar input data However the nature of the problem tackled differs While previous approaches aim at 002nding accurate examples or detecting exceptions we aim at presenting the mined association rules in a condensed format to ease the interpretation of the rationale behind these rules Therefore the 002ltering and grouping strategies we propose differ from previous ones B Mining for structural regularities There are several approaches specialized in mining certain types of source code regularities For instance aspect mining techniques look for frequent scattering patterns ho wever these approaches tend to be dif\002cult to interpret and intolerant to exceptions Another set of approaches has been proposed to detect features i.e the implementation of user-perceivable functionality However feature detection is generally based on data that is dif\002cult to extract such as vectors of words that characterize source code entities and data and control 003ow relations 20 Other feature identi\002cation techniques rely on traces 7 22 which require intense 002ltering to separate the calls to auxiliary methods from those that indeed implement the feature Furthermore there are several approaches to mine for API usages 23 24 25 ho we v er  the results tend to be very low-level implementation rules which are dif\002cult to interpret as domain/application speci\002c rules Finally there are approaches that aim at extracting domain/application design rules such as ne v ertheless the scalability of this approach 
30 


is limited To summarize in comparison to our approach previous regularity mining approaches tend to be specialized for a single type of regularity while our approach would 002nd as many and diverse regularities as properties analyzed In contrast to the approaches presented ours is a lightweight approach which is resilient to exceptions and provides hints to interpret the rationale of the results VII C ONCLUSIONS Structural source code regularities such as idioms naming conventions interface de\002nitions play an important role in easing software maintenance and evolution Unfortunately such regularities are often only implicitly known and not documented Furthermore automatic extraction of such structural regularities from source code is not a trivial task due to the overwhelming amount of information that mining techniques might present a user and the inherent presence of exceptions to the structural regularities in the source code In this paper we have presented a novel approach for mining such regularities that is based on association rule mining The contributions of our approach are 1  Resilience to exceptions in the source code due to the nature of the applied association rule mining technique 2  A comprehensible representation of the mined rules due to an elaborate post-\002ltering and grouping of rules 3  An intentional description of the mined regularities due to the fact that we mine for relations between properties of source code entities and not between the actual entities As a proof-of-concept of the feasibility of our approach we have applied it to two open-source systems one in Smalltalk and one in Java Despite the fact that we only considered three simple properties of the analyzed classes identi\002ers implemented methods inheritance relationships our qualitative analysis of the resulting groups of association rules indicated that our approach is able to discover interesting structural source code regularities Currently we are extending the experiment to methods and relations between those methods A CKNOWLEDGEMENTS This work has been performed under the scope of the MinDeR bilateral project sponsored by MINCyT Argentina and FWO Flanders Angela Lozano is funded by the ICT Impulse Programme of the Institute for the encouragement of Scienti\002c Research and Innovation of Brussels ISRIB Andy Kellens is funded by a research mandate provided by the Institute for the Promotion of Innovation through Science and Technology in Flanders IWT Vlaanderen This work has also been supported by the Interuniversity Attraction Poles IAP Programme of the Belgian State  Belgian Science Policy R EFERENCES   K Bennett and V Rajlich Software maintenance and evolution a roadmap in The Future of Software Engineering  2000 pp 73–87   T Matsumura A Monden and K Matsumoto The detection of faulty code violating implicit coding rules in Workshop on Principles of Software Evolution  2002   K Gallagher and J Lyle Using program slicing in software maintenance IEEE Trans Softw Eng  vol 17 no 8 pp 751–761 1991   K Chen and V Rajlich Case study of feature location using dependence graph in Intl Workshop on Program Comprehension  2000 pp 241–247   M Robillard and G Murphy Concern graphs 002nding and describing concerns using structural program dependencies in Intl Conf on Software Engineering  ACM 2002 pp 406–416   K Mens I Michiels and R Wuyts Supporting software development through declaratively codi\002ed programming patterns Elsevier Journal on Expert Systems with Applications  vol 23 no 4 pp 405–431 2002   T Eisenbarth R Koschke and D Simon Locating features in source code IEEE Trans Softw Eng  vol 29 no 3 pp 210–224 2003   R Agrawal T Imielinski and A Swami Mining association rules between sets of items in large databases in Intl Conf on Management of Data  ACM SIGMOD 1993 pp 207–216   J Han and M Kamber Data Mining Concepts and Techniques  Morgan Kaufmann 2000   B Ganter and R Wille Formal Concept Analysis Mathematical Foundations  Springer Verlag 1999   E Gamma R Helm R Johnson and J Vlissides Design Patterns Elements of Reusable Object-Oriented Software  1995   J Maletic and A Marcus Supporting program comprehension using semantic and structural information in Intl Conf on Software Engineering  IEEE/ACM 2001 pp 103–112   A Michail Data mining library reuse patterns using generalized association rules in Intl Conf on Software Engineering  ACM 2000 pp 167–176   S Thummalapenta and T Xie Mining exception-handling rules as sequence association rules in ICSE 09 Proc of the 2009 IEEE 31st International Conference on Software Engineering  Washington DC USA IEEE Computer Society 2009 pp 496–506   M Bruch M Monperrus and M Mezini Learning from examples to improve code completion systems in European Software Engineering Conf and the symposium on the Foundations of Software Engineering  ACM 2009 pp 213–222   Z Li and Y Zhou Pr-miner automatically extracting implicit programming rules and detecting violations in large software code in European software engineering conference/International symposium on Foundations of software engineering  ACM 2005 pp 306–315   A Kellens K Mens and P Tonella A survey of automated code-level aspect mining techniques Transactions on Aspect-oriented Development TAOSD  2007   K Mens A Kellens and J Krinke Pitfalls in aspect mining in Working Conf on Reverse Engineering  IEEE 2008 pp 113–122   A Marcus and J Maletic Recovering documentation-to-source-code traceability links using latent semantic indexing in Intl Conf on Software Engineering  2003 pp 125–135   B Dagenais S Breu F Warr and M Robillard Inferring structural patterns for concern traceability in evolving software in Automated Software Engineering ASE  ACM 2007 pp 254–263   N Wilde M Buckellew H Page and V Rajlich A case study of feature location in unstructured legacy FORTRAN code in European Conf on Software Maintenance and Reengineering  2001 pp 68–76   G Antoniol and Y Gu  eh  eneuc Feature identi\002cation A novel approach and a case study in Intl Conf on Software Maintenance  2005 pp 357–366   C Williams and J Hollingsworth Automatic mining of source code repositories to improve bug funding techniques Transactions on Software Engineering  vol 31 no 6 pp 466–480 2005   T Xie and J Pei MAPO Mining API usages from open source repositories in Mining Software Repositories  ACM 2006 pp 54–57   H Kagdi M Collard and J Maletic An approach to mining call-usage patterns with syntactic context in Intl Conf on Automated Software Engineering  2007 pp 457–460   P Lam and M Rinard A type system and analysis for the automatic extraction and enforcement of design information in European Conference on Object-Oriented Programming  Springer 2003 pp 275–302 
31 


14] Ji exunLi, GuoqingC hen. "ASAR-based interesting rule mining algorithm" [J].Fuzzy Information Processing Society, 2002 Proceedings.N AFIPS.2002 Annual Meeting of the North American 2002,pp. 178-183 12L IS] J. Han, J. Pei, and Y. Yin, "Mining Frequent Patterns without Candidate Generation," Proc. ACM-SIGMOD Int'l Coni Management of Data, pp. 1-12, May 2000 16] Vaarandi Risto ,"A Breadth-First Algorithm for Mining Frequent Patterns from Event Logs ",Department of Computer Engineering Tallinn University of Technology 


Why Data Mining  N ecessit y is the mother o f inventio n yf Huge Datasets Tera to Peta bytes multi dimensional distributed interrelated semi structured and rapidly growing Requirements Exploratory analysis mining hidden novel patterns knowledge driven analysis Associative IDS for NextGen Frameworks Dr S Dua LA Tech 12 


KDD Process Classification Classification Classifying or predicting Clustering Clustering Finding new classes Feature Selection  Extraction Feature Selection  Extraction Finding the features most strongly Classifying or predicting outcomes based on patterns/behavior in data Finding new classes or refining existing ones Finding the features most strongly related to a particular class Preprocessing Selection Initial Data Target Interpretation Data Transfor Data Mining Pre Processed Transformed Data Model Preprocessing Selection Initial Data Data Interpretation Transfor mation Data Mining Data Data Model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 13 


Dimensionality Reduction Challenges Dimensionality Reduction Challenges Noise Sall la ge oble S ma ll n l ar g e p pro bl em Multidimensional Mapping Estimating Information Loss Gain Ubl d Dt t Dimensionality Reduction F eatu r e Ex t r act i o n U n b a l ance d D a t ase t s Validation through Post Data Mining Cl t i F idi bi l i l l fi i Feature Extraction Feature Selection Cl us t er i ng F i n di ng new bi o l og i ca l c l asses or re fi n i ng existing ones Classification Classifying diseases or predicting outcomes based on gene expression patterns Associative IDS for NextGen Frameworks Dr S Dua LA Tech 14 


Aiti l i dt ii A ssoc i a ti on ru l e i n d a t a m i n i ng Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 15 


Introduction to Association Mining Introduction to Association Mining Association rule mining is a data mining application to extract patterns Reveals interesting relationships called associations in a potentially large database Example Supermarket checkout information about customer purchases used to measure customer purchasing behavior customer purchasing behavior  Evaluation of this information can help retailers devise more efficient and personalized marketing strategies Association Rule Example Milk Beer  Diapers Find all the rules X Y with minimum support and confidence Support  s probability that a transaction contains X and Y Confidence  c conditional probability that a transaction Associative IDS for NextGen Frameworks Dr S Dua LA Tech 16 Image Source budlight.com pampers.com 


Associations as Higher Order Associations as Higher Order Features Hypothesis Associative relationships among features have more discriminatory power than individual/raw features Goal Use these associative relationships for supervised learning classification  Specific Aims Represent associative relationships as features  higher order features Challenges Challenges Not as straightforward as regular classification Rules to higher order feature transformation Rules to higher order feature transformation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 17 


Higher Order Classification Higher Order Classification Extracting Association Rules Each instance represented as idiid ld b Build a new feature space from these rules i n di v id ua l d ata b ase rules Use these higher order features for classification with existing classifier Raw Features Query Instance Query Instance Class Label Features Classifier Extract Rules Rule R epresentation New Feature Space Classifier R epresentation Rules to Higher order Feature Representation Schema Associative IDS for NextGen Frameworks Dr S Dua LA Tech 18 


Aiti T A ssoc i a ti on T ypes Basic Association Rules Enhanced Inter Transaction Association Rules Complex Spatio Temporal Association Rules 19 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 19 


Basi Association Rles Basi c  Association R u les Association is basically connecting or tying up occurrences of Association is basically connecting or tying up occurrences of events Ol dib t f ilt t O n l y d escr ib e se t s o f s i mu lt aneous even t s Cannot describe patterns that iterate over time e g  itemset a  0  b  0  g    Eg If you sense higher data rates on the downlink than normal AND New Route generated Implies high chances of Intrusion AND New Route generated Implies high chances of Intrusion Associative IDS for NextGen Frameworks Dr S Dua LA Tech 20 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



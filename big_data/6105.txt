Abstract Many çbig dataé software syste ms are not interactive automated, or run in a real-time mode. The true utility of cloud computing and çbig data systemsé can be increased by providing an execution framework and control software that is native to cloud architectures and supports interactivity and time synchronization. In addition, a framework to integrate different artificial intelligence and machine learning algorithms is combined with the execution framework to create a powerful cloud computing system development platform 
Batch oriented Brittle 
Intelligent System Development and Integration for Cloud Computing 
  
 Jeffrey Wallace, Ph.D. and Sara Kambouris, Ph.D Infinite Dimensions 700 N. Fairfax Street Suite 220 Alexandria, VA 22314 jeff@id-inc.us, sara@id-inc.us  KeywordsÑcloud computing; complex system representation; integration conceptual graphs synchronization I  I NTRODUCTION  Current cloud compu ting application dev elopment and systems integration suffer from the following problems 
 
the systems are not made to run interactively, or continuously easily fail with slight perturbations to the 
  
Difficult to maintain Complicated to scale Cannot provide clear, concise implementations 
information transacted 
        
as systems are upgraded when additional information and constituent systems, are required among diverse sub-system sets The problems are unlikely to be solved without improvement in the underlying development environment and infrastructure A cloud application develop ment and integration framework  d dress the challenge s CONDORês biologically inspired characteristics have the ability to Create complex, realistic, and scalable networks of component inter-relationships Distribute autonomous co ntrols and monitors Implement complex webs of cause and effect Dynamically alter the execution structure Adapt and evolve the system In addition, CONDOR addresses the ch allenges by fusing 
        
 
    
Advanced systems theory and practice Advanced software development Low-latency, high throug hput, reliable, and robust computer communications Sophisticated software in tegration, interoperability, and synchronization Common approaches to complex system infrastructure, such as systems based on Microsoftês .NET fram based programming \(e.g., systems utilizing threads, semaphores and locks 7][8 object request broke rs 9][10][11], ERP infrastructure  1 3 14 and c l uttered we bbas e d   in one or more of the problem areas listed above. The tremendous number of constructs causes significant setbacks with most application development and integration methods. CONDOR \(with a m acro-based sub-language represents and constructs these complex system capabilities II  A RCHITECTURE D ESCRIPTION  CONDOR is an object-ori ented, event-based, high performance execution system CONDOR provi des high speed communications, which is central to its framework 
    
and utilizes numerous messag ing fabrics for inter-processor communication: shared memory wireless, fiber optic, ATM TCP, IP, and multicast \(implemented in a variety of media 
Component Repository Composability Automation CASE Tool Environment 
User Defined System Interface User Defined Hardware Interface Web Services API JNI, SOAP, OWL, etc 
Shared Memory Reliable Multicast 
TCP/IP Reflective Memory Security State Saving Core Programming Distributed Object Mgmt Std App Dev Interface Synchronization Management Event Management Services Knowledge 
Representation Integration Meta-Data Data Translation Figure 1. CONDOR architecture layering 
Communication Services Common Application Services Intelligent Application Services System Execution Services 
 
2014 International Conference on Computational Science and Computational Intelligence 978-1-4799-3010-4/14 $31.00 © 2014 IEEE DOI 10.1109/CSCI.2014.95 541 
2014 International Conference on Computational Science and Computational Intelligence 978-1-4799-3010-4/14 $31.00 © 2014 IEEE DOI 10.1109/CSCI.2014.95 57 
2014 International Conference on Computational Science and Computational Intelligence 978-1-4799-3010-4/14 $31.00 © 2014 IEEE DOI 10.1109/CSCI.2014.95 57 
2014 International Conference on Computational Science and Computational Intelligence 978-1-4799-3010-4/14 $31.00 © 2014 IEEE DOI 10.1109/CSCI.2014.95 57 


          
       
 
CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU User Application Interface Services Hardware Device Interface Services 3D Visualization Interface Services WAN Interface Services Communication Speed Slow Medium Fast CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU CPU User Application Interface Services Hardware Device Interface Services 3D Visualization Interface Services WAN Interface Services Communication Speed Slow Medium Fast 
          
The provide a variety of mechanisms linking clients to intelligent application services, or the hosting processors internal and external\s standardized for simplified integ  abstraction is then supported for unicast and multicast, and permits various implem entations, and thus protocols, to work simultaneously and  support reliability, synchro nization, fau lt-tolerance, and implementation of persistence services. The provides Standard Template Library STL\and utilizes the state-saving and persistence features EMS\ provide highperformance data structures to develop exceedingly complex reliable, interactive in telligent applications mo re rapidly closely coupled with EMS, control synchronization and timing, which are essential for real-time intellige nt applications interfacing with hardware [2  expedites development of complex, robust intelligent applications by code generation macros and APIs. SAIS synchronizes components as the overall system executes, and scales to simultaneously execute large numbers of components an interactive synchronization mechanism hides programming complexity and provide location transparency and a powerful, yet easy to use, di stributed object computing framework \(e.g., the complex ity in using different interprocessor communications The provides A syntactic notation for relational associations Logical constraints, consequences, and role-based behaviors entailed by the relationships A system of primi tive relational abstractions Method to change abstractions into conceptual hierarchies Means to compose and structure relationships into frameworks and architectures CONDOR utilizes additional state of the art technologies in its architecture and employ the lower layers fo r location transparency, and are based on  3 CONDOR integrates hardware and software systems by extending CG technolog y in three dimensions Embeds in hardware or software programs Links software and hardware components Accommodates new hardware, or software components, without returning to original developers for new versions of graph systems Each node maintains a t ruth value \(belief network theory\4 to m a naged gra ph execution  Collectively, the extensions embodied in CONDOR signify precision in the art. All services adhere to the and easily integrate intelligent applications and WAN \(Figure 2  III  I NTELLIGENT S YSTEM D EVELOPMENT AND I NTEGRATION  The overhead costs of information flow between software and hardware continue to increase. Systems integrators attempt to reduce the costs by repeating the information flow, hopeful to attain greater accuracy and to meet the timeframe of need. The attempts do not solve challenges indicative of increased complex systems, and have been successful due to the following Hardware compatibility Communication protocols Understanding tran sfer information Well defined system interrelationships Mapping for adequate neut ral-format standards 
Communications Services Communications Services API State-Saving Framework State-Saving Services Core Programming Services Event Management Services Synchronization Management Services Standard Application and Integration API \(SAIA Distributed Object Management Services Data Translation Services Metadata Infrastructure \(MDI  Knowledge Execution Engine \(KEE Knowledge Representation Integration Infrastructure KRII CGs Figure 2. Sample CONDOR System Layout External Integration Framework 
conceptual graphs not lack of 
1 Contr  ols, executes, and integrates the entire system a  b  2 Customizes concepts, relation ships, and actors a  3 Controls execution of the KEE a  
542 
58 
58 
58 


Mutual acceptance of the communication purpose Operational meaning in terminology Advancement in the core development environment and infrastructure CONDOR software systems. Visually, a CG mimics knowledge representation in common di agrams for discussions \(using whiteboards, slides, or even table napkins\s, or drawings, are often text snippet s \(typically enclosed in squares or ovals\nd lines \(such as labels\onnecting one snippet to another. Experts often use visual aids to quickly communicate complex details during brai nstorming sessions \(see Figure 3 Concepts Concepts Actors Actors Relationships Relationships CAT STAT LOC SIT MAT CAT STAT LOC SIT MAT MAT A Cat sits on a mat A Cat sits on a mat Une Chat assis sur une matte Une Chat assis sur une matte  In CGs, text snippets \(in a square\re called The line connections are enhanced with ovals called  containing additional text. Hence representation of semantic relations, between various concepts, occurs in a manner consistent with common brainstorming pictures  diamond shaped symbols\ method to encapsulate interfaces to hardware or software components, and indicate data or signal transforming activity is occurring Structurally, a CG provides the following advantages for representing and integrating complex systems Inherently hierarchical; pe rmits operation at increased aggregated levels, when beneficial Can decompose components to appropriate levels of detail, to meet requirements Ability to concept ualize the entire system or one specific concept Capable of capturing any aspect of the system Using CGês, CONDOR simplifies hardware and software component integration; and simu ltaneously, concisely represents the entire system control logic Developers typically manage func tional blocks with various data sending and receiving protocols. However, most developers lack standard approaches across th e enterprises \(u sually one method works as well as the next\onsequently, accurate prediction of time and cost is difficult. CONDOR provides an organized template for encapsul ating functional blocks hardware or software\h is easily mastered by integrator engineering staffs, thereby solv ing the pred iction challenge CG Relationships have simple rules - one concept node must be connected by an incoming arc to a relationship; and one concept node must be connected by an outgoing arc Relationship nodes provide critical semantic structure to system descriptions, and frequently represent modifiers, qualifiers, and constraints Concept nodes may be connect ed to relationship nodes or actor nodes, but direct connections bet ween concept nodes is not permitted. A concept node may have any number of incoming arcs or outgoing arcs, and represent a variety of system features Concepts may be components \(or ob jects\may represent actions \(or verbs\modifiers \(adjectives and adverbs Actor nodes can have any number of incoming arcs from other nodes. However, they have only one outgoing arc. The outgoing arc may be connected to another actor node, or a concept node. Actor nodes provide the critical ability to encapsulate hardware or software components. Hence, actor nodes enable system integration IV  C ONCEPTUAL G RAPHS AND THE K NOWLEDGE E XECUTION E NGINE  One of the purposes of the Knowledge Execution Engine KEE\ves controlling the execution of a collection of hardware and software components, as a cohesive and robust system. Relationships have the si mplest rules - one concept node must be connected by an incoming arc to a relationship; and one concept node must be connected by an outgoing arc Relationship nodes provide critical semantic structure to system descriptions. They frequen tly represent modifiers, qualifiers, and constraints 
 
Concept 1 Relationship 1 Relationship 1 Concept 2 Concepts or Other Actors Actor 1 Actors or Relationships Actors or Relationships Concept 1 Concept Concept or other Actors Concept 1 Relationship 1 Actor 1 INVALID 
Figure 3. Basic CG example  Figure 4.  Conceptual Graph creation rules 
       
       
Concepts Relationships Actors 
543 
59 
59 
59 


Figure 5. Sample CG implementing a simple formula Execution Cycle set reset executed The truth value is manipulated during the execution of the software or hardware function true then activation signal sent to each node outgoing arcs 
 
                      
The basic rules governing CG formation are shown in Figure 4.  Relationships have the simplest rules - one concept node must be connected by an incoming arc to a relationship; and one concept node must be connected by an outgoing arc Relationship nodes provide critical semantic structure to system descriptions.  They frequently represent modifiers, qualifiers and constraints Concept nodes may be connect ed to relationship nodes or actor nodes, but direct connections bet ween concept nodes is not permitted. A concept node may have any number of incoming arcs. Concept nodes may also have any number of outgoing arcs A valid CG for system integra tion must contain at least one input concept node and one output concept node. Concept nodes represent a variety of system features. Concepts may be components \(or objects\may represent actions \(or verbs\ps act as modi fiers \(adjectives and adverbs Concepts and relationships alone enable a wide range of expression through use of CGs  Actor nodes can have any number of incoming arcs from other nodes. However, they have only one outgoing arc. The outgoing arc may be connected to another actor node, or a concept node. Actor nodes provide the critical ability to encapsulate hardware or software components. Hence, actor nodes enable system integration The ability to store and exchange data is central to userdefined actor, relationship, and concept nodes. Data storage and exchange is attained via transm ittance of inputs to actors Transmission follows the direction of arrows in the CGs \(shown in Figure 5 The KEE employs a data structure, or collection of data structures, that represents a CG \(as a software or hardware component\ The CG representation minimally includes 1 A collection of user-defined nodes 2 A collection of user-defined nodes 3 A collection of user-defined nodes 4 A unique ID numbering scheme to identify every node regardless of type 5 A description of the connected nodes, and route of the connection 6 A list of references to input concept nodes \(those with no incoming arcs a A valid CG must contain at least one input concept node 7 A list of references to the output concept nodes \(those with no outgoing arcs a A valid CG must contain at least one output concept node 8 A data structure that records the truth value of each node \(those skilled in the art recognize this may be included in the node data structure The KEE reads standard CGIF files and parses it. The KEE includes the CG parser, as it accomplishes much more than standard CG parsers. The KEEês CG parser must establish all connections between nodes \(specified in the CG\he type information and unique ID tag permit the correct execution order of components The following sequence describes the typical use of the KEE 1 The system is started 2 Each component in the system is initialized 3 Synchronization relati onships are established 4 Inputs are read and loaded into system components 5 The CG associated with the system is initialized and parsed 6 Each system component is associated with a CG element using the unique ID tag \(concept, relationship actor 7 Each component is registered in the correct collection mechanism for each type, using the unique ID tag 8 The system begins operating, with various evolution methods. For example 9 A user inputs information, which changes the state of the system \(either eve nt-based, process-based, or simple update loop 10 Regular update cycles occur for various system aspects 11 The system operation mechanism executes, and an Execution Cycle operation for the CG is activated 12 Each time a system operation mechanism is activated step 4 is repeated To complete the KEE summary, the CG  operation must be described. Recall that each node has a truth value Ö a binary variable. When the system is initialized, the truth value for each node is set to false. Each node can be queried for current truth value. Truth values can be to true, or to false When a node is the appropriate software or hardware function is performed. U pon completion of the nodeês software or hardware function, the truth value is queried If the node is  an is appropriately according to the current nodeês  
Dividend: 9.0 Divisor: 4.0 Number: 144.0 Quotient: 2.0 Remainder: 1.0 SquareRoot: 12.0 Sum: 14.0 divide plus sqrt 
concept relationship actor 
544 
60 
60 
60 


Dividend: 9 Divisor: 4 Number: 144 Quotient: 2 Remainder: 1 SquareRoot: 12 Sum: *s divide plus plus sqrt IF ?r = 0 IF ?r = 0 T T T T T T T T T F 
  
B. Adaptive and Dynamic Operation 
A Machine An Interpreter Algorithm An Interpretation An Agent A Graph A Behavior 
runs Is a generating for Responsible for of Producing 
The first time through the CG execution, an Input nodes typically read data values, or access databases, before execution is completed. Minimally, if a single input node executes and is true, the nodes connected by CG arcs are activated A case in which zero input nodes execute as true The system control mechanism is notified that the CG Execu tion Cycle is complete. This is but the in the opposite case and the system control mechanism is notified. Hence, KEE has the ability to determine that no further nodes can be activated A CG can be viewed and analyzed in terms of graph theory utilizing the rules of CG formation. The constraints on CG formation lead to directed graphs that allow the optimization of computation  The execution of the graph is extremely efficient and straightforward. For cu stomization purpos es, several different techniques exist Ö each maintains efficiency. The exact circumstances of system integration efforts may vary from one job to the next. Hence, different execution optimization methods may be employed; and each method is within scope of the KEE The subsequent description of th e KEEês preferred embodiments provides several op timization possibilities In general, a graph G consists of a set of nodes N, and a set of arcs A with a truth value associated with each graph element The truth values permit a singl e graph to encompass multiple execution paths/outcomes that are rel ated \(shown in Figure 6 the arcs indicate a direction, as the graph in Figure 4 indicates the graph is called a As such, a CG is a directed graph. Furthermore, a CG has speci fic input and output nodes called in general graph theory. Sources and sinks are the starting point of outgoing arcs, an d the terminal point of incoming arcs, respectively A path P is a set of nodes N and directed arcs A starting at an input node, terminating at an output node, and contains a sequence of internal nodes and arcs \(Figure 5, highlighted in red\ber of paths exist in a given CG. Various techniques can be employed to compute the paths, and to store and utilize path information. Tec hniques used to store and access path information will vary from job to job, and are within the scope of the KEE The method in which the truth value is used to control graph execution allows the KEE to implement first order predicate calculus logic rules to cont rol the system \(a critical KEE point as illustrated in Figure 7 Consequently, the KEE enables useful extensions of techniques, common to expert systems. Standard systems integration theory and techniques are incorporated in the design and control system. Clearly, KEE is a powerful tool in system control, and is advanced far beyond standard systems integration theory and techniques The KEE unites numerous di sciplines in realization, and derives value from the union. The KEE provides a knowledgebased representation of the system to be integrated. Furthermore the entire toolkit of advanced system theory is employed in a trouble-free, straightforw ard manner, which contrasts significantly from current complicated methods Adaptive systems theory is an emerging science, central to automated, or çsmarté, systems. However, a major barrier, or problem, is associated with automated devices and systems Current systems are in sufficient in prov iding complex and robust control mechanisms The KEE provides a solution to the barrier in advancement and proliferation of adaptive, automated systems. The KEE has the ability to dynamically chang e the structure system control logic and which components, in cluding new ones, are currently being utilized. As such, KEE facilitates the implementation of adaptive systems The benefits obtained by using KEE are extended in several dimensions \(for example the ability to interactively and automatically control the system\ performance and 
Execution Cycle \(EC\xecution of the input nodes the Execution Cycle is complete the simplest case general concept is true When there are no more nodes that can be activated the Execution Cycle is complete Figure 6. Sample conceptual graph showing a path outlined in red\ontained within the graph Figure 7. Use of truth values to control CG execution 
directed graph sources and sinks 
A. First Order Predicate Calculus 
545 
61 
61 
61 


                 
flexibility is achieved by u tilizing several CGs at once to integrate and control a particularly complex system The ability to dynamically chang e the system control logic is central to the KEEês enhanced flexibility. Typically, a system upgrade in which the control mechanism is altered requires the system to be restarted regularly the equivalent of a çrebooté to PC users\he KEE eliminates the need to restart KEE has the capability to Execute multiple CGs Dynamically load a new CG simultaneous to system execution Pause a CG execution Re-start a CG execution once it has been paused Stop a CG execution with no re-start Enabling a powerful set of tools to manage the complexity of system integration solution analysis design, and implementation will have a dramatic impact on the industries where system integration is a key function  V. E XAMPLE   B UILDING A UTOMATION M ANAGEMENT  To illustrate CONDORês concept of operation, consider the challenge in constructing a building automation management system. Managing the high tech bui ldings in an energy efficient manner, as well as satisfying the occupan ts, is a difficult and costly task without intelligent control systems. An intelligent building maximizes efficiency and energy resources, and minimizes costs. Effectual intelligen ce depends on the intelligent design Minimally, the attri butes an intelligent building should possess include Instant knowledge of occurrences inside and out Assessment and resolution fo r the most convenient comfortable, and productive environment Immediate response to occupants' requests The attributes indicate a ne ed for various technology and management systems. Successful systems integration produces the intelligent bu ilding. Smart automation systems respond to external climate factors and co nditions. Simultaneo usly, sensing control, and monitoring of internal environment factors occur CONDOR provides Reduction of energy consumption and environmental pollution Security for people, possess ions, and environment Increased processing efficiency and decreased time Simple and clear processing features Operations-oriented maintenance management of technical installations to reduce system downtime and decrease living costs Historical and dynamic data processing, presentation, and analysis To realize the above benefits a powerful control and automation system, with va rying levels of information processing \(Figure 8\ust be installed. In order to implement such a system, several sub-systems must be employed \(shown in Figure 14 A perfect integrated buildin g automation system allows physical and functional access to all building systems Integration does not occur unl ess data communication among the various systems transpires in accordance with requirements For integration purposes, an analysis of information requirements is essential \(i.e. safe access to the right information in the right way, at the right place  Supervisory control systems are central to building energy management, and consist of hierarchi cally organized, functional control systems with separate intellig ent automation units. The following aspects are required Each level must operate independently Data interchange must be reduced to a minimum Operational readiness of machinery must not be impaired by communication interchange breakdowns A commanding supervisory syst em is based on distributed intelligence, in which outstations controllers\by a communication bus \(network The control system is configured into four hierarchical Information processing levels Analyzes the systems operating status. Physical and technical data relating to the building, and emanating from the lower control and automation levels, are accessed in a condensed form and processed. Processing is achieved via miniature single board 
                 
Level 1 Information management system Level 2 Information processing And supervisory system Level 3 Information processing Automation system Level 4 Process field 
Figure 8. Automation levels Information and Management Level 
546 
62 
62 
62 


computers \(SBCs\ploying web-browser interfaces that interface to all automation levels Controls, monitors, and logs the processes within the entire building. Configures automation units, measurements, and control units at a level three and sets the parameters. Further functions include: data processing, data recording, and maintenance management of the technical installationês energy management Contains the distri buted intelligence for mathematical and ph ysical-based operation functions, as outstation multi-controllers. The di stributed digital control DDC\onitors and controls the critical statuses and processes within the building The control system, which also provides programmable controller \(pLC functions, allows a logical link in the form of time or status el ements. It optimizes performance and security of installations. The auto mation level consists of numerous DDC controller outstations. Each panel is fully programmable and autonomous in operation. The panels coordinate communication up wards to the central computer horizontally to other outstations Contains the sensors and actuators which directly link to automation syste ms at level three. Most sensors and actuators are available solely as analogue units Communication with levels two and on e is limited to level three  VI  S UMMARY  An approach has been presented for in telligent application development and systems integration within the CONDOR architecture. The approach provides a low-cost, straightforward method for developing easy to use, yet complex consumer devices and systems. CONDOR employs advanced system representation frame works, flexible comm unications structures intelligent application services \(e.g. real-time control\plex synchronization relati onships and constraints, data time tagging checkpoint restart, dynamic syste m control, and persistence CONDOR also provides intelligent application developers and system integrators with a pa rallel and distributed computing capability that supports a wide variety of hardware hosting and integration VII  R EFERENCES   Wallace, Jef f rey and Sara Kam bouris, 2012 A utomated Intelligent Instructional Monitoring Systems,é Proceeding of the 2012 International Conference on Artificial In telligence, World Academy of Sciences, Las Vegas, NV, July 16-19  Wallace, Jef f rey  et al, 2009  Ontolog y based Software and Hardware System Integration and Intelligent Automation,é Proceedings of the World Multi-Conference on Systemics, Cybernetics and Informatics, International Inst itute of Informatics and Systemics Orlando, FL, July 10-13  Peirce, C  S Coll ect ed Pap e r s  of Charles S. Peirce, Hartshorn e Weiss, and Burks \(eds.\ University Press, Cambridge, MA 1932  Sowa, J.F., Knowledge R e presentation  Logical, Philosophical, and  Computational Foundations. 2000, Paci\002c Grove, CA: Brooks/Cole, pp xiv+594  Microsoft .N ET Framework http m sdn.m icrosoft.com enus/vstudio/aa496123  , Microsoft, Inc., 2014  Parallel Virtual Machine http://www.csm.ornl.gov/pvm/pvm_building.html , Oak Ridge National Laboratory, 2005  Environment http://www.cs.wustl.edu/~schmidt/ACE.html , Washington University 2011  POSIX Threads Programming http://www.llnl.gov/computing/tutorials/pthreads/ , Lawrence Livermore National Laboratory, June 30, 2013  Real Time C O RBA with TA O http://www.cs.wustl.edu/~schmidt/TAO.html , Washington University 2013  IBM Comp onent Conn ector  Overview http://www.redbooks.ibm.com/abstracts/SG242022.html?Op en IBM, Inc. June 19, 1998  ORBit2, http://www.gnome org/projects/OR Bit2/, GNOME Foundation, June 29, 2004  SAP Solutions, http www.sap.com/solution html, SAP AG 2014  Oracle Enterprise Resource Planning http://www.oracle.com/us/products/applications/enterprise-resourceplanning/overview/index.html, Oracle, Inc. January 2014  Oracle Ser v ice-Ori ented Architecture http://www.oracle.com/us/products/middleware/soa/overview/index.ht ml, January 2014  About W3C: Technolog y   http://www.w3.org/Consortium/technology, W3C Consortium, June 2012 
Supervisory Control Level Automation Level Field Level Figure 9. Building sub-systems 
Heating Air conditioning Computers Computer Accessories Sanitary Lighting Wastemanagement Electrical Acoustics Video/Security Safety systems Kitchen appliances Entertainment Systems Controls Remote Access Ventilation 
Home 
547 
63 
63 
63 


               


C C C 
Intuitively delta compression should slow down the data-restore performance of a data-reduction system since it needs to restore the resembling chunks by two reads one for the delta data and the other for the base-chunk and then delta decode them But in our evaluation of the restore operations for resembling chunks we nd that the speed of delta decode i.e Xdelta  8  tends to be v ery f ast about 1GB/s in the DARE system Another interesting observation is that for a restoration cache of a given size with a delta chunk and its based chunk  DARE actually caches more logical content of the two chunks and than a deduplication-only system and thus improves the datarestore performance by virtual of the enlarged restoration cache due to delta compression Figures 7\(a and 8\(a show that DARE on average doubles the data-restore speed of the deduplication-only system both running on the RAID Figures 7\(b and 8\(b clearly show that the reason lies in the fact that DARE reads half as many containers for restoration as the deduplicationonly system The superior data-restore performance of SF-2F and SF-4F to the deduplicationonly system is attributed to their data reduction efìciency see Tables 3 and 4  Since the restoreperformance for the other six datasets is similar to and consistent with that of the Less dataset they are omitted to save space The sudden increase in the data-restore performance of the deduplicationonly approach at the backup version 17 Figure 8\(a we observe is due to the fact that most of the backed-up sources targeted for restoration are from the current and recent backups and thus have fewer random reads for restoration 
Figure 5 Percentages of data reduced by DupAdj and the SF SF SF of the super-feature approach respectively in the streaminformed DARE SF-2F and SF-4F approaches a Throughput on RAID b Throughput on SSD Figure 6 Throughputs of four resemblance detection enhanced data reduction approaches on the two synthesized datasets a Restoration throughput b Containers read Figure 7 Data-restore performance versus backup version on the Linux dataset with an LRU cache of size 256MB a Restoration throughput b Containers read Figure 8 Data-restore performance versus backup version on the Less dataset with an LRU cache of size 512MB because it incurs the largest computation overhead for resemblance detection It is noteworthy that DAREês average data-reduction throughput on RAID at 50MB/s is much lower than DAREês average throughput of 85MB/s on SSD The root cause of RAIDês inferior data-reduction performance in Figure 6\(a mainly lies in the random reads of the base-chunks In general DARE achieves superior performance of both throughput and data reduction efìciency among all the resemblance detection approaches as indicated in Figure 6 and Table 4  
002 
4.5 Restoration Performance 
i,k i i k 
1 2 3 
st nd rd 
211 


In this paper we present DARE a deduplication-aware low-overhead resemblance detection and elimination scheme for delta compression on the top of deduplication on backup datasets DARE uses a novel resemblance detection approach DupAdj which exploits the duplicate-adjacency information for efìcient resemblance detection in existing deduplication systems and employs an improved super-feature approach to further detecting resemblance when the duplicate-adjacency information is lacking or limited Our preliminary results on the data-restore performance suggest that supplementing delta compression to deduplication can effectively enlarge the logical space of the restoration cache but the data fragmentation in data reduction systems remains a serious problem  19  W e plan to further study and improve the data-restore performance of storage systems based on deduplication and delta compression in our future work This work was supported in part by National Basic Research 973 Program of China under Grant No 2011CB302301 NSFC No 61025008 61173043 and 61232004 863 Project 2013AA013203 US NSF under Grants IIS-0916859 CCF-0937993 CNS-1116606 and CNS-1016609 This work was also supported by Key Laboratory of Information Storage System Ministry of Education China 
 G W allace F  Douglis H Qian P  Shilane S Smaldone M Chamness and W  Hsu Characteristics of backup workloads in production systems in  2012  P  Shilane M Huang G W allace and W  Hsu W AN optimized replication of backup datasets using streaminformed delta compression in  2012  A Muthitacharoen B Chen and D Mazieres A lo w-bandwidth netw ork le system  in  2001  C Constantinescu J Glider  and D Chambliss Mixing deduplication and compression on acti v e data sets  in  IEEE 2011 pp 393Ö402  B Zhu K Li and H P atterson A v oiding the disk bottleneck in the data domain deduplication le system  in  USENIX Association 2003  J Gailly and M Adler  The gzip compressor   http://www gzip.or g 1991  P  K ulkarni F  Douglis J LaV oie and J T race y  Redundanc y elimination within lar ge collections of les  in  USENIX Association 2004  J MacDonald File system support for delta compression  Masters thesis Department of Electrical Engineering and Computer Science University of California at Berkeley 2000  S Quinlan and S Dorw ard V enti a ne w approach to archi v al storage  in  2002  F  Douglis and A Iyengar   Application-speciìc delta-encoding via resemblance detection  in  USENIX Association 2003  L Arono vich R Asher  E Bachmat H Bitner  M Hirsch and S Klein The design of a similarity based deduplication system in  ACM 2009  M Rabin  Center for Research in Computing Techn Aiken Computation Laboratory Univ 1981  D Gupta S Lee M Vrable S Sa v age A C Snoeren G V ar ghese G M V oelk er  and A V ahdat Dif ference engine harnessing memory redundancy in virtual machines in  2008  Q Y ang and J Ren I-CASH Intelligently coupled array of ssd and hdd  in  2011  A Broder  Identifying and ltering near duplicate documents  in  2000   Some applications of Rabins ngerprinting method  in  1993   On the resemblance and containment of documents  in   V  T araso v  A Mudrankit W  Buik P  Shilane G K uenning and E Zadok Generating realistic datasets for deduplication analysis in  2012  M Lillibridge K Eshghi and D Bhagw at Impro ving restore speed for backup systems that use inline chunkbased deduplication in  2013  W  Xia H Jiang D Feng and Y  Hua SiLo A Similarity-Locality based Near Exact Deduplication Scheme with Low RAM Overhead and High Throughput in  2011 
Proc USENIX FAST Proc USENIX FAST Proc ACM SOSP Data Compression Conference DCC 2011 Proc USENIX FAST USENIX Annual Technical Conference Proc USENIX FAST Proc USENIX FAST Proceedings of SYSTOR 2009 The Israeli Experimental Systems Conference Fingerprinting by random polynomials Proc USENIX OSDI Proc IEEE HPCA Combinatorial Pattern Matching Sequences II Methods in Communications Security and Computer Science Compression and Complexity of Sequences 1997 USENIX Annual Technical Conference Proc USENIX FAST USENIX Annual Technical Conference 
5 Conclusion and Future Work Acknowledgments References 
212 


method increases slightly which is due to two reasons 1 the data before In this experiment we investigate the performance of OLTP queries when OLAP queries are running The workload is update-only and the keys being updated are uniformly distributed We launch ten clients to concurrently submit the updates when the system is deployed on 100 nodes Each client starts ten threads each of which submits one million updates 100 updates in batch Another client is launched to submit the data cube slice query That is one OLAP query and approximately 50,000 updates are concurrently processed in R-Store The system reaches its maximum usage in this setting based on our observation When the system is deployed on other number of nodes the number of clients submitting updates is adjusted accordingly Figure 11\(a shows the throughput of the system The throughput increases as the number of nodes increases which demonstrates the scalability of the system However when OLAP queries are running the update performance is lower than running only OLTP queries This result is expected because the OLAP queries compete for resources with the OLTP queries We also evaluate the latency of updates when the system is approximately fully used As shown in Figure 11\(b the aggregated response time for 1000 updates are similar with respect to varying scales VII C ONCLUSION MapReduce is a parallel execution framework which has been widely adopted due to its scalability and suitability in 0    500    1000    1500    2000  0  10  20  30  40  50  60  70  80  90  100  IncreQueryScan             IncreQueryExe              DC DC DC  Q i i i i T part  Q a Data Cube Slice Query                                                                                                b TPC-H Q1 Fig 7 Performance of Querying    Fig 8 Accuracy of Cost Model    Fig 9 Performance vs Freshness On each HBase-R node the key/values are stored in format Though only one or two versions of the same key are returned to MapReduce HBase-R has to scan all the of the table Since the is materialized to HDFS when it is full these 223les are sorted by time Thus instead of scanning all the and between  only the between   are scanned The value of decides the freshness of the result There is a trade-off between the performance of the query and the freshness of the result the smaller is the fewer real-time data are scanned Figure 9 shows the query processing time with different freshness ratios which is de\223ned as the percentage of the real-time data we have to scan for the query In this experiment  1600 million and 800 million updates on 1 distinct keys are submitted to HBase-R When the freshness ratio is 0 the input of the query is only the data cube Thus the cost of scanning the real-time data is 0 When the freshness ratio increases to 10 the cost of scanning the real-time data is around 1500 seconds because the cost of scanning the real-time table dominates the OLAP query As the freshness ratio increases the running time of and  and when it is not  and  We submit 800 million updates to the server each day and the percentage of keys updated is 223xed to 1 The data cube is refreshed at the beginning of each day and the OLAP query is submitted to the server at the end of the day Since the data are compacted after the data cube refresh the amount of data stored in the real-time table are almost the same at the same time of each day The processing time of and are thus almost constant In contrast when the compaction scheme is turned off HBase-R stores much more data and the cost of locally scanning these data becomes larger than the cost of shuf\224ing the data to MapReduce As a result the processing time of and increases over time and and a user speci\223ed timestamp still need to be scanned and 2 the amount of data shuf\224ed to mappers are roughly the same with different ratios Figure 10 depicts the effectiveness of our compaction scheme In this experiment we measure the processing time of the data cube slice query when the compaction scheme is applied  0 1,000 2,000 3,000 4,000 5,000 Baseline IncreQuery Baseline IncreQuery Baseline IncreQuery Baseline IncreQuery Baseline IncreQuery Baseline IncreQuery Processing time \(s Percentage of keys being updated 1 5 10 15 20 25 IncreQueryExe IncreQueryScan CubeScan BaselineExe BaselineScan Processing Time \(s I/Os \(X10 11  Percentage of Keys Updated CubeScan        Processing Time \(s Freshness Ratio CubeScan                                                                                                            50 0 1,000 2,000 3,000 4,000 5,000 Baseline IncreQuery Baseline IncreQuery Baseline IncreQuery Baseline IncreQuery Baseline IncreQuery Baseline IncreQuery Processing time \(s Percentage of keys being updated 1 5 10 15 20 25 IncreQueryExe IncreQueryScan CubeScan BaselineExe BaselineScan store\223le store\223les part memstore store\223les memstore store\223les IncreQuerying Baseline IncreQuerying Baseline-NC IncreQuerying-NC Baseline IncreQuerying Baseline-NC IncreQuerying-NC C Performance of OLTP 0    1200    2400    3600    4800    6000  1  5  10  15  20  25  0  0.8  1.6  2.4  3.2  4  IncreQueryScan        IncreQueryExe        I/Os estimated for IncreQuery                               I/Os estimated for  Baseline                 T T T T T T T T 


3000    6000    9000    12000  1  2  3  4  5  6  7  IncreQuerying                                   Baseline-NC                   IncreQuerying-NC                       51 002 Fig 10 Effectiveness of Compaction    a Throughput    b Latency Fig 11 Performance of OLTP Queries a large scale distributed environment However most existing works only focus on optimizing the OLAP queries and assume that the data scanned by MapReduce are unchanged during the execution of a MapReduce job In reality the real-time results from the most recently updated data are more meaningful for decision making In this paper we propose R-Store for supporting real-time OLAP on MapReduce R-Store leverages stable technology HBase and HStreaming and extends them to achieve high performance and scalability The storage system of R-Store adopts multi-version concurrency control to support real-time OLAP To reduce the storage requirement it periodically materializes the real-time data into a data cube and compacts the historical versions into one version During query processing the proposed adaptive incremental scan operation shuf\224es the real-time data to MapReduce ef\223ciently The data cube and the newly updated data are combined in MapReduce to return the real-time results In addition based on our proposed cost model the more ef\223cient query processing method is selected To evaluate the performance of R-Store we have conducted extensive experimental study using the TPCH data The experimental results show that our system can support real-time OLAP queries much more ef\223ciently than the baseline methods Though the performance of OLTP degrades slightly due to the competition for resources with OLAP the response time and throughput remain good and acceptable A CKNOWLEDGMENT The work described in this paper was in part supported by the Singapore Ministry of Education Grant No R-252000-454-112 under the epiC project and M.T 250 Ozsu\220s work was partially supported by Natural Sciences and Engineering Research Council NSERC of Canada We would also like to thank the anonymous reviewers for their insightful comments R EFERENCES  http://hbase.apache.or g  http://hstreaming.com  http://www comp.nus.edu.sg epic  M Athanassoulis S Chen A Ailamaki P  B Gibbons and R Stoica Masm ef\223cient online updates in data warehouses In  pages 865\205876 2011  Y  Cao C Chen F  Guo D Jiang Y  Lin B C Ooi H T  V o S W u and Q Xu Es2 A cloud data storage system for supporting both oltp and olap ICDE pages 291\205302 2011  S Ceri and J W idom Deri ving production rules for incremental vie w maintenance In  pages 577\205589 1991  T  Condie N Conw ay  P  Alv aro J M Hellerstein K Elmelee gy  and R Sears Mapreduce online In  pages 313\205328 2010  J Dean S Ghema w at and G Inc Mapreduce simpli\223ed data processing on large clusters In  pages 137\205150 2004  L Golab T  Johnson and V  Shkapen yuk Scheduling updates in a real-time stream warehouse ICDE pages 1207\2051210 2009  M Grund J Kr 250 uger H Plattner A Zeier P Cudre-Mauroux and S Madden Hyrise a main memory hybrid storage engine  4\(2 Nov 2010  A Gupta I S Mumick and V  S Subrahmanian Maintaining vie ws incrementally extended abstract In  pages 157\205166 1993  S H 264 eman M Zukowski N J Nes L Sidirourgos and P Boncz Positional update handling in column stores In  pages 543\205 554 2010  D Jiang G Chen B C Ooi and K.-L T an epic an e xtensible and scalable system for processing big data 2014  D Jiang B C Ooi L Shi and S W u The performance of mapreduce an in-depth study  3\(1-2 Sept 2010  D M Kane J Nelson and D P  W oodruf f An optimal algorithm for the distinct elements problem PODS 22010 pages 41\20552  A K emper  T  Neumann F  F  Informatik T  U Mnchen and DGarching Hyper A hybrid oltp&olap main memory database system based on virtual memory snapshots In  2011  T W  K uo Y T  Kao and C.-F  K uo T w o-v ersion based concurrenc y control and recovery in real-time client/server databases  52\(4 Apr 2003  K Y  Lee and M H Kim Ef 223cient incremental maintenance of data cubes In  pages 823\205833 2006  F  Li B C Ooi M T  250 Ozsu and S Wu Distributed data management using mapreduce In  2014  I S Mumick D Quass and B S Mumick Maintenance of data cubes and summary tables in a warehouse In  pages 100\205111 1997  A Nandi C Y u P  Bohannon and R Ramakrishnan Distrib uted cube materialization on holistic measures In  pages 183\205194 2011  L Neume yer  B Robbins A Nair  and A K esari S4 Distrib uted stream computing platform In  pages 170\205177 2010  C Olston B Reed U Sri v asta v a R K umar  and A T omkins Pig latin a not-so-foreign language for data processing In  pages 1099\2051110 2008  K Ser ge y and K Y ury  Applying map-reduce paradigm for parallel closed cube computation In  pages 62\20567 2009  M Stonebrak er  D J Abadi A Batkin X Chen M Cherniack M Ferreira E Lau A Lin S Madden E O\220Neil P O\220Neil A Rasin N Tran and S Zdonik C-store a column-oriented dbms In  pages 553\205564 2005  A Thusoo J S Sarma N Jain Z Shao P  Chakka S Anthon y  H Liu P Wyckoff and R Murthy Hive a warehousing solution over a mapreduce framework  2\(2 2009  P  V assiliadis and A Simitsis Near real time ETL In  volume 3 pages 1\20531 2009  C White Intelligent b usiness strate gies Real-time data w arehousing heats up  2012 SIGMOD VLDB NSDI OSDI SIGMOD SIGMOD Proc VLDB Endow In ICDE IEEE Trans Comput VLDB ACM Computing Survey SIGMOD ICDE ICDMW SIGMOD DBKDA VLDB PVLDB Annals of Information Systems DM Review 0    Processing Time \(s Time since the Creation of Data Cube \(day Baseline                  Updates Per Second \(K Number of Nodes Updates only                  Response Time for 1000 Updates\(s Number of Nodes Updates only                  0    20    40    60    80    100  10  20  30  40  50  60  70  Updates + OLAP                                    0    2    4    6    8    10  10  20  30  40  50  60  70  Updates + OLAP                                    Proc VLDB Endow 


  13    1  2   3   4   5   6   7   8  9  10  11   


and aeronautical engineering with degrees from Universitat Politecnica de Catalunya in Barcelona Spain and Supaero in Toulouse France He is a 2007 la Caixa fellow and received the Nortel Networks prize for academic excellence in 2002 Dr Bruce Cameron is a Lecturer in Engineering Systems at MIT and a consultant on platform strategies At MIT Dr Cameron ran the MIT Commonality study a 16 002rm investigation of platforming returns Dr Cameron's current clients include Fortune 500 002rms in high tech aerospace transportation and consumer goods Prior to MIT Bruce worked as an engagement manager at a management consultancy and as a system engineer at MDA Space Systems and has built hardware currently in orbit Dr Cameron received his undergraduate degree from the University of Toronto and graduate degrees from MIT Dr Edward F Crawley received an Sc.D in Aerospace Structures from MIT in 1981 His early research interests centered on structural dynamics aeroelasticity and the development of actively controlled and intelligent structures Recently Dr Crawleys research has focused on the domain of the architecture and design of complex systems From 1996 to 2003 he served as the Department Head of Aeronautics and Astronautics at MIT leading the strategic realignment of the department Dr Crawley is a Fellow of the AIAA and the Royal Aeronautical Society 050UK\051 and is a member of three national academies of engineering He is the author of numerous journal publications in the AIAA Journal the ASME Journal the Journal of Composite Materials and Acta Astronautica He received the NASA Public Service Medal Recently Prof Crawley was one of the ten members of the presidential committee led by Norman Augustine to study the future of human space\003ight in the US Bernard D Seery is the Assistant Director for Advanced Concepts in the Of\002ce of the Director at NASA's Goddard Space Flight Center 050GSFC\051 Responsibilities include assisting the Deputy Director for Science and Technology with development of new mission and measurement concepts strategic analysis strategy development and investment resources prioritization Prior assignments at NASA Headquarters included Deputy for Advanced Planning and Director of the Advanced Planning and Integration Of\002ce 050APIO\051 Division Director for Studies and Analysis in the Program Analysis and Evaluation 050PA&E\051 of\002ce and Deputy Associate Administrator 050DAA\051 in NASA's Code U Of\002ce of Biological and Physical Research 050OBPR\051 Previously Bernie was the Deputy Director of the Sciences and Exploration Directorate Code 600 at 050GSFC\051 Bernie graduated from Fair\002eld University in Connecticut in 1975 with a bachelors of science in physics with emphasis in nuclear physics He then attended the University of Arizona's School of Optical Sciences and obtained a masters degree in Optical Sciences specializing in nonlinear optical approaches to automated alignment and wavefront control of a large electrically-pumped CO2 laser fusion driver He completed all the course work for a PhD in Optical Sciences in 1979 with emphasis in laser physics and spectroscopy He has been a staff member in the Laser Fusion Division 050L1\051 at the Los Alamos National Laboratories 050LANL\051 managed by the University of California for the Department of Energy working on innovative infrared laser auto-alignment systems and infrared interferometry for target alignment for the HELIOS 10 kilojoule eight-beam carbon dioxide laser fusion system In 1979 he joined TRW's Space and Defense organization in Redondo Beach CA and designed and developed several high-power space lasers and sophisticated spacecraft electro-optics payloads He received the TRW Principal Investigators award for 8 consecutive years Dr Antonios A Seas is a Study Manager at the Advanced Concept and Formulation Of\002ce 050ACFO\051 of the NASA's Goddard Space Flight Center Prior to this assignment he was a member of the Lasers and Electro-Optics branch where he focused on optical communications and the development of laser systems for space applications Prior to joining NASA in 2005 he spent several years in the telecommunication industry developing long haul submarine 002ber optics systems and as an Assistant Professor at the Bronx Community College Antonios received his undergraduate and graduate degrees from the City College of New York and his doctoral degree from the Graduate Center of the City University of New York He is also a certi\002ed Project Management Professional 14 


 





 17  Jar r e n  A   B al d w i n  is  a  Ch i c a g o  n a t i v e  a n d  c u r r e n t l y  se r v e s a s t h e  l e a d  E l e c t r i c a l  En g i n e e r  a t  B a y  A r e a  s t a r t u p   Oc u l e v e  I n c   He  g r a d u a t e d  fr o m  t h e  U n i v e r s i t y  o f Il l i n o i s  wi t h  a  B  S   i n  2 0 0 9  an d  r ecei v ed  an  M  S   i n  El e c t r i c a l  En g i n e e r i n g  f r  St a n f o r d  U n i v e r s i t y  i n  2 0 1 2   Ja r r e n  d e v e l o p e d  h a r d w a r e  a n d  so f t w a r e  sy st e m s f o r  a  w i d e  ra n g e  o f  f i e l d s   i n c l u d i n g  s p a c e  s c i e n c e  s y s t e m s  a n d  m e d i c a l  de vi c e s  a s  a N A S A  A m es  i nt e r n i n t he  In t e l l i g e n t  S y s t e m s     1  2  3   4   5   6   7   8   9   10   11   12   13   


                        


                           


   












































     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



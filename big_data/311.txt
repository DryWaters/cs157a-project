A Fuzzy AprioriTid Mining Algorithm with Reduced Computational Time Tzung-Pei Hong Department of Electrical Engineering National University of Kaohsiung Kaohsiung 811 Taiwan R.O.C Chan-Sheng Kuo and Shyue-Liang Wang National Chengchi University, I-Shou University Abstract Most of wnventional data mining algorithms identify the relation among transactions with binq values ltansactions with quantitative values are however commonly seen in mal world applicaiions In the past we proposed a fuzzy mining algorithm based on the ApMn approach to explore interesting owledge from the transactions with quantitative 
values This paper pmposes another new fumy mining algorithm based on the Aprioni appmach to rmd fuzzy associatiou rules fnnn given quantitative transactions Each item uses only the linguistic term with the maximum cardinality in later mining processes thus making the number of fuzzy regions to be processed the same as that of the original items The algorithm therefore focuses on the most important linguistic terms fur reduced time complexity I INTRODUCnON In data mining researches inducing association rules 
from transaction data is the most commonly seen 5][12 Most of the previous research works can however only handle transaction data with attributes of binary values In real-world applications transaction data are usually composed of quantitative values Designing a sophisticated data-mining algorithm to deal with different types of data tums a challenge in this research topic Fuzzy set theory 14 is being wed more and more frequently in intelligent systems because of its simplicity and similarity to human reasoning ll Several fuzzy learning algorithms for inducing rules from given sets of data have been designed and used to good effect with 
specific domains In 9 we proposed a mining approach that integrated fuzzy-set concepts with the Apriori mining algorithm 4 to find interesting itemsets and fuzzy association rules in transaction data with auantitative values This mper ProDoses the data in a supermarket of a department store show the feasibility of the proposed mining algorithm 11 NOTAnON In this paper, the fuzzy concepts are used in the AprioriTid data-mining algorithm to discover useful association rules from quantitative values Notation used in this paper is first stated as follows n the total number of transaction data m the total number ofanributes D 
 the i-th transaction dahrm 1 s is n A  the j-th attribute 1 5 j s m 1~~1 thenumberoffuayregionsforAj R vy the quantitative value ofAj forD\(i fj thefuzzy set convertedfrom vf f  the membership value of vy in Region R countg  the summation off for i=l to n county  the maximum count value among count k values k=1 to 1  RY  the region of 
Ai with county a  the predefined minimum support level A  the predefined minimum confidence value C the set of candidate itemsets with r attributes items C  the temporary set for recording the jiuq values of L  the set of large itemsets with r attributes items  the k-thfuzzy region ofA j 1 s k s IA 1 r-items in each data 111 THE PROPOSED FUZZY DATA-MINING ALGORITHM    another new 
fuzzy mi&z algorithm based on the AprioriTid approach 41 to find fuzzy assc&tion rules from given quantitative transactions It is capable of transforming quantitative vaIues in transactions into linguistic tens then filtering them and finding association rules Each item uses only the linguistic term with the maximum cardinality in later processes thus m.&j,,g the number of fuzzy re@ons to he proca the Same as that of the items The algorithm therefore focuses on the most important linguistic terms for Experimental results from The proposed fuzzy mining algorithm first 
transforms each quantitative value into a set with hnguistic terms using membership functions The algorithm then calculates the cardinality of each linguistic ten on all the transaction data using the temporary set F  Each attribute uses only the linguistic term with the maximum cardinality in later mining processes thus keeping the number of items the same as that of the original attributes The mining process based on fuzzy Counts is then Performed to find fuzzy association rules. The 0-7803-7293-x101/$17.00 B 2001 IEFE 360 ZOO1 IEEE International Fuzzy Systems Conference 


detail of the proposed mining algorithm is described as follows The Algorithm INPUT A body of n transaction data each with m attribute values a set of membership functions a predefined minimum support value a  and a predefined confidencevalue E  OUTPUT Aset of fuzzy associate rules STEP 1 Transform the quantitative value vf of each transaction datumD i=l to n for each attribute AI j=1 to m into a fuzzy set f  represented as using the given membership functions where R1 is the k-th fuzzy region of attribute A fji is 4 fuzzy membership value in region Rp  and I A is the number of fuzzy regions for A including all the pairs STEP 2 Build a temporary set Rjk fj of each data where lsisn 1 L j s m 1 d k s Aj and fji L 0 STEP 3 For each region RA stored in Cl calcul its scalar cardinality for all the transactions from C  141 STEP 4 Find counF  MkY\(Eountj kd for j 1 to m where IA the number of fuzzy regions forAj Let Rj he the region with counl;.w for attribute Ai  R will he used to represent this attribute in later mining processing STEP 5 Check whether the county of each  j=l to m is larger than or equal to the predefined minimum support valuen If R is equal to or greater than the minimum support value put it in the set of large 1-itemsets LI That is LI kkounl;n~+a,~sjsm STEP 6 Set r=l where r is used to represent the number of items kept in the current large itemsets STEP 7 Generate the candidate set C from L Restated the algorithm joins L and L under the condition that r-1 items in the two itemsets are the same and the other one is different Store in C the itemsets which have all their sub-r-itemsets in L STEP 8 Build an empty temporary set c  STEP 9 Do the following substeps for each newly formed r+l s with items s1 s2  s in G+1 a For each transaction datum di calculate its fuzzy value on s as f  f  if I using cr  where f is the fuzzy membership value of D in region si If the minimum operator is used for the intersection then f hfb ft b Store the pair s f of Case i in Fr where 1s i 5 n fy  0 c set count  5 f using c d If count is larger than or equal to the predefined minimum support value Cl put s in L,+l STEP 10 IF L,+l is null then do the next step otherwise set r=r+l and repeat STEPS 7 to 10 STEP 11 Construct the association rules for all large q-itemset s with items s sz  sq  qs2 using the following substeps l I 1 a Form all possible association NI as follows s,A...As~.~Ask+,A...As  st k=l toq association rules using  Calculate the confidence values of all fy i-1 i\(f  A f f i 8 i-1 STEP 12: Output the rules with confidence values larger than or equal to the predefined confidence threshold A After STEP 12 the rules constructed are output and can act as the meta-knowledge for the given transactions IV ANEXAMPLE In this section an example is given to illustrate the proposed data-mining algorithm This is a simple example to show how the proposed algorithm can he used to generate association rules for course grades according to historical data concerning students course scores The data set includes 10 transactions as shown in Table L Each case consists of five course scores Statistics \(denoted ST Database denoted DB Object-Oriented Programming denoted OOP Data Structure denoted DS and Management Information System denoted MIS Each course is thought of as an attribute in the mining process Assume the fuzzy membership functions for the course scores are as shown in Figure 1 In this example each attribute has three fuzzy regions Low Middle and High Thus three fuzzy membership values are 361 


produced for each course score according to the predefined membership functions The transaction data in Table I are first bansformed into fuzzy sets with the results shown in Table 11 1 86 1 77  86 71 68 21 61  79 I 77 I 80 89 I 31 84 1 89 1 79 I 89 86 I I 7 I Sfi I 70 I Ild I 67 6 65 77 I86 61 87 7 8 9 10 yw i  59 63 69 73 78 85 90 100 Smre Fig 1 222he membership function used in this example TABLE n SVISTRANSFORMUFROM7HEDIV*INTABLEI Ca.Na ST DB OOP us MIS LMHLMHLMHLMHLMH 1 00 0.0 0.7 0.0 07 0.0 00 0.0 0.7 0.0 0.8 0.0 0.1 0.5 00 61 87 71 80 75 86 63 64 84 86 75 65 87 88 79 79 63 85 89 63 2 0.8 0.0 0.0 0.0 0.5 0.1 0.0 0.0 0.9 0.0 0.7 00 0.0 0.4 0.2 3 0.0 0.1 0.5 0.0 0.0 0.9 0.0 U.0 0.1 0.0 0.5 0.1 0.0 0.0 0.9 4 0.0 10 0.0 0.0 0.0 0.1 0.0 0.5 0.1 0.0 U.1 05 0.7 0.0 0.0 The temporary set C is built as shown in Table 111 The region with the highest count among the three possible regions for each attribute is chosen for usage in the later mining process In this example 223High\224 is chosen for DB OOP and MIS and 223Middle\224 is chosen for ST and DS The number of items chosen is thus the same as that of the original attributes meaning the algorithm will focus on the important items and the time complexity could thus be reduced Assume in this example a is set at 2.0 Since the count values of ST.Middle, DB.Middle OOP.High DS.Middle and MIS.High are all larger than 2.0 these items are put in LI Cz and Fz is then built in Steps 7 to 10 and two itemsets DB.High DS.Middle and OOP.High, DS.Middle are kept in Lz No itemsets are put in Ls Assume the confidence A is set at 0.70 The following three rules are thus output to users 1 If the ware of Database is high, then the score of Data Structure is middle, with a confidence value of 0.71 2 If the score of Object-Oriented Programming is high then the score of Data Structure is middle with a confidence value of 0.70 3 If the score of Data Structure is middle, then the score of Object-Oriented Programming is high with a confidence value of 0.72 These three rules are thus output as meta-knowledge concerning the given transactions V EWERIMFATS Apart of the customer purchase data from a supermarket of a department store in Kaohsiung, Taiwan were used to show the feasibility of the proposed mining algorithm A total of 1508 transactions were included in the data set Each transaction recorded the purchasing information of a customer Execution of the mining algorithm was performed on a Pentium-PC. The relationship between numbers of large itemsets and minimum support values for A 0.3 are shown in Figure 2 From Figure 2 it is easily seen that the numbers of large itemsets decreased along with an increase in minimum support values This is quite consistent with our intuition. The curve of the numbers of large 1-itemsets was also smoother 362 


than that of the numbers of large 2-itemsets, meaning that the minimum support value had a larger influence on itemsets with more items I 5101rm6a I wum sum valve Fig 2 The relationship between numbers of large itemsets and minimum support values VI CONCLUSION AND mRE WORK In this paper we have proposed a fuzzy data-mining algorithm based on the AprioriTid approach to process transaction data with quantitative values and discover fuzzy association rules among them Each item uses only the linguistic term with the maximum cardinality in the mining processes thus making the number of fuzzy regions to be processed the same as that of the original items The algorithm therefore focuses on the most important linguistic terms for reduced time complexity The rules mined out exhibit quantitative regularity in large databases and can be used to provide some suggestions to appropriate supervisors The proposed algorithm can also solve conventional transaction-data problems by using degraded membership functions. Experimental results with the data in a supermarket of a department store show the feasibility of the proposed mining algorithm Although the proposed method works well in data mining for quantitative values it is just a beginning There is still much work to be done in this field. Our method assumes that the membership functions are known in advance In 6-81 we also proposed some fuzzy learning methods to automatically derive the membership functions In the future we will attempt to dynamically adjust the membership functions in the proposed mining algorithm to avoid the bottleneck of the acquisition of membership functions REFERENCES l R Agrawal T Imielinksi and A Swami 223Mining association des hehueen Sets of items in large database,\224 The 1993 ACM SIGMOD Conference Washington DC USA 1993 2 R Agrawal T Imielinksi and A Swami 223Database mining a performance perspective,\224 IEEE Transactiuns on Knowledge andDaia Engineering Vol 5 No 6,1993 pp 914-925 3 R Agrawal R Srikant and Q Vu 223Mining association rules with item constraints,\224 The Third Infemaiional Conference on Knowledge Discovery in Databases and Daia Mining Newport Beach, California, August 1997 4 R Agrawal and R Srikant 223Fast algorithm for mining association rules,\224 The International Conference on Very Large Daia Bases 1994 pp 487-499 5 W J Frawley G Piatetsky-Shapiro and C J Mathens 223Knowledge discovery in databases an overview,\224 The AAAI Workshop on Knowledge Discovery in Databases 1991 pp 1-27 6 T P Hong and J B Chen 223Finding relevant attributes and membership functions,\224 Fuzzy Seis and Sysiems Vo1.103 No 3, 1999 pp.389404 7 T P Hong and J B Chen 223Processing individual fuzzy attributes for fuzzy rule induction,\224 Fuay Seis and Sysiems Vol 112 No 1,2000 pp 127-140 8 T P Hong and C Y Lee 223Induction of fuzzy rules and membership functions from training examples,\224 Fuzzy Seis and Systems Vol 84 1996, pp. 33-47 9 T P Hong C S Kuo, and S C Chi, \223Mining association rules from quantitative data,\224 Inielligeni Daia Analysis Vol 3 No 5,1999 pp 363-376 lo T P Hong and S S Tseng, \223A generalized version space learning algorithm for noisy and uncertain data,\224 IEEE Transactions on Knowledge and Data Engineering Vol 9 No. 2 1991 pp 336-340 ll A Kandel Fuzq Expert Sysiems CRC Press Boca Raton 1992 pp.8-19 12 H Manila 223Methods and problems in data mining,\224 The International Conference on Daiabase Theory 1997 13 R Srikant and R Agrawal 223Mining quantitative association rules in large relational tables,\224 The 1996 ACM SIGMOD Iniernaiional Conference on Management of Daia Monreal Canada, June 1996 pp 1-12 14 L A Zadeh, \223Fuzzy sets,\224 Information and Cunhol Vol 8 No 3 1965 pp 338-353 363 


188 7 experiences low congestion in the resent period or a carrier illustrating exceeded ageing threshold. The delay improvement factor is given in figure 6 The improvement factor represents the percentage of the delay improvement obtained by the DDCR method when compared to the RC method It is obvious than the improvement percentage is greater for higher values of frame sizes i.e for class 2 Thus it is concluded that the higher the TDMA time frames is the greater the delay performance I  I Caniels I I Figure 6 Delay improvement between DDCR and RC methods for class 1 and 2 During the simulations we observed that the frame sizes produced by the DDCR and the RC methods are about the same Even under this condition the mean delay values obtained by the DDCR methods are smaller Figures 7 and 8 show the mean frame duration for classes 1 and 2 respectively. For class 1 the mean frame duration of the RC method is about 1 slot larger than the DDCR \(discipline 2 frame duration \(Figure 7 For class 2 the mean frame duration of the RC method is about 2 slots larger than the DDCR \(discipline 2 frame duration Figure 8 __ _____ 7 A 221470 r I Mean Frame Sizes Class 2 M=15 r6 O r5 O 44 0 43 0 L I BSs 1 O 141 o 1 I 12 13 14 15 16 Figure 7 Mean frame sizes for class 1 for RC method and DDCR discipline 2 when R=60 slots We have introduced a new comparison factor the Normalised improvement Factor, NIF, which represents the number of slots gain of the DDCR method in respect to frame sizes If MeanDelayRc, MeanFrameSizeRc and MeanDelayDDC MeanFrameSizeDDcR denotes the mean delay and mean frame of the RC and DDCR methods respectively then the NIF factor is defined as 19.5 19.0 Mean Frame Size Class I 12 13 14 15 IC Figure 8 Mean frame sizes for class 2 for RC method and DDCR discipline 2 when R=75 slots MeanDelayRc/MeanFrameSizeRc NIF*\(MeanDelayDDcR/MeanFrameSizeoDcR Figure 9 illustrates the achieved NIF factor According to Figure 9 for class 2 the DDCR method achieves about 6 slots delay gain in comparison with the RC, with respect to the fiame sizes This gain is about 2 slots for class 1 Thus, when the frame duration is increased the DDCR delay gain is increased as well 11 Carriers 9 IO II 12 13 14 15 16 17 Figure 9 NIF for class 1 and 2 Another important parameter is the percentage of idle carrier If this parameter receives large values on a highly competitive system i.e large number of interfering BSs and small number of available carriers then the resources are not effectively used The percentage of idle carrier is shown in figures 10 and 1 1 Idle Carrier Class 1,N=17 35 30 25 10 15 IO 5 0 IO II 12 13 14 15 16 17 18 Figure 10 Percentage of idle carrier for class 1 


189 As shown in figures 10 and 11 the DDCR method obtains better utilisation This gain receives higher importance in respect to the mean frame sizes As previously mentioned the RC mean frame duration is about 1 class 1 or 2 class 2 slots larger than the frame duration of the DDCR method. Thus, the DDCR method spreads more effectively the BSs requests among the available carriers 0 35 0 25 20 15 IO 5 0 Idle Carrier,Class 2 N=17 ___ Carriers 10 II 12 13 14 15 16 17 18 Figure 1 1 Percentage of idle carrier for class 2 V CONCLUDING REMARKS We have introduced a distributed carrier reservation method which applies to interfering BSs competing for reservation in an unlicensed wireless ATM environment The BSs offer wireless access to associated MTs using any dynamic TDMA/TDD mechanism however the proposed method can be easily modified to apply to BSs using a TDMNFDD mechanism. The DDCR method is based on etiquette rules where BSs sense the carrier before they start competing for it A carrier selection criterion was applied, based on congestion information to enable the BSs to choose the carrier that experiences the lowest congestion To assess the performance gain the DDCR method was compared with the RC and RR disciplines. From the obtained results it is concluded that the DDCR method achieves lower reservation delays and higher carrier utilisation than the RR and RC method especially for larger time frame periods i.e load class 2 Our recent simulation results not presented here show that if the DDCR process is combined with carrier congestion estimation and the Delayed Job First contention discipline then the delay stabilises Thus, the DDCR process could be associated with a distributed Wireless Call Admission control \(CAC\function. CAC can take into account the DDCR decisions, determine whether the system is under heavy load conditions, and regulate the admission policy accordingly From the recent results we have also observed that a combination of a Longest Job First and Delayed Job First discipline performs better in terms of delay and carrier utilisation Another critical issue is the stimulation of step 1 of the DDCR process According to the BS triggers the selection of a new carrier a when it looses a competition for a carrier and b upon the completion of its reservation on a carrier approach that is followed in this paper as well Recent study focuses on further conditions for carrier selection For instance, consider a BS that senses idle slot in one carrier and the consecutive slot is sensed busy According to DDCR rules this BS could not participate in the partial contention; thus it could be efficient to trigger a carrier selection procedure The proposed mechanism is immune to topology changes e.g establishment of new BS on a coverage area does not increase power consumption on MTs and finally does not require any kind of frequency preplanning Furthermore in contrast to the approach described in lo the DDCR mechanism imposes no limit to the number of BSs operating on a common area or to the number of neighbouring BSs Moreover BSs of any different dynamic TDMARDD technology 2 4 5 6 can use the DDCR mechanism, when operating on a multichannel system. Another issue is the fairness of the proposed approach From our simulations we have observed that all the BSs with identical traffic loads and equal number of interferers experience similar reservation delay performance VI REFERENCES l V 0 K Li and X Qiu, \223Personal communications systems \(PCS in Proc of the IEEE vol. 83, Sept. \22195 2 D Raychaudhuri and N Wilson 223ATM-based transport architecture for multiservices wireless personal communication networks\224 IEEE J on Select. Areas in Commun vol 12 no 8 October 1992 3 N Wilson D Raychaudhuri et al 223CDMA vs Dynamic TDMA for access control in an integrated voice/data PCN\224 in Proc lrst International Conference of Universal Personal Communications September 1992 4 L Merakos N Passas et al 223A medium access control framework for wireless ATM networks\224 in Proc of International Workshop on Mobile Commun Thessaloniki, Greece, September 22196 5 F. Bauchot 223MASCARA A wireless ATM MAC protocol\224 in Proc Wireless ATM Workshop Helsinki Finland, September 1996 6 N Passas L Merakos S Paskalis D Vali 223Quality-of-Service-Oriented medium access control for wireless ATM networks\224 IEEE Commun Mag November 1997 7 M Frodigh, \223Bounds on the performance of DCA algorithms in highway microcellular systems\224 IEEE Trans. on Vehicular Tech vol 43 no 3 August 1994 8 9 Giannis F Marias and Lazaros Merakos 223A distributed dynamic channel reservation for wireless ATM LANs\224 in Proceedings of the IZS2000 the International Zurich Seminar on Broadband Communications, Zurich, Switzerland, February 2000 lo J H Ju and V 0 K Li 223TDMA Scheduling Design of Multihop Packet Radio Networks Based on Latin Square\224 IEEE J on Select Areas in Commun vol 17 no 8 August 1999 OPNET Modeler, MIL Inc 1993 


Acknowledgments The Pacific Northwest National Laboratory is operated for the U.S. Department of Energy by Battelle Memorial Institute under contract DE-AC06-76RLO 1830 This research has been supported by a Laboratory Directed Research and Development grant funded by the U.S. Department of Energy for the Pacific Northwest National Laboratory. We wish to thank Dan Adams George Chin, Kris Cook, Sharon Eaton, Beth Hetzler Wanda Mar, Dennis McQuerry, Ted Tanasse, and Paul Whitney who provided assistance of many forms throughout this research References 1  Rakesh Agrawal and Ramakrishnan Srikant. Mining Sequential Patterns. In Proceedings of the International Conference on Data Engineering ICDE Taipei, Taiwan, March 1995 2  Barry G. Becker. Volume Rendering for Relational Data. In John Dill and Nahum Gershon, editors Proceedings Information Visualization \22297 pages 87 226 90, Los Alamitos, CA, Oct 20 226 21, 1997 IEEE CS Press 3  Barry G. Becker. Visualizing Decision Table Classifiers. In Graham Wills and John Dills, editors Proceedings of Information Visualization 222 98  pages 102-105, Los Alamitos, CA, Oct 19 226 20 1998. IEEE CS Press 4  A. Bookstein, S.T. Klein, and T. Raita. Clumping Properties or Content-Bearing Words Journal of the American Society for Information Science  49\(2\102 226 114, 1998 5  d Elke A Rundensteiner. Hierarchical Parallel Coordinates for Exploration of Large Datasets. In David Ebert Markus Gross, and Bernd Hamann, editors Proceedings IEEE Visualization 222 99 pages 43 226 50 New York, NY, Oct 24 226 Oct 29, 1999. ACM Press 6  Beth Hetzler, Paul Whitney, Lou Martucci, and Jim Thomas. Multi-faceted Insight through Interoperable Visual Information Analysis Paradigms In Graham Wills and John Dill, editors Proceedings Information Visualization 222 98 pages 137 226 144, Los Alamitos, CA, Oct 19-20, 1998. IEEE CS Press 7  Alfred Inselberg and Bernard Dimsdale. Parallel Coordinates: A Tool for Visualizing MultiDimensional Geometry. In Arie Kaufman, editor Proceedings IEEE Visualization 222 90 pages 361 226 375, Los Alamitos, CA, Oct 1990. IEEE Computer Society Press 8  Nancy E. Miller, Pak Chung Wong, Mary Brewster, and Harlan Foote. TOPIC ISLANDS 231 A Wavelet-Based Text Visualization System. In David Ebert, Hans Hagan, and Holly Rushmeier editors Proceedings IEEE Visualization 222 98  pages 189 226 196, New York, NY, Oct 18 226 23 1998. ACM Press 9  Ramakrishnan Srikant and Rakesh Agrawal. Mining Sequential Patterns: Generalizations and Performance Improvements. In Proceedings the Fifth International Conference on Extending Database Technology \(EDBT Avignon, France, March 1996 10  Jim Thomas, Kris Cook, Vern Crow, Beth Hetzler Richard May, Dennis McQuerry, Renie McVeety Nancy Miller, Grant Nakamura, Lucy Nowell Paul Whitney, and Pak Chung Wong. Human Computer Interaction with Global Information Spaces 226  Proceedings British Computer Society Conference Bradford UK, April 1999 Springer Verlag 11  Christopher Westphal and Teresa Blaxton Data tions 226 Methods and Tools for Solving Real-Word Problems New York, 1998. John Wiley and Sons 12  James A. Wise, James J. Thomas, Kelly Pennock David Lantrip, Marc Pottier, Anne Schur, and Vern Crow. Visualizing the Non-visual: Spatial Analysis and Interaction with Information from Text Documents. In Nahum Gershon and Steve Eick, editors Proceedings IEEE Information Visualization 222 95 pages 51 226 58, Los Alamitos CA, Oct 20 226 21, 1995. IEEE CS Press 13  Pak Chung Wong. Visual Data Mining 226 Guest Editor 222 s Introduction IEEE Computer Graphics and Applications Vol 19, No 5, Los Alamitos CA, 1999. IEEE CS Press 14  Pak Chung Wong, Paul Whitney, and Jim Thomas Visualizing Association Rules for Text Mining. In Graham Wills and Daniel Keim, editors Proceedings of IEEE Information Visualization 222 99  Los Alamitos, CA, 1999. IEEE CS Press e   0-76950 9 00 $10.00 @ 2000 IEEE 


Hei kki Mannila Biographical Summary Heikki Mannila is a professor of computer science at the University of Helsinki where he also obtained his Ph.D in 1985 Since then he has been an associate professor at the Universities of Tampere and Helsinki a visiting professor at the Technical University of Vienna, and a guest researcher at the Max Planck Institut fur Informatik in Saarbrucken He has also worked at the National Public Health Institution in Helsinki as well as being an industry consultant His research interests include data mining machine learning database design and text databases He is the co-author of the book Design of Relational Databases Addison Wesley\and he has been the author of numerous articles on algorithms, databases machine learning and data mining He is one of the editors-in-chief of the new scientific journal \223Data Mining and Knowledge Discovery.\224 9 


Figure 7 Correlations between query con straints and new indexed constraint the index attribute may have different ranges We iden tify all possible constraint introduction solutions as follows Algorithm For each constraint on the index attribute CO.Roj Step 1 find the least expensive association from a query constraint to i.e find the incoming link C~.R  CO.Roj with the fewest exceptions For exam ple if the cardinalities of El     E5 are nl   n5 and n4 5 nz _ n3 then the least expensive association for CO.R is c6.b  CO.R~,\(E  E4 Step 2 filter out all the exceptions that do not satisfy at least one of the query constraints C1.Rl    C12 We do not need to test the exceptions for the antecedent of the corresponding rule since they satisfy it by definition The constraint introduction solutions identified in our example are the following  Introduced Constraints Exceptions ele t El Cz.n,\(e    C12.nl2\(e el  E4 C1.h e    C5.nS e C~.R e     C12.nll e ele  E5 C1.nl e     C5.nS e C~.R e    C12.n12 e CO.Rol CO.RO2 CO.RO3 5 Optimizing OQL queries In the previous sections a series of algorithms were given to find a collection of constraint elimination or con straint introduction solutions In this section we show how the original query is transformed to its optimized form using the optimal solution. Consider the OQL query select x fromExtentX as x where C~.R and   and Cn 5.1 Heuristic H1 Let  Cil   Ci,},Ei  be the maintained con straints and the exceptions of a solution i Only the main tained constraints of the optimization solution should be tested on the objects of the whole extent however all the constraints should be tested on the exception cases and the objects that satisfy the maintained constraints but not the ones omitted should be removed from the result Hence the original query should be converted to the following one select x from Extent2 as x where Cil and   and Ci except Ei If we assume that tests on the query constraints take roughly the same time, the optimal solution is the one with fewest exceptions Ei 5.2 Heuristic H2 Let  Co.Roi Ei  be the index constraint and the corre sponding exceptions of a constraint introduction solution Instead of testing the query constraints C1.~l    C,.R on the entire extent Extent X we apply them only on the re sults of the subquery select x from Extent2 as x 40 where CO.R Since Co.Roi is a constraint on a cluster index attribute, the select operation is expected to be quite fast The original query is transformed to its more efficient form select x from 90 as x where Cl and    and C union Ei The exceptions Ei are merged to the result because they satisfy the query constraints but not the new index con straint Co.Roi Since the union operation is relatively cheap the optimal solution is the one that introduces the index con straint with the highest selectivity 6 Discussion We now look at two different scenarios and estimate the extent to which heuristics H1 and H2 speed up query exe cution The Jirst scenario concerns frequently executed queries Assume that the association rules which are used by algo rithm 3 are not modified We may optimize a query once at compilation time then execute its optimized form It is worth optimizing provided that the execution time of the optimized query is less than the execution time of the orig inal query For heuristic H1 this happens only if the time 132 


saved by omitting some constraints is greater than the time needed to remove the exceptions from the result except operation The more the eliminated constraints and the fewer the exceptions the better the optimization As one of the referees pointed out, the time saved by the elimina tion of constraints is CPU-related Since query execution is dominated by data access time this optimization is not expected to alter performance significantly It would help only in contexts rich in associations with few exceptions in which users express many constraints in their queries Heuristic H2 is expected to bring more significant ben efits Firstly, this optimization involves a union operation which is much cheaper than the except operation used in H1 Secondly instead of retrieving all the objects of an extent from the database we need only look at the subset retrieved through an indexed constraint Hence we save a considerable amount of data access time, spending a negli gible amount of CPU time in evaluating the additional con straint The second scenario concerns queries which are exe cuted only once In this case the time required for opti mization is significant. This time depends on the algorithm that finds associations between relaxed constraints and tight constraints \(see section 3 since this is the most expensive step in the optimization process This algorithm finds paths in a directed graph, and combines the exceptions associated with each edge of the path to derive the total exceptions for the path. Therefore its complexity is a function of i the av erage number of exceptions in the existing association rules and ii the number of different constraints found in the an tecedents and the consequents of the rules We have already implemented the algorithms for apply ing H1 the next step is to implement the corresponding al gorithms for H2 This should not be difficult since the main algorithm  finding associations between rule constraints  is common to the two heuristics We intend to set up an experimental model in order to evaluate H1 and H2 in the scenarios discussed above 7 Conclusion The use of association rules for query optimization is rel evant to both relational and object-oriented database sys tems There has been a lot of research on generating asso ciation rules and maintaining them in the presence of up dates Research has also focused on finding heuristics that take advantage of rules in order to optimize a query Most of this work 2 31 has considered integrity rules rather than association rules with exceptions Semantic optimiza tion heuristics were also applied without considering indi rect associations In this paper we implement algorithms that apply two optimization heuristics presented by Siegel et al taking account of both exceptions and indirect asso ciations We show how to use these heuristics to optimize an OQL query The complexity of the optimization process is closely related to the complexity of the constraint graph which represents the set of association rules in the data It also depends on the number of exceptions associated with each rule We have designed an experimental framework to evaluate the two optimization techniques both in the con text of queries repeated frequently over a period of time, and in the context of ad-hoc queries executed once only The re sults of this experimental work will be presented in a later paper 8 Acknowledgements We are grateful to the anonymous referees who read the paper carefully and critically and made many helpful suggestions Agathoniki Trigoni is supported by a scholar ship from the Greek Scholarships Foundation and is deeply obliged to the National Bank of Greece References I R Agrawal T Imielinski and A Swami Mining asso ciation rules between sets of items in large databases In Proceedings of the 1993 ACM SIGMOD Intl Conference on Management oj data pages 207-2 16 1993 2 U Chakravarthy J Grant and J Minker Logic-based ap proach to semantic query optimization ACM Transactions on Database Systems 15\(2 162-207 1990 3 J Grant, J.Gryz J Minker and L Raschid. Semantic query optimization for object databases In ICDE pages 444-453 1997 4 R Miller and Y Yang Association rules over interval data In ACM SIGMOD 1997 5 J Park An effective hash-based algorithm for mining asso ciation rules In ACM SIGMOD pages 175-186 1995 6 M Siegel E Sciore and S Salveter A method for auto matic rule derivation to support semantic query optimiza tion ACM Transactions on Database Systems 17\(4 600 December 1992 7 R Srikant and R Agrawal Mining quantitative association rules in large relational tables In ACM SIGMOD Intl Con ference on Management ojdata pages 1-12 1996 8 D Tsur J Ullman S Abiteboul C Clifton R Motwani S Nestorov and A Rosenthal Query flocks a general ization of association-rule mining In ACM SIGMOD Intl Conference on Management of data pages 1-12 1998 Intelligent query answering in deductive and object-oriented databases In Fourth ACM Intl Conference on Information and Knowledge Management pages 244 251 1994 IO S Yoon 1 Song and E Park Semantic query processing in object-oriented databases using deductive approach In Intl Conference on information and knowledge management pages 150-157 1995 9 S Yoon 133 



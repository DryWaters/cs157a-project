Semi-Supervised Probabilistics Approach for  Normalising Informal Short Text Messages  Abiodun Modupe and Turgay Celik School of Computer Science and Applied Mathematics  University of the Witwatersrand Johannesburg, South Africa Email: abiodun.modupe1@students.wits.ac.za  turgay.celik@wits.ac.za Vukosi Marivate and Melvin Diale Council for Scientific and Industrial Research \(CSIR  Modelling and Digital Science Pretoria, South Africa Email  vmarivate,mdiale  csir.co.za    Abstract The growing use of informal social text messages on  Twitter is  one of  the known sources of  big data These type of  messages are noisy and frequently rife with acronyms slangs  grammatical errors and non-standard words causing grief for  natural language processing \(NLP\ techniques In this study, our  contribution is  to  target non-standard words in  the short text  and propose a method  to  which  the  given  word  is  likely to  be  transformed Our method uses language model probability  to  characterise the relationship between formal and Informal word then employ the string similarity with a log-linear model  to includes features for both word-level transformation and local  context similarity The weights of these features are trained  by  employing maximum likelihood framework using stochastic  gradient descent SGD to  hypothesise the better clean feature  for a given informal short text Experiments were conducted on  a publicly available Enlish-language tweet and the approach is  able to  normalise inflected words in  an online social network  Index Terms Informal Short Text Messages User-generated  Context\(UGC\Social Media Text, Natural Language Processing  Stochastic gradient descent \(SGD\ Online Social Network   I  I NTRODUCTION The appearance of  online communities provide an  oppor tunity for people to interact and share mutual communication  that goes beyond geographical boundaries One of  the most  active online communities is  Twitter 1  According to  recent  statistics about 200  million tweet was posted per day com pared to  65  million  in  the  previous  year  and  the  number  is  still  growing  [1    T h e  len g th   o f   a tweet  cannot  exceed 140  characters but when usernames or  URLs are part of  posted text  the overall average length of  characters goes  beyond 140 characters. Messages from Twitter have shown to  have utility in  many applications like sentiment analysis 2   emergency assistance 3   an d  e v en t  d is co v e r y   4    H o w e v e r   the quality of messages varies significantly, ranging from high quality traditional newswire-like text to  meaningless writing  styles These messages contained informal information 2 such  as typos, acronyms, misspelling errors, and emoticons - which  degrade the performance of natural language processing \(NLP  tools 5    6     7    To  reduce this impact efforts have been  made  by  researcher  to  adopt  machine  learning  \(ML\  and  1 http://internetlivestats.com/twitter statistics  2 short text that has no meaning Outof Vocabulary  information retrieval IR to  transform the textual content in  social media text to canonical standard form [8    9     1 0     1 1    12    1 3    H o w e v e r   d u e  to little available training data, rapid  language changes and high-dimensional feature space  it  is  very difficult to  make sense of  the conversational messages  posted to  online social media 14    1 5     1 6    P er h ap s   t h e  most successful systems are pipeline architecture that em  ploys statistical language models with Levenshtein distance  to  generate handcraft feature engineering to  spellcheck and  normalises rare words in  social media text 17    1 8     7    19   T h e  ex t r a cte d  f ea tu r es  ar e  in ef f i c i en t  a n d  ti m e co n s u m i n g  in  formalising new features for every task or  identify the  canonical form of  the inflected word in  the text However a  natural question to  ask is  how to  normalise set of  informal  short text embedded in  messages posted to  online social  media This study demonstrates a different method that use local  context  to  compute  similarity  metrics  between  string can  didates and the language model which arguably allow rich  representations for the observed sequence to  estimate target  based  on  the  previous  distribution We use  minimum  edit  distance  and a language  model  to  estimate  weight  vector  e.g., features\ during training It  is a lightweight probabilistic  method that relies on  a language model and calculates the  similarity between target domain and homogeneity within a  given dataset Then we  train the model towards a desirable  function in a maximum-likelihood, employing Stochastic Gra dient Descent \(SGD\ algorithms [20  f o r  p ar am eter  est i m a ti o n  to recompose noisy texts. This will help to normalise inflected  words and identify classes of orthographic transformation that  form coherent linguistic styles and improve communication  patterns of a  social context about her social behaviour  The remaining part of this article is succinctly summarised as  follows In a concise manner Section 2 describe previous  work related to online social media text. Section 3 introduces  our  methodology to normalise  the  task  to  generate  target  language sentence  for  informal short  text  in  the conversa tional  messages  posted  to  online  social  media.  Details on  how the model was implementation with the testing dataset  are discussed in  section 4  Finally the performance of  the  proposed model conclusion and motivation for future work  2017 Conference on Information Communications Technology and Society  978-1-4673-8996-9/17/$31.00 ©2017 IEEE 


n  n           t  n    were reported in section 5 and 6 respectively   II  R ELATED W ORK  The text is  a dominant form communication in    hyper connected world which is  used to  unfold our mature  social behaviour It  is  the means by  which user create short  messages posted on  online social media per second so  as  to  share and reach a mutual understanding. [7  p r o p o s ed  m et h o d s  that focussed on  normalising single token between input and  output language sentence but excluded multi-word token lol    out   25  u s e  n o is y  c h a n n el  m o d el   N C M   while 26  m ac h in e  tr an s lati o n   MT   f o r  s p elli n g  co r r ec tio n  based on  annotated dataset The work  finds  target  words  that fit the context with translation models favouring words  that are similar to  the input language sentence\. The method III  M ETHODOLOGY In  this section we  present a discriminative proposition to  transform sets of  input language sentence S in  a collection  of  document D into its desirable output T  This enables us  to  effectively rewrite part of  the arbitrary features in  UGC  e.g., tweets by leveraging on the flexibility of log-likelihood  model to  calculate the weight feature in  predicting the target  language given the input language sentence  A  Model  The finite set of  possible language sentences in  D is  given as  S   s 1 s 2  267 \267 \267  e.g., tweets\ and target language  T   t 1 t 2  267 \267 \267  standard English We  denote the vocab ularies of  possible source and target language as  V D and  V T respectively. Thus we express the conditional probability  P  t  s   which is used to estimate input-source and target  language sentence as follows  used in  this study alike to  a noisy system but unlike prior  work,  no  labelled  data  is  needed.  [23   an d    2 4    p r o p o s ed  P t  s    exp  T f  s  t  1 normalisation techniques that improve parsing and machine  translation respectively 29  m an u all y  id en ti f y  s e v e r a l  ir r eg u la r s  in  social media  text using the supervised noisy channel. Each feature vector is  parametrised with a scalar value so that all legal information in  the are uniformly fit. Then we estimated the scalar parameters  using expectation maximisation \(EM\. The approach achieved  an  excellent result from among the others 30  ad d r ess  th e  use of string edit distance to distinguish and estimate closely related candidate orthographic forms and then decode the  meaning of the input messages using a language model, while  31  m i n e      as a strong word feature to  extract interesting information in the text 17  ex t r a ct  n o is y  f ea tu r e  p air s  u s i n g  s ea r c h  s n ip p ets de  signed in Google, then trained with discriminative undirected  probabilistic model 32  to  estimate P  t  s   which is  the  character-based translation model The work was further ex  tended by adding a feature that allows visual priming an  of fline spell-checker on  local context 33    2 4   ca p tu r e  te x t  semantic meaning incorporate with edit distance using random  walk architecture. The majority of these techniques are devel oped with the aspiration of  annotation data and no  available  data to train unstructured social media text and therefore they  are unsuccessful in  learning feature weights based on  a log likelihood framework. Although, the normalisation techniques  were criticised in 22   w h o  cl ai m s  th a t  it strips away important  social connection with respect to the conversational messages The first step is  to find a target language sentence t based on  the input source language sentence s that maximises prob ability P  t  s   P  s  t  P  t   n N P  s n  t n  P  t n  t n 1   In  order to  find the best possible correct lexical representation  we cannot employ the usual dynamic programming algorithm  because the quadratic cost in  the size of  the target language vocabulary multiple by  the cost of computing the normalised  probability value P  t n  s n   resulting in  a prohibitive time  complexity of  O   V T  V S  2 N   So we consider two approach in finding the target sentence as  shown in  Algorithm 1  The first is  to  simply apply the  proposal distribution with linear complexity in the size of the  two vocabularies However this Algorithm is  not identical to  P  t  s  because of the denominator factor of  Z  t  in Equation 3  We  apply the proposal distribution for selecting the best target word then apply similarity measure only within the  two string. The total cost is  O   V S  T 2 N  where T is define  as the number of target word sentences we consider; this will  asymptotically approach P  t  s  as  T  V T   We  make a Markov assumption so  that the probabilistic mapping between the input source and output target lan guage P  t  s  decomposes across the elements of the sentence P  t  s  n N P  t n  s n  This means that the feature functions  f  s  t  must be  decompose on  each   s n t n  pair Specifically  we then rewrite log-linear model in Equation 1 as   N exp T f s n t n   posted to  online  social media.  However in  this  study we  adopt the same normalisation principles in  34  to  generate P  t  s    n    n 1  Z t n   2 a feature represenation for textual content in social media text  by  aligning the weight features with minimum edit distance  and language model. The weight vector is navigated with the Z t n        exp   T  f   s  t n  s    3  alignment value using the log-linear model with maximum likelihood calculation on  the dataset which is  used to  enu In summary, the combination of Equation \(2\ and \(3 N exp T f s t  merate and rewrite fragments of social text to desirable target language   n    n    P  t s     exp T f s  t    n 1  4 n  


s    t  j 1  j  2  k  k  2     where the f  s  t  is the weight feature associated with each  arbitrary sequence of  words from input and output language as     n n      j j  j  sentence  s n t n   In general, the weight feature in Equation 4 can  be any real numbers and to improve generation ef ficienc y  k    j 1  f k  s t   j 1  t T  P t  s    10 we assume that all the weights are non-positive  B  Training of Model  Given a training  set  that  consists  of N  instances T  327 f k  s j  t j    k  C  Optimisation Method  Stochastic gradient descent SGD is  applied as  an  opti  j j N  j 1  where s j and t j are the source and target language  misation technique to approximate the gradient \(e.g., weights sentence respectively we consider employing maximum like lihood to estimation learn the log linear model in Equation 4  We express the likelihood on the basis of the conditional prob feature vector of the objective function given in Equation 9  The SGD use approximate gradients estimate from subsets  of  the training data and updates the weights of  the features ability of output target given input sentences n N  P  t j  s j   dynamically In contrast to Sequential Monte Carlo \(SMC as  that marginalised over all possible transformations as  N  P  t j  s j  P t j  s j  j  5  j 1   Therefore, the log likelihood function becomes N  L   log P t j  s j  j  6  j 1  The goal is  to find the optimal parameters  of the log linear  model by solving the following optimisation problem a training algorithm [34  th at  u s e s  th e  p r o b ab ilit y  d is tr ib u t i o n  to  estimate weights of  all features randomly from subsets of  the training social media data However exploiting SGD to  find local optima and normalised large label space is difficult  because the objective function in  Eq.9 are not uni-model  distributed So obtaining minimum parameter values by  em  ploying probability distribution to normalise the dimension of  the feature space will slow down the weight updating process  and weights of  the features will moved away from zero  Instead we  used SGD approximates the gradient iteratively  for each training samples by taking replicated steps until local  minimum  is attained as follows   arg max L      7   k 1  k  k      L  j      2   2 j   11  arg max      log P t j  s j    where k is  the iteration counter and  is  the learning rate  k  j which is designed to decrease as the iteration process proceeds  where  denotes the weight parameter Our resolution is  to modify the objective function in Equa tion 6 to  include the regularisation term  which prevents  optimised parameter from becoming too large and in  par One straightforward solution to update weight of  each features  j and solve the problem arising from 2 order regularisation term to consider a sub-gradient at zero and use the following  update equation ticular prevents parameters values from diverging to infinity A common regularisation term is the 2 norm of the parameter  k 1  k  k  L  j   k sign  k  12 values, that is j j  j  2 j  l l   2 8  j  where sign x  1  if x  0   sign x  1  if x  0   and  sign x 0 if  x 0 as discussed in 3   The actual learning rate scheduling methods has a signifi where l l is simply t he length or Euclidean norm of a weight  vector  i.e l l   k 2  The modified objective function  is  n  cant relationship on  the convergence speed in  training SGD  Our typical choice of  learning rate scheduling described in  36  an d  im p le m en ted  in this study 1 L   log P t j  s j   l l  j 1   9  k      k 0  k  13   L  j     2  2 k  k  where  0 is  the relative weights of  the two terms used  in  Equation 8 chosen to  validate the model This allows  equilibrium on  the regularisation of  a term during training  data while the primary term defined the likelihood of  the  training sample to  measures the fitness of   parameter and  the secondary term measure the penalty function Thus the  partial derivative with respect to  parameter k is  calculated where  can either be a constant or decay gradually The configuration process of the SGD based on the learning  rate is  coded using python-library 37   T h u s   t h e  lar g er  t h e  random sampling from the training set then the slower SMC  will attain local minimum and the longer it takes to converge D  Similarity Measure  We  define t e  D e  where D e is  a dictionary of  possible  correct words and s i of  the  source  language  in  tweets  The similarity alignment  t e s i   between input and output 


length  t e    language sentence as   t e s i      LCSRatio t e s i   EditDistance t e s i      14  V  N ORMALISATION Not all the informal short texts extracted from Twitter re  quire normalisation. However, the question on how to ascertain  which words to  normalise continues to  be  an  open research  question Following 7   we  develop a words dictionary that where LCSRatio  t e s i  length  LCS  t e s i   and LCS  t e s i  is  the Longest common subsequence between t e and s i  The Longest Common Subsequence Ratio LCSRatio 38  of two string \(e.g input and output language sentence is  the ratio length of  their LCS and the length of  the longer  string Because the corresponding dictionary term in  social  media text will always be longer than the non-standard token  the denominator of  LCSR is  calculated as  the length of  the  dictionary term Consonant skeletons in 25  u s ed  ed it  d is tan ce  b ased  on the  canonical definition and the informal word token in the source  language sentence So the Levenshtein distance between the  consonant skeletons is small then  t e s i will be high. How ever the intuition behind using EditDistance is  an  example  through the following example. Consider a nonstandard word    catch the correct form   The canonical  definition using method in  25  g i v e    and   as  LCSRatio as  0  5 with respect to    while with respect    as  1 less than   2 with respect to    In  conclusion the similarity measure of  two inflected words  corresponding to the target value is higher compared to    and  respectively  E  Features  We employ word-level transformations and string similarity  using Levenshtein Levenshtein distance to  find the best rep resentation for the given input as  described in  Algorithm 1  Primary we  measure the upper bound characters in the input  source and output sentence to  capture the lexical alignment e.g luv   We  only consider word-level transformation  features that occurred during training Secondly we  measure  the detected features similarity using the method in  30  to  determine target represenation that is likely closer to the input  text We use this similarity to create binary features that could  indicate whether words in  an  input source sentence can be  mapped to  correct lexical sentence We  used the output as  a  feature to find relationship between the target t and the given input s  so  that posterior probability P  t  s  as  described in  Section III A can be compute easily includes targets language to  normalise OOV 3 words and no  attempt is made to normalise source strings that are equivalent  or  match any word in  the observed sentence As  with other  comparable approaches, our method was able to normalise rife  words like   into   you   The set of  IV 4 words  containing 336 words as  discussed in  39  an d  w i th  GNU  Aspell dictionary 5 that contain 97  070  words was used. From  this dictionary we  follow the approach described in  33  to  remove all words that have minimum significant meaning \(e.g  words with the countless than 20  occurrences are excluded  All single tokens in  the tweets like slang abbreviation are  treated as IV, except a  i rt, #brunette, #ootd, #blonde associated  with the tweets are deleted This is  the effectiveness of  the  model from attempting to  normalise the inflected word in  a  given social media text A  Language Modeling  We use language modelling as  an alternative to estimate fea tures similarity in a social media text based on the perplexity  and trained over the sequence in the datasets as illustrated in  Algorithm 1  We create open-vocabulary LMs with annotated  dataset from the Edinburgh Twitter 40  an d  L ex No r m  1  1  19   T h er ef o r e  f o r  each corpus, the ngram models is trained  on  each target word in the sample corpus dataset. Hereafter we  calculate perplexity based on the held-out of the sample from  the sub-dataset to  find textual meaning The resulting output  is  employed to  generate features representation as  illustrated  in Algorithm 1 when computing the weighted function in the  log-linear model B  Parameters  SGD require two parameters the number of  samples s  represented as features and the nested expected target denoted  as  t as  defined in  Eq 11  So we  obtain equal quality  improvement as  the  number  of  iteration  units  increase at  k  10000 and L  2 as  regularisation terms and find little  relative improvement with parameters VI  E VALUATION R ESULTS A  Datasets  For this study, we required only tweets containing short text 6  IV  I MPLEMENTATION D ETAILS AND D ATA messages We  used the Twitter streaming API and used the  The methodology in this paper was implemented in Jupyter  notebook environment running Python 2.7  for  characteris ing and identifying the chain of  orthographic in  social me  dia text that corresponds map to  target values using semi supervised statistical approach The system has the capacity  to  process the roughly large amount of  informal short texts  per hour and the implementation details are available at  https://github.com/dupsy/emnlp2016.git  most popular topic trend include news \(e.g., #PanamaPapers entertainment e.g SonyHack computer e.g datasecu rity and politics e.g NorthKorea china russian re alDonaldTrump whitehouse to  collect tweet The rate of  tweets that can be  collected with Twitter Streaming API is   3 Outof vocabulary  4 In vocabulary 5 http://aspell.net 6 https://dev.twitter.com/streaming/public 


   Algorithm 1  Pseudo-code for feature representation T k  T  where t k denotes a single observed input source  language consisting of a sequential token s 1 s 2  267 \267 \267 s m  and  m   T k   U j  U  is the unigram from t k  B j  B  is the bigram representation generated from T k  input    For A   a 1 a 2  267 \267 267 a n  represents the set of observed sequences such as slang abbreviation and others in the input string t   t 1 t 2  267 \267 \267 t n  is the comparable target value [39  output f B s i s i 1  denote frequence w i w i 1  arises in  B which is denoted as a bigram, while f u s i  calculates the occurences of  s i  T known as a  unigram the value of  s i   foreach sequential element a i in  t k  do    is normalised to somehow but following the IV  words  in  39  an d  s lan g  an n o tati o n s 9 assert the standard form as  shake my head and this the evident from input tweet sentence  example like    The Figure.1a demonstrates the ability  of our approach to obtain noisy features and find appropriate  interpretation that could used to make sense of the communi cation process on the Internet through feature weights Our strategy comes from the flexibility of modelling infor mal short text messages aligning it  to  real word-level based  on  features representation to  derive the lexical similarity in  context to train the parameteristic weight function without the  used of  annotated data The quadratic complexity of  large  space dataset for normalisation task with dynamic program ming was overcome using SGD B  Metrics  Earlier work has proposed normalisation techniques for  identifying  informal  messages  by  focusing  on  finding  the f 1  P s i  s i 1   f B  s i s i 1   s i  a i   correct linguistic styles that map an input tweets sentence [19    f 2    LCSRatio a i t i    f u  s i     19  u s in g  a  m ac h in e  lear n in g  m e tr ic  s u c h  as precision, recall  and F-score. Recall determined the number of noisy features in   EditDistance UGC a i t i    feature vector   f 1 f 2  end      limited per hour. The tweets are retrieved as  a JSON format  which is  very simple and easy to  be  parsed as  each  line of  this format represents an  object 41   H o w e v e r   th e  r et u r n ed  tweet by  the Streaming API contains many attributes of  the  tweets such as  text URLs hash-tags and associated Twitter  structure 7  In total we collected about 650 Megabytes of tweets  from 22 nd  of  February 2016  to  26 th  February 2016  while  we  restricted the collection with tweets containing 22  210  arbitrary textual content and after removing redundancy \(e.g  unnecessary information\. Furthermore, public Streaming API  provides access to  1  of  all public tweets but  access to  the  tweets sent by  protected account are not part of  the sample  The meaning of the arbitrary features of  words in the dataset  is  not available so  we  use the language model jointly with  similarity measure as  discussed in  Section V-A to  generate  the corresponding target In  addition Twitter datasets are not permitted to  be  dis tributed publicly without prior approval 8  In order to evaluate  our approach we  create our  own Twitter content via the  Streaming search API to ensure we  play by the rules. There fore testing the performance of  the proposed approach with  other research studies will be  unrealistic objective because  there is  no  openly accessible corpus In  close analysis with  LMML 11  and LexNorm 1  1 datasets [17    4 2   r ev ea le d  s o m e  inconsistencies in  annotation or  interpreting the text in  the  input sentence for example smh and 2 are normalised to    or    but the words are left unnormalised while 7 http://support.gnip.com/sources/twitter/data format.html 8 https://twittercommunity.com/t/twitter-and-open-datain academia/51934 the social text that is formalised correctly; precision establishes quantity which is correct and f-score is the statistical average  of precision \(P\ and recall \(R C  Result  To  infer knowledge and address the presented difficulties  of making meaning with online social media text through  discriminative learning. Firstly we conduct an analysis dispo sition of noisy features with our tweets dataset. Predominantly  we calibrate the distribution of  noisy features per UGC e.g  tweet message\  and plot  the proportion  at  which they  oc  curred for the entire dataset In a uniform distribution, around  12  5  of tweets have 50  or more noisy features presented  in  Figure.1a We  further analysed the informal text in  our  datatset e.g Twitter and randomly selected 414 of  the text  and analysed the category the inflected word to determine the  phenomena that our normalisation system needs to deal with  We identified 20 token instances of rare words in tweets and  broke them down into to  as  to  understand the occurrence of  noise word in the dataset as listed in Table I  TABLE I Assessment of Noisy Features  Category  Ratio  Abbreviation  48  6  Slang  26  3  Letters    Numbers  10  38  Letter  5  36  Others  10  34     and   are cited as  artifacts that par ticipating individuals create in  sharing opinion on  the Inter net e.g swin to    what i   or  lol to    out    as  described in  39     and   it  refers  to  instances  where  one  or  two  letter  are  missing/extra or   9 http://www.internetslang.com/trending.asp 


  a  Distribution of Noisy Features b\ Visualising Features Vectors Fig 1 Noisy Features distribution in English Twitter dataset   misspelled letters  or  number  exchange  e.g luv to   or  2mor to    however the corresponding target  language can  be  found easily from Algorithm 1 discussed  in  Section III A    is  the remainder of  the instances  which predominately occupy space between the features and  need to  be  deleted e.g thenewcastlesun to    new castle    This heuristic discovery help CFI as  a strategy to  predict and recognise the  behaviour with respect to their  communication pattern D  Visualising the Training Feature Vectors  We  explore the likelihood of  viusalising any given input  tweets s i formalised to  the canonical form w i as  described  in  Eq.1 This help to  observe the input tweets s clusters and  pairs target t clusters association up  hierarchically based on  the weight parameters f  t n  s n  as  discussed in  Eq.4 The  unambiguous distribution of  words in  the feature representa tion based on  counting frequencies of  occurrences of  noisy  symbol sequences used in the training is shown in Figure.1b The plot in Figure 1b  is the multiple pairwise of the features  vector pattern in  the dataset that has the most weight which  is  employed to  learn a representation to  transform each rife  word in tweets into the desired enumerated target E  SGD Performance  We  evaluate the effectiveness of  our feature vectors with  the log-linear model using an  SGD algorithm on  the Twitter  dataset The feature vectors used in  this experiment were  based on  bigram and edit-distance measurement that outline  the arbitrary symbols to their clean grammatical meaning To  eschew some superiority to SGD algorithms over the regular isation terms of  the precision in  estimating the  parameter  the L 2 norm describes in  Eq.8 was used when controlling  the regularisation strength on   to  estimate  parameter We  use the exponentially decreasing learning rate as  described  in  Eq.12 by  starting   0  5 and 0  1  0  where k is  the  iteration counter. Experiments were conducted until 100  000  training instances were observed before attaining convergence  with the final learning rate In Figure 2  we show the evaluation  metrics To recompose given noisy features in a given tweets  we utilised the feature vector as described earlier to construct a  confusion matrix so  as  to test the effectiveness of our Twitter  dataset The bigger iteration values give better precision but  decrease the recall as  shown in  Figure 2a  and 2b.  While  Figure 2c describes that a small amount of regularisation  significantly has no  influence on  the   performance  although SGD training took about 145  seconds on  Intel  Core i7 2630QM processor to  train the richer feature vector  in  the log-linear model Generally as  the iteration number  increases, the precision score improves while recall decreases  significantly. Thus we achieve 37  5  for f-score 42  3  for  precision and 38  10  for recall for nomalising rife words for  a given tweet documents VII  C ONCLUSION AND F UTURE W ORK In  this paper  we  introduce  a semi-supervised analytical  approach for normalising arbitrary features embedded in  the  social text. This improves the quality of messages retrieved and  provides better insight to make sense of online communication  processes with respect   behaviour The competence of  our proposition comes from adopting minimum similarity  measures and a language model to develop features representa tion, then exploit the contextual features to train the equivalent  feature weights of unknown datasets such as Twitter. However  the technique issues with the large dataset were overcome with  stochastic gradient descent SGD that ef ficiently trains L 2  regularised log-linear models. Future work may consider using  deep learning architecture as  a recurrent neural network ap  proach for formalising and recomposing rife words \(e.g non  standard language\ social media text We intend to investigate  the adaptations of  the deep learning with a self-supervised  dictionary if  it can formalise representation to normalise and  mimic understanding with near-human accuracy the textual  content posted to online social media per seconds R EFERENCES 1  O  J Dyar E Castro-Sa\264nchez, and A  H Holmes   ma k es people  talk about antibiotics on social media? a retrospective analysis of twitter    Journal of Antimicrobial Chemotherapy  p dku165, 2014 2  S  Kiritchenko X  Zhu and S  M  Mohammad   analysis of  short informal  Journal of Artificial Intelligence Research vol. 50 


  a  Precision b\ Recall c\ F-score Output for Noisy Features Fig 2 Effect of regularisation term on the F-score and Precision-Recall for Noisy Features   pp. 723 762, 2014 3  S Karimi J Yin, and C Paris  microblogs for  in  Proceedings of the 18th Australasian Document Computing Symposium   ACM, 2013, pp 26 33 4  X Dong D Mavroeidis F Calabrese, and P Frossard  event  detection in  social   Data Mining and Knowledge Discovery   vol. 29, no 5 pp. 1374 1405, 2015 5  N Okazaki Y Tsuruoka S Ananiadou, and J Tsujii discriminative  candidate generator for string   in  Proceedings of  the  Conference on  Empirical Methods in  Natural Language Processing   Association for Computational Linguistics, 2008, pp. 447 456 6  A  Ritter C  Cherry and B  Dolan   modeling of  twitter    in  Human Language Technologies The 2010 Annual  Conference of  the North American Chapter of  the Association for  Computational Linguistics  Association for Computational Linguistics  2010, pp 172 180 7  B  Han and T  Baldwin   normalisation of  short text messages  Makn sens a  in Proceedings  of  the  49th  Annual  Meeting  of  the Association for Computational Linguistics Human Language  Technologies-Volume 1  Association for Computational Linguistics  2011, pp 368 378 8   K Gimpel N Schneider B    D Das D Mills J Eisenstein M  Heilman D  Yogatama J  Flanigan  and N  A.  Smith  of  speech tagging for twitter Annotation features and   in  Proceedings of the 49th Annual Meeting of the Association for Computa tional Linguistics: Human Language Technologies: short papers-Volume  2  Association for Computational Linguistics, 2011, pp 42 47 9   J  Foster O  Cetinoglu J  Wagner J  Le  Roux S  Hogan J  Nivre D  Hogan and J  van Genabith   tagging and parsing the twitter   in  Proceedings of  the AAAI Workshop on  Analyzing Microtext   2011 10  X Liu S Zhang F Wei, and M Zhou  named entities in    in  Proceedings of  the 49th Annual Meeting of  the Association  for Computational Linguistics: Human Language Technologies-Volume  1  Association for Computational Linguistics, 2011, pp. 359 367  11   A  Ritter S  Clark O  Etzioni et  al    entity recognition in  tweets an  experimental   in  Proceedings of  the Conference on  Empirical Methods in  Natural Language Processing  Association for  Computational Linguistics, 2011, pp. 1524 1534 12  O Owoputi B    C Dyer K Gimpel N Schneider, and N  A  Smith  partof speech tagging for online conversational text  with word   Association for Computational Linguistics, 2013 13  L  Derczynski A  Ritter S  Clark and K  Bontcheva   partof  speech tagging for all: Overcoming sparse and noisy   in  RANLP   2013, pp 198 206 14   R    S p r o a t    A    W  Black S Chen S Kumar M Ostendorf   and C Richards   of non-standard   Computer Speech  Language vol. 15, no 3 pp. 287 333, 2001 15  Z Liu X Chen Y Zheng, and M Sun  keyphrase extraction  by bridging vocabulary   in  Proceedings of the Fifteenth Conference  on  Computational Natural Language Learning  Association for Com putational Linguistics, 2011, pp. 135 144 16   K Xu Y Xia, and C H Lee  normalization with  pp 920 928, 2015 17  F  Liu F  Weng B  Wang and Y  Liu   deletion or  substitu tion?: normalizing text messages without pre-categorization nor super   in  Proceedings of  the 49th Annual Meeting of  the Association  for Computational Linguistics Human Language Technologies short  papers-Volume 2  Association for Computational Linguistics 2011  pp 71 76 18  B  Han P  Cook and T  Baldwin   constructing a nor malisation dictionary for   in  Proceedings of the 2012 joint  conference on  empirical methods in  natural language processing and  computational natural language learning  Association for Computa tional Linguistics, 2012, pp 421 432 19     normalization for social media   ACM Transactions  on Intelligent Systems and Technology \(TIST vol 4 no 1  p  5 2013 20  L  Bottou   gradient descent   in  Neural Networks  Tricks of the Trade    Springer, 2012, pp. 421 436 21  M Choudhury R Saraf V Jain A Mukherjee S Sarkar, and A Basu    and modeling of  the structure of  texting   International Journal of  Document Analysis and  Recognition IJDAR   vol. 10, no. 34 pp. 157 174, 2007 22  J Eisenstein   to  do about bad language on the   in  HLT NAACL 2013, pp. 359 369 23  C   Z h a n g   T Baldwin H Ho, B. Kimelfeld, and Y Li  parser centric text   in  ACL \(1 2013, pp. 1159 1168 24  H Hassan and A Menezes  text normalization using contextual  graph random   in  ACL \(1 2013, pp. 1577 1586 25  E Prochasson C Viard-Gaudin,  and  E Morin  models  for handwritten short message   in  Document Analysis  and  Recognition 2007 ICDAR 2007 Ninth International Conference on   vol. 1 IEEE, 2007, pp 83 87 26  A  Aw M  Zhang J  Xiao and J  Su    phrase-based  statistical  model for sms text   in  Proceedings of the COLING/ACL  on  Main conference poster sessions  Association for Computational  Linguistics, 2006, pp 33 40 27  C  Kobus F  Yvon and G  Damnati   sms  are two  metaphors better than   in  Proceedings of  the 22nd International  Conference on  Computational Linguistics-Volume 1  Association for  Computational Linguistics, 2008, pp. 441 448 28  R  Beaufort S  Roekhaut L A  Cougnon and C  Fairon  hybrid  rule/model-based finite-state framework for normalizing sms    in  Proceedings of  the 48th Annual Meeting of  the Association for  Computational Linguistics  Association for Computational Linguistics  2010, pp 770 779 29  P  Cook and S  Stevenson    unsupervised  model  for  text  mes sage   in  Proceedings of the workshop on computational  approaches to  linguistic creativity  Association  for Computational  Linguistics, 2009, pp 71 78 30  D  Contractor T  A  Faruquie and L  V  Subramaniam   cleansing of  noisy   in  Proceedings of  the 23rd International  Conference on  Computational Linguistics Posters  Association for  Computational Linguistics, 2010, pp. 189 196 31  S  Gouws D  Hovy and D  Metzler   mining of  lexical  variants from noisy   in  Proceedings of the First workshop on Unsu pervised Learning in  NLP  Association for Computational Linguistics  2011, pp 82 90 32  J  Lafferty A  McCallum and F  Pereira   random fields  Probabilistic models for segmenting and labeling sequence   in  Proceedings of  the eighteenth international conference on  machine  learning, ICML vol 1 2001, pp. 282 289 


33  F Liu F Weng, and X Jiang broad-coverage normalization system  for social media   in  Proceedings of the 50th Annual Meeting  of the Association for Computational Linguistics: Long Papers-Volume  1  Association for Computational Linguistics, 2012, pp. 1035 1044  34   Y  Yang and J  Eisenstein  log-linear model for unsupervised text   in  EMNLP 2013, pp 61 72 35  Y  Tsuruoka J  Tsujii and S  Ananiadou   gradient descent  training for l1 regularized log-linear models with cumulative   in  Proceedings of  the Joint Conference of  the 47th Annual Meeting  of  the ACL and  the 4th International Joint Conference on  Natural  Language Processing of  the AFNLP Volume 1-Volume 1  Association  for Computational Linguistics, 2009, pp. 477 485 36  A  Bordes L  Bottou and P  Gallinari  qn Careful quasi-newton  stochastic gradient   The Journal of Machine Learning Research   vol. 10, pp. 1737 1754, 2009 37   I  J Goodfellow D Warde-Farley P Lamblin V Dumoulin M Mirza R Pascanu J Bergstra F Bastien, and Y Bengio  machine  learning research   arXiv preprint arXiv:1308.4214 2013 38  L  Bergroth H  Hakonen and T  Raita  survey of  longest com mon subsequence   in  String Processing and Information  Retrieval 2000 SPIRE 2000 Proceedings Seventh International Sym posium on  IEEE, 2000, pp 39 48 39   H  B  Dixon Jr   tweeting and other internet   Judges J vol. 50 p 30, 2011 40  S  Petrovic M  Osborne and V  Lavrenko   edinburgh twitter    in  Proceedings of the NAACL HLT 2010 Workshop on Compu tational Linguistics in a World of Social Media 2010, pp 25 26  41  A  Bifet and E  Frank   knowledge discovery in  twitter  streaming   in  International Conference on  Discovery Science   Springer, 2010, pp. 1 15 42  T Baldwin P Cook M Lui A MacKinlay, and L Wang  noisy  social media text, how diffrnt social media   in  IJCNLP 2013  pp. 356 364 


         


                                                        


2168-6750 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TETC.2017.2703784, IEE\E Transactions on Emerging Topics in Computing   en-US    8   en-US 4    r l   Em s  1   en-US 5   s 3  8   en-US 6  D       62   en-US 7  Y       o  1   en-US 8         0   en-US 9          2   en-US 0  a  to     s   en-US 1   t       2   en-US 2      o 3 7   en-US 3     L  9   en-US 4    f r l     9   en-US 5  v    1   en-US 6  A    r   1   en-US 7     w  r    1   en-US 8        2   en-US 9     s  7   en-US 0        2   en-US 1    i     1   en-US 2     t     7   en-US 3      7   en-US 4        7   en-US 5     rs  9    en-US 6        s  1   en-US 7      o    5   en-US 8      s   3 3   en-US 9  G     3   en-US 0  G      s   17   en-US 1  El  4   en-US 2    i     6   en-US 3   n i   o    6   en-US 4    o g  A ES   o   5    en-US 5    s    4   en-US 6      o r      en-US 7   i  o    8 2   en-US 8     g   en-US 9   n   h     0    en-US 0      e s   s   en-US 1   g    s  0    en-US 2  d  t  3   en-US 3    k   r    8   en-US 4  T   B   r s   7   en-US  en-US  


2168-6750 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TETC.2017.2703784, IEE\E Transactions on Emerging Topics in Computing   en-US  en-US i ng      n       r  io s   n  ch   en-US  en-US  en-US  en-US i     T  io       en-US  en-US  en-US  en-US Cui  D        H   ics  en-US  en-US  en-US  en-US in     He   e  e t ical   en-US  en-US  en-US  en-US injun Chen   m        i    IEEE  en-US  en-US  en-US  en-US  en-US  en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   13     en-US n en-US  en-US 1 en-US en-US nen-US rther en-US  en-US 5 en-US  en-US  en-US i en-US en-US en-US ch en-US  en-US  en-US 4.3.1  en-US es en-US  en-US ed en-US ion en-US r en-US non en-US en-US t en-US  en-US is en-US  en-US e en-US y en-US  en-US  en-US  en-US  en-US nd en-US  en-US  en-US  en-US ed en-US  en-US logic en-US en-US ed en-US ion en-US  en-US n en-US non en-US en-US i en-US en-US a en-US y en-US em en-US en-US  en-US h en-US  en-US o en-US ion en-US  en-US en-US width en-US iciency en-US 2 en-US oben-US nonlinea en-US ren-US o en-US  en-US i en-US en-US  en-US ion en-US  en-US  en-US  en-US  en-US 4.4  en-US  en-US ing en-US  en-US  en-US  en-US ion en-US  en-US  en-US D en-US ion en-US  en-US  en-US in en-US  en-US en-US s en-US  en-US  en-US n en-US 3 en-US he en-US en-US  en-US  en-US g en-US een-US  en-US u en-US high en-US en-US rity en-US reen-US cking en-US en-US ion en-US  en-US i en-US en-US  en-US y en-US  en-US ck en-US en-US to en-US en-US  en-US  en-US  en-US en-US e en-US h en-US en-US  en-US  en-US en-US  en-US 4 en-US in en-US  en-US 5 en-US  en-US  en-US llo en-US  en-US ck en-US ion en-US  en-US  en-US oben-US  en-US t en-US en-US e en-US en-US he en-US  en-US c en-US er en-US  en-US 6 en-US  en-US he en-US i en-US en-US en-US  en-US i en-US on en-US  en-US  en-US e en-US en-US en-US highly en-US d en-US  en-US 7 en-US  en-US  en-US ion en-US  en-US  en-US o en-US en-US  en-US ion en-US  en-US  en-US en-US  en-US e en-US  en-US e en-US  en-US  en-US l en-US cen-US re en-US en-US  en-US  en-US er en-US en-US ed en-US ion en-US  en-US  en-US t en-US  en-US  en-US y en-US  en-US ed en-US ion en-US  en-US n en-US  en-US 8 en-US o en-US en-US e en-US  en-US c en-US  en-US  en-US  en-US c en-US t en-US en-US ed en-US o en-US en-US ilen-US een-US ion en-US  en-US en-US  en-US ion en-US  en-US he en-US  en-US y en-US ilien-US en-US  en-US ion en-US  en-US elioen-US ion en-US  en-US y en-US  en-US work en-US  en-US l en-US eren-US non en-US en-US  en-US non en-US en-US op en-US oben-US ic en-US ion en-US  en-US en-US  en-US 9 en-US b en-US comen-US re en-US  en-US cking en-US ion en-US  en-US ien-US i en-US en-US  en-US i en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  14      en-US a en-US k en-US ck en-US en-US to en-US en-US en-US en-US  en-US ion en-US  en-US  en-US i en-US  en-US en-US  en-US  en-US ion en-US e en-US cy en-US  en-US 0 en-US  en-US  en-US n en-US igen-US  en-US en-US in en-US  en-US 5 en-US  en-US  en-US ion en-US la en-US  en-US en-US  en-US  en-US t en-US  en-US n en-US en-US ck en-US en-US to en-US en-US  en-US o en-US en-US ien-US n en-US en-US e en-US  en-US rs en-US en-US  en-US  en-US hen-US in en-US  en-US 0 en-US  en-US in en-US  en-US 1 en-US  en-US  en-US ll en-US en-US cova en-US nce en-US 2 en-US  en-US ion en-US 3 en-US  en-US Cov en-US nion en-US  en-US 3 en-US  en-US  en-US  en-US  en-US r en-US  en-US he en-US oen-US  en-US en-US rien-US he en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US o en-US  en-US  en-US  en-US  en-US  en-US  en-US  en-US en-US low en-US en-US en-US F en-US  en-US  en-US elow en-US  en-US Cross en-US en-US on en-US  en-US  en-US s en-US en-US  en-US 2    1 5 4  en-US  en-US  en-US y en-US Y   whe re X  a nd  Y  a r e t he ra nd om v ect or s   E  is  ex en-US  en-US      en-US  en-US  en-US    en-US  en-US      10   en-US on en-US Co en-US  en-US  en-US 3 en-US  en-US  en-US  en-US KF en-US  en-US a en-US  en-US  en-US o en-US  en-US  en-US  en-US  en-US  en-US coen-US io en-US  en-US     11    en-US en-US   12   en-US H en-US ere en-US en-US  en-US  en-US  en-US on en-US  en-US  en-US in en-US  en-US 3 en-US  en-US en-US en-US  en-US  en-US  en-US  en-US y en-US en-US  en-US oth en-US en-US  en-US nd en-US  en-US en-US e en-US   en-US  en-US  en-US      en-US  en-US nd en-US       en-US  en-US re en-US   en-US  en-US  en-US   en-US  en-US  en-US en-US  en-US ion en-US  en-US l en-US en-US  en-US ien-US in en-US en-US ion en-US  en-US  en-US or en-US  en-US  en-US ion en-US  en-US 5    1 5 5  en-US  en-US  en-US cking en-US ion en-US  en-US  en-US ynen-US  en-US cking en-US ion en-US  en-US  en-US er en-US  en-US re en-US en-US en-US  en-US  en-US  en-US In en-US  en-US  en-US 9 en-US o en-US en-US  en-US n en-US  en-US 6 en-US  en-US  9 i    


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   15     en-US  en-US e en-US  en-US t en-US e en-US g en-US eful en-US ion en-US  en-US e en-US  en-US  en-US 4.4.1  en-US es en-US  en-US in en-US ions en-US  en-US re en-US  en-US h en-US n en-US en-US er en-US  en-US inen-US ct en-US otion en-US en-US ed en-US ion en-US  en-US en-US ion en-US  en-US 9 en-US  en-US  en-US  en-US en-US u en-US  en-US  en-US H en-US owe en-US  en-US ccuen-US en-US l en-US een-US T en-US re en-US he en-US i en-US en-US en-US cking en-US  en-US in en-US  en-US 4    1 4 6     1 5 7     1 5 8  en-US  en-US  en-US  en-US en-US en-US  en-US lly en-US  en-US  en-US ib en-US en-US r en-US  en-US  en-US T en-US  en-US ion en-US  en-US  en-US O en-US s en-US  en-US  en-US  en-US  en-US ion en-US  en-US  en-US 5  en-US E en-US  en-US D en-US ATA FUS en-US ION en-US  en-US T en-US DS en-US  en-US e en-US on en-US en-US ion en-US  en-US  en-US ion en-US  en-US o en-US ic en-US t en-US  en-US ent en-US  en-US  en-US ion en-US  en-US en-US s en-US  en-US I en-US  en-US ion en-US  en-US  en-US  en-US re en-US ion en-US  en-US  en-US how en-US p en-US  en-US nce en-US ion en-US  en-US  en-US  en-US 5.1  en-US s en-US ed en-US s en-US  en-US elf en-US en-US  en-US own en-US  en-US ence en-US  en-US  en-US  en-US o en-US  en-US  en-US en-US  en-US y en-US a en-US  en-US or en-US  en-US ource en-US  en-US  en-US c en-US  en-US  en-US riving en-US  en-US ion en-US  en-US ine en-US  en-US hing en-US a en-US  en-US le en-US  en-US  en-US ict en-US  en-US  en-US of en-US  en-US ion en-US  en-US ehicle en-US s en-US  en-US r en-US  en-US elf en-US en-US elen-US t en-US  en-US re en-US  en-US y en-US gy en-US an en-US inen-US elop en-US ing en-US  en-US en-US rive en-US en-US his en-US  en-US ed en-US he en-US e en-US en-US of en-US en-US rt en-US ion en-US  en-US en-US ing en-US  en-US ing en-US  en-US  en-US a en-US comen-US  en-US  en-US t en-US ics en-US  en-US ed en-US by en-US  en-US en-US n en-US 9 en-US  en-US en-US  en-US ing en-US  en-US in en-US 0 en-US  en-US  en-US n en-US 1    1 6 2  en-US inen-US  en-US  en-US hing en-US en-US p en-US en-US en-US ri en-US in en-US 3 en-US  en-US which en-US es en-US  en-US  en-US in en-US 4 en-US  en-US  en-US icyen-US i en-US en-US n en-US 5 en-US  en-US  en-US  en-US in en-US 5 en-US  en-US ge en-US  en-US cten-US  en-US 6 en-US  en-US in en-US 7 en-US  en-US T en-US  en-US leen-US d en-US en-US s en-US  en-US en-US  en-US  en-US  en-US riven-US in en-US 8 en-US  en-US her en-US  en-US on en-US e en-US  en-US re en-US  en-US ove en-US  en-US e en-US ny en-US  en-US en-US ges en-US  en-US  en-US ien-US r en-US inct en-US  en-US c en-US en-US en-US  en-US en-US nce en-US en-US e en-US en-US r en-US  en-US  en-US  en-US  en-US  en-US 9 en-US  en-US  en-US 0 en-US  en-US elf en-US en-US en-US  en-US en-US rive en-US en-US ed en-US  en-US  en-US n en-US ion en-US  en-US n en-US ion en-US 1 en-US  en-US  en-US he en-US  en-US ve en-US  en-US ed en-US  en-US r en-US  en-US h en-US ion en-US  en-US  en-US ion en-US  en-US ing en-US  en-US re en-US  en-US er en-US  en-US  en-US ion en-US  en-US re en-US ring en-US a en-US  en-US r en-US en-US  en-US  en-US  en-US  en-US 5.2  en-US ing en-US  en-US sion en-US  en-US rning en-US  en-US  en-US  en-US  en-US ion en-US r en-US ied en-US  en-US rning en-US  en-US  en-US  en-US  en-US ha en-US e en-US t en-US  en-US  en-US c en-US  en-US  en-US ni en-US z en-US ions en-US  en-US or en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  16      en-US  en-US 1 en-US D en-US ning en-US  en-US rnen-US el en-US he en-US l en-US  en-US t en-US  en-US ke en-US s en-US  en-US  en-US lly en-US r en-US reen-US o en-US  en-US ediction en-US s en-US  en-US  en-US rning en-US  en-US  en-US el en-US  en-US  en-US  en-US g en-US  en-US el en-US  en-US  en-US which en-US help en-US s en-US  en-US hink en-US  en-US  en-US  en-US rning en-US  en-US  en-US lly en-US  en-US h en-US ceen-US b en-US on en-US  en-US rning en-US  en-US 2 en-US t en-US  en-US rning en-US  en-US r en-US  en-US  en-US  en-US  en-US he en-US he en-US  en-US comen-US ion en-US ources en-US  en-US g en-US ine en-US ing en-US  en-US e en-US  en-US  en-US 3 en-US  en-US rning en-US  en-US in en-US 3    1 7 4  en-US  en-US i en-US en-US 9  cr it ica lly ex p la in s  t he p re s ent  s t a t e en-US en-US of en-US en-US elen-US in en-US rning en-US  en-US  en-US n en-US rning en-US  en-US n en-US 0  a u t hor s  d is cu s s  t he p a s t  a nd  P res ent  of  en-US  en-US rning en-US  en-US o en-US rnen-US ing en-US  en-US rning en-US  en-US n en-US 5    1 7 6  en-US  en-US e en-US ed en-US  en-US ion en-US  en-US u en-US nen-US n en-US w en-US  en-US ery en-US ce en-US rning en-US  en-US rning en-US  en-US king en-US inen-US o en-US  en-US ion en-US  en-US in en-US  en-US l en-US ly en-US  en-US l en-US  en-US ning en-US  en-US in en-US 7 en-US en-US 9 en-US  en-US en-US n en-US 4 en-US  en-US eo en-US  en-US g en-US in en-US 0 en-US  en-US  en-US  en-US rning en-US  en-US  en-US 6   d ee p  f u lly convolu t iona l neu ra l  en-US rth en-US  en-US  en-US ion en-US  en-US in en-US 1 en-US  en-US  en-US  en-US work en-US 2 en-US r en-US ion en-US 4 en-US en-US R en-US en-US he en-US  en-US ion en-US  en-US en en-US  en-US in en-US t en-US he en-US  en-US  en-US 2 en-US  en-US  en-US  en-US  en-US e en-US rning en-US  en-US  en-US ion en-US  en-US  en-US  en-US  en-US lica en-US  en-US in en-US  en-US  en-US s en-US  en-US n en-US  en-US ion en-US  en-US 3 en-US  en-US ion en-US  en-US f en-US  en-US 4 en-US  en-US l en-US ion en-US  en-US in en-US 5 en-US  en-US n en-US  en-US 6 en-US  en-US  en-US  en-US  en-US in en-US o en-US ing en-US  en-US rning en-US  en-US o en-US  en-US  en-US ion en-US  en-US  en-US  en-US en-US ing en-US  en-US  en-US rning en-US  en-US  en-US v en-US  en-US  en-US rning en-US  en-US  en-US  en-US  en-US  en-US rning en-US  en-US re en-US as en-US  en-US ion en-US  en-US  en-US 5.3  en-US  en-US  en-US es en-US  en-US en-US  en-US lif en-US n en-US en-US  en-US eren-US a en-US  en-US en-US  en-US l en-US w en-US  en-US ing en-US 7    1 8 8  en-US  en-US he en-US en-US  en-US lly en-US en-US  en-US ge en-US en-US  en-US  en-US y en-US en-US  en-US 6 en-US  en-US en-US  en-US in en-US  en-US  en-US y en-US ien-US  en-US en-US v en-US ed en-US  en-US e en-US  en-US  en-US rning en-US  en-US  en-US  en-US nen-US re en-US 9 en-US  en-US in en-US 0 en-US y en-US in en-US rt en-US e en-US  en-US recen-US  en-US en-US how en-US en-US een-US e en-US en-US who en-US  en-US en-US e en-US en-US who en-US  en-US A en-US d en-US  en-US in en-US 1 en-US  en-US  en-US  en-US  en-US 2 en-US en-US 4 en-US  en-US  en-US 5 en-US  en-US  en-US  en-US 6 en-US en-US 8 en-US  en-US 9 en-US en-US 1 en-US  en-US s en-US re en-US 2 en-US en-US 4 en-US  en-US en-US r en-US ocieen-US e en-US s en-US  en-US 5    2 0 6  en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   17     en-US 2 en-US  en-US oT en-US en-US v en-US l en-US l en-US ions en-US  en-US 7 en-US  en-US s en-US  en-US 8 en-US  en-US 9 en-US  en-US 0 en-US en-US 3 en-US  en-US en-US ices en-US  en-US 4 en-US  en-US len-US ove en-US  en-US 5 en-US en-US 8 en-US  en-US e en-US en-US ourcing 1 en-US  2 en-US  en-US hoc en-US en-US rp en-US es en-US 6    2 1 9  en-US en-US s en-US  en-US 0 en-US s en-US 1 en-US  en-US  en-US 2 en-US  en-US cience en-US 3 en-US  en-US cy en-US 4 en-US  en-US  en-US t en-US  en-US l en-US 4 en-US  en-US 5 en-US  en-US 6 en-US  en-US  en-US nning 8 en-US  en-US  en-US hone en-US  en-US ches en-US  en-US  en-US t en-US en-US en-US g en-US  en-US la en-US ion en-US he en-US er en-US rt en-US  en-US  en-US  en-US n en-US gyroen-US  en-US  en-US nd en-US  en-US a en-US xen-US or en-US  en-US conen-US t en-US en-US heir en-US  en-US  en-US ion en-US  en-US enen-US  en-US ices en-US  en-US ion en-US 6 en-US  en-US in en-US 7    2 2 8  en-US  en-US  en-US hen-US o en-US e en-US s en-US  en-US en-US ies en-US Very en-US  en-US ion en-US  en-US on en-US he en-US  en-US here en-US r en-US t en-US en-US  en-US ap en-US d en-US ed en-US ion en-US  en-US le en-US  en-US nd en-US  en-US  en-US s en-US rt en-US c en-US  en-US f en-US len-US ove en-US en-US d en-US  en-US  en-US s en-US rt en-US c en-US m en-US en-US en-US nen-US  en-US  en-US 6  en-US C en-US O en-US LUSION en-US  en-US y en-US  en-US en-US  en-US s en-US en-US ig en-US  en-US nen-US nd en-US  en-US en-US  en-US een-US nen-US  en-US ellig en-US  en-US  en-US en-US  en-US  en-US o en-US  en-US en-US l en-US hen-US  en-US s en-US  en-US  en-US  en-US ien-US f en-US  en-US ed en-US ed en-US r en-US  en-US s en-US o en-US  en-US ic en-US en-US ed en-US en-US  en-US d en-US  en-US  en-US re en-US  en-US o en-US ed en-US  en-US en-US ed en-US ch en-US  en-US  en-US A en-US ENT en-US  en-US  en-US he en-US er en-US  en-US  en-US he en-US ing en-US iz en-US  en-US y en-US h en-US  en-US  en-US ing en-US  en-US  en-US  en-US a en-US  en-US  en-US R en-US ES en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US vey en-US en-US s en-US  en-US 7 en-US en-US  en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US 437 en-US en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US TU en-US en-US TU en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US nc en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US  en-US the en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US EE en-US E en-US ess en-US  en-US 5 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US i en-US en-US n en-US  en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US  en-US en-US  en-US ew en-US i   Ava i l a bl e   en-US o en-US 3 en-US en-US the en-US en-US r en-US en-US of en-US en-US the en-US en-US net en-US en-US of en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US  en-US vey en-US en-US s en-US  en-US 7 en-US en-US  en-US  en-US  en-US  en-US 10 en-US  en-US  en-US  en-US en-US  en-US  en-US a en-US vey en-US en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 11 en-US  en-US  en-US Al en-US en-US  en-US  en-US en-US  en-US  en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  18      en-US S en-US v en-US  en-US  en-US  en-US 12 en-US  en-US  en-US  en-US en-US  en-US ti en-US en-US  en-US en-US sors en-US  en-US 1 en-US en-US  en-US  en-US  en-US 13 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US  en-US l en-US  en-US  en-US  en-US 14 en-US  en-US  en-US  en-US en-US n te en-US en-US of en-US en-US the en-US en-US  en-US en-US n en-US  en-US 28 en-US en-US  en-US  en-US  en-US 15 en-US  en-US  en-US N en-US en-US  en-US en-US  en-US en en-US  en-US en-US  en-US vey en-US en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 16 en-US  en-US  en-US ez en-US en-US  en-US en-US  en-US e en-US  en-US  en-US en-US sors en-US  en-US  en-US  en-US  en-US 17 en-US  en-US  en-US  en-US en-US  en-US ti en-US en-US  en-US en-US sors en-US n en-US  en-US 1 en-US en-US  en-US  en-US  en-US 18 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 19 en-US  en-US  en-US  en-US en-US  en-US T en-US en-US  en-US  en-US  en-US 73 en-US en-US  en-US  en-US  en-US 20 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 15 en-US en-US  en-US  en-US  en-US 21 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US i en-US  en-US  en-US  en-US  en-US 22 en-US  en-US  en-US  en-US i en-US en-US n en-US  en-US  en-US  en-US  en-US 23 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US  en-US  en-US  en-US  en-US 24 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 540 en-US en-US  en-US  en-US  en-US 25 en-US  en-US  en-US  en-US en-US  en-US t en-US  en-US  en-US en-US l en-US  en-US 8 en-US en-US  en-US  en-US  en-US 26 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US n en-US  en-US 7 en-US en-US  en-US  en-US  en-US 27 en-US  en-US  en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US i en-US en-US B\256 en-US  en-US  en-US  en-US  en-US 29 en-US  en-US  en-US  en-US  en-US  en-US  en-US ew en-US en-US  en-US  en-US  en-US  en-US  en-US 30 en-US  en-US  en-US r en-US en-US e en-US en-US ti en-US en-US  en-US n en-US en-US  en-US ess en-US  en-US 807 en-US en-US  en-US  en-US  en-US 31 en-US  en-US  en-US  en-US  en-US  en-US en-US ted en-US en-US 2015 en-US s en-US  en-US 7 en-US en-US  en-US  en-US  en-US 32 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US no en-US  en-US 1 en-US en-US  en-US  en-US  en-US 33 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 34 en-US  en-US  en-US  en-US en-US  en-US l en-US  en-US en-US  en-US 190 en-US en-US  en-US  en-US  en-US  en-US 35 en-US  en-US  en-US  en-US en-US nt en-US en-US  en-US  en-US  en-US en-US  en-US en-US  en-US IC en-US  en-US  en-US  en-US  en-US  en-US  en-US 36 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 37 en-US  en-US  en-US  en-US en-US s en-US  en-US  en-US en-US EE en-US en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 38 en-US  en-US  en-US  en-US en-US er en-US en-US  en-US en-US  en-US eo en-US  en-US  en-US 6 en-US en-US  en-US  en-US  en-US 39 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US EE en-US en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 40 en-US  en-US  en-US  en-US en-US ti en-US en-US t en-US  en-US n en-US en-US P en-US  en-US 1 en-US en-US  en-US  en-US  en-US 41 en-US  en-US  en-US  en-US en-US ti en-US en-US e en-US en-US  en-US  en-US en-US rol en-US  en-US 7 en-US en-US  en-US  en-US  en-US 42 en-US  en-US  en-US L en-US en-US  en-US en-US t en-US  en-US  en-US en-US 0 en-US  en-US  en-US  en-US 43 en-US  en-US  en-US  en-US n en-US  en-US ey en-US en-US  en-US  en-US  en-US 44 en-US  en-US  en-US L en-US en-US  en-US en-US  en-US ti en-US en-US n en-US en-US  en-US  en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 45 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US n en-US en-US s en-US  en-US 6 en-US en-US  en-US  en-US  en-US  en-US 46 en-US  en-US  en-US  en-US en-US  en-US ng en-US en-US  en-US en-US  en-US ess en-US 2 en-US  en-US 2 en-US en-US  en-US  en-US  en-US 47 en-US  en-US  en-US en en-US  en-US i en-US en-US n en-US  en-US  en-US  en-US  en-US 48 en-US  en-US  en-US  en-US en-US  en-US ver en-US e en-US en-US  en-US  en-US en-US rks en-US  en-US  en-US  en-US 49 en-US  en-US  en-US  en-US en-US  en-US e en-US en-US  en-US  en-US en-US rks en-US  en-US  en-US  en-US 50 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 51 en-US  en-US  en-US  en-US en-US r en-US n en-US en-US  en-US 7 en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   19     en-US  en-US  en-US  en-US 52 en-US  en-US  en-US  en-US en-US e en-US ti en-US en-US  en-US  en-US en-US  en-US 4 en-US en-US  en-US  en-US  en-US 53 en-US  en-US  en-US  en-US en-US  en-US  en-US DA en-US en-US  en-US  en-US  en-US  en-US 54 en-US  en-US  en-US  en-US en-US e en-US n en-US  en-US en-US  en-US v en-US en-US  en-US  en-US  en-US 55 en-US  en-US  en-US  en-US en-US k en-US en-US thm en-US en-US  en-US ron en-US  en-US 0 en-US en-US  en-US  en-US 5 en-US 6 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US n en-US  en-US  en-US  en-US 57 en-US  en-US  en-US  en-US en-US ti en-US en-US T en-US  en-US n en-US en-US  en-US  en-US  en-US  en-US  en-US 58 en-US  en-US  en-US  en-US en-US  en-US Pre en-US en-US  en-US t en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 3 en-US en-US 1 en-US  en-US  en-US  en-US 59 en-US  en-US  en-US t en-US  en-US  en-US n en-US en-US  en-US  en-US en-US  en-US OS en-US  en-US 2 en-US en-US  en-US  en-US  en-US 60 en-US  en-US  en-US  en-US en-US  en-US ti en-US  en-US t en-US en-US  en-US 4 en-US en-US  en-US  en-US  en-US 61 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US ess en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 62 en-US  en-US  en-US  en-US en-US X en-US en-US ng en-US en-US s en-US  en-US en-US  en-US  en-US i    en-US x en-US en-US e en-US en-US i en-US en-US r en-US en-US is en-US en-US 2 en-US en-US Dec en-US en-US 6  en-US  en-US  en-US 63 en-US  en-US  en-US i en-US  en-US en-US  en-US  en-US en-US h en-US i   Av a i l a bl e   en-US e en-US en-US is en-US en-US ng en-US en-US a en-US en-US nd en-US en-US b en-US en-US r en-US en-US the en-US en-US net en-US en-US of en-US en-US 0 en-US en-US Dec en-US en-US 6  en-US  en-US  en-US 64 en-US  en-US  en-US BI en-US en-US  en-US en-US e en-US  en-US  en-US en-US er en-US  en-US i    en-US du en-US en-US es en-US en-US new en-US en-US ai en-US en-US nd en-US en-US net en-US en-US of en-US en-US s en-US en-US ves en-US en-US 6 en-US en-US 0 en-US en-US Dec en-US en-US 6  en-US  en-US  en-US 65 en-US  en-US  en-US  en-US en-US Su en-US  en-US  en-US en-US a en-US  en-US 9 en-US en-US  en-US  en-US  en-US  en-US 66 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US s en-US  en-US  en-US  en-US  en-US 67 en-US  en-US  en-US  en-US en-US  en-US a en-US en-US ve en-US en-US a en-US  en-US 383 en-US en-US  en-US  en-US  en-US 68 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US ess en-US  en-US 7 en-US en-US  en-US  en-US  en-US 69 en-US  en-US  en-US  en-US en-US  en-US vey en-US en-US  en-US ri en-US s en-US  en-US 77 en-US en-US  en-US  en-US  en-US 70 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 71 en-US  en-US  en-US o en-US  en-US  en-US ne en-US en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 72 en-US  en-US  en-US  en-US en-US  en-US n en-US e en-US  en-US en-US  en-US n en-US  en-US 6 en-US en-US  en-US  en-US  en-US 73 en-US  en-US  en-US  en-US en-US  en-US  en-US hy en-US  en-US en-US  en-US n en-US  en-US 6 en-US en-US  en-US  en-US  en-US 74 en-US  en-US  en-US  en-US en-US  en-US t en-US en-US I en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 75 en-US  en-US  en-US  en-US en-US  en-US ty en-US en-US  en-US en-US  en-US f en-US en-US  en-US  en-US  en-US  en-US 76 en-US  en-US  en-US a en-US  en-US en-US ti en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 96 en-US en-US  en-US  en-US  en-US 77 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US 0 en-US 8 en-US en-US  en-US  en-US ess en-US  en-US 85 en-US en-US  en-US  en-US  en-US 78 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US  en-US  en-US  en-US  en-US  en-US 79 en-US  en-US  en-US hen en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 80 en-US  en-US  en-US  en-US en-US ng en-US en-US  en-US  en-US  en-US en-US s en-US  en-US  en-US 6 en-US en-US  en-US  en-US  en-US 81 en-US  en-US  en-US N en-US  en-US  en-US en-US  en-US  en-US en-US 2011 en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 82 en-US  en-US  en-US  en-US  en-US en-US o en-US  en-US  en-US en-US 2011 en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 83 en-US  en-US  en-US  en-US en-US  en-US s en-US  en-US  en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 84 en-US  en-US  en-US  en-US en-US  en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  20      en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 85 en-US  en-US  en-US F en-US  en-US en-US  en-US  en-US en-US  en-US 0 en-US  en-US 5 en-US en-US  en-US  en-US  en-US 86 en-US  en-US  en-US h en-US  en-US  en-US l en-US en-US  en-US en-US  en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 87 en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US  en-US d en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 88 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US 6 en-US  en-US 263 en-US en-US  en-US  en-US  en-US 89 en-US  en-US  en-US  en-US en-US tem en-US en-US OTA en-US  en-US 6 en-US  en-US 6 en-US en-US  en-US  en-US  en-US  en-US 90 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US m en-US  en-US 87 en-US en-US  en-US  en-US  en-US  en-US 91 en-US  en-US  en-US e en-US  en-US  en-US en-US  en-US  en-US en-US  en-US m en-US  en-US 87 en-US en-US  en-US  en-US  en-US  en-US 92 en-US  en-US  en-US  en-US en-US  en-US a en-US  en-US  en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 93 en-US  en-US  en-US  en-US en-US  en-US r en-US en-US  en-US  en-US en-US  en-US 195 en-US en-US  en-US  en-US  en-US 94 en-US  en-US  en-US Wei en-US en-US xi en-US ng en-US en-US eng en-US en-US  en-US en-US  en-US k en-US en-US to en-US en-US  en-US  en-US en-US ess en-US  en-US 1 en-US en-US  en-US  en-US  en-US 95 en-US  en-US  en-US  en-US en-US  en-US c en-US r en-US en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 96 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US r en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 97 en-US  en-US  en-US  en-US  en-US  en-US en-US e en-US en-US  en-US r en-US en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US  en-US m en-US en-US s en-US en-US 3 en-US  en-US 3 en-US en-US  en-US  en-US  en-US 98 en-US  en-US  en-US a en-US en-US  en-US en-US  en-US ter en-US en-US  en-US  en-US en-US l en-US  en-US  en-US  en-US  en-US 99 en-US  en-US  en-US a en-US  en-US en-US  en-US  en-US  en-US en-US  en-US BE en-US  en-US 1 en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US e en-US  en-US  en-US  en-US  en-US 1 en-US  en-US  en-US e en-US en-US  en-US ter en-US en-US  en-US  en-US  en-US  en-US 2 en-US  en-US  en-US e en-US en-US  en-US ter en-US en-US the en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US  en-US ter en-US en-US  en-US ti en-US en-US n en-US en-US  en-US n en-US  en-US 3 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US th en-US  en-US  en-US ter en-US en-US  en-US  en-US en-US s en-US  en-US 7 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US en en-US en-US  en-US n en-US  en-US  en-US en-US 4 en-US  en-US 4 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US e en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US ter en-US en-US  en-US tem en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US  en-US en-US  en-US a en-US en-US  en-US en-US  en-US S en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US  en-US  en-US en-US ter en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 72 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US n en-US en-US a en-US  en-US 5 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US W en-US  en-US en-US  en-US  en-US nty en-US en-US  en-US ON en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US  en-US Se en-US  en-US en-US  en-US l en-US  en-US 334 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US Int en-US en-US y en-US  en-US  en-US  en-US 249 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US en-US  en-US d en-US en-US  en-US 1 en-US 1 en-US 52 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US  en-US te en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US en-US r en-US  en-US 34 en-US en-US  en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   21     en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US i en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US s en-US  en-US  en-US  en-US 2 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US 1 en-US 77 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US d en-US en-US a en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US 2 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US o en-US  en-US en-US  en-US  en-US en-US s en-US  en-US 0 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US s en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US en-US a en-US  en-US 321 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US K en-US en-US t en-US en-US  en-US en-US  en-US  en-US s en-US en-US dy en-US en-US matics en-US  en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US  en-US res en-US  en-US  en-US  en-US 9 en-US  en-US  en-US R en-US n en-US en-US  en-US en-US  en-US  en-US en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US n en-US en-US  en-US en-US n en-US  en-US  en-US  en-US en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US man en-US en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US d en-US en-US s en-US 2 en-US  en-US 46 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US ti en-US en-US ti en-US en-US  en-US n en-US en-US n en-US  en-US 1 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US n en-US en-US n en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US en-US 2 en-US  en-US ron en-US  en-US 351 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US Semi en-US en-US  en-US  en-US en-US  en-US S en-US s en-US en-US  en-US  en-US  en-US 2 en-US en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US ex en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 9 en-US  en-US  en-US nt en-US en-US  en-US en-US  en-US  en-US a en-US  en-US en-US  en-US r en-US  en-US 7 en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US EEE en-US  en-US 6 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US s en-US  en-US 7 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US n en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US ene en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 7 en-US en-US  en-US  en-US 4 en-US  en-US  en-US en-US  en-US ti en-US en-US  en-US en-US  en-US  en-US 8 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US i en-US  en-US  en-US en-US  en-US dy en-US en-US  en-US n en-US y en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US  en-US  en-US en-US IE en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US ter en-US en-US n en-US en-US  en-US l en-US en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US  en-US  en-US n en-US en-US  en-US en-US  en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US  en-US the en-US  en-US en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  22      en-US Inte en-US  en-US  en-US 132 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US n en-US en-US  en-US I en-US en-US  en-US  en-US  en-US 69 en-US en-US 8 en-US  en-US  en-US  en-US 2 en-US  en-US  en-US r en-US en-US  en-US en-US k en-US en-US to en-US en-US  en-US  en-US en-US r en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US t en-US en-US n en-US en-US n en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US i   en-US m en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US  en-US tr en-US  en-US n en-US en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US en-US a en-US i   en-US d en-US en-US a en-US en-US c en-US en-US es en-US 2 en-US en-US n en-US en-US 7  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US dy en-US en-US  en-US n en-US y en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US  en-US en-US  en-US vey en-US en-US  en-US  en-US 13 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US n en-US en-US  en-US n en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US 2010 en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US  en-US o en-US n en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US B en-US  en-US en-US A en-US ti en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 6 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US e en-US en-US s en-US  en-US  en-US  en-US en-US  en-US n en-US  en-US 1 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US f en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US e en-US en-US  en-US  en-US  en-US 1 en-US 68 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US f en-US en-US  en-US ew en-US en-US e en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US i en-US  en-US  en-US en-US  en-US n en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US h en-US en-US er en-US i   Av a i l a bl e   en-US p en-US en-US ten en-US en-US hn en-US y en-US en-US ends en-US en-US l en-US en-US the en-US en-US l en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US  en-US en-US re en-US  en-US 6 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US y en-US en-US  en-US e en-US en-US  en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US en-US re en-US  en-US 6 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US en-US t en-US  en-US earn en-US  en-US 9 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 34 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US Lef en-US  en-US en-US  en-US  en-US ti en-US en-US  en-US en-US V en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US Pro en-US  en-US  en-US  en-US 34 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US ng en-US en-US ti en-US en-US  en-US  en-US  en-US en-US  en-US 1 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US O en-US en-US M en-US  en-US en-US l en-US en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US N en-US s en-US  en-US en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US to en-US en-US  en-US en-US n en-US  en-US  en-US  en-US 5 en-US  en-US  en-US D en-US  en-US  en-US en-US nt en-US en-US  en-US en-US  en-US en-US  en-US  en-US  en-US  en-US 6 en-US en-US  en-US 2 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US edes en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US t en-US  en-US en-US  en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   23     en-US  en-US 22 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US t en-US en-US  en-US vey en-US en-US  en-US  en-US ne en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US  en-US  en-US tbed en-US en-US  en-US en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US G en-US  en-US en-US o en-US en-US  en-US en-US  en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US e en-US en-US ent en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US a en-US en-US z en-US en-US  en-US dez en-US en-US z en-US en-US  en-US en-US  en-US a en-US  en-US  en-US en-US  en-US 26 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US a en-US en-US a en-US en-US o en-US en-US  en-US a en-US en-US  en-US en-US o en-US en-US F en-US en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 8 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US  en-US  en-US en-US  en-US en-US  en-US 2015 en-US b en-US 5 en-US  en-US 9 en-US en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US o en-US en-US  en-US en-US  en-US  en-US en-US n en-US  en-US  en-US 45 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US k en-US  en-US  en-US en-US  en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US r en-US  en-US 86 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US y en-US en-US by en-US en-US  en-US en-US  en-US s en-US  en-US 1 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US  en-US dez en-US en-US  en-US en-US n en-US en-US  en-US en-US  en-US n en-US y en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US tem en-US en-US  en-US ti en-US en-US ve en-US en-US  en-US  en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US ty en-US en-US  en-US en-US  en-US  en-US  en-US 5 en-US  en-US 2 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US en en-US en-US  en-US  en-US  en-US en-US ess en-US  en-US 831 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US ne en-US en-US  en-US e en-US en-US  en-US  en-US 26 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US ve en-US  en-US  en-US en-US  en-US rk en-US  en-US 7 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US Sy en-US  en-US  en-US en-US  en-US  en-US  en-US es en-US  en-US 1 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US  en-US  en-US r en-US rks en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US n en-US  en-US  en-US 9 en-US 0 en-US  en-US 411 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US tems en-US en-US  en-US  en-US  en-US  en-US n en-US  en-US en-US  en-US v en-US es en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US en en-US en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US m en-US en-US  en-US  en-US th en-US en-US  en-US en-US  en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US ng en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US  en-US rk en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 8 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US t en-US dy en-US en-US n en-US s en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  24      en-US  en-US i en-US  en-US en-US  en-US  en-US 9 en-US  en-US 2 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US n en-US  en-US t en-US 7 en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US n en-US en-US E en-US ess en-US  en-US 858 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US ess en-US  en-US 1 en-US en-US  en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US  en-US  en-US o en-US en-US  en-US en-US in en-US  en-US  en-US  en-US l en-US en-US  en-US g en-US  en-US 0 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US Ben en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US f en-US  en-US  en-US dy en-US en-US  en-US 11 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US  en-US en-US T en-US en-US  en-US o en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US z en-US en-US  en-US en-US ti en-US en-US  en-US  en-US  en-US en-US sort en-US  en-US  en-US 5 en-US  en-US  en-US  en-US 8 en-US  en-US  en-US z en-US en-US  en-US en-US  en-US f en-US en-US the en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 121 en-US en-US  en-US  en-US  



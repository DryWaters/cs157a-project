A CLOUD PLATFORM FOR FLOW-BASED ANALYSIS OF LARGE-SCALE NETWORK TRAFFIC Wenzhao Liao 1 Zhiren Fu 1  1 China Telecom Co., Ltd. Shanghai Branch, Shanghai 200085, China liaowenzhao@shtel.com.cn, fuzr@shtel.com.cn Keywords Cloud Platform, Netflow, Network Traffic MapReduce  Abstract Traditional flow-based network monitoring and analyzing tools are challenged with large-scale network traffic for the big size of data This paper proposes a Cloud Platform for large-scale network analysis. It exploits HDFS and DataX to deal with the storage of heterogeneous big data. And the MapReduce model is applied to concurrently compute the 
analyzing and correlating on large amount of network flow data. Flow-based techniques are employed in collecting network data to make possible an application level analysis of network usage. Experimental results show that the performance of the platform is greatly improved compared with that of the traditional RDBMS application 1  Introduction In order to provide a good quality of service, network administrators need to maintain a healthy state of the network by measuring the IP traffic between network nodes, analyzing customer behavior and collecting statistics data about important business network bandwidth, as well as proper 
network planning and evaluating. They need timely and accurate flow monitoring and statistical tools on network traffic and the business hosted upon it Generally there are three kinds of ways to monitor the network traffic  1\ Common network monitoring tools, such as MRTG, Cacti These tools use the SNMP protocol to monitor port state and calculate port traffic. However, these methods can only monitor indicators such as the bytes counter of packets entering and leaving a single port. The traffic information is too rough and it can’t be understood what the traffic carries and where the traffic flows to  2\ Packet capturing software, such as PCAP or DPI \(Deep 
Packet Inspection\. By unpacking and investigate the details of each packet, these analytical methods can learn more about the network traffic data, and can even replay network traffic However, due to the huge amount of data, the unpacking analysis method is costly. And it often creates new points of failure to the network. Therefore, it is difficult to deploy  3\ Flow-based analysis software, such as CISCO NetFlow By extracting information from the flow, it can help analyze the network application – which is made up of flows -- in the network traffic. Those flows, if enriched by information such as associated radius log and DNS log data, can also be 
exploited to analyze the customer behavior. Flow-based measurement approach strikes a balance on the granularity and the efficiency of traffic monitoring. Moreover, it has the advantages of investment saving and fast deployment Although flow-based network monitoring has many advantages over other monitoring methods, analysis and processing of the data is still a problem, mainly due to the extremely large amount of traffic data when facing with large-scale network traffic monitoring. Especially when a long term traffic data should be analyzed, the analysis task is hardly to be done with the traditional data storage and RDBMS technology 
This paper proposes a Cloud network analyzing platform to deal with ‘flow’ of data analysis and processing. It uses general-purpose and low-cost hardware and software to build a cluster solution. This system copes well with the storage of big network flow and the analysis and statistics on big data. It can be used to analyze large-scale network traffic 2  Why Is the Network Analyzer Flow-Based 2.1  Network Flow A network flow can be defined in many ways. Cisco’s standard NetFlow version 5 defines a flow as a unidirectional sequence of packets that share all of the following 7 values Ingress interface \(SNMP ifIndex 
Source IP address Destination IP address IP protocol Source port for UDP or TCP, 0 for other protocols Destination port for UDP or TCP, type and code for ICMP, or 0 for other protocols IP Type of Service The above definition of flows is also used for IPv6, and a similar one is used for MPLS and Ethernet flows  NetFlow is a network protocol developed by Cisco Systems for IP traffic information collection. NetFlow has become an industry standard for traffic monitoring and is supported on various platforms. Advanced NetFlow or IPFIX implementations like Cisco Flexible NetFlow also allow user-defined flow keys  NetFlow was initially implemented by Cisco, and described 
in an ‘informational’ document that was not on the standards track: RFC 3954 – Cisco Systems NetFlow Services Export Version 9. The NetFlow protocol itself has been superseded by Internet Protocol Flow Information eXport \(IPFIX\. Based on the NetFlow Version 9 implementation, IPFIX is on the IETF standards track with RFC 5101, RFC 5102, etc., which were published in 2008 Many vendors other than Cisco provide a NetFlow equivalent technology on their routers and switches, among them some 259 ICSSC 2013 


typical examples are listed in table 1 Table1 Some Typical NetFlow Equivalent Technology Protocol vendors Jflow or cflowd Juniper Networks NetStream Huawei Technologies Cflowd Alcatel-Lucent AppFlow Citrix 2.2  Data Enrichment The NetFlow data should be enriched with various data sources to deal with various network problems Multiple data sources provide valuable enrichment for the whole picture of what’s occurring on a network. A centralized platform shall be provided to quickly and easily search analyze, correlate and report across multiple data types. Here are the examples Enriching NetFlow data with RADIUS Logs—RADIUS Logs is helpful to ensure the authenticity of network stakeholders Since IP address assignments can change after each connection, malicious activity that occurs one day may be difficult to be traced back into the affected systems once the assignments changed. Attaching RADIUS logs along with NetFlow and other sources would enable this kind of tracing Enriching NetFlow Data with DNS Logs—DNS logs can be used to detect abnormalities and unusual instances of DNS For example, traffic communicating directly with an IP address with no corresponding DNS lookup would be suspicious and need further investigation At least two fields would be enriched to the flow data, i.e., the user identity and the domain name of the site 2.3  Advantages of Flow-Based Analysis The distributive feature of modern enterprises raises a series of operative and infrastructural problems to network administrators. Network administrators are often required to diagnose network problems quickly. But they are always lack of the global visibility to find the root cause. To deal with these problems, IT administrators need to clearly observe how traffic traverses. They have to monitor and record activities in order to understand how the traffic interacts among network applications and users. Only with effective network analyzer it would be possible to have a complete picture of network traffic Using the flow-based traffic analysis tools, the health state of the network can be easily and efficiently monitored  1\upport analyzing network flows by customized strategies The analysis can help identify top talkers and dialogue, and then recognize which users and applications have utilized the maximum bandwidth, and so on 2\nderstand the traffic trends and usage patterns. By viewing the trend of network traffic, the top-level application and peak usage time is able to be determined 3\ Mark specific applications as special flows. A combination of ports and protocols is used to mark applications as exceptions. That means these ‘marked’ applications shall not be restricted so that the traffic they’ve caused in the flow statement can be specifically highlighted out 4\etect the bandwidth usage of specific user groups, e.g the utilization rate and the bandwidth or applications assigned to each organization \(regions, countries, or provinces\fined by IP addresses 5\ Perform user behavior analysis, such as network traffic characteristics of specific groups of users, or the access pattern to specific network application from certain user group 6\mprove the accuracy of resource calculation by the use of real-time bandwidth and network usage statistics 3  Cloud Platform for the Network Analyzer Generally for large-scale network traffic, the time window for the analysis cannot be too big, and so is for the correlation analysis of other data sources \(such as RADIUS, DNS\. The root of these problems lies in the huge amount of data. If taking into account the correlation of Radius, DNS \(and others\ith network flow data, the amount of data will be heavily multiplied Traditional flow-based monitoring and analysis system is running in the centralized high-performance computers, rather than a distributed system. A prominent problem to be encountered in this mode is: how to store the data, and how to analyze and do statistics upon them The SAN is the traditional data storage system. In order to improve performance, data is stored in the FC-SAN. With the continuous expansion of the data amount, such a solution will face the scalability problem. And with limited fiber-switch port number, the total capacity of this solution will eventually reach the upper limit. For data analysis, even with the performance tuning, traditional database will spent too much time dealing with TBs’ data In this paper, a Cloud computing platform is introduced to try to solve the big data problem in flow-based monitoring and analysis system    Figure1 Architecture of the Cloud platform for large-scale network analysis Figure 1 shows the architecture of the flow measurement and analysis system. Flow data from routers are delivered to Collector nodes, as well as the Radius logs and DNS logs are The Collector nodes will correlate the flow data with the log data, and then use the data integration tools \(DataX\o load the data into a distributed file system. Processing nodes are managed by the master node to process the data  Each Collector node is equipped with a flow collector a log 260 


file reader and a DataX library . Each processing node is equipped with a distributed cluster file system, and a MapReduce library and a Hive library. A flow collector receives flow packets, correlates with the log data, then stores them into local files system. The DataX then loads files from local disk to the cluster file system. NetFlow packets from routers or monitoring servers are usually sent to cluster nodes in unicast. Flow data are enriched with the log data and saved periodically into files associated with each flow-exporting router, and then uploaded to the cluster file system. The flow collector uses the NetFlow as the collecting and processing tool. DataX will load the data in the local file system into the HDFS. Mapper and Reducer \(or Hive\ will analyze flow data with Hadoop MapReduce library 3.1  Distributed Computing with ‘Map-Reduce Model Hadoop is employed for the Cloud network analysis system It provides open MapReduce software framework and distributed file system. HDFS is suitable for handling very large files with the streaming data access pattern that is a write-once and read-any pattern. In HDFS, a name node operates management of the file system metadata and provides management and control services, while a data node supplies block storage and retrieval services. A name node at the master site will perform recovery and automatic backup of name nodes. The block size \(64 MB by default\ and the number of replicated blocks in HDFS could be customized according to the fault-tolerance policy To meet the customized purpose of flow analysis, appropriate Mapper and Reducer programs should be implemented. The map-reduce programming model was introduced by Google in 2004, in a paper describing the architecture along with some limited aspects of their non-public implementations One of the primary advantages of programming in the map-reduce model is that it abstracts away, and even eliminates – to some degree -- the complexity of writing a concurrent program. The programmer implements two functions: map and reduce. The framework takes care of invoking these functions on the input data and scheduling parallel execution of them across any number of computation nodes 3.2  Data Integration with Datax Input and output data for the network analyzer are data of heterogeneous. They may be a text file, a binary file or some data from RDBMS. The Cloud platform uses a high performance big data integration tool ‘DataX’ to access and integrate different data   Figure2 Integration of heterogeneous big data with DataX DataX has some specific features 1\igh-speed switching between heterogeneous database file system data 2\sing Framework + plugin architecture to build a Framework that deals with buffering, flow controlling concurrency, and loading the context of high-speed data exchanging most of the technical problems, providing a simple interaction interface with widget 3\ Run mode: Stand-alone, data transfer process is completed within a single process, the entire memory operation does not read and write disk, nor the IPC 4\pen framework, developers can develop a new plug-in to quickly support new database / file system  In our experimental platform, the corresponding data file reader plug-in has been developed to load data into HDFS 3.3  Flow Analyzing A network flow analysis requirement can typically be expressed as a query consisting of one of more of the following A filter expression defining what flow records should be included in the processing A set Q = {Q1,...,Qm} of aggregation queries, each defining a set of flow record fields to aggregate on A sort condition to indicate how the end result should be sorted, such as sorting by the total number of bytes A limit statement to restrict the number of returned rows typically indicating the lines that he or she is mostly interested To complete the query, the MapReduce programming model is exploited. In this model, the computation takes a set of input key/value pairs, and produces a set of output key/value pairs. Map and Reduce are two basic functions in the MapReduce computation. A user writes the Map method that takes an input pair and produces intermediate key/value pairs The Hadoop MapReduce library will group the intermediate values according to the keys. Also, a user writes the Reduce method to merge the intermediate values for smaller values To implement various data analysis programs with MapReduce, appropriate input key/value pairs for each analysis program have to be defined. For example, to analyze the behavior of a message sender, the user id and the octets counter can be defined as the key-value pairs  With MapReduce, typical flow analysis functions provided by well-known Internet traffic statistics programs can be realized without too much effort. Figure 3 shows the procedure of the 261 


MapReduce-based program that performs mail-transform analysis of flow data  Flow data\(HDFS timestamp,srcip,dstip,srcport,dstport,ifindex,TOS,pr otocal,userid,domain_name Read each line Parse the userid,octets Filter\(dstport=80 Add result set  userA,64 userB,64 userA,256 userC,128 Intermediate pairs  Read the tempdata userA,[64,256 userB,[64 userC,[128 reduce userA,320 userB,64 userC,128 Reducer   Figure3 A MapReduce program for mail analysis 1\ Input flow files: After flow data from flow probes is stored on the local disk, the raw NetFlow v5 files are moved to the HDFS. As the current Hadoop mapper supports only text files as the input format, NetFlow files are converted to text-format ones. As the size of text-format flow files is much larger than that of binary-format ones, binary flow files have to be supported as the inputs for Mapper. Otherwise, the gzip-compressed text flow files could be used for the input format 2\apper: The flow mapper reads each flow record that is split by new lines. A flow record has attributes of timestamp IP addresses, port, protocol, flag, octet count, packet count and interface numbers. After reading a flow record, we filter out necessary flow attributes for a flow analysis job. As shown in Fig. 3, when the flow analysis job sums up octet counts per user_id, we set key/value pairs as \(user_id, octets The flow map task will write its temporary results onto the local disk 3\educer: The flow reducer will be called with the inputs as intermediate values generated by flow mappers. As in the mail transfer example, a value list of octets belonging to the user_id will be summed up. After merging octet values associated with the user, the flow reducer writes the octet value for each user_id 4  Experimental Results In order to evaluate the performance of flow analysis with MapReduce, a small Hadoop testbed including a master node and four data nodes is built up. Each node has quad-core 2.83 GHz CPU, 4 GB memory and 1.5 TB hard disk. HDFS is used as the distributed file system. All Hadoop nodes are connected with Gigabit Ethernet cards Flow-tools are used to collect NetFlow v5 packets sent by a router. Then, exported flows are saved into a file every five minutes. Flow data on a network consisting of 100 interfaces was captured for months, and a few TB of traffic data was collected to test the performance of the program The performance of traditional database applications was compared with that of MapReduce program. The experiments showed that the MapReduce program performance has been greatly improved when the data amount changed from a few GB to a few TB Additionally, we test the hive framework. Hive provides a query language, HiveQL, that is similar to SQL and more general than the Pig query language. All data sets processed by Hive are exposed as tables. These tables can be processed by selection, insertion, joining or other operations which are often associated with relational algebra. For example, a Hive query can be written like this way  SELECT flows.src_addr, SUM \(flows.packets\ SUM flows.bytes\ FROM flows GROUP BY flows.src_addr   Similarly to SQL, Hive supports grouping of records and calculating sums and record counts for the aggregated data, a feature that has been utilized in the example above. The listing above also illustrates the similarity between SQL and HiveQL, and shows that HiveQL can be considerably less verbose than Pig Latin. Although it is not shown in the example, Hive also allows filtering, sorting and limiting of the result set 5  Conclusions This paper proposes a Cloud Platform for large-scale network analysis. It exploits HDFS and DataX to deal with the storage of heterogeneous big data. And the MapReduce model is applied to concurrently compute the analyzing and correlating on large amount of network flow data. Experimental results shows that the performance of the platform is greatly improved compared with the traditional RDBMS application Acknowledgments This work is supported by Innovation Action Plan supported by Science and Technology Commission of Shanghai Municipality \(No.11511500200 References 1  An Internet traffic analysis method with MapReduce, In proceeding of: Network Operations and Management Symposium Workshops, 2010, P357-361 2  http://code.taobao.org/p datax/wiki/index/ 2013 3  http://en.wikipedia.org/wiki/NetFlow/ 2013 4  http://hadoop.apache.org 5  Distributed NetFlow Processing Using the Map-Reduce Model,http://ntnu.divaportal.org/smash/get/diva2:35247 2/FULLTEXT01 262 


Deep Zoom Pyramid Building 388 frames of stitched images 219GB 2 bytes per pixel 593 MB 6,596 folders 2,476,683 files; 151 GB JPG file format 2-18KB per file B  Computer Hardware and Software Characteristics We ran the benchmarks on the NIST Raritan cluster and on a desktop computer. Table 4 summarizes the cluster and desktop hardware and software specifications. The cluster nodes differ in terms of CPU speed and RAM, and are allocated to jobs based on the requested resources in a Portable Batch System \(PBS script. We installed Hadoop and Java 1.7 on the cluster to support Java code execution and Java Remote Method Invocation \(RMI\he desktop computer had similar software configuration to the cluster  Table 4. NIST Raritan cluster and test desktop characteristics  Specs Cluster Desktop Hardware Cluster Nodes 800 computer nodes having from 2 to 16 virtual processors with 4 to 32GB of RAM Intel Xeon @ 2GHz 6 cores, 64GB of RAM and hyper threading activated Networking 1Gbit/second  Software Java Virtual Machine Java version 1.7.0_17 Java\(TM\E Runtime Environment \(build 1.7.0_17-b02 Java HotSpot\(TM 64-Bit Server VM build 23.7-b01 mixed mode Java version 1.7.0_15 Java\(TM\E Runtime Environment \(build 1.7.0_15-b03 Java HotSpot\(TM 64-Bit Server VM build 23.7-b01 mixed mode Hadoop hadoop-2.0.3-alpha Operating System CentOS 5.9 Linux 2.6.18274.3.1.el5 x86_64 Ubuntu 12.10 Linux 3.5.0-28generic x86_64 File System Lustre parallel distributed file system ext4 on top of Logical Volume Manager \(LVM  C  Characteristics of Image Processing Benchmarking Software All four computations were implemented as independent Java libraries and used on the desktop, Java RMI and Hadoop cluster platforms. Thus the same image processing code is invoked regardless of the platform. The desktop implementation is a Java program starting a fixed number of threads \(specified on the command line\ using a fixed thread pool. One image is processed by each thread. As soon as a thread has finished processing an image, it starts processing a new image The Java RMI Application Programming Interface API\nvokes methods on remote computers \(i.e., on the cluster nodes\We build a simple job scheduler with a client-server architecture using the Java RMI API. The Java RMI-based server provides a method to fetch the next image to process. When a client node has finished processing an image, it notifies the server with another RMI call and fetches the next image to pro cess. Similar to the desktop implementation, the client node s can run multiple threads one per image In order to invoke the four image processing computations from Hadoop, we implemented a new Hadoop FileInputFormat named ImageInputFormat. This class reads an image file from HDFS and submits it as a map task input The map tasks then retr ieve a BufferedImage from the ImageInputFormat and pass it to the processing implementations. Once the processing is done, the result is saved back to HDFS directly from the map task. Thus, the jobs do not have any reduce task. The design of our Hadoop implementation leverages Hadoop data and computation colocation as summarized in Table 5. The key differences among the three platform-specifi c implementations lie in the computational elasticity associated with each platform and in the locality of the data and computation. We have observed on average 98.4% of tasks getting input data from local node for image segmentation and 99.8% of tasks for flat field correction computations except accessing two common files from HDFS Table 5.  Characteristics of co mputational elasticity and data computation collocation for the three experimental platforms Computational Platform Computational Elasticity Data & Compute Collocation Desktop Low limited by the RAM and CPU of the executing computer Yes: all data are on a local disk Java Remote Method Invocation RMI\/Raritan Cluster High nodes can be requested as needed No: all data are transferred over network to the computing node Hadoop/Raritan Cluster High nodes can be requested as needed Yes with high probability: After pushing 3 data replicas to HDFS Hadoop launches computations where the data are D  Benchmark and Baseline Runs We have documented the following samples in the space of image processing computations, and hardware and software configurations applied to the selected data set  Four image processing computations described in Table 1 and the Terasort computation from the Apache Hadoop test suite [4  Raritan hardware cluster configurations used for computations \(8 virtual processors @2.5 GHz available per node with local storage:  >100GB o  Number of client nodes: 5, 10, 20, 30, 40, 50 60 o  RAM on cluster nodes: 16GB \(Segmentation Java RMI\, 24GB \(Feature extraction\ 32GB RAM \(all other computations  Raritan software cluster configurations used for computations 733 


o  Cluster computation management: Simple Java RMI server started with PBS script or Hadoop middleware o  Number of map tasks per node: 1 \(all computations\ 2 \( Pyramid building  Desktop software configurations o  Number of threads: 1 \(all computations Feature extraction\5,10,12,16 \(Pyramid The numerical results are shown in Figure 1 through 6 Figure 1 sets our desktop baseline and represents run times of processing a Terabyte volume on a desktop with a 6-core CPU and 64GB of RAM  Figure 2 compares flat field correction with Teragen on the Hadoop Raritan cluster since both image and text operations are very I/O intensive. Figure 3 shows image segmentation and Terasort computations executed on the Raritan cluster for the same input file sizes and file numbers. The image spatial filtering \(kernel multip lications of an image matrix and sorting \(number/word comp arisons key discriminators between image and text processing Figure 4 illustrates the comparis on of Hadoop and Java RMI based management of the Raritan cluster for image pyramid building in terms of the numb er of parallel processes. The map tasks in Hadoop and the number of threads per node in Java RMI show similar performance with Hadoop outperforming Java RMI for larger number of nodes. Figure 5 and Figure 6 focus on run time decomposition of pyramid building and feature extraction computations to understand the overheads and gains for various cluster configurations The overhead of pushing data to HDFS in Hadoop could be minimized by running multiple computations on the same data over many nodes since the Hadoop-based computation is only slightly outperforming the Java RMI based computation \(~9% at 60 nodes, feature extraction By way of an aside, the numerical results in the graphs are reported for the number of client nodes that were allocated by the Raritan cluster. Thus, the number of requested nodes was higher than the number shown in the figures below. Computations that deal with a large number of small input files \(flat fiel d correction\ or output files pyramid building\ were programmed to package the files by either tarring them or creating a serialized Hadoop Sequence File for better I/O efficiency  Figure 1: Pyramid and feature extraction computations executed on a 6 core desktop with various number of threads. Feature extraction with more than 2 threads is limited by the desktop RAM size equal to 65GB \(each feature extraction job requires more than 24GB of RAM  Figure 2: Flat field correction \(FFC\mputation executed on the Hadoop Raritan cluster and compared to Teragen that generates the same number of files as FFC  Figure 3: Image segmentation and Terasort computations executed on Raritan cluster for the same input file sizes and file numbers. The Hadoop execution \(blue\ outperforms RMI execution \(red\more than 10 nodes and is faster than the Terasort computation. All power approximations have a residual R 2 higher than 0.949 indicating a very good fit 734 


 Figure 4: Pyramid computation executed on the Hadoop Raritan cluster with one or two map tasks per node and on the Java RMI cluster with one or two threads per node. Hadoop with K map tasks outperforms Java RMI with the same number of K threads for more than 25 nodes \(K=1 nodes \(K=2   Figure 5 Pyramid computation executed on the Hadoop Raritan cluster with one or two map tasks per node and presented with 5 contributions to each run time The key benefit of launching multiple map tasks is the reduction of the pyramid building time green color bars  Figure 6: Feature extraction executed on the Raritan cluster using Hadoop solid green line\and Java RMI \(dashed orange line using Hadoop is slightly faster than using Java RMI if the overhead of pushing data to HDFS is viewed as a one-time overhead.  All power approximations have a residual R 2 higher than 0.9778 indicating a very good fit E  Computational Reliability In our case, running benchmarks for image processing operations has also served the purpose of stress testing the Raritan Hadoop cluster.  By default, Hadoop middleware has a built-in mechanism for handling possible hardware failures or straggler tasks through speculative execution  have used t h e defaul t speculative execution setting and documented the errors of failed executions. The NIST Raritan cluster is quite hetero geneous. Although we did not observe single straggler tasks, we have encountered task failures due to the entire system overload such as many tasks failing at the same time, SSH connection closed as a function of possible network overload, socket timeout exception from Hadoop or sometimes failing to push data to HDFS without a notification. Future stress tests for image processing computations can be designed for the users running image processing on Hadoop clusters similar to the analyses reported based on text 35  F  Relative Efficiency of Image Processing Computations As the number of nodes in the cluster increases computations can be run in sh orter amounts of time, but the efficiency of computation naturally decreases. We adopted Am e asuri ng parallel efficiency and computed the relative efficiency of cluster computations elapsed time for 1 worker/client divided by the multiplication of M workers and elapsed time for M workers\ Our modification is introduced on the right side of Equation \(3\wo reasons. First, benchmarking of image processing computations is very time consuming when using only one node of a cluster. For all practical purposes, users should be able to compute the parallel efficiency based on the elapsed run time on any small number of cluster nodes. Second, each benchmark has an inherent temporal uncertainty due to variable system loads no matter how many times the execution is re-run. Relative efficiency values larger than one do not have practical meaning and can be avoided by considering the minimum sample for the numerator of the following equation  1 L RELATIVE M M TLT E M TMT 3 Here 1 T is the run time on a single cluster node M T is the runtime on M nodes where M is in the sample set of working nodes of size NumSamples 1  NumSamples ii Mw  and L T is the runtime on the number of L cluster nodes for which min LM M LT M T Ideally, the parallel efficiency would be always one for any number of nodes. The efficiency formula can also be extended in the future to include power considerations  M o dified relative efficiency coefficients for all four image processing and Terasort computations are reported in Figure 7 735 


 Figure 7: Modified relative efficiency computed for all sample points  Based on the results in Figure 7, we computed a cluster computing suitability score S per computation configuration according to Equation \(4\is an average of deviations from the ideal relative efficiency \(equal to one  1 1 1 1 NumSamples CONFIG CONFIG RELATIVE i SEi NumSamples 4 According to the scores shown in Figure 8, the majority of image processing operations executed on a Hadoop cluster outperformed their corresponding benchmarks run on Java RMI clusters or compared against number/text sorting computations for the same input file sizes IV  S UMMARY  There is a lack of algorithms for processing Giga to Terabyte-sized images that can leverage very powerful parallel and distributed hardw are architectures such as Hadoop clusters. We have researched four image processing algorithms and the corresponding Hadoop infrastructure for running these algorithms on Hadoop clusters. The software enabled \(a e characterization of a Hadoop cluster against several baseline measurements, and \(b\ent of relative efficiency of image processing computation running on a cluster and their suitability for Hadoop platforms. The research also serves as a potential contribution to the suite of be nchmark and stress tests for the Apache Hadoop project and to a future development of a standard for big image data processing on distributed platforms.  Similar results to those showed in Figure 8 could be developed as reference measurements to aid cluster performance ‘calibration’ across smaller groups and larger institutions or to assess benefits of cluster configurations for various computation types We concluded that image processing operations benefit from scalability on a Hadoop cluster because of the computational elasticity of cluster platforms and the collocation of data and computation in Hadoop. The spatial extent of image processing operations defined the data access pattern during many computations. It was a factor for the RAM requirements per node since a half GB size files had to be loaded without subdividing the input images. On the other side, close to one hundred images as inputs \(flat field correction\4 million images as outputs \(pyramid pose challenges on efficient data transmission to the cluster nodes, and handling I/O operations. Image processing on a Hadoop cluster would not be efficient without additional considerations of RAM requirements, data transmission packaging and I/O tasks, and therefore a Hadoop infrastructure for benchmarking image analyses becomes important.  To illustrate this point, although the total runtime of all reported benchmarks was about 95 hours, the actual runtime was about three times as much due to test replicates of runs, configuration efficiency experimentations and failed computations In the future, we plan to design specific stress tests for image processing computations running on Hadoop clusters. Our aim is to make the transitions from a desktop solution for image processing to a solution running on Hadoop cluster hardware architectures much easier for all scientists   Figure 8. Computation and configuration ranking according to the cluster computation efficiency score. Lower scores imply better cluster computing suitability V  A CKNOWLEDGMENT  This work was sponsored by NIST as a part of the Computational Science in Biol ogical Metrology project. We would like to acknowledge all project team members for their contributions VI  D ISCLAIMER  Commercial products are identified in this document in order to specify the experime ntal procedure adequately Such identification is not intended to imply recommendation or endorsement by the National Institute of Standards and Technology, nor is it intended to imply that the products identified are necessa rily the best available for the purpose VII  R EFERENCES    E E. Schadt, M. D. Linder m an J. Sorenson, L. Lee, and G. P Nolan, “Computational solutions to large-scale data management 736 


and analysis Nature reviews. Genetics vol. 11, no. 9, pp. 647 57, Sep. 2010   Xy ratex, “Using Lustre with Apache Hadoop,” 2010. [O nline Available http://wiki.lustre.org/images/1/1b/Hadoop_wp_v0.4.2.pdf Accessed: 31-May  O. O. Malley TeraBy t e So rt on Apache Hadoop,” 200 8  m a rk.org/Y a hooHadoop.p df Accessed: 31-May  O O Malley  Hadoop Benchm ar king in Workshop on Big Data Benchmarking 2012, no. May, pp. 1–13   Apache, “Hadoop Bench m arking Code Grepcode 2013 Online]. Available http://grepcode.com/file/repository.cloudera.com/content/reposito ries/releases/org.apache.hadoop/hadoop-test/0.20.2cdh3u0/org/apache/hadoop/mapred. [Accessed: 31-Ma   I N TEL, “Optim izing Hadoop  Deploym ents,” 2010. [Online  Available http://software.intel.com/sites/default/files/m/f/4/3/2/f/31124Optimizing_Hadoop_2010_final.pdf. [Accessed: 31-May   M. Stonebreake r  D. Abadi D. J  De witt, S  Madden, E  Paulson A. Pavlo, and A. Rasin, “MapReduce and Parallel DBMSs  Friends or Foes  Communications of the ACM vol. 53, no. 1 2010   P. Kent, “Hadoop Bench m arki ng from a SAS Perspective,” in Workshop on Big Data Benchmarking 2012, pp. 1–9   R. Jones, “NetPerf Bench m ark, Computer Program,” 2013  erf.org/netperf/. [Accessed 31-May    W  D Nor c ott and D. Capps Iozone Filesystem Benchmark 2013. [Onlin ailable http://www.iozone.org/docs/IOzone_msword_98.pdf. [Accessed 31-May    D. Heger, “Hadoop Perform ance Tu ning - A Prag m a tic  Iterative Available http://www.cmg.org/measureit/issues/mit97/m_97_3.pdf Accessed: 31-May  F. Ah m a d  S. Le e M Tothenthodi, and T. N. Vijay ku m a r PUMA Purdue MapReduce Benchmarks Suite, Tech. Report 2012. [Onlin ailable http://web.ics.purdue.edu/~fahmad/benchmarks.htm. [Accessed 31-May    M. H. Al m e er Cloud Hadoo p Map Reduce For Rem o te Sensing Image Analysis Journal of Emerging Trends in Computing and Information Sciences vol. 3, no. 4, pp. 637–644, 2012   C. Ny berg M. Shah, and N. Govindar a ju, “Sor t Benchm ar k W e b  http://sortbench m ark.org Accessed: 15-May  Google, “Google I/O conference Google’s developer conference 2012. [Online]. Available http://www.engadget.com/event/googleio2012/articles Accessed: 05-May  J. Lawrence, S. Arietta, C Sweeney  and L. Liu, “Hadoop Im age Processing Interface, Computer Program Available: http://hipi.cs.virginia.edu/about.html. [Accessed: 31May    W  Rasband, “Im a geJ Fiji & I m ag eJA & I m ageJ2, C o m puter Program ble  http://rsbweb.nih.gov/ij Accessed: 15-May  Bioim ageXD, Com puter Pr ogr am  2013. [Onli n e Av ailable http://www.bioimagexd.net   T. Plunkett M A Sick, and J. Su, “Cloud Analy tics To ols by  Serene Software Inc SBIR DOD/OSD 2010. [Online Available: http://www.sbir.gov/sbirsearch/detail/13117 Accessed: 15May  A. A  Di m a  J T Elliott, J J. Fillibe n M Halte r A. P e skin, J Bernal, M. Kociolek, M. C. Brady, H. C. Tang, and A. L. Plant Comparison of segmentation algorithms for fluorescence microscopy images of cells Cytometry. Part A: the journal of the International Society for Analytical Cytology vol. 79, no. 7 pp. 545–59, Jul. 2011   S. Philip, B Su mm a  P. B r e m er an d V. Pascucci  P a r allel Gradient Domain Processing of Massive Images,” in Eurographics Symposium on Parallel Graphics and Visualization 2011 2011, p. 9   M. D   Theys R M  Born M. D  Al le m a ng, and H J. Si ege Morphological Image Processing on Three Parallel Machines in Frontiers of Massively Parallel Computing, Sixth Symposium  1996, pp. 327–334   C. Bakal, J. Aach G. Church, and N   Perri m on Q uantitative morphological signatures define local signaling networks regulating cell morphology Science \(New York, N.Y vol. 316 no. 5832, pp. 1753–6, Jun. 2007   K. Huang and R. F  Murphy F ro m q u antitative m icrosc opy to automated image understanding Journal of biomedical optics  vol. 9, no. 5, pp. 893–912, 2004   N. Or lov, L. Sham ir  T M acur a J. Johnston, D. M   Eckley and I   G. Goldberg, “WND-CHARM: Multi-purpose image classification using compound image transforms Pattern Recognition Letters vol. 29, no. 11, pp. 1684–1693, Aug. 2008   M.-K Hu, “Visual Pattern Recognition by Mo m e nt Invariants IRE Transactions on Information Theory pp. 179–188, 1962   R. M. Haralick M. Shan m ugan, and I. Dinstein, “Textural features for Image Classification IEEE Transactions on Systems, Man and Cybernetics vol. SMC-3, no. 6, pp. 610–621 1973   Y. Sae y s I Inza a nd P Larrañaga, “A review of feature selection techniques in bioinformatics Bioinformatics \(Oxford England vol. 23, no. 19, pp. 2507–17, Oct. 2007   Microsoft, “Deep Zoo m Silverlight  Microsoft Developer Network \(MSDN 2010. [Onlin ailable http://msdn.microsoft.com/en-us/library/cc645050\(v=vs.95 Accessed: 27-May Open Seadragon  Open Seadragon project 2013. [On Available: http://openseadragon.codeplex.com/. [Accessed: 15May    R. Kooper and P Bajcsy   C o m putat ional Scalability of Large  Size Image Dissemination,” in IS&T/SPIE Electronic Imaging  2011, pp. 7872–23   R. Kooper, P  Bajc sy, and N   M Hernández S titching Giga Pixel Images Using Parallel Computing,” in IS&T/SPIE Electronic Imaging 2011, pp. 7872–17   Yahoo Hadoop Tutor i al fr o m  Yahoo  On-Line Tutorial  2013. [Onlin ailable http://developer.yahoo.com/hadoop/tutorial/module4.html Accessed: 14-May  R. Dudko, A. Sharm a and J. Tedesco, “Effective Failure Prediction in Hadoop Clusters,” 2012 l e https://wiki.engr.illinois.edu/download/attachments/195766887/J AR-2nd.pdf?version=3&modi ficationDate=1333424381000 Accessed: 31-May  E. Bor tnikov, A Fr ank, K Tivon, and E. Hillel, “Predicting Execution Bottlenecks in Map-Reduce Clusters Available https://www.usenix.org/system/files/conference/hotcloud12/hotcl oud12-final50.pdf. [Accessed: 31-May  I Foster Designing and Building Parallel Programs Chicago IL ADDISON WESLEY Publishing Company Incorporated 1995, p. 381   D H  W oo and H  S Lee Extending Am dahl s  Law for Ener gyEfficient Computing in the Many-Core Era IEEE Computer pp 24–32, 2008    737 


  10  te m p e r a tu r e  s e n s o r  pol ynom i a l  i s  0 9977  w hi l e  t he  R 2   fo r  t h e  ba s e pl a t e  t e m pe r a t ur e  s e ns or  pol ynom i a l  i s  0 9984   Ta b l e  8  pr e s e nt s  t he  pol ynom i a l  c oe f f i c i e nt s     Fi g u r e  14  q ue nc y  H z    Te m p e r a t u r e  d  Ce l s i u s   f o r  A u x i l i a r y  O s c i l l a t o r  a n d  Ba s e p l a t e   Ta b l e  8  Co e f f i c i e n t s  fo r  F r e q u e n c y  v s  T e m p e r a t u r e  Po l y n o m i a l s    Al t h o u g h  t h e  h i g h  R 2  va l ue s  s e e m  t o pr ovi de  r e a s on f or  co n f i d en ce i n  t h es e t em p er at u r e p r ed i ct i o n s   t h e E D L  th e r m a l e n v ir o n m e n t d if f e r s  n o ta b ly  f r o m  th a t in  c r u is e  St e a d y  t e m p e r a t u r e s  a n d  t h e r m a l  e q u i l i b r i u m  c h a r a c t e r i z e  th e  c r u is e  th e r m a l e n v ir o n m e n t  T h e  E D L  th e r m a l i ro n m e n t  i s  c h a ra c t e ri z e d  b y  ra p i d  h e a t i n g    A s  a  re s u l t   th e  S D S T  a n d  its  in te r n a l c o m p o n e n ts  w e r e  n o t in  th e r m a l eq u i l i b r i u m  d u r i n g  E D L   In  t h e rm a l  e q ui l i br i um   a s  s how n  Fi g u r e  15  be l ow   t he  A U X  O S C  i s  nor m a l l y s om e w ha t  wa r m e r  t h a n  t h e  b a s e p l a t e    Ho we v e r   a s  Fi g u r e  15   sh o w s  d u r i n g  E D L   t h e  b a se p l a t e  t e m p e r a t u r e  r o se  re l a t i v e l y  q u i c k l y  a n d  ra p i d l y  o v e rs h o t  t h e  A U X  O S C  te m p e r a tu r e   A lth o u g h  A U X  O S C  te m p e r a tu r e  r o s e  s lo w ly  to   c a tc h  u p   w ith  b a s e p la te  te m p e r a tu r e  th e  S D S T  w a s  n o t in  th e r m a l e q u ilib r iu m  d u r in g  E D L   T h is  im p a c ts  th e  accu r acy  o f  an y  f r eq u en cy  p r ed i ct i o n s  b as ed  o n  b as ep l at e te m p e r a tu r e     15  MS L  E D L  S D S T  T e m p e r a t u r e s  S 34 S 45 34 m y  a  As  a  b a c k up t o t he  pr i m e  70 m a n t e n n a   D S S 43   t he  si g n a l s f r o m  a b eam  w av eg u i d e  34 m a n t e n n a s   D S S 34    a h i g h  ef f i ci en cy  3 4 m a n t e n n a   S 45  w e r e  co m b i n ed  an d  r eco r d ed    k up  da t a  w a s  not  ne e de d in r e a l  d  wa s  a n a l y z e d  i n  p o s t ng  Di r e c t to h   re c e i v e d  b y  t h e  D S S S y dur i ng M S L  E D L  i s  s how n i n  Fi g u r e  16   Av e r a g e  c er to noi s e  pow e r   P c N o  p l o t t e d  i n  l i g h t  b l u e  m e a s u re d  by th e  E D A  us i ng t he  D S S S 45 a r r a y dur i ng E D L  w a s  dB     Fi g u r e  16  MS L  E D L  P c N o P e N o a n d R e s id u a l Fr e q u e n c y  w i t h  D SS S y  An t e n n a  se n si t i v i t y  i s m e a su r e d  b y  T  w h e r e  G  is   an t en n a g ai n   an d  T  is  th e  s y s te m   te m p e r a tu r e   G   fu n c t i o n  o f w a v e l e n g t h     phys i c a l  a pe r t ur e  a r e a   A p   ap er t u r e ef f i ci en cy     as  s h o w n  b el o w                    6    Ba s e d  s o l e l y  o n   ap er t u r e  ea  A p    T   a  34 m a n t e n n a  is  a b o u t 1 7  0  1 7  0  3 5  0  3 5    6   T   0   Ho we v e r   t h e  N 70 m a n t e n n a  al s o  h as  b et t er  ap er t u r e ef f i ci en cy     a n d  a  lo w e r  s y s te m  noi s e  t e m pe r a t ur e   T  th a n  th e  D S N  3 4 e    th e s e  f a c to r s  c o n s id e r e d  th e  T  of  a  D S N  34 m a n t e n n a  i s  ab o u t  1 8   t h e T  of  a  D S N  70 m a n t e n n a  8    pr e di c t e d di f f e r e nc e  i n a r r a y ga i n be t w e e n t he  70  an d  t w o  ar r ay ed  3 4 m a n t e n n a s  i s  10 g 10   1 0   18  18    4 44  dB   a s s um i ng no c om bi ni ng l os s   P c N o  is  p r o p o r tio n a l  T   Th e  m e a s u r e d  d i f f e r e n c e  i n  P c N o   S S S n  17   Th e  m e a n  m e a s u r e d  d i f f e r e n c e  f r o m  E 645 s e c onds  t o E 2 9 9  s e c o n d s  w a s  4  2 6  d B   Th e r e f o r e  m e a n  c o m b i n i n g  lo s s d u r in g th is tim e w a s  ab o u t  0  1 8                      0 1 23 45''67626 84  3 6 9 2 7 7    6593 9\(:6 562\(6\(2'47   0        0 1 5'695\(95 87 7 3 5   4 7 5 2  97599 562\(6\(&765 


  11   Fi g u r e  17  e re n c e  i n  D S S 43 a nd D S S S P c N o   Af t e r  E DL   E v e n t  R e c o r d s   E VR s   t h a t  l o g g e d  e a c h  t o n e  is s u e d  d u r in g  E D L  w e r e  obt a i ne d f r om  M S L   Th e s e  l o g s  we r e  c o m p a r e d  wi t h  t h e  r e a l tim e  r e s u lts  p r o v id e d  b y  th e  ED A  t o  d e t e r m i n e  p e r f o r m a n c e    Th e  D TE c o m m u n i c a t i o n s  sy st e m  r e c e i v e d  a n d  c o r r e c t l y  i d e n t i f i e d  1 0 0   o f  ra d i a t e d   i n r e a l tim e  d u r in g  M S L  E D L   Th e s e  r e s u l t s  a r e  co n s i s t en t  w i t h  t h e t h eo r et i cal  pr oba bi l i t i e s  of  c a r r i e r  acq u i s i t i o n  t r ack i n g  an d  d at a t o n e d et ect i o n  co m p u t ed  i n  Se c t i o n  3   5   C ON   Th e  D i r e c t to Ea r t h  X ba nd c om m uni c a t i ons  s ys t e m  ut i l i z e d dur i ng M S L  E D L  s uc c e s s f ul l y de t e c t e d a l l  ra d i a t e d   de s pi t e  c ha l l e ngi ng s i gna l  dyna m i cs  w i t h  l ar g e u n k n o w n  ch an g es  i n  D o p p l er  f r eq u en cy   r at e  an d  accel er at i o n   Fu t u r e  m i s s i o n s  w i t h  p e r i o d s  o f  r a p i d  a n d  u n k n o w n  s i g n a l  dyna m i c s  s uc h a s  Ma r s  o r  i c y  m o o n  la n d e r s  can  l ev er ag e fr o m  t h e  M S L  de s i gn f or  D T E  c om m uni c a t i ons    6   A CK NO W L E DG E M E NT S   T he  a ut hor s  w oul d l i ke  t o a c know l e dge  t he  c ont r i but i on s   Ja n  T a r sa l a   te s tin g  o f  th e  E D A  p r io r  to  M S L  E D L  us i ng a  P R S R  a nd M S L  t e s t be d    Th e  a u t h o r s  w o u l d   th a n k  J e r e m y  S r  fo r  p r o v i d i n g  6 D O F  s i m u l a t i o n  d a t a  th a t w a s  v a lu a b le  in  c o n f ig u r in g  th e  E D A   Th e  a u t h o r s  wo u l d  a l s o  l i k e  t o  t h a n k  t h e  C DS C C  s t a t i o n  p e r s o n n e l  f o r  th e ir  e x c e lle n t s u p p o r t a n d  ope r a t i ons  of  t he  D S N  eq u i p m en t  an d  t h e F u l l  S p ect r u m  P r o ces s o r  A r r ay  i n  u   Th i s  r e s e a r c h  w a s  c a r r i e d  o u t  a t  t h e  J e t  P r o p u l s i o n  La b o r a t o r y   C a l i f o r n i a  I n s t i t u t e  o f  Te c h n o l o g y    Co p y r i g h t  2012 C a l i f or ni a  I ns t i t ut e  of  T e c hnol ogy  Go v e r n m e n t  sp o n so r sh i p  a c k n o w l e d g e d     


  12  R EF ER EN C ES   1  E  S a t o r i u s   P   Es t a b r o o k   J   W i l s o n   D   F o rt    D i re c t to  Ea r t h  c o m m u n i c a t i o n s  a n d  s i g n a l  p r o c e s s i n g  f o r  M a r s  ex p l o r at i o n  r o v er  en t r y   d es cen t  an d  l an d i n g   T h e In t e rp l a n e t a ry  N e t w o rk  P ro g re s s  R e p o rt   IP N  P ro g re s s  Re p o r t  4 2 2003  2 A n d re  J o n g e l i n g  an d  S u s an  F i n l ey     M ar s  S ci en ce La b o r a t o r y  Te l e c o m  S y s t e m  En g i n e e r i n g  P r e  Re v i e w   E D L  D a t a  A n a l y s i s  S i m u l a t i o n s  Re s u l t s     A p r i l  24  2007   3 W   J   H u rd   P   E s t a b ro o k   C   S   R a c h o   a n d  E   S a t o ri u s   C r i t i cal  sp acecr af t to ear t h  co m m u n i cat i o n s   ex p l o r at i o n  r o v er   M E R   en t r y   d es cen t  an d  l an d i n g   Pr o c   I E E E  A e r o s p a c e  C o n f e r e n c e   v o l  3   p p   1 2 8 3  MT   Ma r c h  2 0 0 2    4 M  S o r i a n o   S   F i n l e y   A   J o n g e l i n g   D   F o r t   C   G o o d h a r t   D  R o g s t a d   R   Na v a r r o    Sp a c e c r a f t to Ea r t h  Co m m u n i c a t i o n s  fo r J u n o  a n d  M a rs  S c i e n c e  L a b o ra t o ry  Cr i t i c a l  E v e n t s   P r o c  I E E E  A e r o sp a c e  C o n f e r e n c e   M T   2   5 A   M a k o v s k y   P   Il l o t t   J   T a y l o r    M a rs  S c i e n c e  La b o r a t o r y  Te l e c o m m u n i c a t i o n s  S y s t e m  D e s i g n    D e e p  Sp a c e  C o m m u n i c a t i o n s  a n d  N a v i g a t i o n  Sy s t e m s  C e  of  E xc e l l e nc e  D e s i gn a nd P e r f or m a nc e  S um m a r y S e r i e s   No v e m b e r  2 0 0 9   6 M   S o ri a n o  a n d  P   E s t a b ro o k    M S L  E D L  S i m u l a t i o n s   i n t e rn a l  d o c u m e n t   J e t  P ro p u l s i o n  L a b o ra t o ry   P a s a d e n a   CA   M a y  7   2 0 1 2   7  Sa t o r i u s  R e v i s e d  T h r e s h o l d s  f o r  E D L    i n t e r n  doc um e nt    J e t  P r opul s i on L a bor a t or y  P a s a de na   C A   Ja n u a r y  1 4   2 0 0 3   8 A   K w o k     M o d u l e  2 0 6  Te l e m e t r y  G e n e r a l  In fo rm a t i o n    i n DS N  T e l e c o mmu n i c a t i o n s  L i n k  De s i g n  k B   D S N  N o  8 1 0 005   P a s a de na  Ca l i f o r n i a   J P L   Oc t o b e r  3 1   2 0 0 9  ht t p   e i s  j pl  na s a g o v d e e p s p a c e d s n d o c s 8 1 0 005     


  13  M el i s s a  S o r i a n o  ff f tw a r e  e n g in e e r  in  th e  T r a c k in g  Sy s t e m s  and A ppl i c at i ons  Se c t i on at  t he  J e t  P r opul s i on L abor at or y    She  has  de v e l ope d r e al  so f t w a re  f o r t To  co m m u n i ca t i o n s  w i t h  M a r s  Sc i e nc e  L abor at or y  dur i ng E nt r y   De s c e n t   a n d  L a n d i n g   th e  L o n g  W a v e le n g th  Ar r a y   N AS A s  Br e a d b o a r d  Ar r a y   a n d  t h e  W i d e b a n d  VL BI  S c i e n c e  Re c e i v e r  u s e d  i n  t h e  D e e p  S p a c e  N e t w o r k   Me l i s s a  i s  a l s o  cu r r en t l y t h e s o f t w a r e co g n i z a n t  en g i n eer  f o r  t h e D S C C  Do w n l i n k  A r r a y   She  has  a B  S   fr o m  C a lte c h  d o u b le  m a jo r  in  E le c tr ic a l a n d  C o m p ut e r  E ngi ne e r i ng and B us i ne s s  Ec o n o m i c s  a n d  M a n a g e m e n t    S h e  a l s o  h a s  a n  M  S    Co m p u t e r  S c i e n c e  fr o m G e o r g e M a so n  U n i v e rsi t y   Sus a n F i nl e y  is  a  k e y  s ta ff me mb e r  i n  t h e  P r o c e s s o r  S y s t e ms  De v e l o p me n t  Gr o u p  a t  J P L     is  th e  s u b s y s te m  e n g in e e r  fo r  th e  Fu ll S p e c tr u m  P r o c e s s o r  su b sy st e m  d e p l o y e d  i n  N A S A  s De e p  S p a c e  N e t w o r k     exp er i en ce i n cl u d es  t h e o p er a t i o n  of  t he  E D A  f or  bot h of  t he  M E R  l andi ngs  on M ar s  as  w e l l  as  th e  o p e r a tio n  o f th e  R a d io  S c ie n c e  R e c e iv e r  fo r  th e  la n d in g  o f th e  H u y g e n s  P r o b e  o n  T it an and f or  t he  P hoe ni x  l andi ng on s    Da v i d  t  re c e i v e d  a  B  A  S c  i n  En g i n e e r i n g  Ph y s i c s  a n d  M  S c  i n  As t r o n o m y  f r o m  t h e  U n i v e r s i t y  o f  To r o n t o  a n d  a n  M S c   a n d  P h  D   i n  Ra d i o  As t r o n o m y  f r o m  t h e  U n i v e r s i t y  of  M anc he s t e r    H e  j oi ne d N R C  C a n a d a  i n  1 9 7 2  a n d  w o r k e d  o n  a l l  as pe c t s  of  V L B I  unt i l  1987   H e  su b se q u e n t l y  j o i n e d  J P L  i n  se c t i o n  3 3 5  a n d  w o rk e d  o n  a  num be r  of  har dw ar e  and s of t w ar e  pr oj e c t s  f or  t he   be c am e  s upe r v i s or  of  t he  P r oc e s s or  Sy s t e m s  de v e l opm e nt  Gr o u p  f o r  t h e  t w o  y e a r s  p r i o r  t o  r e t u r n i n g  t o  N R C  i n  2 0 0 2   Un t i l  h i s  r e t i r e me n t  i n  2 0 1 0  h e  w o r k e d  o n   Co r r e l a t o r  P r o j e c t    No w a   G u e s t  W o r k e r    h e  h e l p s  o u t  wi t h  t h e  E V L A  a s  i t  b e c o m e s f u l l y  o p e ra t i o n a l  a n d  w i t h  oc c as i onal  que s t i ons  f r om  J P L    Br i a n  S c h r a t z  is  th e  le a d  e n g in e e r  fo r  th e  E D L  te le c o m m u n ic a tio n s  o n  th e  Ma r s  S c i e n c e  L a b o r a t o r y  m i s s i o n  a n d  a m e m be r  of  J P L  s  C om m uni c at i ons  Sy s t e m s  and O pe r at i ons  gr oup      jo in e d  J P L  th r e e  y e a r s  a g o   B S  E E  a n d  M  S  E E   Pe nns y l v ani a St at e  U ni v e r s i t y    Pe t e r  I l o t t  is  th e  te le c o m m u n ic a tio n s  sy st e m  l e a d  f o r t h e  M S L  m i ssi o n   H e  has  w or k e d on s pac e c r af t  te le c o m m u n ic a tio n s  s y s te m  d e s ig n  fo r  2 5  y e a r s  1 1  y e a r s  o n  c o m m e r c ia l sp a c e c ra f t   a n d  si n c e  2 0 0 0  a t  J P L    wo r k e d  o n  M E R   P h o e a te le c o m m u n ic a tio n s  s y s te m  e n g in e e r  Pe t e r  w o r k e d  o n  a l l  t h e  M a r s  ED L   e n t r y  and la n d in g   e ffo r ts  s in c e  M E R  a n d  in  b e tw e e n  M a r s  m is s io n s  he l pe d out  on t he  D e e p I m pac t  and C l oudat  mi s s i o n s  a t  J P L   He  c u r r e n t l y  s u p p o r t s  t h e  M S L  s u r f a c e  mi s s i o n  p h a s e   a n d  i s  th e  te le c o m m u n ic a tio n s  le a d  fo r  th e  E u r o p a  m is s io n  cu r r en t l y u n d er  s t u d y  I l o t t  h o l d s  B S c  M S c  a n d  P h D  de gr e e s  i n phy s i c s  and e l e c t r i c al  en g i n eer i n g  f r o m  M cG i l l  i st y  o f  M o n t re a l    i  re c e i v e d  t h e  B  S  E  E   and t he  M  S E  E   i n 1997 and t he  Ph  D   i n  El e c t r i c a l  En g i n e e r i n g  i n  2003  al l  f r om  U C L A    He  h a s  b e e n  em p l o yed  a t  t h e Jet  P r o p u l s i o n  La b o r a t o r y  a s  a  Te l e c o m m u n i c  en g i n eer  s i n ce 1 9 9 9  a n d  h a s  s er ved  on t he  M ar s  E x pl or at i on R ov e r   DA W N   C a s s i n i   J u n o   a n d  M a r s  Sc i e nc e  L abor at or y  pr oj e c t s     Po l l y  E s t a b r o o k  is  th e  d e p u ty  ma n a g e r  o f  t h e  C o mmu n i c a t i o n  Ar c h i t e c t u r e s  a n d  Re s e a r c h  S e c t i o n  at  J P L     She  i s  a m e m be r  o f N A S A  s  Spac e  C om m uni c at i on and Na v i g a t i o n  P r o g r a m  s u p p o r t i n g  t h e  de f i ni t i on of  t he  N A SA  s  f ut ur e  In t e g r a t e d  C o m m u n i c a t i o n  a n d  Na v i g a t i o n  Ne t wo r k  a n d  i s  a  m e m b e r  o f  t h e  I n t e g r a t e d  Sy s t e m  E ngi ne e r i ng t e am  f or  t he  M ar s  Sc i e nc e  L abor at or y  r   Fr o m  2 0 0 5  t o 2010  s he  l e d s e v e r al  c om m uni c at i on sy st e m  d e si g n  t e a m s w i t h  t h e  g o a l  o f  d e f i n i n g  t h e  mo d i f i c a t i o n s  t o  N A S A  s  S p a c e  C o mmu n i c a t i o n  a n d  Na v i g a t i o n  i n f r a s t r u c t u r e  n e e d e d  t o  s u p p o r t  t h e  p l a n n e d  hum an m i s s i ons  t o t he  M oon and M ar s   F r om  2000 t o 2004 sh e  w a s t he  l e ad t e l e c om  s y s t e m  e ngi ne e r  f or  t he  M ar s  Ex p l o r a t i o n  Pr o j e c t   r e s p o n s i b l e  f o r  t h e  p e r f o r m a n c e  o f  t h e  en t r y d es cen t  a n d  l a n d i n g  t el eco m m u n i ca t i o n s  s ys t em  a n d  fo r  th e  o v e r a ll d e s ig n  a n d  p e r fo r m a n c e  o f th e  D ir e c t to  Ea r t h  a n d  r e l a y  c o m m u n i c a t i o n s  s y s t e m s   In  2 0 0 4   D r   Es t a b r o o k  r e c e i v e d  t h e  N AS A Ex c e p t i o n a l  Ac h i e v e m e n t  Me d a l  f o r  h e r  w o r k  o n  t h e  Ma r s  E x p l o r a t i o n  R o v e r  T e l e c o m  Sy s t e m   She  has  w r i t t e n ov e r  35 t e c hni c al  pape r s  and ch a i r ed  n u m er o u s  I E E E  a n d  A I A A  co n f er en ce S es s i o n s    Po l l y  Es t a b r o o k  r e c e i v e d  h e r B  A   i n  e n g i n e e ri n g  p h y si c s fr o m  th e  U n iv e r s ity  o f C a lifo r n ia  B e r k e le y  a n d  M S  a n d  Ph  D   d e g r e e s  i n  e l e c t r i c a l  e n g i n e e r i n g  f r o m  S t a n f o r d  Un i v e r s i t y   S t a n f o r d   C A      


  14  Ka m a l  O u d r h i r i  is  a  s e n io r  r  in  th e  R a d io  S c ie n c e  Sy s t e m s  G r oup at  NA S A  s  J e t  Pr o p u l s i o n  L a b o r a t o r y   As  a co n t r a ct  t ech n i ca l  m a n a g er   Ou d r h i r i  lti di s c i pl i nar y  te a m s  th r o u g h  th e  de s i gn  im p le m e n ta tio n  a n d  d e liv e r y  of  flig h t h a r d w ar e  t o t he  r adi o sc i e n c e  c o m m u n i t y   Ov e r  t h e  l a s t  d e c a d e   Ou d r h i r i  se rv e d  i n  key r o l es  o n  m u l t i p l e N A S A  mi s s i o n s   T h e  M a r s  E x p l o r a t i o n  s  M E R   t h e  In t e r n a t i o n a l  C a s s i n i  m i s s i o n  t o  Sat ur n T he  GR A I L  l u n a r  mi s s i o n  a n d  T h e  M a r s  S c i e n c e  La b o r a t o r y     Da n i e l  K a h a n  is  a s e ni or  m e m be r  of  S ci en ce S ys t em s  G r o u p  at  NA S A  s  J e t  Pr o p u l s i o n  La b o r a t o r y   Ov e r  t h e  l a s t  ei g h t  yea r s   h e h a s  pr ov i de d e ngi ne e r i ng s uppor t  f or  t he  i o s c i e nc e  c om m uni t y   NA S A  m i s s i o n s   i n c l u d i n g  M a r s  G l o b a l  Sur v e y or   M ar s  R e c onnai s s anc e  Or b i t e r   th e  G R A I L  lu n a r  m is s io n  th e  In t e r n a t i o n a l  C a s s i n i  mi s s i o n  t o  S a t u r n   a n d  Ma r s  S c i e n c e  La b o r a t o r y   Ed g a r  H   S a t o r i u s  is  a  p r in c ip a l me mb e r  o f  t h e  t e c h n i c a l  s t a f f  i n  th e  F lig h t C o m m u n ic a tio n s  Sy s t e m s  Se c t i on of  t he  J e t  Pr o p u l s i o n  L a b   H e  p e r f o r m s  sy st e m s a n a l y si s i n   de v e l opm e nt  of  di gi t al  s i gnal  e ssi n g  a n d  c o m m u n i c a t i o n s sy st e m s w i t h  sp e c i f i c  a p p l i c a t i o n s t o  b l i n d  d e m o d u l a t i o n   di gi t al  di r e c t i on f i ndi ng and di gi t al  r e c e i v e r s   H e  has  publ i s he d ov e r  90 ar t i c l e s  and hol ds  t w o pat e nt s  i n t he  f i e l d of  di gi t al  s i gnal  pr oc e s s i ng and i t s  appl i c at i ons   I n a ddi t i on  he  i s  an A dj unc t  A s s oc i at e  P r of e s s or  at  t he  U ni v e r s i t y  of  Sout he r n C al i f or ni a w he r e  he  t e ac he s  di gi t al  s i gnal  pr oc e s s i ng c our s e s   H e  r e c e i v e d hi s  B  Sc   i n e ngi ne e r i ng fr o m  th e  U n iv e r s ity  o f C a lifo r n ia  L o s  A n g e le s  a n d  th e  M S  and P h D   de gr e e s  i n  el ect r i ca l  en g i n eer i n g  f r o m  t h e Ca l i f o r n i a  I n s t i t u t e  o f  T e c h n o l o g y   P a s a d e n a   Ca l i f o r n i a   


Example 2: Identifying Causal Factors CAUSAL FACTORS  Indicators – Data Element Methods – Identifying Context and Causes  Time of day  Date range \(month day  Aircraft type  Fix or coordinates  Originating airport  Destination airport  Weather notes We pinpoint the sequencing of flights on the IAH Junction Seven departure \(at CUZZZ\the specified wind conditions to find cases wher e a B737-900 at 20,000 feet precedes by 11 miles a B737-800 at 17,000 feet  Search related data sets including ASDI flight tracks, local traffic and congestion  Weather conditions for alter native causes \(winds aloft shear and convecti ve activity  Airline specific informati on \(repeated occurrence of event in aircraft type Big data gives us visibility into contextual factors even if specific data points are missing such as a specific date or route Big-data analytics gives us insight into unreported factors as well 


Example 3: Correlating Utilization and Delays  60 65 70 75 80 85 90 95 100 7 9 11 13 ONTIME DEPARTURE PERFORMANCE HOURS OF DAILY UTILIZATION 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Narrowbodies By Day of Week 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Widebodies by Day of Week Daily Utilization vs. On-time Departures January 2013 System Operations Correlation Coefficient -0.53 Includes AA, AC, AS B6 F9, FL, NK, UA, US VX and WN SOURCE masFlight \(masflight.com COMPARING OTP AND UTILIZATION 


 6.2 6.0 5.8 5.8 5.2 4.9 LGB JFK BOS MCO DCA FLL JetBlue Focus Average Daily Deps per Gate Used UTILIZATION BY HUB Example 4: Daily Utilization of Gates, by Hub Big-data analysis of different carriers daily departures per gate used SOURCE masFlight \(masflight.com June 1 through August 31, 2012 Gates with minimum 1x daily use 7.7 7.4 7.2 6.2 6.1 5.8 3.8 3.6 ORD LAX SFO EWR DEN IAH IAD CLE United Airlines Hubs Average Daily Deps per Gate Used 7.8 6.4 5.5 5.4 5.3 4.4 4.3 4.0 SEA SAN PDX ANC SFO GEG LAX SJC Alaska Airlines Hubs Average Daily Deps per Gate Used 7.2 6.9 6.8 6.4 5.0 2.7 ORD DFW LAX LGA MIA JFK American Hubs Average Daily Deps per Gate Used 7.2 6.9 6.6 4.9 4.2 CLT DCA PHL PHX BOS US Airways Hubs Average Daily Deps per Gate Used 6.6 5.9 5.5 4.7 MCO BWI ATL MKE AirTran Hubs Average Daily Deps per Gate Used ne pe 


Conclusions for Big Data in Aviation  Big-data transforms operational and commercial problems that were practically unsolvable using discrete data and on-premises hardware  Big data offers new insight into existing data by centralizing data acquisition and consolidation in the cloud and mining data sets efficiently  There is a rich portfolio of information that can feed aviation data analytics  Flight position, schedules, airport/gate, weather and government data sets offer incredible insight into the underlying causes of aviation inefficiency  Excessive size of each set forces analysts to consider cloud based architectures to store, link and mine the underlying information  When structured, validated and linked these data sources become significantly more compelling for applied research than they are individually  Today’s cloud based technologies offer a solution CONCLUSIONS 


Conclusions:  Our Approach  masFlight’s data warehouse and analysis methods provide a valuable example for others attempting to solve cloud based analytics of aviation data sets  masFlight’s hybrid architecture, consolidating secure data feeds in on-premises server installations and feeding structured data into the cloud for distribution, addresses the unique format, security and scale requirements of the industry  masFlight’s method is well suited for airline performance review competitive benchmarking, airport operations and schedule design and has demonstrated value in addressing real-world problems in airline and airport operations as well as government applications CONCLUSIONS 






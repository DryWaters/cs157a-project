Interactive Constrained Frequent-Pattern Mining System Carson Kai-Sang Leung The University of Manitoba Canada kleung@cs.umanitoba.ca Abstract Data mining refers to the search for implicit previously unknown and potentially useful information such as frequent patterns that might be embedded in data Most of the existing data mining algorithms do not allow users to express the patterns to be mined according to their intention via the use of constraints Consequently these unconstrained mining algorithms can yield numerous patterns that are not interesting to users Moreover data mining 
is supposed to be an exploratory process In this context we are working on a project with the objective of implementing an efìcient interactive human-centered system for mining frequent patterns that satisfy the user constraints In this paper we develop such a system called iCFP  for i nteractive mining of C onstrained F requent P atterns  Our developed system uses a tree-based mining framework In addition it i allows human users to impose a certain focus on the mining process ii provides users with feedback 
during the mining process and iii permits users to dynamically change their constraints during the process Keywords Data mining and knowledge discovery interactive system constraints constraint changes succinctness frequent sets FP-trees 1 Introduction Since its introduction 1 the prob lem of mining association rulesÑand the more general problem of nding frequent patternsÑfrom large databases has been the subject of numerous studies These studies can be broadly divided into two generations In the rst generation all studies focused either on performance issues e.g the Apriori 
framework 2 3 hashin g and se gme ntation 16  2 0   the tree-based framework 13 increm ental upd ating 8 9 or on functionality issues e.g extending the initial notion of association rules or frequent patterns to long patterns 4 quantitative and multi-dimensional rules 10 17  a s well as correlations and causal structures 7 23 Studies in this generation basically considered the data mining exercise in isolation On the other hand studies in the second generation explored how data mining can best interact with other key componentsÑsuch as the database management system 22 25 and the 
human user in the broader picture of knowledge discovery From this standpoint studies in the rst generation rely on a computational model where the mining system does almost everything and the user and/or the DBMS is un-engaged in the mining process Consequently this model provides little or no support for user focus e.g limiting the computation to what interests the user and user interaction e.g obtaining feedback from the computational model making dynamic changes to the mining parameters midstream However the support for both user focus and user inter 
action is necessary For instance in many real-life applications the user may have certain broad phenomena in mind on which to focus the mining e.g may want to nd expensive snack items Without user focus the user often needs to wait for a long time for numerous frequent patterns out of which only a tiny fraction may be interesting to the user This motivates the call for constrained mining  Moreover it is also not uncommon that even with broad phenomena in mind the user may need to modify the mining parameters/constraints e.g to slightly modify the price value that 
quantiìes the expensiveness of snack items during the mining process This is because an inappropriate choice e.g for the price value can yield either too many or too few interesting patterns This problem is worsened when lacking continuous feedback from the mining system as the user may not realize the inappropriateness of the parameters until the end of a possibly long wait This motivates the call for interactive mining  In addition for a mining system to be truly interactive it is important for the system to provide comprehensible feedback in a real time fashion Recent studies 13 sho w that those algor ithms based on a Fre 
quent Pattern tree FP-tree\Ñwhich is an extended preìx tree for effective capturing of the content of the transaction databaseÑavoid the time-consuming candidate generation process and thereby speeding up the mining process Consequently such tree-based mining helps achieve real-time responses due to enhancement in performance Proceedings of the International Database Engineering and Applications Symposium \(IDEASê04 1098-8068/04 $20.00 © 2004 IEEE 


Table 1 Our implemented iCFP system vs the most relevant algorithms Carma CAP    DCF Our proposed 14 19 21 15 iCFP system Constrained mining      Interactive mining  Provides continuous feedback       Handles dynamic constraint changes      FP-tree based mining      In response to the calls for constrained and/or interactive mining several algorithms 5 6 11 12 24 ha v e been proposed to provide user focus and/or user interaction However to our knowledge there is no work on incorporating constrained mining with interactive mining in a tree-based framework  To elaborate existing algorithms including the most relevant ones like Carma 14 CAP 19     21 and DCF 15 f all short in dif f erent aspects For instance while CAP and    are effective in capturing user constraints they do not handle dynamic changes to the constraints i.e not interactive mining Carma does not handle constraints let alone deal with dynamic changes to the constraints i.e not constrained mining While DCF handles constraints and dynamic changes to them it does not use the FP-tree i.e not FP-tree based mining The key contribution of this work is the development of an efìcient interactive human-centered system for mining frequent patterns that satisfy the user constraints More speciìcally we implement a system called iCFP  for i nteractive mining of C onstrained F requent P atterns  Our system provides the user with i the opportunity to impose a certain focus on the mining process ii the privilege to obtain continuous feedback during the mining process and iii the exibility to dynamically change the constraints during the mining process The system pushes the constraints deep inside the mining process and thus leads to more effective pruning and more efìcient mining In addition iCFP uses tree-based mining to further enhance its performance Last but certainly not the least this implemented system is novel and original To the best of our knowledge no work has been done to incorporate constrained mining i.e handling user constraints with interactive mining i.e handling dynamic changes to user constraints during the computation in an FP-tree based framework  Table 1 summarizes the salient features of our iCFP system as compared with its most relevant algorithms This paper is organized as follows In the next section related work is discussed Section 3 introduces our iCFP system for handling constraints Section 4 describes how the iCFP system handles dynamic changes to constraints Section 5 shows the experimental results Finally conclusions are presented in Section 6 2 Related work Regarding constrained mining  Ng et al 19 proposed a constrained frequent-set mining framework within which the user can use a rich set of constraints including SQL-style aggregate constraints e.g   012   015                012                and nonaggregate constraints e.g   012            guide the mining process to nd only those itemsets satisfying the constraints Here constraint   012   015             says that the minimum      value of all items in an itemset  is at least    constraint   012           says that all items in an itemset  are of      equal to    These two constraints    and    are anti-monotone because any supersets of an itemset violating the constraints e.g itemsets containing an item whose         violate    also violate the constraints All three aforementioned constraints       and    are succinct because one can directly generate precisely all and only those itemsets satisfying the constraints e.g by using a precise formula called a member generating function 19 that does not require generating and excluding itemsets not satisfying the constraints For instance itemsets satisfying   012               can be precisely generated by combining at least one item whose        with some optional items whose    values are unimportant thereby avoiding the substantial overhead of the generation and exclusion of invalid itemsets It is important to note the following 19 A majority of constraints are succinct For constraints that are not succinct many of them can be induced into weaker constraints that are succinct Refer to the work of Ng et al 19 for more details abou t antimonotone constraints and succinct constraints Among the existing constrained mining algorithms the most rel evant ones are CAP 19    21 and DCF 15  Although CAP     DCF and iCFP all handle constraints there are several key differences among them First CAP and DCF handle constraints in an Apriori-based framework whereas    and iCFP do so in an FP-tree based framework Second although    can handle succinct constraints it does so indirectly by converting the succinct constraints into another class of constraints and does not Proceedings of the International Database Engineering and Applications Symposium \(IDEASê04 1098-8068/04 $20.00 © 2004 IEEE 


completely exploit properties of succinct constraints Our iCFP system on the other hand directly handles the succinct constraints and exploits their properties Third both CAP and    do not handle dynamic changes to the constraints that is they are not for interactive mining Regarding interactive mining  Nag et al 18 prop osed caching algorithms that cache previous results and reuse these results as needed for future queries However the algorithms do not handle changes to parameters during the mining process for the current query They only allow the user to change the parameters at the end of the mining process for the current query 3 The iCFP system handles constraints Before discussing how our iCFP system handles dynamic changes to constraints let us describe in this section how iCFP efìciently handles constraints by effectively exploiting the properties of constraints A na ve approach to handle a constraint  in an FP-tree based framework is to rst run an unconstrained FP-tree based mining algorithm to compute all frequent itemsets and then to check each of these computed itemsets whether it is valid i.e whether it satisìes   While simple this na ve approach suffers from the fact that  is not pushed inside the mining algorithm to effect pruning as early as possible As a result although the use of an FP-tree based algorithm helps improve performance when compared with its Apriori counterpart the computational effort is still not proportional to the selectivity of   This problem is worsened when  is a highly selective one i.e when only a tiny fraction of frequent itemsets satisfy   To overcome this problem our iCFP system pushes the constraint  deep inside the computation and exploits properties of   Recall that a constraint can be succinct and/or anti-monotone or neither As described below the iCFP can do a lot better when the constraint is succinct 3.1 Succinctness-based exploitation Like many FP-tree based algorithms our proposed iCFP system handles a succinct constraint   by using two main operations i the construction of FP-tree and ii the recursive growth of valid frequent patterns The system exploits a nice property of succinct constraints One can easily enumerate all and only those itemsets that are guaranteed to satisfy the succinct constraint    To elaborate any frequent itemset  satisfying   e.g        012   015                is composed of mandatory items i.e items satisfying    and possibly some optional items i.e items not satisfying    Let      and      denote the set of mandatory items and the set of optional items respectively Then a frequent itemset  satisfying   is usually of the form   012   1 where i 012       such that 012 015    and ii         Due to succinctness items in      and      can be efìciently enumerated Because of succinctness our iCFP system can discover frequent patterns satisfying a succinct constraint   as follows It rst divides the domain items into two sets the set      consisting of all mandatory items and the set      consisting of all optional items it then scans the transaction database to check for frequency of all items in both sets and infrequent items are removed Afterwards iCFP builds an FP-tree with the mandatory and optional items ordered in such a way that mandatory items appear before optional items In other words mandatory items appear below optional items in the FP-tree i.e mandatory items are closer to the leaves and optional items are closer to the root With this item-ordering scheme if an itemset     violates    then   is an optional item and any item   ordered after item   is also optional thus itemset          also violates    Given that all frequent itemsets satisfying   must be extensions of an item from      i.e all valid frequent itemsets must be grown from an item in       all iCFP needs to do is to recursively apply the usual FP-tree based mining process to each projected database of only those valid frequent itemsets i.e apply to each 012 projected databaseÑwhich is a collection of transactions having 012 as its preìxÑwhere 012        Note that our iCFP system pushes the succinct constraints inside the computation and exploits the succinctness property of the constraints As a result during the entire mining process no constraint checking is required for projected databases at recursive steps All valid frequent patterns can be discovered by the above procedure without any extra constraint checking This is feasible due to the way in which iCFP orders the domain items More speciìcally with the above item order i all the mandatory items can be identiìed at the initial step by using a member generating function mentioned in Section 2 and ii all the valid itemsets can be grown from the projected databases of these mandatory items Pruning for constraint satisfaction is done once-and-for-all at the initial step when iCFP divides the domain items thereby avoiding all unnecessary constraint checking for projected databases at recursive steps To gain a better understanding of how the iCFP system works let us consider the following example Example 1 Consider the following transaction database Transactions Contents 012           012       012           012           Proceedings of the International Database Engineering and Applications Symposium \(IDEASê04 1098-8068/04 $20.00 © 2004 IEEE 


       a:1 a:1 FPätree for Trans. DB b:4 d:1 e:1 a:1 d:1 e:1 Mandatory Optional e:1 e:1 a:2 b:3 c:2 FPätree for {d}äproj. DB FPätree for {a}äproj. DB a,e}äproj. DB FPätree for a,c}äproj. DB FPätree for b:2 b:2 b:3 c:2 d:1 d,a}, {d,b}, {d,a,b a,e,b a,c,b a}, {d a,b}, {a,c}, {a,e Figure 1 The iCFP system discovers frequent patterns satisfying the succinct constraint   with the following auxiliary information about items Item                      012           015      Let succinct constraint   be constraint           012    015    and the minimum support threshold be  i.e     The iCFP system discovers valid frequent itemsets as follows It rst partitions the domain items into two sets i the mandatory set containing items  and   and ii the optional set containing items    and   Then iCFP builds an FP-tree as shown in Figure 1 In the gure the dashed line indicates the boundary between mandatory and optional items in the initial FP-tree i.e the FP-tree built for the transaction database Here mandatory items appear below/before optional items Within each of the mandatory set and the optional set items can be arranged consistently according to any item-ordering scheme e.g a non-ascending frequency order Note that for a succinct constraint the boundary only exists in the initial FP-tree but not in any FP-trees built for subsequent projected databases The reason is that once a projected database is formed for each valid frequent singleton itemset e.g         there is no distinction between mandatory and optional items In other words once a valid itemset  contains a mandatory item any other items in  can be chosen from the mandatory or the optional sets refer to Equation 1 This explains why once iCFP forms the    and    projected databases the usual FP-tree based mining process with only frequency checking can be applied recursively to these and subsequent projected databases Let us complete the execution The iCFP system nds frequent and thus valid itemsets            and        from the    projected database it nds frequent itemsets            and      from the    projected database As the mining process is applied recursively      and      projected databases are formed and valid frequent itemsets        and        are found respectively Therefore iCFP nds all and only those valid frequent itemsets                                                      and         Note that projected databases are formed only for valid frequent singleton itemsets e.g         and no constraint checking is required for projected databases at recursive steps 3.2 Succinct-antimonotonicity based exploitation So far we have described how the iCFP system exploits the succinctness property of succinct constraints for effective mining Next we discuss the case where the succinct constraints happen to be anti-monotone as well In the reminder of this paper we denote these succinct antimonotone constraints as SAM constraints  Similarly we denote those succinct non-antimonotone constraints as SUC constraints  Hence succinct constraints can be divided into SAM constraints and SUC constraints In addition to exploiting the succinctness property iCFP also exploits the anti-monotonicity property of the SAM constraints If an itemset violates the SAM constraint then all its supersets also violate the constraint  Recall from Section 3.1 that for a succinct constraint optional items are those items not satisfying the constraint i.e those items violating the constraint Hence for a SAM constraint      any itemsets containing an optional item do not satisfy     i.e any itemsets containing an optional item violate      Therefore any frequent itemset  satisfying     is composed of only valid/mandatory items and can be represented in the form     012 2 where i     015  012 which is the set of valid/mandatory items such that      and ii 012    015   which is the set of invalid/optional items such that 012    This form can be reduced to become the following     015  012 3 By exploiting nice properties of the SAM constraints our iCFP system can effectively nd valid frequent itemsets as Proceedings of the International Database Engineering and Applications Symposium \(IDEASê04 1098-8068/04 $20.00 © 2004 IEEE 


follows The system rst divides the domain items into two setsÑthe set      consisting of all valid/mandatory items and the set      consisting of all invalid items It then scans the transaction database to check for frequency of all items and infrequent items are removed Afterwards iCFP builds an FP-tree with the items ordered in such a way that valid items appear after/above invalid items Given that all frequent itemsets satisfying     must be grown only from the items in       all iCFP needs to do is to recursively apply the FP-tree based mining process to each projected database of only valid frequent itemsets In other words invalid items are not included in any projected databases these invalid items are only kept in this initial FP-tree for the purpose of dynamic mining which will be described in Section 4.2 For lack of space we do not show further details We leave as an exercise for the reader to apply iCFP for nding frequent patterns satisfying           012    015    from the database given in Example 1 4 The iCFP system handles dynamic changes to constraints In the previous section we discussed how our iCFP system handles succinct constraints i.e SAM constraints as well as SUC constraints In this section we show how it handles dynamic changes to these succinct constraints Regarding dynamic changes there are two casesÑa tightening change and a relaxing change Our discussion here assumes that at any point in time there is at most one constraint being modiìed During the entire process many different constraints can of course be changed The base case of our discussion below is on how to deal with changes to the constant       When      is modiìed by the user in the direction of restricting the new solution space to be a subset of the old space we call this a tightening change  Otherwise whenever the change to      corresponds to the situation when the new solution space contains the old space we call this a relaxing change  For example if the original succinct constraint is        012    015     then changing from   to   or to any value that is less than    corresponds to a tightening change Similarly changing from   to   or to any value that is greater than    corresponds to a relaxing change Clearly inserting a new constraint is a special case of a tightening change and deleting an old constraint is an extreme case of a relaxing change Thus while our discussion below is conìned to changing the constant       any other modiìcation to constraints e.g modifying        012    015    to        012    015     can be dealt with as a pair of constraint deletion and insertion 4.1 Handling a dynamic tightening change to a SAM constraint By deìnition a tightening change from an old succinct constraint     to a new constraint     corresponds to a restriction of the old solution space In other words             where      and      respectively denote the old solution space and the new solution space To accommodate     dynamically our iCFP system carries out two main operations  For processed frequent itemsets satisfying      check if they still satisfy       For unprocessed itemsets only generate those satisfying      Recall from Section 3.2 that any frequent itemset  satisfying a SAM constraint is composed of only valid items i.e items satisfying the constraint individually In other words  is a subset of the set      of valid items For a tightening change any frequent itemset  satisfying the new SAM constraint     is a subset of          which is a subset of                              4 An alternative way to view this tightening change is that some items are no longer valid i.e some items are transferred from      to the set of invalid items       To handle the tightening change a na ve approach is to rebuild a new FP-tree from the transaction database so as to reîect the changes to constraints However a close examination reveals that such a tree reconstruction is unnecessary Instead after a SAM constraint is tightened one can reuse the existing FP-tree to generate the unprocessed itemsets Speciìcally our iCFP system uses the existing FP-tree to form projected databases only for the items satisfying      When forming an    projected database for an item  012          iCFP excludes the items that satisfy     but not      These excluded items can be efìciently enumerated due to succinctness Once iCFP forms these    projected databases the usual FP-tree based mining process can be applied recursively to these projected databases As a nal step iCFP checks for each itemset that was processed before the tightening constraint change i.e the itemset that satisìes      Among these itemsets that satisfy      iCFP keeps and returns only those itemsets that satisfy both     and      Example 2 below shows how iCFP deals with a tightening change to a SAM constraint Example 2 Consider the same transaction database as in Example 1 Suppose a SAM constraint             012    015    is tightened to             012    015    after the    projected database has Proceedings of the International Database Engineering and Applications Symposium \(IDEASê04 1098-8068/04 $20.00 © 2004 IEEE 


Items to be excluded b:4 d:2 c:1 e:1 c:1 a:3 d:1 b}, {a}, {d c}, {e change After the FP-tree for b:2 Processed FP-tree for d}-proj. DB bad:1, bd:1 a:2 d,a a:2 e,a}, {e,b e,a,b bace:1, bade:1 Before the items  FP-tree for Trans. DB e:1 e}-proj. DB change Figure 2 The iCFP system handles tightening changes to a SAM constraint been processed i.e after obtaining all three itemsets containing  namely            and         Then due to succinctness the items that satisfy     but not     can be efìciently enumerated items  and   Therefore as shown in Figure 2 when forming the    projected database iCFP excludes items  and  from the extracted paths        2 and      1 A valid frequent itemset      is then produced by using the FP-tree built for the    projected database Finally iCFP needs to check all the itemsets that were processed before the change i.e the ve singleton itemsets and the three itemsets containing   which all satisfy      whether they still satisfy      4.2 Handling a dynamic relaxing change to a SAM constraint In general a relaxing change from an old succinct constraint     to a new constraint     has different and tougherÑcomputational requirements than a tightening change The reason is that for a tightening change the new solution space is contained in the old space i.e             and all that is needed is to verify whether every itemset  satisfying     also satisìes      In contrast for a relaxing change this veriìcation is unnecessary because             What is needed however is to insert into the new solution space all the itemsets that were not generated before the constraint was relaxed Therefore our iCFP system needs to carry out the following operations  For processed itemsets satisfying      no further constraint checking is required because they also satisfy       For unprocessed itemsets iCFP generates i the remaining itemsets satisfying      as well as ii those satisfying     but not      For a relaxing change any frequent itemset  satisfying the new SAM constraint     is a subset of    012      which is a superset of    012           012      where    012         012      5 Again an alternative way to view the relaxing change is that some items are transferred from    012  to    012   From this angle the treatment for the relaxing changes can be similar though not identical to that for the tightening changes Speciìcally the iCFP system uses the existing FP-tree which was built before the relaxing constraint change to generate all unprocessed itemsets This is possible because all frequent items valid as well as invalid items are kept in the tree refer to Section 3.2 By forming a projected database for each item that satisìes     i.e items in    012         012      iCFP generates all the remaining itemsets satisfying      In addition iCFP also needs to generate those itemsets satisfying     but not      To generate these itemsets iCFP forms projected databases for all items that satisfy     but not     i.e the items that are transferred from    012  to    012   Similar to the tightening case iCFP excludes some items but it excludes the items that violate both     and     i.e those non-transferred optional items for the relaxing case These items can be efìciently enumerated because of succinctness For lack of space we do not show further details We leave as an exercise for the reader to show how iCFP handles the case where a SAM constraint         012    015        is relaxed to         012    015        after the    projected database has been processed 4.3 Handling a dynamic tightening change to a SUC constraint We have discussed how iCFP handles dynamic changes to one class of succinct constraintsÑnamely dynamic changes to a SAM constraint      Next we turn our attention to dynamic changes to another class of succinct constraintsÑnamely dynamic changes to a SUC constraint      Recall from previous sections that a tightening change to a SAM constraint can be viewed as a situation where some valid items are transferred to the set of invalid items i.e from    012  to    012   Similarly a tightening change to a SUC constraint can be viewed as a situation in which some mandatory items are transferred to the set of optional items i.e from    012  to    012 015  On the surface this tightening change appears to be very similar to a tightening change to a SAM constraint but a close examination reveals that the former is more complicated The reason is that for the SAM constraint once a valid item Proceedings of the International Database Engineering and Applications Symposium \(IDEASê04 1098-8068/04 $20.00 © 2004 IEEE 


become invalid it can be ignored because it will not contribute to the nal answers of valid frequent itemsets even when combining with any valid items In contrast for the SUC constraint once a mandatory item become optional there are still opportunities for it to contribute to the nal answers e.g when this optional item is combined with some mandatory items to form a valid itemset See Example 3 Example 3 Consider items    and  in Example 1 The    values of these items are        and     respectively Then with        012   015          i items  and  are mandatory whereas item  is optional ii itemsets                          and        are valid When this constraint is tightened to become        012   015          the mandatory item  becomes optional but it still contributes to the nal answers e.g itemset      is valid Therefore to ensure the completeness of the resulting answer sets of valid frequent itemsets the iCFP system executes as follows It forms a projected database only for each item that is mandatory with respect to      When forming the    projected database for each mandatory item   iCFP includes not only the items above  in the tree as usual but also all the unprocessed optional items below  that are located in the same tree path as   Once iCFP forms these    projected databases the usual FPtree based mining process with the usual node extraction from tree paths and with only frequency checking can be applied recursively to these projected databases So the complication arises only when forming projected databases from the initial FP-tree the formation of subsequent projected databases from subsequent FP-trees can be found as usual Example 4 illustrates how the iCFP system handles a tightening change to a SUC constraint Example 4 Consider the same transaction database as in Example 1 Suppose a SUC constraint        012   015         is tightened to        012   015         after the    projected database has been processed i.e after obtaining all three itemsets containing  namely            and         Then due to succinctness the items that satisfy     but not     can be efìciently enumerated items  and   Since the    projected database has been processed iCFP will not include item  in the extracted paths Therefore as shown in Figure 3 when forming the    projected database iCFP includes unprocessed optional item  in the extracted paths i.e          1        1 and      1 Three valid frequent itemset            and        can then be found from the FP-tree built for the    projected database Similarly when forming the    projected database iCFP includes item  in the extracted paths i.e        1         1 and      1 Three valid c}, {e b}, {a}, {d Before the Processed d:2 a:3 b:4 c:1 d:1 items change a,c,b a}-proj. DB FP-tree for c:2 bac:1, ba_c:1, ba:1 change After the bace:1, bade:1 e,a}, {e,b a,c}, {a,b badc:1, bad:1, bd:1 d,a}, {d,b FP-tree for b:2 FP-tree for d,a,b a:2 a:2 b:3 b:3  d}-proj. DB e,a,b e}-proj. DB e:1 c:1 e:1 FP-tree for Trans. DB Figure 3 The iCFP system handles tightening changes to a SUC constraint frequent itemset            and        can then be found from the FP-tree built for the    projected database Finally iCFP needs to check all the itemsets were processed before the change i.e the ve singleton itemsets and the three itemsets containing   which all satisfy      whether they still satisfy      4.4 Handling a dynamic relaxing change to a SUC constraint Recall from the previous section that a tightening change to a SUC constraint causes some items to transfer from      to     012  In contrast a relaxing change to a SUC constraint does the opposite that is some items are transferred from     012 to       Since both tightening and relaxing changes cause the transfer of items their treatment is quite similar except for the following When a SUC constraint is tightened iCFP only needs to generate the itemsets satisfying     In contrast when a SUC constraint is relaxed iCFP needs to generate both i the remaining/unprocessed itemsets satisfying     and ii those itemsets satisfying     but not      Therefore the iCFP system rst forms a projected database for each item that is mandatory with respect to      and computes valid frequent itemsets from the projected database as usual Second it forms a projected database for each item  that satisìes     but not      When forming a projected database for each of these items iCFP includes not only all the items above  in the tree as usual but also all the optional items below  that are located in the same tree path as   Once iCFP forms these    projected databases the usual FP-tree based mining process with the usual node extraction from tree paths and with only frequency checking can be applied recursively to these projected databases Proceedings of the International Database Engineering and Applications Symposium \(IDEASê04 1098-8068/04 $20.00 © 2004 IEEE 


 0 50 100 150 200 0 20 40 60 80 100 Runtime \(in seconds Selectivity \(i.e., percentage of items selected Handling the SUC constraint FIC   iCFP   0 20 40 60 80 100 120 140 160 180 0 20 40 60 80 100 Runtime \(in seconds Selectivity \(i.e., percentage of items selected Handling the SAM constraint FIC iCFP   a Handling the SUC constraint b Handling the SAM constraint Figure 4 Runtime iCFP vs    For lack of space we do not show further details We leave as an exercise for the reader to show how iCFP handles the case where a SUC constraint            012   015     is relaxed to            012   015     after the    projected database has been processed 5 Experimental results The experimental results cited below are based on a transaction database of 100k records with an average transaction length of 10 items and a domain of 1000 items The database was generated by the program developed at IBM Almaden Research Center 3 Unless othe rwise speciìed we used a minimum support threshold of 0.01 All experiments were run in a time-sharing environment in a 700 MHz machine The reported gures are based on the average of multiple runs In the experiment all the algorithms were implemented in C In the rst set of experiments we evaluated the effectiveness of i succinctness-based exploitation and ii succinctantimonotonicity based exploitation  More speciìcally we compared our iCFP system with its most relevant algorithm     The key difference between them is that    does not completely exploit properties of succinct constraints whereas iCFP does The y-axis of Figure 4 shows the runtimes of iCFP and     and the x-axis shows the selectivity of the succinct constraint A constraint with pct  selectivity means pct  of items is selected The higher the pct value the more is the number of selected items It is observed from Figure 4\(a that as the selectivity of the SUC constraint     decreases i.e fewer items are selected the runtime of iCFP decreases but that of    increases In terms of speedup it is more beneìcial to use iCFP than     especially when     has a lower selectivity A reason for the gap in runtime is that iCFP exploits the properties of      Consequently constraint checking is only performed on the original database at the initial step but not on projected databases at recursive steps Pruning is done once-and-for-all In contrast    checks constraints at many steps including many projected databases at recursive steps The results show the effectiveness of succinctness-based exploitation  Similarly it is observed from Figure 4\(b that there is a gap in runtime between iCFP and     In terms of runtime when the selectivity of the succinct anti-monotone SAM constraint     decreases i.e fewer items are selected both    and iCFP take shorter execution time Again a reason for the gain in performance when compared iCFP with     is that the iCFP system exploits properties of SAM constraints The results show the effectiveness of succinct-antimonotonicity based exploitation  We have tested with various minimum support thresholds The results show that when the threshold increases the runtime decreases In addition we have also tested scalability with the number of transactions The results show that our proposed iCFP system has a linear scalability In the second set of experiments we evaluated the effectiveness of iCFP in handling dynamic changes to constraints  More speciìcally we compared our iCFP system with its most relevant algorithms DCF and Rerun The key differences among them are as follows i iCFP and Rerun are FP-tree based whereas DCF is Apriori-based ii iCFP and DCF reuse the processed itemsets as much as possible after a constraint is changed whereas Rerun ignores all processed itemsets and generates itemsets satisfying the modiìed constraint from scratch Rerun isana ve approach of handling dynamic changes to constraints It simply ignores all valid frequent itemsets that have been produced so far with respect to the Proceedings of the International Database Engineering and Applications Symposium \(IDEASê04 1098-8068/04 $20.00 © 2004 IEEE 


 10 20 30 40 50 60 70 0 0.2 0.4 0.6 0.8 1 Runtime \(in seconds Fraction of items processed before changing the constraint Handling a dynamic tightening change to the SAM constraint Rerun, old pct=80%, new pct=60 iCFP, old pct=80%, new pct=60   Rerun, old pct=60%, new pct=40   iCFP, old pct=60%, new pct=40   30 40 50 60 70 80 90 100 110 0 0.2 0.4 0.6 0.8 1 Runtime \(in seconds Fraction of items processed before changing the constraint Handling a dynamic relaxing change to the SAM constraint Rerun, old pct=80%, new pct=100   iCFP, old pct=80%, new pct==100   Rerun, old pct=60%, new pct=80   iCFP, old pct=60%, new pct=80   a Handling a tightening change b Handling a relaxing change Figure 5 Runtime for handling a dynamic change to a SAM constraint iCFP vs Rerun old constraint     i.e ignore all processed itemsets and reruns the mining process again using the new constraint      Our iCFP system takes a better approach It exploits properties of constraints and reuses all processed itemsets To evaluate the effectiveness of our system we experimented with a situation where a SAM constraint               012    015  is tightened to               012       The percentage old pct of items having    012   015  and the percentage new pct of items having    012     are set in such a way that new pct  old pct      We varied old pct from    to     The x-axis in Figure 5\(a shows the fraction  of itemsets processed before tightening the constraint and  varied from    to     The y-axis shows the total runtime in seconds of both iCFP and Rerun From the graph it is clear that our iCFP system always beats Rerun but the extent varies under different situations When  is higher i.e more itemsets are processed the relative speedup is higher In other words it is more beneìcial to use iCFP than Rerun especially when  is high The reason is that when  is higher i.e more items have been processed more processed items are ignored by Rerun Next we turned our attention to a relaxing change Figure 5\(b shows the experimental results for a situation where a SAM constraint               012    015  is relaxed to               012       Here the percentage old pct of items having    012   015  and the percentage new pct of items having    012     are set in such a way that new pct  old pct      We varied old pct from    to     The gure again shows that our iCFP system always beats Rerun The reasons are as follows First Rerun ignores all the itemsets produced before the change i.e the itemsets satisfying     and computes itemsets satisfying      which contain those ignored itemsets Hence the higher the   the higher is the number of itemsets that are generated and ignored by Rerun One can easily observed that Reurn is really a waste of computation Second our iCFP system reuses all the itemsets ignored by Rerun i.e all those itemsets satisfying      Due to succinctness             After     is relaxed to become      the iCFP generates i the remaining itemsets satisfying     and ii those satisfying     but not      This explains why the runtime of iCFP is quite steady Therefore it is more beneìcial to use iCFP than to use Rerun especially when  is high i.e more items have been processed In addition we have also compared iCFP with DCF In all experiments iCFP far dominates DCF A reason is that the former is FP-tree based and thus avoids the computationally costly and time-consuming candidate generation process of the latter This shows the importance and the beneìts of incorporating interactive constrained in the FPtree based mining framework 6 Conclusions A key contribution of this paper is to develop and implement an interactive mining system called iCFP  for the i nteractive mining of C onstrained F requent P atterns  The system is an integration of constrained mining treebased mining and interactive mining Consequently the system i allows human users to impose a certain focus on the mining process ii provides users with quick response/feedback during the mining process and iii permits users to dynamically change their constraints during the process In ongoing work we are interested in exploring improvements to the iCFP system For example we are interested in investigating efìcient methods for handling dynamic changes to non-succinct constraints Along this direction an interesting question to explore is how to incorProceedings of the International Database Engineering and Applications Symposium \(IDEASê04 1098-8068/04 $20.00 © 2004 IEEE 


porate iCFP into a data mining tool for handling various real-life applications Acknowledgement This project is partially sponsored by Natural Sciences and Engineering Research Council of Canada NSERC and The University of Manitoba in the form of research grants References  R Agra w al T  Imielinsk i and A Sw ami Mining Association Rules between Sets of Items in Large Databases In Proc SIGMOD 1993  pp 207Ö216  R Agra w al H Mannila R Srikant H T o i v onen  and A.I Verkamo Fast Discovery of Association Rules In Advances in Knowledge Discovery and Data Mining  AAAI/MIT Press 1996 ch 12  R Agra w a l and R Srikant F ast Algorith ms for Mining Association Rules In Proc VLDB 1994  pp 487 499  R.J Bayardo Ef ciently Mining Long P atterns from Databases In Proc SIGMOD 1998  pp 85Ö93  R.J Bayardo R Agra w al and D Gunop ulos Constraint-Based Rule Mining in Large Dense Databases In Proc ICDE 1999  pp 188Ö197  J.-F  Boulicau t and B Jeudy  Mining Free Itemsets under Constraints In Proc IDEAS 2001  pp 322329  S Brin R Motw ani and C Silv erstein Be yond Market Baskets Generalizing Association Rules to Correlations In Proc SIGMOD 1997  pp 265Ö276  D.W  Cheung J Han V  T  Ng and C.Y  W ong Maintenance of Discovered Association Rules in Large Databases An Incremental Updating Technique In Proc ICDE 1996  pp 106Ö114  W  Cheung and O.R Za  ane Incremental Mining of Frequent Patterns with Candidate Generation or Support Constraint In Proc IDEAS 2003  pp 111Ö116 10 T  Fuku da Y  Morim oto S Morishita and T Tokuyama Data Mining Using Two-Dimensional Optimized Association Rules Scheme Algorithms and Visualization In Proc SIGMOD 1996  pp 13 23 11 M.N Garof alak is R Rastogi and K Shim SPIRIT  Sequential Pattern Mining with Regular Expression Constraints In Proc VLDB 1999  pp 223Ö234  G Grahn e L.V S Lakshm anan and X W ang Ef cient Mining of Constrained Correlated Sets In Proc ICDE 2000  pp 512Ö521  J Han J Pei and Y  Y in Mining Frequ ent P atterns without Candidate Generation In Proc SIGMOD 2000  pp 1Ö12  C Hidber  Online Association Rule Mining In Proc SIGMOD 1999  pp 145Ö156  L.V S Lakshm anan C.K.-S Leung  and R Ng Ef cient Dynamic Mining of Constrained Frequent Sets ACM TODS  28 4 Dec 2003 pp 337Ö389  C.K.-S Leung  R.T  Ng and H Mannila OSSM A Segmentation Approach to Optimize Frequency Counting In Proc ICDE 2002  pp 583Ö592  R.J Miller and Y  Y ang   Association Rules o v e r Interval Data In Proc SIGMOD 1997  pp 452Ö461  B Nag P M Deshpand e and D.J DeW itt Using a Knowledge Cache for Interactive Discovery of Association Rules In Proc SIGKDD 1999  pp 244Ö253  R.T  Ng L.V S Lakshm anan J Han and A P ang Exploratory Mining and Pruning Optimizations of Constrained Associations Rules In Proc SIGMOD 1998  pp 13Ö24  J.S P ark M.-S Chen and P S Y u  Using a HashBased Method with Transaction Trimming for Mining Association Rules IEEE TKDE  9 5 Sept./Oct 1997 pp 813Ö825  J Pei J Han and L.V S Lakshm anan Mining Frequent Itemsets with Convertible Constraints In Proc ICDE 2001  pp 433Ö442  S Sara w a g i  S  Tho mas and R Agra w al Inte g rating Association Rule Mining with Relational Database Systems Alternatives and Implications In Proc SIGMOD 1998  pp 343Ö354  C Silv erstein S Brin R Motw ani and J Ullman Scalable Techniques for Mining Causal Structures In Proc VLDB 1998  pp 594Ö605  R Srikan t Q V u  and R Agra w al Mining Association Rules with Item Constraints In Proc KDD 1997  pp 67Ö73  D Tsur  J.D Ullman S Abitebou l C Clifton R Motwani S Nestorov and A Rosenthal Query Flocks A Generalization of Association-Rule Mining In Proc SIGMOD 1998  pp 1Ö12 Proceedings of the International Database Engineering and Applications Symposium \(IDEASê04 1098-8068/04 $20.00 © 2004 IEEE 


quests can be served in the cache. When the cache is full, it uses LRU scheme to do cache replacement. However, LRU does not consider the relationships among data items and important data items may be replaced by others using LRU scheme. For the CMIP scheme, it has mined the relationships among data items and known which data items have higher future access probabilities. So it can keep important data items longer in the cache. Thus, more client  s requests can be served locally in the cache and the cache hit ratio is improved. This explains why our CMIP scheme can achieve a better performance than the NOPRE scheme in term of cache hit ratio Figure 4\(b ter than the UIR scheme. This can be explains as follows The UIR scheme is based on the cache locality: a client has a large chance to access the invalidated cache items in the near future; downloading these data items in advance should be able to increase the cache hit ratio [7]. However, the UIR scheme does not differentiate the items in the cache. Although, the UIR scheme classi?es data items into hot data and cold data and treat them differently during cache management, they are treated equally in prefetching and assumed to have the same access probability in the future. However, as stated above, some of the data items within the cache are important, while others are not. The CMIP scheme differentiates the importance of the data items and the important data items are kept longer in the cache. As a result, the CMIP scheme can achieve a higher cache hit ratio than the UIR scheme Figure 4\(c mobile clients is 200. We put it here to show a clear picture of the comparison of these three schemes. As can be seen CMIP is about 15% better than the NOPRE scheme and about 9% better than UIR. Although UIR scheme achieves a better cache hit ratio than NOPRE scheme, later we will see that the high cache hit ratio of the UIR scheme is at the cost of high additional traf?c 3.2.2. The Percentage of Reduced Uplink Requests The percentage of reduced uplink requests is de?ned as the ratio of the number of saved uplink requests to the total number of requests. Since the NOPRE scheme does not prefetch, it will not be compared. Figure 5 shows the percentage of reduced uplink requests using the CMIP Proceedings of the 2004 IEEE International Conference on Mobile Data Management \(MDM  04 0-7695-2070-7/04 $20.00  2004 IEEE 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0  50  100  150  200  250  300 Ca ch e hi t r at io Cache size 1 client using CMIP 100 clients using CMIP 200 clients using CMIP 1 client using NOPRE 100 clients using NOPRE 200 clients using NOPRE 0.2 0.3 0.4 0.5 0.6 


0.6 0.7 0.8 0  50  100  150  200  250  300 Ca ch e hi t r at io Cache size 1 client using CMIP 100 clients using CMIP 200 clients using CMIP 1 client using UIR 100 clients using UIR 200 clients using UIR a b 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0  50  100  150  200  250  300 Ca ch e hi t r at io Cache size 200 clients using CMIP 200 clients using UIR 200 clients using NOPRE c Figure 4. The comparison of cache hit ratio using three schemes 0 2 4 6 8 10 0 50 100 150 200 250 300 Pe rc en ta ge o f r ed uc ed u pl in k re qu es ts Cache size The Percentage of Reduced Uplink Requests Using CMIP Scheme vs. UIR Scheme 1 client using CMIP 100 clients using CMIP 200 clients using CMIP 1 client using UIR 


1 client using UIR 100 clients using UIR 200 clients using UIR Figure 5. The percentage of reduced uplink requests scheme and the UIR scheme. Generally speaking, using our CMIP scheme, the percentage of reduced uplink requests increases as the cache size increases. After the cache size reaches 120, the percentage no longer changes. This can be explained as follows. As the cache size increases, more and more important data items having high access probability can be stored in the cache. When the cache size is still not large enough, the cache hit ratio will increase sharply when cache size increases. As a result, the rate of reduced uplink requests is higher than the arrival rate of new requests Thus, the percentage of reduced uplink requests has a trend of increasing. When the cache size is big enough to hold all the items within our prefetch sets, the rate of reduced uplink requests is no long signi?cant to the arrival rate of new requests. Hence, the percentage of reduced uplink requests no longer changes after reaching a certain cache size From Figure 5, we also notice that although the trend of the percentage of reduced uplink requests is increasing there are some ups and downs. For example, when the number of clients is 200, the percentage of reduced uplink requests reaches the peak when the cache size is about 50 As the cache size continues increasing, the percentage begins to decrease a little bit, and then it increases again. This can be explained as follows. As the cache size increases more queries can be served within the cache. So, the number of reduced uplink requests keeps increasing. Depending on the access patterns of the clients, the number of reduced uplink requests may increase at a rate higher or lower than the increase of the number of requests. If the rate is higher, the percentage of reduced uplink requests will increase. If the rate is lower, the percentage will decrease instead. Thus, there are some ups and downs in the percentage of reduced uplink requests, although the trend is increasing Figure 5 also shows that our CMIP scheme outperforms the UIR scheme with various cache sizes and various number of mobile clients. The percentage of reduced uplinks using the CMIP scheme is twice as much as that of usProceedings of the 2004 IEEE International Conference on Mobile Data Management \(MDM  04 0-7695-2070-7/04 $20.00  2004 IEEE ing the UIR scheme. In term of percentage of reduced uplink request, even the worst case of the CMIP scheme is better than the best case of the UIR scheme. For instance the CMIP scheme has the worse performance when there is one mobile client and the percentage of reduced uplinks is about 6% \(7.5% at best achieves its best performance when there are 200 mobile clients with about 3% of reduced uplinks. This is because the CMIP scheme can better predict the future access of the clients and prefetch them in advance than the UIR scheme Hence, the CMIP scheme can reduce the uplink requests at a percentage much higher than the UIR scheme 3.2.3. The Percentage of Additional Traf?c. The percentage of additional traf?c is de?ned as the ratio of the number of prefetches from the broadcast channel to the number of requests. As we know, downloading a data item from the channel also consumes a lot of system resources such as the bandwidth and the power. So the prefetch scheme should not do aggressive prefetching; otherwise it will consume too much system resources. This is especially important in mobile environments, where the system resource is very limited One argument about this metric is that the percentage of additional traf?c depends on the number of requests that are quite application-dependent and it does not make much sense to compare on this metric. We argue that this met 


sense to compare on this metric. We argue that this metric, when combined with other metric, such as the cache hit ratio, can well describe a prefetch scheme  s ef?ciency and predictability. A good prefetch scheme should be able to improve the cache hit ratio without incurring too much additional traf?c \(or prefetches pares the two schemes in term of the percentage of additional traf?c Figure 6\(a more additional traf?c to the system. For example, the percentage of additional traf?c for UIR scheme is up to 20 when there are 200 clients. This is because the UIR scheme is an aggressive prefetch scheme. Whenever a data item within the cache has been updated and is broadcasted on the channel, the client will download it and update the cache But for the CMIP scheme, the percentage of additional traf?c to the system is negligible, as shown in Figure 6\(b example, the percentage is lower than 0.5% when cache size becomes larger than 100. Why the percentage of additional traf?c is so small is due to the characteristic of our CMIP scheme. Using the CMIP scheme, only those data items which are within our prefetch sets are prefetched The data items within prefetch sets are got from association rules with a high con?dence and support. So the set of data items to be prefetch is small and the number of prefetches is also small. This explains why the percentage of additional traf?c is negligible Figure 6\(c percentage of additional traf?c when there are 200 mobile clients. From 6\(c curs only a fraction of 20 of the percentage of additional traf?c incurred by the UIR scheme. By far, we can say that our CMIP scheme is much better than the UIR scheme and the NOPRE scheme in terms of increased cache hit ratio reduced uplink requests and negligible additional traf?c 4. Related Work In the literature, prefetch technique is widely employed to reduce the access latency in WWW environments [17 16, 8, 12, 9]. [17] presents a predictive prefetching scheme for the World Wide Web in which the server tells the clients which ?les are likely to be requested by the user, and the clients decide whether to prefetch these ?les or not based on local considerations \(such as the contents of the local cache  posed. This scheme predicts the ?les  future access probabilities based on the access history and the network condition. The scheme allows the prefetching of a ?le only if the access probability of the ?le is greater than a function of the system bandwidth, delay and retrieval time. In [9], Cohen and Kaplan investigate three other types of prefetching in web: pre-resolving host-names \(pre-performing DNS lookup prefetching TCP connections prior to issuance of HTTP request sending a  dummy  HTTP HEAD request to Web servers  velops a new method for prefetching Web pages into the client cache. Clients send reference information to the Web server, which aggregates the reference information in nearreal-time and then disperses the aggregated information to all clients, piggybacked on GET responses. The information indicates how often hyperlink URLs embedded in pages have been previously accessed relative to the embedding page. Based on the knowledge about which hyperlinks are generally popular, clients initiate prefetching of the hyperlinks and their embedded images according to any algorithm they prefer Most of these work were not designed for mobile environments and did not consider the constraints of mobile environments. Recently, several prefetch schemes have been proposed as a client-side technique to reduce the access latency in mobile environments [1, 13, 6, 19]. In [1], a simple prefetching heuristic, called PT, computes the value of 


ple prefetching heuristic, called PT, computes the value of a page by taking the product of the probability \(P cessing of the page with the time \(T fore that page appears on the broadcast again. PT ?nds the page in the cache with the lowest pt value and replaces it with the current broadcast page if the latter has a higher pt value. However, this time-based prefetch scheme is expensive to implement since it computes the pt for each item in Proceedings of the 2004 IEEE International Conference on Mobile Data Management \(MDM  04 0-7695-2070-7/04 $20.00  2004 IEEE 0 5 10 15 20 0  50  100  150  200  250  300 Th e pe rc en ta ge o f a dd iti on al tr af fic Cache size 1 client using UIR 100 clients using UIR 200 clients using UIR 0 0.5 1 1.5 2 2.5 3 3.5 4 0  50  100  150  200  250  300 Th e pe rc en ta ge o f a dd iti on al tr af fic Cache size 1 client using CMIP 100 clients using CMIP 200 clients using CMIP a b 0 5 10 15 


20 0  50  100  150  200  250  300 Pe rc en ta ge o f a dd iti on al tr af fic Cache size 200 clients using CMIP 200 clients using UIR c Figure 6. The percentage of additional traf?c the cache at every clock tick. A similar scheme has been proposed in [13], which uses fv, a function of the access rate of the data item only, to evaluate the value of each data item i that becomes available to the client on the channel If there exists a data item j in the client  s cache such that fv\(i j replaced with i A prefetch scheme based on the cache locality, called UIR scheme, was proposed in [7]. It assumes that a client has a large chance to access the invalidated cache items in the near future. It proposes to prefetch these data items if it is possible to increase the cache hit ratio. In [6], Cao improves the UIR scheme by reducing some unnecessary prefetches based on the prefetch access ratio \(PAR scheme, the client records how many times a cached data item has been accessed and prefetched, respectively. It then calculates the PAR, which is the number of prefetches divided by the number of accesses, for each data item. If the PAR is less than one, it means that the data item has been accessed a number of times and hence the prefetching is useful. The clients can mark data items as non-prefetching when PAR &gt; b, where b is a system tuning factor. The scheme proposes to change the value of b dynamically according to power consumption. This can make the prefetch scheme adaptable, but no clear methodology as to how and when b should be changed. Yin et al. [19] proposed a power-aware prefetch scheme, called value-based adaptive prefetch \(VAP the number of prefetches based on the current energy level to prolong the system running time. The VAP scheme de?nes a value function which can optimize the prefetch cost to achieve better performance These existing schemes have ignored the following characteristics of a mobile environment: \(1 query some data items frequently, \(2 during a period of time are related to each other, \(3 miss is not a isolated events; a cache miss is often followed by a series of cache misses, \(4 eral requests in one uplink request consumes little additional bandwidth but reduces the number of future uplink requests. In this paper, we addressed these issues using a cache-miss-initiated prefetch scheme, which is based on association rule mining technique. Association rule mining is a widely used technique in ?nding the relationships among data items. The problem of ?nding association rules among items is clearly de?ned by Agrawal et al. in [5]. However in the mobile environment, one cannot apply the existing association rule mining algorithm [4] directly because it is too complex and expensive to use This makes our algorithm different from that of [4] in 


This makes our algorithm different from that of [4] in twofold. First, we are interested in rules with only one data item in the antecedent and several data items in the consequent. Our motivation is to prefetch several data items which are highly related to the cache-miss data item within Proceedings of the 2004 IEEE International Conference on Mobile Data Management \(MDM  04 0-7695-2070-7/04 $20.00  2004 IEEE the cache-miss initiated uplink request. We want to generate rules where the antecedent is one data item, but the cache-missed data item and the consequent is a series of data items, which are highly related to the antecedent. If we have such rules, we can easily ?nd the data items which should also be piggybacked in the uplink request. Second in mobile environment, the client  s computation and power resources are limited. Thus, the rule-mining process should not be too complex and resource expensive. It should not take a long time to mine the rules. It should not have high computation overhead. However, most of the association rule mining algorithms [4, 5] have high computation requirements to generate such rules 5. Conclusions Client-side prefetching technique can be used to improve system performance in mobile environments. However, prefetching also consumes a large amount of system resources such as computation power and energy. Thus, it is very important to only prefetch the right data. In this paper, we proposed a cache-miss-initiated prefetch \(CMIP scheme to help the mobile clients prefetch the right data The CMIP scheme relies on two prefetch sets: the alwaysprefetch set and the miss-prefetch set. Novel association rule based algorithms were proposed to construct these prefetch sets. When a cache miss happens, instead of sending an uplink request to only ask for the cache-missed data item, the client requests several items, which are within the miss-prefetch set, to reduce future cache misses. Detailed experimental results veri?ed that the CMIP scheme can greatly improve the system performance in terms of increased cache hit ratio, reduced uplink requests and negligible additional traf?c References 1] S. Acharya, M. Franklin, and S. Zdonik. Prefetching From a Broadcast Disk. Proc. Int  l Conf. on Data Eng., pages 276  285, Feb. 1996 2] S. Acharya, M. Franklin, and S. Zdonik. Balancing Push and Pull for Data Broadcast. Proc. ACM SIGMOD, pages 183  194, May 1997 3] S. Acharya, R. Alonso, M. Franklin, and S. Zdonik. Broadcast disks: Data Management for Asymmetric Communication Environments. Proc. ACM SIGMOD, pages 199  210 May 1995 4] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In J. B. Bocca, M. Jarke, and C. Zaniolo editors, Proc. 20th Int. Conf. Very Large Data Bases, VLDB pages 487  499. Morgan Kaufmann, 12  15 1994 5] R. Agrawal, Tomasz Imielinski, and Arun Swami. Mining Association Rules Between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207  216, Washington, D.C May 1993 6] G. Cao. Proactive Power-Aware Cache Management for Mobile Computing Systems. IEEE Transactions on Computers, 51\(6  621, June 2002 7] G. Cao. A Scalable Low-Latency Cache Invalidation Strategy for Mobile Environments. IEEE Transactions on Knowledge and Data Engineering, 15\(5 ber/October 2003 \(A preliminary version appeared in ACM MobiCom  00 8] K. Chinen and S. Yamaguchi. An Interactive Prefetching Proxy Server for Improvement of WWW Latency. In Proc INET 97, June 1997 9] E. Cohen and H. Kaplan. Prefetching the means for docu 


9] E. Cohen and H. Kaplan. Prefetching the means for document transfer: A new approach for reducing web latency. In Proceedings of IEEE INFOCOM, pages 854  863, 2000 10] R. Cooley, B. Mobasher, and J. Srivastava. Data preparation for mining world wide web browsing patterns. Knowledge and Information Systems, 1\(1  32, 1999 11] C. R. Cunha, Azer Bestavros, and Mark E. Crovella. Characteristics of WWW Client Based Traces. Technical Report TR-95-010, Boston University, CS Dept, Boston, MA 02215, July 1995 12] D. Duchamp. Prefetching hyperlinks. In USENIX Symposium on Internet Technologies and Systems \(USITS  99 1999 13] V. Grassi. Prefetching Policies for Energy Saving and Latency Reduction in a Wireless Broadcast Data Delivery System. In ACM MSWIM 2000, Boston MA, 2000 14] S. Hameed and N. Vaidya. Ef?cient Algorithms for Scheduling Data Broadcast. ACM/Baltzer Wireless Networks \(WINET  193, May 1999 15] Q. Hu and D. Lee. Cache Algorithms based on Adaptive Invalidation Reports for Mobile Environments. Cluster Computing, pages 39  48, Feb. 1998 16] Z. Jiang and L. Kleinrock. An Adaptive Network Prefetch Scheme. IEEE Journal on Selected Areas in Communications, 16\(3  11, April 1998 17] V. Padmanabhan and J. Mogul. Using Predictive Prefetching to Improve World Wide Web Latency. Computer Communication Review, pages 22  36, July 1996 18] N. Vaidya and S. Hameed. Scheduling Data Broadcast in Asymmetric Communication Environments. ACM/Baltzer Wireless Networks \(WINET  182, May 1999 19] L. Yin, G. Cao, C. Das, and A. Ashraf. Power-Aware Prefetch in Mobile Environments. IEEE International Conference on Distributed Computing Systems \(ICDCS 2002 Proceedings of the 2004 IEEE International Conference on Mobile Data Management \(MDM  04 0-7695-2070-7/04 $20.00  2004 IEEE pre></body></html 


um be r o f C he ck ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 6. The Number of Checked Patterns on the Pumsb Data Set 10 100 1000 10000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 R un T im e s ec  Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 7. The RunTime Comparison on the Pumsb Data Set The runtime comparison of MHP and MAFIA on the Pumsb* data set is shown in Figure 5. In the ?gure, we can observe that the runtime of MHP can be signi?cantly reduced with the increase of h-con?dence thresholds. Also the runtime of MHP can be several orders of magnitude less than that of MAFIA even if the h-con?dence threshold is as low as 0.3. The reason is that the number of checked patterns of MHP is sign?cantly smaller than that of MAFIA Similar results are also obtained from the pumsb data set as shown in Figure 6 and Figure 7. For the pumsb data set the number of checked patterns of MHP is much smaller 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207ñ216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intíl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intíl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 






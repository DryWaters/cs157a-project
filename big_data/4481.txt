A Scalable and High-efficiency Discovery Service In IoT Using a New Storage Schema Minbo Li*†, Zhu Zhu*, Guangyu Chen Software School, Fudan University, Shanghai, China China Internet Network Information Center, Beijing, China e-mail: limb@fudan.edu.cn  Abstract Discovery Service \(DS\, used to trace the movement of objects along supply chains, is an important component of the Internet of Things \(IoT\S is faced with the challenge of huge volume of data as well as large amount of parallel requests of discovery and publish. This paper proposes a new central-indexing DS system using distributed NOSQL database HBase to better support big data and parallel processing. A 
new storage schema of DS data is designed to optimize the discovery efficiency of DS records. The new storage schema uses object ID as row key, event timestamp as column identifier and event index content as cell value. The typical recursive discovery algorithm, which is needed in DS but often neglected in previous works, is specified to realize the full tracing of object’s movement. A prototype of the DS system proposed is implemented. The experiments show that the number of concurrent discoveries the proposed DS can handle per second is about 200 times that of the DS based on RDBMS 
and the number of concurrent publishes the proposed DS can process per second is about five times that of the DS based on RDBMS Keywords-Discovery Service; HBase; EPCglobal; IoT I   I NTRODUCTION  Internet of Things \(IoT\ is expected to provide automatic tracking and tracing of serial-level objects’ movement along the supply chain. This function of IoT will benefit the supply chain management of trade partners, help customers to verify the authenticity of articles, and enable government to better supervise the circulation of products in trade. Like web search engines by which you can get relevant webpages 
immediately by typing a keyword, IoT should offer a service which takes the identification of an object as input and outputs the historical logistics information of this object in the supply chain. This function is named IoT Discovery Service \(DS\. Unlike webpages, information resources of IoT are not public on Internet and don’t link to each other Thus the approaches of gathering data and retrieving information for DS are very different from web search engines The EPCGlobal architecture framework 1 is a widely used standard in constructing IoT application. In this architecture, instant data sharing over the whole IoT network is achieved by cooperation of three components which are Information Service \(IS\ject Naming Service 
ONS\d Discovery Service \(DS\. Information Service 2  captures and stores event data in local databases. IS servers are maintained by different supply chain enterprises independently. Object Naming Service 3 resolves an object ID and maps it to a static information resource such as a DS server or the manufacturer’s IS server. Discovery Service maps an object ID to a sequence of relevant IS servers who store relevant event data about the specific object EPCGlobal has published the standards of IS and ONS but the specific standard of DS is still under discussion. In 2007, the Bridge project 4 did further research on Seriallevel Lookup Service based on EPCGlobal architecture framework and gave more specific definitions about DS 
including the record types, input and output, security mechanism, etc. Bridge also analyzed all the possible DS interaction models and concluded with several applicable models. Wen Zhao 5 classified DS solutions into centralized warehouse mode, centralized indexing mode and “follow the chain” mode in the perspective of where and how the DS data are stored. IBM developed a Theseos search engine 6 to trace individual object’s movement along the supply chain by relaying query along the IS chain in order to generate e-pedigrees or achieve targeted recall Theseos is a P2P solution of DS. There are also some other researches     on the P2P solution of Discovery Service in which a DS query is also propagated along IS 
servers. Sergei 11 did comparison of several DS architectures. P2P mode can balance the work load very well but it has difficulty to promote because of an inherent chain scission problem. If there is a broken linkage in the chain caused by data loss or server broken-down or access refusal, the left part behind the broken linkage would be lost In centralized indexing mode, when the object moves along the supply chain, the event data captured by each IS are not only stored locally, but also actively published to the DS in the form of light weighted index. In this way, DS can discover the relevant event indexes for an object from its local database. Partial data missing would not fail the whole discovery. Compared to P2P, centralized indexing mode is 
more practical. But centralized indexing DS is faced with huge data as well as the pressure of lots of concurrent reading and writing requests. However, few follow-up researches are working on improving its ability to maintain and retrieve from massive data as well as the ability to handle large amount of parallel requests Most objects would be packaged into larger containers for transit in its lifecycle. The tags of individual objects inside the container cannot be read directly. When user wants to discovery the history of an individual object, not only the 
2013 IEEE 37th Annual Computer Software and Applications Conference 0730-3157/13 $26.00 © 2013 IEEE DOI 10.1109/COMPSAC.2013.125 754 


events relevant to the object directly are interested, but also the events happened to its container during its transportation are interested. To meet this requirement, recursive discovery should be executed. In the previous works, recursive discovery is always regarded as the responsibility of the client and few work is done about it To solve these problems, a new storage schema of DS data based on a distributed and scalable big data storage tool HBase 12 is proposed in this paper. A typical recursive discovery algorithm is designed and specified. A DS prototype which is based on the new storage schema and offers recursive discovery service is implemented Experiments prove that the new DS shows a significant improvement in both the query efficiency under massive data and the ability to handle parallel read and write requests compared to DS based on RDBMS II   B ACKGROUND OF DS A  Basic definitions about DS According to the documents of Bridge 4 a DS query should specify an object ID \(O ID\ interest, the user’s authentication credentials, and optionally additional constraints. The information provided by Discovery Service in response to a query should consist of a subset of information extracted from multiple DS records concerned with the specified object   Event IS_ID publisher eventTime publishTime businessStep IS IS_ID  service_addr service_type AC_Info  BasicEvent objectList:List<OID AggEvent parent:OID childList:List<OID TransEvent parentList:List<OID childList:List<OID signature action action  Figure 1  Class diagram of DS event index  Figure 1 shows the typical structure of DS records. DS stores three types of events--BasicEvent, AggEvent and TransEvent. They share some common elements such as IS publisher, timestamps, digital signature, etc. Each one has unique attributes. In a BasicEvent, the action can be CREATE”, “LINK”, “CLOSE”, “DESTROY”, etc. A BasicEvent is concerned with a single list of OIDs. In an AggEvent, the action can be “ADD” or “DELETE”. An AggEvent is concerned with both a parent OID and a list of child OIDs. It records an op eration that child objects are added to or deleted from the parent object. A TransEvent is concerned with both a list of parent OIDs and a list of child OIDs. It records the operation that parent objects are transformed into the child objects. BasicEvent which records event of objects leaving an IS or reaching a new IS AggEvent and TransEvent are defined as key events for DS and should be published actively to DS by IS servers B  HBase Apache HBase 12 is a distributed, scalable, big data store modeled after Google’s Bigtable 13 HBase offers strictly consistent reading and writing, automatic failover support between region servers, block cache for real-time queries and good concurrency especially in reading Table in HBase follows the key-value model. A data row in HBase is composed of a row key and an arbitrary number of columns. New columns can be appended to a row dynamically, but every column must belong to a predefined column family. A data cell can hold multiple versions of data distinguished by the timestamp of the update writing Different from traditional RDBMS, HBase is more like a multi-dimensional sorted map: \(Row Key, ColumnFamily Column, Timestamp\> CellValue. Figure 2 gives an example of data model in HBase. All the accesses to HBase table are though the row keys. Secondary indexes on columns are not provided \(tho ugh you can create an extra table by yourself\eries across multiple tables are not supported. All the above features should be taken into consideration for designing DS storage schema in HBase Row Rowkey1  Column Family A  Column X  Timestamp T1  Value1  Timestamp T2  Value2  Column Y  Timpstamp T3  Value3   Column Family B  Column Z  Timestamp T4  Value4    Figure 2  HBase data model  C  A Discovery Service Scenario Figure 3 shows an example scenario of how a product travels along the supply chain and how IoT tracks its movement IS1 IS2 IS3 IS4 DS Status change Manufacturer 3PL Distributor Retailer client ONS 1 2 SGTIN1 3 Product SSCC1 Pallet SSCC2 Truck SSCC3 SSCC2 Pallet SSCC1 SGTIN1 Product Package Package  Figure 3  An example scenario Manufacturer produces a product and identifies it by a SGTIN \(Serialized Global Trade Item Number  named by SGTIN1 in a barcode. This product is packed into a package identified by a SSCC \(Serial Shipping Container Code 1  named SSCC1 in a barcode. Then this package is loaded to a 
755 


pallet which is identified by SSCC2 in a RFID tag. Events happened during this period are captured and stored by the manufacturer’s IS. The pallet is then handed over to a 3PL Third Party Logistics\ for transit. The 3PL loads the pallet to a truck identified by SSCC3 in a RFID tag. The destination of the truck’s journey is a distributor. Until it reaches the distributor, the events happened are captured and stored by the 3PL’s IS. When the truck’s journey is finished the pallet SSCC2 is offloaded from the truck, and then the package SSCC1 is offloaded from the pallet. The distributor sends the package to a retailer. Events happened during this period are captured and stored by the distributor’s IS. The retailer dismantles the package SSCC1 and takes the product SGTIN1 out. Finally the product is put on the goods shelf and sold to a customer. These events are captured and stored by the retailers’ IS. In this scenario, during the whole lifecycle of this product, its status changes as “product  package pallet truck pallet package product In each phases, readers usually only read the identification of the top level container. Data captured by readers and sensors are recorded as IoT events and stored in different IS servers To realize the discovering of the whole story, four IS  servers respectively publish the event indexes to a central DS. When client wants to discover the information of the product SGTIN1, first he locates the DS in charge by querying ONS After DS received the client’s discovery request, it responds with a sequence of IS resources which is {IS1, IS2, IS3, IS4 Then the client queries these IS  servers for the detail information of the product III  A RCHITECTURE OF D ISCOVERY S ERVICE  A  A new storage schema of DS data As we mentioned in Section 2, HBase is very different from RDBMS, thus it’s impossible to move the data structure of DS in RDBMS to HBase directly. In the new storage schema, all the data concerned with discovery operation should be stored in a single table. An appropriate row key should be chosen to make data reading and writing efficient. The new storage schema should minimize the data redundancy caused by violation of the formal forms of RDBMS Figure 4\(a\d 4\(b\hows the storage schema proposed for DS. OID, the key of typical discovery query, is chosen as the row key. Each cell stores an event index in a specific format. The column identifier is the timestamp of the event It should be noticed that the timestamp used as the column identifier is the time when the event actually happens rather than the time when the writing action happens. By this schema, each OID is mapped to a time-ordered list of event indexes in the key-value model. Figure 4\(c\ gives an example of the content of a cell which describes an event index in a plain text. When OIDs in a list are consecutive we can record them as “fisrtOID-lastOID” to save memory For each OID, all the events directly concerned with it are stored in the row of OID. Since an event is concerned with multiple OIDs, an event indexes will be written in several different rows repeatedly. When a new event index is published, DS server parses the event index into a text in specific format and extract the set of directly related OIDs of this event. For each OID in the set, DS appends a new cell recording this event index to the row of this OID  OID1 OID2 OID3 timestamp1 event1.info timestamp3 event3.info timestamp5 event5.info timestamp7 event7.info  timestamp1 event1.info timestamp4 event4.info timestamp6 event6.info timestamp9 event9.info  timestamp2 event2.info timestamp3 event3.info timestamp5 event5.info timestamp8 event8.info   a Rowkey OID Column Family ‘event Column EventTime1: Value EventInfo_1 Column EventTime2: Value EventInfo_2  Column EventTimeN: Value EventInfo_N    EventInfo example action=ADD IS=IS_001|IS|http://www.001.com/IS eventTime=2012-08-06 13:58:19.0 parent=z001 childList={x001-x010,y001-y020 publisher=Tom  b\                                                          \(c Figure 4  DS storage schema in HBase In this storage schema, the time cost of discovering the related events of a specific OID is minimized. Besides though the replications of event indexes in different rows cause data redundancy, the size of each event index text is quite small. For DS based on RDBMS, when the data size is huge, it’s necessary to store mappings from OID to event IDs in an extra table, otherwise the time cost of a discovery will be intolerable. Comparing the memory costs of the storage schema proposed and the storage schema in RDBMS with an <OID, eventID> mapping table, we will see that the gap is not large. This will be proved by experiments in section 4 HBase is a distributed database in the master-slave mode and provides good concurrency in both reading and writing A big table is distributedly stored at different slave servers in a balanced way. When a request of reading or writing is sent to HBase, it locates the slave server which is in charge of the target data area and dispatches the request to the slave server. This strategy enables HBase to handle concurrent reading and writing very effectively. Moreover, HBase offers block cache for real-time query. With these advantages, the new persistence layer of DS obtains good performance B  Business logic There are two business operations that DS will execute frequently. The first one is accepting publish of new event indexes from authorized IS servers. This second one is discovering relevant event indexes for OIDs specified in queries from users 1  Publish an event index DS accepts publish request of new events from authorized IS servers in real time. A valid publish request should 
756 


consist of the publisher’s authentication credentials, service type and service address of the IS, action type, event time list of concerned object IDs, and digital signature to the new event index. When DS accepts a publish request, it first validates the authentication of the publisher and the digital signature, then processes the event index and appends it to the rows concerned with relevant object IDs 2  Recursive Discovery Most objects would be packaged into larger containers for transit in the supply chain. When they are packaged into larger containers, the tags of these objects cannot be read directly. When user wants to discovery the history of an individual object, not only the events captured by reading the object’s tag directly are interested, but also the events happened to its container are interested. To meet this requirement, recursive discovery is necessary  Lifecycle end Lifecycle unfinished Level_1 Container Level_2 Container  Level_N Container  ADD DELETE ADD DELETE  ADD DELETE  No Successor No Successor No Successor  No Successor  CLOSE|DESTROY|TRANS CREATE|TRANS BASIC  BASIC  BASIC BASIC start Single Object No Successor  Figure 5  Recursive Discovery Model in DFA We designed a typical recursive discovery algorithm and implemented it in our DS prototype system. Figure 5 shows the diagram describing the rule of typical recursive discovery The recursive discovery is operated as the following steps Step 0 Initialize the status as Level_0 Step 1 An OID and a discovery time range \(ST, ET\e input. DS reads the row of OID from HBase and gets the list L of cells \(event indexes\ whose timestamps are in \(ST, ET Step 3 Read the event indexes in L one by one If it’s an event index in which current OID is added to a container, transfer to status Level_x where x = current status level+1, and recursively execute discovery on \(OID of the container, timestamp of this event, ET\ the result R and append R* to the result set. If the tail event of R* equals to the next event in L, continue. Otherwise, it denotes that the lifecycle of OID is not completed by this moment, then close the discovery and return the result set If it’s an event index in which the previous OID are deleted from current OID as a child, transfer to the status Level_x where x = current status level–1, add this event into the result set, and return the result set If it’s an event index in which the OID is closed or destroyed or transformed to other things, close the discovery and return the result set If it’s a basic event index of other actions, add it to the result set and continue Step 4 If the result set has not been returned after all the event indexes in L have been processed, it denotes that the lifecycle of OID is not completed by this moment, close the discovery and return the result set IV  E XPERIMENT AND E VALUATION  We implemented a DS prototype proposed in this paper and named it as “Mode 3” in experiments. Another two DS prototypes based on RDBMS are also implemented for comparison with the proposed DS. They are named as Mode 1” and “Mode 2”. The service interfaces and business logics of the three prototypes are similar IS BasicRecord AggRecord TransRecord ChildLis tF or Basic ChildLis tFor A gg ParentListForTrans ChildLis tF or Trans 1 1 1 1 1 1 1 IS_ID serviceType serviceAddr  record_id OID OID record_id OID record_id OID record_id action time record_id  IS_ID action time record_id IS_ID parent  time record_id  IS_ID  Figure 6  Database schema of Mode 1 In Mode 1, the database schema is designed following the class diagram of DS events \(Fig. 1\, and is shown in figure 6. The full information of an event index has to be separately stored in several tables. In Mode 2, besides all the tables in Mode 1, an extra indexing table whose structure is shown in table 1 is built to accelerate the discovery TABLE I  OID  I NDEX TABLE  Attributes OID Even t _Type Record_ID Event_Time DataType String Enum{Basic, Agg, Trans Long Timestamp A  Experiment Environment In the prototypes of Mode 1 and Mode 2, a machine is served as the DS server. The model of the machine’s CPU is Intel\(R\ Core\(TM\ i5-2400 CPU @3.10 GHz. The RAM memory size of the machine is 4 GB. The software of RDBMS is Mysql Ver 14.14 Distrib 5.5.20 
757 


In the prototype of Mode 3, three machines of the same configuration compose the HBase cluster. In each machine CPU model is Inter\(R\ Core\(TM\ Duo CPU E8400 3.00GHz, the RAM memory size of each machine is 4 GB and the software used for HBase are Hadoop-0.20.2 zookeper-3.3.5 and hbase-0.90.5 B  Dataset We surveyed a famous clothing factory and collected some information about the data DS may handle 1  About 10,000,000 clothes are produced every year 2  20-30 clothes are packed into a box 3  An auto container carries at most about 150 boxes 4  An auto container experiences several ADD or DELETE events during a shipping process 5  An article travels through 3-5 supply chain links in its lifecycle, and 10-20 DS events in the perspective of IoT information discovery According to these features, we generate the dataset for experiment. The dataset contains about 1,100,000 nested event indexes and describes the history of 1,000,000 objects’ movement along the supply chain. Readers may notice that 1,100,000 is much smaller than the product of 1,000,000 and 10. That is because the number of relevant objects to each event varies from 1 to 150 in this scenario C  Experiment 1 of the average time cost Experiment 1 examines the average time cost of a single recursive discovery under three modes. The number of traced objects increases from 10,000 to 1,000,000. For a single object, 12-18 DS events are discovered by a recursive discover query. Figure 7 shows how the average time costs of a recursive discovery change as the data size is increasing under three modes  Figure 7  Comparison of avg timecost of a recursive discovery In Mode 1, the time cost is apparently hard to tolerate especially when the data size is large. Thus we regard this mode as a complete failure. In Mode 2, the average time cost of a query increases with the increase of data size, but it is still tolerable. In Mode 3, there is not an obvious growth trend of the discovery time curve with the increase of data size. The average discovery time of Mode 3 is less than 10 of that of Mode 2 when the number of traced objects is larger than 700 thousand D  Experiment 2 of the memory cost Experiment 2 records the memory cost of the data storage as more and more events are published to the DS. The comparisons of memory cost under different modes are presented in figure 8. Under each mode, the memory cost is increasing linearly with the increasing of traced object number. Obviously, Mode 1 costs the least memory. The memory cost of Mode 2 is nearly 3 times of Mode 1 because the indexing table is very large. The memory cost of Mode 3 is about 30% larger than Mode 2. But considering the great improvement in discovery efficiency this redundancy is acceptable  Figure 8  Comparison of memory cost E  Experiment 3 of parallel query Since the performance of Mode 1 is intolerable, we only tested Mode 2 and Mode 3 in the following two experiments Both experiment 3 and 4 are executed under the condition that event indexes tracking 1,000,000 objects’ movement are stored in database. Figure 9 shows the query numbers of recursive discovery Mode 2 and Mode 3 can handle under different numbers of parallel clients. Since the maximum parallel connection number of Mysql is 100, the tests under 200 and 400 parallel clients are only executed in Mode 3 As the number of parallel clients is increasing, the QPS query per second\s also increasing drastically In fact, the bottleneck of the performance is in the business logic layer rather than the data persistence layer in the given experiment environment. However, the QPS of Mode 2 is not increasing with the number of parallel clients. It can only handles around 10 queries per second which is only about 0.5% of Mode 3 F  Experiment 4 of parallel publish Experiment 4 records the request numbers of event publish DS can handle per second under different modes 
758 


with the increase of parallel clients. Every event index published in test is of the same size, and every event is relevant to 20 objects. In Mode 2, when DS accepts a publish request, it writes the information about this event index into several tables and then updates the OID index table. While in Mode 3, DS appends the event index to the rows of the concerned OIDs. Figure 10 shows the experiment results of parallel publishes. Tests under 200 and 400 parallel clients are only executed on Mode 3 for similar reason in Experiment 3. The maximum number of parallel publishes that Mode 2 can handle per second is less than 80 while the maximum number of parallel publishes that Mode 3 can handle is nearly 400  Figure 9  Comparison of parallel queries handled per second  Figure 10  Comparison of parallel publishes handled per second Experiment 1 to experiment 4 proved that both the ability to discover information from a big volume of DS records and the ability to handle concurrent requests of the proposed DS system are much better than DS based on RDBMS and its extra memory cost is acceptable V  C ONCLUSION  This paper works on improving the central-indexing DS which is faced with the challenge of massive data and large amount of parallel requests. The paper presents a new storage schema of DS data based on HBase. The new storage schema uses OID as row key, event time as column identifier, and event index as cell value to improve the discovery efficiency. A recursive discovery algorithm is specified to realize the full tracing of object which consists of both the events happened to the specific object and the events happened to its containers. The recursive discovery is included in the DS system as a service to reduce the client’s workload. A prototype of the proposed DS system is implemented. A series of comparison experiments are conducted to prove the performance advantage of the proposed DS system in both efficiency and concurrency A CKNOWLEDGMENT  The research activities as described in this paper were funded by national 863 high technology plan of China Grant No. 2011AA100701\ and the DNSLAB research project of China Internet Network Information Center R EFERENCES  1  EPCGlobal. The EPCGlobal Achitecture Framework Final Version 1.4, 2010 http://www.gs1.org/gsmp/kc/epcglobal/architecture/architecture_1_4framework-20101215.pdf 2  EPCGlobal. EPC Information Services \(EPCIS\rsion 1.0.1. 2007 http://www.gs1.org/gsmp/kc/epcglobal/ons/ons_1_0_1-standard20080529.pdf 3  EPCGlobal. EPCglobal Object Naming Service \(ONS\. 2008 http://www.gs1.org/gsmp/kc/epcglobal/ons/ons_1_0_1-standard20080529.pdf 4  Bridge. WP02 High level design of Discovery Services, 2007 5  Wen Zhao, XueYang Liu, Sen Ma, ChongYi Yuan, LiFu Wang. A Distributed RFID Discovery System: Achitecture, Component and Application. The 14th IEEE International Conference on Computational Science and Engineering, 2011 6  A Cheung, K Kailing, and S Schonauer, Theseos: A Query Engine for Traceability across Sovereign, Distributed RFID Databases. Proc. of the 2007 IEEE 23rd International Conference on Data Enginering Istanbul, Apr 2007. 1495-1496 7  Liu Dongdong Study on the information discovery service of Internet of Things based on P2P. Zhengzhou University, 2011 8  Kong Ning. Research on Key Technology of the Resource Addressing in the Internet of Things. Graduate University of Chinese Academy of Sciences, 2008 9  Zhao Wen, Li XinPeng, Liu Dianxing, Zhang Shikun, Wang Lifu. A Distributed RFID Discovery Service for Supply Chain. ACTA ELECTRONICA SINICA. Vol. 38, No. 2A, P99-106, Feb 2010   Zheng Linjiang, Liu Weining, Lu Yanliang. Link-style discovery service method based on extended ONS.Computer Engineering and Applications. 2010, 46\(6\204-207   Sergei Evdokimov, Benjamin Fabian, Steffen Kunz, Nina Schoenemann. Comparison of Discovery Service Architectures for the Internet of Things. 2010 IEEE International Conference on Sensor Networks, Ubiquitous, and Trustworthy Computing   HBase. http://hbase.apache.org   F. Chang, J. Dean, S. Ghemawat, w.e. Hsieh, D.A. Wallach, M Burrows, T. Chandra, A. Fikes and RE. Gruber. Bigtable: a distributed storage system for structured data. ACM Transactions on Computer Systems, vol 26, Jun. 2008, doi:10.1145/1365815.1365816   EPCGlobal. EPC Tag Data Standard Version 1.5, 2010 http://www.gs1.org/gsmp/kc/epcglobal/tds/tds_1_5-standard20100818.pdf  
759 


Figure 9  A map of the area with 002elds of view and localization points Figure 10  A frame and the image points from Camera 1 for the vessel without AIS By applying the same procedure to one of the previously estimated position for both passenger ships as shown in Figure 13 b and c we obtain a much more stretched estimated covariance Clearly localization accuracy in range is much smaller than in azimuth and it is a function of target distance from the sensors All the results are superimposed as green points in Figure 13 d observing that the crosses keep their shape near the coast and collapse with increasing distance 8 C ONCLUSIONS This paper has proposed an innovative calibration technique for cameras displaced on harbour coastline in which the calibration points are obtained from AIS data from ships sailing in the cameras 002elds of views Our experimental results have showed that the procedure localizes well vessels appearing in the two camera 002elds of view Future work will focus on the deployment of larger arrays of cameras A con\002guration with N cameras implies a longer calibration phase but any increase in view diversity would contribute to an increase in localization precision The procedure must be inherently adaptive also because a generic vessel could be seen only by a subset of the sensor array at any given time Therefore localization of a vessel requires a combination of solutions of different systems 13 for best use of available information Figure 11  A frame and the image points from Camera 2 for the vessel without AIS Figure 12  Pixel cross-variation for Camera 1 a and Camera 2 b to evaluate localization accuracy Figure 13  Error position covariance for vessel without AIS a Abundo b and Nomentana c 7 


Another important issue is the positioning of cameras in the harbour It is well-known that the localization accuracy is strongly dependent on the distance from the vessels range but an intelligent displacement of cameras with their 002elds of view properly intersected to cover almost the same portion of the sea plane could increase the strength of the whole process A CKNOWLEDGMENTS We would like to thank Prof Carlo Regazzoni from Universit 264 a di Genova for very stimulating discussions on data fusion and for letting us use his precious class notes R EFERENCES  R Tsai 223A versatile camera calibration technique for high-accuracy 3d machine vision metrology using offthe-shelf tv cameras and lenses,\224 IEEE Journal of Robotics and Automation vol 3 no 4 pp 323-344  August 1987  Z Zhang 223A 003exible new technique for camera calibration,\224 IEEE Transactions on Pattern Analysis and Machine Intelligence vol 22 no 11 pp 1330-1334  November 2000  Technical characteristics for an automatic identi\002cation system using time-division multiple access in the VHF maritime mobile band  Recommendation ITU-R M.1371-4 April 2011  IALA Guideline No 1082 On an Overview of AIS  International Association of Marine Aids to Navigation and Lighthouse June 2011  International Convention for the Safety of Life at Sea SOLAS  IMO May 2011  R Hartley and A Zisserman Multiple View Geometry in Computer Vision 2ed  Cambridge 2003  E Trucco and A Verri Introductory Techniques for 3-D Computer Vision  Prentice Hall 1998  G Medioni and S B Kang Emerging Topics in Computer Vision  Prentice Hall 2004  223Marine traf\002c,\224 http://www.marinetraf\002c.com/ais 2012 B IOGRAPHY  Francesco A.N Palmieri received his Laurea in Ingegneria Elettronica from Universita degli Studi di Napoli Federico II Italy in 1980 In 1981 he served as a 2nd Lieutenant in the Italian Army in full\002llment of draft duties In 1982 and 1983 he was with the ITT 002rms FACE SUD Selettronica in Salerno currently Alcatel Italy and Bell Telephone Manufacturing Company in Antwerpen Belgium as a designer of digital telephone systems In 1983 he was awarded a Fulbright scholarship to conduct graduate studies at the University of Delaware USA where he received a Master's degree in Applied Sciences and a PhD in Electrical Engineering in 1985 and 1987 respectively He was appointed Assistant professor in Electrical and Systems Engineering at the University of Connecticut Storrs USA in 1987 where he was awarded tenure and promotion to Associate Professor in 1993 In the same year he was awarded the position of Professore Associato at the Dipartimento di Ingegneria Elettronica e delle Telecomunicazioni at Universit 264 a degli Studi di Napoli Federico II Italy where he has been until October 2000 when he became Professore Ordinario di Telecomunicazioni and moved to the Dipartimento di Ingegneria dellInformazione  Seconda Universit 264 a di Napoli Aversa Italy His research interests are in the areas of signal processing data fusion communications information theory and neural networks Francesco Castaldo received his Laurea in 2009 and his Laurea Magistrale in 2012 both in Ingegneria Informatica from Seconda Universita degli Studi di Napoli SUN He has cooperated during his thesis work with the PRISMA lab at Universit 264 a degli Studi di Napoli Federico II with prof B Siciliano and prof V Lippiello He is currently a postgraduate fellow with the Dipartimento di Ingegneria Industriale e dell'Informazione at SUN His research interests are in image processing computer vision and data fusion applied to robotics and home automation Guglielmo Marino received his Laurea in Ingegneria Elettronica at Seconda Univerit 264 a degli Studi di Napoli SUN in December 2012 His 002nal thesis project has been on data fusion of digital images with AIS data in harbor management 8 


boards of several journals including IEEE Transactions on Service Computing and the Journal of Performance Evaluation   Zhen has given keynotes and distinguished lectures in various conferences and universities. He was an adjunct professor at University of Science and Technology of China and Beijing University of Post and Telecommunications While he was in France Zhen was  also an adjunct professor of the University of Paris VI \(University of Pierre & Marie Curie\and the University of Nice  Sophia Antipolis, France   His areas of expertise include mobile computing, mobile services, cloud computing, stream processing re al time analytics performance modeling stochastic optimization service oriented architecture and semantic Web      
lxxxi 


en-US Keynote VI I I  en-US GreenCom iThings CPSCom 2013   Towards Carrier Cloud   Dr. Tarik Taleb  Senior Researcher and 3GPP Standards Expert  NEC Europe Ltd, Heidelberg, Germany  Email tarik.taleb@nw.neclab.eu    Abstract   Mobile operators are in need of means to cope with the ever increasing mobile data traffic, introducing minimal additional capital expenditures on existing infrastructures, principally due to the modest Average Revenues per User ARPU Network virtualizat ion and cloud computing techniques along with the principles of the latter in terms of service elasticity on demand and pay per use could be important enablers for various mobile network enhancements and cost reduction This talk discusses the recent tr ends the mobile telecommunications market is experiencing showcasing some of the emerging consumer products and services that are facilitating such trends. The talk also discusses the challenges these trends are representing to mobile network operators. T he talk also demonstrates the possibility of extending cloud computing beyond data centers towards the mobile end user providing end to end mobile connectivity as a cloud service. The talk introduces a set of technologies and methods for the on demand pro vision of a decentralized and elastic mobile network as a cloud service over a distributed network of cloud computing data centers; federated cloud. The concept of Follow Me Cloud whereby not only data but also mobile services are intelligently following t heir respective users is also introduced. The novel business opportunities behind the envisioned carrier cloud architecture and service are also discussed, considering various multi stakeholder scenarios   Bio   Tarik Taleb is currently working as Senior Researcher and 3GPP Standards Expert at NEC Europe Ltd Heidelberg, Germany. Prior to his current position and till Mar. 2009, he worked as assistant professor at the Graduate School of Information Sciences, Tohoku University, Japan, in a lab fully funded by KDDI, the second largest network operator in Japan From Oct 2005 till Mar 2006 he was working as research fellow with the Intelligent Cosmos Research Institute Se ndai Japan He received his B E   degree in Information Engineering with distinction M.Sc and Ph.D degrees in Information Sciences from GSIS Tohoku Univ., in 2001, 2003, and 2005, respectively   Dr Taleb  s research interests lie in the field of architectural enhancements to mobile core networks particularly 3GPP  s mobile cloud net working mobile multimedia streaming congestion control protocols handoff and mobility management inter vehicular communications and social media networking Dr Taleb has been also directly engaged in the development and standardization of the Evolved  Packet System as a member of 3GPP  s System Architecture working group. Dr. Taleb is a board member of the  IEEE Communications Society Standardization Program Development Board  As an attempt to bridge the gap between academia and industry Dr Taleb has f ounded and has been the     Dr Taleb  is/was on the editorial board of the IEEE Wireless Communications Magazine IEEE Transactions on Vehicular Technology, IEEE Communications Surveys & Tutorials, and a number of Wiley journals. He is serving as vice chair of the Wireless Communications Tech nical Committee, the largest in IEEE ComSoC He also served as Secretary and then as Vice Chair of the Satellite and Space Communications Technical Committee of IEEE ComSoc 2006  2010 He has been on the technical   
lxxxii 


program committee  of different IEEE c onferences including Globecom, ICC and WCNC and chaired some of their symposia   Dr Taleb is the recipient of the 2009 IEEE ComSoc Asia Pacific Best Young Researcher award Jun 2009 the 2008 TELECOM System Technology Award from the Telecommunicati ons Advancement Foundation Mar 2008 the 2007 Funai Foundation Science Promotion Award Apr 2007 the 2006 IEEE Computer Society Japan Chapter Young Author Award Dec 2006 the NiwaYasujirou Memorial Award Feb 2005 and the Young Researcher's Enc ouragement Award from the Japan chapter of the IEEE Vehicular Technology Society \(VTS\\(Oct. 2003\ Some of Dr. Taleb  s research work has been also awarded best paper awards at prestigious conferences. Dr. Taleb is a senior IEEE member      
lxxxiii 


en-US Keynote I X  en-US GreenCom iThings CPSCom 2013   How Densely Should the Data Base Stations  B e Deployed in Hyper Cellular Networks   Professor Zhisheng Niu  Tsinghua National Lab for Information Science and Technology  Tsinghua University, Beijing 100084, China  E mail niuzhs@tsinghua.edu.cn    Abstract   One of the key approaches to make the mobile communication networks more GREEN Globally Resource optimized and Energy Efficient Networks\is to have the cellular architecture and radio resource allocation more adaptive to the environment and traffic varia tions including making some lightly loaded base stations \(BSs\go to sleep. This is the concept of so called TANGO \(Traffic Aware Network planning and Green Operation and CHORUS Collaborative and Harmonized Open Radio Ubiquitous Systems published by th e author earlier. To realize this, a new cellular framework, named hyper cellular networks HCN has been proposed in which the coverage of control signals is decoupled from the coverage of data signals so that the data coverage can be more elastic in ac cordance with the dynamics of traffic characteristics and QoS requirements. Specifically, the data base stations \(DBSs\in HCN can be densely deployed during peak traffic time in order to satisfy the capacity requirement, while a portion of DBSs can be swi tched off or go to sleep mode if the traffic load is lower than a threshold in order to save energy. A fundamental question then arises how densely should the DBSs be deployed in order to balance the QoS requirements and the energy consumption in hyper ce llular networks     In this talk, we characterize the optimal DBS density for both homogeneous and heterogeneous hyper cellular networks to minimize network cost with stochastic geometry theory For homogeneous cases both upper and lower bounds of the optimal DBS density are derived For heterogeneous cases our analysis reveals the best type of DBSs to be deployed for capacity extension or to be switched off for energy saving. Specifically, if the ratio between the micro DBS cost and the macro DBS cost  is lower than a threshold which is a function of path loss and their transmit power then the optimal strategy is to deploy micro DBSs for capacity extension or to switch off macro DBSs \(if possible\for energy saving with higher priority Otherwise the  optimal strategy is the opposite Based on the parameters from EARTH numerical results show that in the dense urban scenario compared to the traditional macro only homogeneous cellular network with no DBS sleeping deploying micro DBSs can reduce about 40 of the total energy cost, and further reduce about 20% with DBS sleeping capability   Bio   Zhisheng Niu graduated from Northern Jiaotong University currently Beijing Jiaotong University Beijing China in 1985 and got his M.E and D.E degrees fr om Toyohashi University of Technology Toyohashi, Japan, in 1989 and 1992, respectively. After spending two years at Fujitsu Laboratories Ltd Kawasaki, Japan, he joined with Tsinghua University, Beijing, China, in 1994, where he is now a professor at the  Department of Electronic Engineering and the deputy dean of the School of Information Science and Technology. His major research interests include queueing theory, traffic engineering, mobile Internet radio resource management of wireless networks, and g reen communication and networks   Dr Niu has been an active volunteer for various academic societies including council member of Chinese Institute of Electronics 2006 10 vice chair of the Information and Communication Network Committee of Chinese In stitute of Communications 2008 12 Councilor of IEICE Japan 2009 11 and membership development coordinator of IEEE Region 10 \(2009 10\ In particular, in IEEE Communication 
lxxxiv 


Society, he has been serving as an editor of IEEE Wireless Communication Magaz ine \(2009 12\ director of Asia Pacific Region \(2008 09\ director for Conference Publications \(2010 11\ chair of Beijing Chapter 2001 08 and members of Award Committee 2011 13 Emerging Technologies Committee 2010 12 On line Content Committee 20 10 12 and Strategy Planning Committee He has also been serving as general co   co    chairs o f    Prof. Niu is a co recipient of the Best Paper Awards from the 13th and 15th Asia Pacific Conference on Communication APCC in 2007 and 2009 respectively and received Outstanding Young Researcher Award from Natural Science Foundati on of China in 2009 He is now the Chief Scientist of the National  Energy and Resource Optimized Hyper Cellular Mobile Communication System 2012 2016 which is the first national project green communications in China He is the fellow of IEEE and IEICE and a distinguished lecturer of IEEE Communication Society \(2012 2013  
lxxxv 



Lina Li Cuiping Li Hong Chen Xiaoyong Du 
Key Laboratory of Data Engineering and Knowledge Engineering MOE Renmin University of China,Beijing China lina licuiping chong duyong ruc.edu.cn 
MapReduce-Based SimRank Computation and Its Application in Social Recommender System 
Recently there has been a lot of interest in graph-based analysis with examples including social network analysis recommendation systems document classiìcation and clustering and so on A graph is an abstraction that naturally 
Abstract 
  
captures data objects as well as relationships among those objects Objects are represented as nodes and relationships are represented as edges in the graph There are many cases in which similarities among nodes are required to compute SimRank is one of the simple and intuitive algorithms for this purpose It is rigidly based on the random walk theorem Existing methods on SimRank computation suffer from one limitation the computing cost can be very high in practice In order to optimize the computation of SimRank a few techniques have been proposed However the performance of these methods are still limited by the processing ability of the single computer Ideally we 
Keywords 
would like to develop new parallel solutions that can offer improved processing power to compute SimRank on large data set In this paper we propose parallel algorithms for SimRank computation on Map-Reduce framework and more speciìcally its open source implementation Hadoop Two different parallel methods are proposed and their performances are evaluated and compared Furthermore we employ the proposed methods to do the similarity computation in order to recommend appropriate products to users in social recommender systems I I 
Simrank Parallel Mapreduce Recommendation 
NTRODUCTION Recently there has been a lot of interest in graph-based analysis with examples including social network analysis recommendation systems document classiìcation and clustering and so on A graph is an abstraction that naturally captures data objects as well as relationships among those objects Objects are represented as nodes and relationships are represented as edges in the graph There are many cases in which it would be important to answer queries such as Which two nodes are the most similar in the network To this end a great number of similarity 16 18 12 and 19 ha v e been proposed Typically there are two kinds of methods computing the 
similarity between two nodes One method is based on the content of text This method takes the text object as a set of short terms or phrases and the weights of terms constitute a feature vector Then proper methods are used to compute the similarity between the text objects with the feature vector The other method is used to compute similarity between linked objects As the objects are linked more information can be inferred from the relation between the two objects SimRank is one of the methods to compute similarity between linked objects And SimRank is applied in many elds such as collaborative ltering recommendation cluster 
algorithm classiìcation algorithm and search engines Existing methods on SimRank computation suffer from one limitation the computing cost can be very high in practice In order to optimize the computation of SimRank a few techniques have been proposed 22 Ho we v er  the performance of these methods are still limited by the processing ability of the single computer Ideally we would like to develop new parallel solutions that can offer improved processing power to compute SimRank on large data set In this paper we propose parallel algorithms for SimRank computation on Map-Reduce framework and more speciìcally its open source implementation Hadoop 
 T w o dif ferent parallel methods are proposed and their performances are evaluated and compared Furthermore we employ the proposed methods to do the similarity computation in order to recommend appropriate products to users in social recommender systems Speciìcally this paper has made the following contributions 
We propose two Map-Reduce-based computation algorithms for the initial iterative SimRank computation and the matrix multiplication SimRank computation respectively We employ the proposed methods to do the similarity computation in order to recommend appropriate prod 
  
ucts to users in social recommender systems 
We conduct extensive experiments on various kinds of real data sets to verify the efìciency and effectiveness of the proposed methods The rest of this paper is organized as follows Section II gives the background information of our study Section III introduces our parallel SimRank computation techniques A performance analysis of our methods is presented in Section IV Section V gives the recommendation policies in social 
 
2013 IEEE International Congress on Big Data 978-0-7695-5006-0/13 $26.00 © 2013 IEEE DOI 10.1109/BigData.Congress.2013.26 133 


A Notations and Assumptions B Initial Iterative Algorithm C Matrix Multiplication Algorithm D Map-Reduce Computing Model E Work of This Paper 
matrices bold upper case transpose of matrix A th element of matrix A the number of nodes in the graph the current iterative step the decay factor for SimRank Without loss of generality given a graph 
T 
O n O n G V E V E v I v O v v S a b  a b S a b c I a I b S I i a I j b c I a a I j a j I a S k a b c I a I b S k  I i a I j b S k c W T S k  W c I I W W T W M M N 
            0                               1  
    
002     I     I 003  003 
recommender systems We discuss related work in Section VI and conclude the study in Section VII II PRELIMINARIES SimRank is an important method to compute similarities between objects This method can be applied to compute the similarity between hyper-link documents and then sort the documents by the similarity value This method can also be used in recommendation system to recommend an item to a client who might be the potential costumer Typically there are two ways to compute SimRank The rst one is a naive formula which is raised by the SimRank proposer This method calculates similarity accurately but the drawback of this method is the high time complexity of for each iteration step and the high space complexity of  The second one is the matrix multiplication method This method turns the initial formula into a standard adjacent matrix multiplication In this section we provide the necessary background for the subsequent discussions We rst present some notations and assumptions that are adopted in this paper in Section II-A and then give a brief review of two SimRank computations in Section II-B and II-C Table I lists the main symbols we use throughout the paper Table I S YMBOLS where nodes in represent objects of the domain and edges in represent relationships between objects For a node in a graph and denote the set of in-neighbors and out-neighbors of  respectively This method is based on the following assumption if two objects are similar then the neighbors of the objects are also similar Let denote the similarity between two objects and  the iterative similarity computation equation of SimRank is as follows 1 where is the decay factor for SimRank a constant between 0 and 1 is a set of the nodes which are input nodes of  represents node in the node set  This formula indicates that the similarity of nodes are mainly determined by their neighbors Initially the similarity between a node and itself is 1 and the similarity between two different nodes is 0 Later similarities are computed iteratively using the following iterative formula 2 Paper gi v es a ne w w ay to compute SimRank scores between objects In this method the initial formula is turned into the following matrix format 3 where is an identity matrix is a column standardized matrix of the adjacency matrix of the graph is the transport matrix of  Similarity computation of objects in this method is changed to do some matrix multiplications And the related proof is presented in the original paper Map-Reduce is a parallel computing model It splits the input data set into parts and starts mappers and each mapper deals with one data part Mapper produces key/value pairs and writes them into the intermediate les If there are key values in the intermediate result then N reducers need to be started to obtain the nal result This is called a Map-Reduce job Designing a Map-Reduce algorithm has some challenges such as any computing process should be able to turn into map/reduce procedures and obey strict rules The complexity of the algorithm makes it more challenging So far there are some modiìed frameworks such as Pig Latin SCOPE 6 The y pro vide a higher le v el language and even other operators such as join operator Frameworks like Hadoop and iMapReduce 23 are all modiìed on the initial Hadoop In this paper we donêt make any change on the Hadoop platform but we take the strategy that iMapReduce uses which will be mentioned in the following sections All implementations are based on the initial Hadoop platform Existing methods are not scalable and not practical on large dataset This paper pays attention to the details of the parallel SimRank computation on Hadoop platform The following sections present detailed descriptions about the algorithms applications and experimental evaluations on different scale data sets Accuracies and efìciencies of proposed methods are tested and presented 
3 2  a   002 i 1  I  b   002 j 1  a   002 i 1  I  b   002 j 1 1 1 
Symbol Deìnition and Description 
A A A i j i j n k c 
134 


   002 002     004 005  004 005 004 005 004 005   
                                                                                1  1 
  1   1 1   1   1 1 1     1   1   1 1 1 1 
                      
002 002 002 002 002 002 
A Parallelism of Initial Iterative Algorithm 
S a b c I a I b S I a I b i I a j I b S a b c I a I b S i j S a b S i j S a b S a b i\002I a j\002I b S a b i j a b k S a b a b i j a b S a b a b a<b a,b>,S a b k S i j S a b k uin a b    out x y    u v u v u in a,b out x y    u v u out v v in u u in a,b out x y    k k u u 
O UTPUT  The similarity of the node pair  u v  01 Map edge  u v  into records  002 u 003 out  v  and  002 v 003 in  u  02 Reduce the records with the same key to a record  002 u 003 in  a,b  out  x,y  01 Given  u v sim   i 004 O  a   and j 004 O  b  02 Computing S uv  i j  and recorded as  002 i j 003 sim  
Algorithm 1 
III S IM R ANK P ARALLEL C OMPUTATION Equation 2 and 3 show that SimRank scores are propagated through the graph in multiple iterations until convergence As discussed earlier this computation framework is very expensive in most real applications In this section we introduce two new SimRank computation methods which utilize the parallel computation power of Map-Reduce to speed up SimRank computations on large graphs Initial iterative algorithm performs same operations on a data set for several iterations Here we describe our proposed algorithm for the SimRank computation under Map-Reduce framework we rst re-write Equation 2 into the following form 4 Let  wehave 5 Let  then we have 6 where represents the similarity contribution of node pair    making to node pair   nthe iteration  the similarity of node pair  is the sum of all contributions made by other node pairs during one iteration During one iteration all contributions made by the node pair to other node pair are computed as  This process can be achieved by a parallel map procedure The key of the map output is  and the output record is  With the features of Map-Reduce Computing Model the records with the same key will be pushed to the same reducer The reduce procedure then sums up all the contributions for the pair In the iteration step since the similarities of any node pair for the last iteration is known the similarity of is easy to be computed for the iteration step One iteration step uses one MapReduce job This is a typical iterative algorithm The computation tasks of each iteration are independent and similar They need read data from or write data into the le system So the major challenge for an efìcient algorithm for this is to minimize the I/O and communication cost In our setting the topology of the whole graph  especially the input and output node collections of a node need to be obtained during the computation In order to improve the computation efìciency we consider to put this information in the cache The input and output information is recorded as  It is written in a le and then sent to each computer Since the graph is static the information of the input and output node collections is static too In the implementation the information is cached in the Distributed Cache to reduce the communicate cost between task tracker and the job tracker When a Map-Reduce job is run for the rst time the input and output node collections information is put into the memory It is kept in the cache during the whole computing process and can be used for all reduce procedure Through this way the algorithm can reduce the expenses of swap and reduce the communication cost as well Algorithm 1 outlines the pseudo-code of the parallel initial iterative SimRank computation algorithm based on MapReduce for the node pair  Parallel Initial Iterative SimRank Computation I NPUT  The graph G   V E  The whole algorithm consists of two phases The rst phase is to do the pre-precessing During this phase the topology of the graph is pre-processed Each graph edge is changed into the format of  In this way the inputs and outputs of all nodes are obtained The pre-processing phase is nished in a MapReduce computing model In the Map procedure the input record is turned into the records and  In the Reduce procedure the records with the same key are reduced to a record  In the second phase iterative SimRank computation is performed The result les generated in the pre-processing phase are distributed to all computers in the platform These les will be used in the following iterative computing The input le of iteration step is the output of the iteration In the beginning of the second phase the similarity between a node and itself is 1 So initially the similarity record is like  In order to do the computation on Hadoop platform the input le is split into several small les Later each map produce will be performed on one 
k I a i I b j k i j k I a i I j j k k ij c I a I b k k I a i I b j k ij k ij th ij ij th k k ij th th th 
I Pre-processing II Iterative Computation 
135 


 004 005  004 005  004 005 004 005 006 004 005 004 005 004 005 004 005 004 005 004 005 003 004 005 003  003 003  003  004 005 004 005 004 005 003 003 003 003 
th k uv k uv m t th th ij ij ij ij ij ij ij ij mt tn mn mn mn k T k T T c c k T c k c c T c k c T c k T c k c n n m m mn t t n n nt th th ij ij ij i i i 
003 004 005 005 006 007 010 010 011 004 005 005 006 007 010 010 011 
1 1 1 1 1 1 1 1 1 1 11 12 1 21 22 2 1 2 11 12 1 21 22 2 1 2 1 2 3 
B Parallelism of Matrix Multiplication Method 1 Single Tuple Method STM 2 Row Divided Method RDM 
 1                                 1   2     1     2   1   2   1     2              1    1    1 1 1 1 1 1             1 2 3     
small le Each iteration will start a Map-Reduce job The details of the iteration computation is as below Map procedure in the pre-process phase the topology of the graph has been stored in every computer Assuming the input similarity for the iterative step is recorded as u v sim With records and cached in the memory the score of can be computed represents the contribution made by the node pair to other node pairs  The result is recorded in format  Reduce procedure the similarity score of node pair for this iteration can be computed by summing up those records which share the same key Equation 3 entails three matrix-matrix multiplications So the core of this method is to do the matrix multiplication in parallel We propose two methods one is the single tuple method and the other is the row divided method We will introduce them respectively in the subsequent sections Let us analyze the matrix multiplication rst Given two matrices and  the multiplication of and is   Suppose both Matrices and have columns and rows and the value of element in row and column is  Then the element can be represented as a record 0 In the pre-processing phase each element in Matrix is represented as a record  and each element in Matrix is represented as a record  The description of the pre-processing phase is as below First turn the record of Matrix to  turn the record of Matrix to  Then devide records into two categories and  The records with same key are sent to the same reducer In a reduce procedure the element record from matrix is used as  and the element record from matrix is used as  The multiplication is performed to obtain  in which is the element value of the result matrix  recorded as  Then another Map-Reduce job is started to sum up all with the same key Next pre-processing the result Matrix  which will be used as the input of the next iteration Matrix Multiplication method needs two Map-Reduce jobs One job multiplies each element from Matrix by an element from Matrix  and the other job is used to sum them up Now it is ready to apply the method to compute the SimRank The formula of SimRank is  in which is the column standardized adjacency matrix and is the delay factor When computing the SimRank if let  be  then the formula is turned into  Since Matrix is represented as a collection of records like  Matrix is represented as a collection of records like  At rst Matrix is multiplied by Matrix  and get the result Matrix  Then Matrix is multiplied by Matrix  The result matrix is added to Matrix  At this time one iteration step is nished Since the graph is static matrix and matrix in the formula is unchanged during the computation In order to further improve the computation efìciency we develop another method for the matrix multiplication This method is more effective than the one before Let us analyze the matrix multiplication in another way For example matrix A can be multiplied by matrix B as below  in which the element of the result Matrix can be looked as the vector multiplication result of the row of Matrix and the column of Matrix  since each row of Matrix can be multiplied by different column of B independently the multiplication can be nished in parallel Here we do not divide Matrix B Each computer in distribute platform keeps all records of Matrix B in memory The matrix multiplication is performed as following Map procedure turn the input record into  Reduce procedure from input records  get the row record in Matrix as record  Multiplying the row record to each column of the Matrix  Experiments show this method is more effective than the single tuple method This is because the division of Row Divided Method is based on row unit of a matrix while the division of Single Tuple Method is based on tuple unit of a matrix Row Divided Method produces less intermediate records than the Single Tuple Method does Thus it reduces the expenses of sort in shufîe procedure In the Single Tuple Method there are   tuples in matrix and matrix  so there are   records after mapping In the shufîe procedure all these records are sorted and sent to different reducers In the Row Divided Method it only divides the matrix by row and doesnêt divide matrix  Thus in the shufîe procedure it only needs 
             
k u in a,b out x y    v in a,b out x y    S i j S i j u v i j i j sim u v i j sim A B A B C C i j A i t B t j A B m m i j t i j t t A j i,j,a B i i,j,b i j a A j  i,j,a i j b B i  i,j,b j  i,j,a i  i,j,b t  m,t,a A A m t t  t,n,b B B t n C m n A m t B t n c C m n c c C A B S c W S W c I W c c W beW c I I S W S W I I   I   c W S T T W I W W S W S W I A A  A A A  A  A A  A B B  B B B  B  B B  B C i j C i A j B A i j a i j,a i j,a A i  a a a  B m n n t A B m n n t A B 
136 


records which is much less than that the Single Tuple Method will have to sort Therefore it reduces the expenses of sorting and communication greatly The difference between the two methods mentioned before is the division granularity Single Tuple Method is divided by element unit and Row Divided Method is divided by row unit As we expected the rst method should be more effective than the second one because it has higher parallelism than the second one does But the result of the experiments is totally opposite which shocks us Then we analyze the amazing results In the parallel Map-Reduce Computing Model there exist data exchanging procedures between map procedure and reduce procedure which are sort and shufîe procedures In the sort procedure all outputs of the map procedure are sorted During the sorting different nodes need to communicate with each other and thus communication cost are incurred When sorting is nished shufîe procedure sends the sorted results to different reducer The time consuming in sorting cannot be ignored High level parallel is important but the consuming of the sort and shufîe procedures cannot be neglected The efìciency is determined by several factors high parallelism is only one among them IV T HE E XPERIMENTAL R ESULTS This paper realizes all the algorithms of SimRank computation on a Hadoop platform with 20 slave machines and a master machine Each machine has 6 cores and installs Linux of Redhat Enterprise version All the experiments are developed by JAVA language and using hadoop API Three methods are tested on ve different scale data sets and the efìciencies of different methods are compared The data set comes from Stanford data website The three different algorithms of SimRank computation are tested on ve different scale data sets and the differences among them are compared Table II shows the features of each data sets Wiki-vote data set contains 7115 nodes and 103689 edges Its details are showed in table III P2P-Gnutella05 data set 
m 
3 Comparison between two methods A Comparison between the several methods 
Table II FEATURES OF ALL DATA SETS nodes edges diameter Average degree wiki-vote 7115 103689 7 14.6 P2P-Gnutella05 8846 31839 9 3.6 P2P-Gnutella31 62586 147892 11 2.4 Web-Stanford 281903 2,312,497 740 8.2 wiki-Talk 2,394,385 5,021,410 9 4 Table III WIKI VOTE DATASET Pre-process 1st iteration 2nd iteration 3rd iteration 4th iteration Final Analysis Initial 1min30s 3min26sec 1h39min4sec 1h57min42sec 2h2min14sec STM 4min12sec 6min33sec 7min29sec 8min26sec 8min32sec RDM 1min6sec 2min13sec 2min13sec 2min16sec 2min18sec Table IV P2P-G NUTELLA 05 DATA SET Pre-process 1st iteration 2nd iteration 3rd iteration 4th iteration Final Analysis Initial 1min30s 1min6sec 1min8sec 2min15sec 8min14sec STM 6min14sec 9min38sec 9min34sec 9min36sec 10min8sec RDM 1min6sec 2min12sec 2min12sec 2min15sec 2min12sec Table V P2P-G NUTELLA 31 DATASET Pre-process 1st iteration 2nd iteration 3rd iteration Final Analysis Initial 1min33 sec 1min36 sec 7min28 sec 1h23min11sec STM 6min56 sec 9min28 sec 12min23 sec 12min RDM 1min10sec 2min45sec 2min43sec 3min2sec to sort 
137 


Table VI W EB S TANFORD DATASET Pre-process 1st iteration 2nd iteration 3rd iteration Final Analysis Initial 1min57sec 2h2min37sec 104h49min58sec STM 3min20 sec 7min1sec 88min32sec 5h42min34sec RDM 1min18sec 29min55sec 23min50sec 27min25sec Table VII WIKI TALK DATASET Pre-process 1st iteration 2nd iteration 3rd iteration 4rd iteration 5th iteration 6th iteration RDM 1min28sec 6h38min28s 5h47min54s 5h45min6sec 5h31min3sec 5h29min12 5h31min51s contains 8846 nodes and 31839 edges details are showed in table IV P2P-Gnutella31 data set contains 62586 nodes and 147894 edges details are showed in table V Web-Stanford data set contains 281973 nodes and 2312497 edges Since the graph is big less iteration is carried out Details are showed in table VI Wiki-talk data set is too large that only RDM can give the nal results details showed in table VII The tables above show the result of three algorithms on different scale data sets The efìciencies of different methods are determined by several factors such as the number of nodes the number of edges the average degree of each node in the graph and so on For example the number of nodes in P2P-Gnutella05 is larger than the number of nodes in wiki-vote but the edges in P2P-Gnutella05 is less than the edges in wiki-vote data set For the Initial Iterative method the performance on the P2P-Gnutella01 data set is faster than that on the wiki-vote data set There are millions of nodes in the wiki-talk data set except the RDM can deal with this kind scale of data set others are not suitable for the data set of this scale RDM has a better scalability V A PPLICATION IN S OCIAL R ECOMMENDER S YSTEM Social Recommender system plays an important role in many practical applications that help users to deal with information overload and provide personalized recommendations to them The collaborative ltering recommendation is one of the most popular recommendation method There are two categories of collaborative ltering methods One is itembased and the other one is user-based In Recommendation system users usually mark item with score scaling from 0 to 5 which consists the scoring matrix Collaborative recommendation methods using scoring matrix suffer from the problems such as cold start sparsity and so on In order to resolve these problems this paper proposes one recommendation method which is based on the linkage relationships among objects Although most of the work on collaborative ltering has focused on the traditional two-dimensional user-item matrix there has been a recent increase of interest in integrating Figure 1 Graph with User-Tag-Item relationships additional information to recommendations This is probably due to the richness of additional information This paper analyzes the similarity between objects with user-tag-item linkage Tag System is a hot web system in Internet in which users can issue any tags to items if the user consider the tag is suitable for the item In this way the tags can be looked as the content set of the item the same as words to a document So there is an tag-item relationship As we know the importance of different tag to the same item is not the same In the Tag System an user can label several tags to an item and the same tag may be issued to the same item by several users Figure 1 shows an example of graph with the user-tag-item relationships We can apply the previously discussed parallel SimRank computing method on this kind of graph to compute the similarities between the user and items and then recommend the most similar items to the users VI R ELATED W ORKS Many methods have been proposed to better understanding of graph Here we brieîy describe the work that is most relevant to the current work There is a lot of research work on static graph analysis including power laws discovery  clustering and community identiìcation 26 15 frequent pattern mining 32 and node ranking 27  There are two categories of methods to compute node similarity The rst one is based on text of items 
138 


The second one is based on link relations 18 12  In research 24 the abo v e tw o kinds of measures are evaluated and link-based measure produced systematically better correlation with human judgements than the former one SimRank is a measure of the second cate gory  Xi et al proposed another node similarity computing algorithm called SimFusion that utilizes the similar idea to compute node similarity scores However the time complexity of the initial SimRank or SimFision computation algorithms are very high There are many optimization techniques to reduce the computation cost of SimRank Fingerprint-SimRank pre-computes some steps of random walk path from each object Although it improves computational performance of SimRank Fingerprint-SimRank has highly cost of high space complexity Lizorkin et al estimates the accurac y of computing SimRank and presents three optimization strategies to speed up the computation of SimRank proposes single-pair SimRank Computation algorithm Overall these methods are all based on one computer none of which has considered to utilize the parallel framework of Map-Reduce proposes one parallel method to compute the SimRank There are also some research works which use GPUs as a parallel hardware accelerator for SimRank computation 10 discussed the challenge and adv ances to implement sparse matrix multiplication under parallel architecture and used graphic processers to further improve the performance Map-Reduce was created by Google mainly to process big volume of unstructured data Now it is widely used in several application such as machine learning data mining text processing and so on Map-Reduce is a good tool for processing large scale graph In the Map-Reduce computing model the user only needs to provide a map function and a reduce function The map function is applied to all input rows of the data set and produces an intermediate output that is aggregated by the reduce function later to produce the nal result Many more algorithms including graph processing algorithms can be run on the Map-Reduce platform and it can handle not only the unstructured data but also structured data efìciently This paper designs three ne w algorithms for SimRank computation based on Map-Reduce including the parallel algorithm for the Initial Iterative Method and the algorithms for the Matrix Multiplication method Recently there is also an increasing interest in mining dynamic graphs such as group or community evolution  8 po wer la ws of dynamic graphs 20 dynamic tensor analysis and dynamic clustering 11 In terms of similarity updating to the best of our knowledge the only two existing papers are and 21 30 proposed two algorithms to update the similarity matrix incrementally based on the Random Walk with Restart RWR model for a bipartite graph considers the incremental SimRank update problem on evolving graphs VII C ONCLUSION This paper combines with the feature of MapReduce Computing Model designs several novel methods for SimRank computing which not only improve the efìciency but also can deal with large scale data set By comparing the several different methods we nd that Monte Carlo Method is the fastest among all the parallel methods Initial Formula Method is not that quick but it ensures the accuracy Compared with the existing initial method this parallel method is improved much in efìciency Matrix multiplication method has good scalability especially the Row Divide method This strategy can also be applied to other matrix algorithm A CKNOWLEDGMENT This work was partially supported by NSFC under the grant No.61070056 61033010 61272137 61202114 National Basic Research Program of China 973 No 2012CB316205 and National Social Science Foundation of China Project Number 12&ZD220 It was partially done when the authors worked in SA Center for Big Data Research in Renmin University of China This Center is funded by a Chinese National 111 Project Attracting R EFERENCES  J Lin M Schatz Design patterns for ef cient graph algorithms in MapReduce Eighth Workshop on Mining and Learning with Graphs 2010 pp.78-85  T  Kalde we y  E Shekita S T ata Clydesdale Structured Data Processing on MapReduce EDBT 2012 pp.15-25  W  Y u X Lin J Le T aming Computational Comple xity:Efìcient and Parallel Simrank Optimizations on undirected Graphs WAIM 2010,LNVS 6184,pp 280-296,2010  G He H Feng C Li H Chen P arallel simrank computation on large graphs with iterative aggregation Proceedings of the 16th ACM SIGKDD 2010  P  Li H Liu J Y u J He X Du F ast Single-P air SimRank Computation SIAM International Conference on Data Mining 2010,p.571-582  J Zhou N Bruno M W u SCOPE parallel databases meet MapReduce The VLDB Journal published online 2012 DOI 10.1007/s00778-012-0280-z  http://snap.stanford.edu/data  L Backstrom D Huttenlocher  and J Kleinber g Group formation in large social networks membership growth and evolution In 
 2006 
Proc of the 12th Intêl Conference on Knowledge discovery and data mining\(KDDê06 
139 


 N Bell and M Garland Ef cient sparse matrix-v ector multiplication on cuda In  2008  A Buluc  and J R Gilbert Challenges and adv ances in parallel sparse matrix-matrix multiplication In  pages 503Ö510 Washington DC USA 2008 IEEE Computer Society  Y  Chi X Song D Zhou K Hino and B L Tseng Ev olutionary spectral clustering by incorporating temporal smoothness In  2007  C F aloutsos K S McCurle y  and A T omkins F ast disco v ery of connection subgraphs In  pages 118Ö127 New York NY USA 2004 ACM  D F ogaras and B Racz Scaling link-based similarity search In  2005  P  Ganesan H Garcia-Molina and J W idom Exploiting hierarchical domain structure to compute similarity  21\(1 2003  M Girv an and M Ne wman Community structure in social and biological networks In  2002  G Jeh and J W idom Simrank a measure of structuralcontext similarity In  pages 538Ö543 New York NY USA 2002 ACM  J Kleinber g Authoritati v e sources in a h yperlink ed en vironment  1999  Y  K oren S C North and C V olinsk y  Measuring and extracting proximity in networks In  pages 245Ö255 New York NY USA 2006 ACM  E A Leicht P  Holme and M E J Ne wman V erte x similarity in networks  73:026120 2006  J Lesk o v ec J M Kleinber g and C F aloutsos Graphs o v er time densiìcation laws shrinking diameters and possible explanations In  2007  C Li J Han G He X Jin Y  Sun Y  Y u and T  W u Fast computation of simrank for static and dynamic information networks In  2010  D Lizorkin P  V elikho v  M Grine v  and D T urdak o v  Accuracy estimate and optimization techniques for simrank computation In  2008  Y  Zhang Q Gao L Gao y  C W ang iMapReduce A Distributed Computing Framework for Iterative Computation datacloudê2011  A G Maguitman F  Menczer  F  Erdinc H Roinestad and A Vespignani Algorithmic computation and approximation of semantic similarity  9\(4 2006  M.E.J.Ne wman The structure and function of comple x netwroks  2003  A Ng M Jordan and Y  W eiss On spectral clustering Analysis and an algorithm In  2002  L P age S Brin R Motw ani and T  W inograd The pagerank citation ranking Bringing order to the web  1998  J Sun D T ao and C F aloutsos Be yond streams and graphs dynamic tensor analysis In  2006  C T antipathananandh T  Y  Ber ger W olf and D K empe A framework for community identiìcation in dynamic social networks In  2007  H T ong S P apadimitriou P  S Y u and C F aloutsos Proximity tracking on time-evolving bipartite graphs In  2008  W  Xi E A F ox W  F an B Zhang Z Chen J Y an and D Zhuang Simfusion measuring similarity using uniìed relationship matrix In  pages 130Ö137 New York NY USA 2005 ACM  X Y an and J Han Close graph Mining closed frequent graph patterns In  2003  X Y an P  S Y u and J Han Substructure similarity search in graph databases In  2005  J Dean and S Ghema w at MapReduce simpliìed data processing on large clusters in proceedings of the 6th conference on Symposium on Opearting Systems Design and Implementation 2004  Y  Bu B Ho we M Balazinska and M Ernst HaDoop Ef cient Iterative Data Processing on Large Clusters Proceedings of the VLDB Endownment Vol3 No.1  C Olston B Reed U Sri v asta v a Pig Latin A Not-So-F oreign Language for Data Processing Proceedings of SIGMODê08 1099-1111 
Technical Report NVR-2008-004 ICPP 08 Proceedings of the 2008 37th International Conference on Parallel Processing Proc of the 13th Intêl Conference on Knowledge discovery and data mining\(KDDê07 KDD 04 Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining Proc of the 14th Intêl Conference on World Wide Web WWWê05 ACM Trans Inf Syst Proc Of the National Academy of Sciences KDD 02 Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining Journal of the ACM KDD 06 Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining Physical Review E Proc of the 13th Intêl Conference on Knowledge discovery and data mining\(KDDê07 EDBTê10 Proc of the 34st Intêl Conference on Very Large Databases VLDBê08 World Wide Web SIAM Review Proc Of the Advances in Neural Information Processing Systems\(NIPS Technical report Stanford University Database Group http://citeseer.nj.nec.com/368196.html Proc of the 12th Intêl Conference on Knowledge discovery and data mining\(KDDê06 Proc of the 13th Intêl Conference on Knowledge discovery and data mining\(KDDê07 Proc of SDM SIGIR 05 Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval Proc of the 9th Intêl Conference on Knowledge discovery and data mining\(KDDê03 Proc Of ACM-SIGMOD Intêl Conference on Management of Data 
140 


Jorda Polo, David Carrera, Yolanda Becerra, Malgorzata Steinder  and Ian Whalley. Performance-driven task co-scheduling for  mapreduce environments. In Network Operations and Management  Symposium \(NOMS\2010 IEEE, pages 373 Ö380, 19-23 2010 12 K. Kc and K. Anyanwu, çScheduling hadoop jobs to meet deadlines  in 2nd IEEE International Conference on Cloud Computing  Technology and Science \(CloudCom\, 2010, pp. 388 Ö392 13 Xicheng Dong, Ying Wang, Huaming Liao çScheduling Mixed Real time and Non-real-time Applications in MapReduce Environment  In the proceeding of 17th International Conference on Parallel and  Distributed Systems. 2011, pp. 9 Ö 16 14 Xuan Lin, Ying Lu, J. Deogun, and S. Goddard. Real-time divisible  load scheduling for cluster computing. In Real Time and Embedded  Technology and Applications Symposium, 2007. RTAS ê07. 13th  IEEE pages 303 Ö314, 3-6 2007 15 HDFS  http://hadoop.apache.org/common/docs/current/hdfsdesign.html  16 Chen He, Ying Lu, David Swanson. çMatchmaking : A New  MapReduce Scheduling Techniqueé. In the proceeding of 2011  CloudCom, Athens, Greece, 2011, pp. 40 Ö 47 17 Matei Zaharia, Dhruba Borthakur, Joydeep Sen Sarma and Khaled  Elmeleegy, Scott Shenker, and Ion Stoica, çDelay scheduling: a  simple technique for achieving locality and fairness in cluster  schedulingé. In the proceedings of the 5th European conference on  Computer systems, 2010.  pp 265-278 18 Zhuo Tang, Junqing Zhou, Kenli Li, and Ruixuan Li "A MapReduce  task scheduling algorithm for deadline constraints.", Cluster  Computing, Vol. 15,  2012 19 Eunji Hwang, and Kyong Hoon Kim. "Minimizing Cost of Virtual  Machines for Deadline-Constrained MapReduce Applications in the  Cloud." Grid Computing \(GRID\, 2012 ACM/IEEE 13th  International Conference on. IEEE, 2012 20 Micheal Mattess, Rodrigo N. Calheiros, and Rajkumar Buyya  Scaling MapReduce Applications across Hybrid Clouds to Meet Soft  Deadlines." Technical Report CLOUDS-TR-2012-5, Cloud  Computing and Distributed Systems Laboratory, the University of  Melbourne, August 15, 2012 21 
 
11 
                
Chen He, Ying Lu, David Swanson. çReal-Time Application Scheduling in Heterogeneous MapReduce Environments Technical Report TR-UNL-CSE2012-0004, University  of Nebraska-Lincoln, 2012 Available: http://cse apps.unl.edu/facdb/publications/TR-UNL-CSE20120004.pdf 22 T. Condie, N. Conway, P. Alvaro, J. M. Hellerstein, K  Elmleegy, and R. Sears. çMapreduce Onlineé. In NSDI 2010 23 A. D. Ferguson, P. BodÌk, S. Kandula, E. Boutin, and R  Fonseca. çJockey: Guaranteed Job Latency in Data Parallel Clusters. In EuroSys, 2012 24 G. Wang, A. R. Butt, P. Pandey, and K. Gupta. çA Simulation Approach to Evaluating Design Decisions in MapReduce Setupsé. In MASCOTS 2009 25 H. Herodotou and S. Babu. Profiling, çWhat-if Analysis and Cost-based Optimization of MapReduce Programs In VLDB 2011 26 H. Herodotou, F. Dong, and S. Babu. çNo One \(Cluster Size Fits All: Automatic Cluster Sizing for Dataintensive Analyticsé. In SoCC 2011  
1544 
1544 


Figure 15  3D model of the patio test site Figure 16  Model of the patio test site combining 2D map data with 3D model data a Largest explored area b Smallest explored area Figure 14  Maps built by a pair of 2D mapping robots Yellow indicates area seen by both robots Magenta indicates area seen by one robot and Cyan represents area seen by the other a 3D point cloud built of the patio environment Figure 16 shows a model built combining 2D map data with 3D model data A four-robot mission scenario experiment was conducted at the mock-cave test site This included two 2D mapping robots a 3D modeling robot and a science sampling robot There was no time limit on the run Figure 17 shows a 3D model of the tunnel at the mock cave Figure 18 shows a model built combining 2D map data with 3D model data 7 C ONCLUSIONS  F UTURE W ORK The multi-robot coordination framework presented in this paper has been demonstrated to work for planetary cave mission scenarios where robots must explore model and take science samples Toward that end two coordination strategies have been implemented centralized and distributed Further a core communication framework has been outlined to enable a distributed heterogenous team of robots to actively communicate with each other and the base station and provide an online map of the explored region An operator interface has been designed to give the scientist enhanced situational awareness collating and merging information from all the different robots Finally techniques have been developed for post processing data to build 2  3-D models of the world that give a more accurate description of the explored space Fifteen 2D mapping runs with 2 robots were conducted The average coverage over all runs was 67 of total explorable area Maps from multiple robots have been merged and combined with 3D models for two test sites Despite these encouraging results several aspects have been identi\002ed that can be enhanced Given the short mission durations and small team of robots in the experiments conducted a simple path-to-goal costing metric was suf\002cient To use this system for more complex exploration and sampling missions there is a need for learning-based costing metrics Additional costing parameters have already been identi\002ed and analyzed for future implementation over the course of this study One of the allocation mechanisms in this study was a distributed system however task generation remained centralized through the operator interface In an ideal system robots would have the capability to generate and auction tasks based on interesting features they encounter Lastly the N P complete scheduling problem was approximated during task generation However better results could potentially 10 


Figure 17  3D model of the tunnel in the mock cave test site Figure 18  Model of the mock cave test site combining 2D map data with 3D model data be obtained by releasing this responsibility to the individual robots A CKNOWLEDGMENTS The authors thank the NASA STTR program for funding this project They would also like to thank Paul Scerri and the rCommerceLab at Carnegie Mellon University for lending hardware and robots for this research R EFERENCES  J C W erk er  S M W elch S L Thompson B Sprungman V Hildreth-Werker and R D Frederick 223Extraterrestrial caves Science habitat and resources a niac phase i study\\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2003  G Cushing T  T itus and E Maclennan 223Orbital obser vations of Martian cave-entrance candidates,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  M S Robinson B R Ha wk e A K Boyd R V Wagner E J Speyerer H Hiesinger and C H van der Bogert 223Lunar caves in mare deposits imaged by the LROC narrow angle camera,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  A K Bo yd H Hiesinger  M S Robinson T Tran C H van der Bogert and LROC Science Team 223Lunar pits Sublunarean voids and the nature of mare emplacement,\224 in LPSC  The Woodlands,TX 2011  S Dubo wsk y  K Iagnemma and P  J Boston 223Microbots for large-scale planetary surface and subsurface exploration niac phase i.\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2006  S Dubo wsk y  J Plante and P  Boston 223Lo w cost micro exploration robots for search and rescue in rough terrain,\224 in IEEE International Workshop on Safety Security and Rescue Robotics Gaithersburg MD  2006  S B K esner  223Mobility feasibility study of fuel cell powered hopping robots for space exploration,\224 Master's thesis Massachusetts Institute of Technology 2007  M T ambe D Pynadath and N Chauv at 223Building dynamic agent organizations in cyberspace,\224 IEEE Internet Computing  vol 4 no 2 pp 65\22673 March 2000  W  Sheng Q Y ang J T an and N Xi 223Distrib uted multi-robot coordination in area exploration,\224 Robot Auton Syst  vol 54 no 12 pp 945\226955 Dec 2006  A v ailable http://dx.doi.or g/10.1016/j.robot 2006.06.003  B Bro wning J Bruce M Bo wling and M M V eloso 223Stp Skills tactics and plays for multi-robot control in adversarial environments,\224 IEEE Journal of Control and Systems Engineering  2004  B P  Gerk e y and M J Mataric 223 A formal analysis and taxonomy of task allocation in multi-robot systems,\224 The International Journal of Robotics Research  vol 23 no 9 pp 939\226954 September 2004  M K oes I Nourbakhsh and K Sycara 223Heterogeneous multirobot coordination with spatial and temporal constraints,\224 in Proceedings of the Twentieth National Conference on Arti\002cial Intelligence AAAI  AAAI Press June 2005 pp 1292\2261297  M K oes K Sycara and I Nourbakhsh 223 A constraint optimization framework for fractured robot teams,\224 in AAMAS 06 Proceedings of the 002fth international joint conference on Autonomous agents and multiagent sys11 


tems  New York NY USA ACM 2006 pp 491\226493  M B Dias B Ghanem and A Stentz 223Impro ving cost estimation in market-based coordination of a distributed sensing task.\224 in IROS  IEEE 2005 pp 3972\2263977  M B Dias B Bro wning M M V eloso and A Stentz 223Dynamic heterogeneous robot teams engaged in adversarial tasks,\224 Tech Rep CMU-RI-TR-05-14 2005 technical report CMU-RI-05-14  S Thrun W  Bur g ard and D F ox Probabilistic Robotics Intelligent Robotics and Autonomous Agents  The MIT Press 2005 ch 9 pp 222\226236  H Mora v ec and A E Elfes 223High resolution maps from wide angle sonar,\224 in Proceedings of the 1985 IEEE International Conference on Robotics and Automation  March 1985  M Yguel O A ycard and C Laugier  223Update polic y of dense maps Ef\002cient algorithms and sparse representation,\224 in Intl Conf on Field and Service Robotics  2007  J.-P  Laumond 223T rajectories for mobile robots with kinematic and environment constraints.\224 in Proceedings International Conference on Intelligent Autonomous Systems  1986 pp 346\226354  T  Kanungo D Mount N Netan yahu C Piatk o R Silverman and A Wu 223An ef\002cient k-means clustering algorithm analysis and implementation,\224 IEEE Transactions on Pattern Analysis and Machine Intelligence  vol 24 2002  D J Rosenkrantz R E Stearns and P  M Le wis 223 An analysis of several heuristics for the traveling salesman problem,\224 SIAM Journal on Computing  Sept 1977  P  Scerri A F arinelli S Okamoto and M T ambe 223T oken approach for role allocation in extreme teams analysis and experimental evaluation,\224 in Enabling Technologies Infrastructure for Collaborative Enterprises  2004  M B Dias D Goldber g and A T  Stentz 223Mark etbased multirobot coordination for complex space applications,\224 in The 7th International Symposium on Arti\002cial Intelligence Robotics and Automation in Space  May 2003  G Grisetti C Stachniss and W  Bur g ard 223Impro ving grid-based slam with rao-blackwellized particle 002lters by adaptive proposals and selective resampling,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2005  227\227 223Impro v ed techniques for grid mapping with raoblackwellized particle 002lters,\224 IEEE Transactions on Robotics  2006  A Geiger  P  Lenz and R Urtasun 223 Are we ready for autonomous driving the kitti vision benchmark suite,\224 in Computer Vision and Pattern Recognition CVPR  Providence USA June 2012  A N 250 uchter H Surmann K Lingemann J Hertzberg and S Thrun 2236d slam with an application to autonomous mine mapping,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2004 pp 1998\2262003  D Simon M Hebert and T  Kanade 223Real-time 3-d pose estimation using a high-speed range sensor,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  1994 pp 2235\2262241 B IOGRAPHY  Ammar Husain received his B.S in Mechanical Engineering Robotics from the University of Illinois at Urbana-Champaign He is pursuing an M.S in Robotic Systems Development at Carnegie Mellon University He has previously worked on the guidance and control of autonomous aerial vehicles His research interests lie in the 002eld of perception-based planning Heather Jones received her B.S in Engineering and B.A in Computer Science from Swarthmore College in 2006 She analyzed operations for the Canadian robotic arm on the International Space Station while working at the NASA Johnson Space Center She is pursuing a PhD in Robotics at Carnegie Mellon University where she researches reconnaissance exploration and modeling of planetary caves Balajee Kannan received a B.E in Computer Science from the University of Madras and a B.E in Computer Engineering from the Sathyabama Institute of Science and technology He earned his PhD from the University of TennesseeKnoxville He served as a Project Scientist at Carnegie Mellon University and is currently working at GE as a Senior Cyber Physical Systems Architect Uland Wong received a B.S and M.S in Electrical and Computer Engineering and an M.S and PhD in Robotics all from Carnegie Mellon University He currently works at Carnegie Mellon as a Project Scientist His research lies at the intersection of physics-based vision and 002eld robotics Tiago Pimentel Tiago Pimentel is pursuing a B.E in Mechatronics at Universidade de Braslia Brazil As a summer scholar at Carnegie Mellon Universitys Robotics Institute he researched on multi-robots exploration His research interests lie in decision making and mobile robots Sarah Tang is currently a senior pursuing a B.S degree in Mechanical and Aerospace Engineering at Princeton University As a summer scholar at Carnegie Mellon University's Robotics Institute she researched multi-robot coordination Her research interests are in control and coordination for robot teams 12 


Shreyansh Daftry is pursuing a B.E in Electronics and Communication from Manipal Institute of Technology India As a summer scholar at Robotics Institute Carnegie Mellon University he researched on sensor fusion and 3D modeling of sub-surface planetary caves His research interests lie at the intersection of Field Robotics and Computer Vision Steven Huber received a B.S in Mechanical Engineering and an M.S in Robotics from Carnegie Mellon University He is curently Director of Structures and Mechanisms and Director of Business Development at Astrobotic Technology where he leads several NASA contracts William 223Red\224 L Whittaker received his B.S from Princeton University and his M.S and PhD from Carnegie Mellon University He is a University Professor and Director of the Field Robotics Center at Carnegie Mellon Red is a member of the National Academy of Engineering and a Fellow of the American Association for Arti\002cial Intelligence 13 



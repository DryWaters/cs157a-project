Sorted Compressed Tree: An Improve Method of Frequent Patterns Mining without Support Constraint Chuang-Kai Chiou College of Engineering Chung Hua University Hsinchu, 300, Taiwan, ROC d09524003@chu.edu.tw Judy C. R. Tseng Dept. of Computer Science and Information Engineering Chung Hua University Hsinchu, 300, Taiwan, ROC judycrt@chu.edu.tw AbstractSeveral algorithms have been proposed for association rule mining, such as Apriori and FP Growth. In these algorithms a minimum support should be decided for mining large itemsets However, it is usually the case that several minimum supports should be used for repeated mining to find the satisfied collection of association rules. To cope with this problem, several algorithms were proposed to allow the minimum support to be adjusted without rebuilding the whole data structure for frequent pattern mining. The Compressed and Arranged Transaction Sequences tree \(CATS tree Nevertheless, CATS Tree builds its tree structure dynamically, so that the mining process is complex and tedious. In this paper, we present an improved algorithm called the Sorted Compressed tree \(SC tree be built statically. Moreover, association rules can be mined in a bottom-up style instead of bi-directional in CATS tree and recursive in FP Growth. Hence, the cost of association rule mining is reduced. From preliminary experimental results, SC tree is not only more efficient but is also space saving Keywords-association rule mining; without suppoort constrain CSTS tree; SC Tree I. INTRODUCTION Recently, the size of digital data grows in an exponential rate. Finding out the knowledge behind the huge amounts of data becomes an important issue. Such knowledge is derived by statistical data and the relationship among products [1 However, the relationships among products are not easily to find intuitively. That is why data mining becomes an important research topic. Among data mining methodologies Association Rule Mining is the most widely applied 


technique For mining the large itemset, Apriori [2] algorithm and Frequent Patterns growth \(FP-growth  most well-known method. Both of them must configure a minimum support value before mining large itemsets However, an appropriated minimum support value is hard to be chosen without enough knowledge about the application domain. Generally speaking, administrator needs to adjust the value several times to obtain the satisfied result William Cheung and Osmar R. Zaiane proposed a novel data structure called Compressed and Arranged Transaction Sequences Tree \(CATS tree  adjust the minimum support value while mining patterns and it also improved the efficiency of the association rule mining Once CATS tree is built, it can be mined repeatedly with different support thresholds without reconstructing the tree However, the processes of tree construction and frequent patterns in CATS tree are quite complex and trivial. To cope with the problem, the Sorted Compressed Tree \(SC Tree proposed Efficiency of tree construction and association rule mining in CATS tree are improved by SC tree. The main idea is to simplify the process of tree construction and the method of rule mining. By pre-sorting the dataset, the data arrangement of SC tree is consistent, so that dynamic adjustment of the tree structure can be avoided. Moreover, association rules can be mined in a bottom-up style instead of bi-directional in CATS tree and recursive in FP Growth. Hence, the cost of association rule mining can be reduced. From preliminary experimental results, SC tree is not only more efficient but is also space saving II. RELATIVE WORKS For association rule mining, the most well-know algorithm is Apriori algorithm. Apriori algorithm is easy to be implemented and many algorithms are Apriori based nowadays 5-7]. However, the main drawback of Apriori algorithm is the low performance of mining efficiency. In this reason researches focused on eliminating the huge candidates during mining process [3-4, 8-10]. The most typical algorithm is Frequent Patterns Growth \(FP Growth Han and et al. in 2000 [3]. Nevertheless, when the minimum support value is changed, the pre-constructed data structure for 


frequent pattern mining is useless, and a new construction is needed William Cheung and Osmar R. Zaiane tried to solve this problem and proposed a data structure called Compressed and Arranged Transaction Sequences Tree \(CATS tree  algorithm, large itemsets for different minimum supports can be found with the same data structure. That is, no reconstruction is needed when the minimum support is changed Later, Grouping Compressed tree \(GC tree Liou in 2006 [11] to further improve the performance of CATS tree 328 A. Frequent Patterns Growth Algorithm In the Frequent Patterns Growth \(FP Growth extended prefix-tree, called frequent pattern tree \(FP-tree was employed for storing compressed information about frequent patterns [3, 8-10]. Bottleneck of Candidate Generation in Apriori algorithm can be avoided in FP-growth algorithm. FP-growth algorithm is also the representative pattern growth based algorithm FP-growth algorithm improved the efficiency of mining with three techniques: \(1 frequently by compressing database into a highly condensed much smaller data structure. \(2 itemsets by adopting pattern fragment growth method in FPtree-based mining. \(3 decomposing the mining task into a set of smaller tasks for mining confined patterns in conditional databases FP-growth method is efficient and scalable for mining both long and short frequent patterns and it is about an order of magnitude faster than the Apriori algorithm. Although FPgrowth outperforms other algorithm, the difficulty of minimum support setting still exists in this method B. Compressed and Arranged Transaction Sequences Tree Algorithm In FP-growth tree algorithm, when the minimum support value is changed, the itemsets which is satisfied the constraint are different. To coping with this problem, William Cheung and Osmar R. Zaiane proposed a novel data structure called Compressed and Arranged Transaction Sequences Tree \(CATS tree  tree preserves all elements without reducing 


When minimum support threshold is changed, the tree structure is unnecessary to be reconstructed. The only thing needs to do is to re-execute the mining process in CATS tree algorithm. This property shortens the system respond time while adjusting the minimum support threshold. An example of constructing a CATS tree is shown in Fig. 1 Initially, the CATS Tree is empty. TID 1 \(F, A, C, D, G, I M, P A, B, C, F, L, M, O is added, common items, F, A, C, M are found. Items F, A, C are extracted from TID 2 and then merged with the existent node. Item M cannot be merged directly, so node M in CATS Tree is swapped in front of node D and then merged. The remaining items \(B, L, O branch The concept of prefix tree is employed for constructing tree structure in both CATS algorithm and FP-growth, but CATS algorithm constructs without sorting. Therefore, CATS always needs to adjust the tree structure. The drawbacks of CATS tree algorithm are: \(1 2 3 Mining operation is complicated Figure 1. Illustration of CATS tree construction C. Grouping Compress Tree Algorithm Grouping Compress Tree algorithm \(GC Tree by Shin-Yi Liou in 2006 [11]. Firstly, they pre-process the transaction data and then compress these data into Grouping Compress Tree \(GC Tree efficient algorithm to find out the large item set by simplifying the complexity of data construction and mining process In pre-processing stage, GC tree algorithm counts the support value of each item and then creates an index table Itemset are sorted in descendent order according to their support value and a unique index value is given to each item Then items in transaction database are transferred to its index number. Because transaction data is pre-sorted, the arrangement of the data in GC tree is consistent. It is unnecessary to adjust the nodes while constructing, so the constructing process is simplified After pre-processing, GC tree algorithm creates a left skew tree to compress transaction data. The same subset in the tree structure will be grouped \(compressed techniques of upward counting, bottom-up mining, and 


projection are employed. Although GC tree algorithm solves the problem of complicated construction, the construction of left skew tree still wastes the memory space III. SORTED COMPRESS TREE ALGORITHM In this paper, we propose a new algorithm called Sorted Compressed Tree \(SC Tree problems suffered in CATS and GC tree algorithm. We focus on two aspects. One is to simplify the process of tree construction, and another is to simplify the rule mining method SC tree algorithm mines the frequent itemset in three stages 1 2 3 mining in SC tree. These stages will be explained in the followings Identify applicable sponsor/s here. \(sponsors 329 A. Data Preprocessing Sorting brings benefits for mining as it in the binary searching tree. In our previous work proposed in 2007 [6], we actually improved the Apriori algorithm with sorting technique Arrangement of sorted transactions is consistent, so it is unnecessary to adjust the tree structure as in CATS tree Efficiency of tree constructing and rule mining can be improved. Searching space can be reduced because useless nodes can be skipped by comparing their indexes For a better performance and consistent arrangement, items in SC tree will be sorted by their occurred frequency in descendent. The preprocessing is shown in Fig. 2 1 2 items. Create a frequency table to record the occurred frequency of each item 3 decreasing order and build an index table. This new frequency table will be treated as Header table in the mining process 4 C will be translated to index 1 and item A be translated to index 3 5 Finally, the new transaction database is obtained B. SC Tree Constructing After Data Preprocessing stage, we obtain a sorted 


transaction database and then start to construct the SC tree. The constructing process is similar to FP-growth tree. An example of constructing SC tree for TID 1 and TID 2 is shown in Fig. 3 1 2 branch in SC tree 3 in SC tree, merge it and accumulate its count. Otherwise create a new branch. In TID 2, items 1, 2 and 3 already exist in SC tree, so their counts will be accumulated. Then a new branch beneath the last common item 3 is created for the remaining part 4 compressed into the tree structure. The SC tree with the five transactions is shown in Fig. 4 By the way, a Header table will be constructed. Each item in Header table will be linked to the corresponding node where it was first occurred in SC tree. The nodes with same index value \(item name linked list. The linked list will be used to mining frequent itemset in different branches C. Mining in SC Tree Nodes \(items direction in SC tree can be single direction. In order to satisfy the constraint of minimum support \(min_sup direction in SC tree is bottom up. The mining processes in SC tree are Figure 2. Database pre-processing in SC tree algorithm Figure 3. Insert TID 1 and TID 2 in SC tree Figure 4. Example of SC Tree 330 1 According to the given minimum support value, SC tree will be scanned by mining algorithm and items whose count is larger than or equal to the minimum support constraint min_sup than the min_sup will not be considered and their linkages will also be ignored. Because these linkages are ignored, the items will be filtered out in mining process. For instant, a Header table with min_sup?3 is shown in Fig. 5 2 In order to mine the frequent itemset in SC tree, each item 


whose counts is large than or equal to min_sup will be considered. The conditional condensed SC tree of item X will be constructed. Item X in SC tree will be found by the linkage recorded in Header table. Then the path along item X to the root will be constructed. Because all the items with same index item name item X in different branch will be constructed either. By the way, a Header table for mining process will be created An example of mining frequent itemset including item 6 with min_sup?3 is shown in Fig. 6. There are two paths, \(6, 5 3, 2, 1 6, 4, 1 these two paths, counts of items along the path will be recorded in a Mining_Header table 3 In mining table, a node whose count is less than the min_sup will be deleted. Then, a conditional SC tree of eliminated itemset will be created. Finally, the preserved paths are the frequent itemsets As shown in Fig. 6, nodes whose count is less than three will be deleted. Only item 6 and item 1 are preserved but others are deleted. Beneath item 1, there are two preserved items \(6:2 6:1 1:3 6:3 with min_sup?3 is \(1, 6 Stage \(2 3 the items in Header table whose count is large than or the same as min_sup are considered Figure 5. A Header table with min_sup?3 Figure 6. . Frequent itemset mining with min_sup?3 and including item 6 IV. EXPERIMENT AND EVALUATION In this section, we will verify the performance of SC tree CATS tree, and GC tree algorithm. We will focus on executing performance and memory requirement in different minimum support and transaction size. The equipment we used is a PC with Pentium IV 2.8GHz processor with 2GB memory. Testing data was generated by data generator from IBMs Almaden project [12]. The meaning of parameters is shown as follows N : Number of data items D : Number of transactions in the database T : Average size of transactions I : Average size of the maximal potentially frequent itemset L : Number of maximal potentially frequent itemset 


A. Efficiency Evaluation For evaluating the performance of three algorithms, the experiments focus on two aspects 1 There are 100K transactions and average size \(length transactions is 10 and average size of the maximal potentially frequent itemset is 4. The result is shown as Fig. 7 These algorithms are minimum support independent, so the results are not influenced by different minimum supports. The constructing time of SC tree is shorter than CATS tree and GC tree. Then we evaluate the influences of different transaction sizes with a fixed minimum support 0.4%. As shown in Fig. 8 SC tree still outperforms the other two algorithms 0 1 2 3 4 5 6 0.20% 0.30% 0.40% 0.50% 0.60 Minimum Support Ex ec uti ng T im e se c CATS Tree GC Tree SC Tree Figure 7. Tree construction time with different minimum support in T10I4D100K database 331 0 20 40 60 80 100 100K 250K 500K 750K 1000K 


Transaction Size E xe cu tin g T im e s ec  CATS Tree GC Tree SC Tree Figure 8.  Tree construction time with fixed minimum support 0.4% in T10I4D100K~1000K database 2 In this part, we focus on the efficiency of mining process Three algorithms are verified with different minimum supports under 500K transactions and different transaction sizes under fixed minimum support 0.2%. The results are shown in Fig. 9 and Fig. 10 As shown in Fig. 9 and Fig. 10, the average mining time of SC tree is always much less than the CATS tree and GC tree algorithm. By concluding the experiments in this part, we can say that SC tree algorithm outperforms CATS tree and GC tree algorithm, especially in low minimum support cases 0 2 4 6 8 10 12 14 16 18 0.20% 0.30% 0.40% 0.50% 0.60 Minimum Support E xe cu tin 


g T im e s ec  CATS Tree GC Tree SC Tree Figure 9. Mining efficiency with different minimum support in T10I4D500K database 0 10 20 30 40 100K 250K 500K 750K 1000K Transaction Size Ex ec ut in g Ti m e s ec  CATS Tree GC Tree SC Tree Figure 10. Mining efficiency with different transaction size and fixed minimum support 0.2 B. Memory Requirements Evaluation For evaluating the memory requirements of three algorithms, the experiments focus on two aspects 1 We verify the memory requirements of tree construction among three algorithms with different minimum supports in T10I4D100K database. The result is shown in Fig. 11 As shown in Fig. 11, the results are not influenced by different minimum supports because theses algorithms are minimum support value independent. Nevertheless, for constructing T10I4D100K data set, CATS tree spent 15,654KB 


GC tree spent 19,881KB, and SC tree only spent 13,030KB SC tree algorithm saves about 17% and 34% than CATS tree and GC tree Then, we evaluate the influences of different transaction sizes with a fixed minimum support 0.4%. As shown in Fig. 12 we can find that the average constructing space for SC tree saves about 16% and 34% than CATS tree and GC tree 2 In this part, we focus on memory requirements of mining process. Three algorithms will be verified with different minimum support under 500K transactions and different transaction sizes under fixed minimum support 0.2%. The results are shown in Fig. 13 and Fig. 14 Obviously, the average mining space for SC tree is less than both CATS tree and GC tree 0 5000 10000 15000 20000 25000 0.20% 0.30% 0.40% 0.50% 0.60 Minimum Support M em or y Sp ac e K B CATS Tree GC Tree SC Tree Figure 11. Tree construction space requirement with different minimum support in T10I4D100K database 0 50000 100000 150000 200000 100K 250K 500K 750K 1000K Transaction Size 


M em or y Sp ac e K B  CATS Tree GC Tree SC Tree Figure 12. Tree construction space requirement with fixed minimum support 0.4% in T10I4D100K~1000K database 332 0 200 400 600 800 1000 1200 0.20% 0.30% 0.40% 0.50% 0.60 Minimum Support M em or y Sp ac e K B  CATS Tree GC Tree SC Tree Figure 13. Memory requirements under different minimum support in T10I4D500K database 0 200 400 600 800 1000 


1200 1400 100K 250K 500K 750K 1000K Transaction Size M em or y Sp ac e K B CATS Tree GC Tree SC Tree Figure 14. Memory requirements with fixed minimum support 0.2 T10I4D100K~1000K database V. CONCLUSION AND FURTURE WORKS In this paper, a new tree structure called SC tree and a mining algorithm for association rule are proposed. Advantages of several algorithms are combined in this algorithm, and experimental results also show that the proposed algorithm outperforms CATS tree and GC tree mining algorithms For the SC tree algorithm, the mining model \(tree structure does not need to be re-constructed while the minimum support is changed. This property enables users to adjust the minimum support dynamically to find out satisfied large itemsets Because the database is sorted before mining, the SC tree can be mined only from the bottom-up direction, which is quite different from the bi-directional mining in CATS tree and thus the mining time for SC tree is shorter than CATS tree Moreover, the arrangement of sorted transactions is consistent so it is unnecessary for SC tree to adjust the tree structure as in CATS tree. That further improves the efficiency of tree construction in SC tree In addition, the memory requirements for constructing and mining the tree structure of SC tree are also less than both the CATS tree algorithm and the GC tree algorithm. Experimental results show that SC tree algorithm saves 16%~ 34% of memory space Although SC tree algorithm is more efficient than the other approaches, there are still some aspects can be considered for further improvement. One is the process of pre-sorting. When 


the data set is updated, the whole database has to be re-sorted If only partial tree structure rather than the whole tree structure is to be adjusted, execution time can be reduced substantially Another aspect is the scalability. When applying the SC tree algorithm in a large database, employing the technique of parallel and distributed computing can not only lightens the loading of processers and the requirement memory space but also suits for the architecture of disturbed computing environment in enterprises REFFERENCE 1] Peng, Y., Kou, G., Shi, Y., and Chen, Z., A Descriptive Framework for the Field of Data Mining and Knowledge Discovery , International Journal of Information Technology and Decision Making, Vol. 7, Issue: 4, Page 639 - 682, 2008 2] R. Agrawal & R. Srikant, Fast Algorithms for Mining Association Rules, Proceedings of the 20th VLDB Conference Santiago, pp. 487-499, September 1994 3] J. Han, J. Pei, Y. Yin and R. Mao, et al., Mining frequent patterns without candidate generation: A frequent-pattern tree approach, Data Mining and Knowledge Discovery, vol. 8, no. 1 2004, pp. 53-87 4] W. Cheung and O.R. Zaiane, Incremental mining of frequent patterns without candidate generation or support constraint Citeseer, 2003, pp. 111-116 5] G. J. Hwang, W. F. Tsai and J. C. R. Tseng, A Minimal Perfect Hashing Approach for Mining Association Rules from Very Large Databases, Proc. The 6th IASTED International Conference on Internet and Multimedia Systems and Applications, 2002, pp. 80-85 6] C.-K. Chiou, and J. C. R. Tseng, A Scalable Association Rules Mining Algorithm Based on Sorting, Indexing and Triming Proc. International Conference on Machine Learning and Cybernetics, 2007, pp. 2257-2262 7] W. Pei-ji, S. Lin, B. Jin-niu and Z. Yu-lin, Mining Association Rules Based on Apriori Algorithm and Application, Proc International Forum on Computer Science-Technology and Applications, 2009, pp. 141-143 8] J. Pei, J. Han, B. Mortazavi-Asl, J. Wang, H. Pinto, Q. Chen, U Dayal and M. C. Hsu, Mining sequential patterns by patterngrowth: The prefixspan approach, IEEE Transactions on Knowledge and Data Engineering, 2004, pp. 1424-1440 9] G. Grahne and J. Zhu, Fast algorithms for frequent itemset 


mining using FP-trees, IEEE Transactions on Knowledge and data Engineering, vol. 17, no. 10, 2005, pp. 1347-1362 10] L. Qihua, Z. Defu and W. Bo, A New Algorithm for Frequent Itemsets Mining Based on Apriori and FP-Tree, Proc. WRI Global Congress on Intelligent Systems, 2009, pp. 360-364 11] S.Y. Liu, An Efficiency Incremental Mining with Grouping Compress Tree, Unpublished masters thesis, National Central University Taoyuan Country, Taiwan, 2004 12] IBM Almaden Research Center http://www.almaden.ibm.com/cs/disciplines/iis 13] S. K. Tanbeer, C. F. Ahmed and J. Byeong-Soo., Parallel and Distributed Frequent Pattern Mining in Large Databases, Proc 11th IEEE International Conference on High Performance Computing and Communications, 2009, pp. 407-414 333 


ec  d Fig. 5: Computation Performance Comparison Tab. 4: Computation Savings by TOP-MATA K Connect K Retail K Wap La12 50 58.35% 100 0.01% 200 0.83% 23.04 150 55.91% 400 2.65% 400 30.12% 45.38 250 53.61% 700 1.84% 800 20.03% 25.95 350 48.28% 1100 3.95% 1600 13.06% 27.89 450 43.12% 1400 1.48% 3200 6.14% 12.70 550 39.36% 1700 4.00% 6400 5.63% 7.11 Second, Fig. 5 shows the results of four data sets computed by TOP-MATA and TOP-DATA, respectively. As can be seen, in general, TOP-MATA shows a better performance than TOP-DATA. And as the increase of the ? value, the advantage tends to be even more impressive for these four data sets 4.3. The Computation Saving of TOP-MATA As can be seen in the Tab. 4, four data sets, enjoy signi?cant computation savings brought by TOP-MATA. We can conclude that the computation saving is a major factor for the performance of TOP-MATA. That is, compared with TOP-DATA, a higher computation saving implies a much better performance of TOP-MATA. Since this saving is more signi?cant as the increase of the items, TOP-MATA works better for large scale data sets with a large number of items 5. Conclusion In this paper, we studied the problem of searching for top? item pairs with the highest cosine values among all item pairs. Speci?cally, we provided a novel algorithm TOPMATA which employ a Max-First traversal strategy for ef?ciently performing top-? cosine similarity search. Extensive experimental results veri?ed the effectiveness of the algorithms, And TOP-MATA algorithm is superior to TOPDATA for large-scale data sets with multiple items Acknowledgment This research was partially supported by the National Natural Science Foundation of China \(NSFC No. 70901002 and the Ph.D. Programs Foundation of Ministry of Education of China \(No. 20091102120014 


REFERENCES 1] R. Agrawal, T. Imielinski, and A. Swami, Mining association rules between sets of items in large databases, in SIGMOD 1993 2] C. Alexander, Market Models: A Guide to Financial Data Analysis. John Wiley & Sons, 2001 3] W. Kuo, T.-K. Jensen, A. Butte, L. Ohno-Machado and I. Kohane, Analysis of matched mrna measurements from two different microarray technologies Bioinformatics, vol. 18, p. 405C412, 2002 4] H. Xiong, X. He, C. Ding, Y. Zhang, V. Kumar, and S. Holbrook, Identi?cation of functional modules in protein complexes via hyperclique pattern discovery in PSB, 2005 5] J. Han, H. Cheng, D. Xin, and X. Yan, Frequent pattern mining: Current status and future directions DMKD, vol. 15, no. 1, pp. 5586, 2007 6] P.-N. Tan, M. Steinbach, and V. Kumar, Introduction to Data Mining. Addison-Wesley, 2005 7] S. Brin, R. Motwani, and C. Silverstein, Beyond market basket: generalizing association rules to correlations, in SIGMOD 1997, Tucson, AZ, 1997, pp 265276 8] E. Omiecinski, Alternative interestmeasures formining associations, TKDE, vol. 15, pp. 5769, 2003 9] H. Xiong, S. Shekhar, P.-N. Tan, and V. Kumar Exploiting a support-based upper bound of pearsons correlation coef?cient for ef?ciently identifying strongly correlated pairs, in KDD 2004, 2004, pp 334343 10] I. Ilyas, V. Markl, P. Haas, P. Brown, and A. Aboulnaga, Cords: Automatic discovery of correlations and soft functional dependencies, in SIGMOD 2004 2004, pp. 647658 11] J. Zhang and J. Feigenbaum, Finding highly correlated pairs ef?ciently with powerful pruning, in CIKM 2006, 2006, pp. 152161 12] H. Xiong, W. Zhou, M. Brodie, and S. Ma, Top-k correlation computation, JOC, vol. 20, no. 4, pp 539552, 2008 13] S. Zhu, J. Wu, and G. Xia, Top-k cosine similarity interesting pairs search, in 


http://datamining.buaa.edu.cn/TopKCos.pdf 14] M. Zaki, Scalable algorithms for association mining, TKDE, vol. 12, pp. 372390, 2000 


enhance item-based collaborative filtering, in 2nd IASTED International Conference on Information and Knowledge Sharing, Scottsdale, Arizona, 2003 476 2010 10th International Conference on Intelligent Systems Design and Applications 


Basi Association Rles Basi c  Association R u les Association is basically connecting or tying up occurrences of Association is basically connecting or tying up occurrences of events Ol dib t f ilt t O n l y d escr ib e se t s o f s i mu lt aneous even t s Cannot describe patterns that iterate over time e g  itemset a  0  b  0  g    Eg If you sense higher data rates on the downlink than normal AND New Route generated Implies high chances of Intrusion AND New Route generated Implies high chances of Intrusion Associative IDS for NextGen Frameworks Dr S Dua LA Tech 20 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



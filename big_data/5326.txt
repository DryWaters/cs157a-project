Efficient Mining of Generalized Negative Association Rules  Li-Min Tsai, Shu-Jing Lin, and Don-Lin Yang Dept. of Information Engineering and Computer Science Feng Chia University, Taichung, 407 Taiwan debbi100@ms54.hinet.net, lin.shu.jing@gmail.com, dlyang@fcu.edu.tw   Abstract  Most association rule mining research focuses on finding positive relationships between items However, many studies in intelligent data analysis indicate that negative association rules are as important as positive ones. Therefore, we propose a method improved upon the traditional negative association rule mining. Our method main ly decreases the huge 
computing cost of mining negative association rules and reduces most non-interesting negative rules. By using a taxonomy tree that was obtained previously, we can diminish computing costs; through negative interestingness measures, we can quickly extract negative association data from the database  Keywords-data mining; negative association rule concept hierarchy; taxonomy; negative interestingness  I  INTRODUCTION In the research of data mining, association rule mining is one of the most important research topics. Most association rule algorithms focus on finding positive association rules. Many literatures in intelligent data analysis show that negative association rules are as 
important as positive rules. Especially, negative association rule mining can be applied to a domain that has too many types of factors. Negative association rules can help users quickly decide which ones are important instead of checking too many rules. For example, in Bioinformatics, we may find out a negative association rule such as {if protein A appears, then protein B and protein C will not appear}. This kind of negative association rule is useful for biologists when they research on disease or drug development. In traditional approach finding negative association rules encounters a large search space and generates too many non-interesting rules 
Therefore, an efficient and useful algorithm for finding negative association rules is very valuable. Our research focuses on reducing computing time and trying to find interesting negative association rules. The proposed algorithm could speed up comp uting time efficiently and through the domain taxonomy tree, we could find interesting negative association rules more easily  II  RELATED WORK The Apriori algorithm [1 a sic alg o rith m in  mining association rules. Based on Apriori, many improved algorithms are proposed. For example, partition algorithm w a s dev e l oped f o r redu ci ng t h e num ber o f  
database scan; FP-growth algorithm w a s  u s ed to s p eed up computation time; generalized association rule [4 w a s  an extension of association rule where no item in Y is an ancestor of any item in X for the rule Y X 002  Nevertheless, until now, most improved association rules algorithms focus on positive association rules or some rare association rules mining  Mining negative association rules is another issue that has raised some resear chers’ attention [6 r example, when we determine strategies of product placement and purchase analysis, there are many factors 
that we must weight the pros and cons. To minimize negative impacts and increase possible benefits  managers must consider which side-effect is unlikely to occur when the expected advantage factor is selected. In such a situation, a negative association rule like Y X  002 would be useful. Because this rule tells us that C \(e.g., a disadvantage factor\ not occur or rarely occurs when A \(e.g., an advantage factor\hows up Algorithms for discovering negative association rules are not widely discusse T h e di s c ov er y  procedure of these algorithms can be decomposed into three stages: \(1\ind a set of positive rules; \(2\enerate 
negative rules based on existing positive rules and domain knowledge; \(3\ prune the redundant rules. Ashok, et al. [8  generates negative association rules based on a complex measure of rule parts. A negative association rule defined in [8 i m p licat io n  o f th e f o r m  X Y w h e r e  003  004 Y X X is called the antecedent, and Y is the consequence of the rule. Every negative association rule has a rule interest measure RI which is defined as   support   support 
  support  X Y X Y X RI 005  005  006 1 where 002³\004í\002î\003\006\003\010\003\003\003\003\003\002\003\005\003\007\002 002 002¼\002ð\002 is the expected support of an itemset X The rule interest RI is negatively related to the actual support of the itemset Y X 005 It is the highest if the actual support is zero, and zero if the actual support is the 
2010 IEEE International Conference on Granular Computing 978-0-7695-4161-7/10 $26.00 © 2010 IEEE DOI 10.1109/GrC.2010.148 471 


same as the expected support Xiaohui, et al [9 ge ne r a t e s ne ga t i ve a sso c i a t i o n  rules by using a similar concept of T h ree m eas u r es  used in the algorithm are minimum support, minimum confidence and SM \(salience measure\A negative association rule defined in s as an i m p l i cat i on of  t h e  form Y X or  000   000 Y X where I X 007  I Y 007 and 003  004 Y X The SM \(salience measure is used to provide clues to potentially useful negative rules and defined as follows          r conf E r conf SM   2 where    r conf is the actual confidence of rule r A large value for SM is an evidence for accepting the hypothesis that Y X 002  is false. That is Y X  002   may be true. In brief, to qualify as a negative rule, it must satisfy two conditions: first, there must exist a large deviation between the estimated and actual confidence values and, second, the support and confidence are greater than the minimum required In this paper, we focus on efficiently mining negative association rules. The reasons that motivate us are 1  Negative association rules are as important as positive rules 2  Traditional approaches lead to a very large number of rules and expensive computing costs On account of these motivations, we developed a method to solve these problems. Our method can speed up computing time and find the interesting negative rules according to user’s requirements The rest of the paper is organized as follows. Section III gives the detailed process of the proposed algorithm The experiment results and their discussion are presented in Section IV. Finally in Section V, we conclude this paper III  PROPOSED METHOD Negative association rule discovery encounters a large search space such that it may spend more computing time than traditional positive rule discovery using intuitive mining algorithms like Apriori. Therefore, we propose an improved approach called Generalized Negative Association Rule \(GNAR\gorithm. For efficiency, we scan the database once and transform transactions into a space-reduced structure called vertical TID table stored in main memory. We assume that the information of taxonomy tree is available in advance. The taxonomy tree is used to assist creating vertical TID table That is, through the taxonomy tree, we can filter transactions that do not belong to this domain and make no contribution to the end result. In addition to eliminate a large number of useless transactions, the information in the taxonomy tree can be used to mine negative association rules In the mining steps of GNAR, we use negative interestingness and negative confidence to increase accuracy of mined results. Pruning techniques are used to remove non-interesting negative association rules A. The Concepts of GNAR The concepts used in GNAR can be divided into two parts: concept hierarchy and negative interestingness Since the search space of mining negative association rules is extremely large, a concise representation of negative association rule must be developed. Concept hierarchy or taxonomy is used for this purpose. The second is negative interestingness. As mentioned above we can think of negative association rules as a complement of positive association rules. The nature of negative association rule is totally different from positive one. Therefore, traditional measures such as support and confidence used for positive association rules are not proper for negative association rule anymore. Suitable measures for mining negative association rules are needed More detailed descriptions about these two concepts are as follows Concept hierarchy A concept hierarchy allows a series of mappings from a set of low-level concepts to higher-level, more general concepts. It is a useful form of background knowledge in that they allow raw data to be represented at generalized levels of abstraction Generalization of the data, or rolling up, is achieved by replacing primitive-level data by higher-level concept. By using concept hierarchy, we can condense the negative association rules to a more succinct form    Figure 1.  A concept hierarchy for the dimension snacks   Fig. 1 shows a concept hierarchy for the dimension snacks. In this paper, concept hierarchy and taxonomy tree\will be used interchangeably. We take Fig. 1 as an example, if a generated rule of the form R cracker  B  Brand Pepsi 002 then the rule of the form 1 R  Cracker  Drink Soft 002 would also be generated and hold a larger support than R. This kind of concept is suitable for mining negative association rules. Because the number of generated negative association rules would 
472 


be greater than generated positive ones. Therefore, a negative association rule would be more easily understood if we present it with a concept hierarchy. It also allows users to view the data at more meaningful and explicit abstractions  Fig. 1 shows three nodes for different use. Only items of leaf node are presented in the database. The other two nodes \(Root and Internal node\sed for concept hierarchy presentation. Three types of generalized negative association rule would be mined in our method node  Internal node  Internal    Drink   Leaf node  Internal  B    Drink   Leaf Leaf  A  Brand   Coke   002  002  002  002  002  002   In our proposed method, we assume that this kind of taxonomy tree can be provided in advance. Through the taxonomy tree, we can first eliminate transactions that do not belong to the domain or contain user-specified items. After counting support of each item, the taxonomy tree would be further pruned to become a smaller one The taxonomy information is reserved for the following negative association rule mining process Negative interestingness Before we start to introduce negative interestingness, we shall discuss relationships between items first. Here, we only discuss binary relationship. A state diagram is shown in Table 1 X and Y are different items in a database. Each item in the database has two conditions, that is, presence or absence Therefore, such a four-state table is created for item X and Y. From Table 1, we can easily deduce support and confidence for mining traditional association rules. For instance, support of rule Y X 002 can be expressed by d c b a a N N N N N    and confidence of rule Y X 002  can be expressed by b a a N N N  In order to extract interesting negative association rules from large databases we must define a proper measure for negative association rule mining. From Table 1, we find that attribute a N is the condition that X and Y occur at the same time. The others have at least one negative \(Absence\factor Therefore, instead of using traditional measures such as d c b a a N N N N N    for support and b N a N a N  for confidence, we define a measure for mining interesting negative association rules as follows Negative interestingness   5   4 3 2 1 w d N c N b N a N w d N w c N w b N w      3  This measure is a general case that contains most of dissimilarity measures to the best of our knowledge. For example, dissimilarity measures binary pattern difference average squared and binary Euclidean are subsets of negative interestingness. Users are allowed to modify these flexible parameters 1 w to 5 w g to their applications and specific demands. Moreover, we also can easily define confidence for negative association rules from the four-state diagram of Table 1. Three types of negative association rules are shown as follows  d N c N d N d N c N c N b N a N b N Y X Y X Y X     002  002   002        TABLE 1. Binary relations  B. The Process of GNAR In this section, we give a detailed description of the proposed GNAR algorithm in the following three steps 1\we scan the database into a vertical TID table in main memory. The vertical TID table is a memory space-reduced structure. It transforms transactions into a bit-map string mode according to data distribution in the original database. If the original database is dense \(most of items occur more than half of total transactions\e vertical TID table can then change to record TID of each item, which is not occurred in the database. If the original database is sparse, then the vertical TID table only records TID of each item occurred in the database. Because our GNAR algorithm is a memory-based algorithm, the use of memory space must be considered carefully The vertical TID table can be applied in both dense and sparse databases 
473 


 Figure 2. The GNAR algorithm   2  Second, we assume the information of taxonomy tree is always available. According to this taxonomy tree we can eliminate items and transactions that do not belong to this domain. Then, with a minimum support we can find L1 from the vertical TID table and calculate support of each internal node in the taxonomy tree. In this step, the support of each internal node and root node can be calculated by using the OR operation. In the GNAR process, we use negative interestingness mentioned before to replace support measure except when forming L1  3  After calculating all support of internal nodes in the taxonomy tree, we can generate frequent taxonomy itemsets T. Then we generate C2 from L1. When counting the support for L2, we use negative interestingness as its threshold and apply a pruning technique. That is, items in C2 that belong to the same parent node according to the taxonomy tree will be pruned. From L2, we can generate R2 with another pruning technique being applied here. That is, assume a rule in the form of 2 1     I I  002   003  004 2 1 I I no item in 2 I is an ancestor of any items in 1 I After that, we construct an association graph based on L1, L2 and frequent taxonomy items T The association graph is used to join frequent taxonomy items with original large items in the database and to keep taxonomy information for the following mining process. Based on the association graph, we can produce k-generalized negative association rules. In our GNAR algorithm, we only consider generalized negative association rules in the form of       ItemsetB ItemsetA  002  that items in braces ItemsetA or ItemsetB  positively associated respectively Fig. 2 shows our GNAR algorithm. Negative confidence is used to extract three types of rules in each rule-generation step IV  EXPERIMENT RESULT AND DISCUSSION We use Visual C++ programming language to implement the GNAR algorithm. We perform our experiments on a personal computer of Intel Pentium 4 processor with a clock rate of 2.4AGHz and 512MB DDR266MHz main memory. The test data of our experiments were produced from IBM dataset generator  A. Experimental Parameters Table 2 shows the parameter settings used in generating the three testing databases. T is the average number of items per transaction. I is the average length of maximal frequent patterns. D is the total number of transactions. In addition to compare with traditional negative association rule algorithm, we also performed experiments on different parameter settings \(test1~test5 in Table 3\ our algorithm  TABLE 2. Test databases   TABLE 3. Test parameters   
474 


B. Experiment results and discussion We ran both GNAR and traditional algorithms on the three datasets with parameter setting of test1~test5 in Table 3. The average level of taxonomy data is set to 6 and 11 categories were given here. We use dataset T10I6D10K for the first experiment. The weight parameters of GNAR are w1 = w2 = w3 = w4 = w5 = 1 and negative interestingness = negative confidence = 0.6   Figure 3. Execution time experiments on T10I6D10K  Fig. 3 shows the result of experiment for database T10I6D10K. X-axis represents various values of initial support of GNAR and support of traditional negative association rule algorithm. These values range from 0.5 to 1.0. Y-axis represents execution time of the two algorithms according to diff erent support values. From Fig. 3, we can find that GNAR spends less time than traditional algorithm in most cases. When support is close to 0.5, GNAR performs much better than traditional negative association rule algorithm. On the other hand when support is close to 1, the performance of these two algorithms is similar We use dataset T15I12D100K in the second experiment to analyze the performance of algorithms when the average length of maximal frequent patterns is long. In this experiment, we set the parameters of GNAR as w1=1, w2=1, w3=1, w4=1, w5=1, negative interestingness = 0.6 with different Ini_Sup values, and different supports of traditional algorithm. We found traditional algorithm is inefficient, especially when the average size of transactions of maximal potentially large itemsets is doubled from 6 to 12. Fig. 4 shows that traditional algorithm spends more time to generate negative association rules than GNAR when support is close to 0.5. When support is close to 1, the performance of GNAR and traditional algorithms is almost the same   Figure 4. T15I12D100K  In the third experiment, we use different parameter settings \(test1~test5\rom Table 3 to analyze the generated negative association rules for dataset T12I8D50K. Taxonomy data used here are set as the average number of levels = 6 and the average number of categories = 11 Fig. 5 shows the result of this experiment. We found that test4 generated the most amounts of negative association rules. This is because the denominator of negative interestingness decreases such that many rules can be extracted by using negative interestingness. On the other hand, both generated rules of test3 and test5 are much less than other tests. The reason is that the feature of the tested database has less negative relationship   Figure 5. Generated negative association rules using different testing settings of test1~test5  In the last experiment, we use different taxonomy data for comparing the effect of our GNAR algorithm with different taxonomic structures. In this experiment we set the parameters of GNAR as w1=1, w2=1, w3=1 
475 


w4=1, w5=1, negative interestingness = 0.6, Ini_Sup 0.6 and negative confidence = 0.6. Two taxonomic structures are used here for comparison. Taxonomy1 is set to the average number of levels = 3 and the average number of categories = 11. Taxonomy2 is set to the average level size = 9 and the average number of categories = 11. The tested dataset is T12I8D50. Fig. 6 shows the execution time of these two taxonomies. From Fig. 6, we found that our method is more efficient when the level size of taxonomy is larger. The reason is that the fan-out of taxonomy deeply effects the performance of GNAR. Since Taxonomy2 is set to have a larger level size than Taxonomy1, Taxonomy2 has smaller fan-out than Taxonomy1. Therefore, the GNAR algorithm is more efficient for mining negative association rules with a larger level size   Figure 6. Comparison of different taxonomies V  CONCLUSION A considerable body of work has been carried out on the problem of positive association rule mining, but negative association rule mining has received very little attention. Negative association rule mining can be applied to a domain that has various types of factors and it can help user quickly decide which one is an important factor instead of checking too many rules. In this paper, we proposed an efficient method of mining generalized negative association rules Instead of mining negative association rules with an intuitive method, we use negative interestingness to characterize the property of negative association rules and justify the effectiveness. With taxonomy tree information we reduce the search space of the mining process and a useful representation of generalized negative association rule is proposed. In the future, m ining sequential patterns with negative conclusions and developing scalable parallel algorithms are two major directions of our future research   ACKNOWLEDGMENT This research was supported by the National Science Council, Taiwan, under grants NSC 98-2221-E035-059-MY2 and NSC 98-2218-E-007-005  REFERENCES 1 R. A g ra w a l a nd R. Srik a n t  F a s t A l g o rithm s  f o r Mining  Association Rules in Large Databases,” Proc. of the 20th International Conference on Very Large Databases, pp. 487-499 Santiago, Chile, 1994   A  S avasere E  Om i eci n s ki  an d S  B Navat h e A n  Efficient Algorithm for Mining Association Rules in Large Databases,” Proceedings of the 21st International Conference on Very Large Databases, pp. 432-444, Zurich, Switzerland, 1995  3 J  H a n J   P e i a n d Y  Y i n M ini n g Fr e q ue nt  P a tte r n s  without Candidate Generation,” Proceedings of 2000 ACM SIGMOD International Conference on Management of Data, pp 486-493, May 2000  4 R. Srik a n t a n d R. A g ra w a l M ini n g G e ne ra liz e d Assoc i a tion Rules,” VLDB ’95, pp. 407-419, Zurich Switzerland, 1995  5  Y. S. Koh and N. Rountree, Rare Association Rule Mining and Knowledge Discovery: Technologies for Infrequent and Critical Event Detection, Information Science Reference publisher, August 2009  6  X. W u C  Z h a n g  S Zha n g   E f f ic ie nt Mining of B o t h  Positive and Negative Association Rules,” ACM Transactions on Information Systems, Vol. 22, No. 3, July 2004, pp. 381–405  7 C h en gq i  Z h an g, S c h i c h ao Zhan g S h i c h a o  Z h an g a n d B e r n o Eugene Heymer, Association Rule Mining: Models and Algorithms \(Lecture Notes in Artificial Intelligence\, Springer Verlag, July 2002  8 A  Sa v a se r e E. Om ie c insk i, a nd S  Na v a the   M ining f o r strong negative associations in a large database of customer transactions,” Proceedings of International Conference on Data Engineering, pp. 494-502, February 1998   X  Y u an  B Bu ckl e s Z  Yu an  an d J Z h an g M i n i n g Negative Association Rules,” Proceedings of the Seventh IEEE International Symposium on Computers and Communications ISCC’02\, pp. 623-628, 2002  1 C  C o r n el i s  P  Yan   X   Z h an g an d G  C h en and  Mi n in g Positive and Negative Association Rules from Large Databases,” IEEE Conference on Cybernetics and Intelligent Systems, pp. 613-618, 2006  11 I B M A l m a de n R e s e a r c h C e nte r 20 06. Sy nthe tic da ta  generation code, http://www.almaden.ibm.com/ software/quest 
476 


  Figure 9.  Comparing running time of XCLS and XCLS The FScore value of a category Z r  is the maximum  FScore value attained in any cluster of the clustering solution. Hence, the FScore of the overall clustering solution is defined as the sum of the individual class FScores weighted differently according to the number of documents in the class N C Z F n FScore k r i r r   1     where k is the number of clusters. A good clustering solution has the FScore value close to one  5.3. Quality evaluation  Table 2 shows all the experiments and assessments about the quality of clustering. As shown in table, we tried to compare the algorithms under different circumstances and each time we run the algorithms with different parameters and record the results. The results declare that XCLS+ clusters the documents with better quality  5.4. Running Time Evaluation  The time complexity for both algorithms XCLS and XCLS+ is equal because the basis of both algorithms is equal and the difference is the way they use to find the common elements between two documents. Thus as the XCLS algorithm assert time complexity is linear but the running time is different because as explained previously XCLS+ algorithm is able to find all common elements just by one iteration but XCLS needs two iterations. According to recent explanation our algorithm must have better running time than the XCLS. After calculating the running time for one of our data sets Figure 9 proves our claim  6. Conclusion and future works  We presented an algorithm for clustering XML documents based on the XCLS algorithm. We compared our algorithm with the XCLS algorithm and perceived that it works better than XCLS or in the worst case it performs like XCLS. Although this Table2. The experiments and assessments about the quality of clustering  Data set Algorith m  r facto r Threshol d Entrop y Purit y FScore Cluster No XML Files XCLS 2 0.75 0.06 0.86 0.88 21 2 0.6 0.07 0.83 0.84 21 1.5 0.75 0.08 0.85 0.86 21 XCLS 2 0.75 0.04 0.94 0.96 22 2 0.6 0.04 0.93 0.94 22 1.5 0.75 0.05 0.91 0.92 22 m-db-s-0 XCLS 2 0.75 0.21 0.73 0.75 11 2 0.6 0.20 0.73 0.73 11 1.5 0.75 0.20 0.72 0.73 11 XCLS 2 0.75 0.18 0.79 0.80 11 2 0.6 0.17 0.78 0.79 11 1.5 0.75 0.18 0.75 0.78 11 m-db-s-1 XCLS 2 0.75 0.26 0.69 0.71 11 2 0.6 0.24 0.68 0.70 11 1.5 0.75 0.26 0.68 0.69 11 XCLS 2 0.75 0.17 0.72 0.72 11 2 0.6 0.17 0.71 0.71 11 1.5 0.75 0.18 0.72 0.71 11 m-db-s-2  XCLS 2 0.75 0.31 0.66 0.67 11 2 0.6 0.30 0.66 0.68 11 1.5 0.75 0.32 0.65 0.66 11 XCLS 2 0.75 0.28 0.69 0.71 11 2 0.6 0.27 0.68 0.70 11 1.5 0.75 0.28 0.69 0.71 11  Proceedings of the 14th International CSI Computer Conference \(CSICC'09 594 


algorithm solves some of the problems of the XCLS algorithm but one of its remained problem is specifying the threshold that may affect its performance remarkably. Future works for this paper can be: specifying the threshold by the algorithm automatically, considering the concepts of elements for clustering, designing a two phases algorithm for clustering as in one phase using pair wise algorithms and in another using incremental algorithms. Finally as the role of XML documents becomes more important, we hope our algorithm would be useful for clustering XML documents especially in search engines that search huge resources of the World Wide Web  7. References  1 R  N a y a k    F a s t a nd ef f e c t i v e c l us te r i ng of XML da ta using structural information", Knowl. Inf. Syst. 14\(2\008 pp. 197-215  2 R. N a y a k    X ML D a ta Mini ng  P r oc e s s a n d  Applications", in Song, Min and Wu, Yi-Fang, Eds, Idea Group Inc. /IGI Global, 2008  3 R. Nay a k  T  T r an  A P r o g ressiv e Clu s terin g  A l g o rith m to Group the XML Data by Structural and Semantic Similarity", IJPRAI 21\(4\, 2007, pp. 723-743  4 L  De noy e r P  G a llina r i R e port o n the  X M L m i ning track at INEX 2005 and INEX 2006: categorization and clustering of XML documents", SIGIR Forum 41\(1\, 2007 pp. 79-90  5 S. A b ite bo ul P. B u ne m a n and D  S u c i u   D a t a on the  Web: From Relations to Semistructured Data and XML Morgan Kaumann, CA, 2000  6 S Fles ca, G  Ma nc o E M a sc ia ri, L  P o ntie ri a n d A   Pugliese, "Fast detection of XML structural similarities IEEE Trans. Knowl. Data Engin 7 2\, 2005, pp. 160–175  7 T  Da la m a g a s T  Che ng K  W i nk e l T  K. Se llis, "A methodology for clustering XML documents by structure Inf. Syst. 31\(3\2006, pp. 187-228  8 W  L i a n D  W  C h e ung  N  Ma m oulis S Y i u   A n Efficient and Scalable Algorithm for Clustering XML Documents by Structure", IEEE Trans. Knowl. Data Eng 16\(1\, 2004, pp. 82-96  9 T h e W i sc onis n  s XML d a ta ba nk  A c ce s s e d f r o m   http://www.cs.wisc.edu/hiagara/data.html. Cited sept 2004 The XML data repository. Accessed from http://www.cs.washington.edu/research/xmldatasets/. Cited Sept 2004  10 I N EX 2 00 5 D o c u m e nt m i ning tr a c k  A c c e s se d f r om   http://inex.is.informatik.uni-duisburg.de/2005  11 Y  Zha o G  K a r y pis   C rite rion f unc ti ons f o r doc um e n t clustering: Experiments and analysis", Department of Computer Science, University of Minnesota, Minneapolis 2001 Proceedings of the 14th International CSI Computer Conference \(CSICC'09 595 


9 Appendix Fig 6: Forest Cover Types of the U.S. \(Source. USGS National Atlas of US Summary of Forest Cover Type Data Type Multivariate Abstract The forest cover type for 30 x 30 meter cells obtai ned from US Forest Service \(USFS\ Region 2 Resource Information System RIS\ data Data Characteristics The actual forest cover type for a given observatio n \(30 x 30 meter cell\ was determined from US Fores t Service \(USFS\ Region 2 Resource Information System RIS data Independe nt variables were derived from data originally obta ined from US Geological Survey \(USGS\ and USFS data. Data is in raw form \(not scaled\ and contains binary \(0 or 1 columns of data for qualitative independent variables \(wilderness areas and soil types Summary Statistics Number of instances observations 581012 Number of Attributes 54 Attribute breakdown 12 measures, but 54 columns of data \(10 quantitativ e variables, 4 binary wilderness areas and 40 binary soil type variables Missing Attribute Values None 43 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        






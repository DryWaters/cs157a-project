GET /dgs HTTP/1.1 Host: www.WebComposition.net   Martin Gaedke 1  1 Chemnitz University of Technology, Germany Faculty of Computer Science firstname.lastname}@cs.tu-chemnitz.de   Andreas Heil 1,2  2 Microsoft Research, UK Computational Science Group v-aheil@microsoft.com   Abstract   During the last years, the asset costs for storage have been decreasing continuously. Coincidentally, the demand to create and publish data in the Web has grown in an unprecedented manner. Within the Web 2.0, the user became an active part by creating publishing, changing and annotating data and its related metadata in a wide variety of new kinds of applications. Many data management but also architectural decisions for such applications are driven by distribution and semantic aspects. In this paper, we present how the WebComposition Data Grid Service \(WebComposition/DGS 
emerges new kinds of data-centric applications as a REST-architectural style component within the context of Web 2.0 but also satisfies requirements within traditional SOA-based business scenarios   1  Introduction  Within the idea of Web 2.0, data is a substantial f r ch itectu ral d e cis i on s are bas e d on  distributed and semantic aspects about data, its related metadata and its overall availability but also accessibility. Competitive advantages arise through data, the way it is generated and the way it is made available. A typical characteristic of the data is that a large amount of it is created by the users themselves Some of the best known and commonly used representatives are eBay auctions, Amazon reviews Flickr photostreams, Last.fm scrobblings or Twitter feeds. This data is not created by an editorial team but rather by the users directly. Consequently, this has led to a vital change of the digital identity of users in the 
Web. Originally, the user s homepage was the one and only place where all information was stored and published, since it was the only place where the user typically gained write access in the Web. Nowadays the digital identity of a user is scattered all over the Web. Photos are hosted with Flickr, news articles are posted on a weblog such as Blogger, microblogging and instant messaging is achieved through Twitter feeds, links are archived within del.icio.us and contact details are stored in social network portals such as LinkedIn or Plaxo \(see Figure 1\ Various portals such as Facebook or MySpace provide functionality to mesh up this scattered data into one single Web page or a Web site as substitution for the personal homepage While the data of a user formerly resided on this dedicated, central place where he was allowed to create data, it is now conflated from multiple data providers possibly stored in data formats the user has no direct 
influence on 
Figure 1 Digital identity through multiple data providers 
The usage of this distributed, heterogeneous data sources is rather limited. If ever, each data provider offers a different way of interacting with the stored data in other applications. This circumstance makes the efficient development of applications based on those data sources often very unpredictable, if not impractical at all. The question now is how to interact with the data, how to link the data from the various data sources in a meaningful way to each other and how to reuse this data in other applications In this paper we discuss the WebComposition Data Grid Service \(WebComposition/DGS\mponent. Our main contribution here lies in its capability to implicitly manage metadata based on Semantic Web Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 1 978-0-7695-3450-3/09 $25.00 © 2009 IEEE 


standards as first-class constructs. We will especially focus on the capability to use this metadata and to make use of the concept of linked data within different architectural styles. Subsequently, we discuss the extensible core elements of the WebComposition/DGS that allow a high degree of reuse to reduce development costs of systems dealing with metadata irrespectively of the underlying architecture style  2  Motivation and Background  2.1  Example Scenario  During a code review, Clark, a software engineer in an international software company came along with an idea for a tool to increase the productivity within his team. To make this tool available to all team members he decided to make this tool available within the company s intranet. He set up a Web server and wrote this little, Web-based application in his spare time. At this time, the Web-server s address was known only by his team members and Clark did not care a lot about security. Also, the tool stored all the data in plain text files, since Clark simply did not want to spend too much time on this Several weeks later, during an internal architecture review of the company s latest product, he accessed the tool via his Web browser to show the information that was requested from him. Several colleagues became very curious about that tool, they had never seen before. They realized the added value by this tool and asked Clark, if their teams might use it as well. Clark was flattered and agreed. He also realized that the tool was not capable of dealing with multiple data sets from different teams. So he spent a remarkable portion of his spare time to change the tool s way of dealing with data. At this point he thought a database might be a good solution to dealing with the increasing amount of data Once he was contacted by the manager of the internal tools division, who asked Clark to make this tool available to all employees within the company This increasing degree of awareness also required some additional functionality to deal with security aspects since not all users should have been able to see all the projects managed by this tool. Clark had to implement additional functionality. Luckily, a developer from the internal tools division supported Clark to modify the tool to use the company s internal user directory During the annual review, the company realized that the tool caused an incredible increase in performance within the various product groups. The management thus realized the potential of this tool and that it might be an appropriate supplement to the company s portfolio of Web-based services. Hence they decided to offer this as a new service. Based on the company s user directory, a fixed integration with the storage solution, a data structure that was fitted with the company s internal operations and the integration into several in-house products, the tool had to be redesigned and newly developed, which caused not to be underestimated costs for the company. The results were the great idea behind the tool and a well designed system that however, did not succeed on the market for a long time The difference was indeed, that the tool, as long as developed and used in-house, underwent a permanent evolution. Since it was Web-based, it is not possible to roll-out new versions of the tool on a regular basis Changes have been introduced gradually. Hence, it adapted to new requirements and technologies. While Clark was aware of other in-house products and their related data formats and metadata, he developed plugins that enabled the tool to connect to various other tools used by the product groups. The service offered by the company was however not capable to integrate with many other tools. In fact, the easy extensibility and in particular, the integration with other tools, was the secret of the success of Clark s tool  2.2  Data & Semantic  Based on w e def i n e a c a talog u e o f es se n tia l  aspects and relations among these structures to be considered when designing a data-centric Web-based application Data The creation, maintenance and handling of data must be easy and reliable. Storing the data in a corresponding data storage and simple querying the data are key features, which the solution must provide The underlying technology must not restrict the user in terms of content to be stored and should provide the possibility of different views on the data. Changes or further developments in the underlying data processing and storage solutions should not affect already established applications based on the service Systematic creation and structuring of data  While in the context of Web 2.0 flexibility is eligible the systematic creation of structured data is required to address business-scale scenarios, where the integrity of data is indispensable. In certain cases, the user might be forced to adopt a specific structure for the data, e.g for constraining structures and content or for validating the data. The systematic creation and structuring of data, thus allows defining how symbols can be combined Metadata Metadata is required to describe the data itself. It must be provided in a machine-readable Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 2 


format. The metadata must provide information for understanding what one needs to know about data received from other sources, in order to proceed intelligently with the data. Also metadata is required to provide meanings of syntactically valid collections of data Linked Data Data needs to be identified published and linked. Based on its metadata, useful information has to be provided for connecting data Similarly appears the idea of links in HTML especially automatically generated trackbacks and pingbacks in the weblog domain\: data and data clouds must be connected for lookups and traversing the data Metadata is thus required to step through the data Security Security aspects are important for applications within a personal scope up to businessscale scenarios. Applications dealing with personal or business data must guarantee both the integrity of the data itself and the protection of privacy. The absence of a security mechanism, e.g. in a business environment, might result in financial risks for the particular company and is thus a key requirement for the particular solution Reuse and Integration The reuse of the components includes easy deployment, extensibility of the system, and the avoidance of one-off efforts. How easy can the solution to be used in already existing solutions and how much effort is required to achieve this, are key factors, especially in the Web 2.0 context which must be considered carefully. It is important that a solution supports the reuse of existing data and provides capabilities needed to integrate components within the context of another application and within different architectural styles  3  The WebComposition Approach  The WebComposition system was first introduced during the WWW6 conference in an  object-oriented approach, especially for the discipline of Web Engin d i n contras t  to t h e  discipline of traditional Software Engineering. The WebComposition approach was continuously developed up to today, where it abstracts the development and evolution of Web-based applications that are composed out of Web components. The WebComposition approach describes only the development and evolution process, the concept of composing and reusing Web components, but does not address the concrete technology applied to create the solution The Web components used to create a Web-based solution address different perspectives of an application: the content-perspective includes aspects related to data and semantics, the UIX perspective contains aspects related to the user interface experience and the DSA perspective contains especially aspects related to distributed system and architecture behavior The two core concepts of the WebComposition approach focus especially on two different perspectives of reuse. The development of Web components for reuse focuses on the creation of units that implement a certain perspective or corresponding aspects and, on the other hand, the development of solutions by reusing existing Web components to create complete Web applications/systems by composing existing Web components. To develop the WebComposition/DGS, as a central component of the 4 th Generation of the WebComposition approach, we also applied the lessons learned from our previous work, the WebComposition Service Linking System and the therefore developed CRUDS-Servi   3.1  WebComposition/DGS  The WebComposition/DGS is especially designed to meet today s requirements for developing distributed application in the Web, especially following the concept of Representational State Transfer \(REST architecture style. REST refers a set of constraints that define the distributed architectural styl e s o u r ces  are addressed using unique identifiers to which access is given through a uniform interface. In contrast to a service-oriented architecture, manipulation of resources is performed through stateless interaction with their representations. The most common RESTbased architecture is the Web itself, using the HTTP protocol to provide a uniform access to resources The WebComposition/DGS allows to put new ideas into practice very easily by using these REST principles but also common SOA-based approaches We find multiple interfaces for different scenarios while facing the particularities of Web 2.0 and taking into account the standards of the Semantic Web, the WebComposition/DGS is furthermore designed to be also applied in traditional business scenarios REST Business SOAP XML RPC DGS  Figure 2  WebComposition/DGS corner pillars Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 3 


The core interfaces \(cf. Figure 2\ided are \(i HTTP-based interface to be used within REST-like architecture styles, \(ii\imple XML/RPC interface to be used in simple ad-hoc implementation and \(iii SOAP interface, supporting document/literal SOAbased architectures suitable for most business scenarios Designed to be suitable for a variety of application scenarios, the WebComposition/DGS comes as a modularized componen h at can be ea s i l y e x te n d ed and adapted for specific needs. Before showing example scenarios where the WebComposition/DGS is already successfully applied in productive system, we discuss the key functionality of the WebComposition/DGS regarding the various aspects already identified in Section 2.2  4  WebComposition/DGS Internals  In this section we will discuss the core features of the WebComposition/DGS. We will especially focus on the usage within REST-like architecture styles however, the described functionality is accessible also through the provided SOAP and XML-RPC interfaces  4.1  In Direct Touch with the Data  Regardless of whether we are facing a serviceoriented architectur E ST li k e arc h itect u r e  styl e rel y an  u n c o n s t rain ed arch itect u re w e  always deal with the concept of resources when looking at a Web-based application/system. Therefore we enforce a strict usage of Uniform Resource Identifiers \(URI i t h i n t h e  WebComposition/DGS. Each resource created regardless whether data or metadata, can be accessed via its strictly composed URI such as depicted in Figure 3 below Http-URI http://vsr-data.cs.tu-chemnitz.de Container Data Item http http://vsr-data.cs.tu-chemnitz.de/meta http://vsr-data.cs.tu-chemnitz.de/people/heil Meta Meta http://vsr-data.cs.tu-chemnitz.de/people/heil/meta http://vsr-data.cs.tu-chemnitz.de/people/meta Meta http://vsr-data.cs.tu-chemnitz.de/people Information Store HTTP-URI  Figure 3  WebComposition/DGS URI concept  Each WebComposition/DGS service represents a container for one or many information stores An information store is the access point, at which users can add and query data. One could understand an information store as a list or set, where related data is logically grouped together. Within an information store, each data item stored in it can be accessed via its own URI. For each of the concepts \(container information store and data item\ the key path segment meta can be concatenated to access the related metadata  4.2  Create and Structure Data  In some ad-hoc scenarios, the user might create data in a quite easy fashion as Clark did in our example during his initial approach in Section 2.1. On the other hand, sophisticated business scenarios might require the creation and validation of structured data The WebComposition/DGS component supports both scenarios: Data is processed by a so-called data adapter cf. Figure 4\This exchangeable component of the WebComposition/DGS is the core element for creating and manipulating data  Data Adapter Data only Data + Schema Storage solution Input Filter Output Filter Meta Connector  Figure 4  WebComposition/DGS data adapter concept The concept of the data adapter is based on two major features: \(i\tensibility allows to create own data adapters for new kinds of data. For the current version of the WebComposition/DGS, data adapters for XML and HTML are already provided. Additional data adapters however can be developed and specified via a ii\stomization of data adapters via input and output  filters Filters specify the format of data as well as the kind of accepted data. Additional filters can be developed and specified via the configuration file. Hence, the system can be simply reconfigured if new requirements arise This even allows specifying an output format different from the original input format and thus provides a high flexibility regarding the data representation Transforming the data to or from the internal representation of the data adapter is incumbent upon the corresponding filter The provided XML data adapter supports creation of both, structured and unstructured data. As such, adProceedings of the 42nd Hawaii International Conference on System Sciences - 2009 4 


hoc scenarios can be realized very easily. Regarding the interface for REST- like architecture style, the HTTP verbs are used as follows GET queries a resource at the given URI. The representation of the resource depends on the output filter specified in the configuration file of the WebComposition/DGS instance. By specifying a accept HTTP-header in the corresponding HTTPrequest, we indirectly specify which data adapter to use. However, the concept of the data adapter is transparent to the client that simply requests any resource from the service. If no accept header is specified, the WebComposition/DGS applies the default data adapter POST allows for the creation of new information stores on non-existing URIs. The XML data adapter which is the default adapter provided in the current WebComposition/DGS implementation, accepts a XSD schema send along with this request. The schema is then used to validate the data added to this newly created information store. Additional settings regarding the validation of the data can then be applied by adding further metadata as we will see in Section 4.3 below New data items are added using PUT on the information store s URI. The content-type specified in the HTTP-header specifies which data adapter is used to create the data item. Data items, but also complete information stores, can be deleted by sending DELETE  to the corresponding URI The SOAP interface can be used for document/literal SOA to achieve the same functionality. However, the functionality here is contained in the SOAP message, rather than in the protocol semantic. To allow easy integration with already existing SOA systems, a SOAP adapter is specified equivalent to the procedure of the data adapter connecting to data adapter \(cf  Figure 5 Hence, the WebComposition/DGS can be easily customized to fit into already existing SOA-based systems, while reusing existing components within the service    webComposition   dataGridService    dataAdapters    dataAdapter   type   WebComposition.Dgs.Content.Data.XmlDataAdapter WebComposition.Dgs.Content Version=1.0.0.0 Culture=neutral PublicKeyToken=null  inputNotation   TEXT/XML  outputNotation   TEXT/XML   contentType   text/xml    metaData  inputNotation   RDF/N3   outputNotation   RDF/XML    dataAdapter    dataAdapters    dataGridService   webComposition   Figure 5  Example data adapter configuration  4.3  Metadata is Data  Following e u n d ers t a n d m e t a dat a  as f i rst  class resource within the WebComposition/DGS Therefore, metadata can be accessed via its dedicated URI. Data and metadata are treated as open data and open metadata \(i.e. you have access to all data and metadata you create By default, all metadata is stored in the format of the Resource Description Framework \(RDF\his comes in handy for two reasons: at first, due to the strict URI concept within the WebComposition/DGS each resource \(including metadata\ identified by its URI. Therefore, each resource can appear in a RDF triple as subject and/or object. This especially allows us to use metadata to describe metadata again Secondly, RDF data is machine readable and accessible by a wide audience. Also the complexity of the metadata is not restricted, e.g. compared to the Exchangeable Image File \(EXIF\e It is  useful, that additional information can be simply added by inserting additional RDF triples. By default, each created resource is supplemented with the Dublin Core 14 m e tad ata, sto r ed as R D F trip les as w e ll. T h ese 1 5  standardized attributes are used to describe and classify Web resources using common characteristics of resources. This information base is supplemented by the WebComposition/DGS metadata vocabulary This data differs for each resource type and can be extended through data adapters. The container instance provides information about the contained information stores, an information stores again provides additional information about the contained data items such as content-types and item count. Additional metadata might be generated through the data adapter processing the data. For instance, it might be useful to extract EXIF metadata contained in images and store it directly as metadata with the corresponding resource when uploading digital photos to a WebComposition/DGS service Resource Settings Resource Dublin Core Metadata WebComposition/DGS Meta Vocabulary CRUD-Event Metadata User-Specific Metadata  Figure 6  WebComposition/DGS information stack  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 5 


 Data Adapter 1 Data Adapter m Meta Store Subscription Bus Data Adapter 2 Non DGS Web Service SOAP Adapter 1 SOAP Adapter 2 SOAP Adapter n HTTP Client WebComposition/DGS Web Browser Native DGS Client  Figure 7  WebComposition/DGS component interactions  A further aspect within the WebComposition information stack \(cf. Figure 6\ is the CRUD-Event metadata CRUD stands for create, read update and delete and describes the core operations performed on  Each operation on  a resou r ce is thu s trac k e d  and stored as CRUD metadata. This is especially helpfully in addressing the question of provenance since the representation in RDF is already suitable to process the information  w e con s ider th is, t h e  CRUD-Event metadata also addresses the issues of provenance in SOA-based systems  g e n e ral  Easy access to the events is granted through CRUDEvent RSS feed as depicted in Figure 8. By publishing the events to the feed, arbitrary clients can subscribe to the feed and monitor activities on the data. As metadata is understood as a first class resource additional, user-specific metadata can be added in the same way as data itself. Also for metadata, we can specify different input and output filters \(cf. Figure 5 By default, the WebComposition/DGS supports RDF/XML and Notation3 \(N3\ as metadata formats Additional filters can be created and specified  CRUD-Event RSS Feed CRUD-Event CRUD-Event RDF/XML  Figure 8  CRUD-Event RSS feed Finally, the WebComposition/DGS information stack provides the possibility to store se ttings for resources, such as the service itself. Settings usually describe the behavior of a system or a resource. Since everything within the WebComposition/DGS is understood as a resource, settings are stored as metadata describing this resource. We will subsequently discuss the usage of metadata for settings based on two common settings of the WebComposition/DGS As the WebComposition/DGS supports the creation of structured data, the XML data adapter supports the validation against XSD schemas \(cf. Section 4.2\.  It is possible to change the scope of the validation by using the settings to no validation at all, validating the submitted data \(a-priori validation of the data\r validation of the complete XML structure \(a-posteriori of the data after inserting into the XML structure\he default validation, applicable for any newly created information store, is set in the configuration file as seen in Figure 9 below   webComposition    dataGridService   defaultSchemaScope  scope   None     dataGridService    webComposition   Figure 9  Default schema validation  Using the N3 input filter, the default settings can be changed by putting the metadata through a simple HTTP-request to the information store s URI containing the N3 statement in Figure 10 below. By adding this metadata, we can simply set the validation for a particular information store to the a-priori validation described above  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 


prefix dm: http://www.webcomposition.net/dgs/meta  http://vsr-data.cs.tu-chemnitz.de/people dm:schemaScope Element  Figure 10  Schema validation metadata in N3 notation  As we can see in Figure 3, each data item within an information store provides its own URI. To address data items within a information store we apply the concept of URI templates 18  T o  illu strate th i s  concept we assume that the XML data for the information store http://vsr-data.cs.tuchemnitz.de/people is structured as seen in Figure 11  below   xml  version   1.0   encoding   utf-8    people   person   name  Heil  name   firstName  Andreas  firstName   title  Dipl.-Inform  title   office  1/B204  office    person   person   name  Gaedke  name   firstName  Martin  firstName   title  Prof. Dr.Ing  title   office  1/B319  office    person    people   Figure 11  Example information store data  In our example we want to address the data items i.e. the person elements\ via URIs such as http://vsrdata.cs.tu-chemnitz.de/people/Heil and http://vsrdata.cs.tu-chemnitz.de/people/Gaedke To do so, we use an URI template that specifies the URI we require as well as a XPATH expression mapping the requested data to the specified URI. The corresponding URI template, as it is submitted, is shown in Figure 12  prefix dm: http://www.webcomposition.net/dgs/meta  http://vsr-data.cs.tu-chemnitz.de/people dm:urlTemplate [meta:url "people/{value dm:xPath "/people/person[name='{value  Figure 12  URI template in N3 notation  It is important to know that all URIs specified for resources serve also as unique identifiers to address the resource in a SOA-based scenario using e.g document/literal SOAP  4.4  Linking Data and Metadata  By combining data and metadata we address the challenges identified in Section 1 how to link data to each other in a meaningful way. The concepts introduced so far help us in achieving this goal. If we apply the WebComposition/DGS as component in a merely SOA-based system, each resource is still identified by its own URI. Hence, all resources can be referenced transcending the boundaries of information stores when creating linked da   Data as well as metadata are combined by specifying a XSL transformation. A depiction of the process how the data is combined is given in Figure 13 Hence, not only the metadata but also the data itself are provided in a machine-readable format. Data from different information stores as well as the corresponding metadata is combined by specifying a XSL transformation to combine and format the data  Data Adapter RDF/XML Meta Store Metadata Data XSL Transformation RDF/XML from further Information Store Linked Data  Figure 13  WebComposition/DGS linked data  For instance, we can use the contact details out of our information store for people seen before, add metadata such as geospatial information and combine this information with project and publication data stored, to create machine-readable Friend-Of-A-Fried FOAF\iles using the RDF technology o r both  projects and publications we already use location information \(e.g. about the project or conference location\ that again can be used for creating the linked data. As there is no common security concept for REST-like architecture styles, various approaches are applied for different scenarios. In the majority of cases we will see the usage of HTTPS using SSL encryption for point-to-point encryption and authentication. The Backpack AP te n d s t h is b y s e n d ing a 40b y t e  SHA1 hash token along with the request content to authenticate the user. The Amazon o  uses a standard challenge-response approach by sending a token, the so-called AWS Access Key ID along with the HTTP-request as a supplementary HTTP-header. In addition, a signature in the form of a HMAC-SHA1 e n is created an d i n cl u d ed to  ensure authentication of the request. Both, the AWS Access Key ID as well as the signature are also used for SOAP-based invocation of the service Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 


Image from Information Store Images Contact from Information Store People FOAF File generated Project data from Information Store Projects  Figure 14  Example for creating linked data  4.5  Reuse with Security for REST and SOA  As you learned, reuse is the central idea within the WebComposition approach. Therefore, we enable another WebComposition component, the Identity Federation System \(idFS\as an optional security component along with the WebComposition/DGS. The idFS provides a well proved security infrastructure based on the active and passive requestor profiles of the WS-Federation specification h e idFS provides mechanisms to access Web services and resources through security token service access control and identity providers, single sign on and federating components, i.e. accessing resources across organizational boundaries [26, 27, 28   The idFS system is based on a role based system where permissions and restrictions are based on a fine grained security system. While idFS follows the WSFederation specification and thus can be applied immediately to SOA-based scenarios, we use SSL encryption for REST-like architecture styles using the HTTP protocol. The idFS allows us to define groups and to issue tokens for special purposes. This includes for instance granting rights to certain resources, rights for a certain time or rights for a certain number of actions. Issued tokens describe the roles a user is member of. For the WebComposition/DGS we specify the rights following a bottom-up approach. Rights are defined for any anonymous request first, which means when a request does not contain any tokens at all. In the following, we define additional users and roles to grant specific rights on resources. Hence, you can, for example, hand out trial access \(such as access limited in time or number of read/write requests\he important point here is to realize the idFS as an optional component. If not required, the WebComposition/DGS can be used without any security concepts at all. If required, the idFS can be deployed and configured afterwards. This can also happen during the evolution of the system as it was required within our initial example in Section 2.1 where Clark s had to implement user access The idFS is currently deployed and actively used on various sites such as the IT-Management and Web Engineering Research Group s s e Web Engineering community w e ll a s the  portal of the International Society for Web Engineering 31  Reso u r ces o f f e red b y W e b C o m p o s itio n  DG S  instances deployed within further organizations thus be made accessible to the sites already supporting idFS in a very convenient way, without the need of creating and managing additional user profiles or logins This introduced concept allows us to use one WebComposition/DGS instance in both SOA-based scenarios as well as in Web 2.0 scenarios based on a REST-like architecture styles. Access to the data is thus not restricted due to any architectural decisions  5  Related Work  Several commercial approaches currently become noticeable to deal with the new requirement of creating, storing and publishing large amounts of data The Amazon d th e Am azon Si m p leDB   pr ov ide f u n c tion a l i t y to s t ore, pr oces s an d qu er y  data over the Web. The services provide the basic functionality of databases. Both services provide SOAP and HTTP interfaces for service-oriented and REST-like architecture styles. While designed for relatively small amounts of data, the SimpleDB is also publicized as storage for metadata for a corresponding Amazon S3. While the WebComposition/DGS is designed as a Web component, the Amazon S3 as well as the SimpleDB are hosted exclusively by the corresponding provider while the service itself is sold In contrast, Microsoft s ADO.NET Data Services  is an ex tens ion to Micros of t s .NET Framework and can be understood as additive component to the NET Framework. The ADO.NET Data Services include a set of patterns to interact with data by using HTTP, addressing resources and linking data among services. This approach lines up well with the RESTlike architectural style. In addition, the ADO.NET Data Services also provides a RPC-like interface. Being one of the approaches, which meets the requirement of a REST-like architecture style as defined in e m o s t   the ADO.NET Data Services are on the other hand especially designed to connect to Microsoft s SQL Server and are thus bound to a single data provider Backpack o prov ides  bas i c fun ction a lit y t o  store and maintain data in the form of lists such as notes, images and files on the Web with a strong focus on visual representation. A HTTP-based interface is complemented by a set of wrappers for multiple Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 


programming languages to access the service. Similar to Amazon s approach, Backpack is merely offered as a commercial service. It is also not designed to support SOA-based scenarios as the WebComposition/DGS does The WebComposition Service Linking System CRUDS serv a g e n e ric, SO A P b as ed   service to store, manipulate and publish data. As a predecessor of the WebComposition/DGS, many ideas influenced the design of this component. However, the CRUDS service does not provide the flexibility of the WebComposition/DGS and is a purely SOAP-based Web service Menagerie a relati v e l y  y o un g s o f t w a re  framework targeting similar issues as the WebComposition/DGS, such as combining data scattered across multiple data providers in the Web and manipulating this data with standard applications.  In contrast, this approach focuses on personal data specifying the Menagerie Service Interface and the Menagerie File System.  The WebComposition/DGS however also targets business-scale scenarios and provides a higher flexibility. As such, the support of idFS as security infrastructure component for the WebComposition/DGS is optional. The WebComposition approach does not restrict the system to any of its components. Google s OpenSo focuses especially on social network data and defines an API that allows any social network platform to host third party social applications. Also, the Goolge Data AP def i n e s a m o re g e n e ral approach by prov iding a set of simple APIs for reading and manipulating data on the Web While some of the features of the WebComposition/DGS are closely related to the previously mentioned systems, it is unique with its combination of implicit usage of metadata extensibility through its component based approach and transparent usage within different architectural styles suitable for both, REST-like architecture style based systems in the context of Web 2.0 and SOAbased business scenarios 9. Summary and Outlook  In this paper, we presented the WebComposition Data Grid Service \(WebCompostion/DGS\ the first component of the 4 th generation of the WebComposition approach. The data dispersion within the Web, e.g. seen when personal data is used to create ones digital identity, introduces new issues in maintaining and meaningfully linking data on the Web The WebComposition/DGS addresses these issues with the consequent application of Web technologies, WS specifications, standards from the semantic Web and a design that provides a high flexibility in terms of reuse extensibility and customization. The WebComposition/DGS appears to be a component suitable for REST-like architecture and SOA stylebased systems and even allows integrating systems of different architecture styles. We showed the Web component-based approach based on the Identity Federation System \(idFS\ that provides a wellestablished security infrastructure component for the WebComposition approach Beside using the WebComposition/DGS as central component of the Distributed and Self-organizing Systems Group at Chemnitz University of Technology s Web application, the component is recently applied in multiple research project. Among others we are currently working on additional data adapters for common data types, an information flow system, based on the WebComposition/DGS and the integration of additional security infrastructure components The WebComposition components, demos and additional documentation are accessible through http://www.WebComposition.net/DGS and http://www.WebComposition.net/idFS         10. References  1 T  O  Re il ly  W e b 2 0 Co m p ac t D e f i nit i o n  T r y i ng A g ain   http://radar.oreilly.com/2006/12/web-20-compact-definitiontryi.html 05-29-2006 2 L  B a s s  P  C l em en t s an d R K a zm a n  S o f t w a r e  A r c h i t e c t u r e in  Practice. Boston, San Francisco, New York: Addison-Wesley 2003    3 H  W G e l l e r s e n, R W icke   an d M. G a e dke  WebComposition: An Object-Oriented Support System for the Web Engineering Lifecycle  6 th International World Wide Web Conference  Santa Clara, CA, USA, 1997, pp. 1429-1437 4 Y  D e s h pa nde  S   M u r u g e s a n  A  G i nig e S  H a ns e n  S   Schwabe, M. Gaedke, and B. White, "Web Engineering", Journal of Web Engineering  vol. 1, pp. 3-17, 2002  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 


5 M  G a e dke  M. N u s s ba um e r a n d E. T o nk in  W e b Co m p o s i tio n  Service Linking System: Supporting development, federation and evolution of service-oriented Web applications  3 rd Int. Workshop on Web-oriented Software Technology \(IWWOST 2003\, 2003 6 I T M a n a g em en t an d W e b E n gin eeri n g R e s e a r ch G r ou p  MWRG\, "WebComposition Service Linking System http://mwrg.tm.uni-karlsruhe.de/wsls 02-10-2008 7 R F i e l ding  A r c hi te ct ur al S t y l e s  an d the D e s i g n o f N e tw o r kbased Software Architectures", University of California, Irvine 2000 8 L  Ric h ar d s o n  an d S  R u by RES T f u l W e b S e r v ice s  O  Re il ly  2007 9 A  H e il and M  G a e dke  W e b Co m p o s it io n  D G S  S uppo r t ing  Web2.0 Developments With Data Grids  IEEE International Conference on Web Services \(ICWS 2008  Beijing, China, 2008   C   M  M a c K en zi e K   L a s k e y  F   M c C a b e  and R  M e t z   Reference Model for Service Oriented Architecture 1.0 http://www.oasis-open.org/committees/soa-rm   T  B e r n er s Lee Un i v er s a l R e s o u r c e  I d en t i f i e r s in W W W    http://www.ietf.org/rfc/rfc1630.txt 11-24-2007-2007  T  B e r n er s Lee M et a d at a A r c h it ec t u r e   http://www.w3.org/DesignIssues/Metadata.html 05-31-2008 13 J a p a n El e c tr o n i c s  an d I n f o r m atio n T e chno l o g y  I ndus tr ie s  Association, "Exchangeable image file format for digital still cameras: Exif Version 2.2", 2002 14 L  A ndr e s e n  D ubl i n  Co r e Me ta da ta El e m e n t S e t, V e r s io n 1.1: Reference Description http://dublincore.org/documents/dces  02-18-2008 15 H  K i l o v  F r o m s e m a ntic to O b j e cto r ie nte d D a ta Mo de l i ng    First international Conference on Systems Integration  Morristown NJ, USA, 1990, pp. 385-393 16 J  F u tr e l l e  H a r v e s ting RD F T r ipl e s    International Provenance and Annotation Workshop \(IPAW'06  Chicago, Il USA, 2006, pp. 64-72  V. T a n  P G r ot h  S   M i les  S  J i an g S. Mun r oe S T s a s ak ou  and L. Moreau, "Security Issues in a SOA-based Provenance System  International Provenance and Annotation Workshop IPAW'06  Chicago, Il, USA, 2006, pp. 203-21 18 J  G r e g o r io M. H a dl e y M. N o tt i n g h a m  an d D  O r c h ar d   URI Template http://tools.ietf.org/id/draft-gregorio-uritemplate03.txt 02-06-2008  T  B e r n er s Lee  L i n k e d Da ta   http://www.w3.org/DesignIssues/LinkedData.html 02-20-2008 20 D  Br ic kl ey and L  Mil l e r  F OA F V o cabul ar y S p e c if ic at io n 0.9 http://xmlns.com/foaf/spec/20070524.html 06-03-2008   37 s i gna ls L L C  B a c kp ac k    http://www.backpackit.com 0219-2008  A m a z on W e b Servi c e s  L L C   A m a zon Si m p le St ora ge Service Developer Guide http://docs.amazonwebservices.com/AmazonS3/2006-03-01 0603-2008  F  Sha n ah an  A m a z on  c om  M a s h u p s   B i rm in gha m  UK  W r o x  Press Ltd., 2007 24 H  K r aw c z y k M  Be l l a r e an d R Ca ne tt i H MA C K e y e dHashing for Message Authentication http://www.ietf.org/rfc/rfc2104.txt 06-03-2008 25 H  L o ckhar t  S  A n de r s e n S  J  B o hr e n Y  S v e r dl o v  M  Hondo, H. Maruyama, A. Nadalin, N. Nagaratnam, T. Boubez, K S. Morrison, C. Kaler, A. Nanda, D. Schmidt, D. Walters, H Wilson, L. Burch, D. Earl, S. Baja, and H. Prafullchandra, "Web Services Federation Language \(WS-Federation\", 2006 26 M  G a e dke  J  Me i n e c ke an d M N u s s b au m e r    A  Mo de l i ng  Approach to Federated Identity and Access Management  14 th  International World Wide Web Conference \(WWW'05  Chiba Japan, 2005, pp. 1156-1157 27 J   Me ine c ke a n d M  G a e dke  M o de l i ng F e de r a tio ns o f W e b Applications with WAM  Third Latin American Web Congress LA-WEB 2005  Buenos Aires, Argentina, 2005, pp. 23-31  J  M e i n eck e  M  N u s s b au m e r and  M  G a ed k e   B ui ldi n g Blocks for Identity Federations  Fifth International Conference on Web Engineering \(ICWE 2005  Sydney, Australia, 2005, pp. 203208 29 I T M anag e m e n t an d W e b E n g i ne e r ing Re se ar ch G r o up MWRG\, "Home of the IT-Management and Web Engineering Research Group http://mwrg.tm.uni-karlsruhe.de 03-06-2008  w e b e n g i n eeri n g org T h e W e b E n gi n e eri n g C o m m u n i t y Si t e  WebEngineering.org http://www.webengineering.org 06-032008  I n t e rn a t i o n a l Soc i et y for Web E ngi n eeri n g e V  I S W E    International Societe for Web Engineering e.V http://www.isweev.de 06-03-2008  A m a z on W e b Servi c e s  L L C   A m a zon Si m p leDB Deve lop e r Guide", 2008 33 P  C a str o  P r o je ct A s to r i a T h e  A r chite ct ur e Jo ur nal  pp. 1217, 2007 34  M N u s s ba um e r  E ntw i c k l ung  u n d E v o l utio n diensteorientierter Anwendungen im Web Engineering Universität Karlsruhe \(TH\, Karlsruhe, 2007 35  R. G e am bas u  C  C h e u ng A  Mo s h c h u k  S  D  G r ibbl e  a n d H. M. Levy, "Organizing and Sharing Distributed Personal WebService Data  15 th International World Wide Web Conference WWW 2008  Bejing, China, 2008, pp. 755-754  G oogl e I n c   Op en Soc i a l   http://code.google.com/apis/opensocial 06-03-2008  G oogl e I n c   Goog le Da t a A P I s    http://code.google.com/apis/gdata 02-17-2008  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


transform spectrometry,\224 A pplied Optics  vol 46 no 21 pp 4774\2264779 2007 B IOGRAPHY Dmitriy Bekker r eceived his M.S and B.S degrees in Computer Engineering from Rochester Institute of Technology in 2007 He has been at JPL as a summer student in 2006 and now is a full time employee since February 2008 in the Instrument Software and Science Data Systems section His areas of interest include FPGAs embedded systems digital signal processing and system architecture He has co-op and work experience at Draper Laboratory NASA Dryden Flight Research Center Syracuse Research Corporation and Brookhaven National Laboratory He is a member of IEEE Dr Jean-Francois Blavier 002 rst joined the JPL-MkIV Team in August 1985 as a contractor from Ball Aerospace He participated in the MkIV campaigns in McMurdo Antarctica ground-based and from Punta Arenas Chile NASA DC8 In late 1987 he started graduate work with Profs Delbouille and Dubois at the University of Li 036 ege Belgium His research tasks included installing the Fourier transform spectrometers at the International Scienti\002c Station of the Jungfraujoch Switzerland for atmospheric measurements and at the Institute of Astrophysics in Li 036 ege for laboratory measurements He was hired by JPL in August 1990 as MkIV cognizant engineer and participated in all the MkIV campaigns since then one DC-8 campaign 20 balloon campaigns Dr J.-F Blavier obtained his Ph.D in Physics from the University of Li 036 ege in July 1998 Dr Geoffrey Toon  after receiving his B.A degree in Physics at Oxford University in 1978 obtained a D Phil in Atmospheric Physics in 1984 also from Oxford University He then came to JPL as an NRC post-doctoral Researcher and worked on the assembly and testing of the JPL MkIV interferometer and on analysis of ATMOS Spacelab-3 data Since becoming a JPL employee in 1986 he has worked almost exclusively on the MkIV project becoming the Principal Investigator in 1988 This work has earned seven NASA Achievement Awards and has resulted in more than 100 peer-reviewed journal articles Dr Christian Servais 002 rst joined the Institute of Astrophysics at the University of Li 036 ege in 1982 designing a digital 002lter for a prototype Fourier transform infrared spectrometer installed at the high altitude international scienti\002c station of the Jungfraujoch Switzerland In April 1984 he moved to the chemistry department of the University of Li 036 ege and developed time-of-\003ight and Photoion-Photoelectron coincidence experiments for his PhD thesis that he obtained in September 1994 He then returned to the Institute of Astrophysics were he has been since overseeing all experimental developments at the Laboratory of Atmospheric and Solar Physics located at the Jungfraujoch He is now specially involved in the design of improved Fourier transform spectrometer acquisition chains and remotely controlled hardware adapted to harsh environmental conditions 11 


departments on average\ignificant differences were found regarding the age of the applications. The variables for the coverage of the products and processes were not included in this test because the overlap was computed using these two variables implying that there is a significant relation between the respective variables\his lends some support to proposition P2.4 stating that involvement of more users leads to greater overlap of applications. The proposition that older applications also exhibit a higher degree of overlap was not supported \(P1.4  A.2. Results from analyzing impacts of AA complexity  Impacts of interdependency-related AA complexity A Kruskal-Wallis test \(Table 4\ealed a statistically significant difference in operations cost as well as maintenance cost across the three different interdependency-groups of applications. The more interdependent group \(i.e. applications with 3-7 or with 8 or more interfaces\igher median of operations \(Md=119,000 and 363,000 EUR respectively\ and maintenance costs \(Md=326,000 and 506,000 EUR respectively\ than the less interdependent group \(fewer than 3 interfaces applications \(Md=52,000 EUR operations costs and 64,000 EUR maintenance costs\. This supports the proposition \(P3.1\ that more interdependent applications also incur higher IT \(operations and maintenance\ts  Impacts of diversity-related AA complexity   Regarding OS-related diversity, a Mann-Whitney U test \(Table 5\howed no significant difference between the operations costs of more \(Md=93,890 n=105\d less diverse applications \(Md=131,540 n=27\09.5, z=-1.174, p=.24. The same holds for maintenance costs \(Md=166,400; n=121 vs Md=116,900; n =31\782, z=-.43; p=.668 To measure DBMS-related diversity, a MannWhitney U test was conducted \(Table 5\d revealed no significance difference in operations costs of more Md=129,985; n=85\d less diverse applications Md=154,777; n=16\5, z=-.237, p=.813. The same holds for maintenance costs \(Md=210,500 n=98 vs. Md=245,700; n=19\36, z=-.704 p=.481. Hence, the proposition \(P3.2\ that diversityrelated AA complexity leads to higher IT costs is not supported  Impacts of deviation-related AA complexity   Regarding deviation from the standard OS, a MannWhitney U test \(Table 6\revealed no significant difference between the maintenance costs and operations costs for standard-compliant \(Md=83,581 n=94 for operations cost and Md=148,300; n=113 for maintenance cost\nd non-compliant applications Md=180,147; n=38 for operations cost and Md=166,400; n=39 for maintenance cost z=-1.921, p=.055 for operations cost and U=2116 z=-.371, p=.711 for maintenance cost Concerning deviation from the standard DBMS, a Mann-Whitney U test \(Table 6\ealed a significant difference between maintenance costs for standardcompliant \(Md=373,100; n=59\d non-standardcompliant applications \(Md=170,200; n=58 U=1303, z=-2.231, p=.026. It is remarkable that the non-compliant applications had lower maintenance costs than the compliant applications. The difference between operations costs for compliant Md=109,978; n=51\d non-compliant applications Md=180,147; n=50\s not significant, U=1196.5 z=-.533, p=.594 Thus, the proposition \(P3.3\at application that deviate from technology standards incur higher IT costs is not supported. In contrast, for DBMSstandard deviation, we observed significantly lower maintenance cost for non-compliant than for compliant applications  Impacts of overlap/redundancy-related AA complexity a Kruskal-Wallis test \(Table 7\ showed significant differences in operations costs across the applications with a low \(less than 34 overlaps Md=90,442; n=37\edium \(35-79 overlaps Md=55,770; n=56\ and high level of overlap/redundancy \(more than 80 overlaps Md=129,985; n=61 6.862, p=.032. It is striking to see that the applications with medium overlaps have a lower median operations cost than those with a low or high-level of overlap, implying a non-linear U-shape relation between overlap and operations cost. Interestingly, the same holds true for maintenance cost. Applications with a low degree of overlap exhibited a median maintenance cost of 96,600 \(n=59\, those with a medium level of overlap incurred a median of 81,300 \(n=58\d highly overlapping applications a median of 248,700 \(n=67 9.791, p=.007. Hence, the proposition \(P3.4\at applications with a greater degree of overlap also exhibit higher IT costs is not supported  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 12 


Interdependency Number of interfaces \(gp3_y4_sum_intf  2 22 2 22 Df 047 000 000 016 000 000 Asymp. Sig 6.134 22.298 20.875 8.331 17.018 18.917 N Median 46 45 43 46 27 37 41 41 41 41 36 38 2 intf 8 intf 1.0000 2.2000 1.0000 1.0000 52.3020 64.4000 2.0000 7.8000 4.0000 2.0000 363.9885 506.3500 2 intf 8 intf Mean rank 55.89 47.03 44.13 56.13 33.67 37.77 2 intf 73.46 83.40 76.61 76.21 60.89 68.89 8 intf 40 39 33 40 30 34 3 7 intf 1.0000 3.2000 2.0000 1.0000 119.3940 326.2000 3 7 intf 63.63 59.97 56.50 60.54 42.33 58.22 3 7 intf  Business requirements Causes of complexity Impacts of complexity  No. of IB products covered y24_#_IB_ bankprod Application age y14_age No. of user departments y19_#_ user_dpts No. of IB process covered \(y26_ IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost 2  Table 4: Results of Kruskal-Wallis test for causes and impacts of interdependency-related AA complexity    Diversity Number of OS/DBMS used by an application Operating systems \(gp2_y7a_OS DBMS \(gp2_y8a_DBMS 2,726.500 18,302.500 1.503 133 1,087.500 1,318.500 1.362 173 3,308.000 902 367 543.000 7,446.000 3.925 000 2,642.000 2,536.000 3,202.000 855 392 757.500 7,198.500 2.187 029 2,884.500 18,460.500 965 335 1,216.500 1,447.500 583 560 1,209.500 6,774.500 1,174 240 654.500 790.500 237 813 1,782.000 9,163.000 430 668 836.000 5,687.000 704 481 Wilcoxon W Z Asymp. Sig N Median Mean rank Mann-Whitney U Wilcoxon W Z Asymp. Sig Mann-Whitney U 21 1.0000 125 1.0000 75.30 62.79 20 8.0500 117 2.2000 63.64 100.35 19 3.0000 113 1.0000 63.70 83.13 21 1.0000 125 1.0000 74.27 68.93 16 154.7770 85 129.9850 51.30 49.41 19 245.7000 98 210.5000 58.03 64.00 N Median 1 DBMS 2 DBMS 1 DBMS 2 DBMS Mean rank 1 DBMS 2 DBMS Data not shown as no significance found  Business requirements Causes of complexity Impacts of complexity  No. of IB products covered \(y24_#_ IB_bankprod Application age y14_age No. of user departments y19_#_user_dpts No. of IB process covered \(y26_#_ IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost  Table 5: Results of Mann-Whitney test for causes and impacts of diversity-related AA complexity  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 13 


 Deviation degree of deviation from standard OS/DBMS Operating systems \(gp2_y7b_OS_Dev DBMS \(gp2_y8b_DBMS_Dev 2,780.000 16,146.000 3.681 000 163 49 1.0000 2.0000 99.06 131.27 2,611.000 5,312.000 227 820 73 1.0000 73 1.0000 72.77 74.23 3,970.500 2.107 035 151 47 3.2000 2.2000 104.18 84.48 2,102.000 4,587.000 1.074 283 70 2.2000 67 3.5000 72.63 2,842.500 65.53 2,902.000 4,030.000 1.509 131 143 47 2.0000 1.0000 98.71 85.74 1,551.500 3,829.500 3.041 002 67 1.0000 65 3.0000 76.13 57.16 3,103.500 16,469.500 2.698 007 163 49 1.0000 2.0000 101.04 124.66 2,610.000 5,311.000 232 816 73 1.0000 73 1.0000 72.75 74.25 1,404.000 5,869.000 1.921 055 94 38 83.5815 180.1470 62.44 76.55 1,196.500 2,522.500 533 594 50 180.1470 51 109.9780 49.46 52.57 2,116.000 8,557.000 371 711 113 39 148.3000 166.4000 75.73 78.74 1,303.000 3,014.000 2.231 026 58 170.2000 59 373.1000 65.92 51.97  Wilcoxon W Z Asymp. Sig N Median No deviation \(1.0 Deviation 1.1 No deviation \(1.0 Deviation 1.1 Mean rank Mann-Whitney U No deviation \(1.0 Deviation 1.1 Wilcoxon W Z Asymp. Sig N Median No deviation \(1.0 Deviation \(>1.0 No deviation \(1.0 Deviation \(>1.0 Mean rank Mann-Whitney U No deviation \(1.0 Deviation \(>1.0  Business requirements Causes of complexity Impacts of complexity  No. of IB products covered \(y24_#_ IB_bankprod Application age y14_age No. of user departments y19_#_user_dpts No. of IB process covered \(y26_#_ IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost  Table 6: Results of Mann-Whitney test for cause s and impacts of deviation-related AA complexity  Overlap/redundancy \(gp3_overlap_count 22 22 Df 216 001 032 007 Asymp. Sig 3.066 13.139 6.862 9.791 2 N Median 90 81 37 59 79 78 61 67 34 80 2.2000 1.0000 90.4420 96.6000 2.6000 2.5000 129.9850 248.7000 34 80 Mean rank 129.29 113.80 82.76 87.25 34 137.18 144.50 85.66 108.10 80 86 85 56 58 35 79 2.2000 1.0000 55.7705 81.3000 35 79 118.22 110.61 65.14 79.82 35 79  Not applicable Not applicable Business requirements Causes of complexity Impacts of complexity  No. of IB products covered \(y24_ _IB_bankprod Application age y14_age No. of user departments y19_#_ user_dpts No. of IB process covered \(y26_ _IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost  Table 7: Results of Kruskal-Wallis test for causes and impacts of overlap-/redundancy-related AA complexity Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 14 


  15 R EFERENCES    http://www.w3.org/XML/Schema   eb Orchestration with BPEL\224 http://www.idealliance.org/pa pers/dx_xml03 papers/0406-01/04-06-01.html  Hi bernat e hom e page www.hibernate.org   Al l a rd, Dan and Hut c herson, Joe, \223C om m uni cat i ons Across Complex Space Networks\224, IEEE Aerospace Conference, March 1-8, 2008  W e b Servi ce Defi ni t i on Language http://www.w3.org/TR/wsdl   B a uer, C h ri st i a n and Ki ng Javi n Java Persi s t e nce for Hibernate, New York: Manning Publications, 2007 7] \223Software Agents An Overview\224 http://www.sce.carleton.ca/netm anage/docs/AgentsOverview ao.html  e thodology.org  http://www.riaspot.com artic les/entry/What-is-Ajax  http://www.json.org 11 h ttp to m cat.ap ach e.o r g   12] http://java.sun com/products/servlet  http://www.w3.org/Sty le/CSS    B IOGRAPHY  Dan Allard has worked as a software engineer at the Jet Propulsion Laboratory for the past 17 years.   He currently leads the development of core JPL accountability systems applications and infrastructure Other recent work includes the development of a message-based ground data system for the Mars Science Laboratory as well as research and development of ontologybased distributed communications     Dr. Charles D \(Chad\ards, Jr received his A.B degree in Physics from Princeton University in 1979 and his Ph.D. in Physics from the Calif ornia Institute of Technology in 1984.  Since then he has worked at NASA\222s Jet Propulsion Laboratory, where he currently serves as Manager of the Mars Network Office and as Chief Telecommunications Engineer for the Mars Exploration Program, leading the development of a dedicated orbiting infrastructure at Mars providing essential telecommunications and navi gation capabilities in support of Mars exploration.  Prior to that he managed the Telecommunications and Mission Operations Technology Office, overseeing a broad program of research and technology development in support of NASA\222s unique capabilities in deep space communications and mission operations.  Earlier in his career, Dr. Edwards worked in the Tracking Systems and Applications section at JPL where he carried out research on novel new radio tracking techniques in support of deep space navigation, planetary science, and radio astronomy  


  16  


Thank you Questions 


 18  Astronautical Congress Valencia, 2006 27  Bu reau  In tern atio n a l d e s Po ids et Mesures. \(2 008  August\SI Base Units. [On http://www.bipm.org/en/si/base_units   B IOGRAPHY  Author, Karl Strauss, has been employed by the Jet Propulsion Laboratory for over 22 years.  He has been in the Avionics Section from day One.  He is considered JPL\222s memory technology expert with projects ranging from hand-woven core memory \(for another employer\o high capacity solid state designs.  He managed the development of NASA\222s first Solid State Recorder, a DRAM-based 2 Gb design currently in use by the Cassini mission to Satu rn and the Chandra X-Ray observatory in Earth Orbit.  Karl was the founder, and seven-time chair of the IEEE NonVolatile Memory Technology Symposium, NVMTS, deciding that the various symposia conducted until then were too focused on one technology.  Karl is a Senior IEEE member and is active in the Nuclear and Plasma Scie nce Society, the Electron Device Society and the Aerospace Electronic Systems Society Karl is also an active member of SAE Karl thanks his wonderful wife of 28 years, Janet, for raising a spectacular family: three sons, Justin, Jeremy Jonathan.  Karl\222s passion is trains and is developing a model railroad based upon a four-day rail journey across Australia\222s Northern Outback   


 19 Bollobás, B. 2001. Random Graphs. Cambridge University Press; 2nd edition. 500pp  Cawley, G. C., B. L. C. Talbot, G. J. Janacek, and M. W Peck. 2006. Sparse Bayesian Ke rnel Survival Analysis for Modeling the Growth Domain of Microbial Pathogens  Chiang C. L. 1960. A stochastic study of life tables and its applications: I. Probability distribution of the biometric functions. Biometrics, 16:618-635  Cox,  D. R. 1972. Regression models and life tables J. R Stat. Soc. Ser. B 34:184-220  Cox, D. R. 1975.   Partial likelihood Biometrika 62:269276  Cox, D. R. & D. Oakes. 1984 Analysis of Survival Data  Chapman & Hall. London  Cressie, N. A. 1993 Statistics for Spatial Data John Wiley Sons. 900pp  Duchesne, T. 2005. Regression models for reliability given the usage accumulation history. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty Y. Armijo. pp.29-40. World Scientific, New Jersey  Eleuteri, A., R. Tagliaferri, L. Milano, G. Sansone, D D'Agostino, S. De Placido,  M. Laurentiis. 2003.  Survival analysis and neural networks. Proceedings of the International Joint Conference on Neural Networks, Vol. 4 20-24 July 2003 Page\(s\:2631 - 2636  Ellison, E., L. Linger, and M Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013, 1997  Fleming, T. R. & D. P. Harrington. 1991. Counting process and survival analysis. John Wiley & Sons. 429pp  Graver, J. and M. Sobel 2005. You may rely on the Reliability Polynomial for much more than you might think Communications in Statistics: Theory and Methods  34\(6\1411-1422  Graves, T. and M. Hamada. 2005. Bayesian methods for assessing system reliability: models and computation. In Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson, et al. pp.41-53  Grimmett, G. 2006 The Random-Cluster Model Springer  Grimmett, G. 1999 Percolation Springer  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis.  Springer. 481pp  Jin Z. 2005. Non-proportional semi-parametric regression models for censored data. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.279-292 World Scientific  Kalbfleisch, J. D. & R. L. Prentice. 1980 The Statistical Analysis of Failure Time Data John Wiley & Sons.  New York. 1980  Kalbfleisch, J. D. &  R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data.  Wiley-InterScience, 2nd ed 462pp  Lisboa, P. J. G. and H. Wong. 2001. Are neural networks best used to help logistic regression? Proceedings of International Joint Conference on Neural Networks, IJCNN 01. Volume 4, 15-19,  July 2001. Page\(s\:2472 - 2477 vol.4  Kauffman, R. J. and B. Wang. 2002. Duration in the Digital Economy. Proceedings of th e 36th Hawaii International Conference on System Sciences \(HICSS03\ Jan 2003  Kaplan, E. L. & P.  Meier.  1958.  Nonparametric estimation from incomplete observations J. Amer. Statist. Assoc  53:457-481  Klein, J. P. and P. K. Goel 1992. Survival Analysis: State of the Art.  Kluwer Academic Publishes. 450pp  Klein, J. P. and  M. L Moeschberger. 20 03. Survival analysis techniques for ce nsored and truncated data Springer  Krings, A. and Z. S. Ma. 2006.  "Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks MILCOM 2006, Military Communications Conference, 2325 October, 7 pages, 2006  Krings, A. W. 2008.  Survivable Systems.  in Information Assurance: Dependability and Security in Networked Systems Yi Qian, James Joshi, David Tipper, and Prashant Krishnamurthy, Morgan Kaufmann Publishers. \(in press  Lawless, J. F. 1982. Statistical models and methods for lifetime data.  John Wiley & Sons. 579pp  Lawless, J. F. 2003. Statistical models and methods for lifetime data.  John Wiley & Sons. 2nd ed. 630pp  Li, M. and P. Vitanyi. 1997. Introduction to  Kolmogorov Complexity and Its Applications. 2nd ed, Springer  Ma, Z. S. 1997.  Survival analysis and demography of Russian wheat aphid populations.  Ph.D dissertation, 307pp University of Idaho Moscow, Idaho, USA 


 20 Ma, Z. S., and E. J. Bechinski. 2008.  Developmental and Phenological Modeling of Russian Wheat Aphid Annals of Entomological Soc. Am In press  Ma, Z. S. and A. W. Krings. 2008a. The Competing Risks Analysis Approach to Reliability Survivability, and Prognostics and Health Management.  The 2008 IEEEAIAA AeroSpace Conference. BigSky, Montana, March 18, 2008. \(In Press, in the same volume  Ma, Z. S. and A. W. Krings 2008b. Multivariate Survival Analysis \(I\e Shared Frailty Approaches to Reliability and Dependence Modeling. The 2008 IEEE-AIAA AeroSpace Conference. BigSky Montana, March 1-8, 2008 In Press, in the same volume  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(II\ Multi-State Models in Biomedicine and Engineering Reliability. 2008 IEEE International Conference on Biomedical Engineering and Informatics BMEI 2008\27th-30th, 2008 Accepted   Mani, R., J. Drew, A. Betz, P. Datta. 1999. Statistics and Data Mining Techniques for Lifetime Value Modeling ACM Conf. on Knowledge Discovery and Data Mining  Mazzuchi, T. A., R Soyer., and R. V Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Meeker, W. Q. and L. A. Escobar. 1998. Statistical Methods for Reliability Data. Wiley-Interscience  Munson, J. C. 2003. Software Engineering Measurement Auerbach Publications  Nelson, W. 1969. Hazard plotting for incomplete failure data J. Qual. Tech 1:27-52  Nakagawa, T. 2006.  Shock and Damage Models in Reliability Theory. Springer  Osborn, B. 2005. Leveraging remote diagnostics data for predictive maintenance.   In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp. 353-363  Pena, E. A. and E. H. Slate. 2005. Dynamic modeling in reliability and survival analysis. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.55-71  Reineke, D. M., E. A. Pohl, and W. P. Murdock. 1998 Survival analysis and maintenance policies for a series system, with highly censore d data.  1998 Proceedings Annual Reliability and Maintainability Symposium. pp 182-188  Schabenberger, O. and C. A. Gotway. 2005. Statistical Methods for Spatial Data Analysis.  Chapman & Hall/CRC  Severini, T. A. 2000. Likelihood methods in statistics Oxford University Press  Shooman, M. L. 2002. Reliability of Computer Systems and Networks: Fault Tolerance, Analysis and Design. John Wiley and Sons. 551pp  Stillman, R. H. and M. S. Mack isack, B. Sharp, and C. Lee 1995. Case studies in survival analysis of overhead line components. IEE Conferen ce of the Reliability and Distribution Equipment. March 29-31, 1995. Conference Publication No. 406. pp210-215  Therneau, T. and P. Grambsch. 2000 Modeling Survival Data: Extending the Cox Model Springer  Wilson, A.  N. Limnios, S Kelly-McNulty, Y. Armijo 2005. Modern Statistical and Mathematical Methods in Reliability. World Scientific, New Jersey  Xie, M. 1991. Software Reliability Modeling. World Scientific Press    B IOGRAPHY   Zhanshan \(Sam\ Ma holds a Ph.D. in Entomology and is a Ph.D. candidate in Computer Science at the University of Idaho. He has published approximately 30 journal and 30 conference papers, mainly in the former field.  Prior to his recent return to academia, he worked as senior network/software engineers in software industry.  His current research interests include reliability and survivability of wireless sensor networks, fault tolerance survival analysis, evolutionary game theory, evolutionary computation and bioinformatics  Axel W. Krings is a professor of Computer Science at the University of Idaho.  He received his Ph.D. \(1993\ and M.S 1991\ degrees in Computer Science from the University of Nebraska - Lincoln, and his M.S. \(1982\ in Electrical Engineering from the FH-Aachen, Germany.  Dr. Krings has published extensively in the area of Computer Network Survivability, Security, Fault-Tolerance and Realtime Scheduling. In 2004/2005 he was a visiting professor at the Institut d'Informatique et Mathématiques Appliquées de Grenoble, at the Institut National Polytechnique de Grenoble, France.  His work has been funded by DoE/INL DoT/NIATT, DoD/OST and NIST 



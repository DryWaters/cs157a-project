ProductRank: A Random Walk Model for E-Commerce Recommendations Liang Wu School of Software Engineering Beijing University of Posts and Telecommunications Beijing, China, 100876 wuliang211@gmail.com Guoshi Wu School of Software Engineering Beijing University of Posts and Telecommunications Beijing, China, 100876 buptsse.gwu@gmail.com Jing Li School of Software Engineering Beijing University of Posts and Telecommunications Beijing, China, 100876 lijing@email.buptsse.cn Xinyu Zhang School of Software Engineering Beijing University of Posts and Telecommunications Beijing, China, 100876 zxy346000837@gmail.com AbstractElectronic Commerce has offered a convenient way for people to go shopping on the Internet. However, it is difficult for Internet customers to select a valuable item from the great number of various products available on line. When we use a keyword and search in a EC website, the ranking algorithm of products is usually based on statistics or simply the shop managers preference, which does not fully exploit the knowledge and experiences hidden in the prior daily transaction records in the database. In this paper, we propose a novel approach to extract the purchasing behaviour of customers who purchase the same kind of goods, and with which we rank the products for user personally by comparing their behaviour. We introduce our 


evaluation metrics to assess the prediction accuracy of the proposed recommendation algorithm using transaction records of an online wine shop, the experiment results show that our algorithm is able to produce valuable recommendations General TermsAlgorithms, Experimentation, Performance KeywordsRecommendation, Random Walk I. INTRODUCTION The E-Commerce induced by rapid development of Internet has greatly promoted the on-line sales. With the growth of massive database of transaction records, the problem of finding hidden habits and behaviour of customers has attracted many researchers to attach increasing importance to the research and application of E-Commerce recommendation systems Recommendation systems provide advice on movies products, travel, leisure activities, and many other topics Some popular systems have achieved great triumph, such as Google News[1], Amazon[2] and movieLens[3 Currently, the E-Commerce recommendation systems mainly provide three ways to help users find products to their needs. The first one is based on semantic, which analyses customers reviews[4], or/and require customers to express their preference according to either certain system pre-defined format[5, 6] or in natural language[7]. The customers requirement may be distorted when they cannot determine the rigorous description of the goods that they need. Due to the limited nature of semantic analysis, using natural language cannot meet the needs of users fuzzy and emotional shopping psychology either. Thus, the contradiction of requirement is prominent in such systems The second approach is based on association rule mining[7 9, 10, 11, 12, 13, 14], which was first introduced by Argawal Imielinski and Swami[11, 12]. Most of these systems are goal-oriented recommendation systems, which are able to provide product-related information well, but cannot provide real-time recommendation The third way is based on Collaborative Filtering [1, 2, 6 15, 16, 17, 18]. Collaborative Filtering\(CF demonstrated to be an effective framework to generate recommendations. It identifies the potential preference of a customer for a new product based on the information collected from other consumers. The CF based recommendation system 


involves three components in general:?A method to represent user-user or product-product similarities. ?A method to combine the similarities to generate a raw map of recommendation strategies. ?A method to evaluate the recommendation strategies to adjust the system and optimize the performance However, the performance of CF based recommendation systems is still limited. The reason is that CF cannot explore transitive associations between products that have never been bought together but share the same neighbourhoods. One way to overcome the problem is to use random walk based recommendation algorithms The random walk model is closely related to Googles PageRank algorithm[19], and has been applied to the task of text summarization [20], and question-answering [21, 22 In this paper, our proposed model first fully exploit the past transaction records and extract the consumers habits of different products. Then we incorporate the information into a random walk model, i.e., a Markov chain to analyse the association of different kinds of products. The process is similar to Opinion-PageRank Model in [22 978-1-4244-7161-4/10/$26.00 2010 IEEE Finally, we compute the similarity between the users consuming habits and the purchasing feature of customers of every kind of products, by integrating the similarity with the relation between products, we calculate a score for each of the products and rank them according to the scores The remainder of the paper is organized as follows. Section 2 presents the proposed model. We will discuss our evaluation metrics and experiment results in section 3. Section 4 concludes this paper and provides possible future work II. PRODUCTRANK MODEL In order to uncover the hidden habits of customers, we first build up sets of customers by the kind of products they bought That is, given the set }{ iP bB = containing all products and the set }{viVp =  containing all the products to be recommended \( pV is a subset of pB two classes of products, the first class are products in pV these are potential products a user may want to buy and are called positive products. The rest products of pB  are used to describe the purchasing habits of positive products consumers Set iC  is the set of customers who have bought product iv 


Note that the intersection of two different sets, iC  and jC is usually not null, for a customer may buy both product iv and product jv . By adding up all prior daily transaction records of the customers in a set, we got a history vector ih ={ 1in , 2in , , ijn }for each positive product. The value of ijn  ranges from zero to any integer, which stands for the number of product j bought by customers in set iC According to the history vector, we know what and how many products the consumers of a positive product have purchased, the purchasing habits are hidden in the history vectors. Secondly, we will calculate the weight for each item of a history vector ih      1k ik ij ij w ww     \(1 ijijij idffw =?    \(2 j ij ij MaxFreq freqf =   \(3   j j N Nidf =   \(4 which is similar as \(Ribeito-Neto and Baeza-Yates, 1999 ijfreq  is the raw frequency that describes how often the product jb  is bought by customers of iC , jMaxFreq  is the maximum frequency of product jv  among all history vectors. N is the number of history vectors, i. e. , its the number of products in pV . jN  is the number of history vectors in which the jn  is bigger than the threshold, during this paper, we set the threshold to 1 for simplicity. The f factor 


provides one measure of how well that product describes the consumer behaviours of a positive product. The motivation for usage of an idf  factor is that products which appear in many history vectors but are not very useful for distinguishing a users habit. For example, the buyers of flashlight usually buy many batteries at the same time. Though the quantity sold of batteries is large, it cannot distinguish the purchasing habits of different flashlights consumers well. Without the idf factor, the flashlight will be described by the quantity sold of batteries, instead of the preference of consumers Therefore we got a weighted vector iW ={ 1iw , 2iw ijw  } for each of the products in pV , where ijw  means how strong the product jb can represents the hidden habits of customers who bought product iv 1  1j ijw  to be 1. It ensures that both popular products, the products bought more often, and the other products share the same recommendation priority. Without normalization, the popular products rank significantly higher than the rest which distorts the process of describing purchasing habits However, sometimes the popularity is an important factor a user may be interested in. So we introduce the ?  factor to adjust the model We rewrite \(1      1   k ik ij ij w ww where ?  ranges from 0 to 1. When ?  = 0, it is the same as\(1 the process of normalization is totally abandoned, the popular 


products take advantages over the others when being recommended as they have a much higher overall score than the products not being bought that often Then we introduce how to incorporate the products into the Markov Random Walk model, which is similar to the opinion PageRank model [22]. We construct a similarity graph where each node represents a product in pV . There are edges between nodes. The edge weight between product iv and jv is the normalized cosine similarity between iW  and jW we define cos\( iW ? iW  ji WWQ      1     pV k ki ji WW WW As a result of this normalization, the sum     1 1  pV j ji WWQ . If we view each product as a state in a Markov chain ji WWQ ?  is the transition probability from state i to state j in the corresponding Markov chain. The Markov random walk model can be used to describe the relations between positive products When a customer login to the website and type in a keyword to search something, we should first generate a normalized history vector ch  for it in a statistical way 


ch ={ 1n , 2n , , jn jn     1k k j n n kn?  stands for the number of product kb  bought by the user In order to incorporate the user-product\(The product here is referred to prior consumers purchasing habits of this product products for the user, we propose a ProductRank model\(Figure 1 layer contains the past purchasing information, the history vector of the user. The second layer denotes the products relations in the Markov Random Walk model discussed above We denote the user-product relation as the lines between the two layers Figure 1:ProductRank model Then we compute the score for each of the product to be recommended as follows      1       pV k kikc ici WWQWh WhScore   


Where ?  is the damping factor. It is a trade-off which controls the relative contributions from user-product relation and product-product relation III. EXPERIMENT 1 We collect all the transaction records of a wine shop in taobao. com. We choose the latest 20 transaction records to be the testing set, and the older ones to be the training set By analysing the training set we know which products were bought, who the consumers are and the prior daily records of those consumers. Applying these data to the ProductRank model, we can get the weighted vectors for each of the products of that wine shop and the Markov chain of those products We view the customers of the latest 20 transaction records as new customers. We collect all the past transaction records of them, and delete the items that were bought in this wine shop. Thus we can compute the hc  vector for these new customers. By applying the ProductRank model with the weighted vectors, Markov chain and the hc , we can calculate a score for each of the products of this shop, and get a list of products and their corresponding scores 2 As most online shops will provide no less than 20 products in the first result page when a user search for some item using keywords, we explicitly list the top 20 high-scored products and their corresponding scores We introduce the Prediction Accuracy\(PA performance of the ProductRank model. We compute the PA as follows If some a product bought by the customer\(it is the product bought in this wine shop, which is the same product deleted from the history vector accuracy is 0 Instead, if the product bought by this user is in the top 20 list, the prediction accuracy of the model is calculated as follows PA = 100 MaxScore ScoreHit  Where ScoreHit is the score of the product bought by the 


customer and MaxScore is the score of the top ranked product We compute the PA of those twenty new customers with varying ? \(0, 0.2, 0.5, 0.8 and 1 value of PA respectively Note that we set the ?  factor to be 0 in this paper, as we are only concerned about how accurately the ProductRank model can predict which items a new customer will buy While the performance of a recommendation system is usually measured by how much it can improve the sales, the end user of the system, a market manager or a customer, may be interested to regulate the ?  factor, the trade-off between purchasing habits and product popularity 3 In this section, we present the results of our experiments The performance is affected by the damping factor Figure 2:Prediction accuracy with varying In ProductRank model, the ?  factor combines the product-product relation and user-product relation. For lower value of ? , we give more importance to the similarity between different products than the relation of purchasing habits between new customer and history customers. Figure2 curves the prediction accuracy when the ?  factor changes When the ? is too low or too high, the PA decreases. This demonstrates the importance of reinforcement between two products. When we set value of ?  to 0.5, the prediction accuracy of this model reaches the highest point, about 0.37  Figure 3 : The snapshot of a recommendation result Figure 3 shows a snapshot of the recommendation results of ProductRank. The bought item of the customer is Schwarzbier From the chart we can see that the other two top ranked products, Dry red wine and Fenjiu wine are both with low alcohol content, which is similar to Schwarzbier. The  latter two kinds of wine are products that share likely neighborhoods with the bought product, but rarely purchased together. That is the customers often buy snacks like peanuts together with Schwarzbier, and the customers of Fenjiu wine and Fruit wine may also like to buy such sort of snacks. As most customers would not buy the three kinds of wine at the same time, the other two products, Dry red wine and Fenjiu wine will hardly be recommended if we use state of the art algorithms like collaborative filtering. They are both valuable 


recommendation items and can be produced by ProductRank as we explore the transitive association between different products. The random walk model solves the problem of exploiting the relation between products,  which limits the performance of CF based model a lot IV. CONCLUSIONS AND FUTURE WORK This paper proposes a ProductRank model based on random walk for personalized recommendation for the on-line shops The proposed model fully exploits the past transaction records in the database to uncover the hidden purchasing habits of consumers who bought a certain kind of products. The model also takes the similarity of different products into consideration, which is proven to be important by the experiment results. By incorporating both the product-product relation and user-product relation, the PageRank model produces valuable personalized recommendations for users The PageRank model can be applied by E-Commerce websites to produce live recommendations and provide personalized searching results for customers as it is less time-consuming than many other recommendation algorithms By recording the improvement of sales, we will also regulate factor and thus optimizing the precision ACKNOWLEDGMENT This work is supported by the National College Students Innovation Plan Project named The Research and Implementation of Knowledge Discovery Algorithm Based on Training Set. We would also like to thank the anonymous reviewers for their comments which helped to improve this paper REFERENCES 1] A. Das, M. Datar, A. Garg, and S Rajaram. Google news personalization:scalable online collaborative filtering. In WWW, pages 271-280, 2007 2] G. Linden, B. Smith, and J. York. Amazon. com recommendations Item-to-Item collaborative filtering. IEEE Internet Computing, Jan/Feb 2003 3] B. Miller, I. Albert, S. Lam, J. Konstan, and J. Riedl. Movielens unplugged: Experiences with an occasionally connected recommender system. In Intl Conf Intelligent User Interfaces, 7\(2 4] Hui Li, Cun-hua Li, Shu Zhang. Learning to Recommend Product With The Content of Web Page. In Intl. Conf. On Fuzzy Systems and Knowledge Discovery. 2009 


5] Francisco, G. S. Rafael. An integrated approach for developing e-commence applications. Expert Systems with applications. Vol 28, pp 223-235, 2005 6] J. Han, P. , Xie, B. , Yang, F. . A scalable P2P recommender system based on distributed collaborative filtering. Expert Systems with Applications, Vol. 27, pp. 203-210, 2006 7] Zhang Xizheng. Building Personalized Recommendation system in E-Commence Using Association Rule-based Mining and Classification 8] Bing Liu, Yiming Ma, Ching Kian Wong, and Philip S. Yu. Scoring the Data Using Association Rules 9] S. Wesley Changchien, Tzu-Chuen Lu. Mining association rules procedure to support on-line recommendation by customers and products fragmen 10] Xiaobin Fu, Jay Budzik, Kristian J. Hammond. Mining Navigation History for Recommendation. IUI 2000 11] Agrawal, K. Imielinski, T. and Swami A. Mining association rules between sets of items in large databases. In Proceedings of ACM SIGMOD Conf. on Management of Data. 1993, 207-216 12] Agrawal, R. and Srikant R. Fast Algorithm for Mining Association Rules. In Proceedings of the 20th VLDB Conf. Santiago, Chile 1994 13] Fukuda, T. , Morimoto Y. , Morishita, S. , and Tokuyama T. Data mining using two-dimensional optimized association rules for numeric data: scheme, algorithms, visualization. In Proceedings of the ACM SIGMOD Intl Conf. on Management of Data. \(1996 14] Holsheimer, M. , Kersten M. , Mannila, H. , and Toivonent H. A perspective on database and data mining. In Proceedings of the First Intl Conf. on Knowledge Discovery and Data Mining\(1996 15] J. K. Kim, Y. H. Cho, W. J. Kim, and J. H. Suh. A personalized recommendation procedure for internet shopping. Electronic Commence Research and Applications. Vol. 1, No. 3-4 2002 16] D. R. Liu and Y. Y. Shih. Hybrid approach to product recommendation based on customer lifetime value. Information & Management, Vol 42 No. 3, pp 387-400, 2005 17] C. Miao, Q. Yang, H. Fang, and A. Goh. A cognitive approach for agent-based personalized recommendations. Knowledge-Based Systems Vol. 20, No. 4, pp. 394-405, 2007 18] R. R. Yanger. Fuzzy logic methods in recommender systems. Fuzzy Sets and Systems. Vol. 136, No. 2, pp. 133-149, 2003 19] S. Brin and L. Page. The anatomy of a large-scale hypertextual web search engine. Comput. Netw. ISDN Syst. 30\(1-7 20] Gnes Erkan ?and Dragomir R. Radev. Lex-page rank: Prestige in multi-document text summarization. In EMNLP, 2004 


21] Jahna Otterbacher, Gnes Erkan, and Dragomir R. Radev. Using random walks for question-focused sentence retrieval. In IILT/EMNLP, 2005 22] Fangtao Li, Yang Tang, Minlie Huang, and Xiaoyan Zhu. Answering opinion Questions with Random Walks on Graphs. ACL and AFNLP 2009, pp. 737-745 


1995 13] Pollack, H. M., McClennan, B. L., Clinical Urography. 2nd edition. Philadelphia: W. B Saunders/Elsevier, 2000 14] Bommanna Raja, K., Madheswaran, M Thyagarajah, K., A general segmentation scheme for contouring kidney region in ultrasound kidney images using improved higher order spline interpolation. Intl. J Biomedical Sciences 2\(2 REFERENCES 1] Marcela   X.   Ribeiro ,  Agma  J.  M . Traina Caetano Traina, and Paulo M. Azevedo-Marques, An Association Rule-Based Method to Support Medical Image Diagnosis with      Efficiency, IEEE Transactions on Multimedia, vol. 10, NO. 2, 277-285 , 2008 15] Bommanna Raja, K., Madheswaran, M Thyagarajah, K., Ultrasound kidney image analysis for computerized disorder identification and classification using content descriptive power spectral features. J. Med Syst. 31:307317, 2007 2] Verma B., Zakos, J., A computer-aided diagnosis system for digital mammograms based on fuzzy-neural and feature extraction techniques. IEEE Trans. Inf Technol. Biomed. 5\(1  Textural features for image classification, IEEE Trans Syst., Man, Cybern., vol. SMC-3, pp. 6 10621, 1973 


BU-UFM Utility threshold=5  Figure 5.  Utility frequent patterns mining on T40I10D100K V. CONCLUSIONS In this paper, we introduce a utility frequent pattern mining model based on a share strategy to find the combination of items with high frequencies and utilities. This model first find all patterns with a given minimum support threshold. In this step, a share strategy gives a way to share most of the results from the previous mining process instead of separating them distinctively, thereby dramatically reducing the cost of computation. And then all patterns that do not satisfy a minimum utility threshold are pruned The extension of our technique, for maintenance of the already mined utility frequent patterns when updating databases, is an interesting topic for future research REFERENCES 1] R. Agrawal, T. Imielinski, A. Swami, Mining association rules between sets of items in large databases, In: Proceedings of the 1993 ACM-SIGMOD, Washington, DC, 1993, 207216 2] J. Han, H. Cheng, D. Xin, X. Yan, Frequent pattern mining: current status and future directions, Data Min knowl Disc 2007, 55-86 3] Y. Liu, W. Liao, A.Choudhary, A two-phase algorithm for fast discovery of high utility itemsets, Lecture Notes in Artificial Intelligence 2005, 3518:689-695 4] Y. Liu, W. Liao, A. Choudhary, A fast high utility itemses mining algorithm, In: Proceeding of the 2005 ACM SIGKDD workshop on utility-based data mining, Chicago, Illinois, USA, 2005, 90-99 5] J. Yeh, Y. Li, C. Chang, Two-phase algorithms for a novel utilityfrequent mining model, Lecture Notes in Artificial intelligence 2007 4819: 433-444 6] C, Aaron, F. John, Association mining, ACM Computing Surveys 2006, 38\(2 7] H.Yao, H. Hamilton, C. Butz, A foundational approach to mining itemset utilities from databases, In: Proceeding of the 4th SIAM International Conference on Data Mining, Lake Buena Vista, Florida 2004, 428-486 8] H. Yao, H. Hamilton, L. Geng, A unified framework for utility based measures for mining itemsets, In: Proceedings of ACM SIGKDD 2nd workshop on utility-based data mining, New York, NY, 2006, 28-37 9] J. Han, M. Kamber, Data mining: concepts and techniques, 2nd edn 


Morgan Kaufmann. 2006 10] J. Han, J. Pei, Y. Yin, Mining frequent patterns without candidate generation, In: Proceeding of the 2000 ACM-SIGMOD international conference on management of data, Dallas, TX, 2000, 112 


2] S. Brin, R. Motwani, J. D. Ullman, and S. Tsur Dynamic Itemset Counting and Implication Rules for Market Basket Data," in Proceedings of the 1997 ACM SIGMOD international conference on Management of data, Tucson, Arizona, United States 1997, pp. 255-264 3] J. S. Park, M. S. Chen, and P. S. Yu, "An Effctive Hash based Algorithm for mining association rules in Prof. ACM SIGMOD Conf Management of Data New York, NY, USA, 1995, pp. 175 - 186 4] R. Agrawal, T. ,PLHOL?VNL DQG $. Swami, "Mining Association Rules between Sets of Items in Very Large Databases," in Proceedings of the 1993 ACM SIGMOD international conference on Management of data, Washington, D.C., 1993, pp. 207-216 5] H. Mannila, H. Toivonen, and A. I. Verkamo Efficient Algorithms for Discovering Association Rules," in AAAI Workshop on Knowledge Discovery in Databases, 1994, pp. 181-192 6] R. Srikant and R. Agrawal, "Mining Generalized Association Rules," in In Proc. of the 21st Int'l Conference on Very Large Databases, Zurich Switzerland, 1995 7] R. Srikant, Q. Vu, and R. Agrawal, "Mining association rules with item constraints," in In Proc 3rd Int. Conf. Knowledge Discovery and Data Mining, 1997, pp. 67--73 8] A. Savasere, E. Omiecinski, and S. B. Navathe, "An Efficient Algorithm for Mining Association Rules in Large Databases," in Proceedings of the 21th International Conference on Very Large Data Bases 1995, pp. 432 - 444 9] H. Mannila, "Database methods for data mining," in The Fourth International Conference on Knowledge Discovery and Data Mining, 1998 10] B. Liu, W. Hsu, and Y. Ma, "Mining Association Rules with Multiple Minimum Supports.," in SIGKDD Explorations, 1999, pp. 337--341 11] H. Yun, D. Ha, B. Hwang, and K. H. Ryu, "Mining association rules on significant rare data using relative support.," Journal of Systems and Software archive vol. 67, no. 3, pp. 181 - 191, 2003 


12] M. Hahsler, "A Model-Based Frequency Constraint for Mining Associations from Transaction Data Data Mining and Knowledge Discovery, vol. 13, no 2, pp. 137 - 166, 2006 13] L. Zhou and S. Yau, "Association rule and quantitative association rule mining among infrequent items," in International Conference on Knowledge Discovery and Data Mining, San Jose, California 2007, pp. 156-167 14] C. Ordonez, C. Santana, and L. d. Braal, "Discovering Interesting Association Rules in Medical Data," in Proccedings of ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery, 2000, pp. 78-85 15] L. J. Sheela and V. Shanthi, "DIMAR - Discovering interesting medical association rules form MRI scans," in 6th International Conference on Electrical Engineering/Electronics, Computer Telecommunications and Information Technology 2009, pp. 654 - 658 16] C. Ordonez, N. Ezquerra, and C. A. Santana Constraining and summarizing association rules in medical data," Knowledge and Information Systems vol. 9, no. 3, pp. 259 - 283, September 2005 17] H. Pan, J. Li, and Z. Wei, "Mining Interesting Association Rules in Medical Images," Lecture Notes In Computer Science, vol. 3584, pp. 598-609, 2005 18] S. Doddi, A. Marathe, S. S. Ravi, and D. C Torney Discovery of association rules in medical data Medical Informatics and the Internet in Medicine, vol 26, no. 1, pp. 25-33, January 2001 86 


the time needed for execution exceeded 100000 seconds Thus, from this analysis we see that FPrep, which uses FCM clustering, clearly outperforms the CLARANS and CURE based methods on the basis of speed. The execution times for CLARANS and CURE mentioned in fig. 7 and Table II do not include the time required to create fuzzy sets, and calculate the membership value  for each numerical data point in every fuzzy set for the numerical attribute under consideration. These times also do not take into account the time required to transform crisp numerical attributes to fuzzy attributes, and derive the fuzzy dataset from the original crisp dataset The fuzzy partitions generated for each of the five numerical attributes for the USCensus1990raw dataset are shown in Table III. Coincidentally, generating three fuzzy partitions for each numerical attribute seemed a perfect fit In addition to the superior speeds achieved by FPrep, as illustrated in fig. 7 and Table II, Table III indicates the semantics and the quality of the fuzzy partitions generated by FPrep. Moreover, the number of frequent itemsets generated by a fuzzy ARM algorithm \(like fuzzy ARMOR and fuzzy Apriori minimum support threshold, is illustrated in fig. 8   Fig. 7. Algorithm, numerical attribute comparison based on speed \(log10 seconds   Fig. 8. Number of frequent itemsets for various minimum support values  B. Results from Second Dataset We have also applied FPrep on the FAM95 dataset http://www.stat.ucla.edu/data/fpp transactions. Of the 23 attributes in the dataset, we have used the first 18, of which six are quantitative and the rest are binary. For each of the six quantitative attributes, we have generated fuzzy partitions using FPrep. A thorough analysis with respect to execution times, has already been performed on the USCensus1990raw dataset \(which is manifolds bigger in size than the FAM95 dataset both on the basis of number of transactions and number of unique values for numerical 


attributes dataset has been done solely to provide further evidence of the quality and semantics of the fuzzy partitions generated by FPrep. The details of the same are in Table IV. In this case, the number of fuzzy partitions is different for different numerical attributes. Thus, the number and type of fuzzy partitions to be generated is totally dependent on the attribute under consideration. A graphical representation of the fuzzy partitions generated for the attribute Age has already been provided in fig. 5, and clearly shows the Gaussian nature of the fuzzy partitions. The nature and shapes of fuzzy partitions for the rest of the attributes are also similar. Last, the number of frequent itemsets generated for different minimum support values is illustrated in fig. 8  C. Analysis of Results With FPrep, we can analyze and zero in on the number and type of partitions required based on the semantics of the numerical attributes, which the methods detailed in [19 20] do not necessarily facilitate. Then, FPrep, backed by FCM clustering, takes care of the creating the fuzzy partitions, especially assigning membership values for each numerical data point in each fuzzy partition. In section 8.A we have already shown that FPrep is nearly 9 to 44 times faster than the CURE-based method, and 2672 to 13005 times faster than the CLARANS-based method. FPrep is not only much faster than other related methods, but also generates very high quality fuzzy partitions \(Table III and IV much user-intervention. We have created a standard way of representing any fuzzy dataset \(converted from any type of crisp dataset efficacy of the same is corroborated by the successful implementation of Fuzzy Apriori and Fuzzy ARMOR on the fuzzy dataset \(converted from crisp version of FAM95 dataset an initial implementation of Fuzzy ARMOR, are very encouraging. FPrep, when used in conjunction with these fuzzy ARM algorithms, generates a pretty good number of high-quality frequent itemsets \(fig. 8 frequent itemsets generated for a particular minimum support is same, irrespective of the fuzzy ARM algorithm 


used IX. CONCLUSIONS In this paper we have highlighted our methodology, called FPrep, for ARM in a fuzzy scenario. FPrep is meant for seamlessly and holistically transforming a crisp dataset into a fuzzy dataset such that it can drive a subsequent fuzzy ARM process. It does not rely on any non-fuzzy techniques and is thus more straightforward, fast, and consistent. It facilitates user-friendly automation of fuzzy dataset 1 0 1 2 3 4 5 Age - 91 Hours - 100 Income3 4949 Income2 13707 Income1 55089 Ti m e lo g1 0 se co nd s Numerical Attribute - Number of Unique Values FCM CURE CLARANS 0 500 1000 1500 2000 2500 


3000 0.075 0.1 0.15 0.2 0.25 0.3 0.35 0.4 N o o f F re qu en t I te m se ts Minimum Support USCensus1990 FAM95 generation through FCM, and subsequent steps in preprocessing with very less manual intervention and as simple and straightforward manner as possible. This methodology involves two distinct steps, namely creation of appropriate fuzzy partitions using fuzzy clustering and creation of fuzzy records, using these partitions, to get the fuzzy dataset from the original crisp dataset FPrep has been compared with other such techniques, and has been found to better on the basis of speed. We also illustrate its efficacy on the basis of quality of fuzzy partitions generated and the number of itemsets mined by a fuzzy ARM algorithm which is preceded by FPrep. This preprocessing technique provides us with a standard method of fuzzy data \(record that it is useful for any kind of fuzzy ARM algorithm irrespective of how the algorithm works. Furthermore, this pre-processing methodology has been adequately tested with two disparate fuzzy ARM algorithms, Fuzzy Apriori and Fuzzy ARMOR, and would also work fine with other fuzzy ARM algorithm REFERENCES 1] Zadeh, L. A.: Fuzzy sets. Inf. Control, 8, 338358 \(1965 2] Chen G., Yan P., Kerre E.E.: Computationally Efficient Mining for Fuzzy Implication-Based Association Rules in Quantitative Databases. International Journal of General Systems, 33, 163-182 


2004 3] Hllermeier, E.: Fuzzy methods in machine learning and data mining Status and prospects. Fuzzy Sets and Systems. 156, 387-406 \(2005 4] De Cock, M., Cornelis, C., Kerre, E.E.: Fuzzy Association Rules: A Two-Sided Approach. In: FIP, pp 385-390 \(2003 5] Yan, P., Chen, G., Cornelis, C., De Cock, M., Kerre, E.E.: Mining Positive and Negative Fuzzy Association Rules. In: KES, pp. 270-276 Springer \(2004 6] De Cock, M., Cornelis, C., Kerre, E.E.: Elicitation of fuzzy association rules from positive and negative examples. Fuzzy Sets and Systems, 149, 7385 \(2005 7] Verlinde, H., De Cock, M., Boute, R.: Fuzzy Versus Quantitative Association Rules: A Fair Data-Driven Comparison. IEEE Transactions on Systems, Man, and Cybernetics - Part B: Cybernetics 36, 679-683 \(2006 8] Dubois, D., Hllermeier, E., Prade, H.: A systematic approach to the assessment of fuzzy association rules. Data Min. Knowl. Discov., 13 167-192 \(2006 9] Dubois, D., Hllermeier, E., Prade, H.: A Note on Quality Measures for Fuzzy Association Rules. In: IFSA, pp. 346-353. Springer-Verlag 2003 10] Hllermeier, E., Yi, Y.: In Defense of Fuzzy Association Analysis IEEE Transactions on Systems, Man, and Cybernetics - Part B Cybernetics, 37, 1039-1043 \(2007 11] Agrawal, R., Imielinski, T., Swami, A.N.: Mining Association Rules between Sets of Items in Large Databases. SIGMOD Record, 22, 207216 \(1993 12]  Agrawal, R., Srikant, R.: Fast Algorithms for Mining Association Rules. In: VLDB, pp. 487-99. Morgan Kaufmann \(1994 13] Han, J., Pei, J., Yin, Y.: Mining Frequent Patterns without Candidate Generation. In: SIGMOD Conference, pp. 1-12. ACM Press \(2000 14] Han, J., Pei, J., Yin, Y., Mao, R.: Mining Frequent Patterns without Candidate Generation: A Frequent-Pattern Tree Approach. Data Mining and Knowledge Discovery, 8, 5387 \(2004 15] Pudi V., Haritsa J.R.: ARMOR: Association Rule Mining based on Oracle. CEUR Workshop Proceedings, 90 \(2003 16] Dunn, J. C.: A Fuzzy Relative of the ISODATA Process and its Use in Detecting Compact, Well Separated Clusters. J. Cyber., 3, 32-57 1974 17] Hoppner, F., Klawonn, F., Kruse, R, Runkler, T.: Fuzzy Cluster Analysis, Methods for Classification, Data Analysis and Image Recognition. Wiley, New York \(1999 


18] Bezdek J.C.: Pattern Recognition with Fuzzy Objective Function Algorithms. Kluwer Academic Publishers, Norwell, MA \(1981 19] Fu, A.W., Wong, M.H., Sze, S.C., Wong, W.C., Wong, W.L., Yu W.K. Finding Fuzzy Sets for the Mining of Fuzzy Association Rules for Numerical Attributes. In: IDEAL, pp. 263-268. Springer \(1998 20] Kaya, M., Alhajj, R., Polat, F., Arslan, A: Efficient Automated Mining of Fuzzy Association Rules. In: DEXA, pp. 133-142. Springer \(2002 21] Mangalampalli, A., Pudi, V. Fuzzy Association Rule Mining Algorithm for Fast and Efficient Performance on Very Large Datasets In FUZZ-IEEE, pp. 1163-1168. IEEE \(2009 22] Kaya, M., Alhajj. Integrating Multi-Objective Genetic Algorithms into Clustering for Fuzzy Association Rules Mining. In ICDM, pp. 431434. IEEE \(2004  Table II. Algorithm, numerical attribute comparison based on speed \(seconds  Algorithm Age - 91 Hours - 100 Income3 - 4949 Income2 - 13707 Income1 - 55089 FCM 0.27 0.3 3.13 6.28 79.4 CURE 0.25 0.25 28.67 163.19 3614.13 CLARANS 1.3 1.34 8363.53 78030.3 Table III. Attributes and their fuzzy partitions  Attribute Fuzzy Partitions Age Old Middle Aged Young Hours More Average Less Income1 High Medium Low Income2 High Medium Low Income3 High Medium Low  Table IV. Attributes and their fuzzy partitions  Attribute Fuzzy Partitions AGE Very old Around 25 Around 50 Around 65 Around 35 HOURS Very High Zero Around 40 Around 25 INCHEAD Very less Around 30K Around 50K Around 100K INCFAM Around 60K Around 152K Around 96K Around 31K Around 8K TAXINC Around 50K Around 95K Around 20K Very less FTAX Around 15K Very less Around 6K Very high Around 33K  


the US census data set. The size of pilot sample is 2000, and all 50 rules are derived from this pilot sample. In this experiment the ?xed value x for the sample size is set to be 300. The attribute income is considered as a differential attribute, and the difference of income of husband and wife is studied in this experiment. Figure 3 shows the performance of the 5 sampling 331 6DPSOLQJ9DULDQFH             9D UL DQ FH R I V WL PD WL RQ  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW    


      6D PS OL QJ  RV W 9DU 9DU 9DU 5DQG b 6DPSOLQJ$FFXUDF          5  9DU 9DU 9DU 5DQG c Fig. 2. Evaluation of Sampling Methods for Association Rule Mining on the Yahoo! Dataset procedures on the problem of differential rule mining on the US census data set. The results are also similar to the experiment results for association rule mining: there is a consistent trade off between the estimation variance and sampling cost by setting their weights. Our proposed methods have better performance than simple random sampling method 


We also evaluated the performance of our methods on the Yahoo! dataset. The size of pilot sampling is 2000, and the xed value x for the sample size is 200. The attribute price is considered as the target attribute. Figure 4 shows the performance of the 5 sampling procedures on the problem of differential rule mining on the Yahoo! dataset. The results are very similar to those from the previous experiments VI. RELATED WORK We now compare our work with the existing work on sampling for association rule mining, sampling for database aggregation queries, and sampling for the deep web Sampling for Association Rule Mining: Sampling for frequent itemset mining and association rule mining has been studied by several researchers [23], [21], [11], [6]. Toivonen [23] proposed a random sampling method to identify the association rules which are then further veri?ed on the entire database. Progressive sampling [21], which is based on equivalence classes, involves determining the required sample size for association rule mining FAST [11], a two-phase sampling algorithm, has been proposed to select representative transactions, with the goal of reducing computation cost in association rule mining.A randomized counting algorithm [6] has been developed based on the Markov chain Monte Carlo method for counting the number of frequent itemsets Our work is different from these sampling methods, since we consider the problem of association rule mining on the deep web. Because the data records are hidden under limited query interfaces in these systems, sampling involves very distinct challenges Sampling for Aggregation Queries: Sampling algorithms have also been studied in the context of aggregation queries on large data bases [18], [1], [19], [25]. Approximate Pre-Aggregation APA  categorical data utilizing precomputed statistics about the dataset Wu et al. [25] proposed a Bayesian method for guessing the extreme values in a dataset based on the learned query shape pattern and characteristics from previous workloads More closely to our work, Afrati et al. [1] proposed an adaptive sampling algorithm for answering aggregation queries on hierarchical structures. They focused on adaptively adjusting the sample size assigned to each group based on the estimation error in each group. Joshi et al.[19] considered the problem of 


estimating the result of an aggregate query with a very low selectivity. A principled Bayesian framework was constructed to learn the information obtained from pilot sampling for allocating samples to strata Our methods are clearly distinct for these approaches. First strata are built dynamically in our algorithm and the relations between input and output attributes are learned for sampling on output attributes. Second, the estimation accuracy and sampling cost are optimized in our sample allocation method Hidden Web Sampling: There is recent research work [3 13], [15] on sampling from deep web, which is hidden under simple interfaces. Dasgupta et al.[13], [15] proposed HDSampler a random walk scheme over the query space provided by the interface, to select a simple random sample from hidden database Bar-Yossef et al.[3] proposed algorithms for sampling suggestions using the public suggestion interface. Our algorithm is different from their work, since our goal is sampling in the context of particular data mining tasks. We focus on achieving high accuracy with a low sampling cost for a speci?c task, instead of simple random sampling VII. CONCLUSIONS In this paper, we have proposed strati?cation based sampling methods for data mining on the deep web, particularly considering association rule mining and differential rule mining Components of our approach include: 1 the relation between input attributes and output attributes of the deep web data source, 2 maximally reduce an integrated cost metric that combines estimation variance and sampling cost, and 3 allocation method that takes into account both the estimation error and the sampling costs Our experiments show that compared with simple random sampling, our methods have higher sampling accuracy and lower sampling cost. Moreover, our approach allows user to reduce sampling costs by trading-off a fraction of estimation error 332 6DPSOLQJ9DULDQFH      


     V WL PD WL RQ R I 9D UL DQ FH  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW          6D PS OL QJ  RV W 9DU 9DU 


9DU 5DQG b 6DPSOLQJ$FFXUDF          5  9DU 9DU 9DU 5DQG c Fig. 3. Evaluation of Sampling Methods for Differential Rule Mining on the US Census Dataset 6DPSOLQJ9DULDQFH             9D UL DQ FH R I V WL 


PD WL RQ  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW          6D PS OL QJ  RV W  9DU 9DU 9DU 5DQG b 6DPSOLQJ$FFXUDF         


    5  9DU 9DU 9DU 5DQG c Fig. 4. Evaluation of Sampling Methods for Differential Rule Mining on the Yahoo! Dataset REFERENCES 1] Foto N. Afrati, Paraskevas V. Lekeas, and Chen Li. Adaptive-sampling algorithms for answering aggregation queries on web sites. Data Knowl Eng., 64\(2 2] Rakesh Agrawal and Ramakrishnan Srikant. Fast algorithms for mining association rules. In Proceedings of the 20th International Conference on Very Large Data Bases, pages 487499, 1994 3] Ziv Bar-Yossef and Maxim Gurevich. Mining search engine query logs via suggestion sampling. Proc. VLDB Endow., 1\(1 4] Stephen D. Bay and Michael J. Pazzani. Detecting group differences Mining contrast sets. Data Mining and Knowledge Discovery, 5\(3 246, 2001 5] M. K. Bergman. The Deep Web: Surfacing Hidden Value. Journal of Electronic Publishing, 7, 2001 6] Mario Boley and Henrik Grosskreutz. A randomized approach for approximating the number of frequent sets. In ICDM 08: Proceedings of the 2008 Eighth IEEE International Conference on Data Mining, pages 4352 Washington, DC, USA, 2008. IEEE Computer Society 7] D. Braga, S. Ceri, F. Daniel, and D. Martinenghi. Optimization of Multidomain Queries on the Web. VLDB Endowment, 1:562673, 2008 8] R. E. Ca?isch. Monte carlo and quasi-monte carlo methods. Acta Numerica 7:149, 1998 9] Andrea Cali and Davide Martinenghi. Querying Data under Access Limitations. In Proceedings of the 24th International Conference on Data Engineering, pages 5059, 2008 10] Bin Chen, Peter Haas, and Peter Scheuermann. A new two-phase sampling based algorithm for discovering association rules. In KDD 02: Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 462468, New York, NY, USA, 2002 ACM 


11] W. Cochran. Sampling Techniques. Wiley and Sons, 1977 12] Arjun Dasgupta, Gautam Das, and Heikki Mannila. A random walk approach to sampling hidden databases. In SIGMOD 07: Proceedings of the 2007 ACM SIGMOD international conference on Management of data pages 629640, New York, NY, USA, 2007. ACM 13] Arjun Dasgupta, Xin Jin, Bradley Jewell, Nan Zhang, and Gautam Das Unbiased estimation of size and other aggregates over hidden web databases In SIGMOD 10: Proceedings of the 2010 international conference on Management of data, pages 855866, New York, NY, USA, 2010. ACM 14] Arjun Dasgupta, Nan Zhang, and Gautam Das. Leveraging count information in sampling hidden databases. In ICDE 09: Proceedings of the 2009 IEEE International Conference on Data Engineering, pages 329340 Washington, DC, USA, 2009. IEEE Computer Society 15] Loekito Elsa and Bailey James. Mining in?uential attributes that capture class and group contrast behaviour. In CIKM 08: Proceeding of the 17th ACM conference on Information and knowledge management, pages 971 980, New York, NY, USA, 2008. ACM 16] E.K. Foreman. Survey sampling principles. Marcel Dekker publishers, 1991 17] Ruoming Jin, Leonid Glimcher, Chris Jermaine, and Gagan Agrawal. New sampling-based estimators for olap queries. In ICDE, page 18, 2006 18] Shantanu Joshi and Christopher M. Jermaine. Robust strati?ed sampling plans for low selectivity queries. In ICDE, pages 199208, 2008 19] Bing Liu. Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data \(Data-Centric Systems and Applications Inc., Secaucus, NJ, USA, 2006 20] Srinivasan Parthasarathy. Ef?cient progressive sampling for association rules. In ICDM 02: Proceedings of the 2002 IEEE International Conference on Data Mining, page 354, Washington, DC, USA, 2002. IEEE Computer Society 21] William H. Press and Glennys R. Farrar. Recursive strati?ed sampling for multidimensional monte carlo integration. Comput. Phys., 4\(2 1990 22] Hannu Toivonen. Sampling large databases for association rules. In The VLDB Journal, pages 134145. Morgan Kaufmann, 1996 23] Fan Wang, Gagan Agrawal, Ruoming Jin, and Helen Piontkivska. Snpminer A domain-speci?c deep web mining tool. In Proceedings of the 7th IEEE International Conference on Bioinformatics and Bioengineering, pages 192 199, 2007 24] Mingxi Wu and Chris Jermaine. Guessing the extreme values in a data set a bayesian method and its applications. VLDB J., 18\(2 25] Mohammed J. Zaki. Scalable algorithms for association mining. IEEE Transactions on Knowledge and Data Engineering, 12:372390, 2000 


333 



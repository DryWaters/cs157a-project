Association Rules Mining Based Approach for Web Usage Mining  Mohamad Nagi a Abdallah ElSheikh b Iyad Sleiman a Peter Peng b Mohammad Rifaie c  Keivan Kianmehr d Panagiotis Karampelas e Mick Ridley a  Jon Rokne b Reda Alhajj b  d,e  
a School of Computing University of Bradford Bradford, UK b Department of Computer Science University of Calgary Calgary, Alberta, Canada c RBC Royal Bank Toronto, Ontario, Canada d Department of Computer Science Global University Beirut, Lebanon e Department of Information Technology Hellenic American University New Hampshire, USA f Department of Electrical and Computer  Engineering University of Western Ontario 
London, Ontario, Canada Abstract The web has emerged rapidly into a valuable source of information. Web visitors leave trace behind them which is used by web site owners for knowledge discovery. The latter information guides site owners in deciding how to organize the information in their website and how to provide the best for their visitors in order to maximize their profit. Various mining techniques combined with machine learning models could be employed for effective knowledge discovery. The work described in this paper utilizes association rules mining integrated with fuzziness factor in order to analyze weblog data. The target is to find 
pages that are accessed together by majority of the users and hence should be linked in a proper way in order to maximize user satisfaction by providing to the users the access flow they expect. This way the number of visitors to the analyzed website will be maximized and hence the target will be achieved. Existing systems that are currently in use, such as AxisLogMiner and WebMiner, will be analyzed Keywords web mining, weblog, association rules mining fuzziness, web structure 1. Introduction The World Wide Web \(or the web for short\ has influenced all aspects of 
our life from education to purchasing to entertainment to social media, etc. Almost every house in the developed countries is connected to the internet. Further, the new development in handheld devices made the internet widely available almost everywhere People are adapting the custom to access the internet to seek any piece of information they are looking for. The web is turning into a global encyclopedia. This increased the competition between commercial merchants who are trying to attract and keep the largest number of customers from all over the world. The interesting aspect of the game is having different customers from different regions and 
with different backgrounds and even different expectations. Thus, the problem facing all website owners is how to attract more visitors and how to retain the attracted visitors. To handle this, log access patterns are being kept for every website and later analyzed for knowledge discovery Web mining may be classified into three categories namely weblog mining, web content mining, and web structure mining. Weblog mining is the process of analyzing visitors’ access patterns. For this purpose, every website keeps tracks of all accesses to the website by maintaining the IP address, the time of access and the pages accessed. Web content mining analyzes the content 
of the various pages in the website to find out the correlation between the content and how they all form one integrated semantic unit. Finally, web structure mining concentrates on the links between web pages of a given website. In this paper, we concentrate mainly on weblog mining and web structure mining. We leave web content mining as future work to be integrated into the comprehensive framework described in this paper. Our target is to combine the discoveries from both weblog and web structure mining in order to guide for better website design that would attract a wider population as visitors 
Various approaches have been proposed to tackle the problem. Almost all of the approaches apply data mining techniques in order to discover groups of users who have similar access patterns Since the amount of data which is available is growing there needs to be a more efficient way to traverse the data to get the information we want. Web Data Mining currently employs algorithms which are able to do this effectively, but for how long can they continue to be 166 IEEE IRI 2011, August 3-5, 2011, Las Vegas, Nevada, USA 978-1-4577-0966-1/11/$26.00 ©2011 IEEE 


effective amongst the ever-growing size of data with their current flaws In this paper, we present an approach that combines association rules mining with fuzziness in order to produce a technique capable of analyz ing weblog data and webs structure data for effective knowledge discovery. We apply frequent pattern mining on weblog data and on web structure data separately. The outcome from each is turned into fuzzy sets and the two groups of fuzzy sets are further analyzed for knowledge discovery. This dual knowledge discovery process produces a robust framework for website analysis. We want to be able to suggest to visitors of the analyzed website certain pages that have been navigated by visitors who have shown access patterns similar to the current user This will educat e the current visitor and will mostly maximize his/her experience with the visited website. Such recommendations are highly valuable to all types of visitors and mostly naïve visitors who would spend extra time and effort to attain their target. The reported test results are encouraging. They demonstrate the applicability and effectiveness of the proposed framework The rest of this paper is organized as follows. Section 2 presents the necessary background and related work Section 3 describes the proposed framework. Section 4 reports experimental results. Section 5 is summary and conclusions 2 Related Work Research on weblog analysis, web structure and web content mining has attracted co nsiderable attention over the past two decades. With the exponential growth of the web and the diversity in the visitors it is becoming extremely hard to put together a website that remains static and attractive over time. Researchers realized the need for automated methods to analyze all website related stuff to adapt to the chan ge accordingly Ardissono et al des c ri bes a f r a m e w ork f o r t h e  dynamic revision of user models in a Web store shell which tailors the suggestion of goods to the characteristics of the individual user. The behavior of the user is monitored by segmenting it on the basis of the focus spaces explored in the browsing activity, and the actions performed by the user are summarized into abstract facts These facts are used for revising the user model via the interpretation process performed by a Bayesian Network which relates user features to user behavior. Borodin et al  r es s e d an approach th a t u s e s  hy perli n k s t r u ct u r es to  determine the relative aut hority of a Web page and produce improved algorithms for the ranking of Web search results. In particular, it works within the hubs and authorities framework. The algorithms proposed in s e  a Bayesian approach as opposed to the usual algebraic and graph theoretic approaches. Borges pro pos ed a  different approach to capture the user navigation behavior patterns. The user navigatio n sessions are modelled as hypertext probabilistic grammar whose higher probability strings correspond to the users preferred trails. The algorithm to mine such trails makes use of the N-gram model which assumes that the last N pages browsed affect the probability of the next page to be visited Abitebou prop os ed an alg o rit h m  OP IC S, f o r computing the page importance in a dynamic graph. Their algorithm works online and does not require storing the link matrix. It is online in that it continuously refines its estimate of page importance while the web/graph is visited. In h e a u th ors propos e a n e w ra nk i n g  fu n c t i o n   called page quality that measures the intrinsic quality of a page. The proposed framework investigates how the search engine bias in more concrete terms; it provides clear understanding on why PageRank is effective in many cases; it also highlights when PageRank is problematic They propose a practical way to estimate the intrinsic page quality in order to avoid the inherent bias of PageRank. In  h e au th ors det ect  u s ers n a v i g a t i on pat h s b y  implementation of a profiler which captures clients selected links and pages order, page viewing time and cache. The information captured by the profiler is then utilized by a knowledge discovery technique to cluster users with similar interests A path clustering method based on the similarity of the history of user navigation is used in the proposed framework Fu et al opos ed an al g o ri t h m  w h ere f i rs t th e server log data is processe d to identify sessions of Web usage. The sessions are then generalized using the attribute-oriented induction method; and finally they are clustered using a hierarchical cl ustering algorithm. Li et al 15 investi g ated the i n teract io n b e t w ee n usab ilit y a n d a web site structure. They discuss a web structure mining algorithm which allows the automatic extraction of navigational structures in a website without performing hypertext analysis. Hsu et al s c u s s e d t h e probl e m of link recommendations in weblogs and in similar social networks. They have used both collaborative recommendations and content based recommendations by exploiting the link structures and mutually declared interests. The authors argue that this allows more in-depth analysis of the structures combined with the content. The proposed hybrid approach, LJMiner mines weblog data of people from the social network service LiveJounal www.livejournal.com\which people use mainly as personal publishing tool. But the authors of this research manuscript are more interested in mining hyperlink usage behavior to better structure the hyperlinks of a website rather than mining an actual friendship network Lee et al c t e d t h at  n e xt g e n e rat i on w e b portals would place an increased emphasis on web personalization. This will result in an automatic user profiling, and recommendation made to users based on 167 


their web usage. In order to achieve this automatic recommendation, they suggest mining web usage or click stream data in order to discover interesting web usage patterns and statistical correlations between Web pages and user groups. By seamlessly matching these recommendations with users’ social behavior, a better web personalization can be achieved. Adnan et  presented a social network modelling technique that uses frequent close patterns to construct the social network. The authors argue that frequent closed patterns have the advantage that they successfully grab the inherent information content of the dataset being analyzed; the model is applicable to a broader application domain Entropies of the frequent closed patterns are used to collect the best set of features for the social network construction process. In this paper, we have used sequential closed patterns to construct the social network of hyperlinks. This can be considered as the reciprocal view of the approach presented in w h ere t h e r e lation s h i ps a m o n g t h e u s ers  of the data are identified base d on the data usage; while here we identify relationships among key data items hyperlinks\ed on how the users used them Finally, there exist some other systems for web data mining, e.g., AxisLogMiner, and WebMiner. The inputs to most of these algorithms are server logs, site files, and other optional usage stats. The output consists of a user session file, a transaction file, site topology, and page classification. User registration is preferred in these systems because it has the advantage of being able to obtain information above and beyond what is provided in the user log. As well, this allows the ID of the user sessions to be simplified, focusing on a user name, rather than an IP Address \(which might not necessarily be the same user every time\ drawback to this idea is the fact that many Internet users try to avoid websites which require registration. Since the main goal of weblog mining is to get a picture of user’s behaviors, this does not allow us to get an accurate picture of all users. As well, many websites do not require user registration among its viewers, so these systems have to cope with that aspect of the data log. WebMiner [8 r im ar y f o cuse s o n the d a ta  preprocessing, namely data cleansing, user identification and session identification. WebMiner [18 w o rk s o n  removing the unusable information in the system logs, and then to identify the different users and how many sessions each participates in 3. The Proposed Approach Web usage mining and web structure mining are two orthogonal sources for valuable knowledge which could be used to build a robust recommendation system that will guide users navigating the analyzed website. From the web usage data log we derive some association rules showing how visiting some pages would mostly lead to visiting some other pages. A weight is assigned to each page in the rules by using a formula which considers all the derived set of most frequently accessed pages. The weighting could be considered as kind of fuzzifying the outcome from the frequent pattern mining process. From the direct links between pages, we will find sets of pages forming hubs, i.e., connected to from most pages. The second discovery will enhance the first discovery into a robust recommendation framework consisting of a set of rules Each rule will fire based on the weight of the visited pages from its antecedent. The process of deriving frequent patterns from both web usage data and web structure data is described next in this section 3.1. From Weblog data to Association Rules In its simplest form, as asso ciation rule is a correlation between two disjoint sets of items such that the union of the two sets is frequent by considering the whole given data. In other words, after mapping a given problem into the required structure, the association rules mining process consists of two steps. First frequent sets of items and then finding interesting rules from the rules constructed using the frequent sets of items. Frequency \(support\ is the percentage of transactions that contain an itemset. An itemset is said to be frequent if it satisfies a minimum support threshold. Further, a rule is interesting if it has high confidence which is measured as the support of the union of the antecedent and consequent divided by the support of the antecedent Mapping the problem is the most crucial part to begin with. The mapping is required because the association rules mining technique was first proposed for analyzing market basket data. Given a se t of transactions showing the items purchased by each customer in one visit to the market, first frequent sets of items are determined based on a predefined minimum frequency measure called minimum support threshold. Each frequent itemset consists of items which have purchased together by most of the customers The model is general enough to fit to any problem which contains two types of entities which can be mapped into transactions and items, respectively. Fortunately, our application domain could be successfully handled using the association rules mining model. For the weblog data users represent transactions, i.e., each session corresponds to a transaction and each webpage in the visited site could be seen as an item. A table is constructed where each row is a session and each column is a page; an entry in the table is set to one if and only if the page is visited during the session, otherwise the entry is set to zero. On the other hand, for the web structure data each page of the analyzed website is a transaction and pages of the website are the items. Here rows and columns in the table correspond to pages. An entry is set to one if and only if the page in the 168 


row includes a link to the page in the column; it is set to zero otherwise Before applying the association rules technique on the weblog data, it is important to prepare the data first by cleaning and sessionizing the data as described next in this section The goal of the data cleaning is to eliminate from the log files all redundant informa tion. This way, the pattern discovery phase can search through fewer irrelevant links that would distract it from finding the patterns. The basic work done involves removing all pictures, scripts, agents and robots which are located in the received log file. The actual implementation of the data cleaning process is very trivial. We ha ve a function dataClean which takes as input one line from the log at a time, and returns the line to be fed into the session and user identification steps. The function breaks down the line of data which has been read into tokens, using a StringTokenizer, and then places each token in a temporary array.  We use the URL requested part of the log entry to determine whether to keep or remove the line.  To handle the case for pictures and other non-relevant documents we removed any line that had a and ignored the lines with an ‘.html’ or ‘.htm’.  We assumed this after first implementing our cleaning function by using different cases for each suffix.  It was very trivial to see that just searching for a ‘.’ was much faster and more efficient because the results were virtually the same For the web agent case we determined that anything with a MMAgent’ identified as a web robot so those lines were removed as well along with the first identifier line to begin the user’s history After the log is cleaned, users could be identified based on the IP address; a user is mostly an IP address Fortunately the log files are mostly separated by users but they do not take into account multiple users coming from the same source.  But to compensate for that, we used a time interval of 30mins, whereby we assume that any user in one sitting will traverse th rough the site for at most 30 minutes; this is actually a session Pages visited in each session form a transaction and all transactions are used to find sets of pages frequently accessed by most users. However, we realized that the size of the log file is large and hence the number of transactions is also large. This produced a large number of frequent itemsets. We decided to reduce the number of large itemsets further by considering only maximal closed itemsets. Such number is manageable A frequent itemset X is said to be closed if and only if there is no other frequent itemset Y such that X  Y and support\(X\upport\(Y\urther, X is said to be maximal closed if there is no itemset Z such that X  Z and Z is frequent After identifying all maximal frequent sets of pages, we find a weight for each page in each maximal frequent itemset. Of course the weight is zero if the page does not belong to the maximal frequent itemset. Otherwise, the weight for a page, say p, in itemset X is computed as average support of X divided by the sum of average support of all itemsets Y \(including set X\which contain p The average support is determined by dividing the support of an itemset by the number of pages in the itemset By considering the maximal closed frequent sets of pages, we derive all possible association rules and retain only the frequent rules. These rules will constitute our recommendation system to be employed for guiding visitors to the website. A rule is fired if all the visited pages are in its antecedent and it is the rule that has the highest overall weight for the mentioned pages. Firing the latter rule means recommending to the visitor pages that appear in the consequent of the rule as the pages to be visited next because they have been visited by most of the previous visitors who visite d the pages appearing in the antecedent 3.2 Analyzing Web Structure Data As mentioned in the previous section, we build a table from web structure data. The table is analyzed to find frequent sets of pages that are referenced by most of the pages, including self references The frequent sets of pages produced in this stage are processed by the same way applied to the frequent sets of pages produced by analyzing the weblog. In other words we concentrate the analysis on the maximal frequent itemsets in order to be consistent with the sets produced and analyzed in the previous section. We find a weight for each page in each maximal frequent itemset by applying the same process described in th e previous section. Finally we derive association rules from the maximal frequent itemsets The outcome from the process described in this section enforces and supports the outcome from the previous section in the following way. First, we check the overlap between the maximal closed frequent itemsets produced from the two stages. A maximal closed frequent itemset produced from the weblog data will have high value if there it overlaps with at least one of the maximal closed frequent itemset from the second stage; the more sets it overlaps with the higher will be its value. Further, a rule produced by the first stage will have higher value if its antecedent and consequent overlap with at least one of the rules produced from the second stage 3.2 Recommending Site Restructuring As a byproduct of the analysis and knowledge discovery approach describe above, we advanced the framework one step further into a recommendation system for website restructuring. We benefit from the association rules discovered in Section 3.1 to find pages that are accessed 169 


directly after accessing some other pages. They pages may not have direct link and hence, it is recommended to consider them for adding some direct links to the satisfaction of the user Given the set of rules produced from the approach described in Section 3.1, we rank the rules based on the weight \(degree of fuzziness\aracterizing individual pages appearing in each rule. Recall that the same page appears in different rules with different weights assigned to it. Further, the confidence in the rule is also used in the ranking process. So, for each rule, we find a new measure computed by adding its confidence and the average of the weights of the pages appearing in the rule. We consider the average in order to avoid any bias from rules involving more pages For each rule starting from the rule with the highest rank we check if page\(s\g in the antecedent have direct link to pages appearing in the consequent. If the link does not exist, then we add such a link to the recommendation set with co nfidence computed as the average of the rule confidence and the average weight of the pages that appear in the rule. This process produces a list of recommendations which includes all possible links to be added to pages. The list is presented to the website owner for final approval. All approved links may be later on added to the pages by the webmaster whose responsibility is to maintain the website 4. Experiments and Analysis We run some experiments to demonstrate the applicability and effectiveness of the proposed framework. For this purpose, we used the Music Machines web s T h e weblog used in the testing has been anonymized. We downloaded a zip file of all of the logs for October of 1997.  Each file corresponds to one day of server transactions by different users. Every transaction in the log file is separated by a user identifier in the form ---O identifier After this line the following lines are the user’s succession through the site.  These lines are in the form: O: identifier || T: time of request || U: URL requested R: referring URL Some of the derived rules derived by analyzing the input weblog dataset are shown in Table 1 where the weight of each item is shown between the parentheses. Notice how different items have different weights in different rules This means the rules have been derived from different maximal closed frequent sets of pages. We arbitrarily set minimum support and minimum confidence to 0.1 and 0.7 respectively  Table1 Sample rules from the music machines weblog Weblog Analysis Rules for Recommendation System P18 \(0.3\P12 \(0.125  P10 \(0.02\  P5 \(0.14 P9 \(0.2\  P5 \(0.105  P0 \(0.05 P12 \(0.1\P18 \(0.024\P45 \(0.01  P5 \(0.25\ P2 \(0.1 P3 \(0.08\ P37 \(0.19\ P1 \(0.12  P2 \(0.23\ P6 \(0.05 The analysis of the web structure data produces some rules similar to the sample rules enumerated in Table 1. The two sets of rules are matched in or der to enrich the set of rules produced from the web usage data. The enrichment process may include confidence is a rule Once the latter set of rules is finalized it is kept as the core of the recommendation system 8. Summary and Conclusions There is rapid and even hard to control increase in the number of websites developed and the number of pages per website. Websites are getting more dynamic to meet the expectations of the visitors This is the ultimate goal of website owners who are more interested in increasing the visitors to their websites. This would not be possible without adapting to the change and providing some attractive facilities liked and a ppreciated by visitors. One such facility has been described in this paper. The developed framework analyzes the web usage data of an existing website. We employ association rules mining to produce a set of recommendation rules that helps in guiding the visitors to the website. The rules are used in a planned way by considering the rank determined by the framework. Further, we are able to suggest restructuring the website into a better accessible site with better reachable pages by recommending adding direct links between pages most frequently accessed by the visitors. To move this project forward, we are currently working on enriching the developed framework with variety of new functionalities. We want to turn the web usage mining process into an incremental approach that periodically realizes changes in access and reflects them into the recommendation system. We want also to zoom into certain periods of the year, month, week, days, etc. We want to be able to say visitors who accessed these page\(s at noon on Friday also accessed the following page\(s\e want also to analyze content of the website to find out how content of each pages are coherent and whether it is possible to recommend partitioning and moving content around for better access and readability References   A b i t e bou l  M. Preda  an d G. C oben a A d apt i v e online page importance computation. Proceedings of the International Conference on World Wide Web, pp.280290, 2003 2 M  Ad na n R  Al ha j j   J  G   Ro k n e  I d e n tif yi n g So c i a l  Communities by Frequent Pattern Mining. IV 2009, pp 413-418, 2009 170 


  A r di s s o n o an d P T o ras s o, D y n a m i c U s er Model i n g  in a Web Store Shell, In Proceedings of the Conference European Conference on Artificial Intelligence, Berlin Germany, pp.621-625, 2000   Boro din  G. O. R oberts  J. S  R o s e n t h a l, a n d P   Tsaparas. Link analysis ranking: algorithms, theory and experiments. ACM Transactions on Internet Technology, 5\(1\231–297, 2005 5  J  Bo r g e s a n d M  Le ve ne   D a ta  m i ni ng o f use r  navigation patterns, Proceedings of Workshop on Web Usage Analysis and User Profiling \(WEBKDD conjunction with ACM SIGKDD International Conference on Knowledge Discovery and Data Mining San Diego, CA., pp.31-36, 1999   C h e n A  W  C F u an d F. C  H T o n g  Opti m a l Algorithms for Finding User Access Sessions from Very Large Web Logs. Journal of World Wide Web pp. 259–279, 2004 7  J  Cho  S Ro y  a n d R E  A d a m s P a ge q u a lit y: i n  search of an unbiased web ranking. Proceedings of ACM SIGMOD, pp.551-562, 2005   C ooley B  Mobas h er an d J  Sriv as tav a Data preparation for mining World Wide Web browsing patterns, Journal of Knowledge and Information Systems, 1\(1\, pp.55-32, 1999. Title Suppressed Due to Excessive Length 21  K. San d h u a n d M.Y Sh i h C l u s teri n g o f  WebUsers Based on Access Patterns, Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, 1999   H. Han  G. Kary pi s, V. Kum a r, an d B  Mobash er Clustering based on association rule hypergraphs Proceedings of the Workshop on Research Issues on Data Mining and Knowledge Discovery, pp.9-13 Tucson, Arizona, 1997  W. H. Hs u  A  Kin g  M S  Parades i  T   Py dim a rri  and T. Weninger. Collaborative and structural recommendation of friends using weblog-based social network analysis. In AAAI Spring Symposium on Computational Approaches to Analyzing Weblogs CAAW\olume SS-06-03, pages 55–60, Menlo Park CA, 2006 12  J  H o u a n d Y  Zha n g E f f e c tive l y f i nd i ng r e le va n t  we b  pages from linkage information. IEEE Transactions on Knowledge and Data Engineering, 15\(4\940–951 2003  ry pis R A g g a r w al V. Kum a r, an d S. S h e k h a r Multilevel hypergraph partitioning: Applications in VLSI domain. Proceedings ACM/IEEE Design Automation Conference, 1997   L ee, H. S  Yon g  Web Pers on al i zat i o n  M y  O w n  Web Based on Open Content Platform. Web Information Systems Engineering WISE 2005, 3806 pp.731-739 2005   H. L i an d C  K. C h u i  W e b s t ru ctu r e m i n i ng f o r usability analysis. Proceedings of IEEE/WIC/ACM International Conference on Web Intelligence, pp.309312, 2005 16  P  M a ssa a n d C H a y e s P a ge r e r a nk: U s i ng tr uste d  links to re-rank authority. Proceedings of IEEE/WIC/ACM International Conference on Web Intelligence, pp.614–617, 2005   Sh ah abi, A  M Z a rk es h  J  A b idi an d V. Sh a h  Knowledge discovery from users Webpage navigation Proceedings of the IEEE International Workshop on Research Issues in Data Engineering \(RIDE\29 1997 18 D   T a na sa  W e b U s a g e M i ni ng Co ntr i b u tio n s to  Intersites Logs Preprocessi ng and Sequential Pattern Extract with Low Support, 2005  Perk ow i t z a n d O. Et zi on i  L o g  F i l e s  f o r Mu si c Machines at Hyperreal, 1997 http://www.cs.washington.edu research/adaptive/downl oad.html    J. Han  an d R  Afs h ar. C l oS pa n  Min i ng  Closed Sequential Patterns in Large Datasets. Proc. of 2003 SIAM Int. Conf. Data Mining, 2003  171 


same class ranked/placed* as two thirds in the search list. These indices are in accordance with the visual results displayed in Figure 3 On the other hand, the Kmeans algorithm gives a result between 70 and 33% for the first 35K \(first third that the first third of the search list contains a combination of objects: those belonging to the same class as the requested object and others belonging to other classes. Moreover, the K that is greater than 35 corresponds to a score less than 85 which suggests that the rest of the objects belonging to the same class that are similar to the requested object are far from the top of list search V. CONCLUSION In this article, we introduced the concept of 3D object indexation, in particular the indexation from the views of these 3D objects. First, we introduced an algorithm that is independent of the 2D used descriptor in order to extract the characteristic views of a 3D object. The outcomes of this method are very satisfying since this latter reduces the 3D object size \(instead of using 342 initial views, the system automatically reduces this number depending on the threshold of the distance  to a smaller number be characterized by a small number of views called characteristic views. Next, we used the probabilistic bayesian view \(translated by T.F Ansary, J.P. Vandeborred and M Daoudi[5 displayed results highlight the good performances of this method compared to some classical methods of classification This method produces great results when the object size is big enough, with more than 340 views per object These tests are performed based on Princeton Shape benchmark REFERENCES 1] Rakesh Agrawal , Ramakrishnan Srikant, Fast Algorithms for Mining Association Rules in Large Databases, Proceedings of the 20th International Conference on Very Large Data Bases, p.487-499 September 12-15, 1994 2] Mohammed J. Zaki, Member, IEEE, and Ching-Jui Hsiao Efficient Algorithms for Mining Closed Itemsets and Their Lattice Structure IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING VOL. 17, NO. 4, APRIL 2005 3] A. Baskurt, F. Blum, M. Daoudi, J.L. Dugelay, F. Dupont, A. Dutartre 


T. Filali Ansary, F. Fratani, E. Garcia, G. Lavou, D. Lichau, F. Preteux J. Ricard, B. Savage, J.P. Vandeborre, T. Zaharia. SEMANTIC-3D COMPRESSION, INDEXATION ET TATOUAGE DE DONNES 3D Rseau National de Recherche en Tlcommunications \(RNRT 2002 4] T.Zaharia F.Prteux, Descripteurs de forme : Etude compare des approches 3D et 2D/3D 3D versus 2D/3D Shape Descriptors: A Comparative study 5] T.F.Ansary J.P.Vandeborre M.Daoudi, Recherche de modles 3D de pices mcaniques base sur les moments de Zernike 6] A. Khothanzad, Y. H. Hong, Invariant image recognition by Zernike moments, IEEE Trans. Pattern Anal. Match. Intell.,12 \(5 1990 7] Agrawal R., Imielinski T., Swani A. \(1993 between sets of items in large databases. In : Proceedings of the ACM SIGMOD Conference on Management of Data, Washington DC, USA 8] Hbrail G., Lechevallier Y. \(2003 In : Govaert G. Analyse des donnes. Ed. Lavoisier, Paris, pp 323-355 9] T.F.Ansary J.P.Vandeborre M.Daoudi, une approche baysinne pour lindexation de modles 3D base sur les vues caractristiques 10] Ansary, T. F.   Daoudi, M.   Vandeborre, J.-P. A Bayesian 3-D Search Engine Using Adaptive Views Clustering, IEEE Transactions on Multimedia, 2007 11] Ansary, T.F.   Vandeborre, J.-P.   Mahmoudi, S.   Daoudi, M. A Bayesian framework for 3D models retrieval based on characteristic views, 3D Data Processing, Visualization and Transmission, 2004 3DPVT 2004. Proceedings. 2nd International Symposium Publication Date: 6-9 Sept. 2004 12] Agrawal R., Srikant R., Fast algorithms for mining association rules in larges databases. In Proceeding of the 20th international conference on Very Large Dada Bases \(VLDB94 September 1994 13] U. Fayyad, G.Piatetsky-Shapiro, and Padhraic Smyth, From Data Mining toKnowledge Discovery in Databases, American Association for Artificial Intelligence. All rights reserved. 0738-4602-1996 14] S.Lallich, O.Teytaud,  valuation et validation de l'intrt des rgles d'association 15] Osada, R., Funkhouser, T., Chazelle, B. et Dobkin, D. \(\( Matching 3D Models with Shape Distributions International Conference on Shape Modeling & Applications \(SMI 01 pages 154168. IEEE Computer Society,Washington, DC, Etat-Unis 2001 16] W.Y. Kim et Y.S. Kim. A region-based shape descriptor using Zernike 


moments. Signal Processing : Image Communication, 16 :95100, 2000 


And put forward that we could use confidence, category homoplasy and relevancy strength to improve the quality of feature extension modes. We also verified that confidence category homoplasy and relevancy strength are effective through our experiments. In the same time we have drawn the following conclusions: \(1 relationships for short-text can improve their classification performance; \(2 effectiveness of information in the feature extension mode library we should choose the suitable thresholds; \(3 information is too small to meet the demand of short-text feature extension. So we should find out a perfect method which can increase information coverage in the feature extension mode library for short-text classification; \(4 extension library for short-text extension effectively, i.e., choosing a perfect feature extension strategy is also our further work ACKNOWLEDGMENT The research is supported in part by the National Natural Science Foundation of China under grant number 60703010 the Nature Science Foundation of Chongqing province in China under grant number CSTC, 2009BB2079, and the Scientific Research Foundation for the Returned Overseas Chinese Scholars of Ministry of Education of China under grant number [2007] 1109 REFERENCES 1] Fabrizio Sebastiani.Machine Learning in Automated Text Categorization, A.ACM Computing Surveys, C.2002.34\(1 2] Fan Xing-hua,Wang peng. Chinese Short-Text Classification in TwoStep, J.Journal of DaLian Maritime Universtiy, 2008,11\(2 3] Zelikovitz S. and Hirsh H. Improving Short Text Classification Using Unlabeled Background Knowledge to Assess Document Similarity C. In: Proceedings of ICML-2002, 2002, 1183-1190 4] Wang Xi-wei,Fan Xing-hua and Zhao Jun. A Method for Chinese Short Text Classification Based on Feature Extension, J.Journal of Computer Applications,2009,29\(3 5] JIAWEI HAN,JIAN PEI ,YIWEN YIN, BUNYING MAO.Ming Frequent Patterns without Candidate Generation:A Frequent-Pattern Tree.Data Mining and Knowledge Discovery,2004,8:53-87 6] Liu Fei. Huang Xuan-qing and Wu Li-de.Approach for Extracting Thematic Terms Based on Association Rule, J.Computer Engineering,2008\(4 7] Xinhua Fan, Jianyun Nie. Link Distribution Dependency Model for 


Document Retrieval, C.Journal of Information and Computational Science6:3\(2009  90 


shows that proposed post mining of association rule mining technique for missing sensor data estimation is an area worth to explore REFERENCES 1] Agrawal, R., & Imielinski, T., & Swami, A., "Mining association rules between sets of items in massive databases", International Conference on Management of Data, 1993 2] Austin, F. I., "Austin Freeway ITS Data Archive", Retrieved January 2003 from http://austindata.tamu.eduidefauIt.asp 3] Bastide, Y., & Pasquier, N., & Taouil, R, & Stumme, G., & Lakhal L., "Mining minimal non-redundant association rules using frequent closed itemsets", First International Conference on Computational Logic, 2000 4] Cool, A. L., "A review of methods for dealing with missing data The Annual Meeting of the Southwest Educational Research Association, 2000 5] Deshpande, A., & Guestrin C., & Madden, S., "Using probabilistic models for data management in acquisitional environments", The Conference on Innovative Data Systems Research, 2005 6] Halatchev, M., & Gruenwald, L., "Estimating missing values in related sensor data streams", International Conference on Management of Data, 2005 7] Iannacchione, V. G., "Weighted sequential hot deck imputation macros", Proceedings of the SAS Users Group International Conference, 1982 8] Nan Jiang, "Discovering Association Rules in Data Streams Based On Closed Pattern Mining", SIGMOD Ph.D. Workshop on Innovative Database Research, 2007 9] Li, Y., & Liu, Z. T., & Chen, L., & Cheng, W., & Xie, C.H Extracting minimal non-redundant association rules from QCIL The 4th International Conference on Computer and Information Technology, 2004 10] Little, R 1. A., & Rubin, D. B., "Statistical analysis with missing data", New York: John Wiley and Sons, 1987 II] McLachlan, G., & Thriyambakam, K., "The EM algorithm and extensions", New York: John Wiley & Sons, 1997 12] Mitchell, T., "Machine Learning", McGraw Hill, 1997 13] Papadimitriou, S., & Sun, 1., & Faloutsos, C., "Streaming pattern discovery in multiple time-series", The International Conference on Very Large Databases, 2005 14] Rubin, D., "Multiple imputations for nonresponce in surveys", New York: John Wiley & Sons, 1987 


15] Shafer, 1., "Model-Based Imputations of Census Short-Form Items In Proceedings of the Annual Research Conference, 1995 16] Taouil, R., & Pasquier, N., & Bastide, Y., & Lakhal, L., "Mining bases for association rules using closed sets", International Conference on Data Engineering, 2000 17] Wilkinson & The AP A Task Force on Statistical Inference, 1999 18] Zaki, M. 1., Hsiao, C. 1., "Efficient algorithms for mining closed itemsets and their lattice structure", IEEE Transactions on Knowledge and Data Engineering, 2005 V5-106 


General Chair f!!\f  Organizing Chairs  f!!\f  f$% \f!!\f  Organizing Co-chairs f    f  f\f   f\f\f   f*!\f!\f.\f  f f  Program Committee Chairs  f\f\f   f!!\f  Publication Chair 0   


200 250 300  The size of dataset/10,000 R es po ns e tim e S    a 0 50 100 150 200  The size of dataset/10,000 R es po ns e tim e S    b 0 10 20 30 40 50 


60  The size of dataset/30,000 R es po ns e tim e S    c Fig. 9 The scalability of our algorithm compared with FP-growth  Paper [12] proposed a way to reduce times of scanning transaction database to reduce the cost of I/O IV. CONCLUSIONS AND FUTURE WORK This paper first discusses the theory of foundations and association rules and presents an association rules mining algorithm, namely, FP-growth algorithm. And then we propose an improved algorithm IFP-growth based on many association rules mining algorithms. At last we implement the algorithm we propose and compare it with algorithm FPgrowth algorithm. The experimental evaluation demonstrates its scalability is much better than algorithm FP-growth 177 Now, lets forecast something we want to do someday Firstly, we would parallelize our algorithm, because data mining needs massive computation, and a parallelable environment could high improve the performance of the algorithm; Secondly, we would apply our algorithm on much more datasets and study the run performance; At last, we would study the performance when the algorithm deal with other kinds of association rules  REFERENCES 1] S. Sumathi and S. N. Sivanandam. Introduction to Data Mining and its Applications, Springer, 2006 2] V. J. Hodge, J. Austin, A survey of outlier detection 


methodologies, Artificial Intelligence Review, 2004, 22 85-126 3] Han, J. and M. Kamber. Data Mining: Concepts and Techniques. Morgan Kaufmann, San. Francisco, 2000 4] Jianchao Han, Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases, Journal of Advanced Computational Intelligence and Intelligent Informatics 2006, 10\(3 5] Jiuyong Li, Hong Shen, Rodney Topor. Mining Informative Rule Set for Prediction. Journal of Intelligent Information Systems, 2004, 22\(2 6] Jianchao Han, and Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases. Journal of Advanced Computational Intelligence, 2006, 10\(3 7] Doug Burdick, Manuel Calimlim, Jason Flannick Johannes Gehrke, Tomi Yiu. MAFIA: A Maximal Frequent Itemset Algorithm. IEEE Transactions on Knowledge and Data Engineering, 2005, 17\(11 1504 8] Assaf Schuster, Ran Wolff, Dan Trock. A highperformance distributed algorithm for mining association rules. Knowledge and Information Systems, 2005, 7\(4 458-475 9] Mohammed J. Zaki. Mining Non-Redundant Association Rules. 2004, 9\(3 10] J.Han, J.Pei, Y.Yin, Mining frequent patterns without candidate generation, Proceedings ACM SIGMOD 2000 Dallas, TX, May 2000: 1-12 11] P.Viola, M.Jones. Rapid Object Detection Using A Boosted Cascade of Simple Features. Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 2001 12] Anthony K. H. Tung, Hongjun Lu, Jiawei Han, Ling FengJan. Efficient Mining of Intertransaction Association Rules. 2003, 154\(1 178 


For each vertex b in g form j forests body\(a, g, i s.t. bodyAnt\(a, g, i a, g, i with itemsets Ant\(b b and each subset of itemsets Ant\(b b in P\(a, g, j Assign to each leaf l of trees bodyAnt\(a, g, i bodyCons\(a, g, i a fresh variable Vm,M, m, M = size\(itemset\(l Assign to each leaf l of tree headAnt\(a, g, j the variable assigned to itemset l in some leaf of some tree bodyCons\(a, g, i TABLE II.  EXPERIMENTAL DATA Conf. #rules #pruned #dftrs PtC 0.5 6604 2985 1114 0.6 2697 2081 25 0.75 1867 1606 10 0.8 1266 1176 0 0.95 892 866 1 0.98 705 699 1 DSP 0.5 2473 1168 268 0.6 1696 869 64 0.75 1509 844 89 0.8 1290 1030 29 0.95 1032 889 15 0.98 759 723 1 Arry 0.5 770 492 82 0.6 520 353 60 0.75 472 327 39 0.8 408 287 22 0.95 361 255 25 0.98 314 243 30  Our induction algorithm has been launched for each combination of thresholds. Our scheme eliminates all redundant rules in the sense of [25, 31], i.e. those association rules that are not in the covers. All the meta-rule deductive schemes implicitly included in [25] and [31] are induced by our method. The percentage of pruning, thus, outperforms [25 


The results produced for k=3, support 0.25 and confidences between 0.7 and 0.99 are shown in Fig. 3, in terms of pruning percentage \(vertical axis when applied to low confidences \(from 0.7 to 0.9 The percentage of pruning achieved diminishes as the confidence is superior to 0.9. Nevertheless, the pruning is effective with confidence of 0.99 in the majority of cases Pruning at Support = 0.25 0,00 5,00 10,00 15,00 20,00 25,00 30,00 35,00 40,00 45,00 50,00 0,7 0,8 0,9 0,95 0,99 Confidence P ru n in g L e v e l Case 1 Case 2 Case 3  Figure 3.  Pruning experiences at support 0.25  V. DISCUSSION AND CHALLENGES It is important to discuss the technique presented here with focus on the purpose the technique pursues:  to produce semantic recommendation The reader should have noticed that the algorithm presented 


relies strongly on "choice". For instance, the algorithm chooses ears in the graph to form an order for elimination, and the choice is arbitrary. This strategy is essential to maintain low complexity \(polynomial practical. Nevertheless, a warned reader may conclude that this arbitrary choice implies that there are many compactions to produce and therefore the approach as a whole does not show to produce an optimal solution. And the reader is right in this conclusion. Since the goal is compaction, the search for an optimal solution can be bypassed provided a substantial level of pruning is achieved To complete the whole view, we describe how web service descriptions are complemented with the association rules as recommendations. In effect, under our scheme, the document describing the web service is augmented with a set of OWL/RDF/S triples that only incorporate the non-pruned rules with the format of Example 1, that is, the set ARmin of the compaction program obtained by our algorithm, together with the thresholds applied to the mining process and a registered URI of a registered description service. The assumptions and defeaters are not added to the web service description. If the associations encoded in the triples are not sufficient for the client \(a search engine, for instance widening of the response to the description service identified by the given URI, and then the assumptions and defeaters are produced. The reasoning task required for deriving all the implicitly published rules is client responsibility Notice that, under this scheme, the actual rules that appear as members of the set initial ARmin set are irrelevant; the only important issue is the size of the set The developed scheme also supports an extension of the algorithm that admits the assignment of priorities to rules and to itemsets, in order to allow the user to produce a more controlled program as output. Nonetheless, the importance of the extension has not been already tested, and therefore it is beyond the subject of the present paper It would be also interesting to design a scheme that supports queries where the client provides an itemset class and values for support and confidence and the engine produces a maximal class of inferred associated itemsets as a response. This scheme is also under development, so we have not discussed this aspect here 


VI. CONCLUSION In this paper, we have presented a defeasible logic framework for managing associations that helps in reducing the number of rules found in a set of discovered associations. We have presented an induction algorithm for inducing programs in our logic, made of assumption schemas, a reduced set of association rules and a set of counter-arguments to conclusions called defeaters, guaranteeing that every pruned rule can be effectively inferred from the output. Our approach outperform those of [17], because all reduction compactions presented there can be expressed and induced in our framework, and several other patterns, particular to the given datasets, can also be found. In addition, since a set of definite clauses can be obtained from the induced programs, the knowledge obtained can be modularly inserted in a richer inference engine Abduction can be also attempted, asking for justifications that explain the presence of certain association in the dataset The framework presented can be extended in several ways Admitting defeaters to appear in the head of assumption, to define user interest Admitting arithmetic expressions within assumptions for adjustment in pruning Admitting set formation patterns as itemset constants Extending the scope, to cover temporal association rules REFERENCES 1]  R. Agrawal, and R. Srikant: Fast algorithms for mining association rules In Proc. Intl Conf. Very Large Databases. \(1994 2]  A. V. Aho, J. E. Hopcroft, J. Ullman. The design and analysis of computer algorithms, Addison-Wesley, 1974 3]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher, A. Rock: A Family of Defeasible Reasoning Logics and its Implementation. ECAI 2000: 459-463 4]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher: Representation results for defeasible logic. ACM Trans. Comput. Log. 2\(2 2001 5]  A. Basel, A. Mahafzah, M. Al-Badarneh: A new sampling technique for association rule mining, Journal of Information Science, Vol. 35, No. 3 358-376 \(2009 6]  R. Bayardo and R. Agrawal: Mining the Most Interesting Rules. In Proc of the Fifth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 145-154, \(1999 


7]  R. Bayardo, R. Agrawal, and D. Gunopulos: Constraint-based Rule Mining in Large, Dense Databases. Data Mining and Knowledge Discovery Journal, Vol. 4, Num-bers 2/3, 217-240. \(2000 8]  A. Berrado, G. Runger: Using metarules to organize and group discovered association rules. Data Mining and Knowledge Discovery Vol 14, Issue 3. \(2007 9]  S. Brin, R. Motwani, J. Ullman, and S. Tsur: Dynamic itemset counting and implication rules for market basket analysis. In Proc. ACMSIGMOD Intl Conf. Management of Data. \(1997 10] L. Cristofor and D.Simovici: Generating an nformative Cover for Association Rules. In ICDM 2002, Maebashi City, Japan. \(2002 11] Y. Fu and J. Han: Meta-rule Guided Mining of association rules in relational databases. In Proc. Intl Workshop on Knowledge Discovery and Deductive and Object-Oriented Databases. \(1995 12] B. Goethals, E. Hoekx, J. Van den Bussche: Mining tree queries in a graph. KDD: 61-69. \(2005 13] G. Governatori, D. H. Pham, S. Raboczi, A. Newman and S. Takur: On Extending RuleML for Modal Defeasible Logic. RuleML, LNCS 5321 89-103. \(2008  14] G. Governatori and A. Stranieri. Towards the application of association rules for defeasible rules discovery In Legal Knowledge and Information Systems, JURIX, IOS Press, 63-75. \(2001 15] J. Han, J. Pei and Y. Yin: Mining frequent patterns without candidate generation. In Proc. ACM-SIGMOD Intl Conf. Management of Data 2000 16] C. Hbert, B. Crmilleux: Optimized Rule Mining Through a Unified Framework for Interestingness Measures. DaWaK: LNCS 4081, 238247. \(2006 17] E. Hoekx, J. Van den Bussche: Mining for Tree-Query Associations in a Graph. ICDM 2006: 254-264 18] R. Huebner: Diversity-Based Interestingness Measures For Association Rule Mining. Proceedings of ASBBS Volume 16 Number 1, \(2009 19] B. Johnston, Guido Governatori: An algorithm for the induction of defeasible logic theories from databases. Proceedings of the 14th Australasian Database Conference, 75-83. \(2003 20] P. Kazienko: Mining Indirect Association Rules For Web Recommendation. Int. J. Appl. Math. Comput. Sci., Vol. 19, No. 1, 165 186. \(2009 21] M. Klemettinen, H. Mannila, P. Ronkainen, H. Toivonen, and A Verkamo: Finding interesting rules from large sets of discovered association rules. In Proc. 3rd Intl Conf. on Information and Knowledge 


Management. \(1994 22] M. J. Maher, A. Rock, G. Antoniou, D. Billington, T. Miller: Efficient Defeasible Reasoning Systems. International Journal on Artificial Intelligence Tools 10\(4 2001 23] C. Marinica, F. Guillet, and H. Briand: Post-Processing of Discovered Association Rules Using Ontologies. The Second International Workshop on Domain Driven Data Mining, Pisa, Italy \(2008 24] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal: Closed sets based discovery of small covers for association rules. In Proc. BDA'99 Conference, 361-381 \(1999 25] N. Pasquier, R. Taouil, I. Bastide, G. Stume, and  L. Lakhal: Generating a Condensed Representation for Association Rules. In Journal of Intelligent Information Systems, 24:1, 29-60 \(2005 26] P. Pothipruk, G. Governatori: ALE Defeasible Description Logic Australian Conference on Artificial Intelligence.  110-119 \(2006 27] J. Sandvig, B. Mobasher Robustness of collaborative recommendation based on association rule mining, Proceedings of the ACM Conference on Recommender Systems \(2007 28] W. Shen, K. Ong, B. Mitbander, and C. Zaniolo: Metaqueries for data mining. In Fayaad, U. et al. Eds. Advances in Knowledge Discovery and Data Mining. \(1996 29] I. Song, G. Governatori: Nested Rules in Defeasible Logic. RuleML LNCS 3791, 204-208 \(2005 30] H. Toivonen, M. Klemettinen, P. Ronkainer, K. Hatonen, and H Mannila: Pruning and grouping discovered association rules. In ECML Workshop on Statistics, Machine Learning and KDD. \(1995 31] M. Zaki: Generating Non-Redundant Association Rules. In Proc. of the Sixth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 34-43, \(2000 32] w3c. OWL Ontology Web Language Reference. In http://www.w3.org/TR/2004/REC-owl-ref-20040210 33] w3c. RDF/XML Syntax Specification. In: http://www.w3.org/TR/rdfsyntax-grammar 34] w3c. RDF Schema. In: http://www.w3.org/TR/rdf-schema      


 8   2  3\f            8  D    F  \b 1 8 & #J      b 1  1  4    2  


4 1    9  E 1  2 4 1    9 1   4      8 2  8 1  D 1        1 1  b 


     b b b b b  K            8          2 D 9   F  \b 1 8 ,+J  9 


     b 1     1 2  9 1  12 L 1   9  8       1  2      2   


     b b b b b  K            2  0 \b f  b\f      9       


  8 2   E 1   1     M13 31L 1    b  8E 1   1 #3\b?### 1  1     E 1   1 \b?###3        


1   1   b 1  2 2 18 2     8              1    2 \b 1    2  


    2          2   1 L 2 1   1   L 2 2    2 1  2        


    8  2H D \b A             2  2H D \b A 2 \f 3%\f  f   4%\f f !  , \f\b  C    2    2 


 6    3 1      253 6   1 L 2    6   1         f\b3\f       


               1     1     8 2    E       2  1   


     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



Detecting Resource Leaks through Dynamical Mining of Resource Usage Patterns Huxing Zhang 003  Gang Wu 003  Kingsum Chow y  Zhidong Yu y  and XueZhi Xing y 003 School of Software Shanghai Jiao Tong University Shanghai 200240 China f ralf0131 wugang@cs g sjtu.edu.cn y Intel Corporation f kingsum.chow zhidong.yu xuezhi.xing g intel.com Abstract 227Resource management is crucial to software productions Resources must be carefully acquired and released or a resource leak might occur For open source projects resource leaks can be easily introduced during code checkin and it is laborious to review identify report and 002x such leaks Recently there has been a growing interest in data mining API usage patterns to discover potential bugs such as resource leaks However the usage patterns mined are speci\002c to a certain library which cannot be applied to detect bugs in other libraries In this paper we present an idea called MODE 223Mine Once Detect Everywhere\224 to address the universality of such patterns and use them to detect potential resource leaks automatically before code check-in We propose an ef\002cient algorithm to record the most valuable API calls that are related to resource usage during program execution and mine resource usage patterns from the traces with a sequence miner To verify the effectiveness of the patterns experiments are given to use them to detect real resource leaks in large open source projects Keywords Resource Leak Detection Data Mining Dynamical Analysis I I NTRODUCTION Resource management is crucial to software productions Resources such as 002le handlers database connections and locks must be carefully acquired and released For example a 002le on a hard drive must be eventually closed after being opened If a resource is not correctly released a resource leak is likely to occur A recent study 1 shows that 86 of downtime in production systems was due to resource leaks including memory leaks 002les not closed locks that aren't released and so on Even a little leak can bring down the production system if it occurs many times Unfortunately it is dif\002cult to manage resources automatically Although some advanced languages such as Java and C provide ef\002cient garbage collection to aid programmers in managing memory objects to acquire or release other resources it still needs to explicitly call APIs provided by third party software libraries or low level systems For example the Oracle 9i JDBC Developer's Guide and Reference 1 http://www.javaperformancetuning.com/news/news116.shtml  w arn 223If you do not e xplicitly close your ResultSet and Statement objects serious memory leaks could occur.\224 Normally these resource usage APIs could be summarized as resource usage patterns and any violation to the patterns can be inferred as a resource leak However these resource usage patterns are not easy to extract due to their uniqueness complexity and lack of documentation Usually only those who have prior knowledge can summarize them For open source projects resource leaks can be easily introduced during code check-in It has been recognized that code refactoring is a leading cause of introducing resource leaks Careless developers may concentrate on improving functionality while forget to check the resource usage upon check-in Therefore it is laborious to review identify report and 002x such leaks For example it took 23 days and 87 project revisions to 002x an IO resource leak LUCENE2106 2  in Apache Lucene To tackle these problems a wide spectrum of research has been done in data mining API usage patterns from source codes  e x ecution traces 8]\226[10 or documentation  and use them to detect b ugs such as resource leaks Mining from source codes which is usually called static mining offers a fast and automatic way to discover resource usage patterns without program execution However it is not able to capture resource usage precisely which is likely to bring false positives Relati v ely  dynamic mining from execution traces could solve such problem but the execution trace can be incredibly huge For example the complete execution trace size for Apache Tomcat 7.0.5 startup is 325,391 KB and it contains 6,054,030 calls in total The processing time of such large traces is unacceptable In addition the usage patterns mined by both static and dynamic mining approaches are speci\002c to a certain library therefore the impact is limited as the patterns cannot be applied to detect bugs in other libraries In this paper we present an idea called MODE 223Mine Once Detect Everywhere\224 to address the universality of such patterns We found that most application resource leaks 2 http://issues.apache.org/jira/browse/LUCENE-2106 


could eventually be attributed to violation of some base API usage patterns i.e standard Java API usage pattern Once these patterns are mined they could be used to detect resource leak in any program that built upon the base API To achieve this goal we propose MODEJ an approach to detect resource leaks in Java programs First we record standard Java API calls during program execution In order to minimize the execution trace size and processing time we develop an ef\002cient algorithm to record the most valuable Java API calls the outermost layer of Java API calls which will be elaborated later that are related to resource usage Second we perform a sequential data mining on the calls we recorded to extract resource usage patterns Finally we verify these patterns with real resource leak issues from Apache Software Repository.We reproduce the leaks with existing test cases record the traces and check if any violation to the patterns is inferred from the traces The result shows that our approach is able to detect resource leak issues that are dif\002cult to identify in various projects The remainder of this paper is organized as follows Section II gives an example to illustrate our approach Section III introduces the detailed approach Experiments are given in Section IV Section V reviews related work and Section VI concludes the paper II M OTIVATIONAL E XAMPLES In this section we give an motivational example to showcase that how we are able to detect an real world resource leak issue CASSANDRA-313 3 using the pattern we mined.CASSANDRA-313 is a 002le descriptor leak issue which causes Cassandra to eventually crash due to too many open 002les One of the developers reports that a 002le descriptor is not closed at each memtable rotation We further investigated the issue and found that it was introduced due to a source code check-in in revision 789465 which refactored several lines of codes in order to make sure only one part of codes was writing logs to disk However it forgot to close a temporary object logWriters  which caused the leak More importantly the object was correctly closed before this check-in Fig 1 Fix of resource leak issue CASSANDRA-313 3 https://issues.apache.org/jira/browse/CASSANDRA-313 This issue was 002xed in revision 797173 after 24 days and 58 project check-ins Obviously it costs a lot of time and effort to identify and 002x the issue The leaky source code are given in Figure 1 We may infer from the code that there exists a resource usage pattern in Cassandra library 1 IFileWriter.createWriter 2 IFileWriter.close and the missing call to IFileWriter.close is a violation to such a pattern To extract this pattern mining must be performed on either Cassandra source codes or its execution traces However this patten is not applicable to discover resource leaks in other libraries because the names of classes or methods may vary Actually we ran Cassandra library revision 789465 with its unit test case org.apache.cassandra.db.CommitLogTest  analyzed the execution trace and found that IFileWriter.createWriter eventually called java.io.RandomAccessFile.open while IFileWriter.close eventually called java.io.RandomAccessFile.close in behind Therefore such a leak is essentially a violation of standard Java resource API usage pattern 1 java.io.RandomAccessFile.open 2 java.io.RandomAccessFile.close If we check the resource usage before code check-in we could eliminate the leak in advance This motivates us to extract the resource usage pattern from standard Java API calls As these patterns do not rely on any speci\002c library they are universal enough to discover resource leak on any library that written in Java III A PPROACH In this section we describe in detail the MODE approach to record the most valuable API calls mine resource usage patterns and use them to detect resource leaks Fig 2 Overview of framework Figure 2 depicts the steps in our approach First we hook into the base system/platform to intercept base API calls during program execution To minimize the trace size and processing time we proposed an ef\002cient algorithm to record the most valuable base API calls that are related to resource usage Next a sequential mining is applied on the calls recorded to extract resource usage patterns Finally the 


patterns are used to detect resource leaks in projects from large open source repository A Extract the outermost layer of base API calls In our approach we assume every project is already equipped with well-covered unit test cases which could drive a project into execution With the help of existing system pro\002ling interface\(i.e JVMTI 4  it is straightforward to generate the complete execution trace However the trace might be too huge to bear For example the complete execution trace size for Tomcat 7.0.5 startup is 325,391 KB and it contains 6,054,030 calls in total We carefully analyze the traces and 002nd that a trace can be expanded as a call tree in which each node represents a method and all the sub-methods becomes its children iteratively We name any method invocation to third-party libraries as an External Call EC while any method invocation to base API as an Internal Call IC During program execution we only care about the ICs rather than ECs However some frequently occurred children of an IC would overwhelm others in mining phase For example in Java any object initiation would eventually call java.lang.Object.init  Such a pattern is naive and would never fail thus it should be ignored In other words we only record the outermost layer of ICs De\002nition III.1 A call is de\002ned as an outermost layer of IC referred to as an outermost call if and only if it itself is an IC and its parent call is an EC Fig 3 Hierarchy of execution trace Figure 3 describes the hierarchy of an sample execution trace 030  f A B 1  C 1  D 1  C 2  B 2  C 3  B 3  C 4  D 2  C 5  D 3 g  where each red nodes with thick borders represents an EC and each black nodes with thin borders represents an IC In this case A calls B 1  B 2 and B 3  B 1 calls C 1 and C 2  B 2 calls C 3  B 3 calls C 4 and C 5  C 1 calls D 1  C 4 calls D 2  C 5 calls D 3  The outermost calls of trace 030 actually contains only 5 calls f D 1  C 2  B 2  C 4  D 3 g  Note that C 3 4 http://download.oracle.com/javase/6/docs/platform/jvmti/jvmti.html and D 2 should be eliminated because they are children of outermost call B 2 and C 4  respectively The record process is able to 002nish in linear time with several 003ags It takes in each call one by one at runtime decide whether a call is an outermost call in O\(1 time and output it if an outermost call is met Here three assistant 003ags are maintained the depth of current call CCD  the depth of last IC LICD  and the depth of deepest EC so far M ECD  We mark LICD to N U LL whenever an EC is met The idea behind is that the outermost call can only be found in two conditions a Last call is an EC and current call is an IC which should satisfy LICD  N U LL and CCD 024 M ECD  1  D 1 and C 4 in Figure 3 b Last call is an IC and current call is also an IC which should satisfy LICD 6  N U LL  CCD 024 M ECD  1  and CCD 024 LICD  C 2  B 2 and D 3 in Figure 3 B Resource Usage Pattern Mining In this phase we treat two calls that invoke the same method but from different caller objects as the same element for mining We adopt a sequential mining algorithm called AprioriAll to mine resource usage patterns because the sequence of calls in a pattern is critical AprioriAll takes in a minimal support threshold min  sup and a minimal con\002dence threshold min  conf  and outputs all frequent sequence whose support is equal to or larger than min  sup  For each frequent sequence it outputs all association rules whose con\002dence is equal to or larger than min  conf  An association rule indicates temporal relationship among different calls in a resource usage pattern C Resource Leak Detection In this phase we develop a rule checker to detect violation to the association rules we mined A violation occurs if the pre-condition of an association rule is satis\002ed while the post-condition is not Such violation indicates potential resource leaks The rule checker works as follows For each trace check all the association rules For each association rule if the trace contains the pre-condition but does not contain the post-condition a violation is reported IV E XPERIMENTAL R ESULTS To evaluate the effectiveness and ef\002ciency of our approach we have implemented MODEJ which consists of a outermost Java API call tracer based on JVMTI a sequential miner and a rule checker in Java We apply MODEJ on 3 open source projects in Apache Commons.io 5  Lucene 6  and Cassandra 7  Commons.io is a fast and ef\002cient library of utilities to assist with developing IO functionality Lucene is a high-performance text search engine library Cassandra 5 http://commons.apache.org/io 6 http://lucene.apache.org 7 http://cassandra.apache.org 


is a highly scalable distributed NoSQL database which is open-sourced in 2008 by Facebook For each project we randomly pick up a revision check out the source codes and run their unit test cases along with our tracer to record outermost call traces We apply our sequence miner on the traces to discover resource usage patterns To verify these patterns we choose other speci\002c project revisions which contains previous-known resource leak bugs We reproduce the leaks with existing test cases yield leaky trace using our tracer and feed them to our rule checker to see whether those leaks can be reported A Tracer Performance and Result We have developed a complete tracer which records every single call during program execution to compare with our outermost call tracer We startup Tomcat 7.0.5 along with both two tracers and measure the running time trace size and the number of calls recorded Note that we directly skip some undesired calls such as java.lang.Classloader  junit.framework.Assert  etc The programs are run on a Microsoft Windows XP Professional with Intel\(R Core\(TM Duo CPU E8500  3.16 GHz and 3.46 GB memory TABLE I T RACER P ERFORMANCE R ESULT  T OMCAT STARTUP  Tracer Execution time\(ms  of calls Trace size\(KB  Complete tracer 161,296 325,391 6,054,030 Outermost call tracer 44,214 35,718 1,088,547 Delta change 72.6 82.0 89.0  The result is described in Table I The execution time the number of calls recorded and trace size are shown in the second third and fourth column respectively The result shows that our outermost call tracer completely outperforms the complete tracer It is 72.6 percent faster than the complete tracer Besides the trace size and the number of calls recorded are over 80 percent smaller than that of complete tracer Afterwards we record the outermost trace for each project with existing test cases Table II shows the tracing result Column 223 Version 224 lists the revision number Column 223 LOC 224 lists the total line of codes Column 223 TC 224 lists the total number of test cases Column 223 TCV 224 lists the number of valid test cases A valid test case is a successfully 002nished test case with a non-empty sized outermost call trace Column 223 TrSize 224 lists the total outermost call trace size B Mining Performance and Result In the experiments we mine resource usage patterns on Java IO API\(IO and Java Concurrent API\(CONC which are two subsets of standard Java API Our mining experiment is conducted on the following scenarios TABLE II P ROJECT REVISIONS AND THE TRACE RESULT  Project Version LOC TC TCV TrSize  Commons.io 805996 25,142 78 56 81MB Lucene 478241 116,485 94 74 599MB Cassandra 954571 70,282 74 60 149MB  017 Given min  conf  0.8 with the increase of min  sup  collect the running time the number of patterns mined and the number of rules generated for both IO and CONC pattern mining 017 Given min  sup  0.038 with the increase of min  conf  collect the running time and the number of rules generated for IO pattern mining a Java IO API usage pattern mining result min  conf 0.8 b Java Concurrent API usage pattern mining result min  conf 0.8 c Java IO API association rule generation result min  sup 0.038 Fig 4 Mining Performance and Result The results are shown in Figure 4 We can observe from Figure 4\(a and 4\(b that the mining time the number of patterns and the number of association rules all decrease with the increase of min  sup  Besides the number of patterns would be exponentially large if min  sup is below 0.033 for IO patterns and 0.22 for CONC patterns With the same order of magnitude of running time the min  sup of IO patterns is lower than that of CONC patterns probably 


because of the multiplicity of Java IO APIs over Java Concurrent APIs Note that the y-axis of the left 002gure of Figure 4\(a and 4\(b is in logarithmic scale For IO association rule generation Figure 4\(c shows that the running time grows in a small range of 003uctuation with the increase of min  conf  It can be inferred that pattern mining dominate the whole process rather than rule generation On the other hand the number of rules generated gets approximately linear decrease with the increase of min  conf  Figure 5 shows some interesting resource usage patterns mined Note that the numbers indicates their temporal relationship Fig 5 Resource Usage Pattern Examples C Verifying Result To verify the mined patterns we have identi\002ed 7 IO related resource leak issues from bug tracking systems of Cassandra and Lucene For each issue we learn when it is introduced when it is 002xed how many revisions and how long time it takes to 002x the issue We check out the buggy project revision run the causing test case and generate leaky trace using our tracer Then we feed the leaky trace to our rule checker The ruler checker takes in the rules as well as the leaky traces and checks for violations We calculate the number of issues that has been detected as well as the number that has not been detected For those issues that have not been detected we analyzes why they have not been detected The results are listed in table III For each issue the second column re\003ects the revision when it is introduced while the third column describes the revision when it is 002xed The 223 RP 224 Column lists the total number of project revisions it takes to 002x it The 223 Duration 224 Column gives its duration The sixth column lists the 002les that are polluted The seventh column explains it in natural language The last column shows whether it is detected or not From the table we have the following observations First the duration of listed issues vary a great deal It is to our surprise that the average  RP and durations for the 7 issues are 385 and 377 days respectively In the worst case it takes 2295 revisions and 2527 days to 002x issue LUCENE1455 although it is a simple stream not close leak Second among 7 issues 4 are detected 2 are partially detected and 1 is not detected In the 4 detected issues CASSANDRA313 LUCENE-720 and LUCENE-1374 eventually violate the rule 1 java.io.RandomAccessFile.open  java.io.RandomAccessFile.close and LUCENE-1455 eventually violates the rule 1 java.io.File.<init 2 java.io.FileInputStream.<init  java.io.FileInputStream.close CASSANDRA-71 and CASSANDRA-1188 are also attributed to missing of java.io.RandomAccessFile.close  However we are not able to genereate the leaky trace by running any of CASSANDRA's unit test case Therefore we have to manually design a test case to reproduce it We regard these issues as partially detected In this case our approach is not competitive because designing such test case requires manual work and might be tricky For issue LUCENE-2106 we have successfully generated the leaky trace by running its test case However no violation to any of our rules is reported We studied the trace carefully and found that rather than calling a java.io.Reader object in standard Java API LUCENE itself has implemented a reader class that has the same functionality as java.io.Reader  Therefore no standard Java resource API usage pattern is violated which means our approach is not applicable in this case V R ELATED W ORK To mine API usage DynaMine analyzes source code check-ins to 002nd highly correlated method call pairs Michail et al mine library reuse patterns using gener alized association rules PR-Miner uses frequent item set mining to extract implicit programming rules such as functions variables and data types MAPO uses code search engines to gather source 002les and mines sequential usage patterns to a given query Kagdi et al mine frequently appearing ordered sets patterns of function-call usages considering control constructs such as if-statements Acharya et al present a frame w ork to automatically extract usage scenarios among user-speci\002ed APIs as partial orders Williams et al mine source code repository to detect a commonly 002xed bug Chow et al conduct an empirical study to evaluate the effectiveness of data mining software code defects in large software repository To infer speci\002cations Yang et al introduce a technique to dynamic infer alternating patterns from execution traces Zhong et al infer resource usage speci\002cations from natural language API documentations Gabel et al  propose a symbolic algorithm based on binary decision diagrams to mine temporal speci\002cations from execution traces Igarashi et al formalize a general problem of analyzing resource usage and propose a type-based solution to the problem Lo et al propose a speci\002cation mining architecture with trace 002ltering and clustering to improve 


TABLE III R ESOURCE L EAK I SSUES FROM BUG TRACKING SYSTEM AND V ERIFYING R ESULT  Issue i RI RF RP Duration Affected Files Description Detected  LUCENE-720 478239 478241 1 1days org.apache.lucene.index TestIndexFileDeleter.java org.apache.lucene.index TestBackwardsCompatibility.java added a few missing close's Yes LUCENE-1374 691617 691694 1 1days org.apache.lucene.index TestIndexWriter.java Cannot 002nd close method so this looks like a descriptor leak Yes LUCENE-1455 150802 783595 2295 2527days org.apache.lucene.ant.HtmlDocum ent.java A stream is not closed which may be a descriptor leak Yes LUCENE-2106 836154 887899 87 23days org.apach.lucene.benchmark byTask.tasks.ReadTask.java ReadTask does not close its Reader when OpenReader or CloseReader are not used No CASSANDRA-71 769874 770424 10 1days org.apache.cassandra.db Table.java Close FileStructs after range query Partially CASSANDRA-313 789465 797173 58 24days org.apache.cassandra.db 002lter.CommitLog.java Close temporary logWriters to avoid leaking FD Yes CASSANDRA-1188 932431 954572 246 67days org.apache.cassandra.db.\002lter SSTableNamesIterator.java Close FileStruct in SSTableNamesIterator when opened locally Partially  i https://issues.apache.org/jira/browse/ISSUE  NAME speci\002cation miners Weimer et al present an automatic speci\002cation mining algorithm that uses information about error handling to learn temporal safety rules Kremenek et al use Bayesian learning to match methods with a prede\002ned automata template for speci\002cations J Bloch from Google proposes a new Java 7 feature called Automatic Resource Managements ARM 8  which aims at automatically close resource when it is not used With ARM a few statements would be automatically added by complier to close declared resources within a try statement This proposal is actually a syntax improvement to developers However ARM can only handle local resources leak within method scope In contrast our approach is able to report missing resource closure within class scope or across classes VI C ONCLUSION In order to improve the pattern universality and detect resource leak before code check-in this paper proposes an approach to record the most valueable base API calls during program execution and mine resource usage patterns from the API call traces The patterns are further veri\002ed with real resource leaks from large open source projects The results show that resource usage patterns mined by our approach are universal to detect resource leaks in various projects R EFERENCES 1 B Wright E Perry M Sanko and T Pfaef\003e 223Oracle 9i JDBC developer's guide and reference,\224 Tech Rep May 2002 2 B Livshits and T Zimmermann 223Dynamine Finding common error patterns by mining software revision histories,\224 in Proceedings of ESEC/FSE  2005 pp 296\226305 8 http://jnb.ociweb.com/jnb/jnbMay2010.html#arm 3 Z Li and Y Zhou 223PR-miner Automatically extracting implicit programming rules and detecting violations in large software code,\224 in Proceedings of ESEC/FSE  2005 pp 306\226315 4 H Kagdi M L Collard and J I Maletic 223An approach to mining call-usage patternswith syntactic context,\224 in Proceedings of ASE  2007 pp 457\226460 5 A Michail 223Data mining library reuse patterns using generalized association rules,\224 in Proceedings of ICSE  2000 pp 167\226176 6 M Acharya T Xie J Pei and J Xu 223Mining API patterns as partial orders from source code from usage scenarios to speci\002cations,\224 in Proceedings of ESEC/FSE  2007 pp 25\22634 7 C C Williams and J K Hollingsworth 223Automatic mining of source code repositories to improve bug 002nding techniques,\224 IEEE Transactions on Software Engineering  vol 31 pp 466\226480 June 2005 8 G Ammons R Bod 264 021k and J R Larus 223Mining speci\002cations,\224 in Proceedings of POPL  2002 pp 4\22616 9 J Yang D Evans D Bhardwaj T Bhat and M Das 223Perracotta mining temporal API rules from imperfect traces,\224 in Proceedings of ICSE  2006 pp 282\226291 10 M Gabel and Z Su 223Symbolic mining of temporal speci\002cations,\224 in Proceedings of ICSE  2008 pp 51\22660 11 H Zhong L Zhang T Xie and H Mei 223Inferring resource speci\002cations from natural language API documentation,\224 in Proceedings of ASE  2009 pp 307\226318 12 R Agrawal and R Srikant 223Mining sequential patterns,\224 in Proceedings of ICDE  1995 pp 3\22614 13 T Xie and J Pei 223MAPO Mining API usages from open source repositories,\224 in Proceedings of MSR  2006 pp 54\22657 14 K Chow X Xing Z Wu and Z Yu 223An empirical study of data mining code defect patterns in large software repositories,\224 in Proceedings of PNSQC  2009 15 A Igarashi and N Kobayashi 223Resource usage analysis,\224 ACM Transactions on Programming Languages and Systems  vol 27 pp 264\226313 March 2005 16 D Lo and S.-C Khoo 223SMArTIC Towards building an accurate robust and scalable speci\002cation miner,\224 in Proceedings of FSE  2006 pp 265\226275 17 W Weimer and G C Necula 223Mining temporal speci\002cations for error detection,\224 in Proceedings of TACAS  2005 pp 461\226476 18 T Kremenek P Twohey G Back A Ng and D Engler 223From uncertainty to belief inferring the speci\002cation within,\224 in Proceedings of the 7th OSDI  2006 pp 161\226176 


mining procedures. Our motivation in this study is to utilize the redundancy for extracting algorithm of fuzzy association rules IV. IMPROVEMENT OF APRIORI ALGORITHM BASED ON If max{Conf\(Z ? y X ? y max{CF\(Z ? y X ? y ZEQ Proof From the assumption, there exist P E Q that satisfY Con/\(P ? y X ? Y P ? y 0: CF\(X ? Y CF\(X ? y P ? Y Z ? V ZEQ 70 The necessary point in the Apriori algorithm for extracting association rules is to generate the frequent item sets efficiently Though the confidence of the association rules are calculated mally after all decision of frequent itemsets in traditional Apriori algorithm, the basic idea of our proposal is that the confidence of the rule can be calculated after each step A3 in the Apriori algorithm and used for pruning the redundant itemsets. The issue is to decide which itemset should be pruned utilizing the confidence information. Then we define "strong redundant rule" and "strong redundant itemset Confidence 1.0 2 3 4 The number of items Figure 2. Conceptual Diagram of Pruning Method Definition 2: Let X ? Y be a fuzzy association rule, where X and Yare fuzzy item sets. Let Q be Q = 2 x - X If min\(ConJ\(Z ?Y X ?Y ZEQ X ? Y strong redundant rule Let k-rule denote the rule that has k attributes\(items consequent part, and the "subset rule" denote that itemset corresponding to the rule is subset of the item set of larger rule and the consequent parts of both rules are the same set Definition 3: Let Z be a fuzzy itemset that has k items\( k>2 When all the k-rules generated from Z are strong redundant, we call the itemset Z strong redundant itemset Fig.2 shows the concept of strong redundant rule and strong redundant itemset. Since the Apriori algorithm generates the candidate itemsets in tum from l-itemsets, the pruning based 


on the redundancy should be performed simultaneously In addition to the basic Apriori algorithm, the following procedures are employed for k> I as A4 confidence of k-rule based on Lk and Lk.j AS The concept of the procedure is that the confidence value of rule should increase by increasing the number of antecedent items. In other words, the procedure is based on valid heuristics that the combination of items in antecedent part which deteriorates the confidence value will become redundant in the following iterations. We can expect reduction of computational time and redundant rules pruning by the additional procedures It should be noted that the confidence calculation in each iteration does not lead to the increase of overall calculation time in association rules mining v. NUMERICAL EXAMPLES We develop the fuzzy mining system based on the redundancy pruning and evaluate the proposed algorithms through numerical examples. We apply the system to "abalone data" available from the vcr Machine Learning Repository[7 The abalone data set consists of 4177 measured data with 1 nominal attribute and 8 continuous attributes as shown in 71 Table. I. In the experiments, the nominal attribute is transformed to the continuous attribute. Table 2\(a statistics and the fuzzy partition information of attributes are summarized in Table 2\(b wider than the actual data distribution for performance evaluation. The fuzzy partition example is shown in Fig.3. We use two types of fuzzy sets with different width, i.e. triangle type and trapezoid type. Although it is better to use the factor such as "interesting" for pruning the derived rules in addition we apply the native association rule extraction for proposed algorithm evaluation. The minimal support is set as 0.2 Table.l. Abalone Data No Input Output xl x2 x3 x4 x5 x6 x7 x8 y I 00.455 0.365 0.095 0.5140 0.2245 0.1010 0.150 15 2 00.350 0.265 0.090 0.2255 0.09 95 0.0485 0.070 7 3 2 0.530 0.420 0.135 0.6770 0.2565 0.1415 0.210 9 


4177 010710 0.555101 9511948510 9455 0.3765 10.4 95 1 12 Table.2. Statistical Information and Fuzzy Sets Settings a xl x2 x3 x4 x5 x6 x7 x8 y Min 0 0.075 0.055 0.00 0.002 0.001 0.001 0.002 I Max 2 0.815 0.650 1.13 2.826 1.488 0.760 1.005 29 b xl x2 x3 x4 x5 x6 x7 x8 y Mininum center of 0 0 0 0 0 0 0 0 0 fuzzy set Maximum center of fuzzy set 2 2 2 5 5 2 2 2 30 Number of 3 II II II II II II II 16 partitions Membersh ip Value Lk Di- X2 Membership V 0.0 2.0 Figure 3 Example of Fuzzy Partition 12000 10000 8000 6000 4000 2000 40 en d en E 30  25 0:; 20 0 15 \(1 n 


E 10 s c 1 fr/l 60000 2 s 0 50000 l ro 40000  l 4-; 30000 0 l D 20000 E s s:: 10000 <l s f0 0.7 Itemset Size Figure 4. Results by Apriori Algorithm Candidate Frequent 4 6 The number of itemsets Figure 5. Results by the Proposed Algorithm Extracted Rules Non-Redunda nt Rules 0.75 0.8 0.85 0.9 0.95 Min imal Confidence\(Threshold Figure 6. The number of extracted rules by the conventional algorithm 9 The results by standard Apriori algorithm for fuzzy association rules mining are shown in Fig.4. At around 4th item set calculation, much waste computation is fulfilled. From the results, it can be seen that the waste computation should be reduced 72 250 


Vl 200 0 <I Q d 0 0 .... 100 <I D E ::: 50 I  f0 Deleted Non-Redundant Rules ___ Deleted Rules r 0.7 0.75 0.8 0.85 0.9 0.95 Minimal Confidence\(Threshold Figure 7. The number of deleted rules by the proposed algorithm Fig.5 shows the results of reduction of itemsets by the proposed algorithm. We can see that fair itemsets are pruned by the proposed method. Fig.6 shows the number of extracted rules by the conventional Apriori algorithm. Many redundant rules are extracted as well as the necessary non-redundant rules Our issue is to restrain the extraction of redundant rules. Fig.7 shows the results of the number of deleted rules by the proposed algorithm. Some redundant rules are deleted simultaneously along with frequent itemsets extraction However, since a few non-redundant rules are also unexpectedly deleted at the lower threshold value of minimal confidence, we have to investigate further about heuristics, i.e strong redundant itemsts and relation of threshold values. It should be noted that the number of deleted rules has less dependence on the minimal confidence These results are promising in terms of computational time and redundant rules pruning. However, the improvement is limited in terms of computational time. We consider that the performance of the proposed method must be improved by applying the output field specification method[17]. We expect that the number of pruned rules becomes larger based on the specifications. Moreover, the other measures to prevent redundant rules extraction in fuzzy association rules mining 


could be applied as well as the proposed algorithm VI. CONCLUSION In this paper, we proposed a basic algorithm based on the Apriori algorithm for rule extraction utilizing redundancy of the extracted rules, in order to improve the efficiency of the association rules mining and to prune the redundant rules extracted. We also proved the redundancy defmition of the rule based on the CF\(certainty factor algorithm was evaluated through numerical experiments using benchmark data, "Abalone". From the results, the method was found to be promising in terms of computational time and redundant rule pruning. Our future plan includes sophistication of the proposed algorithm, application to the huge data mining problem, and further improvement of fuzzy association rules mining REFERENCES I] R. Srikant and R. Agrawal, "Mining Generalized Association Rules Proc. of the 21" VLDB Conf, pp.407-419, 1995 2] R. Srikant and R. Agrawal, "Mining Quantitative Association Rules in Large Relational Tables," Proc. of the ACM Corif. on Management of the Data, pp.I-12, 1996 3] G. Chen and Q. Wei, "Fuzzy Association Rules and the Extended Mining Algorithms," Iriformation Sciences, Vo1.l47, pp.20 1-228, 2002 4] H. Ishibuchi H. and T. Yamamoto, "Fuzzy Rule Selection by Data Mining Criteria and Genetic Algorithms," Proc. of Genetic and Evolutionary Computation Coriference, pp. 399-406, 2002 5] Y. Hu, R. Chen, and G. Tzeng, "Discovering Fuzzy Association Rules Using Fuzzy Partition Methods," Knowledge-Based Systems, Vol. 16 pp.137-147,2003 6] T. Watanabe and N. Nakayama, "Fuzzy Rule Extraction Based on the Mining Generalized Association Rules," Proc. of the 2003 IEEE Int Conf on Syst., Man, and Cybern., pp.2690-2695, 2003 7] UCI Machine Learning Repository: http://www ics.uci.edu/-mlearnIMLRepository.html 8] T. Watanabe, A. Kitamura, K. Higuchi, and H. Ikeda, "Intelligent Manufacturing Techniques for Quality and Process Design of Steel Plate," 2003 IEEE International Coriference on Emerging Technologies and Factory Automation Proceedings, Vol.2, pp.596-601, 2003 9] S. Shankar and T. Purusothaman, "Utility Sentient Frequent Itemset Mining and Association Rule Mining: A Literature Survey and Comparative Study," International Journal of Soft Computing Applications, Issue 4, pp.81-95, 2009 


10] M. Delgado, N. Marin, D. Sanchez, and M.-A. Vila, "Fuzzy Association Rules: General Model and Applications," IEEE Trans. on Fuzzy Systems VoU I, No.2, pp.214-225, 2003 II] M. Delgado, N. Marin, M. J. Martin-Bautista, D. Sanchez, and M.-A Vila, "Mining Fuzzy Association Rules: An Overview," Studies in Fuzziness and Soft Computing, Springer, VoU64/2005, pp.351-373 2006 12] H. Verlinde, M. De Cock, and R. Boute, "Fuzzy Versus Quantitative Association Rules: A Fair Data-Driven Comparison," IEEE Trans. on System, Man, and Cybernetics, Part B, Vol.36, No.3, pp.679-684, 2006 13] E. Hullermeier and Y. Yi, "In Defense of Fuzzy Association Analysis IEEE Trans. on System, Man, and Cybernetics, Part B, Vol.37, No.4 pp.1039-1043,2007 14] Y. C. Lee, T. P. Hong, and T. C. Wang, "Mining Fuzzy Multiple-level Association Rules under Multiple Minimum Supports," Proc. of the 2006 IEEE International Conference on Systems, Man, and Cybernetics pp.4112-4117,2006 15] A. Mangalampalli and V. Pudi, "Fuzzy Association Rule Mining Algorithm for Fast and Efficient Performance on Very Large Datasets Proc. of the 2009 IEEE International Coriference on Fuzzy Systems pp.1163-1168,2009 16] Y. Xu, Y. Li, and G. Shaw, "Concise Representations for Approximate Association Rules," Proc. of the 2008 IEEE International Coriference on Systems, Man, and Cybernetics, pp.94-IOI, 2008 17] T. Watanabe, "Mining Fuzzy Association Rules of Specified Output Field ", Proc. of the 2004 IEEE Int. Corif. on Syst., Man, and Cybern pp.5754-5759,2004 73 


General Chair f!!\f  Organizing Chairs  f!!\f  f$% \f!!\f  Organizing Co-chairs f    f  f\f   f\f\f   f*!\f!\f.\f  f f  Program Committee Chairs  f\f\f   f!!\f  Publication Chair 0   


200 250 300  The size of dataset/10,000 R es po ns e tim e S    a 0 50 100 150 200  The size of dataset/10,000 R es po ns e tim e S    b 0 10 20 30 40 50 


60  The size of dataset/30,000 R es po ns e tim e S    c Fig. 9 The scalability of our algorithm compared with FP-growth  Paper [12] proposed a way to reduce times of scanning transaction database to reduce the cost of I/O IV. CONCLUSIONS AND FUTURE WORK This paper first discusses the theory of foundations and association rules and presents an association rules mining algorithm, namely, FP-growth algorithm. And then we propose an improved algorithm IFP-growth based on many association rules mining algorithms. At last we implement the algorithm we propose and compare it with algorithm FPgrowth algorithm. The experimental evaluation demonstrates its scalability is much better than algorithm FP-growth 177 Now, lets forecast something we want to do someday Firstly, we would parallelize our algorithm, because data mining needs massive computation, and a parallelable environment could high improve the performance of the algorithm; Secondly, we would apply our algorithm on much more datasets and study the run performance; At last, we would study the performance when the algorithm deal with other kinds of association rules  REFERENCES 1] S. Sumathi and S. N. Sivanandam. Introduction to Data Mining and its Applications, Springer, 2006 2] V. J. Hodge, J. Austin, A survey of outlier detection 


methodologies, Artificial Intelligence Review, 2004, 22 85-126 3] Han, J. and M. Kamber. Data Mining: Concepts and Techniques. Morgan Kaufmann, San. Francisco, 2000 4] Jianchao Han, Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases, Journal of Advanced Computational Intelligence and Intelligent Informatics 2006, 10\(3 5] Jiuyong Li, Hong Shen, Rodney Topor. Mining Informative Rule Set for Prediction. Journal of Intelligent Information Systems, 2004, 22\(2 6] Jianchao Han, and Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases. Journal of Advanced Computational Intelligence, 2006, 10\(3 7] Doug Burdick, Manuel Calimlim, Jason Flannick Johannes Gehrke, Tomi Yiu. MAFIA: A Maximal Frequent Itemset Algorithm. IEEE Transactions on Knowledge and Data Engineering, 2005, 17\(11 1504 8] Assaf Schuster, Ran Wolff, Dan Trock. A highperformance distributed algorithm for mining association rules. Knowledge and Information Systems, 2005, 7\(4 458-475 9] Mohammed J. Zaki. Mining Non-Redundant Association Rules. 2004, 9\(3 10] J.Han, J.Pei, Y.Yin, Mining frequent patterns without candidate generation, Proceedings ACM SIGMOD 2000 Dallas, TX, May 2000: 1-12 11] P.Viola, M.Jones. Rapid Object Detection Using A Boosted Cascade of Simple Features. Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 2001 12] Anthony K. H. Tung, Hongjun Lu, Jiawei Han, Ling FengJan. Efficient Mining of Intertransaction Association Rules. 2003, 154\(1 178 


For each vertex b in g form j forests body\(a, g, i s.t. bodyAnt\(a, g, i a, g, i with itemsets Ant\(b b and each subset of itemsets Ant\(b b in P\(a, g, j Assign to each leaf l of trees bodyAnt\(a, g, i bodyCons\(a, g, i a fresh variable Vm,M, m, M = size\(itemset\(l Assign to each leaf l of tree headAnt\(a, g, j the variable assigned to itemset l in some leaf of some tree bodyCons\(a, g, i TABLE II.  EXPERIMENTAL DATA Conf. #rules #pruned #dftrs PtC 0.5 6604 2985 1114 0.6 2697 2081 25 0.75 1867 1606 10 0.8 1266 1176 0 0.95 892 866 1 0.98 705 699 1 DSP 0.5 2473 1168 268 0.6 1696 869 64 0.75 1509 844 89 0.8 1290 1030 29 0.95 1032 889 15 0.98 759 723 1 Arry 0.5 770 492 82 0.6 520 353 60 0.75 472 327 39 0.8 408 287 22 0.95 361 255 25 0.98 314 243 30  Our induction algorithm has been launched for each combination of thresholds. Our scheme eliminates all redundant rules in the sense of [25, 31], i.e. those association rules that are not in the covers. All the meta-rule deductive schemes implicitly included in [25] and [31] are induced by our method. The percentage of pruning, thus, outperforms [25 


The results produced for k=3, support 0.25 and confidences between 0.7 and 0.99 are shown in Fig. 3, in terms of pruning percentage \(vertical axis when applied to low confidences \(from 0.7 to 0.9 The percentage of pruning achieved diminishes as the confidence is superior to 0.9. Nevertheless, the pruning is effective with confidence of 0.99 in the majority of cases Pruning at Support = 0.25 0,00 5,00 10,00 15,00 20,00 25,00 30,00 35,00 40,00 45,00 50,00 0,7 0,8 0,9 0,95 0,99 Confidence P ru n in g L e v e l Case 1 Case 2 Case 3  Figure 3.  Pruning experiences at support 0.25  V. DISCUSSION AND CHALLENGES It is important to discuss the technique presented here with focus on the purpose the technique pursues:  to produce semantic recommendation The reader should have noticed that the algorithm presented 


relies strongly on "choice". For instance, the algorithm chooses ears in the graph to form an order for elimination, and the choice is arbitrary. This strategy is essential to maintain low complexity \(polynomial practical. Nevertheless, a warned reader may conclude that this arbitrary choice implies that there are many compactions to produce and therefore the approach as a whole does not show to produce an optimal solution. And the reader is right in this conclusion. Since the goal is compaction, the search for an optimal solution can be bypassed provided a substantial level of pruning is achieved To complete the whole view, we describe how web service descriptions are complemented with the association rules as recommendations. In effect, under our scheme, the document describing the web service is augmented with a set of OWL/RDF/S triples that only incorporate the non-pruned rules with the format of Example 1, that is, the set ARmin of the compaction program obtained by our algorithm, together with the thresholds applied to the mining process and a registered URI of a registered description service. The assumptions and defeaters are not added to the web service description. If the associations encoded in the triples are not sufficient for the client \(a search engine, for instance widening of the response to the description service identified by the given URI, and then the assumptions and defeaters are produced. The reasoning task required for deriving all the implicitly published rules is client responsibility Notice that, under this scheme, the actual rules that appear as members of the set initial ARmin set are irrelevant; the only important issue is the size of the set The developed scheme also supports an extension of the algorithm that admits the assignment of priorities to rules and to itemsets, in order to allow the user to produce a more controlled program as output. Nonetheless, the importance of the extension has not been already tested, and therefore it is beyond the subject of the present paper It would be also interesting to design a scheme that supports queries where the client provides an itemset class and values for support and confidence and the engine produces a maximal class of inferred associated itemsets as a response. This scheme is also under development, so we have not discussed this aspect here 


VI. CONCLUSION In this paper, we have presented a defeasible logic framework for managing associations that helps in reducing the number of rules found in a set of discovered associations. We have presented an induction algorithm for inducing programs in our logic, made of assumption schemas, a reduced set of association rules and a set of counter-arguments to conclusions called defeaters, guaranteeing that every pruned rule can be effectively inferred from the output. Our approach outperform those of [17], because all reduction compactions presented there can be expressed and induced in our framework, and several other patterns, particular to the given datasets, can also be found. In addition, since a set of definite clauses can be obtained from the induced programs, the knowledge obtained can be modularly inserted in a richer inference engine Abduction can be also attempted, asking for justifications that explain the presence of certain association in the dataset The framework presented can be extended in several ways Admitting defeaters to appear in the head of assumption, to define user interest Admitting arithmetic expressions within assumptions for adjustment in pruning Admitting set formation patterns as itemset constants Extending the scope, to cover temporal association rules REFERENCES 1]  R. Agrawal, and R. Srikant: Fast algorithms for mining association rules In Proc. Intl Conf. Very Large Databases. \(1994 2]  A. V. Aho, J. E. Hopcroft, J. Ullman. The design and analysis of computer algorithms, Addison-Wesley, 1974 3]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher, A. Rock: A Family of Defeasible Reasoning Logics and its Implementation. ECAI 2000: 459-463 4]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher: Representation results for defeasible logic. ACM Trans. Comput. Log. 2\(2 2001 5]  A. Basel, A. Mahafzah, M. Al-Badarneh: A new sampling technique for association rule mining, Journal of Information Science, Vol. 35, No. 3 358-376 \(2009 6]  R. Bayardo and R. Agrawal: Mining the Most Interesting Rules. In Proc of the Fifth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 145-154, \(1999 


7]  R. Bayardo, R. Agrawal, and D. Gunopulos: Constraint-based Rule Mining in Large, Dense Databases. Data Mining and Knowledge Discovery Journal, Vol. 4, Num-bers 2/3, 217-240. \(2000 8]  A. Berrado, G. Runger: Using metarules to organize and group discovered association rules. Data Mining and Knowledge Discovery Vol 14, Issue 3. \(2007 9]  S. Brin, R. Motwani, J. Ullman, and S. Tsur: Dynamic itemset counting and implication rules for market basket analysis. In Proc. ACMSIGMOD Intl Conf. Management of Data. \(1997 10] L. Cristofor and D.Simovici: Generating an nformative Cover for Association Rules. In ICDM 2002, Maebashi City, Japan. \(2002 11] Y. Fu and J. Han: Meta-rule Guided Mining of association rules in relational databases. In Proc. Intl Workshop on Knowledge Discovery and Deductive and Object-Oriented Databases. \(1995 12] B. Goethals, E. Hoekx, J. Van den Bussche: Mining tree queries in a graph. KDD: 61-69. \(2005 13] G. Governatori, D. H. Pham, S. Raboczi, A. Newman and S. Takur: On Extending RuleML for Modal Defeasible Logic. RuleML, LNCS 5321 89-103. \(2008  14] G. Governatori and A. Stranieri. Towards the application of association rules for defeasible rules discovery In Legal Knowledge and Information Systems, JURIX, IOS Press, 63-75. \(2001 15] J. Han, J. Pei and Y. Yin: Mining frequent patterns without candidate generation. In Proc. ACM-SIGMOD Intl Conf. Management of Data 2000 16] C. Hbert, B. Crmilleux: Optimized Rule Mining Through a Unified Framework for Interestingness Measures. DaWaK: LNCS 4081, 238247. \(2006 17] E. Hoekx, J. Van den Bussche: Mining for Tree-Query Associations in a Graph. ICDM 2006: 254-264 18] R. Huebner: Diversity-Based Interestingness Measures For Association Rule Mining. Proceedings of ASBBS Volume 16 Number 1, \(2009 19] B. Johnston, Guido Governatori: An algorithm for the induction of defeasible logic theories from databases. Proceedings of the 14th Australasian Database Conference, 75-83. \(2003 20] P. Kazienko: Mining Indirect Association Rules For Web Recommendation. Int. J. Appl. Math. Comput. Sci., Vol. 19, No. 1, 165 186. \(2009 21] M. Klemettinen, H. Mannila, P. Ronkainen, H. Toivonen, and A Verkamo: Finding interesting rules from large sets of discovered association rules. In Proc. 3rd Intl Conf. on Information and Knowledge 


Management. \(1994 22] M. J. Maher, A. Rock, G. Antoniou, D. Billington, T. Miller: Efficient Defeasible Reasoning Systems. International Journal on Artificial Intelligence Tools 10\(4 2001 23] C. Marinica, F. Guillet, and H. Briand: Post-Processing of Discovered Association Rules Using Ontologies. The Second International Workshop on Domain Driven Data Mining, Pisa, Italy \(2008 24] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal: Closed sets based discovery of small covers for association rules. In Proc. BDA'99 Conference, 361-381 \(1999 25] N. Pasquier, R. Taouil, I. Bastide, G. Stume, and  L. Lakhal: Generating a Condensed Representation for Association Rules. In Journal of Intelligent Information Systems, 24:1, 29-60 \(2005 26] P. Pothipruk, G. Governatori: ALE Defeasible Description Logic Australian Conference on Artificial Intelligence.  110-119 \(2006 27] J. Sandvig, B. Mobasher Robustness of collaborative recommendation based on association rule mining, Proceedings of the ACM Conference on Recommender Systems \(2007 28] W. Shen, K. Ong, B. Mitbander, and C. Zaniolo: Metaqueries for data mining. In Fayaad, U. et al. Eds. Advances in Knowledge Discovery and Data Mining. \(1996 29] I. Song, G. Governatori: Nested Rules in Defeasible Logic. RuleML LNCS 3791, 204-208 \(2005 30] H. Toivonen, M. Klemettinen, P. Ronkainer, K. Hatonen, and H Mannila: Pruning and grouping discovered association rules. In ECML Workshop on Statistics, Machine Learning and KDD. \(1995 31] M. Zaki: Generating Non-Redundant Association Rules. In Proc. of the Sixth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 34-43, \(2000 32] w3c. OWL Ontology Web Language Reference. In http://www.w3.org/TR/2004/REC-owl-ref-20040210 33] w3c. RDF/XML Syntax Specification. In: http://www.w3.org/TR/rdfsyntax-grammar 34] w3c. RDF Schema. In: http://www.w3.org/TR/rdf-schema      


 8   2  3\f            8  D    F  \b 1 8 & #J      b 1  1  4    2  


4 1    9  E 1  2 4 1    9 1   4      8 2  8 1  D 1        1 1  b 


     b b b b b  K            8          2 D 9   F  \b 1 8 ,+J  9 


     b 1     1 2  9 1  12 L 1   9  8       1  2      2   


     b b b b b  K            2  0 \b f  b\f      9       


  8 2   E 1   1     M13 31L 1    b  8E 1   1 #3\b?### 1  1     E 1   1 \b?###3        


1   1   b 1  2 2 18 2     8              1    2 \b 1    2  


    2          2   1 L 2 1   1   L 2 2    2 1  2        


    8  2H D \b A             2  2H D \b A 2 \f 3%\f  f   4%\f f !  , \f\b  C    2    2 


 6    3 1      253 6   1 L 2    6   1         f\b3\f       


               1     1     8 2    E       2  1   


     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



A New Parallel Algorithm for the Frequent Itemset Mining Problem Mitic  aCraus Gh Asachi Technical University Department of Computer Science and Engineering 53 A Dimitrie Mangeron Street 700050 Iasi Romania craus@cs.tuiasi.ro Abstract A new parallel algorithm for nding the frequent itemsets in databases is presented It differs fundamentally of well known Apriori algorithm where at the beginning of every step the dimension of the new frequent itemsets increases by 1  In our algorithm the frequent itemsets are determined by progressively enlarging the interval which the individual items appertain i.e if at the k th step the new candidates are from  i i  k  intervals i 1  2 n  k  at the next step k 1  the new candidates will belong to  i i  k 1 intervals i 1  2 n  k  1  The frequent individual items are identiﬁed by their index The basic idea is that the new frequent itemsets with individual items from the interval  i j   simultaneously contain the items i and j  The frequent itemsets are built by sharing the work between n processors Hereby the processor P i computes step by step the sets F i,j of the frequent itemsets with individual items from the intervals  i j  j  i,...,n  In order to compute the set F i,j  the processing unit P i uses F i,j  1 obtained in the previous step and F i 1 j received from the processor P i 1  The main advantage of our parallel algorithm is that it uses a communication pattern known before algorithm start which allows mapping communication to hardware Another major advantage is that the set of the transactions can be distributed to processors prior to beginning This is possible because a processor P i has to compute F i,j j  i,...,n and therefore only the transactions containing the frequent item i are needed 1 Introduction Association rule discovery ARD refers the following problem Given a data set one must determine all relations between elements in such way that the presence of a given element implies the presence of another element Such relations may be associations between elements that belong to the same set or between different data sets Association rule discovery implies an essential stage frequent itemset mining FIM in target databases Let I be a set of items and D a database of transactions Every transaction is a set of distinct items  itemset  from I  An itemset with k items is referred to as a k-itemset The support of an itemset X  denoted as 002  X   is the total number of transactions in which that itemset occurs as a subset A second formal deﬁnition for the support of an itemset X is given by Agrawal an itemset X has a support of s if s of transactions in D contains X as a subset This second formal deﬁnition is somewhat more rigorous as it emphasizes that the maximum support of an itemset cannot exceed the total number of transactions in D  An itemset is called frequent if its support is grater than a user-deﬁned minimum support value A frequent k-itemset X is maximal if no other k’-itemset where k<k 002  contains X as a subset  An association rule is an expression X 002 Y  where X and Y are disjoint itemsets  A n i mportant note i s t hat an association rule must not be considered as an implication but rather as a coexistence of the two itemsets The support of an association rule is given by the support of the X 003 Y itemset The conﬁdence of an association rule is the conditional probability that a transaction contains Y  given that it contains X  The conﬁdence is computed using t he formula c  X 002 Y  002  X 003 Y  002  X   Minimum conﬁdence of a rule is a user deﬁned value An association rule is strong if it has a support greater than minimum support value and conﬁdence greater than the minimum conﬁdence value Let n be the total number of individual items and m the total number of transactions in target database D  The rst stage of an ARD algorithm is nding all frequent itemsts The search space for this step is exponential in 2  the total number of candidate sets is 2 n  The second stage of an ARD algorithm implies searching step by step all frequent itemsets previously found in order to discover all possible association rules that meet the minimum-support and minimum-conﬁdence conditions A general way to generate the association rules is X  Y 002 Y  
2008 International Symposium on Parallel and Distributed Computing 978-0-7695-3472-5/08 $25.00 © 2008 IEEE DOI 10.1109/ISPDC.2008.45 165 


where X is a frequent itemset and Y is a subset of X Mohammed proves that this stage is O  r  2 l   where r is the number of frequent itemsets and l is the longest frequent itemset the itemset containing the most items 2 Related work The Apriori algorithm represents the foundation of association rule mining algorithms Apriori algorithm Algorithm 1 was proposed by Agrawal and Srikant Algorithm 1 Apriori Notations  L k  set of k itemsets having minimum support frequent itemsets C k  set of candidate k itemsets items to be counted Initial conditions  D  set of transactions L 1   f requent 1  itemsets  Algorithm  for  k 2 L k  1 004  005 k  do C k 006 Apriori gen  L k  1   new candidates for all transactions t 007 D do C t 006 Subset  C k t   candidates contained in t for all candidates c 007 C t do c.count 006 c.count 1 end for end for L k 006 c 010 C k  c.count 011 minsupp  end for Answer  002 k L k At the rst step the Apriori algorithm determines all frequent 1-itemsets by scanning the transaction database D  At the subsequent k th step rst the candidate k-itemsets will be generated based on frequent k 1 itemsets found in the corresponding k 1 step Then the support for each candidate k-itemset will be computed and the candidates that meet the minimum support condition will be retained An optimal generation of candidate k-itemsets is based on the Apriori Principle  If an itemset is frequent then all of its subsets must also be frequent  This theorem can easily be proved by analyzing the deﬁnition of support and considering the following property of the itemsets 012 X Y  X 013 Y 002 s  X  011 s  Y  1 where X  Y are itemsets Also Agrawal states that the results of Apriori are not inﬂuenced by imposing a particular order for the individual items prior to determining frequent itemsets  Among the optimized versions of the algorithm can be enumerated Apriori-TID and Apriori-Hybrid DHP 5 SON  T he y i mpro v e the performances of the base a lgorithm through a series of modiﬁcations reduce the number of database scans reduce the size of the analyzed dataset at each scan use of various pruning techniques The HPA Hash Partitioned Apriori algorithm is one of the most efﬁcient parallel implementations of Apriori algorithm This algorithm partitions both candidates and database transactions between processing nodes using a hash function  The steps of the HPA algorithm are as follows Step 1 Generate candidate k itemsets All processors have all the large  k  1 itemsets in their memory when the k th pass starts Each processor generates candidate k itemsets using large  k  1 itemsets applies a hash function and determines a destination processor identiﬁer If the identiﬁer is the processor’s own the itemset is inserted into the hash table otherwise it is discarded Step 2 Scan the transaction database and count the support value Each processor reads its transaction database and computes the support for each k itemset It generates k itemsets from those transactions and applies the same hash function used in the rst step Then the processor determines the destination processor and sends the k itemsets to it When a processor receives these itemsets it searches the hash table for a match and increments the match count Step 3 Determine large k itemsets Each processor checks all the itemsets it has and determines large itemsets locally then broadcasts them to the other processors Step 4 Check the terminal condition If the number of the large k itemsets is 0 the algorithm terminates Otherwise an all-to-all communication broadcasts large k itemsets to all the processors and the algorithm enters the next iteration The speedup of the HPA algorithm is depending on the hash function HPA avoids the memory overﬂow caused of large number of candidate itemsets by partitioning those itemsets among nodes using hash function as in the hash join Apriori algorithm has two major drawbacks with respect to storage space memory use and running time multiple scans of the initial database and the complex phase of efﬁcient candidate generation In order to avoid the above mentioned issues a series of alternative algorithms have been proposed One of them is the FP-Growth Frequent Pattern Growth algorithm which uses a tree structure  T he algorithm generates all frequent itemsets with only two scans of the target database without employing a candidate generating step The algorithm has two basic steps building the FP-Tree Frequent Pattern Tree and generation of frequent itemsets Although it surpasses the performances of the Apriori algorithm the FP-Growth algorithm is difﬁcult to use within interactive systems within which users frequently modify support and conﬁdence factors and within 
166 


which database size is not constant Another tree based algorithm for mining association rules is RARM Rapid Association Rule Mining this algorithm e mplo ys tree structures in representing the input data set 3 New parallel algorithm for frequent itemset mining problem The basic idea of our new parallel algorithm for the FIM problem is to determine step by step the frequent itemsets by enlarging the interval to which the individual items belong to i.e if at the k th step the new candidates are from  i i  k  intervals i 1  2 n  k  at the next step k 1  the new candidates will be from  i i  k 1 intervals i 1  2 n  k  1  Let us consider n individual frequent items and m transactions In the rst step the new candidates will be subsets of the sets  1  2    2  3    n  1 n   In the second step the new candidates will be subsets of the sets  1  2  3    2  3  4    n  2 n  1 n   In the last step the new candidates will be subsets of the set  1  2 n   This approach simpliﬁes the candidate generation function and has bigger parallelism potential than Apriori algorithm Will will use the following notations F i,j  the set of all frequent itemsets from the interval  i j  set of items having minimum support C i,j  the set of candidate itemsets from the interval  i j   Lemma 1 A frequent itemset from F i,j which does not simultaneously contain the items i and j belongs to F i,j  1 or F i 1 j  Proof Let us suppose an itemset  k  l  k 011 i l 014 j  1  is in F i,j but not in F i,j  1  This means that F i,j  1 does not contains all frequent itemsets from the interval  i j    Similarly for an itemset  k  l  k 011 i 1 l 014 j Lemma 2 The new frequent itemsets in F i,j simultaneously contain the items i and j Proof Lemma 2 is an immediate consequence of Lemma 1 From Lemma 2 it results that the candidates from the interval  i j  are obtained in accordance with the relation 2 C i,j   X 003 Y   X 007 F i,j  1 015 i 007 X  015  Y 007 F i 1 j 015 j 007 Y  2 Figures 1 and 2 present an example with 10 transactions and 9 frequent individual items The transactions are denoted by T 1 T 2 T 10 and the individual items i 1 i 2 i 9 are identiﬁed with their indices T 1 016 1  2  T 2 016 1  2  3  5  9  T 3 016 1  4  T 4 016 3  4  5  6  7  8  T 5 016 7  8  9  T 6 016 2  4  6  8  T 7 016 1  3  5  7  9  T 8 016 1  4  5  6  7  T 9 016 2  4  5  6  9  T 10 016 3  4  5  6  7  minimum-suport 2 Initial Frequents items 1,2,3,4,5,6,7,8,9 F 1  1   1   F 2  2   2   F 3  3   3   F 4  4   4   F 5  5   5   F 6  6   6   F 7  7   7   F 8  8   8   F 9  9   9   Step 1 Initial frequent itemsets in step 1 IF 1  2   1,2   IF 2  3   2,3   IF 3  4   3.4   IF 4  5   4,5   IF 5  6   5,6   IF 6  7   6,7   IF 7  8   7,8   IF 8  9   8,9   Candidates C 1  2   1,2   C 2  3   2,3   C 3  4   3.4   C 4  5   4,5   C 5  6   5,6   C 6  7   6,7   C 7  8   7,8   C 8  9   8,9   New frequent itemsets NF 1  2   1,2   NF 2  3  005  NF 3  4   3,4   NF 4  5   4,5   NF 5  6   5,6   NF 6  7   6,7   NF 7  8   7,8   NF 8  9  005  Frequent itemsets at the end of the step 1 F 1  2   1,2  1,2   F 2  3   2,3   F 3  4   3,4  3,4   F 4  5   4,5  4,5   F 5  6   5,6  5,6   F 6  7   6,7  6,7   F 7  8   7,8  7,8   F 8  9   8,9   Step 2 Initial frequent itemsets in step 2 IF 1  3   1,2,3  1,2   IF 2  4   2,3,4  3,4   IF 3  5   3,4,5  3,4    4,5   IF 4  6   4,5,6  4,5    5,6   IF 5  7   5,6,7  5,6    6,7   IF 6  8   6,7,8  6,7    7,8   IF 7  9   7,8,9  7,8   Candidates C 1  3   1,3    1,2,3   C 2  4   2,4    2,3,4   C 3  5   3,5    3,4,5   C 4  6   4,6    4,5,6   C 5  7   5,7    5,6,7   C 6  8   6,8    6,7,8   C 7  9   7,9    7,8,9   New frequent itemsets NF 1  3   1,3   NF 2  4   2,4   NF 3  5   3,5    3,4,5   NF 4  6   4,6    4,5,6   NF 5  7   5,7    5,6,7   NF 6  8   6,8   NF 7  9   7,9   Frequent itemsets at the end of the step 2 F 1  3   1,2,3  1,2    1,3   F 2  4   2,3,4  3,4    2,4   F 3  5   3,4,5  3,4    4,5    3,5    3,4,5   F 4  6   4,5,6  4,5    5,6    4,6    4,5,6   F 5  7   5,6,7  5,6    6,7    5,7    5,6,7   F 6  8   6,7,8  6,7    7,8    6,8   F 7  9   7,8,9  7,8    7,9  Figure 1 New parallel algorithm for the FIM problem Example Part I 
167 


Step 3 Initial frequent itemsets in step 3 IF 1  4   1,2,3,4  1,2    1,3    3,4    2,4   IF 2  5   2,3,4,5  3,4    2,4    3,4    4,5    3,5    3,4,5   IF 3  6   3,4,5,6  3,4    4,5    3,5    3,4,5    4,5    5,6    4,6    4,5,6   IF 4  7   4,5,6,7  4,5    5,6    4,6    4,5,6    5,6    6,7    5,7    5,6,7   IF 5  8   5,6,7,8  5,6    6,7    5,7    5,6,7    6,7    7,8    6,8   IF 6  9   6,7,8,9  6,7    7,8    6,8    7,8    7,9   Candidates C 1  4   1,4    1,2,4    1,3,4    1,2,3,4   C 2  5   2,5    2,3,5    2,4,5    2,3,4,5   C 3  6   3,6    3,4,6    3,5,6    3,4,5,6   C 4  7   4,7    4,5,7    4,6,7    4,5,6,7   C 5  8   5,8    5,6,8    5,7,8    5,6,7,8   C 6  9   6,9    6,7,9    6,8,9    6,7,8,9   New frequent itemsets NF 1  4   1,4   NF 2  5   2,5   NF 3  6   3,6    3,4,6    3,5,6    3,4,5,6   NF 4  7   4,7    4,5,7    4,6,7    4,5,6,7   NF 5  8  005  NF 6  9  005  Frequent itemsets at the end of the step 3 F 1  4   1,2,3,4  1,2    1,3    3,4    2,4    1,4   F 2  5   2,3,4,5  3,4    2,4    3,4    4,5    3,5    3,4,5    2,5   F 3  6   3,4,5,6  3,4    4,5    3,5    3,4,5    4,5    5,6    4,6    4,5,6    3,6    3,4,6    3,5,6    3,4,5,6   F 4  7   4,5,6,7  4,5    5,6    4,6    4,5,6    5,6    6,7    5,7    5,6,7    4,7    4,5,7    4,6,7    4,5,6,7   F 5  8   5,6,7,8  5,6    6,7    5,7    5,6,7    6,7    7,8    6,8   F 6  9   6,7,8,9  6,7    7,8    6,8    7,8    7,9   F 1  8 F 2  9 F 1  7 F 1  6 F 1  5 F 1  4 F 1  3 F 1  2 F 1  1 F 2  8 F 2  7 F 2  6 F 2  5 F 2  4 F 2  3 F 2  2 F 3  9 F 3  8 F 3  7 F 3  6 F 3  5 F 3  4 F 3  3 F 5  9 F 5  8 F 5  7 F 5  6 F 5  5 F 7  9 F 7  8 F 7  7 F 4  9 F 4  8 F 4  7 F 4  6 F 4  5 F 4  4 F 6  9 F 6  8 F 6  7 F 6  6 F 8  9 F 8  8 F 9  9 F 1  9 Initial Step 1 Step 2 Step 3 Step 4 Step 5 Step 6 Step 7 Step 8 Figure 2 New parallel algorithm for the FIM problem Example Part II The new parallel algorithm for the FIM problem Algorithm 2 is based on the fact that the frequent itemsets are built by sharing the work between n processors The sets F i,j j  i,...,n  are computed in successive steps by the processor P i  In order to compute the set F i,j  the processor P i uses F i,j  1 from the previous step and F i 1 j received from the processor P i 1 Figure 3 The main advantage of our parallel algorithm is that the set of the transactions can be distributed to processors prior to the beginning of the analysis This is possible because a processor P i needs to compute F i,j j  i,...,n only D i  the set of the transactions which contain the individual frequent item i  Therefore when the algorithm starts P i needs to have access to D i and F i,i   frequent item i   F 1  8 F 2  9 F 1  7 F 1  6 F 1  5 F 1  4 F 1  3 F 1  2 F 1  1 F 2  8 F 2  7 F 2  6 F 2  5 F 2  4 F 2  3 F 2  2 F 3  9 F 3  8 F 3  7 F 3  6 F 3  5 F 3  4 F 3  3 F 5  9 F 5  8 F 5  7 F 5  6 F 5  5 F 7  9 F 7  8 F 7  7 F 4  9 F 4  8 F 4  7 F 4  6 F 4  5 F 4  4 F 6  9 F 6  8 F 6  7 F 6  6 F 8  9 F 8  8 F 1  9 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 002 Initial Step 1 Step 2 Step 3 Step 4 Step 5 Step 6 Step 7 Step 8 F 9  9 P 1 P 2 P 3 P 4 P 5 P 6 P 7 P 8 P 9 Figure 3 Processors communication at new parallel algorithm for the FIM problem When the processors number  m  is less than the frequent items number  n  the parallel algorithm can be modiﬁed as follows In the rst stage the frequent itemsets from the intervals  i i  n  m   i 1 m are sequentially computed Then at the second stage the last m  1 steps of the parallel algorithm are applied The natural communication topology is the chain Figure 4 P 1 P 2 P 3 P 4 P 5 P 6 P 7 P 8 P 9 Figure 4 Chain communication topology 
168 


Algorithm 2 New parallel algorithm for the FIM problem for k 1 to n  1 do for all i  i 007 1 n  k  par do j 006 i  k F i,j 006 F i,j  1 003 F i 1 j C i,j 006 X 003 Y   X 007 F i,j  1 015 i 007 X  015  Y 007 F i 1 j 015 j 007 Y  for all transactions t 007 D i do C t 006 subset  C i,j t   candidates contained in t for all candidates c 007 C t do c.count 006 c.count 1 end for end for F i,j  F i,j 003 c 007 C i,j  c.count 011 minsupp  end for end for Algorithm 3 Scalable parallel algorithm for k 1 to n  m do for all i  i 007 1 m  do j 006 i  k F i,j 006 F i,j  1 003 F i 1 j C i,j 006 X 003 Y   X 007 F i,j  1 015 i 007 X  015  Y 007 F i 1 j 015 j 007 Y  for all transactions t 007 D i do C t 006 subset  C i,j t   candidates contained in t for all candidates c 007 C t do c.count 006 c.count 1 end for end for F i,j  F i,j 003 c 007 C i,j  c.count 011 minsupp  end for end for for all i  i 007 1 m  do send F i,j to P i end for for k  n  m 1 to n  1 do for all i  i 007 1 n  k  par do j 006 i  k F i,j 006 F i,j  1 003 F i 1 j C i,j 006 X 003 Y   X 007 F i,j  1 015 i 007 X  015  Y 007 F i 1 j 015 j 007 Y  for all transactions t 007 D i do C t 006 subset  C i,j t   candidates contained in t for all candidates c 007 C t do c.count 006 c.count 1 end for end for F i,j  F i,j 003 c 007 C i,j  c.count 011 minsupp  end for end for 4 Performance Analysis Our algorithm uses a xed communication pattern This is the greatest advantage of our proposal In the worst case D 1 is D  This is the case when every transaction from D contains 1 the rs frequent item Anyway only in the rst step D 1 is entirely scanned In the k th step the transactions from D 1  which have all the items less than k 1  are skipped The processor P i searches for new frequent itemsets only in the transactions which contain the item i  Also in the k th step P i skips in D i all the transactions for which the maximum item is less than k  i  If the transactions are previously cleaned of not frequent items D i i 1 n  can be easily extracted from D Having D i for every processor P i  a sorting algorithm can be applied now in order to obtain the reverse lexicography order of transactions from D i  Example  After sorting in reverse lexicography order D 1 resulted from the example presented in Figures 1 and 2 the transactions order will be as follows T 1   1  2  T 3   1  4  T 8   1  4  5  6  7  T 2   1  2  3  5  9  T 7   1  3  5  7  9  Now at the k th step P i can easily skip in D i all the transactions which have the maximum item less than k  i  The problem remains load balancing The processor P i works a step more than the processor P i  1  In order to improve the processors usage a two rows mesh communication topology can be used so that when 017 n 2 020 processors are free and the others 021 n 2 022 processors have to compute F i,j i 1  021 n 2 022  j  i  k and k 021 n 2 022  every processor P i can send a half of its work to P 2 004 n 2 005 1  i Figure  T his means that P i will combine the the rst half of set C i i,j  1   X  X 007 F i,j  1 015 i 007 X  with the set C j i 1 j   Y  Y 007 F i 1 j 015 j 007 Y  and P 2 004 n 2 005 1  i will combine the the second half of set C i i,j  1   X  X 007 F i,j  1 015 i 007 X  with the set C j i 1 j   Y  Y 007 F i 1 j 015 j 007 Y   Then they will search in D i to compute the support of the obtained candidates They will skip in D i all the transactions which have only items less than j  This kind of work can start in the step 017 n 2 020 and can continue to the end The idea presented above splitting the task between processors can be applied recursively As result the most adequate architecture for load balancing is a mixture of linear array chain and hypercube Figure 6 Let us suppose that at one moment p  021 n 2 k 022 processors are busy and n 017 n 2 k 020 processors are free At this point every busy processor P i  i 1 p  will send a half of its work to P i  p  Then the procesor P i will send half of its work to the processor P i 2 p and he procesor P i  p will send half of its work to the 
169 


F 1  10 F 2  11 F 3  12 F 4  13 P 1 P 2 P 3 P 4 P 16 P 15 P 14 P 13 F 5  14 F 6  15 F 7  16 F 8  17 P 5 P 6 P 7 P 8 P 12 P 11 P 10 P 9 Figure 5 Two rows mesh processors communication topology P 1 P 2 P 3 P 5 P 6 P 7 P 8 P 9 P 11 P 13 P 14 P 15 P 16 P 10 P 4 P 12 Figure 6 Mixture of chain and hypercube processor P i  p 2 p and so on Thus in order to transfer a part of its work the procesor P i needs a direct link-up to the processors P i 2 k p k 011 0  The architecture from Figure 6 provides a chanel for every comunication implied by the work spliting step 5 Conclusion and Future Work The idea of our new FIM parallel algorithm differs fundamentally of the well known Apriori algorithm Our algorithm determines step by step the frequent itemsets by enlarging the interval to which the individual items belong to unlike the Apriori algorithm at the beginning of every step increases the dimension of the new frequent itemsets by 1 Our algorithm uses a communication pattern known before algorithm start This is a very important issue because it allows hardware implementation for the processors communication pattern Another major advantage is that the set of the transactions can be distributed to processors prior to the beginning of the analysis In order to compare our algorithm with other FIM algorithms we will use a MPI framework which is in the nal stage of implementation At the end a grid service for association rule discovery problems will be carried out The processors workload allocation can still be improved This is one of the future objectives The distribution of the transactions between the processors will be also in focus 6 ACKNOWLEDGEMENT The Excellence Research Program through grant 74 CEEX-II03/31.07.2006  Academic Grid for Complex Applications GRAI has supported the research for this paper References  R  A gra w al and R Srikant F ast A lgorithms for Mining Association Rules in Large Databases Proceedings of the 20th International Conference on Very Large Data Bases  Santiago Chile September 1994 pp 487–499  M C raus A ne w a lgorithm f or association r ule d isco very Proceedings of the 9th International Symposium on Automatic Control and Computer Science Iasi,Romania November 2007  A Das A W K Ng and Y  K W oon Rapid a ssociation rule mining Proceedings of the tenth international conference on Information and knowledge management  ACM Press 2001 pp 474-481  J  Han J Pei and Y  Y i n Mining frequent patterns without candidate generations Proceedings of the International Conference on Management of Data ACMSIGMOD 2000  J S P ark M.S Chen and P  S Y u  An e f f ecti v e hash based algorithm for mining association rules Proceedings of the 1995 ACM SIGMOD International Conference on Management of Data  M J Carey and D A Schneider Eds San Jose California 1995 pp 175186  A S a v esere E Omiecinski and S Na v a the An ef cient algorithm for mining association rules in large databases Proceedings of 20th International Conference on VLDB  1995  T  Shintani and M Kitsure g a w a Hash Based P arallel Algorithms for Mining Association Rules Proceedings of the 4th International Conference on Parallel and Distributed Information Systems PDIS 96 1996  P N T an M Steinbach and V  K u mar  Introduction to data mining  Addison Wesley 2005  M.J Z aki P arallel and Distrib u ted D ata Mining A Sur vey IEEE Concurrency Journal  7\(4 
170 


 Kluwer Academic Publishers Springer, New York 1st edition, 2001 14  S c h e f f e r   T   F i n d i n g  A s s o c i a t i o n  Ru l e s  t h a t  T r a de Support Optimally Against Confidence th The Elements of Statistical Learning self_care_guide/Urogenital/Postate%20Cancer.pdf  Accessed, 25 August, 2008 11  A g r a w a l   R  T   I m i e l i n s k i     A   S w a m i   M i n i n g  association rules between sets of items in large databases, In Proceedings of the 1993 ACM SIGMOD international conference on Management of data  The Netherlands 42 2001 61-95  Ordonez C Association rule discovery with the train and test approach for heart disease predictio n 207\226 216 12 001 13  H a s t i e   T    R  T i b s h i r a n i     J  H   F r i e d m a n   Proceedings of the 5th European Conference on Principles and Practice of Knowlege Discovery in Databases\(PKDD'01 IEEE Transactions on Information Technology in Biomedicine, 10\(2\, 2006. 334 \226 343 001 Freiburg, Germany : SpringerVerlag, 2001. 424-435 15  F l a c h   P  A     L a c h i c h e   N   Co n f i r m a t i o n g u i d e d  discovery of first-order rules with Tertius 10  P h a r m a c y   h t t p    w w w  p h a r m a c y  g o v  m y    


 7. Conclusions  In this paper we have proposed an intelligent and efficient technique to reassess the distances between dynamic XML documents when one or all of the initially clustered documents have changed. After the changes, the initial clustering solution might become obsolete - the distances between clustered XML documents might have changed more or less depending on the degree of modifications \(insert update, delete\hich have been applied. Re-running full pair-wise comparisons on the entire set of modified documents is not a viable option, because of the large number of redundant operations involved Our proposed technique allows the user to reassess the pair-wise XML document distances, not by fully comparing each new pair of versions in the clustering solution, but by determining the effect of the temporal changes on the previously known distances between them. This approach is both time and I/O effective, as the number of operations involved in distance reassessing is greatly reduced  References  1  Beringer, J. and H\374llermeier, E., Online clustering of parallel data streams Data and Knowledge Engineering 58\(2\,  2006, 180-204 2  Catania, B. and Maddalena A., A Clustering Approach for XML Linked Documents, Proceedings of the 13th International Workshop on Database and Expert Systems Applications \(DEXA\22202\, IEEE 2002 3  Chen, M.S., Han, J. and Yu, P., Data Mining: An Overview from Database Perspective, IEEE Transactions on Knowledge and Data Engineering vol. 8, 1996, 866-883 4  Cormen, T., Leiserson, C. and Rivest, R Introduction to algorithms, MIT Press, 1990 5  Costa, G., Manco, G., Ortale, R. and Tagarelli, A., A tree-based Approach to Clustering XML documents by Structure, PAKDD 2004, LNAI 3202, 137-148 Springer 2004 6  Dalamagas, T., Cheng, T., Winkel, K.J. and Sellis, T 2004, Clustering XML documents by Structure SETN 2004, LNAI 3025, 112-121, Springer 2004 7  Ester, M., Kriegel, H.P., Sander, J., Wimmer,M. and Xu, X., Incremental Clustering for Mining in a Data Warehousing Environment, Proc.of the 24 th VLDB Conference, New York, USA, 1998 8  Garofalakis, M., Rastogi, R., Seshadri, S. And Shim K., Data Mining and the Web: Past, Present and Future Proceedings of WIDM 99 Kansas, US, ACM 1999 9  Mignet, L., Barbosa, D. and Veltri, P., The XML web : a first study, In Proceedings of the 12 th  International Conference on WWW, 500-510 2003   Nayak, R., Xu, S., XCLS: A Fast and Effective Clustering Algorithm for Heterogeneous XML Documents, In Proceedings of the 10 th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining, Singapore, LNCS 3918, 2006   Rusu, L.I., Rahayu, W. and Taniar, D., A methodology for Building XML Data Warehouses International Journal of Data warehousing Mining, 1\(2 67-92, 2005   Rusu, L.I., Rahayu, W. and Taniar D.,  Maintaining Versions of Dynamic XML Documents, In Proceedings of the 6th International Conference on Web Information Systems Engineering, New York NY, USA, November 20-22, 2005, LNCS 3806   Rusu, L.I., Rahayu, W. and Taniar, D., Warehousing Dynamic XML Documents, In Proceedings of the 8 th  International Conference on Data Warehousing and Knowledge Discovery \(DaWaK 2006 LNCS 4081 Springer, 175-184, 2006   Shen, Y. and Wang, B., Clustering Schemaless XML documents, CoopIS / DOA/ODBASE 2003, LNCS 2888, 767-784, Springer 2003   Yoon, J. P., Raghavan, V., Chakilam, V., and Kerschberg, L., BitCube: A Three-Dimensional Bitmap Indexing for XML Documents J. Intel. Inf Syst 17, 2-3 \(Dec. 2001\, 241-254   XML data repository, online at http www.cs.washington.edu / research / projects / xmltk xmldata  
456 
456 


5 Related Work There exists extensive previous work on both the mining of software repositories and on the use of clustering algorithms in software engineering This discussion focuses on the most similar and recent work in the area of software evolution Mining Software Repositories Our technique was partially inspired by the work of Zimmermann et al and Y ing et al 17 on the mining of association rules in change history As described in Section 1 we sought to expand the technique to be able to recommend larger but less precise clusters of elements to guide program navigation Bouktif et al also investigated how to recommend cochanges in software development As opposed to the work cited above Bouktif et al used change patterns instead of association rules Also their approach does not attempt to reconstruct transactions and can consider associated 002les that were changed in different transactions ChangeDistiller is a tool to classify changes in a transaction into 002ne-grained operations e.g addition of a method declaration and determines how strongly the change impacts other source code entities Our approach uses similar repository analysis techniques but is focused on providing task-related information as opposed to an overall assessment of a system's evolution Finally repository mining can also be used to detect aspects in the code In this conte xt aspects are recurring sets of changed elements that exhibit a regular structure Aspects differ from the clusters we detect in the regular structure they exhibit which may not necessarily align with the code that is investigated as part of change tasks Clustering Analysis The classical application of clustering for reverse engineering involves grouping software entities based on an analysis of various relations between pairs of entities of a given version of the system Despite its long and rich history  e xperimentation with this approach continues to this day For example Andreopoulos et al combined static and dynamic information K uhn et al used a te xtual similarity measure as the clustering relation and Christl et al used clustering to assist iterative semi-automated reverse engineering The main dif ferences b e tween most clusteringbased reverse engineering techniques and the subject of our investigation is that the entities we cluster are transactions rather than software entities in a single version of a system For this reason our analysis is based strictly on the evolving parts of the system Both Kothari et al and V an ya et al 15 recently reported on their use of clustering to study the evolution of software systems The idea of using change clusters is the same in both works and ours but the purpose of the work is different Kothari et al use change clusters to uncover the types of changes that happened e.g feature addition maintenance etc during the history of a software system Vanya et al use change clusters which they call evolutionary clusters to guide the partitioning of a system that would increase the likelihood that the parts of the system would evolve independently In contrast we cluster transactions based on overlapping elements not 002les to recommend clusters to support program navigation as opposed to architectural-level assessment of the system Finally Hassan and Holt evaluated on 002ve open source systems the performance of several methods to indicate elements that should be modi\002ed together This study found that using historical co-change information as opposed to using simple static analysis or code layout offered the best results in terms of recall and precision The authors then tried to improve the results using 002ltering heuristics and found that keeping only the most frequently cochanged entities yielded the best results As opposed to our approach the evaluated 002ltering heuristics were only applied on entities recovered using association rules and not using clustering techniques The focus of their study was also more speci\002c as they recommend program elements that were strictly changed  as opposed to recommending elements that might be inspected by developers 6 Conclusion Developers often need to discover code that has been navigated in the past We investigated to what extent we can bene\002t from change clusters to guide program navigation We de\002ned change clusters as groups of elements that were part of transactions or change sets that had elements in common Our analysis of close to 12 years of software change data for a total of seven different open-source systems revealed that less than 12 of the changes we studied could have bene\002ted from change clusters We conclude that further efforts should thus focus on maximizing the quality of the match between the current task and past transactions rather than 002nding many potential matches Our study has already helped us in this goal by providing reliable evidence of the effectiveness of some 002ltering heuristics and useful insights for the development of additional heuristics Acknowledgments The authors thank Emily Hill and Jos  e Correa for their advice on the statistical tests and the anonymous reviewers for their helpful suggestions This work was supported by NSERC 
25 
25 
25 
25 
25 


References  B Andreopoulos A An V  Tzerpos and X W ang Multiple layer clustering of large software systems In Proc 12th Working Conf on Reverse Engineering  pages 79ñ88 2005  S Bouktif Y G Gu  eh  eneuc and G Antoniol Extracting change-patterns from cvs repositories In Proc 13th Working Conf on Reverse Engineering  pages 221ñ230 2006  S Breu and T  Zimmermann Mining aspects from v ersion history In Proc 21st IEEE/ACM Int'l Conf on Automated Software Engineering  pages 221ñ230 2006  A Christl R K oschk e and M.-A Store y  Equipping the re\003exion method with automated clustering In Proc 12th Working Conf on Reverse Engineering  pages 89ñ98 2005  D 020 Cubrani  c G C Murphy J Singer and K S Booth Hipikat A project memory for software development IEEE Transactions on Software Engineering  31\(6 465 2005  B Fluri and H C Gall Classifyi ng change types for qualifying change couplings In Proc 14th IEEE Int'l Conf on Program Comprehension  pages 35ñ45 2006  A E Hassan and R C Holt Replaying de v elopment history to assess the effectiveness of change propagation tools Empirical Software Engineering  11\(3 2006  D H Hutchens and V  R Basili System s tructure analysis Clustering with data bindings IEEE Transactions on Software Engineering  11\(8 1985  D Janzen and K De V older Na vig ating and querying code without getting lost In Proc 2nd Int'l Conf on AspectOriented Software Development  pages 178ñ187 2003  J K ot hari T  Denton A Shok ouf andeh S Mancoridis and A E Hassan Studying the evolution of software systems using change clusters In Proc 14th IEEE Int'l Conf on Program Comprehension  pages 46ñ55 2006  A K uhn S Ducasse and T  G  021rba Enriching reverse engineering with semantic clustering In Proc 12th Working Conf on Reverse Engineering  pages 133ñ142 2005  M P  Robillard T opology analysis of softw are dependencies ACM Transactions on Software Engineering and Methodology  2008 To appear  M P  Robillard and P  Mangg ala Reusing program in v estigation knowledge for code understanding In Proc 16th IEEE Int'l Conf on Program Comprehension  pages 202 211 2008  J Sillito G Murph y  and K De V older Questions programmers ask during software evolution tasks In Proc 14th ACM SIGSOFT Int'l Symposium on the Foundations of Software Engineering  pages 23ñ34 2006  A V an ya L Ho\003and S Klusener  P  v an de Laar and H van Vliet Assessing software archives with evolutionary clusters In Proc 16th IEEE Int'l Conf on Program Comprehension  pages 192ñ201 2008  N W ilde and M C Scully  Softw are reconnaissance Mapping program features to code Software Maintenance Research and Practice  7:49ñ62 1995  A T  Y ing G C Murph y  R Ng and M C Chu-Carroll Predicting source code changes by mining change history IEEE Transactions on Software Engineering  30\(9 586 2004  A Zeller  The future of programming en vironments Integration synergy and assistance In Proceedings of the 29th International Conference on Software Engineering The Future of Software Engineering  pages 316ñ325 2007  T  Zimmermann and P  W eiﬂgerber  Preprocessing C VS data for 002ne-grained analysis In Proc 1st Int'l Workshop on Mining Software Repositories  pages 2ñ6 May 2004  T  Zimmermann P  W eiﬂgerber  S Diehl and A Zeller  Mining version histories to guide software changes In Proc 26th ACM/IEEE Int'l Conf on Software Engineering  pages 563ñ572 2004 A Clustering Algorithm This algorithm is not sensitive to whether a given program element exists or not in a given version of a program For example if method m exists in one version it is considered a valid program element even if it is removed in a later version In the rest of this section we use the term program element to refer to the uniquely identifying representation of the element e.g a Java fully-quali\002ed name Let T be a transaction modeled as a set of program elements changed together during the history of a software system Let T be a sequence of transactions In this algorithm a cluster is also modeled as a set of elements 1 Input  T  A sequence of transactions 2 Parameter  M IN O VERLAP  A positive non-zero value indicating the minimum overlap between two transactions in a cluster 3 Var  C  A set of clusters initially empty 4 for all T i 2 T do 5 MaxOverlap  0 6 MaxIndex  000 1 7 for all C j 2 C do 8 if j C j  T i j  MaxOverlap then 9 MaxOverlap  j C j  T i j 10 MaxIndex  j 11 end if 12 end for 13 if MaxIndex   0  MaxOverlap 025 M IN O VERLAP  then 14 C MaxIndex   C MaxIndex  T i  15 else 16 NewCluster  T i 17 C  C  f NewCluster g 18 end if 19 end for 20 return C B Systems Analyzed System home pages last veri\002ed 7 May 2008 Ant ant.apache.org Azureus azureus.sourceforge.net Hibernate www.hibernate.org JDT-Core www.eclipse.org/jdt/core JDT-UI www.eclipse.org/jdt/ui Spring springframework.org Xerces xerces.apache.org 
26 
26 
26 
26 
26 



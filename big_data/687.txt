Detection of Public Information Sign in Airport Terminal Based on Multi-scales Spatio-temporal Vision Information Gao Qingji   Nanjing University of Aeronautics and Astronautics Robotics Institute, Civil Aviation University of China Tianjin, China gaoqingji@vip.sohu.com Yue Yue Department of Automation Northeast Dianli University Jilin, China yueyue320@tom.com  Yang Guoqing Nanjing University of Aeronautics and Astronautics Nanjing, China   Abstract A new method based on multi-scales spatio-temporal vision information is presented to detect public information signs for the airport terminal service robot \(ATSR\ocalization Firstly, public information signs are searched roughly in big space scale by using the connected components labeling algorithm. Secondly, the signs position and size in visual field are adjusted properly based on spatio-temporal relativity. Finally the signs are detected according to the extracted SIFT \(Scale Invariant Feature Transform\ features. Experiments by this new method on ATSR show that public information signs are detected rapidly and precisely  Keywords- Multi-scales spatio-temporal information; Public information sign; SIFT features; Airport terminal  service robot I   I NTRODUCTION  In recent years, robots have been gradually applied to many kinds of airport services. For instance: luggage pointing, guided tours, patrols and so on. In this paper, ASR is a kind of mobile robot indoor which is used to meet services in terminal Accurate localization in robot is a key to achieve decency and service functions in real-time, and whether the public information signs are detected is an important premise for localization, so real-time public information sign detection poses a complex problem for ASR. Based on the standard of China's civil aviation [1   p u b l i c in f o rm atio n s i g n s c o m p o s e d  o f  graphical symbols are used to guide passengers in terminal ticket office. In our work, public information signs which are composed graphical symbols or letters are used in terminal public information signs are called public signs for short in the next context\, for instance inquiry and luggage storage public signs. There is no uniform method to detect objects, in which most of sign detection are traffic \(road\ signs. Up to now little information referred in other papers is related to our research Normally, sign detection is based on extracting color or shape features to segment and classify, but there is some influence condition: illumination conditions, direction of sign’s face status of paint on signs, placement of multiple signs near each other, torn and variations in sign’s scale, obstacles etc, so problems of false detection bought out [2 3 4  T h i s p a pe r addresses the problem of vision focused on public sign detection in terminal for the system of ASR. Due to the particularity in spatial position, there are some difficulties in the detection processing:\(1\ape features can not be extracted easily for the distortion of public signs in the image;\(2\Because the public signs locate dispersedly, sometimes public signs are missed or only part of the sign is in the image;\(3\Images contained signs are in low resolution, so they are hard to detect;\(4\Public signs are occluded mutually in images, so most existing splitting approaches by making use of morphology [5 or histogram [6 ar e i n v a l i dat e d In al l u s i on  t o t h es es  pr o b l e m s  above, a new method based on multi-scales and spatiotemporal information is presented. In our method  public signs are searched fast by making use of stabilization of image edge in big space scale, while there is plenty of detail information in small space scale image [7   8   9    1 0  im ag in g p o s i t i on  ar e changed automatically based on spatio-temporal relativity of public signs: imaging position of public sign is corrected continuously by establishing a detection window and image is extracted SIFT features[1  an d  1 2 in v a r i ou s s p ac e s c a l es  in  search for the prior space scale, over these phases public sign detection is finished II  D ETECTION OF P UBLIC S IGN B ASED ON M ULTI SCALES AND S PATIO TEMPORAL I NFORMATION  The whole detection processing is composed of three phases in succession: \(1\ Fast searching for public signs in big space scale; \(2\ Public sign detection by spatio-temporal changing; \(3\ Searching for prior space scale based on extracting SIFT features A  Fast Searching for Public Signs in Big Space Scale Based on the standard of China's civil aviation [1  t h er e  must be intense contrast between graphical symbols and color grounding in public signs. A searching method based on color features and spatial information is designed in this phase \(see Fig. 1  
2008 International Conference on Computer Science and Software Engineering 978-0-7695-3336-0/08 $25.00 © 2008 IEEE DOI 10.1109/CSSE.2008.606 67 
2008 International Conference on Computer Science and Software Engineering 978-0-7695-3336-0/08 $25.00 © 2008 IEEE DOI 10.1109/CSSE.2008.606 67 


 Figure 1  The frame of searching for public signs in big space scale The position calibration of robot’s head is defined by L  p tz p expresses as pan position, t expresses as tilt position and z represents the zoom value, due to the reason of public sign’s height in space, the tilt searching scope is regulated  t 002\002   1 002 is the threshold determined by robot’s viewpoint scope and the height of public signs in space. Blue grounding has been used in most terminals. The main task of this phase is to segment the input image and extract out the areas that contain public sign patterns, color feature is extracted first. The raw input image is transformed from the original RGB color space to the HSV color space. Next, objects in the binary image are extracted using the connected components labeling algorithm Finally every ROI \(Region of interest,\ is signed by center coordinates, width and height in the raw image, so as to the public signs are searched fast in big space scale image Public sign images from different sites or in different illumination status \(see Fig. 2\ were picked up in order to obtain the thresholds of HSV. There was another interfere because of the mirrors in the surrounding, public signs could be reflected by the mirror and virtual public sign images may be detected, \(see Fig. 3\(a\, so S value must be regulated more reasonably. Different result images were showed distinctly c         Figure 2  Seletetd public information signs for extraction thresholds      a\                                          \(b  c Figure 3  Public information sign images contained disturbance. \(a disturbance representation. \(b\ - \(c\ searching images representation at different thresholds of S The HSV thresholds are regulated as followings  H<  H < H low high S S S low High V V V low High 000 000 000 000 000 000 000 2  Public information signs are searched by these processing above, result images are shown in Fig. 4 and ROI are drew in white thick lines    a\                                                \(b  c Figure 4  Public information signs searched in big space scale. \(a\ RGB representation. \(b\ binary images representation. \(c\ interested regions in the RGB images B  Public Sign Detection Based on Spatio-temporal Changing Information After searching in big space scale, imaging position and space scales are changed automatically based on spatiotemporal relativity of public signs in the image by robot’s head controlling in order to validate the reality of  ROI 
68 
68 


When public signs are detected by robot in real time, a number of issues may do effect detection. Some problematic public sign images will be presented. \(see Fig. 5    a\                                            \(b  c  Figure 5  Seleted public sign images for detection. \(a\ one part of the public sign in the image. \(b\one public sign occluded by the other. \(c\ one blurred public sign in the image By taking into the synthesis of all the information aforementioned, spatio-temporal changing method is designed as followed \(see Fig. 6   Figure 6  The frame of spatio-temporal changing Step1: The parameter L is obtained from current robot’s position, and center coordinates   00 i Xxy  i W and i H are achieved to express the ROI sequence. ROI are detected in the order of i S value from big to small i S is expressed as  i S  i W  i H 3 Step2: The occluded public signs in images are processed by threshold 003  003 is defined as the ratio between width and height of normal public sign, when  1.5 2 W i H i 003\003  4 ROI is considered to be two sign regions and two virtual center coordinates are defined to be      ii TxyH xy   1.5 0  1.5 0  0 xx W i xx W i yy y 000  000 000  000 000 000  000 5  Step 3: In this phase, a detection window is presented originally, where the detection window is expressed as that the window is being sized to m pixels x m pixels , and the window center is the same as the center of the input image, the m value is determined by velocity of robot’s head and size of input image. The motion control vector OX 000J\000J\000J\000K is constructed, and robot’s head is controlling by vector OX 000J\000J\000J\000K  Step4:In the processing of motion, the center coordinates of ROI is   00 i X xy in the foregoing frame, the input image is scanning inversely compared with OX 000J\000J\000J\000K in which   00 i X xy  and 004 are taken as the scanning initial point, scanning step respectively [13 a nd 14 002 004 is the longest moving step of center coordinates between two sequential frame. Then decision depending on temporal relativity is made as followed if the ROI limited is detected again, it proves to the reality of detection result in the foregoing frame, keep detecting this ROI, or else stop searching for the ROI limited. Carry out processing above time and again until X coordinates is in the detection window scope Step5: Space scale is reduced at the speed of v, once the space scale is changed, the ROI is detected by some criteria to search for the prior space scale, the image in the prior space scale will be the result image Step6: Resume the initial position L, switch to the step 1 to carry through detecting the next ROI, the changing phrase is ended until all the ROI are detected C  Searching for Prior Space Scale Based on Extracting SIFT Features Space scale could be enhanced by adjusting zoom value of the camera in robot’s head and the resolution of images can be enhanced [15  b u t i f t h e s p ac e s c a l e i s  c h a nged w i t h o u t an y  criteria, system is time-consuming as well as redundant, the detection efficiency will fall. Lowe present a algorithm which is called SIFT [1 n d [12  T h e fea t u r e s ar e i nvar i a n t t o  image rotation, affine distortion, in addition of noise, change in 3D viewpoint, and change in illumination. The features are highly distinctive and they can describe the environment excellently. A plenty of images contained public signs collected from terminals were used to do experiments: these images were M1 pixels x N1 pixels. Public sign regions were extracting SIFT features and SIFT feature numbers were increased nonlinearly followed by the enhancing of the space scale, when the numbers reached to or exceeded M for object recognition, results were correct in most samples, these features were accurately described the public signs in terminals 
69 
69 


The criteria space scale is regulated by extracting stable SIFT features 1\The value of zoom is changed at the speed of v, the maximal regulating times is n. During the processing of every regulation  S i R S image  6 If 0 R R 005 the regulation is stopped 0 R is a ratio threshold and S image is the image size 2\To minimize the cost of extracting SIFT features, when the quantity of features of the ROI is more than M, regulation is stopped 3\ompared with the quantity of features in the foregoing space scale, if the quantity falls in current space scale regulation is stopped and the detection image in the foregoing space scale will be the result image III  E XPERIMENTS  The detection method had been tested on “fuwa” ASR which had an Intel PM 1.6G CPU and 1G memory. Tianjin airport terminal and Beijing N0.3 airport terminal were chosen as our testing circumstances, Fig. 7 showed the scene that robot was in terminal. This part was implemented in the windows platform and Visual Studio 6.0 development environment. By using decision system, the system performed well on public information sign detection by motion control of robot’s head The image was 320 pixels x 240 pixels, the detection window was limited at 10 pixels x 10 pixels, and the detection edge of public signs in terminal were drew in white thick lines     Figure 7  The “fuwa” ASR image A  Experiments in Tianjin Airport Terminal Experiment 1: In this experiment, images with the public signs in bad status were used to test the searching algorithm in big space scale \(see Fig. 8 Set1: the image contained public signs where illuminant was in it or not at the same time was used Set2: the image contained public sign in intense illumination and in bad view point was used Set3: the image contained public signs in different illumination status was used. The public signs were not well reflected by light in the image This experiment sets also contained another 40 public information sign images in terminal. The searching module’s right rate was found to be 98    a\                                             \(b    c   Figure 8  Searched images of public signs in various status. \(a\ set1 image representation. \(b\ set2 image representation. \(c\ set3 image representation  Experiment 2: In this experiment, images used were problematic. One part of a public sign was detected in the beginning. Following the spatio-temporal changing, the detection region of the public sign was gradually expanded see Fig. 9     a\                                    \(b  c  Figure 9  The detection images of a public sign by spatio-temporal changing Experiment 3: the image contained multi public signs was detected in one scene \(see Fig. 10\onsidering the detection time, three regions were selected in the sequence of area value from big and small. The ROI were signed with the number from one to three. The parameter L was [5 0 15 0 0  v n M  and 0 R values were respectively 1,5,600,0.6. The top right corner regions in the images were sign extraction images in every frame. Took the detection processing of the second ROI in Fig. 10\(a\ example  
70 
70 


  a\                                     \(b   c\                                    \(d   e  f   g\\(166   h\\(264  460   670  Figure 10  A sequence detection images of the second public sign in one scene. \(a\ the searching image in one scene in big space scale. \(b\ spatiof\mages of the second sign in various space scales.\(g\-\(j\ extracting SIFT feature images and SIFT feature numbers in every space scale The searching speed in big space scale of every frame was 0.109 seconds and the speed of robot’s head was from zero to sixty degree per second. Time cost of public signs during every detection phase detected in Fig. 10\(a\as showed in Table.1       TABLE I  T IME COST OF PUBLIC SIGN DETECTION IN ONE SCENE  Public information signs  Spatiotemporal changing\(s  Time cost in space scales changing\(s  Number 1 1.150  Scale   1 0.313 2 0.625 3 0.750 Number 2 0.419  Scale   1 0.179 2 0.316 3 0.453 4 0.714 Number 3 0.506  Scale   1 0.043 2 0.086 3 0.199 4 0.488 5 0.750  Experiment 4:In this experiment, images used were problematic that one sign was occluded by the other. The virtual center coordinates were 002 59,161 002 and 002 177,161 002 at first and spatio-temporal changing was done on the two virtual regions. The splitting result showed in Fig. 11. When public sign images were captured in big space scale, two public signs were detected as a whole region, with the regulation of space scale, the two public signs were split finally   a\                                          \(b   c\                                          \(d   e Figure 11  The splitting images of occluded public signs representation B  Experiments in Beijing No.3 Airport Terminal Beijing No.3 airport terminal \(T3\s being used not long ago, the setting of public information sign has been changed compared with other domestic terminals as followings 1\Hue and saturation of sign’s color have been changed in the low illumination, some signs could not been seen clearly 2\There are another public signs: green signs and guide signs on the floor 3\here are also some public signs in the same grounding 
71 
71 


The parameters were changed correspondingly in this experiments and Fig. 12 showed the result images    a\                                              \(b   c\                                          \(d   e\                                        \(f  Figure 12  The detection images of public signs in T3.\(a\ult image of fuscous-blue public sign.\(b\ult image of blue and green public signs.\(c\ult image of guide sign on the floor.\(d\result image of multi-signs in the same grounding.\(e\earched images of public sign in big space scale IV  C ONCLUSION  A new method based on multi-scales and spatio-temporal information was presented in this paper. Multi-information involved space scale, spatio-temporal information were synthesized in the method. The detection module performed very well in real time on the public signs under various statuses: public signs were missed, part of a public sign was in the image, too small public sign images were captured and some public signs were occluded by other signs in the image moreover, it was achieved robustly on the robot at real-time performance in different environments  R EFERENCES  1  The Standard of China’s civil aviation MH00005-1997 http://www.biaozhi.net.html 2  Gareth Loy, Nick Barnes, “Fast Shape-based Road Sign Detection for a Driver Assistance System”, In: Proc. of the IEEE IRSJ Int. Conf. on Intelligent Robots and Systems, IEEE Press, Japan, pp. 70 –75, Oct 2004 3  Fabien Moutarde, Alexandre Bargeton, Anne Herbin, Lowik Chanussot Robust on-vehicle real-time visual detection of American and European speed limit signs with a modular Traffic Signs Recognition system”, In Proceedings of the 2007 IEEE Intelligent Vehicles Symposium Istanbul IEEE Press, Turkey, pp. 1122–1125, June 2007 4  Mark Dougherty, Dinesh Aenugula, and Sruthi Baddam, “Invariant Road Sign Recognition with Fuzzy ARTMAP and Zernike Moments In:Proceedings of the2007 IEEE Intelligent Vehicles Symposium Istanbul, IEEE Press, Turkey, pp. 31–36, June 2007 5  YUN Tian-yuan, JIANG Zhi-guo, MENG Ru-song, “An Automatic Processing Method Based on Mathematic”, Chinese Journal of Stereology and Image Analysis,  pp.41–43, March 2003 6  Alberto Broggi, Pietro Cerri, Paolo Medici, Pier Paolo Porta, “Real Time Road Signs Recognition”, In:Proceedings of the 2007 IEEE Intelligent Vehicles Symposium Istanbul, IEEE Press, Turkey, pp.981–986, June 2007 7  DUAN Gui-duo, LI Jian-ping , HUANG Tian-xi, “Study on image multi-scale geometric analysis”, Application Research of Computers pp.4–12, Oct 2007 8  Elisabet Perez and Bahram Javidi, “Nonlinear Distortion-Tolerant Filters for Detection of Road Signs in Background Noise”, IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, pp.567–576 May 2002 9  ZHU Zhong-jie, JIANG Gang-yi, “New Algorithm for Extracting Moving Object Based on Spatio-temporal Information”, Journal of Image and Graphics,  pp. 423–425, Apr 2003   Huang Ke-wei, Zhao Yan-nan, Sun Fa-jie and Wang Jia-qin, “An Efficient Object Exploring Strategy and Its Application in the Image Analysis”, Journal of Image and Graphics, pp.1039–1042, Dec 1999   LI Mao-hai, HONG Bing-rong, LUO Rong-hua,CAI Ze-su, “MonocularVision-Based Mobile R0bot Global Localization”, ROTOT,  pp.141–144 Mar 2007   David G. Lowe, “Distinctive Image Features from Scale-invariant Keypoint”, Computer Science Department University of British Columbia Vancouver,B.C, pp.1–29, 2003   HUANG-Jing, ZHAO Chen, ZHOU Ming-ming, “Identification of objects for micro soccer robot based on fast color space transformation JOURNAL OF HARBIN INSTITUTE OF TECHNOLOGY, pp.1037 1038, Sep 2003   ZHAO Qing-jie, LIAN Guang-yu, SUN Zeng-qi, “Suvey of Robot Visual Serving”, CONTR0L AND DECISION, pp.850–852, Nov 2001   FU Rong, XU Hong-Li, “Color Image Retrieval Method Based on Wavelet Multi-scale Analysis”, Journal of Image and Graphics pp.1327–1330, Nov 2004 
72 
72 


error either across the entire image or speci\002cally in areas not adjacent to object edges The reconstruction algorithm then employs the binary mask to select the appropriate portions of each preliminary reconstructed image and then combine them into a single 002nal image During evolution of the 002lter designed to reduce error near edges the entire training image is reconstructed but 002tness is only calculated at the pixel positions located within the black portions of the mask enclosing the edges identi\002ed by the edge detection algorithm for the provided training image This approach forces the GA to evolve a 002lter that improves image reconstruction near object edges Section 5 describes the development of this 002lter The 002lter used to reconstruct the remaining areas of images may be optimized to either reduce error across an entire image or to speci\002cally reduce the error in the portions of an image not adjacent to object edges 050not selected by the binary mask\051 These two approaches are contrasted in section 6 For clarity we refer to 002lters evolved using the entire image as globally evolved 002lters and to 002lters evolved using the edge-enclosing masks as locally evolved 002lters Locally evolved 002lters are optimized either for the edge-adjacent or non-edge-adjacent portions of images as noted 4 P RELIMINARY E XPERIMENTS The edge detection algorithm generates a greyscale image isolating the edges within a satellite image as shown in 002gure 6 Edges are then isolated through the generation of a binary mask separating dark pixels from light pixels in the edge image Our initial experiments seek to identify an appropriate pixel shade threshold for binary mask generation that ultimately provides improved image reconstruction near object edges Preliminary analysis indicates satisfactory MSE results using appropriate mask threshold determination on selected satellite images Mask Threshold Determination The creation of the binary mask used to isolate the edge portions of the training image requires a set threshold This threshold dictates the required strength of the edge detection output for a given pixel position to be considered part of an edge for the mask In the range 0 000   lower thresholds select fewer areas of the image as edges Higher thresholds enclose a higher portion of the training image To determine an appropriate setting for the edge threshold several GA runs are conducted using the U.S Air Force museum image from 002gure 2 At a quantization level of 64 and one level of decomposition the MSE of the image reconstructed using the Daub4 DWT 000 1 is 138.13 A globally evolved 002lter used as a baseline for comparison achieves a reconstruction MSE of 106.108 representing a reduction of 23.18 Local 002lters for the reconstruction of object edges are evolved using edge masks generated at various threshold settings ranging from 48 up to 192 Recall that during evolution MSE 002tness is only assessed near the object edges of the training image as Figure 9   MSE improvement in masked region of edgeevolved 002lter against Daub4 wavelet 050dashed\051 and globally evolved 002lter 050dotted\051 indicated by the mask created at the given threshold At each threshold the locally evolved 002lter response is compared to the Daub4 DWT 000 1 response and the globally evolved 002lter response for the edge portions of the training image isolated by the mask The  reductions in MSE of the local 002lter against the global 002lter and the wavelet are plotted in 002gure 9 The local 002lters exhibit a reduction typically ranging from 14\22616 against the Daub4 wavelet Against the globally evolved 002lter the local 002lters demonstrate an improvement of 21.30 at a conservative threshold of 48 The degree of improvement steadily declines as the threshold increases but remains signi\002cant at thresholds below 120 This makes sense because at low thresholds only dark positions of the edge detection algorithm indicating large intensity transitions between neighboring pixels 050strong edges\051 are encompassed by the mask images At higher thresholds the masks are less selective and encompass larger portions of the image The two plots cross at a threshold of 112 at this point the responses of the wavelet and the globally evolved 002lter are approximately equal From this point the wavelet outperforms the global 002lter in the mask-encompassed portion of the image to an increasing degree as the threshold decreases The reverse is true as the threshold increases This con\002rms that the globally evolved 002lter while reducing error across the entire image actually increases reconstruction error near object edges However the locally evolved 002lters provide consistent improvement near object edges Figure 10 plots the overall reduction in MSE with the image reconstructed using the combined locally and globally evolved 002lters versus the globally evolved 002lter alone at each tested threshold level Improvement ranges from 1.98\2262.25 at thresholds under 120 with the best performance coming at a threshold of 104 At this threshold the MSE reduces from 106.11 to 103.72 a reduction of 2.25 While this may not 7 


Figure 10   MSE improvement for entire image using combined reconstruction over reconstruction with globally evolved 002lter only seem to be a signi\002cant improvement across the entire image this improvement occurs strictly near object edges such as building outlines or aircraft pro\002les The portions of the image most critical for intelligence analysis demonstrate signi\002cantly improved reconstruction Performance on Selected Satellite Images The results above demonstrate trends in 002lter response but because each is the result of a single GA run on a single image statistically sound conclusions may not yet be drawn In order to assess the performance of the proposed technique on a wider range of conditions replicated GA experiments are conducted at multiple threshold levels for the four satellite images presented in 002gure 5 For each image a global reconstruction 002lter is evolved as well as an edge-isolated local 002lter using masks created at threshold levels 48 88 and 104 in a single experimental replication Fifteen total replications are conducted for each image The responses of the wavelet the globally evolved 002lter and the locally evolved 002lter are recorded at each threshold level for the mask-enclosed portion of the image Table 1  MSE of images reconstructed with Daub4 wavelet and globally evolved 002lters Table 1 presents the MSE of each image reconstructed with the Daub4 DWT 000 1 and the average MSE achieved with the globally evolved 002lters across all replications Evolved 002lters reduce MSE by between 13.57 and 20.51 on average deTable 2   of images covered by masks created at each threshold Table 3  Mean  MSE reduction in area enclosed by masks using combined 002lter reconstruction pending on the image The masks created for each threshold encompass varying amounts of the training images Table 2 provides the  of each image enclosed by the masks for each threshold value The masks for the Baghdad image encompass between 24.67 and 41.56 of the image as seen in 002gure 7 050top right\051 the large number of structures in this image lead to a large number of edges in the image The remaining images are much more edge sparse with the Air Force museum image containing the smallest percent covered by the edge mask The locally evolved 002lters are compared within the maskenclosed regions for each image in table 3 This table shows the average reduction of MSE over the wavelet 050top\051 and over the evolved 002lters 050bottom\051 for the given image The best result and any results not statistically signi\002cantly different are shown in bold for each image T-tests at signi\002cance level 013  0  05 provides assessments of the differences between results Within the mask-enclosed region the local 002lters perform very well compared to the wavelet The threshold value does not appear to strongly in\003uence performance 8 


Table 4  Mean  MSE reduction of entire images using combined 002lter reconstruction for the given images The local 002lters demonstrate the best performance at a threshold of 104 for two images and only slightly lower than the best performance for the two remaining images Compared to the globally evolved 002lters the local 002lters show signi\002cantly improved results for three of four images with the best performance typically coming at a threshold of 48 consistent with the plot in 002gure 9 demonstrating greater improvement over the globally evolved 002lter at smaller threshold values The locally evolved 002lters provide only minor improvement over the global 002lters for the Baghdad image Recall from table 2 this image contains the greatest degree of edge transitions Filters trained on this image exert a relatively large amount of selective pressure on 002lters providing improved reconstruction near object edges Images containing fewer edges provide less evolutionary pressure preferring improved reconstruction across the entire image at the expense of reconstruction near edges Table 4 shows MSE improvement when combining the global and local 002lters for reconstruction The top portion shows improvement over the Daub4 DWT 000 1 when the mask-covered portion of the image is reconstructed with the local 002lter and the remainder with the wavelet Because masks enclose a small portion of each image improvement is modest These small gains are measured across the entire image though all improvement comes near edges  Not surprisingly the greatest error reduction comes for the Baghdad image containing the largest mask coverage The best improvement comes at a mask threshold of 104 for each image consistent with the trends illustrated in 002gure 10 The lower portion of table 4 provides results seen for reconstruction using both local and global evolved 002lters over use of globally-evolved 002lters alone The Baghdad image demonstrates the smallest improvements this image provides suf\002cient selection pressure for edge reconstruction as a training image The remaining images show reconstruction improvement of between 2.22 and 3.41 even though a relatively small portion of each image is covered by the mask The best improvements typically occur at the 104 threshold where a larger amount of image coverage provides greater room for improvement 5 R ECONSTRUCTION A DJACENT TO E DGES Because image transforms evolved for global reconstruction of an entire image demonstrate increased error near object edges we place emphasis upon the reduction of reconstruction error near edges The evolution of a robust image 002lter for near-edge reconstruction requires the identi\002cation of training images that result in 002lters that perform well on the reconstruction of unseen images 50 GA runs are conducted to evolve 002lters for near-edge reconstruction Each run employs one of the 50 unique available satellite images as the training image Images are referenced according to their number in the satellite image set as reported in the 002rst image would be referred to as sat01 The GA attempts to minimize the MSE within the edge-adjacent portions of the training image during 002lter evolution After evolution the resulting reconstruction 002lter's performance is assessed across all 50 satellite images We suspect that the abundance of object edges within a training image may in\003uence its performance as a training image For each evolved 002lter 002gure 11 plots the average  MSE reduction near edges compared to the Daub4 DWT 000 1 002lter obtained across all 50 images plotted against the  of that 002lter's training image enclosed by the binary edge detection mask obtained at a mask generation threshold of 88 050see section 4\051 From this plot it appears that there is a loose correlation between training image edge abundance and the performance of that image's corresponding evolved 002lter performance Training images with fewer than 10 of their pixels near object edges perform significantly worse than the Daub4 DWT 000 1 002lter On the other hand several images with greater than 25 of pixels near edges result in 002lters providing an average MSE reconstruction improvement near edges of approximately 17 Not all images with an abundance of pixels near edges provide strong performance as training images however It appears that the abundance of pixels near object edges is an important factor in the training performance of images but there may be other important factors as yet unidenti\002ed that play an important role in training image performance as well Images in the satellite set are also ranked according to their reconstruction dif\002culty as test images For each test image the  MSE improvement over the DWT 000 1 002lter is averaged across each of the 50 evolved transform 002lters The average improvement for each test image is plotted against the  of pixels near edges in 002gure 12 Some images are very dif\002cult for the evolved 002lters to reconstruct while others demonstrate an average improvement of nearly 10 over the DWT 000 1 002lter regardless of the evolved 002lter used Based on the seemingly random distribution of points in the plot there does not 9 


Figure 11  Scatterplot of MSE  improvement in edgeadjacent portions of training images against  of training images adjacent to object edges Improvement is averaged across all test images appear to be any correlation between an image's edge abundance and its dif\002culty as a reconstruction test case Figure 12  Scatterplot of MSE  improvement in edgeadjacent portions of test images against  of test images adjacent to object edges Improvement is averaged across 002lters evolved for reconstructing the edge-adjacent portions of images A single GA run using each training image enables an initial ranking of the training images but is insuf\002cient to identify a single best image To identify a single best training image for edge-adjacent reconstruction 30 GA replications are performed for each of the 002ve best initially-ranked training images 30 replications provide a suf\002cient sampling to enable a robust statistical analysis of the results For each replication the average performance of the evolved 002lter is assessed as the average percentage reduction of MSE for reconstruction in the binary mask-enclosing areas of each of the 50 satellite images Table 5 reports statistics collected across Table 5  Results of replicated GA experiments comparing performance of 002lters evolved using the top 5 ranked training images for reconstruction of edge-adjacent portions of satellite images Evolved 002lter performance is assessed as the average MSE  improvement over the Daub4 DWT 000 1 002lter across all test images Statistics are assessed over 30 GA replications for each training image all 30 replications for each image Image sat30 provides the best mean and median performance as a training image Filters evolves using this image provide an average MSE reduction of 17.02 across all images in the satellite set for the reconstruction of pixels near object edges We conducted a series of hypothesis tests comparing the results of the sat30 training replications with the replications obtained for each of the other top-ranked training images All tests are conducted at a con\002dence level 013  0  05  Lilliefors tests determine the normality of the replicated results Only the results for the sat39 training image do not strongly con\002rm to a normal distribution though with a p-value of 0.0423 they only slightly fail this test Since the results of all replication sets are largely normal we compare the mean values of results using standard two-sided t-tests We also compare the medians using the more conservative non-parametric Wilcoxon ranksum tests and compare the distributions directly using the non-parametric Kolmogrov-Smirnov test The results of these tests indicate that while the sat30 image provides the best performance for training edge-targeted reconstruction 002lters the sat17 image provides statistically equivalent performance The remaining three training images demonstrate strong performance but do not provide as great of an improvement over the Daub4 DWT 000 1 002lter for reconstructing near-edge pixels One of the replications obtained using the sat30 training image provides the best observed chromosome for the reconstruction of images near edges The corresponding low and high frequency reconstruction 002lter coef\002cients are as fol10 


lows Low R  f 0  4794  0  7915  0  2302  000 0  0892 g High R  f\000 0  2013  000 0  0246  0  6493  000 0  2917 g 0507\051 Across all 50 satellite images this 002lter reduces the MSE of pixels reconstructed near object edges by an average of 17.10 over the Daub4 DWT 000 1 002lter with a standard deviation of 1.66 The worst improvement was 12.69 with improvement reaching as high as 20.91 This consistent performance demonstrates that the evolved 002lter is well suited for the reconstruction of unseen images and is not the result of overtraining by the genetic algorithm for the provided training image 6 R ECONSTRUCTION N ONADJACENT TO E DGES In reconstruction 002lters are e v olv ed to pro vide impro v ed reconstruction for entire satellite images with no particular emphasis upon the reconstruction of pixels near object edges The experiments presented in follo w the same e xperimental framework presented here with 30 GA replications comparing the performance of the 5 top-ranked training images for global reconstruction 002lter evolution The best 002lter coef\002cients obtained for global image reconstruction are as follows Low R  f 0  4702  0  7654  0  2373  000 0  0620 g High R  f\000 0  1979  000 0  0316  0  6372  000 0  2921 g 0508\051 The performance of globally evolved 002lters provides signi\002cant improvement over the Daub4 DWT 000 1 002lter under conditions subject to quantization error In the areas of images not selected by the edge detection mask 050not adjacent to object edges\051 the 002lter shown in equation 8 reduces the MSE by an average of 14.98 with a standard deviation of 2.12 While this 002lter may provide suf\002cient performance for the reconstruction of pixels not adjacent to edges we conduct a series of experiments to determine whether 002lters evolved only to improve non-edge adjacent reconstruction provide improved reconstruction In these experiments 002tness is assessed by the GA as the reconstruction error only in pixels not covered by the binary edge detection masks  As before an initial set of 50 GA runs evolve 002lters using each of the satellite images for training The top-5 initially ranked training images are each used in a set of 30 replicated GA experiments The results of these experiments are summarized in table 6 In this case all 002ve replication sets pass a Lilliefors test for normality The sat08 image provides the best training performance resulting in an average improvement of 15.87 with a standard deviation of 0.18 across all 50 satellite images A series of hypothesis tests comparing the sat08 replication results to the results obtained for the other best-ranked training images demonstrate that the sat31 and sat04 training images provide statistically equivalent performance Any of these three images provide Table 6  Results of replicated GA experiments comparing performance of 002lters evolved using the top 5 ranked training images for reconstruction of non-edge-adjacent portions of satellite images Evolved 002lter performance is assessed as the average MSE  improvement over the Daub4 DWT 000 1 002lter across all test images Statistics are assessed over 30 GA replications for each training image strong performance for the training of 002lters designed for reconstructing the pixels in an image One of the 002lters obtained using sat04 as a training image provides the best observed performance for reconstruction away from edges The coef\002cients for this 002lter are Low R  f 0  4593  0  7322  0  2493  000 0  0253 g High R  f\000 0  1858  000 0  0130  0  6700  000 0  2692 g 0509\051 Across the entire set of 50 satellite images this 002lter achieves a 16.18 mean MSE improvement with a 2.52 standard deviation in the areas of the images not covered by their respective binary edge masks The median improvement is 16.65 with a minimum and maximum improvement of 7.81 and 20.54 respectively This 002lter outperforms the best globally evolved 002lter shown in equations 8 by an average of 1.42 in the reconstruction of pixels not adjacent to object edges with a standard deviation of 1.70 The maximum improvement is 6.24 This 002lter outperforms the globally evolved 002lter for 37 of the 50 satellite images Among the images for which the global 002lter exhibits better improvement its performance is not greater than 1.65 better than this 002lter In general the 002lter optimized for the reconstruction of nonedge-adjacent pixels provides improved reconstruction over a globally evolved 002lter These results justify the use of two locally evolved 002lters for image reconstruction one for the reconstruction of the image covered by the binary edge mask and the other for the remainder of the image 11 


7 D ISCUSSION The image reconstruction scheme illustrated in 002gure 8 requires two separate evolved reconstruction 002lters one for reconstruction of the image near object edges and the other for reconstruction away from edges The 002lters presented in equations 7 and 9 are optimized to reconstruct the edgeadjacent and non-edge adjacent portions of images respectively Using these combined 002lters to reconstruct all of the satellite images results in a mean MSE improvement of 16.53 with a standard deviation of 1.91 The improvement ranges from a minimum of 8.94 up to a maximum of 20.59 In contrast the best globally evolved 002lter in equation 8 only provides a mean improvement of 15.21 with a standard deviation of 1.78 Overall improvement with the global 002lter ranged from 8.83 up to 19.04 Our proposed image reconstruction approach utilizing edge and non-edgetargeted optimized 002lters improves upon the performance of both the Daub4 DWT 000 1 002lter and the best identi\002ed globallyevolved 002lter By utilizing 002lters optimized for high-spacial frequency changes for reconstruction near edges and 002lters optimized for low-spacial frequency changes for non-edgeadjacent edges we are able to realize better reconstruction resolution than a single 002lter optimized for an entire image permits The successful optimization of robust image transforms requires the careful selection of an appropriate image for training during evolution The scatter plot in 002gure 11 demonstrates the importance of training image selection Several training images result in 002lters that fail to improve upon the performance of the standard inverse wavelet transform in the reconstruction of the collected satellite images This is due to overtraining by the genetic algorithm The GA discovers a 002lter that provides strong reconstruction of the supplied training image but the resulting 002lter does not generalize well to the remaining satellite images and may provide signi\002cantly worse performance than the wavelet Though we recognize the importance of training image selection to the ultimate performance of the resulting evolved image 002lters the identi\002cation of salient image features governing an image's suitability for GA training remains an open research question Figure 13 shows the 002ve best training images for near-edge reconstruction 002lter optimization while 002gure 14 shows the 002ve worst images Filters trained upon the best images provide strong performance across the entire satellite image set In contrast 002lters trained using the worst images demonstrate very poor performance While there appears to be a loose correlation between performance and the number of near-edge pixels in the training image 050see 002gure 11\051 there are likely other factors at play as well These factors may include the distribution of light and dark pixel intensities in the image the shape and direction of long and short object edges or the rotational axis of the training image relative to the distribution of object edges The good training images tend to contain many small boxed objects such as houses oil storage tanks and hangers while the poor training edges contain fewer buildings The distribution of buildings/small geometric objects may in\003uence an image's training performance in an as yet unforseen manner Future research should focus upon the factors impacting an image's suitability as a GA training sample This may lead to the identi\002cation of improved training samples outside of the current image database and thus leading to greater performance from evolved image 002lters 8 C ONCLUSIONS Existing techniques of 002lter evolution potentially provide signi\002cant improvement over standard wavelet transforms but they may increase the error present near the edges of objects Image processing applications such as target recognition and intelligence gathering cannot afford this resolution loss in the most critical sections of the image The use of an edge detection algorithm and an edge-enclosing mask allows the evolution of reconstruction 002lters that improve the reconstruction resolution near object edges by as much as 20 under conditions subject to high quantization error Likewise 002lters evolved with emphasis upon the reconstruction of pixels not adjacent to object edges outperform existing 002lter optimization techniques through the remaining portions of images By ignoring edges such 002lters demonstrate an improved response over globally evolved 002lters to the edge-sparse portions of images Reconstruction combining 002lters optimized for near edge and non-edge adjacent performance provides a robust reconstruction algorithm suitable for applications requiring maximum object resolution while maintaining maximal compression ratios Results indicate that there may exist a correlation between the degree of edges within an image and the potential improvement a locally evolved 002lter may provide Future experiments should focus on images containing a wide range of edge sparseness or abundance while studying the in\003uence of other image properties upon a given image's suitability as a training sample Experiments should focus on the determination of appropriate mask creation thresholds for images of various edge abundance These experiments will lead to the development of a system that given an image determines the appropriate threshold setting and selection of appropriate 002lters from a library of previously evolved 002lters Recent related research has focused upon the optimization of image transform 002lters of greater length and complexity designed to outperform wavelets at greater levels of multiple resolution analysis regardless of quantization level As the complexity of evolved transforms increases the separation of the reconstruction task into unique 002lters for the reconstruction of pixels adjacent and non-adjacent to object edges may be of further bene\002t Further research will establish the performance of this reconstruction strategy upon increasingly complex image transform 002lters Lossy image processing systems that maintain high resolution near object edges improve the amount of useful intelligence 12 


Figure 13  The 002ve best training images for 002lter evolution of edge-adjacent image portion reconstruction Figure 14  The 002ve worst training images for 002lter evolution of edge-adjacent image portion reconstruction that may be gathered from images reconstructed using this approach This improved performance may be of particular interest to the scienti\002c defense and homeland security communities that require the transmission of copious amounts of data over bandwidth-limited channels without signi\002cant loss of observational information A CKNOWLEDGMENTS The authors thank the U.S Air Force Research Laboratory Sensors Directorate 050Dr Robert Ewing\051 and the U.S Air Force Of\002ce of Scienti\002c Research 050Computational Mathematics\051 for their support R EFERENCES   C E Shannon and W Weaver The Mathematical Theory of Communication  University of Illinois Press 1964   A Gersho and M Gray Vector Quantization and Signal Compression  Kulwer Academic Publishers 1991   B E Usevitch 223A tutorial on modern lossy wavelet image compression foundations of jpeg 2000,\224 IEEE Signal Processing Magazine  pp 22\22635 September 2001   I Daubechies Ten Lectures on Wavelets  SIAM 1992   G Davis and A Nosratinia 223Wavelet-based image coding an overview,\224 Applied and Computational Control Signals and Circuits  vol 1 no 1 1998   M R Peterson G B Lamont and F Moore 223Improved evolutioanry search for image reconstruction transforms,\224 in Proceedings of the IEEE World Congress on Computational Intelligence  2006 pp 9785\2269792   A Skodras C Christopoulos and T Ebrahimi 223The jpeg 2000 still image compression standard,\224 pp 36\22658 2001   J Walker A Primer on Wavelets and Their Scienti\002c Applications  CRC Press 1999   D A Huffman 223A method for the construction of minimum redundancy codes.\224 in Proceedings of the IRE  vol 40 1952 pp 1098\2261101   M Lankhorst and M van der Lann 223Wavelet-based signal approximations with genetic algorithms,\224 in Proceedings of the 4th Annual Conference on Evolutionary Programming  1995 pp 237\226255   E Jones P Runkle N Dasgupta L Couchman and L Carin 223Genetic algorithm wavelet design for signal classi\002cation,\224 IEEE Transactions on Pattern Analysis and Machine Intelligence  vol 23 no 8 pp 890\226895 August 2001   U Grasemann and R Miikkulainen 223Evolving wavelets using a coevolutionary genetic algorithm and lifting,\224 in Proceedings of the Genetic and Evolutionary Computation Conference GECCO-04  ser Lecture Notes in Computer Science vol 3103 Springer-Verlag 2004 pp 969\226980   F Moore 223A genetic algorithm for optimized reconstruction of quantized signals,\224 in IEEE Congress on Evolutionary Computation 050CEC\051 Proceedings vol 1  2005 pp 105\226111   A Bruckmann T Schell and A Uhl 223Evolving subband structures for wavelet packet based image compression using genetic algorithms with non-additive cost functions,\224 in Proceedings of the International Conference on Wavelets and Multiscale Methods  1998 13 


  Y Hill S O'Keefe and D Thiel 223An investigation of wavelet design using genetic algorithms,\224 in Microelectronic Engineering Research Conference  2001   B S Rani and S Renganathan 223Wavelet based texture classi\002cation with evolutionary clustering networks,\224 in TENCON 2003 IEEE Conference on Convergent Technologies for Asia-Paci\002c Region  vol 1 2003 pp 239\226 243   U Grasemann and R Miikkulainen 223Effective image compression using evolved wavelets,\224 in Proceedings of the Genetic and Evolutionary Computation Conference 050GECCO'05\051  2005 pp 1961\2261968   W Sweldens 223The lifting scheme a custom-design construction of biorthogonal wavelets,\224 Journal of Aplied and Computational Harmonic Analysis  vol 3 no 2 pp 186\226200 1996   T Hopper C M Brislawn and J N Bradley 223Wsq gray-scale 002ngerprint image compression speci\002cation,\224 Federal Bureau of Investigation Tech Rep IAFIS-IC-0110 February 1993   F Moore 223A genetic algorithm for evolving improved mra transforms,\224 WSEAS Transactions on Signal Processing  vol 1 no 1 pp 97\226104 2005   F Moore P Marshall and E Balster 223Evolved transforms for image reconstruction,\224 in IEEE Congress on Evolutionary Computation 050CEC\051 Proceedings vol 3  2005 pp 2310\2262316   Google 223Google earth plus,\224 http://earth.google.com 2006   M R Peterson G B Lamont F Moore and P Marshall 223A satellite image set for the evolution of image transforms for defense applications,\224 in GECCO 07 Proceedings of the 2007 GECCO conference companion on Genetic and evolutionary computation  New York NY USA ACM Press 2007 pp 2901\2262906   A H Wright 223Genetic algorithms for real parameter optimization,\224 in Foundations of Genetic Agorithms  G Rawlins Ed San Mateo Morgan-Kaufman 1991 pp 205\226220   I E Sobel 223Camera models and machine perception,\224 Ph.D dissertation Electrical Engineering Department Stanford University Stanford CA 1970   Y Yang 223Color edge detection and segmentation using vector analysis,\224 Master's thesis University of Toronto Toronto Canada 1995   D Kaur and L Ying 223Creating a neuro-fuzzy model by combining 002ltered images with various 002ltering operators for the detection of edges in new images,\224 2006 technical report University of Toledo   B J Babb F W Moore and P Marshall 223Evolved multiresolution analysis transforms for improved image compression and reconstruction under quantization,\224 in IEEE Symposium on Computational Intelligence in Image and Signal Processing  2007 pp 202\226207 B IOGRAPHY Michael Peterson received his B.S degree in Computer Engineering and his M.S degree in Computer Science from Wright State University in 2001 and 2003 respectively He is currently a Ph.D candidate in Computer Science and Engineering at Wright State University Since 2005 he has worked in the Evolutionary Computation Laboratory at the U.S Air Force Institute of Technology where he has developed a robust methodology for the evolution of wavelet-based image reconstruction transforms His research interests include evolutionary and bio-inspired computation signal and image processing pattern recognition and bioinformatics Gary Lamont received the B.S degree in physics and the M.S.E.E and Ph.D degrees from the University of Minnesota Minneapolis in 1961 1967 and 1970 respectively He is currently a Professor of Electrical and Computer Engineering at the Air Force Institute of Technology Wright-Patterson AFB OH where he directs the parallel and distributed computing and the evolutionary computation research groups Previously he was an Engineering Systems Analyst for the Honeywell Corporation for six years He has authored or coauthored a book several book chapters and over 100 papers His current research interests include parallel/distributed computation evolutionary computation 050genetic algorithms evolutionary strategies\051 combinatorial optimization problems 050single objective multiobjective\051 formal methods software engineering digital signal processing intelligent and distributed control systems computational and numerical methods and computer-aided design 14 


CONCLUSIONS Given that this project was intended to estimate missions lying 10-15 years out we structured it differently than one intended to estimate contemporary projects A variety of conventional techniques were not used as we felt they would over fit training observations and thus not be suitable for prediction We also were not sure which approach would work so we tried many We heavily favored ensemble methods where models are combined because we surmised that any one model could not be guaranteed to have the best view of the future However a single neural network ultimately yielded the most competitive results Another finding was that methods built upon simple models such as with three variables generally did work best not surprisingly because they were less likely to over fit calibration data A graph of the three best methods is shown in figure 18 with estimates for the same missions sorted by cost For the neural network calibration occurred until just before the results shown for continuous boosting calibration occurred no more recently than 15 years prior to the results and for Adaboost calibration also occurred up until the results shown A graph sorted by year is not shown we think it instructive that no results seemed to degrade over time As mentioned but obvious from figure 17 the neural network performs best followed by Adaboost and then continuous boosting It is interesting to note that the three cases in which the neural network goes haywire and predicts too low also correspond to worst performances for the Adaboost method pointing to exceptional data points We will be further investigating these regularly errant results and other outliers which may result in estimating improvements ACKNOWLEDGEMENTS This work was carried out under Small Business Innovation Research contract FS9453-05-C-0023 with the Air Force Research Lab The authors wish to gratefully acknowledge Judy Fennelly and later Ross Wainwright our technical points of contact at AFRL for their continuous support and encouragement Our contract officer Timothy Provencio also provided invaluable assistance Our critical seed stock of data was provided by Joseph Hamaker who previously was Director of NASA Headquarters Cost Analysis Division and now is Senior Cost Analyst with SAIC Ainsley Chong and Dale Martin USAF Ret also lent considerable assistance with data gathering APPENDIX A MISSIONS COLLECTED Active Cavity Radiometer Irradiance Monitor Satellite Active Magnetospheric Particle Tracer Explorer Adeos Advanced Communications Technology Satellite Advanced Composition Explorer Alexis Amos-I AMSC-1 Anik El Anik E2 Applications Technology Satellite-I Applications Technology Satellite-2 Applications Technology Satellite-5 All MREs Lu 1.00 0.75 l 0.50l 0.25 l 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75-2.00oi v 1   Cost o N X  X~~~~~Cl Figure 16 Comparison of estimating error for three best methods 15 


Applications Technology Satellite-6 Aqua Argos Atmospheric Explorer AURA Aurora 2 Calipso Cassini Cassini Spacecraft  Huygens Probe Chandra X Ray Observatory CHIPSat Clark Clementine CloudSat COBE Columbia 5 Contour CRRES DART Dawn DBS-1 Deep Impact Flyby Spacecraft  Impactor Deep Space 1 Deep Space 2 Defense Meteorological Satellite Program-5D Defense Meteorological Satellite Program-5D3 Defense Support Program DSCS 3 FIO DSCS 3 F7 DSCS I DSCS-II DSCS-IIIA DSCS-IIIB Dynamics Explorer-I Dynamics Explorer-2 Earth Observing Satellite 1 Earth Radiation Budget Experiment EchoStar 5 Extreme Ultraviolet Explorer Far Ultraviolet Spectroscopic Explorer FAST FLTSATCOM 6 Galaxy 5 Galaxy 11 Galaxy Evolution Explorer Galileo Orbiter  Probe Gamma Ray Large Area Space Telescope GE 1 GE 5 Genesis GFO 1 Globalstar 8 Glomr GOES 3 GOES 9 GOES N GPS-1 GPS-IIR GPSMYP GRACE Gravity Probe-B GRO/Compton Gamma Ray Observatory GStar4 Hayabusa HEAO-1 HEAO-2 HEAO-3 HESSI-II High Energy Transient Explorer-II HETE HST ICESat Ikonos IMAGE IMP-H Inmarsat 3-F5 Intelsat K INTELSAT-II INTELSAT-IV International Ultraviolet Explorer Iridium James Webb Space Telescope Jason 1 JAWSAT KEPLER KOMPSAT LANDSAT1 LANDSAT-4 LANDSAT-7 Lewis Lunar Orbiter Lunar Prospector Magellan Magsat Mariner-4 Mariner-6 Mariner-8 Mariner1 0 MARISAT Mars Exploration Rover Mars Express/Beagle 2 Mars Global Surveyor Mars Observer Mars Odyssey Mars Surveyor 2001 Orbiter Mars Pathfinder  Sojourner Rovers Mars Polar Lander Mars Reconnaissance Orbiter Mars Telecommunication Orbiter Mars Climate Orbiter Messenger Meteor Mid-course Space Experiment MightySat Milstar 3  Adv EHF Model-35 Morelos NATO III Near Earth Asteroid Rendezvous NEAR Shoemaker New Horizons 16 


NIMBUS NOAA 8 NOAA 15 NPOESS Preparatory Project Orbital Maneuvering Vehicle Orbcomm Orbiting Carbon Observatory Orbiting Solar Observatory-8 Orbview 2 Orion 1 P78 Pas 4 Phoenix Pioneer P-30 Pioneer Venus Bus/Orbiter Small Probe and Large Probe Pioneer-I 0 Polar QuikSCAT Radarsat Reuven High Energy Solar Spectroscopic Imager REX-II Rosetta Instruments Sage III SAMPEX Satcom C3 Satcom C4 SBS 5 SCATHA Seastar SMART-1 SNOE Solar Dynamics Observatory Solar Maximum Mission Solar Mesosphere Explorer Solar Radiation and Climate Experiment Solar Terrestrial Relations Observatory Space Interferometry Mission Space Test Program Small Secondary Satellite 3 Spitzer Space Telescope SPOT 5A Stardust  Sample Return Capsule STEPO STEPI STEP3 STEP4 STRV ID Submillimeter Wave Astronomy Satellite Surfsat Surveyor Swift Gamma Ray Burst Exporer Synchronous Meterological Satellite-I TACSAT TACSAT 2 TDRS F7 Tellura Terra Terriers Tethered Satellite System Thermosphere Ionosphere Mesosphere Energetics and Dynamics TIMED TIROS-M TIROS-N TOMS-EP Total Ozone Mapping Spectrometer TOPEX TRACE Triana Tropical Rain Measuring Mission TSX-5 UFO I UFO 4 UFO 9 Ulysses Upper Atmosphere Research Satellite Vegetation Canopy Lidar VELA-IV Viking Viking Lander Viking Orbiter Voyager Wilkinson Microwave Anisotropy Probe WIND WIRE XMM X-Ray Timing Explorer XTE XSS-iO XSS-ii APPENDIX B FIELDS COLLECTED Mission Mission Scenario Mission Type Launch Year Launch Vehicle Bus Model Bus Config Bus Diameter Location Expected Life Flight Profile Flight Focus Technical Orbit Currency Total Cost Including Launch Unit Sat Costs Average Sat Cost Production Costs Launch Costs Operations Cost Orbit Weight Wet Weight Dry Weight Max Power EOL Power BOL Power  of Batts 17 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



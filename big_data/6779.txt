402 Mondou Web search engine with textual data mining Hiroyuki Kawano Kyoto University ABSTRACT It is too difficult to discover useful documents on web without rich background knowledge In this paper with applying techniques of the textual data mining to the web resource discovery we try to derive effective association rules in order to submit more effective queries From 1995 we have been developing the resource discovery system Mon dou which derives associative keywords from collected and parsed Japanese web pages This paper includes a brief eval uation 
of our system and java applet in order to visualize search results with multi-dimensional measurements 1 Introduction The volume of web documents is increasing exponentially it makes difficult to find cool URLs for various users Es pecially increasing of web documents makes it difficult to find out the adequate URLs including invaluable informa tion and to discover the relationship among world wide web sites[3 Many search engines, Lycos AltaVista and many others in the web, make it possible to retrieve web documents by the technology of textual database as a legacy system using typ ical boolean expressions However 
without rich background knowledge about the relations or structures of keywords it is impossible to judge whether interesting documents really include the combination of several keywords Therefore in order to describe effective queries it is important to grasp the suitable combination or descriptions of keywords which exist in the web as textual database We develop the search engine with applying techniques of textual data mining to the web resource Our developed search engine provides the search results including associative keywords, users are easily able to modify initial query with boolean expressions of keywords In 
this paper we explain the ability of our developing search system which is named as Mondou with applying our proposed mining algorithm to the collected Japanese HTML documents RCAAU means the 223retrieval location by weighted association rule\224 in the digital 223monde\224 and R-C-A-A-U also spells Mondou Using RCAAU we may gain insight into one of the methods of Zen The URL\222 is also referred from many search pages in Japan Our Mondou executed more than one million queries re quired by anonymous users from February in 1996 We an 222http 
www  kuamp kyoto-u ac  jp/labs/inf ocom/mondou index-e  html alyze the part of log and evaluate the effectiveness of our developed search strategies 2 Approach to web mining 2.1 Structure of web space We consider web space as a typical hyper graph we try to analyze the structure of web space by following two types of links Inside link to another page on the same web server Outside 
link to pages on other web servers    0        y 223  i 0 0          f   inside links   outside links   site _  Figure 1 Inside links and outside links We estimate the hyper links in the web by the values of sp,ip op which is the combination of 
the document size the number of inside links and the number of outside links for the parent document P in Figure 1 Then each child documents CI are referred by parent P we can also describe sk,Zk,ok for Ck We define the following cost function pk in order to evalu ate the quality of contents Ck p  s  ik 222 w  Ok  WO We define W and WO as the 
weighted values for inside and outside links respectively Thus we could evaluate pk as the approximate cost of the several attributes for wek documents Figure 2 shows average utilized points pk for thc part of the web space that are evaluated for 6,621 parenl documents including 18,397 links in jp-domain with W  1 and WO  30 From these figures it must be too difficult foi us to discover the interesting contents ck by the function o sp,ip op based on only links 0-7803-3905-3/97/$10.00@1997 IEEE 


403 Therefore in this paper we regard the web space as a simple textual database with hyper links which doesn\222t have strongly integrated data model documents by the following equations where K includes any combina tion of keywords from all keywords K related with retrieving 222i 100 1 I 2215 80 ft 60 0 2000 4000 6000 8000 10000 Document size Bytes E 100 80 40 0 5 10 15 20 25 30 35 40 Number of inside links 223 60 0 5 10 15 20 25 30 35 40 45 50 Number of outside links Figure 2 Utilized point vs size inside links outside links 2.2 Textual data mining At present data mining is noteworthy field to be studied based on various kinds of researches such a.s machine learn ing, inductive learning and knowledge representation with considering characteristic features of database[4 2 6 51 n order to make it possible to retrieve web documents more sophisticatedly by derived keywords We extend the typical mining algorithm to derive association rule[l Weighted association rule We have a brief sketch for mining weighted association rule[7 Basically we extend the original mining algorithm to handle weighted keywords for markup language especially for tags in HTML For example the rule of 223program  database\224 from the sets of  program  and  program, database  will be found in databases by satisfying of the threshold values We create all rules whose confidence is equal to or greater than minconf If rules  program  and  program database  are derived from the set of keywords we discover the rule 223program 3 database,\224 where the values of support and confidence are important measurement for the strongness of rules In addition to the conditions of threshold values in the case of retrieving keyword k if IC appears wtJ times in doc uments T we consider that kJ has the weight of wij and define aij  kJ w Thus we select documents T,\(i E I including set of key words K  kjlj E J from all documents set 7 Given T including atJ  kJ,wy sup\(K  Nu N\(K can be defined 3 Mondou 3.1 Structure of Mondou Mondou consists of the following three main modules 1 agent 2 database 3 query server which are shown in Figure 3 WWW Resources CGI i Daitabase LA Figure 3 The structure of Mondou Generally the first module is called as the robot spider or agent[9 and the robot collects web documents in the net and store them into the textual database. In addition to the stan dard functions of the robot, our intelligent agent parses col lected documents by several methods including natural lan guage processing[lO for Japanese documents Moreover in order to collect more interesting documents, our agent often visits to special URLs as interesting web pages if they chil dren\are referred many times from other web pages outside parent pages The database stores huge numbers of attribute values not only about keywords but also date size of documents and the number of links from other URLs The CGI Common Gate Interface\module of query server is the search program ancl it provides search results and mining association rules The input form of Mondou is shown in Figure 4 it is possi ble to enter combination of search keywords using AND and NOT boolean expressions in each empty box When one submitted initial keyword knowledge Mondou provided several keywords of association 223engineering sys tems U knowledge in Japanese acquisition\224 and so on which is shown in Figure 5 Consequently even by apply ing our proposed algorithm without taxonomies, conceptual trees or ontologies we are able to grasp the association of important keywords in their interesting URLs 


404 Figure 4 Input form of Mondou 3.2 Quality of associative keywords At present we have been operating Mondou in the net and we try to examine the quality of search queries patterns of combination of keywords and so on Table 1 shows typical examples of derived keywords the number of URLs and related keywords derived by our algo rithm Thus we can easily get interesting combination of the key words that can be treated as several meanings in web docu ments Most of beginners could easily grasp the structure of web documents via association of keywords Moreover from February to October in 1996 Mondou ex ecuted 931,537 queries submitted from the netters Surpris ingly there are only 20,734 queries 2.23 with NOT ex pression it is too difficult for most of users to describe the query with adequate NOT keywords The number of query patterns is 338,535 and 51,510 pat terns 15.2 are described by only one keyword 287,025 84.8 patterns are described using more than two key words Most of users can submit various queries using the derived keywords Furthermore keywords including all ex ecuted queries covers 129,445 words 40.5 for all 319,426 keywords which are stored in our database. Thus our Mon dou can provide the rich combination of keywords in order to modify initial submitted query As a result by using textual data mining algorithm in Mondou web surfers could get much more information about the relationship of keywords in the natural way Even if users don't know well about web documents to be find out it is possible to discover the interesting URLs quickly Figure 5 Output results from Mondou 3.3 It is also necessary to develop a visual interface that can express information with multi-dimensional metric including network environment on client side and we can focus on interesting sets with derived association rule Then we have been developing an interactive search interface by Java in Figure 6 we show one example of search results with the attributes as shape, area size brink interval and so on In current implementation we represent the cost of access time from users to the web server and relevance of the URLs including given keywords Moreover the size of documents as area, support sets by derived keywords as color and struc ture of URLs as arrows with quantity are also presented Visualization results of web mining 4 Conclusions and future works In order to retrieve efficiently web documents by suitablc queries we applied the algorithm of mining association rules which is extended to handle weighted keywords in HTML documents which are collected by agents Many users car easily focus on interesting web resources without the knowl edge of taxonomy or intelligent data dictionary given bj data.base administrators We can conclude that our proposec algorithm works very effectively in searching textual data ir the web We developed the first prototype of vondou as a central ized system, but we should improve it as a distributed systen in order to keep much more URLs and to focus on URLs mort effectively since web grows very rapidly We are also improv ing the visual interface for effective search on web browsers 


405 Table 1 Examples of textual data mining keywords number of URLs related keywords applied 1,168 mathematics mechanics analysis physics media geochemistry superconductivity, optics geology engine honda search stirling dragon L 2 7 2 engine in Japanese 876 behavior, similarities parts applied analysis 1,904 fujita numerical, behavior method, top plan, multidimensional _ simulation 634 software 7  I L  7 3 2 simulation in Japanese computer results numerical sciences conference noise advanced center, singapore internet, usa, thailand, las vegas leisure travel guide 77 Acknowledgment This work was supported in part by a Grant in Aid for Science Research from the Ministry of Education Science and Culture of Japan And the part of this work was also supported by the educational grant from Mitsubishi Electric Corporation We also thank students Mr Hideki Nishimura Sharp Corporation and Mr Koichiro Ito \(The Goldman Sachs Group as excellent programmers Figure 6 Visual interface for Mondou References R Agrawal and R Srikant 223Fast Algorithms for Mining Association Rules,\224 Proc of the 20th International Confer ence on Very Large Data Bases Santiago Chile pp.487-489 1994 M.-S Chen J Han and P S Yu 223Data Mining An Overview from a Database Perspective,\224 IEEE Trans on Knowledge and Data Engineering vo1.8 No.6 pp.866-883 1996 0 Etzioni 223The World-Wide Web Quagmire or Gold Mine?,\224 Communications of the ACM vo1.39 No.11 pp U M Fayyad G Piatetsky-Shapiro, P Smyth and R Uthu rusamy 223Advances in Knowledge Discovery and Data Min ing,\224 AAAI/MIT Press 1996 T Honkela S Kaski K Lagus and T Kohonen 223News group Exploration with WEBSOM Method and Brousing Interface,\224 Technical Report A32 Laboratory of Computer and Information Science, Helsinki University of Thechnology 1996 H Kawano S Nishio J Han and T Hasegawa, \223HOW Does Knowledge Discovery Cooperate with Active Database Tech niques in Controlling Dynamic Environment?,\224 Proc 5th In ternational Conference on DEXA Athens Greece pp.370 379 1994 H Kawano and T Hasegawa 223Textual Data Mining for In telligent Search Engine in WWW information space,\222\222 Ad vanced Database Symposium 22296 Tokyo pp.27-34 1996 In Japanese D A Keim and H.-P Kriegel 223Visualization Techniques for Mining Large Databases A Comparison,\224 IEEE Trans on Knowledge and Data Ehgineering Vo1.8 No.6 pp.923-938 1996 M Koster 223Guidelines for Robot Writers,\224 http://info.webcrawler.com/mak/pro jects/robots guidelines.htm1 Y Matsumoto S Kurohashi T Utsuro Y Myoki and M Nagao 223Japanese Morphological Analysis System JUMAN Manual version 1.0,\222\222 Nara Institute of Science and Technol ogy 1993 65-68 NOV 1996 


4.1 Results for the Zoo Data Set Table 1 shows the average results over the 5 runs of the cross-validation procedure for the zoo data set Each row of this table is associated with the best-discovered rule for a different rule consequent a pair goal attribute goal attribute value In the Zoo data set there are 11 distinct rule consequents since the goal attributes predator domestic and type can take on 2 2 and 7 distinct values respectively Hence table 1 has 11 rows Note that each row is associated with an individual of the last generation since we used an elitism strategy for preserving the best rule for each rule consequent The first column of Table 1 indicates the pair goal attribute goal attribute value characterizing the rule consequent The second column shows the average value of the degree of interestingness of the rule antecedent AnZnt equation l for the rules having the consequent specified in the first column. This average was computed over 5 rules namely the best rule having that consequent in each of the 5 ms of the cross-validation procedure The thud column of table 1 shows the value of the degree of interestingness of the rule consequent ConsZnt equation 5 for all the rules having the consequent specified in the first column. \(Note that the value of ConsZnt is constant for all the rules with a given consequent The fourth and fifth columns of Table 1 show the predictive accuracy on the training and test sets for the rules having the consequent specified in the first column The sixth column shows the average number of examples covered for the rules having the consequent specified in the first column The average results reported in the fourth fifth and sixth columns were computed in a manner similar to the above-described computation of the average for the second column 221fie predictive accuracy on the training set was computed as defined in equation 6 The predictive accuracy on the test was computed by a simplified version of equation 6 namely c4 h CJ  PI Note that in the case of the test set there is no need to subtract  fiom h CJ as it was done for the training set That subtraction was used in training set to compensate for the fact that the measure c4  CJ  is a too optimistic estimate of the predictive accuracy of a rule on unseen data Quinlan 871 Hence this correction is not necessary in the test set which contains data unseen during training As can be seen in Table 1 overall the discovered rules have a very high value of AntZnt i.e their antecedent are considered by the measure specified in equation l to be very interesting surprising In addition Table 1 shows that most of the discovered rules have a good generalization performance on the test set Five out of the 1 1 rules have a predictive accuracy of 100 in the test set Two other rules have a high predictive accuracy in the test set keeping the same performance level as in the training set Only four rules have a predictive accuracy in the test set significantly smaller than the one in the training set Note that the value of JAJ is not as small as it might look at first glance since the test set has only 20 instances The final rules discovered fiom the full data set are show in Table 2 The table shows the best rule for each possible rule consequent As explained before the quality of these rules is best estimated by looking up the corresponding rows in Table 1 In any case for the sake of completeness we have included in table 2 for each rule the antecedent\222s degree of interest AntZnt the consequent\222s degree of interest ConsZnt the number of examples covered by the rule antecedent MI and the number of correctly predicted examples 1.4  CI Note that most of the rules are not only interesting and highly accurate as shown in Table 1 but also comprehensible at least in the sense of representing high level knowledge and not being very long Table 1 Results of cross-validation for the Zoo data set AntZnt I ConsZnt I PredAcc I PredAcc I VI I 1326 


Table 2 Results of learning from the full zoo data set Goal Value predator false predator, true Discovered Rule Antlnt Conslnt p&cl AI If hah=O and eggs and milkO and 0.9843 1 1 0.74461 8 4 4 If\(airbone=O and\(aquatic=l and backbone=l and 0.952456 0.667491 11 11 backbone=l and tail=l and domestic=l Then predator=O I catsize=l Then predato~l I 1 I I domestic, false I lf\(eggs=l airbone=O and predatot-1 and I 0.957968 I 0.358766 I 22 I 22 domestic true type 1 type 2 type 3 type 4 type 5 type 6 type 72 venomous=O Then Domestic=O Then domestic=l lf\(eggs=O aquatic=O and tail=O 0.959166 0.933428 1 1 If\(eggs=O venomous=O domestic=O Then 0.949641 0.770752 32 32 If\(feathers=l venomous=O Domestic=O 0.95521 3 0.895533 17 17 tYPe=l Then type=2 toothed 1 and\(fins=O and\(domestic=O and\(catsize=O Then\(type=3 and\(tail 1 Then\(type=4 breathes 1  catsize=O Then\(type5 If eggs 1  aquatic=O predator 1  0.936044 0.97493 3 3 3 Iflaquatic 1  breathes=O venomous=O 0.939000 0.93 3428 12 12 Iflairbone=O aquatic=l toothed=l 0.92 1090 0.979998 4 4 I f\(predator I  breathes=O tail=O 0.953098 0.949205 7 7 If\(airbone=l fins=O tail=O Then\(type6 0.928637 0.959579 6 6 Dom est ic=O Th en\(type=7 4.2 Results for the Nursery Data Set Table 3 shows the average results over the 5 runs of the cross-validation procedure for the Nursery data set The meaning of the columns of table 3 is analogous to the meaning of Table 1\222s columns as explained in the previous section In the nursery data set there are 10 distinct rule consequents since the goal attribute finance social and recommendation can take on 2 3 and 5 values respectively The results reported in Table 3 are even better than the results reported in Table 1 Again overall the discovered rules have a high value of Antlnt and have a very good generalization performance on the test set Seven out of the tem rules have a predictive accuracy of 100 in the test set The other three rules have a much lower performance in the test set The final rules discovered fiom the full data set are shown in table 4 The table shows the best rule for each possible consequent The meaning of Table 4\222s columns is analogous to the meaning of Table 2\222s columns Again we warn the reader that the last 4 columns of Table 4 were included only for the sake of completeness, since the quality of the rules shown in Table 4 is best estimated by the correspond rows in Table 3 Table 3 Results of cross-validation for the Nursery data set I Goal atiribute Attribute value  I Antlnt recommendation, recommended  recommendation very recorn I 0.9423296 I 0.9805278 I 0.9566708 I 1 o I 3.0 recommendation priority I 0.921443 I 0.7744442 I 0.9949844 I 1 o I 21.4 recommendation, spec prior I 0.92 12322 I 0.8788452 1 0.9949754 I I O 1 22.8 1327 


convenient 0.8 16497 0.816497 0.816497 I 1 0.999882 0.980528 I L I 0.878845 1 0.774445 social nongrob r Discovered rule If\(has-nurs=very-crit and\(children= more and\(health=recommended\and\(class=priority Then financeconvenient If\(has-nurs=very_crit\and\(housing=convenient and\(social=slightlygrob and \(health-7ecommended and class=specqrior Then finan ce=incov If\(form=complete\and\(housing=critical and\(class=ver y-recom Then sociahorn prob social problematie Antlnt 0.998888 0.999 1 1 1 0.996424 recommendation not-recom Then class=n<t-recim If\(children=l Then class=recommended 0.997195 recommendation recommended recommendation very-recom  recommendation priority recommendation specgrior If\(parents=usual hasnurs=critical and 10.997318 If\(parents=pretentious has-nurs=lessgroper and \(housing=convenient\and \(finance=convenient and social=slightlygrob and health=recommended health=recommended\and class=specgrior housing=less-conv and \(finance=incov health=not recom 0.943364 Then \(class=very recom I If parents=pretensious\and has-nurs=lessgroper I 0.93421 1 and \(form=more\and health-riority form=more\and \(fmance=incov and 5 Conclusion and Future Work Our genetic algorithm GA was designed from the scratch to discover a few interesting rules which might be called 223knowledge nuggets\224 rather than to discover a large set of accurate \(but not necessarily interesting\rules The results reported in this paper are very promising since the GA did discover rules which were both highly accurate on an unseen test set and interesting However, a more extensive empirical evaluation of our GA would be useful and will be object of future research We also intend to extend the GA described in this paper to cope with continuous attributes \(the current implementation can handle only categorical attributes Conslnt 0.706733 0.707481 0.8 16497 T 720 2160 7-p Another direction for further research would be to evaluate the performance of the GA with other rule interestingness measures proposed in the literature Bibliography Cover  Thomas 911 Cover T M and Thomas J A Elements of Information Theory John Wiley Sons 1991 Freitas 981 Freitas A A On objective measures of rule surprisingness Roc 2\224 European Symp. on Principles of Data Mining and Knowledge Discovery PKDD-98 Lecture Notes in Artificial Intelligence 15 10 1-9 1 998 1328 


Freitas 991 Freitas A A A genetic algorithm for generalized rule induction In R Roy et al Advances in Soft Computing  Engineering Design and Manufacturing 340-353 Springer-Verlag 1999 Greene  Smith 931 Greene D P  Smith S F Competition-based induction of decision models om examples Machine Learning 13,229-257 1 993 Hand 971 Hand d Construction and Assessment of ClassiJcation Rules John Willey &sons 1 997 Liu et al 971 Liu B Hsu W  Chen S Using general impressions to analyze discovered class fication rules Roc 31d Int Conf on Knowledge Discovery  Data Mining KDD-97\31-36 AAAI Press 1997 Quinlan 871 Quinlan J R Generating production rules from decision trees Roc IJCAI-87,304-307 \(1987 Suzuki  Kodratoff 981 Suzuki E  Kodratoff Y Discovery of surprising exception rules based on intensity of implication Roc 2"d European Symp on Principles of Data Mining and Knowledge Discovery PKDD-98 Lecture Notes in Artificial Intelligence 1510 10-18. \(1998 Syswerda 891 Syswerda G Ungorm Crossover in genetic Algorithms Roc 3 International conference on genetic algorithms \(ICGA89 2  9 1989 1329 


In Figures 10 and 11 we see MAFIA is approximately four to five times faster than Depthproject on both the Connect-4 and Mushroom datasets for all support levels tested down to 10 support in Connect-4 and 0.1 in Mushroom For Connect-4 the increased efficiency of itemset generation and support counting in MAFIA versus Depthproject explains the improvement Connect 4 contains an order of magnitude more transactions than the other two datasets 67,557 transactions amplifying the MAFIA advantage in generation and counting For Mushroom the improvement is best explained by how often parent-equivalence pruning PEP holds especially for the lowest supports tested The dramatic effect PEP has on reducing the number of itemsets generated and counted is shown in Table 1 The entries in the table are the reduction factors due to PEP in the presence of all other pruning methods for the first eight levels of the tree The reduction factor is defined as  itemsets counted at depth k without PEP   itemsets counted at depth k with PEP In the first four levels Mushroom has the greatest reduction in number of itemsets generated and counted This leads to a much greater reduction in the overall search space than for the other datasets since the reduction is so great at highest levels of the tree In Figure 12 we see that MAFIA is only a factor of two better than Depthproject on the dataset Chess The extremely low number of transactions in Chess 3196 transactions and the small number of frequent 1-items at low supports only 54 at lowest tested support muted the factors that MAFIA relies on to improve over Depthproject Table 1 shows the reduction in itemsets using PEP for Chess was about an order of magnitude lower compared to the other two data sets for all depths To test the counting conjecture we ran an experiment that vertically scaled the Chess dataset and fixed the support at 50 This keeps the search space constant while varying only the generation and counting efficiency differences between MAFIA and Depthproject The result is shown in Figure 13 We notice both algorithms scale linearly with the database size but MAFIA is about five times faster than Depthproject Similar results were found for the other datasets as well Thus we see MAFIA scales very well with the number of transactions 5.3 Effects Of Compression To isolate the effect of the compression schema on performance experiments with varying rebuilding threshold values we conducted The most interesting result is on a scaled version of Connect-4, displayed in Figure 14 The Connect-4 dataset was scaled vertically three times so the total number of transactions is approximately 200,000 Three different values for rebuilding-threshold were used 0 corresponding to no compression 1 compression immediately and all subsequent operations performed on compressed bitmaps\and an optimized value determined empirically We see for higher supports above 40 compression has a negligible effect but at the lowest supports compression can be quite beneficial e.g at 10 support compression yields an improvement factor of 3.6 However the small difference between compressing immediately and finding an optimal compression point is not so easily explained The greatest savings here is only 11 at the lowest support of Conenct-4 tested We performed another experiment where the support was fixed and the Connect-4 dataset was scaled vertically The results appear in Figure 15 The x-axis shows the scale up factor while the y-axis displays the running times We can see that the optimal compression scales the best For many transactions \(over IO6 the optimal re/-threshold outperforms compressing everywhere by approximately 35 In any case both forms of compression scale much better than no compression Compression on Scaled ConnectAdata Compression Scaleup Connectldata ALL COMP 0 5 10 15 20 25 30 100 90 80 70 60 50 40 30 20 10 0 Min Support  Scaleup Factor Figure 14 Figure 15 45 1 


6 Conclusions We presented MAFIA an algorithm for finding maximal frequent itemsets Our experimental results demonstrate that MAFIA consistently outperforms Depthproject by a factor of three to five on average The breakdown of the algorithmic components showed parent-equivalence pruning and dynamic reordering were quite beneficial in reducing the search space while relative compressiodprojection of the vertical bitmaps dramatically cuts the cost of counting supports of itemsets and increases the vertical scalability of MAFIA Acknowledgements We thank Ramesh Agarwal and Charu Aggarwal for discussing Depthproject and giving us advise on its implementation We also thank Jayant R Haritsa for his insightful comments on the MAFIA algorithm and Jiawei Han for providing us the executable of the FP-Tree algorithm This research was partly supported by an IBM Faculty Development Award and by a grant from Microsoft Research References I R Agarwal C Aggarwal and V V V Prasad A Tree Projection Algorithm for Generation of Frequent Itemsets Journal of Parallel and Distributed Computing special issue on high performance data mining to appear 2000 2 R Agrawal T Imielinski and R Srikant Mining association rules between sets of items in large databases SIGMOD May 1993  R Agrawal R Srikant Fast Algorithms for Mining Association Rules Proc of the 20th Int Conference on Very Large Databases Santiago Chile, Sept 1994  R Agrawal H Mannila R Srikant H Toivonen and A 1 Verkamo Fast Discovery of Association Rules Advances in Knowledge Discovery and Data Mining Chapter 12 AAAVMIT Press 1995 5 C C Aggarwal P S Yu Mining Large Itemsets for Association Rules Data Engineering Bulletin 21 1 23-31 1 998 6 C C Aggarwal P S Yu Online Generation of Association Rules. ICDE 1998: 402-41 1 7 R J Bayardo Efficiently mining long patterns from databases SICMOD 1998: 85-93 8 R J Bayardo and R Agrawal Mining the Most Interesting Rules SIGKDD 1999 145-154 9 S Brin R Motwani J D Ullman and S Tsur Dynamic itemset counting and implication rules for market basket data SIGMOD Record ACM Special Interest Group on Management of Data 26\(2\1997 IO B Dunkel and N Soparkar Data Organization and access for efficient data mining ICDE 1999 l 11 V Ganti J E Gehrke and R Ramakrishnan DEMON Mining and Monitoring Evolving Data. ICDE 2000: 439-448  121 D Gunopulos H Mannila and S Saluja Discovering All Most Specific Sentences by Randomized Algorithms ICDT 1997: 215-229 I31 J Han J Pei and Y Yin Mining Frequent Pattems without Candidate Generation SIGMOD Conference 2000 1  12 I41 M Holsheimer M L Kersten H Mannila and H.Toivonen A Perspective on Databases and Data Mining I51 W Lee and S J Stolfo Data mining approaches for intrusion detection Proceedings of the 7th USENIX Securiry Symposium 1998 I61 D I Lin and Z M Kedem Pincer search A new algorithm for discovering the maximum frequent sets Proc of the 6th Int Conference on Extending Database Technology EDBT Valencia Spain 1998 17 J.-L Lin M.H Dunham Mining Association Rules: Anti Skew Algorithms ICDE 1998 486-493 IS B Mobasher N Jain E H Han and J Srivastava Web mining Pattem discovery from world wide web transactions Technical Report TR-96050 Department of Computer Science University of Minnesota, Minneapolis, 1996 19 J S Park M.-S Chen P S Yu An Effective Hash Based Algorithm for Mining Association Rules SIGMOD Conference 20 N Pasquier Y Bastide R Taouil and L Lakhal Discovering frequent closed itemsets for association rules ICDT 99 398-416, Jerusalem Israel January 1999 21 J Pei J Han and R Mao CLOSET An efficient algorithm for mining frequent closed itemsets Proc of ACM SIGMOD DMKD Workshop Dallas TX May 2000 22 R Rastogi and K Shim Mining Optimized Association Rules with Categorical and Numeric Attributes ICDE 1998 Orlando, Florida, February 1998 23 L Rigoutsos and A Floratos Combinatorial pattem discovery in biological sequences The Teiresias algorithm Bioinfomatics 14 1 1998 55-67 24 R Rymon Search through Systematic Set Enumeration Proc Of Third Int'l Conf On Principles of Knowledge Representation and Reasoning 539 550 I992 25 A Savasere E Omiecinski and S Navathe An efficient algorithm for mining association rules in large databases 21st VLDB Conference 1995 26 P Shenoy J R Haritsa S Sudarshan G Bhalotia M Bawa and D Shah: Turbo-charging Vertical Mining of Large Databases SIGMOD Conference 2000: 22-33 27 R Srikant R Agrawal Mining Generalized Association Rules VLDB 1995 407-419 28 H Toivonen Sampling Large Databases for Association Rules VLDB 1996 134-145 29 K Wang Y He J Han Mining Frequent Itemsets Using Support Constraints VLDB 2000 43-52 30 G I Webb OPUS An efficient admissible algorithm for unordered search Journal of Artificial Intelligence Research 31 L Yip K K Loo B Kao D Cheung and C.K Cheng Lgen A Lattice-Based Candidate Set Generation Algorithm for I/O Efficient Association Rule Mining PAKDD 99 Beijing 1999 32 M J Zaki Scalable Algorithms for Association Mining IEEE Transactions on Knowledge and Data Engineering Vol 12 No 3 pp 372-390 May/June 2000 33 M. J. Zaki and C Hsiao CHARM An efficient algorithm for closed association rule mining RPI Technical Report 99-10 1999 KDD 1995: 150-155 1995 175-186 3~45-83 1996 452 



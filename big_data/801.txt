Multiframe-Multichannel Blind Deconvolution for Polarimetric Imagery  Daniel A LeMaster National Air and Space Intelligence Center Wright Patterson AFB OH 45433 daniel.lemaster@wpafb.af.mil Abstract\227 An algorithm for the blind deconvolution of multichannel incoherent polarimetric imagery has been demonstrated recently in the literature Three new aspects of the algorithm are explored in this paper First the algorithm is compared to the case of single channel blind deconvolution Second a test is designed to con\002rm or refute the presence of an apparent polarization angle bias as suggested in the original work Finally the case for multiframe-multichannel blind deconvolution is made Each of these variations on the theme are addressed via simulation or laboratory data T 
ABLE OF C ONTENTS 1 I NTRODUCTION                                    1 2 P OLARIMETRIC B LIND D ECONVOLUTION        1 3 T EST T ARGETS                                    2 4 S INGLE C HANNEL C OMPARISON 
                 3 5 A NALYSIS OF THE A NGLE B IAS I SSUE            5 6 T HE M ULTIFRAME M ULTICHANNEL C ASE       5 7 C ONCLUSIONS                                     5 A CKNOWLEDGEMENTS 
                           5 R EFERENCES                                      5 B IOGRAPHY                                        7 1 I NTRODUCTION In a maximum lik elihood ML multichannel blind deconvolution algorithm using expectation maximization is derived for incoherent polarimetric imagery The purpose of this algorithm is to estimate the true linear polarization state of a target scene in the presence of photon noise and an un 
known atmospheric path A channel in this sense is de\002ned by a linear polarization analyzer placed in the optical path of the sensor The primary advantage of this technique over traditional polarization insensitive blind deconvolution is that despite scene content differences between channels each channel serves to constrain the estimate of the others In this way accurate estimation can be achieved without the need for additional observations The original work which is discussed in section 2 leaves open several questions that will be addressed here using laboratory and simulated data These test data are de\002ned in U.S Government work not protected by U.S copyright IEEEAC Paper 1063 Updated 19 December 2008 section 3 In section 4 the multichannel blind deconvolution algorithm is compared to traditional blind deconvolution 
of each channel independently The purpose of this test is to demonstrate that the information shared between channels substantially improves the performance of the estimator in practice These tests are executed using simulated data so that comparisons can be made against absolute truth and to allow for execution in a reasonable amount of time Additionally laboratory results in the original paper indicate the possibility of a bias in the estimated angles of polarization This apparent bias may be caused by unmodeled sources of error such as less than optimal analyzer performance or alignment or by a true estimator bias in a statistical sense In section 5 simulations are used to test for the later case Again simulations are preferred to lab measurements because the target and sensor are known with complete certainty and many realizations of the target and estimator can 
be achieved in a short period of time Finally in section 6 a multiframe multichannel polarimetric blind deconvolution estimator is demonstrated using laboratory data Despite the fact that this algorithm modi\002cation requires little additional analytical effort the improvement in the estimator is tangible especially in the presence of strong PSF diversity In the context of maximum likelihood estimation theory the additional data serve to 224sharpen\224 increase the gradient of the likelihood function around the ML estimate thus reducing the uncertainty in the estimator 2 P OLARIMETRIC B LIND D ECONVOLUTION The polarimetric blind deconvolution algorithm derived in speci\002cally addresses the case where all quantities of inter 
est are estimated from a single frame for each polarization sensitive channel In this derivation these data describe a log-likelihood function that is maximized across the parameter set of interest Since photon noise is independent between frames the joint log-likelihood function for multiple frames is simply the sum of the log-likelihoods of the individual frames Thus the derivation of a multiframe multichannel blind deconvolution algorithm is a trivial extension of the original Consequently a brief discussion of the algorithm derivation is presented in this section but not developed fully because it would be largely redundant with the original work 1 


In this section the multiframe estimator is presented alone the interested reader is encouraged to refer to the original work for a deeper understanding of the derivation Results showcasing the multiframe estimator are provided in section 6 The original single frame estimator which is used in sections 4 and 5 is simply a special case of the multiframe estimator What follows is a brief overview of the multichannel multiframe estimator The purpose of the algorithm is to jointly estimate three quantities 025 u  the unpolarized component of the scene 025 p  the polarized component of the scene and 013 the angle of polarization corresponding to each point in 025 p  Since the atmospheric path between the target scene and sensor is unknown the point spread function PSF for each channel is also estimated as a nuisance parameter Assume the channels of the polarization imager are evenly distributed in linear polarization space e.g 0 o  60 o and 000 60 o for a 3-channel system De\002ne the indices n to be the current iteration m to be the frame number and c to be the channel Coordinate x de\002nes the 2-D image space and y de\002nes a dummy coordinate to be summed over later in equation 3 For each channel and frame the measured data is represented by d mc and the estimated point spread function for the current iteration by h n mc  At each iteration d mc is modeled as a random variable with mean i n mc  y   X x o n c  x  h n mc  y 000 x  1 which is simply the convolution of the estimated true underlying image o n c  x   1 2 025 n u  x   025 n p  x  cos 2  013 n  x  000 022 c  2 and the current estimate of the point spread function Considering a point x 0 in the iterated image these estimates are updated via 025 n 1 k  x 0   2 M C X m X c X y  n 1 kmc  y x 0  3 where  n 1 pmc  y x   d mc  y  i n mc  y  025 n p  x  cos 2  013 n  x  000 022 c  h n mc  y 000 x   n 1 umc  y x   1 2 d mc  y  i n mc  y  025 n u  x  h n mc  y 000 x  4 such that k is u or p for the unpolarized and polarized components respectively M is the number of available frames and the n  1 superscript is added to signify that the estimate has been updated To estimate 013  an intermediate Stokes vector  is formed S n 1  A 000 1 t p 5 such that 013 n 1  x 0   1 2 tan 000 1 S n 1 2  x 0  S n 1 1  x 0  6 where t p represents the vector of summed fully polarized channel components t p  c  P m  n 1 pmc  Note that A is the matrix of channel weighting parameters a xc  de\002ned by the 002xed relationship between the Stokes vectors and each channel image o n c  x 0   a 0 c S n 0  x 0   a 1 c S n 1  x 0   a 2 c S n 2  x 0  7 The reader should note that 7 and 2 are completely equivalent The use of one representation over the other in the estimator is determined purely by mathematical convenience The PSF estimator does not change between the single and multiframe cases because the PSF is assumed to be independent between frames and channels Even if this assumption were not true i.e if the correlation time of the atmospherically induced phase is long compared to the frame rate the PSFs can still be estimated separately 3 T EST T ARGETS In the sections that follow results will be presented using both simulated and laboratory data In preparation the generation of these data are explained in this section Laboratory Data For each channel the test scene is imaged with a Photometrics Cascade 512B camera cooled to 000 30 o C with a roughly uniform 4 photons per count response at 660 nm Each channel image is formed using a single focusing lens f  250 mm a 3.175 mm stop and a variable polarization analyzer The stop is selected to ensure proper sampling on the FPA A separate visible red neutral density 002lter is used to attenuate stray light The stop lens and polarizing 002lter are shown in 002gure 1 The laboratory data requires additional preprocessing before it is presented to the deconvolution algorithm First a detector count bias which has nothing to do with the scene is subtracted off each image Second the image is cropped down to 150 002 150 pixels around the target to speed up processing The target itself consists of a partitioned off bar resolution target This target is back illuminated by red 660 nm diode light The top three bars exhibit weak polarization   10  due to Fresnel re\003ections on target glass surfaces the induced angle of polarization for these surfaces is unknown The bottom three bars are fully polarized in the horizontal plane i.e the 0 o plane of the image via a broadband polarizing 002lter Simulated Data Similar to the laboratory data the simulated target consists of two fully polarized bar targets that are each 20 pixels in length 3 pixels in width and separated by 3 pixels The bars appear against a dark 002eld of 128 002 128 pixels Each illuminated pixel contains 10 4 photons before it is blurred by the PSF attenuated by the channel polarizers and corrupted 2 


Figure 1  The lens and polarizer assembly used to collect laboratory data by Poisson noise The angle of polarization for each bar is pulled from a uniform distribution of all possible polarization angles The phase for each channel point spread function is generated from a random combination of the 002rst 9 Zernike polynomial coef\002cients Each Zernik e coef 002cient is nor mally distributed with zero mean and a variance of 1 wavelength i.e a phase of 2 031 radians The blurring and channel attenuation action of the simulated sensor results in a wide variety of image signal-to-noise ratios even without varying the illumination rate The sensor itself is in the previously described 0 o  60 o  and 000 60 o con\002guration Example simulated channels are shown in 002gure 2 4 S INGLE C HANNEL C OMPARISON The results in demonstrate the viability of the polarimetric blind deconvolution algorithm What remains then is to determine how the algorithm compares to the alternatives Though this estimator has no peer it is possible to estimate each channel image and point spread function individually i.e without knowledge of the other channels and then combine the result in the end to estimate 025 u  025 p  and 013 or any equivalent representation In this section simulated polarimetric imagery is used to compare the new joint estimator with Schulz's polarization insensitive blind deconvolution algorithm applied on a per channel basis As a historical note Schulz did not address the problem of estimating an image and a point spread function from a single frame of data in his original work However in the single channel case the image estimator in the Schulz algorithm is indistinguishable from the Richardson-Lucy algorithm which has been applied to the single channel blind problem see for instance The dif ference between these tw o approaches lies in how the PSFs are estimated Since there is no obvious advantage to choosing one PSF estimator over the other the Schulz PSF estimator which is also the PSF estimator in is used here for consistency Evaluation Criteria and Implementation Normalized Mean Squared Error NMSE is routinely used as a image deconvolution evaluation metric F or a true image intensity f  and an estimated image  f  the NMSE is de\002ned to be N M SE  P x h f  x  000  f  x  i 2 P x f 2  x  8 where x is the 2-dimensional coordinates in the image plane It is clear from 8 that a smaller NMSE represents a better estimate of f  Typically the NMSE is plotted against iteration number to convey both the accuracy and rate of convergence of the estimator In the present case it is desirable to convey the accuracy and rate of convergence for both the image itself and its polarimetric properties In section 2 image polarization content is conveyed through 025 u  025 p  and 013  Clearly NMSE applied to an 013 223image\224 would be uninterpretable Instead the Stokes parameters which all have units of intensity are fed into the NMSE equation for consistent representation The polarimetric deconvolution algorithm reduces to Schulz's algorithm in the case where the target is known to be fully unpolarized a priori  This is also true when only a single channel image and PSF are estimated In this case the channel images are estimated individually from equation 3 for 025 u with C  1 and M  1  The PSF estimator is unchanged After each algorithm iteration is complete the Stokes vectors are formed at each pixel via S  A 000 1 I where A is the matrix of channel weighting parameters from 7 and I is a vector containing the iterated estimates from each channel Similarly the Stokes parameters at each iteration can be calculated from 025 u  025 p  and 013 for each iteration of the multichannel estimator S 0  025 u  025 p S 1  025 p p 1+tan 2 013 001 sign[cos\(2 013  S 2  S 1 tan 2 013 9 where sign 001  is an operator that returns the sign of the argument Both the single and multichannel algorithms are given the same aperture size and initial PSF guess arbitrarily selected to be 1 wave of defocus Both algorithms are run for 100 iterations for 1500 separate realizations of the target and noise 3 


Figure 2  Examples of simulated data  002 2 zoom Channels left to right 0 o  60 o  and 000 60 o Figure 3  NMSE for S 0  Results The goal is to represent the aggregate results of many simulated targets therefore the following plots contain the median second quartile NMSE with error bars representing the 002rst and third quartiles of these data Quartiles are used in lieu of mean and standard deviation to avoid error bars with negative values at low NMSE The NMSE quartiles are shown for each Stokes parameter in 002gures 3 4 and 5 The single channel results are shown in red and the multichannel results in blue It is clear from these results that the multichannel estimator provides both a better median restoration of the target in all cases and a substantially smaller interquartile range on the restoration in the S 1 and S 2 cases Recall that parameters S 1 and S 2 carry all the polarization information about the scene Figures 4 and 5 for the single channel estimator show that after around 25 iterations the NMSE actually increases slightly for S 1 and S 2  in other words the single channel algorithm produces a median estimate that is getting farther from the truth with additional iterations Equations 3 and 6 help to explain the observed behavior In the multichannel case information is shared between channels via the estimates of 025 u  025 p  and 013  Mathematically this information transfer occurs during the sum over c in 3 The Figure 4  NMSE for S 1  Figure 5  NMSE for S 2  result of this transfer is a more constrained estimator These image constraints also indirectly translate into improved PSF estimates even though the PSFs themselves do not share information across channels In the single channel case without this shared information the number of possible combinations of PSFs and images that maximize the likelihood function increases resulting in more estimator error on average One obvious extrapolation of this argument is that the restoration would be improved further if additional channels or ad4 


ditional frames from the same channels were added to the estimator as is demonstrated later in section 6 5 A NALYSIS OF THE A NGLE B IAS I SSUE In this section simulation is used to determine whether or not the linear polarization angle error shown in the original work is a symptom of an actual bias in a statistical sense The simulated data are as described in section 3 In this case the multichannel deconvolution algorithm is run for 200 iteration over 1500 realizations of the data 200 iterations are used is this case to ensure near convergence of the results The restored target polarization angles  013  are taken to be the average over the true bar target area The bias is de\002ned as b  013 000  013 10 where b is de\002ned between 000 90 o and 90 o example 013 000  013  120 o  b  000 60 o  The simulation results show an average bias of 0  5 o essentially unbiased with a standard deviation of 16  3 o  Consequently even in the absence of calibration and unmodeled noise errors the laboratory results in the original work are typical at least in the sense that the reported angle errors are well within a standard deviation of the mean error in this simulated case A histogram of the angle bias results bin width 3  66 o  is shown in 002gure 6 As a 002nal note the reported standard deviation of the 013 estimates are due in part to the distribution of possible atmospheric phase realizations As such better lower standard deviation measurements would be based on prevailing conditions at the time of collection 6 T HE M ULTIFRAME M ULTICHANNEL C ASE In this section multiframe multichannel blind deconvolution is demonstrated using the 3-channel polarimetric imager and target described in section 3 Two frames of data each with a unique phase error are collected for each of the channels These raw data are shown in 002gure 7 The algorithm in section 2 is applied for 500 iterations The algorithm began to stagnate i.e the estimated quantities ceased to improve but got no worse at around 300 to 350 iterations The entire procedure was executed in roughly 8 minutes in Matlab on an AMD dual-core processor with 1G of RAM The before and after results are shown in 002gure 8 for the unpolarized component and in 002gure 9 for the fully polarized component The algorithm separates the polarized and unpolarized components of the image and resolves each of the six target bars Imperfections in the results include the obvious non-physical artifacts in each of the recovered images faint extraneous 223ghost bars\224 etc Additionally the estimated degree of polarization for the top bars is somewhat high 0.5 compared to a true value of 031 0.1 Finally the reconstructed mean angle of polarization for the bottom three bars is 000 2  6 o with a standard deviation of 4  6 o  Even if the true angle of polarization for the bottom three bars was exactly 0 o which is dif\002cult to verify this result is quite competitive with the results shown in section 4 for the single channel case 7 C ONCLUSIONS This paper further develops the multichannel polarimetric blind deconvolution algorithm originally presented by the author in In section 4 this a lgorithm is compared to blind deconvolution of the individual imaging polarimeter channels The results of these tests show that the performance of the multichannel estimator is indeed superior as is predicted by elementary estimation theory In section 5 a test for bias in polarization angle estimation is derived The results of this test show that in the case of an ideal polarimetric imager the estimator is unbiased though errors even large errors can occur with low probability The actual variance on the angle of polarization estimates will ultimately be determined by atmospheric conditions and signal level at the time of collection Finally the results of a multiframe multichannel version of the algorithm are presented The results show complete target reconstruction with few artifacts in the presence of substantial path corruption The course of future research that will likely be most bene\002cial entails expanding the model to include the effects of sensor noise in addition to photon noise Though sensor noise can be suppressed via hardware e.g through focal plane cooling etc this suppression comes with additional cost and complexity Algorithmic compensation if it is possible will likely require increased processing time In that case the tradeoffs between cost and processing time should be studied A CKNOWLEDGMENTS Sections 4 and 5 appeared in my dissertation while at the Air Force Institute of Technology As such I would like to thank my advisor S Cain and my committee members R Martin and M Oxley for their suggestions and encouragement The opinions and views expressed by the author are not necessarily those of the United States Air Force or the Department of Defense R EFERENCES  D LeMaster and S Cain 223Multichannel blind deconvolution of polarimetric imagery,\224 J Opt Soc Am A  vol 25 no 9 pp 2170\2262176 2008  E Collett Polarized Light Fundamentals and Applications  New York Marcel Dekker Inc 1992  M Roggemann a n d B W elsh Imaging Through Turbulence  Boca Raton CRC Press 1996  T  Schulz 223Multiframe blind decon v olution of astronomical images,\224 J Opt Soc Am A  vol 10 no 5 pp 1064\226 1073 1993  D e a Fish 223Blind decon v olution by means of the 5 


Figure 6  Results of the angle bias simulation Figure 7  Laboratory test data Starting with the upper left two frames from each of the 0 o  60 o  and 000 60 o channels Figure 8  025 u at iteration 1 left and iteration 500 right 6 


Figure 9  025 p at iteration 1 left and iteration 500 right Richardson-Lucy algorithm,\224 J Opt Soc Am A  vol 12 no 1 pp 58\22665 1995  D K undur and D Hatzi nak os 223Blind image decon v olution,\224 Signal Processing Magazine IEEE  vol 13 no 3 pp 43\22664 1996 B IOGRAPHY Daniel A LeMaster received a PhD in electrical engineering 2008 and an MS in applied physics 2004 from the Air Force Institute of Technology He also has a BSE in engineering physics from Wright State University 2003 He is currently employed at the National Air and Space Intelligence Center Wright Patterson AFB Ohio 7 


VIRTUALIZED COMPUTER INFRASTRUCTURES  Initially, IBM invented Virtualization to extend a single task system to multitasking systems. A modern hypervisor transfers the old ideas to state of the art hardware, considering the entity of an OS with all installed software as \223Guest\224 or task  Vendors of virtualization software developed many sophisticated features and tools around the core of virtualization in order to the range of additional value for virtualization users  Physical to Virtual - P2V Before any virtualization can commence, it is necessary to find ways to convert an existing physical machine into a VM. Conversion is a procedure of transferring a physical computer with all of its hardware the installed OS and applications into a \223Virtual Machine\224  The definition of a Virtual Machine according to Forrester Research is as follows  A virtual machine is stored as a set of files in a directory in the DATASTORE. A virtual disk inside each virtual machine is one or more files in the directory. As a result, you can operate on a virtual disk \(copy move, backup,\205\ just like a file. New virtual disks can be \223hot added\224 to a virtual machine without powering it off. In this case a virtual disk file \(.vmdk\ is created in a V irtual M achine F ile S ystem \(VMFS to provide new storage for the hot added virtual disk or an existing virtual disk file associated with a virtual machine  Vendors in the field of virtualization software are offering software tools for P2V purposes. Physical machines can be virtualized on the fly, i.e. while they are running and performing their usual work. Other methods are using boot-CDs, hard disks or hard disk images to convert a computer. Furthermore back-up file formats of most important back-up solution providers are supported as base for a P2V conversion   Virtual Infrastructure The real benefits of virtualization become possible with the implementation of a virtual infrastructure layer Virtualization software vendors coined the term \223cloud computing\224 for this issue. One of these vendors even claims to offer the first \223cloud computing operating system\224   Picture 4 Set of host computers administrated by a Virtualization Layer with numerous "Guests\224   The infrastructure layer abstracts hardware to a very high degree. The layer considers no individual elements of hardware but it pools all available rescores instead. The virtual infrastructure would provide the aggregate of RAM of MHz to potential guests. All features regarding redundancy and high  availability 


are configured and maintained within the \223Administrat ion layer\224. The \223administration layer\224 itself can even just be a Guest in the virtual environment  Along with the implementation of the administration layer the storage philosophy needs to be adapted to benefit from virtualization. Virtual machine files should be no longer physically located on a hard disk of an individual server, but on a common S torage A rea N etwork \(SAN\ instead. Now the critical point of failure has changed in virtualized environments from the hard-disk of an individual server to the SAN  Flexibility Virtual machines handled by system management software must not continuously reside on an initially assigned computer. In fact a \223Guest\224 can move around while still provid ing all service from one physical machine to another. This feature enables hardware maintenance without risks and interruption of computer operation in a very simple way  A growing demand of resources by additional applications or increased machine load can be covered by adding new machines and distributing the Guests differently in the extended cluster This process can even be automated, meaning that load balancing between computer resources can be realized without manual inte rvention \(if the hardware is already in place  Rapid provisioning and backup As said before, a virtual machine is in essence just a file on file system. This file represents a computer with everything in it, to run on a virtualization host This hardware independence enables administrators to create clones of working images for roll out purposes In case of tests of hot fixes or updates, snapshots of the running machine can be taken to which one can revert in case a test fails Backups are simplified a lot, because third party tools are almost obsolete  Quick recovery After a failure \226no matter hard- or software caused a virtual machine can reboot automatically elsewhere in the virtual environment in order to keep the service. As this type of quick recovery causes interruptions to computer operation it is not suitable for process automation purposes  Failover Real failover has only been available in commercial products since approximately two years. In principle it consists of a foreground Guest VM with a \223Shadow-VM\224 of this Guest running in the background on different hardware of the resource pool. The shadow VM is an identical bit-copy of the foreground machine. It would become activated in case the foreground machine suffers a hardware breakdown  Both features, Failover and Quick Recovery make use of the mobility of Virtual Ma chines in administrated environments The applied principle to achieve failover is highly comparable with system backup software which is capable of backing up system partitions while the system is running  The working principle is a method which takes a snap-shot at a point in time and monitors the deviation to the snap shot while the initial snap shot is taken. The procedure is applied as long as the delta file size between snapshot and data to be copied\ero. At this moment the Copy-VM takes over The dead time for taking over by the Shadow-VM is just some \(we only found one\ packets - thus just some milliseconds  But beware  Breakdowns caused by \223buggy\224 software are not covered by this technology, because the shadow-VM would crash as well  


Impact on automation layout in a cement plant Next picture shows a generic control system layout as used at HeidelbergCement with logical segregation of production stages and an \223automation backbone\224 which connects subordinate control systems  Each control system consists of a redundant set of servers for failsafe reasons   Picture 5 Standard PCS layout  Process control systems are typically installations which are subject to evolution rather than to revolution Most cement plants would never do a \223one-shot replacement\224 of an installed system \(or version\ by another but proceed in steps  Logically, the approach towards virtualization is logically very similar to PCS upgrades The reason for the reference plant which introduced Virtualization Technology in 2008 for online control purposes were hardware failures and obsolete hardware for Windows-NT-based-CEMAT-V4-control systems The first machine to be virtualized was not \223mission critical\224 but represented in principle the entire functionality of CEMAT V4. It was an engineering station which was set up as a combined \223server-clientengineering station\224  Almost at the same time, this plant introduced a Process Data Acquisition System \(Management Information System\. According to the vendor\222s specification, the whole system should be installed on 5 different computers \(Com-Server, OPC Server, Database Server,\205\ough it was obvious that it could be done on fewer machines the plant decided to follow the vendor\222s specification because of warranty issues. However, setting up 5 machines for a relatively unimportant job was considered to be excessive and as the virtualization platform was availabl e we utilized it for the PDAS installation  Due to the positive experience after step one, it was decided, to migrate also one PCS Server of the redundant server-set into a VM and install it to a host. The process control system software runs untouched on both machines and realizes failover between a physical and a virtual machine  The decisive steps at our pilot plant were also done at a relatively early point in time \(immediately after the tests with the engineering station were completed\ September 2008  The infrastructure software layer was installed \226although we could not use it extensively- almost at the very beginning, i.e. with the first host, in order to give our staff the opportunity to become familiarized with this new \(to automation people\y 


  Picture 6 PCS layout with virtual infrastructure and SAN  The second very important step was the installation and commissioning of a Storage Area Network SAN\, because only a network storage enables to make use of virtualization infrastructure features such as failover. This is due to the fact that virtual machine disk files may not exist on a certain host, as in case of failure it would not be accessible and available any longer to be restarted on a different physical host  SANs are either based on Fibre Channel or iSCSI Technology. The idea of both technologies is to extend the \(usually\nal data lines between hard disk controllers and hard-disks to external devices Fibre Channel has been a proven technology for this type application for years. It has a slightly better performance, but is more expensive than iSCSI iSCSI stands for Internet Small Computer System Interface It  means encapsulation  of the SCSI protocol within TCP/IP packages. Today iSCSI delivers sufficient performance to build up SANs for process automation purposes at a cement works  In such an arrangement, from a failure point of view, the SAN is the most critical peace of hardware in virtualized computer architecture  Although SANs are built up internally fail safe \(redundant power supply, NICs, hard disk controllers,\205 and data sheets give impressive figures for availability, any concept for process control purposes should allow for setting up auto-synchronizing SANs at different spots  User interface VMs running on a host are comparable to applications running on a Terminal Server. In other words, VMs obviously need input and output devices to be handled. Fat clients \(PC\222s\o good choice if it is intended to simplify the maintenance of the process control system hardware. Moreover, they are costly and sometimes prone to error Another step forward -with limited risk only- was to replace some operator stations of a segment by Thin Clients without hard disk The connection between thin client and VM is either done by vendor specific client software, RDP or VNC  Obstacles Minor issues may occur while transferring physical control systems into virtual ones Most of the problems the reference plant encountered had to do with the hardware interfaces such as serial and parallel ports and multi-media features  


Unresolved points \(minor\are to date realizing failover with legacy interfaces and sound output with Windows NT guests   CONCLUSION  Virtualization is no new but a revitalized technol ogy. First virtualization solutions \(purely based on software\ell as computer emulation deliver poor results in terms of performance  Hardware supported virtualization and pure software virtualization are totally different approaches  Virtualization today is most powerful when it combines the strengths of the different technologies. CPU demanding applications are wasting less performance than memory-intense application. \(TLB miss costs  VMware ESX is a good example of this. ESX uses Para-virtualized drivers for the most critical I/O components \(but not for the CPU\, emulation for the le ss important I/O and Binary Translation in order to avoid the high "trap and emulate" performance penalty. In this way, virtualized applications perform quite well, in some cases almost as if th ere were no extra VMM layer involved  The user benefit of virtualization is manifold. Virtualization 225  decouples software from hardware \(provides availability for \223legacy platforms\224, enables software in a cloud 225  utilizes installed hardware more efficient 225  safes space, energy, and invest cost 225  eases system administration extensively  225  but requires additional know-how of system administrators  At this point in time we can say that virtualization has met all of our expectations and offered \226in particular with respect to system administration- even more. The number of plants that started using Virtualization is growing  The process automation staff is still on a learning curve with virtualization in order to take maximum benefit of this technology  Unexploited potential is likely to be found in the field of setting up systems, handling of back-ups and disaster recovery procedures     REFERENCES  200  K. Lawton, Running muliple operating systems concurrently on an IA32 PC using virtualization techniques,http://plex86.org/research/paper.txt 200 www.codinghorror.com/blog/archives/001029.html 200 it.anandtech.com 200 en.wikipedia.org/wiki/Platform_virtualization 200  Virtualization for dummies SUN and AMD special edition 200 www.intel.com/technology/virtualizatio n/technology.htm?iid=tech_vt+tech 200  2008 Automation Summit - ID#: 1474 - Dow Chemical R&D\222s Global Rollout of PCS7\256 Using VMWare\256, Chicago    200 en.wikipedia.org/wiki/Ring_\(computer_security 


  13 edge of the aperture.  The distance of the reflected beam from the center of the aperture is then used to calculate I  which varies from about -0.8\260 to +0.8\260 in the experiment Figures 24-28 show the change r I    found by taking the difference of the center of each spectral image and subtracting from its location when I and compared the modeled values over the same range of I Figure 23 illustrates that there is some amount of random error in these measurements, but overa ll the data is grouped around r 0 pixel difference between the measured and modeled values.  The 404.7nm source shows the most variation  Figure 23 \226 The difference in pixel displacement at the detector array between measurements from modeled and collected data as a function of I     Figure 24 \226 Measured and modeled r   p  for the 404.7nm spectral line   Figure 25 \226 Measured and modeled r   p  for the 435.8nm spectral line   Figure 26 \226 Measured and modeled r   p or the 546nm spectral line   Figure 27 \226 Measured and modeled r   p  for the 577.5nm spectral line   Figure 28 \226 Measured and modeled r   p  for the 635nm spectral line   Given that the model is able to predict the displacement of energy as a result of an error in p   due to incident angle data was collected similar to that with the tilted camera to examine the effect system atic error due to unknown I  caused by a misaligned prism Here, the prism was angled in the mount in two directions to create the angles x and y  between the prism face and the normal to the optical axis as shown in Fig. 10.  The mo unt itself was tilted in two directions to create the misalignment angles x and y as shown in Fig. 12.  The magnitudes of these angles were measured by a laser as described above.  The aperture was placed such that each mm of separation at the aperture equates to 0.25\260 of angle at th e prism.  Misalignment in the instrument was used that gave values x  0.5\260 y  0.5\260 x 0.75\260 and y  0.5\260 with the instrument design again limiting the amount of error that could be imparted  The r   p  expression from Equation 17 will be compared to see how the displacement of each of the 5 wavelengths as a function of rotation angle varies given the different I  due to misalignment as the prism rotates.  The estimation in 3 2 1 0 1 2 3 4 5 6 1.0 0.5 0.0 0.5 1.0 r from model \(pixels I degrees 404.7nm 435.8nm 546nm 578nm 635nm 400 390 380 370 360 350 0 90 180 270 360 r   p pixels p degrees 404 nm, measured 404 nm, modeled 258 255 252 249 246 243 240 237 234 231 0 90 180 270 360 r   p pixels p degrees 435 nm, measured 435 nm, modeled 0 1 2 3 4 5 6 7 8 9 0 90 180 270 360 r   p pixels p degrees 546 nm, measured 546 nm, modeled 28 30 32 34 36 38 40 0 90 180 270 360 r   p pixels p degrees 578 nm, measured 578 nm, modeled 76 78 80 82 84 86 88 90 0 90 180 270 360 r   p pixels p degrees 635 nm, measured 635 nm, modeled 


  14 error for angles and is +/-0.2\260 and is incorporated into the model prediction.  Results are shown in Figures 24-29  Here, the measured data match the overall trends of the model very well, with some slight offset of about 2 pixels in each of the r   p  comparisons.  This would lead to the assumption that the estimate of x is not accurate, but is likely not the case since the mean of the model is too high in the 404nm data, and too low in the 435nm data.  This indicates that there are other errors being observed, as again it is nearly impossible to lim it the measurement to error in the intended so urce.  Also, note the decrease in impact the rotation error has as wavelength increases.  This is due to the lowered bearing P has on p as shown in the previous section.  However, the error magnitudes are a ratio of the distance from the undeviated wavelength, and in this data set are large due the large fractional error of and   4  R ESULTS  The systematic errors in a CTI instrument affect the spectral and spatial resolutions and locations in the reconstructed hyperspectral data cube in similar ways that these errors would affect the results of a traditional prism spectrograph This would be expected since the 3-D data is constructed from 2-D projection data.  The CTI becomes much more sensitive to error dependent on how the error kernel in the reconstruction behaves as a function of the prism rotation angle p and degree of freedom not in a fixed element dispersion system.  Four type s of systematic error were examined in this study; those due to tilt in the detector array  between the det ector array and the lens L 3  d   error in knowledge of the angular prism dispersion p    and error in estimation of the prism rotation angle p   s that can be inse rted into the error kernel functions were developed for each to model the effects For reasonably large array tilts of up to 3\260 and error in distance of up to 2mm, only a slightly noticeable shift of less than a pixel in spatial location was observed, mostly dependent on the tilt angle.  A more substantial spectral peak shift resulted which was due to error in distance, with a 7nm shift seen at the longer wavelengths at d  2mm.  The spatial and spectral resolu tions remained virtually unchanged, indicating that an accurate construction occurs in a shifted location The dispersion angle can be in error due to faulty estimation of prism performance.  This w ill cause an apparent shift of spectral peaks as shown in Figu re 8.  A more complicated  is the result of its dependence on the incident angle to the prism face I This is caused by mi salignment of the prism in the mount, or misalignment of the mount itself.  Mount misalignment is similar to cons tant error in estimation of p   with a shift in spectral p eaks observed.  For the AFIT CTI, this shift is only a few nm per 1\260 of misalignment Mount misalignment produces a more complex error kernel as shift and loss of resolutio n occur for relatively smaller angular errors.  More impor tantly, the spectral peaks become split into two peaks for errors of total misalignment in both the x and y directions of 1\260.  The spectral resolution may be recovered if the entire spatial area of the image is integrated.  However, simila r to splitting of peaks, the spatial distribution is a donut shape in the bin of emission  Finally, the error in projection angle p was examined though in a more obligatory fa shion since it is a relative error \(i.e. not a systematic erro r necessarily, but an error in choice of the reference coordinate system\.  There is no shifting of spectral peaks or lo ss of spectral resolution however there is a circular displacement of the spatial image again causing donut shap es for large enough   Most importantly, the error mode l was verified by collecting measured data from the AFIT CTI instrument with systematic error intentionally created in the instrument to assess the effect.  While in some cases it was apparent that sources of error other than those being investigated were influencing the results, the data did match the model for the situations where th e studied error effect was dominant usually at higher angular dispersi on, or spectral resolution Further investigation of some error may be necessary, as our CTI system design could only support a certain degree of component alteration to assess er ror.  In some cases, due to sampling of the detector array w ith respect to the size of the PSF of the system, slight changes in performance caused by error could not be resolved  4  C ONCLUSIONS  The purpose of this study wa s to assess the effect of systematic error on the reconstr ucted data sets collected by a rotating prism CTI instrument While the results are specific to the AFIT CTI desi gn, it is intended that the relative magnitude of each error and result on the reconstructed data will apply to any set of data given the general nature of the equations describing the reconstruction and error kernel that is con volved with each spectral bin  The consequence of each systematic error was quantified by the shift in spectral and/or spatial location, and degradation of spectral and/or spatial reso lution.  Table 2 summarizes the contribution of each analy zed error to these quantities   Table 2 \226The effect of systematic error.  An \223x\224 indicates an effect exists, a \223-\223 indicates no effect is observed   


  15 The model of the system allows for a quick assessment of the error, and provides a more illustrative demonstration of the prism misalignment error an d how each spectral peak is affected differently.  Figure 29 shows how the spectral peak changes as the prism mount alignment is increased in both the x and y directions for the 400nm and the 450nm spectral peaks   Figure 29 \226 The 400nm and 450nm peak shapes with varying misalignment of the prism mount   Similarly, Figure 30 represents the situation where the prism mount misalignment is constant at x  y 0.5\260 but the misalignment of the prism in the mount is changing so that a constant shape is produced, but shifted as x increases   Figure 30\226 Shifting of the 400nm spectral peak as x  increases.  The shape remains the same as the misalignment of the mount is constant   Though presented independently, the obvious contribution of the errors of the system are cumulative and must be considered in total.  Given th e great number of variations possible, this was not attempted here, but can be done based on the mathematics  This study is intended to explore the effect of systematic error for the purpose of examining sensitivity of performance when designing th e instrument.  In practice the reconstruction of collected data is done using after calibration of the instrument to directly measure r  p   without regard for the sources of error.  While this measurement can be a diagnostic of the instrument, the fact that it is well known is enough to perform acceptable reconstructions.  If instrume nt components are accessible the diagnostics be used to correct for second order error created in the instrument.  For example, errors in distance to the focal plane or tilt also result in a defocus error which cannot be easily recovered in the reconstruction algorithm R EFERENCES  1  C G r o s s, G  P. Perram an d R. F. Tu ttle, \223Mo d el i n g  infrared spectral intensity data from bomb detonations\224 Proceedings of SPIE  5881 p. 100 \(2005  2 o oney, \223A ngu l arly Mu ltip lex ed  Sp ectral Im ag er\224 Proceedings of SPIE  2480 pp. 65\22677, 1995   a ster, \223De sign and M o del Verification of an Infrared Chromotomographic Imaging System.\224 AFIT Masters Thesis, 2004  4 bb ins D  J. Go dfrey 223D ig ital x-ray tomosynthesis: current state of the art and clinical potential\224 Phys Med. Biol 48, pp. R65-R106, 2003   R.A Br oo ks an d G Di Chi r o 223Pri nci p l e s o f Com p u t er Assisted Tomography \(CAT\n Radiographic and Radioisotopic Imaging\224 Phys. Med. Biol  21 No. 5, pp 689-732, 1976  6 R.L. Bostick, G.P. Perr am, \223Hyperspectral Imaging Using Chromotomography: A Fieldable Visible Instrument for Transient Events\224 International Journal of High Speed Electronics and Systems  18 no. 3, pp. 519\226529, 2008  7 Bo stick   G  P.Perram an d R.F.Tu tt le 223Characterization of spatial and spectral resolution of a rotating prism chromotomographic hyperspectral imager\224 Proceedings of the SPIE  Next-Generation Spectroscopic Technologies II Conference, April 2009  B IOGRAPHY  Randy Bostick is a part-time PhD student at AFIT developing a metrology for a rotating prism chromotomographic imaging system.  Mr. Bostick is employed full time at the National Air and Space Intelligence Center at Wright-Patterson Air Force Base as an intelligence analyst for national remote sensing assets  


http://www.w3.org/TR/wsci 36] The World Wide Web Consortium \(W3C vice Modeling Language \(WSML http://www.w3.org/Submission/WSML 37] The World Wide Web Consortium \(W3C vice Modeling Ontology \(WSMO http://www.w3.org/Submission/WSMO 38] J. Yang and M.P. Papazoglou, ?Web Component: A Substrate for Web Service Reuse and Composition?, Proc 14th Conf. Advanced Information Systems Eng. \(CAiSE 02 LNCS 2348, pp. 21?36, Springer-Verlag, 2002 39] Y.P. Yang, Q.P. Tan, and Y. Xiao, ?Verifying Web Services Composition Based on Hierarchical Colored Petri Nets?, IHIS?05, pp. 47-53, Bremen, Germany, 2005 40] Y.P. Yang, Q.P. Tan, Y. Xiao, J.S. Yu, and F. Liu, ?Exploiting Hierarchical CP-Nets to Increase the Reliability of Web Services Workflow?, Symposium on Applications and the Internet \(SAINT?06 41] X.C. Yi and K.J. Kochut, ?Process Composition of Web Services with Complex Conversation Protocols: a Colored Petri Nets Based Approach?, Conference on Design, Analysis, and Simulation of Distributed Systems, pp.141-148, 2004 42] D. Zhovtobryukh, ?A Petri Net-based Approach for Automated Goal-Driven Web Service Composition?, SIMULATION, Vol. 83, Issue 1, pp.33-63, January 2007 43] C. Zhou, L.T. Chia, and B.S. Lee, "Web Services Discovery with DAML-QoS Ontology", International Journal of Web Services Research, vol. 2: no. 2: pp. 43-66, 2005   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


  17 Mission Phase Relevant Archit ecture Informat ion Purpose Funct ion Mat urit y Pr oduct s DODAF M odel Re f e r e nce N ot e s Preliminary System Design Integrated Risk List Cross  functional list of risks compiled across integrated product team PDR Delivery Consolidated Ri sk Li st FFP1A Operational Environment M atrix documenting how test requirements that have been levied are satisfied with test \(at both the component and system levels Identification of the method that w ill be used to verify the requirement Identification of any potential non-conformances  Initial Delivery Environmental Te st  Verification Matrix FFP7 This will show the capability of the SV to withstand various environments \(i.e. launch vehicles System Interface Control Documentation This will be a suite of documents, the mission plan s hould identify critical system boundaries that reuqire a formal interface control document M inimum Criteria:  SV - Ground and Payload to SV ICD initial drafts must be compl e t e Other pertinent ICDs:  LV - Spacecraft, Component interface ICD Initial Delivery Interface Control Documentation SV 1  SV 6 Schedule Program Driving Schedule Requirements Key schedule driven technical decisions Giver receiver relationships that span different program elements Li v i n g Document Intgrated Milestone Schedule PV2 System Sub-system Design Specifications Partial Preliminary understanding of system subsystem design Allocation of required system functions to configuration items Demonstration of how system requirements are satisfied by design Initial Delivery PDR De si gn  Presentation SV 5 Open System Trades Desription organized by susbsystem of open design trades and decsions that need to be completed Each trade should have an owner and assocaited due dates that are aligned with program constriants Li v i n g Document Trade  Decision tracking matrix FFP5 Technical Performance Measures Demonstrate design peformance to critical program requirements outlined within the requirements document Initial Delivery Technical performance budget SV 7 Values in the budget should be compared to industry standards for a given maturity in the devleopment De t ai l e d De si gn System  Design Specifications Detailed description of "to be"  system subsystem design Allocation of required system functions to configuration items Demonstration of how system requirements are satisfied by design Final Delivery CDR De si gn  Presentation SV 4  SV 5 Note: Reference Lesson 11 - Need to look at some views and diagrams that would be useful for every subsystem Integrated Risk List Cross  functional list of risks compiled across integrated product team CDR Delivery Consolidated Ri sk Li st FFP1A Operational Environment Matrix documenting how test requirements that have been levied are satisfied with test \(at both the component and system levels Identification of the method that w ill be used to verify the requirement Identification of any potential non-conformances  Final Delivery Environmental Te st  Verification Matrix FFP7 Note: previous delivery s houl d have defined how requirements would be satisfied for long lead components.  This delivery would address all remaiing compents and system levels System Interface Control Documentation This will be a suite of documents, the mission plan s hould identify critical system boundaries that reuqire a formal interface control document M inimum Criteria:  SV - Ground and Payload to SV ICD initial drafts must be compl e t e Other pertinent ICDs:  LV - Spacecraft, Component Interface ICD Final Delivery Interface Control Documentation SV 1  SV 6 Schedule Program Driving Schedule Requirements Key schedule driven technical decisions Giver receiver relationships that span different program elements CDR De l i v e r y Intgrated Milestone Schedule PV2 Integration Prodcution Plan List of all components under procurement and their expected and need dates List should include all piece parts, miscellaneous mat ls, connectors and required ground support equipment Initial Delivery Sy st e m Pa r t s  Li st  FFP6 Technical Performance Measures Demonstrate design peformance to critical program requirements outlined within the requirements document Final Delivery Technical performance budget SV 7 Values in the budget should be compared to industry standards for a given maturity in the devleopment Open System Trades Desription organized by susbsystem of open design trades and decsions that need to be completed Each trade should have an owner and assocaited due dates that are aligned with program constriants Li v i n g Document Trade  Decision tracking matrix FFP5   


 LNCRITIC 0.884 \(.005 0.362 352 0.593 053  CRPRO -0.007 \(.306 0.012 183 0.002 798  CRCON 0.010 \(.291 0.013 230 0.019 095  Model fit F p value 24.900 lt;.0001 11.110 lt;.0001 5.940 lt;.0001 Adjusted R2 0.559 0.553 0.320 p &lt; .10 p &lt; .05 Notes: p values are in parentheses  4.5. South Korean versus American market  In terms of the effect of WOM, we find no discernable difference in the motion picture markets of South Korea and the United States. Volume of WOM is positively correlated to the following week?s revenue in both markets, and valence of WOM is not significant The effect of critical reviews, however, did not concur While the literature on the American market data reports that positive critical reviews are positively related to box office revenue[21, 34], the results on the Korean market was different. There could be several reasons for this. First, South Korea and the United States have different sources for critical reviews, and the sources may have different impacts on moviegoers Second, the characteristics of critics might be different i.e., Korean critics may prefer movies that are considered less commercial or artistic than American critics  5. Conclusion  WOM and critical reviews both are important attributes that influence box office revenue in the motion picture industry. In this study, six hypotheses related to this issue were set up and tested. Data was collected on the motion picture industry of South Korea by using several websites that provide content and statistical data about movies. Finally, data on 118 movies was collected and the movies were categorized into two groups based on the distributors of the movies If the distributor of a movie was one of the major distributors in South Korea, that movie was categorized into mainstream movies, and if not then the movie was categorized into non-mainstream movies. As expected mainstream movies had much higher box office revenue and volume of WOM than non-mainstream Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 movies. In the case of the volume of critical reviews 


movies. In the case of the volume of critical reviews however, there was no big difference between mainstream and non-mainstream movies. WOM and critical reviews were usually positive H1 and H2 tested the relationship between WOM and weekly box office revenue, and the results supported the hypotheses. The volume of WOM was positively related to weekly box office revenue, while the valence of WOM had no significant effect. H3 H4a, and H4b tested the impact of critical reviews, and the results also supported the hypotheses except H4b The volume and valence of critical reviews had no consistent significances to weekly box office revenue H3 H4b. Table 7 showed that the number of critical reviews was statistically significant to aggregate box office revenue \(H4a for the attitude of critical reviews \(H4b the result more detail, an additional test was performed using only those factors related to critical reviews as independent variables. The result of the additional test supported H4, but the signs were reversed, i.e. positive critical reviews had minus signs, and negative critical reviews had plus signs. This reversed signs imply that the preference of critical reviewers is very similar to that of normal moviegoers. H5s and H6s tested the different effects of WOM and critical reviews on mainstream and non-mainstream movies. The result failed to determine that WOM give different impact on mainstream and non-mainstream movies, so H5a and H5b were rejected. H6, however, was supported, i.e the effects of critical reviews were different for mainstream and non-mainstream movies. There were no significant relationships between critical reviews and aggregate box office revenue in mainstream movies. For non-mainstream movies, however, the volume of critical reviews and the percentage of negative critical reviews were significant. Nonmainstream movies have fewer sources from which consumers can get information, and this might explain the results The above findings lead to several managerial implications. First, producers and distributors of movies could forecast weekly box office revenue by looking at previous weeks? volume of WOM. It does not matter what attitude people have when they spread WOM, the important factor is its volume. Therefore producers and distributors need to develop an appropriate strategy to manage WOM for their movies For example, the terms related to WOM marketing such as buzz and viral marketing are easily found Second, for the distributors who usually distribute less commercial and more artistic movies, and consequently have a smaller market compared to the major distributors, critical reviews can impact their movies box office revenues in a significant way. There are usually fewer sources for information for nonmainstream movies than mainstream movies, and so small efforts could leverage the outcomes. Finally, for those who are dealing with mainstream movies, the finding that the valence of WOM and critical reviews do not have significant relationship with box office revenue can have certain implications. Particularly, the attitude of critical reviews showed reversed effects Therefore, they may need to concentrate on other features rather than attitude of moviegoers or critical reviews, such as encouraging moviegoers to spread WOM This study contributes to the understanding of the motion picture industry, especially the relationship between box office revenue and WOM including critical reviews. There are existing studies that already 


critical reviews. There are existing studies that already dealt with similar issues, but this study has some differentiated features compare to prior studies. First the data used in this study was collected from South Korea, while most of the relevant studies usually focus on the North American market. This helps to provide the opportunity to understand the international market especially the Asian market, even though South Korea is a small part of it in terms of the motion picture industry. Second, movies were categorized to two groups, i.e. mainstream and non-mainstream and this study attempted to determine how WOM impacts these categories differently by testing several hypotheses In this study, there are also several limitations that could be dealt with in future research. First, using box office revenue as a dependent variable is more meaningful for distributers rather than producers. Due to there is close correlation between box office revenue and number of screens, one of producers? main concerns is how many screens their movies can be played on. Moreover, DVD sales are also important measurement for success of movies these days, and so it also could be a dependent variable. Therefore, it could be possible to give more fruitful managerial implications to various players in the motion picture industry by taking some other dependent variables Second, in this study, movies were categorized simply as mainstream and non-mainstream movies, but there could be further studies with diverse techniques of movie categorizations. For example, it would be possible to study the varying influence of WOM or critical reviews on different genres or movie budgets Third, an interesting finding of this study is that positive critical reviews could have negative relationship with box office revenue while negative critical reviews could have positive relationship. This study tried to provide a reasonable discussion on the issue, but more studies could be elaborate on it  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 References  1] Dellarocas, C., The Digitization of Word of Mouth Promise and Challenges of Online Feedback Mechanisms Management Science, 2003. 49\(10 2] Bone, P.F., Word-of-mouth effects on short-term and long-term product judgments. Journal of Business Research 1995. 32\(3 3] Swanson, S.R. and S.W. Kelley, Service recovery attributions and word-of-mouth intentions. European Journal of Marketing, 2001. 35\(1 4] Hennig-Thurau, F., et al., Electronic word-of-mouth via consumer-opinion platforms: What motivates consumers to articulate themselves on the internet? Journal of Interactive Marketing, 2004. 18\(1 5] Fong, J. and S. Burton, Electronic Word-of-Mouth: A Comparison of Stated and Revealed Behavior on Electronic Discussion Boards. Journal of Interactive Advertising, 2006 6\(2 6] Gruen, T.W., T. Osmonbekov, and A.J. Czaplewski eWOM: The impact of customer-to-customer online knowhow exchange on customer value and loyalty. Journal of Business Research, 2006. 59\(4 7] Garbarino, E. and M. Strahilevitz, Gender differences in the perceived risk of buying online and the effects of receiving a site recommendation. Journal of Business Research, 2004. 57\(7 8] Ward, J.C. and A.L. Ostrom, The Internet as information minefield: An analysis of the source and content of brand information yielded by net searches. Journal of Business Research, 2003. 56\(11 


9] Goldsmith, R.E. and D. Horowitz, Measuring Motivations for Online Opinion Seeking. Journal of Interactive Advertising, 2006. 6\(2 10] Eliashberg, J., A. Elberse, and M. Leenders, The motion picture industry: critical issues in practice, current research amp; new research directions. HBS Working Paper, 2005 11] S&amp;P, Industry surveys: Movies and home entertainment 2004 12] KNSO, Revenue of Motion Picture Industry 2004 Ministry of Culture, Sports, and Tourism, 2004 13] Duan, W., B. Gu, and A.B. Whinston, Do Online Reviews Matter? - An Empirical Investigation of Panel Data 2005, UT Austin 14] Zhang, X., C. Dellarocas, and N.F. Awad, Estimating word-of-mouth for movies: The impact of online movie reviews on box office performance, in Workshop on Information Systems and Economics \(WISE Park, MD 15] Mahajan, V., E. Muller, and R.A. Kerin, Introduction Strategy For New Products With Positive And Negative Word-Of-Mouth. Management Science, 1984. 30\(12 1389-1404 16] Moul, C.C., Measuring Word of Mouth's Impact on Theatrical Movie Admissions. Journal of Economics &amp Management Strategy, 2007. 16\(4 17] Liu, Y., Word of Mouth for Movies: Its Dynamics and Impact on Box Office Revenue. Journal of Marketing, 2006 70\(3 18] Austin, B.A., Immediate Seating: A Look at Movie Audiences. 1989, Wadsworth Publishing Company 19] Bayus, B.L., Word of Mouth: The Indirect Effects of Marketing Efforts. Journal of Advertising Research, 1985 25\(3 20] Faber, R.J., Effect of Media Advertising and Other Sources on Movie Selection. Journalism Quarterly, 1984 61\(2 21] Eliashberg, J. and S.M. Shugan, Film critics: Influencers or predictors? Journal of Marketing, 1997. 61\(2 22] Reinstein, D.A. and C.M. Snyder, The Influence Of Expert Reviews On Consumer Demand For Experience Goods: A Case Study Of Movie Critics. Journal of Industrial Economics, 2005. 53\(1 23] Gemser, G., M. Van Oostrum, and M. Leenders, The impact of film reviews on the box office performance of art house versus mainstream motion pictures. Journal of Cultural Economics, 2007. 31\(1 24] Wijnberg, N.M. and G. Gemser, Adding Value to Innovation: Impressionism and the Transformation of the Selection System in Visual Arts. Organization Science, 2000 11\(3 25] De Vany, A. and W.D. Walls, Bose-Einstein Dynamics and Adaptive Contracting in the Motion Picture Industry Economic Journal, 1996. 106\(439 26] Bagella, M. and L. Becchetti, The Determinants of Motion Picture Box Office Performance: Evidence from Movies Produced in Italy. Journal of Cultural Economics 1999. 23\(4 27] Basuroy, S., K.K. Desai, and D. Talukdar, An Empirical Investigation of Signaling in the Motion Picture Industry Journal of Marketing Research \(JMR 2 295 28] Neelamegham, R. and D. Jain, Consumer Choice Process for Experience Goods: An Econometric Model and Analysis. Journal of Marketing Research \(JMR 3 p. 373-386 29] Lovell, G., Movies and manipulation: How studios punish critics. Columbia Journalism Review, 1997. 35\(5 30] Thompson, K., Film Art: An Introduction. 2001 McGraw Hill, New York 31] Zuckerman, E.W. and T.Y. Kim, The critical trade-off identity assignment and box-office success in the feature film industry. Industrial and Corporate Change, 2003. 12\(1 


industry. Industrial and Corporate Change, 2003. 12\(1 27-67 32] KOFIC, Annual Report of Film Industry in Korea 2006 Korean Film Council, 2006 33] Sutton, S., Predicting and Explaining Intentions and Behavior: How Well Are We Doing? Journal of Applied Social Psychology, 1998. 28\(15 34] Basuroy, S., S. Chatterjee, and S.A. Ravid, How Critical Are Critical Reviews? The Box Office Effects of Film Critics Star Power, and Budgets. Journal of Marketing, 2003. 67\(4 p. 103-117  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 






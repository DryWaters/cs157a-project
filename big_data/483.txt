A Taxonomy-based Approach to Determining. Generic Interestingness of Association Rules 222 Rajesh Natarajan and B Shekar\221 Quantitative Methods and Information Systems Area Indian Institute of Management Bangaldre Bangalore, Kamataka India 560 076 m shek\222 iimh.emet.in Abstract Items are related to each other either because of the generic category to whichzthey belong or due to their usage contexts We describe four notions of item relatedness based on relationships existing between them using a taxonomy We combine 
two of them to get a new measure of item relatedness We compare and contrast this measure\222 with a traditional taxonomy-based similarity measure Interestingness of an association rule is then inversely proportional to the least-related item pair in the rule I INTRODUCTION Association Rule mining an important area of Data Mining is concemed with the detection of implicit pattems in large database of transactions on the basis of the co-occurrence between items 
In the retail market-basket context association rules inform a user ahout the items that are likely to be purchased together by a customer in a purchase transaction Association rule discovery methods are highly automated. A large number of rules are generated A user perusing these rules will be unable to get an overview of the domain Also most rules are obvious to the user It is manually impossible to inspect the rules and select the most relevant ones. Therefore, automated methods that select the most relevant and interesting mles are needed Interestingness measures 
6 81 quantify the amount of 221interest\222 that a rule is expected to evoke in a user examining it Interestingness measures are classified into two classes viz objective and subjective Objective measures E use the structure of a pattem and the data generating process to quantify its interestingness. Subjective measures 6 in addition, incorporate the views of the user who inspects it Silberschatz and Tuzhilin 6 identify two aspects that characterize subjective interestingness viz unexpectedness and actionability Most studies use unexpectedness to operationalize subjective interestingness 
This is done by evaluating rules against user-beliefs. The interestingness of a rule is directly proportional to its deviation from user beliefs 0-7803-7651-X1031$17.000 2003 IEEE Here we look at 221interestingness\222 in a slightly different fashion Items in an association rule might be related to each other to various degrees because of relationships between them These relationships might be a result of their primary functionalities secondary functionalities and usage contexts Stronger and larger numbers of relationships imply strong relatedness Normally we expect strongly 
related items to occur together in an association rule However if an association rule contains unrelated or weakly related item pairs then this occurrence tends to surprise a user This is because large occurrences of such item combinations are unexpected Our approach consists of using the domain knowledge of users to express relationships between items available for sale in a retail market in a taxonomy of items We then utilize the structural aspects of the taxonomy tree to comment on the 221relatedness\222 hetwcen item pairs occurring in the 
mined association,rules An item-pair is more 221interesting\222 if the items are less related to each other and vice-versa. The least related item pair in a rule drives the interestingness of the entire rule Taxonomies have been used in data mining studies to find associations between items at different levels of the taxonomy tree 4 to mine negative associations 7 and in attribute-oriented generalization 3 Hamilton and others 3 used taxonomies to rank generalized relations on basis of interestingness. However they construct taxonomies for 
individual attributes, but do not consider relationships that exist between the attributes Here we do not deal with attribute values explicitly but consider the relationships between two items based on their positions in the taxonomy tree Basu et al 2 used WordNet a lexical knowledge base of English words to evaluate novelty of tcxt-mined rules Our approach is similar to the approach adopted by Basu et al However they do not consider certain categories of relatedness characteristic to our context 


TENCON 2003 704 2 INTUITIVE NOTIONS OF ITEM RELATEDNESS A taxonomy is a tree that brings out the relationships hetween various items and their categories on the hasis of their attributes The relationships depicted are 221is-a\222 type of relationships Items that have similar or closely related attributes occur close to each other in the taxonomy as they tend to belong to the same broad category The categorization process creates two types of divisions in a taxonomy The first one is related to the number of values each attribute can take thus controlling the 221widthibreadth\222 of the taxonomy The second division concerns the number of attributes that a domain expert may use to describe a category. Although a large number of attributes need not necessarily imply greater depth the clarity of classification could greatly improve if greater depth is imparted to the taxonomy The description of a category concept then becomes more 221specific\222 Together these two types of divisions define the complexity of the taxonomy We cannot expect a domain expert to have complete knowledge about hisher domain In some sense a taxonomy is always incomplete with respect to the knowledge it represents We can have two taxonomies that represent the same set of items However they might describe the items to varying levels of detail This description.depends on the number of relationships captured by each taxonomy We can use the structure of a taxonomy i.e the positions of 221items\222 and the various categories connecting them to comment on the 221relatedness\222 between items We make use of graph theoretic terms freely Unless specified the terms are standard 2 I Node Separation Reloredness NSR A path that connects two leaf-level items or nodes consists of category nodes that lie in the traversal between them The conceptual separation of these two 221items\222 in the concept hierarchy can he the length of the \221path\222 connecting the two items The path connecting the two items includes various category nodes that divide the domain according to the attributes of the items Some of these attributes might be specific to one of the two items Occurrence of such attributes instantiated specifically on one of the two items would reduce 221rclatedness\222 A longer path has a greater likelihood of containing such 221category\222 nodes\222specific to one of the two items. Therefore relatedness between two items decreases as the length of path increases and consequently \221interestingness\222 increases The first notion of item relatedness called node separation relatedness \(NSR is the length of the simple path in terms of the number of nodes\connecting the two leaf-level items A and B I NSR A,B  Lp\(A,.B Traditionally in semantic nets representing natural language and othcr graph-based representation schemes, the semantic distance between two words is defined as the length of the shortest path that connects the two words This is defined in terms of the number of edges Except for the use of nodes instead of edges, the first notion of relatedness is similar to that employed in traditional literature Path length can he defined either in terms of nodes or in terms of edges As the number of nodes in a path is one less than the numhcr of edges, both the definitions are equivalent 2.2 Highest Level Node Relaredness \(HR A path connecting any two items in the taxonomy-tree consists of a number of nodes Of these one node called the highest-level node HP plays a significant role in determining relatedness between the two items The highest-level node is the lowest co,mmon ancestor for both the items The closer the highest level node HP is to the root node greater is the degree of separation between the items and lower the relatedness 221Fundamental\222 or basic attributes are used for categorization at higher levels near the root nodes while at lower levels categorization is by attributes that are more fine-grained and maybe specific to a category As a consequence of this kind of taxonomy construction, two siblings at a lower level of the taxonomy tree will he similar to each\222other to a greater extent than two siblings at a higher level of the concept hierarchy i.e closer to the 221root node Further the HP is the closest common ancestor node for both items If HP is at a lower level a large number of attributes will be common to both the items attributes specific to categories that belong to the path from HP to root node of the tree This increases the relatedness between items The second notion of item relatedness called Highest level Node Relatedness HR\for two items A and B is defined as the level of the highest level node of the path\(A,B connecting the two items HR A,B Level I HP\(A,B I We note that relatedness between two items increases with an increase in the value of HR and decreases with an increase in the value of NSR These two notions can be combined as follows The factor 221I\222 takes into account the case wherein the root node happens to he the lowest common ancestor It can easily he shown that the maximum relatedness between any two items in a taxonomy of depth 221K\222 is equal to K Therefore 221K\222 is used as the normalization factor The measure given by equation I is similar to the traditional hierarchy-based measure given as equation 2 5 2  HR\(A B depth\(A  deprh\(B Sim-Trad  where depth\(A and depth\(B are the depths in terms of edges at which the items A and B occur in the taxonomy 


Web Technology and Data Mining 705 Figure 1 A Partial Taxonomffor a retail Stole Although ltem-Relulednes and Sim-Trad appear to be similar there are some differences between the two Conceptually Sim-Trud measure can be viewed as the ratio of the number of concepts common to the two items to the total number of concepts instantiated by the\222two items On the other hand Item-Relatedness is the ratio of the number of concepts common to the two items to the number of concepts different across the two items Therefore it is a ratio of the commonality to the differences between the two items In the case of Item-Relatedness measure an increase in the commonality will directly increase its value given a fixed difference in direct proportion On the other hand in case of Sim-Trud increase in value is not in direct proportion to the increase in commonality Another point of differcnce is regarding how the two measures treat the case when the root node happens to be the least common ancestor ofthe two item nodes Sim-Trad directly takes a value of zero since the level of the root node is 0 This medns that any two leaf-level items even if connected by paths of varying lengths will always have a value of Sin-Trud equal to 0 This docs not correspond to intuition as wc know that paths of different lengths mean different levels of similarities Also thcre is at least a small degree of similarity between two items even though they may be far away from each other On the other hand em-Relatedness is more intuitive as it does not assign a value of zero but gives a very low value ofrelatedness This depends on the length of the path connecting the two items A longer path will lead to lower relatedness Finally Sim-Trad is not normalized and therefore cannot tie used to compare relatedness between items in two different taxonomies Item-Relatedness can give some idea of the relative relatedness because of the normalization factor Figure I depicts a sample taxonomy and Table I gives the computed values of item relatedness measures for some sample item pairs 2.3 Level-Imbalance Relatedness LR Items can occur as leaf nodes at different levels in a concept hierarchy tree A lower level item has larger number of 221instantiated attributes\222 going into the description of the category it belongs to By 221instantiated attributes\222 we mean\222 the attributes that are peculiar to a category and whose values go into defining the item under the category On the other hand a higher-level item is sufficiently described by fewer attribute instantiations A rule relating an 222item\222 from a 221higher-level\222 category to a Iower-level\222 category would be more interesting because it would be connecting a 221general\222 item to a 221particular\222 item generality being defined by lesser number of attribute instantiations We would be interested in knowing why not to the sibling of the 221particular\222 item which is sufficiently similar to the Iower level item We try to capture this aspect of relatedness, by a third measure called level imbalance relatedness ER LR is simply the difference in the levels of the two items Therefore LR\(A B  I level\(A  level\(B I 


TENCON 2003 706 Table 1 Item Rclatedness between some sample item pairs I The larger the differcnce the lower is the relatedness and consequently higher the interestingness Another interesting point that concerns an item-pair that has a sufficiently high LR is the fact that there are usually more choices available to a user in the domain of thc lower-level item than the domain of the higher-level item  2.4 Density Relatedness DR In a taxonomy tree different categories are instantiated by different number\222 of attributes While in one case five anributcs might sufficiently describe the functionality of a categoj in another one may require ten or more Also cach attribute can take different values from its range Therefore,\221different portions of a taxonomy are not equally 221dense\222 with respect to 221categories\222 and 221sub-categories\222 If a path connecting two items lies in a 221dense\222 area of the concept hierarchy then that path will be connecting two items whose functionality is specified by more number of instantiated altributes This connection is particularly interesting because there is a lot of choice available in the 222dense\222.part of the concept hierarchy If a category is monopolizcd by very few items, a customer does not have choices This ,introduces sparseness A connection between any two items in a sparsely populated part of the concept hierarchy would not be as interesting because a cusomer would be forced to purchase the available items due to the absence of choices Whereas we would be interested in knowing why a specific connection between items takes place in the densely populated portion of the tree and not with respect to the siblings of the items Wc capture this aspect by a measure called 221density relatedness\222 DR which in a\222sense measures the relevant choices available for a customer\222s purchase To calculate DR\(A B we note the number of children of,each node belonging to path\(A B and sum them up This gives us a measure of 221denseness\222 of that part the concept hierarchy where the path lies  Thus DR\(A,B zlchildrenofA X\200palh\(A B This notion is similar to the notion of conceptual density developed by Agirre and Rigua I where they note that concepts that are in a denser part of a taxonomy are relatively closer than those in a sparser region However here we use the notion of density in a different sense We note that more product variants are available in a denser part of the taxonomy Therefore an item pair connecting two items in a denser part of the taxonomy tends to be\222more interesting due to the specific connection among all the possible connections 3 D~SCUSSIONS Table 1 shows the item relatedness measures calculated for sample item pairs specified by the taxonomy given in Figure 1 We highlight the important features here The first point to be noted is that both Item-Relatedness and Sim-Trad rank the relatedness between item pairs in a similar way i.e the relative rankings are more or less the same Sim-Trad assigns a value of 0 to the first five item pairs because the root node happens to be the lowest common ancestor for these item pain However Item-Relatedness assigns low values of relatedness depending 011 their path lengths This is more intuitive as we see that all the items are household items, which means that they are related in some way or the other although to a small extent. Notice that in item pairs 6 and 7 Item-Relatedness values are much lower than the values assigned by Sim-Trad This is because of the normalization factor that is prcsent in ItemiRclateness We also note Itcm-Relatedness assigns the maximum possiblc value I to the pair Orange SoJi Drink Lemon Sofr Drink This pair has the 221strongest relatedness in the entire taxonomy NSR and HR are relatedness at a more basic level than LR and DR Therefore, we can look at relatedness from two levels initially we can use the Item-Relatedness values to rank\221item pairs Then Level Imbalance and Density Relatedness values are useful for comparing those item pairs that have equal or nearly the same values of Item-Relatedness or Sim-Trad It is not appropriate to use 


Web Technology and Data Mining 707 the LR and DR measures in isolation Considcr the item pairs 2 and 3 in Table I They have equal values for all relatedness measures except for Level Relatedness The item pair Cake Liquid Soap is slightly more interesting than  Whire Bread Shampoo because Cake which is at a higher level in the taxonomy is related to a very specific item viz Liquid Soap This is brought out by the level relatedness measure. Finally we note that association rules contain morc than one item pair Therefore while considering the interestingness of a rule we have to consider the relatedness of all item pairs The interestingness of an association rule can then be said to be inversely proportional to the relatedness of the 222least-related\222 item pair of the rule 4 SUMMAR Knowledge discovery in databases aims at discovering unknown relevant and significant knowledge from large databases. However in association rule mining automated methods for discovering the most interesting and relevant rules, are nccessary because association rule mining algorithms typically tend to\222 discover a large number of rulcs The numbers are too large for easy human comprehension Further most of the discovered rules are obvious to the user due to hisiher domain knowledge In this paper we have described a knowledge-based approach to dctermining generic interestingness of association rules Items sold at a retail outlet are inter related to various extents due to their primary and secondary functionalities and usage contexts We use a knowledge taxonomy to depict the is-a relationships between the items and their categories. Structural aspects of this taxonomy are used to describe four intuitive notions of item relatedness Two of thesc notions viz Node Separation relatedness and Highest-level node relatedness are combined to obtain a quantitative measure of relatedness i.e Item-Relatedness We have compared this with a traditional similarity measure viz Sim-Trad 5 The other two notions viz density relatedness and level imbalance relatedness can be used to further discem item pairs having near equal values of Item-Relatedness In general association rules can contain many items We then need to consider the relatedness values of all item pairs A rule\222s least related itcm-pair is its most interesting one. We can usc this pair to represent the rule The least-related item pair is identified for all rules Then association rules are ranked according to an increasing order of 1lem~ReIatedne.w Interestingness and item rclatedness are opposing notions The presence of unrelated and weakly related item-pairs in a rule helps in determining interestingness of rules both qualitative and quantitative We have attempted to identify and quantify this presence REFERENCES I E Agirre and G Rigau, \223Word Sense Disambiguation Using Conceptual Density,\224 in Proceedings of COLING 22196 Copenhagen, Denmark 16-22 1996 2 S Basu R I Mooney K V Pasupuleti, and J Ghosh 223Evaluating the Novelty of Text-Mined Rules Using Lexical Knowledge,\224 Seventh International Conference on Knowledge Discovey and Data 222 Mining KDD 2001 Proceedings California USA 2001 3 H I Hamilton and D R Fudger 224Estimating DBLEARN\222s Potential for Knowledge Discovery in Databases,\224 Compnlationrrl Intelligence 11\(2 280-296 1995 4 I Han and Y Fu 223Mining multiple association rules in large databases,\224 lEEE Transactions on Knowledge and Data Engineering 11\(5 1-8 1999 5 P Resnik 223Semantic Similarity in a Taxonomy An Information-Based Measure and its Application to Problems of Ambiguity in Natural Language,\224 Journal of Artificial Intelligence Research 11 95-130 1999 6 A Silberschatz and A. Tuzhilin 223What makes Patterns lntercsting in Knowledge Discovery Systems,\224 IEEE Transoclion.5 on Knowledge and Data Engineering 8\(6 970-974 December 1996 7 D K Subramanian V S Ananthanarayana and M Narasimha Murty 223Knowledge-Based Association Rule Mining using AND-OR Taxonomies,\224 Know1edge-Ba.yed Sysrems 16,37-45 2003 SI P Tan V Kumar and J Srivastava, \223Selecting the Right Interestingness Measure for Association Pattems,\224 Eighth ACM SIGKDD Int\222l Conf on Knowledge Discovery and Data Mining KDD-2002 Proceedings July 23-26 2002  


Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


Figure 8 Visual interface for Moridou system Search EngineTest Page 0 UI 0 5 5 Keyword plealet Figure 9 Prototype system in hcterogeneous environment 283 


6 Conclusions We presented MAFIA an algorithm for finding maximal frequent itemsets Our experimental results demonstrate that MAFIA consistently outperforms Depthproject by a factor of three to five on average The breakdown of the algorithmic components showed parent-equivalence pruning and dynamic reordering were quite beneficial in reducing the search space while relative compressiodprojection of the vertical bitmaps dramatically cuts the cost of counting supports of itemsets and increases the vertical scalability of MAFIA Acknowledgements We thank Ramesh Agarwal and Charu Aggarwal for discussing Depthproject and giving us advise on its implementation We also thank Jayant R Haritsa for his insightful comments on the MAFIA algorithm and Jiawei Han for providing us the executable of the FP-Tree algorithm This research was partly supported by an IBM Faculty Development Award and by a grant from Microsoft Research References I R Agarwal C Aggarwal and V V V Prasad A Tree Projection Algorithm for Generation of Frequent Itemsets Journal of Parallel and Distributed Computing special issue on high performance data mining to appear 2000 2 R Agrawal T Imielinski and R Srikant Mining association rules between sets of items in large databases SIGMOD May 1993  R Agrawal R Srikant Fast Algorithms for Mining Association Rules Proc of the 20th Int Conference on Very Large Databases Santiago Chile, Sept 1994  R Agrawal H Mannila R Srikant H Toivonen and A 1 Verkamo Fast Discovery of Association Rules Advances in Knowledge Discovery and Data Mining Chapter 12 AAAVMIT Press 1995 5 C C Aggarwal P S Yu Mining Large Itemsets for Association Rules Data Engineering Bulletin 21 1 23-31 1 998 6 C C Aggarwal P S Yu Online Generation of Association Rules. ICDE 1998: 402-41 1 7 R J Bayardo Efficiently mining long patterns from databases SICMOD 1998: 85-93 8 R J Bayardo and R Agrawal Mining the Most Interesting Rules SIGKDD 1999 145-154 9 S Brin R Motwani J D Ullman and S Tsur Dynamic itemset counting and implication rules for market basket data SIGMOD Record ACM Special Interest Group on Management of Data 26\(2\1997 IO B Dunkel and N Soparkar Data Organization and access for efficient data mining ICDE 1999 l 11 V Ganti J E Gehrke and R Ramakrishnan DEMON Mining and Monitoring Evolving Data. ICDE 2000: 439-448  121 D Gunopulos H Mannila and S Saluja Discovering All Most Specific Sentences by Randomized Algorithms ICDT 1997: 215-229 I31 J Han J Pei and Y Yin Mining Frequent Pattems without Candidate Generation SIGMOD Conference 2000 1  12 I41 M Holsheimer M L Kersten H Mannila and H.Toivonen A Perspective on Databases and Data Mining I51 W Lee and S J Stolfo Data mining approaches for intrusion detection Proceedings of the 7th USENIX Securiry Symposium 1998 I61 D I Lin and Z M Kedem Pincer search A new algorithm for discovering the maximum frequent sets Proc of the 6th Int Conference on Extending Database Technology EDBT Valencia Spain 1998 17 J.-L Lin M.H Dunham Mining Association Rules: Anti Skew Algorithms ICDE 1998 486-493 IS B Mobasher N Jain E H Han and J Srivastava Web mining Pattem discovery from world wide web transactions Technical Report TR-96050 Department of Computer Science University of Minnesota, Minneapolis, 1996 19 J S Park M.-S Chen P S Yu An Effective Hash Based Algorithm for Mining Association Rules SIGMOD Conference 20 N Pasquier Y Bastide R Taouil and L Lakhal Discovering frequent closed itemsets for association rules ICDT 99 398-416, Jerusalem Israel January 1999 21 J Pei J Han and R Mao CLOSET An efficient algorithm for mining frequent closed itemsets Proc of ACM SIGMOD DMKD Workshop Dallas TX May 2000 22 R Rastogi and K Shim Mining Optimized Association Rules with Categorical and Numeric Attributes ICDE 1998 Orlando, Florida, February 1998 23 L Rigoutsos and A Floratos Combinatorial pattem discovery in biological sequences The Teiresias algorithm Bioinfomatics 14 1 1998 55-67 24 R Rymon Search through Systematic Set Enumeration Proc Of Third Int'l Conf On Principles of Knowledge Representation and Reasoning 539 550 I992 25 A Savasere E Omiecinski and S Navathe An efficient algorithm for mining association rules in large databases 21st VLDB Conference 1995 26 P Shenoy J R Haritsa S Sudarshan G Bhalotia M Bawa and D Shah: Turbo-charging Vertical Mining of Large Databases SIGMOD Conference 2000: 22-33 27 R Srikant R Agrawal Mining Generalized Association Rules VLDB 1995 407-419 28 H Toivonen Sampling Large Databases for Association Rules VLDB 1996 134-145 29 K Wang Y He J Han Mining Frequent Itemsets Using Support Constraints VLDB 2000 43-52 30 G I Webb OPUS An efficient admissible algorithm for unordered search Journal of Artificial Intelligence Research 31 L Yip K K Loo B Kao D Cheung and C.K Cheng Lgen A Lattice-Based Candidate Set Generation Algorithm for I/O Efficient Association Rule Mining PAKDD 99 Beijing 1999 32 M J Zaki Scalable Algorithms for Association Mining IEEE Transactions on Knowledge and Data Engineering Vol 12 No 3 pp 372-390 May/June 2000 33 M. J. Zaki and C Hsiao CHARM An efficient algorithm for closed association rule mining RPI Technical Report 99-10 1999 KDD 1995: 150-155 1995 175-186 3~45-83 1996 452 



COMPARISON AND IMPROVEMENT OF ASSOCIATION RULE MINING ALGORITHM XIAO-FENG GU 
XIAO-HUA WU I XIAO-MING WANG 3 1 School of Information and Software Engineering University of Electronic Science and Technology of China ChengDu 610054 China 2 State Grid Inner Mongolia Eastem Electric Power Limited Company Information and Communication Branch Huhehaote 
eHEN-XI MA4 AO-GUANG WANG 
2 
HUI-BEN ZHANG 
XIAO-JUAN HOU 
I I I 
0 I 0020 China 3 Liaohe Oil Field Panjin 124000 China 4Chengdu COMSYS Information Tech Co Ltd ChengDu 6 I 0054 China EMAIL 1033203783@qq.com.guxf@uestc.edu.cn Abstract In recent years the data mining technology has been developed rapidly New efficient algorithms are emerging Association data mining plays an important role in data mining and the frequent item sets are the highest and the most costly This paper is based on 
the association rules data mining technology The advantages and disadvantages of Apriori algorithm and FP-growth algorithm are deeply analyzed in the association rules and a new algorithm is proposed finally the performance of the algorithm is compared with the experimental results 
provides a reference for the extension and improvement of the algorithm of association rule mining Keywords Association rules Apriori FP-growth 1 
lt 
Introduction The concept of data mining is was frrstly raised at the ACM conference in the United States in 1995 Data mining is also called KDD 
has a high practical value in the field of database research Association rule mining is an 
refers to mining a large amount of data from the database to reveal the implicit unknown potentially useful information of the non-trivial process 1 2 
It It 
important branch of data mining research 3 Association Rule Mining is used to find a link that is hidden in the interest of large data sets In this paper the two algorithms are discussed 2 Association rule theory 2.1 Basic definition 978-1-4673-8266-3/15/$3l.00 
251l015 
IEEE 383 Assume 1 il 12 i3  In is a collection of items and data set D tasks related is a collection of 
transaction databases and each trans action T is a collection of a number of items to make 
Each trans action has a representation called TID The transaction T contains a collection of items A if and only if 
An association rule is a form of A=>B logical implication among them AcI Bel and AnB=\(I 5 The evaluation criteria of association rules are mainly support and 
confidence Support represents frequent degree that rules are used in the collection oftransactions Support\(A---->B  A 
U 
Confidence determines the predictability of the rules Confidence\(A=>B BIA  A 
B  A 2.2 Association rule mining process The mining process of association rules mainly contains two stages 6 in the frrst phase we must firstly find out all the items whose support is greater than minimum support from the transaction database that is to 
UB 
find all frequent item sets the second stage is to generate the expected association rules from these frequent item sets 3 Apriori algorithm 3.1 The basic idea Apriori algorithm is a kind of typical breadth first search combined with direct counting algorithm using the iterative strategy of layer by layer search Firstly it will generate candidate set and filter the candidate set then produce frequent sets of the layer 7 


bccfchccsc chickCll cloth es count the number of each item and get candidate I sets CI with the minimum support for comparison so that get the frequent I sets LI such as Fig.I Cl LI Ttcm sets count bcer Ttcm sets count chccsc clOlhcs chccsc clothes produces the considerable proved to be non-frequent candidate item sets and the cost of counting is quite high especially when the candidate set is relatively long time and space is achallenge 4 FP-growth algorithm 4.1 The basic idea Aiming at the bottIeneck problem of Apriori algorithm a method called FP-growth is proposed by Wang In 2000[8].The proposed algorithm only scans the database for 2 times FP-growth algorithm is a depth first search algorithm combined with direct counting using recursive strategy of pattern growth it need not generate candidate sets instead the trans action database is compressed into a tree structure that stores only the frequent items All the frequent item sets are obtained by recursively mining FP-tree 4 9  1 ducken milk dothes J ducken milk dothesJ L3 Itcm sets count beef chicken milk bccf chickcn chccsc chickcn milk clothes Fig.3 Step 3 Step 4 generate candidate 4 sets C4 by frequent 3 sets L3 and pruning candidate 4 sets C4 is empty such as Fig.4 C4 ltemsets beef ducken nulk cheeseJ beef ducken nulk dothesJ Fig.4 Step 4 3.3 Advantages and disadvantages 3.3.1 Advantages Apriori algorithm generates the candidate item sets by using Apriori which greatly compress the candidate item sets and the size of the frequent item sets and obtain good performance 3.3.2 Disadvantages I The need for multiple scan database system 1/0 load is quite large The time of each scanning will be very long resulting in a relatively low efficiency of Apriori algorithm 2 It maybe produce huge candidate item sets In the worst case milk chccsc milk clOlhcs milk clOlhcs bccfclolhcs chickCll milk chickCll chccsc chccsc milk boots chccsc TID milk chccsc it T3 Items Tl beef chicken milk T2 beefcheese   chickcn chccsc  chickcn clothes L2 ltem sets counts beef chieken beefmilkJ beef cheeseJ l chieken milk l chieken cheeseJ l chieken clothesJ milk clothesJ Fig.2 Step 2 Step 3 generate candidate 3 sets C3 by frequent 2 sets L2 and pruning then scan transaction database 0 count the number of each item in C3 with the minimum support for comparison then get the frequent 3 sets L3 such as Fig.3 384 C3 C3 HC1l1 sets HC1l1 sets count 3.2 Examples of Apriori algorithm Take the supermarket retail industry as an example mining the association rules through the analysis of the sales records Known trans action database D as shown in table I the database has 7 transactions with minimum support of2 Table I Transaction database D D cheese boots T4 beef chicken cheese T5 beef chicken clothes cheese milk T6 chicken clothes milk T7 chicken milk clothes Step I scan transactlOn database clOlhcs clOlhcs Fig.1 Step I Step 2 generate candidate 2 sets C2 by frequent I sets LI and then scan transaction database 0 and count the number of each item in C2  with the minimum support for comparison then get the frequent 2 sets L2 such as Fig.2 C2 C2 Hem sets ltemsets counts beef chickenJ beef chieken bccf1l1ilkj bccfmilk   bcer chccsc 


T3 Items Tl chicken beef milk T2 beefcheese cheese T4 chicken beef cheese T5 chicken beef milk cheese clothes T6 chicken milk clothes T7 chicken milk c10thes Step 3 msert each transactIOn record from the second step into FP-Tree fmished FP-Tree is shown in Fig.5 The suffix mode is empty at first The frequent item table after Sorting is pIP P is the first frequent item and P is the remaining frequent items Call insert tree P pi T recursively Step 4 find frequent items from the FPTree traverse the header in each cheese 4 as an example 1 Find all the cheese node from the FPTree traverse its ancestors and get conditional mode the suffix mode at this time is cheese 1 2 build the FP-tree on the basis ofthe conditional model as shown in  Fig.6 Fig.5 FPTree 385 chi ck t n milk Fig.6 Conditional FP-tree Repeat the above operation and mme frequent patterns such as table 4 Table 4 Frequent pattern table item frequent patterns c10thes milk clothes:5 clothes:5 chicken milk clothes:5 chicken clothes:5 chicken cheese:4 cheese:4 cheese chicken beef cheese:4 beef cheese:4 milk beefmilk:4 milk:4 chicken beefmilk:4 chicken milk:4 beef chicken beef:4 beef:4 chicken  chicken:5 4.3 Advantages and disadvantages 4.3.1 Advantages I the tree FP algorithm uses a compressed storage tree structure to access trans action records only for the two scan the scan time consumption is less than Apriori algorithm 2 FP tree algorithm does not generate candidate sets completely and does not count the candidate item sets so the time performance is better than the Apriori algorithm 4.3.2 Disadvantages I FP-tree algorithm in mmmg frequent patterns inevitably need to create additional data structures which will consume a lot oftime and space 2 For the FP tree algorithm the performance of the algorithm will be affected if the condition tree is very rich in the worst case 3 The FP tree algorithm can only be used to excavate the Boolean association rules of a single dimension 5 Aigorithm improvement Based on the growth FP algorithm the main idea is to inherit the advantages of FP-growth algorithm that need not TID 4.2 Examples of FP-growth algorithm This instance uses the transaction database D of table 1 with minimum support of2 Step 1 firstly scan the database each element is sorted descending by frequency and delete the element whose frequency is less than the minimum support and get frequent 1 set as shown in table 2 Table 2 F Item sets count chicken 5 beef 4 milk 4 cheese 4 clothes 3 Step 2 secondly scan database for each transaction resort according to the order of F 1 and delete elements that not belong to the frequent 1 sets of F I such as table 3 Table 3 Transaction database D 


the generation of candidate sets firstly count the total number of frequent I sets marked as n then scan the database n times each time a database subset of every item in Cl is obtained Then, the growth FP algorithm is used to constrain the frequent item sets in the database subsets and obtain the frequent item sets containing the frequent item sets In the end merger these frequent items and get all the frequent item sets 6 Conclusion In order to verify the efficiency of the algorithm Eclipse is used to implement the above algorithms Test data contains a number of transactions 4627 and each transaction contains 217 attributes Support was respectively 0.1 0.2 0.3 0.4 and 0.5 The test results are shown in Fig.7 Obviously when the minimum support degree is smalI the running speed of FP-growth algorithm is much faster than the Apriori algorithm When the minimum support degree is large the running speed of FP-growth algorithm is faster than the new algorithm But the new algorithm runs faster than the FP-growth algorithm when minimum support is small to a certain degree The reasons for this phenomenon are as follows the time cost of FP-growth algorithm depends on the construction and mining frequent item sets but the time cost of the new algorithm depends on the generation of the database subsets the trees bui Iding of the database subsets and the mining of frequent item sets With the decrease of the minimum support degree the total number of the total number of FP-growth algorithm increases the memory overhead and time overhead ofthe FP-growth algorithm are becoming more and larger so the digging speed is slower and slower At this time the time cost of the new algorithm in database subset generation is increasing but in terms of building the database sub sets and constrained frequent item sets mining due to the relatively small memory overhead time overhead is relatively small the overall mining speed is faster than FP-growth The bigger database the more obvious advantages 11 12 10   8 Usama M Fayyad,Gegory Piatetsky Advance In knowledge discovery and data mining California AAAI/MIT Press 1996 9 Zhixin Feng Cheng Zhong Mining maximal frequent patterns based on FP-Tree algorithm Computer Engineering 2004,6 11 123-126 growtll I'P growth 2 I Apriori Fig.7 Results 386 AcknowIedgments The research work was supported by 2012 National Science and technology support program 20 12BAH87F03 References 1 Ke Luo Biye Cai Shengxian Bu Research on data mining and its development 1 database and information processing 2002 14 182-184 2 Xiaoyi Li Zhaodi Xu Analysis of association rule mining algorithm J Journal of Liaoning Technical University 2006 24 2 319-320 3 JOCHEN H ULRICHG GHOLAMREZA Aigorithms for association rule mining a general survey and comparison[1 SIGKDD Explorations 2001 2\(1 5864 4 Min Li Chunping Li Analysis and comparison of 4 frequent pattern mining algorithm 2005 12 5 Hau JW Kamber Mi,Ming Fan Xiaofeng Meng Data mining concepts and techniques Beijing Mechanical Industry Press 2006 6 Xiaodong He Weiguo Liu Association rule algorithm in data mining J computer engineering and design.2005 7 Lili KUANG Discussion on Apriori algorithm and FP-tree algorithm Huaibei Coal Industry Teachers College NATURAL SClENCE EDITION 2010 31   


          012     015                      012 012    012                012 012   012        012        012               012                   012    012                      012    012                                 012                   012              012            012                  012         012    012     012                       012         012                           012     012                 012                012                 012                   012       012             012                      012                  012     012                                                         0                          1  012                      012               012              2    012             1  012      3    4      5      4 6  4 7         8 9  5    8            0                 2                       012     012             012   012                                   2    012            3     9      6       5 4   9         8 9  5    5                   2                    012           012            1  012                              2    012           012     3    5 8            6 5  6 4        8 9  8         A   B      C                 012   012                                       2    012             3     9      5      5 D   9         8 9  5    4  0      C    015          C  0             015  012  E                        012                    012                012          012     012                       012          2 C   0      012         F G H I J K L   8 9 9      6   2                     B                        M       012         012     012               012                                    012                012            3    5 9      5      5   5 5         8 9      N O P Q R S T U U V W X Y Z  S     U   _  a  b X  U R X c  W S X c d  e S X  U R U X T U  S X  fc T  W X U  g U c R X W X Y  c X V  e h i U R X U  W T Z j  kl c X Y m  S l j    n  a  o l d h j   _  a 


Figure 5 Experimental results with n  1 050each item missing from one instance\051 Patterns 002ltered by 10 100 and 1000 surrogate data sets Intuitively x 050 pat 051 S  w  s min 050 i  J 051 sums the grades of synchrony underlying each of the patterns that connect i to the other items in J  Note that in this de\002nition we assume 050as is common practice\051 that x 050 pat 051 S  w  s min 050 i  J 051  0 if C 003 S  J 050 w  s min 051   0  This approach has the advantage that merely the 002ltered set of closed frequent patterns is needed However it has the disadvantage that subset patterns which by chance occur again outside of the instances of the full pattern may deteriorate the detection quality An example of such an occurrence can be seen in Figure 4 the neurons a  b and e 002re together between the second and third instance of the full set However this is not an incomplete instance of the full set but rather a chance coincidence resulting from the background spikes This can lead to a subset being preferred to the full pattern even though the sum in the above de\002nition gives higher weight to events that support multiple instances 050as these are counted multiple times\051 Removing instances is necessary to improve the detection quality To obtain concrete instances of the functions x S  w  s min 050 i  J k 051 we de\002ne Instance-based Approach We start from the same idea in 050Borgelt et al 2015\051 that we only want to consider instances that are not 223isolated\224 but 223overlap\224 some other instance 050preferably of a different pattern\051 The reason is that isolated instances likely stem from chance coincidences while instances that 223overlap\224 other instances likely stem from the same 050complete or incomplete\051 instance of the full pattern we try to identify Unlike 050Borgelt et al 2015\051 where the instance-based approach merely counts spikes without considering the precision of synchrony in our approach we recompute the support from the reduced set of instances which is simple as the instances are known Let C 003 S 050 w  s min 051 and C S  J 050 w  s min 051 be de\002ned as above Let U S  w 050 I 051 022 E S  w 050 I 051 be the set of all instances of I that was identi\002ed by the CoCoNAD algorithm in order to compute the support s S  w 050 I 051  Furthermore let V S  w  s min 050 J 051  S I 2 C 003 S  J 050 w  s min 051 U S  w 050 I 051  That is V S  w  s min 050 J 051 is the set of all instances underlying all patterns found in S that are subsets of J  To implement our idea of keeping overlapping instances of different patterns we de\002ne V 003 S  w  s min 050 i  J 051  f R 2 V S  w  s min 050 J 051 j  9 T 2 V S  w  s min 050 J 051  f 050 T 051 6  f 050 R 051  o i 050 T  R 051  1 g  where f is the pattern operator de\002ned in Section 2 and o i 050 R  T 051 is an operator that tests whether the instances R and T overlap In words V 003 S  w  s min 050 i  J 051 is the set of instances of patterns that contain the item i 2 J and are subsets of the set J  which overlap at least one other instance of a different pattern The operator o i checks whether the instances have a non-empty intersection The instance-based approach has the advantage that chance coincidences are much less likely to deteriorate the detection quality However its disadvantage is that it is more costly to compute because not just the patterns but the individual instances of all relevant patterns have to be processed 


Figure 6 Example of generated data sets that imitate parallel neural spike trains Each row of blue dots represents the spike train of each neuron In this example the injected patterns are drawn in red The selective participation adaptation method proposes to study only instances that overlap with other instances of different patterns re-compute the support for these patterns and 002nally apply the pattern-based approach 6 EXPERIMENTS We implemented our frequent synchronous pattern mining method in Python using an ef\002cient C-based Python extension module that implements the pattern mining and surrogate generation 2 We generated event sequence data as independent Poisson processes with parameters chosen in reference to our application domain 100 items 050number of neurons that can be simultaneously recorded with current technology\051 20Hz event rates 050typical average 002ring rate observed in spike train recordings\051 3s total time 050typical recording times for spike trains range from a few seconds up to about an hour\051 Into such independent data sets we injected a single synchronous pattern each with sizes z ranging from 2 to 12 items and numbers c of occurrences 050instances\051 ranging from 2 to 12 To simulate imprecise synchrony the events of each pattern instance were jittered independently by drawing an offset from a uniform distribution on  000 1ms   1ms  050which corre 2 The implementation of the CoCoNAD algorithm is developed in Python 050Rossum 1993\051 and the core of the algorithm is developed in C 050Kernighan and Ritchie 1978\051 This implementation can be found at http://www.borgelt.net/coconad.html and http://www.borgelt.net/pycoco.html A Java graphical user interface is available at http://www.borgelt.net/cocogui.html The scripts with which we executed our experiments as well as the complete result diagrams 050all parameter combinations\051 will be available at http://www.borgelt.net/hypernad.html sponds to typical bin lengths for time-binning of parallel neural spike trains which are 1 to 7ms\051 An example of such a data set is depicted in Figure 6 To simulate selective participation we deleted each item of a parallel episode from a number n 2 f 1  2  3  4  5 g of their instances This created data sets with instances similar to those shown in Figure 4 050which corresponds to z  6 c  6 and n  1 but has much fewer background spikes\051 a few instances may be complete but most lack a varying number of items For each signature h z  c i of a parallel episode and each value of n we created 1000 such data sets Then we tried to detect the injected synchronous patterns with the methods described in Sections 4 and 5 For mining closed frequent patterns we used different values of the window width w 2 f 2  3  4  5 g 050matching the jitter of the temporal imprecision\051 using a minimum support s min  1  0 and a minimum pattern size z min  2 Based on results presented in 050Ezennaya-G 264 omez and Borgelt 2015\051 the window value used is 3  2 j  Then 002ltering patterns mined with different pattern spectrum derived from 10 100 and 1000 data sets with independent spike trains The method described in Section 5 is applied to the resulting patterns Some of the results we obtained are depicted in Figures 5 7 and 8 In each row of the 002gures the 002rst diagram shows the number of 050strict\051 false negatives that is the fraction of runs 050of 1000\051 in which something else than exactly the injected pattern was found In order to elucidate what happens in those runs in which the injected parallel episode was not 050exactly\051 detected the diagrams in columns 2 and 3 show the fraction of runs in which a superset or a subset respectively of the injected parallel episode was returned Column 4 shows the fraction of runs with overlap patterns 050the reported pattern contains some but not all of the items of the injected parallel episode and at least one other item\051 column 5 the fraction of runs with patterns that are unrelated to the injected parallel episode On top of each diagram the different approaches are shown with its parameters The 002rst value corresponds to the number of missing instances followed by the type of 002lter and the type of reduction sequence approach applied and value of r parameter Figure 5 shows the different results obtained by 002ltering closed frequent patterns with the different patterns spectra 05010 100 and 1000\051 Note that graded synchrony has less problems with unrelated patterns We observe that 002ltering by surrogates derived from 100 and 1000 performs better w.r.t unrelated patterns That is 002ltering with 100 and 1000 surrogate data sets detect every injected pattern if only something is detected at all Figure 7 shows a comparison between 


Figure 7 Experimental results with instance-based approach and pattern-based approach for graded synchrony 050each item missing from one instance\051 Figure 8 Comparison between the instance/pattern-based approach for graded synchrony and the instance-based approach for binary synchrony the instance-based approach and the pattern-based approach using graded synchrony The 002rsts two rows of diagrams show results for r  0 and the second two rows correspond to r  1 The pattern-based approach is slightly better than the instance-based approach in terms of false negatives 050exact pattern detection\051 Concretely for r  1 the pattern-based approach has better ratios in supersets and overlaps by 


paying a price of a slightly worse ratio for subsets Taken together the price of having more subsets is preferred because subsets contain only items actually in the assembly while superset and overlap patterns also contain unrelated items The 002rst and second row of 002gure 8 correspond to the instance and the pattern-based approach for graded synchrony The third corresponds to the instance-based approach for binary synchrony Comparing the diagrams for unrelated patterns our graded method detects all injected patterns 050\002rst and second rows\051 while the binary method also produces unrelated pattern In 050Borgelt et al 2015\051 it is demonstrated that the instance-based approach yields slightly better results than the pattern approach However this approach does not consider the precision of synchrony Surprisingly using only the pattern-based approach with a graded notion of synchrony yields a better ratio for overlap and superset patterns 7 CONCLUSIONS In this paper we presented a method to detect frequent synchronous patterns in event sequences using a graded notion of synchrony for mining patterns in the presence of imprecise synchrony of events constituting occurrences and selective participation 050incomplete occurrences\051 Our method adapts methods presented in the literature to tackle selective participation using binary synchrony especially the instancebased approach which looks at instances of patterns to improve the detection by removing instances that are likely chance events checking the precision of synchrony of these instances We demonstrate in our experiments that using a graded notion of synchrony for support computation helps to simplify the detection of selective participation because a pattern-based approach yields better results or at least equally good results as an instance-based approach This is a considerable advantage since identifying the individual pattern instances is costly and thus it is desirable to avoid it ACKNOWLEDGMENTS The work presented in this paper was partially supported by the Spanish Ministry for Economy and Competitiveness 050MINECO Grant TIN2012-31372\051 and by the Principality of Asturias through the 2013-2017 Science Technology and Innovation Plan 050Programa Asturias CT1405206\051 and the European Union through FEDER funds REFERENCES Abeles M 0501982\051 Role of the cortical neuron Integrator or coincidence detector Israel Journal of Medical Sciences  18\0501\051:83\22692 Borgelt C 0502012\051 Frequent item set mining In Wiley Interdisciplinary Reviews 050WIREs\051 Data Mining and Knowledge Discovery  pages 437\226456 050 J Wiley  Sons Chichester United Kingdom 2 Borgelt C Braune C and Loewe K 0502015\051 Mining frequent parallel episodes with selective participation In Proc 16th World Congress of the International Fuzzy Systems Association 050IFSA\051 and 9th Conference of the European Society for Fuzzy Logic and Technology 050EUSFLAT\051 IFSA-EUSFLAT2015  Gijon Spain Atlantis Press Borgelt C and Picado-Muino D 0502013\051 Finding frequent synchronous events in parallel point processes In Proc 12th Int Symposium on Intelligent Data Analysis 050IDA 2013 London UK\051  pages 116\226126 Berlin/Heidelberg Germany Springer-Verlag Dudoit S and van der Laan M J 0502008\051 Multiple Testing Procedures with Application to Genomics  Springer New York USA Ezennaya-G 264 omez S and Borgelt C 0502015\051 Mining frequent synchronous patterns with a graded notion of synchrony In Proc 16th World Congress of the International Fuzzy Systems Association 050IFSA\051 and 9th Conference of the European Society for Fuzzy Logic and Technology 050EUSFLAT\051 IFSA-EUSFLAT2015  pages 1338\2261345 Gijon Spain Atlantis Press ISBN 050on-line\051 978-94-62520-77-6 Hebb D O 0501949\051 The Organization of Behavior  J Wiley  Sons New York NY USA Kernighan W and Ritchie D 0501978\051 The C Programming Language  Prentice Hall K 250 onig P Engel A K and Singer W 0501996\051 Integrator or coincidence detector the role of the cortical neuron revisited Trends in Neurosciences  19\0504\051:130\226137 Louis S Borgelt C and Gr 250 un S 0502010\051 Generation and selection of surrogate methods for correlation analysis In Gr 250 un S and Rotter S editors Analysis of Parallel Spike Trains  pages 359\226382 Springer-Verlag Berlin Germany Mannila H Toivonen H and Verkamo A 0501997\051 Discovery of frequent episodes in event sequences In Data Mining and Knowledge Discovery  pages 259\226 289 Springer New York NY USA 1\0503\051 Picado-Muino D and Borgelt C 0502014\051 Frequent itemset mining for sequential data Synchrony in neuronal spike trains Intelligent Data Analysis  18\0506\051:997\226 1012 Picado-Muino D Borgelt C Berger D Gerstein G L and Gr 250 un S 0502013\051 Finding neural assemblies with frequent item set mining Frontiers in Neuroinformatics  7 Picado-Muino D Castro-Le 264 on I and Borgelt C 0502012\051 Fuzzy frequent pattern mining in spike trains In Proc 11th Int Symposium on Intelligent Data Analysis 050IDA 2012 Helsinki Finland\051  pages 289\226300 Berlin/Heidelberg Germany Springer-Verlag 


Rossum G V 0501993\051 Python for unix/c programmers copyright 1993 guido van rossum 1 In Proc of the NLUUG najaarsconferentie Dutch UNIX users group  Torre E Picado-Muino D Denker M Borgelt C and Gr 250 un S 0502013\051 Statistical evaluation of synchronous spike patterns extracted by frequent item set mining Frontiers in Computational Neuroscience  7 Tsourakakis C Bonchi F Gionis A Gullo F and Tsiarli M 0502013\051 Denser than the densest subgraph Extracting optimal quasi-cliques with quality guarantees In Proc 19th ACM SIGMOD Int Conf on Knowledge Discovery and Data Mining 050KDD 2013 Chicago IL\051  pages 104\226112 New York NY USA ACM Press Zaki M J Parthasarathy S Ogihara M and Li W 0501997\051 New algorithms for fast discovery of association rules In Proc 3rd Int Conf on Knowledge Discovery and Data Mining 050KDD 1997 Newport Beach CA\051  pages 283\226296 Menlo Park CA USA AAAI Press 



 Abstract Genetic-fuzzy data mining can successfully find out linguistic association rules and appropriate membership functions close to human concepts from quantitative transactions and thus becomes a promising research field in these years. It repeatedly uses fuzzy frequent 1-itemsets to evaluate fitness values of chromosomes, which is very time-consuming. In this paper, we propose a MapReduce preprocessing approach to efficiently transform given quantitative transaction data into pairs of items and quantity lists to increase the performance of genetic-fuzzy mining. The MapReduce architecture totally fits the conversion due to its characteristics of key-value format Experimental results also show the effect of the proposed approach I  INTRODUCTION Traditional data mining only considers the items with occurrence or not in transactions of a database, but without their quantities. Some meaningful association rules may thus be dropped because of it. In the past, Srikant and Agrawal proposed quantitative association rules to prevent rule loss by partitioning quantitative data valu et al. t h en  proposed a fuzzy mining approach for deriving association rules from quantitative data i ng u i stic a n d i n terpretable rules could thus be easily found. Some other extended algorithms or applications were also proposed [8  12   In fuzzy data mining, the quality of membership functions may, however, have a critical effect on the final mining results Hong et al. thus adopted the genetic algorithm \(GA\ to automatically derive appropriate fuzzy membership functions because of the great optimizing capability of GA in limited time   It is qu ite ti m e c ons um i n g  es peciall y  t h e fitness evaluating process. It needs to find all the large 1itemsets by scanning the entire database since the items are spread in transactions. In this paper, we thus try to convert the original dataset into \(item, quantity list\airs to speed up the execution of genetic fuzzy data mining for deriving appropriate membership functions. Besides, the \(item, quantity list\pairs fit the requirement of MapReduce, so we will also apply MapReduce framework to parallelize the preprocessing process and to see how much time can be saved II  R ELATED W ORKS  Compare to traditional binary mining data, quantitative data are much closer to the real-world applications and human concept. Srikant and Agrawal proposed quantitative   association rules to well partition quantitative values and reduce the loss of knowledge o n g et al. adopted f u z z y  concept into mining techniques T h ey e x tract fu z z y  association rules by giving each item a fuzzy membership function. The fuzzy association rules can thus be found Since the quality of membership function is a critical issue for the final results, GA-based fuzzy data mining was thus proposed [1 h ic h u s e gen etic al g o rithm to f i n d better membership function. However, although the quality of membership function is improved, the execution time is still suffered by finding the large 1-itemsets to evaluate the fitness Some algorithms   w e re t h us propos ed t o i m prov e the time efficiency by parallelizing fitness evaluation process Google proposed MapReduce in 2008 It con t a i n s t w o  main functions, map and reduce, and the input and output data of each phrase will be stored as key-value format. There are many kinds of research on it, like large-scale data processing  d databas e [1 an d ef f i cie n c y i m prov e m ent f o r MapRedu  III  T HE A LGORITHM  In this paper, we only consider how much time can be speeded up in preprocessing by MapReduce, and we use threads to simulate the performance of MapReduce The proposed system architecture and data conversion algorithm is shown Fig. 1 and below    Fig. 1.  System architecture  The MapReduced Fuzzy Data Conversion Algorithm INPUT 1\n original dataset D  with n triples, each of which consists of transaction ID, item ID \(or name and item quantity 2\ MapReduce architecture with a key-size shift parameter k and m available mappers OUTPUT A converted dataset of \(item, quantity list\airs with the quantity list being the sequence of non-zero quantities of the item STEP 1  The master processor removes the field of transaction ID from each triple in D as the the keyvalue format for the MapReduce architecture, where a key is an item and a value is a quantity of the item STEP 2  The master processor splits the input dataset D into  Efficient Data Preprocessing for Genetic-Fuzzy Mining with MapReduce Tzung-Pei Hong 1 Yu-Yang Liu 2 Min-Thai Wu 1 and Chun-Wei Tsai 3  1 Department of Computer Science and Information Engineering, National Kaohsiung University, Taiwan 2 Department of Computer Science and Engineering, National Sun Yat-Sen University, Taiwan 3 Department of Computer Science and Information Engineering, National Ilan University, Taiwan  2015 International Conference on Consumer Electronics-Taiwan \(ICCE-TW 978-1-4799-8745-0/15/$31.00©2015 IEEE 88 


  p data pieces  each of which contains k triples in D  Thus p is  k n  STEP 3  The master processor distributes the p data pieces  to the m mappers in a round-robin way STEP 4  Each mapper w j  j 1 to m performs the following substeps for concatenating the quantites of the same item ID STEP 4.1  Receive the allocated pieces of data from the master. Assume each w j receive amount t j  of data STEP 4.2  Scan the received data one by one until all the data are processed; If the item i in the currently scanned data appears for the first time, then set a quantity list s ji with the current quantity as its value, and set i as its index; Otherwise, link the current quantity to s ji  STEP 5  The reducer do the following substeps for merging the data from the mappers STEP 5.1  The reducer receives the data sent from the mappers STEP 5.2  Keep the received data pairs \(item index i  quantity list s i from the first mapper STEP 5.3  Scan the received data \(item index, quantity list\e by one coming from the other mappers until all the data are processed; If the item index i in the currently scanned data does not appear in the existing indexes kept then set a new quantity list s i as the current quantity list; Otherwise, link the current quantity list to s i  STEP 5.4  Output each item index i and its s i   After STEP 5, the outputs are the converted data very suitable for chromosome evaluation in genetic-fuzzy data mining IV  E XPERIMENTAL R ESULTS  Some experiments were done to show the performance of the proposed MapReduced fuzzy data conversion algorithm Four datasets were adopted in our experiments. They have 30000, 50000, 70000 and 90000 transactions, respectively and each of them has 64 items. The experiments were run with single thread, 2 threads, 4 threads and 8 threads, respectively The results for the two datasets are shown in Fig. 2 respectively  Fig. 2. Execution time cost for different amount of transactions  It can be observed in these figures that the execution time decreases along with the increase of the thread numbers. The time efficiency of using multiple threads is better than that of using single thread The results show that the MapReduce architecture provides a solution to speed up the preprocessing of fuzzy data for genetic-fuzzy mining V  C ONCLUSION  In this paper, we suggest to preprocess original dataset by joining the quantities of the same item together. After this action, each row will include all the quantities of an item. It means that you do not need to scan the entire database to find one itemês information, and the data will stay complete after the division process of mapping. We examine the time efficiency of preprocessing the dataset in different number of thread, and the result is that the more threads are used, the less time is need to complete the job as expectation. In the future research, we will apply those re-ordered data and see how the data structure actually improves the performance R EFERENCES  1  Feng Li, Beng Chin Ooi, M. Tamer ÷zsu and Sai Wu, "Distributed data management using MapReduce ACM Computing Surveys vol. 46 2014 2  Jeffrey Dean and  Sanjay Ghemawat, "MapReduce: simplified data processing on large clusters Communications of the ACM vol. 51, pp 107-113, 2008 3  Jorge-Arnulfo QuianÈ-Ruiz, Christoph Pinkel, Jˆrg Schad and Jens Dittrich, "RAFT at work: speeding-up MapReduce applications under task and node failures ACM Special Interest Group on Management of Data pp. 1225-1228, 2011 4  Ramakrishnan Srikant and Rakesh Agrawal Mining quantitative association rules in large relational tables ACM Special Interest Group on Management of Data vol. 25, pp. 1-12, 1996 5  Sherif Sakr, Anna Liu and Ayman G Fayoumi The family of MapReduce and large-scale data processing systems Communications of the ACM vol. 46, 2013 6  Tzung-Pei Hong, Chun-Hao Chen, Yeong-Chyi Lee and Yu-Lung Wu Genetic-fuzzy data mining with divide-and-conquer strategy   IEEE Transactions on Evolutionary Computation vol. 12, pp. 252-265, 2008 7  Tzung-Pei Hong, Chan-Sheng Kuo and Sheng-Chai Chi, "Mining association rules from quantitative data Intelligent Data Analysis vol 3, pp. 363-376, 1999 8  Tzung-Pei Hong, Kuei-Ying Lin and Been-Chian Chien, "Mining fuzzy multiple-level association rules from quantitative data Applied Intelligence vol. 18, pp. 79-90, 2003 9  Tzung-Pei Hong, Kuei-Ying Lin and Shyue-Liang Wang, "Fuzzy data mining for interesting generalized association rules Fuzzy Sets and Systems vol. 138, pp. 255-269, 2003   Tzung-Pei Hong, Yeong-Chyi Lee and Min-Thai Wu, "An Effective Parallel Approach for Genetic-Fuzzy Data Mining Expert Systems with Applications vol. 41, pp. 655-662, 2004   Tzung-Pei Hong, Chun-Hao Chen, Yu-Lung Wu and Yeong-Chyi Lee A GA-based fuzzy mining approach to achieve a trade-off between number of rules and suitability of membership functions Soft Computing vol. 10, pp. 1091-1101, 2006   Salma Elhag, Alberto Fern·ndez, Abdullah Bawakid, Saleh Alshomrani and Francisco Herrera, "On the combination of genetic fuzzy systems and pairwise learning for improving detection rates on intrusion detection systems Expert Systems with Applications vol. 42, pp. 193202, 2015  89 


IEEE Sponsored 9th International Conference on Intelligent Systems and Control \(ISCO\2015 and memory for candidate generation process. It is a bottom-up approach Liu et al  p r opo sed M S A pr i o ri w hi c h i s a n e xt e nsi o n o f  Apriori algorithm. MS-Apriori tries to mine frequent itemsets involving rare items. It assigns a minsup \(MIS\ value to each item and items having the MIS value higher than the lowest MIS value were used for generating frequent itemset. In that way this algorithm tried to overcome the rare itemset problem and was found more efficient than single minsup based algorithm. Rules which had Low support and high confidence were not identified by this algorithm. The reason for inefficiency of this algorithm was the removal of rules with higher MIS values Troiano et al. [7 aly zed th e pr o b lem of bo tt om u p approach algorithms that searches through many levels. For reducing the number of searches the author proposed the Rarity algorithm that starts with identification of longest transaction from database and search rare itemsets in top-down approach It avoids lower layers which contains frequent itemsets Candidates \(Rare itemsets\ are pruned in two different ways Adda et al. [8 r o pos ed A f R I M A l g o r ith m th at als o u s e s  top-down approach which is similar to the Rarity Algorithm Searches for rare items starts with the itemset having all items found in database. Pruning of candidates are same as Rarity Algorithm. It examined itemsets that had zero support, which was the major drawback of this algorithm Szathmary et al. [9 pr o p o s e d t w o alg o r ith m s th at can m i n e  rare itemset. In those algorithms three type of itemsets were defined: minimal generators \(MG\, minimal rare generators MRG\, and minimal zero generators \(MZG\ MRG-Exp Algorithm used MRG for generating candidates in bottom-up fashion by using MGs. The MRGs represents a boundary that separated the frequent and rare itemsets. Other algorithm ARIMA utilized these MRGs to generate the complete set of rare itemsets which was generated in MRG-Exp Algorithm When MZG reaches to border, this algorithm stops the search for non-zero rare itemsets. Because above that boundary there were only zero rare itemsets Koh et al  p rop o s ed A p ri or i I nver s e used t o m i ne perfect rare itemsets. Except that, at the initialization, this algorithm was similar to the Apriori. Only 1-itemset that fell below minsup was used to generate two itemsets. AprioriInverse inverts the downward-closure property of Apriori. For allowing Apriori Inverse to find near prefect rare itemsets, Koh et al. also proposed several modifications Han et al. [1 prop o s e d F P G r o w t h A l go r i t hm w hi c h use d frequent pattern tree \(FP-tree\ for storing transactions of database and reduce database scanning. One scan is for finding the items which satisfied minimum frequency support threshold; another scan is for initial FP-tree construction. This algorithm also supported multiple minsup framework Maximum Constraint Based Conditional Frequent Growth MCCFP-Growth\ Algorithm i s  e xt e nsi o n o f F P G ro w t h algorithm. MCCFP-growth algorithm involves three steps: one is tree construction, second is compact MIS-tree derivation and third is mining frequent patterns. This algorithm took more time for database scan because of item pruning. It also occupied more memory space RP-Tree Algorithm [13 is a m o d i f i c a ti o n  o f th e F P G r o w t h  algorithm. Similar to FP-Growth algorithm, this algorithm performs database scan for counting support. In the second scan for building initial tree, RP-Tree used the transactions having at least one rare item. In this way, the transactions having non-rare items were not included in RP-Tree construction. This algorithm tried to provide complete set of rare-item itemset. RP-Tree is an efficient algorithm that uses the tree data structure and identifies most rare association rules Most of the algorithms used the fundamental Apriori approach which is single minsup based frequent pattern mining technique. It had potentially expensive pruning steps and candidate generation. Those algorithms try to find out all rare itemsets but they spent most of the time in searching for nonrare itemsets which tends to provide uninteresting association rules. To address the \223rare item problem\224, \223multiple minsup framework\224 [6, 14  w a s use d t o d i sco ver r a r e  a s s o c i a t i o n  rules.  Different models were proposed in this framework They are: \(i\ minimum constraint model [6, 15, 17 i i   maximum constraint model [14   200  Minimum Constraint Model In this model, every item has minimum item support MIS\ith the use of minimal MIS value among all items minsup of pattern is represented. In this way, each pattern satisfies a different minsup value among the respected items within it. Instead of satisfying downward closure property, all pattern are satisfying sorted closure property A s per s o rted  closure property, \223all non-empty subsets of a frequent pattern need not be frequent, only the subsets consisting of the item having lowest MIS value within it should be frequent\224. Hence based on this model Apriori-like or F P g ro w t hl i k e  15, 18, 19 pproach es co n s i d er f requ e n t an d i n f requen t  patterns. The sorted closure property was briefly explored in    200  Maximum Constraint Model Maximum constraint model has been proposed in  In th i s  m odel MIS v al u e s  w ere g i v e n to each ite m a n d it  is known as frequent pattern only if it satisfies MIS values of all the items. This model was capable to mine uninteresting patterns but, issue was that only Apriori-like approach was used with this model. As this approach was having performance problem, we cannot extend it. With this motivation, we propose tree like approach that uses this model for finding rare patterns  The proposed Maximum Constraint based Rare Pattern Tree \(MCRP-Tree\ an improvement over existing algorithm in many ways. First is, it avoids expensive pruning step and item generation by using tree data structure based on FP-tree to find rare items. Second is, MCRP-Tree focuses on rare-item itemset which gives interesting rule and does not spend more time in finding non-rare-item itemsets which are uninteresting Third is, MCRP-Tree contains only rare items by excluding 


IEEE Sponsored 9th International Conference on Intelligent Systems and Control \(ISCO\2015 the transactions which does not have rare items and also eliminate frequent items from the selected transactions. In the next section, we present the proposed approach which uses maximum constraint model for finding rare items III  M AXIMUM CONSTRAINT  BASED  RARE  PATTERN  TREE  MCRP-TREE A  Basic Concept: Rare Itemset The rare items are those that occur rarely in very few transactions and are normally pruned out. But rare items have significant use in many domains. Support and confidence are the factors used to identify the rare items among the dataset Rare items have lower support value but value of confidence is higher The minRareSup threshold works as a noise filter. The items are considered as a noise if they fall below this threshold An itemset is called as rare itemset if it has support above or equal to the minimum rare support threshold \(minRareSup\ but less than the minimum frequent support threshold minFreqSup For instance, suppose there are 4 items  with supports w = 0.80, x = 0.30, y = 0.50, and z = 0.12, with minFreqSup = 0.15 and minRareSup = 0.05. If the itemset  has a support of 0.09, then this itemset will be a nonrare-item itemset \(\(1\ above\ since all items are frequent, and its support lies between minFreqSup and minRareSup. The itemset  will be a rare-item itemset \(\(2\ above\ assuming that the support of  0.05, since the itemset includes the rare item z Formally, an itemset X is a rare itemset iff    An itemset X is a non-rare-item itemset iff       An itemset X is a rare-item itemset iff       The values of minimum rare support threshold minRareSup\d minimum frequent support threshold minFreqSup\e t according to the characteristics of the dataset  B  Maximum Constraint based Rare Pattern Tree MCRP-Tree RP-Tree algorithm is a frequent itemset mining algorithm which is a modification of the FP-Growth algorithm. It performs only one database scan for counting item support RP-Tree uses the transactions which consist of at least one rare item for building tree. In this way, transaction that doesn\222t have rare items cannot take part in RP-Tree construction. This algorithm requires minFreqSup and minRareSup in advance MCRP-Tree Algorithm shown in Algorithm 1 is the modification of RP-Tree algorithm. This algorithm accepts transactional dataset and similarly as RP-Tree, it perform only one database scan for counting support. With a prior knowledge of item\222s MIS value, this approach discovers the rare items from the dataset. MCRP-Tree select only those transactions which having at least one rare item in it. For example, if  was the rare itemset for given database then the transactions will have to contain at least one of  to avoid being pruned. At the time of tree construction, this approach takes only rare items and prunes other items from transaction. In this way, the proposed approach constructs only a rare item tree. For calculating MIS value for each item in the transaction dataset         Where is the support of item in the dataset  is the user specified lowest minimum item support allowed is used to control MIS value of ite ms according to their support Range of is 0 to 1 During insertion of items into tree, order of the item should be according to the frequency of item in original dataset and not according to the pruned tran saction dataset. It may be possible that rare items have higher support value than the frequent items. This is the reason behind not considering the support of pruned dataset. MCRP-Tree constructs conditional pattern base and conditional trees for each item existing in tree. In this way, MCRP-Tree will generate complete set of rare items   Algorithm 1. MCRP-Tree Input  Dataset  minFreqSup  Output rareItemsets  Initialization   countMIS items d countSupport items            Mining   for item i in tree  do  Build i\222s conditional pattern-base and then i\222s conditional FPTree      end for  return  rareItemsets    MCRP-Tree Example Let us consider a transactional dataset as shown in Table I A\ms  have support count 6, 6, 4, 4 2, 2, 1 and MIS values 4, 4, 3, 3, 2, 2, 3 respectively. Value of Minimum Frequent Support is set to 5 \(minFreqSup=5\n item is said to be rare if its support is less than the Minimum Frequent Support and greater than the respective MIS value of that item. So  are the rare items identified by this algorithm and are included in rareItems   


IEEE Sponsored 9th International Conference on Intelligent Systems and Control \(ISCO\2015 During the construction of MCRP-Tree, all the transactions are selected because each transaction has at least one rare item among rareItems If the transaction does not have any rare item, it cannot contribute into the construction of a tree. In addition, since the support of  is greater than minFreqSup and item fails to satisfy MIS value constraint they are ignored during construction of MCRP-Tree, as shown in Fig 2. The initial tree is constructed using RP-tree, which only ignores the items that falls below minRareSup=3, as shown in Fig 1. This RP-tree has 3 additional nodes that show frequent items as compared to the tree building using MCRPTree \(shown in Fig 2\. In addition, RP-tree does not contains  rare items as it removes the items having support less than minRareSup which is constant for each item in database MCRP-Tree builds conditional pattern bases and conditional tree to find the rare-item itemsets for each rare item   Fig  1. RP-Tree constructed from Dataset  Fig  2. MCRP-Tree constructed form Dataset IV  R ESULTS  From the literature survey we can determine that all algorithms can implemented in Java. With Brief survey experimental result for number of itemset generated and Time taken for itemset generation by ARIMA, FP-Growth and RPTree algorithm can be found. Due to the computationally expensive pruning steps and candidate generation, time taken by ARIMA is significantly greater. From the experiment we can say that runtime of ARIMA is 32 times greater than FPGrowth in all datasets. RP-Tree generated far fewer itemsets for some datasets in comparison to FP-Growth in majority of cases [9, 11, 13   MCRP-Tree is an extension of RP-Tree as it builds reduced tree with complete set of rare items and prunes all frequent nodes. With this approach we can reduce the time taken for itemset generation and can find complete set of rare items very efficiently as compared to the ARIMA, FP-Growth and RPTree algorithm. All existing algorithm spends most of the time finding rare items and as a result they identify non-rare or frequent items. For identifying complete set of rare items proposed approach provides two constraints i.e., minimum Frequent support and MIS value. Proposed approach removes the frequent items from the transactions during tree generation and builds tree with only rare items known as MCRP-Tree. As insertion of node in the tree is computationally expensive, this approach significantly reduces the execution time as compared to others With the help of literature survey we can provide tentative results that compare Time taken for Itemset generation and number of itemset generated by proposed algorithm with existing algorithm \(ARIMA, FP-Growth and RP-Tree\. We can easily estimate that proposed algorithms required less than half time for execution and generate less no of itemset   Fig  3. Number of Itemsets generated  Fig  4. Time taken for Itemset generation 


IEEE Sponsored 9th International Conference on Intelligent Systems and Control \(ISCO\2015 V  C ONCLUSION  Data mining is one of the largest and challenging areas of research with the major topic \223Association Rule Mining\224. Most association rule mining techniques concentrate on finding frequent rules. But rare association rules are sometimes more useful and interesting than frequent association rules Maximum Constraint Model is most effective model for finding rare items. However, mining rare itemset using Apriorilike approach raises performance issues. We present a new effective method for finding complete rare itemset from large database. To our knowledge, proposed MCRP-Tree algorithm is a unique method which uses tree structure with maximum constraint model to mine rare items. The MCRP-Tree algorithm will consider only the rare items while constructing the tree from the dataset. Thus, the tree which takes most of the time for insertion of node is avoided. As a result the processing time for mining complete rare items will be minimized. The effectiveness of MCRP-Tree is shown by the tentative results R EFERENCES  1  R. Agrawal, T. Imielinski,  A Swami, \223Mining association rules between sets of items in large databases\224, Proceedings of the 1993 ACM SIGMOD International Conference On Management Of Data, vol. 22, pp. 207-216, 1993 2  J. Hipp, U. Guntzer, G. Nakhaeizadeh, \223Algorithms for Association Rule Mining-A General Survey and Comparison\224 ACM SIGKDD Explorations Newsletter, vol. 2, pp. 58-64 2000 3  G. Melli, R.Z. Osmar, B. Kitts, \223Introduction to the Special Issue on Successful Real-World Data Mining Applications\224 Proceedings of the ACM SIGKDD Explorations, vol. 8, pp.1-2 2006 4  K. Sotiris, K.  Dimitris, \223Association rules mining-A recent overview\224, Proceedings of International Transactions on Computer Science and Engineering-GESTS, vol. 32, pp. 71-82 2006 5  R. Agrawal, R. Srikant, \223Fast algorithms for mining association rules in large databases\224, Proceedings of the 20th International Conference on Very Large Data Bases, pp. 487-499, 1994 6  B. Liu, W. Hsu, Y. Ma, \223Minin g association rules with multiple minimum supports\224, Pro ceedings of the fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 337-341 , 1999 7  L. Troiano, G. Scibelli, C. Birtolo, \223A Fast Algorithm for Mining Rare Itemsets\224, Proceedings of the Ninth International Conference on Intelligent Systems Design and ApplicationsIEEE, pp. 1149-1155 , 2009 8  M. Adda, L. Wu, Y. Feng, \223Rare itemset mining\224, Proceedings of the Sixth International Conference on Machine Learning and Applications, pp. 73-80, 2007 9  L. Szathmary, A. Napoli, P. Valtchev, \223Towards rare itemset mining\224, Proceedings of the 19th IEEE International Conference on Tools with Artificial Intelligence-ICTAI, vol. 1, pp. 305-312 2007 10  Y. S. Koh, N. Rountree, \223Finding Sporadic Rules Using AprioriInverse\224, Advances in Knowledge Discovery and Data MiningSpringer, vol. 3518, pp. 97-106, 2005 11  J. Han, J. Pei, Y. Yin, R. Mao, \223Mining frequent patterns without candidate generation: A frequent-pattern tree approach\224 Data Mining and Knowledge Discovery-Springer, vol. 8, pp. 5387, 2004 12  R. Uday Kiran, P. Krishna Reddy, \223An Efficient Approach to Mine Rare Association Rules Using Maximum Items\222 Support Constraints\224, Data Security and Security Data-Springer, vol 6121, pp. 84-95, 2010 13  S. Tsang, Y. S. Koh, G. Dobbie, \223Finding Interesting Rare Association Rules Using Rare Pattern Tree\224, Transactions on Large-Scale Data- and Knowledge-Centered Systems VIIISpringer, vol. 7790, pp. 157-173, 2013 14  Y. Lee, T. Hong, W. Lin, \223Mining Association Rules with Multiple Minimum Supports using Maximum Constraints\224 International Journal of Approximate Reasoning- Elsevier, vol 40, pp. 44-54, 2005 15  Y. H. Hu, Y. L. Chen, \223Mining association rules with multiple minimum supports: A new algorithm and a support tuning mechanism\224, Decision Support Systems-Elsevier, vol. 42, pp. 124, 2006 16  L. Zhou, S. Yau, \223Association Rule and Quantitative Association Rule Mining among Infrequent Items\224, Proceedings of the 8th international workshop on Multimedia data mining pp. 156\226167, 2007 17  R. Uday Kiran, P. Krishna Reddy, \223An Improved Multiple Minimum Support Based Approach to Mine Rare Association Rules\224, IEEE Symposium on Computational Intelligence and Data Mining, pp. 340-347, 2009 18  R. Uday Kiran, P. Krishna Reddy, \223An Improved Frequent Pattern-growth Approach To Discover Rare Association rules\224 Proceedings of the International Conference on Knowledge Discovery and Information Retrieval, pp. 43\22652, 2009 19  R. Uday Kiran, P. Krishna Reddy, \223Mining Rare Association Rules in the Datasets with Widely Varying Items\222 Frequencies\224 Database Systems for Advanced Applications-Springer, vol 5981, pp. 49-62, 2010 20  C.S. Kanimonzhi Selvi, A. Tamilarasi, \223Mining Association rules with Dynamic and Collective Support Thresholds\224 International Journal of Engineering and Technology, vol. 1, pp 427\226438, 2009 21  M. G. Weiss, \223Mining With Rarity: A Unifying Framework\224 ACM SIGKDD Explorations, vol. 6, pp. 7 \226 19, 2004 22  L. Szathmary, P. Valtchev, A. Napoli, \223Finding Minimal Rare Itemsets and Rare Association Rules, Knowledge Science\224 Engineering and Management-Springer, vol. 6291, pp. 16-27 2010  


E Impacted Coef\002cient of the Additional Itemset De\002nition 13 The impacted coef\002cient of an additional itemset is to describe how effective this itemset is to manufacture the derivative itemset from underlying itemset denoted as AU G 001 X j X 0   de\002ned as AU G 001 X j X 0   r C 2 001 X j X 0   W 2 001 X j X 0  2 14 This equation averages the value of C 001 X  in Equation 9 and W 001 X  in Equation 11 Here we use the Quadratic Mean QM also known as Root-Mean Square to measure the signi\002cance of the itemset 001 X in terms of both utility and relationship perspectives because it represents the sample standard deviation of the difference between W and C  thus the result cannot be affected heavily by the smaller value It is easy to prove QM 2  X    X  2  033 2  X  15 Here X and 033  X  stand for the arithmetic mean and the standard deviation of W and C  We also tried another measurement by Harmonic Mean HM as a baseline which is proven to be less effective in our experiments For a speci\002c X 0  for each itemset 001 X to be considered the higher AUG means this itemset is likely to impel the underlying itemset into higher utility itemset On the contrary the lower the AUG is the lower utility that derivative itemset might be As all the AUG would be calculated only the largest AUG value itemset will be chosen F The CUARM Algorithm In this section an algorithm named Combined UtilityAssociation Rule Mining CUARM is proposed to discover all the actionable combined utility-association rules At the beginning of the algorithm it picks all UIs as candidates For each UI all the combined patterns are discovered with their AUGs which form a combined pattern cluster as in Equation 2 and only the most effective pattern would be selected In addition if two patterns are coupled with utility increment and decrement a combined pattern pair forms The input is the transaction database including all transactions with the utility of each item and the output is the combined pattern pairs their underlying itemset and the corresponding utilities In line 1 we prepare all the itemsets with their utilities in the alphabetical order and the length of longest itemset In lines 2-5 we start with each of the UIs named itemset 0 with its utility U 0  In lines 6-11 the DIs are ready and we calculate their AUGs In line 12-13 we select the pattern with max AUG values as CUAR V E XPERIMENTS In this section we conduct intensive experiments to evaluate the proposed methods Our experiments were run on a PC with a 2.30 GHz Intel Core 16 gigabyte memory CUARM is implemented in Java Two real datasets and two synthetic datasets are used for the experiments The real Algorithm 1 CUARM Input  Transaction database D  including the utility U  X  of each item in D Output  All actionable combined utility-association rules 1 Get all itemsets utilities via UG-Tree  2 Get the length of longest itemset lmax  3 for len  1 len  lmax len do 4 for Itemset whose length is equal to len do 5 Get itemset 0 with U 0 itemset-utility 6 for itemset.length  len do 7 Check inclusive and utility changes 8 Get itemset 1 with U 1  9 Calculate C 10 Scan the database get W 11 Calculate AUG 12 Selected max one 13 Present this utility-association rule TABLE VIII C HARACTERISTICS OF DATASETS Dataset Number of Transactions Number of Items Average Length Retail 2 88162 16470 10.3 Chainstore 3 1112949 46086 7.3 t20i6d100k 100000 658 13.7 c20d10k 10000 187 13 datasets are Retail 2 and Chainstore 3  and the synthetic datasets are t20i6d100k and c20d10k  The parameters of the datasets are listed in Table VIII A Comparison of Two Functions for Calculating Impacted Coef\002cient Here we propose two functions for calculating the impacted coef\002cient One is the quadratic mean QM which is adopted in this paper the other function is the harmonic mean HM which is proved to be less accurate in the experiments Those itemsets with a good coef\002cient measurement should be associated with both high frequency and high utility growth we thus can separate the database randomly If the output itemsets discovered in each sub-database are stable we can assume that this measurement is suitable The experiments were conducted on the Retail dataset for the sake of simply examining the QM function The top 100 experimental results are selected and shown in Fig 4 The 002gure on the left shows the comparison between UP-Growth and QM while the 002gure on the right shows the result of QM and HM on C 001 X  and W 001 X   The database is split into 10 parts randomly The 002rst part contains 10 transactions in the database and each later part contains 10 more transactions than the former part such that the second part contains 20 and the last part is 100 The X axis is the k th  1 024 k 024 10  part of the database and the Y axis is the match ratio which means the ratio of the exact patterns found in the k th part 2 http://www.philippe-fournier-viger.com/spmf/index.php?link=datasets.php 3 http://cucis.ece.northwestern.edu/projects/DMS/MineBench.html 


Fig 4 The Comparison of HM QM and UP-Growth matching with the  k  1 th part As seen from the 002gures the QM method outperforms both HM and UP-Growth B Experimental Evaluation of CUARM Next we present the experimental results of comparing derivative itemsets with the traditional HUIs FIs and UIs Underlying Itemsets respectively The statistic values of each dataset are shown in Table VIII The experiment is conducted as follows Firstly we collect all the utility itemsets with their utilities and frequencies in each dataset respectively Secondly we also collect all the frequent itemsets with their frequency and utility Then we calculate the utilities of the frequent itemsets frequencies of the HUIs and both utilities and frequencies of the derivative itemsets At last we plot the frequency of itemsets discovered via UP-Growth and CUARM the utility of itemsets discovered by FP-Growth and CUARM and the utility changes from each underlying itemset to derivative itemset as shown in Fig 5 Such exhibition is made for the comparison of our algorithm with FIM and HUI to demonstrate the UtilityAssociation Rules we discovered have both high utility and high frequency Here all the frequent and utility itemsets we compare with contain at least two items because the derivative itemsets our algorithm discover contain no less than two items Experiments on Real Datasets We 002rst present the outputs of dataset Retail in Fig 5\(a and Fig 5\(b Top 50 patterns of each algorithm are selected for experiments By analyzing the frequencies and utilities of patterns many of them are without much difference in both two experiments which means the association rules we found via traditional AR algorithms are also high utility-association rules via our method In addition such rules are also with high utilities This explains why some parts of the curves overlap In addition customers prefer to buy a few products at one time that is most of FIs and HUIs contain only one or two items which also explains the observations In datasets Chainstore  the differences are much clearer because customers usually prefer a variety of products in each of transactions and high utility itemsets are always low in frequency while highly frequent itemsets are with low utility For example in Fig 5\(d the CUARM performs much better than that of FP-Growth while in Fig 5\(e even at some points the performance is not so good the global performance is much better To sum up we can assert that the performance of our algorithm CUARM is much better than the others Experiments on Synthetic Datasets Experimental results on synthetic datasets t20i6d100k and c20d10k are shown in Fig 5\(g Fig 5\(h Fig 5\(j and Fig 5\(k The results are much clearer than those from real datasets because the items included are much neat and with orderliness For most of the patterns discovered via CUARM the frequencies are much higher than those traditional high utility itemsets At the same time most Utility-associated rules are also with much higher i.e twice the utility than traditional association rules especially in Fig 5\(h from dataset t20i6d100k  C Evaluation of the Utility Increment We demonstrate the utility increment in a graphic way to show how the utility increases from underlying itemset to derivative itemset The utility increment is valued based on the same datasets as above points are ordered by the utility of derivative itemsets The performance of our algorithm varies from one dataset to another The performance in chainstore is much better than that in retail because the transaction time in chainstore is 12 times more than that in retail while the item types are only twice more However in the synthetic datasets the performance is better In conclusion for each dataset the performance is different but the utility actually increases D Utility Variation Experiments Conclusion Based on the above datasets and experimental results a table is used to demonstrate the conclusion that comes from our experiments and shown as Table IX This table describes the number of itemsets whose utilities are increase or decrease with given threshold Also two kinds of utility incremental forms are listed One is the utility of derivative itemset is higher than both the utilities of underlying itemset and additional itemset which is denoted as FA the other is that the utility of derivative itemset is higher than only the utility of underlying itemset which is denoted as FB As for each underlying itemset only one derivative itemset would be discovered some FA and FB might be ignored For the utility decrement itemsets whose utilities are only lower than the underlying itemsets would not be considered in this table because these itemsets can also be regarded as FBs when the underlying itemsets and additional itemsets exchange TABLE IX U TILITY V ARIATION C ONCLUSION Dataset Min Sup N.DI R.U N.FA N.FB N.DecI Retail 0.01 89 20.3 50.4 28 22 39 0.008 135 18.6 50.4 37 46 52 0.002 1667 8.4 50.4 473 769 425 Chainstore 0.002 79 4.6 207.2 7 19 53 t20i6d100k 0.017 33 25.7 78.5 8 11 14 0.015 79 22.8 78.5 24 19 36 0.012 383 1.8 78.5 112 137 134 c20d10k 0.05 120 19.7 150.9 28 48 44 In Table IX M in Sup in the minimum support for mining itemsets N:DI is the number of derivative itemsets discovered 


figures1//retail_f-eps-converted-to.pdf a retail figures1//retail_u-eps-converted-to.pdf b retail figures1//retail_i-eps-converted-to.pdf c retail figures1//ds7_f-eps-converted-to.pdf d chainstore figures1//ds7_u-eps-converted-to.pdf e chainstore figures1//ds7_i-eps-converted-to.pdf f chainstore figures1//t20i6d100k_f-eps-converted-to.pdf g t20i6d100k figures1//t20i6d100k_u-eps-converted-to.pdf h t20i6d100k figures1//t20i6d100k_i-eps-converted-to.pdf i t20i6d100k figures1//c20d10k_f-eps-converted-to.pdf j c20d10k figures1//c20d10k_u-eps-converted-to.pdf k c20d10k figures1//c20d10k_i-eps-converted-to.pdf l c20d10k Fig 5 Experiments for FP UP and CUARM with the threshold M in Sup  R:U in the utility incremental rate from underlying itemset to derivative itemset N:F A is the number of FA itemsets N:F B is the number of FB itemsets and N:DecI is the number of decremental itemsets VI C ONCLUSIONS AND F UTURE W ORK Traditional high utility itemset mining methods have the weak point that if the minimum utility threshold is set too high the itemsets discovered might contain unrepresentative items while if the threshold is set too low too many redundant itemsets will be found On the other hand traditional association rule mining ignores the utility hidden among the items This work proposes a novel pattern select method from two aspects One is the co-occurrence of two underlying and additional itemsets another is the utility increment from underlying itemset to derivative itemset It is an effective approach for identifying actionable combined utility itemsets in which for different items only one itemset will be selected with the highest association-utility growth which caters for both high association and high utility Thus only the most effectively impacted itemsets will be presented The results demonstrate that our method can discover patterns that are composed of different item combinations of both utility increment and high representativeness For the future work we may 002nd some more interesting pattern selection method For example there exists a dependent relationship between two itemsets A and B which means A might appear frequently alone or with other items but for most time B appears together with A VII A CKNOWLEDGMENTS This work is sponsored in part by Australian Research Council Discovery Grant P130102691 R EFERENCES  R Agra w al R Srikant 1994 F ast Algorithms for Mining Association Rules in Proc of the 20th Int'l Conf on Very Large Data Bases pp.487-499 Santiago Chile  C.F  Ahmed S.K T anbeer  B.-S Jeong and Y K Lee 2009 Ef 002cient Tree Structures for High utility Pattern Mining in Incremental Databases in Proc of IEEE Transactions on Knowledge and Data Engineering Vol 21 Issue 12 pp 1708-1721  L Cao Y  Zhao C Zhang 2008 Mining Impact-T ar geted Acti vity Patterns in Imbalanced Data IEEE Trans on Knowledge and Data Engineering 20\(8 1053-1066  L Cao P  S Y u C Zhang and Y  Zhao 2010 Domain Dri v en Data Mining Springer  L Cao 2013 Combined mining Analyzing object and pattern relations for discovering and constructing complex yet actionable patterns Wiley Interdisc Rew Data Mining and Knowledge Discovery 3\(2 140-155  J Han J Pei and Y  Y in 2000 Mining Frequent P atterns without Candidate Generation in Proc of the ACM-SIGMOD Int'l Conf on Management of Data pp 1-12 Dallas TX USA  J Han H Cheng D Xin and X Y an 2007 Frequent P attern Mining Current Status and Future Directions DMKD 15 55-86  M S Khan M Muyeba and F  Coenen 2008  A W eighted Utility Framework for Mining Association Rules in Proc of the Second UKSIM European Symposium on Computer Modeling and Simulation pp 87-92  X Lin Q Zhu F  Li Z Geng and S Shi 2010 S Share Strate gy for Utility Frequent Patterns Mining in Proc of the Seventh International Conference on Fuzzy Systems and Knowledge Discovery pp 14281432 Yantai China  J Liu K W ang and B C M Fung 2012 Direct Disco v ery of High Utility Itemsets without Candidate Generation in Proc of the IEEE Int'l Conf on Data Mining ICDM  M Liu and J Qu 2012 Mining High Utility Itemsets without Candidate Generation in Proc Of the ACM Int'l Conf on Information and Knowledge Management CIKM pp 55-64 


 Y  Liu W  Liao and A C houdhary  2005  A T w o-Phase Algorithm for Fast Discovery of High Utility Itemsets in Proc of PAKDD pp 689-695  S Shankar  T  Purusothaman S Kannimuthu and P  K V ishnu 2010 A Novel Utility and Frequency Based Itemset Mining Approach for Improving CRM in Retain Business International Journal of Computer Applications Volume 1 No 18 pp 87-94  V  S Tseng C.-W  W u B.-E Shie and P  S Y u 2010 UP-Gro wth An Ef\002cient Algorithm for High Utility Itemset Mining in Proc of Int'l Conf on ACM-SIGMOD pp.253-262  B V o B Le and J Jung 2012  A T ree-Based Approach for Mining Frequent Weighted Utility Itemsets in Proc of ICCCI 2012 Part I LNAI 7653 pp 114-123  C W u Y  Lin P  S Y u and V  S Tseng 2013 Mining High Utility Episodes in Complex Event Sequences in Proc of ACM SIGKDD International Conference on Knowledge Discovery and Data Mining KDD pp 536-544  C W u P  Philippe P  S Y u and V  S Tseng 2011 Ef 002cient Mining of a Concise and Lossless Representation of High Utility Itemsets in Proc of IEEE Int'l Conf on Data Mining ICDM pp.824-833  C W u B Shie V  S Tseng and P  S Y u 2012 Mining top-K high utility itemsets in Proc of ACM SIGKDD International Conference on Knowledge Discovery and Data Mining KDD pp 78-86  H Y ao H J Hamilt on and C J Butz 2004  A foundati onal approach to mining itemset utilities from databases in Proc of the 4th SIAM Int'l Conf on Data Mining Florida USA  J S Y eh Y  Li and C Cheng 2007 T w o-Phase Algorithms for a Novel Utility-Frequent Mining Model in Proc of PAKDD Workshop LNAI 4819 pp 433-444  J Y in Z Zheng and L Cao 2012 USpan An Ef 002cient Algorithm for Mining High Utility Sequential Patterns in Proc of ACM SIGKDD International Conference on Knowledge Discovery and Data Mining KDD pp 660-668  H Zhang et al 2008 Combined Association Rules Mining in Proc of PAKDD08 pp.1069-1074  Q Zhao and S Bho wmick 2003  Association Rules Mining a Surv e y Journal of Nanyang Technological University 2003116  Y  Zhao et al 2007 Mining for Combined Association Rules on Multiple Datasets in Proc of the KDD 2007 Workshop on Domain Driven Data Mining San Jose CA USA pp 18-23 



Towards a Classification of Information Logistics Scenarios An Exploratory Analysis   Gerrit Lahrmann Institute of Information Management University of St. Gallen, Switzerland gerrit.lahrmann@unisg.ch  Florian Stroh Institute of Information Management University of St. Gallen, Switzerland florian.stroh@unisg.ch   
 Abstract  This study identifies typical scenario patterns in information logistics and explores the impact of a broad context of factors such as strategy, organization, processes, and systems on the shaping of those patterns. Based on an empirical investigation, the current state of information logistics is analyzed. The results reveal three common information logistics scenarios: \(S1\alanced, \(S2\andard biased and S3\ality and strategy biased. Each scenario is analyzed by taking into account different factors. The four predominant factors identified in this study are F1\entralization and process integration, \(F2 Quality, \(F3\ardization, and \(F4\histication of strategy. It is important to understand which 
information logistics scenarios exist and how these are shaped. This knowledge is necessary to systematically adapt methods and conceptual models for information logistics design to specific situations 1. Introduction Over the last decades, analytical information systems and technologies like business intelligence \(BI data warehousing \(DWH\r Management Support Systems \(MSS\ have become of vital importance to enterprises A f ter copin g  w i t h t h e adoption   companies are faced with operations and ongoing development of these systems today. However, acti 
vities and projects in this domain still lack a holistic perspective as well as long-term planning and budgeting a tech nic a l v i e w con c epts an d technologies like DWH or BI allow systematic and cross-functional consolidation and use of information  o r m all y  h a v e co m p arat iv el y  s m all num bers of users, usually on various management levels   The combination of these concepts, covering business related aspects across all hierarchy levels, is addressed by the paradigm of information logistics 
 IL\o ensure sustainable business value of analytical systems T h e t e rm  information logistics has been used synonymously for DWH, BI or MSS by a few authors in the past th is paper w e  consider information logistics as planning, execution, and control of data flows within or between organizations f o r m ation is accoun ted as e n riched, integrated and aggregated data for analysis and decision support purposes in contrast to purely 
transactional data flow In the past, a variety of design research artifacts has been presented in information systems research including models and methods covering both technical and business aspects [22, 32 It is n o table  that most of these artifacts are relatively generic and do not differentiate enterprise specific needs. Recently, concepts in design research have evolved which tend to enhance generic problem solving approaches such as adaptable conceptual models itu ational method engineering  m e a n s of th e s e  approaches, existing artifacts in the domain of IL can 
be refined to ensure that a model or method fits best to problem-specific application requirements. The construction of these artifacts might be rather complex, as the application environments are often not well known. Therefore the identification of application situations with different characteristics, referred to as scenarios in the following, can help to systematize the construction and application of artifacts. Scenarios can be considered as specifications of plausible alternative application requirements which specifically highlight the situation specific opportunities and risks  
In the context of IL, a scenario represents the present situation of an enterprise regarding its IL environment as well as its potential future shape, as the usage of the term scenario often deals with alternative future environments  T h eref ore, th e obj ective of this study is to increase our knowledge about IL by taking a scenario-based approach. Specifically we seek to answer the following questions Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 1 978-0-7695-3450-3/09 $25.00 © 2009 IEEE 
 


1  What are the predominant factors that influence IL scenarios 2  Based on these factors, which IL scenarios can be identified in organizations  In order to address these questions, this paper proceeds as follows. In the next paragraph, this article first explicates the concepts of IL, adaptable artifacts in design research, and IL as a comprehensive concept of decision support. Then, an empirical investigation for identifying factors as well as enterprise scenarios using data collected from an exploratory field survey among 39 participants is described Following that, an in-depth analysis of three IL scenarios is provided. After discussing theoretical and practical implications, the article concludes with a short summary and gives an outlook on future research 2. Research framework 2.1 Information logistics As mentioned earlier, IL addresses several aspects which go beyond classical concepts and technologies in the domain of analytical systems. IL delimitates its scope on non-transactional data flows which are relevant for decision support. These data flows can occur between various objects, ranging from jobs - as organizational units with smallest granularity - to entire companies \(cf. figure 1   Data flows relevant for information logistics Company A Company B Business Unit A Business Unit B Department A Department B Job A Job B   Figure 1: Cross-unit data flow  By means of these cross-unit data flows, synergy potentials might be realized if the output of one organizational unit can be used as intermediate input for another or if organizational units bundle their competences and thereby reduce costs and create added value  On e of IL s main characteristics its infrastructure character which covers a broad range of aspects such as architecture management metadata management, data quality management, or organizational structure issues is an enabler to realize these synergy potentials. In order to address infrastructural aspects, several generic artifacts such as models or methods have been developed, whereas their generic character has led - as already mentioned to a need for adaptation before deployment 2.2 Examples of adaptable artifacts in design research As stated above, models as artifacts in design research have recently been discussed in the literature in terms of configuring and adapting them to problem-specific application requirements h rou g h  their formalized way of description, conceptual models tend to reduce complexity of the construction of information systems [11 As th e y  w e re in i tiall y s u p posed to be general and recommendatory, it became clear that their generic character could be enhanced by adding adaptation mechanisms reg a rd to IL, this implies adapting existing IL specific models to the IL scenarios as identified and presented in paragraph 3 Similarly to conceptual models, in recent years the construction of situational methods situational method engineering as emerged in design research to cover problem-specific application requirements 4, 25 To ov ercom e th e s h o r tcom ing s of  one-sizefits-all approaches, similar mechanisms as used in the domain of conceptual modeling are applied, e.g aggregation, configuration, or analogy construction  T h e ou tco m e is a con f i g u r able an d adaptable method which can be customized to specific scenarios 2.3 Information logistics as a comprehensive concept of decision support According to the definition given above, IL deals with data flows that are used for decision support. It differs from traditional concepts like DWH or BI in its comprehensive focus on strategy, organization and information systems, as well as in its inclusion of inter-organizational information exchange. Thus, for analyzing and identifying different scenarios, the discriminatory enterprise-wide approach of IL requires a comprehensive analysis. It includes a broad context of strategy, business processes, organizational structures, technology, and infrastructu information systems research, a considerable body of literature on layer models including these viewpoints can be found [34, 37  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 2 
 


Consequently, in this study, IL is analyzed in its entirety, including the following commonly used layers   Business architecture \(business strategy   Process architecture \(organization   Integration architecture \(integration of information systems in the relevant enterprise context      Software architecture \(e.g. software services data structures   Technology \(or infrastructure\itecture \(e.g hardware and networks  IL supports decisions at any hierarchy level within companies, from the strategic to tactical levels  d th eref ore a f f ects t h e bu s i n e s s arch i t ectu re as  well as the process architecture. In addition, by means of cross-functional horizontal integration of information, IL also focuses on layers covering the integration as well as software architecture. All of these layers have been addressed in the survey and have been utilized for structuring the questionnaire as stated below 3. Empirical investigation 3.1. Research design By means of an exploratory analysis we investigate the status quo of IL in practice. In order to elucidate the predominant factors of IL, data is examined by factor analysis. The factor scores of this precedent factor analysis are used as input values for clustering in order to determine IL scenarios Among other purposes, factor analytic methods are used to develop theory regarding the nature of constructs and to summarize relationships in the form of a more parsimonious set of factor scores that can then be used in subsequent analyses  w o discrete classes of factor analysis, namely exploratory factor analysis \(EFA\nd confirmatory factor analysis \(CFA\stinguis Wh i l e i n E F A  the researcher may not have any specific expectations regarding the number of underlying factors, in CFA the researcher is required to have a firm a priori sense, based on past evidence and theory, of the number of factors that exist in the data, of which indicators are related to which factors, and so forth   s th e article at h a n d is of ex ploratory  n atu re  EFA is used as factor analytic method The purpose of clustering, a form of combinatorial data analysis, is to investigate a set of objects in order to establish whether or not they fall  n to groups  of obj ects  w i t h t h e property t h at obj ects  in the same group are similar to one another and different from objects in other groups 12 t th e beginning of the investigation, these groups are unknown and need to be determined. Various clustering methods exist. They can be categorized by the type of algorithm used to obtain the clusters. Agglomerative divisive, incremental, direct optimization, and parallel algorithms can be distinguish g g l o m erative algorithms start with n clusters, each containing a single object. One by one at each step, the number of clusters is reduced. Ac g l o m erativ e  algorithms have the largest significance in practice Therefore, we utilize a clustering method which is based on an agglomerative algorithm. Concerning the selection of the clustering method it should be noted that there is usually no uniquely obvious method of analyzing the data as it is highly dependent on the selection of an appropriate clustering criterion  3.2. Data collection A questionnaire was used to collect data. The items of the questionnaire cover a broad context of topics \(cf. paragraph 2.3\he responses were scored on a five-point Likert scale. For example, one of the items asked Information needs are gathered centrally possible responses ranged from 5 \(strongly strongly disagree  Table 1. Characterization of the data set  Industry sector Less than 500 employees 500 - 1000 employees More than 1000 employees Total Manufacturing 2 3 5 Supplier   3 3 Commerce  1 1 Banking   12 12 Insurance 1 1 Software / IT 2  7 9 Others 1 1 1 3 Total 3 3 28 34  The data collection of this study started in February 2008 and concluded in May 2008. We contacted IT, business, and management personnel at an IL expert workshop held in Switzerland in March 2008 This workshop was attended by company representatives of companies of different industry sectors and size \(cf. table 1\artly, personal contacts were used in order to obtain additional questionnaires Additional communications by email and by telephone led to a total return of 39 out of 66 distributed questionnaires. This correlates to a response rate of Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 3 
 


59.1%. Because of missing values regarding one of the items presented in 3.3.1, and because of contradictory values in control questions, five questionnaires had to be excluded from analysis beforehand No company was represented by more than four questionnaires in the survey  Table 2. Results of factor analysis \(rotated component matrix  Item description Fac. 1 Fac. 2 Fac. 3 Fac. 4 IL applications are integrated into common workflows 0.799 0.160 0.079 0.084 Users make use of IL applications 0.755 0.289 0.057 0.194 Users are aware of the negative consequences of not using IL 0.656 0.192 0.236 0.158 Information needs are gathered centrally 0.644 -0.030 0.295 0.091 Information is provided centrally 0.622 -0.102 0.494 0.166 Currently used data is of high credibility 0.207 0.852 -0.041 -0.041 Data quality is high 0.387 0.819 0.047 0.027 The IL department s share of tasks related to IL systems is high 0.044 0.803 0.253 0.042 IL system quality is high 0.165 0.623 0.402 0.162 The IL system landscape is standardized 0.146 0.250 0.890 -0.009 The IL application landscape is standardized 0.408 0.021 0.787 0.103 New IL systems are realized in conformity to guidelines 0.355 0.337 0.653 -0.020 The IL strategy is devised by business users 0.012 -0.060 -0.326 0.842 The stage of maturation of the IL strategy is high 0.312 -0.098 0.077 0.826 The corporate strategy is communicated adequately 0.089 0.211 0.209 0.634 The IL strategy has a company wide scope 0.430 0.130 0.376 0.590  3.3. Data analysis 3.3.1. Factors influencing information logistics scenarios EFA \(cf. paragraph 3.1\ used as the factor analytic method to identify the predominant factors of IL cf. research question 1 in paragraph 1\s stated above, the overall goal is to find a common term embracing multiple items. As input for the factor analysis a set of 16 items has been used Prior to the EFA, the adequacy of the data set is verified by means of two criteria. Variables are suitable for factor analysis, if and only if the anti-image of the variables is as low as possible. This means that off-diagonal elements of the anti-image covariance AIC\matrix have to be as close as possible to zero  u gg es t to categ orize a c o rrelation  m a tri x as unsuitable for factor analysis, if the percentage of the off-diagonal elements unequal to zero \(> 0.09\ the AIC matrix is 25 % or more. In the data set at hand this criterion is about 15.0 %. The second criterion is the measure of sampling adequacy \(MSA\ proposed by In literatu re, th is criterion i s reg a rded as the best available method to examine the correlation ma th e pres e n t  cas e, th e MSA  is 0.702  which puts the data set at hand in the middling range  C o n c lu di n g  th e s e f i n d i n gs prov e th e g e n e ral  suitability of the data set for factor analysis Principal components and principal axes factors analyses are by far the two most commonly used factor extraction methods a h i gh er num ber of variables, principal components and principal axes factors tend to be increasingly similar [24  P r in cip al components analysis \(PCA\as some additional desirable properties, and is probably the most frequently used EFA extraction method T h eref ore, P C A is used as factor extraction method In order to ascertain the desirable number of factors, the Kaiser-Guttmann criterion and the scree test are applied. The Kaiser-Guttmann criterion u ggests that the number of factors to be extracted should equal the number of factors with eigenvalues bigger than one \(cf. figure 2\herefore, four factors explaining 69.7 % of the total variance are extracted The scree test as proposed by h o w s an elbo w at  two factors and therefore suggests the subjectively undesirable extraction of only one factor \(cf. figure 2  Factor Eigenvalue 1 5.784 2 2.370 3 1.775 4 1.227 5 0.986 6 0.831 7 0.598 8 0.579 16 0.057  0 1 2 3 4 5 6 7 012345678 9   Figure 2. Eigenvalues and Scree plot \(factors on x-axis, eigenvalues on y-axis  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 4 
 


The varimax factor rotation method with Kaiser normalization was used to clarify the nature of the underlying constructs. Varimax is the most common rotation of any kind, it is the default rotation in most statistical packages, and in about 85% of EFA applications varimax will yield a simple structur Table 2 summarizes the results of the EFA. Items are assigned to a factor if the factor loading adds up to at least 0.5 [1  The four factors consist of three to five items. The composition of the factors leads to the following description of the predominant factors of IL Factor 1 Centralization and process integration  The first factor is made up of five items which relate to process integration and centralization of information provision. Organizations scoring high on centralized process integration can be distinguished by high integration of IL applications into common workflows, high usage of IL applications by endusers, a high user awareness of the negative consequences of not using IL, and the centralized gathering and fulfillment of information needs Factor 2 Quality  Four items constitute the second factor. These items all describe aspects of quality in IL. According to our findings, an organization can achieve high quality in IL if the credibility of currently used data is high, the data quality \(i.e timeliness, integrity, consistency, transparency [30   is high, the IL department s share of tasks related to IL systems is high, and the IL system quality \(i.e performance, flexibility, availability, security  high Factor 3 Standardization  Three items were found to contribute significantly to the formation of the third factor. All three items relate to aspects of standardization of elements of the application and system layers of enterprise architectur T h e current situation is addressed by the IL systems and IL application landscape s degree of standardization while the future development is targeted by the realization of new IL systems in conformity to guidelines Factor 4 Sophistication of strategy  The fourth factor covers aspects of strategy. Both corporate strategy and IL strategy impact this factor. Companies score high on sophisticated strategy if the IL strategy is devised by business users, if the stage of maturation of the IL strategy is high, if the corporate strategy is communicated adequately in a comprehensible way, and if the IL strategy has an enterprise wide scope   3.3.2. Information logistics scenarios In order to identify IL scenarios in organizations cf. research question 2 in paragraph 1\uster analysis is used. In preparation for the cluster analysis factor scores were calculated using the regression meth   As motivated above, we utilize a clustering method which is based on an agglomerative algorithm The Ward method is used for clustering, as it finds very good partitions and reveals the appropriate number of clusters with a similar number of observations in each cluster at the same time Ward s method starts with individual cases each forming a separate cluster and progresses by combining them into clusters until each and every case is in the same cluster. The decision which clusters to merge next is based on minimizing the sum of the squared Euclidean distance of each case from the mean of its cluster. Other clustering algorithms and distance measures were also tested, but the Ward method in combination with the squared Euclidean distance produced the best results in terms of interpretability, context, and purpose of the study at hand      Figure 3. Results of cluster analysis \(dendrogram  Tree diagrams are generally used to summarize hierarchical classifications. The tree is referred to as a dendrogram, if a height is associated with each internal node of th h e den d rog ra m repres e n t s the clustering process graphically, and supports the determination of the number of clusters to be identified. Interpreting figure 3, the definition of three clusters seems to be the most appropriate solution. These three clusters represent three different IL scenarios In table 3, the arithmetic means and the standard deviations of the factor scores for each cluster are listed  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 5 
 


Table 3. Results of cluster analysis \(arithmetic means and standard deviations of factor scores for each cluster    Factor 1 Factor 2 Factor 3 Factor 4  x s x s x s x S Cluster 1 n = 15 0.50 0.72 0.56 0.56 0.48 0.51 0.23 1.06 Cluster 2 n = 10 0.39 1.32 -0.97 1.11 0.42 0.92 -0.43 0.89 Cluster 3 n = 9 0.40 0.64 0.15 0.64 -1.26 0.53 0.09 0.96 x = arithmetic mean s = standard deviation  The values and the combinations of the mean factor scores of the clusters in combination with the preceding description of the factors of IL lead to a graphical representation of the IL scenarios as depicted in figure 4  Centralization and process integration Quality in information logistics Standardization of applications and systems Sophistication of strategy Cluster 1 Cluster 2 Cluster 3    Figure 4. Graphical cluster interpretation   Concluding, the following descriptive statements regarding the design of IL scenarios can be deducted Cluster 1 Balanced  The first cluster scores highest on each single factor. The 15 organizations assigned to this cluster have a highly centralized process integration of IL, a generally high quality in IL, standardized applications and systems, and a highly sophisticated strategic orientation in common Cluster 2 Standard biased  Cluster two scores quite high on factor three, low on factors one and four, and very low on factor two. It consists of 10 organizations. The implementation and enforcement of standards is almost as high as in cluster one. Centralization and process integration of IL, i.e., the organizational embedding of IL, and the advancement in strategic concerns are rather low Cluster 3 Quality and strategy biased  Cluster three includes 9 cases. Cluster three has medium scores on factors two and four, a low score on factor one, but a very low score on factor three. The quality of IL and the sophistication of strategy are in the middling range. Similarly to cluster two, centralization and process integration of IL are rather low Based on the used data set no conclusions regarding any industry dependencies could be made. Reasons for this might be the comparatively small size of the data set and the predominance of the banking sector in the survey \(cf. paragraph 6\rthermore no preferred ordering of the clusters can be deduced from the data 4. Discussion In order to distinguish the clusters, their relations in correspondence to the different factors are visualized in figure 5. To illustrate the values of the four factors of each scenario in a two-dimensional coordinate system, every scenario is represented by two value pairs. The x-axis stands for the values of the factors Centralization and process integration and Standardization the y-axis values comprise the factors Quality and Sophistication of strategy  The clusters are arranged by their arithmetic means As the clusters are disjunctive per se, a composition of the value pairs with the best possible visualization was chosen. This non-overlapping visualization of the three scenarios \(denoted by the grey clusterframe\supports the perception that they differ significantly from each other  1 0.5 0 0.5 1 1 0.5 0 0.5 1  Scenario 1  Balanced Scenario 2 Standard biased Scenario 3  Quality and strategy biased x = Centralization and process integration  / y = Quality in information logistics x = Standardization of applications and systems  /  y = Sophistication of strategy  Figure 5. IL scenarios 4.1. Interpretation Concluding, this leads to the following interpretation for the application of design research artifacts like adaptive models and methods in the context of the three scenarios Scenario 1 Balanced  This scenario can be characterized by its high scoring in all identified factors. Consequently, artifacts utilized in enterprises of the first scenario need to comply meticulously with quality requirements, standards, and guidelines, as these enterprises excel in high standardization and quality in IL. In addition, due to the high process Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 
 


integration of IL, changes imposed by IL methods and models do have a huge impact on the overall business. The number of users getting in touch with IL daily is comparatively high. This has to be taken into account as errors in a method or model can affect a large user base. Furthermore, the application of design research artifacts needs to be aligned with the strategy, so that strategic goals are supported and enforced Scenario 2 Standard biased  Enterprises of the second scenario can be characterized by a bias on standards, while the sophisticated strategy and the centralized process integration are in the middling range. Huge deficits in various quality issues exist This implies that a\ the implementation of artifacts should be fostered to accomplish more systematic and formalized IL activities and b\ese artifacts should explicitly address the quality problems within these enterprises Scenario 3 Quality and strategy biased  Considering the third scenario, the bias on quality and strategy and the lack of implemented IL standards is especially noticeable. This leads to an intensified need for the application of methods that can ensure a systematic and comprehensible approach. Models that are deployed company-wide could be helpful to promote the establishment of standards Concerning the derivation of these interpretative statements and the stated areas of improvement, it should be noted that these are not shown as a result of the analysis, but are purely recommendatory 4.2. Examples of use In general, our approach enables the development of new artifacts which explicitly address scenariospecific properties. Furthermore, existing artifacts could be adapted in accordance to our three scenarios. In the following, two possible examples of use of our findings in the later case \(adaptation of existing artifacts\ are shown The construction of situational methods situational method engineering has emerged in design research to cover problem-specific application requiremen Si m ilar m ech a n i s m s as us ed in the domain of conceptual modeling are applied, e.g aggregation, configuration, or analogy construction  T h e ou tco m e is a con f i g u r able an d adaptable method which can be customized to specific scenarios. In m e th od f o r de m a n d d riv e n  inf o r m at ion requirements analysis in data warehousing projects is presented. When adopted in enterprises of scenario 1 the high degree of centralized process integration might lead to far-ranging consequences. Among others, activities of the method include the identification of targeted users and the homogenization of information requirements \(cf. figure 6\s scenario 1 can be characterized by the integration of IL into common workflows, the targeted user base will be rather large Therefore, the task of homogenizing information requirements will be very complex. Furthermore, high quality requirements, a high degree of standardization, and a rather sophisticated strategy might add to complexity. Thus, high attention should be given to the harmonization of information requirements As a second example, the tool vendor Cognos developed the so called IBM Cognos Performance Blueprints h es e blu e prin t s are pre-configured solution building blocks that pool collective best practice knowledge  h e y are des i gn ed e.g  to  enable companies to coordinate operational planning to make better resource allocations, and to streamline project implementation schedules. Various functionally specialized performance blueprints exist, for example on the topic of financial management and control the blueprints Close, Consolidate, and Report  and Management and Financial Reporting and the blueprints Project Planning  Workforce Planning  and Expense Planning and Control on the topic of enterprise planning    Figure 6. Focused activity model of a method for the demand-driven information requirements analysis \(cf     In early 2008, the IL department of an international mail, express, logistics, and financial service provider \(MELF-SP\ to approach its IL development and operations more systematically. This decision was partly based on the findings of our analysis, which classified the business of MELF-SP s IL department as Standard biased cf. table 4     Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 
 


Table 4. Factor scores of MELF-SP  Company Centralization and process integration Quality Standardization Sophistication of strategy MELF-SP -0.04 -0.81 0.40 -1.00  On the one hand, the huge demand for IL demanded a strategically aligned approach; on the other hand, quality issues prevented further adoption of IL applications As the tool of choice to support this more systematical approach, a perfor mance blueprint was chosen. This blueprint was adapted in terms of quality metrics like filed helpdesk incidents and overall quality control \(QC\sts, and strategic aspects like portfolio management, and lifecycle, resource, and capacity planning \(cf. figure 7   IL Portfolio Management Product Lifecycle Planning Resource Planning Capacity Planning Headcount by Competency METRIC Defects and Incidents Filed Development Resource Analysis METRIC Standardization Compliance METRIC QC Costs IL / D&O   Figure 7. Adapted IL / Development and Operations solution map \(cf. [8  Both example show how scenario-specific characteristics may result in specific adaptation needs of artifacts. The adaptation of these specific artifacts might be rather complex, as the application environments are often not well known. The IL scenarios can systematically guide the construction and application of artifacts and therefore lead to better specific artifacts 5. Conclusions and future research In the study at hand, we identified typical scenarios in IL and explored the impact of strategy, organization, processes, and systems on the shaping of those scenarios. The results revealed three common IL scenarios: \(S1\ced, \(S2\dard biased and \(S3\ality and strategy biased. These scenarios are determined by four predominant factors: \(F1 Centralization and process integration, \(F2\ Quality F3\tandardization, and \(F4\ophistication of strategy Concerning the study at hand, the explorative empirical investigation with a rather small sample size should be confirmed by means of further comparative data analyses \(e.g. confirmatory factor analysis  A bigger sample would also allow investigating the influence of further items on the shaping of the scenarios, e.g., the exploration of industry dependencies The identification of any industry-specific characteristics could in turn provide an additional basis for the elaboration of situational artifacts for IL Interestingly, the absence of standards, as in scenario three, did not result in an overall low performance concerning quality and strategy. For future research, the causal dependencies of the identified factors should be investigated. For exam  showed that implementation success with organizational and project issues did have significant effects on system quality In the context of the study at hand, the identification of a similar dependency between the factors Centralization and process integration and Quality in IL would be interesting. In a next st h o w ed t h at data quality and system quality had significant relationships with perceived net benefits This leads towards the question which factors influence the quality of the supported decisions and furthermore the overall performance of the enterprise In general, our findings might support the construction and application of scenario-specific adaptable artifacts. These artifacts can enable the implementation and advancement of information logistics as a holistic, but also specialized concept. Concluding, a major research opportunity can be seen in the design, adaptation, and evaluation of situational artifacts in information logistics context. Further work needs to be done to identify these contexts. The work at hand can be seen as a viable first step 6. References 1 A lter, S A General, yet Useful Theory of Information Systems Communications of the AIS, 1999 1 3  2 A lter, S A Work System View of DSS in its Fourth Decade Decision Support Systems, 2004 38 3\: p. 319327   Becker J  C Jan i esch  a n d D  P f ei ff er  Reuse Mechanisms in Situational Method Engineering in Situational Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 
 


Method Engineering - Fundamentals and Experiences  2007. Boston: Springer  4 Brink k e m p e r S Method Engineering - Engineering of Information Systems Devel opment Methods and Tools  Information and Software Technology, 1996 38 4\ p. 275280  5 Brow n, T  A  Confirmatory Factor Analysis for Applied Research Methodology in the social sciences. 2006, New York, London: Guilford Press. XVIII, 475  6 Ca tte ll, R  B The Scree Test for the Number of Factors  Multivariate Behavioral Research, 1966 1 p. 245-276  7 Che rm a c k  T J  a nd J  W a lton, S  Scenario planning as a development and change intervention International Journal of Agile Systems and Management, 2006 1 1\: p 46-59  8 Co g n o s UL C Cognos Innovations Center for Performance Management: IBM Cognos Performance Blueprints  2006, Cognos ULC \(formerly Cognos Inc.\ an IBM Company  9 Dziuba n, C.D an d E.C Sh irk e y   When is a Correlation Matrix Appropriate for Factor Analysis Psychological Bulletin, 1974 81 6\: p. 358-361  10  Fa he y a nd R a nda ll Learning from the Future: Competitive Foresight Scenarios 1997, Hoboken, NY: Wiley  11 Fe ttk e  P   a n d P L oos  Reference Modeling for Business Systems Analysis ed. P. Fettke and P. Loos. 2007 Hershey: IGI Publishing  12 G o rd on A  D  Hierarchical Classification in Clustering and Classification P. Arabie, L.J. Hubert, and G. De Soete, Editors. 1996, World Scientific Publishing: River Edge, NJ. p. 65-121  13 G o rry  A  a nd M Sc ot t M o rt on A Framework for Management Information Systems Sloan Management Review, 1971 13 1\: p. 55-70  14 H a ir J r  J  F B. Bla c k a n d B  Ba bin   Multivariate Data Analysis 6 ed. 2006, Australia et al.: Prentice Hall  15 H a n  J  a n d M  K a m b e r  Data Mining - Concepts and Techniques 2nd edition ed. 2006, San Francisco: Morgan Kaufmann  16 Härd le, W  an d L  Sim a r Applied Multivariate Statistical Analysis 2003, Berlin: Springer  17 H e v n e r A R., e t a l   Design Science in Information Systems Research MIS Quarterly, 2004 28 1\. 75-105  18 I n m on, W  H  Building the Data Warehouse 3 ed 2002, New York: Wiley Computer Publishing  1 Kaiser H F  and K W  Dickman   Analytic Determination of Common Factors American Psychological Reports 1959 14 p. 425-430  20 K a is e r H  F  An second-generation Little Jiffy Psychometrika, 1970 35 p. 401-415  2 Krau se O an d K M e rti n s  Performance Management  in Global Production Management O. Krause, K. Mertins and B. Schallock, Editors. 1999, Kluwer Academics Publishers. p. 243-251  22 L a ha A   RAP: a conceptual business intelligence framework in Proceedings of the 1st Bangalore annual Compute conference 2008. New York, NY, USA: ACM  23 L a ud on K  C  a n d J  P. L a udo n Management Information Systems: Managing the Digital Firm 10 ed. 2006 Upper Saddle River: Prentice Hall  2 Ogasawara H   Some Relationships between Factors and Components Psychometrika, 2000 65 2\: p. 167-185  25 Raly té, J. an d C Ro l l an d   An Approach for Method Reengineering in Conceptual Modeling - ER 2001 2001 Berlin: Springer  26 Ra m a m u rthy K A  Se n, a nd A  P  Si nha  An empirical investigation of the key determinants of data warehouse adoption Decision Support Systems, 2008 44 4\: p. 817841  27 T hom ps on B    Exploratory and Confirmatory Factor Analysis: Understanding Concepts and Applications 2004 Washington, DC: American Psychological Association  28 T i m m I.J e t a l  Flexible Mass Customization - Managing its Information Logistics Using Adaptive CoOperative Multiagent Systens in Logistics and the Digital Economy - Proceedings of the 6th International Symposium on Logistics 2001. Nottingham: University of Nottingham  2 vo m Br o c ke J   Design Principles for Reference Modeling - Reusing Information Models by Means of Aggregation, Specialization, Instantiation, and Analogy in Reference Modeling for Business Systems Analysis P. Fettke and P. Loos, Editors. 2007, Idea Group: Hershey. p. 47-75  30 W a nd Y  a n d R.Y  W a ng  Anchoring data quality dimensions in ontological foundations Communications of the ACM, 1996 39 11\95  31 W a rd J r  J  H  Hierarchical Grouping to Optimize an Objective Function Journal of the American Statistical Association, 1963 58 301\: p. 236-244  32 W a ts on H  J C  F u lle r, a n d T  A r i y a c ha ndra  Data warehouse governance: best practices at Blue Cross and Blue Shield of North Carolina Decision Support Systems 2004 38 3\: p. 435-450  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 
 


33 W i nt er R. an d B St rauch   A Method for Demanddriven Information Requirements Analysis in Data Warehousing Projects in Proceedings of the 36th Hawaii International Conference on System Sciences 2003: IEEE  34 W i nt er R. an d R Fi scher Essential Layers, Artifacts and Dependencies of Enterprise Architecture Journal of Enterprise Architecture, 2007 3 2\. 7-18  35 W i n t er R Enterprise-wide Information Logistics Conceptual Foundations, Technology Enablers, and Management Challenges in CTI 2008 2008. Croatia  36 W i x o m  B.H  a nd H  J  W a ts on An Empirical Investigation of the Factors Affecting Data Warehousing Success  MIS Quarterly, 2001 25 1\: p. 17-41  37 Za c h m a n, J  A  A Framework for Information Systems Architecture IBM Systems Journal, 1987 26 3\: p. 276292   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 
 


  Picture 6 PCS layout with virtual infrastructure and SAN  The second very important step was the installation and commissioning of a Storage Area Network SAN\, because only a network storage enables to make use of virtualization infrastructure features such as failover. This is due to the fact that virtual machine disk files may not exist on a certain host, as in case of failure it would not be accessible and available any longer to be restarted on a different physical host  SANs are either based on Fibre Channel or iSCSI Technology. The idea of both technologies is to extend the \(usually\nal data lines between hard disk controllers and hard-disks to external devices Fibre Channel has been a proven technology for this type application for years. It has a slightly better performance, but is more expensive than iSCSI iSCSI stands for Internet Small Computer System Interface It  means encapsulation  of the SCSI protocol within TCP/IP packages. Today iSCSI delivers sufficient performance to build up SANs for process automation purposes at a cement works  In such an arrangement, from a failure point of view, the SAN is the most critical peace of hardware in virtualized computer architecture  Although SANs are built up internally fail safe \(redundant power supply, NICs, hard disk controllers,\205 and data sheets give impressive figures for availability, any concept for process control purposes should allow for setting up auto-synchronizing SANs at different spots  User interface VMs running on a host are comparable to applications running on a Terminal Server. In other words, VMs obviously need input and output devices to be handled. Fat clients \(PC\222s\o good choice if it is intended to simplify the maintenance of the process control system hardware. Moreover, they are costly and sometimes prone to error Another step forward -with limited risk only- was to replace some operator stations of a segment by Thin Clients without hard disk The connection between thin client and VM is either done by vendor specific client software, RDP or VNC  Obstacles Minor issues may occur while transferring physical control systems into virtual ones Most of the problems the reference plant encountered had to do with the hardware interfaces such as serial and parallel ports and multi-media features  


Unresolved points \(minor\are to date realizing failover with legacy interfaces and sound output with Windows NT guests   CONCLUSION  Virtualization is no new but a revitalized technol ogy. First virtualization solutions \(purely based on software\ell as computer emulation deliver poor results in terms of performance  Hardware supported virtualization and pure software virtualization are totally different approaches  Virtualization today is most powerful when it combines the strengths of the different technologies. CPU demanding applications are wasting less performance than memory-intense application. \(TLB miss costs  VMware ESX is a good example of this. ESX uses Para-virtualized drivers for the most critical I/O components \(but not for the CPU\, emulation for the le ss important I/O and Binary Translation in order to avoid the high "trap and emulate" performance penalty. In this way, virtualized applications perform quite well, in some cases almost as if th ere were no extra VMM layer involved  The user benefit of virtualization is manifold. Virtualization 225  decouples software from hardware \(provides availability for \223legacy platforms\224, enables software in a cloud 225  utilizes installed hardware more efficient 225  safes space, energy, and invest cost 225  eases system administration extensively  225  but requires additional know-how of system administrators  At this point in time we can say that virtualization has met all of our expectations and offered \226in particular with respect to system administration- even more. The number of plants that started using Virtualization is growing  The process automation staff is still on a learning curve with virtualization in order to take maximum benefit of this technology  Unexploited potential is likely to be found in the field of setting up systems, handling of back-ups and disaster recovery procedures     REFERENCES  200  K. Lawton, Running muliple operating systems concurrently on an IA32 PC using virtualization techniques,http://plex86.org/research/paper.txt 200 www.codinghorror.com/blog/archives/001029.html 200 it.anandtech.com 200 en.wikipedia.org/wiki/Platform_virtualization 200  Virtualization for dummies SUN and AMD special edition 200 www.intel.com/technology/virtualizatio n/technology.htm?iid=tech_vt+tech 200  2008 Automation Summit - ID#: 1474 - Dow Chemical R&D\222s Global Rollout of PCS7\256 Using VMWare\256, Chicago    200 en.wikipedia.org/wiki/Ring_\(computer_security 


  13 edge of the aperture.  The distance of the reflected beam from the center of the aperture is then used to calculate I  which varies from about -0.8\260 to +0.8\260 in the experiment Figures 24-28 show the change r I    found by taking the difference of the center of each spectral image and subtracting from its location when I and compared the modeled values over the same range of I Figure 23 illustrates that there is some amount of random error in these measurements, but overa ll the data is grouped around r 0 pixel difference between the measured and modeled values.  The 404.7nm source shows the most variation  Figure 23 \226 The difference in pixel displacement at the detector array between measurements from modeled and collected data as a function of I     Figure 24 \226 Measured and modeled r   p  for the 404.7nm spectral line   Figure 25 \226 Measured and modeled r   p  for the 435.8nm spectral line   Figure 26 \226 Measured and modeled r   p or the 546nm spectral line   Figure 27 \226 Measured and modeled r   p  for the 577.5nm spectral line   Figure 28 \226 Measured and modeled r   p  for the 635nm spectral line   Given that the model is able to predict the displacement of energy as a result of an error in p   due to incident angle data was collected similar to that with the tilted camera to examine the effect system atic error due to unknown I  caused by a misaligned prism Here, the prism was angled in the mount in two directions to create the angles x and y  between the prism face and the normal to the optical axis as shown in Fig. 10.  The mo unt itself was tilted in two directions to create the misalignment angles x and y as shown in Fig. 12.  The magnitudes of these angles were measured by a laser as described above.  The aperture was placed such that each mm of separation at the aperture equates to 0.25\260 of angle at th e prism.  Misalignment in the instrument was used that gave values x  0.5\260 y  0.5\260 x 0.75\260 and y  0.5\260 with the instrument design again limiting the amount of error that could be imparted  The r   p  expression from Equation 17 will be compared to see how the displacement of each of the 5 wavelengths as a function of rotation angle varies given the different I  due to misalignment as the prism rotates.  The estimation in 3 2 1 0 1 2 3 4 5 6 1.0 0.5 0.0 0.5 1.0 r from model \(pixels I degrees 404.7nm 435.8nm 546nm 578nm 635nm 400 390 380 370 360 350 0 90 180 270 360 r   p pixels p degrees 404 nm, measured 404 nm, modeled 258 255 252 249 246 243 240 237 234 231 0 90 180 270 360 r   p pixels p degrees 435 nm, measured 435 nm, modeled 0 1 2 3 4 5 6 7 8 9 0 90 180 270 360 r   p pixels p degrees 546 nm, measured 546 nm, modeled 28 30 32 34 36 38 40 0 90 180 270 360 r   p pixels p degrees 578 nm, measured 578 nm, modeled 76 78 80 82 84 86 88 90 0 90 180 270 360 r   p pixels p degrees 635 nm, measured 635 nm, modeled 


  14 error for angles and is +/-0.2\260 and is incorporated into the model prediction.  Results are shown in Figures 24-29  Here, the measured data match the overall trends of the model very well, with some slight offset of about 2 pixels in each of the r   p  comparisons.  This would lead to the assumption that the estimate of x is not accurate, but is likely not the case since the mean of the model is too high in the 404nm data, and too low in the 435nm data.  This indicates that there are other errors being observed, as again it is nearly impossible to lim it the measurement to error in the intended so urce.  Also, note the decrease in impact the rotation error has as wavelength increases.  This is due to the lowered bearing P has on p as shown in the previous section.  However, the error magnitudes are a ratio of the distance from the undeviated wavelength, and in this data set are large due the large fractional error of and   4  R ESULTS  The systematic errors in a CTI instrument affect the spectral and spatial resolutions and locations in the reconstructed hyperspectral data cube in similar ways that these errors would affect the results of a traditional prism spectrograph This would be expected since the 3-D data is constructed from 2-D projection data.  The CTI becomes much more sensitive to error dependent on how the error kernel in the reconstruction behaves as a function of the prism rotation angle p and degree of freedom not in a fixed element dispersion system.  Four type s of systematic error were examined in this study; those due to tilt in the detector array  between the det ector array and the lens L 3  d   error in knowledge of the angular prism dispersion p    and error in estimation of the prism rotation angle p   s that can be inse rted into the error kernel functions were developed for each to model the effects For reasonably large array tilts of up to 3\260 and error in distance of up to 2mm, only a slightly noticeable shift of less than a pixel in spatial location was observed, mostly dependent on the tilt angle.  A more substantial spectral peak shift resulted which was due to error in distance, with a 7nm shift seen at the longer wavelengths at d  2mm.  The spatial and spectral resolu tions remained virtually unchanged, indicating that an accurate construction occurs in a shifted location The dispersion angle can be in error due to faulty estimation of prism performance.  This w ill cause an apparent shift of spectral peaks as shown in Figu re 8.  A more complicated  is the result of its dependence on the incident angle to the prism face I This is caused by mi salignment of the prism in the mount, or misalignment of the mount itself.  Mount misalignment is similar to cons tant error in estimation of p   with a shift in spectral p eaks observed.  For the AFIT CTI, this shift is only a few nm per 1\260 of misalignment Mount misalignment produces a more complex error kernel as shift and loss of resolutio n occur for relatively smaller angular errors.  More impor tantly, the spectral peaks become split into two peaks for errors of total misalignment in both the x and y directions of 1\260.  The spectral resolution may be recovered if the entire spatial area of the image is integrated.  However, simila r to splitting of peaks, the spatial distribution is a donut shape in the bin of emission  Finally, the error in projection angle p was examined though in a more obligatory fa shion since it is a relative error \(i.e. not a systematic erro r necessarily, but an error in choice of the reference coordinate system\.  There is no shifting of spectral peaks or lo ss of spectral resolution however there is a circular displacement of the spatial image again causing donut shap es for large enough   Most importantly, the error mode l was verified by collecting measured data from the AFIT CTI instrument with systematic error intentionally created in the instrument to assess the effect.  While in some cases it was apparent that sources of error other than those being investigated were influencing the results, the data did match the model for the situations where th e studied error effect was dominant usually at higher angular dispersi on, or spectral resolution Further investigation of some error may be necessary, as our CTI system design could only support a certain degree of component alteration to assess er ror.  In some cases, due to sampling of the detector array w ith respect to the size of the PSF of the system, slight changes in performance caused by error could not be resolved  4  C ONCLUSIONS  The purpose of this study wa s to assess the effect of systematic error on the reconstr ucted data sets collected by a rotating prism CTI instrument While the results are specific to the AFIT CTI desi gn, it is intended that the relative magnitude of each error and result on the reconstructed data will apply to any set of data given the general nature of the equations describing the reconstruction and error kernel that is con volved with each spectral bin  The consequence of each systematic error was quantified by the shift in spectral and/or spatial location, and degradation of spectral and/or spatial reso lution.  Table 2 summarizes the contribution of each analy zed error to these quantities   Table 2 \226The effect of systematic error.  An \223x\224 indicates an effect exists, a \223-\223 indicates no effect is observed   


  15 The model of the system allows for a quick assessment of the error, and provides a more illustrative demonstration of the prism misalignment error an d how each spectral peak is affected differently.  Figure 29 shows how the spectral peak changes as the prism mount alignment is increased in both the x and y directions for the 400nm and the 450nm spectral peaks   Figure 29 \226 The 400nm and 450nm peak shapes with varying misalignment of the prism mount   Similarly, Figure 30 represents the situation where the prism mount misalignment is constant at x  y 0.5\260 but the misalignment of the prism in the mount is changing so that a constant shape is produced, but shifted as x increases   Figure 30\226 Shifting of the 400nm spectral peak as x  increases.  The shape remains the same as the misalignment of the mount is constant   Though presented independently, the obvious contribution of the errors of the system are cumulative and must be considered in total.  Given th e great number of variations possible, this was not attempted here, but can be done based on the mathematics  This study is intended to explore the effect of systematic error for the purpose of examining sensitivity of performance when designing th e instrument.  In practice the reconstruction of collected data is done using after calibration of the instrument to directly measure r  p   without regard for the sources of error.  While this measurement can be a diagnostic of the instrument, the fact that it is well known is enough to perform acceptable reconstructions.  If instrume nt components are accessible the diagnostics be used to correct for second order error created in the instrument.  For example, errors in distance to the focal plane or tilt also result in a defocus error which cannot be easily recovered in the reconstruction algorithm R EFERENCES  1  C G r o s s, G  P. Perram an d R. F. Tu ttle, \223Mo d el i n g  infrared spectral intensity data from bomb detonations\224 Proceedings of SPIE  5881 p. 100 \(2005  2 o oney, \223A ngu l arly Mu ltip lex ed  Sp ectral Im ag er\224 Proceedings of SPIE  2480 pp. 65\22677, 1995   a ster, \223De sign and M o del Verification of an Infrared Chromotomographic Imaging System.\224 AFIT Masters Thesis, 2004  4 bb ins D  J. Go dfrey 223D ig ital x-ray tomosynthesis: current state of the art and clinical potential\224 Phys Med. Biol 48, pp. R65-R106, 2003   R.A Br oo ks an d G Di Chi r o 223Pri nci p l e s o f Com p u t er Assisted Tomography \(CAT\n Radiographic and Radioisotopic Imaging\224 Phys. Med. Biol  21 No. 5, pp 689-732, 1976  6 R.L. Bostick, G.P. Perr am, \223Hyperspectral Imaging Using Chromotomography: A Fieldable Visible Instrument for Transient Events\224 International Journal of High Speed Electronics and Systems  18 no. 3, pp. 519\226529, 2008  7 Bo stick   G  P.Perram an d R.F.Tu tt le 223Characterization of spatial and spectral resolution of a rotating prism chromotomographic hyperspectral imager\224 Proceedings of the SPIE  Next-Generation Spectroscopic Technologies II Conference, April 2009  B IOGRAPHY  Randy Bostick is a part-time PhD student at AFIT developing a metrology for a rotating prism chromotomographic imaging system.  Mr. Bostick is employed full time at the National Air and Space Intelligence Center at Wright-Patterson Air Force Base as an intelligence analyst for national remote sensing assets  


http://www.w3.org/TR/wsci 36] The World Wide Web Consortium \(W3C vice Modeling Language \(WSML http://www.w3.org/Submission/WSML 37] The World Wide Web Consortium \(W3C vice Modeling Ontology \(WSMO http://www.w3.org/Submission/WSMO 38] J. Yang and M.P. Papazoglou, ?Web Component: A Substrate for Web Service Reuse and Composition?, Proc 14th Conf. Advanced Information Systems Eng. \(CAiSE 02 LNCS 2348, pp. 21?36, Springer-Verlag, 2002 39] Y.P. Yang, Q.P. Tan, and Y. Xiao, ?Verifying Web Services Composition Based on Hierarchical Colored Petri Nets?, IHIS?05, pp. 47-53, Bremen, Germany, 2005 40] Y.P. Yang, Q.P. Tan, Y. Xiao, J.S. Yu, and F. Liu, ?Exploiting Hierarchical CP-Nets to Increase the Reliability of Web Services Workflow?, Symposium on Applications and the Internet \(SAINT?06 41] X.C. Yi and K.J. Kochut, ?Process Composition of Web Services with Complex Conversation Protocols: a Colored Petri Nets Based Approach?, Conference on Design, Analysis, and Simulation of Distributed Systems, pp.141-148, 2004 42] D. Zhovtobryukh, ?A Petri Net-based Approach for Automated Goal-Driven Web Service Composition?, SIMULATION, Vol. 83, Issue 1, pp.33-63, January 2007 43] C. Zhou, L.T. Chia, and B.S. Lee, "Web Services Discovery with DAML-QoS Ontology", International Journal of Web Services Research, vol. 2: no. 2: pp. 43-66, 2005   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


  17 Mission Phase Relevant Archit ecture Informat ion Purpose Funct ion Mat urit y Pr oduct s DODAF M odel Re f e r e nce N ot e s Preliminary System Design Integrated Risk List Cross  functional list of risks compiled across integrated product team PDR Delivery Consolidated Ri sk Li st FFP1A Operational Environment M atrix documenting how test requirements that have been levied are satisfied with test \(at both the component and system levels Identification of the method that w ill be used to verify the requirement Identification of any potential non-conformances  Initial Delivery Environmental Te st  Verification Matrix FFP7 This will show the capability of the SV to withstand various environments \(i.e. launch vehicles System Interface Control Documentation This will be a suite of documents, the mission plan s hould identify critical system boundaries that reuqire a formal interface control document M inimum Criteria:  SV - Ground and Payload to SV ICD initial drafts must be compl e t e Other pertinent ICDs:  LV - Spacecraft, Component interface ICD Initial Delivery Interface Control Documentation SV 1  SV 6 Schedule Program Driving Schedule Requirements Key schedule driven technical decisions Giver receiver relationships that span different program elements Li v i n g Document Intgrated Milestone Schedule PV2 System Sub-system Design Specifications Partial Preliminary understanding of system subsystem design Allocation of required system functions to configuration items Demonstration of how system requirements are satisfied by design Initial Delivery PDR De si gn  Presentation SV 5 Open System Trades Desription organized by susbsystem of open design trades and decsions that need to be completed Each trade should have an owner and assocaited due dates that are aligned with program constriants Li v i n g Document Trade  Decision tracking matrix FFP5 Technical Performance Measures Demonstrate design peformance to critical program requirements outlined within the requirements document Initial Delivery Technical performance budget SV 7 Values in the budget should be compared to industry standards for a given maturity in the devleopment De t ai l e d De si gn System  Design Specifications Detailed description of "to be"  system subsystem design Allocation of required system functions to configuration items Demonstration of how system requirements are satisfied by design Final Delivery CDR De si gn  Presentation SV 4  SV 5 Note: Reference Lesson 11 - Need to look at some views and diagrams that would be useful for every subsystem Integrated Risk List Cross  functional list of risks compiled across integrated product team CDR Delivery Consolidated Ri sk Li st FFP1A Operational Environment Matrix documenting how test requirements that have been levied are satisfied with test \(at both the component and system levels Identification of the method that w ill be used to verify the requirement Identification of any potential non-conformances  Final Delivery Environmental Te st  Verification Matrix FFP7 Note: previous delivery s houl d have defined how requirements would be satisfied for long lead components.  This delivery would address all remaiing compents and system levels System Interface Control Documentation This will be a suite of documents, the mission plan s hould identify critical system boundaries that reuqire a formal interface control document M inimum Criteria:  SV - Ground and Payload to SV ICD initial drafts must be compl e t e Other pertinent ICDs:  LV - Spacecraft, Component Interface ICD Final Delivery Interface Control Documentation SV 1  SV 6 Schedule Program Driving Schedule Requirements Key schedule driven technical decisions Giver receiver relationships that span different program elements CDR De l i v e r y Intgrated Milestone Schedule PV2 Integration Prodcution Plan List of all components under procurement and their expected and need dates List should include all piece parts, miscellaneous mat ls, connectors and required ground support equipment Initial Delivery Sy st e m Pa r t s  Li st  FFP6 Technical Performance Measures Demonstrate design peformance to critical program requirements outlined within the requirements document Final Delivery Technical performance budget SV 7 Values in the budget should be compared to industry standards for a given maturity in the devleopment Open System Trades Desription organized by susbsystem of open design trades and decsions that need to be completed Each trade should have an owner and assocaited due dates that are aligned with program constriants Li v i n g Document Trade  Decision tracking matrix FFP5   


 LNCRITIC 0.884 \(.005 0.362 352 0.593 053  CRPRO -0.007 \(.306 0.012 183 0.002 798  CRCON 0.010 \(.291 0.013 230 0.019 095  Model fit F p value 24.900 lt;.0001 11.110 lt;.0001 5.940 lt;.0001 Adjusted R2 0.559 0.553 0.320 p &lt; .10 p &lt; .05 Notes: p values are in parentheses  4.5. South Korean versus American market  In terms of the effect of WOM, we find no discernable difference in the motion picture markets of South Korea and the United States. Volume of WOM is positively correlated to the following week?s revenue in both markets, and valence of WOM is not significant The effect of critical reviews, however, did not concur While the literature on the American market data reports that positive critical reviews are positively related to box office revenue[21, 34], the results on the Korean market was different. There could be several reasons for this. First, South Korea and the United States have different sources for critical reviews, and the sources may have different impacts on moviegoers Second, the characteristics of critics might be different i.e., Korean critics may prefer movies that are considered less commercial or artistic than American critics  5. Conclusion  WOM and critical reviews both are important attributes that influence box office revenue in the motion picture industry. In this study, six hypotheses related to this issue were set up and tested. Data was collected on the motion picture industry of South Korea by using several websites that provide content and statistical data about movies. Finally, data on 118 movies was collected and the movies were categorized into two groups based on the distributors of the movies If the distributor of a movie was one of the major distributors in South Korea, that movie was categorized into mainstream movies, and if not then the movie was categorized into non-mainstream movies. As expected mainstream movies had much higher box office revenue and volume of WOM than non-mainstream Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 movies. In the case of the volume of critical reviews 


movies. In the case of the volume of critical reviews however, there was no big difference between mainstream and non-mainstream movies. WOM and critical reviews were usually positive H1 and H2 tested the relationship between WOM and weekly box office revenue, and the results supported the hypotheses. The volume of WOM was positively related to weekly box office revenue, while the valence of WOM had no significant effect. H3 H4a, and H4b tested the impact of critical reviews, and the results also supported the hypotheses except H4b The volume and valence of critical reviews had no consistent significances to weekly box office revenue H3 H4b. Table 7 showed that the number of critical reviews was statistically significant to aggregate box office revenue \(H4a for the attitude of critical reviews \(H4b the result more detail, an additional test was performed using only those factors related to critical reviews as independent variables. The result of the additional test supported H4, but the signs were reversed, i.e. positive critical reviews had minus signs, and negative critical reviews had plus signs. This reversed signs imply that the preference of critical reviewers is very similar to that of normal moviegoers. H5s and H6s tested the different effects of WOM and critical reviews on mainstream and non-mainstream movies. The result failed to determine that WOM give different impact on mainstream and non-mainstream movies, so H5a and H5b were rejected. H6, however, was supported, i.e the effects of critical reviews were different for mainstream and non-mainstream movies. There were no significant relationships between critical reviews and aggregate box office revenue in mainstream movies. For non-mainstream movies, however, the volume of critical reviews and the percentage of negative critical reviews were significant. Nonmainstream movies have fewer sources from which consumers can get information, and this might explain the results The above findings lead to several managerial implications. First, producers and distributors of movies could forecast weekly box office revenue by looking at previous weeks? volume of WOM. It does not matter what attitude people have when they spread WOM, the important factor is its volume. Therefore producers and distributors need to develop an appropriate strategy to manage WOM for their movies For example, the terms related to WOM marketing such as buzz and viral marketing are easily found Second, for the distributors who usually distribute less commercial and more artistic movies, and consequently have a smaller market compared to the major distributors, critical reviews can impact their movies box office revenues in a significant way. There are usually fewer sources for information for nonmainstream movies than mainstream movies, and so small efforts could leverage the outcomes. Finally, for those who are dealing with mainstream movies, the finding that the valence of WOM and critical reviews do not have significant relationship with box office revenue can have certain implications. Particularly, the attitude of critical reviews showed reversed effects Therefore, they may need to concentrate on other features rather than attitude of moviegoers or critical reviews, such as encouraging moviegoers to spread WOM This study contributes to the understanding of the motion picture industry, especially the relationship between box office revenue and WOM including critical reviews. There are existing studies that already 


critical reviews. There are existing studies that already dealt with similar issues, but this study has some differentiated features compare to prior studies. First the data used in this study was collected from South Korea, while most of the relevant studies usually focus on the North American market. This helps to provide the opportunity to understand the international market especially the Asian market, even though South Korea is a small part of it in terms of the motion picture industry. Second, movies were categorized to two groups, i.e. mainstream and non-mainstream and this study attempted to determine how WOM impacts these categories differently by testing several hypotheses In this study, there are also several limitations that could be dealt with in future research. First, using box office revenue as a dependent variable is more meaningful for distributers rather than producers. Due to there is close correlation between box office revenue and number of screens, one of producers? main concerns is how many screens their movies can be played on. Moreover, DVD sales are also important measurement for success of movies these days, and so it also could be a dependent variable. Therefore, it could be possible to give more fruitful managerial implications to various players in the motion picture industry by taking some other dependent variables Second, in this study, movies were categorized simply as mainstream and non-mainstream movies, but there could be further studies with diverse techniques of movie categorizations. For example, it would be possible to study the varying influence of WOM or critical reviews on different genres or movie budgets Third, an interesting finding of this study is that positive critical reviews could have negative relationship with box office revenue while negative critical reviews could have positive relationship. This study tried to provide a reasonable discussion on the issue, but more studies could be elaborate on it  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 References  1] Dellarocas, C., The Digitization of Word of Mouth Promise and Challenges of Online Feedback Mechanisms Management Science, 2003. 49\(10 2] Bone, P.F., Word-of-mouth effects on short-term and long-term product judgments. Journal of Business Research 1995. 32\(3 3] Swanson, S.R. and S.W. Kelley, Service recovery attributions and word-of-mouth intentions. European Journal of Marketing, 2001. 35\(1 4] Hennig-Thurau, F., et al., Electronic word-of-mouth via consumer-opinion platforms: What motivates consumers to articulate themselves on the internet? Journal of Interactive Marketing, 2004. 18\(1 5] Fong, J. and S. Burton, Electronic Word-of-Mouth: A Comparison of Stated and Revealed Behavior on Electronic Discussion Boards. Journal of Interactive Advertising, 2006 6\(2 6] Gruen, T.W., T. Osmonbekov, and A.J. Czaplewski eWOM: The impact of customer-to-customer online knowhow exchange on customer value and loyalty. Journal of Business Research, 2006. 59\(4 7] Garbarino, E. and M. Strahilevitz, Gender differences in the perceived risk of buying online and the effects of receiving a site recommendation. Journal of Business Research, 2004. 57\(7 8] Ward, J.C. and A.L. Ostrom, The Internet as information minefield: An analysis of the source and content of brand information yielded by net searches. Journal of Business Research, 2003. 56\(11 


9] Goldsmith, R.E. and D. Horowitz, Measuring Motivations for Online Opinion Seeking. Journal of Interactive Advertising, 2006. 6\(2 10] Eliashberg, J., A. Elberse, and M. Leenders, The motion picture industry: critical issues in practice, current research amp; new research directions. HBS Working Paper, 2005 11] S&amp;P, Industry surveys: Movies and home entertainment 2004 12] KNSO, Revenue of Motion Picture Industry 2004 Ministry of Culture, Sports, and Tourism, 2004 13] Duan, W., B. Gu, and A.B. Whinston, Do Online Reviews Matter? - An Empirical Investigation of Panel Data 2005, UT Austin 14] Zhang, X., C. Dellarocas, and N.F. Awad, Estimating word-of-mouth for movies: The impact of online movie reviews on box office performance, in Workshop on Information Systems and Economics \(WISE Park, MD 15] Mahajan, V., E. Muller, and R.A. Kerin, Introduction Strategy For New Products With Positive And Negative Word-Of-Mouth. Management Science, 1984. 30\(12 1389-1404 16] Moul, C.C., Measuring Word of Mouth's Impact on Theatrical Movie Admissions. Journal of Economics &amp Management Strategy, 2007. 16\(4 17] Liu, Y., Word of Mouth for Movies: Its Dynamics and Impact on Box Office Revenue. Journal of Marketing, 2006 70\(3 18] Austin, B.A., Immediate Seating: A Look at Movie Audiences. 1989, Wadsworth Publishing Company 19] Bayus, B.L., Word of Mouth: The Indirect Effects of Marketing Efforts. Journal of Advertising Research, 1985 25\(3 20] Faber, R.J., Effect of Media Advertising and Other Sources on Movie Selection. Journalism Quarterly, 1984 61\(2 21] Eliashberg, J. and S.M. Shugan, Film critics: Influencers or predictors? Journal of Marketing, 1997. 61\(2 22] Reinstein, D.A. and C.M. Snyder, The Influence Of Expert Reviews On Consumer Demand For Experience Goods: A Case Study Of Movie Critics. Journal of Industrial Economics, 2005. 53\(1 23] Gemser, G., M. Van Oostrum, and M. Leenders, The impact of film reviews on the box office performance of art house versus mainstream motion pictures. Journal of Cultural Economics, 2007. 31\(1 24] Wijnberg, N.M. and G. Gemser, Adding Value to Innovation: Impressionism and the Transformation of the Selection System in Visual Arts. Organization Science, 2000 11\(3 25] De Vany, A. and W.D. Walls, Bose-Einstein Dynamics and Adaptive Contracting in the Motion Picture Industry Economic Journal, 1996. 106\(439 26] Bagella, M. and L. Becchetti, The Determinants of Motion Picture Box Office Performance: Evidence from Movies Produced in Italy. Journal of Cultural Economics 1999. 23\(4 27] Basuroy, S., K.K. Desai, and D. Talukdar, An Empirical Investigation of Signaling in the Motion Picture Industry Journal of Marketing Research \(JMR 2 295 28] Neelamegham, R. and D. Jain, Consumer Choice Process for Experience Goods: An Econometric Model and Analysis. Journal of Marketing Research \(JMR 3 p. 373-386 29] Lovell, G., Movies and manipulation: How studios punish critics. Columbia Journalism Review, 1997. 35\(5 30] Thompson, K., Film Art: An Introduction. 2001 McGraw Hill, New York 31] Zuckerman, E.W. and T.Y. Kim, The critical trade-off identity assignment and box-office success in the feature film industry. Industrial and Corporate Change, 2003. 12\(1 


industry. Industrial and Corporate Change, 2003. 12\(1 27-67 32] KOFIC, Annual Report of Film Industry in Korea 2006 Korean Film Council, 2006 33] Sutton, S., Predicting and Explaining Intentions and Behavior: How Well Are We Doing? Journal of Applied Social Psychology, 1998. 28\(15 34] Basuroy, S., S. Chatterjee, and S.A. Ravid, How Critical Are Critical Reviews? The Box Office Effects of Film Critics Star Power, and Budgets. Journal of Marketing, 2003. 67\(4 p. 103-117  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 






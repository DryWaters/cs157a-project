MPIS Maximal-Profit Item Selection with Cross-Selling Considerations Raymond Chi-Wing Wong Ada Wai-Chee Fu Department of Computer Science and Engineering The Chinese University of Hong Kong cwwong,adafu@cse.cuhk.edu.hk Ke Wang Department of Computer Science Simon Fraser University Canada wangk@cs.sfu.ca Abstract In the literature f data mining many different algorithms for association rule mining have been proposed However there s relatively little study on how association rules can aid in more speci\336c targets In this paper one of the applications for association rules maximal-pro\336t item selection with cross selling effect MPIS problem is investigated The problem is about selecting a subset of items which can give the maximal pro\336t with the consideration of cross-selling We rove that a simple version of this problem is NP-hard We propose a ew approach o the problem with the consideration of the 
loss rule a kind of association rule to model the cross-selling effect We show that the problem can be transformed to a quadratic ramming problem In case quadratic ramming is not applicable e also propose a heuristic approach Experiments are conducted to show that both of the proposed methods are highly effective and ef\336cient 1 Introduction Recent studies in the retailing market have shown a winning edge for customer-oriented business which is based on decision making from better knowledge about the customer behaviour Furthermore the behaviour in terms of sales transactions is considered signi\223cant 6 This is als o called mark et basket analysis We consider the scenario of a supermarket or a large store typically there are a lot of different items offered and e amount of transactions can be very large For exam 
ple 11 quot ed t h e e xampl e o f A meri can s upermark et chai n Wal-Mart which keeps about 20 million sales transactions per day This growth of data requires sophisticated method in the analysis At about the same time associa tion rule mining 3 has been proposed by computer scientists which aims at understanding the relationships among items in transactions or market baskets However it is generally true that the association rules in themselves do not serve the end purpose of the business people We believe that association rules can aid in more speci\223c targets Here we investigate the application of association rule mining on the problem of market basket analysis As pointed out in 6 a m aj or t a s k of t a l e nt ed merchant s i s t o p i c k t he 
pro\223t generating items and discard the losing items It may be simple enough to sort items by their pro\223t and do the selection However by doing that we would have ignored a very important aspect in market analysis and that is the crossselling effect The cross-selling effect arises because there can be items that do not generate much pro\223t by themselves but they are the catalysts for the sales of r pro\223table items Recently some researchers 17 s ugges t that as s o ciation rules can be used in the item selection problem with the consideration of relationships among items Here we follow this line of work in what we consider as investigations of the application of data mining in the decision-making process of an 
enterprise In this paper the problem of Maximal-Pro\223t Item Selection with Cross-Selling Considerations MPIS is studied With the consideration of the cross-selling effect MPIS is the problem of 223nding a set of 000 items such that the total pro\223t from the item selection is maximized where 000 is an input parameter This problem arises naturally since a store or a company typically changes the products they carry once in a while The products that can generate the best pro\223ts should be retained and poor-pro\223t items can be removed then new items can be introduced into the stock In this way the business can follow the market needs and generate the best possible results 
for both the business and e customers n order to determine the pro\223t value of an item one can rely on expert knowledge However since this can be a highly complex issue especially for a large store with thousands of products for  we can try to apply data mining techniques based on a history of customer purchase records Hence the problem is how to determine a subset of a given set of items based on a history of transaction records so that the subset should give the best pro\223ts with considerations of the cross-selling effects We show that a simple version of his problem is NP-hard We model the cross-selling factor with a special kind of association rule called 
loss rule  The rule is of the form 001 000 000\001 002 where 001 000 is an item and 002 is a set of items and 001 002 means any items in 002  This loss rule helps to estimates the loss in pro\223t for item 001 000 if the items n 002 are missing after the selection The rule corresponds to the cross-selling effect between 001 000 and 002  To handle this problem we propose a quadratic programming method QP and a heuristics method called S 
Alg In QP we express the total pro\223t of the item selection in quadratic form and solve a quadratic optimization problem Algorithm MPIS Alg is a greedy approach which uses an estimate of the bene\336ts of the items to prune items iteratively for maximal-pro\223t From our experiment the pro\223tabilities of our two proposed algorithms are greater than that of naive approach for all data sets On average the pro\223tability of Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


both QP and MPIS Alg is 1.33 times higher than the naive approach for the synthetic data set In a real drugstore data set the best previous method HAP 26 g i v e s a p r o 223 tab ility th at is about 2.9 times smaller than MPIS Alg When the number of items is large as in the drugstore data set the execution time of HAP is 6.5 times slower than MPIS Alg These shows that the MPIS Alg is highly effective and ef\223cient 2 Problem De\336nition Maximal-pro\223t item selection MPIS is a problem of selecting a subset from a given set of items so that the estimated pro\223t of the resulting selection is maximal among all choices Our de\223nition of the problem is close to 26  G i v en a d ata set with 000 transactions 001 000 002\001 001 002\003\003\003\002\001 000 and 004 items 005 000 002\005 001 002\003\003\003\002\005 001  Let 005 000 000 005 000 002\005 001 002 003\003\002 005 001 001  The pro\223t of item 005 002 in transaction 001 003 is given by 006\007 b\t 001 005 002 002\001 003 002  1 Let n 002 005 be a set of 013 selected items In each transaction 001 003  we de\223ne two symbols 001 000 003 and f 003  for the calculation of the total pro\223t 000 000 000 000 000 000 000 001\002 003 000 000 000 000 001 000 000 000 000 000 000 set of items selected in 001 in transaction 000 000 003 000 set of items not selected in 001 in transaction 000 000 Suppose we select a subset n of items it means that some items n 005 000 002 003\003\003\002 005 001 will be eliminated The transactions 001 000 002 003\003\003\002 001 000 might not occur in exactly the same way if some items have been removed beforehand since customers may not make some purchase if they know they cannot get some of the items Therefore e pro\223t 006\007 b\t 001 005 002 002\001 003 002 can be affected if some items are removed from the stock This is caused by the cross-selling factor The cross-selling factor is modeled by r\016\t 017\r\001\b\007 001 020\002 005 002 002 where 020 is a set of items and 003 003 r\016\t r\001\b\007 001 020\002 005 002 002 003 004  r\016\t r\001\b\007 001 020\002 005 002 002  is the fraction of the pro\223t f 005 002 that will be lost in a transaction if the items in 020 are not available Note that the cross-selling factor can be determined in different ways One way is by the domain experts We may also have a way to derive this factor from the given history of transactions De\336nition 1 Total Pro\336t of Item Selection The total pro\336t of an item selection n is given by 004 000 000 001 000 000\001 000 002 000 001 003 000 001 005\006 007\b 001 t 004 002\000 000 002\001\003 001 n\013\b f\n\000\007\006 001 003 000 002\t 004 002\002 We are interested in selecting a set of 013 items so hat he total pro\223t is the maximal among all such sets MPIS  Given a set of transactions with pro\336ts assigned to each item in each transaction and the cross-selling factors r\016\t 017\r\001\b\007 001\002  pick a set n of 013 items from all given items which gives a maximum pro\336t This problem is at least as dif\223cult as the following decision problem which we call the decision problem for MPIS MPIS Decision Problem  Given a set of items and a set of transactions with pro\223ts assigned to each item in each transaction a minimum bene\223t 021  and cross-selling factors 1 This de\223nition generalizes the case where pro\223t of an item is 223xed for all transactions We note that the same item in different transactions can differ because the amount of the item purchased are different or the item can be on discount for some transactions and the pro\223t will be reduced If the pro\223t of an item is uniform over all transactions we can set 000\001 002\003 000 004 004 005\006 000 001 to be a constant over all 007  r\016\t 017\r\001\b\007 001\002  can we pick a set n of 013 items such that 022 004 021  In our proof in the ollowing we consider the very simple version where r\016\t 017\r\001\b\007 001 f 003 002\005 002 002\000\004 for any non-empty set of f 003  That is any missing item in the transaction will eliminate the pro\223t of the other items This may be a much simpli\223ed version of the problem but it is still very dif\223cult 2.1 NP-hardness Theorem 1 The maximal-pro\336t item selection MPIS decision problem where r\016\t 017\r\001\b\007 001 f 003 002\005 002 002 000 004 for f 003 005 000 023 and r\016\t 017\r\001\b\007 001 f 003 002\005 002 002\000\003 for f 003 000 023 is NP-hard Proof sketch  We shall transform the problem of CLIQUE to the MPIS problem CLIQUE 9 i s a n N P complete p roblem de\223ned as followd CLIQUE Givenagraph 024 000\001 025\002 026 002 and a positive integer 027 003\006 025 006  is there a subset 025 000 007 025 such that 006 025 000 006\004 027 and every two vertices in 025 000 are joined by an edge in E  The transformation from CLIQUE to MPIS problem is described as follows Set 013 000 027  021 000 027 001 027 b 004\002  For each vertex 030 t 025  construct an item For each edge 031 t 026  where 031 000\001 030 000 002\030 001 002  create a transaction with 2 items 000 030 000 002\030 001 001  Set 006\007 b\t 001 005 004 002\001 003 002\000\004 where 001 003 is a transaction created in the above 032 000\004 002 005 002 003\003\003\002 006 026 006 and 005 004 is an item in 001 003  It is easy to see that this transformation can be constructed in polynomial time It is also easy to verify that when the problem is solved in the transformed MPIS the original clique problem is also solved Since CLIQUE is an NP-complete problem the MPIS problem is NP-hard 3 Related Work In recent years the problem of association rule mining has received much attention We are given a set 005 of items and a set of transactions Each transaction is a subset of 005 An association rule has e form 033 n 005 004 where 033 007 005 and 005 004 t 005 the 016\034\006\006\b\007 001 of such a rule is the fraction of transactions containing all items in 033 and item 005 004  the con\223dence for the rule is the fraction of the transactions containing all items in set 033 that also contain item 005 004  The problem is to 223nd all rules with suf\223cient support and con\223dence Some of the earlier work include 22 4 1  3.1 Item Selection Related Work There are some recent works on the maximal-pro\223t item selection problem PROFSET 8 7 m o d e ls th e c r o sssellin g effects by frequent itemsets  which are sets of items cooccurring frequently A maximal frequent itemset is a frequent itemset which does not have a frequent item superset The pro\223t margins of maximal itemsets are counted in the total pro\223t The problem is formulated as 0-1 linear programming that aims to maximize the total pro\223t However PROFSET has several drawbacks as pointed out in 26 More det a i l s can be found i n 26  HAP 26 is a s o l u tio n o f a sim ilar p r o b l em  I t a p p lies th e 216hub-authority\216 pro\223t ranking approach 23 t o s ol v e t h e maximal pro\223t item-selection problem Items are considered as vertices in a graph A link from 005 003 to 005 004 represents the crossselling effect from 005 003 to 005 004  A node 005 004 is a good authority if there are many links of the form 005 003 n 005 004 with a strong Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


strength of the link The HITS algorithm 18 i s a ppl i e d a nd the items with the highest resulting authorities will be the chosen items It is shown that the result converges to the principal eigenvectors of a matrix de\223ne d in terms of the links con\223dence values and pro\223t values However HAP also has some weaknesses 1 Problems of dead ends or spider traps as illustrated in 25 can arise F o r example if there is an isolated subgraph with a cycle while other items are not connected then the authority weight and hub weight of all items in the cycle are accumulated and is increased to an extremely high value giving an over-estimating ranking for these items 2 In HAP the authority weight of an item 000 000 depends on the pro\223t of any other item 000 001 with the association rule 000 001 000 000 000  It is possible that some items with low/zero pro\223t gain very high authority weights and are selected by HAP In fact the real data set we shall use in the experiments exhibits this phenomenon and HAP cannot give a competitive solution 4 Cross selling effect by Association Rules In Section 2 we did not specify how to determine the crossselling effect 001\002\003 004\001\005\006\007 of some items for other items In previous work 26 t h e concept of as s o ci at i o n rul es i s appl i e d t o this task Here we also apply the ideas of association rules for the determination of 001\002\003 004\001\005\006\007  Let us estimate the possible pro\223t from a given set of transaction If all items are selected the pro\223t is the same as the given pro\223t Suppose we have made a selection b of t items from the set of items Now some transactions may lose pro\223ts if some items are missing Consider a transaction 005 001 in our transaction history suppose some items says 000 002  are selected in b but some items are not selected i.e n 001  Then if we have a rule that purchasing 000 002 always 216implies\216 at least one element in n 001 then it would be impossible for transaction 005 001 to exist after the selection of b since 005 001 contains 000 002 and no element in n 001 after the selection The pro\223t generated by 005 001 from 000 002 should be removed from our estimated pro\223t We can model the above rule by an association rule In fact we can model the cross-selling factor in the total pro\223t of item selection 001\002\003 004\001\005\006\007 000 n 001 013\000 002 001 by 001\006\f\003 000 000 002 000\001 n 001 001 where 001 n 001 is given by the following De\336nition 2 Let n 001 002 002 r 000 013\r 001 013\r 002 013 016\016\016\013 r 003 003 where r 001 refers o a single item for 017 002\003 013 004 013 016\013 020  then 001 n 001 002 r 000 004 r 001 004 r 002 004 016\016\016\016 004 r 003  The rule 000 002 000\001 n 001 is called a loss rule Therule 000 002 000\001 n 001 indicates that a customer who buys the item 000 002 must also buy at least one of the items n n 001  If none of the items in n 001 are available then the customer also will not purchase 000 002  Therefore the higher the con\223dence of 216 000 002 000\001 n 001 216 the more likely the pro\223t of 000 002 in 005 001 should not be counted This is the reasoning behind the above de\223nition The l pro\223t is to estimate the amount of pro\223t we would get from the set of transaction 005 000 013\016\016\016\005 004  if the set of items s reduced to the selected set b  From De\223nition 1 we have De\336nition 3 Total Pro\336t of Item Selection association rule based The association rule based total pro\336t of item selection b is given by 000 000 000 000 001 000\001 000 002 000 000 003 000 001 001\002 003\004 001 005 004 006\007 001 002\001\003 000 b\003\t\004 001 005 004 001\002 n 001 002\002 For the special cases if all items in transaction 005 001 are selected in the set b then n 001 is empty 005 001 will not be affected and so the pro\223t of transaction 005 001 would remain unchanged If no item in transaction 005 001 is selected then e customer could not have executed the transaction 005 001 then 005 000 001 is an empty set and the pro\223t of transaction 005 001 becomes zero after we have made the selection The loss rule 000 002 000\001 n 001 is treated as an association rule The con\223dence of this rule is de\223ned in a similar manner as for the association rule De\336nition 4 001\006\f\003 000 000 002 000\001 n 001 001 is computed as no of transactions containing 005 004 and any element in n 001 no of transactions containing 005 004 5 Quadratic Programming Linear programming or non-linear programming has been applied or optimization problems in many companies or businesses and has saved millions of dollars in their running 12 The problem involves a number of decision variables an objective function in terms of these variables to be maximized or minimized and a set of constraints stated as inequalities in terms of the variables In linear programming the objective function is a linear function of the variables In quadratic programming the objective function must be quadratic That means the terms in the objective function involve the square of a variable or the product of two variables If 002 is the vector of all variables a general form of such a function is 021 002 003 005 002 005 000 001 002 005 022\002 where 003 is a vector and 022 is a symmetric matrix If the variables take binary values of 0 and 1 the problem is called zero-one quadratic programming In this section we propose to tackle the problem of MPIS by means of zero-one quadratic programming We shall show that the problem can be approximated by a quadratic programming problem Let 002 002\000 002 000 002 001 016\016\016\002 006 001 005 be a binary vector representing which items are selected in the t b  002 001 002\003 if item 000 001 is selected in the output Otherwise 002 001 002\006  The total pro\223t of item selection 021 can be approximated by the quadratic form 003 005 002 005 000 001 002 005 022\002 where 003 is a vector of length f and 022 is an f by f matrix in which the entries are derived from the given transactions The objective is to maximize 003 005 002 005 000 001 002 005 022\002  subject to 000 006 001 003\000 002 001 002 t Theterm 000 006 001 003\000 002 001 002 t means that there are t items to be selected With a little overloading of the term 005 001  we say that 005 001 002 000 005 001 000 005 001 001 016\016\016\005 001\006 001 005 is a binary vector representing which items are in the transaction 005 001  005 001\000 002\003 if item 000 000 is in the transaction 005 001  Otherwise 005 001\000 002\006  Similarly 005 000 001 is a binary vector representing which items are selected in S in the transaction 005 001  n 001 is a binary vector representing which items are not selected in S in the transaction 005 001  Then we have the following For 017 002\003 013 004 013 016\016\016\013 023 and 024 002 003 013 004 013\016\016\016\013\f  005 000 001\000 002 005 001\000 005 002 000 and n 001\000 002 005 001\000 006 005 000 001\000 016 Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


000 000 number of transactions containing item 001 000 000 000\001 number of transactions containing 001 000 and 001 001 000 001 000 000 002\003\003\003\001 000\001 000 number of transactions containing 001 001 000 000 002 003\003\003\002 001 000\001 002 Observation 1 The con\336dence 000\001\002\003 000 004 000 000 001 005 001 001 can be approximated by 000 002 000 000 002 003 001\000 005 001\003 002 000\003  The above observation is based on the principle of sionexclusion in set theory To see this let us consider the numerator in De\223nition 4 and let it equal to 006 000 004 004 007\005 001 001  De\336nition 5 Let b 002 004  b 002 003 t 000 007\t 002 007 n\n\n\007 t 005 004 and 004 006 006 b  where t 001 refers o a single item for 013 002\003 007 004 007\n\n\007\f  004 000 001 002 002\005 001\002 000 000 000 000 000 003 000 001 002 006 000 000\003 000 000 000 000\004\001 000 003 000 001 002 006 000 006 001 000 003 000 000 000 000\004\001 004\005 000 003 000 001 002 006 000 006 001 006 005 000\003 003\003\003 003\000 003 004\001 006 001\000 000 001 002 006 000 006 002 003\003\003\006 003 000 where 007 004 006 t 001 t 000 n\n\n 007 is the number of transactions containing the items 004 006  t 001  t 000   We have 007\b\000\t 000 001 001 004\005 n 000 001\002 007 003 b 000 t\n 001 004 no of transactions containing item 001 001 006 005\006\007 000 001 000 000 005 000 006 001 b 000 b 002 001\002 n 001\002 no of transactions containing item 001 001 002 004 002 002\005\006\007 003 000 006 000 001 006 005 005\000 n 000\005 000 001\005 002 004 004 The reason why the above approximation is acceptable is that the number of transactions containing a set of items b is typically smaller than the number of transactions containing a subset of b  Hence 007 004 000 004 003 004 007 007 is typically much smaller than 007 004 000 004 003 007  etc From this approximation we can deduce the following theorem Theorem 2 The total pro\336t of item selection can be approximated by the quadratic form r 002 003 b 016 005 000 002 016 b 017\016 where 003 is a vector of size 002 and 017 is an 002 by 002 matrix Proof sketch  013 006 001 013 000 005\000 001 006 001 005\000 f 003 000\001 r\016 b\t 000 001 001 002\f 000 001 003 004 003 000 006 000 001 006 005 005\000 n 000\005 000 001\005 004 002 001 013 000 005\000 001 006 001 005\000 f 000\001 017 001 r\016 b\t 000 001 001 002\f 000 001 000 004 003 001 003 002 000\001 003 f 001\002 004 f 000 001\002 004 006 000\002 006 000 002 002 t r 017 003 000 002 017 r 020\017 where t 002 000 t 001 000 t 001 002 001 013 000 005\000 f 000\001 r\016 b\t 000 001 001 002\f 000 001\000\004 003 000 006 000 001 006 005 005\000 f 000\005 000 001\005 001 for 021 002\004 002 b 002 003\003\002 000 001 r 020 002 000 022 001\005 000 022 001\005 002 002 006 000\002 006 000 001 013 000 005\000 f 000\001 r\016 b\t 000 001 001 002\f 000 001 f 000\005 for 021\002 023 002\004 002 b 002 003\003\003\002 000 001 Corollary 1 P can be approximated by r 000 002 003 b 016 005 000 002 016 b 020\016 where 020 is a symmetric 002 by 002 matrix The corollary follows because 013 002 t r 017 003 000 002 017 r 020\017 002 t r 017 003 000 002 017 r 024\017 where 024 002\000 025 000\001 001 and 025 000\001 002 000 002 000 022 000\001 003 022 001\000 001 for all 026\002 021 002\004 002 b 002\003\003\003\002\000 Since the value of 016 001 is either 0 or 1 from the above corollary we have approximated the problem of MPIS by that of 0-1 quadratic programming with the maximization of r 000 and an equality constraint of 001 001 016 001 002 021  Maximize 013 003 002 t r 017 003 000 002 017 r 024\017 such that 001 006 000 005\000 017 000 002 027  and 017 000 002\t or 017 000 002\004 for 026 002\004 002 b 002 003\003\002 000 Any 0-1 quadratic programming problem is polynomially reducible to an unconstrained binary quadratic programming problem 16 An uncons t r ai ned bi nary quadrat i c programming problem can be transformed to a inary linear programming problem zero-one linear programming 5 More related properties can be found in 20 and 14   Zero-one l i n ear programming and quadratic programming are known to be NP-complete 24 Ho we v e r  t h ere e x i s t programmi ng t ool s which can typically return good results within a reasonable time for moderate problem sizes We shall apply such a tool in our experiments which will be presented in Section 7 6 Algorithm MPIS Alg Since quadratic programming is a dif\223cult problem and existing algorithms may not scale up to large data sizes we propose also a heuristical algorithm called Maximal-Pro\223t Item Selection MPIS Alg This is an iterative algorithm In each iteration we estimate a selected item set with respect to each item based on its 215neighborhood\216 in terms of cross-selling effects and hence try to estimate a pro\223t for each item that would include the cross-selling effect With the estimated pro\223t we can give a ranking for e items so that some pruning can be achieved in each iteration The possible items for selections will become more and more re\223ned with the iterations and when the possible set reaches the selection size we return it as the result There are some factors that make this algorithm desirable 1 We utilize the exact formula of the pro\223tability in the iterations This will steer the result better toward the goal of maximal pro\223ts compared to other approaches 26 t hat d o not directly use the formula 2 With the 215neighborhood\216 consideration the item pruning at each iteration usually affect only a minor portion of the set of items and hence introduce only a small amount of computation for an iteration Compared to the HAP approach where the entire cross-selling matrix is involved in each iteration our approach can be much more ef\223cient when the number of items is large Before describing the algorithm we de\223ne a few terms that we use If a transaction contains 004 003 only the transaction is an individual transaction for 004 003 The individual count 000 003  of an item 004 003 is the total number of individual transactions for 004 003  The individual count re\224ects the frequency of an item appearing without association with other items Let 022 003 be the t of transactions that contain 004 003 the average pro\336t is given by 023 003 002\000 001 t 001 000 n 002 023\024 001\003 000 004 003 007\025 001 001\001 026 007 022 003 007  De\336nition 6 We de\336ne 005 r 000 027 001 to be the estimated pro\336t assuming that the items in set 027 are selected 005 013 000 030 001\002 001 013 000 005\000 001 b 004 005 f 000 001 r\016 b\t 000 001 016 002\f 000 001\000\004 003 007\b\000\t 000 001 016 004\005 n 000 001\001 Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


The formula 000 000 000 001 001 is equal to that used in De\223nition 3 If 001 002 002 where 002 is the output selection set 000 000 000 001 001 is equal to the 223nal output estimated pro\223t 000 000 individual count of item 001 000 002 000 average pro\223ts of item 001 000 003 000 Bene\223t f item 001 000 004 000 estimation set for item 001 000 005 000\001\002 Estimated value of item 001 002 from item 001 000  005 000\001\002 000 002 002 000 000 002 001\002 002 002 001 002 000 003 000 006\007\002\002\b\t n 002 001 000 013\001 002 003 6.1 Overall Framework In the algorithm MPIS Alg there are two phases 1 Preparation Phase and 2 Main Phase  In the Preparation Phase the frequency and the individual count of each item and the size 2 itemsets are returned In the Main Phase the bene\336t of each item is evaluated Initially the result set contains all items a number of iterative steps of removing items with minimum estimated bene\223t proceeds until 003 items remains Preparation Phase 1 count the number of occurrences of each item 004 000 005\004 001 005\006\006\006\005\004 000  obtain the individual count for each item 007 000 005\007 001 005\006\006\006\005\007 000 2 generate all size 2 itemsets with their counts Main Phase 1 Estimation Set Creation In this step the estimation sets for all items 002 000 005\002 001 005 006\006\006\005 002 000 are computed For each item b 001  calculate the estimated value of item b 002 from item b 001  t 001\003\002 002 n 002 000 007 002 003 000 n 002 003 n 001 001 000 013\f\n\n\r\016 017 000 b 001 005\b 002 001 005 where 013\f\n\n\r\016 017 000 b 001 005\b 002 001 is the support of the itemset 001 b 001 005\b 002 002  Among these b 002 items choose 003 003 004 items with the highest estimated values Put these items into the estimation set 002 001 for b 001  2 Item Bene\336t Calculation determine the estimated bene\223t 020 001 of each item b 001  003 000 001 000 f 002 004 000 002\003 001 000 004 003 3 Item Selection and Item Bene\336t Update Let 004 000 be the set of items that has not been pruned a prune an item b 004 with a smallest bene\223t 020 004 value among the items in 004 000 b for each remaining item b 001 in 004 000  If b 004 is in 002 001  i remove b 004 in the set 002 001  Choose the item b 005 which has not been selected yet in 002 001 with the greatest value of t 001\003\005 Insert b 005 into the set 002 001  ii Calculate 003 000 001 000 f 002 004 000 002\003 001 000 004 003 4 Iteration Repeat Step 3 until 003 items remain 6.2 Enhancement Step We can add a pruning step in between Step 1 and Step 2 in the above to enhance the performance We call this the Item Pruning step and it prunes items with apparently small bene\223t The basic idea is to compute both a lowest value and an upper value for the pro\223t of each item These values are generated by varying the estimated selection set for an item 1 For each item b 001  calculate 021 001 and 022 001 where r 000 000 000 f 002 003 001 000 004 003 and 016 000 000 000 f 002 004 000 002\003 001 000 004 003 005 000 f 002 004 000 003 2 Find e 003 th largest value  021 006  among all 021 002 3 For each b 001  remove item b 001 if 022 001 023\021 006 021 001 is an estimate of the lowest possible pro\223t contributed by b 001  we assume that the selected set contains only b 001 In this case the cross-selling effect may greatly reduce the pro\223t generated from b 001  022 001 is e opposite of 021 001  we assume that as many as possible of the items related to b 001 are selected in 002 001  022 001 is equal to the pro\223t gain from adding item b 001 to set 002 001  Hence the cross-selling effect will diminish the pro\223t to a much lesser extent For b 001  the initial pro\223t is zero in 000 000 000 002 001 001  since it is not in 002 001  After b 001 is included in 002 001  the pro\223t from b 001 should be greater than or equal to e pro\223t that b 001 generates when it is the only item selected because of less cross-selling pro\223t loss factors Hence 022 001 and 021 001 satisfy the following property Lemma 1 022 001 005 021 001  Item b 001 is pruned if 022 001 is smaller than the values of 021 002 of the 223rst 003 items which have the highest values of 021 002 The rationale is that b 001 has little chance of contributing more pro\223t than other items When this pruning step is inserted Step 2 in the Main Phase above will not need to compute the estimated bene\223t for all items only the items that remain are not pruned will be considered when computing the estimated bene\223ts However the set 002 001 would be updated if it initially contains items that are pruned Our experiments show that this step is very effective In the IBM synthetic data set there are 1000 items If the number of items to be selected 003  is 500 there are only 881 remaining items after the pruning step Note that if 003 is  s enhancement step can be skipped 6.3 Implementation Details Here we describe how some of the steps are implemented Some sophisticated mechanisms such as the FP-tree techniques are employed to make the computation ef\223cient even with a vast amount of items and transactions 6.3.1 Reading transactions from an FP-tree In a number of cases the transactions in the database are examined for computation for example in the preparation step when we generate all size 2 itemsets in the item bene\223t calculation to determine the pro\223t of a selection If we actually scan the given database which typically contains one record for each transaction the computation will be very costly Here we make use of the FP-tree structure 10  W e cons t r uct an FP-tree 006\007\b once for all transactions setting the support threshold to zero and recording e occurrence count of itemsets at each tree node With the zero threshold 006\007\b retains all information in the given set of transactions Then we can traverse 006\007\b instead of scanning the original database The advantage of 006\007\b is that it forms a single path for transactions with repeated patterns In many applications there exist many transactions with the same pattern especially when the Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


 Root I:5 2 I:4 4 I:2 1 I:1 4 I:1 5 I:1 3 I:1 5 I:1 3 Item Head of Node-link I 5 I 1 I 2 I 3 I 4   I 6                 I:1 6  R u R s I-A A Figure 1 An example of an FP-MPIS-tree number of transactions is large These repeated patterns are processed only once with 000\001\002  From our experiments this mechanism can greatly reduce the overall running time 6.3.2 Calculating Pro\336t with the FP-MPIS-tree In the de\223nition of the pro\223t of an item selection 000 000 000 001 001 see De\223nition 6 we need to compute the number of transactions containing some selected items 002 000 andanyiteminset 003 000 the value of 004 000 002 001 005\003 000 001  where 002 001 003 001 and 003 000 004 002 005 001 This is computed for many selections for each iteration hence the ef\223ciency is important For this task we use the FP-MPIStree data structure In the FP-MPIS-tree we divide the items into two sets 002 005 001 and 001 Set 001 corresponds to items selected while 002 005 001 contains those not selected The items in set 002 005 001 are inserted into FP-MPIS-tree near to the r oot Similar to the FP-tree the ordering of items in each set in the FP-MPIS-tree is based on the frequencies of items An example is shown in Figure 1 In the 223gure the set of selected items is 001 002 006 002 000 005\002 001 005\002 002 007 and e set of unselected items is 002 005 001 002 006 002 003 005\002 004 005\002 005 007  To compute 004 000 002 001 005\003 001  we 223rst look up the horizontal linked list dotted links in Figure 1 of item 002 001 in the FP-MPIStree For each node 006 in the linked list we call the function parseFPTree 006\005 003  The function returns a count we add up all the counts returned from e nodes 006 and it is the value of 004 000 002 001 005\003 001  Function parseFPTree 007\005 003  computes the number of transactions containing item 002 001 and at least one item in 003 in the path from root of FP-tree to 007  Starting from e node 007  we traverse the tree upwards towards the root of the FP-tree until we d a node b containing one element in set 003 or we hit the root node If b exists the count stored in node 007 is returned The call of function parseFPTree 007\005 003  is quite ef\223cient as we do not need to traverse downwards from node 007  This is because all nodes below node 007 are selected items no item in 003 will be found below 007  A further re\223nement for the FP-MPIS-tree is to insert only transactions that contain both selected and non-selected items For transactions with only selected items the pro\223t for each selected item is simply given For transactions with only nonselected item the pro\223t contribution will be zero This re\223nement can greatly reduce the size of the FP-MPIS-tree Note also that the FP-MPIS-tree is built from the FP-tree 000\001\002 and not from the original database 6.3.3 Item Bene\336t Update In each iteration after we remove item 002 002  we need to check the selection t 000 for each item 002 000 in b 000 If t 000 contains item 002 002  it should be updated because item 002 002 has been removed also a new item 002 003 will be lected to be included into t 000 As t 000 is changed the bene\223ts n 000 also have to be updated Let t 000 000 t\006 002 002 007 be the selection before we remove item 002 002 while t 000 000 t\006 002 003 007 be the selection after we have removed item 002 002 and added item 002 003 in the selection t 000  We can do the item bene\223t update y scanning only those transactions 002 containing at least one of item 002 002 and item 002 003 Let 000 000 000 000 001\005 002 001 be the pro\223t of the item selection 001 generated by transactions in 002 The item bene\223t is updated n 000 n n 000 003 000 000 000 000 t 000 000 t\006 002 003 007 005 002 001 005 000 000 000 000 t 000 000 t 006 002 002 007 005 002 001  The computation of 000 000 000 000 001\005 002 001 can be done in a similar manner as 000 000 000 001 001 but 000 000 000 000 001\005 002 001 considers only transactions 002  instead of all transactions As there are fewer transactions in 002 compared to the whole database the update can be done very ef\223ciently 7 Empirical Study We use the Pentium IV 1.5 GHz PC to conduct our experiment Frontline System Solver is used to solve the QP problem All algorithms other than QP are implemented in C/C The pro\336tability is in terms of the percentage of the total pro\223t in the data set We compare our methods with HAP and the naive approach The naive approach simply calculates the pro\223ts generated by each item for all transactions and select the 013 items with the greatest pro\223ts Several synthetic data sets and a real data set are to be tested in our experiments We have tried a number of quadratic programming tools including LINDO TOMLAB GAMS BARON OPTRIS WSAT Frontline System Solver MOSEK and OPBDP We choose Frontline System Solver Premium Solver Premium Solver Platform 1 becaus e i t performs the bes t out of thes e solvers 7.1 Synthetic Data Set In our experiment we use the IBM synthetic data generator in 2 t o g en erate th e d ata set with th e f o llo win g p aram eters same as the parameters of 26 1,000 i t e ms  10,000 t r ans actions 10 items per transaction on average and 4 items per frequent itemset on average The price distribution can be approximated by a lognormal distribution as pointed out in 15 We use the same settings as 26 That i s  10 of i t e ms ha v e the low pro\223t range between 0.1 and 1 80 of items have the medium pro\223t range between 1 and 5 and 10 of items have the high pro\223t range between 5 and 10 7.2 Real Data Set The real data set is obtained from a large drug store in Canada over a period of 3 month In this data set there are 26,128 items and 193,995 transactions On average each transaction contains 2.86 items About 40 of the transactions contain a single item 22 contain 2 items 13 contain 3 items the percentages for increasing sizes decrease smoothly and there are about 3 of the transactions with more than 10 items The greatest transaction size is 88 items In this data set the pro\223t distribution of items is shown in the Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


following table Pro\223t Range Proportion Pro\223t Range Proportion 0-$0.1 2.03 5-$10 10.43 0.1-$1 25.05 10-$100 7.75 1-$5 54.59 100-$400 0.15 7.3 Results r Synthetic Data In the 223rst experiment we have the same setup as in 26 but the pro\223t follows lognormal distribution The result is shown in Figure 2 In the 223gure it is noted that the pro\223tability lines for MPIS Alg QP and HAP are overlapping and the execution-time line for HAP is slightly greater than that for naive For pro\223tability we observe that for the data set the naive approach gives the lowest pro\223tability among all algorithms This is because the naive approach does not consider any cross-selling effect Naturally the pro\223tabilities of all algorithms increase when the number of items selected increases From the graph of the execution time against the selection size the execution time of MPIS Alg increases from 0 selection reaching a maximum when about half the items are selected and then decreases afterwards Here the execution time depends on two factors The 223rst factor is related to the complexity of each iteration If there are more items to be selected the bene\223t calculation is more complex and updates to the bene\223t are more likely The initial increase is related to the 223rst factor The second factor is related to the number of iterations in the algorithm When 000  the number of items selected increases the number of items to be removed in the iteration step decreases Thus the number of iterations decreases if 000 is large compared with 001  The 223rst factor is dominant when the selection is below 50 but the second factor becomes dominant when the selection is larger than 50 The quadratic programming approach QP used in the chosen Solver uses a variant of the Simplex method to determine a easible region and then uses the methods described in 13 to 223nd the solution As the approach uses an iterative step based on e current state to determine the next step the execution time is quite 224uctuating as the execution time is mainly dependent on the problem or which state the algorithm is in HAP is an iterative approach to 223nd the authority weight of each item The formula for the update of the authority weight is in the form 002 000 003\002 where 002 is a vector of dimension 001 representing the authority weight of 001 items and 003 is an 001 000 001 matrix used in HAP to update the authority weight In our experiment we observed that the authority weights converge rapidly QP takes the longest execution time compared with other algorithms Naive gives the shortest execution time as there are only simple operations HAP gives the second shortest execution time for this small synthetic data set We note that the number of iterations involved are quite small MPIS Alg has the second greatest execution time but it scales much better with increasing number of items where it can outform HAP many folds see the next subsection 7.4 Results r Real Data Set With the drug store data set we have conducted similar experiments as with the synthetic data However the Quadratic Programming QP Solver 1 does not handl e m ore t han 2000 variables In the real data set there are 26,128 variables i.e items hence it is not possible to experiment with our QP tool The results of the experiments are shown in Figure 3 In the results HAP gives the lowest pro\223tability The reason is as follows In the dataset there are some items with zero-pro\223t and high authority weight described in Section 3 yielding a low estimated total pro\223t of the item selection Suppose item 004 000 has zero pro\223t it is likely a good buy and hence can lead to high support If there are suf\223cient number of purchases of other item says item 004 001  with item 004 000 and if item 004 000 usually occur in e transactions containing item 004 001  the con\223dence of the rule 004 001 001 004 000 is quite high This creates a high authority weight for item 004 000  Items like 004 000 would lead to smaller profitability for HAP MPIS Alg gives a greater pro\223tability than naive approach in the real data set For instance if 000 000\001\002 005 003\002\001  the difference in pro\223tabilities between these two approaches is 2 In the real data set the l pro\223t is equal to 1,006,970 The difference in 2 pro\223tability corresponds to 20,139.4 which is a signi\223cant value If J=8709 the difference in pro\223tabilities between the two approaches is about 8 which corresponds to 80,557.6 On average the execution time of HAP is 6.5 times slower than MPIS Alg when the problem size is large HAP requires 6 days to 223nd the item selection while MPIS Alg requires about 1 day to 223nd the solution Since item selection is typically performed once in a while only when a store should update the types of products it carries the execution time is acceptable Though the naive method is much faster the pro\223t gain consideration from MPIS Alg would make it the better choice for an application The execution time of HAP increases signi\223cantly when the number of items increases compared with MPIS Alg In HAP a cross-selling matrix 006 is updated iteratively The matrix is of the order 001 000 001  For the real data set 001 000 001\004 005 005\001\006 and 001 000 will be very large Let 002 be e 001 000 005 vector representing the authority weight of each item In HAP there is a process to update 003\002 iteratively where 003 000 006 002 006 Thismatrix multiplication of matrix 003 with vector 002 is highly costly Let us consider the memory required for matrix 003  If double data type 8 bytes is used for storage of each entry then the matrix requires a memory size of about 5.08GB If 224oat data type 4 bytes is required then about 2.5GB memory is required This large matrix cannot 223t into the physical memory g a t of disk accesses for virtual memory Since the matrix 003 is sparse a hash data structure can be used so that only non-zero entries are stored We have adopted the hash structure for the real data set and fouud that less than 5MB memory is needed Our results in Figure 3 are based on this enhanced hashing approach However the computatio n with this reduced size is still very massive We have also tried other sets of experiments where not all Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


the items are considered but only those above a minimum support threshold of 0.05 or 0.1 are considered However the resulting pro\223tabilities are much lower than those shown in Figure 3 For instance if J  500 and min-support  0.05 the pro\223tability of naive and MPIS Alg is about 1.3 But if all items are considered the pro\223tability of those approaches is about 25 This is explained by the existence of items that generate h pro\223ts but which are not purchased frequently enough to be counted given the support thresholds  Na ve i Na ve i Figure 2 The Synthetic Data Set Na ve i Na ve i Figure 3 The drug store data set 8 Conclusion One of the applications of association rule the maximalpro\223t item selection problem with cross-selling effect MPIS is discussed in this paper We propose a modeling by the loss rule which is used in the formulation of the total pro\223t of the item selection We propose both a quadratic programming approach and a heuristical approach to solve the MPIS problem We show by experiments that these methods are ef\223cient and highly effective We believe that much future work can be done The heuristical method can be enhanced with known methodologies such as hill climbing Expert knowledge can be included in the methods and the de\223nition of the problem can be changed in different ways to re\224ect different user environments Acknowledgements We would like to thank M.Y Su for his generous help in providing the source codes for the HAP solution and his other advices We also thank Ping Quin of DBMiner Technology for providing the real dataset This research is supported by the Hong Kong RGC Earmarked Grant UGC REF.CUHK 4179/01E References 1 F ro n tlin e s y s tems so lv er  h ttp www so lv er co m 2 R  A gr a w al  I bm synt het i c dat a gener at or  http://www.almaden.ibm.com/cs/quest/syndata.html 3 R  A g r a w al T  I milien s k i  a n d Sw ami M i n i n g asso ciatio n r u l es between sets of items in large databases In SIGMOD  1993  R  A gra w al and R  S r i kant  F ast al gori t h ms for m i n i n g a ssoci ation es In VLDB  1994  J  E  B easl e y  H euri st i c al gori t h ms for t he unconst rai ned bi nary quadratic programming problem In chnical report the Management School Imperial College London  Dec 1998  T  B l i s chok E v ery t ransact i o n t el l s a s t o ry  I n Chain Store Age Executive with Shopping Center Age 1 3  pages 50\20557 1995 7 T  B r i j s  B  G oet hal s  G  S wi nnen K V a nhoof  a nd G W e t s  A data mining framework for optimal product selection in retail supermarket data The generalized profset model In SIGKDD  2000 8 T  B r i j s  G  S wi nnen K V a nhoof  a nd G W e t s  U si ng associ ation rules for product assortment decisions A case study In SIGKDD  1999  M R Gare y and D S  Johnson Computers and intractability A guide to the theory of np-completeness In Freeman  1979  J Han J P e i  and Y  Y i n Mi ni ng f r e quent pat t e r n s w i t hout candidate generation In SIGMOD  2000  S  Hedber g T h e dat a gol d r ush I n BYTE October  pages 83\205 99 1995  Hiller and L ieber man Introduction to operations research In McGraw Hill Seventh Edition  2001 13 B V  Ho h e n b a lk e n  A 223n ite a l g o r ith m t o m a x imiz e c e r ta in pseudoconcave functions on polytopes In Mathematical Programming 8  1975  R  Hor s t  P  M Par dal os and N  V  T hoai  I nt r oduct i o n t o global optimization In Kluwer Academic Publishers Second Edition  2000  J C  Hul l  Opt i ons fut u res and o t her deri v a t i v es In Prentice Hall International Inc 3rd Edition  1997  L  D Iasemi di s P  Pardal os J C S ack el l ares and D S  S h i au Quadratic binary programming and dynamical system approach to determine the predictability of epileptic seizures In Journal of Combinatorial Optimization Kluwer Academic  pages 9\20526 2001  J Kl ei nber g C  Papadi mi t r i ou and P  R agha v a n A m i c r o economic view of data mining In Knowledge Discovery Journal  1998  J M Kl ei nber g Aut hor i t a t i v e sour ces i n a hyper l i n k e d e n v i ronment In Proc ACM-SIAM Symp on Discrete Algorithms  1998 Also in JACM 46:5 1999  S  J L e on L i near al gebr a w i t h appl i cat i ons I n Prentice Hall Fifth Edition  1998 20 J Lu o  K R P a ttip ati an d P K W illett A s u b o p timal s o f t d ecision pda method for binary quadratic programming In Proc of the IEEE Systems Man and Cybernetics Conference  2001  H Manni l a  M et hods and pr obl ems i n dat a mi ni ng I n Proc of Int Conf on Database Theory  1997  H Manni l a  H  T oi v onen and A I  V e r kamo E f 223 c i ent al gorithms for discovering association rules In KDD  1994  V  S a f r ono v a nd M Par ashar  O pt i m i z i n g w eb ser v e r s usi n g page rank prefetching for lustered accesses In World Wide Web Internet and b Information Systems Volume 5 Number 1  2002  S  S a hni  C omput at i onal l y r e l a t e d p r obl ems I n SIAM J Comput 3  pages 262\205279 1974 25 J Ullman  L ectu re n o t es o n search in g t h e web  h ttp wwwdb.stanford.edu ullman/mining/mining.html  K W a ng and M Y  S u  I t e m sel ect i o n b y 216 hubaut hor i t y 216 p r o 223 t ranking In SIGKDD  2002 Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


I Plenary Panel Session J Future Directions in Database Research  456 Chair Surajit Chaudhuri Microsoft Corporation Panelists Hector Garcia-Molina Stanford University Hank Korth, Bell Laboratories Guy Lohman IBM Almaden Research Center David Lomet Microsoft Research David Maier Oregon Graduate Institute I Session 14 Query Processing in Spatial Databases I Chair Sharma Chakravarthy University of Florida Processing Incremental Multidimensional Range Queries in a Direct Manipulation Visual Query Environment  458 High Dimensional Similarity Joins Algorithms and Performance Evaluation  466 S Hibino and E Rundensteiner N Koudas and K.C Sevcik Y Theodoridis E Stefanakis and T Sellis Cost Models for Join Queries in Spatial Databases  476 Mining Association Rules Anti-Skew Algorithms  486 J.-L Lin and M.H Dunham Mining for Strong Negative Associations in a Large Database of Customer Transactions  494 A Savasere E Omiecinski and S Navathe Mining Optimized Association Rules with Categorical and Numeric Attributes  503 R Rastogi and K Shim Chair: Anoop Singhal AT&T Laboratories S Venkataraman J.F Naughton and M Livny Remote Load-Sensitive Caching for Multi-Server Database Systems  514 DB-MAN A Distributed Database System Based on Database Migration in ATM Networks  522 T Hara K Harumoto M Tsukamoto and S Nishio S Banerjee and P.K Chrysanthis Network Latency Optimizations in Distributed Database Systems  532 I Session 17 Visualization of Multimedia Data I Chair Tiziana Catarci, Universita di Roma 223La Sapienza\224 W Chang D Murthy A Zhang and T.F Syeda-Mahmood Global Integration of Visual Databases  542 X 


The Alps at Your Fingertips Virtual Reality and Geoinformation Systeps  550 R Pajarola l Ohler P Stucki K Szabo and P Widmayer C Baral G. Gonzalez and T.C Son Design and Implementation of Display Specifications for Multimedia Answers  558 1 Session 18 Management of Objects I Chair: Arbee Chen National Tsing Hua University P Boncz A.N Wilschut, and M.L. Kersten C Zou B Salzberg, and R Ladin 0 Wolfson S Chamberlain S Dao L Jiang, and G. Mendei Flattening an Object Algebra to Provide Performance  568 Back to the Future Dynamic Hierarchical Clustering  578 Cost and Imprecision in Modeling the Position of Moving Objects  588 ROL A Prototype for Deductive and Object-Oriented Databases  598 A Graphical Editor for the Conceptual Design of Business Rules  599 The Active HYpermedia Delivery System AHYDS using the M Liu W Yu M Guo and R Shan P Lang W Obermair W Kraus and T Thalhammer PHASME Application-Oriented DBMS  600 F Andres and K. Ono S Chakravarthy and R Le S Mudumbai K Shah A Sheth K Parasuraman and C Bertram ECA Rule Support for Distributed Heterogeneous Environments  601 ZEBRA Image Access System  602 Author Index  603 xi 


11  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02  data bindings domain-specific metric for assessing module interrelationship  interface errors errors arising out of interfacing software modules  Porter90 Predicting software  faults 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 From decision trees to association rules  Classifiers  223this and this\224 goes with that \223class\224  conclusions \(RHS\ limited to one class attribute  target very well defined  Association rules  223this and this\224 goes with \223that and that\224  conclusions \(RHS\ may be any number of attributes  But no overlap LHS and RHS  target wide open  Treatment learning  223this and this\224 goes with \223less bad and more good\224  223less\224,  \223more\224: compared to baseline  223bad\224, \223good\224: weighted classes Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


12  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Association rule learning  www.amazon.com  Customers who bought this book also bought  The Naked Sun by Isaac Asimov  The Caves of Steel by Isaac Asimov  I, Robot by Isaac Asimov  Robots and Empire by Isaac Asimov 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Support and confidence  Examples = D , containing items I  1: Bread, Milk 2: Beer Diaper Bread, Eggs 3: Beer Coke, Diaper Milk 4: Beer Bread, Diaper Milk 5: Coke, Bread, Diaper Milk  LHS  RHS = {Diaper,Milk  Beer  Support       =   | LHS U RHS|  / | D |       = 2/5 = 0.4  Confidence  =   | LHS U RHS |  / | LHS |    = 2/3 = 0.66  Support-based pruningreject rules with s < mins  Check support before checking confidence Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


13  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Example of supportbased pruning 4 Bread 1 Eggs 4 Diaper 3 Beer 4 Milk 2 Coke Count 1Item 3 Beer,Diaper 3 Milk, Diaper 2 Milk,Beer 3 Bread, Diaper 2 Bread,Beer 3 Bread,Milk Count 2Item 2 Milk, Diaper Beer 3 Bread,Milk Diaper Count 3Item Support-based pruning 225 Min support =3 Ignore subsets of items of size N 225 only if N-1 support > min-support Without pruning 6 C 1  6 C 2  6 C 3 41 With pruning: 6 + 6 + 2 = 14 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Classifiers versus Association rules \(again  Classifiers  Assume entire example set can fit into RAM  Association rule learners  can handle very big data sets  Agraw  t he APRIORI alg o r i t h m   very large data sets  10,000,000 examples  843MB Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


14  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 The Data Mining Desiderata Bradley  Require one scan \(or less\ of the database if possible  On-line \223anytime\224 behavior  223best\224 is always available, with status information on progress, expected remaining time, etc. provided  Suspendable, stoppable, resumable  incremental  progress saved to resume a stopped job  Ability to incrementally incorporate additional data with existing models efficiently  Work within confines of a given limited RAM buffer  Ooops, good-bye traditional classifiers e.g. C4.5  Argued against by some  223Memory is cheap\224: [W A R2 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Conf1  outlo o k overc a s t   1 0   82  40    84  40   4 0 0  Treatment learning sunny, 85 86 false none \(2 1 2 sunny, 80 90 true none sunny, 72 95 false none rain 65 70 true,          none rain, 71 96 true none rain 70  false some \(2 2 4 rain, 68 80 false,  some rain, 75 80 false some sunny,      69 70 false lots    \(2 3 8 sunny,      75 70 true lots overcast,     83  false lots overcast,     64  true lots overcast,     72  true lots overcast,     81 75 false lots outlook temp humidity wind hours on course A good attribute range 225 More frequent in good that bad 225 Weighted by 223distance\224good to bad 225 Normalized by total count 225 Summed for all good/bad class pairs Lots  none Lots  some Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


15  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 sunny, 85 86 false none \(2 1 2 sunny, 80 90 true none sunny, 72 95 false none rain 65 70 true,           none rain, 71 96 true none rain 70  false some \(2 2 4 rain, 68 80 false,  some rain, 75 80 false some sunny,      69 70 false lots    \(2 3 8 sunny,      75 70 true lots overcast,     83  false lots overcast,     64  true lots overcast,     72  true lots overcast,     81 75 false lots 0 1 2 3 attribute ranges with deltaf 4-2024681 conf1 225 treatments 002 attribute.range.conf1 > X 225 treatments|=N 225TAR2 = O\(2 N  225 fails for large N outlook temp humidity wind hours on course Conf1  outlo o k overc a s t   1 0   82  40    84  40   4 0 0  Lots  none Lots  some 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Treatments for golf 0 1 2 3 4 none some lots I f outl ook o verc as t Th en l o t s o f go l f  4 4  0 Least monitor watch the humidityalert if rising over 90 Least change pick a vacation location with overcast weather I f h u m i d i t y  90  97 Th en l o t s o f go l f  1 4  0 1 2 3 none some lots 0 1 2 3 4 5 6 none some lots If n o ch an ge Th en l o t s o f go l f  6 6 3 5  3  Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


16  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 6.7 <= RM < 9.8 And 12.6 <= Ptratio 15.9 BEST ACTION 0.6 <= NOX < 1.9 and 17.16 <= LSTAT < 39 WORST ACTION BASELINE 500 examples  of bad--, bad, ok, good Stop staring at the scenery and tell me where to steer or what to dodge 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Require overall require2 require3 require5 require4     action1 action1, action2, action3,  \205   Cost,    Benefit 1 Y              Y             N,        \205   23200,  250 2           N              N             Y ,       \205   11400,  150 205..       \205             \205            \205        \205   \205         \205 action2 fault2 fault3 fault1 JPL requirements Feather&Menzie Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


17  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study 99 proposed actions for deep space satellite design; 2 99 10 30 options Each row is one project plan action1, action2, action3,  \205   Cost,    Benefit 1 Y              Y             N,        \205   23200,  250 2           N              N             Y ,       \205   11400,  150 205..       \205             \205            \205        \205   \205         \205 Learnt 225 Do 16 225 Don\222t do 14 225 Ignore 66 options 225 c.f. genetic algorithms Each dot  is one randomly generated project plan 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Pr of tampering 0.02 Pr of fire 0.01 Pr of smoke  given [fi  0.90 Pr of smoke  given [fi  0.01 Pr of report given [exodus=ye 0.75 Pr of report given [exodus=no 0.01 Pr of exodus given [alarm=yes 0.88 Pr of exodus given [alarm=no 0.001 etc tampering fire alarm smoke exodus run away report hello, operator I want to report a fire 0.02 0.01 Use Bayesian analysis to update probabilities given new information Use Bayesian analysis to update probabilities given new information Bayesian Tuning Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


18  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 tampering fire alarm smoke NO exodus report YES 0.50 was 0.02 0.03 was 0.01 Q1: What if there is a report, but no smoke Q1: What if there is a report, but no smoke Q2: What if there is a report, and smoke Q2: What if there is a report, and smoke tampering fire alarm smoke YES exodus 0.03 was 0.02 0.97 was 0.01 report YES Example from : [Poole98   p37 1 Source = http:// www.swi.psy.uva.nl/projects/SWI-Prolog/download.html http://www.cs.ubc.ca/spider/poole/ci/code.tar.gz Files    = code/acp/bnet.pl code/acp/bnet_t1.pl Bayesian Tuning 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Non-na\357ve model bayesian network Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


19  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Low testing effort EXPLAINS 1\ some observed operational defects  and 2\ low pre-release defects 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02  Ancestors  ancestor\(X,Y\:-parent\(X,Y  ancestor\(X,Y\:-parent\(X,Z\ancestor\(Z,Y  Lists  member\(X,[X|Z   member\(X,[Y|Z me mb er X Z   append X X   append\([X|X Y s X Z s  a ppe nd X s Ys Z s  Example Example action action hypothesis hypothesis p\(b,[b add clause p\(X,Y   specialize p\(X,[V p\(x,[a specialize p\(X,[X p\(b,[a add clause p\(X,[X p\(X,[V p\(X W Inductive Logic Programming Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


20  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 East-West trains 1. TRAINS GOING EAST 2. TRAINS GOING WEST 1 2 3 4 5 1 2 3 4 5 1. TRAINS GOING EAST 2. TRAINS GOING WEST 1 2 3 4 5 1 2 3 4 5 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 ILP representation  Example eastbound\(t1  Background theory car\(t1,c1\      car\(t1,c2\       car\(t1,c3\.      car\(t1,c4 rectangle\(c1\  rectangle\(c2\     rectangle\(c3\.   rectangle\(c4 short\(c1\      long\(c2\.          short\(c3\       long\(c4 none\(c1\.        none\(c2\.          peaked\(c3\.      none\(c4 two_wheels\(c1\  three_wheels\(c2\two_wheels\(c3\two_wheels\(c4 load\(c1,l1\.     load\(c2,l2\       load\(c3,l3\    load\(c4,l4 circle\(l1\      hexagon\(l2\       triangle\(l3\    rectangle\(l4 one_load\(l1\  one_load\(l2\.      one_load\(l3\    three_loads\(l4  Output ne\(C Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


21  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Predicting Correctness Almei NewID CN2 C4.5 C4.5_rule FOIL Accuracy 52 54 66 68 73 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 FOIL\222s best rule high\(A executable\(A,B maximum_statement_nesting_depth\(A,C lines_of_comments\(A,B commentsdivsize\(A,E n1\(A,F n2\(A,G less_or_equal\(E,F not less_or_equal\(B,G C <> 4 C <> 43 less_or_equal\(C,D High faults when comment density <= #operators and executable statements > #operators and max nesting <= number of lines of comments and max nesting is not 4 or 43 High faults when comment density <= #operators and executable statements > #operators and max nesting <= number of lines of comments and max nesting is not 4 or 43 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


22  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Inside  some learners  neural nets  genetic algorithms  decision tree learners  association rule learners  treatment learners  bayesian tuning  inductive logic programming 225 sub-symbolic locally guided descent symbolic, global search 225 recursive diversity reduction 225 this goes with that CLASS 225 this goes with that 225 asses 225 a little model goes a long way 225 Horn clauses  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case studies predicting effort \(45 predicting faults \(51 model-based ML \(54 early lifecycle project planning \(60 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


23  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study How can we estimate earlier in the life cycle  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Predicting development times in months\Srinivasan95 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


24  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Bayes for effort Chulani99  The COCOMO-II project  Open-source software cost estimation  Reuse vs effort XH : multiple product lines VH : across product lines H : across program N : across project L  : none  Regression over data from 83 software projects  Regression conflicted with \223Delphi values\224  Tune regression values using Delphi expectations 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5 1.6 Low N H VH XH Delphi Regression Adjusted Da ta   reus e low e rs effo r t Ex pe ct e d  reus e incre a se  effo r t    251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 COCOMO-II \(1998\COCOMO-II \(1997 Pred\(30 Pred\(25 Pred\(20 Pred\(X 52 49 46 83 projects 63 59 54 161 projects 7561 68 55 63 48 161 projectsbased on Bayesian 161 projectsbased on Delphi Percentage of estimated effort within X of actual Conclusion data + delphi tuning\a Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


25  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Neural Network Count the wi dge ts in the I n te r f ace to es ti m a te e f f o r t  Labels Edit Boxes Grid Boxes Check Boxes Buttons 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Neural Network Subsystem Pred\(25 MARE Buyer Admin 80 17.6 Buyer Client 80 14.6 Distribution Server 20 96.7 Supplier Client 90 12.2  12 Different Widgets Counted and associated with effort Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


26  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study: Predicting software 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Predicting software  faults Khoshgoftaar99 Whi c h d o g s di d not ba r k  225 42 attri b ute s  in dat a s e t 225 Only 6 in the l e arnt th e o ry Diffe re nt attri b ute s than b e fore 225 223c au se s f a u l t 224  do m a in s pec i f i c 225 Me thod for fin d ing fa ult s  gen e r a l Whi c h d o g s di d not ba r k  225 42 attri b ute s  in dat a s e t 225 Only 6 in the l e arnt th e o ry Diffe re nt attri b ute s than b e fore 225 223c au se s f a u l t 224  do m a in s pec i f i c 225 Me thod for fin d ing fa ult s  gen e r a l Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


27  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Issue of generality  Specific conclusions may not apply to general projects  Proposal one  Intra-project learning  Lessons should generalize across the same developer methodology, application and tool set  Proposal two  Inter-project learning  Need larger training set  COCOMOII uses 161 projects  Note: two = N * one Khoshgoft good bad Tia bad good  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Model-based ML Bratko89,Pearc Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


28  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Model-based ML simple e.g sum\(X,  Y Z sum   sum   sum\(0 0 0 sum 0  sum 0  sum\(0   sum\(0   sum  Any sum  Any if X >0 X\222=      if X < 0 0 if X= 0  switch\(State,Volts,Amps switch\(on,       0,     Any switch\(off,      Any,   0 blub\(Mode,Light,Volts,Amps bulb\(blown,dark, Any 0 bulb\(ok,     light   bulb\(ok,    light   bulb\(ok,    dark 0 0 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 A qualitative circuit go  :tell\('circ.data'\ go1, told go1 :functor\(X,circuit,9\ forall\(X, example\(X example\(circuit\(Sw1,Sw2,Sw3,B1,B2,B3,L1,L2,L3\classification\(B1,B2,B3,Class format\('~a,~a,~a,~a,~a,~a,~a~n Sw1,Sw2,Sw3,L1,L2,L3,Class  classification\(B1, B2, B3,Class needs 2 our of three bulbs working classification\( ok, ok, B3,   good classification\( ok, B2, ok,   good classification\( B1, ok, ok,   good classification\( B1, B2, B3,   bad Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


29  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Results from > 700 examples circ.names good,bad switch1: on, off switch2: on, off switch3: on, off bulb1: light, dark bulb2: light, dark bulb3: light, dark Command line c4.5 -f circ -m 2 W a t c hing bulb1 tells us th e rest Insight f ul  Or dull W a t c hing bulb1 tells us th e rest Insight f ul  Or dull 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 More Model-based ML Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


30  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 ca n we r e v i s i t thos e warranti e s   Run 1 35,000 tions  Learn 1  Run 2 if Sw2c=off then 3264 tions  Learn 2  Run 2 if Sw2c=off n then 648 tions  Learn 3 Ca n\222t clos e  Sw3c warranty issu es No b u d g e t  for e x p e ns i v e ha rd wa r e 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 3 \223tunings\224 5 SLOC guesstimates 150,000 runs Treatments for software projects Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


31  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 flex=1 pmat=3 sced=2 rest anything from kc1 150,000 runs 150,000 runs Treatments for software projects \(ii 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 pmat=2 acap=2 sced=2 rest anything from kc1 30,000 runs 30,000 runs Treatments for software projects \(iii Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


32  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 ons discussion \(64 downloads \(69 further reading \(71 references \(72 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Will you try ML  Have we motivated you  Will you rush home and do ML on your data  Clearly  ML algorithms work  Caution  you may find it harder than you think Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


33  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Many ways to learn numerous case studies but there is still a problem Theme Learning is a solved problem \(sort of Data collecting and modeling is not 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Be warned match your ML goals to your software process level Project metrics coarse-grain conclusions Product metrics product learning Process metrics process learning Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


34  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Also, match your tool to task Task ML Tool Assembly line robot deciding what to reject Decision tree learner Repair robot trying to do the least to fix the rejected parts Treatment learner Predicting the life of a robot Neural Network Optimizing the assembly line Genetic Algorithm If clustering when no classes iation rule learning If simple background knowledge Bayesian If complex relational background knowledge ILP 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Have we learnt enough  Not yet  But wait Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


35  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Cost = $0  WEKA  E.g. http://www.cs.waikato.ac.nz/~ml/weka/: ML in JAVA 003 decision tree inducers,rule learners, naive Bayes, decision tables locally weighted regression  GDB_Net  http://nas.cl.uh.edu/boetticher/gdb_net.zip  TAR2  http://www.ece.ubc.ca/twiki/bin/view/Softeng/TreatmentLearner  APRIORI  http://fuzzy.cs.uni-magd eburg.de/~borgelt/apriori/apriori.html#download  And many others  E.g. ML  A public domain \223C\224 library of common algorithms  Naive Bayes, ID3, MC4 , Decision Tables ,   Holte's OneR CN2,\205  http://www.sgi.com/tech/mlc/utils.html 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Cost > $0  C4.5  Comes with the book Quinlan  C5.0  http://www.rulequest.com/download.html  Microsoft SQL SERVER 2000\231  Comes with numerous machine learning tools  Proprietary algorithms  Etc  223data mining\224 \223commercial software\224 in Google  3,340 links  223data mining consultancy\224 in Google  850 links Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


36  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Further reading  Mendonca  great rev i e w art i cl e on ML  Large list of available tools  All the things you can do with a decision tree [Menzies0  Treatment learning: [Menzies01a  Michalski\222s excellent survey of ML types [Michalski  Neural nets: [Boetticher01  Special issue SEKE journal, knowledge discovery Morasca99  Inductive logic programming [Bergadano95,Cohen95  Come by IJCAI 2011 and I\222ll tell you all about it\222s applications  Genetic algorithms: [Goldberg8  Bayesian learning [Cheeseman88 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 References  Agrawal  Agrawal, R., and T.Imeilinski and A.Swami \223Mining Association Rules between Sets of Items in Large Databases,\224 Proceedings of the 1993 ACM SIGMOD Conference Washington DC, USA  Bergadan  Bergadano, F., and D.Gunetti Inductive Logic Programming: From Machine Learning to Software Engineering The MIT Press, 1995  B  Berry, M. J. A., and G., Linoff Data Mining For Marketing, Sales, and Customer Support John Wiley Sons, Inc., New York, 1997  Boetticher01  Boetticher, G., "An Assessment of Metric Contribution in the Construction of a Neural Network-Based Effort Estimator Second International Workshop on Soft Computing Applied to Software Engineering  Enschade, NL, 2001 Available from http://nas.cl.uh.edu/boetticher/publications.html  Boetticher01  Boetticher, G., "Using Machine Learning to Predict Project Effort: Empirical Case Studies in Data-Starved Domains First International Workshop on Model-based Requirements Engineering San Diego, 2001 Available from http://nas.cl.uh.edu/boetticher/publications.html  Bradley  Bradley, P., U. Fayyad, and C. Reina. \223Scaling clustering algorithms to large databases\224. In KDD'98  B  Bratko, I., I. Mozetic, and N. Lavrac KARDIO: a Study in Deep and Qualitative Knowledge for Expert Systems MIT Press, 1989  Breim  Breiman, L., J. Friedman, R. Olshen, C. Stone, \223Classification and Regression Trees,\224 Wadsworth International Group, 1984 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


37  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 References  Burgess  Burgess, C.J., and Martin Lefley. \223Can genetic programming improve software effort estimation? A comparative evaluation,\224 Information and Software Technology er 2001  Cheesem  P. Cheeseman, D. Freeman, J. Kelly, M. Self, J. Stutz, and W. Taylor. \223Autoclass: a bayesian classification system,\224 In Proceedings of the Fifth International Conference on Machine Learning  Morgan Kaufman, 1988  Chulani  S.Chulani,  B. Boehm, and B. Steece 223Bayesian analysis of empirical software engineering cost models,\224 IEEE Transaction on Software Engineering 25\(4\ly/August  1999  Cohe  W. W. Cohen, \223Inductive specification recovery: Understanding software by learning  from example behaviors,\224 Automated Software Engineering 2:107-129, 1995  DeJon  DeJong, K.A., and Spears, W.M. "An Analysis of the Interacting Roles of Population Size and Crossover in Genetic Algorithms Proc. First Workshop Parallel Problem Solving from Nature  Springer-Verlag, Berlin, 1990  Dietteric  Dietterich, T. G., \223Machine Learning  Research: Four Current Directions,\224 AI Magazine 18 \(4\97 Pp. 97-136. Available from ftp://ftp.cs.orst.edu/pub/tgd/papers/aimag-survey.ps.gz  s  Feather, M.S., and T. Menzies: \223Converging on the Optimal Attainment of Requirements IEEE Joint Conference On Requirements Engineering  ICRE'02 and  RE'02 9-13th September, University of Essen, Germany, 2002. Available from http://tim.menzies.com/pdf/02re02.pdf 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 References  Fenton00  Fenton, N., and  M. Neil \223Software Metrics: A Roadmap,\224 International Conference on Software Engineering, 2000. Available from http://www.dcs.qmul.ac.uk/~norman/papers/metrics_roadmap.pdf  Goldberg  Goldberg, D.E Genetic Algorithms in Search, Optimization, and Machine Learning Addison-Wesley Reading, Massachusetts, 1989  Khoshgoftaar  Khoshgoftaar, T.M., and E.B. Allen. \223Model software quality with classification trees,\224 in H. Pham, editor 223Recent Advances in Reliability and Quality  Engineering\224, World Scientific, 1999  Mendonc  Mendonca, M., and N.L. Sunderhaft, \223Mining Software Engineering Data: A Survey,\224 A DACS State-ofthe-Art Report September 1999. Available from http://www.dacs.dtic.mil/techs/datamining  Menzie  Menzies, T., \223Practical Machine Learning for Software Engineering and Knowledge Engineering,\224 ftware Engineering and Knowledge Engineering volume 1, 2001\vailable from http://tim.menzies.com/pdf/00ml.pdf  Menzies01a  Menzies, T., and Y. Hu, \223Reusing models for requirements engineering,\224 First International Workshop on Model-based Requirements Engineering 2001. Available from http://tim.menzies.com/pdf/01reusere.pdf  Menzies01b  Menzies, T., and Y. Hu, \223Constraining discussions in requirements engineering,\224 First International Workshop on Model-based Requirements Engineering San Diego, 2001. Available from http://tim.menzies.com/pdf/01lesstalk.pdf  Menzie  Menzies. T., and J. Kiper, \223Better reasoning about software engineering activities,\224 Automated Software Engineering 2001. Available from http://tim.menzies.com/pdf/01ml4re.pdf Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


38  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02  Michalski90   Michalski, R.S., \223Toward a unified theory of learning,\224  In B.G. Buchanan and D.C. Wilkins, editors 223Reading in Knowledge  Acquisition and Learning\224, pages 7--38. Morgan Kaufmann, 1993  Mitchell  Mitchell, T Machine Learning McGraw-Hill, 1997  Morasca99  Morasca, S., and Gunther Ruhe, Guest editors' introduction of the Special issue on \223Knowledge Discovery from Software Engineering Data,\224 International Journal of Software Engineering and Knowledge Engineering October, 1999  Pearce  Pearce, D., \223The induction of fault diagnosis systems from qualitative models,\224 in Proc. AAAI-88 1988  Poole9  Poole, D. L.,  A. K. Mackworth, and R. G. Goebel Computational Intelligence: A Logical Approach  Oxford University Press, New York, 1998  Porter9  Porter, A.A., and R.W. Selby  \223Empirically guided software development using metric-based classification trees,\224 IEEE Software Pp. 46-54, March 1990  Quinla  Quinlan, R C4.5: Programs for Machine Learning Morgan Kaufman, 1992  Srinivasa  Srinivasan, K., and D. Fisher,  \223Machine learning approaches to estimating software development effort,\224 IEEE Transactions on Software Engi neering Pp. 126-137, February 1995  Tian9  Tian, J., and M.V. Zelkowitz 223Complexity measure evaluation and selection,\224 IEEE Transactions on Software Engineering 21\(8\p. 641-649,  August 1995  Webb0  Webb, G., \223Efficient search for association rules,\224 Proceeding of KDD-2000 Boston, MA,  2000  Zhang0  Zhang, Du, \223Applying Machine Learning Algorithms in Software Development,\224 Modelling Software System Structures in a fastly moving scenario Santa Margherita Ligure, Italy, 2000 References Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 



             
              
                  
             
                 
              
                 
      415 2011 China located International Conference on Information Systems for C\risis Response and Management 978-1-4577-0366-9/11/$26.00 ©2011 IEEE November 25-27, 2011 


 419  theoretical basis and guidin g significance. Firstly, the sample data set about assessment indexes of describing fire situation; Secondly, we find out useful information about possible future fire w ith association rule data mining  2 Forecasting fires with association rule data mining In this section, we use association rule data mining technology to analysis th e relationship rules between assessment indexes based history data. Then useful information to forecasting future fires will be found, such as fires grade, fires place, and so on 2.1 Definitions of association rule data mining with fire assessment indexes Association rule was or iginally proposed by Agrawal and Srikant in 1993. Then in the literatures [9  ciation rule again. T h e aim  of association rule is to find out the contact with different commodity \(set\he trade da ta base, that is, to look for the interesting contact in th e appointed data collection Through the description of th e potential relation rules between data sets in the data base, we can discover the dependence relations between many domains which are satisfied with the given threshold value of support and confidence. For discussing problems conveniently, we give several definitions of association rule with fire situation  Definition 1 Let D  D  t 1  t 2 205 t k 205 t n be association rule mini ng data collection t k   i 1  i 2 205 i i 205 i p  k 1,2,\205 n  t k stands up an affair and the element in t k is called by an Item which is the description of the fire situation Definition 2 We assume  that  I  i 1  i 2 205 i m is composed of all items in D Any subset X of I is called itemset X is called Xitemset if there is X  k  Association rule is the im plication formula such as X Y  where X I  Y I also X Y   X is the forward item and Y is the back item; Associati on rule can reflect the rule when the item of X appears, the item of Y must be. In fire problems, the interesting asso ciation rule can provide the reliable data for future fires prevention and fighting Definition 3. The number of affairs including item X  in D  is modeled as the support number of item X namely x The support rate of item X is figured as support  X  100 sup j x D Xport   1 where D denotes the affair number of D If support  X not smaller than the appointed smallest support, called min-support, we can reckon X as a big item, conversely a small ite m. The support rate of X Y is the support rate of association rule X Y namely support  X Y  support  X Y And we denote the confidence of association rule X Y by confidence  X Y  100 sup sup   Xport YXport YX confidence 2 The smallest confidence which is designated by the user could be figured as min-confidence  2.2 Process of mining association rules The process of mining association rules is categorized into the followings: \(1\nding out all of big items; \(2\g into being association rules through big items 1\nding out all of big items: According to definitions, the frequency that these big items appear is at least as same as the appo inted smallest support number Firstly, we establish the sample data set D of fire data over years  in Tab.1  Tab.1 Fires sample data set D  TID t 1 t 2 t k  t n  P 1  V 11  V 12  V 1 k  V 1 n P 2  V 21 V 22  V 2 k  V 2 n      P i V i 1 V i 2  V ik V in      P m V m 1  V m 2  V mk  V nn  Where P i is the place of fire and t k  k n the item of D In this paper, we assume that t k is an assessment index. Because there are plenty of assessment indexes we choose the fire survey, large fires, major fires, fire reasons, police action, battle results as t 1  t 2  t 3  t 4 The fire survey t 1 ncludes three items as following, fire number i 1 ber i 2 njured number i 3  property loss i 4 choose fire number i 5  i 6 s only item for large fires and major fires; there are human factors i 7 ctrical i 8 production operations i 9  the fire carelessly i 10 oking i 11 playing with fires  i 12 ontaneous combustion i 13 lightning strike i 14  static electricity i 15 gue reasons i 16 hers i 17  t 2  there are inputs to the human resources i 18 nd inputs to vehicles i 19 n t 3 there are the number of saving i 20  the number of evacuation i 21 d saving property i 22  in t 4 In this paper, we use Apriori algorithm to mine the Boolean association rules so that the value of quantitative attribute should be transformed to Boolean values. We will disperse the value of quantitative attribute. \223 i 1  i 22 224 are quantitative attribute, for the consistency of record amounts in every group, we disperse the twenty-two quantitative attributes based on same length or same distance method. We will introduce the transformation means as following i 1 is categorized into the followings a1 V i 1 0,20\}, a2 V i 1 20,40\ a3 V i 1 40,60 a4 V i 1 60,100\, a5 V i 1 100  i 2 is categorized into the followings: b1 V i 2 0,5 b2 V i 2 5,10 V i 2 10  i 3 is categorized into the followings c1 V i 3 0,15\}, c2 V i 3 15  


 420  i 4 is categorized into the followings d1 V i 4 0,100000\}, d2 V i 4 100000,200000 d3 V i 4 200000  i 5 is categorized into the followings: e1 V i 5 0,4 e2 V i 5 4,8 i 6 is categorized into the followings: f1 V i 6 0 f2 V i 6 0,5  i 7 is categorized into the followings g1 V i 7 0,15 V i 7 15,30\}, g3 V i 7 30,45 i 8 is categorized into the followings h1 V i 8 0,20 V i 8 20,40\ h3 V i 8 40,60 h4 V i 8 60,80\}, h5 V i 8 80,100 i 9 is categorized into the followings: i1 V i 9 0,15 i2 V i 9 15,30 i 10 is categorized into the followings j1 V i 10 0,15\ j2 V i 10 15,30\3 V i 10 30,45 j4 V i 10 45,60 i 11 is categorized into the followings k1 V i 11 0,20\}, k2 V i 11 20,40\}, k3 V i 11 40,60 k4 V i 11 60,80 i 12 is categorized into the followings l1 V i 12 0,15\ l2 V i 12 15,30 i 13 is categorized into the followings m1 V i 13 0,10\, m2 V i 13 10,20 m3 V i 13 20  i 14 is categorized into the followings o1 V i 14 0,3\ o2 V i 14 3,6   i 15 is categorized into the followings p1 V i 15 0,5\ p2 V i 15 5  i 16 is categorized into the followings q1 V i 16 0,10\}, q2 V i 16 10  i 17 is categorized into the followings: r1 V i 17 0,20 r2 V i 17 20,40\, r3 V i 17 40,60\}, r4 V i 17 60,80 i 18 is categorized into the followings s1 V i 18 0,1000\}, s2 V i 18 1000,2000 s3 V i 18 2000,3000\, s4 V i 18 3000,4000 s5 V i 18 4000  i 19 is categorized into the followings t1 V i 19 0,200\}, t2 V i 19 200,400 t3 V i 19 400,600\}, t4 V i 19 600,800 t5 V i 19 800  i 20 is categorized into the followings u1 V i 20 0,20\}, u2 V i 20 20,40\}, u3 V i 20 40,60 u4 V i 20 60,80 i 21 is categorized into the followings v1 V i 21 0,250\}, v2 V i 21 250,500 v3 V i 21 500,1000\}, v4 V i 21 1000  i 22 is categorized into the followings w1 V i 22 0,1000\}, w2 V i 22 1000,2000 w3 V i 22 2000,3000\}, w4 V i 22 3000,4000 w5 V i 22 4000,5000 For P i if V i 1 163, V i2 3 V i 3 0 V i 4 249370 V i 5 1 V i 6 0 V i 7 7 V i 8 62 V i 9 7 V i 10 31 V i 11 11 V i 12 6  V i 13 9 V i 14 0 V i 15 0 V i 16 0 V i 17 30 V i 18 3221  V i 19 769 V i 20 10 V i 21 7 V i 22 621, then Tab.1 could be transformed to Tab.2 after above disposal   Tab.2 Affair data transformed from Tab.1  TID List of Transaction Item P i  a5, b1, c1, d4, e1, f1, g1, h4, i1 j3, k1, l1, m1, o1, p1, q1, r2, s4 t2, u1, v1, w1  We can obtain the affair data base through the homologous process 2\oming into being association rules through big items: Here we employ conventional Apriori algorithm and we assume that min-support is 0.7 and the lowest threshold of min-confidence is destined for 0.5. We make the assumption any frequency item l and its nonempty subset s if there is the following formula      confidence sport lport min sup sup 3 then we can output the rule s  l s his results in interesting rules such as A: j3 a3 s4 t4 [57%, 84 we can explain it: there are 40-60 fires with the fire carelessly, the probability is above 57%, then we dispatch that the number of personnel and vehicles are in 3000, 4000\d [600, 800\ectively. It is confidence is above 84%. We can use the association rule to retrieval the sample data set D to find out the place data which conforms to the range of j3, a3, s4, t4. We need to take measures to strength the management of making use of fire by human being  Tab.1 Type size and typeface for papers Appearance Type Size pts Times New Roman Time s New Roman Bold 9 Figures, tables Figure captions, table names 10 Main text, equations references Subheadings 12 Authors\222 names Section titles 14 Paper title  3 Results analysis  Test the performances of the different min-support and min-confidence, we comp are that the relationship between different min-support with the amount of big items in Fig.1, and the relationship between different min-confidence with the ratio of interesting rules in Fig.2 where the ratio is given by the following equation \(4  n m ratio 4 where m is the number of interesting rules, and n is the number of all rules In fig.1, we can find that, with the continuous improvement of the min-support numerical, the amount of big items is decreasing. This is because that fire is 


 421  relative small probability event than other events. We do not allow that same fire event usually takes place under similar situations. So, the trend of the circle is consistent with the fact. It is important how to set up a moderate min-support. Not only there are enough data to mine the interesting rules, but it doesn\222t take too much time to scan the data base. In Fig.2, we can find that, with the continuous improvement of the min-confidence numerical, the ratio of the interesting rules to all rules is increasing.  However, when min-confidence is about 67%, the ratio of interesting rules is nearly equal to the other with higher min-confid ence. We can explain that the rules are useless if min-conf idence is low. Even if we get quite a lot of association rules, they are meaningless to analysis fires situation  0.0 0.2 0.4 0.6 0.8 1.0 0 50 100 150 200  Amount of big items Min-support   Fig.1 the relationship between different min-support with the number of big items               Fig.2 the relationship betw een different min-confidence with the ratio of interesting rules  We use the data of fires about some city in 2000-2009. With the presented method, min-support is 54% and min-confidence is 67%, we can find out many interesting rules to forecas t the probability where, how many and why fire take place. The results conform to the data facts of 2010. Therefore, we can prove the feasibility and validity of the given algorithm to forecast the future situation and fire prediction and suppression  4 Conclusion  In this paper, a new approach with association rule data mining to forecast fires is presented. Experimental results showed that the proposed algorithm could be used to achieve the optimal solution. However, confidence and support will affect the result of forecasting fires Future work should examine more appropriate confidence and support. Furthermore, we use the traditional Apriori algorithm to find out interesting rules we should find out a new method to improve the mining speed. In addition, we will expand our algorithm to apply it to all kinds of environment, such as forest fires, which need to reset up an affair data base and compute the value of min-support and min-confidence. To resolve the problem is a challenge References   n  HAN Ga ng BO Y i ngs h en Forecasting and trend of forest fire occurance  J o u r nal o f  No r  thwest A & F University. 2008, 36 \(2\ 91-96   M ao h u a Z h on g  W e i c hen g Fa na T i em i n Li u b  Pei d e  Li. Statistical analysis on curre nt status of China forest fire safety [J Fir e Saf e ty Jour n a l 20 03 38  2 57269  3 l ard W  Jahn C Abecassis-Empis, G. Rein J.L. Torero. Sensor assisted fire fightin   Fire  Technology. 2010, 46 \(3\: 719-741 4 in, A.I. Filk ov A  deterministic-probabilistic system for predicting forest  Sa fety Journal. 2011,46: 56-62 5 V o lokitin a, M.A. So frono v  Classificatio n an d Cartography of Vegetation Fuels[R P ubl i s hi n g H o use SB RAS, Novosibirsk. 2002: 314  Deem in g, G  W   La ncas ter   M.A Fos b er g a  o., The  National Fire-Danger Rating System. USDA Forest Service [J 972 165     D 355az J Ga rc\355a-He rre ra R., T r i g o  R.M   Linares  C   Valente, M.A., De Miguel J.M., Hern\341ndez, E. The impact of the summer 2003 heat wave in Iberia: how should we measur   Int. J. Bi o m eteo ro l 20 06 50  159-166  r a P  J. Exam ples of Heat He alth W a rni n g  Systems: Lisbon's ICARO's surveillance system, summer of x trem e weathe r events and Public Health Responses. European Public Health Association. 2005   S ri ka nt R   R  Ag ra wal  M i ni ng Se que nt i a l Pat t e rns  Generalizations and Performance Improvements[C   Preceedings of the 5th Inte rnational Conference on Extending Database Technology \(EDBT\Avignon France, IBM Research Division, 1996: 3-17 10 Zhou  X i n, Sh a Zh aof e ng, Zhu Y a n g y on g, Sh i B o le Interest Measure-Another Threshold in Assocition Rules nal of C o m p u ter Research & Development 2000, 5\(37\: 51-63 1 Wang Huili, Fu Weiping, Fang Zongde. A Path Plann Method for Mobile Robot Based on Improved Potential Field Function M achi n e T ool  Hy dra u l i c s, 2 0 0 2  6   67-71  0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0  Ratio of interesting rules Min-confidence 


Distribution Disi\(A occurrence frequency in some category, such as category i    2 Here max term A while sec and i?j. And Trendi\(A to category i. From the formula \(2 distributed, it will have a weak category tendency; else it has a strong category tendency Definition3. \(Category Homoplasy extension mode A=>B, calculate the Trendi\(A B If there exits i=j and that Trendi\(A B larger than zero, then we say that the feature extension mode A=>B have Category Homoplasy The intuition of this definition is as follows: Category Homoplasy is determined by the category tendency of the terms represented a feature extension mode. If there exits i?j the feature extension mode has no Category Homoplasy. If there exits i=j, but that one or all of the terms has zero category tendency, the feature extension mode also has no Category Homoplasy The measure of Category Homoplasy ensures that the terms represented a feature extension mode are inclined to an identity category, besides, all of them have strong category tendency. So we can say that the feature extension modes which satisfy a given threshold of Category Homoplasy have effective information. However, the terms represented a feature extension mode have different category distribution though they are inclined to an identity category. That may lead to the thresholds of Category Homoplasy different z The Establishment of Relevancy Strength Based on association rule mining method, they follow the assumption that the higher co-occurrence frequency the terms have, the stronger relevancy strength they have. But there has a problem like that the co-occurring relationship that appear closely together is considered in the same way as that co-occurring relationship at distance. For example, the mode  ? ? => ??  \(data=>mining frequency of occurrence as ??=>?? \(grieve=>country would be considered to have the same relevancy strength In fact, the former have stronger relevancy strength than the latter, though their frequencies of co-occurrence are same 


In fact, the co-occurrence frequency and relevancy strength are two different types of information. Some high frequent co-occurrences may have weak relevancy strength 88 Now how can we determine and measure the relevancy strength for a co-occurrence relationship? Here, we can call co-occurrences relationship link [7], and give our answer by means of link distribution    3 Here posd\(a 3 documentd . And consist of two terms a andb which occur in a given window x  in documentd   dFre x L a ba b d x= ?                             \(4 Here | . |  in \(4 set, and Frea,b\(x It is the total number of the unordered term pair consists of two terms a and b which co-occurs in a given window x. It is also called the frequency of link ab when the window size is x, or it is called link distribution intuitively    5 The Cumulative link distribution function CDFa,b\(x represents the proportion of term pairs of a and b that have distance less than or equal tox Link distribution Fre\(x changing with the size of given window. We will find that cumulative link distribution function of Fre\(x corresponding relation with relevancy strength. It should be considered that the higher the proportion of term pairs having small distance, the stronger relevancy strength between terms is. The way of introducing CDF\(x bringing the mode with weak relevancy strength into the feature extension mode library. According to the training data, the distributions of CDF\(x x extension modes, which are randomly selected Bayerische-Motoren-Werke\(BMW BMW=>Red-Flag It can be seen that CDF\(x strength of links, i.e., the CDF\(x more than that of ??=>?? \(0.8>0.7727 while x=10 0.9333 >0.8636 while x =20, 1>0.9545 while x =30 


fact the strength of the former is higher than that of the latter What Fre\(x TABLE I.  THE DISTRIBUTION OF CDF\(X FRE\(X 10,20,30 win size distribution  Fre\(Win Win Win Win 10   12 0.8 17 0.7727 20 14 0.9333 19 0.8636 30   15 1 21 0.9545 15 1 22 1 it is contradictory to their real link strengths. As for the parameter, window size x is not sensitive; and it can be from 10 to 30 according to our training set. In this paper, x  is 20 III. OUR CONSTRUCTION APPROACH OF HIGH-QUALITY FEATURE EXTENSION MODE LIBRARY The process of constructing a high-quality feature extension mode library is described as follows Step 1 Doing Pre-processing for Data First, filter the texts of the training set according to the list of Chinese stop words. Then consider every filtered text as an affair and every concept word as a term Step 2 Doing Association Rules Mining Give a minimum support and a minimum confidence threshold, and then excavate the association rules of terms hidden in training set through Fp-Growth algorithm Step 3 Checking up the feature words Check up the association rules according our feature set having selected only leaving the association rules whose former part is not in the feature-set and the latter is Step 4 Using Category Homoplasy Constraint Scan the training set again to get category tendency of the terms represented every feature association rule from step 3, and then give the minimum homoplasy thresholds to get the feature association rules whose terms are not only have an identity category but also have strong category tendency Step 5 Using Relevancy Strength Constraint Scan the training set again to get the cumulative link distribution of every feature association rule from step 4 and give a minimum relevancy strength threshold to construct a 


high-quality feature extension mode library IV. EXPERIMENTS A. Experiments dataset The dataset is composed of six categories including finance, reading, news, military, technology, and automobile Each category is composed of 18000 Chinese short-texts. We averagely divided texts of each category into four parts randomly, one part as testing data, the rest as training data B. Experimental Design In our experiments, the feature extension strategy is raising the weight of feature terms that represent the latter part of association rule according to its former terms. We choose SVM as our text classifier For the sake of checking the influences of feature extension mode library with different quality degree on the short-text classification, we construct five feature extension mode libraries with different measures as TABALE TABLE II.  THE DIFFERENT FEATURE EXTENSION MODE LIBRARY WITH DIFFERENT CONSTRAIN OF MEASURES measure value mode library I1 I2 I3 I4 I5 Support 0.00003 0.00003 0.00003 0.00003 0.00003 Confidence  0.02   0.02 Category Homoplasy   0.1;0.3  0.1;0.3 Relevancy Strength    0.2 0.2 89 TABLE III.  COMPARISION OF THE PERFORMANCE OF EACH CATEGORY WHIH DIFFERENT QUALITY FEATURE EXTENSION MODE LIBRARY category measure non Extended Extended-with I1 Extended-with I2 Extended-with I3 Extended-with I4 Extendedwith I5 P R F1 P R F1 P R F1 P R F1 P R F1 P R F1 finance 50.42 79.26 61.63 52.73 80.02 63.57 53.21 80.22 63.98 51.67 81.42 63.22 52.62 80.18 63.54 52.41 80.63 63.53 reading 80.75 78.09 79.40 81.51 80.45 80.98 81.90 80.31 81.10 81.72 81.53 81.63 81.58 80.34 80.96 82.82 80.63 81.71 news 52.96 41.74 46.69 55.34 40.93 47.06 55.03 41.34 47.21 57.18 45.18 50.48 55.35 40.94 47.07 56.98 46.05 50.94 military 46.99 73.47 57.32 49.67 74.84 59.71 49.62 74.79 59.65 53.58 70.76 60.98 49.80 74.79 59.79 54.63 70.53 61.57 technology 93.46 45.54 61.24 90.57 46.73 61.65 90.67 46.95 61.86 87.96 47.40 61.60 90.53 


46.80 61.70 85.86 48.59 62.06 automobile 88.13 54.86 67.63 83.92 61.51 70.99 84.01 61.80 71.23 80.63 62.68 70.53 83.92 61.49 70.98 77.61 63.88 70.08 Average 68.78 62.16 62.32 68.96 64.08 63.99 69.07 64.24 64.17 68.79 64.83 64.74 68.97 64.09 64.01 68.39 65.05 64.98 C. Experimental results We use the following measures in the evaluation of classification: Precision \(P R F1 The experimental results are shown in TABLE D. Experimental Analysis Comparing the results of non extended and extended with I1, we know that the co-occurrence relationships can be taken as useful extra information to help short-text classification The results of extended with I1, extended with I2 extended with I3 and extended with I4 show that confidence, category homoplasy and relevancy strength can improve the quality of feature extension mode respectively. Especially category homoplasy it can make short-text classification result to the best Table. ? indicates that the feature extension mode libraries with different quality play different roles for short-text classification. With the improvement of the quality of feature extension mode library, the role of extension for short-text concept is enhancing or the classification result is improving on the whole We can also see that the degree of improvement is small; even there is decline, such as finance and automobile. By analyst, there are some reasons as follows\(1 modes in the feature extension mode library is too few, leading that the information coverage in it is limited and the extension chance for term is small 2 accurate enough and could bring some noise into texts by extension; \(3 text also have an influence on its classification result 4 suitable for Chinese short-text classification V. CONCLUSION In this paper, we study how to construct a high-quality feature extension mode library for short-text classification 


And put forward that we could use confidence, category homoplasy and relevancy strength to improve the quality of feature extension modes. We also verified that confidence category homoplasy and relevancy strength are effective through our experiments. In the same time we have drawn the following conclusions: \(1 relationships for short-text can improve their classification performance; \(2 effectiveness of information in the feature extension mode library we should choose the suitable thresholds; \(3 information is too small to meet the demand of short-text feature extension. So we should find out a perfect method which can increase information coverage in the feature extension mode library for short-text classification; \(4 extension library for short-text extension effectively, i.e., choosing a perfect feature extension strategy is also our further work ACKNOWLEDGMENT The research is supported in part by the National Natural Science Foundation of China under grant number 60703010 the Nature Science Foundation of Chongqing province in China under grant number CSTC, 2009BB2079, and the Scientific Research Foundation for the Returned Overseas Chinese Scholars of Ministry of Education of China under grant number [2007] 1109 REFERENCES 1] Fabrizio Sebastiani.Machine Learning in Automated Text Categorization, A.ACM Computing Surveys, C.2002.34\(1 2] Fan Xing-hua,Wang peng. Chinese Short-Text Classification in TwoStep, J.Journal of DaLian Maritime Universtiy, 2008,11\(2 3] Zelikovitz S. and Hirsh H. Improving Short Text Classification Using Unlabeled Background Knowledge to Assess Document Similarity C. In: Proceedings of ICML-2002, 2002, 1183-1190 4] Wang Xi-wei,Fan Xing-hua and Zhao Jun. A Method for Chinese Short Text Classification Based on Feature Extension, J.Journal of Computer Applications,2009,29\(3 5] JIAWEI HAN,JIAN PEI ,YIWEN YIN, BUNYING MAO.Ming Frequent Patterns without Candidate Generation:A Frequent-Pattern Tree.Data Mining and Knowledge Discovery,2004,8:53-87 6] Liu Fei. Huang Xuan-qing and Wu Li-de.Approach for Extracting Thematic Terms Based on Association Rule, J.Computer Engineering,2008\(4 7] Xinhua Fan, Jianyun Nie. Link Distribution Dependency Model for 


Document Retrieval, C.Journal of Information and Computational Science6:3\(2009  90 


shows that proposed post mining of association rule mining technique for missing sensor data estimation is an area worth to explore REFERENCES 1] Agrawal, R., & Imielinski, T., & Swami, A., "Mining association rules between sets of items in massive databases", International Conference on Management of Data, 1993 2] Austin, F. I., "Austin Freeway ITS Data Archive", Retrieved January 2003 from http://austindata.tamu.eduidefauIt.asp 3] Bastide, Y., & Pasquier, N., & Taouil, R, & Stumme, G., & Lakhal L., "Mining minimal non-redundant association rules using frequent closed itemsets", First International Conference on Computational Logic, 2000 4] Cool, A. L., "A review of methods for dealing with missing data The Annual Meeting of the Southwest Educational Research Association, 2000 5] Deshpande, A., & Guestrin C., & Madden, S., "Using probabilistic models for data management in acquisitional environments", The Conference on Innovative Data Systems Research, 2005 6] Halatchev, M., & Gruenwald, L., "Estimating missing values in related sensor data streams", International Conference on Management of Data, 2005 7] Iannacchione, V. G., "Weighted sequential hot deck imputation macros", Proceedings of the SAS Users Group International Conference, 1982 8] Nan Jiang, "Discovering Association Rules in Data Streams Based On Closed Pattern Mining", SIGMOD Ph.D. Workshop on Innovative Database Research, 2007 9] Li, Y., & Liu, Z. T., & Chen, L., & Cheng, W., & Xie, C.H Extracting minimal non-redundant association rules from QCIL The 4th International Conference on Computer and Information Technology, 2004 10] Little, R 1. A., & Rubin, D. B., "Statistical analysis with missing data", New York: John Wiley and Sons, 1987 II] McLachlan, G., & Thriyambakam, K., "The EM algorithm and extensions", New York: John Wiley & Sons, 1997 12] Mitchell, T., "Machine Learning", McGraw Hill, 1997 13] Papadimitriou, S., & Sun, 1., & Faloutsos, C., "Streaming pattern discovery in multiple time-series", The International Conference on Very Large Databases, 2005 14] Rubin, D., "Multiple imputations for nonresponce in surveys", New York: John Wiley & Sons, 1987 


15] Shafer, 1., "Model-Based Imputations of Census Short-Form Items In Proceedings of the Annual Research Conference, 1995 16] Taouil, R., & Pasquier, N., & Bastide, Y., & Lakhal, L., "Mining bases for association rules using closed sets", International Conference on Data Engineering, 2000 17] Wilkinson & The AP A Task Force on Statistical Inference, 1999 18] Zaki, M. 1., Hsiao, C. 1., "Efficient algorithms for mining closed itemsets and their lattice structure", IEEE Transactions on Knowledge and Data Engineering, 2005 V5-106 


General Chair f!!\f  Organizing Chairs  f!!\f  f$% \f!!\f  Organizing Co-chairs f    f  f\f   f\f\f   f*!\f!\f.\f  f f  Program Committee Chairs  f\f\f   f!!\f  Publication Chair 0   


200 250 300  The size of dataset/10,000 R es po ns e tim e S    a 0 50 100 150 200  The size of dataset/10,000 R es po ns e tim e S    b 0 10 20 30 40 50 


60  The size of dataset/30,000 R es po ns e tim e S    c Fig. 9 The scalability of our algorithm compared with FP-growth  Paper [12] proposed a way to reduce times of scanning transaction database to reduce the cost of I/O IV. CONCLUSIONS AND FUTURE WORK This paper first discusses the theory of foundations and association rules and presents an association rules mining algorithm, namely, FP-growth algorithm. And then we propose an improved algorithm IFP-growth based on many association rules mining algorithms. At last we implement the algorithm we propose and compare it with algorithm FPgrowth algorithm. The experimental evaluation demonstrates its scalability is much better than algorithm FP-growth 177 Now, lets forecast something we want to do someday Firstly, we would parallelize our algorithm, because data mining needs massive computation, and a parallelable environment could high improve the performance of the algorithm; Secondly, we would apply our algorithm on much more datasets and study the run performance; At last, we would study the performance when the algorithm deal with other kinds of association rules  REFERENCES 1] S. Sumathi and S. N. Sivanandam. Introduction to Data Mining and its Applications, Springer, 2006 2] V. J. Hodge, J. Austin, A survey of outlier detection 


methodologies, Artificial Intelligence Review, 2004, 22 85-126 3] Han, J. and M. Kamber. Data Mining: Concepts and Techniques. Morgan Kaufmann, San. Francisco, 2000 4] Jianchao Han, Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases, Journal of Advanced Computational Intelligence and Intelligent Informatics 2006, 10\(3 5] Jiuyong Li, Hong Shen, Rodney Topor. Mining Informative Rule Set for Prediction. Journal of Intelligent Information Systems, 2004, 22\(2 6] Jianchao Han, and Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases. Journal of Advanced Computational Intelligence, 2006, 10\(3 7] Doug Burdick, Manuel Calimlim, Jason Flannick Johannes Gehrke, Tomi Yiu. MAFIA: A Maximal Frequent Itemset Algorithm. IEEE Transactions on Knowledge and Data Engineering, 2005, 17\(11 1504 8] Assaf Schuster, Ran Wolff, Dan Trock. A highperformance distributed algorithm for mining association rules. Knowledge and Information Systems, 2005, 7\(4 458-475 9] Mohammed J. Zaki. Mining Non-Redundant Association Rules. 2004, 9\(3 10] J.Han, J.Pei, Y.Yin, Mining frequent patterns without candidate generation, Proceedings ACM SIGMOD 2000 Dallas, TX, May 2000: 1-12 11] P.Viola, M.Jones. Rapid Object Detection Using A Boosted Cascade of Simple Features. Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 2001 12] Anthony K. H. Tung, Hongjun Lu, Jiawei Han, Ling FengJan. Efficient Mining of Intertransaction Association Rules. 2003, 154\(1 178 


For each vertex b in g form j forests body\(a, g, i s.t. bodyAnt\(a, g, i a, g, i with itemsets Ant\(b b and each subset of itemsets Ant\(b b in P\(a, g, j Assign to each leaf l of trees bodyAnt\(a, g, i bodyCons\(a, g, i a fresh variable Vm,M, m, M = size\(itemset\(l Assign to each leaf l of tree headAnt\(a, g, j the variable assigned to itemset l in some leaf of some tree bodyCons\(a, g, i TABLE II.  EXPERIMENTAL DATA Conf. #rules #pruned #dftrs PtC 0.5 6604 2985 1114 0.6 2697 2081 25 0.75 1867 1606 10 0.8 1266 1176 0 0.95 892 866 1 0.98 705 699 1 DSP 0.5 2473 1168 268 0.6 1696 869 64 0.75 1509 844 89 0.8 1290 1030 29 0.95 1032 889 15 0.98 759 723 1 Arry 0.5 770 492 82 0.6 520 353 60 0.75 472 327 39 0.8 408 287 22 0.95 361 255 25 0.98 314 243 30  Our induction algorithm has been launched for each combination of thresholds. Our scheme eliminates all redundant rules in the sense of [25, 31], i.e. those association rules that are not in the covers. All the meta-rule deductive schemes implicitly included in [25] and [31] are induced by our method. The percentage of pruning, thus, outperforms [25 


The results produced for k=3, support 0.25 and confidences between 0.7 and 0.99 are shown in Fig. 3, in terms of pruning percentage \(vertical axis when applied to low confidences \(from 0.7 to 0.9 The percentage of pruning achieved diminishes as the confidence is superior to 0.9. Nevertheless, the pruning is effective with confidence of 0.99 in the majority of cases Pruning at Support = 0.25 0,00 5,00 10,00 15,00 20,00 25,00 30,00 35,00 40,00 45,00 50,00 0,7 0,8 0,9 0,95 0,99 Confidence P ru n in g L e v e l Case 1 Case 2 Case 3  Figure 3.  Pruning experiences at support 0.25  V. DISCUSSION AND CHALLENGES It is important to discuss the technique presented here with focus on the purpose the technique pursues:  to produce semantic recommendation The reader should have noticed that the algorithm presented 


relies strongly on "choice". For instance, the algorithm chooses ears in the graph to form an order for elimination, and the choice is arbitrary. This strategy is essential to maintain low complexity \(polynomial practical. Nevertheless, a warned reader may conclude that this arbitrary choice implies that there are many compactions to produce and therefore the approach as a whole does not show to produce an optimal solution. And the reader is right in this conclusion. Since the goal is compaction, the search for an optimal solution can be bypassed provided a substantial level of pruning is achieved To complete the whole view, we describe how web service descriptions are complemented with the association rules as recommendations. In effect, under our scheme, the document describing the web service is augmented with a set of OWL/RDF/S triples that only incorporate the non-pruned rules with the format of Example 1, that is, the set ARmin of the compaction program obtained by our algorithm, together with the thresholds applied to the mining process and a registered URI of a registered description service. The assumptions and defeaters are not added to the web service description. If the associations encoded in the triples are not sufficient for the client \(a search engine, for instance widening of the response to the description service identified by the given URI, and then the assumptions and defeaters are produced. The reasoning task required for deriving all the implicitly published rules is client responsibility Notice that, under this scheme, the actual rules that appear as members of the set initial ARmin set are irrelevant; the only important issue is the size of the set The developed scheme also supports an extension of the algorithm that admits the assignment of priorities to rules and to itemsets, in order to allow the user to produce a more controlled program as output. Nonetheless, the importance of the extension has not been already tested, and therefore it is beyond the subject of the present paper It would be also interesting to design a scheme that supports queries where the client provides an itemset class and values for support and confidence and the engine produces a maximal class of inferred associated itemsets as a response. This scheme is also under development, so we have not discussed this aspect here 


VI. CONCLUSION In this paper, we have presented a defeasible logic framework for managing associations that helps in reducing the number of rules found in a set of discovered associations. We have presented an induction algorithm for inducing programs in our logic, made of assumption schemas, a reduced set of association rules and a set of counter-arguments to conclusions called defeaters, guaranteeing that every pruned rule can be effectively inferred from the output. Our approach outperform those of [17], because all reduction compactions presented there can be expressed and induced in our framework, and several other patterns, particular to the given datasets, can also be found. In addition, since a set of definite clauses can be obtained from the induced programs, the knowledge obtained can be modularly inserted in a richer inference engine Abduction can be also attempted, asking for justifications that explain the presence of certain association in the dataset The framework presented can be extended in several ways Admitting defeaters to appear in the head of assumption, to define user interest Admitting arithmetic expressions within assumptions for adjustment in pruning Admitting set formation patterns as itemset constants Extending the scope, to cover temporal association rules REFERENCES 1]  R. Agrawal, and R. Srikant: Fast algorithms for mining association rules In Proc. Intl Conf. Very Large Databases. \(1994 2]  A. V. Aho, J. E. Hopcroft, J. Ullman. The design and analysis of computer algorithms, Addison-Wesley, 1974 3]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher, A. Rock: A Family of Defeasible Reasoning Logics and its Implementation. ECAI 2000: 459-463 4]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher: Representation results for defeasible logic. ACM Trans. Comput. Log. 2\(2 2001 5]  A. Basel, A. Mahafzah, M. Al-Badarneh: A new sampling technique for association rule mining, Journal of Information Science, Vol. 35, No. 3 358-376 \(2009 6]  R. Bayardo and R. Agrawal: Mining the Most Interesting Rules. In Proc of the Fifth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 145-154, \(1999 


7]  R. Bayardo, R. Agrawal, and D. Gunopulos: Constraint-based Rule Mining in Large, Dense Databases. Data Mining and Knowledge Discovery Journal, Vol. 4, Num-bers 2/3, 217-240. \(2000 8]  A. Berrado, G. Runger: Using metarules to organize and group discovered association rules. Data Mining and Knowledge Discovery Vol 14, Issue 3. \(2007 9]  S. Brin, R. Motwani, J. Ullman, and S. Tsur: Dynamic itemset counting and implication rules for market basket analysis. In Proc. ACMSIGMOD Intl Conf. Management of Data. \(1997 10] L. Cristofor and D.Simovici: Generating an nformative Cover for Association Rules. In ICDM 2002, Maebashi City, Japan. \(2002 11] Y. Fu and J. Han: Meta-rule Guided Mining of association rules in relational databases. In Proc. Intl Workshop on Knowledge Discovery and Deductive and Object-Oriented Databases. \(1995 12] B. Goethals, E. Hoekx, J. Van den Bussche: Mining tree queries in a graph. KDD: 61-69. \(2005 13] G. Governatori, D. H. Pham, S. Raboczi, A. Newman and S. Takur: On Extending RuleML for Modal Defeasible Logic. RuleML, LNCS 5321 89-103. \(2008  14] G. Governatori and A. Stranieri. Towards the application of association rules for defeasible rules discovery In Legal Knowledge and Information Systems, JURIX, IOS Press, 63-75. \(2001 15] J. Han, J. Pei and Y. Yin: Mining frequent patterns without candidate generation. In Proc. ACM-SIGMOD Intl Conf. Management of Data 2000 16] C. Hbert, B. Crmilleux: Optimized Rule Mining Through a Unified Framework for Interestingness Measures. DaWaK: LNCS 4081, 238247. \(2006 17] E. Hoekx, J. Van den Bussche: Mining for Tree-Query Associations in a Graph. ICDM 2006: 254-264 18] R. Huebner: Diversity-Based Interestingness Measures For Association Rule Mining. Proceedings of ASBBS Volume 16 Number 1, \(2009 19] B. Johnston, Guido Governatori: An algorithm for the induction of defeasible logic theories from databases. Proceedings of the 14th Australasian Database Conference, 75-83. \(2003 20] P. Kazienko: Mining Indirect Association Rules For Web Recommendation. Int. J. Appl. Math. Comput. Sci., Vol. 19, No. 1, 165 186. \(2009 21] M. Klemettinen, H. Mannila, P. Ronkainen, H. Toivonen, and A Verkamo: Finding interesting rules from large sets of discovered association rules. In Proc. 3rd Intl Conf. on Information and Knowledge 


Management. \(1994 22] M. J. Maher, A. Rock, G. Antoniou, D. Billington, T. Miller: Efficient Defeasible Reasoning Systems. International Journal on Artificial Intelligence Tools 10\(4 2001 23] C. Marinica, F. Guillet, and H. Briand: Post-Processing of Discovered Association Rules Using Ontologies. The Second International Workshop on Domain Driven Data Mining, Pisa, Italy \(2008 24] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal: Closed sets based discovery of small covers for association rules. In Proc. BDA'99 Conference, 361-381 \(1999 25] N. Pasquier, R. Taouil, I. Bastide, G. Stume, and  L. Lakhal: Generating a Condensed Representation for Association Rules. In Journal of Intelligent Information Systems, 24:1, 29-60 \(2005 26] P. Pothipruk, G. Governatori: ALE Defeasible Description Logic Australian Conference on Artificial Intelligence.  110-119 \(2006 27] J. Sandvig, B. Mobasher Robustness of collaborative recommendation based on association rule mining, Proceedings of the ACM Conference on Recommender Systems \(2007 28] W. Shen, K. Ong, B. Mitbander, and C. Zaniolo: Metaqueries for data mining. In Fayaad, U. et al. Eds. Advances in Knowledge Discovery and Data Mining. \(1996 29] I. Song, G. Governatori: Nested Rules in Defeasible Logic. RuleML LNCS 3791, 204-208 \(2005 30] H. Toivonen, M. Klemettinen, P. Ronkainer, K. Hatonen, and H Mannila: Pruning and grouping discovered association rules. In ECML Workshop on Statistics, Machine Learning and KDD. \(1995 31] M. Zaki: Generating Non-Redundant Association Rules. In Proc. of the Sixth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 34-43, \(2000 32] w3c. OWL Ontology Web Language Reference. In http://www.w3.org/TR/2004/REC-owl-ref-20040210 33] w3c. RDF/XML Syntax Specification. In: http://www.w3.org/TR/rdfsyntax-grammar 34] w3c. RDF Schema. In: http://www.w3.org/TR/rdf-schema      


 8   2  3\f            8  D    F  \b 1 8 & #J      b 1  1  4    2  


4 1    9  E 1  2 4 1    9 1   4      8 2  8 1  D 1        1 1  b 


     b b b b b  K            8          2 D 9   F  \b 1 8 ,+J  9 


     b 1     1 2  9 1  12 L 1   9  8       1  2      2   


     b b b b b  K            2  0 \b f  b\f      9       


  8 2   E 1   1     M13 31L 1    b  8E 1   1 #3\b?### 1  1     E 1   1 \b?###3        


1   1   b 1  2 2 18 2     8              1    2 \b 1    2  


    2          2   1 L 2 1   1   L 2 2    2 1  2        


    8  2H D \b A             2  2H D \b A 2 \f 3%\f  f   4%\f f !  , \f\b  C    2    2 


 6    3 1      253 6   1 L 2    6   1         f\b3\f       


               1     1     8 2    E       2  1   


     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



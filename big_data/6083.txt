2010 International Conference on Computer, Mechatronics, Control and Electronic Engineering CMCE User Attention Items Recommendation and Personalized Information Service Based on "Chinese Sciencepaper Online Huanli Pang!, Qiong wu2, Le Liu3 1 College of Computer Science and Engineering Changchun University of Technology Changchun, China e-mail:panghuanli@mail.ccut.edu.cn 2 College of Computer Science and Engineering Changchun University of Technology Changchun, China e-mail:25490940@sina.com 3 College of Computer Science and Engineering Changchun University of Technology Changchun, China e-mail: bigbiggirl2005@163.com A?ersonalized information service works for different service mode from users' different needs, to help users obtain resources information quickly, promptly and effectively. Based on 'Chinese Sciencepaper Online', users give the weights according to each item of attention degree that is concerned. This article introduces the user attention to show the tendency when the user make the choice. We combine together the tendency with the association rules when defining. It will overcome the combination of association rules of credibility of the disadvantage of low accuracy recommended, so as to provide more accurate user recommended attention KeywolYls-welgltleti llSSocifllioll,' IISt!I' IlIImtlo pe1'Solllllketi senlce I. INTRODUCTION With the rapid development of Internet, more and more resource information continuously added to the network. However, information on the Internet is too bulky, users do not know how to access the content for 


their own need. Access to the Internet a common way to obtain information is view. This method is suitable for the situation that purpose here is not clear, when the user needs to fmd a specific content, efficiency of the method is very poor. Therefore, it is expected that more efficient tools for the emergence of information services to help users quickly items of concern it may set Literature [5] use based on the nearest neighbor users collaborative filtering technology recommended for users But in practice its shortcomings of the sparsity and scalability are gradually exposed.In literature [I according to the similarity between the project preliminary forecast the score which the users did not score, calculated on this basis then calculate the target user's nearest neighbor. This method with the number of users and projects increases linearly, system performance and scalability is still poor. And when calculate the similarity of the project even the two projects are very similar, but may also be because of the lack of a common assessment of their users, lead to inaccurate of the forecasting project score Association rules are the most commonly used method for found the associations between items and items According to the associations between items and item relationship, be able to find all association rules which meet a certain degree of support and confidence. When the projects recommended for the target user, the first to 978-1-4244-7956-6/10/$26.00 20 1 0 IEEE 181 fmd out all the rules of the user support, the left items of such rules are all in the item sets which he has chosen, and then make the items in the right join the recommended set Ru of condidat, fmally, Ru sort by confidence, if an item appears in the right side of number of rules, take the highest degree of confidence, and will recommend to the user before the N items. The advantages of this method are: \(I static, when use it provide those recommendations to users, they can avoid each recalculation, rules generated in recommended algorithm for association rules can be carried offline in advance, therefore recommend more efficient, which make the performance of the system 


higher efficiency than based on the nearest neighbor users collaborative filtering technology to some extent. \(2 When use the association rules to find the association relationship between two items, unlike literature [I], it is not subject to the common choice of the item number of users, so that it can more accurately fmd the relationships between the items However, the algorithm still has two drawbacks: \(1 the most famous the Apriori algorithm thinks that each item is the item which has the same importance in the whole item set. Virtually the position of every item in the item set is not exactly the same. If one item be selected by many users, it indicates the high degree of concern by the user, and then this items occupies very important position in the whole item set. Another example is a Web documents which published an important notice, when to provide recommendations to the user the recommendation should be to come out. \(2 association rules is according to the habits of all users's choices to establish the link between items, in the recommendation will recommend the after pieces of the rules which has the higher confidence to the user, not considered the concerned about the tendency when the user selects items, recommendations lack certain targeted make recommendation accuracy is less than based on the nearest neighbor users collaborative filtering technology This paper presents a WIR algorithm, that is, user attention items recommendation algorithm based on weighted association rules, to recommend user attention items. We compared the WIR algorithm proposed in this paper with the algorithm in literature [I] by the experiment. Experiment verification, the paper provides a good performance algorithm, and recommends the project to users with the user's click-through rate than the algorithm in the literature [I] has increased CMCE2010 II. USER ATTENTION ITEMS RECOMMENDATION ALGORITHM BASED ON WEIGHTED ASSOCIATION RULES The text for each item given a weight W, using the weighted value of the project reflected the extent of concern of the various items, reflecting the importance of various items in the entire item sets. WIR algorithm is 


based on the improved algorithm [3] in the literature formed. Introduced the concept of user profiles, using algorithm [3] proposed weighted association rules discovery algorithm to discover the relationship between item and item. In the recommendation, in order to reflect the tendency which user tend to select items of interest introduce the concept of concern about the selection, and concern about the selection combined with the confidence to recommend for the target users, to make up for the feature about the traditional recommendation algorithm based on association rules in accordance with the size of confidence broadly recommend to the users its accuracy rate is less than the based on the nearest neighbor users collaborative filtering technology WIR algorithm is divided into two steps: \(1 the weighted association rule discovery algorithm based on user profiles, found that the association between item and item, set for the project to establish the term and term association model; \(2 association rules which the target users supported according to the size of recommendation degrees to provide the project's recommendation for the target users Recommendation is defined as the product of the confidence and the concern about the selection A. Weighted association rules discovery algorithm based on the user pro/1le According to the literature [3] proposed weighted association rules discovery algorithm, set up I as a collection for the items, then the support of the form as A=> B\( A c I, Be I, run B = <II the weighted support 0 -sup = [}?JB w/lSUP\(A? B 1 Among, [ L Wi] is the total weights of all items in 0EAJB A,B, sup\( A ? B Because in the weighted association rules model a subset of frequent item sets may not be frequent, so can not use the nature of Apriori algorithm for any subset in the frequent item must be frequent. This literature[3] also introduced k-expectations, that if the q-item set Y is a subset of a frequent k-item sets \(q < k support of the frequent k-item sets should not be less than 


B \(Y, k y, k B\(Y,k 2 W\(Y,k Among, ro -min-sup is the minImum weighted support; And W \(Y, k W\(Y,k 3 182 Here, Y is a q-itemset, q <k. In the remaining projects set \(1-Y k-q mind for the irl, ir2, ... , irk-q, W \(Y, k item set Y of any k-item sets the maximum possible values In this article, the input data expressed as a R: m x n user-options matrix, the user selects a note of the user concerned, m is the number of users, n is the number of items. R is a 0,1 matrix, fij = I that the first i-users to select the first j entries. And rij =  means no choice of the Set the project set to I = { h, b, ...  , in }, to characterize the importance of items focused on different items for each entry ij is given a weight Wj. Empowerment in a key value to reflect the extent of the project concern the use of the frequency of items selected by the user as to the weights let the user select the item number ij Nj, then Wj = Nj I m and its rounded up. It also introduces the concept of user profiles, user i's profile, said with a row vector Ui, Ui elements for the user has selected an item, the set of vectors Vi shall set all the user profile, with U said Centralized user profile found for Weighted Association Rules algorithm is as follows Algorithm 1 find item weighted association rules Enter the user profile set, the weight of each item Wj minimum confidence min _ conf, minimum weighted support OJ - min - sup; frequent item set L = <I Output weighted association rule sets WAR WAR+-<II II Centralized user profile vector length of the largest Ilvalue of U as a frequent item sets the maximum possible Illength, is also k-support bound the Ilmaximum value k Sizemax = Mat\( size\( U for i = 1 to Sizemax do C = <I> , Li = <I> ; II Ci for a possible subset of Ilfrequent i-item collection, Li for the frequent i-item 


Ilcollection, initially are empty for j = 1 to n do sc\(ij ij Ilusers ij for k = 2 to Sizemax do if sc@ >= B\( {ij },k C 1 <- ij; I I The formation of frequent 1-itemsets Ilmay be frequent k-item subset of the set  for k = 2 to Sizemax do Ck= Link \(Ck-I 1 Ck = Prune \(Ck 2  If \(co _sup \(Ck Lk<- Ck L = L U itemsets L II Frequent k-item set formed Lk ; I I The formation of frequent WAR = Rulesgen\(L 3 The following algorithm \(1 2 3 key processes in detail 1 Ck-I Ck I method is: if Ck-I in each element of the pre-k-2 entries are the same, then the elements of Ck-I division can be connected. For example, in C3 {2,3,4}, {2,3,5} the two elements, then the connection form {2,3,4,5 2 Ck Ck is to connect the Ck generating frequent item in the collection can not be set to delete the element. Remove method is: Calculate the set of Ck in the support of the project number and all the support expected, if a k-item sets the number of less than all of its support for the support of the expectations can be determined later in the traversal of it can not be any frequent subset of items to be deleted. In this process is complete, all may be a subset of frequent item sets of k-item sets constitute the candidate set Ck 3 L L frequent set L generated all of its non-empty subset of L s for each non-empty subset s=>\(L-s 


calculation rules conf, if the conf :::: min _ conf, will be added to the WAR in the weighted association rule sets B. Recommended set if user interests in the production In the weighted association rule discovery algorithm the weights of items is selected by the user through the items to get the frequency reflects the key focus on the degree of concern, but the establishment of the weighted association rule set is based on habits of all users to select items, items of concern to users used to fmd the association between relationship established, if the pure level of confidence to recommend the use can not reflect the user's personality, recommendations for current users should also take into account the objectives of the project when the user selects some of the concerns tend to not simply the customer support of association rules according to rules of confidence after the pieces of the size of direct referral to the user. Therefore, the introduction of choice attention, in their recommendations will choose attention, and rules to combine the recommended level of confidence, reflecting the concern of users tend to select projects Concerned about the degree of choice is based on the idea: When the user has selected an item, then when the user select the other item he has n choices, that the user selected the item h, he may choose to b, also may choose to is, also may select other items. Well, the choice of a relatively high frequency in these options appear should be users tend to be, the more concerned choice In user - option matrix, all the users are as a whole to consider the concerns of the key choices. If some users pre-m options are the same, while the first m + 1 option has n choices, which set Si for the support of the user selected the first i kind of choices, that the user through the fmt i kind of choice, select the frequency of the next item. The average support for each selected as S = :t Sj In' the concerned about the degree of choice of 1=1 the first k \(k = 1,2 ,,,., n P=Skl s After we get the weighted association rules, set up the associated model between the items. When recommend 183 


the target users the focus projects, the first under the item set that the user has selected and the weighted rule sets fmd the weighted association rule set that the item of the user has chosen to support, then calculate concerns the choice of degree \(attention specific algorithm is as follows Algorithm 2 Users concerned about the project recommended set generation algorithm Input: weighted association rules WAR, the minimum recommended degree min Jecom Output: recommendation set R R?<I Select ?{ ij' "., ik }; I I The items of the target user l/has selected for each rule \(A => B if Select c A then I I The Association Rules that Iluser support Calculate the concern in the degree of attention that the user selects the item in Select and then choose the item in B recom = conf\( A=> B if recom:::: min Jecom then R ? B III. EXPERIMENTAL RESULTS AND ANALYSIS In the experiment, using the Web document as a test object, about a Web document as a per item. Use the 400 pages in "Chinese Sciencepaper Online" website as a test set, for convenience of operation; we build an index number for each page. From the historical information of the 400 pages that the users accessed, select the access information of 20 users, which each user in these 20 users at least visited 20 pages. In the test using Given X test method, take X = 0.8, about 80% data of the entire data set as the training set, 20% data as the test set We use the computer has Intel P4 2.4GHz DDR256MB, Windows XP platform, using Java language to implement the WIR algorithm in the text and the algorithm \(referred to as IRP algorithm Literature [1 A. Compare the user hits if the recommended items if the two algorithms In the experiment, using the average rate of recommendation that the user clicks on the recommended 


projects, to measure the accuracy of the algorithm I' k the actual number of users click on the item Item user c IC rate = -----------number of recommended projects The average click rate use each user hits of users with the test data set, the total number of each user hits divided by the number of users to get. Users generally more interest in the previous 7 items that recommend to them and the items after the previous 7 items users will not see how, so in the experiment the number of items recommended by a maximum of 10. We calculated respectively when the recommended number of pages C 2,4,6,8,10 the average click rate of the users, as shown in Table 1 and Figure 1, we can see that the in the text the average click rate of users of the WIR algorithm than IRP algorithm increased 6.68 TABLE I. AVERAGE CLICK RATE recommended WIR IRP number of pages C algorithm algorithm 2 0.376 0.326 4 0.4126 0.3876 6 0.4246 0.409 8 0.51826 0.4996 10 0.556 0.526 0.6 ,-------:--1 0.2 1---------1 L..----=..:cc...J 10 Figure I. average click rate B. Algorithm execution time compared When comparing the performance of algorithms, used to measure the average prediction time, the average prediction time was express by the result of training time and testing time \(corresponding to the learning stage and application stage of the recommended system the number of the forecast project. Performance comparison of two algorithms had shown in Figure 2, in which the horizontal axis as the items of the item set website seconds. When the page number of relatively low, the average predicted time of the use of WIR algorithm is less han the IRP algorithm, but the number of pages gradually mcrease, the average predicted time of the use of WIR algorithm is more and more obvious less than the IRP 


algorithm use the WIR algorithm 20 r-- ----:::::a 15 1--- ...,....11 10 ? ..... ..v-,:::::.. ___ 5 1 o 1-..-,---,---,---,-.-1 20 40 60 80 100 IVIR IRP Figure 2. average forecast time IV. CONCLUSION AND OUTLOOK By establishing a information service platform that oriented user's needs, can improve the effective utilization of network information resources, allowing users to timely, accurate and fast access to the knowledge and information that they actual needs. Algorithm presented in this paper, by give weight to the items in the item set to reflect the extent of the item, reflecting the importance of items in the item set. Because the relationship between the item and item is static, in the establishment of weighted association rule set the complexity of the algorithm is low than based on nearest neighbor collaborative filtering technology. Use the metho of combine the degree of choice attention and association rules confidence to recommend to the users 184 overcome the the shortcomings of the low accuracy of the recommend that simple use the confidence in association rules REFERENCES 1] Deng Ailin, Zhu Yangyong, Shi Bole. A Collaborative Filtering Recommendation Algorithm Based on Item Rating Prediction[J Journal of Software, 2003, 14\(9 2] Li Van. E-Commerce Recommendation Algorithm and Implementation[d]. Shang Hai: Fudan University, 2002 3] Ouyang Weimin, Zheng Cheng, Cai Qingsheng. Discovery of Weighted Association Rules in Databases[J]. Journal of Software 2001, 12\(4 4] X?n? Dongmin, Sh?n Junyi, Song Qinbao. From the Web log mmmg user browsmg preferred browse sub-path[J]. Chinese Journal of Camputers, 2003,23\(11 5] Breese J. Hecheman D. Kadie C. Empirical Analysis of 


Predictive Algorithms for Collaborative Filtering[C]. Preceedings of the 14th Conference on Uncertainty in Artificial Intelligence 1998:43-52  Ruann Pang was born in 1970. He received the Master Degree from Jilin University at 2002. Now he is an associate professor of Changchun University of technology. He is now doing some research work on Artificial Intelligence and Data Mining Qiong Wu was born in 1984. She received the Bachelor Degree from Changchun University of Technology at 2006. Now she is pursuing a Master Degree in Changchun University of Technology. She is now doing some research work on Artificial Intelligence and Data Mining Le Liu was born in 1988. She received the Bachelor Degree from Changchun University of Technology at 2008. Now she is pursuing a Master Degree in Changchun University of Technology. She is now doing some research work on Artificial Intelligence and Data Mining 


efficiently, and fuzzy c-means \(FCM attributes. To evaluate the performance of the proposed algorithm, we compare BitTableAC with other well-known classifiers on accuracy including previous associative classifiers, C4.5 and LIBSVM on 6 test datasets from UCI Machine Learning Repository. The results show that, in terms of accuracy, BitTableAC outperforms others REFERENCES 1] G. Goulbourne, F. Coenen, and P. Leng, "Algorithms for computing association rules using a partial-support tree," Knowledge-Based Systems vol. 13, pp. 141-149, Apr 2000 2] M. J. Zaki, "Scalable algorithms for association mining," Ieee Transactions on Knowledge and Data Engineering, vol. 12, pp. 372-390 May-Jun 2000 3] F. Bonchi, F. Giannotti, A. Mazzanti, and D. Pedreschi, "Efficient breadth-first mining of frequent pattern with monotone constraints Knowledge and Information Systems, vol. 8, pp. 131-153, Aug 2005 4] G. Grahne and J. F. Zhu, "Fast algorithms for frequent itemset mining using FP-trees," Ieee Transactions on Knowledge and Data Engineering, vol 17, pp. 1347-1362, Oct 2005 5] I. I. Artamonova, G. Frishman, and D. Frishman, "Applying negative rule mining to improve genome annotation," Bmc Bioinformatics, vol. 8, pp. -, Jul 21 2007 6] J. W. Han, J. Pei, Y. W. Yin, and R. Y. Mao, "Mining frequent patterns without candidate generation: A frequent-pattern tree approach," Data Mining and Knowledge Discovery, vol. 8, pp. 53-87, Jan 2004 7] Y. C. Hu and G. H. Tzeng, "Elicitation of classification rules by fuzzy data mining," Engineering Applications of Artificial Intelligence, vol. 16, pp 709-716, Oct-Dec 2003 8] J. D. Holt and S. M. Chung, "Mining of association rules in text databases using Inverted Hashing and Pruning," Data Warehousing and Knowledge Discovery, Proceedings, vol. 1874, pp. 290-300, 2000 9] Y. J. Li, P. Ning, X. S. Wang, and S. Jajodia, "Discovering calendar-based temporal association rules," Data & Knowledge Engineering, vol. 44, pp 193-218, Feb 2003 10] Y. J. Tsay and J. Y. Chiang, "CBAR: an efficient method for mining association rules," Knowledge-Based Systems, vol. 18, pp. 99-105, Apr 2005 11] B. Liu, W. Hsu, and Y. Ma, "Integrating Classification and Association Rule Mining," in Proceedings of the Fourth International Conference on Knowledge Discovery and Data Mining, KDD'98, AAAI, New York, 1998, pp. 80-86 12] W. Li, J. Han, and J. Pei, "CMAR: accurate and efficient classification 


based on multiple class association rule," in Proceedings of the 2001 IEEE International Conference on Data Mining, ICDM'01, San Jose, CA, 2001 pp. 369-376 13] D. Janssens, G. Wets, T. Brijs, and K. Vanhoof, "Adapting the CBA algorithm by means of intensity of implication," Information Sciences, vol 173, pp. 305-318, Jun 23 2005 14] W. Song, B. R. Yang, and Z. Y. Xu, "Index-BitTableFI: An improved algorithm for mining frequent itemsets," Knowledge-Based Systems, vol. 21 pp. 507-513, Aug 2008 15] J. Dong and M. Han, "BitTableFI: An efficient mining frequent itemsets algorithm," Knowledge-Based Systems, vol. 20, pp. 329-335, May 2007  532 


 Table I.  Number of intervals Stage Interval No. Stage Interval No EP 7 ES 8 ED 10 EB 9 ET 8 EI 11  Table II.  Results using the proposed approach Stage Bias MMRE MdMRE ES -8.5% 27.0% 17.0 ED -33.1% 40.5% 13.7 EB -2.8% 9.3% 7.5 ET -11.6% 16.7% 7.23 EI -20% 91.0% 30.2  Table III.  Results using exponential regression Stage Bias MMRE MdMRE ES -24.3% 81.3% 49.7 ED -72.3% 120.4% 54.224 EB 0.7% 44.35% 37.6 ET -45.4% 81.1% 39.0 EI -179% 184% 104.0  Results shown in Table III revealed that most of predictions are under estimation which supports our approach findings. The best estimation accuracy was obtained in building stage, which also corroborates our findings that best estimation accuracy was in building stage. The negative values in Bias criterion show underestimation. It is acknowledged that MMRE is unbalanced in many validation circumstances and leads to overestimation more than underestimation. In our case, we found that MMRE leads to underestimation in most stages. This is may be related to the absence of systematic scheme between all prior effort records   253   Figure 1. Effort distribution of Planning stage 


Figure 2. Effort distribution of Specification stage Figure 3. Effort distribution of Design effort stage  Figure 4. Effort distribution of Building stage Figure 5. Effort distribution of Testing stage Figure 6. Effort distribution of Imp stage   Table IV. Statistical significance Stage sum rank Z-value p-Value ES 769 -4.31 <0.01 ED 713 -5.03 <0.01 EB 685 -5.4 <0.01 ET 595 -6.54 <0.01 EI 799 -3.93 <0.01  The comparison between our approach and exponential regression technique showed that there are considerable improvements in estimation accuracy on all phases of software development lifecycle. MMREs of our approach have been reduced by at least 35.05 and at most 93%. Biases have been reduced by at least 3.5% and at most 159%.We have to bear in mind that the length of interval plays important role in estimation accuracy, thus, when the universe of discourse is partitioned into several equal intervals, the distribution of data should be taken into account. Moreover, we should remove the extreme values because they affect interval partitioning, thus, estimation accuracy Figures 7 to 11 show comparison between proposed approach and exponential regression in each stage by using Boxplot. The Boxplot [17] offers a way to compare between estimation models based on their absolute residuals. The Boxplot is non-parametric statistics used to show the median as central tendency of distribution, interquartile range and the outliers of individual models [17]. The length of Boxplot from 


lower tail to upper tail shows the spread of the distribution. The length of box represents the interquartile range that contains 50% of observations The position of median inside the box and length of Boxplot indicate the skewness of distribution. A Boxplot with a small box and long tails represents a very peaked distribution while a Boxplot with long box represents a flatter distribution. The prominent and common characteristic among these figures is the spread of absolute residuals for our approach is less than spread of exponential regression which presents more accurate results. The larger interquartile of exponential regression indicates a high dispersion of the absolute residuals. The Boxplot revealed that the box length for our models is smaller than exponential regression which also indicates reduced variability of absolute residuals. The median of our model is smaller than median of exponential regression which revealed that at least half of the predictions of our model are more accurate than exponential regression 254  Figure 7. Boxplot of absolute residuals for the specification stage  Figure 8. Boxplot of absolute residuals for the design stage   Figure 9. Boxplot of absolute residuals for the building stage Figure 10. Boxplot of absolute residuals for the testing stage   The lower tails of our model is much smaller than upper tail which means the absolute residuals are skewed towards the smaller value Figure 11 illustrates the reason of why prediction of implementation stage in our approach produced the worst accuracy. The reason related to the existing of outlier. Although one project is considered as an outlier the MMRE is easily influenced with that project Based on the obtained results, we can observe that 


exponential regression gave bad accuracy. The reason may relate to the structure complexity of prior effort records. There is no correlation between all prior stages and target stage To ensure that the results obtained are not by chance we investigated the statistical significance of the proposed approach using Wilcoxon sum rank test for absolute residuals as shown in Table IV. In this test if the resulting p-value is small \(p<0.05 statistically significant difference can be accepted between the two samples median. The residuals obtained using the proposed approach were significantly different from those obtained by exponential regression Suggesting that, there is difference if the predications generated using the proposed approach or exponential regression and based on the accuracy comparison in Tables II and III we can safely conclude that our proposed method outperformed exponential regression for stage effort estimation Figure 11. Boxplot of absolute residuals for the implementation stage  VIII. CONCLUSIONS Some of software projects are failed due to the absence of re-estimation during software development which results in huge gap between initial plan and final outcome. Even with good estimate at first stage the project manager must keep update with project progress and should be able to re-estimate the project at any particular point of project in order to re-allocate the proper number of resources. The objective of this paper was to check whether the prior effort records can 255 be used to predict stage effort with reasonable accuracy or not. The obtained results revealed that using association rule and Fuzzy set theory lead to significant improvement in stage-effort estimation and give project manager an evolving picture about project progress. Comparing our approach with exponential regression showed that there is a considerable potential in estimation accuracy. As part of future plan, we 


intend to expand this work to involve some interesting features in each stage prediction and evaluate it on many datasets   REFERENCES  1] F. Ricardo, N. Ana, M. Paula, B. Gleidson, R. Fabiano ODE: Ontology-based software Development Environment, Proceedings of the IX Argentine Congress on Computer Science, pp. 1124-1135, 2003 2] E. Mendes, B. A. Kitchenham. Further comparison of cross-company and within-company effort estimation models for Web applications. In: Proc. 10th IEEE International Software Metrics Symposium, Chicago USA, pp.348-357, 2004 3] B. Boehm, R. Valerdi. Achievements and Challenges in Software Resource Estimation, Proceedings of ICSE 06 Shanghai, China, pp. 74-83,  2006 4] K. Molokken, M. Jorgensen. A review of software surveys on software effort estimation, Proceedings of International Symposium on Empirical Software Engineering \(ISESE 2003 5] M. Jorgensen, K. Molokken-Ostvold. How large are software cost overruns? A review of the 1994 CHAOS report, Information and Software Technology, Vol. 48 issue 4. PP. 297-301, 2006 6] X. Huanga, D. Hob, J. Rena, L. F. Capretz. Improving the COCOMO model using a neuro-Fuzzy approach Applied Soft Computing, Vol.7, issue 1, pp. 29-40, 2007 7] L. Briand, T. Langley, I. Wieczorek. A replicated assessment and comparison of common software cost modeling techniques, Proceedings of the 22nd international conference on Software Engineering, 2000 8] S.-J Huang, N. H. Chiu. Optimization of analogy weights by genetic algorithm for software effort estimation Information and Software Technology, Vol. 48, issue 11 pp. 1034-1045, 2006 9] Z. Xu, T. M. Khoshgoftaar. Identification of Fuzzy models of software cost estimation, Fuzzy Sets and Systems, Vol. 145, issue 1, pp. 141-163, 2004 10] R. Pressman. Software Engineering: practitioner 


approaches, McGraw Hill, London, 2004 11] M. Boraso, C. Montangero, H. Sedhi. Software cost estimation: an experimental study of model performance Universita di Pisa, Italy, 1996 12] Y. Wang, Q. Song, J. Shen., 2007. Grey Learning Based Software Stage-Effort Estimation. International Conference on Machine Learning and Cybernetics, pp 1470-1475, 2007 13] S. G. MacDonell, M. J. Shepperd. Using prior-phase effort records for re-estimation during software projects Ninth International, Software Metrics Symposium, pp 73- 86, 2003 14] M .C Ohlsson, C. Wohlin. An Empirical Study of Effort Estimation during Project Execution, Sixth International Software Metrics Symposium \(METRICS'99 1999 15] N. H. Chiu,,S. J. Huang.  The adjusted analogy-based software effort estimation based on similarity distances Journal of Systems and Software, Vol. 80, issue 4, pp 628-640, 2007 16] P. Sentas, L. Angelis, I. Stamelos, G.  Bleris. Software productivity and effort prediction with ordinal regression Information and Software Technology, Vol. 47, issue 1 pp. 17-29, 2005 17] E. Mendes, N. Mosley. Comparing effort prediction models for Web design and authoring using boxplots Australian Computer Science Communications,  Vol. 23 Issue 1, pp. 125-133, 2001 18] E. Mendes, N. Mosley, I. Watson. A comparison of casebased reasoning approaches, Proceedings of the 11th international conference on World Wide Web, pp. 272280, 2002 19] Q. Zhao, S. S. Bhowmick. Association Rule Mining: A Survey  http://citeseer.ist.psu.edu/734613.html, 2003 20] S. Morisak, A. Monden, H. Tamada. An Extension of association rule mining for software engineering data repositories, Information Science Technical Report NAIST, 2006 21] Q. Song, M. Shepperd.  M. Cartwright, C. Mair. Software defect association mining and defect correction effort prediction, IEEE transaction on software engineering Vol. 32, No.2, pp. 69-82, 2006 


22] R. Agrawal, T. Amielinski, A. Swami. Mining association rule between sets of items in large databases Proceedings of the ACM SIGMOD International Conference on Management of Data, pp. 207-216, 1993 23] M-J. Huang, Y-L. Tsou, S-C. Lee.  Integrating Fuzzy data mining and Fuzzy artificial neural networks for discovering implicit knowledge, J. Knowledge-Based Systems, Vol.19 \(6 24] ISBSG International Software Benchmarking standards Group, Data repository release 10, Site http://www.isbsg.org, 2007 25] L. Zadeh. Toward a theory of Fuzzy information granulation and its centrality in human reasoning and Fuzzy logic. J. Fuzzy sets and Systems 90, pp. 111-127 1997 26] I. H. Witten, E. Frank. Data Mining: Practical machine learning tools and techniques, 2nd Edition, Morgan Kaufmann, San Francisco, 2005   256 


encountering a related term, i.e. IC\(c e intuition behind the use of the negative likelihood is that the more probable a term to appear, the less information it conveys. All these features show that Jiangs measure tends to be more general and more appropriate for evaluating nontaxonomically related terms. Indeed, a high score of the relatedness measures suggests a strong relationship between terms Nevertheless, all relatedness measures have limitations because they assume that all the semantic content of a particular term is modeled by semantic links in WordNet Consequently, in many situations, truly related terms obtain a low scores even though their belongings to a certain category of tags, e.g., jargon tags Additionally, when measuring the quality of an automatically knowledge acquisition results, the typical measures used in Information Retrieval are Recall, Precision and F-Measure. However, computing Recall and F-Measure requires the availability of a Gold Standard. Hence, we will only compute the Precision which speci?es to which extent the non-taxonomic relationships is extracted correctly. In this case, the ratio between the correctly extracted relations i.e., their relatedness measures is greater than or equal to a minimum threshold, and the whole number of extracted ones is computed. Thus, we have Precision Total correctly selected entities Total selected entities 12 http://search.cpan.org/dist/WordNet-Similarity 13 A term refers to a tag subject or a tag object C. Evaluation of non-taxonomic relationships Only a percentage of the full set of non-taxonomic relationships \(89 is caused by the presence of non standard terms which are not contained in WordNet and, in consequence, cannot be evaluated using WordNet-based relatedness measures. Fig. 5 depicts the evaluation results of the extracted non-taxonomic relationships against their relatedness measures High relatedness score \(88 17% of the extracted relationships, as most of terms are strongly related with respect WordNet Null Scores were obtained for 5% of the extracted 


relationships. Analyzing this case in more detail, we have observed that the poor score is caused in many situations by the way in which Jiangs distance metric works. This latter completely depends on the distance between two terms based on the number of edges found on the path between them in WordNet. In consequence this measure returns a value that does not fully represent reality. For example, on the one hand, Jiangs distance metric returns a null value for the relationship between insurance and car, even though the ?rst is a commonly related to the second, i.e., car involved insurance Finally with a minimal Jiangs distance metric threshold, set to 46%, the computed precision of correctly extracted relationships candidates is equal to 68.8 An example of extracted non-taxonomic relationships is depicted in Table V where each relation describes the subject tag, e.g., tool, the predicate, e.g is being developed within, and the object tag, e.g mesh. Fig. 4 represent a fragment output of the extracted ontological structure where each concept de?nes a set of similar and synonym tags and labels, i.e., mentions has been, revealed, caused and is created with describe the predicates of the non-taxonomic relationships between terms Due to the limitations observed by the automatic evaluation procedure and the lack of gold standards containing non-taxonomic relationships, we have examined the extracted non-taxonomic relationships from a linguistic point 377 Top space      distance     quad great     groovy nifty caused address      addresses extension      quotation   reference  references extensions        referenz     source      refrence sources    rfrences    quotations research    search     searching searchs open-source     open_source 


opensource linux aim     design     designer      designers patern    project     patterns     projekte projects web+design    web_design webdesign internet       internetbs net          web network      networking networks      web discussion     news       password word      words community      communities is_created_with mentions revealed has_been Figure 4. A fragment output of the extracted ontological structure of view. This qualitative evaluation can bring some interesting insights about the kind of results one can expect Invalid relations are extracted: Even though a relation such as music cities skill is considered as correct one since tag subject, tag object and predicate are correctly extracted. From a semantic point of view, this relation has no meaning. Hence, a higher precision is expected Figure 5. Summary of non-taxonomic evaluation measure Table V EXAMPLES OF EXTRACTED NON TAXONOMIC RELATIONSHIPS Subject Predicate Object search has been reference reference mentions search tool is being developed within mesh security added encoding search revealed reference java provides library by performing the sense analysis on complete relations An ambiguity in the extracted predicates between terms is observed: Hence, same relations are redundant since they use a synonym predicates between terms, e.g java provides library and java yields library. Thus we expect that the redundancy removal within extracted relations will be of bene?t for the improvement of the 


obtained results VI. CONCLUSION AND FUTURE WORK The extraction of non-taxonomic relationships from folksonomies is to the best of our knowledge is the least tackled task within ontology building from folksonomy. This is why there is a need of novel and general purpose approaches covering the full process of learning relationships. In this paper, we introduced a new approach called NONTAXFOLKS that starts by pre-processing tags aiming at getting a set of frequent tagsets corresponding to an agreed representation Then, they are used to retrieve related tags using external resources such as WordNet. Thanks to the particular structure of triadic concepts, it allows grouping semantically related tags by considering the semantic relatedness embodied in the different frequencies of co-occurences among users, resources and tags in the folksonomy. Thereafter we introduced an algorithm called NTREXTRACTION for extracting non-taxonomic relationships between pair of tags picked from the triadic concepts. In summary, our approach uses several well known techniques \(such as formal concept analysis or association rule discovering the social bookmaring environnement in order to propose a new way of extracting labeled non-taxonomic relationships between tags. Currently, we are investigating the following topic concerning the discovered predicates between two terms. Indeed, in order to avoid relationships redundancy and thus a redundancy in the builded ontology. One can try to classify them into prede?ned semantic classes, detect synonyms, inverses, etc. A standard classi?cation of verbs could be used for this purpose, adding additional information about the semantic content, e.g., senses, verb types, thematic roles, etc., of predicates relationships 378 REFERENCES 1] J. Pan, S. Taylor, and E. Thomas, Reducing ambiguity in tagging systems with folksonomy search expansion, in Proceedings of the 6th Annual European Semantic Web Conference \(ESWC2009 2] V. S. M. Kavalec, A. Maedche, Discovery of lexical entries for non-taxonomic relations in ontology learning, in Proceedings of the SOFSEM 2004, LNCS, vol. 2932, 2004, pp 249256 


3] L. Specia and E. Motta, Integrating folksonomies with the semantic web, in Proceedings of the 4th European Semantic Web Conference \(ESWC 2007 Innsbruck, Austria, vol. 4519, June 2007, pp. 624639 4] P. Mika, Ontologies are us: A uni?ed model of social networks and semantics, in Proceedings of the 4th International Semantic Web Conference \(ISWC2005 3729, Galway, Ireland, June 2005, pp. 522536 5] P. Schmitz, Inducing ontology from ?ickr tags, in Proceedings of the Workshop on Collaborative Tagging \(WWW 2006 Edinburgh, Scotland, May 2006 6] M. Zhou, S. Bao, X. Wu, and Y. Yu, An unsupervised model for exploring hierarchical semantics from social annotations, in Proceedings of the 6th International Semantic Web Conference and 2nd Asian Semantic Web Conference ISWC/ASWC2007 Korea, vol. 4825, November 2006, pp. 673686 7] C. Schmitz, A. Hotho, R. Jaschke, and G. Stumme, Mining association rules in folksonomies, in Proceedings of the 10th IFCS Conference \(IFCS 2006 2006, pp. 261270 8] A. Hotho, A. Maedche, S. Staab, and V. Zacharias, On knowledgeable unsupervised text mining, in Proceedings of Text Mining Workshop, Physica-Verlag, 2003, pp. 131152 9] A. Hotho, R. Jaschke, C. Schmitz, and G. Stumme, Information retrieval in folksonomies: Search and ranking, in The Semantic Web: Research and Applications, vol. 4011 Springer, 2006, pp. 411426 10] F. Lehmann and R. Wille, A triadic approach to formal concept analysis, in Proceedings of the 3rd International Conference on Conceptual Structures: Applications, Implementation and Theory. Springer-Verlag, 1995, pp. 3243 11] R. Jaschke, A. Hotho, C. Schmitz, B. Ganter, and G.Stumme Discovering shared conceptualizations in folksonomies Web Semantics: Science, Services and Agents on the World Wide Web, vol. 6, pp. 3853, 2008 12] A. Mathes, Folksonomies - cooperative classi?cation and communication through shared metadata, Graduate School of Library and Information Science, University of Illinois Urbana-Champaign, Tech. Rep. LIS590CMC, December 2004 13] H. Lin, J. Davis, and Y. Zhou, An integrated approach 


to extracting ontological structures from folksonomies, in Proceedings of the 6th European Semantic Web Conference ESWC 2009 vol. 5554, 2009, pp. 654668 14] M. Szomszor, H. Alani, K. OHara, and N. Shadbolt, Semantic modelling of user interests based on cross-folksonomy, in Proceedings of the 7th International Semantic Web Conference \(ISWC 2008 15] G.Begelman, P. Keller, and F.Smadja, Automated tag clustering: Improving search and exploration in the tag space, in Proceedings of the the Collaborative Web Tagging Workshop WWW 2006 16] R. Jaschke, A. Hotho, C. Schmitz, B. Ganter, and G. Stumme TRIAS - an algorithm for mining iceberg tri-lattices, in Procedings of the 6th IEEE International Conference on Data Mining, \(ICDM 2006 2006, pp. 907911 17] C. Borgelt, Ef?cient implementation of APRIORI and ECLAT, in FIMI, COEUR Workshop Proceedings, COEURWS.org, vol. 126, 2003 18] J. Tang, H. Leung, Q. Luo, D. Chen, and J. Gong, Towards ontology learning from folksonomies, in Proceedings of the 21st international jont conference on Arti?cal intelligence IJCAI 2009 20892094 19] L. Ding, T. Finin, A. Joshi, R. Pan, R. Cost, Y. Peng P. Reddivari, V. Doshi, and J. Sachs, Swoogle: A search and metadata engine for the semantic web, in Proceedings of the 13th ACM Conference on Information and Knowledge Management, ACM Press, 2004, pp. 652659 20] A. Hliaoutakis, G. Varelas, E. Voutsakis, E. Petrakis, and E. E Milios, Information retrieval by semantic similarity, International Journal on Semantic Web and Information Systems IJSWIS 21] G. Pirro, M. Ruffolo, and D. Talia, Secco: On building semantic links in peer to peer networks, Journal on Data Semantics XII, LNCS 5480, pp. 136, 2009 22] C. Meilicke, H. Stuckenschmidt, and A. Tamilin, Repairing ontology mappings, in Proceedings of the International Conference AAAI 2007, Vancouver, British Columbia, Canada 2007, pp. 14081413 23] S. Ravi and M. Rada, Unsupervised graph-based word sense 


disambiguation using measures of word semantic similarity in Proceedings of the International Conference ICSC 2007 Irvine, California, USA, 2007 24] H. G. A. Budanitsky, Semantic distance in wordnet: an experimental application oriented evaluation of ?ve measures in Proceedings of the International Conference NACCL 2001 Pittsburgh, Pennsylvania, USA, 2007, pp. 2934 25] J. Jiang and D. Conrath, Semantic similarity based on corpus statistics and lexical taxonomy, in Proceedings of the International Conference ROCLING X, 1997 379 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



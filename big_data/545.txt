Improving Image Resolution with Edge-Targeted Filter Evolution  Michael R Peterson and Gary B Lamont Department of Electrical and Computer Engineering Graduate School of Engineering and Management U.S Air Force Institute of Technology 2950 Hobson Way Bldg 640 Wright-Patterson AFB OH 45433-7765 937-255-3636 f Michael.Peterson,Gary.Lamont g a\002t.edu Abstract\227 Government commercial scienti\002c and defense applications in image processing often require transmission of large amounts of data across bandwidth-limited channels Applications require robust transforms simultaneously minimizing bandwidth requirements and image resolution loss Image processing algorithms take advantage of quantization to provide substantial lossy compression ratios at the expense 
of resolution Recent research demonstrates that genetic algorithms evolve 002lters outperforming standard discrete wavelet transforms in conditions subject to high quantization error While evolved 002lters improve overall image quality wavelet 002lters typically provide a superior high frequency response demonstrating improved reconstruction near the edges of objects within an image This paper presents an algorithm to generate transform 002lters that optimize edge reconstruction improving object edge resolution by an average of 17 Edges within satellite images are isolated and image transforms are evolved to optimize both the edge and non-edge portions of reconnaissance photographs Such 002lters provide an increased object resolution over standard wavelets and traditionally evolved 002lters for varied applications of image processing 
T ABLE OF C ONTENTS 1 I NTRODUCTION                                    1 2 B ACKGROUND                                      2 3 M ETHODOLOGY                                   4 4 P RELIMINARY E XPERIMENTS 
                    7 5 R ECONSTRUCTION A DJACENT TO E DGES        9 6 R ECONSTRUCTION N ONADJACENT TO E DGES    11 7 D ISCUSSION                                        12 8 C ONCLUSIONS                                     
12 A CKNOWLEDGEMENTS                            13 R EFERENCES                                      13 B IOGRAPHY                                        14  1-4244-1488-1/08 25  00 c 015 2008 IEEE IEEEAC Paper 1363 Version 1 Updated 10/22/2007 
1 I NTRODUCTION Image and signal processing are active areas of defense and scienti\002c research Satellites and unmanned aerial vehicles 050UAVs\051 potentially collect and transmit huge volumes of data during reconnaissance missions Sonar and radar systems process huge amounts of sensor data in real time Deep-space probes require robust data encoding algorithms to compensate for noise induced by electromagnetic interference or solar radiation In each case the need to minimize mission cost while maximizing performance motivates the development of compression techniques that simultaneously minimize bandwidth and storage requirements while maintaining maximum signal information With these requirements in mind quantization is often necessary for military industrial and scienti\002c digital signal processing 050DSP\051 applications Shannon's theorem places lim 
its on the amount of compression achievable by any lossless encoding algorithm In order to achie v e higher rates of compression through higher energy compaction than lossless encoders allow algorithms must permit some loss of information Quantization 050Q\051 minimizes storage requirements by mapping all values in signal x to a small alphabet of values Q 050 x 051  Smaller alphabets pro vide greater compression b ut result in greater data loss Perfect reconstruction of x from Q 050 x 051 is impossible due to the loss of data in low-order bits  Wavelets  are a standard methodology for signal compression algorithms The discrete wavelet transform 050DWT\051 re 
distributes the energy in a signal by transforming a time signal into a time-frequency domain A signal may be compressed by 002rst applying the DWT followed by quantization and then by applying entropy coding Signals are reconstructed in a reverse manner Most information loss occurs during quantization Note that wavelets have become a popular technique for image coding and pro vide the algorithmic basis for the JPEG 2000 image compression standard While wavelet performance degrades at high quantization levels optimized 002lters replacing wavelet coef\002cients may 1 


improve image resolution This paper demonstrates that while 002lters optimized using previously published techniques improve the overall mean-squared error 050MSE\051 of reconstructed images the resulting resolution near the edges of objects may be further re\002ned For reconnaissance and intelligence-gathering applications the resolution of object edges is crucial for identi\002cation and analysis We propose an algorithm for the evolution of 002lters designed speci\002cally for reconstructing the portions of images both near and away from object edges By reconstructing different areas of decomposed images the resulting 002lter combinations provide improved object resolution and provide greater MSE reduction than either wavelets or traditionally optimized 002lters alone provide 2 B ACKGROUND This research investigation is primarily based upon the discrete wavelet transform and evolutionary computation techniques which are brie\003y discussed below The Discrete Wavelet Transform In ideal conditions the DWT 000 1 algorithm provides nearperfect reconstruction of a DWT-decomposed image signal However for some applications higher compression ratios are required than can be achieved by DWT decomposition and entropy encoding alone In such cases a quantizer transforms the DWT-decomposed signal to a smaller alphabet before entropy encoding A corresponding dequantizer translates the decoded signal back to the original alphabet before image reconstruction via the DWT 000 1 algorithm This process is demonstrated in 002gure 1 Figure 1  A wavelet-based image compression model A DWT convolves a signal against speci\002c wavelet instances at various time scales and positions resulting in a compressed representation of the original signal The compression is reversed via the corresponding DWT 000 1 by convolving the compressed signal against an inverted order of the original wavelet instances to produce an approximation of the original signal Wavelets conserve energy and redistribute the bulk of that energy to the 223\002rst trend\224 subsignal Most of the transformed signal's remaining values outside of the 002rst trend are insigni\002cant and may be eliminated without significant loss of information providing a favorable compression rate at the expense of perfect reconstruction A scaling function 036 050 t 051 and a wavelet function  050 t 051 characterize any DWT as follows 036 050 t 051  X n h n 036 0502 t 000 n 051 0501\051  050 t 051  X n g n 036 0502 t 000 n 051 0502\051 where h n is the scaling 002lter's impulse response g n is the wavelet 002lter's impulse response and n is the translation parameter The scaling number set h 1  f h n g and wavelet number set g 1  f g n g provide coef\002cients corresponding to the projection of the basis functions for the DWT's low-pass and high-pass 002lters 4 pp h 1 and g 1 for the Daub4 wavelet are shown in equations 3 and 4 where P  4 is the size of each set and n  1 P is the position of the coef\002cient within the ordered set The Daub4 wavelet presented here is used for image decomposition and is the basis for evolved image reconstruction transforms developed in this research investigation h 1  f p  2 003 0501  p  3\051  8  p  2 003 0503  p  3\051  8  p  2 003 0503 000 p  3\051  8  p  2 003 0501 000 p  3\051  8 g 0503\051 g 1 024 000 1 n 003 h 1 f P 000 n g 0504\051 Sets h 2 and g 2  consisting of mirror images of sets h 1 and g 1  de\002ne the DWT 000 1 The inverse transform reconstructs an approximation of the original signal by convolving the compressed signal using h 2 and g 2  For image applications a two-dimensional 0502D\051 DWT compresses a discrete image f consisting of M rows and N columns by 002rst applying a one-dimensional 0501D\051 DWT to the columns of f and then repeating the transform for the rows  A 2D D WT 000 1 reconstructs the image by applying a 1D DWT 000 1 002rst to the rows and then to the columns of the compressed signal Let image f have dimensions M and N A single level DWT applied to f results in subimages a 1  h 1  d 1  and v 1  each of size M/2 by N/2 a 1 is the 002rst trend subimage of f  concentrating most of the information in f  The remaining subimages h 1  d 1  and v 1 are its 002rst horizontal diagonal and vertical 003uctuation subimages Containing most of the information in a 1 results in improved compression obtained during entropy coding The small values in the 003uctuation subimages require fewer bits to encode By employing multiresolution analysis 050MRA\051 the DWT may be applied up to k 024 log 2 050min\050 M N 051\051 times The DWT is recursively applied to a 1 i 000 1  where i is the current level of decomposition When i  1  a i 0 is the original image f  By applying multiple decomposition steps the majority of the energy within the 2 


image signal is restricted to smaller trend subimages minimizing the data to encode MRA reconstruction occurs in reverse order of decomposition by combining the subimages at level i  applying the DWT 000 1 to obtain a i 000 1 0  and repeating until the image is reconstructed In a typical wavelet coding system the signal 015 emerging from the DWT is quantized 050see 002gure 1\051 015 is mapped onto a restricted alphabet Q 050 015 051  The quantized signal is not changed by entropy encoding and decoding assuming the use of a lossless encoder such as standard Huffman encoding Applying dequantization to Q 050 015 051 results in a dequantized signal 015 0 6  015  rendering prefect reconstruction by the DWT 000 1 impossible Evolutionary Computation and Image Transforms Evolutionary algorithms 050EAs\051 are a popular paradigm for numerical optimization By applying Darwinian principles of recombination and natural selection over a number of algorithmic generations initially poor solutions are soon re\002ned into a population of solutions that may be dif\002cult to identify using traditional numeric optimization techniques In recent years evolutionary algorithms have been used in conjunction with wavelets for a variety of signal processing applications including signal approximation s ignal classi\002cation and signal compression and reconstruction 12  EAs have been used in conjunction with wavelets for a number of image processing applications Bruckmann et al employ a binary genetic algorithm 050GA\051 to evolve subband structures for wavelet packet based image compression Hill et al evolve a windowed trigonometric function for use in a continuous wavelet transform In 16 a GA con\002gures a Kohonen self organizing map 050SOM\051 that taken with a wavelet-based 002lter provides robust image texture classi\002cation In a GA applies the lifting technique 18 to design complementary wavelet 002lters The evolved wavelets outperform the standard FBI wavelet for 002ngerprint image compression Moore presents a GA e v olv es digital 002lters e xploiting MRA by initializing the GA population with values near the original DWT 002lter and then searching for improved 002lters in the neighborhood of the original wavelet through a local mutation mechanism The GA successfully improves image reconstruction both when evolving a single 002lter for all MRA levels or when evolving unique 002lters for each level of MRA wavelet decomposition In related work a GA evolves only the reconstruction coef\002cients of a wavelet-based 002lter to improve image reconstruction in the presence of quantization error By focusing on the e v olution of optimized reconstruction coef\002cients the underlying compression rate of the forward transform is unaffected The resulting 002lters described in 6 no longer conform to the mathematical proper ties of wavelets such as 002lter biorthogonality Evolved with one or more training images the resulting 002lters provide imFigure 2  USAF museum satellite image proved reconstruction when applied to images not explicitly represented by the training image population Our evolutionary approaches of 6 e v olv e 002lters designed to reduce the reconstruction error of an entire image These techniques successfully provide signi\002cant mean squared error 050MSE\051 reduction to their wavelet counterparts typically at the expense of increased error in localized portions of images Consider the satellite image of the U.S Air Force museum in Dayton Ohio in 002gure 2 Figure 3 transformation with a Daubechies-4 050Daub4\051 DWT at one MRA level and a quantization step size of 64 Darker pixels indicate greater error de\002ned as the absolute difference in pixel values between the original image and the reconstructed image Note that the error is fairly evenly distributed across the entire image The Daub4 wavelet achieves 138.13 MSE 1  Using the GA described in a 002lter e v olv ed to impro v e on the Daub4 reconstruction for this image reduces error in the lowspatial frequency areas of the image at the cost of increased error in the high-spatial frequency areas 050i.e near the edges of objects see 002gure 4\051 This image depicts the areas of error between the reconstructed image using the evolved 002lter Increased error occurs near the edges of objects such as the edges of planes and hangars The evolved 002lter reduces the MSE to 107.54 an improvement of 22.15 at the expense of increased error near object edges Ideally evolved 002lters increase the amount of intelligence that can be gathered from reconnaissance images through improved resolution so this loss of edge resolution is undesired Thus this paper presents an approach to reduce reconstruction error near the edges of objects within the reconstructed image without increasing error in the low-spatial frequency areas of the object Improved reconstruction near edges provides improved object resolu 1 MSE aggregates the average squared pixel error between two images and is used as the standard error measurement here and is presented in equation 6 3 


Figure 3  USAF museum Daub4 wavelet reconstruction error Figure 4  USAF museum evolved 002lter reconstruction error tion thus preserving the intelligence that may be gathered from images subject to data loss from high quantization Furthermore reconstruction is improved in the remaining regions of images through use of reconstruction 002lters optimized for reconstruction of pixels not adjacent to edges 3 M ETHODOLOGY Speci\002c structures and algorithms employed and developed in this research include satellite image set benchmarks genetic algorithm 002lter evolution edge detection binary edge mask generation and image reconstruction strategies All these components are critical to improving image reconstrucFigure 5  Sample satellite images used in experiments Top left USAF museum Top right Baghdad Iraq Bottom left B-52s at Davis-Monthan U.S Air Force base Bottom right Wright-Patterson U.S Air Force base tion as discussed Satellite Image Set Images obtained during reconnaissance missions typically require analysis by intelligence experts Objects within images must be identi\002ed with a high degree of con\002dence requiring the highest resolution possible Mission conditions may result in a loss of resolution due to bandwidth restrictions requiring quantization or data loss due to noise induced by interference The development of image transforms preserving object resolution to the best possible degree requires training images that may be obtained by satellites UAVs or other observation platforms We employ a set of 50 publicly available high resolution satellite images downloaded from the Google Earth database This image set is suf 002ciently lar ge to provide a robust training and validation testbed for the image reconstruction strategies developed in this research Each image is a 512 by 512 pixel black and white image that has been adjusted for maximum contrast All images represent locations of potential interest to defense and security applications including cities airports military installations and important landmarks This image set is described in detail in  These images are selected because the y contain objects whose shapes must be preserved for identi\002cation by intelligence experts or object recognition algorithms and hence provide appropriate training images for the development of transforms preserving object edge resolution Figure 5 shows four representative images used from this image set The top left image of the U.S Air Force Museum in Dayton Ohio contains aircraft two hangers and a third under construction The top right image shows buildings near downtown Baghdad Iraq At the bottom right various B-52 aircraft are seen 4 


at the Davis-Monthan U.S Air Force base near Tucson Arizona The 002nal image depicts various buildings and a portion of a runway at Wright-Patterson U.S Air Force base in Dayton Ohio These four images are employed in initial experiments described in section 4 for the development of a robust algorithm for edge-targeted image transformations The entire set of 50 images is employed in the validation experiments described in sections 5 and 6 Filter Evolution To demonstrate improvement over previously published techniques this research employs the real-coded genetic algorithm described in implemented using Matlab s Genetic Algorithm and Direct Search Toolbox Each experiment evolves a population of 50 002lters for 500 generations without early termination Because Daub4 wavelet reconstruction 002lters are de\002ned by eight real-valued coef\002cients the GA employs a chromosome of eight double precision coef\002cients replacing the original Daub4 DWT 000 1 coef\002cients to de\002ne a new image reconstruction 002lter Darwinian principles of natural selection are applied through use of a recombination operator to swap genetic material between solutions and a mutation operator to introduce random perturbations throughout the population at each generation Each generation the GA copies the two 002ttest individuals into the next generation Recombination and mutation are used to create 70 and 30 of the remaining offspring in each generation respectively The relatively high rate of mutation is empirically determined from initial experiments Recombination consists of Wright's heuristic crossover in which a child lies on the line between the two parents closer one of two selected parents with the better 002tness Parents are chosen using stochastic uniform selection This operator is speci\002cally intended for use with real-valued chromosomes The standard initialization operator randomly creates genes using a random uniform distribution in the range Mutation adds a random value taken from a Gaussian distribution centered at a randomly chosen parent with a variance of 0.5 at the 002rst generation The mutation shrinks in successive generations At generation k  the variance is var k  var k 000 1 0501 000  75 003 k  Gens 051 0505\051 where Gens is the maximum generation Initially large variance permits fast exploration of the search space As the variance shrinks and the mutation makes very small re\002nements with increasing probability The initial population includes one chromosome consisting of original Daub4 reconstruction coef\002cients The remaining individuals are copies of the original wavelet coef\002cients multiplied by a small random factor Additionally 5 of the Daub4 coef\002cients are negated The GA only evolves reconstruction 002lters always using the original Daub4 wavelet decomposition 002lter Experiments employ a quantization level q  64  meaning that each value in the wavelet-decomposed signal 015 is integer divided by 64 with the remainder discarded Resulting values are dequantized via multiplication by 64 before reconstruction While the GA is capable of identifying improved 002lters at multiple levels of resolution 20]\051 this paper emplo ys a single level of MRA image decomposition and reconstruction to enable faster GA performance During 002tness evaluation previously decomposed images are reconstructed with a candidate 002lter using a function for 2dimensional reconstruction found in Matlab's Wavelet Toolbox The 002tness function determines the similarity of a reconstructed image to the original via mean squared error 050MSE\051 Let x  f x i j i  1  2   N g and y  f y i j i  1  2   N g represent original and reconstructed images The MSE between x and y is M SE 050 x y 051  1  n n X i 1 050 x i 000 y i 051 2 0506\051 The GA seeks to improve image reconstruction by minimizing MSE Edge Detection and Mask Generation Error in images reconstructed with evolved 002lters occurs near object edges The 002rst step to counter this effect is to isolate these edges using an edge detection algorithm to identify areas containing signi\002cant transitions in pixel intensities Classic edge detection algorithms include the Sobel detector and the 3x3 dif ference v ector detector 26 among many others These algorithms take a variety of approaches for edge identi\002cation The classic Sobel edge detector performs a 2-D spacial gradient convolution using a pair of 3x3 convolution kernels responding edges running vertically and horizontally relative to the pixel grid W e emplo y an edge detector developed using a neuro-fuzzy training of a Sugeno-type fuzzy inference system to improve the response in non-pixel axis directions of a Sobel-inspired operator Figure 6 shows the edges in 002gure 2 identi\002ed by this edge detector Once the edges of an image have been isolated the GA evolves a 002lter to reconstruct the portions of an image near edges A binary mask image is created from the edge image by setting a pixel threshold Pixels darker than the given threshold in the edge image are set to black in the mask enveloping the edges The remaining pixels are white The black portions of the mask are used to select a portion of the original training image to consider during 002tness evaluation Figure 7 shows the masks generated with a threshold of 88 for the four training images These masks are employed as described in the following section to control the evolution of image 002lters designed to improve the resolution of reconstructed images either near object edges or in the remaining portions of images 5 


Figure 6  Edge detection algorithm applied to 002gure 2 Figure 7  Masks for each test image at threshold 88 Image Reconstruction Figure 8 demonstrates our proposed method for image reconstruction using evolved 002lters The original image is decomposed with a discrete wavelet transform and then subjected to a desired amount of quantization Simultaneously the image is subjected to an edge detection algorithm The resulting edge image is converted to a binary mask In a deployed image processing system both the quantized image signal and the binary mask are subjected to lossless encoding such as Huffman encoding and then transmitted The recei ving system decodes the quantized signal and the mask and decodes the signal The image is reconstructed using two evolved image 002lters the 002rst having been evolved to reduce error near object edges the second evolved to reduce Figure 8  Image decomposition and reconstruction with evolved 002lters targeting edge-adjacent and non-edge-adjacent portions of images 6 


error either across the entire image or speci\002cally in areas not adjacent to object edges The reconstruction algorithm then employs the binary mask to select the appropriate portions of each preliminary reconstructed image and then combine them into a single 002nal image During evolution of the 002lter designed to reduce error near edges the entire training image is reconstructed but 002tness is only calculated at the pixel positions located within the black portions of the mask enclosing the edges identi\002ed by the edge detection algorithm for the provided training image This approach forces the GA to evolve a 002lter that improves image reconstruction near object edges Section 5 describes the development of this 002lter The 002lter used to reconstruct the remaining areas of images may be optimized to either reduce error across an entire image or to speci\002cally reduce the error in the portions of an image not adjacent to object edges 050not selected by the binary mask\051 These two approaches are contrasted in section 6 For clarity we refer to 002lters evolved using the entire image as globally evolved 002lters and to 002lters evolved using the edge-enclosing masks as locally evolved 002lters Locally evolved 002lters are optimized either for the edge-adjacent or non-edge-adjacent portions of images as noted 4 P RELIMINARY E XPERIMENTS The edge detection algorithm generates a greyscale image isolating the edges within a satellite image as shown in 002gure 6 Edges are then isolated through the generation of a binary mask separating dark pixels from light pixels in the edge image Our initial experiments seek to identify an appropriate pixel shade threshold for binary mask generation that ultimately provides improved image reconstruction near object edges Preliminary analysis indicates satisfactory MSE results using appropriate mask threshold determination on selected satellite images Mask Threshold Determination The creation of the binary mask used to isolate the edge portions of the training image requires a set threshold This threshold dictates the required strength of the edge detection output for a given pixel position to be considered part of an edge for the mask In the range 0 000   lower thresholds select fewer areas of the image as edges Higher thresholds enclose a higher portion of the training image To determine an appropriate setting for the edge threshold several GA runs are conducted using the U.S Air Force museum image from 002gure 2 At a quantization level of 64 and one level of decomposition the MSE of the image reconstructed using the Daub4 DWT 000 1 is 138.13 A globally evolved 002lter used as a baseline for comparison achieves a reconstruction MSE of 106.108 representing a reduction of 23.18 Local 002lters for the reconstruction of object edges are evolved using edge masks generated at various threshold settings ranging from 48 up to 192 Recall that during evolution MSE 002tness is only assessed near the object edges of the training image as Figure 9   MSE improvement in masked region of edgeevolved 002lter against Daub4 wavelet 050dashed\051 and globally evolved 002lter 050dotted\051 indicated by the mask created at the given threshold At each threshold the locally evolved 002lter response is compared to the Daub4 DWT 000 1 response and the globally evolved 002lter response for the edge portions of the training image isolated by the mask The  reductions in MSE of the local 002lter against the global 002lter and the wavelet are plotted in 002gure 9 The local 002lters exhibit a reduction typically ranging from 14\22616 against the Daub4 wavelet Against the globally evolved 002lter the local 002lters demonstrate an improvement of 21.30 at a conservative threshold of 48 The degree of improvement steadily declines as the threshold increases but remains signi\002cant at thresholds below 120 This makes sense because at low thresholds only dark positions of the edge detection algorithm indicating large intensity transitions between neighboring pixels 050strong edges\051 are encompassed by the mask images At higher thresholds the masks are less selective and encompass larger portions of the image The two plots cross at a threshold of 112 at this point the responses of the wavelet and the globally evolved 002lter are approximately equal From this point the wavelet outperforms the global 002lter in the mask-encompassed portion of the image to an increasing degree as the threshold decreases The reverse is true as the threshold increases This con\002rms that the globally evolved 002lter while reducing error across the entire image actually increases reconstruction error near object edges However the locally evolved 002lters provide consistent improvement near object edges Figure 10 plots the overall reduction in MSE with the image reconstructed using the combined locally and globally evolved 002lters versus the globally evolved 002lter alone at each tested threshold level Improvement ranges from 1.98\2262.25 at thresholds under 120 with the best performance coming at a threshold of 104 At this threshold the MSE reduces from 106.11 to 103.72 a reduction of 2.25 While this may not 7 


Figure 10   MSE improvement for entire image using combined reconstruction over reconstruction with globally evolved 002lter only seem to be a signi\002cant improvement across the entire image this improvement occurs strictly near object edges such as building outlines or aircraft pro\002les The portions of the image most critical for intelligence analysis demonstrate signi\002cantly improved reconstruction Performance on Selected Satellite Images The results above demonstrate trends in 002lter response but because each is the result of a single GA run on a single image statistically sound conclusions may not yet be drawn In order to assess the performance of the proposed technique on a wider range of conditions replicated GA experiments are conducted at multiple threshold levels for the four satellite images presented in 002gure 5 For each image a global reconstruction 002lter is evolved as well as an edge-isolated local 002lter using masks created at threshold levels 48 88 and 104 in a single experimental replication Fifteen total replications are conducted for each image The responses of the wavelet the globally evolved 002lter and the locally evolved 002lter are recorded at each threshold level for the mask-enclosed portion of the image Table 1  MSE of images reconstructed with Daub4 wavelet and globally evolved 002lters Table 1 presents the MSE of each image reconstructed with the Daub4 DWT 000 1 and the average MSE achieved with the globally evolved 002lters across all replications Evolved 002lters reduce MSE by between 13.57 and 20.51 on average deTable 2   of images covered by masks created at each threshold Table 3  Mean  MSE reduction in area enclosed by masks using combined 002lter reconstruction pending on the image The masks created for each threshold encompass varying amounts of the training images Table 2 provides the  of each image enclosed by the masks for each threshold value The masks for the Baghdad image encompass between 24.67 and 41.56 of the image as seen in 002gure 7 050top right\051 the large number of structures in this image lead to a large number of edges in the image The remaining images are much more edge sparse with the Air Force museum image containing the smallest percent covered by the edge mask The locally evolved 002lters are compared within the maskenclosed regions for each image in table 3 This table shows the average reduction of MSE over the wavelet 050top\051 and over the evolved 002lters 050bottom\051 for the given image The best result and any results not statistically signi\002cantly different are shown in bold for each image T-tests at signi\002cance level 013  0  05 provides assessments of the differences between results Within the mask-enclosed region the local 002lters perform very well compared to the wavelet The threshold value does not appear to strongly in\003uence performance 8 


Table 4  Mean  MSE reduction of entire images using combined 002lter reconstruction for the given images The local 002lters demonstrate the best performance at a threshold of 104 for two images and only slightly lower than the best performance for the two remaining images Compared to the globally evolved 002lters the local 002lters show signi\002cantly improved results for three of four images with the best performance typically coming at a threshold of 48 consistent with the plot in 002gure 9 demonstrating greater improvement over the globally evolved 002lter at smaller threshold values The locally evolved 002lters provide only minor improvement over the global 002lters for the Baghdad image Recall from table 2 this image contains the greatest degree of edge transitions Filters trained on this image exert a relatively large amount of selective pressure on 002lters providing improved reconstruction near object edges Images containing fewer edges provide less evolutionary pressure preferring improved reconstruction across the entire image at the expense of reconstruction near edges Table 4 shows MSE improvement when combining the global and local 002lters for reconstruction The top portion shows improvement over the Daub4 DWT 000 1 when the mask-covered portion of the image is reconstructed with the local 002lter and the remainder with the wavelet Because masks enclose a small portion of each image improvement is modest These small gains are measured across the entire image though all improvement comes near edges  Not surprisingly the greatest error reduction comes for the Baghdad image containing the largest mask coverage The best improvement comes at a mask threshold of 104 for each image consistent with the trends illustrated in 002gure 10 The lower portion of table 4 provides results seen for reconstruction using both local and global evolved 002lters over use of globally-evolved 002lters alone The Baghdad image demonstrates the smallest improvements this image provides suf\002cient selection pressure for edge reconstruction as a training image The remaining images show reconstruction improvement of between 2.22 and 3.41 even though a relatively small portion of each image is covered by the mask The best improvements typically occur at the 104 threshold where a larger amount of image coverage provides greater room for improvement 5 R ECONSTRUCTION A DJACENT TO E DGES Because image transforms evolved for global reconstruction of an entire image demonstrate increased error near object edges we place emphasis upon the reduction of reconstruction error near edges The evolution of a robust image 002lter for near-edge reconstruction requires the identi\002cation of training images that result in 002lters that perform well on the reconstruction of unseen images 50 GA runs are conducted to evolve 002lters for near-edge reconstruction Each run employs one of the 50 unique available satellite images as the training image Images are referenced according to their number in the satellite image set as reported in the 002rst image would be referred to as sat01 The GA attempts to minimize the MSE within the edge-adjacent portions of the training image during 002lter evolution After evolution the resulting reconstruction 002lter's performance is assessed across all 50 satellite images We suspect that the abundance of object edges within a training image may in\003uence its performance as a training image For each evolved 002lter 002gure 11 plots the average  MSE reduction near edges compared to the Daub4 DWT 000 1 002lter obtained across all 50 images plotted against the  of that 002lter's training image enclosed by the binary edge detection mask obtained at a mask generation threshold of 88 050see section 4\051 From this plot it appears that there is a loose correlation between training image edge abundance and the performance of that image's corresponding evolved 002lter performance Training images with fewer than 10 of their pixels near object edges perform significantly worse than the Daub4 DWT 000 1 002lter On the other hand several images with greater than 25 of pixels near edges result in 002lters providing an average MSE reconstruction improvement near edges of approximately 17 Not all images with an abundance of pixels near edges provide strong performance as training images however It appears that the abundance of pixels near object edges is an important factor in the training performance of images but there may be other important factors as yet unidenti\002ed that play an important role in training image performance as well Images in the satellite set are also ranked according to their reconstruction dif\002culty as test images For each test image the  MSE improvement over the DWT 000 1 002lter is averaged across each of the 50 evolved transform 002lters The average improvement for each test image is plotted against the  of pixels near edges in 002gure 12 Some images are very dif\002cult for the evolved 002lters to reconstruct while others demonstrate an average improvement of nearly 10 over the DWT 000 1 002lter regardless of the evolved 002lter used Based on the seemingly random distribution of points in the plot there does not 9 


Figure 11  Scatterplot of MSE  improvement in edgeadjacent portions of training images against  of training images adjacent to object edges Improvement is averaged across all test images appear to be any correlation between an image's edge abundance and its dif\002culty as a reconstruction test case Figure 12  Scatterplot of MSE  improvement in edgeadjacent portions of test images against  of test images adjacent to object edges Improvement is averaged across 002lters evolved for reconstructing the edge-adjacent portions of images A single GA run using each training image enables an initial ranking of the training images but is insuf\002cient to identify a single best image To identify a single best training image for edge-adjacent reconstruction 30 GA replications are performed for each of the 002ve best initially-ranked training images 30 replications provide a suf\002cient sampling to enable a robust statistical analysis of the results For each replication the average performance of the evolved 002lter is assessed as the average percentage reduction of MSE for reconstruction in the binary mask-enclosing areas of each of the 50 satellite images Table 5 reports statistics collected across Table 5  Results of replicated GA experiments comparing performance of 002lters evolved using the top 5 ranked training images for reconstruction of edge-adjacent portions of satellite images Evolved 002lter performance is assessed as the average MSE  improvement over the Daub4 DWT 000 1 002lter across all test images Statistics are assessed over 30 GA replications for each training image all 30 replications for each image Image sat30 provides the best mean and median performance as a training image Filters evolves using this image provide an average MSE reduction of 17.02 across all images in the satellite set for the reconstruction of pixels near object edges We conducted a series of hypothesis tests comparing the results of the sat30 training replications with the replications obtained for each of the other top-ranked training images All tests are conducted at a con\002dence level 013  0  05  Lilliefors tests determine the normality of the replicated results Only the results for the sat39 training image do not strongly con\002rm to a normal distribution though with a p-value of 0.0423 they only slightly fail this test Since the results of all replication sets are largely normal we compare the mean values of results using standard two-sided t-tests We also compare the medians using the more conservative non-parametric Wilcoxon ranksum tests and compare the distributions directly using the non-parametric Kolmogrov-Smirnov test The results of these tests indicate that while the sat30 image provides the best performance for training edge-targeted reconstruction 002lters the sat17 image provides statistically equivalent performance The remaining three training images demonstrate strong performance but do not provide as great of an improvement over the Daub4 DWT 000 1 002lter for reconstructing near-edge pixels One of the replications obtained using the sat30 training image provides the best observed chromosome for the reconstruction of images near edges The corresponding low and high frequency reconstruction 002lter coef\002cients are as fol10 


lows Low R  f 0  4794  0  7915  0  2302  000 0  0892 g High R  f\000 0  2013  000 0  0246  0  6493  000 0  2917 g 0507\051 Across all 50 satellite images this 002lter reduces the MSE of pixels reconstructed near object edges by an average of 17.10 over the Daub4 DWT 000 1 002lter with a standard deviation of 1.66 The worst improvement was 12.69 with improvement reaching as high as 20.91 This consistent performance demonstrates that the evolved 002lter is well suited for the reconstruction of unseen images and is not the result of overtraining by the genetic algorithm for the provided training image 6 R ECONSTRUCTION N ONADJACENT TO E DGES In reconstruction 002lters are e v olv ed to pro vide impro v ed reconstruction for entire satellite images with no particular emphasis upon the reconstruction of pixels near object edges The experiments presented in follo w the same e xperimental framework presented here with 30 GA replications comparing the performance of the 5 top-ranked training images for global reconstruction 002lter evolution The best 002lter coef\002cients obtained for global image reconstruction are as follows Low R  f 0  4702  0  7654  0  2373  000 0  0620 g High R  f\000 0  1979  000 0  0316  0  6372  000 0  2921 g 0508\051 The performance of globally evolved 002lters provides signi\002cant improvement over the Daub4 DWT 000 1 002lter under conditions subject to quantization error In the areas of images not selected by the edge detection mask 050not adjacent to object edges\051 the 002lter shown in equation 8 reduces the MSE by an average of 14.98 with a standard deviation of 2.12 While this 002lter may provide suf\002cient performance for the reconstruction of pixels not adjacent to edges we conduct a series of experiments to determine whether 002lters evolved only to improve non-edge adjacent reconstruction provide improved reconstruction In these experiments 002tness is assessed by the GA as the reconstruction error only in pixels not covered by the binary edge detection masks  As before an initial set of 50 GA runs evolve 002lters using each of the satellite images for training The top-5 initially ranked training images are each used in a set of 30 replicated GA experiments The results of these experiments are summarized in table 6 In this case all 002ve replication sets pass a Lilliefors test for normality The sat08 image provides the best training performance resulting in an average improvement of 15.87 with a standard deviation of 0.18 across all 50 satellite images A series of hypothesis tests comparing the sat08 replication results to the results obtained for the other best-ranked training images demonstrate that the sat31 and sat04 training images provide statistically equivalent performance Any of these three images provide Table 6  Results of replicated GA experiments comparing performance of 002lters evolved using the top 5 ranked training images for reconstruction of non-edge-adjacent portions of satellite images Evolved 002lter performance is assessed as the average MSE  improvement over the Daub4 DWT 000 1 002lter across all test images Statistics are assessed over 30 GA replications for each training image strong performance for the training of 002lters designed for reconstructing the pixels in an image One of the 002lters obtained using sat04 as a training image provides the best observed performance for reconstruction away from edges The coef\002cients for this 002lter are Low R  f 0  4593  0  7322  0  2493  000 0  0253 g High R  f\000 0  1858  000 0  0130  0  6700  000 0  2692 g 0509\051 Across the entire set of 50 satellite images this 002lter achieves a 16.18 mean MSE improvement with a 2.52 standard deviation in the areas of the images not covered by their respective binary edge masks The median improvement is 16.65 with a minimum and maximum improvement of 7.81 and 20.54 respectively This 002lter outperforms the best globally evolved 002lter shown in equations 8 by an average of 1.42 in the reconstruction of pixels not adjacent to object edges with a standard deviation of 1.70 The maximum improvement is 6.24 This 002lter outperforms the globally evolved 002lter for 37 of the 50 satellite images Among the images for which the global 002lter exhibits better improvement its performance is not greater than 1.65 better than this 002lter In general the 002lter optimized for the reconstruction of nonedge-adjacent pixels provides improved reconstruction over a globally evolved 002lter These results justify the use of two locally evolved 002lters for image reconstruction one for the reconstruction of the image covered by the binary edge mask and the other for the remainder of the image 11 


7 D ISCUSSION The image reconstruction scheme illustrated in 002gure 8 requires two separate evolved reconstruction 002lters one for reconstruction of the image near object edges and the other for reconstruction away from edges The 002lters presented in equations 7 and 9 are optimized to reconstruct the edgeadjacent and non-edge adjacent portions of images respectively Using these combined 002lters to reconstruct all of the satellite images results in a mean MSE improvement of 16.53 with a standard deviation of 1.91 The improvement ranges from a minimum of 8.94 up to a maximum of 20.59 In contrast the best globally evolved 002lter in equation 8 only provides a mean improvement of 15.21 with a standard deviation of 1.78 Overall improvement with the global 002lter ranged from 8.83 up to 19.04 Our proposed image reconstruction approach utilizing edge and non-edgetargeted optimized 002lters improves upon the performance of both the Daub4 DWT 000 1 002lter and the best identi\002ed globallyevolved 002lter By utilizing 002lters optimized for high-spacial frequency changes for reconstruction near edges and 002lters optimized for low-spacial frequency changes for non-edgeadjacent edges we are able to realize better reconstruction resolution than a single 002lter optimized for an entire image permits The successful optimization of robust image transforms requires the careful selection of an appropriate image for training during evolution The scatter plot in 002gure 11 demonstrates the importance of training image selection Several training images result in 002lters that fail to improve upon the performance of the standard inverse wavelet transform in the reconstruction of the collected satellite images This is due to overtraining by the genetic algorithm The GA discovers a 002lter that provides strong reconstruction of the supplied training image but the resulting 002lter does not generalize well to the remaining satellite images and may provide signi\002cantly worse performance than the wavelet Though we recognize the importance of training image selection to the ultimate performance of the resulting evolved image 002lters the identi\002cation of salient image features governing an image's suitability for GA training remains an open research question Figure 13 shows the 002ve best training images for near-edge reconstruction 002lter optimization while 002gure 14 shows the 002ve worst images Filters trained upon the best images provide strong performance across the entire satellite image set In contrast 002lters trained using the worst images demonstrate very poor performance While there appears to be a loose correlation between performance and the number of near-edge pixels in the training image 050see 002gure 11\051 there are likely other factors at play as well These factors may include the distribution of light and dark pixel intensities in the image the shape and direction of long and short object edges or the rotational axis of the training image relative to the distribution of object edges The good training images tend to contain many small boxed objects such as houses oil storage tanks and hangers while the poor training edges contain fewer buildings The distribution of buildings/small geometric objects may in\003uence an image's training performance in an as yet unforseen manner Future research should focus upon the factors impacting an image's suitability as a GA training sample This may lead to the identi\002cation of improved training samples outside of the current image database and thus leading to greater performance from evolved image 002lters 8 C ONCLUSIONS Existing techniques of 002lter evolution potentially provide signi\002cant improvement over standard wavelet transforms but they may increase the error present near the edges of objects Image processing applications such as target recognition and intelligence gathering cannot afford this resolution loss in the most critical sections of the image The use of an edge detection algorithm and an edge-enclosing mask allows the evolution of reconstruction 002lters that improve the reconstruction resolution near object edges by as much as 20 under conditions subject to high quantization error Likewise 002lters evolved with emphasis upon the reconstruction of pixels not adjacent to object edges outperform existing 002lter optimization techniques through the remaining portions of images By ignoring edges such 002lters demonstrate an improved response over globally evolved 002lters to the edge-sparse portions of images Reconstruction combining 002lters optimized for near edge and non-edge adjacent performance provides a robust reconstruction algorithm suitable for applications requiring maximum object resolution while maintaining maximal compression ratios Results indicate that there may exist a correlation between the degree of edges within an image and the potential improvement a locally evolved 002lter may provide Future experiments should focus on images containing a wide range of edge sparseness or abundance while studying the in\003uence of other image properties upon a given image's suitability as a training sample Experiments should focus on the determination of appropriate mask creation thresholds for images of various edge abundance These experiments will lead to the development of a system that given an image determines the appropriate threshold setting and selection of appropriate 002lters from a library of previously evolved 002lters Recent related research has focused upon the optimization of image transform 002lters of greater length and complexity designed to outperform wavelets at greater levels of multiple resolution analysis regardless of quantization level As the complexity of evolved transforms increases the separation of the reconstruction task into unique 002lters for the reconstruction of pixels adjacent and non-adjacent to object edges may be of further bene\002t Further research will establish the performance of this reconstruction strategy upon increasingly complex image transform 002lters Lossy image processing systems that maintain high resolution near object edges improve the amount of useful intelligence 12 


Figure 13  The 002ve best training images for 002lter evolution of edge-adjacent image portion reconstruction Figure 14  The 002ve worst training images for 002lter evolution of edge-adjacent image portion reconstruction that may be gathered from images reconstructed using this approach This improved performance may be of particular interest to the scienti\002c defense and homeland security communities that require the transmission of copious amounts of data over bandwidth-limited channels without signi\002cant loss of observational information A CKNOWLEDGMENTS The authors thank the U.S Air Force Research Laboratory Sensors Directorate 050Dr Robert Ewing\051 and the U.S Air Force Of\002ce of Scienti\002c Research 050Computational Mathematics\051 for their support R EFERENCES   C E Shannon and W Weaver The Mathematical Theory of Communication  University of Illinois Press 1964   A Gersho and M Gray Vector Quantization and Signal Compression  Kulwer Academic Publishers 1991   B E Usevitch 223A tutorial on modern lossy wavelet image compression foundations of jpeg 2000,\224 IEEE Signal Processing Magazine  pp 22\22635 September 2001   I Daubechies Ten Lectures on Wavelets  SIAM 1992   G Davis and A Nosratinia 223Wavelet-based image coding an overview,\224 Applied and Computational Control Signals and Circuits  vol 1 no 1 1998   M R Peterson G B Lamont and F Moore 223Improved evolutioanry search for image reconstruction transforms,\224 in Proceedings of the IEEE World Congress on Computational Intelligence  2006 pp 9785\2269792   A Skodras C Christopoulos and T Ebrahimi 223The jpeg 2000 still image compression standard,\224 pp 36\22658 2001   J Walker A Primer on Wavelets and Their Scienti\002c Applications  CRC Press 1999   D A Huffman 223A method for the construction of minimum redundancy codes.\224 in Proceedings of the IRE  vol 40 1952 pp 1098\2261101   M Lankhorst and M van der Lann 223Wavelet-based signal approximations with genetic algorithms,\224 in Proceedings of the 4th Annual Conference on Evolutionary Programming  1995 pp 237\226255   E Jones P Runkle N Dasgupta L Couchman and L Carin 223Genetic algorithm wavelet design for signal classi\002cation,\224 IEEE Transactions on Pattern Analysis and Machine Intelligence  vol 23 no 8 pp 890\226895 August 2001   U Grasemann and R Miikkulainen 223Evolving wavelets using a coevolutionary genetic algorithm and lifting,\224 in Proceedings of the Genetic and Evolutionary Computation Conference GECCO-04  ser Lecture Notes in Computer Science vol 3103 Springer-Verlag 2004 pp 969\226980   F Moore 223A genetic algorithm for optimized reconstruction of quantized signals,\224 in IEEE Congress on Evolutionary Computation 050CEC\051 Proceedings vol 1  2005 pp 105\226111   A Bruckmann T Schell and A Uhl 223Evolving subband structures for wavelet packet based image compression using genetic algorithms with non-additive cost functions,\224 in Proceedings of the International Conference on Wavelets and Multiscale Methods  1998 13 


  Y Hill S O'Keefe and D Thiel 223An investigation of wavelet design using genetic algorithms,\224 in Microelectronic Engineering Research Conference  2001   B S Rani and S Renganathan 223Wavelet based texture classi\002cation with evolutionary clustering networks,\224 in TENCON 2003 IEEE Conference on Convergent Technologies for Asia-Paci\002c Region  vol 1 2003 pp 239\226 243   U Grasemann and R Miikkulainen 223Effective image compression using evolved wavelets,\224 in Proceedings of the Genetic and Evolutionary Computation Conference 050GECCO'05\051  2005 pp 1961\2261968   W Sweldens 223The lifting scheme a custom-design construction of biorthogonal wavelets,\224 Journal of Aplied and Computational Harmonic Analysis  vol 3 no 2 pp 186\226200 1996   T Hopper C M Brislawn and J N Bradley 223Wsq gray-scale 002ngerprint image compression speci\002cation,\224 Federal Bureau of Investigation Tech Rep IAFIS-IC-0110 February 1993   F Moore 223A genetic algorithm for evolving improved mra transforms,\224 WSEAS Transactions on Signal Processing  vol 1 no 1 pp 97\226104 2005   F Moore P Marshall and E Balster 223Evolved transforms for image reconstruction,\224 in IEEE Congress on Evolutionary Computation 050CEC\051 Proceedings vol 3  2005 pp 2310\2262316   Google 223Google earth plus,\224 http://earth.google.com 2006   M R Peterson G B Lamont F Moore and P Marshall 223A satellite image set for the evolution of image transforms for defense applications,\224 in GECCO 07 Proceedings of the 2007 GECCO conference companion on Genetic and evolutionary computation  New York NY USA ACM Press 2007 pp 2901\2262906   A H Wright 223Genetic algorithms for real parameter optimization,\224 in Foundations of Genetic Agorithms  G Rawlins Ed San Mateo Morgan-Kaufman 1991 pp 205\226220   I E Sobel 223Camera models and machine perception,\224 Ph.D dissertation Electrical Engineering Department Stanford University Stanford CA 1970   Y Yang 223Color edge detection and segmentation using vector analysis,\224 Master's thesis University of Toronto Toronto Canada 1995   D Kaur and L Ying 223Creating a neuro-fuzzy model by combining 002ltered images with various 002ltering operators for the detection of edges in new images,\224 2006 technical report University of Toledo   B J Babb F W Moore and P Marshall 223Evolved multiresolution analysis transforms for improved image compression and reconstruction under quantization,\224 in IEEE Symposium on Computational Intelligence in Image and Signal Processing  2007 pp 202\226207 B IOGRAPHY Michael Peterson received his B.S degree in Computer Engineering and his M.S degree in Computer Science from Wright State University in 2001 and 2003 respectively He is currently a Ph.D candidate in Computer Science and Engineering at Wright State University Since 2005 he has worked in the Evolutionary Computation Laboratory at the U.S Air Force Institute of Technology where he has developed a robust methodology for the evolution of wavelet-based image reconstruction transforms His research interests include evolutionary and bio-inspired computation signal and image processing pattern recognition and bioinformatics Gary Lamont received the B.S degree in physics and the M.S.E.E and Ph.D degrees from the University of Minnesota Minneapolis in 1961 1967 and 1970 respectively He is currently a Professor of Electrical and Computer Engineering at the Air Force Institute of Technology Wright-Patterson AFB OH where he directs the parallel and distributed computing and the evolutionary computation research groups Previously he was an Engineering Systems Analyst for the Honeywell Corporation for six years He has authored or coauthored a book several book chapters and over 100 papers His current research interests include parallel/distributed computation evolutionary computation 050genetic algorithms evolutionary strategies\051 combinatorial optimization problems 050single objective multiobjective\051 formal methods software engineering digital signal processing intelligent and distributed control systems computational and numerical methods and computer-aided design 14 


CONCLUSIONS Given that this project was intended to estimate missions lying 10-15 years out we structured it differently than one intended to estimate contemporary projects A variety of conventional techniques were not used as we felt they would over fit training observations and thus not be suitable for prediction We also were not sure which approach would work so we tried many We heavily favored ensemble methods where models are combined because we surmised that any one model could not be guaranteed to have the best view of the future However a single neural network ultimately yielded the most competitive results Another finding was that methods built upon simple models such as with three variables generally did work best not surprisingly because they were less likely to over fit calibration data A graph of the three best methods is shown in figure 18 with estimates for the same missions sorted by cost For the neural network calibration occurred until just before the results shown for continuous boosting calibration occurred no more recently than 15 years prior to the results and for Adaboost calibration also occurred up until the results shown A graph sorted by year is not shown we think it instructive that no results seemed to degrade over time As mentioned but obvious from figure 17 the neural network performs best followed by Adaboost and then continuous boosting It is interesting to note that the three cases in which the neural network goes haywire and predicts too low also correspond to worst performances for the Adaboost method pointing to exceptional data points We will be further investigating these regularly errant results and other outliers which may result in estimating improvements ACKNOWLEDGEMENTS This work was carried out under Small Business Innovation Research contract FS9453-05-C-0023 with the Air Force Research Lab The authors wish to gratefully acknowledge Judy Fennelly and later Ross Wainwright our technical points of contact at AFRL for their continuous support and encouragement Our contract officer Timothy Provencio also provided invaluable assistance Our critical seed stock of data was provided by Joseph Hamaker who previously was Director of NASA Headquarters Cost Analysis Division and now is Senior Cost Analyst with SAIC Ainsley Chong and Dale Martin USAF Ret also lent considerable assistance with data gathering APPENDIX A MISSIONS COLLECTED Active Cavity Radiometer Irradiance Monitor Satellite Active Magnetospheric Particle Tracer Explorer Adeos Advanced Communications Technology Satellite Advanced Composition Explorer Alexis Amos-I AMSC-1 Anik El Anik E2 Applications Technology Satellite-I Applications Technology Satellite-2 Applications Technology Satellite-5 All MREs Lu 1.00 0.75 l 0.50l 0.25 l 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75-2.00oi v 1   Cost o N X  X~~~~~Cl Figure 16 Comparison of estimating error for three best methods 15 


Applications Technology Satellite-6 Aqua Argos Atmospheric Explorer AURA Aurora 2 Calipso Cassini Cassini Spacecraft  Huygens Probe Chandra X Ray Observatory CHIPSat Clark Clementine CloudSat COBE Columbia 5 Contour CRRES DART Dawn DBS-1 Deep Impact Flyby Spacecraft  Impactor Deep Space 1 Deep Space 2 Defense Meteorological Satellite Program-5D Defense Meteorological Satellite Program-5D3 Defense Support Program DSCS 3 FIO DSCS 3 F7 DSCS I DSCS-II DSCS-IIIA DSCS-IIIB Dynamics Explorer-I Dynamics Explorer-2 Earth Observing Satellite 1 Earth Radiation Budget Experiment EchoStar 5 Extreme Ultraviolet Explorer Far Ultraviolet Spectroscopic Explorer FAST FLTSATCOM 6 Galaxy 5 Galaxy 11 Galaxy Evolution Explorer Galileo Orbiter  Probe Gamma Ray Large Area Space Telescope GE 1 GE 5 Genesis GFO 1 Globalstar 8 Glomr GOES 3 GOES 9 GOES N GPS-1 GPS-IIR GPSMYP GRACE Gravity Probe-B GRO/Compton Gamma Ray Observatory GStar4 Hayabusa HEAO-1 HEAO-2 HEAO-3 HESSI-II High Energy Transient Explorer-II HETE HST ICESat Ikonos IMAGE IMP-H Inmarsat 3-F5 Intelsat K INTELSAT-II INTELSAT-IV International Ultraviolet Explorer Iridium James Webb Space Telescope Jason 1 JAWSAT KEPLER KOMPSAT LANDSAT1 LANDSAT-4 LANDSAT-7 Lewis Lunar Orbiter Lunar Prospector Magellan Magsat Mariner-4 Mariner-6 Mariner-8 Mariner1 0 MARISAT Mars Exploration Rover Mars Express/Beagle 2 Mars Global Surveyor Mars Observer Mars Odyssey Mars Surveyor 2001 Orbiter Mars Pathfinder  Sojourner Rovers Mars Polar Lander Mars Reconnaissance Orbiter Mars Telecommunication Orbiter Mars Climate Orbiter Messenger Meteor Mid-course Space Experiment MightySat Milstar 3  Adv EHF Model-35 Morelos NATO III Near Earth Asteroid Rendezvous NEAR Shoemaker New Horizons 16 


NIMBUS NOAA 8 NOAA 15 NPOESS Preparatory Project Orbital Maneuvering Vehicle Orbcomm Orbiting Carbon Observatory Orbiting Solar Observatory-8 Orbview 2 Orion 1 P78 Pas 4 Phoenix Pioneer P-30 Pioneer Venus Bus/Orbiter Small Probe and Large Probe Pioneer-I 0 Polar QuikSCAT Radarsat Reuven High Energy Solar Spectroscopic Imager REX-II Rosetta Instruments Sage III SAMPEX Satcom C3 Satcom C4 SBS 5 SCATHA Seastar SMART-1 SNOE Solar Dynamics Observatory Solar Maximum Mission Solar Mesosphere Explorer Solar Radiation and Climate Experiment Solar Terrestrial Relations Observatory Space Interferometry Mission Space Test Program Small Secondary Satellite 3 Spitzer Space Telescope SPOT 5A Stardust  Sample Return Capsule STEPO STEPI STEP3 STEP4 STRV ID Submillimeter Wave Astronomy Satellite Surfsat Surveyor Swift Gamma Ray Burst Exporer Synchronous Meterological Satellite-I TACSAT TACSAT 2 TDRS F7 Tellura Terra Terriers Tethered Satellite System Thermosphere Ionosphere Mesosphere Energetics and Dynamics TIMED TIROS-M TIROS-N TOMS-EP Total Ozone Mapping Spectrometer TOPEX TRACE Triana Tropical Rain Measuring Mission TSX-5 UFO I UFO 4 UFO 9 Ulysses Upper Atmosphere Research Satellite Vegetation Canopy Lidar VELA-IV Viking Viking Lander Viking Orbiter Voyager Wilkinson Microwave Anisotropy Probe WIND WIRE XMM X-Ray Timing Explorer XTE XSS-iO XSS-ii APPENDIX B FIELDS COLLECTED Mission Mission Scenario Mission Type Launch Year Launch Vehicle Bus Model Bus Config Bus Diameter Location Expected Life Flight Profile Flight Focus Technical Orbit Currency Total Cost Including Launch Unit Sat Costs Average Sat Cost Production Costs Launch Costs Operations Cost Orbit Weight Wet Weight Dry Weight Max Power EOL Power BOL Power  of Batts 17 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



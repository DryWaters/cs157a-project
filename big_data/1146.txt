Collaborative Filtering by Mining Association Rules from User Access Sequences Mei-Ling Shyu Department of Electrical and Computer Engineering University of Miami Coral Gables FL 33124 USA shyu@miami.edu Choochart Haruechaiyasak Information Research and Development Division RDI National Electronics and Computer Technology Center NECTEC Thailand Science Park Klong Luang Pathumthani 12120 Thailand choochart.haruechaiyasak@nectec.or.th Shu-Ching Chen and Na Zhao Distributed Multimedia Information System Laboratory School of Computer Science Florida International University Miami FL 33199 USA  chens nzhao002  cs.\336u.edu Abstract Recent research in mining user access patterns for predicting Web age requests focuses only on consecutive sequential Web age accesses i.e pages which re accessed by following the hyperlinks In this paper we ropose a ew method for mining user access patterns that allows the prediction of multiple non-consecutive Web ages i.e any pages within the Web site Our approach consists of two major steps First the shortest path algorithm in graph theory is applied to 336nd the distances between Web ages In order to capture user access behavior on the Web the distances are derived from user access sequences as opposed to static structural hyperlinks We refer to these distances as Minimum Reaching Distance MRD information The association rule mining ARM technique is then applied to form a set of predictive rules which re further re\336ned and pruned by using the MRD information The proposed approach s applied as a collaborative 336ltering technique to recommend Web ages within a Web site Experimental results demonstrate that our approach improves performance over the existing Markov model approach in terms of precision and recall and also has a better potential of reducing the user access time on the Web Keywords Association Rule Mining Collaborative Filtering Web Data Extraction Web og/Navigation Path Analysis 1 Introduction Due to the increase in t Transfer Protocol HTTP traf\336c on the World-Wide b WWW the amount of transaction log records generated and collected on the servers grows tremendously n order to bene\336t from these server log records data mining has emerged as a tool to extract any useful patterns and analyze user access behavior on the b This speci\336c type of data mining technique is known as Web usage mining  In par ticular the technique of mining user access patterns also known as browsing patterns and path traversal patterns has been applied in a wide range of applications including b caching 11 W e b page recommendation 6 8 and W e b personalization 10 12 In general mining user access patterns can be considered as a special type of mining sequential patterns in the 336eld of knowledge discovery and data mining Association rule mining has recently attracted considerable attention and proven o e a highly successful technique for extracting useful information from very large databases 1 2 7 F o r the problem of mining user access patterns data sequences are typically user access sequences of b pages These access sequences are extracted from server log records via some b data preparation techniques Applying a method for mining user access patterns on these access sequences reveals the user browsing behavior on the Web Various algorithms and techniques for mining user acProceedings of the 2005 International Wo rkshop on Challenges in Web Informati on Retrieval and Integration \(WIRI\22205 0-7695-2414-1/05 $20.00 \251 2005  IEEE 


cess patterns have been proposed in the literature In 11  v ariations of the Mark o v model such as 336rst-order Markov model and all K th order Markov model were applied to construct a predictive model to predict the user requests on b pages Their work mainly focused on the analysis of consecutive sequential access of b pages and hence given a currently visiting b page the ability to predict the next request is limited to the following adjacent b pages on the user access sequence r example given a user access sequence containing n Web pages in an ordered list  p 1  p 2  p n  where p i represents a Web page an approximation of the 336rst-order Markov model would contain the transitional probabilities of two adjacent b pages in the user access sequence Pr  p i  p i 212 1   where 1 i 001 n  In this paper e propose a ew approach for mining user access patterns The approach aims at predicting b page requests on the b site in order to reduce the access time and to assist the users in browsing within the b site To capture the user access behavior on the b site an alternative structure of the b s constructed from user access sequences obtained from the server logs as opposed to static structural hyperlinks Most of the previous research work focused on the forward and backward accesses where forward accesses are those accesses that browse the b pages by following the hyperlinks embedded within the Web pages and backward accesses are those that access the b pages by backtracking to the previous b pages r example in the user access sequence was ivided into smaller sequences called the maximal forward references  and the effect of backward references was not considered However considering only the smaller sub-sequences of the user access patterns does not fully capture the user\325s intention of accessing a particular set of b pages since some of the b pages may be put into a different access sequence Another type of accesses is the jump accesses which the user retrieves a b page by entering the Uniform Resource Locator URL directly on the b browser n this paper all three access types are considered when the model is constructed We pruned out the duplicate b pages in the access sequences since our goal is to predict the b pages which the user has not yet visited A user access sequence is used to represent a data record during the mining process Using this user traversal structure a shortest path problem in the Graph Theory is applied to 336nd the 322access\323 distances between b pages We refer to these distances as Minimum Reaching Distance MRD information The ARM technique is then applied to 336nd a set of predictive rules that pass the user-speci\336ed minimum support The MRD information is used to prune the results from ARM in order to increase the prediction accuracy and reduce the space complexity The proposed method for mining user access sequences was applied as a collaborative 336ltering technique The results from the process of mining user access patterns are a predictive rule set that is used to recommend b pages according to the users who accessed the b site in the past 8 Under the Markov model notion our method can be viewed as the All K th Order Markov model with the lookahead ability which allows the prediction to include multiple non-consecutive b pages i.e any Web pages within the Web site which are not necessarily connected by hyperlinks r example the approximation of the 336rst-order Markov model with the look-ahead ability would contain the following transitional probabilities of two Web pages including non-consecutive ones Pr  p j  p i   where 1 001 i n and i<j 001 n  The remainder of this paper is organized as follows In Section 2 the method of mining user access patterns based on association rule mining is explained in details The periments on a real b data set are given in Section 3 In the same section the experimental results are presented and analyzed Conclusion is given in Section 4 2 Association Rule Mining for User Access Patterns We propose to apply the association rule mining ARM technique 1 in mining user access patterns on the W e b pages The objective is to construct a model that predicts users\325 b page requests to assist in browsing the b pages and to reduce the access time In ARM a k itemset contains k items that pass the userspeci\336ed minimum support value Hence in essence ARM enables one to discover interesting patterns or associations among the k itemset in a iven collection of records Our framework applies the ARM technique to 336nd the frequent itemsets of b pages from the user access sequences and to construct a set of rules based on those itemsets Generally the number of rules constructed from ARM is large In the original algorithm the minimum con\336dence value is used to prune the rules while in our proposed framework the number of rules is pruned by incorporating the MRD information which reduces the state complexity of the model Our MRD calculation adopts the concept from the shortest-path problem in the Graph Theory The original algorithm assumes that the traversal path follows the link structure of the graph where a link structure is a representation of Web pages along with the embedded hyperlinks However the pages that a user accesses do not always follow the link structure of the b pages and hence an alternative b representation based on the actual user browsing activity on the b site needs to be constructed Here a user access sequence also referred to as a browsing sequence or a traversal path is Proceedings of the 2005 International Wo rkshop on Challenges in Web Informati on Retrieval and Integration \(WIRI\22205 0-7695-2414-1/05 $20.00 \251 2005  IEEE 


 A B C D E F G H I J K A 1 1 B 1 1 1 1 C 1 D 1 E 1 1 F 1 1 G 1 H I J K 1 st Iteration 2 nd n 3 rd n A B C D E F G H I J K A 1 1 2 2 2 2 B 1 1 1 1 2 2 2 2 C 1 2 D 1 E 1 1 F 1 1 G 1 H I J K A B C D E F G H I J K A 1 1 2 2 2 2 3 3 3 3 B 1 1 1 1 2 2 2 2 3 C 1 2 D 1 E 1 1 F 1 1 G 1 H I J K done F F F F F F F T T T T done F F F T T T T T T T T done F F T T T T T T T T T 4 th Iteration A B C D E F G H I J K A 1 1 2 2 2 2 3 3 3 3 B 1 1 1 1 2 2 2 2 3 C 1 2 D 1 E 1 1 F 1 1 G 1 H I J K done T T T T T T T T T T T A B C D E F G H I J   K   User Traversal Path Adjacency List A B C B C D E F C G D H E H J F I  J G K H I J K   Figure 1 Minimum Reaching Distance MRD Construction an ordered list of b pages accessed by a user during one session User access sequences are extracted from the b server log records as part of the data preprocessing step The issues and analysis of the user access sequence are considered in many research works including 3 r example the top of Figure 1 shows the result of constructing a graph based on the user access sequences This representation allows us to capture some paths such as E 002 J which do not previously exist in the link structure graph In addition some of the links that exist in the link structure do not appear in the user-based graph since no user has traversed these particular links Therefore using the userbased graph offers a better view f the user access behavior on the b site than using the link structure graph The bottom of Figure 1 also shows the iterations of constructing the MRD information using the user-based graph As shown in this 336gure in the 336rst iteration the algorithm 336rst translates the user-based graph into an adjacency matrix structure M  where the value in the position M p i  p j  s 1 if p j has a direct link from p i in the user-based graph and 2-itemset A,B B,D A,C B,E A,D B,F A,E B,H A,H B,J 3-itemset A,B,D A,B,E A,B,H rules A B B D B A D B A C   B E C A   E B A D   B F D A   F B A E B H E A H B A H   B J H A   J B rules B, D A A, D B A, B D B, E A A, E B A, B E B, H A A, H B A, B H Figure 2 Frequent itemsets and rule pruning is blank otherwise The values of the done  p i  column are false  F frow p i contains at least one direct link from the user-based graph In the second iteration MRD 336nds the possible reaching distance from the b page whose value in the done array is false r example considering b page A A has the direct links to B and C In order to search for other possible reaching distances the algorithm looks for the direct links from B and C Since B has the direct links to C D E and F and C has the direct link to G Therefore A can reach D E F and G in wo steps Please note that the distance between A and C remains 1 since C is reachable from A n one step and the MRD algorithm is to keep the minimum reaching distance r each iteration the element done  p i  i s set to true  T  f there is no change of the value in row p i in an iteration The algorithm terminates when all the elements in array done are true In this example it terminates in 4 iterations Once the MRD information for the b pages are constructed they are used in the rule pruning process Assume that Figure 2 shows all the resulting 2-itemsets and 3itemsets that passed a pre-speci\336ed minimum support value The next step is to generate the rules from these itemsets To build the model for predicting b page accesses we consider the rules with single-item consequence r example three single-consequence rules can be generated from the 3-itemset A B D B D 002 A A D 002 B and A B 002 D Next the MRD information from Figure 1 is used to prune the resulting rules as follows Consider a singleconsequent rule of the form  p 1  p 2   p n 212 1  002 p n  this rule would pass the pruning step if and only if M p i  p n  is greater than 0 003 i  1 001 i<n  That is when the postcondition item is reachable from all the pre-condition items in the rule As seen from Figure 2 using the MRD information some of the rules are pruned out r instance the rule B 002 A s pruned since A is not reachable from B In addition using our approach of constructing the predictive model the b pages which are non-consecutive to a current b page are also considered which we believe can Proceedings of the 2005 International Wo rkshop on Challenges in Web Informati on Retrieval and Integration \(WIRI\22205 0-7695-2414-1/05 $20.00 \251 2005  IEEE 


 0.4 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 1.3 1.4 0 500 1000 1500 2000 2500 Minimum support Number of rules link MRD none Figure 3 Number of rules comparison for three approaches 1 without a pruning process none 2 via the MRD information MRD and 3 via the link structure link better predict the user access patterns r example the predictive rule of A 002 H is included in our approach although A s not consecutive to H 3 Experimental Results Experiments on a real b data set from University of Miami are conducted to evaluate the performance of our proposed framework A crawling program was eveloped to collect the hyperlinks embedded within the Web pages for the link structure The total number of b pages with unique URLs is equal to 3,948  The user log records are used to construct the user access sequences Once all the user access sequences are identi\336ed two-third of the data set with 34,362 user access sequences is used as the training data set while one-third of it have 17,182 user access sequences and are used as the test data set Figure 3 shows the reduction comparison of the resulting rules by using our MRD-based pruning approach  MRD  the original association rule mining without a pruning process  none  and with the pruning process using the link structure  link  The 336rst observation is that by increasing the minimum support value for all different methods the number of rules decreases at an exponential rate This is because the minimum support value limits the number of itemsets which are the basis for the rule construction Another observation is that using the link structure for the pruning process reduces more rules than using the MRD information The reason for this outcome is that in addition to browse b pages by the forward accesses the users are also likely to access b pages by backward accesses and jump accesses Although using the link structure could reduce more rules than using the MRD information our further analysis 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 Precision Recall Markov model \(link Association rule mining \(link Markov model \(MRD Association rule mining \(MRD Figure 4 Performance evaluation under precision and recall shows that using the link structure actually yields a worse performance than using the MRD information in terms of precision and recall This implies that the pruning process using the link structure may over-prune the rule set and affect the performance Whereas under the MRD information the precision and recall are not affected compared to the case of the original association rule mining Next we evaluate the performance based on the precision and recall Assume we have a test access sequence U   u 1 u 2 u n   where n is the number of user\325s visited b pages and a list of predicted b pages V   v 1 v 2 v m   where m is the number of predicted b pages The precision measures the accuracy f the predictive rule set when applied to the testing data set It is de\336ned as the ratio of the number of b pages correctly predicted over the total number of b pages presented to the user That is precision   U 001 V  m  n the other hand the recall measures the coverage or the number of rules from the predictive rule set that match the incoming requests It is de\336ned as the ratio of the number of b pages correctly predicted over the total number of user\325s visited b pages That is recall   U 001 V  n  In this experiment the precision and recall values are compared for the following four different approaches 1 association rule mining using link structure information association rule mining link 2 Markov model using link structure information Markov model link 3 association rule mining using the MRD information association rule mining MRD and 4 Markov model using the MRD information Markov model MRD The ffer size the limited number of predicted b pages presented to the user varies from 1 to 50 The precision and recall graph based on the support value of 0.8 is Proceedings of the 2005 International Wo rkshop on Challenges in Web Informati on Retrieval and Integration \(WIRI\22205 0-7695-2414-1/05 $20.00 \251 2005  IEEE 


 Predictive Model Averaged F 1 Value association rule mining MRD 0.2911 Markov model MRD 0.2771 association rule mining link 0.1559 Markov model link 0.1524 e  d F 1 measures under four different approaches for mining user access patterns shown in Figure 4 From this 336gure it can be observed that for both association rule mining and the Markov model approaches using the link structure information to prune the results of the association rule mining gives a worse performance compared to those using the MRD user-based information In addition our proposed approach association rule mining MRD improves the performance over the isting Markov model approach Using the combination of the precision and recall the F 1 measure which is the harmonic average of precision and recall is de\336ned in Equation 1 F 1  2 327  precision 327 recall  precision  recall 1 Table 1 shows the summarized results of Figure 4 under the F 1 measures As shown in this table the approach of association rule mining improves the performance under F 1 by 5.05 over the Markov model using the same MRD information In addition using the MRD information to prune the set of predictive rules the averaged F 1 value improves about twice as much as of the hyperlink structure This is since the MRD information is derived based on the user traversal constraint and therefore it can better capture the user access behavior on the b site 4 Conclusion In this paper the problem of mining user access patterns is considered A ew method is proposed based on the association rule mining and the shortest path algorithm in graph theory To capture the user access behavior e model the Web by using user access sequences instead of static hyperlinks The association rule mining technique is then applied to approximate and construct the predictive model The proposed Minimum Reaching Distance MRD information is used to prune the results from the association rule mining to reduce the state-space complexity of the model The proposed approach improves the performance over the existing Markov model approach by allowing the prediction to include multiple non-consecutive b pages To demonstrate a potential usage we applied the proposed approach for the collaborative 336ltering technique Experimental results using a real b data set show that our approach improves performance over the existing approaches in terms of both precision and recall and also has a better potential of reducing the user browsing time on the b References  R Agra w al T  Imielinski and A Sw ami 322Mining Association Rules between Sets of Items in Large Databases,\323 Proc of M SIGMOD Conf n Management of Data  1993 pp 207-216  R Agra w a l and R Srikant 322Mining Sequential P atterns 323 Proc of the Eleventh Int Conf n Data Engineering  1995 pp 3-14  P  Berkhin J D Becher  and D J Randall 322Interacti v e P ath Analysis of b Site Traf\336c,\323 Proc of the Seventh M SIGKDD Int Conf n Knowledge Discovery and Data Mining  2001 pp 414-419  M.-S Chen J S P ark and P  S Y u  322Ef 336cient Data Mining for Path Traversal Patterns,\323 IEEE Trans on Knowledge and Data Engineering 10\(2 1998 pp 209-221  R Coole y  B Mobasher  and J Sri v asta v a  322Data Preparation for Mining World Wide b Browsing Patterns,\323 Knowledge and Information Systems  1\(1 1999 pp.5-32  J Dean and M R Henzinger  322Finding Related P ages in the World Wide Web,\323 Proc of the Eighth Int World Wide b Conf  1999 pp 389-401  J Han and M Kamber  Data Mining Concepts and niques  Morgan Kaufmann Publishers 2001  C Haruechaiyasak M.-L Shyu and S.-C Chen 322 A W ebPage Recommender System via a Data Mining Framework and the Semantic b Concept,\323 accepted for publication International Journal of Computer Applications in chnology   C Haruechaiyasak M.-L Shyu and S.-C Chen 322 A Data Mining Framework for Building A Web-Page Recommender System,\323 2004 IEEE International Conference on Information Reuse and Integration IRI\3252004  Las Vegas Nevada USA November 8-10 2004 pp 357-262  B Mobasher  R  Coole y  and J Sri v asta v a  322 Automatic Per sonalization Based on b Usage Mining,\323 Communications of the M  43\(8 2000 pp 142-151  V  N P admanabhan and J C Mogul 322Using Predicti v e Prefetching to Improve World Wide b Latency,\323 ACM SIGCOMM Computer Communications Review  26\(3 1996 pp 22-36  J Pitk o w and P  Pirolli 322Mining Longest Repeating Subsequences to Predict World Wide b Sur\336ng,\323 Proc of the Second USENIX Symposium on Internet chnologies and Systems  1999 pp 139-150  S Schechter  M  Krishnan and M D Smith 322Using P ath Pro\336les to Predict HTTP Requests,\323 Computer Networks and ISDN Systems  30\(1-7 1998 pp 457-467  M.-L Shyu S.-C Chen and R L Kashyap 322 A Generalized Af\336nity-Based Association Rule Mining for Multimedia Database Queries,\323 Knowledge and Information Systems KAIS An International Journal  vol 3 no 3 August 2001 pp 319-337 Proceedings of the 2005 International Wo rkshop on Challenges in Web Informati on Retrieval and Integration \(WIRI\22205 0-7695-2414-1/05 $20.00 \251 2005  IEEE 


 J Sri v asta R Coole y  M Deshpande and P  T an 322W eb Usage Mining Discovery and Applications of Usage Patterns from b Data,\323 SIGKKD Explorations  1 2000 pp 1223 Proceedings of the 2005 International Wo rkshop on Challenges in Web Informati on Retrieval and Integration \(WIRI\22205 0-7695-2414-1/05 $20.00 \251 2005  IEEE 


1  Grayish 3 1 ; Blackish 3 2 2 1 To make this explanation clearer we can merge overlapping components. To preserve completeness of the derived definition we applied the sum operator over the algebraic product when merging all overlapping concepts: Any = {Whitish 3 2  2 1 Grayish 3 1  2 1 3 1  2 1 3 2  2 1 Whitish 3 1 ; Grayish 3 1 ; Blackish 3 1 So we can see that the approximated explanation of abstracts, via drilling down fuzzy concept hierarchies has a transitive character. If we explain concept ck with the subset of Ck-1, and then each of the elements from this set with the concepts from the set Ck-2, then ck can be also fully explained by the merger of definitions based on the set Ck-2 This approach to explanation of abstract concepts has a rather trivial character when none of the abstract  s components \(direct specializers count of the votes greater than the given generalization threshold \(denoted further as T separate entity in the generalized relation. However, in the other case, we have to make certain that the concepts that reached a significant count at the lower level of abstraction \(and were already placed in the final generalized relation higher-level concepts. Otherwise the explanations would have a confusing character, since the client could be under impression that the same tuples are reported and counted abstraction. We have to remember that final users of data mining applications are decisions makers who, in contrasts to experts and data analysts, usually do not have time to gather detailed knowledge about techniques which were applied to generalize the data Therefore the last equation should include the restriction lt;?1kjc      \(4 where T is the threshold value representing the minimal value of COUNT which is recognized by the client as significant aggregation of original data \(e.g.  one may wish all generalized tuples which describe more than T 


wish all generalized tuples which describe more than T 5% of the original dataset to be reported separately in the output relation number of original data records generalized to the abstract concept 1?kjc This property assures that each lower-level concept employed in derivation of a hierarchical explanation was not separately reported in the final generalized relation VI. EXTRACTION OF MULTI-LEVEL ASSOCIATIONS FROM T OXIC RELEASE INVENTORY DATA A data-mining task, for which we have chosen to empirically test the AOFI method, was to provide a concise and exact summary of toluene emission in the air of Louisiana in 2001 \(the most current dataset provided by U.S. Environmental Protection Agency We have chosen this particular toxin since it is a chemical most commonly reported to the Toxics Release Inventory [13] by the local industrial facilities Toxics Release Inventory \(TRI database, which has been created under the Emergency Planning and Community Right-t o-Know Act \(EPCRA in 1986. The 2001 TRI dataset contains information on releases of approximately 650 toxic chemicals. The data was gathered from over 21,000 manufacturing facilities located within the US When performing our method over the dataset we concentrate our analysis on three main aspects: \(1 Localization of the toluene emitters \(i.e. discovery of regions in Louisiana which have high air emission of the chemical 2 state \(i.e. estimation of the toxicity level in different regions of Louisiana 3 responsible for the local toxification \(i.e. types of businesses which are emitting toluene in the air of Louisiana i.e. Standard Industry Code TABLE 1. Number of concepts at each abstraction level for each of the generalized attributes ABS_ LEVEL FACILITY_LO CALIZATION SIC_CODE TOTAL_AIR_ EMISSION 0-level 62 cities 30 original codes continous range 1-level 35 parishes 21 3-dig. groups 8 fuzzy clusters 2-level 5 regions 10 2-dig. groups 3 fuzzy clusters 3-level 2 parts 7 industry grps 1 concept 4-level 1 concept 1 concept The 2005 IEEE International Conference on Fuzzy Systems788 Fig. 2. Fuzzy concept hierarchy for generalization of FACILITY_LOCALIZATION Figure 2 represents fuzzy generalization hierarchy for generalization of facilities  localizations based on Louisiana geography. Similar hierarchies were defined by experts for the remaining two attributes, before the AOFI was performed The number of abstract descriptors at each level of concept hierarchies for the analyzed TRI dataset is presented in Table 1. The second row of this table reflects PreGeneralization [1], where attribute values are transformed to the concepts placed at the leaves of the concept hierarchies. Since this phase is performed without an increase of abstraction level \(denoted as 0abstraction level in Table 1 the leaves of the concept hierarchies are actually the original attribute values As with regular AOI, we are able to extract separate generalization paths for each attribute value from the concept hierarchies. However the fuzzy generalization paths can not be implemented in the form of lists but 


paths can not be implemented in the form of lists but need to be represented in the form of trees As in the crisp  approach, we are allowed to order steps of generalization according to our preferences Each stage of AOI can be characterized by  a vector representing the current abstraction level for each of the generalized attributes, where the order of its elements reflects the order of attributes in the generalized relation. In our example, since we generalize three columns of the table including task relevant data, we can describe PreGeneralization as \(0 0, 0 are at the 0-abstraction level. So the final possible stage \(all attribute values in each column are characterized by a single, most general concept vector \(4, 4, 3 FACILITY_LOCALIZATION and SIC_CODE are generalized to the 4th level of abstraction, and the last attribute, i.e. TOTAL_AIR_EMISSION, is abstracted to the 3rd level \(all these levels ar e final, since they reflect roots of the utilized concept hierarchies The final, generalized relation, which provides the user with information about only significant clusters of data at the abstract level, is presented in the Table 2 Each of the generated tuples can be interpreted as a conjunctive rule, characterizing release of toluene in Louisiana \(i.e. the tuples stored in the initial relation Obviously, the order of AOFI steps could reflect different data mining goals. Since we were particularly interested in analyzing what types of facilities release toluene into the air in Louisiana we decided to generalize the SIC codes as late as possible TABLE 2. Generalized \(output release in Louisiana AOFI stage FACILITY_LO CALIZATION SIC TOTAL_AIR_ EMISSION COUNT 1 5 Cajun Country 5169 Below &amp; about 603 4.52 2 5 Crossroads 5171 Below &amp; about 603 4.45 3 5 Plantation Country 286- Below &amp; about 603 5.10 4 6 Cajun Country 286- Low 7.39 5 7 Cajun Country 28-- Low 5.33 6 7 Plantation Country 28-- Low 9.61 7 7 Plantation Country 28-- Medium 5.26 8 8 South 29-- Low 5.98 9 8 South 29-- Medium 7.05 10 8 South 34-- Medium 4.69 11 8 South 51-- Low 10.02 12 10 LA 28-- Any 9.12 13 10 LA 29-- Any 5.14 14 11 LA 3--- Any 10.76 15 12 LA Any Any 5.54 When mapping generated abstract tuples into characteristic rules at a common level of abstraction with quantitative information about support of these BOSSIER L A SPORTSMAN'S PARADISE SOUTHNORTH CALDWELL CROSSROADS RAPIDES BEAUREGARD ST. JAMES CAJUN COUNTRY ASSUMPTION  0.20.8 


0.20.8 0.75 0.25 0.9 0.1 City 1 City 2 City ... City ... City ... City 1.0 1.01.01.0 1.0 1.0 1.0 1.0 1.0 0.9 NATCHITOCHES 0.90.1 0.4 0.60.1 1.0 1.0 1.0 A B ST R A C TI O N L EV EL 1 2 3 4 0 The 2005 IEEE International Conference on Fuzzy Systems789 characteristics, we must ensure preservation of the distribution of COUNT according to the background knowledge as reflected in the fuzzy concept hierarchies For instance, if we are particularly interested in the business sector classified by government as 51  i.e Wholesale Trade of the Non-durable Goods merge the 1st,  2nd and 11th record of the generalized relation to build the following characteristic rule South? Cajun Country? Crossroads 51--? 5169 5171 Low ? Below and about 603 This rule can be further simplified to the form South ? Crossroads abstract description of 18.99% \(i.e 4.52%+4.45%+10.02 records. However if we want to transform this characterization to a more general form, such as: South 51-- ? Low , we have to remember that according to the fuzzy concept hierarchy presented in the Figure 2 only 25%  of the Crossroads country lies in the southern Louisiana, therefore in this generalization a summarization of the COUNT values needs to be appropriately modified 10.02% + 4.52% + 0.25*4.45%  = 15.65 Now we can conclude that almost 19% of facilities which officially reported a release of toluene into the air of Louisiana, are the wholesale traders of nondurable goods and that over 82% of them \(i.e 15.65 / 18.99 = 0.8241 part of the state. All these  51-type  facilities released only low amounts of toluene VI I. CONCLUSIONS In this paper we first introduced a consistent model of fuzzy induction and then applied it to mine generalized association rules  from environmental data In addition, we presented how the generated results can be explained to users via extraction of their approximate definitions There are many aspects by which we may judge the technique presented here. The ordinary \(crisp will usually perform with higher computational efficiency then AOFI. However utilization of fuzzy 


efficiency then AOFI. However utilization of fuzzy concept hierarchies provides more flexibility in reflecting expert knowledge and so allows better modeling of real-life dependencies among attribute values, which will lead to more satisfactory overall results for the induction process. The drawback of the computational cost may additionally decline when we notice that, in contrast to many other data mining algorithms, hierarchical induction algorithms need to run only once through the original \(i.e. massive dataset. We are continuing an investigation of computational costs of our approach for large datasets ACKNOWLEDGMENT Rafal Angryk would like to thank the Montana NASA EPSCoR Grant Consortium for sponsoring this research REFERENCES 1] J. Han , M. Kamber, Data Mining: Concepts and Techniques, Morgan Kaufmann, New York, NY 2000 2] J. Han, Y. Cai, and N. Cercone  Knowledge discovery in databases: An attribute-oriented approach  Proc. 18th Int. Conf. Ver y Large Data Bases, Vancouver, Canada, 1992, pp. 547-559 3] J. Han  Towards Efficient Induction Mechanisms in Database Systems  Theoretical Computing Science, 133, 1994, pp. 361-385 4] J. Han, Y. Fu  Discovery of Multiple-Level Association Rules from Large Databases  IEEE Trans.  on KD E, 11\(5 5] C.L. Carter, H.J. Hamilton  Efficient AttributeOriented Generalization for Knowledge Discovery from Large Databases  IEEE Trans. on KDE 10\(2 6] R.J. Hilderman, H.J. Hamilton, and N. Cercone  Data mining in large databases using domain generalization graphs  Journal of Intelligent Information Systems, 13\(3 7] C.-C. Hsu  Extending attribute-oriented induction algorithm for major values and numeric values   Expert Systems with Applications , 27, 2004, pp 187-202 8] D.H. Lee, M.H. Kim  Database summarization using fuzzy ISA hierarchies  IEEE Trans . on SMC - part B, 27\(1 9] K.-M. Lee  Mining generalized fuzzy quantitative association rules with fuzzy generalization hierarchies  20th NAFIPS Int'l Conf., Vancouver Canada, 2001, pp. 2977-2982 10] J. C. Cubero, J.M. Medina, O. Pons &amp; M.A. Vila  Data Summarization in Relational Databases through  Fuzzy Dependencies  Information Sciences, 121\(3-4 11] G. Raschia, N. Mouaddib  SAINTETIQ:a fuzzy set-based approach to database summarization   Fuzzy Sets and Systems, 129\(2 162 12] R. Angryk, F. Petry  Consistent fuzzy concept hierarchies for attribute generalization  Proceeding of the IASTED Int. Conf. on Information and Knowledge Sharing, Scottsdale AZ, USA, November 2003, pp. 158-163 13] Toxics Release Inventory \(TRI available EPA database hosted at http://www.epa.gov/tri/tridata/tri01/index.htm The 2005 IEEE International Conference on Fuzzy Systems790 pre></body></html 


the initial global candidate set would be similar to the set of global MFIs. As a result, during the global mining phase the communication and synchronization overhead is low  0 2 4 6 8 1 0 Number of Nodes Figure 5. Speedup of DMM 4.4.2 Sizeup For the sizeup test, we fixed the system to the 8-node con figuration, and distributed each database listed in Table 2 to the 8 nodes. Then, we increased the local database sire at each node from 45 MB to 215 MB by duplicating the initial database partition allocated to the node. Thus, the data distribution characteristics remained the same as the local database size was increased. This is different from the speedup test, where the database repartitioning was per formed when the number of nodes was increased. The per formance of DMM is affected by the database repartitioning to some extent, although it is usually very small. During the sizeup test, the local mining result of DMM is not changed at all at each node The results shown in Figure 6 indicate that DMM has a very good sizeup property. Since increasing the size of local database did not affect the local mining result of DMM at each node, the total execution time increased just due to more disk U 0  and computation cost which scaled almost linearly with sizeup 5 Conclusions In this paper, we proposed a new parallel maximal fre quent itemset \(MFI Max-Miner \(DMM tems. DMM is a parallel version of Max-Miner, and it re quires low synchronization and communication overhead compared to other parallel algorithms. In DMM, Max Miner is applied on each database partition during the lo 0 45 90 135 180 225 270 Amwnt of Data per Node \(ME Figure 6. Sizeup of DMM cal mining phase. Only one synchronization is needed at thc end of this phase to construct thc initial global candi date set. In the global mining phase, a top-down search is performed on the candidate set, and a prefix tree is used to count the candidates with different length efficiently. Usu ally, just a few passes are needed to find all global maximal frequent itemsets. Thus, DMM largely reduces the number of synchronizations required between processing nodes Compared with Count Distribution, DMM shows a great improvement when some frequent itemscts are large \(i.e long patterns employed by DMM for efficient communication between nodes; and global support estimation, subset-infrequency based pruning, and superset-frequency based pruning are used to reduce the size of global candidate set. DMM has very good speedup and sizeup properties References I ]  R. Agrawal and R. Srikant  FdSt Algorithms for Mining As sociation Rules  Pmc. o f f h e  ZOrh VLDB Conf, 1994, pp 487499 2] R. Agrawal and I. C. Shafer  Parallel Mining of Association Rules  IEEE Trans. on Knowledge and Dura Engineering Vol. 8, No. 6, 1996, pp. 962-969 3] R. I. Bayardo  Efficient Mining Long Patlems from Databases  Proc. ofrhe ACM SIGMOD Inf  l Conf on Man ogemenr ofDara, 1998, pp. 85-91 4] S.  M. Chung and J. Yang  A Parallel Distributive Join Al gorithm for Cube-Connected Multiprocessors  IEEE Trans on Parallel and Disrribured Systems, Vol. 7, No. 2, 1996, pp 127-137 51 M. Snir, S. Otto. S. Huss-Lederman, D. Walker, and J. Don gana, MPI: The Complete Reference, The MIT Press, 1996 


gana, MPI: The Complete Reference, The MIT Press, 1996 6] R. Rymon  Search through Systematic Set Enumeralion   Pmc. of3rd Inr  l Con$ on Principles of Knowledge Repre sentation and Reasoning, 1992, pp. 539-550 507 pre></body></html 


sketch-index in answering aggregate queries. Then Section 5.2 studies the effect of approximating spatiotemporal data, while Section 5.3 presents preliminary results for mining association rules 5.1 Performance of sketch-indexes Due to the lack of real spatio-temporal datasets we generate synthetic data in a way similar to [SJLL00 TPS03] aiming at simulation of air traffic. We first adopt a real spatial dataset [Tiger] that contains 10k 2D points representing locations in the Long Beach county \(the data space is normalized to unit length on each dimension These points serve as the  airbases  At the initial timestamp 0, we generate 100k air planes, such that each plane \(i uniformly generated in [200,300], \(ii, iii destination that are two random different airbases, and iv  the velocity direction is determined by the orientation of the line segment connecting its source and destination airbases move continually according to their velocities. Once a plane reaches its destination, it flies towards another randomly selected also uniform in [0.02, 0.04 reports to its nearest airbase, or specifically, the database consists of tuples in the form &lt;time t, airbase b, plane p passenger # a&gt;, specifying that plane p with a passengers is closest to base b at time t A spatio-temporal count/sum query has two parameters the length qrlen of its query \(square number qtlen of timestamps covered by its interval. The actual extent of the window \(interval uniformly in the data space \(history, i.e., timestamps 0,100 air planes that report to airbases in qr during qt, while a sum query returns the sum of these planes  passengers. A workload consists of 100 queries with the same parameters qrlen and qtlen The disk page size is set to 1k in all cases \(the relatively small page size simulates situations where the database is much more voluminous specialized method for distinct spatio-temporal aggregation, we compare the sketch-index to the following relational approach that can be implemented in a DBMS. Specifically, we index the 4-tuple table lt;t,b,p,a&gt; using a B-tree on the time t column. Given a count query \(with window qr and interval qt SELECT distinct p FROM &lt;t,b,p,a&gt WHERE t?qt &amp; b contained in qr The performance of each method is measured as the average number of page accesses \(per query processing a workload. For the sketch-index, we also report the average \(relative Specifically, let acti and esti be the actual and estimated results of the i-th query in the workload; then the error equals \(1/100 set the number of bits in each sketch to 24, and vary the number of sketches The first experiment evaluates the space consumption Figure 5.1 shows the sketch index size as a function of the number of sketches used \(count- and sum-indexes have the same results more sketches are included, but is usually considerably smaller than the database size \(e.g., for 16 signatures, the size is only 40% the database size 0 20 40 60 80 


80 100 120 140 160 8 16 32 number of sketches size \(mega bytes database size Figure 5.1: Size comparison Next we demonstrate the superiority of the proposed sketch-pruning query algorithm, with respect to the na  ve one that applies only spatio-temporal predicates. Figure 5.2a illustrates the costs of both algorithms for countworkloads with qtlen=10 and various qrlen \(the index used in this case has 16 sketches also illustrate the performance of the relational method which, however, is clearly incomparable \(for qrlen?0.1, it is worse by an order of magnitude we omit this technique Sketch-pruning always outperforms na  ve \(e.g., eventually two times faster for qrlen=0.25 increases with qrlen, since queries returning larger results tend to set bits in the result sketch more quickly, thus enhancing the power of Heuristics 3.1 and 3.2. In Figure 5.2b, we compare the two methods by fixing qrlen to 0.15 and varying qtlen. Similar to the findings of [PTKZ02]4 both algorithms demonstrate  step-wise  growths in their costs, while sketch-pruning is again significantly faster The experiments with sum-workloads lead to the same observations, and therefore we evaluate sketch-indexes using sketch-pruning in the rest of the experiments 4 As explained in [PTKZ02], query processing accesses at most two paths from the root to the leaf level of each B-tree regardless the length of the query interval Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE sketch-pruning naive relational 0 100 200 300 400 500 600 700 800 900 0.05 0.1 0.15 0.2 0.25 number of disk accesses query rectangle length 300 0 100 200 400 500 600 1 5 10 15 20 number of disk accesses query interval length a qtlen=10 b qrlen=0.15 Figure 5.2: Superiority of sketch-pruning \(count As discussed in Section 2, a large number of sketches reduces the variance in the resulting estimate. To verify this, Figure 5.3a plots the count-workload error of indexes 


using 8-, 16-, and 32- sketches, as a function of qrlen qtlen=10 error \(below 10 it increases slowly with qrlen used, however, the error rate is much higher \(up to 30 and has serious fluctuation, indicating the prediction is not robust. The performance of 16-sketch is in between these two extremes, or specifically, its accuracy is reasonably high \(average error around 15 much less fluctuation than 8-sketch 32-sketch 16-sketch 8-sketch relative error 0 5 10 15 20 25 30 35 0.05 0.1 0.15 0.2 0.25 query rectangle length relative error 0 5 10 15 20 25 30 35 1 5 10 15 20 query interval length a qtlen=10, count b qrlen=0.15, count relative error query rectangle length 0 5 10 15 20 25 0.05 0.1 0.15 0.2 0.25 relative error query interval length 0 5 10 15 20 25 30 1 5 10 15 20 c qtlen=10, sum d qrlen=0.15, sum Figure 5.3: Accuracy of the approximate results The same phenomena are confirmed in Figures 5.3b where we fix qrlen to 0.15 and vary qtlen 5.3d \(results for sum-workloads number of sketches improves the estimation accuracy, it also leads to higher space requirements \(as shown in Figure 5.1 Figures 5.4a and 5.4b show the number of disk accesses for the settings of Figures 5.3a and 5.3b. All indexes have almost the same behavior, while the 32-sketch is clearly more expensive than the other two indexes. The interesting observation is that 8- and 16-sketches have 


interesting observation is that 8- and 16-sketches have almost the same overhead due to the similar heights of their B-trees. Since the diagrams for sum-workloads illustrate \(almost avoid redundancy 32-sketch 16-sketch 8-sketch number of disk accesses query rectangle length 0 50 100 150 200 250 300 350 400 0.05 0.1 0.15 0.2 0.25 number of disk accesses query interval length 0 50 100 150 200 250 300 350 1 5 10 15 20 a qtlen=10 b qrlen=0.15 Figure 5.4: Costs of indexes with various signatures Summary: The sketch index constitutes an effective method for approximate spatio-temporal \(distinct aggregate processing. Particularly, the best tradeoff between space, query time, and estimation accuracy obtained by 16 sketches, which leads to size around 40 the database, fast response time \(an order of magnitude faster than the relational method average relative error 5.2 Approximating spatio-temporal data We proceed to study the efficiency of using sketches to approximate spatio-temporal data \(proposed in Section 4.1 as in the last section, except that at each timestamp all airplanes report their locations to a central server \(instead of their respective nearest bases maintains a table in the form &lt;time t, plane p, x, y&gt;, where x,y with parameters qrlen and qtlen distinct planes satisfying the spatial and temporal conditions. For comparison, we index the table using a 3D R*-tree on the columns time, x, and y. Given a query, this tree facilitates the retrieval of all qualifying tuples, after which a post-processing step is performed to obtain the Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE number of distinct planes \(in the sequel, we refer to this method as 3DR method introduces a regular res  res grid of the data space, where the resolution res is a parameter. We adopt 16 sketches because, as mentioned earlier, this number gives the best overall performance Figure 5.5 compares the sizes of the resulting sketch indexes \(obtained with resolutions res=25, 50, 100 the database size. In all cases, we achieve high compression rate \(e.g., the rate is 25% for res=25 evaluate the query efficiency, we first set the resolution to the median value 50, and use the sketch index to answer workloads with various qrlen \(qtlen=10 


workloads with various qrlen \(qtlen=10 size \(mega bytes database size 0 20 40 60 80 100 120 140 160 25 50 100 resolution Figure 5.5: Size reduction Figure 5.6a shows the query costs \(together with the error in each case method. The sketch index is faster than 3DR by an order of magnitude \(note that the vertical axis is in logarithmic scale around 15% error observations using workloads with different qtlen Finally, we examine the effect of resolution res using a workload with qrlen=0.15 and qtlen=10. As shown in Figure 5.6c, larger res incurs higher query overhead, but improves the estimation accuracy Summary: The proposed sketch method can be used to efficiently approximate spatio-temporal data for aggregate processing. It consumes significantly smaller space, and answers a query almost in real-time with low error 3D Rsketch number of disk accesses query rectangle length 1 10 100 1k 10k 0.05 0.1 0.15 0.2 0.25 16 14% 15 15% 13 relative error number of disk accesses query interval length 1 10 100 1k 10k 1 5 10 15 20 16 15% 15% 12% 11 relative error a qtlen=10, res=25 b qrlen=0.15, res=25 0 500 1000 1500 2000 2500 25 50 100 number of disk accesses resolution 20% 15% 14 relative error c qrlen=0.15, qtlen=10 


c qrlen=0.15, qtlen=10 Figure 5.6: Query efficiency \(costs and error 5.3 Mining association rules To evaluate the proposed algorithm for mining spatiotemporal association rules, we first artificially formulate 1000 association rules in the form \(r1,T,90 with 90% confidence i randomly picked from 10k ones, \(ii in at most one rule, and \(iii Then, at each of the following 100 timestamps, we assign 100k objects to the 10k regions following these rules. We execute our algorithms \(using 16 sketches these rules, and measure \(i  correct  rules divided by the total number of discovered rules, and \(ii successfully mined Figures 5.7a and 5.7b illustrate the precision and recall as a function of T respectively. Our algorithm has good precision \(close to 90 majority of the rules discovered are correct. The recall however, is relatively low for short T, but gradually increases \(90% for T=25 evaluated in the previous sections, the estimation error decreases as the query result becomes larger \(i.e., the case for higher T 78 80 82 84 86 88 90 92 94 96 5 10 2015 25 precision HT 78 80 82 84 86 88 90 92 94 96 5 10 2015 25 recall HT a b Figure 5.7: Efficiency of the mining algorithm Summary: The preliminary results justify the usefulness of our mining algorithm, whose efficiency improves as T increases Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE 6. Conclusions While efficient aggregation is the objective of most spatio-temporal applications in practice, the existing solutions either incur prohibitive space consumption and query time, or are not able to return useful aggregate results due to the distinct counting problem. In this paper we propose the sketch index that integrates traditional approximate counting techniques with spatio-temporal indexes. Sketch indexes use a highly optimized query algorithm resulting in both smaller database size and faster query time. Our experiments show that while a sketch index consumes only a fraction of the space required for a conventional database, it can process 


required for a conventional database, it can process queries an order of magnitude faster with average relative error less than 15 While we chose to use FM sketches, our methodology can leverage any sketches allowing union operations Comparing the efficiency of different sketches constitutes a direction for future work, as well as further investigation of more sophisticated algorithms for mining association rules. For example, heuristics similar to those used for searching sketch indexes may be applied to improve the brute-force implementation ACKNOWLEDGEMENTS Yufei Tao and Dimitris Papadias were supported by grant HKUST 6197/02E from Hong Kong RGC. George Kollios, Jeffrey Considine and were Feifei Li supported by NSF CAREER IIS-0133825 and NSF IIS-0308213 grants References BKSS90] Beckmann, N., Kriegel, H., Schneider, R Seeger, B. The R*-tree: An Efficient and Robust Access Method for Points and Rectangles. SIGMOD, 1990 CDD+01] Chaudhuri, S., Das, G., Datar, M., Motwani R., Narasayya, V. Overcoming Limitations of Sampling for Aggregation Queries. ICDE 2001 CLKB04] Jeffrey Considine, Feifei Li, George Kollios John Byers. Approximate aggregation techniques for sensor databases. ICDE, 2004 CR94] Chen, C., Roussopoulos, N. Adaptive Selectivity Estimation Using Query Feedback. SIGMOD, 1994 FM85] Flajolet, P., Martin, G. Probabilistic Counting Algorithms for Data Base Applications JCSS, 32\(2 G84] Guttman, A. R-Trees: A Dynamic Index Structure for Spatial Searching. SIGMOD 1984 GAA03] Govindarajan, S., Agarwal, P., Arge, L. CRBTree: An Efficient Indexing Scheme for Range Aggregate Queries. ICDT, 2003 GGR03] Ganguly, S., Garofalakis, M., Rastogi, R Processing Set Expressions Over Continuous Update Streams. SIGMOD, 2003 HHW97] Hellerstein, J., Haas, P., Wang, H. Online Aggregation. SIGMOD, 1997 JL99] Jurgens, M., Lenz, H. PISA: Performance Models for Index Structures with and without Aggregated Data. SSDBM, 1999 LM01] Lazaridis, I., Mehrotra, S. Progressive Approximate Aggregate Queries with a Multi-Resolution Tree Structure. SIGMOD 2001 PGF02] Palmer, C., Gibbons, P., Faloutsos, C. ANF A Fast and Scalable Tool for Data Mining in Massive Graphs. SIGKDD, 2002 PKZT01] Papadias,  D., Kalnis, P.,  Zhang, J., Tao, Y Efficient OLAP Operations in Spatial Data Warehouses. SSTD, 2001 PTKZ02] Papadias, D., Tao, Y., Kalnis, P., Zhang, J Indexing Spatio-Temporal Data Warehouses ICDE, 2002 SJLL00] Saltenis, S., Jensen, C., Leutenegger, S Lopez, M.A. Indexing the Positions of Continuously Moving Objects. SIGMOD 2000 SRF87] Sellis, T., Roussopoulos, N., Faloutsos, C The R+-tree: A Dynamic Index for MultiDimensional Objects. VLDB, 1987 TGIK02] Thaper, N., Guha, S., Indyk, P., Koudas, N Dynamic Multidimensional Histograms 


SIGMOD, 2002 Tiger] www.census.gov/geo/www/tiger TPS03] Tao, Y., Papadias, D., Sun, J. The TPR*Tree: An Optimized Spatio-Temporal Access Method for Predictive Queries. VLDB, 2003 TPZ02] Tao, Y., Papadias, D., Zhang, J. Aggregate Processing of Planar Points. EDBT, 2002 TSP03] Tao, Y., Sun, J., Papadias, D. Analysis of Predictive Spatio-Temporal Queries. TODS 28\(4 ZMT+01] Zhang, D., Markowetz, A., Tsotras, V Gunopulos, D., Seeger, B. Efficient Computation of Temporal Aggregates with Range Predicates. PODS, 2001 ZTG02] Zhang, D., Tsotras, V., Gunopulos, D Efficient Aggregation over Objects with Extent PODS, 2002 Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE pre></body></html 



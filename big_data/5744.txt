Method of Association Rule Based on Im proved Genetic Algorithm and Application of Network Consuming for the Contemporary Youth  Xiang Zhuoyuan  Zhongnan University of Economics and Law School of Information and Safety Engineering Hubei, Wuhan e-mail: xiangzy2005@yahoo.com.cn  Li Ying  Zhongnan University of Economics and Law School of Information and Safety Engineering Hubei, Wuhan e-mail: Christina.1101@163.com  Abstract  Genetic Algorithm and Association Rules both are commonly used methods in data mining. In this paper, a brief overview of Genetic Algorithm and Association Rules has been given, and this paper has presented an improved extract method of association rules of genetic algorithm based on their respective advantages and disadvantages. It also did some research on designing encoding methods, structuring and choosing fitness functions, and improving crossover operators and mutation operators. In the end, the analysis of contemporary youth consumption condition has been shown as a specific example to illustrate the process of mining association rules of contemporary youth s consumption behavior Keywords-Data mining, Genetic Algorithm, Association Rules, Network Consuming I  I NTRODUCTION  Data Mining is to extract th e hidden, implicit and valid information and knowledge from numerous and irregular practical data 1 Mining Association Rules is an important aspect of data mining and it is also an important kind of rule contained in the data. Its goal is to find all the concurrency relation in the data items. However, Association Rules only concern about support and confidence, and this may probably arouse some false rules, and in the meanwhile mining frequent itemset is a difficult job because it will take a lot of time to traverse all the records in a database for several times. And the Genetic Algorithm has its own unique advantages in solving large space, nonlinear and global optimization problems; just to make up for the weakness of Association Rules. This paper has presented an algorithm for mining based on the improved Association Rules of Genetic Algorithm. This can greatly improve the algorithm  s calculate efficiency by avoiding the production of numerous frequent itemsets 2 
 II   R ELEVANT C ONCEPTIONS AND P RINCIPLES  Association Rules Let 12 I{i,i i m 002 i m  be the items, and D be the set of all transactions, transaction T is a subset of set I set TI 003 and each transaction has its own transaction ID identification. An association rule is defined as an implication of the form XY 004 where XI 003 002 YI 003 and XY 005 Y  005  X is called antecedent of the rule, and Y is the consequent of the rule. Association Rules has two widely-used numbers to express the degree of uncertainty of the rules 1  Support S XY 004 T contains the percentage of transactions in the set XY Y it shows the frequency that the rule has been used in the transaction T S 002 XY 004 002  D    XY TDT T 003\006 
  
   
  002 2-1 002  2\ Confident C XY 004 it is the percentage of amounts contains both transaction X and Y occupy in all the amounts contain transaction X C 002 XY 004 002  D   D   XY TDT XTDT 003\006 003\006   
   
 002 002 2-2 002  Genetic Algorithm Genetic Algorithm is a mechanism that premised on the evolutionary ideas of natural selection and genetic 3-5 It simulates the method of searching optimal solution in natural evolutionary process. The method is to improve the individual  s adaptability through natural selection, genetic and variation mechanism. Usually, in the simple genetic algorithm, during the process of crossover, the two individuals are randomly picked. And this means has some kind of one-sidedness. It cannot find all the global optimal solutions. What has been used in this paper is an improved algorithm based on the traditional simple genetic algorithm III  M INING A SSOCIATION R ULES B ASED O N G ENETIC A LGORITHM  A    Encoding In the Genetic Algorithm, there are several kinds of encoded mode, such as binary coding, real coding, symbolic coding and variable length coding. And usually we  ll take the binary coding, but due to the high accuracy, low volatility of 
2011 International Conference on Management of e-Commerce and e-Government 978-0-7695-4544-8/11 $26.00 © 2011 IEEE DOI 10.1109/ICMeCG.2011.45 3 
2011 International Conference on Management of e-Commerce and e-Government 978-0-7695-4544-8/11 $26.00 © 2011 IEEE DOI 10.1109/ICMeCG.2011.45 3 


coded-decimal notation, we choose decimal coding in this paper. That means to give each attribute a decimal number then each decimal number can represent gene. Put all the decimal numbers \(represent the attribute\ of one individual together to form a decimal string. Each string represents a chromosome, the carrier of genetic information Then, use the real number array method for encoding The numbers of the elements in the real number array should be in accordance with the number of fields in the transaction database. Each element represen ts an attribute value of the field. Suppose to use an array of length N for the individual encoding in a transaction database, that means A[1  represents field 1, A r e pr esen ts f iel d  2  A[R  represents field R 6 After the encoding, crossover and variation operation have become array operation B.    Construct Fitness Function  Fitness Function is used to evaluate the performance of individuals of the population in Genetic Algorithm. This will help us pick the individuals with high confidence. We can use the support and confidence of association rules to define its fitness value, that is fitness 002 XY 004 002 S 002 XY 004 002 C 002 XY 004 002 002 3-1 002  It means that only those individuals with high support and confidence can survive. This will make the association rules we mined more reliable than those rules mined based on the fitness function which is defined only with the consideration of support Improve the Genetic Operators According to the characters of association rules and the weakness of traditional basic genetic algorithm, we can improve the basic genetic algorithm from the operator perspective. This will accelerate the genetic evolution process, and can also enhance the global convergence of the algorithm to avoid the premature convergence 1\ Choose operator Choosing operator is in order to avoid gene deletion and to enhance global converg ence and calculate efficiency It is established base on the evaluation of the individual s fitness. It picks those chromosomes with high degree of adaption from the initial population, and then put them into the mating pool preparing for the crossover to generate new population. Generally, simple genetic algorithm often use roulette wheel selection, but this method is easy to result in premature convergence, and can probably make the genetic algorithm lose its evaluation ability. In this paper we have chosen another selection algorithm instead of the roulette wheel selection, and in this algorithm individuals are sorted according to their degree of fitness. And copy the sorted population one more time can improve its quality. The description of this algorithm is as follows  Sort the individuals of population according to their degree of fitness  Do while \(the population hasn  t been scanned over   Copy the top 20% of the excellent individuals  Do not copy the 80% normal individuals   2\ Crossover Operator Generally speaking, there are two ways in crossover one is point crossover and the other is multiple point crossovers. Because this paper has adopt the decimal coding method, so the crossover operators will make the two selected individual genes cross randomly for n times according to the point crossover method. This will generate 2n offspring, and then choose the best two individuals of them into the next generation. This will keep the genes of male parent and female parent, and can also improve the performance of genetic algorithm  3\ Mutation Operator Although mutation operator is just a helping method in the genetic algorithm to generate new individuals, it is a necessary step in the algorithm, because it determines the local searching ability of genetic algorithm. The mutation operator presented in this paper is that: To take a random value form the corresponding gene range to a predetermined probability to substitute the origin gene value, and generate a new chromosome. Therefore, the search point can move freely in the whole searching space. This can enhance the population  s diversity  4\ Rules Extraction The output of rules extraction is not an optimal solution but a set that accords with the rules  requirements. Use the association rules to extract the rules according to the pre-set support and confidence requirem ents, and if the rules fit the requirements then output th em, otherwise, reject them IV  T HE APPLICATION OF IMPROVED ALGORITHM  Today, the study and life condition for new generation is much better than before. Their consumption level and structure have changed a lot. With the fast development of E-commerce, network consumption spreads quickly among young consumers, and it is becoming the main form of consuming gradually. What kinds of consuming habit and behavior can instruct college students to establish correct consuming concept, how to give suggestions to them, this means a lot to society and individuals. The example below uses these improved methods discussed above to mine and conclude the consuming situation of the contemporary youth nowadays Select 200 data samples according to results of investigation, freshman, sopho more, junior and senior account for 25% separately. Maintain those useful columns 
4 
4 


remove those useless ones, such as name, student ID. There are many factors affect college studentsê consuming view here we select 6 main factors, related with 6 attributes, so the length of code string is six, attributes are as below: grade sex, develop status of hometown, monthly family revenue monthly consuming status, network consuming amount  A  The coding method of genetic algorithm  It can do decimal coding for each attribute; it should keep the sequence of fields consis tent when coding, coding as follows: the attribute values of grade field are grade one grade two, grade three and grade four, the corresponding coding values are 1, 2, 3 and 4; similarly, male is 1, and female is 2; the field values of development level of domestic seat are developed, relatively developed, general and underdeveloped, the corresponding coding values are 1 2, 3 and 4; the field values of family income per month are less than 2000 Yuan, from 2000 to 4000 Yuan, from 4000 to 6000 Yuan, and over 6000 Yuan, the corresponding coding values are 1, 2, 3 and 4; the field values of consumption level per month are under 500 Yuan, from 500 to 800 Yuan from 800 to 1000 Yuan, and over 1000 Yuan, the corresponding coding values are 1, 2, 3 and 4; the field values of network consumption amount are no network consumption, from 50 to 100 Yuan, from 100 to 200 Yuan from 200 to 300 Yuan and over 300 Yuan, the corresponding coding values are 1, 2, 3 , 4 and 5 For example: code value  212321  is means that it is a male of grade two, the develo pment level of domestic is relatively developed, the family income per month is between 4000 and 6000 Yuan, the consumption level per month is between 500 and 800 Yuan and no network consumption. The coding table is as Fig. 1 below  Table 1: Coding Table S1 S2 S3 S4 S5 S6 2 3 1   2 1 2   1 2 3   2 4 3   1 2 1   1 2 3    B  The basic idea of algorithm According to the idea of genetic algorithm, you can do some operations to species group, such as encode, select, intersect and variation, finally you can draw some useful association rules. The main promotion lies in taking support and confidence as calculation standard of fitness function in the meantime, and considering the influence of two individuals In the initial species group, it will produce more excellent individual copy, which can raise the quality of species group According to the mutation operator on variation, and then adjust the individuals in the two small species groups according to the fitness size, further guarantees the quality of population C   The implementation steps of algorithm Step 1: initialization. It will randomly generate an initial species group which include N individuals after coding, and then calculate the fitness an d average fitness of each individual in species group according to the calculation formula of fitness which has been defined above Step 2: sorting each individual in the species group according to their fitness size from large to small Step 3: copying individuals according to the size of fitness. Copying the top 20% individuals, and don t copy the rest 80% individuals, and calculating the number of reserved individuals as M Step 4: if M<N, then randomly generates N-M individuals, and keep the total number N of species group otherwise skip step 4 Step 5: comparing the individuals according to fitness and average fitness, and then confirm the individual mutation rate Step 6: calculating the minimum fitness value of top 20% excellent individuals and the maximum fitness value of 80% general individuals, if the minimum fitness value is less than the maximum fitness valu e, then exchange the two individuals, otherwise jump to step 7; repeating this step until it can  t exchange, then jump to step 7 Step 7: selecting two individuals from top 20 excellent individuals copy group randomly, then conducting many single points across to the two individuals, finally selecting the most excellent individual from the obtained individuals and storing into new species group Step 8: stopping until it meets end conditions otherwise jump to step 2 Step 9: drawing the rules  D  Association rules extraction According to the front algorithm, application examples can be found in the part of association rules as follows 3213 004 000022>  \(35%support 002 100%confidence Namely < grade: junior, gender: female, domestic development level: developed, family income: 4,000 to 6,000 Yuan 004  monthly consumption level: 500 ~ 800 Yuan, network consumption amount: 100 to 200 Yuan 1132 004 000034>  \(21%support 002 100%confidence Namely < grade: freshman, gender: male, domestic development level: generally, family income: 2,000 to 4,000 Yuan 004  monthly consumption level: 800 ~ 1000 Yuan no network consumption 4213 004 000023>  \(13%support 002 96%confidence Namely < grade: senior, gender: female, domestic development level: developed, family income: 4,000 to 6,000 Yuan 004  monthly consumption level: 800 ~ 1000 Yuan, network consumption amount: 100 to 200 Yuan 
5 
5 


2124 004 000045>  \(7%support 002 94%confidence Namely < grade: sophomore, gender: female, domestic development level: more developed, family income: above 6,000 Yuan 004  monthly consumption level: above 1000 Yuan, network consumption am ount: above 300 Yuan According to the above result of extracting rules, we can get the conclusion that the family of level high monthly consumption income also has the high consumption level Network consumption amount also depends on the monthly consumption level; the person who comes from the domestic that developed well, can accept outside new things faster, so has the advancing consumption concept; In the groups of the contemporary youth network consumer, girls accounts for the majority of network consumption, thus it can be seen that women are more attractive to the network consumption V   C ONCLUSION  This article combined genetic algorithm with association rules, and constructed association rules mining model in data mining by genetic algorithm, and then calculated the fitness function through the support degree and confidence degree found law hidden in the database, to help us analyze and solve problems. Using the decimal array coding method, it facilitated operation of crossover, mutation, and selection operators. Association rules mining technology, based on the genetic algorithm, can also be used in the student information analysis, financial credit risk analysis, traffic accidents analysis and other areas. It has very good practical value  R EFERENCES  1 N J  PE I J 9 YIN Y. Mining Frequent Patterns Without Candidate Generation[A I n SI G M O D 00 C  D a l l a s  T X 201 0 112   2 Ka p u r J N  Ke s a v a n H K E n t r o p y O p t i m i z a t i o n P r i n c i p l e s wi t h  Applications, Academic Press, 2002,1-98 3 K P  S o m a n S h ya m Di wa k a r V  A j a y   I n s i g h t  i n t o Da t a  M i n i n g T h e o r y  and Practice, China Machine Press, 2009 4 Z o ng be n X u J i a n g s he Z h a n g  Y a l i n g Z h e n g  Bio n i c s i n  Computational intelligence 9 theory and the algorithm, Science Press 2003 5 n g N in g T a n   M i c h ae l Ste i n b a c h V i p i n K u mar, I n tro d u c t i o n  to D a ta  mining, People postal Press, 2006 6 Jame s H a ig h Br ing i ng T o g e the r D r iv e r s and F i e l dbus T e ch no l o gy  Control and Instrumentation [C U S A  s  n    2 0 0 4  5 86 3   7 R A W L E Y W J, P I A T ET S K Y  S G  M A T H EUS C G  K n o w le d g e  Discovery in Database: An Overview [A  I A T E T S KY S G   FRAWLEY W J, Knowledge Discovery in Database [C  Massachusetts:AAA/MIT Press,2001.1-27 8 H A N J, D a t a  Mi ni ng T e ch ni que s  R    C a n a da S i m o n F r as e r  University,2006 9 AGR A W A L R   I M I E IN S K IT  S W AM I  A M i n i n g  As s o c i a t i o n  R u l e s Between Set of Item in Large Database [A CCA J B, JA RK E M  ZANIOLO C. VLDB94  C h i l e: M o rga n K a u f m a n n  200 4 487 499   
6 
6 


ICSSE 2011 From Figure 4, we can know that the number of rules derived by proposed approach is larger than the previous approach, especially when the minimum supports are set at small values. In other words, these results mean that there are actually more information \(useful rules\ can be derived by using TFARM. Thus, the proposed approach is effective and efficient VI C ONCLUSION A ND F UTURE W ORKS n this paper, we take item lifespan into consideration and have proposed a fuzzy temporal mining algorithm for mining fuzzy temporal association rules. The proposed approach first transforms each quantitative value into a fuzzy set using the given membership functions. Meanwhile, item lifespans are collected and recorded in temporal information table during the transformation process. Apriori-like concept is then utilized to derive fuzzy temporal association rules. Experiments on a simulation dataset also show the proposed approach can actually derive extra fuzzy rules The main contribution of this paper is that since the lifespan of each item are considered, the proposed approach can find more information inside the given transaction database. In the future, we will extend the proposed approach for solving more complexity problems A CKNOWLEDGMENT This research was supported by the National Science Council of the Republic of China under contract NSC 99-2218E-032-005 R EFERENCES 1 R A g r a w a l T  I m i e li n k s i an d A  S w a m i  Da t ab a s e m i n i n g a performance perspective IEEE Transactions on Knowledge and Data Engineering Vol. 5, No. 6, 1993, pp. 914-925 2 R. A g r a w a l and R. S r i k a n t   F ast al g o r ithm f o r m i n i ng  asso ci at io n  rules,î T he International Conference on Very Large Data Bases 1994 pp. 487-499 3 C C Ch an a nd W  H  A u  M i n i n g f u z z y asso cia tio n r u l e s The Conference on Information and Knowledge Management Las Vegas pp. 209-215, 1997 4 L  C h en  S S  Bh ow m i c k an d J  L i  M i n i n g t e m p ora l ind i rec t  associations,î Pacific-Asia Conference on Knowledge Discovery and Data Mining, 2006 5 P A  H e ng T  T  W o ng Y  Ro ng Y  P   C h u i Y   M. X i e  K  S  L e ung  and P. C. Leung, ìIntelligent inferencing and haptic simulation for Chinese acupuncture learning and training IEEE Transactions on Information Technology in Biomedicine Vol. 10, No. 1, pp. 28-41, 2006 6 T  P  Hon g C  S  K u o an d S   C   Ch i  Tr a d e o f f b e t w een t i m e complexity and number of rules for fuzzy mining from quantitative data International Journal of Uncertainty, Fuzziness and Knowledgebased Systems Vol. 9, No. 5, pp. 587-604, 2001 7 H   I s h i b u ch i and T Ya m a m o t o  Ru l e wei g h t s p eci f i ca ti on in f u zzy r u l e based classification systems IEEE Transactions on Fuzzy Systems  Vol. 13, No. 4, pp. 428-435, 2005 8 C K u ok  A  F u an d M  W o n g  M in in g f u zz y a s s o c i at i o n r u les in databases SIGMOD Record Vol. 27, No. 1, pp. 41-46, 1998 9 Y   C  Lee T P  Ho n g and W  Y. L i n  M ini n g fu zzy a s s o c i a t i on ru les  with multiple minimum supports using maximum constraints Lecture Notes in Computer Science Vol. 3214, pp. 1283-1290, 2004 10 C. H  L e e  C. R L i n an d M. S   Ch e n  O n  Mi ni ng G e ne r a l  Te m p o r al  Association Rules in a Publication Database The IEEE International Conference on Data Mining 2001  11 W  J L e e  D isco v e r y  o f f u zzy te m p o r al and pe r i o d i c asso c i a t io n r u l e s National Sun Yat-Sen University: Department of Electrical Engineering 2008  C  Y  Ch an g  M  S  Ch en  a n d  C  H  Lee M i n in g G e n e ra l Tem p o ra l  Association Rules for Items with Different Exhibition Periods The IEEE International Conference on Data Mining pp. 59-66, 2002 13 C. Z h uo L  J iah ui an d L  Che n A F u zzy Cal e ndar b as e d A l go r ithm  for Mining Temporal Association Rules and Its Application The International Conference on Fuzzy Systems and Knowledge Discovery  pp28-33, 2009 14 S  Y u e  E  T s ang  D  Y e ung  an d D  S h i  M i n i n g f u z z y asso ciat io n r u l e s with weighted items The IEEE International Conference on Systems Man and Cybernetics pp. 1906-1911 2000 15 L   A  Z a de h F uzzy s e ts  Information and Control Vol. 8, No. 3, 1965 pp. 338-353 409 


The proposed approach focuses on Mining Maximal Frequent Itemset Generation. In this paper, Array based approach and Effective Pruning Mechanism is used for generating Maximal frequent patterns There are two main ingredients to develop an efficient MFI algorithm. The first is the set of techniques used to reduce the size of search space, and the second is the representation used to perform fast frequency computations. This paper describes how proposed algorithm achieves the same  In general the structure of the transactional database may be in two different ways -Horizontal data format and Vertical data format. Here, we are using vertical data format for storing the transactions in the database. In vertical data format, the data is represented as item-tidset format, where item is the name of the item and tidset is the set of transaction identifiers containing the item Consider our example database which includes six different items, I = {A, B, C, D, E, F} and six transactions T= {1, 2, 3, 4, 5, 6}. The vertical data format of the database DB is given below Table 1 : Vertical Data format of the transactional database DB All Frequent items are extracted first. The support is directly given by the number of transactions in the tidset of each item. Let us consider the minimum support to be 3 From the above structure, all items except F are frequent The items A, B, C, D and E are frequent items and will be considered to next level In the next level a dynamic array \(N intersecting the tidsets of every two frequent items. The constructed array \(N two frequent items. The size of the array will be n\(n+1 where n is the number of frequent items. Value of each and every cell in the array is initialized to zero. The value of cell N[i,j] is 1 if number of transaction occurred in the intersection of tidset of frequent item i and j satisfies the user specified minimum support. Otherwise the cell value is zero. Once the array is constructed successfully, all possible Maximal frequent itemsets\(PMFI from the array. The constructed array is given below N ABCD 


E D C B  Table 2: Dynamic array \(N frequent items The possible maximal frequent itemsets \(PMFI obtained from this array are considered to the next level All the other itemsets are pruned. The number of possible large itemsets is less than or equal to number of frequent itemsets. From this array, PMFIs are obtained in two ways. We can take all columns and first row. \(Columns A B, C, D and row E Rows E D, C, B and Column A One column entry or one row entry is a single PMFI. For example the itemset \(x,y,z itemset if and only if there is an entry 1 in both cells N[x,y] and N[x,z]. For example ADC is a PMFI because of the values of both cells N [A, D] and N [A, C] is 1 Once all PMFIs are retrieved from the array, they are arranged in descending order with respect to their size First column entries produce the PMFI that includes the frequent item A \(ADC the PMFI includes the frequent item B \(B entries produce the PMFI that includes the frequent item C CDE the frequent item D \(D PMFI that includes the frequent item E \(EC are arranged in descending order with respect to their size So the Itemsets in PMFI are ADC, CDE, EC, B, D The First itemset ADC has no superset in MFI and it is frequent. So ADC is a MFI\(with support count 3 added to MFI The Second itemset CDE has no superset in MFI and it is a infrequent item set. so all \(n-1 includes C CDE are generated. 2-itemsets of CDE are CD and CE.\(DE is not taken for test. It does not include the item C ignored. CE is frequent and it has no supersets in MFI. So it is added to MFI. CE is a MFI\(with support count 3 obtained from CDE 


The Third itemset EC is already included in MFI and it is ignored The Forth item B has no superset in MFI and it is a frequent item and it is added to MFI The Fifth item D has a superset in MFI and it is ignored From above example, MFIs with support count 3 are ADC, CE, B The process will be continued till testing all possible maximal frequent itemsets. The pruning can be done while finding the MFI itself, but not after finding FI completely The pseudo code for proposed algorithm is given below in figure 1  Item  Tidset A  T1, T2, T3, T4 B  T1, T4, T5 C  T1, T2, T3, T5, T6 D  T1, T2, T3 E  T2, T4, T5, T6 F  T6, T5    Pseudo code Find All MFI\(PMFIs,min_sup all Maximal Frequent Itemsets Inputs i Possible Maximal Frequent itemsets ii for mining process Interfacing Functions Output i Find All MFI\(PMFIs, min_sup For each x  PMFIs if x has a superset in MFI continue else if x is frequent MFI=MFI U x else Find MFI by obtaining Permutations\(x,min_sup For End return MFI 


Find MFI by obtaining Permutations \(PMFI, min_sup Function to find Maximum Frequent Itemsets form Kitemsets of PMFI Inputs i ii defined for mining process Interfacing Functions Figure 1. Pseudo code for ABMFI Algorithm Output i Find MFI by obtaining Permutations \(PMFI, min_sup n=number of items in PMFI k=n-1; // k-itemsets Freq_item={}; S={}; do In_Freq=0; //to check infrequent itemsets C=generate k-itemsets that includes first item of PMFI; Foreach x C if x has a superset in MFI S=S U x; continue; else if x is frequent Freq_item=Freq_item U x; else In_Freq=1; For End; If PMFI==unique\(Freq_item U S MFI=MFI U Freq_item; return; End if; K--; while\(In_freq!=0 && k!=0 The proposed algorithm performs better because MFI is being calculated directly before computing FI completely The Pruning mechanism works effectively and counting is not performed for the subset of MFIs. So, the time taken to compute MFI is negligible. As we are following vertical data format, support also need not be calculated separately In this case, support is directly given by the number of transactions in the tidlist of each FI. The vertical representation has the following major advantages over the horizontal layout: Firstly, computing the support of itemsets is simpler and faster with the vertical layout since it involves only the intersections of tidsets. Secondly, with the vertical layout, there is an automatic reduction of the database before each scan in that only those itemsets that are relevant to the following scan of the mining process are accessed from disk Pruning The Possible Maximal Frequent itemsets\(Maximal 


Candidate Itemsets array. All Maximal frequent itemsets are obtained from only these PMFIs. Other itemsets are pruned automatically. The pruning can be done while finding the MFI itself, but not after finding FI completely. The proposed approach applies superset checking to eliminate the non maximal frequent itemsets. Once all PMFIs are generated, each PMFI is checked whether it is a subset of any maximal pattern. If so the itemset is eliminated entirely. Counting is not performed for this itemset and next PMFI is taken for test IV. RESULTS The testing of the proposed algorithm has been carried out on the real dataset \(containing long itemsets the number of candidate itemsets taken by the proposed algorithm to find MFIs and it is compared to Genmax algorithm for various values of minimum support. The support is varied from 75 to 95. The proposed algorithm had been compared with GenMax algorithm and results show the proposed approach generates less number of candidate itemsets to find all MFIs Figure 2 illustrates that, the proposed approach generates less number of candidate itemsets and produces all MFIs very quickly than GenMax algorithm. Support is taken as x axis and the number of candidate itemsets taken to find all MFI is taken as y axis For Mushroom, the improvement is best explained by how the MFI is computed at each level and found directly without waiting for FI completely. This leads to a much greater reduction in the overall search space, since the reductions is so great at highest levels  Figure 2. Number of Candidate itemsets taken by ABMFI and GenMax Algorithm from Mushroom dataset This approach will be working very efficiently for any sparse and dense dataset, when the size of maximal frequent itemsets is close to the number of frequent itemsets V. CONCLUSION In this paper we have investigated an array based approach and algorithm \(ABMFI itemsets. The algorithm is straight forward  basic steps are finding frequent items from the database, Dynamic 


array construction and Pruning infrequent itemset obtaining Possible Maximal Frequent itemsets from array and finding MFIs from PMFIs. Our algorithm had been compared with GenMax algorithm and obtained that the proposed algorithm generates less number of candidate itemsets to find all MFIs. The vertical data format representation of the database, Dynamic array construction and directly computing MFIs from PMFIs are the added advantages of this algorithm REFERENCES 1]. Agrawal, R., T. Imielinski and A. Swami, 1998. Mining association rules between sets of items in very large databases In the Proceedings of the ACM SIGMOD International Conference on Management of Data, May 25-28, Washington D.C., US, pp: 207-216. http://doi.acm.org 10.1145/170035.170072. [2]. Jiawei Han and Micheline Kamber, 2001. Data Mining: Concepts and Techniques. 1st Edn., Morgan Kaufmann pp: 500. ISBN-10: 1558604898. [3 Ganti, V., J. Gehrke and R. Ramakrishnan, 2000. DEMON mining and monitoring evolving data. ICDE 2000, San Diego CA., pp: 439-448. http://wwwdb.cs.wisc.edu/dbseminar/spring00 / talks/demon_paper.pdf [4 Holsheimer M., M. Kersten, H. Mannila and H. Toivonen, 1995 A perspective on databases and data mining. Proceeding of the 1st International Conference on Knowledge Discivery and Data Mining, Aug. 1995, AAAI Press, Montreal, Canada, pp 150-155, http://www.cs.helsinki.fi/ research fdk/datamining/pubs/kdd95.ps.gz [5]. Savasere, A., E Omiecinski and S. Navathe, 1995.An efficient algorithm for mining association rules in large databases. Proceedings of 21 st International VLDB Conference on Very Large Data Bases, Sep. 11-15, Morgan Kaufmann Publishers Inc. San Francisco, CA, USA ., pp:432-444 http://portal/acm.org/citation.cfm?id=673300 [6]. Ramesh C Agarwal, Charu C. Aggarwal and V.V.V. Prasad, 2001. A tree projection algorithm for generation of frequent itemsets. J Parallel Distribut. Comput., 61: 350-371. DOI: 10.1006 jpdc.2000.1693 [7]. Agrawal, R. H. Mannila, R. Srikant, H Toivonen and A.I. Verkamo, 1996. Fast Discovery of Association Rules. In: Advances in Knowledge Discovery and Data Mining, Usama Fayyad, M.G.P. Shapiro, P. Smyth, and R 


Uthurusamy,\(Eds pp: 307 -28 I. SBN:0-262-56097-6 [8]. Aggarwal, C.C. and P.S Yu, 1998. Mining large itemsets for association rules. Bull IEEE Comput. Soc. Technical Committee Data Eng.,: 23-31 http://citeseerx.ist.psu.edu/viewdoc/summary?doi 10.1.1.48.306 [9]. Aggarwal, C.C. and P.S. Yu, 1998. Online generation of association rules. In Proceedings of the 14th International Conference on Data Engineering, Feb. 23-27,IEEE Xplore, Orlando, FL, USA., pp: 402-411. DOI 10.1109/ICDE.1998.655803 [10]. Mohammed J. Zaki, 2000 Scalable algorithms for association mining. IEEE Trans. Knowl Data Eng., 12: 372 390. DOI: 10.1109/69.846291. [11]. Shenoy, P., J. Haritsa, S. Sudarshan, G Bhalotia, M. Bawa and D. Shah, 2000. Turbo-charging vertical mining of large databases. Proceeding of ACM SIGMOD International Conference on Management of Data, June 2000, Dallas, Texas USA,pp:22-33.http://doi.acm.org/10.1145/ 335191.335376 [12 Gunopulos, D., H. Mannila and S. Saluja, 1997. Discovering all most specific sentences by randomized algorithms. In Proceedings of the 6 th International Conference on Database Theory, Jan. 08-10, Springer-Verlag London, UK pp:215-229. http://portal.acm.org/citation.cfm? id=65 6097 [13]. Agrawal, R and R. Srikant, 1994. Fast algorithms for mining association rules Proceedings of the 20th International Conference on Very Large Databases Sep. 12-15, Santiago de chile, Chile, pp: 487-499. DOI: 10.1.1.40.7506. [14 Lin, D.I. and Z.M. Kedem, 1998. Pincer search: A new algorithm for discovering the maximum frequent sets. In Proceedings of the 6 th International Conference on Extending Database Technology, Mar. 23-27, Springer-Verlag London, UK.,pp:105-119. http://portal.acm.org/citation.cfm id=645338.6503 96. [15]. Park, J.S., M.S. Chen, P.S. Yu, 1995. An effective hash based algorithm for mining association rules. ACM SIGMOD Record 24: 175-186. http://doi.acm.org/10.1145/ 68271.223813 [16]. Rin Popescul and Lyle H. Ungar and Steve Lawrence and David M. Pennock 2002. Towards structural logistic regression: Combining relational and statistical learning. In Proceedings of KDD2002 Workshop on Multi-Relational Data Mining 02, ACM, Alberta, Canada, pp: 130-141 http://citeseerx.ist.psu.edu/ viewdoc/summary?doi=10.1.1.19.6235 [17 Taskar, B., E. Segal and D. Koller, 2001. Probabilistic classification and clustering in relational data. In Proceedings of the 17 


th International Joint Conference on Artificial Intelligence 01, Lawrence Erlbaum Associates Ltd USA.,pp:870-876 http://direct.bl.uk/bld/PlaceOrder.do?UIN=107907 71&ETOC=RN&from=searchengine 18]. Dunkel, B. and N. Soparkar, 1999. Dataorganization and access for effcient data mining. In the Proceedings of the 15th International Conference on Data Engineering, Mar. 23-26, IEEE Xplore, Sydney, NSW, Australia, pp 522-529. DOI: 10.1109/ICDE.1999.754968 [19]. Mohammed Zaki, J. and C.J Hsiao, 2002. CHARM: An efficient algorithm for closed itemset mining. In Proceedings of SDM02Conference http://citeseerx.ist.psu.edu/viewdoc /summary?doi=10.1.1.111.520 20]. Bastide, Y., R. Taouil, N. Pasquier, G. Stumme and L. Lakhal, 2000 Mining frequent patterns with counting inference. ACM SIGKDD Explorations Newsletter,2:66-75. http://doi.acm.org/10.1145 /380995 381017 [21]. Pasquier, N., Y. Bastide, R. Taouil and L. Lakhal, 1999 Discovering frequent closed itemsets for association rules. In Proceedings of the 7 th International Conference on Database Theory,Jan. 10-12 Springer-Verlag London, UK., pp:398-416. http://portal acm.org/citation.cfm?id=645503.656256 [22]. Getoor, L., N. Friedman, D Koller and B. Taskar, 2001. Learning probabilistic models of relational structure. In Proceedings of International Conference on Machine Learning ICML'01 177.http://direct.bl.uk/bld/PlaceOrder.do?UIN=100556 121&ETOC=RN&from=searchengine [23]. Zaki, M.J., S Parthasarathy, M. Ogihara and W. Li, 1997. New algorithms for fast discovery of association rules. In Proceeding of the 3 rd International Conference on Knowledge Discovery and Data Mining 97, AAAI Press, pp: 283-286 http://citeseerx.ist.psu.edu/viewdoc/summary?doi 10.1.1.42.5143 [24]. Zaki, M.J., 2000. Generating non-redundant association rules. In Proceedings of the 6th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Aug. 20-23, Boston, Massachusetts, US., pp: 34-43 http://doi.acm.org/10.1145/347090.347101 [25]. Ganter B. and R. Wille, 1999. Formal Concept Analysis: Mathematical Foundations. 1st Edn., Springer-Verlag, USA., pp 284. ISBN-10: 3540627715 


26]. Gouda, K. and M.J. Zaki, 2001. Efficiently mining maximal frequent itemsets. In the Proceedings of International Conference on Data Mining, Nov 29-Dec. 02 2001, IEEE Computer Society Washington, DC, USA., pp 163-170. http://portal.acm.org/citation. cfm?id = 645496.6580 47&coll=GUIDE&dl=GUIDE [27]. Bayardo, R.J., 1998. Efficiently mining longpatterns from databases. In the Proceedings of the 1998 ACM SIGMOD International Conference on Management of Data, Seattle, June 001-04 Washington, United States, pp: 85-93 http://doi.acm.org/10.1145/276304.27631 [28]. Gunopulos, D., H. Mannila and S. Saluja, 1997. Discovering all the most specific sentences by randomized algorithms. In Intenational Conference on Database Theory, Jan 08-10, Springer-Verlag London,UK.,pp:215-229 http://portal.acm.org/citation.cfm?id=645502.6560 97 [29]. Burdick D., M. Calimlim and J. Gehrke, 2001. MAFIA: A maximal frequent itemset algorithm for transactional databases. In International Conference on Data Engineering, Apr. 02-06, IEEE Computer Society Washington, DC, USA pp:443-452 http://portal.acm.org/citation.cfm?id=645484.6563 86&coll=GUIDE&dl=GUIDE. [30]. Agrawal, R., C. Aggarwal and V Prasad, 2000. Depth first generation of long patterns. In the Proceedings of the 6th ACM SIGKDD international Conference on Knowledge Discovery and Data Mining, Aug. 20-23, Boston, Massachusetts, United States, pp: 108-118. http://doi.acm.org/10.1145/347090.347114 31]. A.M.J. Md. Zubair Rahman and P. Balasubramanie,2008 Kongu Engineering College, Perundurai, Tamilnadu, India An Efficient Algorithm for Mining Maximal Frequent Item Sets [32]. Karam Gouda and Mohammed J. Zaki, 2005. GenMax: An Efficient Algorithm for Mining Maximal Frequent Itemsets. In the Proceedings of the Data Mining and Knowledge Discovery, 11, 120, 2005. [33]. Han, J., J. Pei and Y. Yin, 2000. Mining frequent patterns without candidate generation In the Proceedings of the 2000 ACM SIGMOD International Conference on Management o f Data, May 15-18, Dallas, Texas, United States, pp 1-12 http://doi.acm.org/10.1145/342009.335372 


experts can start their ore deposits estimations with much clearer data which is easier to deal with XII. CONCLUSION We have presented how data mining can be applied to the borehole data coming from active mine area. We are certain that data mining has a huge potential for other types of borehole data. One of the important steps in data mining is the preparation of data into useful form for various algorithms. Together with domain experts we have identified a way for transforming data to a form acceptable to k-NN classification and association rules mining algorithms Although we have shown how the k-NN classification and association rules mining techniques can be applied here this framework will open new possibilities to perform other data mining tasks to this type of data. Our experimental results are very promising in this regard as they show that we are not only able to match the accuracy of the results with IDW method used in the mining industry, but also exceed it \(93.1% accuracy was obtained by 3-NN method while IDW gave 88.5% accuracy rules as a separate analysis tool can improve not only k-NN classification results but also IDW interpolation results. This is particularly important for convincing mining companies 119 of the benefits of data mining, as with a little effort they can improve the method they are already using As we have shown in this paper, not only choosing right classification techniques can help us to improve interpolation, but more general analysis on data like association rules can contribute a lot. Thus, the more knowledge we have on the hidden relationships and patterns the more accurately you can construct an interpolation. Moreover, discovering hidden correlations not only important for this task, but also can contribute to understanding about complex geological processes that this specific area undergone. Therefore data mining, which can discover useful knowledge purely from data is of great importance and will be area of research for next generation of exploration and mining specialists Finally, we have proposed to use mathematical morphology for filtering the results of rock type interpolation. In the example given here, we have seen that it performed well in removing relatively small objects and filtering out large 


areas of interest from rock types XIII. FUTURE WORK This paper provides a framework for using data mining techniques on the borehole data. Using this framework we would like to investigate possibilities of using other classification techniques on this type of data. We mentioned that borehole data can contain more information about the area besides spatial coordinates, rock types and metal grades so classification that utilizes this extra information will be on our immediate research agenda Application of mathematical morphology provides possibilities for further research on domaining \(filtering out large areas of interest be given also to this ACKNOWLEDGEMENT I want to thank the Director of the WH Bryan Mining and Geology Research Centre, at the University of Queensland Professor Alan Bye and his PhD student Mr Younes Fadakar Alghalandis for contributing their expertise to this research This work is supported by the AuScope National Collaborative Research Infrastructure Strategy by the Australian Commonwealth, the Queensland State Government and The University of Queensland REFERENCES 1] A. G. Journel and C. J. Huijbregts, Mining geostatistics Academic Press, London, 1978 2] D. Shepard, A two-dimensional interpolation function for irregularly-spaced data, in Proc. ACM Annual Conference 1968, pp. 517524 3] C. Caruso and F. Quarta, Interpolation methods comparison Computers Math. Applications., vol. 35, pp. 109126, 1998 4] K. Gibert, M. S?nchez-Marre`, and I. Rodr?guez-Roda, Short communication: Gesconda: An intelligent data analysis system for knowledge discovery and management in environmental databases, Environ. Model. Softwares, vol. 21, no. 1 pp. 115120, 2006 5] A. R. Solow, Mapping by simple indicator kriging, Mathematical Geology, vol. 18, no. 3, pp. 335352, 1986 6] M. Armstrong, Problems with universal kriging, Mathematical Geology, vol. 16, no. 1, pp. 101108, 1984 7] N. Roussopoulos, S. Kelley, and F. Vincent, Nearest neighbor queries, in Proc. SIGMOD Conference, 1995, pp. 7179 


8] M. Ankerst, H.-P. Kriegel, and T. Seidl, A multistep approach for shape similarity search in image databases, IEEE Trans Knowl. Data Eng., vol. 10, no. 6, pp. 9961004, 1998 9] K. S. Beyer, J. Goldstein, R. Ramakrishnan, and U. Shaft When is nearest neighbor meaningful? in Proc. of Database Theory - ICDT 99, 7th International Conference 1999, pp. 217235 10] P. Ciaccia and M. Patella, Pac nearest neighbor queries Approximate and controlled search in high-dimensional and metric spaces, in Proc. of ICDE, 2000, pp. 244255 11] X. Wu, V. Kumar, J. Quinlan, J. Ghosh, Q. Yang, H. Motoda G. McLachlan, A. Ng, B. Liu, P. Yu, Z.-H. Zhou, M. Steinbach, D. Hand, and D. Steinberg, Top 10 algorithms in data mining, Knowledge and Information Systems, vol. 14, no. 1 pp. 137, 2008 12] X. Cheng, R. Dolin, M. O. Neary, S. Prabhakar, K. Ravikanth D. Wu, D. Agrawal, A. El Abbadi, M. Freeston, A. K. Singh T. Smith, and J. Su, Scalable access within the context of digital libraries, in Proc of ADL, 1997, pp. 7081 13] C. Faloutsos, M. Ranganathan, and Y. Manolopoulos, Fast subsequence matching in time-series databases, in Proc. of SIGMOD Conference, 1994, pp. 419429 14] F. Korn, N. Sidiropoulos, N. Faloutsos, E. Siegel, and Z. Protopapas, Fast nearest neighbor search in medical image databases, in Proc. of VLDB, 1996, pp. 215226 15] T. Kahveci and A. K. Singh, Efficient index structures for string databases, in Proc. of VLDB, 2001, pp. 351360 16] M. Ankerst, G. Kastenmuller, H.-P. Kriegel, and T. Seidl Nearest neighbor classification in 3d protein databases, in Proc of International Conference on Intelligent Systems for Molecular Biology, ISMB, 1999, pp. 3443 17] R. Agrawal and R. Srikant, Fast algorithms for mining association rules in large databases, in Proc of VLDB, 1994 pp. 487499 18] B. Liu, W. Hsu, and Y. Ma, Integrating classification and association rule mining, in Proc of KDD, 1998, pp. 8086 19] J. Serra, Image Analysis and Mathematical Morphology Orlando, FL, USA: Academic Press, Inc., 1983 120 


http://datamining.buaa.edu.cn/TopKCos.pdf 14] M. Zaki, Scalable algorithms for association mining, TKDE, vol. 12, pp. 372390, 2000 


enhance item-based collaborative filtering, in 2nd IASTED International Conference on Information and Knowledge Sharing, Scottsdale, Arizona, 2003 476 2010 10th International Conference on Intelligent Systems Design and Applications 


Basi Association Rles Basi c  Association R u les Association is basically connecting or tying up occurrences of Association is basically connecting or tying up occurrences of events Ol dib t f ilt t O n l y d escr ib e se t s o f s i mu lt aneous even t s Cannot describe patterns that iterate over time e g  itemset a  0  b  0  g    Eg If you sense higher data rates on the downlink than normal AND New Route generated Implies high chances of Intrusion AND New Route generated Implies high chances of Intrusion Associative IDS for NextGen Frameworks Dr S Dua LA Tech 20 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



A New Approach For On Line Recommender System in Web Usage Mining Subhash K.Shinde, Dr.U.V.Kulkarni Department of Computer Engineering, Bharati Vidyapeeth Collge of Engineering,Navi Mumbai, India Department of Computer Engineering , S.G.G.S College of Engineering & Technology, Nanded, India E-mail:  skshinde@rediffmail.com,  kulkarniuv@yahoo.com Abstract The Internet is one of the fastest growing areas of intelligence gathering. During their navigation web users leave many records of their activity. This huge amount of data can be a useful source of knowledge Sophisticated mining processes are needed for this knowledge to be extracted, understood and used. Web Usage Mining \(WUM\ systems are specifically designed to carry out this task by analyzing the data representing usage data about a particular Web Site WUM can model user behavior and, therefore, to forecast their future movements. Online prediction is one web usage mining application. However, the accuracy of the prediction and classification in the current architecture of predicting users’ future requests systems can not still satisfy users especially in Huge Web sites. To provide online prediction efficiently, we develop architecture for online recommendation for predicting in Web Usage Mining System .In this paper we propose architecture of on line recommendation in Web usage mining\(OLRWMS for enhancing accuracy of classification by interaction between classifications, evaluation, and current user activates and user profile in online phase of this architecture 1. Introduction With the explosive growth of knowledge available on the World Wide Web, which lacks an integrated structure or schema, it becomes much more difficult for users to access relevant information efficiently Meanwhile, the substantial increase in the number of websites presents a challenging task for webmasters to organize the contents of the websites to cater to the needs of users. Modeling and analyzing web navigation behavior is helpful for understand what information online users demand. Following that, the analyzed results can be seen as knowledge to be used in intelligent online applications, refining web site maps and improving searching accuracy when seeking information. Nevertheless, an online navigation behavior grows each passing day, and thus extracting intelligently from it is a difficult issue. Web Mining has shown to be a viable technique to discover information hidden” into Web-related data [1  p a rt i c u l ar  W e b  Usage Mining \(WUM\s the process of extracting knowledge from Web user’s access data by exploiting Data Mining \(DM\ technologies [2  I t c a n b e use d  f o r  different purposes such as personalization, system improvement and site modification. Typically, the WUM prediction process is structured according to two components performed online and off-line with respect to the Web server activity [14  3    1 2  an d  5 T h e off-line component is aimed at building the knowledge base by analyzing historical data, such as server access log files, that is then used in the online component The main functions carried out by this component are Preprocessing, i.e. data cleaning and session identification, and Pattern Discovery, i.e. the application of DM techniques, like association rules sequential patterns, clustering or classification. The online component is devoted to the generation of personalized content. On the basis of the knowledge extracted in the off-line component, it processes a request to the Web server by adding personalized content which can be expressed in several forms, such as links to pages, advertisements, and information relating to products or service estimated to be of interest for the current user. In the past, several WUM projects have been proposed to predict users preference and their navigation behavior, as well as many recent results improved separately the quality of the recommendations or the user profiling phase [6   7   2. Related Work Recently, several WUM systems have been proposed to predicting user’s preference and their navigation behavior. In the following we review some of the most 
2008 International Conference on Advanced Computer Theory and Engineering 978-0-7695-3489-3/08 $25.00 © 2008 IEEE DOI 10.1109/ICACTE.2008.72 973 
2008 International Conference on Advanced Computer Theory and Engineering 978-0-7695-3489-3/08 $25.00 © 2008 IEEE DOI 10.1109/ICACTE.2008.72 973 


significant WUM systems and architecture that can be compared with our system. Analog [9 i s o n e o f th e first WUM systems. It is structured according to an offline and an online component. The off-line component builds session clusters by analyzing past users activity recorded in server log files. Then the online component builds active user sessions which are then classified according to the generated model. The classification allows to identify pages related to the ones in the active session and to return the requested page with a list of suggestions. The geometrical approach used for clustering is affected by several limitations, related to scalability and to the effectiveness of the results found Nevertheless, the architectural solution introduced was maintained in several other more recent projects In [1 a n d   11  B   Moba s h e r  et al., present WebPersonalizer a system which provides dynamic recommendations, as a list of hypertext links, to users The analysis is based on anonymous usage data combined with the structure formed by the hyperlinks of the site. Data mining techniques \(i.e. clustering association rules and sequential pattern discovery\ are used in the preprocessing phase in order to obtain aggregate usage profiles. In this phase Web server logs are converted in clusters made up of sequences of visited pages, and cluster made up of set of pages with common usage characteristics. The online phase considers the active user session in order to find matches among the user’s activities and the discovered usage profiles. Matching entries are then used to compute a set of recommendations which will be inserted into the last requested page as a list of hypertext links. Web Personalizer is a good example of two-tier architecture for Personalization systems. In [4  they proposed an architecture that named KLAS, base on customer’s on-line navigation behaviors by analyzing their navigation patterns through pre-trained artificial neural networks. In t h e y h a v e de v e l ope d a recommendation system, termed Yoda that is designed to support large-scale Web-based applications requiring highly accurate recommendations in realtime. With Yoda, they introduced a hybrid approach that combines collaborative filtering \(CF\d contentbased querying to achieve higher accuracy. Yoda is structured as a tunable model that is trained online and employed for real-time recommendation on-line. The on-line process benefits from an optimized aggregation function with low complexity that allows real time weighted aggregation of the soft classification of active users to predefined recommendation sets. Liu and Keselj [2 r o p o s ed  t h e au to m a t i c cl as s i f i cat io n o f  w e b  user navigation patterns and proposed a novel approach to classifying user navigation patterns and predicting users’ future requests. The approach is based on the combined mining of Web server logs and the contents of the retrieved web pages. They used character Ngrams to represent the contents of web pages, and combined them with user navigation patterns by building user navigation profiles composed of a collection of N-grams. The approach is implemented as an experimental system, and its performance is evaluated based on two tasks: classification and prediction. The system achieves the classification accuracy of nearly 70% and the prediction accuracy of about 65%, which is about 20% higher than the classification accuracy by mining Web server logs alone. In the session vectorization of this system for capturing the interest degree of a web page there is only two factors: Frequency and duration In this system they can incorporate their current off-line mining system into an on-line web recommendation system to observe and calculate the degree of real users satisfaction on the generated recommendations, which are derived from the predicted requests, by their system. In  B a r a g l ia a n d P a l m e r i n i pr o pos e d a  WUM system called SUGGEST, that provide useful information to make easier the web user navigation and to optimize the web server performance. The main goal of SUGGEST is to find useful information from the user access data collected in web server logs SUGGEST adopts a two levels architecture composed by an offline creation of historical knowledge and an online engine that understands user’s behavior. After a pre-processing of the data recorded in the web server log files, SUGGEST creates clusters of related pages based on users past activity, and then classifies new users by comparing pages in their active sessions with pages inside the clusters created. A set of suggestions is then obtained for each request. The main disadvantages of this system are: Online component and offline component work separately, how to maintain and update the knowledge extracted in the offline phase and how the system can exactly understand the differences between index page and content page In the new architecture of SUGGEST they put together the previous two components into a single online module performing the same operation [16 A s t h e  requests arrive at this system module it incrementally updates a graph representation of the Web site based on the active user sessions and classifies the active session using a graph partitioning algorithm. This architecture was designed to be usable on Web sites made up of pages statically generated, i.e. Web sites with a fixed number of pages. A list containing all the information describing a Web site pages was required as input by this architecture at its start-up time 
974 
974 


Potential limitation of this architecture might be: a\ the memory required to store Web server pages is quadratic in the number of pages. This might be a severe limitation in large sites made up of millions of pages; b\ it does not permit us to manage Web sites made up of pages dynamically generated. The last contribution of SUGGEST architecture proposed by Baraglia et al. [9  T h is v e r s io n o f  S U GG ES T  introduce a novel solution to implement WP\(Web Personalization\ as a single online module that performs user profiling, model updating, and recommendation building. It is designed to dynamically generate personalized contents of potential interest for users of large Web sites made up of pages dynamically generated. It is based on an incremental personalization procedure tightly coupled with the Web server. It is able to update incrementally and automatically the knowledge base obtained from historical usage data and to dynamically generate a list of page links suggestions\. The suggestions are used to personalize the HTML page requested on-the-fly. The adoption of a LRU-based \(Least Recently Used\orithm handling the knowledge base makes it possible for SUGGEST to manage large Web sites. But in this system quality of recommendations is not better than previous version of this system 3. Architecture of Online Recommendation in Web Usage Mining System The OLRWUMS, shorting for the Online Recommendation for Predicting in Web Usage Mining system, is a Data Mining system that can be used for online predicting of users’ request. According to different functions, the system can be partitioned into two main phases; offline phases and online phases. The architecture of this system is shown in Fig.1 3.1 Offline Phase This phase consists of two major modules: Data pretreatment and Navigation Patterns Mining. In this phase we start with the primary Web-Log Preprocessing \(Data pretreatment\ extract user navigation session from dataset and after that we will try to apply some algorithm to mining navigational patterns 3.1.1 Data pretreatment Data pretreatment in a web usage mining model \(WebLog preprocessing\ aims to reformat the original web Fig 1: The Architecture of OLRWUMS logs to identify all web access sessions. The Web server usually registers all users’ access activities of the website as Web server logs. Due to different server setting parameters, there are many types of web logs but typically the log files share the same basic information, such as: client IP address, request time requested URL, HTTP status code, referrer, etc Generally, several pretreatment tasks need to be done before performing web mining algorithms on the Web server logs. For our work, these include data cleaning user differentiation and session identification. These preprocessing tasks are the same for any web usage mining problem and are discussed by Cooley et al 19 T h e o r i g in al s e rv er l o g s are clean ed  f o r m at t e d   and then grouped into meaningful sessions before being utilized by web usage mining 3.1.2 Navigation Pattern Mining After the data pretreatment step, we will perform navigation pattern mining on the derived user access sessions. As an important operation of navigation pattern mining, clustering aims to group sessions into clusters based on their common properties. Since access sessions are the images of browsing activities of users, the representative user navigation patterns can be obtained by clustering them. These patterns will be further used to facilitate the user profiling process of our system. In this system module, we will introduce how we perform the session clustering and how we 
975 
975 


identify the optimal number of clusters from clustering results 3.1.3 Session vectorization For the session clustering we should assign a weight to web page visited in a session. The weight needs to be appropriately determined to capture a user’s interest in a web page. In general, all the accessed page can be considered interesting to various degrees because users visited them. In reference  t h e y pr opos e d  a w e i g h t  measure for approximating the interest degree of a web page to a user. In this research for representing the interest degree of a web page to a user in the session they measured “Frequency” and “Duration” of a page in the session. But we are interested in incorporation more influencing factors into the weight measure of the session vectorization, for example sequence of accessed web pages. After interest measuring every user access session is successfully transformed into an m-dimensional vector of weights of web pages, where m is the number of web pages visited in all user access sessions. For reducing dimensions, we can use a frequency threshold f min as a constraint to filter out web pages that are accessed less than f min time sin all access sessions 3.1.4 Session Clustering In this step, standard clustering algorithm can partition user access sessions. The result of session clustering is used to represent the set of user navigation patterns Given the transformation of user access sessions into a multi-dimensional space as vectors of web pages standard clustering algorithms can partition this space into groups of sessions that are close to each other based on a distance measure. The results of sessions clustering will save in navigational pattern profile 3.2 Online Phase During the online phase, when a new request arrives at the server, the URL requested and the session to which the user belongs are identified, the underlying knowledge base is updated, and a list of suggestion is appended to the requested page. This phase consists of some functions that are discussed below 3.2.1 Recommendation engine The objectives of this part of OLRWUMS are to classify user navigation patterns and predict users future requests. Classification module uses a classification algorithm to classify current user activity Each user session will be assigned a class label of pattern, so users’ navigation activities can be clearly identified. We propose K-Nearest neighbor algorithm for classifying user’s sessions. Next module of the architecture is evaluation of classification module which aims to evaluate the results of classification based on some evaluation algorithm .If accuracy of classification does not meet satisfaction, classification module will be run again based on user profile and latest user activities. Otherwise prediction results achieve from future request prediction module According to the prediction results, reasonable recommendations can be provided to the active session for better meeting of user’s need. The suggestion list module shows the prediction of users’ future request The users can choose a suggestion from suggestions list or maybe they continue their activities. Anyway each user action saves into user profile. This user profile will be used for improving accuracy of classification A more sophisticated approach k nearest neighbor  k NN\assification, finds a group of k objects in the training set that are closest to the test object, and bases the assignment of a label on the predominance of a particular class in this neighborhood. There are three key elements of this approach: a set of labeled objects e.g., a set of stored records, a distance or similarity metric to compute distance between objects, and the value of k the number of nearest neighbors. To classify an unlabeled object, the distance of this object to the labeled objects is computed, its k nearest neighbors are identified, and the class labels of these nearest neighbors are then used to determine the class label of the object  Algorithm: 1, below provides a high-level summary of the nearest-neighbor classification method Given a training set D and a test object x   x  y the algorithm computes the distance \(or similarity\ between z and all the training objects  x y 002 D to determine its nearest-neighbor list Dz  x is the data of a training object, while y is its class. Likewise x is the data of the test object and y is its class Once the nearest-neighbor list is obtained, the test object is classified based on the majority class of its nearest neighbors   i D y x v t y v I y Voting Majority z i i   002 003 max arg  Where v is a class label, y i is the class label for the ith nearest neighbors, and I \(·\s an indicator function that returns the value 1 if its argument is true and 0 otherwise Input D i the set of k training objects and test object Z= \(x’, y 
976 
976 


Process Compute d \(x’, x\,the distances between z and every object\(x,y D 003  Select Dz  D 004 the set of k closet object to z   i D y x v t y v I y Output z i i   002 003 max arg  Algorithm 1: k-nearest neighbor \(kNN\sification 4. Conclusion  In this paper, the architecture is proposed to classify user navigation pattern and Online Recommendation to users’ for predication of future request by mining of web server logs. This architecture will be used in the Web Usage Mining System named as ORWUMS. In this architecture, a recommendation engine that works in online phase predicts next user request by interacting user profile and classification module. After classification part, accuracy of classification will be evaluated by evaluation part. If this accuracy doesn’t satisfy the user, classification part will operate again based on latest user activity and user profile until the needed accuracy is satisfied 5. References 1 R. Kosala, H. Blockeel, Web mining research: a survey, SIGKDD: SIGKDD explorations newsletter of the special interest group \(SIG\n knowledge discovery & data mining, ACM 2 \(1 pages 1-15, 2000 2 H. Liu, V. Keselj, Combined mining of Web server logs and web contents for  classifying user navigation patterns and predicting users’ future requests,  Elsevier, 2007 3 T. W. Yan, M. Jacobsen, H. Garcia-Molina, and D. Umeshwar. From user access patterns to dynamic hypertext linking. Fifth International World Wide Web Conference, May 1996 4 Shuchih Ernest Changa, S. Wesley Changchiena Ru-Hui Huangb ,Assessing users’ productspecific knowledge for personalization in electronic commerce, Expert Systems with Applications 30 pages 682–693,2006 5 R. Baraglia and P. Palmerini. Suggest: A web usage mining system. In Proc. of IEEE Int’l Conf on InfoTech: Coding and Computing, April 2002 6 O. Nasraoui and C. Petenes. Combining web usage mining and fuzzy inference for website personalization. In Proc. Of WebKDD, 2003 7 M. Nakagawa and B. Mobasher. A hybrid web personalization model based on site connectivity In Proc. of WebKDD, pages 59–70, 2003 8 E. Frias-Martinez and V. Karamcheti. Reduction of user perceived latency for a dynamic and personalized site using web-mining techniques. In Proc. of WebKDD, pages 47–57, 2003 9 T. W. Yan, M. Jacobsen, H. Garcia-Molina, and D. Umeshwar. From user access patterns to dynamic hypertext linking. Fifth International World Wide Web Conference, May 1996 10 R. Baraglia, F. Silvestri, Dynamic Personalization of Web Sites Without User Intervention Communication of the ACM,February 2007 11 M. Nakagawa and B. Mobasher. A hybrid web personalization model based on site connectivity In Proc. of WebKDD, pages 59–70, 2003 12 B. Mobasher, N. Jain, E.-H. S. Han, and J Srivastava. Web mining: Pattern discovery from world wide web transactions. TR 96-050 University of Minnesota, 1996 13 C. Shahabi, F.B. Kashani, Y.-S. Chen, D. McLeod Yoda: An accurate and scalable web-based recommendation system, in: Proceedings of the 9th International Conference on Cooperative Information Systems, Springer-Verlag, pages 418 432, 2001 14 B. Mobasher, R. Cooley, and J. Srivastava Automatic personalization based on web usage mining. Communications of the ACM, 43\(8\:142 151, a ugust 2000 15 R. Baraglia and P. Palmerini. Suggest: A web usage mining system. In Proc. of IEEE Int’l Conf on I.T: Coding and Computing,April 2002 16 F. Silvestri, R. Baraglia, P. Palmerini and M.Serrano. On-line generation of suggestions for web users. In Proc. of IEEE Int’l Conf. on Info Technology: Coding and Computing, 2004 17 R. Baraglia, F. Silvestri, An online recommender system for large Web sites. In Proceedings of the IEEE/WIC/ACM International Conference on Web Intelligence, pages 20–24, 2004 18 B. Mobasher, R. Cooley, and J. Srivastava Automatic personalization based on web usage mining. Communications of the ACM, 43\(8\:142 151, a ugust 2000 19 R. Cooley, B. Mobasher, J. Srivastava. Data Preparation for Mining World Wide Web Browsing Patterns. Journal of Knowledge and Information Systems. Vol. 1.No. 1. Pages 5–32 1999 
977 
977 


Figure 1 Experiment Design used in our experiments in order to maintain the high stability as suggested by The topics ha v e title description and narrative However only the titles are used as queries because in real world users only use short phrases to express their information needs 4.1 Information Gathering System An information gathering system IGS is implemented for common use by all the experimental models The IGS is an implementation of a model developed by which uses user pro\002les for information gathering The s model is chosen because not only it is veri\002ed better than the Rocchio and Dempster-Shafer models but also it is extensible in using support values of training documents The input support values associated with documents would affect the IGS's performance sensitively The technical details and the related justi\002cations can be referred to The IGS 002rst uses the training set to evaluate weights for a set of selected terms T  After text pre-processing of stopword removal and word stemming a positive document d becomes a pattern that consists of a set of term frequency pairs  d  f  t 1  f 1    t 2  f 2        t k  f k  g  where f i is t i s term frequency in d  The semantic space referred by  d is represented by its normal form 014  d   which satis\002es 014  d   f  t 1  w 1    t 2  w 2        t k  w k  g  where w i  i  1      k  are the weight distribution of terms and w i  f i P k j 1 f j  A probability function on T can be derived based on the normal forms of positive documents and their supports for all t 2 T  pr 014  t   X d 2 D    t;w  2 014  d  support  d  002 w 12 The testing documents can be indexed by weight  d   which is calculated using the probability function pr 014  weight  d   X t 2 T pr 014  t  002 034  t d  13 where 034  t d   1 if t 2 d  otherwise 034  t d   0  4.2 TREC Model The TREC model is the implementation of a user's mental model For a given topic the TREC linguists read a set of documents and marked each document positive or negative against the topic If a document d is marked positive it becomes a positive document in the TREC training set and support  d   1 j D  j  otherwise it becomes a negative document and support  d   0  Since the linguists who marked the documents are also the people who generated the topics following the assumption that only users know their interests and preferences perfectly the TREC model makes a golden model to our proposed model to mark The modelling of a user's mental model can be proven successful if the ONTO model can achieve the same or close performance to this golden model 4.3 ONTO Model This model is the implementation of our proposed model As illustrated in Fig 1 and required by the IGS the input to this model is a topic and the output is a training set consisting of positive documents  D   and negative documents  D 000  Each document is associated with a support  d  value indicating its support level to the topic The WKB described in Section 3.3.1 is constructed based on the Library of Congress Subject Headings 2 LCSH system The LCSH system is a categorization developed for organizing the large volumes of library collections and for retrieving information from the library The subject headings in the LCSH are transformed into the subjects in WKB  and the LCSH structure is transformed into the backbone of WKB  Eventually the constructed WKB contains over 400,000 subjects covering various topics The semantic relations in the WKB are transformed from the references Broader term  Narrower term and Used-for  speci\002ed in the LCSH The Broader term and Narrower term references are transformed into hyponym/hypernym relations Used-for references are usually used in two situations to describe an action or to describe an object When object A is used for an action A actually becomes a part of that action like using turner in cooking when A is used for object B  A becomes a part of B  like“using wheels for a car Hence we transform the 2 http://classi\002cationweb.net 
511 
515 


Used-for references in the LCSH into holonym/meronym relations in our WKB  In the experiments we assume that each topic comes from an individual user We attempt to evaluate our model in an environment that covers great range of topics However it is not realistic to expect a participant to hold such great range of topics in personal interests Thus for the 50 experimental topics we assume each one coming from an individual user and learn her his personalized ontology An LIR is collected through searching the subject catalogue of Queensland University of Technology QUT Library 3 by using the title of a topic Librarians have assigned title table of content summary and a list of subjects to each information item e.g a book stored in QUT library The assigned subjects are treated as the tags in Web documents that cite the knowledge in the WKB  In order to simplify the experiments we only use the librarian summarized information title table of content and summary to represent an instance in an LIR  All these information can be downloaded from QUT's Web site and are available to the public Once the WKB and an LIR are ready an ontology is learned as described in Section 3.3.1 and personalized as in Section 3.3.2 The user con\002dence rates on the subjects are speci\002ed as in Section 3.3.3 A document d i in the training set is then generated by an instance i  and its support value is determined by support  d i   X s 2 021  i  s 2S sup  s Q  14 where s 2 S in O  Q  are as de\002ned in De\002nition 5 As sup  s Q   0 for s 2 S 000 according to Eq 11 the documents with support  d   0 go to D 000  whereas those with support  d   0 go to D   4.4 Performance Measures The performance of the experimental models are measured by three methods the precision averages at eleven standard recall levels 11SPR the mean average precision MAP and the F 1 Measure They are all based on precision and recall the modern IR evaluation methods The 11SPR is reported suitable for information gathering and is used in TREC evaluations as a performance measuring standard An 11SPR v alue is computed by summing the interpolated precisions at the speci\002ed recall cutoff and then dividing by the number of topics P N i 1 precision 025 N  025  f 0  0  0  1  0  2      1  0 g  15 N is the number of topics and 025 are the cutoff points where the precisions are interpolated At each 025 point an aver3 http://library.qut.edu.au Figure 2 Experimental 11SPR Results age precision value over N topics is calculated These average precisions then link to a curve describing the recallprecision performance The MAP is a stable and discriminating choice in information gathering evaluations and is recommended for measuring general-purpose information gathering methods The average precision for each topic is the mean of the precision obtained after each relevant document is retrieved The MAP for the 50 experimental topics is then the mean of the average precision scores of each of the individual topics in the experiments The MAP re\003ects the performance in a non-interpolated recall-precision fashion F 1 Measure is also well accepted by the information gathering community which is calculated by F 1  2 002 precision 002 recall precision  recall  16 Precision and recall are evenly weighted in F 1 Measure For each topic the macro F 1 Measure averages the precision and recall and then calculates F 1 Measure whereas the micro F 1 Measure calculates the F 1 Measure for each returned result and then averages the F 1 Measure values The greater F 1 values indicate the better performance 5 Results and Discussions The experiments attempt to evaluate our proposed model by comparing to an implementation of mental model We expect that the ONTO model can achieve at least the close performance to the TREC model The experimental 11SPR results are illustrated in Fig 2 At recall point 0.3 the TREC model slightly outperformed the ONTO model but at 0.5 and 0.6 the ONTO model achieved better results than the TREC model subtly At all other points their 11SPR results are just the same For the MAP results shown on Table 1 the ONTO model achieved 0.284 which is just 0.006 below the TREC model 2 
512 
516 


TREC ONTO p-value Macro-FM 0.388 0.386 0.862 Micro-FM 0.356 0.355 0.896 MAP 0.290 0.284 0.484 Table 1 Other Experimental results downgrade For the average macroand microF 1 Measures also shown on Table 1 the TREC model only outperformed the ONTO model by 0.002 0.5 in macro F 1 and 0.001 0.2 in micro F 1  The two models achieved almost the same performance The evaluation result is promising The statistical test is also performed on the experimental results in order to analyze the evaluation's reliability As suggested by we use the Student's Paired T-Test for the signi\002cance test The null hypothesis in our T-Test is that no difference exists in two comparing models When two tests produce substantially low p-value usually  0.05 the null hypothesis can be rejected In contrast when two tests produce high p-value usually  0.1 there is not or just little practical difference between two models The T-Test results are also presented on Table 1 The pvalue s show that there is no evidence of signi\002cant difference between two experimental models as the produced pvalue s are quite high  p-value 0.484\(MAP 0.862\(macroFM and 0.896\(micro-FM far greater than 0.1 Thus we can conclude that in terms of statistics our proposed model has the same performance as the golden TREC model and the evaluation result is reliable The advantage of the TREC model is that the experimental topics and the training sets are generated by the same linguists manually They as users perfectly know their information needs and what they are looking for in the training sets Therefore it is reasonable that the TREC model performed better than the ONTO model as we cannot expect that a computational model could outperform a such perfect manual model However the knowledge contained in TREC model's training sets is well formed for human beings to understand but not for computers The contained knowledge is not mathematically formalized and speci\002ed The ONTO model on the other hand formally speci\002es the user background knowledge and the related semantic relations using the world knowledge base and local instance repositories The mathematic formalizations are ideal for computers to understand This leverages the performance of the ONTO model As a result as shown on Fig 2 and Table 1 the ONTO model achieved almost the same performance as that of the TREC model 6 Conclusions In this paper an ontology-based knowledge IR framework is proposed aiming to discover a user's background knowledge to improve IR performance The framework consists of a user's mental model a querying model a computer model and an ontology model A world knowledge base is used by the computer model to construct an ontology to simulate a user's mental model and the ontology is personalized by using the user's local instance repository The semantic relations of hypernym/hyponym holonym/meronym and synonym are speci\002ed in the ontology model The framework is successfully evaluated by comparing to a manual user model The ontology-based framework is a novel contribution to knowledge engineering and Web information retrieval References   C Buckley and E M Voorhees Evaluating evaluation measure stability In Proc of SIGIR 00  pages 33–40 2000   R M Colomb Information Spaces The Architecture of Cyberspace  Springer 2002   D Dou G Frishkoff J Rong R Frank A Malony and D Tucker Development of neuroelectromagnetic ontologies\(NEMO a framework for mining brainwave ontologies In Proc of KDD 07  pages 270–279 2007   S Gauch J Chaffee and A Pretschner Ontology-based personalized search and browsing Web Intelligence and Agent Systems  1\(3-4 2003   X Jiang and A.-H Tan Mining ontological knowledge from domain-speci\002c text documents In Proc of ICDM 05  pages 665–668 2005   J D King Y Li X Tao and R Nayak Mining World Knowledge for Analysis of Search Engine Content Web Intelligence and Agent Systems  5\(3 2007   D D Lewis Y Yang T G Rose and F Li RCV1 A new benchmark collection for text categorization research Journal of Machine Learning Research  5:361–397 2004   Y Li and N Zhong Mining Ontology for Automatically Acquiring Web User Information Needs IEEE Transactions on Knowledge and Data Engineering  18\(4 2006   H Liu and P Singh ConceptNet a practical commonsense reasoning toolkit BT Technology  22\(4 2004   A D Maedche Ontology Learning for the Semantic Web  Kluwer Academic Publisher 2002   S E Robertson and I Soboroff The TREC 2002 002ltering track report In Text REtrieval Conference  2002   M D Smucker J Allan and B Carterette A Comparison of Statistical Signi\002cance Tests for Information Retrieval Evaluation In Proc of CIKM'07  pages 623–632 2007   X Tao Y Li and R Nayak A knowledge retrieval model using ontology mining and user pro\002ling Integrated Computer-Aided Engineering  15\(4 2008   X Tao Y Li N Zhong and R Nayak Ontology mining for personalzied web information gathering In Proc of WI 07  pages 351–358 2007   T Tran P Cimiano S Rudolph and R Studer Ontologybased interpretation of keywords for semantic search In Proc of the 6th ICSW  pages 523–536 2007   Y Y Yao Y Zeng N Zhong and X Huang Knowedge retrieval KR In Proc of WI 07  pages 729–735 2007 
513 
517 


TESTS IN SECOND t INDICATES nl WAS LOWERED TO 2 Training BSTC Top-k RCBT 7 OC Holdout Validation Results RCBT outperforms BSTC on the single test it could finish by more then 7 although it should be kept in mind that RCBT's results for the 24 unfinished tests could vary widely Note that BSTC's mean accuracy increases monotonically with training set size as expected At 60 training BSTC's accuracy behaves almost identically to RCBT's 40 training accuracy see Figure 6 4 Ovarian Cancer OC Experiment For the Ovarian Cancer dataset which is the largest dataset in this collection the Top-k mining method that is used by RCBT also runs into long computational times Although Top-k is an exceptiounally fast CAR group upper bound miner it still depends on performing a pruned exponential search over the training sample subset space Thus as the number of training samples increases Top-k quickly becomes computationally challenging to tune/use Table VI contains four average classification test run times in seconds for each Ovarian Cancer\(OC training size As before the second column run times each give the average time required to build both class 0/1 BSTs and then use them to classify all test's samples with BSTC Note that BSTC was able to complete each OC classification test in about 1 minute In contrast RCBT again failed to complete processing most classification tests within 2 hours Table VI's third column gives the average times required for Top-k to mine the top 10 covering rule groups upper bouhnds for each training set test with the same 2 hour cutoff procedure as used for PC testing The fourth column gives the average run times of RCBT on the tests for which Topk finished mining rules also with a 2 hour cutoff Finally the  RCBT DNF column gives the number of tests that RCBT was unable to finish classifying in  2 hours each THE OC TESTS THAT RCBT FINISHED Training BSTC RCBT 40 92.05 97.66 60 95.75 96.73 80 94 12 98.04 1-133/077 9380 96.12 1070 cJ CZ C 0.95 0.9 0.85 0.8 0.75 0.7 0.65 0.6 0.55 0.5 BSTC RCBT d Median Median  Mean 260 Near outliers  Far outliers 40 Training 60 Training 0.90.80.70.6BSTC RCBT a 80 Training 1-52/0-50 Training 0.9DNFI 0.80.70.6BSTC RCBT b 1 u0.9DNFI 0.80.70.6BSTC RCBT  RCBT DNF 40 30.89 0.6186 273.37 0/25 60 61.28 41.21  5554.37 19/25 80 71.84  1421.80  7205.43 t 21/22 TIMES FOR THE OC 9 Mean 0 Near outliers  Far outliers 1.01 11 01 1.0 d Fig 6 PC Holdout Validation Results BSTC RCBT a Fig 0.80.8 0.8BSTC RCBT BSTC RCBT b c c i DNF cJ CZ C 40 Training 60 Training 80 Training 1-133/0-77 Training 0.95 DNF DNF DNF 0.9 0.90.90.90.85 0.8 BSTC RCBT TABLE VI AVERAGE RUN 1 133/0-77 70.38  1045.65  6362.86 t 20/23 over the number of tests for which Top-k finished Because RCBT couldn't finish any 80 or 1-133/0-77 tests within 2 hours with nl  20 we lowered nl to 2 Classification Accuracy Figure 7 contains boxplots for BSTC on all four OC classification test sets Boxplots were not generated for RCBT with 60 80 or 1-133/0-77 training since it was unable to finish all 25 tests for all these training set sizes in  2 hours each Table VII lists the mean accuracies of BSTC and RCBT over the tests on which RCBT was able to produce results Hence Table VII's 40 row consists of averages over 25 results Meanwhile Table VII's 60 row results are from 6 tests 80 contains a single test's result and 1-133/0-77 results from 3 tests RCBT has better mean accuracy on the 40 training size but the results are closer on the remaining sizes   4 difference over RCBT's completed tests Again RCBT's accuracy could vary widely on its uncompleted tests CAR Mining Parameter Tuning and Scalability We attempted to run Top-k to completion on the 3 OC 80 training and 2 OC 1-133/0-77 training tests However it could not finish mining rules within the 2 hour cutoff Top-k finished two of the three 80 training tests in 775 min 43.6 sec and 185 min 3.3 sec However the third test ran for over 16,000 mnm  11 days without finishing Likewise Top-k finished one of the two 1-133/0-77 tests in 126 min 45.2 sec but couldn't finish the other in 16,000 min  11 days After increasing Top-k's support cutoff from 0.7 to 0.9 it was able to finish the two unfinished 80 and 1-133/0-77 training tests in 5 min 13.8 sec and 35 min 36.9 sec respectively However RCBT with nl 2 then wasn't able to finish lower bound rule mining for either of these two tests within 1,500 min Clearly CAR-mining and parameter tuning on large training sets is TABLE VII MEAN AcCU1ACIES FOR 


support pruning gene expression classifier with an accurate and compact fuzzy rule base for microarray data analysis Biosystems vol 85 computationally challenging As training set sizes increase it is likely that these difficulties will also increase VI RELATED WORK While operating on a microarray dataset current CAR 1 2 3 4 and other pattern/rule 20 21 mining algorithms perform a pruned and/or compacted exponential search over either the space of gene subsets or the space of sample subsets Hence they are generally quite computationally expensive for datasets containing many training samples or genes as the case may be BSTC is explicitly related to CAR-based classifiers but requires no expensive CAR mining BSTC is also related to decision tree-based classifiers such as random forest 19 and C4.5 family 9 methods It is possible to represent any consistent set of boolean association rules as a decision tree and vice versa However it is generally unclear how the trees generated by current tree-based classifiers are related to high confidence/support CARs which are known to be particularly useful for microarray data 1 2 6 7 11 BSTC is explicitly related to and motivated by CAR-based methods To the best of our knowledge there is no previous work on mining/classifying with BARs of the form we consider here Perhaps the work closest to utilizing 100 BARs is the TOPRULES 22 miner TOP-RULES utilizes a data partitioning technique to compactly report itemlgene subsets which are unique to each class set Ci Hence TOP-RULES discovers all 100 confident CARs in a dataset However the method must utilize an emerging pattern mining algorithm such as MBD-LLBORDER 23 and so generally isn't polynomial time Also related to our BAR-based techniques are recent methods which mine gene expression training data for sets of fuzzy rules 24 25 Once obtained fuzzy rules can be used for classification in a manner analogous to CARs However the resulting fuzzy classifiers don't appear to be as accurate as standard classification methods such as SVM 25 VII CONCLUSIONS AND FUTURE WORK To address the computational difficulties involved with preclassification CAR mining see Tables IV and VI we developed a novel method which considers a larger subset of CAR-related boolean association rules BARs These rules can be compactly captured in a Boolean Structure Table BST which can then be used to produce a BST classifier called BSTC Comparison to the current leading CAR classifier RCBT on several benchmark microarray datasets shows that BSTC is competitive with RCBT's accuracy while avoiding the exponential costs incurred by CAR mining see Section VB Hence BSTC extends generalized CAR based methods to larger datasets then previously practical Furthermore unlike other association rule-based classifiers BSTC easily generalizes to multi-class gene expression datasets BSTC's worst case per-query classification time is worse then CAR-based methods after all exponential time CAR mining is completed O SlS CGl versus O Si CGi As future work we plan on investigating techniques to decrease this cost by carefully culling BST exclusion lists ACKNOWLEDGM[ENTS We thank Anthony K.H Tung and Xin Xu for sending us their discretized microarray data files and Top-k/RCBT executables This research was supported in part by NSF grant DMS-0510203 NIH grant I-U54-DA021519-OlAf and by the Michigan Technology Tri-Corridor grant GR687 Any opinions findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding agencies REFERENCES 1 G Cong K L Tan A K H Tung and X Xu Mining top-k covering rule Mining SDM 2002 5 R Agrawal T Imielinski and A Swami Mining associations between sets of items Y Ma Integrating classification and association rule mining KDD 1998 11 T McIntosh and S Chawla On discovery of maximal confident rules without pp 43-52 1999 24 S Vinterbo E Kim and L Ohno-Machado Small fuzzy and interpretable pp 165-176 2006 1071 pp 207-216 1993 6 G Dong pp 273-297 t995 9 pp 5-32 2001 20 W Li J R Quinlan Bagging boosting and c4.5 AAAI vol 1 V Vapnik Support-vector networks the best strategies for mining frequent closed itemsets KDD 2003 4 M Zaki and C Hsiao Charm L Wong Identifying good diagnostic genes or gene expression data SIGMOD 2005 2 G Cong A K H Tung X Xu F Pan and J Yang Farmer Finding interesting rule gene expression data by using the gene expression based classifiers BioiiiJcrmatics vol 21 l and Inrelligent Systenis IFIS 1993 16 Available at http://sdmc.i2r.a-star.edu.sg/rp 17 The dprep package http:/cran r-project org/doclpackages dprep pdfI 18 C Chang and C Lin Libsvm a library for support vector machines 2007 Online Available www.csie.ntu.edu.tw cjlin/papers/libsvm.pdf 19 L Breiimnan Random forests Maclh Learn vol 45 no 1 M Chen and H L Huang Interpretable X Zhang 7 J Li and pp 725-734 2002 8 C Cortes and Mac hine Learming vol 20 no 3 in microarray data SIGKDD Worikshop on Dtra Mining in Bioinfrrnatics BIOKDD 2005 12 R Agrawal and R Srikant Fast algorithms for mining association rules VLDB pp 1964-1970 2005 25 L Wong and J Li Caep Classification by aggregating emerging patterns Proc 2nd Iat Coif Discovery Scieice DS 1999 gene groups from pp 487-499 t994 13 Available ot http://www-personal umich edu/o markiwen 14 R Motwani and P Raghavan Randomized Algoriitlms Caim-bridge University Press 1995 15 S Sudarsky Fuzzy satisfiability Intl Conf on Industrial Fuzzy Contri J Han and J Pei Cmar Accurate and efficient classification based on multiple class-association rules ICDM 2001 21 F Rioult J F Boulicaut B Cremilleux and J Besson Using groups for groups in microarray datasets SIGMOD 2004 3 concept of emerging patterns BioinformJotics vol 18 transposition for pattern discovery from microarray data DMKD pp 73-79 2003 22 J Li X Zhang G Dong K Ramamohanarao and Q Sun Efficient mining of high confidence association rules without S Y Ho C H Hsieh H pp 725-730 1996 10 B Liu W Hsu and support thresholds Principles f Drata Mining aind Knowledge Discovery PKDD pp 406 411 1999 23 G Dong and J Li Efficient mining of emerging patterns discovering trends and differences KDD J Wang J Han and J Pei Closet Searching for An efficient algorithm for closed association rule mining Proc oJ the 2nd SIAM Int Con on Data in large databases SIGMOD 



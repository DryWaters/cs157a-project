html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">Data Mining  Application for Predictive Learning from Visiting Nurse Association Data Pallavi Vyas1, Ade1 Elmagbrabyl, and Robert TOpp2 University of Louisville, KY USA psvyasO 1 ,  ade1, rvtoppO l}@louisville.edu Abstract - In the following paper the process of knowledge generation from the Visiting Nurse Association database for elderly care is explored. This inquiry is concerned with predicting falls. Predicting which patients are likely to fall can assist the clinician in the identification of high-risk patients and suggest the need for early falls prevention programs. The entire data mining process is described beginning with data gathering followed by cleaning, aggregation, and integration. Issues faced while conducting the research are discussed Results of decision trees and decision rules, and artificial neural networks used to predict falls are presented Keywords - falls, community, gerontology, fall prevention, predictive data mining, and health informatics 1. Introduction Knowledge Discovery and Data mining \(KDD rapidly growing interdisciplinary field which merges together database management, statistics, machine learning and related areas the ultimate goal of which is to extract useful knowledge from large data sets in order to improve clinical outcomes. Knowledge discovery in databases is the process of identifying valid, novel, potentially useful, and ultimately understandable patterns/models in data. Data mining is a step in the knowledge discovery process consisting of developing particular data mining algorithms that under some acceptable computational efficiency limitations, finds patterns or models in data. In other words, the goal of knowledge discovery and data mining is to find clinical relevant patterns and/or models that exist in databases but are hidden among the volumes of data Data comprises a set of facts F \(e.g., cases in a database Pattern is an expression E in some language L describing a subset FE of the data F \(or a model applicable to that subset beyond its traditional sense to include models or 1. CECS Department - Speed School of Engineering 2. Nursing Research - School of Nursing structure in data \(relations between facts IF Medicationsscore EQUALS 5 Ambulationscore EQUALS 4 4.5 LESS THAN OR EQUALS SafetyScore LESS THAN 9 LevelScore EQUALS 4 Prediction EQUALS Fallers Process: Usually in KDD process is a multi-step process, which involves data preparation, search for patterns, knowledge evaluation, and refinement involving iteration after modification. The process is assumed to be non-trivial, that is, to have some degree of search autonomy Validity: The discovered patterns should be valid on new data with some degree of certainty. A measure of certainty is a function C mapping expressions in L to a partially or totally ordered measurement space Me An expression E in L about a subset FE of set F can be assigned a certainty measure c = C\(E, F Novel: The patterns are novel \(at least to the system changes in data \(by comparing current values to previous or expected values how a new finding is related to old ones this can be measured by a function N\(E, F 


this can be measured by a function N\(E, F be a Boolean function or a measure of degree of novelty or unexpectedness Potentially Useful: The patterns should potentially lead to some useful actions, as measured by some utility function. Such a function U maps expressions in L to a partially or totally ordered measure space Mu: hence, u = U\(E, F Ultimately Understandable: A goal of KDD is to make patterns understandable to humans in order to facilitate a better understanding of the underlying data While this is difficult to measure precisely, one frequent substitute is the simplicity measure. Several measures of simplicity exist, and they range from the purely syntactic \(e.g., the size of a pattern in bits the semantic \(e.g., easy for humans to comprehend in some setting by a function S mapping expressions E in L to a partially or totally ordered measure space Ms: hence, s S\(E,F Typical problems that data mining addresses are how to classify data, cluster data, find associations between data items, and perform time series analysis Numerous data mining techniques have been invented for each type of problem [1,2]. Each problem requires data mining techniques to analyze large quantities of data. Knowledge discovery in databases using data mining techniques is an approach to extracting patterns from large data sets and deducing knowledge insights from those patterns [2]. This knowledge discovery process has several distinct steps or sub processes that begin with data gathering, followed by data cleaning then aggregation and integration. At this point the data is ready to be utilized for data visualization and finally data mining. Rather than being sequential, sub  processes in the data mining process are iterative i.e movement from data visualization back to data cleaning if irregularities are discovered in the data set 2,3 2. Knowledge Discovery in Databases With the advent and proliferation of on-line data collection, truly massive databases are now available to health care researchers. In that situation, data  mining methods yield some unique opportunities to researchers who wish to develop prediction models and to establish associations [13]. Data mining and knowledge discovery in Databases relate to the process of extracting valid, previously unknown and potentially useful patterns and information from raw data in large databases. "The analogy of "mining suggests the sifting through of large amounts of low grade ore \(data multi- step, iterative inductive process [3]. It includes such tasks as problem analysis, data extraction, data preparation and cleaning, data reduction, rule development, output analysis and review. Generally data mining and knowledge discovery in databases are treated as synonyms and refer to the whole process in moving from data to knowledge [2]. A small number of published studies address the value of data mining within the healthcare industry \(see [1] for a survey Other popular data mining techniques applied to healthcare are Bayesian models, association rules case-based reasoning, genetic algorithms, and fuzzy systems \(see [1,2] for applications For the purpose of this study, the knowledge Discovery process is viewed in multiple stages Ramaprasad's [3] staged model that consisted of data acquisition, integration, mining, and revisions of requirements is expanded to a model that consists of the following: acquisition, validation, aggregation and 


the following: acquisition, validation, aggregation and integration, visualization, mining, and revision of objectives \(see figure 1 assignment must begin with clear objectives in mind These objectives will not be in the form of preconceived hypothesis, but must state clearly the scope of the study and potential goals. The process begins with data gathering in which relevant data is sought after for analysis, followed by cleaning and validation. Next disparate data sources will need to be aggregated and visualized to gain preliminary insights Following this we apply algorithms to mine the data and extract or deduce relevant patterns - knowledge At each stage of the data mining process questions and goals may be revised Figure 1: Stage Model for Knowledge Discovery in Databases 3. Problem Definition Clinical databases have accumulated large quantities of information about patients and their medical conditions. The healthcare field faces strong pressures to reduce costs while increasing quality of services delivered [5,6,7,8,9,10]. Storing patient's records in electronic format and the development in medical-information systems cause a large amount of clinical data to be available online [4]. Relationships and patterns within this data could provide new medical knowledge. Unfortunately, few methodologies have been developed and applied to discover this hidden knowledge. In this study, the techniques of data mining \(also known as Knowledge Discovery in Databases large clinical database [12]. Predictive modeling is a fundamental data-mining task. It's an approach that reads training data composed of multiple input variables and a target variable. It then builds a model that attempts to predict the target on the basis of the inputs. After this model is developed, it can be applied to new data that is similar to the training data, but which doesn't contain the target. If the model is successful it will predict the values of the missing target from the values of the new inputs [15 Falls are a significant cause of morbidity and mortality among the older adult population. In community-dwelling individuals age 65 and older approximately one-third fall every year \(King and Tinetti, 1995 in a fracture, a fifth of fall incidents require medical attention [11]. Older adults who experience an injury as a result of a fall substantially increase their risk of death in the 12 months following the fall. A number of investigators have identified risk factors for falls among the older adult population. Many preventive intervention programs based on these risk factors have been established and evaluated. These have included exercise program designed to improve strength or balance, education programs, medication optimization environmental modification in homes or institutions and nutritional or hormonal supplementation [11 Risk factors have been grouped into individual characteristics including polypharamacy, difficulty with ambulation and performing functional tasks, poor vision, declines in muscle strength and postural control and increasing numbers of co-morbidities [18]. Risk factors for a fall have also been categorized into environmental factors including a poorly lit cluttered environment, reduced social support and living alone Each of these risk factors in isolation has been shown to be significantly associated with increased falls/injury risk among older people. However individuals with multiple falls risk factors have an increased rate of falls compared to individuals with 


increased rate of falls compared to individuals with one falls risk factor [14]. Several studies have been performed to predict falls but no investigator has yet examined predictors of falls among community dwelling older adults who are under the care of the VNA [17]. This population exhibits a number of the previously mentioned risk factors for falls and experience a disproportionate frequency of falls compared to age matched community dwelling adults not being cared for by the VNA The purpose of the study was to discriminate individuals being cared for by the Visiting Nurse Association \(VNA experienced a fall within the previous months \(Fallers from individuals being cared for by the Visiting Nurse Association \(VNA not experienced a fall \(Non Fallers techniques of data mining \(also known as Knowledge Discovery in Databases fallers from non-fallers by using data from a large clinical database. Specifically, data accumulated on 63,000 VNA patients were evaluated for factors potentially contributing to differences between fallers and non-fallers using decision trees and decision rules artificial neural network. This paper describes the processes involved in mining a clinical database including data warehousing, data query and cleaning and data analysis Research Question  Does the Fall Risk Screening Tool predict falls among VNA patients who are age 65 and older 4. Methodology Records were identified from 63,000 VNA patient visits records obtained during the 12 months of 2003 To be included in the target for the study the individual must have received ongoing VNA care during 2003, be age 65 and older and community dwelling. Individuals were excluded from the study if their VNA record indicated they did not ambulate. This sample was then dichotomized into two groups, Fallers and Non  fallers. 146 Fallers were identified from this group and included those individuals in the target who had at least one fall documented on their VNA patient record These individual Fallers were matched by age, gender admission date and zip code with 1847 individuals in the target who had no documented fall on their VNA record. A random sample \(arithmetic mean = 12 146 individuals was then drawn from this group of Non-fallers. This methodology resulted in 146 Fallers and 146 Non-fallers being identified for the study Data for the Fallers were extracted from an incident report describing the fall and information collected during the most recent VNA visit with the patient prior to the fall. Data for the Non-fallers were collected from their most recent VNA visit. Data collected during the VNA visit included demographic information as well as information documented on a fall risk-screening tool. This tool assessed level of consciousness, history of falls, ambulation capacity vision status, medication and safety and environmental hazards. These variables acted as the inputs i.e. the predictor variables and the target \(response variable was a binary variable which classified patients into the category of Fallers and Non-Fallers 5. Results and Discussion Two data mining techniques were employed to determine the optimal model in discriminating Fallers from Non-fallers including Decision Trees and Decision Rules and Artificial Neural Network. The statistical tool employed for this study was SAS Enterprise Miner. Based on SAS software, Enterprise 


Enterprise Miner. Based on SAS software, Enterprise Miner combines the data mining process with graphical ease of use. In order to build an effective model, Enterprise Miner does not process all the data at once. It divides the data into three subsets of training, validation and testing. The training subset is used for preliminary model fitting; the validation subset is used to tune model weights during estimation; the test subset is used for model assessment [15]. The Data Partition Node provides several options to partition data For this data it partitioned with a percentage of 75 15 &amp; 10 into Training, Validation and test and the method used was Simple Random. Method gives a choice of three data partition methods. Simple Random method relies on a random seed which can be used to duplicate the partitions. Stratified enables us to select the strata. User Defined enables us to specify the variables that defme the partitions. The target value was binary, either category 0- Fallers or Category 1Non-Fallers. The target can have any of the four values: Binary, Nominal, ordinal and Interval. The first three have there missing values replaced with the most commonly occurring level. Interval variables have there missing values replaced with the mean of the sample Decision Tree used Entropy Reduction as the splitting criteria with mmlmum number of observations in a leaf as 1 and maximum depth of tree as 6. Entropy reduction performs measures of nude impurity. Missing values were treated as unacceptable and the measure used for model assessment was Proportion correctly classified. For assessment of the model validation data set was used. The Decision Tree method generated a model with 70% sensitivity 70.83% specificity using medication, history, and safety and environmental hazards. The decision tree states that "IF SafetyScore IS LESS THAN 2.068627451 AND Medicationsscore EQUALS 5 THEN patients belong to the category of Fallers". A sample of the diagnostic chart \(Figure 2.a decision tree \(Figure 2.b demonstrates visually the sensitivity versus specificity of the dataset mining results. Decision Tree summary is illustrated in tabular format \(Figure 2.c  tree has the best classification rate for the validation data. The decision tree rules \(Figure 2.d patients into category 0 with a percentage of 100 Category 0 belongs to Fallers 75 70 65 60 55 50 45 40 35 30 25 T arge!=CATEGORY Mod.1 Name=T &lt;Be Pelcent Actual T \(lfget Pr  dicted T .3rget Percent 291651;66657 7O.B33333333 Figure 2a: Diaguostic Chart for Decision Tree Figure 2.b: Decision Tree a 27 105 TRAIN N 52 62 114 TfltilH N ? llJ ffi 219 


TfltilH N ? llJ ffi 219 TRAlIl Rt&gt;;\\&lt;% I mAitl Rt&gt;;\\&lt;}; 4'b ? 100 TRAIH RQ  41 100 TRt!JJH C$'&gt;;; 0 WJ 11 48 1RA1tl C11\\'&gt;;; 4jJ 70 52 TflAlti [:$,%: ? roo 11 tRAJN 0 :is liB TRAIN 24 2e ?2 1RA1tl % ? 59 4' ? 100   J..ID ?? 0 14 S 2IJ 0.lID tl 17 24 0.lID N 21 lJ 44 u? Ro\\'?% I   J..ID RI AUD RI 4iID Ce\\\\: 0 ?l lJ ?5 UD C gt;\\UD Cill';%: 100 100 100 i  J..ID 0 32 14 45 4iID ?" 1  3 55 AtID '&gt;, ,'* + 43 52 100 Figure 2.c: Summary of Decision Tree IF Historyscore EQUALS 6 AND Medicationsscore IS ONE OF: 2 3 4 THEN NODE N 0 1 5 14 78,6 21.4 IF SafetyScore &lt; 2,068627451 AND Medicationsscore EQUALS 5 THEN NODE: 6 N: 6 0: 100.0 1: 0.0 IF Medicationsscore IS ONE OF: 2 3 AND Historyscore EQUALS 2 THEN NODE N 0 1 8 58 31.0 69.0 IF 2.068627451 &lt;= SafetyScore &lt; 4.068627451 AND Medicationsscore EQUALS 5 THEN NODE N 0 1 12 8 25.0 75.0 IF 4.068627451 &lt;= SafetyScore AND Medicationsscore EQUALS 5 THEN NODE N 0 1 IF SafetyScore &lt; 1.5 13 


13 13 76.9 23.1 AND Medicationsscore EQUALS 4 AND Historyscore EQUALS 2 THEN NODE N 0 1 16 23 30.4 69.6 IF 1.5 &lt;= SafetyScore AND Medicationsscore EQUALS 4 AND Historyscore EQUALS 2 THEN NODE N 0 1 Figure 2.d 17 97 52.6 47.4 Decision Tree Rules Additionally, using the Artificial Neural Network method resulted in a model with 85% sensitivity, 38 specificity. The most prominent variables in this model included medication, and vision. A sample of the diagnostic chart is shown in Figure 3.a using SAS Enterprise Miner. Figure 3.b and Figure 3.c gives the fit statistics and weights chart for the Artificial Neural Network. An Artificial Neural Network \(ANN information-processing paradigm that is inspired by the way biological nervous systems, such as the brain process information. The key element of this paradigm is the novel structure of the information processing system. It is composed of a large number of highly interconnected processing elements \(neurons in unison to solve specific problems. ANNs, like people, learn by example. An ANN is configured for a specific application, such as pattern recognition or data classification, through a learning process. Learning in biological systems involves adjustments to the synaptic connections that exist between the neurons This is true of ANN s as well. An artificial neuron is a device with many inputs and one output [16]. A neuron has two modes of operation; the training mode and the using mode. In the training mode, the neuron can be trained to fire \(or not patterns. In the using mode, when a taught input pattern is detected at the input, its associated output becomes the current output. If the input pattern does not belong in the taught list of input patterns, the firing rule is used to determine whether to fire or not The accuracy of the result is measured by the ROC Chart. Receiver Operating Characteristics \(ROC Analysis originated from signal detection theory, as a model of how well a receiver is able to detect a signal in the presence of noise. Its key feature is the distinction between hit rate \(or true positive rate false alarm rate \(or false positive rate performance measures T orgel=CATEGORY Model Name=ANN Percirl Predicted T argel Actual T algel Percerl 


Percerl 15 Figure 3.a: Diagnostic Chart for Artificial Neural Networks I [TARGET =CATEGORY  2 I Aver age Prolil  Misclassilicalion Rate 4 I Average Error  5 I Aver age Squared Error 6 I Sum 01 Squared Errors LU Rool Average Squared Error W Rool Final Prediction Error . 9 I Root Mean Squared Error  10. I Error Funclion 11 Mean Squared Error Maximum AbsJule Error Final Prediction Error D ivisor lor AS E Model Degrees 01 Freedom Degrees 01 Freedom lor Error T olal Degrees 01 Freedom 0.4794520548 0..4545454545 0.724137931 0.4337899543 0..40.90.90.90.91 0..37931 0.3448 0..6723174873 0..6943438379 0..710.851940.6 0.23964110.88 0..250.20.46559 0.2561184377 10.4,96280.48 220.180.0.9718 14,854869387 0..4895315177 0.,50.0.20.4614 0.50.60.814536 0.5171320.75 0..50.3520.9478 0.50.0.20.4614 0..50.60.814536 294.4750.5945 61.1 0.2257735 41.229412553 0,2535333449 0,250.20.46559 0,2561184377 0..7457752369 0.7469569154 0..739877480.7 0.267425583 438 12 20.7 219 88 58 Sum 01 F reqlJencies 219 44 88 29 58 Sum Case Weights' Frequencies 438 Akaike's Inlormalion Crilerion 318.4750.5945 Schwarz's Baysian Crilerion 359,14392021 Figure 3.b: Fit Statistics for Artificial Neural Network Figure 3.e: Weights Chart for Artificial Neural Network ROC analysis has also widely been used in medical data analysis to study the effect of varying the threshold on the numerical outcome of a diagnostic test. It has been introduced to machine learning relatively recently, in response to classification tasks with varying class distributions or misclassification costs. ROC analysis is set to cause a paradigm shift in machine learning [19]. ROC curve is a plot of the true positive rate against the false positive rate for the different possible cut points of a diagnostic test A ROC curve demonstrates several things 1. It shows the tradeoff between sensitivity and specificity \(any increase in sensitivity will be accompanied by a decrease in specificity 2. The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test 3. The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test 4. The slope of the tangent line at a cut point gives 


4. The slope of the tangent line at a cut point gives the likelihood ratio \(LR 5. The area under the curve is a measure of test accuracy Figure 4 demonstrates the area under the curve of the decision tree and artificial neural network. Decision Tree curve follows the left-hand border and then the top border of the ROC space more accurately then the Artificial neural network so decision tree has a better area under the curve and hence a more accurate test 6. Conclusion Two data mining modeling techniques resulted in models with varying degrees of sensitivity and specificity. Based upon examination of these models the Decision Tree approach produced a superior predictive model. This model employed medication history, and safety and environmental hazards to discriminate Fallers from Non-Fallers with a high degree of sensitivity, and specificity. The model predicted safety score and medication score as the two most important factors in predicting falls. Clinicians may evaluate these characteristics of their VNA patients when attempting to identify patients who have a high likelihood of falling in the future U M U V M U 1  SpeclO:iW OOI I!I!Tree I!I!Neurai Figure 4: ROC Chart for Decision Tree and Artificial Neural Network 7. Acknowledgements This project was supported by Visiting Nurse Association, Louisville, KY References 1] Desouza, K.C. \(2001 healthcare management" In Proceedings of the First International Conference on Management of Healthcare and Medical Technology Enschede Netherlands: Institute for Healthcare Technology Management 2] Desouza, K.C. \(2002 with artificial intelligence". Westport, CT: Quorum Books 3] Ramaprasad, A. \(1996 mining". Journal of Database Marketing 4 \(1 75 4] M. Kantardzic, \(2002 Models, Methods, and Algorithms", IEEE Press &amp John Wiley 5] Baxt, W.G. and Skora, J. \(1996 Validation of Artificial Neural Network Trained to Identify Acute Myocardial Infarction." The Lancet 347 12-15 6] Berkowitz, M., O'Leary, P., Kruse, D., &amp; Harvey C. \(1998 medical and social costs". New York: Demos Medical Publishing, Inc 7] Cabena, P., Hadjinian, P., Stadler, R., Verhees, J., &amp Zanasi, A. \(1998 concept to implementation". Upper Saddle River NJ: Prentice Hall, Inc 8] Kraft, M.R., Desouza, K.C., and Androwich, I 2002 injury patients using neural networks and nursing diagnoses data". In Proceedings of the Second International Conference on Management of Healthcare and Medical Technology, Chicago Illinois. July. \(In Press 9] Kraft, M., Desouza, K.C., and Androwich, I 2002 Issues and Process." In M. Khosrow-Pour \(Editor Issues &amp; Trends of Information Technology 


Issues &amp; Trends of Information Technology Management in Contemporary Organizations, Vol. I Hershey, PA: Idea Group Publishing, pp. 168-171 10] Walczak, S. and Scharf, J. E. \(2000 Surgical Patient Costs Through Use of an Artificial Neural Network to Predict Transfusion Requirements." Decision Support Systems 30 \(2 125-138 11] Gillespie, L.D., Gillespie, W.J., Robertson, M.C Lamb, S.E., Cumming, R.G., &amp; Rowe, B.H. \(2004 Interventions for preventing falls in elderly patients". Cochrane Database of Systematic Reviews. \(2 12] Prather, J.C., Lobach, D.F., Goodwin, L.K., Hales J.W., Hage, M.L., &amp; Hammond, W.E. \(1997 Medical data mining: knowledge discovery in a clinical data warehouse". Proceedings/AMIA Annual Fall Symposium 101-5 13] Hobbs, G.R. \(2001 informatics". American Journal of Health Behavior 25 \(3 14] Keith, H., Robyn, S., Kate, M., Jane, S., Jenny, G Peteris, D., &amp; Freda, V. \(2000 Research Institute 15] Getting started with Enterprise Miner Software From SAS Online Tutorial. Retrieved October 8, 2004 from http://www.stat.purdue.eduHosong/stat598m1EMT doc 16] Christos, S. and Dimitrios, S., Neural Networks Retrieved on October 8, 2004 from http://www.csic.comell.edU/20 lIneural_ network 17] Swartzbeck, E. \(1983 elderly". Nursing Management, 14 \(12 18] Witte, N. \(1979 Journal of Nursing, 79 \(10 19] Preter, A.F. \(2004 analysis in machine learning". Retrieved on October 8,2004 from pre></body></html 


efficiency then AOFI. However utilization of fuzzy concept hierarchies provides more flexibility in reflecting expert knowledge and so allows better modeling of real-life dependencies among attribute values, which will lead to more satisfactory overall results for the induction process. The drawback of the computational cost may additionally decline when we notice that, in contrast to many other data mining algorithms, hierarchical induction algorithms need to run only once through the original \(i.e. massive dataset. We are continuing an investigation of computational costs of our approach for large datasets ACKNOWLEDGMENT Rafal Angryk would like to thank the Montana NASA EPSCoR Grant Consortium for sponsoring this research REFERENCES 1] J. Han , M. Kamber, Data Mining: Concepts and Techniques, Morgan Kaufmann, New York, NY 2000 2] J. Han, Y. Cai, and N. Cercone  Knowledge discovery in databases: An attribute-oriented approach  Proc. 18th Int. Conf. Ver y Large Data Bases, Vancouver, Canada, 1992, pp. 547-559 3] J. Han  Towards Efficient Induction Mechanisms in Database Systems  Theoretical Computing Science, 133, 1994, pp. 361-385 4] J. Han, Y. Fu  Discovery of Multiple-Level Association Rules from Large Databases  IEEE Trans.  on KD E, 11\(5 5] C.L. Carter, H.J. Hamilton  Efficient AttributeOriented Generalization for Knowledge Discovery from Large Databases  IEEE Trans. on KDE 10\(2 6] R.J. Hilderman, H.J. Hamilton, and N. Cercone  Data mining in large databases using domain generalization graphs  Journal of Intelligent Information Systems, 13\(3 7] C.-C. Hsu  Extending attribute-oriented induction algorithm for major values and numeric values   Expert Systems with Applications , 27, 2004, pp 187-202 8] D.H. Lee, M.H. Kim  Database summarization using fuzzy ISA hierarchies  IEEE Trans . on SMC - part B, 27\(1 9] K.-M. Lee  Mining generalized fuzzy quantitative association rules with fuzzy generalization hierarchies  20th NAFIPS Int'l Conf., Vancouver Canada, 2001, pp. 2977-2982 10] J. C. Cubero, J.M. Medina, O. Pons &amp; M.A. Vila  Data Summarization in Relational Databases through  Fuzzy Dependencies  Information Sciences, 121\(3-4 11] G. Raschia, N. Mouaddib  SAINTETIQ:a fuzzy set-based approach to database summarization   Fuzzy Sets and Systems, 129\(2 162 12] R. Angryk, F. Petry  Consistent fuzzy concept hierarchies for attribute generalization  Proceeding of the IASTED Int. Conf. on Information and Knowledge Sharing, Scottsdale AZ, USA, November 2003, pp. 158-163 13] Toxics Release Inventory \(TRI available EPA database hosted at http://www.epa.gov/tri/tridata/tri01/index.htm The 2005 IEEE International Conference on Fuzzy Systems790 pre></body></html 


the initial global candidate set would be similar to the set of global MFIs. As a result, during the global mining phase the communication and synchronization overhead is low  0 2 4 6 8 1 0 Number of Nodes Figure 5. Speedup of DMM 4.4.2 Sizeup For the sizeup test, we fixed the system to the 8-node con figuration, and distributed each database listed in Table 2 to the 8 nodes. Then, we increased the local database sire at each node from 45 MB to 215 MB by duplicating the initial database partition allocated to the node. Thus, the data distribution characteristics remained the same as the local database size was increased. This is different from the speedup test, where the database repartitioning was per formed when the number of nodes was increased. The per formance of DMM is affected by the database repartitioning to some extent, although it is usually very small. During the sizeup test, the local mining result of DMM is not changed at all at each node The results shown in Figure 6 indicate that DMM has a very good sizeup property. Since increasing the size of local database did not affect the local mining result of DMM at each node, the total execution time increased just due to more disk U 0  and computation cost which scaled almost linearly with sizeup 5 Conclusions In this paper, we proposed a new parallel maximal fre quent itemset \(MFI Max-Miner \(DMM tems. DMM is a parallel version of Max-Miner, and it re quires low synchronization and communication overhead compared to other parallel algorithms. In DMM, Max Miner is applied on each database partition during the lo 0 45 90 135 180 225 270 Amwnt of Data per Node \(ME Figure 6. Sizeup of DMM cal mining phase. Only one synchronization is needed at thc end of this phase to construct thc initial global candi date set. In the global mining phase, a top-down search is performed on the candidate set, and a prefix tree is used to count the candidates with different length efficiently. Usu ally, just a few passes are needed to find all global maximal frequent itemsets. Thus, DMM largely reduces the number of synchronizations required between processing nodes Compared with Count Distribution, DMM shows a great improvement when some frequent itemscts are large \(i.e long patterns employed by DMM for efficient communication between nodes; and global support estimation, subset-infrequency based pruning, and superset-frequency based pruning are used to reduce the size of global candidate set. DMM has very good speedup and sizeup properties References I ]  R. Agrawal and R. Srikant  FdSt Algorithms for Mining As sociation Rules  Pmc. o f f h e  ZOrh VLDB Conf, 1994, pp 487499 2] R. Agrawal and I. C. Shafer  Parallel Mining of Association Rules  IEEE Trans. on Knowledge and Dura Engineering Vol. 8, No. 6, 1996, pp. 962-969 3] R. I. Bayardo  Efficient Mining Long Patlems from Databases  Proc. ofrhe ACM SIGMOD Inf  l Conf on Man ogemenr ofDara, 1998, pp. 85-91 4] S.  M. Chung and J. Yang  A Parallel Distributive Join Al gorithm for Cube-Connected Multiprocessors  IEEE Trans on Parallel and Disrribured Systems, Vol. 7, No. 2, 1996, pp 127-137 51 M. Snir, S. Otto. S. Huss-Lederman, D. Walker, and J. Don gana, MPI: The Complete Reference, The MIT Press, 1996 


gana, MPI: The Complete Reference, The MIT Press, 1996 6] R. Rymon  Search through Systematic Set Enumeralion   Pmc. of3rd Inr  l Con$ on Principles of Knowledge Repre sentation and Reasoning, 1992, pp. 539-550 507 pre></body></html 


sketch-index in answering aggregate queries. Then Section 5.2 studies the effect of approximating spatiotemporal data, while Section 5.3 presents preliminary results for mining association rules 5.1 Performance of sketch-indexes Due to the lack of real spatio-temporal datasets we generate synthetic data in a way similar to [SJLL00 TPS03] aiming at simulation of air traffic. We first adopt a real spatial dataset [Tiger] that contains 10k 2D points representing locations in the Long Beach county \(the data space is normalized to unit length on each dimension These points serve as the  airbases  At the initial timestamp 0, we generate 100k air planes, such that each plane \(i uniformly generated in [200,300], \(ii, iii destination that are two random different airbases, and iv  the velocity direction is determined by the orientation of the line segment connecting its source and destination airbases move continually according to their velocities. Once a plane reaches its destination, it flies towards another randomly selected also uniform in [0.02, 0.04 reports to its nearest airbase, or specifically, the database consists of tuples in the form &lt;time t, airbase b, plane p passenger # a&gt;, specifying that plane p with a passengers is closest to base b at time t A spatio-temporal count/sum query has two parameters the length qrlen of its query \(square number qtlen of timestamps covered by its interval. The actual extent of the window \(interval uniformly in the data space \(history, i.e., timestamps 0,100 air planes that report to airbases in qr during qt, while a sum query returns the sum of these planes  passengers. A workload consists of 100 queries with the same parameters qrlen and qtlen The disk page size is set to 1k in all cases \(the relatively small page size simulates situations where the database is much more voluminous specialized method for distinct spatio-temporal aggregation, we compare the sketch-index to the following relational approach that can be implemented in a DBMS. Specifically, we index the 4-tuple table lt;t,b,p,a&gt; using a B-tree on the time t column. Given a count query \(with window qr and interval qt SELECT distinct p FROM &lt;t,b,p,a&gt WHERE t?qt &amp; b contained in qr The performance of each method is measured as the average number of page accesses \(per query processing a workload. For the sketch-index, we also report the average \(relative Specifically, let acti and esti be the actual and estimated results of the i-th query in the workload; then the error equals \(1/100 set the number of bits in each sketch to 24, and vary the number of sketches The first experiment evaluates the space consumption Figure 5.1 shows the sketch index size as a function of the number of sketches used \(count- and sum-indexes have the same results more sketches are included, but is usually considerably smaller than the database size \(e.g., for 16 signatures, the size is only 40% the database size 0 20 40 60 80 


80 100 120 140 160 8 16 32 number of sketches size \(mega bytes database size Figure 5.1: Size comparison Next we demonstrate the superiority of the proposed sketch-pruning query algorithm, with respect to the na  ve one that applies only spatio-temporal predicates. Figure 5.2a illustrates the costs of both algorithms for countworkloads with qtlen=10 and various qrlen \(the index used in this case has 16 sketches also illustrate the performance of the relational method which, however, is clearly incomparable \(for qrlen?0.1, it is worse by an order of magnitude we omit this technique Sketch-pruning always outperforms na  ve \(e.g., eventually two times faster for qrlen=0.25 increases with qrlen, since queries returning larger results tend to set bits in the result sketch more quickly, thus enhancing the power of Heuristics 3.1 and 3.2. In Figure 5.2b, we compare the two methods by fixing qrlen to 0.15 and varying qtlen. Similar to the findings of [PTKZ02]4 both algorithms demonstrate  step-wise  growths in their costs, while sketch-pruning is again significantly faster The experiments with sum-workloads lead to the same observations, and therefore we evaluate sketch-indexes using sketch-pruning in the rest of the experiments 4 As explained in [PTKZ02], query processing accesses at most two paths from the root to the leaf level of each B-tree regardless the length of the query interval Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE sketch-pruning naive relational 0 100 200 300 400 500 600 700 800 900 0.05 0.1 0.15 0.2 0.25 number of disk accesses query rectangle length 300 0 100 200 400 500 600 1 5 10 15 20 number of disk accesses query interval length a qtlen=10 b qrlen=0.15 Figure 5.2: Superiority of sketch-pruning \(count As discussed in Section 2, a large number of sketches reduces the variance in the resulting estimate. To verify this, Figure 5.3a plots the count-workload error of indexes 


using 8-, 16-, and 32- sketches, as a function of qrlen qtlen=10 error \(below 10 it increases slowly with qrlen used, however, the error rate is much higher \(up to 30 and has serious fluctuation, indicating the prediction is not robust. The performance of 16-sketch is in between these two extremes, or specifically, its accuracy is reasonably high \(average error around 15 much less fluctuation than 8-sketch 32-sketch 16-sketch 8-sketch relative error 0 5 10 15 20 25 30 35 0.05 0.1 0.15 0.2 0.25 query rectangle length relative error 0 5 10 15 20 25 30 35 1 5 10 15 20 query interval length a qtlen=10, count b qrlen=0.15, count relative error query rectangle length 0 5 10 15 20 25 0.05 0.1 0.15 0.2 0.25 relative error query interval length 0 5 10 15 20 25 30 1 5 10 15 20 c qtlen=10, sum d qrlen=0.15, sum Figure 5.3: Accuracy of the approximate results The same phenomena are confirmed in Figures 5.3b where we fix qrlen to 0.15 and vary qtlen 5.3d \(results for sum-workloads number of sketches improves the estimation accuracy, it also leads to higher space requirements \(as shown in Figure 5.1 Figures 5.4a and 5.4b show the number of disk accesses for the settings of Figures 5.3a and 5.3b. All indexes have almost the same behavior, while the 32-sketch is clearly more expensive than the other two indexes. The interesting observation is that 8- and 16-sketches have 


interesting observation is that 8- and 16-sketches have almost the same overhead due to the similar heights of their B-trees. Since the diagrams for sum-workloads illustrate \(almost avoid redundancy 32-sketch 16-sketch 8-sketch number of disk accesses query rectangle length 0 50 100 150 200 250 300 350 400 0.05 0.1 0.15 0.2 0.25 number of disk accesses query interval length 0 50 100 150 200 250 300 350 1 5 10 15 20 a qtlen=10 b qrlen=0.15 Figure 5.4: Costs of indexes with various signatures Summary: The sketch index constitutes an effective method for approximate spatio-temporal \(distinct aggregate processing. Particularly, the best tradeoff between space, query time, and estimation accuracy obtained by 16 sketches, which leads to size around 40 the database, fast response time \(an order of magnitude faster than the relational method average relative error 5.2 Approximating spatio-temporal data We proceed to study the efficiency of using sketches to approximate spatio-temporal data \(proposed in Section 4.1 as in the last section, except that at each timestamp all airplanes report their locations to a central server \(instead of their respective nearest bases maintains a table in the form &lt;time t, plane p, x, y&gt;, where x,y with parameters qrlen and qtlen distinct planes satisfying the spatial and temporal conditions. For comparison, we index the table using a 3D R*-tree on the columns time, x, and y. Given a query, this tree facilitates the retrieval of all qualifying tuples, after which a post-processing step is performed to obtain the Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE number of distinct planes \(in the sequel, we refer to this method as 3DR method introduces a regular res  res grid of the data space, where the resolution res is a parameter. We adopt 16 sketches because, as mentioned earlier, this number gives the best overall performance Figure 5.5 compares the sizes of the resulting sketch indexes \(obtained with resolutions res=25, 50, 100 the database size. In all cases, we achieve high compression rate \(e.g., the rate is 25% for res=25 evaluate the query efficiency, we first set the resolution to the median value 50, and use the sketch index to answer workloads with various qrlen \(qtlen=10 


workloads with various qrlen \(qtlen=10 size \(mega bytes database size 0 20 40 60 80 100 120 140 160 25 50 100 resolution Figure 5.5: Size reduction Figure 5.6a shows the query costs \(together with the error in each case method. The sketch index is faster than 3DR by an order of magnitude \(note that the vertical axis is in logarithmic scale around 15% error observations using workloads with different qtlen Finally, we examine the effect of resolution res using a workload with qrlen=0.15 and qtlen=10. As shown in Figure 5.6c, larger res incurs higher query overhead, but improves the estimation accuracy Summary: The proposed sketch method can be used to efficiently approximate spatio-temporal data for aggregate processing. It consumes significantly smaller space, and answers a query almost in real-time with low error 3D Rsketch number of disk accesses query rectangle length 1 10 100 1k 10k 0.05 0.1 0.15 0.2 0.25 16 14% 15 15% 13 relative error number of disk accesses query interval length 1 10 100 1k 10k 1 5 10 15 20 16 15% 15% 12% 11 relative error a qtlen=10, res=25 b qrlen=0.15, res=25 0 500 1000 1500 2000 2500 25 50 100 number of disk accesses resolution 20% 15% 14 relative error c qrlen=0.15, qtlen=10 


c qrlen=0.15, qtlen=10 Figure 5.6: Query efficiency \(costs and error 5.3 Mining association rules To evaluate the proposed algorithm for mining spatiotemporal association rules, we first artificially formulate 1000 association rules in the form \(r1,T,90 with 90% confidence i randomly picked from 10k ones, \(ii in at most one rule, and \(iii Then, at each of the following 100 timestamps, we assign 100k objects to the 10k regions following these rules. We execute our algorithms \(using 16 sketches these rules, and measure \(i  correct  rules divided by the total number of discovered rules, and \(ii successfully mined Figures 5.7a and 5.7b illustrate the precision and recall as a function of T respectively. Our algorithm has good precision \(close to 90 majority of the rules discovered are correct. The recall however, is relatively low for short T, but gradually increases \(90% for T=25 evaluated in the previous sections, the estimation error decreases as the query result becomes larger \(i.e., the case for higher T 78 80 82 84 86 88 90 92 94 96 5 10 2015 25 precision HT 78 80 82 84 86 88 90 92 94 96 5 10 2015 25 recall HT a b Figure 5.7: Efficiency of the mining algorithm Summary: The preliminary results justify the usefulness of our mining algorithm, whose efficiency improves as T increases Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE 6. Conclusions While efficient aggregation is the objective of most spatio-temporal applications in practice, the existing solutions either incur prohibitive space consumption and query time, or are not able to return useful aggregate results due to the distinct counting problem. In this paper we propose the sketch index that integrates traditional approximate counting techniques with spatio-temporal indexes. Sketch indexes use a highly optimized query algorithm resulting in both smaller database size and faster query time. Our experiments show that while a sketch index consumes only a fraction of the space required for a conventional database, it can process 


required for a conventional database, it can process queries an order of magnitude faster with average relative error less than 15 While we chose to use FM sketches, our methodology can leverage any sketches allowing union operations Comparing the efficiency of different sketches constitutes a direction for future work, as well as further investigation of more sophisticated algorithms for mining association rules. For example, heuristics similar to those used for searching sketch indexes may be applied to improve the brute-force implementation ACKNOWLEDGEMENTS Yufei Tao and Dimitris Papadias were supported by grant HKUST 6197/02E from Hong Kong RGC. George Kollios, Jeffrey Considine and were Feifei Li supported by NSF CAREER IIS-0133825 and NSF IIS-0308213 grants References BKSS90] Beckmann, N., Kriegel, H., Schneider, R Seeger, B. The R*-tree: An Efficient and Robust Access Method for Points and Rectangles. SIGMOD, 1990 CDD+01] Chaudhuri, S., Das, G., Datar, M., Motwani R., Narasayya, V. Overcoming Limitations of Sampling for Aggregation Queries. ICDE 2001 CLKB04] Jeffrey Considine, Feifei Li, George Kollios John Byers. Approximate aggregation techniques for sensor databases. ICDE, 2004 CR94] Chen, C., Roussopoulos, N. Adaptive Selectivity Estimation Using Query Feedback. SIGMOD, 1994 FM85] Flajolet, P., Martin, G. Probabilistic Counting Algorithms for Data Base Applications JCSS, 32\(2 G84] Guttman, A. R-Trees: A Dynamic Index Structure for Spatial Searching. SIGMOD 1984 GAA03] Govindarajan, S., Agarwal, P., Arge, L. CRBTree: An Efficient Indexing Scheme for Range Aggregate Queries. ICDT, 2003 GGR03] Ganguly, S., Garofalakis, M., Rastogi, R Processing Set Expressions Over Continuous Update Streams. SIGMOD, 2003 HHW97] Hellerstein, J., Haas, P., Wang, H. Online Aggregation. SIGMOD, 1997 JL99] Jurgens, M., Lenz, H. PISA: Performance Models for Index Structures with and without Aggregated Data. SSDBM, 1999 LM01] Lazaridis, I., Mehrotra, S. Progressive Approximate Aggregate Queries with a Multi-Resolution Tree Structure. SIGMOD 2001 PGF02] Palmer, C., Gibbons, P., Faloutsos, C. ANF A Fast and Scalable Tool for Data Mining in Massive Graphs. SIGKDD, 2002 PKZT01] Papadias,  D., Kalnis, P.,  Zhang, J., Tao, Y Efficient OLAP Operations in Spatial Data Warehouses. SSTD, 2001 PTKZ02] Papadias, D., Tao, Y., Kalnis, P., Zhang, J Indexing Spatio-Temporal Data Warehouses ICDE, 2002 SJLL00] Saltenis, S., Jensen, C., Leutenegger, S Lopez, M.A. Indexing the Positions of Continuously Moving Objects. SIGMOD 2000 SRF87] Sellis, T., Roussopoulos, N., Faloutsos, C The R+-tree: A Dynamic Index for MultiDimensional Objects. VLDB, 1987 TGIK02] Thaper, N., Guha, S., Indyk, P., Koudas, N Dynamic Multidimensional Histograms 


SIGMOD, 2002 Tiger] www.census.gov/geo/www/tiger TPS03] Tao, Y., Papadias, D., Sun, J. The TPR*Tree: An Optimized Spatio-Temporal Access Method for Predictive Queries. VLDB, 2003 TPZ02] Tao, Y., Papadias, D., Zhang, J. Aggregate Processing of Planar Points. EDBT, 2002 TSP03] Tao, Y., Sun, J., Papadias, D. Analysis of Predictive Spatio-Temporal Queries. TODS 28\(4 ZMT+01] Zhang, D., Markowetz, A., Tsotras, V Gunopulos, D., Seeger, B. Efficient Computation of Temporal Aggregates with Range Predicates. PODS, 2001 ZTG02] Zhang, D., Tsotras, V., Gunopulos, D Efficient Aggregation over Objects with Extent PODS, 2002 Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE pre></body></html 



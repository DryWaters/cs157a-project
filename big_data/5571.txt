An Improvement of Fuzzy Association Rules Mining Algorithm Based on Redundacy of Rules Toshihiko Watanabe Faculty of Engineering Osaka Electro-Communication University Neyagawa, Japan t-wata@isc.osakac.ac.jp Abstract- In data mining approach, the quantitative attributes should be appropriately dealt with as well as the Boolean attributes. This paper presents a fast algorithm for extracting fuzzy association rules from database. The objective of the algorithm is to improve the computational time of mining for the actual application. In this paper, we propose a basic algorithm based on the Apriori algorithm for rule extraction utilizing redundancy of the extracted rules. The performance of the algorithm is evaluated through numerical experiments using benchmark data. From the results, the method is found to be promising in terms of computational time and redundant rule pruning Keywords-component; Data Mining; Association Rules;Fuzzy Association Rules; Redundancy 1. INTRODUCTION In data mining approach, association rules mmmg algorithms are promising for actual applications such as marketing problems. Recently, it has been applied also to the other fields such as biological knowledge extraction. However the association rules mining is essentially based on Boolean attributes constitution in database. In order to apply the mining algorithm to further various problems, the quantitative attributes should also be appropriately dealt with as well as the Boolean attributes. Especially in manufacturing area quantitative attributes such as states of a process, conditions of manufacturing, and measured quality of products, are necessary for quality control[8], manufacturing management planning, and decision of management strategy. In order to deal with the quantitative attributes in mining association rules algorithms based on the generalized association rules that handle the continuous attributes as the Boolean vector by partitioning into several intervals are proposed[1 ][2]. Though several methods were also proposed to improve the computational efficiency and utility[ 11], the process performed by the algorithms was still time consuming and 


complicated to the user. Fuzzy association rules mining approaches are proposed to overcome such disadvantages based on the fuzzy set concept[3-6,1 0, 11]. These approaches are based on fuzzy extensions of the classical association rules mining by defining support and confidence of the fuzzy rule 978-1-4244-8314-3110/$26.00 2010 IEEE 68 The fuzzy association rules mining has a good property in terms of quantization of numerical attributes in database compared with Boolean quantized generalized association rules mining[12,13]. Though the mining results of fuzzy association rules are easy to understand for corresponding human operators, two drawbacks are still remained for applying such fuzzy approaches to the actual problems. One is the computational time for mining from database, and the other is huge redundant rules extraction as the result of mining The issue of computational efficiency is critical for fuzzy association rules mining compared with traditional Boolean rules mining, as the number of fuzzy items for mining increases for quantization of numerical attributes In order to deal with such computational efficiency, a memory based approach is proposed and shows significance of the performance[14]. However, the method occupies the necessary internal computer resource, i.e. memory, for mining calculation. In the another point of view, a mining method that extracts association rules with multiple minimal support thresholds of items in database[15]. Though the method is also necessary for actual applications, the decision problem of the importance of each item realized as minimal support is still remained as an indispensable issue In this paper, we discuss an improvement of algorithm for extracting fuzzy association rules from database. The objective of the algorithm is to improve the computational efficiency of data mining and to reduce the redundant rules extracted for the actual application. Firstly, we define redundancy of fuzzy association rules inspired by [16]. We also prove essential theorems concerning with redundancy of fuzzy association rules. Secondly, we propose a basic algorithm based on the Apriori algorithm for rule extraction considering redundancy of rules. The basic idea is to calculate the confidence of the rule and the redundancy in the extraction process, instead of final calculation of the confidence in conventional methods Utilizing the confidence and the redundancy of the rule 


candidate itemsets generation can be restrained by the proposed algorithm. Through numerical experiments using UCI benchmark data\(abalone  algorithm is demonstrated The paper is organized as follows. In section 2, extraction technique of fuzzy association rules is introduced. In section 3 basic concepts of redundancy of fuzzy association rules are described. The algorithm to improve the computational efficiency based on the redundancy is proposed in section 4. In section 5, results of numerical examples to confirm the proposed algorithm are shown. Finally, conclusions are drawn in section 6 II. EXTRACTION OF Fuzzy ASSOCIATION RULES A. Fuzzy Association Rules Fuzzy association rules are extension of Boolean association rules based on quantization using fuzzy sets. Fuzzy association rules extraction is performed as the following steps Let F = {P,Q,T} denotes the fuzzy itemset which consists of fuzzy sets in different attribute, where P, Q, and T denote the fuzzy sets. Support of the itemset F is defmed as s\(F Xp m 1 where x p denotes the transaction of the database, J1 F \(x P denotes the membership value calculated by the product operation \(t-norm Fuzzy Set denotes the total number of transactions in the database. It is obvious that the definition is equivalent to the wel1-known Boolean mining problem" when the item sets consist of "crisp sets." From the support value, confidence of the fuzzy association rule G ? H is calculated by c\(G ? H GuH G 2 where G and H are fuzzy item sets. The fuzzy association rule is extracted when these values of the rule are more than pre defmed minimal support and pre-defmed minimal confidence When we apply the mining algorithm to the actual huge problems, the support calculation is critical calculation concerning the number of queries to the database. The item set which has the value greater than predefined threshold is called frequent itemset." One of the main problems of mining fuzzy association rules is how efficiently fmd the "frequent itemsets from the database 


B. The Apriori Algorithm The Apriori algorithm is an essential and effective method for finding the frequent itemsets. The basic idea is that the frequent itemset should contain the subsets of frequent itemsets. Owing to this characteristic, frequent itemsets can be compounded from the smaller frequent itemsets one after another. Let k-itemset denote an itemset having k items. Let Lk represent the set of frequent k-itemsets, and Ck the set of candidate k-itemsets. The algorithm to generate the frequent item sets is as fol1ows AI A2 k-l is not in Lk_1 are deleted A3 database scan to decide Lk It should be noted that the plural fuzzy sets defined in the same attribute cannot be included together in the same item set 69 After LI is decided first through database scan, the above Al A3 procedures are iterated until Lk becomes empty set. The association rules are extracted by combining the decided frequent item sets to calculate the confidence of the association rule by Eq.\(2 more than pre-defined minimal confidence are decided III. REDUNDANCY OF THE RULE First we need an appropriate measure of redundancy of extracted rules. In this study, we deal with the redundancy based on the certainty factor[10,1l,16]. The certainty factor is an important and popular used measure of belief to inference rules since MYCIN era. The certainty factor\(CF rule A ? C is defined as follows CF\(A ? C Conf\(A ? C C l-supp\(C if Conf\(A ? C supp\(C CF\(A ? C Conf\(A ? C C supp\(C if Conf\(A ? C C CF\(A ?C C CF\(A ? C C 1 In this study, we defme redundancy of fuzzy association 


rules inspired by the conventional studies[16,17]. Whereas Xu et. al proved the redundancy of rules having different conclusion parts, we assume that the conclusion part of rules is identical for redundancy theorem from the viewpoint of application in this study Theorem 1: Let X ? Y and X' ? Y be two fuzzy association rules If Conf\(X ? Y X' ? Y then CF\(X ? Y X' ? Y Proof Assume that S = CF \(X ? Y X' ? Y 1 X'? Y Y Conf\(X ? Y X' ? Y Conf\(X ? Y Y s = Con/\(X ? Y Y X'? Y Y 1 -supp\(Y Y Con/\(X ? Y X'? Y I-supp\(Y 2 X' ? Y Y situation, we have two cases i X ? Y Y In this case s = Conf\(X ? Y Y X'? Y Y supp\(Y Y Conf\(X ? Y X'? Y 2 0 supp\(Y ii X ? Y Y In this case s = Conf\(X ? Y Y X'? Y Y 1 -supp\(Y Y Conf\(X ? Y Y y X'? Y 0 1-supp\(Y Y 3 Y Y is obviously hold Theorem 2: Let A ? Y, B ? Y and A,B ? Y be three fuzzy association rules, where A, B and Yare fuzzy itemsets If max\(Conf\(A ? y B ? Y A, B ? Y then max\(CF\(A ? Y B ? Y A,B ? Y Proof 1 Conf\(A ? Y B ? V 


0: Conf\(A, B ? y max\(CF\(A ? V B ? y CF\(A ? y B ? V 2: CF\(A,B? Y 2 Conf\(A ? Y B ? V Conf\(A, B ? y A, B ? y A ? y or Conf\(A, B ? Y B ? Y max\(CF\(A ? Y B ? Y A,B ? Y We can extend the Theorem 2 to the general condition Theorem 3: Let X ? Y be a fuzzy association rule, where X and Yare fuzzy item sets. Let Q be Q = 2 x - X -  , where 2x is the power set of X and  is the empty set Confidence 1.0 Confidence threshold Non-lledllndanlllule A-> Y o:: ..... :::::;e A,C-> Y C-> Y ? lIedllndal1lllllle 8-> Y o---==;e 8,C-> Y 0 '------'----'-----'---2 3 4 The number of items Figure I. Conceptual Diagram of Redundancy of the Rules Definition 1: Let X ? Y be a fuzzy association rule, where X and Yare fuzzy itemsets. Let Q be Q = 2 x - X -  , where 2x is the power set of X and  is the empty set If max{Conf\(Z ? y X ? Y ZEQ X ? Y redundant rule If max{Conf\(Z ? Y X ? Y ZEQ X ? Y non-redundant rule The redundant rule has never maximum value of CF among the subset fuzzy association rules. On the contrary, the non redundant rule has maximum value of CF among the subset fuzzy association rules from Theorem 3. Fig.l shows the conceptual diagram of the redundant rule and the non redundant rule The objective of association rules mining becomes to find the fuzzy association rules that are non-redundant and satisfY traditional confidence and support conditions. Clearly we can calculate the redundancy and prune the redundant rules after 


mining procedures. Our motivation in this study is to utilize the redundancy for extracting algorithm of fuzzy association rules IV. IMPROVEMENT OF APRIORI ALGORITHM BASED ON If max{Conf\(Z ? y X ? y max{CF\(Z ? y X ? y ZEQ Proof From the assumption, there exist P E Q that satisfY Con/\(P ? y X ? Y P ? y 0: CF\(X ? Y CF\(X ? y P ? Y Z ? V ZEQ 70 The necessary point in the Apriori algorithm for extracting association rules is to generate the frequent item sets efficiently Though the confidence of the association rules are calculated mally after all decision of frequent itemsets in traditional Apriori algorithm, the basic idea of our proposal is that the confidence of the rule can be calculated after each step A3 in the Apriori algorithm and used for pruning the redundant itemsets. The issue is to decide which itemset should be pruned utilizing the confidence information. Then we define "strong redundant rule" and "strong redundant itemset Confidence 1.0 2 3 4 The number of items Figure 2. Conceptual Diagram of Pruning Method Definition 2: Let X ? Y be a fuzzy association rule, where X and Yare fuzzy item sets. Let Q be Q = 2 x - X If min\(ConJ\(Z ?Y X ?Y ZEQ X ? Y strong redundant rule Let k-rule denote the rule that has k attributes\(items consequent part, and the "subset rule" denote that itemset corresponding to the rule is subset of the item set of larger rule and the consequent parts of both rules are the same set Definition 3: Let Z be a fuzzy itemset that has k items\( k>2 When all the k-rules generated from Z are strong redundant, we call the itemset Z strong redundant itemset Fig.2 shows the concept of strong redundant rule and strong redundant itemset. Since the Apriori algorithm generates the candidate itemsets in tum from l-itemsets, the pruning based 


on the redundancy should be performed simultaneously In addition to the basic Apriori algorithm, the following procedures are employed for k> I as A4 confidence of k-rule based on Lk and Lk.j AS The concept of the procedure is that the confidence value of rule should increase by increasing the number of antecedent items. In other words, the procedure is based on valid heuristics that the combination of items in antecedent part which deteriorates the confidence value will become redundant in the following iterations. We can expect reduction of computational time and redundant rules pruning by the additional procedures It should be noted that the confidence calculation in each iteration does not lead to the increase of overall calculation time in association rules mining v. NUMERICAL EXAMPLES We develop the fuzzy mining system based on the redundancy pruning and evaluate the proposed algorithms through numerical examples. We apply the system to "abalone data" available from the vcr Machine Learning Repository[7 The abalone data set consists of 4177 measured data with 1 nominal attribute and 8 continuous attributes as shown in 71 Table. I. In the experiments, the nominal attribute is transformed to the continuous attribute. Table 2\(a statistics and the fuzzy partition information of attributes are summarized in Table 2\(b wider than the actual data distribution for performance evaluation. The fuzzy partition example is shown in Fig.3. We use two types of fuzzy sets with different width, i.e. triangle type and trapezoid type. Although it is better to use the factor such as "interesting" for pruning the derived rules in addition we apply the native association rule extraction for proposed algorithm evaluation. The minimal support is set as 0.2 Table.l. Abalone Data No Input Output xl x2 x3 x4 x5 x6 x7 x8 y I 00.455 0.365 0.095 0.5140 0.2245 0.1010 0.150 15 2 00.350 0.265 0.090 0.2255 0.09 95 0.0485 0.070 7 3 2 0.530 0.420 0.135 0.6770 0.2565 0.1415 0.210 9 


4177 010710 0.555101 9511948510 9455 0.3765 10.4 95 1 12 Table.2. Statistical Information and Fuzzy Sets Settings a xl x2 x3 x4 x5 x6 x7 x8 y Min 0 0.075 0.055 0.00 0.002 0.001 0.001 0.002 I Max 2 0.815 0.650 1.13 2.826 1.488 0.760 1.005 29 b xl x2 x3 x4 x5 x6 x7 x8 y Mininum center of 0 0 0 0 0 0 0 0 0 fuzzy set Maximum center of fuzzy set 2 2 2 5 5 2 2 2 30 Number of 3 II II II II II II II 16 partitions Membersh ip Value Lk Di- X2 Membership V 0.0 2.0 Figure 3 Example of Fuzzy Partition 12000 10000 8000 6000 4000 2000 40 en d en E 30  25 0:; 20 0 15 \(1 n 


E 10 s c 1 fr/l 60000 2 s 0 50000 l ro 40000  l 4-; 30000 0 l D 20000 E s s:: 10000 <l s f0 0.7 Itemset Size Figure 4. Results by Apriori Algorithm Candidate Frequent 4 6 The number of itemsets Figure 5. Results by the Proposed Algorithm Extracted Rules Non-Redunda nt Rules 0.75 0.8 0.85 0.9 0.95 Min imal Confidence\(Threshold Figure 6. The number of extracted rules by the conventional algorithm 9 The results by standard Apriori algorithm for fuzzy association rules mining are shown in Fig.4. At around 4th item set calculation, much waste computation is fulfilled. From the results, it can be seen that the waste computation should be reduced 72 250 


Vl 200 0 <I Q d 0 0 .... 100 <I D E ::: 50 I  f0 Deleted Non-Redundant Rules ___ Deleted Rules r 0.7 0.75 0.8 0.85 0.9 0.95 Minimal Confidence\(Threshold Figure 7. The number of deleted rules by the proposed algorithm Fig.5 shows the results of reduction of itemsets by the proposed algorithm. We can see that fair itemsets are pruned by the proposed method. Fig.6 shows the number of extracted rules by the conventional Apriori algorithm. Many redundant rules are extracted as well as the necessary non-redundant rules Our issue is to restrain the extraction of redundant rules. Fig.7 shows the results of the number of deleted rules by the proposed algorithm. Some redundant rules are deleted simultaneously along with frequent itemsets extraction However, since a few non-redundant rules are also unexpectedly deleted at the lower threshold value of minimal confidence, we have to investigate further about heuristics, i.e strong redundant itemsts and relation of threshold values. It should be noted that the number of deleted rules has less dependence on the minimal confidence These results are promising in terms of computational time and redundant rules pruning. However, the improvement is limited in terms of computational time. We consider that the performance of the proposed method must be improved by applying the output field specification method[17]. We expect that the number of pruned rules becomes larger based on the specifications. Moreover, the other measures to prevent redundant rules extraction in fuzzy association rules mining 


could be applied as well as the proposed algorithm VI. CONCLUSION In this paper, we proposed a basic algorithm based on the Apriori algorithm for rule extraction utilizing redundancy of the extracted rules, in order to improve the efficiency of the association rules mining and to prune the redundant rules extracted. We also proved the redundancy defmition of the rule based on the CF\(certainty factor algorithm was evaluated through numerical experiments using benchmark data, "Abalone". From the results, the method was found to be promising in terms of computational time and redundant rule pruning. Our future plan includes sophistication of the proposed algorithm, application to the huge data mining problem, and further improvement of fuzzy association rules mining REFERENCES I] R. Srikant and R. Agrawal, "Mining Generalized Association Rules Proc. of the 21" VLDB Conf, pp.407-419, 1995 2] R. Srikant and R. Agrawal, "Mining Quantitative Association Rules in Large Relational Tables," Proc. of the ACM Corif. on Management of the Data, pp.I-12, 1996 3] G. Chen and Q. Wei, "Fuzzy Association Rules and the Extended Mining Algorithms," Iriformation Sciences, Vo1.l47, pp.20 1-228, 2002 4] H. Ishibuchi H. and T. Yamamoto, "Fuzzy Rule Selection by Data Mining Criteria and Genetic Algorithms," Proc. of Genetic and Evolutionary Computation Coriference, pp. 399-406, 2002 5] Y. Hu, R. Chen, and G. Tzeng, "Discovering Fuzzy Association Rules Using Fuzzy Partition Methods," Knowledge-Based Systems, Vol. 16 pp.137-147,2003 6] T. Watanabe and N. Nakayama, "Fuzzy Rule Extraction Based on the Mining Generalized Association Rules," Proc. of the 2003 IEEE Int Conf on Syst., Man, and Cybern., pp.2690-2695, 2003 7] UCI Machine Learning Repository: http://www ics.uci.edu/-mlearnIMLRepository.html 8] T. Watanabe, A. Kitamura, K. Higuchi, and H. Ikeda, "Intelligent Manufacturing Techniques for Quality and Process Design of Steel Plate," 2003 IEEE International Coriference on Emerging Technologies and Factory Automation Proceedings, Vol.2, pp.596-601, 2003 9] S. Shankar and T. Purusothaman, "Utility Sentient Frequent Itemset Mining and Association Rule Mining: A Literature Survey and Comparative Study," International Journal of Soft Computing Applications, Issue 4, pp.81-95, 2009 


10] M. Delgado, N. Marin, D. Sanchez, and M.-A. Vila, "Fuzzy Association Rules: General Model and Applications," IEEE Trans. on Fuzzy Systems VoU I, No.2, pp.214-225, 2003 II] M. Delgado, N. Marin, M. J. Martin-Bautista, D. Sanchez, and M.-A Vila, "Mining Fuzzy Association Rules: An Overview," Studies in Fuzziness and Soft Computing, Springer, VoU64/2005, pp.351-373 2006 12] H. Verlinde, M. De Cock, and R. Boute, "Fuzzy Versus Quantitative Association Rules: A Fair Data-Driven Comparison," IEEE Trans. on System, Man, and Cybernetics, Part B, Vol.36, No.3, pp.679-684, 2006 13] E. Hullermeier and Y. Yi, "In Defense of Fuzzy Association Analysis IEEE Trans. on System, Man, and Cybernetics, Part B, Vol.37, No.4 pp.1039-1043,2007 14] Y. C. Lee, T. P. Hong, and T. C. Wang, "Mining Fuzzy Multiple-level Association Rules under Multiple Minimum Supports," Proc. of the 2006 IEEE International Conference on Systems, Man, and Cybernetics pp.4112-4117,2006 15] A. Mangalampalli and V. Pudi, "Fuzzy Association Rule Mining Algorithm for Fast and Efficient Performance on Very Large Datasets Proc. of the 2009 IEEE International Coriference on Fuzzy Systems pp.1163-1168,2009 16] Y. Xu, Y. Li, and G. Shaw, "Concise Representations for Approximate Association Rules," Proc. of the 2008 IEEE International Coriference on Systems, Man, and Cybernetics, pp.94-IOI, 2008 17] T. Watanabe, "Mining Fuzzy Association Rules of Specified Output Field ", Proc. of the 2004 IEEE Int. Corif. on Syst., Man, and Cybern pp.5754-5759,2004 73 


General Chair f!!\f  Organizing Chairs  f!!\f  f$% \f!!\f  Organizing Co-chairs f    f  f\f   f\f\f   f*!\f!\f.\f  f f  Program Committee Chairs  f\f\f   f!!\f  Publication Chair 0   


200 250 300  The size of dataset/10,000 R es po ns e tim e S    a 0 50 100 150 200  The size of dataset/10,000 R es po ns e tim e S    b 0 10 20 30 40 50 


60  The size of dataset/30,000 R es po ns e tim e S    c Fig. 9 The scalability of our algorithm compared with FP-growth  Paper [12] proposed a way to reduce times of scanning transaction database to reduce the cost of I/O IV. CONCLUSIONS AND FUTURE WORK This paper first discusses the theory of foundations and association rules and presents an association rules mining algorithm, namely, FP-growth algorithm. And then we propose an improved algorithm IFP-growth based on many association rules mining algorithms. At last we implement the algorithm we propose and compare it with algorithm FPgrowth algorithm. The experimental evaluation demonstrates its scalability is much better than algorithm FP-growth 177 Now, lets forecast something we want to do someday Firstly, we would parallelize our algorithm, because data mining needs massive computation, and a parallelable environment could high improve the performance of the algorithm; Secondly, we would apply our algorithm on much more datasets and study the run performance; At last, we would study the performance when the algorithm deal with other kinds of association rules  REFERENCES 1] S. Sumathi and S. N. Sivanandam. Introduction to Data Mining and its Applications, Springer, 2006 2] V. J. Hodge, J. Austin, A survey of outlier detection 


methodologies, Artificial Intelligence Review, 2004, 22 85-126 3] Han, J. and M. Kamber. Data Mining: Concepts and Techniques. Morgan Kaufmann, San. Francisco, 2000 4] Jianchao Han, Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases, Journal of Advanced Computational Intelligence and Intelligent Informatics 2006, 10\(3 5] Jiuyong Li, Hong Shen, Rodney Topor. Mining Informative Rule Set for Prediction. Journal of Intelligent Information Systems, 2004, 22\(2 6] Jianchao Han, and Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases. Journal of Advanced Computational Intelligence, 2006, 10\(3 7] Doug Burdick, Manuel Calimlim, Jason Flannick Johannes Gehrke, Tomi Yiu. MAFIA: A Maximal Frequent Itemset Algorithm. IEEE Transactions on Knowledge and Data Engineering, 2005, 17\(11 1504 8] Assaf Schuster, Ran Wolff, Dan Trock. A highperformance distributed algorithm for mining association rules. Knowledge and Information Systems, 2005, 7\(4 458-475 9] Mohammed J. Zaki. Mining Non-Redundant Association Rules. 2004, 9\(3 10] J.Han, J.Pei, Y.Yin, Mining frequent patterns without candidate generation, Proceedings ACM SIGMOD 2000 Dallas, TX, May 2000: 1-12 11] P.Viola, M.Jones. Rapid Object Detection Using A Boosted Cascade of Simple Features. Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 2001 12] Anthony K. H. Tung, Hongjun Lu, Jiawei Han, Ling FengJan. Efficient Mining of Intertransaction Association Rules. 2003, 154\(1 178 


For each vertex b in g form j forests body\(a, g, i s.t. bodyAnt\(a, g, i a, g, i with itemsets Ant\(b b and each subset of itemsets Ant\(b b in P\(a, g, j Assign to each leaf l of trees bodyAnt\(a, g, i bodyCons\(a, g, i a fresh variable Vm,M, m, M = size\(itemset\(l Assign to each leaf l of tree headAnt\(a, g, j the variable assigned to itemset l in some leaf of some tree bodyCons\(a, g, i TABLE II.  EXPERIMENTAL DATA Conf. #rules #pruned #dftrs PtC 0.5 6604 2985 1114 0.6 2697 2081 25 0.75 1867 1606 10 0.8 1266 1176 0 0.95 892 866 1 0.98 705 699 1 DSP 0.5 2473 1168 268 0.6 1696 869 64 0.75 1509 844 89 0.8 1290 1030 29 0.95 1032 889 15 0.98 759 723 1 Arry 0.5 770 492 82 0.6 520 353 60 0.75 472 327 39 0.8 408 287 22 0.95 361 255 25 0.98 314 243 30  Our induction algorithm has been launched for each combination of thresholds. Our scheme eliminates all redundant rules in the sense of [25, 31], i.e. those association rules that are not in the covers. All the meta-rule deductive schemes implicitly included in [25] and [31] are induced by our method. The percentage of pruning, thus, outperforms [25 


The results produced for k=3, support 0.25 and confidences between 0.7 and 0.99 are shown in Fig. 3, in terms of pruning percentage \(vertical axis when applied to low confidences \(from 0.7 to 0.9 The percentage of pruning achieved diminishes as the confidence is superior to 0.9. Nevertheless, the pruning is effective with confidence of 0.99 in the majority of cases Pruning at Support = 0.25 0,00 5,00 10,00 15,00 20,00 25,00 30,00 35,00 40,00 45,00 50,00 0,7 0,8 0,9 0,95 0,99 Confidence P ru n in g L e v e l Case 1 Case 2 Case 3  Figure 3.  Pruning experiences at support 0.25  V. DISCUSSION AND CHALLENGES It is important to discuss the technique presented here with focus on the purpose the technique pursues:  to produce semantic recommendation The reader should have noticed that the algorithm presented 


relies strongly on "choice". For instance, the algorithm chooses ears in the graph to form an order for elimination, and the choice is arbitrary. This strategy is essential to maintain low complexity \(polynomial practical. Nevertheless, a warned reader may conclude that this arbitrary choice implies that there are many compactions to produce and therefore the approach as a whole does not show to produce an optimal solution. And the reader is right in this conclusion. Since the goal is compaction, the search for an optimal solution can be bypassed provided a substantial level of pruning is achieved To complete the whole view, we describe how web service descriptions are complemented with the association rules as recommendations. In effect, under our scheme, the document describing the web service is augmented with a set of OWL/RDF/S triples that only incorporate the non-pruned rules with the format of Example 1, that is, the set ARmin of the compaction program obtained by our algorithm, together with the thresholds applied to the mining process and a registered URI of a registered description service. The assumptions and defeaters are not added to the web service description. If the associations encoded in the triples are not sufficient for the client \(a search engine, for instance widening of the response to the description service identified by the given URI, and then the assumptions and defeaters are produced. The reasoning task required for deriving all the implicitly published rules is client responsibility Notice that, under this scheme, the actual rules that appear as members of the set initial ARmin set are irrelevant; the only important issue is the size of the set The developed scheme also supports an extension of the algorithm that admits the assignment of priorities to rules and to itemsets, in order to allow the user to produce a more controlled program as output. Nonetheless, the importance of the extension has not been already tested, and therefore it is beyond the subject of the present paper It would be also interesting to design a scheme that supports queries where the client provides an itemset class and values for support and confidence and the engine produces a maximal class of inferred associated itemsets as a response. This scheme is also under development, so we have not discussed this aspect here 


VI. CONCLUSION In this paper, we have presented a defeasible logic framework for managing associations that helps in reducing the number of rules found in a set of discovered associations. We have presented an induction algorithm for inducing programs in our logic, made of assumption schemas, a reduced set of association rules and a set of counter-arguments to conclusions called defeaters, guaranteeing that every pruned rule can be effectively inferred from the output. Our approach outperform those of [17], because all reduction compactions presented there can be expressed and induced in our framework, and several other patterns, particular to the given datasets, can also be found. In addition, since a set of definite clauses can be obtained from the induced programs, the knowledge obtained can be modularly inserted in a richer inference engine Abduction can be also attempted, asking for justifications that explain the presence of certain association in the dataset The framework presented can be extended in several ways Admitting defeaters to appear in the head of assumption, to define user interest Admitting arithmetic expressions within assumptions for adjustment in pruning Admitting set formation patterns as itemset constants Extending the scope, to cover temporal association rules REFERENCES 1]  R. Agrawal, and R. Srikant: Fast algorithms for mining association rules In Proc. Intl Conf. Very Large Databases. \(1994 2]  A. V. Aho, J. E. Hopcroft, J. Ullman. The design and analysis of computer algorithms, Addison-Wesley, 1974 3]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher, A. Rock: A Family of Defeasible Reasoning Logics and its Implementation. ECAI 2000: 459-463 4]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher: Representation results for defeasible logic. ACM Trans. Comput. Log. 2\(2 2001 5]  A. Basel, A. Mahafzah, M. Al-Badarneh: A new sampling technique for association rule mining, Journal of Information Science, Vol. 35, No. 3 358-376 \(2009 6]  R. Bayardo and R. Agrawal: Mining the Most Interesting Rules. In Proc of the Fifth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 145-154, \(1999 


7]  R. Bayardo, R. Agrawal, and D. Gunopulos: Constraint-based Rule Mining in Large, Dense Databases. Data Mining and Knowledge Discovery Journal, Vol. 4, Num-bers 2/3, 217-240. \(2000 8]  A. Berrado, G. Runger: Using metarules to organize and group discovered association rules. Data Mining and Knowledge Discovery Vol 14, Issue 3. \(2007 9]  S. Brin, R. Motwani, J. Ullman, and S. Tsur: Dynamic itemset counting and implication rules for market basket analysis. In Proc. ACMSIGMOD Intl Conf. Management of Data. \(1997 10] L. Cristofor and D.Simovici: Generating an nformative Cover for Association Rules. In ICDM 2002, Maebashi City, Japan. \(2002 11] Y. Fu and J. Han: Meta-rule Guided Mining of association rules in relational databases. In Proc. Intl Workshop on Knowledge Discovery and Deductive and Object-Oriented Databases. \(1995 12] B. Goethals, E. Hoekx, J. Van den Bussche: Mining tree queries in a graph. KDD: 61-69. \(2005 13] G. Governatori, D. H. Pham, S. Raboczi, A. Newman and S. Takur: On Extending RuleML for Modal Defeasible Logic. RuleML, LNCS 5321 89-103. \(2008  14] G. Governatori and A. Stranieri. Towards the application of association rules for defeasible rules discovery In Legal Knowledge and Information Systems, JURIX, IOS Press, 63-75. \(2001 15] J. Han, J. Pei and Y. Yin: Mining frequent patterns without candidate generation. In Proc. ACM-SIGMOD Intl Conf. Management of Data 2000 16] C. Hbert, B. Crmilleux: Optimized Rule Mining Through a Unified Framework for Interestingness Measures. DaWaK: LNCS 4081, 238247. \(2006 17] E. Hoekx, J. Van den Bussche: Mining for Tree-Query Associations in a Graph. ICDM 2006: 254-264 18] R. Huebner: Diversity-Based Interestingness Measures For Association Rule Mining. Proceedings of ASBBS Volume 16 Number 1, \(2009 19] B. Johnston, Guido Governatori: An algorithm for the induction of defeasible logic theories from databases. Proceedings of the 14th Australasian Database Conference, 75-83. \(2003 20] P. Kazienko: Mining Indirect Association Rules For Web Recommendation. Int. J. Appl. Math. Comput. Sci., Vol. 19, No. 1, 165 186. \(2009 21] M. Klemettinen, H. Mannila, P. Ronkainen, H. Toivonen, and A Verkamo: Finding interesting rules from large sets of discovered association rules. In Proc. 3rd Intl Conf. on Information and Knowledge 


Management. \(1994 22] M. J. Maher, A. Rock, G. Antoniou, D. Billington, T. Miller: Efficient Defeasible Reasoning Systems. International Journal on Artificial Intelligence Tools 10\(4 2001 23] C. Marinica, F. Guillet, and H. Briand: Post-Processing of Discovered Association Rules Using Ontologies. The Second International Workshop on Domain Driven Data Mining, Pisa, Italy \(2008 24] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal: Closed sets based discovery of small covers for association rules. In Proc. BDA'99 Conference, 361-381 \(1999 25] N. Pasquier, R. Taouil, I. Bastide, G. Stume, and  L. Lakhal: Generating a Condensed Representation for Association Rules. In Journal of Intelligent Information Systems, 24:1, 29-60 \(2005 26] P. Pothipruk, G. Governatori: ALE Defeasible Description Logic Australian Conference on Artificial Intelligence.  110-119 \(2006 27] J. Sandvig, B. Mobasher Robustness of collaborative recommendation based on association rule mining, Proceedings of the ACM Conference on Recommender Systems \(2007 28] W. Shen, K. Ong, B. Mitbander, and C. Zaniolo: Metaqueries for data mining. In Fayaad, U. et al. Eds. Advances in Knowledge Discovery and Data Mining. \(1996 29] I. Song, G. Governatori: Nested Rules in Defeasible Logic. RuleML LNCS 3791, 204-208 \(2005 30] H. Toivonen, M. Klemettinen, P. Ronkainer, K. Hatonen, and H Mannila: Pruning and grouping discovered association rules. In ECML Workshop on Statistics, Machine Learning and KDD. \(1995 31] M. Zaki: Generating Non-Redundant Association Rules. In Proc. of the Sixth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 34-43, \(2000 32] w3c. OWL Ontology Web Language Reference. In http://www.w3.org/TR/2004/REC-owl-ref-20040210 33] w3c. RDF/XML Syntax Specification. In: http://www.w3.org/TR/rdfsyntax-grammar 34] w3c. RDF Schema. In: http://www.w3.org/TR/rdf-schema      


 8   2  3\f            8  D    F  \b 1 8 & #J      b 1  1  4    2  


4 1    9  E 1  2 4 1    9 1   4      8 2  8 1  D 1        1 1  b 


     b b b b b  K            8          2 D 9   F  \b 1 8 ,+J  9 


     b 1     1 2  9 1  12 L 1   9  8       1  2      2   


     b b b b b  K            2  0 \b f  b\f      9       


  8 2   E 1   1     M13 31L 1    b  8E 1   1 #3\b?### 1  1     E 1   1 \b?###3        


1   1   b 1  2 2 18 2     8              1    2 \b 1    2  


    2          2   1 L 2 1   1   L 2 2    2 1  2        


    8  2H D \b A             2  2H D \b A 2 \f 3%\f  f   4%\f f !  , \f\b  C    2    2 


 6    3 1      253 6   1 L 2    6   1         f\b3\f       


               1     1     8 2    E       2  1   


     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



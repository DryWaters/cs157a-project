  
   
  
    
 
 


0003\000\031\000 000P\000è\000ã\000j\000~\000o\000Ö\000 000R\000 000i 000ë\000o\000 000o\000à\000ë\000 0000\000H\000l\000 000G 000 000ô\000w\000x 000\013\000 000w\000Å\000\013\000 000\031\000\031\000\031\000 000\013\000 000w\000â\000õ\000 000D\000H\000 000C\000 000k\000H\000l\000 000e\000I\000 000à\000 000G\000Y\000k\000l\000Y\000c\000F\000l\000 000`\000Y\000l\000H\000h\000C\000`\000k\000 000F\000C\000`\000_\000H\000G\000 000f\000e\000k\000Y\000l\000Y\000r\000H\000 000Y\000l\000H\000a\000k\000\005\000 000O\0001\000ô\000 000†\000w 000\010\000\013\000 000†\000w 000 000\002\000 000\031\000\031\000\031\000 000\013\000 000†\000w\000Ñ\000õ\000 000E\000H\000 000C\000 000k\000H\000l\000 000e\000I\000 000.\000\002\000k\000 000F\000e\000h\000h\000H\000k\000f\000e\000c\000G\000Y\000c\000U\000 000c\000e\000c\000\010\000e\000F\000F\000p\000h\000h\000Y\000c\000U\000 000Y\000l\000H\000a\000k\000 000F\000C\000_\000_\000H\000G\000 000c\000H\000U\000C\000l\000Y\000r\000H\000 000Y\000l\000H\000a\000k\000\011\000 000w\000\010\000 000Y\000k\000 000F\000C\000_\000_\000H\000G\000 000l\000W\000H\000  000N\000,\000S\000Y\000I\0007\000S\000f 000e\000I\000 000†\000w 000h 000\014\000 000C\000c\000G\000 000†\000w\000x\000 000Y\000k\000 000F\000C\000_\000_\000H\000G\000 000l\000W\000H\000  000N\000,\000S\000Y\000I\0007\000S\000f 000e\000I\000 000w\000x 000ü\000 000Y\000 000Y\000k\000 000C\000 000l\000h\000C\000c\000k\000C\000F\000l\000Y\000e\000c\000 000G\000C\000l\000C\000D\000C\000k\000H\000 000e\000I\000 000r\000C\000h\000Y\000C\000D\000_\000H\000\010\000_\000H\000c\000U\000l\000W\000 000l\000h\000C\000c\000k\000C\000F\000l\000Y\000e\000c\000k\000 000e\000r\000H\000h\000 000!\000\002\000B 000C\000c\000G\000 000l\000W\000H\000 000c\000p\000a\000E\000H\000h\000 000e\000I\000 000l\000h\000C\000c\000k\000C\000F\000l\000Y\000e\000c\000k\000 000Y\000c\000 000V\0008\000 000Y\000k\000 000G\000H\000c\000e\000l\000H\000G\000 000C\000k\000 000$\000C\000F\000W\000 000l\000h\000C\000c\000k\000C\000F\000l\000Y\000e\000c\000 000F\000e\000c\000l\000C\000Y\000c\000k\000 000C\000 000k\000H\000l\000 000e\000I\000 000[\000l\000H\000a\000 000w\000x 000\016\000 000w\000Å\000\016\000 000\034\000\034\000\034\000 000\016\000w\000 000;\000 000!\000B 000C\000c\000G\000 000H\000C\000F\000W\000 000l\000h\000C\000c\000k\000C\000F\000l\000[\000e\000c\000 000[\000k\000 000C\000k\000k\000e\000F\000Y\000C\000l\000H\000G\000 000s\000Y\000l\000W\000 000C\000 000p\000c\000Y\000g\000p\000H\000 000Y\000G\000H\000c\000l\000Y\000O\000H\000h\000 000Z\0008 000\033\000 000\034\000 000k\000H\000l\000 000e\000I\000 000G\000Y\000k\000l\000Y\000c\000F\000l\000 000Y\000l\000H\000a\000k\000 000Q\000e\000a\000 000s\000í\000J\000s\000 000Y\000k\000 000F\000C\000_\000_\000H\000G\000 000C\000c\000 000A\000Y\0007\000F\000V\0007\000Y\000\021\000f 000:\000W\000H\000 000c\000p\000a\000E\000H\000h\000 000e\000I\000 000Y\000l\000H\000a\000k\000 000Y\000c\000 000C\000c\000 000Y\000l\000H\000a\000k\000H\000l\000 000\035\000 000Y\000k\000 000l\000W\000H\000 000`\000H\000c\000U\000l\000W\000 000e\000I\000 000l\000W\000H\000 000Y\000l\000H\000a\000 000k\000H\000l\000\005\000 000G\000H\000c\000e\000l\000H\000G\000 000D\000w\000 000~\000o\000à\000u\000ë\000v\000\006\0002 000\007\000\033\000 000\034\000c\000 000Y\000l\000H\000a\000k\000H\000l\000 000e\000I\000 000_\000H\000c\000U\000l\000W\000 000^\000 000C\000h\000H\000 000h\000H\000I\000H\000h\000h\000H\000G\000 000l\000e\000 000C\000k\000 000^\000\010\000Y\000l\000H\000a\000k\000H\000l\000\011\000 000#\000C\000F\000X\000 000Y\000l\000H\000a\000 000k\000H\000l\000 000W\000C\000k\000 000C\000c\000 000C\000k\000k\000e\000F\000Y\000C\000l\000H\000G\000 000k\000l\000C\000l\000Y\000k\000l\000Y\000F\000C\000_\000 000a\000H\000C\000k\000p\000h\000H\000 000F\000C\000_\000_\000H\000G\000 000k\000p\000f\000f\000e\000h\000l\000\005\000 000G\000H\000c\000e\000l\000H\000G\000 000E\000w\000 000ê\000\033\000 000&\000e\000h\000 000C\000c\000 000Y\000l\000H\000a\000k\000H\000l\000 000\035\000\007\000 000ê\000\005 0002 000\007\000 0002 000\033 000l\000ã\000ì\000à\000ë\000 000\036\000B\000V\0008\000B\000\013\000 000s\000W\000H\000h\000H\000 0002 000\033 000l\000ã\000ì\000à\000ë\000 000Y\000k\000 000l\000X\000H\000 000c\000p\000a\000D\000H\000h\000 000e\000I\000 000l\000h\000C\000c\000k\000C\000F\000l\000Y\000e\000c\000k\000 000F\000e\000c\000l\000C\000Y\000c\000Y\000c\000U\000 000Y\000l\000H\000a\000 000k\000H\000l\000k\000 000\035\000 000Y\000c\000 000Y 000\033\000 000:\000e\000 000Y\000l\000H\000a\000k\000H\000l\000k\000 000\035\000 000C\000c\000G\000 000C\000 000a\000Y\000c\000Y\000a\000p\000a\000 000k\000p\000f\000f\000e\000h\000l\000 000 000 000\014\000 000\005\000 \000\007\000 000Y\000I\000 000\035\000 000e\000c\000_\000w\000 000F\000e\000c\000l\000C\000Y\000c\000k\000 000f\000e\000k\000Y\000l\000Y\000r\000H\000 000Y\000l\000H\000a\000k\000 000C\000c\000G\000 000 000q\0002 000\007\000 000A\000B 000 000 000\014\000 000l\000W\000H\000c\000 000\034\000 000Y\000k\000 000F\000C\000_\000_\000H\000G\000 000C\000 0006\000%\000*\0009\000\005\000 000C\000c\000G\000 000\001 000\020 000\006\000 000Y\000I\000 000\035\000 000F\000e\000c\000l\000C\000Y\000c\000k\000 000c\000H\000U\000C\000l\000Y\000r\000H\000 000Y\000l\000H\000a\000k\000 000C\000c\000G\000 000ê\000p 0002 000\007\000 000A\000B 000 000 000\014\000 000l\000W\000H\000c\000 000\034\000~\000Y\000k\000 000F\000C\000_\000_\000H\000G\000 000C\000 0003\000&\000 000\033\000B 000A\000o\000à\000o\000 000i 000ë\000o\000 000M\000y\000è\000ã\000Ö\000 000P\000@\000 000*\000c\000 000e\000h\000G\000H\000h\000 000l\000e\000 000U\000H\000c\000H\000h\000C\000l\000H\000 000C\000`\000_\000 000c\000e\000c\000\010\000h\000H\000G\000p\000c\000G\000C\000c\000l\000 000c\000H\000U\000C\000l\000Y\000r\000H\000 000F\000C\000c\000G\000Y\000G\000C\000l\000H\000 000Y\000l\000H\000a\000k\000H\000l\000k\000 000Q\000e\000a\000 000Q\000<\000C\000T 000\014\000 000s\000H\000 000G\000H\000k\000Y\000U\000c\000 000C\000c\000 000H\000I\000O\000F\000Y\000H\000c\000l\000 000a\000H\000l\000W\000e\000G\000 000l\000e\000 000U\000H\000c\000H\000h\000C\000l\000H\000 0003\0009\000 000 000U\000H\000c\000H\000h\000C\000_\000 000Y\000G\000H\000C\000 000Y\000k\000 000l\000e\000 000F\000W\000C\000c\000U\000H\000 000C\000c\000w\000 000f\000e\000k\000Y\000l\000Y\000r\000H\000 000Y\000l\000H\000a\000k\000 000w\000 000Y\000c\000 000C\000 0006\000%\000*\0009\000 000l\000e\000 000Y\000l\000k\000 000c\000H\000U\000C\000l\000Y\000r\000H\000 000f\000C\000h\000l\000c\000H\000h\000\011\000 000%\000e\000h\000a\000C\000`\000_\000w\000\005\000 000%\000e\000h\000 000C\000 000^\000z 000Y\000l\000H\000a\000k\000H\000l\000 0006\000%\000*\0009\000\005\000 000Y\000l\000k\000 0002\000 \000,\0009\000 000C\000h\000H\000 000U\000H\000c\000H\000h\000C\000l\000H\000G\000 000E\000w\000 000F\000X\000C\000c\000U\000Y\000c\000U\000 000C\000c\000w\000 000Ö\000 000G\000Y\000k\000l\000[\000c\000F\000l\000 000[\000l\000H\000a 000\001 000k 000\006\000 000l\000e\000 000[\000l\000k\000 000\001 000l\000W\000H\000[\000i 000\006\000 000c\000H\000U\000C\000l\000[\000r\000H\000 000f\000C\000h\000l\000c\000H\000h 000\001 000k 000\006 000\005\000 000 000 000D\000\014\000%\000\014\000 000\032\000\032\000\032\000§\000\014 000^\000\010 000!\000\032\000 000>\000H\000 000G\000e\000c\000\002\000l\000 000U\000H\000c\000H\000h\000C\000l\000H\000 000o\000X\000H\000 0002\000 \000,\0009\000 000e\000I\000 000C\000 0006\000%\000*\0009\000 000s\000X\000H\000c\000 000 000/\000{\000 000\005 000}\000D 000\007\000 000E\000H\000F\000C\000p\000k\000H\000 000s\000H\000 000G\000e\000c\000\002\000l\000  000l\000W\000Y\000k\000  000e\000I 0003\000 \000 000C\000h\000H\000 000a\000H\000C\000c\000Y\000c\000U\000T\000_\000\011\000 000#\000`\000,\000F\000N\000C\0007 000\020\000f 000:\000e\000 000 000\023 000Y\000l\000H\000a\000k\000H\000l\000 000\005 000i\000j\000l 000\007 000\014\000 000Y\000l\000k\000 0002\000 \000,\0009\000 000Y\000c\000F\000`\000p\000G\000H\000\030\000 000\005 000 000i\000j\000l 000\007 000\014 000\005 000i 000†\000j\000l 000\007 000\014 000\005 000i\000j\000†\000l 000\007 000\014\000 000s\000W\000H\000c\000 000 000 000\000-\000 000\005 000i\000†\000j\000†\000l 000\007 000\014\000 000\005 000 000i\000j\000†\000l 000\007 000\014\000 000\005 000 000i\000†\000j\000l 000\007 000\014\000 000s\000X\000H\000c\000 000 000 000 000\033\000 0004\000E\000r\000Y\000e\000p\000k\000`\000w\000\005\000 000s\000H\000 000F\000C\000c\000 000p\000k\000H\000 000l\000W\000Y\000k\000 000a\000H\000l\000X\000e\000G\000 000l\000e\000 000U\000H\000c\000H\000h\000C\000l\000H\000 000C\000_\000_\000 000Q\000e\000a\000 000C\000_\000_\000 000Q\000<\000C\000T\000 000C\000c\000G\000 000l\000W\000Y\000k\000 000a\000H\000l\000W\000e\000G\000 000F\000C\000c\000\002\000l\000 000U\000H\000c\000H\000h\000C\000l\000H\000 000h\000H\000G\000p\000c\000G\000C\000c\000l\000 0003\000 \000 000s\000W\000Y\000_\000H\000 000C\000c\000  000s\000C\000w\000 000F\000C\000c\000\011\000 000\034\000\006\000B 0005\000i\000~\000l\000ì\000~\000i\000ë\000o\000 000ë\000v\000o\000 000R\000ì\000å\000å\000ã\000è\000ë\000 000ã\000y\000 000M\000 000C\000ä\000 000f 000 000g 000\014\000 000l\000W\000H\000 000C\000p\000l\000W\000e\000h\000k\000 000U\000C\000r\000H\000 000k\000e\000a\000H\000 000H\000g\000p\000C\000l\000Y\000e\000c\000k\000 000l\000e\000 000F\000C\000_\000F\000p\000_\000C\000l\000H\000 000l\000W\000H\000 000k\000p\000f\000f\000e\000h\000l\000 000e\000I\000 000C\000c\000 000Y\000l\000H\000a\000k\000H\000l\000k\000 000F\000e\000c\000l\000C\000Y\000c\000Y\000c\000U\000 000c\000H\000U\000C\000l\000Y\000r\000H\000 000Y\000l\000H\000a\000k\000\011\000 000:\000X\000H\000 000E\000C\000k\000Y\000F\000 000Y\000G\000H\000C\000 000e\000I\000 000H\000g\000p\000C\000l\000Y\000e\000c\000 000\037\000B 000Y\000k\000 000l\000W\000H\000 000Y\000c\000F\000_\000p\000k\000Y\000e\000c\000\010\000H\000u\000F\000`\000p\000k\000Y\000e\000c\000 000f\000h\000Y\000c\000F\000Y\000f\000_\000H\000 000Y\000c\000 000k\000H\000l\000 000l\000W\000H\000e\000h\000w\000\011\000 000'\000Y\000r\000H\000c\000 000?\000 000 000ô\000 000\010\000\013\000 000 000#\000\013\000 000\033\000\033\000\033\000 000\014 000[\000 000õ\000\013\000 000 000|\000 000s\000 000\005\000 000 000E 000\014\000%\000\014\000 000\033\000\033\000\033\000 000 000\007 000\014\000 000`\000 000/\000 000 000ò\000I 000\013 000a\000 000\013\000 000\033\000\033\000 000 000\014 000a\000 000õ\000\014\000 000Y\000\011\000H\000\011\000\005\000 000 000b\000é\000 000/\000 000 000c\000h 000\003 000 000a 000 000\003\000\001\000 000\033 000\014 000c\000 000õ\000\014\000 000a 000|\000;\000 000!\000B 000\005\000{\000 000 \000 000\005\000\020\000\005\000 000\031\000\031\000\031\000 000\010\000P\000\003\000\010\000f 000l\000W\000H\000c\000 000 000\006 000^\000¢\000e 000\007\000/\000 000S 000\006 000^\000d 000h 000\014 000c 000 000\014\000 000\033\000\033\000\033\000 000\014 000c 000 000\007\000 000/\000 000\005\000 000\007\000\023 000\006 000\007 000\002\000\010 000\011 000\012\000\013\000\003\000\004\000\014 000\006\000\014 000\015\000\016 000\002\000\010 000\011\000\014 000\001\000\007\000\016 000\011 000\001\000\005\000\014 000\005\000 000\011\000 000\033\000\033\000\033\000 000\011\000 000\005\000\023 000D\000 000\007 000 000\017\000Ä\000 000\005\000 \000\007\000 0009\000f\000H\000F\000Y\000C\000_\000_\000w\000\005\000 000Y\000I\000 000C\000 0003\000 \000 000e\000c\000_\000w\000 000F\000e\000c\000l\000C\000Y\000c\000k\000 000e\000c\000H\000 000c\000H\000U\000C\000l\000Y\000r\000H\000 000Y\000l\000H\000a\000\005\000 000H\000g\000p\000C\000l\000Y\000e\000c\000 000\005\000 \000\007\000 000E\000H\000F\000e\000a\000H\000k\000 000ê\000\005 000†\000 000\007\000/\000 000B\000Y\000B 000\023\000 000\005 000 000\007\000 000\001 000\020 000\006\000 000$\000`\000,\000F\000N\000C\0007\000\020\000f 000ê\000\005\000 000†\000i 000†\000j\000l 000\007\000 000ê\000\005 000l 000\007\000\023\000\005\000\023\000E\000\007 000x\000 000f\000ê\000\005 000i\000l 000\007\000\011 000ê\000\005 000j\000l 000\007\000g\000\011\000\005\000\023 000 000\007 000 000ê\000\005 000i\000j\000l 000\007\000 000\021\000\014\000\026\000B 000:\000\031\000 0002\000à\000 000:\000 000i 000Ö\000 000~\000o\000 0002\000e\000s\000 000s\000H\000 000p\000k\000H\000 000C\000c\000 000H\000u\000C\000a\000f\000_\000H\000 000l\000e\000 000H\000u\000f\000_\000C\000Y\000c\000 000l\000X\000H\000 000C\000E\000e\000r\000H\000 000k\000l\000H\000f\000k\000\011\000 000:\000X\000H\000 000k\000C\000a\000f\000`\000H\000 000G\000C\000l\000C\000E\000C\000k\000H\000 000Y\000k\000 000k\000X\000e\000s\000c\000 000Y\000c\000 000l\000C\000D\000`\000H\000 000 \000\005\000B 000>\000\027\000\031\0000\000\037\000f 0001\000f 000\013\000\003\000\011\000\012\000\010\000\006\000\016 000\005\000\003\000\014\000\003\000\004\000\003\000\013\000\006\000\016 000%\000'\000B 000"\000>\000*\0004\000;\000*\000>\000;\000B 000\013\000B 000+\000\011\000.\000\011\0000\000f 000\015\000B 000.\000\011\0002\000f 000\016\000B 000+\000\012\0006\000f 000\017\000B 000+\000\011\000.\000\011\0000\000\015\000f 000\020\000B 0000\000\011\0002\000f 000%\000'\000B 000"\000>\000*\0004\000;\000*\000>\000;\000B 000\022\000B 000+\000\011\000.\000\011\0000\000\013\000:\000f 000\023\000B 000.\000\011\0002\000\011\0006\000f 000\025\000B 000+\000\015\000f 000\027\000B 0000\000\011\0002\000\011\0006\000f 000\012\000\011\000B 0000\000\011\0002\000\011\0006\000f 0009\000l\000H\000f\000 000!\000,\000 000<\000k\000H\000 000&\0005\000\010\000U\000h\000e\000s\000l\000W\000 000Y\000c\000 000l\000W\000Y\000k\000 000f\000C\000f\000H\000h\000 000l\000e\000 000a\000Y\000c\000H\000 0005\000&\000 000'\000Y\000r\000H\000c\000 000 000ê\000 000'\000\014\000 000s\000H\000 000F\000C\000c\000 000U\000H\000l\000\030\000 000Q\000<\000C\000T 000 000ô\000i 000\005\000 000\014\000§\000j 000\005\000 000\014\000 000l 000\005 000*\000\007 000\014\000§\000n 000\005\000 000\014\000§\000o 000\005\000\(\000\007 000\014 000z\000 000 000\007 000\014 000i\000j 000\005 000 000\007 000\014\000 000i\000l 000\005 000 000\007 000\014\000 000i 000z\000 000 000\007 000\014\000 000j\000l 000\005 000 000\007 000\014\000 000l\000n 000\005 000 000\007 000\014\000 000n\000o 000\005 000 000\007 000\014\000 000i\000j\000l 000\005 000 000\007 000õ\000\031\000 0009\000l\000H\000f\000 000\020\000\030\000 000'\000H\000c\000H\000h\000C\000l\000H\000 0002\000 \000*\0009\000 000Q\000e\000a\000 0006\000%\000*\0009\000\013\000 000K 0007 000C\000T 000 000ô\000§\000†\000i\000\014\000 000†\000j\000\014\000 000†\000l\000\014\000 000†\000n\000\014\000 000†\000o\000\014\000 000\030\000 000†\000i\000j\000\014\000 000i 000†\000j\000\014\000 000†\000i 000l\000\014\000 000i 000†\000l\000\014\000 000†\000i\000t\000\014\000 000i\000\027\000\015\000 000†\000j\000l\000\014\000 000j\000†\000l\000\014\000 000†\000l\000n\000\014\000 000l\000†\000n\000\014\000 000†\000n\000o\000\014\000 000n\000†\000o\000\014\000 000†\000i\000j\000l\000\014\000 000°\000j\000l\000\014\000 000i\000j\000†\000l\000\014\000 000i 000†\000j\000†\000l\000\014\000 000†\000i\000j\000†\000l\000\014\000 000†\000i 000†\000j\000l\000 000\033\000 0009\000l\000H\000f\000 000'\000,\000 000 \000C\000_\000F\000p\000`\000C\000l\000H\000 000l\000X\000H\000 000k\000p\000f\000f\000e\000h\000l\000 000e\000I 0002\000 \000*\0009\000 000p\000k\000Y\000c\000U\000 000H\000g\000p\000C\000l\000Y\000e\000c\000 000\017\000\010\000\020\000\011\000 000\(\000H\000h\000H\000 000C\000h\000H\000 000k\000e\000a\000H\000 000H\000u\000C\000a\000f\000_\000H\000k\000\011\000 000ê\000\005 000†\000i 000\007\000/\000 000 000\037\000\020 000ê\000\005 000i 000\007\000 000 000-\000 000ê\000\005 000†\000j 000\007\000/\000 000 000\037\000\020 000ê\000\005 000j 000\007\000 000 000-\000 000ê\000\005 000†\000l 000\007\000/\000 000 \000\037\000\020 000ê\000\005 000l 000\007\000 000 000-\000 000ê\000\005 000 000i\000j 000\007\000§\000/\000 000ê\000\005 000j 000\007\000 000\020\000ê\0006 000i\000j 000\007\000§\000 000 000 000/\000 000\020\000\031\000 000ê\000\005 000i 000†\000j 000\007\000§\000/\000 000ê\000p\000i 000\007\000 000\020\000ê\000\005 000i\000j 000\007\000§\000 000 000 000/\000 000\020\000\031\000 000ê\000\005 000†\000i\000l 000\007\000§\000/\000 000ê\000\005 000l 000\007\000 000\020\000ê\000\005 000i\000l 000\007\000 000/\000 000\023 000 000 000'\000-\000 000ê\000\005 000†\000i 000†\000j\000l 000\007\000 000ê\000\005 000l 000\007\000\023 000\005\000\023 000D\000 000\007 000\010 000f\000ê\000\005 000i\000l 000\007\000\011 000ê\000\005 000j\000l 000\007\000g\000\011\000\005\000\023 000D\000 000\007 000 000ê\000\005 000i\000j\000l 000\007\000 000/\000*\000 000\020 000\005 000 000\011 000 000\007\000\011 000'\000 000 000'\000-\000 000;\000k\000H\000 000l\000X\000H\000 000k\000C\000a\000H\000 000s\000C\000w\000\005\000 000s\000H\000 000F\000C\000c\000 000U\000H\000l\000 000l\000W\000H\000 0002\000%\000*\0009\000 000O\000c\000C\000_\000_\000w\000\011\000 000K\000<\000C\000T\000 000/\000 000ô\000†\000i\000\014\000 000†\000j\000\014\000 000†\000l\000\014\000 000†\000n\000\014\000 000†\000o\000\014\000 000\027\000\015\000 000†\000i 000l\000\014\000 000†\000j\000l\000\014\000 000†\000i 000†\000j\000l\000 000\033\000 000\036\000B 0002\000~\000u\000ã\000è\000w\000ë\000v\000Ö\000 000o\000\021\000N\000 000\037\000C\000k\000H\000G\000 000e\000c\000 000l\000W\000H\000 000C\000D\000e\000r\000H\000 000G\000Y\000k\000F\000p\000k\000k\000Y\000e\000c\000k\000\005\000 000s\000H\000 000f\000h\000e\000f\000e\000k\000H\000 000l\000W\000H\000 000C\000`\000U\000e\000h\000Y\000l\000W\000a\000 000o\000\021\000J\000=\000s\000R 000\033\000 000\034\000_\000U\000e\000h\000Y\000l\000W\000a\000\030\000 000H\000\010\0003\000&\000 000*\000c\000f\000p\000l\000\030\000 000G\000C\000l\000C\000D\000C\000k\000H\000 000Y\000-\000 000 000 000-\000 0004\000p\000l\000f\000p\000l\000\030\000 0006\000%\000*\0009\000 000C\000c\000G\000 0002\000%\000*\0009\000\031\000 000\005 000 000\007\000 000<\000k\000H\000 000&\0005\000\010\000U\000h\000e\000s\000l\000W\000 000C\000_\000U\000e\000h\000Y\000l\000W\000a\000 000l\000e\000 000U\000H\000l\000 0005\000&\000 000C\000c\000G\000 000l\000W\000H\000Y\000h\000 000k\000p\000f\000f\000e\000h\000l\000k\000\031\000 000\001 000\020 000\006 000\014\000\014\0001\000Y\000c\000Y\000c\000U\000 000K\000<\000C\000T\000 000\005 000 000\007\000 000;\000L\000S\000f 000C\000c\000w\000 000Y\000l\000H\000a\000k\000H\000l\000 000?\000 000Y\000c\000 000Q\000<\000C\000T\000 0003\000L\000f 000c\000f 000\005\000\(\000\007\000 000\010\000\001\000B 000?\000e\000c\000_\000w\000 000F\000e\000c\000l\000C\000Y\000c\000k\000 000e\000c\000H\000 000Y\000l\000H\000a\000 000\001\000\010\000B 000\005\000 000\\\000K\000_\000H\000c\000U\000l\000W 000\003\000\034\000\006 000\032\000\017\000 000Y\000?\0007\000I\000f 000c\000f 000\005 000*\000\007\000 000ê\000\005 000†\000 000\007 0000\000F\000W\0009\000F\000\022 000 000r 000\007 000-\000 000\005 000 000\007\000 000A\000;\000f 000ê\000\005\000  000 000/\000 000 000ê\000 000Y\000?\0007\000I\000f 000K\000<\000C\000T 000/\000 000K\000<\000C\000T\000 000\005\000 000†\000_ 000\007 000-\000 000\003\000\026\000\004\000 000d\000f 000\003\000\027\000\004\000 0007\000C\000V\0007\000f 000c\000f 000\005 000 000\037\000\007\000 000;\000L\000S\000f 000C\000c\000w\000 000Y\000l\000H\000a\000k\000H\000l 000\035\000\005\000 0004 000/\000 000ô\000j\000\010\000\013\000 000j\000#\000\013\000 000\033\000\033\000\033\000 000\014\000j\000â\000õ\000\014\000 000\005 000D\000D 000\007\000 000\006\0002\000 000í\0003 000/\000 000 000\024\000\002\000f 000\035 0000 0003 000 000 000\007\000 0003\000L\000f 000c\000f 000\005\000 000 000\007\000 000à\000l\000w 000ê\000/\000 000\006\0002\000†\000j\000x\000 000†\000j 000#\000\004 000\001\000 000†\000j\000 000\007 000-\000 000\005\000 \000\(\000\007\000 000F\000C\000`\000F\000p\000_\000C\000l\000H\000 000ê\000\005 000à\000l\000w 000ê\000\007\000 000E\000w\000 000H\000g\000p\000C\000l\000Y\000e\000c\000 000\005 000D 000\007\000 000-\000 000\004\000\013\000\016\000\010\000 0001\000,\000B 000 000\002 000à\000m\000w 000 000 000/\000 000ê\000 000=\000/\000 000L\000>\000X\000U 000/\000 000L\000>\000X\000U\000 000\002 000à\000m\000w 000 000\007 000.\000 


     


B  Data preprocessing and types conversion After constructing the dataset, the following steps were applied 1  Dimensions with 20% or more missing values were removed. This eliminated height, weight, and chronic disease\(s 2  Tuples with 50% or more missing values were removed. This eliminates 11 tuples  Table I  shows the final dimensions along with their possible values and their coverage percentage. The problem of missing values was handled according to what is shown in Table II    TABLE I  T HE FINAL DIMENSIONS OF THE DATA  Attribute  Value  Range Coverage Field of influence Religion 9  Philosophy 8  Invention 10  Science chemistry physics biology medicine psychology  30  Politics  politics, exploring conquest economics  38  Art art, music literature 5  Age at first engagement with field of influence  early teens 10-15 8  late teens 16-19 27  early twenties 20-25  37  late twenties 26-29  early thirties 30-35  late thirties 36-39 3  Environment  C oastal/ island 12  On a river/ on a lake  on a river, on a lake, river & forest 57  Country 8  Valley  valley s forests 7  V illage 8  City 8  Whether a parent had died  Yes 46  No 54  F amily size Small 1-3 35  Medium 4-7 4 8   Large 8 17  Birth o rder in the family  First 35  Middle  48  Last 17  M arital status Single 19  Married  married, divorced widowed 81  Early contact with an influential person Yes 65  No 35  Religion at death Abrahamic 74  non Abrahamic 26  Financial status during  childhood Poor 16  P oor-average 4  A verage 30  A verage-rich 11  R ich 39  A ge at death Thirties 30-39  1  Forties 40-49  7  Fifties 50-59 21  Sixties 60-69 27  Seventies 70-79 26  Eighties 80-89 17  Nineties 90-99  1  TABLE II  REPLACEMENT OF M ISSING VALUES  Attribute Percentage Replaced value Reasoning Environment 1 City The exact location is unknown so it is replaced by the capital city Family size 10 Medium Replaced by the median of the available data Order in family 15 Middle Replaced by the median of the available data Marital status 1 Single Replaced by the default value Religion at death  1 Abraham ic  The character is a European scientist from the nineteenth century so it is assumed that he was of an Abrahamic faith Financial status during childhood 1 Average Replaced by the median of the available data  Age at death 1 Eighties The character is alive and in his early eighties, so it is replaced by  eighties   C  Extraction of Association Rules As the objectives are to extract the association rules and cluster the data to find common characteristics,  Apriori and DBSCAN algorithms were used, respectively The Apriori algorithm, which is considered one of the best 10 data mining algorithms according to   op ts a bottom up approach in which it attempts to find frequent item sets from a transaction dataset. Each frequent item set is supposed to have frequency larger than or equal to a user specified minimum support. De pending on the frequent item 
722 


sets, association rules are generated with confidence larger than or equal to a user specified minimum confidence To discover association rules, Rapid Miner software was used to apply the W-Apriori algo rithm. Due to the size of the dataset and the scattered nature of the data, the minimum support threshold was set low \(2%\etect rare patterns while the confidence parameter was set high \(100%\ to ensure accuracy. The rationale behind these choices is: if the same combination of factors occurred in the lives of at least two most influential people, then this combination is likely to be significant D  Clusters Identification DBSCAN \(Density-Based Spatial Clustering of Applications with Noise\ensity-based clustering algorithm. The algorithm grows regions with sufficiently high density into clusters. It can discover clusters of arbitrary shape in spatial databases with noise. It defines a cluster as a maximal set of density-connected objects. The algorithm accepts two inputs 026 and MinPoints The parameter 026 is used to define the radius of the object sê neighborhood while MinPoints defines the least sufficient number of objects in a neighborhood to be considered dense. In this case 026\005 was set to equal 1.0 and MinPoints to 8 To cluster the dataset, first, the values of some attributes were generalized as follows 025  Field of influence: religion - art & philosophy science & invention - politics 025  Age at first engagement in field of influence: teens  twenties  thirties 025  Financial status at childhood: poor  average  rich 025  Age at death: less than 50, 50-69, more than 70 Then, using Rapid Miner and the DBSCAN algorithm we experimented using different combinations of features to cluster the dataset. Ultimately, family size and financial status during childhood generate d the best clusters in terms of density, distribution and feasibility IV  R ESULTS AND D ISCUSSIONS  Association rules discovery and data clustering algorithms were applied indepe ndently. The following subsections contain the results obtained from the use of each technique A  Association Rules The following rule s were extracted 025  Rule 1 People who came from small poor families who also had a dead parent became influential in philosophy 025  Rule 2 If the individual was raised in the country and did not have early contact with an influential person, then he would definitely have had a dead parent 025  Rule 3 Influential people in religion who came from small families did not need to have early contact with an influential person 025  Rule 4 Unmarried people who first engaged with their field of influence in their late teens, did not have early contact with an influential person 025  Rule 5 Scientists who first engaged with their field of influence in their late teens and had a dead parent, were also the fi rst child in the family 025  Rule 6 Scientists who first engaged with their field of influence in their early teens came from small families 025  Rules 7 & 8 Scientists who were raised in a city came from small families an d died in their fifties 025  Rule 9 Influential people in religion who were the first children in the family all had a dead parent 025  Rule 10 Philosophers who did not get married lived to their eighties 025  Rule 11 Inventors who did not get married also did not have early contact with an influential person 025  Rule 12 Influential people in art who first engaged with their field of influence in their early teens never got married 025  Rules 13 & 14 People who came from poor families first engaged with their field in their late teens if they were raised in the country, while the first engagement was in their late twenties if they were raised in a village 025  Rules 15 & 16 People who were raised in a valley first engaged with their field of influence in their late teens if they were the last child in the family whereas if they were the first, the first engagement would be in their late twenties 025  Rule 17 confidence 80 1 ntors who were middle children did not need to have had early contact with an influential person B  Clustering Family size and financial status during childhood were used to cluster the available dataset. The result was five clusters whose distribution is shown in çFig. 1 and is described as follows TABLE III  C LUSTERS  CHARACTERISTICS  Cluster No Family size Financial status at childhood Coverage 1 Medium rich 23.5 2 Small rich 16 3 Small poor 10 4 Medium average 18 5 Small average 9 6 Large rich 11  Cluster 1 shows people who were raised in rich families of medium size, among which 85.7% were influential either  1  The confidence is below 100% but th e rule provides an interesting fact regarding middle children  
723 


in politics or in science and inventions. The same percentage represents those who first engaged with the field of influence in their twenties or earlier, and those who lived to be more than 50 years of age. 33% made it to their seventies. 71.5 had early contact with an influential person, and 81% got married. In addition, 62% were middle children. However all the last-born children of this cluster had both a dead parent and early contact with an influential person Cluster 2 demonstrates people who were raised in small rich families. 78.5% were either in politics or in science and inventions. 93% first engaged with their field of influence in their twenties or earlier. 71.5% were raised beside rivers or in a coastal area. Although 64% of this group were first children who usually had a dead parent, none of the last-born children had a dead parent. 85.7% got married and 57% lived more than seventy years In cluster 3, we find people who were raised in small poor families. 77.7% were rais ed beside rivers. 66.6% first engaged with their field of influence in their twenties and 66.6% lived more than seventy years. 77.7% had early contact with an influential person and 55.5% were first children. In addition, none of the people influential in religion belongs to this cluster Cluster 4 describes influential people who were raised in medium-size families with average financial status. 62.5 were raised beside rivers. 50% first enga ged with their field of influence in their teens and 31.25% in their twenties. 75 got married and all those who did not were middle children 93.75% lived more than fifty years and 37.5% made it to their seventies. 81% were of an Abrahamic faith Cluster 5 deals with people who were raised in small families with average financial status. 75 didnêt have a dead parent, yet 87.5% had early contact with an influential person. 87.5% were either first or last children, and the same percentage were of an Abrahamic faith. Moreover, none of the artists or philosophers were included in this cluster Cluster 6 demonstrates influential people who were raised in large rich families. 70% were influential in politics while none were influential in religion. 90% were raised beside rivers or in a coastal area. 70% were middle children 80% either had both a dead parent and early contact with an influential person, or neither. All of them got married, but only 80% were of an Abrahamic faith Figure 1  The distibution of the clusters V  C ONCLUSION  In this paper, data mining techniques were applied to discover common characteristics and special patterns from social, environmental and economic factors in the lives of a group of the most influential people in history. The association rules showed how some factors might be related such as how the environment affected the age at first engagement in the field of influence for individuals from poor families. Another rule demonstrated how birth order in the family affected the age at first engagement in the field of influence for people who grew up in similar environments In addition, the association rules suggested that marital status was affected by the field of influence, age at first engagement with the field of influence, and whether or not there was early contact with an influential person On the other hand, clustering divided the data into 6 clusters depending on different combinations of the family size and financial status during childhood. Each cluster was analyzed and it was found that some characteristics were dominant within a cluster. The rules derived and the resulting clusters might be the subject of a further social study. This study may lead to further understanding of personality traits and an increased capacity to measure the effect of environmental and sociological factors on peopleês abilities and achievements R EFERENCES  1  Michael H. Hart The 100: A Ranking of th e Most Influential Persons in History Kensington Publishing Corp., 1992 2  B.H.M. Custers  Effects of Unreliable Group Prof iling by Means of Data Mining  Proceedings of the 6 th International Conference on Discovery Science; Spring er LNCS, Vol. 2843, 2003 3  Markus Breitenbach, Tim Brennan, William Dieterich, and Gregory Grudic  Clustering of Psychological Person ality Tests of Criminal Offenders  ECML PKDD 2006 SAS Workshop on Practical Data Mining, 2006 4  CJ Chang, and SW Shyue  A Study on the Application of Data Mining to Disadvantaged Social Clas ses in Taiwan's Population Census  Expert Systems with Applications, Vol. 36, pp. 510-518 2009 5  M. Ramaswami, and R. Bhaskaran  A CHAID Based Performance Prediction Model in Educational Data Mining  International Journal of Computer Science Issues \(IJCSI Vol. 7, Issue 1, No. 1, January 2010 6  PAKDD 2007 Data Mining Competition http://lamda.nju.edu.cn/conf pakdd07/dmc07 7  Bin Bi, Lei Ji, and Qian Hu  Comparative Study on Classification Techniques to Identif y Potential Customers  Proceedings of the 2008 International Symposium on Computational Intelligence and Design ISCID'08 8  J. Han, an M. Kamber Data Mining Concepts and Technique Moran Kaufmann Publishers,pp. 45  61, 2001 9  Pang-Ning Tan, Michael Steinbach, and Vipin Kumar Introduction to Data Mining Pearson Education, US, 2006 10  Britainica Online Encyclopidea. h ttp://www.britannica.com 11  XindongWu, Vipin Kumar, J. Ross Quinlan, Joydeep Ghosh, Qiang Yang, Hiroshi Motoda, Geoffrey J. McL achlan, Angus Ng, Bing Liu Philip S. Yu, Zhi-Hua Zhou Michael Steinbach, David J. Hand, and Dan Steinberg  Top 10 algorithms in data mining  Springer-Verlag London Limited, 2007 12  James C. Kaufman,Robert J. Sternberg   The Cambridge Handbook of Creativity Cambridge University Press, pp. 180, 2010 
724 


StepS: If there is an existing itemset A in Lk and A  B u C , then calculate the value of confm \(B ? C reserve the rule such as B ? C which value is greater or equal than Wminconf Step6: Output all the mixed weighted rules such 1ikeB? c VI. THE MINING SAMPLES AND ANALYSIS ON CONSEQUENCE OF MIXED WEIGHTED ASSOCIATION RULES BASED ON COLLEGE-WIDE EXMINATION COURSE GRADE Convenient for mining, the score of each question has been divided into three sections which contains excellent average, weak. Meanwhile, made a certain notation for each section, and then use the notation instead of the score in the corresponding section. Taking score of windows for example windows have IS points, the score has been divided into three sections: if it is not only greater or equal than 13, but also equal or lower than IS ,or scoreE[13,IS], which is defined excellent part, make 0 instead of the scores in this part; Similarly, score E [9,13 use E instead of the scores in that part; score E [0,9 defined weak part, and use F instead of the scores in the part The score of network, word, excel, optional have been divided into three sections, which apply the same approach where powerpoint and access questions as a questions of optional, and the greater points of power point and access as optional grades. The detail corresponding relations between sections of questions and notations are shown in table 1 TABLE! DISCRETIZATION OF SCORES  otations Excellent Average Weak Questions Windows\(J5 Network\(20 Word\(25 ExceJ\(20 OptionaJ\(20  SImIlarly, each college IS aSSIgned a certam notatIOn to instead of them. In sequence, the notations of colleges of Mathematic Science, Electronic engineering, Physics and 


technology, Education science, Economics and management Law, Foreign studies, Physical culture, Music, File art are 0,1,2,3,4,S,6,7,8,9. The vertical weights of ten colleges Vi set as following: Vo:O.l; VJ:O.l; V2:O.l; V3:0.6; V4:O.S; Vs:O.S V6:0.6; V7:O.9; Vs:0.9; V9:O.9. The horizontal weights of questions hj set as following: Windows \(hl h2 h3  hs The following list of ten transactions \(as shown in table II algorithm Where H _weight is abbreviation of Horizontal weight V_weight is abbreviation of Vertical weight Applied mixed weights in college computer cultural foundation grades database, with Wminsup=30% and Wminconf=60%, the following interesting two rules have been extracted from the database 1 u a ? Z\(W sup = 53%, Wcan! = 84 V14-532 2010 International Conference on Computer Application and System Modeling \(rCCASM 2010 L u Z => O\(W sup = 33%, Wcon! = 90 TABLE I!. TEN TRANSACTIONS  cores Windows Network Word Er:cel Optional v ? weights notations 0.3 0.4 0.6 0.7 0.9 Vo:O.1 D G J N X V\(O.I D G J M X V2:0.1 E I J M Y VJ:0.6 D G J M X V4:O.5 0 H K M Z V5:0.5 E I K N Z V6:0.6 F G K M Y V7:O.9 E H J M Z V8:0.9 0 H L 0 Z V9:0.9 0 H L 0 Z From the first aSSocIatIOn rule, we can find that the students who get weak grades in network and excel, also obtain weak in the optional questions, moreover, the mixed weighted support of the rule is 53%, and confidence is 84 The second rule shows that the students who get weak grades in word and optional, also get weak grades in the excel questions, and the mixed weighted support of this rule is 


33%, confidence is 90%. However, the rules relevant to excel by using Apriori algorithm can not be found at the same thresholds And then, add score of single choice, the total score of student and the college as horizontal weighted items to transaction database, furthermore, 0.5, 1.2 and 1 have been assigned to the items in sequence. Other items' weights are the same as above setting. Score of single choice has been divided into three sections in the same way, and a certain notation has been assigned to each part. Also total score has been treated in the same way. In sequence, use notation A, B and C instead of scores in excellent, average and weak sections for single-choice questions, X, Y and Z for total score. With Wminsup=20% and Wminconf=30%, the following valuable rules have been discovered in the database 9 ? CCW sup = 27%, Wcan! = 38 9 ? L\(W sup = 27%, Wean! = 39 9 ? O\( W sup = 27%, Wean! = 69 9 ? Z\(W sup = 27%, Weanf = 83 Then set Wminsup=50% and Wminconf=80%, the rules have been extracted from the database o u Z ? T\(W sup = 53%, Wearif = 87 O u T  ? C\(W sup = 78%, Wean! = 100 Analyzing of the first four rules can discover that students from college of File art get the worst score in optional questions. Only if teachers strengthen the teaching of this chapter can improve average of the college, thereby improving average of the university. From later two rules we can find that grades of excel, optional and single choice have closer relationship with total score than other scores of questions. But if apply Apriori to mining rules in the transaction database and only if minimum support is decreased to 5%, rules relation with colleges can be obtained Moreover, the last rule with 48% support and 95 confidence can be obtained by using Apriori. Obviously using mixed weighted association rules algorithm improves the support and confidence of rules, and makes them be discovered easier VII. CONCLUSION This paper takes college computer cultural foundation course grade database as example, applies mixed weighted 


association rules algorithm to obtain some importance and valuable information according to characteristic of the database, such as the correlations of chapters, and the factors influence total score of students. The information has reference value for teaching, and is helpful to improve learning efficiency of students. Ultimately, the average scores of the students are improved. Similarly, the approach of analysis in scores of computer foundation course database can also be applied in other college examination course grade database, such like college English test grades database, principles of Marxist philosophy test scores database and so on. In addition, application in other database like national computer rank test, CET-4, a lot of valuable information can be discovered. This important information as reference for the teaching reform is beneficial to improve quality of teaching REFERENCES I] R. Agrawal and R. Srikant, "Fast algorithms for mining association," In Proc. of the 20th In!'1 Conf. on Very Large Database Santiago, Chile, 1994, pp. 487-499 2] Cai ,e.H., Fu, Ada W.e., Cheng,e.H., et al. "Mining association rules with weighted items," Database Engineering and Applications Symposium, Cardiff, 1998,m Porceedings, IDEAS '98, Internationa 3] Lu, S ,  Hu, H.,and Li, F., "Mining weighted association rules Intelligent Data Analysis 5\(200 I 4] Yu, S, Zhu, D., Liu, Z ,  "Application study in E-business using weighted association rule mining algorithm," Computer Engineering and Applications,2008,44\(17 5] Han,J.,Kamber,M.,2005,"Data Mining: concepts and techniques in press 6] Wang, W., Yang, J., and Yu, P.S., "Efficient mining of weighted association rules\(WAR 2000,pp.270-274 7] Kao, W ,  Huang, I., and Shen, H., et aI. "A study of weighted association rule applied in human resource job requirement Pervasive Computing\(JCPC 8] Cheng, L.,Chen,S., and Chen,J , "Applying weighted association rules with the consideration of product item relevancy," Service Systems and Service Management,2009.ICSSM'09.6th International conference, pp 888-893 V14-533 


  Xi?X s0 = ?iusx Yi?Y s0 = ?iusy Zi?Zs0 = ?iusz 4  OMsi = i  Osmi   Xi = ixsi Yi = iysi Zi = izsi 5 Substituting \(5 4 equations  ixsi ?X s0 = ?iusx iysi ?Y s0 = ?iusy izsi ?Zs0 = ?iusz 6 If ? is a vertical plane in the sphere frame Rs, i.e. us 0,0,1]T , then  ixsi ?X s0 = 0 iysi ?Y s0 = 0 izsi ?Zs0 = ?i 7 Because we know [xsi ,ysi ,zsi ]T and [X s0 ,Y s0 ,0]T , we can compute i for each i. We can then substitute in Equation \(5 obtain the extreme points of the lines in ?. Finally, we apply the homogeneous transformation to transform the coordinates of those points to the global coordinate system and trace the 3D lines. The result is shown in Fig. 8. Observe how the vertical lines are consistent with the 2D map Fig. 8. Environment with 3D lines VI. DISCUSSION AND PERSPECTIVES This paper describes an original composite sensor approach that takes advantage of the information given by an omnidirectional camera and a laser range finder to ef 


ficiently solve the Simultaneous Localization and Mapping problem for indoor environments, and to reconstruct a 3D representation of the environment. The accompanying video illustrates the incremental generation of a 2D map and the estimation of the robot trajectory alongside the laser range data projected on omnidirectional images. It also shows the vertical lines detected in the images and their mapping into a 3D reconstruction of the environment In order to show the robustness of the methodology, we tested the algorithm with a sequence taken in a different indoor environment with our old robot Anis which is equipped with the same catadioptric camera and an AccuRange 4000 2D laser range finder. This laser is composed of a laser telemeter with a rotating mirror that allows measurements of points on 360?, except for an occlusion cone of approximately 30? caused by the assembly of the mirror. The resulting 2D map is shown in Figure 9. The vertical line extraction and the reconstruction of the 3D environment were 3523 Fig. 9. Global Map obtained by SLAM in Borel Building consistent as well The SLAM problem has been solved using many different approaches, however some important problems need to be addressed that are often directly linked to the sensors used Laser range finders cannot help in evaluating the translation of a robot moving in a straight line in a corridor. Mapping in dynamic environments is also hard with only laser data. On the other hand, using visual sensors alone introduces issues such as propagating correctly the scale factor, initializing the range when using a monocular sensor, and merging data when using multiples cameras In our approach, the laser provides metric information of the environment that helps to fix a scale factor \(removing the difficulty of propagating the scale factor need to use multiple cameras. Throughout the paper we have identified several advantages of combining laser and visual sensors. Our experimental results are encouraging and give us valuable insight into the possibilities offered by this composite sensor approach We have considered several research directions that could be pursued to improve the results obtained so far. We have thought about extending our algorithm with loop closure de 


tection. This would allow the algorithm to detect previously visited locations and improve the accuracy of mapping and the precision in the estimation of the robot pose. Being able to detect previously visited places is of great importance to solve the problem of global localization and to recover the robot from kidnapping, a situation occurring when the robot is displaced by something out of its control \(e.g. taking an elevator, being transported from one location to another Therefore, solving the loop closure problem will not only improve SLAM performance, but will as well enable new capabilities Further work will concentrate on an extension of the PSM algorithm to exploit the information about vertical lines detected using omnidirectional images. Segmentation of the ground \(floor a dense \(textured onto the geometric model of the world. Finally, we believe the general approach can be extended to solve the full six degrees of freedom \(6DOF active field of research REFERENCES 1] L.Charbonnier and O.Strauss, A suitable polygonal approximation for laser range finder data, Proceedings of the Intelligent Vehicles 95 Symposium, Detroit, Mi, 1995, pp 118-123 2] J.Nieto, T.Bailey and E.Nebot, Recursive scan-matching SLAM Robotics and Autonomous Systems, vol. 55, 2007, pp 39-49 3] J.S. Gutmann,T.Weigel and B. Nebel, A fast, accurate and robust method for self-localization in polygonal environments using laser range finders, Advanced Robotics Journal, vol 14, 2001, pp 651-667 4] P.J. Besl and N.D. Mackay, A method for registration of 3D shapes IEEE Transactions on Pattern Analysis and Machine Intelligence, vol 14, 1992, pp.239-256 5] F.Ramos, J.Nieto and H.Durrant-Whyte, Recognising and modelling landmarks to close loops in outdoor SLAM, Proceedings of the IEEE International Conference on Robotics and Automation, Roma, It, 2007 pp 2036-2041 6] F.Lu and E.Milos, Robot pose estimation in unknown environments by matching 2D range scans, Journal of Intelligent and Robotic Systems vol. 20, 1997, pp 249-275 7] A.Diosi and L.Kleeman, Laser Scan Matching in polar coordintes with application to SLAM, Proceedings of the IEEE/RSJ International Conference on Robotics and Automation, Edmonton, Canada, 2005, pp 


3317-3322 8] G.Dudek and M.Jenkin, Computational Principles of Mobile Robotics Cambridge University Press, Cambridge, 2000 9] T.Lemaire, C.Berger, I.K.Jung and S.Lacroix, Vision-Based SLAM Stereo and Monocular Approaches, International Journal of Computer Vision, vol. 74, 2007, pp 343,364 10] G.Silveira, E.Malis and P.Rives, An efficient direct method for improving visual SLAM, IEEE International Conference on Robotics and Automation, Roma, It, 2007, pp 4090-4095 11] A.J.Davison, Real-time simultaneous localisation and mapping with a single camera. Proceedings of International Conference on Computer vision, vol. 2, 2003, pp 1403-1410 12] C.Mei and P.Rives, Calibration between a Central Catadioptric Camera and a Laser Range Finder for Robotic Aplications, IEEE International Conference on Robotics and Automation, Orlando, Florida, 2006 13] http://www.robots.ox.ac.uk  cmei/Toolbox.html 14] C.Mei and E.Malis, Fast central catadioptric line extraction, estimation, tracking and structure from motion. Proceedings of of the IEEE/RSJ International conference on Intelligent Robots and Systems Beijing, China, 2006, pp. 4774-4779 15] C.Mei, Laser-Augmented Omnidirectional Vision for 3D localisation and mapping.PhD thesis, Ecole des mines de Paris, Inria Sophia Antipolis, 2007 16] J.P. Barreto, General central projection systems, modeling, calibration and visual servoing, PhD thesis,University of Coimbra, Department of electrical and computer engineering, 2003 17] C.Geyer and K.Daniilidis, A Unifying Theory for Central Panoramic Systems and Practical Applications, in European Conference on Computer Vision, 2000, pp. 445-461 18] R.Smith and P.Cheeseman, On the representation of spatial uncertainty, International Journal of Robotic Research, vol 5, No.4, 1987 pp.56-68 19] R.Smith, M.Self and P.Cheeseman Estimating Uncertain Spatial Relationships in Robotis, Proceedings of the Second Annual Conference on Uncertainty in Artificial Intelligence, Philadelphia, PA, USA Elsevier, 1986, pp. 435-461 20] P.Biber, H.Andreasson, T.Duckett and A.Schilling,3D Modeling of Indoor Environments by a Mobile Robot with a Laser Scaner and Panoramic Camera, IEEE/RSJ International conference on Intelligent Robots and Systems, Sendai, Japan, October 2004 


21] S. Baker and S.K. Nayar, A Theory of Catadioptric Image Formation, IEEE International Conference on Computer Vision \(ICCV pp.35-42, Jan, 1998 22] S.K. Nayar, Catadioptric Omnidirectional Cameras, IEEE Conference on Computer Vision and Pattern Recognition \(CVPR 488, Jun, 1997 23] A.Victorino, La commande referencee capteur: une approche robuste au proble`me de navigation, localisation et cartographie simultanees pour un robot dinterieur. PhD thesis, LUniversite de Nice-Sophia Antipolis, Inria Sophia Antipolis, 2002 3524 


ec  d Fig. 5: Computation Performance Comparison Tab. 4: Computation Savings by TOP-MATA K Connect K Retail K Wap La12 50 58.35% 100 0.01% 200 0.83% 23.04 150 55.91% 400 2.65% 400 30.12% 45.38 250 53.61% 700 1.84% 800 20.03% 25.95 350 48.28% 1100 3.95% 1600 13.06% 27.89 450 43.12% 1400 1.48% 3200 6.14% 12.70 550 39.36% 1700 4.00% 6400 5.63% 7.11 Second, Fig. 5 shows the results of four data sets computed by TOP-MATA and TOP-DATA, respectively. As can be seen, in general, TOP-MATA shows a better performance than TOP-DATA. And as the increase of the ? value, the advantage tends to be even more impressive for these four data sets 4.3. The Computation Saving of TOP-MATA As can be seen in the Tab. 4, four data sets, enjoy signi?cant computation savings brought by TOP-MATA. We can conclude that the computation saving is a major factor for the performance of TOP-MATA. That is, compared with TOP-DATA, a higher computation saving implies a much better performance of TOP-MATA. Since this saving is more signi?cant as the increase of the items, TOP-MATA works better for large scale data sets with a large number of items 5. Conclusion In this paper, we studied the problem of searching for top? item pairs with the highest cosine values among all item pairs. Speci?cally, we provided a novel algorithm TOPMATA which employ a Max-First traversal strategy for ef?ciently performing top-? cosine similarity search. Extensive experimental results veri?ed the effectiveness of the algorithms, And TOP-MATA algorithm is superior to TOPDATA for large-scale data sets with multiple items Acknowledgment This research was partially supported by the National Natural Science Foundation of China \(NSFC No. 70901002 and the Ph.D. Programs Foundation of Ministry of Education of China \(No. 20091102120014 


REFERENCES 1] R. Agrawal, T. Imielinski, and A. Swami, Mining association rules between sets of items in large databases, in SIGMOD 1993 2] C. Alexander, Market Models: A Guide to Financial Data Analysis. John Wiley & Sons, 2001 3] W. Kuo, T.-K. Jensen, A. Butte, L. Ohno-Machado and I. Kohane, Analysis of matched mrna measurements from two different microarray technologies Bioinformatics, vol. 18, p. 405C412, 2002 4] H. Xiong, X. He, C. Ding, Y. Zhang, V. Kumar, and S. Holbrook, Identi?cation of functional modules in protein complexes via hyperclique pattern discovery in PSB, 2005 5] J. Han, H. Cheng, D. Xin, and X. Yan, Frequent pattern mining: Current status and future directions DMKD, vol. 15, no. 1, pp. 5586, 2007 6] P.-N. Tan, M. Steinbach, and V. Kumar, Introduction to Data Mining. Addison-Wesley, 2005 7] S. Brin, R. Motwani, and C. Silverstein, Beyond market basket: generalizing association rules to correlations, in SIGMOD 1997, Tucson, AZ, 1997, pp 265276 8] E. Omiecinski, Alternative interestmeasures formining associations, TKDE, vol. 15, pp. 5769, 2003 9] H. Xiong, S. Shekhar, P.-N. Tan, and V. Kumar Exploiting a support-based upper bound of pearsons correlation coef?cient for ef?ciently identifying strongly correlated pairs, in KDD 2004, 2004, pp 334343 10] I. Ilyas, V. Markl, P. Haas, P. Brown, and A. Aboulnaga, Cords: Automatic discovery of correlations and soft functional dependencies, in SIGMOD 2004 2004, pp. 647658 11] J. Zhang and J. Feigenbaum, Finding highly correlated pairs ef?ciently with powerful pruning, in CIKM 2006, 2006, pp. 152161 12] H. Xiong, W. Zhou, M. Brodie, and S. Ma, Top-k correlation computation, JOC, vol. 20, no. 4, pp 539552, 2008 13] S. Zhu, J. Wu, and G. Xia, Top-k cosine similarity interesting pairs search, in 


http://datamining.buaa.edu.cn/TopKCos.pdf 14] M. Zaki, Scalable algorithms for association mining, TKDE, vol. 12, pp. 372390, 2000 


enhance item-based collaborative filtering, in 2nd IASTED International Conference on Information and Knowledge Sharing, Scottsdale, Arizona, 2003 476 2010 10th International Conference on Intelligent Systems Design and Applications 


Basi Association Rles Basi c  Association R u les Association is basically connecting or tying up occurrences of Association is basically connecting or tying up occurrences of events Ol dib t f ilt t O n l y d escr ib e se t s o f s i mu lt aneous even t s Cannot describe patterns that iterate over time e g  itemset a  0  b  0  g    Eg If you sense higher data rates on the downlink than normal AND New Route generated Implies high chances of Intrusion AND New Route generated Implies high chances of Intrusion Associative IDS for NextGen Frameworks Dr S Dua LA Tech 20 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



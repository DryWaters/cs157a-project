Capability of Classification of Control Chart Patterns Classifiers Using Symbolic Representation Preprocessing and Evolutionary Computation  K. Lavangnananda 1 P. Sawasdimongkol 2  IP-Communications Lab., School of Information Technology\(SIT King Mongkutês University of Technology Thonburi \(KMUTT 126 Pra-cha-u-tid Road, Bangmod, Bangkok 10140, Thailand E-mail 1 Kitt@sit.kmutt.ac.th  2 Pantharee.boom@sit.kmutt.ac.th   Abstract  Ability to monitor and detect abnormalities accurately is important in a manufacturing process. This can be achieved by recognizing abnormalities in its control charts 
This work is concerned with classification of control chart patterns \(CCPs\ utilizing a technique known as Symbolic Aggregate Approximation \(SAX\ and an evolutionary based data mining program known as Self-adjusting Association Rules Generator \(SARG\ SAX is used in preprocessing to transform CCPs, which can be considered as time series, to symbolic representations. SARG is then applied to these symbolic representations to generate a classifier in a form of a nested IF-THEN-ELSE rules. A more efficient nested IFTHEN-ELSE rules classifier in SARG is discovered. A systematic investigation was carried out to find the capability of the proposed method. This was done by attempting to generate classifiers for CCPs datasets with different level of noises in them. CCPs were generated by Generalized Autoregressive Conditional Heteroskedasticity GARH where 002 
is the noise level parameter. Two crucial parameters in SAX are Piecewise Aggregate Approximation and Alphabet Size values.  This work identifies suitable values for both parameters in SAX for SARG to generate CCPs classifiers This is the first work to generate CCPs classifiers with accuracy up to 90% for 002 at 13 and 95 % for 002 at 9  Keywords Association Rules; Autoregressive Conditional Heteroskedasticity \(GARH\l; Control Chart Patterns CCPs\lutionary Computation; Symbolic Aggregate Approximation \(SAX\ Symbolic Representation; Self-adjusting Association Rules Generator \(SARG\eries  I   I NTRODUCTION  Control chart patterns \(CCPs\e used in Statistical 
Process Control to provide information on the state of a process. They are used in detecting abnormalities in a systemês condition by monitoring the behavior of the system in order to ensure high quality control. CCPs can be considered as time series. They represent sequences of real values over a period of time. In order to monitor the systemês condition, control charts are classified into different categories. Hence, accurate classification is a vital for an effective system monitoring. Apart from an ability to classify time series, discovering useful hidden patterns in them is advantageous as their behaviors and characteristics can then be understood. As hidden patterns in time series are detected 
from consecutives values rather than from values at particular instances, this renders most data mining algorithms which work on values of individual attributes inappropriate It is also difficulty to classify the patterns of CCPs in highly noisy situation. Therefore, suitable symbolic representation of the CCPs time series data under investigation is beneficial to the mining process This work is an improvement to classification of control chart patterns by utilizing a technique in symbolic representation of time series known as Symbolic Aggregate Approximation \(SAX\ and a technique in generating association rules known as Self-adjusting Association Rules Generator \(SARG 
 SAX is the method of preprocessing CCPs data. In pre-processing using SAX, real valued time series are transformed into the Piecewise Aggregate Approximation \(PAA\ representation and then symbolize the PAA representation into a discrete string which also retains its essential features. This preprocessing data performs dimensionality reduction and lower bounding of the data Output from SAX \(i.e. symbolic representations\ can then be an input to SARG in order to generate association rules for the classification. SARG adopts evolutionary computation approach which comprises 3 main components, Data Preprocessing, Evolutionary Computation and Final Classifier Builder 
The main objective of this study is to systematically investigate the suitable values for PAA and Alphabet Size in SAX for classification of CCPs as well as assess the classification ability of utilizing both SAX and SARG by increasing the noise in CCPs. It also discovers a more effective way to generate a nested IF-THEN-ELSE rules in the Final Classifier Builder in SARG   II  C ONTROL CHART PATTERNS  Control chart patterns \(CCPs\ are used to detect abnormalities during the process [1  T h e r e ar e  m a n y  unnatural patterns that may exist indicating the process is out 
of control. The presence of unnatural patterns implies that a process is affected by abnormal causes, and correction should be taken as soon as possible. Identification of unnatural patterns can greatly narrow the set of possible causes that must be investigated, and thus reducing the diagnostic time. CCPs used in this work are patterns which are commonly occurred in control systems. Figure 1. shows the example of six main types of pattern that might be observed on a control chart normal, cyclic, decreasing trend, increasing trend, downward shift and upward shift   
2011 23rd IEEE International Conference on Tools with Artificial Intelligence 1082-3409/11 $26.00 © 2011 IEEE DOI 10.1109/ICTAI.2011.178 1047 


             Figure 1. Example of six control chart patterns  These patterns are generated  by  GARH  \(Generalized Autoregressive Conditional Heteroskedasticity Model   Equations which are used to generate control chart patterns used in this work can be found in [3  Equations for GARH are shown below  1. Normal y\(t\  =  µ + r\(t 002   1 2. Cyclic y\(t\  =  µ + r\(t 002 a sin\(2 003 t/T\     \(2 3. Decreasing trend:  y\(t\  =  µ + r\(t 002 gt  3 4. Increasing trend:   y\(t\  =  µ + r\(t 002 gt  4 5. Downward shift:   y\(t\  =  µ + r\(t 002 ks  5 6. Upward shift:         y\(t\  =  µ + r\(t 002 ks  6  Where y\(t  Time Series value   Mean value r  Normally distributed random number t  Time  002  Standard deviation a  Amplitude of cyclic variations g  Magnitude of gradient trend k  Determines shift position s  Shift magnitude T  Period of cycle  The standard deviation 002 is  the  critical  parameter  which dictates  the level of noise in each pattern. Higher value of 002  presents higher level of noise in the CCPs and most researches in classification of CCPs tend to concentrate on varying the 002 value  III  R ELATED W ORK  Numerous approaches have been proposed to control chart patterns classification. Earliest work on these patterns attempted to study performance of neural networks and was proven superior to the use of expert systems and statistical methods [4 ne r g y o f ne ural ne t w o r ks w a s al so d e vel ope d for this classification with better performance than a single unit [5   Oth e r w o rk s o n th es e p a tt e r n s at tem p te d t o s t u d y  performance of different architectures of neural networks These include Self-Organizing Network [6  w a v e let an a l y s is with neural networks [7 n d s u p e r v i s ed n e ur al net w o r ks [8  Recently, capability of neural networks in classifying CCPs was systematically investigated to find limitation of neural networks in CCPs classification [9 To improve classification, preprocessing techniques were introduced. The earliest work [10 is t o in v e stig a t e su it ab l e  training algorithms. One of the more promising approaches is to extract useful features from the signals so they could then be used in training neural networks. The first attempt was carried out by [1 w h ere f o u r f e a t u r es m ean  s t an da r d  deviation, skewness and kurtosis\image processing were extracted. Synergy of neural networks was also introduced  together  with  features extraction  in  [12  an d   b y i n co rpor a t i ng t w o m o r e fe at ur e s   s l o p e a n d P e ar s o n  correlation coefficient\ and additional transformation of original signals. The advantage of extracting statistical features from CCPs as input vector to neural networks was also affirmed in [1   Other significant works on the classification of control CCPs include  w h e r e d i scr i m i na t i v e pa t t e r ns w e r e  extracted by piecewise constant modeling of temporal signals by regression trees. SAX was also employed for this classification in [16  Inductive learning is one of many techniques where patterns can be learned or induced from a collection of samples. A popular method in evolutionary computation Genetic Algorithms \(GAs\ was employed in a program Genetic Algorithm for Inductive Learning \(GAIL  where chromosomes represent possible classification rules GAIL was furthered improved into SynGAIL [18  w h ich  achieved higher accuracy by adopting synergism of different GAIL units. The program Genetic Programming for Inductive Learning \(GPIL\ \(a data mining program i s  an improvement from GAIL and SynGAIL. In application of evolutionary computation in CCPs classification, tree representation of chromosomes was proven more flexible and efficient than binary strings A recent approach app l i ed SAX  i n  p r e p ro ce ssi ng t o  transform the time series CCPs to symbolic representations for a mining program SARG, to generate association rules   E v e n  tho ugh, util iz ing  SA X a nd SA RG had p r o v e n  superior to previous works, it has not determine the optimal values for Piecewise Aggregate Approximation segments PAA l d Alphabet Size s or transforming CCPs into symbolic representations for mining algorithms. The work also revealed that the difficulty in the classification lies in differentiation of some patterns which may appear very similar when signals are highly noisy IV  U TILIZING SAX AND SARG IN C LASSIFICATION OF CCP S  This work bases the classification of CCPs from the previous work [2 w h e r e S A X a n d S A R G w e r e  ut i l i z ed i n  building classifiers for CCPs. It investigates these two techniques for classification of CCPs. This Section provides a brief description of both SAX and SARG. Figure 2 illustrates the development of the CCPs classifier in this work 
1048 


 Figure 2. Development of CCPs Classifier A  Symbolic Aggregate Approximation \(SAX As reported in [20  a s u ita bl e ch oi ce of r e p r es en ta ti on  affects the efficiency of time series data mining algorithms considerably. Several time series representations have been introduced, including Discrete Fourier Transform, Piecewise Linear Approximation, Max. Wavelet Transform and Piecewise Constant Approximation The major drawback of using the above representations in mining time series data is that they are real value. This limits the algorithms, data structures and definitions available for them. Such limitation has led many researchers to consider transforming real valued time series data into symbolic representations. SAX adopted in this work was first introduced in [22  SA X h a s t h e ad v a n t ag e o f  d i m e n s io n a li ty  and noise reductions. It also allows real valued data to remain the original characteristics with only an infinitesimal time and space overhead In SAX, the number of Piecewise Aggregate Approximation segments l ined to reduce dimensions of the time series. Hence, a time series data T of length n  can now be represented in T of length l Each element of T is calculate by the following equation 1\1 n i l i j n ji l TT   002 7 The Alphabet Size s then defined. For example, if alphabets èaê, èbê, ècê and èdê are to be used, then the Alphabet Size s 4. Each value of i T is now represented by an alphabet that is determined by breakpoint. Because the distribution of the data is normal, the breakpoint is defined by value from statistical table \(Z-table\ For example, Figure 3 illustrates SAX representation of an upward shift control chart for n 60 l 6 and s 4    Figure 3.  An example of SAX representation  The result of the SAX representation for the upward shift control chart above is è1a2b3b4b5d6dê. Detail and analysis of SAX can be founded  in a n d  16   B  Self-adjusting Association Rules Generator \(SARG The mining algorithm creating the classifier in this work is SARG [21   It adopts evolutionary computation approach which comprises 3 main components data preprocessing evolutionary computation and Final Classifier Builder as shown in Figure 4                    Figure 4  Three main components in SARG  In SARG, the data set must be split into 2 sets, ètraining setê and ètest setê. Data preprocessing preprocesses the training set for the input to the evolutionary computation The evolutionary computation is responsible for generating rules. It comprises 2 processes as namely Regrouping and Genetic Programming GP  Referring to Figure 4, the number of Regroup, GP Unit and Rules sorting sequences are equal to the number of categories in the classification Each sequence is responsible for generating rules for that particular class In each Regroup, it splits the dataset into two groups those which belong to that group and those which do not  During the inductive learning, SARG has the ability to adjust its evolutionary computation to suit the nature of the training dataset. This is done by means of a crossover method known as èMaxToMinê \(i.e. replacing sub-branch of a tree which has the minimum fitness value with a sub            Control Chart Patterns CCPs  Classifier for the Control Chart Patterns Nested IF-THEN-ELSE rules Self-adjusting Association Rules Generator \(SARG Symbolic Representations of CCPs Eg. è1a2b3b4b5d6d Symbolic Representation of the Control Chart Patterns  S ymbolic A ggregate appro X imation 
1049 


branch from another tree with the maximum fitness value together with three modes of operations. The progress in evolutionary computation is monitored and the operation mode is changed if no progress occurs after 50 generations have elapsed. These are three modes of operation in GP Unit i.e. different combinations of  èCrossoverê and èSelection methods  In Rule Sorting all rules generated are sorted according to their fitness value. The one with the highest fitness value is then taken as the rule \(i.e. a classifier\ssify patterns in that category. The detail of these operators can be found in The Final Classifier Builder in SARG builds a classifier in the form of a nested IF-THEN-ELSE format Association rules from all categories are nested according to the fitness value rather than category number. This is because rules with higher fitness values are likely to classify samples more accurately than those with lower one. Finally the classifier is evaluated for their accuracy by the test dataset \(i.e. how accurate it can classify the test dataset  This work improves the Final Classifier Builder based on observation and intuition. This is discussed in the next Section V  I MPROVEMENT TO THE F INAL C LASSIFIER B UILDER  As stated in the previous section, SARG builds a classifier in the form of a nested IF-THEN-ELSE format. An example of a classifier for n categories is shown below   IF condition\(s\or the rule with highest fitness value  THEN class = category of the rule with highest fitness value ELSE IF condition\(s\or the rule with 2 nd highest fitness value THEN class=category of the rule with 2 nd highest fitness value  ELSE IF condition\(s\ for the rule with lowest fitness value  THEN class = category of the rule with lowest fitness value ELSE sample is unclassified   All rules are used in the above format. A situation where a pattern does not fit condition\(s\n any category merits further investigation. As all rules are ranked by their fitness value, fitness value of condition\(s\r each category can also be seen as a probability of belonging to that particular category. If a pattern also does not fit any condition\(s\ in the nested IF-THEN-ELSE format, this implies that the pattern is too hard to be classified and hence it is labeled as unclassifiedê. In reality, however, it actually belongs to one of the categories, but the classifier fails to find its category From observation, experiment, and human intuition suggest an alternative format to the nested IF-THEN-ELSE rules. Considering an analogy where there can only be three categories \(A, B and C\to all patterns. If a pattern is proven that it is neither A nor B, then an assumption can be made that it belongs to C with no verification necessary. Referring back to the nested IF-THEN-ELSE rules above, if a pattern does not fit any condition\(s\from the category with the highest fitness value to the 2 nd lowest fitness value. Declaring it as belonging to the category with the lowest fitness value rule actually carries a lower risk of being incorrect than declaring it as èunclassifiedê. This work proposes an alternative format for the classifier by removing the rule with the lowest fitness value and declaring the pattern belongs to that category if it fails to match all condition\(s\ of the rules for categories with higher fitness value. Hence, there is no possibility of èunclassifiedê pattern. The alternative format is shown below   IF condition\(s\or the rule with highest fitness value  THEN class = category of the rule with highest fitness value ELSE    IF condition\(s\or the rule with 2 nd highest fitness value    THEN  class= category of the rule with 2 nd highest fitness value    ELSE  IF condition\(s\r  the  rule with 2 nd lowest  fitness value THEN class = category of the rule with 2 nd  lowest fitness value ELSE class = category of the rule with lowest fitness value  Experiments have been carried out with the new nested IF-THEN-ELSE rules on numerous test datasets. They were found superior to the one used in previous work. For example, the format used in the previous work [20 wa s te st  on datasets with 002 at 5 It yielded 95 % accuracy while the new format presented here yield 96 % accuracy on the same datasets  VI  S YSTEMATIC I NVESTIGATION OF CCP S C LASSIFIERS   C APABILITY  In order to investigate the full potential of using SAX in preprocessing and SARG in generating classifiers for different sets of CCPs, datasets for the six patterns of CCPs were generated using equations 1 to 6 as stated in Section 2 They were generated with different level of noise in them by varying the parameter 002 in the GARH model  The best classifier is the one which can classify all given set of patterns with 100% accuracy. In practice, however setting a goal to develop a classifier, especially for CCPs which contain high level of noise, with 100% accuracy may be unrealistic. Therefore, this work investigates the full potential of developing classifiers for CCPs by setting two levels of accuracy at 90% and 95% as these two levels are commonly expected and deemed acceptable  As stated in Section 2 002 is the most critical parameter as it dictates the level of noise in the CCPs. Therefore, this work investigated CCPs systematically by generating datasets with 002 at 1, 2, etc. until the SARG was unable to generate a classifier with an accuracy of at least 90 %. The results are discussed in the next section  A dataset at each 002 comprises 800 samples. Each sample consists of 60 interval values. 600 samples were used for the training setê and 200 samples were used for the ètest setê for 
1050 


SARG In order to ensure the validity of the investigation samples in the original dataset were mixed up and three datasets were created. Each contains different samples in both training setê and ètest set  To investigate suitable combination\(s\ for PPA l and Alphabet Size s values in SAX, variation of these two parameters were carried out. Alphabet Size s alues were considered from the breakpoint determination that would produce an equal-sized area under Gaussian curve by referring to a statistical table as suggested in [1 He nc e Alphabet Size s at 2, 3, 4, 5 and 6 were considered in this investigation. As each sample consists of 60 interval values the PPA l alues were selected to be the numbers which can divide 60 exactly without any remainder starting from 2 i.e. 2, 3, 4, 5, 6, 10, 12, 15 and 20\Using PPA l e than 20 is not so meaningful bearing in mind that the purpose of SAX is to transform a time series into symbolic representation. Reducing 60 values to more than 20 values is very unlikely to provide suitable representation for SARG Therefore, there are 45 combinations for these two parameters in SAX for each 002 As 14 values for 002 were considered and three datasets were created for each 002 there were 1,890 processes altogether  Each process \(i.e. generation of a classifier\ was carried out on a personal computer \(PC\ with Intel\(R\ CPU specification of CORE\(TM\2 Duo, E E8600 3.33GHz and 3.25 GB. RAM. Parameters in SARG were set to the same as in previous work [20 e p opu l a t i on s i z e wa s 50 Ea ch process took around 1:25 hrs. to generate a classifier for 500 generations in evolutionary computation unit  VII  R ESULTS  As three datasets were generated for each 002 the method proposed here generated a classifier \(i.e. nested IF-THENELSE rules\ for each dataset. The results of the three classifiers for each 002 were averaged. Table I and II shows the results \(using average values\ of the classifiers for each 002  which could at least achieved 90% level of accuracy \(values are shown in nearest integer for ease of understanding altogether with the PAA l and Alphabet Size s alues  Note that there can be more than one possible combinations for PAA l Alphabet Size s  002 of 1 and 2. This is because there were relatively less noise in their CCPs, which made the proposed method able to generate classifiers with more than one combinations. Once the CCPs datasets contained more noise in them, the task of generating very high accuracy classifiers became very hard without suitable combination for PAA l lphabet Size s  values in preprocessing using SAX. As many types of classifiers exist, producing a classifiers for CCPs with 002 of less than 5 is not a difficult task and several previous works had managed to do so with significantly high level of accuracy If the 90% accuracy threshold is sufficient, the proposed method was able to generate a classifier up to 002 of 13. If a more stringent accuracy threshold of 95 % is required, the proposed method was able to generate a classifier up to 002 of 9. Incidentally, the suitable PAA l ize s  values for both 002  13 and 9 are 3 and 4 respectively TABLE I  CLASSIFICATION ACCURACY FOR EACH 002 AND THEIR PAA L  AND A LPHABET S IZE  S  VALUES  002  Accuracy PAA l  Alphabet Size\(s 1 100 2 3 5 6 3 3 4 3 5 3 2 100 2 3 6 3 100 2  4 4 100 2  5 5 98 3  2 6 100 2  6 7 100 2  6 8 95 3  4 9 95 3  4 10 91 3  6 11 92 3  4 12  92  3  6  13 91 3  4 14 88 3 4 VIII  D ISCUSSION  While it may be possible that suitable PAA l nd Alphabet Size s at different combinations and still yield the same level of accuracy. This work suggests that it is not likely. It is also important to realize that lower number for both PAA l and Alphabet Size s e preferable than higher ones. This is because higher values for these two parameters means more computation time while generating a classifier The pattern of time series under investigation also affect the determination PAA l ize s  using SAX. Intuitively, if the amplitude range in the time series is large, this suggests that more values for PAA l  may be necessary and similar rationale can be said about Alphabet Size s he time series comprises a large numbers of points, a suitable value for Alphabet Size s s likely to be higher too  IX  C ONCLUSION AND F UTURE W ORK  This work affirms that suitable symbolic representations have direct influence to SARG in generating accurate CCPs classifiers. This directly implies that good combination for PAA l ize s for SAX is needed This work systematically investigates these parameters and found that PAA l d Alphabet Size s e best combination for CCPS classification in general. A new and more efficient format for generating a nested IF-THENELSE rules classifier in Final Classifier Builder in SARG is also discovered  Several works had classified CCPs based on GARH model, and all had used 002 at no more than 8. This work is the first to produce CCPs classifiers for with accuracy up to 90 for 002 at 13 and 95 % for 002 at 9. However, it must be borne in mind that high accuracy classification also depends on the 
1051 


level of noises CCPS or in the time series of interest in general. If CCPs \(or any time series\ contain very high level of noise \(i.e. signal to noise ratio is very low\, this simply implies that there are a lot of noise and very little signal in them. In such situation, it is probably impossible to develop a classifier with high degrees of accuracy regardless of technique used  Future work can be carried out in several aspects. Similar study can be carried out on other kinds of time series data to learn more about relationship between PAA l nd Alphabet Size s SAX Other time series benchmarks available in public websites can also be considered  The self-adjusting unit in SARG merits further improvement as this would make it possible to generate more efficient classifiers and possibly with less computation time. Evolutionary operators may be investigated and calibrated to achieve maximum efficiency. At present, a classification rule for each category is taken from the rule with highest fitness value. An alternative method is to improve the Final Classifier Builder to come up with different format rather than a nested IF-THEN-ELSE rules Generating a probabilistic form of classifier similar to those used in Bayesian classifiers may also be investigated A CKNOWLEDGEMENT  The authors gratefully acknowledge the KMUTT research grant for this work and School of Information Technology at KMUTT for its computing facilities  R EFERENCES  1  Domenico Cantone and Simone Faro, çPattern Matching for Control Chart Monitoringé, Springer  Mathematics in Industry, 2008,Volume 12, No.3, pp. 918-922 2  Tim Bollerslev, çGeneralized Autoregressive Conditional Heteroskedasticityé, Journal of Econometrics 31,pp 307-327,1986 3  C.C. Chiu, Y.E. Shao, T.S. LEE and K.M. LEE, çIdentification of process disturbance using SPC/EPC and neural networksé, Journal of Intelligent Manufacturing, 14, 2003, pp. 379-388 4  Pham, D. T. and Oztemel, E., çControl chart pattern recognition using neural networksé,  Journal of Systems Engineering , Vol.2, No.4 pp.256-262,1992 5  Lavangnananda, K. and Tengsriprasert, O., çClassification of Time Series Data: A Synergistic Neural networks Approaché, Proc. of the 9 th Int. Conf. on Neural Information Processing \(ICONIPê02\, 18-22 November, Singapore, Vol.1, 2002, pp. 179-183 6  Pham, D. T., and Chan, A. B., çControl Chart Pattern Recognition using a New Type of Self-Organising Networké, Proc. Instn. Mech Engs., Vol. 212, No. 1, pp. 115-127, 1998 7  Hui-Ping Cheng and Chuen-Sheng  Control Chart Pattern Recognition Using Wavelet Analysis and Neural Networks  Journal of Quality,Vol.16, No.5, pp. 311-321, 2009 8  Hwarng, H. B. and Hubele, N. F., çX-bar chart pattern identification through efficient off-line neural network trainingé, IIE Transactions Vol.25, pp.27-40,1993a 9  Lavangnananda, K. and Kasikitsakulphol, S.,2010, çSystematic Study to Assess Neural Networksê Capability in Classifying Control Chart Patternsé, Proc. of the 2010 IEEE Int. Conf. on Intelligent Computing and Intelligent Systems \(ICIS2010\, 29-31 October, Xiamen, China Vol. 2, PP. 718-722   Pham, D.T. and Sagiroglu, S., çA Comparative Study of Four Multilayered Perceptron Training Algorithmsé, Int. Journal of Machine Tools and Manufacture, Vol. 41, 2001, pp. 419-430   Alcock, R.J. and Manolopoulos, Y., 1999, çTime-Series Similarity Queries Employing a Feature-Based Approaché, Proc. of 7th Hellenic Conference on Informatics, 27-29 August, Ioannina, Greece, 1999 pp. 3.1-3.9   Lavangnananda, K., Piyatumrong, A. and Nakkathon, A., çUtilizing Features Extraction in Classifying Control Chart Patterns using Neural networksé, Proc. of 8 th National Computer Science and Engineering Conference \(NCSEC 2004\-22 October, Songkhla Thailand, 2004, pp. 41-48.\(9   Lavangnananda, K. and Piyatumrong, A., çImage Processing Approach to Features Extraction in Classification of Control Chart Patternsé, Proc. of 2005 IEEE Mid-Summer Workshop on Soft Computing in Industrial Applications \(SMCia/05\, 28-30 June Espoo, Finland, 2005, pp. 85 Ö 90.\(10   Gauri, S. K. and Chakraborty, S.,çRecognition of control chart patterns using  improved selection of featuresé, Computers and Industrial Engineering , Vol.56, No.4, 2004, pp. 1577-1588   Lin, J., Keogh, E., Patel, P. and Lonardi, S., çFinding Motifs in Time Series". In proceedings of the 2nd Workshop on Temporal Data Miningé, Proc. of 8th ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining, 23-26 July, Edmonton, Alberta, Canada 2002   Lin, J., Keogh, E., Lonardi, S. and Chiu, B., çA Symbolic Representation of Time Series, with Implications for Streaming Algorithms.é, Proc. of 8th ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery, 13 June, San Diego, CA., USA, 2003   Alcock R.J. and Manolopoulos, çUsing Genetic Algorithms for Inductive Learningé, Proc. of 3rd Int. Multiconference on Circuit Systems,Communications and Computers \(CSCCê99\, 1999, Athens Greece, 4th Ö 7th July 1999   Lavangnananda, K.,2001  Synergistic Genetic Algorithm for Inductive Learning \(SynGAIL\é, Proc. of the Int. ICSC Congress on Computational Intelligence : Methods and Applications CIMAê2001\, 19-22 June, University of Wales Bangor, U.K., PP 443 Ö 449   Lavangnananda, K., 2004, A Genetic Programming Approach to Inductive Learning, Proc. of the Int. Conf. Computational Intelligence for Modelling, Control and Automation CIMCAê2004\, 12th Ö 14th July, Gold Coast, Australia   Lavangnananda K. and Wongwattanakarn C., çUtilizing Symbolic Representation  and  Evolutionary  Computation  in Classification of Control Chart Patterns.é, Proc. of 2008 IEEE  Mid-Summer Workshop  on  Soft  Computing  in  Industrial Applications SMCia/08\ 2008   Lavangnananda, K., çSelf-adjusting Association Rules Generator for Classification : An Evolutionary Computation Approaché, Proc. of 2006 IEEE Mountain Workshop on Adaptive and Learning Systems SMCals/06\, 24-26 July, Utah, USA., 2006, pp. 237 Ö 242   Keogh, E., Chakrabarti, K., Pazzani, M. and Mehrotra, S., çLocally Adaptive Dimensionality Reduction for Indexing Large Time Series Databasesé, Proc. of ACM SIGMOD Conf. on Management of Data 21-24 May, Santa Barbara, CA., USA. 2001, pp 151-162   Keogh, E., Xi, X., Wei, L., and Ratanamahatana, C. A. 2006. The UCR Time Series Classification/Clustering Homepage http://www.cs.ucr.edu/~eamonn/time_series_data  
1052 


 Figure 4  Compression of the action table from Nursery dataset of size 250Mb into FP-Tree with varying minimum support values VII  C ONCLUSION AND FUTURE WORK  In this paper, we propose the action table as the ideal search domain for action rules mining. The action table transforms the complex problem of finding action rules from a plain decision table, into finding action rules from an action table. As a result, the problem of action rules mining is reformulated into association-mining In practice, we applied FAARM on the Hepatitis and Nursery datasets and compared the results and performances with AAR and ARD. Although the space and time complexity associated with generating the action table are O\(n 2 experiments show that FAARM has a better execution time on relatively small dataset, over ARD and AAR Generating the action table directly into the FP-Tree could mitigate the space complexity associated with action table. As a future work, we propose to look at parallel implementation of Apriori and FP-Growth to test the scalability of using the action table with large datasets R EFERENCES  1  Z. Pawlak, çInformation systems - theoretical foundationsé, Information Systems Journal, Elsevier, Vol 6, 1981, 205-218 2  J. Han, J. Pei, and Y. Yin, çMining frequent patterns without candidate generationé, ACM SIGMOD International Conference on Management of Data, 2000, 1 12 3  Z.W. Ras and A. Wieczorkowska,  "Action-Rules: How to Increase Profit of a Company",  The Fourth European Conference on Principles and Practice of Knowledge Discovery in Databases, 587-592 4  Z. He, X. Xu, S. Deng, R. Ma, çMining action rules from scratché, Expert Systems with Applications, Elsevier, Vol 29, No. 3, 2005, 691-699 5  Z.W. Ras and A. Dardzinska,  "Action Rules Discovery without Pre-existing Classification Rules",   The Sixth International Conference on Rough Sets and Current Trends in Computing, 2008, 181-190 6  Z.W. Ras, A. Dardzinska, L. Tsay,  and H. Wasyluk Association Action Rules",   IEEE International Conference on Data Mining Workshops, 2008, 283-290 7  Qiang Yan, Jie Yin, Charles Ling, Tielin Chen,"Postprocessing Decision Trees to Extract Actionable Knowledge", IEEE International Conference on Data Mining, 2003,  685-688 8  Z.W. Ras and L. Tsay,  "Discovering Extended ActionRules \(System DEAR\,   International IIS IIPWM'03 Conference, 2003, 293-300 9  L. Tsay and Z.W. Ras,  "Action rules discovery: system DEAR2, method and experiments",   Journal of Experimental & Theoretical Artificial Intelligence, 2005 119-128   Z.W. Ras, E. Wyrzykowska,  and H. Wasyluk,  "ARAS Action Rules Discovery Based on Agglomerative Strategy",   Third International Workshop on Mining Complex Data, 2007, 196-208   http://archive.ics.uci.edu/ml/datasets   S. Im and Z.W. Ras,  "Action Rule Extraction from a Decision Table: ARED",   International Syposium on Methodologies for Intelligent Systems, 2008, 160-168   J. S. Deogun, V. V. Raghavan, and H. Sever, çRough set based classification methods and extended decision tables International Workshop on Rough Sets and Soft Computing, 1994, 302-309   R. Agrawl and R. Srikant, çFast algorithm for mining assocation rules,é International Conference on Very Large Data Bases, 1993, 487-499  
404 


a  Figure 1.  The original Share-struct and the steps of S?s change C. Share-FPM algorithm In this subsection, we will develop an efficient algorithm for mining all frequent patterns Algorithm 2 Share-FPM Input: S?, the Share-struct constructed based on Algorithm 1 and s, the minimum support threshold Output: The complete set of frequent patterns Method:Call Share-FPM \(S?,?, s Procedure Share-FPM \(S? ,?, s 1 for each entry si in S 2   if \(si.local-count<s and si->new! =NULL 3     add all si ->news children to the new fields of relevant entries in S 4   else ? =?si; ?-SD = ?-SD 5     if \(si ->new != NULL 6       if si is the only active entry 7         ?-SD=?-SDsi 8         add all children of si to relevant entries in S 9         si ->old= S 10      else ?-Postfix = ?-Postfix ?si 11        if \(si ->old == S 12          call Inherit\(si, S TID Items Bought \(Ordered 100 f, a, c, d, g, i, m, p f, c, a, m, p 200 a, b, c, f, l, m, o f, c, a, b, m, l, o 300 b, f, h, j, o f, b, o 400 b, c, k, s, p c, b, p 500 a, f, c, e, l, p, m, n f, c, a, m, p, l 1431 13        else call Initialize \(S?, si->new, si->old 14        if \(si ->old == NULL 15          flag_upload =TRUE 16        si->old = S 17        call Share-FPM \(S?, ?, s 18        if \(flag_upload ==TRUE 19          call Upload \(S?, S 20    else if \(si ->old ? S 21      ?-SD=?-SD?the items that appear after ? in ?-SD 22      ?-Postfix=the items that appear after ? in ?-Postfix 


23      for each pi in ?-Postfix 24        ? = ??pi 25        ?-SD = the items that appear before pi in ?-SD 26        call Share-FPM \(pi->old, ?, s 27      call Generate-FP \(?, ?-SD, ?-Postfix 28 call Generate-FP \(?,?-SD, ?-Postfix the end of Share-FPM The procedures Inherit, Upload and Generate-FP are shown in the following Procedure Inherit \(s, S if s->old can be released then //memory management S? = s->old else create a new Share-table S? by inheriting s->old call Initialize \(S?, s->new  Procedure Upload \(S?, S for each entry si in S upload all new and old fields in S? to old fields in S add si.local-count in S? to si.local-count in S  Procedure Generate-FP \(?,?-SD, ?-Postfix for each nonempty combination ? of the items in ?-SD generate pattern ?? ? with support minimum support of items in it for each item pi in ?-Postfix for each combination ? of the items which appear before pi generate pattern ?? ? ? pi with support minimum support of items in it  D. Share-UFPM Algorithm According to our mining model description, each utility frequent pattern is also frequent. After Share-FPM algorithm finds all frequent patterns, the Share-UFPM algorithm scans the database once to check whether each frequent pattern candidate algorithm is as follow Algorithm 3 Share-UFPM Input:   S?, s Output:   UFP, utility frequent patterns in DB Method:  Call Share-UFPM\(S?, s 


Procedure Share-UFPM\(S?, s UFP FP = Share-FPM \(S?,?, s for each transaction Ti ? DB for each candidate c ? FP if \(c ? Ti and u \(c, Ti c.support for each candidate c ? FP if \(c.support ? s UFP = UFP + c return UFP  IV. PERFORMANCE STUDY To evaluate the efficiency and effectiveness of our algorithms, we have done extensive experiments on various kinds of datasets with different features. The experiments are based on a 2.4GMHz Pentium IV PC with 512MB main memory and 60 GB hard driver, running on Microsoft Windows 2000 Server. All the programs are written in Microsoft/Visual C++6.0 The measured performance is algorithms execution time on the datasets with different minimum support threshold. The execution time only includes the disk reading time \(scan datasets output frequent patterns speed of disk writing A. Datasets and characteristics We use real world and synthetic data for our performance study. The basic characteristics of datasets are listed in the following The real world dataset called Retail is achieved from a retailing company. Retail contains products from various categories. There are 16469 items and 88162 transactions in the dataset. Each transaction consists of the products purchased by a customer at a time point. Its average transaction size and average maximal potentially frequent patterns size are 10.3 and 3. The size of this dataset is 4M The synthetic data sets which were used for the experiments were achieved from the online FIMI repository See the RUL: http://fimi.cs.helsinki.fi/. The data sets are T10I4D100K and T40I10D100K. In T10I4D100K, the average record size and average maximal potentially frequent patterns 


size are 10 and 4. In T40I10D100K, they are 40 and 10. The numbers of transactions in both two dataset are set to 100K There are exponentially numerous frequent patterns when the support threshold goes down B. Experimental results In order to mine the utility frequent patterns, we randomly generate the count of each item between 1 and 6. In fact, most items are in the low profit range, we synthetically generate utility values of each item from 0.01 to 10.00, using a log normal distribution. For instance, Fig.2 shows the distribution of the utility values of items in T10I4D100K 1432 0 1 2 3 4 5 6 7 8 9 10 0 20 40 60 80 100 120 140 160 180 N um be r o f i te m s Utility value  Figure 2.  Utility value distribution in T10I4D100K For selecting appropriate utility thresholds, we use the average transaction utility value to constraint the utility threshold instead of randomly choosing it. For example, in Table 1, where the average transaction utility value is 40. If the utility threshold is equal to 25%, it represents that ? = 10 40  25% =10 We compare the performance of Share-FPM with BUUFM [5], an up to date algorithm for utility frequent patterns 


mining. Fig.3 through Fig.5 show the performance curves of two algorithms on three datasets respectively. We can see that the Share-UFPM algorithm outperforms BU-UFM on all datasets, and the performance gap becomes significant when the minimum support threshold drops low enough 0.0 0.2 0.4 0.6 0.8 1.0 1.2 0 10 20 30 40 50 60 70 80 90 100 110 120 Ti m e S ec on ds  Minimum support \(%0 Share-UFPM BU-UFM Utility threshold=5  Figure 3.  Fig.12 Utility frequent patterns mining on Retail 0.0 0.2 0.4 0.6 0.8 1.0 0 50 100 150 200 250 300 350 


400 450 500 550 600 Ti m e S ec on ds  Minimum support \(%0 Share-UFPM BU-UFM Utility threshold=5  Figure 4.  Fig.13 Utility frequent patterns mining on T10I4D100K 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 0 50 100 150 200 250 300 350 400 450 500 550 Ti m e S ec on ds  Minimum support Share-UFPM 


BU-UFM Utility threshold=5  Figure 5.  Utility frequent patterns mining on T40I10D100K V. CONCLUSIONS In this paper, we introduce a utility frequent pattern mining model based on a share strategy to find the combination of items with high frequencies and utilities. This model first find all patterns with a given minimum support threshold. In this step, a share strategy gives a way to share most of the results from the previous mining process instead of separating them distinctively, thereby dramatically reducing the cost of computation. And then all patterns that do not satisfy a minimum utility threshold are pruned The extension of our technique, for maintenance of the already mined utility frequent patterns when updating databases, is an interesting topic for future research REFERENCES 1] R. Agrawal, T. Imielinski, A. Swami, Mining association rules between sets of items in large databases, In: Proceedings of the 1993 ACM-SIGMOD, Washington, DC, 1993, 207216 2] J. Han, H. Cheng, D. Xin, X. Yan, Frequent pattern mining: current status and future directions, Data Min knowl Disc 2007, 55-86 3] Y. Liu, W. Liao, A.Choudhary, A two-phase algorithm for fast discovery of high utility itemsets, Lecture Notes in Artificial Intelligence 2005, 3518:689-695 4] Y. Liu, W. Liao, A. Choudhary, A fast high utility itemses mining algorithm, In: Proceeding of the 2005 ACM SIGKDD workshop on utility-based data mining, Chicago, Illinois, USA, 2005, 90-99 5] J. Yeh, Y. Li, C. Chang, Two-phase algorithms for a novel utilityfrequent mining model, Lecture Notes in Artificial intelligence 2007 4819: 433-444 6] C, Aaron, F. John, Association mining, ACM Computing Surveys 2006, 38\(2 7] H.Yao, H. Hamilton, C. Butz, A foundational approach to mining itemset utilities from databases, In: Proceeding of the 4th SIAM International Conference on Data Mining, Lake Buena Vista, Florida 2004, 428-486 8] H. Yao, H. Hamilton, L. Geng, A unified framework for utility based measures for mining itemsets, In: Proceedings of ACM SIGKDD 2nd workshop on utility-based data mining, New York, NY, 2006, 28-37 9] J. Han, M. Kamber, Data mining: concepts and techniques, 2nd edn 


Morgan Kaufmann. 2006 10] J. Han, J. Pei, Y. Yin, Mining frequent patterns without candidate generation, In: Proceeding of the 2000 ACM-SIGMOD international conference on management of data, Dallas, TX, 2000, 112 


2] S. Brin, R. Motwani, J. D. Ullman, and S. Tsur Dynamic Itemset Counting and Implication Rules for Market Basket Data," in Proceedings of the 1997 ACM SIGMOD international conference on Management of data, Tucson, Arizona, United States 1997, pp. 255-264 3] J. S. Park, M. S. Chen, and P. S. Yu, "An Effctive Hash based Algorithm for mining association rules in Prof. ACM SIGMOD Conf Management of Data New York, NY, USA, 1995, pp. 175 - 186 4] R. Agrawal, T. ,PLHOL?VNL DQG $. Swami, "Mining Association Rules between Sets of Items in Very Large Databases," in Proceedings of the 1993 ACM SIGMOD international conference on Management of data, Washington, D.C., 1993, pp. 207-216 5] H. Mannila, H. Toivonen, and A. I. Verkamo Efficient Algorithms for Discovering Association Rules," in AAAI Workshop on Knowledge Discovery in Databases, 1994, pp. 181-192 6] R. Srikant and R. Agrawal, "Mining Generalized Association Rules," in In Proc. of the 21st Int'l Conference on Very Large Databases, Zurich Switzerland, 1995 7] R. Srikant, Q. Vu, and R. Agrawal, "Mining association rules with item constraints," in In Proc 3rd Int. Conf. Knowledge Discovery and Data Mining, 1997, pp. 67--73 8] A. Savasere, E. Omiecinski, and S. B. Navathe, "An Efficient Algorithm for Mining Association Rules in Large Databases," in Proceedings of the 21th International Conference on Very Large Data Bases 1995, pp. 432 - 444 9] H. Mannila, "Database methods for data mining," in The Fourth International Conference on Knowledge Discovery and Data Mining, 1998 10] B. Liu, W. Hsu, and Y. Ma, "Mining Association Rules with Multiple Minimum Supports.," in SIGKDD Explorations, 1999, pp. 337--341 11] H. Yun, D. Ha, B. Hwang, and K. H. Ryu, "Mining association rules on significant rare data using relative support.," Journal of Systems and Software archive vol. 67, no. 3, pp. 181 - 191, 2003 


12] M. Hahsler, "A Model-Based Frequency Constraint for Mining Associations from Transaction Data Data Mining and Knowledge Discovery, vol. 13, no 2, pp. 137 - 166, 2006 13] L. Zhou and S. Yau, "Association rule and quantitative association rule mining among infrequent items," in International Conference on Knowledge Discovery and Data Mining, San Jose, California 2007, pp. 156-167 14] C. Ordonez, C. Santana, and L. d. Braal, "Discovering Interesting Association Rules in Medical Data," in Proccedings of ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery, 2000, pp. 78-85 15] L. J. Sheela and V. Shanthi, "DIMAR - Discovering interesting medical association rules form MRI scans," in 6th International Conference on Electrical Engineering/Electronics, Computer Telecommunications and Information Technology 2009, pp. 654 - 658 16] C. Ordonez, N. Ezquerra, and C. A. Santana Constraining and summarizing association rules in medical data," Knowledge and Information Systems vol. 9, no. 3, pp. 259 - 283, September 2005 17] H. Pan, J. Li, and Z. Wei, "Mining Interesting Association Rules in Medical Images," Lecture Notes In Computer Science, vol. 3584, pp. 598-609, 2005 18] S. Doddi, A. Marathe, S. S. Ravi, and D. C Torney Discovery of association rules in medical data Medical Informatics and the Internet in Medicine, vol 26, no. 1, pp. 25-33, January 2001 86 


the time needed for execution exceeded 100000 seconds Thus, from this analysis we see that FPrep, which uses FCM clustering, clearly outperforms the CLARANS and CURE based methods on the basis of speed. The execution times for CLARANS and CURE mentioned in fig. 7 and Table II do not include the time required to create fuzzy sets, and calculate the membership value  for each numerical data point in every fuzzy set for the numerical attribute under consideration. These times also do not take into account the time required to transform crisp numerical attributes to fuzzy attributes, and derive the fuzzy dataset from the original crisp dataset The fuzzy partitions generated for each of the five numerical attributes for the USCensus1990raw dataset are shown in Table III. Coincidentally, generating three fuzzy partitions for each numerical attribute seemed a perfect fit In addition to the superior speeds achieved by FPrep, as illustrated in fig. 7 and Table II, Table III indicates the semantics and the quality of the fuzzy partitions generated by FPrep. Moreover, the number of frequent itemsets generated by a fuzzy ARM algorithm \(like fuzzy ARMOR and fuzzy Apriori minimum support threshold, is illustrated in fig. 8   Fig. 7. Algorithm, numerical attribute comparison based on speed \(log10 seconds   Fig. 8. Number of frequent itemsets for various minimum support values  B. Results from Second Dataset We have also applied FPrep on the FAM95 dataset http://www.stat.ucla.edu/data/fpp transactions. Of the 23 attributes in the dataset, we have used the first 18, of which six are quantitative and the rest are binary. For each of the six quantitative attributes, we have generated fuzzy partitions using FPrep. A thorough analysis with respect to execution times, has already been performed on the USCensus1990raw dataset \(which is manifolds bigger in size than the FAM95 dataset both on the basis of number of transactions and number of unique values for numerical 


attributes dataset has been done solely to provide further evidence of the quality and semantics of the fuzzy partitions generated by FPrep. The details of the same are in Table IV. In this case, the number of fuzzy partitions is different for different numerical attributes. Thus, the number and type of fuzzy partitions to be generated is totally dependent on the attribute under consideration. A graphical representation of the fuzzy partitions generated for the attribute Age has already been provided in fig. 5, and clearly shows the Gaussian nature of the fuzzy partitions. The nature and shapes of fuzzy partitions for the rest of the attributes are also similar. Last, the number of frequent itemsets generated for different minimum support values is illustrated in fig. 8  C. Analysis of Results With FPrep, we can analyze and zero in on the number and type of partitions required based on the semantics of the numerical attributes, which the methods detailed in [19 20] do not necessarily facilitate. Then, FPrep, backed by FCM clustering, takes care of the creating the fuzzy partitions, especially assigning membership values for each numerical data point in each fuzzy partition. In section 8.A we have already shown that FPrep is nearly 9 to 44 times faster than the CURE-based method, and 2672 to 13005 times faster than the CLARANS-based method. FPrep is not only much faster than other related methods, but also generates very high quality fuzzy partitions \(Table III and IV much user-intervention. We have created a standard way of representing any fuzzy dataset \(converted from any type of crisp dataset efficacy of the same is corroborated by the successful implementation of Fuzzy Apriori and Fuzzy ARMOR on the fuzzy dataset \(converted from crisp version of FAM95 dataset an initial implementation of Fuzzy ARMOR, are very encouraging. FPrep, when used in conjunction with these fuzzy ARM algorithms, generates a pretty good number of high-quality frequent itemsets \(fig. 8 frequent itemsets generated for a particular minimum support is same, irrespective of the fuzzy ARM algorithm 


used IX. CONCLUSIONS In this paper we have highlighted our methodology, called FPrep, for ARM in a fuzzy scenario. FPrep is meant for seamlessly and holistically transforming a crisp dataset into a fuzzy dataset such that it can drive a subsequent fuzzy ARM process. It does not rely on any non-fuzzy techniques and is thus more straightforward, fast, and consistent. It facilitates user-friendly automation of fuzzy dataset 1 0 1 2 3 4 5 Age - 91 Hours - 100 Income3 4949 Income2 13707 Income1 55089 Ti m e lo g1 0 se co nd s Numerical Attribute - Number of Unique Values FCM CURE CLARANS 0 500 1000 1500 2000 2500 


3000 0.075 0.1 0.15 0.2 0.25 0.3 0.35 0.4 N o o f F re qu en t I te m se ts Minimum Support USCensus1990 FAM95 generation through FCM, and subsequent steps in preprocessing with very less manual intervention and as simple and straightforward manner as possible. This methodology involves two distinct steps, namely creation of appropriate fuzzy partitions using fuzzy clustering and creation of fuzzy records, using these partitions, to get the fuzzy dataset from the original crisp dataset FPrep has been compared with other such techniques, and has been found to better on the basis of speed. We also illustrate its efficacy on the basis of quality of fuzzy partitions generated and the number of itemsets mined by a fuzzy ARM algorithm which is preceded by FPrep. This preprocessing technique provides us with a standard method of fuzzy data \(record that it is useful for any kind of fuzzy ARM algorithm irrespective of how the algorithm works. Furthermore, this pre-processing methodology has been adequately tested with two disparate fuzzy ARM algorithms, Fuzzy Apriori and Fuzzy ARMOR, and would also work fine with other fuzzy ARM algorithm REFERENCES 1] Zadeh, L. A.: Fuzzy sets. Inf. Control, 8, 338358 \(1965 2] Chen G., Yan P., Kerre E.E.: Computationally Efficient Mining for Fuzzy Implication-Based Association Rules in Quantitative Databases. International Journal of General Systems, 33, 163-182 


2004 3] Hllermeier, E.: Fuzzy methods in machine learning and data mining Status and prospects. Fuzzy Sets and Systems. 156, 387-406 \(2005 4] De Cock, M., Cornelis, C., Kerre, E.E.: Fuzzy Association Rules: A Two-Sided Approach. In: FIP, pp 385-390 \(2003 5] Yan, P., Chen, G., Cornelis, C., De Cock, M., Kerre, E.E.: Mining Positive and Negative Fuzzy Association Rules. In: KES, pp. 270-276 Springer \(2004 6] De Cock, M., Cornelis, C., Kerre, E.E.: Elicitation of fuzzy association rules from positive and negative examples. Fuzzy Sets and Systems, 149, 7385 \(2005 7] Verlinde, H., De Cock, M., Boute, R.: Fuzzy Versus Quantitative Association Rules: A Fair Data-Driven Comparison. IEEE Transactions on Systems, Man, and Cybernetics - Part B: Cybernetics 36, 679-683 \(2006 8] Dubois, D., Hllermeier, E., Prade, H.: A systematic approach to the assessment of fuzzy association rules. Data Min. Knowl. Discov., 13 167-192 \(2006 9] Dubois, D., Hllermeier, E., Prade, H.: A Note on Quality Measures for Fuzzy Association Rules. In: IFSA, pp. 346-353. Springer-Verlag 2003 10] Hllermeier, E., Yi, Y.: In Defense of Fuzzy Association Analysis IEEE Transactions on Systems, Man, and Cybernetics - Part B Cybernetics, 37, 1039-1043 \(2007 11] Agrawal, R., Imielinski, T., Swami, A.N.: Mining Association Rules between Sets of Items in Large Databases. SIGMOD Record, 22, 207216 \(1993 12]  Agrawal, R., Srikant, R.: Fast Algorithms for Mining Association Rules. In: VLDB, pp. 487-99. Morgan Kaufmann \(1994 13] Han, J., Pei, J., Yin, Y.: Mining Frequent Patterns without Candidate Generation. In: SIGMOD Conference, pp. 1-12. ACM Press \(2000 14] Han, J., Pei, J., Yin, Y., Mao, R.: Mining Frequent Patterns without Candidate Generation: A Frequent-Pattern Tree Approach. Data Mining and Knowledge Discovery, 8, 5387 \(2004 15] Pudi V., Haritsa J.R.: ARMOR: Association Rule Mining based on Oracle. CEUR Workshop Proceedings, 90 \(2003 16] Dunn, J. C.: A Fuzzy Relative of the ISODATA Process and its Use in Detecting Compact, Well Separated Clusters. J. Cyber., 3, 32-57 1974 17] Hoppner, F., Klawonn, F., Kruse, R, Runkler, T.: Fuzzy Cluster Analysis, Methods for Classification, Data Analysis and Image Recognition. Wiley, New York \(1999 


18] Bezdek J.C.: Pattern Recognition with Fuzzy Objective Function Algorithms. Kluwer Academic Publishers, Norwell, MA \(1981 19] Fu, A.W., Wong, M.H., Sze, S.C., Wong, W.C., Wong, W.L., Yu W.K. Finding Fuzzy Sets for the Mining of Fuzzy Association Rules for Numerical Attributes. In: IDEAL, pp. 263-268. Springer \(1998 20] Kaya, M., Alhajj, R., Polat, F., Arslan, A: Efficient Automated Mining of Fuzzy Association Rules. In: DEXA, pp. 133-142. Springer \(2002 21] Mangalampalli, A., Pudi, V. Fuzzy Association Rule Mining Algorithm for Fast and Efficient Performance on Very Large Datasets In FUZZ-IEEE, pp. 1163-1168. IEEE \(2009 22] Kaya, M., Alhajj. Integrating Multi-Objective Genetic Algorithms into Clustering for Fuzzy Association Rules Mining. In ICDM, pp. 431434. IEEE \(2004  Table II. Algorithm, numerical attribute comparison based on speed \(seconds  Algorithm Age - 91 Hours - 100 Income3 - 4949 Income2 - 13707 Income1 - 55089 FCM 0.27 0.3 3.13 6.28 79.4 CURE 0.25 0.25 28.67 163.19 3614.13 CLARANS 1.3 1.34 8363.53 78030.3 Table III. Attributes and their fuzzy partitions  Attribute Fuzzy Partitions Age Old Middle Aged Young Hours More Average Less Income1 High Medium Low Income2 High Medium Low Income3 High Medium Low  Table IV. Attributes and their fuzzy partitions  Attribute Fuzzy Partitions AGE Very old Around 25 Around 50 Around 65 Around 35 HOURS Very High Zero Around 40 Around 25 INCHEAD Very less Around 30K Around 50K Around 100K INCFAM Around 60K Around 152K Around 96K Around 31K Around 8K TAXINC Around 50K Around 95K Around 20K Very less FTAX Around 15K Very less Around 6K Very high Around 33K  


the US census data set. The size of pilot sample is 2000, and all 50 rules are derived from this pilot sample. In this experiment the ?xed value x for the sample size is set to be 300. The attribute income is considered as a differential attribute, and the difference of income of husband and wife is studied in this experiment. Figure 3 shows the performance of the 5 sampling 331 6DPSOLQJ9DULDQFH             9D UL DQ FH R I V WL PD WL RQ  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW    


      6D PS OL QJ  RV W 9DU 9DU 9DU 5DQG b 6DPSOLQJ$FFXUDF          5  9DU 9DU 9DU 5DQG c Fig. 2. Evaluation of Sampling Methods for Association Rule Mining on the Yahoo! Dataset procedures on the problem of differential rule mining on the US census data set. The results are also similar to the experiment results for association rule mining: there is a consistent trade off between the estimation variance and sampling cost by setting their weights. Our proposed methods have better performance than simple random sampling method 


We also evaluated the performance of our methods on the Yahoo! dataset. The size of pilot sampling is 2000, and the xed value x for the sample size is 200. The attribute price is considered as the target attribute. Figure 4 shows the performance of the 5 sampling procedures on the problem of differential rule mining on the Yahoo! dataset. The results are very similar to those from the previous experiments VI. RELATED WORK We now compare our work with the existing work on sampling for association rule mining, sampling for database aggregation queries, and sampling for the deep web Sampling for Association Rule Mining: Sampling for frequent itemset mining and association rule mining has been studied by several researchers [23], [21], [11], [6]. Toivonen [23] proposed a random sampling method to identify the association rules which are then further veri?ed on the entire database. Progressive sampling [21], which is based on equivalence classes, involves determining the required sample size for association rule mining FAST [11], a two-phase sampling algorithm, has been proposed to select representative transactions, with the goal of reducing computation cost in association rule mining.A randomized counting algorithm [6] has been developed based on the Markov chain Monte Carlo method for counting the number of frequent itemsets Our work is different from these sampling methods, since we consider the problem of association rule mining on the deep web. Because the data records are hidden under limited query interfaces in these systems, sampling involves very distinct challenges Sampling for Aggregation Queries: Sampling algorithms have also been studied in the context of aggregation queries on large data bases [18], [1], [19], [25]. Approximate Pre-Aggregation APA  categorical data utilizing precomputed statistics about the dataset Wu et al. [25] proposed a Bayesian method for guessing the extreme values in a dataset based on the learned query shape pattern and characteristics from previous workloads More closely to our work, Afrati et al. [1] proposed an adaptive sampling algorithm for answering aggregation queries on hierarchical structures. They focused on adaptively adjusting the sample size assigned to each group based on the estimation error in each group. Joshi et al.[19] considered the problem of 


estimating the result of an aggregate query with a very low selectivity. A principled Bayesian framework was constructed to learn the information obtained from pilot sampling for allocating samples to strata Our methods are clearly distinct for these approaches. First strata are built dynamically in our algorithm and the relations between input and output attributes are learned for sampling on output attributes. Second, the estimation accuracy and sampling cost are optimized in our sample allocation method Hidden Web Sampling: There is recent research work [3 13], [15] on sampling from deep web, which is hidden under simple interfaces. Dasgupta et al.[13], [15] proposed HDSampler a random walk scheme over the query space provided by the interface, to select a simple random sample from hidden database Bar-Yossef et al.[3] proposed algorithms for sampling suggestions using the public suggestion interface. Our algorithm is different from their work, since our goal is sampling in the context of particular data mining tasks. We focus on achieving high accuracy with a low sampling cost for a speci?c task, instead of simple random sampling VII. CONCLUSIONS In this paper, we have proposed strati?cation based sampling methods for data mining on the deep web, particularly considering association rule mining and differential rule mining Components of our approach include: 1 the relation between input attributes and output attributes of the deep web data source, 2 maximally reduce an integrated cost metric that combines estimation variance and sampling cost, and 3 allocation method that takes into account both the estimation error and the sampling costs Our experiments show that compared with simple random sampling, our methods have higher sampling accuracy and lower sampling cost. Moreover, our approach allows user to reduce sampling costs by trading-off a fraction of estimation error 332 6DPSOLQJ9DULDQFH      


     V WL PD WL RQ R I 9D UL DQ FH  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW          6D PS OL QJ  RV W 9DU 9DU 


9DU 5DQG b 6DPSOLQJ$FFXUDF          5  9DU 9DU 9DU 5DQG c Fig. 3. Evaluation of Sampling Methods for Differential Rule Mining on the US Census Dataset 6DPSOLQJ9DULDQFH             9D UL DQ FH R I V WL 


PD WL RQ  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW          6D PS OL QJ  RV W  9DU 9DU 9DU 5DQG b 6DPSOLQJ$FFXUDF         


    5  9DU 9DU 9DU 5DQG c Fig. 4. Evaluation of Sampling Methods for Differential Rule Mining on the Yahoo! Dataset REFERENCES 1] Foto N. Afrati, Paraskevas V. Lekeas, and Chen Li. Adaptive-sampling algorithms for answering aggregation queries on web sites. Data Knowl Eng., 64\(2 2] Rakesh Agrawal and Ramakrishnan Srikant. Fast algorithms for mining association rules. In Proceedings of the 20th International Conference on Very Large Data Bases, pages 487499, 1994 3] Ziv Bar-Yossef and Maxim Gurevich. Mining search engine query logs via suggestion sampling. Proc. VLDB Endow., 1\(1 4] Stephen D. Bay and Michael J. Pazzani. Detecting group differences Mining contrast sets. Data Mining and Knowledge Discovery, 5\(3 246, 2001 5] M. K. Bergman. The Deep Web: Surfacing Hidden Value. Journal of Electronic Publishing, 7, 2001 6] Mario Boley and Henrik Grosskreutz. A randomized approach for approximating the number of frequent sets. In ICDM 08: Proceedings of the 2008 Eighth IEEE International Conference on Data Mining, pages 4352 Washington, DC, USA, 2008. IEEE Computer Society 7] D. Braga, S. Ceri, F. Daniel, and D. Martinenghi. Optimization of Multidomain Queries on the Web. VLDB Endowment, 1:562673, 2008 8] R. E. Ca?isch. Monte carlo and quasi-monte carlo methods. Acta Numerica 7:149, 1998 9] Andrea Cali and Davide Martinenghi. Querying Data under Access Limitations. In Proceedings of the 24th International Conference on Data Engineering, pages 5059, 2008 10] Bin Chen, Peter Haas, and Peter Scheuermann. A new two-phase sampling based algorithm for discovering association rules. In KDD 02: Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 462468, New York, NY, USA, 2002 ACM 


11] W. Cochran. Sampling Techniques. Wiley and Sons, 1977 12] Arjun Dasgupta, Gautam Das, and Heikki Mannila. A random walk approach to sampling hidden databases. In SIGMOD 07: Proceedings of the 2007 ACM SIGMOD international conference on Management of data pages 629640, New York, NY, USA, 2007. ACM 13] Arjun Dasgupta, Xin Jin, Bradley Jewell, Nan Zhang, and Gautam Das Unbiased estimation of size and other aggregates over hidden web databases In SIGMOD 10: Proceedings of the 2010 international conference on Management of data, pages 855866, New York, NY, USA, 2010. ACM 14] Arjun Dasgupta, Nan Zhang, and Gautam Das. Leveraging count information in sampling hidden databases. In ICDE 09: Proceedings of the 2009 IEEE International Conference on Data Engineering, pages 329340 Washington, DC, USA, 2009. IEEE Computer Society 15] Loekito Elsa and Bailey James. Mining in?uential attributes that capture class and group contrast behaviour. In CIKM 08: Proceeding of the 17th ACM conference on Information and knowledge management, pages 971 980, New York, NY, USA, 2008. ACM 16] E.K. Foreman. Survey sampling principles. Marcel Dekker publishers, 1991 17] Ruoming Jin, Leonid Glimcher, Chris Jermaine, and Gagan Agrawal. New sampling-based estimators for olap queries. In ICDE, page 18, 2006 18] Shantanu Joshi and Christopher M. Jermaine. Robust strati?ed sampling plans for low selectivity queries. In ICDE, pages 199208, 2008 19] Bing Liu. Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data \(Data-Centric Systems and Applications Inc., Secaucus, NJ, USA, 2006 20] Srinivasan Parthasarathy. Ef?cient progressive sampling for association rules. In ICDM 02: Proceedings of the 2002 IEEE International Conference on Data Mining, page 354, Washington, DC, USA, 2002. IEEE Computer Society 21] William H. Press and Glennys R. Farrar. Recursive strati?ed sampling for multidimensional monte carlo integration. Comput. Phys., 4\(2 1990 22] Hannu Toivonen. Sampling large databases for association rules. In The VLDB Journal, pages 134145. Morgan Kaufmann, 1996 23] Fan Wang, Gagan Agrawal, Ruoming Jin, and Helen Piontkivska. Snpminer A domain-speci?c deep web mining tool. In Proceedings of the 7th IEEE International Conference on Bioinformatics and Bioengineering, pages 192 199, 2007 24] Mingxi Wu and Chris Jermaine. Guessing the extreme values in a data set a bayesian method and its applications. VLDB J., 18\(2 25] Mohammed J. Zaki. Scalable algorithms for association mining. IEEE Transactions on Knowledge and Data Engineering, 12:372390, 2000 


333 



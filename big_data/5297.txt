 











    
maximum flow solution algorithm, which is actually to obtain the flow with maximum cost by the above algorithm The obtained result is also a series of path of the maximum similarity values. The system controls the display of the predicted numbers of tracks according to the requirements of users, while gives more priority to the track with higher prediction probability for display. Besides, the system has a modification module, which is capable of selfrevising according to the correction command submitted by users, including modifying the structure of cost-network  recalculating and rebuilding new prediction track Modification module can fix some errors produced by the procedure of videos analysis and process, thus improve the robustness of the system  Figure 2. The example of a cost-flow network D A large surveillance system sometimes contains more than thousands of cameras which forms a huge camera network. If we want to track targets within the whole network, the amount of calculation is extremely enormous To overcome this obstacle, in our approach, the camera network is divided into several independent sub-network units according to the characteristics of its topology relationship The target association algorithm then can be carried on independently at the same time The sub-graph partition should not destroy the structure of the camera network, so that the trajectory calculated in each sub-graph unit can be easily linked to form the total vehicle trajectory. In our system, the sub-graph network division algorithm should follow several principles. For each subgraph      1, 2 satisfies a Completeness Principles: For each target, if its appeared node then the last disappeared node  satisfied In reverse, if the targetês disappeared node  001\031  and the target appears again, then the next appeared node satisfied  001\031  b Minimization Principles: The amount of nodes in each unit should be as small as possible on condition of the completeness principle. It means that the camera network should be divided elaborately to get sub-graph units as many as possible The completeness principle makes sure the complete independence of each unit, so that all nodes involved are within the sub-graph unit when calculating the associate relationship of the targets, and do not need exchange information with other units. Only each sub-graph remains independent, can the trajectory connect into the whole track The minimization principle makes the structure of each subgraph unit as small as possible, cannot be re-split, which guarantees the minimum calculation overhead of the associated algorithm The method of devising the camera network into subgraph units is as follow: in a field of camera view, if an appeared node only connected with a disappeared node  then remove the dotted connection between them and put  and into two different sub-graph units. Eventually the entire camera network turns into an unconnected graph. Take in Figure 1 as an example, the appeared node is only connected with the disappeared node then remove the edge   between them, makes and assigned into two different sub-graph unit. The method of dividing the whole network into sub-networks provides the distributed intelligent video surveillance system with strong support. It is possible to build some local process units to process video information, and the local process units only transmit key information to the central process unit for deeper analysis Our system applies the framework of MapReduce based on Hadoop to realize the parallel computing of all sub-graphs First, different tasks from different sub-graphs are mapped to different MapReduce nodes for track analysis independently Then, all information will be returned to central server to be reduced by the presented approach mentioned in previous sub-sections IV E XPERIENCES AND P ERFORMANCE  To verify the effectiveness of the approach presented in this paper, a batch of vehicle monitoring videos from 23 cameras in the real campus security monitoring system of HUST\are applied and analyzed. All videos are in the resolution of 1920◊1080 with 25 frames per second. 8 non-overlapping cameras with 5-minute durations are selected for evaluation These dataset are challenging because: i\ the roads monitored are two-way with lots of intersections, that makes the tracking environment more complicated; ii\ due to the shadows of many trees along the roads in the campus, the colors and illuminations of the vehicle objects tracked change obviously across cameras; iii\ the traffic are relative heavy. For example in the selected cameras, more than 500 vehicles passed through the cameras; iv\ high resolution video takes much time to process. The map view is shown in Figure 3 For evaluation of tracking, the tracking metric in [1  is used. Evaluation results across multiple cameras are shown in Table I. In the table indicate the number of real vehicles captured by the specified cameras is the successful tracking rate within a camera. It is hard to get all tracks of all objects precisely. If the degree of accuracy of a target tracked is more than 90% compared to the 
G Camera Network Sub-graph Partitioning A A p i q j i j m q j 001\031 A p i p i 001\031 A p j A q k q k A q i p j q i p j C 3 q 1 p 4 e q 1 p 4 q 1 p 4 Huazhong University of Science and Technology real targets Track recall 
1217 
1217 


Real targets Track recall Mostly tracked Partially tracked Mostly lost 
corresponding real track, it is considered as  see Table I\. Since the time span of the group video data is limited, some vehicle tracks are broken off, which are marked as Since some conditions of camera views are not perfect enough, when a car disappears in the view which goes beyond the detection area, it is marked as  also includes those cars that disappear in blind regions  Figure 3. Cameras for evaluation on the map TABLE  I  E VALUATION OF MULTI CAMERA TRACKING  For the location measure, enter/exit area is defined for each camera and their connections across cameras are used as spatial features. For the time measure, the mean and variance between two corresponding enter/exit areas is learned during the training stage. A single Gaussian distribution is used to model the object travel time. In this practical traffic surveillance system, since all cameras are deployed in a campus, the distance between two neighbor cameras is not far Most of them are 50-200 meters, and the speeds of most vehicles in the campus are between 10-40km/h. Table II shows the parameters for enter/exit areas pairs during the training stage TABLE  II  L EARNED PARAMETERS OF TIME MEASUREMENT FOR  ASSOCIATED ENTER  EXIT AREA PAIRS  Since the classification method we used concerns primarily with the front area of the vehicle, the identifying accuracy is poor when a target shows only the back part in the camera views. However, it is a good opportunity to test how robustly the system can run in such a serious situation Some vehicle objects of correct tracking across 6 major cameras are shown in Figure 4, while some of incorrect tracking are shown in Figure 5  Eight serials of monitoring videos with duration of 5 minutes are processed by the server with 2.26 GHz 2xIntel Xeon E5520 CPU. The amount of objects we detected is 233 We use two ways to search for the tracks. One is the traditional Bayesian method, the other is our MCMF\ethod 
Camera number Average Pair of Enter/Exit Area Arrival time \(second Mean Variation  Camera 1 Camera 2 Camera 3 Camera 4 Camera 5 Camera 6 Camera 1 Camera 2 Camera 2 Camera 3 Camera 2 Camera 4  
1 15 100% 15 0 0 2 46 87.0% 37 3 6 3 43 90.7% 36 3 4 4 39 97.4% 36 2 1 5 34 100% 30 4 0 6 38 92.1% 31 4 3 7 9 77.8% 5 2 2 8 9 77.8% 5 2 2 30.38 90.35 24.38 2.5 2.25 A Camera 1-2 8.5 7.5 Camera 2-3 6 9 Camera 3-4 11.5 3.5 Camera 4-5 7 7 Camera 5-6 3 3 Camera 6-7 14 1 Camera 7-8 5 2 Additionally, since there are two intersections in the blind regions and there is a traffic light in one of the eight camera views, the variation of the link between them is set slightly looser Location, time, SURF, HOG, and LBP are used for appearance measure. Here, the weights for the location, time SURF, HOG and LBP are set to: 1, 1, 0.85, 0.22, and 0.55  respectively, based on experiments  B Figure 4. Objects of correct tracking across six major cameras Figure 5. Objects of incorrect tracking \(marked by red crosses  C 
   
mostly tracked partially tracked mostly lost Mostly lost Location, Time and Appearance Measures Overall Performance of Multi-camera Tracking Computational Time minimum cost and maximum flow 
1218 
1218 


3 1534 1013 34 6 4112 2763 33 10 5873 4279 27 12 5627 4628 18 15 18811 12461 34 17 13195 10567 20 8192 5951.83 27.5 TABLE  IV  C OMPARATION ON ACCURACY   3 100% 100% 1:1 6 100% 100% 1:1 10 100% 100% 1:1 12 50% 57.14% 1:1.14 15 58.33% 83.33% 1:1.42 17 53.33% 70% 1:1.31 76.94% 85.08% 1:1.11 V J. Berclaz, F. Fleuret, and P. Fua, çRobust people tracking with global trajectory optimizationé, in Proceedings of IEEE Conference on Computer Vision and Pattern Recogn ition \(CVPRê06\, 2006, pp.744750 2 B. Wu and R. Nevatia, çDetection and tracking of multiple, partially occluded humans by Bayesian combination of Edgelet based part detectorsé, in International Journal of Computer Vision, Vol.75, No.2 November 2007, pp.247-266 3 N. Anjum and A. Cavallaro, çTrajectory association and fusion across partially overlapping camerasé, in Proceeding of IEEE International Conference on Advanced Video and Signal Based Surveillance AVSSê09\, 2009, pp.201-206 4 C. del-Blanco, R. Mohedano, N. Garcia, L. Salgado, and F Jaureguizar, ç Color-based 3D particle filtering for robust tracking in heterogeneous environmentsé, in Proceedings of second ACM/IEEE International Conference on Distributed Smart Cameras \(ICDSCê08 2008, pp.1-10 5 W. Youlu, S. Velipasalar, and C. Gursoy, çDistributed wide-area multi-object tracking with non-overlapping camera viewsé, in Multimedia Tools and Applications, 2012, pp.1-33  6 O. Javed, K. Shafique, and M. Shah, çAppearance modeling for tracking in multiple nonoverlapping camerasé, in Proceeding of IEEE Conference on Computer Vision and Pattern Recognition \(CVPRê05 vol.2, 2008, pp.26-33 7 B. Prosser, S. Gong, and T. Xiang, çMulti-camera matching using bidirectional cumulative brightness transfer functionsé, in Proceeding of the British machine vision conference \(BMVCê08\ Vol. 8, 2008 pp.1-10 8 T. DêOrazio, P. Mazzeo, and P. Spagnolo, çColor brightness transfer function evaluation for non-overlapping multi camera trackingé, in Proceeding of ACM/IEEE international Conference on Distributed Smart Cameras \(ICDSCê09\ 2009, pp.1-6 9 W. Youlu, L. He, and S. Velipasalar, çReal-time distributed tracking with non-overlapping camerasé, in Proceedings of IEEE Conference on Image Processing \(ICIPê10\, 2010, pp.697-700  A. Chilgunde, P. Kumar, S. Ranganath, and W. Huang, çMulticamera target tracking in blind regions of cameras with nonoverlapping fields of viewé, in Proceeding of the British Machine Vision Conference \(BMVCê04\4, pp.1-10  E. Monari, J. Maerker, and K. Kroschel, çA robust and efficient approach for human tracking in multi-camera systemsé, in Proceeding of the IEEE International Conference on Advanced Video and Signal Based Surveillance \(AVSSê09\, pp.134Ö139  J. Kang, I. Cohan, and G. Medioni, çPersistent objects tracking across multiple non overlapping camerasé, in Proceeding of the IEEE workshop on Motion and Video Computing \(WACV/MOTIONSê05 vol.2, 2005, pp.112-119  R. Pflugfelder and H. Bischof, çTracking across non-overlapping views via geometryé, in Proceeding of the International Conference on Pattern Recognition \(ICPRê08\, 2008, pp.1-4  Y. Shan, S. Sawhney, and R. Kumar, çUnsupervised Learning of Discriminative Edge Measures for Vehicle Matching between NonOverlapping Camerasé, in Proceeding of the International Conference on Pattern Recognition \(ICPRê05\, 2005, pp.894-901  A. Rahimi, B. Dunagan, and T. Darrell, çSimultaneous calibration and tracking with a network of non-overlapping sensorsé, in Proceeding of IEEE Computer Society Conference on Computer Vision and Pattern Recognition \(CVPRê04\ 2004, pp.187-194  W. Leoputra, T. Tan, and L. Lim, çNon-overlapping Distributed Tracking using Particle Filteré, in Proceeding of 18th International Conference on Pattern Recognition \(ICPRê06\6, pp.181-185  T. Huang and S. Russell, çObject identification: a Bayesian analysis with application to traffic surveillanceé, in Artificial Intelligence 1998, pp.77Ö93  L. Zhang, Y. Li, and R. Nevatia, çGlobal Data Association for MultiObject Tracking Using Network Flowsé, in Proceeding IEEE Conference on Computer Vision and Pattern Recognition \(CVPRê08 2008, pp.1-8  B. Song, and A. K. Roy-Chowdhury, çStochastic adaptive tracking in a camera networké, in Proceeding IEEE Conference on Computer Vision and Pattern Recognition \(CVPRê08\ 2008, pp.1-8 
 
In accuracy, the contrast ratio between our method and the Bayesian method is 1:1.11; in the computation time, our method increases about 27.5%. Table III shows the comparison of detail computational time taken by two methods and Table IV shows the accuracy comparison  TABLE  III  C OMPARATION ON COMPUTATIONAL TIME  C ONCLUSIONS  In this paper, we present a new vehicle tracking surveillance approach with non-overlapping views in multicamera. A framework to perform robust multiple targets tracking across multiple cameras is discussed. The multiobjects in multi-camera data association problem is formed with a minimum cost and maximum flow mode. For robust multi-camera tracking, time, location, classification type, and appearance of targets are effectively applied as a similarity measure. The approach is tested with real surveillance videos from the campus of HUST. The experimental results validate the robustness and effectiveness of the approach Experimental results also indicate that the method of tracking across multiple cameras is feasible after a high quality of feature extraction and target detection. For future work, more efficient and effective appearance models and feature extraction are desired to increase the accuracy of the approach A CKNOWLEDGMENT  This work is supported by National Natural Science Foundation of China under grant No.61133008 R EFERENCES  1 
                   
Record amount Computational time Bayesian 002 ms 002  MCMF 002 ms 002  Performance improvement Average Record amount Accuracy Bayesian MCMF Comparison Average 
1219 
1219 


 H. Jiang, S. Fels, and J. Little, çA linear programming approach for multiple object trackingé, in Proceeding IEEE Conference on Computer Vision and Pattern Recognition \(CVPRê07\, 2007, pp.1-8  N. Dalal and B. Triggs, çHistograms of oriented gradients for human detectioné, in Proceeding of IEEE Computer Society Conference on Computer Vision and Pattern Recognition \(CVPRê05\, 2005, Vol.1 pp.886-893  T. E. Choe, Z. Rasheed, G. Taylor, and N. Haering, çGlobally optimal target tracking in real time using max-flow networké, in Proceedings of IEEE International Conference on Computer Vision Workshops ICCVWê11\, 2011, pp.1855-1862 
   
1220 
1220 


state of innovation stakeholder  node PQ It  s a balanced node Based on this, we could calculate the  node PQ Calculation process is: set different inn ovation stakeholders state i U  and j U Value of ij 000T can be get from  innovation time difference. Innovation stakeholdersí social effect and industrial effect can be obtained upon ij B  and ij G set according to relation between innovation stakeholders  Model 4.1 points out  that the value of Gij  directly affects social benefits and sector benefits. Large Gij  can lead to increasing benefits of the entire industry and the entire social growth Bij reflects big organizationís impact on businesses. Only strengthening the inter agent association within big organization and enhancing the str ategic partnership between enterprises can jointly promote the development of the entire industry, and bring more social benefits, so that each agent can be improved   5 Summary This paper puts forward the concept of the big organization based on the CSM t heory. It introduces the basic implication of the big organization and theoretical framework of the big organization including: the big organization's perspective  overall perspective, dynamic perspective, and new resource perspective; the big organizat ionís sense  the purpose of the organizational structure is innovation, organizational activities around the flow of information, breaking the traditional organizational structure, encouraging self run structure, and blurring organizational boundaries; the big organizationís platform  the platform ecosystem of the big organization ; the big organizationís operation mode  borderless learning mode, and cluster effect; the big organizationís theory  active management theory  leading consumers, and culture  entropy reduction theory  negative culture entropy and humanistic ecology theory  inspiring humanity, and circuit theory  a virtuous circle, and collaborative innovation theory  collaborative innovation stakeholder. This paper also discusses culture entropy reduction theory of the big organization  negative culture entropy, and coordinated innovation theory  innovation stakeholders collaboration. Culture entropy change model and collaborative in novation model are constructed   The research has just begun for the big organization. It also needs further improvement but remains the trend of the times   Reference  1  Gordon Pellegrinetti, Joseph Bentsman. Nonlinear Control Oriented Boiler Modeling A Benchmark Problem for Controller De sign [J  I E E E tr a n s a c tio n s o n c o n tr o l s y s te m s te c h n o lo g y 2 0 1 0  4 1\57 65  2  Klaus Kruger, Rudiger Franke, Manfred Rode Optimization of boiler start up using a nonlinear 457 


boiler model and hard constraints [J  E n e r gy 201 1 29   22 39 2251  3  K.L.Lo, Y.Rathamarit  State estimation of a boiler model using the unscented Kalman filter [J  I E T  Gener. Transm. Distrib.2008 2 6\917 931  4  Un Chul Moon, Kwang. Y.Lee. Step resonse model development for dynamic matrix control of a drum type boiler turbine system [J IE E E  T ra nsactions on Energy Conversion.2009 24 2\:423 431  5  Hacene Habbi, Mimoun Zelmat, Belkacem Ould Bouamama. A dynamic fuzzy model for a drum boiler turbine system [J  A u to m a tic a 2 0 0 9 39:1213 1219  6  Beaudreau B C. Identity, entropy and culture J   J o ur na l  o f  economic psychology, 2006, 27\(2 205 223  7  YANG M, CHEN L. Information Technique and the Entropy of Culture J  A cad e m i c E x ch a n g e  2006, 7: 048  8  ZHANG Zhi feng. Research on entropy change model for enterprise system based on dissipative structure J  Ind ustrial  Engineering and  Management 2007, 12\(1\ :15 19  9  LI Zhi qiang, LIU Chun mei Research on the Entropy Change Model for Entrepreneurs' Creative Behavior System Based on Dissipative Structure J  C h i n a S of t S c i e n c e  2009   8  1 62 166   458 


A Global Solution COVERAGE North and South America EMEA and Asia White lines are flights in the masFlight platform from February 8, 2013 Yellow pins are weather stations feeding hour ly data to our platform Maps from Google Earth / masFlight masFlight tracks flights, airports and weather around the world  Global daily flight information capture  82,000 flights  350 airlines  1700 airports  Integrated weather data for 6,000 stations  Match weather to delays  Validate block forecasts at granular level  Add weather analytics to IRROPS review and scenario planning 


Example 1: Proposed FAA Tower Closures masFlight used big-data to link airport operations across three large data sets  Current and historical airline schedules  Raw Aircraft Situation Display to Industry \(ASDI\AA  Enhanced Traffic Management System Counts \(ETMS\Airport operations counts by type \(commercial, freight, etc TOWER CLOSINGS Dots indicate closures; Red dots have scheduled service Based on scheduled service March 1 7, 20 13; scheduled service includes scheduled charter flights, cargo flig hts, and passenger flights Dots  indicate  closures  Red  dots  have  scheduled  service Bas ed  o n sc h edu l ed  se rvi ce  M a r c h 1  7, 2013; scheduled se rvi ce includ es scheduled c harter fli g hts car g o fli g hts a nd passen g er fli g hts Findings: Proposed Tower Closings  From schedules database: 55 airports with scheduled passenger airline service  14 EAS Airports  From ASDI & ETMS: 10,600 weekly flights on a flight plan \(ex. VFR and local traffic  6,500 Part 91/125 weekly flights  4,100 Part 135/121 weekly flights  


Example 1: Big-Data Analytics Applied to ASDI and ETMS To Analyze Operations TOWER CLOSINGS  26 44 24 23 11 10 6 2 1 2 Up to 5 5-10 10-15 15-20 20-25 25-30 30-35 35-40 40-45 45 Count of Airports Average Number of Daily Operations with a Flight Plan Filed Distribution of Airports By Average Number of ìDailyî Impacted Flights Airports Affected by Tower Closures Source: ASDI radar data ñ Part 91 151 flying and Part 135/121 flying March 1-7, 2013; masFlight analysis Note: Average ìdailyì operations based on 5-day week 


Example 2: Aviation Safety Causal Factor For example, consider the following ASRS report \(ACN 1031837 Departing IAH in a 737-800 at about 17,000 FT, 11 m iles behind a 737-900 on the Junction departure over CUZZZ Intersection. Smooth air with wind on the nose bearing 275 degrees at 18 KTS We were suddenly in moderate chop which lasted 4 or 5 seconds then stopped and then resumed for another 4 or 5 seconds with a significant amount of ri ght rollingÖ I selected a max rate climb mode in the FMC in order to climb above the wake and flight path of the leading -900 We asked ATC for the type ahead of us and reported the wake encounter. The 900 was about 3,300 FT higher than we were  Synopsis  B737-800 First Officer reported wake encounter from preceding B737-900 with resultant roll and moderate chop What causal factors can be identified from this narrative that could be applied to future predictive applications CAUSAL FACTORS Data-mining algorithms can mine the text of safety reports to obtain specific data that can be used to analyze causal factors  


Example 2: Identifying Causal Factors CAUSAL FACTORS  Indicators ñ Data Element Methods ñ Identifying Context and Causes  Time of day  Date range \(month day  Aircraft type  Fix or coordinates  Originating airport  Destination airport  Weather notes We pinpoint the sequencing of flights on the IAH Junction Seven departure \(at CUZZZ\the specified wind conditions to find cases wher e a B737-900 at 20,000 feet precedes by 11 miles a B737-800 at 17,000 feet  Search related data sets including ASDI flight tracks, local traffic and congestion  Weather conditions for alter native causes \(winds aloft shear and convecti ve activity  Airline specific informati on \(repeated occurrence of event in aircraft type Big data gives us visibility into contextual factors even if specific data points are missing such as a specific date or route Big-data analytics gives us insight into unreported factors as well 


Example 3: Correlating Utilization and Delays  60 65 70 75 80 85 90 95 100 7 9 11 13 ONTIME DEPARTURE PERFORMANCE HOURS OF DAILY UTILIZATION 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Narrowbodies By Day of Week 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Widebodies by Day of Week Daily Utilization vs. On-time Departures January 2013 System Operations Correlation Coefficient -0.53 Includes AA, AC, AS B6 F9, FL, NK, UA, US VX and WN SOURCE masFlight \(masflight.com COMPARING OTP AND UTILIZATION 


 6.2 6.0 5.8 5.8 5.2 4.9 LGB JFK BOS MCO DCA FLL JetBlue Focus Average Daily Deps per Gate Used UTILIZATION BY HUB Example 4: Daily Utilization of Gates, by Hub Big-data analysis of different carriers daily departures per gate used SOURCE masFlight \(masflight.com June 1 through August 31, 2012 Gates with minimum 1x daily use 7.7 7.4 7.2 6.2 6.1 5.8 3.8 3.6 ORD LAX SFO EWR DEN IAH IAD CLE United Airlines Hubs Average Daily Deps per Gate Used 7.8 6.4 5.5 5.4 5.3 4.4 4.3 4.0 SEA SAN PDX ANC SFO GEG LAX SJC Alaska Airlines Hubs Average Daily Deps per Gate Used 7.2 6.9 6.8 6.4 5.0 2.7 ORD DFW LAX LGA MIA JFK American Hubs Average Daily Deps per Gate Used 7.2 6.9 6.6 4.9 4.2 CLT DCA PHL PHX BOS US Airways Hubs Average Daily Deps per Gate Used 6.6 5.9 5.5 4.7 MCO BWI ATL MKE AirTran Hubs Average Daily Deps per Gate Used ne pe 


Conclusions for Big Data in Aviation  Big-data transforms operational and commercial problems that were practically unsolvable using discrete data and on-premises hardware  Big data offers new insight into existing data by centralizing data acquisition and consolidation in the cloud and mining data sets efficiently  There is a rich portfolio of information that can feed aviation data analytics  Flight position, schedules, airport/gate, weather and government data sets offer incredible insight into the underlying causes of aviation inefficiency  Excessive size of each set forces analysts to consider cloud based architectures to store, link and mine the underlying information  When structured, validated and linked these data sources become significantly more compelling for applied research than they are individually  Todayís cloud based technologies offer a solution CONCLUSIONS 


Conclusions:  Our Approach  masFlightís data warehouse and analysis methods provide a valuable example for others attempting to solve cloud based analytics of aviation data sets  masFlightís hybrid architecture, consolidating secure data feeds in on-premises server installations and feeding structured data into the cloud for distribution, addresses the unique format, security and scale requirements of the industry  masFlightís method is well suited for airline performance review competitive benchmarking, airport operations and schedule design and has demonstrated value in addressing real-world problems in airline and airport operations as well as government applications CONCLUSIONS 






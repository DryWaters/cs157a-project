An Artificial Immune Algorithm for Association Rule Mining among Concepts with Uncertainty Hongyu Di Sun’an Wang School of Mechanical Engineering Xi’an Jiaotong University Xi’an, Shaanxi, P.R. China dishtony@163.com Abstract During a design procedure of association rule mining approach, there are two common issues: the transformation method from continuous quantitative attributes to qualitative concepts, and efficiency of data mining. In order to acquire association rules in a database with different types of attributes, the cloud transformation which is included in the cloud model theoretical framework is applied as an uncertain concept extraction tool in this paper. By the feature analysis of association rule mining in uncertain concept space, the frequent item-set generation is converted to a combination optimization problem. A modified object function and artificial immune algorithm for association rule mining are designed accordingly. A novel method of non-frequent item hyper set detection is introduced to reduce the number of database scanning and improve the efficiency. The numerical experiments show that the proposed algorithm can accomplish the association rule mining by global random search, with the robustness that the computational cost is insensitive with the variation of threshold parameters   Index Terms Association rule, cloud model, artificial immune algorithm, non-frequent item hyper set I  I NTRODUCTION  Association rule mining is an important technique of data mining. From a large scale database, it could extract hidden correlations among qualitative concepts, which could be regarded as background knowledge of business decision making, market analysis, and inventory management. What’s more, it has great potential in pattern recognition and signal processing. Since the Apriori algorithm  was proposed by R Agrawal [1, 2  m a ny a sso c i at i o n r u l e m i ni ng a ppr oa c h e s and efficiency increasing methods had been researched [3, 4   s u ch  as FP-growth\(Frequent Pattern growth\, DHP\(Direct Hashing and Pruning\, tree projection, genetic algorithm, sampling parallelization, et al. All of these association rule mining techniques have to solve two basic problems: The first is how to get qualitative concepts from quantitative attribute data by an inductive process which could transform the continuous attribute into concept space, so that different type of attributes can be mined. The second is how to reduce the computational cost in large scale data mining, i.e. how to improve the mining efficiency Language is the carrier of thought and representation of concept, hence linguistic terms or concepts are usually treated as the basic units in human cognition procedure. Nevertheless the concept expressed by linguistic words has uncertainty characteristics [5  Tra d it ion al clas s i f i cat ion  m eth od  w h ich  c a n  be called hard partition, usually divides continuous attribute into discrete concepts by distinct thresholds. The hard partition method is not in accord with cognitive habits in many fields therefore many granular computing methods, such as fuzzy set rough set, cloud model, type-2 fuzzy set, quotient space theory and so on, are developed to externalize the uncertainty [6   T h e cloud model, which was proposed by Deyi Li [7, 8  w a s  widely researched in recent years because it has the ability of synthetically describing both the randomness and fuzziness of concepts with uncertainty. In the theoretical framework of cloud model, the cloud transformation is applied in this paper as a tool that convert quantitative attributes into concepts with uncertainty, thus the association rule mining could be implemented in an uncertain concept space Apriori is a classic association rule mining algorithm which has two phases: frequent item-set generation and rule confidence examination. Because the stepwise traversal search method is used in the frequent item-set generation, the database needs to be scanned repetitively that became the bottleneck of this algorithm. Artificial immune algorithm is an effective stochastic global optimization search method h i c h ha s  features of robustness and implicit parallelism. If the frequent item-set generation could be converted to a combination optimization problem, the application of artificial immune algorithm would improve the efficiency of association rule mining. Some attempts in the similar way [10, 11 g a in e d  satisfied results In this paper, the cloud transformation method, which could extract concepts with uncertainty, is introduced. The features of association rule mining in uncertain concept space are analyzed Based on these features, an optimization object function is proposed, and an artificial immune algorithm is designed correspondingly. Furthermore, a modification method, which is called non-frequent item hyper set detection, is applied to reduce the number of databases scan operation 2015 IEEE 11th International Colloquium on Si g nal Processin g its Applications \(CSPA2015 y sia 978-1-4799-8249-3/15/$31.00 ©2015 IEEE 15 


II  C LOUD M ODEL AND C LOUD T RANSFORMATION  Cloud model is proposed by Deyi Li as a bidirectional transformation tool between numeric values and linguistic concepts [7 I t  i s de fi ned a s  be lo w U is a qualitative universe described by precise numeric values, and C is a qualitative concept on U If a quantitative value x U  and x is a random instantiation of concept C The certainty degree  x  C  0, 1   which describes that x belongs to C is a random number with a stable tendency  0,1   UxUxxC      1 then the distribution of x on universe U is defined as a cloud and x is called as a cloud drop. It’s obviously that a cloud is the representation of a concept with uncertainty In the cloud model, a cloud concept can be described by three numeric measures: expected value Ex entropy En and hyper-entropy He denoted as C  Ex  En  He  A  Normal Cloud Model In practical applications, due to most of random variables obey normal or approximate normal distribution, the normal cloud model is widely used [1 Wh en t h e c l ou d d r o p  x obeys a normal distribution x~N  Ex, En 2 and the variance obeys another normal distribution En’~N  En, He 2 if the certainty degree  x, C  x to concept C satisfied   2 2    exp 2  x Ex xC E n  2 then the distribution of x on universe U can be called  a normal cloud model Especially when He 0, the certainty degree  x, C  cloud model C will degenerate to  a fuzzy membership function it can be regarded as the mean expectation curve of cloud C  denoted as  2 2   exp 2 C x Ex MEC x En   3 MEC C  x represents the fuzzy nature of a cloud model under the two-fold random, and it also describes the basic characters of a linguistic concept B  Cloud Transformation and Concept Extraction According to Bernoulli’s law of large numbers, when enough random instantiation data were acquired, the probability density function of data could be estimated by frequency distribution histogram with small interval. The function of frequency curve can be regard as an approximation of the probability density function f  x  The distribution of cloud drops, which belong to the cloud concept C can be described by MEC C  x so MEC C  x n be regarded as the expected probability density function of x In the database, if the f  x f a quantitative attribute x is known, it can be divided into multiple clouds’ mean expectation curves which is called cloud transformation, as shown in Eq. 4   1  0,1 i n iC i i Amp MEC x fx Amp       4 Where Amp i is an amplitude coefficient n is the total number of cloud concepts The curve fitting method is used in cloud transformation to determine the value of Amp i  Ex i and En i Furthermore, the value of He i is estimated by the fitting error. The attribute x is reflected to n cloud concepts by the cloud transformation, and each C i has a certainty degree  x  C i As shown in Fig. 1, the frequency curve is converted to a superposition of two clouds Fig. 1  Cloud transformation III  A SSOCIATION R ULES ON U NCERTAIN C ONCEPT S PACE  According with the association rule definition in distinct attributes, an association rule in uncertain concept attributes can be defined as follows: Let I  I 1 I 2 I m be a set of m uncertain concept attributes T be a transaction that contains a subset of items T I  D be a database of transaction records If two item-sets C A  and C B are contained in T  C A T  C B T  and they do not have any common concept item   C A C B  then an association rule is an implication in the form of C A C B  C A is called antecedent while C B is called consequent. When a rule mining task concerns the state of C B  C A contains decision attributes while C B contains task attributes Quantitative attributes could be mapped into uncertain concept space by cloud transformation that proposed in the above. Hence every quantitative decision attribute Ai can be expressed as a combination of Pi concepts C Ai  C Ai1 C Ai2  C Aij C AiPi on the universe U Ai meanwhile the task attribute B can be expressed as a combination of Q concepts C B  C B1  C B2 C Bk C BQ on the universe U B Association rule mining is implemented in a space of uncertain concepts C R   C A11 C A12 C Am-1Pm-1 C B1 C B2 C BQ   Support and confidence are two basic measures for an association rule. Support S f C Aij C Bk is defined as the 2015 IEEE 11th International Colloquium on Si g nal Processin g its Applications \(CSPA2015 y sia 16 


       occurrence probability shown in Eq. 5, which can be calculated by the fraction of the number of records that contain C Aij C Bk to the number of all records in the database   Aij Bk Aij Bk SC C PC C   5 Confidence T  C Aij C Bk is defined as the conditional probability shown in Eq. 6, which can be calculated by the fraction of the number of records that contain C Aij C Bk to the number of records that contain C Aij    Aij Bk Bk Aij Bk Aij Aij TC C PC C PC C PC  6 The threshold of support S min and the threshold of confidence T min are usually predefined by users to determine whether a rule is useful or interesting. However in the uncertain concept space, it should be noticed that only when the certainty degree of a record x to a concept C ij  is greater than or equal to T min i.e  x, C ij  T min the record x can be regarded as a realization of C ij For a high-dimension uncertain concept combined by some low-dimension concepts, the certainty degree of high-dimension concept is determined by the minimum certainty degree of low-dimension concepts, as shown in Eq. 7  12 1 2   min     xC C xC xC  7 Accordingly, only when  x, C Aij  T min  and  x, C Bk  T min  record x can be regarded as a realization of rule C Aij C Bk  IV   A N A RTIFICIAL IMMUNE ALGORITHM FOR A SSOCIATION R ULE M INING  Frequent item-set generation method is the determinant of efficiency in all association rule mining approaches. If the task attribute of a rule is fixed, finding the decision attributes combination, which is built up by frequent items, is an optimization problem. Artificial immune algorithm has the ability of global optimization in an implicit parallel search procedure, so that it can be applied in association rule mining In this section, an artificial immune algorithm for association rule mining \(AIARM\designed, and the implementation and modification processes are introduced A  Artificial immune optimization algorithm Learning the mechanism of specific antibodies generation in biological immune response produce, artificial immune algorithm is a novel optimization algorithm that modifies the simple genetic algorithm \(SGA\ by utilizing the characteristic information of object problem to avoid degeneration. In the application of association rule mining, rules can be regarded as antibodies, while the evaluations of rules in a database can be regarded as antigens. Since the sequence arrangement of concepts in a rule’s antecedent has no effect with the rule’s establishment, all concepts that might occur in the antecedent and consequent can be arranged in a binary code string to represent the rule. The antibody coding is shown in Fig. 2 When the value on a coding position is 1, it means the concept of this coding position is an element of the rule. Otherwise when the value is 0, it means the concept of this coding position is not an element of the rule. Hence each association rule can be represented by an antibody’s binary code string Fig. 2  Antibody coding In immune optimization searching procedure, the initial antibody population is randomly generated, and the clone and mutation are used as two main operators to generate next generation of antibody population. According to the evaluation result of affinity between antigen and antibody, the antibody population is updated after the better antibodies are stored in the antibody memory. The antibody memory is designed to transmit concept item sets of better rules to next generation which is a simulation of biological immune memory phenomena. Meanwhile a rule memory is built to save all rules that satisfy the thresholds examination of support and confidence in the search history. When the iterative search is terminated, the best antibody in the antibody memory is the optimal solution, and all association rules are stored in the rule memory B  Affinity function design Mutual recognition between antigen and antibody is the foundation of specific immunity. This recognition is simulated by affinity function calculating in artificial immune algorithm design processes. Affinity describes the degree of gene matching between antibody and antigen, or between two antibodies.  The aim of optimization is to find the antibody that has the biggest affinity with antigen. Since an association rule is represented by an antibody Rx the comprehensive performance measure of the rule can be treated as the antigen affinity AF  Rx i.e. the object function of the optimization problem Besides support and confidence, the coverage N s another important measure for a rule. It’s defined as the conditional probability shown in Eq. 8, which can be calculated by the fraction of the number of records that contain C Aij C Bk to the number of records that contain C Bk  The confidence measures the sufficient degree while the coverage measures the necessary degree of a rule    Aij Bk Aij Bk Aij Bk Bk NC C PCC PCCPC   8 Because support, confidence and coverage are probability calculations, their product can be treated as a comprehensive performance measure. Meanwhile the threshold constrains should be considered, thus the antigen affinity function of Rx is designed in the form of Eq. 9 2015 IEEE 11th International Colloquium on Si g nal Processin g its Applications \(CSPA2015 y sia 17 


     AF Rx hs S Rx ht T Rx N Rx  9 Where hs nd ht e threshold limitation functions, they are shown in Eq. 10 and Eq. 11  min min    0 SRx SRx S hs S Rx SRx S      10  min min    0 TRx TRx T ht T Rx TRx T      11 The antibody affinity is a measure of similarity degree of two rules. Two antibodies Rx v and Rx w represented by two binary code strings has an antibody affinity AF  Rx v  Rx w  shown in Eq. 12     1 1  M vw vj wj j AF Rx Rx Rx Rx M     12 Where Rx v,j and Rx w,j are the values on the j coding  position of Rx v and Rx w respectively;  is an XOR operator C  Clone probability calculation In biological immune systems, an antibody have a higher antigen affinity can be cloned to next generation with a bigger probability. At the same time, the effect of competitive exclusion restrains the antibodies with high density, so that the diversity is not easy to be lost in the antibody population. The density of an antibody Rx v can be calculated by antibody affinities, as shown in Eq. 13  1 11  1  A AA S vk kkv v SS vk vkkv AF Rx Rx D\(Rx  AF Rx Rx 012 012     13 Where S A is the scale of antibody population Both the antigen affinity and density of an antibody Rx are considered, the clone probability can be calculated in Eq. 14      C P Rx AF Rx D Rx  14 The clone operation is executed by this probability, so that the antibodies with high antigen affinities are stimulated in the population, as well as the diversity is maintained D  Algorithm implementation process The algorithm implementation process of AIARM is described as follows   Step1. Initialization: initialize the antibody population with a scale of S A and randomly sample S M  antibodies to build the antibody memory   Step2. Antibody evaluation and rule extraction calculate the antigen affinity AF  Rx and density D  Rx  of each Rx so that the P C  Rx n be gotten. After removing duplicate rules, all rules satisfied AF  Rx  0 would be stored in rule memory   Step3. Antibody memory updating: arrange all the antibodies in descending order of clone probabilities use the top S M antibodies to rebuild antibody memory   Step4. Iterative termination determination: if the termination condition is satisfied, quit the iteration process. Otherwise, go to Step 5   Step5. Antibody population updating: implement the clone selection of antibodies by P C  Rx If an antibody is not selected to be clone, it mutates with a predefined probability. Go to Step 2 AIARM transfers the information of better antibodies directly to next generation by clone operation, and realize the global random search by mutation operation. The antibody memory eliminates the degeneration of antibody population and the rule memory save all interesting rules that were found in the iterative search E  Non-frequent item hyper set detection When AIARM evaluates an antibody, the database needs to be scaned once. Since new rules are generated by random search in AIARM, there will be a lot of rules combined by nonfrequent items and AF  Rx 0. To decrease the database scan number, the non-frequent hyper set detection is designed as a modified method of AIARM According to the basic logic law in Apriori that a high order frequent item is combined by some lower order frequent items it can be known that the support value of a rule Rx which includes a non-frequent item in item-set must be lower than S min then the antigen affinity AF  Rx Because an antibody is coded in the form of binary string which represents a combination of concepts, an antibody is exactly an item-set and the relationship of two antibodies can be described by subset or hyper-set For an antibody Rx whose consist item codes are not all 0 if any concept item whose value is 1  in Rx is also values as 1 in another antibody Ry then Rx is defined as a hyper set of Ry  while Ry is a sub set of Rx The relationship can be denoted in Eq. 15  R yRx  15 If there is a relationship Ry Rx of two antibodies, in support calculating they must fulfill the inequality     SRy S Rx  16 Furthermore, if Rx is  a non-frequent item set S  Rx  S min  it’s sub set Ry must be a non-frequent item set, and the antigen affinity of Ry must be zero A non-frequent item hyper set memory can be built to save the common hyper sets of antibodies that are non-frequent item 2015 IEEE 11th International Colloquium on Si g nal Processin g its Applications \(CSPA2015 y sia 18 


sets. Thus for a new antibody Rx need to be evaluated, the nonfrequent item hyper set detection can be implemented before antigen affinity calculation. If Rx was a sub set of a record in the memory, then AF  Rx 0, so that the database scan in antigen affinity calculation could be canceled. Only the antibodies that are confirmed as not sub sets need to calculate the antigen affinities. If a new non-frequent item set was found during the antigen affinity calculation, a common hyper set extraction method could be used to update the memory The non-frequent item hyper set detection is realized in binary coding space. With small computational cost, this method could decrease the database scan number significantly and improve the efficiency of AIARM V  C ALCULATION E XAMPLE A NALYSIS  The abalone database in UCI machine learning repository 13 is s e lec te d as a c a l c u l ati on  ex am ple to tes t t h e  performance of AIARM. In this database, there are 4177 records. Every record has 8 quantitative attributes and one classification information of 3 classes. By the means of cloud transformation, 8 quantitative attributes can be converted to 21 cloud concepts. Moreover, when both the entropy and hyperentropy are equal to zero, a cloud can represent a qualitative concept of hard partition. Hence the classification information can be expressed by 3 cloud concepts. Thus every record can be transformed to certainty degrees of 24 cloud concepts, and every association rule consists of a combination of 24 cloud concepts The sex classification attributes of abalone database are selected as task attributes. Within constrains of different S min  and T min Apriori and AIARM are used to mine the rules in abalone database. The numbers of rules mined by two algorithms are compared in TABLE I. The numbers of rules in the column of AIARM are average results of 20 times operation TABLE I  C OMPARISON OF M INED R ULES   N UMBER  Threshold Number of rules support confidence Apriori AIARM 10% 50 58 57.4 10% 60 34 33.8 15% 50 20 20 15% 60 9 9 20% 50 8 8 20% 60 2 2 Apriori uses the stepwise traversal search method to generate frequent item-set and it can get all association rules without any missing. In TABLE I, it can be seen that AIARM can get most of the rules by a random search The database scan number of Apriori and AIARM are shown respectively in TABLE II. In the low support threshold conditions, the number of AIARM is significantly less than the number of Apriori. Conversely, in the high support threshold conditions, the number of AIARM is bigger than the number of Apriori. The database scan number of AIARM is determined by the feature of random search, a certain amount of database scanning for antibody population evaluating can not be avoided TABLE II  C OMPARISON OF D ATABASE S CAN N UMBER  Threshold Database scan number support confidence Apriori AIARM 10% 50 18348 7064 10% 60 12514 6352 15% 50 10152 5493 15% 60 6257 5628 20% 50 5264 6092 20% 60 2788 6533 However, it should be noticed that these numbers of AIARM keep relatively stable in various constrains, and all iterative times are less than 100. AIARM has strong robustness of computational cost, so it can be used in an interactive association rule mining whose threshold constrains vary frequently. AIARM will neither waste a lot of time in frequent item-set generating as Apriori in low support threshold condition, nor construct decision trees repeatedly as FP-growth VI  C ONCLUSIONS  In this paper different types of attributes are converted into an uncertain concept space by cloud transformation, thus any quantitative or qualitative attribute of a record can be represented by a certainty degree set of cloud concepts that describe the attribute. The correlations among these cloud concepts are association rules. An optimization object function for mining these rules is constructed and an artificial immune algorithm AIARM  is proposed. In this algorithm, frequent item-sets are generated by random searches and the rules can be extracted. To improve the efficiency, a non-frequent item hyper set detection method is designed to reduce the times of database scanning. The result of numeric experiments shows that AIARM could accomplish the task of association rule mining in different threshold constrains with a relatively stable computational cost A CKNOWLEDGMENT  This research was supported by National Natural Science Foundation of China, under Grant NSFC51375368 R EFERENCES  1  R. Agrawal, T. Imielinske, A. Swami, “Mining association rules between sets of items in large databases,” in Proc of the ACM SIGMOD Int 'l Conf on the Management of Data, Washington USA, 1993, pp. 207-216 2  R. Agrawal, R. Srikant, “Fast algorithms for mining association rules in large databases,” Proceedings of the 20 th international conference on very large data bases, Santiago, Chile, 1994 pp.487-499 3  J. Dixit, A. Choubey, “A survey of various association rule mining approaches,” International Journal of Advanced Research in Computer Science and Software Engineering, vol 4, no. 3, 2014, pp. 651-655 2015 IEEE 11th International Colloquium on Si g nal Processin g its Applications \(CSPA2015 y sia 19 


4  S. Kotsiantis, D. Kanellopoulos, "Association rules mining: A recent overview", International Transactions on Computer Science and Engineering, vol.32, no.1, 2006, pp.71-82 5  A. Bargiela, W. Peddrycz, “Toward a theory of granular computing for human-centered information processing,” IEEE Trans on Fuzzy Systems, Vol.16, no. 2, 2008, pp.320-330 6  Y.Y. Yao, “Granular computing: past, present and future,” IEEE International Conference on Granular Computing, Hangzhou China, 2008, pp.80-85 7  D.Y. Li, Y. Du, “Artificial Intelligence with Uncertainty Beijing: National Defend Industry Press, 2005 8  D.Y. Li, C.Y. Liu, W.Y. Gan, “A new cognitive model: Cloud model,” International Journal of Intelligent Systems, vol. 24, no 3, 2009, pp. 357–375 9  L. Wang, J. Pan, L.C. Jiao, “The Immune Algorithm,” Acta Electronica Sinca, vol. 28, no. 7, 2000, pp. 74-78 10  T. Zeng, C. Tang, Y. Xiang, et al., “A model of immune gene expression programming for rule mining,” Journal of Universal Computer Science, vol. 13, no. 10, 2007, pp.1484-1497 11  Mining fuzzy rules using an artificial immune system with fuzzy partition learning,” Applied Soft Computing, vol. 11, no 2, 2011, pp. 1965-1974 12  D.Y. Li, C.Y. Liu, “Study on the universality of the normal cloud model,” Chinese Engineering Science, vol. 6, 2004, pp 28-34 13  C.L. Blake, C.J. Merz, “UCI repository of machine learning databases,” http://www.ics.uci.edu.html  2015 IEEE 11th International Colloquium on Si g nal Processin g its Applications \(CSPA2015 y sia 20 


E Impacted Coef\002cient of the Additional Itemset De\002nition 13 The impacted coef\002cient of an additional itemset is to describe how effective this itemset is to manufacture the derivative itemset from underlying itemset denoted as AU G 001 X j X 0   de\002ned as AU G 001 X j X 0   r C 2 001 X j X 0   W 2 001 X j X 0  2 14 This equation averages the value of C 001 X  in Equation 9 and W 001 X  in Equation 11 Here we use the Quadratic Mean QM also known as Root-Mean Square to measure the signi\002cance of the itemset 001 X in terms of both utility and relationship perspectives because it represents the sample standard deviation of the difference between W and C  thus the result cannot be affected heavily by the smaller value It is easy to prove QM 2  X    X  2  033 2  X  15 Here X and 033  X  stand for the arithmetic mean and the standard deviation of W and C  We also tried another measurement by Harmonic Mean HM as a baseline which is proven to be less effective in our experiments For a speci\002c X 0  for each itemset 001 X to be considered the higher AUG means this itemset is likely to impel the underlying itemset into higher utility itemset On the contrary the lower the AUG is the lower utility that derivative itemset might be As all the AUG would be calculated only the largest AUG value itemset will be chosen F The CUARM Algorithm In this section an algorithm named Combined UtilityAssociation Rule Mining CUARM is proposed to discover all the actionable combined utility-association rules At the beginning of the algorithm it picks all UIs as candidates For each UI all the combined patterns are discovered with their AUGs which form a combined pattern cluster as in Equation 2 and only the most effective pattern would be selected In addition if two patterns are coupled with utility increment and decrement a combined pattern pair forms The input is the transaction database including all transactions with the utility of each item and the output is the combined pattern pairs their underlying itemset and the corresponding utilities In line 1 we prepare all the itemsets with their utilities in the alphabetical order and the length of longest itemset In lines 2-5 we start with each of the UIs named itemset 0 with its utility U 0  In lines 6-11 the DIs are ready and we calculate their AUGs In line 12-13 we select the pattern with max AUG values as CUAR V E XPERIMENTS In this section we conduct intensive experiments to evaluate the proposed methods Our experiments were run on a PC with a 2.30 GHz Intel Core 16 gigabyte memory CUARM is implemented in Java Two real datasets and two synthetic datasets are used for the experiments The real Algorithm 1 CUARM Input  Transaction database D  including the utility U  X  of each item in D Output  All actionable combined utility-association rules 1 Get all itemsets utilities via UG-Tree  2 Get the length of longest itemset lmax  3 for len  1 len  lmax len do 4 for Itemset whose length is equal to len do 5 Get itemset 0 with U 0 itemset-utility 6 for itemset.length  len do 7 Check inclusive and utility changes 8 Get itemset 1 with U 1  9 Calculate C 10 Scan the database get W 11 Calculate AUG 12 Selected max one 13 Present this utility-association rule TABLE VIII C HARACTERISTICS OF DATASETS Dataset Number of Transactions Number of Items Average Length Retail 2 88162 16470 10.3 Chainstore 3 1112949 46086 7.3 t20i6d100k 100000 658 13.7 c20d10k 10000 187 13 datasets are Retail 2 and Chainstore 3  and the synthetic datasets are t20i6d100k and c20d10k  The parameters of the datasets are listed in Table VIII A Comparison of Two Functions for Calculating Impacted Coef\002cient Here we propose two functions for calculating the impacted coef\002cient One is the quadratic mean QM which is adopted in this paper the other function is the harmonic mean HM which is proved to be less accurate in the experiments Those itemsets with a good coef\002cient measurement should be associated with both high frequency and high utility growth we thus can separate the database randomly If the output itemsets discovered in each sub-database are stable we can assume that this measurement is suitable The experiments were conducted on the Retail dataset for the sake of simply examining the QM function The top 100 experimental results are selected and shown in Fig 4 The 002gure on the left shows the comparison between UP-Growth and QM while the 002gure on the right shows the result of QM and HM on C 001 X  and W 001 X   The database is split into 10 parts randomly The 002rst part contains 10 transactions in the database and each later part contains 10 more transactions than the former part such that the second part contains 20 and the last part is 100 The X axis is the k th  1 024 k 024 10  part of the database and the Y axis is the match ratio which means the ratio of the exact patterns found in the k th part 2 http://www.philippe-fournier-viger.com/spmf/index.php?link=datasets.php 3 http://cucis.ece.northwestern.edu/projects/DMS/MineBench.html 


Fig 4 The Comparison of HM QM and UP-Growth matching with the  k  1 th part As seen from the 002gures the QM method outperforms both HM and UP-Growth B Experimental Evaluation of CUARM Next we present the experimental results of comparing derivative itemsets with the traditional HUIs FIs and UIs Underlying Itemsets respectively The statistic values of each dataset are shown in Table VIII The experiment is conducted as follows Firstly we collect all the utility itemsets with their utilities and frequencies in each dataset respectively Secondly we also collect all the frequent itemsets with their frequency and utility Then we calculate the utilities of the frequent itemsets frequencies of the HUIs and both utilities and frequencies of the derivative itemsets At last we plot the frequency of itemsets discovered via UP-Growth and CUARM the utility of itemsets discovered by FP-Growth and CUARM and the utility changes from each underlying itemset to derivative itemset as shown in Fig 5 Such exhibition is made for the comparison of our algorithm with FIM and HUI to demonstrate the UtilityAssociation Rules we discovered have both high utility and high frequency Here all the frequent and utility itemsets we compare with contain at least two items because the derivative itemsets our algorithm discover contain no less than two items Experiments on Real Datasets We 002rst present the outputs of dataset Retail in Fig 5\(a and Fig 5\(b Top 50 patterns of each algorithm are selected for experiments By analyzing the frequencies and utilities of patterns many of them are without much difference in both two experiments which means the association rules we found via traditional AR algorithms are also high utility-association rules via our method In addition such rules are also with high utilities This explains why some parts of the curves overlap In addition customers prefer to buy a few products at one time that is most of FIs and HUIs contain only one or two items which also explains the observations In datasets Chainstore  the differences are much clearer because customers usually prefer a variety of products in each of transactions and high utility itemsets are always low in frequency while highly frequent itemsets are with low utility For example in Fig 5\(d the CUARM performs much better than that of FP-Growth while in Fig 5\(e even at some points the performance is not so good the global performance is much better To sum up we can assert that the performance of our algorithm CUARM is much better than the others Experiments on Synthetic Datasets Experimental results on synthetic datasets t20i6d100k and c20d10k are shown in Fig 5\(g Fig 5\(h Fig 5\(j and Fig 5\(k The results are much clearer than those from real datasets because the items included are much neat and with orderliness For most of the patterns discovered via CUARM the frequencies are much higher than those traditional high utility itemsets At the same time most Utility-associated rules are also with much higher i.e twice the utility than traditional association rules especially in Fig 5\(h from dataset t20i6d100k  C Evaluation of the Utility Increment We demonstrate the utility increment in a graphic way to show how the utility increases from underlying itemset to derivative itemset The utility increment is valued based on the same datasets as above points are ordered by the utility of derivative itemsets The performance of our algorithm varies from one dataset to another The performance in chainstore is much better than that in retail because the transaction time in chainstore is 12 times more than that in retail while the item types are only twice more However in the synthetic datasets the performance is better In conclusion for each dataset the performance is different but the utility actually increases D Utility Variation Experiments Conclusion Based on the above datasets and experimental results a table is used to demonstrate the conclusion that comes from our experiments and shown as Table IX This table describes the number of itemsets whose utilities are increase or decrease with given threshold Also two kinds of utility incremental forms are listed One is the utility of derivative itemset is higher than both the utilities of underlying itemset and additional itemset which is denoted as FA the other is that the utility of derivative itemset is higher than only the utility of underlying itemset which is denoted as FB As for each underlying itemset only one derivative itemset would be discovered some FA and FB might be ignored For the utility decrement itemsets whose utilities are only lower than the underlying itemsets would not be considered in this table because these itemsets can also be regarded as FBs when the underlying itemsets and additional itemsets exchange TABLE IX U TILITY V ARIATION C ONCLUSION Dataset Min Sup N.DI R.U N.FA N.FB N.DecI Retail 0.01 89 20.3 50.4 28 22 39 0.008 135 18.6 50.4 37 46 52 0.002 1667 8.4 50.4 473 769 425 Chainstore 0.002 79 4.6 207.2 7 19 53 t20i6d100k 0.017 33 25.7 78.5 8 11 14 0.015 79 22.8 78.5 24 19 36 0.012 383 1.8 78.5 112 137 134 c20d10k 0.05 120 19.7 150.9 28 48 44 In Table IX M in Sup in the minimum support for mining itemsets N:DI is the number of derivative itemsets discovered 


figures1//retail_f-eps-converted-to.pdf a retail figures1//retail_u-eps-converted-to.pdf b retail figures1//retail_i-eps-converted-to.pdf c retail figures1//ds7_f-eps-converted-to.pdf d chainstore figures1//ds7_u-eps-converted-to.pdf e chainstore figures1//ds7_i-eps-converted-to.pdf f chainstore figures1//t20i6d100k_f-eps-converted-to.pdf g t20i6d100k figures1//t20i6d100k_u-eps-converted-to.pdf h t20i6d100k figures1//t20i6d100k_i-eps-converted-to.pdf i t20i6d100k figures1//c20d10k_f-eps-converted-to.pdf j c20d10k figures1//c20d10k_u-eps-converted-to.pdf k c20d10k figures1//c20d10k_i-eps-converted-to.pdf l c20d10k Fig 5 Experiments for FP UP and CUARM with the threshold M in Sup  R:U in the utility incremental rate from underlying itemset to derivative itemset N:F A is the number of FA itemsets N:F B is the number of FB itemsets and N:DecI is the number of decremental itemsets VI C ONCLUSIONS AND F UTURE W ORK Traditional high utility itemset mining methods have the weak point that if the minimum utility threshold is set too high the itemsets discovered might contain unrepresentative items while if the threshold is set too low too many redundant itemsets will be found On the other hand traditional association rule mining ignores the utility hidden among the items This work proposes a novel pattern select method from two aspects One is the co-occurrence of two underlying and additional itemsets another is the utility increment from underlying itemset to derivative itemset It is an effective approach for identifying actionable combined utility itemsets in which for different items only one itemset will be selected with the highest association-utility growth which caters for both high association and high utility Thus only the most effectively impacted itemsets will be presented The results demonstrate that our method can discover patterns that are composed of different item combinations of both utility increment and high representativeness For the future work we may 002nd some more interesting pattern selection method For example there exists a dependent relationship between two itemsets A and B which means A might appear frequently alone or with other items but for most time B appears together with A VII A CKNOWLEDGMENTS This work is sponsored in part by Australian Research Council Discovery Grant P130102691 R EFERENCES  R Agra w al R Srikant 1994 F ast Algorithms for Mining Association Rules in Proc of the 20th Int'l Conf on Very Large Data Bases pp.487-499 Santiago Chile  C.F  Ahmed S.K T anbeer  B.-S Jeong and Y K Lee 2009 Ef 002cient Tree Structures for High utility Pattern Mining in Incremental Databases in Proc of IEEE Transactions on Knowledge and Data Engineering Vol 21 Issue 12 pp 1708-1721  L Cao Y  Zhao C Zhang 2008 Mining Impact-T ar geted Acti vity Patterns in Imbalanced Data IEEE Trans on Knowledge and Data Engineering 20\(8 1053-1066  L Cao P  S Y u C Zhang and Y  Zhao 2010 Domain Dri v en Data Mining Springer  L Cao 2013 Combined mining Analyzing object and pattern relations for discovering and constructing complex yet actionable patterns Wiley Interdisc Rew Data Mining and Knowledge Discovery 3\(2 140-155  J Han J Pei and Y  Y in 2000 Mining Frequent P atterns without Candidate Generation in Proc of the ACM-SIGMOD Int'l Conf on Management of Data pp 1-12 Dallas TX USA  J Han H Cheng D Xin and X Y an 2007 Frequent P attern Mining Current Status and Future Directions DMKD 15 55-86  M S Khan M Muyeba and F  Coenen 2008  A W eighted Utility Framework for Mining Association Rules in Proc of the Second UKSIM European Symposium on Computer Modeling and Simulation pp 87-92  X Lin Q Zhu F  Li Z Geng and S Shi 2010 S Share Strate gy for Utility Frequent Patterns Mining in Proc of the Seventh International Conference on Fuzzy Systems and Knowledge Discovery pp 14281432 Yantai China  J Liu K W ang and B C M Fung 2012 Direct Disco v ery of High Utility Itemsets without Candidate Generation in Proc of the IEEE Int'l Conf on Data Mining ICDM  M Liu and J Qu 2012 Mining High Utility Itemsets without Candidate Generation in Proc Of the ACM Int'l Conf on Information and Knowledge Management CIKM pp 55-64 


 Y  Liu W  Liao and A C houdhary  2005  A T w o-Phase Algorithm for Fast Discovery of High Utility Itemsets in Proc of PAKDD pp 689-695  S Shankar  T  Purusothaman S Kannimuthu and P  K V ishnu 2010 A Novel Utility and Frequency Based Itemset Mining Approach for Improving CRM in Retain Business International Journal of Computer Applications Volume 1 No 18 pp 87-94  V  S Tseng C.-W  W u B.-E Shie and P  S Y u 2010 UP-Gro wth An Ef\002cient Algorithm for High Utility Itemset Mining in Proc of Int'l Conf on ACM-SIGMOD pp.253-262  B V o B Le and J Jung 2012  A T ree-Based Approach for Mining Frequent Weighted Utility Itemsets in Proc of ICCCI 2012 Part I LNAI 7653 pp 114-123  C W u Y  Lin P  S Y u and V  S Tseng 2013 Mining High Utility Episodes in Complex Event Sequences in Proc of ACM SIGKDD International Conference on Knowledge Discovery and Data Mining KDD pp 536-544  C W u P  Philippe P  S Y u and V  S Tseng 2011 Ef 002cient Mining of a Concise and Lossless Representation of High Utility Itemsets in Proc of IEEE Int'l Conf on Data Mining ICDM pp.824-833  C W u B Shie V  S Tseng and P  S Y u 2012 Mining top-K high utility itemsets in Proc of ACM SIGKDD International Conference on Knowledge Discovery and Data Mining KDD pp 78-86  H Y ao H J Hamilt on and C J Butz 2004  A foundati onal approach to mining itemset utilities from databases in Proc of the 4th SIAM Int'l Conf on Data Mining Florida USA  J S Y eh Y  Li and C Cheng 2007 T w o-Phase Algorithms for a Novel Utility-Frequent Mining Model in Proc of PAKDD Workshop LNAI 4819 pp 433-444  J Y in Z Zheng and L Cao 2012 USpan An Ef 002cient Algorithm for Mining High Utility Sequential Patterns in Proc of ACM SIGKDD International Conference on Knowledge Discovery and Data Mining KDD pp 660-668  H Zhang et al 2008 Combined Association Rules Mining in Proc of PAKDD08 pp.1069-1074  Q Zhao and S Bho wmick 2003  Association Rules Mining a Surv e y Journal of Nanyang Technological University 2003116  Y  Zhao et al 2007 Mining for Combined Association Rules on Multiple Datasets in Proc of the KDD 2007 Workshop on Domain Driven Data Mining San Jose CA USA pp 18-23 



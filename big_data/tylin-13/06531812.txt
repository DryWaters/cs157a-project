The Framework of Cloud Computing Platform for Massive Remote Sensing Images 
 Feng-Cheng Lin, Lan-Kun Chung, Wen-Yuan Ku, Lin-Ru Chu, Tien-Yin Chou Geographic Information Systems Research Center  Feng Chia University  Taichung, Taiwan, ROC  e-mail: {francis, peter, cool, carrie, jimmy}@gis.tw   
In recent years, due to the rapid development of remote sensing technology, a single high-quality image will occupy larger storage space, and video has become so widespread in the usage of environmental observation and 
Abstract 
record. Hence, digital data is growing exponentially, and how to manage them and make image processing more effectively is a key issue in Geographic Information System. Additionally the limitation of hardware resource and time-consuming images' processing is a bottleneck to cope with such big data by commercial software in single PC. The aim of this paper is to propose a framework based on some standards of the interface WCS, WMS, and WPS\m Open Geospatial Consortium OGC\, cloud storage from HDFS, and image processing from MapReduce. Within this framework, we implement image 
management as well as simple WebGIS and test a read/write performance under four kinds of data sets \(Normal Distribution, Skew to Left, Skew to Right, and Peak in Left and Right\ The results reveal write/read performance of HDFS are outperform than the local file system in the situation of larger files \(most files range in size from 8 MB to 10 MB and a large number of threads \(threads equal to 40 or 50 
Keywords-HDFS; MapReduce; Cloud Computing; Remote Sensing Images 
 
 I NTRODUCTION  The meaning of çremote sensingé refers to the activities 
I 
of recording, observing, and perceiving \(sensing\ects or events remotely   We can ach iev e this task by Unmanned Aerial Vehicle \(UAV\ather large volumes of images, then a further step is to analyze and recognize Modern image processing technology helps scientists to extract meaningful regions from acquired images  5   However, high resolution images will occupy more hard disk space, and images processing will cost more times therefore, we need to have a well-designed platform to store remote sensing images and process images effectively in a distributed environment  
Recently, çcloudé was discussed in many books     d w e t h ink   clou d is n o t j u st an adj ectiv e; it s h ou l d  be a real workable infrastructure. Under cloud environment manager can have a large pool of easily usable and accessible virtualized resources, that is, hardware development platforms and/or services. These resources can be dynamically reconfigured to adjust to a variable load scale\wing also for an optimum resource utilization Further, resources are typically exploited by a pay-per-use model where guarantees are offered and followed by customized Service Level Agreements \(SLA\by the resource provider. Monitoring of surface deformation, land 
cover classification, and change detection in tropical zones are examples for applications that rely on multi-temporal remote sensing images of urban areas [9  1 0 11   T o  improve the computational performance of processing large amounts of real-time geodata and overcome the limited storage space, Cloud Computing provides appropriate tools    14], [15   16 The remainder of this paper was organized as following The source of remote sensing images was introduced in section II. Related works \(remote sensing images processing in single machine and cloud computing environment\ were 
discussed in section III. Then, we propose a suitable framework for remote sensing images processing in section IV. Section V presents a prototype implementation of WebGIS embedded image post-processing presentation layer In section VI, we design four types of data sets to test write/read performance of local file system and HDFS Finally, t 
concludes this paper in section VII II T HE SOURCE OF R EMOTE S ENSING I 
he last part 
 
 
MAGES  To collect aerial images, GIS Research Center of Feng Chia University developed Unmanned Aerial Vehicle UAV\at integrates aerial engineering and electronics wireless transmission, image post-processing, and GPS technique's coordination with OGC-SWE compatible software for comprehensive cross-platform environmental investigation  Figure 1 Unmanned Aerial Vehicle \(named for AS-4\GIS, FCU 
2013 IEEE 27th International Conference on Advanced Information Networking and Applications 1550-445X/13 $26.00 © 2013 IEEE DOI 10.1109/AINA.2013.94 621 


    
A Remote Sensing Images processing in single machine 
       
The appearance of our UAV \(AS-4\ is shown in Fig. 1 and related specification is in the following: maximum carried weight is 15 KGs; maximum altitude is 10,000 feet about 3000m\; it can fly one-hour with standard oil box range is 30 KM radius; and the highest speed is 100 KM/h   Figure 2 R ELATED W ORK  In this section, we studied and executed remote sensing image processing in single machine and cloud computing environment There are many unsupervised classification algorithms    9 w hi c h ha ve b e e n w i d e l y use d i n t h e cl a ssi fi c a t i o n of remote sensing image. Two of most frequently used algorithms are K-means [4 1 2], [13] a n d I S O D A T A 16  In this paper, the input of image processing is a color remote sensing image, a set of pixels each of which represented by RGB value. We apply the transformation of each pixel from 4   T h ey tran s f e r e ach  pix el f r om R G Bv alu e t o L  a b  value where L is a brightness layer and can be ignored, a indicates where color falls along the red-green axis, and b indicates where color falls along the blue-yellow axis In this section, we demonstrate how to use these images in a single machine by real case. Firstly, a researcher can retrieve one image from the repository returned by AS-4 in Fig. 6. Then, this paper implements normal steps referred to  f pro ce ssing cluster ing for one image as follows 1 Read image form aerial image repository 2 Image transformation \(RGB L*a*b 3 Extract a pair \(a*, b*\of each pixel in above step and keep them in an array 4 Apply clustering algorithm \(K-means is used here 5 Label every pixel in the image using the results from K-MEANS 6 Clusters are done and rendered on a graphics layer 
Related modules of AS-4 Since AS-4 is configured with the related modules given in Fig. 2, UAV can shoot high-resolution picture or HD movie with camera in sky, and we can control UAV by realtime monitoring software in Fig. 3 installed in the personal computer on the ground. Consequently, rescue workers can also plan a flight path and shoot information of the disaster area   Figure 3 Automatic flying system in ground control station Fig. 4 depicts the flight path of UAV \(CP01-START POINT is the start of the shot\ after the take-off point in Taichung City of Taiwan   Figure 4 The flight path of AS-4 in Taichung city of Taiwan After shooting multiple images, the subsequent images can be mosaicked into a large high-resolution image, so that the researchers can get the overall picture of the environment in the following Fig. 5. Meanwhile, system will keep metadata of each aerial photo \(ex. *.jgw of *.jpg and *.tfw of tiff  Figure 5 Mosaicked aerial images photographed by AS-4 III 
002 
 
622 


Original image photo \(5184*3456\phed by AS-4  Figure 7 The result of image transformation by  makecform\('srgb2lab Matlab The Fig. 7 and Fig. 8 are implemented by Matlab 2011b image transformation using makecform\('srgb2lab clustering algorithm using kmeans meth     Figure 8 The results of clustering by K-means method in Matlab Implementing this process requires some programming background and skill; therefore, researchers can also use commerical software to render the result visually by simple image loading and parameter's settings. Here, we quickly apply K-means \(K=5\orithm embedded in ENVI 4.7 illustrated in Fig. 9 in which the result of a real case shows that the parts of red and green is the trees and lawn, deep blue is the road; yellow is the playground; and light blue is buildings   Figure 9 Test Aerial Image Classification Results by K-means rendering by ENVI 4.7 and K=5 
B Remote Sensing Images processing in Cloud Computing 
 
In Fig. 6, 7, and 8, we illustrate the results of implementation of image processing by Matlab \(read image using imread   Figure 6 Remote sensing \(RS\ image processing work can be done by standalone software, ENVI, but the limitation of computing and storage resources and the tolerance of time consuming are two bottlenecks in processing a large amount of RS images [1   T h e r ef or e r e s e ar ch ers h a v e  dev e lo p e d  many kinds of variants of the algorithm executing in parallel and most of them are implemented by using MPI. However writing programs in MPI requires sophisticated skills Because of the convenience of cloud computing, the cloud lets you create and manage VMs and storage more cheaply quickly, and efficiently Lv et al., [12 in t r odu c e d th e pr og ram m i n g  m odel  MapReduce and a platform Hadoop. Wang, He, and Liu proposed a classification algorithm for high spatial resolution remote sensing data based on mapping mechanism [5 Almeer [1 em pl oy ed Ha d o o p  Ma pR e d u c e f ram e w ork t o  implement parallel processing of remote sensing images and built an experimental 112-core high-performance cloud computing system in the Environmental Studies Center at the University of Qatar Besides the scholarês effort in Hadoop MapReduce, there is MapReduce enabled clustering implementations in Apache Mahout [18  I t of f e rs u s e r t o  cr eat e s c ala bl e m ach in elearning algorithms included including k-Means, fuzzy kMeans, Canopy, Dirichlet, and Mean-Shift  
    
623 


 
Hardware expansion SW and HW Storage Multiple-user Reliability A UAV Images Management B WebGIS Service Interface C Data Analysis and processing module D Cloud Computing Environment 
     
IV P ROPOSED F RAME W ORKS  003 Cloud Computing 003  003 Internet 003  003 Computing on the Internet 003 shows a concept that computers can collaborate with each other, and services spread far and wide In remote sensing images repository, we have lots of highresolution images called as big data, and related services will access these data by standard interface. We encountered some questions that how do we cope with these big data, and users/applications can use them in the following situations: 1 is not easy, 2 are costly, 3 capacity is hard to expand, 4 access makes the poor efficiency result, 5. Ensure of data Therefore, based on these issues and requirements, this paper proposes a cloud computing framework that is suitable for remote sensing images. This framework consists of four major parts and is described as follows. A. User can upload and retrieve aerial images by UAV image Management; B WebGIS used to render aerial images and put a dynamic layer in any web page; C. Data Analysis and processing module is serious part of the framework to store and process images; and D. Cloud Computing Environment is a basic infrastructure. We implement part A and B in section V and test performance of part C and D in section VI  Hadoop WCS WMS WPS Service Interface Data Management Unit HDFS MapReduce Image Retrieval Image Manager User Interface Metadata Unit Image Analysis unit Image Recognition Image Classification Applications OpenLayers Users Cloud Computing Portal Module Data Analysis and Processing Module Cloud Computing Environment HDFS Adapter MapServer 002Ë\002‘\002È\002≥\002‹\003\000\002Ù\002˙\002¯\003\006 002‡\002Ù\003\001\002Ù\002˙\002¯\003\000\002¯\003\001\003\007 002Í\002¯\002ı\002⁄\002‹\002  Figure 10 UAV Image Management is a system for users to upload images and manage these images afterwards. This system includes image retrieval and image manager by the user interface. An image retrieval system is a web system for browsing, searching and retrieving images from the database of aerial images repository. Most traditional and common methods of image retrieval utilize some methods of adding metadata to the images so that retrieval can be performed over the annotation words. Manual image annotation is timeconsuming, laborious and expensive; to address this, there has been a large amount of research done on automatic image annotation. By Image Manager, user can upload related images, and all uploaded images stored in the data warehouse WebGIS is an interface that can accept userês parameters setting and show the relevant map information that adds layer objects to your map by OpenLayers [19  T h e presentation should communicate with the service interface by standard of OGC; that is, WCS, WMS, and WPS OpenLayers Ö Google Maps gives you a quick and easy way to add maps to your Web site, but when you're using Google's API, your ability to display other data is limited. If you have your own data you want to display, or data from sources other than Google, OpenLayers, an open source JavaScript library, can give you more options. OpenLayers works either with data you're serving yourself, using a package such as GeoServer or MapServer, or with data others are publishing via WMS WCS Ö The OGC Web Coverage Service \(WCS allows for the publication of çcoveragesé- digital geospatial information representing space-varying phenomena WMS Ö A Web Map Service \(WMS\is a standard protocol for serving georeferenced map images over the Internet that are generated by a map server using data from a GIS database WPS Ö The Web Processing Service \(WPS Interface Standard provides rules for standardizing how inputs and outputs \(requests and responses\ for geospatial processing services, such as polygon overlay. The standard also defines how a client can request the execution of a process, and how the output from the process is handled. It defines an interface that facilitates the publishing of geospatial processes and clientsê discovery of and binding to those processes  An image retrieval system is a computer system for browsing, searching and retrieving images from a large database of digital images. MapServer [17  is  a po pu la r  Open Source project which purpose is to display dynamic spatial maps over the Internet. HDFS adapter we proposed holds a feature to mount HDFS as a file system. Image Classification utilizes Mahout [18  t o p r o cess  im ag e clustering  Under cloud computing environment, we clustered 2dimensional points that are the values of a* and b* discussed above and applied KMeansDriver of Mahout to image classification module in Fig. 10 and computed similarity by EuclideanDistanceMeasure. For more details, refer to the book of Mahout by Owen, Anil, Dunning, and Friedman   
Proposed Framework of Cloud Computing Platform 
    
    
624 


   
A User Interface B Presentation of MapServer by OpenLayers 
  
V Metadata is used to present "data about image" here \(it records images by year, location, and description\d user can retrieve related images from metadata by user interface and double click çSubmité button in Fig. 11, then the result of query is shown in the right side where the Open function is to list the thumbnail of images photographed at the same time and places   Figure 11 To have a better understanding of images processing results in aerial images, we build a simple user interface by OpenLayers i n al i m ag e is  s h o w n i n F i g 13\(a  overlapping layers presents the result of combining the original layer and clustering layer \(70% transparency\ Fig 13\(b   a\sable checkbox of çClustering Resultsé in original image layer  b\le checkbox of çClustering Resultsé to combine two layers original image layer and clustering result layer Figure 13 
IMPLEMENTATION  By uploading images to the data warehouse in HDFS Researchers can query images by year, country, town, and village to obtain query results. Then these images can be fully or partially downloaded as a zip file in the following prototype. Furthermore, image processing module executed in back-end and this module integrates with MapServer [17   through the front-end of the display interface, showing layers of overlapping effects in part B of this section Implementation of Part A in Fig. 10 Fig. 12 summarized the results of querying data from warehouse of UAV in the cloud computing environment in GIS Research Center of Feng Chia University These photos were taken in Fengshan Village, Alishan Town Chiayi County, Taiwan after Typhoon Morakot in 2009-0817. Researchers can download these images as a zip file   Figure 12 Query results of UAV photographed in Alishan area of Taiwan Implementation of Part B in Fig. 10 by OpenLayers [19  VI EXPERIMENTATION  There were 2 difficulties confronted during the experiment. The first is the storage of large number of aerial image, and second is image processing. In this section, we just test the performance of storing and accessing image files in local file system and HDFS \(replication = 1\. We simulated four types of datasets \(100 files included in each dataset\depicted in Fig. 14: \(a\ormal Distribution with average of around 5MB and a standard deviation of around 1MB in dataset 1; \(b\ew to Left with eighty percent of 13MB; \(c\w to Right with eighty percent of 8-10MB; and d\Peak in Left and Right with forty percent of 1-3MB and forty percent of 8-10MB. And we also simulated the number of threads \(10, 20, 30, 40, and 50\o test concurrent users in writing and reading performance 
  
625 


Distribution of different data sets  VII W. Qihao, Remote Sensing and GIS Integration, Theories. Methods and Applications, McGraw-Hill Professional, 2010 2 J. A. Richards and X. Jia, Remote Sensing Digital Image Analysis An Introduction, Springer-Verlag, 2006 
Hadoop Performance Evaluation 
   
Our cluster environment includes one NameNode and four DataNode, and each node equipped with 8 ◊ 2.53 GHz CPU, 4 GB RAM, 1 TB disk space  In Fig. 15 and Fig. 16, the results revealed that read/write performance in four kinds of data sets. Compare HDFS with local file system performance, the HDFS writing performance is lower than the local file system in  Fig. 15\(a and Fig. 15\(b\d  the HDFS reading performance is lower than the local file system in  Fig. 16\(a\d Fig. 16\(b These results delivered that local file system outperforms than HDFS in Normal Distribution and Skew to Left   However, it is noteworthy that write/read performance of HDFS increases as concurrent users increase. Overall, the results have been very positive; that is, HDFS can serve more threads and have better performance than the file system in data set \(8-10 MB\eschrittene indicated HDFS writing performance scales well on both small and data set in  r experiments also confirm this trend, especially in the threads more than 40. The write/read performance of HDFS is better than the local file system in the situation of larger files most files range in size from 8 MB to 10 MB\d a large number of threads \(threads equals to 40 or 50  a\ Data Set 1: Normal Distribution   b\Set 2: Skew to Left  c\ Data Set 3: Skew to Right   d\Set 4: Peak in Left and Right Figure 14 C ONCLUSIONS AND F UTURE W ORK  Based on the remote sensing images from UAV by GIS of FCU, we proposed a cloud-based framework for massive remote sensing image storage and process. We have also demonstrated how to process real sensing image by Matlab and ENVI in a single machine and by Mahout in a cloud computing environment. This framework also implements image management by communicating with metadata unit and data management unit; furthermore, prototype WebGIS can accept userês parameters setting and show the relevant map information of MapServer included clustering result by OpenLayers. Finally, we utilize four types of data distribution and simulate concurrent users by threads to test massive image files in writing and reading performance in local file system and Hadoop HDFS A CKNOWLEDGMENT  This work is supported by the National Science Council of Taiwan, under grant NSC100-2625-M-035-003, NSC1002119-M-035-001, NSC101-2625-M-035-002, and NSC1012119-M-035-003 R EFERENCES  1 
 
626 


3 S. M. De Jong and F. D. Van Der MEER, Remote Sensing Image Analysis: Including the Spatial Domain, Kluwer Academic Publishers, 2004 4 A. Z. Chitade and DR. S. K. Katiyar, çColour Based Image Segmentation Using K-Means Clustering,é International Journal of Engineering Science and Technology, vol. 2, 2010, pp. 5319-5325 5 G. Wang, G. He, and J. Liu, çA New Classification Method for High Spatial Resolution Remote Sensing Image Based on Mapping Mechanism,é Proc. of the 4th GEOBIA, May, 2012, pp.186-190 6 B. Sosinsky, Cloud Computing Bible, Wiley Publishing, Inc., 2011 7 M. Cafar  o and G. Aloisio, Grids, Clouds and Virtualization 2011 8 Z. Mahmood and R. Hill, Cloud Computing for Enterprise Architectures, Springer-Verlag London Limited, 2011 9 M. J. Canty and A. A. Nielsen, çVisualization and unsupervised classification of changes in multispectral satellite imagery International Journal of Remote Sensing, vol. 27, 2006, pp. 3961 3975  C. R. Fichera1, G. Modica and M. Pollino1, çLand Cover classification and change-detection analysis using multi-temporal remote sensed imagery and landscape metrics,é European Journal of Remote Sensing, vol. 45,  2012, pp. 1-18  N. C. F. Codella, G. Hua, A. Natsev, J. R. Smith, çTowards Large Scale Land-cover Recognition of Satellite Images,é Proc. IEEE Information, Communications and Signal Processing \(ICICS 8th IEEE Press, Dec. 13-16, 2011, pp. 1-5  Z. LV, Y. Hu, H. Zhong, J. Wu, B. Li, and H. Zhao, çParallel KMeans Clustering of Remote Sensing Images Based on MapReduce in Web Information Systems and Mining, Lecture Notes in Computer Science, vol. 6318, F.L. Wang et al. Eds. Berlin/Heidelberg: Springer 2010, pp.162-170  W. Zhao, H. Ma, and Q. He, çParallel K-Means Clustering Based on MapReduce,é in CloudCom, Lecture Notes in Computer Science, vol 5931, M.G. Jaatun, G. Zhao, and C. Rong Eds. Berlin/Heidelberg Springer, 2009, pp.674-679  J. Zhang, T. Li, D. Ruan, Z. Gao, C. Zhao, çA parallel method for computing rough set approximations,é Information Sciences, vol 194, July 2012, pp. 209-223  M. H. Almeer, çCloud Hadoop Map Reduce For Remote Sensing Image Analysis,é Journal of Emerging Trends in Computing and Information Sciences, vol. 3, April 2012, pp. 637-644  B. Li, H. Zhao, and Z. LV, çParallel ISODATA Clustering of Remote Sensing Images Based on MapReduce,é Proc. IEEE CyberEnabled Distributed Computing and Knowledge Discovery \(CyberC IEEE Press, Oct. 10-12, 2010, pp.380-383  B. Kropla, Beginning MapServer: Open Source GIS Development New York: Springer-Verlag Inc, 2005  S.  Owen, R. Anil, T. Dunning, and E. Friedman, Mahout in Action New York: Manning Publications Co, 2012  E. Hazzard, OpenLayers 2.10 Beginner's Guide: Create, optimize and deploy stunning cross-browser webmaps with the OpenLayers JavaScript web-mapping library, Birmingham: Packt Publishing Ltd 2011  V. France and V. Hlavac, Statistical pattern recognition toolbox for matlab. Technical report, Czech Technical University, 2004  T. D. Dinh, Hadoop Performance Evaluation , availabe in http://wr.informatik.unihamburg.de/_media/research/labs/2009/2009-12-tien_duc_dinhevaluierung_von_hadoop-report.pdf a\te Performance in Data Set 1 c\te Performance in Data Set 3  b\Write Performance in Data Set 2  d Write Performance in Data Set 4  Figure 15 Write performance in different data sets   
Springer-Verlag London Limited 
                    
627 


a\ Read Performance in Data Set 1  c\ Read Performance in Data Set 3  b\ea d Performance in Data Set 2   d ea d Performance in Data Set 4  Figure 16 Read performance in different data sets 
 
628 


B U 
DistGreedyCSS 
 The use of the distributed CSS algorithm extends the original algorithm proposed by C ivril and Magdon-Ismail to work on distributed matrices In order to allow efìcient implementation on MapReduce the number of leading singular vectors is set of   is the distributed column subset selection method described in Algorithm 4 For all experiments the dimension of the random projection matrix is set to  This makes the size of the concise representation the same as the DistApproxSVD method Two types of random matrices are used for random projection 1 a dense Gaussian random matrix rnd and 2 a sparse random sign matrix ssgn For the methods that require the calculations of Singular Value Decomposition SVD the Stochastic SVD SSVD algorithm is used to approximate the leading singular values and vectors of the data matrix The use of SSVD signiìcantly reduces the run time of the original SVDbased algorithms while achieving comparable accuracy In the conducted experiments the SSVD implementation of Mahout was used Table II shows the run times and relative accuracies for different CSS methods It can be observed from the table that for the data set the DistGreedyCSS methods with random Gaussian and sparse random sing matrices outperforms all other methods in terms of relative accuracies In addition the run times of both of them are relatively small compared to the DistApproxSVD method which achieves accuracies that are close to the DistGreedyCSS method Both the DistApproxSVD and DistGreedyCSS methods achieve very good approximation accuracies compared to randomized and hybrid methods It should also be noted that using a sparse random sign matrix for random projection takes much less time than a dense Gaussian matrix while achieving comparable approximation accuracies Based on this observation the sparse random matrix has been used with the data set For the data set although the DistApproxSVD achieves slightly higher approximation accuracies than DistGreedyCSS with sparse random sign matrix the DistGreedyCSS selects columns in almost one-third of the time The reason why the DistApproxSVD outperforms DistGreedyCSS for this data set is that its rank is relatively small less than 1024 This means that using the leading 100 singular values to represent the concise representation of the data matrix captures most of the information in the matrix and accordingly is more accurate than random projection The DistGreedyCSS however still selects a very good subset of columns in a relatively small time IX C ONCLUSION This paper proposes an accurate and efìcient MapReduce algorithm for selecting a subset of columns from a massively distributed matrix The algorithm starts by learning a concise representation of the data matrix using random projection It then selects columns from each sub-matrix that best approximate this concise approximation A centralized selection step is then performed on the columns selected from different sub-matrices In order to facilitate the implementation of the proposed method a novel algorithm for greedy generalized CSS is proposed to perform the selection from different submatrices In addition the different steps of the algorithms are carefully designed to be MapReduce-efìcient Experiments on big data sets demonstrate the effectiveness and efìciency of the proposed algorithm in comparison to other CSS methods when implemented on distributed data R EFERENCES  A K Jain and R C Dubes 
Table II T HE RUN TIMES AND RELATIVE ACCURACIES OF DIFFERENT CSS METHODS T HE BEST PERFORMING METHOD FOR EACH 0.6 0.6 0.5 0.00 0.00 0.00 0.8 0.8 2.9 2.37 1.28 4.49 1.6 1.5 3.7 4.54 0.81 6.60 1.3 1.4 3.6 9.00 12.10 18.43 16.6 16.7 18.8 41.50 57.19 63.10 5.8 6.2 7.9 61.92 67.75 2.2 2.9 5.1 40.30 1.3 1.3 1.3 0.00 0.00 0.00 1.5 1.7 8.3 19.99 6.85 6.50 3.3 3.4 9.4 17.28 3.57 7.80 52.4 52.5 59.4 3.59 8.57 10.82 71.0 70.8 75.2 22.1 23.6 24.2 67.58 25.18 20.74 to select columns that best approximate the leading singular vectors by setting 
Run time minutes Relative accuracy  RCV1 200K Uniform Baseline Hybird Uniform Hybird Column Norms Hybird SVD-based Distributed Approx SVD Distributed Greedy CSS rnd 51.76 Distributed Greedy CSS ssgn 62.41 67.91 Tiny Images 1M Uniform Baseline Hybird Uniform Hybird Column Norms Hybird SVD-based Distributed Approx SVD 70.02 31.05 24.49 Distributed Greedy CSS ssgn 
Algorithms for Clustering Data 
 002 100 100 
l l l l l l l 
10  100  500 10  100  500 
 Upper Saddle River NJ USA Prentice-Hall Inc 1988 
 
k k 
RCV1-200K TinyImages-1M TinyImages-1M 
IS HIGHLIGHTED IN BOLD  AND THE SECOND BEST METHOD IS UNDERLINED N EGATIVE MEASURES INDICATE METHODS THAT PERFORM WORSE THAN UNIFORM SAMPLING  Methods 
179 


 L Kaufman and P  Rousseeuw  Clustering by means of medoids Technische Hogeschool Delft Netherlands Department of Mathematics and Informatics Tech Rep 1987  S Deerwester  S Dumais G Furnas T  Landauer  and R Harshman Indexing by latent semantic analysis  vol 41 no 6 pp 391Ö407 1990  C Boutsidis J Sun and N Anerousis Clustered subset selection and its applications on it service metrics in  2008 pp 599Ö608  C Boutsidis M W  Mahone y  and P  Drineas  An impro v ed approximation algorithm for the column subset selection problem in  2009 pp 968Ö977  C Boutsidis P  Drineas and M Magdon-Ismail Near optimal column-based matrix reconstruction in  2011 pp 305 314  J Dean and S Ghema w at MapReduce Simpliìed data processing on large clusters  vol 51 no 1 pp 107Ö113 2008  T  White  1st ed OêReilly Media Inc 2009  A Frieze R Kannan and S V empala F ast Monte-Carlo algorithms for nding low-rank approximations in  1998 pp 370 378  P  Drineas A Frieze R Kannan S V empala and V  V inay  Clustering large graphs via the singular value decomposition  vol 56 no 1-3 pp 9Ö33 2004  P  Drineas R Kannan and M Mahone y  F ast Monte Carlo algorithms for matrices II Computing a low-rank approximation to a matrix  vol 36 no 1 pp 158Ö183 2007  P  Drineas M Mahone y  and S Muthukrishnan Subspace sampling and relative-error matrix approximation Column-based methods in  Springer Berlin  Heidelberg 2006 pp 316Ö326  A Deshpande L Rademacher  S V empala and G W ang Matrix approximation and projective clustering via volume sampling  vol 2 no 1 pp 225Ö247 2006  A C  i vril and M Magdon-Ismail Column subset selection via sparse approximation of SVD  vol 421 no 0 pp 1  14 2012  A K F arahat A Ghodsi and M S Kamel  An ef cient greedy method for unsupervised feature selection in  2011 pp 161 170   Ef cient greedy feature selection for unsupervised learning  vol 35 no 2 pp 285Ö310 2013  T  Elsayed J Lin and D W  Oard P airwise document similarity in large collections with MapReduce in  2008 pp 265Ö268  A Ene S Im and B Mosele y  F ast clustering using MapReduce in  2011 pp 681Ö689  H Karlof f S Suri and S V assilvitskii A model of computation for MapReduce in  2010 pp 938Ö948  S Dasgupta and A Gupta An elementary proof of a theorem of Johnson and Lindenstrauss  vol 22 no 1 pp 60Ö65 2003  D Achlioptas Database-friendly random projections Johnson-Lindenstrauss with binary coins  vol 66 no 4 pp 671Ö687 2003  P  Li T  J Hastie and K W  Church V ery sparse random projections in  2006 pp 287Ö296  G Golub and C V an Loan  3rd ed Johns Hopkins Univ Pr 1996  A Deshpande and L Rademacher  Ef cient v olume sampling for row/column subset selection in  2010 pp 329 338  V  Gurusw ami and A K Sinop Optimal column-based lo wrank matrix reconstruction in  2012 pp 1207Ö1214  D D Le wis Y  Y ang T  G Rose and F  Li Rcv1 A ne w benchmark collection for text categorization research  vol 5 pp 361Ö397 2004  W Y  Chen Y  Song H Bai C.-J Lin and E Chang Parallel spectral clustering in distributed systems  vol 33 no 3 pp 568 586 2011  A T orralba R Fer gus and W  Freeman 80 million tin y images A large data set for nonparametric object and scene recognition  vol 30 no 11 pp 1958Ö1970 2008  N Halk o P G Martinsson Y  Shk olnisk y  and M T ygert An algorithm for the principal component analysis of large data sets  vol 33 no 5 pp 2580Ö2594 2011 
Journal of the American Society for Information Science and Technology Proceedings of the Seventeenth ACM Conference on Information and Knowledge Management CIKMê08 Proceedings of the Twentieth Annual ACM-SIAM Symposium on Discrete Algorithms SODAê09 Proceedings of the 52nd Annual IEEE Symposium on Foundations of Computer Science FOCSê11 Communications of the ACM Hadoop The Deìnitive Guide Proceedings of the 39th Annual IEEE Symposium on Foundations of Computer Science FOCSê98 Machine Learning SIAM Journal on Computing Approximation Randomization and Combinatorial Optimization Algorithms and Techniques Theory of Computing Theoretical Computer Science Proceedings of the Eleventh IEEE International Conference on Data Mining ICDMê11 Knowledge and Information Systems Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics on Human Language Technologies Short Papers HLTê08 Proceedings of the Seventeenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining KDDê11 Proceedings of the 21st Annual ACM-SIAM Symposium on Discrete Algorithms SODAê10 Random Structures and Algorithms Journal of computer and System Sciences Proceedings of the Twelfth ACM SIGKDD international conference on Knowledge Discovery and Data Mining KDDê06 Matrix Computations Proceedings of the 51st Annual IEEE Symposium on Foundations of Computer Science FOCSê10 Proceedings of the 21st Annual ACM-SIAM Symposium on Discrete Algorithms SODAê12 The Journal of Machine Learning Research Pattern Analysis and Machine Intelligence IEEE Transactions on Pattern Analysis and Machine Intelligence IEEE Transactions on SIAM Journal on Scientiìc Computing 
180 


Bottom Top A B 
Figure 15 Figure 16 
messages seen for all workers in a superstep \(Figures 10 and 13\. When looking at the messages sent by workers in a superstep for METIS, we see that there are message load imbalances within work ers in a superstep, caused due to concentration of vertices being traversed in that superstep in certain partitions This variability is much more pronounced in CP as compared to WG \(Figures 11 and 14\ E.g. in superstep 9 for CP, twice as many messages \(4M\ are generated by a worker compared to another \(2M\.  For Pregel BSP, the time taken in a superstep is determined by the slowest worker in that superstep. Hence increase d variability in CP causes even çgoodé partitioning strategies to cause an increase in total execution time wh en using the Pregel/BSP model VIII A NALYSIS OF E LASTIC C LOUD S CALING  Cloud environments offer elasticity Ö the ability to scale-out or scale-in VMs on-demand and only pay for what one uses [28   On th e f l i p s i de  on e en ds u p  paying for VMs that are acquired even if they are underutilized. We have already shown the high variation in compute/memory resources used by algorithms like BC and APSP across different supersteps. While our earlier swath initiation heuristics attempt to flatten these out by overlapping swath executions, one can consider leveraging the cloudês elasticity to, instead, scale up and down the concurrent workers \(and graph partitions\ allocated in each superstep The peak and trough nature of resource utilization combined with Pregel/BSPês synchronous barrier between supersteps offers a window for dynamic scaleout and Öin at superstep boundaries. Peak supersteps can greatly benefit from additional workers, while those same workers will contribute to added synchronization overhead for trough supersteps We offer an analysis of the potential benefits of elastic scaling by extrapolating from observed results for running BC on WG and CP graphs, using four and eight workers.  To provide a fair and focused comparison, we turned off swath heuristics in favor of fixed swath sizes and initiation intervals Figure 15 \(Bottom\ plots the speedup of BC running on eight workers when normalized to BC running on four workers, at corresponding supersteps.  The number of workers does not impact the number of supersteps We also plot the number of active vertices \(i.e. vertices still computing for a given swath\these supersteps which is a measure of how much work is required \(Fig 15 \(Top\. We find that we occasionally get superlinear speedup spikes \(i.e. >2x\ that shows a strong correlation with the peaks of active messages, for both WG and CP graphs. At other times, the sp eedup is sublinear or even a speed-down \(i.e. <1\responding to inactive vertices.  The superlinear speedup is attributable to the lower contention and reduced memory pressure for 8 workers when the active vertices peak \(similar to what we observed for the swath initiation heuristics Similarly, the below par speedup during periods of low activity is contributed by the increased overhead of barrier synchronization across 8 workers. Intuitively, by dynamically scaling up the number of workers for supersteps with peaking active vertices and scaling them down otherwise, we can leverage the superlinear speedup and get more value per worker Using a threshold of 50% active vertices as the threshold condition for between 4 and 8 workers in a superstep, we extrapolate the time per superstep and compared this to the fixed 4 and 8 worker runtimes. We also compute the best-case run time using an çoracleé approach to i.e. for each superstep, we pick the minimum of the 4 or 8 workerês time.  Note that these projections do not yet consider the overheads of scaling, but are rather used to estimate the potential upside if we had an ideal or an automated heuristic for scaling. The total time estimates for running BC on WG and CP graphs, normalized to  
 plot shows speedup of 8 workers relative to 4 workers, for each superstep, when running BC on WG and CP graphs plot shows the number of vertices active in that superstep Estimated time for BC using elastic scaling, normalized to time taken for 4 workers. Normalized cost is shown on secondary Y axis WG graph shown on left CP graph shown on right. Smaller is better 
022\011 022\010 022\007 022\002 006 002 007 006 002 007 010 011 012 013 014 015 006 006\003\002 006\003\007 006\003\010 006\003\011 006\003\012 006\003\013 006\003\014 006\003\015 006\003\016 002 027\031\030\037\020#@\020"\031\030\027\020\035 0201!2#\024$#\015#5\024",\020"#\017\003"\003\031\003#\011#5\024",\020"\035 024"'\033\026\0309\0201#\\031\020 2 035#\032\020"#+!\034 017\020\021\022\023\024\024\025\026\020 027\030\031\022\032\033\031\020\034\031\035 017\020\021\022\023\024\024\025\026\020#?#/\027\031\030\037\020#@\020"\031\030\027\020\035 027\030\031\022\032\033\031\020\034\031\035#?#/\027\031\030\037\020#@\020"\031\030\027\020\035 036\030\034\020\033"#\\0201!2 006 006\003\007 006\003\011 006\003\013 006\003\015 002 002\003\007 006 006\003\002 006\003\007 006\003\010 006\003\011 006\003\012 006\003\013 006\003\014 006\003\015 006\003\016 002 011#5\024",\020 B\034\0267 015#5\024",\020 B\034\0267 1\0332\031\030\037\020 030\034\025 1\0332\031\030\037\020 036\024\017\020 024!\0341 024\035\031#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#.\024\035\031 017\020\021\022\023\024\024\025\026\020#+!\034\022&\030'\020#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#&\030'\020 011#5\024",\020"#&\030'\020 015#5\024",\020"#&\030'\020 024\035\031 006 006\003\007 006\003\011 006\003\013 006\003\015 002 002\003\007 002\003\011 002\003\013 006 006\003\002 006\003\007 006\003\010 006\003\011 006\003\012 006\003\013 006\003\014 006\003\015 006\003\016 002 011#5\024",\020 B\034\0267 015#5\024",\020 B\034\0267 1\0332\031\030\037\020 033\026\030\034\025 1\0332\031\030\037\020 036\024\017\020 024!\0341 024\035\031#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#.\024\035\031 027\030\031\022\032\033\031\020\034\031\035#+!\034\022&\030'\020#>\024"'\033\026\0309\0201#\031\024#\011#5\024",\020"#&\030'\020 011#5\024",\020"#&\030'\020 015#5\024",\020"#&\030'\020 024\035 031 
 
dynamically scaling ideal scaling 
Our hypothesis is that an intelligent adaptive scaling of workers can achieve a similar performance as a large, fixed number of workers, but with reduced cost 
213 


Nature Nature Ecological Applications Nature ACM International Conference on Management of Data \(SIGMOD In Parallel Object-Oriented Scientic Computing \(POOSC Science Communications of the ACM ACM Workshop on Mining and Learning with Graphs Communications of the ACM HotCloud Proceedings of the 19th ACM International Symposium on High PErformance Distributed Computing HPDC Knowledge and Information Systems KAIS International Conference on Computational Science IEEE International Conference on Cloud Computing Technology and Science ACM/IEEE Conference on Advances in Social Network Analysis and Mining \(ASONAM IEEE International Parallel and Distributed Processing Symposium \(IPDPS International Conference on Distributed Computing and Networking Journal of Mathematical Sociology International Conference on Parallel Processing Communications of the ACM 
 
observed time taken using 4 workers, are plotted in Figures 16\(A\ and 16\(B We see that our dynamic scaling heuristic using the percentage of active vertices achieves nearly the same CP\ or better \(WG\ performance as a fixed 8 worker approach. Clearly there is benefit of using fewer workers for low utilization su persteps to eliminate the barrier synchronization overhead. Also, the dynamic scaling heuristic performs almost as well as the ideal scaling. Finally, when we consider the monetary cost of the proposed approaches, assuming a pro-rata normalized cost per VM-second plotted on the secondary Y axis, we see that dynamic scaling is comparable \(CP\ or cheaper \(WG\ than a 4 worker scenario while offering the performance of an 8 worker deployment IX C ONCLUSION  In conclusion, we introduce optimization and heuristics for controlling memory utilization and show they are critical to performance.  By breaking computation into swaths of vertices and using our sizing heuristics we achieve up to 3.5x speedup over the maximum swath size that does not cause the a failure.  In addition overlapping swath executions can provide a 24% gain with automated heuristics and even greater speedup when a priori knowledge of the network characteristics is applied This evaluation offers help to eScience users to make framework selection and cost-performancescalability trade-offs. Our he uristics are generalizable and can be leveraged by other BSP and distributed graph frameworks, and for graph applications beyond BC. Our work uncovered an unexpected impact of partitioning and it would be worthwhile, in future, to examine the ability to pred ict, given certain graph properties, a suitable partitioning model for Pregel/BSP It may also be useful to perform such evaluations on larger graphs and more numbers of VMs. At the same time, it is also worth considering if non-linear graph algorithms are tractable in pr actice for large graphs in a distributed environment B IBLIOGRAPHY  1  F  L i lj er os C   Ed l i n g L  A m a r a l H  S t an ley   and Y    berg The web of human sexual contacts 
vol. 411, pp. 907908, 2001   H Je o n g  S   Ma so n A  L   B a ra b s i  a nd Z   Oltva i  L e t ha l i t y  and centrality in protein networks vol. 411, pp. 41-42 2001   O. B o din and E   E s t r ada    U s i n g n e t w ork c e nt r a l i t y  m e a s ures t o  manage landscape connectivity vol 18, no. 7, pp. 1810-1825, October 2008   D. W a ts s  and S  S t r ogat z  C olle c t i v e  d y nam i cs of  s m a ll-w orl d   networks vol. 393, no. 6684, pp. 440Ö442, June 1998   G  Ma lew i c z   M A u s t er n A   Bik  J   Dehn er t I  Hor n   N. L e i s er and G. Czajkowski, "Pregel: A system for large-scale graph processing," in 2010   D. G r egor  and A  L u m s dain e  T h e  pa r a llel  B G L  A gen e r i c  library for distributed graph computations," in 2005   B. S h a o  H. W a n g  and Y  L i T he T r init y G r aph E n g i n e    Microsoft Research, Technical Report MSR-TR-2012-30, 2012   A  F ox  C lo ud c o m putin g w h at  s  in it for m e  as  a  s c i e n tis t     vol. 331, pp. 406-407, 2011   S. G h e m a w a t  and J  De an   Map re duc e s i m p lifi e d data  processing on large clusters vol 51, no. 3, pp. 107-113, 2008   J  L i n and M. S c hat z   Des i g n  patt er n s  for eff i ci ent gr aph algorithms in MapReduce," in 2010   L   Va l i ant   A b r id g i n g m o d e l f or pa r a llel com putati o n  vol. 33, no. 8, pp. 103-111, 1990 12 a c h e  Ha ma    O n l i n e    http://hama.apache.org   13 Ap a c h e  Ha d o op    O n l i n e    http://hadoop.apache.org     M Z a h a r i a, M. Ch ow dhu ry M F r ank l in S  S h e n k e r, and I   Stoica, "Spark: Cluster Computing with Working Sets," in 2010   J  Ekana y ak e e t a l     T w i st er A  r untim e f o r it er ati v e  MapReduce," in Chicago, 2010, pp. 810-818   U. K a n g  C  T s o u rakakis   and C. F a l outs o s  Peg a s us   Minin g  Peta-scale Graphs," in 2010   M. P a c e  B S P vs  MapR e duc e    in vol. 103.2081, 2012   S. Seo  E  Yoo n, J  K i m  S  J i n  J-S. K i m   and S   Ma e n g HAMA: An Efficient matrix computation with the MapReduce framework," in 2010, pp. 721-726   S. S a l i h ogl u  and J  W i d o m  G PS A G r a ph P r oc e s s i n g Sy s t em    Stanford University, Technical Report 2011   R L i cht e n w a l t e r and N   Cha w la D is Ne t  A fr am ew ork for  distributed graph computation," in  2011   K  Maddu r i  D. E d i g er K   J i an g  D. Bad e r  and D  Cha v a r riaMiranda, "A faster parallel algorithm and efficient multithreaded implementations for evaluating betweenness centrality on massive datasets," in 2009   E  K r e p s k a, T  K i el m a nn, W  F o kkink, H   Ba l, "A  hi g h level framework for distributed processing of large-scale graphs," in 2011, pp. 155-166   L   Pa ge  S  B r in R. M o t w ani and T  W i nogr ad  T h e P a geRank citation ranking: Bringing order to the web," Stanford InfoLab Technical Report 1999-66, 1999   U  Brand  s  A f a s t er  a l gor ith m for  b e t w eenn e s s c e nt r a l i t y    vol. 25, no. 2, pp. 163-177 2001   Stan fo r d  Net w or k A na l y s is Pro j e c t  O n l in e    http://snap.stanford.edu    I  S t ant o n and G  K l i o t, "S t r e a m i n g G r aph P a rtiti o n in g  for L a rge Distributed Graphs," Microsoft Corp., Technical Report MSRTR-2011-121, 2011   G   K a ry pis and V   K um a r A fas t and hi g h qua l i t y m u l t i l evel scheme for partitioning irregular graphs," in 1995, pp. 113-122   M. A r m b r u s t e t  a l   A v i ew of  c l o u d  c o m putin g    vol. 53, no. 0001-0782, pp. 50-58 April 2010  
214 


  13  or gani c  c he m i s t r y  i n our  Sol ar  Sy s t e m       Xi a n g  L i r e c e i v e d h i s B  S   m is tr y  fr o m  th e  P e k in g  U n iv e r s ity  C h in a  in  2 0 0 3  and P h D   i n P hy s i c al  C he m i s t r y  f r om  t he  J ohns  H opk i ns  Un i v e r s i t y  i n  2 0 0 9   He  h a s  b e e n  a  R e s e a r c h  A s s o c i a t e  wi t h  a  j o i n t  a p p o i n t m e n t  a t  t h e  U n i v e r s i t y  o f  M a r y l a n d   Ba l t i m o r e  C o u n t y  a n d  N AS A G o d d a r d  S p a c e  Fl i  Ce n t e r  s i n c e  2 0 1 1   H i s  r e s e a r c h  f o c u s e s  o n  t h e  d e t e c t i o n  of  t r ac e  e l e m e nt  and as t r obi ol ogi c al l y  r e l e v ant  or gani c  mo l e c u l e s  i n  p l a n e t a r y  s y s t e ms   l i k e  M a r s   He  i s  es p eci a l l y i n t er es t ed  i n  t h e d evel o p m en t  o f  T i m e of  and I on T r ap m as s  s pe c t r om e t e r s w i t h v a r i o u s i o n i z a t i o n  ng te c h n iq u e s   Wi l l  B r i n c k e r h o f f  sp a c e  sc i e n t i st  i n  t h e  Pl a n e t a r y  En v i r o n m e n t s  La b  a t  N A S A  s  G o d d a r d  Spac e  F l i ght  C e nt e r  i n Gr e e n b e l t   M D w i t h  pr i m ar y  r e s pons i bi l i t y  f or  th e  d e v e lo p m e n t o f th e  L D TO F  m a s s  s p e c t r o  th is  p r o je c t H e  h a s  fo c u s e d  re c e n t l y  o n  t h e  d e v e l o p m e n t  o f  m i n i a t u re  l a se r d ma s s  s p e c t r o me t e r s  f o r  f u t u r e  p l a n e t a r y  mi s s i o n s  a l o n g  wi t h  b a s i c  e x p e r i m e n t a l  r e s e a r c h  i n  a s t r o b i o l o g y  a n d  p r e bi ot i c  s y nt he s i s   D r   B r i nc k e r hof f  i s  i nv ol v e d i n t he  de v e l opm e nt  of  m as s  s pe c t r om e t e r  f or  bot h t he  2011 Ma r s  S c i e n c e  L a b o r a t o r y  a n d  t h e  2 0 1 8  E x o Ma r s  mi s s i o n s   


  14   


Copyright © 2009 Boeing. All rights reserved  Issues and Observations Initial load of one day of data ~ 7 hours Optimizations  Write data in batches  Use a mutable data structure to create data strings  Deploy a higher performance machine  Use load instead of insert  Use DB2 Range-Partitioned tables  Database tunings Time reduced from 7 hours to approx 30 minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Use a mutable data structure to create data strings  Original application created the SQL statement by appending elements to a Java String  It was taking five hours \(of the seven hours Strings  Instead Java StringBuilder used  Java Strings immutable  Time savings of 71.4 


Copyright © 2009 Boeing. All rights reserved  Optimizations Deployed on a higher-performance machine  Application ported from IBM Blade Center HS21 \(4GB of RAM and 64-bit dual-core Xeon 5130 processor to Dell M4500 computer \(4GB of RAM and 64-bit of quad-core Intel Core i7 processor  Reduced the time to thirty minutes Bulk loading instead of insert  Application was modified to write CSV files for each table  Entire day worth of data bulk loaded  Reduced the time to fifteen minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Range-Partitioned tables \(RPT  To limit the size of tables, the original code created multiple tables per table type  This puts burden on the application to query multiple tables when a range crosses several tables  With RPT, user is not required to make multiple queries when a range crosses a table boundary  Increased the time to thirty minutes  Additional fifteen minute cost per day of partitioning enabled time savings during queries 


Copyright © 2009 Boeing. All rights reserved  Optimizations Database tunings  Range periods changed from a week to a month  Automatic table space resizing changed from 32MB to 512KB  Buffer pool size decreased  Decreased the time to twenty minutes Overall, total time savings of 95.2 


Copyright © 2009 Boeing. All rights reserved  20 IBM Confidential Analytics Landscape Degree of Complexity Competitive Advantage Standard Reporting Ad hoc reporting Query/drill down Alerts Simulation Forecasting Predictive modeling Optimization What exactly is the problem What will happen next if What if these trends continue What could happen What actions are needed How many, how often, where What happened Stochastic Optimization Based on: Competing on Analytics, Davenport and Harris, 2007 Descriptive Prescriptive Predictive How can we achieve the best outcome How can we achieve the best outcome including the effects of variability Used with permission of IBM 


Copyright © 2009 Boeing. All rights reserved Initial Analysis Activities Flights departing or arriving on a date Flights departing or arriving within a date and time range Flights between city pair A,B Flights between a list of city pairs Flights passing through a volume on a date. \(sector, center, etc boundary Flights passing through a volume within a date and time range Flights passing through an airspace volume in n-minute intervals All x-type aircraft departing or arriving on a date Flights departing or arriving on a date between city pair A,B Flights departing or arriving on a date between a list of city pairs Flights passing through a named fix, airway, center, or sector Filed Flight plans for any of the above Actual departure, arrival times and actual track reports for any of the above 


Copyright © 2009 Boeing. All rights reserved  Initial SPSS Applications Show all tracks by call sign 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case For a given Airspace Volume of Interest \(AVOI compute distinct traffic volume at some point in the future  Aim to alert on congestion due to flow control areas or weather if certain thresholds are exceeded  Prescribe solution \(if certain thresholds are exceeded Propose alternate flight paths  Use pre-built predictive model  SPSS Modeler performs data processing Counts relevant records in the database \(pattern discovery Computes traffic volume using statistical models on descriptive pattern Returns prediction with likelihood 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  24 Pulls in the TRACKINFO table of MAIN using SQL Limits the data to database entries which fall inside the AVOI Combines the SOURCE_DATE and SOURCE_TIME to a timestamp that can be understood by modeler Computes which time interval the database entry falls in. The time interval is 15 minutes Defines the target and input fields needed for creating the model Handles the creation of the model Produces a graph based off of the model results Final prediction 


Copyright © 2009 Boeing. All rights reserved  Initial Cognos BI Applications IBM Cognos Report Studio  Web application for creating reports  Can be tailored by date range, aircraft id, departure/arrival airport etc  Reports are available with links to visuals IBM Framework Manager  Used to create the data package  Meta-data modeling tool  Users can define data sources, and relationships among them Models can be exported to a package for use with Report Studio 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 1 of 3 Report shows the departure date, departure and arrival locations and hyperlinks to Google Map images DeparturePosition and ArrivalPosition are calculated data items formatted for use with Google Maps Map hyperlinks are also calculated based on the type of fix 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 2 of 3 DeparturePosition, Departure Map, ArrivalPosition and Arrival Map are calculated data items \(see departure items below DepartureLatitude DepartureLongitude DeparturePosition Departure Map 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 3 of 3 


Copyright © 2009 Boeing. All rights reserved  Conclusion and Next Steps Current archive is 50 billion records and growing  Approximately 34 million elements per day  1GB/day Sheer volume of raw surveillance data makes analytics process very difficult The raw data runs through a series of processes before it can be used for analytics Next Steps  Continue application of predictive and prescriptive analytics  Big data visualization 


Copyright © 2009 Boeing. All rights reserved  Questions and Comments Paul Comitz Boeing Research & Technology Chantilly, VA, 20151 office Paul.Comitz@boeing.com 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  31 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  32 Backup Slides 


Copyright © 2009 Boeing. All rights reserved  Initial Approach Initial Investigations  Apache Solr/Lucene  Data Warehouse Evaluate Hadoop in the future 


Copyright © 2009 Boeing. All rights reserved  Using SOLR Uncompress Track Information Messages To use with Solr  Transforming track messages from their  original schema to Solr required building a ìkey, valueî list using an XSTL  Queries made against this list of ìkey, valueî pairs Transformation Process  One day of data ~ 4.5 hours Once transformation complete search/query performance very good Geo spatial queries using  unique query language 


Copyright © 2009 Boeing. All rights reserved  Representation Aviation data is frequently represented in more than one form 



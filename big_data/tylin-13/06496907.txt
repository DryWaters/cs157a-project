Harbour Surveillance with Cameras Calibrated with AIS Data Francesco A N Palmieri Francesco Castaldo and Guglielmo Marino Dipartimento di Ingegneria Industriale e dell'Informazione Seconda Universit 264 a di Napoli SUN via Roma 29 81031 Aversa CE ITALY francesco.palmieri@unina2.it france.castaldo@gmail.com guglielmo.marino@studenti.unina2.it Abstract\227 The inexpensive availability of surveillance cameras easily connected in network con\002gurations suggests the deployment of this additional sensor modality in port surveillance Vessels appearing within cameras 002elds of view can be recognized and localized providing to fusion centers information that can be added to data coming from Radar Lidar AIS etc Camera systems that are used as localizers however must be properly calibrated in changing scenarios where often there is limited choice on the position on which they are deployed Automatic Identi\002cation System AIS data that includes position course and vessel's identity freely available through inexpensive receivers for some of the vessels appearing within the 002eld of view provide the opportunity to achieve proper camera calibration to be used for the localization of vessels not equipped with AIS transponders In this paper we assume a pinhole model for camera geometry and propose perspective matrices computation using AIS positional data Images obtained from calibrated cameras are then matched and pixel association is utilized for other vessel's localization We report preliminary experimental results of calibration and localization using two cameras deployed on the Gulf of Naples coastline The two cameras overlook a section of the harbour and record short video sequences that are synchronized of\003ine with AIS positional information of easily-identi\002ed passenger ships Other small vessels not equipped with AIS transponders are localized using camera matrices and pixel matching Localization accuracy is experimentally evaluated as a function of target distance from the sensors T ABLE OF C ONTENTS 1 I NTRODUCTION                                   1 2 P INHOLE C AMERA M ODEL                      2 3 C AMERA C ALIBRATION                          3 4 3D-L OCALIZATION                               4 5 H ARBOUR S CENARIO                             4 6 C AMERA C ALIBRATION U SING AIS             5 7 E XPERIMENTS IN THE G ULF OF N APLES        6 8 C ONCLUSIONS                                    7 A CKNOWLEDGMENTS                            8 R EFERENCES                                     8 B IOGRAPHY                                      8 1 I NTRODUCTION Future surveillance systems will be based on the integration of large amounts of heterogeneous data coming from different sensor modalities The availability of low-cost sensors poses new challenges to the harbour management systems that will have to make intelligent use of current information coming This project is partially sponsored by Ministero Infrastrutture e Trasporti PON01-01936 Harbour Traf\002c Optimization System HABITAT with Consorzio Nazionale Interuniversitario per le Telecomunicazioni CNIT 978-1-4673-1813-6/13 31  00 c 015 2013 IEEE Figure 1  Harbour scenario with surveillance cameras from Radar Lidar satellite sensors surveillance networks etc Low-cost networked cameras in the visible and/or infrared spectra add an interesting opportunity to provide additional information to the harbour management specially in critical conditions for localization of non cooperative vessels Security and near-coast collision avoidance will bene\002t from rich data fusion that utilizes anything available at anytime In this work we analyze the problem of fusing information from surveillance cameras arbitrarily displaced on the harbour coastline as shown in Figure 1 Off-the-shelf lowcost cameras may have different accuracies be deployed with no special provisions record data asynchronously at different rates cover different sea sections and be subject to lossy transmission Useful combination of such information requires robust techniques for camera calibration and feature extraction Camera calibration is a well-known topic in the computer vision literature with Tsai and Zhang 2 the standard reference methods that require known anchor points in order to extract the mapping model between cameras and the 3D world In this paper we propose that camera calibration be based on some vessel GPS positions available from the AIS network 4 5 AIS is a well-kno wn automatic identi\002cation system that provides information about the status of registered ships However not all ships below a certain class are required to be equipped with such a system small sailboats motorboats etc and sometimes these are the most critical ones in harbour safety and security It is enough that an AIS-equipped vessel appears at least few times in each camera 002eld of view to grab useful information for calibration Once cameras have been calibrated it is possible to fuse all images for localizing other targets In this paper we apply calibration and localization algorithms to the harbour scenario reviewing the corresponding mathematical models We include experimental results of such a procedure for images grabbed with two commercial cameras in the Gulf of Naples using two passenger ships for calibration 1 


Figure 2  Pinhole camera model with image plane parallel to  X c  Y c  The paper is structured as follows In Section 2 we review the camera model and in Section 3 and 4 camera calibration and 3D-localization procedures are explained In Section 5 we show how such a technique is applied to the harbour scenario In Section 6 the theoretical results are applied to our case study Section 7 reports the results obtained in different experiments in the Gulf of Naples harbour Section 8 draws conclusions and suggests future developments 2 P INHOLE C AMERA M ODEL A camera is a mapping between 3D world objects and a 2D image We consider the simplest camera model the so-called pinhole model  From Figure 2 point C  to which all viewing rays from 3D space points converge is the origin of the Euclidean coordinate system and it is called the center of projection  The center of projection is also called the camera center or the optical center  This model emerges as the equivalent of a classical camera setup in which the camera plane also called image plane  is behind the camera center C  The image that is formed upside down on the camera plane is transposed in front of the camera center where the image appears in its natural orientation and with the same dimensions Such a plane Z c  f is the new image plane as shown in Figure 2 The line that heads perpendicularly from the camera center to the image plane is called the principal axis for the camera The intersection p of the principal axis and the image plane is called principal point  A 3D point  X c   X c  Y c  Z c  T in the Euclidean space  X c  Y c  Z c  centered in C called the camera standard reference frame is mapped to a point  x   x y  T on the image plane where the viewing line of  X c meets the image plane The image reference frame is centered in p with x and y axes parallel to X c and Y c  Considering the plane  Y c  Z c  as shown in Figure 3 by similarity of  d CZ c Y c  and  d Czy   we can write y  f Y C Z C  By the same reasoning in the plane  X c  Z c  we have x  f X C Z C  Therefore the point  X C  Y C  Z C  T is mapped to the point  f X C Z C  f Y C Z C  f  T  that lies on the image plane Ignoring the obvious third coordinate we can write  X c   X c  Y c  Z c  T   x   x y  T   f X c Z c  f Y c Z c  T  1 Note that we cannot write 1 in terms of matrix multiplications due to the non-linearity of the mapping between the Figure 3  Relation of coordinates system to focal length coordinates of  X c and  x  It is convenient as it has become standard in the literature to de\002ne world and image points by the augmented vectors X c  022  X c 1 023  x  022  x 1 023  called homogeneous coordinates  Observing that  f X c f Y c Z c    f 0 0 0 0 f 0 0 0 0 1 0  0 B  X c Y c Z c 1 1 C A  2 multiplying and dividing the 002rst member of 2 by Z c we can write Z c 0  f X c Z c f Y c Z c 1 1 A  Z c x  and then write X c  Z c x   f X c f Y c Z c    f 0 0 0 0 f 0 0 0 0 1 0  0 B  X c Y c Z c 1 1 C A  More compactly we have 025 x  P X c  3 where 025 is a generic scale factor that depends on the speci\002c point X c  Another way to write this expression is x  P X c  where  denotes equalities up to a scale factor Matrix P   f 0 0 0 0 f 0 0 0 0 1 0   is called the camera projection matrix  The camera model just presented above is the simplest one and it is idealized because we have assumed that the origin of coordinates in the image plane is at the principal point and that the image plane is parallel to the  X c  Y c  plane However cameras deployed in arbitrary position and orientation need to be described in a more general reference system A 002rst generalization assumes that the origin of image coordinates is not in in the principal point p  Denoting p   p x  p y  T  we can write  X c   x   f X c Z c  p x  f Y c Z c  p y  T  2 


Figure 4  Image coordinate system with principal point translation Figure 5  World-to-camera coordinate frames that in homogeneous coordinates is X c  025 x   f X c  Z c p x f Y c  Z c p y Z c   P 0 B  X c Y c Z c 1 1 C A  4 where P   f 0 p x 0 0 f p y 0 0 0 1 0   K  I 3 j   with K   f 0 p x 0 f p y 0 0 1   and I 3 the 3 002 3 identity matrix K is called the camera calibration matrix  Generalizing the standard camera coordinate frame  X c  Y c  Z c  to generic coordinates known as the world coordinate frame  X Y Z   as shown in Figure 5 we can relate the two coordinate frames through a rotation matrix R and a translation vector t  Therefore  X c  R  X Y Z  000  C x C y C z   R   X 000  C   where  X   X Y Z  T and  C   C x  C y  C z  T represent respectively the generic 3D point and the camera center in the world reference frame In homogeneous coordinates we can write X c  024 R 000 R  C 0 1 025 0 B  X Y Z 1 1 C A  024 R 000 R  C 0 1 025 X  5 where x  022  x 1 023 is the generic point in homogeneous image coordinates Therefore putting 4 and 5 together we have 025 x  P X  6 with P  KR  I 3 j 000  C   We can decide not to show explicitly the camera center  C and write the transformation as  X c  R  X  t  with t  000 R  C  Therefore the camera matrix is P  K  R j t   Another element that we should take into account is the possibility of different scaling along both image coordinates In the model derived above we assumed that image coordinates are Euclidean with equal scales in both axes directions In transfering the coordinates to pixels we will need to multiply the original coordinates by scale factors m x and m y as pixels may have different equivalent dimensions in x and y the number of pixel per unit distance in x and y direction may be different Matrix K becomes K   013 x 0 x 0 0 013 y y 0 0 0 1  with 013 x  f m x and 013 y  f m y and x 0  m x p x and y 0  m y p y the coordinates of the principal points in terms of pixels in x and y direction In the form derived above the parameters contained in K f f 013 x  013 y  x 0  y 0 g are called internal or intrinsic parameters  and the parameters in R and t are called external or extrinsic parameters  This camera model has 10 degrees of freedom  f 013 x  013 y  x 0  y 0  f g form a set of four independent parameters plus we have three for R and three for t  3 C AMERA C ALIBRATION The goal of camera calibration is to calculate the camera projection matrix P de\002ned above when the sensor is deployed in arbitrary locations We assume to know a certain number of point correspondences f x i  X i g between 3D points X i and 2D image points x i projections on the image plane of X i  and we are required to 002nd the matrix P such that 025 x i  P X i  as shown in 6 for all i  World points may be extracted from known landmarks or objects There are several ways to accomplish calibration One possible approach is to rewrite the equation as  025x i 025y i 025    p 11 p 12 p 13 p 14 p 21 p 22 p 23 p 24 p 31 p 32 p 33 p 34  0 B  X Y Z 1 1 C A  7 where  025x i 025y i 025   025 x i  025  x i y i 1   and P   p 11 p 12 p 13 p 14 p 21 p 22 p 23 p 24 p 31 p 32 p 33 p 34   8 with x i  025x i 025  p 11 X i  p 12 Y i  p 13 Z i  p 14 p 31 X i  p 32 Y i  p 33 Z i  p 34 y i  025y i 025  p 21 X i  p 22 Y i  p 23 Z i  p 24 p 31 X i  p 32 Y i  p 33 Z i  p 34  9 We can write a homogeneous linear system using 9 for each known correspondence In our model P has 10 degrees of freedom therefore we need at least 5 world-images point matches but in general using a calibration pattern we can obtain many more correspondences and consequently calculate a more accurate solution through a least-squares method In fact given N correspondences we can write 3 


A p  0  with A  2 6 6 6 6 6 6 4 X 1 Y 1 Z 1 1 0 0 0 0 000 x 1 X 1 000 x 1 Y 1 000 x 1 Z 1 000 x 1 0 0 0 0 X 1 Y 1 Z 1 1 000 y 1 X 1 000 y 1 Y 1 000 y 1 Z 1 000 y 1 X 2 Y 2 Z 2 1 0 0 0 0 000 x 2 X 2 000 x 2 Y 2 000 x 2 Z 2 000 x 2 0 0 0 0 X 2 Y 2 Z 2 1 000 y 2 X 2 000 y 2 Y 2 000 y 2 Z 2 000 y 2                                     X N Y N Z N 1 0 0 0 0 000 x N X N 000 x N Y N 000 x N Z N 000 x N 0 0 0 0 X N Y N Z N 1 000 y N X N 000 y N Y N 000 y N Z N 000 y N 3 7 7 7 7 7 7 5 and p   p 11  p 12   p 33  p 34  T  We have to solve a set of homogeneous equations in which there are more equations than unknowns The obvious solution p  0 is not of interest therefore we have to pick a constraint in order to impose the minimization problem A reasonable constraint would be jj p jj  1  we also observe that if p is a solution then so is k p for any scalar k  Therefore the least-squares problem can be stated as 002nding p that minimizes jj A p jj subject to jj p jj  1  Using the SVD we know that A  U 006 V T  then the problem requires to minimize jj U 006 V T p jj  However jj U 006 V T p jj  jj 006 V T p jj and jj p jj  jj V T p jj using the properties of orthonormal matrices U and V  Therefore we have to minimize jj 006 V T p jj subject to jj V T p jj  1  If we put y  V T p  the problem becomes to minimize jj 006 y jj subject to jj y jj  1  Since 006 is a diagonal matrix with its elements in descending order the minimum solution is simply y  0  0   0  1 T  and since p  V y is simply the last column of V  Rearranging p we can obtain P  Improvements of the resulting P can be achieved implementing data normalization and iterative procedures to reduce the error 4 3D-L OCALIZATION Assuming that projection matrices P i are known for each camera i  we can localize a generic 3D point X using camera matrices and corresponding 2D points x i on each camera that are the projection of the same X onto the two image planes A separate problem is the identi\002cation of corresponding points in different images i.e given one pixel in the 002rst image 002nd automatically its homologous in the second image  In this paper we do not address such a problem and in the experiments that will follow we have manually localized homologous points in pairs of images Object identi\002cation is a important larger problem that we will address elsewhere Going back to the 3D inversion if we have available only two cameras the problem also known as camera intersection  can be stated as follows From 6 applied to both cameras we have 025 1 x 1  P 1 X 025 2 x 2  P 2 X  This pair of equations can be rearranged in matrix form as A X 025  0  10 with A  024 P 1 x 1 0 P 2 0 x 2 025  Figure 6  3D world points on the sea plane framed by a camera and X 025  2 6 6 6 6 4 X Y Z 1 000 025 1 000 025 2 3 7 7 7 7 5  We can solve the system via a least-squares method as the one presented for camera calibration and obtain X 025  from which extract X 002rst 4 elements of X 025  The method can be applied to an arbitrary number of cameras assuming to have N cameras and to know N 2D points x i  projections of the 3D point X that needs to be reconstructed we get equation 10 with A  2 6 6 6 6 6 6 4 P 1 x 1 0 0    0 P 2 0 x 2 0    0 P 3 0 0 x 3    0                P N 0 0 0    x N 3 7 7 7 7 7 7 5  and X 025  2 6 6 6 6 6 6 6 6 4 X 000 025 1 000 025 2 000 025 3    000 025 N 3 7 7 7 7 7 7 7 7 5  5 H ARBOUR S CENARIO In the harbour application we constrain the world points X to lie on the two-dimensional sea plane Our world coordinates are latitude and longitude as shown in Figure 6 In this case the relationship to consider is 025 x  HX  11 with X that now with an abuse of notation indicates a GPS 2D point in homogeneous coordinates and H is a 3 002 3 matrix usually called homography matrix The relationship between homography H and projective matrix P presented above is  h 11 h 12 h 13 h 21 h 22 h 23 h 31 h 32 h 33    p 11 p 12 p 14 p 21 p 22 p 24 p 31 p 32 p 34   4 


i.e matrix H is P without the third column In order to execute the calibration we have to consider pairs of correspondences between 2D points f x i  X i g  The equation to consider is 025 x i  H X i  for all i  and the goal is to 002nd the homography matrix H  In order to use the procedure presented above we can simply note that  025x i 025y i 025    h 11 h 12 h 13 h 21 h 22 h 23 h 31 h 32 h 33   X i Y i 1   with x i  025x i 025  h 11 X i  h 12 Y i  h 13 h 31 X i  h 32 Y i  h 33 y i  025y i 025  h 21 X i  h 22 Y i  h 23 h 31 X i  h 32 Y i  h 33  12 Therefore just as above we can consider N correspondences and write A h  0  with A  2 6 6 6 6 6 6 4 X 1 Y 1 1 0 0 0 000 x 1 X 1 000 x 1 Y 1 000 x 1 0 0 0 X 1 Y 1 1 000 y 1 X 1 000 y 1 Y 1 000 y 1 X 2 Y 2 1 0 0 0 000 x 2 X 2 000 x 2 Y 2 000 x 2 0 0 0 X 2 Y 2 1 000 y 2 X 2 000 y 2 Y 2 000 y 2                            X N Y N 1 0 0 0 000 x N X N 000 x N Y N 000 x N 0 0 0 X N Y N 1 000 y N X N 000 y N Y N 000 y N 3 7 7 7 7 7 7 5  and h   h 11  h 12   h 33  T  Through singular value decomposition we can 002nd the leastsquares solution and rearranging h  we obtain H  Regarding camera intersection for two cameras we have to consider 11 and write 025 1 x 1  H 1 X  025 2 x 2  H 2 X  that in matrix form is A X 025  0  13 with A  024 H 1 x 1 0 H 2 0 x 2 025  and X 025  2 6 6 4 X Y 1 000 025 1 000 025 2 3 7 7 5  Solving the system we extract X  Similarly with N cameras we have equation 13 with A  2 6 6 6 6 6 6 4 H 1 x 1 0 0    0 H 2 0 x 2 0    0 H 3 0 0 x 3    0                H N 0 0 0    x N 3 7 7 7 7 7 7 5  and X 025  2 6 6 6 6 6 6 6 6 4 X 000 025 1 000 025 2 000 025 3    000 025 N 3 7 7 7 7 7 7 7 7 5  6 C AMERA C ALIBRATION U SING AIS The algorithm developed in this work implements camera calibration using AIS data coming from various ships sailing near the coast AIS Automatic Identi\002cation System 4 5 is an automatic tracking system used on ships and by VTS Vessel Traf\002c Services to identify and locate vessels in real-time by electronically exchanging data through VHF transmissions with other nearby ships and AIS base stations AIS principal functions are to allow information exchange between vessels within VHF range or shore station increasing situational awareness improving traf\002c management in congested waterways and sending safety related information AIS cannot replace radar not all the ships are equipped with AIS and the system cannot detect land masses or navigational beacons but it can be used in conjunction with it improving vessel tracking no target swap providing a wider geographical coverage a greater positional accuracy dependent on the position input sensor information in radar shadow area sees around bends and behind islands near real-time maneuvering data and no loss of targets in sea rain and snow clutter Dynamic messages given by the system provide realtime information on the trip such as ship's position speed course and time stamp in UTC automatically updated from the ship sensors connected to AIS We propose to use GPS information coming from the AIS network fused with images to provide the necessary calibration GPS coordinates are provided in decimal degrees and are assumed to be the Cartesian coordinated on the sea plane Distances of interest allow us to ignore the terrestrial curvature The cameras are placed on the harbour coastline in 002xed positions any change of camera position or orientation implies a signi\002cant variation of extrinsic parameters of camera matrix K  In order to implement the camera calibration algorithm presented above we need at least 5 correspondences between image points and world points In our scenario image points for calibration are the pixel positions of one or more well-identi\002ed ships with AIS on board and world points are GPS positions of the same ships grabbed from the AIS network Vessels and ships are basically on the same 223plane\224 the small portion of the sea we frame with cameras therefore we use 2D-constrained geometry for the world coordinates homography and equation 11 with x that denotes image coordinates of the ship and X representing latitude and longitude in homogeneous coordinates of the framed vessel By framing the same ship during its navigation we can obtain a good number of correspondences because pixel coordinates of the vessel are easily extracted from the images and GPS coordinates are provided by AIS Of course ships on the image may occupy more than one pixel therefore we have to choose a criterion to decide what is the pixel that best de\002nes the object position it can be the ship's center the last point in contact with the sea etc In the following sections we will comment further on our speci\002c choice Using more than one ship for calibration we can provide a 223rich\224 set of pairs f x i  X i g to the algorithm and obtain a wellconditioned matrix H  This process is applied to each camera using information about different moving vessels appearing within their own 002eld of view Localization of a generic vessel framed by two or more calibrated cameras is the 002nal step of the procedure Using the camera intersection presented above 13 we 002rst validate the model by localizing ships for which AIS data is known Subsequently we reconstruct the position of vessels without AIS on board clearly the estimation of ship positions will 5 


Figure 7  A frame from Camera 1 used for calibration bene\002t from the use of as many views as possible 7 E XPERIMENTS IN THE G ULF OF N APLES In this experimental setup we have used two inexpensive commercial cameras Toshiba Camileo P20 1920x1080 Camera 1 and Panasonic SDR-H90 1024x576 Camera 2 The two cameras have clocks synchronized with an accuracy of a few seconds The two sensors have different intrinsic parameters and must be calibrated separately One of the two cameras has been purposely tilted to show the robustness of the procedure Two typical frames are shown in Figures 7 and 8 The two 002elds of view are drawn in Figure 9 where only a portion of the monitored area is in common The two cameras have been deployed in via Posillipo in Naples in June 2012 and they were placed with no special provision on the observation railing No intrinsic or extrinsic parameter is known a priori Only image sequences have been used in our calibration procedure We have waited for two passenger ships to appear within the 002eld of view  Abundo and Nomentana  and we have recorded two short image sequences with a rate of 30 and 25 frames per second respectively for the two cameras We have collected AIS data from a publicly available website which pro vides free almost real-time information about ship movements across the coastlines of many countries around the world AIS data were downloaded later and imported off-line in Matlab along with the video sequences We have chosen the pixel de\002ning the ship as the rightmost one in contact with sea surface as shown in Figures 7 and 8 The 002elds of view for the two cameras were estimated calculating through linear interpolation with AIS data the position of a ship which appears and disappears from the camera views To estimate homographies H 1 and H 2  at least 5 calibration points and hand-selected image points are needed for each camera We have extracted six calibration points for Abundo and eight for Nomentana An example of a selected point for both cameras is shown in Figures 7 and 8 while Table 7 shows the fourteen calibration coordinates and the respective image points for both cameras Model Validation\227 To validate our procedure we have run few experiments using thirteen points extracted from Table 7 to calibrate leaving one point out for testing The reconstructed points coordinates longitude and latitude are respectively 14.2427 40.7957 and 14.2541 40.7875 which are fairly close to the real AIS position data that are 14.2432 40.7960 for Abundo's position and 14.2562 40.7864 for Nomentana's position The obtained results Figure 8  A frame from Camera 2 used for calibration TABLE 1 Coordinates of the calibration points and respective image points for the two cameras Calibration points Image pixel points Image pixel points latitude and longitude degrees First camera Second camera Abundo 14.2432 40.7960 1543 994 642 329 14.2455 40.7968 1383 872 527 322 14.2478 40.7976 1226 758 415 320 14.2503 40.7989 1075 636 304 322 14.2529 40.8002 929 524 193 319 14.2555 40.8014 779 416 86 317 Nomentana 14.2699 40.7967 663 323 18 318 14.2681 40.7954 776 406 104 318 14.2663 40.7940 890 496 188 317 14.2641 40.7924 1006 583 274 317 14.2620 40.7908 1120 669 360 320 14.2598 40.7892 1238 756 441 320 14.2577 40.7876 1348 846 526 318 14.2562 40.7864 1468 931 609 324 are also shown in Figure 9 where the red triangles represent Abundo's positions given by AIS the cyan triangles indicate Nomentana's positions given by AIS the green triangles indicate reconstructed Nomentana and Abundo's test positions and the green stars indicate the camera positions Vessel without AIS localization\227 Finally localization of a small vessel not equipped with AIS has been considered Cameras calibrated using all the fourteen points shown in Table 7 have captured different images during the transit of other vessels We have chosen one of these boats to be our target and after hand-selection of the corresponding image pixels shown in Figures 10 and 11 we have estimated the boat's position The obtained coordinates are 14.2231 40.8151 and they are represented with a green circle in Figure 9 We have no ground truth for this localization because the vessel has no AIS on board but approximate visual estimate seem to match well the result of our automatic procedure Localization Accuracy\227 To evaluate localization accuracy we have varied the image points corresponding to the vessel's position between 000 10 and 10 pixels in two orthogonal directions direction of motion and its normal Figure 12 a and b show the test points for the small vessel from Camera 1 and 2 respectively For each homologous pair on the cross pattern we have performed position estimation as shown in Figure 13 a that visualizes position error covariance 6 


Figure 9  A map of the area with 002elds of view and localization points Figure 10  A frame and the image points from Camera 1 for the vessel without AIS By applying the same procedure to one of the previously estimated position for both passenger ships as shown in Figure 13 b and c we obtain a much more stretched estimated covariance Clearly localization accuracy in range is much smaller than in azimuth and it is a function of target distance from the sensors All the results are superimposed as green points in Figure 13 d observing that the crosses keep their shape near the coast and collapse with increasing distance 8 C ONCLUSIONS This paper has proposed an innovative calibration technique for cameras displaced on harbour coastline in which the calibration points are obtained from AIS data from ships sailing in the cameras 002elds of views Our experimental results have showed that the procedure localizes well vessels appearing in the two camera 002elds of view Future work will focus on the deployment of larger arrays of cameras A con\002guration with N cameras implies a longer calibration phase but any increase in view diversity would contribute to an increase in localization precision The procedure must be inherently adaptive also because a generic vessel could be seen only by a subset of the sensor array at any given time Therefore localization of a vessel requires a combination of solutions of different systems 13 for best use of available information Figure 11  A frame and the image points from Camera 2 for the vessel without AIS Figure 12  Pixel cross-variation for Camera 1 a and Camera 2 b to evaluate localization accuracy Figure 13  Error position covariance for vessel without AIS a Abundo b and Nomentana c 7 


Another important issue is the positioning of cameras in the harbour It is well-known that the localization accuracy is strongly dependent on the distance from the vessels range but an intelligent displacement of cameras with their 002elds of view properly intersected to cover almost the same portion of the sea plane could increase the strength of the whole process A CKNOWLEDGMENTS We would like to thank Prof Carlo Regazzoni from Universit 264 a di Genova for very stimulating discussions on data fusion and for letting us use his precious class notes R EFERENCES  R Tsai 223A versatile camera calibration technique for high-accuracy 3d machine vision metrology using offthe-shelf tv cameras and lenses,\224 IEEE Journal of Robotics and Automation vol 3 no 4 pp 323-344  August 1987  Z Zhang 223A 003exible new technique for camera calibration,\224 IEEE Transactions on Pattern Analysis and Machine Intelligence vol 22 no 11 pp 1330-1334  November 2000  Technical characteristics for an automatic identi\002cation system using time-division multiple access in the VHF maritime mobile band  Recommendation ITU-R M.1371-4 April 2011  IALA Guideline No 1082 On an Overview of AIS  International Association of Marine Aids to Navigation and Lighthouse June 2011  International Convention for the Safety of Life at Sea SOLAS  IMO May 2011  R Hartley and A Zisserman Multiple View Geometry in Computer Vision 2ed  Cambridge 2003  E Trucco and A Verri Introductory Techniques for 3-D Computer Vision  Prentice Hall 1998  G Medioni and S B Kang Emerging Topics in Computer Vision  Prentice Hall 2004  223Marine traf\002c,\224 http://www.marinetraf\002c.com/ais 2012 B IOGRAPHY  Francesco A.N Palmieri received his Laurea in Ingegneria Elettronica from Universita degli Studi di Napoli Federico II Italy in 1980 In 1981 he served as a 2nd Lieutenant in the Italian Army in full\002llment of draft duties In 1982 and 1983 he was with the ITT 002rms FACE SUD Selettronica in Salerno currently Alcatel Italy and Bell Telephone Manufacturing Company in Antwerpen Belgium as a designer of digital telephone systems In 1983 he was awarded a Fulbright scholarship to conduct graduate studies at the University of Delaware USA where he received a Master's degree in Applied Sciences and a PhD in Electrical Engineering in 1985 and 1987 respectively He was appointed Assistant professor in Electrical and Systems Engineering at the University of Connecticut Storrs USA in 1987 where he was awarded tenure and promotion to Associate Professor in 1993 In the same year he was awarded the position of Professore Associato at the Dipartimento di Ingegneria Elettronica e delle Telecomunicazioni at Universit 264 a degli Studi di Napoli Federico II Italy where he has been until October 2000 when he became Professore Ordinario di Telecomunicazioni and moved to the Dipartimento di Ingegneria dellInformazione  Seconda Universit 264 a di Napoli Aversa Italy His research interests are in the areas of signal processing data fusion communications information theory and neural networks Francesco Castaldo received his Laurea in 2009 and his Laurea Magistrale in 2012 both in Ingegneria Informatica from Seconda Universita degli Studi di Napoli SUN He has cooperated during his thesis work with the PRISMA lab at Universit 264 a degli Studi di Napoli Federico II with prof B Siciliano and prof V Lippiello He is currently a postgraduate fellow with the Dipartimento di Ingegneria Industriale e dell'Informazione at SUN His research interests are in image processing computer vision and data fusion applied to robotics and home automation Guglielmo Marino received his Laurea in Ingegneria Elettronica at Seconda Univerit 264 a degli Studi di Napoli SUN in December 2012 His 002nal thesis project has been on data fusion of digital images with AIS data in harbor management 8 


boards of several journals including IEEE Transactions on Service Computing and the Journal of Performance Evaluation   Zhen has given keynotes and distinguished lectures in various conferences and universities. He was an adjunct professor at University of Science and Technology of China and Beijing University of Post and Telecommunications While he was in France Zhen was  also an adjunct professor of the University of Paris VI \(University of Pierre & Marie Curie\and the University of Nice  Sophia Antipolis, France   His areas of expertise include mobile computing, mobile services, cloud computing, stream processing re al time analytics performance modeling stochastic optimization service oriented architecture and semantic Web      
lxxxi 


en-US Keynote VI I I  en-US GreenCom iThings CPSCom 2013   Towards Carrier Cloud   Dr. Tarik Taleb  Senior Researcher and 3GPP Standards Expert  NEC Europe Ltd, Heidelberg, Germany  Email tarik.taleb@nw.neclab.eu    Abstract   Mobile operators are in need of means to cope with the ever increasing mobile data traffic, introducing minimal additional capital expenditures on existing infrastructures, principally due to the modest Average Revenues per User ARPU Network virtualizat ion and cloud computing techniques along with the principles of the latter in terms of service elasticity on demand and pay per use could be important enablers for various mobile network enhancements and cost reduction This talk discusses the recent tr ends the mobile telecommunications market is experiencing showcasing some of the emerging consumer products and services that are facilitating such trends. The talk also discusses the challenges these trends are representing to mobile network operators. T he talk also demonstrates the possibility of extending cloud computing beyond data centers towards the mobile end user providing end to end mobile connectivity as a cloud service. The talk introduces a set of technologies and methods for the on demand pro vision of a decentralized and elastic mobile network as a cloud service over a distributed network of cloud computing data centers; federated cloud. The concept of Follow Me Cloud whereby not only data but also mobile services are intelligently following t heir respective users is also introduced. The novel business opportunities behind the envisioned carrier cloud architecture and service are also discussed, considering various multi stakeholder scenarios   Bio   Tarik Taleb is currently working as Senior Researcher and 3GPP Standards Expert at NEC Europe Ltd Heidelberg, Germany. Prior to his current position and till Mar. 2009, he worked as assistant professor at the Graduate School of Information Sciences, Tohoku University, Japan, in a lab fully funded by KDDI, the second largest network operator in Japan From Oct 2005 till Mar 2006 he was working as research fellow with the Intelligent Cosmos Research Institute Se ndai Japan He received his B E   degree in Information Engineering with distinction M.Sc and Ph.D degrees in Information Sciences from GSIS Tohoku Univ., in 2001, 2003, and 2005, respectively   Dr Taleb  s research interests lie in the field of architectural enhancements to mobile core networks particularly 3GPP  s mobile cloud net working mobile multimedia streaming congestion control protocols handoff and mobility management inter vehicular communications and social media networking Dr Taleb has been also directly engaged in the development and standardization of the Evolved  Packet System as a member of 3GPP  s System Architecture working group. Dr. Taleb is a board member of the  IEEE Communications Society Standardization Program Development Board  As an attempt to bridge the gap between academia and industry Dr Taleb has f ounded and has been the     Dr Taleb  is/was on the editorial board of the IEEE Wireless Communications Magazine IEEE Transactions on Vehicular Technology, IEEE Communications Surveys & Tutorials, and a number of Wiley journals. He is serving as vice chair of the Wireless Communications Tech nical Committee, the largest in IEEE ComSoC He also served as Secretary and then as Vice Chair of the Satellite and Space Communications Technical Committee of IEEE ComSoc 2006  2010 He has been on the technical   
lxxxii 


program committee  of different IEEE c onferences including Globecom, ICC and WCNC and chaired some of their symposia   Dr Taleb is the recipient of the 2009 IEEE ComSoc Asia Pacific Best Young Researcher award Jun 2009 the 2008 TELECOM System Technology Award from the Telecommunicati ons Advancement Foundation Mar 2008 the 2007 Funai Foundation Science Promotion Award Apr 2007 the 2006 IEEE Computer Society Japan Chapter Young Author Award Dec 2006 the NiwaYasujirou Memorial Award Feb 2005 and the Young Researcher's Enc ouragement Award from the Japan chapter of the IEEE Vehicular Technology Society \(VTS\\(Oct. 2003\ Some of Dr. Taleb  s research work has been also awarded best paper awards at prestigious conferences. Dr. Taleb is a senior IEEE member      
lxxxiii 


en-US Keynote I X  en-US GreenCom iThings CPSCom 2013   How Densely Should the Data Base Stations  B e Deployed in Hyper Cellular Networks   Professor Zhisheng Niu  Tsinghua National Lab for Information Science and Technology  Tsinghua University, Beijing 100084, China  E mail niuzhs@tsinghua.edu.cn    Abstract   One of the key approaches to make the mobile communication networks more GREEN Globally Resource optimized and Energy Efficient Networks\is to have the cellular architecture and radio resource allocation more adaptive to the environment and traffic varia tions including making some lightly loaded base stations \(BSs\go to sleep. This is the concept of so called TANGO \(Traffic Aware Network planning and Green Operation and CHORUS Collaborative and Harmonized Open Radio Ubiquitous Systems published by th e author earlier. To realize this, a new cellular framework, named hyper cellular networks HCN has been proposed in which the coverage of control signals is decoupled from the coverage of data signals so that the data coverage can be more elastic in ac cordance with the dynamics of traffic characteristics and QoS requirements. Specifically, the data base stations \(DBSs\in HCN can be densely deployed during peak traffic time in order to satisfy the capacity requirement, while a portion of DBSs can be swi tched off or go to sleep mode if the traffic load is lower than a threshold in order to save energy. A fundamental question then arises how densely should the DBSs be deployed in order to balance the QoS requirements and the energy consumption in hyper ce llular networks     In this talk, we characterize the optimal DBS density for both homogeneous and heterogeneous hyper cellular networks to minimize network cost with stochastic geometry theory For homogeneous cases both upper and lower bounds of the optimal DBS density are derived For heterogeneous cases our analysis reveals the best type of DBSs to be deployed for capacity extension or to be switched off for energy saving. Specifically, if the ratio between the micro DBS cost and the macro DBS cost  is lower than a threshold which is a function of path loss and their transmit power then the optimal strategy is to deploy micro DBSs for capacity extension or to switch off macro DBSs \(if possible\for energy saving with higher priority Otherwise the  optimal strategy is the opposite Based on the parameters from EARTH numerical results show that in the dense urban scenario compared to the traditional macro only homogeneous cellular network with no DBS sleeping deploying micro DBSs can reduce about 40 of the total energy cost, and further reduce about 20% with DBS sleeping capability   Bio   Zhisheng Niu graduated from Northern Jiaotong University currently Beijing Jiaotong University Beijing China in 1985 and got his M.E and D.E degrees fr om Toyohashi University of Technology Toyohashi, Japan, in 1989 and 1992, respectively. After spending two years at Fujitsu Laboratories Ltd Kawasaki, Japan, he joined with Tsinghua University, Beijing, China, in 1994, where he is now a professor at the  Department of Electronic Engineering and the deputy dean of the School of Information Science and Technology. His major research interests include queueing theory, traffic engineering, mobile Internet radio resource management of wireless networks, and g reen communication and networks   Dr Niu has been an active volunteer for various academic societies including council member of Chinese Institute of Electronics 2006 10 vice chair of the Information and Communication Network Committee of Chinese In stitute of Communications 2008 12 Councilor of IEICE Japan 2009 11 and membership development coordinator of IEEE Region 10 \(2009 10\ In particular, in IEEE Communication 
lxxxiv 


Society, he has been serving as an editor of IEEE Wireless Communication Magaz ine \(2009 12\ director of Asia Pacific Region \(2008 09\ director for Conference Publications \(2010 11\ chair of Beijing Chapter 2001 08 and members of Award Committee 2011 13 Emerging Technologies Committee 2010 12 On line Content Committee 20 10 12 and Strategy Planning Committee He has also been serving as general co   co    chairs o f    Prof. Niu is a co recipient of the Best Paper Awards from the 13th and 15th Asia Pacific Conference on Communication APCC in 2007 and 2009 respectively and received Outstanding Young Researcher Award from Natural Science Foundati on of China in 2009 He is now the Chief Scientist of the National  Energy and Resource Optimized Hyper Cellular Mobile Communication System 2012 2016 which is the first national project green communications in China He is the fellow of IEEE and IEICE and a distinguished lecturer of IEEE Communication Society \(2012 2013  
lxxxv 



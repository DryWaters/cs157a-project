Guanying Wang Aleksandr Khasymski Krish K R Ali R Butt 
Department of Computer Science Virginia Tech Email wanggy khasymskia kris butta cs.vt.edu 
Towards Improving MapReduce Task Scheduling Using Online Simulation Based Predictions 
MapReduce is the model of choice for processing emerging big-data applications and is facing an ever increasing demand for higher efìciency In this context we propose a novel task scheduling scheme that uses current task and system state information to drive online simulations concurrently within Hadoop and predict with high accuracy future events 
Abstract 
  
e.g when a job would complete or when task-speciìc datalocal nodes would be available These predictions can then be used to make more efìcient resource scheduling decisions Our framework consists of two components i 
Task Predictor Job Simulator 
that predicts task-level execu tion times based on historical data of the same type of tasks and ii that instantiates the real task scheduler in a simulated environment and predicts expected schedulin g decisions for all the tasks comprising a MapReduce job Evaluation shows that our framework can achieve high prediction accuracy  95 of the 
predicted task execution times are within 10 of the actual times  with negligible overhead 1.29 Finally we also present two realistic usecases job data prefetching and a multistrategy dynamic scheduler which can beneìt from integration of our prediction framework in Hadoop 
I I NTRODUCTION In recent years MapReduce/Hadoop 1 h as emer ged a s the de facto model for big data applications and is employed by industry 2   3  4    5  and academia 6  7  8  a lik e Improving the efìciency of Hadoop is therefore crucial Recent research is revisiting classic optimizations such as anticipatory scheduling and historyäbased prediction in the context of Hadoop Delay scheduling 9 del a ys as s i gnment 
of a task with nonäoptimal data lo cality with the a nticipation that a node with better locality may become available soon PACMan 10 manages a n i n memory cache o n each Hadoop node and tries to keep hot data blocks in the cache Such systems typically rely on heuristics for resource management decisions however this can cause false positives/negatives when the heuristics fail to correctly capture the behavior of the current workload We make the observation that if future events can be accurately predicted in Hadoop the information can be used to better drive resource management than the use of pure heuristics only consequently improving overall system per formance For instance if we can predict that no node with 
better data locality will become available in the near future we can avoid the overhead of Delay Scheduling 9 a nd schedule the task immediately Similarly if we can predict when and where a task is likely to be run in PACMan 10  we can prefetch the needed data from disks into the memory cache right before the task start s However predicting behav ior of an entire system is a challenging task For example in operating systems external factors including user input and creation of new processes make future system state hard to predict Similarly highäperformance computing applications usually involve complicated communication and dependen cies between tasks and hence not easily predictable In 
contrast MapReduce tasks ar e inherently independent with no interätask communication or synchronization except for a wellädeìned shufîe phase so task behavior depends only on local node resources Moreover MapReduce is a batch processing system where new tasks are added to a pending queue Thus the scheduler is aware of what workloads are in line to run in the near future These properties are promising in enabling highäaccuracy behavior prediction in a Hadoop In this paper we present an online prediction framework that leverages the above properties of Hadoop that can drive more efìcient task scheduling Powered by historyäbased statistical prediction and online simulation our framework can continuously predict future execution of tasks and jobs 
in live Hadoop The online prediction framework comprises two components and The key insight in is that the execution time of a task is directly correlated with the size of the data the task processes This allows us to derive a linear regression model for task execution time based on task input size and apply the model to estimate execution time of pending tasks predicts when a task will start to run and on which node based on the current state of the system  when invoked replicates the current real 
Task Predictor Job Simulator Task Predictor Job Simulator Job Simulator 
system state and uses the execution time estimates from to simulate future states The real MapReduce scheduler is modiìed to invoke and consider its outcomes before making scheduling decisions Moreover our simulator employs the same code as the real MapReduce scheduler to ensure that the simulated environment is as close to the real events as possible and that the simulation can offer a good prediction for expected future system behavior Speciìcally this paper makes the following contributions We design an online framework for making predic 
Task Predictor Job Simulator 
 
2013 19th IEEE International Conference on Parallel and Distributed Systems 1521-9097/13 $31.00 © 2013 IEEE DOI 10.1109/.49 299 
2013 19th IEEE International Conference on Parallel and Distributed Systems 1521-9097/13 $31.00 © 2013 IEEE DOI 10.1109/.49 299 
2013 19th IEEE International Conference on Parallel and Distributed Systems 1521-9097/13 $31.00 © 2013 IEEE DOI 10.1109/.49 299 
2013 International Conference on Parallel and Distributed Systems 1521-9097/13 $31.00 © 2013 IEEE DOI 10.1109/ICPADS.2013.50 299 


a TeraGen map b random text writer map c TeraSort map d TeraSort reduce Figure 1 Task execution time versus data size for representative Hadoop applications tions based on realätime state of a Hadoop system The framework provides a basis for designing more advanced prediction algorithms and simulations We develop a simulation engine that can predict task scheduler decisions that will be made in the near future and leverage this information to derive more efìcient scheduling decisions We implement the online prediction framework as a patch for Hadoop release 0.20.203.0 We intend to release the patch to the community to enable further research in efìcient MapReduce Systems We evaluate our framework using representative ap plications and show that it achieves high prediction accuracy  95 of the predicted task execution times are within 10 of the actual times  with negligible overhead 1.29 II O NLINE S IMULATION F RAMEWORK In this section we present the main components of our online simulation framework We rst describe the basis for our task execution time predictions followed by how we utilize this information to simulate the system and predict when and where a particular task will be scheduled Our main objective is to predict the execution time for an entire job However since jobs in Hadoop comprise of one or more tasks we rst focus on predicting the execution time for individual tasks making up a job Empirical observation and in tuition suggest that the total computation and I/O time for a MapReduce task is correlated with the input data size of the task To better understand this relationship we run a set of representative MapReduce applications 11 wi t h v a ryi n g i nput dat a s i ze and obs erv e the resulting execution time For this purpose we use a single worker node conìgured with one map slot and one reduce slot to eliminate the effect of any parallelization We also conìgured MapReduce to start running reduce tasks only after all map tasks have nished which ensures that only one task is running on a given node at any time For each application we create jobs to process different data sizes The results of this study are shown in data size versus execution time plots in Figure 1 Each data point on the graphs shows the average execution time and standard deviation observed for tasks with a given data size We observe that most jobs show linear correlation between data size and task execution time In some jobs all associ ated tasks have similar input data sizes and corresponding execution times One notable difference is observed for c TeraSort map where the result shows two different linear correlations one occurring for input data size below 27 MB approximately and the other above that The reason is that in a job such as TeraSort that involves both map and reduce phases when input data size is less than a threshold 27 MB for our test a map task can write to a single output le and no merge is necessary Whereas when input data size is larger than the threshold the map task must write to multiple les and later merge the results This produces the different patterns as observed in the graph The threshold may vary for different jobs and tasks but the pattern is expected to be similar for mapäreduce phase jobs Based on the above observations we predict execution time of a task using information about previously nished tasks of the same type We develop to rst derive a performance model from tasks that have already nished and then apply the model to predict execution time of new tasks observes data sizes and corresponding execution times for all previous tasks of a particular type and uses linear regression to determine the correlation between them With the determined correlation model we can then predict execution time of a task of the same type using its input data size A limitation of is that it must have observed the complete execution of a type of task before it can reasonably predict the execution time for a new task of the type If encounters a task it has not observed before it si mply estimates the execution time based on the input size of the task and a preäspeciìed default value Such predic tion may not be very accurate but serves as a starting point w hich is then reìned when the same type of task is encountered on its next occurrences Also note that although we use a linear regression model based on input data size in our current implementation of  our framework can easily incorporate more complex models such as those presented in 12   7    8   
1 1.5 2 2.5 3 3.5 4 4.5 0 10 20 30 40 50 60 70 80 90 100 Execution time \(s Data size \(MB 1 1.5 2 2.5 3 3.5 4 4.5 0 10 20 30 40 50 60 70 80 90 100 Execution time \(s Data size \(MB 1 1.5 2 2.5 3 3.5 4 4.5 5 5.5 6 0 10 20 30 40 50 60 70 Execution time \(s Input data size \(MB 7 7.5 8 8.5 9 9.5 10 10.5 11 11.5 12 12.5 0 10 20 30 40 50 60 70 80 90 100 Execution time \(s Input data size \(MB 
A Estimating Task Execution Time Using Linear Regression Implementation of Task Predictor Task Predictor Ta sk Predictor Limitations Task Predictor Task Predictor Task Predictor 
50 
   
300 
300 
300 
300 


Job Simulator 
002 002 002 002 002 
heartbeat task finish heartbeat task finish 
Pseudo code for driving engine queue is not empty AND not all jobs have nished next event in the queue advance virtual clock to when occurs is a heartbeat event prepare a status update calls heartbeat processes the heartbeat actions for a heartbeat response with send back to performActions is a task nish event mark as COMPLETED a map task nishes a reduce task nishes Once we have obtained estimated task execution times we use them to predict tasks scheduling decisions for the execution of an entire job as follows We design a realistic simulator  that captures all the information used by Hadoop task scheduler instantiates the same task scheduler code in the simulated environment as that used for the real scheduling and drives a simulation to mimic the scheduling decisions that are likely to occur in the real system given the current state By speeding up virtual time provides a prescient look of how the system will behave in the near future if the scheduler were to continue its course with the currently batched jobs This also allows to predict when and where particular tasks would be scheduled The real scheduler can then use the predicted information from to make more efìcient decisions if needed Finally is updated periodically and the above process is repeated A dedicated thread in the Hadoop process is added to run  First we take a snapshot of the current status of and instantiate a simulated and task scheduler component in  contains replicated information for each running job tasks in each job running tasks etc from the real  We also instantiate a simulated object  n for each that is active in the real system at the time when the current round of simulation started Figure 2 shows the architecture of  and task scheduler in both run the same code as their counterparts in the real system s are simulated objects that are controlled by a discrete event simulator engine s communicate with  similar to how s communicate with the  One challenge we faced was that the original code only works with physical time but had to run with virtual time during the simulations We refactored the code to make it compatible with both physical and virtual time thus enabling the use of the same code directly within  The simulation engine maintains a priority event queue sorted by the virtual time when each event is scheduled to occur The engine advances the virtual time to the point when the next event in the queue will occur and processes the event During the processing more events can be inserted into the queue as events that will occur in the virtual future The engine repeats the process until the queue is empty or in our case when all jobs in the system are completed Algorithm 1 shows the pseudo code for the simulation engine We currently implement two types of events a event and a event On re ceiving a from  the associated creates an upätoädate status and sends a heartbeat message to  processes heartbeat messages calls the task scheduler to make scheduling decisions if necessary and returns a heartbeat response with actions to the  then performs the actions such as a launchämapätask action or a allämapsäcompleted action to launch a reduce task The processing of a heartbeat response message is done after has processed all actions requested in the message On a  simply marks the task as COMPLETED and frees the slots occupied by the task The engine then moves on to process the next event in the queue The procedure is repeated until all jobs in the simulation complete To avoid using too much resources on the physical machine each simulation stops after a long enough virtual period default 1 hour has elapsed typically within about 10 seconds in physical time This amount of simulation is sufìcient as status of the real system may 
Job Simulator SimTT SimTT SimJT SimJT SimJT SimTT SimJT SimJT SimTT SimTT SimTT SimTT SimTT B Predicting Job Schedules Job Simulator Job Simulator Job Simulator Job Simulator Job Simulator JobTracker Job Simulator JobTracker JobTracker SimJT Job Simulator SimJT JobTracker Ta skTra cker SimTT Job Simulator Ta skTra cker Job Simulator JobTracker Job Simulator SimTT SimTT SimJT Ta skTra cker JobTracker JobTracker SimJT JobTracker SimJT SimJT SimTT SimJT SimJT SimTT SimTT SimTT SimTT 
Algorithm 1 while do if then else if then if then else if then end if end if end while 
event event event actions response actions response event task map slots map slots reduce slots reduce slots 
1 1 
Figure 2 Overview of architecture 
301 
301 
301 
301 


change due to newly submitted jobs machine failure or recovery random noise etc Running the simulation for any longer will likely result in it diverging signiìcantly from the actual system behavior can predict each scheduling decision to be made by the task scheduler If the virtualized environment supplied to the task scheduler mimics the real envi ronment the task scheduler will make the same scheduling decision in simulation as it will in the real system with high accuracy since the simulation implements the same code as the real system Every decision is valuable information and can be used to improve overall system performance When all tasks of a job nish in the simulation we can predict the total job nish time as well as the start and nish time of all of its tasks The simulator engine drives  which in turn calls and the task scheduler on a  The engine and can be viewed as a virtualized environment which surrounds and the task scheduler as if and task scheduler are running in a real system Fur thermore since we do not modify the existing task scheduler code is compatible with any deterministic task scheduler To make a task scheduler compatible with our  the scheduler must implement a method to create a new task scheduler object that is a snapshot of itself and the scheduler must support virtual time We have ported the default JobQueueTaskScheduler and Fair Scheduler naive fair scheduler as discussed in 9  to work with  One limitation of is that it can predict the execution time only of the jobs that are submitted when the simulation starts In contrast to real Hadoop does not have a job client and no new jobs can be added during a simulation run However this is not a problem since the simulation is rerun periodically and new jobs can be captured in the next round also cannot predict hardware and network failures In every simulation all jobs are simulated with the assumption of no failure When a failure does occur in the real system we rely on the subsequent simulation runs to include the failure and simulate its impact This is also not a major hurdle as the simulation can be reäinvoked soon after the system recovers and will quickly adapt to the new system state In order to be practically useful the simulation time must not be longer than the interval between two simulations executions In a large cluster might be too busy running simu lations and not be able to keep up with heartbeat messages from s In order to minimize performance impact on the  can be separated from as a standäalone process or even run on another node The new process can communicate with to get status update and send simulation results via periodical heartbeat messages Thus pro cess will minimize the overhead on process and utilize processing power of multiäcore processors or even processing power of another node III E VA L UAT I O N We have implemented the online prediction framework including both and as a patch for Apache Hadoop release 0.20.203.0 in about lines of code In this section we evaluate the prediction accuracy of and under two sched ulers JobQueueTaskScheduler the default Hadoop FCFS scheduler and Fair Scheduler 9 W e al s o i n v e s t i g at e t he performance impact of our approach on  We conducted our experiments on a small cluster with and s Nodes are connected via a 1000 Mbps link Each is conìgured with map and reduce slots We conìgured MapReduce to launch reduce tasks only after all map tasks have nished Speculative execution is turned off In the rst set of tests we evaluate the accuracy of s task execution time predictions We run a work load with grep jobs and wordäcount jobs and record the predicted and actual execution time for each associated task The jobs are submitted together in the beginning of the test We run the same 20äjob workload twice rst for training and then for the testing is turned off in this experiment We run the same experiment under both FCFS scheduler and Fair Scheduler The results for map tasks under the stud ied schedulers are shown in Figure 3 and 4 The graphs show normalized error expressed as percentage of predicted execution time against actual execution time of a task A positive error means that a predicted value is larger than the actual value while a negative error means that the predicted value is smaller The predictions are ordered by the order in which each task nished as observed in the Hadoop task log Overall we observe that 95 of the predictions are within 10 of the actual measurements and 75 of all errors are within 5 of real ex ecution time These results are promising in the showing the efìcacy of our approach Prediction accuracy of our approach for reduce tasks under the two schedulers also sees high accuracy 95 of all prediction errors are within 10 of actual measurements We observe few signiìcant outliers e.g a task running for seconds predicted to run for seconds We believe that such outliers can be reduced with more training that is possible in a long running scheduler with much more historic information Moreover given high accuracy for most of the tasks we expect the impact of such missed predictions to be small 
Predictions Based on Online Simulation Job Simulator SimTT SimJT SimTT SimJT JobTracker Job Simulator Job Simulator Job Simulator Limitation Job Simulator Job Simulator Job Simulator Job Simulator Performance Impact of Job Simulator JobTracker Ta skTra cker JobTracker Job Simulator JobTracker Job Simulator JobTracker Job Simulator JobTracker Task Predictor Job Simulator Task Predictor Job Simulator JobTracker JobTracker Ta skTra cker Ta skTra cker A Prediction Accuracy of Task Predictor Ta sk Predictor Job Simulator Map tasks Reduce tasks 
heartbeat copy 
6000 1 3 2 2 10 10 3 7 8 
 
302 
302 
302 
302 


40 30 20 10 0 10 20 30 Relative error Prediction grep-search grep-sort wordcount 
In the next test we study the accuracy of  For this purpose we run a workload of wordäcount jobs twice rst for training as before and then for testing  In this case we did not use grep jobs as they involve dependency between jobs For every test we record predicted ex ecution time of each task and each job We show the results of predicted execution time of each of the jobs under the two studied schedulers in Figures 5 and 6 Individual lines show how predicted execution time of each job change s as the workload executes A line stops when a job completes as no further predictions are made for that job Flat lines as seen for FCFS in Figure 5 show that our predictions do not change over time and are accurate from the beginning of the workload run Error in predicted execution time of each job is observed to be within seconds for the seconds workload Results for Fair Scheduler also show stable prediction for each job with error observed to be within seconds Given the seconds workload runtime we note that we can predict nish times of jobs minutes earlier as long as no other job is submitted during our simulation To further understand the accuracy of we divide prediction of task execution time provided by and prediction of task start time provided by  We compare the start time of each task predicted by against the actual start time of the task Since runs periodically the information is most useful for a short time window in the near future when seconds for the second workload for both the cases of 30äsecond windows and 60äsecond windows Fair Scheduler results however show much higher average errors up to seconds This is because Fair Scheduler is more sensitive to small differences in task execu tion time A small difference may result in a task from a different job scheduled or a task scheduled to another node or after a long interval Some tasks are predicted outäofäorder as compared to actual execution trace so the error could be very large To avoid bias due to highäerror tasks we calculated average percentage of tasks within each window that are predicted to start within an error bound Moreover map tasks must be predicted to run on the same nodes that they are actually scheduled on The result is shown in Figure 9 and shows that under Fair Scheduler nearly 80 of tasks in a 30äsecond window are predicted correctly with an error of less than seconds Hence we observe that is accurate for most of the tasks even though 20 tasks are predicted to run outäofäorder with much higher errors To study the overhead of our online prediction framework caused by the periodic running of the online simulation 
B Prediction Accuracy of Job Simulator Job Simulator Task Predictor Job Simulator Job Simulator Ta sk Predictor Job Simulator Job Simulator Job Simulator Job Simulator C Performance Overhead of Online Simulation 
20 15 10 5 0 5 10 15 Relative error Prediction grep-search grep-sort wordcount 0 100 200 300 400 500 600 700 800 900 1000 0 5 10 15 20 25 30 35 40 45 50 Predicted execution time \(s Prediction job 1 job 2   job 3   job 4   job 5   job 6   job 7   job 8   job 9   job 10 0 100 200 300 400 500 600 700 800 900 1000 0 5 10 15 20 25 30 35 40 45 50 Predicted execution time \(s Prediction job 1 job 2   job 3   job 4   job 5   job 6   job 7   job 8   job 9   job 10 
10 10 10 900 40 900 15 2 900 70 2 
Figure 3 Prediction errors for map tasks under FCFS scheduler Figure 4 Prediction errors for map tasks under Fair Scheduler Figure 5 Prediction of job execution time under FCFS scheduler Figure 6 Prediction of job execution time under Fair Scheduler the scheduler can act on the information To test this we determine all tasks that start to run in a 30äsecond or 60 second window after each simulation run and compare the error of actual start time and predicted start time of these tasks Figures 7 and 8 show average prediction error of start time of all tasks within each window FCFS results show almost perfect predictions with average errors of less than 
303 
303 
303 
303 


MEASURED IN TERMS OF AVERAGE JOB EXECUTION TIME  MAXIMUM JOB EXECUTION TIME AND HEARTBEAT PROCESSING RATE  service for dataäintensive parallel computing frameworks such as MapReduce While PACMan is effective in reducing average completion time of jobs by over 50 the authors also note that data processed by over 30 of tasks is accessed only once which cannot beneìt from caching Thus even with large amounts of RAM e.g 20 GB per node in PACMan caching efìciency can still be improved Our system can facilitate much higher efìciency than gen eralized caching Rather than caching previously accessed data in memory and hoping that some tasks will access the cached data we can use our system to predict which data blocks will be accessed on which node Then we can prefetch or retain only the needed data blocks into memory just before tasks start to run Thus the I/O latency of the data access is hidden from the task when it starts and depending on the accuracy of our predictions that is high as shown in our evaluation we can achieve signiìcantly higher hit ratio Moreover data that is not likely to be accessed again can be discarded immediately e.g the 30 of jobs observed in PACMan will have their data prefetched and see a performance gain but their data will be discarded after the rst use to free the cache and beneìt other jobs Thus using our approach also eliminates the need for reserving large amounts of RAM for caching which would otherwise be needed to support such jobs Prefetching is good at reducing data loading time for all tasks with modest RAM usage However it can impose increased load on disk if we discard data from RAM as soon as the processing is nished Prefetching works best if a long queue of jobs are waiting to run In contrast caching can reduce load on disks by absorbing recurring access to the 
Job Simulator Job Simulator 
grep and word count jobs with and without Wevarythe simulation period and measure the impact of running the extra simulations on our workload performance We use the Fair Scheduler for this purpose though not shown FCFS shows similar results We summarize average job execution time maximum job execution time workload execution time and heartbeat processing rate calculated by number of heartbeats processed divided by length of experiment in Table I Running every seconds incurs a 1.29 overhead in workload execution time and a 5.29 reduction in heartbeat processing rate In larger clusters we expect higher overhead on and as a result propose separating process in order to lower the overhead on  In summary our results show that can help in improving scheduling performance while imparting small overhead IV C ASE S TUDIES D YNAMIC S CHEDULING AND D ATA P REFETCHING In this section we introduce two use cases for our online simulations framework namely data caching and prefetching and dynamic scheduler selection Figure 10 and outline how it can be employed to improve the overall performance and efìciency in each case Data caching for MapReduce systems has been the focus of recent research For instan ce PACMan 10 is a caching 
10 10 20 
0 1 2 3 4 5 6 7 8 0 5 10 15 20 25 30 35 40 45 50 Average error in start period \(s Prediction 30s 60s   0 10 20 30 40 50 60 70 80 0 5 10 15 20 25 30 35 40 45 50 Average error in start period \(s Prediction 30s 60s   40 50 60 70 80 90 100 1s 2s 5s 10s Average percentage of tasks within an error range in start period Delta \(s fcfs 30s fcfs 60s   fair 30s fair 60s   
Job Simulator Job Simulator JobTracker Job Simulator JobTracker Job Simulator A Data Caching and Prefetching 
Figure 7 Average prediction error for task start times within a short time window under FCFS scheduler Figure 8 Average prediction error for task start times within a short time window under Fair Scheduler we run the same workload of Figure 9 Percentage of relatively accu rate predictions within a short window average maximum heartbeat interval exec time s exec time s proc rate off 735 1293 1.00 60s 728 1297 0.98 30s 743 1302 0.96 20s 751 1310 0.94 10s 769 1331 0.89 5s 825 1384 0.80 Table I O VERHEAD OF RUNNING 
304 
304 
304 
304 


          
Manager Node Job 4 Job 1 Job 3 Job 2 Queue Manager Node Node Node Job Simulator Predictor Task Job Simulator Predictor Task Time Simulation Selection Hadoop simulation interval t2 state capture sim start t2+x fineätune sim end t1 state capture sim start t1+x fineätune sim end Dynamic Scheduling Data Prefetching Online Prediction Online Prediction Figure 10 Use Cases of Online Prediction Framework same data block from disks To get the best performance and efìciency scheduler should work together with both caching and prefetching We will use an example to illustrate how caching and prefetching can improve pe rformance and efìciency of Hadoop Suppose 3 jobs as shown in Table II are submitted to a MapReduce system The nish column shows estimated nish time of each job in the baseline MapReduce system With these numbers in a baseline system the 3 jobs account for 340 clusteräseconds in a baseline MapReduce system With caching enabled only j ob 3 can beneìt from caching because it accesses data 
d d d d d d 
1 1 1 1 1 1 20 
which was also accessed by job 1 Job 1 and job 2 access data for the rst time so these data cannot be cached and cannot be sped up Assume job 3 get a speed up of 50 and it runs for 50 seconds Therefore The 3 jobs account for 290 clusteräseconds in total with caching enabled If we can predict task locations and prefetch data blocks for all tasks we can preload data into RAM for each job and we can speed up each job by 50 regardless of whether data has ever been accessed before The 3 jobs account for 170 clusteräseconds in total with prefetching enbaled In terms of performance Prefetching outperforms baseline by 100 and caching by 70 Prefetching can improve performance of the system but it imposes more load on underlining disk resource Because we prefetch data again for job 3 is read twice  once for job 1 and once for job 3 Total data read for prefetching is 3 GB the same as baseline In comparison with caching enabled we do not need to read data again for job 3 because is already cached in RAM Total d ata read for caching is 2 GB a 50 improvement over baseline and prefetching Job Start Finish Accessing data 1 0 100 d1 1GB 2 10 150 d2 1GB 3 200 300 d1 1GB Table II J OBS IN A M AP R EDUCE SYSTEM  Job Baseline w caching w prefetching w both 1 100 100 50 50 1GB 1GB 1GB 1GB 2 140 140 70 70 1GB 1GB 1GB 1GB 3 100 50 50 50 1GB 0GB 1GB 0GB Overall 340 290 170 170 3GB 2GB 3GB 2GB Table III P ERFORMANCE AND RESOURCE CONSUMPTION OF THE JOBS  In fact caching and prefetching can work together and make the system optimal Consider the same example with caching and prefetching both enabled Consider with prefetching enabled and we k eep data prefetched and pro cessed in RAM as we would do with caching enabled All jobs can be sped up by 50 and total CPU used is 170 clusteräseconds For data read from disks we donêt need to read again for job 3 so total data read from disks is 2 GB Overall Table III summarizes the pros and cons of caching and prefetching The default scheduler in MapReduce JobQueue TaskScheduler is a rstäcomeäìrstäserve FCFS scheduler Under JobQueueTaskScheduler all jobs are sorted by submission order into a queue and the scheduler always picks new tasks from the rst job in the queue until the rst job nishes and the second job is promoted to be the new rst job A major drawback of FCFS is that subsequent jobs must wait until preceding jobs nish If the rst job in the queue is a large job subsequent small jobs must wait for a long period before they are executed A new class of schedulers including Quincy 13 and D el ay S c hedul i n g 9 tries to solve the problem of long delays for small jobs in FCFS Multiple jobs are allowed to run concurrently and share the resource of a cluster in term of task slots fairly so small jobs are not blocked by longärunning large jobs Wang et al 11 ha v e s h o w n d if ferent w o rkloads p erform differently under different scheduler Hence the scheduling strategy should be determined at runtime based on the properties of the jobs currently running in the cluster and the ones waiting in the queue Our online prediction framework can solve exactly that problem by predicting the execution time of the current workload under different scheduler policies in faster virtual time In Section III we have shown that running the simula tion every seconds is sufìciently frequent to be accurate as running time of most tasks is in the minutes Thus the system can provide feedback in time to make the next real scheduling decision Of course this technique should not be 
B Dynamic Scheduling 
305 
305 
305 
305 


taken to an extreme where the system is forced to switch back and forth between two schedulers that produce very similar results for the current workload To prevent this and any overhead associated w ith that scenario the system should change to a different scheduler only if that results in signiìcant performance gain V R ELATED W ORKS shares its goal of integrated simulation with another MapReduce simulator Mumak 14  b ut di f f ers from it in that Mumak is designed to run ofîine driven by a trace whereas our runs online along with the real and is driven by the live workload on the cluster In  we must predict execution time of a new task based on historical Another difference is that runs periodically and each time it runs we must take snapshots of  task scheduler and worker nodes and replicate them into  Several recent works 12 7  8 are b as ed on pre deìned performance models within each MapReduce task We adopt a simple linear model in this paper Since MapRe duce jobs are a collection of a large number of smaller tasks simple linear model is accura te enough for a computation framework like Hadoop There has been other extensive previous research in simulation of MapReduce workloads and setups 14   15  12    16  17    18  is unique in its goal of predicting a live MapReduce task Compared to all other MapReduce simu lators our prediction framework is arguably more realistic easier to verify and evaluate and can directly beneìt system performance Our framework predicts what is about to happen in the current system in the near future and therefore predictions can be veriìed and evaluated The results from the prediction can be readily used to improve performance of the live system In contrast other simulators either try to match what has already happened in the past or simulate a particular cluster environment ofîine VI C ONCLUSION In this paper we have described a simulationäbased online prediction framework for Hadoop We design and employ our simulator to predict nearäfuture system behavior based on the current state of the Hadoop scheduler The information can then be incor porated into the scheduler to better allocate jobs to nodes and achieve overall higher performance We evaluate the proposed simulation frame work using TeraGen TeraSort grep and wordcount We nd that for studied applications 95 of the predicted task execution times are within 10 of the actual values and 80 of predicted task start times in a 30äsecond window are within seconds of the actual start times In our future work we plan to leverage the prediction framework to implement prefetching for MapReduce to improve latency of initial I/O and a dynamic multiästrategy scheduler that can switch between multiple scheduling strategies based on current workload A CKNOWLEDGMENT This work was sponsored in part by the NSF under Grant No CNSä1016408 CNSä1016793 CCFä0746832 and CNS 1016198 R EFERENCES 1 A pache S of t w ar e F oundat i on   A p ache H adoop  F eb  2011  A v a ilable h ttp://hadoop.apache.org  J  D ean and S  G hema w at MapReduce Simpliìed Data Processing on Large Clusters in 
Job Simulator Job Simulator JobTracker Job Simulator Job Simulator JobTracker Job Simulator Job Simulator 
2 
 2004 pp 137Ö150 3 B al deschw i e l e r  E r i c   H o r t onw or ks Mani f e st o   O n l i n e  Available http://hortonworks.com/blog/ourämanifesto 4 D  B or t h akur  S  R ash R  S c hmi d t  A  A i yer  J G r ay  J S Sarma K Muthukkaruppan N Spiegelberg H Kuang K Ranganathan D Molkov and A Menon Apache hadoop goes realtime a t Facebook in  Jun 2011 p 1071  A mazon Amazon E lastic MapReduce  E M R   Online Available http://aws.amazon.com/elasticmapreduce 6 H  M ont i  A  R  B u t t  and S  S  V azhkudai  C A T C H  A Cloudäbased Adaptive Data Transfer Service for HPC in  2011 7 H  H er odot ou H  L i m G  L uo N  B o r i so v  L  D ong F  B  Cetin and S Babu Starìsh A Selfätuning System for Big Data Analytics in  2011 pp 261Ö272 8 H  H er odot ou H adoop P e r f o r mance Model s   D u k e U n i v er  sity Tech Rep CSä2011ä05 Feb 2011  M  Z aharia D  B orthakur  J  S en S arma K E l melee gy  S Shenker and I Stoica Del ay scheduling a simple tech nique for achieving locality and fairness in cluster schedul ing in  2010 pp 265Ö278  G  A n ant h anar ayanan A  G hodsi  A  W a ng D  B o r t hakur  S Kandula S Shenker and I Stoica Pacman coordinated memory caching for parallel jobs in  2012 pp 20Ö20  G  W a ng A  R  B u t t  H  Mont i  and K  G upt a T o w ar ds Synthesizing Realistic Workload Traces for Studying the Hadoop Ecosystem in  2011  G  W a ng A  R  B u t t  P  Pande y  and K  G upt a A si mul a t i o n approach to evaluating desig n decisions in mapreduce setups in  2009  M I s ar d V  P r abhakar a n J C u r r e y  U  W i eder  K  T alw a r  and A Goldberg Quincy fair scheduling for distributed computing clusters in  2009 pp 261Ö276  A  C  Mur t hy   Mumak M ap R educe S i m ul at or   MAPREDUCEä728 Apache JIRA 2009 Onlin  A v a i l a bl e http://issues.apache.org/jira/browse/MAPREDUCEä728  A  V e r ma L  C h er kaso v a  a nd R  H  C ampbel l  P l a y I t Again SimMR in  IEEE Sep 2011 pp 253Ö261  F  T e ng L  Y u a nd F  Magoul  es SimMapReduce A Sim ulator for Modeling MapReduce Framework in  IEEE Jun 2011 pp 277Ö282  Y  L i u M L i  N  K  A l h am and S  H ammoud H S i m A MapReduce simulator in enabling Cloud Computing  May 2011  S  H ammoud MR S i m  A di scr e t e e v ent b ased MapR educe simulator in  IEEE A ug 2010 pp 2993Ö2997 
OSDI SIGMOD Proc IPDPS CIDR Proc EuroSys NSDI MASCOTS MASCOTS Proc sosp 2011 IEEE International Conference on Cluster Computing 2011 Fifth FTRA International Conferen ce on Multimedia and Ubiquitous Engineering Future Generation Computer Systems 2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery 
306 
306 
306 
306 


state of innovation stakeholder  node PQ It  s a balanced node Based on this, we could calculate the  node PQ Calculation process is: set different inn ovation stakeholders state i U  and j U Value of ij 000T can be get from  innovation time difference. Innovation stakeholdersí social effect and industrial effect can be obtained upon ij B  and ij G set according to relation between innovation stakeholders  Model 4.1 points out  that the value of Gij  directly affects social benefits and sector benefits. Large Gij  can lead to increasing benefits of the entire industry and the entire social growth Bij reflects big organizationís impact on businesses. Only strengthening the inter agent association within big organization and enhancing the str ategic partnership between enterprises can jointly promote the development of the entire industry, and bring more social benefits, so that each agent can be improved   5 Summary This paper puts forward the concept of the big organization based on the CSM t heory. It introduces the basic implication of the big organization and theoretical framework of the big organization including: the big organization's perspective  overall perspective, dynamic perspective, and new resource perspective; the big organizat ionís sense  the purpose of the organizational structure is innovation, organizational activities around the flow of information, breaking the traditional organizational structure, encouraging self run structure, and blurring organizational boundaries; the big organizationís platform  the platform ecosystem of the big organization ; the big organizationís operation mode  borderless learning mode, and cluster effect; the big organizationís theory  active management theory  leading consumers, and culture  entropy reduction theory  negative culture entropy and humanistic ecology theory  inspiring humanity, and circuit theory  a virtuous circle, and collaborative innovation theory  collaborative innovation stakeholder. This paper also discusses culture entropy reduction theory of the big organization  negative culture entropy, and coordinated innovation theory  innovation stakeholders collaboration. Culture entropy change model and collaborative in novation model are constructed   The research has just begun for the big organization. It also needs further improvement but remains the trend of the times   Reference  1  Gordon Pellegrinetti, Joseph Bentsman. Nonlinear Control Oriented Boiler Modeling A Benchmark Problem for Controller De sign [J  I E E E tr a n s a c tio n s o n c o n tr o l s y s te m s te c h n o lo g y 2 0 1 0  4 1\57 65  2  Klaus Kruger, Rudiger Franke, Manfred Rode Optimization of boiler start up using a nonlinear 457 


boiler model and hard constraints [J  E n e r gy 201 1 29   22 39 2251  3  K.L.Lo, Y.Rathamarit  State estimation of a boiler model using the unscented Kalman filter [J  I E T  Gener. Transm. Distrib.2008 2 6\917 931  4  Un Chul Moon, Kwang. Y.Lee. Step resonse model development for dynamic matrix control of a drum type boiler turbine system [J IE E E  T ra nsactions on Energy Conversion.2009 24 2\:423 431  5  Hacene Habbi, Mimoun Zelmat, Belkacem Ould Bouamama. A dynamic fuzzy model for a drum boiler turbine system [J  A u to m a tic a 2 0 0 9 39:1213 1219  6  Beaudreau B C. Identity, entropy and culture J   J o ur na l  o f  economic psychology, 2006, 27\(2 205 223  7  YANG M, CHEN L. Information Technique and the Entropy of Culture J  A cad e m i c E x ch a n g e  2006, 7: 048  8  ZHANG Zhi feng. Research on entropy change model for enterprise system based on dissipative structure J  Ind ustrial  Engineering and  Management 2007, 12\(1\ :15 19  9  LI Zhi qiang, LIU Chun mei Research on the Entropy Change Model for Entrepreneurs' Creative Behavior System Based on Dissipative Structure J  C h i n a S of t S c i e n c e  2009   8  1 62 166   458 


A Global Solution COVERAGE North and South America EMEA and Asia White lines are flights in the masFlight platform from February 8, 2013 Yellow pins are weather stations feeding hour ly data to our platform Maps from Google Earth / masFlight masFlight tracks flights, airports and weather around the world  Global daily flight information capture  82,000 flights  350 airlines  1700 airports  Integrated weather data for 6,000 stations  Match weather to delays  Validate block forecasts at granular level  Add weather analytics to IRROPS review and scenario planning 


Example 1: Proposed FAA Tower Closures masFlight used big-data to link airport operations across three large data sets  Current and historical airline schedules  Raw Aircraft Situation Display to Industry \(ASDI\AA  Enhanced Traffic Management System Counts \(ETMS\Airport operations counts by type \(commercial, freight, etc TOWER CLOSINGS Dots indicate closures; Red dots have scheduled service Based on scheduled service March 1 7, 20 13; scheduled service includes scheduled charter flights, cargo flig hts, and passenger flights Dots  indicate  closures  Red  dots  have  scheduled  service Bas ed  o n sc h edu l ed  se rvi ce  M a r c h 1  7, 2013; scheduled se rvi ce includ es scheduled c harter fli g hts car g o fli g hts a nd passen g er fli g hts Findings: Proposed Tower Closings  From schedules database: 55 airports with scheduled passenger airline service  14 EAS Airports  From ASDI & ETMS: 10,600 weekly flights on a flight plan \(ex. VFR and local traffic  6,500 Part 91/125 weekly flights  4,100 Part 135/121 weekly flights  


Example 1: Big-Data Analytics Applied to ASDI and ETMS To Analyze Operations TOWER CLOSINGS  26 44 24 23 11 10 6 2 1 2 Up to 5 5-10 10-15 15-20 20-25 25-30 30-35 35-40 40-45 45 Count of Airports Average Number of Daily Operations with a Flight Plan Filed Distribution of Airports By Average Number of ìDailyî Impacted Flights Airports Affected by Tower Closures Source: ASDI radar data ñ Part 91 151 flying and Part 135/121 flying March 1-7, 2013; masFlight analysis Note: Average ìdailyì operations based on 5-day week 


Example 2: Aviation Safety Causal Factor For example, consider the following ASRS report \(ACN 1031837 Departing IAH in a 737-800 at about 17,000 FT, 11 m iles behind a 737-900 on the Junction departure over CUZZZ Intersection. Smooth air with wind on the nose bearing 275 degrees at 18 KTS We were suddenly in moderate chop which lasted 4 or 5 seconds then stopped and then resumed for another 4 or 5 seconds with a significant amount of ri ght rollingÖ I selected a max rate climb mode in the FMC in order to climb above the wake and flight path of the leading -900 We asked ATC for the type ahead of us and reported the wake encounter. The 900 was about 3,300 FT higher than we were  Synopsis  B737-800 First Officer reported wake encounter from preceding B737-900 with resultant roll and moderate chop What causal factors can be identified from this narrative that could be applied to future predictive applications CAUSAL FACTORS Data-mining algorithms can mine the text of safety reports to obtain specific data that can be used to analyze causal factors  


Example 2: Identifying Causal Factors CAUSAL FACTORS  Indicators ñ Data Element Methods ñ Identifying Context and Causes  Time of day  Date range \(month day  Aircraft type  Fix or coordinates  Originating airport  Destination airport  Weather notes We pinpoint the sequencing of flights on the IAH Junction Seven departure \(at CUZZZ\the specified wind conditions to find cases wher e a B737-900 at 20,000 feet precedes by 11 miles a B737-800 at 17,000 feet  Search related data sets including ASDI flight tracks, local traffic and congestion  Weather conditions for alter native causes \(winds aloft shear and convecti ve activity  Airline specific informati on \(repeated occurrence of event in aircraft type Big data gives us visibility into contextual factors even if specific data points are missing such as a specific date or route Big-data analytics gives us insight into unreported factors as well 


Example 3: Correlating Utilization and Delays  60 65 70 75 80 85 90 95 100 7 9 11 13 ONTIME DEPARTURE PERFORMANCE HOURS OF DAILY UTILIZATION 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Narrowbodies By Day of Week 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Widebodies by Day of Week Daily Utilization vs. On-time Departures January 2013 System Operations Correlation Coefficient -0.53 Includes AA, AC, AS B6 F9, FL, NK, UA, US VX and WN SOURCE masFlight \(masflight.com COMPARING OTP AND UTILIZATION 


 6.2 6.0 5.8 5.8 5.2 4.9 LGB JFK BOS MCO DCA FLL JetBlue Focus Average Daily Deps per Gate Used UTILIZATION BY HUB Example 4: Daily Utilization of Gates, by Hub Big-data analysis of different carriers daily departures per gate used SOURCE masFlight \(masflight.com June 1 through August 31, 2012 Gates with minimum 1x daily use 7.7 7.4 7.2 6.2 6.1 5.8 3.8 3.6 ORD LAX SFO EWR DEN IAH IAD CLE United Airlines Hubs Average Daily Deps per Gate Used 7.8 6.4 5.5 5.4 5.3 4.4 4.3 4.0 SEA SAN PDX ANC SFO GEG LAX SJC Alaska Airlines Hubs Average Daily Deps per Gate Used 7.2 6.9 6.8 6.4 5.0 2.7 ORD DFW LAX LGA MIA JFK American Hubs Average Daily Deps per Gate Used 7.2 6.9 6.6 4.9 4.2 CLT DCA PHL PHX BOS US Airways Hubs Average Daily Deps per Gate Used 6.6 5.9 5.5 4.7 MCO BWI ATL MKE AirTran Hubs Average Daily Deps per Gate Used ne pe 


Conclusions for Big Data in Aviation  Big-data transforms operational and commercial problems that were practically unsolvable using discrete data and on-premises hardware  Big data offers new insight into existing data by centralizing data acquisition and consolidation in the cloud and mining data sets efficiently  There is a rich portfolio of information that can feed aviation data analytics  Flight position, schedules, airport/gate, weather and government data sets offer incredible insight into the underlying causes of aviation inefficiency  Excessive size of each set forces analysts to consider cloud based architectures to store, link and mine the underlying information  When structured, validated and linked these data sources become significantly more compelling for applied research than they are individually  Todayís cloud based technologies offer a solution CONCLUSIONS 


Conclusions:  Our Approach  masFlightís data warehouse and analysis methods provide a valuable example for others attempting to solve cloud based analytics of aviation data sets  masFlightís hybrid architecture, consolidating secure data feeds in on-premises server installations and feeding structured data into the cloud for distribution, addresses the unique format, security and scale requirements of the industry  masFlightís method is well suited for airline performance review competitive benchmarking, airport operations and schedule design and has demonstrated value in addressing real-world problems in airline and airport operations as well as government applications CONCLUSIONS 






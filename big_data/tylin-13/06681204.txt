Luiz Angelo Steffenel  Olivier Flauzac  Andrea Schwertner Char„o  Patricia Pitthan Barcelos  Benhur Stein  Sergio Nesmachnow  Manuele Kirsch Pinheiro and Daniel Diaz 
PER-MARE Adaptive Deployment of MapReduce over Pervasive Grids 
002 002       002 
Universit de Reims Champagne-Ardenne Reims France luiz-angelo.steffenel,olivier.îauzac}@univ-reims.fr 
 
Abstract 
Universidade Federal de Santa Maria Santa Maria Brazil andrea,pitthan,benhur}@ufsm.br Universidad de la Rep˙blica Montevideo Uruguay sergion@ìng.edu.uy Universit Paris 1 PanthÈon-Sorbonne Paris France manuele.kirsch-pinheiro,daniel.diaz}@univ-paris1.fr 
  
MapReduce is a parallel programming paradigm successfully used to perform computations on massive amounts of data being widely deployed on clusters grid and cloud infrastructures Interestingly while the emergence of cloud infrastructures has opened new perspectives several enterprises hesitate to put sensible data on the cloud and prefer to rely 
Keywords 
on internal resources In this paper we introduce the PERMARE initiative which aims at proposing scalable techniques to support existent MapReduce data-intensive applications in the context of loosely coupled networks such as pervasive and desktop grids By relying on the MapReduce programming model PER-MARE proposes to explore the potential advantages of using free unused resources available at enterprises as pervasive grids alone or in a hybrid environment This paper presents the main lines that orient the PER-MARE approach and some preliminary results I I 
Pervasive computing MapReduce Big data 
NTRODUCTION The MapReduce programming paradigm has become a popular solution for rapid implementation of distributed data-intensive applications being supported on both grid and cloud environments Interestingly while the emergence of cloud infrastructures has opened new perspectives several enterprises hesitate to migrate their applications to the cloud as clouds present several security issues when compared to private or managed infrastructures such as grids or clusters When dealing with sensitive data these enterprises prefer therefore to rely on private infrastructures to develop their applications By proposing a pervasive grid environment supporting a programming model such as MapReduce we can intend to explore the potential advantages of using free 
unused resources structured as a pervasive grid be it alone or in a hybrid environment The PER-MARE initiative aims at the adaptation of a popular MapReduce distribution for pervasive and desktop grids proposing scalable techniques to support existent MapReduce-based data-intensive applications but in the context of loosely coupled networks such as pervasive and desktop grids We consider pervasive grids as a type of large-scale infrastructure with speciìc characteristics in terms of volatility reliability connectivity security etc In the general case pervasive grids rely on resources contributed by volunteers Desktop grids are a particular case of pervasive grids lever 
aging unused processing cycles and storage space available within the enterprise These environments present challenging deployment and context-awareness constraints as heterogeneity fault tolerance and resource volatility facts may strongly impact the performance of such networks Although some works tried to address this problem before PERMARE initiative innovates by adopting a two-fold development approach  
 on one hand we wish to adapt a wellknown MapReduce implementation Hadoop for instance including context-aware elements that may allow its efìcient deployment over a pervasive or desktop grid and  
i 
ii 
n the other hand we shall work on the implementation of a Hadoop-compatible API over a P2P distributed computing environment originally meant for pervasive grids We believe that this double process will bring us better insights on the deployment of MapReduce over pervasive grids In this paper we introduce the PER-MARE approach and some preliminary results We present PERMARE vision about a context-aware MapReduce which intends to handle high volatility of pervasive grid resources by applying context-awareness techniques on tasks distribution and scheduling Such volatility represented mainly by nodes churn affects both task and data distribution 
Context-awareness will allow to better adapt MapReduce applications to this dynamic environment but an appropriate and fault tolerant infrastructure is also needed We propose here a P2P MapReduce implementation which intends to be an alternative implementation compatible with Hadoop API and pervasive grids The preliminary results of such implementation are also presented in this paper We believe that providing a context-aware behavior to MapReduce applications while keeping the compatibility with the API from Hadoop will contribute to easily deploy existent applications 
2013 Eighth International Conference on P2P, Parallel, Grid, Cloud and Internet Computing 978-0-7695-5094-7/13 $31.00 © 2013 IEEE DOI 10.1109/3PGCIC.2013.10 17 
2013 Eighth International Conference on P2P, Parallel, Grid, Cloud and Internet Computing 978-0-7695-5094-7/13 $31.00 © 2013 IEEE DOI 10.1109/3PGCIC.2013.10 17 
2013 Eighth International Conference on P2P, Parallel, Grid, Cloud and Internet Computing 978-0-7695-5094-7/13 $31.00 © 2013 IEEE DOI 10.1109/3PGCIC.2013.10 17 


over pervasive grids and therefore evaluate the performance and fault-tolerant issues related to such environments The rest of the paper is organized as follows Section 2 presents an overview on related work Section 3 introduces the problem statement Section 4 introduces PER-MARE approach and proposals Section 5 presents our preliminary results before concluding on Section 6 II B ACKGROUND AND R ELATED W ORKS Data-intensive distributed computing is an active research topic The approaches to this problem include programming paradigms and supporting infrastructures In this section we present the MapReduce paradigm and discuss some important issues and related works concerning the deployment of MapReduce applications over pervasive and desktop grid infrastructures MapReduce is a parallel programming paradigm successfully used by large Internet service providers to perform computations on massive amounts of data After being strongly promoted by Google it has also been implemented by the open source community through the Hadoop project maintained by the Apache Foundation and supported by Yahoo and even by Google itself This model is currently getting more and more popular as a solution for rapid implementation of distributed data-intensive applications The key strength of the MapReduce model is its inherently high degree of potential parallelism that should enable processing of petabytes of data in a couple of hours on large clusters consisting of several thousand nodes A MapReduce computation takes a set of input key/value pairs and produces a set of output key/value pairs The user of the MapReduce paradigm expresses the computation through two functions 1 map that processes a key/value pair to generate a set of intermediate key/value pairs and 2 reduce that merges all intermediate values associated with the same intermediate key The framework takes care of splitting the input data scheduling the jobs component tasks monitoring them and re-executing the failed ones Furthermore when associated with a distributed lesystem HDFS in the case of Hadoop MapReduce can improve its performance by minimizing data transfers over the network A few typical examples of simple MapReduce applications include counting URL Access Frequency by processing web page requests creating reverse Web-link graph or an inverted index from large set of documents Although desktop grids have been very successful with projects such as Seti@Home F olding@home 3 and others data-intense computing on these environments is a still a promising area for now desktop grids have mostly focused on loosely coupled parallel applications with few I/O and without dependencies between the tasks Some major achievements combining their huge storage potential with their processing capability are expected They would impact the applications requiring an important volume of data input storage with frequent data reuse and limited volume of data output The MapReduce programming model adapts well to this class of applications and there is a growing interest in supporting MapReduce on desktop grids Since enabling MapReduce on pervasive and desktop grids raises many research issues we can decompose this problem in two subtopics data distribution and storage and data processing There are two approaches to distribute large volume of data to large number of nodes distributed on Internet The rst approach relies on P2P protocols where peers collaboratively participate to the distribution of the data by exchanging le chunks In and 5 authors in v estigate the use of the Bittorrent protocol with the XtremWeb and BOINC Desktop Grid in the case of data-intense bag of tasks application relies on a JXT A platform deplo ying two overlay networks M-net and S-net master and slave respectively which mimics the master-slave coordination mechanism from Hadoop Note that if the P2P approach seems efìcient it assumes that volunteers would agree that their PC connects directly to another participantês machine to exchange data Unfortunately this could be seen as a potential security threat It is unlikely to be widely accepted by users This drawback has so far prevented adoption of P2P protocol by major volunteer computing projects The second approach is to use a content delivery approach where les are distributed by a secure network of well-known and authenticated volunteers 8 This approach is follo wed by the ATTICS project Peer to-Peer Architecture for Data-Intensive Cycle Sharing Instead of retrieving les from a centralized server workers get their input data from a network of cache peers organized in a P2P ring Several systems have been proposed to aggregate unused storage of desktop workstation within a LAN Farsite builds a virtual centralized le system over a set of untrusted desktop computers It provides le reliability and availability through cryptography replication and le caching Freeloader fulìlls similar goals b ut uniìes data storage as a unique scratch/cache space for hosting immutable datasets and exploiting data locality allowing to persistently store data on desktop PCs Lin et al discuss limitations of MapReduce implementations over volatile non-dedicated resources They propose a system called MOON MapReduce On Opportunistic eNvironment which extends Hadoop in order to efìciently deal with the high unavailability of resources in desktopbased volunteer computing environments MOON relies on 
A About MapReduce B Data-intensive applications on Pervasive and Desktop Grids 
18 
18 
18 


a hybrid architecture where a small set of dedicated nodes are used to provide resources with high reliability in contrast to volatile nodes which may become inaccessible during computations Their goal is somewhat similar to ours but their solution based on dedicated nodes does not t well to more dynamic environments as pervasive grids Due to the simplicity of its processing model map and reduce phases data processing can be easily adapted to a given distributed middleware which can coordinate tasks through different techniques centralized task server workstealing/bag of tasks speculative execution etc Nevertheless good performances can only be achieved through the minimization of data transfers over the network which is one of the key aspects of Hadoop HDFS lesystem Only few initiatives associate data-intense computing with large-scale distributed storage on volatile resources In the authors present an architecture following the super-peer approach where the super-peers serve as cache data server handle jobs submissions and coordinate execution of parallel computations The deployment of MapReduce over pervasive and desktop grids exposes most of the challenges presented in this section with respect to data distribution storage and processing At the moment there is no single solution that solves all these issues together When considering pervasive grids where heterogeneity is a major characteristic data processing/scheduling must be driven by contextual information resources characteristics node reliability network performance data location in order to achieve the expected processing performance As cloud computing has leveraged the use of MapReduce it is natural that most MapReduce distribution have been tailored to such environments For instance most IaaS clouds use sets of virtual machines that share similar characteristics such as computational power and memory and in such cases MapReduce does not require speciìc adaption to the computational context as all virtual machines are similar As a consequence most users simply rely on MapReduce default conìgurations such as the number of reduce tasks by machine the maximum memory etc Although this behavior can be modiìed through property les there is no mechanism to automatically detect and modify these parameters When dealing with a heterogeneous environment such as a pervasive grid MapReduce must be able to automatically tune to the nodes characteristics While the computational context is tightly related to the processing power of the resources it also impacts other aspects such as fault-tolerance and data storage Indeed Hadoop allow a certain number of duplicated processes/data in order to circumvent fault situations If the context on pervasive grid is not considered tasks may be inefìciently allocated or even disappear if the node volatility is high Similarly HDFS tries to place data for the map and reduce phases as closes as possible to the processes/tasks that will need it as to reduce the slow access over the network In a pervasive grid the placement policy must account also on the volatility and speed of the resources preventing data losses While the contextual information required for the adaption of MapReduce can be obtained from the system properties CPU and network speed number of cores memory size etc the diffusion and analysis of such information must be tightly integrated into the MapReduce framework to boost the platform efìciency For this reason contextawareness and conte xt distrib ution 14 are important elements to be considered III P ROBLEM STATEMENT One of the rst challenges a user faces when deploying MapReduce is that its most known and popular implementation Hadoop requires a highly structured environment such as a grid or a cloud to be deployed For instance Hadoop relies on a collection of tools Hadoop Core HDFS etc developed by different Apache subprojects which interact through a complicate set of master and slave daemons As a result Hadoop installation although well documented requires a stable set of machines known at startup time Please note that the installation procedure lacks of automatic context adaption forcing the administrator to manually deìne the characteristics of the resources such as the number of cores of each machine Together these elements prevent a user to quickly launch MapReduce over unused internal resources e.g an enterprise desktop grid or over a volunteer network where nodes join and leave the network dynamically Some authors  addressed this problem by de v eloping P2P frame w orks compatible with the MapReduce paradigm While proposing interesting solutions for the distribution and fault tolerance issues these frameworks have their own APIs that are not compatible with application codes written for Hadoop Our project is precisely addressing this point proposing scalable techniques to support existent Hadoop applications in the context of loosely coupled networks such as pervasive grids We consider pervasive grids as a type of largescale infrastructure with speciìc characteristics in terms of volatility reliability connectivity security etc According to Parshar and Pierson perv asi v e grids represent the extreme generalization of the grid concept in which the resources are pervasive For these authors pervasive grids seamlessly integrate pervasive sensing/actuating instruments and devices together with classical high performance systems In the general case pervasive grids rely on resources contributed by volunteers but these resources are extremely volatile They may appear and disappear from the grid according their availability Desktop grids are a particular case of pervasive grids leveraging unused processing cycles and storage space available within the enterprise 
C Adaption to the Computational Context 
19 
19 
19 


However contrarily to simple desktop grids general pervasive grids have to deal with a more dynamic environment in a transparent way Indeed mobile devices should be able to come into the environment in a natural way as their owner moves De vices from dif ferent natures from the desktop and laptop PCs until the last generation tablets should be integrated in seamlessly way It results an environment characterized by   the volatility of its components whose participation on the grid is notably a matter of opportunity and availability and   by the heterogeneity of these components whose capabilities may vary on different aspects platform OS memory and storage capacity network connection etc Besides the internal status of these devices may also vary during their participation into the grid environment For instance during the execution of a job a mobile device integrated to a pervasive grid may change its network connection passing from a xed connection to a wireless one The same can be observed with the available memory after starting a job deviceês owner may start new applications that modify device memory status Pervasive grids environments have to deal with such additional constraints related to the heterogeneity and volatility of the resources In such environments it is essential to adapt the application to the network variable behavior and to coordinate the resources task scheduling data placement etc According to Coronato  De Pietro perv asi v e grid environments should be able to self-adapt and selfconìgure in order to incoming mobile devices We strongly believe that context-awareness is needed in order to support such self-adaption Context-awareness can be deìned as the ability of a system to adapt its operations to the current context aiming at increasing usability and effectiveness by taking environmental context into account In order to support environments changes context-awareness becomes a critical aspect to boost the efìciency of the applications over pervasive grids Besides considering the extreme development of mobile devices inside organizations nowadays the opportunistic use of such resources as an internal pervasive grid appears as an interesting alternative for those who hesitate to distribute sensible data over cloud infrastructures These still suffer from security issues that prevent their application in some cases Nevertheless in order to be fully operational pervasive grids environment have to rst tackle problems related to its dynamic nature IV T HE PER-MARE APPROACH Given the problems presented above we propose to address the lack of context adaptation of MapReduce applications over pervasive grids all while keeping the compatibility with MapReduce most popular implementation Hadoop To meet this global goal several aspects need to be investigated Our approach is to improve the behavior of MapReducebased applications on pervasive grids using a two-fold investigation method Hence to better understand the elements that may impact the deployment of MapReduce over pervasive grids our teams investigate the problem through two different approaches on the one hand we shall modify Hadoop as to implement automatic tuning of the nodes simplifying therefore the deployment procedure over pervasive nodes On the other hand the second approach relies on the adaptation of a distributed computing platform C ONFIIT  to mak e it compatible with the MapReduce paradigm and more speciìcally with Hadoopês API We believe that this double approach is essential to understand and cover all the facets of the problem By comparing these two approaches side by side we can propose effective solutions for pervasive grids In order to validate our developments we target a scalable execution across multiple sites with real-life workloads from existing applications A distributed desktop grid among our institutions shall provide important insights on the adaptability to the heterogeneity of resources and the dynamic nature of the networks In addition the Grid5000 platform  https://www.grid5000.fr  will provide the additional experimental infrastructure to explore the scalability issues of our work In order to cope with pervasive grids MapReduce implementations have to deal with issues mainly related to nodes volatility and heterogeneity of such environments Indeed dynamic nature of pervasive environments demands adapting to changing operating conditions and to enable more efìcient and effective operation while avoiding system failure Context-awareness is then needed in order to cope with such changing environments Unfortunately as discussed previously Hadoop was not designed to support such changing environment with resources that may appear and disappear from the environment or new resources that can be integrated opportunistically neither with active resources whose capabilities may also vary during the execution Although several MapReduce implementations can handle nodes disconnection most of them cannot support a smooth re-connection of a node after a disconnection period or the addition of a new node Indeed Hadoop only allow new nodes to join the network through the restart of the entire daemon network This means that they cannot fully handle mobile devices which are often characterized by frequent disconnection and re-connection They cannot either discover for new nodes that were not previously declared in the conìgured cluster Such behavior limits the use of such implementations and mainly Hadoop over pervasive grids In order to deal with such limitation PER-MARE intends to propose a context-aware implementation of Hadoop Our proposal is to introduce into Hadoop a lightweight context middleware allowing to dynamically feed Hadoop platform 
i ii A Towards context-aware MapReduce 
20 
20 
20 


and applications with context information Such information could then be used for data and task scheduling in order to fully beneìt from pervasive grids Nevertheless to reach this goal several challenges should be tackled First nodes availability should be observed New nodes should be integrated on the grid on the y as well as disconnected nodes should be able to reintegrate the grid once available again This means that nodes should be able to dynamically join and leave pervasive grid A P2P behavior is needed in which nodes discover other nodes and inform them about their availability Such P2P behavior supposes to extend heartbeat mechanism traditionally used by Hadoop to identify nodes failures in order to allow nodes to join the grid during execution Context information about the nodes themselves should also be observed and this without a signiìcant impact on the nodes performance Different context information can be observed node location available memory storage network latency etc Such context information set must be extensible New context information should be easily integrated on it A plugin-based mechanism such as can be used in order easily plug new sensor capabilities on the platform Besides context information about a node should be relayed to the others nodes in order to allow an efìcient data and task schedule inside the pervasive grid In other words a context distribution mechanism similar to should be considered Such mechanism should integrate heartbeat mechanism in order to couple context information with nodes-alive signal forming a lightweight P2P context distribution mechanism In order to handle such challenges we need rst to study the feasibility of such proposals on Hadoop platform Hadoop is composed by a complex set of daemons and components involved on the multiple aspects of HDFS and MapReduce execution Modify such ecosystem can reveal itself a delicate task Thus an initial study about Hadoop internal infrastructure has already started 23 By using failure injection techniques this study has demonstrated Hadoop vulnerabilities concerning nodes failures notably when such failures concern master data nodes This conìrms our opinion that more exible mechanisms are necessary in order to allow Hadoop applications to fully beneìt from pervasive grid environments Our feasibility study is still in process and we expect to publish results soon Due to its simple task model MapReduce can be easily implemented in a distributed computing environment In our project we rely on the P2P distributed computing middleware like C ONFIIT Computation Over Network for FIIT In C ONFIIT  the programmer needs to decide how to divide the problem into a nite number of independent tasks and how to compute each individual task This is the same principle of MapReduce and steps which can be considered as a sequences of Finite number of Independent and Irregular Tasks FIIT problems The C ONFIIT framework is structured around collaborative nodes connected over a logical oriented ring overlay network Communication between nodes is achieved using a token-like mechanism which carries the state of computation around the ring Task status and partial results are broadcasted among the nodes which contributes to the coordination of the computing tasks and form a global view of the calculus A node owns the different parameters of the current computations a list of tasks and associated results It is able to locally decide which tasks still need to be computed and can carry the work autonomously if no other node can be contacted If later a node reintegrates a community it is able to share the results from the tasks it completed and resynchronize its taskês list A simple scheduling mechanism randomly rearrange the list of tasks at each node which helps the computation of tasks in parallel without requiring additional communication between nodes Since constraints of a given application could be different and sometimes in contradiction fault tolerance efìciency etc C ONFIIT offers two main programming models distributed and centralized mode The allows a high fault tolerance level in the computation since task results are distributed to each node in the community Thus a broken computation can be re-launched using already computed tasks Figure 1\(a shows information exchanges in the community for a distributed application At rst the launcher sends the computing request to a node The request is propagated along the community During computation results of individual tasks are propagated across the community such that each node could locally store all individual results data blocks Concurrently to the computations information on the global computation is also exchanged among nodes.Besides it is worth noting that the launcher only needs to be connected during the initiation phase At the end of the computation the global result can be retrieved from any node in the community The concentrates the storage on a single node the job launcher which reduces the global load of storage space but reduces fault tolerance As this mode is too restrictive for a pervasive environment we prefer to rely on the Distributed mode on the remaining of this paper C ONFIIT C ONFIIT offers an interesting platform for building a P2P MapReduce implementation Its fault tolerant characteristics make it particularly appropriate for pervasive grid Thus we are introducing into C ONFIIT a MapReduce implementation inspired by Hadoop API This rst implementation intends allowing comparing traditional Hadoop implementation with a P2P implementation of MapReduce leveraging advantages and inconvenients that shall be further explored in our future 
B MapReduce on a P2P distributed computing environment map reduce 1 Programming models 2 Using for MapReduce 
distributed mode centralized mode 
21 
21 
21 


    
WordCount map reduce 
      
application over C ONFIIT  This prototype uses a core application independent from C ONFIIT or Hadoop as show in Figure 2 This core application could then be used on both prototypes allowing a clear comparison between both solutions Besides as illustrated in Figure 2 in this rst tentative we rely on the Distributed mode for both Map and Reduce parts as it has interesting fault tolerance properties that can be useful in a volatile environment such as full replication of partial results Our prototype reproduces the Map and Reduce phases with two C ONFIIT instances one for each phase The computation of each task calls the or methods from the core classes shared with the Hadoop implementation In the case of the Map job each task returns a list of K V elements For the Reduce job task solvers access the results from the previous job and can therefore compute a word count K V  Because the Distributed mode replicates all results over the entire C ONFIIT community the Reduce tasks can read the results from the Map instance directly from their hard drives While most parts of a MapReduce application can be directly mapped to C ONFIIT methods one single difference resides on the need to indicate the number of computing tasks Indeed this behavior is automatized on Hadoop which tries to guess the required number of Map and Reduce processes In our prototype this parameter was deìned as to mimic the behavior of Hadoop i.e by setting a number of Map tasks to roughly correspond to the number of input les and the number of Reduce tasks to correspond to the number of computing cores in the C ONFIIT nodes at the time Reduce starts this number may vary later due to nodes volatility The experiments were conducted over 16 machines on a Gridê5000 cluster 1  Each machine is composed by 2 AMD 1 http://www.grid5000.fr 
launcher  receiver 
CounterExample    MapReduceBase MapReduce Consumer Distributed Mapper Reducer WordCounter 
Hadoop Conìit Conìit Conìit Conìit Hadoop 
a Distributed mode  b Centralized mode Figure 1 C ONFIIT Programming modes works When using C ONFIIT  a MapReduce job can be expressed as a two rounds execution one handling Map tasks and another handling Reduce tasks Similarly to Hadoop during Map phase several tasks are launched according the number of input les The number of tasks during the Reduce phase is calculated based on the number of available nodes Once a round starts each node starts a task from the shared task list and broadcasts its results at the end of the taskês computation When using the distributed mode MapReduce implementation over C ONFIIT supports nodes failures as well as nodes volatility allowing nodes to dynamically leave and join the grid Indeed as long as a task is not completed other nodes on the grid may pick it up In this way when a node fails or leaves the grid other nodes may recover tasks originally taken by the crashed node Inversely when a node joins the C ONFIIT community it receives a copy of the working data and may pick up available incomplete tasks on the shared task list Such P2P-like behavior offers a better support for more dynamic environments such as pervasive grids and also allows the joining of additional nodes a feature that usually lacks on Hadoop In the next session we present the rst results obtained with a MapReduce prototype over C ONFIIT  Besides we are also working on supplying on C ONFIIT a fully compatible Hadoop API Even if it is already possible to build MapReduce-like applications over C ONFIIT  porting Hadoop applications to C ONFIIT still requires additional adaptations We believe that by offering a fully compatible API migratFigure 2 Experimental application shared between Hadoop and Conìit implementations ing application from Hadoop API to C ONFIIT will be easier offering an alternative P2P execution platform for existent applications and also as a cheap testing platform V P RELIMINARY RESULTS In a rst step to deploy MapReduce applications over a pervasive network we implemented a prototype version of the classic 
launcher      
22 
22 
22 


Science Fiction Bookshelf CD 
Figure 3 Comparison between Conìit and Hadoop over 16 nodes Opteron 275 2.2GHz CPUs totalizing 4 cores per node A Gigabit Ethernet interconnects the nodes For the experiments we evaluate the performance of both C ONFIIT and Hadoop solutions when varying the total amount of data and the number/size of input les For each data size we measure 3 different input splits one single le 1MB splits and 512kB splits The reason for such approach is to analyse the impact of the input les on the map step from both solutions For the input data we chose the Gutenberg Project 
2  which contains more than 200 books in text format The results presented on Figure 3 represent the median of the performed measures When analyzing the measures two scenarios arise for small data volumes our prototype outperforms Hadoop while Hadoop performs much better for large data sets In the rst scenario this is mostly due to C ONFIIT lightweight middleware However when the data volume augments we observe a huge performance slowdown Investigation shows that this is due to the task update pattern used on the Distributed mode which overloads the token passing mechanisms and creates a bottleneck More speciìcally the current implementation of C ONFIIT Distributed mode see Figure 1\(a spreads results using service layer messages the same messages that are used to keep nodes updated about the tasks completion are used to transmit the tasks results For small data sets this procedure poses no problem but when the amount of data grows the service layer becomes overloaded As a consequence nodes nish by computing most of the tasks locally because few updates are able to reach to the other nodes Future works will focus on correcting these problems improving massive data exchanges among C ONFIIT nodes This can be achieved through the use of speciìc data exchange channels created on-demand by nodes that wish to complete their data sets after receiving an update message or through a third-part P2P lesystem Indeed the use of a DHT with controlled data replication is also an interesting solution to 2 http://www.gutenberg.org/wiki/Gutenberg:The_CD_and_DVD_Project ensure fault tolerance without relying on a full replication of all data an especial concern in the case of BigData The development of a context-awareness scheduling shall also help on this effort as data distribution and data locality are successful elements of the Hadoop framework VI C ONCLUSION The MapReduce programming paradigm and its most known implementation Hadoop are becoming increasingly popular Particularly designed for distributed data-intensive applications MapReduce is being largely supported on both grid and cloud environments Nevertheless Hadoop similarly to other MapReduce implementations is designed for dedicate environments It does not support dynamic environments which are subject to nodes volatility and changes on internal node state As a consequence Hadoop does not t pervasive grid environments which are characterized by such dynamism and by an opportunistic use of heterogeneous nodes In this paper we presented the PER-MARE initiative which aims at adapting MapReduce to pervasive grids PERMARE proposes an innovative two-fold approach aiming at on the one hand adapting Hadoop implementation by adding on it a context-aware behavior and on the other hand proposing a P2P Hadoop compatible implementation based on C ONFIIT platform This paper presented the bases of this two-fold approach and some preliminary results Indeed although in an early stage PER-MARE has already some stimulating results A rst prototype of P2P MapReduce over C ONFIIT is already available at or project website 3 and we are currently working on a Hadoop compatible API for C ONFIIT  Besides we are currently analyzing Hadoop internal infrastructure in order to allow Hadoop to support nodes volatility and especially dynamic joining of new nodes Handling nodes volatility is a rst step towards a contextaware implementation of Hadoop This next step intends to allow a smart task and data schedule based on node context information such as location available memory and storage network latency etc This context-aware effort will be extended also to C ONFIIT and our P2P MapReduce implementation In this case context information will be mainly used for adapting P2P data distribution over available nodes according execution context of each node A CKNOWLEDGMENTS The authors would like to thank their partners in the PERMARE project and acknowledge the nancial support given to this research by the CAPES/MAEE/ANII STIC-AmSud collaboration program project number 13STIC07 3 http://cosy.univ-reims.fr/PER-MARE 
23 
23 
23 


R EFERENCES  J Dean and S Ghema w at Mapreduce simpliìed data processing on large clusters 
 vol 51 no 1 pp 107Ö113 2008  D Anderson J Cobb E K orpela M Lebofsk y  and D Werthimer Seti@home an experiment in publicresource computing  vol 45 no 11 pp 56Ö61 Nov 2002 A v ailable http://doi.acm.or g/10 1145/581571.581573  A Beber g D Ensign G Jayachandran S Khaliq and V Pande Folding@home Lessons from eight years of volunteer distributed computing in  2009 pp 1Ö8  S V azhkudai V  Freeh X Ma J Strickland N T ammineedi and S Scott FreeLoader Scavenging desktop storage resources for scientiìc data in  Seattle USA 2005  F  Costa L Silv a G Fedak and I K elle y  Optimizing data distribution in desktop grid platforms  vol 18 no 3 pp 391Ö410 Sep 2008  F  Marozzo D T alia and P  T runìo  A peer to-peer framework for supporting mapreduce applications in dynamic cloud environments in  ser Computer Communications and Networks N Antonopoulos and L Gillam Eds Springer London 2010 pp 113Ö125  C Mastroianni P  Cozza D T alia I K elle y  and I T aylor  A scalable super-peer approach for public scientiìc computation  vol 25 no 3 pp 213Ö223 2009  I K elle y and I T aylor   Springer 2008    A peer to-peer architecture for data-intensi v e c ycle sharing in  New York NY USA ACM 2011 pp 65Ö72  A Adya W  Bolosk y  M Castro G Cermak R Chaik en J Douceur J Howell J Lorch M Theimer and R Wattenhofer Farsite federated available and reliable storage for an incompletely trusted environment  vol 36 pp 1Ö14 2002  H Lin X Ma J Archuleta W  Feng M Gardner  and Z Zhang Moon Mapreduce on opportunistic environments in  2010 pp 95Ö106  E Cesario C Mastroianni N De Caria and D T alia Distributed data mining using a public resource computing framework  2010  D Preuv eneers K V ictor  Y  V anrompay  P  Rigole and M Kirsch-Pinheiro  IGI Global 2009 ch 1 pp 1Ö25  M Kirsch-Pinheiro Y  V anrompay  K V ictor  Y  Berbers M Valla C Fra A Mamelli P Barone X Hu A Devlic and G Panagiotou Context grouping mechanism for context distribution in ubiquitous environments in  ser Lecture Notes in Computer Science R Meersman and Z Tari Eds vol 5331 Springer 2008 pp 571Ö588  DiscoProject http://discoproject.or g  M P arashar and J.-M Pierson Perv asi v e grids Challenges and opportunities in  K Li C Hsu L Yang J Dongarra and H Zima Eds IGI Global 2010 pp 14Ö30  A Coronato and G D Pietro Mipe g A middle w are infrastructure for pervasive grids  vol 24 no 1 pp 17  29 2008  A v ailable http://www sciencedirect.com/science article/pii/S0167739X07000593  M Baldauf S Dustdar  and F  Rosenber g  A surv e y on context-aware systems  vol 2 no 4 pp 263Ö277 Jun 2007 A v ailable http://dx.doi.org/10.1504/IJAHUC.2007.014070  O Flauzac M Krajecki and L Stef fenel Conìit a middlew are for peer-to-peer computing  vol 53 no 1 pp 86Ö102 July 2010  A Ferscha Ed  Institute for Pervasive Computing Johannes Kepler University Linz 2011 Available http://www.perada.eu/research-agenda  N P aspallis Middle w are-based de v elopment of conte xtaware applications with reusable components Ph.D dissertation University of Cyprus 2009  E Gondim B Prates P  P  Barcelos and A Char„o  An·lise de alternativas para injeÁ„o de falhas no Apache Hadoop in  VitÛria ES Brazil 2011  E Gondim P  P  Barcelos and A S Char„o Explorando o framework de injeÁ„o de falhas do Apache Hadoop in  PetrÛpolis RJ Brazil 2012  M Krajecki  An object oriented en vironment to manage the parallelism of the FIIT applications in  ser Lecture Notes in Computer Science V Malyshkin Ed St Petersburg Russia Springer-Verlag Sep 1999 vol 1662 pp 229Ö234 
Commun ACM Commun ACM Proceedings of the 23rd IEEE International Symposium on Parallel Distributed Processing IPDPS 09 Proceedings of Supercomputing 2005 SCê05 Parallel Processing Letters Cloud Computing Future Gener Comput Syst Bridging the Data Management Gap Between Service and Desktop Grids Proceedings of the rst international workshop on Network-aware data management NDM 11 SIGOPS Oper Syst Rev Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing HPDC 10 Grids P2P and Service Computing Context-Aware Adaptation in an Ecology of Applications OTM Conferences 1 Handbook of Research on Scalable Computing Technologies Future Generation Computer Systems Int J Ad Hoc Ubiquitous Comput Journal of Supercomputing Pervasive Adaptation  Next generation pervasive computing research agenda Proceedings of the XII SimpÛsio em Sistemas Computacionais Proceedings of the XIII SimpÛsio em Sistemas Computacionais Parallel Computing Technologies 5th International Conference PaCT-99 
24 
24 
24 


  9 NASA AIRS and Suomi NPP science teams and the NPOESS Sounding Operational Algorithm Team. He is the Principal Investigator on the MicroMAS \(Micro-sized Microwave Atmospheric Satellite\ program, comprising a high-performance passive microwave spectrometer hosted on a 3U cubesat planned for launch in 2013.\302  He was previously the Integrated Program Office Sensor Scientist for the Advanced Technology Microwave Sounder on the Suomi National Polar Partnership that launched in 2011 and the Atmospheric Algorithm Development Team Leader for the NPOESS Microwave Imager/Sounder. Dr. Blackwell received the 2009 NOAA David Johnson Award for his work in neural network retrievals and microwave calibration and is co-author of Neural Networks in Atmospheric Remote Sensing published by Artech House in July, 2009.\302  He received a poster award at the 12th Specialist Meeting on Microwave Radiometry and Remote Sensing of the Environment in March 2012 for ``Design and Analysis of a Hyperspectral Microwave Receiver Subsystem'' and was selected as a 2012 recipient of the IEEE Region 1 Managerial Excellence in an Engineering Organization Award ``for outstanding leadership of the multidisciplinary technical team developing innovative future microwave remote sensing systems  Paul E. Racette has been the principal engineer responsible for the overall instrument concept development and deployment of highly-innovative remote sensing instruments. Each of these instruments has produced unique, scientifically rich data. Paul has participated in more than fifteen major field experiments around the world pioneering techniques to observe the Earth. As a member of the senior technical staff at Goddard, he has initiated technology developments research projects, and international collaborations that have advanced the state of th e art in microwave remote sensing and instrument calibration. For these efforts and accomplishments Paul recei ved the NASA Medal for Exceptional Service and was the first recipient of Goddard\222s Engineering Achievement Award established to publicly recognize Goddard\222s highest achieving engineers. In 2005 he completed the requirements for his Doctor of Science in elect rical engineering from The George Washington Universi ty. Recognizing the critical needs in education and a desire to seek new adventures Paul applied and was accepted into the NASA Administrator\222s Fellowship Program. As a NAFP fellow he returned to his home state to serve as a guest faculty at the Haskell Indian Nations University during the 2005 \226 2006 academic year Paul recently completed the s econd year of his fellowship working at NASA Headquarters as Special Assistant to the Deputy Assistant Administrator in the Office of Education  Paul is highly commited to serving the public through professional activities. Paul has served the IEEE in many capacities including secretary of the University of Kansas\222 IEEE student chapter, the Geoscience and Remote Sensing Society\222s New Technology Directions Committee Representative, Chair of the Instrumentation and Future Technologies Committee, and Professional Activities Committee for Engineers Representative. He now serves as Editor-In-Chief for Earthzine  Christopher J. Galbraith is a member of the Technical Staff at MIT Lincoln Laboratory in the RF and Quantum System s group where he develops microwave circuits for communications, radar, and radiometric systems, small form-factor packaging and antennas, and superconducting electronics  He  received the B.S.E.E., M.S.E.E. and Ph.D degrees from the University of Michigan, Ann Arbor. During the summers of 2001 and 2002, he was an intern with TRW Space and Electronics, Redondo Beach, CA, where he worked on satellite communications syst ems and microwave circuit design. He is active in the IEEE Microwave Theory and Techniques society \(MTT-S\ where he currently serves as the chair of the Boston chapter   Erik Thompson Assistant Staff at MIT Lincoln Laboratory. He r eceived a B.E. in Electrical Engineering from Stevens Ins titute of Technology. As a Stevens student T hompson was selected as the Cooperative Education and Internship Student of the Year award by the New Jersey Cooperative Education and Internship Association \(NJCEIA As an undergraduate at Stevens, Thompson took part in five Co-op internships. The first two assignments were with Datascope Patient Monitors, where he worked with the electrical engineering staff to test hospital products and implement fixes. Next, he worked as a computer engineer at the Armament Research, Development and 


  10 Engineering Center \(ARDEC\ at Picatinny Arsensal Finally, Thompson spent two semesters at Safe Flight Instrument Corporation. There, he served as project lead for the development of co ckpit sensors that prevent airplanes from stalling. He was primarily responsible for overseeing the design and testing of software and electronics systems    


  11  


Nature Nature Ecological Applications Nature ACM International Conference on Management of Data \(SIGMOD In Parallel Object-Oriented Scientic Computing \(POOSC Science Communications of the ACM ACM Workshop on Mining and Learning with Graphs Communications of the ACM HotCloud Proceedings of the 19th ACM International Symposium on High PErformance Distributed Computing HPDC Knowledge and Information Systems KAIS International Conference on Computational Science IEEE International Conference on Cloud Computing Technology and Science ACM/IEEE Conference on Advances in Social Network Analysis and Mining \(ASONAM IEEE International Parallel and Distributed Processing Symposium \(IPDPS International Conference on Distributed Computing and Networking Journal of Mathematical Sociology International Conference on Parallel Processing Communications of the ACM 
 
observed time taken using 4 workers, are plotted in Figures 16\(A\ and 16\(B We see that our dynamic scaling heuristic using the percentage of active vertices achieves nearly the same CP\ or better \(WG\ performance as a fixed 8 worker approach. Clearly there is benefit of using fewer workers for low utilization su persteps to eliminate the barrier synchronization overhead. Also, the dynamic scaling heuristic performs almost as well as the ideal scaling. Finally, when we consider the monetary cost of the proposed approaches, assuming a pro-rata normalized cost per VM-second plotted on the secondary Y axis, we see that dynamic scaling is comparable \(CP\ or cheaper \(WG\ than a 4 worker scenario while offering the performance of an 8 worker deployment IX C ONCLUSION  In conclusion, we introduce optimization and heuristics for controlling memory utilization and show they are critical to performance.  By breaking computation into swaths of vertices and using our sizing heuristics we achieve up to 3.5x speedup over the maximum swath size that does not cause the a failure.  In addition overlapping swath executions can provide a 24% gain with automated heuristics and even greater speedup when a priori knowledge of the network characteristics is applied This evaluation offers help to eScience users to make framework selection and cost-performancescalability trade-offs. Our he uristics are generalizable and can be leveraged by other BSP and distributed graph frameworks, and for graph applications beyond BC. Our work uncovered an unexpected impact of partitioning and it would be worthwhile, in future, to examine the ability to pred ict, given certain graph properties, a suitable partitioning model for Pregel/BSP It may also be useful to perform such evaluations on larger graphs and more numbers of VMs. At the same time, it is also worth considering if non-linear graph algorithms are tractable in pr actice for large graphs in a distributed environment B IBLIOGRAPHY  1  F  L i lj er os C   Ed l i n g L  A m a r a l H  S t an ley   and Y    berg The web of human sexual contacts 
vol. 411, pp. 907908, 2001   H Je o n g  S   Ma so n A  L   B a ra b s i  a nd Z   Oltva i  L e t ha l i t y  and centrality in protein networks vol. 411, pp. 41-42 2001   O. B o din and E   E s t r ada    U s i n g n e t w ork c e nt r a l i t y  m e a s ures t o  manage landscape connectivity vol 18, no. 7, pp. 1810-1825, October 2008   D. W a ts s  and S  S t r ogat z  C olle c t i v e  d y nam i cs of  s m a ll-w orl d   networks vol. 393, no. 6684, pp. 440Ö442, June 1998   G  Ma lew i c z   M A u s t er n A   Bik  J   Dehn er t I  Hor n   N. L e i s er and G. Czajkowski, "Pregel: A system for large-scale graph processing," in 2010   D. G r egor  and A  L u m s dain e  T h e  pa r a llel  B G L  A gen e r i c  library for distributed graph computations," in 2005   B. S h a o  H. W a n g  and Y  L i T he T r init y G r aph E n g i n e    Microsoft Research, Technical Report MSR-TR-2012-30, 2012   A  F ox  C lo ud c o m putin g w h at  s  in it for m e  as  a  s c i e n tis t     vol. 331, pp. 406-407, 2011   S. G h e m a w a t  and J  De an   Map re duc e s i m p lifi e d data  processing on large clusters vol 51, no. 3, pp. 107-113, 2008   J  L i n and M. S c hat z   Des i g n  patt er n s  for eff i ci ent gr aph algorithms in MapReduce," in 2010   L   Va l i ant   A b r id g i n g m o d e l f or pa r a llel com putati o n  vol. 33, no. 8, pp. 103-111, 1990 12 a c h e  Ha ma    O n l i n e    http://hama.apache.org   13 Ap a c h e  Ha d o op    O n l i n e    http://hadoop.apache.org     M Z a h a r i a, M. Ch ow dhu ry M F r ank l in S  S h e n k e r, and I   Stoica, "Spark: Cluster Computing with Working Sets," in 2010   J  Ekana y ak e e t a l     T w i st er A  r untim e f o r it er ati v e  MapReduce," in Chicago, 2010, pp. 810-818   U. K a n g  C  T s o u rakakis   and C. F a l outs o s  Peg a s us   Minin g  Peta-scale Graphs," in 2010   M. P a c e  B S P vs  MapR e duc e    in vol. 103.2081, 2012   S. Seo  E  Yoo n, J  K i m  S  J i n  J-S. K i m   and S   Ma e n g HAMA: An Efficient matrix computation with the MapReduce framework," in 2010, pp. 721-726   S. S a l i h ogl u  and J  W i d o m  G PS A G r a ph P r oc e s s i n g Sy s t em    Stanford University, Technical Report 2011   R L i cht e n w a l t e r and N   Cha w la D is Ne t  A fr am ew ork for  distributed graph computation," in  2011   K  Maddu r i  D. E d i g er K   J i an g  D. Bad e r  and D  Cha v a r riaMiranda, "A faster parallel algorithm and efficient multithreaded implementations for evaluating betweenness centrality on massive datasets," in 2009   E  K r e p s k a, T  K i el m a nn, W  F o kkink, H   Ba l, "A  hi g h level framework for distributed processing of large-scale graphs," in 2011, pp. 155-166   L   Pa ge  S  B r in R. M o t w ani and T  W i nogr ad  T h e P a geRank citation ranking: Bringing order to the web," Stanford InfoLab Technical Report 1999-66, 1999   U  Brand  s  A f a s t er  a l gor ith m for  b e t w eenn e s s c e nt r a l i t y    vol. 25, no. 2, pp. 163-177 2001   Stan fo r d  Net w or k A na l y s is Pro j e c t  O n l in e    http://snap.stanford.edu    I  S t ant o n and G  K l i o t, "S t r e a m i n g G r aph P a rtiti o n in g  for L a rge Distributed Graphs," Microsoft Corp., Technical Report MSRTR-2011-121, 2011   G   K a ry pis and V   K um a r A fas t and hi g h qua l i t y m u l t i l evel scheme for partitioning irregular graphs," in 1995, pp. 113-122   M. A r m b r u s t e t  a l   A v i ew of  c l o u d  c o m putin g    vol. 53, no. 0001-0782, pp. 50-58 April 2010  
214 


  13  or gani c  c he m i s t r y  i n our  Sol ar  Sy s t e m       Xi a n g  L i r e c e i v e d h i s B  S   m is tr y  fr o m  th e  P e k in g  U n iv e r s ity  C h in a  in  2 0 0 3  and P h D   i n P hy s i c al  C he m i s t r y  f r om  t he  J ohns  H opk i ns  Un i v e r s i t y  i n  2 0 0 9   He  h a s  b e e n  a  R e s e a r c h  A s s o c i a t e  wi t h  a  j o i n t  a p p o i n t m e n t  a t  t h e  U n i v e r s i t y  o f  M a r y l a n d   Ba l t i m o r e  C o u n t y  a n d  N AS A G o d d a r d  S p a c e  Fl i  Ce n t e r  s i n c e  2 0 1 1   H i s  r e s e a r c h  f o c u s e s  o n  t h e  d e t e c t i o n  of  t r ac e  e l e m e nt  and as t r obi ol ogi c al l y  r e l e v ant  or gani c  mo l e c u l e s  i n  p l a n e t a r y  s y s t e ms   l i k e  M a r s   He  i s  es p eci a l l y i n t er es t ed  i n  t h e d evel o p m en t  o f  T i m e of  and I on T r ap m as s  s pe c t r om e t e r s w i t h v a r i o u s i o n i z a t i o n  ng te c h n iq u e s   Wi l l  B r i n c k e r h o f f  sp a c e  sc i e n t i st  i n  t h e  Pl a n e t a r y  En v i r o n m e n t s  La b  a t  N A S A  s  G o d d a r d  Spac e  F l i ght  C e nt e r  i n Gr e e n b e l t   M D w i t h  pr i m ar y  r e s pons i bi l i t y  f or  th e  d e v e lo p m e n t o f th e  L D TO F  m a s s  s p e c t r o  th is  p r o je c t H e  h a s  fo c u s e d  re c e n t l y  o n  t h e  d e v e l o p m e n t  o f  m i n i a t u re  l a se r d ma s s  s p e c t r o me t e r s  f o r  f u t u r e  p l a n e t a r y  mi s s i o n s  a l o n g  wi t h  b a s i c  e x p e r i m e n t a l  r e s e a r c h  i n  a s t r o b i o l o g y  a n d  p r e bi ot i c  s y nt he s i s   D r   B r i nc k e r hof f  i s  i nv ol v e d i n t he  de v e l opm e nt  of  m as s  s pe c t r om e t e r  f or  bot h t he  2011 Ma r s  S c i e n c e  L a b o r a t o r y  a n d  t h e  2 0 1 8  E x o Ma r s  mi s s i o n s   


  14   


Copyright © 2009 Boeing. All rights reserved  Issues and Observations Initial load of one day of data ~ 7 hours Optimizations  Write data in batches  Use a mutable data structure to create data strings  Deploy a higher performance machine  Use load instead of insert  Use DB2 Range-Partitioned tables  Database tunings Time reduced from 7 hours to approx 30 minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Use a mutable data structure to create data strings  Original application created the SQL statement by appending elements to a Java String  It was taking five hours \(of the seven hours Strings  Instead Java StringBuilder used  Java Strings immutable  Time savings of 71.4 


Copyright © 2009 Boeing. All rights reserved  Optimizations Deployed on a higher-performance machine  Application ported from IBM Blade Center HS21 \(4GB of RAM and 64-bit dual-core Xeon 5130 processor to Dell M4500 computer \(4GB of RAM and 64-bit of quad-core Intel Core i7 processor  Reduced the time to thirty minutes Bulk loading instead of insert  Application was modified to write CSV files for each table  Entire day worth of data bulk loaded  Reduced the time to fifteen minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Range-Partitioned tables \(RPT  To limit the size of tables, the original code created multiple tables per table type  This puts burden on the application to query multiple tables when a range crosses several tables  With RPT, user is not required to make multiple queries when a range crosses a table boundary  Increased the time to thirty minutes  Additional fifteen minute cost per day of partitioning enabled time savings during queries 


Copyright © 2009 Boeing. All rights reserved  Optimizations Database tunings  Range periods changed from a week to a month  Automatic table space resizing changed from 32MB to 512KB  Buffer pool size decreased  Decreased the time to twenty minutes Overall, total time savings of 95.2 


Copyright © 2009 Boeing. All rights reserved  20 IBM Confidential Analytics Landscape Degree of Complexity Competitive Advantage Standard Reporting Ad hoc reporting Query/drill down Alerts Simulation Forecasting Predictive modeling Optimization What exactly is the problem What will happen next if What if these trends continue What could happen What actions are needed How many, how often, where What happened Stochastic Optimization Based on: Competing on Analytics, Davenport and Harris, 2007 Descriptive Prescriptive Predictive How can we achieve the best outcome How can we achieve the best outcome including the effects of variability Used with permission of IBM 


Copyright © 2009 Boeing. All rights reserved Initial Analysis Activities Flights departing or arriving on a date Flights departing or arriving within a date and time range Flights between city pair A,B Flights between a list of city pairs Flights passing through a volume on a date. \(sector, center, etc boundary Flights passing through a volume within a date and time range Flights passing through an airspace volume in n-minute intervals All x-type aircraft departing or arriving on a date Flights departing or arriving on a date between city pair A,B Flights departing or arriving on a date between a list of city pairs Flights passing through a named fix, airway, center, or sector Filed Flight plans for any of the above Actual departure, arrival times and actual track reports for any of the above 


Copyright © 2009 Boeing. All rights reserved  Initial SPSS Applications Show all tracks by call sign 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case For a given Airspace Volume of Interest \(AVOI compute distinct traffic volume at some point in the future  Aim to alert on congestion due to flow control areas or weather if certain thresholds are exceeded  Prescribe solution \(if certain thresholds are exceeded Propose alternate flight paths  Use pre-built predictive model  SPSS Modeler performs data processing Counts relevant records in the database \(pattern discovery Computes traffic volume using statistical models on descriptive pattern Returns prediction with likelihood 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  24 Pulls in the TRACKINFO table of MAIN using SQL Limits the data to database entries which fall inside the AVOI Combines the SOURCE_DATE and SOURCE_TIME to a timestamp that can be understood by modeler Computes which time interval the database entry falls in. The time interval is 15 minutes Defines the target and input fields needed for creating the model Handles the creation of the model Produces a graph based off of the model results Final prediction 


Copyright © 2009 Boeing. All rights reserved  Initial Cognos BI Applications IBM Cognos Report Studio  Web application for creating reports  Can be tailored by date range, aircraft id, departure/arrival airport etc  Reports are available with links to visuals IBM Framework Manager  Used to create the data package  Meta-data modeling tool  Users can define data sources, and relationships among them Models can be exported to a package for use with Report Studio 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 1 of 3 Report shows the departure date, departure and arrival locations and hyperlinks to Google Map images DeparturePosition and ArrivalPosition are calculated data items formatted for use with Google Maps Map hyperlinks are also calculated based on the type of fix 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 2 of 3 DeparturePosition, Departure Map, ArrivalPosition and Arrival Map are calculated data items \(see departure items below DepartureLatitude DepartureLongitude DeparturePosition Departure Map 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 3 of 3 


Copyright © 2009 Boeing. All rights reserved  Conclusion and Next Steps Current archive is 50 billion records and growing  Approximately 34 million elements per day  1GB/day Sheer volume of raw surveillance data makes analytics process very difficult The raw data runs through a series of processes before it can be used for analytics Next Steps  Continue application of predictive and prescriptive analytics  Big data visualization 


Copyright © 2009 Boeing. All rights reserved  Questions and Comments Paul Comitz Boeing Research & Technology Chantilly, VA, 20151 office Paul.Comitz@boeing.com 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  31 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  32 Backup Slides 


Copyright © 2009 Boeing. All rights reserved  Initial Approach Initial Investigations  Apache Solr/Lucene  Data Warehouse Evaluate Hadoop in the future 


Copyright © 2009 Boeing. All rights reserved  Using SOLR Uncompress Track Information Messages To use with Solr  Transforming track messages from their  original schema to Solr required building a ìkey, valueî list using an XSTL  Queries made against this list of ìkey, valueî pairs Transformation Process  One day of data ~ 4.5 hours Once transformation complete search/query performance very good Geo spatial queries using  unique query language 


Copyright © 2009 Boeing. All rights reserved  Representation Aviation data is frequently represented in more than one form 



A Cloud Service for the Evaluation of Company's Financial Health Using XBRL-based Financial Statements  Wen-Chiao Hsu a Jyun-Yao Huang a Chi-Hao Chen a Chien-Yu Su a Hsiao-Chen Shih a Tzu-Ya Liao b I-En Liao a  a Department of Computer Science and Engineering National Chung Hsing University Taichung, Taiwan ieliao@nchu.edu.tw b Department of Business Administration National Cheng-Kung University Tainan, Taiwan tzuyaliao@gmail.com   Abstract Financial statements of all listed and over the counter \(OTC\mpanies collected by stock exchange represent valuable big open data. Therefore, automatic processing and analyzing such big data would create tremendous added value economically. In this paper, we design and implement a cloud service for evaluating company's financial health using XBRL-based financial statements collected by Taiwan Stock Exchange Corporation \(TWSE The XBRL-based financial statements are parsed and stored as key-value pairs into MongoDB, which is a kind of NoSQL database. The proposed system is designed using three-tier architecture for flexibility and maintainability. It also provides user-friendly interface with various charts. The proposed system indeed demonstrates powerful benefits of implementing interactive data using XBRL for financial disclosure documents in big data era Keywords-XBRL, Financial statements, Financial health evaluation, MongoDB, NoSQL I   I NTRODUCTION  The convergence of cloud computing and big data is changing the world and will have far-reaching implications on technological area. When large amounts of data are collected in the cloud data center for processing, a standard machine-readable format for data representation is one of the critical requirements. As a result, XML \(eXtensible Markup Language\ is widely accepted as a standard for exchange of information over the Internet, and it has grown into a big family of specifications. For instance, XBRL \(eXtensible Business Reporting Language\, which is a global standard for exchanging business information, is an XML-based language. Since the hierarchical structure of XML and the relational data models are not fully compatible, the NoSQL database, which provides a mechanism for storage and retrieval of "unstructured data", are developed to address that issue. NoSQL is often used for storing big data and designing real-time web applications. There are many NoSQL databases, such as MongoDB [1 uc hD B  2  RethinkD  Ca ss a ndr a [4  a n d s o  o n  As data grows at an astonishing rate, data analytics need to be developed to produce valuable insights of business data Before the introduction of XBRL, most of the financial statements are reported in the formats of HTML, PDF, Word or EXCEL that are not suitable for automatic processing Therefore, XBRL was developed in 1998 as a business reporting language. Since then, a growing list of government agencies and other entities have also begun to incorporate XBRL into their disclosure systems, including US SEC Australia, Committee of European Banking Supervisors CEBS\, United Kingdom, Japan, Taiwan, etc The development of the proposed system is a result of 2013 XBRL Software Design Competition hosted by TWSE in which our team won the national championship. The characteristics of the proposed systems can be described as follows  It is a Web-based service system which allows users to use services through browser without installing any other application. It can also be deployed as SaaS service supporting different kinds of user devices including smart phones  T aking into account of big data problem, a NoSQL database, MongoDB, is used for data storage  It adopts three-tier system architecture with newly developed API for flexibility and maintainability  The results of financial health evaluation are presented using five different light bulbs for easy understanding  It provides user-friendly interface with various charts such as bar, radar, and trends, for users to interact in a natural and intuitive way II  R ELATED W ORK  In this section, we will describe the development of XBRL and the concept of NoSQL, including MongoDB A  The development of XBRL XBRL was first developed by a consortium created by AICPA \(American Institute of CPAs\ 1998, and in recent years, it is accepted as a standard business reporting language worldwide. The first recommendation, version 1.0 was published in 2000. The version 2.0 was published in 2001. The current recommended specification is version 2.1 5   T h e w e lldef i n e d f o rm at of X B R L p r ov i d es m ach in ereadable tags to exchange and transfer business information across individual computation platforms [6   T h e  X B RL  taxonomies are the reporting-area specific hierarchical dictionaries used by the XBRL community Dif f e ren t  taxonomies or taxonomy extensions will be required for different business reporting purposes. For example, some 978-1-4799-1293-3/13/$31.00 ©2013  IEEE 


national jurisdictions define their taxonomies to reflect local accounting and other reporting regulations With the development of XBRL, it has increased the financial report transparency across companies and achieves the important financial disclosures Currently, XBRL is being used across a wide range of sectors, including securities regulation banking, insurance, data aggregators and taxation, as well as for non-financial reporting such as carbon disclosure sustainability efforts and risk reporting Although the development of best practices in the use of XBRL is still in the early stages there are many researches that have been published to analyze the concept benefits and applications of XBRL from different perspectives [8 For example, Callaghan et al. [11 p r es en ts a f r am ew ork f o r  augmenting the XBRL documents through the use of UML constructs to increase utilization of XBRL documents in financial analysis and decision-making.  Murthy and Groomer  pr e s e n t  a co nt i nuo us a u d i t i ng w e b s e r v i c e s  CAWS\ model that uses the emerging XML Web services framework to support a "pull model of continuous auditing in a world of XML-enabled accounting systems, such as XBRL GL and business process execution language for web services BPEL4WS Stivason et al. [13 p r o p o s e a  Us e r  Defined Account Model UDAM\, which allows users to determine which measure they would like to employ by accessing the primary measures and compiling financial statements in any format they desire. O'Riain et al. [14  argue that linked data technology can accommodate XBRL data and make it easier to combine it with open datasets They proposed a system that provides a middleware for offering useful queries by converting XBRL to RDF Resource Description Framework\, which is then integrated with the other linked open data Some business application systems for XBRL have also been developed Fujitsu has leveraged XBRL in its own financial reporting and built the XBRL's Global Ledger XBRL-GL\ framework 1 wi t h a st a n d a rd i zed vi e w o f t h e  ERP system data Altova has extended the reach of its XML development tools with support for XBRL 1  S A P  delivers the BusinessObjects XBRL Publishing 17 t o  enable easier communication of financial and business data Taiwan Stock Exchange Corporation \(TWSE\ adopted XBRL in 2008 by announcing a demonstration platform at the end of that year and then requested all listed companies to report their financial statements in XBRL format starting from 2010 B NoSQL and MongoDB Big Data relates to data creation, storage, retrieval and analysis that are impractical or impossible to manage with traditional software tools. New technologies like NoSQL referred to as "Not only SQL", databases are frequently used to store big data They are suitable for dynamic data structures and are highly scalable without categorizing and parsing the data into a fixed schema [1  T he  N o S Q L database aims to address the shortcomings of relational databases and the demands of modern software development One of the leading NoSQL database is MongoDB 1  which is a document database A database of MongoDB contains collections, which hold a set of documents. A document is represented as a BSON \(Binary JSON\ structure i.e., a list of key-value pairs. The value can be of three types a primitive value, an array of documents or again a list of key-value pairs. It is why the MongoDB can work with dynamic schemas. MongoDB provides four basic database operations \(i.e. Core MongoDB Operations, CRUD\, which stands for create read, update, and delete, for application development. To query these documents the client can set filters on the collections expressed as a list of key-value pairs The queries are also JSON structured and it is possible for query nested fields III M ETHODOLOGY OF P ROPOSED S YSTEM A System Architecture The workflow of the proposed system is shown in Figure 1. We designed a Web crawler to collect the original XBRL documents from the Market Observation Post System in Taiwan \(http://mops.twse.com.tw/server-java/t147sb02 Then, the XBRL documents are parsed and stored in MongoDB The financial health evaluation system is deployed in Microsoft Azure and provides the service as a SaaS Figure 1 Workflow of the proposed system B Data processing An example of XBRL document is shown in Figure 2 An XBRL taxonomy is an industry-specific categorization scheme. We use XBRL Java API 20  p a r s e XB R L  documents. In order to speed up query processing and support scalability, we choose MongoDB to manage the financial data. Since the value of a key-value pair can be another list of key-value pairs it is compatible with the hierarchical structure of the xml-based document. A snapshot of XBRL in MogoDB is shown in Figure 3 C System Development Since the financial data are constantly increased and the functional modules are also potentially changeable, a threetier architecture is adopted as our system’s fundamental architecture. As shown in Figure 4, the system provides abstraction among the presentation layer, logic layer, and the data layer, which makes our system more flexible and maintainable in the lifetime of the system 11 


Figure 2 An instance of an XBRL Figure 3 A snapshot of XBRL in MongoDB Figure 4 Three-tier system architecture D Financial Health Lights and Indicators The financial health of a company is comprised of six dimensions: capital structure, repayment ability, ability to benefit, operation efficiency, ability to growth, and cash-flow Each dimension involves several financial ratios, which are listed in Table I The financial ratios can help to make sense of the overwhelming amount of information that can be found in a company's financial statements, and the formulas of all financial ratios can be found in most of the finance books The performance of financial ratio and the six dimensions of financial health are finally represented by five different light bulbs. The derivation steps are performed as follows 1 Calculate the scale of performance for each financial ratio The scale of a ratio depends on the industry average over the same period and the value of year-over-year. The scale of the financial ratio r p is calculated by Equation \(1 where r y,i denotes the value of a financial ratio r over i th quarter of the year y and I\(r y,i indicates the the industry average of r over i th quarter of the year y  r p r y,i r y-1,i r y-1,i r y,i I\(r y,i I\(r y,i  2  2 Translate the scales to financial health light bulbs Five different light bulbs are used to represent the "financial health", i.e., red, yellow-red, green, yellow-blue and blue We grades five indicators from one to five points, and each light bulb has its grade-point scale. Table II lists the mapping between scale and grade, as well as the meanings of light bulbs 3 Aggregate financial ratios to six dimensions According to the classification in Table I, we can express the financial health in each dimension by averaging the scales of the corresponding financial ratios. The results are also represented by light bulbs as shown in Table II TABLE I S IX D IMENSIONS AND THE C ORRSPONING F INANCIAL R ATIOS Dimension Financial Ratio Capital Structure Equity ratio Debt-to-asset ratio Debt-to-equity ratio Capitalization ratio Current liabilities to total liability ratio Fixed assets to permanent capital ratio Repayment Ability Current ratio Quick ratio Interest protection multiples Ability to Benefit Return on assets Return on equity Gross profit margin ratio Net profit margin ratio Operation Efficiency Total assets turnover ratio Fixed assets turnover rate Accounts receivable turnover ratio Inventory turnover ratio Ability to Growth Sales growth ratio Net profit growth ratio Total equity growth ratio Equity growth ratio Cash Flow Cash flow ratio Cash re-investment ratio 12 


TABLE II D ESCRIPTION OF F INANCIAL H EALTH L IGHT B UL B S Monitoring Indicators Light Bulb Red Yellow-red Green Yellow-blue Blue Scale 50 50 ~ 15 15 ~ -15 15 ~ -50  50 Grade 5 4 3 2 1 Meaning Very Good Good Fair Bad Very Bad IV S YSTEM I MPLEMENTATION For system implementation, we adopt three-tier system architecture to simplify the application development process A web crawler is developed to collect the XBRL instance documents, including the financial statements of all listed and OTC companies from the first quarter of 2010 to the fourth quarter of 2012, from the Market Observation Post System in Taiwan. The XBRL instance documents are parsed and stored in MongoDB All the development tools are listed in Figure 5, including some newly developed APIs for flexibility and maintainability This system had been deployed in Microsoft Windows Azure cloud platform for testing It is now maintained at http://xbrl.dmlab.cs.nchu.edu.tw Figure 5 Development tools for three-tier architecture Because the system is intended to be used by Taiwanese users, the user interface uses Chinese characters. Figure 6 is one snapshot of the proposed system. The area numbered "1 shows three ways to display financial information for single company, for multi-company comparison, and for userdefined filters, from top to down. For example, when we chose to view the financial health of a company and pressed the top button in area "1", all we need to do is setting required entries in area "2", i.e., the target industry, company year, and quarter. Then press the "submit" button.  The results will be shown in area "3". The evaluation of company’s financial health is represented in terms of six dimensions and one overall performance. Each one is presented using five different light bulbs based on the calculation described in Section III-D, steps 2-3\ The grades and the meanings of light bulbs are also listed on the left side of the web page to assist users’ understanding. The button numbered "4" can be clicked to show the corresponding radar chart The buttons in area "5" provides detailed information for each dimension As an example, Figure 7 shows the evaluation results of the "Capital Structure" dimension. The detailed information of six financial ratios is in the area "6". The calculation of the scale of performance for each financial ratio is described in Section III-D, step 1 The system also provides bar chart and trend chart for each ratio as in numbered "7" and "8 respectively V C ONCLUSION In this paper, a cloud service for evaluation of company’s financial health based on XBRL-tagged financial statements is designed and developed with emphasis on three-tier system architecture and NoSQL database. The proposed system provides user-friendly interface that makes complicated financial data easy to understand. It indeed demonstrates tremendous benefits of implementing interactive data using XBRL for financial information in big data era A CKNOWLEDGMENT This research was partially supported by National Science Council, Taiwan, under Contract No. NSC101-2221E-005-087 R EFERENCES 1 M on goDB   On lin e v a i lab l e a t  h ttp   w ww  m on god b  org   Accessed: August 8 20  2 A pache Co uc hD B   O nl i n e  A v ail a bl e at h tt p   co u c h d b.a p ac he o r g  Accessed: August 8 20  3 R e t h i n k D B O nl i n e  A v ail a bl e at h tt p w w w re t hin k db co m   Accessed: August 8 20  4 A p a c h e C a s s a n d r a  O n l i n e  A v a i la b l e a t  http://cassandra.apache.org/,  [Accessed: August 8 2013 5 S pe cif i cat io n Re co m m e n d a tio n    O nl i n e  A v ail a bl e a t http://www.xbrl.org/SpecRecommendations. [Accessed: August 8 2013 6 B D o o l in a n d I  T r o s hani X B R L  a r e s e ar ch no te Q u al i t at iv e  Research in Accounting & Management, vol. 1, iss. 2, 2004, pp. 93104, doi:10.1108/11766090410813373 7 T a x on om i e s   O n lin e A v a i la b l e a t  h t t p  www  x b r l org Ta xon o m i es  Accessed: August 8 20  8 M  A  Alles and G. L. Gray, “A relative cost framework of demand for external assurance of XBRL filings,” Journal of Information Systems, vol 26 no. 1 2012, pp. 103–126 doi: 10.2308/isys-10248 9 J E Bo r i tz an d W  G  N o  A s s ur an ce o n X B RL r el ate d do c u m e n t s   The case of United Technologies Corporation,” Journal of Information Systems, vol 23,  iss. 2 2009, pp 49–78 doi 10.2308/jis.2009.23.2.49 1 J  W  K i m  J  H. L i m  a n d W  G  No  T h e eff e c t of fi rs t w a ve  mandatory XBRL reporting across the financial information environment,”. Journal of Information Systems, vol 26, iss. 1 2012 pp. 127–153 doi:10.2308/isys-10260 1 J  H. C a lla gha n  A  Sa va ge and V. S u gu m a ra n A u g m e n t in g X BR L  using UML: Improving financial analysis,” The Review Of Business Information Systems, vol. 6, iss. 4,  Jan. 2002, pp. 27-33 12 U  S  M u r t hy an d S  M  G r o o m e r   A co nt in uo us a u di ti ng w e b services model for XML-based accounting systems,” International Journal of Accounting Information Systems, vol. 5, iss. 2, Jul. 2004 pp. 139-163 doi:10.1016/j.accinf.2004.01.007 13 


13 C. S t iv as o n  D  H i cks  a nd G  S a un de r s  U s e r de f i ne d acco un ti ng  model,” Review of Business Information Systems, vol. 12, no. 4 2008 1 S O'R i a i n  E  Cu rry   A  Ha rt h  X B R L a n d op e n  d a t a for glob a l  financial ecosystems: A linked data approach,” International Journal of Accounting Information Systems, vol. 13, iss. 2, Jun. 2012 pp 141-162 doi:10.1016/j.accinf.2012.02.002 1 F u j i t s u  a d ap t s t o  a ch an gi n g en vi r o nm en t w i th  a m o ve t o eXt e n s ib le Business Reporting Language \(XBRL Online A v ail a bl e a t  http://www.fujitsu.com/global/casestudies/INTSTG_Fujitsu_XBRL.h tml Accessed: September 10 2013 1 AL T O V A  XB R L S o lu t i o n s   On lin e A v a i la b l e a t   http://www.altova.com/solutions/xbrl.html, [Accessed: September 10 2013 17 S A P Bus i ne s s O b je cts X B RL P ubl i s hi ng  by U B Ma tr ix   O n l i ne  Available at:  http://help.sap.com/bo_xblr Accessed September 10 2013 18 X BRL D e m o ns tr atio n P l atf o r m  T a iw an  O nl i n e   A v ail a bl e a t  http://xbrldemo.twse.com.tw Accessed: August 8 20  1 J P Dij c k s  Ora c le W h i t e Pa p e r B i g Da t a for t h e  E n t e rp ri se Ora c le  Corporation Jun 2013 20 X BRL J a v a A P I  O nl ine   A v a i l a bl e a t http://siitest.twse.com.tw/doc/jcx.zip Accessed: August 8, 2013 Figure 6 Example of financial health evaluation in six dimensions and overall performance Figure 7 Example of six financial ratios in "Capital Structure dimension 14 


Figure 2 Concrete implementation action acPostProcForPut and de\002ne additional condition a c P o s t P r o c F o r P u t  ON  o b j P a t h l i k e  003  p r o c  003         Listing 4 Rule to trigger processing details omitted Listing 2 shows a Pig script that can be used for the word calculation The script however has a prede\002ned input and output  path/file.txt and path/output.dat respectively This had to be changed Pig scripts can take external parameters they are marked by  in the script We agreed on a convention to call the input of a Pig script input and output output  The input of the script can be extracted from the name of the special 002le the output should be directed to a temporary directory 002rst and then moved to overwrite the special 002le after the computation is completed Now both parts have to be put together and the creation of the special 002le should trigger the execution of the Pig script iRODS provides a microservice that can be convenient here msiExecCmd can be used to call batch scripts stored on the iRODS server It was quite simple to write a short batch script called executing script  that takes the logical and physical name of the special 002le as parameters start a Pig processing script and move its results back to overwrite the special 002le Surprisingly the most challenging task was the last one iRODS stores the 002le size in the iCAT database Since the process of overwriting changes the size of the special 002le the iCAT content has to be updated This was done by issuing direct SQL query to the iCAT database Listing 5 shows how the executing script runs the processing script  u s r  b i n  p i g 000 p i n p u t    i n p u t  000 p o u t p u t    o u t p u t  000 l  v a r  p i g  l o g PIG_SCRIPTS   s c r i p t N a m e  p i g Listing 5 Fragment of the executing script Let us now extend the simple example presented above to show more advanced features of the Workspace The Pig script for word counting produces output in form presented on Listing 6 where the 002rst column contains the number of occurrences of the given word from the second column 1775 t h e 1040 o f 730 i n 677 and 457 t o 343 was 334 a 331 und 248 d i e 223 he    Listing 6 Processing results For the sake of discussion let us assume that the researcher is only interested which words occurred more often than 200 times and less than 300 times It is a simple 002ltering job that should analyze the 002rst column of the 002le First challenge to tackle is the need to provide more parameters to a Pig script than just input and output In Section II we mentioned that the parameters should be part of the logical name of the special 002le This is certainly true for the input and output parameters that can be derived from the full path of the 002le But it is also possible to include more parameters in the full name Particularly for the 002ltering job it would be reasonable to encapsulate the 002ltering criteria in the 002le name like this path/proc/filter\(coll1>200 AND coll1<300  Within this convention it is quite simple to write a Pig script for the required analysis that allow for 003exibility in terms of 002ltering e g change of the 002ltering boundaries The script is presented on Listing 7 A  LOAD   i n p u t  USING P i g S t o r a g e    t   AS  c o l l 1  c o l l 2   B  FILTER A BY   p a r a m s   STORE B INTO   o u t p u t   Listing 7 Pig script for 002ltering 68 


The executing script that is used for starting the job must be extend as well to pass not only the input and output parameters but also the 002ltering conditions to Pig It must also determine which script to run either wordCount or filter  This is done based on the name of the special 002le We sought after an extensible solution for the Workspace and it is to expect that sooner or later the researchers needs would not be satis\002ed by the two scripts presented so far and they will look for ways of de\002ning own processing scripts This functionality is easily enabled by storing the Pig scripts in ordinary iRODS collections The more advanced users could then upload their Pig scripts to a iRODS directory The scripts must only follow the convention of 003exible input and output paths and parameter passing if required The whole processing work\003ow does not change much First a creation of a special 002le with name in form collection/proc/function\(parameters is detected by iRODS Subsequently this logical name is passed to the executing script that extracts the function name which is mapped on the Pig script name and job parameters The appropriate Pig script is fetched from the iRODS collection and executed with extracted parameters In the last step the result is written back to the special 002le The 002nal solution is extensible and future-proof it allows to easy extend the set of processing function run them on new data by all the users of Workspace and share the results of the computation IV R ELATED W ORK In the previous sections we presented the idea architecture and a prototype of the Generic Workspace for Big Data Processing in Humanities The Workspace can be seen as an active storage i e a storage that not only stores the data but also provides a means for ef\002cient processing of the data Let us compare the presented approach to some previous work in the 002eld Our concept is clearly related to the idea of Virtual Research Environments An example of VRE is TextGrid although it is much more on the organizational level than just a tool TextGrid comprises two main components a web front-end and a repository TextGridRepo that abstracts underlying storage resources and services Usually the VREs provide high-level complex services like XML editing or text comparison tools The Workspace does not 002t into this category It can be seen as a service of underlying middelware that is exposed as a service to the user to enable ef\002cient processing before the ingest of the data for preservation in the TextGridRepo or further processing with high-level tools There are also plans for migrating the TextGrid repository infrastructure to Fedora Commons and iRODS that would allow to even reuse some parts of our prototype The digital humanities workbench pro vides a wide collection of useful text processing tools as on-line services Making the existing tools available without the need of installing them locally is a central concept of all kinds of VREs The authors of presented a general-purpose Virtual Research Environments that facilitates the integration of information resources and tools for supporting research activities We believe that our Workspace could easily be integrated into VREs as a tool that provides ef\002cient processing of large amounts of data Most of the VREs foresee the possibility to extend the installations by adding new storage resources Since the Workspace provides a 002le system interface it can be integrated into a VRE There are already examples of the application of MapReduce in digital humanities The moti v ation of the authors were the performance problems of the tool called Text Analysis Portal for Research TAPoR which is a web-based application that provides a suite of text-analysis tools to scholar and researcher in the digital humanities The authors identi\002ed that the problem was caused by the Ruby-based backend services that performed the actual processing They decided to migrate the services to Hadoop and achieved substantial performance improvements This work shows that the Hadoop-based services can be successfully used to solve problems in digital humanities The main architectural difference between this work and our solution is the application of the declarative approach in the Workspaces We have shown that our approach has serious implications with regard to the user-friendliness and the costs of integration of new services Despite its high popularity and broad application it becomes clear that MapReduce is not always the right tool and has its limitations 19 Our w ork w as moti v ated by the experience of cyber-infrastructure providers in a digital humanities project The rationale behind the Workspace is to enable quick integration of new services into an emerging infrastructure We used Hadoop MapReduce and Pig to build a working prototype but the same approach can be used to integrated alternative processing solutions Especially while we use a declarative approach the user is not even aware how the actual computation is done Thus changes or additions of new services are seamless to the end-users Adding new services would be an interesting avenue for further research The work discusses generic processing en vironments the solution however strives for general applicability of the remote method execution pattern The discussion focusses on the low level technologies which is out of scope for our work Admittedly the user interface was not a primary concern of our work Given the heterogeneous user-base of DARIAH it would be hard to come up with an interface that could be suitable and acceptable for all users We decided to use the well-known abstraction of a 002le system as a primary lowlevel interface to the Workspace The decision was motivated by the presence of such a 002le system offered by iRODS The abstractions of the web and 002le system resources however 69 


are quite close to each other thus it would be easy to build an HTTP-based ReST interface above the 002le-system-based Workspace in the future This might become a relevant topic given the DARIAH efforts to provide an HTTP-based user interface to storage resources and common portal 21 V C ONCLUSION We presented a generic concept of Workspace for Big Data Processing in Humanities Our work was inspired by the experiences collected during the establishing of a distributed service-oriented cyber-infrastructure in DARIAHDE We proposed a solution that ful\002lls two main design goals it is user-friendly and reduces the burden of integrating and providing new services The working demonstrator of the concept helps users to process large amounts of data by employing ef\002cient data processing based on Hadoop and Pig two emerging data processing products often applied to deal with the challenges of Big Data The two products were used together with a well-established data Grid solution iRODS The paper presents a provider-centric view on enabling Big Data processing tools which is the 002rst step of their application in digital humanities As long as the tools are not available there is little chance that they will be used to solve the actual research problems A CKNOWLEDGEMENTS The work has been supported by DARIAH-DE which is partially funded by the German Federal Ministry of Education and Research BMBF fund number 01UG1110A-M and by EUDAT funded by the European Union under the Seventh Framework Program contract number 283304 R EFERENCES  D ARIAH Digita l Research Infrastructures for the Arts and Humanities A v ailable http://www dariah.eu  D Lane y  2233D Data Management Controlling Data V olume Velocity and Variety,\224 Gartner Tech Rep 2001  A Rajase kar  R Moore C.-Y  Hou C A Lee R Marciano A de Torcy M Wan W Schroeder S.-Y Chen L Gilbert P Tooby and B Zhu iRODS Primer Integrated RuleOriented Data System  ser Synthesis Lectures on Information Concepts Retrieval and Services Morgan  Claypool Publishers 2010  D T onne J Rybicki S E Funk and P  Gietz 223 Access to the DARIAH bit preservation service for humanities research data,\224 in PDP 13 21st Euromicro International Conference on Parallel Distributed and Network-Based Processing  2013 pp 9\22615  M Sarw ar  M Ale xander  J Anderson J Green and R Sinnott 223Implementing MapReduce over language and literature data over the UK National Grid Service,\224 in ICET 11 7th IEEE International Conference on Emerging Technologies  2011 pp 1\2266  D Jef fre y and G Sanjay  223MapReduce simpli\002ed data processing on large clusters,\224 Communications of the ACM  vol 51 no 1 pp 107\226113 Jan 2008  T  White Hadoop The de\002nitive guide  O'Reilly Media Inc 2012  T  Blank e L Candela M Hedges M Priddy  and F  Simeoni 223Deploying general-purpose virtual research environments for humanities research,\224 Philosophical Transactions of the Royal Society A Mathematical Physical and Engineering Sciences  vol 368 no 1925 pp 3813\2263828 2010  R Fielding 223 Architectural styles and the design of netw orkbased software architectures,\224 Ph.D dissertation University of California Irvine 2000  R Fi elding J Gettys J Mogul H Frystyk L Masinter  P Leach and T Berners-Lee 223Hypertext Transfer Protocol 226 HTTP/1.1,\224 RFC 2616 Draft Standard Internet Engineering Task Force Jun 1999 A v ailable http://www.ietf.org/rfc/rfc2616.txt  B Zhu R Marciano R Moore L Herr  and J P  Schulze 223Digital repository preservation environment and policy implementation,\224 International Journal on Digital Libraries  vol 12 no 1 pp 41\22649 2012  C Ol ston B Reed U Sri v asta v a R K umar  and A T omkins 223Pig latin a not-so-foreign language for data processing,\224 in SIGMOD 08 ACM International Conference on Management of Data  2008 pp 1099\2261110  Apache Pig Project Online A v ailable http://pig.apache.or g  H Neuroth F  Lohmeier  and K M Smith 223T e xtGrid 226 vir tual research environment for the humanities,\224 International Journal of Digital Curation  vol 6 no 2 pp 222\226231 2011  Fedora commons repository softw are Online A v ailable http://www.fedora-commons.org  A Bia 223The digital humanit ies w orkbench 224 in INTERACCION 12 13th ACM International Conference on Interacci\363n Persona-Ordenador  2012 p 50  H V ashishtha M Smit and E Stroulia 223Mo ving te xt analysis tools to the cloud,\224 in SERVICES-1 6th IEEE World Congress on Services  2010 pp 107\226114  A P a vlo E P aulson A Rasin D J Abadi D J DeW itt S Madden and M Stonebraker 223A comparison of approaches to large-scale data analysis,\224 in SIGMOD 09 ACM International Conference on Management of Data  2009 pp 165\226 178  A Ro wstron D Narayanan A Donnelly  G O'Shea and A Douglas 223Nobody ever got 002red for using Hadoop on a cluster,\224 in HotCDP 12 ACM 1st International Workshop on Hot Topics in Cloud Data Processing  2012 pp 1\2265  B Dumant F  Horn F  D T ran and J.-B Stef ani 223Jonathan an open distributed processing environment in Java,\224 Distributed Systems Engineering  vol 6 no 1 p 3 1999  D ARIAH Porta l Online A v ailable https://portalde.dariah.eu 70 


A CKNOWLEDGEMENTS The authors acknowledge the Texas Advanced Computing Center TACC at The University of Texas at Austin for providing HPC resources that have contributed to the research results reported within this paper URL:http://www.tacc utexas.edu This research was partially supported by the National Institutes of Health NIH Grants R01GM08533703 R EFERENCES  J Dean and S Ghema w at Mapreduce simpli“ed data processing on large clusters Commun ACM  vol 51 no 1 pp 107…113 Jan 2008  C Olston B Reed U Sri v asta v a  R  K umar  and A T omkins Pig latin a not-so-foreign language for data processing in Proceedings of the 2008 ACM SIGMOD international conference on Management of data  ser SIGMOD 08 New York NY USA ACM 2008 pp 1099…1110  M Blum R W  Flo yd V  Pratt R L Ri v est and R E Tarjan Time bounds for selection J Comput Syst Sci  vol 7 no 4 pp 448…461 Aug 1973  C A R Hoare  Algorithm 65 nd  Commun ACM  vol 4 no 7 pp 321…322 Jul 1961  C A R Hoare Quicksort  The Computer Journal  vol 5 no 1 pp 10…16 1962  M Caf aro V  De Bene and G Aloisio Deterministic par allel selection algorithms on coarse-grained multicomputers Concurr Comput  Pract Exper  vol 21 no 18 pp 2336 2354 Dec 2009  S Stadtm  uller S Speiser A Harth and R Studer Datafu a language and an interpreter for interaction with read/write linked data in Proceedings of the 22nd international conference on World Wide Web  ser WWW 13 Republic and Canton of Geneva Switzerland International World Wide Web Conferences Steering Committee 2013 pp 1225…1236  R J T ibshirani F ast computation of the median by successive binning Computing Research Repository CoRR  vol abs/0806.3301 2008  H Prodinger   Multiple quickselect&mdash;hoare s nd algorithm for several elements Inf Process Lett  vol 56 no 3 pp 123…129 Nov 1995  S G Akl  A n optimal algorithm for parallel selection  Inf Process Lett  vol 19 no 1 pp 47…50 Sep 1984  P  Gupta and G P  Bhattacharjee  A parallel selection algorithm BIT  vol 24 no 3 pp 274…287 1984  D A Bader   An impro v ed randomized algorithm for parallel selection with an experimental study J Parallel Distrib Comput  vol 64 no 9 pp 1051…1059 Sep 2004  S Rajasekaran Randomized parallel selection  i n Proceedings of the tenth conference on Foundations of software technology and theoretical computer science  ser FST and TC 10 New York NY USA Springer-Verlag New York Inc 1990 pp 215…224  L Monroe J W endelber ger  and S Michalak Randomized selection on the gpu in Proceedings of the ACM SIGGRAPH Symposium on High Performance Graphics  ser HPG 11 New York NY USA ACM 2011 pp 89…98  T e xas Adv anced Computing Center   T e xas adv anced computing center http://www.tacc.utexas.edu 2006 On A v ailable  http://www.tacc.utexas.edu/user-services user-guides/stampede-user-guide  420 


boiler model and hard constraints [J  E n e r gy 201 1 29   22 39 2251  3  K.L.Lo, Y.Rathamarit  State estimation of a boiler model using the unscented Kalman filter [J  I E T  Gener. Transm. Distrib.2008 2 6\917 931  4  Un Chul Moon, Kwang. Y.Lee. Step resonse model development for dynamic matrix control of a drum type boiler turbine system [J IE E E  T ra nsactions on Energy Conversion.2009 24 2\:423 431  5  Hacene Habbi, Mimoun Zelmat, Belkacem Ould Bouamama. A dynamic fuzzy model for a drum boiler turbine system [J  A u to m a tic a 2 0 0 9 39:1213 1219  6  Beaudreau B C. Identity, entropy and culture J   J o ur na l  o f  economic psychology, 2006, 27\(2 205 223  7  YANG M, CHEN L. Information Technique and the Entropy of Culture J  A cad e m i c E x ch a n g e  2006, 7: 048  8  ZHANG Zhi feng. Research on entropy change model for enterprise system based on dissipative structure J  Ind ustrial  Engineering and  Management 2007, 12\(1\ :15 19  9  LI Zhi qiang, LIU Chun mei Research on the Entropy Change Model for Entrepreneurs' Creative Behavior System Based on Dissipative Structure J  C h i n a S of t S c i e n c e  2009   8  1 62 166   458 


A Global Solution COVERAGE North and South America EMEA and Asia White lines are flights in the masFlight platform from February 8, 2013 Yellow pins are weather stations feeding hour ly data to our platform Maps from Google Earth / masFlight masFlight tracks flights, airports and weather around the world  Global daily flight information capture  82,000 flights  350 airlines  1700 airports  Integrated weather data for 6,000 stations  Match weather to delays  Validate block forecasts at granular level  Add weather analytics to IRROPS review and scenario planning 


Example 1: Proposed FAA Tower Closures masFlight used big-data to link airport operations across three large data sets  Current and historical airline schedules  Raw Aircraft Situation Display to Industry \(ASDI\AA  Enhanced Traffic Management System Counts \(ETMS\Airport operations counts by type \(commercial, freight, etc TOWER CLOSINGS Dots indicate closures; Red dots have scheduled service Based on scheduled service March 1 7, 20 13; scheduled service includes scheduled charter flights, cargo flig hts, and passenger flights Dots  indicate  closures  Red  dots  have  scheduled  service Bas ed  o n sc h edu l ed  se rvi ce  M a r c h 1  7, 2013; scheduled se rvi ce includ es scheduled c harter fli g hts car g o fli g hts a nd passen g er fli g hts Findings: Proposed Tower Closings  From schedules database: 55 airports with scheduled passenger airline service  14 EAS Airports  From ASDI & ETMS: 10,600 weekly flights on a flight plan \(ex. VFR and local traffic  6,500 Part 91/125 weekly flights  4,100 Part 135/121 weekly flights  


Example 1: Big-Data Analytics Applied to ASDI and ETMS To Analyze Operations TOWER CLOSINGS  26 44 24 23 11 10 6 2 1 2 Up to 5 5-10 10-15 15-20 20-25 25-30 30-35 35-40 40-45 45 Count of Airports Average Number of Daily Operations with a Flight Plan Filed Distribution of Airports By Average Number of “Daily” Impacted Flights Airports Affected by Tower Closures Source: ASDI radar data – Part 91 151 flying and Part 135/121 flying March 1-7, 2013; masFlight analysis Note: Average “daily“ operations based on 5-day week 


Example 2: Aviation Safety Causal Factor For example, consider the following ASRS report \(ACN 1031837 Departing IAH in a 737-800 at about 17,000 FT, 11 m iles behind a 737-900 on the Junction departure over CUZZZ Intersection. Smooth air with wind on the nose bearing 275 degrees at 18 KTS We were suddenly in moderate chop which lasted 4 or 5 seconds then stopped and then resumed for another 4 or 5 seconds with a significant amount of ri ght rolling… I selected a max rate climb mode in the FMC in order to climb above the wake and flight path of the leading -900 We asked ATC for the type ahead of us and reported the wake encounter. The 900 was about 3,300 FT higher than we were  Synopsis  B737-800 First Officer reported wake encounter from preceding B737-900 with resultant roll and moderate chop What causal factors can be identified from this narrative that could be applied to future predictive applications CAUSAL FACTORS Data-mining algorithms can mine the text of safety reports to obtain specific data that can be used to analyze causal factors  


Example 2: Identifying Causal Factors CAUSAL FACTORS  Indicators – Data Element Methods – Identifying Context and Causes  Time of day  Date range \(month day  Aircraft type  Fix or coordinates  Originating airport  Destination airport  Weather notes We pinpoint the sequencing of flights on the IAH Junction Seven departure \(at CUZZZ\the specified wind conditions to find cases wher e a B737-900 at 20,000 feet precedes by 11 miles a B737-800 at 17,000 feet  Search related data sets including ASDI flight tracks, local traffic and congestion  Weather conditions for alter native causes \(winds aloft shear and convecti ve activity  Airline specific informati on \(repeated occurrence of event in aircraft type Big data gives us visibility into contextual factors even if specific data points are missing such as a specific date or route Big-data analytics gives us insight into unreported factors as well 


Example 3: Correlating Utilization and Delays  60 65 70 75 80 85 90 95 100 7 9 11 13 ONTIME DEPARTURE PERFORMANCE HOURS OF DAILY UTILIZATION 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Narrowbodies By Day of Week 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Widebodies by Day of Week Daily Utilization vs. On-time Departures January 2013 System Operations Correlation Coefficient -0.53 Includes AA, AC, AS B6 F9, FL, NK, UA, US VX and WN SOURCE masFlight \(masflight.com COMPARING OTP AND UTILIZATION 


 6.2 6.0 5.8 5.8 5.2 4.9 LGB JFK BOS MCO DCA FLL JetBlue Focus Average Daily Deps per Gate Used UTILIZATION BY HUB Example 4: Daily Utilization of Gates, by Hub Big-data analysis of different carriers daily departures per gate used SOURCE masFlight \(masflight.com June 1 through August 31, 2012 Gates with minimum 1x daily use 7.7 7.4 7.2 6.2 6.1 5.8 3.8 3.6 ORD LAX SFO EWR DEN IAH IAD CLE United Airlines Hubs Average Daily Deps per Gate Used 7.8 6.4 5.5 5.4 5.3 4.4 4.3 4.0 SEA SAN PDX ANC SFO GEG LAX SJC Alaska Airlines Hubs Average Daily Deps per Gate Used 7.2 6.9 6.8 6.4 5.0 2.7 ORD DFW LAX LGA MIA JFK American Hubs Average Daily Deps per Gate Used 7.2 6.9 6.6 4.9 4.2 CLT DCA PHL PHX BOS US Airways Hubs Average Daily Deps per Gate Used 6.6 5.9 5.5 4.7 MCO BWI ATL MKE AirTran Hubs Average Daily Deps per Gate Used ne pe 


Conclusions for Big Data in Aviation  Big-data transforms operational and commercial problems that were practically unsolvable using discrete data and on-premises hardware  Big data offers new insight into existing data by centralizing data acquisition and consolidation in the cloud and mining data sets efficiently  There is a rich portfolio of information that can feed aviation data analytics  Flight position, schedules, airport/gate, weather and government data sets offer incredible insight into the underlying causes of aviation inefficiency  Excessive size of each set forces analysts to consider cloud based architectures to store, link and mine the underlying information  When structured, validated and linked these data sources become significantly more compelling for applied research than they are individually  Today’s cloud based technologies offer a solution CONCLUSIONS 


Conclusions:  Our Approach  masFlight’s data warehouse and analysis methods provide a valuable example for others attempting to solve cloud based analytics of aviation data sets  masFlight’s hybrid architecture, consolidating secure data feeds in on-premises server installations and feeding structured data into the cloud for distribution, addresses the unique format, security and scale requirements of the industry  masFlight’s method is well suited for airline performance review competitive benchmarking, airport operations and schedule design and has demonstrated value in addressing real-world problems in airline and airport operations as well as government applications CONCLUSIONS 






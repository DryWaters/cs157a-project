Abstract 
002 002  002 002  
University of Arkansas at Little Rock Little Rock AR USA College of Information Engineering Xiangtan University Xiangtan China vxmartha@ualr.edu wxzhao1@ualr.edu xwxu@ualr.edu 
VenkataSwamy Martha  Weizhong Zhao  Xiaowei Xu 
h-MapReduce A Framework for Workload Balancing in MapReduce 
The big data analytics community has accepted 
 
MapReduce as a programming model for processing massive data on distributed systems such as a Hadoop cluster MapReduce has been evolving to improve its performance We identiìed skewed workload among workers in the MapReduce ecosystem The problem of skewed workload is of serious concern for massive data processing We tackled the workload balancing issue by introducing a hierarchical MapReduce or h-MapReduce for short h-MapReduce identiìes a heavy task by a properly deìned cost function The heavy task is divided into child tasks that are distributed among available workers 
as a new job in MapReduce framework The invocation of new jobs from a task poses several challenges that are addressed by h-MapReduce Our experiments on h-MapReduce proved the performance gain over standard MapReduce for dataintensive algorithms More speciìcally the increase of the performance gain is exponential in terms of the size of the networks In addition to the exponential performance gains our investigations also found a negative effect of deploying hMapReduce due to an inappropriate deìnition of heavy tasks which provides us a guideline for an effective application of h-MapReduce 
Keywords 
I I NTRODUCTION Since its introduction in 2004 by Google MapReduce paradigm has become one of the programming model of choice for processing large data sets MapReduce is a framework for developing a distributed solution for complex problems over huge data sets using a large number of computers nodes collectively referred to as a cluster or a grid Favor from distributed le systems such as HDFS enhanced the framework to improve its efìciency by leveraging 
MapReduce workload balancing hierarchical MapReduce 
data locality awareness Similar to other distributed systems MapReduce also constitutes a master and a set of workers The master is called job tracker while the workers are called task trackers In contrast to traditional distributed programming models 3 2 MapReduce neither provides a shared memory nor a message passing interface To compensate for the lack of communication outputs of some set of tasks called map tasks are passed to other set of tasks called reduce tasks A MapReduce algorithm comprises both map tasks that project given data set called input records into another data set called intermediate records and a Reduce 
Figure 1 Power law degree distribution of a Twitter user-follower network task that combines intermediate records to a desired nal result Therefore the reduce phase does not start until all map tasks are completed In general the Map and Reduce functions divide the data that they operate on for load balancing purposes It is not uncommon for data intensive social network analysis that a map/reduce task works on a vertex or edge The workload of all map/reduce tasks is not uniform as the degree distribution of social networks is skewed Social networks such as 
Twitter user-follower network and Document-Term network follow power law degree distribution which is skewed For instance as it is shown in Figure 1 most of the vertices have a low degree whereas only a very small portion of the vertices have extreme high degrees for a Twitter userfollower network When such netw ork is distrib uted as a set of vertices among map/reduce tasks for vertexbased processing the workload among the mappers is also skewed The mappers that receive a high degree vertex take much longer time to complete than those that receive a low degree vertex However slow or bogged down machines may 
lead to straggler computations within the system that might lead to a longer completion time the completion time is only as fast as the slowest computation If one straggler computation is twice as slow as other computations then the total elapsed time would be twice of that without the straggler computation In such a case a straggler detection and avoidance mechanism becomes necessary In this paper we identiìed skewed workload in distributing tasks among workers in MapReduce ecosystem The problem of skewed workload is of serious concern 
2013 IEEE 27th International Conference on Advanced Information Networking and Applications 1550-445X/13 $26.00 © 2013 IEEE DOI 10.1109/AINA.2013.48 637 


Algorithm 1 
002 002 002 002 002 002 
002 
c N v 
  
v N v v triangles v c d v c N v d N v  c N d d N c and c d triangles v N c N v  v CC v triangles v  N v N v  
                       2            1 2 
key is a vertex  v and value is adjacency list of  v  i.e  N  v   key is a unique term i.e CC value is local CC of vertex  v  1 Let v vertex 2 Let degreeOf v sizeof N  v   3 Let triangleCount=0 4 for each c in N  v   triangleCount+=CountCommonElements N  c   N  v   5 localCC=triangleCount/\(degreeOf v degreeOf v 1 6 emit\(èCCê,localCC key is unique term CC values are local CCs of all vertices of the network key is unique term CC value is average CC of the network 1 Let avgCC=0 2 Let ccCount=0 3 for each oneCC in values avgCC+=oneCC ccCount 4 emit CC avgCC/ccCount  In the Algorithm 1 the function CountCommonElements is computationally costly and called for each vertex in the neighbor list of a vertex The more the neighbors the more the number of calls to the function therefore more the time is required to compute local clustering coefìcient of such high degree vertex There is no guarantee that the degree distribution is uniform In cases where 99 of the vertices are low degree and just 1 of the vertices are high degree compared to low degrees the maps that run mapper 
for massive datasets We address the issue by introducing a hierarchical MapReduce paradigm h-MapReduce Workload balancing in h-MapReduce framework is achieved by splitting the heavy tasks The solution poses several challenges that can be addressed by h-MapReduce Our investigations on h-MapReduce proved the performance beneìts over standard MapReduce for data-intensive algorithms For the demonstration purposes Hadoop is considered as MapReduce ecosystem and Hadoop and MapReduce are referred to interchangeably The rest of the paper is organized as follows We present the skewed workload problem in Section II followed by our proposed solution h-MapReduce in Section III An experimental evaluation of h-MapReduce is presented in Section IV and V We review related work in Section VI Finally we conclude the paper with future work in Section VII II P ROBLEM D ESCRIPTION MapReduce is intelligent in distributing tasks among task trackers by leveraging location aware algorithms A task can be either a map task or a reduce task Each task tracker completes its assigned task The task assignment is carried out by MapReduceês job tracker using speciìed conìguration A task tracker reports progress of the running task and job tracker preempts if it takes longer than conìgured threshold time  referred as timeout There is no mechanism to predict beforehand that a task is heavy for a task tracker that take long time to complete There are two types of long running tasks 1 Tasks that run forever and never complete 2 Tasks that take long time to complete Type 1 tasks encounter due to bugs in algorithm or code Our work primarily focuses on the tasks of type 2 The long running tasks put the job on wait for completion It is a serious concern if there are more such long running tasks Example 1 To illustrate the problem assume a job for computing average clustering coefìcient CC of a network In graph theory a clustering coefìcient is a metric which represents how likely network elements tend to come together to form clusters Triangle is primary building block of clusters in a network and CC measures the density of triangles in a network A triangle is formed when two neighbors of a vertex are themselves neighbors Let  be a vertex and be the neighbor set i.e adjacency list of vertex   The number of links among the neighbors i.e the number of triangles with this vertex is 1 can also be written as 2 The local clustering coefìcient of a vertex in a network is proportion of number of triangles to number of possible triangles in other words it is the number of links between the vertices within its neighbourhood divided by the number of links that could possibly exist between them Having the number of triangles the local clustering coefìcient of the vertex   in an undirected network is computed as 3 Then on the average CC of a network is deìned as average of local clustering coefìcients of all vertices in the network Consider a job to compute average clustering coefìcient in MapReduce framework The input key and values pair for map tasks is the vertex and its neighbors in the adjacency list A map task is to compute local clustering coefìcient of the input vertex which can be performed by obtaining the adjacency lists of its neighbor vertices MapReduce algorithm to compute average clustering coefìcient is presented in Algorithm 1 Algorithm to compute average clustering coefìcient CC of a network 
    002 002 002 002 003    004 005    006   
Mapper Reducer 
Input Output Input Output 
638 


on lower degree vertices complete very quickly and sitting idle to wait for the high degree vertices to complete that actually count just 1 of the network The reduce tasks do not start until all the map tasks complete thus causing long time to complete the job Therefore if the adjacency list of vertices is a skewed distribution like in the case of social networks the task computations are also not balanced One can argue that workload can balanced based on computation cost of a task for a vertex which is computed from the size of its adjacency list The cost function cannot balance the workload in the case of skewed degree distributions such as those of social networks because this cannot change when there is one very less number of high degree vertex\(s In skewed distributions task trackers who work on high degree vertices could have been working while other task trackers are sitting idle after completing corresponding tasks One can observe the problem if the tasks cost function is skewed The fundamental risks from the skewed workload distribution are following Some task trackers are overloaded with heavy tasks Heavily loaded tasks run for long therefore the job waits for this task to complete which in turn increases run time of the job Under-utilization of resources when the heavily loaded task tracker is working and other task trackers are sitting idle There are many such MapReduce algorithms besides computing average clustering coefìcient in a network that encounter the skewed work load distribution issues III H M AP R EDUCE The limitation of MapReduce paradigm prompts us to further split heavy tasks of a job When a task on a record of a map reduce job takes long time or needs more resources than others the task on the record is eligible for further splitting to make use of idle resources in the infrastructure It is trivial to use the existing MapReduce ecosystem for the tasks that split The new tasks run in the same MapReduce framework in the form of a new job and called Child Job The tasks that initiated child jobs refer the tasks as parent tasks wait until the child jobs get completed This way a task of a task tracker is distributed among active and available task trackers if the task is predicted to run for long time The decision whether to distribute a task needed to be taken beforehand the processing a record of the task The task of a heavily loaded task tracker is parallelized to complete the task in reasonable time The parent and child jobs constitute a hierarchy of jobs thus the proposing solution framework is called h-MapReduce short for hierarchical MapReduce Since parent and child jobs run on MapReduce ecosystem both jobs are developed using MapReduce programming model Developers are free to use other distributed systems for child jobs if one exists Parent task sits on hold until its child job gets back with Figure 2 Architecture of h-MapReduce results The framework for the hierarchy of parent and child jobs does not alter the underlying MapReduce ecosystem but leverages it for workload balancing The architectural view of the h-MapReduce framework is presented in Figure 2 The proposed concept of initiating a job from a task of a job is complex and poses several challenges The challenges are addressed in the following discussion h-MapReduce addresses design and development challenges that arise from creating a child job from a task of a MapReduce job The challenges are following The basis of h-MapReduce is to develop a mechanism to draw a line between light-weight tasks and heavy tasks The heavy task deìnition decides when to split a task A cost function of a task helps to draw such a line Cost functions depend on the algorithm and the problem that the algorithm is attempting to address The cost function of a task that computes the clustering coefìcient of a vertex in an undirected network is the degree of the vertex A vertex having degree more than a threshold implies a heavy task and leads to a child job for the vertex from the task As we discussed the existing MapReduce ecosystem is used to parallelize the child job This requires developers to come up with a MapReduce-based algorithm for child jobs To keep things simple the child job needs to be efìciently designed for the MapReduce paradigm The child job works on the record that could cause heavy work load in parent job In our example of computing clustering coefìcients the child job is implemented as a MapReduce algorithm to count the number of triangles associated with the vertex in the parent task With the result from the child job the parent task computes clustering coefìcient of the vertex 
   
A Challenges in h-MapReduce 1 Deìnition of heavy task When to split a task 2 Algorithm for Child Job How to distribute a task 
639 


3 Deadlock 4 Conìguration conîicts A Datasets B Calculating Average Clustering Coefìcient 
It is not uncommon that hierarchical jobs encounter deadlock situations and h-MapReduce is no exception In the case that all the resources i.e all task trackers are occupied by the parent job child jobs sit waiting in queue for available resources The parent job could not vacate the resources until child job complete as tasks in the parent job waits for child jobs This scenario resembles deadlock where there is no progress of jobs because of child job waiting for resources occupied by parent job that waiting for child job to complete Though there are several possibilities to address the deadlock situation a simple approach is presented here that does not disturb the MapReduce ecosystem The simple approach is to reserve speciìed resources i.e set of task trackers for parent jobs and the rest for child jobs This is analogous to a division of one MapReduce ecosystem into two MapReduce ecosystems It is not exactly dividing the ecosystem but reserving resources for dependent jobs so that they should not compete for resources To demonstrate reservations are accomplished in h-MapReduce through the Hadoop Fair Scheduler Two queues are deìned one for parent jobs and aother for child jobs The Fair Scheduler takes necessary steps to prevent competition for resources among two queues and consequently prevents competition between parent and child jobs A conìguration is necessary to initiate a new MapReduce job Each task in a job obtains the conìguration in the MapReduce ecosystem hMapReduce uses the conìguration obtained from the parent job to initiate a new job in a task Since the algorithms for parent and child jobs are different there is a need for different conìguration The conîicts encountered from such inheritance necessitated attention from developers to reset conìguration parameters inherited from the parent job The INPUT SPLIT parameter in the MapReduce conìguration set is the best example that demonstrates the importance of attention paid to conîicts The parent job works on massive input and needs to set a higher value for INPUT SPLIT while child jobs work on a smaller input e.g one adjacency list and require a lower value to best utilize MapReduce resources By addressing these challenges h-MapReduce is able to successfully initiate and complete child jobs from a MapReduce task We investigated the performance of the hMapReduce with standard apache Hadoop the experiments are presented in Section IV IV EXPERIMENTS Several experiments are conducted to analyse the effectiveness of the proposed h-MapReduce in comparison to traditional MapReduce framework We adopted Apache Hadoop as the MapReduce framework and implemented hMapReduce on top of it Two applications are developed on both the Hadoop and h-MapReduce The applications are 1 Compute average clustering coefìcient of a network and 2 Sorting terms of each document in a corpus All the experiments are performed on Hadoop cluster of 2 masters and 24 slaves each with 7 mappers and 7 reducers Each slave has 8 processors and 16GB RAM The experiments include a run using standard Hadoop ecosystem and other with proposed h-MapReduce framework Each experiment run twice and average of the run times is considered The run time for each experiment is noted and plotted in charts for the discussion in the following section Two types of datasets are used to evaluate the hMapReduce framework for undirected networks Each serves a distinct purpose One of them is star shaped networks Star networks are constructed in such way that only a single vertex is connected to every other vertex in the network and there is no other connections The rationale behind choosing this dataset is to nd the gain from h-MapReduce over traditional MapReduce In these datasets we only see a heavy task and rest are light weighted ones Therefore the dataset is good for evaluating the performance in case of one heavy task We generated several star networks of various numbers of vertices from 5,000 to 200,000,000 The other type of datasets is generated using Benchmark network generator The primary use of the dataset is to show the negative effect of the proposed framework with wrong deìnition of heavy task Benchmark networks possess low degree Other characteristics of the benchmark networks include both the degree distribution and the size of community structures follows power law distribution Networks with number of vertices ranging from 10,000 to 160,000 are generated for the purpose The primary objective of the algorithm is to compute average clustering coefìcient of a network MapReduce algorithm for computing average CC of a network is presented in Algorithm 1 Mapper of the algorithm takes a vertex and corresponding adjacency list as key and values The mapper emits vertex   as key and corresponding local clustering coefìcient as value Reducer sums up all the local clustering coefìcients and emits mean of them as value key does not matter here An index mechanism is implemented to retrieve adjacency list of a given vertex The index is distributed on distributed le system and available for all tasks of a MapReduce job Therefore the mappers leverages the index to obtain  and to compute CC  As mentioned in Section II Algorithm 1 is not efìcient when the given network has skewed degree distribution Therefore h-MapReduce strategy is applied to address the workload balancing problem More speciìcally h-MapReduce splits the task which is heavy loaded by introducing a new MapReduce job In our experiments we 
v N v N c N d v 
      
640 


v v N v v v v N v v v N v c N v N c N v v v w w N v v w u N w u w v v w w 
002 
countTrianglesInChildJob 
Mapper Reducer Mapper Reducer 
                
N v  N v  v w w v v v w v v w v w w v v w w v v v 
  5000 5000   5000 
key is a vertex  and value is adjacency list of   i.e   key is a unique term i.e CC value is local CC of vertex   1 Let vertex 2 Let degreeOf sizeof  3 if\(degreeOf 5000 triangleCount  countTrianglesInChildJob   4 else Let triangleCount=0 for each in  triangleCount+=CountCommonElements   5 localCC=triangleCount/\(degreeOf degreeOf 1 6 emit\(èCCê,localCC key is unique term CC values are local CCs of all vertices of the network key is unique term CC value is average CC of the network 1 Let avgCC=0 2 Let ccCount=0 3 for each oneCC in values avgCC+=oneCC ccCount 4 emit CC avgCC/ccCount  Expensive operation in the algorithm 1 is counting number of triangles associated with a vertex that is reduced in hMapReduce paradigm by introducing a new MapReduce job for the purpose In algorithm 2 a child job is initiated if the given vertex has high degree The function key is vertex   where key is vertex value is distance from   1 Let vertex 2 for each in  emit 2 3 emit 1 key is vertex value is distances from   key is vertex value is number of triangles with   and this vertex 1 Let  vertex nTriangles=0 isTriangle  false 2 for each distance in values if distance  1 isTriangle  true if distance  2 nTriangles 3 if isTriangle  emit  nTriangles  distance to reach the vertex  
deìne a heavy task if and the heavy task is to compute clustering coefìcient of a high degree vertex The rationale in choosing is that our investigations found the computation time for vertices with is lesser than Hadoop job setup and cleanup times The h-MapReduce paradigm based algorithm for computing average CC is summarized in Algorithm 2 Algorithm to compute average clustering coefìcient CC of a network using h-MapReduce Parent Job takes the neighbor list and passes the list as input to child job to run the algoirthm 3 The child job receives adjacency list as input and counts the number of triangles with each vertex in the adjacency list of   A MapReduce algorithm for child job is developed and presented in Algorithm 3 A mapper of the child job takes a vertex   as input value We deìne distance of a vertex say   as number of hops needed for it to reach the vertex   for which the child job is invoked A vertex in adjacency list of  isat distance 1 and they can reach   in one hop A mapper in child job nds neighbors of the vertex   and emits its Algorithm to count number of triangles associated with a vertex   MapReduce Algorithm for Child Job  i.e distance of 2 as value Alternately each vertex in adjacency list of   can reach   in 2 hops through   The mapper also emits the vertices with distance 1 i.e   with distance 1 Reducer of the child job receives a vertex as a key and corresponding distances as values For a vertex if there is a value of 1 then this vertex has direct edge with   and all the distances of 2 corresponds to triangles Therefore the number of triangles associated with the vertex   and with the vertex  is number of distances of 2 if there is at least a distance of 1 By the end of the reducer we have a vertex   in adjacency list of   and corresponding count of triangles The owchart of the algorithm is presented in Figure IV-B For performance improvement the reducer emits a record for each triangle i.e for each value of distance 2 The number of triangles with vertex   in a task from parent job is number of output records from child job The clustering coefìcient of   is computed using the obtained values and the Eq 3 Therefore a task of a mapper is distributed among available task trackers in MapReduce ecosystem For star shaped networks we deìne a heavy task if a mapper gets a vertex of degree over 5,000 The h-MapReduce framework computed average clustering coefìcient faster than traditional MapReduce A discussion on run time is presented in following section It is obvious that a local clustering coefìcient of a vertex with only 100 edges can be computed by a task for which no child task is necessary To 
Input Output Input Output Input Output Input Output 
Algorithm 2 Algorithm 3 
641 


Sorting terms of each document in a corpus is another case study of the h-MapReduce Assume there is a bi-partite document-term network One type of vertices in the network is documents and other is terms one or more words A document is connected to several terms which occurred in the document There are many such documents and terms Now the task is to sort the terms in lexicographic order in each document In other words to sort adjacency list of each document vertex in the document-term network Sorting terms can be applied in many real world applications such as information retrieval If there is only a document a fast algorithm can be developed on MapReduce ecosystem The algorithm can be extended to sort terms of more than one document in a corpus Each mapper takes a document and sorts its terms Input for a mapper is document identiìer as key and containing terms as value Mapper sorts the terms and emits document identiìer as key and sorted terms as value There is no need for reducer But if there is a document that contains tens of thousands of terms the mapper that processes the document i.e sorts its terms takes a long time because the number of terms are more than a mapper can handle h-Mapreduce comes again to rescue when a map task is too heavy Though there are techniques for external sorting to deploy in a map task they do not scale for millions of items MapReduce found its efìcacy in sorting of given keys Taking the advantage h-MapReduce framework distributes the task of sorting among MapReduce task trackers as a new job As a default operation MapReduce outputs keys in sorted order The terms of a document is given as input keys for a MapReduce job and output obtained from identity mapper and identity reducer is sorted list of terms Figure 4 Running time for calculating average CC of star networks Investigation on this algorithm is also carried out on star network datasets As discussed the star networks show ne detailed gain of the proposed h-MapReduce over standard MapReduce for one heavy task The analogy of documentterm layout with star network is that the center vertex is a document and other vertices are terms For this algorithm we deìne a heavy task that sorts the terms of a document with more than 10,000 terms because similar to other application the time to sort terms less than 10,000 is less than a Hadoop job setup and cleanup times V RESULTS AND DISCUSSION The results from the experiments evidenced the efìcacy of h-MapReduce over standard Hadoop The running time from each experiment is recorded for comparison The size of the datasets is increased for repeated experiments Run time for computing average CC of a network using standard MapReduce and the proposed h-MapReduce framework is recorded The recorded running time is plotted in Figure 4 The run time curve that represents standard MapReduce grows exponentially which indicates the effect of lack of workload balancing The plot in Figure 4 also reveals the effect of heavy task in Hadoop that slow down the computation The speedup measures the gain of h-MapReduce which is deìned as follows Runtime without h-MapReduce Runtime with h-MapReduce 4 The speedup by using h-MapReduce in comparison with standard MapReduce ecosystem increases as the network size increases The plot showing the speedup for each network is pictured in Figure 5 The increase in speedup is signiìcantly large with increasing size of the networks which further justiìes the need of h-MapReduce The plots also demonstrate a signiìcant performance improvement over the standard MapReduce ecosystem 
C Sorting terms of each document in a corpus A Runtime analysis in calculating clustering coefìcient 
Speedup 
 
Figure 3 Flowchart for computing average Clustering Coefìcient show the adverse effect of the proposed framework with a wrong deìnition of heavy task a heavy task is deìned with the degree over 100 Benchmark datasets are used for the purpose of showing negative effect of h-MapReduce The result is presented in Section V 
642 


Figure 6 shows the plot of the running time for sorting terms in each document in a corpus represented as bipartite document-term networks From the plot it is observed that the run time by using h-MapReduce is longer for smaller networks and as the network size grows the run time becomes much less in comparison A longer run time for smaller networks suggests that h-MapReduce is not suitable for smaller datasets The speedup of h-MapReduce over Hadoop increases as the network grows which indicates that h-MapReduce is more appropriate for data intensive tasks Figure 7 shows the speedup of h-MapReduce over the standard MapReduce h-MapReduce has its limitations with its dependency on deìnition of heavy task The efìciency of h-MapReduce Figure 8 Run time for calculating average CC for benchmark networks shows an adverse effect highly depends on the decision to split a task Here negative effect of the h-MapReduce is presented which encountered by an inappropriate deìnition of heavy task For the purpose we deìne a heavy task for computing clustering coefìcient as a task that receives a vertex with more than 100 adjacent vertices Benchmark networks are used for this experiment as it contains more vertices of various degrees We generated benchmark networks in such a way that the network degrees range is minimal The run time for computing average CC for each benchmark network is plotted in Figure 8 For the benchmark networks using h-MapReduce took more time than standard MapReduce ecosystems The reasons for the adverse effect is due to the following reasons A heavy task using a child job takes more time than it runs in the parent task Creating a child job is not free the child job setup and cleanup adds more time There are many heavy tasks that do not have enough resources task trackers to run child jobs The adverse effect of h-MapReduce indicates the importance of a proper deìnition of heavy tasks In practice we should only use h-MapReduce for really big data where a skewed workload distribution is a great concern VI RELATED WORK In this section we review existing solutions for optimizing Hadoop  MapReduce performance Zhang and Sterck developed a system called CloudBATCH to enable Hadoop to function as a traditional batch job queuing system with enhanced management functionalities for cluster resource management CloudB A TCH constitutes of a set of HBase  tables that are used for storing resource management information such as user credentials queue and job information which provide the basis for rich customized management functionalities Elnikety et al proposed iHadoop an add on for the MapReduce framework optimized for iterative applications that exhibit a producer/consumer relation of consecutive iterations on the same physical node where the cost of inter-iteration data transfer is minimal Besides iHadoop Zhang et al proposed iMapReduce that extracts the common features of iterative MapReduce algorithms and 
B Runtime analysis for sorting terms in a document C Limitation of h-MapReduce 
Figure 5 Speedup of h-MapReduce for calculating average CC of star networks Figure 6 Run time for sorting terms in document-term networks Figure 7 Speedup of h-MapReduce for sorting terms in document-term networks 
   
643 


Table I E VOLUTION OF H ADOOP PERFORMANCE TUNING System Level of Scheduling Scheduling Technique Hadoop Task Naive Speculative  Mantri  and StarFish[13 Task Resource based skewT and ske Record Overload based h-MapReduce instructions in a task for a Record Cost function based provides the built-in support for these features Speculative execution is proposed to enhance Hadoop framework in heterogeneous infrastructure to reschedule straggling tasks on available other work In addition there resource based schedulers attempt to uniformly distribute the load among tasks such as and Mantri[12 In all the MapReduce based frameworks it is assumed that all the map and the reduce tasks are uniformly loaded which may not be true as it is demonstrated for social networks such as Twitter shown in section I In contrast to the traditional way of assuming a task an atomic there are techniques to repartition the tasks when found SkewTune aggressively repartitions the input data for a task so that the task do not run longer than the other tasks Similar to SkewTune SkewReduce partitions the input records to address the skewed workload distribution based on user-deìne cost In contrast h-MapReduce distributes a task for a record among available task trackers so to avoid straggling To summarize h-MapReduce complements existing performance tuning techniques The evolution in Hadoop performance tuning techniques at various levels are compiled in Table VI VII C ONCLUSION MapReduce is a pervasive programming model for big data analysis Despite of its intelligent scheduling techniques we identiìed skewed workload in distributing tasks among workers in MapReduce ecosystem The problem of skewed workload is of serious concern for massive datasets h-MapReduce built on top of MapReduce is proposed in this work to address the lack of workload balancing in MapReduce ecosystem Workload balancing in h-MapReduce is achieved by splitting heavy tasks The solution poses several challenges such as deadlocks inheritance conîicts etc h-MapReduce addresses these challenges Our experiments using various networks including social networks and document-term networks demonstrated the speedup of using h-MapReduce over standard MapReduce for big datasets where skewed workload is a great concern The investigations also found the negative effect of h-MapReduce with a feeble deìnition of heavy tasks Our future work will explore additional opportunities to further improve the performance of h-MapReduce A CKNOWLEDGMENT This project was funded by Acxiom Corporation The authors are grateful for invaluable collaboration with Kevin Liles and Derek Leonard throughout the project This work was supported in part by the National Science Foundation under Grant CRI CNS-0855248 EPS-0701890 EPS0918970 MRI CNS-0619069 OISE-0729792 and the National Natural Science Foundation of China No 61105052 R EFERENCES  Gropp W  Lusk E  The MPI communication library its design and a portable implementation Scalable Parallel Libraries Conference 1993 pp.160-165 6-8 Oct 1993  B Lampson Remote Procedure Calls LNCS V ol 105 Springer-Verlag New York 1981 pp 365-370  G R Andre ws and F  B Schneider  Concepts and Notations for Concurrent Programming ACM Computing Surveys Vol 15 No 1 Mar 1983 pp 3-43  Dean Jef fre y  and Sanjay Ghema w at MapReduce  Simpliìed Data Processing on Large Clusters Ed L Purich Daniel Communications of the ACM 51.1 2008  1-13  Hae w oon Kw ak Changhyun Lee Hosung P ark and Sue Moon What is Twitter a Social Network or a News Media WWW 2010 April 2630 2010  C Zhang H Sterck CloudB A TCH A Batch Job Queuing System on Clouds with Hadoop and HBase IEEE Conference on Cloud Computing Technology and Science 368-375 2010  Lancichinetti Andrea Santo F ortunato and Filippo Radicchi Benchmark graphs for testing community detection algorithms Physical Review E Statistical Nonlinear and Soft Matter Physics 78.4 Pt 2 2008  E Elnik ety  T  Elsayed H Ramadan iHadoop Asynchronous Iterations for MapReduce 3rd IEEE Intêl Conference on Cloud Computing Technology and Science pages 81-90 2011  Y  Zhang Q Gao L Gao C W ang iMapReduce A Distrib uted Computing Framework for Iterative Computation J Grid Computing 10:47-68 2012  HBase http://hadoop.apache.or g/hbase  Zaharia Matei and K onwinski Andy and Joseph Anthon y D and Katz Randy and Stoica Ion Improving MapReduce performance in heterogeneous environments 8th USENIX conference on OSDI pp.29-42 2008  Ganesh Ananthanarayanan Srikanth Kandula Albert Greenberg Ion Stoica Yi Lu Bikas Saha and Edward Harris 2010 Reining in the outliers in map-reduce clusters using Mantri 9th USENIX conference on OSDI pp 1-16  Herodotos Herodotou and Harold Lim and Gang Luo and Nedyalko Borisov and Liang Dong and Fatma Bilgen Cetin and Shivnath Babu Starìsh A Self-tuning System for Big Data Analytics CIDR 2011 pp 261-272  Y ongChul Kw on Magdalena Balazinska Bill Ho we and Jerome Rolia 2012 SkewTune mitigating skew in mapreduce applications In Proceedings of the 2012 ACM SIGMOD ACM New York NY USA pp 25-36  Y ongChul Kw on Magdalena Balazinska Bill Ho we and Jerome Rolia 2010 Skew-resistant parallel processing of feature-extracting scientiìc user-deìned functions 1st ACM symposium on Cloud computing SoCC 10 pp 75-86 
644 


Dissimilarity Features in Recommender Systems 825 Christos Zigkolis, Savvas Karagiannidis, and Athena Vakali Fourth IEEE Workshop on Privacy Aspects of Data Mining \(PADM 2013 Differentially Private Anomaly Detection with a Case Study on Epidemic Outbreak Detection 833 Liyue Fan and Li Xiong A Semi-Supervised Learning Approach to Differential Privacy 841 Geetha Jagannathan, Claire Monteleoni, and Krishnan Pillaipakkamnatt The Independence of Fairness-Aware Classifiers 849 Toshihiro Kamishima, Shotaro Akaho, Hideki Asoh, and Jun Sakuma Incentive-Compatible Privacy-Preserving Distributed Data Mining 859 Murat Kantarcioglu Privacy-Preserving Kernel k-Means Outsourcing with Randomized Kernels 860 Keng-Pei Lin Select-Organize-Anonymize: A Framework for Trajectory Data Anonymization 867 Giorgos Poulis, Spiros Skiadopoulos, Grigorios Loukides, and Aris Gkoulala-Divanis Data Anonymity Meets Non-discrimination 875 Salvatore Ruggieri Privacy Preserving Social Network Publication against Mutual Friend Attacks 883 Chongjing Sun, Philip S. Yu, Xiangnan Kong, and Yan Fu Adaptive Differentially Private Data Release for Data Sharing and Data Mining 891 Li Xiong Sentiment Elicitation from Natural Text for Information Retrieval and Extraction \(SENTIRE Enhancing Sentiment Classification Performance Using Bi-Tagged Phrases 892 Basant Agarwal, Namita Mittal, and Erik Cambria Dynamic Construction of Dictionaries for Sentiment Classification 896 Hanen Ameur and Salma Jamoussi Multi-Class Sentiment Analysis with Clustering and Score Representation 904 Mohsen Farhadloo and Erik Rolland Robust Language Learning Via Efficient Budgeted Online Algorithms 913 Simone Filice, Giuseppe Castellucci, Danilo Croce, and Roberto Basili Pattern-Based Topic Models for Information Filtering 921 Yang Gao, Yue Xu, and Yuefeng Li Interest Analysis Using Semantic PageRank and Social Interaction Content 929 Chung-Chi Huang and Lun-Wei Ku Joint and Pipeline Probabilistic Models for Fine-Grained Sentiment Analysis: Extracting Aspects, Subjective Phrases and their Relations 937 Roman Klinger and Philipp Cimiano 
xiii 
xiii 


Learning the Roles of Directional Expressions and Domain Concepts in Financial News Analysis 945 Pekka Malo, Ankur Sinha, Pyry Takala, Oskar Ahlgren, and Iivari Lappalainen A Framework of Review Analysis for Enhancement of Business Decision Making 955 Atika Qazi, Ram Gopal Raj, Muhammad Tahir, and Syed Ghaour Abbas Naqvi Sentiment Analysis in News Articles Using Sentic Computing 959 Prashant Raina Interpreting or Describing? Measuring Verb Abstraction 963 Dominika Rogozi ska and Aleksander Wawer Possible Usage of Sentiment Analysis for Calculating Vectors of Felific Calculus 967 Rafal Rzepka and Kenji Araki Subjective Bayes Method for Word Semantic Similarity Measurement 971 Junhua Wang, Xianglin Zuo, Wanli Zuo, and Tao Peng Eighth International Workshop on Spatial and Spatio-Temporal Data Mining SSTDM Qualitative Spatial Structure in Complex Areal Objects Using Location-Free, Mobile Geosensor Networks 978 Alan Both and Matt Duckham A Novel Approach to Trajectory Analysis Using String Matching and Clustering 986 Madhuri Debnath, Praveen Kumar Tripathi, and Ramez Elmasri Severe Hail Prediction within a Spatiotemporal Relational Data Mining Framework 994 David John Gagne II, Amy McGovern, Jerald Brotzge, and Ming Xue Blazing Fast Time Series Segmentation Based on Update Techniques for Polynomial Approximations 1002 AndrÈ Gensler, Thiemo Gruber, and Bernhard Sick DLOREAN: Dynamic Location-Aware Reconstruction of Multiway Networks 1012 Fredrik Johansson, Vinay Jethava, and Devdatt Dubhashi Mining Semantic Time Period Similarity in Spatio-Temporal Climate Data 1020 Michael P. McGuire and Ziying Tang An Integer Programming Approach to Temporal Pattern Matching Queries 1028 Megan Monroe and Amol Deshpande Analyzing the Proximity and Interactions of Friends in Communities in Gowalla 1036 Tommy Nguyen, Mingming Chen, and Boleslaw K. Szymanski 4D+SNN: A Spatio-Temporal Density-Based Clustering Approach with 4D Similarity 1045 Ricardo Oliveira, Maribel Yasmina Santos, and Jo„o Moura Pires Multi-sensor Remote Sensing Image Change Detection: An Evaluation of Similarity Measures 1053 Karthik Ganesan Pillai and Ranga R. Vatsavai New Spatiotemporal Clustering Algorithms and their Applications to Ozone Pollution 1061 Sujing Wang, Tianxing Cai, and Christoph F. Eick 
xiv 
xiv 


The Passenger Demand Prediction Model on Bus Networks 1069 Chunjie Zhou, Pengfei Dai, and Renpu Li Demo Papers SaferCity: A System for Detecting and Analyzing Incidents from Social Media 1077 Michele Berlingerio, Francesco Calabrese, Giusy Di Lorenzo, Xiaowen Dong, Yiannis Gkoufas and Dimitrios Mavroeidis The MiningZinc Framework for Constraint-Based Itemset Mining 1081 Tias Guns, Anton Dries, Guido Tack, Siegfried Nijssen, and Luc De Raedt Demand Finder: Set Top Box Television Ad Targeting Using a Novel Interactive Data Visualization System 1085 Brendan Kitts, Dyng Au, Brian Burdick, Jon Borchardt, Amanda Powter, and Todd Otis An Evaluation Framework for Temporal Subspace Clustering Approaches 1089 Hardy Kremer, Stephan G¸nnemann, Arne Held, and Thomas Seidl Interactive Data Analysis Tool by Augmenting MATLAB with Semantic Objects 1093 Changhyun Lee, Jaegul Choo, Duen Horng \(Polo Demonstrating Interactive Multi-Resolution Large Graph Exploration 1097 Zhiyuan Lin, Nan Cao, Hanghang Tong, Fei Wang, U. Kang, and Duen Horng \(Polo NIM: Scalable Distributed Stream Process System on Mobile Network Data 1101 Lujia Pan, Jianfeng Qian, Caifeng He, Wei Fan, Cheng He, and Fan Yang PhD Forum A Multi Density-Based Clustering Algorithm for Data Stream with Noise 1105 Amineh Amini, Hadi Saboohi, and Teh Ying Wah MapReduce Based Frameworks for Classifying Evolving Data Stream 1113 Ahsanul Haque and Latifur Khan Time-Sensitive Route Planning Using Location-Based Data 1121 Hsun-Ping Hsieh, Cheng-Te Li, and Shou-De Lin Mining Discrete Patterns via Binary Matrix Factorization 1129 Peng Jiang and Michael T. Heath Mining Adverse Drug Reactions from Electronic Health Records 1137 Henry Z. Lo, Wei Ding, and Zohreh Nazeri Quantification of Financial News for Economic Surveys 1141 Mihail Minev Local Discriminative Distance Metrics and their Real World Applications 1145 Yang Mu and Wei Ding Host-Based Anomaly Detection Using Learning Techniques 1153 Ahmad Mustafa, Mohiuddin Solaimani, Latifur Khan, Ken Chiang, and Joe Ingram Rapidly Labeling and Tracking Dynamically Evolving Concepts in Data Streams 1161 Brandon S. Parker and Latifur Khan 
xv 
xv 


Author Index 1165 
xvi 
xvi 


Copyright © 2009 Boeing. All rights reserved  Historical Data Processing To load correlated data  Uncompress, unmarshall  Create a list of files containing the correlated data  Write data to warehouse 


Copyright © 2009 Boeing. All rights reserved  Live Data Processing Processed using IBM MQ IBM Message Broker and a technique called XML Shredding Message Broker Compute Nodes  Uncompress Node  Extract correlated messages  Shred Node adds to DB Stored Procedure ìshreds XML docs and adds to tables 


Copyright © 2009 Boeing. All rights reserved  Issues and Observations Initial load of one day of data ~ 7 hours Optimizations  Write data in batches  Use a mutable data structure to create data strings  Deploy a higher performance machine  Use load instead of insert  Use DB2 Range-Partitioned tables  Database tunings Time reduced from 7 hours to approx 30 minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Use a mutable data structure to create data strings  Original application created the SQL statement by appending elements to a Java String  It was taking five hours \(of the seven hours Strings  Instead Java StringBuilder used  Java Strings immutable  Time savings of 71.4 


Copyright © 2009 Boeing. All rights reserved  Optimizations Deployed on a higher-performance machine  Application ported from IBM Blade Center HS21 \(4GB of RAM and 64-bit dual-core Xeon 5130 processor to Dell M4500 computer \(4GB of RAM and 64-bit of quad-core Intel Core i7 processor  Reduced the time to thirty minutes Bulk loading instead of insert  Application was modified to write CSV files for each table  Entire day worth of data bulk loaded  Reduced the time to fifteen minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Range-Partitioned tables \(RPT  To limit the size of tables, the original code created multiple tables per table type  This puts burden on the application to query multiple tables when a range crosses several tables  With RPT, user is not required to make multiple queries when a range crosses a table boundary  Increased the time to thirty minutes  Additional fifteen minute cost per day of partitioning enabled time savings during queries 


Copyright © 2009 Boeing. All rights reserved  Optimizations Database tunings  Range periods changed from a week to a month  Automatic table space resizing changed from 32MB to 512KB  Buffer pool size decreased  Decreased the time to twenty minutes Overall, total time savings of 95.2 


Copyright © 2009 Boeing. All rights reserved  20 IBM Confidential Analytics Landscape Degree of Complexity Competitive Advantage Standard Reporting Ad hoc reporting Query/drill down Alerts Simulation Forecasting Predictive modeling Optimization What exactly is the problem What will happen next if What if these trends continue What could happen What actions are needed How many, how often, where What happened Stochastic Optimization Based on: Competing on Analytics, Davenport and Harris, 2007 Descriptive Prescriptive Predictive How can we achieve the best outcome How can we achieve the best outcome including the effects of variability Used with permission of IBM 


Copyright © 2009 Boeing. All rights reserved Initial Analysis Activities Flights departing or arriving on a date Flights departing or arriving within a date and time range Flights between city pair A,B Flights between a list of city pairs Flights passing through a volume on a date. \(sector, center, etc boundary Flights passing through a volume within a date and time range Flights passing through an airspace volume in n-minute intervals All x-type aircraft departing or arriving on a date Flights departing or arriving on a date between city pair A,B Flights departing or arriving on a date between a list of city pairs Flights passing through a named fix, airway, center, or sector Filed Flight plans for any of the above Actual departure, arrival times and actual track reports for any of the above 


Copyright © 2009 Boeing. All rights reserved  Initial SPSS Applications Show all tracks by call sign 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case For a given Airspace Volume of Interest \(AVOI compute distinct traffic volume at some point in the future  Aim to alert on congestion due to flow control areas or weather if certain thresholds are exceeded  Prescribe solution \(if certain thresholds are exceeded Propose alternate flight paths  Use pre-built predictive model  SPSS Modeler performs data processing Counts relevant records in the database \(pattern discovery Computes traffic volume using statistical models on descriptive pattern Returns prediction with likelihood 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  24 Pulls in the TRACKINFO table of MAIN using SQL Limits the data to database entries which fall inside the AVOI Combines the SOURCE_DATE and SOURCE_TIME to a timestamp that can be understood by modeler Computes which time interval the database entry falls in. The time interval is 15 minutes Defines the target and input fields needed for creating the model Handles the creation of the model Produces a graph based off of the model results Final prediction 


Copyright © 2009 Boeing. All rights reserved  Initial Cognos BI Applications IBM Cognos Report Studio  Web application for creating reports  Can be tailored by date range, aircraft id, departure/arrival airport etc  Reports are available with links to visuals IBM Framework Manager  Used to create the data package  Meta-data modeling tool  Users can define data sources, and relationships among them Models can be exported to a package for use with Report Studio 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 1 of 3 Report shows the departure date, departure and arrival locations and hyperlinks to Google Map images DeparturePosition and ArrivalPosition are calculated data items formatted for use with Google Maps Map hyperlinks are also calculated based on the type of fix 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 2 of 3 DeparturePosition, Departure Map, ArrivalPosition and Arrival Map are calculated data items \(see departure items below DepartureLatitude DepartureLongitude DeparturePosition Departure Map 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 3 of 3 


Copyright © 2009 Boeing. All rights reserved  Conclusion and Next Steps Current archive is 50 billion records and growing  Approximately 34 million elements per day  1GB/day Sheer volume of raw surveillance data makes analytics process very difficult The raw data runs through a series of processes before it can be used for analytics Next Steps  Continue application of predictive and prescriptive analytics  Big data visualization 


Copyright © 2009 Boeing. All rights reserved  Questions and Comments Paul Comitz Boeing Research & Technology Chantilly, VA, 20151 office Paul.Comitz@boeing.com 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  31 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  32 Backup Slides 


Copyright © 2009 Boeing. All rights reserved  Initial Approach Initial Investigations  Apache Solr/Lucene  Data Warehouse Evaluate Hadoop in the future 


Copyright © 2009 Boeing. All rights reserved  Using SOLR Uncompress Track Information Messages To use with Solr  Transforming track messages from their  original schema to Solr required building a ìkey, valueî list using an XSTL  Queries made against this list of ìkey, valueî pairs Transformation Process  One day of data ~ 4.5 hours Once transformation complete search/query performance very good Geo spatial queries using  unique query language 


Copyright © 2009 Boeing. All rights reserved  Representation Aviation data is frequently represented in more than one form 



Abstract Keywords- Big data; Spatial data mining; Data intelligence 
In this paper, spatial data mining is presented in the context of big data.  Spatial data plays a primary role in big data attracting human interests. Spatial data mining confronts much difficulty when attracting the value hidden in spatial big data The techniques to discover knowledge from spatial big data may help data to become intelligent 
 Shuliang WANG   Hanning YUAN School of Software Beijing Institute of Technology 5 South Zhongguancun Street, Haidian District, Beijing, 100081, P. R. China Email: slwang2011 bit.edu.cn yhn6@bit.edu.cn    
Spatial Data Mining in the Context of Big Data 
 
I 
 
 S PATIALLY DISTRIBUTED BIG DATA  Big data is complex data set that has the following main characteristics: Volume, Variety, Velocity and Veracity 1 2 3  These make it difficult to use the existing tools to manage and manipulate  In these data, spatial data specifically accounts for the vast majority. About 80% of data is associated with the spatial position 6 Spatial data is the basis of data and source of wisdom for people to understand the real-world through the information world 7. Big Data is closely related to applications 
11 and spatial data mining is its principal application  9-1  Big data centers data, and mines knowledge in the entire data, breaking the sampling randomness of the sample 1 and demonstrating on big data center and mobile terminal. These information technologies serve for the understanding and transforming of the real world.  Big data is attracting much attention, for example, the United Nations, the United States the Peopleês Republic of China, Science, Nature, the Wall Street Journal, Gartner, McKinsey, Microsoft, IBM, Oracle Google, and Baidu 1-5 6-2    
A 
The content of spatial data describes spatial objectsê specific geographic orientation and spatial distribution in the real world Spatial data also includes space entities attributes, the number location, and their mutual relations, and covers the entire Macro-Meso-Micro level. The data can be the value of point height, road length, polygon area, building volume and the pixel gray. It can be the string of geographical name and annotation. It can also be graphics, images, other multimedia spatial relationships and other topologies  8  Compared with the General data, spatial data is with characteristics of spatial temporal, multi-dimensional, Volume, complex spatial 
Spatial data is the basis for big data 
relations and so on 1 For the tools of collecting spatial data, it can be macro and micro sensors or devices such as radar, infrared, optical satellite multispectral scanner, digital camera, imaging spectrometer, electronic total station, telescopes, television camera, electron microscopy imaging and CT imaging. It can be spatial data acquisition means such as conventional field measurements, census, land resources survey, map scanning map digitizing and statistics charts. It also can be a process of technology applications and analysis spatial data, such as computers, networks, GPS, RS and GIS. The concrete content includes data sources, the original observations \(raw data\, as 
well as steps, format conversion, date, time, location personnel, environmental, transmission and history of data collecting, editing, storage and using 21-3  The remote sensing Earth observation has become an indispensable part of social 24. Spatial sensors, satellite launch, satellite control and other hardware technology has made a major breakthrough. In the future, space-based information systems and Earth Observing System \(EOS\will try to establish the ability to get a variety of spatial data realtime and around-the-clock. Moreover it will gradually forms the satellite \(group\ of EOS: set of high spatial, high spectral high temporal resolution, wide ground covered and other 
performance, along with positioning, communications and observation functions \(Fig. 1, Fig. 2\. The rapid development of sensors also makes the number of bands that describing the space object attributes increase from a few to dozens or even hundreds. Remote sensing Earth observation technologies are supporting a multi-level, multi-angled, all-round and aroundthe-clock global stereoscopic earth observation network which combines with high, medium and low orbits and cooperates with large, medium and small satellite, and coarse, fine resolution complement to each other. The range of ground resolution magnitude of the sensor is from kilometers to centimeters. The range of wavelength is from ultraviolet to 
long wave. The interval is from ten days once to three times a day. The range of probing depth is from a few meters to ten thousand meters. Quick Bird, IRS, IKONOS have provided high resolution remotely-sensed data through new remote sensing earth observation technology marked by high spatial high spectral and high dynamic. Earth observation system with multi-sensor, multi-purpose, multi-resolution and multifrequency can provide Moderate-resolution Imaging Spectroradiometer \(MODIS\ data, ASTER infrared-imagecontained data, CERES model data coming from clouds measuring and 4-D simulating, MOPIT data and MISR data New satellite sensors with high-resolution and high dynamic 
2013 19th IEEE International Conference on Parallel and Distributed Systems 1521-9097/13 $31.00 © 2013 IEEE DOI 10.1109/.87 486 
2013 19th IEEE International Conference on Parallel and Distributed Systems 1521-9097/13 $31.00 © 2013 IEEE DOI 10.1109/.87 486 
2013 19th IEEE International Conference on Parallel and Distributed Systems 1521-9097/13 $31.00 © 2013 IEEE DOI 10.1109/.87 486 
2013 International Conference on Parallel and Distributed Systems 1521-9097/13 $31.00 © 2013 IEEE DOI 10.1109/ICPADS.2013.88 486 


Satellite-based earth observation network   Figure 2 Satellite data and services   data infrastructure f space-based data contained a large b ase, road network of urban planning database, en g database, current land use information database, regulat o municipal red line database, ar c line database, cadaster databas e planning database. Furthermo r day can reach terabyte level data global coverage every two c ades of history data arou n d the   g ineering geological information database, strategic planning o ry detailed planning database c hitectural columns and building e s and basic farmland protection r e, in addition to those already 
  
are not only high dynamicb and numb e resolution, high data rate, short period, b u large amount of data which can reach giga b For example, the space remote sensing d a  F i   The speed of the construction of spatial is increasing, as well as the accumulation o f  Spatial data infrastructure has already number of cities in the electronic map data b e r, high spectral u t also particularly b i t level or above a ta obtai n ed from EOS-AM1 and PM1 in one Landsat can get satellite image weeks, and there has been de c world accumulated 1-3   i gure 1 
487 
487 
487 
487 


 
B Spatial data is the focus of the research and development big data 
 
stored and accumulated data, new spatial data are being generated and collected  The research and development of big data involve national security, life and health, climate variation, geological survey disaster prevention and reduction and Smart Planet, which are all associated with spatial data 1   For example, in the United States, government established National Information Infrastructure in 1993, released National Broadband Plan in 2010, and invested 200 million dollars to start Big Data Research and Development Initiative. In this plan, US Geological Survey and National Aeronautics & Space Administration are most closely associated to spatial data    The USGS John Wesley Powell Center for Analysis and Synthesis provides scientists with the place and time to indepth analysis, the most advanced computing ability and the collaboration tools to perceive big data sets, which eventually promotes the innovation thinking of the Earth System Science ESS\ In this center, scientists cooperate to synthesize the comprehensive and long-term data, and further convert big data and the big ideas of Earth science theory to scientific discoveries with the aim to improve the understanding of the ESS and response capabilities. For example, species respond to climate change, earthquake recurrence rate and the next generation of ecological indicators NASA uses advanced information systems to mature big data capacity in order to support future Earth observation missions. Firstly, the Earth information can be identified by NASA Climate Center. Secondly, it can further reduce the risk cost, size and development time of space-based and groundbased information system in the Earth Sciences Department Finally, it can also improve the accessibility and practicality of scientific data. NASA Earth science data and information system project has been active for more than 15 years. This project aimed at archiving, processing and publishing Earth satellite data, air and ground truth data, in order to ensure that scientists and the public can access data from the Earth into space, and enhance the ability to respond to climate and environmental change. NASA established the global Earth observation system is an attempt of international cooperation to share and integrate Earth observation data. It teamed up with the U.S. Environmental Protection Agency, the U.S. National Oceanic and Atmospheric Administration and many other agencies and countries. It has integrated satellite and groundbased monitoring and modeling systems to assess environmental conditions and predict events \(such as forest fires, population growth and other natural or human development issues\ In the foreseeable future, researchers will integrate the complex air quality information in order to have a better understanding and find a better method to deal with the air quality impact on the environment and human health NASA sets a space action agreement with Cray Company which allows one or more projects cooperate around the development and application of low-latency big data system NASA also uses the highly integrated non-SQL databases to transfer data, in order to accelerate the modeling and analysis of software running to test the practicality of the hybrid computer system. NASA Planetary Data System is a planetary mission data archives, and has become the basic resources for scientists all around the world, one of which is planetary discipline online catalog system, via which all products can be peer-reviewed, improved records and do access or queries Multitasking archive of NASA Space Telescope Science Institute is a part of the distributed space science data services which focuses mainly on the spectrum and other sciencerelated data sets of optical, ultraviolet and infrared. It also provides various astronomical data archives that supporting a variety of tools to access. NASA Earth System Grid Federation is a public archives and cooperates with the U.S. Department of Energy to provide observations and models for the Federal Government. Word Wind, released by NASA is an open source geographic science software, which shows the three dimensional Earth model provided by NASA, USGS, and other WMS vendor. Through this software users can browse the historical image data, monitor disaster events by Modis data and dynamic monitor of global temperatures    In addition, special mitigation satellites, remote sensing satellites, communication and navigation satellites have been widely used in a variety of disaster management, such as earthquakes, tsunamis, typhoons \(hurricanes\, floods, droughts geological disasters and fire. Currently, Disaster Monitoring Constellation is a system that consists of satellites from various countries through international cooperation. This system has these follow characteristics, high time resolution, large monitor range and fast response. It can be widely used disaster reduction process and disaster mapmaking in floods, hurricanes and fires  II 
 S PATIAL DATA DISASTER  Spatial data is closely related to human daily life, permeated all walks of life. The number, size and complexity are all in sharp increasing. A large amount of data has been stored in the spatial database and warehouse in types of text, graphics images and multimedia 9-1  The research from International Data Corporation 16 has shown that, as of 2003 humans have created a total of 5EB data, while in the year of 2011, the amount of data that had been copied and produced is exceeded 1.8ZB. It is expected that by 2020 global data usage will reach 35.2ZB, which needs 37.6 billion hard drives of 1TB capacity to store. On the one hand these data broadens the scope of available spatial data available for human to gain wisdom. On the other hand the value of a single unit of the data is rapidly declining. Human is submerged by the data ocean but thirsty for knowledge 32-3  Big data is voluminous and it grows quickly, but it has very low density in value, which means there is a lot of junk data   Spatial data from the real world is polluted 33 There are a variety of causes lead to spatial data incomplete. Inaccurate spatial data means incorrect value compared with the reality of the physical attributes. Duplicate records means one real-world recorded is stored in a multi-source spatial data tautologically or the real-world information is duplicated stored in multiple systems. Inconsistent spatial data  refers to the case that space 
488 
488 
488 
488 


A Basic big data technology B Discovery Spatial knowledge 
  
 
  
data context-related conflicts are caused by different systems and applications on type, format, granularity, synonyms encoding, and so on The production, transmission, replication and accumulation of data have gone far beyond people's capacity for analyzing understanding and implementing   Over time, all walks of life are submerged by contaminated data garbage, and then it could lead the big data into "garbage in, garbage out", and the çbig dataé becomes the useless çbig garbageé. Now, useful data is buried, and implied value is blanked in big data 3   III T HE VALUE OF SPATIAL DATA  Adam Smith, a well-known Scottish economist, believed that useful thingsé can be treated as capital. Data is valuable, and its value is in increasing via adaptive self-learning. Spatial big data is collected from numerous and interconnected sources Real usefulness is its maximum value. The generally accepted rule of big data is çdecision on dataé. The first prerequisite is to keep data always useful and activated. The ultimate value of big data is to gain human intelligence 9  3 8  Big data provides an unprecedented opportunity to observe the real world in a full view rather than partial samples 4 1 7   Big data are treated as Basic resources. McKinsey 4 believes that data is the basic resource, and can be compared with physical assets, human capital, create significant value for the world economy, improve the productivity and competitiveness of the enterprises and the public sector, and create a large number of economic surplus for consumers. In 2012, Gartner believes that çBig data is big moneyé. The U.S. government considers big data as çnew oilé related to the country's economic restructuring and industrial upgrading 2 3 4 0   IV S PATIAL DATA MINING  Spatial data mining refers to the basic technologies to realize the value of big data, relocate data assets, and use it effectively Spatial data mining can be used to extract information from data, mine knowledge from information, extract data intelligence in knowledge, improve the ability of self-learning self-feedback adaptation, finally realize human-machine intelligence  41    The basic techniques of big data include data collection storage, processing, expression, and quality evaluation 1  Big data can be generated in mobile devices, tracking systems, radio frequency identification devices \(RFIDs\ sensor networks, social networking, Internet search, automatic recording systems, video archives, e-commerce, as well as the process in analyzing those data. The acquisition mode of big data can be divided into three types: Point acquisition, plane acquisition, and mobile acquisition 1 The point acquisition means collecting spatial coordinates and attributes of the surface point-by-point through total station, GPS receivers and other conventional ground-based measurement. The plane acquisition means collecting images of large areas through air and space with remote sensing methods, to extract the geometric and physical properties. The mobile acquisition means integrating the use of space positioning system currently mainly refers to the Global Positioning System Remote Sensing \(RS\ and Geographic Information Systems GIS\ to collect, store, manage, update, analyze and apply spatial data in EOS Big data storage technology is the basis for data mining. It is designed to meet the growing need for data storage, which aims to provide scalability, high reliability, excellent performance data storage, access, and management solution such as distributed data storage, multiple levels caching, load balancing, fault-tolerant mechanisms. Conventional methods are not adequate for these missions. It needs to establish a large platform for data through software, to provide places to store and interface to access. In February 2012, researchers at the University of York in UK developed a heat rather than the magnetic field of computer hard disk data storage technology that reduces energy consumption while reach the storage speed of thousands of GB per second 3 In October 2012, the Fujifilm and IBM developed a barium ferrite particles coated tape, which can store 35TB data in the size of 10cm 2cm    In December, the Massachusetts Institute of Technology synthesized the third magnetic state herbertsmithite pure crystal, which may have a tremendous impact on magnetic storage technology 34  Big data processing is to implement the transitions: from data to information, from information to knowledge and from knowledge to wisdom. Big data processing includes object superposition, target buffer, spatial data cleaning, spatial data analysis, spatial data mining, spatial feature extraction, image segmentation, and image classification Big data expression technology is designed to represent the data in a clear and effective way that reveals meaningful information to the user, or provide the user with a new perspective of view. Big data expression technology includes triangulated irregular networks, digital elevation models digital terrain models, flat maps, three-dimensional maps image maps, and digital city maps Big data quality assessment technology is aimed to avoid the risk of big data collecting and high-density measuring. The technology includes logical assessment method, exception value based assessment method, and accounting based assessment method  Spatial knowledge discovery is the technology that uses spatial data mining method to extract previously unknown, potentially useful, and ultimately comprehensible rules. It is also a process of gradual sublimation from spatial data to space information and to space knowledge, step-by-step. Spatial data mining systems aims to make spatial data gradually summarized into spatial knowledge. Through the integration of space data, it can 
489 
489 
489 
489 


 
C Extraction data intelligence 
 
deeply extract space knowledge. By using such new knowledge, data can be processed in real time in order to understand and apply the data, to make intelligent judgments and well-informed decisions. Space knowledge can be selflearning, self-enhance, universal, and easily recognized. It could serve as a basis for decision support If businesses take full advantage of spatial knowledge, it will be more precise and dynamic for humans to learn, work life, and achieve wisdom state. It will help to improve resource utilization and productivity level. Moreover, it will also help to respond to the economic crisis, the energy crisis, the deterioration of the environment and many other global issues  Data intelligence is the ability to obtain a more innovative systematic and comprehensive knowledge to solve a particular problem through an in-depth analysis of the collected data. It is an ability to understand and solve problems fast, flexibly and correctly. Spatial data intelligent has three features: more thoroughly perception, more extensive interoperability, and deeper intelligence. The three features are aimed to get bigger and more comprehensive data,  to share and co-operate data via the Internet, to do data analysis and data mining by variety of advanced techniques, and to constitute a hierarchy of spatial data intelligences \(Fig. 3 35   More in-depth data intelligence is to create new value of data. On the one hand, when making full use of spatial data knowledge in all walks of life, it can produce secondary knowledge. In order to form a mining mechanism to mine knowledge in knowledge, it needs to bring primary knowledge together to form an intelligent form of expression. Ultimately the destination knowledge can be achieved. On the other hand based on a general industrial or socio-ecological system, it can redefine the interactive mode of government, companies and individuals, so that it improves the interaction clarity efficiency, flexibility and response speed. It changes from the traditional single dimension such as: production consumption management, or planning execution, to a new multidimensional collaborative relationship. In this new relationship both individuals and organizations can freely contribute and get information and expertise accurately and timely. This new relationship exerts a positive influence on each other to reach smart running macro-effects 40  Spatial data prompted the fusion of world's digital infrastructure and physical infrastructure. Almost anyone or anything can be connected to a digital network at low-cost. It is easy to embed sensors in a variety of ecosystems. It can be more sophisticated, dynamic management of production and life to achieve the smart status, through global infrastructure of equipment and devices, via the integration of human society and the physical system by Internet, with supercomputers and cloud computing. For example, space knowledge can be found through integrating the data from satellite positioning systems sensors, and wireless networks. , Spatial knowledge is then transferred to the mobile phone terminal, which helps users make reasonable judgment based on location services in order to achieve the intelligent data transformation into wisdom \(Fig 3\.  Firstly, the reality space world is thoroughly studied through the acquisition of spatial data from satellite positioning systems, sensors and wireless ne tworks. Secondly, the spatial data is stored and managed by appropriate method, in order to integrate into spatial information. Thirdly, a variety of spatial knowledge is extracted through purposefully data mining methods and mining model. Spatial knowledge is integrated to the new available knowledge, in order to reach deeper data intelligence. Finally, data intelligence is integrated into the digital earth and the "Internet of things", in order to enhance the wisdom of users and machines, and to achieve smarter real world data interaction 41-4    Figure 3 
Location-based data intelligences   
490 
490 
490 
490 


United Nations Global Pulse, 2012, Big Data for Development Challenges & Opportunities, May 2012 2 Office of Science and Technology Policy | Executive Office of the President, 2012, Fact Sheet: Big Data across the Federal Government March 29 9 2012 9 www.WhiteHouse.gov/OSTP 3 Office of Science and Technology Policy | Executive Office of the President, 2012, Obama Administration Unveils 003\014 Big Data 003\015 Initiative Announces $200 Million in New R&D Investments, March 29 9 2012 9 www.WhiteHouse.gov/OSTP 4 McKinsey Global Institute, 2011, Big Data: the Next Frontier for Innovation, Competition, and Productivity, May 2011 5 Rajaraman A, Ullman J D 9 Mining of Massive Datasets, Cambridge University Press, 2011 6 Grossner K, Goodchild M, Clarke K, Defining a digital earth system Transactions in GIS, 12\(1\: 145-160, 2008 7 Densham P J, Goodchild M F, Spatial decision support systems: A research agenda, In: Proceedings GIS/LIS'89, Orlando, FL., 1989, pp 707-716 8 Li D R, Wang S L, Li D Y, Theory and Application of Spatial Data Mining \(the fisrt edition\, Beijing 9 Science Press, 2006 9 Li D R, Wang S L, Li D Y, Theory and Application of Spatial Data Mining \(the second edition\, Beijing 9 Science Press, 2013  Ester M et al., Spatial data mining: databases primitives, algorithms and efficient DBMS support. Data Mining and Knowledge Discovery, 2000 4, 193-216  Miller H J, Han J, Geographic Data Mining and Knowledge Discovery the second edition\, London: Taylor and Francis, 2009  Schoier G., Borruso G., 2012, Spatial data mining for highlighting hotspots in personal navigation routes, International Journal of Data Warehousing and Mining, 8\(3\:45-61  Bimonte S., Bertolotto M., Gensel J., Boussaid O., Spatial OLAP and Map Generalization: Model and Algebra. International Journal of Data Warehousing and Mining, 8\(1\: 24-51, 2012  Silva R., Moura-Pires J., Santos M. Y. 2012, Spatial Clustering in SOLAP Systems to Enhance Map Visualization. International Journal of Data Warehousing and Mining,8\(2\: 23-43 \(2012\ Lapkin A, Hype Cycle for Big Data, 31 July 2012, Gartner, Inc. | G00235042, 2012  Shekar S, Xiong H\(Eds.\ Encyclopedia of GIS. New York: Springer 2007  Mills M P, Ottino J M, The Coming Tech-led Boom[N   2 012 10 12 9 www.wsj.com  Reshef D N et al., 2011, Detecting novel associations in large data sets Science, 334, 1518  Surhone L M, Tennoe M T, Henssonow S F, Big Data: BigTable, Cloud Computing, Database Theory.  Betascript Publishing, 2010  Tu Z 9 Big D ata: Data revolution is coming 9 Guangxi Normal University Press, 2012  Zhu Z, Yu C, Yan L, Big data: Big value,Big chance,Big Change Electronics Industry Press, 2012  Barabasi A.-L 9 Bursts: The Hidden Patterns Behind Everything We Do 9 Plume Books 9 2011  Meyer-Schoenberger V, Cukier K, Big Data: a Revolution That will Transform How We Live, Work and Think, London:John Murray, 2013  Bian F L, Digital vision to see the world, Wuhan: Wuhan University Press, 2011  Wang S L, Zeng Y X, Yuan H N, Service Science Introduction, Wuhan Wuhan University Press 9 2009  Wang S L, Shi W Z, 2012, chapter 5 Data Mining, Knowledge Discovery. In: Wolfgang Kresse and David Danko \(eds.\ Handbook of Geographic Information \(Berlin: Springer\, pp.123-142  Li D R, Wang S L, 2007, Spatial data mining and knowledge discovery Advances in Spatio-Temporal Analysis: in: ISPRS Book Series, Vol. 5 171-192, Editor\(s\inming Tang, Yaolin Liu, Jixian Zhang, Wolfgang Kainz, London:Taylor and Francis  Burstein F, Holsapple C W, Handbook of Decision Support System Berlin: Springer , 2008  Cressie N, Statistics for Spatial Data \(revised edition\, New York: John Wiley and Sons Inc. 1993  Haining R., Spatial Data Analysis: Theory and Practice, Cambridge Cambridge University Press, 2003  Koperski K, A Progressive Refinement Approach to Spatial Data Mining. Ph.D. Thesis. British Columbia: Simon Fraser University, 1999  International Data Corporation, Electronic Medicines Compendium 2011 IDC Digital Universe Study: Big Data is Here, Now What?. June 28, 2011  Smets P, Imperfect information: imprecision and uncertainty. In Uncertainty Management in Information Systems. London: Kluwer Academic Publishers. 225-254, 1996  Smithson M J, Ignorance and Uncertainty: Emerging Paradigms. New York: Springer-Verlag, 1989  Kim W. et al., A taxonomy of dirty data. Data Mining and Knowledge Discovery, 2003,7: 81Ö99  Hern‡ndez M A , Stolfo S J, Real-world data is dirty: data cleansing and the merge/purge problem. Data Mining and Knowledge Discovery 1998, 2, 1-31  Dasu T, Exploratory Data Mining and Data Cleaning. New York: John Wiley & Sons, 2003  Paul M, Cassette tapes are the future of big data storage.  New Scientist 2887, p20, 2012  Smith A, An Inquiry into the Nature and Causes of the Wealth of Nations. New York: The Modern Library, 1776  Ostler T.A., et al. Ultrafast heating as a sufficient stimulus for magnetization reversal in a ferrimagnet. Nature Communications 3, 666 Feb. 07, 2012  W ang S L, Spatial data mining under smart earth, Proceedings of 2011 I EEE International Conference on Granular Computing, 2011, pp.717722  Craglia M, Bie K, Jackson D, Digital Earth 2020: towards the vision for the next decade , International Journal of Digital Earth, 2012, 5\(1\:4-21  Wang S L, Gan W Y, Li D Y, Li D R, Data Field for Hierarchical Clustering. International Journal of Data Warehousing and Mining, 2011 7\(2\ 43-63  Morgan Stanley. Cloud Computing Takes off Market Set to Boom as Migration Accelerates. May 23, 2011 
 
 V C ONCLUSION  The development of big data extends the scope of human activities. The world has been cooperating and integrating on a global scale. It redefines the relationship among individuals businesses, organizations, gove rnments, and societies through networked thinking and further to improve the human living environment, to enhance the quality of public services, to improve performance, efficiency and productivity through the interactive operation. The technological progress and industrial upgrading of big data will create new markets, business models and industry rules, and more importantly it demonstrates the collective will of a country that looking for strategic advantage Although there is still a large gap to gain data intelligence like human wisdom, big data is a promising topic to understand the world from an entirely new aspect A CKNOWLEDGEMENTS  This project is supported by the NSFC \(61173061, 71201120 and the Doctoral Fund of Higher Education \(20121101110036 R EFERENCES  1 
                                           
491 
491 
491 
491 


not possible under other visualization frameworks because they lacked the ability to succinctly express the differences between the different overplotting treatments V I MPLEMENTATION The ability to interactively switch between different Abstract Rendering encodings is a signiìant advantage of Abstract Rendering over other libraries Efìciency changing rest directly on implementation decisions Abstract Rendering has been implemented in Java and Python This section describes the implementation in Java The Python implementation is similarly structured but differs in the parallelization strategy relying heavily on vectorization through NumPy The Abstract Rendering implementation follows the definition provided in Section II Aggregate info and transfer functions are directly represented though aggregate functions are slightly modiìed to provide efìcient execution in out-of-core environments The select function is replaced with a Renderer class that controls the overall data access order This includes access not just to the underlying dataset as the select function implies but also to the aggregate values i.e the order and frequency that the x/y values appear in Renderers fall into two general categories by pixel and by glyph Bypixel renderers perform selection essentially as described in Section II This strategy is efìcient when used with datasets that are spatially arranged such as a quad-tree Any given glyph will be accessed once for each pixel the glyph touches Many data structures do not efìciently handle the highly spatial nature of these queries and thus a pixel-oriented rendering strategy is not effective A glyph-based rendering strategy takes the opposite tack Each glyph is visited exactly once and each pixel may be updated multiple times This enables efìcient rendering when using non-spatial data structures because each glyph is visited in an order convenient to its container However the different iteration order means that synthetic values i.e the s xy values are typically updated multiple times The aggregation function does not receive a list of info function results as described in Section II Instead it receives one info result and a pre-existing aggregate value To compensate for this difference aggregate functions must provide a zero value and must be commutative/associative if deterministic execution is desired The zero is used to initialize the synthetic data space When presented with a list of info results the operator receives all of its operands at once and thus commutativity and associativity are not signiìcant The implementation supports a number of parallelization strategies and data conìgurations A full analysis is beyond the scope of this paper In brief thread-level parallelism and vector-based parallelism have been explored GPU distributed memory and streaming data conìgurations have also been investigated All use the components described   Figure 10 Scaling behavior of Abstract Rendering as processor count increases Scaling behavior is near linear as processors as are added but shows no additional improvements with hyper-thread processors processors 8-15 are hyperthreads and improve by less than 5 vs 8 cores above augmented with various helper functions to facilitate data access or partial result combination The out-of-core conìguration is used in performance analysis Section VI and to handle the Kiva data set Section IV-B VI P ERFORMANCE Section III described several Abstract Rendering phrasings demonstrating its expressive capabilities To be practical the framework must be performant as well as expressive An simple characterization of runtime performance was done with an eight physical core machine Two adjacency matrix visualizations were used The rst was the Kiva dataset described Section IV-B The second dataset is an adjacency-list of links found on Wikipedia receiving the same treatment The Wikipedia data set includes 153 million edges representing the links of the largest connected cluster if the category system is ignored Both data sets were binaryencoded adjacency-lists stored in a memory mapped le The le contents were streamed off disk and rendered in a glyphparallel strategy These datasets were used because the data volume is sufìcient to require out-of-core processing but require simple analysis to create a visual representation Figure 10 presents the average performance over 10 executions while keeping the core count xed In general more processors are more helpful but hyperthreading is not The scaling characteristic is similar between the two datasets but the difference shows the overhead of abstract rendering in general Even though this Wikipedia data set is four times larger than the Kiva data set the overall runtime is only three times longer on average Overall the performance numbers are generally supportive of interactive visualization applications 15 


VII F UTURE W ORK Current Abstract Rendering implementations closely tie the bin-elements with the display resolution and region This decision introduces view-dependent effects View-dependent effects are used advantageously in high-deìnition alpha composition but may not always be desirable Developing techniques for avoiding these effects and guidelines for their usage is an ongoing effort Section V described implementation considerations There are several unexplored options that may lead to more efìcient implementations or to implementations that run in more complex runtime environments Options include distributed memory or efìcient GPU execution The idea of binning is shared inMens Abstract Rendering can be applied to more than just overplotting High-deìnition alpha composition rests on the idea of measuring pixel-level information This same idea can be applied to screen-space metrics for visualization evaluation 17 Such applications are also being e xplored The idea of the transfer function comes from scientiìc visualization However years of research into transfer functions has yielded many interesting techniques Mixed rendering styles and context-aware highlighting are strong candidates for exploration Additionally as noted in Section I Z-ordering creates an implicit volume-like space Some volume-based techniques from scientiìc visualization maybe more directly applicable by more literally applying this metaphor VIII C ONCLUSIONS Visualizing large data sets inevitably runs into overplotting issues By considering the rendering process as binning Abstract Rendering provides a means to unify many overplotting techniques Furthermore those techniques can be encoded succinctly at compile time and executed efìciently at runtime R EFERENCES  S K Card J Mackinlay  and B Shneiderman Readings in Information Visualization Using Vision to Think  Morgan Kaufman 1999  M Bostock and J Heer  Proto vis A graphical toolkit for visualization IEEE Transactions on Visualization and Computer Graphics  vol 15 no 6 pp 1121Ö1128 2009  M Bostock V  Ogie v etsk y  and J Heer  D3 DataDriven Documents IEEE Trans Visualization  Comp Graphics Proc InfoVis  2011 A v ailable http vis.stanford.edu/papers/d3  J A Cottam Design and implementation of a stream-based visualization language Ph.D dissertation Indiana University 2011  L W ilkinson The Grammar of Graphics  2nd ed New York Springer-Verlag 2005  H W ickham  A layered grammar of graphics  Journal of Computational and Graphical Statistics  vol 19 no 1 pp 3Ö28 March 2010  G S Da vidson B Hendrickson D K Johnson C E Meyers and B N Wylie Knowledge mining with VxInsight Discovery through interaction Journal of Intelligent Information Systems  vol 11 no 3 pp 259Ö285 1998  J A Cottam and A Lumsdaine Extended assortitivity and the structure in the open source development community in International Sunbelt Social Network Conference  International Network for Social Network Analysis January 2008 A v ailable http://www.insna.org/PDF/Awards/awards  ms 2007.pdf  C Muelder  F  Gygi and K.-L Ma V isual analysis of inter process communication for large-scale parallel computing IEEE Transactions on Visualization and Computer Graphics  vol 15 no 6 pp 1129Ö1136 Nov 2009 Available http://dx.doi.org/10.1109/TVCG.2009.196  National Historical Geographic Information System V ersion 2.0 University of Minnesota Minneapolis MN 2011  A v ailable http://www nhgis.or g  T  Porter and T  Duf f Compositing digital images  SIGGRAPH Comput Graph  vol 18 no 3 pp 253Ö259 Jan 1984 A v ailable http://doi.acm.or g/10.1145 964965.808606  J Johansson P  Ljung M Jern and M Cooper  Re v ealing structure within clustered parallel coordinates displays in Proceedings of the Proceedings of the 2005 IEEE Symposium on Information Visualization  ser INFOVIS 05 Washington DC USA IEEE Computer Society 2005 pp 17 Available http://dx.doi.org/10.1109/INFOVIS.2005.30  H Hagh-Shenas V  Interrante C Heale y  and S Kim Weaving versus blending a quantitative assessment of the information carrying capacities of two alternative methods for conveying multivariate data with color in Proceedings of the 3rd symposium on Applied perception in graphics and visualization  ser APGV 06 New York NY USA ACM 2006 pp 164Ö164 A v ailable http://doi.acm.org/10.1145/1140491.1140541  T  E Oliphant Guide to NumPy  Provo UT Mar 2006  A v ailable http://www tramy us  Z Liu B Jiang and J Heer  immens Real-time visual querying of big data Computer Graphics Forum Proc EuroVis  vol 32 2013 A v ailable http vis.stanford.edu/papers/immens  J W  T u k e y and P  A T u k e y  Computer Graphics and Exploratory Data Analysis An Introduction in Proceedings of the Sixth Annual Conference and Exposition Computer Graphics  Fairfax VA Nat Computer Graphics Association 1985 pp 773Ö785  A Dasgupta and R K osara P ar gnostics Screen-space metrics for parallel coordinates IEEE Transactions on Visualization and Computer Graphics  vol 16 no 6 pp 1017Ö1026 Nov 2010 A v ailable http dx.doi.org/10.1109/TVCG.2010.184 16 


state of innovation stakeholder  node PQ It  s a balanced node Based on this, we could calculate the  node PQ Calculation process is: set different inn ovation stakeholders state i U  and j U Value of ij 000T can be get from  innovation time difference. Innovation stakeholdersí social effect and industrial effect can be obtained upon ij B  and ij G set according to relation between innovation stakeholders  Model 4.1 points out  that the value of Gij  directly affects social benefits and sector benefits. Large Gij  can lead to increasing benefits of the entire industry and the entire social growth Bij reflects big organizationís impact on businesses. Only strengthening the inter agent association within big organization and enhancing the str ategic partnership between enterprises can jointly promote the development of the entire industry, and bring more social benefits, so that each agent can be improved   5 Summary This paper puts forward the concept of the big organization based on the CSM t heory. It introduces the basic implication of the big organization and theoretical framework of the big organization including: the big organization's perspective  overall perspective, dynamic perspective, and new resource perspective; the big organizat ionís sense  the purpose of the organizational structure is innovation, organizational activities around the flow of information, breaking the traditional organizational structure, encouraging self run structure, and blurring organizational boundaries; the big organizationís platform  the platform ecosystem of the big organization ; the big organizationís operation mode  borderless learning mode, and cluster effect; the big organizationís theory  active management theory  leading consumers, and culture  entropy reduction theory  negative culture entropy and humanistic ecology theory  inspiring humanity, and circuit theory  a virtuous circle, and collaborative innovation theory  collaborative innovation stakeholder. This paper also discusses culture entropy reduction theory of the big organization  negative culture entropy, and coordinated innovation theory  innovation stakeholders collaboration. Culture entropy change model and collaborative in novation model are constructed   The research has just begun for the big organization. It also needs further improvement but remains the trend of the times   Reference  1  Gordon Pellegrinetti, Joseph Bentsman. Nonlinear Control Oriented Boiler Modeling A Benchmark Problem for Controller De sign [J  I E E E tr a n s a c tio n s o n c o n tr o l s y s te m s te c h n o lo g y 2 0 1 0  4 1\57 65  2  Klaus Kruger, Rudiger Franke, Manfred Rode Optimization of boiler start up using a nonlinear 457 


boiler model and hard constraints [J  E n e r gy 201 1 29   22 39 2251  3  K.L.Lo, Y.Rathamarit  State estimation of a boiler model using the unscented Kalman filter [J  I E T  Gener. Transm. Distrib.2008 2 6\917 931  4  Un Chul Moon, Kwang. Y.Lee. Step resonse model development for dynamic matrix control of a drum type boiler turbine system [J IE E E  T ra nsactions on Energy Conversion.2009 24 2\:423 431  5  Hacene Habbi, Mimoun Zelmat, Belkacem Ould Bouamama. A dynamic fuzzy model for a drum boiler turbine system [J  A u to m a tic a 2 0 0 9 39:1213 1219  6  Beaudreau B C. Identity, entropy and culture J   J o ur na l  o f  economic psychology, 2006, 27\(2 205 223  7  YANG M, CHEN L. Information Technique and the Entropy of Culture J  A cad e m i c E x ch a n g e  2006, 7: 048  8  ZHANG Zhi feng. Research on entropy change model for enterprise system based on dissipative structure J  Ind ustrial  Engineering and  Management 2007, 12\(1\ :15 19  9  LI Zhi qiang, LIU Chun mei Research on the Entropy Change Model for Entrepreneurs' Creative Behavior System Based on Dissipative Structure J  C h i n a S of t S c i e n c e  2009   8  1 62 166   458 


A Global Solution COVERAGE North and South America EMEA and Asia White lines are flights in the masFlight platform from February 8, 2013 Yellow pins are weather stations feeding hour ly data to our platform Maps from Google Earth / masFlight masFlight tracks flights, airports and weather around the world  Global daily flight information capture  82,000 flights  350 airlines  1700 airports  Integrated weather data for 6,000 stations  Match weather to delays  Validate block forecasts at granular level  Add weather analytics to IRROPS review and scenario planning 


Example 1: Proposed FAA Tower Closures masFlight used big-data to link airport operations across three large data sets  Current and historical airline schedules  Raw Aircraft Situation Display to Industry \(ASDI\AA  Enhanced Traffic Management System Counts \(ETMS\Airport operations counts by type \(commercial, freight, etc TOWER CLOSINGS Dots indicate closures; Red dots have scheduled service Based on scheduled service March 1 7, 20 13; scheduled service includes scheduled charter flights, cargo flig hts, and passenger flights Dots  indicate  closures  Red  dots  have  scheduled  service Bas ed  o n sc h edu l ed  se rvi ce  M a r c h 1  7, 2013; scheduled se rvi ce includ es scheduled c harter fli g hts car g o fli g hts a nd passen g er fli g hts Findings: Proposed Tower Closings  From schedules database: 55 airports with scheduled passenger airline service  14 EAS Airports  From ASDI & ETMS: 10,600 weekly flights on a flight plan \(ex. VFR and local traffic  6,500 Part 91/125 weekly flights  4,100 Part 135/121 weekly flights  


Example 1: Big-Data Analytics Applied to ASDI and ETMS To Analyze Operations TOWER CLOSINGS  26 44 24 23 11 10 6 2 1 2 Up to 5 5-10 10-15 15-20 20-25 25-30 30-35 35-40 40-45 45 Count of Airports Average Number of Daily Operations with a Flight Plan Filed Distribution of Airports By Average Number of ìDailyî Impacted Flights Airports Affected by Tower Closures Source: ASDI radar data ñ Part 91 151 flying and Part 135/121 flying March 1-7, 2013; masFlight analysis Note: Average ìdailyì operations based on 5-day week 


Example 2: Aviation Safety Causal Factor For example, consider the following ASRS report \(ACN 1031837 Departing IAH in a 737-800 at about 17,000 FT, 11 m iles behind a 737-900 on the Junction departure over CUZZZ Intersection. Smooth air with wind on the nose bearing 275 degrees at 18 KTS We were suddenly in moderate chop which lasted 4 or 5 seconds then stopped and then resumed for another 4 or 5 seconds with a significant amount of ri ght rollingÖ I selected a max rate climb mode in the FMC in order to climb above the wake and flight path of the leading -900 We asked ATC for the type ahead of us and reported the wake encounter. The 900 was about 3,300 FT higher than we were  Synopsis  B737-800 First Officer reported wake encounter from preceding B737-900 with resultant roll and moderate chop What causal factors can be identified from this narrative that could be applied to future predictive applications CAUSAL FACTORS Data-mining algorithms can mine the text of safety reports to obtain specific data that can be used to analyze causal factors  


Example 2: Identifying Causal Factors CAUSAL FACTORS  Indicators ñ Data Element Methods ñ Identifying Context and Causes  Time of day  Date range \(month day  Aircraft type  Fix or coordinates  Originating airport  Destination airport  Weather notes We pinpoint the sequencing of flights on the IAH Junction Seven departure \(at CUZZZ\the specified wind conditions to find cases wher e a B737-900 at 20,000 feet precedes by 11 miles a B737-800 at 17,000 feet  Search related data sets including ASDI flight tracks, local traffic and congestion  Weather conditions for alter native causes \(winds aloft shear and convecti ve activity  Airline specific informati on \(repeated occurrence of event in aircraft type Big data gives us visibility into contextual factors even if specific data points are missing such as a specific date or route Big-data analytics gives us insight into unreported factors as well 


Example 3: Correlating Utilization and Delays  60 65 70 75 80 85 90 95 100 7 9 11 13 ONTIME DEPARTURE PERFORMANCE HOURS OF DAILY UTILIZATION 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Narrowbodies By Day of Week 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Widebodies by Day of Week Daily Utilization vs. On-time Departures January 2013 System Operations Correlation Coefficient -0.53 Includes AA, AC, AS B6 F9, FL, NK, UA, US VX and WN SOURCE masFlight \(masflight.com COMPARING OTP AND UTILIZATION 


 6.2 6.0 5.8 5.8 5.2 4.9 LGB JFK BOS MCO DCA FLL JetBlue Focus Average Daily Deps per Gate Used UTILIZATION BY HUB Example 4: Daily Utilization of Gates, by Hub Big-data analysis of different carriers daily departures per gate used SOURCE masFlight \(masflight.com June 1 through August 31, 2012 Gates with minimum 1x daily use 7.7 7.4 7.2 6.2 6.1 5.8 3.8 3.6 ORD LAX SFO EWR DEN IAH IAD CLE United Airlines Hubs Average Daily Deps per Gate Used 7.8 6.4 5.5 5.4 5.3 4.4 4.3 4.0 SEA SAN PDX ANC SFO GEG LAX SJC Alaska Airlines Hubs Average Daily Deps per Gate Used 7.2 6.9 6.8 6.4 5.0 2.7 ORD DFW LAX LGA MIA JFK American Hubs Average Daily Deps per Gate Used 7.2 6.9 6.6 4.9 4.2 CLT DCA PHL PHX BOS US Airways Hubs Average Daily Deps per Gate Used 6.6 5.9 5.5 4.7 MCO BWI ATL MKE AirTran Hubs Average Daily Deps per Gate Used ne pe 


Conclusions for Big Data in Aviation  Big-data transforms operational and commercial problems that were practically unsolvable using discrete data and on-premises hardware  Big data offers new insight into existing data by centralizing data acquisition and consolidation in the cloud and mining data sets efficiently  There is a rich portfolio of information that can feed aviation data analytics  Flight position, schedules, airport/gate, weather and government data sets offer incredible insight into the underlying causes of aviation inefficiency  Excessive size of each set forces analysts to consider cloud based architectures to store, link and mine the underlying information  When structured, validated and linked these data sources become significantly more compelling for applied research than they are individually  Todayís cloud based technologies offer a solution CONCLUSIONS 


Conclusions:  Our Approach  masFlightís data warehouse and analysis methods provide a valuable example for others attempting to solve cloud based analytics of aviation data sets  masFlightís hybrid architecture, consolidating secure data feeds in on-premises server installations and feeding structured data into the cloud for distribution, addresses the unique format, security and scale requirements of the industry  masFlightís method is well suited for airline performance review competitive benchmarking, airport operations and schedule design and has demonstrated value in addressing real-world problems in airline and airport operations as well as government applications CONCLUSIONS 






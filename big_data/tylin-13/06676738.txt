Abstract 
002  
 
Tape Cloud Scalable and Cost Efìcient Big Data Infrastructure for Cloud Computing Varun S Prakash 
Magnetic tapes have been a primary medium of backup storage for a long time in many organizations In this paper the possibility of establishing an inter-network accessible centralized tape based data backup facility is evaluated Our motive is to develop a cloud storage service that organizations 
Department of Computer Science University of Houston Houston TX 77004 U.S.A Email vsprakash@uh.edu  wyf@cs.uh.edu  larryshi@cs.uh.edu 
 Yuanfeng Wen  Weidong Shi 
002  
 
can use for long term storage of big data which is typically Write-Once-Read-Many This Infrastructure-as-a-Service IaaS cloud can provide the much needed cost effectiveness in storing huge amounts of data exempting client organizations from high infrastructure investments We make an attempt to understand some of the limitations induced by the usage of tapes by studying the latency of tape libraries in scenarios most likely faced in the backing up process in comparison to its hard disk counterpart The result of this study is an outline of methods to overcome these limitations by adopting novel tape storage architectures lesystem schedulers to manage data transaction requests from various clients and develop faster ways to retrieve requested data to extend the applications beyond backup We use commercially 
available tapes and a tape library to perform latency tests and understand the basic operations of tape With the optimistic backing of statistics that suggests the extensive usage of tapes to this day and in future we propose an architecture to provide data backup to a large and diverse client base 
I I NTRODUCTION The last decade has seen an explosion of data generated by individuals and organizations For instance the amount of video data captured by a single HD surveillance camera at 30fs in 14 days requires 1TB storage space The number of CCTV cameras in UK alone is estimated to be 1.85 million  There are more than one f actors that or ganizations consider before investing in a certain type of storage infrastructure 
 4 
of the data or the intended period that the data needs to be stored or backed up of the storage media which should have low susceptibility to physical damage and be tolerant of a wide range of environmental conditions without data loss of the storage technology or inversely the technologyês ability to be easily updated based on the availability of newer solutions or the over all expense of ownership including cost of purchasing and maintaining the necessary hardware software and the media require and or the overall amount of data that need to be stored or backed up for the organizationês 
1\vity 2 3 4 5 
future use 
or the importance of data that needs to be Based on these factors organizations requiring data storage solutions can either have in house data back up facility or rely on a service provider to carry out the task efìciently and economically Ho we v er  there are man y intermediate considerations that both players need to consider Choice of storage media can be meagerly categorized on the basis of the capacity of data that need to be stored because although it is a nearly irrefutable factor it has a close relationship with the overall costs Storage service providers and organization will be forced to decide in most cases on a tradeoff between a smaller high speed expensive storage media and larger low 
6 Criticalness 
speed inexpensive storage media A high initial in v estment for the operating hardware and software may force smaller organizations to discard the option although the cost of the media itself is very economical Similarly high media costs can create scalability issues for organizations that needs storage expansion on a regular basis even in a nearly automated environment Magnetic tapes which started off as a primary storage media decades ago have been preferred for backup storage of data generated by organizations for a long time now There has been a continuous development of quality form factor capacity and robustness of the storage It also continues to be a very economic type of storage media The data stored on 
tapes has a property that justiìes this choice in that this data may or may not be accessed in the near future For instance studies of enterprise le servers show that in a three month period more than 90 percent of the data on the servers was never accessed T apes serv e its purpose well in situations where information was lost due to natural calamity human error or system failures For this reason trained personnel are hired in order to maintain and service tape drives and tape libraries Despite the advantages of tapes there has not been an increase in its usage due to high initial investment of the operating hardware and software which force smaller organizations to discard the option although the cost of the media itself is very economical This defeats the v ery 
purpose of affordable backup and limits the storage bandwidth signiìcantly Another important reason for the at rate of increase in tape usage is its inability to promise high data rate transactions The fact that tapes are linear data access media causes many processes waiting for data input/output from tapes to stay idle for longer periods accounts against tapes to be used for storing data which needs a more volatile storage environment as compared to backup or archival data The main contributions of our work are as follows 
We propose and evaluate for the rst time in literature an exciting new alternative in tape based big data stor 
 
2013 IEEE Sixth International Conference on Cloud Computing 978-0-7695-5028-2/13 $26.00 © 2013 IEEE DOI 10.1109/CLOUD.2013.129 541 


    
003"-\002 006\007-\002 004\002 004\002\002 1\002\002 006."\002 007 007\002 003-\002 006\002\002 007\007 006-\002 005\002 002 006\002\002\002 003\002\002\002 007\002\002\002 010\015\013\011 033\024\016\015\031\034\024 033\035\036\005\003\004\002\004\002\037 !\007"\002  022\007\004 \002"\002!'\(\\005 017+\024\016\030\017 007\002 036\011\015\025\015\016\011 036\010\007-\002\003\006\004 033\024\016\015\031\034\024 033\035,\005\003\004\002\003\004/ !\007-\002 036\011\015\025\015\016\011 036\010\007\005\007.\004\004 0 023\011\014\0252\0203\030\011\026\020\0214\032\0175\011\030\027 036\016\032\014\015\025\011\020&\011\026\024\015 0265\011 036\016\015\023\02662 
002\003\004\005\006\007 002\003\004\005\006\007\010\011\004\012\005\010 013\006\007\005\014\015\016\017\005 020\004\021\022\010\023\016\021\005\012\010\024\004\023\014\016\014\025 026\016\027\005\010\023\016\021\005\012\010\021\007\030\014\016\031\005\010\015\030\014\010 023\016\017\022\032\027\010\016\006\012\010\016\014\017\033\004\034\005 020\014\030\027\023\030\035\036\010 037\030\030\031\003\005\010\002\003\030\032\012\036\010 005\007\017 026\016\027\005\010\002\003\030\032\012 005\014\004\030\012\004\017\010!\016\017\022\032\027\010"\006\031\004\006\005 
The design of a cloud based storage framework provided as a service which implements the necessary middleware for seamlessly integration of large scale multi-user tape libraries with the cloud model is presented The tape cloud is designed to work autonomously or in conjunction with the current cloud infrastructure An attempt to optimize performance of the tape cloud with a multi-level hybrid storage model where hard disks are employed for providing cache spaces for data to be stored or retrieved from tape libraries\(one LTO 5 tape library can provide the storage capacity from 72TB to more than 1PB is made and the observations are reported Solutions are devised to support efìcient multi-user accesses to tape cloud using optimized hardware conìgurations and combinations and high level scheduling approaches which are evaluated for their performance The proposed tape cloud framework points to a new direction for creating service oriented cost effective massive scale infrastructure to meet the growing storage challenge in the coming era of big data enabled industries and research The paper is organized as follows A study of economic impacts of tapes is done in section II The system design for the tape cloud along with operational details are provided in section III We propose models for testing hypotheses on I/O performance on tapes details of which is discussed in section IV and results of which have been posted in section V A note on works related to our research is given in section VI and the conclusion and our future plan is given in section VII II B ACKGROUND Magnetic tapes have been in active usage over the last 60 years a time period that is comparatively high for storage technology in the growing IT age This has been possible due to the continuous improvement in the quality capacity durability and areas of application of tapes The dominant motivation to use tapes however arises from the fact that tapes are highly economical and ideal to store large amount of data which may or may not be useful to the organization in the near future The Linear Tape-Open is a set of standards that directs development and manages licensing and certiìcation of media and mechanism manufacturers.The standard form-factor of LTO technology goes by the name Ultrium the original version of which was released in 2000 and could hold 100 GB of data in a cartridge LTO version 6 released in 2012 can hold 2.5 TB in a cartridge of the same size as its predecessors Another very important storage media that has been around for a long time is the Hard Disk Drive The similarity between hard disk and tapes is only the principle of using magnetic material to store data hard disks rose to the scene as a better option to store data that needed faster retrieval The cost of operating hard disks has been an attractive tradeoff to make to the cost of the media itself This also has proved to be the tape killer as the hardware required to operate tapes and personnel required to maintain them costs unreasonably high A comparative study performed let us see that the monetary expenses in the form of initial investment involved create an obstruction for many small organizations to have backup solutions on tapes despite its competitive cost advantages results of which have been shown in table I TABLE I C OMPARISON OF C OSTS OF S TORING U NIT D ATA O N D IFFERENT S TORAGE M EDIA Solid State Hard Disk T apes TB/yr  total TB/yr  total TB/yr  total Media 19456 96.0 220 25.1 23 5.4 Capital 197 0.009 163 18.6 155 36.4 Maintenance 152 0.007 176 20.1 88 20.7 F acilities 221 0.010 118 13.5 56 13.1 Personnel 234 0.01 197 22.5 103 22.4 T otal 20260 874 425 
002 003\004 004\002 005\004 006\002\002 002 006\002\002 003\002\002 007\002\002 010\011\012\013\011\014\015\016\017\014\011\020\021\022\011\023\016\024\025\014\015\026\011\027 010\024\012\011\020\021\030\011\031\032\023\026\030\027 033\024\016\015\031\034\024\020\033\035\036\005\003\004\002\004\002\037 !\007"\002 010\015\013\011\020\035\014\024#\011 020$\022\007\004 \002"\002!'\(\\002\005 017+\024\016\030\017\020&,\(\007\002 036\011\015\025\015\016\011\020\036\010\007-\002\003\006\004 033\024\016\015\031\034\024\020\033\035,\005\003\004\002\003\004/ !\007-\002 036\011\015\025\015\016\011\020\036\010\007\005\007.\004\004 0 
Fig 1 Tape Cloud is a cloud storage service that uses magnetic tapes as the main storage media to store unstructured and big data unlike most of the commercial cloud storage solution available today age model that allows organizations to beneìt from a large storage bandwidth without having to invest in the infrastructure itself The crux of this approach lies in the optimization of the usage of the most affordable media This allows storage service providers to focus on the technicalities such as using affordable media required infrastructure and man power to handle them and permit client organizations to concentrate monetary expenditures away from investing on the fundamentals of data backup and storage Fig 2 Operating Temperatures of different media Fig 3 Unused State Energy Consumption of different media Another contributor to costs is the overall energy consumption of storage media and the associated infrastructure Power inefìciencies in storage systems can arise at two stages when the system uses a lot of energy even in the idle state Figure 3 and when the operating temperatures Figure 2 of the system results in the need for external conditioning systems A study performed with a tape drive and six hard disk drives of 
542 


002 003 004 005 006 002\007 010 011 002\002 012 013 002\005 014\015\016\017\020\021\022\023\024\017 025\017\015\026\027\030\022\023\031\017\020\032\017\015\026\020 033\002\034  014\015\016\017\020\035\015\022\031\020\033\010\034  035\015\022\031\020\025\015\023\036\020\033\003\034 014\015\016\017\020\035\015\022\031\022\023\026\037\017 \020!\036"\031 \020\033\012\034 035"#\016$\031\017\022\020\033!%!\020&'\031\017\022\(\015\\017\034 035"'\031\022"\036\036\017\022\020\033\005\034 014\015\016\017\020\023'\020\031*\017\020\036\023+\022\015\022 
036'&\(\010\010 036%\\010 036\(*+\036+++\010\010 036$\(+\010\010  036 036 036 036 036+++\036 036,++\036 036%++\036 036*++\036 026\016\027\005\010.\017/\032\004\021\004\007\004\030\006\010 \014\004\017\005 026\016\027\005\010\\014\010"\006\005\014\031\025\010\002\030\021\007 020 004\021\022\010.\017/\032\004\021\004\007\004\030\006\010 \014\004\017\005 020\004\021\022\010\\005\016\014\010"\006\005\014\031\025\010\002\030\021\007 
A An Abstraction for Tape Library Hardware 
Fig 4 Tape and Disk Acquisition and Energy Cost from INSIC Study The ve year period energy cost of disks is comparable with the acquisition cost of the tapes with equal storage capacities different speciìcation and manufacturer reveals that tape is much more power efìcient than hard disk when used on a large scale such as in data centers The fact that hard disks need to be electrically powered for operation is a mammoth disadvantage over tapes which is a non powered static storage and has very low power consumption per unit data Figure 4 sho ws the relative expenditure of acquiring the two different kinds of media as compared to the operational costs in terms of power required for their usage From the perspective of the storage infrastructure service provider scalability becomes very expensive 13 14 The infrastructure for using tapes which in most cases is the library introduces a new kind of expenses in the form of delays which need to be incurred due to the use of robotics inside the device The delay caused can create a slowdown of I/O processes also affecting business processes of the organization W e study some of these de vice speciìc delays We conducted experiments over commercial LTO-5 tape libraries e.g Tandberg tape Figure 5 shows the diagrammatic representation of the simple tape library the number of tape slots is a parameter that varies among different tape library products The numbered slots are tape cartridge holders The robotic cart runs on the rail in front of the tape driver and helps load the tapes into the driver To complete our analysis we have made a multi trial recording of delay of the various operations performed within the library We can understand the basic principles of operation and create a time proìle for these operations which helps us in creating faster and more efìcient hardware Table II in section V shows the delay incurred in moving tape cartridges in the numbered slots to the drive and back to the slots after performing the operation The average time taken for the transport of cartridges in both cases is more than a minute Once the tape is in place it takes nearly 30 seconds for it to load and be ready to read or write The tape transportation cart has an upward path time of 2.6 seconds and a total end to end path time of 7.4 seconds The robot usually performs both together during the load or unload operation from a slot at the very end of the library so time can be saved Based on the numbers we can get a clear time proìle about the tape library operations One of our design objectives is to reduce Fig 5 Representation of the Tandberg T24 Tape Library At the bottom is the Tape library showing parts with numbers mapped to the representation above it Bottom right is a single LTO5 tape cartridge time spent on the tasks such as movement of tapes from the slots to the drive III S YSTEM D ESIGN Figure 6 shows a birdês eye view of the tape cloud architecture Our effort in creating a cloud storage with a media that is known to be at the bottom of the ladder of performance calls for alteration of hardware assembly and design In order to get best results we create a design for the hardware that cases the tapes along with special instructions for multiple reader rewinder sets aimed to keep the setup cost effective Although the unit operations such as writing data onto tapes remains similar we consider some augmentative enhancements that are speciìc to our case The software of the tape cloud can be effectively termed as a middleware which operates between faster yet smaller hard disk buffers and comparatively slower yet larger tape backend storage This middleware needs to function as an agent arbitrating various components in order to reduce the overhead caused by using a slower backend media  as sho wn in Figure 9 It also performs v arious other tasks such as data set segmentation scheduling encryption load balancing and management of database containing the meta data and block IDs of data stored in tapes Figure 8 provides an understanding of the middle ware that operates between the distributed le system and tape storage This serves as an agent aiding the distributed le system in overcoming the latencies of using a slower media and also serves as an abstraction in clouds using hybrid storage infrastructure 
In order to make the workîow seamless and application independent special considerations about the hardware setup and conìguration need to be performed The massive scale of our focus encompasses multiple drives high speed robotics that seek grab and load tapes to drivers at high speeds and hazard resistant tape storage space To make data retrieval and deposition more efìcient we consider a conventional driver to be split into two parts One part rewinds the subsequent scheduled tapes to the correct position and the other part is involved in reading and writing into tapes the read and write head also has a rewinding functionality to perform small and quick seeks so it could be the addition of a rewinder in the 
543 


Fig 6 Implementation Architecture of Tape Cloud The arrows represent the direction of ow of data system This way we can pipeline the rewinding process and isolate the rewind latency from the overall read operation Fig 7 Stages and functions of each stage of the lesystem for Tape Cloud Although distributed by functionality the lesystem is monolithic across the storage system Fig 9 The block representation of the middleware on the basis of roles and responsibilities within the system server requests a memory allocation on the collection servers where the user data is going to be collected It also creates and manages database entries for the blocks that are created and manages redundancy to avoid data loss and increase availibility The load balancing servers connect and talk directly with the metaserver and the central database which contain information about the load on the Tape Interface Machines and currently serviced clients 
037"\0261\002\030\003\003\005\017\007\004\030\006\010\011\005\014\034\005\014 2\0261\002\030\003\003\005\017\007\004\030\006\010\011\005\014\034\005\014 002\003\004\005\006\007\010\002\003\030\032\012 3\005\007\016\021\005\014\034\005\0144 3\0055\017\016\017\033\005 002\005\006\007\014\016\003\010!\003\030\017\022\010\020\016\007\016\023\016\021\005 024\030\016\012\010!\016\003\016\006\017\004\006\031\010 011\005\014\034\005\014 026\016\027\005\010!\003\030\017\022\010\020\016\007\016\023\016\021\005 026\016\027\005\010\024\004\023\014\016\014\025 
002\030\003\003\005\017\007\004\030\006 002\003\004\005\006\007 002\003\004\005\006\007 002\003\004\005\006\007 003\030\017\022\010\002\014\005\016\007\004\030\006 011\017\033\005\012\032\003\004\006\031 0136\010\011\017\033\005\012\032\003\004\006\031\010 \030\003\004\017\004\005\021 002\005\006\007\014\016\003\010!\003\030\017\022\010 020\016\007\016\023\016\021\005 026\016\027\005\010 011\007\030\014\016\031\005 026\016\027\005\010 011\007\030\014\016\031\005 003\030\017\022\004\006\031\010\016\006\012\010 006\017\014\025\027\007\004\030\006\010 030\003\004\017\004\005\021 6\023\007\016\004\006\010\002\003\004\005\006\007\010 020\016\007\016\010\030\034\005\014\010 7\005\0078\030\014\022 6\023\007\016\004\006\010\002\003\004\005\006\007\010 020\016\007\016\010\007\033\014\030\032\031\033\010 3\005\012\004\016   011\007\016\031\005\010 011\007\016\031\005\010 
002\003\004\005\006\007\010\011\012\006\013\006\007\010\005 014\015\016\010\011\017\020\021\010\022\003\011\023\004\004\024\025\026 027\030\031\020\010\032\032\010\032\011\002\033\016\015\003\010\011\034\035\036\011 037\010\006\016\003\015\031\010\011 \006\026\010\011 037\010\006\032\010\005\011 002\022!\010\032\025\016\010\005 034\015"\024\011 \006\026\010\011\035\025##\010\005 004\031\026\005\010""\010\032\011 \006\026\010\011\035\016\004\022\024 037\010\006\032\011\037\010\033\025\010"\003\011 025\010\025\010 006\026\010\011&\013\032\010'\011 027\030\031\020\010\032\032\010\032\011\002\033\016\015\003\010\011\034\035\036 006\026\010\011\034\006\003\006\011\002\003\005\010\006\031 037\010\022\010\015\(\010\005 006\026\010 006\026\010\011 037\004\020\004\003 006\026\010\011\037\010\006\032\010\005 014\015\020\005\010\011$!\006\013\013\010\016 004"\003\011*\032\006\026\003\010\005 006\026\010\011\034\006\003\006\011\002\003\005\010\006\031 002\010\013\032\010\005 005\015\003\010\011\037\010\033\025\010"\003\011 025\010\025\010 
FUSE is a frame w ork to help de v elop customized le system FUSE module has been ofìcially merged into the Linux kernel tree since kernel version 2.6.14 FUSE provides 35 interfaces to fully comply with POSIX le operations We design a le system using FUSE used at different tiers in the architecture The le system is monolithic but logically distributed and staged based on functionality as shown Figure 7 Figure 8 provides a block representation of the lesystem which is an important part of the middleware The collection servers the PUT-Collection servers and GETCollection servers implement modules which acquire client data to be written to or retrieved from tapes Based on client speciìc policies the data to be stored on tapes is encrypted and segmented Each of the segments are identiìed and accounted in local databases Similarly to retrieve data from tapes the lesystem queries the local databases and requests particular blocks from tapes and converts it to the pristine data The Tape Interface Machines TIM are networked to the collection servers and blocks of data are sent and received via high speed connections The load balancing server manages a workload based scheduling system in order to efìciently distribute data to various TIMs to avoid IO bottle necks The lesystem is highly customizable in the sense data from clients can be blocked and stored based on preference chosen by the clients For example video surveillance data should the client be able to obtain data by the hour must be handled differently as compared to be able to obtain data by days So the collection servers are responsible to block these data in a manner easy for retrieval The duties of the Load balancing servers are by far the most critical in the system It is involved in many services to all other entities and ensures that there is no data clogging at a certain point in the network First of all it acts as a contact point to all the clients who wish to store or retrieve data from the tapes After the client is authorized the load balancing The systemês data collection from the user can be performed in two main ways Data sets of smaller sizes which can be uploaded directly through the internet are stored in the Collection servers The client side has an application that requests a data upload session from the Load balancing server which then allocates the required amount of space in the collection server and initiates the client to directly upload its data to the speciìed location Another data acquisition protocol is designed for very large data sets where data is received in the form of storage media units itself The collection servers in this case provide a docking interface functionality where the media can be mounted directly on the servers and the extracted data be treated in the same way as uploaded data 
B Multi Tier File System C Load Balancing D Data Handling a Data Acquisition 
544 


002  002  1 
 T seek 
      002 
                      020 011"\002 010!\0246\002:\011 020 011"\002 010!\0246\002:\011 020 011"\002 010!\0246\002:\011 013\026 011"\002 010!\0246\002:\011 020 011"\002 010!\0246\002:\011                       020 011"\002 010!\0246\002:\011 020 011"\002 010!\0246\002:\011 020 011"\002 010!\0246\002:\011 013\026 011"\002 010!\0246\002:\011 020 002 010!\0246\002:\011 011"\002<\010 011"\002<\010 011"\002<\010 011"\002<\010 005\015\030\014\005\010\011\017\033\005\012\032\003\004\006\031 015\007\005\014\010\011\017\033\005\012\032\003\004\006\031 005\016\012\0104\010=\014\004\007\005\010>\005\016\012 005\016\012\0104\010=\014\004\007\005\010>\005\016\012 
Input Output while do if then for do if then else end if end for end if end while 
3\030\032\006\007\005\012\010 016\007\033 92\011"\010:\005\014\006\005\003\010 3\030\012\032\003\005 011\007\030\014\016\031\005\010 3\016\006\016\031\005\014 3\005\007\016\010\020\016\007\016 004\006\010"5\023\005\012\012\005\012\010\020 005\016\003\007\0045\005\010\026\016\027\005\010 011\017\033\005\012\032\003\005\014 026\016\027\005\0109\011 020\014\004\034\005\014\021 9\004\023\014\005\010\002\033\016\006\006\005\003\010 030\014\007 9\004\023\014\005\010\002\033\016\006\006\005\003\010 030\014\007 9\004\023\014\005\010\002\033\016\006\006\005\003\010 030\014\007 9\004\023\014\005\010\002\033\016\006\006\005\003\010 030\014\007 026\016\027\005 005\016\012\005\014 026\016\027\005 005\016\012\005\014 026\016\027\005 005\016\012\005\014 026\016\027\005 005\016\012\005\014 020\004\021\022\010\026\016\027\005\010!\032\015\015\005\014 013\006\012\005\03543\005\007\016\010\020\016\007\016\010 004\006\010"5\023\005\012\012\005\012\010\020 0209\011 013\006\007\005\014\015\016\017\005 0209\011\010 3\005\007\016\010\020\016\007\016 026\016\027\005\010\024\004\023\014\016\014\025 3\004\012\012\003\0058\016\014\005\010!\003\030\017\022 
t m r n x x x c x x x c i x i 
1 2 1 2 
Once the data has been segmented at collection servers it is distributed to the TIM computers Data is distributed to a TIM based on its current IO queue depth Overloading a single TIM computer with more than required write requests would cause a long latency in the read process as they tend to pile up at a single TIM computer A record or a map of these segments are made and stored in the meta server Like any other cloud service the architecture is complex with a large number of tape drives In order to increase the IO bandwidth parallel reading and writing of data into multiple tapes can be envisioned This consideration however needs to be analysed from more than one perspective The larger the number of subdivisions the larger the latency induced by seeking for the data Yet a huge single read or write to tape can cause an increase in the waiting time of other requests Many task scheduling algorithms have been to impro v e performance of IO in tapes and better utilize drive resources but little has been done with the latest LTO5 tapes drives Based on the latency test results of the tape device we see that the seek time of the robotics takes a considerable longer time than reading or writing of data to the disk In order to improve time efìciency we schedule the I/O requests such that each request spends the least amount of time performing seek operations and longer periods of read or write operations From the latency analysis we can see that the the largest time consumption is by the seek grab and load into driver operations In order to make the system time efìcient we need to let the system spend most of the time reading from or writing data onto the tapes For this reason we have to schedule read and write operations in a way that the next operation to be performed is on a tape that is either the same tape or one that is closest to the current tape The scheduling algorithm is applied at the Tape Interface Machines after it obtains the data from the collection servers or after it receives a read read request from the load balancer Figure 10 has a representation of how the scheduling is done at the TIMs We evaluate our design and latency model for a scheduler called Closest Process First that does exactly this The algorithm is shown below Closest Process First Scheduler IV S YSTEM M ODELS In this section we describe several models to analyze system response time The assumptions and notations for the models are as follows i is the time to move the tape reader to the correct tape for the i th request and load the tape to the reader 
b Data distribution to Tape Interface Machines TIM c Distributed Tape Write/Read E Closest Process First Scheduling 
m tape tape  tape n request  request   request req req L L true req L i n L L L req L 
Algorithm 1 
tapes requests Drive/Rewinder Seek Path 1 New Request   Inìnity 3 Record current location of the drive/rewinder new request arrives of process to be performed 8 is closer to than before i in the schedule queue 11 
Fig 8 Logical diagram of a tape cloud node to show the relationship between the various functional units within the FUSE enabled tape cloud infrastructure Fig 10 The Closest Process First Schedule before scheduling\(top and after scheduling\(bottom 2 Location value of 4 5 wait for a request 6 7 Get location 9 10 place 12 move to next request 13 14 15 16 
545 


transf er transf er consume 
002 002 002 
          10 4 1 400 20 000    2  2  2   1 1  1 1 1 1 2 2  2  1 1 1 1 1          
Block Size 
  1 
A Response Time Model B System I/O Model  C Multiple Reader Model 
       
The data users request is loaded by blocks Once a block is loaded users can start processing the blocks for example applying the video analysis on the loaded block of videos while the next block can be loaded simultaneously The size of each block is chose to minimize the average response time The size of a block is denoted as  i,j is the time to wind the tape fast forward to the rst byte of the block to read for request is the average time to wind the tape fast forward to the rst byte read for request i,j is the time to either read the block frome the tape for the request is the average time to either read a block from the tape for the request is the data transfer rate of the tape  varies from 30MB/s to 160MB/s is the data consumption rate of the request which describes how fast users can nish processing the data that they request The response time of a user request is deìned as the length of the period starting from when the request is released and ending at the point all the data are fully consumed by the user For example if one user requests 200 GB data given     then the response time is 21,414s If multiple requests are queued and processed in the order of their arrival only after the only after the completion of the previous request the average response time would be very long As discussed before the data consumption rate is usually much smaller than the data transfer rate therefore it is beneìcial to read data partially in order to reduce the average response time for each request The I/O time based on the experiments conducted on the tape library has been analyzed to be the sum of three major components  is proportional to the distance between the tape drive and the location of the tape in the library that the robot has to cover Seeking process is very time consuming Thus we have to minimize the seek time by reducing both the number of the seeks and the time for moving the tape reader For the rst purpose the system chooses a large block size For the second purpose the system has to use an optimal schedule for processing the requests The data stored on the tape are logically organized as blocks A block is considered the minimum unit when reading from or writing to the tapes The block size can not be either too large or too small If the block size is too large it will block the following requests or make them to wait much longer On the other hand if it is too small frequent seeking to perform the next IO will degrade performance Generally the block size is set based on the fact that the transfer time of one block should be larger or much larger than the average seek time Here is an example to demonstrate how the block size is determined Assume that there are two requests in the queue each of them asks to load GB data Since the system uses a block size of  after the block is loaded from the tape to the hard drive it will take units of time to process During this period the reader can switch to process the other request to load the block which will take to load the block for that request Then the reader switches back and loads the block for the rst request which will take  Ideally if  the rst request will not even notice that its data loading process has been interrupted Generally if there are requests waiting in the queue as long as  the request will be processed smoothly without noticing that the data loading process has been interrupted If there are more than one readers available the scheduling problem is known to be NP-Hard Since it is impossible to nd the optimal solution we propose a partitioned solution for multiple reader scheduling as shown in Alg.2 In this design each reader is assigned to be responsible for a speciìc set of tapes Each reader only stops at the tapes assigned to it and skips the others For example if there are two readers and 100 tapes the rst reader may take care of the rst 50 tapes while the second reader are in charge of the rest The tapes in one set should be physically close to each other However this design may result in hot spot that is one reader may be busy all the time while others are idle To solve this the system allows the idle readers help to process the requests but have to be back to their own duties if requests to their assigned tapes arrive Algorithm 2 Partitioned Task Scheduling Algorithm for Multiple Tape Readers Input m 
BLK T j i T i i T j i T i i R T R R i i T s T s T  s T  s T T T T T D BLK j BLK/R k T T k T k k j T T j T j BLK/R T T k T k T T j T j w T p T p T p i 
wind th th wind th transf er th th transf er th transf er transf er Size R transf er consume th seek wind transf er consume I/O seek wind transf er seek th consume th seek wind transf er th th seek wind transf er consume seek wind transf er seek wind transf er BLK R i w p seek wind transf er th 
tapes 002 t   tape 1 tape 2   tape m  n tape readers 002 tr   reader 1  reader 2    reader n  Output Online Schedule for each coming requests 1 Assign the m tapes to n readers Each reader will take care at most 003 m/n 004 tapes which are close to each other 2 Store the assignments to the global schedule manager 3 while TRUE do  5 Get the meta-information of the req from the database and nd the tape id for req  6 Forward req to the reader which is in charge of the requests for tape id  7 Schedule req at the reader locally using elevator schedule algorithm 8 end while 
4 Wait for the next request req 
546 


002 005\002 006.\002 003\006\002 003-\002 007\004\002 006\002 002 006\004\002 003\003\002 0031\002 007"\002 007\002 004\002\002 011\014\015\025\011\020\\030\013\032\023\030\011\020\010\024\012\011\021\012\024\023\027 5\032\0317\020\036\0248\011\020\021/%\027 
T 
seek 
TABLE II T ANDGERG T24 L OAD AND U NLOAD D ELAYS Fig 11 Average Response Time under Different Block Sizes V E VALUATION We simulate a tape cloud node having 100 tapes and up to 10 tape readers used simultaneously to evaluate our design The parameters used in the simulation are measured from an actual Tandberg LTO-5 tape library 19 The physical capacity per cartridge is 1.5 TB the data transfer rate is 140 MB/s the rewind speed is 10 meters/sec the tape length is 846 meters the cartridge memory is 8 KB the load and unload delays are summarized in Table II In the rst set of experiments the average response time under different block sizes are studied Each user request requires 1TB tape data in total In this experiment the number of tape reader is one User requests are randomly generated Data is read and processed by blocks The consumption rate is 20MB/s As discussed in section IV-B once one block of data is loaded the tape reader switch to serve the next request As shown in Figure 11 when the block size is between 50GB and 100GB the average response time is minimized Fig 12 Average Response Time under Different Scheduling Algorithms Fig 13 Average Response Time Using Globally Partitioned Workspace Fig 14 Average Response Time Using Partitioned and Unpartitioned Scheduling Algorithms In addition if the block size is too large the average response time will increase signiìcantly The average response time with the block size of 500GB is almost 1.5 times of that with the block size of 50GB Second the average response time results under two different scheduling algorithms i.e First Come First Serve FCFS and Closet Process First CPF are shown in Figure 12 Up to 80,000 requests are generated and their response times are measured According to the results the CPF scheduling algorithm saves around 80 of the response time When handling multiple tape drives we either have the option of creating an any-tape to any-drive environment where a drive has access to any tape in a limited system or we can partition the system such that a drive services only a speciìc set of tapes referred to as Global partitioning Global partitioning also avoids uncontrolled tape seek time 
002 004\002 006\002\002 006\004\002 003\002\002 003\004\002 007\002\002 007\004\002 002 003\002.\002"\002-\002\006\002\002 011\014\015\025\011\020\\030\013\032\023\030\011\020\010\024\012\011\020\021\012\024\023\027 9\020\032:\020\014\011;\017\011\030\016\030\020\021<\006\002\002\002\027 022*\036 022 
    
Type From To Motion\(sec Load\(sec Type From To Motion\(sec Load\(sec Average 63.64 33.1 Average 62.37 31.21 
002 004 006\002 006\004 003\002 003\004 006 006\003\003\007\007..\004\004""\005\005!#\011\014\015\025\011\020\\011\030\013\032\023\030\011\020\010\024\012\011\021\012\024\023\027 9\020\032:\020\014\011;\017\011\030\016\020\021<\006\002\002\002\027 0\024\016\034\032\017\016\020/5\0326\0155\020,\015\014\016\024\016\024\032\023 0\024\016\034\020/5\0326\0155\020,\015\016\024\016\024\032\023 
which from our study can be seen to be most expensive Employing global partitioning decreasing the average response time for requests as shown in Figure 13 We also found that the scheduling algorithms get affected when we use global partitioning The average response time results when using multiple readers are evaluated in Figure 14 One or more up to 10 tape reader are enabled to work simultaneously Two different scheduling algorithms are compared the partitioned algorithm shown in Alg.2 and the unpartitioned algorithm which allows each reader to serve any tapes in the library The results are presented in Figure 14 As the number of working tape readers increase the average response time is reduced accordingly However when the number of tape readers goes beyond 5 both scheduling approaches show 
LOAD 1 Drive 62.4 33.3 UNLOAD Drive 1 61.6 30.1 LOAD 2 Drive 62.9 31.9 UNLOAD Drive 2 62.3 30.6 LOAD 3 Drive 64.06 32.6 UNLOAD Drive 3 62.26 30.3 LOAD 4 Drive 65.2 34.6 UNLOAD Drive 4 64.0 30.3 LOAD 5 Drive 62.42 34.0 UNLOAD Drive 5 61.3 30.9 LOAD 6 Drive 63.3 33.6 UNLOAD Drive 6 61.76 31.01 LOAD 7 Drive 64.2 31.3 UNLOAD Drive 7 62.22 30.1 LOAD 8 Drive 65.45 33.9 UNLOAD Drive 8 63.8 29.62 LOAD 9 Drive 61.8 34.0 UNLOAD Drive 9 60.7 30.3 LOAD 10 Drive 62.3 31.6 UNLOAD Drive 10 61.4 30.34 LOAD 11 Drive 63.7 32.23 UNLOAD Drive 11 61.97 33.9 LOAD 12 Drive 64.02 33.8 UNLOAD Drive 12 63.6 32.59 
002 006\002\002 003\002\002 007\002\002 002\003."-\006 002 011\014\015\025\011\020\\030\013\032\023\030\011\020\010\024\012\011\020\021\012\024\023\027 9\020\032:\020\010\015\013\011\020\035\014\024#\011\014\030 015\014\016\024\016\024\032\023\011\026 036\031\034\011\026\0175\024\023\025 3\023\013\015\014\016\024\016\024\032\023\011\026 036\031\034\011\026\0175\024\023\025 
547 


little changes in response time This is because under the current workload 5 readers are able to serve the requests efìciently Even if more readers are added some of them will be idle for most of the time Figure 14 indicates that the partitioned scheduling algorithm performs much better than the unpartitioned one VI R ELATED W ORK In spite of the potential to be the most scalable and cost efìcient solution for meeting the growing storage demand cloud based services leveraging tapes have received little or almost no attention from the academic research community To our best knowledge our paper is the rst and the only one that provides a complete tape based service model and integrates large scale tape infrastructure with the cloud In industry there has been a long history of improving the existing and designing new tape libraries for enterprise customers e.g Hewlett-Packard StorageWorks ESL/EML IBM TS3400/TS3500 Quantum Scalar Oracle StorageTek These tape libraries are designed as end-user products for the enterprise users to own their own on-premise tape infrastructures Our efforts represent an opposite off-premise cloud based direction with the objective to provide low cost tape based storage to the users without the requirement to own a private tape infrastructure VII C ONCLUSION AND F UTURE W ORK We present and evaluate a design to provide a cloud storage system with tape media as backend which is a rst in its kind which implements centralized data storage facility using tape media We recognize some of the barriers of using tape technology both economically and operationally Some solutions and ideas are evaluated in order to reduce the consequences faced by these barriers and provide a smooth performance in data storage and retrieval process From the results obtained in design evaluation we can see that there is an increase in I/O throughput using the scheduling and parallel I/O models that are discussed in the paper thus paving way for the possibility of having large scale operations using these techniques The speed of data retrieval is critical for a cloud service Tape by nature has been used for backing up data and creating archives which means that request for data stored on tapes arrives with a probability that varies well below 1 as compared to other day-to-day cloud storage In this case the tape cloud data centers provide sufìcient security and safety against theft re and natural calamity as compared to on site backing up One of the most exciting aspects of our research is the opportunities it presents for future work Understanding the economics of revisiting a legacy system to solve the data explosion problems of today requires an overhaul of nearly every piece of technology associated with the storage system An interesting study to perform is the relation between the number of media units and the number of drivers used in large scale deployments Also we would like to implement an easy and direct interfacing system which allows the tape cloud to be connected directly to major cloud storage providers such as Dropbox or Google Cloud and see the effects of using tape media in conjunction with the storage media used by other storage providers Other plans of extension include the evaluation of tape cloud in applications which require much higher I/O throughput VIII A CKNOWLEDGEMENT We would like to thank the reviewers for their comments which signiìcantly improved the paper This research is partially supported by the National Science Foundation under Award Number CNS 1205708 The conclusions contained in this document are those of the authors and should not be interpreted as representing the opinions or policies of NSF R EFERENCES  Seagate V ideo surv eillance storage Ho w much is enough  County of cameras Cheshire constab ulary aims to count e v ery pri v ate camera in the county 
  D Ally  Choosing the appropriate storage media to collect video-based evidentiary data Digital Ally Inc Tech Rep 2009  W  Purvis The hot ne w storage technology for 2011 is tape  March 1 2011  J.-H Lee T  Feng W  Shi A Bedagkar Gala S K Shah and H Yoshida Towards quality aware collaborative video analytic cloud in  2012 pp 147Ö154  D S Rosenthal D Rosenthal E L Miller  I Adams M W  Storer  and E Zadok The economics of long-term digital storage in  Sep 2012  I F oster  Glob us online Accelerating and democratizing science through cloud-based services  vol 15 no 3 pp 70 73 May-June 2011  A J Ar gumedo D Berman R G Bisk eborn G Cherubini R D Cideciyan E Eleftheriou W H  aberle D J Hellman R Hutchins W Imaino J Jelitto K Judd P.-O Jubert M A Lantz G M McClelland T Mittelholzer C Narayan S  Olc∏er and P J Seger Scaling tape-recording areal densities to 100 gb/in 2  vol 52 no 4 pp 513Ö527 Jul 2008  J Jackson Most netw ork data sits untouched   July 2008 A v ailable http://gcn.com/Articles/2008/07 01/Most-network-data-sits-untouched.aspx  F  Moore T ape Ne w g ame ne w rules tape re-architects for 21st century data explosion A v ailable http://www horison.com Tape21stCentury.pdf  D Reine In search of the long-term archi ving solution tape delivers signiìcant tco advantage over disk  December 23 2010 A v ailable http://www clipper com research/TCG2010054.pdf  IDC W orldwide storage in the cloud 2010-2014 forecast Gro wth in public cloud storage services continues as rms decapitalize it  International magnetic tape storage roadmap   nov 2011  T w o thirds of disk-only users look to add tape into storage infrastructure  March 2008 A v ailable http www.storagenewsletter.com/news/tapes/lto-programsurvey-tape-disk  T andber g storagelibrary t24  Online A v ailable http://www.tandbergdata.com/us/index.cfm/products/tape-automation storagelibrary/storagelibrary-t24  I Drago M Mellia M M Munafo A Sperotto R Sadre and A Pras Inside dropbox understanding personal cloud storage services in  ser IMC 12 2012 pp 481Ö494  Fuse lesystem project  Online A v ailable http://fuse.sourcefor ge net  O Sandsta and R Midtstraum Impro ving the access time performance of serpentine tape drives in  1999 pp 542Ö551  Linear tape-open  Online A v ailable http://en.wikipedia.or g/wiki Linear Tape-Open 
CCTV Image Online Research Note Data Mobility Group IEEE CLOUD The Memory of the World in the Digital Age Digitization and Preservation Internet Computing IEEE IBM J Res Dev Government Computer News The Clipper Group INFORMATION STORAGE INDUSTRY CONSORTIUM Storage Newsletter Proceedings of the 2012 ACM conference on Internet measurement conference Data Engineering 1999 Proceedings 15th International Conference on 
548 


  9   Fi g u r e 9 A O T F s p e c t r u m o f ic y r e s id u e f r o m G S F C s  Co s m i c  I c e  L a b o r a t o r y    3  C ON C L U S I ON S  Th e  r e c e n t  i n t e g r a t i o n o f t h e A O T F P S a n d t h e L D T O F  ma s s  s p e c t r o me t e r a l l o w e d f o r c o i n c i d e n t s p e c t r a l  me a s u r e me n t s  o f  m in e r a l e s  g a d i r e c t  co m p ar i s o n  b et w een  t w o  co m p l em en t ar y  d at a s et s   an al y s i s  o f  o u r  i n i t i al  d at a s et  f r o m  t h e i n t eg r at i o n  p er i o d  i s  st i l l  u n d e r w a y   a n d  w e  c o n t i n u e  t o  m a k e  c d me a s u r e me n t s  o f  r e f e r e n c e  s a mp l e s   e  g   P A H  s  a n d  a mi n o  aci d s  o n  m i n er al  s u b s t r at es    Fu t u r e  m e a s u r e m e n t s  t o  b e  ma d e  w i t h  t h e  i n t e g r a t e d  i n s t r u me n t  i n c l u d e  a  w i d e r  a r r a y  o f  mi n e r a l o g i c a l  s a mp l e s   i n c l u d i n g  t h o s e  k n o w n  t o  b e  in h a b ite d b y m ic r o b e s   u ltim a te  g o a l f o r  th e  A O T F  P S  is  c o n f id e n t d e te c tio n  o f  u nc t i ona l  gr oups i n m i n e r a l o g i c a l s a m p l e s  T h e r e s u l t s  fr o m  o u r  fi r s t  i n t e g r a t i o n  w i t h  t h e  L D T O F  m a s s  sp e c t r o m e t e r  su g g e st  t h a t  th is  g o a l is  a c h ie v a b le  th r o u g h  car ef u l  d at a an al y s i s  an d  i n t er p r et at i o n  o f  o u r  A O T F  d at a   Th e  f i n a l  p h a s e  o f  t h i s  p r o j e c t  w i l l b e t o c h a r a c t e r i z e t h e  re l a t i o n s h i p  b e t w e e n  s p e c t ra l  f e a t u re s  i n  t h e  A O T F  d a t a  a n d  el em en t al  m as s  r es u l t s  o b t ai n ed  f r o m  t h e L D T O F  me a s u r e me n t s    T h i s  w i l l  h i g h l i g h t  t h e  e f f e c t i v e n e s s  o f  us i ng I R  r e f l e c t a nc e  m e a s ur e m e nt s   s uc h a s  t hos e  obt a i ne d wi t h  t h e  AO TF  P S   a s  a  p r e s c r e e n i n g  t o o l  t h a t  c a n  b e  u s e d  to in f o r m s u b s e q u e n t m a s s s p e c tr o s c o p y d a ta a c q u is i   Fi n a l l y   t he  A O T F  P S  c oul d a l s o be  de pl oye d a s  a  por t a bl e   d al o n e i n s t r u m en t  t o  m ak e itu m e a s u r e m e n t s  W e  pl a n t o de m ons t r a t e  t hi s  c a pa bi  ove r  t he  ne xt  12 24 mo n t h s  i n  N e w  M e x i c a n  f i e l d  e n v i r o n me n t s  o f  h i g h  as t r o b i o l o g i cal  i n t er es t  I n p r i n c i p l e b o t h t h e A O T F P S a n d  th e  L D T O F  c a n  b e  o p e r a te d  in  e ith e r  d a y tim e  o r  n ig h ttim e  co n d i t i o n s   p r o v i d ed  t h at  a co n t ex t  i m ag i n g  cam er a i s  n o t  re q u i re d   4   A CK NO W L E DG E M E NT S   Th i s  w o r k  w a s  s u p p o r t e d  b y  gr a nt s  f r om  N A S A  s  Ex p e r i m e n t a l  P r o g r a m  t o  S t i m u l a t e  C o m p e t i t i v e  R e s e a r c h  E P S C o R  a n d  A s t ro b i o l o g y  S c i e n c e  a n d  T e c h n o l o g y  In s t ru m e n t  D e v e l o p m e n t  A S T ID  p ro g ra m s   s p e c i f i c a l l y  th r o u g h  a w a r d  n u m b e r s  N N X 0 8 A Y 4 4 G A ST I D   a n d  NNX0 8 AV8 5 A  E P S C o R    Ad d i t i o n a l  s u p p o r t  wa s  pr ovi de d by N e w  M e xi c o T e c h  N M S U  s  A s t r onom y a nd El e c t r i c a l  a n d  C o m p u t e r  En g i n e e r i n g  D e p a r t m e n t s   t h e  N e w  Me x i c o  E P S C o R  p r o g r a m  o f f i c e   t h e  N MS U  V i c e  P r e s i d e n t  fo r  R e s e a r c h   a n d  t h e  N M S U  A D V A N C E  P r o   th a n k  D r s  R e g g ie  H u d s o n  a n d  P e r r y  G e r a k in e s  f r o m  GS F C  s  C o s m i c  I c e  L a b o r a t o r y  f o r  p r o v i d i n g  u s  wi t h  t e s t  sa m p l e s o f  i c y  r e si d u e s W e t h a n k R  H u l l f o r h i s  co n t r i b u t i o n s   th e  A O T F  P S  e le c tr o n ic s s y s t e m a n d h i s  pa r t i c i pa t i on i n t he  A O T F i nt e gr a t i on a c t i v i t i e s  We  a l s o  t h a n k  D r   D   M   K u e h n  f o r  h i s  c o n t r i b u t i o n  t o  t h e  de ve l opm e nt  a nd i m pl e m e nt a t i on of  t he  A O T F  P S  da t a  acq u i s i t i o n  s o f t w ar e   


  10  R ES  1  Vi s i o n  a n d  Vo y a g e s  f o r  Pl a n e t a r y  S c i e n c e  i n  t h e  D e c a d e  2013 2022 N a tio n a l A c a d e m y o f S c ie n c e 2 0 1 1   2  O  Ko r a b l e v   J  L  B e r t a u x   A   F e d o r o v a   D   F o n t e y n   A   St e p a n o v   Y   K a l i n n i k o v   A   K i s e l e v   A   G r i g o r i e v   V   Je g o u l e v   S   P e r r i e r   E   D i m a r e l l i s  J  P   D u b o i s  A   Re b e r a c   E   V a n  Ra n s b e e c k   B  G o n d e t   F   M o n t m e s s i n   an d  A   R o d i n    S P I CA M  I R a c o u s t o opt i c  s pe c t r om e t e r  ex p er i m en t  o n  M ar s  E x p r es s   J   G eo p h y s   R es   1 1 1   E0 9 S 0 3   d o i  1 0  1 0 2 9  2 0 0 6 J E0 0 2 6 9 6   2 0 0 6   3  J L  B e r t a u x  a n d  3 5  c o au t h o r s    S P I C A V  o n  V en u s  Ex p r e s s   Th r e e  s p e c t r o m e t e r s  t o  s t u d y  t h e  g l o b a l  s t r u c t u r e  an d  co m p o s i t i o n  o f t h e V e n u s a t m o s p h e r e   P l a n e t  S p a c e  Sc i   5 5   1 6 7 3 2007  4  D  A  Gl e n a r   J   J   Hi l l m a n   B   S a i f   a n d  J   B e r g s t r a l h   o opt i c  i m a gi ng s pe c t r opo la r im e tr y  f o r  r e m o te   A ppl   O pt i c s  33  7412 1994   5  D  A  Gl e n a r   J   J   Hi l l m a n   M  L e L o u a r n  R  Q  F u g a te  an d  J   D   D r u m m o n d    M u l t i s p ect r al  i m ag er y  o f  J u p i t er  an d  S at u r n  u s i n g  ad ap t i v e o p t i cs  an d  aco u s t o  im a g in g  P u b l. A s tr o n S o c P a c if ic 1 0 9 3 2 6 1997  6  D  A  Gl e n a r   D  L   B l a n e y   a n d  J   J   Hi l l m a n    AI M S   Ac o u s t o op tic  im a g in g  s p e c tr o m e te r  f o r  s p e c tr a l m a p p in g  of  s ol i d s ur f a c e s    A c t a  A s t r ona ut i c a  1824  1 2002   7  G  Ge o r g i e v   D  A  Gl e n a r   a n d  J   J   Hi l l m a n    S p e c t r a l  ch ar act er i zat i o n  o f  aco u s t o opt i c  f i l t e r s  us e d i n i m a gi ng sp e c t r o sc o p y    A p p l   O p t i c s 4 1   2 0 9 2 2002   8  N  J   C h a n o v e r   J   J   Hi l l m a n   a n d  D  A  Gl e n a r   M u l t i s p e c t r a l  n e a r IR  i m a g i n g  o f V e n u s  n i g h t s i d e  c l o u d  fe a t u re s     J   G e o p h y s   R e s   1 0 3   3 1 3 3 5 1998   9  N  J   C h a n o v e r   C   M   An d e r s o n   C   P   M c Ka y   P   Ra n n o u   D   A   G l e n a r   J   J   H i l l ma n   a n d  W   E   B l a s s   P r o b i n g  T i t a n  s  l o w e r  a t m o s p h e r e  w i t h  a c o u s t o  i ng    I c a r us  163  150 2003   0 T  J   C o r n i s h   S   Ec e l b e r g e r   a n d  W   B r i n c k e r h o f f   M i n i a t u r e  t i m e of fl i g h t  m a s s  s p e c t ro m e t e r u s i n g  a  fl e x i b l e  ci r cu i t b o ar d  r ef l ect o r   R a pi d C om m uni c a t i ons  i n M a s s  Sp e c t r o m e t r y  1 4   2 4 0 8 2000  1  N  J   C h a n o v e r   D  A  Gl e n a r   D  G  Vo e l z   X  Xi a o   R   Ta w a l b e h   P   J   B o s t o n   W   B   B r i n c k e r h o f f   P   R   M a h a f f y   S  G e t t y   I   t e n  K a t e   a n d  A   M c A d a m    A n  A O T F LD TO F  sp e c t r o m e t e r  su i t e  f o r  itu o r g a n i c d e t e c t i o n a n d  ch ar act er i zat i o n   2011 I E E E  A e r os pac e  C onf e r e nc e  Pr o c e e d i n g s i 1 0 1 1 0 9 A E R O 2 0 1 1 5 7 4 7 2 9 5   2 N  J   C h a n o v e r   R   T a wa l b e h   D  A  Gl e n a r   D  G  Vo e l z   X  Xi a o   K  Uc k e r t   P   J   B o s t o n   S   Ge t t y   W   B   Br i n c k e r h o f f   P   R  Ma h a f f y   T   C o r n i s h   a n d  S   Ec e l b e r g e r    R a p i d  a s s e s s m e n t  o f  h i g h  v a l u e  s a m p l e s   A n  F LD TO F  s p e c t r o m e t e r  s u i t e  f o r  p l a n e t a r y  s u r f a c e s    2012 I E E E  A e r os pac e  C onf e r e nc e  P r oc e e di ngs   3  N  C h a n o v e r  D  A  Gl e n a r   K  Uc k e r t     Vo e l z   X  Xi a o   R    T a wa lb e h  P  B o s t o n  W B r i n c k e r h o f f  S  G e t t y   an d  P   M ah af f y    Mi n i a t u r e  s p e c t r o m e t e r  f o r  d e t e c t i o n  o f  or ga ni c s  a nd i de nt i f i c a t i on of  t he i r  m i ne r a l  c ont e xt    Pr e s e n t a t i o n  a t  In t e r n a t i o n a l  W o r k s h o p  o n  In s t r u m e n t a t i o n  f o r  P l a n e t a r y  M i s s i o n s O c to b e r 2 0 1 2   4  R  L   F r o s t   R A  W i l l s   W   M a r t e n s  a n d  M   W e i e r   N I R  s p e c t r o s c o p y  o f  j a r o s i t e s    S p e c t r oc hi m i c a  A c t a  62  869 2005   5  M  S    B  Bo r n s t e i n   M   D   M e r r i l l   R  Ca s t a   an d  J   P   G r een w o o d    Ge n e r a t i o n  a n d  p e r f o r m a n c e  o f  au t o m at ed  j ar o s i t e mi n e r a l  d e t e c t o r s  f o r  v i s i b l e  n e a r in f r a r e d  s p e c tr o m e te r s  a t M a r s  Ic a ru s  195 9 183  2008  6  S  J   G a f f e y    Sp e c t r a l  r e f l e c t a n c e  o f  c a r b o n a t e  m i n e r a l s  in  th e  v is ib le  a n d  n e a r  in f r a r e d   0 3 5 2 55 m i c r ons    cal ci t e  ar ag o n i t e  an d  d o l o m i t e  A m er i can  Mi n e r a l o g i s t   700 1986   17  J  L   P o st  a n d  P   N  N o b l e    T h e  n e a r  co m b i n at i o n  b an d  f r eq u en ci es  o f  d i o ct ah ed r al  s m ect i t es   mi c a s  a n d  i l l i t e s    C l a y s  a n d  C l a y  M i n e r a l s   4 1   6 3 9  1993  8  R  N   Cl a r k   Ch a p t e r  1   S p e c t r o s c o p y  o f  Ro c k s  a nd Mi n e r a l s   a n d  P r i n c i p l e s  o f  S p e c t r o s c o p y   i n  Ma n u a l  o f  Re m o t e  S e n s i n g   Vo l u m e  3   Re m o t e  S e n s i n g  f o r  t h e  Ea r t h  Sc i e nc e s   A  N  R e n c z  e d    N e w Y o r k  J o h n W i l e y a n d  So n s   1 9 9 9   9  J  L   B i sh o p   C   M   P i e t e r s  R   G   B u r n s  J  O   E d w a r d s  an d  R   L   M an c in e lli  R e f le c ta n c e  s p e c tr o s c o p y  o f  f e r r ic  e be a r i ng m ont m or i l l oni t e s  a s  M a r s  s oi l  a na l og ma t e r i a l s     I c a r u s  1 1 7   1 0 1 1995  0  M  C r a i g   E   A   C l o u t i s   L   K a l e t z k e   K   Mc C o r m a c k  an d  L   S t ew ar t   A lte r a tio n  o f  h y d r a tio n  a b s o r p tio n  fe a t u re s  in  r e f le c ta n c e  s p e c tr a  o f  s e le c te d  s u lf a te s  in  a  lo w  pr e s s ur e  e nvi r onm e nt   0 45   m   L u n a r  a n d  Pl a n e t a r y  Sc i e n c e s  C o n f e r e n c e   2 0 0 6   1  F  R u l l   S  M a u r i c e   E   D i a z   C   T a t o   A   Pa c r o s   a n d  t h e  RL S  T e a m    T h e  Ra m a n  L a s e r  S p e c t ro m e t e r R L S  o n  th e  E x oM a r s  2018 r ove r  m i s s i on  L u n a r a n d P l a n e t a r y  Sc i e n c e  C o n f e r e n c e   2 0 1 1   


  11  2 2  E u ro p e a n  S p a c e  A g e n c y   A R o b o t i c E x p l o r a t i o n o f  Ma r s   T h e  E x o Ma r s  R o v e r  I n s t r u m e n t  S u i t e   R L S   Ra m a n  S p e c t r o m e t e r  h t t p    e x p l o r a t i o n  e s a  i n t  e e w w w  o b j ect  i n d ex  cf m  fo b j e c t i d  4 5 1 0 3  fb o d y l o n g i d   2130  N ove m be r  2012  3  D  P u l l a n   F   W e s t a l l   B   A  Ho f m a n n   J  a rn e l l   C   S   Co c k e l l   H   G M  E d w a r d s  S   E  J  V illa r  C  r d  G  C r e s s e y   L   M a r i n a n g e l i   L  R i c h t e r  a n d G   h f e r    n tif ic a tio n  o f  mo r p h o l o  bi os i gna t ur e s  i n M a r t i a n a na l ogue  f i e l d s pe c i m e ns  us i ng itu p l a n e t a r y i n s t r u m e n t a t i o n   A s t r o b i o l o g y   119  2008  2 4  G   K l i n g e l h f e r   R   V   Mo r r i s   B   B e r n h a r d t   C   r de r   D   S   R odi onov  P   A   de  S ouz a  J r    A   Y e n  R   Ge l l e r t   E   N E v l a n o v  B  Z u b k o v  J  F o h  U  B o n n e s  E   Ka n k e l e i t   P   Gu tlic h  D  W  M in g  F  R e n z  T  W d o w ia k  S  W   Sq u y r e s   a n d  R   E   A r v i d s o n    Ja r o si t e  a n h em at i t e an i P la n u m  f r o m  O p p o r tu n ity  s  M  ssb a u e r  s pe c t r om e t e r   S c ie n c e 3 0 6   1740  2004  5  I  F l e i s c h e r  G  K l i n g e l h f e r   D   S   R odi onov  E   N   Ev l a n o v   M   B l um e r s   B   B e r nha r dt   J   G i r one s L o p e z   J  Ma u l   O   F   P r i l u t s k i i   A   F   S h l y k   V   M  L i n k i n   a n d  dU s t on   Th e  m i n i a t u r i z e d  M s s ba ue r  s pe c t r om e t e r  MI MO S  I I  o n  t h e  P h o b o s Gr u n t  m i s s i o n     ond In t e r n a t i o n a l  C o n f e r e n c e  o n  t h e  E x p l o r a t i o n  o f  P h o b o s  os 2 0 1 1   6  A   K   K l i n g e rh    Mi n i a t u r i z e d  M s s ba ue r  sp e c t r o m e t e r  f o r  t h e  m i n e r a l o g i c a l  a n a l y si s o f  t h e  su r f a c e  of  pl a ne t  M a r s   i a c g u 3 2  c h e m i e  u n i ma i n z  d e  mi mo s  p h p   J a n u a r y  2 0 13  7  L  M   P r a t t   C   A l l e n   A   A l l w o o d   A   A n b a r   S   A t r e y a   M C a r r  D  D e s Ma r a i s  J  G r a n t  D  G l a v i n  V  H a m i l t o n   K  He r k e n h o f f   V  Hi p k i n   B   S h e r wo o d  L o l l a r   T   Mc C o l l o m   A   Mc E w e n   S   Mc L e n n a n   R   Mi l l i k e n  Mi n g   G  G  O r i J  P a r n e ll F  P o ul e t   a nd F  W e s t a l l    Th e  M a r s  a s t r o b i o l o g y  e x p l o r e r X  pot e nt i a l  r ove r  m i s s i on f or  2018  A s t r o b i o l  10 2  127  2010  8  S   A   G e t t y   W   B   B ri n c k e rh o ff  X   L i   M  A  M  F lo y d  R  D   A r e v a l o  J r    J   E l s i l a   M   Ca l l a h a n   T   J   Co r n  A  E c e l b e r g e r   N  C h a n o v e r   D  Vo e l z   X  Xi a o   R    Ta w a l b e h   K   U c k e r t   a n d  D   G l e   La s e r  de s or pt i on i oni z a t i on t i m e of fl i g h t  m a s s  s p e c t ro m e t ry  fo r  in  s itu p l a n e t a r y m i s s i o n s  P r e s e n t a t i o n a t  In t e r n a t i o n a l  W o r k s h o p  o n  In s t r u m e n t a t i o n  f o r P l a n e t a ry  Mi s s i o n s O c to b e r 2 0 1 2       B IO G R A P H Y  Na n c y  C h a n o v e r  is  a n  A s s o c ia te  Pr o f e s s o r   o f  As t r o n o m y  a t  N e w  Me x i c o  S t a t e  U n i v e r s i t y  a n d  s e r v e s  as  t he  P r i nc i pal  I nv e s t i gat or  of  t hi s  pr oj e c t    She  has  be e n i nv ol v e d i n th e  d e m o n s tr a tio n  a n d  im p le m e n ta tio n  o f A O T F  te c h n o lo g ie s  fo r  p la n e ta r y  s c ie n c e  si n c e  1 9 9 7    H e r re se a rc h  i n t e re st s i n c l u d e  t h e  v e rt i c a l  st ru c t u re  a n d  d y n a m i c s o f  p l a n e t a ry  a t m o sp h e re s a n d  in s tr u m e n t d e v e lo p m e n t  S h e  e a r n e d  h e r  P h D  fr o m  N e w  Me x i c o  S t a t e  U n i v e r s i t y  i n  1 9 9 7   z a P r o f e s s o r  in  th e  K lip s c h  S c h o o l o f El e c t r i c a l  a n d  C o m p u t e r  En g i n e e r i n g  a t  N e w  M e x i c o  St at e  U ni v e r s i t y    H e  has  be e n i nv ol v e d i n t he  de v e l opm e nt  of  opt i c al  sy st e m s i n v o l v i n g  A O T F  co m p o n en t s  s i n ce 2 0 0 2    Hi s  r e s e a r c h  i n t e r e s t s  in c lu d e  s p e c tr a l a n d  p o la r iz a t io n  s e n s in g  la s e r  b e a m  pr opagat i on t hr ough t ur bul e nc e   l as e r  c om m uni c at i ons  and i m agi ng t he or y    H e  e ar ne d a P h D   E E  de gr e e  f r om  th e U n iv e r s ity o f I llin o is in 1 9 8 7   r is a n E m e r itu s  pl ane t ar y  s c i e nt i s t  at  N A SA  s  Go d d a r d  S p a c e  F l i g h t   wh e r e  h i s  r e s e a r c h  in te r e s ts in c lu d e d h ig h  re so l u t i o n  sp e c t ro sc o p y   appl i c at i ons  of  A O T F s  f or  sp e c t ra l  i m a g i n g   a n d  ra d i a t i v e  t ra n sf e r m o d e l i n g   He  i s  c u r r e n t l y  S e n i o r  Re s e a r c h  As s o c i a t e  i n  t h e  As t r o n o m y  D e p a r t m e n t  a t  Ne w M e x i c o  S t a t e  U n i v e r s i t y  s o a m e m be r  of  t he  N at i onal  L unar  Sc i e nc e  e   


  12  o r e c e iv e d h e r  BS  a n d  M S  d e g r e e s  i n  phy s i c s  f r om  X i am e n Un i v e r s i t y  F u j i a n   C h i n a   in 1 9 9 8 a n d 2 0 0 1  re sp e c t i v e l y   S h e  e a rn e d  he r  M S and P hD  de gr e e s  i n el ect r i ca l  en g i n eer i n g  f r o m  Ne w M e x i c o  S t  Un i v e r s i t y  i n  2 0 0 4  a n d  2008  r e s pe c t i v e l y   w he r e  sh e  i s c u rre n t l y  a  p o st d o c    re se a rc h  i n c l u d e s si m u l a t i o n  and m ode l i ng of  f r e e r co m m u n i ca t i o n   l i q u i d cr ys t a l  p o l a r i z a t i o n   a n d  de m ons t r at i on and i m pl e m e nt at i on of  A O T F  te c h n o lo g ie s   Ru l a  T a wa l b e h    Do c t o r a l  s t u d e n t  i n  t h e  De p a r t me n t  o f  E l e c t r i c a l  and C om put e r  E ngi ne e r i ng at  N e w  M e x i c o St at e  Un i v e r s i t y   S h e  g r a d u a t e d  fr o m Y a r m o u k U n iv e r s ity  Jo r d a n  i n  1 9 9 7   a n d  s h e ea r n ed  h er  M S c f r o m  Jo r d a n  U n i ver s i t y o f  Sc i e nc e  and T e c hnol ogy  i n  2001  She  i s  i nt e r e s t e d i n f r e e  s pac e  opt i c s   s pe c t r os c opy  and opt i c al  ne t w or k s   Ky l e  U c k e r t r e c e i v e d  hi s  B S de gr e e  o phy s i c s  f r om   Un i v e r s i t y  i n  2 0 1 0  a n d  is  c u r r e n tly  a  g r a d u a te  st u d e n t  i n  t h e  As t r o n o m y  D e p a r t m e n t  at  N e w  M e x i c o St at e  Un i v e r s i  re se a rc h  h a s f o c u se d  on t he  anal y s i s  of  st e l l a r o c c u l t a t i o n  d a t a  to  s tu d y  N e p tu n e  s  at m os phe r e   and he  i s  cu r r en t l y w o r ki n g  o n  th e  d e m o n s tr a tio n  o f th e  A O T F  p o in t s p e c tr o m e te r  fo r  a s tr o b io lo g y     P e n e lo p e  B o s to n   Di r e c t o r  o f  t h e  C a  Ka r s t  S t u d i e s  P r o g r a m  a n d  a P r o f e s s o r i n t h e E a r t h   En v i r o n m e n t a l  S c i e n c e s  De p t   a t  N e w  M e x i c o  In s t i t u t e  o f  M i n i n g    Te c h n o l o g y   i n  S o c o r r o   NM    B o s t o n  i s  a l s o  A s s o c i a t e  D i r e c t o r  o f  t h e  Na t i o n a l  Ca v e  a n d  Ka r s t  R e s e a r c h  I n s t i t u t e  i n  Ca r l s b a d   NM     re se a rc h  f o c u se s o n  g e o m i c ro b i o l o g y  a n d  a st ro b i o l o g y  i n  ext r em e en vi r o n m en t s   ca ves   h o t  a n d  co l d  d es er t s   h i g h  la titu d e s  a n d  a ltitu d e s    h u m a n  life  s u p p o r t is s u e s  in  sp a c e  a n d  p l a n e t a ry  e n v i ro n m e n t s  a n d  u se  o f  ro b o t i c s t o  as s i s t  e x pl or at i on and s c i e n ce i n  ext r em e E a r t h  a n d  ext r a t er r es t r i a l  en vi r o n m en t s   S h e h a s  p u b l i s h ed  o ver  1 3 0  wo r k s  i n  h e r  c a r e e r   i n c l u d i n g  9 6  r e f e r e e d  p a p e r s    S h e  has  e di t e d 4 v ol um e s  and has  2 book s  i n pr oc e s s    She  i s  a Fe l l o w  o f  t h e  N AS A I n s t i t u t e  f o r  Ad v a n c e d  C o n c e p t s  d 2 0 0 0  a n d r e c e i v e d t h e L i f e t i m e A c h i e v e m e n t i n  Sc i e nc e  A w ar d f r om  t he  N at i onal  Spe l e ol ogi c al  Soc i e t y  2 0 1 0   B o s t o n  r e c e i v e d  h e r  P h D  i n  1 9 8 5  f r o m  t h e  U n i v   of  C ol or ado  B oul de r   on an A dv anc e d St udi e s  G r aduat e  Fe l l o w s h i p  f r o m  t h e  N a t i o n a l  C e n t e r  f o r  At m o s  Re s e a r c h   Bo u l d e r   C O   f o l l o w e d  b y  a  N a t i o n a l  Re s e a r c h  Co u n c i l  P o s t d o c t o r a l  F e l l o ws h i p  a t  NA S A  L a n g l e y  Re s e a r c h  C e n t e r     y   me mb e r  o f  t h e  P l a n e t a r y  En v i r o n m e n t s  L a b o r a t o r y  at  N A SA  s  G oddar d Spac e  Fl i g h t  C e n t e r    H e r  re se a rc h  i n te r e s ts  a r e  in  th e  ar e a of  s c i e nt i f i c  i ns t r um e nt  de v e l opm e nt  f or  i n s i t u pl ane t ar y  s c i e nc e   par t i c ul ar l y  i n t he  pur s ui t  of  unde r s t andi ng t he  or i gi n  e v ol ut i on  and pr oc e s s i ng of  


  13  or gani c  c he m i s t r y  i n our  Sol ar  Sy s t e m       Xi a n g  L i r e c e i v e d h i s B  S   m is tr y  fr o m  th e  P e k in g  U n iv e r s ity  C h in a  in  2 0 0 3  and P h D   i n P hy s i c al  C he m i s t r y  f r om  t he  J ohns  H opk i ns  Un i v e r s i t y  i n  2 0 0 9   He  h a s  b e e n  a  R e s e a r c h  A s s o c i a t e  wi t h  a  j o i n t  a p p o i n t m e n t  a t  t h e  U n i v e r s i t y  o f  M a r y l a n d   Ba l t i m o r e  C o u n t y  a n d  N AS A G o d d a r d  S p a c e  Fl i  Ce n t e r  s i n c e  2 0 1 1   H i s  r e s e a r c h  f o c u s e s  o n  t h e  d e t e c t i o n  of  t r ac e  e l e m e nt  and as t r obi ol ogi c al l y  r e l e v ant  or gani c  mo l e c u l e s  i n  p l a n e t a r y  s y s t e ms   l i k e  M a r s   He  i s  es p eci a l l y i n t er es t ed  i n  t h e d evel o p m en t  o f  T i m e of  and I on T r ap m as s  s pe c t r om e t e r s w i t h v a r i o u s i o n i z a t i o n  ng te c h n iq u e s   Wi l l  B r i n c k e r h o f f  sp a c e  sc i e n t i st  i n  t h e  Pl a n e t a r y  En v i r o n m e n t s  La b  a t  N A S A  s  G o d d a r d  Spac e  F l i ght  C e nt e r  i n Gr e e n b e l t   M D w i t h  pr i m ar y  r e s pons i bi l i t y  f or  th e  d e v e lo p m e n t o f th e  L D TO F  m a s s  s p e c t r o  th is  p r o je c t H e  h a s  fo c u s e d  re c e n t l y  o n  t h e  d e v e l o p m e n t  o f  m i n i a t u re  l a se r d ma s s  s p e c t r o me t e r s  f o r  f u t u r e  p l a n e t a r y  mi s s i o n s  a l o n g  wi t h  b a s i c  e x p e r i m e n t a l  r e s e a r c h  i n  a s t r o b i o l o g y  a n d  p r e bi ot i c  s y nt he s i s   D r   B r i nc k e r hof f  i s  i nv ol v e d i n t he  de v e l opm e nt  of  m as s  s pe c t r om e t e r  f or  bot h t he  2011 Ma r s  S c i e n c e  L a b o r a t o r y  a n d  t h e  2 0 1 8  E x o Ma r s  mi s s i o n s   


  14   


Copyright © 2009 Boeing. All rights reserved  Issues and Observations Initial load of one day of data ~ 7 hours Optimizations  Write data in batches  Use a mutable data structure to create data strings  Deploy a higher performance machine  Use load instead of insert  Use DB2 Range-Partitioned tables  Database tunings Time reduced from 7 hours to approx 30 minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Use a mutable data structure to create data strings  Original application created the SQL statement by appending elements to a Java String  It was taking five hours \(of the seven hours Strings  Instead Java StringBuilder used  Java Strings immutable  Time savings of 71.4 


Copyright © 2009 Boeing. All rights reserved  Optimizations Deployed on a higher-performance machine  Application ported from IBM Blade Center HS21 \(4GB of RAM and 64-bit dual-core Xeon 5130 processor to Dell M4500 computer \(4GB of RAM and 64-bit of quad-core Intel Core i7 processor  Reduced the time to thirty minutes Bulk loading instead of insert  Application was modified to write CSV files for each table  Entire day worth of data bulk loaded  Reduced the time to fifteen minutes 


Copyright © 2009 Boeing. All rights reserved  Optimizations Range-Partitioned tables \(RPT  To limit the size of tables, the original code created multiple tables per table type  This puts burden on the application to query multiple tables when a range crosses several tables  With RPT, user is not required to make multiple queries when a range crosses a table boundary  Increased the time to thirty minutes  Additional fifteen minute cost per day of partitioning enabled time savings during queries 


Copyright © 2009 Boeing. All rights reserved  Optimizations Database tunings  Range periods changed from a week to a month  Automatic table space resizing changed from 32MB to 512KB  Buffer pool size decreased  Decreased the time to twenty minutes Overall, total time savings of 95.2 


Copyright © 2009 Boeing. All rights reserved  20 IBM Confidential Analytics Landscape Degree of Complexity Competitive Advantage Standard Reporting Ad hoc reporting Query/drill down Alerts Simulation Forecasting Predictive modeling Optimization What exactly is the problem What will happen next if What if these trends continue What could happen What actions are needed How many, how often, where What happened Stochastic Optimization Based on: Competing on Analytics, Davenport and Harris, 2007 Descriptive Prescriptive Predictive How can we achieve the best outcome How can we achieve the best outcome including the effects of variability Used with permission of IBM 


Copyright © 2009 Boeing. All rights reserved Initial Analysis Activities Flights departing or arriving on a date Flights departing or arriving within a date and time range Flights between city pair A,B Flights between a list of city pairs Flights passing through a volume on a date. \(sector, center, etc boundary Flights passing through a volume within a date and time range Flights passing through an airspace volume in n-minute intervals All x-type aircraft departing or arriving on a date Flights departing or arriving on a date between city pair A,B Flights departing or arriving on a date between a list of city pairs Flights passing through a named fix, airway, center, or sector Filed Flight plans for any of the above Actual departure, arrival times and actual track reports for any of the above 


Copyright © 2009 Boeing. All rights reserved  Initial SPSS Applications Show all tracks by call sign 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case For a given Airspace Volume of Interest \(AVOI compute distinct traffic volume at some point in the future  Aim to alert on congestion due to flow control areas or weather if certain thresholds are exceeded  Prescribe solution \(if certain thresholds are exceeded Propose alternate flight paths  Use pre-built predictive model  SPSS Modeler performs data processing Counts relevant records in the database \(pattern discovery Computes traffic volume using statistical models on descriptive pattern Returns prediction with likelihood 


Copyright © 2009 Boeing. All rights reserved  Predictive / Prescriptive Analytics Use-Case Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  24 Pulls in the TRACKINFO table of MAIN using SQL Limits the data to database entries which fall inside the AVOI Combines the SOURCE_DATE and SOURCE_TIME to a timestamp that can be understood by modeler Computes which time interval the database entry falls in. The time interval is 15 minutes Defines the target and input fields needed for creating the model Handles the creation of the model Produces a graph based off of the model results Final prediction 


Copyright © 2009 Boeing. All rights reserved  Initial Cognos BI Applications IBM Cognos Report Studio  Web application for creating reports  Can be tailored by date range, aircraft id, departure/arrival airport etc  Reports are available with links to visuals IBM Framework Manager  Used to create the data package  Meta-data modeling tool  Users can define data sources, and relationships among them Models can be exported to a package for use with Report Studio 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 1 of 3 Report shows the departure date, departure and arrival locations and hyperlinks to Google Map images DeparturePosition and ArrivalPosition are calculated data items formatted for use with Google Maps Map hyperlinks are also calculated based on the type of fix 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 2 of 3 DeparturePosition, Departure Map, ArrivalPosition and Arrival Map are calculated data items \(see departure items below DepartureLatitude DepartureLongitude DeparturePosition Departure Map 


Copyright © 2009 Boeing. All rights reserved  Flights Departing Las Vegas on Jan 1, 2012 3 of 3 


Copyright © 2009 Boeing. All rights reserved  Conclusion and Next Steps Current archive is 50 billion records and growing  Approximately 34 million elements per day  1GB/day Sheer volume of raw surveillance data makes analytics process very difficult The raw data runs through a series of processes before it can be used for analytics Next Steps  Continue application of predictive and prescriptive analytics  Big data visualization 


Copyright © 2009 Boeing. All rights reserved  Questions and Comments Paul Comitz Boeing Research & Technology Chantilly, VA, 20151 office Paul.Comitz@boeing.com 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  31 


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  32 Backup Slides 


Copyright © 2009 Boeing. All rights reserved  Initial Approach Initial Investigations  Apache Solr/Lucene  Data Warehouse Evaluate Hadoop in the future 


Copyright © 2009 Boeing. All rights reserved  Using SOLR Uncompress Track Information Messages To use with Solr  Transforming track messages from their  original schema to Solr required building a ìkey, valueî list using an XSTL  Queries made against this list of ìkey, valueî pairs Transformation Process  One day of data ~ 4.5 hours Once transformation complete search/query performance very good Geo spatial queries using  unique query language 


Copyright © 2009 Boeing. All rights reserved  Representation Aviation data is frequently represented in more than one form 



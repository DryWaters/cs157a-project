Large Scale Predictive Analytics for Real-Time Energy Management   Natasha Balac, Tamara Sipes, Nicole Wolter, Kenneth Nunes, Bob Sinkovits, Homa Karimabadi University of California, San Diego La Jolla, CA USA natashab@sdsc.edu   Abstract As demand for cost-effective energy and resource management continues to grow, intelligent automated building solutions are necessary to reduce energy consumption, increase alternative energy sources, reduce operational costs and find interoperable solutions that integrate with legacy equipment without massive investments in new equipment and tools. The ability to analyze understand and predict building behavior offer tremendous opportunities to demonstrate and validate increased energy efficiencies, which may ease many particular exorbitant pressures taxing the grid. In this paper, we describe a research platform driven by an existing campus microgrid for developing large scale, predictive analytics for real-time energy management  Keywords—data mining, smart grid, big data, time series I  I NTRODUCTION  Advances in technology have led to an unprecedented ability to collect and store data. Harnessing the real-time streaming sensor data from modern electric microgrids and smart grids via advanced processing, modeling optimization, real-time forecasting and analytics is a major challenge due to the sheer volume, complexity, and rate of acquisition. Managing and controlling actual energy delivery is an optimization and prediction problem that depends on many factors, some of which are present in monitoring within the grid itself, and some of which are only available outside the system, such as weather residents’ behavior and economics University campuses offer a comprehensive setting to deploy a microgrid and to maximize its operational benefits In addition, it offers a unique assemblage of both intellectual and physical resources, including cutting-edge analytics and high performance computing resource needed to successfully analyze this vast amount of continually produced heterogeneous stream data. We present a forward thinking, innovation engine employing novel time series prediction algorithms to improve operational efficiency lower operating costs, and reduces the overall carbon footprint of the microgrid II  S MART G RID  A  Smart Grid A smart grid is a modernized electrical grid that uses information and communications technology to gather and act on information about the behaviors of suppliers and consumers, in an automated fashion.  The goal of the smart grid is to improve the efficiency, reliability, economics, and sustainability of the production and distribution of electricity T h e pres e n t d a y electric g r id w a s orig i n all y built in the 1890s and improved upon as technology advanced through each decade. Today, it consists of more than 9,200 electric generating units with more than one million megawatts of generating capacity connected to more than 300,000 miles of transmission lines T h e digital technology enabling two-way communication between the utility and its customers, and the sensing along the transmission lines is what makes the grid smart Similarly to the Internet, the Smart Grid consists of controls, computers, automation, new technologies and equipment working together.  In the case of the smart grid these technologies need to work with the electrical grid to respond digitally to quickly changing electric demand.  The predictive power of the time series methods is of critical importance for enabling an efficient smart grid performance B  UCSD Microgrid Environment The University of California, San Diego \(UCSD\s the owner-operator of a 45 MW peak load Smart Grid and one of the first adopters of many new technologies, including multiple renewable and non-renewable energy generation resources, significant energy storage, and sophisticated monitoring for controlling flex-demand loads for a community of 54,000 energy consumers with an effectually, insatiable demand. With an aim of nurturing consumer adoption of energy-efficient vehicles, UCSD has made considerable progress in a adopting a campus-wide electric-vehicle \(EV\leet that includes providing direct-tosolar plant connections and storage for solar plant power production S D s 45 MW Microg rid in cl u d es a  master controller and optimization system that self 2013 IEEE International Conference on Big Data 978-1-4799-1293-3/13/$31.00 ©2013 IEEE 657 


generates 92% of its own annual electricity load and 95 of its heating and cooling load. It also owns and maintains a 69 kV substation, ninety-six 12kV underground feeder circuits and four 12kV distribution substations throughout the 1200-acre campus C  System Architecture Current smart grid integration has been conducted through a public-private partnership consisting of UCSD researchers and staff, and the resources of Power Analytics and OSISoft’s hardware, software and expertise combined to create a smart grid master controller. In collaboration with our industry partners, UCSD has developed a microgrid master controller that can monitor and control real time operations of the microgrid, and conduct power system analysis to verify reliability constraints for the planning and operation of the microgrid. Integration of predictive analytics with the smart grid master controller’s optimization and scheduling capabilities is dramatically improving the energy management team’s ability to optimize indigenous resources and import energy, as well as export surpluses and shed loads when lucrative capacity energy and ancillary price signals are received.  UCSD now saves more than $800,000 per month through use of its own system microgrid generation when compared to the alternative of being a direct access customer importing from the grid The UCSD microgrid power system and building facilities are highly instrumented, and currently monitor approximately 84,000 data streams per second and is designed for expeditious integration of distributed energy resources \(DER\The microgrid controller is integrated with OSI Soft’s PI data server on campus. Data collection and data analysis techniques are centrally managed by the on campus PI servers, which are interfaced with the Power Analytics’ microgrid controller. The UCSD microgrid also has one of the nation’s largest academia installations of synchrophasors \(phasor measurement units [PMU  fo r  data collection and data processing, which includes Gordon’s data intensive capabilities. Ultimately, the microgrid controller is also expected to utilize this data to provide the capability to operate the UCSD microgrid in an islanded condition. Local and national government as well as utility entities are collaboratively engaged to utilize the UCSD microgrid to improve management and efficiencies of the utilities and statewide grid operations such as demand response, excess generation, renewable supply load balancing and power outages D  Microgrid Data Collection Data collection and analysis software is centrally managed through eight servers interfaced with the Power Analytics’ master controlle. Two servers are dedicated to OSISoft interfaces; two are web servers for Power Anralytics master controller and OSISoft web services; one is an OSISoft PI server, and one is hosting Viridity’s pro Viridity’s software. See Figure 1  Figure 1. UCSD Microgrid Platform Since February 2011, the UCSD campus data acquisition system has collected continuous measurements from the heating, ventilation and air conditioning \(HVAC system at one-minute intervals. They include more than 17,000 measurements from the network simulation model nearly 10,000 additional measurements from electric power meters, and a large number of dependent variables computed in real time. The UCSD microgrid power system and building facilities are highly instrumented, and currently monitor approximately 84,000 data streams per second and is designed for expeditious integration of distributed energy resources \(DER\he steady state archive writes exceed 500,000 events per second. The simultaneous read rate is over 20,000,000 events per second and growing as more assets and more powerful sensors are added to the system daily. This very large complex data holds enormous potential for discovering patterns and forecasts that can create significant energy savings.  Advanced forecasting and “big data” analytics techniques are employed in order to realize real improvements in energy efficiency and reductions in the energy cost of the campus microgrid, as presented below III  B IG D ATA P ROCESSING POWER  A  Computing Architecture The SDSC’s Gordon system was specifically designed for data-intensive workloads and careful attention was paid to data movement and capacity at all levels of the memory hierarchy. Each dual socket node contains two eight-core Intel Sandy Bridge processors and 64 GB of DDR3-1333 memory. With four channels per socket, the Gordon compute nodes have a theoretical peak memory bandwidth of 85 GB/s. Groups of sixteen compute nodes are connected to pairs of 36 port switches using QDR InfiniBand \(40 Gb/s\d these switches are then networked into a 4x4x4 dual rail 3D torus. Each switch is also connected to an I/O node, which serves both as a router to the Lustre parallel file system and houses sixteen 300 GB Intel 710 Series \(Lyndonville\SDs. Pairs of bonded 10 GbE connections from the I/O nodes to the Lustre Object Storage Servers provide an aggregate bandwidth of up to 100 GB/s into Gordon 658 


The decision to place the SSDs in the I/O nodes and export using the iSER network protocol rather than physically installing on the compute nodes allows for significant flexibility in their deployment. For the majority of jobs using Gordon’s flash-based memory, one SSD is exported to each compute node and made available to user jobs as a 300 GB scratch file system. In some instances though, all sixteen SSDs are exported to a single “big flash” compute node and combined into a single RAID 0 device with a raw capacity of 4.8 TB   The other novel data intensive feature of Gordon is the use of ScaleMP’s vSMP foundation software to aggregate multiple compute nodes and the corresponding I/O nodes into large shared memory nodes. Although data exchange between physical nodes still takes place via the underlying IB network, the user is presented with a logical shared address space. The basic building block for the vSMP nodes is 16 compute nodes and one I/O node, with each unit contributing nearly 1 TB of DRAM and 4.8 TB of flash. Gordon currently has four of these 16+1 vSMP nodes in production, but has the flexibility to deploy more as needed, including 32+2 or larger configurations B  Hadoop Cluster Path SDSC has deployed a persistent 16-node Hadoop cluster with the Hadoop file system \(HDFS\ stored on the flash drives of the Gordon supercompute  All Gordon users have temporary access to flash storage. Typically, at the start of a job, the Torque prologue creates a temporary directory on the flash file system that is available for the duration of the job and deleted once the job finishes. For projects requiring Hadoop clusters or frequently accessed databases, persistent access is preferred. To accommodate these workloads, a portion of the Gordon system is reserved for dedicated I/O node projects In this case, the I/O node serves as the access point to the Hadoop cluster and as the management node. The I/O node hosts all metadata and resource management services whereas the compute nodes host the Hadoop Distributed File System \(HDFS\ data and execute map tasks and reduce tasks. HDFS is created on the flash drives that are exported via iSER and are presented to HDFS as local devices.  This platform is used for data exploration, preparation and cleaning for the purpose of this study.  A number of big data and especially smart grid analytics projects are consuming tools like R[6  M a ho ut 7   H i ve  8  a n d o t he r  Hadoop based technologies employed  on this platform due to the 4V’s a t u re of th e S m art g r id data C  Smart Grid Analytics Test Bed Figure 2 provides an overview of the analytics test bed The key steps in the process are described below. Campus building and energy data are collected from 86,000 distinct data streams, of raw data deposited to the PI server. The PI server performs cursory analysis, provides dashboard capability for visualization, and offers other management functions such as alerts and basic reporting  Figure 2. Analytics Test Bed Data Flow From the PI server, the data is transferred to the Data Oasis high performance file system over the SDSC LAN where it is staged for the real-time analytics. Numerically intensive statistical analysis is performed on the dedicated set of the Gordon compute cluster \(I/O nodes\ and results are staged on the Data Oasis file system. The final analysis results will be transferred from Data Oasis to the PI server where models will be integrated into the existing architecture for real-time scoring and predictions. From the perspective of the PI system, the data generated on Gordon is simply another data stream From Data Oasis, the original data and some subset of the derived data products can also be sent to the SDSC Cloud Storage environment for archive, reporting and future analysis IV  D ATA M INING  Predictive data analytics have the potential to greatly enhance the smart grid and amplify its impact by enabling the understanding of an increasing wealth of data about energy usage and the kinds of demands placed on the grid UCSD is committed to acquiring alternative forms of energy generation, with the goal of self-sufficiency and main grid independence by 2016. The campus utilizes smart grid data with advanced forecasting and “big data analytics in order to realize real improvements in energy efficiency and reductions in energy cost Buildings consume significant energy, and according to the DOE are responsible for 70% of the total electricity consumption of the US. UCSD, has over 450 buildings supported by a campus scale micro-grid.  In order to predict and manage energy use holistically across the buildings, we first need to create powerful predictive models for each building and then discover and consider their interdependencies by employing the vast amounts of heterogeneous data collected at the second level frequency from the smart grid.   Traditional time series models performance and scalability are innsuficient  for this large and compelx data.  We have employed scalable mutlivariate predictive analytics techniques to identify suspect and unforeseen performance behaviour.  This approach will enable the establishment of the baseline models for future measurement comparisons and creation of temporal and generalized building behavior consumption models Applying such approaches to the available data in the microgrid environment enables informed, real-time decisions and enhancements, resulting in a truly intelligent and optimized micro grid 659 


A  Data Description Campus building and energy data are collected for the UCSD Microgrid.  Data is currently collected from 86,000 distinct data streams, from approximately 30 different buildings on the UCSD Campus.  Data Streams, include measures and set points, are collected from the Building Management system, Johnson Control systems, which includes HVAC systems, the central utility plant, Schneider Electric power meters, as well as from photovoltaic panels network model output data and weather data stations at various location on campus.  The data collected includes measurements of airflow, carbon dioxide level, current damper position, dew point, humidity, power, pressure, real power, speed, temperature, valve, voltage Initial research focused on modeling three buildings which are representative of the majority of campus buildings.  The three buildings selected are newer buildings representing the leading edge of campus energy efficiency and technology and more importantly contain the most instrumentation for data collection.   The buildings include the San Diego Supercomputer Center, which includes computer rooms, conference rooms and office space EBU3B building is the home for the computer science department and it includes classrooms, conference rooms and offices.  The third building is called Pacific Hall and it consists of two large laboratory spaces.  In order to create highly accurate models, input attributes, algorithm parameters and environmental condition variables were chosen while exploring issues of seasonal variability and timing The buildings sensor data ranges from February 2011 and May 2013.  All three datasets contained the time stamp the year, month, day, outside temperature and the power usage \(in kW\ variables.  We added the time of the week Monday-Sunday\ariable as well as a workday flag \(=1 if yes, =0 if no B  Predicting Energy Consumption using Time Series Approach Modeling the energy usage behavior of campus buildings is an important step to improving the efficiency of the system. An accurate model of future energy usage compared to actual energy usage enables anomalies discovery in the actual data that may signify wasteful usage of energy. This predictive information is used to combat the high future demand or optimize pre-heating or pre-cooling scheduling to maximize the energy efficiency.  The shortterm predicted energy usage, can determine how much renewable energy should be used, help guide decisions regarding demand response, excess generation, renewable supply and load balancing and manage power outages Ultimately the microgrid controller will utilize these predictions to provide the capability to enable the operation of the UCSD microgrid in an islanded condition, if necessary The energy use in commercial buildings varies depending on many factors including weather, building insulation, equipment efficiencies, hours of equipment operation, system controls, building size, etc, overt time There are various modeling techniques that could be employed to analyze and predict building energy consumption.  Most of the traditional predictive methods overlook, discretize or require oversimplification of the temporal characteristic of the data in order to produce a model  order to capu t re th e te m poral n a t u re of the Smart Grid data we used a time series approach was chosen for energy demand forecasting and building behavior modeling due to the temporal nature of the Smart Grid data.  The strength of this model is that it can work on any building with existing historical or real-time energy consumption data.  The goal of this study is to create highly accurate models predicting energy demand for the campus micro grid at multiple levels of granularity.  The study presented below focuses on modeling building level energy behaviors Time series data containing multiple variables \(i.e multivariate time series data\monly occurs in a wide variety of fields including biology, finance, science and engineering. A time series \(or more generally temporal data\ a sequence of measurements that follow nonrandom orders and can be generated either from a fixedpoint measurement at several time intervals or a convolved spatial-temporal variation as measured from a moving detector. Multivariate time series analysis is used when one wants to model and explain the interactions among a group of time series variables. Much of the scientific data is in the form of multivariate time series. Examples include ECG measurements, energy consumption data, temperature, and sign language hand movements, among others  Multivariate time series classification attempts classification of a new time series based on past observations of time series examples, rather than providing an analysis of a single variate time series. A data mining technique called MineTool-TS is introduced which captures the time-lapse information in multivariate time series data through extraction of global features and metafeatures  Unlike traditional approaches such as Hidden Markov Models, recurrent Artificial Neural Networks, Dynamic Time Warping  17] a n d m o s t recentl y T c las s 18  MineTool can handle real-world, continuous, noisy data really well, and does not suffer from the large number of parameters, non-linear search and black-box model issues as well as the assumptions difficult to obtain in energy data If one could replace the time series by a static data consisting of variables that capture the relevant and interesting features \(e.g., number of zero crossings, slope extreme or average values\of the time series, then the standard MineTool technique could be used. Even though this approach is rather successful for a small number of simple datasets and problems, neither of these two approaches yields high accuracy results in modeling real life, complex time series data. Instead, we use a more sophisticated approach to extract features from multivariate time series data that yields much higher accuracy  C  MineTool for Static Data The core data-mining algorithm that underlies MineTool-TS is MineTool  T h e adv a n t ag e s of MineTool over traditional algorithms such as support vector machine and artificial neural net \(ANN automated steps that make it more accessible and 660 


applicable in a variety of domains, its accuracy and robustness and the analytical form of the model at the output An important algorithmic issue in data mining is how to find the optimal complexity of the model or the fitting function. Too much complexity in the model can result in model overfit, whereas not enough complexity can result in an underfit. The mathematical foundations of MineTool are based on considerations to balance the competing dangers of underfit and overfit to identify the level of model complexity that guarantees the best out-of-sample prediction performance without ad hoc modifications to the fitting algorithms themselves[19  2 0  Min e T o o l creates a  predictive model architecture that is linear in the parameters. The algorithm searches for a model M that best relates rows of the input variable values Xij to the appropriate target value yi \(yi = M\(Xij\here i = 1,…,N and j = 1,…,K. The model parameters are either linear combinations of the input \(Xi where prime indicates transpose of the vector, index i refers to the i th  observation   linear transformations of the input variables  Xi   or highly non-linear transformations of the input Xi  Equation \(1\ describes the general form of a MineTool model, and the specifics of the method in given in [14  11   Q P i pq y     iipiqq X X X  1. MineTool Model Equation In its simplest form, the model would be a linear combination of the input parameters \(i.e., a linear regression model\eTool goes beyond a simple linear model by introducing the linear \(such as level-1 and level-2 transformations producing cross-products, ratios, squares cubes etc.\d non-linear transformation of the input variables, if their addition increases the model accuracy The non-linear transforms are single hidden layer feed forward ANN-like transforms, just like the ANNs of the same architecture, with the difference that the non-linear transformed inputs are combined into a linear model Metafeature and Global Feature Detection To be able to process a \(time\ataset \(represented with multiple rows of data describing one instance or observation\ using MineTool, the data needs to be “flattened,” or made static This needs to be accomplished without losing the important information incorporated in sequential measurements varying with time. Historically, this has been done either by summarizing the data and writing only the mean of the different row values of one observation, or recording the difference between the pairs of rows and then treating them as single instance entries. These techniques work somewhat well on just a limited set of time series problems. For real life, complex scientific datasets, these approaches are most often too weak to incorporate the important time changes in the data. The MineTool-TS solution to this problem is to collect the important time-changing information that can occur in one of the time series variables. While a value varies with time, it most often increases, decreases or stagnates. There are other, more complex features one can record, that consist of the three basic changes, such as bipolar signature \(relevant in case of flux transfer events where a value goes up, then goes down crossing the axis and goes up again \(the sinusoid function demonstrates the bipolar behavior, for example\eatures, just like the metafeatures, are used to extract the information from all the rows representing one observation. Global features describe one instance of rows using one measurement, such as: the maximum value, minimum value, mean, mode or the number of zero crossings. The metafeatures and global featu res included in the MineTool-TS algorithm are listed here \(all used in the analys except for the bipolar feature  Increasing Metafeature An increasing metafeature is recorded for all the consecutive rising time-series measurements. For each increasing event, we record its start point, duration, gradient and average value, so that the increasing events can be used for analysis and comparison Decreasing Metafeature A decreasing metafeature is recorded for all the consecutive reducing time-series measurements. For each decreasing event, similar to the increasing events, we record starting point, duration gradient \(which is negative in this case\d average value Plateau Metafeature A plateau metafeature is recorded for all the consecutive non-changing time-series measurements. MineTool-TS allows for a small amount of noise to be ignored, so that the true plateaus are captured Bipolar Signature Metafeature A bipolar signature metafeature is recorded for all the consecutive time-series measurements that increase, decrease and cross the zero and increase again Global Minimum For each single variable, the global minimum feature extracts the minimum value of all of the time observations belonging to one time series instance for the variable, and records it as the global minimum feature for that input channel Global Maximum The maximum value of all of the time observations belonging to one time series instance for the variable is recorded as the global maximum feature for that variable Mean The average value of all of the time observations belonging to one time series instance for the variable is recorded as the global mean feature for that specific variable Mode The mode value of all of the time observations belonging to one time series instance for the variable is recorded as the global mode feature for that specific input variable Number of Zero Crossings Lastly, the number of zero crossings occurring during the time observation recorded measurements is written down as the number of zero crossings global feature Next, once all the requested features are collected, the MineTool-TS algorithm performs the feature space segmentation to group similar features and makes them have a higher predictive value for data mining. More details on the algorithm can be found in  D  Modelling Results We provided a three-level predictive analysis of power usage: static analysis \(where all the sensor information 661 


entries are thought of as independent instances\ and time series \(where the entries are considered a part of a time series, i.e. time dependent measurements\or all three datasets \(CogSci, PAC Hall and SDSC Building data\he three buildings have different usage profiles, different schedules, occupancy and energy needs In the static case, we compared the results of static MineTool to a multilayer perceptron method \(an artificial neural network \(ANN\method   In th e cas e of  time series analysis, we used the MineTool-TS method described above To prepare the data for time series analysis, the dataset was treated as a set of one-hour long streams of data Below, we demonstrate the results of the static vs. time series analysis and show the accuracy achieved in predicting the energy usage for each of the different buildings Dataset 1 – CogSci Building Data  Table 1 demonstrates the results of the static vs. time series analysis for the first dataset, the CogSci building data.  We used the 10-fold cross validation evaluation and the table lists the standard numerical prediction evaluation measures: CC mean absolute error\d RMSE \(root mean squared error From the multivariate time series classification analysis point of view, out of all the standard metafeatures \(such as increment, decrement and plateau features\ and the global features \(such as mean, number of zero crossings\he best performing feature chosen by the algorithm was the mean as well as the plateau feature with a relaxed noise level This is due to the fact that the fluctuations within an hour are minimal, and there are no distinctive increases and decreases within the one hour long streams that have a high predictive capability Figure 3 demonstrates a part of the time series prediction model represented in a tree form. We can see that workday, hour of the day, month of the year and the temperature all seem to have a high predictive ability in forecasting the usage, and that the workday seems to be the highest determining factor of the levels of power usage Table 1 demonstrates that treating the data as time series indeed leads to stronger model accuracy. MineTooTS achieved the correlation coefficient of 0.9, as tested using 10-cross validation, whereas the static analysis only yielding accuracy at the random guessing level of below 0.49 and 0.44 TABLE 1. COMPARATIVE ANALYSIS OF POWER USAGE MODELS FOR THE COGSCI DATASET  Analysis Method CC MAE RMSE Static MineTool 0.4939 3.4812 7.3371 Static ANN 0.4436 6.8216 8.5553 Time Series MineTool 0.9013 2.6971 3.8941   Figure 3. Part of the CogSci Power Usage Prediction Model  We believe that adding more measurements, such as the occupancy, class schedule and similar information to the current data would increase the accuracy of the models Furthermore, campus events, cloud coverage and similar variables would, we believe would increase the predictive accuracy even further  Dataset 2 – PAC Hall Data  We provided a slightly different two-level analysis of the PAC Hall dataset. To be able to compare the time series analysis to the standard data mining, we preprocessed the second building data by averaging the values within each hour stream of the data Table 2 illustrates the results of the static averaged data vs time series analysis for this dataset.  We also used the 10fold cross validation evaluation and the table lists the standard numerical prediction evaluation measures: CC mean absolute error\d RMSE \(root mean squared error Table 2 above confirms that treating the data as time series leads to stronger model accuracy.  MineTool-TS achieved the accuracy of 0.95 correlation coefficient, tested using 10-cross validation, whereas the static analysis performed on the hour averages data yielded 0.64 CC accuracy Figure 4 demonstrates a part of the time series prediction model represented in a tree form. We can see that in the case of PAC Hall data, the power usage has changed from year 2011 to 2012, and year 2013 as well, as the predictive analysis output shows a distinct submodel for 2011. In the case of this building, particular day of the week seems to have a higher predictive ability as well, not just a workday as in the case of the previous dataset.  Hour of the day, month of the year and the temperature all still seem to have a high predictive ability in assessing the usage as in the CogSci dataset case TABLE 2. COMPARATIVE ANALYSIS OF POWER USAGE MODELS FOR THE PAC HALL DATASET  Analysis Method CC MAE RMSE Static ANN 0.6354 3.8081 5.1177 Time series MineTool 0.9508 1.3368 2.0348  662 


TABLE 3. COMPARATIVE ANALYSIS OF POWER USAGE MODELS FOR THE SDSC DATASET Analysis Method CC MAE RMSE Static ANN 0.7589 63.927 95.2282 Time series MineTool 0.9736 8.989 9.2737 Dataset 3 – SDSC Building Data  Using the same twolevel analysis as in the case of previous building, we obtained the SDSC power usage data analysis results shown in Table 3 Table 3 above reiterates that multi variate time series analysis is indeed over-performing static analysis of the data. The time series model achieved 0.97 correlation coefficient accuracy, while the static models achieved 0.76 CC accuracy Figure 5 demonstrates a part of the time series prediction model represented in a tree form. Power usage patterns changed from year 2011 to 2012 and 2013 in this building as well, and the day of the week, not just workday as well as the hour are important predictors of power usage In summary, predictive analytics of energy big historical usage data obtained excellent predictive results of power usage in kW, in three building of the UCSD micro grid system.  The multivariate time series classification produced excellent models \(accuracy yielding 0.9-0.97 CC as compared to the standard data mining analysis where the data is treated as static, independent rows, and instances are processed as independent examples, or averaged over an hour of streaming data.  The models demonstrate that the time of the day, workday, day of the week, month, hour and outside temperature are all excellent predictors of the power usage per building on the micro grid.  Put in the global perspective, this initial analysis of big data will enable us to be closer to predicting power usage and lower the cost of energy of the entire campus microgrid F IGURE 4  P ART OF THE PAC  H ALL P OWER U SAGE M ODEL   Figure 5. Part of the SDSC Power Usage Model V  C ONCLUSION  UCSD is committed to acquiring alternative forms of energy generation, with the goal of self-sufficiency and main grid independence by 2016. We are utilizing smart grid data with advanced forecasting and a “big data analytics platform leveraging available large scale data and HP system in order realize tangible improvements in energy efficiency and cost.  We are further exploring clustering methods, real time and active learning models employed for predicting peaks and potential outages.   As data is rapidly growing, the stream mining and predictions become futher challenging due to the vast volume and speed of data.   Future work will involve scalling of the ongoing efforts to efficiently model the campus in its entirety and evalutae the system in real-time.  As model complexity and data granularity increase the need for large memory nodes and HDFS rise.  Investigating the parallelization of the worksflows and Minetool on a number of different platforms is be the focus of the future work.  This initial real-life case study has shown clear value through the big data analytics in both efficiencies and cost savings.    Applying such approaches to the available large scale sensor data in the microgrid environment enables informed, real-time decisions and enhancements resulting in a truly intelligent and optimized microgrid 663 


A CKNOWLEDGEMENT  The authors would like to personally thank Byron Washom, director of Strategic Energy Initiatives; John Dilliott, manager of Energy and Utilities; and Robert Austin, administrator of Energy Management Systems at UCSD; Bob Caldwell, President of Centaurus Prime and a UCSD microgrid consultant who were instrumental in providing access to campus energy data; as well as our funding agencies, i.e., the National Science Foundation and the California Energy Commission R EFERENCES  1  U.S. Department of Energy Smart Grid / Department of Energy  2  http://www.smartgrid.gov/the_smart_grid#smart_grid 3  Washom, B., Dilliott, J., Weil, D., Kleissl, J., Balac, N Torre, W., Richter, C., "Ivory Tower of Power: Microgrid Implementation at the University of California, San Diego Power and Energy Magazine, IEEE vol.11, no.4, pp. 28,32 July 2013. doi: 10.1109/MPE.2013.2258278 4  Strande, S.M., Cicotti, P., Sinkovits, R.S., William, S Young, W.S., Wagner, R., Tatineni, M., Hocks, E., Snavely A., Norman, M. 2012. Gordon: Design, performance, and experiences deploying and supporting a data intensive supercomputer. In Proceedings of the 1st Conference of the Extreme Science and Engineering Discovery Environment Bridging from the eXtreme to the Campus and Beyond  XSEDE '12\. ACM, New York, NY, USA, Article 3, 8 pages. DOI=10.1145/2335755.2335789 5  Dean, J., Ghemawat, S. 2008. MapReduce: simplified data processing on large clusters Commun. ACM 51, 1 \(January 2008\, 107-113. doi: 10.1145/1327452.1327492 http://doi.acm.org/10.1145/1327452.1327492 6  http://www.r-project.org  7  http://mahout.apache.org  8  http://hive.apache.org  9  IBM What is big data? — Bringing big data to the enterprise 01.ibm.com 10  Solomon, D., Winter, R.L., Boulanger, A.G., Anderson R.N., Wu, L.L., \(2011 Forecasting Energy Demand in Large Commercial Buildings Using Support Vector Machine Regression Technical Report Columbia University Computer Science Technical reports; CUCS-040-11; New York; http://hdl.handle.net/10022/AC:P:12171  11  Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann P., Witten, I.A. \(2009\; The WEKA Data Mining Software An Update; SIGKDD Explorations, Volume 11, Issue 1 12  Breiman, L., Friedman, J., Stone, C. J., Olshen, R. A. \(1984 Classification and regression trees Chapman & Hall/CRC 13  Kalogirou S.A. 2000. Applications of artificial neuralnetworks for energy systems Applied Energy Volume 67 Issues 1–2 September 2000, Pages 17–35 14  Karimabadi, H., Sipes, T. B., White, H., Marinucci, M Dmitriev, A., Chao, L.K., Driscoll, J., Balac, N 2007\.  Data Mining in Space Physics: 1. The MineTool Algorithm J. Geophys. Res 112, A11215 doi:10.1029/2006JA012136 15  Myers, C. S. and Rabiner, L. R.  A comparative study of several dynamic time-warping algorithms for connected word recognition. The Bell System Technical Journal 60\(7\:1389-1409, September 1981 16  Rabiner, L. R. and Juang, B. H.  An introduction to hidden markov models.  IEEE Magazine on Acoustics, Speech and Signal Processing, 3\(1\4-16, 1986 17  Schmidhuber, J., Graves, A., Gomez, F. and Hochreiter, S Recurrent Neural Networks, Cambridge University Press 2012 18  Kadous, M. W Temporal Classification: Extending the Classification Paradigm to Multivariate Time Series PhD thesis, School of Computer Science & Engineering University of New South Wales, 2002 19  Pérez-Amaral, T., Gallo, G. M. and White, H.,  A Comparison of Complementary Automatic Modeling Methods: RETINA and  PcGets Econometric Theory 2005 20  White, H., Personnel Readiness: Neural Network Modeling of Performance-Based Estimates Final Report to the Office of Naval Research, Contract #: N00014-95-C-1078 1999 21  technique: Automated detection of flux transfer events using Cluster data J. Geophys. Res  Vol 114, A06216 doi:10.1029/2009JA014202, 2009  22  White, H., Personnel Readiness: Neural Network Modeling of Performance-Based Estimates Final Report to the Office of Naval Research, Contract #: N00014-95-C-1078 1999  664 


 10  Acknowledgments  The authors are deeply indebted to Isabelle Guyon and her team for designing the problematics of the Causality Challenge, and for providing the Lucas0 test data  11  References  1 A g ra wa l, R. Srik a n t, H   Fa st a l g o rithm s f o r m i ning  association rules in large databases Research Report RJ 9839 IBM Almaden Research Center, San Jose, California June 1994  2 Ba stide Y Data mining : algorithmes par niveau techniques d'implantation et applications Doctoral dissertation, Université Blaise Pascal, Clermont-Ferrand 2000  3 Botta M., Bo ulic a u t J.-F  Ma sson C., Me o R A Comparison between Query Languages for the Extraction of Association Rules DaWaK 2002 1-10  4 C a do t, M   2 0 06   Extraire et valider les relations complexes en sciences humaines : statistiques, motifs et règles d'association Doctoral dissertation, University of Franche-Comté, France. Available online at http://www.loria.fr/~cadot/cadot_these_2006.pdf  5 C a dot M., Ma j  J  B  Zi a d  T   2005 A s s o c i a tion  Rules and Statistics, in J. Wang \(Ed Encyclopedia of Data Warehousing and Mining pp. 74-77\. Hershey, US, Idea Group Publishing  6 Ch e n Q Mining Exceptions and Quantitative Association Rules in Olap Data Cube Master Thesis, Simon Fraser University, 1999   F a b r is C C  A  A  F r eitas Disco v er y o f su rp risin g  patterns by detecting occurrences of Simpson's paradox Research and d eveloppement in intelligent systems XVI Proc ES99. The 19th SGES Int. Conf. on Knowledge-based systems and applied artificial intelligence\. 148-160 Springer-Verlag, 1999  8 F u Y  Discovery of multiple-Level Rules from large Databases Master Thesis, Simon Fraser University, 1996  9 G u ig ue s J  L  e t D uque nne  V   19 86 Fa m ille s  m i ni m a le s  d'implications informatives résultant d'un tableau de données binaires Math. Sci. Hum n°95, 5-18  10 G u ille t F., Ha m ilton H., \(200 7 Quality Measures in data mining Springer  11 G u y on I., Ca usa lity Cha lle ng e 1: Ca usa tio n a n d  Prediction, 2008 http://www.causality.inf.ethz.ch/challenge.php  12 H o c J.-M L'analyse planifiée des données en psychologie PUF, Paris, 1983  13 Ho we l D  C    Statistical Methods for Psychology  Duxbury, A Division of International Thomson Publishing Inc., 1997  1 Jaku l i n A    Attribute Interactions in Machine Learning  Master's thesis University of Ljubljana, Slovenija, 2003  15 L u x e nbur g e r M I m plic a tions  pa r tie lle s da ns u n  contexte Mathématiques, Informatique et Sciences humaines n°113,  35-55, 1991  1 P earl  J   Causality models, reasoning, and inference  Cambridge University Press, 2000, 267 - 279  17 Sim p son  E. H., T h e inte r p re ta tion of inte ra c tion in  contingency tables Journal of the Royal Statistical Society  Series B, 13, 238-241, 1951  18 Suz u k i E., K odr a t of f Y   D i s c ov e r y of Sur p r i s i ng  Exception Rules Based on Intensity of Implication Second European Symposium on Principles of Data Mining and Knowledge Discovery Springer-Verlag, London, UK. Source Lecture Notes In Computer Science. 1998, p. 10-18  19 T o iv o n e n H Kle m e n ttine n  M., R onk a i ne n  P   Ha t ne n  K., Mannila H., Pruning and Grouping Discovered Association Rules ECML'95   20 W i ne r B  J B r ow n D  R   Mic h e l s K  M Statistical principles in experimental design third edition\w York McGraw–Hill, 1991  21 Za k i M., Mini ng N onR e dun da nt A s s o c i a tion R u le s   Data Mining and Knowledge Discovery 9, 223-248, 2004 Kluwer Academic Publishers, Netherlands  22 Zh u  H  On-Line Analytical Mining of Association Rules Master Thesis, Simon Fraser University, 1998  
98 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        






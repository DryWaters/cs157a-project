Continuous Clustering in Big Data Learning Analytics 
Abstract 
Kannan Govindarajan 1 
Thamarai Selvi Somasundaram 1 Vivekanandan S Kumar 2 Kinshuk 2     
  
Learners' attainment of academic knowledge in postsecondary institutions is predominantly expressed by summative or formative assessment approaches. Recent advances in educational technology has hinted at a means to measure learning efficiency, in terms of personalization of learner competency and capacity in terms of adaptability of observed practices, using raw data observed from study experiences of learners as individuals and as contributors in social networks 
While accurate computational models that embody learning efficiency remain a distant and elusive goal, big data learning analytics approaches this goal by recognizing competency growth of learners, at various levels of granularity, using a combination of continuous, formative and summative assessments. This study discusses a method to continuously capture data from students learning interactions. Then, it analyzes and clusters the data based on their individual performances in terms of accuracy efficiency and quality by employing Particle Swarm Optimization PSO\lgorithm 
Keywords: Big Data, Learning Analytics, Particle Swarm Optimization \(PSO\based Clustering, Hadoop, K-Means Clustering 
 
 I NTRODUCTION  The analysis and discovery of relations between human 
I 
learning and contextual factors that influence these relations have been one of the contemporary and critical global challenges facing researchers in a number of areas, particularly in Education, Psychology, Sociology, Information Systems and Computing. Traditionally, these relations concern learner performance and the effectiveness of the learning context from summative and formative points of view.  Be it the assessment marks distribution in a classroom context or the mined pattern of best practices in an apprenticeship context, analysis and discovery have always addressed the elusive causal question about the need to best serve learnersê learning efficiency Learning efficiency encompasses any and all aspects that concern çlearningé of individual learners or groups of learners Examples of learning efficiency aspects include learning style 
metacognitive scaffolds, peer interactions, self-regulation, coregulation, social networking, and other learning-oriented activities and characteristics associated with learners. With the advent of new technologies such as eye-tracking, activities monitoring, video analysis, content analysis, sentiment analysis and interaction analysis, one could potentially collect continuous dataé, in addition to formative and summative data. Continuous data is different from the other two in terms of its incessant arrival from direct observations of a learning activity and other activities related to that learning activity. For    example, assessment of a submitted essay by a student offers summative data. Observing the development of the essay that assists the learner \(or the teacher\ in making targeted decisions 
about the quality of the essay being written offers formative data. This data can be obtained at real time and can be used to classify each studentês progress in a learning task and to develop a model of growth of competency, say in writing essays. The volume and arrival rate of continuous data leads to big data learning analytics Big data analytics, as opposed to smaller data analytics that can be equated to approaches that use data mining or simpler artificial intelligence in education techniques, targets large volumes of data \(beyond terabytes\ well as large numbers of voluminous computational models \(models using a significant number of variables\ concerning learning efficiency. Big data is characterized using the following five factors Ö volume speed, variety, veracity, and value. Learning Analytics is 
different from Artificial Intelligence in Education in terms of the focus on learning evolution. Learning Analytics is different from Educational Data Mining in that it does not expect welldefined data to be available in a repository.  Learning Analytics is different from User Modelling on the use of big data as the basis. It can be readily applied in the domains of reading writing, free-hand writing, coding, mathematical problem solving, understanding learning styles, gaming, chats \(e.g video, audio, text\n-class performances, metacognitive activities \(e.g., self-regulation, co-regulation\, social network contributions \(e.g., social network analysis\d usage of learning resources/tools such as Matlab, SPSS, Eclipse Moodle and Cognitive Authoring Tools \(CTAT There are many techniques available to analyze student 
competencies based on big data on learning performances. One such technique concerns clustering of students based on their performances to date on a learning activity.  Clustering is the process for grouping of similar data objects, for instance students with similar misconceptions could be clustered Clustering algorithms are classified into two types such as supervised and unsupervised learning. The supervised learning algorithm has an external director for making decision to form the clusters. The unsupervised learning algorithm works on the principle of finding similarity or distance between the objects and forming of clusters based on the similarity measures. There are various clustering algorithms such as K-Means, Centroid Clustering, Fuzzy-means and so on. The main drawback of the existing clustering algorithms is the random selection of initial 
centroids and their ability to deal with continuous arrival of data. This paper presents a novel Particle Swarm Optimization PSO\ based unsupervised clustering algorithm for clustering of students for continuously arriving data. It is a populationbased stochastic optimization technique, which has been modeled based on the swarm of particles. The particles in each   
 2 Athabasca University Edmonton, Canada Email: vive@athabascau.ca kinshuk@athabascau.ca 
 1 Madras Institute of Technology Anna University, Chennai, India Email: kannan.gridlab@gmail.com stselvi@annauniv.edu 
2013 IEEE Fifth International Conference on Technology for Education 978-0-7695-5141-8/13 $31.00 © 2013 IEEE DOI 10.1109/T4E.2013.23 61 


 
FIGURE 1: PROPOSED SYSTEM ARCHITECTURE 
swarm represent the potential solution. Each particle in the swarm tries to find the optimal solution by considering task emotive, social and cognitive factors. The algorithm utilizes a cloud based storage resources for storing big data. The paper will describe the PSO algorithm, use the algorithm to cluster students based on 3 sample factors Ö efficiency, accuracy and error count, and use simulated data to assess the performance of the algorithm.  Section II describes the background and related work. Section III describes the system architecture Section IV discusses the PSO algorithm. Section V discusses the study and Section VI concludes the paper II RELATED  WORKS There has been a lot of research effort carried out in monitoring and discovery and we discuss some of the works that has been closely related to our work A surge of interest in educational data mining has been observed in recent years [1   Ka di r Gey i k   6  pr o p o s e d th e con ce pt  of clu s t e rin g t h e learners based on the attributes such as recently accessed materials, frequently accessed materials and monetary factors where a hierarchical clustering algorithm clustered learners based on self-organizing map, followed by a non-hierarchical clustering approach called fuzzy clustering. Stavros Valsamidis 7 used  t h e Ma r k o v c l ust e ri ng a l go ri t h m t o c l ust e r l e a r n e r s  based on their activities with respect to enrichment, interest and disappointment.  Xiaohui Cui et al prop o s ed  P a r t i c l e  swarm optimization based clustering to cluster documents using cosine similarity as a measure to cluster similar documents. Dheeban S.G. et al. [9 p r o p o s e d a pe rs on ali z ed  learning approach using Modified Particle Swarm Optimization, where learners are grouped based on their ability level and difficulty of the course, thus allowing an estimation of a courseês suitability for a learner. Sridevi et al. [10  proposed cosine semantic similarity measure to cluster annotated documents using PSO based clustering. In all these approaches, initial solutions have been randomly chosen and hence offer less-than-optimal convergence. Further, these approaches do not offer optimal clustering solutions when the data tends to arrive continuously. To address these two issues one would require an algorithm that approaches convergence much faster than contemporary approaches. Further, such an algorithm would have to inform intermediate solutions about newly arrived data sets in order to revise these intermediate solutions on a continuous basis. The novel PSO algorithm proposed in this paper addresses these two key concerns  III PROPOSED SYSTEM ARCHITECTURE  The system-level architecture for implementing our proposed work is shown in Figure 1. The system fetches three types of data from studentsê study activities in the domain of Java programming - exercises, assignments and assessments. These three data sets are preprocessed before being fed into the PSOclustering manager. We developed a Hackystat based continuous data trace mechanism to collect coding related data This mechanism continuously collected data from Eclipse as and when students engaged in UML-based design of Java programs, writing of programs, debugging of programs documenting programs, and testing programs. The Coordinator is the entry point for the proposed system that acts as the mediator for coordinating various activities such as \(a\nvoke the Data Collector to collect or fetch the continuous data \(b Invoke the Data Preprocessor to process the collected data \(c Invoke the PSO-based Clustering Manager to cluster the students based on the similarity value \(d\ Invoke the Resource Allocator to select the cloud resources for storage activity c Invoke the Cloud Resource Information Aggregator in a periodic interval to dynamically aggregate the physical resource information about Cloud resources \(e\ Invoke the Data Storage Manager for efficiently storing the structured data in Hadoop Distributed File System \(HDFS\. The Data Preprocessor processes the raw data; the processed structured data is fed into PSO-based clustering manager for further processing. It includes an analysis of studentsê discussion forum contributions as well as sentiment analysis input obtained from students. Data Collector retrieves the studentês data from the tools such as Moodle Learning Management Systems \(LMS\ Virtual Programming Lab \(VPL\ Intelligent Tutors, and Eclipse IDE extensions. The Cloud Resource Information Aggregator makes use of Zookeeper to monitor and manage the Hadoop clusters. The Resource allocator is the component that helps to locate suitable resources for data storage as well as data retrieval. The Data Storage Manager is responsible for interacting with Hadoop Distributed File System \(HDFS\to efficiently store and retrieve the unprocessed data as well as processed data  IV PARTICLE SWARM OPTIMIZATION \(PSO CLUSTERING Particle Swarm Optimization \(PSO\ a population-based artificial intelligence mechanism that is inspired by social behavior of swarm of birds. PSO algorithm is employed with the swarm of particles, and every particle is responsible for tracking the fitness of each particle. Every particle is associated with corresponding velocity that helps the particle to move onto best position and every particle in the swarm search the better solution. The convergence of PSO depends on the particleês personal position and global best position of swarm. The number of students to be clustered is M. In the PSO clustering algorithm, a swarm of particles P, each driven with a velocity V, aims to cluster the learners according to 
62 


i Clus P P Gbest Pbest 
i P P 
i PP i P best f P 
 2   3   4   
12   12   1 0 0 1 0 0 12   
12   12   
002 
002 003 
 Algorithm 1: Particle Swarm Optimization \(PSO  Input Output  calculating fitness function   choosing Pbest and Pbest position choosing Gbest and Global best Position  updating the velocity and position  
i i PP K P PbestPos ce ce ce i Clus K P GbestPos ce ce ce 
004 004 
j SS D ce ce ce iN ce x x x k k U rand D ce ce ce i fP 
1  
002  002 
i PP i PP i ce i ce i PP Clus Gbest Clus GbestPos i PP i PP ti ce P Mn ijt jt f Pdsce i PP 
their observed behaviors. The particle èPê is represented as have èDê dimensions. In PSO clustering, each dimension represents a cluster centroid. In other words, the number of clusters to be formed is èDê.  The characteristic of a student is given as  The pseudo code for PSO-based clustering algorithm is illustrated under Algorithm 1 shown below  Number of particles  A particle is represented as where represents centroid of the cl uster èiê. Cluster centroid  is represented as where N denotes the number of attributes or features An optimal particle P i that represents cluster centroid For each particle  Initialize as  Initialize as  Initialize as  Initialize as  Initialize velocity of as  Initialize particle as  End Repeat until max generation For each particle  For each student where 1 < j < M For each cluster centroid  Where 1  
002\002 
http://vpl.dis.ulpgc.es/index.php http://vpl.dis.ulpgc.es/index.php/en/documentation/18-how-to-configurethe-jail-daemon http://code.google.com/p/hackystat http://www.eclipse.org 
 
 
005\005 
 
002 002 002 002 
 
A. Experimental Setup B. Results and Discussion 
 End End End For each particle   If          End End min   For each particle  Update the velocity and position for the next iteration End End \(of max generations  V  EXPERIMENTAL  SETUP  AND  RESULTS   To evaluate the suitability of the PSO algorithm for big data learning analytics, an experimental setup is made in our department. The Moodle server version of 2.2.1 is installed in server hardware of Quad Core CPU with i5 processor. It has 16 GB RAM, 500 GB Hard disk and Debian 6.x as operating system. The Virtual Programming Lab \(VPL 1 is installed along with jail-server 2 in an Ubuntu-based Operating System In addition to that, Hackystat 3 sensor server component is installed along with Moodle server that collects the data from Eclipse IDE 4 through Hackystat sensor clients installed in lab desktop machines. The PSO system and Moodle are installed separately in external servers. Data collected is pre-processed and directly stored in the Hadoop Distributed File System HDFS\. The Hadoop cluster for this experiment comprises of three separate servers, where each server has the capacity of 2000 GHz processor speed, 128 GB RAM and Cent OS 5.5 as the operating system A simulated experiment was carried out for the range of 100 to 500 students, over a total of 60 problems, and a total of 30 hours to solve these problems. Learner study experiences are randomly generated corresponding to estimates of accuracy efficiency, and quality based on the observed distribution of real data collected from students. The generated results are subjected to K-means clustering, followed by PSO-based clustering. K-means is a partioning based algorithm; it tends to solve NP-Hard problems. However the main drawback of KMeans clustering is formation of poor clusters, due to the random selection of initial centroids. The Quality of a cluster is measured by three parameters:  a\tra Cluster Distance ICD\d b\ter Cluster Distance \(InterCD\Accuracy The Intra Cluster Distance is measured as sum of distance between all data instances belonging to the cluster and Inter Cluster distance is measured as sum of distance between all   
    
 
  0,1  
  
 
  
002 003 002 003 
002 002 002 002 002 002 002 
j jjj S SID Accuracy Efficiency Quality jS S S S 
tD 
002 002 
003 
003 
11  
i PP P best i PP PbestPos i PP V i PP P best 
  12   
  
P P PP P j SS 
  
63 


          
FIGURE 2: COMPARISON OF INTRA CLUSTER DISTANCE    FIGURE 3: COMPARISON OF INTER CLUSTER DISTANCE TABLE 1: COMPARISON OF ACCURACY 
TP TN Accuracy TP FN FP TN 
the centroids. The Intra Cluster distance should be minimum and Inter Cluster distance should be maximum. The Intra Cluster Distance is lower in PSO-based clustering and it reaches the convergence value in a steady manner compared to K-Means algorithm. Moreover, the Inter Cluster Distance is consistently higher in PSO-based clustering than K-Means clustering approach. The comparison of Intra Cluster Distance is shown in Figure 2 and the Inter Cluster Distance is shown in Figure 3. Accuracy represents the quality of a cluster. The quality of a cluster is measured using the following values such as: True Positive \(TP\e Negative \(TN\se Positive \(FP\d False Negative \(FN\he computed accuracy for PSO-based clustering and K-Means clustering is shown in Table 1   VI CONCLUSION AND FUTURE WORK Educational institutions are read y to supplement classroom environments with online environments. Recent advances in big data learning analytics allows for the collection of continuous data from learning activities performed by learners. Such data can be used to continuously, efficiently and accurately cluster students based on their competencies and study habits. The PSO-based approach is validated by generating simulated data based on actual/real data collected from engineering graduates. The proposed PSO-based clustering performs better than K-Means algorithm. In our efforts to scale the clustering requirements, we aim to develop a Cloud-based MapReduce framework with Hadoop environment to perform clustering in a parallel and in a distributed manner. We aim to allow students, peers and teachers to interact with the PSO-algorithm that generates additional particles for the swarm. Such an interactive approach will be experimentally tested for its accuracy of clustering in comparison with other clustering methods ACKNOWLEDGEMENT The authors would like to thank and acknowledge the IndoCanadian Shastri Institute, Canada for providing the PDIG grant to carry out this research work and for the student researcher to visit Canada from India. The authors extend their gratitude to Athabasca University, Edmonton, Canada, Anna University, Chennai, India, and NSERC, Canada for their support References 1 
 S.No Accuracy in PSO-based Clustering Accuracy in K-Means Clustering 1 0.943 0.845 2 0.912 0.81 3 0.923 0.8267 4 0.935 0.798 5 0.97 0.86 Brusilovsky, P., Peylo, C., \(2003\. çAdaptive and intelligent web-based educational systemsé, International Journal of Artificial Intelligence in Education, 13, 156-169 2 GarcÌa, E., Romero, C., Ventura, S., Castro, C. \(2006\. çUsing rules discovery for the continuous improvement of e-learning coursesé, In International Conference Intellligent Data Engineering and Automated Learning. Burgos, Spain, pp. 887-895 3 Romero, C., Ventura, S., GarcÌa E. \(2008\. çData mining in course management systems: Moodle case study and tutorialé, Computers in Education, 51 \(1\, pp. 368-384 4 Romero, C., Ventura, S., & Bra, P. D. \(2004\ çKnowledge discovery with genetic programming for providing feedback to courseware authoré, User Modeling and User-Adapted Interaction: The Journal of Personalization Research, 14\(5\, 425Ö464 5 Baker, R.S.J.d., Yacef, K. \(2009\. çThe State of Educational Data Mining in 2009: A Review and Future Visionsé, Journal of Educational Data Mining, 1 \(1\-17 6 Geyik, K. \(2007\ çClustering e-Students in a Marketing Context: A Two stage Clustering Approaché, ECEL 6th European conference on ELearning Copenhagen Business School, pp.245-252 7 Valsamidis, S., Kontogiannis, S., Kazanidis, I., Theodosiou, T Karakos, A. \(2012\. çA Clustering Methodology of Web Log Data for Learning Management Systemsé, Educational Technology & Society, 15 2\ 154Ö167 8 Cui X., Potok, T.E., Palathingal, P. \(2005\. çDocument Clustering using Particle Swarm Optimizationé, IEEE Swarm Intelligence Symposium The Westin, pp. n/a 9 Dheeban S.G, Deepak V, Dhamodharan L, Susan Elias, \(2010 Improved personalized e-course Composition Approach using Modified Particle Swarm Optimization with Inertia coefficient International Journal of Computer Applications volume 1 Ö No.6, 102 107  Sridevi. U.K, Nagaveni. N., \(2011\. çSemantically Enhanced Document Clustering Based on PSO Algorithmé, European Journal of Scientific Research, Vol. 57, No.3, pp. 485-493  
  
   
64 


x-none 000x  Insecure storage of credentials Username and passwords stored in the database are not encrypted As a result, an attacker can eavesdrop  on the network and gain  000D\000F\000F\000H\000V\000V\000\003 000X\000V\000H\000U\000V\000  unauthorized information Thus an attacker is able to gain access to the database to view 000X\000V\000H\000U\000V\000  data  x-none 000x  Horizontal privilege escalation 000  The application allows users to view friends CDs and view comments on CDs without logging into the app lication  x-none 000x  Cross Site Request Forgery 000  Malicious scripts may be injected into the comment field of Tunestore which includes a crafted link When a victim clicks on the link, it causes some actions to occur, such as logging the victim out, etc  x-none 000x  Integer Ove rflow 000  The submission of large numbered values will overflow the balance field 000R\000Q\000\003\000W\000K\000H\000\003\000D\000F\000F\000R\000X\000Q\000W\000\021\000\003\0007\000K\000H\000\003\000≥\000D\000G\000G\000\003\000E\000D\000O\000D\000Q\000F\000H\000¥\000\003\000R\000S\000W\000L\000R\000Q\000\003\000Z\000L\000O\000O\000\003\000Q\000R\000\003 longer operate correctly  x-none 000x  An attacker 000F\000D\000Q\000\003 000D\000G\000G\000\003 000D\000Q\000\003 000D\000P\000R\000X\000Q\000W\000\003 000W\000R\000\003 000W\000K\000H\000\003 000≥\000D\000G\000G\000\003 000E\000D\000O\000D\000Q\000F\000H\000¥\000\003 000I\000H\000D\000W\000X\000U\000H\000\003 000L\000Q\000\003 000W\000K\000H\000L\000U\000\003 000S\000U\000R\000I\000L\000O\000H\000\003 000E\000\\\000\003 using SQL injection t echniques  Hence an attacker can successfully create a new user account with a substantial amount of money added to their account without providing valid credit card information As a result the attacker  is able to purchase CDs for free This vulnerabili ty was discovered through examining the source code  x-none 000x  I nsecure D irect O bject Reference Requests for protected resources in this case the music files are made directly to the static resources which are located within the web root of the server. The musi c filenames are predictable The last names of the artists are used. Changing the values in the download link permits a user to download any song from Tunestore without purchasing them  VII  D ISCUSSION  Our case study shows that Tunestore is a good example application for teaching students about web security. It can be used to demonstrate various web application vulnerabilities to the students. Limited by our academic environment, we do not have the full versions of Fortify and Acunetix Therefore the testing results from the demonstration or the trial version of the tools are very limited in this study. Universities can apply for the Hewlett-Packard Company Educational Software License Agreement to receive the full version of Fortify for free for educational purposes.  However, we could not get the full version of Fortify because our university did not agree  with the user agreement for the license for the Fortify software  The web spidering and proxy features of Paros and WebScarab are very useful for web application testing The web spidering functions allow testers to understand the content and structure of the web application. The proxy allows testers to intercept and modify requests and responses transmitted between the client and server to conduct attacks The scanner feature of Paros is quite limited It does report some main vulnerabilities such as SQL injection cross-s ite scripting and s 000H\000V\000V\000L\000R\000Q\000\003 000,\000'\000\003 000L\000Q\000\003 0008\0005\000/\000\003 000U\000H\000Z\000U\000L\000W\000H\000\017\000\003 000H\000W\000F\000\021\000\003 000:\000H\000E\0006\000F\000D\000U\000D\000E\000∂\000V\000\003 fuzzer feature can be very useful because a large number of attack strings can be submitted to test the application automatically Some of the manual testing conducted in this case study such as testing for buffer overflow integer overflow vulnerabilities could have been done using 000:\000H\000E\0006\000F\000D\000U\000D\000E\000∂\000V\000\003 000I 000 000H 000U 000\003 000I 000H 000D 000W 000X 000U 000H 000\021 000\003 000\000 000U 000R 000 000X\000 000 000\003 000G\000R 000H 000V 000\003 not have good documentation on how to use the tool From our use of the tool, we discovered a bug in the tool, and did not think the tool worked properly as it is supposed to However the attack types and payloads embedded in the tool can be useful The payloads can be used for manual testing or testing with 000:\000H\000E\0006\000F\000D\000U\000D\000E\000∂\000V\000\003\000I 000 000H 000U\000\003 000I 000H 000D 000W 000X 000U 000H 000\021  Manual testing discovered most of the vulnerabilities especially the design flaws Some of them are the same as those found using Paros, Fortify, Acunetix, for example, SQL injection and cross-site scripting vulnerabilities Most of the authentication and access control vulnerabilities can only be 000I\000R\000X\000Q\000G\000\003 000W\000K\000U\000R\000X\000J\000K\000\003 000P\000D\000Q\000X\000D\000O\000\003 000W\000H\000V\000W\000L\000Q\000J\000\003 000E\000D\000V\000H\000G\000\003 000R\000Q\000\003 000W\000H\000V\000W\000H\000U\000∂\000V\000\003 000R\000E\000V\000H\000U\000Y\000D\000W\000L\000R\000Q\000V\000\021\000\003 Therefore it is important to utilize a variety of tools as well as conduct careful manual testing in order to find the most number of vulnerabilities in a web application VIII  C ONCLUSION  This paper describes a case study of testing for security vulnerabilities of an example application 000  Tunestore It provides an overview of web application security testing tools such as Paros, WebScarab, JBroFuzz, Acunetix, and Fortify. It presents the security vulnerabilities found within an application by using these tools, and by manual testing. While commercial tools are not easily available in an academic environment open source tools can be used to conduct security testing with limited results Our case study shows manual testing is very important since some vulnerability 000W\000\\\000S\000H\000V\000\003 000F\000D\000Q\000\003 000R\000Q\000O\000\\\000\003 000E\000H\000\003 000I\000R\000X\000Q\000G\000\003 000W\000K\000U\000R\000X\000J\000K\000\003 000P\000D\000Q\000X\000D\000O\000\003 000W\000H\000V\000W\000L\000Q\000J\000\003 000D\000Q\000G\000\003 000W\000H\000V\000W\000H\000U\000∂\000V\000\003 observations. It is important to utilize a variety of tools as well as conduct careful manual testing in order to find the most number of vulnerabilities in a web application Based on this case study hands-on labs can be developed for teaching web security, software security testing, and other topics R EFERENCES    Studdard, D., & Pinto, M 0007\000K\000H\000\003\000:\000H\000E\000\003\000$\000S\000S\000O\000L\000F\000D\000W\000L\000R\000Q\000\003\000+\000D\000F\000N\000H\000U\000∂\000V\000\003 Handbook Discovering and Exploiting Security Flaws  Wiley Publishing: Indianapolis, Indiana, 2008   The Open Web Application Security Project Testing Introduction and Objectives 2012 https://www.owasp.org/index.php/Testing:_Introduction_ and_objectives retrieved on November 6, 2012   McGraw G Software Security Building Security In  Pearson Education: Boston, Massachusetts, 2006 


  The Open Web Application Security Project OWASP Top Ten 2010 000  Main 2010 www.owasp.org/index.php/Top_10_2010-Main  retrieved on January 13, 2013   Web-Hacking-Incident-Database Retrieved on Jan 6 2013 http://projects.webappsec.org/w/page/13246995/WebHa cking-Incident-Database    Top 10 2010 Retrieved on January 10 2013 https://www.owasp.org/index.php/Top_10_2010-Main   Paros Paros 000  for web application security assessment 2004 http://www.parosproxy.org  retrieved on November 6, 2012   Paros User Guide for Paros v2.x 2003 http://www.parosproxy.org/paros_user_guide.pdf  retrieved on November 6, 2012   The Open Web Application Security Project Category OWASP WebScarab Project 2012 https://www.owasp.org/index.php/Category:OWASP_We bScarab_Project retrieved on November 6, 2012   The Open Web Application Security Project OWASP 2012 www.owasp.org retrieved on November 6, 2012   Dustin E Nelson L Wysopal C Zovi D The Art of Software Security Testing Identifying  Software Security Flaws  Symantec Corporation Upper Saddle River New Jersey, 2007   The Open Web Application Security Project JBroFuzz 2012 https://www.owasp.org/index.php/JBroFuzz  retrieved on November 6, 2012   Acunetix Ltd Acunetix Web Application Security www.acunetix.com/vulnerability-scanner  retrieved on November 6, 2012   HP Enterprise Security, HP Fortify Static Code Analyzer 2012 http://www.hpenterprisesecurity.com/products/hpfortify-software-security-center/hp-fortify-static-codeanalyzer retrieved on November 6, 2012  


017\012\037\007\034\022\020\027.\007\026$\012\016\034\010\012\027 017.*4\004\007\013\012\016\027.\007\026$\012\016\034\010\012\027 
We have used an Intel Westmere cluster for our evaluations This cluster consists of compute nodes with Intel Westmere series of processors using Xeon Dual quad-core processor nodes operating at 2.67 GHz with 12GB RAM and 160GB HDD Each node is equipped with MT26428 QDR ConnectX HCAs 32 Gbps data rate with PCIEx Gen2 interfaces The nodes are interconnected using a Mellanox QDR switch Each node runs Red Hat Enterprise Linux Server release 6.1 Santiago at kernel version 2.6.32131 with OpenFabrics version 1.5.3 This cluster also has dedicated storage nodes with the same conìguration but with 24GB of RAM each Additionally eight of the storage nodes are equipped with two 1TB HDD each Four of the storage nodes also have Chelsio T320 10GbE Dual Port Adapters with TCP Ofîoad capabilities In the gures presented in this section we have mentioned OSU-IB to indicate our RDMA-based design of MapReduce and Hadoop-A to indicate the design in 32 Gbps indicates InìniBand QDR card speed We have performed this experiment in 10 GigE IPoIB 32 Gbps with vanilla Hadoop and Hadoop-A and compared the results with our design For this experiment we have found that the optimal HDFS block-size for 10 GigE IPoIB 32 Gbps and our design is 256 MB whereas it is 128 MB for Hadoop-A We have used TeraGen to generate the input data for TeraSort Figure 4 shows the job execution times of the TeraSort benchmark in a four-DataNode cluster In the experiments for Figure 4\(a we show performance results with single and dual HDDs for each interconnect For single HDD 30 GB sort size our design reduces the job execution time by 9 over Hadoop-A 32 Gbps 35 over IPoIB 32 Gbps and 38 over 10 GigE Compared with IPoIB and 10 GigE our design uses native IB verbs communication for the data shufîe which is much better than the socket based communication on IPoIB and 10 GigE Although HadoopA also uses native IB verbs communication the data prefetching and caching mechanism of our design improves the performance On the other hand if two HDDs are used per node our design improves the execution time by 13 over HadoopA 32 Gbps 38 over IPoIB 32 Gbps and 43 over 10 GigE for the same sort size For 40 GB sort size our design achieves an improvement of 17 48 and 51 over Hadoop-A 32 Gbps IPoIB 32 Gbps and 10 GigE respectively When multiple HDDs are used per node the performance bottleneck of the local disk read and write bandwidth is alleviated Compared to Hadoop-A our design can utilize the improved bandwidth more efìciently to overlap the data shufîe merge and reduce further as illustrated in section III-B We have performed similar experiments with the TeraSort benchmark using eight DataNodes In this case we varied the sort size from 60 GB to 100 GB As shown in Figure 4\(b our design reduces the job execution time 21 over Hadoop-A 32 Gbps for 100 GB sort size with single 
Figure 3 Overlapping of different processes in MapReduce workîow IV P ERFORMANCE E VALUATION In this section we present the detailed performance evaluations of our RDMA-based design of Hadoop MapReduce and its impact on different Hadoop benchmarks We compare the performance of our design with socket based interconnects 10 GigE and IPoIB and Hadoop-A W e ha v e performed the experiments on different storage platforms single/multiple HDDs or SSD per node in order to illustrate the effect of I/O on our design In this study we perform the following set of experiments 1 Evaluation with the TeraSort benchmark and 2 Evaluation with the Sort benchmark These benchmarks are described in section II For each of the benchmarks we have identiìed the optimal values of HDFS block-size for different interconnects as well as for Hadoop-A and our design Additionally in our experimental setup we have also determined that four is the maximum number of map and reduce tasks that can be run simultaneously to achieve the optimal performance by a TaskTracker In all our experiments we have used Hadoop 0.20.2 Hadoop-A and JDK 1.7.0 
002\003\004 005\006\007\010\010\011\012 002\012\013\014\012 015\012\016\007\017\012 020\021\004\011\022\017\022\023\024\025\003\013\013\022\012\013 002\003\004 005\006\007\010\010\011\012 002\012\013\014\012 015\012\016\007\017\012 020\021\004\011\022\017\022\023\024\025\003\013\013\022\012\013 
A Experimental Setup B Evaluation with the TeraSort Benchmark 
1914 


      
0 500 1,000 1,500 2,000 2,500 40 30 20 Job Executiion Time \(sec Sort Size \(GB 10GigEä1disk 10GigEä2disks IPoIBä1disk \(32Gbps IPoIBä2disks \(32Gbps HadoopAäIBä1disk \(32Gbps HadoopAäIBä2disks \(32Gbps OSUäIBä1disk \(32Gbps OSUäIBä2disks \(32Gbps 0 500 1,000 1,500 2,000 2,500 3,000 3,500 4,000 100 80 60 Job Executiion Time \(sec Sort Size \(GB 1GigEä1disk 1GigEä2disks IPoIBä1disk \(32Gbps IPoIBä2disks \(32Gbps HadoopAäIBä1disk \(32Gbps HadoopAäIBä2disks \(32Gbps OSUäIBä1disk \(32Gbps OSUäIBä2disks \(32Gbps 0 500 1,000 1,500 2,000 2,500 3,000 3,500 4,000 200GBä24nodes 100GBä12nodes Job Executiion Time \(sec Sort Size 1GigE IPoIB \(32Gbps HadoopAäIB \(32Gbps OSUäIB \(32Gbps 0 50 100 150 200 250 300 350 400 450 500 20 15 10 5 Job Executiion Time \(sec Sort Size \(GB 1GigE IPoIB \(32Gbps HadoopAäIB \(32Gbps OSUäIB \(32Gbps 
C Evaluation with the Sort Benchmark 
a Total job execution times in 4 nodes cluster          b Total job execution times in 8 nodes cluster Figure 4 TeraSort benchmark evaluation HDD From Figure 4\(b we observe that with two HDDs per node our design achieves an improvement of 31 over Hadoop-A 32 Gbps          Figure 5 TeraSort benchmark evaluation with larger sort size We have also evaluated TeraSort with larger sized cluster In this case we have varied the sort size from 100 GB to 200 GB with 12 and 24 compute nodes in the cluster respectively Figure 5 shows these results For 100 GB sort size we achieve 41 beneìt over IPoIB 32Gbps and 7 beneìt over Hadoop-A 32Gbps For 200 GB sort size also we achieve similar beneìts From Figure 4 and Figure 5 we observe that Hadoop-A performs better with respect to IPoIB in a bigger cluster with the same sort size whereas our implementation achieves better performance in both cases compared to Hadoop-A As in our setup storage nodes have twice as much memory as compute nodes our implementation has more beneìts in storage nodes compared to those in compute nodes This clearly depicts the efìciency of the caching mechanism implemented in our design Figure 7 Sort benchmark evaluation with SSD Figure 6\(a shows the performance results of the Sort benchmark using four DataNodes For this we have used four compute nodes in our cluster Each DataNode has single HDD per node In this case our design reduces the job execution time by 26 over IPoIB 32 Gbps and 38 over Hadoop-A for 20 GB sort From Figure 6\(b we observe that with eight DataNodes our design can achieve an improvement of 27 over IPoIB 32 Gbps and 32 over Hadoop-A Compared with the TeraSort benchmark the difference in the Sort benchmark is the variable size of the key-value pairs In Sort the combined length of key-value pairs can be as large as 20,000 bytes From the results we can observe that Hadoop-A performs worse than IPoIB even after conìguring all the tunable parameters with optimum values as mentioned in Hadoop-A release It re v eals that only substituting the socket based communication with the native IB verbs some applications such as the Sort benchmark cannot get better performance due to the inefìciency in number of keyvalue pairs transferred each time that also affects proper overlapping between all the stages Our design with the efìcient caching mechanism can get better performance in 
We perform the regular Sort benchmark in 1 GigE IPoIB 32 Gbps with vanilla Hadoop and Hadoop-A and compare the results with our design For this experiment the optimal value of HDFS block-size is 64 MB We have used RandomWriter to generate the input data for the Sort benchmark            
1915 


        
0 200 400 600 800 1,000 1,200 1,400 20 15 10 5 Job Executiion Time \(sec Sort Size \(GB 1GigE IPoIB \(32Gbps HadoopAäIB \(32Gbps OSUäIB \(32Gbps 0 200 400 600 800 1,000 1,200 1,400 40 35 30 25 Job Executiion Time \(sec Sort Size \(GB 1GigE IPoIB \(32Gbps HadoopAäIB \(32Gbps OSUäIB \(32Gbps 0 100 200 300 400 500 600 20 15 10 5 Job Executiion Time \(sec Sort Size \(GB IPoIB OSUäIB \(Without Caching Enabled OSUäIB \(With Caching Enabled 
D Beneìts of Caching 
a Total job execution times in 4 nodes cluster         b Total job execution times in 8 nodes cluster Figure 6 Sort benchmark evaluation both these cases as it considers the size of the key-value pair before the transfer We also evaluate Sort benchmark using SSD as HDFS data stores Figure 7 shows the comparison for this evaluation In this case our design achieves a beneìt of 22 over Hadoop-A 32Gbps and 46 over IPoIB 32Gbps in job execution time for 15 GB sort Figure 8 Effect of Caching Mechanism Figure 8 shows the performance comparison between caching enabled and caching disabled in our RDMA-based design for Sort benchmark We perform this experiment using SSD as HDFS data store In this case enabling caching with our design can enhance performance by 18.39 over caching disabled in the same design for 20 GB sort size It reveals that for big workload as in sort an efìcient caching mechanism can signiìcantly improve the performance for an RDMA-based design using a high performance interconnect V R ELATED W ORK Many studies have paid attention to improve the performance of MapReduce in recent years As mentioned before the most analogous one is Hadoop-A which pro vides a new merge method to Hadoop MapReduce framework by utilizing RDMA over InìniBand Our work has some major enhancements and differences with respect to their work along pre-fetching caching codebase modiìcation etc We have discussed these detail in section III-C In the authors ha v e proposed techniques of prefetching and pre-shufîing into MapReduce From their results the techniques can improve the overall performance of Hadoop We have focused on implementing an efìcient key-value pairs pre-fetching and caching mechanism inside TaskTracker which is responsible for fast data shufîe when the mappers are yet to be completed Such a design can help reduce the overhead in the reducer side when the shufîe and merge procedures run in an overlapped manner The research has demonstrated that there is an impressi v e space for performance improvement in Hadoop MapReduce compared with traditional HPC technologies such as MPI Our earlier work 7 re v ealed that SSD can reduce the I/O cost and make the overheads involved in datatransmission over the network prominent In this paper we have conducted experiments with multiple HDDs and SSDs per node to lessen the I/O bottleneck when studying the effect of communication over different interconnects VI C ONCLUSION In this paper we have presented an RDMA-based design of MapReduce over InìniBand We have also proposed efìcient pre-fetching and caching mechanisms for retrieving of the intermediate data Our performance evaluation shows that we achieve 21 beneìt in terms of execution time over Hadoop-A for 100 GB TeraSort For regular Sort benchmark our design outperforms Hadoop-A by 32 for 40 GB sort We also observe an improvement of 22 over Hadoop-A for the same sort size using SSD In future we plan to extend 
In our design we have implemented efìcient map output pre-fetching and caching mechanism We have also provided a conìguration parameter to enable/disable the caching In this experiment we have evaluated the performance improvement that we can get through caching enabled        
1916 


our design to handle faster recovery in case of task failures We will also evaluate our design on larger clusters with a range of applications R EFERENCES  Y  W ang X Que W  Y u D Goldenber g and D Sehgal Hadoop Acceleration through Network Levitated Merge in  ser SC 11 2011  Apache Hadoop http://hadoop.apache.or g  J Dean and S Ghema w at MapReduce Simpliìed Data Processing on Large Clusters in  2004  K Shv achk o H K uang S Radia and R Chansler  The Hadoop Distributed File System in  2010  J Appa v oo A W aterland D Da Silv a V  Uhlig B Rosenburg E Van Hensbergen J Stoess R Wisniewski and U Steinberg Providing A Cloud Network Infrastructure on A Supercomputer in  ser HPDC 10 New York NY USA ACM 2010 pp 385Ö394  Greenplum Analytics W orkbench http://www.greenplum.com/news/greenplum-analyticsworkbench  S Sur  H W ang J Huang X Ouyang and D K Panda Can High Performance Interconnects Beneìt Hadoop Distributed File System in  Atlanta GA 2010  J Jose H Subramoni M Luo M Zhang J Huang M W Rahman N S Islam X Ouyang H Wang S Sur and D K Panda Memcached Design on High Performance RDMA Capable Interconnects in  Sept 2011  J Huang X Ouyang J Jose M W  Rahman H W ang M Luo H Subramoni C Murthy and D K Panda High-Performance Design of HBase with RDMA over InìniBand in   N S Islam M W  Rahman J Jose R Rajachandrasekar H Wang H Subramoni C Murthy and D K Panda High Performance RDMA-based Design of HDFS over InìniBand in  November 2012  J Jose M Luo S Sur  and D K P a nda Unifying UPC and MPI Runtimes Experience with MVAPICH in  Oct 2010  Hadoop Map Reduce The Apache Hadoop Project  http://hadoop.apache.org/mapreduce  Sort http://wiki.apache.or g/hadoop/Sort  RandomWriter http://wiki.apache.or g/hadoop RandomWriter  Inìniband T rade Association http://www inìnibandta org  OpenF abrics Alliance http://www openf abrics.or g  P  Balaji H V  Shah and D K P anda Sockets vs RDMA Interface over 10-Gigabit Networks An In-depth analysis of the Memory Trafìc Bottleneck in  2004  RDMA Consortium  Architectural Speciìcations for RDMA over TCP/IP http://www.rdmaconsortium.org  B Fitzpatrick Distrib uted Caching with Memcached   vol 2004 pp 5 August 2004  A v ailable http://portal.acm.or g/citation.cfm id=1012889.1012894  Apache HBase The Apache Hadoop Project  http://hbase.apache.org  MV APICH2 MPI o v er InìniBand 10GigE/iW ARP and RoCE http://mvapich.cse.ohio-state.edu  Mellanox T echnologies Unstructured Data Accelerator http://www.mellanox.com/page/products dyn product family=144  S Seo I Jang K W oo I Kim J.-S Kim and S Maeng HPMR Prefetching and Pre-shufîing in Shared MapReduce Computation Environment in  Sep 2009 pp 1Ö8  X Lu B W ang L Zha and Z Xu Can MPI Beneìt Hadoop and MapReduce Applications in  2011 
Proceedings of 2011 International Conference for High Performance Computing Networking Storage and Analysis Operating Systems Design and Implementation OSDI IEEE 26th Symposium on Mass Storage Systems and Technologies MSST Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing Workshop on Micro Architectural Support for Virtualization Data Center Computing and Clouds in Conjunction with MICRO 2010 International Conference on Parallel Processing ICPP IEEE International Parallel and Distributed Processing Symposium IPDPSê12 The International Conference for High Performance Computing Networking Storage and Analysis SC Fourth Conference on Partitioned Global Address Space Programming Model PGAS Workshop on Remote Direct Memory Access RDMA Applications Implementations and Technologies RAIT in conjunction with IEEE Cluster Linux Journal Cluster Computing and Workshops 2009 CLUSTER 09 IEEE International Conference on IEEE 40th International Conference on Parallel Processing Workshops ICPPW 
1917 


A Global Solution COVERAGE North and South America EMEA and Asia White lines are flights in the masFlight platform from February 8, 2013 Yellow pins are weather stations feeding hour ly data to our platform Maps from Google Earth / masFlight masFlight tracks flights, airports and weather around the world  Global daily flight information capture  82,000 flights  350 airlines  1700 airports  Integrated weather data for 6,000 stations  Match weather to delays  Validate block forecasts at granular level  Add weather analytics to IRROPS review and scenario planning 


Example 1: Proposed FAA Tower Closures masFlight used big-data to link airport operations across three large data sets  Current and historical airline schedules  Raw Aircraft Situation Display to Industry \(ASDI\AA  Enhanced Traffic Management System Counts \(ETMS\Airport operations counts by type \(commercial, freight, etc TOWER CLOSINGS Dots indicate closures; Red dots have scheduled service Based on scheduled service March 1 7, 20 13; scheduled service includes scheduled charter flights, cargo flig hts, and passenger flights Dots  indicate  closures  Red  dots  have  scheduled  service Bas ed  o n sc h edu l ed  se rvi ce  M a r c h 1  7, 2013; scheduled se rvi ce includ es scheduled c harter fli g hts car g o fli g hts a nd passen g er fli g hts Findings: Proposed Tower Closings  From schedules database: 55 airports with scheduled passenger airline service  14 EAS Airports  From ASDI & ETMS: 10,600 weekly flights on a flight plan \(ex. VFR and local traffic  6,500 Part 91/125 weekly flights  4,100 Part 135/121 weekly flights  


Example 1: Big-Data Analytics Applied to ASDI and ETMS To Analyze Operations TOWER CLOSINGS  26 44 24 23 11 10 6 2 1 2 Up to 5 5-10 10-15 15-20 20-25 25-30 30-35 35-40 40-45 45 Count of Airports Average Number of Daily Operations with a Flight Plan Filed Distribution of Airports By Average Number of ìDailyî Impacted Flights Airports Affected by Tower Closures Source: ASDI radar data ñ Part 91 151 flying and Part 135/121 flying March 1-7, 2013; masFlight analysis Note: Average ìdailyì operations based on 5-day week 


Example 2: Aviation Safety Causal Factor For example, consider the following ASRS report \(ACN 1031837 Departing IAH in a 737-800 at about 17,000 FT, 11 m iles behind a 737-900 on the Junction departure over CUZZZ Intersection. Smooth air with wind on the nose bearing 275 degrees at 18 KTS We were suddenly in moderate chop which lasted 4 or 5 seconds then stopped and then resumed for another 4 or 5 seconds with a significant amount of ri ght rollingÖ I selected a max rate climb mode in the FMC in order to climb above the wake and flight path of the leading -900 We asked ATC for the type ahead of us and reported the wake encounter. The 900 was about 3,300 FT higher than we were  Synopsis  B737-800 First Officer reported wake encounter from preceding B737-900 with resultant roll and moderate chop What causal factors can be identified from this narrative that could be applied to future predictive applications CAUSAL FACTORS Data-mining algorithms can mine the text of safety reports to obtain specific data that can be used to analyze causal factors  


Example 2: Identifying Causal Factors CAUSAL FACTORS  Indicators ñ Data Element Methods ñ Identifying Context and Causes  Time of day  Date range \(month day  Aircraft type  Fix or coordinates  Originating airport  Destination airport  Weather notes We pinpoint the sequencing of flights on the IAH Junction Seven departure \(at CUZZZ\the specified wind conditions to find cases wher e a B737-900 at 20,000 feet precedes by 11 miles a B737-800 at 17,000 feet  Search related data sets including ASDI flight tracks, local traffic and congestion  Weather conditions for alter native causes \(winds aloft shear and convecti ve activity  Airline specific informati on \(repeated occurrence of event in aircraft type Big data gives us visibility into contextual factors even if specific data points are missing such as a specific date or route Big-data analytics gives us insight into unreported factors as well 


Example 3: Correlating Utilization and Delays  60 65 70 75 80 85 90 95 100 7 9 11 13 ONTIME DEPARTURE PERFORMANCE HOURS OF DAILY UTILIZATION 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Narrowbodies By Day of Week 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Widebodies by Day of Week Daily Utilization vs. On-time Departures January 2013 System Operations Correlation Coefficient -0.53 Includes AA, AC, AS B6 F9, FL, NK, UA, US VX and WN SOURCE masFlight \(masflight.com COMPARING OTP AND UTILIZATION 


 6.2 6.0 5.8 5.8 5.2 4.9 LGB JFK BOS MCO DCA FLL JetBlue Focus Average Daily Deps per Gate Used UTILIZATION BY HUB Example 4: Daily Utilization of Gates, by Hub Big-data analysis of different carriers daily departures per gate used SOURCE masFlight \(masflight.com June 1 through August 31, 2012 Gates with minimum 1x daily use 7.7 7.4 7.2 6.2 6.1 5.8 3.8 3.6 ORD LAX SFO EWR DEN IAH IAD CLE United Airlines Hubs Average Daily Deps per Gate Used 7.8 6.4 5.5 5.4 5.3 4.4 4.3 4.0 SEA SAN PDX ANC SFO GEG LAX SJC Alaska Airlines Hubs Average Daily Deps per Gate Used 7.2 6.9 6.8 6.4 5.0 2.7 ORD DFW LAX LGA MIA JFK American Hubs Average Daily Deps per Gate Used 7.2 6.9 6.6 4.9 4.2 CLT DCA PHL PHX BOS US Airways Hubs Average Daily Deps per Gate Used 6.6 5.9 5.5 4.7 MCO BWI ATL MKE AirTran Hubs Average Daily Deps per Gate Used ne pe 


Conclusions for Big Data in Aviation  Big-data transforms operational and commercial problems that were practically unsolvable using discrete data and on-premises hardware  Big data offers new insight into existing data by centralizing data acquisition and consolidation in the cloud and mining data sets efficiently  There is a rich portfolio of information that can feed aviation data analytics  Flight position, schedules, airport/gate, weather and government data sets offer incredible insight into the underlying causes of aviation inefficiency  Excessive size of each set forces analysts to consider cloud based architectures to store, link and mine the underlying information  When structured, validated and linked these data sources become significantly more compelling for applied research than they are individually  Todayís cloud based technologies offer a solution CONCLUSIONS 


Conclusions:  Our Approach  masFlightís data warehouse and analysis methods provide a valuable example for others attempting to solve cloud based analytics of aviation data sets  masFlightís hybrid architecture, consolidating secure data feeds in on-premises server installations and feeding structured data into the cloud for distribution, addresses the unique format, security and scale requirements of the industry  masFlightís method is well suited for airline performance review competitive benchmarking, airport operations and schedule design and has demonstrated value in addressing real-world problems in airline and airport operations as well as government applications CONCLUSIONS 






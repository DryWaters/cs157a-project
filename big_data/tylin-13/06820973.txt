Modeling Energy Savings in Volunteers Clouds Congfeng Jiang 
Hangzhou Dianzi University 1 2nd Street Xiasha Higher Education Zone Hangzhou 310018 China Email cjiang@hdu.edu.cn Universit  e de Paris 13 PRES Sorbonne Paris Cit  e LIPN UMR CNRS 7030 
 Jian Wan Christophe C  erin  Paolo Gianessi  Yanik Ngoko 
002 002    002  
99 avenue Jean-Baptiste Cl  ement 93430 Villetaneuse France Email christophe.cerin@lipn.univ-paris13.fr 
Abstract 
In this paper we propose different models for the energy consumption in a special existing cloud system named SlapOS In this cloud the data center comprises dedicated and volunteer machines these latter ones are not always available Our objective is to state how to plan the run of applications for minimizing the global energy consumption we propose two modelings In the rst model we assume that we have a nite number of homogeneous volunteers nodes on which our applications can be run The objective is to determine which application to run on each node in order to minimize the 
Index Terms 
overhead in energy consumption caused by these runs We show that the key computational challenge in this problem consists in nding a feasible solution when it exists We propose for it a polynomial time algorithm In the second model we assume that the volunteers nodes are heterogeneous In this case we show again how to nd a feasible solution in polynomial time But in comparison to the homogeneous case the key computational problem to solve here is NP-hard We then propose an ILP Integer Linear Programming formulation for addressing and evaluate it throughout various simulations of the SlapOS system in a realistic volunteer computing context Energy efìciency performance evaluation and 
benchmarking  cloud computing Energy consumption Volunteer and desktop grid computing Linear programming and optimization 
I M OTIVATIONS SlapOS is an open source Cloud Operating system which was inspired by recent research in Grid Computing and in particular by BonjourGrid 4 a meta Desktop Grid middleware for the coordination of multiple instances of Desktop Grid middleware Figure 1 shows the current architecture SlapOS is based on two types of nodes SlapOS Nodes and SlapOS Master SlapOS is an hybrid cloud in the sense that each of its nodes can be dedicated Data center in Figure 1 or dynamically provisioned from volunteers Home 
cloud in Figure 1 The Masterês role is to install applications and run processes on SlapOS nodes It acts as a central directory of all SlapOS Nodes knowing where each SlapOS Node is located and which software can be installed on each node The role of SlapOS Master is to allocate processes to SlapOS Nodes In comparison to the traditional cloud view SlapOS innovates in considering the possibility to build data centers-like with dedicated and volunteer nodes The usage of volunteer nodes can improve the cloud elasticity at lower prices Indeed for managing in users requests or demands it might be cheaper for the cloud owners 
temporal overhead extrastorage 
to negotiate the subscription of volunteer nodes instead of buying new machines Moreover we can beneìt from the fact that volunteer machines might consume less energy Regarding fault tolerance issues volunteer nodes imply that we maintain multiple active copies for each application in order to have a minimum of service availability Doing so however we increase the global energy consumption The purpose of this paper is to optimize these excesses in energy consumption by adequate placements of cloud applications In this paper we propose two models for optimizing the run of applications in our volunteer context In the rst model we assume that we have a nite number of homogeneous 
volunteers nodes on which our applications can be run Homogeneous volunteers means that the computing nodes used in the cloud platform have the same speciìcation This implies for instance that each node can run the same maximal number of applications and that each machine is assumed to have similar or identical power consumption characteristics Heterogeneous volunteers means that the computing nodes may have different speciìcations e.g different power consumption characteristics Considering the homogeneous case rst then the heterogeneous case is conventional in distributed computing Results obtained in the analysis of the homogeneous case are extended in the heterogeneous case Our modeling in the homogeneous case also serve as introducing the discussion and 
the key concepts This step by step methodology can also help understand the rationale of the modeling and the reìnement process Whatever case we consider the objective is to determine which application to run in each node in order to minimize the total overhead in energy consumption caused by these runs In the homogeneous case we show that the key computational challenge consists in nding a feasible solution when it exists In the heterogeneous case we show again how to nd a feasible solution in polynomial time But in comparison to the homogeneous case the key computational problem to solve 
2013 International Conference on Cloud Computing and Big Data 978-1-4799-2829-3/13 $26.00 © 2013 IEEE DOI 10.1109/CLOUDCOM-ASIA.2013.78 52 
2013 International Conference on Cloud Computing and Big Data 978-1-4799-2830-9/14 $31.00 © 2014 IEEE DOI 10.1109/CLOUDCOM-ASIA.2013.78 52 


002 1 0  002  
t i i t 
modeling A Initial Assumptions 
https://slapos.cloud.univ-paris13.fr 
here is NP-hard We then propose an ILP formulation for addressing it and evaluate it throughout various simulation of the SlapOS system in a realistic volunteer computing context We would like to assert that the paper is about rst and not about experiments on a real system However we estimate that our modeling is a good compromise between the parameters we consider impacting the phenomenon and the realism of current cloud technologies For instance our parameter settings consider the SlapOS cloud system running in production and available at  The organization of the paper is as follows In section 2 we introduce some applications of our work and we give further motivations We formalize the energy consumption problem in our cloud system in section 3 and section 4 step by step and we conduct extensive experiments under different conìgurations Section 5 is about related works Section 6 concludes the paper Fig 1 The SlapOS Architecture II A PPLICATIONS OF OUR WORK SlapOS has been ported on a Nexus S mobile phone and under Android 4.0.4 Mobile phones are potential volunteers for hosting applications The following experiment has been made by the SlapOS team They deployed the Wordpress which contains an Apache server application on the Nexus and the operating system was a chrooted Debian The standby processor option Wave Lock was disabled and Wi was enabled Wi Lock A script was coded for writing the date in a le every 5 minutes They measured the battery life when Wordpress was running and when it was not running The script was running in these two cases They noticed a battery life of 22 hours without Wordpress and 12 hours with Wordpress running They also noticed that starting a new Wordpress instance took few seconds with Android These observations reinforce our initial intuitions about the current technology a SlapOS applications may reduce drastically the battery life This high penalty might not motivate volunteers to keep their nodes in SlapOS clouds b the penalty in restarting an application when needed is not prohibitive In another words we could imagine at large scale to use volunteers nodes Tablets Smartphones PCs for hosting Web applications under the condition that we know how to optimize the energy consumption This work is a rst stage for improving the SlapOS scheduler and application manager in this direction In its actual version SlapOS implements the following behavior For joining a SlapOS cloud any new volunteer must rst register its machine to a SlapOS master node by declaring various parameters such as the memory space disk space CPU type location of the machine   Then the volunteer can choose from the catalog of SlapOS applications some that he accepts to install on his machine Finally the volunteer can let his machine opened for other users the machine is registered as public or not For any user SlapOS maintains a list of executable applications These applications are those that the user accepted to install or those that are located on machines nodes registered as public Our study considers the restricted setting where SlapOS manages a nite set of client/server applications on volunteer nodes We call such a system a volunteer cloud At each time instant we must run multiple instances of the server part of each application on volunteers nodes This is both for managing the ow of user requests and preventing faults in execution However these runs are energy consuming For reducing the consumption we propose at any time instant to only start on volunteer nodes a subset of servers we are referring to the server part of applications among those that can be started Naturally these servers must be on available nodes and will be used for all client executions Since volunteers nodes can get disconnected at anytime we need in this strategy to constantly adapt the subset of servers that are maintained active In a technical viewpoint this might require to implement mechanisms for data migration We do not consider this issue in this paper In summary given a set of applications a set of volunteer nodes with their availability distribution the objective of this work is to propose a strategy for making the servers running and available on each volunteer node in order to minimize the global energy consumption In the mid term we expect to include such solutions into the SlapOS system III P ROBLEM D ESCRIPTION F IRST REFINEMENT We have client/servers applications At each time instant we must maintain available instances or copies of the server part of each application In practice a challenging question consists in determining the good value of  This requires a large system analysis that we do not consider in this paper We assume in our modeling that is a known input The applications can be run on volunteers machines We assume that the time is discretized in periods of size for which we have the availability of machines In each period this is given by the vector of size  is the number of machines such that when the machine is available in the interval of time otherwise We are interested in nding for any time interval  the applications 
N k k k m M m m M M t t 
53 
53 


B First Modeling Applications copies must be put on machines that are available copies of each applications must be assigned on exactly distinct machines On any machine  there is a constant number stating the maximal number of application copies that can be assigned to it Fact 3.1 Property 3.2 Proof Proposition 3.3 Proof A Second modeling 
  002 003 004  005 005 O O   O 
002 002 002 002 002  002  1  1 1 2 3 2 3 1  1 1 1 1 1   
base i e i,j min h max h min h min h max h i,j i,j base i e i,j t i,j t t t i,j t t base i e i,j t base i t t e i,j t base i t t e i,j t t e i 002 j j t t e i,j j t i m i j Z j i i m N j j m i i m i i m i i t m i i L i 
t t t t t t i 
m k i P j i P t h C f C C C C P t i t j P t P P t i t t E t t P t dt P P t dt P P t dt P j i i P t dt P t dt E P t dt i j E t t i Z N E M M Z Z C C k k C i q C q C E k M k M q N.k k M C t t M q N.k N.k m N.m M L i Z q m j 
002 003 
to keep active on each machine Let us remark that in doing this we do not consider the global optimization problem in the multiple time intervals and that in practical cases is far larger than  We admit a piece-wise constant model for the energy consumption At any time instant if there is no application running on machine  its power consumption is If however there is an application running on machine  we have an extra power consumption of Wecan relate this model to the one used in In this solution the power consumption for a given computer is given by  corresponds to the power used when the host is idle and is the power consumption when the host is fully used Our model generalizes this formulation by not considering an explicit formulation of the extra consumption led by applications run We denote by the power consumption of machine at time running application  From our previous assumption we have  On machine  the induced energy consumption in interval is given by We assume that machines are identical This implies that the value of is the same whatever machine On identical machines it is also normal to expect a low variation in the energy consumed by a same application on different machines This means given an application and two machines that we have  Therefore we propose to use a constant  Admitting that we have the constants and the availability matrix in a time interval  we are looking in this rst modeling for an assignment of applications copies that will minimize the excess in energy consumption caused by applications run For estimating this excess we consider that the real-time power consumption is linear with respect to the number of application run on each machine Therefore let us admit that on each machine  we assigned copies of the applications  the excess of energy consumption that we want to minimize is Let us remark that to assign an application copy on a machine means that we maintain this application active on it We include in this formulation because there is no energy consumption led by machines that are not available There are some additional constraints that must be fulìlled in order to ensure that any assignment is valid The Figure 2 presents them       Fig 2 Constraints in the rst modeling The idea with constraint is to ensure that we have enough replications executed for any application while ensuring that copies of the same applications are not put on the same machine Let us remark that there is no interest in putting all applications copies in the same machine since an execution fault that occurs in this machine can cause the unavailability of the application A parameter is introduced in constraint for keeping a reasonable CPU load on machines Indeed the more we assign application copies on a machine the lower is their service response time For this rst modeling we have the following results Any feasible solution will lead to the same total energy consumption This cost is equal to  This simple observation suggests that we can nd an optimal solution by looking just for a feasible solution The conditions and are necessary and sufìcient for the existence of a feasible solution If then it will be impossible to put applications copies on distinct machines The constraint will be violated Given the availability matrix the total number of copies that can be run in the time interval is  There is a feasible solution only of this number is at least equal to the number of application copies   If a feasible solution exists then it can be found in  Indeed a feasible solution can be obtained from Algorithm 1 see page 4 The worst case complexity of this algorithm is in  However if there exist a feasible solution then we will always have and in executing the while loop because of the ordering Since the ordered list can be created in  we have the proof IV I NTRODUCING A FORM OF HETEROGENEITY S ECOND REFINEMENT Let us now consider a setting where machine are heterogeneous Our initial assumption states that the energy consumption led by the run of application in machine 
             002   002         002    002         002  1    002             1   
002 002 002 003 003 002 004 004 004 004 004 004 004 
54 
54 


002 004 004 004 004 004 
1       002  1 1 0 1  3 3 1 1 2     2   1 1         
m i L i L i L i t base i t t e i,j base i i,j m m i   Z  base i m i j 003 Z i,j i m i i m i i i L i L i i base i i j base i i,j m u u 003 m m i i L i L i L i L i 
 and    and   On any machine  there is a constant number stating the maximal number of application copies that can be assigned to it B Feasibility and complexity in the heterogeneous case Proposition 4.1 Proposition 4.2 Proof  and    and   
006  006  005   007   005 005 O   O 003      006  006  005   007   
1 2 for 4 end 5 for 7 while 10 11 end 12 13 end 14 end Algorithm 1 1 2 for 4 end 5 for 7 while 10 11 end 12 13 end 14 end Algorithm 2 
 A vector of application copies the availability matrix  empty sets  An assignment for each machine Create and ordered list of machine indices   from the available to the non available Feasible solution in homogeneous case is  Since the machines are heterogeneous both terms of this sum might differ for an application ran in distinct machines Let us denote the rst term by and the second by  In the rst modeling we stated that the minimization goal was to reduce the excess in energy consumption led application runs This formulation is natural since either the machine will be available and not used or it will be available and exploited in our assignment It is not easy however in the heterogeneous case to nd a good formulation for capturing the excess in energy consumption Indeed the machines here have different energy consumptions when they are idle It is important to include this difference in our minimization objective Therefore in the heterogeneous case what we are looking for is an assignment that minimizes Any assignment here must again respect the constraints deìned on Figure 2 We however consider here that the maximal threshold above which there is a performance degradation due to the execution of multiple application can differ per machines We then reformulate the constraint as follows in Figure 3   Fig 3 Constraints C 3 As for the homogeneous one we cannot always ensure that there is a feasible solution in the heterogeneous case We can also establish that such a solution however will exist if the conditions and are met Finally we have the following result A feasible solution in the second modeling can be found in  Such a solution can be obtained by adapting our previous algorithm for building a feasible solution in the homogeneous case We propose Algorithm 2 The initial ordering that we did ensure that we will always have   and   Since can be created in  we have the result The feasible solution returned by Algorithm 2 is not always optimal There is indeed a simple counter example Let us consider the case where we have application and one copy for each  Let us also assume that we have machines available such that  Finally let us assume that  where is available  It is clear in this setting that the feasible solution returned by Algorithm 2 will not be optimal One can criticize this proof since we chose  However the argument used in it can easily be generalized even for   A vector of application copies the availability matrix  empty sets  An assignment for each machine Create and ordered list of machine indices   in using as rst criteria the availability and second one the value of from greater to smaller Feasible solution in heterogeneous case Since any feasible solution will not necessarily be optimal we need to nd another approach for obtaining the optimal solution in the heterogeneous case The following result shows that even in feasible cases it will not be simple to nd an optimal solution 
T N M m m Z Z Z i L m j N T j k j N i T j i<m M L i Z q Z Z j T j T j i i i P P t dt E E Z Z E E C C i q M k M q N.k N.k m M L i Z q L m N k l q N i j E E E E i q u k k T N M m m Z Z Z i L m q j N T j k j N i T j i<m M L i Z q Z Z j T j T j i i 
Data Result do 3 do 6 do 8 if then 9 Data Result do 3 do 6 do 8 if then 9 
1  1  1 1   1 0   0     1      1  1 002             1   1   arg max 1 1 1  1  1 1   1 0   0     1      1  1 
t i  i m m 
in the second modeling We now discuss about the feasibility and the complexity in the heterogeneous case 
55 
55 


i v 
 1 1 1   1 3 1 1  1 1 1 1 2 
i,j i i m i base i i i m i i i i q v i j i,j p i i v v m i,j i,j i,j i m i N j i,j i,j m i base i i i,j i m i i,j i N j i,j i i i i i 
005 004 004 006 004 004 004 006 006 
  
 1  0   0 1 1 1 1   1   1 2 1 1 0 0 1 1   min 0 1 0 1  1 
The computation of the optimal solution in the heterogeneous case is NP-hard The proof is obtained by a reduction to the minimum knapsack problem Let us indeed assume that  is the same Then the problem can be reduced to the one of choosing a subset of machines with minimal base energy consumption and whose global capacities is enough for executing copies More formally let us consider a variable deìned as follows if at least one application is assigned on otherwise Then the optimization problem to solve is the following Minimize such that 1 2 In this formulation we did not include the energy consumption induced by the execution of applications since its global cost will be the same whatever feasible solution we have This formulation corresponds exactly to the minimum knapsack problem Since this latter problem is NP-hard we have the proof This NP-hardness reduction is based on the idea that it is hard to determine the right subset of machines that should be used in order to reduce energy consumption In the case however where this subset is known the problem is not necessarily hard More formally we have the following result If and we have the subset of machines used in the optimal solution then the optimal feasible solution can be computed in pseudo-polynomial time The proof is obtained from a reduction to the assignment problem Let us assume that in the optimal solution applications must be deployed exactly on the machines  We propose to associate the heterogeneous case with the following assignment problem For each machine  we create unit machines such that on each of them we can run at most one application at a given time instant Given any application  its energy consumption on a unit machine is  Let us consider that If  we also create virtual applications such that on any unit machine  the energy consumption of the virtual copy is  The goals of this assignment problem are the following 1 there is one application assigned to any unit machine 2 any application is assigned to only one unit machine 3 the sum of the energy consumed by applications on assigned machine is minimized It straightforward to notice that the creation of this assignment problem from the initial heterogeneous problem can be done in pseudo polynomial time Virtual applications in this reduction serve for having a bijection as in the classical assignment problem From any solution of this assignment problem we can derive a solution for the original heterogeneous problem This can be done by putting the application on the machine if in the related assignment problem is assigned to a unit machine  Since this assignment problem can be solved in by the mean of the Hungarian algorithm we have the proof Thus in the case where  we can nd an optimal solution by building subset of machines and solving on each an assignment problem The algorithm proposed for can be generalized for an arbitrary  The idea is to consider successive allocations of one copy of each application until all copies are deployed This means that we solve assignment problems The solution that results in the lowest energy consumption is retained In doing so we obtain a local solution to the global optimization problem obtained however in exponential time If this can be interesting for small values of  we do believe that if we have to spend an exponential time near exact or exact solution are preferable Consequently in what follows we propose a mixed integer linear programming model that can be used in the general case The proposed model are based on the following variables and constants For any machine and application  we have a decisional variable If  then the application must be deployed on machine  Otherwise For any machine wehavea variable that will comprise if at least one application is assigned to it We derive the following model 1 s.t 2 3 4 5 6 Let us remark here that the equation 3 ensures both that the constraints and are met The equation 6 ensures that we can assign at least one applications on the machine  Moreover an assignment of at least one application implies to set to  The proposed formalization is a standard 01 programming problem The next section is devoted to our experiments 
003 006  005  006 003 006 003 003 010 003 
Theorem 4.3 Proof Theorem 4.4 Proof C An integer linear programming model for the second modeling 
i j E x x i E x x  i m x q N.k k p i q i i j i E E Q q Q>N Q N i j i j i O Q k k k k k i j A A j i A i x z E A E x z A  i j x  i A M k j A M q x i C C q i x 
56 
56 


002  k        E E 
base 
 
  
We performed some experiments in order to observe How the ILP runtime behave with a huge number of machines because it is one of the key factors that usually have impact on the user experience How is the energy distributed in using our allocation modeling For observing the energy distribution we will use two notions the distribution of the energy and the service distribution The distribution of the energy captures the total energy consumption when doing experiments with a given number of nodes The service distribution metric returns for each machine the total number of applications copies that were run on them during the experiments We created various conìgurations with different number of machines  from to  Given a machine number we created an availability matrix for a period of hours discretized in hour We assumed that the availability of our machines obey to a Weibull distribution with the parameters  and as in W e assumed while using this distribution that a machine is available if the probability returned by the implementation is respectively or according to the experiment In this way we obtain the availability of machines during one hour We assumed that we have applications with copies The queue lengths and the energy values   were generated with a Gaussian law The parameters used for generation are given in Figure 4 Finally let us recall that by the mean of our generation approach for the matrix availability it might happen that some machines donêt be used Thus we reported in the same gure the mean effective number of machines used for each conìguration We used Matlab for implementing and generating optimal solutions of our Integer Linear Programming model In Figure 7 we present the evolution of the cumulative energy consumed due to application runs when considering various number of machines The accumulated energy diminishes as we increase the number of machines But the reason for this is simple the more we have machines the more we have available ones suitable for running our application This also means that the consumed energy decreases here because we used a random setting generation Finally let us precise that in this plot and in the others it is the cumulative results observed for a period of hours that are reported For the service distribution metrics we plotted the gure where the x axis is machine node y axis is hours 1 to 24 z axis is the accumulated application instances executed on the node for each hour Figures 5 and 6 are samples of our results This kind of gure more exactly the shapes may help the applications provider to nd some trends for application distribution and migrations From the service distribution results we can see that the accumulated service instance execution decreases when the number of machines increases from 100 to 500 It is intuitive that for large scale cloud system more nodes can reduce the workload on individual node and balance the workload However Figures 5 and 6 also show that more energy is consumed if few machines acceptable probability 0.4 are available for the same amount of application replications in the heterogeneous volunteer cloud One explanation is that with less machines we have less choice to allocate services on machines Therefore a larger system scale is not only important for load balancing but also important for application ofîoading this is because we can nd optimal application placement such that the energy consumption is also minimal Fig 7 Tabular 4 summarizes the above results and discussion If we extend the system scale to very large i.e 1 million nodes itês nearly impossible for the solver to nd an optimal application placement solution in 1 minute due to the huge searching space Actually in Matlab version 2010b it costs almost 28.3613 seconds to generate such solution with 20 applications and each application with 3 copies in a system with 3000 node\(available node number is 2607 We can see in Fig.8 that the solution time increases almost linearly with the number of available nodes In our simulation when the number of available nodes is 3474 accept prob is 02 for 4000 total nodes in one case then the size of the problem is too large for the current solver in Matlab without hacking into the optimization solver Moreover if we increase the scale of the problem in other dimension i.e the number of application types from 20 to 100 or increase the number of copies from 3 to upper value it cost much more time to generate such solution Therefore we should tradeoff between the realtime response of the application allocation and the optimal allocation with less energy consumption Fig 5 Services distribution\(100 nodes,acceptable probability=0.2 V R ELATED WORK The context of our work is related to volunteer computing and Desktop Grid Computing Desktop Grids DG ha v e 
D Experiments E Experimental Settings F Experimental Results 
100 4000 24 1 0 393 2 964 0 2 0 4 0 6 0 8 20 3 24 
57 
57 


e e 
 002 
and are the mean and standard deviation value used for generating machines energy consumptions Fig 6 Services distribution 3000 nodes,acceptable probability=0.4 Fig 7 Energy consumption of different allocations with same application instances on different available nodes energy consumption is normalized been successfully used for solving scientiìc applications at low cost DGs middleware such as Condor BOINC 8 XtremWeb OurGrid 10 pro vide researchers a wide range of high throughput computing systems by utilizing idle resources However we did not nd in this context a work that aims at optimizing the energy consumption in a setting similar to the one considered in this paper In authors introduce a synthesis of the usage of methFig 8 Solution time\(in seconds for one scheduling interval mean value of 20 measuring on the experimenting laptop ods and technologies used for energy-efìcient operation of computer hardware and network infrastructure They consider the ICT eld in general and they focus on energy-aware scheduling in multiprocessor and grid systems on the power minimization in clusters of servers on the power minimization in wireless and wired networks Clouds are not speciìcally considered in their work In authors propose an ef cient resource po wer management policy for virtualized Cloud data centers The objective is to continuously consolidate virtual machines They show that the dynamic reallocation of virtual machines brings substantial energy savings They propose four criteria for migrating the virtual machines Authors do not discuss about the quality of the solution and they recognize that despite the fact that they use heuristics the algorithms provide good experimental results We believe that our solution can be extended for consolidating virtual machines in a volunteer context In Beloglazo v and Buyya propose online algorithms for virtual machines placement with guaranty of performance They conduct competitive analysis and prove competitive ratios of optimal online deterministic algorithms for a single virtual machine migration and dynamic virtual consolidation problems An interesting future work is to extend this result to volunteers clouds contexts Beaumont Eyraud-Dubois and Larchev 032 eque consider in  the problems of reliable service allocation in clouds Among the different papers introduced in this section it is a paper that cover similar problems than ours They consider rst that mapping virtual machines having heterogeneous com 
Node acc.prob av.nodes ass.apps avg  stddev energy solu.time 100 0.2 93 60 0.4991 0.2868 5.4255 2.6940 1.1606 0.6335 100 0.4 40 60 0.5183 0.2912 5.2826 2.7862 2.9799 0.3763 500 0.2 431 60 0.5081 0.2873 5.4362 3.0287 0.3274 4.0052 500 0.4 168 60 0.5081 0.2891 5.4043 2.8258 0.6866 1.6589 1000 0.2 873 60 0.5014 0.2894 5.5487 2.8081 0.1192 6.6276 1000 0.4 362 60 0.5007 0.2893 5.5470 2.9084 0.3069 3.3893 2000 0.2 1749 60 0.4983 0.2884 5.5597 2.8579 0.0657 17.3444 2000 0.4 682 60 0.4968 0.2898 5.6012 2.8022 0.1651 5.5039 3000 0.2 2607 60 0.4980 0.2894 5.4956 2.8779 0.0387 28.3613 3000 0.4 1059 60 0.5005 0.2898 5.3654 2.8180 0.1003 8.2305 4000 0.4 1426 60 0.5000 0.2884 5.3212 2.8794 0.0715 13.0007 Fig 4 Overall Statistics for the experiments 10 examples of one scheduling interval Here acc.prob is the accept probability av.nodes is the number of available nodes ass.apps is the number of assigned application instances,solu.time is the time consumed by the Matlab solver for one solution 
e e i i 
 002 q q 
58 
58 


n 
 pages 765Ö766 IEEE 2011  Christophe C  erin and Gilles Fedak  Chapman  Hall/CRC Numerical Analysis and Scientiìc Computing Series 2012  Heithem Abbes Christophe C  erin and Mohamed Jemni BonjourGrid as a Decentralised Job Scheduler In  pages 89Ö94 IEEE 2008  Heithem Abbes Christophe C  erin and Mohamed Jemni BonjourGrid Orchestration of multi-instances of grid middlewares on institutional Desktop Grids In  pages 1Ö8 IEEE 2009  Damien Bor getto Henri Casano v a Geor ges Da Costa and Jean-Marc Pierson Energy-aware service allocation  28\(5 2012  Bahman Ja v adi Derrick K ondo Jean-Marc V incent and Da vid P  Anderson Discovering Statistical Models of Availability in Large Distributed Systems An Empirical Study of SETI@home  22\(11 2011  Ali R Butt Rongmei Zhang and Y  Charlie Hu A self-or ganizing ock of condors  66\(1 2006  Da vid P  Anderson BOINC A System for Public-Resource Computing and Storage  0:4Ö10 2004  G Fedak C Germain V  Neri and F  Cappello XtremW eb a generic global computing system  pages 582 587 2001  Nazareno Andrade W alfredo Cirne Francisco V ilar Brasileiro and Paulo Roisenberg OurGrid An Approach to Easily Assemble Grids with Equitable Resource Sharing  2862:61Ö86 2003  Andreas Berl Erol Gelenbe Marco Di Girolamo Gio v anni Giuliani Hermann de Meer Dang Minh Quan and Kostas Pentikousis EnergyEfìcient Cloud Computing  53\(7 2010  Anton Beloglazo v and Rajkumar Buyya Ener gy Ef cient Allocation of Virtual Machines in Cloud Data Centers In  pages 577Ö578 IEEE 2010  Anton Beloglazo v and Rajkumar Buyya Optimal online deterministic algorithms and adaptive heuristics for energy and performance efìcient dynamic consolidation of virtual machines in Cloud data centers  24\(13 1420 2012  Oli vier Beaumont Lionel Eyraud-Dubois and Hubert Larche v 032 eque Reliable service allocation in clouds In  pages 55Ö66 IEEE Computer Society 2013  M R Gare y and Da vid S Johnson W H Freeman 1979  Mark W eiser  Brent B W elch Alan J Demers and Scott Shenk er  Scheduling for Reduced CPU Energy In  pages 13Ö23 USENIX Association 1994  Etienne Le Sueur and Gernot Heiser  Dynamic V oltage and Frequenc y Scaling The Laws of Diminishing Returns In  Vancouver Canada Oct 2010  Aaron Carroll and Gernot Heiser  An analysis of po wer consumption in a smartphone In  pages 1Ö12 Boston MA USA Jun 2010 
n 
15 2 
puting demands onto physical machines having heterogeneous capacities can be modeled as a multi-dimensional bin-packing problem They assume that each virtual machine comes with its failure rate i.e the probability that the machine will fail during the next time period But they do not consider that services should be duplicated on different machines to derive a robust solution The authors focus on formal speciìcations of the problems as we usually do before deriving complexity results then they show and prove complexity results For instance to prove Theorem 5.1 they use a reduction to the 3-partition problem  F or the e xperiments the y consider only machines far below our study because they say that computing the reliability of an allocation takes time  In authors study the problem of ener gy-a w are resource allocation for hosting long-term services or on-demand compute jobs in clusters They do not capture the possibility of copies but they have a constraint on the RAM available on each node The objectives and constraints lead to greedy algorithms This work is similar to our work but the main differences are that for each job allocated to a machine we must have to decide the fraction of CPU to use and we need also for an estimate of the RAM consumption of the job The fraction of CPU is for studying a form of heterogeneity but it does not include all the cases that can be derived from our heterogeneous modeling We do not model the commonly-used Dynamic Voltage and Frequency Scaling DVFS power management technique  17 as it is no w a v ailable on most processors including processors for smartphones and tablets DVFS is able to reduce the power consumption of a CMOS integrated circuit by scaling the frequency at which it operates and when the load varies dynamically VI C ONCLUSION In this paper we explain how to optimize the energy consumption in a context where volunteers nodes are used for building a cloud Our proposal consists in two models one in homogeneous context and the other one in heterogeneous ones We then propose various experiments using Matlab for solving the combinatorial problem in order to observe the system behavior suggested by our models The simulation results show that our modeling is effective and suitable for real volunteer cloud environment For future since we need to ofîoad the copies of applications to various machines with different availability patterns we should also consider more realistic issues including the performance and user experiences on the devices network latency and data transportation and communication time We can also use a weighted objective function for energy consumption and other performance overheads like application migrations The network-dependent factors have signiìcant impact on user-perceived performance of the hosting applications The network communications also consumes lots of energy The cellular connectivity is one of the biggest contributors of energy consumption in a smartphone The task afìnity and QoS guarantees are also important in real volunteer cloud environment VII A CKNOWLEDGMENT The funding supports of this work by Natural Science Fund of China No 61003077 Natural Science Fund of Zhejiang Province Y1101092 and Research Fund of Department of Education of Zhejiang Province No GK100800010 are greatly appreciated In France this work is funded by the FUI12 Resilience project from the ministry of industry R EFERENCES  Jean-P aul Smets-Solanes Christophe C  erin and Romain Courteaud SlapOS A Multi-Purpose Distributed Cloud Operating System Based on an ERP Billing Model In Hans-Arno Jacobsen Yang Wang and Patrick Hung editors 
IEEE SCC Desktop Grid Computing APSCC IPDPS Future Generation Comp Syst IEEE Trans Parallel Distrib Syst J Parallel Distrib Comput Grid Computing IEEE/ACM International Workshop on Cluster Computing and the Grid 2001 Proceedings First IEEE/ACM International Symposium on Job Scheduling Strategies for Parallel Processing 9th International Workshop JSSPP 2003 Seattle WA USA June 24 2003 Revised Papers Comput J CCGRID Concurrency and Computation Practice and Experience IPDPS Computers and Intractability A Guide to the Theory of NP-Completeness OSDI Proceedings of the 2010 Workshop on Power Aware Computing and Systems HotPowerê10 Proceedings of the 2010 USENIX Annual Technical Conference 
59 
59 


We now evaluate the overhead of the FChain system Table II lists the CPU cost of each key module in FChain We observe that most modules in FChain is light-weight The most computation-intensive module is the abnormal change point selection component which is triggered only when a performance anomaly occurs F Chain also distributes the change point computation load on different hosts and executes them in parallel to achieve scalability The online validation takes about 30 seconds for each component since we need some time to observe scaling impact for deciding whether we have made a pinpointing error However the online validation is only performed on those suspicious components pinpointed by the integrated fault diagnosis module The FChain daemon running inside the Domain 0 of each host imposes less than 1 CPU load and consumes about 3MB memory during normal execution IV R ELATED W ORK Our work is rst closely related to previous black-box fault localization schemes F or example NetMedic p rovided detailed application-agnostic fault diagnosis by learning inter-component impact NetMedic rst needs to assume the knowledge of the application topology To perform impact estimation NetMedic needs to nd a historical state that is similar to the current state for each component However for previously unseen anomalies we might not be able to nd a historical state that is similar to the current state for the faulty components Under those circumstances NetMedic assign a default high impact value whic h sometimes lead to inaccurate diagnosis results as shown in Section III In comparison FChain can diagnose previously unseen anomalies and does not assume any prior application knowledge Oliner et al proposed to compute anomaly scores using the histogram approach and correlates the anomaly scores of different components to infer the inter-component inîuence graph As shown in Section III it is difìcult for the histogram-based anomaly detection to perform online fault localization over suddenly manifesting faults Moreover unrelated components can have indirect correlations caused by workload uctuations which will cause their system to raise false alarms In comparison FChain is more robust to different types of faults and workload uctuations To achieve black-box diagnosis researchers have also explored various passive network trafìc monitoring and analysis techniques such as Sherlock  O ri on 27 S N A P  28 However those analysis schemes can only achieve coarsegrained machine-level fault localization Additionally during our experiments we found that previous network trace analysis techniques cannot handle continuous data stream processing applications due to the lack of gaps between packets for extracting different network ows Project5 and E2EProf performed cros s correl a t i ons bet w een mes s a ge traces to derive causal paths in multi-tier distributed systems WAP5 e x t e nds t h e b l ack-box caus a l p at h a nal y s i s t o support wide-area distributed systems Orion di s c o v e rs dependencies from network trafìc using packet headers and timing information based on the observation that the trafìc delay distribution between dependent services often exhibits typical spikes LWT propos ed t o di s c o v e r t he s i mi l a ri t y of the CPU usage patterns between different VMs to extract the dependency relations hips between different VMs However as shown in our experiments dependency-based fault localization techniques are not robust which can make frequent pinpointing mistakes due to various reasons e.g the back pressure effect in distributed applications common network services pinpointed as culprits Furthermore existing dependency discovery techniques need to accumulate a large amount of trace data to achieve reasonable accuracy Particularly network trace based techniques only support requestand-reply types of applications which fail to discover any dependency in continuously running applications such as data stream processing systems In contrast FChain provides online fault localization which does not require any training data for anomalies or a large amount of training data for normal behaviors FChain is fast which can quickly localize faulty components with high accuracy af ter the performance anomaly is detected A urry of research work has proposed to use end-to-end tracing for distributed system debugging Magpie  i s a request extraction and workload modelling tool that can record ne-grained system events and correlate those events using an application speciìc event sch ema to capture the control ow and resource consumption of each request Pinpoint t ak es a request-oriented approach to tag each call with a request ID by modifying middleware platform and applies statistical methods to identify components that are highly correlated with failed requests Monitor t racks t he reques t s e xchanged b et ween components in the system and performs probabilistic diagnosis on the potential anomalous components X-Trace i s a n integrated cross-layer crossapplication tracing framework which tags all network operations resulting from a particular task with the same task identiìer to construct a task tree Spectroscope can di agnos e p erformance anomal i e s b y comparing request ows from two executions In contrast our approach does not require any instrumentation to the 
G FChain System Overhead Measurements 
System Modules CPU cost 
VM monitoring 6 attributes 1.03 0.09 m illisec onds Normal uctuation modeling 22.9 2 millis econds 1000 samples Abnormal change point selection 602.4 105.2 m illisec onds 100 samples Integrated fault diagnosis 22 1 microseconds Online validation per-component 30 1 seconds TABLE II FC HAIN OVERHEAD MEASUREMENTS  size for the DiskHog fault in Hadoop The reason has been described in Section III-A Generally the look-back window should be long enough to capture the fault manifestation We are currently investigating an adaptive look-back window conìguration scheme by examining the metric changing speed 
     
206 
29 
29 


application or middleware platform to collect request ows Thus it is much easier to deploy FChain in large-scale IaaS clouds Blacksheep correl a t e s t he change poi nt of s y s t em-l e v el metrics e.g cpu usage with the change in count of Hadoop application states i.e events extracted from logs of DataNodes and TaskTrackers to detect and diagnose the anomalies in a Hadoop cluster Kahuna-BB correl a t e s b l ack-box dat a system-level metrics and white-box data Hadoop console logs across different nodes of a MapReduce cluster to identify faulty nodes In comparison FChain is a black-box fault localization system which is application-agnostic without requiring any knowledge about the application internals We believe that FChain is more practical and attractive for IaaS cloud systems than previous white-box or gray-box techniques V C ONCLUSION In this paper we have presented FChain a robust blackbox online fault localization system for IaaS cloud computing infrastructures FChain can quickly pinpoint faulty components immediately after the performance anomaly is detected FChain provides a novel predictability-based abnormal change point selection scheme that can accurately identify the onset time of the abnormal behaviors at different components processing dynamic workloads FChain combines both the abnormal change propagation knowledge and the inter-component dependency information to achieve robust fault localization FChain can further remove false alarms by performing online validation We have implemented FChain on top of the Xen platform and conducted extensive experimental evaluation using IBM System S data stream processing system Hadoop and RUBiS online auction benchmark Our experimental results show that FC hain can achieve much higher accuracy i.e up to 90 higher precision and up to 20 higher recall than existing schemes FChain is light-weight and non-intrusive which makes it practical for large-scale IaaS cloud computing infrastructures A CKNOWLEDGMENT This work was sponsored in part by NSF CNS0915567 grant NSF CNS0915861 grant NSF CAREER Award CNS1149445 U.S Army Research Ofìce ARO under grant W911NF-10-1-0273 IBM Faculty Awards and Google Research Awards Any opinions expressed in this paper are those of the authors and do not necessarily reîect the views of NSF ARO or U.S Government The authors would like to thank the anonymous reviewers for their insightful comments R EFERENCES   A m azon E las tic Com pute Cloud  h ttp://a w s  a m azon com ec2   V i rtual c om puting lab  http://vcl ncs u  e du  P  Barham  A  D onnelly  R I s aacs  a nd R M o rtier   U s ing m agpie f or request extraction and workload modelling in 
 2004  M  Y  Chen A  A ccardi E  K icim an J  L lo yd D  P atters on A  F ox and E Brewer Path-based failure and evolution management in  2004  R F ons eca G  P o rter  R H  K atz S  S h enk e r  and I  S toica X T race A pervasive network tracing framework in  2007  I  Cohen M  G o lds z m i dt T  K elly  J  S ym ons  a nd J  S  Chas e Correlating Instrumentation Data to System States A Building Block for Automated Diagnosis and Control in  2004  I  C ohen S  Z h ang M  G o lds z m i dt J  S ym ons  T  K elly  a nd A  F ox Capturing indexing clustering and retrieving system history in  2005  S  D uan S  Bab u  a nd K  M unagala F a A s ys tem for a utom ating failure diagnosis in  2009  S  K andula R Mahajan P  V erkaik S  A garw al J  P a dhye a nd V  Bahl Detailed diagnosis in computer networks in  2009  A  J  O liner  A  V  K ulkarni and A  A ik en  U s ing c orrelated s u rpris e to infer shared inîuence in  2010  P  Bahl R Chandra A  G r eenber g  S  K andula D  A  M altz and M Zhang Towards highly reliable enterprise network services via inference of multi-level dependencies in  2007  Z  G ong X  G u  a nd J  W ilk es   P RE S S  P Redicti v e E las tic ReS ource Scaling for Cloud Systems in  2010  H  N guyen Y  T a n and X  G u P A L  P ropagation-a w are a nom aly localization for cloud hosted distributed applications in  2011  B Gedik H Andrade K L  W u P  S  Y u and M  D oo SP ADE  t he system s declarative stream processing engine in  2008  A pache H adoop S y s tem   http://hadoop apache  or g/co re   Rice uni v e rs ity bidding s y s tem   http://rubis  objectw eb  o r g   M Ben-Y e huda D  B reitgand M F actor  H  K o lodner  V  K r a v ts o v  and D Pelleg NAP a building blo ck for remediating performance bottlenecks via black box network analysis in  2009  Y  T a n X  G u  a nd H  W a ng  A dapti v e s ys tem anom aly prediction f or large-scale hosting infrastructures in  2010  D  L  M ills   A b rief his t ory o f N T P tim e m e m o irs o f a n i nternet timekeeper  2003  Y  T a n H  N guyen Z  S h en X  G u C V e nkatram ani and D  R ajan PREPARE Predictive Performance Anomaly Prevention for Virtualized Cloud Systems in  2012  M  Bas s e ville and I  V  N ikiforo v   Prentice-Hall Inc 1993  L  Cherkaso v a  K  O zonat N Mi J  S ym ons a nd E  Sm irni  Anom aly application change or workload change towards automated detection of application performance anomaly and change in  2008  P  Barham and e t al   X e n a nd the a rt of virtualization  i n  2003  T he ircache p roject  h ttp://www.ircache.net  H ttperf  h ttp://code google com  p htt p er f  S  K u llback  T h e ku llback-leibler distance  1987  X  Chen M  Z hang Z  M  M a o and P  B ahl  A utom ating n etw ork application dependency discovery experiences limitations and new solutions in  2008  M Y u  A  G reenber g  D  M altz J  Re xford L  Y u an S  K andula and C Kim Proìling network performance for multi-tier data center applications in  2011  M K  A guilera J  Mogul J  W iener  P  R e ynolds  a nd A  Muthitacharoen Performance debugging for distributed systems of black boxes in  2003  S  A g arw ala F  A l e g re K  S chw a n and J  M ehalingham  E 2E P r of A utomated end-to-end performance management for enterprise systems in  2007  P  Re ynolds  J  L  W iener  J  C M ogul M  K  A guilera and A  V ahdat  WAP5 black-box performance debugging for wide-area systems in  2006  R Apte L  Hu K  S chw a n and A  G hosh L ook W ho s T alking Discovering dependencies between virtual machines using cpu utilization in  2010  G Khanna I  L aguna F  A rshad an d S Bagchi Distr ibuted diagnosis of failures in a three tier e-commerce system in  2007  R R S a m b as i v an A  X  Z heng M  D e Ros a  E  K re v at S  W h itm an M Stroucken W Wang L Xu and G R Ganger Diagnosing performance changes by com paring request ows in  2011  J  T a n a nd P  N a ras i m h an  RA M S and B lackS h eep I nferring w h ite-box application behavior using black-box techniques CMU Tech Rep 2008  J  T a n X  P a n E  Marinelli S  K a vulya R  G andhi a nd P  N a ras i m h an Kahuna Problem diagnosis for mapreduce-based cloud computing environments in  2010 
OSDI NSDI NSDI OSDI SOSP ICDE SIGCOMM DSN SIGCOMM CNSM SLAML SIGMOD ICAC PODC Computer Communication Review ICDCS Detection of abrupt changes theory and application DSN SOSP The American Statistician OSDI NSDI SOSP DSN WWW HotCloud SRDS NSDI NOMS 
207 
30 
30 


A Global Solution COVERAGE North and South America EMEA and Asia White lines are flights in the masFlight platform from February 8, 2013 Yellow pins are weather stations feeding hour ly data to our platform Maps from Google Earth / masFlight masFlight tracks flights, airports and weather around the world  Global daily flight information capture  82,000 flights  350 airlines  1700 airports  Integrated weather data for 6,000 stations  Match weather to delays  Validate block forecasts at granular level  Add weather analytics to IRROPS review and scenario planning 


Example 1: Proposed FAA Tower Closures masFlight used big-data to link airport operations across three large data sets  Current and historical airline schedules  Raw Aircraft Situation Display to Industry \(ASDI\AA  Enhanced Traffic Management System Counts \(ETMS\Airport operations counts by type \(commercial, freight, etc TOWER CLOSINGS Dots indicate closures; Red dots have scheduled service Based on scheduled service March 1 7, 20 13; scheduled service includes scheduled charter flights, cargo flig hts, and passenger flights Dots  indicate  closures  Red  dots  have  scheduled  service Bas ed  o n sc h edu l ed  se rvi ce  M a r c h 1  7, 2013; scheduled se rvi ce includ es scheduled c harter fli g hts car g o fli g hts a nd passen g er fli g hts Findings: Proposed Tower Closings  From schedules database: 55 airports with scheduled passenger airline service  14 EAS Airports  From ASDI & ETMS: 10,600 weekly flights on a flight plan \(ex. VFR and local traffic  6,500 Part 91/125 weekly flights  4,100 Part 135/121 weekly flights  


Example 1: Big-Data Analytics Applied to ASDI and ETMS To Analyze Operations TOWER CLOSINGS  26 44 24 23 11 10 6 2 1 2 Up to 5 5-10 10-15 15-20 20-25 25-30 30-35 35-40 40-45 45 Count of Airports Average Number of Daily Operations with a Flight Plan Filed Distribution of Airports By Average Number of ìDailyî Impacted Flights Airports Affected by Tower Closures Source: ASDI radar data ñ Part 91 151 flying and Part 135/121 flying March 1-7, 2013; masFlight analysis Note: Average ìdailyì operations based on 5-day week 


Example 2: Aviation Safety Causal Factor For example, consider the following ASRS report \(ACN 1031837 Departing IAH in a 737-800 at about 17,000 FT, 11 m iles behind a 737-900 on the Junction departure over CUZZZ Intersection. Smooth air with wind on the nose bearing 275 degrees at 18 KTS We were suddenly in moderate chop which lasted 4 or 5 seconds then stopped and then resumed for another 4 or 5 seconds with a significant amount of ri ght rollingÖ I selected a max rate climb mode in the FMC in order to climb above the wake and flight path of the leading -900 We asked ATC for the type ahead of us and reported the wake encounter. The 900 was about 3,300 FT higher than we were  Synopsis  B737-800 First Officer reported wake encounter from preceding B737-900 with resultant roll and moderate chop What causal factors can be identified from this narrative that could be applied to future predictive applications CAUSAL FACTORS Data-mining algorithms can mine the text of safety reports to obtain specific data that can be used to analyze causal factors  


Example 2: Identifying Causal Factors CAUSAL FACTORS  Indicators ñ Data Element Methods ñ Identifying Context and Causes  Time of day  Date range \(month day  Aircraft type  Fix or coordinates  Originating airport  Destination airport  Weather notes We pinpoint the sequencing of flights on the IAH Junction Seven departure \(at CUZZZ\the specified wind conditions to find cases wher e a B737-900 at 20,000 feet precedes by 11 miles a B737-800 at 17,000 feet  Search related data sets including ASDI flight tracks, local traffic and congestion  Weather conditions for alter native causes \(winds aloft shear and convecti ve activity  Airline specific informati on \(repeated occurrence of event in aircraft type Big data gives us visibility into contextual factors even if specific data points are missing such as a specific date or route Big-data analytics gives us insight into unreported factors as well 


Example 3: Correlating Utilization and Delays  60 65 70 75 80 85 90 95 100 7 9 11 13 ONTIME DEPARTURE PERFORMANCE HOURS OF DAILY UTILIZATION 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Narrowbodies By Day of Week 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Widebodies by Day of Week Daily Utilization vs. On-time Departures January 2013 System Operations Correlation Coefficient -0.53 Includes AA, AC, AS B6 F9, FL, NK, UA, US VX and WN SOURCE masFlight \(masflight.com COMPARING OTP AND UTILIZATION 


 6.2 6.0 5.8 5.8 5.2 4.9 LGB JFK BOS MCO DCA FLL JetBlue Focus Average Daily Deps per Gate Used UTILIZATION BY HUB Example 4: Daily Utilization of Gates, by Hub Big-data analysis of different carriers daily departures per gate used SOURCE masFlight \(masflight.com June 1 through August 31, 2012 Gates with minimum 1x daily use 7.7 7.4 7.2 6.2 6.1 5.8 3.8 3.6 ORD LAX SFO EWR DEN IAH IAD CLE United Airlines Hubs Average Daily Deps per Gate Used 7.8 6.4 5.5 5.4 5.3 4.4 4.3 4.0 SEA SAN PDX ANC SFO GEG LAX SJC Alaska Airlines Hubs Average Daily Deps per Gate Used 7.2 6.9 6.8 6.4 5.0 2.7 ORD DFW LAX LGA MIA JFK American Hubs Average Daily Deps per Gate Used 7.2 6.9 6.6 4.9 4.2 CLT DCA PHL PHX BOS US Airways Hubs Average Daily Deps per Gate Used 6.6 5.9 5.5 4.7 MCO BWI ATL MKE AirTran Hubs Average Daily Deps per Gate Used ne pe 


Conclusions for Big Data in Aviation  Big-data transforms operational and commercial problems that were practically unsolvable using discrete data and on-premises hardware  Big data offers new insight into existing data by centralizing data acquisition and consolidation in the cloud and mining data sets efficiently  There is a rich portfolio of information that can feed aviation data analytics  Flight position, schedules, airport/gate, weather and government data sets offer incredible insight into the underlying causes of aviation inefficiency  Excessive size of each set forces analysts to consider cloud based architectures to store, link and mine the underlying information  When structured, validated and linked these data sources become significantly more compelling for applied research than they are individually  Todayís cloud based technologies offer a solution CONCLUSIONS 


Conclusions:  Our Approach  masFlightís data warehouse and analysis methods provide a valuable example for others attempting to solve cloud based analytics of aviation data sets  masFlightís hybrid architecture, consolidating secure data feeds in on-premises server installations and feeding structured data into the cloud for distribution, addresses the unique format, security and scale requirements of the industry  masFlightís method is well suited for airline performance review competitive benchmarking, airport operations and schedule design and has demonstrated value in addressing real-world problems in airline and airport operations as well as government applications CONCLUSIONS 






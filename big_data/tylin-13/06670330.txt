Understanding Query Performance in Accumulo Scott M Sawyer B David OêGwynn An Tran and Tamara Yu MIT Lincoln Laboratory Emails  scott.sawyer dogwynn atran tamara  ll.mit.edu Abstract Open-source BigTable-like distributed databases provide a scalable storage solution for data-intensive applications The simple keyÖvalue storage schema provides fast record ingest and retrieval nearly independent of the quantity of data stored However real applications must support non-trivial queries that require careful key design and value indexing We study an Apache AccumuloÖbased big data system designed for a network situational awareness application The applicationês storage schema and data retrieval requirements are analyzed We then characterize the corresponding Accumulo performance bottlenecks Queries are shown to be communication-bound and server-bound in different situations Inefìciencies in the opensource communication stack and lesystem limit network and I/O performance respectively Additionally in some situations parallel clients can contend for server-side resources Maximizing data retrieval rates for practical queries requires effective key design indexing and client parallelization I I NTRODUCTION An increasing number of applications now operate on datasets too large to store on a single database server These Big Data applications face challenges related to the volume velocity and variety of data A new class of distributed databases offers scalable storage and retrieval for many of these applications One such solution Apache Accumulo is an open-source database based on Googleês BigTable design BigTable is a tabular keyÖvalue store in which each key is a pair of strings corresponding to a row and column identiìer such that records have the format row column  value Records are lexicographically sorted by row key and rows are distributed across multiple database servers The sorted records ensure fast efìcient reads of a row or a small range of rows regardless of the total system size Compared to HBase another open-source BigTable implementation Accumulo provides cell-level access control and features an architecture that leads to higher performance for parallel clients The BigTable design eschews many features of traditional database systems making trade-offs between performance scalability and data consistency A traditional Relational Database Management System RDBMS based on Structured Query Language SQL provides atomic transactions and data consistency an essential requirement for many applications On the other hand BigTable uses a NoSQL model that relaxes these transaction requirements guaranteeing only eventual consistency while tolerating stale or approximate data in  This work is sponsored by the Assistant Secretary of Defense for Research and Engineering under Air Force contract FA8721-05-C-0002 Opinions interpretations conclusions and recommendations are those of the author and are not necessarily endorsed by the United States Government the interim Also unlike RDBMS tables BigTables do not require pre-deìned schema allowing columns to be added to any row at-will for greater exibility However new NoSQL databases lack the mature code base and rich feature set of established RDBMS solutions Where needed query planning and optimization must be implemented by the application developer As a result optimizing data retrieval in a NoSQL system can be challenging Developers must design a row key scheme decide which optimizations to employ and write queries that efìciently scan tables Because distributed systems are complex bottlenecks can be difìcult to predict and identify Many open-source NoSQL databases are implemented in Java and use heavy communication middleware causing inefìciencies that are difìcult to characterize Thus designing a Big Data system that meets challenging data ingest query and scalability requirements represents a very large tradespace In this paper we study a practical Big Data application using a multi-node Accumulo instance The Lincoln Laboratory Cyber Situational Awareness LLCySA system monitors trafìc and events on an enterprise network and uses Big Data analytics to detect cybersecurity threats We present the storage schema analyze the retrieval requirements and experimentally determine the bottlenecks for different query types Although we focus on this particular system results are applicable to a wide range of applications that use BigTable-like databases to manage semi-structured event data Advanced applications must perform ad hoc multi-step queries spanning multiple database servers and clients Efìcient queries must balance server client and network resources Related work has investigated key design schemes and performance issues in BigTable implementations Although distributed keyÖvalue stores have been widely used by web companies for several years studying these systems is a relatively new area of research Kepner et al propose the Dynamic Distributed Dimensional Data Model D4M a general purpose schema suitable for use in Accumulo or other BigTable implementations W asi-ur Rahman et al study performance of HBase and identify the communication stack as the principal bottleneck The primary contrib ution of our work is the analysis of Accumulo performance bottlenecks in the context of an advanced Big Data application This paper is organized as follows Section II discusses the data retrieval and server-side processing capabilities of Accumulo Section III contains a case study of a challenging application using Accumulo Then Section IV describes our performance evaluation methodology and presents the results Finally Section V concludes with speciìc recommendations for optimizing data retrieval performance in Accumulo 978-1-4799-1365-7/13/$31.00 2013 IEEE 


  Fig 1 In a parallel client query M tablet servers send entries to N Accumulo clients where results are further processed before being aggregated at a single query client II D ATA R ETRIEVAL IN A CCUMULO A single keyÖvalue pair in Accumulo is called an entry  Per the BigTable design Accumulo persists entries to a distributed le system generally running on commodity spinning-disk hard drives A contiguous range of sorted rows is called a tablet  and each server in the database instance is a tablet server  Accumulo splits tablets into les and stores them on the Hadoop Distributed File System HDFS which pro vides redundancy and high-speed I/O Tablet servers can perform simple operations on entries enabling easy parallelization of tasks such as regular expression ltering Tablet servers will also utilize available memory for caching entries to accelerate ingest and query At query time Accumulo tablet servers process entries using an iterator framework Iterators can be cascaded together to achieve simple aggregation and ltering The server-side iterator framework enables entries to be processed in parallel at the tablet servers and ltered before sending entries across the network to clients While these iterators mak e i t easy to implement a parallel processing chain for entries the iterator programming model has limitations In particular iterators must operate on a single row or entry be stateless between iterations and not communicate with other iterators Operations that cannot be implemented in the iterator framework must be performed at the client An Accumulo client initiates data retrieval by requesting scans on one or more row ranges Entries are processed by any conìgured iterators and the resulting entries are sent from server to client using Apache Thrift object serialization middleware 10 Clients deserialize one entry at a time using client-side iterators and process the entries according to application requirements Simple client operations may include generating a list of unique values or grouping and counting entries Unlike a RDBMS Accumulo queries often require processing on both the server side and client side because of the limitations of the iterator framework Fortunately tablet servers can handle simultaneous requests from multiple clients enabling clients to be parallelized to accelerate queries A simple way to parallelize an Accumulo client is to partition the total row range across a number of client processes Each Accumulo client processes its entries and then results can be combined or reduced at a single query client Figure 1 shows how data ows in a query with parallel Accumulo clients In a multi-step query an Accumulo client receives entries and uses those results to initiate a new scan For example using an index table to locate rows containing speciìc values Src. Dest. Bytes Port 13-01-01_a8c8 Alice Bob 128 13-01-02_c482 Bob Carol 80 13-01-02_7204 Alice Carol 8080 13-01-03_5d86 Carol Bob 55 21 13-01-01_a8c8 13-01-02_c482 13-01-02_7204 13-01-03_5d86 Alice|Src. 1 1 Bob|Dest. 1 1 Bob|Src. 1 Carol|Dest. 1 1 Carol|Src. 1 Primary Table Index Table Fig 2 In this example network events are stored in a primary table using a datestamp and hash as a unique row identifer The index table enables efìcient look-up by attribute value without the need to scan the entire primary table requires a two-step query Suppose each row in the primary table represents a persisted object and each column and value pair in that row represent an object attribute In the index table each row key stores a unique attribute value from the primary table and each column contains a key pointing to a row in the primary table Figure 2 illustrates a notional example of this indexing technique Given these tables an indexed value look-up requires a rst scan of the index table to retrieve a set of row keys and a second scan to retrieve those rows from the primary table In a RDBMS this type of query optimization is handled automatically III C ASE S TUDY N ETWORK S ITUATIONAL A WARENESS Network Situational Awareness SA is an emerging application area that addresses aspects of the cybersecurity problem with data-intensive analytics The goal of network SA is to provide detailed current information about the state of a network and how it got that way The primary information sources are the logs of various network services Enterprise networks are large and complex as an organization may have thousands of users and devices dozens of servers multiple physical locations and many users connecting remotely Thus network logs exhibit the variety velocity and volume associated with Big Data The data must be efìciently stored and retrieved to support real-time threat detection algorithms as well as forensic analysis The various data sources capture different types of network events For example an event may represent a user logging in to a device or a device requesting a web page through a proxy server Each type of event has a set of attributes associated with it LLCySA currently stores more than 50 event types in an Accumulo database instance A data enrichment process can create additional event types by combining information from multiple captured data sources Recall Accumulo is a tabular keyÖvalue store in which keys contain a row and column identiìer In LLCySA each event type is stored in a separate table A row in an event table corresponds to a particular event occurrence Columns store the 


various attributes of the event occurrence For example web proxy trafìc is stored in a dedicated Accumulo table Each row represents a speciìc web request and contains many columns corresponding to the eventês attributes such as time requested URL source IP address and dozens of other properties LLCySA also applies three optimization techniques at ingest time in order to accelerate future queries First the row identiìer contains a reversed timestamp encoded to lexicographically sort in descending order such that the most recent events sort to the top This feature enables efìcient queries constrained by time range and enables the most recent events to be returned to the user rst Second each event table has a corresponding index table to support efìcient queries based on column values In the index table the row identiìers begin with values concatenated with column names and each column points to a row in the primary event table Without such an index table nding a particular value would require scanning the entire event table This indexing technique would be equivalent to the following SQL CREATE INDEX field_index ON event_table field event_time for each event attribute field  Figure 3 shows the key scheme for the event and index tables Note that Accumulo keys support column families for locality grouping cell versioning and cell access control For simplicity these components of the entry keys are not shown in Figure 3 The nal optimization is sharding  a partitioning technique that distributes rows across database servers LLCySA uses random sharding in the event tables to ensure database scans will always have a high degree of parallelism by avoiding hot spots corresponding to time ranges Sharding in Accumulo is accomplished by pre-pending a shard number to the start of the row key Shard number for an event is determined based on a hash of the eventês attributes resulting in an essentially random assignment uniformly distributed among the allowed shard numbers We instruct Accumulo to distribute these shards across tablet servers by pre-splitting tablets based on shard number ranges As the database grows the exact mapping between shard number and tablet server may change but the uniform distribution will be largely maintained Scanning for a single time range in the sharded event tables requires specifying a key range for each valid shard number This adds complexity to the Accumulo clients but results in a higher degree of scan parallelism Accumulo and the LLCySA storage schema enable highperformance parallel data ingest We have previously demonstrated data ingest rates in excess of four million records per second for our 8-node Accumulo instance with speedup for up to 256 client processes parsing raw data and inserting records These ingest rates on the LLCySA system are roughly an order of magnitude faster than insert rates for traditional relational databases reported on the web and the Accumulo architecture offers signiìcantly more scalability Network SA also requires high-performance data retrieval for a variety of queries Simple queries may extract all or some of the columns for events in some time range Use cases for these simple scan-based queries include graph formation or listing active devices over some time range Other queries  Fig 3 The LLCySA storage schema uses two tables per event type and carefully designed keys to support efìcient queries nd the set of events where a column contains a particular value i.e the equivalent of a SQL SELECT query with a WHERE clause These queries may utilize the index table to identify applicable event rows Another common query creates a histogram for event occurrences over a time range The next section identiìes the bottlenecks of each of these types of query IV P ERFORMANCE R ESULTS To quantify Accumulo data retrieval performance we run four types of queries on the LLCySA web_request table Rows of the table have over 50 columns e.g event_time  source_ip  and domain_name  corresponding to the various event attributes captured in the proxy server log le In each experiment the number of Accumulo clients is varied with the parallel clients partitioned by time range For example if a one-hour time range were partitioned across four clients each client would request a contiguous 15-minute chunk of that hour The sharding scheme ensures data requested by each client will be distributed uniformly among the tablet servers The key performance metrics for the query experiements are query speedup how many times faster the parallel clients complete the query compared to a single client and scan rate the total number of entries per second received by clients Experiments are performed on a 16-node cluster managed by the Grid Engine scheduler Each server node contains dual AMD Opteron 6100 12-core processors 64 GB RAM 12 TB RAID storage and nodes are interconnected with 10 Gbps Ethernet The rst 8 servers comprise a single distributed Accumulo 1.4 database instance The remaining 8 servers are used as grid compute nodes To execute parallel queries clients are dispatched onto compute nodes by the scheduler Experiments are managed by a custom benchmarking framework which monitors CPU and network utilization on each server and performed parameter sweeps Query 1 Unìltered Scan In this query a full scan is performed over a time range of web request data with no server-side ltering Every entry within the time range is returned to a client The total time 


 0 100 200 300 400 500 0 5 10 15 20 25 30 35 Scan Rate \(Thousands Number of Clients Scanning with Parallel Clients a 0 0.5 1 1.5 2 2.5 0 2 4 6 8 10 12 14 CPU Usage \(util*cores Number of Clients Average CPU Utilization Tablet Servers Clients b Fig 4 Query 1 results a Scan rate increases with number of clients b Client CPU usage stalls at 2.0 range is partitioned across a variable number of parallel clients The clients receive entries and count them but perform no other processing The web request records are sharded randomly across all tablet servers so each parallel client will receive entries from all 8 tablet servers Figure 4 a shows that scan rate increases with the number of clients with diminishing returns for higher numbers of clients as scan rate approaches about 500,000 entries per second Figure 4 b shows average CPU usage across clients peaks around 2.0 i.e 2 fully utilized cores out of 24 while server CPU usage continues to increase linearly with the number of clients These trends suggest that Query 1 is bound primarily by the ability of the clients to receive entries from the network and de-serialize the messages Although these queries are communicationbound average network utilization for the 12-client case is 29.8 Mbps more than 300x below the network capacity Therefore scan rate is limited by communication overhead rather than network bandwidth Query 2 Server-Side Filtering Now records are ltered by the tablet servers Acceptance rate refers to the fraction of entries read at the tablet server that are sent to the client A custom server-side iterator is used to vary acceptance rate as an independent variable By comparison Query 1 had an acceptance rate of 1.0 The number of clients n  is also varied Figure 5 a shows that for high acceptance rates right side of x-axis scan rate varies with number of clients which indicates scan rate is bound by the clients ability to receive entries as seen in Query 1 However for low acceptance rates left side of x-axis the total scan rate is independent of the number of clients In Figure 5 b entries handled per second refers to the rate at which entries are read from disk and passed through the server-side iterator chain As acceptance rate decreases going right to left along the x-axis the total number of entries handled peaks at a rate mostly independent of client count Figure 5 c shows the average CPU usage at client and server Together these three plots demonstrate that data retrieval is client bound for high acceptance rates and server bound for low acceptance rates with the crossover point around 1 for this particular dataset and cluster For serverbound scans a sustained disk read rates of 80Ö160 MB/s were observed consistent with expected read performance but below the maximum performance of the underlying RAID Thus we conclude scans with low acceptance rates are I/O bound by HDFS read rates Query 3 Histogram Counting occurrences of unique values or binning values to form a histogram are common queries for database applications While Accumulo provides some server-side capability for aggregating results in the iterator framework many of these count-type operations must be performed at the client For example consider this SQL query that creates a histogram of web requests to a particular domain name over the time range  t 1 t 2   assuming timestamps have been previously binned and stored in the bin eld SELECT bin COUNT bin FROM web_requests WHERE event_time  t1 AND event_time  t2 AND domain_name  example.com GROUP BY bin Figure 6 shows results for the simple histogram query in which time stamps from web requests are binned into time ranges by parallel clients This query differs from the SQL example above because the bins are computed by the client rather than pre-computed and stored as a separate column Our schema enables this particular query to be performed using only the index table since the WHERE clause depends only on the timestamp and one other eld recall the index table keying scheme in Figure 3 Measured runtime does not include the nal reduce step which would combine the counts generated by each client However the runtime of this nal step is insigniìcant compared to total query runtime Query 3 is run for two different time ranges of web request data For the larger time range 8 hours this query achieves increasing speedup for up to 5 clients before contention for the index table eventually lowers the scan rate Query 4 Index Look-up Finally Query 4 looks at parallelization of a query using both tables This is two-step query in which the index table is used to nd a set of rows containing a particular attribute name and value pair The index table also supports conditions on time range with no additional computation After the rst step completes the clients have a set of keys corresponding to 


 0 50 100 150 200 250 0.0001 0.001 0.01 0.1 1 Entries Sent \(Thousands Acceptance Rate Filtered Scan Rate n=1 n=4 n=8 a 0 2 4 6 8 10 12 0.0001 0.001 0.01 0.1 1 Entries Handled \(Millions Acceptance Rate Entries Handled Per Second n=1 n=4 n=8 b 0 0.5 1 1.5 2 2.5 0.0001 0.001 0.01 0.1 1 CPU Usage Acceptance Rate CPU Usage \(n=1 Tablet Servers Client c Fig 5 Query 2 results showing a scan rate b entry handling rate and c client and server CPU usage as a function of lter acceptance rate where n is the number of Accumulo clients 0 0.5 1 1.5 2 2.5 3 0 2 4 6 8 10 12 14 Speedup Number of Clients Histogram Creation Speedup 1 hour 8 hours Fig 6 Query 3 results show speedup for parallel histogram creation queries rows in the event table The clients then issue scans to retrieve the desired columns from those event rows In LLCySA this type of query could be used to retrieve all source IP addresses that accessed a particular domain name This query could be equivalently expressed in SQL as follows SELECT source_ip FROM web_requests WHERE event_time  t1 AND event_time  t2 AND domain_name  example.com  Without an index table this query would require a complete scan of the event table over the desired time range If only a small percentage of trafìc went to example.com the query would have a very low acceptance rate and would consume signiìcant tablet server resources to complete the scan This multi-step Accumulo query approach could also be used to accomplish JOINs across tables Figure 7 shows speedup for Query 4 Interestingly parallelizing this query across multiple clients signiìcantly degrades performance In the case of two and four clients as shown the index table step comprised 1Ö2 of the total query runtime time Thus the bottleneck is clearly on the second step 0 0.2 0.4 0.6 0.8 1 1.2 0 1 2 3 4 5 Speedup Number of Clients Indexed Query Speedup Fig 7 Query 4 results show speedup for parallel queries using index table retrieving the set of relevant rows from the event table During this step each client requests a disjoint set of rows located randomly across the tablet servers Accumulo is unable to efìciently process these random-access requests from multiple clients The contention for the various tablets and underlying les decimates performance V C ONCLUSIONS The results for our four experimental queries help deìne the landscape of data retrieval performance in Accumulo For someone with a background in traditional database systems these results may seem unintuitive Accumulo is a scalable distributed tabular keyÖvalue store built on an open-source Java-based software stack Compared to traditional databases the Accumulo code base is orders of magnitude smaller and less mature Moreover developers must implement their own application-speciìc query planning and optimization Parallel database management systems have demonstrated far better query performance at the scale of 10Ö100 nodes Already for several years the inefìciency of popular open-source dataintensive computing platforms have been noted Ho we v e r  the cost complexity and limited exibility of commercial parallel database solutions have pushed many users to the 


Hadoop paradigm for Big Data applications Additionally Accumulo and other BigTable implementations can achieve far better ingest rates compared to other database architectures which can be a key requirement for applications with ingestheavy workloads In the rst query we observed scan rates limited by the clientês ability to receive and process messages over the network When tablet servers send all entries to a small number of clients the query is bound by communication overhead at the client as a small number of threads fully utilize a subset of the CPU cores and bottleneck the scan rate Communication in Accumulo is handled by Apache Thrift which does not saturate network bandwidth as conìrmed by benchmarks available on the web Re-architecting the communication stack in future versions of Accumulo could alleviate this bottleneck For other queries with low acceptance rates the scan rate is server bound In this case the query is bound by I/O rates and disk read rates are limited by the performance of the distributed lesystem and the storage hardware We also observed queries in which server-side contention for records bottlenecked scan rate performance The histogram operation in which multiple clients create hotspots in the index table shows speedup for only a small number of clients Beyond that performance is likely bound by contention for the index tablets Two-step queries utilizing the index table were not effectively parallelized at all Multiple clients randomly accessing rows from the tablet servers resulted in contention that seriously degraded scan rate performance Queries with random row-access patterns should not be parallelized Given these performance results we can issue some additional recommendations to application developers First row keys should be selected to accelerate the applicationês queries For example in our application case study all queries were constrained by a time range Therefore including a timestamp in the event table row keys improved query performance Next an index table should only be used when the scan acceptance rate is expected to be very low For the LLCySA system the critical lter acceptance rate was around 1 This value will vary for different hardware and software conìgurations Finally an area of future work is improving client-bound scan rates by optimizing the Accumulo client The open-source community has recently created a C implementation of an Accumulo client Using a l o wer le v e l language may help improve communication efìciency In summary we have characterized performance of typical queries in a Big Data application Some queries are bound by the communication stack while others are bound by lesystem I/O In both cases hardware is not fully utilized by the opensource Java software stack which could beneìt from optimization Although Accumulo offers schema-less storage developers must carefully design row keys in order to efìciently support their applicationês query requirements Accumulo and Hadoop offer easy server administration and programmability On the other hand traditional database systems provide advanced query planning and optimization features No single product ts all applications perfectly However Accumulo can be an effective storage solution for data-intensive applications requiring high ingest rates distributed processing and a high degree of scalability R EFERENCES 1 Apache Accumulo  A v ailable http://accumulo.apache.or g  F  Chang J Dean S Ghema w at W  C Hsieh D A W allach M Burrows T Chandra A Fikes and R E Gruber Bigtable A distributed storage system for structured data ACM Transactions on Computer Systems TOCS  vol 26 no 2 p 4 2008 3 Apache HBase  A v ailable http://hbase.apache.or g  S P atil M Polte K Ren W  T antisiriroj L Xiao J L  opez G Gibson A Fuchs and B Rinaldi YCSB benchmarking and performance debugging advanced features in scalable table stores in Proceedings of the 2nd ACM Symposium on Cloud Computing  ACM 2011 p 9  J K epner  W  Arcand W  Ber geron N Bliss R Bond C Byun G Condon K Gregson M Hubbell J Kurz et al  Dynamic distributed dimensional data model D4M database and computation system in Acoustics Speech and Signal Processing ICASSP 2012 IEEE International Conference on  IEEE 2012 pp 5349Ö5352  M W asi-ur Rahman J Huang J Jose X Ouyang H W ang N S Islam H Subramoni C Murthy and D K Panda Understanding the communication characteristics in HBase What are the fundamental bottlenecks in Performance Analysis of Systems and Software ISPASS 2012 IEEE International Symposium on  IEEE 2012 pp 122Ö123 7 Apache Hadoop  A v ailable http://hadoop.apache.or g  A Fuchs  Accumulo e xtensions to Google s Bigtable design  March 2012 lecture Morgan State University 9 Apache Thrift  A v ailable http://thrift.apache.or g  M Slee A Agarw al and M Kwiatk o wski Thrift Scalable crosslanguage services implementation Facebook White Paper  vol 5 2007  C Byun W  Arcand D Bestor  B  Ber geron M Hubbell J K epner  A McCabe P Michaleas J Mullen D OêGwynn et al  Driving big data with big compute in High Performance Extreme Computing HPEC 2012 IEEE Conference on  IEEE 2012 pp 1Ö6  P  Zaitse v  High rate insertion with MySQL and Innodb January 2011 A v ailable http://www.mysqlperformanceblog.com/2011/01/07/high-rateinsertion-with-mysql-and-innodb  A P a vlo E P aulson A Rasin D J Abadi D J DeW itt S Madden and M Stonebraker A comparison of approaches to large-scale data analysis in Proceedings of the 35th SIGMOD international conference on Management of data  ACM 2009 pp 165Ö178  E Anderson and J T ucek Ef cienc y matters ACM SIGOPS Operating Systems Review  vol 44 no 1 pp 40Ö45 2010  Ja v a serialization benchmarking  2013 Online A v ailable https://github.com/eishay/jvm-serializers/wiki  C J Nolet Accumulo A C library for Apache Accumulo   A v ailable https://github com/cjnolet/accumulo-cpp 


Figure 9  A map of the area with 002elds of view and localization points Figure 10  A frame and the image points from Camera 1 for the vessel without AIS By applying the same procedure to one of the previously estimated position for both passenger ships as shown in Figure 13 b and c we obtain a much more stretched estimated covariance Clearly localization accuracy in range is much smaller than in azimuth and it is a function of target distance from the sensors All the results are superimposed as green points in Figure 13 d observing that the crosses keep their shape near the coast and collapse with increasing distance 8 C ONCLUSIONS This paper has proposed an innovative calibration technique for cameras displaced on harbour coastline in which the calibration points are obtained from AIS data from ships sailing in the cameras 002elds of views Our experimental results have showed that the procedure localizes well vessels appearing in the two camera 002elds of view Future work will focus on the deployment of larger arrays of cameras A con\002guration with N cameras implies a longer calibration phase but any increase in view diversity would contribute to an increase in localization precision The procedure must be inherently adaptive also because a generic vessel could be seen only by a subset of the sensor array at any given time Therefore localization of a vessel requires a combination of solutions of different systems 13 for best use of available information Figure 11  A frame and the image points from Camera 2 for the vessel without AIS Figure 12  Pixel cross-variation for Camera 1 a and Camera 2 b to evaluate localization accuracy Figure 13  Error position covariance for vessel without AIS a Abundo b and Nomentana c 7 


Another important issue is the positioning of cameras in the harbour It is well-known that the localization accuracy is strongly dependent on the distance from the vessels range but an intelligent displacement of cameras with their 002elds of view properly intersected to cover almost the same portion of the sea plane could increase the strength of the whole process A CKNOWLEDGMENTS We would like to thank Prof Carlo Regazzoni from Universit 264 a di Genova for very stimulating discussions on data fusion and for letting us use his precious class notes R EFERENCES  R Tsai 223A versatile camera calibration technique for high-accuracy 3d machine vision metrology using offthe-shelf tv cameras and lenses,\224 IEEE Journal of Robotics and Automation vol 3 no 4 pp 323-344  August 1987  Z Zhang 223A 003exible new technique for camera calibration,\224 IEEE Transactions on Pattern Analysis and Machine Intelligence vol 22 no 11 pp 1330-1334  November 2000  Technical characteristics for an automatic identi\002cation system using time-division multiple access in the VHF maritime mobile band  Recommendation ITU-R M.1371-4 April 2011  IALA Guideline No 1082 On an Overview of AIS  International Association of Marine Aids to Navigation and Lighthouse June 2011  International Convention for the Safety of Life at Sea SOLAS  IMO May 2011  R Hartley and A Zisserman Multiple View Geometry in Computer Vision 2ed  Cambridge 2003  E Trucco and A Verri Introductory Techniques for 3-D Computer Vision  Prentice Hall 1998  G Medioni and S B Kang Emerging Topics in Computer Vision  Prentice Hall 2004  223Marine traf\002c,\224 http://www.marinetraf\002c.com/ais 2012 B IOGRAPHY  Francesco A.N Palmieri received his Laurea in Ingegneria Elettronica from Universita degli Studi di Napoli Federico II Italy in 1980 In 1981 he served as a 2nd Lieutenant in the Italian Army in full\002llment of draft duties In 1982 and 1983 he was with the ITT 002rms FACE SUD Selettronica in Salerno currently Alcatel Italy and Bell Telephone Manufacturing Company in Antwerpen Belgium as a designer of digital telephone systems In 1983 he was awarded a Fulbright scholarship to conduct graduate studies at the University of Delaware USA where he received a Master's degree in Applied Sciences and a PhD in Electrical Engineering in 1985 and 1987 respectively He was appointed Assistant professor in Electrical and Systems Engineering at the University of Connecticut Storrs USA in 1987 where he was awarded tenure and promotion to Associate Professor in 1993 In the same year he was awarded the position of Professore Associato at the Dipartimento di Ingegneria Elettronica e delle Telecomunicazioni at Universit 264 a degli Studi di Napoli Federico II Italy where he has been until October 2000 when he became Professore Ordinario di Telecomunicazioni and moved to the Dipartimento di Ingegneria dellInformazione  Seconda Universit 264 a di Napoli Aversa Italy His research interests are in the areas of signal processing data fusion communications information theory and neural networks Francesco Castaldo received his Laurea in 2009 and his Laurea Magistrale in 2012 both in Ingegneria Informatica from Seconda Universita degli Studi di Napoli SUN He has cooperated during his thesis work with the PRISMA lab at Universit 264 a degli Studi di Napoli Federico II with prof B Siciliano and prof V Lippiello He is currently a postgraduate fellow with the Dipartimento di Ingegneria Industriale e dell'Informazione at SUN His research interests are in image processing computer vision and data fusion applied to robotics and home automation Guglielmo Marino received his Laurea in Ingegneria Elettronica at Seconda Univerit 264 a degli Studi di Napoli SUN in December 2012 His 002nal thesis project has been on data fusion of digital images with AIS data in harbor management 8 


boards of several journals including IEEE Transactions on Service Computing and the Journal of Performance Evaluation   Zhen has given keynotes and distinguished lectures in various conferences and universities. He was an adjunct professor at University of Science and Technology of China and Beijing University of Post and Telecommunications While he was in France Zhen was  also an adjunct professor of the University of Paris VI \(University of Pierre & Marie Curie\and the University of Nice  Sophia Antipolis, France   His areas of expertise include mobile computing, mobile services, cloud computing, stream processing re al time analytics performance modeling stochastic optimization service oriented architecture and semantic Web      
lxxxi 


en-US Keynote VI I I  en-US GreenCom iThings CPSCom 2013   Towards Carrier Cloud   Dr. Tarik Taleb  Senior Researcher and 3GPP Standards Expert  NEC Europe Ltd, Heidelberg, Germany  Email tarik.taleb@nw.neclab.eu    Abstract   Mobile operators are in need of means to cope with the ever increasing mobile data traffic, introducing minimal additional capital expenditures on existing infrastructures, principally due to the modest Average Revenues per User ARPU Network virtualizat ion and cloud computing techniques along with the principles of the latter in terms of service elasticity on demand and pay per use could be important enablers for various mobile network enhancements and cost reduction This talk discusses the recent tr ends the mobile telecommunications market is experiencing showcasing some of the emerging consumer products and services that are facilitating such trends. The talk also discusses the challenges these trends are representing to mobile network operators. T he talk also demonstrates the possibility of extending cloud computing beyond data centers towards the mobile end user providing end to end mobile connectivity as a cloud service. The talk introduces a set of technologies and methods for the on demand pro vision of a decentralized and elastic mobile network as a cloud service over a distributed network of cloud computing data centers; federated cloud. The concept of Follow Me Cloud whereby not only data but also mobile services are intelligently following t heir respective users is also introduced. The novel business opportunities behind the envisioned carrier cloud architecture and service are also discussed, considering various multi stakeholder scenarios   Bio   Tarik Taleb is currently working as Senior Researcher and 3GPP Standards Expert at NEC Europe Ltd Heidelberg, Germany. Prior to his current position and till Mar. 2009, he worked as assistant professor at the Graduate School of Information Sciences, Tohoku University, Japan, in a lab fully funded by KDDI, the second largest network operator in Japan From Oct 2005 till Mar 2006 he was working as research fellow with the Intelligent Cosmos Research Institute Se ndai Japan He received his B E   degree in Information Engineering with distinction M.Sc and Ph.D degrees in Information Sciences from GSIS Tohoku Univ., in 2001, 2003, and 2005, respectively   Dr Taleb  s research interests lie in the field of architectural enhancements to mobile core networks particularly 3GPP  s mobile cloud net working mobile multimedia streaming congestion control protocols handoff and mobility management inter vehicular communications and social media networking Dr Taleb has been also directly engaged in the development and standardization of the Evolved  Packet System as a member of 3GPP  s System Architecture working group. Dr. Taleb is a board member of the  IEEE Communications Society Standardization Program Development Board  As an attempt to bridge the gap between academia and industry Dr Taleb has f ounded and has been the     Dr Taleb  is/was on the editorial board of the IEEE Wireless Communications Magazine IEEE Transactions on Vehicular Technology, IEEE Communications Surveys & Tutorials, and a number of Wiley journals. He is serving as vice chair of the Wireless Communications Tech nical Committee, the largest in IEEE ComSoC He also served as Secretary and then as Vice Chair of the Satellite and Space Communications Technical Committee of IEEE ComSoc 2006  2010 He has been on the technical   
lxxxii 


program committee  of different IEEE c onferences including Globecom, ICC and WCNC and chaired some of their symposia   Dr Taleb is the recipient of the 2009 IEEE ComSoc Asia Pacific Best Young Researcher award Jun 2009 the 2008 TELECOM System Technology Award from the Telecommunicati ons Advancement Foundation Mar 2008 the 2007 Funai Foundation Science Promotion Award Apr 2007 the 2006 IEEE Computer Society Japan Chapter Young Author Award Dec 2006 the NiwaYasujirou Memorial Award Feb 2005 and the Young Researcher's Enc ouragement Award from the Japan chapter of the IEEE Vehicular Technology Society \(VTS\\(Oct. 2003\ Some of Dr. Taleb  s research work has been also awarded best paper awards at prestigious conferences. Dr. Taleb is a senior IEEE member      
lxxxiii 


en-US Keynote I X  en-US GreenCom iThings CPSCom 2013   How Densely Should the Data Base Stations  B e Deployed in Hyper Cellular Networks   Professor Zhisheng Niu  Tsinghua National Lab for Information Science and Technology  Tsinghua University, Beijing 100084, China  E mail niuzhs@tsinghua.edu.cn    Abstract   One of the key approaches to make the mobile communication networks more GREEN Globally Resource optimized and Energy Efficient Networks\is to have the cellular architecture and radio resource allocation more adaptive to the environment and traffic varia tions including making some lightly loaded base stations \(BSs\go to sleep. This is the concept of so called TANGO \(Traffic Aware Network planning and Green Operation and CHORUS Collaborative and Harmonized Open Radio Ubiquitous Systems published by th e author earlier. To realize this, a new cellular framework, named hyper cellular networks HCN has been proposed in which the coverage of control signals is decoupled from the coverage of data signals so that the data coverage can be more elastic in ac cordance with the dynamics of traffic characteristics and QoS requirements. Specifically, the data base stations \(DBSs\in HCN can be densely deployed during peak traffic time in order to satisfy the capacity requirement, while a portion of DBSs can be swi tched off or go to sleep mode if the traffic load is lower than a threshold in order to save energy. A fundamental question then arises how densely should the DBSs be deployed in order to balance the QoS requirements and the energy consumption in hyper ce llular networks     In this talk, we characterize the optimal DBS density for both homogeneous and heterogeneous hyper cellular networks to minimize network cost with stochastic geometry theory For homogeneous cases both upper and lower bounds of the optimal DBS density are derived For heterogeneous cases our analysis reveals the best type of DBSs to be deployed for capacity extension or to be switched off for energy saving. Specifically, if the ratio between the micro DBS cost and the macro DBS cost  is lower than a threshold which is a function of path loss and their transmit power then the optimal strategy is to deploy micro DBSs for capacity extension or to switch off macro DBSs \(if possible\for energy saving with higher priority Otherwise the  optimal strategy is the opposite Based on the parameters from EARTH numerical results show that in the dense urban scenario compared to the traditional macro only homogeneous cellular network with no DBS sleeping deploying micro DBSs can reduce about 40 of the total energy cost, and further reduce about 20% with DBS sleeping capability   Bio   Zhisheng Niu graduated from Northern Jiaotong University currently Beijing Jiaotong University Beijing China in 1985 and got his M.E and D.E degrees fr om Toyohashi University of Technology Toyohashi, Japan, in 1989 and 1992, respectively. After spending two years at Fujitsu Laboratories Ltd Kawasaki, Japan, he joined with Tsinghua University, Beijing, China, in 1994, where he is now a professor at the  Department of Electronic Engineering and the deputy dean of the School of Information Science and Technology. His major research interests include queueing theory, traffic engineering, mobile Internet radio resource management of wireless networks, and g reen communication and networks   Dr Niu has been an active volunteer for various academic societies including council member of Chinese Institute of Electronics 2006 10 vice chair of the Information and Communication Network Committee of Chinese In stitute of Communications 2008 12 Councilor of IEICE Japan 2009 11 and membership development coordinator of IEEE Region 10 \(2009 10\ In particular, in IEEE Communication 
lxxxiv 


Society, he has been serving as an editor of IEEE Wireless Communication Magaz ine \(2009 12\ director of Asia Pacific Region \(2008 09\ director for Conference Publications \(2010 11\ chair of Beijing Chapter 2001 08 and members of Award Committee 2011 13 Emerging Technologies Committee 2010 12 On line Content Committee 20 10 12 and Strategy Planning Committee He has also been serving as general co   co    chairs o f    Prof. Niu is a co recipient of the Best Paper Awards from the 13th and 15th Asia Pacific Conference on Communication APCC in 2007 and 2009 respectively and received Outstanding Young Researcher Award from Natural Science Foundati on of China in 2009 He is now the Chief Scientist of the National  Energy and Resource Optimized Hyper Cellular Mobile Communication System 2012 2016 which is the first national project green communications in China He is the fellow of IEEE and IEICE and a distinguished lecturer of IEEE Communication Society \(2012 2013  
lxxxv 



Vehicle Tracking with Non-overlapping Views for Multi-camera Surveillance System 
E-mail 
 Wenbin Jiang, Chang Xiao, Hai Jin, Shuo Zhu, Zhiwei Lu Services Computing Technology and System Lab Cluster and Grid Computing Lab School of Computer Science and Technology Huazhong University of Science and Technology, Wuhan, 430074, China wenbinjiang@hust.edu.cn  
Abstract 
With the rapid development of intelligent video surveillance system for transportation, traditional singlecamera-based video analysis has become insufficient. Many researches have focused on the non-overlapping multi-camera target tracking. However, the tracking precision and the 
 
computing overhead are still big obstacles. This paper proposes a novel vehicle tracking approach for non-overlapping multicamera targets with data fusion by using minimum cost and maximum flow method. Structured information of moving targets is extracted and associated with other information such as motion time, the topology of camera network to solve targeted vehicle tracks. Besides, to improve the performance of the process, a parallelization algorithm for camera network topology partitioning is presented, which makes it possible for each sub-graph to track target independently in parallel. The experiment results show that the presented approach is able to perform target vehicle tracking analysis with high efficiency 
and accuracy 
Keywords-vehicle tracking; non-overlapping; camera view data fusion; minimum cost and maximum flow 
 
I I NTRODUCTION  Vehicle has become one of essential part of our daily lives Howover, it also has become an impotant cause resulting in transportation accidents, criminality, etc. So traffic video surveillance system has become a crucial measure to monitor the transportation situation while protect our lives and properties. It is not only able to make real-time monitoring recording for monitored situations, but also able to perform analysis and give warnings for some special or dangerous events, such as law violations or crimes. This would be 
helpful for security staffs to deal with emergency and ensure the public safety The foundation and core technologies of intelligent video surveillance system lie in the detection and tracking of vehicle objectives, because only after the images of targets are extracted we can do further analysis on their characteristics and behaviors. The means of detection and tracking of targets can be divided into two categories: the single-camera way and the multi-camera way. Benefiting from long-term studying, the research on single-camera detection and tracking of targets is relatively mature. The common detection approaches are frame subtraction and background subtraction. The common tracking approaches 
are the ones based on model, characteristic and mean shift However, with the numbers of cameras inside many intelligent video monitoring systems increasing rapidly, the way of single-camera-based analysis become insufficient to meet the practical requirements. Therefore, the multi-camerabased analysis technologies have attracted more and more attentions of researchers Nowadays, the traditional deployment model of surveillance systems for urban roads traffic usually is monitoring and recording in front-end by cameras compressing and transmitting videos in middle-end, and storing, processing and analyzing the content of videos in surveillance center in back-end. This kind of model has two 
disadvantages. First, it is expensive and ineffective to analyze huge amounts of recorded videos manually, especially in multi-camera conjoint analysis; second, huge data of video files causes great pressure on transmission networks and storage devices In order to achieve the goal of tracking vehicle targets which pass through multiple cameras, we need to associate the targets captured by different cameras. This kind of association, which leverages the vehicle-related characteristic information and spatial-temporal constraint information, turns out to be a data fusion problem. With the structured information extracted from traffic surveillance videos combining with the topology structure of camera networks 
we build a data fusion model based on minimum cost and maximum flow, and implement a non-overlapping multicamera target tracking strategy. In order to crack the hard nut of the overhead of processing and storage, this paper puts forward a network division algorithm based on camera network topology. It can improve the stability and the performance of the tracking system with massive data, which implements distributed target tracking, breaks the computational bottleneck of centralized processing and significantly reduces the cost in terms of computation time and network transmission costs The rest of the paper is structured as follows. Section II 
gives the background knowledge related to this work including an overview of related work about identification and re-identification of targets across multiple cameras and the major methods used in vehicle tracking in multi-camera surveillance systems. Section III presents the features and key technologies used in the approach presented, including the methods of extracting the target associated features, the topology estimation way of camera networks method and the target association algorithm. In section IV, the measurements of the non-overlapping camera in the multi-camera surveillance system both in functionality and performance are 
2013 IEEE International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing 978-0-7695-5088-6/13 $26.00 © 2013 IEEE DOI 10.1109/HPCC.and.EUC.2013.172 1213 
2013 IEEE International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing 978-0-7695-5088-6/13 $31.00 © 2013 IEEE DOI 10.1109/HPCC.and.EUC.2013.172 1213 


maximum a posteriori probability red, green, blue hue, saturation, value brightness transfer function principal component analysis mean BTF cumulative BTF joint probability data association filter linear programming 
 
discussed, while a traditional Bayesian fusion method is used as a contrast. Finally, section V draws conclusions and gives some directions for future work II R ELATED W ORK  Tracking targets in a single camera has been widely studied. Targets are often modeled using various features such as color, motion, size, and time.  However, with the rapid development of intelligent video surveillance system for transportation, traditional single-camera-based video analysis has become insufficient. Many researches have focused on the non-overlapping multi-camera target tracking approaches This kind of tracking is often modeled as a global data association issue which is formulated as a MAP\ problem. Berclaz et al. [1 tracked multiple targets using dynamic programming to solve a global data association problem with overlapping multiple cameras. Wu and Nevatia [2 det ect e d pe o p le  u s in g  a n  Edgelet-based Adaboost classifier that models target by its histogram, size and time. The trajectory of a target is also estimated by applying a MAP formulation Object tracking with partially overlapping camera views has also been researched extensively in the last decade [3, 4   However, in wide-area tracking and wide-area surveillance applications, it is always unrealistic to assume that all the cameras in the system have overlapping fields of views Tracking across disjoint camera views is a more challenging problem than that with overlapping cameras due to lack of spatial continuity, which resulting in blind regions [5  Identification and re-identification of targets across multiple cameras are challenging because the same target may have significant variations in shape and appearance across cameras. Targets may enter and exit a scene randomly with highly non-linear motions. The process of identification and re-identification is normally performed by finding the similarities of the features of objects, and/or the probabilities of object transitions Appearance is an obvious feature to associate objects in different camera views. However, due to different camera angles, illumination variations and different camera parameters, some appearances cannot offer help clearly Thus, people prefer to choose features which are influenced by environment less. Color is one of the most commonly used appearance features. Color information is often represented by color histograms in the RGB r HSV  color spaces. HSV is more robust to illumination changes due to its inherent properties. Javed et al pr opo sed a  su b s pa ce b ase d  BTF\y using probabilistic  PCA\o calculate the subspace of BTFs for a set of known correspondences. This method relies on large amount of training data with a good range of clothing colors to give an accurate MBTF\Prosser et al po s e d t o use CBTF\ instead of MBTF, which made use of available color information from a very sparse training set. A comparison of these two different BTFs [8 demonstrated similar behaviors of the two methods when the simple association problem needed to be solved. Their experiments also showed that appearance matching relying on color exclusively is not reliable when the scenario became more complicated Fusing more visual features could help improve the effectiveness of the appearance matching and reduce the influence of environment changes. Wang et al m p l o y ed  multiple features such as color histogram, height, moving detection, travel time and speed to match objects across nonoverlapping views Spatial-temporal information is another important evidence to be considered for object re-identification. One way of using spatial-temporal constraints is predicting the objectsê positions when they are in the blind region. With the assumption of linear motion model, a Kalman filter or a similar mechanism was employed [10, 11  Th e p o s i t i on s  of  the objects could also be inferred based on a common ground assumption, which allowed the warping between the cameras views by using a homography matrix [1 n   13  an  expanded triangulation with motion constrains, which assumed linear motion of the objects, was employed to infer the positions of the objects Another category of research also used spatial-temporal information, but focused on the recovery of camera network topology, instead of object tracking. To make use of the spatial features, some methods have been introduced to predict the motions of objects by assuming a common ground plane and small gap between two cameras [10, 14  Kan g e t  al. [14  u s e d a  sp ati alte m poral  JPDAF\ to formulate a joint probability model for encoding the appearances and motions of objects Chilgunde et al. [10 d a K a lm a n filte r t o  ob t a in th e  targetês track in the blind region between cameras. For multicamera correspondence matching, the Gaussian distributions are applied for computing the tracking parameters across cameras for the target motion and position in the ground plane view. However, this approach is not competent to some complex situations such as obvious crossroads, big turns Rahimi et al. [1 t a i n ed  t h e ca l i br a t i o n pa ra m e t e r s o f  t h e cameras and the trajectories of targets by using MAP estimation. Monari et al. [4 i n ten de d t o t r a ck  o b j e cts in  b o t h  overlapping and non-overlapping camera networks. They applied 3D positions combined with color space features to perform object association. The 3D positions in the blind region are predicted by a Particle filter, which also was used in [1   For data fusion algorithm of this kind of global data association issue, Huang and Russell a d op t e d m u ltip l e  features for vehicle matching in a Bayesian formulation. An association matrix is employed for finding the best assignments for multiple objects. Zhang et al. [18 f o u n d  a n  optimal MAP data association in a single camera by finding the max-flow of a network. There are also other fusion algorithms. Song and Roy-Chowdhury [1 p r opo sed a n optimized method to combine short-term feature correspondences and long-term feature dependencies across multiple cameras. The LP olution presented in [20 in t r o d u ce d  a te rm th at en cou rag e d r elat i v e 
1214 
1214 


 
ia jb t ia jb l ia jb a ia jb SO O Tt t Ll l Aa a 
Extraction of Target Associated Features Speeded Up Robust Features Histogram of Oriented Gradients Local Binary Pattern a b C i C j S O i,a O j,b T\(t i,a t j,b  L\(l i,a  l j,b  A\(a i,a a j,b  002 002 
    
positions of objects to remain constant, however it assumed that the number of objects was fixed III D ESIGN AND A LGORITHM  Vehicle tracking in multi-camera surveillance systems has attracted a lot of attention in recent years because of its widespread applications in many scenarios such as public transportation, campus security, and production process. In order to achieve full network tracking, diversified methods have been proposed in the last decade. One of the most common ones is to associate the same target appeared in different cameras by extracting the target appearance characteristics and spatial-temporal characteristics, while combining with the topology of multiple cameras The key to associate the same targets in different cameras is to find the correspondence among various targets Considering the scale of surveillance and the cost of installment, most video surveillance systems are nonoverlapping which makes the observed targets discrete in space and time. Blind areas make it complex and difficult to track the targets. Now the usual way of doing this is to extract the external features and spatial-temporal features of the targets, and combine with the topology relationship of cameras, then build a spatial-temporal constraint with the target shifting among cameras, finally utilize the proper association algorithm to match the targets captured by different cameras. All of these are done for target tracking within the entire network. The solution for this problem includes three parts: the extraction of target associated features, the topology estimation of camera networks, and target association algorithm For large-scale surveillance systems, the number of vehicles that appear in the cameras would be very large even in a short time, which not only leads to a big rise in computational time, but also brings great pressure to the system center. In order to achieve load balance, a sub-graph network division algorithm is designed and implemented. The whole camera network will be divided into multiple subgraph units, the target correlation algorithm can be executed independently and parallel within each sub-graph units A The extraction of target associated features is the foundation of the realization of targets association. The approach presented partitions target associated features into two types: descriptive semantic information and characteristic quantity-based numerical data information Semantic information refers to the detailed descriptive understandable information including the type, color and size of a target, when and where the target appears, the speed of movement, and its direction and track. The target type means the brand and model of the vehicle. Through exacting and modeling the header information of the target vehicle, the approach presented uses SURF algorithm to compare the information with the standard vehicle models in database to obtain the type of the target vehicle. In addition, the motion direction and specific track of the target are gained by continuously tracking and recording the motion trail of the target vehicle within the view of a single camera. The target speed is calculated through the offset of the movement of the target Characteristic quantity-based numerical data information refers to the characteristic value information which can be used to identify the level of similarity in the field of image recognition. The characteristic value information applied here includes vehicle type  HOG\ operators, and LBP\rators All the associated features are used to judge the relevance of two targets, and the semantic information are used for target filtering and choosing In order to carry out the associated multi-feature of the target with reasonable fusion, a similarity measure function is presented here. Similarity measure function combines numerical features and set weight for each feature. It is used to describe the level of similarity between the targets and determine the correlation between the targets. Assume target and target are two vehicles observed in camera and  respectively, the similarity measure function    defined in \(1 1 The above refers to the contrast ratio of the features including time denoted by location denoted by appearance model denoted by We set a weight for each feature to control the reliability. The value of depends on the importance of the feature. For time and location, it is relative easy to construct the similarity of the specific objects according to object appearing time and the topology of the monitoring network.  So, we focus on the appearance model, which consists of vehicle type, HOG and LBP a Vehicle type The vehicle type means the brand and model of the target Through exacting and modeling the header information of the target vehicle, the system uses SURF algorithm to compare the information with the standard vehicle models in database to obtain the information of the brand and model of the target vehicle. It makes the head area of the vehicle compare with other samples in the feature library and record the matching result b HOG HOG feature descriptor was first proposed by N. Nalal and B. Tr in 2005 i t s cor e  ide a is t o  r e pr e s e n t th e  appearance and outline of the target by gradient or an edge direction of density distribution, without setting gradients and marginal positions. In the approach presented in this paper two targetsê screenshots are used to do the comparison. First each image is divided into some small connecting areas These areas are often referred as cells. Then generate the gradient or edge direction histogram of each pixel within each cell. Finally combine these h istograms by the statistical 
     
002\002\002 003\003 
1215 
1215 


004   004   
A H B H S H S L 
       
cos 2  cos 3 B The topology relationship of camera networks refers to the temporal and spatial patterns of the target movement among cameras. With topology relationship, it is possible to build a spatial-temporal constraint of the target shifting among cameras. According to the spatial-temporal constraint we can not only properly reduce computing scale, but also further improve the accuracy of target association. The system builds the spatial topology relationship according to installation sites of the cameras and road connection, with the temporal topology relationship obtained by statistical learning. Within the fixed view of a camera, the appearing area and disappearing area of multiple targets can be learned based on the position information of the target appearing and leaving detected by the camera As Figure 1 shows, for any pair of nodes     002  002 there is a variable 0, 1}, where 0 indicates that objects between the two nodes cannot pass directly, without going through other nodes; 1 indicates that objects can directly pass the two nodes without going through other nodes. Since we are not concerned on the connections inside the camera, the transfer inside the camera is marked by dotted line. In real scenarios, traffic lights and traffic conditions may have some influence on the time it takes for the target to pass the distance between two cameras. Gaussian model is adopted here to indicate the temporal relationship between two cameras. The relationship is marked by solid edge in the figure. Its parameters  The target association algorithm in our approach is a minimum cost and maximum flow algorithm based on the relationship of the camera network topology. Figure 2 shows an example of the cost-flow network built in this paper. The following steps are taken to construct a cost-flow network a Select observed targets in each camera, based on the semantic information within a certain period of time mark each of these selected targets as  b For each camera has recorded its track information, thus we simply add the start point and end point in the track to graph as independent nodes. At the same time, we also need to add a directed edge   hich has infinite capacity and zero cost to graph  c For any pair and if the similar function between them is   0, then add a directed edge   which has the capacity of    and the cost of   graph Whatês more, if falls into disappearing area of the camera   falls into the appearing area of the camera and 1, make   2, otherwise make    d Append virtual nodes source and sink for the graph For each region node in the camera subnet, if there are other directed edges from other camera subnet point to for each node that falls into add a directed edge   hich has the capacity of 1 and the cost of 0 to graph On the contrary, if has a directed edge point to other camera subnet, for each node that falls into add a directed edge    that has the capacity of 1 and the cost of 0 to graph  After building cost-flow network, the minimum cost flows of the whole network can be solved by minimum cost and 
H HH H HH A B s A B L LL L LL A B s A B 
Topology Estimation of Camera Networks p i p j p i 001\031 C m p j 001\031 C n i j C m C n L i,j 003 i,j 004 i,j Target Association Algorithm O i,a O i,a C i u i,a v i,a G e u i,a v i,a G O i,a O j,b S O i,a O j,b e v i,a u j,b Cap O i,a O j,b S O i,a O j,b G v i,a C i u j,b C j L m,n Cap O i,a O j,b Cap O i,a O j,b s t G p a p a u i,a p a e s u i,a G p a v i,a p a e v i,a t G 
methods to form the targetês HOG feature descriptor. In order to improve the accuracy of the feature, we use overlapping local contrast normalization technology. Put the local histogram of each cell in a broader interval called block, and calculate the density in the interval. According to the density of the block, the system normalizes other cells within the block. Normalization process makes HOG operator a better robustness with light changes and shadows c LBP A LBP feature descriptor is often used to describe the local texture features of the image. Since the LBP value is corresponding to pixel window, it means that LBP value is related with the location of the picture. This makes the selection of a suitable comparison window position a critical impact on comparative results. In order to reduce the position dependence of the LBP operator information, the image is divided into several sub-regions. The LBP feature value of each pixel is extracted within sub-region. So the LBP feature value of this sub-region could be described by the statistic histogram of these pointsê LBP feature. The multiple subregional statistic histograms compose the LBP statistic histogram of the whole image We use the cosine between feature vectors to represent the similarity. HOG and LBP are treated as two separate features for object matching. If two HOG descriptors are denoted by and the cosine similarity score of HOG descriptors is calculated by \(2\ The similarity score of the LBP descriptors is calculated by \(3 
 
 
2 e obtained by training and learning                            Figure 1. Topology relationship of camera network C 
1216 
1216 


    
maximum flow solution algorithm, which is actually to obtain the flow with maximum cost by the above algorithm The obtained result is also a series of path of the maximum similarity values. The system controls the display of the predicted numbers of tracks according to the requirements of users, while gives more priority to the track with higher prediction probability for display. Besides, the system has a modification module, which is capable of selfrevising according to the correction command submitted by users, including modifying the structure of cost-network  recalculating and rebuilding new prediction track Modification module can fix some errors produced by the procedure of videos analysis and process, thus improve the robustness of the system  Figure 2. The example of a cost-flow network D A large surveillance system sometimes contains more than thousands of cameras which forms a huge camera network. If we want to track targets within the whole network, the amount of calculation is extremely enormous To overcome this obstacle, in our approach, the camera network is divided into several independent sub-network units according to the characteristics of its topology relationship The target association algorithm then can be carried on independently at the same time The sub-graph partition should not destroy the structure of the camera network, so that the trajectory calculated in each sub-graph unit can be easily linked to form the total vehicle trajectory. In our system, the sub-graph network division algorithm should follow several principles. For each subgraph      1, 2 satisfies a Completeness Principles: For each target, if its appeared node then the last disappeared node  satisfied In reverse, if the targetês disappeared node  001\031  and the target appears again, then the next appeared node satisfied  001\031  b Minimization Principles: The amount of nodes in each unit should be as small as possible on condition of the completeness principle. It means that the camera network should be divided elaborately to get sub-graph units as many as possible The completeness principle makes sure the complete independence of each unit, so that all nodes involved are within the sub-graph unit when calculating the associate relationship of the targets, and do not need exchange information with other units. Only each sub-graph remains independent, can the trajectory connect into the whole track The minimization principle makes the structure of each subgraph unit as small as possible, cannot be re-split, which guarantees the minimum calculation overhead of the associated algorithm The method of devising the camera network into subgraph units is as follow: in a field of camera view, if an appeared node only connected with a disappeared node  then remove the dotted connection between them and put  and into two different sub-graph units. Eventually the entire camera network turns into an unconnected graph. Take in Figure 1 as an example, the appeared node is only connected with the disappeared node then remove the edge   between them, makes and assigned into two different sub-graph unit. The method of dividing the whole network into sub-networks provides the distributed intelligent video surveillance system with strong support. It is possible to build some local process units to process video information, and the local process units only transmit key information to the central process unit for deeper analysis Our system applies the framework of MapReduce based on Hadoop to realize the parallel computing of all sub-graphs First, different tasks from different sub-graphs are mapped to different MapReduce nodes for track analysis independently Then, all information will be returned to central server to be reduced by the presented approach mentioned in previous sub-sections IV E XPERIENCES AND P ERFORMANCE  To verify the effectiveness of the approach presented in this paper, a batch of vehicle monitoring videos from 23 cameras in the real campus security monitoring system of HUST\are applied and analyzed. All videos are in the resolution of 1920◊1080 with 25 frames per second. 8 non-overlapping cameras with 5-minute durations are selected for evaluation These dataset are challenging because: i\ the roads monitored are two-way with lots of intersections, that makes the tracking environment more complicated; ii\ due to the shadows of many trees along the roads in the campus, the colors and illuminations of the vehicle objects tracked change obviously across cameras; iii\ the traffic are relative heavy. For example in the selected cameras, more than 500 vehicles passed through the cameras; iv\ high resolution video takes much time to process. The map view is shown in Figure 3 For evaluation of tracking, the tracking metric in [1  is used. Evaluation results across multiple cameras are shown in Table I. In the table indicate the number of real vehicles captured by the specified cameras is the successful tracking rate within a camera. It is hard to get all tracks of all objects precisely. If the degree of accuracy of a target tracked is more than 90% compared to the 
G Camera Network Sub-graph Partitioning A A p i q j i j m q j 001\031 A p i p i 001\031 A p j A q k q k A q i p j q i p j C 3 q 1 p 4 e q 1 p 4 q 1 p 4 Huazhong University of Science and Technology real targets Track recall 
1217 
1217 


Real targets Track recall Mostly tracked Partially tracked Mostly lost 
corresponding real track, it is considered as  see Table I\. Since the time span of the group video data is limited, some vehicle tracks are broken off, which are marked as Since some conditions of camera views are not perfect enough, when a car disappears in the view which goes beyond the detection area, it is marked as  also includes those cars that disappear in blind regions  Figure 3. Cameras for evaluation on the map TABLE  I  E VALUATION OF MULTI CAMERA TRACKING  For the location measure, enter/exit area is defined for each camera and their connections across cameras are used as spatial features. For the time measure, the mean and variance between two corresponding enter/exit areas is learned during the training stage. A single Gaussian distribution is used to model the object travel time. In this practical traffic surveillance system, since all cameras are deployed in a campus, the distance between two neighbor cameras is not far Most of them are 50-200 meters, and the speeds of most vehicles in the campus are between 10-40km/h. Table II shows the parameters for enter/exit areas pairs during the training stage TABLE  II  L EARNED PARAMETERS OF TIME MEASUREMENT FOR  ASSOCIATED ENTER  EXIT AREA PAIRS  Since the classification method we used concerns primarily with the front area of the vehicle, the identifying accuracy is poor when a target shows only the back part in the camera views. However, it is a good opportunity to test how robustly the system can run in such a serious situation Some vehicle objects of correct tracking across 6 major cameras are shown in Figure 4, while some of incorrect tracking are shown in Figure 5  Eight serials of monitoring videos with duration of 5 minutes are processed by the server with 2.26 GHz 2xIntel Xeon E5520 CPU. The amount of objects we detected is 233 We use two ways to search for the tracks. One is the traditional Bayesian method, the other is our MCMF\ethod 
Camera number Average Pair of Enter/Exit Area Arrival time \(second Mean Variation  Camera 1 Camera 2 Camera 3 Camera 4 Camera 5 Camera 6 Camera 1 Camera 2 Camera 2 Camera 3 Camera 2 Camera 4  
1 15 100% 15 0 0 2 46 87.0% 37 3 6 3 43 90.7% 36 3 4 4 39 97.4% 36 2 1 5 34 100% 30 4 0 6 38 92.1% 31 4 3 7 9 77.8% 5 2 2 8 9 77.8% 5 2 2 30.38 90.35 24.38 2.5 2.25 A Camera 1-2 8.5 7.5 Camera 2-3 6 9 Camera 3-4 11.5 3.5 Camera 4-5 7 7 Camera 5-6 3 3 Camera 6-7 14 1 Camera 7-8 5 2 Additionally, since there are two intersections in the blind regions and there is a traffic light in one of the eight camera views, the variation of the link between them is set slightly looser Location, time, SURF, HOG, and LBP are used for appearance measure. Here, the weights for the location, time SURF, HOG and LBP are set to: 1, 1, 0.85, 0.22, and 0.55  respectively, based on experiments  B Figure 4. Objects of correct tracking across six major cameras Figure 5. Objects of incorrect tracking \(marked by red crosses  C 
   
mostly tracked partially tracked mostly lost Mostly lost Location, Time and Appearance Measures Overall Performance of Multi-camera Tracking Computational Time minimum cost and maximum flow 
1218 
1218 


3 1534 1013 34 6 4112 2763 33 10 5873 4279 27 12 5627 4628 18 15 18811 12461 34 17 13195 10567 20 8192 5951.83 27.5 TABLE  IV  C OMPARATION ON ACCURACY   3 100% 100% 1:1 6 100% 100% 1:1 10 100% 100% 1:1 12 50% 57.14% 1:1.14 15 58.33% 83.33% 1:1.42 17 53.33% 70% 1:1.31 76.94% 85.08% 1:1.11 V J. Berclaz, F. Fleuret, and P. Fua, çRobust people tracking with global trajectory optimizationé, in Proceedings of IEEE Conference on Computer Vision and Pattern Recogn ition \(CVPRê06\, 2006, pp.744750 2 B. Wu and R. Nevatia, çDetection and tracking of multiple, partially occluded humans by Bayesian combination of Edgelet based part detectorsé, in International Journal of Computer Vision, Vol.75, No.2 November 2007, pp.247-266 3 N. Anjum and A. Cavallaro, çTrajectory association and fusion across partially overlapping camerasé, in Proceeding of IEEE International Conference on Advanced Video and Signal Based Surveillance AVSSê09\, 2009, pp.201-206 4 C. del-Blanco, R. Mohedano, N. Garcia, L. Salgado, and F Jaureguizar, ç Color-based 3D particle filtering for robust tracking in heterogeneous environmentsé, in Proceedings of second ACM/IEEE International Conference on Distributed Smart Cameras \(ICDSCê08 2008, pp.1-10 5 W. Youlu, S. Velipasalar, and C. Gursoy, çDistributed wide-area multi-object tracking with non-overlapping camera viewsé, in Multimedia Tools and Applications, 2012, pp.1-33  6 O. Javed, K. Shafique, and M. Shah, çAppearance modeling for tracking in multiple nonoverlapping camerasé, in Proceeding of IEEE Conference on Computer Vision and Pattern Recognition \(CVPRê05 vol.2, 2008, pp.26-33 7 B. Prosser, S. Gong, and T. Xiang, çMulti-camera matching using bidirectional cumulative brightness transfer functionsé, in Proceeding of the British machine vision conference \(BMVCê08\ Vol. 8, 2008 pp.1-10 8 T. DêOrazio, P. Mazzeo, and P. Spagnolo, çColor brightness transfer function evaluation for non-overlapping multi camera trackingé, in Proceeding of ACM/IEEE international Conference on Distributed Smart Cameras \(ICDSCê09\ 2009, pp.1-6 9 W. Youlu, L. He, and S. Velipasalar, çReal-time distributed tracking with non-overlapping camerasé, in Proceedings of IEEE Conference on Image Processing \(ICIPê10\, 2010, pp.697-700  A. Chilgunde, P. Kumar, S. Ranganath, and W. Huang, çMulticamera target tracking in blind regions of cameras with nonoverlapping fields of viewé, in Proceeding of the British Machine Vision Conference \(BMVCê04\4, pp.1-10  E. Monari, J. Maerker, and K. Kroschel, çA robust and efficient approach for human tracking in multi-camera systemsé, in Proceeding of the IEEE International Conference on Advanced Video and Signal Based Surveillance \(AVSSê09\, pp.134Ö139  J. Kang, I. Cohan, and G. Medioni, çPersistent objects tracking across multiple non overlapping camerasé, in Proceeding of the IEEE workshop on Motion and Video Computing \(WACV/MOTIONSê05 vol.2, 2005, pp.112-119  R. Pflugfelder and H. Bischof, çTracking across non-overlapping views via geometryé, in Proceeding of the International Conference on Pattern Recognition \(ICPRê08\, 2008, pp.1-4  Y. Shan, S. Sawhney, and R. Kumar, çUnsupervised Learning of Discriminative Edge Measures for Vehicle Matching between NonOverlapping Camerasé, in Proceeding of the International Conference on Pattern Recognition \(ICPRê05\, 2005, pp.894-901  A. Rahimi, B. Dunagan, and T. Darrell, çSimultaneous calibration and tracking with a network of non-overlapping sensorsé, in Proceeding of IEEE Computer Society Conference on Computer Vision and Pattern Recognition \(CVPRê04\ 2004, pp.187-194  W. Leoputra, T. Tan, and L. Lim, çNon-overlapping Distributed Tracking using Particle Filteré, in Proceeding of 18th International Conference on Pattern Recognition \(ICPRê06\6, pp.181-185  T. Huang and S. Russell, çObject identification: a Bayesian analysis with application to traffic surveillanceé, in Artificial Intelligence 1998, pp.77Ö93  L. Zhang, Y. Li, and R. Nevatia, çGlobal Data Association for MultiObject Tracking Using Network Flowsé, in Proceeding IEEE Conference on Computer Vision and Pattern Recognition \(CVPRê08 2008, pp.1-8  B. Song, and A. K. Roy-Chowdhury, çStochastic adaptive tracking in a camera networké, in Proceeding IEEE Conference on Computer Vision and Pattern Recognition \(CVPRê08\ 2008, pp.1-8 
 
In accuracy, the contrast ratio between our method and the Bayesian method is 1:1.11; in the computation time, our method increases about 27.5%. Table III shows the comparison of detail computational time taken by two methods and Table IV shows the accuracy comparison  TABLE  III  C OMPARATION ON COMPUTATIONAL TIME  C ONCLUSIONS  In this paper, we present a new vehicle tracking surveillance approach with non-overlapping views in multicamera. A framework to perform robust multiple targets tracking across multiple cameras is discussed. The multiobjects in multi-camera data association problem is formed with a minimum cost and maximum flow mode. For robust multi-camera tracking, time, location, classification type, and appearance of targets are effectively applied as a similarity measure. The approach is tested with real surveillance videos from the campus of HUST. The experimental results validate the robustness and effectiveness of the approach Experimental results also indicate that the method of tracking across multiple cameras is feasible after a high quality of feature extraction and target detection. For future work, more efficient and effective appearance models and feature extraction are desired to increase the accuracy of the approach A CKNOWLEDGMENT  This work is supported by National Natural Science Foundation of China under grant No.61133008 R EFERENCES  1 
                   
Record amount Computational time Bayesian 002 ms 002  MCMF 002 ms 002  Performance improvement Average Record amount Accuracy Bayesian MCMF Comparison Average 
1219 
1219 


 H. Jiang, S. Fels, and J. Little, çA linear programming approach for multiple object trackingé, in Proceeding IEEE Conference on Computer Vision and Pattern Recognition \(CVPRê07\, 2007, pp.1-8  N. Dalal and B. Triggs, çHistograms of oriented gradients for human detectioné, in Proceeding of IEEE Computer Society Conference on Computer Vision and Pattern Recognition \(CVPRê05\, 2005, Vol.1 pp.886-893  T. E. Choe, Z. Rasheed, G. Taylor, and N. Haering, çGlobally optimal target tracking in real time using max-flow networké, in Proceedings of IEEE International Conference on Computer Vision Workshops ICCVWê11\, 2011, pp.1855-1862 
   
1220 
1220 


state of innovation stakeholder  node PQ It  s a balanced node Based on this, we could calculate the  node PQ Calculation process is: set different inn ovation stakeholders state i U  and j U Value of ij 000T can be get from  innovation time difference. Innovation stakeholdersí social effect and industrial effect can be obtained upon ij B  and ij G set according to relation between innovation stakeholders  Model 4.1 points out  that the value of Gij  directly affects social benefits and sector benefits. Large Gij  can lead to increasing benefits of the entire industry and the entire social growth Bij reflects big organizationís impact on businesses. Only strengthening the inter agent association within big organization and enhancing the str ategic partnership between enterprises can jointly promote the development of the entire industry, and bring more social benefits, so that each agent can be improved   5 Summary This paper puts forward the concept of the big organization based on the CSM t heory. It introduces the basic implication of the big organization and theoretical framework of the big organization including: the big organization's perspective  overall perspective, dynamic perspective, and new resource perspective; the big organizat ionís sense  the purpose of the organizational structure is innovation, organizational activities around the flow of information, breaking the traditional organizational structure, encouraging self run structure, and blurring organizational boundaries; the big organizationís platform  the platform ecosystem of the big organization ; the big organizationís operation mode  borderless learning mode, and cluster effect; the big organizationís theory  active management theory  leading consumers, and culture  entropy reduction theory  negative culture entropy and humanistic ecology theory  inspiring humanity, and circuit theory  a virtuous circle, and collaborative innovation theory  collaborative innovation stakeholder. This paper also discusses culture entropy reduction theory of the big organization  negative culture entropy, and coordinated innovation theory  innovation stakeholders collaboration. Culture entropy change model and collaborative in novation model are constructed   The research has just begun for the big organization. It also needs further improvement but remains the trend of the times   Reference  1  Gordon Pellegrinetti, Joseph Bentsman. Nonlinear Control Oriented Boiler Modeling A Benchmark Problem for Controller De sign [J  I E E E tr a n s a c tio n s o n c o n tr o l s y s te m s te c h n o lo g y 2 0 1 0  4 1\57 65  2  Klaus Kruger, Rudiger Franke, Manfred Rode Optimization of boiler start up using a nonlinear 457 


boiler model and hard constraints [J  E n e r gy 201 1 29   22 39 2251  3  K.L.Lo, Y.Rathamarit  State estimation of a boiler model using the unscented Kalman filter [J  I E T  Gener. Transm. Distrib.2008 2 6\917 931  4  Un Chul Moon, Kwang. Y.Lee. Step resonse model development for dynamic matrix control of a drum type boiler turbine system [J IE E E  T ra nsactions on Energy Conversion.2009 24 2\:423 431  5  Hacene Habbi, Mimoun Zelmat, Belkacem Ould Bouamama. A dynamic fuzzy model for a drum boiler turbine system [J  A u to m a tic a 2 0 0 9 39:1213 1219  6  Beaudreau B C. Identity, entropy and culture J   J o ur na l  o f  economic psychology, 2006, 27\(2 205 223  7  YANG M, CHEN L. Information Technique and the Entropy of Culture J  A cad e m i c E x ch a n g e  2006, 7: 048  8  ZHANG Zhi feng. Research on entropy change model for enterprise system based on dissipative structure J  Ind ustrial  Engineering and  Management 2007, 12\(1\ :15 19  9  LI Zhi qiang, LIU Chun mei Research on the Entropy Change Model for Entrepreneurs' Creative Behavior System Based on Dissipative Structure J  C h i n a S of t S c i e n c e  2009   8  1 62 166   458 


A Global Solution COVERAGE North and South America EMEA and Asia White lines are flights in the masFlight platform from February 8, 2013 Yellow pins are weather stations feeding hour ly data to our platform Maps from Google Earth / masFlight masFlight tracks flights, airports and weather around the world  Global daily flight information capture  82,000 flights  350 airlines  1700 airports  Integrated weather data for 6,000 stations  Match weather to delays  Validate block forecasts at granular level  Add weather analytics to IRROPS review and scenario planning 


Example 1: Proposed FAA Tower Closures masFlight used big-data to link airport operations across three large data sets  Current and historical airline schedules  Raw Aircraft Situation Display to Industry \(ASDI\AA  Enhanced Traffic Management System Counts \(ETMS\Airport operations counts by type \(commercial, freight, etc TOWER CLOSINGS Dots indicate closures; Red dots have scheduled service Based on scheduled service March 1 7, 20 13; scheduled service includes scheduled charter flights, cargo flig hts, and passenger flights Dots  indicate  closures  Red  dots  have  scheduled  service Bas ed  o n sc h edu l ed  se rvi ce  M a r c h 1  7, 2013; scheduled se rvi ce includ es scheduled c harter fli g hts car g o fli g hts a nd passen g er fli g hts Findings: Proposed Tower Closings  From schedules database: 55 airports with scheduled passenger airline service  14 EAS Airports  From ASDI & ETMS: 10,600 weekly flights on a flight plan \(ex. VFR and local traffic  6,500 Part 91/125 weekly flights  4,100 Part 135/121 weekly flights  


Example 1: Big-Data Analytics Applied to ASDI and ETMS To Analyze Operations TOWER CLOSINGS  26 44 24 23 11 10 6 2 1 2 Up to 5 5-10 10-15 15-20 20-25 25-30 30-35 35-40 40-45 45 Count of Airports Average Number of Daily Operations with a Flight Plan Filed Distribution of Airports By Average Number of ìDailyî Impacted Flights Airports Affected by Tower Closures Source: ASDI radar data ñ Part 91 151 flying and Part 135/121 flying March 1-7, 2013; masFlight analysis Note: Average ìdailyì operations based on 5-day week 


Example 2: Aviation Safety Causal Factor For example, consider the following ASRS report \(ACN 1031837 Departing IAH in a 737-800 at about 17,000 FT, 11 m iles behind a 737-900 on the Junction departure over CUZZZ Intersection. Smooth air with wind on the nose bearing 275 degrees at 18 KTS We were suddenly in moderate chop which lasted 4 or 5 seconds then stopped and then resumed for another 4 or 5 seconds with a significant amount of ri ght rollingÖ I selected a max rate climb mode in the FMC in order to climb above the wake and flight path of the leading -900 We asked ATC for the type ahead of us and reported the wake encounter. The 900 was about 3,300 FT higher than we were  Synopsis  B737-800 First Officer reported wake encounter from preceding B737-900 with resultant roll and moderate chop What causal factors can be identified from this narrative that could be applied to future predictive applications CAUSAL FACTORS Data-mining algorithms can mine the text of safety reports to obtain specific data that can be used to analyze causal factors  


Example 2: Identifying Causal Factors CAUSAL FACTORS  Indicators ñ Data Element Methods ñ Identifying Context and Causes  Time of day  Date range \(month day  Aircraft type  Fix or coordinates  Originating airport  Destination airport  Weather notes We pinpoint the sequencing of flights on the IAH Junction Seven departure \(at CUZZZ\the specified wind conditions to find cases wher e a B737-900 at 20,000 feet precedes by 11 miles a B737-800 at 17,000 feet  Search related data sets including ASDI flight tracks, local traffic and congestion  Weather conditions for alter native causes \(winds aloft shear and convecti ve activity  Airline specific informati on \(repeated occurrence of event in aircraft type Big data gives us visibility into contextual factors even if specific data points are missing such as a specific date or route Big-data analytics gives us insight into unreported factors as well 


Example 3: Correlating Utilization and Delays  60 65 70 75 80 85 90 95 100 7 9 11 13 ONTIME DEPARTURE PERFORMANCE HOURS OF DAILY UTILIZATION 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Narrowbodies By Day of Week 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Widebodies by Day of Week Daily Utilization vs. On-time Departures January 2013 System Operations Correlation Coefficient -0.53 Includes AA, AC, AS B6 F9, FL, NK, UA, US VX and WN SOURCE masFlight \(masflight.com COMPARING OTP AND UTILIZATION 


 6.2 6.0 5.8 5.8 5.2 4.9 LGB JFK BOS MCO DCA FLL JetBlue Focus Average Daily Deps per Gate Used UTILIZATION BY HUB Example 4: Daily Utilization of Gates, by Hub Big-data analysis of different carriers daily departures per gate used SOURCE masFlight \(masflight.com June 1 through August 31, 2012 Gates with minimum 1x daily use 7.7 7.4 7.2 6.2 6.1 5.8 3.8 3.6 ORD LAX SFO EWR DEN IAH IAD CLE United Airlines Hubs Average Daily Deps per Gate Used 7.8 6.4 5.5 5.4 5.3 4.4 4.3 4.0 SEA SAN PDX ANC SFO GEG LAX SJC Alaska Airlines Hubs Average Daily Deps per Gate Used 7.2 6.9 6.8 6.4 5.0 2.7 ORD DFW LAX LGA MIA JFK American Hubs Average Daily Deps per Gate Used 7.2 6.9 6.6 4.9 4.2 CLT DCA PHL PHX BOS US Airways Hubs Average Daily Deps per Gate Used 6.6 5.9 5.5 4.7 MCO BWI ATL MKE AirTran Hubs Average Daily Deps per Gate Used ne pe 


Conclusions for Big Data in Aviation  Big-data transforms operational and commercial problems that were practically unsolvable using discrete data and on-premises hardware  Big data offers new insight into existing data by centralizing data acquisition and consolidation in the cloud and mining data sets efficiently  There is a rich portfolio of information that can feed aviation data analytics  Flight position, schedules, airport/gate, weather and government data sets offer incredible insight into the underlying causes of aviation inefficiency  Excessive size of each set forces analysts to consider cloud based architectures to store, link and mine the underlying information  When structured, validated and linked these data sources become significantly more compelling for applied research than they are individually  Todayís cloud based technologies offer a solution CONCLUSIONS 


Conclusions:  Our Approach  masFlightís data warehouse and analysis methods provide a valuable example for others attempting to solve cloud based analytics of aviation data sets  masFlightís hybrid architecture, consolidating secure data feeds in on-premises server installations and feeding structured data into the cloud for distribution, addresses the unique format, security and scale requirements of the industry  masFlightís method is well suited for airline performance review competitive benchmarking, airport operations and schedule design and has demonstrated value in addressing real-world problems in airline and airport operations as well as government applications CONCLUSIONS 






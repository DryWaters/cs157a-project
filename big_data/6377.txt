A Case Study in Seeding Collaboration Transformation With Experience Themes  Faith McCreary, Marla Gomez Anne McEwan  IT User Experience Research  Intel Corporation  Portland, OR  USA   Susan Michalak  IT User Experience  Intel Corporation  Portland, OR, USA  C i ndy  Pickering  IT Collaboration Engineering  Intel Corporation  Chandler, AZ, USA   Deidre Ali  Human Centered Design  Emerson Net work Power  Columbus, OH USA     Abstract 000 Collaboration at Intel is currently in a stage of 
transformation with increased focus on using social computing and other technologies to boost collaborati on and productivity  This transformation requires a shift in the services IT provides and a solid understanding of the expectations that employees have of both their technology and the larg er environment in which collaboration happens  At the same time we have been given the mandate to Be Bold, and Act Fast, leaving little time for upfront user research and requiring us as UX professionals to re think how we enable project teams to be more  effective within this new reality  One approach that is being  used within IT to help product  design teams move more quickly is experience themes which package available user research for easier reuse 
The collaboration portfolio has been an early adopt er and used experience themes for the last year to help define the desired collaboration experience from upfront strategy  and back end architecture  to the design of individual products We will share  learnings on how to best use these concepts and discus s the benefits of having a re usable over arching experience vision in guiding product  decision making  Keywords C ollaboration Frameworks and Methodologies for Collaboration Architecture  and Design of Collaboration Systems Collaborative Human Centered  Systems  
I   I NTRODUCTION  0007\000R\000G\000D\000\\\000¶\000V\000\003 collaboration  experience is often a fragmented one that spans multiple vendors devices products and platforms U sers must shift between vastly different interfaces with divergent experiences, leaving the user often frust rated and less efficient as a result.   IT shops wanting to give the user a more uniform experience often define interface standards that prescribe color schemes fonts layouts and the like  While these standards are often successful at taming the visua l inconsistencies they do little to address the functional inconsistencies or to ensure that the many fragments come together in a coherent fashion  in support of collaboration   After years of trying to wrestle the individual components 
of the enterprise experience into some semblance of a usable experience, Intel IT took on an audacious goal to define a One IT experience that met both employee and customer needs Defining an  over arching enterprise user experience  UX  started  with having trusted data tha t can help set the direction While we well understood the value of traditional UX methods   1   2   3   4    we found over time that insights derived from these methods which are often elicited using small sample sizes that are not statistically significa nt for an enterprise   were often not trusted by  traditional IT  To increase trust and the 
likelihood of the larger IT organization acting on the resulting insights we decided to take a hybrid approach that would weave together the outputs of traditional UX methods with analysis of 000W\000K\000H\000\003 000R\000S\000H\000U\000D\000W\000L\000R\000Q\000D\000O\000\003 000³\000E\000L\000J\000\003 000G\000D\000W\000D\000´\000\003 000W\000K\000D\000W\000\003 000H\000Q\000W\000H\000U\000S\000U\000L\000V\000H\000V\000\003 000F\000R\000O\000O\000H\000F\000W\000\003 about their users   5    6    7   Along with establishing a trusted data source  for optimizing the UX of IT systems we also generated a treasure trove of da ta about user behavio r and a frame of reference for testing the generalizability of UX insights  What started out as cross company research to develop a 000K\000R\000O\000L\000V\000W\000L\000F\000\003\000X\000Q\000G\000H\000U\000V\000W\000D\000Q\000G\000L\000Q\000J\000\003\000R\000I\000\003\000Z\000K\000D\000W\000\003\000W\000K\000H\000\003\000F\000R\000P\000S\000D\000Q\000\\\000¶\000V\000\003 
more than 100K employees want and need evolved into a common language and fra mework that defines the One IT experience vision that spans the many products and services provided by corporate IT 8   The framework is  designed to help IT product teams more easily re use insights from user research and document user needs from high le vel themes They can then define roadmaps  usage models  and user requirements that will be mapped to design prototypes, underlying capabilities and technologies   In this paper we focus on the framework and research results that inform design and imple mentation of enterprise collaboration solutions S ection II  d iscuss es the experience research framework, approach, demographics 
 and the  data set characteristics   It also explains how the data was connected to individual user s to identify user  patterns an d subsequent  derivation of core experience themes user segments environmental influencers and work activities   It goes on to describe three  experience themes and then focusses on the qualities and elements for the Connect Me theme wh ich is all about C ollaboration  Section III explains how the results  derived in S ection II are  being used within the enterprise by  the 978-1-4799-5158-1/14/$31.00 ©2014 IEEE 72 


IT collaboration portfolio team who was a n early adopter of the Connect Me experience theme and the underlying data   It includes  a case s tudy of how the experience themes were used f or purposes ranging from setting portfolio strategy to helping an agile product team move faster on a proof of concept  implementation  Section IV includes challenges V discusses results and VI concludes with  le ssons learned from a year of applying using experience themes and their interplay with presumptive design   Reader Note  in this paper social computing spans a range of collaborative technologies including so cial analytics immersive video and sketching r ecommendation engines social networking   content collaboration via multi media blogs wiki and discussion forums  and cross system activity stream aggregation  as used in an enterprise setting  II  A  B IG D ATA E XPERIENCE F RAMEWORK  IT in partnership with HR conducted more than 200 interviews and 300 participatory design sessions with employees to better understand their needs of the Intel experience  Additionally over 12 million employee transactions with Intel systems were captured.  Since the initial stud y in 2011 IT has added to the data set with more than 10,000 employee surveys and many millions of additional employee transactions   resulting in a 275 growth in the data set in less than two years.  The resulting multi gigabyte data set covers more than  88,000 employees across Intel and around the world  The transactional  000³\000E\000L\000J\000\003 000G\000D\000W\000D\000´\000\003 000S\000U\000R\000Y\000L\000G\000H\000G\000\003 000G\000H\000W\000D\000L\000O\000V\000\003 000D\000E\000R\000X\000W\000\003 employee  behavior but it did not help us  understand what motivated  000H\000P\000S\000O\000R\000\\\000H\000H\000V\000¶\000\003 000E\000H\000K\000D\000Y\000L\000R\000U\000\003 or their  larger context  While UX methods yielded rich contex tual insights they relied on small numbers of users and sample sizes that were not always  statistically significant at the enterprise level which put  their generalizability into question  However by connecting our diver se  data sets, we could mitigate t hese inherent risks of both types it also let us study the actual behavior of users along with their attitudes towards their IT experience while at the same time growing our understanding of the holistic IT consumption by individual employees  We put users at the center of our strategy for connecting our large scale data set.  Each piece of data was linked to a specific user, and all data for an individual user was linked together.  As o ur foremost concern was protecting the privacy of employees prio r  to making any attempt to integrate the data sets, the raw data was anonymized by replacing all employee identifiers with an encrypted identifier  By organizing the data in terms of individuals we could more easily discern user patterns and connect new d ata as it is discovered  Best fit patterns were then identified based on similarities in how employees used and responded to IT solutions  Over a period of months the final 000 meta 000  patterns emerged and became the foundation of the experience framework  000x  T hemes or the core experiences that enterprise users wanted from the IT experience regardless of what product or service the user was interacting with  000x  Segments or groups of users with similar usage of enterprise systems, attitudes towards IT, and user n eeds  000x  Influencers or core elements of the enterprise 000H\000Q\000Y\000L\000U\000R\000Q\000P\000H\000Q\000W\000\017\000\003 000Z\000K\000R\000V\000H\000\003 000F\000K\000D\000U\000D\000F\000W\000H\000U\000L\000V\000W\000L\000F\000V\000\003 000L\000P\000S\000D\000F\000W\000\003 000W\000K\000H\000\003 000X\000V\000H\000U\000¶\000V\000\003 ability to accomplish work  \(e.g., culture  000x  Activities  or the high level tasks that all enterprise users engage in in order to accomplish work \(e g., find information  Together they define the over arching IT experience desired by employees  To aid decision making each component had experience objectives defined in terms of user minimum, target and outstanding expectations of that specific compo nent To use teams must first look for intersections between their product and the larger desired IT experience 8    The framework represented the first ever broad understanding of the IT experience that is re usable and extensible to a range of IT p roducts and services.   It provided a shared vocabulary and reference for discussing the enterprise experience that can be applied across individual enterprise products as well as the cumulative IT experience. By providing a common language for discussing the IT experience it facilitated cross product conversations helped democratize participation in UX and encouraged shared ownership of improving the larger IT experience  A  Seeding Action with  Stories  While the underlying data patterns were potentially powerful they did not lend themselves to easy re use in different contexts.  We needed teams to be able to zoom in and understand at a detailed level how the framework could help them reframe the experience of a specific product or service At the same t ime, we needed teams to be able to zoom out and assess how well their prod uct fit the larger experience   The supporting collateral for the framework needed to put  a face to the underlying big data and provide IT with an actionable experience vision to driv e product design   Key to the successful use of the experience framework  has been the introduction of large scale layered storytelling as an underlying unifier across the supporting collateral  By necessity, the underlying stories focus on particular el ements of the dataset and ignore the rest  Strung together they map the larger IT experience but individually only tell a piece  The data set is simply too large and diverse to be told by a single story  The stories associated with different pieces  pro vide different insights  and follow different models   Users of the framework  then take these stories and underlying data to create their own stories that are relevant to what they are trying to accomplish many stories are possible from the same data Much  has been learned in the last year about how to most effectively use this information with product teams and the collateral has iteratively evolved to better support the layered storytelling necessary to make sense of this mountain of data For the framew 000R\000U\000N\000¶\000V\000\003\000S\000R\000W\000H\000Q\000W\000L\000D\000O\000\003\000W\000R\000\003\000E\000H\000\003\000U\000H\000D\000O\000L 000H 000G\000\017 000\003 we needed to socialize it through  presentations social media workshops and training with everyone from portfolio owners technical strategists UX apprentices and practitioners architects and IT staff Socialization has b een an iterative 73 


process requiring persistence and refinement of our messaging and  collateral for different roles within the organization  B  Seeding Shared Understanding  Experience themes helped the collaboration portfolio team understand the shared expectat ions that employees have of both the collaboration environment as well as their interactions with social computing tools.  There are three key experience themes that employees expect all social computing solutions to satisfy  000x  Feed Me   I quickly and easily find the information I need to speed my work and my life  000x  Connect Me   Connect me with the people resources and expertise I need to be successful at Intel  000x  Know Me   My  information is known and protected  by Intel   my information  is used to improve provi ded services  Of the three Connect Me has the strongest affinity to the overall collaboration portfolio  To increase the ease of applying an experience theme to a specific product or service the themes are further broken into qualities that define the essential experience principles needed to bring a specific theme to life  Each quality  include s  key usage elements and desired functionality  They were packaged 000D\000V\000\003\000T\000X\000D\000O\000L\000W\000\\\000\003\000³\000W\000U\000D\000G\000L\000Q\000J\000\003\000F\000D\000U\000G\000V\000´\000\003 to  provide tangible artifacts for teams to u se while defining  UX st rategy and solution  roadmaps  In order to provide sufficient detail to fuel product teams experience qualities were decomposed into elements Elements specify the key usages that make up a quality including user scenarios user requirements relative im portance illustrative examples and any user differences  They were packaged in theme vision books and as 8x10 cards to facilitate use in face to face design sessions  Together the t hree themes 12 qualities 59 elements and many hundreds of user req uirements detail the envisioned experience  By mapping the intersection between experience qualities and elements against portfolio and product roadmaps teams can identify potential gaps between the planned and desired experience for the products in thei r portfolio  Table I  maps employee expectations related to collaboration from the Connect Me theme  C  Seeding Shared User Models  Segments provide a common cast of characters for IT teams creating enterprise experiences Segments are groups of users with s imilar usage of enterprise systems attitudes towards IT and user needs  Of all the framework building blocks the adoption curve for segments was the shortest with teams readily seeing the value of knowing the pain points and IT usage patterns of their  target audiences  Each segment has a persona family that represents it 000S\000H\000U\000V\000R\000Q\000D\000V\000\003 000S\000X\000W\000\003 000D\000\003 000³\000I\000D\000F\000H\000´\000\003 000W\000R\000\003 000W\000K\000H\000\003 000H\000Q\000W\000H\000U\000S\000U\000L\000V\000H\000\003 000X\000V\000H\000U\000\003 000V\000H\000J\000P\000H\000Q\000W\000V\000\021\000\003 0007\000K\000H\000\\\000\003 provide summary information on user characteristics, goals and needs, key tasks and behaviors, pain points, use of IT pro ducts and relative priority of different experience qualities The collateral ranges from persona family posters contextual scenarios individual personas day in the life 000 s and trading cards  Although IT experience themes are based on research with tho usands of employees and apply to all IT products, how they apply to individual employee segments may vary depending on activity, e.g., collaboration.  Table II summarizes the high level collaboration patterns or shared focus within the segments  TABLE I  C ONNECT M E  E XPERIENCE Q UALITIES AND E LEMENTS  Qualities  Key Elements  Purposeful   Together we do work  000\000\003\000\003\0005\000D\000S\000L\000G\000O\000\\\000\003\000F\000R\000P\000P\000X\000Q\000L\000F\000D\000W\000H\000\003\000D\000Q\000G\000\003 share using an online workspace  000\000\003\000+\000D\000Y\000H\000\003\000D\000F\000F\000H\000V\000V\000\003\000W\000R\000\003 internal crowdsourcing  000\000\003\000\003\000&\000R creation  000\000\003\000\003\000&\000R\000O\000O\000D\000E\000R\000U\000D\000W\000H\000\003\000H\000[\000W\000H\000U\000Q\000D\000O\000O\000  000\000\003\000\003\000\(\000[\000S\000H\000U\000W\000\003\000D\000Q\000G\000\003\000H\000[\000S\000H\000U\000W\000L\000V e finding  Easy   Easy to work together and connect  000\000\003\000\024 Stop collaboration  000\000\003\000\024\000\003\000S\000O\000D\000F\000H\000\003\000W\000R\000\003\000P\000D\000Q\000D\000J\000H\000\003\000P\000H\000H\000W\000L\000Q\000J\000V  000\000\003\0004\000X\000L\000F\000N\000\003\000D\000Q\000G\000\003\000H\000D\000V\000\\\000\003\000F\000R\000O\000O\000D\000E\000R\000U\000D\000W\000L\000R\000Q\000\003\000P\000D\000Q\000D\000J\000H\000P\000H\000Q\000W  000\000\003\000$\000O\000Z\000D\000\\\000V\000\003\000D\000Y\000D\000L\000O\000D\000E\000O\000H\000\003\000\011\000\003\000V\000D\000I\000H  000\000\003\000$\000O\000Z\000D\000\\\000V\000\003\000V\000D\000I\000H  Cooperative  000  Help w illingly as I need people to be successful  000\000\003\000/\000H\000D\000G ers lead the way  000\000\003\000&\000R\000O\000O\000D\000E\000R\000U\000D\000W\000L\000R\000Q\000\003\000I\000U\000L\000H\000Q\000G\000O\000\\\000\003\000F\000X\000O\000W\000X\000U\000H  000\000\003\000&\000R\000O\000O\000D\000E\000R\000U\000D\000W\000L\000R\000Q\000\003\000I\000U\000L\000H\000Q\000G\000O\000\\\000\003\000Z\000R\000U\000N\000V\000S\000D\000F\000H\000V  000\000\003\000&\000R\000O\000O\000D\000E\000R\000U\000D\000W\000L\000R\000Q\000\003\000I\000U\000L\000H\000Q\000G\000O\000\\\000\003\000W\000H\000D\000P\000L\000Q\000J\000\003  000\000\003\000,\000¶\000P\000\003\000U\000H\000D\000G\000\\\000\017\000\003\000Z\000L\000O\000O\000L\000Q\000J\000\017\000\003\000D\000Q\000G\000\003\000D\000E\000O\000H  to collaborate  000\000\003\0009\000D\000O\000X\000H\000\003\000I\000R\000U\000\003\000P\000H  Presence   Always present or at least I feel like you are near  000\000\003\000&\000D\000Q\000\003\000E\000H\000O\000R\000Q g to online groups  000\000\003\000.\000Q\000R\000Z\000\003\000Z\000K\000H\000Q\000\003\000R\000W\000K\000H\000U\000V\000\003\000D\000U\000H\000\003\000D\000Y\000D\000L\000O\000D\000E\000O\000H\000\003\000W\000R\000\003\000F\000R\000Q\000Q\000H\000F\000W\000\003\000D\000O\000R\000Q\000J\000\003 with who they are  000\000\003\0006\000H\000H\000\003\000Z\000K\000R\000\003\000,\000¶\000P\000\003\000Z\000R\000U\000N\000L\000Q\000J\000\003\000Z\000L\000W\000K  000\000\003\0006\000H\000H\000\003\000Z\000K\000R\000\003\000R\000U\000\003\000Z\000K\000D\000W\000\003\000L\000V\000\003\000F\000R\000Q\000Q\000H\000F\000W\000H\000G\000\003\000W\000R\000\003\000W\000K\000L\000Q\000J\000V\000\003\000,\000\003\000D\000P\000\003 interested in  000\000\003\0006\000H\000U\000H\000Q\000G\000L\000S\000L\000W\000R\000X\000V\000O\000\\\000\003\000³\000E\000X\000P\000S\000\003\000L\000Q\000W\000R\000´\000\003\000L\000Q\000W\000H\000U\000H\000V\000W\000L\000Q\000J\000\003\000S\000H\000R\000S\000O\000H\000\003\000R\000U\000\003 information  TABLE II  USER SEGMENTS AND  THEIR C OLLABORATION PATTERN S  Segments  Shared Focus  Key Concerns  Hardware Technologists  Hardware but at different stages of the product lifecycle  000\000\003 Finding  information in secure repositories  000\000\003\000\003\0000\000R\000V\000W\000\003\000F\000R\000Q\000F\000H\000U\000Q\000H\000G\000\003\000Z\000L\000W\000K\000\003\000V\000H\000F\000X\000U\000L\000W\000\\\000\003\000R\000I\000\003 collaboration tools  New Em ployees  Doing the job while figuring out the corporation  18 months  000\000\003 Informal networking to learn  000\000\003\000,\000Q person training helps  grow network  000\000\003\000/\000H\000D\000V\000W\000\003\000F\000R\000Q\000F\000H\000U\000Q\000H\000G\000\003\000Z\000L\000W\000K\000\003\000V\000K\000D\000U\000L\000Q\000J\000\003 information socially  Manufacturing Operations  Meeting production schedules  000  Prefer in person sharing over electronic  000\000\003\000/\000R\000Z\000H\000V\000W\000\003\000X\000V\000H\000\003\000R\000I\000\003\000F\000R\000O\000O\000D\000E\000R\000U\000D\000W\000L\000R\000Q\000\003\000W\000R\000R\000O\000V\000\003 due to limited computer access  Versatile Experts  Applying their skill sets across the corporation  000\000\003\000 eaviest users of collaboration tools  000\000\003\0000\000R\000V\000W\000\003\000G\000L\000Y\000H\000U\000V\000H\000\003\000Q\000H\000W\000Z\000R\000U\000N\000V  000\000\003\000\\000U\000X\000V\000W\000U\000D\000W\000H\000G\000\003 by silos  Software Developers  Software but targeting different audiences  Intel versus  external  audiences   000\000\003\000/\000H\000D\000V\000W\000\003\000O\000L\000N\000H\000O\000\\\000\003\000W\000R\000\003\000Z\000R\000U\000N\000\003 independently  000\000\003\000/\000H\000D\000V\000W\000\003\000V\000D\000W\000L\000V\000I\000L\000H\000G\000\003\000Z\000L\000W\000K\000\003\000F\000R\000O\000O\000D\000E\000R\000U\000D\000W\000L\000R\000Q\000\003 tools expect internal tools to function like latest external ones  Adm inistrators  Helping others by acting on their behalf  000\000\003\000$\000P\000R\000Q\000J\000\003\000K\000H\000D\000Y\000L\000H\000V\000W\000\003\000X\000V\000H\000U\000V\000\003\000R\000I\000\003\000P\000R\000V\000W\000\003 collaboration tools  000\000\003 A dminister  and manage the collab orations of  other s  74 


D  Seeding a Future Vision of Collaboration  The experience framework is a representation of the desi red future of the enterprise from the user perspective.  It provides a thinking model for those who make the day to day decisions that define the enterprise It encourages them to look beyond their immediate challenges past the boundaries of what they ar e responsible  for  and consider the holistic experience from the perspective of enterprise users  This big data look at the employee experience has provided significant insights as to what employees want and need from Intel IT related to collaboration Ke y opportunities for improving collaboration that emerged included  000x  Make use of collaboration tools easier through  seamless integration of tools, a single center of gravity for accessing and managing collaborations consumer grade experiences and increased  support for sense making across multiple activity streams  000x  Make finding experts or expertise easier through  personalized recommendations more transparent security, and making connections more visible  000x  Increased personal interactions with more opportuni ties to collaborate in person higher fidelity virtual alternatives, and increased access to video  000x  Create a more supportive culture for collaboration through  more leadership support and role modeling of best approaches including discipline collaboration  9     III  TURNING  UNDERSTANDING  INTO  TRANSFORMATION  The framework was intended to seed the envisioned experience into existing processes by providing a shared vocabulary and shared ways of examining the enterprise  We encouraged teams to selectively apply dif ferent pieces of the framework depending on where they were in their existing processes To help guide enterprise  professionals in incorporating the framework into their processes, we proposed the following iterative approach with the outputs of the last step feed ing  back into the first  000x  Evaluate what is  Use segments to better understand users and theme s  and associated components   to determine how well current reality is meeting user needs   000x  Ask what if  Use relevant theme components to start the co nversation with users stakeholders and team s  and to envision possible new futures  000x  Prioritize what is most needed  Use the experience objectives and the outputs of previous steps to set UX strategy, define roadmaps, and identify gaps   000x  Define the detail   Use framework personas requirements scenarios and related design patterns to define what a product or service would do  We stressed that framework insights were not a replacement for what was already known but instead were additive.  We set the exp ectation that the framework would not answer all their questions and any gaps in understanding would need to be filled  using traditional UX methods   2  3  4   A  Seeding Agility with Presumptive Design  The IT collaboration portfolio team further evolved  this approach by combining this experience framework with e lements of presumptive design 4    T he  e xpe r i e nc e  t he m e s   along with what was already known about a particular audience e.g field sales   000I\000R\000U\000P\000X\000O\000D\000W\000H\000G\000\003 000W\000K\000H\000\003 000V\000W\000D\000U\000W\000L\000Q\000J\000\003 000³\000S\000U\000H\000V\000X\000P\000S\000W\000L\000R\000Q\000V\000´\000\003 000R\000Q\000\003 which design s were based  These starting presumptions were then validated using low cost methods and prototypes   The exact validation approach varied depending on the level of the collaboration facet under scrutiny e.g portfolio strategy product experience bu t regardless of approach there was a shared focus on quick low cost ways to expose presumptions to potential users and have them respond  B  Validating Strategic Direction  The IT collaboration portfolio team led a recent  corporate strategic discussion CSD  with exe cutive management  The discussion content pulled heavily from the information that formed the original basis for the IT Experience Themes However the original data was almost nine months old so many of the most recent hires into Intel were not represented by the information.  Additionally, our CEO saw attracting and 000U\000H\000W\000D\000L\000Q\000L\000Q\000J\000\003 000Q\000H\000Z\000\003 000H\000P\000S\000O\000R\000\\\000H\000H\000V\000\003 000D\000V\000\003 000D\000Q\000\003 000H\000V\000V\000H\000Q\000W\000L\000D\000O\000\003 000F\000R\000P\000S\000R\000Q\000H\000Q\000W\000\003 000R\000I\000\003 000,\000Q\000W\000H\000O\000¶\000V\000\003 growing business in new markets  The CSD team turned to crowdsourcing for a quick way to validate our starting assumption s about collaboration and 000F\000D\000S\000W\000X\000U\000H\000\003 000W\000K\000H\000\003 000F\000R\000O\000O\000H\000F\000W\000L\000Y\000H\000\003 000Z\000L\000V\000G\000R\000P\000\003 000R\000I\000\003 000,\000Q\000W\000H\000O\000¶\000V\000\003 000Q\000H\000Z\000H\000V\000W\000\003 000H\000P\000S\000O\000R\000\\\000H\000H\000V\000\003 000R\000Q\000\003 this topic. Crowdsourcing is the practice of soliciting feedback on a subject from a large group of people through an online community The general concept is to combine  the efforts of many participants, where each one contributes a small portion which then creates a relatively large or significant result.  It is definitely a guerilla method of employee research meaning it is quick and dirty but still gathers lots of us eful data\.  It is also fast for employees and takes only a matter of minutes versus an hour or so for more traditional user research methods  A 10 day bounded crowdsourcing was used to gather ideas on how Intel can better leverage the combined intellige nce of employees to improve collaboration and increase velocity at Intel.  We asked questions in four categories that we presumed to be the primary problem areas related to collaboration  000x  Velocity of innovation  000x  Barriers to working together  000x  External best pr actices we should integrate within Intel  000x  Finding the right people to collaborate with  44 percent of the threads related to organizational barriers 45 percent to technology, 7 percent to people, and 4 percent to the physical workspace  The crowdsourcing r esults aligned with 000R\000W\000K\000H\000U\000\003\000U\000H\000V\000H\000D\000U\000F\000K\000\003\000Z\000H\000¶\000G\000\003\000F\000R\000Q\000G\000X\000F\000W\000H\000G\000\017\000\003\000Z\000K\000L\000F\000K\000\003\000I\000R\000X\000Q\000G\000\003\000W\000K\000D\000W\000\003\000\032\000\026\000\003\000S\000H\000U\000F\000H\000Q\000W\000\003\000R\000I\000\003 employees talked about how collaboration hel ps them feel engaged at work  10, 11     75 


C  Identifying Goals and Priorities  the Portfolio  The experience themes and their underlyi ng components were diagrammed into a wall sized mind map format Meanwhile the portfolio UX teams had compiled deep dive research in the context of specific business groups and projects Using sticky notes and highlighters we added in data that we found  from the deep dive research  where it intersected with the experience themes and components   We also found a few small nuances that we added to the mind map and noted the sources so we could go back to them  Next   we reviewed the mind map and looked for nuances related to particular audiences or segments  Figure 1  shows a portion of the  combined picture tha t highlights what was in common along with gaps that we needed to resolve  for Connect Me  theme Presence  000T\000X\000D\000O\000L\000W\000\\\000\003 000D\000Q\000G\000\003 000W\000K\000H\000\003 000³\0006\000H\000H\000\003 000Z\000K\000R\000\003 000,\000\003 000D\000P\000\003 000Z\000R\000U\000N\000L\000Q\000J\000´\000\003 000Z\000L\000W\000K\000\003 e lement which mapped to pervasive video capabilities  Next, we used the mind  map and the underlying user needs defined by experience qualities and elements to get the portfolio design process started.  To help define the portfolio 000¶\000V  collaboration gaps and p riorities  we isolated the elements relevant to collaboration and developed a he at map Key questions included  H 000R\000Z\000\003 000Z\000H\000O\000O\000\003 000D\000U\000H\000\003 000W\000R\000G\000D\000\\\000¶\000V\000\003 000F\000D\000S\000D\000E\000L\000O\000L\000W\000L\000H\000V\000\003 000P\000H\000H\000W\000L\000Q\000J\000\003 target requirements for each collaboration element How important are each of those elements to our us ers? Answers to those two questions would help us prioritize where to focus development energy first.  We relied heavily on the minimum target, and outstanding requirements that were defined for each quality and element from the themes   This importance r ating of requirements was based on the relative frequency of requirements across the underlying research and the importance that employees placed on the requirement  For each experience element related to collaboration we looked across the portfolio an d identified which capabilities and services currently addressed the requirements and at the      same time identified where the gaps were  For example an 000H\000O\000H\000P\000H\000Q\000W\000\003 000F\000U\000L\000W\000L\000F\000D\000O\000\003 000W\000R\000\003 000L\000Q\000L\000W\000L\000D\000W\000L\000Q\000J\000\003 000F\000R\000O\000O\000D\000E\000R\000U\000D\000W\000L\000R\000Q\000\003 000L\000V\000\003 000³\000%\000X\000P\000S\000\003 000L\000Q\000W\000R\000\003 000,\000Q\000W\000H\000U\000H\000V\000W\000L\000Q\000J\000\017\000´\000\003\000Z\000K\000L\000F\000K\000\003\000L\000V\000\003\000D\000E\000R\000X\000W\000\003\000K\000H\000O\000S\000L\000Q\000J\000\003\000X sers serendipitously bump into information or people that are interesting and useful to them We looked across the portfolio and identified which capabilities and services currently addressed the requirements 000I\000R\000U\000\003 000³\000%\000X\000P\000S\000\003 000L\000Q\000W\000R\000\003 000,\000Q\000W\000H\000U\000H\000V\000W\000L\000Q\000J\000\021\000´\000\003 000,\000Q\000\003 000W\000K\000L\000V\000\003 000F\000D\000V\000H\000\017\000\003 000Z\000H\000\003 000I ound that the 000S\000R\000U\000W\000I\000R\000O\000L\000R\000\003\000G\000L\000G\000Q\000¶\000W\000\003\000K\000D\000Y\000H\000\003\000D\000Q\000\\\000\003\000V\000R\000O\000X\000W\000L\000R\000Q\000V\000\003\000W\000K\000D\000W\000\003\000Z\000H\000U\000H\000\003\000P\000H\000H\000W\000L\000Q\000J\000\003\000W\000K\000H\000\003 target requirements 000 that is presenting people and resources to the 000X\000V\000H\000U\000\003 000E\000D\000V\000H\000G\000\003 000R\000Q\000\003\000W\000K\000H\000\003 000X\000V\000H\000U\000¶\000V\000\003 000F\000X\000U\000U\000H\000Q\000W\000\003 000F\000R\000Q\000Q\000H\000F\000W\000L\000R\000Q\000V\000\017\000\003 000W\000K\000H\000\003 000F\000R\000P\000P\000X\000Q\000L\000W\000L\000H\000V\000\003 that they follow, and t heir online activity.   Figure 2  shows an excerpt from the heat map for that element with details for minimum  and target roadmap levels   Figure 2  000³\000%\000X\000P\000S\000\003\000L\000Q\000W\000R\000\003\000,\000Q\000W\000H\000U\000H\000V\000W\000L\000Q\000J\000´\000\003\000+\000H\000D\000W\000\003\0000\000D\000S\000\003\000'\000H\000W\000D\000L\000O  D  Speeding Agile Product Design  On agile pr ojects where time is typically  the scarcest commodity t he rich detail provided by the framework helps bring focus to team efforts and helps teams more rapidly move Figure 1. An Excerpt from the Composite Collaboration Mind Map  76 


from concept discussions to prototypes.  Framework segments and an underlying component of experience qualities namely experience elements were c ombined with what was already known about a particular space to formulate the starting 000³\000S\000U\000H\000V\000X\000P\000S\000W\000L\000R\000Q\000V\000´\000\003\000R\000Q\000\003\000Z\000K\000L\000F\000K\000\003\000G\000H\000V\000L\000J\000Q\000V\000\003\000Z\000H\000U\000H\000\003\000E\000D\000V\000H\000G\000\021\000\003\000\003\000\003  Teams found that experience elements were the richest source of starting presumptions  They  document key usage scenarios  requirements users expect in products  with a particular quality provide example designs  and provide rich detail for project teams In multiple projects this information has seeded agile Vision Quest activities and served as a catalyst for creating desi gn hypotheses around core presumptions of what features and capabilities should be included in the solution  From the created design hypotheses a series of contextual scenarios were written that re framed element usage scenarios in light of the current project and then were used to storyboard the product vision  From the design hypothesis that the team formed a series of contextual scenarios were written The scenarios were collectively organized to form a high level 000 000Q\000D\000U\000U\000D\000W\000L\000Y\000H\000´\000\003\000W\000R\000\003\000W\000H\000O\000O\000\003\000D\000\003\000S\000H\000U\000V\000X\000D\000V\000L\000Y\000H\000\003\000V\000W ory  of the product vision and  documen ted in a storyboard artifact  Figure 3  shows a narrative excerpt from the resulting storyboard     Figure 3  Product Storyboard Narrative Excerpt  Framework examples often inspire many of the designs reflected in th e proof of concep t \(POC\ prototypes \(see Figure 4  and the storyboard typically contains a swim lane that the team used to map the experience themes to the relevant portion of the story  To validate design presumptions with users several intervals of pre sumptive design tests were conducted with end users in tandem with design activities. Those features 000W\000K\000D\000W\000\003 000Z\000H\000U\000H\000\003 000Q\000R\000W\000\003 000Y\000D\000O\000L\000G\000D\000W\000H\000G\000\003 000D\000V\000\003 000³\000Y\000D\000O\000X\000D\000E\000O\000H\000´\000\003 000E\000\\\000\003 000X\000V\000H\000U\000V\000\003 000Z\000H\000U\000H\000\003 000U\000H\000P\000R\000Y\000H\000G\000\003 from the storyboard and product vision. Following this process   the vision iteratively became m ore defined and evolved into a 000µ\000O\000L\000J\000K\000W\000Z\000H\000L\000J\000K\000W\000¶\000\003 000F\000O\000L\000F\000N\000D\000E\000O\000H\000\003 000S\000U\000R\000W\000R\000W\000\\\000S\000H\000\003 000Z\000K\000L\000F\000K\000\003 000Z\000D\000V\000\003 000W\000K\000H\000Q\000\003 000X\000V\000H\000G\000\003 000W\000R\000\003 engage stakeholders impacted teams analysts solution architects and the technical team in more conversations about feasibility and product requirements    Figure 4   000 Low Fidelity Prototype B ased on an Experience Element  E  Evaluating Experiences  Along with using the framework to set strategy and define project goals, IT teams are  also evaluating how well existing  or proposed  experiences satis fy  the cumulative IT experie nce envisioned by our users  Evaluation is made easy with a  spreadsheet that lets teams check  off the high level requirements satisfied by the  experience and then  quickly see how well it aligns with the over arching  experience framework The end result i s a color coded heat map which allows teams to visualize  where they should focus more attention in order to improve user experience    Red areas in the heat map signify gaps  that are important to resolve for users green areas represent healthy areas and y ellow  show medium level concern  The evaluation facilitates  discussion between business owners developers and UX professional s  to determine what capabilities the business thinks they need and creates a space for possibility thinking with developers  IV  C HAL LENGES  The IT Experience Framework puts a face to the underlying big data and provide s  an approach to defining a unified IT experience, but th e se insights are merely the tip of the iceberg of potential ones that could be derived from the underlying data se t.  They are like any model, a simplification, but even so and with supporting collateral project teams can still find them unwieldy to work with unless they have had coaching prior to interacting with them  There are multiple challenges with undertakin g an effort of this size  Designing great collaboration solutions is as much about getting and analyzing data as it is about transforming an 000R\000U\000J\000D\000Q\000L 000D 000W 000L 000R\000Q\000\003 000W 000R\000\003 000D 000F 000W 000X\000D 000O 000O 000 000\003 000X 000V 000H 000\003 000L 000W 000\003 000H 000I 000I 000H 000F 000W 000L 000Y 000H 000O 000 000\021\000\003 000 000W 000 000V 000\003 000D 000\003 000M 000R\000X\000U 000Q\000H 000 000\003 000D 000Q\000G\000\003 000D 000\003 process 000  not a silver bullet It requires joint  partnership and extensive collaboration across multiple disciplines Despite best efforts, the challenges of use are only expected to grow.  In the two years since the introduction of experience themes the underlying data set has grown 275% and the suppo rting story telling collateral has grown by 870% to better support the range 000R\000I\000\003 000X\000V\000D\000J\000H\000\003 000V\000H\000H\000Q\000\003 000D\000F\000U\000R\000V\000V\000\003 000,\0007\000\003 000S\000U\000R\000M\000H\000F\000W\000\003 000W\000H\000D\000P\000V\000\021\000\003 000\003 0007\000K\000D\000W\000¶\000V\000\003 000D\000\003 000O\000R\000W\000\003 000R\000I\000\003 information for anyone to digest  Some of the key challenges associated with this process are discussed below  77 


A  Trapped in Flat Space  To date, the majority of experience theme collateral resides in flat files or posts in social media forums  The underlying hierarchical structure of the deep storytelling defined by the collateral can be obscured by the media in which they resi de While physical artifacts are often needed for kickoff or face to face sessions online access  and an effective search  is also needed  We have experimented with using a wiki as a knowledge delivery system for the framework  but  by definition it is a s ite  where people go to collaborate on content  which typically contains  few graphics The framework is a definitive document   and while w e encourage linking of additional information  the framework content must remain unchanged  Additionally, the framewo rk is highly visual with data graphics personas and design examples which do not lend themselves to the content heavy wiki format  nor is there a simple mechanism for turning existing, highly readable content into wiki pages, so it increases our workload    B  Enabling Social Storytelling  Today, storytelling with the underlying big data is primarily limited to the research team that produced the experience themes or the UX professionals who work directly with them The rich data available on individuals spe cific job roles different organizations and even geographic areas makes possible a great many more stories than what is currently embedded in the experience themes  However the lack of 000³\000V\000H\000O\000I 000V\000H\000U\000Y\000L\000F\000H\000´\000\003 000H\000Q\000Y\000L\000U\000R\000Q\000P\000H\000Q\000W\000V\000\003 000W\000R\000\003 000H\000Q\000D\000E\000O\000H\000\003 000X\000W\000L\000O\000L 000D 000W 000L 000R 000Q\000\003 000R\000I 000\003 000W 000K\000H 000\003 000G\000D 000W 000D 000\003 limit s utilization of the data within larger IT  Additionally IT teams often need to understand how the overarching information about the employee experience intersects with data specific to an IT product or service in order to discover new insights about em ployee expectations of their product and how their product need s  to align with the over arching IT experience  Today this is also a manual process that can require substantive manipulation to ensure the 000O\000L\000P\000L\000W\000D\000W\000L\000R\000Q\000V\000\003\000R\000I\000\003\000W\000R\000G\000D\000\\\000¶\000V\000\003\000D\000Q\000D\000O\000\\\000V\000L\000V\000\003\000W\000R\000R\000O\000V\000\003\000D\000U\000H\000\003\000Q\000R\000W\000\003\000H\000[\000F\000H\000H ded   C  Fostering Knowledge Sharing  P roject teams are not just re using existing knowledge, they are adding to it by creating detailed stories of use in specific contexts and potentially doing additional research that may lend themselves to re use by other IT teams focused on the same audience  While the experience framework provides a skeleton for sharing information, this structure has not yet been brought to life online and no easy methods exist for teams wanting to share their stories and associated des igns.  Until that happens widespread sharing and associated efficiencies is unlikely to occur  Knowledge sharing is further inhibited by the siloed nature of most IT shops.  Each dataset incorporated in the framework requires individual negotiation and data from different areas is often incompatible incomprehensible and messy to tie together  Additionally users of the framework seldom share the experience artifacts built on top of the framework whether personas scenarios or design patterns  Su ccess requires shifting the mindset of UX professionals  to look past individual methods  and products  and look holistically at the enterprise experience to be comfortable with leveraging re usable insights about their users, and to accept that  these insigh ts can be successfully packaged for re use by traditional IT professionals     D  Exponentially Increasing Big Data  Lastly although collateral growth is beginning to stabilize based on active use by IT project teams, the underlying data set is expected to gr ow even more rapidly in coming years as analysis tools become capable of handling even larger data sets Only about 30 of available user transactional data has been incorporated in the current framework and the amount of data continues to increase on a daily basis further exacerbating the challenges of re use and sense making by IT project teams at large  E  Experience Driven Change is a Journey  Even with an over arching experience framework and strong leadership commitment to change collaboration at Intel  experience driven transformation is a journey and what works for one team or individual may not work for another.  It takes time and resources It takes a willingness to collaborate with the rest of the organization to find approaches that work  It requ ires recognizing that every team or individual is starting from a different point of faith and understanding of what UX is and how to do it. To do this, we have all had to transform our thinking, our approach, our decisions, and actions 000  from how we do us er research to defining portfolio strategy to individual decisions made on enterprise projects all the way up to architectural decisions and overall strategy decisions for the IT organization   V  D ISCUSSION AND R ESULTS  The experience framework is an innova tive way to represent UX research in a way that is consumable within the enterprise The framework is being used across various levels of the collaboration portfolio It is feeding collaboration portfolio strategy technical architecture plans and the des ign of specific products.  As a result, new learnings have emerged about how to most effectively integrate into the portfolio strategy and design which in turn has resulted in the development of new supporting collateral.  Key lessons learned include  000x  When  first introducing a team to the underlying concepts having them use the qualities to evaluate their own product or service is key to learning and provides a baseline for future improvements  000x  For setting product vision and strategy experience qualities are paramount They spark conversation and provide easy user functionality checklists that can be incorporated into user experience roadmaps  000x  Product teams once they get past the original strategizing and into design need the more detailed experience e lement cards that provide one place to access user requirements scenarios and key audience differences  78 


000x  Having sample designs that satisfy the themes is important they serve as a baseline for conversations about how the pattern can be improved or spa rk a new idea  000x  Different people have different learning styles and different teams have different ways to work together 000,\000I\000\003\000F\000R\000O\000O\000D\000W\000H\000U\000D\000O\000\003\000G\000R\000H\000V\000Q\000¶\000W\000\003\000U\000H\000V\000R\000Q\000D\000W\000H\000\017\000\003\000L\000W\000H\000U\000D\000W\000H\000\017\000\003\000L\000W\000H\000U\000D\000W\000H\000\017\000\003\000L\000W\000H\000U\000D\000W\000H\000\021  We also have found that in the early stages of an effort, a hard copy of c ollateral is often key to their successful use during project kickoffs.  Generating design ideas is often fastest when you have hardcopy of element cards and other experience theme collateral so the team 000F\000D\000Q\000\003\000³\000U\000H 000X\000V\000H\000´\000\003\000F\000R\000O\000O\000D\000W\000H\000U\000D\000O\000\003\000H\000O\000H\000P\000H\000Q\000W\000V\000\003\000L\000Q\000\003 paper prototypes   We have seen the value add of the principles of presumptive design and the agile process to experience themes At their most basic, they provide a foundational understanding of the needs of different kinds of employees in spaces that lack the time or re sources to invest in more traditional user research The themes also mitigate some of the key risks associated with presumptive design by pr o v i di ng a l a r g e r hol i s t i c l ook a t t he  experience space and overarching prioritization that helps prevent teams  from focusing on the wrong solution to design or ignoring the needs of the larger experience into which a design must fit  However use of experience themes does come at a cost Newcomers to experience themes can easily lose their way in the multi laye red story  Coaching or training on experience themes is needed before teams dive into their use  Some understanding of how the pieces fit together helps teams more quickly and effectively integrate themes into their existing process.  Often times the fir st exposure may feel overwhelming and only in follow up discussions do the pieces click  But when they do click they substantially speed teams from strategy definition to design  Furthermore experience themes provide IT with common target experiences and shared understanding of target users that can be leveraged across IT services and portfolios  not just collaboration This shared vision has the potential to transform IT product and services resulting in a more cohesive and usable 1 IT experience tha t could increase the velocity of teams across Intel  VI  C ONCLUSIONS  By far, the biggest potential value offered by IT Experience Themes is increased velocity Imagine the time gained by having productive team discussions that generate strategy and design idea s faster because the team is referencing a common framework and language that can be understood by all This recent work with experience themes can lead the way for other teams both in IT and in broader Intel to more effectively use experience themes to dr ive service strategy and design  However the framework results in significant change in the over arching IT experience  only when the finds are communicated in a way that resonates with the broad base of people who work together to define and develop the enterprise experience.  An architect will look at the framework collateral through  a different lens than a systems analyst or service owner  Further the framework seeds change  only through  a participatory process 000 it is not something that can be done by m erely throwing the framework over the fence at those outside of UX  For change to happen all levels of the organization must participate in the conversation and take ownership of how their own role impacts the enterprise experience  The large scale laye red storytelling approach allows experience theme users to explore the underlying data below the surface level of themes to find their own meaning and seeds design investigations of features and possible interaction models This approach to socializing and  utilizing experience themes provides a practical model for the creators of other types of experience themes to more quickly trigger transformation in their own spaces  A CKNOWLEDGMEN TS   We wou ld like to thank Jayne May who was instrumental in evolving the framework collateral  We would also like to thank the HR Employee Centered Solutions team that helped gather data for the original research that spawned the framework  Lastly we would like to thank Linda Wooding  who headed  000,\000Q\000W\000H\000O\000\003 000,\0007\000¶\000V\000\003 User Experience  tea m for without her belief and support this work  would not have been possible  R EFERENCES    A. Tuch R Trusell and K Hornbaek  000 000$\000Q\000D\000O\000 000L 000Q\000J 000\003 0008 000V 000H 000U 000V 000 000\003 0001 000D 000U 000U 000D 000W 000L 000Y\000H 000V 000\003 000W 000R\000\003 Understand Experience with Interactive Products 000  in P roc CHI 2013  ACM Press  pp 2079 2088 2013     I Young I Mental Models Aligning Design Strategy with Human Behavior Rosenfeld Media 2008     H. Beyer  and K. Holtzblatt 000 Contextual Design 000  Interactions  vol VI   no.1  pp 32 42 January  February  1999     000/\000\021\000\003 000\\000U\000L\000V\000K\000E\000H\000U\000J\000\017\000\003 000 Presumptive Design  Cutti 000Q\000J\000\003 000W\000K\000H\000\003 000/\000R\000R\000N\000L\000Q\000J\000\003 000*\000O\000D\000V\000V\000\003 000&\000D\000N\000H\000´\000\017\000\003  Intera ctions  vol. XIII no. 1 pp. 18 20  January / February 2006     S Madden. \(May, 2012  How Companies like Amazon Use  Big Data to Make You Love Them  Online   A va i l a bl e   http://www.fastcodesign.com/1669551/how companies lik e amazon use big data to make you love them    F  McCreary K Raval K and 0000\000\021\000\003 000\\000D\000O\000O\000H\000Q\000V\000W\000H\000L\000Q\000\017\000\003 000 Case Study in Using Macroergonomics as a Framework for Business Transformation 000  in  Proc Human Factors and Erg onomics Society Annual Meeting  vol. 50 no. 15 pp 1483 1487 October 2006     B  000.\000O\000H\000L\000Q\000H\000U\000\017\000\003\000 Macroergonomics as a Large Work S ystem Transformation 0007\000H\000F\000K\000Q\000R\000O\000R\000J\000\\\000´\000\017  Human Factors and Ergonomics in Manufacturing  vol 14 no. 2  pp 99 115 2004     000\\000\021\000\003\0000\000F\000&\000U\000H\000D\000U\000\\\000\017\000\003\0000\000\021\000\003\000*\000R\000P\000H 000\017 000\003 000 000\021 000\003 0006 000F 000K 000O 000R\000V 000V 000\017 000\003 000D 000Q 000G\000\003 000 000\021 000\003 0000 000F 000 000Z 000D 000Q\000\017 000\003 000 Charting a New Cou rse for the Workpla ce with an Experience Framework 000  in Proc 16th International Human Computer Interaction Conference in press      M Hansen Collaboration How Leaders Avoid the Traps Build Common Ground, and Reap Big Results   Boston, MA: Harvard Busine ss School Publish ing 2009    000&\000\021\000\003\0003\000L\000F\000N\000H\000U\000L\000Q\000J\000\017\000\003\000 Synergizing People, Process, and Technology to Motivate Knowledge Sharing and Collaboration 000´\000\003 000L\000Q\000\003 Proc International Conference on Collaboration Technologies and Systems   2013     F McCreary  and M Gomez     2013  Ja mming on Collaboration  Online    A va i l a bl e   http://www.slideshare.net/ITatIntel/jamming on collaboration  2013   79 


1 2 3 3 3 3 1 3 1 1 1 1 1 1 2 1 1 1 1 1 2 G G G G G G G c g f k G G G h h G G i G G G G G G V V v u V v V v v G v v v G V v G u v u v V v v V V E E V V E V v V E v V u V u v V V u T T s V T s  T T V G G i E E E E u E i i i i i i i i i i i i i i i i i i i i i i i i i i i i i d d i d d i d i i i i i i i i i i i i 212 i i 212 i i f G   and and and and and and and can be handled similarly In such a way Type-2 nodes can be effectively reduced in is generated from two can be computed In c G c G c G in in in itself is an is still a vertex cover of in line 4 of Algorithm 3 by joining in into into in in the in the next iteration of  In the following we introduce techniques to re duce the nodes and edges when constructing G  Thus the key point to reduce the I/O cost of the  when adding nodes into from  before adding can be removed from is removed can be removed from and Get SCC and there is no need to add v G v G v G v G v G v G v G v G v G v G v G h G h G h G h G E in each graph in each graph Example 6.1  when generating can be removed because  we check whether Node Reduction has been covered by node b e l j VII I/O C OST M INIMIZATION In this section we show how to optimize our contractionexpansion based is a Type-1 node from constructed in the from which is computed using can only hold                                                                                                                                                                             Type-2 nodes are order sensitive i.e if node in line 8-9 of Algorithm 3 for each edge smallest nodes using operator line 2 of Algorithm 3 A sequential scan of Fig 5 shows the process of the graph expansion phase to expand the graphs in order of  when constructing  if there does not exit another node may not be a Type-2 node Note that our aim is to reduce nodes in To remove Type-1 node  we only keep the nodes with both using a dictionary  In addition it is straightforward that each edge denoted by light gray nodes and has already been computed using Algorithm 3 the following two types of nodes can be removed from are Type-2 nodes after scanned suppose G are the removed nodes when constructing denoted by dark gray nodes In with a single node Finally there are two in Algorithm 3 Such an operation does not generate any extra I/O cost in Algorithm 3 In order to reduce Type-2 nodes when scanning all edges in which many not reside entirely in the main memory Suppose algorithm on approach by further reducing the I/O cost The I/O cost can be reduced in two ways 1 to reduce the number of graphs constructed in the graph contraction phase and 2 to reduce the number of nodes and edges for each graph s in later iterations A Type-2 node th graph contraction phase without increasing the I/O complexity Although sSCC g g f i i c k b l k i j G c d e b a l g f h i k j m SCC f g e c f c e f g b i l j k d or 0 Any node with              6 4                       1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 212    Thus     in later iterations as  Since SCC SCC SCC SCC SCC SCC SCC nodes respectively has been added into  Such edges can be reduced in a lazy way when generating Type-1 For a node Type-2 For a node is a valid node set of with  Similarly the with with with will be removed in with G G needs to be added after line 2 of Algorithm 3 to eliminate parallel edges in  0 We develop two methods to reduce the edge size in order to reduce the intermediate results We will discuss the ef\336ciency in our performance studies Firstly for parallel edges with the same form out out out out out out out out 0 deg deg deg deg deg deg deg deg nbr nbr nbr nbr nbr nbr nbr nbr u G u v u v u v u v u w v>u in in in in in in in in in in in i i i i i i i i i i i i i  all nodes nodes in memory since a node with higher degree are less possible to be removed from 4 3 2 1  However such a solution needs to check whether Semi u>v generated in the graph contraction phase in Fig 4 The dashed circles in each graph algorithm is to reduce the number of nodes and number of edges cannot be combined with other nodes to form new  According to the node selection condition in Lemma 5.1 without generating any extra I/O cost in Algorithm 3 can be removed because when  Given graph such that Lemma 7.1 can reside entirely in the main memory By doing so we can reduce the number of Type-2 nodes in Edge Reduction can be removed from 0 SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC s are computed namely 002 212 002 002   024    002 002 002 004 004   002       wehave to make sure that th iteration According to the stop condition of graph contraction reducing the number of graphs is equivalent to reducing the number of nodes Omitted due to lack of space is an  and there is no need to include again The situation for to cover the edge Given  0  Fig 5 Graph Expansion Example computed according to Lemma 6.4 This can be done in line 8 of Algorithm 4 by checking whether 216 if  By applying the  for node s of node  for node  Thus node with a single node in without introducing new I/O cost thus we only reduce those Type-1 and Type-2 nodes that are easy to be identi\336ed The following lemma can be used to reduce Type-1 nodes or or  we only maintain the top  only one of them needs to be kept in 212 1 2  suppose  200  200   A Type-1 node  4 3 2 1 4 3 3 4 3 2 1 1 1 1 G E  G G V V V V E V V v V V v v V V   V V V  V E  E w            0  0     and nodes  If so edge  we introduce two ways to reduce the number of edges when generating  it is possible that G   017      Proof Sketch Ext Ext 002 002 002 002 g G G  


Size of Largeincrease The reasons are twofold Firstly when increases according to the node selection scheme to construct decrease There are two reasons Firstly when the memory size increases the stop condition for graph contraction is easier to be satis\336ed since more nodes can 336t in memory Secondly when the memory size increases the costs of the external sorts in both graph contraction and graph expansion phases decrease  Average Degree Number of Largeincreases the time and I/O consumptions for both increases the number of iterations in graph contraction increases This is because when number of edges increases the cost to sort and scan edges in each iteration increases thus more time and I/Os are consumed in each iteration                                     2 4 1 u E  V v E    u v  G  V E M V M V K G V V M KB Range 25M,50M,100M,150M,200M 2,3,4,5,6 200M,300M,400M,500M,600M 400K 8K 20,30,40,50,60 30,40,50,60,70 10K to in the operator in line 4 both in line 4 and augmented in all nodes in in line 5-7 VIII P ERFORMANCE S TUDIES In this section we conduct experimental studies by comparing four external algorithms for is the number of bytes to keep a node in memory We set the max time cost to be 24 hours If a test does not stop in the time limit we will denote it using until all nodes form an to Size of Small The results are shown in Fig 7\(a and Fig 7\(b for time and I/O costs respectively When the memory size increases the time and I/O costs for both 100M 400M 40 1 1 50 TABLE I R ANGE AND D EFAULT V ALUE FOR P ARAMETERS Parameter in all cases since more nodes/edges are removed in each iteration in Operator  operator speci\336es a unique total order among all nodes in the graph operator in line 9 when generating algorithm needs to hold and and and and and used in introduced in 26  w h i ch is cu r r e n tly th e m o s t I O ef 336cien t sem i e x t er n a l algorithm for and  Secondly when and out out out out out out out Fig.6\(a and Fig 6\(b show the time and I/O costs when varying the number of edges of WEBSPAM-UK2007 from 20 to 100 respectively v G v G v G v G v G v G v G v G v G v G v G v G v G v G 002 212 327 327  002 002 327 327 327 327 327       2 cannot stop in the time limit even if the graph contains only 20 of the edges When Size of 8 our e x t e rnal cont ract i on-e xpans i o n b as ed algorithm Algorithm 2 and our algorithm by applying the optimization techniques introduced in Section VII in new edges are added into In Algorithm 3 in order to make use of the new s The graphs contain nodes from 25M to 200M with average degree varying from 2 to 6 A synthetic graph is generated as follows We construct a graph computation namely the external contraction based 13 t he e x t e rnal DFS based by randomly selecting all nodes in SCC SCC SCC SCC SCC SCC  we apply the algorithm computation The  Finally additional random nodes and edges are added to the graph The parameters for synthetic datasets and their default values are shown in Table VIII outperforms 1PB 1PB since it cannot stop in all cases Memory Size need to be computed in Ext Ext Ext Ext EM Ext EM Ext Ext Ext Ext Ext Ext Ext Ext    3  002  For the semi-external algorithm  In our experiments we use a real large web graph and several synthetic datasets The real web graph is WEBSPAM-UK2007 4  which consists of 105,896,555 web4 barcelona.research.yahoo.net/webspam/datasets/uk2007/links   4H   8H   12H   16H   20H   24H   INF   20   40   60   80   100   Time\(hour Ext-SCC-Op   Ext-SCC                           DFS-SCC                 Largein in in in in in in 2 plus one disk block in the main memory that is Size of MassiveNumber of Massive\(a Time Vary Memory   1M   2M   3M   4M   5M   6M   7M   8M   INF   400M   600M   800M   1G   Number of I/Os Ext-SCC-Op   Ext-SCC                       DFS-SCC               iff one of the following three conditions holds 1 b I/Os Vary Memory Fig 7 WEBSPAM-UK2007 Varying Memory Size pages in 114,529 hosts in the UK domain The graph contains 105,895,908 nodes and 3,738,733,568 edges with the average degree 35 per node For synthetic data we generate 3 different kinds of datasets denoted Massive.The 4K,6K,8K,10K,12K 6K,8K,10K,12K,14K u w u G u G u G u G u G u G u G  For any  containing different sizes of and Small 327     V i i i i i d d d i i De\036nition 7.1 DFS Op Op Op Op Op Op 217 before adding  The default memory size is  In our experiments we do not show the results of  thus more iterations are needed according to the stop condition of graph contraction in 327 Semi add Datasets Exp-1 Performance on WEBSPAM-UK2007 in Algorithm 3 more nodes will be selected in id id 200K,300K,400K,500K,600K as follows DFS SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC  By considering  All the algorithms are implemented using Visual C 2005 and tested on a PC with Intel Core2 Quar 2.66GHz CPU and 3.5GB memory running Windows XP The disk block size is  according to Theorem 5.3 nodes with small degrees are removed when constructing 256 400   256 400 Default INF 327 deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg  4 w V V E V G V G   u  v V G G E E E E G where can be further reduced We rede\336ne the operator Number of SmallD M s s s i i i i i i i 1 1 1 1 1 1 u>v 4  Secondly using operator  and for each removed node  s 336rst Then we add edges among the nodes in an  We vary the memory size from                     a Time Vary Graph Size   1M   2M   3M   4M   5M   6M   7M   8M   INF   20   40   60   80   100   Number of I/Os Ext-SCC-Op   Ext-SCC                           DFS-SCC                 b I/Os Vary Graph Size Fig 6 WEBSPAM-UK2007 Varying Graph Size Percent   4H   8H   12H   16H   20H   24H   INF   400M   600M   800M   1G   Time\(hour Ext-SCC-Op   Ext-SCC                       DFS-SCC               


SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC increases the time and I/O costs for both dataset dataset The results for both Largedatasets are similar to those in the Massive When either the average   800 105 895 908 8  256  847 200 600 25 200 50 12 30 70 f I/Os SmallTo test the synthetic data we vary the memory size M   K  M M M M M M M M M M D D D D K s s s of nodes from 2 to 6 The time and I/O costs on Largedo not have signi\336cant impact on the ef\336ciency of our algorithms as long as by 20 on average for both time and I/O consumptions Fig 8\(c and Fig 8\(d show the results on Large 1 1 4  the costs for both d I/Os Vary Degree   c Time Vary Degree   25 327         Size and G M G M V V V V V V V K E G Wevary the node size decrease sharply The reason is that in order to process the graph using in all test cases to to is smaller the decrease rate is larger This is because when is smaller more iterations are needed for both to  and the time and I/O costs are shown in Fig 9\(a and Fig 9\(b respectively When to to respectively Fig 9\(g and Fig 9\(h show the time and I/O costs when varying the number of 4   s and and and and and and and and Wevary the average degree Size   Size   Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os 2H   3H   4H   5H   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 200K   400K   600K   800K   1M   1.2M   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 1H   2H   3H   4H   5H   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 200K   400K   600K   800K   1M   1.2M   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 1H   2H   3H   4H   5H   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 200K   400K   600K   800K   1M   1.2M   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 8H   12H   16H   20H   INF   25M   50M   100M   150M   200M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 1M   2M   3M   4M   5M   INF   25M   50M   100M   150M   200M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 2H   4H   6H   8H   10H   INF   2   3   4   5   6   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 400K   600K   800K   1M   1.2M   INF   2   3   4   5   6   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 2H   3H   4H   5H   INF   4K   6K   8K   10K   12K   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 400K   600K   800K   1M   INF   4K   6K   8K   10K   12K   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 2H   3H   4H   5H   INF   30   40   50   60   70   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 400K   600K   800K   1M   INF   30   40   50   60   70   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 e Time Small,andwhen increase This is because when n in Synthetic Data in Synthetic Data DFS DFS DFS Exp-5 Vary Op Op Op Op Op Op Op Op Op Op Op Op Ext  The time and I/O costs on Massiveare shown in Fig 9\(c and Fig 9\(d respectively When decrease When f I/Os Vary Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext  V  V Number in Synthetic Data c Time Large\(a Time Vary e Time Vary cannot stop in limited time in all cases Similar to the results on the real dataset in Fig 7 when dataset and Fig 8\(e and Fig 8\(f show the results on Smallconsume less than 1 hour increases the time and I/O consumptions for both consumes more than 20 hours while both are the number of nodes and the number of edges of the graph As a result the size of memory is needed thus when the memory size is dataset are shown in Fig 8\(a and Fig 8\(b respectively dataset and this is true for all the remaining test cases when varying other parameters in synthetic data In the following due to the lack of space we only show the test results on the Large and in the graph contraction phase the contraction rate decreases when the number of iterations increases since the graph becomes denser with larger number of iterations is larger and the cost on each iteration to scan and   Exp-4 Vary Average Degree in Synthetic Data from from increases the time and I/O consumptions for both and the number of outperforms outperforms cannot stop within the time limit when outperforms in all cases When the memory increases from increases the time and I/O costs for both When a Time Massive\(b I/Os Massiveis larger is larger the gap between is larger This is because when number of edges is larger more edges can be pruned by the edge reduction techniques used in increases the number of edges increases As a result more iterations are needed and larger cost is consumed in each iteration as analyzed in Exp-1 when varying the graph size size increases or the number of are not in\337uenced much As anal yzed in Section VII the key factors that in\337uence the cost of Num   Num Fig 9 Synthetic Data Largecan be directly applied on the original graph to output all                       Fig 8 Synthetic Data Vary Memory Size outperforms  and Smallincrease This is because the stop condition for graph contraction is harder to be satis\336ed when  sort nodes/edges is larger when   Fig 9\(e and Fig 9\(f show the time and I/O costs when varying the average no iteration is needed and size from SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC 1H   4H   200K   1H   200K   1H   200K   sfrom b I/Os Vary g Time Vary h I/Os Vary        218 d I/Os LargeSemi Semi Exp-2 Vary Memory Size Exp-3 Vary Node Size   


are 336xed This also explains why the results in the three datasets Massiveis a primitive operation in directed graph exploration which has been studied for both internal memory model and external memory model In the internal memory model strongly connected components of a directed graph can be computed in s for a directed graph with the assumption that the nodes of the graph cannot reside entirely in memory We overcome the de\336ciencies of the existing external    sort sort computation algorithms and propose a new two-phase algorithm with graph contraction followed by graph expansion We analyze the I/O cost of our approach and show that our algorithm can signi\336cantly reduce the number of random I/Os We propose techniques to further reduce the I/O cost of our algorithm and con\336rm the I/O ef\336ciency of our approaches using extensive experiments on both real and synthetic web scale graphs The work was supported by grant of the Research Grants Council of the Hong Kong SAR China No 418512 R EFERENCES  J  A bello A  L  Buchs baum  a nd J  W e s t brook A f unctional a pproach to external graph algorithms s of a graph Zhang et al 26 i mpro v e s uch a n a l gori t h m by constructing and maintaining a special in-memory spanning tree of the graph The semi-external algorithms 23 an d  2 6  are introduced in details in Section III Other than the problem of 336nding time based on DFS 12  A naive way to externalize the internal DFS algorithm requires s Such an algorithm may end up an in\336nite loop and cannot compute all  33\(2 2001  H  Y ildir im  V  C haoji and M  J  Z aki Grail Scalable reachability index for large graphs s repeatedly until the graph 336ts in memory then an internal memory algorithm is used to 336nd the 336nal sor DFS tree on external directed graphs several problems in the external memory model are studied in the literature Dementiev et al 14 p ro vi de an i m pl ement a t i o n o f a n e xt ernal m emory minimum spanning tree algorithm based on the ideas of 22 which performs extremely well in practice even though theoretically inferior to the algorithms of 1   1 0   A jw an i e t al 4 6  propos e i mpl e ment at i ons of e x t e rnal undi rect ed breadth-\336rst search algorithm with the idea from 18 Ul rich Meyer et al 20 21  19  des i gn and i mpl e ment pract i c al I/O-ef\336cient single source shortest paths algorithm on general undirected sparse graphs Surveys about designing I/O ef\336cient algorithms for massive graphs can be found at 24 5  X C ONCLUSIONS In this paper we study I/O ef\336cient algorithms to 336nd all  3\(1 2010  J  Hellings  G  H  F letcher  and H  H averkort Ef\336cient external-memory bisimulation on dags In  3\(1 2010  Z  Z h ang J  X Y u  L  Q in L  C hang a nd X L i n I/O e f 336 cient Computing sccs in massive graphs In scan by maintaining the list of nodes that should not be traversed using tournament trees 17 and b uf fered repos i t o ry t rees 8  respectively Despite their theoretical guarantees these algorithms are considered impractic al for general directed graphs that encountered in real applications Cosgaya-Lozano and Zeh 13 p res e nt a c ont ract i o n b as ed al gori t h m w hi ch cont ract s V M E B V B 2 are similar as stated in Exp-2 IX R ELATED W ORK Finding strongly connected components of a directed graph V G V G E G E V E E V E  14\(1 1985  T  H  Cor m en C  S tein R  L  R i v es t and C  E  L eis e r s on  2003  U Me yer a nd N Z e h I/O-ef 336c ient undirected shortest paths with unbounded edge lengths In s Both DFS based algorithm 8 and c ont ract i o n b as ed algorithm 13 a re i n t roduced i n det a i l s i n S e ct i o n III In addition to external algorithms there are semi-external algorithms for ACM Comput Surv Introduction to Algorithms IFIP TCS         Proc of ESA\22202 Proc of ESA\22206 SIAM J Comput Commun ACM Proc of SIGMOD\22213  32\(3 2002 2 A  A ggar w a l a nd J  S  V itter  T h e i nput/output com p le xity of s o r ting and related problems  31\(9 1988  A  V  A ho J  E  Hopcroft a nd J  D Ullm an I/Os Chiang et al 10 propos e a n a l gori t h m with I/O complexity  Addison-Wesley 1983 4 D  A jw ani R D e m e ntie v  and U  M e y er  A com putational s tudy of external-memory bfs algorithms In  2006  D  A jw ani a nd U Me yer   6\(1 2011  A  L  Buchs baum  M  H  G oldw a sser S Venkatasubramanian and J Westbrook On external memory graph traversal In  2002  J  S  V itter  E x ter n al m e m o r y algor ithm s and d ata s tr uctur e s   2007 7 E  A ngel R Cam p igotto a nd C L a f o r e s t  A nalys i s a nd com p ar is on of three algorithms for the vertex cover problem on large graphs with low memory capacities  1995  N  Chiba a nd T  N i s h izeki A r bor icity and s ubgr aph lis ting algor ithm s   2009  R Dem e ntie v  P  Sanders  D  S chultes  and J  F  S ibe y n E ngineering an external memory minimum spanning tree algorithm In  2012  V  K u m a r a nd E  J  Schw abe Im pro v e d a lgorithm s and d ata s tructures for solving graph problems in external memory In  2002  U  M e yer a nd V  O s ipo v  D es ign a nd im plem entation o f a pr actical i/o-ef\336cient shortest paths algorithm In  2009  U Me yer a nd N Z e h I/O-ef 336c ient undirected shortest paths In  2006  J  F  S i be yn E x ter n al connected com p onents  I n  2013 A CKNOWLEDGMENT  Algorithmic Operations Research          267        and computation which assume that all nodes of the graph can 336t in the main memory Sibeyn et al 23 propose a semi-external DFS  which can be used to 336nd all og  pages 457\320468 2012  Y  J  C hiang M T  Goodrich E  F  Gro v e  R  T am as s i a D E  V e ngrof f and J S Vitter External-memory graph algorithms In  Proc of ALENEX\22207 Proc of SIGMOD\22212 Proc of SODA\22295 Proc of SEA\22209 PVLDB Proc of ALENEX\22209 Proc of ESA\22203 PVLDB                    McGraw-Hill 2001  A  Cos g ayaL o zano a nd N  Z e h A h eur i s tic s t r o ng connecti vity algorithm for large graphs In Algorithmica LargeProc of SPAA\22202 G O O O O Algorithmics of Large and Complex Networks Data Structures and Algorithms SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC  Later Kumar and Schwabe 17 a nd B u chs b aum e t a l  8  i mprove the I/O complexity to  chapter 1 Design and Engineering of External Memory Traversal Algorithms for General Graphs Springer 2009  D  A jw ani U Me yer  and V  O s i po v  Im pro v e d e xternal m em ory b fs implementation In  2000  J  Cheng Y  K e  S  Chu and C Cheng E f 336 cient p roces s i ng of distance queries in large graphs a vertex cover approach In  2004  W  F a n J  L i  S  M a H W a ng and Y  W u Graph hom om orphis m revisited for graph matching  1996  K Mehlhorn a nd U Me yer  E xtern al-memory breadth-\336rst search with sublinear i/o In  2004  J  F  Sibe yn J  Abello a nd U Me ye r Heuristics for semi-external depth 336rst search on directed graphs In Proc of SWAT\22204  and SmallProc of SODA\22206 Proc of SODA\22200 219 Proc of SPDP\22296 Proc of SIGMOD\22212 


                  


             


 





 17  Jar r e n  A   B al d w i n  is  a  Ch i c a g o  n a t i v e  a n d  c u r r e n t l y  se r v e s a s t h e  l e a d  E l e c t r i c a l  En g i n e e r  a t  B a y  A r e a  s t a r t u p   Oc u l e v e  I n c   He  g r a d u a t e d  fr o m  t h e  U n i v e r s i t y  o f Il l i n o i s  wi t h  a  B  S   i n  2 0 0 9  an d  r ecei v ed  an  M  S   i n  El e c t r i c a l  En g i n e e r i n g  f r  St a n f o r d  U n i v e r s i t y  i n  2 0 1 2   Ja r r e n  d e v e l o p e d  h a r d w a r e  a n d  so f t w a r e  sy st e m s f o r  a  w i d e  ra n g e  o f  f i e l d s   i n c l u d i n g  s p a c e  s c i e n c e  s y s t e m s  a n d  m e d i c a l  de vi c e s  a s  a N A S A  A m es  i nt e r n i n t he  In t e l l i g e n t  S y s t e m s     1  2  3   4   5   6   7   8   9   10   11   12   13   


                        


                           


   












































     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



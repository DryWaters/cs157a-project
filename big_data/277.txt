CloseMiner Discovering Frequent Closed Itemsets using Frequent Closed Tidsets N Gourakishwar Singh and S Ranbir Singh Department of Computer Science Manipur University Imphal-795003 Manipur India gourke@rediffmail.com Anjana K Mahanta Department of Computer Science Gauhati University Guwahati-781014 Assam India anjanagu@yahoo.co.in Abstract Complete set of itemsets can be grouped into nonoverlapping clusters identiìed by closed tidsets Each cluster has only one closed itemset and is the superset of all itemsets with the same support Number of closed itemsets is identical to the number of clusters Therefore the problem of discovering closed itemsets can be considered as the 
problem of clustering the complete set of itemsets by closed tidsets In this paper we present CloseMiner a new algorithm for discovering all frequent closed itemsets by grouping the complete set of itemset s into non-overlapping clusters identiìed by closed tidsets An extensive experimental evaluation on a number of real and synthetic databases shows that CloseMiner outperforms Apriori and CHARM 1 Introduction Pasquier et al 5 found that complete s e t o f frequent itemsets includes many redundant frequent itemsets and proposed an interesting alternative complete set of frequent closed itemsets represents the set of all frequent itemsets without information loss and number of frequent closed 
itemsets is much smaller compared to the number of frequent itemsets  As a result the problem of mining frequent itemsets can be reduced to the problem of mining frequent closed itemsets This is the main motivation of this paper In this paper we focus only on discovering complete set of frequent closed itemsets rather than generating association rules 2 We present CloseMiner a new algorithm for discovering frequent closed itemsets over a large database Unlike previous algorithms 4 11 5 6 C l os eMi ner groups t h e complete set of itemsets into non-overlapping clusters and each cluster is uniquely identiìed by a closed tidset we deìned closed tidset in Section 2 All itemsets in a cluster 
are subsets of a unique maximal itemset closed itemset of the cluster The number of closed itemsets and the number of clusters are identical see Lemma 1 in subsection 3.1 Thus the problem of mining frequent closed itemsets can be deìned as the problem of mining closed tidsets.This is the main contribution of our paper Like CHARM 11 we us e the concept of IT-tree to explore both itemsets and tidsets simultaneously but search space of CloseMiner is bound by that of CHARM The rest of this paper is organized as follows In Section 2 we deìne frequent closed itemsets Section 3 describes our algorithm and Section 4 describes experimental evaluations Section 5 concludes our paper 
2 Problem Statement Let  T,I  be the data mining context where   T  I is a binary relation between transactions in T   t 1 t 2  t n  and items in I   i 1 i 2  i m  representing the input database A set X  I is called itemset and a set Y  T is called tidset  If a transaction 
t i  T contains an item x  I  it is denoted as  t i x    or alternatively as t i x  The support of an itemset X    X  is the percentage of transactions containing X in T and is said to be frequent if   X   min sup  0 where min sup is the user deìned minimum support threshold We can deìne two functions over the given data mining 
context  T,I   t 2 I  2 T t  X   y  T  x  X yx  i 2 T  2 I i  Y   x  I  y  Y yx  where X  I and Y  T  These two functions deìne a Galois connection 3 b etween po wer s e t o f trans actions s e t 2 T and items 
2 I and Calois closure operators 3 c it  X  i  t  X  in 2 I and c ti  Y  t  i  Y  in 2 T see 5 4 Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


Figure 1 Example Transaction Database Deìnition 1 An itemset X a tidset Y ssaidtobeclosed if and only if X  c it  X   Y  c it  Y   3 Algorithm Design and Implementation Having discussed frequent cl osed itemsets we describe CloseMiner for discovering frequent closed itemsets in this section We nd that set of all itemsets is a complete lattice in which join and meet are given by union and intersection respectively see 3 f or lattice theory 3.1 Clusters exploring closed tidset Complete set of itemsets in 2 I can be grouped into disjoint clusters Acluster C is deìned as set of itemsets X and Y such that t  X  t  Y   for all X and Y in 2 I Itemsets X and Y are in two different clusters if and only if t  X    t  Y   It induces that every itemset X  C has the same t  X  Wedeìne t  X  as the identiìer of the cluster and it is different for different clusters Again we also nd that each cluster is a join-semilattice i.e union of two itemsets is guaranteed to be present in the cluster.Every cluster C has an itemset Z deìned as Z   X  C X Itisthesuperset of all itemsets in C and therefore maximal itemset of C i.e join of the sublattice We observe the following properties Property 1 Let Y be an identiìer tidset of a cluster C  Then Y is closed Property 2 Let X be the maximal itemset of the cluster C  Then X is closed Lemma 1 Number of closed itemsets and number of clusters are identical Lemma 2 Let X and Y are two closed tidsets Then X  Y is also closed tidset Lemma 3 Let X 012 Y and   X    Y  Then   X  Z    Y  Z    Z  I  Figure 2 a IT-Tree and b CloseMinerês search space Frequent closed itemsets search space is exponential to  I  i.e 2 I  which requires huges space for long pattern datasets Using preìx based equivalent relation complete set of otemset can be partitioned into  X  equivalent classes where X is the preìx 1 9 Each partitioned can be processed independently which requires smaller amount of memory 3.2 CloseMiner Algorithm design Our algorithm design consists of two major steps Firstly determine initial clusters and secondly apply CloseMiner algorithm pseudo code in Figure 4 over set of initial clusters The performan ce of our algorithm depends on the nature of this closure set which in turn depends on the nature of the input database  T,I  Closure itemset of X i.e c it  X   represents all itemsets Z with X  Z  c it  X  Then t  X  is closed tidset with closed itemset c it  X   CloseMiner considers set of all such c it  X   t  X  for all  X   X  I as initial set of clusters and starts with this set Remaining clusters i.e closed tidsets can be generated from this initial set by performing intersection operations subsequently It avoids generating many nodes with unclosed itemsets and thus reduces search space and number of camparisons Figure 2 shows the search space for CloseMiner over the database shown in Figure 1 The size of search space for the case of CloseMiner is always bound by that of CHARM depending on the nature of input database  T,I   Unlike CHARM CloseMiner combines a node X  t  X  with another node Y  t  Y  with X<Y in the sequence if and only if Y  012 X  We can determine itemset Y with single masking operation on X  It minimizes the number of comparisons We arrange the itemsets and tidsets pairs in such a way that X  012 Y forall X<Y  CloseMiner performs the best in such an arrangement Whenever a new combination is Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


Figure 3 CloseMiner verses CHARM performed i.e  X  Y    t  X   t  Y   it checks for two kinds of subsumptions i.e subsumed to itemset refer CHARM 11 and subsumed to tidset  If it is not subsumed to both then CloseMiner generates a new node with the level  X  Y    t  X   t  Y  deìning a new cluster But if it is subsumed to tidset t  Z  i.e t  Z  t  X   t  Y   then Z  t  Z  is replaced by  X  Y  Z   t  Z  in both  and P i Line 10 and 11 in pseudo code Subsumed to itemset satisìes subsumed to tidset but not necessarily the reverse The main computation is performed in the Miner Extend function which returnsthe set of all frequent closed itemsets   Figure 3 shows comparisons between CloseMiner and CHARM over the example database shown in Figure 1 Despite many advantages of vertical database format 9 7  i t s u f f e rs with larg er time c o n s u m p tio n i n i n t ersectio n operations and larger memory consumption for storing tidsets We consider diffsets as one of the best option refer 11 10 for details  a nd us e a dif f s et databas e f ormat that we call as closure diffset as input We construct it as diffsets of all tidsets in the clusure vertical database with respect to Universal set of tids We need a fast subsumption checking mechanism to avoid comparing new itemset with all elements in  We have used hash table with the same hash function i.e h  X  T  t  X  T as described in CHARM 11 a nd for the same reason Algorithm Correctness CloseMiner enumerates all frequent closed itemsets since its search is based on complete lattice over all items in I  In the rst step we only prune itemsets which are subset to a closure itemset with same support CloseMiner only prunes those branches which do not have sufìcient support and which are subsumed either to an itemset or a cluster identiìer tidset After exploring complete search space and performing all possible subsumption operations each cluster has only its maximal itemset which is always closed By Lemma 2 number of closed itemsets and number of clusters are identical Hence proof Figure 4 CloseMiner pseudo code Figure 5 Datasets characteristics 4 Experimental Evaluation All experimental evaluations were performed on a 2.4GHz Intel Xeon processor PC with 1GB of RAM running RedHat Linux 8.0 For the performance comparisons we downloaded CHARM diffsetbased from http:www.cs.rpi.edu  zaki and Apriori Borgelt from FIMI03 http:ìmi.cs.helsinki  All testing datasets both real and synthetic were collected from FIMI03 which is publicly available for performan ce testing As for CloseMiner source code it is coded in C Basic concept in our source code is borrowed from CHARM because of its similarity in basic frame works Figure 5 shows the characteristics of the both real and synthetic datasets used in our experimental evaluation Figure 6 and 7 show the performance comparisons among CloseMiner Apriori and CHARM over some datasets given in Figure 5 We nd that for the datasets with less number of items and shorter patterns CloseMProceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


Figure 6 Comparisons over mushroom and chess iner outperforms both Apriori and CHARM by several orders of magnitude For example CloseMiner outperforms Apriori and CHARM by several orders of magnitude for the datasets chess connect and mushroom But for the datasets with larger number of items and longer patterns this gap becomes narrower and almost overlaps for very smaller support values It is because of the fact that CloseMiner may perform more number of subsumption operations compared to CHARM In the case of synthetic datasets T10I4D100K and T40I10D100K which has a large number of items and is sparse performance of CloseMiner and CHARM are almost same because of the above reasons 5 Conclusions In this paper we present CloseMiner a new algorithm for mining frequent itemsets Unlike previous algorithms it groups itemsets in 2 I  into disjoint clusters identiìed by a closed tidset At the same time it explores itemsets space simultaneously to generate closed itemsets Each cluster has only one closed itemsets and number of closed itemsets is identical with the number of clusters From experimental evaluations we nd that CloseMiner outperforms Apriori and CHARM It also scales linearly in the number of transactions References 1 J M  A d amo  Data mining for association rules and sequential patterns  Springer-Verlag Berlin Heidalberg New York 2001 Figure 7 Comparisons over connect and pumsb 2 R  A g r awal T  Imielin sk i an d A  S wami M i n i n g asso ciation rules between sets of items in large databases Proceeding of the ACM SIGMOD International Conference on Management of Data  pages 207Ö216 May 1993  B A Davey and P r iestley  Introduction to lattices and order  Cambridge University Press 1990 4 J  H an J P e i  and Y  Y i n Mi ni ng f r e quent pat t e r n wi t hout candidate generation Proceeding of the ACM SIGMOD International Conference on Management of Data  May 2000  N P asqui er  Y  B ast i d e R T a oui l  and L  L akhal  D i scovering frequent closed itemsets Proceeding of the 7th International Conference on Database Theory\(ICDTê99  January 1999  J P e i  J Han and R Mao Cl oset  A n e f  ci ent al gori t h m for mining frequent closed itemsets Proceeding of the ACM SIGMOD Workshop on Research Issues inData Mining and Knowledge Discovery  2000:21Ö30 May 1993  A S a v asere E  Omi eci nski  a nd S  Nav at he An ef  c i ent al gorithm for mining association rules in large databases Proceedings of the 21th International Conference on Very Large Data Bases  pages 432Ö444 1995  M  Z aki  G enerat i n g non redundant associ at i o n r ul es Proceeding of the ACM SIGKDD International Conference of Knowledge Discovery and Data Mining  August 2000  M Z aki  S cal abl e a l gori t h m f or associ at i o n m i n i ng IEEE Transaction on Knowledge and Data Engineering  12\(3\:372Ö390 May-June 2000  M Z a ki and K Gauda F ast vert i cal mi ni ng usi ng di f f sets Technical Report 01-1 Computer Science Department Rensselaer Polytechnic Institute  March 2001  M Z a ki and C  J H si ao C harm An ef  c i ent al gori t h m for closed association rule mining Technical Report 99-10 Computer Science Department Rensselaer Polytechnic Institute  October 1999 Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


other hand, will scan the database at most twice, so the impact of the maximum length of frequent items is less apparent. The impact of an increase in the number of candidate calendar-map patterns is also not as vigorous as that in applying Spatio-temporal Apriori. Hence, our method has better performance in term of execution runtime compared with Spatio-temporal Apriori                      Fig. 1. Experiment 1: Comparison of execution time between Spatio-temporal Apriori and our method  5.2. Experiment 2  We use another four data sets of different sizes in this experiment. They are L 10 F l 4 D 4M  L 10 F l 4 D 6M L 10 F l 4 D 8M\ and  L 10 F l 4 D 10M\. On average, there are 1000 transactions in each basic space-time interval. We apply different support thresholds, 0.06, 0.07, 0.08, 0.09 and 0.1 respectively, to investigate the differences of the two methods in runtime with data sets of different sizes. The match ratio threshold defined in this experiment is 0.8 Figure 2 is, under the data sets of four different sizes how the performance of the two methods will change with different support thresholds. The dotted lines are the runtime of Spatio-temporal Apriori whereas the solid line is that of our proposed new method. Figure 3 is, under the different support thresholds, the number of candidate itemsets and the discovered frequent itemsets from the four data sets with the two methods. Figure 4 is, under the different support thresholds, the number of candidate calendar-map patterns and the discovered frequent calendar-map patterns from the four data sets with the two methods. Before the experiment, we know that the number of scanning times in Spatio-temporal Apriori depends on the allowed maximum length of frequent itemsets. From the figures, we can see that when the sizes of data sets become larger, Spatio-temporal Apriori which relatively needs more number of scanning times has runtime increasing in phase with the sizes of the data sets. What is more, the phenonemun is more apparent when the support threshold becomes smaller. This is because, with a smaller support threshold, there are more candidates that need to be checked in each scanning From Figure 2, we can deduce that our method outperforms Spatio-temporal Apriori in term of execution runtime with all the data sets of different sizes              Fig. 2. Experiment 2: Comparison of execution time between Spatio-temporal Apriori and our method   Fig. 3. Experiment 2: Average number of candidate itemsets and frequent itemsets found by Spatio-temporal Apriori and our method  0.06        


Table 1. Experiment 1: The numbers of candidate and frequent calendar-map patterns as well as the maximum length of generated frequent itemsets by Spatio-temporal Apriori and our method Support threshold  0.06 0.07 0.08 0.09 0.1 Spatio-temporal Apriori 65422 40122 28344 22476 15887 Candidate Calendar-map patterns of Our Method 72987 46112 29987 24929 17842 Discovered frequent calendar-map patterns 64849 39591 28068 22212 14731 L=10;F l 3;D=6M Maximal length of frequent itemsets 7 6 6 5 5 Spatio-temporal Apriori 205891 133929 73778 48733 29274 Candidate calendar-map patterns of Our Method 212939 174211 89913 55207 34686 Discovered frequent calendar-map patterns 198446 128493 71426 46619 27754 L=10;F l 4;D=6M Maximal length of frequent itemsets 8 8 8 6 6 Spatio-temporal Apriori 56021 45431 34217 18193 6151 Candidate calendar-map patterns of Our Method 55463 46087 36559 25584 9424 Discovered frequent calendar-map patterns 52944 43429 31733 16547 5408 L=10;F l 5;D=6M Maximal length of frequent itemsets 6 6 6 6 6 Spatio-temporal Apriori 180694 122017 48051 9785 1323 Candidate calendar-map patterns of Our Method 192268 138011 83421 21125 2411 Discovered frequent calendar-map patterns 162645 105671 42126 8972 1072 L=10;F l 6;D=6M Maximal length of frequent itemsets 9 8 8 6 4                  Fig. 4. Experiment 2: Average number of candidate and frequent calendar-map patterns found by Spatio-temporal Apriori and our method  6. Future Work   First, we would like to explore other meaningful semantics of spatio-temporal association rules and extend our techniques to solve the corresponding data mining problems. Second, we would like to consider spatiotemporal patterns in data mining problems other than association rule mining, such as clustering. Third, mining spatio-temporal patterns involves investigating not only large itemset space and pattern space, but also a large amount of data collected in a long history. It is thus crucial to develop parallel or distributed algorithms for large scale data mining. It would also be interesting to devise online incremental algorithms for this problem  7. Conclusions   This work presented a new approach to solve the association rule mining problem handling the spatial and temporal dimension, i.e., the problem of spatio-temporal association rule mining. We have proposed an algorithm to discover spatio-temporal association rules that appear over any time intervals and locations in a spatio-temporal database. Existing algorithms fail to mine quite evident spatio-temporal association rules, which justifies the need of a new approach. We have also proposed a way to extend Apriori, the most well-known association rule mining algorithm, to mine spatio-temporal association rules. Experimental results have shown that our proposed new method is more efficient than the Apriori-like approach. An explanation of the experiment results is that the number of database scanning time in Apriori-like approaches increases with the maximum allowed length of frequent itemsets but our method scans the target database at most twice  8. References   A g ra w a l  R   a n d S r i ka nt  R  1994  F a s t A l go r i t hm s  for Mining Association Rules,\224 in Proc. of the 20 th Int\222l Conf. on Very Large Data Bases Santiago, Chile, pp 487\226499  2 H a d j ie le f t h e r i o u M  K o llio s  G  G u n o p u l o s D   a n d  Tsotras, V. J. \(2003\On-Line Discovery of Dense Areas in Spatio-temporal Databases,\224 in Proc. of SSTD\22203 pp 306\226324   o ddic k  J  F  a nd S p iliopoulou, M 1999\A Bibliography of Temporal, Spatial and Spatio-Temporal Data Mining Research,\224 in SIGKDD Explorations 1\(1 pp. 34\22638   s o uka t o s  I a nd G u n o pul o s  D   2001 223 E f f i c i e n t  Mining of Spatiotemporal Patterns,\224 in Proc. of SSTD\22201  pp.425\226442  


en g th Percentage of new items e-commerce WUT Figure 4. The percentage of pages for which new items were added for direct rankings In our tests the contribution of pages with too short direct ranking lists to all pages was examined, Fig. 5. For the smallest required length  2 the percentage of too short rankings was similar for e-commerce and WUT  4.2 and 11%, respectively \(Fig. 5 0 20 40 60 80 100 0 5 10 15 20 25 30 35 40 45 50 Required length of recommendation list P er ce n ta g e o f p ag es WUT E-commerce Figure 5. Contribution of pages with too short rankings lists based on direct rules within pages with any ranking Proceedings of the 2005 5th International Conference on Intelligent Systems Design and  Applications \(ISDA  05 0-7695-2286-06/05 $20.00  2005 IEEE In general, the average percentage of pages with too short rankings was quite prominent. Our solution to this problem is the extension of direct ranking lists with indirect and complex ones. We tested the contribution of pages with too short rankings which were successfully extended with complex rules within all pages with short rankings. In order to do this, we took the number of pages with too short direct rankings for which complex ranking list was longer than direct one, for a required list length and next we divided it by the total number of pages with too short direct rankings. The obtained results were very similar for indirect and complex rules. They show how much short direct ranking lists can be extended with indirect or complex ones \(Fig. 6 percentage started from 97.5% for e-commerce and 70.1 for WUT \(for 2-item rankings commerce and 95.1% for WUT This definitely emphasizes the usefulness of complex and in consequence indirect association rules 60 70 80 90 100 0 5 10 15 20 25 30 35 40 45 50 Required length of recommendation list P er ce n 


n t WUT E-commerce Figure 6. Contribution of pages with too short direct ranking lists extended with complex rules within all pages with too short rankings 7.4. Do Recommendation Ranking Lists only Confirm Existing Hyperlinks A vital question one can ask is whether recommendation ranking lists only confirm existing hyperlinks or maybe they add new knowledge as well. If all they did was confirm the existing structure of hyperlinks on a site the recommendations offered to a user might not be interesting to them In order to test if ranking lists add anything new, the content of the WUT site was downloaded. From it information about all hyperlinks on each page was extracted Having the structure of the site we were able to assess recommendation lists in the following way: the number of common items in hyperlink sets and ranking lists cut at various lengths was divided by the ranking length i.e. the required length or the actual length if it was smaller than the required length. Such calculations were performed for direct, indirect and complex recommendation lists, Fig. 7 The results for direct, indirect and complex rankings for very short lists \(1 and 2 items 27.1%, 4.6% and 11.7% respectively for 1 item. The same is true for 20-item long lists: 19.9%, 19% and 11.7% respectively. This indicates that for very short indirect and complex rankings \(up to 2 pages 20 items and more existing hyperlinks and add new potentially useful knowledge 0 5 10 15 20 25 30 1 2 3 5 10 20 Ranking lenght P er ce n ta g e o f ra n k in g i te m s Direct Indirect Complex Figure 7. The average percentage of ranking items covered by hyperlinks at the WUT site 7.5. Assessment of Hyperlinks by Association Rules Another application of direct, indirect and complex rules may be the assessment of hyperlinks on a site. We can test whether the hyperlinks on a page have been 


can test whether the hyperlinks on a page have been placed appropriately by analyzing significant navigational patterns \(association rules In our experiments the percentage of hyperlinks confirmed by rules was calculated by dividing the number of common items in hyperlink sets and whole ranking lists for a given page, by the number of hyperlinks on the page separately for direct, indirect and complex rules \(Fig. 8 Note that the number of hyperlinks was put in the denominator as opposed to calculations in section 7.4 where it was ranking length 48 89%87 0 20 40 60 80 100 direct indirect complex Figure 8. The average percentage of all hyperlinks confirmed by rules Proceedings of the 2005 5th International Conference on Intelligent Systems Design and  Applications \(ISDA  05 0-7695-2286-06/05 $20.00  2005 IEEE The average percentage of hyperlinks confirmed by direct rules amounted to only 48%, probably because there were too few of them. Indirect and complex rules, on the other hand, confirmed many more hyperlinks  87% and 89%, respectively, due to their larger quantity. These relatively great values that we received may have resulted from the enormous differences between the average number of hyperlinks on a page  10 and the average ranking length: 51, 177, 180 for direct, indirect and complex rules respectively. Concluding, indirect and complex rules appear to be better at assessing the usefulness of hyperlinks compared to direct rules Note that in any case at least 11% of hyperlinks were not confirmed by any rule, so they may be recommended to be removed from the content of pages 8. Conclusions and future work Complex rules combining both direct and indirect rules usually increase the length of rankings compared to those based on direct associations. This helps overcome the problem of a multitude of pages with too short rankings Fig. 5 quested ranking length \(Fig. 6 rules substantially change the order of ranking lists \(Fig. 2 and 3 greater extent only confirm hyperlinks existing on web pages compared to lists extracted from complex rules, for short and long ranking lengths \(Fig. 7 of rules, especially indirect and complex ones, can be useful for the assessment of hyperlinks Concluding, far more diverse indirect rules can significantly improve potential value of recommendation. Nevertheless, to confirm the usefulness of indirect rules for end users, some tedious tests with their participation are required Acknowledgements The authors are indebted to thank Marcin Pilarczyk for providing cleansed data about hyperlinks on WUT pages 9. References 1] Agrawal R., Imieli?ski T., Swami A.: Mining association rules between sets of items in large databases. ACM SIGMOD Int. Conference on Management of Data, ACM Press 1993 2] Boley D., Gini, M., Gross, R., Han, E.H., Hastings, K Karypis, G., Kumar, V., Mobasher, B., Moorey, J.: Document Categorization and Query Generation on the World Wide Web Using WebACE. Artificial Intelligence Review 


Wide Web Using WebACE. Artificial Intelligence Review 13 \(5-6 1999 3] Cho Y.H., Kim J.K., Kim S.H.: A personalized recommender system based on web usage mining and decision tree induction. Expert Systems with Applications 23 \(3 2002 4] Chun J., Oh J.-Y., Kwon S., Kim D.: Simulating the Effectiveness of Using Association Rules for Recommendation Systems. AsiaSim 2004. LNCS 3398, Springer Verlag 2005 5] G  ry M., Haddad M.H.: Evaluation of web usage mining approaches for user's next request prediction. WIDM 2003 ACM Press \(2003 6] Ha S.H.: Helping Online Customers Decide through Web Personalization. IEEE Intelligent Systems 17 \(6 2002 43 7] Hamano S., Sato M.: Mining Indirect Association Rules ICDM 2004. LNCS 3275, Springer Verlag \(2004 8] Kazienko P.: IDARM - Mining of Indirect Association Rules. IIS: IIPWM  05. Advances in Soft Computing Springer Verlag \(2005 9] Kazienko P.: Multi-agent Web Recommendation Method Based on Indirect Association Rules. KES  2004. Part II LNAI 3214, Springer Verlag \(2004 10] Kazienko P., Product Recommendation in E-Commerce Using Direct and Indirect Confidence for Historical User Sessions. DS  04. LNAI 3245, Springer Verlag \(2004 269 11] Kazienko P., Kiewra M.: Link Recommendation Method Based on Web Content and Usage Mining. IIS: IIPWM  03 Advances in Soft Computing, Springer Verlag \(2003 534 12] Kazienko P., Kiewra M., Personalized Recommendation of Web Pages. Chapter 10 in: Nguyen T. \(ed Technologies for Inconsistent Knowledge Processing. Advanced Knowledge International, Adelaide, South Australia 2004 13] Kazienko P., Kolodziejski P.: WindOwls - Adaptive System for the Integration of Recommendation Methods in Ecommerce. AWIC  05, LNAI, Springer Verlag \(2005 14] Kazienko P., Matrejek M.: Adjustment of Indirect Association Rules for the Web. SOFSEM 2005. LNCS 3381 Springer Verlag \(2005 15] Kendall, M. G.: Rank correlation methods. London: Charles Griffin &amp; Company, Ltd., London \(1948 16] Lu Z., Yao Y., Zhong N.: Web Log Mining. Chapter 9 in Zhong N., Liu J., Yao Y. \(eds Berlin, New York \(2003 17] Mobasher B., Cooley R., Srivastava J.: Automatic Personalization Based on Web Usage Mining. Communications of the ACM, 43 \(8 2000 18] Tan P.-N., Kumar V.: Mining Indirect Associations in Web Data. WEBKDD 2001. LNCS 2356, Springer Verlag \(2002 145-166 19] Tan P.-N., Kumar V., Srivastava J.: Indirect Association Mining Higher Order Dependencies in Data. PKDD 2000 LNCS 1910, Springer Verlag \(2000 20] Wan Q., An A.: Efficient Mining of Indirect Associations Using HI-Mine. AI 2003. LNCS 2671, Springer Verlag 2003  221 21] Wang D., Bao Y., Yu G., Wang G.: Using Page Classification and Association Rule Mining for Personalized Recommendation in Distance Learning. ICWL `02. LNCS 2436 Springer Verlag \(2002 22] Yang H., Parthasarathy S.: On the Use of Constrained Associations for Web Log Mining. WEBKDD 2002. LNCS 2703 Springer Verlag \(2003  118 Proceedings of the 2005 5th International Conference on Intelligent Systems Design and  Applications \(ISDA  05 0-7695-2286-06/05 $20.00  2005 IEEE pre></body></html 


pre></body></html 


lossless frequent patterns representations with borders. In practice, they are also much more concise than representations based on closed itemsets and approximate representations. In this paper, we offered three methods of deriving an upper bound on the length of sets in such representations. We proved that the upper bound on the length of a longest generalized disjunction-free set depends logarithmically on the number of records in the database. The obtained result is of high importance as it guarantees that any generalized disjunction-free set representation for all patterns \(both frequent and infrequent scans, where n is the number of records in the database irrespectively how strong or weak correlations among items in the database are and irrespectively of the lengths of records and number of distinct items The modifications of the basic estimation take into account the support threshold of the representation to be found or, additionally, the information on the length of longest sets of the representation already calculated for a higher support threshold. Though these estimations are more accurate than the basic one, they are still quite rough. Further improvements of the quality of estimating the length of longest itemsets in generalized disjunctionfree representations is subject to further research References 1] R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, A.I Verkamo  Fast Discovery of Association Rules   Advances in Knowledge Discovery and Data Mining AAAI, CA, 1996 2] J. Baptiste, J.-F. Boulicaut  Constraint-Based Discovery and Inductive Queries: Application to Association Rule Mining  Pattern Detection and Discovery, Springer London, UK, September 2002, pp. 110-124 3] E. Baralis, S. Chiusano, P. Garza  On Support Thresholds in Associative Classification  SAC, ACM, Taipei Taiwan, March 2004, pp. 553-558 4] Y. Bastide, N. Pasquier, R. Taouil, G. Stumme, L. Lakhal  Mining Minimal Non-redundant Association Rules Using Frequent Closed Itemsets  Computational Logic, 2000 pp. 972  986 5] J.-F. Boulicaut, A. Bykowski, C. Rigotti  Approximation of Frequency Queries by Means of Free-Sets  PKDD Springer, Lyon, France, September 2000, pp. 75-85 6] A. Bykowski, C. Rigotti  A Condensed Representation to Find Frequent Patterns  PODS, ACM, Santa Barbara USA, May 2001, pp. 267-273 7] T. Calders, Axiomatization and Deduction Rules for the Frequency of Itemsets, Ph.D. Thesis, University of Antwerp, 2003 8] T. Calders, B. Goethals  Mining All Non-derivable Frequent Itemsets  PKDD, Springer, Helsinki, Finland August 2002, pp. 74?85 9] T. Calders, B. Goethals  Minimal k-free Representations of Frequent Sets  ECML/PKDD, Springer, CavtatDubrovnik, Croatia, September 2003, pp. 71-82 10] J. Han, M. Kamber, Data Mining: Concepts and Techniques, Morgan Kaufmann Publishers, 2000 11] S.K. Harms, J. Deogun, J. Saquer, T. Tadesse  Discovering Representative Episodal Association Rules from Event Sequences Using Frequent Closed Episode Sets and Event Constraints  ICDM, IEEE Computer Society, San Jose, California, USA, November-December 2001, pp. 603  606 12] M. Kryszkiewicz  Closed Set Based Discovery of Representative Association Rules  IDA, Springer Cascais, Portugal, September 2001, pp. 350-359 13] M. Kryszkiewicz  Concise Representation of Frequent Patterns based on Disjunction  free Generators  ICDM IEEE Computer Society, San Jose, California, USA 


IEEE Computer Society, San Jose, California, USA November-December 2001, pp. 305  312 14] M. Kryszkiewicz M  Inferring Knowledge from Frequent Patterns  Soft-Ware, Springer, Belfast, Northern Ireland April 2002, pp. 247  262 15] M. Kryszkiewicz  Concise Representations of Association Rules  Pattern Detection and Discovery, Springer London, UK, September 2002, pp. 92-109 16] M. Kryszkiewicz, Concise Representation of Frequent Patterns and Association Rules, Habilitation Thesis Publishing House of Warsaw University of Technology 2002 Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE 17] M. Kryszkiewicz  Reducing Infrequent Borders of Downward Complete Representations of Frequent Patterns  Proc. of The First Symposium on Databases Data Warehousing and Knowledge Discovery, Scientific Publishers OWN, Baden-Baden, Germany, July, 2003, pp 29-42 18] M. Kryszkiewicz  Closed Set Based Discovery of Maximal Covering Rules  International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems Vol. 11. World Scientific Publishing Company, Singapore September 2003, pp. 15-29 19] M. Kryszkiewicz  Reducing Borders of k-Disjunction Free Representations of Frequent Patterns  SAC, ACM Taipei, Taiwan, March 2004, pp. 559  563 20] M. Kryszkiewicz  Reducing Main Components of k-Disjunction Free Representations of Frequent Patterns   Proc. of IPMU  2004 \(in print 21] M. Kryszkiewicz, M. Gajek  Concise Representation of Frequent Patterns based on Generalized Disjunction  Free Generators  PAKDD, Springer, Taipei, Taiwan, May 2002, pp. 159-171 22] M. Kryszkiewicz, M. Gajek  Why to Apply Generalized Disjunction-Free Generators Representation of Frequent Patterns  ISMIS, Springer, Lyon, France, June 2002, pp 383  392 23] M. Kryszkiewicz, H. Rybi?ski, M. Gajek  Dataless Transitions between Concise Representations of Frequent Patterns  Journal of Intelligent Information Systems JIIS Netherlands, 2004, pp. 41-70 24] N. Pasquier, Data mining: Algorithmes d  extraction et de R  duction des R  gles d  association dans les Bases de Donn  es, Th  se de Doctorat, Universit  Blaise Pascal   Clermont  Ferrand II, 2000 25] N. Pasquier, Y. Bastide, R. Taouil, L. Lakhal  Efficient Mining of Association Rules Using Closed Itemset Lattices  Journal of Information Systems, Vol. 24, No. 1 1999, pp. 25  46 26] N. Pasquier, Y. Bastide, R. Taouil, L. Lakhal  Discovering Frequent Closed Itemsets for Association Rules  ICDT, Springer, Jerusalem, Israel, January 1999 pp. 398  416 27] J. Pei, G. Dong, W. Zou, J. Han  On Computing Condensed Frequent Pattern Bases  ICDM, IEEE Computer Society, Maebashi City, Japan, December 2002 pp. 378-385 28] V. Phan-Luong V  Representative Bases of Association Rules  ICDM, IEEE Computer Society, San Jose California, USA, November-December 2001, pp. 639-640 29] A. Savinov  Mining Dependence Rules by Finding Largest Itemset Support Quota  SAC, ACM, Taipei Taiwan, March 2004, pp. 525-529 30] M.J. Zaki, C.J. Hsiao  CHARM: An Efficient Algorithm for Closed Itemset Mining  SIAM, Arlington, 2002 


for Closed Itemset Mining  SIAM, Arlington, 2002 Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE pre></body></html 


                                                  S J       


                                                      


                         L A                                        


          L A  Table 7. Table of Granules at left-hand-side is isomorphic to  at right- hand-side: By Theorem  3.1 one can ?nd patterns in either table as a single generalized concept  Internal points  are:[4]\(1, 1, 0, 0 tions; [5]\(0, 1, 1, 0  0, 1, 0, 1  0, 1, 1, 1  1, 1 1, 0  1, 1, 0, 1  1, 0, 1, 1 11]\(1, 1, 1, 1 form and simplify them into disjoint normal forms 1  T E N    S J    T E N    S J 2  T W E N T Y    L A    T H I R T Y   A 3  T W E N T Y      T H I R T Y   A 4  T W E N T Y            L A 5  T E N      T W E N T Y    L A    T E N    T W E N T Y   A   S J    T W E N T Y   A      T H I R T Y    L A     Y 7  T E N      T W E N T Y      T H I R T Y   L A    T E N   L A    S  J   A 8  T W E N T Y      T E N      T W E N T Y    L A    T E N   T W E N T Y      T H I R T Y 9  T W E N T Y    N Y    T E N    S J    T H I R T Y    L A      T W E N T Y    L A  1 0  T W E N T Y    N Y    T W E N T Y    L A    T H I R T Y   A    J 1 1  T W E N T Y          T W E N T Y    L A   T H I R T Y    L A    a l l If the simpli?ed expression is a single clause \(in the original symbols non-generalized the following associations 1   T E N     S J    T E N    S J  2. SJ   J 4   L A    T W E N T Y    L A    T H I R T Y    6 Conclusions Data, patterns, method of derivations, and useful-ness are key ingredients in AM. In this paper, we formalize the current state of AM: Data are a table of symbols. The patterns are the formulas of input symbols that repeat. The method of derivations is the most conservative and reliable one, namely, mathematical deductions. The results are somewhat surprising 1. Patterns are properties of the isomorphic class, not an individual relation - This implies that the notion of patterns may not mature yet and explains why there are so many extracted association rules 2. Un-interpreted attributes \(features can be enumerated 3. Generalized associations can be found by solving integral linear inequalities. Unfortunately, the number is enormous. This signi?es the current notion of data and patterns \(implied by the algorithms 4. Real world modeling may be needed to create a much more meaningful notion of patterns. In the current state of AM, a pattern is simply a repeated data that may have no real world meaning. So we may need to introduce some semantics into the data model [12],[10],[11 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE References 1] R. Agrawal, T. Imielinski, and A. Swami  Mining Association Rules Between Sets of Items in Large Databases  in Proceeding of ACM-SIGMOD international Conference on Management of Data, pp. 207216, Washington, DC, June, 1993 


216, Washington, DC, June, 1993 2] Richard A. Brualdi, Introductory Combinatorics, Prentice Hall, 1992 3] A. Barr and E.A. Feigenbaum, The handbook of Arti?cial Intelligence, Willam Kaufmann 1981 4] Margaret H. Dunham, Data Mining Introduction and Advanced Topics Prentice Hall, 2003, ISBN 0-13088892-3 5] Fayad U. M., Piatetsky-Sjapiro, G. Smyth, P. \(1996 From Data Mining to Knowledge Discovery: An overview. In Fayard, Piatetsky-Sjapiro, Smyth, and Uthurusamy eds., Knowledge Discovery in Databases AAAI/MIT Press, 1996 6] H Gracia-Molina, J. Ullman. &amp; J. Windin, J, Database Systems The Complete Book, Prentice Hall, 2002 7] T. T. Lee  Algebraic Theory of Relational Databases  The Bell System Technical Journal Vol 62, No 10, December, 1983, pp.3159-3204 8] T. Y. Lin  Deductive Data Mining: Mathematical Foundation of Database Mining  in: the Proceedings of 9th International Conference, RSFDGrC 2003 Chongqing, China, May 2003, Lecture Notes on Arti?cial Intelligence LNAI 2639, Springer-Verlag, 403-405 9] T. Y. Lin  Attribute \(Feature  The Theory of Attributes from Data Mining Prospect  in: Proceeding of IEEE international Conference on Data Mining, Maebashi, Japan, Dec 9-12, 2002, pp. pp.282-289 10] T. Y. Lin  Data Mining and Machine Oriented Modeling: A Granular Computing Approach  Journal of Applied Intelligence, Kluwer, Vol. 13, No 2, September/October,2000, pp.113-124 11] T. Y. Lin, N. Zhong, J. Duong, S. Ohsuga  Frameworks for Mining Binary Relations in Data  In: Rough sets and Current Trends in Computing, Lecture Notes on Arti?cial Intelligence 1424, A. Skoworn and L Polkowski \(eds 12] E. Louie,T. Y. Lin  Semantics Oriented Association Rules  In: 2002 World Congress of Computational Intelligence, Honolulu, Hawaii, May 12-17, 2002, 956961 \(paper # 5702 13  The Power and Limit of Neural Networks  Proceedings of the 1996 EngineeringSystems Design and Analysis Conference, Montpellier, France, July 1-4, 1996 Vol. 7, 49-53 14] Morel, Jean-Michel and Sergio Solimini, Variational methods in image segmentation : with seven image processing experiments Boston : Birkhuser, 1995 15] H. Liu and H. Motoda  Feature Transformation and Subset Selection  IEEE Intelligent Systems, Vol. 13 No. 2, March/April, pp.26-28 \(1998 16] Z. Pawlak, Rough sets. Theoretical Aspects of Reasoning about Data, Kluwer Academic Publishers, 1991 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207ñ216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intíl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intíl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 






A Support-Based Vertical Partitioning Method for Database Design Lisbeth Rodríguez and Xiaoou Li Department of Computer Science CINVESTAV-IPN Mexico D.F Mexico lisbethr@computacion.cs.cinvestav.mx lixo@cs.cinves tav.mx Abstract In association rule mining support is a measure of association between two sets of items which indicates the r elative occurrence of both sets within the overall set of transactio ns In this paper we propose a support-based vertical partitio ning method that is easy to implement and can nd an optimal vertic al partitioning scheme We present several experimental resu lts to clarify the validness of the proposed method Index Terms Association rules databases data mining support measure vertical partitioning I I NTRODUCTION Vertical partitioning is a design technique used for query optimization in databases this is achieved by grouping the attributes accessed together by the queries as vertical fragm ents Vertical partitioning is an NP-hard problem 1  T h e r e f o r e  the use of heuristics is required to nd a solution Afnity is a widely employed measure in heuristic vertical partitio ning techniques 2   3   i t m e a s u r e s h o w t w o a t t r i b u t e s a r e a c c e ssed together by the queries togetherness The main disadva ntage of this measure is that it only involves two attributes and hence it does not show the togetherness of more than two attributes 4  Data mining is a process for extracting non-trivial implic it previously unknown and potentially useful information fro m data in databases 5  O n e o f t h e m o s t i m p o r t a n t p r o b l e m s in data mining is the discovery of association rules for larg e databases this is called association rule mining Associa tion rules are a simple and natural class of database regularitie s The purpose of association rule mining is to discover the co-ocurrence associations among data in large databases i e to nd items that imply the presence of other items in the same transaction 6  I t s f o r m a l d e  n i t i o n i s  g i v e n a  n i t e multiset of transactions D  the problem of mining association rules is to generate all association rules that have support and condence at least equal to the user-specied minimum suppo rt threshold  min-sup  and minimum condence threshold  minconf  respectively 7  Gorla and Betty 8 d e v e l o p e d a n a s s o c i a t i o n r u l e b a s e d vertical partitioning algorithm One disadvantage of this algorithm is that it is necessary to specify minimum support and condence threshold in order to nd the fragments and it is difcult to set the suite value of such thresholds to obtain t he optimal solution In this paper we use support as a global afnity measure between attributes and we present a vertic al partitioning algorithm called SVP that takes an Attribut e Usage Matrix AUM as input and also needs a minimum support threshold  min-sup  but it is automatically determined by the algorithm SVP consists of three steps in the rst ste p an Attribute Support Matrix ASM is obtained from the AUM  in the second step the min-sup value is determined and nally the optimal fragments are found using the Connection Based Partitioning Algorithm CBPA 9  The rest of the paper is organized as follows in Section II we give an introduction of association rule and its measures  In Section III we propose the support-based vertical partitio ning method Section IV presents several experiments to show the efciency of the proposed method Finally Section V is our conclusion II A SSOCIATION RULES A Introduction Given a set of transactions D  where each transaction contains a set of items an association rule is dened as an expression X  Y  where X and Y are sets of items and X  Y   The rule implies that the transactions of the database which contain X tend to contain Y 6  Support and condence are two measures of association The support factor indicates the relative occurrence of bot h X and Y within the overall set of transactions and is dened as the ratio of the number of tuples satisfying both X and Y over the total number of tuples The condence factor is the probability of Y given X and is dened as the ratio of the number of tuples satisfying both X and Y over the number of tuples satisfying X  The support factor indicates the frequencies of the occurring patterns in the rule and the condence facto r denotes the strength of implication of the rule 5  Let N to be the total number of tuples and  A  to be the number of tuples containing all items in the set A  Dene               1                     2 


n r\n                          3 The problem is to nd all the association rules satisfying user-specied minimum support and minimum condence constraints that hold in a given database 6  B Association Rule-Based Vertical Partitioning Gorla and Betty 8 p r o p o s e d a n a s s o c i a t i o n r u l e b a s e d v e r tical partitioning method This consists of four steps 1 F irst it has to discover large itemsets which are the combinations of attributes that have support above the predened minimum support  min-sup  The Apriori algorithm 10 i s a d a p t e d f o r this step 2 the algorithm lters the large itemsets i.e large itemsets with condence value smaller than the predetermin ed minimum condence  min-conf  are discarded 3 it derives the partitions selecting the disjoint large itemset In thi s step the algorithm generates several vertical fragmentation sc hemes and 4 the vertical partitioning schemes are evaluated to n d the optimal partitioning scheme The main disadvantage of this algorithm is that it can nd different vertical partitioning schemes using differe nt minsup and min-conf values Finding the optimal scheme implies setting the suite value of such thresholds but any guidelin e is given to nd the correct values Even with the suite minsup and min-conf thresholds the algorithm will nd several partitioning schemes and it is necessary to evaluate them us ing a cost function in order to get the optimal scheme It would be more efcient that the algorithm automatically could set the values of the thresholds this would delete the complexity o f determining both the adequate value of the thresholds and th e optimal vertical partitioning scheme C Afnity-Based Support Measure Vertical partitioning algorithms require an Attribute Usage Matrix AUM as input Table I shows an AUM of a relation with six attributes and four queries 11  T h e 0  1 e n t r i e s i n the AUM show whether or not a given attribute is used by a given query and the access column shows for each query the frequency of access to attributes per unit time period e.g a day Since vertical partitioning places in one fragment those attributes usually accessed together there is a need for som e measure that would dene more precisely the notion of togetherness This measure is the afnity of attributes whi ch indicates how closely related the attributes are 12  For a given pair of attributes   and    of a relation schema R        that is accessed by a set of queries Q={q  q    let acc  to be the total access of a query q  and use\(q  a   1 when query q  accesses attribute    afnity is dened as                    n        n   n\n  4 TABLE I A TTRIBUTE U SAGE M ATRIX 1 AUM-1 Queries/Attributes             Access   0 1 1 1 0 0       1 1 0 0 1 1       0 0 0 1 1 1       0 1 1 0 0 0     The main disadvantage of afnity is that it does not show the togetherness when more than two attributes are involv ed Hence this measure has no bearing on the afnity measured with respect to the entire cluster 4  T o s o l v e t h i s p r o b l e m  we dene an afnity-based support factor for vertical partiti oning as follows                       n\n  5 Here support       shows the probability of accessing both attributes i and j with respect to all the accesses of the queries These values are used in a support-based vertical partition ing algorithm to nd an optimal vertical partitioning scheme III T HE S UPPORT B ASED V ERTICAL P ARTITIONING A LGORITHM SVP Algorithm 1 shows the procedure of SVP it has three steps generating the Attribute Support Matrix ASM sett ing the value of the threshold and getting the optimal vertical partitioning scheme VPS Algorithm 1 SVP input Total access frequency of queries total_acc AUM Attribute Usage Matrix output Optimal vertical partitioning scheme VPS begin Step 1 Generating the ASM getASM\(total_acc AUM ASM generate the ASM from AUM using equation 5 Step 2 Setting the threshold getSVM\(ASM,SVM get the SVM from ASM quick_sort\(SVM sort the SVM setThreshold\(SVM min-sup nd the suite value of min-sup Step 3 Getting the optimal VPS CBPA\(ASM min-sup VPS get the optimal VPS using the found value of min-sup  end SVP A Generating the ASM In the rst step ASM is obtained using the AUM of the relation to be fragmented and the variable total_acc which is the summation of the access frequency of all queries this is 


presented in Algorithm 2 ASM is a symmetric n  n matrix  n is the number of attributes of the relation Each element of ASM is one of the support measures dened in equation 5 Algorithm 2 getASM input AUM attribute usage matrix total_acc output ASM Attribute Support Matrix begin support  0 for i  1 to n  1 do for k from 1 to q by 1 do if AUM      then support  acc  total_acc ASM     ASM    support for j  i+1 to n  1 do if AUM       AUM      then support  acc  total_acc ASM     ASM    support ASM     ASM    end_if end_for end_if end_for end_for end getASM Table II shows the ASM from AUM of Table I Each value gives us the percentage of the queries which contains two attributes together and the diagonal gives us the percentag e of the queries which contains an attribute For example the 57 of the queries uses the attribute   ASM     in the 36 of the queries the attribute   is used with the attributes   and   ASM     ASM     and in the 21 with the attributes   and   ASM     ASM     B Setting the Value of the Threshold We use the algorithm Connection-Based Partitioning Algorithm CBPA 9 t o g e t t h e f r a g m e n t s  T h i s a l g o r i t h m  n d s fragments by trying to connect attributes Two attributes b elong to the same fragment only if they are connected i.e if the value of support of such attributes is greater than or equal t o min-sup  So it is necessary to nd the suite values of min-sup to get the optimal vertical partitioning scheme CBPA does not nd the optimal solution if most at least half of the attributes can be classied as connected attrib utes which means that the min-sup value must be carefully choosen  Therefore we determined that the suite value of min-sup must be the support value for the 71 to the 75 of data To set the value of the threshold we rst use the Algorithm 3 which gives us a Support Value Matrix SVM from the ASM Using this algorithm we get a 2  number matrix  number is the number of different support values of a ASM which stores both the different support values in the ASM and their occurrences In the example getSVM Algorithm 3 takes as input the ASM of Table II and generates the SVM presented in Table TABLE II A TTRIBUTE S UPPORT M ATRIX 1 ASM-1 FROM AUM-1               0.14 0.14 0 0 0.14 0.14   0.14 0.64 0.5 0.21 0.14 0.14   0 0.5 0.5 0.21 0 0   0 0.21 0.21 0.57 0.36 0.36   0.14 0.14 0 0.36 0.5 0.5   0.14 0.14 0 0.36 0.5 0.5 Algorithm 3 getSVM input ASM Attribute Support Matrix output SVM Support Value Matrix begin number  0 ban  0 for i  1 to n  1 do for j from 1 to n by 1 do for s from 1 to number by 1 do if ASM     SVM    then SVM r    SVM r    ban  1 s  number end-if end_for if ban=0 then number  number+1 SVM     ASM    SVM r    1 end_if ban  0  end_for end_for end getSVM III Here number 7 because we have seven different support values in ASM so getSVM give us a 2   matrix the rst row of the matrix Support Value presents the different suppor t values an the second row Ocurrence stores the number of times that each value appears in ASM TABLE III S UPPORT V ALUE M ATRIX 1 SVM-1 FROM ASM-1 1 2 3 4 5 6 7 Support Value SV 0.14 0 0.64 0.5 0.21 0.57 0.36 Occurrence OC 11 8 1 7 4 1 4 The next step of the proposed method is sorting the SVM in increasing order using the algorithm quick-sort we use t his algorithm because is one of the fastest and simplest sorting algorithms it has an average running time of   n log n  13  Table IV shows the SVM after applying quick sort To nd the suite value of min-sup we use the Algorithm 4 First the occurrences of each value second row of SVM are accumulated and are stored in the third row of SVM Accumulation This is shown in Table V Next the total number of data  n   where n is the number 


TABLE IV SORTED SVM-1 1 2 3 4 5 6 7 Support Value SV 0 0.14 0.21 0.36 0.5 0.57 0.64 Occurrence OC 8 11 4 4 7 1 1 Algorithm 4 setThreshold input SVM Support Value Matrix output min-sup begin accum  0 for i  1 to number  1 do accum  accum  SVM    SVM     accum end_for total_number  SVM    percentage  total_number  0.75 percentage2  total_number  0.71 for i from 1 to number by 1 do if SVM     percentage then if SVM       percentage2 then min-sup  SVM      i  number else min-sup  SVM    i  number end_if end_if end_for end setThreshold TABLE V SVM-1 COMPLETE 1 2 3 4 5 6 7 Support Value SV 0 0.14 0.21 0.36 0.5 0.57 0.64 Ocurrence OC 8 11 4 4 7 1 1 Accumulation AC 8 19 23 27 34 35 36 of attributes of the relation in the example n=6  so the total number of data is 36 is multiplied by 0.75 and 0.71 respectively In the example this gives us 27 and 25.56 The n the third row of SVM Accumulation is scanned to nd a value greater than or equal to the rst value 27 in the example when such value is found SVM     the previous value is evaluated if it is greater or equal to the second value 25.5 6 in the example then min-sup is equal to the SV of that column otherwise min-sup is equal to the SV of the other column In Table V we can see that SVM    27 but SVM    25.56 so min-sup 0.36 C Getting the optimal VPS Finally to get the optimal VPS we use the algorithm CBPA the input to this algorithm is the ASM and the threshold minsup determined in the previous step In the example the VPS obtained with min-sup=0.36 is a   a  a   a  a  a   and this is the optimal VPS generated by Son and Kim 11 u s i n g their Adaptable Vertical Partitioning AVP algorithm Algorithm 5 CBPA input ASM Attribute Support Matrix min-sup output VPS begin initialize an array VPS of n elements with 0   1 for i  1 to n  1 do if VPS  0 then VPS    for j from i to n by 1 do if ASM   min-sup and VPS  0 then VPS    end_for      end-if end-for  CBPA IV E XPERIMENTS In this section we show several experimental results to evaluate the efciency of the SVP algorithm For the rst experiment consider the AUM of Table VI which was used as an example by Gorla and Betty 8  Table VII shows the SVM In this case the values of the threshold found using the algorithm setThreshold was minsup 0.6 because SVM    36*0.75=27 and SVM    36*0.71=25.56 the optimal VPS generated was a   a  a   a  a   a   and this is the optimal solution found by Gorla and Betty TABLE VI A TTRIBUTE U SAGE M ATRIX 2 AUM-2 queries/attributes             Access   1 1 0 0 1 0       0 1 0 0 1 0       1 0 0 1 0 1       1 1 1 1 1 1       1 1 1 1 1 1     TABLE VII SVM-2 COMPLETE 1 2 3 4 Support Value SV 0.3 0.4 0.6 0.7 Occurence OC 19 4 8 5 Accumulation AC 19 23 31 36 We used the example of Table VIII as second experiment which was used in 1  T a b l e I X s h o w s t h e S V M o f t h i s example The value determined for the threshold by the algorithm setThreshold in this experiment was min-sup 0.18 because SVM   100*0.75=75 and SVM   100*0.71=71 we found the same optimal VPS than 1  a   a  a n  a  a   a  a   a   a  a r  


TABLE VIII AUM-3 Q/A                    n Acc   1 0 0 0 1 0 1 0 0 0 25   0 1 1 0 0 0 0 1 1 0 20   0 0 0 1 0 1 0 0 0 1 25   0 1 0 0 0 0 1 1 0 0 35   1 1 1 0 1 0 1 1 1 0 25   1 0 0 0 1 0 0 0 0 0 25   0 0 1 0 0 0 0 0 1 0 25   0 0 1 1 0 1 0 0 1 1 15 TABLE IX SVM-2 COMPLETE 1 2 3 4 5 6 7 8 9 10 Support Value SV 0 0.07 0.11 0.18 0.22 0.27 0.33 0.38 0.49 0.51 Occurrence OC 30 12 20 9 4 4 12 1 4 4 Accumulation AC 30 42 62 71 75 79 91 92 96 100 TABLE X AUM-4 Q/A                    n                    n Acc   1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 50   0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 50   0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 50   0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 50   1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 15   1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 15   0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 15   0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 0 1 15   0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 10  n 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 10   1 1 1 0 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 10   0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 10   0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 0 0 10   1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 5   0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 5 TABLE XI SVM-2 COMPLETE  ROW 1=SV ROW 2=OC ROW 3=AC 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 0 0.02 0.03 0.05 0.06 0.08 0.09 0.12 0.16 0.17 0.19 0.20 0.22 0.23 0.25 0.27 0.29 0.30 0.31 0.33 122 30 70 60 4 8 2 2 8 14 6 28 8 16 11 3 5 1 1 1 122 152 222 282 286 294 296 298 306 320 326 354 362 378 389 392 397 398 399 400 In the third experiment we used the AUM also used in 1 presented in Table X Table XI shows the SVM In this example the value found by the algorithm setThreshold was min-sup 0.12 because SVM    400*0.75=300 and SVM    400*0.71=284 the optimal VPS generated is a   a   a   a   a   a   a   a   a   a   a   a n  a r  a   a n  a   a   a   a   a r  and this is the optimal solution found by 1  As we can demonstrate with the experiments SVP always found the optimal VPS It overcomes the problems of Betty and Gorlas algorithm because it only generates one solutio n which is the optimal Betty and Gorla algorithm gets differe nt solutions and it is necessary to use a cost function to evalua te them and nd the optimal Also SVP solves the problem of setting the value of the thresholds for Betty and Gorla and CBPA algorithms V C ONCLUSION A support-based vertical partitioning method was presente d the main advantages of this method are that it uses the probability of accessing a pair of attributes respect to all the access of the queries as a global measure and it can autoset a minimum support threshold to nd the optimal vertical partitioning scheme R EFERENCES 1 S  N a v a t h e  S  C e r i  G  W i e d e r h o l d  a n d J  D o u   V e r t i c a l partitioning algorithms for database design ACM TODS  vol 4 pp 680-710 1984 2 F  M a r i r  Y  N a j j a r  M  A l f a r e s s  a n d H  I  A b d a l l a   A n e n hanced grouping algorithm for vertical partitioning problem in DD BS 22nd Int Symposium on Computer and Information Sciences  pp 39-44 2007 3 S  I  K h a n a n d A  S  M  L  H o q u e   A n e w t e c h n i q u e f o r d a t a b a se fragmentation in distributed systems International Journal of Computer Applications  vol 5 no 9 pp 20-24 2010 


4 S  C h a k r a v a r t h y  J  M u t h u r a j  R  V a r a d a r a j a n  a n d S  N a v athe An objective function for vertically partitioning relations in distributed databases and its analysis Distributed and Parallel Databases  vol 2\(21 pp 183-207 1994 5 M  S  C h e n a n d J  H a n  P  S  Y u   D a t a m i n i n g  a n o v e r v i e w f r om a database perspective IEEE Trans on Knowledge and Data Engineering  vol 8 no 6 pp 866-883 1996 6 M  L  S h y u  S  C  C h e n  a n d R  L  K a s h y a p   G e n e r a l i z e d a f  nity-based association rule mining for multimedia database queries Knowledge and Information Systems  vol 3 pp 319-337 2001 7 G  T z a n i s a n d C  B e r b e r d i s   M i n i n g f o r m u t u a l l y e x c l u s i ve items in transaction databases International Journal of Data Warehousing and Mining  vol 3 no 3 2007 8 N  G o r l a a n d P  W  Y  B e t t y   V e r t i c a l f r a g m e n t a t i o n i n d a tabases using data-mining technique International Journal of Data Warehousing and Mining  vol 4 no 3 2008 9 J  D u  K  B a r k e r  a n d R  A l h a j j   A t t r a c t i o n  a g l o b a l a f  nity measure for database vertical partitioning in Proc of the IADIS Int Conf WWW/Internet  pp 538-548 2003 10 R  A g r a w a l a n d R  S r i k a n t   F a s t a l g o r i t h m s f o r m i n i n g a ssociation rules in Proc of the 20th Int Conf on Very Large Databases  1994 11 J  H  S o n a n d M  H  K i m   A n a d a p t a b l e v e r t i c a l p a r t i t i o n ing method in distributed systems J of Syst and Software  vol 73 pp 551-561 2004 12 M  T   z s u a n d P  V a l d u r i e z   Principles of distributed database systems  Third Edition Springer Heidelberg 2011 13 M  H  A l s u w a i y e l   A l g o r i t h m s  d e s i g n t e c h n i q u e s a n d a nalysis Lecture Notes Series on Computing  vol 7 World Scientic 1999 


B.  NFUP algorithm The basic idea of NFUP algorithm is similar to the FUP algorithm. Their difference is shown in follows: FUP algorithm using the original database to set DB mining results, that is frequent items Ls need for DB and db scan for n times, getting final frequent items L' of DBdb; And algorithm NFUP just scan DB for one time and db for several times. NFUP algorithm can improve efficiency by less scanning to DB's I/O operations. Apriori algorithm for db verifies whether the elements of L is he frequent item of dbDB, and generates the frequent items Ldb, then verifies whether elements of Ldb is the frequent items of dbDB through scanning of DB However, the premise of NFUP algorithm is frequent items known metadata DB and the support of elements Therefore, the theoretical NFUP efficiency is far more than that of FUP. In order to compare the two algorithms, the actual operation comparison will be shown in below. Hardware environment: the CPU is Intel p4 2.4 GHz; memory is DDR 1.0 GB. Software environment: Windows 2000 Server operation system, a programming language is Matlab 7.1. The original data DB exist in Boolean matrix form, which is nine project including 10 000 record. The new data base has 500 records \(about 850 KB and FUP is shown in figure 1, minimum support degree in the 20 percent and 80 percent    Figure 1 The comparison of the execution time among same database algorithms From figure 1, for the same database and support circumstances, the execution time of NFUP algorithm is reduced by 50% than FUP algorithm. NFUP algorithm is much fast than FUP algorithm when the support degree in 0.2 and 0.6 V.  CONCLUSIONS Now some algorithm of some existing frequent items has some missed questions, such as many candidate items, big space. The algorithm may reduce the mining efficiency when increasing scan db frequent items. Although algorithm is simple, its process carries on more effective pruning. This paper brings in some knowledge about association rule 


especially discussing the classic association rule of algorithm and mainly pointing out the analysis and conclusion of the FUP Minimum support degree The execution tim e\(in seconds and the IUA. Also two improved algorithm have been discussed in order to help the study of negative association rules for incremental updating   REFERENCES 1] Agrawal R.Srikant R. Fast algorithms for mining association rules in large database [A]. Proceedings of the 1994 International Conference on VLDB [C ]. San Francisco ?  Morgan Kaufmann Publishers 1994.pp487- 499 2] BrinS ? MotwaniR ? SilversteinC..Beyondmarket ? Generalizing association rules tocorrelations [A]. Processing of the ACMSIGMOD Conference 1997[C]. NewYork?ACMPress?1997. 265?276 3]  Hao Xincheng, Zhang Degang, Zhao Hai: E-commerce data mining research. Small Micro-computer Science[J], 2007\(7 4] HUANG De-cai, ZHANG Liang-yan, GONG Wei-hua, LIU Duan-yang Improved Incremental Updating Algorithm for Association Rules. The computer engineering[J], 2008\(5 in Chinese 5] Zhao Huanping: Web data mining and its application in e-commerce Fujian Computer [J].2008 \(1 in Chinese 6] Shi Yan: Applications of web mining techniques in e-commerce Scientific and Technological Information and Economic Development J] 2006 \(7 in Chinese 7] Ling Chuan-Fan: Web mining techniques applications in e-commerce Intelligence Journal [J] 2008 \(1 8] Witten I H?Frank E?Data Mining?Practical Machine LearningTools and Techniques[M]?2005 9] Margarent H?Dunham . Data Mining: A Tutorial-Based Primer  2005 10] J.B. Schafer, J.A. Konstan, and J.Rie1, Recommender Systems in ECommerce. In ACM Conference on Electronic Commerce \(EC99 11] YooJS,Shekhars,ClikM,A Join-less approach for co-location pattern miniing:a summary of rssults. Proceedings of the IEEE International Conference on Data Mining\(ICDM   


0 1 2 3 4 5 2 3 4 5 6 average error\(distance MinTs STT HPM a Prediction performance comparison 0 200 400 600 800 1000 1200 1400 2 3 4 5 6 storage size\(MB MinTs STT HPM b Storage requirements comparison Fig 9 Prediction model comparison DBSCAN clustering may result in clusters of arbitrary shapes and sizes while the error of STT is restricted by the 003xed cell size C Storage Requirements Comparison We next study the storage requirements comparison of STT with HPM As expected Figure 9\(b demonstrates that our method has smaller storage size than HPM While the storage size of HPM dramatically grows with the number of frequent regions increases our method STT still remains the small storage size with tiny changes The reason is that HPM using association rule based patterns generates the exponential number of rules as the number of frequent regions increases On the contrary STT using data structure of suf\003x tree can compress the number of sequential patterns into a compact model D Sensitivity Analysis of Parameters In this section we examine the effect of cell size and MinTs to our model and prediction Figure 11 presents the experimental results with cell size varied The number of trajectory patterns decreases dramatically as the value of cell size grows Furthermore the prediction error affected by cell size is provided in Figure 11 The prediction error potentially rises as the cell size increases We also investigate the effect of MinTs  In our de\003nition a frequent region is decided by MinTs number of trajectories pass the region in a cell size Therefore a high value of 0 2000 4000 6000 8000 10000 12000 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 number of patterns cell size a Car 0 2000 4000 6000 8000 10000 12000 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 number of patterns cell size b Bike 0 50 100 150 200 250 300 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 number of patterns cell size c Run 0 200 400 600 800 1000 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 number of patterns cell size d Walk Fig 10 Effect of cell size on number of patterns 0.6 1 1.4 1.8 2.2 2.6 3 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 average error\(distance cell size a Car 0.6 1 1.4 1.8 2.2 2.6 3 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 average error \(distance cell size b Bike 0.6 0.8 1 1.2 1.4 1.6 1.8 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 average error\(distance cell size c Run 1.2 1.4 1.6 1.8 2 2.2 0.006 0.009 0.012 0.015 0.018 0.021 0.024 0.027 average error\(distance cell size d Walk Fig 11 Effect of cell size on prediction error MinTs may cause a small number of frequent regions and trajectory patterns Prediction based on trajectory patterns could be affected by MinTs  As the results shown in Figure 12 the number of trajectory patterns is reduced as the number of MinTs increases The prediction error increases signi\003cantly due to the small number of trajectory patterns as shown in Figure 13 VII C ONCLUSION In this paper we presented a pattern-based approach to predict an objects future locations We not only focus on that how to discover frequent movement patterns and manage these patterns to answer predictive queries but also aim to propose 
60 
66 
66 


0 500 1000 1500 2000 2500 3000 3500 2 4 6 8 10 number of patterns MinTs a Car 0 500 1000 1500 2000 2500 3000 3500 2 4 6 8 10 number of patterns MinTs b Bike 0 500 1000 1500 2000 2500 3000 3500 2 4 6 8 10 number of patterns MinTs c Run 0 500 1000 1500 2000 2500 3000 3500 2 4 6 8 10 number of patterns MinTs d Walk Fig 12 Effect of MinTs on number of patterns 0.6 1 1.4 1.8 2.2 2.6 3 2 4 6 8 10 average error\(distance MinTs a Car 0.6 1 1.4 1.8 2.2 2.6 3 2 4 6 8 10 average error\(distance MinTs b Bike 0.6 1 1.4 1.8 2.2 2.6 3 2 4 6 8 10 average error\(distance MinTs c Run 0.6 1 1.4 1.8 2.2 2.6 3 2 4 6 8 10 average error\(distance MinTs d Walk Fig 13 Effect of MinTs on prediction error a model that can reduce the pattern storage size To achieve this idea we propose a spatial-temporal trajectory model to capture an objects moving behavior and STT model could be a predictor to forecast its future locations Experimental results show that the STT model is able to re\002ect an objects moving behavior with a smaller storage size compared to existing patten-based approaches while still guaranteeing the accuracy of location prediction Acknowledgments Wen-Chih Peng was supported in part by the National Science Council Project No 97-2221-E009-053-MY3 by Taiwan MoE ATU Program by ITRIJRC Project No 100-EC-17-A-05-01-0626 by D-Link and by Microsoft R EFERENCES  H Jeung Q Liu H T  Shen and X Zhou A Hybrid Prediction Model for Moving Objects in Proc of ICDE  2008 pp 7079  A Monreale F  Pinelli R T r asarti and F  Giannotti Wherene xt a location predictor on trajectory pattern mining in Proc of KDD  2009 pp 637646  M Morzy   Mining frequent trajectories of mo ving objects for location prediction in Proc of MLDM  2007 pp 667680  W C Peng Y  Z K o  a nd W  C Lee On Mining Mo ving P atterns for Object Tracking Sensor Networks in Proc of MDM  2006 pp 4144  N Mamoulis H Cao G K ollios M Hadjieleftheriou Y  T ao and D W  Cheung Mining Indexing and Querying Historical Spatiotemporal Data in Proc of KDD  2004 pp 236245  C.-W  C  C.-C Hung and W C Peng Mining trajectory pro\003les for discovering user communities in Proc of GIS-LBSN  2009 pp 18  J Krumm and E Horvitz Predestination Inferring destinations from partial trajectories in Proc of UbiComp  2006 pp 243260  F  Giannotti M Nanni F  Pinelli and D Pedreschi T rajectory P attern Mining in Proc of KDD  2007 pp 330339  T  Guyet and R Quiniou Mining temporal patterns with quantitati v e intervals in Proc of ICDM Workshops  2008 pp 218227  F  V e rhein k-ST ARs Sequences of Spatio-T emporal Association Rules in Proc of ICDM Workshops  2006 pp 387394  F  V e rhein and S Cha wla Mining spatio-temporal association rules sources sinks stationary regions and thoroughfares in object mobility databases in Proc of DASFAA  2006 pp 187201  H Jeung H T  Shen and X Zhou Mining T rajectory P atterns Using Hidden Markov Models in Proc of DaWaK  2007 pp 470480  Y  Ishika w a  Y  T sukamoto and H Kitaga w a   Extracting mobility statistics from indexed spatio-temporal datasets in Proc of STDBM  2004 pp 916  H.-P  T sai D.-N Y ang W  C Peng and M.-S Chen Exploring Group Moving Pattern for an Energy-Constrained Object Tracking Sensor Network in Proc of PAKDD  2007 pp 825832  H Cao N Mamoulis and D W  Cheung Mining Frequent SpatioTemporal Sequential Patterns in Proc of ICDM  2005 pp 8289  F  Giannotti M Nanni and D Pedreschi Ef 003cient Mining of T emporally Annotated Sequences in Proc of SDM  2006 pp 593597  A Hinneb ur g and D A K eim  A n e f 003 cient approach to clustering in large multimedia databases with noise in Proc of KDD  1998 pp 5865  P  Sun S Cha wla and B Arunasalam Mining for outliers in sequential databases in Proc of SDM  2006  J Y a ng and W  W ang  A gile A General Approach T o Detect T r ansitions In Evovling Data Streams in Proc of ICDM  2004 pp 559562  G Bejerano and G Y ona Modeling protein f a milies using probabilistic suf\003x trees in Proc of RECOMB  1999 pp 1524  D Ron Y  Singer  and N T ishby  The Po wer o f Amnesia Learning Probabilistic Automata with Variable Memory Length Machine Learning  vol 25 no 2-3 pp 117149 1996  B Ostle and L Malone Statistics in research basic concepts and techniques for research workers  Iowa State Press 1988  C.-H Lo W  C Peng C.-W  C hen T  Y  Lin and C.-S Lin CarW eb A Traf\003c Data Collection Platform in Proc of MDM  2008 pp 221 222 
61 
67 
67 


i?{i? |?R?Rel R\(f,i i ratioocc\(u, i 1 2 where ratioocc\(u, i instance i among the instances of the same concept in the users history D. Frequency Module This module aims at detecting the frequent instances and the frequent associations of instances. Indeed, such a frequency depicts an important interest of the user for the concerned instances. Consequently, it is relevant to recommend items with these characteristics to the user 1 considers the profile of the user. It aims at detecting the most important features of interest for the user Regardless of the estimated interest of an instance for a user, we consider that if the user has in his history a significant percentage of items which have as a feature that particular instance, the interest of this instance is significant Unlike the previous computation, this computation ignores the users ratings for the items which have the instance as a feature Example: A user who has watched 80% of the films interpreted by the actor Tom Hanks should get the recommendation of the other 20% he has not seen even if some of the films of Tom Hanks in his history are badly rated 2 case with frequent instances described above, this part of the module deals not only with the profile of the user, but also with the set of items. It aims at discovering frequent associations between the features in the user history. It detects the features that often occur together in order to discover new recommendations. To achieve this, frequent sets of the instances related to the items in the users history are computed. Then, items with such instances are recommended to the user Example: A possible frequent association is the actor Johnny Depp and the director Tim Burton. A user who is interested in these two instances will be recommended the other films related to them E. Recommendation and explanation 


As explained in Sect. II, the collaborative and the semantic modules are in cascade. Consequently, the result is a set of recommendations rec1 which is mixed with the recommendations of the frequency module rec2 such that rec1 is presented before rec2 to the user. This order can be inverted according to user feedback. Concerning the explanation of the recommendations, this is done by highlighting the instances which have highly scored the interest of the user for the items of rec1, and by highlighting the frequent instances in the items of rec2 F. Example In this section, we illustrate the recommendation process for any user u, in the movie domain. We will simplify to preserve the clarity of the example 2010 10th International Conference on Intelligent Systems Design and Applications 473 Table I EXTRACT OF THE PROFILE OF THE USER u Film Rating Transformation Psycho 5 Psychol Rear Window 4 Rear Windowl Four Weddings and a Funeral 4 Four Weddings and a Funerall Monty Pythons Life of Brian 5 Monty Pythons Life of Brianl Carrie 3 Carried Stephen Kings The Langoliers 1 Stephen Kings The Langoliersd Pulp Fiction 4 Pulp Fictionl Dr. Strangelove 2 Dr. Strangeloved A Clockwork Orange 1 A Clockwork Oranged Let us consider u who has rated the movies in Tab. I Collaborative Filtering Module: Let us assume that the association rule mining result is r1 : {Psychol, Pulp Fictionl} ? {The Shiningl r2 : {Pulp Fictionl,Monty Pythons Life of Brianl Monty Python and the Holy Graill r3 : {Monty Python and the Holy Graill, Jurassic Parkl Indiana Jones and the Last Crusadel According to the rules introduced in Sect III-B2, we only keep the association rules r1 and r2 Semantic-Based Module: In this step, the interest of the user for each movie in the head of each rule from the last module is computed. The concerned movies are The Shining and Monty Python and the Holy Grail For The Shining, we obtain the following interest re 


sults conceptInterestActor \(u, TheShining conceptInterestDirector \(u, TheShining conceptInterestWriter \(u, TheShining conceptInterestGenre \(u, TheShining Unlike the prediction of the previous modules, it seems that The Shining is not a good recommendation for u Actually, this film shares its director with Dr. Strangelove and A Clockwork Orange which are negatively rated by u Moreover, it has a writer in common with Carrie and The Langoliers which are also movies disliked by u. The same reasoning is made about the concepts Actor and Genre Concerning Monty Python and the Holy Grail, the interests by concept are conceptInterestActor \(u, HolyGrail conceptInterestDirector \(u, HolyGrail conceptInterestWriter \(u, HolyGrail conceptInterestGenre \(u, HolyGrail This recommendation is a good one. The film shares its actors, writers and director with Monty Pythons Life of Brian which is highly rated by the user. The recommendation is thus justified Figure 3. Extract of the movie ontology Frequency Module: Let us assume that the user rated 60% of Alfred Hitchcocks films \(in Tab. I, Psycho and Rear Window are some of them recommended to u IV. EXPERIMENTAL EVALUATION A. Ontology Description For the experimentation, we built the ontology manually see Fig. 3 IMDB8. We focused only on a set of data which led to the concepts Film, Person, Actor, Director, Writer and Genre The connections between these concepts are Each movie is related to a certain number of persons who can be actors, directors or writers but it can also be related to other movies \(Example: Free Willy 2: The Adventure Home and Free Willy 3: The Rescue are related A person and a movie have a genre \(Action, Adventure Animation, Children, Comedy, Crime, etc B. Experimentation and Evaluation 


We use a subset of the dataset provided by MovieLens, the recommender system of GroupLens Research. The dataset contains a set of users, the set of items they have evaluated with a rating between 1 \(for the least liked for the most liked framework, we deal with a set of 86 movies, 934 users and 13 053 ratings. The dataset contains 3593 actors, 77 directors, 275 writers and 17 genres Using a 65% confidence and a 5% support, association rule mining resulted in 1472 rules after running the collaborative module. We evaluated the results obtained from the system by eighteen 20-50-year-old volunteers. The evaluation consisted exclusively in explicit valuations \(ratings 8http://www.imdb.com 474 2010 10th International Conference on Intelligent Systems Design and Applications Figure 4. Users evaluation of the system between 1 and 5 rated at the beginning between 11 and 31 films. For each recommended item, the user rates it as liked or disliked. If an item is rated as liked, the recommendation is considered as accurate. Otherwise, the system explains the reason why this item is recommended. The user can then agree with this explanation or not. Explanation of recommendation can be effective in convincing users in their appreciation of the items [24]. In our approach, the explanation aims at discovering if the detected patterns in the recommended item are accurate or not. Let us consider the following explanation in the recommendation of a film: This film may interest you because you frequently watched Tim Burtons films with Johnny Depp. If the user agrees with the explanation, that means that the association \(Tim Burton - Johnny Depp relevant but this particular film do not appeal to the user Otherwise, we consider that the detected association was purely a coincidence. In this case, the system will be able to ignore this pattern for this user in the future The results of this evaluation are depicted on Fig. 4. We can see that 84,9% of the recommendations satisfy the users Concerning the recommendations rated as disliked, 59,4% of the explanations are approved by users. Finally, 93,9% of the recommendations are satisfying or approved An average of 5 recommendations is obtained by running the collaborative and the semantic-based modules \(which is 


acceptable due to the low number of movies  86  in the dataset frequency module. This difference is due to the fact that the cascading modules \(collaborative and semantic-based are limited by the unique usage of the ratings to compute the association rules. The frequency module, on the other hand, is based on a statistical analysis of the item contents Consequently, it does not suffer from the sparsity of the user rating matrix like the previous modules The collaborative module results in some recommendations which are not liked by users. Fortunately, such recommendations are eliminated by the semantic-based module Other recommendations are eliminated by the semanticbased module though they appeal to users. We explain this because the concerned items dont share any features with the ones in the users history. This is why, we aim at introducing a semantic similarity measure to alleviate this problem \(see Sect. V module recommendations and 58,1% of the explanations of the disliked recommendations, satisfy the users. We can conclude that the combination of all the modules results in better recommendations V. CONCLUSION AND FUTURE WORK In our work, we propose a hybrid recommender system that combines collaborative filtering and semantic analysis of the items. The approach is based on many modules that refine the rules which progressively lead to a recommendation. A process targeting users with various interests is described. First, the collaborative filtering step is achieved using association rule mining which is a flexible way to classify the user. His history is then used to make the results more adapted to him. The semantic module aims at refining the recommendation issued from the rules. Finally, a frequency module is used to discover other items of interest for the user. Using distinct modules allows us to explain the recommendations to the user The results we have obtained from the evaluation experiments are promising. The combination of the collaborative and semantic modules improves the quality of the recommendations and the frequency module adds new ones. 93,9 of the recommendations are satisfying or approved In near future, we aim at defining the approach to learn 


the user profile in order to adapt the combination of the recommendation modules. We also plan to improve the semantic module by defining the semantic similarity between instances [25], [26]. Thus, when computing the interest by instance, those which are semantically similar to the current instance can be used when the instance is not present in the users history This similarity could also be used during the personalization of the association rules. The personalization rule \(a which consists in only keeping the rules which have a body composed of items contained in the users history, can be relaxed if the items violating \(a the items in the users history. The advantage of the semantic similarity is that it can be computed off-line which does not slow down the recommendation process Another improvement we want to introduce is the use of implicit data collected and based on the users behavior e.g. his search history, the time he spent looking at an item and his navigational patterns. This will help to increase the knowledge about the user and, in turn, lead to a better understanding of his expectations Finally, we plan to experiment the framework on other domains to confirm the domain-independence of the system REFERENCES 1] G. Adomavicius and A. Tuzhilin, Toward the next generation of recommender systems: A survey of the state-of-the-art and 2010 10th International Conference on Intelligent Systems Design and Applications 475 possible extensions, IEEE Trans. Knowl. Data Eng., vol. 17 no. 6, pp. 734749, 2005 2] R. Burke, Hybrid recommender systems: Survey and experiments, User Modeling and User-Adapted Interaction vol. 12, no. 4, pp. 331370, 2002 3] K. Lang, Newsweeder: Learning to filter netnews, in Proceedings of the 12th International Machine Learning Conference \(ML, 1995 4] M. J. Pazzani and D. Billsus, Content-based recommendation systems, in The Adaptive Web, P. Brusilovsky, A. Kobsa, and W. Nejdl, Eds., 2007, vol. 4321, pp. 325341 5] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and J. Riedl Grouplens: An open architecture for collaborative filtering of netnews, in Proceedings of ACM 1994 Conference on Computer Supported Cooperative Work, Chapel Hill, North 


Carolina, 1994, pp. 175186 6] B. Sarwar, G. Karypis, J. Konstan, and J. Reidl, Itembased collaborative filtering recommendation algorithms, in Proceedings of the 10th international conference on World Wide Web \(WWW 295 7] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl, Analysis of recommendation algorithms for e-commerce, in Proceedings of the 2nd ACM conference on Electronic commerce \(EC Minneapolis, Minnesota, USA, 2000, pp. 158167 8] M. Balabanovic and Y. Shoham, Fab: content-based, collaborative recommendation, Commun. ACM, vol. 40, no. 3, pp 6672, 1997 9] D. Billsus and M. J. Pazzani, User modeling for adaptive news access, User Modeling and User-Adapted Interaction vol. 10, no. 2-3, pp. 147180, 2000 10] M. J. Pazzani, A framework for collaborative, content-based and demographic filtering, Artif. Intell. Rev., vol. 13, no. 5-6 pp. 393408, 1999 11] S. Castagnos, A. Brun, and A. Boyer, Probabilistic association rules for item-based recommender systems, in Proceedings of the Fourth Starting AI Researchers Symposium STAIRS 12] W. Lin, Association rule mining for collaborative recommender systems, Masters thesis, Faculty of the Worcester Polytechnic Institute, 2000 13] J. J. Sandvig, B. Mobasher, and R. Burke, Robustness of collaborative recommendation based on association rule mining, in Proceedings of the 2007 ACM conference on Recommender systems \(RecSys 14] B. Mobasher, H. Dai, T. Luo, and M. Nakagawa, Effective personalization based on association rule discovery from web usage data, in Proceedings of the 3rd international workshop on Web information and data management \(WIDM Georgia, USA, 2001, pp. 915 15] R. Agrawal, T. Imielinski, and A. Swami, Mining association rules between sets of items in large databases, in Proceedings of the 1993 ACM SIGMOD international conference on Management of data, New York, NY, USA, 1993, pp. 207 216 16] B. Liu, W. Hsu, and Y. Ma, Integrating classification and association rule mining, in Knowledge Discovery and Data 


Mining, New York City, New York, USA, Aug. 1998, pp 8086 17] Y. Blanco-Fernandez, J. J. P. Arias, A. Gil-Solla, M. R Cabrer, M. L. Nores, J. G. Duque, A. F. Vilas, R. P. D Redondo, and J. B. Munoz, A flexible semantic inference methodology to reason about user preferences in knowledgebased recommender systems, Knowl.-Based Syst., vol. 21 no. 4, pp. 305320, 2008 18] S. E. Middleton, H. Alani, N. R. Shadbolt, and D. C. D Roure, Exploiting synergy between ontologies and recommender systems, in Semantic Web Workshop 2002 At the Eleventh International World Wide Web Conference, 2002 19] M. Zanker and M. Jessenitschnig, Case-studies on exploiting explicit customer requirements in recommender systems User Modeling and User-Adapted Interaction, vol. 19, no 1-2, pp. 133166, 2009 20] N. Ducheneaut, K. Partridge, Q. Huang, B. Price, M. Roberts E. H. Chi, V. Bellotti, and B. Begole, Collaborative filtering is not enough? experiments with a mixed-model recommender for leisure activities, in Proceedings of the 17th International Conference on User Modeling, Adaptation, and Personalization \(UMAP 21] H. Nguyen and P. Haddawy, The decision-theoretic interactive video advisor, in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence \(UAI 494501 22] B. Mobasher, Data mining for web personalization, in The Adaptive Web, ser. Lecture Notes in Computer Science P. Brusilovsky, A. Kobsa, and W. Nejdl, Eds. Springer Berlin Heidelberg, 2007, vol. 4321, ch. 3, pp. 90135 23] T. R. Gruber, A translation approach to portable ontology specifications, Knowl. Acquis., vol. 5, no. 2, pp. 199220 1993 24] N. Tintarev and J. Masthoff, The effectiveness of personalized movie explanations: An experiment using commercial meta-data, in Proceedings of the 5th international conference on Adaptive Hypermedia and Adaptive Web-Based Systems AH 25] R. Albertoni and M. D. Martino, Asymmetric and contextdependent semantic similarity among ontology instances Journal on Data Semantics, vol. 10, pp. 130, 2008 26] X. Jin and B. Mobasher, Using semantic similarity to 


enhance item-based collaborative filtering, in 2nd IASTED International Conference on Information and Knowledge Sharing, Scottsdale, Arizona, 2003 476 2010 10th International Conference on Intelligent Systems Design and Applications 


Basi Association Rles Basi c  Association R u les Association is basically connecting or tying up occurrences of Association is basically connecting or tying up occurrences of events Ol dib t f ilt t O n l y d escr ib e se t s o f s i mu lt aneous even t s Cannot describe patterns that iterate over time e g  itemset a  0  b  0  g    Eg If you sense higher data rates on the downlink than normal AND New Route generated Implies high chances of Intrusion AND New Route generated Implies high chances of Intrusion Associative IDS for NextGen Frameworks Dr S Dua LA Tech 20 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



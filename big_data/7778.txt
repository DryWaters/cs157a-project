Adaptive Intrusion Detection with Data Mining Mahmood Hossain Susan M Bridges, Rayford B Vaughn Jr Department of Computer Science and Engineering Mississippi State University Mississippi State MS 39762 USA mahmood@cse.msstate.edu Abstract  A major constraint of an anomaly-based intrusion detection system IDS lies in its inability to adapt to the changes in normal user behavior patterns and to distinguish these changes from intrusive behavior To overcome these obstacles the normal profile must be updated at regular intervals The naive 
approach of ex haustively recomputing the normal profile is often not viable and can incorporate patterns of intrusive behavior as normal We address technical issues and present an adaptive data mining fmmework for anomaly detection We employ a sliding window approach and use only the audit data inside that sliding window to update the pro file Instead of performing an exhaustive update we use some heuristics to decide when to update Experimental results using real network tmfic data containing simu lated intrusion attacks\demonstrate the effectiveness of the proposed framework Keywords Anomaly detection 
fuzzy association rules, sliding window audit data 1 Introduction Intrusion detection can be defined as identifying unauthorized use misuse and abuse of computer sys tems by both inside and outside intruders There are many categories of network intrusions Examples in clude SMTP SendMail attacks password guessing IF spoofing buffer overflow attacks multiscan attacks de nial of service \(DOS\such as ping-of-death SYN flood etc The goal of a network-based intrusion detection system IDS is to identify patterns of known intru sions misuse detection or to differentiate anomalous network 
activity from normal network traffic anomaly detection Data mining methods have been used to build automatic anomaly detection systems that profile the normal system activities so that abnormal activi ties can be detected by comparing the current activities with the profile 8 9 61 0-T803-T952-7/03/$17.00 F2003 IEEE IThis work was partially sponsored hy National Science Foun dation Grants CCR-0085749 and CCR-9988524 BS well BS Army Research Laboratory Grant DAAD 17-01-C-0011 and Office of Naval Research Grant N00014-01-1-0678 
Association rule mining l is a very popular data min ing technique used to extract multi-feature correlations from a database table Lee and Stolfo IS extended the basic association rule algorithms to capture consistent behavior in program execution and user activities to form a normal profile Subsequent system activities are analyzed to mine frequent patterns This new pattern set is compared with the normal profile to compute devi ations to generate alarms in case of intrusive behaviors Fuzzy logic was integrated with association rule mining to detect network intrusions in 9 A major 
problem with such IDSs is that they can issue false alarms when there are modifications in the normal system behavior The IDS must be capable of adapting to these changes and the normal profile must be updated at regular intervals One straightforward approach is to generate a new normal profile with each set of new au dit data This approach is not computationally feasible and can cause the system to incorporate patterns of in trusive behavior as normal We discuss some technical issues that need to be addressed to develop an adaptive IDS Instead of using existing association rule update 
techniques 5,4 directly in our work we have chosen to present a general framework for an adaptive data min ing system that is appropriate for our domain We have used this proposed framework to achieve adaptability within our existing IDS 9 The adaptive IDS can adapt to changing system environments or user behavior pat terns A collection of intrusion data was generated in the Department of Computer Science and Engineering Mississippi State University over two months and this data has been used to evaluate the adaptive IDS 
2 Background and related work Association rule mining l is a very important data mining technique A typical example of an association rule mined from audit data can be ftp  get[.4 I which implies 40 confidence of the time when the user uses the ftp command the get command is also invoked and doing so constitutes 10 support of the commands issued by the user The Apriori algorithm Z is one of the standard algorithms for association rule mining 3097 


Data mining methods have been applied to audit data in order to compute models that can capture intrusive and non-intrusive behavior Lee and Stolfo 7 utilized association rule mining and frequent episode mining to mine rules from system audit data to form a normal pro file Any subsequent system activities are analyzed to mine frequent patterns and the new pattern set is com pared with the normal profile Similarity functions are used to evaluate deviations and any significant deviation would signal abnormal activities Partitioning quantitative audit data into intervals may cause sharp boundary problems during mining Two adjacent data values may he mined as two differ ent types normal/abuormal for having different sup port values Consequently an intrusive pattern with a small variance may remain undetected To overcome this problem fuzzy data mining was employed for intru sion detection in 91 where quantitative features are cate gorized.into categories having fuzzy membership values Feature selection plays a critical role in applying data mining techniques to audit data A particular set of fea tures might have a relationship only with the signatures of a particular intrusion type and not others Rules con taining irrelevant features may be misleading to some extent A minimized set of features is also required to reduce the computational requirements for real-time intrusion detection Some important feature selection research in intrusion detection has involved the use of empirical knowledge 8 genetic algorithms 3 and sta tistical and rule-based methods lo Association rules discovered from a transaction database may become invalid if the underlying data changes over time The Fast Update FUP 4 alge rit,hm is an incremental algorithm that uses the frame work of Apriori and can maintain association rules when transactions.are added to the database It updates the support counts of the original large itemsets in t.he mod ified database and removes itemsets whose support fall below the minimum threshold On the other hand it creates new candidate itemsets and itemsets that gain enough support are added to the original large itemsets A more general technique called FUP2 was described in 5 that can also handle deletions and modifications of transactions in the database For deletions FUPZ works as a complementary algorithm of FUP The general case of modification is treated as insertions followed by dele tions The incremental update problem has also been studied in ll 12 and 13 3 Adaptive intrusion detection A major shortcoming of current IDSs that employ data mining methods is that they can generate a series of false alarms in'cases of noticeable systems environ ment modifications To overcome this limitation an IDS must be capable of adapting to the changing con ditions typical of an intrusion detection environment 3098 For example in an academic environment the behavior patterns at the beginning of a semester may he differ ent from the behavior patterns at the middle/end of the semester If the system builds its profile based on the audit data gathered during the early days of the semester then the system may generate a series of false alarms at the later stages of the semester System security administrators can tune the IDS hy adjusting the normal profile but it may require frequent human intervention The main purpose of using data mining techniques in computer intrusion detection is to automate the detection process Since normal system activities may change because of modifications to work practices it is important that an IDS should have auto matic adaptability to new conditions Such adaptability can be achieved by employing incremental mining tech niques that use real time data log of audit records to continually update the profile The naive approach of regenerating the normal pro file with the new audit data is not computationally fea sible Any deviation of the current usage profile from the normal profile can either.represeiit an intrusion or a change in behavior In case of a change in system behavior the base profile must be updated in order to avoid false positive alarms in the future If the system tries to make a change to the base profile every time it sees a deviation there is a potential danger of incorpo rating abnormal activities into the profile Therefore the IDS must be able to adapt to the normal changes while still recognizing abnormal activities If both in trusive behavior and changes in normal behavior occur during a particular time interval the problem becomes more complicated There are also additional issues that need to be addressed Theystem should adapt to rapid changes as well as gradual changes in system behavior Selecting the time interval at which the update should take place is also an important issue If the interval is too long the system may miss some rapid changes or short-term attacks If the interval is too small the system may miss some long-term changes We consider two problems as the major issues in de veloping an adaptive IDS One is to select the time when the update should be made The other is to select a mechanism to update the normal profile To tackle the first issue we can continually measure the similarity be tween each day's activity and the profile and utilize this similarity trace If the similarity stays above a threshold level and an abrupt change is not encountered then the behavioral pattern is taken to he a reflection of normal activities and the profile needs to be updated with the current data If the similarity goes below the thresh old level or an abrupt negative change is encountered then the behavioral pattern is taken to be a reflection of some kind of anomalous acti\\r-ities and the profile does not need to be updated This is illustrated in Figure 1 The activities before point tl are considered to be 


normal and the profile does not need any update The activities between tl and ta represent some abnormal behavior and the profile does not need to be updated Again, between ts and til there is a sharp change in sim ilarity that represents abnormal behavior and no update is made Though the similarity between t5 and t6 re mains positive, because of sharp negative change we do not need to update the profile assuming some abnor mality We are assuming that behavioral change occurs gradually not abruptly Although this approach will not be effective against stealth attacks a very slow gradual attack it is likely to be effective against most attacks  Figure 1 Change of similarity with time 3.1 The architecture of an adaptive IDS In this section we present an architecture for the adaptive maintenance of the profile rule set that can overcome the need for recomputation of the rules with out sacrificing the detection capabilities The profile rule set can be updated by adding new rules deleting old rules or by modifying existing rules changing sup port and confidence This flexible framework exploits the rules generated during the earlier stages It is not computationally feasible to archive audit data for a long time Therefore we employ an overlapping sliding window approach to update the base profile The central idea behind the sliding window approach is the concept of a time window an interval of time outside of which audit records are assumed to be too old to characterize the current behavior The time window therefore acts to filter out outdated audit data and to build a profile based on only recent data that reflects the recent system activities We maintain two itemsets large itemsets and near large itemsets As time goes on a large itemset may start losing its support and a near-large itemset may start gaining support We discard some large itemsets losing support in subsequent time windows in the pro cess and include some new ones Though we maintain both the large and near-large itemsets we only use the rules derived from the large itemsets to compute the similarity This facilitates the updating process in case of gradual behavior changes  3099 Figure 2 Architecture of an adaptive intrusion detec tion system Figure 2 presents an architecture for our framework The process begins with an initial set of audit data Genetic algorithms are used off-line for feature selection and tuning the fuzzy membership function parameters Then fuzzy association mining is applied to mine rules into a normal profile During each time window the audit data in the incremental part is mined and com pared with the profile rule set If there is a sharp nega tive change in similarity or the similarity goes below a threshold abnormal behavior is signaled and the profile is not updated If there is a gradual negative change or positive change in the similarity with the similarity staying above the threshold the profile will be updated with the audit data in the current time window 3.2 Updating the profile It is imperative that we select a technique to update the profile rule set that minimizes the amount of recom putation The efficiency of previously reported methods 4 5 11 12 131 relies heavily on the separation of the added transactions and deleted transactions That re quires database recovery and maintenance of database logs Retention of these logs is not feasible for intru sion detection Instead of using any of these techniques directly in our adaptive framework we have chosen to present a generic framework for an adaptive data mining system that is appropriate for our domain 3.2.1 Candidate itemsets generation We maintain two itemsets in our framew-ork In ad dition to the large itemsets L  L1,Lz  L we also define near-large itemsets N  NI Nz    N The near-large itemsets are itemsets for which the sup ports are less than a higher threshold but greater than a lower threshold Let Smi and Ski be two sup port thresholds where Smi  Skin Then formally Li  Xilsx 2 in NI  X~lsx  in and for i  2 N  XilS,,,,n  sx 2 Ski 


With this changed notion the candidate itemsets generation becomes slightly different from Apriori's ap proach Instead of using only Lk-l as in Apriori we use Lk-1 U Nk-1 to generate the candidates Ck for the next iteration using Ch  CL CL_  XuYlX Y E CL-l X n YI  k  2 where CL  Lk-1 U Nk-1 3.2.2 Problem definition In Figure 3 let to tl t    tn-l,tn t,+i t,+z   be a sequence of times where each interval ti..t,+l has equal length Let any sequence ti t,+l ti     ti+,-l,ti form a sliding time window of n intervals Let D be the set of database transactions during the interval ti-l..t Then at any instance of time ti the active window consists of a database Di represented by U;ziDi-k When this active t,ime window progresses to the next interval the active database goes through an update a set of transactions is added to the active database and a set of transactions is deleted Formally when the active window reaches t.he instance ti D is added and D;-n is deleted We can write Di  D-1 D The set of unchanged transactions that are contained in both the previous and current active window database canbedenoted by'Di-lU'DD Di-l-Di Di-Di Let  and Sx be the support count of an itemset X in database Dj and active window database D respectively Then 8.y  S.y  Sx _  Sx lo 4 2   1.1 1 I I  I  I t D 4  4  0 4 Current Window at time f,,,2  Figure 3 Sliding Window for Incremental Databases Let Lj and N3 be the set of large itemsets and near large itemsets respectively in database Dj Let C and Ni be the set of large itemsets and near-large item sets respectively in the active window database D Let Lkj and Nk be the large k-itemsets and near-large k itemsets respectively in database Dj Let Ck Nk and Cki be the large k-itemsets near-large k-itemsets and candidate k-itemsets respectively in the active window database D The update problem is then t,o find the large itemsets Ci at each instance of time ti and also to calculate Sx for each X in Ci 3.2.3 The update process The update mechanism is performed in the Apriori framework The process starts by aggregating the large itemsets from D Then at each subsequent interval the updated database from the active window is considered to update the large itemsets At time ti in each iteration k a candidate k-itemset Ck is generated from Ck U Nk as described in Section 3.2.1 But the difference is in generating the large k itemsets Ck is generated using Ck,-l generated in the previous window Let X be a candidate k-itemset in the current active window database There can be two possibilities with X X can be large in the previous active window database i.e X E Ck,_ or X is not large in the previous active window database i.e X If X E Cki some large itemsets can lose the mini mum support In this case the unchanged part of the active window database Di-n does not need to be scanned and there can be four possibilities Depend ing on one of these possibilities we can decide which database needs to be scanned If X is in both the incremental and outdated databases i.e X E Li nLi then neither the in cremental database Di nor t.he outdated database Di-,'needs to be scanned If X is in the outdated database but not in the incremental database i.e X E Li-n  Li then the incremental database Di needs to be scanned but the outdated database Di need not be scanned If X is in the incremental database but not in the outdated database i.e X E Li  Li then the outdated database Di needs to be scanned but the incremental database D need not be scanned If X is neither in the incremental database nor in the outdated database i.e X 6 Li U Li then both the incremental database Di and the outdated database Di need to be scanned If X Ck some new itemsets can become large But this is only possible if X is large in D or not large in Di Further to reduce computations we make an assumption that if an itemset is not at least near-large in the previous active window database, then it can not be large in the new active window database even if it is large in Di or not large in Di For each X from the above cases we calculate Sx  SX  SX,_  Sxi If Sx 2 I'D;l x in then X is added to Cki Otherwise if Sx 2 I'Dil x SAin then X is added to Nki So depending on these two situations we throw away some old large itemsets and include some new ones At each iteration the next thing to do is to generate the complete near-large itemsets Some near large itemsets are already generated along with the large itemsets For the others we calculate eh  Ck and generate Nk as defined in Section 3.2.1 3100 


4 Implementation and results We used a set of network audit data to test the effec tiveness of our system Real network data was collected from the departmental server The data was sanitized and preprocessed to extract meaningful and useful in formation We then used a genetic algorithm module to select relevant features Finally we implemented our system and tested it with the preprocessed audit data 4.1 Data collection The network traffic data was collected over a 10-week period in the summer of 2000 starting from 07/10/2000 to 09/15/2000 using the tcpdump utility The server disney used for data collection is the general mail and web server of the Computer Science Department at Mis sissippi State University This particular time of the year was selected because of the changing network ac tivities that would be likely to occur in the audit data There are no classes for three weeks in August and there is a long weekend for Labor Day The first week\222s data contains an audit of network traffic without any simu lated attack activity This period began the week af ter classes began for the second summer session The assumption was that the network activity would settle down after one week into the semester Data was col lected for two hours each day from 1O:OO AM to 1200 PM The second and third weeks\222 data contains audit data with simulated portscan attacks Table 1 gives the description of the generated attacks Table 1 Descriptions of simulated portscan attacks 07/19/2000 Wed 07/20/2000 Thu 07/28/2000 Ri 4.2 Data preprocessing Once the data were collected the next step was to preprocess the binary tcpdump data into meaningful audit data Though we collected data for all seven days of a week we used only the weekdays\222 data in our experiments A sanitizing program downloaded from http://ita.ee.lbl.gov/html/contrib/sanitize.html was modified to extract the following timestamped con nection level information source and destination IPS source and destination port numbers Flags SYN FIN RESET PUSH and size of transferred data Then the timestamped data was partitioned into overlapping in tervals to extract meaningful features An interval size of 4 seconds was selected with overlaps of 2 seconds The features that were extracted from each interval are the number of different source and destination IPS num ber of different source and destination ports number of SYN FIN RESET and PUSH flags and amount of transferred data Genetic algorithms were then used to select the appropriate feature subset and to optimize the associated fuzzy membership functions The data from 07/11/2000 Tuesday 07/18/2000 Tuesday and 08/01/2000 Tuesday were used as the baseline nor mal and abnormal data respectively The features that were selected are the number of different source IPS number of different source ports number of SYN flags number of PUSH flags and amount of transferred data 4.3 Implementation of the adaptive IDS The preprocessed data only with the selected fea tures from the first week were used to build the base profile using a modified version of our earlier system 191 Three different fuzzy functions were used to calculate the membership values Z II and S functions respec tively for the LOW MEDIUM and HIGH categories We used 0.2 and 0.8 as the threshold values for support and confidence respectively After the initial profile is built the system uses a sliding window over new data Each day\222s data is mined to compute the similarity with the base profile We modified the non-commutative similarity function used in our previous work 191 to yield the following similarity function for calculating the similarity between two rules where Then the following aggregate function is used to com pute the similarity between two rulesets RSI and RS2 where and I RS1 1 and I RSz 1 are the total number of rules in RS1 and RS2 respectively We measure the similarity between a particular day\222s activity and the base profile If there is a sharp negative change more than 30 in similarity or the similarity goes below a threshold audit activity for that day is flagged as having anomalous activity Consequently we skip that day and do not include that day in the sliding window If there is a gradual negative change in the sim ilarity with the similarity staying above the threshold we include that day in the sliding window and update 3101 


the base profile according to the updating framework presented in section 3.2 We do the same if there is a positive change in similarity and the similarity stays above the threshold For example let d&+l   dk+n form a sliding win dow of n days Let the similarity between the base profile and the rules mined from I be sim and the similarity on the previous occasion be si\224 If sim 2 sim\222 t 0.7 and sim  threshold we change the sliding window to dlc+ldk  I and update the base profile We do the same if sim 2 sin\222 and sim 222 threshold If sim  si\223  0.7 or sim  threshold we flag out dk+n+l and the sliding window remains    da+n If the activity from the next day dk+n+2 is found to be normal then the we change the sliding window to dk+ldk+2  dk+ndk+n+2 4.4 Experiments Several experiments were performed with the preprc cessed audit data The first experiment was conducted to evaluate the effectiveness of the adaptive system The thin line in Figure 4 shows the daily similarity values produced by the adaptive system with a sliding window size of 5 days and\222 a similarity threshold of 0.5 Abnor mal behavior is indicated by a low similarity value Figure 4 Change of similarity values with our adaptive system and with an exhaustive update Intrusion attacks occurred on day S 07/19/00 day 9 07/20/00 day 15 07/28/00 and day 17 OS/Ol/OO as indicated by the dotted vertical lines in Figure 4 The intrusions on days S and 17 were de tected but intrusions on days 9 and 15 were not At tacks on days 9 and 15 were launched less frequently Table 1 to see whether these small attacks can be de tected or not There were three additional days where there were sharp negative changes in the similarity One was on day Z0 08/04/00 That was the day for the final exam of the summer semester One was on day 31 08/21/00 That was the day when the classes started for the fall semester The last one was on day 41 09/04/00 That was the Labor Day The sharp changes in similarity in those three days did indicate anomalous behavior although those were not attacks For example it is natural that there would be higher network traffic on the first Monday of the semester than the previous Friday The abnormal behavior on day 6 07/17/00 could not however be explained or traced back to a specific cause The next experiment was conducted to observe the effects of exhaustively updating the profile without re gard to the degree and direction of changes using the same sliding window size and similarity threshold as in the first experiment The thick line in Figure 4 shows the similarity values produced hy this experiment If we compare both lines in Figure 4 it is evident that if we incorporate each day\222s activity in the profile even if it is abnormal there are an increased number of false alarms For example the activities on days 11 07/24/00 22 OS/OS/OO and 44 09/07/00 were flagged as abnormal even though there were no ab normal behavior to the best of our knowledge On the other hand the abnormal behavior on day 31 08/21/00 could not he detected The next experiment was conducted to observe the effects of not updating the profile the initial profile is used continuously The thick line in Figure 5 shows the similarity values produced by this experiment If we compare both the lines in Figure 5 it is evident that if we do not employ an adaptive system the system accu racy will fall For example our adaptive approach could detect the abnormal behavior on day 17 OS/Ol/OO and day 31 08/21/00 However if the system is not allowed to adapt these intrusions are not detected i Figure 5 Change of similarity values with our adaptive system and with no update The next experiment was conducted to observe the ef fects of different sliding window lengths Figure 6 shows the daily similarity values produced by the adaptive sys tem with sliding window lengths of 5 4 and 3 days A sliding window of 4 days or 3 days could not detect the abnormal behavior on day 31 OS/Zl/OO Moreover the similarity values on average were lower with smaller window length The observations led us to a conclusion that for this data a sliding window of 5 days is more suitable than a sliding window with either 3 or 4 days 3102 


my mcdor    lday mcdow day mndol Figure 6 Change of similarity for the adaptive system with different sliding window lengths 5 Conclusion We presented an adaptive framework for an intru sion detection system that uses fuzzy association rule mining We introduced technical issues that need to he addressed to develop an adaptive intrusion detection system The framework was supported by some encour aging experimental results We showed that false alarms are issued if the profile is not changed at all or is always changed regardless of the traffic pattern There was one occasion when our new system issued a false positive that we could not explain One drawback of the data collection process was that we assumed that the first week\222s data that was used to build the initial profile represented normal activities only There was no way knowing if abnormal behavior had occurred If it did it was incorporated as a part of the normal behavior There are some issues that we plan to investigate in the future We worked with only a single profile In an actual working environment it would he necessary to develop different profiles for different times of the day or different periods of the week e.g weekends For example we can have two different profiles for a sin gle day, one for daytime hours, one for nighttime hours Again we have not addressed the problem where a time window contains both intrusive data and non-intrusive data representing a behavioral change We need to perform some drill-down operations to individual rules to distinguish between intrusive and non-intrusive pat terns There is also another area in which adaptation could be applied The system performance is sensitive to the fuzzy parameter values The system in its cur rent status works with a static set of fuzzy membership function parameters determined at the Keginning But these values could also be tuned dynamically References l R Agrawal T Imielinski and A Swami 223Min ing association rules between sets of items in large databases\224 Proc SIGMOD\22293 Washington D.C May 2628 1993 pp 207-216 2 R Agrawal and A Swami 224Fast algorithms for mining association rules\224 Proc VLDB\22294 Santi ago Chile September 12-15, 1994 pp 487-.199 131 S Bridges and R Vaughn 223Fuzzy data mining and genetic algorithms applied to intrusion detec tion\223 Proc 23rd Nat\222l Information Systems Secu rity Conf Baltimore MD October 16-19 2000 4 D Cheung J Han V Ng and C Wong 223Main tenance of discovered association rules in large databases An incremental updating technique\224 Proc ICDE\22296 New Orleans LA February 26  March 1 1996 pp 106-114 5 D Cheung S Lee and B Kao 223A general incre mental technique for updating discovered associa tion rules\222\222 Proc DASFAA\22297 Melbourne Aus tralia April 1-4 1997 pp 185-194 6 M Hossain 223Data mining approaches for intrusion detection Issues and research directions\223 Proc IASTED SEA\2222000 Las Vegas NV November 6 9 2000 pp 205-210 71 W Lee S Stolfo and K Mok 223Mining audit data to build intrusion detection models\224 Proc KDD\22298 New York City NY August 27-31 1998 pp 66-72 SI W Lee and S Stolfo 223Data mining approaches for intrusion detection\224 Proc 7th USENIX Security Symp SECURITY 22298 San Antonio TX Jan uary 2629 1998 pp 79-94 191 J Luo and S Bridges 223Mining fuzzy association rules and fuzzy frequency episodes for intrusion de tection\224 Int J intelligent systems Vol 15 No 8 pp 687-703 2000 lo R Mukkamala J Gagnon and S Jajodia 223Inte grating data mining techniques with intrusion de tection\224 Proc 13th Ann IFIP WG 11.3 Working Conf on Database Security Seattle WA July 26 28 1999 ll L Nandlal N Sarda, and V Srinivq 223An a,dap tive algorithm for incremental mining of association rules\224 Proc DEXA\22298 Vienna Austria August 24-28 1998, pp 240-245 12 C Rainsford M Mohania and J Roddick 221\221Incre mental maintenance techniques for discovered clas sification rules\224 Proc CODAS\22296 Kyoto Japan December 5-7 1996 pp 281-284 13 S Thomas S Bodagala K Alsabti and S Ranka 223An efficient algorithm for the incremental upda tion of association rules in large databases\224 Proc KDD\22297 Newport Beach, CA, August 14-17 1997 pp 263-266 3103 


Confidenee  0 ote  i U 0 pmoFe MM,atOW 1 Normnalized number 0  X r ofoccuerence C Fig 8 Increasing or decreasing of the confidence of a track From 1 the confidence Y-coordinate is reported 2 3 on the equivalent normalized number of event X-coordinate Then we decrease or increase the value 4 and report it on the confidence axis 01~~~~~~~~~~1 0 2 0.4 eo 0.8 normalized number of occurrence Fig 9 From the figure 8 template curves are generated with Bezier functions That allows to have pessimistic   0.5 or optimistic D  0.5 strategies for the tracking VIII CONCLUSION We have presented the Gruyer and Royere framework This tool allows to realize a tracking with a management of tracks appearance and disappearance In this framework the decision is taken according to a global belief criteria This decision is good when the conflict is weak but if it is not the case some local suspicious associations can appear We present in this article a method based on a MHT approach to avoid these suspicious associations Two tree generation strategies have been developed The proposed system allows to filter the false alarms Thus the higher levels are not aware of these false alarms but by an internal MHT treatment the system keeps the suspicious targets and analyzes them in the time with the use of virtual objects REFERENCES 1 R K Ahuja T L Magnanti and J B Orlin Network Flows Theory Algorithms and Applications Prentice-Hall 1993 2 A Appriou Multi-signal discrimination by the belief theory De'cision et reconnaissance des formes en signal Traite IC2 Information Commande Communication Edition Hermes 2002 Fig 10 The global system can took two different decisions according two different procedures The decision in the informative mode removes the suspicious association whereas the internal mode keeps this association in order to treat them 3 Y Bar-Shalom Multi-target Multi-sensor tracking  Applications and Advances vol.II Artech House 1992 4 Y Bar-Shalom Multitarget-Multisensor tracking Applications and Advances voLIII Artech House 1999 5 S Blackman and R Popoli Design and Analysis of Modern Tracking Systems Artech House 1999 6 D Gruyer and V Cherfaoui Multi-objects association in perception of dynamical situation In Fifteenth Conference on Uncertainty in Artificial Intelligence Stockholm Sweden 30 July I August 1999 7 D Gruyer C Royere and V Cherfaoui Heterogeneous multicriteria combination with partial or full information In Fusion Cairns Australia July 2003 8 S Jouannin Data association and fusion Application to localization and tracking with embedded intelligent vehicle radar PhD thesis university Blaise Pascal of Clermont-Ferrand 1999 9 H W Kuhn The hungarian method for assigment problem Nay Res Quart 2 1955 10 M Rombaut Decision in multi-obstacle matching process using dempster-shafer's theory In AVCS'98 pages 63-68 Amiens France 1998 11 C Royere D Gruyer and V Cherfaoui Data association with believe theory In Fusion Paris France July 2000 12 V Schmidlin Multi-sensors muti-targets tracking with neurals networks Application to air targets PhD thesis Nice-Sophia Antipolis University 1994 13 Ph Smets Belief functions In Non-standard logics for automated reasoning pages 253-286 Academic Press Londres 1988 E.MAMDANI H.DuBoIs et H.PRADE 14 Ph Smets Belief functions the disjunctive rule of combination and the generalized bayesian theorem International Journal of Approximate Reasoning 9:1-35 1993 15 Ph Smets Managing the combination of conflicting belief functions 2004 16 Albena Tchamova Jean Dezert Tzvetan Semerdjiev and Pavlina Konstantinova Target tracking with generalized data association based on the general DSm rule of combination In Per Svensson and Johan Schubert editors Proceedings of the Seventh International Conference on Information Fusion volume I pages 392-399 Mountain View CA Jun 2004 International Society of Information Fusion 929 


 170 0.411 0.384 0.493 0.397   180 0.569 0.611 0.472 0.486   190 0.494 0.553 0.529 0.588   200 0.314 0.372 0.267 0.314   Avg. 0.379 0.413 0.406 0.443  The comparison of average precision of top-20 on ten topics is listed in Table 4. The measures of keyword-based models \(tfidf and pr number of 0.4. Whereas the figures of pattern-based models \(PTM-1 and PTM-2 be over 0.5. This implies that both PTM models improve the precision of the top returned documents Table 4. Average precision of top20 ranked documents on the ten topics  tfidf Pr PTM-1 PTM-2   Avg. 0.400 0.406 0.505 0.515  Figure 3 illustrates the effect of introducing the pattern-based methods on the P/R curves on the topic 110, which can represent the trend of all topics. In Figure 3, as the PTM models are applied, their P/R curves lift up and indicate the improvement of performance made by the PTM models 6. Related work and conclusion Mining sequential patterns has been extensively studied in data mining community since the first research work in [1]. The earlier studies which focused on the large size of retail datasets have developed several Apriorilike algorithms in order to solve the problem of discovering sequential patterns from such databases However, the Apriori-like algorithms only perform well in databases consisting of short frequent sequences [17 This is caused by the fact that it is quite time-consuming to generate nTerms sequences candidates from \(n1 disadvantage of Apriori-like algorithms [1], a variety of algorithms such as PrefixSpan [17], SPADE [25 SLPMiner [22] and GST [12] have been proposed. In order to improve the efficiency, each algorithm pursues a different method of discovering frequent sequential patterns, which makes them featured by the capability of mining such patterns without even generating any candidates With respect to the representation of the content of documents, some research works have used phrases rather than individual words [21]. However, the effectiveness of the text mining systems was not improved very much. The likely reason is that, a phrasebased method has  lower consistency of assignment and lower document frequency for terms  21]. Hence, in this paper, we present a novel concept for mining text documents for sequential patterns. Instead of using single words, we use pattern-based taxonomy to represent documents. By pruning meaningless patterns which have been proven to be the source of the  noise   in this study, the problem of  overfitting  is solved and the experimental results which show the encouraging outcomes are achieved 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0 0.2 0.4 0.6 0.8 1 Recall Pr e c is 


is io n PTM-2 PTM-1 Pr tfidf Figure 3. Precision/Recall curves on Topic110 Proceedings of the IEEE/WIC/ACM International Conference on Web Intelligence \(WI  04 0-7695-2100-2/04 $ 20.00 IEEE Some future research works can be conducted based on the results of this research. To improve the accuracy one major direction is to extract and use the interesting information from negative or unlabeled documents. The weighting scheme of discovered patterns can then be optimized References 1] R. Agrawal, and R. Srikant  Mining sequential patterns  Proceedings of Int. Conf. on Data engineering \(ICDE  95 pp. 3-14 2] H. Ahonen, O. Heinonen, M. Klemettinen, and A I. Verkamo  Applying data mining techniques for descriptive phrase extraction in digital document collections  Proceedings of the IEEE Forum on Research and Technology Advances in Digital Libraries \(ADL  98 1998, pp. 2-11 3] M. L. Antonie and O. R. Zaiane  Text document categorization by term association  ICDM02 Maebashi City, Japan, 2002, pp. 19-26 4] Y. Bi, T. Anderson, S. McClean  A rough set model with ontologies for discovering maximal association rules in document collection   Knowledge-Based Systems vol.16, 2003, pp. 243251 5] G. Chang, M.J. Healey, J. A. M. McHugh, and J T. L. Wang, Mining the World Wide Web: an information search approach, Kluwer Academic Publishers, 2001, pp. 192 6] D. A. Evans, et al., CLARIT experiments in batch filtering: term selection and threshold optimization in IR and SVM Filters, TREC02 2002 7] R. Feldman, et al  Text mining at the term level  Lecture Notes in AI 1510: Principle of data mining and knowledge discovery, SpringerVerlag, 1998, pp. 65-73 8] R. Feldman and H. Hirsh  Mining associations in text in presence of background knowledge   KDD96, 1996, pp. 343-346 9] D. A. Grossman and O. Frieder, Information retrieval algorithms and heuristics, Kluwer Academic publishers, Boston, 1998 10] K. M. Hammouda and M. S. Kamel  Phrasebased document similarity based on an index graph model  Proceedings of IEEE 2002 Int Conf. on Data Mining \(ICDM  02 pp. 203-210 11] J. D. Holt and S. M. Chung  Multipass algorithms for mining association rules in text databases  Knowledge and Information Systems vol.3, 2001, pp. 168-183 12] Y. Huang and S. Lin  Mining sequential patterns using graph search techniques  Proceedings of the 27th Annual Int. Computer Software and Applications Conf. \(COMPSAC  03 2003, pp. 4-9 13] Y. Li, C. Zhang, and J. R. Swan  An information filtering model on the Web and its application in 


filtering model on the Web and its application in JobAgent  Knowledge-based Systems 13\(5 2000, pp. 285-296 14] B. Liu, Y. Dai, X. Li, W. S. Lee, and P. S. Yu  Building text classifiers using positive and unlabeled examples  ICDM03, 2003, pp. 179186 15] B. Liu, Y. Ma, and Philip S. Yu, Discovering business intelligence information by comparing company Web sites, in: N. Zhong, J. Liu and Y Y. Yao \(eds  Web Intelligence  SpringerVerlag, 2003, pp. 105-127 16] J. Mostafa, W. Lam, and M. Palakal  A multilevel approach to intelligent information filtering: model, system, and evaluation  ACM Transactions on Information Systems 15\(4 1997, pp. 368-399 17] J. Pei, J. Han, B. Mortazavi-Asl, H. Pinto, Q Chen, U. Dayal, and M. Hsu  PrefixSpan Mining sequential patterns efficiently by prefixprojected pattern growth  Proceedings of Int Conf. on Data Engineering \(ICDE  02 Heidelberg, Germany, 2001, pp. 215-224 18] M. F. Porter  An algorithm for suffix stripping   Program 14\(3 19] S. Robertson and I. Soboroff, The TREC 2002 Filtering Track Report, NIST Special Publication: SP 500-251 \(TREC-2002 20] T. Rose, M. Stevenson, and M. Whitehead  The Reuters Corpus Volume1 - From yesterday  s news to today  s language resources  Proceedings of the 3rd Inter. Conf. on Language Resources and Evaluation, Las Palmas, Spain 2002 21] F. Sebastiani  Machine learning in automated text categorization  ACM Computing Surveys Vol. 34, No.1, 2002, pp. 1-47 22] M. Seno and G. Karypis  SLPMiner: An algorithm for finding frequent sequential patterns using length-decreasing support constraint   Proceedings of IEEE 2002 Int. Conf. on Data Mining \(ICDM  02 23] P. Tzvetkov, X. Yan, and J. Han  TSP: Mining top-K closed sequential patterns  ICDM03 2003, pp. 347-354 24] X. Yan, J. Han, and R. Afshar  CloSpan: mining closed sequential patterns in large datasets   Proceedings of SIAM Int. Conf. on Data Mining SDM 03 177 25] M. Zaki  SPADE: An efficient algorithm for mining frequent sequences  Machine Learning vol. 40, 2001, pp. 31-60 Proceedings of the IEEE/WIC/ACM International Conference on Web Intelligence \(WI  04 0-7695-2100-2/04 $ 20.00 IEEE pre></body></html 


  12  Figure 32 Bottom view of dual frequency antenna tile with perforated L-band patc h in lower layer with Kuband patches  Figure 33 Layer stack with perforated L-band patch in lower layer with Ku-band patches  8  B EAM FORMING N ETWORK  A major keystone for the su ccess of phased array antenna onboard aircraft is the capability of steering the main beam in the direction of the geosta tionary satellites. This requires the inclusion of a broadband beam forming network. Beam steering can be realized by adding RF-phase shifters and LNA\222s to the antenna elements of the array. However traditional phase shifters in ge neral have a narrow band, and hence do not yield the re quired broadband capability Alternative technologies for broadband beam forming are switched beam networks \(using Butler matrices innovative designs for RF-compone nts such as phase shifter LNA components in \(M\IC technology, or beam forming by using opti cal ring resonators  The German SME IMST is involved in several projects for development of electronica lly steerable phased array antennas for satellite communication. In the NATALIA project \(New Automotive Track ing Antenna for Low-cost Innovative Applications\ ESA, IMST is investigating the possibility of realizing a compact costeffective solution for a recei ve-only full electronically steerable antenna for cars in Ku-band. This antenna is a planar array composed of approximately 150 patches circularly polarised by using a 90\260 hybrid, and arranged in a hexagonal fashion. Each patc h is equipped with a MMIC corechip containing a phase sh ifting unit, LNA and digital steering logic  In the Netherlands, a consortiu m \(consisting of University of Twente, Lionix BV, National Aerospace Laboratory NLR and Cyner Substrates developing in the national FlySmart project technology for a broadband optical beam forming network. For the steering of the beam of the conformal phased array a squi nt-free, continuously tunable mechanism is proposed that is based on a fully integrated optical beam forming network \(OBFN optical ring resonators \(ORRs as tunable delay elements. A narrowband continuously tunabl e optical TTD device is realized as a recirculating wa veguide coupled to a straight waveguide. This straight wave guide can behave as a bandpass filter with a periodic, bell-shaped tunable group delay response. The maximum group delay occurs at a tunable resonance frequency. A larger delay-bandwidth product can be achieved by cascading multiple ORR sections. A complete OBFN can be obtaine d by grouping several delays and combining elements in one optical circuit. Such an OBFN can be realized on a si ngle-chip. Electrical/Optical E/O O E by means of filter based single-sideband modulation suppressing the carrier lanced coherent optical detection. Further details of the optical beamforming network have been presented in Re The proof-ofconcept has been shown by manufacturing a chip for an 8x1 OBFN. Essential components of the OBFN are the optical modulators, which are used to modulate the light in the ORR system 9  C ONCLUSIONS  For enhanced communicati on on board aircraft, novel antenna systems with broa dband satellite-based capabilities are required. So far, existi ng L-band satellite based systems for communications are used primarily for passenger application \(APC\i nistrative communications AAC and now data are tending to evolve towards broadband dig ital applications \(Voice over IP\any studies are going on worldwide to employ Kuband TV geostationary sate llites for communication with mobile terminals on aircraft The inbound traffic is about 5 times higher than the outbound The inbound traffic requires the availability of a broadband Ku-band antenna in receive mode only. The outbound traffic services can be supplied by the Inmarsat SBB link, whic h requires the installation of an L-band transmit antenna. In order to avoid both the installation of L-band antenna and Ku-band antenna, the concept of a hybrid dual frequency antenna operating L 


  13 band and Ku-band with low aerodynamic profile has been investigated in this paper. Keyaspects of this research are 200  Design and testing dual-fre quency antenna elements operating in both L-band and Ku-band 200  Conformal aspects of Ku-band phased array antennas 200  Beam forming algorithms for planar and conformal phased array antennas Two designs for dual-frequency antenna tiles consisting of 8x8 Ku-band antenna elements and one L-band element The designs have been analysed by means of computer simulations. Both designs show promising performance both in L-band and Ku-band. The design with slotted Lband antenna has a resonant fre quency in receive mode with a bandwidth of about 1 GHz. The Ku-band antenna is a stacked patch configuration where a parasitic element is placed above a lower patch separated by dedicated space filler. The manufactured protot ype antennas indicate that the bandwidth is sufficiently large In order to be able to communicate with geostationary satellites also at high latitudes e.g. during inter-continental flights\stem should have sufficient performance at low elevation angles. The antenna Ku-band system is required to have a small beamwidth \(to discriminate between the satellite signals\gain 30 dB angles. The effects of these requirements on the size and positioning of the antenna on the aircraft fuselage have been investigated. These requirements can be best satisfi ed by installing two planar phased array antennas on both side s of the fuselage with at least 1600 Ku-band elements. Each element has two feed lines, one for each polarization Every feed line has to be connected to the beam formi ng network. This means that the connections cannot be routed to one of the four sides of the antenna. Instead the concept of vertical feed lines \(by means of vias in a sufficiently thick substrate recommended. These vertical f eed lines connect the L-band and Ku-band antenna elements in the upper layer with feed networks in multiple lower laye rs. This vertical feed line system was not available so far due to manufacturing problems The performances of one dua l-frequency antenna design have been investigated by manufacturing two test antennas without vertical feed line syst em. The first antenna contains only a multilayer structure with L-band slots and 8x8 Kuband stacked patches. The performances of the L-band slots and Ku-band stacked patches c ould be measured separately It was concluded that opportun ities should be considered to improve the design of the dual-frequency antenna \(by optimizing the feeds of the Ku-b and elements the dual frequency test-antenna and the measurement set-up More important, however, is the realization of a mechanically stable vertical feed line system, so that the properties of L-band and Ku-band elements can be measured adequately The second test antenna contains only a multilayer structure with 8x8 Ku-band stacked patches and a feed network with 8 combiners, where each comb iner coherently sums 8 antenna elements. In combination with a prototype 8x1 OBFN, a Ku-band phased arra y antenna is obtained of which the beam can be steered in one direction. This second test antenna is used to analyze the broadband properties of the 8x8 Ku-band antenna array and 8x1 OBFN. The measured performances of this antenna are presented in Ref   A CKNOWLEDGMENT  This work was part of the EU 6 th Framework project ANASTASIA., and the FlySmart project, supported by the Dutch Ministry of Economic A ffairs, SenterNovem project numbers ISO53030 The FlySmart project is part of the Eureka PIDEA  project SMART Cyner Substrates is acknowle dged for technical assistance during the fabrication of the prototype antennas 


  14 R EFERENCES  1  P. Jorna, H. Schippers, J. Verpoorte, \223Beam Synthesis for Conformal Array Antennas with Efficient Tapering\224 Proceedings of 5 th European Workshop on Conformal Antennas, Bristol, September 11-12, 2007 2  The Radio Regulations, editi on of 2004, contain the complete texts of the Radio Regulations as adopted by the World Radio-communication Conference \(Geneva WRC-95 tly revised and adopted by the World Radio-communication Conference WRC-97\RadioWRC2000\and the World Radio-communication Conference WRC-03 Resolutions, Recommendations and ITU-R Recommendations incorporat ed by reference 3  RECOMMENDATION ITU-R M.1643, Technical and operational requirements for ai rcraft earth stations of aeronautical mobile-satellite service including those using fixed satellite service network transponders in the band 14-14.5 GHz \(Earth-to-space 4  ETSI EN 302 186 v1.1.1 \(2004-01 Stations and Systems \(SES\onised European Norms for satellite mobile Aircraft Earth Stations AESs\the 11 12/14 GHz frequency bands covering essential requirement s under article 3.2 of the R&TTE directive 5  EUROCAE ED-14E; Environmental Conditions and Test procedures for Airbor ne Equipment, March 2005 6  F. Croq and D. M. Pozar, \223Millimeter wave design of wide-band aperture-coupled stacked microstrip antennas,\224 IEEE Trans. Antennas Propagation, vol. 39 pp. 1770\2261776, Dec. 1991 7  S. D. Targonski, R. B. Waterhouse, D. M. Pozar Design of wide-band aperture stacked patch microstrip antennas ", IEEE Transactions on Antennas and Propagation, vol. 46, no. 9, Sep. 1998, pp. 1245-1251 8  R. B. Waterhouse, "Design of probe-fed stacked patches", IEEE Transactions on Antennas and Propagation, vol. 47, no. 12, Dec. 1999, pp. 1780-1784 9  D.M. Pozar, S. D. Targonski, \223A shared aperture dualband dual-polarised microstrip array\224, IEEE Transactions on Antennas and Propagation,Vol. 49 no. 2,Feb. 2001, pp. 150-157 10  http://www.ansoft.com 11  J-F. Z\374rcher, F.E. Gardiol, \223Broadband patch antennas\224 Artech House, \(1995\N 0-89006-777-5 12  H. Schippers, J. Verpoorte, P. Jorna, A. Hulzinga, A Meijerink, C. G. H. Roeloffzen, L. Zhuang, D. A. I Marpaung, W. van Etten, R. G. Heideman, A. Leinse, A Borreman, M. Hoekman M. Wintels, \223Broadband Conformal Phased array with Optical Beamforming for Airborne Satellite Communication\224, Proc. of the IEEE Aerospace Conference, March 2008, Big Sky, Montana US 13  H. Schippers, J. Verpoorte, P. Jorna, A. Hulzinga, L Zhuang, A. Meijerink, C. G. H. Roeloffzen, D. A. I Marpaung, W. van Etten, R. G. Heideman, A. Leinse M. Wintels, \223Broadband Op tical Beam Forming for Airborne Phased Array An tenna\224, Proc. of the IEEE Aerospace Conference, March 2009, Big Sky, Montana US 


  15  B IOGRAPHIES  Harmen Schippers is senior scientist at the National Aerospace Laboratory NLR. He received his Ph. D. degree in applied mathematics from the University of Technology Delft in 1982. Since 1981 he has been employed at the National Aerospace laboratory NLR. He has research experience in computational methods for aero-eleastics, aeroacoustic and electromagnetic problems. His current research activities are development of technology for integration of smart antennas in aircraft structures, and development of computational tools for installed antenna analysis on aircraft and spacecraft  Jaco Verpoorte has more than 10 years research experience on antennas and propagation Electromagnetic compatibility \(EMC and radar and satellite navigation He is head of the EMC-laboratory of NLR. He is project manager on several projects concerning EMCanalysis and development of advanced airborne antennas    Adriaan Hulzinga received his BEng degree in electronics from the hogeschool Windesheim in Zwolle Since 1996 he has been employed at the National Aerospace laboratory \(NLR as a senior application engineer. He is involved in projects concerning antennas and Electromagnetic compatibility \(EMC  Pieter Jorna received the M.Sc degree in applied mathematics from the University of Twente in 1999 From 1999 to 2005 he was with the Laboratory of Electromagnetic Research at the University of Technology Delft. In 2005 he received the Ph.D. degree for his research on numerical computation of electromagnetic fields in strongly inhomogeneous media Since 2005 he is with the National Aerospace Laboratory NLR\ in the Netherlands as R&D engineer   Andrew Thain is a research engineer in the field of electromagnetic modelling of antennas. He specialises in the use of surface integral methods for the calculation of coupling and radiation patterns and works closely with Airbus on the topic of antenna positioning. He has experience in the field of electromagnetic modelling  Gilles Peres is head of the Electromagnetics group of EADS-IW He has a wide experience in computational EM modelling particularly the use of FDTD, integral and asymptotic techniques for antenna structure interactions. He has contributed with Airbus experts to the certification campaign of the A340/500 and A340/600. Dr Peres holds a PhD thesis from University of Toulouse \(1998\ on impulsive Electromagnetic Propagation effects through plasma   Hans van Gemeren has a BEng degree in electronics. From the beginning of Cyner substrates he is involved in development and production of prototyping and nonconventional Printed Circuit boards Working mainly for design and research centers Cyner got involved in many high tech projects and from this developed a great expertise in the use of different \(RF materials. In the FlySmart project Hans and his colleagues are able to do what they like most: In close cooperation with designers, creatively working on substrate solutions 


  16  


NIMBUS NOAA 8 NOAA 15 NPOESS Preparatory Project Orbital Maneuvering Vehicle Orbcomm Orbiting Carbon Observatory Orbiting Solar Observatory-8 Orbview 2 Orion 1 P78 Pas 4 Phoenix Pioneer P-30 Pioneer Venus Bus/Orbiter Small Probe and Large Probe Pioneer-I 0 Polar QuikSCAT Radarsat Reuven High Energy Solar Spectroscopic Imager REX-II Rosetta Instruments Sage III SAMPEX Satcom C3 Satcom C4 SBS 5 SCATHA Seastar SMART-1 SNOE Solar Dynamics Observatory Solar Maximum Mission Solar Mesosphere Explorer Solar Radiation and Climate Experiment Solar Terrestrial Relations Observatory Space Interferometry Mission Space Test Program Small Secondary Satellite 3 Spitzer Space Telescope SPOT 5A Stardust  Sample Return Capsule STEPO STEPI STEP3 STEP4 STRV ID Submillimeter Wave Astronomy Satellite Surfsat Surveyor Swift Gamma Ray Burst Exporer Synchronous Meterological Satellite-I TACSAT TACSAT 2 TDRS F7 Tellura Terra Terriers Tethered Satellite System Thermosphere Ionosphere Mesosphere Energetics and Dynamics TIMED TIROS-M TIROS-N TOMS-EP Total Ozone Mapping Spectrometer TOPEX TRACE Triana Tropical Rain Measuring Mission TSX-5 UFO I UFO 4 UFO 9 Ulysses Upper Atmosphere Research Satellite Vegetation Canopy Lidar VELA-IV Viking Viking Lander Viking Orbiter Voyager Wilkinson Microwave Anisotropy Probe WIND WIRE XMM X-Ray Timing Explorer XTE XSS-iO XSS-ii APPENDIX B FIELDS COLLECTED Mission Mission Scenario Mission Type Launch Year Launch Vehicle Bus Model Bus Config Bus Diameter Location Expected Life Flight Profile Flight Focus Technical Orbit Currency Total Cost Including Launch Unit Sat Costs Average Sat Cost Production Costs Launch Costs Operations Cost Orbit Weight Wet Weight Dry Weight Max Power EOL Power BOL Power  of Batts 17 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



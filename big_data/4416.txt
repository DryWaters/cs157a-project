  1  INTRODUCTION  Protein structure prediction is one of the most important tasks in post-genome h e res earch of protein  structure could be tracked back in the 1970s. In bioinformatics e res earch ers u s e of inf or m a tion technology and mathematical methods, to analyze the macromolecules \(DNA and protein\or their biological senses. Protein Structure Prediction, in the many bioinformatics researches occupies an important position In terms of the basic methodology in protein structure researches, X-ray crystallography methods and multi-dimensional magnetic resonance methods are the 
most effective ones by now. They can achieve a high precision, but a long period is necessary and the molecular weight is confined by 20,000. Consequently, one method that is effective, efficient, and independent of crystal culture, is needed urgently. Based on the information of the protein primary structure, to predict the senior structure, is developed for that n  In recent years, although Protein Structure Prediction gets some certain achievements by machine learning and data mining technology, progress of protein secondary structure prediction was still slow, what is eased the fact which is that data rich and poor knowledge. Because the 
forecast accuracy was less than 80 per cent and the models established by these methods were hard to understanding, it is unable to reveal the relationship between space conformation and sequence As a new association analysis of data mining model KDD* process model which is based on double bases cooperating mechanism consider Knowledge Discovery System as cognitive systems, from the perspective of cognitive psychology to recognize knowledge discovery process and focus on cognition autonomy of knowledge discovery process. Trough constructing heuristic coordinator and maintain coordinator respective simulate 
two characteristics and achieve self-knowledge shortage and real-time knowledge base maintenance, then use     This work is supported by National Nature Science Foundation under Grant\(69835001  double bases cooperating mechanism establish a particular relationship between database and knowledge base, from a specific view reveals that the potential nature ,discipline and complexity of knowledge discovery to transform the knowledge discovery process In this paper, based on double bases cooperating mechanism we integer KDD * model with problem of 
protein secondary structure prediction, and proposed an improved CBA algorithm based on complexity distance measure of support and confidence which is based on the protein secondary structure prediction method KAAPRO KDD * Association Analysis Protein secondary structure prediction\hich is the core of the pyramid forecasting model. This model is focus on partial alpha, beta-protein secondary structure prediction which has been made in the higher forecast accuracy. The improved CBA take care of the unobvious structural characteristics of amino acids received 74.6 percent of the prediction accuracy, making the whole model prediction accuracy 86 percent, exceeding the current international Known on the highest 81 percent 
of the prediction. So this model and algorithm have more obvious advantages on the others 2  COMPOUND PYRAMID MODEL For non-trivial problems, such as protein secondary structure prediction, the general single-method models and simple combinations of prediction models, could not obtain satisfied prediction results. The compound pyramid model adopts gradually refining, multi-hierarchical configuration in which the layers focus on independent functions, so that this model get the higher prediction accuracy comparatively. Its configuration is shown in Figure 1 
 An Improved CBA Prediction Algorithm in Compound Pyramid Model Zhou Zhun, Yang Bingru, Hou Wei University of Science and Technology Beijing, Information Engineering School, Beijing 100083 E-mail: zhouzhun.qd@gmail.com Abstract As one of  KDTICM[8 t h e o ry re s e a r c h e s this pa pe r pr o pos e a n im prov e d a l g o rit hm CBA  w h ic h is ba s e d on KDD* model and combined with KAAPRO method, for protein secondary structure prediction problem. Further multi-layer systematic prediction model--Compound Pyramid Model, is proposed. The kernel of this model is CBA which is a classic association rules analysis algorithm. Domain knowledge is used through the model, and the 
phy-chemical attributes is chosen by Causal Cellular Automation. In experiment, the proteins bias alpha/beta structure are precisely predicted. The structures of amino acids, whose structure are obscure, are predicted well by the improved CBA .Finally, the result of this model is satisfied Key Words Association Rule, Protein secondary structure Prediction, Compound Pyramid Model, CBA algorithm 5176 978-1-4244-2723-9/09/$25.00 c  2009 IEEE 


   Figure 1 The compound pyramid model Note: Comprehensive analysis layer integrates SVM multi-classification and homogenous analysis methods, as a result there are 4 sets, in Figure 1 the numbers in circles denotes identified as H or E, outputted as a part of result basically identified as H or E, the further judgment is necessary difficult to be identified, the assistant judgment is necessary identified as C, outputted as a part of result  3  KDD* MODEL In the KDD* process model [7 e h e u r istic co o r d i n a to r and the maintaining coordinator are the most essential mechanisms. The heuristic coordinator simulates the intention creationé in cognitive psychology, so that the shortage of knowledge could be found. In the classical KDD process, the focus depends on userês interest consequently much useful knowledge would be neglected So the heuristic coordinator could help the system of KDD obtain hidden useful knowledge, and work more actively that the human expertsê confinement would be counterbalanced The maintaining coordinator simulates the çpsychological information renovationé, a feature in cognitive psychology so that the real-time maintenance of knowledgebase is realized. Because of the maintaining coordinatorès introduction, under the correct definitions of repetition contradiction and redundancy, the repeated, contradicted and redundant knowledge could be processed in real time by super graph theory. As a result, only the hypothesis of knowledge which is possible to be new know ledges, needs to be processed, and furthest diminish the workload. In the practical expert system, the new knowledge is usually much less than the hypothesis of knowledge, hence maintaining coordinator would improve the efficiency of the system As shown in figure 2  Heuristic coordinator   Focus  Obtain hypothet ic rules  Preprocess    Real database   Split sub-databases  Form data subclass structure according to sub-databases construct minin g database   Directional mining process  Move the rules obtained into knowledge database Ac c or ding to userês demand interes ts  Ma intaining c oordinator    Basic knowledgebase  Assess  Derivative knowled g e database   Split sub-knowledgebases   Separate knowledge nodes according to attributes, form conclusion arcs, construct mining knowledgebase   Search disconnected status from knowledge nodes in mining database discover knowledge shortage        Directional searching  Direc tional min ing   Figure 2 KDD* process model   4  IMPROVED CBA ALGORTITHM Improved CBA algorithm is in core judgment layer of the compound pyramid model, whose core is the KDD * model based on KDTICM theory and improved CBA association classifier protein secondary structure prediction algorithm which is based on complexity distance measure of support and confidence. This layer aimed at taking advantage of the association rules which is mining by high purity of  and  protein database using the KAAPRO methods in KDD model. The construction of the two databases is up to CATH meth h ic h t h e con ditio n i s les s t h an 30 percent homology of  and  protein. Because of high purity database, the results are precisely refinement association rules. According to the mining results of the refinement association rules with a high starting point based on improved CBA associ ation classifier protein secondary structure prediction algorithm, classifies the protein which cannot judge by the layer of comprehensive analysis and the layer of assist judge In partial alpha, beta-protein secondary structure prediction problem, the determination role of the main core layer is classify the different of SVM and homology analysis voting. Using the alpha, beta association rules generated by KDD * system, reduce to the purify knowledge database of alpha, beta rules. After repeated experiments of the training set, we got the parameter  of alpha, beta knowledge database for the proportion of support and confidence. Experiment verify that the results are reliable, and prove that we get the parameter  of alpha, beta knowledge database for the proportion of  support and confidence can save as a fixed knowledge and embed in the whole of compound pyramid model In the using CBA process, we break the convention which is simply setting of support thresholds, according to the cumulative confidence as classify criteria of alpha, beta We do not just use the single measure of confidence, but using confidence and support of the complexity distance measure as a composite measure, which way can better embody the two major indicators in the secondary protein structure prediction In the association rules mining process, we also break the convention. According to the characteristics of protein 2009 Chinese Control and Decision Conference CCDC 2009 5177 


  biological data, we give up the common protein database to generate association rules; on contrary ,we use the relative bias alpha, beta protein database. This way resolves the difficult problem that the support and confidence of association rules in protein association rules mining is low and the rules cannot be trust. The experiments proved that compare with the classic protein prediction precision we get a greater precision 4.1 CBA Algorithm Based on Complex Distance Measure CBA algorithm in the classic classification issues, set a fixed threshold of support measure, which is a single confidence metric. Itês equal to reduce to a single dimension of confidence and given up the metric of support measure. We believe that in two-dimensional protein structure prediction problem the support measure dimension is also important. In the classic association classifier the way of abandon the support measure is unfit in the secondary structure prediction problem. The support is also important parameter, which is including hidden knowledge of classification Rules, so we design based on the complex distance measurement of improved CBA algorithm Through the mining of KDD* system, the alpha, beta rules base is showed as follows  Table 1 A part of alpha database mining results Note: Condition is composed of several items, that are separated by space, which denotes çandé; Support and Confidence are denoted by real number Classic CBA algorithm evaluation function is as follows  1 n CBA i i Score confidence     evaluation function only sum the satisfied i confidence of i rule according to CBA CBA Score Score   predict the protein is alpha type if CBA CBA Score Score   then predict the protein is beta type ,and if the difference is neglect, then send the part of protein to the optimize layer. This is equal to reduce the support dimension, just consider as the confidence measure. In our experiment, we found out the protein data in biology is typical high dimensional nonlinear data. Only using the setting of support threshold is hard to complete the problem of protein secondary prediction From our experimental system, we got the statistics of the Mining KDD rules for the alpha and beta the rules, because of the use of the relatively high starting point alpha, beta protein database, so we got the association rules whose confidences are relatively high, the majority are upper than 95 percent, it lost the significance of statistical. So we have statistics to distribution of ruleês support measure         Figure 3 distribution of support measure statistics in alpha rules base In Figure 3, the abscissa is the support of alpha rules base longitudinal coordinates show the number of corresponding support        Figure 4 distributions of support measure statistics in beta rules base In Figure 4, the abscissa is the support of beta rules base longitudinal coordinates show the number of corresponding support In such statistics, it only focus on the number of same support in statistical analyze. Obviously in this case the high support of association rules is relatively neglect Although the high degree of support is a small port of the total rules, this high-degree support of rules is more meaningful in the protein prediction. So we re-statist the chart, which has the same abscissa of support, and longitudinal coordinates is multiple the number of support with the corresponding value of support. In this case the problem domain becomes a complex measure. We believe that the statistics of distribution under such condition is closer to the real situation       Figure 5 distributions of support measure statistics in alpha rules base \(variety parameter method 5178 2009 Chinese Control and Decision Conference CCDC 2009 


   Figure 6 distributions of support measure statistics in beta rules base \(variety parameter method Through Figure 3 - Figure 6, we get the distribution of association would not be any obvious mathematical distribution, so based on the classic CBA algorithm consider a single confidence measure and solely rely on setting of support threshold is not appropriate So, we proposed an improved CBA complex measure algorithm in this paper based on the classic CBA algorithm which the new evaluation function is as follows 1 22 2 sup 1    sup   n DCBA conf i i i Score w confidence w port       conf w and sup w are parameters of support and confidence In order to facilitate the training, without loss of generality evaluation function will be rewritten as 1 sup 22 2 1 1 22 2 sup 1    sup      sup   n DCBA i i i conf n ii conf i w Score confidence port w confidence w port          When sup 0 conf w    DCBA Score   will become to  CBA Score  on contrary, when sup conf w    DCBA Score   will become to  1 sup n DCBA i i Score port      in this moment D-CBA is equal to classic CBA algorithm. Under the training of train set, we can pick up a best  sup conf w for classifier to effectively prediction alpha-protein and beta-protein 4.2 Experiment The test set of our experiment is identical of paper 13 which is the partial  /  protein database contain by the 256 B 351C, 9PAP, 1BP2 four protein sequence. Q3 is used as a evaluation criterion, which is defined to proportion of the correct number of amino acids and the total number of amino acids  Based on the complex distance measure of improved CBA algorithm, mainly in the core layer process different part of SVM multi-classification and homology analysis in layer of comprehensive analysis. As shown in Table 2 based on the support and confidence complex measure CBA algorithm compared with classic CBA algorithm in the same dataset to run on the rate of discrimination Among parameters sup conf w in D-CBA is under a trained set of the optimal parameters  sup conf w on contrary the result of classic CBA is the best result of different support threshold settings Table 2 D-CBA compared with classic CBA Model through the layer of comprehensive analysis deal with the test set, get 50.4 percent of the amino acid secondary structure was basically decided, with some obvious features of the structure, this part was 92.2 percent accuracy; further in assisted prejudgment layer and core prejudgment layer focus on the more complex amino acids to predict, the collection is divided into two parts, one is the homology sequence methods and SVM both predict to un-Coil amino acid type \(59 windows, here referred to the collection of NC\e other part is the homology sequence methods and SVM predict dissimilarly to Coil amino acid type method \(200 window, here referred to the collection of C\Collection for the NC, which generally mixed with little part of Coil structure, therefore we can be used directly based on the support and confidence complexity distance measure of improved CBA to  /  second structure prediction, the forecast accuracy is 74.6 percent. Collection of C, through SVM classification will be divided into two collections, one  part is Coil structure of the amino acid after SVM Classifier, and the other is by the rest parts Then through the SVM classifier and the KAAPRO methods, respectively 89.2 percent and 59.6 percent accuracy. Integrated part of the results in the pyramid model , the overall accuracy of the test set get 86%. The result has been more th  w h i c h  w a s pu bl i s h e d b y t h e  results of 81 percent, the results of the test is now known as the highest prediction accuracy   Table 3 result details in Q 3  5  CONCLUSION Protein secondary structure prediction is a difficult problem in the biological information domain. Based on KDTICM theory framework, we proposed an improved CBA association classifier protein secondary structure prediction algorithm which is based on complexity distance measure of support and confidence .And be its core, we built a refinement  multi-hierarchical compound pyramid model Experiments show that this model and classified algorithm D-CBA CBA Alpha protein  accuracy 79.2 51 Beta protein  accuracy 70.7 40.5 Total 74.6% 47.4 2009 Chinese Control and Decision Conference CCDC 2009 5179 


  can complete the prediction of unobvious structure of amino acid, get the understanding association rules. In some points, the model and algorithm revealed the impact relations of the physical and chemical properties of amino acids for protein secondary structure in space conformation REFERENCES 1  Thorton J M. From Genome to Function[J  Sc ie nc e  2 0 0 1   292\(5524\, 2095-2097 2  J Cohen. BioinformaticsÑan introduction for computer scientists[J  A C M Com puting Surv e y s  2004  36 2   122-158 3  Jin Lixia. Study on the Methods to Protein Structure Prediction[D  D a lia n D a lia n U n iv e r s i t y of T e c hnolog y   2002 4  A Haoudi, H Bensmail. Bioinformatics and data mining in proteomics[J Ex pe rt R e v i e w o f P r ote om ic s  200 6 3\(3   333-343 5  J Y Li, L S Wong, Q Yang. Data mining in Bioinformatics[J  IEEE Intelligent Systems, 2005, 20 \(6\ 16-18 6  H. Mannila. Theoretical Frameworks for Data Mining[J   SIGKDD Explorations, 1\(2\, \(2000\-32 7  Yang Bingru, Sun Haihong, Xiong Fanlun. Ming Quantitative association rules with standard SQL queries and itês evaluation[J J our na l of C o m pute r R e s e a r c h a n d  Development, 39\(3\, 2002: 307-312 8  Yang Bingru. Knowledge discovery based on theory of inner cognition mechanism and application[M   Electronic Industry Press, Beijing, 2004 9  Yang Bingru, Song Wei, Xu Zhangyan. New Construction of Expert System based on Knowledge Discovery[J Sc ie nc e  in China Series F, 2007, 50\(1\12 10  Yan Longfei, Sun Zhirong. Protein molecular structure[M  Tsinghua Publishing House, Beijing, 1999 11  X Wu, L Jain, J Wang et al. Data Mining in Bioinformatics rlin S p rin g e r  200 5  12  P Y Chou, G D Fasman. Conformational parameters for amino-acids in helical, beta-sheet, and random coil regions calculated from proteins[J  B i oc he m i s t r y  1974   13\(2\:211-222 13  S H Muggleton, R King, M Sternberg. Protein secondary structure prediction using logic-based machine learning[J   Protein Engineering, 1992, 5\(7\647-657 14  H N Lin, J M Chang, K P Wu, T Y Sun, W L Hsu HYPROSP II--a knowledge-based hybrid method for protein secondary structure prediction based on local prediction confidence[J  Bioinf orm a tic s  2005   21\(15\:3227-3233  5180 2009 Chinese Control and Decision Conference CCDC 2009 


Fig. 5 shows the execution time according to changes in the threshold value of weight when using SYN and UCC data. From this figure, we can see that the execution time is greatly influenced by the threshold values. In contrast, in case of file-level prefetching, the change in threshold value of weight does not give a great effect on the execution time For both SYN and UCC data, when the threshold value is set to 2, the proposed method shows the shortest execution time In case of less than 3 \(i.e., prefetching all \(or most of\e objects belonging to the generated sequential patterns excessive prefetching causes a big increase in the execution time. Conversely, as the threshold value becomes higher than the optimal value, the favorable effect from prefetching decreases gradually V  S UMMARY  In this paper, we have proposed an intelligent two-level prefetching method in which sequential pattern mining is incorporated into the FAST-aware hybrid flash-disk storage system. In our work, the hybrid storage uses the flash memory as a cache space, and we focus on prefetching file or block\objects onto prefetch \(or sequential\og blocks to be accessed in the near future through sequential pattern mining. To achieve the best performance, it is very important to determine optimal values in terms of threshold of pattern weight and the size of training data. To be noted is that the proposed method works at the level of file and block objects   b\In case of SYN data   b\In case of SYN data Figure 5: Effect of changes in weight threshold In contrast, previous studies focused on prefetching block-level objects [1 i t h si m p l e he u r i s t i c s e v e n t h o ugh they cannot be applied to hybrid storage systems. On the whole, the proposed two-level prefetching is more effective than file-level prefetching in UCC and the synthetic data Empirical results show that in terms of the execution time the proposed method improves the I/O performance of hybrid storage by about 16% and 18% for UCC and SYN data, respectively, compared to the Top-N prefetching under the FAST scheme. We submit that two-level prefetching can help to significantly enhance the future commercial hybrid storage products. In the future, we plan to study a way of semi-automatically adjusting several parameters such as the weight threshold and the size of training data for sequential pattern mining A CKNOWLEDGMENT  This work was supported by the Basic Research Program through the Korea Science and Engineering Foundation funded by the Ministry of Education, Science and Technology \(Grant Number: R01-2007-000-206490  R EFERENCES  1  Hybrid drive: Wikipedia, http://en.wikipedia.org/wiki/Hybrid_drive 2  S. L. Min and E. H Nam, ìCurrent trends in flash memory technology: invited paperî, Proceedings of the 2006 conference on Asia South Pacific design automation, 2006, pp. 332-333 3  Y.H. Bae, ìDesign Technique of High Performance Flash Memory SSD \(Solid State Disk\, Journal of Korean Institute of Information Scientists and Engineers, Vol. 25, No. 6, 2007, pp.18-28 4  E. Gal and S. Toledo, ìAlgorithms and Data Structures for Flash Memoriesî, ACM Computing Surveys, Vol. 37, No. 2,  2005, pp.138 163 5  H.J. Kim, and S.G. Lee, ìAn Effective Flash Memory Manager for Reliable Flash Memory Managementî, IEICE Transactions on Information and Systems, Vol. 85, No. 6, 2002, pp.950-964 6  S. W. Lee, D. J. Park, T. S. Ching, D. H. Lee, S. W. Park, and H. J Song, ìA Log Buffer-Based Flash Translation Layer Using FullyAssociative Sector Translationî, ACM Transactions on Embedded Computing Systems, Vol. 6, No. 3, 2007, pp.18-44 7  R. Agrawal, R. Srikant, ìMining sequential patternsî, Proceedings of the 11th International Conference on Data Engineering \(ICDE'95 1995, pp.3-14 8  P.N. Tan, M. Steinbach, and V. Kumar, Introduction to Data Mining Addison-Wesley, 2006 9  E.P. Markatos and C. Chronaki, A Top-10 Approach to Prefetching on the Web, Proceedings of the INET 98 Conference, 1998   C.I. Ezeife, Y. Lu, and Y. Liu, ìPLWAP sequential mining: open source codeî, Proceedings of the 1st international workshop on open source data mining \(OSDMí05\, 2005, pp.26-35   M.L. Chiang, Paul C.H. Lee, and R.C. Chang, ìUsing data clustering to improve cleaning performance for flash memoryî, Software Practice and Experience, Vol.29, No.3, 1999, pp.267-290   Z. Li, Z. Chen, S. M. Srinivasan and Y. Zhou, ìC-Miner: Mining Block Correlations in Storage Systemsî, Proceedings of the 3rd USENIX Conference on File and Storage Technology \(FASTí04 2004, pp.173-186  
285 


composition debugging model, are discussed in details. After the decision table is constru cted through collecting WSDL interface information, composition process specification, and testing execution information rule extraction algorithm in rough set reasoning is used to find the rules associated with system or service failures. In a ddition, the feasibility and effectiveness of our approach are validated by two examples and experiments. At present, we onl y consider the debugging problem for the common Web service system, the fault location for semantic Web services should be further explored in the on-going research A CKNOWLEDGMENT  This work was supported in part by the National Natural Science Foundation of China \(NSFC\under Grant No 60803046, China Postdoctoral Science Foundation under Grant No.2007041 0946, the Science Fo undation of Jiangxi Educational Committee under Grant No. GJJ10433, and the Youth Foundation of Jiangxi University of Finance and Economics. The author is grateful to Qiong Zhang for her warm-heart help, and thanks the anonymous reviewers for their insightful comments R EFERENCES  1 W. Han  Integrating Peer-to-Peer into Web Services Master thesis University of Saskatchewan, 2006  W3C Web S e rvi ces Activit y avai lable fro m  http://www w3.org 2002/ws/, accessed on July 2010  W o rld W i de W e b Cons ortiu m  W3C Web Services Description Language \(WSDL\ Version 1.1 March, 2001. Available at http://www. w3.org/TR/wsdl  W o r l d W i de W e b Consor tiu m  W 3C  Simple Object Access Protocol Version 1.2 April 2007, available at http://www.w3.org/TR/soap12  OASIS WSBP EL Technical Co mm i ttee  Web Services Business Process Execution Language, Version 2.0 available at http://docs oasis-open.org/wsbpel/2.0 /wsbpelv2.0.pdf  M. Aoya m a S Wee rawa rana, H Maruya m a and et al W eb  Services Engineering: Promises and Challenges Proc. of ICSEí02  ACM Press, New York 2002, pp. 647-648  C. Liu L. Fei X Yan, and et al., çStatistical Debuggin g: A Hypothesis Testing-Based Approach IEEE Transactions on Software Engineering 2006, vol. 32, no. 10, pp.1-17  W  Dickinson, D. Leon, and A Podgurski, çFinding Failures by Cluster Analysis of Execution Profiles Proc. of ICSEí01 2001, pp 339-348  Z. Li and Y Zhou, çPRM iner: Automatically Extracting Implicit Programming Rules and Detecting Violations in Large Software Code Proc. of ESEC/ FSEí05 2005, pp. 306-315  M. Renieris, and S. P Reiss, çFault LocalizationWith Nearest Neighbor Queries Proc. of ASEí03 2003, pp. 30-39  C. Liu, Z Lian and J. Han, çHow Bayesians Debug Proc. of ICDMí06 2006, pp.382-393  G. D. F a tta, S   Leue, and E. St e g antova D iscri m inative Pattern Mining in Software Fault Detection Proc. of SOQUAí06 2006 pp.62-69  M. J Harrold, G. Rotherm e l, K Sayre, and et al., çAn Empirical Investigation of the Relationship Between Fault-revealing Test Behavior and Differences in Program Spectra Journal of Software Testing Verification and Reliability 2000, vol. 10, no.3, pp. 171-194  D. Jeffrey, N. Gup ta, and R. Gupta Fault Localizatio n Using Value Replacement Proc. of ISSTAí08 2008, pp. 167-178  IBM W e b Services: Taking e-Busi ness to the Next Level White Paper, 2000, available from: http://www.ibm.com/developerworks/cn websphere/ download/pdf/e-businessj.pdf  S. Noikajana, and T. Suwannasart, çW eb Service Test Case Generation Based on Decision Table Proc. of the 8th International Conference on Quality Software \(QSICí08 2008, pp. 321-326  C M a o Per form ing Co m b inator ial Testing on W e b Ser viceBased  Software Proc. of Intíl Conf. on Computer Science and Software Engineering \(CSSEí08 2008, vol.2, pp.755-758  T  Y Chen F.C  Kuo T  H T s e and et al  M eta m or phic T e sting and Beyond Proc. of the 11th International Workshop on Software Technology and Engineering Practice \(STEPí03 2003, pp.94-100  Business Process Managem e nt Initiative Business Process Modeling Language \(BPML November, 2002  W 3 C  OWL-S: Semantic Markup for Web Services Nov. 22, 2004 available from: http://www.w3.org/ Submission/OWL-S  Z. Pawlak, çRoug h Set Intíl Journal of Information and Computer Science vol. 11, 1982, pp. 341-356  Jianhua Dai Research on Rough Set Theory and Its Applications in Knowledge Discovery \(Ph. D. Dissertation Library of Wuhan University, 2003, pp. 97104.   \(in Chinese  M Kry szkiewicz, çRou gh Set Approach to Inco m p l e t e Inform ation Systems Information Sciences 1998, vol. 112, pp. 39-49  C  M a o, çSlicing W e b Ser vicebased Softwar e Proc. of IEEE International Conference on Service-Oriented Computing and Applications \(SOCAí09 Taipei, Taiwan, December 14-15, 2009, pp 91-98  C M a o X Hu and Y L u  T owards a Softwar e Diagnosis M e tho d  Based on Rough Set Reasoning Proc. of the IEEE 8th International Conference on Computer and Information Technology \(CITí08  Sydney, Australia, July 811, 2008, pp. 718-723  I   Gr osclaude  M odelbased M o nitor ing of Co m ponentbased Software Systems Proc. of the 15th International Workshop on Principles of Diagnosis 2004, pp. 155-160  L  Ar dissono L  Console A Go y  and et al Enhancing W e b  Services with Diagnostic Capabilities Proc. of the 3rd IEEE European Conference on Web Services 2005, pp. 182-191  X Fu P Z ou  Z   Shang and et al   Fault Diagnosis f o r W e b Ser vice Composition Based on Bayesian Networké, Computer Applications 2008, vol.28, no. 5, pp. 1095-1097.   \(in Chinese   
299 


        


9 Appendix Fig 6: Forest Cover Types of the U.S. \(Source. USGS National Atlas of US Summary of Forest Cover Type Data Type Multivariate Abstract The forest cover type for 30 x 30 meter cells obtai ned from US Forest Service \(USFS\ Region 2 Resource Information System RIS\ data Data Characteristics The actual forest cover type for a given observatio n \(30 x 30 meter cell\ was determined from US Fores t Service \(USFS\ Region 2 Resource Information System RIS data Independe nt variables were derived from data originally obta ined from US Geological Survey \(USGS\ and USFS data. Data is in raw form \(not scaled\ and contains binary \(0 or 1 columns of data for qualitative independent variables \(wilderness areas and soil types Summary Statistics Number of instances observations 581012 Number of Attributes 54 Attribute breakdown 12 measures, but 54 columns of data \(10 quantitativ e variables, 4 binary wilderness areas and 40 binary soil type variables Missing Attribute Values None 43 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        






Mining Strong Af\336nity Association Patterns in Data Sets with Skewed Support Distribution Hui Xiong 000 Computer Science and Engineering Univ of Minnesota Twin Cities huix@cs.umn.edu Pang-Ning Tan Computer Science and Engineering Michigan State University ptan@cse.msu.edu Vipin Kumar Computer Science and Engineering Univ of Minnesota Twin Cities kumar@cs.umn.edu Abstract Existing association-rule mining algorithms often rely on the support-based pruning strategy to prune its combinatorial search space This strategy is not quite effective for data sets with skewed support distributions because they tend to generate many spurious patterns involving items from different support levels or miss potentially interesting low-support patterns To overcome these problems we propose the concept of hyperclique pattern which uses an objective measure called h-con\336dence to identify strong af\336nity patterns We also introduce the novel concept of crosssupport property for eliminating patterns involving items with substantially different support levels Our experimental results demonstrate the effectiveness of this method for 336nding patterns in dense data sets even at very low support thresholds where most of the existing algorithms would break down Finally hyperclique patterns also show great promise for clustering items in high dimensional space 1 Introduction Many data sets have inherently skewed support distributions For example the frequency distribution of English words appearing in text documents is highly skewed 204 while a few of the words appear many times most of the words appear only a few times Such a distribution has been observed in other application domains including retail data Web click-streams and telecommunication data This paper examines the problem of applying association analysis 1 2 t o data sets with sk e w ed support distributions Existing algorithms often use a minimum support threshold to prune its combinatorial search space Two major problems arise when applying such strategy to skewed data sets 000 Contact Author 000 If the minimum support threshold is too low many uninteresting patterns involving items with substantially different support levels are extracted We call such patterns as cross-support patterns An example of a cross-support pattern is 001 Caviar  Milk 002 where Caviar is a low support item and Milk is a high support item It is not surprising to 223nd Milk in transactions that contain Caviar since Milk is present in many transactions Cross-support patterns also tend to have very low pairwise correlations 000 If the minimum support threshold is too high many strong af\336nity patterns involving items with low support levels are missed Such patterns are useful for capturing associations among rare but expensive items such as caviar and vodka or necklaces and earrings To illustrate these problems consider the support distribution for the pumsb census data set shown in Figure 1 Pumsb is often used as benchmark for evaluating the performance of association rule algorithms on dense data sets Observe the skewed nature of the support distribution with 81.5 of the items having support less than 1 while 0.95 of them having support greater than 90   0   20   
40   60   80   100   0   500   1000   1500   2000 Support Sorted Items The Support Distribution of Pumsb Dataset 
Figure 1 The support distribution of Pumsb We can partition the items into 223ve disjoint groups based on their support levels as shown in Table 1 The group Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


Table 1 Groups of items r pumsb data set Group 000 000 000 001 000 002 000 003 000 004 Support 0-1 1%-5 5%-40 40%-90 001 90 005 Items 1735 206 101 51 20 000 000 has the lowest support level less than or equal to 1 but contains the most number of items i.e 1735 items To detect patterns involving items from 000 000  the minimum support threshold must be less than 1 but such a low threshold will degrade the performance of existing algorithms considerably Our experiments showed that stateof-the-art algorithms such as Apriori 2 Charm 16 and MAFIA break do wn when applied to pumsb at support threshold less than 40 1  Furthermore if the support threshold is low e.g 0.05 many cross-support patterns involving items from both 000 000 rare items and 000 001 very frequent items are generated Just to give an indication of the scale out of the 18847 frequent pairs involving items from 000 000 and 000 001  about 93 of them are cross-support patterns These cross-support patterns have extremely poor correlation because the presence of the item from 000 001 does not necessarily imply the presence of the item from 000 000  It would be advantageous to develop techniques that can automatically eliminate such patterns during the mining process Omiecinski recently proposed an alternative to the support measure called all-con\336dence  which represents the minimum con\223dence of all association rules extracted from an itemset Omiecinski proved that all-con\223dence has the desirable anti-monotone property that allows us to incorporate the measure directly into the mining process We call the patterns derived from this measure as hyperclique patterns  Note that we had independently proposed a measure called h-con\223dence to capture the de gree of af 223nity in a hyperclique pattern The equivalence between hcon\223dence and all-con\223dence measures is shown in Section 2 For brevity we will use the term h-con\223dence when referring to the af\223nity measure of hyperclique patterns In this paper e introduce a ovel concept called the cross-support property  which is useful for eliminating candidate patterns having items with widely differing support levels We show that h-con\223dence possesses such a property and develop an ef\223cient algorithm called hyperclique miner that utilizes both the cross-support and antimonotone properties of the h-con\223dence measure Our perimental results suggest that hyperclique miner can ef\223ciently discover strong af\223nity patterns even when the support threshold is set o zero Hyperclique patterns are also valuable patterns in their own right because they correspond to itemsets involving only tightly-coupled items Discovering such patterns can 1 This is observed on a Sun Ultra 10 workstation with a 440MHz CPU and 128 Mbytes of memory be potentially useful for a variety of applications such as item clustering copy detection and collaborative 223ltering We demonstrate one potential application of hyperclique patterns in the area of item clustering where such patterns can be used to provide high-quality hyperedges to seed the hypergraph-based clustering algorithms Related Work Support-based pruning does not work well with dense data sets nor is it effective at 223nding low support patterns The concepts of maximal 3 5 and closed itemsets 11 were proposed to address these limitations Although these concepts can identify a smaller set of representative patterns their algorithms may still break down at low support thresholds especially for data sets with skewed support distribution Both closed and maximal itemsets are also not designed to explicitly remove the cross-support patterns There has also been growing interest in developing techniques for mining association patterns without support constraints 6 Ho we v e r  such techniques are either limited to analyzing pairs of items or does not address the cross-support problem 14 2 Hyperclique Pattern In this section we describe the concept of a hyperclique pattern and introduce some important properties of the con\223dence measure 2.1 Hyperclique Pattern Concepts De\336nition 1 The h-con\336dence of an itemset 001 002 000 002 000 003\002 001 003 001\001\001 003\002 002 002  denoted as 004\005\006\007\b 003 001 004  s a measure that re\337ects the overall af\336nity among items within the itemset This measure is de\336ned as t\002\007 000 005\006\007\b 000 002 000 003 002 001 003\n\n\n 003\002 002 002 003 005\006\007\b 000 002 001 003 002 000 003\002 002 003\n\n\n 003 002 002 002 003 n\n\n 003 005\006\007\b 000 002 002 003 002 000 003 n\n\n 003\002 002 000 000 002\002  where 005\006\007\b follows from the de\336nition of association rule con\336dence Example 1 Consider an itemset 001 002 000 013\003 f 003 r 002  Assume that 016\017\020\020 003 000 013 002 004 002 005 n 000  016\017\020\020 003 000 f 002 004 002 005 n 000  016\017\020\020 003 000 r 002 004 002 005 n 005\006  and 016\017\020\020 003 000 013\003 f 003 r 002 004 002 005 n 005\006  where 016\017\020\020 is the support of an itemset Then 005\006\007\b 000 013 003 f\003 r 002  supp 000 A B C 002   000 A 002   0.6 005\006\007\b 000 f 003 013\003 r 002 002 005 n 006  and 005\006\007\b 000 r 003 013\003 f 002 002 000  Hence 004\005\006\007\b 003 001 004 002 t\002\007 000 005\006\007\b 000 f 003 013\003 r 002 003 005\006\007\b 000 013 003 f\003 r 002 003 005\006\007\b 000 r 003 013\003 f 002\002  0.6 De\336nition 2 Given a transaction database and the set of all items 021 002 000 021 000 003\021 001 003\n\n\n 003\021 003 002  n itemset 001 is a hyperclique pattern if and only if 1 001 004 021 and 005 001 005 022 005 2 004\005\006\007\b 003 001 004 006 004 004  where 004 004 is the h-con\336dence threshold A hyperclique pattern 001 is a strong-af\223nity association pattern because the presence of any item 023 007 001 in a transaction strongly implies the presence of 001 b\000 023 002 in the same Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


transaction To that end the h-con\223dence measure is designed speci\223cally for capturing such strong af\223nity relationships Nevertheless hyperclique patterns can also miss some interesting patterns e.g an itemset 000 A B C 001 that produces low con\223dence rules 000 002 001\002  001 002 000\002 and 002 002 000\001 but a high con\223dence rule 000\001 002 002  Such type of patterns are not the focus of this paper 2.2 Properties of h-con\336dence We illustrate three important properties of the hcon\223dence measure in this subsection 2.2.1 Anti-monotone Property As previously noted the h-con\223dence measure is mathematically equivalent to the all-con\223dence measure proposed by Omiecinski 10 e v en though both measures are de v eloped from different perspectives De\336nition 3 The all-con\336dence measure for an itemset 003 000 000 004 000 005\004 001 005 003\003\003 005\004 000 001 is de\336ned as 001\002\003 004 000 006\007\b\t 004 000 002 001 004\005 000\005 001 006 003\005 000 007 001 000 003\005 000 b 001 000 t\001 005 n Lemma 1 If 003 000 000 004 000 005\004 001 005 003\003\003 005\004 000 001 is an itemset then 013\006\007\b\t 004 003 005 is mathematically equivalent to allcon\336dence 004 003 005 and is equal to f\r\016\016 004 000 004 000 005\004 001 005\n\n\n 005\004 000 001 005 017\020\021 000 000 001 000 000 000 f\r\016\016 004 000 004 001 001 005 001 n 1 Omiecinski proved that all-con\223dence is an antimonotone measure i.e if an itemset 000 004 000 005\n\n\n 005\004 000 001 is above the all-con\223dence threshold so is every subset of size m-1 Since h-con\223dence is mathematically identical to all-con\223dence it is also monotonically non-increasing as the size of the hyperclique pattern increases This antimonotone property allows us to push the h-con\223dence constraint into the search algorithm Thus when searching for hyperclique patterns the support of a candidate pattern 000 004 000 005\n\n\n 005\004 000 001 is counted only if all its subsets of size m-1 are hyperclique patterns 2.2.2 Cross-Support Property In this section we introduce the concept of cross support property This property is useful to avoid generating crosssupport patterns  which are patterns containing items from substantially different support levels We also show that the h-con\223dence measure possesses such a property Before presenting the concept of 006\022 007\f\f f\r\016\016\007\022 023 property we 223rst introduce the idea of an upper bound function for a measure of association De\336nition 4 Let t be a measure of association and t 002\003\004 be its maximum possible value We de\336ne r\016\016\024\022 004 t 005 as an upper bound function for t if 005 003 006 t 004 003 005 n r\016\016\024\022 004 t 004 003 005\005  where 003 is an association pattern An upper bound function is trivial if r\016\016\024\022 004 t 005 000 t 002\003\004  For example r\016\016\024\022 004 f\r\016\016 004 003 005\005 000 007 is a trivial upper bound function for the support measure An example of a non-trivial upper bound function for the h-con\223dence measure is presented below Lemma 2 Given an itemset 003 000 000 004 000 005\n\n\n 005\004 000 001  the hcon\336dence for 003 has the following upper bound r\016\016\024\022 004 013\006\007\b\t 004 003 005\005 000 017\004\b 000 000 002 000 000 000 f\r\016\016 004 000 004 002 001 005 001 017\020\021 000 000 001 000 000 000 f\r\016\016 004 000 004 001 001 005 001 n 2 We will use the notion of upper bound function to describe cross-support property n a nutshell given a speci\223ed threshold t if a function t has the cross-support property we can 223nd two itemsets from different support levels such that for any 006\022 007\f\f f\r\016\016\007\022 023 pattern 003  we are guaranteed to have t 004 003 005 025 023  The formal de\223nition of the crosssupport property of a function t is given below De\336nition 5 Let 026 000 000 004 000 005\004 001 005 003\003\003 005\004 003 001 be an ordered set of items sorted according to their support values i.e 005 027 006 f\r\016\016 004 004 001 005 n f\r\016\016 004 004 001 005\000 005  In addition for each item 021 013 026  let 030 004 021 005 000 000 021 001 004 f\r\016\016 004 021 001 005 n f\r\016\016 004 021 005 001 and 031 004 021 005 000 000 021 001 004 f\r\016\016 004 021 001 005 f f\r\016\016 004 021 005 001  A function t satis\336es the cross-support property if r 021\005 032 013 026 such that f\r\016\016 004 021 005 025 f\r\016\016 004 032 005 and r\016\016\024\022 004 t 004 021\005 032 005\005 025 023 implies 005 003 006 t 004 003 005 025 023  where 003 is an itemset containing at least one item from 030 004 021 005 and at least one item from 031 004 032 005 and 023 is the speci\336ed threshold In the following we provide a suf\223cient condition for t to satisfy the cross-support property Theorem 1 Given 1 A measure of association t 2\A pair of items 021 and 032 with f\r\016\016 004 021 005 025 f\r\016\016 004 032 005   A pair of itemsets 030 004 021 005 000 000 021 001 004 f\r\016\016 004 021 001 005 n f\r\016\016 004 021 005 001 and 031 004 032 005 000 000 032 001 004 f\r\016\016 004 032 001 005 f f\r\016\016 004 032 005 001  If the following conditions hold 1 A non-trivial upper bound function for t exists 2 r\016\016\024\022 004 t 004 000 021\005 032 001 005\005 is computed using only f\r\016\016 004 021 005 and f\r\016\016 004 032 005  3 r\016\016\024\022 004 t 004 000 021\005 032 001 005\005 decreases monotonically with increasing f\r\016\016 004 032 005 if 021 is 336xed 4 r\016\016\024\022 004 t 004 000 021\005 032 001 005\005 decreases monotonically with decreasing f\r\016\016 004 021 005 if 032 is 336xed 5 t is an anti-monotone measure when applied to patterns of size two or more Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


Then 000 000 001 001 000 002\001\001\003\004 000 000 000 001 005\006 007 002 001\001  where 001 is a crosssupport pattern that contains at least one item from b 000 005 001 and at least one item from t 000 007 001  The proof of this theorem is given in As a consequence 002\001\001\003\004 000 000 000 001 005\006 007 002 001\001 n 013 implies 000 000 001 001 n 013 which means that 000 must satisfy the cross-support property Lemma 3 The h-con\336dence measure satis\336es the f\004 r\016\016 016\002\001\001\r\004 013 property Furthermore the h-con\336dence value for any cross-support pattern 017 002 001 005 000 000 006\005 000 001 006 020\020\020 006 005 000 000 006\007 001 000 006\007 001 001 006 020\020\020 006 007 001 001 002 has an upper bound as 002\003\004 000 000 002 000 003 000 005\006\007\007 000 000 004 002 001 001 001 002\000\b 000 000 004 000 005 000 005\006\007\007 000 000 t 004 001 001 001 Lemma 3 provides an upper bound of the h-con\223dence values for all possible cross-support patterns from two itemsets with different support levels Thus if the h-con\223dence threshold is set higher than this upper bound we will not generate any cross-support pattern as candidate hyperclique pattern during the mining process h-con\223dence is not the only measure that satis\223es the cross-support property Table 2 provides a list of other measures of association that possess such a property Among the measures that do not have the f\004 r\016\016 016\002\001\001\r\004 013 property include support and odds ratio 13 Table 2 Measures with the f\004 r\016\016 016\002\001\001\r\004 013 property Assume that 016\002\001\001 000 005 001 n 016\002\001\001 000 007 001  Measure Computation Formula Upper Bound Cosine 006\007\002\002 002 b\t\n 003 002 006\007\002\002 002 b 003 006\007\002\002 002 n 003 000 006\007\002\002 002 b 003 006\007\002\002 002 n 003 Jaccard 006\007\002\002 002 b\t\n 003 006\007\002\002 002 b 003\004 006\007\002\002 002 n 003 001 006\007\002\002 002 b\t\n 003 006\007\002\002 002 b 003 006\007\002\002 002 n 003 PS supp\(x y supp\(x 1-supp\(y 2.2.3 Strong Af\336nity Property In this subsection we investigate the relationships between h-con\223dence and other similarity measures such as cosine Lemma 4 and Jaccard Lemma 5 measures Our goal is to derive the lower bounds for these similarity measures in terms of the h-con\223dence threshold 021 n  De\336nition 6 Given a pair of items 017 002 001 022 002 006\022 003 002  the cosine measure for 017 can be computed as 005\006\007\007 000 000 000 000 013\000 001 001 001 003 005\006\007\007 000 000 000 001 003 005\006\007\007 000 000 001 001 006 while the Jaccard measure 12 for 017 is 005\006\007\007 000 000 000 000 013\000 001 001 001 005\006\007\007 000 000 000 000 001 001\004 005\006\007\007 000 000 000 001 001 001 004 005\006\007\007 000 000 000 000 013\000 001 001 001 020 Lemma 4 If 017 002 001 022 002 006\022 003 002 is a size-2 hyperclique pattern then f\r\016\022\023\003 000 017 001 004 021 n  Lemma 5 If 017 002 001 022 002 006\022 003 002 is a size-2 hyperclique pattern then 024 f\f\025\004 026 000 017 001 004 021 n 027 003  The above lemmas suggest that if 021 n is suf\223ciently high then all size-2 hyperclique patterns contain items that are strongly af\223liated with each other in terms of their cosine and Jaccard values For a hyperclique pattern that contains more than two items we can compute the average Jaccard and cosine measure for all pairs of items within this pattern Due to the antimonotone property of the h-con\223dence measure every pair of items within a hyperclique pattern must have an h-con\223dence value greater than or equal to 021 n As a result the average Jaccard or cosine measure of a hyperclique pattern must also satisfy the above lemmas 3 Hyperclique Miner Algorithm In this section we design a level-wise algorithm called hyperclique miner for discovering hyperclique patterns Example 2 We illustrate how hyperclique miner works using the running example shown in Figure 2  As can be seen the process of searching hyperclique patterns is illustrated by the generation of branches of a set-enumeration tree For this running example suppose the minimum support threshold is zero and the minimum h-con\336dence threshold is 55 There are two major pruning techniques incorporated into our algorithm 1 We can prune itemsets by the anti-monotone property of the h-con\336dence measure For instance applying Equation 1 the h-con\336dence of the candidate pattern 001 4 5 002 is supp 001 4 5 002  001 supp 001 4 002  supp 001 5 002  002  0.1/0.2  0.5 which s less than 55 Hence the itemset 001 4 5 002 is not a hyperclique pattern and is immediately pruned In turn we can prune the candidate pattern 001 3 4 5 002 by the anti-monotone property of the h-con\336dence measure since one of its subset 001 4 5 002 is not a hyperclique pattern 2 We can do pruning by the cross-support property of hcon\336dence For instance given a sorted list of items 001 1 2 3 4 5 002  suppose we split the list into two sets 030 002  001 1 2 002 and 030 003  001 3 4 5 002  We can compute the upper bound of h-con\336dence for any cross-support pattern between these two item sets by Lemma 3 In this example the upper bound is equal to max 001 supp 001 3 002  supp 001 4 002  supp 001 5 002  002 min 001 supp  001 1 002  supp 001 2 002  002  3/9 0.33 Therefore the h-con\336dence for every crosssupport pattern involving these items must be less than 33 If the h-con\336dence threshold is 55 we may prune all these cross-support patterns even before they are generated as candidate patterns Without applying cross-support pruning e have to generate six additional patterns including 001 1 3 002  001 1 4 002  001 1 5 002  001 2 3 002  001 2 4 002  and 001 2 5 002  s candidate hyperclique patterns and prune them later upon computing their actual h-con\336dence values Note that the anti-monotone Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


property does not help us to pre-prune the six candidate patterns since every subset of these patterns are hyperclique patterns according to Equation 1 the hcon\336dence values of size-1 itemsets are 1 0.2 0.8 0.2 0.2 0.1\\(0.2\\(0.2\\(0.2\\(0.1\\(0.2\\(0.1 0.1 3, 4, 5 1 3 5}{4}{2  0.25 0.2 0.3 0.9 0.9 4 3 0.2 1,2}  {1,3}  {1,4}   {1,5}{2,3} {2,4} {2,5} {3,4} {3,5} {4,5 1 2 3 4 5 6 7 8 9 10 2, 3, 5 1, 2 1, 2 0.3\\(0.9\\(0.9\Support Item TID Items 1, 2 1, 2 1, 3, 4 1, 2 1, 2 1, 2 1, 2, 3, 4, 5 2  1 SupportItem Figure 2 A running example Hyperclique Miner Input  1 a set F of 000 Boolean feature types F 000 001 000 002\001 001 002\003\003\003 002\001 000 001 2 a set T of 004 transactions T 000 005 000 003\003\003\005 001 001  each 005 002 002 006 is a record with K attributes 000 007 000 002\007 001 002\003\003\003 002\007 000 001 taking values in 000 0 1 001  where the 007 003 is the Boolean value for the feature type 001 003 for 000 003 b 003 000  3 A user speci\223ed h-con\223dence threshold  min conf  4 A user speci\223ed support threshold  min supp  Output  hyperclique patterns with h-con\223dence t n\007\013 f\r\013\001 and support t n\007\013 016\017\b\b Method  1 Get size-1 prevalent items 2 Construct item sets at different levels of support 3 for size of itemsets in 2 3 003\003\003  000 004 000  do 4 Generate candidate hyperclique patterns 5 Prune based on the support measure 6 Prune based on the h-con\223dence measure 7 Generate hyperclique patterns Algorithm Description The Hyperclique Miner prunes the exponential search space based on the following three conditions 1 Pruning based on anti-monotone property of h-con\223dence and support 2 Pruning based on the upper bound of h-con\223dence By Lemma 2 if the upper bound for 020\f\r\013\001 001 f 002 is less than 020 004  then 020\f\r\013\001 001 f 002 must also be less than 020 004  We can easily compute the upper bound of the h-con\223dence for any candidate itemset since the support for every individual item is stored in memory 3 Pruning by the f\021 r\016\016 016\017\b\b\r\021 005 property of h-con\223dence 4 Hyperclique-based Item Clustering This section describes how to use hyperclique patterns for clustering items in high dimensional space For high dimensional data traditional clustering schemes such as K-means tend to produce poor results when directly applied to large high-dimensional data sets One promising approach proposed by Han et al is to cluster the data using a hypergraph partitioning algorithm More speci\223cally a hypergraph is constructed with individual items as vertices and frequent itemsets as hyperedges connecting between these vertices r example if 000 A B C 001 is a frequent itemset then a hyperedge connecting the vertices for A B and C will be added The weight of the hyperedge is given y the average con\223dence of all association rules generated from the corresponding itemset The resulting hypergraph is then partitioned using a hypergraph partitioning algorithm such as HMETIS http://www.cs.umn.edu 005 karypis/metis/hmetis/index.html to obtain clusters Although the hypergraph-based clustering algorithm has produced promising results it can be further impro v e d if the initial hypergraph contains a good representative set of high-quality hyperedges Frequent itemsets may not provide such a good representation because they include crosssupport patterns which may have ow af\223nity but relatively high average con\223dence In addition many low support items cannot be covered by frequent itemsets unless the minimum support threshold is suf\223ciently low However if the threshold is indeed low enough a large number of frequent itemsets will be extracted thus resulting in a very dense hypergraph It will be dif\223cult for a hypergraph partitioning algorithm to partition such a dense hypergraph which often leads to poor clustering results In this paper we use hyperclique patterns as an alternative to frequent itemsets In the hypergraph model each hyperclique pattern is represented by a hyperedge whose weight is equal to the h-con\223dence of the hyperclique pattern r example if 000 022\002 023 002 024 001 is a hyperclique pattern with the h-con\223dence equals to 0.8 then the hypergraph contains a hyperedge that connects the vertices 022  023 and 024  The weight for this hyperedge is 0.8 There are several advantages of using the hypercliquebased clustering algorithm First since hyperclique patterns are strong af\223nity patterns they can provide a good representative set f hyperedges to seed a hypergraph-based clustering algorithm Second hyperclique patterns can be extracted for very low support items without making the hypergraph becomes too dense Finally hyperclique-based Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


clustering algorithm is also more tolerant to noise compared to traditional clustering algorithms such as k-means because it can explicitly remove the weakly related items 5 Experimental Evaluation r evaluation purposes we have performed our experiments on real data sets obtained from several application domains The characteristics of these data sets are summarized in Table 3 Table 3 Real Data set Characteristics Data set Item Record Avg Length Source Pumsb 2113 49046 74 IBM Almaden S&P 500 932 716 75 Stock Market Retail 14462 57671 8 Retail Store The pumsb data set corresponds to a binary version of a census data set Retail is a masked data set obtained from a large mail-order company In addition the stock market data set contains events representing the price movement of various stocks that belong to the S&P 500 index from January 1994 to October 1996 All experiments were performed on a Sun Ultra 10 workstation with a 440 MHz CPU and 128 Mbytes of memory running the SunOS 5.7 operating system Note that we have implemented hyperclique miner as an extension to the publicly available implementation of the Apriori algorithm by Borgelt http://fuzzy.cs.uni-magdeburg.de 000 borgelt As a result the performance of hyperclique miner is almost equivalent to Apriori when the h-con\223dence threshold is set to zero 5.1 The Pruning Effect of Hyperclique Miner The purpose of this experiment is to demonstrate the effectiveness of the h-con\223dence pruning on hyperclique pattern generation Recently the CHARM algorithm was proposed by Zaki et to ef 223ciently disco v e r frequent closed itemsets As shown in their paper for a dense data set with skewed support distribution such as 000\001\002\003\004  CHARM can achieve relatively better performance than other stateof-the-art pattern mining algorithms such as CLOSET and MAFIA when the support threshold is lo w  Hence we chose CHARM as the baseline to compare against the performance of hyperclique miner on dense data sets even though hyperclique miner and CHARM are actually targeted towards different kinds of patterns Figure 3 shows the number of patterns generated by hyperclique miner and CHARM on the pumsb data set As can be seen the number of patterns discovered by our algorithm is several orders of magnitude smaller than the number of patterns found by CHARM provided that the  100 1000 10000 100000 1e+06 1e+07 1e+08 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 Number of Hyperclique Patterns Minimum Support Thresholds Confidence-Pruning Effect min_conf = 95  min_conf = 90   min_conf = 85   CHARM  Figure 3 The effect of h-con\223dence pruning in terms of the number of patterns generated 10 100 1000 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 Execution Time \(sec Minimum Support Thresholds min_conf = 95  min_conf = 90   min_conf = 85   CHARM  Figure 4 The effect of h-con\223dence pruning in terms of execution time h-con\223dence threshold is suf\223ciently high In addition CHARM has dif\223culties in identifying patterns when the support threshold is less than or equals to 0.4 However our technique identi\223es many strong af\223nity patterns with very low support r instance we obtain a long pattern containing 9 items with the support 0.23 and h-con\223dence 94.2 Recall from Table 1 that nearly 96.6 of the items have support less than 0.4 With a support threshold greater than 0.4 CHARM can only identify associations among a very small fraction of the items Figure 4 shows the relatively performance of hyperclique miner and CHARM on pumsb data set With h-con\223dence pruning we can use hyperclique miner to identify hyperclique patterns even at support threshold equal to zero 5.2 Quality of Hyperclique Patterns Table 4 shows some of the interesting hyperclique patterns extracted from the retail data set r example we identi\223ed a hyperclique pattern involving closely related items such as Nokia battery Nokia adapter and Nokia cell phone We also discovered several interesting patterns containing very low support items such as 001 earrings gold ring bracelet 002  These items are expensive rarely bought by customers and belong to the same product category Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


Table 4 Hyperclique Patterns from Retail Hyperclique patterns support h-conf 000 earrings gold ring bracelet 001 0.019 45.8 000 nokia battery nokia adapter nokia cell phone 001 0.049 52.8 000 coffee maker can opener toaster 001 0.014 61.5 000 baby bumper pad diaper stacker baby crib sheet 001 0.028 72.7 000 skirt tub 3pc bath set shower curtain 001 0.26 74.4  0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 20 40 60 80 100 Average Correlation Percentile  Non-hypercliques   Hypercliques  Figure 5 Average Correlation We also evaluated the af\223nity of hyperclique patterns by the correlation measure Speci\223cally for each hyperclique pattern 000 000 000 001 000 002\001 001 002 001\001\001 001 000 002  we calculate the correlation for each pair of items 001 001 001 002\001 002 002 within the pattern The overall correlation of a hyperclique pattern is then de\223ned as the average pair wise correlation Note that this experiment was conducted on Retail data set with the h-con\223dence threshold 0.8 and the support threshold 0.0005 Figure 5 compares the average correlation for hyperclique patterns versus non-hyperclique patterns We sorted the average correlation and displayed them in increasing order Notice that the hyperclique patterns have extremely high average pair wise correlation compared to the nonhyperclique patterns This result supports our previous assertion that hyperclique patterns can identify itemsets that contain only tightly-coupled items 5.3 Hyperclique-based Item Clustering In this section we illustrate the application of hyperclique patterns as an alternative to frequent patterns in hypergraph-based clustering approach W e use the S&P 500 index data set for our clustering experiments Table 5 shows the dramatic increase in the number of frequent patterns as the minimum support threshold is decreased As can be seen the number of frequent patterns increases up to 11,486,914 when we reduce the support threshold to 1 If all these frequent itemsets are used for hypergraph clustering this will create an extremely dense hypergraph and s the hypergraph-based clustering algorithm becomes computationally intractable In the authors have used a higher minimum support threshold i.e 3 for their experiments and obtained 19,602 frequent itemsets covering 440 items A hypergraph consisting of 440 vertices and 19,602 hyperedges was then constructed and 40 partitions were generated Out of 40 partitions 16 of them are clean clusters as they contain stocks primarily from the same or closely related industry groups Table 5 Number of frequent patterns Support No of frequent patterns items covered 3 19602 440 2 149215 734 1 11486914 915 With hyperclique patterns we can construct hypergraphs at any support threshold and thus covering more items r instance with a minimum h-con\223dence threshold 20 and a support threshold 0 we obtain 11,207 hyperclique patterns covering 861 items A hypergraph consisting of 861 vertices and 11,207 hyperedges is then constructed and partitioned into smaller clusters For comparison purposes we partitioned the hypergraph into 80 partitions to ensure that the average size of clusters is almost the same as the average size of the 40 clusters obtained using frequent patterns Note that for both approaches we only use patterns containing two or more items as hyperedges Our experimental results suggest that the hyperclique pattern approach can systematically produce better clustering results than the frequent pattern approach First many items with low levels of support are not included in the frequent pattern approach Speci\223cally there are 421 items covered by hyperclique pattern based clusters that are not covered by frequent pattern based clusters Second the hypergraph clustering algorithm can produce a larger fraction of clean clusters using hyperclique patterns than frequent patterns 204 1 out of 80 partitions versus 16 out of 40 partitions Third all the clean clusters identi\223ed by the frequent pattern approach were also present in the results by the hyperclique pattern approach Finally for the same clean cluster identi\223ed by both approaches there are more same category items included by the hyperclique based approach Table 6 shows some of the clean hyperclique pattern based clusters that appear at low levels of support around 1 support Such clusters could not be identi\223ed by the frequent pattern approach As the table shows our hyperclique pattern approach was able to discover retail chemical  health-product power and communication clusters A complete list of clusters is given n Technical Report We have also applied the graph-partitioning scheme in CLUTO 2  This algorithm takes the adjacency matrix of the similarity graph between the n objects to be clustered as input The experiment results indicate that this approach can produce much worse clustering results than the hypercliquebased approach r instance out of the 80 clusters derived 2 http://www.cs.umn.edu 000 karypis/cluto/index.html Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


Table 6 Some clean clusters No Discovered Clusters Industry Group 1 Becton Dickinso 000  Emerson Electric 000 AmerHome Product 000  Johnson  Johnson 000  Merck 000  P\223zer 000  Schering-Plough 000  Warner-Lambert 000 health product 2 duPont EI deNemo 001  Goodrich B.F 001  Nalco Chemical 001  Rohm  Haas 001  Avon Products 001 chemical 3 Federated Dept 001 GapInc 001  Nordstrom Inc 001 PepBoysMan 001  Sears 001 TJX 001 Walmart 001 Retail 4 Bell Atlantic Co 001  BellSouth Corp 001 CPCIntl 001  GTE Corp 001  Ameritech Corp 001  NYNEX Corp 001  Paci\223c Telesis 001  SBC Communication 001 USWest Communication 001 Comm 5 Baltimore Gas 000  CINergy Corp 000  Amer Electric Power 000  Duke ower 000  Consolidated Edi 000  Entergy Corp 000 Genl Public Util 000  Houston Indus 000  PECO Energy 000 Texas Utilities 000 Power by CLUTO less than 30 of them are clean clusters This result is not surprising since the graph-partitioning scheme considers only information about pairs of items but not higher order interactions In addition we also applied the improved version of the k-means clustering algorithm in CLUTO When using cosine as the similarity measure we were able to identify 36 clean clusters out of 80 clusters which is worse than the hyperclique pattern approach Finally we observed the following effects of the hyperclique-based clustering approach If we set the minimum support threshold to 0 and h-con\223dence threshold to 20 the discovered hyperclique patterns cover 861 items Since there are 932 items in total the hyperclique pattern mining algorithm must have eliminated 71 items We amine the distribution of these 71 items in the CLUTO means clustering results We observe that 68 of the items are assigned to the wrong clusters by CLUTO As a result we believe that the items not covered by these hyperclique patterns are potentially noise items 6 Conclusions In this paper e formalized the problem of mining perclique patterns in data sets with skewed support distribution We also introduced the concept of cross-support property and showed how this property can be used to avoid generating spurious patterns involving items from different support levels Furthermore a ew algorithm called hyperclique miner was eveloped This algorithm utilizes crosssupport and anti-monotone properties of h-con\223dence for the ef\223cient discovery of hyperclique patterns Finally we demonstrated applications of hyperclique patterns for discovering strong af\223nity patterns among low-support items and for hyperclique-based item clustering For future work there is a potential for using the hyperclique concept in a variety of applications such as dimensionality reduction copy detection and collaborative 223ltering Also it is valuable to exploit the 000\001 002\003\003 003\004\005\005\002\001 006 property on some other interestingness measures Acknowledgments This work was partially supported by NASA grant  NCC 2 1231 NSF grant  ACI-9982274 DOE contract  DOE/LLNL W-7045-ENG-48 and by Army High Performance Computing Research Center contract number DAAD19-01-2-0014 Also we would like to thank Dr Mohammed J Zaki for providing us the CHARM code and Dr Johannes Gehrke for providing us the MAFIA code Finally we would like to thank Dr Shashi Shekhar Dr Ke Wang and Mr Michael Steinbach for valuable comments References  R Agra w a l T  Imielinski and A  S w a mi Mining association rules between sets of items in large databases In Proc of the M SIGMOD  pages 207\205216 May 1993  R Agra w a l and R Srikant F ast algorithms for mining association rules In Proc of the 20th VLDB  1994  R J Bayardo Ef 223ciently mining long patterns from databases In Proc of the M SIGMOD  1998  S Brin R Motw ani and C Silv erstein Be yond mark et baskets Generalizing assoc iation rules to correlations In Proc of the M SIGMOD  pages 265\205276 1997  D Burdick M Calimlim a nd J Gehrke Ma\223a A m aximal frequent itemset algorithm for transactional databases In Proc of the ICDE  2001  E Cohen M Datar  S  Fujiw ara A Gionis P  Indyk R Motwani J Ullman and C Yang Finding interesting associations without support pruning In ICDE  2000  E Han G Karypis and V  K umar  H yper graph based clustering in high-dimensional data sets A summary of results Bulletin of the chnical Committee on Data Engineering  21\(1 March 1998  T  Hastie R  T ibshirani a nd J Friedman The Elements of Statistical Learning Data Mining Inference and Prediction  Springer 2001  A Jain and R  Dubes Algorithms for Clustering Data Prentice Hall 1998  E Omiecinski A lternati v e i nterest measures for mining associations In IEEE TKDE  Jan/Feb 2003  J Pei J Han and R  M ao C loset An ef 223cient algorithm for mining frequent closed itemsets In DMKD  May 2000  C J V  Rijsber gen Information Retrieval 2nd Edition  Butterworths London 1979  P  T a n V  K u mar  and J Sri v asta v a  Selecting the right inter estingness measure for association patterns In Proc of the Eighth M SIGKDD  2002  K W a ng Y  He D Cheung and Y  Chin Mining con\223dent rules without support requirement In M CIKM  2001  H Xiong P  T a n and V  K umar  M ining h yperclique patterns with con\223dence pruning In chnical Report 03-006 Computer Science Univ f Minnesota  Jan 2003  M Zaki and C.-J Hsiao Charm An ef 223cient algorithm for closed itemset mining In Proc of the 2nd SDM  2002 Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


of the query expression without ha ving the global view of the in ten tion There is a big c hance that the enco ded pro cedure ma y not b e the b est w a y to compute the rules dep ending on the database instance F urthermore as w e understand it their prop osals require p oten tially large n um ber of name generation for relations and attributes The names that are needed are usually database dep enden t and th us p ossibly cannot b e gathered at query time An additional pro cess needs to b e completed to gather those v ariables b efore actual computations can b egin 5  9 Optimization Issues While it w as in tellectually c hallenging to dev elop a declarativ e expression for asso ciation rule mining from deductiv e databases there are sev eral op en issues with great promises for resolution In the w orst case the least xp oin tneedsto generate n 2 tuples in the rst pass alone when the database size is n  Theoretically  this can happ en only when eac h transaction in the database pro duces an in tersection no de and when they are not related b y subset-sup erset relationship In the second pass w e need to do n 4 computations and so on The question no w is can w e a v oid generating and p erhaps scanning some of these com binations as they will not lead to useful in tersections F or example the no de b 0 3 in gure 11 is redundan t A signican t dierence with apriori lik e systems is that our system generates all the item sets top do wn in the lattice without taking their candidacy as a large item set in to consideration Apriori on the other hand do es not generate an y no de if their subsets are not large item sets themselv es and thereb y prunes a large set of no des Optimization tec hniques that exploit this so called an ti-monotonicit y prop ert y of item set lattices similar to apriori could mak e all the dierence in our setup The k ey issue w ould b e ho ww e push the selection threshold minim um supp ort inside the top do wn computation of the no des in the lattice in our metho d F or the momen t and for the sak e of this discussion let us consider a higher supp ort threshold of 60 for the database T of gure 9 No w the l-en v elop e will b e the one sho wn in ligh ter dashed lines in gure 11 and the no des under this line will b e the large item sets Notice that no ww eha v eto discard no des ad 2 0 and d 0 2 to o This raises the question is it p ossible to utilize the supp ort and condence thresholds pro vided in the query and prune candidates for in tersection an y further Ideas similar to magic sets transformation 3  24 ma y be b orro w ed to address this issue The only problem is that pruning of an y no de dep ends on its supp ort coun t whic h ma y come at a later stage By then all no des ma y already ha v e b een computed and th us pushing selection conditions inside aggregate op erator ma y b ecome non-trivial Sp ecial data structures and indexes ma y also aid in dev eloping faster metho ds to compute ecien t interse ction joins that w e ha v e utilized in this pap er W e lea v e these questions as op en issues that should be tak en up in the future F ortunately though there has been a v ast b o dy of researc h in optimizing Datalog programs including recursiv e programs suc h as the one w e ha v e used in this pap er and hence the new questions and researc h 5 Recall that their prop osal requires one to express the mining problem to the system using sev eral queries and up date statemen ts that utilizes information ab out the database con ten ts to ac hiev e its functionalit y  c hallenges that this prop osal raises for declarativ e mining ma y exploit some of these adv ances Needless to emphasize a declarativ e metho d preferably a formal one is desirable b ecause once w e understand the functioning of the system w e will then be able to select appropriate pro cedures dep ending on the instances to compute the seman tics of the program whic hw e kno wis in tended once w e establish the equiv alence of declarativ e and pro cedural seman tics of the system F ortunately  w e ha v e n umerous pro cedural metho ds for computing asso ciation rules whic h complemen t eac h other in terms of sp eed and database instances In fact that is what declarativ e systems or declarativit y buy us  a c hoice for the most ecien t and accurate pro cessing p ossible 10 Conclusion Our primary goal for this pap er has b een to demonstrate that mining asso ciation rules from an y rst-order kno wledge base is p ossible in a declarativ ew a y  without help from an y sp ecial to ols or mac hinery  and that w e can no wha v ea v ery in tuitiv e and simple program to do so W eha v esho wn that it is indeed p ossible to mine declarativ ekno wledge b y exploiting the existing mac hinery supp orted b ycon temp orary inference engines in programming languages e.g Prolog or kno wledge base systems e.g RelationLog XSB LD L  CORAL All w e require is that the engine b e able to supp ort set v alued terms grouping aggregate functions and set relational op erators for comparison functionalities whic hmostofthesesystemscurren tly supp ort W e ha v e also demonstrated that our formalism is grounded on a more mathematical foundation with formal prop erties on whic h the seman tics of the R ULES system rely  W e ha v e also raised sev eral op en issues related to eciency and query optimization whic h should b e our next order of business As future researc h w e plan to dev elop optimization tec hniques for mining queries that require non-trivial lo ok ahead and pruning tec hniques in aggregate functions The dev elopmen ts presen ted here also ha v e other signican t implications F or example it is no w p ossible to compute c hi square rules 4 using the building blo c ks pro vided b y our system Declarativ e computation of c hi square rules to our kno wledge has nev er b een attempted for the man y pro cedural concepts the computation of c hi square metho d relies on In a separate w ork 2 w e sho w that the coun ting metho d prop osed in this pap er can be eectiv ely utilized to generate the exp ectations needed in order to compute suc h rules rather easily  These are some of the issues w e plan to address in the near future The motiv ation imp ortance and the need for in tegrating data mining tec hnology with relational databases has b een addressed in sev eral articles suc h as 12  13 They con vincingly argue that without suc h in tegration data mining tec hnology ma y not nd itself in a viable p osition in the y ears to come T o b e a successful and feasible to ol for the analysis of business data in relational databases suc htec hnology m ust b e made a v ailable as part of database engines and as part of its declarativ e query language Our prop osal for declarativ e mining bears merit since it sheds ligh t on ho w rst order databases can be mined in a declarativ e and pro cedure indep enden t w a y so that the optimization issues can b e delegated to the underlying database engine Once suc h argumen ts are accepted sev eral systems 9 


related issues b ecome prime candidates for immediate atten tion F or example traditionally database systems supp orted declarativ e querying without the necessit y to care ab out the pro ceduralit y of the queries In this pap er w eha v e actually demonstrated that asso ciation rule mining can b e view ed as a Datalog query  It is immediate that a direct mapping from the Datalog expressions presen ted in this pap er to SQL can be dev elop ed with no problem at all W e can then rely on ecien t database pro cessing of the query in an optimized fashion Hence w ecomeclose to the essence of the visions expressed b y the leading database researc hers and practioners 12  References 1 Rak esh Agra w al and Ramakrishnan Srik an t F ast algorithms for mining asso ciation rules in large databases In VLDB  pages 487{499 1994 2 Anon ymous A declarativ e metho d for mining c hisquare rules from deductiv e databases T ec hnical rep ort Departmen t of Computer Science Anon ymous Univ ersit y USA F ebruary 2001 3 C Beeri and R Ramakrishnan On the po w er of magic In Pr o c e e dings of the 6th A CM Symp osium on Principles of Datab ase Systems  pages 269{283 1987 4 Sergey Brin Ra jeev Mot w ani and Craig Silv erstein Bey ond mark et bask ets Generalizing asso ciation rules to correlations In Pr o c A CM SIGMOD  pages 265 276 1997 5 D Chimen ti et al The LD L system protot yp e IEEE Journal on Data and Know le dge Engine ering  2\(1 90 1990 6 Jia w ei Han Jian P ei and Yiw en Yin Mining frequen t patterns without candidate generation In Pr o c A CM SIGMOD  pages 1{12 2000 7 Marcel Holsheimer Martin L Kersten Heikki Mannila and Hann uT oiv onen A p ersp ectiv e on databases and data mining In Pr o c of the sixth A CM SIGKDD Intl Conf  pages 150{155 Mon treal Queb ec 1995 8 Flip Korn Alexandros Labrinidis Y annis Kotidis and Christos F aloutsos Ratio rules A new paradigm for fast quan tiable data mining In Pr o c of 24th VLDB  pages 582{593 1998 9 Brian Len t Arun N Sw ami and Jennifer Widom Clustering asso ciation rules In Pr o c of the 3th ICDE  pages 220{231 1997 10 Mengc hi Liu Relationlog At yp ed extension to datalog with sets and tuples In John Llo yd editor Pr oc e e dings of the 12th International L o gic Pr o gr amming Symp osium  pages 83{97 P ortland Oregon Decem ber 1995 MIT Press 11 Rosa Meo Giusepp e Psaila and Stefano Ceri An extension to SQL for mining asso ciation rules Data Mining and Know le dge Disc overy  2\(2 1998 12 Amir Netz Sura jit Chaudh uri Je Bernhardt and Usama M F a yy ad In tegration of data mining with database tec hnology  In Pr o c e e dings of 26th VLDB  pages 719{722 2000 13 Amir Netz Sura jit Chaudh uri Usama M F a yy ad and Je Bernhardt In tegrating data mining with SQL databases In IEEE ICDE  2001 14 Ra ymond T Ng Laks V S Lakshmanan Jia w ei Han and Alex P ang Exploratory mining and pruning optimizations of constrained asso ciation rules In Pr o c A CM SIGMOD  pages 13{24 1998 15 Jong So o P ark Ming-Sy an Chen and Philip S Y u An eectiv e hash based algorithm for mining asso ciation rules In Pr o c A CM SIGMOD  pages 175{186 1995 16 Karthic k Ra jamani Alan Co x Bala Iy er and A tul Chadha Ecien t mining for asso ciation rules with relational database systems In Pr o c e e dings of the International Datab ase Engine ering and Applic ations Symp osium  pages 148{155 1999 17 R Ramakrishnan D Sriv asta v a and S Sudarshan CORAL  Con trol Relations and Logic In Pr o c of 18th VLDB Confer enc e  pages 238{250 1992 18 Konstan tinos F Sagonas T errance Swift and Da vid Scott W arren XSB as an ecien t deductiv e database engine In Pr o c of the A CM SIGMOD Intl Conf  pages 442{453 1994 19 Sunita Sara w agi Shib y Thomas and Rak esh Agra w al In tegrating mining with relational database systems Alternativ es and implications In Pr o c A CM SIGMOD  pages 343{354 1998 20 Ashok a Sa v asere Edw ard Omiecinski and Shamk an tB Nav athe An ecien t algorithm for mining asso ciation rules in large databases In Pr o c of 21th VLDB  pages 432{444 1995 21 Pradeep Sheno y  Ja y an t R Haritsa S Sudarshan Gaura v Bhalotia Ma y ank Ba w a and Dev a vrat Shah T urb o-c harging v ertical mining of large databases In A CM SIGMOD  pages 22{33 2000 22 Abraham Silb ersc hatz Henry F Korth and S Sudarshan Datab ase System Conc epts  McGra w-Hill third edition 1996 23 Shib y Thomas and Sunita Sara w agi Mining generalized asso ciation rules and sequen tial patterns using SQL queries In KDD  pages 344{348 1998 24 J D Ullman Principles of Datab ase and Know le dgeb ase Systems Part I II  Computer Science Press 1988 25 Mohammed J Zaki Generating non-redundan t association rules In Pr o c of the 6th A CM SIGKDD Intl Conf  Boston MA August 2000 1 0 


OM OM 006 OD8 01 012 014 016 018 02 022 False alarm demity Figure 9 Percentage of tracks lost within 200 seconds using three-scan assignment with PD  0.9 TI  O.ls Figure 11 T2  1.9s and T  Is ij  20 and 0  0.1 24 1 22  20  E fls 0  8l 16 0 n 14  12  0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 T1/12 PD Average track life of three-scan assignment with PD varying TI  0-ls T2  1.9s T  Is X  0.02 ij LO and   0.1 mareuvenng index Figure 12 Percentage of lost tracks of 4-D assipment in 200 seconds with maneuvering index varying X  0.01 Ti  0.1 T2  1.9s and T  IS PD  0.98 Figure 10 Percentage of lost tracks of 4-D assignment in 200 SeoDllCls with TI and T2 varying PD  0.98 X  0.02 q 20 and 0  0.1 4-1607 


Figure 13 Average gate size for Kalman filter Figure is relative as compared to nq and curves are parametrized by ij/r with unit-time between each pair of samples 1.2 Iy I 1.1 0.5 I A CRLB for he unifm samiina I  0.4 0.35 d 3 03 i7 3 0.25 0 0.M 0.04 0.06 008 0.1 0.12 0.14 0.16 0.18 0.2 False A!am DemW V I    Figure 14 CramerRao Lower Boundfor Mean Square Error of uniform and nonuniform sampling schemes with Ti  O.ls T2  1.9s T  IS PD  0.9 ij  5 and U  0.25 1 unifon sampling r-ls ked i non-uniform sampling loge inlewi I ti non-uniform sampling shod interva I 0.9 0.8 I Figure 15 MSE comparison of three-scan assignment with Ti and T2 varying I'D  1 X  0.01 ij  20 and U  0.1 4-1608 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



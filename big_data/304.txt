A Systematic Method to Design a Fuzzy Data Mining Model Yo-Ping Huang Ya-Hui Ke and Chi-Peng Ouyang Dept of Computer Science and Engineering Tatung University Taipei Taiwan 1045 1 R.O.C E-mail yphuang@cse.ttu.edu.tw Abstract-Based on the available transaction records we use AprioriTid model to derive the association rules from large database We then exploit association rules to establish an initial fuzzy inference model A novel tuning method is proposed to adjust the fuzzy model such that every association rule from data mining model can in turn help us recommend the most 
appropriate products to the prospective customers By combining the Larsen\222s inference method and gradient descent method we derive a systematic approach to refine the fuzzy model Thus a new adjusting method i.e Larsen-like is proposed in this paper How to derive the association rules from large database how to apply the derived rules to establishing a fuzzy inference model and how to optimize the fuzzy model are illustrated by simple examples I INTRODUCTION Fuzzy logic-based models and systems can be found everywhere in our daily life. Washing machine, refrigerator and air conditioner are among the frequently used household appliances that have used the fuzzy technique 
Thus fuzzy set theory attracts more and more attentions since Zadeh introduced it in 1965 6 In fuzzy set theory users can use the given data to define membership functions to characterize an element with a fuzzy subset Whenever the input and output variables are known, we can use some training data to design a rule base to model the behavior of the to-be-controlled system Users can also apply some techniques to adjusting the fuzzy model to a satisfactory performance 7-81 Similar to fuzzy set theory the extension theory 5 investigates how to formalize our concepts to solve the incompatible or contradictory problems In our daily life domain experts can handle many things without difficulty 
Whenever a question is asked, most people can give an exact or nearly correct answer intuitively or through some sort of thinking How can we integrate the conceptual ideas into helping solve the complicated problems The Laplace transformation used in the engineering field provides such a good example. In extension theory, let\222s define the name of a matter by N one of the characteristics of the matter by CR and the value about CR by V We use an ordered ternary R=\(N CR V as the fundamental element to describe a matter for transformation and call it a matter element  As shown in 9 the extension theory can combine with the fuzzy theory to enhance the performance 
of a fuzzy model Recently data mining technique becomes more and more important in e-commerce In the Internet-based commerce, a better personal service is a key to make profits Data mining Kent Lin CRM Department Neiman Marcus Dallas TX 75201 U.S.A E-mail Kent-Lin@neimanmarcus.com means a process to extract useful information from a large database l-31 If we can discover more useful association rules from a large database we can provide better service for customers In a database containing sales transactions it is important to exploit some techniques to discover the implicit relationship inside the transactions In today\222s business data mining provides another way for a company to realize the personalized service to its customers Unlike conventional models that only concerned whether items appeared 
simultaneously in the transactions we propose a deeper model that also considers some important factors such as purchased quantity and total expenditure during the mining process. Therefore, this paper exploits the association rules to derive a fuzzy inference model that is called a fuzzy data mining model 11 ASSOCIATION RULES AND FUZZY CLUSTERING As we know a fuzzy rule base can be derived directly from numerical data. Traditionally, fuzzy clustering methods, such as fuzzy c-means and mountain clustering, can help group the training data to establish the fuzzy rule base. In this paper, we apply the association rules derived from transaction database as a mean to clustering the data patterns 2 I Association rules 
from lalge database The process of data mining can be divided into two steps 1 find all frequent item sets and 2 generate strong association rules from the frequent item sets I Two criteria are used to measure the frequent item sets. Traditionally, both minimum support and confidence are defined in advance to find the frequent item sets. The support value from grouping item A with item B is defined as follows 1 _tuples-coniaining_both_ A-and B   transactions Support A B  Similarly, the confidence value from relating item A to item B is defined as follows 
  tuples  containing  both  A  and  B   tuples  containing  A Confidence\(A  B  f 2 Based on the predefined support and confidence values we can find whether two or more items appear frequent enough in the transactions. Different methods have been proposed to find the association rules. Apriori algorithm 4 finds frequent 0-7803-7280-8/02/$10.00 02002 IEEE 896 


item sets by using the candidate generation. Apriori employs an iterative approach known as level-wise search where k-item sets are used to explore k+l sets A two-step process which consists of joining and pruning actions that look at how Lk-1 is used to find L  is required The joining step is defined to find Lk  a set of candidate k-items generated by joining Lk-1 with themselves In the pruning step all candidates ck  having items no less than the minimum support are fiequent by definition AprioriTid is a refined version of the original Apriori algorithm 4 The feature of the AprioriTid is that the database is not used for counting support after the first pass. Thus much time can be saved. The Boolean method is another approach to obtaining the association rules In the Boolean algorithm two major steps are needed. First, both logical OR and AND operations are used to compute the frequent item sets Second logical AND and XOR operations are applied to deriving all interesting association rules. As can be seen that the Apriori AprioriTid and Boolean algorithms can derive the association rules without difficulty The problem is how to modify the conventional models such that they can provide more valuable information for today\222s business. In this paper we select AprioriTid method to obtain the association rules 2.2 Fuzzy clustering The AprioriTid method in data mining allows us to derive the large item sets step by step For example large 3-item sets are obtained from large 2-item sets. Based on this knowledge we can use the first two items as the premise variables and the third one as the consequent variable in fuzzy rules Since different attributes such as retailed price may associate with a product We focus on the price factor in ow fuzzy model with the hope to recommend the appropriate products to customers to fulfill a personalized service In ow example we analyze the purchasing behavior from 20,000 transactions Since we are conceming the price factor the transactions that spent less than 100 dollars were removed from our records Based on this observation, the distribution of the retailed prices is roughly divided into three parts each corresponding to a fuzzy subset as shown in Fig 1 For example we use Low L Medium M and High H for price in Fig 1 The purpose here corresponds to categorize the grocery and to quickly establish an initial fuzzy rule base in accordance with the price factor if no other clustering method is used The application of fuzzy clustering in target selection from large databases for direct marketing DM purposes is discussed in IO Association rules from a large database are used as training patterns The results obtained from a well-tuned fuzzy inference model are applied to deriving what class of items should be recommended to prospective customers 111 THE PROPOSED MODEL Previous models generated the association rules by considering whether the interesting items exist simultaneously or not Most models did not consider the number of purchased quantity total expenditure or seasonal factor in a single transaction. As we know in wholesale stores customers usually buy multiple pieces of the same item As a result, the purchased quantity should be carefully considered Due to the world wide economic recession and high unemployment rate people will control their own budget Thus, in this paper we extract the factor of retailed price from the association rules and put it into the fuzzy model Take the transaction records in Table 1 for example It means that the first customer bought item-A, item-B and item-C with prices 19 24 and 23 dollars respectively The second customer bought item-D item-E and item-F with prices 48 487 and 134 respectively. Although each customer bought three items the total expenditure is quite different. Some customers prefer to buy low-priced products but some enjoy having high-priced items. Thus, the relationship among the products in the first transaction is different from the second one Our purpose is to establish a fuzzy model to enhance the personalized service 3 I Matter-element analysis We apply the matter-element model discussed in extension theory to constructing our new model As we know the retailed price for each item is already given in the transaction record When considering from the aspect of retailed price we can express the transaction in terms of matter-element model as follows For example item-A in the first transaction in Table 1 can be expressed by The membership degree for item-A in the hzzy subset L is determined by the membership hctions defined in Fig 1 Similarly item-B in the first transaction can be expressed either by R  item  name price membership degree RA  item  A price pL A  RB  item  B price pL B or R  item  B price pM B  It happens that two or more consecutive membership functions may include a given price and result in different rules to fire From Table 1 the association rule from the first transaction can be derived as follows RA  item  AB price pL A x pL B or RA  item  AB price pL A x pM B  Similarly, the association rule from the second transaction can be obtained as follows R  item  DE, price pM D x pH E or R  item  DE, price pH D x pH E  Having analyzed from the transaction records when both item-A and item-B have been purchased customers may continue purchasing item-C we may derive the following 0-7803-7280-8/02/$10.00 92002 IEEE 897 


fuzzy rules If item-A is FA and item-B is FB  then item-C is FC  Note that FA FB  and FCi are linguistic variables defined for item-A item-B and item-C respectively Assuming three labels low L medium M and high H are selected for all premise and consequent variables in our model Depending on the distribution of the data different labels may be used in different cases. Besides, the fuzzy rules may take other types in consequent parts 8 The next step is to establish the hzzy inference rule base such that we can have an idea what kind of next item should be recommended to prospective customers. Fig 2 illustrates the procedures for our fuzzy inference model When minimum support is 0.1 and confidence is 40 we obtained 244 association rules for 3-large item sets as shown in Fig. 3 We use those 244 patterns as our training data for the fuzzy rule base similar to the one depicted in Table 2 When the minimum support value is increased, the number of rules reduces from 244 to only 16 as depicted in Fig 4 Furthermore in Fig 5 we plot the 1 2 and 3-large item sets Fig 6 shows part of the 244 association rules from our data mining model 3.2 The gradient descent method forfuzzv models A roughly established fuzzy model needs further optimization to meet the control or identification requirement better. For example, adjusting the centers and spreads of the triangular membership functions can affect the firing degrees of the fuzzy rules. Define the error function as follows 3 1 E=y\(yc yd 9 where yc and yd denotes the inferred and desired outputs respectively. Assuming the parameters to be adjusted in fuzzy models are pi's The quantity of pi to be adjusted in each iteration can be obtained by taking the first derivatives of B I  from Eq.\(3 As long as the quantity of pi to be adjusted is determined the new pi can be updated as follows 4 where y is the preset learning rate For example the consequent part y in singleton-type hzzy rule is adjusted by the combination of chain rules and gradient descent method as follows a W;\(t+l t hi c In Eq.\(5 7 represents the prearranged learning rate Similarly, if the triangular membership functions are used taking the first derivatives of the error function with respect to the centers and spreads of the membership functions allow us to systematically adjust the fuzzy models When the consequent part is a fuzzy number the conventional gradient descent method is not directly applicable to this kind of fuzzy model if the center of area defuzzification method is used 9 To apply the gradient descent method to refining a fuzzy model the expression of the conventional center of area method must be reformulated Suppose that in a specific fuzzy system three fuzzy rules are fired. Next we will use Fig 7 to illustrate how the center of area method works and how a crisp output is inferred In Fig 7 yL and yR correspond to the left and the right margins to which the inferred outputs mapped respectively pl  p2  and p3 are the assumed firing degrees from the fired fuzzy rules. The center of area method calculates the center of gravity of the fuzzy output for the control action Assuming the discretization numbers are m and the corresponding control output at the discrete pointj is yj  we have inferred output yc  PiYj yc  6 C Pi i=l Depending on the discretization numbers of output space selected the defuzzification outputs may differ a little bit Before deriving a crisp output by the center of area method formulated in Eq.\(6 the sampling steps must be determined in advance By letting the discretization number be m then the step size will be 7 Based on the definition of center of area method we can reformulate the numerator of Eq.\(6 as follows m i=l C piyi  P~YL  PZ A U m YL  1 As a result, the center of area method expressed in Eq.\(6\can be rewritten as follows m 5 piyi 5 Pi  c i  1 i=l i=l F pi  yc  c Pi i=l i=l 9 i=l It is clear that the new defuzzification formula is independent of yi and is more convenient for us to combine with the gradient descent method to adjust the fuzzy model Before investigating how to formally adjust a fuzzy model let us introduce a different inference method i.e the Larsenk inference method 0-7803-7280-8/02/$10.00 02002 IEEE 898 


Let pa represent the firing degree from the premise part of the ith fuzzy rule and  be the corresponding triangular membership functions are used By defining the have dE  api  8 4   8  membership degree for the current output. Suppose that only premise firing degrees of fuzzy rules by a product form we iA-Yc Y AIpa l-pb 16  YC Yd di Lp p=l Note that in Eq.\(lO uy and by correspond to the center and left or right spread of the ith fuzzy subset for thejth input variable respectively In Eq.\(ll ci and dj stand for the center and spread for the output membership function respectively In this paper we present a Larsen's-like implication method to adjust the fuzzy model The firing degrees from the premise parts are obtained by the minimum operations in the original Larsen's inference method Here the minimum operations for the premise parts are replaced by the product ones and the consequent parts are remained in the product forms to allow us to obtain the gradient descent method Therefore, our modified method is termed as the Larsen's-like one to distinguish it from the original method. Based on this modification the inference degree for the consequent part will become We can derive the Larsen's-like gradient descent method as follows pi  pa  pb  12 z  z c a~i 2Pa dA ay 4Jc  aPo 3Ay ay    p=l 13 p=l 0-7803-7280-8/02/$10.00 02002 IEEE As illustrated in Fig 2 the procedures to derive our model can be summarized as follows 1 Use conventional method such as AprioriTid algorithm to obtain the large-item sets For example we can proceed from large 1-itemset A to large 2-itemset AB and then to large 3-itemset ABC 2 Express the interesting items by matter-element models 3 Denote the interesting items in smaller large-item set Lk-1 as the conditional part and the item joined to Lk-l to generate the larger Lk as the consequent part in the fuzzy rules. Establish a fuzzy rule base from the derived association rules 4 Use the hzy inference model to infer the quantity of candidate item for the prospective customers IV EXPERIMENTAL PROCESS To illustrate how the proposed model works with the conventional methods we use 20,000 data from a large database including 143,114 transactions to run the simulations We first exploit the AprioriTid method to extract the association rules. Fig 3 shows the joining result when the minimum support is 0.1 YO and minimum confidence is 40 For comparison Fig 4 shows the joining result when the minimum support is increased to 0.15 Both Fig. 3 and Fig 4 explain what will the next item be as shown in the right-hand-side shopping cart when two items have been purchased as shown in the left-hand-side shopping cart\Comparing Fig 3 with Fig 4 it is quite clear that association rules decrease whenever either the minimum support or confidence is increased. Fig 5 plots the large 1-, 2 and 3-itemset when different conditions are set. Fig 6 is the association rules from our data mining model Again the higher the thresholds, the lower the number in large item set For example, there are 100 patterns of 3-large item set \(i.e three items appeared simultaneously in the same transaction when minimum support is 0.1  However, the quantity drops to 8 when minimum support is set to 0.15%. Since we use a double-input and single-output system to verify our model 244 association rules shown in Fig 6 serve as our training patterns in our example We propose a new model to derive the fuzzy rule base from the final association rules By integrating the final association rules shown in Fig 6 the transaction records in our database, the methods discussed in the third section, and the rule base from fuzzy c-means we can adjust the fuzzy model We pick 138 data from Fig 6 to serve as our training patterns. Conventional fuzzy c-means method is exploited to cluster the data. The clustering results are plotted in Fig 8 The clustering results are then projected into each coordinate 899 


to construct the initial membership functions as shown in Fig 9 to Fig 11 Depending on the types of fuzzy rules used Eq.\(3 to Eq.\(16\are applied to refining our fuzzy models The purpose to establish such a fuzzy inference model is focused on providing personalized services to prospective customers. For example there are 547 patterns in 2-large item set in Fig 5 Part of the 2-item sets joins another item to become the 3-large item set By taking the 2-itemset as the two premise variables and the third item in the corresponding 3-itemset as the consequent variable in the fuzzy rules we can apply the refined fuzzy model to inferring the suitable products that can be recommended to the prospective customers to buy them By the way we can automatically forward any news or catalog closely related to the inferred item to the customers\222 electronic mails or websites to realize the personalized services and in turn to increase the company\222s profits This is why we emphasize that we dedicate to combine the proposed fuzzy model with the association rules to provide a better service to the prospective customers We will report our simulation results later Comparison with previous work is also under investigation V CONCLUSION In this paper we combined the fuzzy inference model with the association rules from the large database to fulfill the personalized service We created a new model that not only considered the association between interesting items but also took the factor of purchased quantity into account This proposed model is particularly suitable to the wholesale stores However the same technique can be easily applied to situations whenever different factors need to be considered The process to derive the large-item sets was illustrated by examples How to establish the fuzzy inference model was also discussed in detail. Finally, we explained how to use the fuzzy model to recommend the most suitable items to the prospective customers. Our results verified that the proposed model is also useful in different areas ACKNOWLEDGMENTS This work was supported by the National Science Council Taiwan, R.O.C., under Grant NSC90-2213-E-036-013 and by Tatung University under grant B90- 1600-0 1 References J Han and M Kamber Data mining: concepts and techniques Morgan Kaufmann Publishers San Francisco, CA, 2001 S.Y Wur and Y H Leu 223An effective Boolean algorithm for mining rules in large database,\224 Pmc 61h Int Con on Database Systems for Advanced Applications pp. 179 1 86, 1999 M.-S Chen J Han and P.S Yu 223Data mining an overview from a database perspective,\224 IEEE Trans on Knowledge and Data Engineering vol 8 no 6 pp.866-883, Dec. 1996 R Agrawal and R Srikant 223Fast algorithms for mining association rules in large databases,\224 Proc 2flh Int Con Very Large Data Bases pp.478-499, Sept. 1994 0-7803-7280-8/02/$10.00 02002 IEEE ___ W Cai, \223The extension set and incompatible problem,\224 J of Scientific Exploration vol 1 pp.81-93, 1983 L.A. Zadeh, \223Fuzzy sets,\224 Information and Control vol 8 pp.338-353 1965 K Nozaki H Ishibuchi and H Tanaka 223A simple but powerful heuristic method for generating fuzzy rules from numerical data,\224 Fuzzy Sets andSystems vol. 86, pp.251-270, 1997 M Sugeno and T Yasukawa 223A fuzzy-logic-based approach to qualitative modeling,\224 IEEE Trans Fuzzy Systems vol 1 no 1 pp.7-31 1993 Y.-P Huang and H.-J Chen, \223Using the transformed data to construct an extension-based fuzzy inference model,\224 in Proc. 9th IEEE Int Con on Fuzzv Svstems San Antonio TX USA 00.823-828. Mav 2000   I.L I IO M. Setnes and U. Kaymak, \223Fuzzy modeling of client preference from large data sets An application to target selection in direct marketing,\224 IEEE Trans on,ruzzy Systems vol 9 no 1 February. 2001 I I Y Saygin and 0 Ulusoy, \223Automated construction of fuzzy event sets and its application to active databases,\224 IEEE Trans on Fuzzy Systems vol 9 no 3, June 2001 TABLE 1 A SIMPLE TRANSACTION TABLE TABLE 2. A FUZZY RULE BASE FOR DOUBLE INPUTS AND SINGLE OUTPUT DERIVED FROM 3-LARGE ITEMSET LMH H MHH Fig 1 The membership functions for the variable 223price.\224 900 1 Fig 2 The framework of fuzzy inference procedures 


I Cluster1 I 1-large itemsec 2-larye itemser 4 3-largc iVmse1 Fig 3 Part of the three-item association rules from minimum support=o.l and minimum confidence40 Totally there are 244 association rules I ClwterZ I I I I Fig 5 Part of the large itemsets from minimum support=O.l% and minimum confidence=40%. There are 353, 547 and 100 patterns for I-large 2-large Fig 6 The generated 244 association rules from our data mining model with minimum support=O 1  and minimum confidence40Yo Y Fig 8 The symbols 2210\222 and 221*\222 denote the 9 and 13 clustering centers respectively, from 138 data 1 A Fig 9 The initial membership functions for the first premise variable, item-A from the clustering result 224 1 B 191327 lRlRR 110114 Fig 10 The initial membership functions for the second premise variable item-B, from the clustering result P 4 1 C Fig 1 1 The initial membership functions for the consequent variable, item-C from the clustering result 0-7803-7280-8/02/$10.00 a002 IEEE 901 


References 1 A garw al, R., Aggarw al, C., an d Prasad V., A tree projection algorithm for generation of frequent itemsets. In Proceedings of High Performance Data Mining Workshop Puerto Rico, 1999 2 A graw al R an d Srikan t, R F a st al go rith ms f o r mining association rules In Proceedings of the 20 th VLDB conference pp. 487-499, Santiago Chile, 1994 3 B uc hne r  A  a nd M u l v e nna M   D  D i sc ov e r i n g internet marketing intelligence through online analytical Web usage mining SIGMOD Record  4\ 27, 1999 4 C har n iak  E  Statistical language learning MIT Press, 1996 5 C l i f t o n, C a n d Co ol e y R., T opCa t  da t a  m i ni ng for topic identification in a text corpus. In Proceedings of the 3rd European Conference of Principles and Practice of Knowledge Discovery in Databases Prague, Czech Republic, 1999 6  Coole y  R M obasher  B., an d Sr iv astav a J., Data preparation for mining World Wide Web browsing patterns Journal of Knowledge and Information Systems 1\ 1, 1999 7 C hen, M  S Par k J. S a nd Y u  P S  Data mining for path traversal patterns in a Web environment In Proceedings of 16th International Conference on Distributed Computing Systems  1996 8 Han, E H, Bole y  D., Gini, M Gr oss R   Hastings, K., Karypis, G., Kumar, V., and Mobasher, B., More, J., Document categorization and query generation on the World Wide Web using WebACE Journal of Artificial Intelligence Review January 1999 9 Her lock er  J K onstan, J., B o r c her s, A., Rie d l, J  An algorithmic framework for performing collaborative filtering. To appear in Proceedings of the 1999 Conference on Research and Development in Information Retrieval August 1999 10 Han, E H, K a r y pis, G., K u m a r  V., and M o basher  B., Clustering based on association rule hypergraphs. In Proccedings of SIGMOD\22297 Workshop on Research Issues in Data Mining and Knowledge Discovery \(DMKD\22297 May 1997 11 Han, E H, K a r y pis, G., K u m a r  V., and M o basher  B., Hypergraph based clustering in highdimensional data sets: a summary of results IEEE Bulletin of the Technical Committee on Data Engineering 21\ 1, March 1998 12 Jo ach im s T F r eitag  D., Mitch e ll T   WebWatcher: A Tour Guide for the World Wide Web. In Proceedings of the International Joint Conference in AI \(IJCAI97 August 1997 1 L i eb e r man   H Letizia: an agen t th at assists W e b browsing. In Proceedings of the 14 th International Joint Conference in AI \(IJCAI95 AAAI Press Menlo Park, California, 1995 14 Nasr a oui O F r i g ui, H., Jos h i, A., K r ishnap u r a m  R., Mining Web access logs using relational competitive fuzzy clustering. To appear in the Proceedings of the Eight International Fuzzy Systems Association World Congress August 1999 15 Pe r k ow i t z M  a nd E t z i oni O A d a p t i v e W e b sites: automaticlly synthesizing Web pages. In Proceedings of Fifteenth National Conference on Artificial Intelligence Madison, WI, 1998 16 Sp ilio p o u l o u  M a n d  F a u l stich  L  C., W U M: A Web Utilization Miner In Proceedings of EDBT Workshop WebDB98 Valencia, Spain, LNCS 1590, Springer Verlag, 1999 17 Sc he c h t e r  S., K r i s hna n, M a nd Sm i t h M  D   Using path profiles to predict HTTP requests. In Proceedings of 7th International World Wide Web Conference Brisbane, Australia, 1998 1 Sh ard a n a n d   U., Maes, P So cial inf o rmatio n filtering: algorithms for automating "word of mouth." In Proceedings of the ACM CHI Conference 1995 1 Sh ah ab i C., Zarkesh  A. M Ad i b i J  and  Sh ah V., Knowledge discovery from users Web-page navigation. In Proceedings of Workshop on Research Issues in Data Engineering  Birmingham, England, 1997 2 Yan  T  Jaco b s en M Garcia-Mo lin a, H., Da y a l U., From user access patterns to dynamic hypertext linking. In Proceedings of the 5 th International World Wide Web Conference, Paris France, 1996 


results are shown in Table 4 6 Conclusions mem \(M mem M associative classification 1 efficiency at handling huge Table 4 The comparison of CBA and CMAR on main memory usage Dataset Auto Hypo Ion0 Sick Please note that in this experiment we disable the lim itation of number of rules in CBA In such a setting CBA and CMAR generate all the rules necessary for classifica tion and thus are compared in a fair base From the table one can see that on average CMAR achieves 77.12 sav ing on main memory usage The saving in main memory usage can be explained from two apsects First CMAR uses CR-tree The compactness of CR-tree brings significant gain in storing a large set of rules where many items in the rules can be shared On the other hand CR-free is also an index structure of rules Before a rule is inserted into a CR-tree CMAR checks if there is a general rule or some more specific rules in the tree If so related pruning is pursued immediately Such a pruning techique also contributes to the saving of main memory To test the scalability of CMAR we compare the run time of CBA and CMAR on six data sets The results are shown in Figure 5 Again we disable the limit on number of rules in CBA In the experiments CBA spends a large portion of runtime on YO  attr  cls  rec CBA runtime CMAR runtime 25 7 205 612s 408s 25 2 3163 92s 19s 34 2 351 150s 89s 29 2 2800 74s 13s Sonar I 60 I 2  208 1 226s 145s Table 5 The runtime of CBA and CMAR As can be seen from the table CMAR is faster than CBA in many cases Please be note that the machine we use for testing is with relatively small size of main memory 128M Both CBA and CMAR can be expected running significantly faster if more main memory is available racy 2 it prunes rules effectively based on confidence correlation and database coverage and 3 its efficiency is achieved by extension of an efficient frequent pat tern mining method FP-growth construction of a class distribution-associated FP-tree and applying a CR-tree structure to store and retrieve mined association rules effi ciently Our experiments on 26 databases in UCI machine learning database repository show that CMAR is consis tent highly effective at classification of various kinds of databases and has better average classification accuracy in comparison with CBA and C4.5 and is more efficient and scalable than other associative classification methods References I R Agrawal and R Srikant Fast algorithms for mining as 2 P Clark and T Niblett The CN2 induction algorithm Ma 3 G Dong X Zhang L Wong and J Li Caep Classifi sociation rules In VLDB\22294 Chile Sept 1994 chine Learning 3:261-283,1989 cation by aggregating emerging patterns In DS\22299 LNCS I72 I Japan Dec 1999 4 R Duda and P Hart Pattern Classification and Scene Anal ysis John Wiley  Sons 1973 5 J Han J Pei and Y Yin Mining frequent patterns without candidate generation In SIGMOD\222OO Dallas TX May 2000 6 B Lent A Swami, and J Widom Clustering association rules In ICDE\22297 England April 1997 7 W Li Classification based on multiple association rules M.Sc Thesis Simon Fraser University April 2001 8 T.-S Lim W.-Y Loh and Y.-S Shih A comparison of prediction accuracy complexity and training time of thirty-three old and new classification algorithms Machine Learning 39,2000 9 B Liu W Hsu and Y Ma Integrating classification and association rule mining In KDD\22298 New York NY Aug 1998 IO J R Quinlan C4.5 Programs forkfachine Learning Mor gan Kaufmann 1993 I I K. Wang S Zhou and Y He Growing decision tree on support-less association rules In KDD\222OO Boston MA Aug 2000 376 


of the query expression without ha ving the global view of the in ten tion There is a big c hance that the enco ded pro cedure ma y not b e the b est w a y to compute the rules dep ending on the database instance F urthermore as w e understand it their prop osals require p oten tially large n um ber of name generation for relations and attributes The names that are needed are usually database dep enden t and th us p ossibly cannot b e gathered at query time An additional pro cess needs to b e completed to gather those v ariables b efore actual computations can b egin 5  9 Optimization Issues While it w as in tellectually c hallenging to dev elop a declarativ e expression for asso ciation rule mining from deductiv e databases there are sev eral op en issues with great promises for resolution In the w orst case the least xp oin tneedsto generate n 2 tuples in the rst pass alone when the database size is n  Theoretically  this can happ en only when eac h transaction in the database pro duces an in tersection no de and when they are not related b y subset-sup erset relationship In the second pass w e need to do n 4 computations and so on The question no w is can w e a v oid generating and p erhaps scanning some of these com binations as they will not lead to useful in tersections F or example the no de b 0 3 in gure 11 is redundan t A signican t dierence with apriori lik e systems is that our system generates all the item sets top do wn in the lattice without taking their candidacy as a large item set in to consideration Apriori on the other hand do es not generate an y no de if their subsets are not large item sets themselv es and thereb y prunes a large set of no des Optimization tec hniques that exploit this so called an ti-monotonicit y prop ert y of item set lattices similar to apriori could mak e all the dierence in our setup The k ey issue w ould b e ho ww e push the selection threshold minim um supp ort inside the top do wn computation of the no des in the lattice in our metho d F or the momen t and for the sak e of this discussion let us consider a higher supp ort threshold of 60 for the database T of gure 9 No w the l-en v elop e will b e the one sho wn in ligh ter dashed lines in gure 11 and the no des under this line will b e the large item sets Notice that no ww eha v eto discard no des ad 2 0 and d 0 2 to o This raises the question is it p ossible to utilize the supp ort and condence thresholds pro vided in the query and prune candidates for in tersection an y further Ideas similar to magic sets transformation 3  24 ma y be b orro w ed to address this issue The only problem is that pruning of an y no de dep ends on its supp ort coun t whic h ma y come at a later stage By then all no des ma y already ha v e b een computed and th us pushing selection conditions inside aggregate op erator ma y b ecome non-trivial Sp ecial data structures and indexes ma y also aid in dev eloping faster metho ds to compute ecien t interse ction joins that w e ha v e utilized in this pap er W e lea v e these questions as op en issues that should be tak en up in the future F ortunately though there has been a v ast b o dy of researc h in optimizing Datalog programs including recursiv e programs suc h as the one w e ha v e used in this pap er and hence the new questions and researc h 5 Recall that their prop osal requires one to express the mining problem to the system using sev eral queries and up date statemen ts that utilizes information ab out the database con ten ts to ac hiev e its functionalit y  c hallenges that this prop osal raises for declarativ e mining ma y exploit some of these adv ances Needless to emphasize a declarativ e metho d preferably a formal one is desirable b ecause once w e understand the functioning of the system w e will then be able to select appropriate pro cedures dep ending on the instances to compute the seman tics of the program whic hw e kno wis in tended once w e establish the equiv alence of declarativ e and pro cedural seman tics of the system F ortunately  w e ha v e n umerous pro cedural metho ds for computing asso ciation rules whic h complemen t eac h other in terms of sp eed and database instances In fact that is what declarativ e systems or declarativit y buy us  a c hoice for the most ecien t and accurate pro cessing p ossible 10 Conclusion Our primary goal for this pap er has b een to demonstrate that mining asso ciation rules from an y rst-order kno wledge base is p ossible in a declarativ ew a y  without help from an y sp ecial to ols or mac hinery  and that w e can no wha v ea v ery in tuitiv e and simple program to do so W eha v esho wn that it is indeed p ossible to mine declarativ ekno wledge b y exploiting the existing mac hinery supp orted b ycon temp orary inference engines in programming languages e.g Prolog or kno wledge base systems e.g RelationLog XSB LD L  CORAL All w e require is that the engine b e able to supp ort set v alued terms grouping aggregate functions and set relational op erators for comparison functionalities whic hmostofthesesystemscurren tly supp ort W e ha v e also demonstrated that our formalism is grounded on a more mathematical foundation with formal prop erties on whic h the seman tics of the R ULES system rely  W e ha v e also raised sev eral op en issues related to eciency and query optimization whic h should b e our next order of business As future researc h w e plan to dev elop optimization tec hniques for mining queries that require non-trivial lo ok ahead and pruning tec hniques in aggregate functions The dev elopmen ts presen ted here also ha v e other signican t implications F or example it is no w p ossible to compute c hi square rules 4 using the building blo c ks pro vided b y our system Declarativ e computation of c hi square rules to our kno wledge has nev er b een attempted for the man y pro cedural concepts the computation of c hi square metho d relies on In a separate w ork 2 w e sho w that the coun ting metho d prop osed in this pap er can be eectiv ely utilized to generate the exp ectations needed in order to compute suc h rules rather easily  These are some of the issues w e plan to address in the near future The motiv ation imp ortance and the need for in tegrating data mining tec hnology with relational databases has b een addressed in sev eral articles suc h as 12  13 They con vincingly argue that without suc h in tegration data mining tec hnology ma y not nd itself in a viable p osition in the y ears to come T o b e a successful and feasible to ol for the analysis of business data in relational databases suc htec hnology m ust b e made a v ailable as part of database engines and as part of its declarativ e query language Our prop osal for declarativ e mining bears merit since it sheds ligh t on ho w rst order databases can be mined in a declarativ e and pro cedure indep enden t w a y so that the optimization issues can b e delegated to the underlying database engine Once suc h argumen ts are accepted sev eral systems 9 


related issues b ecome prime candidates for immediate atten tion F or example traditionally database systems supp orted declarativ e querying without the necessit y to care ab out the pro ceduralit y of the queries In this pap er w eha v e actually demonstrated that asso ciation rule mining can b e view ed as a Datalog query  It is immediate that a direct mapping from the Datalog expressions presen ted in this pap er to SQL can be dev elop ed with no problem at all W e can then rely on ecien t database pro cessing of the query in an optimized fashion Hence w ecomeclose to the essence of the visions expressed b y the leading database researc hers and practioners 12  References 1 Rak esh Agra w al and Ramakrishnan Srik an t F ast algorithms for mining asso ciation rules in large databases In VLDB  pages 487{499 1994 2 Anon ymous A declarativ e metho d for mining c hisquare rules from deductiv e databases T ec hnical rep ort Departmen t of Computer Science Anon ymous Univ ersit y USA F ebruary 2001 3 C Beeri and R Ramakrishnan On the po w er of magic In Pr o c e e dings of the 6th A CM Symp osium on Principles of Datab ase Systems  pages 269{283 1987 4 Sergey Brin Ra jeev Mot w ani and Craig Silv erstein Bey ond mark et bask ets Generalizing asso ciation rules to correlations In Pr o c A CM SIGMOD  pages 265 276 1997 5 D Chimen ti et al The LD L system protot yp e IEEE Journal on Data and Know le dge Engine ering  2\(1 90 1990 6 Jia w ei Han Jian P ei and Yiw en Yin Mining frequen t patterns without candidate generation In Pr o c A CM SIGMOD  pages 1{12 2000 7 Marcel Holsheimer Martin L Kersten Heikki Mannila and Hann uT oiv onen A p ersp ectiv e on databases and data mining In Pr o c of the sixth A CM SIGKDD Intl Conf  pages 150{155 Mon treal Queb ec 1995 8 Flip Korn Alexandros Labrinidis Y annis Kotidis and Christos F aloutsos Ratio rules A new paradigm for fast quan tiable data mining In Pr o c of 24th VLDB  pages 582{593 1998 9 Brian Len t Arun N Sw ami and Jennifer Widom Clustering asso ciation rules In Pr o c of the 3th ICDE  pages 220{231 1997 10 Mengc hi Liu Relationlog At yp ed extension to datalog with sets and tuples In John Llo yd editor Pr oc e e dings of the 12th International L o gic Pr o gr amming Symp osium  pages 83{97 P ortland Oregon Decem ber 1995 MIT Press 11 Rosa Meo Giusepp e Psaila and Stefano Ceri An extension to SQL for mining asso ciation rules Data Mining and Know le dge Disc overy  2\(2 1998 12 Amir Netz Sura jit Chaudh uri Je Bernhardt and Usama M F a yy ad In tegration of data mining with database tec hnology  In Pr o c e e dings of 26th VLDB  pages 719{722 2000 13 Amir Netz Sura jit Chaudh uri Usama M F a yy ad and Je Bernhardt In tegrating data mining with SQL databases In IEEE ICDE  2001 14 Ra ymond T Ng Laks V S Lakshmanan Jia w ei Han and Alex P ang Exploratory mining and pruning optimizations of constrained asso ciation rules In Pr o c A CM SIGMOD  pages 13{24 1998 15 Jong So o P ark Ming-Sy an Chen and Philip S Y u An eectiv e hash based algorithm for mining asso ciation rules In Pr o c A CM SIGMOD  pages 175{186 1995 16 Karthic k Ra jamani Alan Co x Bala Iy er and A tul Chadha Ecien t mining for asso ciation rules with relational database systems In Pr o c e e dings of the International Datab ase Engine ering and Applic ations Symp osium  pages 148{155 1999 17 R Ramakrishnan D Sriv asta v a and S Sudarshan CORAL  Con trol Relations and Logic In Pr o c of 18th VLDB Confer enc e  pages 238{250 1992 18 Konstan tinos F Sagonas T errance Swift and Da vid Scott W arren XSB as an ecien t deductiv e database engine In Pr o c of the A CM SIGMOD Intl Conf  pages 442{453 1994 19 Sunita Sara w agi Shib y Thomas and Rak esh Agra w al In tegrating mining with relational database systems Alternativ es and implications In Pr o c A CM SIGMOD  pages 343{354 1998 20 Ashok a Sa v asere Edw ard Omiecinski and Shamk an tB Nav athe An ecien t algorithm for mining asso ciation rules in large databases In Pr o c of 21th VLDB  pages 432{444 1995 21 Pradeep Sheno y  Ja y an t R Haritsa S Sudarshan Gaura v Bhalotia Ma y ank Ba w a and Dev a vrat Shah T urb o-c harging v ertical mining of large databases In A CM SIGMOD  pages 22{33 2000 22 Abraham Silb ersc hatz Henry F Korth and S Sudarshan Datab ase System Conc epts  McGra w-Hill third edition 1996 23 Shib y Thomas and Sunita Sara w agi Mining generalized asso ciation rules and sequen tial patterns using SQL queries In KDD  pages 344{348 1998 24 J D Ullman Principles of Datab ase and Know le dgeb ase Systems Part I II  Computer Science Press 1988 25 Mohammed J Zaki Generating non-redundan t association rules In Pr o c of the 6th A CM SIGKDD Intl Conf  Boston MA August 2000 1 0 


OM OM 006 OD8 01 012 014 016 018 02 022 False alarm demity Figure 9 Percentage of tracks lost within 200 seconds using three-scan assignment with PD  0.9 TI  O.ls Figure 11 T2  1.9s and T  Is ij  20 and 0  0.1 24 1 22  20  E fls 0  8l 16 0 n 14  12  0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 T1/12 PD Average track life of three-scan assignment with PD varying TI  0-ls T2  1.9s T  Is X  0.02 ij LO and   0.1 mareuvenng index Figure 12 Percentage of lost tracks of 4-D assipment in 200 seconds with maneuvering index varying X  0.01 Ti  0.1 T2  1.9s and T  IS PD  0.98 Figure 10 Percentage of lost tracks of 4-D assignment in 200 SeoDllCls with TI and T2 varying PD  0.98 X  0.02 q 20 and 0  0.1 4-1607 


Figure 13 Average gate size for Kalman filter Figure is relative as compared to nq and curves are parametrized by ij/r with unit-time between each pair of samples 1.2 Iy I 1.1 0.5 I A CRLB for he unifm samiina I  0.4 0.35 d 3 03 i7 3 0.25 0 0.M 0.04 0.06 008 0.1 0.12 0.14 0.16 0.18 0.2 False A!am DemW V I    Figure 14 CramerRao Lower Boundfor Mean Square Error of uniform and nonuniform sampling schemes with Ti  O.ls T2  1.9s T  IS PD  0.9 ij  5 and U  0.25 1 unifon sampling r-ls ked i non-uniform sampling loge inlewi I ti non-uniform sampling shod interva I 0.9 0.8 I Figure 15 MSE comparison of three-scan assignment with Ti and T2 varying I'D  1 X  0.01 ij  20 and U  0.1 4-1608 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



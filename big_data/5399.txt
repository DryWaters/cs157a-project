A real time index model for big data based on DC-Tree 
ABSTRACT 000 
Due to the low efficiency and poor real-time performance of actual query in big data , this paper puts forward a new multidimensional big data real-time query mode which is based on a dynamic indexing structure and the corresponding real-time query and dynamic insertion algorithm. It utilizes the Z curve to reduce  dimension of multidimensional data,adopt Bloom Filter realize discrete 
 DanWei Chen Information Security Laboratory, Nanjing University of Posts and Telecommunications, Nanjing 210003, Jiangsu Province, P. R. China  chendw@njupt.edu.cn  
Keywords big data;Z curve;Bloom Filter;DC-Tree 
storage and parallel computing, Meanwhile it enhances the real-time performance of data by using dynamic indexing structure DC-Tree. The results of experimental show that the model not only improves the query efficiency of big data but also improve the real-time effect of data 
INTRODUCTION With the rapid development of Internet, social networking, mobile applications become increasingly hot as we can see,the amount of data in the network information increase rapidly, big data which is as a new concept of data and information carrier is defined.The explosive growth of data allows us to enter the era of 
I 
 
 
large-scale data analysis, which is characterized by computationally intensive and requires large-scale concurrent storage and processing capabilities. How to extract valuable information  from the mass of data quickly, timely and effectively is the urgent problem to solve There are two kinds of mainstream technologies about Large-scale data analysis currently: \(1\ in the 1980s,Teradata and Gamma's research projects which was as the represent of parallel database developed gradually,is was composed by a series of operators.The output stream of the former operator is the next operator's input stream.Record passed these operators sequentially by the way of pipeline.As a result,their method had high 
performance. \(2\Parallel computing framework about a shared-nothing" simple functional programming is composed of Distributed File System GFS,it supports hundreds of millions of searches every day.Apache's Hadoop is an open source implementation of Map Reduce.But these large-scale data processing technology is difficult to meet real-time requirements, and more for off-line data processing.Literature[2 an a l y zed th e  advantages and disadvantages of these two techniques,architectural differences and similarities.Hadoop is more of a ETL tool,the relationship between the two is complement rather than compete Jun Zhuang  Information Security Laboratory, Nanjing University of 
Posts and Telecommunications, Nanjing 210003, Jiangsu Province, P. R. China  zhuangjun_1988@126.com  On the other hand,the Guttman [3  p r op o s e d  a dynamic index structure based on R-Tree and R-Tree variants i n s e rtion q u er y a n d oth er operation s ca n  be performed simultaneously, and at the same time it supports multi-dimensional model. The advantage of the manner is obvious in many spatial indexing techniques However, with the tree height increasing, the query node overlap increases in large-scale data processing,which resulted in rapid decrease in query efficiency This article presents a kind of mass data real-time query model based on dynamic index DC-Tree, this 
    Figure 1. An order curve   Figure 2. 2nd order curve  Z Curve belongs to a space-filling curve, and its role is to map high-dimensional spatial data to one dimension the relationship is one to one correspondence. The simplest Z Curve is shown in Figure 1.In order to construct a k-Z Curve,the  each grid in the simplest Z 
model can not only achieve efficient parallel processing in large-scale data ,but also improve the real-time effectiveness of data 
RELATED  WORK 
 
II 
A Z Curve 
 
  also the item   is referred to as the point pês Z value  
Curve should be replaced by \(k-1\ order Z Curve .2nd order curve shown in Figure 2 AR n ApZ pZ B Bloom Filter 
Z Curve is defined as one-one mapping between the n-dimensional space and one-dimensional space A, it can be written as Z 002  If the point then the item 
 
Definition 2-1 
n Rp 
003 
002 003 
n R 
Bloom filter is a space-efficient and low lookup time complexity method , its storage space and insertion/query time are constant.It is widely used in spell checking, and database systems The initial state, Bloom Filter is a set of bits containing m bits, each bit sets 0. As shown below  
2013 International Conference on Advanced Cloud and Big Data 978-1-4799-3261-0/14 $31.00 © 2014 IEEE DOI 10.1109/CBD.2013.8 99 


Concept hierarchy  2 multi-dimension data set MDS \(minimum description subset 
C DC-Tree 1 3 
 
ii DM ii Mm ii ma ii DN ii Mm ii Nn ii nm ii DM ii DN ii Nn ii nm 
    
 1  1  DC-Tree stores each dimension in concept hierarchy,and distribute ID to each dimension's attribute,which is in order to reduce information redundancy caused by storing character strings.DC-Tree manage its concept hierarchy dynamically,Every time of the update is on the basis of attribute value ID of inserting record.ID structure is shown in Figure 7,the ID structure is only 4 bytes in length,and the first four bits indicate the concept hierarchy height  S is the smallest MDS \(minimum description subset\,it is such a sequence   1 
i 0010  k\ As shown in Figure 3  Figure 4. Bloom Filter hashing process In determining whether y belongs to the set,y is applied to the k-th hash function , if all HF positions are 1 1 0010 i 0010 k\, y is considered the element in the set or just a false positive \(since Bloom Filter has a certain error rate\, or that y is not the elements of the collection Judgmental process shown in Figure 5  Figure 5. Bloom Filter judgmental proces DC-Tree is a dynamic index structure, it is mainly composed of the data node, directory node and super node A minimum MDS \(minimum description subset\ is a guide of indexing. The following will show several relevant and important concepts about DC-Tree  A multi-dimensional data set contains several functional properties, a data set is grouped into different dimension based on different attribute characteristics.A multi-dimension data set can be seen as a spatial array,the array element contains the respective multi-dimension data set and its corresponding dependency attribute value.If there are multiple functions in each dimension attributes,these attributes are organized by hierarchical structure.A concept hierarchy is a instance of hierarchy model.Figure 6 shows an example:customer dimension and its functional attribute including regional, national and customer ID.ALL is the root of the conceptual level representing all the conceptual hierarchy values  Figure 6. Customer dimension hierarchy model and concept hierarchy model    We define a multidimensional \(n\et D,each of its dimensions is called domain Di,m is a value of its dimension dependency attribute.Then D can be expressed in the following form A data in multi-dimension data set is called data record, a data record performance in the form of   1 1 and the Define the n-dimensional data set D,Di is a assemble of each field.let so that S is a subset of D,for example a assemble of data records,the form of data record is   1 1 the the this sequence must meet the following two conditions For all  1 1 and all i 1 there is established that  If there is   1 and meeting the above coverage conditions,then for all i 1,and there is established that  After defining MDS,MDS's several important operations are defined.These are very important in the corresponding algorithms about DC-Tree.The following will list detailedly  N-dimensional data set D 002 Di is a assemble of each field.There is a minimum description subset   1 and There is also another minimum description subset   1 and    represents power of a assemble N contains M, if for every dimension i 1,there is established that  The volume of M is defined as    1 
 2 Overlap of M and N is expressed as overlap\(M,N\, its 
005 003 006 005 003 003 006 005 005 003 006 
Figure 3. Bloom Filter initialization state  To express S = {x1, x2, ..., xn} such a set of n elements, Bloom Filter use k independent hash functions Hash Function\, each element of the collection is mapped to {1 , ..., m} of the range. For any element x, the position of HF mapped by the i-th hash function will be set to 1 \(1 0010 Figure 7. ID structure 
005 003 006\006 006\006 006\006 
DS Sxxaa m n ni ni S ni 
i n i MMvolume 
 007 
004◊◊◊\005 004\003\003 004\003\003 
m n DDD m n xxaa jii xDa m n xxaa jii xDa n MM n NN n MM n NN 
    
100 


A Real-time query model system B real-time query process c 1 
a b a b a\ MDS \(minimum description subset decomposition 
ii n i NMNMoverlap ii n i NMNMextension 
 
  
definition is   1 3 Expansion of M and N is expressed as extension\(M,N\ its definition is  1 4 It is noteworthy that, Mi and Ni's element in each dimension i must belong to the same level at the Concept hierarchy when operating the overlap and extension otherwise the operation is of no significance  QUERY  MODEL In this paper, dynamic index structure DC-Tree is used to construct our real-time query model, the model system is shown in Figure 3.1. This paper uses the distributed architecture system theory, and the ideological structure is simpler and more efficient for processing massive data.In this model, the node type will be divided into MasterNode and DataNode. The difference is that, MasterNode is responsible for data query/update location, and DataNode is responsible for storaging specific data as well as creating dynamic index in each storage  Figure 8. Real-time query model system Construction and application of the real-time query model system is divided into two areas: \(1\ The building of real-time query indexing. \(2\ery of real-time indexing.A detailed description of the construction of the index will be launched in the fourth quarter of this paper.Real-time index query has two main steps The user sends a query to the MasterNode,MasterNode will handle the query content with the Z curve and Bloom Filter operations to determine which part of the DataNode is the query on,and submit these satisfactory DataNode to the user.After the operation,the user will be disconnected to MasterNode and initiative to visit submitted DataNode for querying  The user to obtain the satisfactory DataNode for the platform,parallel query will be carried out on dynamic index structure\(DC-Tree\ these DataNodes.Since each DataNode results on DC-Tree index is only part of the query results,the eventual result returned to the user should be polymerized by all part results The system structure of Real-time query has been elaborated in 3.1, this section will detail the process of decomposition of queries.Process can be divided into three steps multi-dimensional data record is calculated by the way of Z curve in order to achieve the purpose of dimension reduction Take the method of Bloom Filter to select the desired query DataNode through the dimensionality reduction of one-dimensional data According to b\ selected DataNode,parallel DC-Tree Dynamic index will be conducted.Then the aggregated results are returned to the user.The process of real-time query system is shown in Figure 9  Figure 9. Real-time query model process  Detailed step decomposition process is as follows  Manifestation of MDS \(minimum description subset is  1 
d MM ii DM ikiii aaaM iik Dadi dkkk d aaaaaa 
and Assuming that   2,1 and  1 Then the corresponding multi-dimensional data record set of MDS minimum description subset of\s   2112111 marked MM According to step a\'s results set MM, using Z Curve dimension reduction algorithm operation.Setting the Z 
 
  
 003\006\006 
b\   Z curve dimensionality reduction 
III 
010\007  011\007  005 
101 


MMp nj 
  
1\1 2 
r is the length of Bloom Filter array 1 
0 
p y p y p y 
 UNTIL 
012 
z f 
Curve mapping function   and m is the order of Z Curve, and n is the number of dimensions in multidimensional model. Assuming that the mapping function returns a value The pseudo-code about mapping function calculation process is as follows   REPEAT REPEAT   UNTIL   RETURN  As the space complexity of n-dimensional and m-order's mapping function of Z Curve is  therefore the above algorithm results need the n-length array to store the result set.Assuming that this result set is S According to step b\e result set is obtained after dimensionality reduction process.At the same time,the relevant work on Bloom Filter indicate that the k hash functions should be selected firstly.There is a certain error rate in Bloom Filter itself,in order to reduce this positive errors this paper build a hash function according the Knuth argument: two hash functions and forms by the following  can be uesd to generate more hash functions mod   2 1 5 The 
 
nmpf z Step1 Step2 ji jin pp a yy Step3 nO c\  Bloom Filter Positioning rifHFHFHF i ki HF HF if d\  DC-Tree index and aggregate the results A Parallel Query Algorithm PARALLEL QUERY \(PQ INPUT OUTPUT Step1 Step2 Step3 Step4 Step5 Step6 Step7 Step8 for Step9 B Dynamic insertion algorithm a DYNAMICALLY INSERT DI INPUT Step1 Step2 Step3 Step4 Step5 
 006\006  
003  012 
mi NN RSet 
IV  
  
1 and 2 are two independent hash functions.When 0  double hash function mechanism is taken, or using a hash function on the expansion mechanism.In this way maintaining the positive and error rate of the generated hash function constantly,and improves the computational efficiency of the system After the selecting k hash functions the data in set S is mapped,and a DataNode node set is returned.Assuming the set is At the same time,NN is returned to the user According to obtained NN set in step c\,user navigate to the desired indexed DataNode, then DC-Tree indexing algorithm is taken to query the DataNode.Detailed indexing algorithm will be described in Section IV.After searching on each DataNode,the index results will be sent to the final result set,assuming the result is Then polymerizing the index result set and obtaining the final query results  A LGORITHM D ESIGN  This paper presents a indexing algorithm based on real-time query system,which has two main components dynamic index query algorithm and insertion algorithm As the number of DataNode increases, concurrent query and insert operation will greatly reduce the probability of accessing the same node.However,there is still an access violation which will as well as leads to lapse.To address this problem,this paper improves the DC-Tree index structure and propose a kind of access lock mechanism.More specifically,DataNode will be locked into the protected status of the node when it is accessed,and the follow-up visits will wait until the node unlocked  The proposed algorithm for parallel query algorithm begins with the DC-Tree root node of each DataNode from top to bottom, and each result data of DataNode data will be aggregated finally.The process is as follows Parallel Query function necessary inquiries _MDS \(minimum description subset the aggregation of  query result set  for all nodes in NN set,if the node is not locked,all nodes in NN will be concurrently accessed Let D to be the inquiry DC-Tree root node Apply for lock for the root node D For every child node C in D,if the query is not in the same dimension _MDS level in any one dimension of C,the lower dimension of both will be converted to  a higher level of the dimension hierarchy If C's MDS is included in the query _MDS then the MDS and Measure values will be added to the result set If there is overlap between C'MDS and the query _MDS ,and C'MDS is not included in the query _MDS.Then set the child node C as D,and query function PARALLEL QUERY will be recursively called.Going to PQ1 and proceed  If C is a leaf node, then the end of the visit Apply for unlock the root node D Aggregate the result sets of all accessing nodes in NN set,and obtain the final query results  This paper presents a dynamic insertion algorithm which combines X-Tree's super node and the meaning of concept hierarchy,and at the same time combining the access lock mechanism.In this way,the problem about efficiency of dynamic insertion,split balance and access effectiveness is solved greatly.Detailed process of dynamic insertion algorithm is as follows Dynamic Insert Function data record Data Record, denoted by DR Let D be the root node of inserted DC-Tree Apply for lock for the root node D Update the directory nodeês Measure values If the DR is only contained in one of MDS of D s child, then let D be set for this directory child node If the DR in contained in multiple MDSs of D'child,then find out the child which contains minimum 
102 


V 
   
 
Step6 Step7 Step8 Step9 Step10 Step11 b SPLIT \(SP Step1 Step2 Step3 Step4 Step5 Step6 Step7 A Description of experimental environment B Model Performance-Comparative analysis in insertion time performance C Model Performance-Comparative Analysis of query time performance 
data nodes in these children,and D is set to the directory child node If the DR is not contained in any of MDS of the D'child,firstly copy D and set copy D'.DR is added to each child node of D,and calculate the new overlapping values.Then select the child node which has the minimum value of overlapping,and set it D Insert the data records DR into the D and updates the value of D Measure If D has reached the maximum accommodation space, then call splitting function SPLIT, the D is passed as a parameter Update Measure and MDS of Dês father node Let D point to the D's parent node , if D is not updated or is not a root, then go DI6 and continue Otherwise it ends Apply for unlock for the root node D   Split function  Node required to be splitted contains multiple MDSs,choose the smallest dimension of the concept hierarchy in all MDSs elements as a separatist,denoted SplitDimension Calculate each pair's overlap of MDSs,selecte the maximum pair as seed of the two groups  For remaining MDS in MDSs,separate them into two groups, calculate SplitDimension extension values \(extension\n the split dimension,select the extension's biggest MDS MDS selected in SP3 are added to two groups,calculate the overlap value,select the value of the smaller overlap and add MDS to the group If there in any MDS in MDSs,means that group is not yet complete,go to SP3 and continue If separate two groups are unbalanced or overlap value is too high,select the next best split dimension SplitDimension If all dimensions are selected, the split effect has not yet reached a good state,upgrade this node to super node to solve balance problems  E XPERIMENTS AND PERFORMANCE ANALYSIS  Goal of this paper is to design a model for fast indexing queries in large data.In the design of experiment,MatLab7.0 is used to simulate the data model and behavior. Detailed experimental environment is: set the memory page size of 512KB,choose DC-Tree which has the dimension of 3,set DataNode number be 10.This experiment mainly focus on the compare and simulation in area of timeliness of inserting data and querying data The number of data records inserted in experimental is between 2000 to 20,000,Z Curve and Bloom Filter processing should be conducted before inserting.In this way,the process will loss of part of the time,and insertion time of a few data records will be longer than insertion time of a single point.As the data record continuously increases and splitting probability of a single point occurs rapidly,the splitting time increases.At the same time,data records are parallelly allocated and inserted in this model,each DataNode loads balancing.DC-Tree will not increase as fast as a single point,then the split has less affection.As a result,the model improve the performance of the insertion time which is shown in Figure 10  Figure10. Insertion time performance comparison  To test the query performance on the index,the number of data record is set between 2000 to 20,000 Data record which is randomly generated to query every time will cause accidental probability.For querying on different data sets,the average query time of 100 data records randomly generated is used as the current query time,and performance comparison is based on this method.Query time performance comparison is shown in Figure 11  Figure11. Query time performance comparison     As shown in Figure 11,MDS should be split to query in the initial model,and result set must be merged after querying in each DataNode based on the parallel mechanism.These two reasons resulting in a high query time when there is a a small data set.With the increasing data sets,the overlap in single point of MDS become more,and multi-path traversal query add a lot of time-consuming.However,this model uses concurrent multi-point query,and increasing of query time is not 
103 


Data Mining: Concepts and Techniques 
 
obvious.As a result,the model achieve a better query effect To check the time complexity, for example, the time complexity of the model consists of three parts. The first part comes from the Bloom Filter, because it uses a hashing approach, so the average time complexity is reduced to  1 1 The second part is the mapping process from the Z Curve, time complexity of k-dimensional and m-order about Z Curve function is   2 and the k is the length of the array. The third part comes from the dynamic query process based on improved DC-Tree in structure, the complexity of data set is decided by the number of element-N, so as  log 3 In summary, the time complexity of the process is  log\\(\1 3 2 1 CONCLUSIONS This article presents a kind of mass data real-time query model based on dynamic index DC-Tree which is a kind of dynamic multi-dimensional index structure.In this way,the model resolve the problem of lagged query and analysis for massive data,especially for multi-dimensional data sets.AS the data model is based on concept hierarchy,the effectiveness of real time in decision-making on large data sets is greatly improved Certainly,since the concurrent query and insertion mechanism are utilized in the model, it remains future work to solve the problem of conflict between the two more effectively ACKNOWLEDGEMENTS The authors would like to thank the reviewers for their detailed reviews and constructive comments, which have helped improve the quality of this paper REFERENCES  1 
 
J. Han and M. Kamber Morgan Kaufmann Publishers, 2000 2 Michael S, Daniel A, David J D. Map Reduce and Parallel DBMSs:Friends or Foes?[EB/OL  2 0 110 5 1 6   http://database.cs.brown.edu/papers/stonebraker-cacm2010.pdf 3 Guttman A.: èR-trees: A Dynamic Index Structure for Spatial Searchingê, Proc.ACM SIGMOD Int. Conf. on Management of Data, Boston, MA, 1984, pp. 47-57 4 Berchtold, S., Keim, D.A., Kriegel, H.P.: The X-tree: An Index Structure for High-Dimensional Data. In: Proc. of 22th Int. Conf on Very Large Data Bases, Mumbai\(Bombay\, India, pp. 28Ö39 1996 5 Loureiro Jorge,Belo Orlando.The M-OLAP cube selection problem 031 A hyperÖpolymerphic algorithm approach 031 In 031 International Conference.2010-11,194-201 6 J. Gray, S. Chaudhuri, A. Bosworth, A. Layman, D. Reichart,M Venkatrao, F. Pellow, and H. Pirahesh, çData Cube:A Relational Aggregation Operator Generalizing Group-By,Cross-Tab, and Sub-Totals,é Data Min. Know. Disc., vol. 1,pp. 29Ö53, 1997 7 Doka Katerina 031 Tsoumakos Dimitrios 031 Koziris Nectarios 031 Distributing the power of OLAP 031 HPDC 2010-In 031 Proceeding of the 19th ACM international Symposium on High Performance Distributed Computing 031 2010 031 324-327 8 F. Dehne, T. Eavis, and S. Hambrusch, çParallelizing the data cube,é Distributed and Parallel Databases,vol.11,pp.181Ö201,2002.[Online A va i la b l e http://www.springerlink.com/index/BGN4YJUMUBPELXK0.pdf 9 Yu Cao; Chun Chen; Fei Guo; Dawei Jiang; Yuting Lin; Beng Chin Ooi; Hoang Tam Vo; Sai Wu; Quanqing Xu .ES2: A cloud data storage system for supporting both OLTP and OLAP.Data Engineering \(ICDE\, 2011 IEEE 27th International Conference on   Al-Aqrabi, H.; Lu Liu; Hill, R.; Antonopoulos, N. Taking the Business Intelligence to the Clouds.High Performance Computing and Communication & 2012 IEEE 9th International Conference on Embedded Software and Systems \(HPCC-ICESS\ 2012 IEEE 14th International Conference on    U. Onan, çHigh performance on-line analytical processing on computational gridsé, Master Thesis, 2005  G. Brieter. "Cloud computing architecture and strategy". IBM Blue Books, pp. 3-4. 2010  A. Bento and R. Bento. " Cloud Computing: A new phase in IT Management ". Journal of Information Technology Management 22 \(1\. 39-46, 2011  P. Brezany, Y. Zhang, I. Janciak, P.Chen and S. Ye, çAn Elastic OLAP Cloud Platformé, in proceedings of International Conference on Cloud and Green Computing \(CGC 2011\ in Sydney, Australia, December 2011  B. Chadha and M. Iyer. çBI in the cloudé. SET-Lab briefings, 8 1\p. 39-44. Infosys Research. 2010  Sicen Ye, Peng Chen, Ivan Janciak, and Peter Brezany.Accessing and Steering the Elastic OLAP Cloud.MIPRO, 2012 Proceedings of the 35th International Convention    P. Brezany and A. Wˆhrer, çPerformance Evaluation of Web RowSet Implementationsé, In: Proceedings of the Third I nternational Conference on Data Management in Grid and P2P Systems \(GLOBE'10\, Bilbao, Spain 2010  M. Ester, J. Kohlhammer, and H.-P. Kriegel, çThe DC-tree:a fully dynamic index structure for data warehouses,é 16th International Conference on Data Engineering \(ICDE\, pp.379Ö388, 2000 Onlin A v a i la b l e   http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=8 39438  Azza A, Kamil B P, Daniel J A. HadoopDB: An Architectural Hybrid of Map Reduce and DBMS Technologies for Analytical Workloads  Proc  of VL DB 0 9  L yon  F r a n c e A C M Press,2009  Dean J, Ghemawat S. Map Reduce: Simplified Data Processing on Large Clusters[C  P roc of th e 6t h Sy m p os i u m on Op era ti ng  Systems Design and Implementation. San Francisco, USA: [s n 20 0 4    Apache Hadoop Organization. Hive[EB/OL  2 01 1 08 21  http://www.hive.apache.org  Apache Hadoop Organization. Hadoop[EB/OL  2010-08-16\.http://www.hadoop.apache.org   
VI 
D Complexity Analysis O kO NO NOkOONkO 
6 In particular, as the size of data and the dimension of the data increases,combining advantages of the hierarchical structure and the linear structure , the model greatly reduces the overlap between the MBR problems and improves the efficiency of the query 
                      
 
104 


Figure 7  DPA Flowchart token along with information regarding owner goal required capabilities and history of bidders as illustrated in Figure 6 A particular token can be held by exactly one agent at any time instance after its generation The agent makes a decision to either retain this particular token or pass it on Figure 7 is a 003owchart of the algorithm The decision to retain a given task token is a probability function of the associated reward and the individual predicted cost to execute p  retain   e 000 ln  R  ln  c ij  12 where 8 R c ij 2 0  1 are normalized rewards and costs Figure 8 is a plot of the three dimensional probability distribution function Following such a probabilistic retainment structure increases task completion likelihood exponentially given a rise in reward or reduction in cost Figure 8  Probability Distribution Function for retaining tasks 5 M ODEL B UILDING The planetary exploration domain presents a unique challenge the slow computation and low communication bandwidth of space systems limit the resolution of maps and models built online but the highest quality maps and models are desired because robots are there to observe what humans cannot For the mission scenario discussed here the solution is for robots to store data as they explore and to slowly transmit data back to operators after they have completed their exploration tasks Better resolution maps and higher-dimensional models can then be generated in postprocessing For a mission this might mean that coarse 3D maps are created online post-processing builds higher resolution 3D models and 4 or 5D models that augment geometry with multi-spectral re\003ectance soil cohesion or gas concentration In order to demonstrate this concept with readily available robot hardware experiments presented here generate coarse 2D maps online produce re\002ned 2D maps in post-processing and augment 2D maps with 3D data where available 2-Dimensional Two dimensional maps for the mapping robots are constructed using the GMapping SLAM algorithm 25 2  This produces an occupancy grid with cells marked as either free occupied or unknown To combine maps from multiple mapping robots each map is converted to a 2D point cloud with points for every occupied cell The point clouds are transformed into roughly the same frame based on the recorded starting pose The point clouds are trimmed to include only points in the overlapping region The alignment is then re\002ned using 2D iterative closest point ICP The transformation that results from ICP is then applied to the maps Figure 14 shows example merged maps To display 2D maps augmented with 3D data the maps were converted to mesh models and trimmed to include explored areas only 3-Dimensional The scans from a 3D modeling robot described in more detail in Section 6 have been obtained in a stop-and-scan fashion from a rotating laser scanner to obtain 3D point clouds Preprocessing of the point clouds is done using a median 002lter to remove Gaussian noise and the point cloud is further downsampled to reduce the computational requirements Multiple 3D scans are necessary to preclude occlusions when digitizing environments This requires registering several 3D scans and merging them into one coordinate system If a 3D modeling robot has precise localization the registration can be done directly using the robot pose However robot motion on natural terrain has to cope with 3D rotations and translations Pose estimation becomes a problem with six degrees of freedom This combined with noisy sensors makes the self-localization erroneous so the geometric structure of overlapping 3D scans has to be considered for registration Automated registration of the scans is thus done at two levels An initial alignment is done based on the noisy odometry data followed by the 002ne alignment using scan matching For scan matching point clouds are trimmed to include only points that based on coarse alignment lie in overlapping regions Simultaneous matching a modi\002ed v ersion of the 3D iterative closest point algorithm ICP has been used to 002nd the transformation matrices between the two scans 2 The gmapping ROS package was used For more information see http://www.ros.org/wiki/gmapping 7 


k-D trees have been used to speed up the data access which ensures that a data point can be selected in O\(log n See Figure 15 for an example of a generated 3D model 6 E XPERIMENTS  R ESULTS Experiments were conducted at two outdoor test sites and included teams of two to four robots High-resolution laser scans were collected with a tripod-mounted Faro Photon80 at each test site These models serve as ground truth against which experiment data is compared A 2D experiment evaluated exploration performance and two 3D experiments investigated 2D/3D model building Robots The robot team in the experiments consisted of 2D mapping robots a 3D modeling robot and a science sampling robot Not all robots were used in all tests The 2D mapping robots have SICK scanning LIDARs that scan parallel to the ground plane see Figure 9 One covers 180 degrees at 1 degree resolution the other covers 270 degrees at 0.5 degree resolution The 3D modeling robot has a SICK scanning LIDAR mounted on a rotating base See Figure 10 By spinning the LIDAR while scanning it builds a 3D point cloud In these experiments this robot was operated in a stop-and-scan mode the robot would stay still and collect data for approximately 15 seconds before moving to its next position The science sampling robot has a cone penetrometer to measure soil properties and no exteroceptive navigation sensors See Figure 11 The sampling robot was given tasks to proceed to a sampling location by the task allocation system and to operate the penetrometer Figure 9  2D Mapping Robots Figure 10  3D Modeling Robot Test Sites One test site was a patio area surrounded by buildings and retaining walls See Figure 12 This created de\002ned boundaries to the 2D explorable area as would be observed inside a cave The buildings trees and one tunnel under a bridge also a Sampling robot at mock-cave test site b Detail of cone penetrometer Figure 11  Science Sampling Robot provide signi\002cant 3D structure to be modeled The other test site was a mock cave It had terrain more realistic for planetary exploration with dirt gravel and rocks Caves and especially cave entrances often have areas of very blocky and rough terrain that pose a signi\002cant challenge to robot mobility Because robot mobility and cave access were not studied in these experiments the terrain was designed to be mostly drivable but still challenging enough that less capable robots in this case the 2D mappers occasionally get stuck The test site contained an outdoor 223surface\224 area and an indoor 223cave\224 area Figure 12  Patio test site Orange lines outline drivable area Red star indicates approximate starting location of robots 8 


a Outside View b Inside View Figure 13  Mock cave test site Tunnel extends approximately 300m Cave 003oor is covered in rocky material to emulate planetary terrain Site contains surface terrain and tunnel inside building Exploration Performance Experiments A comparison of exploration performance between distributed centralized and uncoordinated task allocation was conducted using a 2-robot team of 2D mapping robots For the uncoordinated runs tasks were randomly assigned to a robot and the robot randomly decided whether to keep the task not taking into account any costs associated with that robot's performance of the task Maps at a resolution of 0.05 meters per pixel were built from 5 runs of each type Each run lasted 15 minutes The operator indicated tasks that should be performed and the system assigned these tasks to a robot In 3 out of 5 runs for each set the 002rst selected task was in the direction of the bridge in the other 2 it was in the direction of the dead-end to the right of the starting position in Figure 12 The same operator selected tasks for all runs Tables 1 2 and 3 show results for each run Percent explored is the percentage of the explorable area as determined from the ground truth model that the robot team explored Unique to total is the ratio of the area explored by a single robot to the total area explored by the team This metric gives a sense of how much overlapping work the robots are doing The average percent explored for runs with a 002rst task in the direction of the bridge was 68 and for runs with the 002rst task in the direction of the dead-end 67 The average ratio of unique to total explored for these cases was 0.45 and 0.44 respectively The average over all runs was 67 of explorable area covered and a ratio of 0.45 unique to total explored area Figure 14 shows merged maps for the runs with the largest and smallest explored areas in this experiment Table 1  2D Mapping Results Distributed Run Bridge 1st  Explored Unique:Total 1 1 80 0.57 2 1 52 0.43 3 1 94 0.45 4 0 97 0.76 5 0 60 0.37 Mean 77 0.52 Std Dev 20 0.15 Table 2  2D Mapping Results Centralized Run Bridge 1st  Explored Unique:Total 1 1 75 0.58 2 0 52 0.46 3 1 55 0.29 4 0 49 0.15 5 1 62 0.59 Mean 59 0.41 Std Dev 10 0.19 Table 3  2D Mapping Results Uncoordinated Run Bridge 1st  Explored Unique:Total 1 1 51 0.20 2 0 54 0.26 3 1 73 0.49 4 0 87 0.65 5 1 68 0.42 Mean 67 0.41 Std Dev 15 0.18 These results show high performance variation within run sets and do not show signi\002cant difference between sets The direction of the 002rst assigned task did not signi\002cantly affect results Limited navigation and path planning capabilities on individual robots common for all runs likely introduces signi\002cant randomness If the robots could more reliably complete their assigned tasks differences between task allocation strategies would likely become more evident Exploration of larger areas could also make differences clearer as more tasks would need to be assigned The lack of signi\002cant differences between allocation methods is somewhat encouraging however It indicates that distributed task allocation the method believed to be most promising for planetary missions does not perform any worse than other methods in early tests The uncoordinated method while by far the simplest would fail once robots with different capabilities are introduced Failure would occur for example if a 3D modeling task were assigned to a 2D mapping robot Mapping and Modeling Experiments An experiment including both 2D mapping and 3D modeling was conducted at the patio test site In this experiment the two 2D mapping robots were operated as described in section 6 A mapped area was then selected by the operator for 3D modeling and the 3D modeling robot was sent to complete that task There was no time limit on the run Figure 15 shows 9 


Figure 15  3D model of the patio test site Figure 16  Model of the patio test site combining 2D map data with 3D model data a Largest explored area b Smallest explored area Figure 14  Maps built by a pair of 2D mapping robots Yellow indicates area seen by both robots Magenta indicates area seen by one robot and Cyan represents area seen by the other a 3D point cloud built of the patio environment Figure 16 shows a model built combining 2D map data with 3D model data A four-robot mission scenario experiment was conducted at the mock-cave test site This included two 2D mapping robots a 3D modeling robot and a science sampling robot There was no time limit on the run Figure 17 shows a 3D model of the tunnel at the mock cave Figure 18 shows a model built combining 2D map data with 3D model data 7 C ONCLUSIONS  F UTURE W ORK The multi-robot coordination framework presented in this paper has been demonstrated to work for planetary cave mission scenarios where robots must explore model and take science samples Toward that end two coordination strategies have been implemented centralized and distributed Further a core communication framework has been outlined to enable a distributed heterogenous team of robots to actively communicate with each other and the base station and provide an online map of the explored region An operator interface has been designed to give the scientist enhanced situational awareness collating and merging information from all the different robots Finally techniques have been developed for post processing data to build 2  3-D models of the world that give a more accurate description of the explored space Fifteen 2D mapping runs with 2 robots were conducted The average coverage over all runs was 67 of total explorable area Maps from multiple robots have been merged and combined with 3D models for two test sites Despite these encouraging results several aspects have been identi\002ed that can be enhanced Given the short mission durations and small team of robots in the experiments conducted a simple path-to-goal costing metric was suf\002cient To use this system for more complex exploration and sampling missions there is a need for learning-based costing metrics Additional costing parameters have already been identi\002ed and analyzed for future implementation over the course of this study One of the allocation mechanisms in this study was a distributed system however task generation remained centralized through the operator interface In an ideal system robots would have the capability to generate and auction tasks based on interesting features they encounter Lastly the N P complete scheduling problem was approximated during task generation However better results could potentially 10 


Figure 17  3D model of the tunnel in the mock cave test site Figure 18  Model of the mock cave test site combining 2D map data with 3D model data be obtained by releasing this responsibility to the individual robots A CKNOWLEDGMENTS The authors thank the NASA STTR program for funding this project They would also like to thank Paul Scerri and the rCommerceLab at Carnegie Mellon University for lending hardware and robots for this research R EFERENCES  J C W erk er  S M W elch S L Thompson B Sprungman V Hildreth-Werker and R D Frederick 223Extraterrestrial caves Science habitat and resources a niac phase i study\\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2003  G Cushing T  T itus and E Maclennan 223Orbital obser vations of Martian cave-entrance candidates,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  M S Robinson B R Ha wk e A K Boyd R V Wagner E J Speyerer H Hiesinger and C H van der Bogert 223Lunar caves in mare deposits imaged by the LROC narrow angle camera,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  A K Bo yd H Hiesinger  M S Robinson T Tran C H van der Bogert and LROC Science Team 223Lunar pits Sublunarean voids and the nature of mare emplacement,\224 in LPSC  The Woodlands,TX 2011  S Dubo wsk y  K Iagnemma and P  J Boston 223Microbots for large-scale planetary surface and subsurface exploration niac phase i.\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2006  S Dubo wsk y  J Plante and P  Boston 223Lo w cost micro exploration robots for search and rescue in rough terrain,\224 in IEEE International Workshop on Safety Security and Rescue Robotics Gaithersburg MD  2006  S B K esner  223Mobility feasibility study of fuel cell powered hopping robots for space exploration,\224 Master's thesis Massachusetts Institute of Technology 2007  M T ambe D Pynadath and N Chauv at 223Building dynamic agent organizations in cyberspace,\224 IEEE Internet Computing  vol 4 no 2 pp 65\22673 March 2000  W  Sheng Q Y ang J T an and N Xi 223Distrib uted multi-robot coordination in area exploration,\224 Robot Auton Syst  vol 54 no 12 pp 945\226955 Dec 2006  A v ailable http://dx.doi.or g/10.1016/j.robot 2006.06.003  B Bro wning J Bruce M Bo wling and M M V eloso 223Stp Skills tactics and plays for multi-robot control in adversarial environments,\224 IEEE Journal of Control and Systems Engineering  2004  B P  Gerk e y and M J Mataric 223 A formal analysis and taxonomy of task allocation in multi-robot systems,\224 The International Journal of Robotics Research  vol 23 no 9 pp 939\226954 September 2004  M K oes I Nourbakhsh and K Sycara 223Heterogeneous multirobot coordination with spatial and temporal constraints,\224 in Proceedings of the Twentieth National Conference on Arti\002cial Intelligence AAAI  AAAI Press June 2005 pp 1292\2261297  M K oes K Sycara and I Nourbakhsh 223 A constraint optimization framework for fractured robot teams,\224 in AAMAS 06 Proceedings of the 002fth international joint conference on Autonomous agents and multiagent sys11 


tems  New York NY USA ACM 2006 pp 491\226493  M B Dias B Ghanem and A Stentz 223Impro ving cost estimation in market-based coordination of a distributed sensing task.\224 in IROS  IEEE 2005 pp 3972\2263977  M B Dias B Bro wning M M V eloso and A Stentz 223Dynamic heterogeneous robot teams engaged in adversarial tasks,\224 Tech Rep CMU-RI-TR-05-14 2005 technical report CMU-RI-05-14  S Thrun W  Bur g ard and D F ox Probabilistic Robotics Intelligent Robotics and Autonomous Agents  The MIT Press 2005 ch 9 pp 222\226236  H Mora v ec and A E Elfes 223High resolution maps from wide angle sonar,\224 in Proceedings of the 1985 IEEE International Conference on Robotics and Automation  March 1985  M Yguel O A ycard and C Laugier  223Update polic y of dense maps Ef\002cient algorithms and sparse representation,\224 in Intl Conf on Field and Service Robotics  2007  J.-P  Laumond 223T rajectories for mobile robots with kinematic and environment constraints.\224 in Proceedings International Conference on Intelligent Autonomous Systems  1986 pp 346\226354  T  Kanungo D Mount N Netan yahu C Piatk o R Silverman and A Wu 223An ef\002cient k-means clustering algorithm analysis and implementation,\224 IEEE Transactions on Pattern Analysis and Machine Intelligence  vol 24 2002  D J Rosenkrantz R E Stearns and P  M Le wis 223 An analysis of several heuristics for the traveling salesman problem,\224 SIAM Journal on Computing  Sept 1977  P  Scerri A F arinelli S Okamoto and M T ambe 223T oken approach for role allocation in extreme teams analysis and experimental evaluation,\224 in Enabling Technologies Infrastructure for Collaborative Enterprises  2004  M B Dias D Goldber g and A T  Stentz 223Mark etbased multirobot coordination for complex space applications,\224 in The 7th International Symposium on Arti\002cial Intelligence Robotics and Automation in Space  May 2003  G Grisetti C Stachniss and W  Bur g ard 223Impro ving grid-based slam with rao-blackwellized particle 002lters by adaptive proposals and selective resampling,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2005  227\227 223Impro v ed techniques for grid mapping with raoblackwellized particle 002lters,\224 IEEE Transactions on Robotics  2006  A Geiger  P  Lenz and R Urtasun 223 Are we ready for autonomous driving the kitti vision benchmark suite,\224 in Computer Vision and Pattern Recognition CVPR  Providence USA June 2012  A N 250 uchter H Surmann K Lingemann J Hertzberg and S Thrun 2236d slam with an application to autonomous mine mapping,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2004 pp 1998\2262003  D Simon M Hebert and T  Kanade 223Real-time 3-d pose estimation using a high-speed range sensor,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  1994 pp 2235\2262241 B IOGRAPHY  Ammar Husain received his B.S in Mechanical Engineering Robotics from the University of Illinois at Urbana-Champaign He is pursuing an M.S in Robotic Systems Development at Carnegie Mellon University He has previously worked on the guidance and control of autonomous aerial vehicles His research interests lie in the 002eld of perception-based planning Heather Jones received her B.S in Engineering and B.A in Computer Science from Swarthmore College in 2006 She analyzed operations for the Canadian robotic arm on the International Space Station while working at the NASA Johnson Space Center She is pursuing a PhD in Robotics at Carnegie Mellon University where she researches reconnaissance exploration and modeling of planetary caves Balajee Kannan received a B.E in Computer Science from the University of Madras and a B.E in Computer Engineering from the Sathyabama Institute of Science and technology He earned his PhD from the University of TennesseeKnoxville He served as a Project Scientist at Carnegie Mellon University and is currently working at GE as a Senior Cyber Physical Systems Architect Uland Wong received a B.S and M.S in Electrical and Computer Engineering and an M.S and PhD in Robotics all from Carnegie Mellon University He currently works at Carnegie Mellon as a Project Scientist His research lies at the intersection of physics-based vision and 002eld robotics Tiago Pimentel Tiago Pimentel is pursuing a B.E in Mechatronics at Universidade de Braslia Brazil As a summer scholar at Carnegie Mellon Universitys Robotics Institute he researched on multi-robots exploration His research interests lie in decision making and mobile robots Sarah Tang is currently a senior pursuing a B.S degree in Mechanical and Aerospace Engineering at Princeton University As a summer scholar at Carnegie Mellon University's Robotics Institute she researched multi-robot coordination Her research interests are in control and coordination for robot teams 12 


Shreyansh Daftry is pursuing a B.E in Electronics and Communication from Manipal Institute of Technology India As a summer scholar at Robotics Institute Carnegie Mellon University he researched on sensor fusion and 3D modeling of sub-surface planetary caves His research interests lie at the intersection of Field Robotics and Computer Vision Steven Huber received a B.S in Mechanical Engineering and an M.S in Robotics from Carnegie Mellon University He is curently Director of Structures and Mechanisms and Director of Business Development at Astrobotic Technology where he leads several NASA contracts William 223Red\224 L Whittaker received his B.S from Princeton University and his M.S and PhD from Carnegie Mellon University He is a University Professor and Director of the Field Robotics Center at Carnegie Mellon Red is a member of the National Academy of Engineering and a Fellow of the American Association for Arti\002cial Intelligence 13 



3076 IEEE TRANSACTIONS ON INFORMATION THEORY VOL 63 NO 5 MAY 2017 An Adaptive Fusion Strategy for Distributed Information Estimation Over Cooperative Multi-Agent Networks Daxin Tian Senior Member IEEE  Jianshan Zhou and Zhengguo Sheng Abstract  In this paper we study the problem of distributed information estimation that is closely relevant to some networkbased applications such as distributed surveillance cooperative localization and optimization We consider a problem where an application area containing multiple information sources of interest is divided into a series of subregions in which only one information source exists The information is presented as a signal variable which has nite states associated with 
certain probabilities The probability distribution of information states of all the subregions constitutes a global information picture for the whole area Agents with limited measurement and communication ranges are assumed to monitor the area and cooperatively create a local estimate of the global information To efciently approximate the actual global information using individual agents own estimates we propose an adaptive distributed information fusion strategy and use it to enhance the local Bayesian rule-based updating procedure Specically this adaptive fusion strategy is induced by iteratively minimizing a JensenñShannon divergence-based objective function A constrained optimization model is also presented to derive minimum 
JensenñShannon divergence weights at each agent for fusing local neighbors individual estimates Theoretical analysis and numerical results are supplemented to show the convergence performance and effectiveness of the proposed solution Index Terms  Cooperative information estimation adaptive distributed fusion nonlinear constrained optimization multiagent networks Jensen-Shannon divergence I I NTRODUCTION N ETWORK-TYPE systems are general in both nature such as sh schools ants and honeybee swarms and engineering such as unmanned aerial vehicles mobile robots and other wireless sensor networks In these systems information estimation and fusion over multi-agent networks is 
of great signiﬁcance which can support individual agents to achieve some common tasks in a distributed manner such as Manuscript received May 15 2015 revised December 19 2015 May 20 2016 and November 27 2016 accepted February 12 2017 Date of publication February 24 2017 date of current version April 19 2017 This work was supported by the National N atural Science Foundation of China under Grant 61672082 Corresponding author Zhengguo Sheng D Tian and J Zhou are with the Beijing Key Laboratory for Cooperative Vehicle Infrastructure Systems and Safety Control Beijing Advanced Innovation Center for Big Data and Brain Computing School of Transportation Science and Engineering Beihang University Beijing 100191 China e-mail dtian@buaa.edu.cn jianshanzhou@foxmail.com Z Sheng is with the Department of Engineering and Design University of Sussex Richmond 3A09 U.K e-mail z.sheng@sussex.ac.uk 
Communicated by T Javidi Associate Editor for Communication Networks Color versions of one or more of the gures in this paper are available online at http://ieeexplore.ieee.org Digital Object Identiﬁer 10.1109/TIT.2017.2674678 environmental monitoring global localization self-defending or attacking invaders etc However some challenges exist to be dealt with for practically realizing highly-scalable information estimation and fusion paradigms such as limited individual detection and interacti on lack of centralized control and dynamic and noisy nature of measurements obtained by every agent In some application scenarios relevant to object detection or target locating the goal of an information estimation model is to estimate the actual probability that a certain target is present in a given closed region The probability of a target existence within a given surveillance 
region is usually assumed to follow the Bernoulli distribution and all of the probab ilities corre sponding to different regions constitute a so-called probability map 1   3   T h e estim atio n of the individual probability map can be iteratively updated by following Bayesian rule For example in 3  to r ealize a distributed strategy for probability map estimation Bayesian updating is combined with the traditional consensus protocol which is used for fusing different individual probability maps of the neighbors of an agent Nevertheless although the proposed estimation fusion strategy based on Bayesian updating is useful in the static object detection it may fail to be applied in a more general scenario where the probability of a subregion state or an object state does not follow the 
Bernoulli distribution Additionally many distributed solutions have been proposed in the context of adaptive distributed LMS LeastMean-Square estimation which include the incremental adaptive strategies  t h e c ons ens u s b as ed s t rat e gi es 7]–[9 and the adaptive diffusion strategies   S peci  cal l y  two diffusion strategies ATC Adapt-Then-Combine and CTA Combine-Then-Adapt have been proven to be powerful to realize distributed optimization and cooperative learning over networks   13  15]–[19 I n m os t o f t hes e s t udies the distributed optimization is always modeled as an unconstrained LMS estimation problem in which the global objective function is formulated as a sum of all individual components The global function has to be localized so that the 
distributed optimization procedure can be induced by adopting the steepest descent algorithm However the unconstrained LMS estimation solutions are not suitable in some speciﬁc application situations where a global task should be formulated as a constrained distributed optimization problem In this context distributed solutions are required to satisfy some certain estimation constraint s at each agent which could be 0018-9448  2017 I EEE Personal u se is perm itted but republication/redistri bution requires IEEE permission See http://www.ieee.org/publications_standards/publications/rights/index.html for more information 


TIAN et al  ADAPTIVE FUSION STRATEGY FOR DISTRIBUTED INFORMATION ESTIMATION 3077 more challenging and beyond the conventional unconstrained LMS estimation schemes Since the information estimation over a distributed system can be modeled as a distributed optimization problem some distributed optimization algorithms with consideration of certain constraints have been proposed  21 I n  21 t w o di s t ri b u t e d opt i m i zat i o n cases are considered the rst case does not take into account the equality constraints and employs Lagrangian relaxation approach to devise a distributed Lagrangian primal-dual subgradient algorithm the second case takes into account the equality constraints and adopts a penalty relaxation approach Although both of equality and inequa lity constraints are taken into account in the second case it require identical local constraint sets to guarantee the Slater’s condition due to the nature of penalty relaxation approach In this paper we present an ATC-type distributed framework which includes a nonlinear constrained optimization model and a fusion-weight optimization model The objective function of the optimization model is deﬁned based on the Jensen-Shannon divergence w hi ch al l o w s t h e i ndi vi dual fusion to iteratively approach to the actual information in terms of minimizing the information-theoretic divergence measure based on the Shannon entropy Besides the fusion-weight optimization model is proposed to iteratively adapt the fusion weights of each agent according t o estimation results collected from the other neighbors Different from the existing work the distributed optimization algorithm proposed in this paper does not need the assumption of identical constraint sets Furthermore another essential difference between our work and  i s t h e d i s t r i b ut ed frame w o rk w here w e adopt a projection gradient approach and the distributed processing is based on ATC By resorting to the probabilistic theory the distributed information estimation is generalized as the process of learning and approaching to probability distributions over the multi-agent network We do not assume any speciﬁc given distribution for instance the Bernoulli distribution adopted in 1   3    2 3   a n d  2 4   f o r th e p r o b a b ilities o f t h e in f o r mation states Hence the proposed solution can be deployed for a wide range of distributed applications once the detection information of interest is appropriately represented as a certain discrete probability distribution The remainder of the paper is organized as follows In Section II relevant preliminaries are brieﬂy outlined for the distributed information estimation problem which include main mathematical notations and deﬁnitions In Section III we introduce the non-cooperative individual information estimation scheme where the Bayesian rule is adopted to incorporate the individual measurements In Section IV the nonlinear constrained optimization model is proposed for improving individual estimation Section V presents the experimental results of the adaptive fusion strategy Finally Section VI concludes this paper II P RELIMINARIES A Notations and Deﬁnitions Notations Throughput this paper we use col  x 1  x n  to represent a column vector constructed by stacking entries x 1  x n on top of each other and diag  x 1  x n  to represent a diagonal matrix with diagonal entries x 1  x n  Besides let 1 n  1 be a column vector of n dimensions all of whose entries are equal to 1 and 0 n  1 beafull-zero column vector of n dimensions The identity matrix of size n is denoted by I n  Unless otherwise speciﬁed all vectors are column vectors and denoted by boldface lowercase letters while matrices are denoted by boldface capital letters Deﬁnitions Given a multi-agent network we use a graph G  V  E  to represent its communication topology with V   1  2  n  denoting a node set and E  V  V denoting an edge set consisting of unordered pairs E    i  j   i  j  V  excluding self-loop  i  i    i  j   E represents a mutual communication between the agents i and j  and any agent i  V is supposed to be periodically communicating with its immediate neighbors  j  j  V  j  i   E  through one-hop broadcastingbased communication We assume that the communication graph is a connected graph i.e the communication is bi-directional and there is always a path between any two agents in the network B Problem Formulation The multi-agent network is assumed to be deployed to detect a geographical region that contains multiple information sources The set of the whole information sources is denoted by   whose cardinality is m i.e m     Then the entire surveillance region can be divided into a series of surveillance subregions each of which corresponds to one information source An agent i can only detect a part of subregions i.e a fraction of information sources The set of partial information sources in i s detection range is deﬁned as  i   i   for all i  V and  i  V  i    Without loss of generality we also assume that the detection regions of any two different agents i 1   i 2  i 1  i 2  V  are not identical i.e  i 1    i 2  This implies that two general situations are considered in our study i some information sources can be only observed by any single agent and ii some others can be observed by multiple at least two agents simultaneously We need to point out that in the rst situation only a single agent’s observation contributes to information gain of the overall network in estimation of an information source without overlapped detection As for any other agent who is blind in observation of this information source the sense of a fusion strategy is reduced to the point that the agent simply needs to collect the other’s useful observation information diffused over the network and incorporates it into its own individual estimation at the meanwhile keeping silence in order to avoid diffusing its blindness By contrast in the second situation several agents with overlapped detection can contribute to information gain of the network in estimation of an information source in their common detection region through diffusing and fusing the multiple observation information with a certain fusion strategy The sense of the fusion strategy lies in that an agent with overlapped detectio n region can combine several others observation information with its own to enhance its own individual estimation at the same time diffusing its own observation information for others fusion In this paper we 


3078 IEEE TRANSACTIONS ON INFORMATION THEORY VOL 63 NO 5 MAY 2017 provide a uniﬁed algorithmic information fusion framework to deal with both of the two considered situations Furthermore we point out that the information released by the sources can be some parameters of interest such as temperature eld multi-target locations or some phenomenons of interest in the corresponding subregions We divide the detection time into discrete time intervals t  Z  0  Considering the dynamic and noisy nature of information detected by agents we formulate the detection signal at time interval t corresponding to an information source k   as a random variable v k  t   such that its time-dependent variability can be modeled by a certain discrete probability distribution The ranges of the detection signal v k  t  are represented as various information states Let the total number of the information states associated with the source k be L k The l th information state is denoted by S k  l   a k  l  b k  l  for l  1  L k  1 while S k  L k   a k  L k  b k  L k   a k  l and b k  l are the lower and the upper bounds of the detection signal v k  t  in the state S k  l  which satisfy b k  l  a k  l  1 for l  1  L k  1 Each information state S k  l is associated with a certain probability denoted by p  v k  t   S k  l   which indicates the possibility of the detection signal v k  t  currently ranging within S k  l  Hence for any k   wehave  L k l  1 p v k  t   S k  l   1 The objective of the information estimation over the multi-agent network is to enable each individual agent to approach the actual probability distributions of information states of the entire surveillance region  p v k  t   S k  l   l  1  2  L k  k     through local measurements estimations and interactions Deﬁne by v k  i  t  the detection signal of an agent i received from the information source k   i at any time interval t  Then this agent is assumed to take multiple measurements on v k  i  t  during this time interval We collect these realtime measurements into a vector v k  i  t    v k  s  i  t   s  1  2   V i  where v k  s  i  t  is the s th sample on the information source k and V i denotes i s sampling number With the individual cumulative observations  v k  i     0  1  t   the agent i can plot a discrete histogram of v k  i  t   which implies a discrete conditional probability distribution of the information states of k   p k  l  i  t   p  v k  i  t   S k  l  v k  t   S k  l   where  p k  l  i  t   0and  L k l  1 p k  l  i  t   1 Indeed this conditional probability p k  l  i  t  representing the possibility that the real-time detection signal range estimated by i is in the l th information state of k given that the actual detection signal value exactly belongs to the same state The conditional probability p k  l  i  t  indicates the accuracy of observed information at i  Correspondingly the false detection probability p k  l  i  t  is p k  l  i  t   p v k  i  t   S k  l  v k  t   S k  l   l    l    L k  l    l p k  l   i  t   L k  l    l 1  1  p k  l  i  t  L k  1 1 We further denote the actual probability distribution of information states of any subregion k   at time interval t as p k  t   col  p v k  t   S k  l   l  1  L k   and then deﬁne p  t   col  p k  t   k  1  m  to collect all of the probability distributions Similarly for any individual i  V  we denote p k  i  t   col  p v k  i  t   S k  l  v k  t   S k  l   l  1  L k   and p  i  t   col  p k  i  t   k  1  m   In addition we use q to denote the total number of information states of the entire region i.e q   m k  1 L k  We note that the sizes of p k  t  and p k  i  t  are identical to L k  while the sizes of p  t  and p  i  t  are identical to q  III I NFORMATION E STIMATION B ASED ON I NDIVIDUAL O BSERVATION The agents can yield the real-time posterior information by combining the informatio n accuracy of their real-time observations p k  l  i  t   based on the well-known Bayesian rule and have p v k  t   S k  l  v k  i  t   S k  l   p v k  i  t   S k  l  v k  t   S k  l  p v k  t   S k  l  p v k  i  t   S k  l  v k  t   S k  l  p v k  t   S k  l    k  l  i  t   p k  l  i  t  p v k  t   S k  l  p k  l  i  t  p k  l v k  t   S k  l    k  l  i  t  2 where  k  l  i  t  is  k  l  i  t   p v k  i  t   S k  l  v k  t   S k  l   l    l  p v k  t   S k  l  l    l   L k 012  l    l p v k  i  t   S k  l  v k  t   S k  l   p v k  t   S k  l   3 By using 1  k i  n  t  can be further expressed as  k  l  i  t   L k 012  l    l p k  l  i  t  p v k  t   S k  l    1  p k  l  i  t  L k  1 L k 012  l    l p v k  t   S k  l    1  p k  l  i  t  L k  1  1  p v k  t   S k  l   4 Generally because of the existence of noises in agents observations the actual probability distribution of information states corresponding to any k     p v k  t   S k  l   l  1  L k   is unknown to these agents At this point it is unpractical to directly apply the equation 2 to distributed estimation since the calculation of this formula requires the exact knowledge of the parameter p v k  t   S k  l   To obtain the current posterior information we adopt the recursive Bayesian updating method to combine the past posterior information and the current observation information For simplicity we denote i s realtime estimation on the posterior probability by  k  l  i  t   i.e  k  l  i  t   p v k  t   S k  l  v k  i  t   S k  l   Then we use the previous posterior estimation represented by  k  l  i  t  1   to substitute the unknown p v k  t   S k  l  in the right term of 2 and get  k  l  i  t   p k  l  i  t  k  l  i  t  1  p k  l  i  t  k  l  i  t  1   1  p k  l  i  t  L k  1  1   k  l  i  t  1   5 


TIAN et al  ADAPTIVE FUSION STRATEGY FOR DISTRIBUTED INFORMATION ESTIMATION 3079 In this paper we generalize the term p k  l  i  t  in equation 5 such that it can reﬂect any distribution pattern captured by the individual observation information The essential concept of 5 is that it allows us to effectively incorporate the past estimated information  k  l  i  t  1   and the real-time observed information p k  l  i  t   into the current individual estimation  k  l  i  t   To analyze the convergence of the Bayesian updating 5 we rearrange the equation 5 as  1  k  l  i  t   1   1 L k  1  1  p k  l  i  t  p k  l  i  t   1  k  l  i  t  1   1  6 and further derive a closed-form expression on  k  l  i  t    k  l  i  t   1 1  015 1   k  l  i  1   k  l  i  1  015 1 L k  1  t  1  t   2 1  p k  l  i   p k  l  i   7 where t  2 By introducing an auxiliary parameter a  t  a  t   1  p k  l  i  t  p k  l  i  t   L k  1  8 we can simplify 7 as  k  l  i  t   1 1  015 1   k  l  i  1   k  l  i  1    t   2 a   9 From 9 it can be found that the accuracy of the individual real-time estimation  k  l  i  t   depends on the number of the information states of the subregion k  L k  and the accuracy of the individual observation p k  l  i  t   Speciﬁcally the inﬂuences of L k and p k  l  i  t  on the convergence of  k  l  i  t  are summarized as the Lemma 1  Lemma 1 The Convergence of the Individual Bayesian Updating Given the individual prior information state probability of any agent i  V  p k  l  i  t    0  1  for l  1  L k  and the nite number of information states of any k    L k  2 the following conclusions are held when calculating 9 1 If 1 L k  p k  l  i  t  for  t  lim t   k  l  i  t   1 holds 2 If 1 L k  p k  l  i  t  for  t   k  l  i  t  does not converge Instead it constantly equals to the initial posterior information estimation over all time intervals i.e  k  l  i  1    k  l  i  t  for  t  3 If 1 L k  p k  l  i  t  for  t  lim t   k  l  i  t   0 holds Proof The conditions required in the three cases correspondingly result in three possible parameter a  t   0  a  t  1 a  t   1 and a  t  1for  t  Then we examine the time-dependent cumulative product on a  t  under the three cases lim t  t    2 a         0  0  a    1  1  a    1    a    1 10 Substituting the results in 10 into 9 leads to the result From Lemma 1  it can be seen that the individual estimation can not be improved despite of its further measurements if the observed information accuracy stays at uniform level i.e p k  l  i  t   1 L k for  t  Besides if the quality of the individual observed information from the individual measurements is good enough i.e p k  l  i  t  1 L k  the individual estimation can converge to 1 Otherwise it leads to failure in the estimation of the information state probability distribution IV A DAPTIVE F USION S TRATEGY A Global Optimization Model As discussed in Section II some subregions may be out of the detection range of an agent i  which can be lumped in a set  i     i  The prior information corresponding to the subregion k    i  p k   l  i  t   can not be obtained from the individual measurements From Lemma 1  it can be found that the recursive Bayesian updating scheme based on 5 can not be implemented in this situation Therefore a distributed cooperative solution for information sharing and fusion among local agents is need ed to improve the accuracy of individual observed information In order to propose a cooperative distributed information estimation we rst develop a nonlinear constrained distributed optimization model Since we formulate the information of interest over the geographic region by a series of nite discrete probability distributions of information states of subregions we can model the optimization objective based on the information theory Speciﬁcally the JensenShannon divergence as an information metric also called information radius IRad  i s adopt ed t o repres ent a n estimation objective It can measure the disparity between two nite random graphs and can reﬂect the mutual information between two related random variables  G i v en a  ni t e discrete probability distribution p   p 1  p 2  p U  T where  U u  1 p u  1and  p u  0 the amount of uncertainty of this distribution p  namely the entropy can be calculated based on Shannon’s information entropy function E  p  26 E  p   U 012 u  1  p u log 2 p u  11 From Jensen’s inequality theorem it shows that this Shannon information entropy 11 is a concave function of the multiple probabilities p 1  p 2  p U  H o w e v er  t he equation 11 may not be applied under some discrete probability distributions For example when one entry in p is equal to zero i.e p u  0 11 is not valid for numerical computation Hence to overcome the drawback of the logarithmic function log     we do not directly adopt 11 in our following mathematical model Instead we establish a modiﬁed Shannon entropy by introducing a parameter  into 11 H  p   U 012 u  1   p u   log 2  p u    12 where    0  1  is a positive constant but should be small enough In 12 the range of the value of any p u is expanded to be  0  1  rather than  0  1   Letting  k    k  1  k  2  T where  k  1 and  k  2 are weights of the two information state probability distributions p k  t  and p k  i  t   respectively satisfying  k  1   k  2  1and 


3080 IEEE TRANSACTIONS ON INFORMATION THEORY VOL 63 NO 5 MAY 2017  k  1  k  2  0 we can deﬁne the Jensen-Shannon divergence of weights  k between p k  t  and p k  i  t  by JSD k  p k  t  p k  i  t    H   k  1 p k  t    k  2 p k  i  t      k  1 H  p k  t    k  2 H  p k  i  t   13 Based on the Jensen-Shannon divergence 13 we further formulate an individual objective function for any agent i as follows f i  p  t   012  k   JSD k  p k  t  p k  i  t   14 Subsequently a global objective function can be deﬁned by collecting all the individual components f  p  t   n 012 i  1 f i  p  t  15 For any k    the probabilities in p k  t  should satisfy an equality constraint  L k l  1 p v k  t   S k  l   1 and inequality constraints  p v k  t   S k  l   0 To provide the compact forms of these constraints we introduce an equality constraint coefﬁcient matrix C  diag  1 L 1  1 L 2  1 L m  T andan inequality constraint coefﬁcient matrix E  I q  It should be noted that the dimension of C is m  q while E is indeed a q  q identity matrix The constraints on p  t  are deﬁned as s  t   Ep  t   0 q Cp  t   1 m 16 where the inequality constraint is element-wise Because the Jensen-Shannon divergence is a nonnegative measure  f  p  t  is also a nonnegative real-value function i.e f  p  t   0 for any input p  t   Additionally the smaller the Jensen-Shannon divergence f  p  t  is the less the difference between the actual and the observed information distributions achieves That is the function f  p  t  can reach zero if and only if any observed distribution p k  i  t  at the individual agent i totally matches the actual distribution p k  t   Therefore treating the unknown p  t  as the decision variable and the prior probability distributions estimated from the observations  p  i  t   i  V   as input parameters we can develop an optimization model where the Jensen-Shannon divergence based objective function 15 is expected to be minimized under the constraints 16 min f  p  t   n 012 i  1 f i  p  t  s  t   Ep  t   0 q Cp  t   1 m  17 From 17 we see that the optimization model has linear constraints while its objective function is nonlinear The following Lemma 2 shows the convexity of its objective function f  p  t   Lemma 2 The Convexity of the Optimization Objective Function Given  k    k  1  k  2  T satisfying  k  1   k  2  1and  k  1  k  2  0for k  1  m  the optimization objective f  p  t  in the global model 17 is a strictly convex function of p  t   Proof According to the Lemma 1 in the work t he Jensen-Shannon divergence based function is strictly convex so that the objective function f  p  t  summing the JensenShannon divergence functions of all the agents must be also strictly convex Thus Lemma 2 is proved B Local Optimization Model From the Lemma 2  it can be found that if an algorithm existing for the nonlinear optimization model can converge to a stationary point of f  p  t   this algorithm can converge to a global minimum of the model In the application context of information estimation such a global minimum indeed corresponds to the actual probability distribution of information states of the entire region Hence we consider that every individual agent’s goal is to approach the same actual global distribution denoted by p 012  t   As each individual has a common goal determining the global distribution p 012  t   they are expected to share local independent observed information and perform local cooperative interaction with other neighbors Two essential issues arises when a distributed processing is considered 1 how to enable each agent to adapt their individual estimation in real time according to its own and neighbors continuous measurements 2 how to enable a better local fusion of each agent’s and its neighbors information to improve individual estimation performance rather than solely solving the global p 012  t  on its own information  To address these issues we rst propose a localized JensenShannon based objective function depending on interactions among the neighboring agents Th en each agent can minimize the localized objective function under the same constraints in the global model 17 through processing a gradient-projection procedure Finally an adaptive fusion strategy also based on Jensen-Shannon divergence is proposed to combine the local intermediate estimations of each agent and its neighbors Let V i denote the immediate neighborhood of an agent i including the agent i itself By introducing some spatial coefﬁcients  x j  i   j  i  V  we present an objective function for the agent i via a weighted sum strategy as g i  p  t   n 012 j  1 x j  i f j  p  t  18 where the coefﬁcients  x j  i  are nonnegative and satisfy  n i  1 x j  i  1and x j  i  0 if and only if j   V i  Considering that each agent can only excha nge its information with its immediate neighbors V i wedeﬁne g i  p  t  as an optimization objective for the individual i  Thus the local optimization model is deﬁned as min g i  p  t   n 012 j  1 x j  i f j  p  t  s  t   Ep  t   0 q Cp  t   1 m 19 where the local objective function g i  p  t  combines the neighbors individual cost functions This enables the 


TIAN et al  ADAPTIVE FUSION STRATEGY FOR DISTRIBUTED INFORMATION ESTIMATION 3081 intermediate estimation information to be diffused among neighboring agents in the network Iteratively solving the localized model 19 at every i can lead to a continuous local information diffusion over the multi-agent network which turns out to improve the individual information estimation Additionally we remark that the nonnegative coefﬁcients  x j  i  can lead to n 012 i  1 g i  p  t   n 012 i  1 n 012 j  1 x j  i f j  p  t   n 012 j  1 n 012 i  1 x j  i f j  p  t   n 012 j  1 f j  p  t  20 which shows that the sum of all individual objective functions  g i  p  t   is identical to the global objective function f  p  t   Since local observed information is diffused over the network and fused at individual nodes to enhance their p  i  t   these individuals can gradually arrive at a consensus on the probability distributions of information states of the whole surveillance region That is their p  i  t  is expected to approach the common distribution under t  Note the local objective function g i  p  t  is constructed with local neighbors p  i  t  and the global objective f  p  t  in 17 indeed collects every individual objectives  g i  p  t   shown in 20 Along with t   minimizing the global objective function in 17 is approximately equivalent to minimizing the local objective 18 at every node of the network G  V  E  in a decentralized manner C Gradient Projection Solution Each agent can solve the local optimization model 19 by the gradient projection algorithm Let p i  t  t  be the agent’s individual estimation of the global p 012  t  at the iteration t  i.e a feasible iterator for the local model 19 Without loss of generality at any p i  t  t   the inequality constraints Ep i  t  t   0 q can be decomposed into two parts one of which is called the active constraints represented by E i  1 p i  t  t   0 q i  1  another is called the nonactive constraints represented by E i  2 p i  t  t  0 q i  2  The coefﬁcient matrices E i  1 and E i  2 are sub-blocks of the matrix E  i.e E  col  E i  1  E i  2   The full-zero vectors 0 q i  1 and 0 q i  2 are also sub-blocks of 0 q i.e 0 q  col  0 q i  1  0 q i  2   where the dimensions satisfy q i  1  q i  2  q  We further point out that since all of the probabilities in a discrete distribution cannot be zero simultaneously the sum of their values constantly equals to 1 all the inequality constraints can not be active simultaneously That is the dimension of E i  1 can not be q  i.e q i  1  q being always held In fact because there totally exist m discrete information state distributions we can see q i  2  m which equivalently implies q i  1   q  m   With the active constraint coefﬁcient matrix E i  1 and the equality constraint coefﬁcient matrix C  we can construct a new constraint matrix associated with the iterator p i  t  t   M i  t  t    E i  1 C  21 where the dimension of M i  t  t  is  q i  1  m   q  The basic idea behind the gradient-projection iterative scheme is that a new iterator is generated in a feasible direction starting from the current feasible iterator When the current feasible iterator is within the feasible region the negative gradient direction can be employed for searching a new point otherwise when the current iterator is on the boundary of the feasible region a new feasib le direction is generated by projecting the negative gradient direction at the current point to the null space constituted by the active constraints Thus considering M i  t  t  with full row rank we are allowed to establish another new matrix P i  t  t   called projection matrix P i  t  t   E   M i  t  t   T 015 M i  t  t   M i  t  t   T   1 M i  t  t  22 It is worth pointing out that when the matrix M i  t  t  is empty we can simply set P i  t  t   E  Once the projection matrix P i  t  t  is achieved at the agent i  it can apply a steepest-descent iterative method to optimize their individual objective functions g i  p  t  in a negative direction of projected gradient d i  t  t   d i  t  t   P i  t  t   p  t  g i  p i  t  t  23 where  p  t  g i  p i  t  t  denotes the gradient of the individual objective function g i  p  t  evaluated at the point p i  t  t   Based on the equation 23 we can get a new iterator at the current point p i  t  t  by u i  t  1  t   p i  t  t    i d i  t  t  24 where the parameter  i  0 is a nonnegative step size According to the equation 24 the iterative procedure can be proceeded only when d i  t  t    0  To solve the problem when d i  t  t   0  we deﬁne an auxiliary vector s i  t  t  as s i  t  t   015 M i  t  t   M i  t  t   T   1 M i  t  t   p  t  g i  p i  t  t  25 Then we divide this vector s i  t  t  into two sub-blocks as follows s i  t  t    s i  t  1  t  s i  t  2  t   26 where the row indexes of s i  t  1  t  and s i  t  2  t  correspond to those of the blocks E i  1 and C in M i  t  t   respectively The Lemma 3 is presented for proceeding the iteration when d i  t  t   0  Lemma 3 Conditions on Gradient Projection Matrix for Iteration Given that the active-constraint coefﬁcient matrix M i  t  t   the projection matrix P i  t  t  and the iteration direction d i  t  t  are derived from 21 22 and 23 respectively and d i  t  t   0 is satisﬁed at the iterator p i  t  t   the following two conclusions are held 1 If s i  t  1  t  is element-wisely nonnegative i.e S i  t  1  t   0  then the current point p i  t  t  is a minimizer for the optimization model 19 


3082 IEEE TRANSACTIONS ON INFORMATION THEORY VOL 63 NO 5 MAY 2017 2 If s i  t  1  t  has at least a negative element denoted by s r i  t  1  t  0where r is its row index then one can remove the r th row from E i  1 to get a new active inequality constraint coefﬁcient matrix  E i  1 and to construct a new active constraint matrix  M i  t  t  by  M i  t  t   col   E i  1  C   With the new  M i  t  t   a new projection matrix  P i  t  t  can also be established by 22  P i  t  t   E  015  M i  t  t   T   M i  t  t  015  M i  t  t   T   1 015  M i  t  t   27 then d i  t  t  can be re-calculated by d i  t  t    P i  t  t   p  t  g i  p i  t  t  28 such that it can satisfy d i  t  t    0 to proceed the iteration 24 Proof When s i  t  1  t   0 and d i  t  t   0  we can see 0   E   M i  t  t   T 015 M i  t  t   M i  t  t   T   1 M i  t  t    p  t  g i  p i  t  t    p  t  g i  p i  t  t    M i  t  t   T 015 M i  t  t   M i  t  t   T   1 M i  t  t   p  t  g i  p i  t  t    p  t  g i  p i  t  t    E i  1  T s i  t  1  t    C  T s i  t  2  t  29 The equation 29 is exactly the Kuhn-Tucker condition  Thus under the c ondition of 1 in Lemma 3  p i  t  t  is indeed a local minimizer of the optim ization model 19 Recall that Lemma 2 states the convexity of the Jensen-Shannon based objective function The model 19 has a convex objective function and linear constraints which indicates that p i  t  t  is also a global optimum of this model Otherwise there exists at least an element s r i  t  1  t  in s i  t  1  t  that is negative i.e s r i  t  1  t  0 Hence we denote the corresponding r th row of E i  1 as E r i  1  To proceed this proof we turn to induce a contradiction given  P i  t  t   p  t  g i  p i  t  t   0  It can be found that noting  M i  t  t   col   E i  1  C    E i  1  T s i  t  t   C T s i  t  t   015  E i  1  T  s i  t  1  t   s r i  t  1  t   E r i  1  T  C T s i  t  2  t   015  M i  t  t   T s i  t  t   s r i  t  1  t   E r i  1  T 30 where  s i  t  1  t  is composed of all the entries in s i  t  1  t  except the r th one and s i  t  t  is composed of  s i  t  1  t  and s i  t  2  t   Substituting 30 into 29 gets 0   p  t  g i  p i  t  t   015  M i  t  t   T s i  t  t   s r i  t  1  t   E r i  1  T 31 Furthermore  P i  t  t   p  t  g i  p i  t  t   0 can lead to 0   P i  t  t   p  t  g i  p i  t  t    E  015  M i  t  t   T   M i  t  t  015  M i  t  t   T   1  M i  t  t    p  t  g i  p i  t  t    p  t  g i  p i  t  t   015  M i  t  t   T s i  t  t  32 Thus subtracting 32 from 31 yields 0  015  M i  t  t   T 015 s i  t  t   s i  t  t    s r i  t  1  t   E r i  1  T 33 The right side of 33 illustrates a linear combination of the row vectors of M i  t  t  Since s r i  t  1  t    0 the row vectors of M i  t  t  are linearly dependent This is incompatible with the fact that M i  t  t  has full row rank Therefore  P i  t  t   p  t  g i  p i  t  t    0  and the conclusion 2 of Lemma 3 is proven Indeed Lemma 3 gives a theoretical condition that indicates when to stop iterating at a given point Speciﬁcally according to the proof of Lemma 3  an iterator p i  t  t  satisfying both of d i  t  t   0 and s i  t  1  t   0 is a Kuhn-Tucker point it is also an optimum since the objective function of the model 19 is strictly convex as presented in Lemma 2  On the other hand since the objective function of the model 19 g i  p  t   collects the agent i s neighboring components  f j  p  t   j  V i   its gradient with respect to p  t  also combines the gradient information of the neighbors i.e  p  t  g i  p  t    j  V i x j  i  p  t  f j  p  t   Recall that in the equation 14 the real-time observation information of any neighbor j  V i  p  j  t   has been introduced into its Jensen-Shannon based function f j  p  t   The agent i s gradient formula  p  t  g i  p  t  not only incorporates its own but also the neighbors real-time observation information In this way the iterative procedure based on 24 can adapt the individual intermediate estimation u i  t  1  t   to local real-time observation information Furthermore once the computation of 24 is accomplished at each individual agent the agent i can enhance its estimation at iteration  t  1  by combining the intermediate estimations of all its neighbors based on a linear-weighted fusion strategy That is we compute i s next iterator p i  t  1  t  by p i  t  1  t   n 012 j  1 y j  i u j  t  1  t  34 where  y j  i  j  1  n  are some non-negative weights that satisfy  n j  1 y j  i  1and y j  i  0 if and only if j   V i  Essentially the equation 34 can lead to the fusion of agents intermediate estimation information over the network which can further beneﬁt the estimation performance of each individual Combining 24 and 34 induces a distributed cooperative estimation solution as  u i  t  1  t   p i  t  t    i  n j  1 x j  i P i  t  t   p  t  f j  p i  t  t  p i  t  1  t    n j  1 y j  i u j  t  1  t  35 for  i  V  


TIAN et al  ADAPTIVE FUSION STRATEGY FOR DISTRIBUTED INFORMATION ESTIMATION 3083 The mathematical structure of the iterative formulas in 35 coincides with the ATC-type Adapt-Then-Combine computation framework  11 T he  r s t i t e rat i o n e quat i o n in 35 can be treated as the individual adaptation to realtime observation information while the second is the combination of multiple agents intermediate information In 35 considering the constraints in the optimization model 19 it is required to guarantee that the estimations  p i  t  t   at each iteration t is feasible The following theorem is presented to guarantee the feasibility of the proposed iterative algorithm based on 35 Let  b j  t  t   0 q j  2  E j  2 p j  t  t  and  d j  t  t   E j  2 d j  t  t  for any j  V i  and denote the l th  l  1  q j  2  elements of the vectors  b j  t  t  and  d j  t  t  by  b j  t  l  t  and  d j  t  l  t   respectively We establish the following Theorem 1 The Feasibility of the Iterative Algorithm Suppose p j  t  t  is a feasible point of the optimization model 19 for  j  V i and  j  0  max j   Then p i  t  1  t  obtained by 35 is also a feasible point  max j is deﬁned by  max j     min   b j  t  l  t   d j  t  l  t       d j  t  l  t  0    d j  t  t   0 q j  2    d j  t  t   0 q j  2 36 Proof Substituting the rst equation of 35 into the second one leads to p i  t  1  t   n 012 j  1 y j  i p j  t  t   n 012 j  1 y j  i  j P j  t  t   p  t  g j  p j  t  t  37 The results of Ep i  t  1  t  and Cp i  t  1  t  are Ep i  t  1  t   n 012 j  1 y j  i Ep j  t  t   n 012 j  1 y j  i  j EP j  t  t   p  t  g j  p j  t  t   n 012 j  1 y j  i Ep j  t  t   n 012 j  1 y j  i  j  E j  1 E j  2  P j  t  t   p  t  g j  p j  t  t   n 012 j  1 y j  i Ep j  t  t   n 012 j  1 y j  i   j E j  1 P j  t  t   p  t  g j  p j  t  t   j E j  2 P j  t  t   p  t  g j  p j  t  t   38 Cp i  t  1  t   n 012 j  1 y j  i Cp j  t  t   n 012 j  1 y j  i  j CP j  t  t   p  t  g j  p j  t  t  39 Firstly according to the deﬁnition of the projection matrix P j  t  t   we can get  j M j  t  t  d j  t  t    j M j  t  t  P j  t  t   p  t  g j  p j  t  t    j M j  t  t   E   M j  t  t   T 015 M j  t  t   M j  t  t   T   1 M j  t  t    p  t  g j  p j  t  t    j 015 M j  t  t   M j  t  t   M j  t  t   T 015 M j  t  t   M j  t  t   T   1 M j  t  t    p  t  g j  p j  t  t    j  M j  t  t   M j  t  t    p  t  g j  p j  t  t   0 q j  1  m 40 Note M j  t  t   col  E j  1  C   40 is equivalent to   j E j  1 P j  t  t   p  t  g j  p j  t  t   0 q j  1  j CP j  t  t   p  t  g j  p j  t  t   0 m 41 Substituting the second equation of 41 into 39 gets Cp i  t  1  t   n 012 j  1 y j  i Cp j  t  t  42 Since p j  t  t  is a feasible point satisfying Cp j  t  t   1 m and  n j  1 y j  i  1 42 is equivalent to Cp i  t  1  t   1 m which indicates that the new iterator p i  t  1  t  satisﬁes the equality constraints of the model 17 To investigate the equation 38 we consider two cases 1 If  d j  t  t  is element-wisely non-negative i.e  d j  t  t   0 q j  2  then the upper bound of the step size  max j issetto  accordingly In this case we can see that  j  d j  t  t    j E j  2 d j  t  t    j E j  2 P j  t  t   p  t  g j  p j  t  t   0 q j  2 43 is held for  j  0 Thus according to 41 and 43 we have    j E j  1 P j  t  t   p  t  g j  p j  t  t    j E j  2 P j  t  t   p  t  g j  p j  t  t     0 q j  1 0 q j  2   0 q 44 Note that the feasible point p j  t  t  satisﬁes Ep j  t  t   0 q  Substituting 44 into 38 derives Ep i  t  1  t   n 012 j  1 y j  i Ep j  t  t   0 q 45 At this point the new iterator p j  t  1  t  also satisﬁes the inequality constraints of the optimization model 17 2 If there exists at least one element in  d j  t  t   i.e  d j  t  t   0 q j  2  we can divide  d j  t  t  into two sub-blocks  d j  t  1  t  and  d j  t  2  t  where the rst sub-block  d j  t  1  t  contains the negative elements of  d j  t  t  and the second  d j  t  2  t  contains the nonnegative elements i.e  d j  t  1  t  0 r j  1 and  d j  t  2  t   0 r j  2  r j  1 and r j  2 are the dimensions of these two sub-blocks respectively and satisfy r j  1  r j  2  q j  2  Thus  d j  t  t  can be 


3084 IEEE TRANSACTIONS ON INFORMATION THEORY VOL 63 NO 5 MAY 2017 rearranged as  d j  t  t   col   d j  t  1  t   d j  t  2  t    In addition we also re-express the matrix E j  2 as E j  2  col  E j  2  1  E j  2  2  where E j  2  1  R r j  1  q and E j  2  2  R r j  2  q  In the second case where the upper bound of the step size is limited by 36 it can be found that for any negative element  d j  t  1  l  t    d j  t  1  t   the following inequality is held  j   max j  min   b j  t  l  t   d j  t  1  l  t     b j  t  l  t   d j  t  1  l  t  46 Additionally noting  d j  t  1  l  t  0 46 is equivalent to  j  d j  t  1  l  t    b j  t  l  t  47 We can further induce  j  d j  t  1  t    b j  t  1  t   0 r j  1  E j  2  1 p j  t  t  48 where  b j  t  1  t  is a sub-block of  b j  t  t  whose row indexes correspond to those of  d j  t  1  t  Since  d j  t  2  t  is elementwisely nonnegative we can also get  j  d j  t  2  t   0 r j  2 49 Combining 48 and 49 we can get  j  d j  t  t    j   d j  t  1  t   d j  t  2  t     0 r j  1  E j  2  1 p j  t  t  0 r j  2  50 According to the deﬁnition of  d j  t  t   i.e  d j  t  t   E j  2 d j  t  t   50 is equivalent to  j E j  2 d j  t  t    j E j  2 P j  t  t   p  t  g j  p j  t  t    0 r j  1  E j  2  1 p j  t  t  0 r j  2  51 According to 41 and 51 the following inequality is held in this case    j E j  1 P j  t  t   p  t  g j  p j  t  t    j E j  2 P j  t  t   p  t  g j  p j  t  t      0 q j  1 0 r j  1  E j  2  1 p j  t  t  0 r j  2   52 Then substituting 52 into 38 we further derive Ep i  t  1  t   n 012 j  1 y j  i   E j  1 E j  2  1 E j  2  2   p j  t  t      n j  1 y j  i 0 q j  1  n j  1 y j  i  0 r j  1  E j  2  1 p j  t  t    n j  1 y j  i 0 r j  2       n j  1 y j  i E j  1 p j  t  t   n j  1 y j  i  E j  2  1 p j  t  t   0 r j  1  E j  2  1 p j  t  t    n j  1 y j  i E j  2  2 p j  t  t     0 q 53 Therefore in the second case p i  t  1  t  also satisﬁes the inequality constraints To sum up we have proven Theorem 1  Based on Theorem 1  we can enhance the adaption step in 35 by designing an appropriate step size  j  Speciﬁcally we consider to optimize  j at each iteration t so as to minimize the objective function g j  p   Once the iteration direction d j  t  t  is obtained by j  V i at any iteration t  we can treat the step size as a decision variable denoted by   and formulate an objective function with respect to    j     g j  p j  t  t    d j  t  t   54 Thus an optimal searching step at t  denoted by  j  t  can be derived as  j  t  argmin    0  max j    j   55 where the upper bound  max j is given according to Theorem 1  D Optimization of Fusion Weights We represent u i  t  1  t   col  u i  k  t  1  t   k  1  m  where u i  k  t  1  t  is the intermediate estimation on the probability distribution of information states of the subregion k  From 35 it can be found that not only the step size  j but also those fusion weights  y j  i  j  V i  have signiﬁcant inﬂuence on the performance of 35 For simplicity let y i denote the set of fusion weights of the agent i i.e y i   y j  i  j  V i  and U i  k  t  1  t    u j  k  t  1  t   j  V i  The Jensen-Shannon based cost function with respect to y i can be deﬁned by JSD  U i  k  t  1  t    y i   H   012 j  V i y j  i u j  k  t  1  t       012 j  V i y j  i H  u j  k  t  1  t     56 Subsequently we can obtain optimal fusion weights by solving the following model min W i  y i   012 k   JSD  U i  k  t  1  t    y i  s  t    j  V i y j  i  1 y j  i  0for  j  V i 57 In 57 y i represents the decision variable This model takes U i  k  t  1  t  as input parameters which implies that once  u j  t  1  t   j  V i  are aggregated at the agent i  the minimizer of this model can be solely solved by the individual agent Thus this model can be well integrated with the previous model 19 Besides according to Lemma 2  the weight optimization model 57 also has a convex objective function It is a typical convex optimization problem which can be solved by many existing efﬁcient numerical algorithms such as augmented Lagrangian methods and the sequential quadratic programming techniques   A schematic diagram of the deployment of a multi-agent network is given in Fig.1 The implementation of the algorithm presented by 35 mainly involves four steps in the rst step 


TIAN et al  ADAPTIVE FUSION STRATEGY FOR DISTRIBUTED INFORMATION ESTIMATION 3085     Fig 1 The deployment of a multi-agent network Fig 2 The framework of the adaptive fusion method any agent i  V collects the gradient information from its immediate neighbors   p  t  f j  p i  t  t   j  V i   so that it can construct a projection matrix P i  t  t  as well as the iteration direction d i  t  t   Then the agent i can calculate an optimal searching step  i  t according to 55 and obtains its own intermediate estimation u i  t  1  t  based on the adaptation equation in 35 Thirdly i obtains an optimal fusion weights y i by solving the model 57 constructed based on its own and its neighbors intermediate estimations Finally a next iterator p i  t  1  t  can be calculated based on the optimal fusion weights according to the combination equation in 35 These four steps are also performed at other agents such that the overall network can achieve a cooperative information estimation To be speciﬁc Fig.2 details the process of the overall proposed solution for cooperative information estimation over a multi-agent network which co mbines the Bayesian updating formula 5 with 35 55 and 57 Fig.2 shows that each agent i needs to broadcast its own intermediate estimation u i  t  1  t   as well as the individual estimation p i  t  t  to its immediate neighbors at each iteration t  Especially any agent’s individual estimation p i  t  t  is used by each of its local neighbors to evaluate the gradient of the Jensen-Shannon based function 14 and once the gradient  p  t  f j  p i  t  t  is obtained by a neighbor j  it should be fed back from the neighbor j to the agent i  There are two time indexes i.e t and t  The former denotes each discrete time interval during which any agent i carries out multiple measurements i.e collecting V i samples on the detection signal to obtain the real-time observation information on the local subregions and then performs the iterative algorithm presented by 35 55 and 57 At the end of each time interval t  the agent calculates the Bayesian updating formula 5 with the individual estimation on the global region obtained from the iterative algorithm As shown in Fig.1 t is used to index the iteration of the proposed algorithm At the beginning of the iterative procedure of any agent i at t  0 i.e at t  0and t  0 we initialize the individual estimation p i  t  t  by following the uniform distribution That is the adaptive fusion algorithm for information estimation is initialized by setting  p i  k  l  0  0   1  L k  l  1  L k  k    for all i where p i  k  l  0  0  denotes the probability of the l th information state of the subregion k estimated by the agent i at t  0 The individual prior distribution of information states of any subregion out of the detection range is also initialized by following the uniform distribution i.e  p k   l  i  0   1  L k   i  1  L k   k    i  for all i  In addition for t  1 at the beginning of the algorithm cycle t  0 the individual estimation p i  0  t  is initialized as p  i  t   i.e p i  0  t   p  i  t   For the sake of practical computation we pre-specify the total number of the algorithm iterations denoted by T  sufﬁciently large to guarantee the convergence of the algorithm The detailed algorithm is shown in Algorithm 1  The main steps of the adaptive fusion strategy are Step 1 Observation  During time interval t  each agent i  V performs multiple measurements to collect V i samples  v k  i  t   k   i   from the detection signals corresponding to the subregions in its detection range Then the agent can calculate the observation information distribution p k  i  t  basedonthecumulative observations  v k  i     0  t  k   i   For the subregions out of the detection range i.e  k    i  their prior distributions of information states are set to a zero vector That is let p k   i  t   0 for all k    i  Step 2 Information estimation with adaptive fusion Initialize p i  t  t  for any i by setting p i  k  0  t   p k  i  t  for the subregions in i s detection range i.e for all k   i  and setting p i  k   0  t   p k   i  t  1  for those out of i s detection range i.e for all k    i  Then run the Algorithm 1 until t  T  Step 3 Bayesian Updating Let p  i  t   p i  T  t  do Bayesian updating based on 5 where p  i  t  is input parameter According to the iterative algorithm given above we remark that since there may be some subregions that are located out of an agent’s detection range this a gent’s real-time observation 


3086 IEEE TRANSACTIONS ON INFORMATION THEORY VOL 63 NO 5 MAY 2017 Algorithm 1 DCIE-AF Distributed Cooperative Information Estimation with Adaptive Fusion Input p  i  t   p i  0  t  and T Output p i  T  t  repeat Broadcast p i  t  t  to j  V i as well as collect  p j  t  t   j  V i   Evaluate f i  p  t  at each p j  t  t  and broadcast   p  t  f i  p j  t  t   j  V i   Collect   p  t  f j  p i  t  t   j  V i   Construct P i  t  t  and d i  t  t  basedonitsown  p  t  f i  p i  t  t  and   p  t  f j  p i  t  t   j  V i   Compute  max i according to 36 and obtain an optimal step  i  t by solving 55 Obtain u i  t  1  t  based on p i  t  t   d i  t  t  and  i  t according to 35 Broadcast u i  t  1  t  to j  V i as well as collect  u j  t  1  t   j  V i   Optimize the fusion weights y i with  u j  t  1  t   j  V i  by solving 57 Obtain new estimation p i  t  1  t  according to 35 t  t  1 until t  T distributions over these subregions can be simply set to zero implying that this agent does not contribute to the information gain in estimation of these subregions In fact following the underlying idea of the model 35 the agents can achieve their individual estimations over the subregions out of their detection range by iteratively collecting and fusing the diffused estimations of others that can directly detect these subregions E Analysis of Convergence In a distributed sensor environment each agent’s computation is not only inﬂuenced by its own local observation data but also by the shared information of its local neighbors To analyze the performance of the adaptive fusion strategy we introduce an error vector e i  t  t   p 012  t   p i  t  t  58 Combining 24 and 34 we derive p i  t  1  t   n 012 j  1 y j  i p j  t  t   n 012 j  1 y j  i  j  t P j  t  t   p  t  g j  p j  t  t  59 which can lead to recalling  n j  1 y j  i  1 e i  t  1  t   n 012 j  1 y j  i e j  t  t   n 012 j  1 y j  i  j  t P j  t  t   p  t  g j  p j  t  t  60 Besides the mean value theorem s h o w s t hat f or an y c ontinuously differentiable function R  x   the following integral equation is held R  x  h   R  x     1 0 R   x  uh  d u  h 61 where x denotes a certain variable h is a real parameter and u is an integral variable In order to relate the gradient term  p  t  g j  p j  t  t  with the error quantity e j  t  t   we substitute h  e j  t  t   x  p 012  t  and R  p  t  g j    into 61 and rewrite  p  t  g j  p j  t  t  as  p  t  g j  p j  t  t    p  t  g j  p 012  t     1 0  2 p  t  g j  p 012  t   u e j  t  t   d u  e j  t  t  62 Since p 012  t  represents an optimum of the objective function g j  p  t   we can have  p  t  g j  p 012  t   0  Thus 62 is reduced to  p  t  g j  p j  t  t     1 0  2 p  t  g j  p 012  t   u e j  t  t   d u  e j  t  t  63 Substituting 63 into 60 yields e j  t  1  t   n 012 j  1 y j  i  E   j  t P j  t  t  H j  t  t   e j  t  t  64 where H j  t  t  is deﬁned by H j  t  t    1 0  2 p  t  g j  p 012  t   u e j  t  t   d u 65 Lemma 4 Positive Semi-Deﬁniteness of Gradient Projection Matrix Given that P j  t  t  obtained from 22 satisﬁes P j  t  t   2 p  t  g j  p j  t  t     0  P j  t  t  is a non-zero symmetrical positive-semideﬁnite matrix and its eigenvalues only consists of 1 and 0 Proof According to 22 it is easy to validate  P j  t  t   T  P j  t  t  and  P j  t  t   2  P j  t  t   Thus for any non-zero column vector x   0  we can get x T P j  t  t  x  x T P j  t  t  T P j  t  t  x   P j  t  t  x  T  P j  t  t  x   0 66 Thus P j  t  t  is a positive semideﬁnite matrix Furthermore since P j  t  t   P j  t  t  2  0  the characteristic polynomial equation of P j  t  t  can be expressed as x  x 2   0  x   1  x   0 Therefore the eigenvalue set of P j  t  t  is composed of 0 and 1 Additionally it should be noted that since P j  t  t    0 otherwise a contradiction would arise from P j  t  t   0 when considering P j  t  t   p  t  g j  p j  t  t    0  all of the eigenvalues of P j  t  t  cannot be equal to 0 simultaneously Thus Lemma 4 is proved On the other hand according to Lemma 2  the JensenShannon based function f i  p  t  is strongly convex This implies that its Hessian matrix  2 p  t  f i  p  t  can be sufﬁciently bounded away from 0 To show this we rst derive the expression of  2 p  t  f i  p  t  as  2 p  t  f i  p  t   diag   2 p k  t  JSD k  p k  t  p k  i  t   k    67 


TIAN et al  ADAPTIVE FUSION STRATEGY FOR DISTRIBUTED INFORMATION ESTIMATION 3087 Recalling the deﬁnition of JSD k  p k  t  p k  i  t  wefurther derive  2 p k  t  JSD k  p k  t  p k  i  t    2 p k  t  H  k  1 p k  t    k  2 p k  i  t    k  1  2 p k  t  H  p k  t  68 Accordingly  2 p k  t  JSD k  p k  t  p k  n  t  can be expressed as  2 p k  t  JSD k  p k  t  p k  i  t   diag   k  1  k  2  p k  l  i  t      ln 2   p k  l  t      k  1 p k  l  t    k  2 p k  l  i  t           69 where l  1  L k  From 67 and 69 it can be found that  2 p  t  f i  p  t  is indeed a diagonal matrix Thus we can easily get the spectral radius of  2 p  t  f i  p  t  012 015  2 p  t  f i  p  t    max  k  l   k  1  k  2  p k  l  i  t      ln 2   p k  l  t      k  1 p k  l  t    k  2 p k  l  i  t      70 Since the agent j  s Hessian matrix evaluated at the agent j s individual estimation p j  t  t  can be represented by  2 p  t  f j   p j  t  t   we can calculate the upper bound of the spectral radius of  2 p  t  f j   p j  t  t  012 015  2 p  t  f j   p j  t  t    max  k  l   k  1  k  2  p k  l  j   t      ln 2   p j  k  l  t  t      k  1 p j  k  l  t  t    k  2 p k  l  j   t       max  k  l   k  1  k  2  p k  l  j   t      ln 2    k  2 p k  l  j   t        j   j 71 where p j  k  l  t  t  corresponds to the p robability of the l th information state of the subregion k estimated by the agent j  and  j   j represents the upper bound The Theorem 2 is presented for stable-state performance Theorem 2 The Stable-State Convergence Given 0   j  min   max j  2  n j   1 x j   j  j   j  for any j  V  the iterative procedure given in 35 asymptotically converges to a stable state for any initial feasible solutions  p j  0  t   j  V  andas t   lim t  015 e j  t  t  015 2  0 72 is held for all j  V  Proof According to Lemma 4  the spectral radius of P j  t  t  cannot be larger than 1 i.e 012 P j  t  t   1 This indicates that 012   j P j  t  t  H j  t  t     j 012  P j  t  t   012  H j  t  t     j 012  H j  t  t   From H j  t  t  in 65 we can further get  j 012  H j  t  t     j 012   n 012 j   1 x j   j  1 0  2 p  t  f j   p 012  t   u e j  t  t   d u   73 Based on the mean value theorem and 71 there always exists a certain point  j  t  t    p 012  t   e j  t  t  p 012  t   that  1 0  2 p  t  f j   p 012  t   u e j  t  t   d u   2 p  t  f j    j  t  t     1 0 d u   012 015  2 p  t  f j    j  t  t    E  j   j E 74 Substituting 74 into 73 we can get  j 012  H j  t  t    j n 012 j   1 x j   j  j   j 75 Since  j  2  n j   1 x j   j  j   j  we can get 012   j P j  t  t  H j  t  t     j  n j   1 x j   j  j   j  2 This result is equivalent to   1  012   j P j  t  t  H j  t  t      1 76 which implies that the matrix  E   j P j  t  t  H j  t  t   is stable namely its sub-multiplicative matrix norm 015 E   j P j  t  t  H j  t  t  015 2 satisfying 015 E   j P j  t  t  H j  t  t  015 2  012 max   1 77 where 012 max  max j  V  012  E   j P j  t  t  H j  t  t   and  is a positive number that is sufﬁciently small Now we denote the global error vector by Q t  t  that collects the error quantities from all the agents Q t  t   col  015 e j  t  t  015 2   j  V  78 Also we denote a fusion weight matrix as Y    y j  i  n  n and lump all the step sizes into a diagonal matrix    diag   j  j  V   Subsequently we derive two block matrices by using the Kronecker product operator   Y  Y   E 79      E 80 where Y and  are of nq columns and nq rows Using these notations above we can rewrite 64 as Q t  1  t   Y T  I nq   Z t  t   Q t  t  81 where Z t  t   diag  P j  t  t  H j  t  t   j  V   Since 015 Y T 015 2  1 we can calculate the 2-norm of both sides of 81 as 015 Q t  1  t  015 2 015 Y T  I nq   Z t  t   Q t  t  015 2 015 Y T 015 2 015 I nq   Z t  t  015 2 015 Q t  t  015 2   012 max    015 Q t  t  015 2   012 max    t  1 015 Q 0  t  015 2 82 


3088 IEEE TRANSACTIONS ON INFORMATION THEORY VOL 63 NO 5 MAY 2017               Fig 3 A region and a network’s co mmunication topology with 6 agents Red dots agents Red dotted lines agents detection ranges Blue lines the network’s communication topology Since  012 max     1 we can get lim t  015 Q t  1  t  015 2  0 The result is equivalent to 72 V N UMERICAL E XAMPLES To evaluate the performance of the distributed information estimation method we set up a scenario where the entire surveillance region is divided into 16  4  4 subregions and several agents are initially generated and distributed over this surveillance region Each agent is considered to be able to detect partial subregions and multiple agents are assumed to be locally connected when th ey are within each other’s communication range An instance of a network’s communication topology with 6 agents is shown in Fig.3 where every grid denotes a subregion and the whole grid plane of 2 dimensions represents the overall surveillance region We assume that each subregion is an information source which could generate a series of information of interest And the information values follow some certain distributions For example the k th subregion generates the information v k  t  at time t  and this subregion’s actual information is assumed to be a random variable following a nite discrete distribution that could be represented with different states  S k  l  l  1  L k   L k is the number of the whole states Each state denotes a certain range of the information variable v k  t  and is associated with a certain probability p  v k  t   S k  l  For testing our model we randomly generate the distribution of information states of each subregion as shown by the dark histogram in Fig.4 These distributions are treated as the actual information distributi ons which each agent would like to estimate In measurement int erval each agent could observe sampleNum samples from each subregion in its detection range and could not detect those subregions out of its range For instance in Fig.3 the grids at the right side of the entire plane could not be detected by the agent located at the top left of the plane We also assume that there are some certain white Gaussian noises existing in each agent’s observations The mean value of the noise corresponding to the agent i is set to 0 and the standard deviation 015 i  For simulations we randomly generate 015 i for each agent by following a uniform distribution U  0 015 max   namely 015 i  U  0 015 max   Additionally we denote the total number of time intervals as T  i.e 0  t  T  and the number of epochs for performing the proposed iterative scheme  Algorithm 1 s T  i.e 0  t  T  We rstly x 015 max  1  5 sampleNum  100 T  1000 and T  50 respectively In the Shannon entropy based function 12 the small parameter  is set to 1  10  6  The probability distribution co rresponding to the information state of every subregion maint ained by each individual agent is initialized by following the uniform distribution Then we set the agent number n  6 and have performed the simulations with 50 independent replications Thus we could average the results over those 50 simulations and then show the whole estimation results we randomly select an agent whose detection subregions are  2  3  4  6  7  8   and illustrate the convergence of its individual estimation corresponding to the whole subregions in Fig.4 the gray histogram in Fig.4 It can be found that even though those subregions the subregions  1  5  9  10  11  12  13  14  15  16   are out of the detection range of this selected agent its actual information state distribution could also be well approached by this agent’s estimation based on our proposed method In order to quantify the performance we deﬁne the evaluation metric i.e the av eraged absolute error at t obtained by an agent i  which is denoted by AAE  i  t  and calculated as AAE  i  t    m k  1  L k l  1    p k  l  i  t   p k  l  T  i  t     q 83 Similarly to evaluate the whole agent network we could also calculate the absolute error by a veraging over all the agents results We deﬁne the averaged absolute error relevant to the agent network as AAE  t  AAE  t    n i  1 AAE  i  t  n 84 Next for evaluating the inﬂuen ce of different parameters on the proposed scheme we set up several simulation situations In the rst situation we use 015 max  1  5 sampleNum  100 T  1000 and T  50 and vary the number of agents from 6 to 14 namely n  6  8  10  12  14   In this situation we also compare our method with the distributed information estimation strategy based on the traditional consensus approach which adopts the same settings on 015 max  sampleNum  T and T  The compared method is simulated at n  6 The results at each point n are also averaged over 50 independent simulations These results are shown in Fig.5 In the second situation we x the number of agents as n  6andthen set different 015 max to show the impact of the noise magnitude on the convergence The consensus-based method uses the xed setting 015 max  0  1 in this situation The third situation simulates the proposed method at different settings on the sample number sampleNum   10  50  200  300   while we x sampleNum  300 for the compared method In this situation we also keep 015 max  1  5 T  1000 T  50 and n  6 From the results it can be found that the agent number impacts the estimation performance of the overall network Particularly with the same number of agents e.g n  6 our proposed method is shown to outperform the compared one Besides from Fig.5a we nd that more agents does not always guarantee a better estimation This gure shows that the 


TIAN et al  ADAPTIVE FUSION STRATEGY FOR DISTRIBUTED INFORMATION ESTIMATION 3089                                  Fig 4 Simulated distributions of information states of 16 subregions a Subregion 1 b Subregion 2 c Subr egion 3 d Subregion 4 e Subreg ion 5 f Subregion 6 g Subregion 7 h Subregion 8  i Subregion 9 j Subregion 10 k Subregion 11 l Subregion 12 m Subregion 13 n Subregio n 14 o Subregion 15 p Subregion 16                                                                        Fig 5 The results obtained from different situations a The  rst situation b The second situation c The third situation averaged absolute error of the individual estimation obtained by a network consisting of 6 agents is slightly better than those obtained by the other networks which contain more than 6 agents The main reason for a slight drop in the performance is that more agents indicating a larger-scale network involving more decision variables in the optimization model could slow down the convergence of the overall network In order to ensure that the distributed algorithm could approach closer to an optimal point of a larger-scale optimization problem they need more interactions and more numbers of learning iterations to diffuse and fuse local information over the network Recall that we have set the same total number of iterations between successive observations i.e T  50 for all the networks That is the iterative algorithm dealing with a 


3090 IEEE TRANSACTIONS ON INFORMATION THEORY VOL 63 NO 5 MAY 2017 larger-scale optimization problem in the case of a larger-scale network is terminated in the same total step size as in the case of a smaller-scale network which could result in a relatively conservative estimate for the optimal point By contrast the optimization algorithm could approach much closer to the optimal point within a nite number of iterations when it handles a smaller-scale optimization problem Actually it is clear that there is a trade-off between the choice of the amount of the agents deployed i.e the scale of the multi-agent network and the potential computing cost arising from complexity in the distributed optimization On one hand a minimum number of agents should be needed so as to ensure that their overall detection range could cover the whole surveillance area More agents added could improve the reliability of the distributed network On the other hand the network size is also increased by more agents  leading to more complexity of the network topology which would require much more effort to handle the corresponding distributed optimization problem Generally a distributed algorithm needs more computing communication resources e.g data buffer bandwidth to address a larger-scale model and more iterations to guarantee its convergence Thus there should be an optimal number of agents for deployment which could depend on not only the algorithm cost and performance in distributed computation but also the amount and distribution of surveillance regions noise level in observations and other comprehensive factors involved in a speciﬁed application context The issue is related to the optimal coverage control which aims at a solution that could attain a speciﬁed optim al objective at the meanwhile determining a minimum number of agents whose coverage could cover the target area This issue is out of scope of this paper it can be referred to many existing works such as  In the second situation see Fig.5b the increased noise level indicated by 015 max could result in a larger averaged absolute error of the overall network The noise in individual observations could also lead to the randomness of the gradient process in the equation 62 so that the actual estimation error of the network could not fully converge to zeros This fact could also be validated by the results in the rst situation as shown in Fig.5a That is the larger amount of agents does not guarantee a lower gradient noise process of the overall network Nevertheless from the results in Fig.5b it can be found that once the noises of individual observations under a certain level a good global information estimation of the overall network could be guaranteed regardless of the limitation of each individual agent’s detection and communi cation The results from the third situation in Fig.5c shows that increasing the amount of measurements denoted by the sample number sampleNum  at each individual observation could decrease the absolute error on average by the proposed method It is because a larger number of samples observed by each individual agent could make the individual estimation more approximate to the actual distribution of a subregion The r esult is in accordance with the law of large number  A ddi t i onal l y  c ompari ng t h e r es ul t s obtained by our proposed method with those of the consensusbased method the averaged absolute error converges to a lower level by our method Speciﬁcally even when our method       Fig 6 Evaluation of the proposed method at different T and T  is simulated at a higher noise level such as 015 max  0  5  1 see Fig.5b or adopts a smaller sample number such as sampleNum  50  200 see Fig.5c it outperforms the consensus-based method as well Finally to evaluate the inﬂuen ce of different observation amounts and iteration numbers on the performance of the multi-agent network we simulate our method at different T   100  400  700  and T   50  80  100   In addition in this situation we x sampleNum  100 and the other parameters 015 max and n are set to be 015 max  1  5and n  6 From the results shown in Fig.6 it can be found that more observations or more iterations tend to reduce the averaged absolute error of the whole network The main reason is that more observations implying more measurem ents could make each agent approach to the actual information state distributions of those subregions in its detection coverage and increasing iteration number could make individual estimation much closer to the ideal solution of the optimization model 19 Appropriate settings on them could be selected or tuned based on a speciﬁed application scenario of interest VI C ONCLUSION In this paper we have proposed an adaptive distributed fusion strategy for estimating global information over a cooperative multi-agent network We have modeled the information of interest associated with a global region being detected by the network from a probabilistic perspective in which probability is related to the accuracy of observed and estimated information We apply an information-theoretic measure i.e the Jensen-Shannon divergence to formulate two objective functions of any agent subject to linear equality and inequality constraints one of which is used in a localized estimation optimization model and the other in a fusion weight optimization model The adaptive fusio n strategy allows each agent to achieve its own optimal individual estimation on the global information of the entire region through minimizing the localized objective functions in a distributed and online manner We have also analyzed the mean-square-error convergence behavior of the proposed algorithm Finally the experimental results have been provided to demonstrate the effectiveness of the proposed algorithm and its advantage over the conventional consensus protocol based algorithm In our future research we will extend the proposed method with consideration of 


TIAN et al  ADAPTIVE FUSION STRATEGY FOR DISTRIBUTED INFORMATION ESTIMATION 3091 optimal coverage control issue and potential failure of local communication links R EFERENCES  L  F  B ertuccelli and J  P  H o w   UAV search for dynamic targets with uncertain motion models in Proc 45th IEEE Conf Decision Control  Dec 2006 pp 5941–5946  P  T  M illet D  W  Cas b eer  T  M erck er  a nd J  Bis hop Multiagent decentralized search of a probability map with communication constraints in Proc AIAA Guid Navigat Control Conf  Aug 2010 pp 2–5 3 J  H u L  X i e K  Y  L u m  and J  X u M ultiagent inf o r m ation f us ion a nd cooperative control in target search IEEE Trans Control Syst Technol  vol 21 no 4 pp 1223–1235 Jul 2013  D  P  B erts ekas   A n e w clas s o f i ncrem e ntal gradient m e thods for l eas t squares problems SIAM J Optim  vol 7 no 4 pp 913–926 1996  M  G  R abbat a nd R D No w a k Quantized increm ental a lgorithm s for distributed optimization IEEE J Sel Areas Commun  vol 23 no 4 pp 798–808 Apr 2005  C  G  L opes a nd A H Sayed Incre mental adaptive strategies over distributed networks IEEE Trans Signal Process  vol 55 no 8 pp 4064–4077 Aug 2007 7 X  L in  A s chem e f or r o b u s t dis t r i b u ted s ens o r f us ion b as ed on average consensus in Proc Int Conf Inf Sensor Netw  Apr 2005 pp 63–70 8 I  D  S chizas  G  M ateos  and G  B  G iannakis  D is tr ib uted L M S f or consensus-based in-network adaptive processing IEEE Trans Signal Process  vol 57 no 6 pp 2365–2382 Jun 2009 9 S  S  S tank o v ic M  S  S tank o v ic a nd D  M  S tipano v ic  D ecentr alized parameter estimation by consensus based stochastic approximation IEEE Trans Autom Control  vol 56 no 3 pp 531–543 Mar 2011  C G L opes a nd A H Sayed Dif fusion least-mean squares over adaptive networks Formulation and performance analysis IEEE Trans Signal Process  vol 56 no 7 pp 3122–3136 Jul 2008  F  S  Catti v e lli and A  H  S ayed  D i f f us ion L M S s t r a te gies f o r distributed estimation IEEE Trans Signal Process  vol 58 no 3 pp 1035–1048 Mar 2010  J  Chen and A  H  S ayed  Dif f us ion a daptation s trate g ies f or dis t rib u ted optimization and learning over networks IEEE Trans Signal Process  vol 60 no 8 pp 4289–4305 Aug 2012  A H Sayed S Y  T u J  Chen X Zhao,andZ.J.Towﬁc,“Diffusion strategies for adaptation and learning over networks An examination of distributed strategies and network behavior IEEE Signal Process Mag  vol 30 no 3 pp 155–171 May 2013  J  Chen C  R ichar d  A  O  H er o and A  H  S ayed  D i f f us ion L M S f o r multitask problems with overlapping hypothesis subspaces in Proc IEEE Int Workshop Mach Learn Signal Process MLSP  Sep 2014 pp 1–6  J  Chen S  Y  T u  a nd A  H  S a yed D is tr ib uted optim ization v ia diffusion adaptation in Proc 4th IEEE Int Workshop Comput Adv Multi-Sensor Adapt Process CAMSAP  Dec 2011 pp 281–284  J  Chen and A  H  S ayed  On the b eneﬁts of dif f us ion c ooperation f or distributed optimization and learning in Proc 21st Eur Signal Process Conf EUSIPCO  Sep 2013 pp 1–5  Z  J  T o wﬁc a nd A H Sayed  A da ptive penalty-based distributed stochastic convex optimization IEEE Trans Signal Process  vol 62 no 15 pp 3924–3938 Aug 2014  A H Sayed  A dapti v e n etw o rks   Proc IEEE  vol 102 no 4 pp 460–497 Apr 2014  X Z h ao and A  H  S ayed  As ynchronous adaptation a nd learning o v e r networks—Part I Modeling and stability analysis IEEE Trans Signal Process  vol 63 no 4 pp 811–826 Dec 2014  A Nedic A Ozdaglar  a nd P  A Parrilo Constrained consensus and optimization in multi-agent networks IEEE Trans Autom Control  vol 55 no 4 pp 922–938 Apr 2010  M Z h u a nd S Martinez On d is tr ibuted convex optimization under inequality and equality constraints IEEE Trans Autom Control  vol 57 no 1 pp 151–164 Jan 2012  J  L i n Di v er gence m eas ures bas e d o n t he Shannon entrop y   IEEE Trans Inf Theory  vol 37 no 1 pp 145–151 Jan 1991  S Oh L  S chenato P  Chen a nd S Sas t ry   T r acking a nd coordination of multiple agents using sensor networks System design algorithms and experiments Proc IEEE  vol 95 no 1 pp 234–254 Jan 2007  P  D a m e s a nd V  K u m a r  Cooperati v e m u lti-tar g et localization w ith noisy sensors in Proc EEE Int Conf Robot Autom ICRA  May 2013 pp 1877–1883  C Manning and H  S chütze Foundations of Statistical Natural Language Processing  Cambridge MA USA MIT Press 1999  C E  Shannon  A m a them atical theory of com m unication  Bell Syst Tech J  vol 27 no 3 pp 379–423 1948  F  Niels e n a nd R Nock Skew Jensen-Bregman Voronoi Diagrams  Berlin Germany Springer 2011  H W  K uhn and A  W  T uck e r  Nonlinear program m i ng  i n Proc 2nd Berkeley Symp Math Statist Probab  Jul 1950 pp 481–492  M H e s t enes   Multiplier a nd gradient m e thods   J Optim Theory Appl  vol 4 no 5 pp 303–320 1969 A v a ilable http://dx.doi.org/10.1007/BF00927673  M  J  D  P o w e ll  A m e thod f o r nonlinear cons tr aints i n m inim ization problems in Optimization Symposium of the Institute of Mathematics and Its Applications University of Keele  London U.K Academic 1969 pp 283–298  M  P o w e ll O n s ear ch dir ections f o r m inim ization a lgor ithm s   Math Program  vol 4 no 1 pp 193–201 1973 A v a ilable http://dx.doi.org/10.1007/BF01584660  J  E  F a lk  L a grange m u ltipliers and nonlinear program m i ng  J Math Anal Appl  vol 19 no 1 pp 141–159 1967  G He  Ros e n s g radient p rojection w ith dis c rete s t eps   Acta Math Appl Sin  vol 6 no 1 pp 1–10 1990 A v a ilable http://dx.doi.org/10.1007/BF02014710  J  Ros e n T he gradient projec tion method for nonlinear programming Part I Linear constraints J Soc Ind Appl Math  vol 8 no 1 pp 181–217 1960 O A v a ilable http://dx doi o r g 10 1137/0108011  W  Rudin Principles of Mathematical Analysis vol.3.NewYork,NY USA McGraw-Hill 1964  J  Cortes  S  M artinez T  Karatas  and F  B ullo  Co v e rage control f or mobile sensing networks IEEE Trans Robot Autom  vol 20 no 2 pp 243–255 Apr 2004  A T  Y  Ster giopoulos   Spatially di stributed area coverage optimisation in mobile robotic networks with arbitrary convex anisotropic patterns Automatica  vol 49 no 1 pp 232–237 Jan 2013  S Cheng G L i u L  Feng Y  W a ng and Q  G ao  Pers is tent a w arenes s coverage control for mobile sensor networks Automatica  vol 49 no 6 pp 1867–1873 Jan 2013  R Durre t t  Probability Theory and Examples  Cambridge U.K Cambridge Univ Press 2011 Daxin Tian M’13–SM’16 is an Associate Professor in the School of Transportation Science and Engineering Beihang University Beijing China His current research interests include mobile computing intelligent transportation systems vehicular ad hoc networks and swarm intelligent Jianshan Zhou received the B.Sc and M.Sc degrees in trafﬁc information engineering and control in 2013 an d 2016 respectively He is currently working toward the Ph.D degree with the School of Transportation Science and Engineering Beihang University Beijing China His current research interests are focused on wireless communication artiﬁcial intelligent system and intelligent transportation systems Zhengguo Sheng is currently a Lecturer with the Department of Engineering and Design University of Sussex U.K He has authored over 50 international conference and journal papers His current research interests cover IoT/M2M vehicular communications a nd edge/cloud computing 


2332-7790 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TBDATA.2017.2680460, I\EEE Transactions on Big Data A 17 for images In this practical based in images  Ho w the feature selection w ould impact the classi\002cation reported  More adv anced feature selection approaches such as the in can be introduced into the frame w ork e images samin images challenge to problem  Man y dif ferent approaches ha v e been proposed to address as results the are Ho we v er  none of these that most eloping MRs 12 Metamorphic testing w as 002rst Chen al  for testing non-testable systems bioinformatics sysaultrelations A recent has compilers  Metamorphic testing has been applied for testi ng a lar ge ASA and also successfully engines Baidu Ho we v er  the quality of reported are w information In this paper  metamorphic in results w are tests xity SUT  Combinatorial technique 53 used for testing softw are for are C N the learning were to classi\002cation the for confusion learning important it data our data techniques A T King and xperi#1262933 e Corporation research R S  V  Gudi v ada R Raeza-Y ates and V  Ragha v an 223Big data Promises and 224 Computer 2015  Y  Bengio 223Learning deep architectures for ai 224 ends Learning 2009  Apache 2016 Hadoop Online A v ailable http://hadoop.apache.or g  V  Gudi v ada D Rao and V  Ragha v an 223Renaissance in database 224 IEEE Computer 2016  J Zhang Y  Feng M S Moran J Lu L Y ang al of 224 ess 2013  R M and T  Poggio 223Models of object recognition 224 oscience 2000  K Jacobs  J Lu and X Hu 223De v elopment of a dif f raction imaging 224 Lett 2009  2016 Adda project Online A v ailable https://github com/addateam adda  T  Y  Chen S C Cheung and S Y iu 223Metamorphic testing a ne w CS98and 1998  J Ding D Zhang and X Hu 223 An application of metamorphic testing in metamorphic ICSE 2016  U Kane w ala and J M Bieman 223T esting scienti\002c softw are A system\224 gy 56 2014  S Se gura G Fraser  A Sanchez and A Ruiz-Cort 264 on 224 Engineering  2016  2016 Mongodb  Online A v ailable https://www mongodb com  2016 Mongochef Online A v ailable http://3t.io/mongochef  M Y urkin and A Hoekstra 2014 User manual for the discrete 1.3b4 A v ailable https team/adda/tree/master/doc  C Hsu C.-C Chang and C.-J Lin 223 A practical guide to support v ector 2003  Y  LeCun Y  Bengio and G Hinton 223Deep learning 224 e 521 2015  R Haralick 223On a te xture-conte xt feature e xtract ion algorithm for in Society ol 650\226 657 
 


2332-7790 \(c This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/TBDATA.2017.2680460, I\EEE Transactions on Big Data A 18  K Dong Y  Feng K Jacobs J Lu R Brock al 223Label-free 224 Biomed ess 2011  R M Haralick K Shanmug an and I H Dinstein 223T e xtural features 224 Cybern SMC-3 1973  S K Thati J Ding D Zhang and X Hu 223Feature selection and analin ion ance 2015  J Dixon and J Ding 223 An empirical study of parallel solution for glcm 2016  T  Kanungo D Mount N Netan yahu C Piatk o R Silv erman and im\224 hine ence 2012  M A Hall 223Correlation-based feat ure selection for machine learning 224 wzealand 1999  A Krizhe vsk y  I Sutsk e v er  and G E Hinton 223Imagenet classi\002cain al systems and 1097\2261105  E Gibne y  223Google ai algorithm masters ancient g ame of go 224 e   M Moran 223Correlating the morphological and light scattering prop 2013  R P an Y  Feng Y  Sa J Lu K Jacobs and X Hu 223 Analysis 224 ess  2014  X Y ang Y  Feng Y  Liu N Zhang L W ang al e fraction 224 ess 7 2014  M Zhang 223 A deep learning based classi\002cation of lar ge scale biomed2016  Y  Feng N Zhang K Jacobs W  Jiang L Y ang al 223Polarization w 224 A 2014  C.-C Chang and C.-J Lin 2016 Libsvm Online A v ailable csie.ntu.edu.tw 030 cjlin/libsvm  2016 Caf fe project Online A v ailable http://caf fe.berk ele yvision.or g  J Mayer and R  Guderlei 223 An empirical study on the selection of good in e C06 475\226484  U Kane w ala J M Bieman and A Ben-Hur  223Predicting metamorphic approach 224 and Reliability 2015  J Ding T  W u J Q Lu and X Hu 223Self-check ed metamorphic testing in on vement apore 2010  W  E W ong and A Mathur  223Reducing the cost of mutati on testing 224 e pp 1995  Y  Jia and M Harman 223 An anal ysis and surv e y of the de v elopment of 224  649\226678 2011  L Cai and Y  Zhu 223The challenges of data quality and data quality 224 ournal 1 2015  J Gao C Xi e and C T ao 223Big data v alidation and quality assurance in Service\(SOSE 433\226441  X Dong E Gabrilo vich K Murph y  V  Dang W  Horn C Lug aresi 224  938\226949 2015  X Y in J Ha n and P  S Y u 223T ruth disco v ery with multiple con\003icting 224 Data  2008  C H W u and Y  Song 223Rob ust and distrib uted web-scale near dup in IEEE Data 2606\226 2611  2016 Apache samza Online A v ailable http://samza.apache.or g  J A Saez B Kra wczyk and M W ozniak 223On the in\003uence of class 002ltering 224 ence 590\226609 2016  M Y ousef D S D M 250 223Feature for 224 bioinformatics 2016  F  Min Q Hu and W  Zhu 223Feature sel ection with test cost constraint 224 Reasoning 167\226 2014  H A L Thi H M Le and T  P  Dinh 223Feature selection in machine function 224 Learning 2015  H Liu F C K uo D T o we y  and T  Chen 223Ho w ef fecti v ely does problem?\224 on Engineering 2014  V  Le M  Afshari and Z Su 223Compiler v alidation via equi v alence in amming on Kingdom 216\226226  M Lindv all D Ganesan R rdal and R E W ie g and 223Metamorphic in 37th Engineering 129\226 138  Z Zhou S Xiang and T  Chen 223Metamorphic testing for softw are 224 e Engineering 2016  C Nie and H Leung 223 A surv e y of combinatorial testing 224 CM y 2011 CE O HERE Ding Computer has Computer in Nanjing 2004 r ed His the He by CM Hu  ada East  
 


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   19     en-US  en-US  en-US  en-US 52 en-US  en-US  en-US  en-US en-US e en-US ti en-US en-US  en-US  en-US en-US  en-US 4 en-US en-US  en-US  en-US  en-US 53 en-US  en-US  en-US  en-US en-US  en-US  en-US DA en-US en-US  en-US  en-US  en-US  en-US 54 en-US  en-US  en-US  en-US en-US e en-US n en-US  en-US en-US  en-US v en-US en-US  en-US  en-US  en-US 55 en-US  en-US  en-US  en-US en-US k en-US en-US thm en-US en-US  en-US ron en-US  en-US 0 en-US en-US  en-US  en-US 5 en-US 6 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US n en-US  en-US  en-US  en-US 57 en-US  en-US  en-US  en-US en-US ti en-US en-US T en-US  en-US n en-US en-US  en-US  en-US  en-US  en-US  en-US 58 en-US  en-US  en-US  en-US en-US  en-US Pre en-US en-US  en-US t en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 3 en-US en-US 1 en-US  en-US  en-US  en-US 59 en-US  en-US  en-US t en-US  en-US  en-US n en-US en-US  en-US  en-US en-US  en-US OS en-US  en-US 2 en-US en-US  en-US  en-US  en-US 60 en-US  en-US  en-US  en-US en-US  en-US ti en-US  en-US t en-US en-US  en-US 4 en-US en-US  en-US  en-US  en-US 61 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US ess en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 62 en-US  en-US  en-US  en-US en-US X en-US en-US ng en-US en-US s en-US  en-US en-US  en-US  en-US i    en-US x en-US en-US e en-US en-US i en-US en-US r en-US en-US is en-US en-US 2 en-US en-US Dec en-US en-US 6  en-US  en-US  en-US 63 en-US  en-US  en-US i en-US  en-US en-US  en-US  en-US en-US h en-US i   Av a i l a bl e   en-US e en-US en-US is en-US en-US ng en-US en-US a en-US en-US nd en-US en-US b en-US en-US r en-US en-US the en-US en-US net en-US en-US of en-US en-US 0 en-US en-US Dec en-US en-US 6  en-US  en-US  en-US 64 en-US  en-US  en-US BI en-US en-US  en-US en-US e en-US  en-US  en-US en-US er en-US  en-US i    en-US du en-US en-US es en-US en-US new en-US en-US ai en-US en-US nd en-US en-US net en-US en-US of en-US en-US s en-US en-US ves en-US en-US 6 en-US en-US 0 en-US en-US Dec en-US en-US 6  en-US  en-US  en-US 65 en-US  en-US  en-US  en-US en-US Su en-US  en-US  en-US en-US a en-US  en-US 9 en-US en-US  en-US  en-US  en-US  en-US 66 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US s en-US  en-US  en-US  en-US  en-US 67 en-US  en-US  en-US  en-US en-US  en-US a en-US en-US ve en-US en-US a en-US  en-US 383 en-US en-US  en-US  en-US  en-US 68 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US ess en-US  en-US 7 en-US en-US  en-US  en-US  en-US 69 en-US  en-US  en-US  en-US en-US  en-US vey en-US en-US  en-US ri en-US s en-US  en-US 77 en-US en-US  en-US  en-US  en-US 70 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 71 en-US  en-US  en-US o en-US  en-US  en-US ne en-US en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 72 en-US  en-US  en-US  en-US en-US  en-US n en-US e en-US  en-US en-US  en-US n en-US  en-US 6 en-US en-US  en-US  en-US  en-US 73 en-US  en-US  en-US  en-US en-US  en-US  en-US hy en-US  en-US en-US  en-US n en-US  en-US 6 en-US en-US  en-US  en-US  en-US 74 en-US  en-US  en-US  en-US en-US  en-US t en-US en-US I en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 75 en-US  en-US  en-US  en-US en-US  en-US ty en-US en-US  en-US en-US  en-US f en-US en-US  en-US  en-US  en-US  en-US 76 en-US  en-US  en-US a en-US  en-US en-US ti en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 96 en-US en-US  en-US  en-US  en-US 77 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US 0 en-US 8 en-US en-US  en-US  en-US ess en-US  en-US 85 en-US en-US  en-US  en-US  en-US 78 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US  en-US  en-US  en-US  en-US  en-US 79 en-US  en-US  en-US hen en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 80 en-US  en-US  en-US  en-US en-US ng en-US en-US  en-US  en-US  en-US en-US s en-US  en-US  en-US 6 en-US en-US  en-US  en-US  en-US 81 en-US  en-US  en-US N en-US  en-US  en-US en-US  en-US  en-US en-US 2011 en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 82 en-US  en-US  en-US  en-US  en-US en-US o en-US  en-US  en-US en-US 2011 en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 83 en-US  en-US  en-US  en-US en-US  en-US s en-US  en-US  en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 84 en-US  en-US  en-US  en-US en-US  en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  20      en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 85 en-US  en-US  en-US F en-US  en-US en-US  en-US  en-US en-US  en-US 0 en-US  en-US 5 en-US en-US  en-US  en-US  en-US 86 en-US  en-US  en-US h en-US  en-US  en-US l en-US en-US  en-US en-US  en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 87 en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US  en-US d en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 88 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US 6 en-US  en-US 263 en-US en-US  en-US  en-US  en-US 89 en-US  en-US  en-US  en-US en-US tem en-US en-US OTA en-US  en-US 6 en-US  en-US 6 en-US en-US  en-US  en-US  en-US  en-US 90 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US m en-US  en-US 87 en-US en-US  en-US  en-US  en-US  en-US 91 en-US  en-US  en-US e en-US  en-US  en-US en-US  en-US  en-US en-US  en-US m en-US  en-US 87 en-US en-US  en-US  en-US  en-US  en-US 92 en-US  en-US  en-US  en-US en-US  en-US a en-US  en-US  en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 93 en-US  en-US  en-US  en-US en-US  en-US r en-US en-US  en-US  en-US en-US  en-US 195 en-US en-US  en-US  en-US  en-US 94 en-US  en-US  en-US Wei en-US en-US xi en-US ng en-US en-US eng en-US en-US  en-US en-US  en-US k en-US en-US to en-US en-US  en-US  en-US en-US ess en-US  en-US 1 en-US en-US  en-US  en-US  en-US 95 en-US  en-US  en-US  en-US en-US  en-US c en-US r en-US en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 96 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US r en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 97 en-US  en-US  en-US  en-US  en-US  en-US en-US e en-US en-US  en-US r en-US en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US  en-US m en-US en-US s en-US en-US 3 en-US  en-US 3 en-US en-US  en-US  en-US  en-US 98 en-US  en-US  en-US a en-US en-US  en-US en-US  en-US ter en-US en-US  en-US  en-US en-US l en-US  en-US  en-US  en-US  en-US 99 en-US  en-US  en-US a en-US  en-US en-US  en-US  en-US  en-US en-US  en-US BE en-US  en-US 1 en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US e en-US  en-US  en-US  en-US  en-US 1 en-US  en-US  en-US e en-US en-US  en-US ter en-US en-US  en-US  en-US  en-US  en-US 2 en-US  en-US  en-US e en-US en-US  en-US ter en-US en-US the en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US  en-US ter en-US en-US  en-US ti en-US en-US n en-US en-US  en-US n en-US  en-US 3 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US th en-US  en-US  en-US ter en-US en-US  en-US  en-US en-US s en-US  en-US 7 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US en en-US en-US  en-US n en-US  en-US  en-US en-US 4 en-US  en-US 4 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US e en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US ter en-US en-US  en-US tem en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US  en-US en-US  en-US a en-US en-US  en-US en-US  en-US S en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US  en-US  en-US en-US ter en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 72 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US n en-US en-US a en-US  en-US 5 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US W en-US  en-US en-US  en-US  en-US nty en-US en-US  en-US ON en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US  en-US Se en-US  en-US en-US  en-US l en-US  en-US 334 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US Int en-US en-US y en-US  en-US  en-US  en-US 249 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US en-US  en-US d en-US en-US  en-US 1 en-US 1 en-US 52 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US  en-US te en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US en-US r en-US  en-US 34 en-US en-US  en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   21     en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US i en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US s en-US  en-US  en-US  en-US 2 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US 1 en-US 77 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US d en-US en-US a en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US 2 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US o en-US  en-US en-US  en-US  en-US en-US s en-US  en-US 0 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US s en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US en-US a en-US  en-US 321 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US K en-US en-US t en-US en-US  en-US en-US  en-US  en-US s en-US en-US dy en-US en-US matics en-US  en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US  en-US res en-US  en-US  en-US  en-US 9 en-US  en-US  en-US R en-US n en-US en-US  en-US en-US  en-US  en-US en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US n en-US en-US  en-US en-US n en-US  en-US  en-US  en-US en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US man en-US en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US d en-US en-US s en-US 2 en-US  en-US 46 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US ti en-US en-US ti en-US en-US  en-US n en-US en-US n en-US  en-US 1 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US n en-US en-US n en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US en-US 2 en-US  en-US ron en-US  en-US 351 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US Semi en-US en-US  en-US  en-US en-US  en-US S en-US s en-US en-US  en-US  en-US  en-US 2 en-US en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US ex en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 9 en-US  en-US  en-US nt en-US en-US  en-US en-US  en-US  en-US a en-US  en-US en-US  en-US r en-US  en-US 7 en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US EEE en-US  en-US 6 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US s en-US  en-US 7 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US n en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US ene en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 7 en-US en-US  en-US  en-US 4 en-US  en-US  en-US en-US  en-US ti en-US en-US  en-US en-US  en-US  en-US 8 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US i en-US  en-US  en-US en-US  en-US dy en-US en-US  en-US n en-US y en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US  en-US  en-US en-US IE en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US ter en-US en-US n en-US en-US  en-US l en-US en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US  en-US  en-US n en-US en-US  en-US en-US  en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US  en-US the en-US  en-US en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  22      en-US Inte en-US  en-US  en-US 132 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US n en-US en-US  en-US I en-US en-US  en-US  en-US  en-US 69 en-US en-US 8 en-US  en-US  en-US  en-US 2 en-US  en-US  en-US r en-US en-US  en-US en-US k en-US en-US to en-US en-US  en-US  en-US en-US r en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US t en-US en-US n en-US en-US n en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US i   en-US m en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US  en-US tr en-US  en-US n en-US en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US en-US a en-US i   en-US d en-US en-US a en-US en-US c en-US en-US es en-US 2 en-US en-US n en-US en-US 7  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US dy en-US en-US  en-US n en-US y en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US  en-US en-US  en-US vey en-US en-US  en-US  en-US 13 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US n en-US en-US  en-US n en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US 2010 en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US  en-US o en-US n en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US B en-US  en-US en-US A en-US ti en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 6 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US e en-US en-US s en-US  en-US  en-US  en-US en-US  en-US n en-US  en-US 1 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US f en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US e en-US en-US  en-US  en-US  en-US 1 en-US 68 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US f en-US en-US  en-US ew en-US en-US e en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US i en-US  en-US  en-US en-US  en-US n en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US h en-US en-US er en-US i   Av a i l a bl e   en-US p en-US en-US ten en-US en-US hn en-US y en-US en-US ends en-US en-US l en-US en-US the en-US en-US l en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US  en-US en-US re en-US  en-US 6 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US y en-US en-US  en-US e en-US en-US  en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US en-US re en-US  en-US 6 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US en-US t en-US  en-US earn en-US  en-US 9 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 34 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US Lef en-US  en-US en-US  en-US  en-US ti en-US en-US  en-US en-US V en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US Pro en-US  en-US  en-US  en-US 34 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US ng en-US en-US ti en-US en-US  en-US  en-US  en-US en-US  en-US 1 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US O en-US en-US M en-US  en-US en-US l en-US en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US N en-US s en-US  en-US en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US to en-US en-US  en-US en-US n en-US  en-US  en-US  en-US 5 en-US  en-US  en-US D en-US  en-US  en-US en-US nt en-US en-US  en-US en-US  en-US en-US  en-US  en-US  en-US  en-US 6 en-US en-US  en-US 2 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US edes en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US t en-US  en-US en-US  en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   23     en-US  en-US 22 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US t en-US en-US  en-US vey en-US en-US  en-US  en-US ne en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US  en-US  en-US tbed en-US en-US  en-US en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US G en-US  en-US en-US o en-US en-US  en-US en-US  en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US e en-US en-US ent en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US a en-US en-US z en-US en-US  en-US dez en-US en-US z en-US en-US  en-US en-US  en-US a en-US  en-US  en-US en-US  en-US 26 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US a en-US en-US a en-US en-US o en-US en-US  en-US a en-US en-US  en-US en-US o en-US en-US F en-US en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 8 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US  en-US  en-US en-US  en-US en-US  en-US 2015 en-US b en-US 5 en-US  en-US 9 en-US en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US o en-US en-US  en-US en-US  en-US  en-US en-US n en-US  en-US  en-US 45 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US k en-US  en-US  en-US en-US  en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US r en-US  en-US 86 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US y en-US en-US by en-US en-US  en-US en-US  en-US s en-US  en-US 1 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US  en-US dez en-US en-US  en-US en-US n en-US en-US  en-US en-US  en-US n en-US y en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US tem en-US en-US  en-US ti en-US en-US ve en-US en-US  en-US  en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US ty en-US en-US  en-US en-US  en-US  en-US  en-US 5 en-US  en-US 2 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US en en-US en-US  en-US  en-US  en-US en-US ess en-US  en-US 831 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US ne en-US en-US  en-US e en-US en-US  en-US  en-US 26 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US ve en-US  en-US  en-US en-US  en-US rk en-US  en-US 7 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US Sy en-US  en-US  en-US en-US  en-US  en-US  en-US es en-US  en-US 1 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US  en-US  en-US r en-US rks en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US n en-US  en-US  en-US 9 en-US 0 en-US  en-US 411 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US tems en-US en-US  en-US  en-US  en-US  en-US n en-US  en-US en-US  en-US v en-US es en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US en en-US en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US m en-US en-US  en-US  en-US th en-US en-US  en-US en-US  en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US ng en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US  en-US rk en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 8 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US t en-US dy en-US en-US n en-US s en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  24      en-US  en-US i en-US  en-US en-US  en-US  en-US 9 en-US  en-US 2 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US n en-US  en-US t en-US 7 en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US n en-US en-US E en-US ess en-US  en-US 858 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US ess en-US  en-US 1 en-US en-US  en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US  en-US  en-US o en-US en-US  en-US en-US in en-US  en-US  en-US  en-US l en-US en-US  en-US g en-US  en-US 0 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US Ben en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US f en-US  en-US  en-US dy en-US en-US  en-US 11 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US  en-US en-US T en-US en-US  en-US o en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US z en-US en-US  en-US en-US ti en-US en-US  en-US  en-US  en-US en-US sort en-US  en-US  en-US 5 en-US  en-US  en-US  en-US 8 en-US  en-US  en-US z en-US en-US  en-US en-US  en-US f en-US en-US the en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 121 en-US en-US  en-US  en-US  



A kind of improved algorithm for weighted Apriori and application to Data Mining Yu Shaoqian School of Computer and Electronic Engineering Hunan business College Changsha, China  AbstractIn data processing of the supermarket, people often use the Apriori algorithm to analyze the customer shopping basket"; Due to the large computation, Apriori algorithm has controlled the number of frequent item sets by using the minimum supporting threshold and pruning techniques, but meaningless frequent item sets still possiblely exist. Divide goods into several broad categories and set up the weighted value of categories; Then, calculate the weighted support and confidence, and do pruning and selection according to the minimum weighted support and confidence threshold to get access to the new frequent item sets and association rules and improve the efficiency of the algorithm Index TermsImproved Apriori algorithm, Weighted supporting degree, Weighted confidence, Shopping Basket analysis I. INTRODUCTION In recent years, chain supermarket developed rapidly Facing fierce marketing competition, people needs to do shopping basket" analysis at any time to understand preferences?spending habits of customers and the relations between the preferences, therefore, it would be better to use Apriori Algorithm for " shopping basket "analysis In 1993, Agrawal, who first proposed the Apriori algorithm about association rule mining [4], the algorithm achieved through multiple scan of data sets, each of which minds the corresponding frequent item sets; in the first scan, the algorithm counts on all data items and find all the frequent 1 item sets; In the following each scan, the algorithm generates a new frequent K item sets on the foundation of frequently \(K-1 item sets of last processing; Through scanning the database, it calculates the degree of support of the candidate sets and frequent item sets; According to the minimum support threshold, it sets pruning operations to candidate frequent item set which does not meet the support threshold to obtain a new frequent item K sets; so repeated until no item frequent itemset 


found so far II. IMPROVEMENT OF APRIORI ALGORITHM It has a positive significance to use association analysis of data mining for analyzing to get a good knowledge of characteristics and laws of consumer groups; Apriori algorithm using pruning techniques bases on the minimum supporting degree, systemly controls the number of items of candidate item sets and the exponential growth A. Apriori Algorithm Problems Although Apriori algorithm can control the excessive growth of the number of items of the candidate item sets by using pruning techniques bases on the minimum supporting degree, it is still possible to have a lot of meaningless and even false association rules which lead to the portfolio explosive growth of item sets and therefore make the algorithm inefficient. Therefore, in the "shopping basket" analysis of chain supermarket, it primarily exists the following two questions In database, each project has the same property and function, they all have the same importance; Therefore each project have no emphasis, but in actual fact, it is better for the supermarket to recmommend relevant commodities according to the season? the project's profit and fashion Calculate the supporting degree if the distribution of the items in the database is relatively even; Practing pruning operation on those candidate frequent item sets which can not meet the supporting threshold; The items in the database receive equal processing; It is difficult to set minimum supporting threshold value,because if it is above the actual value, the discovered association rules may not help to find the lower frequency items; if below , it will find a lot of meaningless and even false association rules reducing the efficiency of the algorithm B.  Improved weighted supporting degree Algorithm In fact, different projects often have different importance. In the real world, for example: the supermarket need to consciously recmommend relevant commodities according to the season?the project's profit and fashion, thus in order to reflect the different importance of each project, it needs to set different weights for different projects. The method 


is to divide goods into several broad categories and set up the weighted value of categories; Then, calculate the weighted support and confidence, and do pruning and selection according to the minimum weighted support and confidence threshold to get access to the new frequent item sets and association rules and improve the efficiency of the algorithm C. Improved weighted Algorithm model So I = \(i1, i2,..., ij t1, t2, ..., tn transaction is the subset of I set. The collection contains any item referred to as item sets, if an item set contains K entries 978-1-4244-6005-2/10/$26.00 2010 IEEE The 5th International Conference on Computer Science & Education Hefei, China. August 2427, 2010 507 ThP1.7  then it is called the K-item set; Suppose X, Y are item sets, to association rules such as the implicating expression X ? Y where X ? I , Y ? I, and X Y? = ? , its the strength can be present by the term of support and confidence[2   n   1    x yc x y x     2 For a given item set T = \(t1, t2,..., tn importance of the project, we assigned weights wi to each project ti, where 0  wi  1, i = \(1, 2 ,..., n weighted association rules and define the weighted supporting degree as[1    


i Ti x y w s x y k   3 Set a K-item as frequent items set, the weighted minimum support threshold: wminsup, if    i Ti x y w s x y w i k   4 So, X ?Y is a valuable association rules The calculation of the weighted confidence level is described as: Given the project set T = \(t1, t2,..., tn the importance of that project, we assigned weights wi to each project ti, where 0  wi  1, i = \(1, 2,..., n confidence level    i Ti x y w c x y k   5 III. IMPROVED ALGORITHM OF DECISION MAKING IN THE SUPERMARKET Supermarkets decision-supporting system uses multidimensional data table to save and manipulate the data. Find the inner link of the goods customers have bought and the data which supermarkets manager is interested in through data mining[3]; The method is that first divide commodities into big categories and each has a uniform weighted value Wi, by using 


this method, it can avoid that each product has a power value which is inconvenient to set and adjust the weights. Divide commodities into big categories, then set value according the big categories ,due to less categories, it is convenient to set and adjust the weights. And then calculate the weighted supporting degree, find the association rules whose weighted supporting degrees meet the requirements and help stores to make effective marketing strategy A.  Calculation and application of the weighted support Supermarket chains collect data and store them in the database through the front-end POS. Divive the goods into several categories according to the area, the principles of posture, the type of goods, respectively named A, B, C, D, each category has several kinds of merchandise goods, for instance A stands for food class, A1 indicates the bread, A2 indicates biscuits; B stands for drinks class, B1 indicates milk, B2 indicates Coke; C stands for electrical class, C1, indicates rice cooker; D indicates fruit, D1 indicates apple. A supermarket sales information shown in Table 1 TABLE I.  TRANSACTION DATABASE TID Product list TID Product list 1 A1,B1,B2,D1 6 A1,A2,D1 2 A2,B1,C1 7 A2,B1,B2 3 A1,A2,B2,D1 8 A1,A2,B2 4 A1,C1,D1 9 B1,B2 5 A1,A2,B1,B2,D1 10 A1,A2,C1,D1 Set weights according to categories, the weighted value between the categories of goods represent the degrees of importance of the interrelation of goods. Due to a limited number of commodity categories, the table of the weighted value will not be too great. Set goods A, B, C, D class, the table of the weighted value shown in Table 2 TABLE II.  CATEGORIES OF GOODS ASSOCIATED WITH THE WEIGHTED VALUE OF TABLE category A B C D weight 1 0.9 0.8 0.7 The weighted value between the categories of goods represent the degrees of importance of the interrelation of goods. the weighted value of categories of goods   i T i x y 


w k   6 Use Apriori nature to divide the algorithm into two steps which are connect and pruning The first step: connect, to connect the frequent sets with candidate set of their own TABLE III.  PRODUCT CANDIDATE 1  ITEM SETS Item set Supporting degree count Supporting degree Weighted Supporting degree A1 7 70? 70 A2 7 70? 70 B1 4 40? 36 B2 5 50? 45 C1 3 30? 24 D1 6 60? 42 Second step: pruning, according to the nature of Apriori algorithm [5], set the minimum weighted supporting threshold as 30%. Compress candidate sets. Scan the database to calculate the weighted supporting degree, involve all the candidate items which meet the minimum weighted supporting degree into frequent sets 508 ThP1.7  according to the steps of Apriori algorithm, find the goods frequent set1 which meet the minimum weighted supporting degree, commodity candidate 1  is filtered to commodity s frequent 1  item sets, such as Table 3, Table 4. The filter criteria is that the minimum weighted supporting threshold is 30 TABLE IV.  COMMODITY FREQUENT 1  ITEMSETS Item 


set Supporting degree count Supporting degree Weighted Supporting degree A1 7 70? 70 A2 7 70? 70 B1 4 40? 36 B2 5 50? 45 D1 6 60? 42 In accordance with the connecting rules of Apriori algorithm to generate all goods candidate 2  item sets, that is A1, A2 A1, B1 A1, B2 A1, D1 A2, B1 B2 D1 item sets, as shown in table 5 TABLE V.  PRODUCT CANDIDATE 2  ITEMSETS Item set Supporting degree count Weight parameter Weighted Supporting degree A1,A2 5 1 50 A1,B1 2 0.95 19 A1,B2 3 0.95 28.5 A1,D1 6 0.85 51 A2,B1 4 0.95 38 A2,B2 4 0.95 38 A2,D1 4 0.85 34 B1,B2 4 0.9 36 B1,D1 2 0.8 16 B2,D1 3 0.8 24 Calculate the weighted supporting degree, and select out commodity frequent 2  item sets which meets the minimum weighted supporting threshold of 30 TABLE VI.  COMMODITY FREQUENT 2  ITEMSETS Item set Supporting degree count Weight parameter 


Weighted Supporting degree A1,A2 5 1 50 A1,D1 6 0.85 51 A2,B1 4 0.95 38 A2,B2 4 0.95 38 A2,D1 4 0.85 34 B1,B2 4 0.9 36 Similarly, get commodity candidate 2  item sets and commodity frequent 2  item sets, as shown in Table 6 and Table 7 TABLE VII.  COMMODITY CANDIDATE 3 - ITEM SETS Item set Supporting degree count Weight parameter Weighted Supporting degree A1,A2,B1 1 0.97 9.7 A1,A2,B2 3 0.97 29.1 A1,A2,D1 4 0.9 36 A2,B1,B2 3 0.93 27.9 A2,B1,D1 2 0.86 17.2 A2,B2,D1 2 0.86 17.2 B1,B2,D1 2 0.83 16.6 commodity candidate 1  is filtered to commodity s frequent 1  item sets, the filter conditions is to meet the minimum weighted supporting threshold of 30 TABLE VIII.  COMMODITY FREQUENT 3 - ITEM SETS Item set Supporting degree count Weight parameter Weighted Supporting degree A1,A2,D1 4 0.9 36 B. Calculation of the weighted confidence In order to tap the concerns of sales-related staff, it use weighted confidence level for calculation, which is multiply of 


commoditys confidence level and associated weighted value of bid categories, this multiply is weighted confidence  of one kind against another kind. As table 8 commodity frequent 3 item sets, \(A1, A2, D1 confidence level and the weighted confidence level above 30 as shown in Table 9 TABLE IX.  CONFIDENCE AND THE WEIGHTED CONFIDENCE LEVEL TABLE Commodity relationship confidence Weighted confidence A1A2^D1 57.14% 51.42 A2A1^D1 66.67? 60 D1A1^A2 66.67% 60 A1^A2D1 80% 72 A1^D1A2 66.67% 60 A2^D1A1 100% 90 Supposing the minimum weighted confidence threshold is 55%, according to the table, weighted confidence which is more than 55% is strongly inter-related, so it is easy for customers to accept this combination. Confidence reflects the degree of correlation between commodities, while the weighted confidence reflects the degree of correlation between assortment of the customers or businesses IV. WEIGHTED SUPPORT AND CONFIDENCE ALGORITHM In practical applications, such as supermarket database according to the season, the project's profits, consumption trend and other factors, it sets the weight of each category of commodities, calculates the weighted supporting degree, sets minimum weighted supporting threshold, and does pruning operation on candidate or frequent item sets which not meet the weighted supporting threshold. Through the use of pruning techniques, some association rules whose weight is not high and which has no practical meaning and which is even false are filtered out; so, it can not only improve the efficiency of algorithm, but also do recommendation focusly and consciously The interrelationship of assortment is more strong whose weighted confidence is more than the minimum threshold of weighted confidence, so it is easy for customers to accept this assortment. Confidence reflects the degree of correlation between commodities, while the weighted confidence reflects 


the degree of correlation between assortment of the customers or businesses. The level of weighted confidence of is critical to the filteration of association rules on the circumstance that the defference of confidences of different assortments is not so clear 509 ThP1.7  V. SUMMARY According to the actual needs of supermarket customers according to season, product type, sales staffs experience,it first divide commodities into big categories, set up the weighted value of categories, through analyzing customer shopping basket", it filters out the item sets whose weight is small and which divisors have no need to care about while it selects out the item sets whose weight is big and which divisors need to care about and find the item sets which meet the minimum weighted confidence; Then, by calculating the weighted confidence, it finds the valuable association rules Thus it can not only find the interrelation of different commodities , but also mine data according to commodites and divisors refered transaction. how to set reasonable weights has great influence on the result of data mining, and need to be further studied  REFERENCES 1] Qiu-Yu, Cao Hua. Apriori algorithm based on weighted association rule mining [J]. Lanzhou University of Technology, 2007,33 \(6 2] Ouyang Weimin, Zheng Cheng, Cai Qing-sheng. Database Weighted Association Rules [J]. Journal of Software, 2001,12 \(04 3] Xue-Hong, WANG Min. Based on DW + OLAP + DM supermarket sales of decision support systems [J]. Computer Engineering, 2007,33 14 4] R. Agrawal, T. Imielinski, A. Swami. Mining association rules between sets of items in large databases [C]. In Proc. Of the 1993 ACM on Management of Data, Washington, D. C, May 1993. 207-216 5] Chen Jing, Zhang Yan. Based on Association Rules Apriori-Partition Algorithm Visualization [J]. Computer, 2009,7-3:190-191  510 ThP1.7 


Proceedings of the 2001 IEEE International Conference on Data Mining, IEEE Press, Dec. 2001, pp. 123-131 2] B. Liu, W.H su and Y.Ma, "Integrating classification and association rule mining", KDD'98, ACM Press, May. 1998, pp. 256-262 3] Srkant R and Agrawal R, "Mining Quantitative Association Rules in Large Relational Tables," Proceeding of the ACM SIGMOD Conference on Management of Data, ACM Press, Sep. 1996, pp. 1-12 4] Agrawal R, Imielinski T and Swami A, "Mining association rules between sets of items in large database," Proceeding of the 1993 ACM SIGMOD InternationaiConference on Management of Data ACM Press, Dec. 1993, pp. 207-216 5] T. S. Lim, W. Y. Loh, and Y. S. Shih. "A comparison of prediction accuracy, complexity, and training time of thirty-three old and new classification algorithms," Machine Learning, vol. 39, Dec. 2000, pp 1201-1211 6] K.W ang, S. Zhou, and Y.H e. "Growing decision tree on support-less association rules," The Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, A CM Press Aug. 2000, pp. 561-570 7] P.C lark and T. Niblett. "The CN2 induction algorithm," Machine Learning, vol. 3, May. 1989, pp. 261-283 8] Savasere. A , Omiecinski. E , Navathe.S, "Mining for St rong Negative Associations in a Large Database of Customer Transactions," Proceedings of IEEE 14th Internal Conference on Data Engineering, IEEE Press, Dec. 1998, pp. 369-376 540 9] Han J, Pei J, Yin YW, "Mining frequent patterns without candidate generation," DataMining and Knowledge Discovery, vol. 8, Sep 2004, pp. 53-87 10] Liu B, Ma Y and Wong K, "Improving an Association Rule Based Classifier," Proc of the 4th European Conference on Principles and Practice of Knowledge Discovery in Databases, Steween Press, Nov 2000, pp. 1 12-123 


that selecting useful clustering characters based on the rules of the observable world. However, this method has a problem of scarcity of information and lack of testifY. This paper aims to establish an association analysis model based on case study and then discover new knowledge from limited information. This paper is supposed to contribute to the name distinction and some other clustering analysis with more reliable method and theory We obtain the association rules by the experiment as followed: having same coauthor; having same workplace and years; having same publication and years The association rules selected by the experiment could be easily explained and commonsensible. Considering the association rules coming from the objective data and data mining method, they are more reliable Our future research will focus on the negative correlation between information [12] that is the local minimum points of function y=f\(x method into the feature extraction of pattern recognitions which have relative sub-information ACKNOWLEDGMENT This work was supported partly by the Special Fund for Fast Sharing of Science Paper in Net Era by CSTD under Grant No. 20096102410001 REFERENCES I] X.Yin, JHan, P.S Yu. "Object distinction Distinguishing objects with identical names," In Proc. of ICDE, pp. 1242-1246, IEEE Press 2007 2] C.C.Fabris, A.A.Freitas. "Discovering surprising patterns by detecting occurrences of Simpson's paradox," In Proc. of the Irj SeES Inti. Con! on Knowledge-Based Systems and Applied ArtifiCial Intelligence, pp. 148-160, Cambridge, UK, December 1999 3] Xiaoming Fan, Jianyong wang, Bing Lv, Lizhu Zhou, Wei Hu GHOST An Effective Graph-based Framework for Name Distinction," In Proc. of CIKM, pp. 1449-1450, ACM Press, 2008 4] A. Kulkarni and T Pedersen. "Name discrimination and email clustering using unsupervised clustering and labeling of similar contexts," In Proc of the Second Indian International Conference on Artificial Intelligence, pp. 703-722, Pune, India, December 2005 5] A.A.Freitas, "Understanding the crucial differences between classification and discovery of association rules - a position paper SIGKDD ExpIrations, 2\(1 


6] L.Feng, H.JLu, JXYu and JHan. "Minging inter-transaction associations with templates," In Proc of the 8th Inti. Cor\(. On Information and Knowledge Management, pp. 225-233, Kansas City Missouri, Nov 1999 7] E.-HHan, G.Karypis, and V.KumarMin-Apriori, "An Algorithm for Finding Association Rules in Data with Continuous Attributes http://www.cs.umn.edu/-han, 1997 8] Travers, Jeffrey, and Stanley Milgram. "An Experimental Study of the Small World Problem," SOCiometry, Vol. 32, No. 4, pp. 425-443 1969 9] de Sola Pool, !thiel, Kochen and Manfred \(1978-1 979 influence," Social Networks 1\(1 10] Stanley Milgram, "The Small World Problem," Psychology Today 1967, Vol. 2, pp. 60-67 II] Pang-Ning Tan, Michael Steinbach and Vipin Kumar, Introduction to Data Mining, Pearson Education, Inc. pp.132-133, 2006 12] X.Wu, C.Zhang and SZhang, "Mining Both Positive and Negative Association Rules," ACM Trans. on Information Systems, 22\(3 381- 405,2004 V4-289 


3 4  9 9  Suppose 3=s , according to formula \(5 of CID006, BP006  is{ }9,3,10 , as shown in table 4,  which indicates  that  e-shopper  CID006 belonged to the tenth cluster in May and moved into the third cluster in June thereafter reaching the ninth cluster in July According to formula \(6 from e-shoppers path with regard to a minimum support of 0.1 and a minimum confidence of 0.5. The association rules are as shown in table 5. The similarities  between the path of e-shopper CID016  and the derived rules are 22016 =SD and 11016 =SD . Therefore, e-shopper CID016 belongs to the ninth cluster at timeT , since the fitness between CID016 and the rules are =FD2016 0.2 and =FD 1 016 0.2001. Therefore, we predict that the products which e-shopper CID016 is likely to buy are Bread, and Biscuit  TABLE V. THE DERIVED ASSOCIATE RULES Rule 1+? sT  1?T  T  Support Confidence 1 2 3  15 16 10 10 3   10 3 1 10  


 3 9 3 4  9 9 0.3 0.1 0.1 0.2 0.1 0.1 1.0 1.0 1.0 0.5 1.0 1.0 V. CONCLUSION The preferences of e-shopper change over time. In this study, we describe a new approach for mining the changes of e-shopper  purchase behavior over time and discuss solutions to several problems. For predicting e-shoppers purchase behavior, the following concepts are proposed: BP j SDij and FDij . The SOM technique is used to detect the evolving e-shopper purchase sequences as time passes. The purchase sequences are derived from the changes in the cluster number of e-shopper. The sequential purchase patterns over user-specified minimum support and confidence are extracted by using the association rule. Then the sequential purchase patterns are stored in the rule database Finally, we give the example to elaborate the new methodology. The research presented in this paper makes a 155 contribution to mining  e-shoppers purchase behavior basing on transaction data. E-retailer may be able to perform effective  one-to-one marketing campaigns by providing individual target e-shoppers with personalized Product basing on using purchase sequences In the future, some possible extensions to this work are as 


follows. From the results of this study, we know which products target e-shoppers are likely to buy, but we have not yet explored the times at which these purchases are likely to occur. Further research analyzing e-shoppers past purchasing patterns should likewise enable prediction of the most appropriate times. Furthermore, one interesting research extension would be the setting up of a real marketing campaign, in which e-shoppers would be targeted using this methodology, which could then be evaluated with regard to its performance REFERENCES 1]Dhond, Gupta, A., Vadhavkar, S. Data mining techniques for optimizing inventories for electronic commerce[C]. In the Proceeding of the ACM-SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005:480-486 2] Kuo, R. J., Chen, J. H., Hwang, Y. C. An intelligent stock trading decision support system through integration of genetic algorithm based fuzzy neural network and artificial neural network[J]. Fuzzy Sets and Systems, 2001 118\(1 3] Agrawal, D., Schorling, C. Market share forecasting: An empirical comparison of artificial neural networks and multinomial logist model Journal of Retailing[J]. 1997, 72\(4 4] Weigen, A. S., Rumelhart, D. E.Generalization by weight-elimination with application to forecasting. Advances in Neural Information Processing Systems[J]. 1999, 3:875882 5] Chen, M, S, Han, J. Data mining: an overview from a database perspective[J]. IEEE Transactions on Knowledge and Data Engineering, 2006 8\(6 6] Schafer, J. B., Konstan. E-commerce recommendation application[J Journal of Data Mining and Knowledge Discovery, 2001, 16:125153 7] Giudici, P, Passerone, G. Data mining of association structures to model e-shopper behavior. Computational Statistics and Data Analysis[J]. 2002 38:533541 8]Changchien, S. Mining association rules procedures to support on-line recommendation by e-shoppers and products fragmentation[J]. Expert Systems with Applications, 2001, 20\(4 9] Song, H, Kim, J. Mining the change of e-shopper behavior in an Internet shopping mall[J]. Expert System with Applications, 2001, 21\(3 10] Anand, S, Patrick, A. A data mining methodology for cross-sales[J Knowledge-Based Systems, 2006, 10:449-461 11] G. Adomavicius, A. Tuzbilin. Using data mining methods to build e-shopper profiles[J]. IEEE Computer, 2006, 34 \(2 


12] Dhond, Gupta, A., Vadhavkar, S. Data mining techniques for optimizing inventories for electronic commerce[C]. In the Proceeding of the ACM-SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005:480-486 13]Chui-Yu Chiu , Yi-Feng Chen. An intelligent market segmentation system using k-means and particle swarm optimization[J]. Expert Systems with Applications, 2009, 36: 45584565 14]Tzung-Shi Chen , Shih-Chun Hsu. Mining frequent tree-like patterns in large datasets[J]. Data & Knowledge Engineering, 2007,62:6583 15]H. Tsukimoto, Extracting rules from trained neural networks[J]. IEEE Trans.Neural Networks, 2000, 11 \(2 156 


http://datamining.buaa.edu.cn/TopKCos.pdf 14] M. Zaki, Scalable algorithms for association mining, TKDE, vol. 12, pp. 372390, 2000 


enhance item-based collaborative filtering, in 2nd IASTED International Conference on Information and Knowledge Sharing, Scottsdale, Arizona, 2003 476 2010 10th International Conference on Intelligent Systems Design and Applications 


Basi Association Rles Basi c  Association R u les Association is basically connecting or tying up occurrences of Association is basically connecting or tying up occurrences of events Ol dib t f ilt t O n l y d escr ib e se t s o f s i mu lt aneous even t s Cannot describe patterns that iterate over time e g  itemset a  0  b  0  g    Eg If you sense higher data rates on the downlink than normal AND New Route generated Implies high chances of Intrusion AND New Route generated Implies high chances of Intrusion Associative IDS for NextGen Frameworks Dr S Dua LA Tech 20 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



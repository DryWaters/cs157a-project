Framework for Discovering Association Rules in a Fuzzy Data Cube Maria J Somodevilla Ivo H Pineda Torres Jos Tecuapacho Zecua Facultad de Ciencias de la Computación Benemérita Universidad Autónoma de Puebla Email:{mariasg,ipineda}@solarium.cs.buap.mx,josetecua@yahoo.com.mx Abstract This work presents a framework for the extraction of association rules from a spatial fuzzy data cube First of all spatial queries are executed to lter the information to be loaded in the data warehouse considering the spatial relationships among data Later on using the Mondrian tool a classic data cube 
is created and a fuzzy data cube FDC is generated from the rst cube by selecting the linguistic variable the fuzzy sets are dened and a threshold that allow us to determine whether the transaction’s value belong to a fuzzy set or other Once the FDC has been obtained and also the information be ready to be mined we use Weka tool in order to extract the association rules from the data Finally we apply the proposed framework through an case study Analysis of risk zones of the Popocatépetl Volcano Index Terms  FDC Fuzzy Sets Spatial Data Mining Data Warehouse,Association Rules I I NTRODUCTION Nowadays human beings could ask to ourselves What 
perception do we have about the world when we look around the landscape automatically we see a collection of objects or entities that perhaps we call spatial objects like land’s parcels rivers etc or the eyes of the mind transform patterns and processes of the nature on mathematical models?[1  Understanding the meaning of the patterns it has been a task that have lead researchers to create new tools for manipulating spatial data which helps to simplify the work of querying large volume of information Given the requirement of make more efcient the management and preprocessing of spatial have came up computational techniques and tools to solve these tasks One of these tasks is the Knowledge Discovery in 
Databases KDD 2  wh ich a llo w u s e x t r actio n o f n o n tr i v ia l spatial and no spatial information previously unknown and potentially useful from data Basically KDD consists of an interactive and iterative process comprising different phases for data mining This work is focused on spatial data analysis and exploitation coming from phenomena occurring over and under the world surface Given their nature and complexity it demands for their interpretation a new mechanism of Data Mining which is a fundamental part of the proposed framework In section 2 previous works are described section 3 presents the proposed framework and nally section 4 exposes a case study to validate this framework 
II R ELATED W ORK There exist previous works on the representation and manipulation of vague regions The more representative is the Fuzzy Minimun Bounding Rectangle FMBR[3  w hi ch i n cor por at es Fuzzy Logic to dene degreees of membership according to a membership function evaluation FMBR has been used to model spatial phenomena in many geographical applications The Fuzzy Data Cube[4 w as de n ed  r s t for a s a l e s p r obl em It is necessary then to extend this concept to consider the FDC generation from a spatial database The treatment of the attributes semantic in the FDC is another approach which has been considered very few in the literature This model helps to draw conclusions with a higher degree of certainty[5  
which has been the main use of FDC Data Mining consists of a set of data analysis techniques for extracting patterns tendencies and regularities to describe and comprehend better the data 6  F u z zy Asso ciatio n R u l es d eal with th e r elatio n ships between attributes and their surrounded environment like human reasoning does[7  S pat i a l a s s o ci at i o n r ul es des c r i be t h e spatial objects co-occurrence intrinsic law referring to closed neighbors association rule union of limits and to the content of spatial entities Essentially association rules can be dened as it is indicated by 1 X   Y  s  c  D  1 where s and c represent support and condence of the 
rule respectively D is the distance threshold between two spatial objects If two spatial objects X and Y satisfy X,Y  D then X Y satisfy the relation A data cube species a fact table containing the analysis object of study The facts are dened by a set of dimensions Dimensions describe the data cube as the same way like width high and depth describe a geometric cube 8 A s s o ci at i o n rules as knowledge representation techniques can be used to represent the existing relationships among data cubes dimensions 2 III F RAMEWORK FOR O BTAINING A SSOCIATION R ULES IN A F UZZY S 
PATIAL D ATA C UBE In this section we propose a framework for the extraction of association rules in a fuzzy spatial data cube This process involves a set of Technologies like GIS ArcGIS Data Warehousing Mondrian Cube Desinger Data Mining 2008 Mexican International Conference on Computer Science 1550-4069/08 $25.00 © 2008 IEEE DOI 10.1109/ENC.2008.17 126 


Weka Spatial Databases and Fuzzy Logic Figure 1 represents the steps to follow for the extraction of association rules rst spatial queries are carried out then the ltered data is loaded and transformed to be integrated in the data warehouse Information is transformed in a multidimensional schema sharp or fuzzy in order to apply data mining The proposed framework focus on the extraction of association rules for making decisions like making predictions based on previous experiences Fig 1 Framework for Obtaining Association Rules in a Fuzzy Spatial Cube It is important to note how is shown in Figure 1 that is possible to apply data mining from a sharp or fuzzy multidimensional structure In the following sections we describe the steps for the implementation of this framework A SpeciÞcation of the Set of Spatial Queries This step which is the rst of this framework see Figure 1 is one of the most important because of spatial queries will lter the necessary information for the integration of the fuzzy data warehouse To compile this information spatial relationships among data have to be taken in consideration 1 Spatial relationships Among the operations Spatial Algebra denes one of the most important are the spatial relationships which are classied in geometric topological and directional.The explicit location of spatial objects denes implicit relationships with their closed neighbors in a way that information related to them should be considered for spatial data mining Respecting to spatial queries it is necessary to guarantee exibility in doing so an appropriate representation of spatial data is required B Creation of the Data Warehouse The design of the proposed data warehouse includes a process of ltering of data known as ETL Extraction Transformation Loading ETL process creates an intermediate data repository being one of the aspects that more effort requires In Figure 1 also is shown how spatial databases are one of the inputs to the ETL process Filtering information is based on executing specic spatial queries in order to extract the information to be loaded in the data warehouse This information need to be standardized and updated to avoid anomalies such as redundancy missing and incomplete data allowing also the creation of keys Then data is loaded from transactional databases or intermediate repository to the data warehouse As we mentioned before the data cube represents a n-dimensional space therefore it is a suitable structure to represent in all its complexity spatial data A critical problem about spatial data is the representation of the border because it exhibits fuzzy characteristics Therefore different fuzzy sets compressing the border could be treated through dimensions of the fuzzy data cube C Multidimensional Structure A multidimensional structure represents an activity that is object of study and it is composed by dimensions characterizing this fact units of measures which are relevant information about the fact forming a data cube known as datamart Pentaho Cube Designer is used to create the classic data cube This tool allows us to create an XML schema containing units of measure hierarchy levels and dimensions Moreover this tool helps to select necessary attributes and execute join operations facilitating the schema creation D Fuzzy Multidimensional Structure Fuzzy Set Theory proposed by Zadeh  w as us ed t o create the fuzzy multidimensional structure This theory allows us to model fuzzy data cubes containing fuzzy facts and dimensions In general the idea is to create a classic data cube and then a fuzzy data cube following the next steps  Select the linguistic variable  Dene the fuzzy sets and assign terms of the context partition  Dene a threshold,to determine membership to a set 1 Linguistic Variable Variables that can take values from natural language terms like many few positive negative etc which are words playing a role of labels in a fuzzy set[12 11  A l i ngui s t i c v a r i abl e i s r e pr es ent e d u s i ng l i ngui s t i c t e r m s  and interpreted as fuzzy numbers a base variable for instance temperature pressure high danger etc In Figure 2 each term of a linguistic variable represents a fuzzy set At the top is the variable’s name in the second level we nd the qualied terms that a variable can take and at the bottom partitions of the context that considers ranges for each term are established 2 Fuzzy Dimension The structure of the fuzzy data cube is similar to the classic which consist on establishing the context of the analysis over the facts In order to access different levels of detail we can dene hierarchies over dimensions establishing as many granularity levels as possible Each of these levels will be a set of names or labels which dene subsets of elements corresponding to the grouped elements of the lower levels 11  127 


 Term2 Term1 Term3 015 2025  15..20 20..25 Context Domain Linguistic Variable Fig 2 Linguistic variable The difference is on labels levels that do not represent sets in a classic sense but do represent sets from fuzzy set theory point of view In this case fuzzy sets are dened for each classic dimension and another fuzzy dimension is created containing terms of a partition context In this partition the element could be included in a set that denes to another and this implies a degree of membership associated with Each element of the dimension will have a level dening a fuzzy set for establishing its degree of membership For each pair of levels we have the relationship in the expression 2  ij  L i  L j  0  1 2 Expression 2 allows us to dene the degree of membership of the elements to their parent levels 11  3 Fuzzy Facts Variables of the domain in analysis for instance sales inventories budgets will dene the facts in the data cube for the fuzzy case Together with the facts we include a value indicating certainty degree of the occurrence of this fact  Having more than one data source it is possible that no all of them have the same level of condence then,we have two possibilities  Consider data This way we could be in risk to make strategic decisions based on possible incorrect external data  Omit data The decision making process could be based on biased data The previous disjunctive deals with the problem of the importance of the information according its source and this way its inuence in the analysis can be controlled This situation can be handled using a fuzzy model through degrees In this way facts having a lower degree will have a lower weight but yet considering in the analysis A fuzzy set 11 c ons i s t s on a s et of at t r i b ut es A 1    A n with domains D 1   D n  let’s consider facts to any pair  h    where h  x 1   x n   in other words any n-tuple dened over the domains of the attributes and   0  1 The value  represents the inuence of the fact in the posterior analysis the more close to 1 the more inuent or important the attribute is 4 Fuzzy Data Cube A fuzzy data cube will be dened by its structure where a component represents fuzzy facts with a certain value the others elements will be the dimensions characterizing these facts A fuzzy data cube is a tuple C   D L b F,H,A  such that  D 1   D n  is a set of fuzzy dimensions L b  I 1 b   I nb  is a set of levels such that l ib belongs to d i F  R   where R is the fuzzy facts set and  an special symbol H is an historic object dened as A  l 1 b     l nb  F  for each value of the dimensions it returns the fact related with this coordinates 3  E Extraction of Asociation Rules Association rules are a formal way of expressing data patterns stored in a database These patterns can serve to predict the data behavior produced by the fuzzy multidimensional schema proposed Therefore the patterns founded and interpreted with the expert help in useful information can assist in the decision making process The intuitive m eaning of an association rule X   Y is that transactions or tuples containing X also contain Y Given an association rule two quality rules measures are incorporated conÞdence and support The rule quality is based on conÞdence c for the rule X   Y  which measures the percent of times that a rule fullls when it is applicable support s is the fraction of the transactions in the database containing X and Y or the number of transactions the rule predicts correctly 2 IV T HE C ASE S TUDY The case study in this paper consists on to analize the Popocateptl’s risk zones and the surrounding counties and towns of the State of Puebla located in the skirts of the volcano The case study is developed according to the steps stated on the framework as seen Figure 1 A Creation of the Spatial Queries For the case study Popocateptl volcano suppose we want to know which towns are directly affected by the lava ow or which ones are spatially related to In order to get such information the query consists of the process of selecting the lava ow and a buffer zone of 500 meters towns that could be affected in this area As we can see in Figure 3 the information returned from the query shows several points representing the towns that are on the lava path in the buffer zone In other words the results of the spatial query are transformed and loaded in to the datawarehouse B Construction of the Data Warehouse The architecture of the proposed multidimensional data warehouse is represented in Figure 4 The information of the Popocatepetl’s data warehouse consists of three dimensions named time space and theme For instance the data representing the lava ow and risk zone are stored in the theme dimension The architecture of the Spatial Data Warehouse is the bottom line for the creation of the data cube together with 128 


 Fig 3 Lava ow  People living risk areas county town FMBR Evacuation route Day week month quarter year danger description risk_zone region membership THEME SPACE TIME Population Attributes Measurements Fig 4 Architecture of the Spatial Data Warehouse their levels of aggregation and disaggregation respectively The proposed data cube will be extended in order to dene a fuzzy data cube C DeÞnition of the Multidimensional Structure XML is used to represent as a schema how the information has to be represented in the data cube Figure 5 shows the XML’s multidimensional structure schema the name of the data cube name of the fact’s table the one will store the entire cube’s information together with the hierarchical levels and the measurement units D DeÞnition of the Fuzzy Multidimensional Structure In order to work with the fuzzy multidimensional structure rstly it has to be dened the fuzzy dimension which is dened with an expert vulcanologist The expert helps on to dene the linguistic variable and the fuzzy sets The linguistic variable for example the risk zone is dened according to Figure 2 1 DeÞnition of the Fuzzy Sets According with the expert there are dened three types of risk zones high zone medium zone and low zone These zones keep a closed relationship Fig 5 XML schema for data cube with the lava ow based on that the shape of the three membership functions is a trapezoid The fuzziness of the information amount of lava  and its capabilities to make a correct decision  explain the decision to work with such types of functions Fig 6 Fuzzy sets for risk_zone variable From Figure 6 the three risk zones can be obtained These zones are represented as semi circles in the state of Puebla The radii of each zone represents the degree of membership of each town to a risk_zone The transactions contained in the data cube are shown in Table 1 considering the distance in kilometers from the volcano to towns that are associated with the risk_zone variable TABLE I T RANSACTION FOR risk_zone Transactions risk_zone km T 1 8 T 2 19 T 3 12 T 4 15 T 5 23 The degrees of membership to the Fuzzy Set are calculated 129 


using the denition given in Equation 3 F  x             0 if  x  a  or  x  d   x  a   b  a  if x   a b  1 if x   b c   d  x   d  c  if x   c d  3 Table 2 shows the results of applying the Fuzzy function Eq 3 for diferent values of risk_zone and the returned value represents the degree of membership to a risk zone for towns that are in such range For example for T 1 with risk_zone of 8 km the membership function returns a highest degree of risk equals to 1 TABLE II T RANSACTIONS D EGREE OF MEMEBERSHIP TO F UZZY SETS  USING F X  IN E Q 3 Fuzzy sets T 1 T 2 T 3 T 4 T 5  risk_degree High 1 0 0.44 0 0  risk_degree Medium 0 0.23 0.56 1 0  risk_degree Low 0 0.77 0 0 1 Another way to estimate the degree of membership consists on to dene a threshold   this value indicates whether a transaction belongs to some set For instance working with  0  3  those transactions with a value less than equal to 0.3 do not belong to a given fuzzy set then their degree of membership will be 0 E Association Rules Extraction The Association Rules are obtained from the spatial datawarehouse using Apriori algorithm which it is part of WEKA A collection of tools that implement decision trees tables and rule learners,etc By using the data cube is possible to generate the association rules like the one represented in expression 4 This rule helps to make the right decision with respect to the evacuation route that exist in towns close to Popocatepetl volcano in case of an eruption COUNTY _ IN _ ROU T E  xRISK _ DEGREE  High ROAD _ STATUS  Good support   SELECTED _ ROU T E  x support conf idence 4 Suppose we consider unpaved road near a town with high population and high probability of seismic activity attributes together with an advisory of evacuation this situation could create a bottle neck so we expected that our model will return an alternative evacuation route INEG’s le containing Popocateptl seismic activity was processed using the Apriori algorithm in order to get the association rules The parameters of the Apriori algorithm are dened as follows Condence of 0.9 high expectation Support minimum 0.01 0.05 0.1  b as ed on t h es e v al ues w e can r e duce t he number o f r ul es and redundancy See Figure 7 Typically it is desirable to generate only rules from frequent itemsets that are well-represented in the data The minimum Fig 7 Association rules from Weka frequent itemset support is a user-specied percentage that limits the number of frequent itemsets produced by the model A frequent itemset must appear in at least this percentage of all the transactions if it is to be used as a basis for rules TABLE III N UMBER OF RULES VS  MINIMUN SUPPORT Support Number of rules Iterations 0.5 3 10 0.1 7 18 0.05 73 19 0.01 197 20 Table 3 shows that keeping high condence equals to 0.9 and varying support we can control the number of rules and working with 10 the number of rules is reasonable It is important to mention that instead of working with the nine attributes,that the le denes were selected only ve attribute zone that represents the three risk zones previously dened ashes_affect represents the level of ashes on the ground volcanic_material represents the level of fallen volcanic material such as incandescent stones ow_path represents different trajectories for lava ow and ow_danger that represents the danger level This reduction of the dimensionality in terms of attributes allows to the algorithm to nd the most interesting patterns V C ONCLUSIONS This work proposes a framework to model the geography according how it is presented in the real world taking advantage of the new information technologies The concepts in which the multidimensional model is based on and the 130 


Fuzzy Logic are complemented for the generation of the Fuzzy Data Cube Data Mining techniques are applied to the information stored in the FDC in order to extract the set of association rules which dene the behavior of spatial objects in their environment Fuzzy sets dened in the FDC allow to model spatial objects whose attributes have a certain degree of membership Spatial and non spatial attributes can support the information related to vague regions Fuzzy Logic is crucial in modeling vague regions since their borders are not sharply dened In the application presented here Fuzzy Logic helps us to determine the degree of membership of the different towns to each risk zone and then can determine which evacuation road could be the most suitable one Therefore Association Rules obtained from FDC will assist on the decision making process for instance when it is necessary to choose among different available evacuation routes it has to be considered quality measures such as condence and support that association rules provide A CKNOWLEDGMENT Authors want to thank Facultad de Ciencias de la Computación Computer Science Dept for the help and support in making this wortk possible Part of this result is in part due to National Council for Science and Technology CONACyT for supporting Jos Tecuapacho R EFERENCES  P  A  B ur r ough and A  U  F r a nk Concepts and paradigms in spatial information Are current geographic information systems truly generic  International Journal of Geogra phical Information Systems 1995 2 J  H er nández J  R  Q u intana and C  F er r i  Introducci—n a la Miner’a de Datos  Capítulos 1 2 y 9 Pearson Prentice Hall 2005 3 M  J  S om ode villa Fuzzy MBRs Modeling for Reasoning about Vague Regions  PhD Thesis Tulane University 2003  L  Y ubao Y  J i an The Computation of Semantic Data Cube  The 4th International Conference on Grid and Cooperative Computing pp 573578.Beijing China Nov 30-Dec 3 2005 5 A  R eda K  M e hm et Integrating Fuzziness into OLAP for Multidimensional Fuzzy Association Rules Mining Third IEEE International Conference on Data Mining pp 469-475.Nov 2003  R ongqin L   W e nzhong S  X iaom ei Y  and G uangyuan L  Mining Fuzzy Spatial ConÞguration Rules Methods and Applications  ISPRS Workshop on Service and Application of Spatial Data Infrastructure.XXXVI pp319323.2005 7 J  M  M olina a nd J  G a r c a TŽcnicas de An‡lisis de Datos Aplicaciones Pr‡cticas utilizando Microsoft Excel y Weka Art Universidad Carlos III Madrid España.pp539-562.2004  M icr o s o ft 2005 OLAP and data mining functionality  Available http://www.microsoft.com/spanish/msdn  M er cedes V ittur i ni S ilvia Cas t r o and S er gio M ar tig  2 005 Modelos de Datos Espaciales  VII Workshop de Investigadores en Ciencias de la Computación.pp39-62.Argentina Available:http://dc.exa.unrc.e du.ar/wicc/papers/Otros/42.pdf  M e ter F is her  Boolean and Fuzzy Regions Department of Geography University of Leicester Leicester,UK.2001  Car l os M o lina F er nández Impresici—n e Incertidumbre en el Modelo Multidimensional Aplicaci—n a la Miner’a de Datos PhD Thesis Universidad de Granada.2005  Bonif acio M ar tín and A lfr e do Sanz Redes Neuronales y Sistemas Difusos Chapter 7 and 8 Alfaomega Ra-Ma 2001 131 


Since the attribute determination algorithm has determined that the attribute Sno in Table 0, the attribute Cno in Table 1, and the attributes <Sno Cno> in Table 2 embrace the double-connective association rule student\(Sno 010 1 course\(Cno 010 2 study\(Sno, Cno\he connective determination algorithm make the relational matrix shown in Fig. 4 according to the binary relationship table of Table 2   C1 C2 C3 C4 S1   T  T  F  F S2   T  F  T  F S3   T  F  F  F S4   F  T  F  F S5   T  F  F  T   Fig. 4 The relational matrix made from Table 2  Fig. 4 is made like this: Table 2 has the tuple S1, C1>, then at the cross of the row S1 and the column C1, a T is filled; Table 2 does not have tuple S1, C3>, then at the cross of the row S1 and the column C3, a F is filled Suppose the cardinality of student\(Sno\s M, in this example 5, i.e. S1 to S5; the cardinality of course\(Cno\n this example 4, i.e. C1 to C4 The algorithms for DCAR1 through DCAR6 are as follows The algorithm for DCAR1 If in Fig. 4 there is M*cf 1 rows, N*cf 2 columns submatrix, in which all elements are Ts, then DCAR1 holds The algorithm for DCAR2 If in Fig. 4 there is at least one column, in which there are at least M*cf 1 Ts, then DCAR2 holds The algorithm for DCAR3 If in Fig. 4 at least M*cf 1 rows have Ts, then DCAR3 holds The algorithm for DCAR4 If in Fig. 4 there is at least one row, in which there are at least N*cf 2 Ts, then DCAR4 holds The algorithm for DCAR5 If in Fig. 4 at least N*cf 2 columns have Ts, then DCAR5 holds The algorithm for DCAR6    DCAR6   DCAR3  DCAR5     DCAR2  DCAR4   DCAR1 Fig. 5 The complement lattice formed by DCAR1 through DCAR6 
277 
277 


000\003 000\\000L\000J\000\021\000\031\000\003\000\003\000&\000R\000Q\000Q\000H\000F\000W\000L\000Y\000H\000\003\000G\000H\000W\000H\000U\000P\000L\000Q\000D\000W\000L\000R\000Q\000\003\000D\000O\000J\000R\000U\000L\000W\000K\000P\000\003 Start Call DCAR1 000D\000O\000J\000R\000U\000L\000W\000K\000P  DCAR1 holds 002  Call DCAR2 000D\000O\000J\000R\000U\000L\000W\000K\000P  Output DCAR1,2,3,4,5,6 End DCAR2 holds 002  Output DCAR2,3,6 Call DCAR3 000D\000O\000J\000R\000U\000L\000W\000K\000P  DCAR3 holds 002  Output DCAR3,6 Call DCAR4 000D\000O\000J\000R\000U\000L\000W\000K\000P  DCAR4 holds 002  Call DCAR5 000D\000O\000J\000R\000U\000L\000W\000K\000P  Output DCAR4,5,6 End DCAR5 holds 002  Call DCAR6 000D\000O\000J\000R\000U\000L\000W\000K\000P  Output DCAR5,6 End DCAR6 holds 002  Output DCAR6 End Error Y N N Y Y N N Y Y N N Y 
278 
278 


If in Fig. 4 there is at least one T, then DCAR6 holds DCAR1 through DCAR6 forms a complement lattice shown in Fig. 5 In Fig. 5, the lower rule implies the upper rule That is, if DCARj is reachable from DCARi via an ascending path, and DCARi holds, then DCARj holds Because DCAR1 through DCAR6 satisfies Fig 5, their algorithms can be merged into one algorithm called connective determination algorithm, shown in Fig. 6 Suppose cf 1 80%, cf 2 75%. In Fig. 4, for the column of C1, there are M*cf 1 5*80%=4 elements whose values are T \(namely, S1, S2, S3, S5 Therefore, DCAR2: course\(Cno 004 1  student\(Sno 003 1  study\(Sno, Cno\olds. From Fig. 5, we know that DCAR3 and DCAR6 also hold. In Fig. 4, there are at least N*cf 2 4*75%=3 columns which have value T \(namely, in the column of C1 there is S1, in the column of C2 there is S1, in the column of C3 there is S2, in the column of C4 there is S5 therefore DCAR5: course\(Cno 003 1  student\(Sno 004 1  study\(Sno, Cno  VI. CONCLUDING REMARKS 1\ Double-connective association rule mining is different from single-connective association rule mining. The former mines the association among the primary keys of the two entity tables and the primary key of the binary relationship table. The latter mines the association between frequent item sets 2\. 4 is different from data cubes in data warehouses. The elements in Fig. 4 are T or F. The elements in the data cubes are data 3\The differences between double-connective association rule and database query are that, first, the query information in databases are predeterminate while the information to be mined by double-connective association rule is not predeterminate, it is implied. Secondly, database query needs to write SQL statements, while double-connective association rule mining is automatic. Thirdly, the information obtained by database query is quantitative, while the information obtained by double-connective association rule mining is qualitative such as “for many”, “there are some  REFERENCES 1 Ji a w ei H a n   M i ch eli n e K a m b er   D a t a  M i n i n g C onc ep t s  a nd Techniques, Higher Education Press, Beijing, 2001, Morgan Kaufmann Publishers, 2000 2 A  G  Ha m i lt on  L o gi c for M a th em a t i c ia ns R evi s ed E d i t i o n   Cambridge University Press, 1988, Tsinghua University Press Beijing, 2003 3 X unw e i Z h o u   Br ie f I ntr o du c t io n  to  Mu t u al l y I nve r s is tic Logic”, 1999 European Summer Meeting of the Association for Symbolic Logic, Utrecht, The Netherlands, August 1-6 1999 4 u n w ei Zh ou F i r s t leve l exp l i c i t m u lt ip le i ndu ct i v e composition”, 2005 Spring Meeting of the Association for Symbolic Logic, The Westin St. Francis Hotel, San Francisco CA. USA, March 25-26, 2005 5 A b rah a m S i lb ers c ha t z  Hen r y  F  Kort h  S S u da rs ha n Dat a b a s e  System Concepts \(Fourth Edition\, Higher Education Press Beijing, 2002, McGraw-Hill Companies, 2002  
279 
279 


support pruning gene expression classifier with an accurate and compact fuzzy rule base for microarray data analysis Biosystems vol 85 computationally challenging As training set sizes increase it is likely that these difficulties will also increase VI RELATED WORK While operating on a microarray dataset current CAR 1 2 3 4 and other pattern/rule 20 21 mining algorithms perform a pruned and/or compacted exponential search over either the space of gene subsets or the space of sample subsets Hence they are generally quite computationally expensive for datasets containing many training samples or genes as the case may be BSTC is explicitly related to CAR-based classifiers but requires no expensive CAR mining BSTC is also related to decision tree-based classifiers such as random forest 19 and C4.5 family 9 methods It is possible to represent any consistent set of boolean association rules as a decision tree and vice versa However it is generally unclear how the trees generated by current tree-based classifiers are related to high confidence/support CARs which are known to be particularly useful for microarray data 1 2 6 7 11 BSTC is explicitly related to and motivated by CAR-based methods To the best of our knowledge there is no previous work on mining/classifying with BARs of the form we consider here Perhaps the work closest to utilizing 100 BARs is the TOPRULES 22 miner TOP-RULES utilizes a data partitioning technique to compactly report itemlgene subsets which are unique to each class set Ci Hence TOP-RULES discovers all 100 confident CARs in a dataset However the method must utilize an emerging pattern mining algorithm such as MBD-LLBORDER 23 and so generally isn't polynomial time Also related to our BAR-based techniques are recent methods which mine gene expression training data for sets of fuzzy rules 24 25 Once obtained fuzzy rules can be used for classification in a manner analogous to CARs However the resulting fuzzy classifiers don't appear to be as accurate as standard classification methods such as SVM 25 VII CONCLUSIONS AND FUTURE WORK To address the computational difficulties involved with preclassification CAR mining see Tables IV and VI we developed a novel method which considers a larger subset of CAR-related boolean association rules BARs These rules can be compactly captured in a Boolean Structure Table BST which can then be used to produce a BST classifier called BSTC Comparison to the current leading CAR classifier RCBT on several benchmark microarray datasets shows that BSTC is competitive with RCBT's accuracy while avoiding the exponential costs incurred by CAR mining see Section VB Hence BSTC extends generalized CAR based methods to larger datasets then previously practical Furthermore unlike other association rule-based classifiers BSTC easily generalizes to multi-class gene expression datasets BSTC's worst case per-query classification time is worse then CAR-based methods after all exponential time CAR mining is completed O SlS CGl versus O Si CGi As future work we plan on investigating techniques to decrease this cost by carefully culling BST exclusion lists ACKNOWLEDGM[ENTS We thank Anthony K.H Tung and Xin Xu for sending us their discretized microarray data files and Top-k/RCBT executables This research was supported in part by NSF grant DMS-0510203 NIH grant I-U54-DA021519-OlAf and by the Michigan Technology Tri-Corridor grant GR687 Any opinions findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding agencies REFERENCES 1 G Cong K L Tan A K H Tung and X Xu Mining top-k covering rule Mining SDM 2002 5 R Agrawal T Imielinski and A Swami Mining associations between sets of items Y Ma Integrating classification and association rule mining KDD 1998 11 T McIntosh and S Chawla On discovery of maximal confident rules without pp 43-52 1999 24 S Vinterbo E Kim and L Ohno-Machado Small fuzzy and interpretable pp 165-176 2006 1071 pp 207-216 1993 6 G Dong pp 273-297 t995 9 pp 5-32 2001 20 W Li J R Quinlan Bagging boosting and c4.5 AAAI vol 1 V Vapnik Support-vector networks the best strategies for mining frequent closed itemsets KDD 2003 4 M Zaki and C Hsiao Charm L Wong Identifying good diagnostic genes or gene expression data SIGMOD 2005 2 G Cong A K H Tung X Xu F Pan and J Yang Farmer Finding interesting rule gene expression data by using the gene expression based classifiers BioiiiJcrmatics vol 21 l and Inrelligent Systenis IFIS 1993 16 Available at http://sdmc.i2r.a-star.edu.sg/rp 17 The dprep package http:/cran r-project org/doclpackages dprep pdfI 18 C Chang and C Lin Libsvm a library for support vector machines 2007 Online Available www.csie.ntu.edu.tw cjlin/papers/libsvm.pdf 19 L Breiimnan Random forests Maclh Learn vol 45 no 1 M Chen and H L Huang Interpretable X Zhang 7 J Li and pp 725-734 2002 8 C Cortes and Mac hine Learming vol 20 no 3 in microarray data SIGKDD Worikshop on Dtra Mining in Bioinfrrnatics BIOKDD 2005 12 R Agrawal and R Srikant Fast algorithms for mining association rules VLDB pp 1964-1970 2005 25 L Wong and J Li Caep Classification by aggregating emerging patterns Proc 2nd Iat Coif Discovery Scieice DS 1999 gene groups from pp 487-499 t994 13 Available ot http://www-personal umich edu/o markiwen 14 R Motwani and P Raghavan Randomized Algoriitlms Caim-bridge University Press 1995 15 S Sudarsky Fuzzy satisfiability Intl Conf on Industrial Fuzzy Contri J Han and J Pei Cmar Accurate and efficient classification based on multiple class-association rules ICDM 2001 21 F Rioult J F Boulicaut B Cremilleux and J Besson Using groups for groups in microarray datasets SIGMOD 2004 3 concept of emerging patterns BioinformJotics vol 18 transposition for pattern discovery from microarray data DMKD pp 73-79 2003 22 J Li X Zhang G Dong K Ramamohanarao and Q Sun Efficient mining of high confidence association rules without S Y Ho C H Hsieh H pp 725-730 1996 10 B Liu W Hsu and support thresholds Principles f Drata Mining aind Knowledge Discovery PKDD pp 406 411 1999 23 G Dong and J Li Efficient mining of emerging patterns discovering trends and differences KDD J Wang J Han and J Pei Closet Searching for An efficient algorithm for closed association rule mining Proc oJ the 2nd SIAM Int Con on Data in large databases SIGMOD 



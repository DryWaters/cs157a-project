Progressive Clustering r Database Distribution on a Grid Valerie FIOLET University of Mons-Hainault 6 Avenue du Champs de Mars 7000 MONS BELGIUM Email Valerie.Fiolet@umh.ac.be Laboratoire d\220Informatique Fondamentale de Lille Email 223olet@li\224.fr Bernard TOURSEL Laboratoire d\220Informatique Fondamentale de Lille UMR CNRS 8022 University of Lill e1-Cit 264 e Scienti\223que 59655 Villeneuve D\220ascq CEDEX FRANCE Email toursel@li\224.fr Abstract The increasing availability of clusters and grids of workstations provides cheap and powerful ssources for distributed datamining To exploit these ressources we need new algorithms adapted to this kind of environment in particular with respect to the way to fragment data and to use this fragmentation An 216intelligent\216 distribution of data is required and can be obtained from clustering Most existing parallel methods of clustering are evelopped for supercomputers with shared memory and hence can not be used on a Grid This paper presents a ew clustering algorithm called ressive Clustering which executes a clustering in an ef\223cient and incremental distributed way The data clusters resulting from this algorithm can subsequently be used in distributed data mining tasks 1 Introduction Knowledge discovery in databases also called Data Mining is a valuable engineering tool that consists in extracting useful information from very large databases These tools usually need high computing capacities which could be provided by parallelism and distribution The DisDaMin project attacks data mining problems as association rules clustering  by distributed computing The aim of the project is to develop parallel and distributed solutions for data mining problems thereby achieving two gains in execution times gain from use of parallelism and gain from decreased necessary computation by using an intelligent distribution of data and computation In a parallel and distributed environment such as a grid or a cluster constraints inherent to the execution platform must be taken into account in algorithms The non-existence of a central memory forces us to distribute the database into fragments and to handle these fragments using parallelism  Because of the high communication cost in this kind of environment parallel computing must be as autonomous as possible to avoid costly communications or at least synchronizations r data mining problems it is necessary to obtain an intelligent data fragmentation  in order to obtain more independent fragments The main problem is how to obtain this intelligent fragmentation For the association rules problem for example the main criterion for intelligent fragmentation is that data rows within a fragment are as similar as possible according to values for each attributes while data rows between fragments are as dissimilar as possible what allows to parallelize this problem which normally needs to access the whole database and also allows to decrease complexity see As this criterion appear similar to the objective of clustering algorithms this fragmentation could be produced by a clustering The usefulness intelligent fragmentation obtained from clustering for the problem of association rules has already been studied by Fiolet and Toursel  This fragmentation from clustering allo ws to obtain a good speed-up from parallelism as well as a decrease of time complexity from using intelligent distribution as pected Clearly the clustering phase itself has to be distributed and fast too in order not to slow own the global ecution time Clustering methods will be described before introducing Parallel Progressive Clustering for execution on grid 2 Clustering Clustering is the process of grouping data into groups called clusters so that objects within the same cluster are Proceedings of the 4th International Symposium on Parallel and Distributed Computing \(ISPDC\22205 0-7695-2434-6/05 $20.00 \251 2005  IEEE 


similar but dissimilar to objects in other clusters Two wellknown clustering algorithms are KMeans see McQueen  F o r g y 4 which yields approximate results b u t has an acceptable time complexity and Agglomerative methods see Sokal which yields relati v e good quality results t s limited from time complexity 2.1 Principle of Kmeans e  KMeans Clustering Principle  Input  the data the number of clusters to compute k Output  clusters of data 1 initialize k objects as the initial centers 2 repeat 3 re each objects to the nearest cluster 4 update the cluster means values 5 until no data change anymore 6 return the k identi\223ed clusters KMeans is an iterative algorithm that constructs an initial k-partition of data An iterative relocation technique attempts to improve the partitioning by moving objects from one group to another one until a terminal criterion see Table 1 KMeans will produce a local optimum result the quality of which depends on the choice of k number of groups to identify and on the choice of initial groups centers Iterative methods allow to 223nd a good value for k The initial centers must provide a good covering of the data space It is also necessary to have a similarity measure and a mean function The algorithm halts if the clusters do not change anymore or after two many iterations 2.2 Principle of Agglomerative clustering e  Agglomerative Clustering Principle Input  the data termination criterion Output  clusters of data 1 to consider each data as a cluster 2 repeat 3 to merge the two nearest clusters 4 until termination criterion 5 return the identi\223ed clusters Hierarchical agglomerative clustering consists in a bottom-up approach of the problem that consider all data separately as clusters and merge two nearest clusters at each iteration until a termination condition is satis\223ed see Table 2 This method uses a similarity measure matrix between clusters that makes the method unsuitable huge datasets 2.3 Parallel algorithms The two methods KMeans clustering and agglomerative clustering need to access the whole database or to communicate between each iteration in order to obtain correct solution Parallel methods exist for KMeans see Forman et Zhang Samato v a and al.[8 and agglomerati v e cluster ing see Johnson on the tw o kinds of data distrib ution vertical and horizontal i.e by attributes or by record instances r parallel clustering to achieve the same quality clusters as under sequential clustering a lot of communications is required Those methods are suited to supercomputers as CC-NUMA or SMP using a common memory and fast internal interconnexion network Parallel Data Miner for IBM-SP3 for example The huge number of communications in existing parallel methods yields performance problems in the context of a Grid The classical methods need to be revisited to take into account the constraints of a grid architecture no common memory slow communications The Parallel Progressive Clustering method presented in the next paragraph is based on these constraints 3 Progressive clustering The Parallel Progressive Clustering method is inspired by the sequential clustering algorithm called CLIQUE see Agrawal The CLIQ UE algorithm consists in clustering data by projections in each dimension and by identifying dense clusters of data projections The method assumes that the whole database can be accessed for projections In the context of a grid for progressive clustering it is assumed that the database is distributed by vertical splits multibase Parallel Progressive clustering see w orks back from CLIQUE in a bottom up approach considering attributes or columns of the database It 223rst computes clusters on rtical fragments containing few attributes see Section 3.3 and then combines these clusters to obtain clusters in higher dimensions see Sections 3.4 and 3.5 Both steps i.e the clustering of vertical fragments and the combination of these clusters execute in a distributed way The combination of results takes bene\223ts from distributed execution see Section 4.3 The next paragraph explains the method of Parallel Progressive clustering Three steps could be identi\223ed initial clustering step crossing step and merging optimizing step  A database with m attributes and n rows s represented by D=\(A K,V where 200 A  A 1  A 2  A m  is a 223nite set of attributes 200 K  K 1  K 2  K n  is the set of keys of the database rows We write v i,j where 1 002 i 002 m ad 1 002 j 002 n  for the i th coordinate of the j th row Proceedings of the 4th International Symposium on Parallel and Distributed Computing \(ISPDC\22205 0-7695-2434-6/05 $20.00 \251 2005  IEEE 


3.1 De\223nitions Let C e a function which associates to a set of attributes X\(X 003 A a k-partition C\(X   Ui  i  1 to k  of k groups of keys Ui Ui 004 K n a subset of attributes X 003 A and a partition C\(X of K the Fragmentation of D relative to X and C  denoted H\(X,C\(X is the set of triplets H X,C\(X   X U G\(X U  U 005 C\(X  where G\(X,U  c i,U i 005 X U 005 C\(X and c i,U  002 j 002 U C i,j  card  U   average of c i,j  see Table 3 e  De\223nitions Projection of a sample Representation U f the database D of G\(X,U on X Keys attributes values keys G\(X,U K 5 v 1 v 2 v 3 v 4 v 5 K 5 K 8 v 002 1 v 002 2 v 002 3 v 002 4 v 002 5 K 8 c 1 U c 2 U c 3 U c 4 U c 5 U K 9 v 216 1 v 216 2 v 216 3 v 216 4 v 216 5 K 9 X s a set of attributes X 002 A with X  A 1 A 2 A 3 A 4 A 5  U s a subset of keys U 002 K U 003 C\(X with U  K 5 K 8 K 9   v 1 v 2 v 3 v 4 v 5  set of attributes values relative to X for instance of keyNumber K 5  3.2 Progressive clustering  General Algorithm The General Distributed Progressive Clustering Algorithm DPG looks like a parallel iterative algorithm which leads to a global fragmentation of the database D i.e relative to all attributes in A by associating two artial fragmentations at each iteration 200 initial phase  partition of attributes fragmentations of the database according to each group of attributes 200 To iterate phases 1 and 2 f database fragmentation considering for each iteration two groups X and Y f the attributes partition 205 Phase 1  crossing phase 205 Phase 2  optimizing merging phase 200 Until a fragmentation relative to the whole set f attributes A s obtained Both the initial phase and the iterative phases are executed in a parallel distributed manner 3.3 Initial phase 1 to choose a partition P k A   X i  i=1 to k  of the attributes set A this partition is generally de\223ned according to the physical distribution of the database 2 006 X 005 P k A to calculate by a classical clustering method a fragmentation H\(X,C\(X   X U G\(X U 005 C\(X  of the database r the future computation of association rules it could be interesting to apply the initial phase to each attribute independently i.e a partition of attributes into nA groups of cardinality 1 in order to obtain a global information about each attribute r example see Table 4 the initial phase on attributes group X has ful\223lled 3 subsets of K U U\220 and U\216 and 2 subsets of K V and V\220 on attributes group Y e  Results C\(X and C\(Y of initial phase on X and Y C\(X C\(X X  A 1 A 2 A 5  Y  A 6 A 8 A 9  keys G G keys U  V  K 5  K 5  K 7  G\(X,U G\(Y,V K 7  K 18  c 1 U c 2 U c 5 U  c 6 V c 8 V c 9 V  K 18  U\220  V\220  K 22  G\(X,U\220 K 22  K 24  c 1 U 003 c 2 U 003 c 5 U 003  G\(Y,V\220 K 24  c 6 V 003 c 8 V 003 c 9 V 003  U\216  K 31  G\(X,U\216 K 31  K 32  c 1 U 216 c 2 U 216 c 5 U 216  K 32  3.4 Crossing phase Let us consider two fragmentations of the database H\(X,C\(X and H\(Y C\(Y respectively s o X and Y 004 A X 007 Y  b  Let Z=X t Y and H 002  Z C 002  Z  a fragmentation of the database relative to Z H\220\(Z C\220\(Z   Z W G\220\(Z W   where 200 W 005 partition C\220\(Z of K 200 G\220\(Z,W  c i,W i 005 Z W 005 C\220\(Z  The crossing phase de\223nes a fragmentation of the database relative to Z from fragmentations related to X and Y It consists in  1 De\223ning C\220\(Z C\220\(Z  W/W=U 007 V 006 U 005 C\(X and 006 V 005 C\(Y W n  b Proceedings of the 4th International Symposium on Parallel and Distributed Computing \(ISPDC\22205 0-7695-2434-6/05 $20.00 \251 2005  IEEE 


2 De\223ning groups G\220 Z W corresponding to groups W of C\220\(Z 006 W 005 C\220\(Z H\(Z W   Z W G\220\(Z W  with W 005 C\220 Z and G\220 Z W c i,W i 005 Z c i,W  c i,U if i 005 Xor c i,W  c i,V if i 005 Y  r example see Table 5 the crossing phase on X and Y has ful\223lled 4 subsets of K W W\220 W\216 and W\220\216 e  Results C\220\(Z at the end of the crossing phase between C\(X and C\(Y  Z X 004 Y  A 1 A 2 A 5 A 6 A 8 A 9  keys G W=U 005 V   K 5  K 7  G\(Z,W K 18  c 1 U c 2 U c 5 U c 6 V c 8 V c 9 V  C\220\(Z W\220=U\220 005 V   K 22  G\(Z,W\220 c 1 U 003 c 2 U 003 c 5 U 003 c 6 V c 8 V c 9 V  W\216=U\220 005 V\220   K 24  G\(Z,W\216 c 1 U 003 c 2 U 003 c 5 U 003 c 6 V 003 c 8 V 003 c 9 V 003  W\220\216=U\216 005 V\220   K 31  G\(Z,U\216\220 K 32  c 1 U 216 c 2 U 216 c 5 U 216 c 6 V 003 c 8 V 003 c 9 V 003  3.5 Optimizing merging phase The last phase consists in optimizing the database fragmentation relative to Z from the one obtained in the preceeding crossing phase Let us consider H\220\(Z W as a database D\220 Z  The initial phase is applied to D\220 Z i.e applying a classical clustering method on D\220 Z giving a ew partition of K C\(Z   K l  l=1tos   using a ponderation of centers calculus by the cardinality of each group i.e the number of keys of each group Thus a new fragmentation relative to Z s obtained by  H\(Z C\(Z    Z W G\(Z W  where 200 W 005 C\(Z 200 G\(Z,W  c i,W i 005 Z W 005 C\(Z and c i,W  002 004 U 002 W/U 002 C 003  Z  C i,U 003 card  U  card  W   where C\220\(Z is the partition of X obtained by the crossing phase i.e c i,W  average of c i,U ponderated by group cardinality of U for the sets U resulting of the crossing phase The initial phase is a particular case of this one where the pound of each value is equal to 1 r example see Table 6 c 2 W 003 220 c 2 U 003 1 c 2 U 216 1 c 2 U 216 003 2 e  Results C\(Z at the end of the optimizing merging phase on C\220\(Z Z X 004 Y  A 1 A 2 A 5 A 6 A 8 A 9  keys G W  K 5  G\(Z,W K 7  c 1 W c 2 W c 5 W c 6 W c 8 W c 9 W  C\(Z K 18  W\220  K 22 G\(Z,W\220 K 24 c 1 W 003 c 2 W 003 c 5 W 003 c 6 W 003 c 8 W 003 c 9 W 003  K 31 K 32  3.6 Iterative criterion The method crossing and merging optimizing phases is iterated associating successive couples of attribute groups X and Y until considering the whole set f attributes A Order used for the association during the crossing phase offers distincts versions see Section 4.3 using availability of C  X i  results As the number of clusters n each attribute should be limited for each addition of attributes using optimizing merging phase costly agglomerative method could be used as well as KMeans inspired methods see Section 5.2 for comparison between the two kinds of methods 4 Parallelism 4.1 Grid speci\223ties The method is iterated by agglomerating clustering results unidimensional or multidimensional see Section 4.2 Crossing and optimizing merging steps could be used between distributed H  X i C  X i  according to initial C  X  fragmentation of the database see Section 4.3 4.2 Macro-Iterative vision In order to test the impact of distributed executions on the results we decided to compare two cases 1 Every vertical partition contains a single attribute unidimensionnal initial clustering 2 Every vertical partition contains number of attributes  1 multidimensionnal initial clustering The multidimensional clustering can be computed on each node computing all attributes of this node instead of computing unidimensional clustering on each attribute on the node This multidimensional consideration for the initial step will be called macro iterative vision in the results presented in next section Proceedings of the 4th International Symposium on Parallel and Distributed Computing \(ISPDC\22205 0-7695-2434-6/05 $20.00 \251 2005  IEEE 


 X1 H X1 U X2 U X3 U X4 X5 U X6 U X7 U X8 X1 U X2 X3 U X4 X5 U X6 HH H H HHHHHHHH X2 X3 X4 X5 X6 X7 X8 X7 U X8 H H D clustering results for D XiXi H D = {i} i = 1 ... nA Figure 1 Binary Incremental Progressif Cross scenario 4.3 Incremental scenarii Several versions have been compared for the incremental scenario to insert clustering results to test association order of attributes impact on results as well as the impacts of association of unidimensional or progressive clustering results In Figures 1 and 2 H Xi represents clustering results unidimensional or multidimensional see Section 4.2 from KMeans or agglomerative method H X i 004 X j  H X i 004 X j 004 X k and others are intermediary progressive clustering results that are considered as multidimensional results from the introduced incremental method Thus Figure 1 presents a binary tree cross scenario f associating clustering results and Figure 2 presents a desynchronized cross scenario dealing with clustering results one at a time The second scenario desynchronized cross is oriented owards a crossing as soon as available from asynchronous execution on Grid Testing those two scenarii allows to assure that the order used to associate see Sections 3.4 distributed initial step results depending on execution on the Grid before optimizing merging step and Macro-Iterative improvements to exploit distribution on the Grid see Section 4.2 yield to same results 4.4 Parallelism and communications Parallel clusterings are computed on attributes of the database according to an initial fragmentation of the multibase and clustering results are stored to be used later in association rules problem Those clustering results of the initial clustering phase appear as global information on attribute independently from others that will allow to optimize local parallel computations of association rules algorithms and that represent an important source of knowledge During the fragmentation step by progressive parallel clustering data are not communicated between nodes    X1 HHHHHHHH X2 X3 X4 X5 X6 X7 X8 H X1 U X2 H clustering results for D Xi Xi H D = {i} i = 1 ... nA D H H X1 U X2  U X3 X1 U X2  U X3 U X4 U X5 U X6 U X7 Figure 2 Desynchronized Incremental Progressif Cross scenario of the grid since the method works only on previous clustering results Then communications are composed of H\(X C\(X see Section 3 that must be treaten by progressive clustering crossing scenario see Figures 1 and 2 Communications are limited according to the crossing scenario used Considering each H\(X C\(X see Figures 1 and 2 stored on a particular node of the grid the number of communications for binary crossing is p-1 for inital phase resulting in  H  X i C  X i  i 1 p   For example see Figure 1 H X 1 004 X 2 is computed on the node storing H X 1  thus H X 2 is sent to this node H X 3 004 X 4 is computed on the node storing H X 3  thus H X 4 is communicated o this node H X 1 004 X 2 004 X 3 004 X 4 is computed on the node storing H X 1 004 X 2  thus H X 3 004 X 4 is communicated to this node  The number of communications for desynchronized crossing is p-1 for i=1...p r example see Figure 2 H X 1 004 X 2 is computed on the node storing H X 1  thus H X 2 is communicated to this node H X 1 004 X 2 004 X 3 is computed on the node storing H X 1 004 X 2  thus H X 3 is communicated to this node  The number of communications is identical for binary and desynchronized methods After this fragmentation step progressive parallel clustering real data are not used association rules are computed on discretized data from results of clustering of attributes Global information is communicated to computing nodes to optimize those t those communications could take place during the progressive parallel clustering since global information is computed at the beginning of the progressive parallel clustering by the initial clustering step Discretized data are communicated to computings nodes according to progressive parallel clustering results Proceedings of the 4th International Symposium on Parallel and Distributed Computing \(ISPDC\22205 0-7695-2434-6/05 $20.00 \251 2005  IEEE 


5 Experiments and results Experiments for progressive clustering were realized r synthetized data from 2 o 5 dimensions Data were synthetized in such a way to assure that groups exist using random centers values and variances to create groups of data According to the complexity of the agglomerative method the number of data rows was limited to 1000 Distinct scenarii were implemented and tested Results for those scenarii were compared with clusters in initial data as data were synthetized in a way that clusters exist information on those 216initial\216 clusters is known and with global multidimensional KMeans clustering method and global multidimensional Agglomerative method Presented results are means r 0 tests on 25-dimensional data results r dimensional data with less than 25 dimensions are similar 5.1 Combination principles used Clustering methods appear at two tages of the progressive clustering method as initial clustering r individual attributes see Section 3.3 and as crossing clustering to compute candidate clusters see Section 3.5 r those two stages KMeans method as well as Agglomerative method can be considered Thus tests will consider combinations of two Initial Clustering C unidimensional KMeans or unidimensional agglomerative clustering crossing phase C KMeans 216cross\216 principle merging step r agglomerative 216cross\216 principle MA et MK represent respectively multidimensional agglomerative and multidensionnal KMeans clustering We use the following notation WXYZ represent progressive clustering versions with 200 W granularity of initial clustering 1 for undimensionnal or n 005 1 m  for the macro-iterative rsion 200 X algorithm for unidimensional clustering A  agglomerative K  KMeans 200 Y algorithm for optmizing merging clustering A or K 200 Z scenario for incremental Cross B binary see Figure 1 r  desynchronized one-by-one see Figure 2 5.2 Results Generated clusters Quality of results is appreciated by the comparison of clusters generated by progressive clustering with initial groups in data as referential Referential groups are identi\223ed by multidimensional agglomerative as well as multidimensional KMeans clustering Comparison of results consists in a veri\223cation that instances repartition is the same between the two ets f clusters 200 Progressive clustering scenarii with agglomerative clustering for initial step classical or macro-iterative initial clustering AY nAY produce clusters that represent a mix of initial groups 1AA scenarii produce the worst results from mix considerations Progressive clustering scenarii with agglomerative clustering for cross step 1KA nKA e until a principal cluster including almost all the instances and 216unitary\216 cluster with a ew instances 200 Progressive clustering scenarii from KMeans initial step 1KY and nKY produce clusters similar to initial groups with some agglomeration of neighboor groups 10 of existing groups don\220t appear as independent resulting group t are included to a neighbour group Instead generated clusters could be considered similar to real clusters and those incremental scenarii could be considered as good heuristical methods taking into account distribution possibilities r this method 5.3 Time considerations Tests allow o con\223rm that scenarii integrating agglomerative method for initial clustering step as well as crossing step are the most expensive for time considerations and thus could not be usable for huge amount of data especially for the undimensional clustering step As those versions do not produce right clusters time\220s consideration for those methods are not n t A multidimensionnal version has computation time 3340 time greater than MK version and AA versions have computation time from 6700 to 13500 time greater than MK Figure 3 represents computation times for KMeans based versions of progressive clustering MK 1KY et nKY 1KY versions have computation\220s time 15 time greater than a K multidimensional clustering t ffer high parallelisation capabilities nKY versions have computation\220s time 6 time greater than a K multidimensional clustering t also offer high parallelisation capabilities Then macro iterative scenarii appear to give good results according to produced clusters what is the most important t also according to the computation time n including overcost of a necessary unidimensional clustering to get useful information see Section 3.5 black zones on Figure 3 with parallelisation capabilities at several steps multidimensional initial step as well as unidimensional if needed crossing Those nKK versions hold attention for futur works Proceedings of the 4th International Symposium on Parallel and Distributed Computing \(ISPDC\22205 0-7695-2434-6/05 $20.00 \251 2005  IEEE 


Figure 3 Computation time comparison r KMeans inspired scenarii 5.4 Balance sheets Table 7 presents balance from clustering methods Agglomerative or KMeans at the two stages of the progressive clustering initial clustering see Section 3.3 and merging clustering see Section 3.5 Versions including agglomerative clustering brings to wrong results despite agglomerative is an exact method and these have unappropriated time computations Particularly using agglomerative methods at the two stages of progressive algorithm initial and merging phase furnishes the worst results according to time consuming and quality a single group is obtained what could be put in parallel with Agrawal\220s works see This could be explained by the fact that an exact method is not appropriated to this iterative process and it con\223rms that combination of heuristic algorithms could produce best results than combination of exact methods allowing a real decrease of computation times as well as obtaining good results e  balance from using Agglomerative or KMeans clustering  Merging clustering Agglomerative KMeans Initial Clustering Speed Results Speed Results Agglomerative false false single group KMeans  false  right Table 8 presents balance r progressive clustering and classical multidimensional clustering The progressive method presented in this paper appears to bring gain from parallelisation without any synchronization and to keep quality of results KMeans clustering progressive versions offers many parallelisation possibilities that could bring to exploit available computing resources Table 8 balance over progressive and classicial clusterings Version Sequential Speed Quality Possible of clusters parallelisation MA  0 MK   0 1KKZ    nKKZ    6 Conclusions and perspectives 6.1 Conclusions Progressive results provide a good solution to distribute database fragments on a grid in an 216intelligent\216 way The method offers quality f resulting clusters as well as speed-up from parallel and distributed computing It will also brings a decrease of complexity and gain from parallelism for the association rules problem It could then be used as an heuristic of parallel clustering that provides good results with regard to gain from parallelism The progressive clustering then appears as an reasonable distributed solution to solve clustering in a distributed environment since distributed algorithms of clustering no longer exist The incremental way binary tree or individual based see Section 4.3 from which the clustering is done appears to have not a great in\224uence on results since those results are similar for each way for a same algorithm for unidimensional clustering and crossing t could be used to take advantages of distributed computing speci\223cities and from the initial repartition of the multibase Then the Progressive Clustering could take place as a distribution step in the problem of association rules research instead of using a centralized clustering step as done in previous works see that v alidate the theory of a decrease of complexity by intelligent distribution 6.2 s As the problem of progressive clustering has appeared to solve a problem of an intelligent fragmentation of database for the association rules problem the next step of this work consists in incorporating this method in the general Proceedings of the 4th International Symposium on Parallel and Distributed Computing \(ISPDC\22205 0-7695-2434-6/05 $20.00 \251 2005  IEEE 


DisDaMin schema Then distributed considerations for incremental way will be inspired from the initial repartition of the multibase and global pipeline considerations will be introduced in relation with those incremental ways References  R Agra w al J Gehrk e D Gunopulos and P  Raghavan Automatic subspace clustering of high dimensional data for data mining application In Proc of the ACM Conf n Management of Data  1998 pp.94-105  V  Fiolet and B T oursel Distrib uted Data Mining Proc of the ISPDC\22002 July 2002 pp 349-365  V  Fiolet and B T oursel Intelligent Database distribution on a Grid using Clustering In Lectures Notes In Computer Sciences Proc of AWIC 2005  SpringerVerlag June 2005  E F o r g y  Cluster analysis of multi v ariate data Ef 223ciency vs interpretability of classi\223cations In Biometrics  1965 21:768  G F orman and B Zhang Distrib uted data clustering can be ef\223cient and exact In SIGKDD explorations 2 2000  E Johnson and H Kar gupta Collecti v e  hierarchical clustering from distributed heterogenous data In Lecture Notes in Computer Science  1759 pp 221-244 Springer-Verlag 1999  J McQueen Some methods for classi\223cation and analysis of multivariate observations In Proc of the Fifth Berkeley Symposium on Mathematical Statistics and Probability  p  281-297 1967  N F  Samato v a  G  Ostroucho v  A Geist and A  Melenchko Rachet An ef\223cient covering based merging of clustering hierarchies from distributed datasets In International Journal of Distributed and rallel Databases  11\(2 pp 157-180 2002  R Sokal and P  Sneath Numerical T axonomy  Freeman San Francisco 1963 Proceedings of the 4th International Symposium on Parallel and Distributed Computing \(ISPDC\22205 0-7695-2434-6/05 $20.00 \251 2005  IEEE 


4J H. Fu and E. Mephu Nguifo. Partitioning large data to scale up lattice-based algorithm. In Proceedings ofICTAI03 pages S37-S41, Sacramento, CA, November 20 03. IEEE Press SJ H. Fu and E. Mephu Nguifo. How well go lattice algo  rithms on currently used machine learning testbeds? In 4emes journees d' Extraction et de Gestion des Connais  sances, pages 373-384, France, 20 04 61 B. Ganter and R. Wille. Formal Concept Analysis. Mathe  matical Foundations. Springer, 1999 7J J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In W. Chen, J. Naughton, and P. A Bernstein, editors, 2000 ACM SIGMOD Intl. Conference on Management of Data, pages 1-12. ACM Press, OS 2000 Data file Objects Items Min support FCI PFC \(msec msec audiology 26 110 1 30401 1302 8563 soybean-small 47 79 1 3541 516 431 lung-cancer 32 228 1 186092 21381 279689 promoters 106 228 3 298772 120426 111421 soybean-large 307 133 1 806030 357408 364524 dermatogogy 366 130 50 192203 20204 18387 breast-cancer-wis 699 110 1 9860 3529 1131 kr-vs-kp 3196 75 1100 2770846 1823092 483896 agaricus-Iepiota 8124 124 100 38347 34815 1462 connect-4bi.data 67557 126 1000 2447136 1165806 65084 Table 1. Experiments on real data.\(FCI means frequent closed itemsets. msec means milliseconds For Ref., + means PFC is faster than CLOSET Data file Min support FCI PFC \(msec msec Worst16 1 65534 571 470 271 9 Worst17 1 131070 1112 1002 541 9 Worst18 1 262142 2243 2174 1091 9 Worst19 1 524286 4576 4466 2213 10 Worst20 1 1048574 9243 9484 4606 10 Worst25 20 68405 2103 66916 451 11 Worst25 19 245505 6099 1095065 1552 11 Worst25 18 726205 15452 10235287 4486 11 Worst25 17 1807780 33348 / 10755 11 Worst25 15 7119515 102237 / 39296 11 Worst30 25 174436 6980 426964 1302 12 Worst30 20 53009101 1029771 / 344035 12 Worst50 47 20875 1132 1042 422 14 Worst50 45 2369935 227207 / 29102 14 Worst60 57 36050 7320 3205 821 15 Worst60 56 523685 82938 1665715 9123 15 Worst60 55 5985197 772210 / 92102 15 Worst70 68 2485 1102 190 121 15 Worst70 67 57225 18096 9483 1933 15 Worst70 66 974120 242138 / 26398 15 Table 2. Experiments on the worst case data 8] S. Kuznetsov and S. Obiedkov. Comparing performance of algorithms for generating concept lattices. lETAI Special Issue on Concept Lattice for KDD, 14\(2/3 9j E. Mephu Nguifo, M. Liquiere, and V. Duquenne. lETA Special Issue on Concept Lattice for KDD. Taylor and Fran  cis, 2002 IOj N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal. Efficient mining of association rules using closed itemsets lattices lournal of Information Systems, 24\(1 II j 1. Pei, 1. Han, and R. Mao. CLOSET: An efficient algo  rithm for mining frequent closed itemsets. InACM SIGMOD Workshop on Research Issues in Data Mining and Knowl  edge Discovery, pages 21-3 0, 200 0 12] 1. Wang, 1. Han, and 1. Pei. Closet+: Searching for the best strategies for mining frequent closed itelnsets. In In Pro  ceedings of the Ninth ACM SIGKDD International Confer  ence on Knowledge Discovery and Data Mining \(KDD'03 Washington, DC, USA, 2003 13] M. I. Zaki and C.-I. Hsiao. CHARM: An efficient algorithm for closed item set mining. Technical Report 99-10, Rensse  laer Polytechnic Institute, 1999 


laer Polytechnic Institute, 1999 pre></body></html 


efficiency then AOFI. However utilization of fuzzy concept hierarchies provides more flexibility in reflecting expert knowledge and so allows better modeling of real-life dependencies among attribute values, which will lead to more satisfactory overall results for the induction process. The drawback of the computational cost may additionally decline when we notice that, in contrast to many other data mining algorithms, hierarchical induction algorithms need to run only once through the original \(i.e. massive dataset. We are continuing an investigation of computational costs of our approach for large datasets ACKNOWLEDGMENT Rafal Angryk would like to thank the Montana NASA EPSCoR Grant Consortium for sponsoring this research REFERENCES 1] J. Han , M. Kamber, Data Mining: Concepts and Techniques, Morgan Kaufmann, New York, NY 2000 2] J. Han, Y. Cai, and N. Cercone  Knowledge discovery in databases: An attribute-oriented approach  Proc. 18th Int. Conf. Ver y Large Data Bases, Vancouver, Canada, 1992, pp. 547-559 3] J. Han  Towards Efficient Induction Mechanisms in Database Systems  Theoretical Computing Science, 133, 1994, pp. 361-385 4] J. Han, Y. Fu  Discovery of Multiple-Level Association Rules from Large Databases  IEEE Trans.  on KD E, 11\(5 5] C.L. Carter, H.J. Hamilton  Efficient AttributeOriented Generalization for Knowledge Discovery from Large Databases  IEEE Trans. on KDE 10\(2 6] R.J. Hilderman, H.J. Hamilton, and N. Cercone  Data mining in large databases using domain generalization graphs  Journal of Intelligent Information Systems, 13\(3 7] C.-C. Hsu  Extending attribute-oriented induction algorithm for major values and numeric values   Expert Systems with Applications , 27, 2004, pp 187-202 8] D.H. Lee, M.H. Kim  Database summarization using fuzzy ISA hierarchies  IEEE Trans . on SMC - part B, 27\(1 9] K.-M. Lee  Mining generalized fuzzy quantitative association rules with fuzzy generalization hierarchies  20th NAFIPS Int'l Conf., Vancouver Canada, 2001, pp. 2977-2982 10] J. C. Cubero, J.M. Medina, O. Pons &amp; M.A. Vila  Data Summarization in Relational Databases through  Fuzzy Dependencies  Information Sciences, 121\(3-4 11] G. Raschia, N. Mouaddib  SAINTETIQ:a fuzzy set-based approach to database summarization   Fuzzy Sets and Systems, 129\(2 162 12] R. Angryk, F. Petry  Consistent fuzzy concept hierarchies for attribute generalization  Proceeding of the IASTED Int. Conf. on Information and Knowledge Sharing, Scottsdale AZ, USA, November 2003, pp. 158-163 13] Toxics Release Inventory \(TRI available EPA database hosted at http://www.epa.gov/tri/tridata/tri01/index.htm The 2005 IEEE International Conference on Fuzzy Systems790 pre></body></html 


the initial global candidate set would be similar to the set of global MFIs. As a result, during the global mining phase the communication and synchronization overhead is low  0 2 4 6 8 1 0 Number of Nodes Figure 5. Speedup of DMM 4.4.2 Sizeup For the sizeup test, we fixed the system to the 8-node con figuration, and distributed each database listed in Table 2 to the 8 nodes. Then, we increased the local database sire at each node from 45 MB to 215 MB by duplicating the initial database partition allocated to the node. Thus, the data distribution characteristics remained the same as the local database size was increased. This is different from the speedup test, where the database repartitioning was per formed when the number of nodes was increased. The per formance of DMM is affected by the database repartitioning to some extent, although it is usually very small. During the sizeup test, the local mining result of DMM is not changed at all at each node The results shown in Figure 6 indicate that DMM has a very good sizeup property. Since increasing the size of local database did not affect the local mining result of DMM at each node, the total execution time increased just due to more disk U 0  and computation cost which scaled almost linearly with sizeup 5 Conclusions In this paper, we proposed a new parallel maximal fre quent itemset \(MFI Max-Miner \(DMM tems. DMM is a parallel version of Max-Miner, and it re quires low synchronization and communication overhead compared to other parallel algorithms. In DMM, Max Miner is applied on each database partition during the lo 0 45 90 135 180 225 270 Amwnt of Data per Node \(ME Figure 6. Sizeup of DMM cal mining phase. Only one synchronization is needed at thc end of this phase to construct thc initial global candi date set. In the global mining phase, a top-down search is performed on the candidate set, and a prefix tree is used to count the candidates with different length efficiently. Usu ally, just a few passes are needed to find all global maximal frequent itemsets. Thus, DMM largely reduces the number of synchronizations required between processing nodes Compared with Count Distribution, DMM shows a great improvement when some frequent itemscts are large \(i.e long patterns employed by DMM for efficient communication between nodes; and global support estimation, subset-infrequency based pruning, and superset-frequency based pruning are used to reduce the size of global candidate set. DMM has very good speedup and sizeup properties References I ]  R. Agrawal and R. Srikant  FdSt Algorithms for Mining As sociation Rules  Pmc. o f f h e  ZOrh VLDB Conf, 1994, pp 487499 2] R. Agrawal and I. C. Shafer  Parallel Mining of Association Rules  IEEE Trans. on Knowledge and Dura Engineering Vol. 8, No. 6, 1996, pp. 962-969 3] R. I. Bayardo  Efficient Mining Long Patlems from Databases  Proc. ofrhe ACM SIGMOD Inf  l Conf on Man ogemenr ofDara, 1998, pp. 85-91 4] S.  M. Chung and J. Yang  A Parallel Distributive Join Al gorithm for Cube-Connected Multiprocessors  IEEE Trans on Parallel and Disrribured Systems, Vol. 7, No. 2, 1996, pp 127-137 51 M. Snir, S. Otto. S. Huss-Lederman, D. Walker, and J. Don gana, MPI: The Complete Reference, The MIT Press, 1996 


gana, MPI: The Complete Reference, The MIT Press, 1996 6] R. Rymon  Search through Systematic Set Enumeralion   Pmc. of3rd Inr  l Con$ on Principles of Knowledge Repre sentation and Reasoning, 1992, pp. 539-550 507 pre></body></html 


sketch-index in answering aggregate queries. Then Section 5.2 studies the effect of approximating spatiotemporal data, while Section 5.3 presents preliminary results for mining association rules 5.1 Performance of sketch-indexes Due to the lack of real spatio-temporal datasets we generate synthetic data in a way similar to [SJLL00 TPS03] aiming at simulation of air traffic. We first adopt a real spatial dataset [Tiger] that contains 10k 2D points representing locations in the Long Beach county \(the data space is normalized to unit length on each dimension These points serve as the  airbases  At the initial timestamp 0, we generate 100k air planes, such that each plane \(i uniformly generated in [200,300], \(ii, iii destination that are two random different airbases, and iv  the velocity direction is determined by the orientation of the line segment connecting its source and destination airbases move continually according to their velocities. Once a plane reaches its destination, it flies towards another randomly selected also uniform in [0.02, 0.04 reports to its nearest airbase, or specifically, the database consists of tuples in the form &lt;time t, airbase b, plane p passenger # a&gt;, specifying that plane p with a passengers is closest to base b at time t A spatio-temporal count/sum query has two parameters the length qrlen of its query \(square number qtlen of timestamps covered by its interval. The actual extent of the window \(interval uniformly in the data space \(history, i.e., timestamps 0,100 air planes that report to airbases in qr during qt, while a sum query returns the sum of these planes  passengers. A workload consists of 100 queries with the same parameters qrlen and qtlen The disk page size is set to 1k in all cases \(the relatively small page size simulates situations where the database is much more voluminous specialized method for distinct spatio-temporal aggregation, we compare the sketch-index to the following relational approach that can be implemented in a DBMS. Specifically, we index the 4-tuple table lt;t,b,p,a&gt; using a B-tree on the time t column. Given a count query \(with window qr and interval qt SELECT distinct p FROM &lt;t,b,p,a&gt WHERE t?qt &amp; b contained in qr The performance of each method is measured as the average number of page accesses \(per query processing a workload. For the sketch-index, we also report the average \(relative Specifically, let acti and esti be the actual and estimated results of the i-th query in the workload; then the error equals \(1/100 set the number of bits in each sketch to 24, and vary the number of sketches The first experiment evaluates the space consumption Figure 5.1 shows the sketch index size as a function of the number of sketches used \(count- and sum-indexes have the same results more sketches are included, but is usually considerably smaller than the database size \(e.g., for 16 signatures, the size is only 40% the database size 0 20 40 60 80 


80 100 120 140 160 8 16 32 number of sketches size \(mega bytes database size Figure 5.1: Size comparison Next we demonstrate the superiority of the proposed sketch-pruning query algorithm, with respect to the na  ve one that applies only spatio-temporal predicates. Figure 5.2a illustrates the costs of both algorithms for countworkloads with qtlen=10 and various qrlen \(the index used in this case has 16 sketches also illustrate the performance of the relational method which, however, is clearly incomparable \(for qrlen?0.1, it is worse by an order of magnitude we omit this technique Sketch-pruning always outperforms na  ve \(e.g., eventually two times faster for qrlen=0.25 increases with qrlen, since queries returning larger results tend to set bits in the result sketch more quickly, thus enhancing the power of Heuristics 3.1 and 3.2. In Figure 5.2b, we compare the two methods by fixing qrlen to 0.15 and varying qtlen. Similar to the findings of [PTKZ02]4 both algorithms demonstrate  step-wise  growths in their costs, while sketch-pruning is again significantly faster The experiments with sum-workloads lead to the same observations, and therefore we evaluate sketch-indexes using sketch-pruning in the rest of the experiments 4 As explained in [PTKZ02], query processing accesses at most two paths from the root to the leaf level of each B-tree regardless the length of the query interval Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE sketch-pruning naive relational 0 100 200 300 400 500 600 700 800 900 0.05 0.1 0.15 0.2 0.25 number of disk accesses query rectangle length 300 0 100 200 400 500 600 1 5 10 15 20 number of disk accesses query interval length a qtlen=10 b qrlen=0.15 Figure 5.2: Superiority of sketch-pruning \(count As discussed in Section 2, a large number of sketches reduces the variance in the resulting estimate. To verify this, Figure 5.3a plots the count-workload error of indexes 


using 8-, 16-, and 32- sketches, as a function of qrlen qtlen=10 error \(below 10 it increases slowly with qrlen used, however, the error rate is much higher \(up to 30 and has serious fluctuation, indicating the prediction is not robust. The performance of 16-sketch is in between these two extremes, or specifically, its accuracy is reasonably high \(average error around 15 much less fluctuation than 8-sketch 32-sketch 16-sketch 8-sketch relative error 0 5 10 15 20 25 30 35 0.05 0.1 0.15 0.2 0.25 query rectangle length relative error 0 5 10 15 20 25 30 35 1 5 10 15 20 query interval length a qtlen=10, count b qrlen=0.15, count relative error query rectangle length 0 5 10 15 20 25 0.05 0.1 0.15 0.2 0.25 relative error query interval length 0 5 10 15 20 25 30 1 5 10 15 20 c qtlen=10, sum d qrlen=0.15, sum Figure 5.3: Accuracy of the approximate results The same phenomena are confirmed in Figures 5.3b where we fix qrlen to 0.15 and vary qtlen 5.3d \(results for sum-workloads number of sketches improves the estimation accuracy, it also leads to higher space requirements \(as shown in Figure 5.1 Figures 5.4a and 5.4b show the number of disk accesses for the settings of Figures 5.3a and 5.3b. All indexes have almost the same behavior, while the 32-sketch is clearly more expensive than the other two indexes. The interesting observation is that 8- and 16-sketches have 


interesting observation is that 8- and 16-sketches have almost the same overhead due to the similar heights of their B-trees. Since the diagrams for sum-workloads illustrate \(almost avoid redundancy 32-sketch 16-sketch 8-sketch number of disk accesses query rectangle length 0 50 100 150 200 250 300 350 400 0.05 0.1 0.15 0.2 0.25 number of disk accesses query interval length 0 50 100 150 200 250 300 350 1 5 10 15 20 a qtlen=10 b qrlen=0.15 Figure 5.4: Costs of indexes with various signatures Summary: The sketch index constitutes an effective method for approximate spatio-temporal \(distinct aggregate processing. Particularly, the best tradeoff between space, query time, and estimation accuracy obtained by 16 sketches, which leads to size around 40 the database, fast response time \(an order of magnitude faster than the relational method average relative error 5.2 Approximating spatio-temporal data We proceed to study the efficiency of using sketches to approximate spatio-temporal data \(proposed in Section 4.1 as in the last section, except that at each timestamp all airplanes report their locations to a central server \(instead of their respective nearest bases maintains a table in the form &lt;time t, plane p, x, y&gt;, where x,y with parameters qrlen and qtlen distinct planes satisfying the spatial and temporal conditions. For comparison, we index the table using a 3D R*-tree on the columns time, x, and y. Given a query, this tree facilitates the retrieval of all qualifying tuples, after which a post-processing step is performed to obtain the Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE number of distinct planes \(in the sequel, we refer to this method as 3DR method introduces a regular res  res grid of the data space, where the resolution res is a parameter. We adopt 16 sketches because, as mentioned earlier, this number gives the best overall performance Figure 5.5 compares the sizes of the resulting sketch indexes \(obtained with resolutions res=25, 50, 100 the database size. In all cases, we achieve high compression rate \(e.g., the rate is 25% for res=25 evaluate the query efficiency, we first set the resolution to the median value 50, and use the sketch index to answer workloads with various qrlen \(qtlen=10 


workloads with various qrlen \(qtlen=10 size \(mega bytes database size 0 20 40 60 80 100 120 140 160 25 50 100 resolution Figure 5.5: Size reduction Figure 5.6a shows the query costs \(together with the error in each case method. The sketch index is faster than 3DR by an order of magnitude \(note that the vertical axis is in logarithmic scale around 15% error observations using workloads with different qtlen Finally, we examine the effect of resolution res using a workload with qrlen=0.15 and qtlen=10. As shown in Figure 5.6c, larger res incurs higher query overhead, but improves the estimation accuracy Summary: The proposed sketch method can be used to efficiently approximate spatio-temporal data for aggregate processing. It consumes significantly smaller space, and answers a query almost in real-time with low error 3D Rsketch number of disk accesses query rectangle length 1 10 100 1k 10k 0.05 0.1 0.15 0.2 0.25 16 14% 15 15% 13 relative error number of disk accesses query interval length 1 10 100 1k 10k 1 5 10 15 20 16 15% 15% 12% 11 relative error a qtlen=10, res=25 b qrlen=0.15, res=25 0 500 1000 1500 2000 2500 25 50 100 number of disk accesses resolution 20% 15% 14 relative error c qrlen=0.15, qtlen=10 


c qrlen=0.15, qtlen=10 Figure 5.6: Query efficiency \(costs and error 5.3 Mining association rules To evaluate the proposed algorithm for mining spatiotemporal association rules, we first artificially formulate 1000 association rules in the form \(r1,T,90 with 90% confidence i randomly picked from 10k ones, \(ii in at most one rule, and \(iii Then, at each of the following 100 timestamps, we assign 100k objects to the 10k regions following these rules. We execute our algorithms \(using 16 sketches these rules, and measure \(i  correct  rules divided by the total number of discovered rules, and \(ii successfully mined Figures 5.7a and 5.7b illustrate the precision and recall as a function of T respectively. Our algorithm has good precision \(close to 90 majority of the rules discovered are correct. The recall however, is relatively low for short T, but gradually increases \(90% for T=25 evaluated in the previous sections, the estimation error decreases as the query result becomes larger \(i.e., the case for higher T 78 80 82 84 86 88 90 92 94 96 5 10 2015 25 precision HT 78 80 82 84 86 88 90 92 94 96 5 10 2015 25 recall HT a b Figure 5.7: Efficiency of the mining algorithm Summary: The preliminary results justify the usefulness of our mining algorithm, whose efficiency improves as T increases Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE 6. Conclusions While efficient aggregation is the objective of most spatio-temporal applications in practice, the existing solutions either incur prohibitive space consumption and query time, or are not able to return useful aggregate results due to the distinct counting problem. In this paper we propose the sketch index that integrates traditional approximate counting techniques with spatio-temporal indexes. Sketch indexes use a highly optimized query algorithm resulting in both smaller database size and faster query time. Our experiments show that while a sketch index consumes only a fraction of the space required for a conventional database, it can process 


required for a conventional database, it can process queries an order of magnitude faster with average relative error less than 15 While we chose to use FM sketches, our methodology can leverage any sketches allowing union operations Comparing the efficiency of different sketches constitutes a direction for future work, as well as further investigation of more sophisticated algorithms for mining association rules. For example, heuristics similar to those used for searching sketch indexes may be applied to improve the brute-force implementation ACKNOWLEDGEMENTS Yufei Tao and Dimitris Papadias were supported by grant HKUST 6197/02E from Hong Kong RGC. George Kollios, Jeffrey Considine and were Feifei Li supported by NSF CAREER IIS-0133825 and NSF IIS-0308213 grants References BKSS90] Beckmann, N., Kriegel, H., Schneider, R Seeger, B. The R*-tree: An Efficient and Robust Access Method for Points and Rectangles. SIGMOD, 1990 CDD+01] Chaudhuri, S., Das, G., Datar, M., Motwani R., Narasayya, V. Overcoming Limitations of Sampling for Aggregation Queries. ICDE 2001 CLKB04] Jeffrey Considine, Feifei Li, George Kollios John Byers. Approximate aggregation techniques for sensor databases. ICDE, 2004 CR94] Chen, C., Roussopoulos, N. Adaptive Selectivity Estimation Using Query Feedback. SIGMOD, 1994 FM85] Flajolet, P., Martin, G. Probabilistic Counting Algorithms for Data Base Applications JCSS, 32\(2 G84] Guttman, A. R-Trees: A Dynamic Index Structure for Spatial Searching. SIGMOD 1984 GAA03] Govindarajan, S., Agarwal, P., Arge, L. CRBTree: An Efficient Indexing Scheme for Range Aggregate Queries. ICDT, 2003 GGR03] Ganguly, S., Garofalakis, M., Rastogi, R Processing Set Expressions Over Continuous Update Streams. SIGMOD, 2003 HHW97] Hellerstein, J., Haas, P., Wang, H. Online Aggregation. SIGMOD, 1997 JL99] Jurgens, M., Lenz, H. PISA: Performance Models for Index Structures with and without Aggregated Data. SSDBM, 1999 LM01] Lazaridis, I., Mehrotra, S. Progressive Approximate Aggregate Queries with a Multi-Resolution Tree Structure. SIGMOD 2001 PGF02] Palmer, C., Gibbons, P., Faloutsos, C. ANF A Fast and Scalable Tool for Data Mining in Massive Graphs. SIGKDD, 2002 PKZT01] Papadias,  D., Kalnis, P.,  Zhang, J., Tao, Y Efficient OLAP Operations in Spatial Data Warehouses. SSTD, 2001 PTKZ02] Papadias, D., Tao, Y., Kalnis, P., Zhang, J Indexing Spatio-Temporal Data Warehouses ICDE, 2002 SJLL00] Saltenis, S., Jensen, C., Leutenegger, S Lopez, M.A. Indexing the Positions of Continuously Moving Objects. SIGMOD 2000 SRF87] Sellis, T., Roussopoulos, N., Faloutsos, C The R+-tree: A Dynamic Index for MultiDimensional Objects. VLDB, 1987 TGIK02] Thaper, N., Guha, S., Indyk, P., Koudas, N Dynamic Multidimensional Histograms 


SIGMOD, 2002 Tiger] www.census.gov/geo/www/tiger TPS03] Tao, Y., Papadias, D., Sun, J. The TPR*Tree: An Optimized Spatio-Temporal Access Method for Predictive Queries. VLDB, 2003 TPZ02] Tao, Y., Papadias, D., Zhang, J. Aggregate Processing of Planar Points. EDBT, 2002 TSP03] Tao, Y., Sun, J., Papadias, D. Analysis of Predictive Spatio-Temporal Queries. TODS 28\(4 ZMT+01] Zhang, D., Markowetz, A., Tsotras, V Gunopulos, D., Seeger, B. Efficient Computation of Temporal Aggregates with Range Predicates. PODS, 2001 ZTG02] Zhang, D., Tsotras, V., Gunopulos, D Efficient Aggregation over Objects with Extent PODS, 2002 Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE pre></body></html 



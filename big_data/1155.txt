A Random Walk through Human Associations Raz Tamir The Hebrew University of Jerusalem raz.tamir@gmail.com Abstract Letting one's thoughts wander is not simply an arbitrary or rambling process. It can better be described as associative thinking", where a complex chain of associative thoughts and ideas are linked. It is our contention that this seemingly chaotic process can be modeled by a random walk in a weighted directed graph Furthermore, is it possible to predict mathematically the steady state" of such a process, to determine where such wandering is leading The random walk process uses rules of association defined by the Local Confidence Gain \(LCG 
interestingness measure. Extracted concepts are used as nodes of a directed graph. The associative "forces" between any two concepts \(measured by LCG\sed to weigh the edges connecting the nodes that create a graph of associations It is common, yet not trivial, for people to look for data about a subject without knowing its exact nomenclature for example, finding the name of a disease just by knowing its symptoms\Random walk in association graphs can discover highly informative phrases that can be used for query expansion in a way that better expresses the user's initial search goals. A different usage is to create a user profile representing his current interests 
We used a modified version of the Turing Test to show that the random walk process discovers association rules that conform to a human associations generating process By constructing the user associations we were able to build a profile representing the user's "line of thoughts". The suggested algorithm can be used in any database and can implement the ranking measures of other association rules 1 Introduction This chapter presents the keystones of the random walk based algorithm. Section 1.1 discusses the role of associations in the cognitive processes that deal with information retrieval from memory. Section 1.2 and 1.3 
discuss the random walk basics and its convergence criteria. In section 1.4 we present the Confidence Gain CG\ association interestingness measure and in section 1.5 we present the Local Confidence Gain \(LCG\measure which is a low complexity version of the Confidence Gain Both CG and LCG represent the edges of the directed graph used for the random walk process. The nodes of such a graph are concepts \(phrases\extracted from Internet pages Section 1.6 presents the contribution of this paper Since this work links association rules interestingness to human cognitive association processes, some of the terms differ from common terminology. We shall sometimes use 
terms such as associative forces or generating associations to describe the process of discovering and evaluating the interestingness of association rules between pairs of concepts. When describing an asymmetric association we shall use the term stimulus as the input and response as the output of the process. Furthermore the phrase user profile represents the most significant concepts \(phrases\at can describe user interests. A user profile is extracted by tracking user behavior while surfing the Internet, and extracting the most significant phrases 
from the sites he chooses to visit. Finally, a few terms are used to specify the words that hold the information and are extracted during the calculations terms  concepts   phrases and associations  1.1 Intelligence and Associations Associations are cognitive links between data units in human memory. The discussion on imitating human associations goes back to Alan Turing, in his original article about an imitation game test of intelligence [3  Turing made two basic claims. The first is that if a machine 
could pass the Turing Test, it would necessarily be intelligent. The second is that in the not too distant future it could in fact be possible to actually build such a machine We shall not discuss here the first claim but rather ask what it takes to build a Turing-Test-qualified machine Researchers such as French m e d th at on l y t h i n g s  that have experienced the world as we have experienced it could pass the Turing Test. On the other hand, others [20  claimed that subcognitive questions, which are designed to probe a network of cultural and perceptual associations could be answered using statistics over large corpuses. In 
this article we agree with the latter opinion. We claim that to some extent, the human associative world, representing the culture and understanding of the environment, can be reconstructed just by looking at the occurrences of certain terms with respect to each other. We claim that if a machine produces outputs that make sense and furthermore help get better search results, its purpose is fulfilled whether the machine is aware of what it is doing or not   15 Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


1.2 Random Walks in Weighted Directed Graphs Let G=\(V,E\ undirected connected graph with n nodes and m edges. A random walk in G starts at node 0 v  At each step, the next node in the walk is selected randomly from the neighbors of the last node in the walk. The probability to move from node t v to any of its neighbors is   t v d 1 where  t v d is the degree of node t v The sequence of visited nodes is a Markov Chain, where the matrix of transition probabilities is 1    otherwise E j i if i d p ij 0    1 We can similarly formulate the transition probability matrix for a weighed directed graph as 2     otherwise E j i if w w p k k i j i ij 0    Here j i w  is the weight of the edge from i to j and  k k i w is the sum of all weights for outgoing edges of node i. Eq. [1 obv iou s l y  a priv ate cas e of eq. [2 1.3 Perron-Frobenious Theorem An n n  matrix M with real entries ij m is called a stochastic matrix provided that \(i\or all ij m 1 0   ij m ii 1  i ij m for all j. A stochastic matrix M is called regular or primitive\ided there is an integer 0 0  q so that 0 q M has all positive entries. Let  0  j x be an element at location j of a vector x at time 0 l l jl x m  0  is the new value of the element at location j at time 1. In matrix notation    1  q q Mx x   represents the probability distribution of being at any node at time q+1. A regular stochastic matrix M has some interesting properties: \(i\ is always an eigenvalue; \(ii\e eigenvector v 1 can be chosen so that all entries are positive and  1 1  i i v iii\or all other eigenvalues i   1  i  and \(iv\for any probability distribution p 1 v p M q  as q goes to infinity. These characteristics enable us to calculate the final probability distribution of all the nodes. Thus, if the graph representation of the associations could be formulated into a regular stochastic matrix, the "steady state" associations distribution could then be calculated. A comprehensive discussion on Perron-Frobenious theorem can be found in 5 1.4 Confidence Gain Interestingness Measure CG en ts th e g a i n  of th e c u rren t a s s o ciation over average confidence of similar associations. Formally let I={I j j=1,2Ém} be a set of items. Let X  I, Y  I be two different items. Let D be a set of transactions, where each transaction t is a set of items. An association rule of the form X Y is defined as follows. Support measure Supp\(X\ the fraction of transcriptions that contains item X in database D. The degree of support and confidence Conf\ for the rule \(X Y\s defined by 3      Supp   Supp Y X  Conf      Y  X Y Supp\(X Y Supp\(X X Y P X Y X Y X P D        Here ||D|| is the total number of the transactions, ||X|| is the number of transactions containing X, and  ||X&Y|| is the number of transactions containing both X and Y. For the current discussion, X represents a stimulus term, and Y represents a possible response. A transaction is a web page containing a set of items. For a fixed stimulus, Conf is a function of all possible responses Y. The average confidence of response Y   Conf Y is calculated by 4   n 1 i i i  Supp\(I Y Supp\(I 1 Y Conf  n where n is the number of valid instances. A valid instance is a rule \(I i Y\aving support and confidence above certain thresholds CG, is a function of both X and Y The averaged confidence is the essence of the new measure. It enables computing the average \(expected confidence of a term, while preserving a sense of locality by performing the averaging process over other terms from a finite yet representative list of terms statistically connected to the stimulus term X. The process is based on parsing a set of the first 250 pages retrieved by Google search engine for a stimulus query phrase. For each phrase the number of pages in which the phrase appears \(1 to 250 is counted. The CG algorithm includes the following stages a. Perform a search over stimulus term and retrieve 250 sites using Google-a b. Scan sites text and select 100 words having the highest frequency of appearance c. Form a list of all possible couples \(stimulus-response of two words \(10,000 couples d. By using Google-API get the number of appearances over the Internet for each couple and its stimulus \(first term e. Calculate confidence of each couple by formul f. Calculate averaged confidence for each of the 100 terms by form g. Calculate CG of each of the couples by formul 5     n 1 i i i  Supp\(I Y Supp\(I Supp\(X Y Supp\(X Y Conf Y Conf\(X Y CG\(X   n Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


h. Return top ranked words sorted by descending CG value Note that the numbers 250, 100 used in the algorithm were chosen empirically since they are large enough to represent the query results space, while still enabling a reasonable execution time of the algorithm. The algorithm was found to be not sensitive to the exact numbers 1.5 Local Confidence Gain The main idea behind the Local Confidence Gain LCG"\ake better use of the retrieved documents While in the basic CG measure, the retrieved sites are used merely for building the most frequent terms list, the local CG uses the term distribution for calculating the average confidence and CG. In order to compensate for the locality" of the data \(using a small number of web pages as against using the entire Internet for the calculation\, the frequency of each response in the local dataset is compared to the average frequency over the Internet. The compensation factor LC \("lingual confidence"\ defined as 6  N n R n R N R LC         where N is the number of pages in the local dataset typically 250\ is the total number of web pages available through a given search engine, N\(R\s the number of sites in the local dataset that contain the term R and n\(R\he number of web pages in the Internet that contain the term R. LCG is formulated as 7       Y LC Y X CG Y X LCG   Note that if the local dataset is the entire Internet, LC=1 and LCG=CG. The modification can be justified in many ways such as looking at LC as a measure of the frequency of a specific term compared to its frequency in the English language. The advantage of LCG is its low complexity Since stage e in the LCG algorithm is performed over the local dataset containing the retrieved sites, it is significantly faster. The LC calculation demands only 100 queries of Google-api, instead of 10,000 needed for calculating CG. A typical execution time for calculating LCG \(for 250 pages and 100 most frequent terms\ is smaller than one minute 1.6 Current Contribution This article extends the concept of random walk in directed graphs to the associative world. The LCG measure enables the creation of a directed graph representation of the links between concepts. The links are both directed and weighted. Using the random walk process on graphs enables us to simulate the associative flow between concepts \(the nodes of the graph\d reach a steady state revealing the probable outcome of a process. It is possible to simulate the importance of any link in the graph to the final outcome and possibly suggest a change in specific links so that the wanted outcome will be reached. The algorithm is called "Associations Rank" \(AR\AR turns the PageRank algorithm to being query dependant. This enables the result to be the most relevant, whereas the simple PageRank algorithm only retrieves the most important documents A large scale Turing Test was performed to show that concepts chosen by the AR algorithm are similar to associations generated by human beings for the same stimuli \(inputs\. Then, the random walk process was used to extract concepts representing the user contemporary profile. By analyzing proxy logs of the surfer's history the essence of the user interest was extracted. Finally, AR was used to "answer" user questions asked in natural language 2 Random Walk in Association Graphs 2.1 Associations Rank Algorithm Formulation Two of the most important characteristics of human associations are their asymmetry \(e.g. the association of Shampoo Hair" is much stronger than "Hair Shampoo"\d the extensive usage on contextual \(or background\nowledge. As mentioned before, terms such as "Shampoo" and "Hair" are the nodes of the graph while the edges exist where there is a high CG connection between any two nodes \(terms As in the concept of the PageRank algorithm, let us begin with terms represented as unconnected nodes randomly located on a plane. Suppose we begin with a random node \(concept\d then perform a random walk to another node. The edges that connect the nodes are the associations. The following measure can then be formulated \(named çAssociation Ranké or çAR 8           E i j j E l j l k j k i l j LCG i j LCG AR AR    1      Here   k i AR is the Association Rank of site i in the k iteration. AR represents the probability that concept i will be accessed after concept j is perceived      E l j l l j LCG i j LCG    is the normalizing factor. The basic concept behind the AR formula is that the probability that a concept will be reached is the sum of probabilities of reaching it from any related concept. For each concept j the probability to move to concept i is normalized by dividing the strength value \(LCG\he association between them in direction from j to i\ivided by the total association strength for all concepts that are linked to concept j. If we define matrix LCG as          otherwise E j i k i LCG j i LCG LCG E k i ij 0  we get the matrix formulation 9  1       k k AR LCG AR where T k n k k k AR AR AR AR        2   1    The AR process can be solved in two ways. The first is by iterating formul d t h e s econ d i s b y  f i n d ing t h e e i g e nv ector that matches the largest eigenvalue, as discussed in the following section Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


2.2 Associations Rank" Algorithm Convergence Criterions In order for the process to converge, let us recall the Frobenious theorem. For a regular stochastic matrix M, if p is any probability distribution then 1 v p M q  as q goes to infinity. AR can easily become a probability distribution if every entry is divided by the sum of all the entries    n l l i AR AR AR 1 This will not alter the ranking. In order for the LCG matrix to become regular, each entry must be made positive by replacing each null entry \(i.e. any entry which represents a case where there is no associative link with a small positive value  Replacing null LCG values by  is equivalent to saying that there is a very small probability to move from one concept to any other concept This intuitively does not contradict any of the pervious assumptions Finally, the process of setting each entry ij to   n l il ij ij LCG LCG LCG 1 makes LCG matrix stochastic. This normalization can be easily justified, since       n LCG n l il 1 1 1 thus LCG LCG  The process will assume the form 10  1       k k AR LCG AR Since LCG is regular and stochastic the process must converge to the eigenvector that corresponds to eigenvalue one. The following figure gives an example of a directed graph containing four nodes \(concepts Figure 1.   Example of a Directed Graph Containing Four Concepts where L i j is the measure LCG\(i j\. L i i represents the small probability for staying on the same node, and is inserted to ensure algorithmic convergence. Thus, the probability of moving from node 1 to node 3 at a stage n is given by the expression        3 1  1  4 1 3 1 2 1 1 1 3 1  1   1  3 1  1   1  4 1 3 1 2 1 1 1 3 1  1                               LCG AR LCG LCG LCG LCG LCG AR L L L L L AR P n n n n 2.3 Using AR Algorithm to Create the Userês Contemporary Profile The actual pages the user visits can be used as the dataset, instead of extracting text from Internet pages retrieved by a search engine. Since the visited sites are temporarily stored on the userês local machine, the process is usually much faster than retrieving sites from the Internet. The algorithm can be performed in background at a preset frequency \(typically every five minutes a. Retrieve new pages visited since last execution b. Create a list of all phrases of consecutive words up to n terms \(n is a parameter set in advance Ö typically 2 c. Select the top 100 phrases that occur in as many of these documents as possible d. Form the LCG matrix. Set the diagonal values and every null entry to 1e-8 Form LCG matrix by normalization e. Perform 100 iterations \(see eq. [10 o m p u t e t h e   AR measure for the vector of phrases f.  Store the 100 phrases and their AR ranks as a user profile The diagonal values are set to a small value \(step d since they represent an unwanted static association. All other nulls are set to small values for the matrix to be positive. In practice it was found that it is much faster to solve eq. [10 iterativ el y rath e r th an d i rectl y co m p u tin g t h e  eigenvector that corresponds to the eigenvalue one This process enables the user to get useful data as he surfs the Web, as we shall demonstrate later 2.4 Using AR Algorithm to Extract Highly Informative Phrases One of the weaknesses of the Google's PageRank algorithm is that it retrieves the most important pages rather than the most relevant ones. This phenomenon occurs since the basic ranks are determined prior to the query \(even though some adjustments are performed after the query phrase is presented\r approach goes a step farther After retrieving an initial set of pages, the AR algorithm is applied to find the most informative phrases within these pages. These phrases are then used to narrow the initial query. The "narrowed" phrase gives more focused results The narrowing process can be unsupervised or supervised where the user selects which of the phrases best reflects his intentions. Phrase extraction is also needed where the user wishes to retrieve phrases that are more accurate, such as an exact disease name or a technical expression \(e.g. "sunk cost", "solar eclipse"\The justification for such a process emerges form the fact that in many cases people can identify and categorize phrases as relevant even if they Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


didnêt think of them in the first place. For example, if one is looking for information on the moon as it looks at the beginning of the month, then a good query phrase would be lunar phases". To most people the term "lunar phases would not "jump into thought" as appropriate, but when presented with it they will agree that it is a good addition to the query terms 3 Experimental Results 3.1 Free Associations Turing Test The Turing Test is based on his claim that for a machine to succeed it must "fool" a human being. In the main experiment that tests this premise, the machine and a human are located in separate rooms. They must respond to identical questions posed by a human interrogator. If the interrogator cannot differentiate between the machine and a human, the machine is passes the Turing Test. In the current research 900, people were given questionnaires containing two sets of stimuli and responses. These people played the part of the interrogators in the Turing Test Several researches explored association rules measures \(see  2  orde r to com pare th e A R al g o rithm  w i th ot h e r association rules measures and human association, we selected seven asymmetrical association measures from 19  as w e d i d in a p r ev io u s research 2 2    T o th is list w e  added Lift measure \(as a representative of the symmetrical association rules measures\CG and AR measures. We focused on asymmetrical measures since, as indicated before, human associations are strongly asymmetrical 11                 1      int                                      log         log    2 2 2 2 2 2 Y P X Y P Y X P Klosgen Y P X Y P Value Added Y P Y P X Y P Factor y Certa Y X P Y P X P Convistion X Y P Confidence Y P Y P X Y P X Y P X P X Y P X Y P X P Index Gini Y P X Y P Y X P Y P X Y P Y X P Measure J                    We used two large psychological databases as sources of human associations: 1. "The MRC Psycholinguistic Database: Machine Readable Dictionary den oted  EAT database\"The University of South Florida Word Association, Rhyme, and Word Fragment Norms  denoted FAN database The following method was employed in order to select valid stimuli set: a. FAN and EAT databases were compared and the top 100 stimuli terms having the largest overlap \(identical responses\were selected \(the stimuli set denoted as "S"\or each stimulus, the first 250 web pages \(retrieved by Google search engine\ were scanned and the 100 terms that appeared with the highest frequency in the scanned pages were stored \(denoted as "top 100" set The S set was used as a base dataset for evaluating the performance of the association measures. The asymmetric measures presented in formul e re us ed to ran k each top 100" set. For each measure, the response with the highest associative strength to the stimulus was given the value 1, and the response having the weakest associative strength to the stimulus was given the rank 100. The criterion for comparison was the claim that a better measure corresponds with a smaller sum. The following table shows the sum of overlapping terms ranks for each measure Table 1.  Sum of Overlapping Response Ranks for the "Top 100" Response List Sum of Overlapping Response Ranks Measure 40866 Added Value 18165 AR 41258 Certainty Factor 44400 Confidence 41258 Conviction 39412 Gini Index 37875 J Measure 23615 Klosgen 16897 LCG 28883 Lift We selected the most promising five association rules having the smallest sum of overlapping terms ranks, for further evaluation \(LCG, AR, Lift, Klosgen and JMeasure\hen randomly selected 50 of the 100 top overlapping terms and built 70 questionnaires, with each containing two lists of stimuli \(input terms\d responses output terms\ne of the sets was extracted from the EAT database while the other was a ranked set of responses of one of the examined association measures. Ten questionnaires containing only human associations were used as a validity check for the test. The following table contains the total number of correct and incorrect answers for each measure. A correct answer was where the interrogator succeeded to identify the human associations Table 2.  Distribution of Correct and Incorrect Answers The score of each measure was calculated by incorrect answers  50 10 0 Measure Correct Answers  Incorrect Answers  Score AR 55 45 90 LCG 62 38 76 Lift 65 35 70 Klosgan 69 31 62 J-Measure 76 24 48 The best measure was the one who scored the highest ratio of number of "wrong" answers, since it was capable of fooling" more people. Logically, the upper boundary of Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


the wrong-to-total ratio was 50%, since the best an associations measure can do is to perform as well as a human being. In this case, the interrogator was not able to decide who is the human and the answers would distribute evenly giving about 50% of the votes to each candidate Thus, by defining the score of each measure as %Incorrect Answers x 100/50 the AR was ranked highest by 90 \(out of 100 A test group was then given a questionnaire containing human associations in both candidates. While being asked to decide which of the two subjects is human the results were 48% of the votes for candidate 1 and 52% of the votes for candidate 2. This result conformed to the expected values \(50% for both candidates The current test had one significant difference from the original Turing Test. While in the original Turing Test there is an unlimited set of questions from which the interrogator selects those to ask, here a given set of questions and answers are given to the interrogator.  This might have biased the decision of interrogators who might not have understood some of the terms. In order to overcome this problem, each interrogator was asked to grade his/her confidence level \(0 Ö not confident 5 very confident\ selecting only those who rated a high confidence level \(4 or 5\, we were able to eliminate cases where the interrogator did not understand the stimuli or responses. The measures performances are shown in the following table Table 3.  Distribution of Correct and Incorrect Answers for Confidence Level > 3 Measure Correct Answers  Incorrect Answers  Score  AR 56 44 88 LCG 66 34 68 Lift 68 32 64 Klosgan 70 30 60 J-Measure 80 20 40 Although the AR score is somewhat smaller in this case it is still better than other measures The following two sections demonstrate the ability of the AR measure to extract valuable phrases from text While section 3.2 focuses on the ability to track the user actions and predict user interests while surfing, section 3.3 starts with a seed query phrase and uses the AR algorithm over the query results to extract highly informative terms These terms can be used to expand the query and extract more focused results 3.2 Analyzing User Surfing History The IRCache Internet pages caching project o u n d ed in 1995, has two goals: provide operational hierarchical caching services and provide large amounts of trace log file data to researchers and other organizations. The cache contains logs of proxy request collected from ten servers in the USA. We analyzed data taken on 12 September 2004 containing more than five million entries\he data in the log files, sanitized to hide users' identity and query terms contained the sorted list of pages visited by the many users We selected four logs and focused on the html pages. The following table shows the raw list of pages \(for convenience only the first four pages are presented\e results of AR algorithm \(the ten highest ranked terms\nd the speculated interest topic of each session Table 4.  Using the AR Algorithm to Analyze User Surfing Logs and Extract the Key Interest Topics Pages Visited first four pages AR Highset Ranked Terms Speculated Topic 1.http://afiwcweb.lackland af.mil/battlelab/index.htm 2.http://fmso.leavenworth army.mil/fmsopubs/fmsop ubs.htm 3.http://images.kazaa.com generic_report/272.html 4.http://images.kazaa.com generic_report/res_1024.ht ml warfare infrastructure defense attack; joint command force potential Military Warfare 1.http://mailing.worldsexci nema.com/galleries/animal fuckers/galleryaf09_y1.ht ml 2.http://publish.aps.org/ST ATUS/wvman1.html 3.http://www.aip.org/pubs ervs/style.html 4.http://www.aip.org/pubs ervs/style/4thed/toc.html ivan; hash hurricane split; cnn tropical; force florida Florida Hurricane Forcast 1.http://mail.gnome.org/arc hives/gtk-list/2004September/msg00049.html 2.http://mail.gnome.org/arc hives/gtk-list/2004September/msg00044.html 3.http://mail.gnome.org/arc hives/gtk-list/2004September/msg00005.html 4.http://207.242.75.40/derb tech/windtunl.htm akron; derby racer soap; rally championship gtk; gnome Car Racing 1.http://www.jhuapl.edu/st ates/fl_0.html 2.http://www.chubbypussy.com/gal010/thehun html 3.http://www.cnn.com/200 4/SHOWBIZ/09/09/showb uzz/index.html 4.http://www.cnn.com/200 4/SHOWBIZ/Movies/09/0 9/neve.campbell.reut/index html cnntogo endorse headline; cnn escape korean external japanese News As can be seen, the terms extracted by the AR algorithm are good descriptors of user interest. These terms can function as the user contemporary profile and be used for further extraction of relevant web pages. Note that the fourth column \(Speculated Topic\ only presented for the Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


reader's convenience. In actual cases the top ranked terms are selected as topic descriptors 3.3 Extracting Highly Informative Terms In our third experiment we began with just a simple question or a phrase. This phrase was fed into the Google search engine. The query results were analyzed by the AR algorithm, and the highest ranked terms were collected for further use. We then used the highest ranked terms to expand the original query and refine the search. The following table holds the query phrases, the AR algorithm highest ranked terms, the revised search phrase and it's first retrieved web page Table 5.  Using the AR Algorithm to Extract Highly Informative Terms \(The extracted terms are used for query expansion Original Query Phrase AR Highest Ranked Phrases Revised Query Phrase Topic of the First Retrieved Page  Sleep and appet-ite depressed mood anxiety disorder Sleep and appetite Depressed mood anxiety disorder Informatio nal Reports on Depression and Stress What is the origin of the human race racial evolution ancient scientific What is the origin of the human race racial evolution ancient scientific The Races of Humanity What is the furthest star in the solar system orbiting asteroid gravitational pluto What is the furthest star in the solar system orbiting asteroid gravitational Pluto HubbleSite All FAQs for Solar System Hitchc-ock movies marnie lodger vertigo psycho Hitchcock movies marnie lodger vertigo psycho Auteur theory of Alfred Hitchcock Once again the AR algorithm extracted terms that served as descriptors and could be used for farther query expansion. We chose to expand the query phrase by simply adding the first four terms extracted by the AR algorithm A different approach would have been to give the user the list of extracted terms. The user would then be able to select from the list the most suitable terms to be added to the original query phrase Note that the question "what is the furthest star in the solar system?" was not stated properly, since the users meant to find the furthest Planet and not Star. The AR algorithm was able to find the term, "Pluto" \(the fourth of the ranked terms\ despite this "mistake". Furthermore, very common terms such as "who", "what", "is" are ignored by the Google search engine. Thus, for example, the query what is the furthest star in the solar system", translated to only four terms "furthest, star, solar, and system 3.4 Discussion This chapter presented three different approaches for validation of the AR algorithm. First - the "Free Associations Turing Test" confronts the question whether the AR algorithm can "imitate" human associations. The second - analyzing proxy logs deals with the question whether the AR algorithm can extract human-interest topics from the user's surfing history. And finally, the third part deals with the question whether the AR algorithm can help the user to better express his thoughts and reach valuable information more efficiently While the answer to the first question is based on a solid statistical base \(we compared ten association rules measures, 100 seed terms, 70 different questionnaires and 900 people who answered the different questionnaires\e latter two were based on much smaller samples. Thus the conclusions were qualitative rather than quantitative. Still we believe that the potential for creating a user profile or using the AR algorithm to extract highly informative phrases has been shown 4 Concluding Remarks The AR algorithm that extracts highly informative phrases was shown capable of both "imitating" humans by creating human-like associations and giving highly informative descriptors of Internet pages. The extracted descriptors were used to reveal the user current interest topics and to supply query expansion terms. The algorithm complexity is low, and can be performed in near real-time The success of the algorithm raises the question whether actual human thinking processes are performed similarly The algorithm is rather robust and can be employed for various usages, or to even use other asymmetrical association measures as links between concepts. One of the most promising usages we forecast for this algorithm is user conceptual modeling and prediction. By using the AR algorithm to extract concepts and associations from the pages the user visits, an analysis of "flow" in a conceptual graph can show trends and determine the probability for the user to reach certain concepts within his current surfing session. In future work we intend to identify common properties for similar users, and define a profiling technique based on the random walk algorithm Many other interesting challenges are still waiting to be addressed in the web search algorithms area. For a good review of the most promising is the partitioning of the web by eigenvectors s   5 References   A  Fara h a t, T  L o Faro, an d J  C  Miller Modification of kleinberg's hits algorithm using matrix exponentiation and web log records Proceedings of the 24th International Conference on Research and Development in Information Retrieval SIGIR 2001 New Orleans, USA, September 2001   A  A  Freita s O n r u le i n ter estingn es s m eas u r es   Knowledge-Based Systems 12, 2000, pp. 309-315 Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


 A  M   T u ring   Computing machinery and intelligence Mind Vol. 59, No. 236, 1950 pp. 433460 4   A  P  Sa ygi n I  Ci c e kl i  a n d V Ak m a n  T ur i ng Test: 50 Years Later Minds and Machines 10\(4 2000, pp. 463-518   C  R  MacC l u er, "T h e m a ny p r oof s an d application s  of Perronsês theorem SIAM Rev 42\(3\0, pp 487Ö498   Gan t m ach er F R   The Theory of Matrices  Volume I, II, Chelsea Publ. Co., New York, 1959  Goog le A P I. h ttp www  g oog le.co m api s   H a v e li w a la T  H an d S  D   K a m v ar The second eigenvalue of the Google matrix Stanford University Technical Report, 2003  IR C ach e I n tern et cac h i n g proj ect See http://www.ircache.net  current 6.2005   J. S h i an d J. Malik  N orm alized C u t s an d I m a g e  Segmentation Proc. Computer Vision and Pattern Recognition 1997   J.R S earl   Minds, Brains and Programs   Behavioral and Brain Science 3\(262\1980, pp. 2631 12   L Kl e i nb e r g J   A ut ho r i t a t i v e  so ur c e s  i n a  hyperlinked environment Proceedings of the ACMSIAM Symposium on Discrete Algorithms 1998  M  D   Wils on   The MRC Psycholinguistic Database: Machine Readable Dictionary   Behavioral Research Methods, Instruments and Computers 20\(1\1988, pp. 6-11   M.R Hen zi n g e r A l g orithm i c C h alle ng es in Web Search Engines Internet Mathematics Vol. 1, No 1, 2003, pp. 115-126  Mich ie D  Turing's Test and Conscious Thought   in P. Millican and A. Clark, eds Machines and Thought: The Legacy of Alan Turing Oxford, UK Oxford University Press, 1996, pp. 27-51   N  D e o, an d P G u pta S a m p ling t h e Web With  Random Walks Congressus Numerantium 149 2001\, 32nd Southeastern International Conference on Combinatorics, Graph Theory and Computing Feb. 26 - Mar. 2, 2001, Baton Rouge, LA. pp. 143154   N  D e o, an d P. G u pta G raph T h e oretic Web  Algorithms: An Overview Lecture Notes in Computer Science eds. T. Bˆhme and H. Unger 2026 \(2001\Innovative Internet Computing Systems, June 21-22, 2001, IImenau Technical University, Germany, pp. 91-102   N e ls on D  L C  L  M c Ev o y an d S c h r eiber T  A   The University of South Florida Word Association Rhyme, and Word Fragment normsNorms 2002 See http://w3.usf.edu/FreeAssociation/Intro.html Current 6.2005   P   T a n  V. Kum ar, an d J  Sriv asta v a  S electing th e  right interestingness measure for association patterns   Technical Report 2002-112 Army High Performance Computing Research Center, 2002  P.D  T u rn e y   Answering Subcognitive Turing Test Questions: A reply to French   Submitted to the Journal of Experimental and Theoretical Artificial Intelligence, 2001    R  L e m p el a n d S   M o rran  SALSA: The stochastic approach for link-structure analysis ACM Transactions on Information Systems 19\(2\001  R   T a m i r  On Confidence Gain Measure for Association Rules Generation and Scoring VLDB Journal forthcoming, 2005   R  T a m i r, an d R  R a pp  M in in g  th e Web to Discover the Meanings of an Ambiguous Word Proceedings of the third IEEE international conference on data mining 19-22 November 2003 Melbourne, Florida, pp. 645  R  M Fren ch   Subcognition and the Limit of the Turing Test   Mind Vol. 99, No. 393, 1990, pp. 5365 25  R  M   S h if f r in    Modeling Memory and Perception   Cognitive Science 27, 2003, pp. 341-378   S. Brin an d L  P a g e  T h e anato m y o f a larg e s cale hypertextual Web search engine Proceedings of the 7 th International World Wide Web Conference Brisbane, Australia 1998  S t ran g  G   Linear Algebra and Its Applications  Third Edition, Harcourt Brace Jovanovich Publishers, San Diego, 1988 28   T J  Pa l m e r i  A n ex em p l ar b a s e d r a n d om  w a lk  model of perceptual categorization". M. Ramscar, U Hahn, E. Cambouropolos, & H. Pain \(Eds Proceedings of the Interdisciplinary Workshop on Similarity and Categorisation Edinburgh, Scotland University of Edinburgh \(1997\p. 181-187 Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


9 Here are some observations and explanations on the results 1\The total time of our comparison includes the time to write the association rules to a file; Bit-AssocRule is 2 to 3 orders of magnitude faster than the various Apriori algorithms \(64-221 times faster\he test data set, the big the time difference between the BitAssocRule and the various Apriori algorithms. We havenêt compared our algorithm with some of the other association rule algorithms such as VIPER  13,24] \(CHARM and CL OSE are base d on the closed frequent itemsets concept\d on their published comparison results with Apriori, our BitAssocRule is very competitive compared to them and a direct comparison will be conducted and reported in the near future 2\e or litter longer time than the various Apriori algorithms in constructing the 1-itemsets because of the extra cost of building the bitmaps for the 1-itemsets. But after the 1-itsemtset is done, Bit-AssocRule is significant faster than the Apriori algorithms in constructing large frequent itemsets because it only uses the fast bit operations \(AND COUNT and SHIFT\nd doesnêt need to test the subsets of the newly candidate 3\aps of the frequent items, and the bitmap storage \(uncompressed less than the original data set \(1/2 to 1/4 of the original data size The main reasons that Bit-AssocRule algorithm is significant faster than Apriori and its variations are 1\ocRule adopts the divide-and-conquer strategy, the transaction is decompose into vertical bitmap format and leads to focused search of smaller domain There is no repeated scan of entire database in BitAssocRule 2\snêt follow the traditional candidate-generate-and test approach, thus saves significant amount of time to test the candidates 3\basic operations are bit Count and bit And operations, which are extremely faster than the pattern search and matching operations used in Apriori and its variations 5. Conclusion The contributions of this paper are in two aspects:  we extend the application domains of bitmap techniques and introduce the bitmap techniques for complex DSS query optimization and association algorithm. We present a bitmap based query optimization algorithm to optimize complex query with multiple table join based on outer join operations and push the outer join operations from the data flow level to the bitmap level and achieve significant performance gain.   We introduce a novel algorithm to calculate the foundset for those tables involved in the prejoin table by using prejoin_bitmap_indexes and integrate this algorithm into the current commercial data flow based query engine seamlessly. Our query optimization can achieve an order of magnitude faster than conventional query engine Secondly we introduce the bitmap technique to the data mining procedure and develop a bitmap-based algorithm Bit-AssocRule to find association rules. Our BitAssocRule avoids the time-consuming table scan to find and prune the itemsets, all the operations of finding large itemsets from the datasets are the fast bit operations. The experimental result of our Bit-AssocRule algorithm with Apriori and AprioirHybrid algorithms shows Bit-AssocRule is2 to 3 orders of magnitude faster. This research indicates that bitmap technique can greatly enhance the performance for decision support queries and finding association rule, and bitmap techniques are very promising for the decision support query optimization and DM applications Bitmap technique is only one way to improve the performance of complex DSS queries and DM algorithm Parallelism is another crucial factor to improve the performance of DSS and data mining.  We are currently working on paralleling the bitmap-based algorithms and hope to report our findings in the near future 6. References  Agrawal R. Sri kant R., çFast al gorithm for mining association rulesé, Prod. of the 20 th VLDB Conf. 1994  Agrawal R., Mannila H., Sri kant R., Toivone n H., Verkamo A., çFast discovery of  association rulesé, in Advances in Knowledge Discovery and Data Mining, MIT 1996  AIP D Tec hnical P u blications In Syba se IQ Administration Guide, Sybase IQ Release  11.2 Collection, Sybase Inc Proceedings of the Seventh International Database Engineering and Applications Symposium \(IDEASê03 1098-8068/03 $17.00 © 2003 IEEE 


10  er-Yahia S., Johnson T., çOptimizing queries on compressed bitmapsé, Prod. of the 20 th VLDB  Conf  wa l, R., Gunopul os D  Constraint-based rule mining in large, dense databases Proc. of the 15th Int'l Conf. on Data Engineering \(ICDE1999 6] Bertino E., Ooi B.C., Sacks-Davis R. etc, çIndexing techniques for advanced database systems Kluwer Academic Publishers  n C Ioa nnidis Y B itm ap index design and evaluationé, Prod of the  SIGMOD-96  h atziant oni ou D Akinde  M, Johnson T Kim  S, çThe md-join: an operator for complex olapé. Prod of the 18 th Intêl Conference on Data Engineering \(ICDE2001  outer joiné, Prod of the 2nd International Conf. on Databases   Fre nch C  One size fits allê databa se arc hitecture do not work for dssé, Prof of the  SIGMOD-95  hal, A., çOute r join simplification and reordering for query optimizationé, ACM TODS, 22\(1\1997  G., çVolcano, an extensible and pa rallel query evaluation systemé, IEEE Transaction on Knowledge and Data Engineering, 6\(6  e i, J. Yin. Y  Mining fre quent patterns without candidate generation", Prod of the SIGMOD-2002    Hanusa R., çA lesso n in outer joins \(learned the hard way!\data Review, Spring 1998  aine C., Data A A novel inde x s u pporting high volume data warehouse insertioné Prod of the 25th VLDB Conf  on T , çPerform ance m easurem ents of compressed bitmap indicesé Prod. of the 25th VLDB conf   Y Data m i ni ng and m achine oriented modeling: a granular computing approaché, Journal of Applied Intelligence, Oct. 2000  Lin T.Y., çFi nding ass ociation rules using fast bit computation: machine-oriented modelingé ISMIS-2000  M., çGroup bit map index: a structure for association rules retrieval Prod. of the 4 th Intêl Conf. on Knowledge Discovery and Data Mining \(KDD-98  OêNeil P Graefe G., çM ulti-table joi ns  through bitmapped join indexesé, SIGMOD September 1995, 8-11   OêNeil P., Quass D., çIm prove d que ry pe rformance with variant indexesé, Prod of the SIGMOD-1997   Inform ix and inde xing s u pport for data warehouses,  Informix Whitepaper  a p join i n dex  http://technet.oracle.com/products/oracle9i/daily/a pr09.html  n, H. Lu, S. Ni shio, S. Ta ng, and D  Yang. "H-mine: hyper-structure mining of frequent patterns in large databases", Proc. The 2001 IEEE Intêl Conference on Data Mining  OêNeil P.,  OêNeil E.,  çBitSliced Index Arithmeticé, Prod of the SIGMOD2001  vase re , A Om iecinski E Na vat he S  An efficient algorithm for mining association rules in large databasesé, in Prod. of the 21 st VLDB conf  She noy P Bhal otia G Haritsa J B a wa M Sudarshan S., Shah D., çTurbo-charging vertical mining of large databaseé, Prod. of the SIGMOD2000  a processi ng for com plex queriesé, Red Brick/Informix White Paper  as and starjoi n technologyé Red Brick/Informix White Paper  P C be nchm ark d de cision s u pport  dard specification, Release 2.2. \(Transaction Processing Performance Council \(TPC  durie x P J oi n indexe s ACM TODS 12\(2\ 1987  W u M Buchm ann A  Encoding bitm ap indexing for data warehouseé, Proc. of the 14th  Intêl Conference on Data Engineering, 220-231, 1998   Gouda K., çF ast vertical usi ng diffsetsé, Tech report, Dept. of  computer science, RPI  Y., Des hpa nde P., Naughton J Shukla A.,  çSimultaneous optimization and evaluation of multiple dimensional queriesé, SIGMOD-98, 271282 Proceedings of the Seventh International Database Engineering and Applications Symposium \(IDEASê03 1098-8068/03 $17.00 © 2003 IEEE 


20% 4 4 4 12 12 30% 4 3 3 12 12 40% 3 3 3 12 11 50% 3 2 2 11 10 60% 2 1 2 11 10 70% 2 1 2 11 11 80% 2 2 2 10 11 90% 2 2 2 9 10 99% 0 1 1 6 10 Looking at Table 9, one may wonder why the representation determined for minSup = 70% has shorter longest elements in its Bd  GDFree \(here: length = 1 than the representation determined for minSup = 80 here: length = 2 border elements in Bd  GDFree, which are infrequent in the representation determined for minSup = 80 become frequent when lowering the support threshold to 70 7. Related work The most similar to the representations based on generalized disjunctive sets is the NDR representation which consists of all frequent non-derivable itemsets [7 8], and the representations based on ?-free sets [7, 9]. It was shown in [8], that for each non-empty itemset Z, one can derive the lower bound \(l\(Z u\(Z on sup\(Z from the fact that sup\(Z Non-derivable itemsets are those for which u\(Z Z gt; 0. If u\(Z Z sup\(Z supersets Y of a derivable itemset are also derivable and u\(Y Y Y such that neither sup\(Z Z Z Z It was proved in [7, 8] that u\(Z Z  u\(Z?{a Z?{a for |Z| ? 1 This important result was used in [7, 8] to determine the upper bound on the length of non-derivable itemsets namely: non-derivable itemsets are not longer than log2|D|? + 1 Hence, the bound on the length of non-derivable itemsets is identical to the bound on the length of generalized disjunction-free sets \(please see Theorem 3.2 It has been proved in [7] that ?-free sets are a subset of non-derivable itemsets, so their length is also bounded by ?log2|D|? + 1 There is a claim in [7, 9] that the generalized disjunction-free sets equal the ?-free sets. This claim however, is not correct, which we will prove by the example beneath. Table 4 contains all generalized disjunction-free sets. Among them, there is {fh}, the support of which equals 0. The support bounds for {fh are found as follows \(please, see [7] for the details  sup\({fh f h   sup\({fh f  sup\({fh h  sup\({fh Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE Hence, l\({fh fh fh sup\({fh free, is not a ?-free set Since the families of the generalized disjunction-free sets and ?-free sets may differ, finding the relationship between them or between the generalized disjunction-free sets and non-derivable itemsets remains a challenge 8. Conclusions The representations based on generalized disjunctionfree sets belong to the most concise ones among all lossless frequent patterns representations with borders. In 


lossless frequent patterns representations with borders. In practice, they are also much more concise than representations based on closed itemsets and approximate representations. In this paper, we offered three methods of deriving an upper bound on the length of sets in such representations. We proved that the upper bound on the length of a longest generalized disjunction-free set depends logarithmically on the number of records in the database. The obtained result is of high importance as it guarantees that any generalized disjunction-free set representation for all patterns \(both frequent and infrequent scans, where n is the number of records in the database irrespectively how strong or weak correlations among items in the database are and irrespectively of the lengths of records and number of distinct items The modifications of the basic estimation take into account the support threshold of the representation to be found or, additionally, the information on the length of longest sets of the representation already calculated for a higher support threshold. Though these estimations are more accurate than the basic one, they are still quite rough. Further improvements of the quality of estimating the length of longest itemsets in generalized disjunctionfree representations is subject to further research References 1] R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, A.I Verkamo  Fast Discovery of Association Rules   Advances in Knowledge Discovery and Data Mining AAAI, CA, 1996 2] J. Baptiste, J.-F. Boulicaut  Constraint-Based Discovery and Inductive Queries: Application to Association Rule Mining  Pattern Detection and Discovery, Springer London, UK, September 2002, pp. 110-124 3] E. Baralis, S. Chiusano, P. Garza  On Support Thresholds in Associative Classification  SAC, ACM, Taipei Taiwan, March 2004, pp. 553-558 4] Y. Bastide, N. Pasquier, R. Taouil, G. Stumme, L. Lakhal  Mining Minimal Non-redundant Association Rules Using Frequent Closed Itemsets  Computational Logic, 2000 pp. 972  986 5] J.-F. Boulicaut, A. Bykowski, C. Rigotti  Approximation of Frequency Queries by Means of Free-Sets  PKDD Springer, Lyon, France, September 2000, pp. 75-85 6] A. Bykowski, C. Rigotti  A Condensed Representation to Find Frequent Patterns  PODS, ACM, Santa Barbara USA, May 2001, pp. 267-273 7] T. Calders, Axiomatization and Deduction Rules for the Frequency of Itemsets, Ph.D. Thesis, University of Antwerp, 2003 8] T. Calders, B. Goethals  Mining All Non-derivable Frequent Itemsets  PKDD, Springer, Helsinki, Finland August 2002, pp. 74?85 9] T. Calders, B. Goethals  Minimal k-free Representations of Frequent Sets  ECML/PKDD, Springer, CavtatDubrovnik, Croatia, September 2003, pp. 71-82 10] J. Han, M. Kamber, Data Mining: Concepts and Techniques, Morgan Kaufmann Publishers, 2000 11] S.K. Harms, J. Deogun, J. Saquer, T. Tadesse  Discovering Representative Episodal Association Rules from Event Sequences Using Frequent Closed Episode Sets and Event Constraints  ICDM, IEEE Computer Society, San Jose, California, USA, November-December 2001, pp. 603  606 12] M. Kryszkiewicz  Closed Set Based Discovery of Representative Association Rules  IDA, Springer Cascais, Portugal, September 2001, pp. 350-359 13] M. Kryszkiewicz  Concise Representation of Frequent Patterns based on Disjunction  free Generators  ICDM IEEE Computer Society, San Jose, California, USA 


IEEE Computer Society, San Jose, California, USA November-December 2001, pp. 305  312 14] M. Kryszkiewicz M  Inferring Knowledge from Frequent Patterns  Soft-Ware, Springer, Belfast, Northern Ireland April 2002, pp. 247  262 15] M. Kryszkiewicz  Concise Representations of Association Rules  Pattern Detection and Discovery, Springer London, UK, September 2002, pp. 92-109 16] M. Kryszkiewicz, Concise Representation of Frequent Patterns and Association Rules, Habilitation Thesis Publishing House of Warsaw University of Technology 2002 Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE 17] M. Kryszkiewicz  Reducing Infrequent Borders of Downward Complete Representations of Frequent Patterns  Proc. of The First Symposium on Databases Data Warehousing and Knowledge Discovery, Scientific Publishers OWN, Baden-Baden, Germany, July, 2003, pp 29-42 18] M. Kryszkiewicz  Closed Set Based Discovery of Maximal Covering Rules  International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems Vol. 11. World Scientific Publishing Company, Singapore September 2003, pp. 15-29 19] M. Kryszkiewicz  Reducing Borders of k-Disjunction Free Representations of Frequent Patterns  SAC, ACM Taipei, Taiwan, March 2004, pp. 559  563 20] M. Kryszkiewicz  Reducing Main Components of k-Disjunction Free Representations of Frequent Patterns   Proc. of IPMU  2004 \(in print 21] M. Kryszkiewicz, M. Gajek  Concise Representation of Frequent Patterns based on Generalized Disjunction  Free Generators  PAKDD, Springer, Taipei, Taiwan, May 2002, pp. 159-171 22] M. Kryszkiewicz, M. Gajek  Why to Apply Generalized Disjunction-Free Generators Representation of Frequent Patterns  ISMIS, Springer, Lyon, France, June 2002, pp 383  392 23] M. Kryszkiewicz, H. Rybi?ski, M. Gajek  Dataless Transitions between Concise Representations of Frequent Patterns  Journal of Intelligent Information Systems JIIS Netherlands, 2004, pp. 41-70 24] N. Pasquier, Data mining: Algorithmes d  extraction et de R  duction des R  gles d  association dans les Bases de Donn  es, Th  se de Doctorat, Universit  Blaise Pascal   Clermont  Ferrand II, 2000 25] N. Pasquier, Y. Bastide, R. Taouil, L. Lakhal  Efficient Mining of Association Rules Using Closed Itemset Lattices  Journal of Information Systems, Vol. 24, No. 1 1999, pp. 25  46 26] N. Pasquier, Y. Bastide, R. Taouil, L. Lakhal  Discovering Frequent Closed Itemsets for Association Rules  ICDT, Springer, Jerusalem, Israel, January 1999 pp. 398  416 27] J. Pei, G. Dong, W. Zou, J. Han  On Computing Condensed Frequent Pattern Bases  ICDM, IEEE Computer Society, Maebashi City, Japan, December 2002 pp. 378-385 28] V. Phan-Luong V  Representative Bases of Association Rules  ICDM, IEEE Computer Society, San Jose California, USA, November-December 2001, pp. 639-640 29] A. Savinov  Mining Dependence Rules by Finding Largest Itemset Support Quota  SAC, ACM, Taipei Taiwan, March 2004, pp. 525-529 30] M.J. Zaki, C.J. Hsiao  CHARM: An Efficient Algorithm for Closed Itemset Mining  SIAM, Arlington, 2002 


for Closed Itemset Mining  SIAM, Arlington, 2002 Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE pre></body></html 


                                                  S J       


                                                      


                         L A                                        


          L A  Table 7. Table of Granules at left-hand-side is isomorphic to  at right- hand-side: By Theorem  3.1 one can ?nd patterns in either table as a single generalized concept  Internal points  are:[4]\(1, 1, 0, 0 tions; [5]\(0, 1, 1, 0  0, 1, 0, 1  0, 1, 1, 1  1, 1 1, 0  1, 1, 0, 1  1, 0, 1, 1 11]\(1, 1, 1, 1 form and simplify them into disjoint normal forms 1  T E N    S J    T E N    S J 2  T W E N T Y    L A    T H I R T Y   A 3  T W E N T Y      T H I R T Y   A 4  T W E N T Y            L A 5  T E N      T W E N T Y    L A    T E N    T W E N T Y   A   S J    T W E N T Y   A      T H I R T Y    L A     Y 7  T E N      T W E N T Y      T H I R T Y   L A    T E N   L A    S  J   A 8  T W E N T Y      T E N      T W E N T Y    L A    T E N   T W E N T Y      T H I R T Y 9  T W E N T Y    N Y    T E N    S J    T H I R T Y    L A      T W E N T Y    L A  1 0  T W E N T Y    N Y    T W E N T Y    L A    T H I R T Y   A    J 1 1  T W E N T Y          T W E N T Y    L A   T H I R T Y    L A    a l l If the simpli?ed expression is a single clause \(in the original symbols non-generalized the following associations 1   T E N     S J    T E N    S J  2. SJ   J 4   L A    T W E N T Y    L A    T H I R T Y    6 Conclusions Data, patterns, method of derivations, and useful-ness are key ingredients in AM. In this paper, we formalize the current state of AM: Data are a table of symbols. The patterns are the formulas of input symbols that repeat. The method of derivations is the most conservative and reliable one, namely, mathematical deductions. The results are somewhat surprising 1. Patterns are properties of the isomorphic class, not an individual relation - This implies that the notion of patterns may not mature yet and explains why there are so many extracted association rules 2. Un-interpreted attributes \(features can be enumerated 3. Generalized associations can be found by solving integral linear inequalities. Unfortunately, the number is enormous. This signi?es the current notion of data and patterns \(implied by the algorithms 4. Real world modeling may be needed to create a much more meaningful notion of patterns. In the current state of AM, a pattern is simply a repeated data that may have no real world meaning. So we may need to introduce some semantics into the data model [12],[10],[11 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE References 1] R. Agrawal, T. Imielinski, and A. Swami  Mining Association Rules Between Sets of Items in Large Databases  in Proceeding of ACM-SIGMOD international Conference on Management of Data, pp. 207216, Washington, DC, June, 1993 


216, Washington, DC, June, 1993 2] Richard A. Brualdi, Introductory Combinatorics, Prentice Hall, 1992 3] A. Barr and E.A. Feigenbaum, The handbook of Arti?cial Intelligence, Willam Kaufmann 1981 4] Margaret H. Dunham, Data Mining Introduction and Advanced Topics Prentice Hall, 2003, ISBN 0-13088892-3 5] Fayad U. M., Piatetsky-Sjapiro, G. Smyth, P. \(1996 From Data Mining to Knowledge Discovery: An overview. In Fayard, Piatetsky-Sjapiro, Smyth, and Uthurusamy eds., Knowledge Discovery in Databases AAAI/MIT Press, 1996 6] H Gracia-Molina, J. Ullman. &amp; J. Windin, J, Database Systems The Complete Book, Prentice Hall, 2002 7] T. T. Lee  Algebraic Theory of Relational Databases  The Bell System Technical Journal Vol 62, No 10, December, 1983, pp.3159-3204 8] T. Y. Lin  Deductive Data Mining: Mathematical Foundation of Database Mining  in: the Proceedings of 9th International Conference, RSFDGrC 2003 Chongqing, China, May 2003, Lecture Notes on Arti?cial Intelligence LNAI 2639, Springer-Verlag, 403-405 9] T. Y. Lin  Attribute \(Feature  The Theory of Attributes from Data Mining Prospect  in: Proceeding of IEEE international Conference on Data Mining, Maebashi, Japan, Dec 9-12, 2002, pp. pp.282-289 10] T. Y. Lin  Data Mining and Machine Oriented Modeling: A Granular Computing Approach  Journal of Applied Intelligence, Kluwer, Vol. 13, No 2, September/October,2000, pp.113-124 11] T. Y. Lin, N. Zhong, J. Duong, S. Ohsuga  Frameworks for Mining Binary Relations in Data  In: Rough sets and Current Trends in Computing, Lecture Notes on Arti?cial Intelligence 1424, A. Skoworn and L Polkowski \(eds 12] E. Louie,T. Y. Lin  Semantics Oriented Association Rules  In: 2002 World Congress of Computational Intelligence, Honolulu, Hawaii, May 12-17, 2002, 956961 \(paper # 5702 13  The Power and Limit of Neural Networks  Proceedings of the 1996 EngineeringSystems Design and Analysis Conference, Montpellier, France, July 1-4, 1996 Vol. 7, 49-53 14] Morel, Jean-Michel and Sergio Solimini, Variational methods in image segmentation : with seven image processing experiments Boston : Birkhuser, 1995 15] H. Liu and H. Motoda  Feature Transformation and Subset Selection  IEEE Intelligent Systems, Vol. 13 No. 2, March/April, pp.26-28 \(1998 16] Z. Pawlak, Rough sets. Theoretical Aspects of Reasoning about Data, Kluwer Academic Publishers, 1991 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207ñ216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intíl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intíl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 






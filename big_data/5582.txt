Evaluating Association Rules by Quantitative Pairwise Property Comparisons Elnaz Delpisheh and John Z Zhang Abstract Evaluating association rules is an integral post process in association rule mining Association rules are examined by measures for their interestingness Di\013erent interestingness measures have been proposed Given an association rule mining task measures are assessed and selected against a set of user-speci\014ed properties However in practice due to the subjectivity and imperfection in property speci\014cations it is a non-trivial task to make appropriate measure selection In this work we propose a novel measure selection approach that makes use of the Analytic Hierarchy Process AHP a scheme for making complex decisions Our approach captures a user's desired requirements quantitatively in an application domain to assess interestingness measures It detects inconsistencies in property speci\014ca 
tions and is invariant to the number of association rules to be evaluated The e\013ectiveness of our approach is shown through case studies Index Terms Association rules Interestingness measures The Analytic Hierarchy Process Interestingness property I Introduction D ATA mining aims at discovering interesting patterns from large-volume data Asso ciation mining is one of the many data mining tasks that has attracted more and more attention It discovers the inherent relationships among objects in an application domain A good application example of these application domains is basket analysis in supermarkets where one tries to discover the relationships among commodities in baskets In association mining interesting patterns are represented as association rules  For example in basket analysis f 
milk eggs g  f bread g is an association rule implying that if milk and eggs are bought together bread is likely to be bought as well One of the non-trivial issues in association mining considered in literature 4 5 6 7 8 9 is the large number of association rules discovered While many of the rules convey non-trivial and interesting information some of them are trivial or even irrelevant 7 10 Th us they are too di\016cult to be interpreted and comprehended by users  Generally two types of users are considered to be involved in the association mining process An end user is an expert of the data to be mined in a particular ap 
plication domain while an analyst is a specialist in data mining The end user should provide the analyst with su\016cient domain knowledge represented as requirements in the domain in order to extract interesting association E Delpisheh is with the Department of Mathematics and Computer Science University of Lethbridge AB Canada e-mail elnaz.delpisheh@uleth.ca J Z Zhang Corresponding author is with the Department of Mathematics and Computer Science University of Lethbridge AB Canada e-mail john.zhang@uleth.ca rules Throughout this pap er the term user is meant to be end user To deal with the large number of association rules a variety of interestingness measures to assess them as how bene\014cial and interesting they are have been proposed  10 12 These measures rank asso ciation rules according to a set of criteria some of which are as follows 
Reliability asks whether the relationship the association rule reveals occurs frequently Peculiarity checks whether an association rule largely di\013ers from other discovered association rules Other criteria include diversity  novelty  surprisingness  utility  and comprehensibility  9 10  It is easy to see that some of the above criteria such as novelty and surprisingness are dependent on each other while some others such as conciseness and reliability are contradictory Requiring them b y the user at the same time introduces inconsistency in measuring association rules 10 14 In addition the user's requirements could be multi-facet desiring multiple-criteria to be put into consideration when measuring association rules 
Moreover the user's requirements may change re\015ecting the current preferences of them in an application domain and as a result in association rule evaluations In our work we attempt to capture from preferences in an application domain the importance of di\013erent properties in assessing interestingness measures In Section II we brie\015y review interestingness measures for evaluating association rules In Section III we discuss the properties against which a measure is assessed and selected In Section IV we present measure selection strategies proposed so far Sections V and VI introduce our measure assessment method which makes use of the Analytic Hierarchy Process to capture the user's subjective requirements and uses them in assessing measures Section VII applies our proposed approach on two cases Section VIII discusses the characteristics of measure selection approaches and compares our approach to the previous ones Finally Section IX summarizes our 
discussions II Interestingness measures This paper focuses on di\013erent interestingness measures for evaluating association rules a post process of an association mining task Let I  f i 1  i 2  i 3  001 001 001  i l g be a set of items and let D  f t 1  t 2  t 3  001 001 001  t n g be a 
transactional database  where each transaction t i 2 D is a subset of I  An association rule is an implication of the form A  B  where A 032 I  B 032 I  and A  B    Usually a large number of association rules are resulted from an association mining process such as Apriori  
2010 IEEE International Conference on Data Mining Workshops 978-0-7695-4257-7/10 $26.00 © 2010 IEEE DOI 10.1109/ICDMW.2010.145 927 
2010 IEEE International Conference on Data Mining Workshops 978-0-7695-4257-7/10 $26.00 © 2010 IEEE DOI 10.1109/ICDMW.2010.145 927 


Many measures have been proposed and studied to evaluate and rank them based on their interestingness Depending on the extent of the user's involvement and the criteria they intend to pursue measures are divided into two groups objective and subjective  An objective measure depends only on the structural nature such as the statistical properties of association rules and underlying data On the other hand a subjective measure considers data itself and its users Criteria including conciseness reliability peculiarity and diversity are considered objective while novelty utility surprisingness and comprehensibility are considered subjective For instance given a rule A  B  for database D  the support s and the con\014dence c are two objective measures to respectively assess the frequency and coverage of an association rule These measures state that s  of transactions in D contain A  B and c  of transactions that contain A also contain B  Another example refers to subjective measures Given an association rule the more it contradicts the user's prior knowledge the more novel thus the more interesting it is This paper focuses on objective measures summarized in Table I More discussions can be found in 5 6 7  9 10 11 12 13 16 17 18 19 Due to the overwhelming number of interestingness measures and their variety in pursuing the criteria which are often contradictory by nature interestingness measures highly di\013er in ranking association rules For instance Support  an objective measure assesses the reliability of association rules while Speci\014city  another objective measure focuses on the peculiarity of association rules Since reliability and peculiarity are two con\015icting criteria measures using them provide con\015icting results Thus an association rule may be ranked the best based on the 014rst measure but the worst based on the other Consequently selecting an appropriate measure to evaluate association rules is highly application-domain dependent In order to assess objective interestingness measures and select an appropriate one for a given application domain a set of properties is proposed These properties represent the requirements from an application domain The appropriate measure for a given application domain is selected based on how it ful\014lls various properties The next section explains these properties and illustrates the measures pursuing them III Properties for assessing measures Given an application domain and an association rule of the form A  B  appropriate objective measures are selected to evaluate association rules for an association mining task based on a set of properties as follows 017 P 1  This property represents that a rule occurred by chance has no interestingness value 10 017 P 2  This property states that when the support for A and B are 014xed the larger the value of support for A and B  the larger their interestingness value is  017 P 3  This property states that when the support for AB and B  A  respectively are 014xed the smaller the support for A  B  respectively the more interesting the association rule is 10 017 P 4  This property makes a distinction between measures evaluating rules A  B from those evaluating B  A  resulting in di\013erent interestingness values  10 12 14 017 P 5  This property states that if there is no counterexample to the rule interestingness stays constant 017 P 6  This property states that the growth of a database does not in\015uence interestingness value if the rate of A  A  B  or B is constant 6 10 12 14 017 P 7  This property states that having a slow decrease in the neighborhood of a logical rule rather than a fast or even linear decrease is desirable It re\015ects the tolerability of a few counterexamples without the loss of interest 10 017 P 8  This property states that the threshold to identify interesting measures from uninteresting ones should be easy to choose and change 10 017 P 9  This property states that a measure is able to express a comprehensive idea of rule interestingness according to three following factors easiness in its de\014nition value interpretation and comprehensibility for the user 6 10 14 017 P 10  This property refers to the interestingness value that changes its sign if either the rows or the columns of the contingency table of a rule are permuted  12 14 017 P 11  This property states that the interestingness value remains the same if both the rows and columns of the contingency table of the rule are permuted In fact this property is a special case of P 10 because permuting the rows columns causes the sign to change once and permuting the columns rows causes it to change back 10 12 017 P 12  This property states that interestingness has no relationship with the number of the records that do not contain A and B  Interestingness measures di\013er in pursuing the aforementioned properties as listed in Table I Value 1 or 0 in each cell in the table is to show if an interestingness measure ful\014lls the respective property or not 10 18  F or the sak e of space the list in T able I is only partial Other measures and their ful\014llments such as Accuracy  Leverage  Jaccard  etc are discussed in detail in  18 20 On the other hand eac h application domain requires its own characteristics and accordingly its own requirements on properties Thus it has been always a challenge to select a measure that well suits a given application domain The follo wing section discusses the strategies proposed in the literature to select appropriate interestingness measures IV Selecting interestingness measures The current approaches to assess and select appropriate measures take the following considerations into account 1 The measure assessment and selection are highly subjective They depend on the user's preferences her/his 
928 
928 


TABLE I Interestingness properties fulfilled by measures Interestingness measure P 1 P 2 P 3 P 4 P 5 P 6 P 7 P 8 P 9 P 10 P 11 P 12 Support 0 1 0 1 0 0 1 1 1 0 0 0 Con\014dence 0 1 0 0 1 0 1 1 1 0 0 0 Coverage 0 0 0 0 0 0 0 1 1 0 0 0 Prevalence 0 0 0 0 1 0 1 1 0 0 0 0 Recall 0 1 0 0 1 0 0 1 1 0 0 1 Speci\014city 0 0 0 0 0 0 0 1 1 0 0 0 Odds ratio 0 1 1 1 1 1 0 1 0 1 1 0 Yule's Q 1 1 1 1 1 1 0 1 1 1 1 0 Yule's Y 1 1 1 1 1 1 0 1 1 1 1 0 Piatetsky-Shapiro 1 1 1 1 0 0 1 1 1 1 1 1 domain knowledge and the application domain 2 The assessment and selection are driven by the user who might have various contradictory rational requirements resulting in inconsistencies in her/his speci\014cations 3 The user's requirements may change over time and accordingly the result of assessing and selecting measures may change as well and 4 The number of association rules grows given the growing volume of data An interestingness measure needs to be general enough to handle this growth The techniques proposed so far to select an appropriate interestingness measure fall into three categories based on the approach applied namely clustering methods  ranking methods  and multiple-criteria decision aid methods  Clustering methods  Clustering methods 11 cluster measures based on their similar properties For instance Tan et al  18 state that the higher the correlation b etween the properties of two measures the stronger the consistency between the measures As a result they are classi\014ed into one single class Clustering methods are objective since they categorize association rules based on their properties However there exist a few shortcomings about them These methods do not take the user's requirements into account and thus do not capture all the complexities that exist in her/his views in assessing measures For example although two measures might be clustered into a same class the user may consider that one measure is of more importance than the other Ranking methods  Ranking methods proposed by Sahar and T an et al  pro vide the user with a small subset of discovered rules for ranking Then this subset is assessed by objective measures Finally a measure whose ranking is the most similar to the user's ranking is selected as the appropriate measure These methods perform well on taking the user's requirements into account but they fail to avoid the user's incomplete and growing domain knowledge that may cause some inconsistencies in evaluating association rules In addition if the number of association rules is large selecting a suitable measure for a small subset may not be generalizable to the entire set of association rules Multiple-criteria decision aid methods  Multiple-criteria decision aid methods proposed by Lenca et al  select appropriate interestingness measures based on the user's objectives To take important criteria into account a few MCDA procedures have been used A preference function is presented to rank the desired properties and some weights are decided and assigned to them which are further used to assess the relative measures In this method the consistency and dynamic behavior of the user's requirements are not checked To remedy the shortcomings of the above methods we propose an assessment approach that not only considers the user's requirements represented by interestingness properties but also checks her/his consistency in property speci\014cations Moreover the approach is invariant to the growth of data volume and the number of association rules to be evaluated as shall be seen shortly V A revised Analytic Hierarchy Process The Analytic Hierarchy Process  AHP  for short is a multi-criterion decision making technique that was originally developed by Saaty Giv en an application domain to achieve maximally a goal that has multiple properties the user needs to prioritize i.e assigns importance to properties under a set of requirements This is essentially an optimization problem In practice the assignment process of preferences may introduce inconsistencies in property importance given for instance incomplete domain knowledge inconsistent requirements etc Moreover it is usually hard to conduct the importance assignment to individual properties given the requirements AHP provides a systematic and e\013ective way to tackle this complicated prioritization by quantifying subjective requirements A AHP details The 014rst step in AHP is to conduct pair-wise comparisons among properties For a set of n properties f P 1  P 2  P 3  001 001 001  P n g  of a given domain there are 000 n 2 001 comparisons For each comparison between two properties the user chooses a quantitative ratio value between them based on her/his qualitative requirements This way we encode qualitative domain-dependent requirements on the two properties into a quantitative value Since it is costly to conduct as many as 000 n 2 001 comparisons our work chooses a revised version of AHP in which properties are engaged in a chain-wise paired comparison  CPC  for short requiring only n 000 1 property compar 
929 
929 


TABLE II The importance values in CPC Scale Importance 1 Equal importance 3 Moderate importance 5 Essential or strong importance 7 Very strong importance 9 Extreme importance 2,4,6 Intermediate values TABLE III The CPC algorithm i R i D i I i  R i M i V i 1 W 1 W 2 D 1 D 1 Q D i D 1 n p Q D j n 000 1 Y i 1  R i M 1 P M j 2 W 2 W 3 D 2 D 2 Q D i D 2 n p Q D j n 000 1 Y i 2  R i M 2 P M j 001 001 001 001 001 001 001 001 001 001 001 001 001 001 n 000 1 W n 000 1 W n D n 000 1 D n 000 1 Q D i D n 000 1 n p Q D j  R n 000 1 M n 000 1 P M j n W n W 1 D n D n Q D i D n n p Q D j 1 M n P M j isons The ma jorit y of the follo wing discussions can also be found in But w e ha v e adapted it to 014t in to our problem context The revised AHP starts from the user-speci\014ed importance value denoted as weight  W i  for each property P i  where i  1  2  001 001 001  n  The user is invited based on her/his requirements on these properties to compare them in pairs and assign them importance ratio values A set of typical ratio values as suggested in is illustrated in Table II Note that seemingly arbitrary those values represent the relative importance among properties For instance if judged from a given application domain property P i is much more important than property P i 1 in selecting measures we would then assign their ratio as 7  1 As the user uses the approach more and more s/he would be more comfortable in deciding those relative ratios Let R i denote the ratio of the i th property to its successor We close the comparison chain with the ratio of the n th property to the 1st property This is represented in the following equation R i   W i W i 1 i  1      n 000 1 W n W 1 i  n 1 The value of R i between two properties is speci\014ed by the user based on her/his domain requirements It is easy to see that under perfect consistency of the speci\014cations the product of R i for all i should equal 1 n Y i 1 R i   W 1 W 2  W 2 W 3      W n W 1   1 2 Otherwise there is a certain degree of inconsistency This is exactly the situation where our approach needs to capture when the user tries to specify which properties are important and which are not based on her/his requirements for the given association mining task In order to do this two di\013erent values of R i are obtained direct or indirect  The direct value D i  is the value of W i that is directly expressed by the user whereas the indirect value I i  is the value computed relative to the other direct values i.e the reciprocal of the product of other D i s I i  D i Q n j 1 D j 3 Obviously I i is equal to W i W i 1 if a perfect consistency is achieved i.e Q n j 1 D j  1 A better estimation of R i  denoted by  R i  using the two di\013erent values D i and I i  is proposed using the weighted geometric mean of D i and I i  Calculation for  R i is shown by Equation 4  R i  D  n 000 1 n i 001 I 1 n i  D  n 000 1 n i 001  D i Q D j  1 n  D i 001 1 n p Q D j 4 The rationale behind Equation 4 is that since direct values are more important than indirect values each D i weighs  n 000 1 times more than I i  Also the geometric mean is used since we expect that the ratio changes occur in a relative way Note that we compare a pair of properties relatively i.e the importance of the property on the numerator relative to the one of the property on the denominator we can consider this ratio as a percentage After introducing  R i  every direct value D i is treated equally in the derivation process It is noted that while R i s are inconsistent in practice  R i s are perfectly consistent i.e Q n i 1  R i  1 Since  R i s are perfectly consistent the weight for each interestingness property relative to the n th property M i  W i M n  can be determined from  R i  The weight of the n th property relative to itself is 1 i.e M n  1 The following recursion represents this calculation M i  8     n 000 1 Y i  R i i  n 000 1      1 1 i  n 5 Finally the normalized relative weights V i  for each of the interestingness properties P i  are obtained by Equation 6 The values of V i s represent the priority of the relative property V i  M i P n j 1 M j 6 The whole CPC algorithm is summarized in Table III  
930 
930 


B Measure of consistency Consistency for chain-wise comparisons can be measured by the quantity Q R i  which when not equal to 1 shows a certain degree of inconsistency In practice some degree of inconsistency is unavoidable As pointed out in there are t w o t yp es of consistencies ordinal and cardinal  Ordinal consistency is maintained as long as the correct order of the interestingness properties is maintained Cardinal consistency is more strict and requires that the importance values for all comparisons assigned by the user be correct W e will discuss more on the cardinal consistency after the ordinal consistency The ordinal consistency is easily checked by comparing the magnitude of I i to its corresponding D i  i.e the pair  I i  D i  The ordinal consistency is achieved if both I i and D i are of the same magnitude i.e both I i and D i are larger than or equal to 1 or both are smaller or equal to 1 The cardinal consistency of the estimations is checked using the following equation as introduced before n Y i 1 R i  1 7 Full consistency is achieved if Equation 7 is satis\014ed However it is hard to achieve full consistency given the uncertainty in the user's requirements for a given association rule mining task Practically a consistency level more than 90 is acceptable During the above process if any consistency violation occurs the user should be noti\014ed to reevaluate the entire property pair-wise comparisons VI AHP-based measure assessment method Our AHP-based measure assessment  AHPMA  for short approach quantitatively prioritizes the user's subjective requirements It includes the following four basic steps 1 Present properties to the user 2 Invite the user to rate the properties 3 Assess the ratings and prioritize the properties 4 Assess property ful\014llment by each interestingness measure A Presenting properties The set of 12 properties P 1  P 2  001 001 001  P 12 are presented to the user B Rating properties Using chain-wise paired comparisons discussed in Section V the user assigns weights to the above properties in pairs based on their importance in her/his requirements for the given association mining task For instance based on the requirements if the ratio of P 1 to P 2 is 4  3 it states that P 1 is 4  3 more important than P 2  C Assessing and prioritizing properties The algorithm in Table III is employed to calculate the relative weight vector This vector represents the prioritized properties The most important property gains the maximum weight and the least important property gains the minimum weight Since some properties gain extremely small weights in comparison to other properties the e\013ect of leaving them out setting them to zero from further consideration is negligible Thus the weights V j  of the remaining properties are adjusted to obtain the adjusted weights  denoted as AW  V j  AW  V j   V j P n i 1 V i  1 024 j 024 n 8 where n is the number of interestingness properties D Assessing property ful\014llment Considering the prioritized properties the measures are assessed For each measure  M i  its overall composite weight  denoted as CW  M i  is computed based on the adjusted weights AW  P j  discussed in the previous step using CW  M i   P j AW  P j  001 C  i j  where C  i j  represents whether measure i ful\014lls property j as indicated by 1 or not as indicated by 0 VII Case studies It would be bene\014cial to apply our approach to a given association mining task in a real-life application to assess interestingness measures However this would entail considerable organizing and expenses Under the current circumstances of the limited resources available to us we follow the same experiment scheme designed and used in  for measure selection approac hes In our experiments we have designed two case studies to simulate measure selections using our approach Each case involves a set of properties that the user desires to have when assessing interestingness measures re\015ecting her/his domain-speci\014c requirements for a given association mining task It should be noted that though we are conducting simulations in our work the application process of our approach should be readily generalized and made use of in reality A Case one This case is presented to illustrate the application of our approach in assessing interestingness measures where the user provides consistent speci\014cations on interestingness properties The following scenarios are required in this case Scenario 1  Reliability of results is required Thus less counterexamples to an association rule are desired Scenario 2  A selected measure should be easily comprehensible by the user Scenario 3  The number of the transactions including neither A nor B should not a\013ect the interestingness of an association rule Scenario 4  Given the reliability requirement association rules happening by accident should be avoided Scenario 5  Rules of the form A  B and B  A should di\013er in their interestingness values Not all the interestingness measures are useful to pursue these requirements Using our method the 12 properties 
931 
931 


TABLE IV Consistent property specifications for the scenarios of case one i R i D i I i  R i M i V i 1 W 1 W 2 9  2  4  500 4  821 4  527 0  623 0  136 2 W 2 W 3 3  2  1  500 1  608 1  509 0  138 0  030 3 W 3 W 4 2  8  0  250 0  268 0  252 0  091 0  020 4 W 4 W 5 8  3  2  667 2  858 2  683 0  363 0  079 5 W 5 W 6 2  2  1  000 1  072 1  006 0  135 0  030 6 W 6 W 7 2  8  0  250 0  268 0  252 0  134 0  029 7 W 7 W 8 8  3  2  667 2  858 2  683 0  534 0  117 8 W 8 W 9 2  8  0  250 0  268 0  252 0  199 0  044 9 W 9 W 10 7  2  3  500 3  751 3  521 0  792 0  173 10 W 10 W 11 2  3  0  667 0  715 0  671 0  225 0  049 11 W 11 W 12 3  9  0  333 0  357 0  335 0  335 0  073 12 W 12 W 1 8  5  1  600 1  715 1  610 1  000 0  219 are prioritized and weighed based on the above scenarios For example the ratio of P 1 to P 2 is set to be 9 to 2 given the importance of P 1 based on Scenario 4 Moreover the ratio of P 7 to P 8 is set to be 8 to 3 given the importance of P 7 based on Scenario 1 The rest of the weights are assigned according to the above scenarios Table IV illustrates the results Column D i represents the ratio values speci\014ed by the user according to the scenarios Both the ordinal and cardinal consistency as explained in Section B for this prioritization are calculated Ordinal consistency is checked by pairs  I i  D i  It is seen that the two corresponding columns all have the same magnitude Thus ordinal consistency is achieved Then cardinal consistency is checked using Equation 7 and the result is 0  933 which is acceptable The last column shows the priority vector of the 12 properties Since the weights for P 2  P 3  P 5  P 6  P 8  and P 10 are very small we will not include them for further calculation Thus only the properties P 1  P 4  P 7  P 9  P 11  and P 12 are considered and using Equation 8 their corresponding weights are adjusted P 12 i 1 V i  0  798 As a result AW  P 1   0  171 AW  P 4   0  099 AW  P 7   0  147 AW  P 9   0  217 AW  P 11   0  092 and AW  P 12   0  274 Under the seven selected properties with their adjusted weights the objective measures are examined with the aim to choose the most appropriate one as illustrated in Table V The rows represent the candidate measures while the columns represent the selected properties For instance the composite weight for Support is computed as follows CW  Support   0  463 As shown in Table V the measure P iatetsky 000 Shapiro  which is of the highest composite weight is chosen B Case two This case is presented aiming at explaining occurrence of inconsistency in the user's property importance speci\014cation Taking the following scenarios into account the user is asked to rank the properties Scenario 1  Accidental rules have no interestingness value TABLE VI Inconsistent property specifications for the scenarios of case two i R i D i I i 1 W 1 W 2 4  2  2  000 0  056 2 W 2 W 3 8  2  4  000 0  112 3 W 3 W 4 5  2  2  500 0  070 4 W 4 W 5 4  6  0  667 0  019 5 W 5 W 6 3  2  1  500 0  042 6 W 6 W 7 8  7  1  143 0  032 7 W 7 W 8 4  7  0  571 0  016 8 W 8 W 9 7  3  2  333 0  066 9 W 9 W 10 1  2  0  500 0  014 10 W 10 W 11 3  2  1  500 0  042 11 W 11 W 12 6  3  2  000 0  056 12 W 12 W 1 7  9  0  778 0  022 Scenario 2  Since novelty is an important property association rules with less frequent items in the antecedent and consequent are considered more interesting Scenario 3  The size of the database may enlarge over time Interestingness of a rule should be invariant to this change Scenario 4  Interestingness criteria may change over time thus interestingness threshold should easily change considering new criteria Scenario 5  Interestingness value changes upon row or column permutations Scenario 6  Interestingness value stays the same upon both row and column permutation Considering the ratios provided by the user in Table VI for i  1  2  3  5  6  8  10 and 11 one 014nds that the magnitude of I i di\013ers from the one of the corresponding D i  Thus the ordinal consistency is violated Moreover the value of cardinal consistency is calculated using Equation 7 with a value of 35  56 which is not acceptable As a result the ranking is cardinally inconsistent too This inconsistency has occurred due to violating the transitivity in is greater than relation 1 in the user's property preferences The speci\014cations state that P 6 is more preferred than P 7  P 7 is more preferred than P 5  and P 5 is more important than P 6  which contradicts the transitivity in the user's preferences Consequently the user is asked to reevaluate the properties for their importance values It should be noted that this process may need to repeat several times until both types of consistency are passed We show one set of consistent speci\014cations on the twelve properties in Table VII Given the same magnitudes of all the pairs  I i  D i  the ordinal consistency is met In addition the cardinal consistency which is equal to 0  957 according to Equation 7 is obtained Column V i shows the priority of the properties Only P 1  P 2  P 3  P 5  P 6  P 8  P 10  and P 11 are taken into account in this case Since the weights for P 4  P 7  P 9 and P 12 are very small they are neglected for further considerations The adjusted weights of the other properties are computed as follows P 12 i 1 V i  0  822 AW  P 1   0  196 1 A relation  is called transitive if for P  Q  and R  P  Q and Q  R  then P  R  otherwise it is intransitive 
932 
932 


TABLE V Composite weights for measures based on property importance for case one Interestingness Measures P 1 P 4 P 7 P 9 P 11 P 12 CW 0  171 0  099 0  147 0  217 0  092 0  274 Support 0 1 1 1 0 0 0  463 Con\014dence 0 0 1 1 0 0 0  364 Coverage 0 0 0 1 0 0 0  217 Prevalence 0 0 1 0 0 0 0  147 Recall 0 0 0 1 0 1 0  491 Speci\014city 0 0 0 1 0 0 0  217 Odds ratio 0 1 0 0 1 0 0  191 Yule's Q 1 1 0 1 1 0 0  579 Yule's Y 1 1 0 1 1 0 0  579 Piatetsky-Shapiro 1 1 1 1 1 1 1  000 TABLE VII Consistent property specifications for the scenarios of case two i R i D i I i 026 R i M i V i 1 W 1 W 2 8  3  2  667 2  788 2  678 3  496 0  161 2 W 2 W 3 3  8  0  375 0  392 0  377 1  305 0  060 3 W 3 W 4 7  2  3  500 3  657 3  514 3  467 0  159 4 W 4 W 5 2  3  0  667 0  697 0  670 0  987 0  045 5 W 5 W 6 4  6  0  667 0  697 0  670 1  473 0  068 6 W 6 W 7 8  3  2  667 2  787 2  678 2  200 0  101 7 W 7 W 8 3  7  0  429 0  448 0  431 0  822 0  038 8 W 8 W 9 7  4  1  750 1  829 1  757 1  908 0  088 9 W 9 W 10 3  7  0  429 0  448 0  431 1  086 0  050 10 W 10 W 11 5  3  1  667 1  742 1  674 2  521 0  116 11 W 11 W 12 3  2  1  500 1  567 1  506 1  506 0  069 12 W 12 W 1 2  7  0  286 0  299 0  287 1  000 0  046 AW  P 2   0  073 AW  P 3   0  193 AW  P 5   0  083 AW  P 6   0  123 AW  P 8   0  107 AW  P 10   0  141 and AW  P 11   0  084 Under the eight selected properties with their adjusted weights the objective measures and their properties are examined As shown in Table VIII the measures Y ule 0 s Q and Y ule 0 s Y are chosen since they ful\014ll the majority of the properties with the highest composite weight VIII Different measure assessment methods The other measure selection approaches proposed so far namely the clustering methods CM the ranking methods RM and the multiple-criteria decision aid methods MCDA as discussed in Section IV aim at pursuing the following characteristics 9 11 12 14 C 1  Taking the user's preferences into account  7  10 11 12 The user should pro vide enough information on what rules are considered interesting C 2  Avoiding inconsistencies in the user's decisions  The user may be inconsistent in providing inputs A selection strategy should deal with those inconsistencies C 3  Adapting to the varying user's requirements  8  A selection strategy should b e able to adapt itself with the user's dynamic requirements C 4  Invariant to the number of association rules  11 An appropriate selection strategy should not be a\013ected by TABLE IX Measure assessment approaches and their characteristics Characteristics CM RM MCDA AHPMA C 1 003 003 003 C 2 003 C 3 C 4 003 003 003 the number of association rules These approaches di\013er in ful\014lling the above characteristics as shown in Table IX A symbol  003  is used to represent the satisfaction of the characteristics by the respective measures Since clustering methods CM classify measures based on either their properties or association rules they do not take the user's preferences into account and accordingly do not conduct consistency checking Furthermore because they focus on properties they are invariant to the number of association rules 11 Th us they are only mark ed on C 4  Ranking methods RM provide the user with a small subset of discovered rules for ranking Thus it is marked on C 1  However if the number of association rules is large selecting a suitable interestingness measure for them may be problematic To make it worse given the user's incomplete and growing domain knowledge there might be some inconsistencies in ranking association rules 14 Multiple-criteria decision aid methods MCDA perform the selection based on the user's objectives and a few MCDA procedures The consistency of the user's requirements is not checked Moreover it does not pay attention to dynamic changes in the user's requirements 11 Our proposed method AHPMA takes the user's requirements into account and detects any inconsistencies in her/his speci\014cations In addition it is not in\015uenced by the number of association rules i.e the time complexity of our method only depends on the number of properties under consideration and is invariant to the size of the data set and the number of association rules mined But like the other three methods it is not able to adapt itself to the user's dynamic requirements 
933 
933 


TABLE VIII Composite weights for measures based on property importance of case two Interestingness Measures P 1 P 2 P 3 P 5 P 6 P 8 P 10 P 11 CW 0  196 0  073 0  193 0  083 0  123 0  107 0  141 0  084 Support 0 1 0 0 0 1 0 0 0  180 Con\014dence 0 1 0 1 0 1 0 0 0  263 Coverage 0 0 0 0 0 1 0 0 0  107 Prevalence 0 0 0 1 0 1 0 0 0  190 Recall 0 1 0 1 0 1 0 0 0  263 Speci\014city 0 0 0 0 0 1 0 0 0  107 Odds ratio 0 1 1 1 1 1 1 1 0  804 Yule's Q 1 1 1 1 1 1 1 1 1  000 Yule's Y 1 1 1 1 1 1 1 1 1  000 Piatetsky-Shapiro 1 1 1 0 0 1 1 1 0  794 IX Conclusions Our main contribution in this paper is a novel approach to assess interestingness measures for association rules Our approach is independent to the number of association rules and assesses the measures based on a set of user's requirements We attribute this to the analytic hierarchical process AHP Some initial case studies are presented to show the e\013ectiveness of our approach It is also noted that none of the measure assessment methods so far deals with the dynamic behavior of the user's requirements In other words these methods must be reapplied in case of changes in the user's behavior In our future work we will attempt to dynamically evaluate association rules according to a collective e\013ect of multiple measures while taking the user's requirements and feedbacks into consideration Acknowledgment The work reported is partially supported by NSERC Canada We also thank Dr Hadi Kharaghani for his comments and 014nancial support References  J Han and M Kamber Data Mining Concepts and Techniques  2nd ed San Francisco CA USA Morgan Kaufmann Publishers Inc 2006  R Agrawal and R Srikant Fast algorithms for mining association rules in large databases in VLDB 94 Proceedings of the 20th International Conference on Very Large Data Bases  San Francisco CA USA Morgan Kaufmann Publishers Inc 1994 pp 487{499  R J Hilderman and H J Hamilton Evaluation of interestingness measures for ranking discovered knowledge in Lecture Notes in Computer Science  vol 2035 Springer-Verlag 2001 pp 247{259  P Lenca P Meyer B Vaillant and S Lallich On selecting interestingness measures for association rules User oriented description and multiple criteria decision aid European Journal of Operational Research  vol 184 no 2 pp 610{626 2008  B Liu W Hsu S Chen and Y Ma Analyzing the subjective interestingness of association rules IEEE Intelligent Systems and their Applications  vol 15 no 5 pp 47{55 2000  O Maimon and L Rokach Data Mining and Knowledge Discovery Handbook  Springer-Verlag New York Inc 2005  B Padmanabhan and A Tuzhilin Unexpectedness as a measure of interestingness in knowledge discovery Decision Support Systems  vol 27 no 3 pp 303{318 1999  A Silberschatz and A Tuzhilin What makes patterns interesting in knowledge discovery systems IEEE Transactions on Knowledge and Data Engineering  vol 8 no 6 pp 970{974 1996  B Vaillant P Lenca and S Lallich A clustering of interestingness measures in Lecture Notes in Computer Science  vol 3245 Springer Berlin/Heidelberg 2004 pp 290{297  L Geng and H J Hamilton Choosing the right lens 014nding what is interesting in data mining in Quality Measures in Data Mining  Springer Berlin  Heidelberg 2007 vol 43 pp 3{24  P Lenca B Vaillant P Meyer and S Lallich Quality Measures in Data Mining  ser Studies in Computational Intelligence Springer Berlin/Heidelberg 2007 vol 43 ch Association Rule Interestingness Measures Experimental and Theoretical Studies pp 51{76  S Sahar Interestingness via what is not interesting in KDD 99 Proceedings of the Fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining  New York NY USA ACM 1999 pp 332{336  A A Freitas On rule interestingness measures Elsevier Science  no 3 pp 309{315 1999  P Tan V Kumar and J Srivastava Selecting the right interestingness measure for association patterns in Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining  Edmonton Alberta Canada ACM 2002 pp 32{41  R Agrawal T Imieli\023nski and A Swami Mining association rules between sets of items in large databases in Proceedings of the International Conference on Management of Data  New York NY USA ACM 1993 pp 207{216  M Klemettinen H Mannila P Ronkainen H Toivonen and A I Verkamo Finding interesting rules from large sets of discovered association rules in Proceedings of the Third International Conference on Information and Knowledge Management  New York NY USA ACM 1994 pp 401{407  E R Omiecinski Alternative interest measures for mining associations in databases IEEE Transactions on Knowledge and Data Engineering  vol 15 no 1 pp 57{69 2003  P Tan V Kumar and J Srivastava Selecting the right objective measure for association analysis Information System  vol 29 no 4 pp 293{313 2004  Y Zhao C Zhang and S Zhang Discovering Interesting Association Rules by Clustering  Springer Berlin  Heidelberg 2004  Y Zhang L Zhang G Nie and Y Shi A survey of interestingness measures for association rules Business Intelligence and Financial Engineering International Conference on  vol 0 pp 460{463 2009  R J B Jr and R Agrawal Mining the most interesting rules in Proceedings of the International Conference on Knowledge Discovery and Data Mining  ACM 1999 pp 145{154  T L Saaty The Analytic Hierarchy Process Planning priority setting resource allocation  New York and London McGrawHill International Book Co 1980  J W Ra Chainwise paired comparisons Decision Sciences  vol 30 pp 581{599 1999  P Wallin J Froberg and J Axelsson Making decisions in integration of automotive software and electronics A method based on ATAM and AHP in SEAS 07 Proceedings of the Fourth International Workshop on Software Engineering for Automotive Systems  Washington DC USA IEEE Computer Society 2007 
934 
934 


9] J.Han. M.Kamber. Data Mining: Concepts and Techniques, 2nd edition, Morgan Kaufmann, 2006 10] Blaschke, C. and A.Valencia\(2002 from the literature, Genome Informatics. 13,201-213  118 


And put forward that we could use confidence, category homoplasy and relevancy strength to improve the quality of feature extension modes. We also verified that confidence category homoplasy and relevancy strength are effective through our experiments. In the same time we have drawn the following conclusions: \(1 relationships for short-text can improve their classification performance; \(2 effectiveness of information in the feature extension mode library we should choose the suitable thresholds; \(3 information is too small to meet the demand of short-text feature extension. So we should find out a perfect method which can increase information coverage in the feature extension mode library for short-text classification; \(4 extension library for short-text extension effectively, i.e., choosing a perfect feature extension strategy is also our further work ACKNOWLEDGMENT The research is supported in part by the National Natural Science Foundation of China under grant number 60703010 the Nature Science Foundation of Chongqing province in China under grant number CSTC, 2009BB2079, and the Scientific Research Foundation for the Returned Overseas Chinese Scholars of Ministry of Education of China under grant number [2007] 1109 REFERENCES 1] Fabrizio Sebastiani.Machine Learning in Automated Text Categorization, A.ACM Computing Surveys, C.2002.34\(1 2] Fan Xing-hua,Wang peng. Chinese Short-Text Classification in TwoStep, J.Journal of DaLian Maritime Universtiy, 2008,11\(2 3] Zelikovitz S. and Hirsh H. Improving Short Text Classification Using Unlabeled Background Knowledge to Assess Document Similarity C. In: Proceedings of ICML-2002, 2002, 1183-1190 4] Wang Xi-wei,Fan Xing-hua and Zhao Jun. A Method for Chinese Short Text Classification Based on Feature Extension, J.Journal of Computer Applications,2009,29\(3 5] JIAWEI HAN,JIAN PEI ,YIWEN YIN, BUNYING MAO.Ming Frequent Patterns without Candidate Generation:A Frequent-Pattern Tree.Data Mining and Knowledge Discovery,2004,8:53-87 6] Liu Fei. Huang Xuan-qing and Wu Li-de.Approach for Extracting Thematic Terms Based on Association Rule, J.Computer Engineering,2008\(4 7] Xinhua Fan, Jianyun Nie. Link Distribution Dependency Model for 


Document Retrieval, C.Journal of Information and Computational Science6:3\(2009  90 


shows that proposed post mining of association rule mining technique for missing sensor data estimation is an area worth to explore REFERENCES 1] Agrawal, R., & Imielinski, T., & Swami, A., "Mining association rules between sets of items in massive databases", International Conference on Management of Data, 1993 2] Austin, F. I., "Austin Freeway ITS Data Archive", Retrieved January 2003 from http://austindata.tamu.eduidefauIt.asp 3] Bastide, Y., & Pasquier, N., & Taouil, R, & Stumme, G., & Lakhal L., "Mining minimal non-redundant association rules using frequent closed itemsets", First International Conference on Computational Logic, 2000 4] Cool, A. L., "A review of methods for dealing with missing data The Annual Meeting of the Southwest Educational Research Association, 2000 5] Deshpande, A., & Guestrin C., & Madden, S., "Using probabilistic models for data management in acquisitional environments", The Conference on Innovative Data Systems Research, 2005 6] Halatchev, M., & Gruenwald, L., "Estimating missing values in related sensor data streams", International Conference on Management of Data, 2005 7] Iannacchione, V. G., "Weighted sequential hot deck imputation macros", Proceedings of the SAS Users Group International Conference, 1982 8] Nan Jiang, "Discovering Association Rules in Data Streams Based On Closed Pattern Mining", SIGMOD Ph.D. Workshop on Innovative Database Research, 2007 9] Li, Y., & Liu, Z. T., & Chen, L., & Cheng, W., & Xie, C.H Extracting minimal non-redundant association rules from QCIL The 4th International Conference on Computer and Information Technology, 2004 10] Little, R 1. A., & Rubin, D. B., "Statistical analysis with missing data", New York: John Wiley and Sons, 1987 II] McLachlan, G., & Thriyambakam, K., "The EM algorithm and extensions", New York: John Wiley & Sons, 1997 12] Mitchell, T., "Machine Learning", McGraw Hill, 1997 13] Papadimitriou, S., & Sun, 1., & Faloutsos, C., "Streaming pattern discovery in multiple time-series", The International Conference on Very Large Databases, 2005 14] Rubin, D., "Multiple imputations for nonresponce in surveys", New York: John Wiley & Sons, 1987 


15] Shafer, 1., "Model-Based Imputations of Census Short-Form Items In Proceedings of the Annual Research Conference, 1995 16] Taouil, R., & Pasquier, N., & Bastide, Y., & Lakhal, L., "Mining bases for association rules using closed sets", International Conference on Data Engineering, 2000 17] Wilkinson & The AP A Task Force on Statistical Inference, 1999 18] Zaki, M. 1., Hsiao, C. 1., "Efficient algorithms for mining closed itemsets and their lattice structure", IEEE Transactions on Knowledge and Data Engineering, 2005 V5-106 


General Chair f!!\f  Organizing Chairs  f!!\f  f$% \f!!\f  Organizing Co-chairs f    f  f\f   f\f\f   f*!\f!\f.\f  f f  Program Committee Chairs  f\f\f   f!!\f  Publication Chair 0   


200 250 300  The size of dataset/10,000 R es po ns e tim e S    a 0 50 100 150 200  The size of dataset/10,000 R es po ns e tim e S    b 0 10 20 30 40 50 


60  The size of dataset/30,000 R es po ns e tim e S    c Fig. 9 The scalability of our algorithm compared with FP-growth  Paper [12] proposed a way to reduce times of scanning transaction database to reduce the cost of I/O IV. CONCLUSIONS AND FUTURE WORK This paper first discusses the theory of foundations and association rules and presents an association rules mining algorithm, namely, FP-growth algorithm. And then we propose an improved algorithm IFP-growth based on many association rules mining algorithms. At last we implement the algorithm we propose and compare it with algorithm FPgrowth algorithm. The experimental evaluation demonstrates its scalability is much better than algorithm FP-growth 177 Now, lets forecast something we want to do someday Firstly, we would parallelize our algorithm, because data mining needs massive computation, and a parallelable environment could high improve the performance of the algorithm; Secondly, we would apply our algorithm on much more datasets and study the run performance; At last, we would study the performance when the algorithm deal with other kinds of association rules  REFERENCES 1] S. Sumathi and S. N. Sivanandam. Introduction to Data Mining and its Applications, Springer, 2006 2] V. J. Hodge, J. Austin, A survey of outlier detection 


methodologies, Artificial Intelligence Review, 2004, 22 85-126 3] Han, J. and M. Kamber. Data Mining: Concepts and Techniques. Morgan Kaufmann, San. Francisco, 2000 4] Jianchao Han, Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases, Journal of Advanced Computational Intelligence and Intelligent Informatics 2006, 10\(3 5] Jiuyong Li, Hong Shen, Rodney Topor. Mining Informative Rule Set for Prediction. Journal of Intelligent Information Systems, 2004, 22\(2 6] Jianchao Han, and Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases. Journal of Advanced Computational Intelligence, 2006, 10\(3 7] Doug Burdick, Manuel Calimlim, Jason Flannick Johannes Gehrke, Tomi Yiu. MAFIA: A Maximal Frequent Itemset Algorithm. IEEE Transactions on Knowledge and Data Engineering, 2005, 17\(11 1504 8] Assaf Schuster, Ran Wolff, Dan Trock. A highperformance distributed algorithm for mining association rules. Knowledge and Information Systems, 2005, 7\(4 458-475 9] Mohammed J. Zaki. Mining Non-Redundant Association Rules. 2004, 9\(3 10] J.Han, J.Pei, Y.Yin, Mining frequent patterns without candidate generation, Proceedings ACM SIGMOD 2000 Dallas, TX, May 2000: 1-12 11] P.Viola, M.Jones. Rapid Object Detection Using A Boosted Cascade of Simple Features. Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 2001 12] Anthony K. H. Tung, Hongjun Lu, Jiawei Han, Ling FengJan. Efficient Mining of Intertransaction Association Rules. 2003, 154\(1 178 


For each vertex b in g form j forests body\(a, g, i s.t. bodyAnt\(a, g, i a, g, i with itemsets Ant\(b b and each subset of itemsets Ant\(b b in P\(a, g, j Assign to each leaf l of trees bodyAnt\(a, g, i bodyCons\(a, g, i a fresh variable Vm,M, m, M = size\(itemset\(l Assign to each leaf l of tree headAnt\(a, g, j the variable assigned to itemset l in some leaf of some tree bodyCons\(a, g, i TABLE II.  EXPERIMENTAL DATA Conf. #rules #pruned #dftrs PtC 0.5 6604 2985 1114 0.6 2697 2081 25 0.75 1867 1606 10 0.8 1266 1176 0 0.95 892 866 1 0.98 705 699 1 DSP 0.5 2473 1168 268 0.6 1696 869 64 0.75 1509 844 89 0.8 1290 1030 29 0.95 1032 889 15 0.98 759 723 1 Arry 0.5 770 492 82 0.6 520 353 60 0.75 472 327 39 0.8 408 287 22 0.95 361 255 25 0.98 314 243 30  Our induction algorithm has been launched for each combination of thresholds. Our scheme eliminates all redundant rules in the sense of [25, 31], i.e. those association rules that are not in the covers. All the meta-rule deductive schemes implicitly included in [25] and [31] are induced by our method. The percentage of pruning, thus, outperforms [25 


The results produced for k=3, support 0.25 and confidences between 0.7 and 0.99 are shown in Fig. 3, in terms of pruning percentage \(vertical axis when applied to low confidences \(from 0.7 to 0.9 The percentage of pruning achieved diminishes as the confidence is superior to 0.9. Nevertheless, the pruning is effective with confidence of 0.99 in the majority of cases Pruning at Support = 0.25 0,00 5,00 10,00 15,00 20,00 25,00 30,00 35,00 40,00 45,00 50,00 0,7 0,8 0,9 0,95 0,99 Confidence P ru n in g L e v e l Case 1 Case 2 Case 3  Figure 3.  Pruning experiences at support 0.25  V. DISCUSSION AND CHALLENGES It is important to discuss the technique presented here with focus on the purpose the technique pursues:  to produce semantic recommendation The reader should have noticed that the algorithm presented 


relies strongly on "choice". For instance, the algorithm chooses ears in the graph to form an order for elimination, and the choice is arbitrary. This strategy is essential to maintain low complexity \(polynomial practical. Nevertheless, a warned reader may conclude that this arbitrary choice implies that there are many compactions to produce and therefore the approach as a whole does not show to produce an optimal solution. And the reader is right in this conclusion. Since the goal is compaction, the search for an optimal solution can be bypassed provided a substantial level of pruning is achieved To complete the whole view, we describe how web service descriptions are complemented with the association rules as recommendations. In effect, under our scheme, the document describing the web service is augmented with a set of OWL/RDF/S triples that only incorporate the non-pruned rules with the format of Example 1, that is, the set ARmin of the compaction program obtained by our algorithm, together with the thresholds applied to the mining process and a registered URI of a registered description service. The assumptions and defeaters are not added to the web service description. If the associations encoded in the triples are not sufficient for the client \(a search engine, for instance widening of the response to the description service identified by the given URI, and then the assumptions and defeaters are produced. The reasoning task required for deriving all the implicitly published rules is client responsibility Notice that, under this scheme, the actual rules that appear as members of the set initial ARmin set are irrelevant; the only important issue is the size of the set The developed scheme also supports an extension of the algorithm that admits the assignment of priorities to rules and to itemsets, in order to allow the user to produce a more controlled program as output. Nonetheless, the importance of the extension has not been already tested, and therefore it is beyond the subject of the present paper It would be also interesting to design a scheme that supports queries where the client provides an itemset class and values for support and confidence and the engine produces a maximal class of inferred associated itemsets as a response. This scheme is also under development, so we have not discussed this aspect here 


VI. CONCLUSION In this paper, we have presented a defeasible logic framework for managing associations that helps in reducing the number of rules found in a set of discovered associations. We have presented an induction algorithm for inducing programs in our logic, made of assumption schemas, a reduced set of association rules and a set of counter-arguments to conclusions called defeaters, guaranteeing that every pruned rule can be effectively inferred from the output. Our approach outperform those of [17], because all reduction compactions presented there can be expressed and induced in our framework, and several other patterns, particular to the given datasets, can also be found. In addition, since a set of definite clauses can be obtained from the induced programs, the knowledge obtained can be modularly inserted in a richer inference engine Abduction can be also attempted, asking for justifications that explain the presence of certain association in the dataset The framework presented can be extended in several ways Admitting defeaters to appear in the head of assumption, to define user interest Admitting arithmetic expressions within assumptions for adjustment in pruning Admitting set formation patterns as itemset constants Extending the scope, to cover temporal association rules REFERENCES 1]  R. Agrawal, and R. Srikant: Fast algorithms for mining association rules In Proc. Intl Conf. Very Large Databases. \(1994 2]  A. V. Aho, J. E. Hopcroft, J. Ullman. The design and analysis of computer algorithms, Addison-Wesley, 1974 3]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher, A. Rock: A Family of Defeasible Reasoning Logics and its Implementation. ECAI 2000: 459-463 4]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher: Representation results for defeasible logic. ACM Trans. Comput. Log. 2\(2 2001 5]  A. Basel, A. Mahafzah, M. Al-Badarneh: A new sampling technique for association rule mining, Journal of Information Science, Vol. 35, No. 3 358-376 \(2009 6]  R. Bayardo and R. Agrawal: Mining the Most Interesting Rules. In Proc of the Fifth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 145-154, \(1999 


7]  R. Bayardo, R. Agrawal, and D. Gunopulos: Constraint-based Rule Mining in Large, Dense Databases. Data Mining and Knowledge Discovery Journal, Vol. 4, Num-bers 2/3, 217-240. \(2000 8]  A. Berrado, G. Runger: Using metarules to organize and group discovered association rules. Data Mining and Knowledge Discovery Vol 14, Issue 3. \(2007 9]  S. Brin, R. Motwani, J. Ullman, and S. Tsur: Dynamic itemset counting and implication rules for market basket analysis. In Proc. ACMSIGMOD Intl Conf. Management of Data. \(1997 10] L. Cristofor and D.Simovici: Generating an nformative Cover for Association Rules. In ICDM 2002, Maebashi City, Japan. \(2002 11] Y. Fu and J. Han: Meta-rule Guided Mining of association rules in relational databases. In Proc. Intl Workshop on Knowledge Discovery and Deductive and Object-Oriented Databases. \(1995 12] B. Goethals, E. Hoekx, J. Van den Bussche: Mining tree queries in a graph. KDD: 61-69. \(2005 13] G. Governatori, D. H. Pham, S. Raboczi, A. Newman and S. Takur: On Extending RuleML for Modal Defeasible Logic. RuleML, LNCS 5321 89-103. \(2008  14] G. Governatori and A. Stranieri. Towards the application of association rules for defeasible rules discovery In Legal Knowledge and Information Systems, JURIX, IOS Press, 63-75. \(2001 15] J. Han, J. Pei and Y. Yin: Mining frequent patterns without candidate generation. In Proc. ACM-SIGMOD Intl Conf. Management of Data 2000 16] C. Hbert, B. Crmilleux: Optimized Rule Mining Through a Unified Framework for Interestingness Measures. DaWaK: LNCS 4081, 238247. \(2006 17] E. Hoekx, J. Van den Bussche: Mining for Tree-Query Associations in a Graph. ICDM 2006: 254-264 18] R. Huebner: Diversity-Based Interestingness Measures For Association Rule Mining. Proceedings of ASBBS Volume 16 Number 1, \(2009 19] B. Johnston, Guido Governatori: An algorithm for the induction of defeasible logic theories from databases. Proceedings of the 14th Australasian Database Conference, 75-83. \(2003 20] P. Kazienko: Mining Indirect Association Rules For Web Recommendation. Int. J. Appl. Math. Comput. Sci., Vol. 19, No. 1, 165 186. \(2009 21] M. Klemettinen, H. Mannila, P. Ronkainen, H. Toivonen, and A Verkamo: Finding interesting rules from large sets of discovered association rules. In Proc. 3rd Intl Conf. on Information and Knowledge 


Management. \(1994 22] M. J. Maher, A. Rock, G. Antoniou, D. Billington, T. Miller: Efficient Defeasible Reasoning Systems. International Journal on Artificial Intelligence Tools 10\(4 2001 23] C. Marinica, F. Guillet, and H. Briand: Post-Processing of Discovered Association Rules Using Ontologies. The Second International Workshop on Domain Driven Data Mining, Pisa, Italy \(2008 24] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal: Closed sets based discovery of small covers for association rules. In Proc. BDA'99 Conference, 361-381 \(1999 25] N. Pasquier, R. Taouil, I. Bastide, G. Stume, and  L. Lakhal: Generating a Condensed Representation for Association Rules. In Journal of Intelligent Information Systems, 24:1, 29-60 \(2005 26] P. Pothipruk, G. Governatori: ALE Defeasible Description Logic Australian Conference on Artificial Intelligence.  110-119 \(2006 27] J. Sandvig, B. Mobasher Robustness of collaborative recommendation based on association rule mining, Proceedings of the ACM Conference on Recommender Systems \(2007 28] W. Shen, K. Ong, B. Mitbander, and C. Zaniolo: Metaqueries for data mining. In Fayaad, U. et al. Eds. Advances in Knowledge Discovery and Data Mining. \(1996 29] I. Song, G. Governatori: Nested Rules in Defeasible Logic. RuleML LNCS 3791, 204-208 \(2005 30] H. Toivonen, M. Klemettinen, P. Ronkainer, K. Hatonen, and H Mannila: Pruning and grouping discovered association rules. In ECML Workshop on Statistics, Machine Learning and KDD. \(1995 31] M. Zaki: Generating Non-Redundant Association Rules. In Proc. of the Sixth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 34-43, \(2000 32] w3c. OWL Ontology Web Language Reference. In http://www.w3.org/TR/2004/REC-owl-ref-20040210 33] w3c. RDF/XML Syntax Specification. In: http://www.w3.org/TR/rdfsyntax-grammar 34] w3c. RDF Schema. In: http://www.w3.org/TR/rdf-schema      


 8   2  3\f            8  D    F  \b 1 8 & #J      b 1  1  4    2  


4 1    9  E 1  2 4 1    9 1   4      8 2  8 1  D 1        1 1  b 


     b b b b b  K            8          2 D 9   F  \b 1 8 ,+J  9 


     b 1     1 2  9 1  12 L 1   9  8       1  2      2   


     b b b b b  K            2  0 \b f  b\f      9       


  8 2   E 1   1     M13 31L 1    b  8E 1   1 #3\b?### 1  1     E 1   1 \b?###3        


1   1   b 1  2 2 18 2     8              1    2 \b 1    2  


    2          2   1 L 2 1   1   L 2 2    2 1  2        


    8  2H D \b A             2  2H D \b A 2 \f 3%\f  f   4%\f f !  , \f\b  C    2    2 


 6    3 1      253 6   1 L 2    6   1         f\b3\f       


               1     1     8 2    E       2  1   


     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



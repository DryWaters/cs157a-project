Mobile Access into Information Systems Tomas Kozel, Antonin Slaby University of Hradec Kralove Department of Informatics and Quantitative methods Rokitanskeho 62, 500 03 Hradec Kralove Czech Republic tomas.kozel@uhk.cz, antonin.slaby@uhk.cz Abstract  At present a big concern is devoted to the problems of effective use of mobile technologies in the area of m-business, mcommerce and other areas. It is important to study carefully the relation and synergy between management area and mobile technologies so that business processes \(mainly\ could be supported efficiently. In the paper we  there discuss basic approaches to Service Oriented Architectures \(SOA\  – web services and their use in mobile devices Keywords mobile device, java, Java ME, SOA web service, WSA, kSOAP, BlackBerry, .NET Compact Framework 1. Introduction At present mobile devices undergo rapid development which results in longer performance without charging, better performance larger set of functions implemented for the use by customers and consequently the area of their potential use spreads constantly Similar progress can be seen and rec ognized in the area of mobile communication networks mainly in the area of mobile data services. Smart phones start to take control of the market of pocket computers and communicators and the classical PDAs withdraw and disappear. The majority of mobile telephones have been recently supporting mobile Java \(Java ME\, many communicators possess their own operating system \(Symbian, Palm OS or Windows Mobile\. All these platforms enable relatively easy opportunity to make mobile applications including data communication access. In line with the current trend \(in the area of management and software development\ – of transition to service-oriented architecture - it becomes possible to use mobile devices as clients of these services. Using mobile clients brings  new views and alternative approaches to many business processes. Permanent access to up-to-date data of business information systems from any place is useful in many areas such as selling products B2B, B2C\, creating better relationships  with the customer \(CRM\ etc In the further text  will be described selected attitudes and subsequently technologies which are applicable for the implementation of the client of information system \(resp. of web service\ on the mobile device. First will be mentioned solutions based on mobile Java technology \(J2ME\ and then the solution offered for BlackBerry platform developed by the firm Research In Motion \(RIM 2. Mobile attitude to information systems Mobile devices that are equipped with the mobile edition of java virtual machine \(Java ME are able to set up communication in the mobile data network making use of the HTTP protocol and selected models can use general socket connection. This capability is enabled for version MIDP 1.0 and later versions. The latest versions of mobile java can offer a row of application program interfaces \(API\ that significantly spread the capability of mobile applications These APIs include also an interface for the access to the web services \(WSA\. In the following text  will be briefly described variants of the  information systems access which are enabled by these technologies 2.1. Proprietary solution of mobile communication Classical solution of the problem of the access to the selected parts of information systems from mobile device can be realized either by classical socket connection and economical proprietary protocol or through the common HTTP\(S 851 Proceedings of the ITI 2008 30 th Int. Conf. on Information Technology Interfaces June 23-26, 2008, Cavtat, Croatia 


protocol. In both cases there is necessary to implement connector on the side of information system \(or use a web server\. The connector enables the mobile device to access the selected functions and data of an information system This solution is more suitable for very specific problems and less suitable for more common problems. Client is often in this case burdened by quantity of application logic that it has to perform. This fact naturally reduces performance of the device. The further disadvantage is the necessity to create one purpose connector which is dedicated for connecting the mobile device only. On the other hand this solution has the advantage of economical data communication which at the same time makes the data transmission between client and information system quicker and cheaper. The model of this solution is depicted on figure 1 Figure 1. Proprietary solution 2.2. Making use of Web Services Calling of remote objects through the web services \(WS\ brings a lot of new possibilities and opportunities into the area of the distributed applications development. Some of them address the problem of applications creation for mobile devices. Let us mention these facts  Computationally requiring tasks can be performed completely on the side of IS application server  The web services are accessible from various platforms and consequently there is not necessary to implemented solution dedicated for the access from the mobile device only  The solution is easier to maintain and modify as the changes mainly concern business logic of application server only and so there is not necessary to distribute the changes to all mobile clients On the other hand it is commonly known that the SOAP protocol used for the communication with the web service, which belongs to the family of XML protocols, is not very economical way for the data transmission Two main disadvantages of the solution come out from this fact  A large amount of data is transmitted which makes the transmission process slower and may cause growth of its expenses  The parsing of an XML document in the mobile device is computationally more requiring and may cause slowdown of the application 2.3 The combination of WS and the economical transmission  The combination  previous two attitudes may lead to the further model. The access to the selected functions of the IS will be enabled via the web services as it is described in part 2.2 Mobile client but will not connect to these web services directly through the SOAP protocol but it will use specially for this purpose designed gateway and it will communicate with this gate via an economical compact protocol in a similar way to the one mentioned in 2.1. The gateway then organizes all the communication with the web services. The principle is depicted in the next figure 2 Figure 2. The gateway for connecting mobile device to web service 3. Exploitable technologies Now  will be described possible technologies for realization of above mentioned variants for the communications of the mobile device with IS. Due to less commonness of the first mentioned model \(2.1\ this variant will not be discussed in details 3.1. kSOAP kSOAP [1  3  i s a li br a r y w h i c h  e n a b le s to c r e a te  application in the mobile Java that communicates directly with the web service and uses the SOAP protocol. One of the basic advantages of kSOAP is the fact that it can be used also with older devices which uses the older MIDP1 profile and also with devices that do not offer the WSA support \(see 3.2\ . It is installed in the form of an additional library for the mobile application in the mobile device. The library implements basic 852 


classes for the cooperation with XML and SOAP protocol, it does not use static typing and therefore it is necessary to use either a HashMap or implement KVMSerializable interface to access structured user types. At present there is available the second revised version of the library. However, the documentation accompanying the library seems very incomplete. Sample code shows one simple example of using this library try SOAP object specifying the namespace and the method SoapObject so = new SoapObject\("http://ws.crm getCustomer parameter setting so.addProperty\("index",Integer.valueOf tfCustNo.getString SoapSerializationEnvelope env = new SoapSerializationEnvelope SoapEnvelope.VER11 env.setOutputSoapObject\(so HttpTransport transport = new HttpTransport http://my:8084/CRM_WS/CRMService method call transport.call\("",env retrieving the result value SoapObject res=\(SoapObject env.getResponse striName.setText res.getProperty\("name"\.toString striSurname.setText res.getProperty\("surname"\oString catch \(Exception ex ex.printstackTrace   3.2 J2ME Web services APIs \(WSA Specification JSR-172 [1  2  of t e n r e f e r r e d t o a s  WSA \(Web services API\ is another possibility of connecting the mobile client with the web service. The purpose of the specification is to enable SOAP/XML calls to the web services in mobile Java and it enables some basic parsing of XML documents too. The implementation of this API by the mobile device is the necessary condition that enables the access to the web services on this mobile client. There is possible to use a stub generator that generates a set of classes needed for the access to a web service. It enables to call methods of the remote service on the client side as it is a local object. The generator is the part of all newer versions of Java ME toolkits. It also creates all the necessary user types of the service from given WSDL document. The classes generated in such a way can be simply included into mobile application and used. The example of code showing communication with web service using stub is in the sample code. Using of the stub results in the fact that there is not visible any trace of communication with remote web service Creating stub instance CRMService srv = new CRMService_Stub Customer z try Service call using stub instance z = srv.getCustomer\( Integer.parseInt tfCustNo.getString striName.setText\(z.getName striSurname.setText\(z.getSurname catch \(Exception ex ex.printStackTrace  3.3 RIM BlackBerry Solution Canadian company Research in Motion \(RIM offers an interesting possibility of access to the web services by means of BlackBerry services The customer of the service, offered by some mobile operators, can create or partially develop the mobile client in a free of charge development environment BlackBerry MDS Studio [4   Mobile client developed in such a way possesses the ability to communicate remotely with the web services and/or with selected database servers. In addition to it the mobile device works virtually as a terminal of inner company network due to features of BlackBerry service. In such a way  high level of security of communication between the mobile device and the web service is ensured and at the same time  administration of all the mobile devices \(which include installation, application maintenance, security policy administration etc\ is fully centralized Running of the client application requires the previous installation of so called MSD Runtime which communicates via firm Blackberry enterprise Server \(BES\with intended web services. The communication between Blackberry device and BES is realized by a simple and compact protocol. The situation is depicted in the following figure 3 853 


Figure 3. Architecture of BlackBerry MDS Studio [4 The development process starts again with the WSDL document of the web service which enables to create either objects of messages and accompanying data types only or even GUI forms for the applications. Event driven application logic on the client side is implemented in JavaScript. MDS applications can also respond to so called push messages sent by the server thanks to implementation of WSEventing standard. The resulting finished application is distributed into devices via central MDS and BES Servers 3.4. Microsoft solution Microsoft latest tool for creation mobile application is visual studio 2008. Visual studio fully supports very efficient implementations of LINQ \(Language INtegrated Query\which cover the need for work with data of various kinds for example by implementation of  LINQ to Objects –for collection of objects in  memory  LINQ to SQL – devoted for databases Microsoft SQL Server 2000 and later  LINQ to XML – intended for elaborating XML documents and other libraries. Especially LiNQ to XML is a user friendly library which is also the alternative to DOM and stream elaboration of XML documents. The above mentioned useful friendly and efficient technologies can be used in a mobile device which possesses Windows Mobile operating system, which includes specialized version of .NET framework called NET Compact framework. Its integral parts are also various emulators and debugging tools running both on mobile device and on emulators 4. Case study In this part of the contribution there will be introduced the project of B2B mobile client BBShop which served for testing various capabilities and the stability of solutions based on BlackBerry services. The aim of this study was the creation of a mobile application for travelling salesmen who directly enters the orders at the customer’s site \(BBShop\. The application offers following functionality  Access to the subset of company’s CRM system – i.e. contact browsing, overview of contracts, remarks; the integration with the BlackBerry communication services \(allows to make a immediate phone call, e-mail processing  Catalogue access – including simple and advanced filtering, displaying the customer as well as the dealer prices, list of price reductions for the selected customer  Order processing – preparation of orders of the items selected from the catalogue, or entered using the Bluetooth barcode reader dispatching the order and its immediate confirmation \(incl. the directly available amount of items, the reservation etc All these functions are available via the BlackBerry device connected to the company’s intranet using BlackBerry Enterprise Server BES\. The solution is based on the extensive use of the BlackBerry Mobile Data Services \(MDS module mentioned earlier. All the operations accessible through the Blackberry terminal/client are implemented in the middleware and they are exposed to the device using the web services endpoint. Although all these web services are generally re-usable and accessible from different sources, their implementation is stigmatized by the fact that all the data will be retrieved and/or processed by the mobile device. The limitations of mobile platform in this case were as follows  The recommended and default size limit for the data transfer message between BB device and BES is 32 kilobytes  The amount of the available internal memory of the device is limited  The browsing and searching of the large datasets on the device is slow and inefficient  The size of the catalogue and of other data components of the application is so large that the online synchronization or transfer is 854 


still almost unusable in current mobile networks All these aspects led to the conclusion to implement some specific concepts of the work with large datasets. It involves for instance  the implementation of the catalogue and customer list output pagination with only current page held in the device’s memory  simple and advanced data filtering including the filters based on the categorization of items, full text filters, barcode filters etc  the possibility to define and use a smaller and the user’s own sub-catalogue of favorite” items  BlackBerry terminal Internet IS MS Dynamics NAV AppServer BES MDS order connector batch sync real time WS Temp. D B Intranet Figure 4. Architecture BBShop The overall architecture model is shown in Figure 6. It is significantly influenced by the used Blackberry solutions. The client and communication infrastructure is implemented in the BlackBerry MDS Studio mentioned earlier The client code is minimalistic and is mainly generated by wizards of the tool. The main task of the client is to collect the user’s demands, to check entered data and pass them to the remote service using its generated stub. The BlackBerry Enterprise Sever together with Mobile Data Services \(BES/MDS\ translates the client’s request to the XML/RPC call against the Web Service Endpoint \(WS Endpoint\. Web service delegates the responsibility to the middleware application server \(AppServer\. In case of the order request the data are pre-processed and sent through the online connector \(Order connector to the Enterprise Information System \(IS – here Microsoft’s Dynamics NAV\ The response of the information system is then sent the same way back to the client, which includes the necessary reverse protocol translation. In another case non-order requests\ the request is processed entirely by the application server and the data is sent back to client without any on-line cooperation with information system. The data for the basic tables of keys are cached in a temporary database of the application server and they are synchronized once a day during the night hours. This solution significantly reduces the need for the direct communication with the information system Middleware application server was designed as a modular system allowing further extensions of the functionality in the future. Therefore it was selected Spring Framework for its implementation. The concept of loosely coupled software components of Spring exactly follows the strong modularity requirement. The caching database is accessed in the object way through Hibernate framework, which allows using different relational database systems as back end storage engines. This solution has paid off after it was decided to change the database server technology from MySQL to Microsoft SQL Server. The need of the code refactoring was minimal and the system was switched to the new database system in several minutes Communication with the enterprise information system is based on an XML family protocol and the transmission of the data is implemented using the socket connection. The entity beans of the application server are directly mapped on the XML entities with the help of JiBX framework integrated into Spring context. Web services are exposed using Axis and by sub-classing of the Spring’s class ServletEndpointSupport. All the communication between BlackBerry Enterprise Server and the application server goes through the local network, so the web tier running on Apache Tomcat does not need to use very strict security policies. Further communication towards and from the BlackBerry client runs through the secured channel of provided by the BlackBerry services of selected telecommunication operator BlackBerry client helped to solve the former problem of growing load of the information system in late afternoon and early evening hours In this period of time all the salesmen used to dispatch the orders from customers which had been collected during the particular day. BBshop project enabled to distribute the application load of the information system more proportionally during the day and at the same time achieved very quick distribution of the orders to the customers. On the other side BlackBerry based 855 


solution is substantially more expensive than solutions based on other in this contribution mentioned technologies and is suitable mainly for larger companies that use or intend to use BlackBerry as their basic communicator. One problem we met at the beginning of the projects and that we still feel as relatively serious is the missing support of connectivity detection on the device's side. BlackBerry device stores all the outgoing messages into the message queue without any regards to the connectivity state. If the device is under coverage, the messages are directly sent to BES/MDS server. Otherwise they are blocked until the connection is restored This is convenient in many applications, but sometimes user wants to get either immediate confirmation of the transaction or at least to know that the confirmation will be delayed Current versions of the BlackBerry MDS Studio do not allow implementing this functionality 5. Conclusion At present mobile devices already have sufficient computational performance to maintain communication via the SOAP protocol. There exist reliable technologies that enable implementation of mobile client of the web services. Concerning the rate of the data transmission, so far prevails the variant of solution described in part 2.3 of the contribution with compact and economical protocol that is implemented for example by BlackBerry services. The authors intend to realize more exact measurement and testing in further stages of the research One of the essential and here not mentioned aspect accompanying the communication of mobile clients with web service is the problem of security and safety of both the transmission channel and the web service itself. None of here mentioned solutions have built-in support of the protocol WS-Security. WSA and kSOAP could be supplemented with the encrypted protocol HTTPS and with authentication of users. Easier situation is in case of BlackBerry application as here secure and authentication possessing access is the organic part of the service itself and mobile device is assumed as computer of inner network Nonetheless, even in this case it is possible to make use of HTTPS and authentication as additional way for security of communication between BES Server and web service in inner network. The results of the project BBShop mentioned in our case study indicate that use of web services raise and widen possibility of exploitation of the mobile telephone \(or communicator\ to the much higher level. Factors that limit or restrict this technology are so far relatively slow commonly offered data services for the mobile phones and of course capabilities of the mobile devices. It is reasonable to implement mobile client for devices having reasonably large display and suitable way of governing input \(pen, QWERTY keyboard The problem of mobile technologies dynamism of their spread and massive use is the purpose of the research funded by Czech Science Foundation GACR Models of Firms with Mobile-Oriented Architecture Research is focused on making basic models of interaction between mobile devices and information systems which enable the support processes and mobility.  In the future study  basic architectures and essential models of information systems based on massive and at the same time also sensible and reasonable use of mobile technology will be described. Various ways of transformation of information systems so that they could possess mobile features will be examined. Effective ways of making processes mobile will be explored 6. Acknowledgements The contribution was made with the financial support of the grant of the Czech Science Foundation GA R No 408/08/1046: Models of Firms with Mobile-Oriented Architecture 7. References 1  Or i t z  E U nde r s ta n d in g t h e W e b S e r v i c e s  Subset API for Java ME, URL http://developers.sun.com/mobility/midp articles/webservices  2  JS R 1 72 J2ME™ W e b S e r v i c e s  Specification.URL: http://www.jcp.org/en jsr/detail?id=172  3  kS oa p  UR L  ht t p   k s o a p 2  s e i g e l  i nf o  wiki/index.php?title=Main_Page   4  B l a c k B e r r y MDS S t udi o F u nd a m e n ta l s  Guide, Research In Motion, PDF document 856 


  7 The following lists key ASC subsystem architectural connectors  200  The simple operational interface, supporting remote service calls for database transactions enables complete ignorance on the part of clients as to the nature and implementation of the underlying persistent store.  It enables very low system integration costs  200  The model abstraction also enables tools to autogenerate relational database schemas including data types and mapping to tables.  This makes for low-cost schema updates and thus improves the overall ability of the system to evolve  200  The approach is highly amenable to automated regression testing as each path in the automated collection process can be auto-tested separately  The current ASC implementation has some key limitations from state-of-the-art at the time of original design and development in 2003.  A primary limitation is a locked-in Oracle interface.  This conflicts with a number of MGSS users requesting compliance with MySQL. Ongoing work looks ahead to take advantage of the rapidly advancing state-of-the art addressing basic \223object-relational\224 functionality to address this concern as well as others including support of relational in addition to hierarchical associations  The next section describes in more detail the process of adaptation of this framework for the RDE upgrade     4  R ELAY A CCOUNTABILITY A DAPTATION  Overview The primary goals of the RDE system include 200  Automating collection of key end-to-end relay parameters with a minimum of human intervention and 200  Providing web access to life-of-Phoenix-mission relay database, supporting planning, analysis, and tactical functions The adaptation of ASC for relay accountability faced a number of ongoing challenges toward meeting system goals, including  Maintaining an accurate picture of relay status e.g. provide \223relay situational awareness\224 a highly dynamic operational environment  Dealing with rapidly evolving data interfaces across a broad spectrum of the end-to-end relay process from the start of relay ORTs through surface operations  Automating data collection within the bounds of the secure flight network, while still providing data accessibility outside of flight and  Delivering a dependable \223relay data service\224 with a low level of funding and staffing Adaptation Implementation Approach The RDE tool was developed with an \223adapted\224 Agile methodology As wi t h a com m on Agi l e approach, earl y  development involved simple prototypes with frequent user demonstrations.  However, hard mission deadlines and 200  The ASC CRUD-based service API provides a primary software component connector  200  Messaging provides a primary application connector  200  Events act as \223triggering\224 connectors   Subsystem Constraints  The primary constraint of the ASC system on end-user adaptations is requiring inheritance of the top-level accountable object type  The primary constraint on the ASC is the requirement that user information definition and user workflow be fully configurable and adaptable as part of an adaptation effort  ASC Conclusions  The software architecture and implemented functionality have provided at least the following benefits  200  Decoupled component implementation reduces code-base impact, thereby reducing the impact of implementing to unexpected requirements  200  The model abstraction to persistent data allows end-user applications to deal with objects as objects as opposed to just tables. It supports a widely used table view as well, as most mission data are typically handled as tables rather than objects  


  8 quality requirements meant that the quick-turnaround approach would have to come to an end  We started the RDE adaptation by implementing a simple information model schema desc ribing a set of parameters making up an \223overflight pass\224 object type.  After presenting this model to the multi-mission relay operations team, we implemented \223prototype\224 data collection applications.  These included a \223planning publisher\224 application and a first cut at an automated pass performance data volume collector as an extension of the ASC Agent Framework.  We also implemented a basic web query interface and performed a series of user demonstrations and multi-mission relay planning mee tings, enabling us to adopt user feedback at an early stage As Phoenix Operational Readiness Tests \(ORTs approached, we adopted a more formal development and delivery process.  This included a complete delivery prior to EDL and surface operations, and a final Phoenix delivery in October 2008 was completed incorporating updates resulting from operational issues and user feedback With each ORT, new functionality was added and automation improved. In particular, the \223Overflight Review\224 web view was a focus of daily relay test meetings and at times evolved on a daily basis to keep up with user needs  The following sections describe the various components adapted for RDE The Relay Data Model The first component of the RDE tool to be developed was the information model schema.  The model is defined in the XML Schema Definition Language \(XSD   The m odel  schema defines all the informa tion that is \223tracked\224 by the system. It defines the persistent object types as well as the relational tables that store objects. This model schema is the primary input of the ASC server application  The focus of the RDE model is the relay overflight and associated information. The heart of the RDE model has always been the relay pass, otherwise known as the 223overflight pass\224 type.  During early development of the model, a couple of different overflight representation options were analyzed. In one approach, the overflight was described as a hierarchical set of classes, with \223Odyssey overflights\224 and \223MRO overflights\224 extending an abstract overflight class.  However, the addition of this hierarchical layering complicated the data publishing mechanisms and eventual user interface.  End users expressed greater comfort with seeing all possible available fields in a single view.  The simplest way to achieve this was to consolidate all of the tracked data fields in a single object type, an Overflight object.  This overflight inherits from a simple abstract Accountable Item class  With next-generation missions such as MSL, we expect to further extend the Relay Engineering model and develop new clients to ingest new types of information and from different sources  Pass Identification One key concern of pass data tracking is the identification of the overflight.  Fortunately certain pass parameters can be combined into a natural unique identifier.  Passes are identified by the combination of the following parameters  200  Relay \(or \223hailing\ asset, such as any relay orbiter 200  User \(or \223responding\224\any surface asset 200  Day of year 200  Pass number \(1 to X 200  Year  These parameters combine into a unique natural identifier for each pass that is useful in pass visualization views as well a means for publishing applications to perform live pass object updates.  This same natural identifier is used in each of the input sources.  The rest of this paper will refer to this composite identifier as the \223relay pass identifier\224  Automated Relay Data Collection  A primary driving goal of the RDE is that overflight data be published without end-user intervention  A primary challenge to the development of the RDE has been a lack of established interfaces.  A large amount of required information is pres ent in spreadsheets, email 223reports\224, and other text file byproducts.   Several of these sources underwent nearly continuous format changes from one operational readiness test to the next, up until early Phoenix operations  To provide the data to meet this model, data ingestion clients \(planning and performance were developed.  Note that the total client developm ent time for this initial upgrade took less than one month, once we had a solid model in place  For RDE, there are two sorts of 223reactive\224 clients that run as full-time processes to provide automated data publication  200  A Message Reactor that provides an interface to a legacy file management system called DOM Distributed Object Manager  200  An ASC \223Agent\224 application built that schedules relay events, publishes event messages, and performs automated data volume lookup  


  9 The DOM was utilized for two primary reasons.  First, the DOM is widely used by JPL mission systems and its interface is available to all operational machines with a standard multi-mission software deployment.  Second, and perhaps more importantly, the DOM is capable of publishing messages when files of any type are published to the file store.  These messages may be filtered by file type and other supported metadata.  This allows for the creation of \223message reactor\224 applica tions that can automatically trigger further processing when a file is published simply by reading the correct message off of a shared message bus  In the architecture of the RDE, a message reactor application reacts to one of several possible file types published to DOM by executing a new application, the purpose of which is to extract the newly published file out of the file repository, parse the relevant accountability data out of the file and publish the new data to the RDE database  The Assembled RDE Upgrade System  Figure 2 shows how runtime automation and web servers were assembled operationally     As can be seen, much of the data are being provided through the DOM and message reactor interface   The RDE Overflight Record Lifecycle   The following section discu sses the lifecycle of the 223overflight record\224 and what data sources provide updates at what point in the process  Pass Planning  The RDE \223overflight pass\224 reco rd is first created when a planning file is published with a set of passes not currently present in the database  Pass planning information includes  200  Requested passes 200  Elevation angle 200  Planned data rates  The long-range link planning process includes the creation the APGEN file that contains all pass schedules. The APGEN file is typically published more than once, with an initial version that contains all geometric opportunities, and further updates identifying t hose opportunities for which a Fi g ure 2 \226 Assembled RDE U pg rade S y stem 200  Geometric pass 


  10 relay service is requested. When a planning file is published that contains records already present in the database, each existing record is updated with any changes from the new file.  This is typically to update each geometric pass with the requested times and pass durations  There are a number of concerns when selecting a pass for use.  Limited lander energy resources drive the need for selecting passes with the best telecommunications performance.  The maximum elevation angle of the pass is a primary consideration when choosing a pass for use. When a relay orbiter is in view near the horizon, link performance can be poor due to the large off-boresight angles of the lander and orbiter antennas, the long slant range between orbiter and lander, and potential multipath effects off of the Mars surface and/or lander deck As the orbiter rises, the signal improves until it reaches the maximum elevation, and then degrades the orbiter agai n approaches the horizon. The orbital elevation for a \223quality\224 signal is typically greater than 5-10 degrees. Also, the higher the maximum orbtier elevation angle for a given , the longer the overflight and the greater the possible total volume of data that can be transmitted.  Therefore, overflight passes with a high maximum elevation are typically selected over passes with a low maximum elevation  Planning files and updates are typically published every one or two weeks  Pass Latency Predictions  One parameter the RDE is required to track is the end-ofpass \223latency\224, that is, the time the relay products for a given pass are expected to arri ve at the lander\222s GDS.  On its own, the end-of-pass latency might be considered a secondary parameter in comparison with pass planning and performance.   For relay missions that provide a \223trigger\224 mechanism to indicate product completion such as MRO via the CCSDS File Delivery Protocol \(CFDP\is a parameter is not of high value, as the \223trigger\224 from the publication of the relay file product provides a means to identify that the complete data product has been delivered  For non-CFDP relay there is a significantly greater challenge to timely relay data collection. The primary nonCFDP relay asset in use is Odyssey, which has delivered more data than any other relay orbiter.  Because no external event trigger to drive the data collection, the best that Odyssey can provide is a prediction of the time that all data should be available to the ground system GDS Telemetry Data Service \(TDS\orbital geometry, data rate etc. Nominally, this predict \(plus some margin\d be enough to reliably trigger data collection in a timely manner soon after the data are made available. However, additional latencies are not rare and data may be received at later times, so that partial or no data may be retrieved at the time of the end of pass predict. To mitigate this, it is necessary to re-request data at a later time than the pass  The RDE design utilizes this pass predict to drive an automated lookup process using the \223ASC agent\224 component  The Odyssey latency predictions have been distributed via email as an XML spreadsheet.  To support the RDE tool the Odyssey planning team agreed to publish a CSV comma separated value\ext version of the XML spreadsheet to the DOM file store.  Upon publication, this file is parsed and the latency values are published via the ASC service API \223update\224 function to the RDE database using the natural pass identifier as an index  Pass Volume Predicts  The ability to compare predicted versus actual data volume is an important function of the RDE. Such comparisons require the ingestion of pred icted volumes for each pass However comparisons are not as straightforward as merely picking the right predict for each pass. Each pass has a number of predicted values for the volume. These predicts depend upon a number of concerns such as data rate elevation mask, elevation angl e, and the remote antenna used for transmission \(Helix or Monopole change over the course of the tactical cycle, sometimes more than once, and so the final "correct" predict may not be the same as the original "planned" predict  The source of Phoenix predicts is a file called the 223Integrated Overflight Summary\224, another Microsoft Excel spreadsheet type.  This spr eadsheet contains a table of predicts for each pass with values taking into account forward and return rates, remote antenna used, etc  We devised a means of exporting these predicts to a CSV file and publishing a table of those values to the RDE database, associating the set of predicts for each pass.  To present an accurate predict the web interface presents predicts that align with the latest set of relating pass parameters \(e.g. final forward a nd return rates for the link  The identification of an accu rate predict from post-pass parameters turned out to be one of the bigger challenges of the RDE upgrade task.  Some open issues remain in this area to be addressed in ongoing work, such as the identification of the actual utilized antenna out of lander GDS telemetry  Pass Performance  There are a number of sources for post-past performance The primary tracked value is the transmitted pass volume Both forward and return link vol umes are tracked closely These data are required for all current analysis views  


  11 Other pass-related collected information includes end of pass times, average transmitter power levels, and frame and packet counts  Pass performance data is collected from a variety of sources, including 200  Query of \223raw\224 telemetry database frames 200  Parsed from data product log files 200  Relay ACE text file report \223scorecard\224  We implemented to the broadly used JPL Telemetry Data System to calculate \223raw\224 total telemetry volumes from Relay and User GDS databases.  This was the only mechanism available to calculate data volumes out of the Odyssey data flow  Unlike Odyssey, the MRO mission uses CFDP to distribute relay data.  With MRO/CFDP, a local JPL process provides an XML file containing pass information.  The total pass volume is identified in a field in this file, as well as final Pass Start and End times  The Relay \223Scorecard\224 was provided through the aforementioned DOM interface and included relay calculated data volume, frame and packet counts, and additional average, minimum, and maximum AGC values  Web Views   A major portion of development work involved the construction of a set of web views supporting strategic and tactical use.  To support these views we implemented an extension of the ASC CRUD API in JavaScript Object Notation \(JSON\ of the Asynchronous Java and XML \(AJAX provides an interface between client JavaScript and an ASC servlet running within a Tomcat application.  The AJAX \223asynchronous XML\224 pattern provides for a highly responsive XML interface  Other web components include  200  CSS Style sheets, and 200  JavaScript  The following five views were re leased as part of the final Phoenix-era RDE delivery  200  Export Volumes 200  General Query 200  Drop Dead Uplink Times, and 200  Overflight Report  Overflight Review  The purpose of this view is to present a \223quick summary\224 of pass performance.  This includes an indication of predicted vs. actual values.  This view was used daily during early ORTs to identify and track pass anomalies and reporting discrepancies.  Often enough the view was valuable as a 223double-check\224 of data collected by various operational teams and the RDE software itself It might be considered the most \223mature\224 of the ava ilable views. We expect MSL will benefit from this view      Figure 4 \226 Overflight Review   As shown, this view contains a large number of \223filtering\224 functions as well as other types of modifying functions  Table 3 describes each of the view control options  Table 3 \226 Overflight Review View Control Options  View Control Description Default Days Range Filter passes in view to a time range from < Text Entry Field 1 > days ago to < Text Entry Field 2 >.  This provides a 223moving window\224 of recent passes 3 days prior to 2 days hence SOL/DOY Filter passes by SOL or Day of Year \(DOY None Show Records Limit the query of number of passes displayed 100 UA Filter by User Asset All RA Filter by Relay Asset All Requested Display \223requested\224 passes This includes all passes with a non-null value in the requested field in the APGEN pass plans, as well as any utilized pass \(RA volume 0 True Utilized Displays any pass with an RA True 200  HTML to provide frames, etc 200  Overflight Review 


  12 volume > 0 SOL Time of Day Filter passes by local \(i.e Mars\e of day False Compare Threshold Percentage difference allowed between predicted and actual values to trigger visual discrepancy \(c.f. \223Comparing Predict vs. Actual\224 40 Remove RS Overhead Remove the Reed-Solomon encoding overhead from the displayed RA Volume values Final value = value * 233 255 True Query Re-query data from database N/A Auto-Query Auto-query the data in view according to the time delay selected from the adjacent pull-down menu \(in seconds  Export Export the data in view to csv format \(c.f. \223Export\224 N/A Report Run a JasperSoft report of the selected pass \(c.f. \223Report by Pass\224 N/A   Export Volumes  As mentioned earlier, a primary purpose of this tool is to provide life-of-mission performance data.  Over the course of the early mission, the export function on the \223Overflight Review\224 was used for this purpose. After approximately two months of data had been collected the review page became unresponsively slow to load all the required data This was largely due to the amount of Javascript on the Review page.  So an additional page was added with the purpose of quick export to csv  General Query  Another important use of the RDE tool is ad-hoc analysis To meet this need, we provided a general-purpose query display.  This includes selection of any set of fields as well any number of SQL \223where\224 clauses.  Only the SQL \223add\224 of where clauses are currently supported, \223or\224 is not    Figure 3 \226 General Query View  Drop Dead Uplink Times  Pass plans include a time value called the \223Drop Dead Uplink Time\224.  These times represents the latest possible time that a User GDS team can submit a forward link product to a Relay GDS team and have it delivered via the indicated link    Figure 4 \226 Drop Dead Uplink View  The provided view is not necessarily a great deal better than the current set of pass spread sheets for those who are used to them. However, new functions such as a \223countdown alarm\224 should improve its utility  Overflight Report  Any tabular record in the Review and General Query displays can be selected and vi ewed as a report.  The report view shows all fields for the overflight record in question Underlying this view is the JasperReport software    Figure 5 \226 Example Report  Other Views  Not all of our initial views made the final cut.  Key remaining views include a \223Latest Pass\224 statistics view \(like the Overflight Report auto-update of recent passes utilized 


  13  Use of Web Technologies The web development effort involved a long learning curve for some of the RDE Upgrade development team HTML We used HyperText Markup Language \(HTML\o layout the web framework and page structures AJAX/JSON  The AJAX \(asynchronous JavaScri pt and XML\tern was introduced to support a responsive web GUI.  An implementation of JSON \(JavaScript Object Notation provides the data service inte rface from the web client to a tomcat-maintained servlet. We have run into very few issues with this technology 10 11 12  CSS Cascading Style Sheets \(CSS\provide a straightforward way to manage web page styles. The language is well supported through the open-source FireBug Edito 14  JavaScript We used JavaScript to provide a rich interactive web interface, however our experien ce with JavaScript was not entirely favorable.   The Java Script \(JS approach to APIs including widgets led to our implementing more JS code than we might otherwise have.  We found the 223typeless\224 language occasionally caused confusion.  We did find that it could be \223made to provide\224 a rich web interface though probably a heavier interface than it needs to be.  One real positive for JS is the huge volume of sample code available on the Internet, saving time when dealing with the many implementation problems that spring up JasperReport  We used a toolkit called JasperReport to build a database report we could execute from our web interface.  A JasperReport is edited using the iReport tool. When the report is opened, the JasperSoft library is executed which updates each field from the database and presents the updated report The next section describes some of the \223analysis views\224 that can be generated from data in the RDE store 5  R ELAY A CCOUNTABILITY A NALYSIS  From the start of the Phoenix mission through the current day the RDE tool has been us ed primarily to extract pass statistics for reporting.  The key primary tracked statistic is the total volume of data delivered by each relay spacecraft Typically the \223Export Volumes\224 web view is used for a 223quick\224 export of these data, though the \223General Query\224 view can also be used for this purpose.  Raw tabular data are exported in Comma Separated Value \(CSV\at and then normally imported into an Excel spreadsheet for charting Figure 6 shows the total volume over time from the start of Phoenix mission \(Sol 0\o Sol 120, about a month past the end of prime mission Cumulative Return Link Data Volume 0 5000 10000 15000 20000 25000 30000 35000 0 30 60 90 120 Sol MRO Cumulative Ret Fill DV MRO Cumulative Ret PHX DV ODY Cumulative Ret Fill DV ODY Cumulative Ret PHX DV   Figure 6 \226 Cumulative Return Link Volume Figure 7 shows the same data values, but charted to show the total data volume transmitted per Sol  Return Link Data Volume by Sol PHX Lander Data + Fill Data 0 50 100 150 200 250 300 350 400 0 30 60 90 120 Sol ODY Ret Data Volume \(PHX Data + Fill bits MRO Ret Data Volume \(PHX Data + Fill bits  Figure 7 \226 Data Volume By Sol  On Figure 6 and Figure 7, the Phoenix Data Volume \(DV shown represents actual telemetry data and science product delivered.  The Fill DV on both figures represents \223fill\224 frames that are transmitted when a relay link is open but no actual lander data is available to transmit.  This chart shows that the Odyssey mission has carried the most part of 


  14 Phoenix relay data over MRO.  The low MRO volumes at the very early end of the chart are due to early MRO communications issues with Phoenix that were not resolved until later in the mission.  The volume discrepancies are clearly visible from both charts Figure 8 shows the data volumes for the 128K overflights as a function of Mars LMST \(Local Mean Solar Time 128 kbps Return Link Data Rate 0 10 20 30 40 50 60 70 80 90 100 0:00:00 6:00:00 12:00:00 18:00:00 0:00:00 Local Mean Solar Time ODY MRO PHX Re q uirement:  30 Mb p ass  Figure 8 \226 Data Volume By Sol  Figure 9 shows a comparison of data volume predicts vs pass performance values  Figure 9 \226 Volume Predicts vs. Performance  6  C ONCLUSIONS  For ASC, the next step is to achieve a level of database independence.  We look to take advantage of emerging best practices technologies and patterns \(e.g. Hibernate  t o  upgrade our core server function to database independence and our Agent Framework to take advantage of a workflow execution function or language such as the Business Process execution Language \(BPEL  RDE is planned for update with the Mars Science Laboratory \(MSL\ission.  This will include any required updates to the planning input s \(MSL will utilize a wider range of relay parameters, including higher data rates multiple frequency channels and possibly new modulation and coding schemes and adaptive data rate functionality and a likely major change in the handling of predicts One significant additional RDE improvement proposed is to develop a web-based tactical interface supporting pass utilization requests and tacti cal updates.  Currently, all tactical relay coordination is accomplished via email and phone.  This process could be greatly improved with the upgrade to of a web-based system.  However, if adopted this upgrade would have a large impact on the current operational tactical process and thus must be carefully engineered across a broad user base  Overall we found we were able to accomplish our primary relay accountability goals using our chosen architecture The ASC server held up as a useful way to manage objectrelational transactions over a distributed network, and our event-driven client mechan isms were assembled in a straightforward manner using the existing ASC Agent Framework as well as the DOM message reactor function Our ability to accomplish this broad integration at a consistently low level of funding tells us that these technologies and patterns are worth pursuing as part of further accountability prototype pilot, and deployment activities A CKNOWLEDGEMENT  The work described in this paper was conducted at the Jet Propulsion Laboratory, Californi a Institute of Technology under a contract with the National Aeronautics and Space Administration  The authors wish to further acknowledge other individuals who made key contributions to research and development including Marti DeMore, Lloyd DeForrest, Derek Kiang Ashley Shamilian, Lori Nakamura, Mark Palm, Priscilla Parrish and Mike Tankenson  


  15 R EFERENCES    http://www.w3.org/XML/Schema   eb Orchestration with BPEL\224 http://www.idealliance.org/pa pers/dx_xml03 papers/0406-01/04-06-01.html  Hi bernat e hom e page www.hibernate.org   Al l a rd, Dan and Hut c herson, Joe, \223C om m uni cat i ons Across Complex Space Networks\224, IEEE Aerospace Conference, March 1-8, 2008  W e b Servi ce Defi ni t i on Language http://www.w3.org/TR/wsdl   B a uer, C h ri st i a n and Ki ng Javi n Java Persi s t e nce for Hibernate, New York: Manning Publications, 2007 7] \223Software Agents An Overview\224 http://www.sce.carleton.ca/netm anage/docs/AgentsOverview ao.html  e thodology.org  http://www.riaspot.com artic les/entry/What-is-Ajax  http://www.json.org 11 h ttp to m cat.ap ach e.o r g   12] http://java.sun com/products/servlet  http://www.w3.org/Sty le/CSS    B IOGRAPHY  Dan Allard has worked as a software engineer at the Jet Propulsion Laboratory for the past 17 years.   He currently leads the development of core JPL accountability systems applications and infrastructure Other recent work includes the development of a message-based ground data system for the Mars Science Laboratory as well as research and development of ontologybased distributed communications     Dr. Charles D \(Chad\ards, Jr received his A.B degree in Physics from Princeton University in 1979 and his Ph.D. in Physics from the Calif ornia Institute of Technology in 1984.  Since then he has worked at NASA\222s Jet Propulsion Laboratory, where he currently serves as Manager of the Mars Network Office and as Chief Telecommunications Engineer for the Mars Exploration Program, leading the development of a dedicated orbiting infrastructure at Mars providing essential telecommunications and navi gation capabilities in support of Mars exploration.  Prior to that he managed the Telecommunications and Mission Operations Technology Office, overseeing a broad program of research and technology development in support of NASA\222s unique capabilities in deep space communications and mission operations.  Earlier in his career, Dr. Edwards worked in the Tracking Systems and Applications section at JPL where he carried out research on novel new radio tracking techniques in support of deep space navigation, planetary science, and radio astronomy  


  16  


Thank you Questions 


 18  Astronautical Congress Valencia, 2006 27  Bu reau  In tern atio n a l d e s Po ids et Mesures. \(2 008  August\SI Base Units. [On http://www.bipm.org/en/si/base_units   B IOGRAPHY  Author, Karl Strauss, has been employed by the Jet Propulsion Laboratory for over 22 years.  He has been in the Avionics Section from day One.  He is considered JPL\222s memory technology expert with projects ranging from hand-woven core memory \(for another employer\o high capacity solid state designs.  He managed the development of NASA\222s first Solid State Recorder, a DRAM-based 2 Gb design currently in use by the Cassini mission to Satu rn and the Chandra X-Ray observatory in Earth Orbit.  Karl was the founder, and seven-time chair of the IEEE NonVolatile Memory Technology Symposium, NVMTS, deciding that the various symposia conducted until then were too focused on one technology.  Karl is a Senior IEEE member and is active in the Nuclear and Plasma Scie nce Society, the Electron Device Society and the Aerospace Electronic Systems Society Karl is also an active member of SAE Karl thanks his wonderful wife of 28 years, Janet, for raising a spectacular family: three sons, Justin, Jeremy Jonathan.  Karl\222s passion is trains and is developing a model railroad based upon a four-day rail journey across Australia\222s Northern Outback   


 19 Bollobás, B. 2001. Random Graphs. Cambridge University Press; 2nd edition. 500pp  Cawley, G. C., B. L. C. Talbot, G. J. Janacek, and M. W Peck. 2006. Sparse Bayesian Ke rnel Survival Analysis for Modeling the Growth Domain of Microbial Pathogens  Chiang C. L. 1960. A stochastic study of life tables and its applications: I. Probability distribution of the biometric functions. Biometrics, 16:618-635  Cox,  D. R. 1972. Regression models and life tables J. R Stat. Soc. Ser. B 34:184-220  Cox, D. R. 1975.   Partial likelihood Biometrika 62:269276  Cox, D. R. & D. Oakes. 1984 Analysis of Survival Data  Chapman & Hall. London  Cressie, N. A. 1993 Statistics for Spatial Data John Wiley Sons. 900pp  Duchesne, T. 2005. Regression models for reliability given the usage accumulation history. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty Y. Armijo. pp.29-40. World Scientific, New Jersey  Eleuteri, A., R. Tagliaferri, L. Milano, G. Sansone, D D'Agostino, S. De Placido,  M. Laurentiis. 2003.  Survival analysis and neural networks. Proceedings of the International Joint Conference on Neural Networks, Vol. 4 20-24 July 2003 Page\(s\:2631 - 2636  Ellison, E., L. Linger, and M Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013, 1997  Fleming, T. R. & D. P. Harrington. 1991. Counting process and survival analysis. John Wiley & Sons. 429pp  Graver, J. and M. Sobel 2005. You may rely on the Reliability Polynomial for much more than you might think Communications in Statistics: Theory and Methods  34\(6\1411-1422  Graves, T. and M. Hamada. 2005. Bayesian methods for assessing system reliability: models and computation. In Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson, et al. pp.41-53  Grimmett, G. 2006 The Random-Cluster Model Springer  Grimmett, G. 1999 Percolation Springer  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis.  Springer. 481pp  Jin Z. 2005. Non-proportional semi-parametric regression models for censored data. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.279-292 World Scientific  Kalbfleisch, J. D. & R. L. Prentice. 1980 The Statistical Analysis of Failure Time Data John Wiley & Sons.  New York. 1980  Kalbfleisch, J. D. &  R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data.  Wiley-InterScience, 2nd ed 462pp  Lisboa, P. J. G. and H. Wong. 2001. Are neural networks best used to help logistic regression? Proceedings of International Joint Conference on Neural Networks, IJCNN 01. Volume 4, 15-19,  July 2001. Page\(s\:2472 - 2477 vol.4  Kauffman, R. J. and B. Wang. 2002. Duration in the Digital Economy. Proceedings of th e 36th Hawaii International Conference on System Sciences \(HICSS’03\ Jan 2003  Kaplan, E. L. & P.  Meier.  1958.  Nonparametric estimation from incomplete observations J. Amer. Statist. Assoc  53:457-481  Klein, J. P. and P. K. Goel 1992. Survival Analysis: State of the Art.  Kluwer Academic Publishes. 450pp  Klein, J. P. and  M. L Moeschberger. 20 03. Survival analysis techniques for ce nsored and truncated data Springer  Krings, A. and Z. S. Ma. 2006.  "Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks MILCOM 2006, Military Communications Conference, 2325 October, 7 pages, 2006  Krings, A. W. 2008.  Survivable Systems.  in Information Assurance: Dependability and Security in Networked Systems Yi Qian, James Joshi, David Tipper, and Prashant Krishnamurthy, Morgan Kaufmann Publishers. \(in press  Lawless, J. F. 1982. Statistical models and methods for lifetime data.  John Wiley & Sons. 579pp  Lawless, J. F. 2003. Statistical models and methods for lifetime data.  John Wiley & Sons. 2nd ed. 630pp  Li, M. and P. Vitanyi. 1997. Introduction to  Kolmogorov Complexity and Its Applications. 2nd ed, Springer  Ma, Z. S. 1997.  Survival analysis and demography of Russian wheat aphid populations.  Ph.D dissertation, 307pp University of Idaho Moscow, Idaho, USA 


 20 Ma, Z. S., and E. J. Bechinski. 2008.  Developmental and Phenological Modeling of Russian Wheat Aphid Annals of Entomological Soc. Am In press  Ma, Z. S. and A. W. Krings. 2008a. The Competing Risks Analysis Approach to Reliability Survivability, and Prognostics and Health Management.  The 2008 IEEEAIAA AeroSpace Conference. BigSky, Montana, March 18, 2008. \(In Press, in the same volume  Ma, Z. S. and A. W. Krings 2008b. Multivariate Survival Analysis \(I\e Shared Frailty Approaches to Reliability and Dependence Modeling. The 2008 IEEE-AIAA AeroSpace Conference. BigSky Montana, March 1-8, 2008 In Press, in the same volume  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(II\ Multi-State Models in Biomedicine and Engineering Reliability. 2008 IEEE International Conference on Biomedical Engineering and Informatics BMEI 2008\27th-30th, 2008 Accepted   Mani, R., J. Drew, A. Betz, P. Datta. 1999. Statistics and Data Mining Techniques for Lifetime Value Modeling ACM Conf. on Knowledge Discovery and Data Mining  Mazzuchi, T. A., R Soyer., and R. V Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Meeker, W. Q. and L. A. Escobar. 1998. Statistical Methods for Reliability Data. Wiley-Interscience  Munson, J. C. 2003. Software Engineering Measurement Auerbach Publications  Nelson, W. 1969. Hazard plotting for incomplete failure data J. Qual. Tech 1:27-52  Nakagawa, T. 2006.  Shock and Damage Models in Reliability Theory. Springer  Osborn, B. 2005. Leveraging remote diagnostics data for predictive maintenance.   In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp. 353-363  Pena, E. A. and E. H. Slate. 2005. Dynamic modeling in reliability and survival analysis. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.55-71  Reineke, D. M., E. A. Pohl, and W. P. Murdock. 1998 Survival analysis and maintenance policies for a series system, with highly censore d data.  1998 Proceedings Annual Reliability and Maintainability Symposium. pp 182-188  Schabenberger, O. and C. A. Gotway. 2005. Statistical Methods for Spatial Data Analysis.  Chapman & Hall/CRC  Severini, T. A. 2000. Likelihood methods in statistics Oxford University Press  Shooman, M. L. 2002. Reliability of Computer Systems and Networks: Fault Tolerance, Analysis and Design. John Wiley and Sons. 551pp  Stillman, R. H. and M. S. Mack isack, B. Sharp, and C. Lee 1995. Case studies in survival analysis of overhead line components. IEE Conferen ce of the Reliability and Distribution Equipment. March 29-31, 1995. Conference Publication No. 406. pp210-215  Therneau, T. and P. Grambsch. 2000 Modeling Survival Data: Extending the Cox Model Springer  Wilson, A.  N. Limnios, S Kelly-McNulty, Y. Armijo 2005. Modern Statistical and Mathematical Methods in Reliability. World Scientific, New Jersey  Xie, M. 1991. Software Reliability Modeling. World Scientific Press    B IOGRAPHY   Zhanshan \(Sam\ Ma holds a Ph.D. in Entomology and is a Ph.D. candidate in Computer Science at the University of Idaho. He has published approximately 30 journal and 30 conference papers, mainly in the former field.  Prior to his recent return to academia, he worked as senior network/software engineers in software industry.  His current research interests include reliability and survivability of wireless sensor networks, fault tolerance survival analysis, evolutionary game theory, evolutionary computation and bioinformatics  Axel W. Krings is a professor of Computer Science at the University of Idaho.  He received his Ph.D. \(1993\ and M.S 1991\ degrees in Computer Science from the University of Nebraska - Lincoln, and his M.S. \(1982\ in Electrical Engineering from the FH-Aachen, Germany.  Dr. Krings has published extensively in the area of Computer Network Survivability, Security, Fault-Tolerance and Realtime Scheduling. In 2004/2005 he was a visiting professor at the Institut d'Informatique et Mathématiques Appliquées de Grenoble, at the Institut National Polytechnique de Grenoble, France.  His work has been funded by DoE/INL DoT/NIATT, DoD/OST and NIST 



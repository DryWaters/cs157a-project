An Effective Boolean Algorithm for Mining Association Rules in Large Databases Suh-Ying Wur and Yungho Leu Department of Information Management National Taiwan University of Science and Technology f yhl,tammy g cs.ntust.edu.tw Abstract In this paper we present an effective Boolean algorithm for mining association rules in large databases of sales transactions Like the Apriori algorithm the proposed Boolean algorithm mines association rules in two steps In the 002rst step logic OR and AND operations are used to compute frequent itemsets In the second step logic AND and XOR operations are applied to derive all interesting association rules based on the computed frequent itemsets By only scanning the database once and avoiding generating candidate itemsets in computing frequent itemsets the Boolean algorithm gains a signi\002cant performance improvement over the Apriori algorithm We propose two ef\002cient implementations of the Boolean algorithm the BitStream approach and the Sparse-Matrix approach Through comprehensive experiments we show that both the BitStream approach and the Sparse-Martrix approach outperform the Apriori algorithm in all database settings Especially the Sparse-Matrix approach shows a very signi\002cant performance improvement over the Apriori algorithm 1 Introduction Due to the rapid growth in the size and number of databases there is a great need for discovering knowledge hidden in large databases Knowledge discovery in databases is also known as data mining Through data mining we can 002nd useful patterns and rules from databases These patterns and rules are very useful for decision making of an organization Therefore data mining has gained a lot of attentions recently Specialists from different areas including machine learning statistics arti\002cial intelligence and expert systems have developed many powerful tools for data mining As stated in 5 man y ki nds of kno wl edge can be mi ned from a database Among them the association rule is a very useful knowledge to be mined The de\002nition of an association rule is described in 3 a nd,for c on v e nience is res t ated in the following Let I f i 1 i 2  001\001\001 i n g beasetofitems Given a set of sales transactions D  where each transaction T is a subset of I  an association rule is an expression of the form X  Y where X and Y are subsets of I and X  Y 036  An association rule X  Y holds in the transaction set D with a con\002dence c if c  of the transactions that contain X also contain Y  An association rule X  Y has a support s if s  of the transactions in D contain both X and Y The task of mining association rules is to 002nd all the association rules which satisfy both the user-de\002ned minimum support and minimum con\002dence A set containing k items is called a k 000 itemset A k 000 itemset is called a frequent k 000 itemsets if given a minimum support s and a transaction set D  at least s  of the transactions in D contain the k 000 itemset  The process of mining association rules can be decomposed into two steps First all the frequent itemsets are identi\002ed Then the association rules satisfying both the minimum support and the minimum con\002dence are identi\002ed based on the frequent itemsets computed in the 002rst step A lot of literature such as[1,2,3,4,6,7,8,9 a v e p o i n t e d o u t t h a t  d u e t o t h e huge amount of data in a database the process of generating frequent itemsets turns out to be the bottleneck in mining association rules Therefore researchers have focused on developing ef\002cient and effective algorithms for the generation of frequent itemsets In this paper we present a Boolean algorithm for ef\002ciently mining association rules In the proposed algorithm we 002rst construct an item table and a transaction table by scanning the database once Then we repeatedly apply OR and AND operations on the item table and the transaction table respectively to generate the frequent itemsets Since both OR and AND operations can be ef\002ciently implemented the Boolean algorithm is very ef\002cient in generating frequent itemsets Through comprehensive experiments we show that the Boolean algorithm outperforms the 


Aprior algorithms in all the test cases This paper is organized as follows In Section 2 we review the related work Section 3 is devoted to the details of the Boolean algorithm In Section 4 we show the experiment results and compare the performance of the Boolean algorithm with that of the Apriori algorithm Finally we conclude this paper and give a word about the future work in Section 5 2 Related Work Agrawal et al Proposed an algorithm called AIS algorithm 1  f or generat i n g frequent i t e ms et s  In t h e A IS algorithm frequent itemsets are generated through iterations on scanning the database The iteration terminates when no new frequent itemset is derived After reading a transaction in the k th iteration the AIS algorithm computes the candidate k 000 itemsets by 002rst deriving a set of  k 000 1 000 itemsets which contains itemsets that are both in the frequent  k 000 1 000 itemsets and in the transaction Then the AIS algorithm extends the derived  k 000 1 000 itemsets with other items in the same transaction A candidate k 000 itemset computed from reading a transaction is added to the set of candidate k 000 itemsets for the k th iteration if it is not already contained in the set of all candidate k 000 itemsets  or the count of the corresponding candidate itemset is increased by one if it is already generated by an earlier transaction At the end of the iteration only those candidate k 000 itemsets that have a suf\002cient count value are considered as the frequent k 000 itemsets  One disadvantage of the AIS algorithm is that it generates too many invalid candidate itemsets Houtsma and Swami proposed the SETM algorithm 7 that uses SQL for generating the frequent itemsets Although it uses standard SQL join operation for generating candidate itemsets the SETM algorithm generates candidate itemsets through a process of iterations similar to that of the AIS algorithm The disadvantage of the SETM algorithm is similar to that of the AIS algorithm That is it generates too many invalid candidate itemsets Agrawal and Srikant also proposed two fast algorithms called Apriori and AprioriTid 3  f or generat i n g frequent itemsets In the Apriori algorithm the candidate k 000 itemsets is generated by a cross product of the frequent  k 000 1 000 itemsets with itself Then the database is scanned for computing the count of the candidate k 000 itemsets  The frequent k 000 itemsets consist of only the candidate k 000 itemsets with suf\002cient support This process is repeated until no new candidate itemsets is generated It is noted that in the Apriori algorithm each iteration requires a pass of scanning the database which incurs a severe performance penalty In order to reduce the number of scanning of the database in the Apriori algorithm the authors proposed Table 1 The truth table for AND OR and XOR operations V 1 1 1 0 0 V 2 1 0 1 0 V l AND V 2 1 0 0 0 V 1 OR V 2 1 1 1 0 V 1 XOR V 2 0 1 1 0 an alternative for fast mining association rules in 3 called AprioriTid Unlike the Apriori algorithm the AprioriTid algorithm scans the database only once in the 002rst iteration Although the AprioriTid algorithm reduces the number of scanning of the database its performance is inferior to that of the Apriori algorithm However it shows that both the Apriori algorithm and the AprioriTid algorithm are superior to the AIS and SETM algorithms Park et al proposed the DHP standing for Direct Hashing and Pruning algorithm  for e f 002 ci ent g enerat i o n o f frequent itemsets The DHP is a hash-based algorithm and is especially effective for the generation of frequent 2 000 itemsets  Based on the Apriori algorithm the DHP algorithm uses an ef\002cient approach to trim the number of candidate 2 000 itemsets  As a result the number of candidate 2 000 itemsets generated by the DHP algorithm is much smaller than those generated by the Apriori and the AprioriTid algorithms Yen and Chen proposed a DLG algorithm 11 a nd an EDM algorithm for discovering association rules In the EDM algorithm 12 i nner product operat i ons are p er formed for counting the support of an itemset While in the DLG algorithm logic AND operations are used to count the support Both algorithms avoid generating candidate itemsets which is a very time consuming operation Roberto proposed a Max-Miner algorithm 10 f or ef 002 c i e nt l y i d ent i fying long frequent itemsets which in turn can be used to generate other frequent itemsets 3 The Boolean Algorithm The Boolean algorithm mines association rules in two steps In the 002rst step the frequent itemsets is identi\002ed Then in the second step the association rules based on the identi\002ed frequent itemsets are generated Because the Boolean algorithm is based on AND OR and XOR logical operations we show for convenience the truth table of these operations in Table 1 In the following we 002rst present the generation of frequent itemsets in section 3.1 Then we describe the generation of association rules in section 3.2 For better understanding of the following discussions we use Example 1 as 


Database D TID Items 100 ACD 200 BCE 300 ABCE 400 BE Item Set I ABCDE Minimum support 40 Minimum Con\002dence 50 Figure 1 A sample database for data mining a sample database Example 1 Figure 1 shows a database D with four sales transactions each transaction is a subset of the item set I which contains 002ve items the minimum support and the minimum con\002dence are 40 and 50 respectively 3.1 Generation of Frequent Itemsets The Boolean algorithm generates frequent itemsets through several iterations based on two tables the item table and the transaction table Section 3.1.1 describes the construction of an initial item table and an initial transaction table Then Section 3.1.2 describes the process of generating frequent k 000 itemsets  3.1.1 Initializing Item Table and Transaction Table The item table in the k th iteration  TI k sa p 002 n table where p is the number of the frequent k 000 itemsets and n is the number of items in I  Each column in TI k represents a data item in item set I while each row in TI k represents a frequent k 000 itemset  An initial item table TI 1 isan n 002 n identity matrix where n is the number of items in I  A transaction table in the k th iteration  TT k sa p 002 m table where p is the number of frequent k 000 itemsets and m is the number of transactions in D  Each column in TT k represents a transaction in D  Each row in TT k records the transactions that contain the corresponding itemset TT k  i j  takes on value 1 if the j th transaction in TT k contains the i th frequent k 000 itemset in TI k  otherwise TT k  i j  takes on value 0 We need to scan database D once in order to construct the initial transaction table TT 1  Finally we use a column vector C k to store the reference count of all frequent k 000 itemsets in the k th iteration The reference count on a k 000 itemset can be obtained by counting the number of l s in the corresponding row of TT k  Hereafter we refer to the concatenation by put them together side by side of the item table  TI  transaction table  TT  and the reference count C as the Table 2 Notations TI k Item table at the k th iteration TT k Transaction table at the k th iteration C k Column vector of reference count in the k th iteration TIC k Concatenation of TI k and C k TITTC k Concatenation of TI k  TT k and C k TIC The union of all TIC k  k  1  001\001\001  to the last iteration TAR Table of association rules item/transaction/count table abbreviated as TITTC  In the Boolean algorithm we use TITTC k to denote the corresponding item/transaction/count table of the algorithm in the k th iteration The notations used in the Boolean algorithm are shown in Table 2 In Table 2 the TIC is the union by treating each row in TIC k as an element and the TIC k as a set for any k fall TIC k The TAR table will contain the derived association rules after the mining process completes Figure 2\(a shows the initial tables for example 1 which consist of TI 1  TT 1  C 1 and their concatenation TITTC 1  According to example 1 the minimum number of transactions needed for a frequent itemset is 40 003 5  which equals to 2  Based on the initial TITTC 1 weprunetherowcorresponding to itemset f D g whose reference count does not satisfy the minimum support requirement TITTC 1 that contains only frequent 1 000 itemsets isshowninFigure2\(b After generation of frequent 1 000 itemsets  the concatenation of the item table and the count vector i.e TIC 1  as shown in Figure 2\(c is retained in TIC for the generation of association rules The detailed algorithm for generating frequent 1 000 itemsets isshowninFigure3 3.1.2 Generation of Frequent k 000 itemsets Frequent k 000 itemsets can be generated through the following iteration Repeat 1 Get a pair of different rows  itemsets n TI k 000 1  2 Apply OR operation on these two rows to get a new temporary itemset If the temporary itemset contains more than k different items or is already produced by a previous OR operation go to step l i.e ignore this new itemset otherwise go to step 3 i.e a new k 000 itemset has been found 3 Apply AND operation on the two rows of TT k 000 1 which correspond to the rows of step 2 The result shows which transactions contain this new k 000 


a The Initial TITTC Table A B C D E T100 T200 T300 T400 Count A 1 0 0 0 0 1 0 1 0 2 B 0 1 0 0 0 0 1 1 1 3 C 0 0 1 0 0 1 1 1 0 3 D 0 0 0 1 0 1 0 0 0 1 E 0 0 0 0 1 0 1 1 1 3 b The TITTC 1 table A B C D E T100 T200 T300 T400 Count A 1 0 0 0 0 1 0 1 0 2 B 0 1 0 0 0 0 1 1 1 3 C 0 0 1 0 0 1 1 1 0 3 E 0 0 0 0 1 0 1 1 1 3 c The TIC 1 Table A B C D E count A 1 0 0 0 0 2 B 0 1 0 0 0 3 C 0 0 1 0 0 3 E 0 0 0 0 1 3 Figure 2 Generation of frequent 1 000 itemsets  Generating initial TITTC 1 and TIC 1  Suppose there are n items in I and m transactions in D Initialize TI 1  by setting TI 1  i j  1 if i  j otherwise TI 1  i j 0  Initialize TT 1  by setting TT 1  i j 0 for i 1  001\001\001  n  and j 1  001\001\001 m  Initialize C 1  by setting C 1  i 0 for i 1  001\001\001 n  for i 1 i  m  i obegin read the i th transaction from the database for  j 1 j  n  j obegin if the i th transaction contains the j th item TT 1  j i 1  end for i 1 i  n  i obegin for  j 1 j  m  j obegin C 1  i  C 1  i  TT 1  i j   end end for i 1 i  n  i obegin if  C 1  i   min support 002 number of total transactions in the database then do begin eliminate row TI 1  i  and TT 1  i   discard C 1  i   end end concatenate TI 1  TT 1 and C 1 toform TITTC 1 for next frequent 2 000 itemsets generation concatenate TI 1 and C 1 toform TIC 1 for association rules generation Figure 3 Algorithm for generating initial TITTC 1 and TIC 1  Algorithm for generation of frequent k 000 itemsets  Suppose after the iteration on computing  k 000 l  000 itemsets  TI k 000 1  has p rows and n columns TT k 000 1 has p rows and q columns count vector  C has p elements if  p 1  then stop else y 1  for i 1 i  p 000 1   i obegin for x  i 1 x  p  x obegin I count 0  for j 1 j  n  j obegin TI k  y j  TI k 000 1  i j  OR TI k 000 1  x j   I count  I Count  TI k  y j   end found  0  for z 1 z<y and I count  k and found 0   z obegin if row vector TI k  z  row vector TI k  y   then found 1  end T count 0  if found 0 and I count  k hendobegin for j 1 j  q  q obegin TT k  y j  TT k 000 1  i j  AND TT k 000 1  x j   T count  T count  TT k  y j   end end if  T count   min support 003 number of transactions in the database then do begin C k  y  T count  y=y+l end end end concatenate TI k  TT k and C k to form TITTC k for next frequent  k  l  000 itemsets generation concatenate TI k and C k to form TIC k for generating association rules Figure 4 Algorithm for generation of frequent k 000 itemsets itemset  We then count the number of 1 sintheresult to get the reference count of this new k 000 itemset  If the count is less than the number of transactions required by the minimum support the new k 000 itemset is discarded Otherwise the new k-itemset the AND result and the reference count are inserted into TI k  TT k and C k respectively Until no new pair of rows in TI k 000 1 left without being processed After the generation of frequent k 000 itemsets  the item table of the k 000 itemsets and its corresponding reference count vector are kept in TIC for generating association rules Figure 4 shows the algorithm for generation of frequent k 000 itemsets  In Figure 5 we use an example to illustrate this algorithm Continued from example 1 by performing OR and AND operations on TI 1  TT 1  in Figure 2\(b respectively we derive table TITTC 2 in Figure 5\(a It is noted that the itemset f AE g is not in table TITTC 2 because it fails to satisfy the minimum support requirement Similarly we derive table TITTC 3 from TITTC 2  which contains only one frequent 3 000 itemset  as is shown in Figure 5\(d After the iteration completes the 002nal TIC whichis needed for generation of the association rules is shown in 


a The TITTC 2 Table A B C D E T100 T200 T300 T400 Count AC 1 0 1 0 0 1 0 1 0 2 BC 0 1 1 0 0 0 1 1 0 2 BE 0 1 0 0 1 0 1 1 1 3 CE 0 0 1 0 1 0 1 1 0 2 b The TIC 2 Table A B C D E Count AC 1 0 1 0 0 2 BC 0 1 1 0 0 2 BE 0 1 0 0 1 3 CE 0 0 1 0 1 2 c The TITTC 3 Table A B C D E T100 T200 T300 T400 Count BCE 0 1 1 0 1 0 1 1 0 2 d The TIC 3 Table A B C D E Count BCE 0 1 1 0 1 2 Figure 5 Example for generating frequent k 000 itemsets A B C D E Count A 1 0 0 0 0 2 B 0 1 0 0 0 3 C 0 0 1 0 0 3 E 0 0 0 0 1 3 AC 1 0 1 0 0 2 BC 0 1 1 0 0 2 BE 0 1 0 0 1 3 CE 0 0 1 0 1 2 BCE 0 1 1 0 1 2 Figure 6 The 002nal TIC table Figure 6 3.2 Generation of Association Rules In this section we present the way that Boolean algorithm mines association rules from the 002nal frequent itemsets table As discussed in Section 1 if the association rule X  Y holds then all X  Y and X  Y must be frequent itemsets Since X  Y contains both X and Y  we can infer that if a frequent itemset is not a subset of any another frequent itemset in TIC then it can be neither an antecedent nor a consequent of any association rule This observation is the foundation of our Boolean algorithm in mining association rules To expedite the mining process we can 002rst eliminate from the TIC table those frequent itemsets that are not subset of any other frequent itemsets However we have found that only frequent 1 000 itemsets are candidates for the elimination Based on the above-mentioned observation the Boolean algorithm mines an association rule by 002rst identifying the potential antecedent and potential consequent and then validate if such a rule satis\002es the minimum con\002dence requirement The basic ideas for mining association rules are described in the following 1 Eliminate the rows of 1 000 itemsets from TIC which have no opportunity to be an antecedent or a consequent of any association rules The Boolean algorithm simply counts the occurrences of 1 s in each column of TI A 1 000 itemset whose corresponding column has only one 1 in the whole column should be eliminated 2 Apply an AND operation on two rows say X and Z  of TI in TIC  and then compare the result with the one which has less number of items assuming it is X  If they are equal then the frequent itemset with less number of items\(i.e X in this case is a potential antecedent 3 Apply an XOR operation on the two rows chosen in step 2  The result denoted as Y  of the XOR operation constitutes a potential consequent with X being its corresponding antecedent 4 If support Z support X  is greater than or equal to the minimum con\002dence then the association rule X  Y is generated Repeat step 2 through step 4 for any combination of X and Z until no new rules is found We create a table of association rules called TAR  to store the antecedent X  consequent Y  support and con\002dence for each association rule X  Y  Figure 7 shows the resultant TAR for example 1 and Figure 8 shows the detailed algorithm for the generation of association rules Take the third row of TAR  which read as f B g f E g  as an example It is derived from row B and row BE in the TIC table of Figure 6 By performing bit-wised AND operationontherow f B g and the row f BE g  we get a binary vector  01000  which is exactly the same as that of row f B g  Therefore f B g is an antecedent By performing a bit-wised XOR operation on row f BE g and row f B g we get itemset f E g as the corresponding consequent A rule of f B g f E g is therefore discovered By checking the counts of f BE g and f B g in TIC and performing the necessary computations we get the support and the con\002dence of this rule which is 75 and 100 respectively 4 Experiments and Results To evaluate the performance of the Boolean algorithm we perform several experiments on Sun SPARC 20 workstation with CPU clock rate 70 MHz 32 MB of main memory 


Antecedent Consequent Support Con\002dence A C 50 100 B C 50 67 B E 75 100 B CE 50 67 C A 50 67 C B 50 67 C E 50 67 C BE 50 67 E B 75 100 E C 50 67 E BC 50 67 BC E 50 100 BE C 50 67 CE B 50 100 Figure 7 TAR for example 1 and running SUNOS 4.1.3 Ul Data resided on a SPARC 002le system We 002rst describe two implementations of the Boolean algorithm in Section 4.1 Then we describe the method for generating synthetic data for experiments in section 4.2 The performance comparisons are given in section 4.3 4.1 Implementations of the Boolean Algorithm It is noted that although we use tables as data structures in the Boolean algorithm these data structures can actually be implemented more ef\002ciently using bit-wised vectors or sparse matrix technique In the following we present two implementations for the Boolean algorithm called the BitStream approach and the Sparse-Matrix approach We use C as the implementation language 4.1.1 The BitStream Approach Since each entry of both item table and transaction table can take only 1 or 0 as its value we use one bit to represent an entry in both the item table and the transaction table This approach signi\002cantly reduces the memory size and computation time for AND/OR operations compared with those of the pure table approach 4.1.2 The Sparse-Matrix Approach In general an itemset will contain only a small number of items compared to the number of items in item set I Also an itemset is usually related to a small number of transactions compared to the large number of transactions in the transaction set D  As a result an item table  TI k ra transaction table  TT k  are very sparse We therefore use sparse matrices to implement all item tables and transaction tables Using this approach only non-zero entries in the tables need to be considered  Generation of association rules  Suppose that after the generation of frequent itemsets we have TIC 1  TIC 2   001\001\001  TIC k tables and each table has num 1  num 2  001\001\001  numk number of rows respectively  Each table has  n 1 columns containing n items and the count vector  Num is a column vector which stores the number of rows contained in TIC 1   TIC 2  001\001\001 and TIC k Thatis Num 1  num 1  Num 2  num 2   001\001\001 and Num  k   numk  Perform a UNION operation on TIC 1  TIC 2  001\001\001  TIC k to form TIC  rows 0  for i 1 i   k  i o rows  rows  Num  k   for j 1 j  n  j obegin occurrence 0  for i 1 i  rows  i o occurrence  occurrence  TIC  i j   if occurrence  1 hendobegin eliminate the row of TIC that consists of the j th item rows  rows 000 1  Num 1  Num 1 000 1  end end p  1  for i 1 i  k  i obegin row 1=1  for j 1 j  i 000 1   j o row 1 row 1 Num  j   for row 2 row 1 Num  i  row 2   rows  row 2 obegin for j 1 j  n  j o temp  j   TIC  row 1 j  AND TIC  row 2 j   if row vector of temp  row vector TIC  row 1 and TIC  row 2 n 1  TIC  row 1 n 1   min-con\002dence then do begin Store the itemset in TIC  rowl   as the antecedent of the rule in TAR  p   for j 1 j  n  j o tempj   TIC  row 1 j  XOR TIC  row 2 j   Store the itemset in temp  j   as the consequent of the rule in TAR  p   Store TIC  row 2 n 1  number transactions in the database as the support of the rule in TAR  p   Store TIC  row 2 n 1 T IC  row 1 n 1  as the con\002dence of the rule in TAR  p   p  p 1  end end end Figure 8 Algorithm for generation of associ\255 ation rules 4.2 Generation of Synthetic Data We use extensive synthetic data to evaluate our algorithms The way in generating synthetic data is similar to that of 3 The d e\002 ni t i ons of v a ri ous paramet e rs us ed i n our experiments are summarized in Table 3 We generated six sales transaction databases by setting N  100  j D j  600 and j L j  2000  We chose 3 different values for j T j  which are 5  10 and 20  We also chose 3 different values for j I j  which are 2  4 and 6  Table 4 summarizes the database parameter settings 4.3 Performance Comparisons We tested the BitStream Sparse-Matrix and Apriori approaches over T 5 I 2  T 10 I 2  T 10 I 4  T 20 I 2  T 20 I 4 and T 20 I 6 synthetic databases with minimum supports ranging 


Table 3 De\002nition of Parameters j D j Number of transactions j T j Average size of the transactions j I j Average size of the potentially maximal frequent itemsets j L j Number of potentially maximal frequent itemsets N Number of items Table 4 Parameter settings Name j T j j I j j D j T 5 I 2 D 600 5 2 600 Tl 0 I 2 D 600 10 2 600 TI 0 I 4 D 600 10 4 600 T 20 I 2 D 600 20 2 600 T 20 I 4 D 600 20 4 600 T 20 I 6 D 600 20 6 600 from 1 to 2  Figure 9 shows that the Sparse-Matrix approach is superior to the other two approaches This is due to the fact that the Sparse-Matrix approach takes extremely less amount of time in generating frequent itemsets 5 Conclusions and Future work We proposed an effective Boolean algorithm for mining association rules in large sales transaction databases The major advantage of the Boolean algorithm over the Apriori algorithm is that the Boolean algorithm generates frequent itemsets without constructing candidate itemsets In contrast construction of candidate itemsets is required by the Apriori algorithm We also presented two ef\002cient implementations for the Boolean algorithm the BitStream approach and the SparseMatrix approach We conduct several experiments using different synthetic databases The results show that both the BitStream approach and the Sparse-Matrix approach outperform the Apriori approach in all database settings Especially the Sparse-Matrix approach shows a signi\002cant performance improvement over that of the Apriori approach In the future we plan to extend this work along the following directions 1 Utilize the parallel system to ef\002ciently generate frequent itemsets 2 Extend the Boolean algorithm for data which exhibit concept hierarchy property  T5I2 0 0.5 1 1.5 2 2.5 2 1.5 1 Minimum supports Time\(sec Apriori BitStream SparseMatrix T10I2 0 50 100 150 200 250 2 1.5 1 Minimum supports Time\(sec Apriori BitStream SparseMatrix T10I4 0 50 100 150 200 250 300 350 2 1.5 1 Minimum supports Time\(sec Apriori BitStream SparseMatrix Figure 9 Execution times 


 T20I2 0 5000 10000 15000 20000 25000 30000 35000 40000 45000 2 1.5 1 Minimum supports Time\(sec Apriori BitStream SparseMatrix T20I4 0 10000 20000 30000 40000 50000 60000 70000 80000 2 1.5 1 Minimum supports Time\(sec Apriori BitStream SparseMatrix T20I6 0 5000 10000 15000 20000 25000 30000 2 1.75 1.5 1.25 Minimum supports Time\(sec Apriori BitStream SparseMatrix Figure 9 Execution times\(Continued 3 Extend the Boolean algorithm for mining association rules in relational databases References  R  A gra w al T  I mielinski and A  S w ami M ining a ssociation rules between sets of items in large databases Proceedings of the ACM SIGMOD International Conference on Management of Data  pages 207\226216 May 1993 2 R  A g r a w al an d J  S h a fer  P a rallel m in in g o f a sso ciatio n rules IEEE Transactions on Knowledge and Data Engineering  8\(6\:962\226969 December 1996 3 R  A gr a w al and R  S r i kant  F ast a l gor i t h ms f o r m i n i n g a ssociation rules in large databases Proceedings of the 20th International Conference on Very Large Data Bases  September 1994 4 S  B r i n R  Mot w ani  J D  U l l man a nd S  T s ur  D ynami c itemset counting and implication rules for market basket data ACM SIGMOD International Conference on Management of Data  pages 255\226264 May 1997  M  S  Chen J  H an a nd P  S  Y u  D ata m ining An o v e rvie w from a database perspective IEEE Transactions on Knowledge and Data Engineering  8\(6\:866\226882 December 1996  E  H Han G Karypis and V  K umar  S calable parallel d ata mining for association rules ACM SIGMOD International Conference on Management of Data  pages 277\226288 May 1997  M  H outsma a nd A S w ami S et-oriented m ining f or association rules in relational databases IEEE 11th International Conference on Data Engineering  pages 25\22633 1995  J  S  p ark M S  C hen and P  S  Y u An ef fecti v e h ash b ased algorithm for mining association rules ACM SIGMOD International Conference on Management of Data  pages 175\226 186 May 1995 9 J  S  P ar k M S  C hen and P  S  Y u U s i n g a hashb ased method with transaction trimming for mining association rules IEEE Transactions on Knowledge and Data Engineering  9\(5\:813\226825 September/October 1997  B  J R ober t o E f 002 c i e nt l y mi ni ng l ong pat t e r n s f r o m databases ACM SIGMOD International Conference on Management of Data  pages 85\22693 1998  S  J  Y en and A  C hen A n ef 002 c i e nt appr oach t o di sco v ering knowledge from large databases Proceedings of the International Conference on Parallel and Distributed Information Systems  pages 8\22618 1996  S  J  Y en and A  C hen A n ef 002 c i e nt dat a mi ni ng t echni que for discovering interesting association rules Proceedings of the International Conference and Workshop on Database and Expert System Applications  pages 664\226669 1997 


local support count X.sup must be smaller than the local threshold s x D Following from the discus sion in Subsection 3.3 X.supq is bounded by the value min\(maxsupq X s x D  1 Hence an upper bound of X.sup can be computed by the sum x.supj  jEX.large-sites 2 min\(mazsupq\(X s x Dq  1 q=l q+?X.large-sites In FDM-LPP Si calls p-upper-bound to compute an upper bound for X.sup according to the above for mula This upper bound can be used to prune away X if it is smaller than the global support threshold 0 As discussed before both FDM-LUP and FDM LPP may have less candidate sets than FDM-LP How ever they require more storage and communication messages for the local support counts Their efficiency comparing with FDM-LP will depend largely on the data distribution 5 Performance Study of FDM An in-depth performance study has been performed to compare FDM with CD We have chosen to im plement the representative version of FDM FDM LP and compare it against CD Both algorithms are implemented on a distributed system by using PVM Parallel Virtual Machine 6 A series of three to six RS/6000 workstations running the AIX system are connected by a 10Mb LAN to perform the experi ment The databases in the experiment are composed of synthetic data In the experiment result the number of candidate sets found in FDM at each site is between 10  25 of that in CD The total message size in FDM is between 10  15 of that in CD The execution time of FDM is between 65  75 of that in CD The reduction in the number of candidate sets and message size in FDM is very significant The reduction in execution time is also substantial However it is not directly proportional to the reduction in candidate sets and message size This is mainly due to the overhead of running FDM and CD on PVM What we have ob served is that the overhead of PVM in FDM is very close to that in CD even though the amount of mes sage communication is significantly smaller in FDM From the results of our experiments it is also clear that the performance gain of FDM over CD will be higher in distributed systems in which the commu nication bandwidth is an important performance fac tor For example if the mining is being done on a distributed database over wide area or long haul net work The performance of FDM-LP against Apriori in a large database is also compared. In that case the response time of FDM-LP is only about 20 longer Interpretation transaction mean size mean size of maximal potentially large itemsets number of potentially large itemsets Number of items Clustering size Pool size Correlation level Multiplying factor Parameter ITI III ILI N sq Ps Mf Cr Value 10 4 2000 1000 5-6 50  70 0.5 1260  2400 Table 5 Parameter Table than 1/n of the response time of Apriori where n is the number of sites This is a very ideal speed-up In terms of total execution time FDM-LP is very close to Apriori The test bed that we use has six workstations Each one of them has its own local disk, and its partition is loaded on its local disk before the experiment starts The databases used in our experiment are synthetic data generated using the same techniques introduced in 2 lo The parameters used are similar to those in lo Table 5 is a list of the parameters and their values used in our synthetic databases Readers not familiar with these parameters can refer to 2  In the following we use the notation Tx.Iy.Dm to denote a database in which D  m in thousands IT1  x and 111  y T10.14.D200K s  3 4 5 6 Number of Nodes FDM CD Figure 1 Candidate Sets Reduction n  3 4 5 6 5.1 Candidate Sets and Message Size Re duction The sizes of the databases in our study range from 200K to 600K transactions and the minimumsupport threshold ranges from 3 to 3.75 Note that the number of candidate sets at each site are the same in CD and different in FDM In our experiment we witnessed a reduction of 75  90 of candidate sets on 39 


T10.14.D200K, n  3 T10.14.D200K, n  3 60  I S 8 3.00 3.25 3.510 3.75 YO  I YO Minimum support FDM kCD  gs 3.00 3.25 3.50 3.75 Minimum support FDM CD Figure 4 Message Size Reduction Figure 2 Candidate Sets Reduction average at each site when FDM-LP is compared with CD In Figure 1 the average number of candidate sets generated by FDM-LP and CD for a 200K transaction database are plotted against the number of partitions FDM-LP has a 75  90 reduction in the candidate sets The percentage of reduction increases when the number of partitions increases This shows that FDM becomes more effective when the system is scaled up In Figure 2 the same comparison between FDM-LP and CD is presented for the same database with three partitions on different thresholds In this case, FDM LP experienced a similar amount of reduction T10.14.D200K s  30/0 I 150 100 50 0 3 4 5 6 Number of Nodos FDM CB Figure 3 Message Size Reduction n  3 4 5 6 The reduction in candidate sets should have a pro portional impact on the reduction of messages in the comparison Moreover as discussed before the polling site technique guarantees that FDM only requires O\(n messages for each candidate set which is much smaller than the O\(n2 messages required in CD In our experiment FDM has about 90 reduction in the total message size in all cases when it is compared with CD In Figure 3 the total message size in FDM and CD for the same 200K database are plotted against the number of partitions In Figure 4 the same compari son on the same database of three partitions with dif ferent support thresholds are presented Both results confirm our analysis that FDM-LP is very effective in cutting down the number of messages required T10.14.D200K s  3 90 E3 28  U 70 cc Q 8 a c 50 c xs w  I 3 4 5 6 Number of Nodes FDM CD Figure 5 Execution Time n  3 4 5 6 T10.14.D200K n  3 3.00 3.25 3.50 3.75 Minimum Support E-FDM A-CD Figure 6 Execution Time 5.2 Execution Time Reduction We have also compared the execution time between FDM-LP and CD The execution time of FDM-LP and CD on a 200K database are plotted against the number of partitions in Figure 5 FDM-LP is about 40 


25  35 faster than CD in all cases In Figure 6 the comparison is plotted against different thresholds for the same database on three partitions Again FDM LP is shown to have similar amount of speed-up as in Figure 5 n  3 D  60011 s  2 I Apriori I FDM-LP response time sec I 1474 I 387 I total execution time sec I 844.7 I 842.9 I Table 6 Efficiency of FDM-LP We have also compared FDM-LP on three sites against Apriori with respect to a 600K transactions database in order to find out its efficiency in large database The result is shown in Table 6 The re sponse time of FDM-LP is only slightly 20 larger than 1/3 of that of Apriori In terms of the total ex ecution time FDM-LP is very close to Apriori For a large database FDM-LP may have a bigger portion of the database residing in the distributed memory than Apriori Therefore it will be much faster than running Apriori on the same database in a single ma chine This shows that FDM-LP on a scalable dis tributed system is an efficient and effective technique for mining association rules in large databases The performance study has demonstrated that FDM generates a much smaller set of candidate sets and requires a significantly smaller amount of mes sages when comparing with CD The improvement in execution time is also substantial even though the overhead incurred from PVM prevents FDM from achieving a speed-up proportional to the reduction in candidate sets and message size Even though we have only compared CD with FDM-LP there is enough evidence to show that FDM is more efficient than CD in a distributed environment In the follow ing sections we will discuss our future plan of imple menting the other versions of FDM 6 Discussions In this discussion we will first discuss the issue of possible extension of FDM for fast parallel mining of association rules Following that we will discuss two other related issues 1 the relationship between the effectiveness of FDM and the distribution of data and 2 support threshold relaxation for possible reduction of message overhead The CD and PDM algorithms are designed for share-nothing parallel environment. In particular CD has been implemented and tested on the IBM SP2 machine In designing algorithm for parallel mining of association rules not only the number and size of messages required should be minimized but also the number of synchronizations which is the number of rounds of message communication CD has a simple synchronization scheme It requires only one round of message communication in every iteration Besides the second iteration PDM also has the same synchro nization scheme as CD If FDM was used in the paral lel environment it has a shortcoming even though it requires much less message passings then CD it needs more synchronizations However FDM can be modi fied to overcome this problem In fact in each itera tion the candidate set reduction and global pruning techniques can be used to eliminate many candidates and then a broadcast can be used to exchange the local support counts of the remaining candidates This ap proach will generate less candidate sets than CD and has the same number of synchronization Therefore it will perform better than CD in all cases Performance studies has been carried out in a 32-nodes IBM SP2 to study several variations of this approach and the result is very promising Another interesting issue is the relationship be tween the performance of FDM and the distribution of the itemsets among the partitions From both The orem 1 and Example 1 it is clear that the number of candidate sets decreases dramatically if the distribu tion of itemsets is quite skewed among the partitions If most of the globally large itemsets were locally large at most of the sites the reduction of candidate sets in FDM would not have been as significant In the worst case if every globally large itemset is locally large at all the sites the candidate sets in FDM and CD will be the same Therefore data skewness may improve the performance of FDM in general Special partitioning technique can be used to increase the data skewness to optimize the performance of FDM Some further study is required to explore this issue The last issue that we want to discuss is the pos sible usage of the relaxation factor proposed in ll In FDM if a site sends not only those candidate sets which are locally large but also those that are almost locally large to the polling sites the polling sites may have local support counts from more sites to perform the global pruning of candidate sets For example if the support threshold is lo every site can send the candidate sets whose local support counts exceed 5 to their polling sites In this case for some candi date sets their polling sites may receive local sup port counts from more sites than the no relaxation case Hence the global pruning may be more effec tive However there is a trade-off between sending more candidate sets to the polling sites and the prun ing of candidate sets at the polling sites More study is necessary on the detailed relationship between the relaxation factor and the performance of the pruning 7 Conclusions In this paper we proposed and studied an efficient and effective distributed algorithm FDM for mining association rules Some interesting properties between 41 


locally and globally large itemsets are observed which leads to an effective technique for the reduction of can didate sets in the discovery of large itemsets Two powerful pruning techniques local and global prun ings are proposed Furthermore the optimization of the communications among the participating sites is performed in FDM using the polling sites Sev eral variations of FDM using different combination of pruning techniques are described A representative version FDM-LP is implemented and whose perfor mance is compared with the CD algorithm in a dis tributed system The result shows the high perfor mance of FDM at mining association rules Several issues related to the extensions of the method are also discussed The techniques of can didate set reduction and global pruning can be inte grated with CD to perform mining in a parallel envi ronment which will be better than CD when consider ing both message communication and synchronization Further improvement of the performance of the FDM algorithm using the skewness of data distribution and the relaxation of support thresholds is also discussed Recently there have been interesting studies on the mining of generalized association rules multiple level association rules quantitative association rules etc Extension of our method to the min ing of these kinds of rules in a distributed or parallel system are interesting issues for future research Also parallel and distributed data mining of other kinds of rules such as characteristic rules 7 classification rules, clustering 9 etc is an important direction for future studies For our performance studies an im plementation of the different versions of FDM on an IBM SP2 system with 32 nodes has been carried out and the result is very promising References l R Agrawal and J C Shafer Parallel mining of association rules Design implementation and experience In IBM Research Report 1996 2 R Agrawal and R Srikant Fast algorithms for mining association rules In Proc 1994 Int Conf Very Large Data Bases pages 487-499 Santiago Chile, September 1994 3 R Agrawal and R Srikant Mining sequential patterns In Proc 1995 Int Conf Data Engi neering pages 3-14 Taipei, Taiwan March 1995 4 D.W Cheung J Wan V Ng and C.Y Wong Maintenance of discovered association rules in large databases An incremental updating tech nique In Proc 1996 Int\222l Conf on Data Engi neering New Orleans, Louisiana Feb 1996 5 U M Fayyad 6 Piatetsky-Shapiro P Smyth and R Uthurusamy Advances zn Knowledge Dis covery and Data Mining AAAI/MIT Press 1996 6 A Geist A Beguelin J Dongarra W Jiang R Manchek and V Sunderam PVM Parallel Virtual Machine A Users\222 Guide and Tutorial for Networked Parallel Computing MIT Press 1994 7 J Han Y Cai and N Cercone Data driven discovery of quantitative rules in relational databases IEEE Trans Knowledge and Data En gineering 5:29-40 1993 Discovery of multiple-level association rules from large databases In Proc 1995 Int Conf Very Large Data Bases pages 420-431 Zurich Switzerland Sept 1995 8 J Han and Y Fu 9 R Ng and J Han Efficient and effective cluster ing method for spatial data mining In Proc 1994 Int Conf Very Large Data Bases pages 144-155 Santiago Chile, September 1994 lo J.S Park M.S Chen and P.S Yu An effec tive hash-based algorithm for mining association rules In Proc 1995 ACM-SIGMOD Int Conf Management of Data pages 175-186 San Jose CA May 1995 ll J.S Park M.S Chen, and P.S Yu Efficient par allel mining for association rules In Proc 4th Int Conf on Information and Knowledge Manage ment pages 31-36 Baltimore Maryland Nov 1995 12 A Savasere E Omiecinski and S Navathe An efficient algorithm for mining association rules in large databases In Proc 1995 Int Conf Very Large Data Bases pages 432-443 Zurich Switzerland Sept 1995 13 A Silberschatz M Stonebraker and J D U11 man Database research Achievements and op portunities into the 21st century In Report of an NSF Workshop on the Future of Database Sys tems Research May 1995 14 R Srikant and R Agrawal Mining general ized association rules In Proc 1995 Int Conf Very Large Data Bases pages 407-419 Zurich Switzerland Sept 1995 association rules in large relational tables In Proc 1996 ACM-SIGMOD Int Conf Manage ment of Data Montreal Canada June 1996 15 R Srikant and R Agrawal Mining quantitative 42 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



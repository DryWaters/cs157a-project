Some Aspects of Optimal Human-Computer Symbiosis in Multisensor Geospatial Data Fusion Eugene Levin Surveying Engineering Program Michigan Technological University Houghton MI 49931 906-487-2446 elevin@mtu.edu Aleksandr Sergeyev Electrical and Computer Engineering Technology Michigan Technological University Houghton MI 49931 906-487-2258 avsergue@mtu.edu Abstract\227 Nowadays vast amount of the available geospatial data provides additional opportunities for the targeting accuracy increase due to possibility of geospatial data fusion One of the most obvious operations is determining of the targets 3 D shapes and geospatial positions based on overlapped 2 D imagery and sensor modeling 3 D models allows for the extraction of such information about targets which cannot be measured directly based on single non-fused imagery Paper describes ongoing research effort at Michigan Tech attempting to combine advantages of human analysts and computer automated processing for ef\002cient human computer symbiosis for geospatial data fusion Speci\002cally capabilities provided by integration into geospatial targeting interfaces novel humancomputer interaction method such as eye-tracking and EEG was explored Paper describes research performed and results in more details T ABLE OF C ONTENTS 1 I NTRODUCTION                                   1 2 W HY E YE T RACKING  S TEREOSCOPIC F U SION AND 3D P ERCEPTION                       1 3 E XPERIMENTAL D ESIGN                         2 4 E XPERIMENT D ESCRIPTION                     3 5 G EOMETRICAL A CCURACY A NALYSIS           3 6 N EEDED FOR EEG IN P RACTICAL A PPLICA TION S CENARIOS                                 4 7 C ONCLUSION AND F UTURE W ORK              6 R EFERENCES                                     6 B IOGRAPHY                                      7 1 I NTRODUCTION Technologies and algorithms aimed at the measurement of object's 3 D properties based on imaging analysis were initially based on photogrammetry with subsequent improvement by the incorporation of computer vision Timely and accurate extraction of target's spatial properties in fully automated mode is complicated by the fact that multisensor geospatial data are burdened by multiple errors Moreover sometimes difference in sensor models scale image quality etc makes algorithmic stereoscopic stereo-restitution not feasible However trained geospatial analyst may fuse these image sources for example US satellite image on the left side and Chinese satellite image on the right side by means of simple mirror stereoscope This fusion ability is due to the human brain's visual perception ef\002ciency equivalent to 13  000 Pentium processors Therefore geospatial ana978-1-4673-1813-6/13 31  00 c 015 2013 IEEE 1 IEEEAC Paper 2153 Version 2 Updated 29/11/2012 lysts involvement in geospatial data re\002nement and decision making is still necessary from practical standpoint Then one of the most interesting research challenges in geospatial data fusion research is the of optimal symbiosis between automated operations To meet this challenge we performed research experiments attempting to combine advantages of human analyst and computer automated processing for ef\002cient human computer symbiosis for geospatial data fusion Speci\002cally experiments performed were related to analysis of potential of incoherent stereo pairs Incoherent stereo pairs were combined of images of obsolete map and actual aerial image of the same territory Anaglyphic product obtained after image processing of such stereo pairs was demonstrated to human analyst subject and stereo perception of such a stereo pairs was achieved The most interesting 002nding of experiment described is the fact that some new objects existing on aerial photo only appeared at incoherent stereo pairs as 3 D  This effect is caused by phenomena of human eye-brain system known as a human stereopsis and binocular summation which are widely deplo yed in photogrammetry To obtain the quantative measurements of effect the eye-tracking system has been deployed Analysis of human eye-movements driven by conscious and subconscious brain processes while percepting incoherent dataset derives a unique opportunity for human computer symbiosed geospatial systems There are two potential outcomes of such approach 017 interpretative analysts gaze-\002xation zones can help to localize the areas where mapping dataset should be updated 017 qunatative processing of eye 002xations geometry during stereo model perception allows transforming virtual 3 D model to geometrical one based on eyegrammetry method Given rational behind optimal system architecture of the simbiosed human-computer environment we came to conclusion that ef\002ciency of eye-tracking deployment can be increased by integration of brain encephalogram sensor EEG that can be trained to help in avoiding false command generated by eye-tracking system widely known as a Midas effect 2 W HY E YE T RACKING  S TEREOSCOPIC F USION AND 3D P ERCEPTION Described in this paper approach makes use of well-known properties of cyclopean vision the brain's ability to merge separate retinal projections into a single visual representation In normal human vision each eye receives a different two-dimensional retinal projection of an object These two retinal projections are offset by the lateral distance between the two eyes a phenomenon known as binocular disparity The visual system calculates the relative depth of an object 1 


Figure 1  Example of bi-temporal stereo-pair with respect to the object that the eyes are 002xated on The perception of three-dimensional depth from two disparate retinal projections is called stereoscopic depth perception or stereopsis Normal human stereopsis requires that projections of viewed object be present in both left and right retinal images When monocular projections to the retina are similar or identical a uni\002ed binocular representation is formed This process is called binocular fusion It is also possible for humans to perceive three-dimensional depth information about an object when a retinal projection of the object is present in one eye only In our pilot experiments human-analyst viewed two images a stereopair through anaglyph glasses which separated the visual information accessible to each eye A target object for example a white box shown in Fig 1 was presented in the view for one eye but absent in the view of the other eye Despite the fact that the target object is present in one image only the cyclopean percept of the stereopair includes a three-dimensional representation of the target image In this uni\002ed percept one of the stereopair images appears to be semi-transparent and overlaid on top of the other image as shown in Figure 1 This percept can be explained by the phenomenon of binocular summation Anaglyph glasses present images dichoptically a separate image shown for each eye When pair of low contrast images is shown dichoptically a dichoptic plaid is created consisting of the images overlaid on each other The perception of a dichoptic plaid results from a process of binocular summation In this process dissimilar monocular images reach consciousness at the same time and their effects are added up point by point Each image contributes to a uni\002ed perception while retaining its own distinct properties In our e xperiments participants also report a percept of a dichoptic plaid while viewing dissimilar stereopairs of bisensory images images representing the same spatial location obtained by different sensors Fig 2 shows a stereopair of bisensory images and a resulting dichoptic plaid The goal of our research is to measure the 3 D properties of objects perceived during dichoptic viewing of bitemporal and biosensor stereopairs We used eye-tracking methodology to compute the 002xation point of each eye as the analyst views a pair of dissimilar images through analglyph glasses Eye-tracking is a non-invasive methodology that records the position of the fovea during viewing The fundamental assumptions of eyetracking methodology are that the eye 002xates on objects of interest during visual attention 7 a b Figure 2  Difference between a stereopsis and  b binocular summation image features based points matching 3 E XPERIMENTAL D ESIGN Computing depth from binocular disparity is of interest to the geospatial information sciences because it can be used to automate quick depth calculations Our research experiment uses dichoptic devices separate images presented to the left and right eyes to study foveal 002xation during underlying stereopsis A common method of presenting dichoptic images is through anaglyph imagery In this process the analyst views a pair of specially prepared images through spectacles with lenses of two different colors usually red and cyan Each individual anaglyph image is composed of two superimposed images which represent the same object at two views slightly offset relative to each other Each layer of an analglyph image is printed in a different color The analyst views the merged image through the colored lens absorbing light from one view of offset image so that images received by the analyst's left and right eyes are offset with binocular disparity Alternative technologies for separating the two views in a dichoptic pair are polarization temporal separation by shutterglasses chroma-stereoscopy and auto stereoscopic displays utilizing spatial separation using lenses Eye-tracking technology can compute the depth of a 002xation point from the binocular disparity and express the disparity numerically While observing a scene the optical axes of both human eyes are naturally directed to the same point on the object This is 2 


particularly true for visual perception of stereoscopic images on a computer screen Human eyes move very rapidly while scanning images and the result of this scan is sent to the brain Our previous research 9 recorded participants eye movements while they observed the virtual stereoscopic models and used eye-tracking protocols to identify 002xations The 002xations are assumed to be feature points of the viewed objects and are used to reconstruct 3 D geometric models by applying classical stereo photogrammetric procedures This eyegrammetric approach is useful for 3 D models restoration measured by stereopsis As show in Fig 2 this method is not applicable for binocular summation estimation because one of the inhomogeneous stereopairs images does not contain the same features During binocular summation the human brain makes 224guesses\224 of where the corresponding feature should be Binocular summation reconstruction consists of two problems  017 how to select from the left and right eye 002xation cloud points depicted in Fig 6 the optimal combination of gazes from the left and right eyes 017 Determining accuracy of the 3 D estimates expressed in eye vergence angles The following approach is proposed to solve the 002rst problem 1 Image feature pixel is selected by of corner detection algorithms and applied to the center 002xation or cursor position if a cursor-click measurement was performed by the analyst to measure the point 2 Selecting image feature where exist by corner detection algorithm and then search of corresponding eye-gaze vector as the most satisfying for classical co-planarity photogrammetry equation 3 Selecting corresponding left and right gaze pair by leastsquare optimization 4 3 D coordinates of points are computed from the stereopair system transformed to 3 D geographical coordinates latitude longitude and altitude 4 E XPERIMENT D ESCRIPTION During experiments several datasets composed of geospatial images of known geometry were generated Some examples are shown in Fig 3 The challenge was to compare 3 D depth measured on standard stereopsis and binocular summation vision This comparison gives a proof-of-feasibility of using inhomogeneous stereopairs in geospatial data processing Speci\002cally depth measurements can be an indicator of the facts how eye-tracking derived binocular summation parallaxes are different from respective parallaxes derived for the same stereopairs in normal stereopsis mode As known stereo measurements by human operators were widely deployed in analog photogrammetry era De\002nition of operator ability of 3 D perception and 223personal difference\224 were some biometric procedures which were commonly used at those times in photogrammetric production environments We have performed a several research experiments following this methodology using Seeing Machines Facelab 4  0 eyetracking system of  sho wn in Figure 4 Experiments were collected with the following sequence 017 2 D and 3 D wearing anaglyphic glasses calibration of eye-tracking system with subject 017 recording of eye-movements protocols simultaneously with Figure 4  Eye-tracking experimental setup 3 D cursor 002xation on virtual 3 D model 017 detection of eye-\002xations in eye-movement protocols corresponding to mouse-click events 017 calculation of relative depth based left and right eye 002xations corresponding to the measurements and calibration parameters 017 comparison of relative depth for normal stereopsis and binocular summation cases To perform 3 D calibration we used control points in the geographical 3 D space Speci\002cally we used StereoGIS workstation provided by SimWright Fig 5 depicts anaglyphically generated test image from StereoGIS and used for the measurements on eye-tracker Graphical illustration of eye-movement trajectory and parallaxes for inhomogeneous case is presented on Figure 6 5 G EOMETRICAL A CCURACY A NALYSIS One of the most critical issues in estimation of potential use of new image fusion method is way of how accuracy and errors are de\002ned Speci\002cally for the stereoscopic measurements potentially we can use 2 ways of accuracy estimation and error de\002nitions 017 compare 3D coordinates photogrammetrically obtained 3 


Figure 3  Images from research experiments showing stereoscopic input and cyclopean percepts from normal stereo-pairs with respective coordinates obtained by means of inhomogeneous computation and 3 D wearing anaglyphic glasses calibration of eye-tracking system with subject 017 compare dimensions results of inhomogeneous computations with respective direct measurements of those dimensions on the ground In experiments described in this section we applied both methods StereoGIS softcop y photogrammetric en vironment was deployed in version of experiments by 223a\224scenario and direct measurements of boxes depicted on Fig 3 were used for the accuracy estimation by 223b\224-scenario Both methods of estimation direct and indirect are numeric and further can serve as a base for classical statistical errors analysis Results of 3 D processing recorded images are summarized in Table 1 It shows that binocular rival measurements provide about 70 percent of 3 D depth measurement accuracy compare to ground dimension and demonstrates the feasibility of the proposed system Future research will concentrate on increasing participant numbers and experimental database size using various aerial and satellite geospatial images 6 N EEDED FOR EEG IN P RACTICAL A PPLICATION S CENARIOS To avoid well-known Midas-effect associated with eyetracking based control of the manned and unmanned targeting environments the next step is the EEG control sensor integration In teleoperation complexity or even delayed communications can degrade performance and destabilize a system Sa ving operator time decreasing comple xity  or in some cases permitting sliding autonomy as noted in may improve robotic interfaces for single and joint robotic missions and outcomes We deployed ubiquitous gaming EEG sensors such as Emotiv to combine it with e yetracking HCI The Emotiv EPOC measures biosignals on the head skin surface Emotiv measure voltage signals at 14 locations around the scalp relative to a pair of feedbackcontrolled reference locations This is a typical measurement circuit for microvolt-scale biopotentials with very high input impedance a 002xed reference electrode and a secondary driven reference electrode which causes the detection system to ride on top of common-mode signals rejecting about 85 dB of common mode input and allowing the ampli\002er reference level to follow the background body potential with high accuracy The references are commonly referred to as CMS Common Mode Sensor and DRL Driven Right Leg a reference to the attachment of this sensor to the right leg of the patient in early electrocardiogram circuits for which it was originally developed Emotiv EPOC input signals are AC coupled  0  16 Hz high-pass and passed to a buffer ampli\002er with extremely high input impedance and a passband of DC 000 87 Hz The signals are sampled internally using a 16 000 bit ADC at 2048 samples per second per channel and then re\002ltered in the digital domain to remove 50 Hz 60 Hz and to heavily attenuate signals above 64 Hz This removes any residual harmonics of the mains signal and other high-frequency noise components including some EMG and very high frequency EEG data In combination with the 50 Hz notch 002lter the effective bandwidth of the signal is now 0  16 000 43 Hz The signals is downsampled to 128 samples=sec=channel  packaged into data packets and transmitted wirelessly to the receiver All of this 002ltering and processing removes all high frequency components which would otherwise appear as alias components in the 128 Hz data stream The remaining signal has an effective 14 bits of skin surface voltage signals with the LSB resolution of about 0  5 026V  with undistorted output from 0  16 to 43 Hz covering the delta theta alpha beta and low gamma bands This voltage trace can then be analyzed in the PC to extract these components Speci\002cally we are working integrating the Emotiv EEG Expressive and Cognitive toolsets The Ex4 


Table 1  Geometrical Accuracy Analysis Experiment Measured Stereoscopic Binocular Error Compared Error Compared Dimension\(m Stereoscopic Summation to Stereopsis to Ground Box 1 bitemporal 0.571 0.495 0.386 13.309 32.399 Box 2 bitemporal 0.68 0.695 0.599 2.205 11.911 Building bisensor 15.345 16.365 11.842 6.647 22.828 Average 22.379 a b Figure 5  a processed on StereoGIS and used for 3 D calibration b stereoscopic cursor used for control synchronization of attention eye-\002xations with manual control measurements procedures pressive toolset enables detecting the following expressions blinking winking looking right or left raising and furrowing brows smiling clenching and laughing Using Emotiv EEG in sensor fusion and platforms control is ef\002cient for processing 2 D and 3 D datasets It will accelerate broad-area search because many manipulations are made possible using thought rather than mouse clicks We performed pilot-studies integrating EEG with softcopy photogrammetric workstation Speci\002cally EEG was implemented for zooming in and out in addition to panning in the cardinal directions The pilot study user interface is depicted in Fig 7 Figure 6  Left\(white and Right\(yellow eye-movement trajectories corresponding 002xations and parallax de\002nition principles Fig 7 illustrates screenshot of the normal usage of the application The user initiates Photomod and and Gyro EGG applications separately Then the user sees a simple window with a combo box that contains potential applications that the program can interface The user selects the application using from the combo box list The user then sees the association of physical actions winking eye brow raise etc with application actions clicking zoom in/out etc To use softcopy photogrammetric workstation the user clicks the 223Start\224 button and interacts with the Google Earth using the Emotiv EPOC headset The Gyro EEG application also enables control of the mouse using the gyroscope built in to the headset Moving the mouse across the screen is as simple as turning one's head Looking from side to side up and down causes the mouse pointer to move across the screen just as a mouse would Clicking 224Stop\224 with either the mouse or the headset disables headset control of the mouse and the various 223Hotkey\224 actions Speci\002cally functions of our interest included control of stereoscopic 3 D cursor which makes impression for the subject that it changes its height over stereoscopic model It is achieved by changing of the parallax between left and right components of the stereoscopic cursor Integration of the eye-tracking and EEG HCI for the have the following advantages in real-life geospatial data fusion scenarios 017 help avoid visual attention interruptions 017 complement eye-tracking interest and emotion sensitive media IES 5 


a b Figure 7  a\v gaming EEG system b View of the application window Experimental results EEG based control of Softcopy Photogrammetric workstation 017 help avoid 223midas-touch\224 false commands 7 C ONCLUSION AND F UTURE W ORK Geospatial data fusion systems will gain the following bene\002ts of integrating described in this paper approach 017 Capability of data fusion which is impossible by other means 017 No deviation of analyst's visual attention 017 Increased operators productivity by using combined EEG and eye-tracking interaction techniques 017 Applicable for both single display and multi-display systems method can be applied to either worktable displays or windows 017 Collaborative work the Emotiv EEG allows to controlling two EEG devices 017 Ease of learning and use 017 Compatibility with currently deployed in industry systems and software Future developments will be devoted to the integration of the developed approach with state-of-the-art geospatial imaging interpretation environment The tasks to initiate stereoscopic viewing are eye-tracker calibration selecting images and rough registration to align the two images In addition eyetracker calibration is required periodically during the stereoscopic viewing Consequently we will use a dual monitor system one monitor devoted to 2 D viewing for calibration and image selection and another monitor devoted to stereoscopic viewing The left and right images will be selected by database queries and selection from annotated thumbnail images The initial registration will be accomplished by selecting corresponding points on the left and right images R EFERENCES  R Blake M Sloane and R Fox 223Further developments in binocular summation\224 Perception and Psychophysics 3D  266-276 1981  B Cyganek J Paul Siebert 223Introduction to 3D Computer Vision Techniques and Algorithms\224 Wiley John and Sons  Incor-porated 2009  CVB-Library http://library.thinkquest.org  A.T Duchowski Eye tracking methodology Theory and practice  New York Springer 2003  G Gienko E Levin 223Eye-tracking in augmented photogrammetric technologies\224 Proc of ASPRS Annual Conference Baltimore,MD 2005  C Harris M Stephens,\223A combined corner and edge detector,\224 Alvey Vision Conf pp 147-151 1988  M Just P Carpenter 223Eye 002xations and cognitive processes\224 Cognitive Psychology  8 441-480 1976  E Levin W Helton R Liimakka G Gienko 223Eye movement analysis in visual inspection of geospatial data\224 Proc of ASPRS Annual Conference Portland OR 2008  E Levin G Gienko A Sergeyev  223Human centric approach for geospatial data fusion in homelend defence and security application scenrious\224 SPIE Defense and Security Symposium Orlando FL  2008  L Liu C Tyler C Schor 223Failure of rivalry at low contrast evidence of a suprathreshold binocular summation process\224 Vision Res  32 1471-1479  R Patterson W Martin Human Stereopsis Human Factors  34\(6 669-692 1992  Q Ning 223Binocular disparity and the perception of depth\224 Neuron  18 359-368  Photomod softcopy photogrammetric software http://www.racurs.ru  A Poole and L Ball 223Eye tracking in HCI and usabilityresearch\224 In C Ghaoui ed Encyclopedia of humancomputer interaction Idea Group Inc Pennsylvania,2006  E Rodriguez-Seda and M Spong 223Experimental Comparison Study of Control Architectures for Bilateral Teleoperators\224 IEEE Transactions on Robotics 25\(6 1304-1318 2009  StereoGIS product description http://www.simwright.com/stereogis.htm  M Springer B Dias B Kannan B Browning E Jones B Argall M Dias M Zink 223Sliding Autonomy for Peer-to-Peer Human-Robot Teams\224 Technical Report CMU-RI-08-16 Robotics Institute Carnegie Mellon University April 2008  Seeing Machines faceLAB http://www.seeingmachines.com  EPOC Emotiv EEG http://emotiv.com 6 


B IOGRAPHY  Eugene Levin is currently a Program Chair of Surveying Engineering and Assistant Professor at School of Technology at Michigan Tech University Dr Levin also directing Integrated Geospatial Technology graduate program He received M.S degree in Astrogeodesy from Siberian State Geodetic Academy in 1982 and Ph.D in Photogrammetry from Moscow State Land Organization University in 1989  He has over 25 years of experience in US Israeli and Russian academy and geospatial industry He held research and managing positions with several Russian Israeli and US research academic institutions and high-tech companies including Research Institute of Applied Geodesy Omsk Agricultural Academy Rosnitc 224Land\224 Ness Technologies Physical Optics Corporation Digital Map Products American GNC and Future Concepts He has served as a Principal Investigator and Project Manager in multiple awardwinning government programs Aleksandr Sergeyev is currently an Assistant Professor in the Electrical Engineering Technology program in the School of Technology at Michigan Technological University Dr Aleksandr Sergeyev is earned his bachelor degree in electrical engineering in Moscow University of Electronics and Automation in 1995  He obtained the Master degree in Physics from Michigan Technological University in 2004 and the PhD degree in Electrical Engineering from Michigan Technological University in 2007  Dr Aleksandr Sergeyev research interests include high energy lasers propagation through the turbulent atmosphere developing advanced control algorithms for wavefront sensing and mitigating effects of the turbulent atmosphere digital inline holography digital signal processing and laser spectroscopy He is also involved in developing new eyetracking experimental techniques for extracting 3-D shape of the object from the movement of human eyes 7 


 intermediary is implemented and tested, demonstrating that the intervention of intermediaries won  t affect the performance of cipher system. On the other hand, there  re no obvious reductions in transmitting speed during experiment due to the utility of RC4+ algorithm. The efficiency experiment confirms this conclusion will be presented later in Section D C  Key Generation and Distribution Experiment Generating and distributing keys are, strictly speaking parts of cipher system. Before any actual uploading or downloading actions, peers should obtain the key corresponding to data from tracker by sending  getcipher   request along with identity information, public key and signature. The detail has been covered in Part III In the experiment, key generator on tracker generates keys to new torrents, illustrated in Fig. 12. Also, peers use their own generator to produce key pairs \(public and private keys\ sign their identity information and send required message to tracker in order to obtain file key. The public key will be used in two ways on tracker: \(1\ to verify the signature; \(2\to encrypt the requested file key The identity information which will be signed is arbitrary only if it  s consistent with peer  s identity and has no ambiguities. In this experime nt, it will be produced as  usernam  passw o rd  i p   t o rr ent h ash    An example of parameters to request a file key recoded in experiment, is shown below \(instructions are shown in italic form and not actually contained in HTTP request   info_hash=%BE%86%A0%C7   torrent hash    getCipher=yes indicates to get file key    sign=PCGqKJ0fM4K   signature    key=MIGfMA0GCSqGSIb3DQEBAQUAA4GN ADCBiQKBgQCQO   peer  s public key  The signature and public key are encoded by Base64, a common algorithm to produce HTTP parameters Different from the original BT, peers who  re not intermediary will send the request containing these parameters before uploading or downloading to obtain file key, and then be able to pe rform data transmission through cipher system In the experiment, all the responses of file keys to peers are identical with the keys generated by tracker generator. Hence the encrypting transmission is also correct D  Efficiency Experiment and Analysis IVCSD provides protection to the network and data with cost of time consumed by identity verification procedure and cipher system. Since looking up authority levels of peers and torrents can be processed in parallel with existing functions of original BT \(such as looking up existing torrents or registering new peers\it  s reasonable to argue that new consumption of time occurs in cipher system, especially encryption, decryption and key generation. Therefore, in this section, cost of time will be tested and analyzed 1  Testing Procedure a  Encryption and Decryption  Figure 12  An example of generated key for a torrent A random byte array with the size of 16KB \(16384 bytes, identical to the size of a default piece in BT network is generated and encrypted by RC4+ algorithm. Run this program for 10000 rounds, 100 times per round, and record the cost of time in each round The decryption of stream cipher algorithm \(such as RC4+\ very similar to encryption, typically just reversing the procedure. It  s sure that the time consumed in decryption is nearly the same as that in encryption. So the result and analysis in uploader \(encryption\ will be similar to that in downloader \(decryption b  Key Generation Nowadays, a secure length of key can be 1024 bits 128 bytes\. Recording the time used by random-number generator to produce a 128-bytes array will be crucial to determine the cost of time in key generator. Again, the program will be run for 10000 rounds, 100 times per round 2  Result Analysis After running the programs described above, the averages of encrypting times and key generating times are 31.24 milliseconds per round and 0.11 milliseconds per round, respectively a  Analysis of Encryption and Decryption With simple calculation, it  s easy to have the conclusion that in every second, approximately 3200 arrays \(reciprocal of 0.0003124\an be encrypted, in other words, 50MB data \(multiply 3200 and 16KB As mechanism of parallel and pipeline is so common on today  s machines, the encrypting/decrypting procedure will not really delay any transmission only if the transmitting speed in BT network is no more than 50MB/s defined as  speed bound  here. What  s more, if parallel mechanism is performed in encryption, allowing uploader to encrypt data \(or downloader to decrypt data\ore than one array at a time, the speed bound should be multiplied by the number of parallels, illustrated in Fig. 13 as solid line. 50MB/s is quite acceptable because it s beyond the bandwidth in most of machines today, especially household computers and portable laptops which uses wide bands giving a max transmitting speed of 10MB/s 89 89 89 


 Even using a 2Gbps optical fiber, five parallel encryptions suffice to the requirement of max speed of 250MB/s. The max speeds are also illustrated in Fig. 13 as dot lines Since the speed bound line ascends linearly, it  s easy to determine, as the method above, how many parallels should be deployed to achieve the maximum transmitting speed of bandwidth  Figure 13  Speed bounds comparing to max transmitting speed b  Analysis of Key Generation Since key generation occurs only once for a new torrent file, it  s easy to determine that generating ten thousand keys consumes only 11 seconds \(multiply 0.11 milliseconds to 10,000\. So it  s safe to argue that the cost of time is negligible 3  Efficiency of IVCSD According to the results and analyses above transmission in IVCSD is as efficient as original BT meaning that adding these functions and schemes will not affect the overall performance in BT network V  C ONCLUSION  This paper proposes a scheme, Identity Verification and Cipher System Distribution \(IVCSD\, to address secure problems in distributing big data. Identity verification protects the network in the aspect of peer admittance and data spreading, by assigning authority to torrents and peers, blocking unauthorized behaviors and keeping track of peers  actions. Cipher system protects the transmission in the aspect of data security and transmitting efficiency. With data encryption, intermediaries are allowed to participate into network without getting original data, sustaining the advantage of BT protocol After implementing IVCSD in testing machines experiment is performed and the results are analyzed Functionality and efficiency is positively demonstrated in the experimental results. As a conclusion, IVCSD is a feasible scheme to distribute big data, with some compromises between security and complexity There  re still some imperfect conditions. \(1\lthough behavior of intermediaries are proposed, implemented and tested, details about how or who to trigger or stop these actions are still absent. \(2\ The code implementing IVCSD for experiment in this paper uses Java. It may have some effects on evaluating efficiency. Other languages may be used in realistic deployment to achieve better performance 3\ Restricted by facilities an d environments in lab, all experiments and evaluations are completed within the local area network, instead of wider one such as Internet This fact may result in inaccuracy of experimental results but according to the analyses in Part IV, the functionality won  t be affected and the efficiency will still be acceptable in future implementation A CKNOWLEDGMENT  This paper is supported by the Hi-tech Research and Development Program of China \(863 Program\ under Grant No. 2011AA01A205, the Open Research Fund of The Academy of Satellite Application under grant NO SSTC-YJS-01-03, the National Natural Science Foundation of China under Grant No. 61232009, the Doctoral Fund of Ministry of Education of China under Grant No. 20101102110018,Beijing Natural Science Foundation under Grant No. 4122042, the fund of the State Key Laboratory of Software Development Environment under Grant No. SKLSDE-2012ZX-06 R EFERENCES  1  The Coming Data Deluge, IEEE Spectrum, February 2011 2  The data deluge, www.economist.com/node/15579717, Feb 25 2010 3  Arun Chokkalingam, Firasath Riyaz. BitTorrent Protocol Specification V 1.0. CSI 5321, Dec 12 2004 4  Zhang, X., Liu, D., Chen, S., Zhang, Z., & Sandhu, R. \(2008 Towards digital rights protection in BitTorrent-like P2P systems Proc. 15th SPIE/ACM Multimedia Computing and Networking MMCN 5  Balfe, S., Lakhani, A. D., & Paterson, K. G. \(2005, August Trusted computing: Providing security for peer-to-peer networks In Peer-to-Peer Computing, 2005. P2P 2005. Fifth IEEE International Conference on \(pp. 117-124\. IEEE 6  So, Jung Ki. Defending against Malicious Behaviors in BitTorrent Systems. Diss. NORTH CAROLINA STATE UNIVERSITY 2012 7  Douceur, J. R. \(2002\. The sybil attack. In Peer-to-peer Systems pp. 251-260\ Springer Berlin Heidelberg 8  Jun, S., & Ahamad, M. \(2005, August\. Incentives in BitTorrent induce free riding. In Proceedings of the 2005 ACM SIGCOMM workshop on Economics of peer-to-peer systems \(pp. 116-121 ACM 9  Sit E, Morris R. Security considerations for peer-to-peer distributed hash tables[J   Pe e r t o Peer Sy ste ms 2 0 0 2  2 6 1 2 6 9     Kinateder M, Pearson S. A privacy-enhanced peer-to-peer reputation system[J E Co m m e r ce a n d W e b T e chno l o g i e s  2 0 0 3   206-215   Damiani E, di Vimercati D C, Paraboschi S, et al. A reputationbased approach for choosing reliable resources in peer-to-peer networks[C P r o ce e d ing s o f t h e 9t h A C M co nf e r e n ce o n  Computer and communications security. ACM, 2002: 207-216   Shamir, A. \(1985\. Identity-based cryptosystems and signature schemes. InAdvances in cryptology \(pp. 47-53\. Springer Berlin/Heidelberg   Cohen B. Incentives build robustness in BitTorrent[C  W o r ks ho p  on Economics of Peer-to-Peer systems. 2003, 6: 68-72 90 90 90 


Figure 15  3D model of the patio test site Figure 16  Model of the patio test site combining 2D map data with 3D model data a Largest explored area b Smallest explored area Figure 14  Maps built by a pair of 2D mapping robots Yellow indicates area seen by both robots Magenta indicates area seen by one robot and Cyan represents area seen by the other a 3D point cloud built of the patio environment Figure 16 shows a model built combining 2D map data with 3D model data A four-robot mission scenario experiment was conducted at the mock-cave test site This included two 2D mapping robots a 3D modeling robot and a science sampling robot There was no time limit on the run Figure 17 shows a 3D model of the tunnel at the mock cave Figure 18 shows a model built combining 2D map data with 3D model data 7 C ONCLUSIONS  F UTURE W ORK The multi-robot coordination framework presented in this paper has been demonstrated to work for planetary cave mission scenarios where robots must explore model and take science samples Toward that end two coordination strategies have been implemented centralized and distributed Further a core communication framework has been outlined to enable a distributed heterogenous team of robots to actively communicate with each other and the base station and provide an online map of the explored region An operator interface has been designed to give the scientist enhanced situational awareness collating and merging information from all the different robots Finally techniques have been developed for post processing data to build 2  3-D models of the world that give a more accurate description of the explored space Fifteen 2D mapping runs with 2 robots were conducted The average coverage over all runs was 67 of total explorable area Maps from multiple robots have been merged and combined with 3D models for two test sites Despite these encouraging results several aspects have been identi\002ed that can be enhanced Given the short mission durations and small team of robots in the experiments conducted a simple path-to-goal costing metric was suf\002cient To use this system for more complex exploration and sampling missions there is a need for learning-based costing metrics Additional costing parameters have already been identi\002ed and analyzed for future implementation over the course of this study One of the allocation mechanisms in this study was a distributed system however task generation remained centralized through the operator interface In an ideal system robots would have the capability to generate and auction tasks based on interesting features they encounter Lastly the N P complete scheduling problem was approximated during task generation However better results could potentially 10 


Figure 17  3D model of the tunnel in the mock cave test site Figure 18  Model of the mock cave test site combining 2D map data with 3D model data be obtained by releasing this responsibility to the individual robots A CKNOWLEDGMENTS The authors thank the NASA STTR program for funding this project They would also like to thank Paul Scerri and the rCommerceLab at Carnegie Mellon University for lending hardware and robots for this research R EFERENCES  J C W erk er  S M W elch S L Thompson B Sprungman V Hildreth-Werker and R D Frederick 223Extraterrestrial caves Science habitat and resources a niac phase i study\\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2003  G Cushing T  T itus and E Maclennan 223Orbital obser vations of Martian cave-entrance candidates,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  M S Robinson B R Ha wk e A K Boyd R V Wagner E J Speyerer H Hiesinger and C H van der Bogert 223Lunar caves in mare deposits imaged by the LROC narrow angle camera,\224 in First Intl Planetary Caves Workshop  Carlsbad NM 2011  J W  Ashle y  A K Bo yd H Hiesinger  M S Robinson T Tran C H van der Bogert and LROC Science Team 223Lunar pits Sublunarean voids and the nature of mare emplacement,\224 in LPSC  The Woodlands,TX 2011  S Dubo wsk y  K Iagnemma and P  J Boston 223Microbots for large-scale planetary surface and subsurface exploration niac phase i.\224 NASA Innovative Advanced Concepts NIAC Tech Rep 2006  S Dubo wsk y  J Plante and P  Boston 223Lo w cost micro exploration robots for search and rescue in rough terrain,\224 in IEEE International Workshop on Safety Security and Rescue Robotics Gaithersburg MD  2006  S B K esner  223Mobility feasibility study of fuel cell powered hopping robots for space exploration,\224 Master's thesis Massachusetts Institute of Technology 2007  M T ambe D Pynadath and N Chauv at 223Building dynamic agent organizations in cyberspace,\224 IEEE Internet Computing  vol 4 no 2 pp 65\22673 March 2000  W  Sheng Q Y ang J T an and N Xi 223Distrib uted multi-robot coordination in area exploration,\224 Robot Auton Syst  vol 54 no 12 pp 945\226955 Dec 2006  A v ailable http://dx.doi.or g/10.1016/j.robot 2006.06.003  B Bro wning J Bruce M Bo wling and M M V eloso 223Stp Skills tactics and plays for multi-robot control in adversarial environments,\224 IEEE Journal of Control and Systems Engineering  2004  B P  Gerk e y and M J Mataric 223 A formal analysis and taxonomy of task allocation in multi-robot systems,\224 The International Journal of Robotics Research  vol 23 no 9 pp 939\226954 September 2004  M K oes I Nourbakhsh and K Sycara 223Heterogeneous multirobot coordination with spatial and temporal constraints,\224 in Proceedings of the Twentieth National Conference on Arti\002cial Intelligence AAAI  AAAI Press June 2005 pp 1292\2261297  M K oes K Sycara and I Nourbakhsh 223 A constraint optimization framework for fractured robot teams,\224 in AAMAS 06 Proceedings of the 002fth international joint conference on Autonomous agents and multiagent sys11 


tems  New York NY USA ACM 2006 pp 491\226493  M B Dias B Ghanem and A Stentz 223Impro ving cost estimation in market-based coordination of a distributed sensing task.\224 in IROS  IEEE 2005 pp 3972\2263977  M B Dias B Bro wning M M V eloso and A Stentz 223Dynamic heterogeneous robot teams engaged in adversarial tasks,\224 Tech Rep CMU-RI-TR-05-14 2005 technical report CMU-RI-05-14  S Thrun W  Bur g ard and D F ox Probabilistic Robotics Intelligent Robotics and Autonomous Agents  The MIT Press 2005 ch 9 pp 222\226236  H Mora v ec and A E Elfes 223High resolution maps from wide angle sonar,\224 in Proceedings of the 1985 IEEE International Conference on Robotics and Automation  March 1985  M Yguel O A ycard and C Laugier  223Update polic y of dense maps Ef\002cient algorithms and sparse representation,\224 in Intl Conf on Field and Service Robotics  2007  J.-P  Laumond 223T rajectories for mobile robots with kinematic and environment constraints.\224 in Proceedings International Conference on Intelligent Autonomous Systems  1986 pp 346\226354  T  Kanungo D Mount N Netan yahu C Piatk o R Silverman and A Wu 223An ef\002cient k-means clustering algorithm analysis and implementation,\224 IEEE Transactions on Pattern Analysis and Machine Intelligence  vol 24 2002  D J Rosenkrantz R E Stearns and P  M Le wis 223 An analysis of several heuristics for the traveling salesman problem,\224 SIAM Journal on Computing  Sept 1977  P  Scerri A F arinelli S Okamoto and M T ambe 223T oken approach for role allocation in extreme teams analysis and experimental evaluation,\224 in Enabling Technologies Infrastructure for Collaborative Enterprises  2004  M B Dias D Goldber g and A T  Stentz 223Mark etbased multirobot coordination for complex space applications,\224 in The 7th International Symposium on Arti\002cial Intelligence Robotics and Automation in Space  May 2003  G Grisetti C Stachniss and W  Bur g ard 223Impro ving grid-based slam with rao-blackwellized particle 002lters by adaptive proposals and selective resampling,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2005  227\227 223Impro v ed techniques for grid mapping with raoblackwellized particle 002lters,\224 IEEE Transactions on Robotics  2006  A Geiger  P  Lenz and R Urtasun 223 Are we ready for autonomous driving the kitti vision benchmark suite,\224 in Computer Vision and Pattern Recognition CVPR  Providence USA June 2012  A N 250 uchter H Surmann K Lingemann J Hertzberg and S Thrun 2236d slam with an application to autonomous mine mapping,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  2004 pp 1998\2262003  D Simon M Hebert and T  Kanade 223Real-time 3-d pose estimation using a high-speed range sensor,\224 in Proceedings of the IEEE International Conference on Robotics and Automation  1994 pp 2235\2262241 B IOGRAPHY  Ammar Husain received his B.S in Mechanical Engineering Robotics from the University of Illinois at Urbana-Champaign He is pursuing an M.S in Robotic Systems Development at Carnegie Mellon University He has previously worked on the guidance and control of autonomous aerial vehicles His research interests lie in the 002eld of perception-based planning Heather Jones received her B.S in Engineering and B.A in Computer Science from Swarthmore College in 2006 She analyzed operations for the Canadian robotic arm on the International Space Station while working at the NASA Johnson Space Center She is pursuing a PhD in Robotics at Carnegie Mellon University where she researches reconnaissance exploration and modeling of planetary caves Balajee Kannan received a B.E in Computer Science from the University of Madras and a B.E in Computer Engineering from the Sathyabama Institute of Science and technology He earned his PhD from the University of TennesseeKnoxville He served as a Project Scientist at Carnegie Mellon University and is currently working at GE as a Senior Cyber Physical Systems Architect Uland Wong received a B.S and M.S in Electrical and Computer Engineering and an M.S and PhD in Robotics all from Carnegie Mellon University He currently works at Carnegie Mellon as a Project Scientist His research lies at the intersection of physics-based vision and 002eld robotics Tiago Pimentel Tiago Pimentel is pursuing a B.E in Mechatronics at Universidade de Braslia Brazil As a summer scholar at Carnegie Mellon Universitys Robotics Institute he researched on multi-robots exploration His research interests lie in decision making and mobile robots Sarah Tang is currently a senior pursuing a B.S degree in Mechanical and Aerospace Engineering at Princeton University As a summer scholar at Carnegie Mellon University's Robotics Institute she researched multi-robot coordination Her research interests are in control and coordination for robot teams 12 


Shreyansh Daftry is pursuing a B.E in Electronics and Communication from Manipal Institute of Technology India As a summer scholar at Robotics Institute Carnegie Mellon University he researched on sensor fusion and 3D modeling of sub-surface planetary caves His research interests lie at the intersection of Field Robotics and Computer Vision Steven Huber received a B.S in Mechanical Engineering and an M.S in Robotics from Carnegie Mellon University He is curently Director of Structures and Mechanisms and Director of Business Development at Astrobotic Technology where he leads several NASA contracts William 223Red\224 L Whittaker received his B.S from Princeton University and his M.S and PhD from Carnegie Mellon University He is a University Professor and Director of the Field Robotics Center at Carnegie Mellon Red is a member of the National Academy of Engineering and a Fellow of the American Association for Arti\002cial Intelligence 13 



P Eklund J Karlsson Department of Computing Science Ume a University SE-90187 Ume a Sweden peklund@cs.umu.se johank@cs.umu.se J Rauch M  Sim unek University of Economics Faculty of Informatics and Statistics 130 67 Prague 3 Czech Republic 
rauch@vse.cz simunek@vse.cz Abstract Multimedia in health care is a topic of growing interest Guideline presentation utility and adherence require intelligence and multimedia to interact in decision support environments In this paper we aim at identifying guideline logic during statistical analysis The case study is drawn from a regional perspective on analysis and production of data infor 
mation and knowledge 1 Introduction Increasingly recognized as an important concept in health care evidence-based medicine 4 5 s tates t hat c are g iv ers s hould s elect diagnostic a nd therap eutic m etho ds based on where available strong empirical evidence In essence evidence-based medicine proposes a shift from experience-based care to acquiring knowledge through systematic reviews of 
appropriate literature To enable evidence-based care use of clinical guidelines is essential A clinical guideline is systematically developed statements to assist practitioner and patient decisions about appropriate health care for speciìc clinical circumstances  B y c onsensus among a l arge enough group of domain-experts such guidelines can be said to represent if not the only 
correct advice but at least given available research results good enough advice  To increase the adherence to clinical guidelines and thus evidence-based care computerbased decision support tools are important C linical guidelines often pro vide t he basis for logic in decision support systems Such logic can also be inferred more directly from patient data  i n e ssence b y v a rious f orms of statistical s tudies 
This paper is organized as follows Section 2 provides background and motivation from a regional health care perspective and presents the Coronary Artery Bypass Grafting CABG case study Section 3 presents the GUHA method with capability to represent computational schemas by logical rules Further in Section 4 we discuss representation of medical knowledge and scope of data management Finally Section 5 concludes the paper 
2 Coronary artery bypass grafting The case study presented in this paper is drawn from data warehousing and multimedia development experiences within the region County Council of V asterbotten in Northern 1 Computational coronary artery bypass grafting Proceedings of the Sixth International Conference on Computational Intelligence and Multimedia Applications \(ICCIMAê05 
0-7695-2358-7/05 $20.00 © 2005 IEEE 


Sweden The population is fairly small but the geographical area is large 4 inhabitants per square kilometer The region is unique in Sweden in that there is only one patient record system which is used both within primary care as well throughout the hospitals The region maintains the responsibility for several national quality registers where interactions with the patient record is highly prioritized Various quality assurance programmes are on the agenda and utility of data mining has been identiìed as having huge potentials In addition to quality registers several clinics maintain their own research databases such as for cardiac surgery where data mining deployment often is more straightforward but then usually at the expense of non-compliance with respect to terminologies with the electronic record structure In V asterbotten there are about 5-6 cardiac surgeries every day most of which are coronary bypass operations Several medical studies show relations between preand postoperative CABG data see for example  T he researc h database in Ume  aalsoinvolves intraoperative data Outcome predictions are certainly needed if possible from preoperative data but outcome predicitions while operating is additionally useful Preoperative data includes information on diseases heart conditions and function classes typical follow-up parameter number of injured vessels character if any of angina pectoris and so on Important intraoperative information is e.g time while aorta is closed and patient is in heart/lung machine number of anastomoses aorta quality and suitability for reoperation Postoperative attributes include death within 30 days after operation hours in intensive care respirator time and postsurgical conditions of various kind 3 Combining statistics and logic for clinical guidelines We will discuss problems appearing during phases prior to having nished analysis and reached consensus guidelines Obvious questions arise on the relation between statistical quantiìcations such as promoted in evidence based medicine and structuring knowledge in terms of logic needed for decision support construction Can we identify guideline logic already during statistical analysis and how can we provide an interplay between statistics and logic already during data analysis The logically elaborate 4ft-Miner approach based on GUHA is used to pro vide association rules for inference The 4ft-quantiìer  provides association rules    where antecedents  and succedents  are conjunctions of Boolean attributes or literals  such as AnginaPectoris  STABLE  and Age  70 80 Given a data matrix M  the association rule    is veriìed using the four-fold table 4ft The table should be given the interpretation that a is the number of objects satisfying M     a b   c d Table 1 The four-fold table both  and   b is the number of objects satisfying  but not   a  b is the number of objects satisfying   and so on Note that an association rule is true or false given a data matrix Proceedings of the Sixth International Conference on Computational Intelligence and Multimedia Applications \(ICCIMAê05 0-7695-2358-7/05 $20.00 © 2005 IEEE 


M Died 30 d  no  Died 30 d  yes  Reop  no   FunctClass  IIIA   LV  Funct  good  436 0   Reop  no   FunctClass  IIIA   LV  Funct  good  2495 44 Table 2 Reop  no   FunctClass  IIIA   LV  Funct  good   1  0;436 Died 30 d  no  Various 4ft-quantiìers are deìned in  Founded implication  p  Base with0 p  1 and Base  0 is subject to conditions a a  b  p and a  Base 1 The association rule   p  Base  is interpreted as 100 of objects satisfying  also satisfy  or  implies  on the level of 100 The above average relation   p  Base  again with 0 p  1and Base  0 is subject to conditions a a  b  1  p  a  c a  b  c  d and a  Base 2 The 4ft-Miner approach can be embedded into a logical calculi for a rst-order language The deduction rule         is applicable if we have that      is true in M whenever    is true in M Formore detail see  Analysis of CABG was done using the LISp-Miner tool  a nd in v o lv ed predictions on one hand from preoperative to postoperative conditions on the other hand from preoperative and intraoperative to postoperative conditions Can we make useful and reliable preoperative-to-postoperative predictions without intraoperative information Which are the most signiìcant intraoperative variables used in addition to preoperative variables when predicting postoperative conditions We have chosen to illuminate the LISp-Miner method and tool by looking at death after 30 days no/yes as an example of postoperative condition The number of postoperative deaths in the data set is rather small 44 cases which is less than 2 of the total number of records 2975 cases Tables 2 3 and 4 present typical examples from analysis within GUHA and using LISpMiner In Table 2 we have an example of a rule that provides 100 survival 30 days after operation This is the strongest founded implication of the form preop 1  preop n  p  Base Died 30 d  no   There are several other strong implications also of the form Age  preop 1  preop n  p  Base Died 30 d  no   In the situation for non-survival after 30 days the association rule for the above average relation turns out to be more suitable The 4ft for the strongest rule is shown in Table 3 The rule should be understood as patients satisfying LV  Funct  bad   M ainSten  no re Proceedings of the Sixth International Conference on Computational Intelligence and Multimedia Applications \(ICCIMAê05 0-7695-2358-7/05 $20.00 © 2005 IEEE 


M Died 30 d  yes  Died 30 d  no  LV  Funct  bad   M ainSten  no  13 125   LV  Funct  bad   M ainSten  no  31 2806 Table 3 LV  Funct  bad   M ainSten  no    5  37;13 Died 30 d  yes  with 5.37 more likely to satisfy Died 30 d  yes  as compared to all observed cases There are 13 patients satisfying both LV  Funct  bad   M ainSten  no swellas Died 30 d  yes  The weakest above average relation is AngP ect  unstable    1  18;19 Died 30 d  yes  Combinations with age  especially for patients in their later 60ês and early 70ês show association rules where patients having LV  Funct  bad sworsethanhaving FunctClass  IV  Finally involving intraoperative information Table 4 shows an example association rule with ClampT ime M     10 67   34 2931 Table 4 ClampT ime 45 90  M ainSten  no    4  0;10 Died 30 d  yes  4 Guideline implementation Representing clinical knowledge such as rules with logical constructs in traditional programming languages can cause problems of knowledge re-use and maintenance In approaches to representation of clinical guidelines are divided in three categories procedural approaches rule based systems and task based systems In early systems such as Arden  a p ro cedural approac h w as used w here the c linical kno w ledge i s i n t egrated i n t he source code itself in so called Medical Logic Modules MLM  T his a pproac h i s c lose to programming with traditional programming languages In rule based systems the logic and medical knowledge can be represented in a declarative form allowing developers to clearly separate algorithms that are used to apply the rules and the rules themselves In task based systems the interpretation of the rules varies between dierent contexts thus further simplifying re-use of rules Unfortunately regardless of which approach is chosen representing clinical knowledge in computers are dicult in practice since many clinical practice guidelines are still published simply as traditional text documents One example of such a guideline is the broadly accepted JNC guideline for hypertension treatment  R ules for pharmacological t reatment of hypertension i.e encoding and regional adaptation of the JNC6 guidelines was in 15 dev e lop e d m ore a s a t raditional programming task L ogic f or the s oft w are w as derived by manual review of the guideline To avoid such time-consuming and potentially erroneous reviews but still allow for computerization of guidelines a more formal way of representing guidelines is obviously needed In  o n d iagnosis of cognitiv e d isorder dementia and dementia types we go beyond the hypertension treatment approach and encode the DSM-IV guidelines t ogether with regional adaptations in a probabilistic argumentation framework Proceedings of the Sixth International Conference on Computational Intelligence and Multimedia Applications \(ICCIMAê05 0-7695-2358-7/05 $20.00 © 2005 IEEE 


Figure 1 Pharmacological treatment of anti-hypertension The hypertension example becomes interesting when the guideline already exists In many or even most situations local adaptations of clinical guidelines need to be developed and are then evidence-based on international results combined and reìned with local practise data Selecting and establishing the underlying logic of guidelines reveals how statistics does not comply with logical inference with logic on the other hand not providing language constructs that can handle statistical information In such a situation heuristics easily enters the scene and a required synergy and even convergence of statistical and logical methods remains unseen Alternatively statistics and logic can be bound more tightly together The goal is then to provide kind of an all-in-one computation that fulìlls requirements for evidence-based statistics and reasoning at the same time providing results represented more strictly within a corresponding logical machinery 5 Conclusions ous work on multimedia guideline implementations using intelligent computing techniques provide a framework for revealing possibilities and limitations of computer supported production of electronic guidelines In particular for CABG the 4ft-Miner approach turns out to be very suitable and providing useful insight related to concrete domain knowledge Further data is often discrete in nature and requirements for decision limits are not very apparent Statistics is traditionally appreciated through a narrow selection of tools sucient to manifest loyalty towards evidence-based medicine Data sets being large or small is irrelevant and applicability e.g of the central limit theorem is not an issue worthy of further contemplation Even worse logic is very sparsely seen as a computational discipline even Our case study on coronary artery bypass grafting together with the overview of previProceedings of the Sixth International Conference on Computational Intelligence and Multimedia Applications \(ICCIMAê05 0-7695-2358-7/05 $20.00 © 2005 IEEE 


less understood as being language and calculi where particular choices aect both representability of rules as well as outcome of inference In consequence evidence and belief is anchored by conìdence levels and documented consensus guidelines as pieces of pure text are pasted on the web and viewed as electronic guidelines Knowledge representation is thus very shallow with guideline performance and adherence impossible to measure We claim that regional and coherent approaches to information analysis and utility together with knowledge representation and presentation based on interaction between statistics and logic provide signiìcant impact on all levels of information management ranging from patient records through a well-founded understanding of organization and workîow all the way to guidelines based on computed evidence and implemented for the purpose of recommended or even enforced adherence Narrowing the gap between statistics and logic requires on one hand data quality guaranteed by fulìlling terminological information speciìcations on the other hand data householding and warehousing supporting exible data retrieval References  S  A c h our M Do jat C Rieux P  Bierling E Lepage A UMLS-Based Knowledge Acquisition Tool for Rule-Based Clinical Decision Support Systems Construction J Amer Med Inform Assoc 8 No 4 2001 351-360  A nagnostou T M  R emzi M  L yk ourinas and B  D ja v a n 2003 Artiìcial Neural Networks for Decision-Making in Urologic Oncology  European Urology 43 6 596 603  J  B ury  J F o x A Seyfang The ProForma guideline speciìcation language Progress and prospects  In First European Workshop on Computer-based Support for Clinical Guidelines and Protocols 2000 1-14  C ohen A  P  Sta v ri a nd W Hersh 2004 A categorization and analysis of the criticisms of Evidence-Based Medicine  International Journal of Medical Informatics 73  35Ö43  D a vido F  B Ha ynes D  S ac k e tt and R  S mith 1995 Evidence based medicine  British Medical Journal 310  1085Ö1086  P  Eklund Network Size Versus Preprocessing  in Fuzzy Sets Neural Networks and Soft Computing ed R Yager L Zadeh Van Nostrand Reinhold New York 1994 250-264  F ield M  a nd K Lohr 1990 Clinical practice guidelines directions for a new program  Chapt Attributes of good practice guidelines pp 53Ö77 National Academy Press  P  H  ajek T Havr anek Mechanising Hypothesis Formation Mathematical Foundations for a General Theory  Springer-Verlag 1978  G  H rip csak Writing Arden syntax medical logic modules  Comput Biol Med 24 1994 331-363  J Karlsson P  Eklund J Karlsson P  Eklund Data mining and structuring of executable data analysis reports Guideline development and implementation in a narrow sense  Medical Infobahn for Europe Stud Health Technol Inform 77 2000 790-794 Proceedings of the Sixth International Conference on Computational Intelligence and Multimedia Applications \(ICCIMAê05 0-7695-2358-7/05 $20.00 © 2005 IEEE 


 A Kirc h er J  A n t onsson A Babic and H  C asimir-Ahn Quan titativ e data analysis for exploring outcomes in cardiac surgery Studies in Health Technology and Informatics  68:457Ö460 1999  H Lindgren P  Eklund Logic of Dementia Guidelines in a Probabilistic Argumentation Framework  submitted  S P a rsons A Proof Theoretic Approach to Qualitative Probabilistic Reasoning Int.J Approximate Reasoning 19 1998 265-297  P e arson S C  M argolis S  D a vis L  S c h reier H Sok o l and L  G ottlieb 1995 Is consensus reproducible A study of an algorithmic guidelines development process  Medical Care 33 6 643Ö660  M P e rsson J Bohlin P  E klund Development and maintenance of guideline-based decision support for pharmacological treatment of hypertension  Comp Meth Progr Biomed 61 2000 209-219  M P e rsson T Mj orndal B Carlberg J Bohlin L H Lindholm Evaluation of a computer-based decision support system for treatment of hypertension with drugs Retrospective nonintervention testing of cost and guideline adherence  Internal Medicine 247 2000 87-93  P-E Puddu G Brancaccio M Leacc h e F Mon t i M Lan ti A  M enotti C  G audio U Papalia B Marino Prediction of early and delayed post-operative deaths after coronary artery bypass surgery alone in Italy  Italian Heart Journal 3 3 2002 166-181  J Rauc h Logical Calculi for Knowledge Discovery in Databases  in Principles of Data Mining and Knowledge Discovery J Komorowski and J Zytkow eds Springer Verlag Berlin 47-57 1997  J Rauc h M  Sim unek Alternative Approach to Mining Association Rules  In Proc ICDM02 Workshop The Foundation of Data Mining and Knowledge Discovery Maebashi Japan 2002 157-162 20 Diagnostic and Statistical Manual of Mental Disorders  Fourth Edition Text Revision DSM-IV-TR r   American Psychiatric Association 1994 21 The sixth report of the joint national committee on prevention detection evaluation and treatment of high blood pressure  Technical Report 98-4080 National Institutes of Health 1997 22 LISp-Miner  http://lispminer.vse.cz  v a n W ijk M J  v an der L ei M  M ossev e ld A  B ohnen and J  v an Bemmel 2002 Compliance of General Practitioners with a Guideline-based Decision Support System for Ordering Blood Tests  Journal of Clinical Chemistry 48 1 55Ö60 Proceedings of the Sixth International Conference on Computational Intelligence and Multimedia Applications \(ICCIMAê05 0-7695-2358-7/05 $20.00 © 2005 IEEE 


ear The speedup is 1.65 for the 2-node system indicating some degree of parallelization overhead mainly due to the interprocess communication to exchange the support count information The speedup is 3.76 for the 4-node system but the increasing rate of the speedup is 2.27 as the number of nodes is doubled from 2 to 4 As the number of nodes is doubled from 4 to 8 the increasing rate of the speedup is higher than linear again which indicates that PMIHP is quite scalable Number of Processors Time \(seconds 0 20000 40000 60000 80000 1 2 4 8 Figure 6 Total execution time of PMIHP to nd frequent 3-itemsets in 1,427 documents minsup  0.15 Number of Processors Speedup    0 2 4 6 8 2 4 8 Figure 7 Speedup of PMIHP minsup  0.15 The PMIHP algorithm has two main data mining activities counting the support of local candidate itemsets in the corresponding local database and counting the support of global candidate itemsets in multiple local databases These two activities are interleaved during the mining as the global support counting is invoked when the number of identiﬁed global candidate itemsets exceeds a certain number at each processing node which was set to 20,000 in our experiments To measure this global support counting time we reconﬁgured PMIHP to defer the global support counting of the global candidate itemsets at each node and synchronized the nodes before the start of the global support counting phase Figure 8 shows the global support counting time of the mining process with the logest run time among all the mining processes executed on different processing nodes Moreover we used the wall clock time to measure this global counting time hence it is an upper bound of the actual global support counting time of all the mining processes Comparing Figures 6 and 8 we can see that the 2-node case has a much longer global support counting phase than 4-node and 8-node cases The portion of the global support counting phase for the 2-node case is about 8 of the total execution time but it is about 4 for the 4-node case and about 3 for the 8-node case Thus the impact of the global support counting time on the overall speedup is very small and it is reduced further as the number of processing nodes increases Number of Processors Time \(seconds 0 1000 2000 3000 4000 2 4 8 Figure 8 Global support counting time to nd frequent 3-itemsets Since our processing environment does not provide the statistics for job accounting exact CPU time measurement was not feasible So we measured the average execution of a processing node using the wall clock time Figure 9 shows the average execution time of a node in the 1-node 2-node 4-node and 8-node conﬁgurations We can see that the 2-node case requires signiﬁcantly less average execution time per node than the 1-node case and as the number of processing nodes increases further the average execution time per node deceases more than linearly This result is completely consistent with the observed speedup values and also indicates that increased efﬁciency is behind the performance gain Since the identical PMIHP algorithm was executed on all of our system conﬁgurations the differences in execution time must be associated with some workload differences Figure 10 shows the average number of candidate 0-7695-2132-0/04/$17.00 \(C Proceedings of the 18th International Parallel and Distributed Processing Symposium \(IPDPSê04 


Number of Processors Time \(seconds 0 20000 40000 60000 80000 1 2 4 8 Figure 9 Average execution time per node to nd frequent 3-itemsets 2-itemsets processed by each node in our four different system conﬁgurations Note that the number of candidate 2itemsets for the 1-node case is approximately the same as the average number of candidate 2-itemsets for the 2-node case This result is consistent with the observed total and average execution times for the 1-node and 2-node cases There is signiﬁcant reduction in the average number of candidate 2-itemsets processed for the 4-node and 8-node cases over the 1-node and 2-node cases This result represents the nonuniform distribution of itemsets over the local databases as well as the effective reduction of the candidate itemsets by the Inverted Hashing and Pruning technique Number of Candidate 2-itemsets 0 100000 200000 300000 400000 MIHP 2-node PM IHP 4-node PM IHP 8-node PM IHP Figure 10 Average number of candidate 2itemsets per node Figure 11 shows the average number of candidate 3itemsets processed by each node We included the number of candidate 3-itemsets processed in Apriori to demonstrate the usefulness of the Inverted Hashing and Pruning The number of candidate 2-itemsets for Apriori was about 82 million which is why we did not show that in Figure 10 We can observe the same pattern of reduction in the candidates 3-itemsets as in the candidate 2-itemsets This reduction in the average number of candidate itemsets processed by each processing node may be the most clear explanation for the high increasing rate of the speedup observed as the number of processing nodes increases Number of Candidate 3-itemsets 0 200000 400000 600000 800000 Apriori MIHP 2-node PM IHP 4-node PM IHP 8-node P M IHP Figure 11 Average number of candidate 3itemsets per node We also ran a test with a larger database 8 weeks of the Wall Street Journal published from January 2 1991 through February 22 1991 February 23rd was a Wall Street Journal holiday There were 6,170 documents and 64,191 unique words of which 31,948 were frequent words at the minimum support level of 0.03 i.e 2 out of 6,170 documents The 1-node system required 845,702 seconds to nd 1,554,442 frequent 2-itemsets whereas the 8-node system required 33,183 seconds This performance represents a superliner speedup of 25.5 of the 8-node system over the 1-node system Thus we can conclude that the performance of PMIHP is quite scalable when the database is large and the minimum support level is low which is the case of high workload The 1-node case generated 16,174,357 candidate 2itemsets whereas the 8-node case generated 2,459,629 candidate 2-itemsets per node on the average The total number of candidate 2-itemsets counted by the 8 nodes were 19,677,031 which means that only 21.7 of the candidate 2-itemsets were counted at more than one processing node This implies that the distribution of words across the 8-week sample of the Wall Street Journal is quite skewed In the Count Distribution algorithm all the nodes count the same set of candidate itemsets in each pass over the database regardless of the distribution of items over the local databases On the other hand in our PMIHP algorithm not all candidate itemsets are counted at more than one node when the distribution of items over the local databases is not uniform Obviously the more skewed the data distribution the better the performance of PMIHP Cheung et al 4 propos ed s e v e ral approaches to partition the databas e 0-7695-2132-0/04/$17.00 \(C Proceedings of the 18th International Parallel and Distributed Processing Symposium \(IPDPSê04 


to achieve a high degree of skewness Text documents arranged in a chronological order do appear to have a high degree of skewness and beneﬁt the PMIHP algorithm 4 Conclusions The proposed Parallel Multipass with Inverted Hashing and Pruning PMIHP algorithm is a parallel version of our Multipass with Inverted Hashing and Pruning MIHP algorithm and it is effective for mining frequent itemsets in large text databases The Multipass approach reduces the required memory space at each processor by partitioning the frequent items and pro cessing each partition separately Thus the number of candidate itemsets to be processed is limited at each instance The Inverted Hashing and Pruning is used to prune the local and global candidate itemsets at each processing node and it also allows each processing node to determine the other peer processing nodes to poll in order to collect the local support counts of each global candidate itemset PMIHP distributes the workload to multiple processing nodes to reduce the total mining time without incurring much parallelization overhead The average number of candidate itemsets to be counted at each processing node is much smaller than the case of sequential mining while the time for the synchronization between processing nodes to exchange the count information for the global candidate itemsets is very small compared to the total execution time PMIHP is able to exploit the natural skewed distribution of words in text databases and demonstrates a superlinear speedup as the number of processing nodes increases It has a much better performance than well-known parallel Count Distribution algorithm 2 becaus e the a v erage number of candidate itemsets to be counted at each processing node is much smaller especially when the minimum support level is low Overall the performance of PMIHP is quite scalable even when the size of the text database is large and the minimum support level is low which is the case of high workload References  R  A gra w al and R  S r i kant   Fast Al gori t h ms for M i n i n g A ssociation Rules Proc of the 20th VLDB Conf  1994 pp 487–499  R Agra w a l and J C S hafer  Paral l e l M i n i n g o f A ssoci at i o n Rules IEEE Trans on Knowledge and Data Engineering  Vol 8 No 6 1996 pp 962–969 3 M  S  C hen J Han and P  S  Y u   Dat a Mi ni ng An Overview from a Database Perspective IEEE Trans on Knowledge and Data Engineering  Vol 8 No 6 1996 pp 866–883 4 D  W  C heung S  D L ee and Y  Xi ao  E f f ect of Dat a S k e w ness and Workload Balance in Parallel Data Mining IEEE Trans on Knowledge and Data Engineering  Vol 14 No 3 2002 pp 498–514 5 S  M  C hung and J Y ang  A Par al l e l D i s t r i b ut i v e J oi n A l gorithm for Cube-Connected Multiprocessors IEEE Trans on Parallel and Distributed Systems  Vol 7 No 2 1996 pp 127–137  R  F e l dman and H Hi rsh F i ndi ng Associ at i ons i n Col l ections of Text Machine Learning and Data Mining Methods and Applications  R Michalski I Bratko and M Kubat editors John Wiley and Sons 1998 pp 223–240  R F e l dman I Dagen and H  H i rsh Mi ni ng T e xt Usi n g Keyword Distributions Journal of Intelligent Information Systems  Vol 10 No 3 1998 pp 281–300  C  Fox L e x i cal Anal ysi s and S t opl i s t s   Inforamtion Retrieval Data Structures and Algorithms W.FrakesandR Baeza-Yates editors Prentice Hall 1992 pp 102–130 9 M  G or don and S  Dumai s Usi ng L a t e nt S e mant i c I nde xi ng for Literature Based Discovery Journal of the Amer Soc of Info Science  Vol 49 No 8 1998 pp 674–685  J Han J P e i  and Y  Y i n Mi n i n g F r equent Pat t e r n s w i t hout Candidate Generation Proc of ACM SIGMOD Intêl Conf on Management of Data  2000 pp 1–12  J D Holt and S  M Chung Multipass Algorithms for Mining Association Rules in Text Databases Knowledge and Information Systems  Vol 3 No 2 Springer-Verlag 2001 pp 168–183  J D Hol t and S  M C hung Mi ni ng Associ at i o n R ul es Using Inverted Hashing and Pruning Information Processing Letters  Vol 83 No 4 Elsevier Science 2002 pp 211–220  J D Hol t and S  M C hung Mi ni ng associ at i o n R ul es i n Text Databases Using Multipass with Inverted Hashing and Pruning Proc of the 14th IEEE Intêl Conf on Tools with Artiìcial Intelligence  2002 pp 49–56  J S  Park M S  C hen and P  S  Y u   Usi n g a Hash-B a sed Method with Transaction Trimming for Mining Association Rules IEEE Trans on Knowledge and Data Engineering  Vol 9 No 5 1997 pp 813–825  G  S a l t on Automatic Text Processing The Transformation Analysis and Retrieval of Information by Computer  Addison-Wesley Publishing 1988  E  M V oorhees and D K Harmon edi t o rs The Fifth Text Retrieval Conference  National Institute of Standards and Technology 1997  O R  Z a i a ne and M L  Ant o i ne C l assi f y i n g T e x t D ocuments by Associating Terms with Text Categories Proc of the 13th Australian Database Conf  2002 0-7695-2132-0/04/$17.00 \(C Proceedings of the 18th International Parallel and Distributed Processing Symposium \(IPDPSê04 


  11 could be improved by a simple modification of the feed by adding a small tuning vane to th e feed. Therefore, it can be stated that some improvement can be expected by modification of the feeds, and adaptation of the test antenna in such a way that surrounding Ku-band element are closed   Figure 28 Reflection coefficient of Ku-band stacked patch antenna element in dual-frequency antenna stack  Figure 29 shows the influence of the L-band slots on the return loss of the Ku-band antenna element. To this end, the four connectors of the L-band elements were alternately open and terminated by means of 50 loads. The deviations were measured with respect to the set-up where all connectors were terminated Apparently, the deviations are acceptable  Figure 29 Influence of L-band termination on return loss of Ku-band antenna element, with and without termination Figure 30 and Figure 31 show the isolation between the Lband and Ku-band elements in L-band and Ku-band respectively. To this end the S21-parameters have been measured. These figures reveal that the mutual coupling between the L-band and Ku-band elements is sufficiently small  Figure 30 Measured isolation between L-band and Ku-band antennas in L-band frequencies  Figure 31 Measured isolation between L-band and Ku-band antennas in Ku-band frequencies From these measurements it can be concluded that opportunities should be considered to improve the design of the dual-frequency antenna \(by optimizing the feeds of the Ku-band elements antenna and the measurement set-up \(closure of surrounding Ku-band ports and use of appropriate connectors for the open Ku-band ports 7  M ODIFIED DUAL FREQUENCY ANTENNA  In order to benefit the str ong points of the two separate designs as discussed in section 4, an alternative antenna is proposed that exploits the properties of a \221best of both worlds\222 solution employing ideas from both designs. The modified antenna possesses an aperture fed L-band patch of a similar form to first design, but situated towards the bottom of the stack. Ku band el ements are located within the L-band perforations and para sitic patches are situated above a foam spacer \(see Figure 32 and Figure 33\A measurement campaign is underway to assess the behaviour of this modified test antenna 


  12  Figure 32 Bottom view of dual frequency antenna tile with perforated L-band patc h in lower layer with Kuband patches  Figure 33 Layer stack with perforated L-band patch in lower layer with Ku-band patches  8  B EAM FORMING N ETWORK  A major keystone for the su ccess of phased array antenna onboard aircraft is the capability of steering the main beam in the direction of the geosta tionary satellites. This requires the inclusion of a broadband beam forming network. Beam steering can be realized by adding RF-phase shifters and LNA\222s to the antenna elements of the array. However traditional phase shifters in ge neral have a narrow band, and hence do not yield the re quired broadband capability Alternative technologies for broadband beam forming are switched beam networks \(using Butler matrices innovative designs for RF-compone nts such as phase shifter LNA components in \(M\IC technology, or beam forming by using opti cal ring resonators  The German SME IMST is involved in several projects for development of electronica lly steerable phased array antennas for satellite communication. In the NATALIA project \(New Automotive Track ing Antenna for Low-cost Innovative Applications\ ESA, IMST is investigating the possibility of realizing a compact costeffective solution for a recei ve-only full electronically steerable antenna for cars in Ku-band. This antenna is a planar array composed of approximately 150 patches circularly polarised by using a 90\260 hybrid, and arranged in a hexagonal fashion. Each patc h is equipped with a MMIC corechip containing a phase sh ifting unit, LNA and digital steering logic  In the Netherlands, a consortiu m \(consisting of University of Twente, Lionix BV, National Aerospace Laboratory NLR and Cyner Substrates developing in the national FlySmart project technology for a broadband optical beam forming network. For the steering of the beam of the conformal phased array a squi nt-free, continuously tunable mechanism is proposed that is based on a fully integrated optical beam forming network \(OBFN optical ring resonators \(ORRs as tunable delay elements. A narrowband continuously tunabl e optical TTD device is realized as a recirculating wa veguide coupled to a straight waveguide. This straight wave guide can behave as a bandpass filter with a periodic, bell-shaped tunable group delay response. The maximum group delay occurs at a tunable resonance frequency. A larger delay-bandwidth product can be achieved by cascading multiple ORR sections. A complete OBFN can be obtaine d by grouping several delays and combining elements in one optical circuit. Such an OBFN can be realized on a si ngle-chip. Electrical/Optical E/O O E by means of filter based single-sideband modulation suppressing the carrier lanced coherent optical detection. Further details of the optical beamforming network have been presented in Re The proof-ofconcept has been shown by manufacturing a chip for an 8x1 OBFN. Essential components of the OBFN are the optical modulators, which are used to modulate the light in the ORR system 9  C ONCLUSIONS  For enhanced communicati on on board aircraft, novel antenna systems with broa dband satellite-based capabilities are required. So far, existi ng L-band satellite based systems for communications are used primarily for passenger application \(APC\i nistrative communications AAC and now data are tending to evolve towards broadband dig ital applications \(Voice over IP\any studies are going on worldwide to employ Kuband TV geostationary sate llites for communication with mobile terminals on aircraft The inbound traffic is about 5 times higher than the outbound The inbound traffic requires the availability of a broadband Ku-band antenna in receive mode only. The outbound traffic services can be supplied by the Inmarsat SBB link, whic h requires the installation of an L-band transmit antenna. In order to avoid both the installation of L-band antenna and Ku-band antenna, the concept of a hybrid dual frequency antenna operating L 


  13 band and Ku-band with low aerodynamic profile has been investigated in this paper. Keyaspects of this research are 200  Design and testing dual-fre quency antenna elements operating in both L-band and Ku-band 200  Conformal aspects of Ku-band phased array antennas 200  Beam forming algorithms for planar and conformal phased array antennas Two designs for dual-frequency antenna tiles consisting of 8x8 Ku-band antenna elements and one L-band element The designs have been analysed by means of computer simulations. Both designs show promising performance both in L-band and Ku-band. The design with slotted Lband antenna has a resonant fre quency in receive mode with a bandwidth of about 1 GHz. The Ku-band antenna is a stacked patch configuration where a parasitic element is placed above a lower patch separated by dedicated space filler. The manufactured protot ype antennas indicate that the bandwidth is sufficiently large In order to be able to communicate with geostationary satellites also at high latitudes e.g. during inter-continental flights\stem should have sufficient performance at low elevation angles. The antenna Ku-band system is required to have a small beamwidth \(to discriminate between the satellite signals\gain 30 dB angles. The effects of these requirements on the size and positioning of the antenna on the aircraft fuselage have been investigated. These requirements can be best satisfi ed by installing two planar phased array antennas on both side s of the fuselage with at least 1600 Ku-band elements. Each element has two feed lines, one for each polarization Every feed line has to be connected to the beam formi ng network. This means that the connections cannot be routed to one of the four sides of the antenna. Instead the concept of vertical feed lines \(by means of vias in a sufficiently thick substrate recommended. These vertical f eed lines connect the L-band and Ku-band antenna elements in the upper layer with feed networks in multiple lower laye rs. This vertical feed line system was not available so far due to manufacturing problems The performances of one dua l-frequency antenna design have been investigated by manufacturing two test antennas without vertical feed line syst em. The first antenna contains only a multilayer structure with L-band slots and 8x8 Kuband stacked patches. The performances of the L-band slots and Ku-band stacked patches c ould be measured separately It was concluded that opportun ities should be considered to improve the design of the dual-frequency antenna \(by optimizing the feeds of the Ku-b and elements the dual frequency test-antenna and the measurement set-up More important, however, is the realization of a mechanically stable vertical feed line system, so that the properties of L-band and Ku-band elements can be measured adequately The second test antenna contains only a multilayer structure with 8x8 Ku-band stacked patches and a feed network with 8 combiners, where each comb iner coherently sums 8 antenna elements. In combination with a prototype 8x1 OBFN, a Ku-band phased arra y antenna is obtained of which the beam can be steered in one direction. This second test antenna is used to analyze the broadband properties of the 8x8 Ku-band antenna array and 8x1 OBFN. The measured performances of this antenna are presented in Ref   A CKNOWLEDGMENT  This work was part of the EU 6 th Framework project ANASTASIA., and the FlySmart project, supported by the Dutch Ministry of Economic A ffairs, SenterNovem project numbers ISO53030 The FlySmart project is part of the Eureka PIDEA  project SMART Cyner Substrates is acknowle dged for technical assistance during the fabrication of the prototype antennas 


  14 R EFERENCES  1  P. Jorna, H. Schippers, J. Verpoorte, \223Beam Synthesis for Conformal Array Antennas with Efficient Tapering\224 Proceedings of 5 th European Workshop on Conformal Antennas, Bristol, September 11-12, 2007 2  The Radio Regulations, editi on of 2004, contain the complete texts of the Radio Regulations as adopted by the World Radio-communication Conference \(Geneva WRC-95 tly revised and adopted by the World Radio-communication Conference WRC-97\RadioWRC2000\and the World Radio-communication Conference WRC-03 Resolutions, Recommendations and ITU-R Recommendations incorporat ed by reference 3  RECOMMENDATION ITU-R M.1643, Technical and operational requirements for ai rcraft earth stations of aeronautical mobile-satellite service including those using fixed satellite service network transponders in the band 14-14.5 GHz \(Earth-to-space 4  ETSI EN 302 186 v1.1.1 \(2004-01 Stations and Systems \(SES\onised European Norms for satellite mobile Aircraft Earth Stations AESs\the 11 12/14 GHz frequency bands covering essential requirement s under article 3.2 of the R&TTE directive 5  EUROCAE ED-14E; Environmental Conditions and Test procedures for Airbor ne Equipment, March 2005 6  F. Croq and D. M. Pozar, \223Millimeter wave design of wide-band aperture-coupled stacked microstrip antennas,\224 IEEE Trans. Antennas Propagation, vol. 39 pp. 1770\2261776, Dec. 1991 7  S. D. Targonski, R. B. Waterhouse, D. M. Pozar Design of wide-band aperture stacked patch microstrip antennas ", IEEE Transactions on Antennas and Propagation, vol. 46, no. 9, Sep. 1998, pp. 1245-1251 8  R. B. Waterhouse, "Design of probe-fed stacked patches", IEEE Transactions on Antennas and Propagation, vol. 47, no. 12, Dec. 1999, pp. 1780-1784 9  D.M. Pozar, S. D. Targonski, \223A shared aperture dualband dual-polarised microstrip array\224, IEEE Transactions on Antennas and Propagation,Vol. 49 no. 2,Feb. 2001, pp. 150-157 10  http://www.ansoft.com 11  J-F. Z\374rcher, F.E. Gardiol, \223Broadband patch antennas\224 Artech House, \(1995\N 0-89006-777-5 12  H. Schippers, J. Verpoorte, P. Jorna, A. Hulzinga, A Meijerink, C. G. H. Roeloffzen, L. Zhuang, D. A. I Marpaung, W. van Etten, R. G. Heideman, A. Leinse, A Borreman, M. Hoekman M. Wintels, \223Broadband Conformal Phased array with Optical Beamforming for Airborne Satellite Communication\224, Proc. of the IEEE Aerospace Conference, March 2008, Big Sky, Montana US 13  H. Schippers, J. Verpoorte, P. Jorna, A. Hulzinga, L Zhuang, A. Meijerink, C. G. H. Roeloffzen, D. A. I Marpaung, W. van Etten, R. G. Heideman, A. Leinse M. Wintels, \223Broadband Op tical Beam Forming for Airborne Phased Array An tenna\224, Proc. of the IEEE Aerospace Conference, March 2009, Big Sky, Montana US 


  15  B IOGRAPHIES  Harmen Schippers is senior scientist at the National Aerospace Laboratory NLR. He received his Ph. D. degree in applied mathematics from the University of Technology Delft in 1982. Since 1981 he has been employed at the National Aerospace laboratory NLR. He has research experience in computational methods for aero-eleastics, aeroacoustic and electromagnetic problems. His current research activities are development of technology for integration of smart antennas in aircraft structures, and development of computational tools for installed antenna analysis on aircraft and spacecraft  Jaco Verpoorte has more than 10 years research experience on antennas and propagation Electromagnetic compatibility \(EMC and radar and satellite navigation He is head of the EMC-laboratory of NLR. He is project manager on several projects concerning EMCanalysis and development of advanced airborne antennas    Adriaan Hulzinga received his BEng degree in electronics from the hogeschool Windesheim in Zwolle Since 1996 he has been employed at the National Aerospace laboratory \(NLR as a senior application engineer. He is involved in projects concerning antennas and Electromagnetic compatibility \(EMC  Pieter Jorna received the M.Sc degree in applied mathematics from the University of Twente in 1999 From 1999 to 2005 he was with the Laboratory of Electromagnetic Research at the University of Technology Delft. In 2005 he received the Ph.D. degree for his research on numerical computation of electromagnetic fields in strongly inhomogeneous media Since 2005 he is with the National Aerospace Laboratory NLR\ in the Netherlands as R&D engineer   Andrew Thain is a research engineer in the field of electromagnetic modelling of antennas. He specialises in the use of surface integral methods for the calculation of coupling and radiation patterns and works closely with Airbus on the topic of antenna positioning. He has experience in the field of electromagnetic modelling  Gilles Peres is head of the Electromagnetics group of EADS-IW He has a wide experience in computational EM modelling particularly the use of FDTD, integral and asymptotic techniques for antenna structure interactions. He has contributed with Airbus experts to the certification campaign of the A340/500 and A340/600. Dr Peres holds a PhD thesis from University of Toulouse \(1998\ on impulsive Electromagnetic Propagation effects through plasma   Hans van Gemeren has a BEng degree in electronics. From the beginning of Cyner substrates he is involved in development and production of prototyping and nonconventional Printed Circuit boards Working mainly for design and research centers Cyner got involved in many high tech projects and from this developed a great expertise in the use of different \(RF materials. In the FlySmart project Hans and his colleagues are able to do what they like most: In close cooperation with designers, creatively working on substrate solutions 


  16  


NIMBUS NOAA 8 NOAA 15 NPOESS Preparatory Project Orbital Maneuvering Vehicle Orbcomm Orbiting Carbon Observatory Orbiting Solar Observatory-8 Orbview 2 Orion 1 P78 Pas 4 Phoenix Pioneer P-30 Pioneer Venus Bus/Orbiter Small Probe and Large Probe Pioneer-I 0 Polar QuikSCAT Radarsat Reuven High Energy Solar Spectroscopic Imager REX-II Rosetta Instruments Sage III SAMPEX Satcom C3 Satcom C4 SBS 5 SCATHA Seastar SMART-1 SNOE Solar Dynamics Observatory Solar Maximum Mission Solar Mesosphere Explorer Solar Radiation and Climate Experiment Solar Terrestrial Relations Observatory Space Interferometry Mission Space Test Program Small Secondary Satellite 3 Spitzer Space Telescope SPOT 5A Stardust  Sample Return Capsule STEPO STEPI STEP3 STEP4 STRV ID Submillimeter Wave Astronomy Satellite Surfsat Surveyor Swift Gamma Ray Burst Exporer Synchronous Meterological Satellite-I TACSAT TACSAT 2 TDRS F7 Tellura Terra Terriers Tethered Satellite System Thermosphere Ionosphere Mesosphere Energetics and Dynamics TIMED TIROS-M TIROS-N TOMS-EP Total Ozone Mapping Spectrometer TOPEX TRACE Triana Tropical Rain Measuring Mission TSX-5 UFO I UFO 4 UFO 9 Ulysses Upper Atmosphere Research Satellite Vegetation Canopy Lidar VELA-IV Viking Viking Lander Viking Orbiter Voyager Wilkinson Microwave Anisotropy Probe WIND WIRE XMM X-Ray Timing Explorer XTE XSS-iO XSS-ii APPENDIX B FIELDS COLLECTED Mission Mission Scenario Mission Type Launch Year Launch Vehicle Bus Model Bus Config Bus Diameter Location Expected Life Flight Profile Flight Focus Technical Orbit Currency Total Cost Including Launch Unit Sat Costs Average Sat Cost Production Costs Launch Costs Operations Cost Orbit Weight Wet Weight Dry Weight Max Power EOL Power BOL Power  of Batts 17 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



1  Activity-based Correlation of Personal Documents and their Visualization Using Association Rule Mining Zafar Saeed Department of Computer Science Quaid-i-Azam University Islamabad, Pakistan zafarsaeed@cs.qau.edu.pk    Abida Sadaf Institute of Information Technology Quaid-i-Azam University Islamabad, Pakistan abida.sadaf@qau.edu.pk  Siraj Muhammad Department of Computer Science Shaheed Benazir Bhutto University Sheringal, Pakistan msiraj83@gmail.com   Abstract It is a common observation nowadays that the personal information of user is difficult to manage, the material which is copied by the users to their personal system are often forgotten by the users. So when they require their information it becomes very difficult to find the relevant information from huge repository. We have introduced a method using which the activities of user for reading documents are captured from running process list and managed in a dataset along with accessing time, then frequent item set and associated weights are calculated for each document with other using Apriori Algorithm and confidence measure in conjunction with combined access time. When user searches a document, the document list appears using any conventional model of retrieval, we have used primary metadata including title, author, type for document searching Beside this, a visual interface is designed to display the list correlated document on the basis of users activities may help them to indentify documents according to their past activities Keywords-Personal Information Management; Association Rule Mining; Correlation of documents I   I NTRODUCTION  The phrase “Personal Information Management” was used in 1980’s in order to manage the digital information on computer systems which tends to increase the information gaining speed as compare to human ability [11   P e r s o n al  information management describes the user’s activity in terms of creating, organizing, searching and managing their personal data [9  T h e  t r e n d of pe r s on a l i n f o r m at i on ma na g e m e n t  system is not new, in past people used to manage the information manually on papers. With the passage of time as information has increased, people has designed their own methods for storing and archiving information including vertical file cabinets, file tags, and sorted file archives. When the information exceeds rapidly its management and retrieval become a challenging task [11     Today’s world is progressive and very fast in development so every person has his own information needs which he wants to get in time effective manner to meet the progressive culture of this world. People want to learn and get the appropriate information efficiently to save their time. People normally collect the information, but when they get an opportunity, of reusing that information, it becomes very hard for them to select the exact information from huge repository 3   Tools and technologies help us in minimizing time which is needed for information management such as filing or e-mail management. With the help of these tools we may have more time to formulate creative and intelligent use of the information in order to get things done. Personal information management helps the people in different ways e.g. a patient with some disease such as cancer may needs to go through different medical treatment phases. So the doctor must have to maintain the historical treatment information of patient so that it will require less time to identify the ongoing treatment for that patient by maintaining his personal information  So far a minimal amount of work has been done for interdocument task based correlation as compared to the conventional methods of task management. Storage and organization of personal information do have importance but user is more interested in identifying and locating relevant documents whenever needed. When user searches documents in personal machines he should be provided correlated documents not only on the basis of informational contents but also on the basis of tasks he performed earlier. Pattern of accessing documents highlight the interest of user in specific time interval. If the frequent patterns are identified with time intervals, it may help users to locate the correlated documents according to their interest. In this paper we have captured the daily activities of user, which shows that how user access documents in order to perform his/her tasks. We have introduced a technique for finding correlation among documents using association rule mining  Association rule mining helps in identifying the common patterns within the item list, in our case item list consists of documents opened by the user. These frequent patterns within the document access log of user show the correlation among these documents. We have calculated association weights using confidence measure in conjunction with total access time of each document with others  This paper is organized as follows: Section 2 discusses the related work, section 3 describes association rule mining section 4 describes the experimental setup, section 5 describes the results and analysis, and section 6 discuses conclusion and future work 978-1-4577-0768-1/11/$26.00 ©2011 IEEE 


2  II  R ELATED W ORK  In 1983 Tom Malone c o nd uc t e d a s u r v e y s t udy a b o u t  paper management that how people usually manage their office documents and identified two main strategies i.e. neat and messy. Using neat strategy the user categorizes his information and place the document according to their category. In mess strategy the documents are placed in less structured way. William Jones et al c o nduc t e d a s u r v e y  which describes how people arrange their personal projects The author concluded that the people already crate planning documents, sometimes simple “to do list" and sometimes elaborate outline. On the basis of survey the authors design a tool called Universal Labeler and the project planner module control this work. Similar is done by Bergman et al [2  T h e  authors perform a survey on personal information management. The purpose of the survey is to test user's working habits empirically in order to overcome the fragmentation problem. On the basis of survey he suggested a method called single hierarchy solution in which all the related information about the project is stored in single folder regardless of format of the related files/documents. The authors designed a tool for single hierarchy, named Project Folders. In their system the entire project related items which include word documents, excel documents, html document, email document are stored together regardless of their formats but they were being separated by tabs at display   In 2006 Xinlong Bao et al [1 pr e s e n t e d a  r e p o r t  on t h e  tool FolderPredictor, which helped in reducing the cost of locating the file in hierarchical folders. FolderPredictor applies a cost sensitive prediction algorithm to the user's previous file access information to predict next folder that will be accessed Experimental results show that FolderPredictor reduces the cost of locating a file by 50% on average. In 2006 Edward Cutrell et al [5 de s c r i b e d t h e de s i g n a nd i m p l e m e n t a t i o n of  tool called Phalt that optimized the search in personal information and provided an interface that merges the searching and browsing activities. Also this tool supports a labeling scheme for organizing the personal content in the storage system  A survey was conducted by Tristan Blac-Brude et al [3   I n  this survey he concentrated on features which are used by the users to retrieve their documents. The main theme of the survey was to improve the tools that allow the user to improve the retrieving of related document. The authors suggested that the attributes that are most often and/or most precisely recalled, namely location, file type or document format, time of last usage, keywords, associated events and visual elements should be used in priority in the retrieval tools  In 2007 David Elsweiler et al [7 e x a m i n e d t h a t t y p e s  of  task are required to re-retrieve the information, and on the basis of these tasks the author proposed a task based evaluation methodology and examined the feasibility of the approach  Sara Cohen et al [4  ad d r essed t h e d e sk t o p sear ch p r o b l e m  and considered ranking of cos and sin distance tf.idf vector of the query and the content, path, name of the file respectively In this technique the query was a set of words and the documents are ranked when at least on query word appear in the file name, content and path of the documents. The authors used two other methods including SVM and Selectiveness of feature which shows better results than basic ranking methods  In 2008 Bruno Possas et al s u g g e s t e d a ne w w e i g h t i n g  scheme for correlating the index terms in vector space model In this weighting scheme, the author used association rule mining for calculating the weights of terms instead of inverse document frequency weighting scheme. He concluded that the new weighting scheme works efficiently which improves the quality of results  Despite the popularity of the search engines, the retrieval process is based on simple query-document matching and is made out of the user interests and preferences context. Daoud et al. [6 p r o p o sed an ap p r o a ch t o p e r s o n al i ze t h e u s er  sessi o n  information. They believe that user session information can provide very useful data regarding the topics in which user may be interested. They have claimed that their approach can distinguish between user's short term and long-term interests and that way personalization will be more effective. Their proposed session measures rely on the topical closeness between the query concept representation and the user context and personalization is achieved through re-ranking the search results of the relevant queries the user have entered and the context of the user  Shen et al e m p h a s i z e s on us i ng t h e pe r s on a l s e a r c h  history, because it is a very important type of personal information, from which we can learn about user's interests and information needs, thus improving the search service for the user and also improves the search accuracy. They have developed an intelligent client-side web search engine that can automatically extract the user's personal search history and store it on the local disk to utilize it for the purpose of personalization. In future work they have emphasized at using the other personal information stored on the user's pc, and also through some initial study, they found that a group of users such as peers in a research group often share some similar information needs, so in future if this data is to be utilized it can help in improving the retrieval accuracy of the search results  Sun et al. [15 p r o p o s ed  a p e r s o n a l i zat i o n t ech n i q u e b y  utilizing log files analysis. They provided personalization ranking of the search results, personalized ranking can be described as reordering documents by the similarity score between documents and user preference vectors. The evaluation has been done on a data set extracted from later access logs and compares it with other non-personalized ranking methods. The experiments show that their proposed method significantly improves the ranking accuracy on 978-1-4577-0768-1/11/$26.00 ©2011 IEEE 


3  redirecting user actions. The limitation to their research is that their personalized model has been tested on one particular website and the generalization of the model is not tested. So in future a generalized study will be very useful to see the difference with other websites TABLE I  T RANSACTION DATA HAS BEEN CONTAINING VARIOUS ITEMS  Transaction ID Items in Transaction  T1 I1, I2, I5 T2 I2, I5 T3 I2, I3 T4 I1, I2, I3 T5 I1, I3 T6 I2, I3 T7 I1, I3 T8 I1, I2, I3, I5 T9 I1, I2, I3  Related work shows that in previous research, researchers have used different mechanisms and data to provide personalization of user information [16   P r ev i o u s r e se ar ch  does not incorporate time as a factor or basis to provide personal information management. We propose that time can be a factor in identifying related documents that user may be accessing on the basis of their relevancy and user activity. For example if user has accessed two files at the same time and has not closed any one of them that means they were related but if the user has closed down one of them that means they were not that relevant. We have used association rule mining technique to uncover the related patterns about the documents which user have accessed at the same time III  A SSOCATION R ULE M INING  Data mining is very useful in uncovering hidden patterns from data. Different data mining techniques have been used in the past to uncover such useful information which can be used for future predictions also. Association Rule Mining \(ARM\ is one such technique [8    Data mining techniques are really helpful when there is huge amount of data involved. Association rule mining has been used in different fields, e.g. to improve the decision making process of business related data, to enhance organization productivity in telecommunication networks \(by finding customers and associated services enhancing those services\. This data mining technique has also been applied to software engineering data to discover various patterns. ARM approach is data driven, and association rules may be found when the data is either transactional or relational. ARM was traditionally used to discover interesting association relationships among business transactions that consequently help in business decision-making process. Market Basket Analysis is an example of association rule mining [8        Association rule mining finds the relationships among items which are to be used together. As an example consider transactional database which contain different items as shown in Table 1. In our research we have used metadata related to how user performs his/her tasks? So, association rule mining may be helpful in uncovering useful rules and associations among the documents which are related to or relevant to the task which user is going to perform  ARM is briefly explained below for understanding how we used it to find associations among items. Let       be a set of items. The attribute values form an item set Considering D to be a database and T to be transactions such that T  D, where each transaction T is a set of items such that T I, an association rule is an expression of the form: A B where A and B are sets of items that belong to I. To further illustrate the concept of association rule mining, consider the example of a Telecom Company. Consider customers who use services \(set of items\ called a “transaction". The transactions made by customers are shown in Table 2. The manager is interested to know which set of services are used together to better manage the services and customers. Considering transactions mentioned in Table 2, association rule mining leads to the rule: sms-service call-service which describes that customers who use sms-service also use call-service There may be other rules but all may not be of interest to the users. For example, the rule sms-service GPRS-service is also formed but association between sms-service and GPRSservice is not as interesting as between sms-service and callservice. The rules that do not meet a minimum threshold are considered to be uninteresting [8    TABLE II  E XAMPLE TO I LLUSTRATE A SSOCIATION R ULE M INING  Transactions Items T1 sms-service, call-service T2 sms-service T3 GPRS-service, call-service, sms-service T4 Other, GPRS-service, call-service, sms-service  Two basic measures for association rules are “support" and Confidence", which reflect the usefulness and certainty of the rules discovered respectively [8   T h es e t w o mea s u r es a r e  defined as                        a                           b    In Table 2, the rule sms-service call- service has support of 75 and confidence of  75 and the rule callservice GPRS-service has support of 50 and confidence of 66 7 The calculated values show that the rule sms-service call-service is stronger \(i.e. more interesting\ as compared to call-service GPRS-service 978-1-4577-0768-1/11/$26.00 ©2011 IEEE 


4   Association rule mining may uncover thousands of rules that are uninteresting to the user, so constraint based association mining may be performed to restrict the rules. The constraints may be knowledge type constraints, data constraints, and dimension constraints, interestingness constraints \(i.e. to specify thresholds on support and confidence measures\ or rule constraints [8    Rule constraints specify the form of rules to be mined and are expressed as metarules. For example, we may want to associate customers' different characteristics with the use of sms-service. The metarule is like: P\(X, Y uses\(X sms service"\, where X is a variable representing a customer andY is the value of the attribute assigned to predicate P. The data mining system can then search for rules that match the given metarule. For instance, rule location \(X, “Islamabad uses X, “sms-service"\ matches with the above metarule, so metarule may help to form a hypothesis regarding the relationships that may be of interest to users  In Interestingness constraints, user specifies a threshold value on interestingness measures like support and confidence For example, user may be interested to find rules whose confidence value is greater than 50%. Data mining system searches for rules which meet these conditions  The documents which are accessed by user at a particular time for performing specific task may be heterogeneous in nature, semantically those documents may not be directly related to each other, but user may need to recall the same documents whenever he/she reviews his/her past activities. In this case task based correlation may helps to identify the appropriate documents even if they are semantically heterogeneous. For example when a student from bioinformatics reads a scientific document about gene sequence and transcription factors, he/she may need to go through certain string matching algorithm. For this purpose user needs to read documents related to pattern matching algorithm which may not be directly related to the ongoing task of that user. In future user may need to review same documents again to recall his/her knowledge, so activity oriented association among personal documents may help users to identify their documents on the basis of their previous activities IV  E XPERIMENTAL S ETUP   Our work is finding correlation among the documents using association rule mining technique TABLE III  F ILTERED DATASET AGAINST D1  D2 TID UID Doc-List S-Time E-Time Date  T100 1 D9, D18, D1 D2 11:12AM 11:23AM 11.02.2005 T200 1 D9, D18 D97, D1 11:23AM 11:35AM 11.02.2005 TID UID Doc-List S-Time E-Time Date T300 1 D18, D97 D1, D2 11:35AM 11:36AM 11.02.2005 T400 1 D18, D97 D1, D2, D5 11:36AM 12:45AM 11.02.2005            Following steps are performed by our functional prototype to find associations among documents. Our assumption is when user performs reading/writing activities on their personal computer they open some related documents which they require in order to perform a certain task. A task can be of reading assignment, writing reports or any research activity So there are relationships among the items \(documents\which they usually open at same time. Initially we are focusing only on the documents of type .doc, .pdf, .ppt, .xls,. rft for finding the correlation on the basis of their  occurrence with each other. To achieve this goal we adopted following steps  Step 1: A volunteer student of post graduate was taken for the study. We developed an application which grabs the information from the process list of user and installed it on participant's computer system. Whenever user would open the documents, the processes manager of windows will maintain its metadata at system level. Our prototype captures this information and creates transactions whenever a document is opened or an old document is closed along with time. The time is used later on for calculating the weight which is a measure used to finding associative ranking among documents and for creating visualization. Our application grabs information against certain document types such as doc, ppt xls, rtf, txt, and pdf  Step 2: The log dataset contains five attributes that are transaction ID, and list of documents that are accessed at the same time, starting time of transaction, ending time of transaction and date. Sample of dataset is shown in Table 3 Because the process, that are running on user's machine change periodically as user activity/task changes, so we get a rich dataset which is further processed in next step  Step 3: Dataset is pre-processed and transactions with one item or document are removed, and then frequent 2-itemsets are found by using Apriori algorithm with threshold of support count 2 as demonstrated in the following example   F D, where F contains all frequent 2-itemsets and D is dataset  F  F,and F   D18,D97  F   D2,D18  F    D1 D2   and so on   D is a single document which belongs to F For finding association weights for document all 2-itemsets are taken in such a way that one item in each should be the document whose association weight is to be calculated. E.g taking 2-itemsets as S, where S F, and each set S  S  contains  S   D1,D2    D1,D18    D1,D97  Then 978-1-4577-0768-1/11/$26.00 ©2011 IEEE 


5  against each 2-itemsets in S the dataset is filtered for calculating the association weights for S as shown in Table 3. Then for calculating the association weight for S  total access time is used in conjunction with confidence where is access time of each 2-itemsets in S            1  is calculated using formula          2  is association weight calculated by multiplying confidence with total access time      3600     60       3  The weight vector W that contains weights of all other documents in S for  is normalized b using normalization technique as follows         100 1   1                                      4  Using the weight vector the documents are ranked and visualization is created  When the user query is applied, the documents are retrieved using its vector space model or metadata including userID, title, type, size, access date  Each document can further be visualized for finding its correlated documents. Frequently accessed documents with Di are listed and ranked according to the calculated weighs  Visualization is created for presenting correlated documents. The document, that is searched and selected, is placed in the center and correlated documents are aligned around it as a spider view. The correlated documents with high associating weight are aligned closer and vice versa as shown in Figure 1. This visual presentation of documents helps user to identify not only the correlated documents but also to identify which one of the documents is more associated on the basis of past activities  For plotting the graph against  following formulas are used         5         6         7  Equation 5 is used to align the correlated documents at equal distance across 360 degree, whereas equation 6 and 7 is used to define the strength of correlation on visual presentation V  R ESULTS A ND A NALAYSIS  Our experiments show that there were total of three hundred and fifty one documents a ccessed by user during the period of 131 days. We found total 2811 2-itemsets with support count = 2. Table 4 shows some generalized results of association rule mining. On average user can find 11 related documents to a particular task TABLE IV  R ESULTS OF A SSOCIATION R ULE M INING A T T HE D EVELOPER E ND  Total 2 item sets with support count 2 2811 Documents with highest support count 267 Average support count of each document 11.14  Figure 1 show an interface of the prototype systems that has been developed containing the spider view of the related documents to the document which is in the center Visualization helps user in instantly identifying the documents which are more related with his/her work In reading activity of user, average number of association links for each document was approximately 11 on the basis of their co-occurrence. When a document is searched by user its correlated documents according to the past activities of user are presented in a way which helps user in finding the correlated documents without cognitive overload of memorizing the document he needs to review along with searched documents   F IGURE 1 V ISUAL P RESENTATION O F C ORRELATED D COUMENTS A GAINST  Our weighting scheme helps user in deciding and identifying the related documents which may be relevant to his/her tasks. This also reduces access time and will eventually help in reducing the overall task completion time of user. It also helps minimizing the extra load of user when user is working on the same task on which he has worked before and just needs the related documents within available time and 978-1-4577-0768-1/11/$26.00 ©2011 IEEE 


6  wants to access related files without wasting time on searching One of an advantage of our proposed visualization is that user does not need to open the document every time because he can see the meta data associated with the document on just one click. Visualization of the results is easy to understand as it is always easy to perceive things when they are presented visually rather than textually. Our prototype/interface save user from hideous task of identifying documents by him on the basis of support count. However to check the usability of the interface we can experiment it in future with a sample of users with different levels of experience. This analysis however does not show that documents are relevant on the basis of their contents. But, on the other hand it provides an overall view to the user activities based on the historical data of documents usage. We believe that with the content based personalization task based personalization is also very important, and more research should be done in this regard VI  C ONCLUSION A ND F UTURE W ORK  Personal information management is related to user's activity for creation, organization, searching and management of their personal data. Since the storage capacity is no more an issue in today's world that is why users store huge data in their personal computers. As the time passes recollection of the personal data becomes difficult for users especially when they try to locate documents on the basis of their past activities. We have performed an experiment on personal data access log of a user comprises 131 days of his activities  We used association rules mining technique with a custom weighted scheme to highlight the correlation among documents on the basis of user activity. Our results show that by average each document has approximately 11 correlated documents which are limited in number and user can easily identify the task based related documents whenever he/she goes for searching particular document. The results show that specific pattern of each document is accessible only with some specific documents, so in future when any document is to be searched by user; he/she may be able to retrieve correlated documents with some effective representation which would be helpful and save user's time in order to identify the required documents. For evaluation the prototype was then given to the same user whose access log of last 131 days was captured, and asked him to perform certain document search. Feedback from the participant was quite in the favor of prototype that the list of related documents do not directly related on the basis of their contents but he wanted to have these documents when performing the same tasks for which he has been studying earlier  As a future work this experiment can be extended by joining the content based correlation with activity based association in order to produce better results which may help to retrieve personal documents of user according to his/her own context and activities  A CKNOWLEDGMENTS  We are very grateful to Dr. Onaiza Maqbool for her valuable suggestions and guidance throughout our research work. We are heartily thankful to Capt. Adil Javaid for participating in our research as volunteer. Capt. Adil has worked on the dataset used in this research work for experiment R EFERENCES  1  X. Bao, J. Herlocker, and T. Dietterich. Fewer clicks and  less frustration: reducing the cost of reaching the right folder In Proc. of 11th International Conference on Intelligent user Interfaces pages 178 185. ACM, 2006 2  O. Bergman, R. Beyth-Marom, and R. Nachmias The project fragmentation problem in personal information management. In Proc SIGCHI pages 271 - 274. ACM, 2006 3  T. Blanc-Brude and D. Scapin. What do people recall about their documents?: implications for desktop search tools. In Proc. of 12th International Conference on Intelligent user Interfaces pages 102 111. ACM, 2007 4  S. Cohen, C. Domshlak, and N. Zwerdling. On ranking techniques for desktop search ACM Transactions on Information Systems \(TOIS  26\(2\:1- 24, 2008 5  E. Cutrell, D. Robbins, S. Dumais, and R. Sarin. Fast fexiblefiltering with Phlat-Personal search andorganization made easy. In Proc. SIGCHI  volume 1, pages 261- 270. Citeseer, 2006 6  M. Daoud, L. Tamine-Lechani, and M. Boughanem Learning user interests for a session-based personalized search. In Proceedings of the second international symposium on Information interaction in context pages 57- 64. ACM, 2008 7  D. Elsweiler and I. Ruthven. Towards task-based personal information management evaluations. In Proc. of SIGIR pages 23- 30. ACM, 2007 8  J. Han and M. Kamber. Data mining: concepts and techniques. Morgan Kaufmann, 2006 9  S. Henderson. Personal document management strategies. In Proc. of 10th International Conference NZ Chapter of the ACM's Special Interest Group on Human-Computer Interaction pages 69-76. ACM 2009 10  W. Jones, H. Bruce, A. Foxley, and C. Munat Planning personal projects and organizing personal information. In Proc. of American Society for Information Science and Technology 43\(1\:1 - 24 2006 11  W. Jones and J. Teevan. Personal information management. Univ. of Washington Pr, 2007 12  T. Malone. How do people organize their desks Implications for the design of office information systems ACM Transactions on Information Systems TOIS 1\(1\:112, 1983 978-1-4577-0768-1/11/$26.00 ©2011 IEEE 


7  13  B. Possas, N. Ziviani, W. Meira Jr, and B. RibeiroNeto. Set-based vector model: An e_cient approach for correlation-based ranking ACM Transactions on Information Systems \(TOIS 23\(4\:397 - 429, 2005 14  X. Shen, B. Tan, and C. Zhai. Exploiting Personal Search History to Improve Search Accuracy Personal Information Management: Now That We Are Talking, What Are We Learning page 94, 2006 15  Y. Sun, H. Li, I. Councill, J. Huang, W. Lee, and C Giles. Personalized ranking for digital libraries based on log analysis. In Proc. of the 10th ACM workshop on Web information and data management pages 133- 140. ACM, 2008 16  C. Chen, F. S.C. Tseng, and T. Liang. An Integration of WordNet and fuzzy association rule mining for multi-label document clustering  Data and Knowledge Engineering. 69\(11\: 1208-1226, 2010 978-1-4577-0768-1/11/$26.00 ©2011 IEEE 


suggested that the simulating tests and the actual tests should be in the same position of the whole network topology to receive better detection results. When doing simulating tests we collect packets in a specific position of network topology for three hours and make sure if there are DoS/DDoS attacks before simulating set of fuzzy association rules for comparison. The concrete steps are as follows: gathering packet traffic statistics once per unit time\(2 seconds calculating twelve required signature values and forming the first record of 5400 in total, written as 5399i0 ??ir \( i is the serial number of record we try to average the total sum of records with the same remainder when 3 is divided by the serial number and the three averaged records will better display the state of network traffic in a certain period. Last, the three records is used to figure out a set of fuzzy association rules for matching. Particularly,network traffic condition differs greatly in different period. In order to get better detection results and reduce false positive rate, fuzzy association rules for individual matching is required in the experiments aiming at different periods, such as morning, noon afternoon, evening and night In practical tests, a record is also formed by twelve signature values of packet traffic statistics gathered once per unit time \(2 seconds worked out by three accumulated records, we compute the similar degree between it and the rules produced in experimental periods. If the similar degree is lower than threshold, it is decided that there are attacks. Once attacks occur, this system cannot automatically update the firewall to block connection unless source of such attacks have been traced Network attacks vary a lot. A complete intrusion detection system is usually constituted by a number of detection modules, each of which is responsible for detecting Volume 7] 2010 2nd International Conference on Computer Engineering and Technology V7-669 Figure 3   Low, Medium, and High in Membership Function certain type of attacks. On the other hand, given to considerations of instantaneity, more than one detection module will be more convenient for parallel processing. Any intelligent judgment depends upon the selection of signature but different signatures are required to effectively detect 


different types of attacks. This system mainly aims at DoS/DDoS. Based on Information Gain values, the selected 12 signatures are arrayed in descending order as follows 0. number of different payload length 1. number of different source IP address 2. number of different destination IP address 3. number of different TCP source port 4. number of different TCP destination port 5. number of different UDP source port 6. number of different UDP destination port 7. number of TCP protocol 8. number of UDP protocol 9. number of ICMP protocol 10. number of SYN flags 11. number of ACK flags Each signature has three Fuzzy Sets: Low, Medium and High. Membership Function in use is taken from Default Function of MATLAB Fuzzy Tool Box \(as follows which a, b, and c can be adjusted into constants. Fig. 3 is the instance of Membership Function. Constants of a and c in Low are 0.3 and 30; constants of a, b and c in Medium 15, 2 50; constants of a and c in High -0.3 and 80 Low f \( x 1 + exp\( a \( x - c Medium f \( x 1 + | \( x - c High f \( x 1 + exp\( -a \( x - c In experiments, we adjust the coefficient so that the signature attains more significance by making Information Gain value higher and Overlay Memory wider. However since not all signature statistics applies to the same Fuzzy Membership Function, many testing experiments are required to fine-tune each Membership Function to appropriate values and grade of individual Membership Function must be calculated in each signature. There are 12 signatures in one record and each signature have to calculate its grades in three different Membership Function. In other words, every record has 36 items, such as f0.low, f0.medium f0.high, , f11.low,f11.medium, f11.high,so it may mine numerous rules in 3 records V. THE ANALYSIS OF EXPERIMENTAL RESULTS The setup of system parameters differs as its operating environment changes, because we need to take into account in experiments which period is more accurate. Namely, the 


morning detection rules is best used for network intrusion detection merely in the morning as sometimes great changes takes place in network traffic condition in different periods of a day. This experiment is based on two buildings of students dormitory and performed in the night. Of the 150 collected DoS attacking software, 100 is used in experiments to search the above-mentioned 12 signatures \(higher Information Gain In order to test the detection results of this system, we have selected three types of attacking \(i.e. SYN Flood Ping of Death and Smurf set 2seconds as an unit time and perform mining \(a judgment horizontal axis of Fig.5 and Fig. 4 represents 6 seconds During the experiment, Fuzzy Association Rules is produced by a long-period accumulating of packets, averaging three records and incorporating them into algorithms of fuzzy association rules. Through long-time collecting and averaging, normal conditions can be better reflected, but it have to take us more time to identify whether these packets contain DoS attacks The bar graph value in Fig. 4indicates the similar degree between fuzzy association rules and detection rules of realtime packet information. If the similar degree is lower than 0.1\(10 a experimental results when the school uses DoS NIC\(Promiscuo us Mode Sniffering packet capture feature t ti ti Cumulativ3 ClearHistory yes no yes Calculate the value of grades Mining Fuzzy Association Rules Threshold No Abnormal 


network behavior Yes Normal network behavior No alarm Yes alter the filtering rules of the firewall Figure 2. System Flow Chart Calculation of similarity Identify the source of attack is IP V7-670 2010 2nd International Conference on Computer Engineering and Technology [Volume 7 a b school c dormitory d school Figure 4. \(a e Figure 5.  Mass Transmission      Figure 6. The Computed Value of of Normal FTP and Similar          Similar Degree in Different Dos Degree Measured in Different Places        Attacks111111111111111 Smurf\(IGMPNUKE V1_0 points, we perform normal network behavior, but at the later stage of the third time point, we start attacking procedures and keep attacking, from which it is found that the rules detected during following time points carry low similar degree with fuzzy association rules. The detection results in b c TosserV2.1 b continuously at time points of 6, 7, 8 and 9 and it is obvious that they are different from normal network behavior. During the first d SYN Flooderv3.0 when they are attacked by SYN Flood From \(d points of 1, 4, 6, 7, 10, 11 and 12 while continuous attacks are found at time points of 3 and 4 from \(e Since DoS features massive packets in a moment, we use multiple computers at the same time to download through FTP large amounts of data to verify if our system will make false positives. In Fig. 5, although it indicates clear decline after the second time intervals, there is still some way from 10%, the threshold. Finally, we execute the 50 attacking procedures thoroughly and their similar degrees are shown in 


Fig. 6. In Fig. 6, each value is the average of ten times, once each day, ten days in total. With every similar degree lower than 10%, it suggests that the twelve signatures selected by sorting Information Gain values and the selecting mode of coefficients in Membership Function can immediately detect Dos/DDoS attacks in the design of our real-time network intrusion detection system Last, we emphasize that measurement of similar degree is greatly affected by network traffic. If network packet information changes frequently, then the measured value will fluctuate in a larger section. Besides, the similar degree is also influenced by density or duration of the attacking VI. THE CONCLUSION AND FUTURE RESEARCH This paper mainly contributes to the design of a real-time network intrusion detection system based on Fuzzy Association Rules. Though we take only three units of time to detect information traffic, there are 36 actual items in each record and three records can detect out many rules since 12 signatures are adopted in each record and each signature value can be incorporated into three fuzzy Membership Functions. By comparing similar degree with experimental rules, if they are lower than 0.1\(10 them as attacking events. According to experimental results it is found that our system can make correct judgment and wont cause false positives towards massive FTP packets in a moment after appropriate adjustment of system parameters In the following few days, our work should focus on improving the efficiency of detecting procedures, including cutting unit time from the present two seconds to one second; redefining the calculating mode of similar degree adjusting the coefficients of fuzzy function by Genetic Algorithm; attempting to detect based on Incremental transaction database instead of three transaction records. In the detection of incremental transaction database, we expect only one more accurate detection is performed in each unit time because both the present and the past information of the record will be detected REFERENCES 1] [1] German Florez , Susan M.Bridges , and Rayford B. Vaughn,?An Improved Algorithm for Fuzzy Data Mining for Intrusion Detection,?Proceedings of the Fuzzy Information Processing Society June 2002, pp. 457-462 


2] [2] Susan M. Bridges and Rayford B. Vaughn, ?Intrusion Detection Via Fuzzy Data Mining?,  Proceedings of the twelfth Annual Canadian Information Technology Security Symposium, June 19-23 2000 3] [3] Dickerson, J.E. and Dickerson J.A.,?Fuzzy network profiling for intrusion detection,?  Fuzzy Information Processing Society, 2000 pp. 301-306 4] [4] Chang-Tien Lu, Arnold P. Boedihardjo and Prajwal Manalwar Exploiting efficient data mining techniques to enhance intrusion detection systems,? Proceedings of the IEEE International Conference on Information Reuse and Integration, 2005, pp. 512- 517 5] [5]Rakesh Agrawal, Tomasz Imielinski, Arum Swami. Mining association rules between sets of items in large databases: proc. of the Volume 7] 2010 2nd International Conference on Computer Engineering and Technology V7-671 ACM SIGMOD Conference onManagement of Data[C Washington,D. C. , 1993 6] [ 6 ] Aly El2Semary, Janica Edmonds, Jesus Gonzalez2Pino, et al App lying data mining of fuzzy association rules to network intrusion detection:p roceedings of the 2006 IEEE Workshop on Information Assurance.[C ]. United StatesMilitary Academy,West Point,NY 2006 V7-672 2010 2nd International Conference on Computer Engineering and Technology [Volume 7 


3 4  9 9  Suppose 3=s , according to formula \(5 of CID006, BP006  is{ }9,3,10 , as shown in table 4,  which indicates  that  e-shopper  CID006 belonged to the tenth cluster in May and moved into the third cluster in June thereafter reaching the ninth cluster in July According to formula \(6 from e-shoppers path with regard to a minimum support of 0.1 and a minimum confidence of 0.5. The association rules are as shown in table 5. The similarities  between the path of e-shopper CID016  and the derived rules are 22016 =SD and 11016 =SD . Therefore, e-shopper CID016 belongs to the ninth cluster at timeT , since the fitness between CID016 and the rules are =FD2016 0.2 and =FD 1 016 0.2001. Therefore, we predict that the products which e-shopper CID016 is likely to buy are Bread, and Biscuit  TABLE V. THE DERIVED ASSOCIATE RULES Rule 1+? sT  1?T  T  Support Confidence 1 2 3  15 16 10 10 3   10 3 1 10  


 3 9 3 4  9 9 0.3 0.1 0.1 0.2 0.1 0.1 1.0 1.0 1.0 0.5 1.0 1.0 V. CONCLUSION The preferences of e-shopper change over time. In this study, we describe a new approach for mining the changes of e-shopper  purchase behavior over time and discuss solutions to several problems. For predicting e-shoppers purchase behavior, the following concepts are proposed: BP j SDij and FDij . The SOM technique is used to detect the evolving e-shopper purchase sequences as time passes. The purchase sequences are derived from the changes in the cluster number of e-shopper. The sequential purchase patterns over user-specified minimum support and confidence are extracted by using the association rule. Then the sequential purchase patterns are stored in the rule database Finally, we give the example to elaborate the new methodology. The research presented in this paper makes a 155 contribution to mining  e-shoppers purchase behavior basing on transaction data. E-retailer may be able to perform effective  one-to-one marketing campaigns by providing individual target e-shoppers with personalized Product basing on using purchase sequences In the future, some possible extensions to this work are as 


follows. From the results of this study, we know which products target e-shoppers are likely to buy, but we have not yet explored the times at which these purchases are likely to occur. Further research analyzing e-shoppers past purchasing patterns should likewise enable prediction of the most appropriate times. Furthermore, one interesting research extension would be the setting up of a real marketing campaign, in which e-shoppers would be targeted using this methodology, which could then be evaluated with regard to its performance REFERENCES 1]Dhond, Gupta, A., Vadhavkar, S. Data mining techniques for optimizing inventories for electronic commerce[C]. In the Proceeding of the ACM-SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005:480-486 2] Kuo, R. J., Chen, J. H., Hwang, Y. C. An intelligent stock trading decision support system through integration of genetic algorithm based fuzzy neural network and artificial neural network[J]. Fuzzy Sets and Systems, 2001 118\(1 3] Agrawal, D., Schorling, C. Market share forecasting: An empirical comparison of artificial neural networks and multinomial logist model Journal of Retailing[J]. 1997, 72\(4 4] Weigen, A. S., Rumelhart, D. E.Generalization by weight-elimination with application to forecasting. Advances in Neural Information Processing Systems[J]. 1999, 3:875882 5] Chen, M, S, Han, J. Data mining: an overview from a database perspective[J]. IEEE Transactions on Knowledge and Data Engineering, 2006 8\(6 6] Schafer, J. B., Konstan. E-commerce recommendation application[J Journal of Data Mining and Knowledge Discovery, 2001, 16:125153 7] Giudici, P, Passerone, G. Data mining of association structures to model e-shopper behavior. Computational Statistics and Data Analysis[J]. 2002 38:533541 8]Changchien, S. Mining association rules procedures to support on-line recommendation by e-shoppers and products fragmentation[J]. Expert Systems with Applications, 2001, 20\(4 9] Song, H, Kim, J. Mining the change of e-shopper behavior in an Internet shopping mall[J]. Expert System with Applications, 2001, 21\(3 10] Anand, S, Patrick, A. A data mining methodology for cross-sales[J Knowledge-Based Systems, 2006, 10:449-461 11] G. Adomavicius, A. Tuzbilin. Using data mining methods to build e-shopper profiles[J]. IEEE Computer, 2006, 34 \(2 


12] Dhond, Gupta, A., Vadhavkar, S. Data mining techniques for optimizing inventories for electronic commerce[C]. In the Proceeding of the ACM-SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005:480-486 13]Chui-Yu Chiu , Yi-Feng Chen. An intelligent market segmentation system using k-means and particle swarm optimization[J]. Expert Systems with Applications, 2009, 36: 45584565 14]Tzung-Shi Chen , Shih-Chun Hsu. Mining frequent tree-like patterns in large datasets[J]. Data & Knowledge Engineering, 2007,62:6583 15]H. Tsukimoto, Extracting rules from trained neural networks[J]. IEEE Trans.Neural Networks, 2000, 11 \(2 156 


http://datamining.buaa.edu.cn/TopKCos.pdf 14] M. Zaki, Scalable algorithms for association mining, TKDE, vol. 12, pp. 372390, 2000 


enhance item-based collaborative filtering, in 2nd IASTED International Conference on Information and Knowledge Sharing, Scottsdale, Arizona, 2003 476 2010 10th International Conference on Intelligent Systems Design and Applications 


Basi Association Rles Basi c  Association R u les Association is basically connecting or tying up occurrences of Association is basically connecting or tying up occurrences of events Ol dib t f ilt t O n l y d escr ib e se t s o f s i mu lt aneous even t s Cannot describe patterns that iterate over time e g  itemset a  0  b  0  g    Eg If you sense higher data rates on the downlink than normal AND New Route generated Implies high chances of Intrusion AND New Route generated Implies high chances of Intrusion Associative IDS for NextGen Frameworks Dr S Dua LA Tech 20 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



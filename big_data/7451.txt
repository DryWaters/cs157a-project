EQUATION OF STATE OF WARM DENSE MATTER A T DARHT 2 FACILITY    T homas J. T. Kwan, M ark 
J. Schmitt, W illiam S Daughton C arl A Ekda hl, John F. Benage, Michael S Murillo F rederick J Wysocki  Applied Physics Division, Los Alamos National Laboratory 
 Los Al amos, NM 87544   Accurate equation of state theory on warm dense matter is a big challenge to model and good experimental data is 
difficult to obtain.  One of the difficulties is the creation of a warm dense matter WDM suitable for experiments to examine its equation of state.  We have examine methods of creating a warm dense matter using three different kinds of energetic particle beams such as short pulse laser energetic 
proton beam and relativistic electron beam  We found that the use of relativistic electrons such as the second axis of the Dual Axis Radiographic Hydro Test \(DARHT\ facility at Los Alamos National Laboratory can create WDM ideally 
suitable for experiments to obtain data on the equation of state of such WDM over an extended parameter sp ace The electron beam has an energy of 18 MeV and a current of 2 kA.  Its pulse length can be varied from 20 ns to 200 ns.  We will present results from our calculations on the creation and 
characterization of WDM using the DARHT electron beam We will also present our planned experiments specifically for the measurements of equations of state of such a WDM   ________________________________  
  Work supported by US DOE/NNSA, performed at LANL operated by LANS LLC under Contract DE AC52 06NA25396   U.S. Government work not protected by U.S. Copyright 


   2 the scientific point of view, the exploration of the millimetre part of the electromagnetic spectrum allows for acquiring valuable data from the lunar surface in terms of  brightness temperature and surface emissivity maps. All the data gathered will be helpful in order to determine the dielectric properties of the surface ma terials and will allow the characterization of the thermal properties of the lunar soil The pursued approach based on the use of millimeter waves is at present feasible because of the advances obtained in the last years by the millim Actually, these wavelengths are employed by radars in a wide range of military, commercial and, recently, scientific applications, such as remote sensing, surveillance telecommunication. Millimeter wave sensors offer higher performance with respect to microwave and infrared-based sensors in several applicati ons. However, this technology has not yet been fully explo ited in the space environment the main drawback of  millimeter waves, i.e. major affection of the atmospheric attenuation, disappears in space where small size and flexibility of the systems become fundamental In this paper preliminary results of the currently ongoing study carried out by Rheinmetall Italy for a millimeter wave radar are reported, especially focused on the millimeter wave radar and its functionalities. The study has been carried out with the collaboration of INAF Moon science team 2  T HE MAGIA  M ISSION  MAGIA is a lunar mission proposed to the Italian Space Agency \(ASI\ a scientific and industrial team led by Rheinmetall Italy \(RHI\ASI funded this phase A study in the frame of a special call devoted to "small missions within the National Aerosp ace Plan. The term "small missions" identifies low-cost and faster space missions capable anyhow of guaranteeing a valuable technology and science return. The study is strongly supported by INAF Italian National Institute of Astrophysics\The program foresees design and development of a Moon orbiter to be inserted into a low orbit \(about 100 km\o carry out remote sensing over two years through the complementary observations of different payloads embarked on a common platform. The latter one is a high performing small bus 200 kg\currently developed by RHI under ASI contract Main objective is to acquire global and local data of the Moon during a first mission phase in order to pursue the following science goals  Detailed study of the internal structure of the Moon through its gravity and figure  Study of the polar and sub-polar regions in terms of their morphology and mineralogy  Study of the lunar exosphere and radioactive environment Moreover, the satellite will provide also a contribution to the fundamental physics, through an improved measurement of the gravitational red-shift from a circumlunar platform and the determination of the position of the seleno-center during a second mission phase characterized by the release of a sub-satellite 95 GHz RAR Block Diagram DDS Chirp Generator Processing and Storage Carrier Generator Altimeter Radiometer LNA SSPA 95 GHz 95 GHz RAR Block Diagram DDS Chirp Generator DDS Chirp Generator Processing and Storage Carrier Generator Altimeter Altimeter Radiometer Radiometer LNA SSPA 95 GHz  Figure 1 \226 Block diagram of  the RAR instrument  With respect to this, so far the lunar orbit chosen is frozen type. Such classes of orbit have the peculiarity to maintain 223constant\224 some orbital parameters. In particular considering satellites orbiting the Moon, eccentricity is the orbit parameter which has to be maintained as constant as possible because the gravitational field anomalies impose an increase of eccentricity of circular orbits and a consequent reduction of peri-selenium height and increase of aposelenium since the semi-major axis \(excluding some oscillation\ is almost constant SB2 Nadir SB1 Moon surface Antenna Beam Configuration MAGIA SB2 Nadir SB1 Moon surface Antenna Beam Configuration MAGIA  Figure 2 \226 Antenna beam configuration for the RAR instrument  


   3 SB1 Nadir SB2 SSPA Noise Source Hot Load LNA Processor 95 GHz Clock DDS SB1 Tx SB2 Tx Nadir Tx 86 GHz 86 GHz 8 GHz 8 GHz Upconverter Frequency Generator Downconverter 1 GHz Tx Switch Matrix 95 GHz Nadir Rx SB2 Rx SB1 Rx Rx Switch Matrix Rad Switch Matrix 1 GHz Mass Memory Communication Payload controller SB3 Sky Beam SB1 Nadir SB2 SSPA SSPA Noise Source Hot Load LNA LNA Processor Processor 95 GHz Clock DDS SB1 Tx SB2 Tx Nadir Tx 86 GHz 86 GHz 8 GHz 8 GHz Upconverter Upconverter Frequency Generator Frequency Generator Downconverter Downconverter 1 GHz Tx Switch Matrix 95 GHz Nadir Rx SB2 Rx SB1 Rx Rx Switch Matrix Rx Switch Matrix Rx Switch Matrix Rad Switch Matrix Rad Switch Matrix Rad Switch Matrix Rad Switch Matrix 1 GHz Mass Memory Mass Memory Communication Payload controller SB3 Sky Beam  Figure 3 \226 RAR front end deta iled general block diagram  Theoretically, a frozen orbit is the best condition for Moon remote sensing but we can not affirm this for the gravity field recovery. Anyhow, considering more refined gravity field representation, the chosen orbit is not frozen so allowing a good trade-off between remote sensing and gravity field measurements The mission MAGIA will allow to study and to go more in depth on all the above mentioned aspects of the lunar science, by means of a \223clev er\224 payload. Actually, the following combination of instruments are envisaged  the CAM-SIR instrument, a high spatial resolution imaging camera operating in the visible, providing high spatial resolution images and aimed at characterizing and mapping the mineral composition of the lunar surface to gain information about the Moon's geologic evolution  CARISMA, a high spatial resolution imaging camera operating in the visible, to provide high spatial resolution images including a panchromatic and broad-band filters  Alena, a particle detector devoted to evaluate the interaction between the Moon and its environment  A spectrometer for particles to be used to characterize the environmen t and identify energetic particles  RAR, a compact millimeter wave radar operating at 95 GHz to provide altimetry, scatterometry and radiometry of the surface  The next section is devoted to describe the RAR instrument  3  T HE M ULTIMODE M ILLIMETER W AVE R ADAR  Several payloads aimed to carry out remote sensing of the lunar surface along a period of two/three years will be embarked on-board the MAGIA orbiter. One of those payloads is named RAR \(Radar Altimeter Radiometer an innovative radar operating at millimeter wavelenghts \(95 GHz\with reduced antenna and mass which will exploit its intrinsic high resolution characteristics in order to provide accurate topography of the luna r surface. Its main science goals aim at the following  achieve an accurate Moon topography  


   4             Figure 4 \226 Timeline of the radar transmitted and received signals   measure the backscattering coefficient of lunar surface  calculate the temperature of lunar surface Such objectives will be achieved with the following main scientific requirements: spatial resolution better than 600 m height accuracy better than 1 m In order to pursue the above mentioned scientific objectives the RAR instrument operates as a multimode 95 GHz multiple-beam sensor, allowing to alternatively work as altimeter, scatterometer and radiometer. This approach exploits in this way the capability of producing both global topographic lunar maps with different spatial resolutions and lunar surface brightness temp erature maps. In addition the use of a multiple-beam mode allows for viewing the surface with different inci dence angles, enabling the scatterometer capability in order to collect measurements of the surface backscatter coeffici ent. The general RAR block diagram is showed in Figure 1 The RAR instrument uses three beam antenna feed assembly associated with th e spacecraft high antenna gain to transmit and receive elect romagnetic radiation according to three operative modes: altimeter mode, scatterometer mode and radiometer mode. Figure 2 illustrates the antenna beam  configuration for the RAR payload. Four beams are envisaged to be used for the RAR instrument. Specifically the central beam \(nadir pointed operate in altimeter mode, the side beams \(SB1 and SB2\ will be used both for scatterometry and finally just the central beam will be used to collect data for radiometry. A fourth beam SB3\s used to observe the sky background \(cosmic microwave background\n order to provide a calibration source \(three sources  are foreseen\ operates separately depending on the instrument operating mode in transmitting and receiving mode Concerning the altimeter mode, it uses the radar in PulseLimited mode \(PL\n which the limitation of the ground patch received in the resolution cell is due to the length of the compressed pulse; this configuration is typical when the altimeter is high enough from the surface  The deramp technique is employed because of its capability of producing a radar mode with a very high resolution over a small field. The altimeter employs a narrow antenna beam to carry out time-of-flight measurements of signals bounced from the surface elevations along the suborbital track aimed at nadir\ain information provided by the altimeter echoes is the range between orbit and surface Such a datum along with the knowledge of orbiter and Moon ephemerides will be turn ed into lunar radius along the track. In this way, a relative and absolute \(post reconstruction r topographic profile will be stemmed In the scatterometer mode, the radar will use two beams at different angles: to characterize in a good way the incoherent echo component the beams angles will be \26115 or 26130 degrees. Furthermore, the signal band will be reduced with respect to the altimeter mode to have a more precision measurement of backscatte ring coefficient. In the radiometer mode, the lateral resolution will be better than 650 m with a sensibility better than -110 dBm/MHz, a radiometer  333 s 666 s  Transmitted Signal Received Signal 1 100 Altimeter Scatterometer Mode  Radiometer Mode 1  100  200 ms 333 s 666 s  Transmitted Signal Received Signal 1 100 Altimeter Scatterometer Mode  Radiometer Mode 1  100  200 ms 


   5  From Feed LO / DDS 86 GHz 95 GHz BPF 100 MHz 95 GHz 9 GHz MAGIA \226 LUNAR MILLIMETRE WAVE RADIOMETRE X 2 BPF Noise Source Heat Source Calibration Section  BPF 400 MHz  From Feed LO / DDS 86 GHz 95 GHz BPF 100 MHz BPF 100 MHz 95 GHz 9 GHz MAGIA \226 LUNAR MILLIMETRE WAVE RADIOMETRE X 2 BPF BPF Noise Source Heat Source Calibration Section  BPF 400 MHz BPF 400 MHz  Figure 5 \226 Block diagram of  the radiometer  accuracy better than 1 K and a radiometer resolution better than 0.1 K. Furthermore, the radiometer will observe the surface covering the temperature range from ~ 60 K to 400 K The detailed general block diagram of the instrument is shown in Figure 3. The instrument is basically constituted by three different sections related to the three operating modes. Such sections are overlapped whenever is possible to share common parts both in the receiving and the transmitting part. Hereafter, the instrument scheme is described A nadir-looking antenna of 0.5 m sends/collects radiation depending on the operating mode through a focal plane filled with four feed-horns \(potter or corrugated horn\. One feed is centred while the side ones are slightly shifted in order to produce respectively a multi-beam configuration through a nadir-looking beam and two symmetrical tilted beams \(30\260, to be confirmed during next phases\A fourth beam is used to collect the sky background radiation to be used as calibration source for the radiometer In the transmitting mode, a frequency generator allows both to generate a suitable waveform through a DDS \(Direct Digital Synthesis\d two local oscillator signals. Then, an up-conversion section increases the frequency up to the nominal transmitting frequency \(95 GHz\d delivers it to a SSPA \(Solid State Power Amplifier\to acquire the required power gain. Once power amplified, the signal is routed through a Tx switch matrix to the specific feed depending on the chosen operati ng mode \(SB1 and SB2 for scatterometry, Nadir for altimetry The Tx switch matrix basically rules the signal path from the SSPA to the SB1, SB2, or nadir horn and at last to a matched load, absorbing in su ch a way the power when the instrument operates in radiometer mode. Equivalently, in the receiving mode, the signal is collected by the antenna and sent to the feeds. Each feed channel is provided with a ferrite circulator in order to separate the transmitting and the receiving mode. The collected signa ls are then sent to a Rx switch matrix that is responsible to route them on the right path depending on the operating mode. A second switch matrix \(Calibration Switch Matrix\stead is used to select the path to carry out the radiometer calibration Concerning the frequency generation section \(part of the general architecture reported in Figure 3\cally, it is based on a master frequency generator at 162 MHz that through consecutive multipliers allo ws to generate two local oscillator signals \(86 GHz and 8 GHz\d a clock signal at 672 MHz. The latter one is sent as input to the DDS in order to produce the desired waveform. Afterwards, this signal is at first increased at 1 GHz through multipliers and then upconverted consecutively at 9 GHz and finally at 95 GHz 


   6 using the local oscillators a bove mentioned. At last, the signal goes to the SSPA input The transmitted signal is a chirp with a variable band in function of the desired resoluti on, the  chirp slope frequency being f = B where B is the bandwidth and is the pulse duration. The instrument works in DDS logic, hence the signal band is adaptable. In Figure 4 is reported the time evolution of the transmitted and received signals. In the high resolution altimeter mode the signal carrier frequency of RAR instrument is 95 GHz and the signal bandwidth is 300-500 MHz. The transmitted waveform will be a chirp with a bandwidth of 330 MHz In the altimeter modes, the received radar echo are proce ssed by deramping, filtered and after sampled by an A/D converter. The signal is elaborated by FFT, a loop tracking and a loop gain to produce the data will be transmitted to Earth. The differences between the two modes are the signal bandwidth, since in the low resolution altimeter mode the bandwidth will be lower than the in altimeter mode and the data will be transmitted to Earth: data concerning AGC Adaptive Gain Control\, the data concerning the height surface, the FFT samples concerning low resolution mode while the samples of radar echo will substitute FFT samples in the high resolution altimeter mode The last operating mode is constituted by radiometry. A simple scheme of the radiometer is reported in Figure 5 Such a mode will exploit the central beam \(Nadir\ collect microwave radiation from the lunar surface in order to obtain brightness temperature maps. The microwave radiometer is basically configured as a total power radiometer. Such a choice is due both to simplify the hardware configuration and to relax payload mass and power requirements but at the same time with the drawback of a poor calibration. The main components of the radiometer are the central feed horn \(Nadir Amplifier \(LNA\e mixer, the local oscillator, the IF amplifier, the pre-detection filter, the detector, the integrator and finally the Analog to Digital Converter \(ADC\Feeds and LNA are shared with the altimeter and the scatterometer in order to reduce complexity and costs In this phase a preliminary evaluation of the radar power budget has been carried out. Table 1 shows the power budget calculated for the altimeter mode. The following formula has been used  to calculate the signal to noise ratio FBkTH cGP p 0 32 022 64 002 003\004\005   The parameters above used are identified in Table 1 Finally, a preliminary evaluati on of the work carried out identifies a maximum power consumption of about 30 W and a maximum mass of 10 kg Table 1   Radar power budget for the altimeter mode \(high resolution NE 0 18 dB 418 400 Total 28 64 2 7 F Noise Figure 35 300 s Pulse width 25 290 K T 0 Temperature 229 1.38*10 23 J/K k Boltzmann constant 150 H =100 km H 3 Height 85 3*10 8 m/s c Light speed 85 330 MHz B Bandwidth 20 10 mW P p Peak Power 104 Antenna efficiency = 0.65 G 2 Gain 50 3.16 mm 2 Wavelenght dB dB Comment Symbol Parameter NE 0 18 dB 418 400 Total 28 64 2 7 F Noise Figure 35 300 s Pulse width 25 290 K T 0 Temperature 229 1.38*10 23 J/K k Boltzmann constant 150 H =100 km H 3 Height 85 3*10 8 m/s c Light speed 85 330 MHz B Bandwidth 20 10 mW P p Peak Power 104 Antenna efficiency = 0.65 G 2 Gain 50 3.16 mm 2 Wavelenght dB dB Comment Symbol Parameter   4  C ONCLUSIONS  Preliminary results of a currently ongoing study related to the design of a millimeter wave radar for lunar remote sensing were reported in the paper. The radar is a multipurpose radar operating at 95 GHz which follows the path opened by the Cassini radar at present orbiting around Saturn. Actually, exploiting the high and innovative operating frequency \(95 GHz nd combining the different operating modes, the RAR instrument will allow to acquire valuable data from the lunar surface data in terms of brightness temperature and su rface emissivity maps. Such data will be used to determine the dielectric properties of the surface materials and will a llow the characterization of the thermal properties of the lunar soil. Future work foresees a detailed definition of the radar and its performance evaluation through system simulation via microwave software        


   7 R EFERENCES  1] \223The vision for Space Expl oration\224, February 2004  E Re, M. Ruggieri, V. Dainelli , M. Ferri, \223Millim eter Wave Technology for Moon and Mars Exploration\224 IEEE Aerospace Conference 2008, Big Sky, Montana, 1-8 March 2008  E Lim iti, M. Ruggieri, \223Innovative Technologies for the Developments of W-band Radars and Communication Payloads\224, IEEE Aerospace Conference 2006, Big Sky, Montana, 1-8 March 2008  ediate Phase A Report\224 Rheinm etall Italy Internal Document 5 i o  B. Pern ice, L. Bo rg arelli, C. Dio n i sio   R Tizzoni, \223Cassini Radar Radio-Frequency Subsystem Design Description and Pe rformance Analysis\224, IEEE 1992 B IOGRAPHY  Marco Lucente received his University Degree in Physics with specialization of Astrophysics and Space Physics in 2002 from the University of Rome \223La Sapienza\224 He was involved in studying the polarimeter of the BOOMERanG Balloon Observation of Millimetric Extragalactic Radiation and Geophysics\ experiment He received a MSc Degree in 223Advanced Communication and Navigation Satellite Systems\224 at the University of Rome \223Tor Vergata\224 in 2004/2005. Since the beginning of 2004, he is a scientific member of the WAVE \(W-band Analysis and VErification project team. He is currently involved in different projects most of them based on the exploitation of microwaves/millimeter waves \(telecommunication, remote sensing, Universe observation He is author of several papers, on proceedings of in ternational conferences and journals. His main fields of research concern Space Systems, EHF Telecommunication Satellites, Universe/Solar System Observation Satellites Spaceborne Remote Sensing Radar Systems, Navigation Sat ellite Systems, and Inertial Navigation Systems  Vittorio Dainelli is microwave/mm wave developments R&D manager at Rheinmetall Italy Rome \(Italy\. About thirty years of experience in design/development/m anagement  of microwave/mm wave systems/subsystems including MMICs, MEMS, and Quasioptic devices for ground/space and subsystem/systems for shipborne, ground military, and civil radars. Degree cum laude  in Electronic Engineering from University of Rome , Ph.D. in Automatic Control Systems  Cesare Dionisio   Mario Noce is a young engineer working at Rheinmetall Italia, Roma \(Italy\. About two years of experience in satellite mission analysis, and about one year of experience in design & development of radar systems. Degree cum laude in Electronic Engineering from University of Palermo, Master Degree cum laude in Advanced navigation and communication satellite system    


   8  


  9 when it is done. However, even this model does not fit the desired model of behavior  Figure 7. Sequence diagram showing the push and pull methods from Asynchronous Web Services  Asynchronous Web Services can use either a Synchronous or Asynchronous MEP \(Message Exchange Protocol transmitting and receiving protoc ol messages.  There are two methods supported for both synchronous and asynchronous MEP types:  polling and callback. Both support non-blocking client side behavior The polling method represents the \223pull\224 model of processing where the client determines when the response is received.  The callback method has the client passing a callback handler to the Web Service Endpoint. This callback is essentially an endpoint on the client side running in a separate thread that waits for the server to respond.  The callback method represents the \223push\224 model of processing where the server determin es the notification For polling-based asynchronous MEP, we find that the client still needs to be active while it polls. That is, a service submission would normally return a response object that is used to check if the job is done. That same response object is also used later to retrieve the results when available. For long duration processing times, the client must still maintain the same response object. Though the response object may in principle be marshalled out for longer persistence implementation-specific network connection reliance be prove to be impractical. The preferred approach would be to move the role of asynchronous waiting from the Web Services request/response objects down further to the job scheduler The remaining option would be to use normal synchronous Web Service calls, but cleanly se parate the different atomic operations into individual synchronous Web Service calls These individual calls consists of submitting a job canceling a job, getting the status of the job \(running cancelled, etc\ting the progress of the job \(console output, etc\and finally getting the results of the job \(figure 8\ Each synchronous call is then delegated to an underlying job manager for the actual service job management. Collectively, the client is provided with an asynchronous service model For particularly long running service jobs, we find that users also want to see progress of the processing activity. In addition to getting the status of the job state \(such as queued, running, done, cancelled\so provide the capability to see progressive real-time output form the processing job. Our service endpoint manages a console buffer of a processing job\222s STDOUT/STDERR. When a Web Service call to get the progress of a particular job is invoked, the current buffer contents of the progress is returned and then flushed from the server-side buffer. This enables clients to build GUI applications on top of this asynchronous service and see the real-time console output of the server-side processing on their client GUI window Additionally, the console refresh rate, determined by the client, can be adjusted to an appropriate rate for that client\222s usage. Other approaches are possible including publishing the progress to a custom Atom feed. But here, the console content is only handled and retrieved when the client needs it  Figure 8. Sequence diagram showing atomic synchronous calls that implement job management capabilities of a service  Though callbacks \(registerable handlers\ally the preferred paradigm over polling, this client example demonstrates the utility of keeping it simple. We require maintaining a set of lightweight Web Service clients across multiple platforms. Not all platforms and Web Service APIs support asynchronous Web Services. For true callbacks 


  10 implementations would also require the clients to run Web Service endpoints of their own This asynchronous service model that is composed of synchronous atomic Web Service calls can also be used at varying levels of complexity as desired by the client user For the novice, the service \223submit-isDone-get\224 sequence can be encapsulated into one simple function call. For the intermediate user, the same aggregated function call can also provide real-time notifications \(Observer design pattern\job currently running on the server. For the advance user network disconnects and client shutdown after a service job has been submitted can be achieved. The unique job id that is returned upon service submission can be stored for persistence enabling users to submit a product request from laptop, shutdown their laptop, and restartup at later time to retrieve the generated products Using AXIS2 and JAX-WS for the various client-side implementations introduces an extra dependency for users of some clients and therefore is less preferable. We also want to maximize ease-of-use for the user where we lessen the burden of installation, set up, and library dependencies Whenever possible, we used the \223vanilla\224 SOAP implementation that is intr insically available for each platform to keep the client footprints small Another intended use of our services is to be orchestratable by Web Services-enabled workflow engines. The callback approach to asynchronous Web Services is currently not as interoperable as standard synchronous Web Services However, current Web Service workflow engines can be set up to operate with standard Web Services that have the atomic actions exposed as multiple synchronous Web Service calls that poll for when a job request is done before continuing Data Delivery Once processing has completed, the service response is returned to the user. In th e Earth science domain, these results typically are generated data products that may be large in size. Given that the SOAP approach to Web Service uses XML as the underlying content being transferred transferring binary data in the SOAP message would not be efficient for large binary data sizes. Large binary file data support in XML currently still exhibits technical and performance issues. Approaches ex ist to encode binary data in various encoding schemes such as MIME and base64 More recently, there have b een new W3C recommendations for handling large binary data transfers such as XML-binary Optimized Packaging \(XOP Transmission Optimization Mechanism \(MTOM and Resource Representation SOAP Header Bl  However these new extensions may not be supported or compatible with all the client platforms that we need to support \(such as Matlab, IDL, and Python We settled on an approach that is compatible across the major client platforms. Rather then forcing data to be encoded in any scheme in SOAP, we simply allow the binary data to be transferred efficiently in standard http/https. When a Web Service job has completed, the generated product data files are placed in a unique URLaccessible location, and these UR Ls are sent back in the service response. The clients are then responsible for downloading the product files from the URLs A side benefit of this approach is observed when orchestrating our services fro m workflows. The URL results from one workflow operator are passed onto the next operator, which then is responsible for pulling the data from the given URLs. This method allows each operator to control the rate of accessing th e previous operator\222s data results OPeNDAP Another mechanism we support for data access is Data Access Protocol  \(DAP\ore specifically, we leverage the  for requesting and transporting data that is generated by the services. OPeNDAP also enables remote subsetting of data using constraint expressions, and the translation of data from one format to another. HDF5 data has been recently shown to work well over OPeNDAP using the Hy  The OPeNDAP protocol in recent years has become more widely used and accepted in the Earth Science community The Earth System Grid \(ESG on Environment and Water \(CREW\two large Earth science data centers using OPeNDAP for data access Date Time Handling For time handling, leveraging the Java GregorianCalendar simplifies handling timezones, time ranges, as well as correct leap years.  The bus iness logic model layer fully leverages the GregorianCalendar model to allow us to support manipulating multiple time granules, from seconds to years, and of any duration for each time granule. There is also a related XMLGregorianCalendar that we leverage for representation of W3C XML Schema 1.0 date/time datatypes across the Web Services For averaging, given a particular start and end time in GregorianCalendar format, along with an integer time duration amount, the model is able to determine the correct time ranges \(i.e. number of averaged files\d partitions the work accordingly for the av eraging engine \(in this case the engine is IDL\anCalendar individual time elements are retrieved and passed on to the engine for 


  11 processing, and the result is a list of files that propagates up to the server side layer For subsetting, latitude and longitude values are handled at the model layer, and translated \(when necessary correct coordinate values for the underlying engine.  Also to reduce the number of parameters a user would need to provide, we support user inputs of date/time string using the ISO 8601 format, the International Standard for the representation of dates and tim For exam pl e t h e input string \2232008-10-31T12:00:00Z\224, would be converted into a GregorianCalendar inst ance representing that exact date/time for the model layer Using the combination of GregorianCalendar and the ISO 8601 standard allows us to easily handle timezone-aware and timezone-na\357ve inputs. Internally to our \223business logic\224 model layer, all date/times are timezone-aware and set to the UTC timezone to match most of the instrument data conventions. But if the user provides a timezone-na\357ve date/time, that is with no timezone specified, then we promote it to UTC standard time. We also support user input in any timezone here we leverage the GregorianCalendar to convert any timezone to the UTC internal representation This simplifies science studies where users simply provide the local time at the area of interest to query data for  7  C LIENT I MPLEMENTATION FOR A NALYSIS E NVIRONMENTS  We implemented client-side modules to adapt to the major working environments favored by most scientists: \(1 4\thon, \(5\/C++, and \(6 Fortran90. Unlike other approaches that force the scientists to leave their familiar working environment to access data our services tool set brings the data access and manipulation back into their working envi ronments. Whenever possible we also aimed to develop the ability to automatically download and construct the native data objects in each respectively environment. This eliminates the need for the end user to worry about data file downloads, local file management, and loading them into in-memory data arrays for manipulation. A consistent experience is given to the user, both across the different tools and across the different platforms, with common interfaces and usage conventions This form of seamless integration directly facilitates the transparent access and manipula tion of heterogeneous data as called for by NASA\222s ACCESS NRA goals Java The Java client was designed to be an importable jar library from any user Java application. Since the Web Service endpoint server was already written with Sun\222s JAX-WS Reference Implementation, we also chose the same for the Java client implementation. This maximizes interoperability since both client and server utilize the same library. The client contains high-level methods for calling the Web Service and automatically downloading the custom-created files, allowing the entire process of service querying and downloading data to be contained in a single method call Lower level methods are also exposed in the service allowing the user more fine-grain control over the data flow and interface with the Web Services Matlab Mathwork\222s Matlab is a popular working environment used by scientists to perform science analysis. The 2008 release of Matlab has built-in support fo r Web Services with autocode-generation from WSDL URLs. It leverages the Java integration that Mathworks has already worked into Matlab We leveraged this built-in capability to develop Matlab modules that access the same server-side Web Services for Level 2 and Level 3 data access and manipulation Our Matlab service client consists of a number of .m files file extension for Matlab custom code\and requires no Java package dependencies beyond the JVM native to the Matlab environment.  Built-in SOAP functions help to create, send, and parse the SOAP message, which is used to communicate with our remotely hosted Web Services For automatic data file downloads, classes and methods standard with Java version 1.5 \(standard with Matlab 7.6 were used to access and download the files via http.  The resulting client allows all of the Web Services and downloading functionality to be transparent to a user Matlab supports the construction and handling of full Java data objects and the invocation of Java class methods directly form within Matlab. We made use of built-in functions that served as the bridge between a Matlab script and a SOAP service call \(createSoapMessage.m callSoapService.m, and parseSoapResponse.m\. These built-in SOAP functions in Matlab constrained us to passing a narrow range of Matlab data types due an incomplete set of Matlab datatype to W3C SOAP datatypes. Particularly the date-time and arrays of strings must be manually handled as more primitive types Two methods of datetime passing were settled upon.  One relies simply upon passing a tuple representation of datetime\227a number for the year, and others for the month, day hour, minute, and second.  While such a method worked well \(converting simple numerical data types\t was seen to be cumbersome and made for far less readable code to have to use six parameters to specify a single datetime.  We turned then using short char acter strings to represent datetimes, following the ISO 8601 standard.  Data type conversion of character strings between Matlab and XML is similarly easy as numerical types, and made for very concise and readable function calls 


  12 Passing arrays of strings required a retreat from any kind of array-like data structure.  Instead, a single, long string was created from an array of strings in Matlab, separated by a distinct delimiter \(a \223,\224 in this case\s single long string is passed through the service interface to the endpoint server, which then parses the string back into a list format before continuing on with the rest of the call sequence IDL ITT\222s IDL is another powerful visualization and analysis tool popular with the Earth science analysis community  Unl i k e M a t l a b, IDL \(as of versi on 7.0 have any built-in Web Services support. IDL can be made to speak the Web Services languages via an IDL-Java bridge delegating the Web Services capability to a linked Java library.  This does allow calling the Web Services, but there were some issues encountered along the way First, the IDL-Java bridge connectivity required some setup and handling by the end user. Environment variables and jar classpaths must be properly configured. While this is easily resolve with an installer, there was a strong desire to minimize the IDL client foot print to where there are no dependencies. We wanted to provide an IDL client code that could be dropped into a directory somewhere and should \223just work\224 Second, there are some known issues working with objects in IDL. We encountered memory errors during execution which appeared to be a memory leak in the IDL-Java bridge there was previously a known memory leak that had been patched\also ex tra overhead when interfacing between IDL and Java where data is converted from Java objects to IDL types Our current effort is focused on building a \223poor man\222s\224 SOAP as part of our IDL client that will allow us to directly call and interface with the Web Services, without having to go through Java.  We plan to utilize IDL\222s built-in simple http support to send manually constructed SOAP messages Though this approach forgoes the robustness of the JAXWS implementation, it will however provide a pure IDL client to our end users with no external dependencies Python The Python scripting environment has become a popular working environment for fast prototyping and exploratory science processing. Among all of the clients here, the Python Web Services client is the most trivial. We leveraged the suds package, a lightweight SOAP client for consuming Web Services in Pyt Though ot her open-source Python Web Service packages exist \(such as ZSI\we have found suds to be the most easy to use and more dynamic in nature. Suds does not require class code generation and can read WSDLs at runtime to dynamically construct a proxy object with an interface representing the WSDL C/C We want any C/C++ client to be able to interact with the server-side Web Services of Level 2 and Level 3 data generation. By using the using the popular open-source gSOAP Toolkit for SOAP Web Services package  client-side modules can interact with the data generation services developed on the server-side. gSOAP also includes facilities to autogenerate C/C++ RPC code from our published WSDL definition files of the Web Service on the server. We have also found that gSOAP has a good selfcontained XML bindings facility Fortran Fortran90 modules can be made capable of remotely accessing and the Level 2 and Level 3 data. Though Fortran has no built-in libraries to perform Web Services, we leveraged our C/C++ Web Service API via gSOAP to do the work. Fortran can call an 223externed\224 C Web Service API and pass back the relevant data into the Fortran environment. This would enable Fortran to fully delegate the Web Services operations to the C/C++ implementation 8  NEWS  L EVEL 2  P RODUCTS  With the availability of the software infrastructure supporting server-side processing, and seamless client-side data query and access, downstream data products can now be generated from the source merged NEWS Level 2 data Averaged One of the most common wa ys to summarize the large amount of data is to calculate the averages of data within a given temporal and spatial boundary. For example, it is very useful for scientists to make daily, weekly, monthly averages of some parameters in a regular latitude-longitudepressure grid, make a global map of the average, and analyze any global patterns and trends. In order to facilitate the needs, we developed an averaging Web Service to generate averaged data products that a user can customize The input arguments for the averaging Web Service are the time range, time granule, and a list of parameter names to produce averaged products with. The time range specifies the start and end time to access the NEWS data from. The time granule specifies the aver aging time period. The list of parameter names specifies the choice of parameters that are requested to make averaged products Subsetted Subsetting a data set is a fundamental way to access specific data from a large collection of data. We developed a usercustomizable subsetting Web Service that supports three general subsetting conditions 1  Spatial condition \(latitude, longitude, vertical range 


  13 2  Temporal condition \(e.g. from 2002-05 to 2002-07 3  Parameter selection \(e.g. te mperature and atmospheric water vapor only The combination of these three conditions allows a user to subset data in time, location, and parameter space 9  NEWS  L EVEL 3  P RODUCTS  Many of these quantities in NEWS L2 product interact through fundamental physical processes \(e.g. temperature affects cloudiness, and also the converse\ Consequently the observations should be treated as statistically separate variables, though traditiona l methods of summarizing satellite data do just that. We applied statistical clustering methods to a multiple-parameter set of observations from the A-Train instruments over the multi-year record. The resulting Level 3 quantitative summaries are made accessible through our serv ice-oriented tool Level 3Q Level 3Q data sets are statistical summaries of underlying Level 2 data. Like traditional Level 3 products they are 223gridded\224 in the sense that they provide a summary of Level 2 data belonging to space-time grid cells. These cells are typically defined as one or fi ve degree spatial regions over a time period of one or eight days, or one calendar month Unlike traditional Level 3 products, the Level 3Q \(L3Q grid cell summaries provide nonparametric multivariate estimates of the joint probability distributions of multiple geophysical parameters. Distribution estimates are derived from the underlying Level 2 data using informationtheoretic principles that balance the quality of the estimate against the amount of data reduction achieved  Figure 9. Raw and summarized data for one grid cell Raw data belonging to that grid cell can be listed in a data table with one row for each of N data points and one column for each variable \(here, two alternate representation: a scatter plot. In both cases each data point has weight 1. On the right are two representations of the compressed summary. The data table has K<<N rows and two extra columns showing cluster count and distortion. Counts are shown in the corresponding scatter plot by the bar heights  Data reduction replaces a larg e number of individual data points with a smaller number of representative data points and associated weights and quality measures. Figure 9 illustrates the basic concept. The idea is to treat a set of coincident measurement of different geophysical parameters for the same footprint as a multivariate vector, and collect all such vectors belonging to a given spatial-temporal grid cell as a set of points in high-dimensional data space. These data are partitioned into disjoi nt groups, called clusters, and we report the following statistic s for each: i\the centroid which is the representative, ii\he number or proportion of original data points assigned to it, and iii\the average squared distance between member data points and the centroid. This latter quantity is also called the cluster distortion The method that assigns data points to clusters is an adaptation of a signal-processing algorithm called Entropyconstrained Vector Quantizati EC VQ i s si m i l a r t o  the well-known K-means clusteri  Kmeans finds an assignment of raw data points to K clusters that minimize distortion. ECVQ finds an assignment that minimizes a quantity based partly on distortion, but also on the entropy of the probability distribution defined by the clustering. Entropy is a measure of information-theoretic complexity, and it is also well known that greater complexity is required to achieve lower distorti  ECVQ was originally proposed as a way of estimating this trade-off. The algorithm may find fewer than K groups as it attempts to balance the competing goals of fidelity to the original data and parsimony of representation.  This produces the smallest, or more properly, the least complex output data set that achieves a given level of fidelity to the original data. Our version of ECVQ is adapted in a number of ways for use as a massive data set reduction tool. These are described in detail in  and 26  W e  have al so previously employed our version of ECVQ to produce monthly summaries of Atmospheric Infrared Sounder data  The algorithm\222s output is best thought of as an estimate of the multivariate distribution of the data in a given space-time grid box. The original data have a distribution that puts probability  N on each multivariate data point, where N is the number of data points. ECVQ coarsens this distribution by collecting similar points into clusters, representing them by cluster centroids, and assigning probabilities N k k where N k is the number of point assigned to the k th cluster. In addition we also report the within-cluster mean squared error distortion\, which is a measure of the quality of the cluster representative as a stand-in for the original data assigned to it 1 N to cluster  


  14 10  A NALYSIS R ESULTS  AIRS, AMSR-E, MODIS and CLOUDSAT data have been merged into a dataset by the NEWS effort, and a framework of Web Services for averaging, subsetting and statistical analysis have been developed. Collectively it facilitates the data access and analysis of hydr ological processes. Here we present an example usage of instrument intercomparison Comparing Data Products Prior to Merging A necessary step in creating a formal merged data product is intercomparison of component data sets.  This ensures that the mutual random and systematic differences between the two data sets are quantified.  This approach does not provide information about absolute bias, which can be obtained only from comparisons with unbiased standard data sets.  For example, wate r vapor and temperature biases are typically constrained through comparisons with in situ observations as from radiosonde.  Such comparisons are usually the responsibility of the data provides, so the analyses described below assume some knowledge of satellite measurement biases An example of comparing component data sets is presented here with a single atmospheric state variable, in this case observed by AIRS \(Atmos pheric Infrared Sounder AMSR-E \(Advanced Microwave Scanning Radiometer for EOS\For this example five variables \(AIRS Total Water column, AMSR-E total water column, AIRS cloud fraction AIRS total water error estimate, AMSR-E liquid water path stemming from two different instruments \(AIRS and AMSR-E\pared and correlated The Atmospheric InfraRed Sounder \(AIRS\he Advanced Microwave Scanning Radiometer \(AMSR-E\are two instruments aboard the AQUA spacecraft. AMSR-E estimates water vapor over water surfaces and AIRS estimates water vapor over ocean and land. A map of the daily average of terrestrial water vapor column is shown in figure 10. This figure maps th e AIRS estimate of average total \(column\er vapor in mm during March 2003 at a spatial resolution of 1 degree in latitude and longitude  Figure 10. Map of averaged AIRS Total column water vapor for 2003-03   Figure 11. Scatter plot of monthly AIRS and AMSR-E column water vapor. AIRS and AMSR-E water vapor agree very well on the co incident locations  A similar a subset of AMSR-E water vapor over the ocean was prepared with our services and merged with the AIRS dataset at the same spatial and temporal resolutions. A scatter plot of the values estimated with AMSR-E is compared to the collocated va lue of AIRS in figure 11 Figure 11 also shows a red line to mark the location where all points should fall if the AIRS and AMSR-E estimates were the same. The figure shows a tendency by AMSR-E to estimate higher total water vapor than AIRS. However there are locations where AIRS does show higher values. A map of the averaged differences \(AIRS-AMSR-E\15 selected monthly means between the years 2003--2006 is shown in figure 12 This map highlights locations where each instrument tends to overe stimate compared with the other. Blue tones identify regions where AIRS estimates are larger than AMSR-E and shades of brown locate the regions where the opposite is true 


  15  Figure 12. Map of average differences over 15 months between AIRS and AMSR-R water vapor  Figure 12 highlights regions th at are characterized by different hydrological regimes. AIRS overestimates coincide with regions where cold western boundary currents cause frequent cold marine stratocumuli. AMSR-E tends to estimate higher total water vapor in regions characterized by warm sea surface temperatures and frequent convective activity. This result is consistent with previous comparisons    Figure 13. AIRS Total Cloud Fraction sum for 2003-03 Sum over all pressure levels AIRS is an IR measurement that cannot estimate water vapor in regions overcast with optically thick clouds. This property introduces a bias that depends on the cloud fraction. Figure 13 shows an estimate of the cloud fraction using a surrogate for cloud fraction over several AIRS pressure levels. It adds up the cloud fraction at the different levels \(because there may be overlaps, the sum over all pressure levels can be larger than one between the areas with large cloud fraction sums and large AMSR-E overestimates with respect to AIRS and vice versa, areas with the smallest cloud fraction sums coincide with the areas with large AIRS water vapor estimates A proxy for the "thickness" of the clouds in the overcast regions is the liquid water content of such clouds. The advantage of this proxy over others is that it also conveys information about the physical and hydrological characteristics of the scenes co rrelated with the differences Figure 14 shows a PDF of the differences as a function of AIRS water vapor and AMSR-E cloud liquid water path. A black contour line marks the change of sign in the differences. It shows that AIRS estimates higher total water vapor at low liquid water paths with a characteristic quasilinear increase between 5--20 mm. AMSR-E estimates larger total water vapor at 1 x 1 degree regions where the liquid water path is high. The pattern of the differences raises questions about why does AMSR-E estimates differ so quickly from AIRS at low water vapor contents and low liquid water paths  Figure 14. AIRS-AMSR-E differences \(in mm function of AIRS total water and AMSR-E cloud liquid water for the month 2003-03  


  16  Figure 15. AIRS-AMSRE differences as a function of AIRS error estimate over one day  AIRS has an error estimate of the total water vapor value that it calculates. The diffe rences between AIRS and AMSR-E are shown as a function of this estimate in figure 15 and very little correlation is found 11  R ELEVANT W ORK  Merged A-Train Level 2 Data A merged product that preserves the relationship of observed atmospheric water properties facilitates the hydrological studies by enabling scientists to get directly at the model data without worrying about the logistics of finding, collecting, and coordinating the measured quantities from different instruments. Previously there did not exist a capability to discover and access data from the A-Train\222s multiple instruments as merged multi-parameter data sets Enabling Orchestratable Service Workflows Our distributed service-oriented approach of loosely coupled services also enable s a higher level of reusability and orchestration with other services. Increasing numbers of workflow engines are already supporting Web Services as components/operators, which can then be orchestrated together into higher-level meta/virtual services SciFlo, a Scientific Dataflow Execution Environment, is a workflow engine that already supports assembling reusable SOAP Services, native execu tables, local command-line scripts, and codes into a distributed computing flow \(a graph of operators\8 SciFlo can u tilize o u r g en eric SOAP services as part of a larger coordinated data flow The Taverna Workbench is a free software tool for designing and executing workflows. Like SciFlo, it can orchestrate SOAP-based Web Services as components within a workflow. Taverna provides a visual editor to construct and edit the sequence of services in the workflow We have found that Taverna can dynamically introspect a given WSDL and construct the workflow component interface representing it Giovanni Giovanni, an acronym for the Goddard Earth Sciences Data and Information Services Cent er, or GES DISC, Interactive Online Visualization and Analys is Infrastructure, is a webbased tool to help visualize Earth science data  It  provides a simple and intuitive way to visualize, analyze and access vast amounts of Eart h science remote sensing data without having to download the data. Similar to the services developed here, it addresses the difficulties of traditional data acquisition and analysis methods by moving the complexity to the server-side Giovanni provides multiple in terface instances based on instrument and measurement ty pes. For example, the \223ATrain Along CloudSat Track Inst ance\224 can provide plots of vertical profiles of clouds, temperature, humidity, cloud and aerosol classification across the multiple instruments of the A-Train A distinction between Givanni\222s A-Train data and the data set in this paper is that we are using a formal merged product of the A-Train. We leverage the NEWS effort that is based on error- and resolution-weighted mean of the input data sets, with associated uncertainty estimates. This provides a formal model of the collective A-Train observations rather than the collection of the individual instrument measurements Each of Giovanni\222s multiple interface instances provides a very simple and easy to use web interface. However, we recognized that sometimes scientists want more than the simple interfaces. Some scien tists may want to process Level 3 products using their own trusted code, or may want to perform variations of their own plots. With Giovanni, the individual scientist wanting more custom advanced capabilities must depend on the Giovanni development team Giovanni is based on the web portal paradigm where users visit a web page and use web tools to find and visualize data. Similar to Giovanni, our client APIs also make data acquisition more seamless. However, our services are based on the different paradigm were the power and flexibility of data analysis and processing are shifted back into the scientists own familiar computing environments. We realize that scientists generally want to perform \223exploratory computing\224 where they can sere ndipitously analyze the data using their own familiar and trusted code 


  17 Giovanni 2 was inherently synchronous where processing was bounded to a single http session. Long service running times still require the user to hold the same http session Similar to our asynchronous Web Service we discussed, the upcoming Giovanni 3 will be supporting asynchronous sessions. They will be using a RSS feed to monitor the service request. Version 3 will also be based on a servicesoriented architecture, wher e Giovanni services can be offered as a standard SOAP Web Services. This is similar to our approach, as well as SciFlo\222s services 12  C ONCLUSIONS  To achieve the science research goal of investigating longterm and global-scale trends in climate, water and energy cycle, and weather variability, we enhanced and improved on existing algorithms to work with distributed and heterogeneous data and information systems infrastructure By developing a service-oriented architecture for discovering, accessing, and mani pulating of NEWS merged A-Train data sets, we can strengthen the interconnectedness and reusability of these services across broader range of Earth science investigations The merged NEWS Level 2 data is a formal model containing the voluminous data from the AIRS, AMSR-E MLS, MODIS, and CloudSat instruments. Previously scientists wanting to perform long-term and global-scale studies encompassing simultaneous measured quantities would quickly face a data acce ss hurdle of first finding the data, then manually downloading them, and finally merging the data into a cohesive model\227before starting their analysis. Additionally the voluminous nature of the data particularly because of the MODIS data\each scientist potentially downloading the same data resulting in redundancy of reprocessing on the client sides. Our paradigm pushes more of the commonly repeated processing onto the server side. Moreover, this avoids repeated downloading of the same data among the science users. We can deliver customi zed averaged, subsetted, and summarized data of the merged A-Train observations to the scientists for them to immediately begin their analysis work We recognized that scientists also often want to perform 223exploratory computing\224 where they can freely explore the aspects of the data and run serendipitous exploration in their own familiar environment. We developed client-side distributed APIs in popular analysis environments such as Matlab, IDL, and Python. Our APIs hide the complexity of Web Services and allow the service capabilities to be embedded in the scientists own computing environments By purposely avoiding the \223web portal\224 paradigm and providing the suite of platform specific APIs in each of these language platforms, we enable the scientists to remain within their own familiar environments to select, process and download the data seamlessly into their environment for their own further analysis. Alternative methods involving web portals force the scientists to leave the environment and manually interact with the web portal to search and download the data We can examine not only long-term changes in amplitude of a single variable but also those among multiple variables Our L3Q clustering method was specifically designed to preserve information about the covariability of multiple observations, such as those from the A-Train.  Weather and climate variability is characterized by changes among atmospheric observables, but those changes have been limited by a lack of observations and analytical techniques We are not aware of any multi-parameter analyses to date The full potential of the A-Train climate record will not be realized until the multi-parameter climatology is understood. The work presented is one method of approaching this difficult problem Our service tool addresses several objectives of the NASA Earth science data community including 1\mprove interoperability to facilitate the transparent access and manipulation of heterogeneous and distributed data by science users, 2\ransition and deploy existing Earth science research analysis tools and software using a 223Service Oriented Architecture\224 \(SOA\ to enhance their reuse potential for other science domains and improve overall awareness and access of these tools by a broad community, 3\ increase users\222 ability to customize their discovery, access, deliv ery, manipulation, and preferred format of data and information 12  F UTURE W ORK  On-demand Level 3T Summaries from Level 3Q We plan to develop services for creating custom summaries of the L3Q data into more refined Level 3T summaries L3T\create their own custom Level 3 products on demand from L3Q. The custom Level 3 products are the transformation of L3Q data based on user-specific objectives such as regression and correlation analyses. The cust om production will generate not only the transformed data but also the statistical estimation of the accuracy of the summarized data based on the distribution of L3Q and the quality of L3Q Delegating the Temporal-Spatial Data Querying Currently, our processing layer utilizes existing and legacy processing code that was developed in IDL, Matlab, and C++. Though the original intent was to be able to adapt existing code and wrap as a service, this meant maintaining its original form of accessing the source data for processing Small modifications were made to enable these codes to quickly access the data based on file path and file naming schemes. However, we want to decouple the file accessibility and processing roles 


  18 We plan to shift the file search and accessibility aspect outside of the IDL/Matlab/C++ code thereby treating it more as a processing \223engine\224. SciFlo\222s geoRegionQuery service can be used as a generic temporal and spatial search that returns a list of matching file URLs \(local file paths if the files are located on the same system geoRegionQuery service relies on a populated MySQL databases containing the list of indexed data files. We then also plan to leverage SciFlo\222s data crawler to index our staged merged NEWS Level 2 data products Improving Access to the A-Train Data Collection Currently, the NEWS task collects the various A-Train data products for merging using a mixture of manual downloading via SFTP and automated shell scripts. This semi-manual process can be automated into a serviceoriented architecture that can automatically access and download the various Level 2 instrument data from their respective data archive center. This will be simplified if more data centers support OPeNDAP, which will aid in data access. OPeNDAP will also allow us to selectively only download the measured properties of interest to the NEWS community for hydrology studies. Additionally OpenSearch, an open method using the REST-based service interface to perform searches can be made available to our staged A-Train data. Our various services such as averaging and subsetting can be modified to perform the OpenSearch to determine the location of the corresponding spatially and temporally relevant data to process. This exposed data via OpenSearch can also be made available as a search service for other external entities interested in our data as well Atom Service Casting We may explore Atom Service Casting to advertise our Web Services. Various services can be easily aggregated to create a catalog of services th at are published in RSS/Atom syndication feeds. This allows clients interested in accessing and using our data services to easily discover and find our WSDL URLs. Essentially, Atom Service Casting may be viewed as a more human-friendly approach to UDDI R EFERENCES   NASA and Energy and W a t e r cy cl e St udy NEW S website: http://www.nasa-news.org  R odgers, C  D., and B  J. C onnor \(2003 223Intercomparison of remote sounding instruments\224, J Geophys. Res., 108\(D3 doi:10.1029/2002JD002299  R ead, W G., Z. Shi ppony and W V. Sny d er \(2006 223The clear-sky unpolarized forward model for the EOS Aura microwave limb sounder \(MLS Transactions on Geosciences and Remote Sensing: The EOS Aura Mission, 44, 1367-1379  Schwartz, M. J., A. Lam b ert, G. L. Manney, W  G. Read N. J. Livesey, L. Froidevaux, C. O. Ao, P. F. Bernath, C D. Boone, R. E. Cofield, W. H. Daffer, B. J. Drouin, E. J Fetzer, R. A. Fuller, R. F. Jar not, J. H. Jiang, Y. B. Jiang B. W. Knosp, K. Krueger, J.-L. F. Li, M. G. Mlynczak, S Pawson, J. M. Russell III, M. L. Santee, W. V. Snyder, P C. Stek, R. P. Thurstans, A. M. Tompkins, P. A. Wagner K. A. Walker, J. W. Waters and D. L. Wu \(2008 223Validation of the Aura Microwave Limb Sounder temperature and geopotential height measurements\224, J Geophys. Res., 113, D15, D15S11  Read, W G., A. Lam b ert, J Bacmeister, R. E. Cofield, L E. Christensen, D. T. Cuddy, W. H. Daffer, B. J. Drouin E. Fetzer, L. Froidevaux, R. Fuller, R. Herman, R. F Jarnot, J. H. Jiang, Y. B. Jiang, K. Kelly, B. W. Knosp, L J. Kovalenko, N. J. Livesey, H.-C. Liu1, G. L. Manney H. M. Pickett, H. C. Pumphrey, K. H. Rosenlof, X Sabounchi, M. L. Santee, M. J. Schwartz, W. V. Snyder P. C. Stek, H. Su, L. L. Takacs1, R. P. Thurstans, H Voemel, P. A. Wagner, J. W. Waters, C. R. Webster, E M. Weinstock and D. L. Wu \(2007\icrowave Limb Sounder upper tropospheric and lower stratospheric H2O and relative humidity with respect to ice validation\224 J. Geophys. Res., 112, D24S35 doi:10.1029/2007JD008752  Fetzer, E. J., W  G. Read, D. W a liser, B. H. Kahn, B Tian, H. V\366mel, F. W. Irion, H. Su, A. Eldering, M. de la Torre Juarez, J. Jiang and V. Dang \(2008\omparison of upper tropospheric water vapor observations from the Microwave Limb Sounder and Atmospheric Infrared Sounder\224, J. Geophys. Res., accepted  B.N. Lawrence, R. Drach, B.E. Eaton, J. M. Gregory, S C. Hankin, R.K. Lowry, R.K. Rew, and K. E. Taylo 2006\aintaining and Advancing the CF Standard for Earth System Science Community Data\224. Whitepaper on the Future of CF Governance, Support, and Committees  NEW S Data Inform ation Center \(NDIC http://www.nasa-news.org/ndic 


  19   Schi ndl er, U., Di epenbroek, M 2006 aport a l based on Open Archives Initiative Protocols and Apache Lucene\224, EGU2006. SRef-ID:1607-7962/gra/EGU06-A03716 8] SciFlo, website: https://sci flo.jpl.nasa.gov/SciFloWiki 9 ern a, web s ite: h ttp tav ern a.so u r cefo r g e.n et  Java API for XM L W e b Services \(JAX-W S https://jax-ws.dev.java.net  Di st ri but ed R e source M a nagem e nt Appl i cat i on DRMAA\aa.org  Sun Gri d Engi ne, websi t e   http://gridengine.sunsource.net  W 3 C R ecom m e ndat i on for XM L-bi nary Opt i m i zed Packaging \(XOP\te: http://www.w3.org/TR/xop10  W 3 C R ecom m e ndat i on for SOAP M e ssage Transmission Optimization Mechanism \(MTOM website: http://www.w3.org/TR/soap12-mtom  W 3 C R ecom m e ndat i on for R e source R e present a t i on SOAP Header Block, website http://www.w3.org/TR/soap12-rep 16] OPeNDAP, website: http://opendap.org  Yang, M Q., Lee, H. K., Gal l a gher, J. \(2008 223Accessing HDF5 data via OPeNDAP\224. 24th Conference on IIPS  ISO 8601 t h e Int e rnat i onal St andard for t h e representation of dates and times http://www.w3.org/TR/NOTE-datetime 19] ITT IDL, website http://www.ittvis.com/ProductServices/IDL.aspx 20] Python suds, website: h ttps://fedorahosted.org/suds  The gSOAP Tool ki t for SOAP W e b Servi ces and XM LBased Applications, website http://www.cs.fsu.edu/~engelen/soap.html  C hou, P.A., T. Lookabaugh, and R M Gray 1989 223Entropy-constrained vector quantization\224, IEEE Trans on Acoustics, Speech, and Signal Processing, 37, 31-42  M acQueen, Jam e s B 1967 e m e t hods for classification and analysis of multivariate observations\224 Proc. Fifth Berkeley Symp Mathematical Statistics and Probability, 1, 281-296  C over, Thom as. and Joy A. Thom as, \223El e m e nt s of Information Theory\224, Wiley, New York. 1991  B r averm a n, Am y 2002 om pressi ng m a ssi ve geophysical datasets using vector quantization\224, J Computational and Graphical Statistics, 11, 1, 44-62 26 Brav erm a n  A, E. Fetzer, A. Eld e rin g  S. Nittel an d K Leung \(2003\i-streaming quantization for remotesensing data\224, Journal of Computational and Graphical Statistics, 41, 759-780  Fetzer, E. J., B. H. Lam b rigtsen, A. Eldering, H. H Aumann, and M. T. Chahine, \223Biases in total precipitable water vapor climatologies from Atmospheric Infrared Sounder and Advanced Microwave Scanning Radiometer\224, J. Geophys. Res., 111, D09S16 doi:10.1029/2005JD006598. 2006 28 SciFlo Scien tific Dataflo w  site https://sciflo.jpl.nasa.gov  Gi ovanni websi t e   http://disc.sci.gsfc.nasa.gov techlab/giovanni/index.shtml  NASA Eart h Sci e nce Dat a Sy st em s W o rki ng Groups website http://esdswg.gsfc.nasa.gov/index.html   M i n, Di Yu, C h en, Gong, \223Augm ent i ng t h e OGC W e b Processing Service with Message-based Asynchronous Notification\224, IEEE International Geoscience & Remote Sensing Symposium. 2008 B IOGRAPHY  Hook Hua is a member of the High Capability Computing and Modeling Group at the Jet Propulsion Laboratory. He is the Principle Investigator of the service-oriented work presented in this paper, which is used to study long-term and global-scale atmospheric trends. He is also currently involved on the design and development of Web Services-based distributed workflows of heterogeneous models for Observing System Simulation Experiments OSSE\ to analyze instrument models. Hook was also the lead in the development of an ontology know ledge base and expert system with reasoning to represent the various processing and data aspects of Interferometric Synthetic Aperture Radar processing. Hook has also been involved with Web Services and dynamic language enhancements for the Satellite Orbit Analysis Program \(SOAP\ tool.  His other current work includes technology-portfolio assessment, human-robotic task planning & scheduling optimization, temporal resource scheduling, and analysis He developed the software frameworks used for constrained optimization utilizing graph search, binary integer programming, and genetic algorith ms. Hook received a B.S in Computer Science from the University of California, Los  


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



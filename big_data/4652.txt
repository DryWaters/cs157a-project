Abstract 
 Extracting relevant information in multilingual context from massive amounts of unstructured structured and semi-structured data is a challenging 
An Ontology-Based Approach for Cross-Lingual Information Retrieval Johanna Monti Dept. of Social and Human Sciences University of Sassari Sassari, Italy jmonti@uniss.it Mario Monteleone, Maria Pia di Buono, Federica Marano Dept. of Political, Social and Communication Sciences University of Salerno Fisciano \(Sa\ Italy mmonteleone, mdibuono, fmarano}@unisa.it 
Natural Language Processing and Big Data 
task. Various theories have been developed and applied to ease the access to multicultural and multilingual resources. This papers describes a methodology for the development of an ontology-based Cross-Language Information Retrieval CLIR application and shows how it is possible to achieve the translation of Natural Language \(NL\ queries in any language by means of a knowledge-driven approach which allows to semiautomatically map natural language to formal language simplifying and improving in this way the humancomputer interaction and communication. The outlined research activities are based on Lexicon-Grammar \(LG 
a method devised for natural language formalization automatic textual analysis and parsing Thanks to its main characteristics LG is independent from factors which are critical for other approaches, i.e. interaction type \(voice or keyboard-based\ length of sentences and propositions type of vocabulary used and restrictions due to usersêidiolects. The feasibility of our knowledgebased methodological framework, which allows mapping both data and metadata will be tested for CLIR by implementing a domain-specific early prototype system Keywords-Cross-Language Information Retrieval CLIR 
Lexicon-grammar; Ontology 
I I NTRODUCTION Cross-language Information Retrieval CLIR allows users to search and access information in multilingual document collections on the web in languages different from their own. Usually, information is searched by means of a query expressed in the userês mother tongue. This query is automatically translated in the desired foreign language and the results are translated back in the userês mother tongue This process is based on two different translation stages query translation and document translation The query translation concerns the translation in the desired foreign 
language of the query expressed in the userês mother tongue whereas the document translation is the back translation in the userês language of the relevant documents found by means of the translated query. For instance, an Italian user expresses a query in his/her native language and wishes to look for relevant information in English on the web: first of all the CLIR application translates the queries from Italian into English query translation and searches the relevant information on the web, subsequently it translates again all the information and the documents detected in this way into 
the user's mother tongue document translation i.e from English into Italian CLIR success clearly depends on the quality of translations therefore faulty translations cause serious problems in retrieving the relevant information In domain specific contexts indeed CLIR applications present significant shortcomings with reference to query translation since short queries do not  provide enough context for disambiguation in choosing proper translations of query words and also because they do not use domain-specific semantic constraints. Furthermore, in document translation translation inaccuracies are mainly due to lack of domain 
adaptation of the MT systems underlying the translation process This paper describes a knowledge-based methodology aimed at the development of an ontology-based CLIR system to overcome the current limitations of the state-of the-art applications in this field, with a focus on proper processing and translation of domain specific queries The methodology has been set up for the Italian/English language pair and in the field of Cultural Heritage \(CH\ but can be easily extended to other language pairs and different domains The remaining of this paper is organized as follows. The next section briefly explains the related work in 
the area of CLIR Section III describes the methodology adopted in our research Then section IV is devoted to system overview and section V describes the feasibility study presenting the Language Resources \(LR\ the semantic and translation model used in  the research work Finally conclusions and future work are reported in section VI II R ELATED W ORK There are several approaches to CLIR, either based on bilingual or multilingual Machine Readable Dictionaries 
SocialCom/PASSAT/BigData/EconCom/BioMedCom 2013 978-0-7695-5137-1/13 $26.00 © 2013 IEEE DOI 10.1109/SocialCom.2013.108 725 


MRD Machine  Translation MT parallel corpora and finally ontologies [1, 2, 3  MRD-based and MT-based CLIR are the most popular approaches but they present several shortcomings particularly in domain-specific  contexts because of the inaccurate processing and translation of multi-word units MWU a very frequent and productive linguistic phenomenon in languages for special purposes \(LSP MWUs are lexical elements composed of more than one word which have a particular structural and semantic internal cohesion, act as single lexical units and belong to different lexical categories    are examples of MWUs They are constructions half way between morphology and syntax since they have a very similar structure to phrases but present distribution and cohesion characteristics which are very close to words In domain-specific contexts the most frequent MWU typology is represented by terminological compound words such as  or  in the Cultural Heritage domain. Terminological compound words, with a limited or no variability of co-occurence among constituents often have unpredictable, non-literal translations and are therefore particularly difficult to process and translate Various techniques have been proposed to reduce the errors due to the presence of MWU introduced during query translation in CLIR applications. Among these techniques phrasal translation co-occurrence analysis and query expansion are the most popular ones Concerning phrasal translation, techniques are often used to identify multi-word concepts in the query and translate them as phrases [1, 4, 5  Co-occurrence statistics is used to identify the best translation\(s among all translation candidates using text collections in the target language as a language model assuming that correct translations occur more frequently than wrong ones As for query expansion techniques, [5, 11 assu m e th at additional terms that are related to the primary concepts in the query are likely to be relevan t and that phrases in query expansion via local context analysis and local feedback can be used to reduce the error associated with automatic dictionary translation Concerning MT-based CLIR in spite of the recent positive developments in Machine Translation the identification, interpretation and translation of MWUs still represent open challenges both from a theoretical and a practical point of view. There is an increasing attention to MWU processing in MT, as witnessed by the recent çMultiword Units in Machine Translation and Translation Technologyé workshop at MT Summit XIV MWU processing and translation in Statistical Machine Translation SMT the current leading approach in MT started being addressed only very recently and different solutions have been proposed so far, but basically they are considered either as a problem of automatically learning and integrating translations word alignment and finally Word Sense Disambiguation \(WSD Current approaches to MWU processing move towards hybrid approaches where phrase-based models are integrated with linguistic kn owledge and scholars are starting to use linguistic resources either hand-crafted dictionaries and grammars or data-driven ones, in order to identify and process MWUs as single units 12  pr ov i d es  a thor ough overview of the different approaches to MWU processing in MT Ontologies are also used in CLIR and are considered by several scholars a promising research area to improve the effectiveness of CLIR techniques particularly for technicaldomain queries us e ont o lo g i es  as inte rlingua i n  cr osslanguage information retrieval in the medical domain and show that the semantic anno tation outperforms machine translation of the queries, but the best results are achieved by combining a similarity thesaurus with the semantic codes 14  perform ontolog y based que r y exp a nsi on  of the m o st relevant terms exploiting the synonymy relation in WordNet III M ETHODOLOGY Our methodology is based on the Lexicon-Grammar LG theoretical and practical analytical framework LG theory was conceived by the French linguist Maurice Gross during the 60s 15 16 17  Un lik e Ch o m s ky  s transformational grammar and its various offspring [18, 19  LG assumes that linguistic formal descriptions should be based on the observation of the lexicon and the combinatory behaviors of its elements encompassing in this way both syntax and lexicon. It has also reached important results in the domain of automatic textual analysis and parsing, with the creation of software and lingware fully oriented toward NLP, such as NooJ 1 and former software packages used in the LG framework such as INTEX and UNITEX 2  Nowadays LG methodology is being adopted by a wide research community for several European French Italian Portuguese, Spanish; English, German, Norwegian; Polish Czech Russian Bulgarian Greek and non-European languages \(Arabic; Korean; Malagasy; Chinese; Thai This methodology is particularly suitable for CLIR applications due to the fact th at the quality of translation is guaranteed by a linguistic approach aimed at the development of a coherent and formalized linguistic knowledge basis This knowledge basis is composed of Linguistic Resources LRs mainly electronic dictionaries and grammars \(described in Section IV\ useful in achieving effective Information Retrieval IR Systems  a n d i n overcoming the weaknesses of the current statistical approaches used in MT by or where the lack of meaning context represents a serious obstacle to MWU disambiguation. LG linguistic framework is grounded in the analysis of  çsimple sentences 3 the minimal linguistic 1 See http://www.nooj4nlp.net/pages/nooj.html 2 More information on the website http://www-igm.univ-mlv.fr/~unitex 3 In LG, a simple sentence is a context formed by a unique predicative element \(a verb, but also a name or an adjective\ and all the necessary arguments selected by the predicate in order to obtain an acceptable and grammatical sentence For more specification on simple sentence definition \(Gross, 1968 
to look at, heavy water arsenic water as soon as possible; in order to  doric frieze spiral stem Google Translate Bing 
726 


002 002 
meaning contexts within which word combinatorial behaviors can be analyzed. The study of simple sentences is achieved by analyzing the so-called rules of co-occurrence and selection restriction i.e distributional and transformational rules based on predicate syntactic-semantic properties Also LG theory is prevalently based on the concept of Operator-Argument Grammar 21  th e refo re it highlights transformational rules active/passive positive/interrogative, etc.\ and mutual relationships between simple sentences as they have been observed by Zellig Harris 22 s tarting  fr om t he bl oo mfield ia n no ti on  of m o rph e m e and the method of commutation or equivalence between different morphemesê available lexi  Thanks to these above-mentioned research studies LG range of analysis concerns lexicon and especially the concept of MWU as meaning unit lexical unit and word group for which  LG identifies four different combinatorial behaviors   T h es e m e an ing units a r e collected and described inside LRs consisting of I morphologically and semantically tagged electronic dictionaries, \(ii\ local grammars in the form of Finite State Transducers/Automata \(FSTs/FSA\ used to parse texts,  and finally \(iii\ binary tables which describe syntactic-semantic properties of lexical entries \(refer to V.A and  V.B The quality of translation s is guaranteed from the beginning by the development of highly formalized LRs according to morphological syntactical and semantic criteria Using smart technologies for translation technologies often implies the deterioration of Translation Quality TQ In LG methodology instead we take advantage of well-formed LRs to to keep a high level of TQ since from the beginning, a supervised approach is carried out by expert linguists during the proper setting of resources Assessing the quality of resources before they are translated prevents from too many subsequent checks on translated resources even if an   evaluation of TQ results is always necessary According to LG a valid evaluation methodology should be based on a hybrid approach that encompasses both human and automatic evaluation The process is composed of two cycles. The first cycle can be outlined as follows \(i\ a query expressed in a Source Language \(SL\ is the input of the CLIR application, \(ii\ the MT system produces sample queries \(i.e. sample texts\ in the Target Language \(TL\ \(iii\ the resulting translated queries are examined by humans Linguists Translators Terminologists/Domain Experts to evaluate their quality The human judgements are based on common criteria of TQ  i.e adequacy and fluency  and are expressed using a Likert scale with scores 1-5 \(for instance using follow-ing judgements 1 Strongly disagree 2 Disagree 3 Neither agree nor disagree, 4. Agree, 5. Strongly agree\, \(iv\ only texts which obtained scores 4-5 become validated and supervisedé texts which represent the gold standard, \(v\ this gold standard is the training set for the Automatic Evaluation process, that can be carried out using METEOR 4 and GTM 5  that are the most suitable methods according to our opinion as well as other ones 6  During the second cycle human evaluation is skipped and the SL queries directly beco me the input for automatic evaluation It is necessary to periodically repeat the first cycle in order to enrich the training set and to increase the quality cycle IV S YSTEM O VERVIEW The proposed architecture aims to map data and metadata exploiting the morph-syntactic and semantic information stored inside both electronic  dictionaries and Finite State Automata/Finite State Transducers \(FSA/FSTs\ \(presented in V.B Furthermore, we use our application in order to define entities and to model relationships, mapping linguistic tags i.e. POS\ and structures \(i.e. sentences, MWUs\ to domain concepts Indeed, in CLIR systems the most frequent error is the assignment of wrong Parts Of Speech POS to lexical meaning units as stated in 25  the com p le xity of the grammatical structures and the quality of parsing are the main cause of the errors Our research framework could allow achievement of major improvements in IR and IE both in recall and precision The system is based on two workflows which are carried out simultaneously but independently. As described in Fig. 1 before the execution of a query against a knowledge base it is necessary to apply the Translation and the Transformation routines The first step performed is a linguistic pre-processing phase which formalizes i.e converts natural language strings into reusable linguistic resources During this first phase we also extract information from free-form user queries, and match this in formation with already available ontological domain conceptualizations The advantages in keeping separate transformation and translation routines are the development of an architecture with a central multilingual formalization of the lexicon, in which there is no specific target language but each language can be at the same time target and source language the development of extraction ontologies and SPARQL/SERQL adaptation systems which could represent a standard not only for our multilingual electronic dictionaries, but also for any lexical and/or language data-base for which translation is required With this dual-structure system it is easier to successfully achieve the question answering QA process 4 http://www.cs.cmu.edu/~alavie/METEOR  5 http://nlp.cs.nyu.edu/GTM 6 BLEU and NIST \(based only on precision measure\ F-Measure \(based also on recall 
A. LG Methodology to Assess the Translation Quality ex post 
727 


002 002 002 002 
since the answers are given explicitly in the target language chosen by the user and the translation process is separated from the matching with the RDF triples V F EASIBILITY S TUDY To test the feasibility of our architecture, we are carrying out a translation experiment from Italian into English, using all ontological and semantic constraints defined for the Italian model We have chosen the Archaeological domain to test the applicability of our approach This choice allows us to demonstrate that the modularity of our architecture may be applied to a domain which is variable by type and properties and is semantically interlinked with other domains In the next paragraphs we will present the LRs developed for our study, together with the a description of the semantic annotation and th e translation routines used in query translation An electronic dictionary is a lexical database homogeneously structured in which the morphologic and grammatical features gender number and inflection of lexical entries are formalized by means of distinctive and non-ambiguous alphanumeric tags 26  All electr onic dictionaries, built according to the LG descriptive method form the DELA 7 system, which is also used as a linguistic knowledge-base embedded in several NLP applications \(text mining, IR, QA systems among others\ and parsers. DELA electronic dictionaries are of two types simple word dictionaries which include semantically autonomous lexical units formed by 7 Dictionnaire lectronique of LADL Laboratoire d'Automatique Documentaire et Linguistique character sequences delimited by blanks such as and  compound word dictionaries, which include lexical units composed of two or more simple words with a non-compositional meaning, such as  and  Terminological entries as already stated the most common obstacle in CLIR applications, are lemmatized in compound word elect ronic dictionaries The following example represents an excerpt extracted from the Italian dictionary of Archaeological Artifacts 8 N+NPN+FLX=C45 DOM=RA1SUOARAL+ EN=crossbow arrow N+AN+FLX=EC3 N+NA+FLX=C556+DOM=RA1SUOIL EN=leafed arrow  N+AN+FLX=EC3 N + NPN + FLX=C12 DOM=RA1EDEAES + EN=frieze crown  N+AN+FLX=EC3 N+NA+FLX=C523 DOM=RA1EDEAES + EN=doric frieze  N+AN+FLX=EC3 N + NPN + FLX = C7 DOM=RA1EDEAES + EN=spiral stem  N+AN+FLX=EC3 For instance, the compound word  Doric frieze is marked with the domain tag DOM=RA1EDEAES which stands for Archaeological Artifacts Building Architectural Elements Structural Elements For each entry, a formal and morphological description is also given, which includes the internal structure of each compound. This means that in the compound word  the tag NAª indicates that the given compound is formed by a Noun, followed by an Adjective. At the same time, in the compound word the tag ´NPNª, indicates that the given compound is formed by a Noun followed by a Preposition followed by a Noun the inflectional class This means that the tag FLX=C523ª indicates the gender and the number of the compound   together with its plural form, i.e. it indicates that  is 8 Itês important to specify that our domain dictionaries, collected in the DELAC/DELACF system cover about 180 different semantic tags The most important dictionaries are those of Computer Science 54,000 entries ca Medicine 46,000 entries ca Law 21,000 entries\ and Engineering \(19,000 entries ca.\ Each dictionary has been created and verified under the supervision of domain experts. Subset tags are also previewed for those domains that include specific subsectors This is the case of Archaeological Artefacts dictionary 9,200 entries ca.\ , for which a generic tag RA1 is used, while more explicit tags are used for object type subject primary material method of manufacture, object description. In order to develop ItalianEnglish dictionary of Archaeological Artefacts we relied on the Thesauri and Guidelines of the Italian Central Institute for the Catalogue and Documentation ICCD available at http://www.iccd.beniculturali.it/index.php?it/240/vocabolari  Figure 1 System Workflow 
A Electronic Dictionaries home chair nursing home rocking chair freccia di balestra freccia foliata fregio con coronamento fregio dorico fusto a spirale fregio dorico fregio dorico  fregio con coronamento fregio dorico fregio dorico 
 
728 


 
002 002 002 
masculine singular does not have any feminine correspondent form and its plural form is  Each inflectional class is associated to a local grammar which produces  the inflected forms of the word according to the inflection class associated to it On the other hand local grammars formally describes syntactic features of natural languages and are used in NooJ 9 to parse texts. Such grammars are defined çlocalé because each one of them account for one and only one syntactic profile of a given predicate. This means that for instance we build a local grammar only to describe the syntactic features of the verb  Local grammars are built and developed in the form of FSA/FSTs  As for ontologies, the formal definition we rely upon is the one given by the International Council of Museums Conseil Interational des Musees ICOM  CIDOC Conceptual Reference Model \(CRM\ [29 CIDOC CRM is composed of two different hierarchies, one composed of 90 classes which includes subclasses and superclasses and another of 148 unique properties and subproperties The object-oriented semantic model and its terminology are compatible with the Re source Description Framework RDF\ Actually, this ontology was already available and is constantly developed At the same time our methodology shows that a given linguistic knowledge can be reused independently from the domain to which it pertains. Domain ontologies refer to mid and upper-level ones which tend pragmatically to be standardized Logically such process indirectly involves also low-level ontologies, and this allows the reuse of linguistic resource s regardless of the domain in which they were developed or to which they pertain LRs are used for analyzing corpora to retrieve recursive phrase structures, in which comb inatorial behaviours and cooccurrence between words identify properties, also denoting a relationship Furthermore electronic dictionaries also include all inflected verb forms allowing to process queries expressed also with passive and more generally nondeclarative sentences Consequently we use FSA variables for identifying ontological classes and properties for subject object and predicate within RDF graphs This matching of linguistic data to RDF triples and their translation into SPARQL/SERQL path expressions allows the use of specific meaning units to process natural language queries 9 NooJ is an NLP software environment which uses electronic dictionaries and local grammars we use automatically read and parse digitized texts. For more on NooJ, see www.nooj4nlp.net Figure 2 is a sample of an automaton showing an associated RDF graph for the following sentence subject  predicate  object According to our ap proach, electronic di ctionaries entries simple words and MWUs\ are the subject and the object of the RDF triple In Figure 3 we develop an FSA with a variable which applies to the sentence the following classes and property E19 indicates çPhysical Objecté class P56 stands for çBears Featureé property E26 indicates çPhysical Featureé class So, the FSA variables transform our sentence into Il Partenone E19  colonne doriche e ioniche \(E26 The role pairs  and  are trigged by the RDF predicate Besides in Fig. 3 we also indicate specific POS for the first noun phrase  DETerminer Noun\, the verb   V and the second noun phrase  Noun+Adjective+Conjuntion+Adjective By applying the automaton in Fig. 3 \(built using the high variability of lexical class and no t of the original form\ we can recognize all instances included in E19 and E26 classes the property of which is P56 In our model the Translation Routines are applied independently of the mapping process of the pivot language This allows us to preserve the semantic representation in both languages. Indeed, identifying semantics through FSA guarantees the detection of all data and metadata expressed in any different language Figure 4 illustrate a FST in which a translation process from Italian to English is performed combining information coming from dictionaries and grammars of analysis with lexical transfer This  translation FST recognizes and annotates the different linguistic elements of declarative sentences such as  etc., with their morphosyntactic and semantic information and performs automatic translations on the basis of an LG Italian-English bilingual dictionary For instance, if a grammar variable, say $E26 holds the value   the output E26$EN will Figure 3 Sample of the use of the FSA variabl es for identifying classes for subject, predicate and object Figure 2 Simple FSA with RDF Graph 
fregi dorici to give  B Semantic annotation Il Partenone presenta colonne doriche e ioniche bears feature Physical Object/name Physical Feature/type presenta Il Partenone presenta colonne doriche e ioniche C Query Translation Il Partenone presenta fregi dorici I templi romani hanno fusti a spirale fusti a spirale 
729 


 
produce the correct English tran slation çspiral stemsé, on the basis of the value associated to the EN feature in the bilingual entry N+AN+FLX=EC3 and  the morpho-syntactic analysis performed by the graph in Figure 4 which identifies and produces the plural form of the compound noun  VI C ONCLUSIONS  AND F UTURE W ORK The architecture described in the previous pages ensures both the coverage of large quantities of knowledge and the preservation of any deep semantic relations which may interlink different languages. Our future work aims therefore at further developing our system we will implement new Linguistic Resources in order to test the accuracy of crosslanguage information retrieval  Futhermore we will carry out a larger number of experiments in different domains on selected corpora N OTE Johanna Monti is author of sections I, II and V.C, Mario Monteleone is author of sections V.A and VI, Maria Pia di Buono is author of sections IV V and V.B and Federica Marano is author of section III and III.A R EFERENCES 1 L  Ballesteros    B  Cro f t Dict io n ary Met h ods  fo r Cro s s-L i n g u al Information Retrieval Proc of the 7th DEXA Conference on Database and Expert Systems Applications Zurich Switzerland September 1996, pp. 791-801  L  Ballesteros a n d B Croft  P hra s al tra nslation  and query expansi on techniques for crosslanguage information retrievalé, Proc. of the 20th annual international ACM SIGIR conference on Research and development in information retrieval, 1997 3 L  Bal l est ero s  B  C r oft  R es olv i n g  Am biguity for  C r o s s-lang u a ge Retrievalé, Proc. Of SIGIRê98 Melbourne, Australia, August 1998 pp. 64-71  L  Bl oom f i e l d  Lang uage Henry Holt  New Yor k  199 3  N  Croft s M Do err T   Gil l S  S t e a d  M S t iff ed s   D e f in iti on  of the CIDOC Conceptual Reference Model, Version 5.0é,  2008  M W Davi s an d W C Og de n  F ree reso u rces an d ad van ce d alignment for cross-language text retrievalé, Proc. of The Sixth Text Retrieval Conference \(TREC-6\ NIST, Gaithersbury, MD, 1997  G  D e  Bue ri i s A El i a  eds  Less i ci e l ett roni ci  e de s c ri z i on i lessicali, sintattiche, morfologiche ed ortograficheé, Plectica, Salerno 2008 8 J  G a o  J  N i e  E X u n  J   Z h a n g M  Z h o u  C H u a n g  I m p r o v i n g Query Translation for Cross-Language Information Retrieval using Statistical Models Proc of the 24th annual international ACM SIGIR conference on Research and development in information retrieval. ACM, 2001  M G r os s Gra m m a i re transf or m ationn ell e  du f r anÁai s     I  Syntaxe du verbeé, Larousse, Paris, 1968  M Gross MÈtho d e s en syntaxe rÈgime des constructions complÈtivesé, Hermann, Paris, 1975 11 M Gr os s  L a co nstru ct io n de d i cti onn air es le ctr on iq u es  Ann ales des TÈlÈcommunications vol 44 n 1-2 4-19 CENT Issy-lesMoulineaux/Lannion, 1989 1 Z  S Harr is C o-o ccurrence and transform at ion in  l i n g u i s t i c structureé, Language 33, 1957, pp. 293-340 1 Z  S Harris Tr an s form ati ons  i n Lin g u i stic Stru cture  Proc o f t h e American Philosophical Society 108:5, 1982, pp. 418-422  Z  S Harris A Gra m m a r of  English on Ma t h e m atica l  Principles John Wiley and Sons, New York, USA,  1982  D  A Hul l  G Grefe n s t e t t e   Q uerying  ac ros s l ang uages  a dictionary-based approach to multilingual information retrieval Proc of the 19th annual international ACM SIGIR conference on Research and development in information retrieval,  1996, pp. 49-57  P K n ot h  T Coll i n s E Sklavo uno uy Z Zdrahal Facilitating crosslanguage retrieval and machine translation by multilingual domain ontologiesé, 2010 1 A  Maed a  F  Sad at et a l     Qu e r y Term Di s a m b iguation fo r  W e b Cross-Language Information Retrieval using a Search Engine in Proc of the Fifth Intêl Workshop on Info Retrieval with Asian Languages, Hong Kong, China, 2000, pp. 173-179 1 F. Mar a no E x pl o r i n g F o r m al Model s o f  L i ng u i sti c Data S t r uctur ing Enhanced Solutions for Knowledge Management Systems Based on NLP Applications 
fusto a spirale, N + NPN + FLX = C7 OM=RA1  EN=spiral stem  fusto a spirale 
PhD Dissertation, University of Salerno Italy 2012 Figure 4 Sample of the use of the translation FSA with variables for identifying classes for subject, predicate and object 
730 


  
1 M Monte leo ne Lessicogra f ia  e d i zio n ar i e l e ttronici Dagli us i linguistici alle basi di dati lessicalié, Fiorentino & New Technology Napoli, 2002  J  Monti  M ulti-word uni t pr ocessing in Machine  Tra n s l a t i o n developing and using language resources for multi-word unit processing in Machine Translationé, PhD dissertation, University of Salerno, Italy, 2013 21 D  W  Oard  Multilingual Information Access in Encyclopedia of Library and Information Sciences, 3rd Ed., edited by Marcia J. Bates Editor, and Mary Niles Maack, Associate Editor, Taylor & Francis 2009 2 A  P i r k o l a   T h e Effect s of Query Structire and Dictionary Setupsé, in Dictionary-Based Cross-language Information Retrieval. In W. Croft et al 21st Annual ACM SIGIR Conference on Research and Development in Information Retrieval SIGIR 2008 Melbourne Australia, August 24-28, 1998, pp.55-63  F Sadat A   Maeda et  al  A  Com b i ned  S t at is t i c a l Query T e rm Disambiguation in Cross-language Information Retrieval Proc. of the 13th Intêl Workshop on Database and Expert Systems Applications Aix-en-Provence France September 2002 pp 251255 2 X  Saral egi   M L de La calle Dictio nar y  an d  Mono lingual Corpus-based Query Translation for Basque-English CLIRé, 2010  M Sil b er z te i n D ictionnaires lectroniques et ana l ys e a u tom a ti q ue de textesé, Masson, Paris, 1993 2 I Szp ekto r I Daga n  A  L a vie D S h a c h a m  S W i ntner C ro ss Lingual and Semantic Retrieval for Cultural Heritage Appreciation Proc. of the ACL Workshop on Language Technology for Cultural Heritage Data, Prague, Czech Republic, 2007 2 S  Vie t r i  A Elia E  D'Ag o sti n o   Lexicon-gram m a r Electro n ic Dictionaries and Local Grammars in Italian, in Laporte, E., LeclËre C Piot M Silberztein M eds Syntaxe Lexique et LexiqueGrammaire Volume dÈdi  Maurice Gross Lingvisticae Investigationes Supplementa 24 John Benjamins Amsterdam/Philadelphia, 2004  M  Volk S  V int ar  a n d  P Bui t elaar  Ont ol o g i e s in  cross-l angua ge information retrieval Proc of WOW2003 Workshop Ontologiebasiertes Wissensmanagement\ Luzern, Switzerland, 2003  P Vosse n  A Sor o a  B Z a pirain G  Ri gau   C rossl in g u al  event mining using wordnet as a shared knowledge interfaceé, Proc. of the 6th Global Wordnet Conference, C. Fellbaum, P. Vossen \(Eds.\ Publ Tribun EU, Brno, Matsue, Japan, January 9-13,  2012, pp.382-390 3 M  Yapom o G Corp a s  a n d R M i t k o v   CLIR-an d  ont ology b ase d approach for bilingual extraction of comparable documentsé, The 5th Workshop on Building and Using Comparable Corpora,  2012 
731 


DATA AND APPLICATIONS masFlightís Data and Applications Platform Data Input Feeds Airport & Gate Status Multisource, real-time feeds Current Weather Global hourly conditions Forecast Weather Standard and severe forecasts Flight Schedules Whatís planned to operate Reference and Static Data Geospatial, airline, airport info Government Economic Data Revenue and audited data Secure U.S./Canada Radar Authorized direct access Other Airspace Data Satellite and transponder info In-House Servers For private govít feeds Cloud Warehouse Linked Information 60TB structured data Robots and Java Applications Secure External Network Automated collection 60TB s t ruc t ure d  OUR CLOUD-BASED DATA WAREHOUSE OUR CUSTOMER APPLICATIONS Web Application masflight.com Cloud Managed Database Hosting Dashboards Web Services HTML 5 / Ruby Analyst focused Customizable Fast deployment SaaS revenue model REST web services Feed internal systems Custom dashboards Flexible interfaces Virtual tables Updated in real time Bypass constraints Ultimate customization 


masFlight Platform MASFLIGHT PLATFORM Multisource, integrated airline operations data Our platform shows where, when and why problems occur  Examine diversions cancellations, delays and determine root causes  Deep-dive into airport gates, taxi times, and runway patterns  Analyze air space usage and air traffic management Planned Flight Schedules Multisource Flight Status Global Weather Data and Maps Airline Ops Data U.S. Radar Data Airline Fleet Information Airport Gate Terminal Data Airport Runway Data Key Partners and Suppliers 


Origin weather Origin information Operating airline Scheduled times Departure gate/time Taxi-out/takeoff times Arrival weather Destination information Landing/taxi times Arrival gate/time Diversion data Aircraft information Flight plan filed Actual path flown Congestion Weather diversions En-route times and fixes  KIAD V268 SWANN 1502Z 1550Z 1620Z END TO END CAPABILITY Big-Data Analytics Facilitates End-to-End Analysis A full picture of each flight is critical for analyzing operations Query flights from planned schedule through post-operation recovery Up to 500 data points per flight Other sources only offer limited, disaggregated and unformatted regional data 


A Global Solution COVERAGE North and South America EMEA and Asia White lines are flights in the masFlight platform from February 8, 2013 Yellow pins are weather stations feeding hour ly data to our platform Maps from Google Earth / masFlight masFlight tracks flights, airports and weather around the world  Global daily flight information capture  82,000 flights  350 airlines  1700 airports  Integrated weather data for 6,000 stations  Match weather to delays  Validate block forecasts at granular level  Add weather analytics to IRROPS review and scenario planning 


Example 1: Proposed FAA Tower Closures masFlight used big-data to link airport operations across three large data sets  Current and historical airline schedules  Raw Aircraft Situation Display to Industry \(ASDI\AA  Enhanced Traffic Management System Counts \(ETMS\Airport operations counts by type \(commercial, freight, etc TOWER CLOSINGS Dots indicate closures; Red dots have scheduled service Based on scheduled service March 1 7, 20 13; scheduled service includes scheduled charter flights, cargo flig hts, and passenger flights Dots  indicate  closures  Red  dots  have  scheduled  service Bas ed  o n sc h edu l ed  se rvi ce  M a r c h 1  7, 2013; scheduled se rvi ce includ es scheduled c harter fli g hts car g o fli g hts a nd passen g er fli g hts Findings: Proposed Tower Closings  From schedules database: 55 airports with scheduled passenger airline service  14 EAS Airports  From ASDI & ETMS: 10,600 weekly flights on a flight plan \(ex. VFR and local traffic  6,500 Part 91/125 weekly flights  4,100 Part 135/121 weekly flights  


Example 1: Big-Data Analytics Applied to ASDI and ETMS To Analyze Operations TOWER CLOSINGS  26 44 24 23 11 10 6 2 1 2 Up to 5 5-10 10-15 15-20 20-25 25-30 30-35 35-40 40-45 45 Count of Airports Average Number of Daily Operations with a Flight Plan Filed Distribution of Airports By Average Number of ìDailyî Impacted Flights Airports Affected by Tower Closures Source: ASDI radar data ñ Part 91 151 flying and Part 135/121 flying March 1-7, 2013; masFlight analysis Note: Average ìdailyì operations based on 5-day week 


Example 2: Aviation Safety Causal Factor For example, consider the following ASRS report \(ACN 1031837 Departing IAH in a 737-800 at about 17,000 FT, 11 m iles behind a 737-900 on the Junction departure over CUZZZ Intersection. Smooth air with wind on the nose bearing 275 degrees at 18 KTS We were suddenly in moderate chop which lasted 4 or 5 seconds then stopped and then resumed for another 4 or 5 seconds with a significant amount of ri ght rollingÖ I selected a max rate climb mode in the FMC in order to climb above the wake and flight path of the leading -900 We asked ATC for the type ahead of us and reported the wake encounter. The 900 was about 3,300 FT higher than we were  Synopsis  B737-800 First Officer reported wake encounter from preceding B737-900 with resultant roll and moderate chop What causal factors can be identified from this narrative that could be applied to future predictive applications CAUSAL FACTORS Data-mining algorithms can mine the text of safety reports to obtain specific data that can be used to analyze causal factors  


Example 2: Identifying Causal Factors CAUSAL FACTORS  Indicators ñ Data Element Methods ñ Identifying Context and Causes  Time of day  Date range \(month day  Aircraft type  Fix or coordinates  Originating airport  Destination airport  Weather notes We pinpoint the sequencing of flights on the IAH Junction Seven departure \(at CUZZZ\the specified wind conditions to find cases wher e a B737-900 at 20,000 feet precedes by 11 miles a B737-800 at 17,000 feet  Search related data sets including ASDI flight tracks, local traffic and congestion  Weather conditions for alter native causes \(winds aloft shear and convecti ve activity  Airline specific informati on \(repeated occurrence of event in aircraft type Big data gives us visibility into contextual factors even if specific data points are missing such as a specific date or route Big-data analytics gives us insight into unreported factors as well 


Example 3: Correlating Utilization and Delays  60 65 70 75 80 85 90 95 100 7 9 11 13 ONTIME DEPARTURE PERFORMANCE HOURS OF DAILY UTILIZATION 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Narrowbodies By Day of Week 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Widebodies by Day of Week Daily Utilization vs. On-time Departures January 2013 System Operations Correlation Coefficient -0.53 Includes AA, AC, AS B6 F9, FL, NK, UA, US VX and WN SOURCE masFlight \(masflight.com COMPARING OTP AND UTILIZATION 


 6.2 6.0 5.8 5.8 5.2 4.9 LGB JFK BOS MCO DCA FLL JetBlue Focus Average Daily Deps per Gate Used UTILIZATION BY HUB Example 4: Daily Utilization of Gates, by Hub Big-data analysis of different carriers daily departures per gate used SOURCE masFlight \(masflight.com June 1 through August 31, 2012 Gates with minimum 1x daily use 7.7 7.4 7.2 6.2 6.1 5.8 3.8 3.6 ORD LAX SFO EWR DEN IAH IAD CLE United Airlines Hubs Average Daily Deps per Gate Used 7.8 6.4 5.5 5.4 5.3 4.4 4.3 4.0 SEA SAN PDX ANC SFO GEG LAX SJC Alaska Airlines Hubs Average Daily Deps per Gate Used 7.2 6.9 6.8 6.4 5.0 2.7 ORD DFW LAX LGA MIA JFK American Hubs Average Daily Deps per Gate Used 7.2 6.9 6.6 4.9 4.2 CLT DCA PHL PHX BOS US Airways Hubs Average Daily Deps per Gate Used 6.6 5.9 5.5 4.7 MCO BWI ATL MKE AirTran Hubs Average Daily Deps per Gate Used ne pe 


Conclusions for Big Data in Aviation  Big-data transforms operational and commercial problems that were practically unsolvable using discrete data and on-premises hardware  Big data offers new insight into existing data by centralizing data acquisition and consolidation in the cloud and mining data sets efficiently  There is a rich portfolio of information that can feed aviation data analytics  Flight position, schedules, airport/gate, weather and government data sets offer incredible insight into the underlying causes of aviation inefficiency  Excessive size of each set forces analysts to consider cloud based architectures to store, link and mine the underlying information  When structured, validated and linked these data sources become significantly more compelling for applied research than they are individually  Todayís cloud based technologies offer a solution CONCLUSIONS 


Conclusions:  Our Approach  masFlightís data warehouse and analysis methods provide a valuable example for others attempting to solve cloud based analytics of aviation data sets  masFlightís hybrid architecture, consolidating secure data feeds in on-premises server installations and feeding structured data into the cloud for distribution, addresses the unique format, security and scale requirements of the industry  masFlightís method is well suited for airline performance review competitive benchmarking, airport operations and schedule design and has demonstrated value in addressing real-world problems in airline and airport operations as well as government applications CONCLUSIONS 






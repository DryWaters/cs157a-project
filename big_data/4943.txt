New Replica Selection Technique for Binding  Replica Sites  in  Data Gri d s   Rafah M Almuttair i   Rajeev Wankar   Atul N e gi   Raghavendra Rao Chillarig e  Department of Computer and Information Science s   University of Hyderabad   Hyderabad   500046   A.P   Indi a   r afahmohammed  gmail.co m    wankarcs, atulcs, crrsm}@uohyd.ernet.i n    Mahdi S. Alma h n a  Department of Computer science &Engineerin g  Acharya Nagarjuna Universit y  Nagarjuna Naga r 522524   A.P  Indi a  mehdisale h gmail.co m     Abstrac t    
           
         Keyword s Data Gri d   Replica  Selection Technique  Hungarian algorithm; association rules    I I 
NT R ODUC T I O N   Grid C omputin g  emerges from the need to  integrate collection of distributed comp u ting resources to  offer performance unattainable by any single machin e   1 5    Data  Gri d  technology facilitates data sharing across many  organizations in different geographical location s  as it is  shown in  Figure 1   Data  R eplicatio n  is  a  servic e  to move  and c ache data close to users  It  is a solution for many gri d based applications such as climatic data analysis and  physics  g rid  n etwork [6 w hi c h b o t h r e q ui r e r e s p o ns i ve  na vi ga t i o n  and manipulation of larg e scale datasets. Moreover, if  multiple replicas exist   Replica Management Service \(RMS  is required to discove r  available replicas and select the best  
replica that matches the user's requirements  To collec t  all  logical names of  replicas and their locations  Replica  Location Service \(RLS   is use d   T o serve  th e  user's request  with bes t  o n e   replic a  selection strateg y  is use d   1 7      Since there  i s  more than one replica of the  requested file at th e  ru n  jo b  time, the best replica selection  becomes an important decision because it  affects the  efficiency of executi o n   8    Previous selection strategies  like random and round robin have  limitation s  as their  selection does not depend upon the characteristics of  replicas or their network links status   1 8     To cover those limitations, here we propose a new replica 
 selec t ion technique that uses association rules of  data  mining approach. We use  Apriori  algorithm for this purpose  which combines different associated sites, having  uncongested links at the time of the file\(s\ transfer    The rest of the paper is organized as fo l lows  Section I I  summarize s  the related work  Section II I  contains  preliminary concepts of association rules  Section I V  explains the general aspect of the data grid architecture. Our  proposed technique is explained in  Section  V   Simulation  input is shown  in  Section V I  and the results and their  interpretation are presented in  Section VI I   then we conclude  in  Section VII I                   I I 
  R ELATED WOR K      Replica Selection Problem \(RSP   has been  investigated by many researchers who only consider e d  response time as a criterion for the selection process   F  Corin a  and  M. Mesaa c     i n  2003   and  Cerye n  and  M  Kevi n  2 3   in 2005 used different algorithms such as greedy  random, partitioned and weight algorithms in the selection  engine   AB C  Replica 3  
 Site 2  Site n ABC Replica 2   ABC Replica n   Logical File Na m e AB C  Figure1  Replicas of ABC fil e  
2010 1st International Conference on Energy, Power and Control \(EPC-IQ Basrah, Iraq, November 30 - December 2, 2010 
187 


 The first re p lica selection approaches proposed to bind a  client to the nearest replica, with respect to some static  metric such as the g eographical distance in miles  2  9  a nd  the topologi c al distance in number of hops [2 6   H o w e v e r  as sev e ral experimental results  27,2 8   s h o w   th e  s ta ti c  metrics are not good predictors for the expected response  time of client requests. The main drawback of both  geographical and topological network metrics is that they  ignore the network pat h 222 s dynamic conditions    In 2001  R. Kavit h a  and  I Foste r  3   u s e d tr a d itio n a l  replica catalog based model, where for each new request  Replica Location Service is queried to get the addresses of  replica's sites and then probe the network link using Hop  count method to select the best replica T his way of  selection is not efficient because the number of hops does  not reflect the actual network condition  such a s  Network  Bandwidth and link\222s latency    During 200 1 2003  Sudharsha n  et al  4,5 8  c o n tr ib u te d  many research results. In their work the y  used the history of  previous file transfer information to predict the best site  ho l d ing  a  copy  of th e  requested file. When a file transfer has  been made between two sites, the file size, the available  network bandwidth   and transfer time are saved, thus  i t can  be used later for training and testing the regression model to  predict the actual transfer time. In their work they showed  that data from various sources can help in better predictions  than data from one source. They achieve a better accuracy in  fil e  transfer throughput prediction by using data from all of  these three sources: data streams of network, file size, and  past grid transfer information    In 2005  Rashedu r  et al  1   exploited a replica selection  technique with the  K Nearest Neighbor \(KNN   rule used to  select the best replica from the information gathered locally  The  KN N  rule selects the best replica for a file by  considering previous file transfer logs indicating the history  of the file and those similar. This technique has a drawback  as t hey mentioned in their paper: the misclassification will  increase in case of the large file transfer and will cost more  than a couple of small file transfer misclassifications  Especially in the Gaussian random access pattern the  accuracy is the lowest. A n other drawback in  KN N  is that  one needs to save all previous instances \(file requests\ to use  them to select the best replica site, which means it will take  some time to search in the large history of data base and the  result might or might not be correct      In 2008  Rashedu r  et al 1 7  pr op os e d a  Neural Networ k  predictive technique \(NN based\ to estimate the transfer  time between sites. The predicted transfer time can be used  as an estimate to select the best replica site among different  sites. Simulati o n results demonstrate that  Neural Networ k  predictive technique works more accurately than the mult i regression model, which was used before  N N  4,8 5   However  N N  technique does not always give the right  decision because the copy of the file may become no  longer  available \(this is a common occurrence in grid\ in the  predicted site, so in this case the  Traditional Mode l  has to be  used   In 2009  A. Jarada t  et al 1 8  pr o pos e d a n e w a ppr oa c h t h a t  utilizes availability, security and time as selection criteria  between different replicas, by adopting k means clustering  algorithm concepts to create a balanced \(best\ solution. The  best site does not mean the site with shortest time of file  transfer, but the site which has three accepted values  security level, ava i lability and time of file transfer    In our previous work we first proposed the association rule  mining approach to RSP   H e r e   i n  t h i s pa pe r  w e  compare our strategy with random selection strategy   We  are introducing a usage of the other simulation s oftware  called  XLMine r   t o g e t a s s oc i a t i on r u l e s  us i ng  A pr i or i  Algorithm  This study improves the replica selection  decision to  achieve higher efficiency and to ensure the  satisfaction of the grid users, providing them with their  required replicas in a  timely manner    II I P RELIMINARY  C ONCEPT S     In this section we declare the preliminary concepts  of  Data Mining D M   A  Association rules: association rules are mostly used in  mining transaction data. Crucial terms in association  rules terminology are   I te m  in  D M  terminology corresponds to attribut e value pair   T ransactio n  a set of items; corresponds to  example   A S e t  data set\ of transactions containing more  different items   For the transactions it is typical that they differ in the  number of items. Therefore   some transformations \(standard  form\ as it is shown in  Table I   might be necessary to be  able to data mine transaction data with one of the data  mining tools   Each transaction in the set gives us information about which  items c o occur in the transa c tion. Using this data one can  create a c o occurrence table that tells the number of times  that any pair \(or itemset\ occurs together in the set of  transactions. From the c o occurrence table we can easily  establish simple rules like   Rule 1   Item 1  comes  together with  Item 2  in  10   of all  transactions   In this rule, the  10   i s a measure of the number of c o occurrence s  of these two items in the set of transactions, and  is called a  support  of the rule. If the frequency of  Item 1  occurring in the set of tran s actions is  10  and that of  Item  2   20  then the ratio of the number of transactions that  support the rule \(10%\ to the number of transactions that  support the  Anteceden t  part of the rule gives the  confidenc e  of the rule. In this case the  confidenc e  is   Rule 1   Item 2  comes together with  Item 1  in  10   of all  transactions   
188 


 Confidence of this rule is   c\(Rule 1\=10/20=0 5  So, the confidence of the  rule 1  is  0 5  and is equivalent to  saying that when  Item 2  occurs in the transaction, there is a  50   chance th a t also  Item 1  will occur in the transaction  The most confident rules seem to be the best ones. But the  problem arises, for example, if  Item 2  occurs more  frequently in the transactions \(let's say in  60   of  transactions\. In that case the rule might have l ower  confidence than the random guess! This suggests usin g  another measure called  improvement   That measure tells  how much better a rule is at predicting the  Consequen t  than  just assuming the result  Improvemen t  is given by formula      1             Consequen t p Anteceden t p Consequen t Anteceden t p Rul e I I\(Rule 1\=0.1/\(0.1*0.2 5    When improvement is greater than 1 the rule is better than  the random chance. When it is less than 1, it is worse. In our  case  Rule  1  is fiv e  times better than the random guess   I V D ATA  G RID  A RCHITECTURE    In this section a D ata Grid architecture  PRAGM A  see  Figure 2 is explained with functionality of each  component                      A   Replica Management System \(RMS     As we see in the  Figure 3 the main component of the  Data Grid is the  Replica Management System \(RMS   i t acts  as a logical single entry point to the system and interacts  with the other components of the systems as follows    B  Replica Location Service \(RLS         Replica Location Service \(RLS   is the service that  keeps track of where replicas exist on p h ysical storage  systems. It is responsible for maintaining a catalog of files  registered by the users or services when the files are created  Later, users or services query  RL S  servers to find these  replicas    Before explaining  RL S  in details, we need to d e fine a few  terms, such as   A  Logical file Name \(LN   is a unique identifier for  the contents of a file   A  Physical file Name \(PN   is the location of a copy  of the file on a storage system    These terms are illustrated in  Figure 1 The job of  RL S  is to  ma i ntain associations or mappings between logical file  names and one or more physical file names of replicas. A  user can provide a logical file name to an  RL S  server and  ask for all the registered physical file names of replicas. The  user can also query an  R L S  server to find the logical file  name associated with a particular physical file location. In  addition  RL S  allows users to associate attributes or  descriptive information \(such as size or checksum\ with  logical or physical file names that are registered  in the  catalog. Users can also query  RLS  based on these attributes   8              C  Replica Optimization Service \(ROS     The Optimization component is used to minimize file  access times by pointing access requests to appropriate  replicas a n d replicating frequently used files based on  gathered access statistics. The goal of the optimization  service is to select the  Best Replica Site \(BRS   with respect  to  a  network and storage access latencies  1 9   RO S  gathers  the  information from the networ k  monitoring s e rvice like  Network Weather Servic e  NWS   1 1  o r  Iperf Servic e  10   and the storage element service about the respective data  access latencies    D   Data Transfer Service \(DTS       After physical addresses are known  RM S  asks  DT S  to  transfer the requested file sets using a hig h  performance  secur e  and reliable data transfer protocol like  GridFT P  13  and  UD T  12  A f t er g et t i n g a s i m p l e an d cl ear p i ct u r e ab o u t  the infrastructure of the data grid, next section explains  P N  Figur e 3 Functionality of Replica Management Syste m  NH F   Probing Network Services  Ex: \(NWS/Iperf   Dat a  L N   Computing Sit e   B R S   Replica  Optimi z ation  Servic e  Ex, ES T  Replica Management Syste m  RMS    Data Transfer  Servic e  Ex\(GridFTP U DT    Replica  Location  Servic e  RLS   Figur e  2 PRAGMA Grid, 28 institutions in 17 region s   BR S  
189 


 where our mode l  resides and how much it changes the data  grid performance    V E FFICIENT  R EPLICA  S ET  S ELECTION  T ECHNIQU E      This section clarifies our approach  its perfo r mance  its difference from the othe r  mode l s  and what are the helpful  advantages for us to cover the l i mit a tions of the traditional  and random selection metho d s    Let us explain the main  steps of our strategy   Single Trip Time STT   ST T  is  a  time taken by the small packet t o  travel  from Replica\222s Site \(RS\ to Computing S it e  CS    The  ST T  delays include pack e t transmission delays  the transmission rate out of each router and out of  the replica site\, packe t propagation delays \(the  propagation on each link\, packe t queuing delays  in intermediate routers and switches, and packe t processing delays \(the processin g  delay at each  router and at the replica site\ for a single trip  starting from replica site to  the  computing site. It  means that  ST T  is the su m mation of all these  delays. We use Standard deviation of  ST T  as a  factor to check the stabilit y  or instability  o f  the  network links [14  B ef o r e s el ect i o n p r o ces s  s t ar t s   the compu t ing site receives  periodica l  ST T s of all  replicas\222 sites and stores the most recent in a log  file called  Network History  Fil e  NH F   as it is  shown i n  Table I   Standardization Data   Using a  mapping function we can convert  STT  values to logical values and safe the result in  Logical History File \(LHF   as it is shown in  Table  II   Association Rules  Discover y   One of  popula r  association rules algorithms of data  mining approach i s  an A prior i  algo r ith m   Here, it i s  used fo r  discovering associated replica site s  to  work concurrently and minimize total time of  transferring the requested file\(s\ as it is shown in  Figure  4  16   Evaluation Rules   Evaluation process is needed to check the  validity  of  the  association rule s                           E fficient  S et  algorithm   In this section, we declare the steps of our proposed  algorithm to get the best set of replica sites working  concurrently with  the  minimum cost of getting the requested  files    Step I Receive a job from  User  Application   Step I I Contact  RL S  to get  all replic a  nam e s   Step II I Contact  NWS/ Ipre f   to get a  N H F    Rows = STT s   Column s  Replica Site s  Step I V  Conver t  N etwork  H istory  F ile  NHF   to  Logical  History Fil e  LHF   that contains logical  values   L V    app l yin g  the following   mapping  function for  each column    a  Calculate the M ea n    1 0    1     l wher e l i l i k j k ST T j i MST T  b  C alculate the Standard deviation   l i l i K j i MST T j ST T j STDEV i  1  2            c  10 0     j i MST T j i STDE V j i Q Fin d   d  replica s numbe r M wher e M M j j i Q AV i Fin d  1   e  1 0    L V otherwis e L V the n j i Q AV i I F Compar e  Step V  Apply  an  Association Rules  T echniqu e   A T   such  as   Aprior i  algorith m  2 1    Call  A T   L H F  c  s  A R        Input          LH F   Logical values of  Network History  Fil e           c Minimum confidence value          s Minimum su p port value       Outpu t        AR:  Association Rule s   Step V I  Measure rule's correlation using  an  Improvement    equation               Consequen t p Anteceden t p Consequen t Anteceden t p Rul e I    If   \(I <1   this indicate s  negative correlation     Otherwise i t  is p o sitive correlatio n       Step VI I  Send p hysical names of  the  highest correlation  rule sites to the transport service  such as   GridFTP  UD T   in order  to  ge t  the requested files      S 1  S 2  S 0  S 3  S 4  S 5  F 2  F 4  F 3  F 5  F 1  Figur e  4 Multiple sites concurrently send different files    
190 


 V I S IMULATION INPUT S    In our simulation, we  suppos e  that  all replicas have  the same ch a racteristics, such as number of jobs to be run  file processing time, delays between each job submission  maximum queue size in each computing element, size and  number of requested files and speed of input/output storage  operation s  to see the effect of ne t work resources onl y We  tested and compared the two selection strategies with our  strategy, traditional and random models                                                     In traditional selection method, the best replica is  the one which has the lea s t number of hops \(routers\, the  highest bandwidth or the minimum round trip time to reach  the computing site. In random method replica manager  selects randomly one of the available replicas to serve user's  request. Figure 4, shows the flowchart of  ES T  ste p s    A  Get data grid job: in our simulation we assume that  there is a job  J with four fil e s  required for  analyzing   B  By contacting  RLS  all   Logical and Pysica l  names  of replicas are collected   C  Getting Single Trip Time STT  Being a node of  PRAGM A  Data Grid  7    w e co n s t r u ct  NH F  using  Ipre f  service of  PRAGM A  infrastructure. We  contact data grid nodes and get the  STT s  for  different periods of time and save  STT s  values in a  file called  NHF.xl s  as it is shown in  Table I   Therefore, our grid configuration file re f lects the  real network nodes and links of the  PRAGMA Gri d  7   D  Convert  STT s  v alues to logical values using a  mapping function   E  Applyin g  Association Rule s   To apply  an  A prior i  algorithm on logical values of   STT Tabl e   Table I I  we use  MLMine r  softwar e     The steps which  we followed are    1  Use a spreadsheet software to open   NH F x l s  fil e   2  From the  XLMine r  menu, select  Ad d In s  menu then  Affinit y  after that chose  Association rule s The  Association Rules dialog box appear s  as it is shown  in  Figur e  6  the n  sele c ts  the  input data format a s  Data in binary matrix format     3  Enter all input data in the  Association Rule s  box  such a s  minimum confidence and support a n d  make the selections  o f  the  binary data of  ST T  an d  click  Finish button. The result will be shown as in  Figure  7    6 0  21 3  6 5  20 2  30 3  20 5  30 5  20 2  30 0  21 2  31 3  21 2  31 0  20 2  30 7  T ABLE  I   T RANSACTIO N S  T ABL E   ST T S VALUE S  Y  N  Is  NH F  availab l e   Y  Figur e  5   F lowcha r t of ESM    Apply  A priori  algorith m  t o  get  the  A R  Compute  Improvement of  Rules  I\(Rule   Convert  NH F  t o  LH F  Get recen t  NH F  from Ipre f  Get the first Job  from job queu e  Get the physical  name s  of  replicas\222 sites  from  RL S  Y  N  Similar to  pre. job  s  replicas    I\(Rule  0  Use  a rule to get  associate d  site s  Get the next Job  from job queu e  
191 


                                                               0  1  0  1  0  1  0  1  0  1  0  1  0  1  0  1  1  1  0  0  0  1  0  1  1  1  0  0  0  1  0  1  0  1  1  1  0  1  0  1  0  1  1  1  0  1  0  1  0  1  1  1  0  1  0  1  0  1  1  1  0  1  0  1  0  1  1  1  0  1  0  1  0  1  1  1  1  1  0  1  0  1  1  1  1  1  0  1  0  1  1  1  1  1  0  1  0  1  1  1  1  1  0  1  0  1  1  1  1  1  0  1  0  1  1  1  1  1  0  1  0  1  1  1  1  1  0  1  Figure  7 XLMiner  menue of  Association Rules    Improv   Figure  7   Apriori  Associa t ion Rules    T ABLE  II    L OGICAL VALUE S   S TANDARD  F OR M  Figure  6   Association Rules   window  in XLMiner softwar e  
192 


 F  To check the validity of association rules  E quatio n  1  is use d  as  it is done i n  th e  last column of  Figur e  7   G  Select one  of th e  rules which have Improvement  value more than   1     H  In case if there is another job asking to get the files  and the s e files are available in the same sites then  choose another rule to serve the new request  Otherwise  apply  Aprior i  algorithm for recent STTs  of  new replicas sites    VI I   I NTERPRETING THE  R ESULT S    This section means to explain how the association  rul e s work better than the traditional and random methods  As it is shown in  Figure 7 after applying  Aprior i  algorithm  we get  602  different rules which can be used to select the  best combination of replica sites   Let us explain Figure 7  in details    Rule #1: if Site\(s S 4  S 7  are selected then this implies  that site\(s S 3  can also be selected at the same time. This  rule has 100% confidence    In other words, it means if site  S 4   and  S 7  are selected to  work together to transfer the requested files, t h en this  implies site\(s  S 3  can also be selected to share the work at  the same time. This rule has confidence  100  This  particular rule has  confidence  of  100  meaning that  S 4  S 7   and  S 3  can be selected as a best set of replicas by  Replica  Manage r  to ge t  requested files. To compute the correlation  of this rule and see how far it is better than choosing the site  randomly, we use an Improvement equation     indicates that it has support of  26  transactions, meaning that in transaction  Single Trip  Time  Table  there are  2 6  concurrent uncongested trips of  S 4  S 7   i.e. these sites have similar network conditions in particular  time      indicates the total number of transactions  involving uncongested trips of  S 3   in  Rule 1  is equal to  174    This is a piece of a side information; it is not involved  in calculating the confidence or support for the rule itself       is the number of transactions where   S 4   S 7 as well as   S 3 has uncongested trips. In  Rule 1  it is equal  to  2 6       or   indicates how much  more likely we are to encounter  S 4  and  S 6  transaction if we  consider just those transactions where  S 3  S 5 and  S 8  have  uncongested trips. As compared to the entire population of  the transactions, it's t h e  confidenc e  divided by  support \(c   where the latter is expressed as a percentage   For  Rule 1 the  confidenc e is  100   support \(c  in  percentage   174/194\*100 = 89.6 9 So, th e    Lift ratio = 100/89.69.1 = 1.1   As it is clearly shown in  Figure 7  some r u les with  an improvement value less than one means this is an  unreliable rule. Whereas the rule with a value more than one  means this rule is better than random replica selection with  number of time equal to improvement value as it is shown in  Figure 8                   When improvement value is more than 1 it is better to use  EST to select replica sites, because it selects the sites able to  work simultaneously    I n  Figure  9  we sho w  the  comparison between EST and  traditional model using highest bandwidth a s  a criterion to  select the best replica. As we can observe our technique has  a better performance most of the times because it selects the  sites which have the stable links. In traditional method the  site which has the highest bandwidth does not always me a n  to be the best because sometimes this highest bandwidth  link can be congeste d   Let us declare more by the following  scenario  o f  Figure 1 0 suppose   S 0   be the computing site  and let   S 1  S 3   S 1 4   be replica sites  Red stars referring to  congested router s   Using traditional selection method the  file will be got from S14 since it has less number of Hops  routers\ and highest and also has highest bandwidth link         Figure 8. Improvement ratio for different rule s  Figure 9. Traditional selection strategy and ES T    
193 


               Using  ES T the replica   S 3    is selected as a best replica  because the link b etween  C S  and  R S  is uncongested     VII I   C ONCLUSIO N  In this paper we presented a dynamic replica  selection strategy that aims to adapt at ru n time its criteria to  flexible QoS binding contracts specified by the service  provider and/or the client. The adapta b ility feature  addressed by our replica selection strategy is inferred from  the observation that the basic metrics, which influence the  QoS that the user perceives when accessing a replica  depend directly on the application being replicated and on  the cli e nts\222 preferences. To reach this objective that, we  used   the concept of association rules of data mining  approach to the most stable links sites in order to reduce the  searching space the response time and network resources  consumed    A CKNOWLEDGEMENT S  Au t hors wish to express their sincere thanks to  Prof. Arun Agarwal, from GridLabs Department of  Computer and Information Sciences, University of  Hyderabad, India for providing all the infrastructural and  computational support required to carry out this work  His  academic suggestions to improve the quality of the work are  also highly appreciated and acknowledged   R EFERENCE S     M  Rashedur Rahma n   Ken Barke r   Reda Alhaj j    Replica  selection in grid environment:a dat a mining approac h    Distributed systems and grid computing \(DSGC\,pp: 695  226  700  2005    J. Gwertzman and M. Seltzer    The case for geographical  push  cashing  In Proceeding of the 5th Workshop on Hot ZTopic in  Operating Systems, 1995     R. Kavitha, I. Foster   Design and evaluation of replication  strategies for a high performance data gri d  in, Proceedings of  Computing and High Energy and, Nuclear P h ysics, 2001   S. Vazhkudai, J. Schopf, I. Foster   Predicting the performance of  wid e area data transfer s  in: 16th International PDPS, 2002   S. Vazhkudai, J. Schopf   Using regression techniques to predict  large data transfer s  in: Computing: Infrastru c ture and  Applications, The International Journal of High Performance  Computing Applications, IJHPCA , August, 2003   A. Abbas, Grid Computing    A Practical Guide to Technology  and  A PPLICATION S    2006   http://goc.pragm a grid.net/wiki/index.php/UoHy d   S. Vazhkudai, S Tuecke, I. Foster   Replica selection in the  globus data gri d  in: First IEEE/ACM International Conference  on Cluster Computing and the Grid, CCGrid 2001   J. Guyton and M. Schwartz   L o cating nearby copies of replicated  internet server s    In Proceeding of ACM SIGCOM M 222  95, 1995   A. Tirumala, J. Ferguson, Iperf 1.2   The TCP/UDP Bandwidth  Measurement Tool, 2002   R. Wolski, Dynamically forecasting network performance using  the Network Weat h er Service, Cluster Computing \(1998   Yunhong Gu, Robert L. Grossman   UDT: UD P based data  transfer for hig h speed wide area network s  Computer  Networks, Volume 51, Issue 7, 16 May  2007, Pages 1777 1799  Elsevier   R.M. Rahman, K. Barker, R. Alhajj   Predicting the performance  of GridFTP transfer s  in: Proceedings of IEEE Symposium of  Parallel and Distributed Systems, 2004, New Mexico, USA, p  238a   J. F. Kurose, K.W. Ross   Compute r  Networking A To p Down  Approach Featuring the Interne t 3rd edition   S. Venugopal, . R. Buyya,"The Gridbus Toolkit for Service  Oriented Grid and Utility Computing: An Overview and Status  Report"2004   R   Agrawal  T  Imielinski  A.Swami    Mining associatio n  rules  between sets of items in large database s  In: Proc. ACM  SIGMOD Intl. Conf. Management Data, 199 3  R  M Rahman, K Barker and R Alhajj   Replica selection  strategies in data gri d    Jou r nal of Parallel and Distributed  Computin g   Volume 68, Issue 1 2 Pages 156 1 1574, December  2008   A. Jaradat, R. Salleh and A. Abid   Imitating K Means to  Enhance Data Selectio n  Journal of Applied Sciences 9 \(19  356 9 3574, 2009, ISSN 181 2 5654, Asian Ne t work for Scientific  Informatio n 2009   S. Venugopal, . R. Buyya, K. Ramamohanarao, "A taxonomy of  Data Grids for distributed data sharing, management, and  processing". ACM Comput. Surv. 38, 1 \(Jun. 2006  AC M   New  York, NY, US A  http://www.resample.com/xlminer/help/Index.ht m  A   K Pujar i    Data mining technique s    Hyderabad : Universities  Press, 2002   G. Williams, M. Hegland and S. Roberts   A Data Mining  Tutoria l  IASTED International Conference on Parallel and  Distributed Computing and Networks P DCN\22298\ 14 December  199 8   T  Ceryen, and M. Kevin, 2005   Performance characterization of  decentralized algorithms for replica selection in dstributed object  system s  Proceedngs of 5th International Workshop on Software  and Performance, July 11  14, Palm a de Mallorca, Spain, pp  25 7 262    F  Corina, and M. Mesaac, 2003  A scalable replica selection  strategy based on flexible contract s  Proceedings of the 3rd  IEEE Workshop on Internet Applications, June 2 3 24, IEEE  Computer Society Washington, DC, USA p p: 9 5 99   R. M. almuttari, R. Wankar, A. Negi, C.R. Rao   Intelligent  Replica Selection Strategy for Data Gri d    In proceeding of the  1 0 t h  International conference on Parallel an d  Distributed  Proceedin g  Techniques and Applications  IEEE Computer  Society W a shington, DC  WorldComp2010, GCA2010   LasVega s   USA  Volume3  pp: 9 5 100  July 1 2 1 5 201 0   Cisco Distributed Director  http://www.cisco.com/warp/public/cc/pd/cxsr/dd/index.shtm l  M   Sayal, Y. Breitbart, P. Scheuermann, R  Vingralek   Selection  algorithms for replicated web server s  In Proceeding of the  Workshop on Internet Server Performance,1998   E. Zegura, M. Ammar, Z. Fei, and S. Bhattacharjee   Applicatio n layer anycasting: a se r ver selection architecture and  use in a replicated web servic e  IEEE/ACM Transactions on  Networking, vol. 8, no. 4, pp. 45 5 226 466, Aug. 2000     Figur e  10   Data Grid and their associated network geometr y   
194 


Application of Chaotic Particle Swarm Optimization Algorithm in Chinese Documents Classification 763 Dekun Tan Qualitative Simulation Based on Ranked Hyperreals 767 Shusaku Tsumoto Association Action Rules and Action Paths Triggered by Meta-actions 772 Angelina A. Tzacheva and Zbigniew W. Ras Research and Prediction on Nonlinear Network Flow of Mobile Short Message Based on Neural Network 777 Nianhong Wan, Jiyi Wang, and Xuerong Wang Pattern Matching with Flexible Wildcards and Recurring Characters 782 Haiping Wang, Fei Xie, Xuegang Hu, Peipei Li, and Xindong Wu Supplier Selection Based on Rough Sets and Analytic Hierarchy Process 787 Lei Wang, Jun Ye, and Tianrui Li The Covering Upper Approximation by Subcovering 791 Shiping Wang, William Zhu, and Peiyong Zhu Stochastic Synchronization of Non-identical Genetic Networks with Time Delay 794 Zhengxia Wang and Guodong Liu An Extensible Workflow Modeling Model Based on Ontology 798 Zhenwu Wang Interval Type-2 Fuzzy PI Controllers: Why They are More Robust 802 Dongrui Wu and Woei Wan Tan Improved K-Modes Clustering Method Based on Chi-square Statistics 808 Runxiu Wu Decision Rule Acquisition Algorithm Based on Association-Characteristic Information Granular Computing 812 JianFeng Xu, Lan Liu, GuangZuo Zheng, and Yao Zhang Constructing a Fast Algorithm for Multi-label Classification with Support Vector Data Description 817 Jianhua Xu Knowledge Operations in Neighborhood System 822 Xibei Yang and Tsau Young Lin An Evaluation Method Based on Combinatorial Judgement Matrix 826 Jun Ye and Lei Wang Generating Algorithm of Approximate Decision Rules and its Applications 830 Wang Yun and Wu-Zhi Qiang Parameter Selection of Support Vector Regression Based on Particle Swarm Optimization 834 Hu Zhang, Min Wang, and Xin-han Huang T-type Pseudo-BCI Algebras and T-type Pseudo-BCI Filters 839 Xiaohong Zhang, Yinfeng Lu, and Xiaoyan Mao A Vehicle License Plate Recognition Method Based on Neural Network 845 Xing-Wang Zhang, Xian-gui Liu, and Jia Zhao Author Index 849 
xiii 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        






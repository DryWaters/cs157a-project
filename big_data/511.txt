Filtering Directory Lookups in CMPs Ana Bosque  V  ctor Vi  nals   Computer Architecture Department Uniersitat Polit  ecnica de Catalunya Barcelona Spain  abosque llaberia  ac.upc.edu Pablo Ib  a  nez   Department of Computer Science and Systems Engineering University of Zaragoza Zaragoza Spain  
victor imarin  unizar.es Jos  e M Llaber  a  Abstract Coherence protocols consume an important fraction of power to determine which coherence action should take place In this paper we focus on CMPs with a shared cache and a directory-based coherence protocol implemented as a duplicate of local caches tags We observe that a big fraction of directory lookups produce a miss since the block looked up is not cached in any local cache We propose to add a lter before the directory lookup in order to reduce the number of lookups to this structure The lter identiìes whether the 
current block was last accessed as a data or as an instruction With this information looking up the whole directory can be avoided for most accesses We evaluate the lter in a CMP with 8 in-order processors with 4 threads each and a memory hierarchy with a shared L2 cache We show that a lter with a size of 3 of the tag array of the shared cache can avoid more than 70 of all comparisons performed by directory lookups with a performance loss of just 0.2 for SPLASH2 and 1.5 for Specweb2005 On average the number of 15-bit comparisons avoided per cycle is 54 out of 77 for SPLASH2 and 29 out of 41 for Specweb2005 In both 
cases the lter requires less than one read of 1 bit per cycle I I NTRODUCTION During the past decade single-core processors have become increasingly more complex reaching a point of diminishing returns on power/performance This fact along with the always increasing density in the chips have encouraged the development of multi-core chips Nowadays most computer manufacturers offer multi-core chips such as the IBM Power6 with tw o cores the AMD Phenom II 2 with four cores the Fujitsu SPARC64 VII with four cores the Intel Xeon 7400 series with six cores and the SUN Niagara 2 with eight cores In all of them there is at least 
a local cache level per node that is kept coherent by means of a coherence protocol Coherence protocols can be classiìed as directory-based or snoopy-based protocols Directory-based protocols keep a directory that stores the state of each block of main memory All transactions should access this structure in order to determine which coherence actions should take place In the snoopy-based protocols the state of each block is stored in the local caches that is the information about the state of the cached data is distributed As a result all transactions should be sent to all the local caches in the system Both kinds of protocols consume an important fraction of shared cache energy to determine the action to take In 
snoopy-based protocols the energy is spent on broadcasting coherence messages and making tag-cache lookups Directory-based protocols reduce energy consumption compared to snoopy-based protocols because it is known which caches have a copy of a block A directory implemented as a copy of the local cache tags requires a small amount of area but the lookups in this structure are highly associative For example Niagara 2 follows the latter scheme and a directory lookup can perform up to 256 15-bit comparisons Along the last decade there have been several proposals to reduce the power consumed by snoopy-based protocols  9 10 11 12 Most of these proposals are based 
on the fact that most broadcasts and tag-cache lookups are not necessary so it is possible to use lters that discard actions that will be useless In directory-based protocols we have observed that an important fraction of the accesses performed to the coherence directory misses that is the searched block is not cached in any local cache in the system In these situations the energy consumed by the directory access is wasted We propose to use simple lters to reduce unnecessary and energy consuming accesses to the directory in CMPs like Niagara 2 where the local cache le v e l i s split into an instruction cache and a data cache and the shared cache is inclusive 
Although instruction and data streams generally access different memory regions it is impossible to assure whether a cache line has been accessed just from one and only one of these streams e.g in self-modifying codes the same block may be accessed as data and instruction As a result in every search in a directory implemented as a copy of the local tags it is necessary to check both the copy of the tags of the local data caches and the copy of the tags of the local instruction caches In a CMP like Niagara 2 with an inclusive shared cache we can exploit the inclusion property and the knowledge 
2010 13th Euromicro Conference on Digital System Design: Architectures, Methods and Tools 978-0-7695-4171-6/10 $26.00 © 2010 IEEE DOI 10.1109/DSD.2010.85 207 


 M M Pn L1 I L1 D SB L2 DIR P0 L1 I L1 D SB L2 DIR CROSSBAR  Figure 1 CMP model having a rst-level local cache per core instruction cache data cache and store buffer and a second-level shared cache divided in several banks Table I Memory hierarchy parameters  L1 D size 8KB L2 size 4MB L1 D associativity 4-way L2 number of banks 8 L1 D block 16B L2 associativity 16-way L1 I size 16KB L2 block 64B L1 I associativity 8-way L2 latency 7 cycles L1 I block 32B L2 MSHR 8 Crossbar arbitration 3 cycles SB 8 entries per thread Crossbar latency 3 cycles Physical address 40 bits Memory latency 117 cycles of the type of the shared cache access instruction fetch data store to implement a lter that reduces the number of associative lookups Thus the lters proposed in this paper identify the stream data or instruction that the accessed block belongs to Based on this information the number of directory lookups can be greatly reduced The rest of this paper is organized as follows In Section II we describe in detail the memory hierarchy of the chosen CMP model We motivate our idea in Section III In Section IV we explain how the proposed lters work Section V shows our experimental results and Section VI discusses related work Finally Section VII contains the conclusions II C HIP MULTIPROCESSOR MODEL Figure 1 shows the CMP conìguration we assume in this work It is a CMP with 8 in-order multithreaded cores and a memory hierarchy similar to the one in Niagara 2 The rst cache level is local per core and is composed of an instruction cache L1 I and a write-through data cache L1 D Each core has also a store buffer SB with several entries per thread that contains all outstanding stores The secondlevel cache L2 which is inclusive is shared among all the cores It is divided in different banks interleaved by secondlevel cache blocks A crossbar communicates the two cache levels A write-invalidate directory-based protocol is used to maintain cache coherence The directory is distributed among the second-level cache banks keeping close to every bank the information about the blocks associated with it Table I collects the speciìc parameters we chose for the memory hierarchy All of them are based on Niagara 2 We also assume a directory similar to that of Niagara 2 which consists of a cop y o f the local cache tags In each bank the directory is implemented as a CAM structure whose area requirements are O\(PxNL1/NBL2 being P the number of processors NL1 the number of lines in the local caches and NBL2 the number of banks of the shared cache As there is inclusion between the local caches and the shared cache and the directory is accessed after the shared cache tag array the area of the directory is reduced by keeping pointers to the shared cache instead of the local cache tags as only the set index and the way in the shared cache has to be stored The directory is split into instruction and data directories replicating the organization of the local caches A directory gives the way or ways of the local caches where the copies of the subblocks are located Thus an invalidation message consists of the set index in the local cache and the way in the set A cache block in a local cache is invalidated by unsetting the valid bit of the way where it is located Stores update local caches when the ack message is received The message includes the way where the copy of the block is located in order to eliminate the lookup in the local cache Like in Niagara 2 instruction/data block e xclusi vity is maintained in the local caches that is the same block can not be at once in both instruction and data caches across all cores The directory is responsible to ensure the instruction/data exclusivity It is important to notice that as the block size of the local caches is smaller than the block size of the shared cache there can be copies of different parts of a shared cache block in local caches of different types A Directory Organization in a Bank The duplicate instruction and data directories have a similar structure see Figure 2 but they are accessed in a different way depending on the kind of memory operation The 8 banks of the shared cache are interleaved by 64B block bits 8:6 The local data cache has 128 sets so four groups of sets bits 10:9 in a local data cache are mapped to a bank of the shared cache As the block size of the shared cache is 4 times the block size of a local cache each of the four groups consists of four contiguous sets bits 5:4 Thus the data directory of a bank of the shared cache has 512 blocks 4 groups x 4 sets per group x 4-way x 8 cores The directory is organized as a set of 16 panels using SUNês terminology A panel is a group of blocks with the same set index in the local caches As any cached block can be allocated in 8 processors cpu id and the local data cache is 4-way associative a panel is a CAM of 32 entries of 15 bits each The panels are arranged in 4 rows contiguous sets and 4 columns group of sets In a similar way the instruction directory of a shared cache bank tracks 512 blocks 4 group s x 2 sets per group x 8-way x 8 cores It is also organized in panels of the same 
208 


 address <10:9 address <5:4  cpu_id \(3 bits  way[1,0 32 entries  L2 index \(9 bits L2 way \(4 bits P \(1 bit V \(1 bit address <5 way[2 DATA DIRECTORY INSTR DIRECTORY PANEL Figure 2 Data or instruction directory structure and how they are accessed size as the data directory Differences are due to larger cache block size and higher associativity in the local instruction caches III M OTIVATION Any access and any eviction done in the shared cache performs a lookup in the directory Along this paper we call memory operations to all these accesses and evictions namely loads and instruction fetches that miss in the local caches stores and evictions Below we describe the memory operations and the actions performed in the directory for each one  Load missing in the local cache load-miss from now on  The directory entry that corresponds to the local cache location in which the block will be allocated is updated with the missing address tag In order to assure instruction/data exclusivity it is necessary to invalidate all the copies of the 16B block L1 D block size in all the local instruction caches The address of this 16B block determines the two single instruction directory panels that can contain a copy of it These two panels are looked up  Instruction fetch missing in the local cache ifetchmiss from now on  The behavior is the same as in a load but instead of the data directory the instruction directory is updated and all the copies of the 32B block L1 I block size are invalidated in the local data caches Thus two subblocks of 16B are invalidated The address of these subblocks determine two data directory panels  Store  As the local data cache is write-through every executed store access the shared cache The copy of the local tags in both directories data and instruction are looked up in order to send invalidations to all the local caches that have the block The address of this block determines one data directory panel and two instruction directory panels  Eviction  As inclusion is enforced in the system the shared cache victim block has to be removed from the local caches so instruction and data directories are Table II Actions performed in the directories for every memory operation that access the shared cache For each lookup action the number of panels looked up is enclosed The shaded cells identify the actions that are unnecessary in a system without data/instruction exclusivity memory operation data directory instruction directory load-miss update lookup 2 ifetch-miss lookup 2 update store lookup 1 lookup 2 eviction lookup 4 lookup 4 looked up in order to send invalidations to all the local caches that have a copy of the 64B evicted block L2 block size Thus up to two 32B blocks in the local instruction caches and four 16B blocks in the local data caches can be invalidated These blocks determine four panels in each directory Table II summarizes the actions performed for every memory operation and the number of panels accessed in the lookup actions The shaded cells identify the actions that are unnecessary in a system without data/instruction exclusivity Update actions are mandatory in order to keep always an exact copy of the tags of the local caches in the directory Lookup actions are only useful if they hit that is if the block looked up is present in any local cache in the system For the rest of the paper we will call useful lookups to the lookup actions that hit in at least one local cache Figure 3 shows the distribution of memory operations that access the shared cache and the total and useful directory lookups in the modeled CMP Refer to Section V for a description of the used workloads and the simulated system Due to space restrictions we represent only the average of the three workloads of Specweb2005 As not all lookups represent the same amount of comparisons we represent the number of directory panels looked up  instead of the number of directory lookups Figure 3 has three columns for each benchmark The rst one shows the memory operations categorized as loadmisses ifetch-misses stores and evictions The second column corresponds to the data and instruction directory panel lookups generated by the memory operations of the rst column The last column represents the number of useful data and instruction directory panels looked up The number of directory panels looked up which requires 32 comparisons per panel is on average almost three times the number of memory operations but only 22 of them for SPLASH2 and 15 for Specweb2005 are useful More than 70 of the memory operations are stores for both SPLASH2 and Specweb2005 Thus the number of panel lookups necessary for maintaining instruction/data exclusivity shaded cells in Table II represent a small fraction 17 on average of the total number of panel lookups In SPLASH2 28 of the directory panel lookups are performed in the data directory and 76 of them are useful 
209 


 225 2.50 2.75 3.00 3.25 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75 2.00 2  25 barnes fmm ocean radiosity raytrace volrend waterns q uared waters p atial AVERAGE SPLASH2 AVG SPEC web2005 evictions evictions stores ifetch-misses load-misses memory operations directory panels memory ops directory panels looked up useful panels looked up billions instruction data Figure 3 The rst column for each benchmark represents the billions of memory operations that access the shared cache categorized as load-misses ifetch-misses stores and evictions The second column collects the billions of panels looked up in each directory The third column represents the billions of useful directory panels looked up in each directory The rest of directory panel lookups 72 are performed in the instruction directory and only 2 of them are useful For Specweb2005 the instruction directory panels looked up represent a smaller fraction than in SPLASH2 65 and the fraction of useful ones is the same as in SPLASH2 2 The rest of directory panel lookups are performed in the data directory 35 and the fraction of useful ones is smaller than in SPLASH2 40 This decrease in the number of useful data directory panel lookups is a result of the larger number of ifetch-misses that access the shared cache in Specweb2005 These memory operations perform data directory panel lookups that in general are not useful In SPLASH2 on the contrary most of the data directory panel lookups are performed by stores and in general they are useful Results from Figure 3 clearly indicate that if we know in advance whether a directory panel lookup is going to be useful or not the number of comparisons and hence the energy consumption can be greatly reduced IV F ILTERING BY THE TYPE OF THE BLOCK In general in the execution of any program the set of memory addresses of the instructions executed and the set of memory addresses of data accessed are disjunctive In our CMP model the local caches are split into data and instruction caches As the directory is implemented by duplicating the tags of the local cache it is possible to distinguish between a data directory and an instruction directory The data directory holds the tags of the local data caches whereas the instruction directory holds the tags of the local instruction caches In Section III we saw that both stores and evictions need to look up both directories because we can not assure that instruction and data are always located in different memory regions Two examples of this situation are self-modifying code and locating constants in the code segment This last case takes place when a compiler locates program constants along with the instructions using them In this situation a cached block could contain instructions and constants so there could be copies of that block in both the local data and instruction caches If this block needs to be evicted from the shared cache all the copies in the system have to be invalidated We propose to implement a lter that is able to know if a block in the inclusive shared cache has been accessed only for instruction-fetch or only as data With this information lookup actions would either be avoided or be performed in one and only one of the directories data or instruction thus reducing the energy consumed We call this lter instruction-data lter ID lter A ID Filter Operation The ID lter is implemented as metadata associated with each block in the inclusive shared cache similar to the state bits of the block For every memory operation the lter is read in parallel with the L2 tag array Then if necessary the directory is accessed in parallel with the L2 data array Note that if the directory is implemented using pointers to the shared cache instead of the local cache tags themselves it is already necessary to access the tag array before accessing the directory By using the ID lter the update actions performed in the directory by load-misses and ifetch-misses Table II can not be avoided However lookup actions can be greatly reduced B A simple implementation the two-bit ID lter The two-bit ID lter classiìes the shared cache blocks as belonging either to the data stream instruction stream or both blocks that have been accessed only by loads and stores will be marked as data blocks  blocks that have been accessed only by instruction fetches will be marked as instruction blocks and blocks accessed by instruction fetches and stores or loads will be marked as mixed blocks Therefore the lter contains two bits per shared cache block The value of these bits is set every time that a new block is allocated in the shared cache and they are updated only when the type of the block changes A data block changes its type when it is accessed by an ifetch-miss and an instruction block changes its type when it is accessed by a load-miss or a store In both cases the type of the block changes to mixed Table III collects the actions performed in the directory depending on the memory operation and the type of the accessed block Comparing Table II and Table III we observe the following differences For load-misses and ifetchmisses the lookup actions can be eliminated for data and instruction blocks respectively For stores and evictions as long as a block is marked by the ID lter as belonging to the instruction or data stream it is only necessary to look up in one directory For a data block all its copies must be in the local data caches so only the data directory is looked up 
210 


Table III Actions performed in the directories when using the two-bit ID lter For each lookup action the number of panels accessed is enclosed  memory operation block type data directory instruction directory load-miss data update  instr update lookup 2 mixed update lookup 2 ifetch-miss data lookup 2 update instr  update mixed lookup 2 update store data lookup 1  instr  lookup 2 mixed lookup 1 lookup 2 eviction data lookup 4  instr  lookup 4 mixed lookup 4 lookup 4 For an instruction block all its copies must be in the local instruction caches and only the instruction directory should be looked up In the two-bit ID lter a block classiìed as mixed can not change its type as long as it remains in the shared cache As an example for an instruction block that is accessed as data once even though hundreds of instruction fetches of it take place it will not be considered an instruction block anymore This situation could be harmful for the lter performance if the block is highly accessed C A smaller lter the one-bit ID lter As blocks in the shared cache barely change their type we propose an ID lter that classiìes every block in the shared cache either as data or as instruction This ID lter contains only one bit per shared cache block so the lter size is halved For a proper operation of the one-bit ID lter it is necessary to modify the coherence protocol to force instruction/data exclusivity of 64B blocks L2 block size So each block in the shared cache is forced to be classiìed either as a data block or as an instruction block Thus there can be copies of a block either in the local data caches or in the local instruction caches but never in both of them A drawback of the one-bit ID lter is that every time a block in the shared cache changes its type all the copies of this block in the local caches must be invalidated A block that changes its type from data to instruction needs to invalidate all its copies in the local data caches Likewise if it changes from instruction to data it is needed to invalidate its copies in the local instruction caches In order to carry out the invalidations a directory lookup is needed We expect the energy consumed by these new directory lookups to be small enough to not spoil the overall beneìt got by the instruction/data exclusivity Table IV shows the actions performed in the directory for each memory operation when instruction/data exclusivity is forced Comparing Table III and Table IV we see that Table IV Actions performed in the directories after looking up in the lter if instruction/data exclusivity for 64B blocks is forced memory operation block type data directory instruction directory load-miss data update  instr update lookup 4 ifetch-miss data lookup 4 update instr  update store data lookup 1  instr  lookup 4 eviction data lookup 4  instr  lookup 4 in general forcing data/exclusivity for 64B blocks causes a bigger number of panel lookups when the memory operation changes the type of the block when a ifetch-miss access a data block or when a load-miss or store access an instruction-block But as the mixed block type does not exist stores and evictions either access the data directory or the instruction directory but they never look up both as before In this implementation as in the previous one the lter information is set in the allocation of new blocks in the shared cache and it is updated every time a block changes its type Every time a new block is allocated in the shared cache the associated lter bit is set to instruction or data depending on the current memory operation When any block changes its type the associated lter bit is updated to the new value V E VALUATION A Methodology We use a Simics-based simulator in which we have modeled using the tools provided by Simics a memory hierarchy with the parameters described in Table I  is a full-system multiprocessor simulator capable of running unmodiìed commercial OSs and applications We conìgured Simics to model a SPARC V9 target system with a Total Store Order TSO consistency memory model running Solaris 9 We simulated a system with 8 in-order blocking 1.2GHz processors with 4 threads each that share a 8 GB memory Due to simulation time restrictions the non-numerical applications are executed in a system with 8 non-multithreaded processors We use the applications of the SPLASH2 benchmark suite and as non-numerical applications the three w orkloads of Specweb2005 Banking Ecommerce and Support In order to adapt the SPLASH2 workloads to our simulated scenario we scaled the input dataset up as proposed by Monchiero et al F o r w ater nsquared and w ater spatial we were only able to scale the datasets to 2k and 4k particles respectively to bound the simulation time We execute the whole parallel section of each benchmark Table V shows the applications used the corresponding datasets and the billions of executed instructions 
211 


Table V SPLASH2 benchmarks the corresponding datasets and the billions of cycles and instructions executed  benchmark dataset instr  10 9  cycles  10 9  barnes 64K particles 4.97 0.62 fmm 64K particles 9.57 1.20 ocean 1026x1026 5.99 0.91 radiosity largeroom ae 5000 7.45 0.94 en 0.050 bf 0.1 raytrace balls4 5.77 0.79 volrend head 0.63 0.08 water-nsquared 2192 particles 13.79 1.72 water-spatial 4096 particles 4.02 0.50 Table VI Specweb2005 workloads the corresponding simultaneous sessions the number of web transactions and billions of instructions executed workload simultaneous sessions web transactions instr  10 9  Banking 200 100 15.52 Ecommerce 1000 1200 8.07 Support 1400 2200 8.07 For the three workloads of Specweb2005 we use the web server Apache 2.0.63 After the initialization of the workload we warm the caches during 0.75 billions of cycles and then simulate during 2.25 billions of cycles The thinking time is always zero Table VI shows the number of transactions and billions of instructions executed for each workload B Coverage In Figure 3 we showed that a big amount of lookups are useless Now we analyze whether the ID lters proposed are able to identify the useless lookups in advance or not Figure 4 shows the number of directory panel lookups in the system without lter and when using the ID lters For each benchmark there are six columns The rst three columns correspond to the instruction directory and the next three correspond to the data directory In both groups the rst column shows the total number of directory panel lookups in the system without lter the second column represents the number of directory panel lookups when using the two-bit ID lter and the third column shows the number of directory panel lookups when using the one-bit ID lter Figure 4 shows that for Specweb2005 the two-bit ID lter identiìes 98 of the instruction directory panel lookups and 39 of the data directory panel lookups as useless The onebit ID lter identiìes 99 of the instruction directory panel lookups but only 16 of the data directory panel lookups For SPLASH2 the instruction directory panel lookups identiìed as useless are 98 of the total for both ID lters The two-bit ID lter identiìes 4 of the data directory panel lookups as useless but the one-bit ID lter requires an additional 2 data directory panel lookups to work properly Summing up the directory panel lookups i.e instructions  data identiìed as useless by the two-bit ID lter are 72 2.00 2.25 o ry panels looked up 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75 barnes fmm ocean radiosity raytrace volrend waternsquared waterspatial AVERAGE SPLASH2 AVG SPEC web2005 billions of direct o instr data instr data instr data instr data instr data instr data instr data instr data instr data instr data base two-bit ID filter one-bit ID filter Figure 4 Billions of directory panel lookups in the system without lter and when using the two-bit and one-bit ID lters The rst three columns correspond to the instruction directory and the next three correspond to the data directory of the total panels looked up for SPLASH2 and 77 for Specweb2005 The one-bit ID lter identiìes as useless 70 of the total panels looked up for both benchmark suites For SPLASH2 the two-bit ID lter identiìes 92 of the useless panel lookups and the one-bit ID lter 90 For Specweb2005 the two-bit ID lter identiìes 91 of the useless panel lookups and the one-bit ID lter 82 Both ID lters are able to lter a small fraction of data directory panel lookups The reason is that in general the data directory panel lookups are useful so the lters should not avoid them Most of the data directory panel lookups are performed by stores Stores represent an important fraction of the memory operations in the shared cache because local data caches in our memory hierarchy are write-through Data directory panel lookups generated by stores are in general useful so they should not be ltered out However instruction directory panel lookups generated by stores which are 2x the number of data directory panel lookups recall Table II are not useful and can be safely ltered out In Specweb2005 as an important fraction of the data directory panel lookups are performed by ifetch-misses they are not useful and the ID lters are able to avoid them The increase in the number of data directory panels looked up when using the one-bit ID lter is caused by blocks of 64B that contain both instructions and data These blocks come from the compiler allocation of constants in the code region Thus the rst 32B of a 64B block can be instructions and the next 32B can be data In the system without ID lters there are copies of the rst 32B in the local instruction caches and there are copies of the next 32B in the local data caches Therefore both loads and instruction fetches that access this block do not need to access the shared cache However in the system with the one-bit ID lter instruction/data exclusivity at 64B blocks is forced because blocks in the shared cache should be classiìed as data or instruction Thus any ifetch-miss that accesses the rst 32B invalidates all the copies of the next 32B in the local data caches and the other way around As a result the number of load-misses and ifetch-misses in the shared cache increases Both load-misses and ifetch-misses look up directory panels 
212 


 2.00 2.25 o ry panels looked up 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75 barnes fmm ocean radiosity raytrace volrend waternsquared waterspatial AVERAGE SPLASH2 AVG SPEC web2005 billions of direct o base one-bit improved ID filter instr data instr data instr data instr data instr data instr data instr data instr data instr data instr data Figure 5 Billions of directory panel lookups when using the onebit improved ID lter compared with the system without lter The rst two columns correspond to the instruction directory and the next two to the data directory recall Table II Therefore there is an increase in the number of directory panels looked up and all of them are useful because there are copies of part of the block in the local caches Radiosity is the most affected benchmark because blocks shared by data and instructions are highly accessed In this benchmark in order to maintain instruction/data exclusivity at 64B boundary the number of data and instruction directory panels looked up increases by 26 and 6 respectively The one-bit ID lter identiìes as useless 8 and 92 of the data and instruction directory panels looked up respectively As a result the number of instruction directory panel lookups is reduced by 92 and the number of data directory panel lookups is increased by 17 C One-bit improved ID lter When a 64B block contains data and instructions the number of useful directory panels looked up can increase This produces an increase in the energy consumed not only due to the extra directory panels looked up but also due to the increase in the invalidations sent to the local caches In order to reduce this waste of energy we propose a new ID lter This ID lter called one-bit improved ID lter assures instruction/data exclusivity by preventing a block classiìed as instruction block to change its type Thus when a load access a block classiìed as instruction block the data is supplied to the local data cache but it is not allocated in this cache In this way the number of loads in the shared cache increases as with the one-bit ID lter but neither directory panel lookups nor invalidations are necessary Moreover the number of ifetch-misses is the same as in the system without ID lters Figure 5 shows the coverage of the one-bit improved ID lter The rst and third columns represent the billions of directory panel lookups performed in the instruction directory and the data directory respectively The second and fourth columns show the billions of directory panel lookups when using the one-bit improved ID lter in the instruction directory and the data directory respectively The one-bit improved ID lter identiìes as useless 96 of the instruction directory panel lookups for SPLASH2 and 99 for Specweb2005 The number of data directory panel lookups identiìed as useless decreases to 15 for Specweb2005 and increases to 1 for SPLASH2 It identiìes as useless 69 of the total directory panel lookups for SPLASH2 and 64 for Specweb2005 D Comparisons avoided per ID lter access The energy saved by using the ID lters can be estimated by contrasting the number of comparisons avoided with the number of operations performed in the ID lter structure The two-bit ID lter consists of two bits per block in the shared cache while the one-bit ID lter and the one-bit improved ID lter need only one bit per block These bits called from now on lter bits should be read written and updated These operations are the ones we compare with the number of comparisons avoided The lter bits are read in every access to the shared cache written every time that a new block is allocated in the shared cache and updated when a block already allocated should change its type In the two-bit ID lter a block can be updated just once from data or instruction to mixed In the one-bit ID lter a block can change its type from data to instruction and the other way around as many times as necessary Finally in the one-bit improved ID lter a block can change its type only from data to instruction so at the most one update per block can be performed Figure 4 shows the number of directory panels looked up that can be reduced with each ID lter Each directory panel lookup action needs to perform a comparison of 32 entries of 15 bits So on average for SPLASH2 using any of the ID lters proposed we avoid 46 billions of comparisons 1.45*32 of 15 bits during the whole execution of any benchmark As on average we execute 0.85 billions of cycles per benchmark Table V 54 out of 77 comparisons per cycle are avoided For Specweb2005 on average the two-bit ID lter avoids 71 billions of comparisons 2.21*32 of 15 bits per workload and either the one-bit ID lter or the one-bit improved ID lter avoids 64 billions of comparisons 2.00*32 of 15 bits per workload As on average we execute 2.25 billions of cycles per workload the two-bit ID lter avoids 32 out of 41 comparisons per cycle and any of the other two ID lters avoids 29 out of 41 comparisons per cycle Figure 6 shows the number of times the lter bits are read written and updated for each ID lter Each benchmark has nine columns many of them are almost 0 The rst three corresponds to the two-bit ID lter the next three corresponds to the one-bit ID lter and the last three to the one-bit improved ID lter For all the ID lters the rst column represents the number of times that the lter bits are read the second columns shows the number of times 
213 


 0 0.25 0.5 0.75 1 1.25 1.5 waternsquared volrend raytrace radiosity ocean fmm barnes waterspatial AVERAGE SPLASH2 AVG SPEC web2005 billions read write udpate Figure 6 Billions of accesses perfomed to the lter bits in order to read write or update them the lter bits are written and the last column represents the number of times the lter bits are updated The number of times that the lter bits are written or updated is negligible compared with the number of times they are read They are barely written or updated because the shared cache miss rate is low and in general a block does not change its type The only two exceptions are ocean and radiosity In ocean the shared cache miss rate is higher than in the rest and therefore the number of times the lter bits are written is 11 of the times they are read In radiosity when using the one-bit ID lter there are several blocks that change its type quite often In this benchmark the lter bits are updated 7 of the times they are read On average for SPLASH2 the two lter bits of the twobit ID lter are read 0.76 billions of times per benchmark and the lter bit of the one-bit ID lter and one-bit improved ID lter is read 0.78 billions and 0.77 billions respectively This means that on average 0.9 reads are done per cycle Thus using any of the proposed ID lters more than 60 comparisons are avoided for each read to the lter bits For Specweb2005 on average the two lter bits of the two-bit ID lter are read 0.39 billions of times per workload and the lter bit of the one-bit ID lter and one-bit improved ID lter is read 0.40 billions per workload This means that on average 0.17 reads are done per cycle Thus the two-bit ID lter avoids 188 comparisons of 15 bits for each read to the two lter bits and any of the one-bit ID lters avoids 170 comparisons of 15 bits for each read to the lter bit E Performance The two-bit ID lter does not modify the coherence protocol so benchmarks performance should not be altered On the contrary the one-bit ID lter and the one-bit improved ID lter modify the coherence protocol forcing the instruction/data exclusivity at 64B blocks It is then necessary to check that the performance of the benchmarks is the same as before Figure 7 shows the normalized execution times of the different ID lters proposed with regard to the system without any ID lter We can see that the performance of the two-bit ID lter is exactly the same as the system without ID lters Using the one-bit and the one-bit improved ID lters the performance is slightly worse The one-bit ID lter is e cution time 0.98 0.99 1 1.01 1.02 1.03 1.04 1.05 barnes fmm ocean radiosity raytrace volrend waternsquared waterspatial GMEAN SPLASH2 normalized ex e GMEAN web2005 two-bit one-bit one-bit improved Figure 7 Normalized execution time of the different ID lters proposed with regard to the system without ID lters on average 0.8 slower for SPLASH2 and 2.7 slower for Specweb2005 but with the one-bit improved ID lter the system is only 0.2 slower for SPLASH2 and 1.5 for Specweb2005 Radiosity is the benchmarks with the worst performance due to the blocks that are accessed simultaneously by loads and instruction fetches Using the one-bit ID lter radiosity have a performance lost of 4 but using the onebit improved ID lter the performance lost is below 1 VI R ELATED W ORK There are several proposals to reduce the power consumption of coherence protocols for both directory-based and snoopy-based protocols For directory-based protocols Zebchuk et al presents a n e w directory implementation based on a grid of small bloom lters that uses less area leakage power and dynamic energy than a conventional directory in a CMP model without a shared cache level On the other hand our proposal is intended for a CMP model with a shared cache level and smaller local caches For snoopy-based protocols all the proposals are based on the fact that most of the snoop-induced lookups result in a miss that is the snooped caches do not contain the searched block Depending on the way used to avoid these unnecessary snoop-induced lookups we can distinguish several groups In the rst group we classify the proposals that lter the snoop-induced lookups based on the information supplied by a small structure accessed before doing the tag cache lookup Jetty implements this idea for SMPs It consists of two small structures per node that respectively represent a subset of not cached blocks and a superset of cached blocks Ekman et al e v aluate this proposal in a CMP and determine that for this type of architecture Jetty is not efìcient because the power consumed by Jetty is at the level of the power consumed by the local caches Salapura et al implement a structure that k eeps a superset of cached blocks This structure is organized as sets of blocks called Stream Registers And the Page Sharing Table PST proposed by Ekman et al uses v ectors that identify sharing at the page level In the last proposal the information is precise The second group of proposals try to avoid not only the snoop-induced lookups but also the broadcast messages 
214 


RegionScout implements se v eral structures per node in a similar way to Jetty b u t these structures k eep global system information about regions which are continuous sections of memory instead of local information about blocks This reduces the area and energy costs of the lter used in Jetty Cantin et al present a similar idea to RegionScout but the information kept in the structures is precise and the structures are bigger In the third group of proposals for snoop-based protocols the main idea is to use the knowledge available about the behavior of a program to determine if a region of memory is shared or private and limit snoop-induced lookups to shared blocks Dash et al propose a mechanism in which the compiler reports the shared arrays of an application to the operating system Ballapuram et al propose a hardw are that compiler-assisted is able to annotate the different regions that are not shared stack global and heap memory Any block in these regions is not snooped The last group of proposals propose to do the snoops necessary in a more efìcient way Saldanha et al propose to serialize snoop messages for load misses in SMPs The average cache miss latency is increased but the snoop-related activity is substantially reduced Ekman et al e v aluated this idea for CMPs concluding that it does not manage to cut much energy because most of the time the block is not cached in any local cache so at the end all the local caches are accessed VII C ONCLUSIONS We observed that many lookups in the directory of the shared cache were useless because there were no copies of the searched block in any cache in the system We propose to use an ID lter before accessing the directory which is able to identify in advance whether a lookup is useless or not ID ltering keeps track of the memory operations that access each block in an inclusive shared cache in order to be able to classify the block as data or instruction This is only possible in a system in which the local cache level is split into data and instruction caches By classifying the block as data or instruction we know if there are copies of a block only in the local data caches only in the local instruction caches or in both of them Thus the lter can determine if a lookup is useless in either the data directory or the instruction directory and prevent it from being performed We propose three different ID lter implementations All of them use a small area since they only need one or two bits per each block in the shared cache which represent from 7 to 3 of the tag array of the shared cache 22 bits tag  6 bits ECC  4 state bits Using any of these lters on average more than 70 of the directory panels looked up are avoided for SPLASH2 and Specweb2005 To maintain the lters updated less than a read per cycle of one or two bits are necessary In SPLASH2 on average 1.45 billions of directory panel lookups are avoided per benchmark execution which represents 46 billions of comparisons of 15 bits so 54 out of 77 comparisons are avoided per execution cycle In Specweb2005 on average more than 2 billions of directory panel lookups are avoided during the simulated time per workload so more than 64 billions of comparisons of 15 bits are avoided On average this means that 29 out of 41 comparisons are avoided per execution cycle A CKNOWLEDGMENT This work was supported in part by grants TIN200766423 and TIN2007-60625 Spanish Government and European ERDF gaZ T48 research group Arag  on Government and European ESF Consolider CSD2007-00050 Spanish Government and HiPEAC-2 NoE European FP7/ICT 217068 R EFERENCES  H Q Le W  J Stark e J S Fields F  P  OêConnell D Q Nguyen B J Ronchetti W M Sauer E M Schwarz and M T Vaden IBM POWER6 microarchitecture IBM J Res Dev  vol 51 no 6 pp 639Ö662 2007  AMD AMD Multi-Core T echnology   in http://multicore.amd.com   Fujitsu Fujitsu SP ARC64 VII Processor  June 2008  Intel Leading V irtualization Performance and Ener gy Ef ciency in a Multi-processor Server  T  Johnson and U Na w athe An 8-core 64-thread 64-bit Power Efìcient SPARC SOC niagara2 in ISPD 07  2007 pp 2Ö2  A Mosho v os G Memik B F alsa and A Choudhary  JETTY Filtering Snoops for Reduced Energy Consumption in SMP Servers in HPCA-7  2001 pp 85Ö96  A Agarw al R Simoni J Hennessy  and M Horo witz An Evaluation of Directory Schemes for Cache Coherence in ISCA-15  May-2 Jun 1988 pp 280Ö289  A Mosho v os Re gionScout Exploiting Coarse Grain Shar ing in Snoop-Based Coherence in ISCA-32  June 2005 pp 234Ö245  J Cantin M Lipasti and J Smith Impro ving Multiprocessor Performance with Coarse-Grain Coherence Tracking in ISCA-32  June 2005 pp 246Ö257  J Cantin J Smith M Lipasti A Mosho v os and B F alsa Coarse-Grain Coherence Tracking RegionScout and Region Coherence Arrays Micro IEEE  vol 26 no 1 pp 70Ö79 Jan.-Feb 2006  C Saldanha and M H Lipasti Po wer Ef cient Cache Coherence Tech Rep 2001 
215 


 V  Salapura M Blumrich and A Gara Design and implementation of the blue gene/P snoop lter in HPCA-14  Feb 2008 pp 5Ö14 13 OpenSPARC T2 System-On-Chip SoC Microarchitecture Speciìcation Vol 1  Sun Microsystems Inc May 2008  P  Magnusson M Christensson J Eskilson D F orsgren G Hallberg J Hogberg F Larsson A Moestedt and B Werner Simics A Full System Simulation Platform Computer  vol 35 no 2 pp 50Ö58 Feb 2002  J P  Singh A Gupta M Ohara E T orrie and S C W oo The SPLASH-2 Programs Characterization and Methodological Considerations ISCA-22  p 24 1995  M Monchiero J H Ahn A F alc  on D Ortega and P Faraboschi How to Simulate 1000 Cores SIGARCH Comput Archit News  vol 37 no 2 pp 10Ö19 2009  J Zebchuk V  Srini v asan M K Qureshi and A Mosho v os A Tagless Coherence Directory in MICRO-42  Dec 2009  M Ekman F  Dahlgren and P  Stenstr  om Evaluation of Snoop-Energy Reduction Techniques for ChipMultiprocessors in Workshop on Duplicating Deconstructing and Debunking 2002 in conjunction with ISCA  May 2002  V  Salapura M Blumrich and A Gara Impro ving the Accuracy of Snoop Filtering Using Stream Registers in MEDEA 07  2007 pp 25Ö32  M Ekman P  Stenstr  om and F Dahlgren TLB and Snoop Energy-Reduction Using Virtual Caches in Low-Power ChipMultiprocessors in ISLPEDê02  2002 pp 243Ö246  A Dash and P  Petro v  Ener gy-Ef cient Cache Coherence for Embedded Multi-Processor Systems through ApplicationDriven Snoop Filtering in DSD 06  2006 pp 79Ö82  C S Ballapuram A Sharif and H.-H S Lee Exploiting Access Semantics and Program Behavior to Reduce Snoop Power in Chip Multiprocessors in ASPLOS XIII  2008 pp 60Ö69 
216 


selection is dominated by O   C k  2   Finally the space requirement is O  MAX  C k  2    Since the size of a community is small both the time and space are also small VII E XPERIMENTAL R ESULTS We now evaluate the performance of our algorithm for object connection discovery We run all experiments on an AMD Opteron 248 with 1GB RAM running Linux 64-bit We use the DBLP co-authorship dataset modeled as a graph The graph has approximate ly 316K nodes and 1,834K edges where a node represents an author and the edge weight is the number of papers co-authored between two authors A Performance of Community Partition We rst evaluate the performance of community partition by our greedy algorithm We test three settings of c local 10 50 and 100 and four settings of c global 10 100 1000 10000 We also compare with Newman’s algorithm 13 Figure 11\(a shows that our algorithm is about an order of magnitude faster than Newman’s when c local 10 Theresult also shows that when c local increases the efﬁciency decreases which demonstrates the effectiveness of Heuristic 1 10 100 1000 10000 10 2 10 3 10 4 c g lobal Running Time \(sec c local 10 c local 50 c local 100 Newman a Running Time 10 100 1000 10000 0 50 100 150 200 250 300 c g lobal Peak Memory Consumption \(MB c local 10 c local 50 c local 100 Newman b Memory Consumption Fig 11 Performance of Community Partition For the effect of Heuristic 2 i.e c global  the performance is the best when c global  1000 When c local 10  the running time is 682 613 570 and 667 seconds for c global  10 100 1000 and 10000 respectively The result can be explained as follows When c global is too small many items are not kept in the global max-heap and hen ce we need to rebuild the heap more often When c global is too large there are too many items in the heap and hence the update of the heap takes longer Figure 11\(b shows that the peak memory consumption of our algorithm increases when c local increases since the size of the local max-heaps increases when c local increases Increasing c global  i.e the size of the global heap from 10 to 10000 only increases the memory usage for less than 1 MB since we have only one global heap However in all cases our algorithm consumes considerably less memory than Newman’s We also record that the value of the modularity of the optimal community partition obtained by the greedy algorithm is 0.71 note that all the algorithms compute the same partition According to Newman 13 a m odul ari t y v a l u e o f g reat er t h an 0.3 indicates a signiﬁcant comm unity structure Therefore 0.71 is a very high value of modularity and indicates a highquality community partition B Semantics of Answer Graph A Case Study We conduct a case study to compare our answer graph with the center-piece subgraph  CEPS  10 Thi s s t udy ai ms to rst provide a more intuitive view on the answer graphs obtained by our algorithm and CEPS Then we perform a more systematic comparison in the following subsection We use the query  Jim Gray  Jennifer Widom  Michael I Jordan  Geoffrey E Hinton   The four scholars are from two different communities Gray and Widom are from the database community while Jordan and Hinton are from the machine learning community This is clearly captured by our answer graph as shown in Figure 1 which is displayed in Section I Figure 12 shows the answer graph of CEPS which is very similar to our answer graph The similarity is because both our algorithm and CEPS nd nodes that are closely related to the query nodes in order to connect them Thus the result shows that both algorithms are able to capture important nodes and paths related to the query nodes However our method not only nds a good connection between all query nodes but also for query nodes that are in the same context we put more emphasis on their connection than the existing methods Compare Figure 1 with Figure 12 we clearly see a stronger connection between Gray and Widom through both Ceri and Hellerstein in our answer graph than CEPS Michael I Jordan Jim Gray Alexander Aiken 1 3 Jennifer Widom Michael Stonebraker Tommi Jaakkola Lawrence K. Saul 3 Zoubin Ghahramani 9 Geoffrey E. Hinton 7 1 2 5 11 2 1 9 1 1 5 3 Joseph M Hellerstein Fig 12 The Answer Graph of CEPS Although the quality of the answer graphs is comparable our algorithm signiﬁcantly outperforms CEPS we take only 0.33 seconds to compute our answer graph while the computation of the CEPS takes 925 seconds We further compare the two methods using more systematic measures as follows C Performance of Object Connection Discovery We compare the performance of our algorithm PCquery with CEPS 10  W e s et t h e b udget t o b e t w i ce of t h e query size We also verify that the answer graphs obtained by PCquery and CEPS are of roughly the same size Other settings of CEPS are as its default We generate two types of queries in-community queries and random queries  which are abbreviated as cq and rq in the gures For in-community queries the nodes in a query are randomly selected from a randomly selected community For random queries the nodes in a query are randomly selected from the set of all nodes in the dataset We generate 100 queries for each type and test the query size from 2 nodes to 20 nodes Figure 13\(a reports the average running time of nding the connection for a query The result shows that PCquery is more 
866 
866 
 


than three orders of magnitude faster than CEPS for both query types We nd that PCquery takes more time to process an incommunity query than a random query This is because the computation of the intra-community connection by dynamic programming is more costly than that of the inter-community connection by tracing the c ommunity hierarchy tree 2 4 8 12 16 20 10 2 10 0 10 2 10 4 Quer y Size \(number of nodes Average Response Time \(sec PCquery \(cq CEPS \(cq PCquery \(rq CEPS \(rq a Average Response Time 2 4 8 12 16 20 0 100 200 300 400 500 600 700 Quer y Size \(number of nodes Peak Memory Consumption \(MB PCquery \(cq CEPS \(cq PCquery \(rq CEPS \(rq b Memory Consumption Fig 13 Efﬁciency of PCquery and CEPS Figure 13\(b reports the peak memory consumption during the entire running process The result shows that PCquery also consumes signiﬁcantly less memory than CEPS in all cases In addition to the comparison on efﬁciency we also compare the quality of the answer graphs obtained by PCquery and CEPS For the fairness of comparison We use the quality metrics proposed in CEPS 10  NRatio and ERatio which indicate the percentage of important nodes and edges that are captured by an answer graph respectively We report the result in Figure 14 2 4 8 12 16 20 0 20 40 60 80 100 Quer y Size \(number of nodes NRatio PCquery \(cq CEPS \(cq PCquery \(rq CEPS \(rq a Average NRatio 2 4 8 12 16 20 0 20 40 60 80 100 Quer y Size \(number of nodes Eratio PCquery \(cq CEPS \(cq PCquery \(rq CEPS \(rq b Average ERatio Fig 14 Quality of Answer Graph Figure 14 shows that both PCquery and CEPS obtain high-quality answer graphs Both NRatio and ERatio of our answer graphs are comparable to those of CEPS although on average those of CEPS are slightly better Considering our algorithm is three orders of magnitude faster and also consumes signiﬁcantly less memory we can conclude that our method is both efﬁcient and effective VIII C ONCLUSIONS We propose context-aware object connection discovery in a large graph We adopt a partition-and-conquer approach to achieve both high performance efﬁciency and high quality results Our method rst partitions a large graph into a set of communities The concept of community not only naturally deﬁnes the context of the nodes but also signiﬁcantly improves the efﬁciency of connection d iscovery since a community is much smaller than the original graph We compute the connection between query nodes rst at the intra-community level by maximizing the information throughput of the nodes and the information ow of the paths in the answer graph and then at the inter-community level by retaining the close relation between the commun ities as deﬁned by modularity The quality of both the intraand intercommunity connection is thus controlled by the integration of information throughput/ﬂow and modularity We verify by experiments that our community partition algorithm is efﬁcient and the set of communities obtained has high quality We also show that our method obtains comparable high-quality answers as the state-of-the-art algorithm but is more than three orders of magnitude faster and consumes signiﬁcantly less memory Acknowledgement This work is partially supported by RGC GRF under grant number CUHK419008 and HKUST617808 We thank Mr Hanghang Tong and Prof Christos Faloutsos for providing us the source code of CEPS R EFERENCES  X  Y an P  S  Y u and J  H an  Graph i nde xing bas e d o n d is crim inati v e frequent structure analysis ACM TODS  vol 30 pp 960–993 2005  J  C he ng Y  K e  W  N g a n d A  L u  F g-i nde x t o w a rds v e r i  c a t i on-fre e query processing on graph databases in SIGMOD  2007 pp 857–872  P  Z hao J  X Y u  a nd P  S Y u   Graph i nde xing T r ee  d elta   graph in VLDB  2007 pp 938–949 4 Y  K e J  Cheng and W  N g Cor r e lation s ear ch in gr aph d atabas es   in KDD  2007 pp 390–399 5 Y  K e J  Cheng and W  N g E f  cient c or r e lation s ear ch f r o m g r a ph databases To appear in TKDE  2008  A  I nokuchi T  W as hio and H  M ot oda An apriori-based algorithm for mining frequent substruc tures from graph data in PKDD  2000 pp 13–23  X  Y an and J  H an  Clos e g raph m i ni ng closed frequent graph patterns in KDD  2003 pp 286–295  J  H uan W  W a ng J  Prins  and J  Y ang Spin mining maximal frequent subgraphs from graph databases in KDD  2004 pp 581–586 9 C  F alouts o s  K  S  M c Cur l e y  a nd A  T o m k ins  F as t d is co v e r y of connection subgraphs in KDD  2004 pp 118–127  H  T ong and C  F alouts o s  Center piece s ubgraphs  p roblem de n ition and fast solutions in KDD  2006 pp 404–413  Y  K o ren S C North and C  V olins k y  Meas uring a nd e x tracting proximity in networks in KDD  2006 pp 245–255  M E  J  Ne wm an and M  G irv a n Finding and e v a luating c om m unity structure in networks Physical Review E  vol 69 p 066113 2004  M E  J  Ne wm an  F a s t algorithm f or detecting c om m unity s t ructure i n networks Physical Review E  vol 69 p 066133 2004  F  W u and B  A  H uber m an  F i nding com m unities i n linear tim e a physics approach The European Physical Journal B Condensed Matter and Complex Systems  vol 38 no 2 pp 331–338 2004  R K u m a r  P  Ragha v a n S Rajagopalan and A  T om kins   T r a w ling the web for emerging cyber-communities Comput Netw  vol 31 no 11-16 pp 1481–1493 1999  R K u m a r  P  Ragha v a n S Rajagopa lan and A Tomkins Extracting large-scale knowledge bases from the web in VLDB  1999 pp 639 650  R K u m a r  U Mahade v a n and D  S i v akum ar   A g raph-theoretic approach to extract storylines from search results in KDD  2004 pp 216–225  D Gibs on R K u m a r  and A  T om kins   Dis c o v e ring lar g e d ens e subgraphs in massive graphs in VLDB  2005 pp 721–732  Y  Douris boure F  Geraci a nd M Pe llegrini Extraction and classiﬁcation of dense communities in the web in WWW  2007 pp 461–470  A Claus e t M E  J  Ne wm an a nd C Moore Finding com m unity structure in very large networks Physical Review E  vol 70 p 066111 2004 
867 
867 
 


  13 false \(double\argets Figure 12 illustrates this situation. The conditional update correctly updates the tracker wh ich is tasked with following the target. However, the detector which is partially spatially coincident with the tracker also receives energy from the conditional update. This can lead the detector to initiate falsely\second target nearby the first target This effect can be countered a number of ways. First, we can adjust the speed at which the tracker re-centers itself The double initialization phenomenon occurs when the PDF peaks near the edge of the tracker grid. However, this method has the side effect of potentially allowing probability to fall off of the grid in low SNR environments causing track loss. Of course if the SNR is low enough or measurement outages occur tracks will be dropped. Second a guardband around the tracker that does not allow any detector sufficiently near the tracker to receive reinforcement via the conditional density can mitigate the double target problem. However, this has the side effect of preventing detection of closely spaced targets. Third increasing the spatial extent of the tracker has a similar effect as the using a guardband. It does require increased computation, but generates a better representation of the posterior There are several engineering tradeoffs. The first is that large tracker grids \(or large guard bands\ prevent falsely detecting new targets because of conditional probability spill over. However, if applied too aggressively, this will prevent correctly detecting cl osely spaced targets. Second quick tracker grid translation correctly centers the target mass, again preventing spillover into nearby detectors However, overly liberal trac ker repositioning may in fact move trackers to spurious energy locations and drop true targets off of the finite grid On Ambiguous Targets As discussed earlier, ambiguous targets will eventually move non-physically and this will cause the tracker to remove them via its natural prediction and update process Figure 13 illustrates this phenomenon. There are two real targets that create two persistent ambiguities. All four are detected and tracked automati cally. The ambiguous targets however, eventually move non-physically due to their reliance on the node bearing angles. The tracker automatically penalizes the non-physical motion and the targets\222 present hypothesis decrease quickly over time Ambiguous target removal is done automatically in the Bayesian framework as follows The PDF on target state is predicted forward in time according to the kinematic model True targets will have behavior consistent with the kinematic model \(note the kinematic model is a statistical model so it is predicting a range of possibilities for the future target state\biguous targets may behave consistently with this model for a period of time, but eventually they will appear to perform a non-physical maneuver \(these epochs typically come when the ambiguous target crosses a line of symmetry in the sensor\this point, the predicted target position will be in strong disagreement with the inco ming measurements on that target. This mismatch in predicted target position and measurements leads to a decr ease in the target present hypothesis as calculated in eq. \(4\long, only true targets remain   Figure 12 \226 Improper selection of grid resolution leads to multiple initializations on the same target. Left Measurement update of a Tracker \(red=highest likelih ood, blue=lowest\Right Measurement update of a detector which lies near the Tracker.  Since the track er size has been improperly chosen, some energy from the measurements of a single target leak s on to the detector. This can le ad to false double-initializations 


  14 8  C ONCLUSION  This paper has described a Bayesian approach to detecting and tracking multiple moving targets using acoustic data from multiple passive arrays In contrast to traditional undersea acoustic systems, which develop tracks at the single array level and require track association, our approach fuses data at the m easurement level and operates directly in the target state space We have detailed a well known nonlinear filtering approach to single target detection and tracking [1, 4 and desc ri be d our computationally efficient finite-grid approach to the required density estimation. We have furthermore extended this to the multiple target case by employing a bank of single target detector tracke rs and approximation methods that adjust for closely spaced targets. This approximate approach avoids fully treating the computationally complex joint multitarget problem Future work includes modified approaches to posterior estimation including dynamic grid extent, dynamic grid resolution, and particle filtering. It is anticipated that adaptive sampling of the posterior will lead to computational savings. Furthermore, future work includes more detailed modeling and estimation of closely spaced targets allowing a more accurate representation of the joint target density. Naively implemented, this implies exponential growth \(in the number of targets\r the probability state space being es timated. However, recent work in a related tracking domain on adaptive density factorization [5 c h a stic sa m p lin g  p article filtering    pr ovi de m e t h o d s t h at m i t i g at e t h i s com put at i o n gr owt h  when the full joint density is treated  A PPENDIX  This section discusses the details of how the single target probability density is time evolved on a discrete grid. This discussion is similar to that found elsewhere [15, 14, 13 We wish to compute the single target probability density at time      from the density at time     The relation between these two densities can be expressed using the law of total probability as                We expand     using a second order Taylor series as               where  is the vector of partial derivatives, i.e and is the matrix of second order partial derivatives Then the relation of \(23\ approximated as   Figure 13\226 Left: P h1 over time for four targets, two of which are real and two of which are ambiguous. Although the ambiguous intersections are persistent, eventually the false targets ha ve non-physical motion. The target present hypothesis quickly goes to zero for these targets and they are elimin ated. Right: the tracker estimate of target position and red circles indicating the removal point fo r the false targets 


  15             Where denotes the expectation with respect to the transition distribution    and the omitted terms involve similar terms involving and and cross terms between the and coordinates We use the nearly constant velocity \(NCV\model to specify the transition distribution    This assumption corresponds to one where the target moves at constant velocity except for random jump changes \(i.e nearly constant velocity\is is a plausible model when  is small as it is here Specifically, the NCV model assumes step changes in target velocity defined by the Ito Equations     This model implies  and likewise for  It is furthermore assumed that th e noise processes in each coordinate are independent Under this model, we can eval uate the required terms from 25\ as follows          And likewise for terms involving and Notice that all cross terms \(e.g  have expectation due to the assumption that the noise process is independent in the two coordinates This model simplifies \(25\ to         where the terms omitted are replicas involving the  coordinate Under the assumption that is small, this can be rewritten as    For implementation, this is approximated using an implicit Euler scheme wh ere      Where the indices  represent the discrete    locations where the probability mass is captured Likewise, using forward differencing      and          and similarly for the y coordinate system When substituted into \(28\is leads to a series of equations of the form                This series of equations defi ne the probability at each point at time  It can be efficiently solved via Thomas\222 algorithm \(rather than simply inverted\he matrix is tridiagonal     


  16 R EFERENCES    R o y E. Bet h el Benjam i n Shapo, C h r i st opher M   Kreucher, \223PDF Detection and Tracking\224, under review IEEE Transactions on Aerospace and Electronic Systems  2 y. E B eth e l an d G. J. Paras, \223A PDF Mu lt it arg et Tracker\224 IEEE Transactions on Aerospace and Electronic Systems vol. 30, no. 2, pp. 386-403, April 1994 3   R o y E  B e t h e l a n d G  J  P a r a s  223 A P D F M u l t i s e n s o r  Multitarget Tracker\224 IEEE Transactions on Aerospace and Electronic Systems vol. 34, no. 1, pp. 153-168 January 1998  L   D   Stone, C. A. Bar l ow, and T. L Corwin, \223Bayesian  Multiple Target Tracking\224  Boston: Artech House, 1999  l la and A. Hero, \223Multitarget Tracking using the Joint Multitarget Probability Density\224 IEEE Transactions on Aerosp ace and Electronic Systems  vol. 41, no. 4, pp. 1396-1414, October 2005  M  M o relande, C. Kreucher, K. Kastella, \223A Bay e sian  Approach to Multiple Target Detection and Tracking\224 IEEE Transactions on Signal Processing vol. 55, no. 5 pp. 1589-1604, May 2007  B  Shapo, and R  E B e t h el  223An Overvi ew of t h e Probability Density Function \(PDF\er\224 Oceans 2006 Boston, Sept. 2006  R oy L. St r e it 223M ult i s ensor M ul tit arget Int e nsit y Fil t er 224  International Conference on Information Fusion  Cologne, Germany July 2008  M  Ort on and W Fi t z geral d 223A B a y e si an approach t o  tracking multiple targets using sensor arrays and particle filters\224 IEEE Transactions on Signal Processing, vol. 50 no. 2, pages 216-223, Feb 2002  A. Doucet B Vo, C Andri e u, and M Davy 223Par t i c le filtering for multi-target tracking and sensor management\224, IEEE International Conference on Information Fusion, 2002  H Van T r ees, \223Det ecti o n Est i m a t i on, and M odul at i o n  Theory IV:  Optimum Array Processing\224  J. C St ri k w erda, Fi nit e  Di fference Sch e m e s and Partial Differential Equations, Ch apman & Hall, New York 1989   K. Kast el la and C Kreucher, \223M ult i p l e  M odel Nonl i n ear  Filtering for Low Signal Ground Target Applications\224 IEEE Transactions on Aerospace and Electronic Systems vol. 41, no. 2, April 2005, pp. 549-564  Z. Tang and \334. \326zg\374n er, \223Sensor Fu si on for Target Track Maintenance with Multiple UAVs based on Bayesian Filtering Method and Hospitability Map\224 Proceedings of the 42 nd IEEE Conference on Decision and Control pages 19-24, December 2003  K. Kast ell a 223Fi n it e di ff erence m e t hods for no nl i n ear filtering and automatic target recognition\224 MultitargetMultisensor Tracking: Applications and Advances vol III, pages 233-258, Artech House, 2000 B IOGRAPHY  Chris Kreucher received his Ph.D. in Electrical Engineering from the University of Michigan in 2005. He is currently a Senior Systems Engineer at Integrity Applications Incorporated in Ann Arbor, Michigan. From 1998 to 2007, he was a Staff Scientist at General Dynamics Advanced Information Systems' Michigan Research & Development Facility \(formerly ERIM\. His current research interests include nonlinear filtering \(specifically particle filtering Bayesian methods of multitarget tracking, self localization information theoretic sensor management, and distributed swarm management Ben Shapo earned his Ph.D. in El ectrical Engineering in 1996 from the University of Michigan.  He is currently a Senior Systems Engineer at Integrity Applications Incorporated in Ann Arbor, Michigan.  From 2003 to 2008 he was a Lead Engineer at General Dynamics, where he contributed to a number of RF and acoustics signal processing and tracking efforts.  Dr. Shapo has 12 years experience in the DoD research community in the areas of detection, tracking, and data fusion, with emphasis on highfidelity simulations and applying new methods to real data  Dr. Roy Bethel is currently employed at The MITRE Corporation in McLean, VA. He has been actively involved in development, testing, and evaluation of signal processing and detection and tracking systems. In particular, he has developed many systems that have been implemented on United States Navy airborne, surface, and submerged platforms. He is currently engaged in research and development of innovative approaches to multitarget detection and tracking  A CKNOWLEDGEMENTS  This work was partially funded by the Office of Naval Research contract N00014-08-C-0275. The authors would like to thank Dr. John Tague for his support, and Mr. Scott Spencer and Dr. Charles Choi for their assistance 


2 1 0 00                4 G ro w th 1  1 3 1 0 9 2 0 2 3 0 10  0 56                So ci ode m og ra ph ic c ha ra ct er is tic s 


s 5 A ge y ea rs   21 7 8 7 3 9 0 01 0 22  0 1 4 0 0 8              6 G en de r i s fe m al e2   0 2 4  0 0 6 0 0 2 0 00 0 0 3 0 10    


           7 C ur re nt ly n ot w or ki ng 2  0 0 5  0 0 8 0 04 0 04 0 0 1 0 16  0 16             8 C ur re nt ly in e du ca tio n2   0 6 


6 7  0 01 0 1 9 0 08  0 03 0 6 8 0 0 7 0 3 2           9 C ur re nt ly w or ki ng 2  0 2 8  0 03 0 18  0 1 1 0 0 3 0 64  0 00 0 1 4 0 8 9   


        10 E du ca tio n ac hi ev ed 3  3 5 7 1 5 2  0 04 0 02 0 2 1 0 1 2 0 16  0 02 0 1 6 0 13  0 0 6         11 D is pe ns ab le in co m e   


  21 0 9 2 72 7  0 14  0 0 1 0 09  0 08  0 2 0 0 00 0 0 4 0 18  0 1 6 0 0 1        In te rn et u sa ge                     


  12 A ct iv e in te rn et u sa ge 1  0 0 2 0 9 6 0 2 1 0 25  0 11  0 12  0 10  0 0 4 0 05  0 0 8 0 0 5 0 0 1 0 12        13 H ou rs o nl in e h ou rs 


rs   2 6 5 3 0 3  0 04 0 12  0 1 1 0 0 3 0 40  0 0 7 0 0 7 0 4 7 0 5 3 0 07  0 1 1 0 07       14 W illi ng ne ss to p ay 1  1 8 3 0 6 3  0 03 0 10 


10  0 07  0 08  0 0 2 0 0 4 0 0 1 0 01  0 00 0 0 5 0 14  0 04 0 05      G am e sp ec ifi c va ria bl es                      15 T en 


ur e w ee ks   2 8 2 3 5 2 0 2 6 0 31  0 0 9 0 01 0 12  0 0 4 0 02 0 0 9 0 0 9 0 07  0 02 0 13  0 08  0 0 4    16 C ro ss o ve r on o ffl in e 4  0 1 5 


5 1 1 1 0 1 9 0 11  0 13  0 18  0 2 0 0 1 4 0 0 7 0 14  0 1 1 0 0 4 0 08  0 15  0 0 5 0 01 0 07    17 S at is fa ct io n1   18 7 5 1 3 16  0 18  0 00 


00 0 44  0 52  0 1 4 0 0 3 0 02 0 07  0 0 9 0 1 4 0 10  0 08  0 0 6 0 09  0 0 1 0 13   18 C om m itm en t1  0 6 2 0 8 3 0 3 1 0 13  0 37  0 39  0 0 7 


7 0 0 6 0 02 0 03  0 0 4 0 1 3 0 14  0 17  0 0 5 0 09  0 07  0 19  0 58  S ou rc e O w n ca lc ul at io n N ot e N  1 3 89 o bs er va tio ns S ig ni fic an ce le ve ls 


ls  p  0 05 S D  S ta nd ar d de vi at io n 1 5 po in t L ik er t s ca le ra ng in g fro m 2 to 2  2 du m m y va ria bl e 3 o rd in al v ar ia bl e ra ng in g fro m v oc at io na l e du ca 


tio n to P h D 4 n um be r o f c on ta ct s   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 



MULTI-SENSOR DATA FUSION FOR SITUATIONAL ASSESSMENT  A CRITICAL ELEMENT OF SYSTEMS INTEGRATION SOME THEORY AND APPLICATION TO COLLISION AVOIDANCE Professor CJ Harris and Mr RS Doyle 1 Introduction To achieve systems integration\222 for large complex engineering systems which incorporate many disparate 
technologies/methodologies any viable approach must exhibit a set of quality features such as interoperability, extensibility robustness and survivability, modularity and portability   Which in turn require at least three fundamental elements  architectures for integration  open system for communications and construction  object oriented 
technology for components definition System architectures take many forms  such as the hierarchical or functional multi-layered approaches including NASREM, RC3 IMA-ARNIC 65 1  or fully distributed-decentralised flat subsumption architectures The hierarchical architecture2 based on the stimulus mpghesis Response SHORE paradigm is most popular in which 
the  Stimulus part relates to sensor processing, data fusion and picture compilation aspects  Hypothesis part relates to situational assessment, diagnositics monitoring aspect  Response part relates to the planning decisioning and control aspect In this paper we consider only the level 1 or layer 1 aspect, Multi Sensor Data Fusion MSDF for situational assessment for real time complex processes 
All three elements of the SHORE paradigm have been considered by the ISIS group for demonstrating this architecture for systems integration of a fully autonomous road, cross-country and drilling vehicle on CEC Project Panorama MSDF is a \223continuous process dealing with the association correlation and combination of data and information from multiple disparate sources to achieve a 
refined state estimate about the environment and timely assessment of the pituation\224 Here we only consider the processes of data integration and state estimation To integrate data from disparate data sources such as sensors look-up tables, human experiences/observations data bases, etc a common currency of information content and data representation is required Existing the~ries\224 such as Bayesian Dempster-Shafer, Artificial Neural Networks 
ANN Case Based Reasoning, Method of Endorsement, Blackboard Expert Systems, Fuzzy Logic etc  all of which have been used for MSDF  are inadequate or inappropriate We propose neurofuzzy algorithms6, since they readily incorporate database knowledge/symbolic/linguistic knowledge in the form of fuzzy rules and sensory data in a single environmentlprocessor 
2 Neurofuzzy Algorithms Neurofuzzy algorithms are single layer ANN in which the input layer is composed of basis functions Image Speech  Intelligent Systems ISIS Research Group Department of Electronics and Computer Science University of Southampton Southampton SO17 IBJ UK 5 1 


ai E\(r i  1 p defined over a lattice of the input data or measurements x\(r E Rn n  p the output layer is a set of adjustable weights w\(t such that the network output y  arw  as the network is linear in the adjustable weights linear algebraic methods and linear optimisation techniques can be used in training the network to learn some unknown nonlinear inpudoutput mapping y  f\(x  These networks have provable learning convergence and stability conditions and are appropriate for online applications such as dynamic process modelling control and estimation Under certain conditions these networks are inpudoutput equivalent to a class of fuzzy systems with adjustable rule confidences thereby allowing upriori knowledge to be incorporated as well as representing linguistic/symbolic processes A major deficiency of these networks is that as n increases the computation/memory cost increases exponentially this applies to all rule base paradigms however recent research7 on neurofuzzy construction algorithms in ISIS have shown that parsimonious models can be automatically generated So now we are able to construct input/output models with very few parameters or rules\for arbitrary nonlinear dynamical processes with either data or symbolic representations/inputs Given that the plant is dependent on some operating point process e.g Mach number, altitude for a gas turbine or aircraft dynamics\over the system envelop then a quasi-linear ARMA model can be found which is parameterised by an additive sum of neurofuzzy systems  each in turn with few parameters This model has a state space representation which is cononical and directly amenable to Kalman filtering In this regard ISIS has generated several neurofuzzy Kalman filters for nonlinear state estimation of unknown dynamical processes with measurable/observable operating points Given that for each data source there is an appropriate estimator/tracker there is then the problem of data integration or fusion where the sensors refer to the same state entity Here we adopt the distributed decentralised fusion architecture5 whereby each sensor contains its own independent estimator sharing its results with all other relevant sensors \(as additional post processing inputs Fusion at each intelligent sensor is based on a weighted sum of all sensor estimates e.g  2  iIl c 1 p?X A  6 l where pi  covariance of xi ii is its estimate given by the ith sector 3 Collision Avoidance To illustrate this approach we consider the application of these methods to the collision avoidance of helicopters in bad weather conditions fog, heavy rain snow storms, etc when visual sensing is impossible There are two subproblems i the localisation problem Where is the aircraft in 3-D space, here GPS, INS RADALT ADS sensors are available for estimation and fusion ii the object detection and tracking problem Determination of fixed and moving obstacles in 3-D space here TCAS microwave radar millimetric radar and terrain data bases are available for estimation and fusion Additionally subproblems such as safe navigation through this obstacle space to avoid collisions and the presentation of the pilot of safe flight comdors are relatively straight forward e.g use of potential field theory etc The demonstrator is a Westland Lynx helicopter flight simulator \(based on 6 silicon graphic processors with a 45 ft display screen successful simulations including head on and crossing agile air obstacles over mountainous terrain have demonstrated the effacy of this methodology 5 I2 


References 1 R Fraser Embedded Command  Control Infrastructures for Intelligent Autonomous Systems PhD Univ of Southampton 1994 2 CJ Harris Applications of AI to Command and Control Peter Peregrinus, 1988 3 E Waltz and J Llinas Multi Sensor Data Fusion Artech House 1990 4 RT Antony Principles of Data Fusion Automation Artech House, 1995 5 J Manyka and H Durrant-Whyte Data Fusion and Sensor Management Ellis Horwood 1994 6 M Brown and CJ Harris Neurofuzzy Adaptive Modelling and Control Peter Peregrinus, 1994 7 KM Bossley, DJ Mills M Brown and CJ Harris Construction and Design of Parsimonious Neurofuzzy Systems in 221Neural Network Engineering in Dynamic Control Systems\222 Ed KJ Hunt etal Springer Verlag, 1995 8 H Wang, M Brown and CJ Harris Modelling and Control of Nonlinear Operating Point Dependent Systems via Associative Memory Networks J Dynamics and Control 6\(2 199-218 1995 9 ZQ Wu and CJ Harris Adaptive Neurofuzzy State Estimators Int J Systems Science, 1996 \(to appear 10 RS Doyle and CJ Harris Multi-Sensor Data Fusion for Helicopter Guidance using Neurofuzzy Estimation Algorithms Aero J Royal Aero Soc. June/July 1996 pp241-251 0 1997 The Institution of Electrical Engineers Printed and published by the IEE Savoy Place London WCPR OBL UK 


Proceedingi of the First International Conference on Machine Laming and Cybernetics Beijing 4-5 November 2002 I 51 8  Suppose Yic Y is the itemset in discrimination vector and Si=YinC where Si and SifSj then Y=IPOSc\(D is the number of Si in the vector K\(C,D POSc\(D for convenience give more details Because IUI is a const in this procedure we can set The method for reduct of itemset see 81 here do not 4 Miningalgorithm 4.1 Primary algorithm Assume that transaction database has N records each record has two.parts the transaction identifiers and the itemset, every the transaction identifiers is unique.Tk denote the k-th transaction L denote frequent itemset The top-down method for mining frequent from database op-Down-Miner L For k=l to N X=Tk.C  X=the candidate itemset in transaction identifiers Tr Del-minItems\(X remove the items with support less than min-support from X If L=Q then Gen-Candidatel\(X L C Generating //candidate frequent itemset C and frequent itemset L from itemset Else endif Endfor out L The algorithm for generating frequent itemset Gen-Candidate\(X L C Gen-frequent\(C L EndTop-Down-Miner Gen-frequent\(C L Nl=ICI For i=l to NI If support\(Ci then Gen-Candidate\(Ci,L,Y candidate frequent itemset from the key-itemset Gen-frequent\(Y,L call Gen-frequent\(Y L Else L=Luci endif Endfor EndGen-frequent This is a recursion algorithm for describing principle  when all the candidate frequent generated are frequent or without any candidate frequent generated the algorithm finish 5 Dseussion of the complexity and efficiency Top-down-Minfrequent algorithm provides an efficient way to generate maximum frequent itemsets which efficiency can be demonstrated by analyzing its worst case time complexity Suppose there are N records in the database the time complexity in the worst case is analyzed as follows For each itemset of record  it generates frequent itemsets once so the total times is N suppose the average length of itemset is M the average computing length of reduct is S and S candidate itemsets whose length is M-l generated each time it needs 1/2MZ for computing candidate itemsets whose length are M M-I  2 1 __  and the time spend on each is at most O\(2\222 So the sum is U2M2  O\(2\222 Since it takes M X O\(N X N\222 to generate reducts each time\(seen 121  the total computing time is about MXO\(N XN\221 1/2 2S O\(2\222 X N\222 here N is the number of tuples in the relation generalized by the database In fact M is dynamic and degressive and the average computing length of reduct\(S is also dynamic and degressive because it changes according to M in general 1  S  M S=M could be Vue only when all generated candidates are reducts no matter how long the length of candidate itemsets is And now the complexity is about 0.5 X M3NX O\(2\222X NZ  The frequent itemsets must be very short because M keeps down to 1 or 2 but it is impossible for mining long frequent itemsets since long frequent itemsets will pass the min-supp threshold when M is large That is to say, it will end far away O\(2\222 Additionally, the computing complexity can be depressed because we can prune the unnecessary branches during the mining procedure Hence the computing complexity for mining long frequent itemsets should be 0.5 X M3N X O 9 S,M X N2  where 2211 S M is a variable accounting to S and M The computing complexity approach to that of polynomial times In most cases the average computing length of reduct S will shorter after erasing the items whose support is smaller than the given min-supp The more the frequent itemsets are determined, the faster the speed will he since the algorithm can prune in time by comparing the known frequent itemsets with candidate itemsets when candidate itemsets already include the frequents Especially it will be a good idea to adopt Apriori approach if S is near to M and M is very large and there are scarcely long frequent itemsets At last the mined maximum frequent itemset is complete since we get frequent itemsets by determining each element of the candidate itemsets ,and each candidate itemsets scan the database using the discrimination vector 6 Conclusions As shown above, in this paper we proposed a top-down mining method for mining long frequent itemsets Our algorithm combined two different mining methods, one for mining association rules, the other for mining classification rules  we think it will be a good idea to combine two or more kinds of methods What\222s more it is still a primary 


Proceedings of the First International Conference on Machine Learning and Cybernetics Beijing 4-5 November 2002 algorithm so there are many issues that should be studied in future to improve it The following are some topic for future research as examples using Apriori algorithm in proper time self-adjusting mining strategy accounting to the length of reduct, how to make the best use of the former result how to get the least number of reducts, developing incremental mining algorithm based on top-town algorithm and so on References Agrawal R Imielinski T Swami A CIMining Association Rules between Sets of Items in Large Databases In Proceedings of ACM SIGMOD Conference on Management of Data,1993,207-216 Agrawal R Srikant R Fast Algorithms for Mining Association Rules In Proceedings of 20 Int'l Conference on Very Large Databases, 1994.478 Lin D.-I and Kedem Z.M Pincer-Search A New Algorithm for Discovering the Maximum Freauent Set C]In Proc Of the Sixth European Conf on Extending database technology 1998 Roberto J Bayardo Jr Efficiently Mininr long patterns from In Proc of the 1998 ACM-SIGMOD Int Conf on Management of Data SIGMOD98 Qinghua Zou Henry Chiu Wesley W Chu Using patterns decomposition methods for finding all frequent Datterns in large datasets,[Rl UCLA CS-TR 200038 awlak Z Rough Sets Theoretical Aspects of Reasoning about Data MI Kluwer Academic Publishers,1991 J Han and J Pei Minine Freauent Patterns bv Pattern Growth Methodology and Implications JIACM SIGKDD Explorations Special Issue on Scaleble Data Mining Algorithms 2\(2 December 2000 Hu Xiaohua Knowledge discovery in database an attribute-oriented rough set approach Dissertation Regina. 1995 Skowron A and Rauszer C The discernibility matrices and functions in information systems Technical Report Research Report, ICSWUT, Warsaw 1991  _ IO Wang Xiaofeng,Yin Danna Shihchuan Cheng Mutuality Sets J Journal of Shenyang Institute of Chemical Technology,l999.3, 67-76 I 11 Wang Xiaofeng,Yin Danna Shihchuan Cheng Mutuality Sets And Its Applications in Reduct of Knowledge System Jl Journal of Tsinghua Unive&ty\(in Chinese 1998.7 No.S2,6-9 I21 Wang Xiaofeng Wang Tianran Mutuality Measure and Computation of Incremental Support and Confidence J Journal of Software in Chinese 2001 To appear  519 


because the use of the same system makes the comparisons more impartial Due to space restrictions we only include the results of the unordered algorithms The results of the CN2-SD algorithm were computed using both the multi plicative weights with y  0.5 0.7 0.9 and the additive weights Results withy  0.7 are not listed as they are al ways between those of 7  0.5 and y  0.9 as expected All other parameters of the CN2 algorithm were set to their de fault values bean-size  5 significance-threshold  99 Table 2 Area under the ROC curve with stan dard deviation AUC  sd for different vari ants of the unordered algorithm using 10-fold stratified cross-validation 3.5 and on CN2-WRAcc with a factor of 2 Note however that rules obtained with additive weights and multiplicative weights with high y are highly overlapping due to the rela tively modest decrease of example weights In addition there is also a substantial increase in the av erage likelihood ratio while the ratios achieved by CNZ standard are already significant at the 99 level this is fur ther pushed up by CNZ-SD with maximum values achieved by additive weights An interesting question to be verified with further experiments is whether the weighted versions of the CN2 algorithm improve the significance of the in duced subgroups also in the case when.CN2 rules are in duced without applying the significance test In summary CNZ-SD produces substantially smaller rule sets, where individual rules have higher coverage and sig nificance Table 3 Average size 9 coverage CVC and llkelihood ratio LHR of rules for different versions of the unordered algorithm induced from the entire data sets We also compared the sizes of the rule sets, average rule coverage, and the likelihd ratio of rules computed from the entire data sets not using cross-validation Table 3 compares CNZ-SD with CN2-standard and CN2-WRAcc in terms of the size of the rule set S is the number of rules in a rule set, including the default rule\average rule coverage CVG is computed as the averaged percentage of covered positive and negative examples per rule and likelihood ra tio\222 per rule The experimental results show that CN2-SD achieves im provements across the board In terms of AUC, the smallest improvement is achieved by additive weights and slightly better improvements of 34 are by multiplicative weights On the other hand additive weights result in ahout 2 times less rules on average than multiplicative weights and 6.5 times less rules than CNZ-standard Average rule coverage is also optimal for additive weights, improving on the av erage the coverage of CN2-standard rules with a factor of 222The likelihood ralio is used in CNZ for testing the significance of Ihs induced tule 141 For Iwo-class problems this stalislic is distributed ap prorimalely as xz wilh one degree of freedom Finally we illustrate our approach in the ROC space by means of the results on the Australian data set Fig ure 1 The solid lines in this graph indicate the ROC curves obtained by CN2-SD and CN2-standard evaluated with AUC-Method-2 i.e probabilistic classification with overlapping tules the top line \(squares for CN2-SD with additive weights, and the bottom line \(triangles for CNZ standard CN2-standard finds many more rules than CN2 SD which leads to overfitting as the ROC curve is mostly below the diagonal For illustrative purposes we also include positive and negative convex hulls constructed from individual sub groups using AUC-Method-l dotted lines The points on the X and Y-axes close to the origin are all small purely positive and negative subgroups found by CN2-standard that do not contribute to the convex hull \(presumably these are the rules that lead to poor performance using probabilis tic classification Using AUC-Method-l we can remove 271 


those overly specific subgroups leading to reasonable posi tive and negative convex hulls Notice, however that CNZ SD still improves on CN2-standard after removing redun dant subgroups Figure 1 Example ROC curves on the Aus tralian data set: solid curvesfor AUC-Method 2 and dotted positive and negative convex hulls for AUC-Method-1 squares for CNZ-SD with additive weights and triangles for CN2 standard 5 Related work Various rule evaluation measures and heuristics have been studied for subgroup discovery IO 241 aimed at bal ancing the size of a group referred to as factor g with its distributional unusualness \(referred to as factor p The properties of functions that combine these two factors have been extensively studied the so-called 221p-g-space\221 lo An alternative measure q   was proposed in 13 for expert-guided subgroup discovery in the TPIFP space aimed at minimizing the number of false positives FP and maximizing true positives TP guided by generalization pa rameter par Besides such 221objective\222 measures of interest ingness some 221subjective\222 measure of interestingness of a discovered pattern can be taken into the account such as ac tionability 221a pattern is interesting if the user can do some thing with it to his or her advantage\222 and unexpectedness 221a pattern is interesting to the user if it is surprising to the user\222 211 Instance weights play an important role in boosting I21 and alternating decision trees 20 Instance weights have been used also in variants of the covering algorithm imple mented in rule learning approaches such as SLIPPER 6 RL 1151 and DAIRY 191 A variant of the weighted cover ing algorithm has been used also in the context of subgroup discovery for rule subset selection 13 6 Conclusions We have presented a novel approach to adapting stan dard classification rule learning to subgroup discovery To this end we have appropriately adapted the covering algo rithm the search heuristics, the probabilistic classification and the performance measure Experimental results on 17 UCI data sets demonstrate that CNZ-SD produces substan tially smaller rule sets where individual rules have higher coverage and significance These three factors are important for subgroup discovery smaller size enables better under standing. higher coverage means larger support, and higher significance means that rules describe discovered subgroups that are significantly different from the entire population We have evaluated the results of CN2-SD also in terms of AUC-Method-2 and shown insignificant increase in terms of the area under the ROC curve In further work we will evaluate the results also by using AUC-Method-1 where each subgroup establishes a sepa rate point in the ROC space and compare the results with the MIDOS subgroup discovery algorithm We plan to in vestigate the behavior of CN2-SD also in multi-class prob lems An interesting question to he verified with further ex periments, is whether the weighted versions of the CN2 al gorithm improve the significance of the induced subgroups also in the case when CN2 rules are induced without ap plying the significance test Finally we plan to use the CNZ-SD subgroup discovery algorithm for solving practical problems in which expert evaluations of induced subgroup descriptions is of ultimate interest Acknowledgements Thanks to Dragan Gamberger for joint work on the weighted covering algorithm and JosC Hernbdez-Orallo and Cesar Ferr-Ramirez for joint work on AUC The work reported in this paper was supported by the Slovenian Min istry of Education Science and Sport the IST-1999-11495 project Data Mining and Decision Support for Business Competitiveness A European Virtual Enterprise and the British Council project Partnership in Science PSP-IS Refer en c e s l R Agrawal H Mannila R Srikant H Toivonen, and A.I Verkamo Fast discovery of association rules In U.M Fayyad G Piatetski-Shapiro P Smyth and R Uthurusamy editors, Advances in Knowledge Discov ery and Data Mining 307-328 AAA1 Press 1996 2 B Cestnik Estimating probabilities: A crucial task in machine learning In L Aiello editor Proc of rhe 9rh European Conference on Artificial Inrelligence 147 149. Pitman 1990 272 


3 P Clark and R. Boswell Rule induction with CNZ Some recent improvements. In Y Kodratoff editor Pmc of rhe 5rh European Working Session on Learn ing 151-163 Springer, 1991 141 P Clark and T Niblett The CNZ induction algorithm Machine Learning 3\(4 261-283 1989 5 W.W Cohen 1995 Fast effective rule induction. In Pmc of rhe 12th Intermrional Conference on Ma chine Learning 115-123 Morgan Kaufmann, 1995 161 W.W Cohen and Y Singer A simple fast and ef fective rule learner In Pmc of AAAI/lAAI 335 342. American Association for Artificial Intelligence 1999 171 S Dieroski B. Cestnik, and 1 Petrovski. \(1993 Us ing the m-estimate in rule induction Journal of Compuring andlnformarion Technology 1\(1 46 1993 8 U.M Fayyad and K.B Irani K.B Multi-interval dis cretisation of continuous-valued attributes for classi fication learning In R Bajcsy editor Pmc of the 13th Inrernarioml Joint Conference on Artificial In telligence 1022-1027 Morgan Kaufmann 1993 19 D Hsu 0 Etzioni and S Soderland A redundant cov ering algorithm applied to text classification In Pmc of the AAA1 Workshop on Learning from Tar Cate gorization American Association for Artificial Intel ligence, 1998 IO W Klosgen. Explora A multipattern and multistrat egy discovery assistant In U.M Fayyad G Piatetski Shapiro P Smyth and R Uthurusamy editors Ad vances in Knowledge Discovery and Data Mining 249-271 MITPress 1996 1111 C Fem-Ramirez P.A Flach and 1 Hemandez Orallo. Learning decision trees using the area under the ROC curve In Pmc of the 19th Internarional Conference on Machine Learning 139-146 Morgan Kaufmann 2002 I21 Y Freund and R.E Shapire. Experiments with a new boosting algorithm In Pmc of the 13th International Conference on Machine Learning 148-156 Morgan Kaufmann 1996 13 D Gamberger and N LavraE Descriptive induction through subgroup discovery A case study in a medi cal domain In Pmc of the 19th Internarional Confer ence on Machine Learning 163-170 Morgan Kauf mann 2002 I41 N Lavraf P Flach and B Zupan Rule evaluation measures A unifying view In Pmc of the 9th Inter national Workshop on Inducrive Logic Pmgramming 74-185 Springer 1999 I51 Y Lee B.G. Buchanan, and J.M. Aronis Knowledge based learning in exploratory science Learning rules to predict rodent carcinogenicity Machine Learning 30 217-240 1998 I61 R.S Michalski 1 Mozeti I Hong and N LavraE The multi-purpose incremental learning system AQl5 and its testing application on three medical domains In Pmc 5th National Conference on Artificial Inrelli gence 104-1045 Morgan Kaufmann, 1986 I71 P.M Murphy and D.W Aha UCI repos itory of chine learning databases http://www.ics.uci edurmleamiMLRepository.html Irvine CA University of California Department of Information and Computer Science 1994 I81 F Provost andT Fawcett Robust classification forim precise environments Machine Learning 42\(3 203 231,2001 I91 R.L Rivest Learning decision lists Machine Learn ing 2\(3 229-246 1987 201 R.E Schapire and Y Singer Improved boosting algo rithms using confidence-rated predictions In Pmc of the 11th Conference on Computational Learning The ory 80-91 ACM Press 1998  A Silbenchatz and A Tuehilin On subjective mea sures of interestingness in knowledge discovery In Pmc of the Isr Internarional Conference on Knowl edge Discovery and Data Mining 275-281 1995 1221 L Todorovski P Flach and N Lavraf Predictive performance of weighted relative accuracy In D.A Zighed 1 Komorowski, and J Zytkow, editors Pmc of the 4rh European Conference on Principles of Data Mining and Knowledge Discovery 255-264 Springer 2000 231 I.H. Witten and E Frank Data Mining: PracricalMa chine Learning Tools and Techniques wirh Java Imple mentations Morgan Kaufmann 1999 24 S Wrobel An algorithm for multi-relational discov ery of subgroups In Pmc of the 1st European Sym posium on Principles of Data Mining and Knowledge Discovery 78-87 Springer. 1997 273 


association-cube, base-cube and population-cube are derived from the volume cube; the confidence-cube is derived from the association cube and population cube and the support-cube is derived from the associationcube and base-cube. The slices of these cubes shown in Figure 2 correspond to the same list of values in dimension merchant, time, area and customer_group  Multidimensional and multilevel rules Representing association rules by cubes and underlying cubes by hierarchical dimensions, naturally supports multidimensional and multilevel rules. Also these rules are well organized and can be easily queried  First, the cells of an association cube with different dimension values are related to association rule instances in different scopes. In the association cube CrossSales cell CrossSales product \221A\222, product2 \221B\222  customer_group 221engineer\222, merchant \221Sears\222, area \221Los Angeles\222, time 221Jan98\222 represents the following multidimensional rule x 316 Customers: buy_product\(x, \221A\222 336 buy_product\(x,\221B\222  275 customer_group = \221engineer\222, merchant = \221Sears\222, area 221Los  Angeles\222, time =  \221Jan98\222 If this cell has value 4500, and the corresponding cell in the population cube has value 10000, then this rule has confidence 0.45 Next as the cubes representing rules can have hierarchical dimensions, they represent not only multidimensional but also multi-level association rules. For example, the following cells CrossSales\(product \221A\222, product2 \221B\222, customer_group 221engineer\222, merchant \221Sears\222, area \221 California 222, time 221Jan98\222 CrossSales\(product \221A\222, product2 \221B\222, customer_group 221engineer\222, merchant \221Sears\222, area \221 California 222, time 221 Year98 222 represent association rules at different area levels \(i.e the city level and the state level\d different time levels \(i.e., the month level, the year level x 316 Customers: buy_product\(x, \221A\222 336 buy_product\(x, \221B\222  275 customer_group = \221engineer\222, merchant =  \221Sears\222, area 221 California 222, time =  \221Jan98\222 x 316 Customers: buy_product\(x, \221A\222 336 buy_product\(x, \221B\222  275 customer_group = \221engineer\222, merchant =  \221Sears\222, area 221 California 222, time =  \221 Year98 222 The cell CrossSales\(product \221A\222, product2 \221B\222,  customer_group 221top\222, merchant \221top\222, area \221top\222,  time \221top\222 represents the customer-based cross-sale association rule for all customers, merchants, areas, and times in the given range of these dimensions, expressed as x 316 Customers: buy_product\(x, \221A\222 336 buy_product\(x, \221B\222 4.3  Generating Association Rule Related Cubes The basic task of our OLAP based association rule mining framework, either at the GDOS or at an LDOS is to convert a volume cube i.e. the cube representing the purchase volumes of customers dimensioned by product  area etc, into an association cube a base cube and a population cube These cubes are then used to derive the confidence cube and the support cube of multidimensional association rule instances. The following general steps are involved in cross-sale association rule mining 267  Roll up the volume cube SaleUnits by aggregating it along merchant, time, area dimensions 267  Derive cube NumOfBuyers from SaleUnits based on the antecedent condition SaleUnits 0 267  Populate cube NumOfShoppers by the counts of customers dimensioned by merchant, area  time not by product\at satisfy the antecedent conditions 267  Derive cube CrossSales from SaleUnits based on the association conditions SaleUnits  product  p 1  0 and SaleUnits  product2  p 2 0 267  Derive cube Confidence and cube Support using cell-wise operations 214  Confidence = CrossSales  NumOfBuyers 214  Support  CrossSales  NumOfShoppers  Cubes Confidence  Support  CrossSales are dimensioned by product  product2 customer_group,merchant  time, area NumOfBuyers is dimensioned by product  customer_group, merchant time, area  NumOfShoppers is dimensioned by customer_group, merchant  time, area Rules with confidence and support that exceed specified thresholds  may be considered interesting 4.4. Rules with Conjoint Items Cubes with conjoint dimensions can be used to represent refined multidimensional association rules For example, using OLAP, we can derive association rules across time  Time-variant or temporal association rules such as 


x 316 Customers buy_product\(x,\222 A\222, \221 Jan98\222  336 buy _product\(x, \221B\222, \221 Feb98\222   275 area = \221Los Angeles\222 can be used to answer such questions as \223 How are  the sales of B in Feb98  associated with the sales of A in Jan98 224 The items in this rule are value pairs of dimensions product and time In order to specify this kind of association rule we introduce a conjoint dimension product, time and mirror it with dimension product2, time2 This allows a cell in the association cube to cross two time values. Accordingly, the cubes related to association rule mining are defined as follows Association cube  CrossSales.2 \(<product, time>, <product2, time2 customer_group, merchant, area  Population cube  NumOfBuyers.2  \(<product, time>, customer_group merchant, area Base cube  NumOfShoppers.2  \( customer_group, merchant, area Confidence cube Confidence.2 \(<product, time>, <product2, time2 customer_group, merchant, area Support  cube  Support.2  product, time>, <product2, time2 customer_group, merchant, area  The steps for generating these cubes are similar to the ones described before. The major differences are that a cell is dimensioned by, besides others product, time and product2, time2 and the template of the association condition is  SaleUnit s  product p 1 time t 1  0 and  SaleUnits  product2 p 2 time2 t 2  0 where, in any instance of this condition, the time expressed by the value of time2 is not contained in the time expressed by the value of time The template of the antecedent condition is SaleUnits   product p 1 time t 1  0 In general, other dimensions such as area may be added to the conjoint dimensions to specify more refined rules 4.5. Functional Association Rules A multidimensional association rule is functional if its predicates include variables, and the variables in the consequent are functions of those in the antecedent.  For example, functional association rules can be used to answer the following questions, where a_month and a_year are variables q  What is the percentage of people in California who buy a printer in the next month after they bought a PC x 316 Customer buy_product\(x, \221PC\222, a_ month 336 buy_product\(x, \221printer\222, a_month+1  275 area = \221California\222 q  What is the percentage of people who buy a printer within the year when they bought a PC  x 316 Customer: buy_product\(x, \221PC\222, a_ year 336 buy_product\(x, \221printer\222, a_year 275 area = \221California\222 To be distinct, we call the association rules that are not functional as instance association rules; e.g x 316 Customer: buy_product\(x,\222 PC\222, \221Jan98\222 336 buy_product\(x,\222 printer\222, \221Feb98\222  275 area =  \221California\222 Time variant, functional association rules can be derived from time variant, instance association rules through cube restructuring. Let us introduce a new dimension time_delta that has values one_day, two_day 205, at the day level, and values one_month, two_month, \205, at the month level, etc. Then, let us consider the following functional association rule related cubes Association cube  CrossSales.3 \(product, product2, customer_group merchant, area, time_delta  Population cube  NumOfBuyers.3 \(product, customer_group, merchant area Base cube  NumOfShoppers.3 \( customer_group, merchant, area Confidence cube  Confidence.3 \(product, product2, customer_group merchant, area, time_delta Support cube  Support.3 \(product, product2, customer_group, merchant area, time_delta The association cube CrossSales.3  can be constructed from CrossSales.2   The cell values of CrossSales.2  in the selected time and time2 ranges are added to the corresponding cells of CrossSales.3 For example, the count value in cell  CrossSales.2\(<PC, Jan98>, <printer, Feb98>\205 is added to cell \(bin CrossSales.3\(PC, printer, one_month,\205 


It can also be added to cell CrossSales.3\(PC, printer one_year,\205 5  Distributed and Incremental Rule Mining There exist two ways to deal with association rules 267  Static that is, to extract a group of rules from a snapshot, or a history, of data and use "as is 267  Dynamic that is, to evolve rules from time to time using newly available data We mine association rules from an e-commerce data warehouse holding transaction data. The data flows in continuously and is processed daily Mining association rules dynamically has the following benefits 267  223Real-time\224 data mining, that is, the rules are drawn from the latest transactions for reflecting the current commercial trends 267  Multilevel knowledge abstraction, which requires summarizing multiple partial results. For example association rules on the month or year basis cannot be concluded from daily mining results. In fact multilevel mining is incremental in nature 267  For scalability, incremental and distributed mining has become a practical choice Figure 3: Distributed rule mining Incremental association rule mining requires combining partial results. It is easy to see that the confidence and support of multiple rules may not be combined directly. This is why we treat them as \223views\224 and only maintain the association cube, the population cube and the base cube that can be updated from each new copy of volume cube. Below, we discuss several cases to show how a GDOS can mine association rules by incorporating the partial results computed at LDOSs 267  The first case is to sum up volume-cubes generated at multiple LDOSs. Let C v,i be the volume-cube generated at LDOS i The volume-cube generated at the GDOS by combining the volume-cubes fed from these LDOSs is 345   n i i v v C C 1  The association rules are then generated at the GDOS from the centralized C v  214  The second case is to mine local rules with distinct bases at participating LDOSs, resulting in a local association cube C a,I a local population cube C p,I  and a local base cube C b,i at each LDOS. At the GDOS, multiple association cubes, population cubes and base cubes sent from the LDOSs are simply combined, resulting in a summarized association cube and a summarized population cube, as 345   n i i a a C C 1   345   n i i p p C C 1  and 345   n i i b b C C 1  The corresponding confidence cube and support cube can then be derived as described earlier. Cross-sale association rules generated from distinct customers belong to this case In general, it is inappropriate to directly combine association cubes that cover areas a 1 205, a k to cover a larger area a In the given example, this is because association cubes record counts of customers that satisfy   customer product merchant time area Doe TV Dept Store 98Q1 California Doe VCR Dept Store 98Q1 California customer product merchant time area Doe VCR Sears 5-Feb-98 San Francisco Joe PC OfficeMax 7-Feb-98 San Francisco customer product merchant time area Doe TV Fry's 3-Jan-98 San Jose Smith Radio Kmart 14-Jan-98 San Jose Association   population      base          confidence      support cube               cube                cube         cube                cube LDOS LDOS GDOS 


the association condition, and the sets of customers contained in a 1 205, a k are not mutually disjoint. This can be seen in the following examples 214  A customer who bought A and B in both San Jose and San Francisco which are covered by different LDOSs , contributes a count to the rule covering each city, but has only one count, not two, for the rule A  336  B covering California 214  A customer \(e.g. Doe in Figure 3\who bought a TV in San Jose, but a VCR in San Francisco, is not countable for the cross-sale association rule TV  336 VCR covering any of these cities, but countable for the rule covering California. This is illustrated in Figure 3 6  Conclusions In order to scale-up association rule mining in ecommerce, we have developed a distributed and cooperative data-warehouse/OLAP infrastructure. This infrastructure allows us to generate association rules with enhanced expressive power, by combining information of discrete commercial activities from different geographic areas, different merchants and over different time periods. In this paper we have introduced scoped association rules  association rules with conjoint items and functional association rules as useful extensions to association rules The proposed infrastructure has been designed and prototyped at HP Labs to support business intelligence applications in e-commerce. Our preliminary results validate the scalability and maintainability of this infrastructure, and the power of the enhanced multilevel and multidimensional association rules. In this paper we did not discuss privacy control in customer profiling However, we did address this issue in our design by incorporating support for the P3P protocol [1 i n  ou r data warehouse. We plan to integrate this framework with a commercial e-commerce system References 1  Sameet Agarwal, Rakesh Agrawal, Prasad Deshpande Ashish Gupta, Jeffrey F. Naughton, Raghu Ramakrishnan, Sunita Sarawagi, "On the Computation of Multidimensional Aggregates", 506-521, Proc. VLDB'96 1996 2  Surajit Chaudhuri and Umesh Dayal, \223An Overview of Data Warehousing and OLAP Technology\224, SIGMOD Record Vol \(26\ No \(1\ 1996 3  Qiming Chen, Umesh Dayal, Meichun Hsu 223 OLAPbased Scalable Profiling of Customer Behavior\224, Proc. Of 1 st International Conference on Data Warehousing and Knowledge Discovery \(DAWAK99\, 1999, Italy 4  Hector Garcia-Molina, Wilburt Labio, Jun Yang Expiring Data in a Warehouse", Proc. VLDB'98, 1998 5  J. Han, S. Chee, and J. Y. Chiang, "Issues for On-Line Analytical Mining of Data Warehouses", SIGMOD'98 Workshop on Research Issues on Data Mining and Knowledge Discovery \(DMKD'98\ , USA, 1998 6  J. Han, "OLAP Mining: An Integration of OLAP with Data Mining", Proc. IFIP Conference on Data Semantics DS-7\, Switzerland, 1997 7  Raymond T. Ng, Laks V.S. Lakshmanan, Jiawei Han Alex Pang, "Exploratory Mining and Pruning Optimizations of Constrained Associations Rules", Proc ACM-SIGMOD'98, 1998 8  Torben Bach Pedersen, Christian S. Jensen Multidimensional Data Modeling for Complex Data Proc. ICDE'99, 1999 9  Sunita Sarawagi, Shiby Thomas, Rakesh Agrawal Integrating Association Rule Mining with Relational Database Systems: Alternatives and Implications", Proc ACM-SIGMOD'98, 1998   Hannu Toivonen, "Sampling Large Databases for Association Rules", 134-145, Proc. VLDB'96, 1996   Dick Tsur, Jeffrey D. Ullman, Serge Abiteboul, Chris Clifton, Rajeev Motwani, Svetlozar Nestorov, Arnon Rosenthal, "Query Flocks: A Generalization of Association-Rule Mining" Proc. ACM-SIGMOD'98 1998   P3P Architecture Working Group, \223General Overview of the P3P Architecture\224, P3P-arch-971022 http://www.w3.org/TR/WD-P3P.arch.html 1997 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



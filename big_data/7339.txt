Web User Proìling using Hierarchical Clustering with Improved Similarity Measure Nilani Algiriyage Sanath Jayasena and Gihan Dias Department of Computer Science  Engineering University of Moratuwa Sri-Lanka Email rangika.nilani@gmail.com sanath@cse.mrt.ac.lk gihan@cse.mrt.ac.lk Abstract Web user proìling targets grouping users in to clusters with similar interests Web sites are attracted by many visitors and gaining insight to the patterns of access leaves lot of information Web server access log les record every single request processed by web site visitors Applying web usage mining techniques allow to identify interesting patterns In this paper we have improved the similarity measure proposed by Vel  asquez et al and used it as the distance measur e i n a n agglomerati v e hierarchical clustering for a data set from an online banking web site To generate proìles frequent item set mining is applied over the clusters Our results show that proper visitor clustering can be achieved with the improved similarity measure I I NTRODUCTION With the evolution of the Internet and continuous growth of the global information infrastructure the amount of data collected has been drastically increased Web server access log les collect substantial data about web visitor access patterns Data mining techniques can be applied on such data which is known as Web Mining to reveal lot of useful information about navigational patterns Generally a proìle contains facts about someoneês interests and behavior The content of the user proìle can be changed based on the context However most common contents of a user proìle can be userês interaction preferences userês knowledge userês interests background skills and knowledge etc In the web usage domain user proìling applies to establishing groups of users exhibiting similar browsing behavior User proìling helps web site owners in multiple ways:personalization system improvements such as load balancing data distribution policies improve web siteês structure develop recommendation systems business intelligence etc Data mining speciìcally web usage mining has been applied by many researchers to handle the problem of web user proìling Mobarsher et al introduced the taxonomy of web mining for the data mining activities performed on web data There are major two types of web mining which is refereed as web content mining and web usage mining Web content mining engages in automatically searching information resources in web pages and web usage mining is related to discovering user access patterns from web usage data We have focused on the later one web usage mining in the context of web visitor proìling In this work we have improved the similarity measure proposed by Vel  asquez et al and applied it in a hierarchical clustering Our similarity measure has two major portions a measure based on the Lavenshtein distance to nd similarity between access sequences and a measure based on normalized time values spent on each web page We used frequent item set mining to generate proìles from the clustered data In the results we show that proper proìling can be achieved for our data set using the improved similarity measure The rest of the paper is organized in the following way Section II presents the related work and in section III we discuss the methodology we followed for web user proìling In section IV experimental evaluation and results are described and nally we discuss the conclusions in section V II R ELATED W ORK In the research community user proìling is studied in different context Among the web mining techniques applied clustering seems most widely used method for grouping similar users Xu et al ha v e tested the feasibility of applying kmeans algorithm to cluster web users Fuzzy clustering has been applied in multiple research works The idea behind the fuzzy clustering is to enable the generation of overlapping clusters This has been successfully applied in the web usage mining process by Nasraoui et al Surya v anshi et al 5 and Castellano et al In order to understand similarity between two visitors similarity measures are required Jitian et al talks about different similarity measures that can be applied for web log data Xie et al has proposed a distance measure for clustering based on Dempster-Shafers theory of combining evidence Ve l  asquez et al ha v e proposed a similarity measure based on the content of the respective web pages and the similarity between different page sequences They have derived the measure in the following way Let  and  be two visitor behavior vectors of cardinality C  and C  respectively and    is a function that applied over  or  that returns the navigation sequence corresponding to a visitor vector sm     dG        1     k 1  k  dp  p k p k  1 where dG is the similarity between sequences of pages visited   min  C  C   and  k is an indicator of visitorês 978-1-4799-1740-2/15/$31.00 c  2015 IEEE 


interest of the web page visited The term  k is deìned as  k  min  t k  t k t k t k   The term dp  p k p k  is the similarity of pages visited This is the angle cosine similarity between two word-page vectors They have applied it in a Self Organizing Feature Maps SOFM clustering for user session clustering How ever we see some drawbacks in the proposed similarity measure and in this work the measure is improved We have applied it in a hierarchical clustering Hierarchical clustering b uilds a hierarchy o f clusters decomposing a given set of data objects Generally there are two types of hierarchical clustering based on the way the hierarchy is formed  Agglomerative:Agglomerative which is also known as bottom-up merges the objects or groups that are close to one another until all of the groups are merged into one or until the termination condition is met  Divisive:Which is also known as top-down approach starts with all of the objects in the same cluster and in each iteration a cluster is split up to smaller clusters until there is one object in each cluster or termination condition is met We used the improved similarity measure in an agglomerative hierarchical clustering and visualized it in a dendrogram Dendrogram is a tree structure which is used to represent the results of a hierarchical clustering It shows how objects are grouped in step by step We further used frequent itemset mining in order to generate user proìles from the identiìed clusters III D ATA P REPARATION We selected a web site of an e-banking service provider in Sri Lanka having following features  A static web site with proper page naming  Web site has a log-in facility and all registered users have to log-in before performing transactions on the web site  Several types of users interact with the web site daily and their interests are different Web site has 170 web pages Details of our data set is discussed in Section IV Our methodology and work ow is summarized in Fig 1 Data cleansing and formatting are the two major preprocessing operations performed Details of the data preparation steps are described in the following A Data Formatting Web servers record requests processed by the server in different formats We have observed that Apache combined log format is very comprehensive Original log les were converted in to Apache combined log format B Data cleansing During the process of data cleansing we have removed lines of the log le which were not fully recorded and did not satisfy the sufìcient length of a log line Keeping these data in the log le would result in unclear clusters We observed that some records of the log le were not sorted We sorted the log le in the ascending order of the recorded time value C User-Session Identiìcation We have used IP address user-agent string and session timeout period in order to identify user sessions following the methodology proposed by Mobasher et al This time period has been considered as 1800 seconds and if the interval is more than the deìned period existing session is closed and new one is initiated D Remove web-crawler sessions For the purpose of user-proìling we are interested only on requests from human users Hence we have followed the methodology proposed by Algiriyage et al to remo v e web crawler sessions E Low support page ltering The number of web pages browsed during a user-session had a large variation For the purpose of proìling we considered only the sessions having browsed more than three pages We ltered out others as accidentally visited the web site without having any interest over the contents F Filter Image and Styling Files For the purpose of human visitor proìling we were not interested in image les Hence we removed extensions cache css png gif jpeg js jpg ico axd ashx xml and considered only web page requests such as asp aspx htm html php pdf and doc  G Navigation sequence identiìcation An example web site with 10 web pages is shown in the Fig 2 6 4 5 1 2 3 10 7 8 9 Fig 2 Web site with navigational paths 


      Fig 1 Methodology for human visitor proìling Suppose visitors in two visitor sessions browsed the web site in the following way S 1=1  2  2  7  2  5  5  6 S 2=1  3  3  7  7  9 Based on the traversal patterns in two sessions we can derive the navigation sequences as Seq  S 1  1  2  7  5  6 Seq  S 2  1  3  7  9 In this case we have not considered backward traversals Hence the cardinality  C  of the two sequences can be given as C  S 1  5 C  S 2  4 H Prepare Session-page Matrix Once the navigation sequence is identiìed we prepared the session-page matrix Table I to show the web page sequences visited in each session As previously described our methodology for session identiìcation was grouping IP address user-agent within 30 minute time period Due to this methodology there can be some sessions from the middle of their activities To avoid the confusions of such sessions we considered only the sessions starting with sign-in and home 


pages in the test data set Further in the session-page matrix we did Scipy encoding to map string page names into integer ones TABLE I Session-page Matrix  Session Pages 1 6,61,70,76,101,110,112,134,161 2 6,61,70,72,76,81,112,136,143 3 6,61,101,102,112,161,162  6,61,70,73,76,101,110,112,161,168 n 8,28,29,30,35,43,44,45,46,49,59,61,114,121 I Prepare Session-time Matrix Session-page matrix was prepared to show the web page sequences browsed in each session Another matrix is prepared to show the time spent on each page within the session This matrix which can be called as Session-time matrix is shown in Table II TABLE II Session-time Matrix Session p1,p2,p3,p4,p5,p6,p7 1 0.5,1.0,2.1,1.2,2.0,1.5,0.7 2 1.0,1.2,1.5,0.0,0.0,0.0,0.0 3 2.3,1.0,1.6,2.3,0.0,0.0,0.0  0.9,2.0,2.4,2.5,2.0,1.5,0.0 n 0.0,0.0,0.9,1.4,0.0,0.0,0.0 J Calculate Lavenshtein Distance To compare the similarity between two sequences we need to use a dissimilarity measure Lavenshtein distance which is also referred as edit distance measures the similarity between two strings For two sequences a  a 1   a x  and b  b 1   b y  Lavenshtein distance is deìned as LD  a x b y         max  x y  if min  x y  min    L  a b   x  1 y  L  a b   x y  1 j  Otherwise L  a b   x  1 y  1  1 a x   b y  2 For example in the sequences that we discussed earlier  and 1,3,7,9 the La v enshtein distance is 3 That is 3 insert/update/delete operations are required to transform  to 1,3,7,9 W e calculated the similarity between the two visiting sequences using Equation 3 sim  S 1 S 2  1   LD  seq  S 1 seq  S 2 max  C  S 1 C  S 2  3 We used a bit different measure from the Vel  asquezês approach in calculation of the similarity using Levenshtein distance For the discussed example similarity of the sequences is 0.4 based on the Equation 3 We refer this similarity which is based on Lavenshtein distance as dLD  K Comparison of Visitor Sessions To compare the visitor sessions a similarity measure is required We propose following measure based on the similarity of navigation sequences and time spent on web pages To derive the equation we followed the notations described 1 Similarity Between Navigational Sequences Let S x and S y be two visitor sessions and F is a function applied over S x and S y which returns navigation sequences Cardinality of the two sequences are C x and C y The distance between two sequences is calculated using Levenshtein distance based measure described in Equation 3 2 Similarity Based on Time Spent Web visitors spend time on web pages based on the interest and relative importance of the content to them Preparation of session-time matrix was described in an earlier section In the Vel  asquez et al approach described in equation 1 for the term  k they have considered that the time spent on web page is proportional to the interest the visitor has in its contents If the times spent by visitor  and  on k th page that they have visited are close to each other the value  k  becomes close to 1 and otherwise it will be close to 0 The problem of this approach for  k is that time is not normalized For example the value will be 0.5 for following two cases But there is a huge difference between the times t  k 2 t  k 4 T k 2  4=0  5 t  k 50 t  k  100 T k 50  100  0  5 To eliminate the problem we normalized the time value using standard score\(Z-score Suppose time spent on page n is t n and the mean of time spent on page n by all visitors is  and standard deviation is   z  t n    4 Then we calculate the euclidean distance between the Z-values ED  z x z y  n  i  z xi  z yi  2 5 We refer this similarity which is based on Euclidean distance as dED  


3 Proposed Similarity Measure We propose a similarity measure based on the web page access sequence and time spent on each page Let s  and s  are two visitor sessions and S  and S  are the related resource request pattern sequences sim  s  s   dLD  S  S    dED  z x z y  6 Formulation of dLD and dED is discussed in Equations 3 and 5 respectively IV E XPERIMENTAL E VALUATION We obtained web server access log les of a online banking service provider in Sri Lanka for a period of two weeks Size of the log le is 243.6MB and it contained 841,196 HTTP requests before the preprocessing stages But for the hierarchical clustering we considered a portion of the data set containing 71,256 HTTP requests before and 71,238 requests after pre-processing Summary of the data set is presented in Table III TABLE III Summary of the log le  Number of HTTP requests before pre-processing 71,256 Number of HTTP requests after pre-processing 71,238 Total number of visitor sessions 2,033 Number of possible web crawler sessions 185 Number of possible Human Visitor sessions 1,848 Number of visitor sessions with initiating sessions 1,212 Number of visitor sessions after low click page ltering 1,169 The complexity of agglomerative clustering for a large dataset is faster than divisive clustering Hence we applied the proposed similarity measure in an agglomerative hierarchical clustering Fig 3 shows the dendrogram generated We have used a color threshold value to show different clusters in the dendrogrm Dendrogram is a tree-structured graph used to visualize the results of a hierarchical clustering A dendrogram can be pruned at any level to generate clusters In this experiment we pruned the dendrogram at level 10 to obtain 10 visitor clusters Generating proìles or gaining more insight to the clusters generated require some additional work We performed a frequent item set mining task in order to understand the behavior patterns in each cluster With the highest conìdence and support values following are the clusters generated in Table IV To understand and describe the clusters we logged-in to the online banking web site as different types of users and performed multiple transactions Based on our browsing patterns in the access log le generated clusters were described in the Table IV According to the clustering results some users logged-in to the system and has perform nothing afterward and the others performed different types of transactions In some clusters there were random browsing behavior which was hard to understand The following is an example for such random browsing behavior Ex 6,61,70,72,236,237,241,6,61,70,72,242,243,244,6,61,70,72 250,251,253,6,61,70,72 TABLE IV Cluster results No Pages Visited Description No of sessions 1 6,61,112 successfully logged-in but nothing was done after the loging 52 1 8,16,24,34 successfully logged-in as corporate users and performed transactions 261 3 6,61,70,76 successfully logged-in as personal users and performed transactions 302 4 6,61,101,112,161 successfully logged-in as personal users and performed transactions 210 5 6,61,70,72 Some strange behavior 2 6 6,61,70,76 successfully logged-in as personal users and performed transactions 207 7 8,28,43,44 successfully logged-in as corporate users and performed transactions 96 8 6,61,70,76 Some strange and random behavior 1 9 5,15,17 New users who do not log-in to the web site 34 10 6,61,8 Some random browsing behavior 4 In one cluster which contained a single user session the behavior was very strange that the visitor traversed a long path without successfully doing any transaction V C ONCLUSION We introduced a new similarity measure to group human users based on their browsing behavior The similarity measure was included in a agglomerative hierarchical clustering algorithm to identify user clusters Our results show that there are clear clusters among the visitors/users of the web site Derived user proìles can be used by the banking organization to get better knowledge about their customer base And also this can be used as an intrusion detection tool where we found some clusters having strange browsing patterns Any way further research has to be carried out to understand how well this clustering helps in intrusion detection As future works we can consider the content of web pages and more advanced features for the proposed similarity measure We have applied the methodology on online banking web server logs To get a better idea this can be applied in multiple web log les In our approach the similarity measure is used in a agglomerative hierarchical clustering algorithm This can be used other clustering algorithms and can test the generated user proìles for further improvements A CKNOWLEDGMENT The authors would like to thank LK domain registry and Techcert for providing necessary data sets and facilities to conduct this research successfully R EFERENCES  J D V e l  asquez H Yasuda and R Weber A new similarity measure to understand visitor behavior in a web site IEICE transactions on Information and Systems  pp 389Ö396 2004  R Coole y  B Mobasher  and J Sri v asta v a  Information and pattern discovery on the world wide web in Proc 9 th Intl Conf on Tools with Artiìcial Intelligence  p 558 1997  J Xu and H Liu W eb user clustering analysis based on kmeans algorithm in International Conference on Information Networking and Automation ICINA  vol 2 pp V2Ö6 2010 


Fig 3 Dendrogram for the hierarchical clustering  O Nasraoui H Frigui A Joshi and R Krishnapuram Mining web access logs using relational competitive fuzzy clustering in Proc 8 th Intl Conf on Fuzzy Systems Association World Congress  pp 195Ö204 1999  B S Surya v anshi N Shiri and S P  Mudur   An ef cient technique for mining usage proìles using relational fuzzy subtractive clustering in Proceedings of the International Workshop on Challenges in Web Information Retrieval and Integration  pp 23Ö29 2005  G Castellano F  Mesto M Minunno and M A T orsello W eb user proìling using fuzzy clustering in Applications of Fuzzy Sets Theory  pp 94Ö101 2007  J Xiao Y  Zhang X Jia and T  Li Measuring similarity of interests for clustering web-users in Proc 12 th Australasian database Conf  pp 107Ö114 2001  Y  Xie and V  V  Phoha W eb user clustering from access log using belief function in Proc 1 st Intl Conf on Knowledge Capture  pp 202Ö208 2001  H Jia wei and M Kamber  Data mining concepts and techniques  San Francisco CA itd Morgan Kaufmann  vol 5 2001  scip y cluster hierarchy dendrogram-nump y and scip y documentation 2014,may 11 A v ailable:http://docs.scip y or g/doc/scip y0.14.0/reference/generated/scipy.cluster.hierarchy.dendrogram.html   Apache http serv er v ersion 2.2  Online A v ailable:http://httpd.apache.org/docs/2.2/logs.html  N Algiriyage S Jayasena G Dias A Perera and K Dayananda Identiìcation and characterization of crawlers through analysis of web logs in Proc 8 th IEEE Intl Conf on Industrial and Information Systems ICIIS  pp 150Ö155 2013  Encoding cate gorical features  Online A v ailable:http://scikitlearn.org/stable/modules/preprocessing.html 


E Impacted Coef\002cient of the Additional Itemset De\002nition 13 The impacted coef\002cient of an additional itemset is to describe how effective this itemset is to manufacture the derivative itemset from underlying itemset denoted as AU G 001 X j X 0   de\002ned as AU G 001 X j X 0   r C 2 001 X j X 0   W 2 001 X j X 0  2 14 This equation averages the value of C 001 X  in Equation 9 and W 001 X  in Equation 11 Here we use the Quadratic Mean QM also known as Root-Mean Square to measure the signi\002cance of the itemset 001 X in terms of both utility and relationship perspectives because it represents the sample standard deviation of the difference between W and C  thus the result cannot be affected heavily by the smaller value It is easy to prove QM 2  X    X  2  033 2  X  15 Here X and 033  X  stand for the arithmetic mean and the standard deviation of W and C  We also tried another measurement by Harmonic Mean HM as a baseline which is proven to be less effective in our experiments For a speci\002c X 0  for each itemset 001 X to be considered the higher AUG means this itemset is likely to impel the underlying itemset into higher utility itemset On the contrary the lower the AUG is the lower utility that derivative itemset might be As all the AUG would be calculated only the largest AUG value itemset will be chosen F The CUARM Algorithm In this section an algorithm named Combined UtilityAssociation Rule Mining CUARM is proposed to discover all the actionable combined utility-association rules At the beginning of the algorithm it picks all UIs as candidates For each UI all the combined patterns are discovered with their AUGs which form a combined pattern cluster as in Equation 2 and only the most effective pattern would be selected In addition if two patterns are coupled with utility increment and decrement a combined pattern pair forms The input is the transaction database including all transactions with the utility of each item and the output is the combined pattern pairs their underlying itemset and the corresponding utilities In line 1 we prepare all the itemsets with their utilities in the alphabetical order and the length of longest itemset In lines 2-5 we start with each of the UIs named itemset 0 with its utility U 0  In lines 6-11 the DIs are ready and we calculate their AUGs In line 12-13 we select the pattern with max AUG values as CUAR V E XPERIMENTS In this section we conduct intensive experiments to evaluate the proposed methods Our experiments were run on a PC with a 2.30 GHz Intel Core 16 gigabyte memory CUARM is implemented in Java Two real datasets and two synthetic datasets are used for the experiments The real Algorithm 1 CUARM Input  Transaction database D  including the utility U  X  of each item in D Output  All actionable combined utility-association rules 1 Get all itemsets utilities via UG-Tree  2 Get the length of longest itemset lmax  3 for len  1 len  lmax len do 4 for Itemset whose length is equal to len do 5 Get itemset 0 with U 0 itemset-utility 6 for itemset.length  len do 7 Check inclusive and utility changes 8 Get itemset 1 with U 1  9 Calculate C 10 Scan the database get W 11 Calculate AUG 12 Selected max one 13 Present this utility-association rule TABLE VIII C HARACTERISTICS OF DATASETS Dataset Number of Transactions Number of Items Average Length Retail 2 88162 16470 10.3 Chainstore 3 1112949 46086 7.3 t20i6d100k 100000 658 13.7 c20d10k 10000 187 13 datasets are Retail 2 and Chainstore 3  and the synthetic datasets are t20i6d100k and c20d10k  The parameters of the datasets are listed in Table VIII A Comparison of Two Functions for Calculating Impacted Coef\002cient Here we propose two functions for calculating the impacted coef\002cient One is the quadratic mean QM which is adopted in this paper the other function is the harmonic mean HM which is proved to be less accurate in the experiments Those itemsets with a good coef\002cient measurement should be associated with both high frequency and high utility growth we thus can separate the database randomly If the output itemsets discovered in each sub-database are stable we can assume that this measurement is suitable The experiments were conducted on the Retail dataset for the sake of simply examining the QM function The top 100 experimental results are selected and shown in Fig 4 The 002gure on the left shows the comparison between UP-Growth and QM while the 002gure on the right shows the result of QM and HM on C 001 X  and W 001 X   The database is split into 10 parts randomly The 002rst part contains 10 transactions in the database and each later part contains 10 more transactions than the former part such that the second part contains 20 and the last part is 100 The X axis is the k th  1 024 k 024 10  part of the database and the Y axis is the match ratio which means the ratio of the exact patterns found in the k th part 2 http://www.philippe-fournier-viger.com/spmf/index.php?link=datasets.php 3 http://cucis.ece.northwestern.edu/projects/DMS/MineBench.html 


Fig 4 The Comparison of HM QM and UP-Growth matching with the  k  1 th part As seen from the 002gures the QM method outperforms both HM and UP-Growth B Experimental Evaluation of CUARM Next we present the experimental results of comparing derivative itemsets with the traditional HUIs FIs and UIs Underlying Itemsets respectively The statistic values of each dataset are shown in Table VIII The experiment is conducted as follows Firstly we collect all the utility itemsets with their utilities and frequencies in each dataset respectively Secondly we also collect all the frequent itemsets with their frequency and utility Then we calculate the utilities of the frequent itemsets frequencies of the HUIs and both utilities and frequencies of the derivative itemsets At last we plot the frequency of itemsets discovered via UP-Growth and CUARM the utility of itemsets discovered by FP-Growth and CUARM and the utility changes from each underlying itemset to derivative itemset as shown in Fig 5 Such exhibition is made for the comparison of our algorithm with FIM and HUI to demonstrate the UtilityAssociation Rules we discovered have both high utility and high frequency Here all the frequent and utility itemsets we compare with contain at least two items because the derivative itemsets our algorithm discover contain no less than two items Experiments on Real Datasets We 002rst present the outputs of dataset Retail in Fig 5\(a and Fig 5\(b Top 50 patterns of each algorithm are selected for experiments By analyzing the frequencies and utilities of patterns many of them are without much difference in both two experiments which means the association rules we found via traditional AR algorithms are also high utility-association rules via our method In addition such rules are also with high utilities This explains why some parts of the curves overlap In addition customers prefer to buy a few products at one time that is most of FIs and HUIs contain only one or two items which also explains the observations In datasets Chainstore  the differences are much clearer because customers usually prefer a variety of products in each of transactions and high utility itemsets are always low in frequency while highly frequent itemsets are with low utility For example in Fig 5\(d the CUARM performs much better than that of FP-Growth while in Fig 5\(e even at some points the performance is not so good the global performance is much better To sum up we can assert that the performance of our algorithm CUARM is much better than the others Experiments on Synthetic Datasets Experimental results on synthetic datasets t20i6d100k and c20d10k are shown in Fig 5\(g Fig 5\(h Fig 5\(j and Fig 5\(k The results are much clearer than those from real datasets because the items included are much neat and with orderliness For most of the patterns discovered via CUARM the frequencies are much higher than those traditional high utility itemsets At the same time most Utility-associated rules are also with much higher i.e twice the utility than traditional association rules especially in Fig 5\(h from dataset t20i6d100k  C Evaluation of the Utility Increment We demonstrate the utility increment in a graphic way to show how the utility increases from underlying itemset to derivative itemset The utility increment is valued based on the same datasets as above points are ordered by the utility of derivative itemsets The performance of our algorithm varies from one dataset to another The performance in chainstore is much better than that in retail because the transaction time in chainstore is 12 times more than that in retail while the item types are only twice more However in the synthetic datasets the performance is better In conclusion for each dataset the performance is different but the utility actually increases D Utility Variation Experiments Conclusion Based on the above datasets and experimental results a table is used to demonstrate the conclusion that comes from our experiments and shown as Table IX This table describes the number of itemsets whose utilities are increase or decrease with given threshold Also two kinds of utility incremental forms are listed One is the utility of derivative itemset is higher than both the utilities of underlying itemset and additional itemset which is denoted as FA the other is that the utility of derivative itemset is higher than only the utility of underlying itemset which is denoted as FB As for each underlying itemset only one derivative itemset would be discovered some FA and FB might be ignored For the utility decrement itemsets whose utilities are only lower than the underlying itemsets would not be considered in this table because these itemsets can also be regarded as FBs when the underlying itemsets and additional itemsets exchange TABLE IX U TILITY V ARIATION C ONCLUSION Dataset Min Sup N.DI R.U N.FA N.FB N.DecI Retail 0.01 89 20.3 50.4 28 22 39 0.008 135 18.6 50.4 37 46 52 0.002 1667 8.4 50.4 473 769 425 Chainstore 0.002 79 4.6 207.2 7 19 53 t20i6d100k 0.017 33 25.7 78.5 8 11 14 0.015 79 22.8 78.5 24 19 36 0.012 383 1.8 78.5 112 137 134 c20d10k 0.05 120 19.7 150.9 28 48 44 In Table IX M in Sup in the minimum support for mining itemsets N:DI is the number of derivative itemsets discovered 


figures1//retail_f-eps-converted-to.pdf a retail figures1//retail_u-eps-converted-to.pdf b retail figures1//retail_i-eps-converted-to.pdf c retail figures1//ds7_f-eps-converted-to.pdf d chainstore figures1//ds7_u-eps-converted-to.pdf e chainstore figures1//ds7_i-eps-converted-to.pdf f chainstore figures1//t20i6d100k_f-eps-converted-to.pdf g t20i6d100k figures1//t20i6d100k_u-eps-converted-to.pdf h t20i6d100k figures1//t20i6d100k_i-eps-converted-to.pdf i t20i6d100k figures1//c20d10k_f-eps-converted-to.pdf j c20d10k figures1//c20d10k_u-eps-converted-to.pdf k c20d10k figures1//c20d10k_i-eps-converted-to.pdf l c20d10k Fig 5 Experiments for FP UP and CUARM with the threshold M in Sup  R:U in the utility incremental rate from underlying itemset to derivative itemset N:F A is the number of FA itemsets N:F B is the number of FB itemsets and N:DecI is the number of decremental itemsets VI C ONCLUSIONS AND F UTURE W ORK Traditional high utility itemset mining methods have the weak point that if the minimum utility threshold is set too high the itemsets discovered might contain unrepresentative items while if the threshold is set too low too many redundant itemsets will be found On the other hand traditional association rule mining ignores the utility hidden among the items This work proposes a novel pattern select method from two aspects One is the co-occurrence of two underlying and additional itemsets another is the utility increment from underlying itemset to derivative itemset It is an effective approach for identifying actionable combined utility itemsets in which for different items only one itemset will be selected with the highest association-utility growth which caters for both high association and high utility Thus only the most effectively impacted itemsets will be presented The results demonstrate that our method can discover patterns that are composed of different item combinations of both utility increment and high representativeness For the future work we may 002nd some more interesting pattern selection method For example there exists a dependent relationship between two itemsets A and B which means A might appear frequently alone or with other items but for most time B appears together with A VII A CKNOWLEDGMENTS This work is sponsored in part by Australian Research Council Discovery Grant P130102691 R EFERENCES  R Agra w al R Srikant 1994 F ast Algorithms for Mining Association Rules in Proc of the 20th Int'l Conf on Very Large Data Bases pp.487-499 Santiago Chile  C.F  Ahmed S.K T anbeer  B.-S Jeong and Y K Lee 2009 Ef 002cient Tree Structures for High utility Pattern Mining in Incremental Databases in Proc of IEEE Transactions on Knowledge and Data Engineering Vol 21 Issue 12 pp 1708-1721  L Cao Y  Zhao C Zhang 2008 Mining Impact-T ar geted Acti vity Patterns in Imbalanced Data IEEE Trans on Knowledge and Data Engineering 20\(8 1053-1066  L Cao P  S Y u C Zhang and Y  Zhao 2010 Domain Dri v en Data Mining Springer  L Cao 2013 Combined mining Analyzing object and pattern relations for discovering and constructing complex yet actionable patterns Wiley Interdisc Rew Data Mining and Knowledge Discovery 3\(2 140-155  J Han J Pei and Y  Y in 2000 Mining Frequent P atterns without Candidate Generation in Proc of the ACM-SIGMOD Int'l Conf on Management of Data pp 1-12 Dallas TX USA  J Han H Cheng D Xin and X Y an 2007 Frequent P attern Mining Current Status and Future Directions DMKD 15 55-86  M S Khan M Muyeba and F  Coenen 2008  A W eighted Utility Framework for Mining Association Rules in Proc of the Second UKSIM European Symposium on Computer Modeling and Simulation pp 87-92  X Lin Q Zhu F  Li Z Geng and S Shi 2010 S Share Strate gy for Utility Frequent Patterns Mining in Proc of the Seventh International Conference on Fuzzy Systems and Knowledge Discovery pp 14281432 Yantai China  J Liu K W ang and B C M Fung 2012 Direct Disco v ery of High Utility Itemsets without Candidate Generation in Proc of the IEEE Int'l Conf on Data Mining ICDM  M Liu and J Qu 2012 Mining High Utility Itemsets without Candidate Generation in Proc Of the ACM Int'l Conf on Information and Knowledge Management CIKM pp 55-64 


 Y  Liu W  Liao and A C houdhary  2005  A T w o-Phase Algorithm for Fast Discovery of High Utility Itemsets in Proc of PAKDD pp 689-695  S Shankar  T  Purusothaman S Kannimuthu and P  K V ishnu 2010 A Novel Utility and Frequency Based Itemset Mining Approach for Improving CRM in Retain Business International Journal of Computer Applications Volume 1 No 18 pp 87-94  V  S Tseng C.-W  W u B.-E Shie and P  S Y u 2010 UP-Gro wth An Ef\002cient Algorithm for High Utility Itemset Mining in Proc of Int'l Conf on ACM-SIGMOD pp.253-262  B V o B Le and J Jung 2012  A T ree-Based Approach for Mining Frequent Weighted Utility Itemsets in Proc of ICCCI 2012 Part I LNAI 7653 pp 114-123  C W u Y  Lin P  S Y u and V  S Tseng 2013 Mining High Utility Episodes in Complex Event Sequences in Proc of ACM SIGKDD International Conference on Knowledge Discovery and Data Mining KDD pp 536-544  C W u P  Philippe P  S Y u and V  S Tseng 2011 Ef 002cient Mining of a Concise and Lossless Representation of High Utility Itemsets in Proc of IEEE Int'l Conf on Data Mining ICDM pp.824-833  C W u B Shie V  S Tseng and P  S Y u 2012 Mining top-K high utility itemsets in Proc of ACM SIGKDD International Conference on Knowledge Discovery and Data Mining KDD pp 78-86  H Y ao H J Hamilt on and C J Butz 2004  A foundati onal approach to mining itemset utilities from databases in Proc of the 4th SIAM Int'l Conf on Data Mining Florida USA  J S Y eh Y  Li and C Cheng 2007 T w o-Phase Algorithms for a Novel Utility-Frequent Mining Model in Proc of PAKDD Workshop LNAI 4819 pp 433-444  J Y in Z Zheng and L Cao 2012 USpan An Ef 002cient Algorithm for Mining High Utility Sequential Patterns in Proc of ACM SIGKDD International Conference on Knowledge Discovery and Data Mining KDD pp 660-668  H Zhang et al 2008 Combined Association Rules Mining in Proc of PAKDD08 pp.1069-1074  Q Zhao and S Bho wmick 2003  Association Rules Mining a Surv e y Journal of Nanyang Technological University 2003116  Y  Zhao et al 2007 Mining for Combined Association Rules on Multiple Datasets in Proc of the KDD 2007 Workshop on Domain Driven Data Mining San Jose CA USA pp 18-23 



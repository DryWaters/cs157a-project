XML Stream Data Reduction by Shared KST Signatures   Stefan Böttcher University of Paderborn Computer Science Fürstenallee 11 D-33102 Paderborn stb@uni-paderborn.de Rita Hartel University of Paderborn Computer Science Fürstenallee 11 D-33102 Paderborn rst@uni-paderborn.de Christian Messinger University of Paderborn Computer Science Fürstenallee 11 D-33102 Paderborn michri@uni-paderborn.de    Abstract Within XML data streams, markup as defined e.g. in a 
DTD is not only being used for structuring large amounts of data, but also for efficiently searching accessing, and processing the required parts of the data streams. However when huge amounts of XML data are involved, data reduction or compression techniques that still allow finding the required parts of the data fast may become crucial to handle data processing We present a data reduction and compression technique for XML data streams that not only significantly reduces the amount of data, but also allows for efficient data processing without requiring a full data decompression. Our data reduction technique combines sub-tree sharing with removing 
structure that is known by a DTD. We have done extensive performance evaluations to compare our compression technique with other approaches to XML compression, and we show that we not only outperform the other techni ques, but also outperform string compression techniques like gzip that do not support query processing on compressed data   1. Introduction  XML is a widely used standard for data exchange in the web, and data sources like publish/subscribe systems produce  several GB of XML data per minute that are structured according to a 
given DTD. As most web standards are based on XML we expect that the amount of XML data will even be significantly increased in the near future, and querying exchanging and processing huge amounts of data will be one of the major challenges in massive web data processing. Data reduction techniques like XML compression have the goal to reduce the data volume by magnitudes providing significantly faster exchange of XML data without limiting the ability to search query, or process the compressed data 
 1.1. Classification of related work  Previous work on XML data reduction can be classified mainly into lossy and lossless data reduction techniques. While lossy data reduction does not allow for a precise reconstruction of the data and may use approximate answers instead of exact answers to queries, we follow the lossless approach to XML data reduction which allows a full reconstruction of arbitrary large parts of the compressed data and which supports exact answers to queries. Lossless XML data reduction approaches use two major approaches: XML 
structure encodings and XML compression techniques XML structure encodings use symbols for all element names, and some of them, like XGrin 9 an d  BSBC s e a bits t rea m to repres e n t th e s t r u ctu re of an XML tree, whereas other structure encodings, like XMLPPM d on th e probabilit y o f t h e occurrence of certain elements. Within the XML compression approaches, we can distinguish nonqueryable compression techniques  at  produce non-queryable compressed data from queryable XML compression techniques 
that produce queryable compressed XML data. We favor queryable XML compression techniques, as they avoid full decompression for search, query answering or processing the compressed XML data. Within queryable XML compression, the following main directions can be distinguished Schema-based compression techniques rely on an XML schema or a DTD and remove information from XML data that can be deduced from the schema or from the DTD. They do not encode the elements in the XML document, the occurrence of which is granted by 
the DTD or the schema. Examples for schema-based compression techniques are XC d Xen i a [16  that use automata-based approaches to reduce the data volume, and DTD subtraction at coun ts  repetitions of sibling elements Structure sharing-based compression techniques e.g ip [6] an d LZC S 1], iden ti fy co m m on sub-structures of XML data and use pointers to Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 1 978-0-7695-3450-3/09 $25.00 © 2009 IEEE 


common sub-trees instead of repeating XML data They work on directed acyclic graphs \(DAGs\ rather than on XML trees such that only the first occurrence of each common sub-tree has to be encoded While schema-based compression yields multiple identical chunks of compressed data for sub-trees that occur multiple times in the XML data as it does not take advantage of common sub-trees, common substructure based approaches to XML compression avoid duplicate storage of common sub-trees, but they often perform even poorer as they do not use the information provided by a DTD or XML schema. Up to now, there has not been a known way how to combine the advantages of both approaches and to avoid the disadvantages  1.2. Contributions  Our paper has the following contributions   We extend and significantly improve the encoding technique for the DTD subtraction leading to a very succinct signature of the tree structure of the XML data, called KST signature   We propose to separate the pointer implementation for sharing of compressed XML data into two parts the part encoding the origin, and the part encoding the destination. For both parts, we present different implementation techniques   We have developed a hybrid approach to XML compression that applies DAG-like structure sharing to DTD subtraction. This includes a technique for identifying XML sub-trees that are suitable for structure sharing of their signature   We have conducted extensive performance evaluations that show that our approach has a comparable query performance and significantly outperforms all the other approaches to XML compression  2. Reducing the structure of XML files  We follow the commonly used approach \(c.f. e.g 2,3,9,12  XML com p re s s i o n of s e parating  constant compression from structure compression for the following reasons   We get better overall compression results and significantly better compression ratios for structure   The structure is often sufficient for navigation to certain content  2.1. Overview of the KST signature generation  The compressed structure index produced by our compression approach is called KST signature in the remainder of this paper. KST signature generation applied to an XML document removes all the structural information from the XML document which is redundant, as it can be derived from the DTD of the XML data, and it stores the remaining structural information of the XML document in the so called KST signature The DTD is a regular tree grammar describing XML trees. As such, it can not only be used for parsing the XML tree, but also for generating a KST signature as a side-effect of parsing the XML tree. For this purpose, the regular tree grammar of the DTD is augmented to an attribute grammar that generates KST output during the parsing process A special feature of this KST signature generation is that the issued KST signature, can also be parsed using the same DTD rules. Furthermore, when the KST signature is parsed using the attribute grammar extending the DTD rules, the original XML document can be generated simply by inverting the substitution operations of the attribute grammar that generated the KST signature More details of concrete algorithms on KST signature generation are given in [3    2.2. Attribute grammar-based KST signature compression by DTD subtraction  Which structural information of an XML document can be derived from the DTD, depends on the regular expressions used in the right-hand side of the DTD s element declarations and on their specific DTD operators          PCDATA, EMPTY, and E where E is an element name. More precisely, for each of these operators, DTD subtraction defines how a regular expression composed of these operators and smaller regular expressions can be compressed to the KST signature. Let r and s be regular expressions occurring in the right hand side of an element declaration \(c.f. Table 1 \(a\\ and let R and S be subtrees of an XML document corresponding to r and s then the KST signature can be computed recursively when using the DTD to parse the XML document roughly as follows \(for details c.f   If the regular expression r describing the sub-tree R to be parsed next consists of an element name E only, there is no choice for this sub-tree R of the XML document, as the root of R must be the element E As this information can be derived from the DTD, the element E can be removed from the XML document when the KST signature is generated and nothing is generated in the KST signature to represent the element E   Similarly, if the expression r describing the subtree R to be parsed next is PCDATA or is EMPTY Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 2 


there is no choice for the sub-tree R of the XML document, as R must contain a text value or must be empty respectively. Therefore, nothing is generated in the KST signature to represent this information   Each regular expression r, s occurring in a DTD element declaration, determines explicitly that a subtree R corresponding to r has to be followed by a sub-tree S corresponding to s in every valid XML document. Again, there is no alternative to S matching s when R matching r has been parsed and no further information has to be encoded in the KST signature. For example, the DTD of Table 1\(a already defines, that the element f has a first child g followed by a second child h Therefore nothing has to be encoded for representing the elements g and h in lines \(3\d \(4\ the XML document shown in Table 1 \(b\n the KST signature shown in Table 1\(c   Each regular expression r | s occurring in a DTD element declaration, determines that either a sub-tree R corresponding to r or a sub-tree S corresponding to s follows next within the XML document Which alternative follows in the XML document can not be derived from the DTD. Therefore, which alternative follows, has to be encoded in the KST signature   The expression r defines that either one or zero XML sub-trees R that correspond to r follow next within the XML document. The information whether or not a sub-tree R corresponding to r follows in the XML document is encoded in the KST signature by a 1 or a 0 respectively   The regular expressions r and r define that any number of XML sub-trees Ri that correspond to expression r or at least one such sub-tree in the case of  ollow next in the XML document. As the KST signature compression of r is performed as described before, the only remaining information to be written to the KST signature is the number x \(or x-1 in the case of  sub-trees Ri corresponding to r that follow in the XML document Example Table 1 shows \(a\D, \(b\ XML document and \(c\he resulting KST signature. As the DTD defines that the element e contains any number of f children, the concrete number 2 of f children can not be deduced from the DTD and is thus encoded in the KST signature. However, the DTD defines that every f element has exactly one g child and exactly one h child, thus the occurrence of these elements does not need to be encoded in the KST signature Finally, as according to the DTD, each f element either has or does not have an i element as its third child, the existence or non-existence of each possible i child of an f element is encoded by 1 or by 0 in the KST signature. This is why the the KST signature in Table 1\(c\ the XML file in Table 1\(b\d the DTD in Table 1\(a\ is  2  1  1 Attributes can be encoded like child elements, and attribute declarations have to be treated analogously to element declarations. However, to simplify the presentation, we focus on elements b XML document and \(c KST signature    2.3. Improvements in KST signature encoding  The compression result KST generated by DTD su s e s on e b y te f o r eac h e n coded tok e n within the KST, except for very large numbers, for which an overflow encoding is provided that allows for using n Bytes, where n is at least 1 and depends on the value of the number to be encoded We have improved the KST signature encoding for the regular expressions mentioned above as follows   For a regular expressions r s occurring in the DTD, the KST signature needs to encode, to which of the provided alternative regular expressions r or or s e sub-tree \(R or or S\ found at actual position of the XML document corresponds. As the number n of different alternatives can be derived from the DTD, we encode this information with log 2  n bits within the KST signature   For the regular expression r occurring in the DTD the KST signature needs to encode whether or not a sub-tree R matching r occurs at the current context node of the XML document. We use one bit for encoding this in the KST signature   For the regular expressions r and r occurring in the DTD, the KST signature needs to encode the number of occurrences of sub-trees Ri in the XML document that correspond to r To improve this encoding, we have performed a series of measurements on many different XML documents with the result that the frequency distribution of these numbers of occurrences is quite similar over all a DTD   ELEMENT e \(f  ELEMENT f \(g,h,i  ELEMENT g \(EMPTY  ELEMENT h \(EMPTY  ELEMENT i \(EMPTY b XML  1  e 2  f 3  g 4  h 5  i 6  f 7  f 8  g 9  h 10  i 11  f 12  e c KST   2   1     1 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 3 


evaluated XML documents. Therefore, we have calculated a DTD-independent static Huffman encoding for these numbers of occurrences which includes an overflow encoding for all the high numbers of occurrences. Due to these optimizations we need only 0.7*n bits on average to encode the n occurrences of sub-trees R matching r in comparison to the previously best other compression approaches, [12 d [1 6], th at n e ed n bits   Applying these optimizations to the encoding of the KST already resulted in a significantly better compression ratio within the KST signature In order to improve the compression ratio even more, we propose to combine the DTD-based compression with a DAG-based compression, e.g  as described in the following sections  3. Combined DAG and KST compression  A compression approach that is solely based on sub-structure sharing is described in w e v e r combining structure sharing with KST signature compression is a challenging task because not every sub-structure of the KST signature is suitable for structure sharing In this section, we first give an example of a KST signature sub-structure that is not suitable for structure sharing, and then describe which sub-structures of the KST signature are suitable for structure sharing  3.1. KST signature sub-structures unsuitable for structure sharing  DAG compression of XML trees either works on unranked XML trees or on binary XML trees. We follow the binary DAG compression approach In the example of the XML document of Table 1\(b\e second binary sub-tree g/><h/><i in lines \(8\\(10\al to the first one in lines \(3\\(5 Therefore, in a binary DAG of the XML document, the sub-tree in lines \(8\\(10\would be replaced with a pointer to line \(3\ever, the f elements are not shared, as they do not have equal next siblings When trying to implement the corresponding pointer to line \(3\within the KST signature, we would have to identify the position of the pointer origin in the KST signature, which is after the first 1 But as this position could refer to the f element of line \(7 well as to the g element of line \(8\e position of the pointer origin in the KST signature is ambiguous. In other words, a unique decompression of a KST signature using this pointer would be impossible 3.2. How and when are KST signatures re-used  In order to avoid the ambiguities described above we only allow for KST signature structure sharing using pointer origins which are unambiguous as the pointer s origins directly correspond to a KST signature position. Such a unique mapping of XML nodes to KST signature positions exists for so called explicit XML nodes   Definition An explicit XML node en is a node of the XML document, for which a KST token has been generated, i.e. no other node has been parsed between the parsing of en and the encoding of a KST token 5\d \(10 the XML document of Table 1 \(b\plicit XML nodes, but the node in line \(7\ot an explicit XML node, as before encoding of the next KST token 1  the nodes in lines \(8\\(10\parsed When using structure sharing on explicit XML nodes, we can uniquely identify the KST signature token corresponding to an explicit node. In other words, we only use DAG pointers that start after an explicit XML node because thereby pointer origins correspond to a KST signature position which uniquely determines an explicit XML node, thus structure sharing on the KST signature can be decompressed  4. Encoding of pointers  We propose separating the pointer implementation for sharing of compressed XML data into two parts the part encoding the origin, and the part encoding the destination. While the encoding of the pointer origin is described in the first sub-section, the encoding of the pointer destination is described the second sub-section  4.1. Encoding of pointer origins  Pointers to shared structures could be encoded externally in a pointer table storing origin and destination of pointers. Alternatively, pointers can be encoded inline in the KST signature. As a pointer origin may occur after each number or bit of the KST signature, inline encoding requires distinguishing between pointers and other KST signature tokens. We use a special escape bit-sequence to describe that a pointer follows in the KST signature. The detection of this escape sequence can be done very efficiently by using an automaton. Our comparative computation of pointer sizes has shown that for pointers within KST signatures, inline encoding compresses much better than external encoding of pointers Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 4 


4.2. Encoding the pointer destination  As all pointers within the DAG point backwards to already known sub-trees, we decided to encode the address of the pointer destination in terms of the distance from the pointer origin to the pointer destination. As a metric for the distance, we use the number of SAX events between the pointer destination which is the first occurrence, and the pointer origin which is the repeated occurrence of the common subtree within the XML document. This metric is much more compressible than pointers addressing bits or bytes in the KST signature  4.3. Example  The compression result depends on the DTD. If we compress the XML document shown in Table 1 \(b using the following DTD which differs in the element definition of the element e from that of Table 1 \(a ELEMENT e \(f?,f ELEMENT f \(g, h, i ELEMENT g \(EMPTY ELEMENT h \(EMPTY ELEMENT i \(EMPTY we get a different list of explicit nodes, and a different resulting KST signature  f  i  f  i  1  1  1  1 where each 1 within the KST signature denotes the existence of an f element or of an i element. If we assume, that the special token for escaping pointers is 00 and we wanted to implement the KST signature pointer for the sub-tree behind the second f element instead of encoding this sub-tree in lines \(8\\(10\ the XML document, the resulting KST signature would be  1 1 1 00 7  where 7 is the distance from the SAX event of line \(8 as e.g h/> corresponds to both one startElement and one endElement SAX event  4.4. Avoiding losses in compression ratio  As can be seen from the previous example implementing a pointer might lead to a longer encoding than repeating shared sub-trees. Therefore we only use pointers when the encoding using pointers is shorter than the repetition of the shared sub-tree Therefore, whenever our compression finds a sharable sub-structure of the KST signature, it simultaneously calculates the encoding of the pointer and the encoding of the shared sub-tree. Afterwards, it writes the shorter of both encodings into the KST signature. Thereby, we can ensure that the combination of KST signature and structure sharing results in a compressed representation that is not larger than the KST signature on its own This avoidance of losses in compression ratios implies especially, that too small sharable sub-trees are not encoded by a backward pointer. As the number of shared sub-trees really saving space is smaller for KST signatures than it is for raw XML documents, applying sub-tree sharing to the KST signature will not result in the same compression increase as applying sub-tree sharing to the raw XML data To summarize, the improvement of KST signature over DTD subtraction can be observed especially for XML documents with large repetitions of common sub-trees \(because of the backward pointers\ and for XML document with a large number of siblings of the same element, represented in the DTD in form of a   or a  operator \(because of the improved encoding of these operators  5. Query processing  When we consider XPath query processing on KST signatures, we have to evaluate the XPath expression itself, and we may have to return the decompressed XML sub-trees of the nodes matching the query Query evaluation on the shared KST signature is based on the following key ideas and concepts We normalize queries in order to minimize set of operations to be implemented and in order to simplify the presentation We use a stack of entries representing XML element nodes on the child path from the root node to the current context node. Each stack entry contains the information necessary to continue query processing More precisely, each stack entry contains the element s name, a text constant counter, a SAX event counter the current KST signature position, and the current parsing position in the DTD rule defining the element s parent We regard query processing for the following subset of XPath  cxp  locationpath locationpath locationstep locationstep locationstep x '::' t | x '::' t pred pred  pred 'and' pred pred 'or' pred not' '\(' pred locationpath locationpath '=' const pred  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 5 


cxp is the start production x represents an axis attribute, self, child, parent, descendant-or-self descendant, ancestor-or-self, ancestor, following preceding, following-sibling, preceding-sibling const represents a constant, and t represents a node test" \(either an XML node name test or   meaning any node name   5.1. Query normalization  In order to simplify the presentation and to reduce the number of location steps to be implemented, we treat attributes like child elements and we normalize queries, such that they contain only the basic axes firstchild\(FC\ext-sibling\(NS\t \(P\d label\(L In the first step, we substitute each location step following::x with the equivalent location step sequence ancestor-or-self::*/following-sibling::*/decendant-or-self::x  and we replace each occurrence of preceding::x with  ancestor-or-self::*/preceding-sibling::*/decendant-or-self::x In a second step, we eliminate backward axes by using the looking forward approach   w h ic h rewrites each XPath query using backward axes into an equivalent XPath query using forward axes only In a third step, we further reduce arbitrary XPath location steps to the basic steps first-child, next-sibling label, parent as motivated in  After the query normalization, the queries contain only the axes first-child, next-sibling, parent and label  5.2. Supporting the basic steps on DAG KST  An FC step is executed as follows. The first-child fc of an element p is that element, the start tag of which follows directly after the start tag of p  Therefore, we parse the KST signature using the DTD If parsing reaches the end of the regular expression r  defining the element p before a first child element is found, then no first child exists. Otherwise, the first child element of p generated as a side-effect of parsing the KST with the DTD is returned as the first child of p  For example, if we look for the first child of the node e in the example of Section 4.3., the first 1 in the KST signature tells us that there is a child f of e  which is returned as the first child A NS step is executed as follows. The next-sibling ns of a current context element ps is that element the start tag of which follows directly after the end tag of ps Therefore we first have to find the end tag of ps In order to find the end tag of ps we parse the KST signature using the DTD until we reach the end of the DTD rule defining ps In case of recursive DTDs parsing continues until we reach the end of the same invocation of the DTD rule for ps hile parsing through DTD rules and KST signature, we have to count PCDATA-Elements within the DTD in order to provide direct access to compressed text values. After we have reached the end tag in this manner, the nextsibling will be the next element returned by continuing the parsing of the DTD rule defining the parent of ps  If parsing reaches the end of this rule without returning an element, no next-sibling exists For example, if we look for the next-sibling of the first f in Example 4.3. which was represented by the first 1 in the KST signature, parsing continues until the end of the DTD rule defining f and consumes the second 1 bit of the KST signature representing the existence of the i child node of the first f element Then parsing continues with the DTD rule defining e  which is the parent of f behind the first occurrence of f which just has been processed. As the element declaration for e contains a second entry f the next KST position, i.e. the third 1 is evaluated to determine that a next sibling f exists In order to support fast navigation along the P axis we keep a stack of previous query evaluation states which contains one entry for each element node on the child path from the XML document root to the current context node. Each stack entry contains the information required to continue query processing at the element node represented by the stack entry including the element node s SAX event counter, text event counter, current position in the KST signature and current position in a DTD rule A navigation to the FC yields a new entry on the stack, whereas a navigation to the NS results in popping the top-most entry from stack and adding a new entry to the stack When a P step is executed, we pop the top-most entry of the stack  5.3. Query evaluation on shared KST signatures  The stack entries support query processing on KST signatures using pointers as follows. When query evaluation requires using a pointer to a common subtree, the pointer destination s SAX event number is used for finding the first stack entry with a less or equal SAX event number, i.e. the first stack entry SE of an element being or enclosing the pointer destination. If the SAX event numbers of the pointer destination and of SE are the same, the element referred to by the pointer is found, and the stack entry SE contains all the inform ation to continue query processing, such as KST signature position and DTD rule position. Otherwise, SE describes an ancestor element of the pointer destination, and the pointer destination s SAX event number is used as an index for Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 


searching the pointer destination among the descendants of the element represented by SE Sharing of common sub-structures by using pointers requires returning to the calling place and continuing further processing from there, when a substructure has been fully processed. Therefore, for each pointer to a shared substructure that is used during query evaluation, we generate a stack entry containing the continuation information needed after the shared substructure is processed, which includes pointer origin, KST position and DTD rule position. This stack entry is popped after returning from a shared substructure  5.4. Answer tree generation and decompression  As we see in Section 6.2, queries can be evaluated on the KST signature nearly as fast as on the original XML representation. Therefore, in most cases, a decompression of the KST signature is not needed. For the remaining cases where decompression of KST substructures is needed, which is e.g. the case for the generation of decompressed XML answer sub-trees to a query, the document can be partially decompressed as follows Concerning the raw KST signature without any pointers for structure sharing, the decompression simply performs the inverse actions to the compression, and it can be implemented by using the DTD to parse the KST signature. Whenever the decompressor reads a pointer referring to a previous SAX event, it follows the pointer as this is done for queries and continues decompression at the node referenced by the pointer  6. Performance evaluation  6.1. Evaluation of compression ratios  We have implemented KST signature using Java 1 5 and a SAX parser for parsing XML documents. We have evaluated KST signature on the following datasets   XMark \(XM 5.3 MB an XML document that models auctions   hamlet \(H 0.3 MB an XML version of the famous Shakespeare play   catalog-01 \(C1 10.6 MB\catalog-02 \(C2 105.3 MB\ctionary-01 \(D1 10.8 MB\ctionary-02 D2 106.4 MB XML documents that were generated by the XBench benchmark   dblp \(DB 308.2 MB a bibliographic collection of publications  0 10 20 30 40 50 60 XGrind 46 32 32 54 54 gzip 32 20 20 20 17 29 29 Bzip2 22 20 12 12 11 19 19 DTD sub 22 25 10 10 13 18 18 BSBC 23 22 10 9 11 18 18 XMill 22 21 10 10 11 18 18 KST+DAG 21 21 9 9 11 16 16 XM H C1 C2 DB D1 D2  Figure 1. Compression ratio of the whole XML document  We compared KST signature with six other approaches   XGrin a queryable XML compressor   gzip a generic compressor based on Huffman encoding and LZ77   BZip2 - a generic compressor based on BurrowsWheeler-Transformation   DTD subtraction a structure-based XML compressor without optimized signature encoding and without structure sharing   BSBC a queryable XML compressor combining XML encoding with DAG-based structure sharing and using BZip2 for the compression of constant values   XMill [11 an XML compressor using BZip2 for the compression of constant values The results of our experiments are shown in Figure 1, where a compression ratio of 20% means that the size of the compressed file is only 20% of the size of the original uncompressed file. Using these datasets KST signature performs better than each of the compared compressors BZip2, gzip, XGrind, DTD subtraction, BSBC and XMill for all documents except for hamlet the smallest document within our evaluation where KST signature is outperformed only by gzip and BZip2, which both produce nonqueryable data Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 


 0.0 5.0 10  0  1 5.0 DTD-Sub 4.4 14.0 2.1 1.8 7.3 7.5 7.6 KST + DA G 0.9 2.2 0.3 0.3 2.1 1.3 1.3 XM H C1 C2 DB D1 D2 Figure 2. Structure Compression Ratio  In order to show the improvement of KST signature compared to DTD subtraction, we have measured the structure compression ratio, i.e. \(size of KST signature size of XML structure\ in a second series of measurements. As shown in Figure 2, we have achieved a significant improvement yielding an improvement factor for the compressed document structure between 3.5 and 7  6  Evaluation of compression and decompression times  Figure 3 summarizes our evaluation results on the data throughput of the compression techniques. gzip yields the highest throughput reaching rates of up to 12000 bytes/ms, XMill is the second fastest followed by Bzip2 and finally followed by the queryable compressors DTDSub, BSBC and KST signature   0 1000 2000 3000 4000 XM H C1C2DBD1D2 Throughput \(byte/ms gzip Bzip2 DTDSub BSBC XMill KST + DAG  Figure 3. Compression throughput  However, Figure 4 shows that most of the compression time of KST signature compression, i.e between 70% and 90%, is consumed by BZip2 for compressing the data values, whereas our KST signature approach uses only 10-30% of the time to compress the XML structure  0 25 50 75 100 XM H C1C2DBD1D2 Structure compression Data compression  Figure 4. Structure vs. data compression times of KST signature compression   We got very similar evaluation results, shown in Figures 5 and 6, for the decompression throughput and the decompression times, with the only difference that decompression is faster than compression for all approaches   0 2500 5000 7500 10000 XM H C1C2DBD1D2 Throughput \(byte/ms gzip Bzip2 DTDSub BSBC XMill KST + DAG Figure 5. Decompression throughput   0 25 50 75 10 0  XM H C1C2DBD1D2 Structure decompression Da t a d e c o m p r essi on Figure 6. Structure decompression time compared to data decompression time  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 


6.3. Evaluation of query performance on compressed data  In order to evaluate the query performance on compressed data, we have compared the query evaluation on KST signature with two other approaches. On the one hand, we have compared it with JAXP, the standard XPath evaluator contained in Java 1.5 in order to compare the overall query performance. On the other hand, we have compared it with our generic query evaluation engine working on uncompressed SAX events and using the same elementary navigation operations first-child and nextsibling and the same framework on top to evaluate queries, in order to evaluate the effect of compression on the query evaluation time Our test data set was generated by the XML generator of the XML Benchmark XMark [14 u s i n g a  scaling factor of 0.001 \(116 kB\p to 0.128 \(14.5 MB On our dataset, we have evaluated queries of the XPath benchmark XPathMark-A h e tes t qu erie s  can be seen in Table 2  Table 2. XPathMark-A queries used for the evaluation of query performance ID Query Q1 /site/closed_auctions/closed_auction annotation/description/text/keyword Q2 /site/closed_auctions/closed_auction//keyword Q3 /site/closed_auctions/closed_auction annotation/description/text/keyword  da te  Q4 /site/closed_auctions/closed_auction descendant::keywo da t e  Q5 /site/people/person profile/gender and profile/age  n a m e  Q6 site/people/person[phone or homepage na m e Q7 site/people/person[address and \(phone or homepage and \(creditcard or profile  n a m e    D128 0 2000 4000 6000 Q1 Q2 Q3 Q4 Q5 Q6 Q7 ms Uncompressed JAXP KST signature  Figure 7. Query evaluation times for document D128  Figure 7 shows the test results of all queries for the largest document with scaling factor 0.128 and a size of 14.5 MB. Except for the queries Q2 and Q4, KST signature performs better than JAXP and performs comparable to our generic query evaluation engine working on the uncompressed XML data. KST signature needs a longer evaluation time than the other approaches for the queries Q2 and Q4, as the descendant-axis location step in these queries requires that the whole sub-tree under the current context node has to be searched and thus partially decompressed. As KST signature was designed for optimal compression an index for descendants has not been included  Q2 0 2000 4000 6000 050100150 ms KST signature JAXP Uncompressed Figure 8. Query evaluation times for query Q2  Figures 8 and 9 show the scaling of queries Q2 where KST signature performs worse than the other two evaluators\d Q7 \(where KST signature performs best of all three evaluators\ can be seen in both figures, KST signature s query evaluation time scales linearly depending on the size of the uncompressed XML document. Therefore, it can be used for extremely large documents as well  Q7 0 1000 2000 3000 4000 5000 0 0.05 0.1 0.15 scaling factor ms KST signature JAXP Uncompressed  Figure 9. Query evaluation times for query Q7 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 


7. Summary and conclusions  We have presented a technique for lossless data reduction of huge XML files and XML data streams Our data reduction technique combines KST signature compression with structure sharing known from DAGs in the following way We introduce the concept of explicit XML nodes that can be used as pointer origin and still allow for unique decompression and fast query evaluation Furthermore, we encode pointer destinations by SAX event numbers of previous XML nodes We have integrated the concept of pointer to substructures with the KST signature that can be generated by parsing the XML document with an attribute grammar that uses the DTD. A special feature of the compression and the attribute grammar rule is that the same DTD rule set can be used for decompressing the KST signature. Query processing avoids full decompression and uses partial decompression on demand, e.g. for answer sub-tree generation We have reduced query processing to a set of elementary navigation operations, consisting of firstchild, next-sibling, parent and label, and we have developed fast query evaluation on top of these elementary operations. To support following pointers and backward navigation, we keep the child path from the root to the current context node on further information on a stack. This supports efficient query evaluation on our compressed data format KST signature without the requirement of expensive decompression Finally, we have conducted extensive performance evaluations that show that our approach not only results in reasonable query evaluation times, but also outperforms the compression ratios of all the other compression techniques, including even nonqueryable compression techniques like gzip, XMill and BZip2 Altogether, our approach reduces huge XML data structures or XML data streams to a significantly smaller KST signature. It combines a scalable and significant size reduction of verbose XML structures with a comparably fast query processing technique Therefore, the use of KST signature is a significant step towards XML data reduction and the management of huge XML files and streams 8. References  1  Joaquín Adiego, Gonzalo Navarro, Pablo de la Fuente Lempel-Ziv Compression of Structured Text. Data Compression Conference 2004 2  Stefan Böttcher, Rita Hartel, Christian Heinzemann BSBC: Towards a succinct data format for XML streams. 4th International Conference on Web Information Systems and Technologies \(WEBIST2008\ Funchal, Portugal, May 2008 3  Stefan Böttcher, Rita St einmetz, Niklas Klein XML index compression by DTD subtraction ICEIS 2007 4  Peter Buneman, Martin Grohe, Christoph Koch: Path Queries on Compressed XML. VLDB 2003: 141-152 5  James Cheney: Compressing XML with Multiplexed Hierarchical PPM Models. Data Compression Conference 2001 6  James Cheng, Wilfred Ng: XQzip: Querying Compressed XML Using Structural Indexing. EDBT 2004 7  Yanlei Diao, Shariq Rizvi, Michael J. Franklin: Towards an Internet-Scale XML Dissemination Service. VLDB 2004 8  Massimo Franceschet: XPathMark: An XPath Benchmark for the XMark Generated Data. XSym 2005 129-143 9  Richard F. Geary, Naila Rahman, Rajeev Raman Venkatesh Raman: A Simple Optimal Representation for Balanced Parentheses. CPM 2004: 159-172 10  Georg Gottlob, Christoph Koch, Reinhard Pichler Efficient Algorithms for Processing XPath Queries VLDB 2002 11  Hartmut Liefke, Dan Suciu: XMILL: An Efficient Compressor for XML Data. SIGMOD Conference 2000 153-164 12  Wilfred Ng, Wai Yeung Lam, Peter T. Wood, Mark Levene XCQ: A queriable XML compression system Knowl. Inf. Syst. 10\(4\: 421-452 \(2006 13  Dan Olteanu, Holger Meuss, Tim Furche, François Bry XPath: Looking Forward. EDBT Workshops 2002: 109127 14  Albrecht Schmidt, Florian Waas, Martin L. Kersten Michael J. Carey, Ioana Manolescu, Ralph Busse XMark: A Benchmark for XML Data Management VLDB 2002: 974-985 15  Pankaj M. Tolani, Jayant R. Haritsa: XGRIND: A Query-Friendly XML Compressor. ICDE 2002: 225234 16  Christian Werner, Carsten Buschmann, Ylva Brandt Stefan Fischer: Compressing SOAP Messages by using Pushdown Automata. ICWS 2006: 19-28 17  Benjamin Bin Yao, M. Tamer Özsu, Nitin Khandelwal XBench Benchmark and Performance Testing of XML DBMSs. ICDE 2004: 621-633  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


 11  Technology under contract from the National Aeronautics and Space Administration The work was funded by the NASA Exploration Technology Development Program and would not have been possible without the flash LIDAR  sensor provide by NASA Langley and the field test system provided by JPL  R EFERENCES  1  Bulyshev Alexander Pierrotte t Diego Amzajerdian Farzin; Busch, George; Vanek, Michael; Reisse, Robert 322Processing of three dimensional flash lidar terrain images generating from an airborne platform\323 roc SPIE, Vol. 7329 April 2009  2  Epp  Chirold and Tom Smith, \322Autonomous Precisio n Landing and Hazard Detection and Avoidance Technology ALHAT\,\323 Proc IEEE Aerospace Conf Big Sky, MT, March 2007  3  Fischler Martin A and Robert C Bolles Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography  Comm Of the ACM 24 June 1981 381 320 395  4  Gennery D.B 322Least Squares Camera Calibration Including Lens Distortion  and Automatic Editing of Calibration Points,\323 Workshop Calibration  and Orientation of Cameras in Computer Vision XVI I Congress  of the International Society of Photogrammetry and Remote Sensing Washington DC, August  2, 1992  5  Johnson Andrew E Jason A Keim and Tonislav Ivanov  322Analysis of Flash Lidar Field Test Data  for Safe Lunar Landing\323 IEEE Aerospace Conferenc e  March 6 13, 2010, Big Sky, Montana  expected  6  Johnson  Andrew E  and Miguel SanMartin Motion Estimation from Laser Ranging for Autonomous Comet Landing Proc Int'l Conf Robotics and Automation pp. 132 138, April 2000  7  Lowe, David G. "Distinctive image features from scale invariant keypoints International Journal of Computer Vision vol. 60.2 \(2004\: 91 110  8  Wertz, James R Spacecraft Attitude Determination and Control  Boston Kluwer Academic Publishers 1978  558 566  9  Melvin \(Jay\ White II, Tom Criss, and Dewey Adams  322 APLNav Terrain Relative Navigation Helicopter Field Testing 323 AIAA Guidance Navigation and Control Conference  August 2009, Chicago, Illinois   B IOGRAPHY  Jason Keim received his B S.B.M.E from the University of Southern California and  M.S.M.E from California State University, Los Angeles. Since 2002, Jason has been a member of the Guidance and Control Analysis Group at the NASA Jet Propulsion Laboratory. His primary focus has been the development and validation of formation flight algorithms and technologies for missions such as NASA Starlight TPF and DARPA F6  Additionally, he has contributed to the autonomous surface operations of the Mars Science Laboratory data processing and t rajectory reconstruction for the Autonomous Landing and Hazard Avoidance Technology program and other research and technology development programs  Dr Sohrab Mobasser is a Senior Member of the Engineering Staff at the National Aeronautics and Space Admi nistration\325s NASA Jet Propulsion Laboratory JPL Sohrab has more than 26 years of aerospace industry experience most of it in spacecraft attitude determination His work can be found on many planetary missions from the Galileo mission to Jupiter to t he successful Pathfinder mission to Mars and the Cassini mission to Saturn His current interests are new technology and applications for autonomous spacecraft attitude determination  Sohrab is the Field Test Lead for ALHAT project    Dr Yang Cheng  Dr Y ang Cheng is senior staff member at JPL and he has been involved in many NASA and reimbursable robotic projects for many years He is the key algorithm developer for the Descent Image Motion Estimation System \(DIMES which played a critical role for Mars Exploration Rovers landing safely on Mars. He was also the key software developer for the MER onboard visual odometry which has been used during critical rover maneuvers and traverses.  In addition, he was also involved in novel vision algorithm developme nt for future Mars and Lunar safe and pinpoint landing   Tonislav Ivanov is an Associate Member of Technical Staff in the Computer Vision Group at JPL He works on lidar data processing  field test setup, and is helping develop the hazard detection algori thm for the Autonomous  Landing and Hazard Avoidance Project He also works on recognition using stereo data for robot human awareness and lunar terrain characterization for future missions to the Moon    320  


12 Dr Da Kuang  received his Ph.D in Aerospace Engineering from The University of Texas at Austin in 1995. He joined the Orbiter and Radio Metric Systems Group at JPL in 1996 His work has been focused on analyzing GPS and GPS like tracking data for precise orbit determ ination and precise relative positioning  Dr Andrew Johnson  is a Principal Member of Technical Staff in the Optical Navigation Group at JPL  He is the JPL Project Manager and  terrain sensing algorithm lead for the Autonomous Landing and Hazard Avoida nce Project which is developing technology for safe and precise landing for the next generation manned lunar lander At JPL he works on development validation and flight implementation of computer vision systems for planetary landers and Mars rovers  Ha nnah R Goldberg  received her M.S.E.E and B.S.E from the Department of Electrical Engineering and Computer Science at the University of Michigan in 2004 and 2003 respectively. She has been employed at the Jet Propulsion Laboratory California Institute of Technology since 2004 as a member of the technical staff in the Precision Motion Control and Celestial Sensors group Her research interests include the development of nano class spacecraft and microsystems   Garen Khanoyan  is a member of the Advanced Co mputer Systems  Technologies group at JPL He has been involved with field testing activities and the development of the Command  Data Storage Unit since 2008 for ALHAT and MSL projects. Garen received his B S.E.E and M S.C.S from the University of Southern California   David B. Natzic received his B.S.C.S. from the Department of  Computer Science at the Universi ty of Management and Technology He has been employed as a n Associate Member of Technical Staff in the Guidance Navigation and Control Group at JPL Dave Joined JPL in 1992 and currently serves as a n  essential ALHAT team member focusing on the design integration and field testing of Flash LIDAR instruments onboard aerial platforms 


13 A PPENDIX    Seconds since targets appeared in the camera field of view   Seconds since the targets appeared in the camera filed of view    A         B      Seconds since targets appeared in the camera field of view   Seconds since the targets appeared in the camera filed of view   C         D Figure 16  The error between the propagated and estimated attitude  A is the scalar error and B is the vector error before the corrections.  \(C\ is the scalar error and \(D\ is the vector error after the correction   200  180  160  140  120  100  80  60  40  20  0  200  180  160  140  120  100  80  60  40  20  200  180  160  140  120  100  80  60  40  20   200  180  160  140  120  100  80  60  40  20  0.35  0.30  0.25  0.10  0.05  0  0  Degrees  0.20 0.15  0.35  0.30  0.25  0.10  0.05  0  Degrees  0.20  0.15  0  0.15  0.10  0  0.15  0.20  0.25  Degrees  0.05  0.10  0.05  0.15  0.10  0  0.15  0.20  Degrees  0.05  0.10  0.05  0  


14   A        B  Figure 17: Yaw and pitch errors from second Borrow Pit flight for \(A\ the LIDAR and \(B\ the camera      A        B  Figure 18: Yaw and pitch errors from the third Lakebed flight for \(A\ the LIDAR and \(B\ the camera  Degrees  Seconds into flight  Seconds into flight  0 3 0  0.25  0.20  0.15 0.10  0.05  0  0 05  0 10  0 15  Degrees  0 3 0  0.25  0.20  0.15 0.10  0.05  0  0 05  0 10  0 15  Degrees  1.0  0.5  0  0.5  1.0  1.5  2.0  2.5  Degrees  1.0  0.5  0  0.5  1.0  1.5  2.0  2.5  500  2000  2500  1000  1500  3000  3500  Seconds into flight  500  2000  2500  1000  1500  3000  3500  Seconds into flight  1000  1500  500  2000  2500  0  0.20  1000  1500  500  2000  2500  0  0.20  


                                                  S J       


                                                      


                         L A                                        


          L A  Table 7. Table of Granules at left-hand-side is isomorphic to  at right- hand-side: By Theorem  3.1 one can ?nd patterns in either table as a single generalized concept  Internal points  are:[4]\(1, 1, 0, 0 tions; [5]\(0, 1, 1, 0  0, 1, 0, 1  0, 1, 1, 1  1, 1 1, 0  1, 1, 0, 1  1, 0, 1, 1 11]\(1, 1, 1, 1 form and simplify them into disjoint normal forms 1  T E N    S J    T E N    S J 2  T W E N T Y    L A    T H I R T Y   A 3  T W E N T Y      T H I R T Y   A 4  T W E N T Y            L A 5  T E N      T W E N T Y    L A    T E N    T W E N T Y   A   S J    T W E N T Y   A      T H I R T Y    L A     Y 7  T E N      T W E N T Y      T H I R T Y   L A    T E N   L A    S  J   A 8  T W E N T Y      T E N      T W E N T Y    L A    T E N   T W E N T Y      T H I R T Y 9  T W E N T Y    N Y    T E N    S J    T H I R T Y    L A      T W E N T Y    L A  1 0  T W E N T Y    N Y    T W E N T Y    L A    T H I R T Y   A    J 1 1  T W E N T Y          T W E N T Y    L A   T H I R T Y    L A    a l l If the simpli?ed expression is a single clause \(in the original symbols non-generalized the following associations 1   T E N     S J    T E N    S J  2. SJ   J 4   L A    T W E N T Y    L A    T H I R T Y    6 Conclusions Data, patterns, method of derivations, and useful-ness are key ingredients in AM. In this paper, we formalize the current state of AM: Data are a table of symbols. The patterns are the formulas of input symbols that repeat. The method of derivations is the most conservative and reliable one, namely, mathematical deductions. The results are somewhat surprising 1. Patterns are properties of the isomorphic class, not an individual relation - This implies that the notion of patterns may not mature yet and explains why there are so many extracted association rules 2. Un-interpreted attributes \(features can be enumerated 3. Generalized associations can be found by solving integral linear inequalities. Unfortunately, the number is enormous. This signi?es the current notion of data and patterns \(implied by the algorithms 4. Real world modeling may be needed to create a much more meaningful notion of patterns. In the current state of AM, a pattern is simply a repeated data that may have no real world meaning. So we may need to introduce some semantics into the data model [12],[10],[11 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE References 1] R. Agrawal, T. Imielinski, and A. Swami  Mining Association Rules Between Sets of Items in Large Databases  in Proceeding of ACM-SIGMOD international Conference on Management of Data, pp. 207216, Washington, DC, June, 1993 


216, Washington, DC, June, 1993 2] Richard A. Brualdi, Introductory Combinatorics, Prentice Hall, 1992 3] A. Barr and E.A. Feigenbaum, The handbook of Arti?cial Intelligence, Willam Kaufmann 1981 4] Margaret H. Dunham, Data Mining Introduction and Advanced Topics Prentice Hall, 2003, ISBN 0-13088892-3 5] Fayad U. M., Piatetsky-Sjapiro, G. Smyth, P. \(1996 From Data Mining to Knowledge Discovery: An overview. In Fayard, Piatetsky-Sjapiro, Smyth, and Uthurusamy eds., Knowledge Discovery in Databases AAAI/MIT Press, 1996 6] H Gracia-Molina, J. Ullman. &amp; J. Windin, J, Database Systems The Complete Book, Prentice Hall, 2002 7] T. T. Lee  Algebraic Theory of Relational Databases  The Bell System Technical Journal Vol 62, No 10, December, 1983, pp.3159-3204 8] T. Y. Lin  Deductive Data Mining: Mathematical Foundation of Database Mining  in: the Proceedings of 9th International Conference, RSFDGrC 2003 Chongqing, China, May 2003, Lecture Notes on Arti?cial Intelligence LNAI 2639, Springer-Verlag, 403-405 9] T. Y. Lin  Attribute \(Feature  The Theory of Attributes from Data Mining Prospect  in: Proceeding of IEEE international Conference on Data Mining, Maebashi, Japan, Dec 9-12, 2002, pp. pp.282-289 10] T. Y. Lin  Data Mining and Machine Oriented Modeling: A Granular Computing Approach  Journal of Applied Intelligence, Kluwer, Vol. 13, No 2, September/October,2000, pp.113-124 11] T. Y. Lin, N. Zhong, J. Duong, S. Ohsuga  Frameworks for Mining Binary Relations in Data  In: Rough sets and Current Trends in Computing, Lecture Notes on Arti?cial Intelligence 1424, A. Skoworn and L Polkowski \(eds 12] E. Louie,T. Y. Lin  Semantics Oriented Association Rules  In: 2002 World Congress of Computational Intelligence, Honolulu, Hawaii, May 12-17, 2002, 956961 \(paper # 5702 13  The Power and Limit of Neural Networks  Proceedings of the 1996 EngineeringSystems Design and Analysis Conference, Montpellier, France, July 1-4, 1996 Vol. 7, 49-53 14] Morel, Jean-Michel and Sergio Solimini, Variational methods in image segmentation : with seven image processing experiments Boston : Birkhuser, 1995 15] H. Liu and H. Motoda  Feature Transformation and Subset Selection  IEEE Intelligent Systems, Vol. 13 No. 2, March/April, pp.26-28 \(1998 16] Z. Pawlak, Rough sets. Theoretical Aspects of Reasoning about Data, Kluwer Academic Publishers, 1991 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 






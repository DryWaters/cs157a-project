Enriching Non-Taxonomic Relations Extracted from Domain Texts N.F.Nabila Faculty of Science and Technology Universiti Sains Islam Malaysia 71800 Putra Nilai, Negeri Sembilan, Malaysia fatin@usim.edu.my A.Mamat, M.A.Azmi-Murad and N.Mustapha Faculty of Computer Science and Information Technology University Putra Malaysia 43300 UPM Serdang, Selangor, Malaysia ali@fsktm.upm.edu.my, masrah@fsktm.upm.edu.my norwati@fsktm.upm.edu.my   Abstract 227 Extracting non-taxonomic relations is one of the important tasks in the construction of ontology from the text Most of current methods on identification and extraction of nontaxonomic relations is based on predicate representing relationships between two concepts, namely the relation between subject and object that occurs in a sentence. However, the number of relations that has been identified does not properly represent the domain as the methods only identify a portion of the total relations from domain texts. In this paper, we present a method that increases the number of relations extracted and thus properly represent the domain. In this method, all potential relations are first generated and then less significant ones, based on their frequency, are removed. The method has been tested on a collection of texts that described electronic voting machine and the result is encouraging   Keywords- Relation Extraction; Relation Identification; Nontaxonomic relation I   I NTRODUCTION  Ontologies became an important topic in various field of study. It is used as knowledge representation to improve several applications, including question answering, text mining, information retrieval, knowledge management and semantic web. However, the manual constructing of ontology is a complex, tedious, time-consuming, expensive and uneasy task o w a da y s t h e f o cus of v a ri ou s res earc h pro j ect s i s  to construct ontology automatically Generally, ontology of a domain consists of three main components [8  c o nc e p t  t a xo no my a nd  no n t a xo no mi c  relation. Even though the number of methods for constructing ontology is increasing, but most of them are only focusing in supporting the concept and taxonomic component. Not many methods focus on non-taxonomic relation component. The extraction of non-taxonomic rela tions has been considered as most challenging and important tasks   T h ere are t w o  sub problems to be considered in non-taxonomic relations identifying the potential relations between concepts and then labeling the potential relation appropriately [17   Most of current methods on identification and extraction of non-taxonomic relations from texts is based on predicate representing relationships between two concepts, namely the relation between subject and object that occurs in a sentence However, the number of relations that has been identified is only a portion of the total relations from domain texts. Thus the methods do not properly represent the domain In this paper, we present a method that increases the number of relations extracted and thus properly represent the domain. In this method, it identifies all the predicates in domain texts that are similar by using WordNet [18 a n d  generate concept pairs based on identified predicates. Then we extract the similar predicates within concepts and list them out. The method aims to produce possible relations between concepts to improve the coverage of relations This paper is organized as follows: Section II discusses related works. Section III presents the proposed method for discovering non-taxonomic relationships starting from domain documents. Section IV illustrates this process with an example. Section V discusses the experimentation and evaluation of the proposed method. Conclusion and future work are discusses in Section VI II  R ELATED WORK  Extracting non-taxonomic relations is one of the important tasks in the construction of ontology from the text. However very least research has been done in this important task. Most of the current methods on identification and extraction of nontaxonomic relations are based on predicate representing relationships between two concepts i.e., the relation between subject and object that occurs in a senten    In [5 en tif ied tran sactio n th at h o ld t w o co n cep ts i f  they frequently occur within the predefined distance from verb as VCC\(n\. Then, the author defined their heuristic \221above expectation\222 \(AE\measure to identify potential relations for concept pair In h e aut h ors propos ed S V O T ri p l e s  m e t h od b y  using MINIPAR dependency parser to identify related concepts as concept pairs. Then, the potential relations for the relations are identified. For this purpose VFxICF \(Verb Frequency x Inverse Concept Frequency\ metric is used and then assigned to the relations using log-likelihood ratios In t h e au t h or pro pos ed a m e t h od t o s u pport t h e  discovery and labeling of non-taxonomic relationships in ontology learning. To identify nouns and verb phrases, the POS tagger is applied to each sentence from the documents 2011 International Conference on Semantic Technology and Information Ret\rieval \r\n                                                             \           28-29 June 2011, Putrajaya, Malaysia \r\n 978-1-61284-353-7/11/$26.00 ©2011 IEEE 99 


Domain Text Documents Subject and Object Extraction Task Text pre-processing Task List of Terms  Matching Task List of  S s 1 s 2 s n List of O o 1 o 2 205,o m Figure 1 Framework for Non-Taxonomic Relationships Extraction Concept Pairs Identification Predicate Identification Domain Text Documents Domain ontology Relation Extraction and labeling Concept Extraction            collection to fulfill the pattern:  <term><verb><term>, where term> is a member of the synonym set corresponding to either the first or the second concept involved. Then, the association rule mining is used to recommend one or more suitable relations with certain degree of confidence to the knowledge engineer Other works that used association rule of data mining and statistical measurements to propose appropriate relations are presented in    8  Most of the existing methods identify and extract the possible relations between concep ts that appear together as subject and object in a sentence but those methods cannot find sufficient relations to represent the whole domain To increase the number of relations, we present a method to identify and extract the relations between concepts in different sentences. It identifies all the predicates in domain texts that are similar by using WordNet. Concept pairs are generated based on the identified predicates and most frequent concepts   III  I DENTIFYING AND EXTRACTION OF NON TAXONOMIC RELATIONSHIPS  In this section, we present a method to identify and extract non-taxonomic relations from domain texts. Fig.1 illustrates the overall system architecture of our method. Our method consists of four steps 1  Concept Extraction 2  Predicate Identification 3  Concept Pair Identification 4  Relation Extraction and Labeling A  Concept Extraction The objective of this step is to identify all the relevant concepts. The process divided into three tasks, text preprocessing, subject-object extraction and matching task. Fig.2 shows the overview of concept extraction We first take the texts and apply part-of-speech \(POS tagging to assign parts of speech to each word by using Brill\222s Rule-based POS tagg Stop w o rd eli m i n atio n proces s is  used to eliminate words based on their high frequency of            occurrences and unrelated to the domain information by using Porter\222s stop word [12 lis t            Figure 2  Overview of concept extraction  Next, morphological analysis is used to reduce all the dissimilarity of the word forms into a singular form WordNet\222s Lemm u s ed f o r th i s proces s an d on ce the process is done, a list of terms is identified Each term is calculated to determine its relevancy in a texts domain by using term frequency-inverse document frequency \(tf.idf\ metric [14 T e rm s w i th h i g h t f id f  v a lu e a r e  selected to obtain the initial cut of the relevant terms. Relevant term will be counted as the concept for the text domain In the second task, we analyze dependency triples which are generated by MINIPAR h allo w pars er to v e ri fy t h e  subject and object of a sentence. Terms which appear as subject are put in subj where subj contains a list of terms that appear as subject. Then, terms which appear as object are put in obj where obj contains a list of terms that appear as object Next, we identify each concept which appears as subject or object in texts. We match both results produced from the previous two tasks. Task one produces a list of relevant terns meanwhile task two produces two sets of terms, i.e subj and 978-1-61284-353-7/11/$26.00 ©2011 IEEE 100 


obj sets. Let S  s 1 s 2 205.,s n  is a set of concepts appear as subject where s n is a list of relevant terms that are matched in s ubj   Let O = {o 1 o 2 205.,o m  is a set of concepts appear as object where o m  is list of relevant terms that are matched in obj The relevant terms also can be a member for both S and O  B  Predicate Identification Verbs are identified from text documents using the previous text preprocessing steps an d s t op w o rd [12 i s  used to eliminate verbs which do not signify to domain texts i.e is, do, has, have,\205etc After the elimination, the identified verbs will be counted as predicate into set P where P is a set of predicate that contains all relevance verbs  Each predicate in P with similar meaning [10 w i l l  b e  grouped together. WordNet is used to identify similar meaning between all the predicates in P Table I shows some of the predicates obtain and the syno nym groups of predicates  For example P  p 1 p 2  p 3 p 4  p 6  p 1 p 3   p 2 p 4   p 6   TABLE I  E XAMPLES OF P REDICATES AND G ROUPS OF S YNONYM P REDICATES  Predicates P  produce, function, provide, work, check make, ensure, create Group of synonym predicates produce, make, create}, {function, work provide, {check, ensure  Then, we identify predicate an d concept which appear in a sentence by using dependency parser MINIPAR and represent them as predicate \(subject, object\ or p\(s,o where  p is a predicate that occurs together with a concept in a sentence  s is a concept which appears as an element in S  o is a concept which appears as an element in O  223-\224 is used when either subject or object are not exist in a sentence Once the rules have been extracted, we regroup the rules as p \(s into set PS which contains all information of predicate and subject and p \(-, o into set PO which contains all information of predicate and object  Definition 2.1 Predicate Subject\et PS = \(p 1 s 1 p 1 s 2  205., p 2 s 1 p 2 s 2 205.,\(p i s n  be a set of predicate and concept as subject that consists of all rules p\(s where p i  002  P , s n 002  S  Definition 2.2 Predicate Object\et PO = \(p 1 o 1 p 1  o 1 205.,\(p 1 o 1 p 1 o 1 205, p i o m  be a set of predicate and concept as object that consists of all rules p\(-,o where p i  002  P , o m 002 new S and b 002  O  C  Concept Pair Identification In this step, for each group of predicate, we generate concept pairs based on appear ance of predicate. For each group in P, we extract all rules in PS and in PO where p is list of predicate in each group. Then, all concepts in the extracted rules from PS will be into new S where new S  contains all concepts as subject. Similarity all concepts in the extracted rules from PO will be into new O  where new O  contains all concepts as object. After we identifying new S and new O the most frequent concepts for new S  and new O  are selected as concept pair Definition 2.3 Concept pair\. Let q   new S  x new O  we call  q  is a set of concept pairs which is the result from the Cartesian product between most frequent concepts for new S  and new O  Several restrictions are used to identify suitable pairs. We assume a,b  a  002 new O the concept pairs new S  new O  are generated using the following restrictions i  a 223not same\224 with b  or ii  a 223not synonym\224 with b or iii  a 223not is-a\224 relation with b  or iv  a 223 not part-of\224 relation with b   For example 1\ the group only contain one predicate p 6 e extract all rules in PS and PO where P  p 6  200  List of subjects and objects for p 6 are listed into  new S  and  new O  as below  new S s 1 s 7  where occurrences for s 1 4 and s 7  10 occurrences  new O  o 3 o 5 o 9  where occurrences for o 3   o 5 12 and, o 9 10 occurrences  So, the most frequent concept for new S  is  s 7  meanwhile the most frequent concepts for  new O are o 3 and  o 5  200  P 1|2 S = \(p 1 s 2 p 1 s 3 p 2 s 3 p 2 s 5  P 1|2 O = \( p 2 o 2 p 2 o 3  200  List of subjects and objects for p 6 are listed into new S  and new O as below  978-1-61284-353-7/11/$26.00 ©2011 IEEE 101 200  Hence, we generate concept  pair  q =  {s 7 x {o 3 o 5  s 7 o 3 s 7 o 5    Concept pair q= {s 7 o 3 s 7 o 5  2\ the group contain more than one predicates, i.e. \(p 1 p 2  we extract all rules in PS and PO, where P p 1  and p 2  200  P 6 S = \(p 6 s 1 p 6 s 7  P 6 O = \(p 6 o 3 p 6 o 5 p 6 o 9  


003 and p o 003  R p 23 o 003  R p 63 o 003  R po new S s 2 s 3 s 5  where occurrences for s 2 s 3 s 5 10 occurrences  new O o 2 o 10  where occurrences for o 2 8 and, o 10 13 occurrences  So, the most frequent concepts for new S  are  s 2 s 3 s 5  meanwhile the most frequent concept for  new O is o 10  003   In Equation \(1 q = \(S,O is a concept pair consists of concepts as subject, S and object, O. Support count q p  total of support count of rules in R that contain p s 003  R p 33 o 003   4 1  4 0  4 1  0.25  sprt\(q p 3   sprt\(s 1  p 3   sprt\(o 3  p 3     R p 31 s 003   4 0  4 2  4 2  0.5  From the statistical result p 3 has the highest support count  with concept pair and considered as suitable relationship for concept pair s 1 o 3  2\oncept pair q= \(s 1 o 3  is generated based on a group of synset predicate = {p 2 p 6 Table III shows example of rules extracted for concept pair \(s 1 o 3 ith corresponding number of rules Rule: 1 s 1 p 2  Rule: 2  s 1 p 6  Rule: 3 p 2 o 3  Rule: 4                p 2 o 3   TABLE III  E XAMPLES OF R ULES F OR C ONCEPT P AIR  S 1  O 3  Concept Predicate Rules s 1 p 2 1 s 1  p 6 3 o 3  p 2 2   sprt\(q p 2   sprt\(s 1  p 2   sprt\(o 3  p 2     R p 21 s 003  P 2|3|6 S  p 2 s 1 p 6 s 1   P 2|3|6 O  p 3 o 3   P 2|6 S  p 2 s 1 p 6 s 1   P 2|6 O  p 2 o 3   978-1-61284-353-7/11/$26.00 ©2011 IEEE 102 003  p is predicates that extracted from rules in PS and PO together with S or O.  R is a total rules extracted. Predicate that has highest degree of support count with concept pair are considered as suitable relationship for that concept pair. If exists more than one predicates have highest degree of support count, both predicates are considered as suitable relationship for that concept pair For example 1\oncept pair q= \(s 1 o 3  is generated based on group of synset predicate p 2 p 3 p 6  Table II shows example of rules extracted for concept pair \(s 1 o 3 ith corresponding number of rules   Rule: 1 s 1 p 2  Rule: 2  s 1 p 6  Rule: 3 p 3 o 3  Rule: 4             p 3 o 3  TABLE II  E XAMPLES OF R ULES F OR C ONCEPT P AIR  S 1  O 3  Concept Predicate Rules s 1 p 2 1 s 1  p 6 1 o 3  p 3 2  sprt\(q p 2   sprt\(s 1  p 2   sprt\(o 3  p 2     R p 21 s 003   4 1  4 0  4 1  0.25  sprt\(q p 6   sprt\(s 1  p 6   sprt\(o 3  p 6     R p 61 s 200  Thus q = {s 2 s 3 s 5 x {o 10 s 2 o 10 s 3 o 10 s 5  o 10   For example s 5  is synonym with o 10 so concept pair s 5 o 10  is eliminated from q Concept pair q= {s 2 o 10 s 3 o 10    D  Relation extraction and Labeling From the previous steps, a group of similar meaning synset of predicates is identified and a list of concept pairs is generated based on groups of predicate. Some pair of concepts may have more than one predicate. In this step, we want to choose the suitable predicate to label the semantic relations between a pair of concepts To find the suitable predicates to label the relationship for concepts pair which both concepts are occur in different sentences, we define sprt\(q p is a support count of rules in R that contain p q 003  R p 23 o 003 where q  S,O similar to support\(S p used in association ru s h o w n i n 1  sprt\(q p  sprt\( S p  sprt\( O p   1   R ps 


003 machine  R create 003  R p 63 o 003 paper   15 6  15 0  15 6  0.4  sprt\(\(machine, paper create   sprt\(machine create  sprt\(paper create   R create 003 machine  R produce  6 1  6 2  6 3  0.5  sprt\(q p 6   sprt\(s 1  p 6   sprt\(o 3  p 6   R p 6 1 s 003   6 3  6 0  6 3  0.5  From the statistical result p 2  and p 6 have similar support count Both p 2  and p 6 are considered as suitable relationship for concept pair s 1 o 3   IV  EXAMPLE For the purpose of illustration this section presents an example of how a relationship between two concepts is identified and extracted. First, voting machine domain texts are applied with concept ex traction and set S and O are identified. For example list of concepts as subject S  machine, voter, company, paper and list of concepts as object O= {machine, paper, voter  In the second step, list of predicate are identified and for example P= {produce, audit, create, provide Next, we grouped it with similar meaning using WordNet. Thus P produce, create}, {audit}, {provide  Then, in the third step, predicate and concept which is occurred in a sentence are identified and we represent them into predicate \(subject, object Example sentence in this text domain as following Sentence1 223This machine can produce many records.\224 So, we extract this sentence using Minipar parser into rule  produce \(machine, record After the rule has been extracted we regroup the rules into PS and PO Set PS produce \(machine, \d Set PO produce\(-, record  Next, concept pairs are generated based on items in group of predicate. For example, we extract all rules in PS and PO where P = {produce, create  P produce\\ create S = \(produce \(machine     create \(company P produce|create O = \(create \(-, paper From the above rules, list of subjects and objects for p 6 are listed into new S and new O as below  new S machine, company}, where occurrences for machine, company = 10    occurrences new O paper} , where occurrences for paper = 12 occurrences The most frequent occurrences concepts for new S and new O  are selected to be generated as concept pair Thus, the Cartesian product between most frequent concepts new S  and new O   Concept pair  q new S  x  new O    machine, company x paper    machine, paper}, {company, paper For predicate produce and create both of them are predicates for concept pair machine, paper and company paper Finally, we need to find either produce or create is suitable for both concept pair respectively using \(1 i. For concept pair q= {machine, paper Table IV shows an example of rules extracted for concept pair  machine, paper TABLE IV  E XAMPLES OF R ULES F OR C ONCEPT P AIR  machine paper  Concept Predicate Rules machine} {produce 6 paper} {create 9  sprt\(\(machine, paper produce  sprt\(machine produce  sprt\(paper  produce   R produce 003 paper   15 0  15 9   15 9   0.6  Then create is considered as suitable relationship for concept pair machine, paper  ii. For concept pair q = {company, paper Table V shows an example of rules extracted for concept pair  company, paper TABLE V  E XAMPLES OF R ULES F OR C ONCEPT P AIR  company paper  Concept Predicate Rules company} {create 3 paper} {create 2  sprt\(\(company, paper produce   sprt\(company create  sprt\(company  create  978-1-61284-353-7/11/$26.00 ©2011 IEEE 103 


 R create 003 company  R create 003 paper   5 3  5 2  5 5 1 Then create is considered as suitable relationship for concept pair company, paper  V  EXPERIMENTS Assessment of ontology learning techniques is a wellknown problem because of the lack of standards and difficulty to assess the performance of the proposed techniques     A s f o r ou r ex peri m e nt w e co m p are t h e performance of our proposed method with the SVO method on  the number of identified relations to increases the number of relations in domain texts. We then evaluate the precision of the results with the domain expert. The precision is defined as the percentage of all relations which are correctly extracted To test our approach, we select Electronic Voting Machine domain. Our text corpus extracted from New York Times website consists of 20 documents To increase the number of relations in domain texts, the extracted predicates which are id entified as synonym to each other using WordNet are grouped together. Example of predicate and the group of synonym predicates are shown in Table 1 in Section III. Then, for each synonym group of predicates, the most frequent concepts which occur together in a sentence or occur in different sentences are generated as concept pair To label the most suitable identified relation for a pair of concepts, the support count \(sprt is defined. As mention in section III, any predicates that have the highest degree of support count are considered as the most suitable relations to label the concept pair. For example sprt\(state, machine  provide is 0.75, meanwhile sprt\(state, machine offer is 0.25. Therefore provide is considered as the most suitable relationship for state, machine rom the observation of the support count results, it shows that the support count can be used to label relations between concepts by counting the frequency of each predicate occurs with its concepts. But we think that by using only the high degree of support count may not enough to label the relationship appropriately  Table VI shows some of relations obtained with the proposed method to increase the number of relations in the domain text. In Table VII, each of triples relations in \(S, P, O S is a concept as subject and O is an object of predicate P and both subject and object are occur together in a same sentence Meanwhile, P\(S, O\hows the increases of relations obtain for subject and object which is occur in different sentences by grouping the predicates with similar meaning. For example  provide, offer a synonym predicate for concept pair state machine here state and machine are the most frequent concepts as subject and object respectively and both concepts appear in different sentences TABLE VI  E XAMPLES OF P ROPOSED M ETHOD R ELATIONS R ESULT  S, P, O P\(S,O machine p roduce paper voter record vote company provide  machine official tell voter  p rovide, o ff er state, machine check, control, hold, ensure voter, election produce, make, create voter, machine function, work, run, serve machine, election read, record, understand machine, process want, require official, machine    TABLE VII  T OTAL R ELATIONS O BTAIN F ROM SVO  T RIPLES M ETHOD AND P ROPOSED M ETHOD  Method Number of Concept pair S, P, O P\(S,O Total nontaxonomic relations SVO Triples 17 12 - 12 Proposed Method 22 12 10 22   In table VII, the initial column shows the method applied Second column shows the number of identified concept pairs Third and fourth column shows the number of extracted potential relations between concept pair that occurs in a sentence and the number of extracted potential relations between concept pair that occurs in different sentences respectively. The fifth column shows the total relations extracted for each method From table VII, SVO methods identified 17 pair of concept pairs which 12 potential relations are extracted between concept pair that occur together in a sentence. However, the proposed method identified 22 pairs of concept pair which 12 potential relations are extracted for concept pairs that occur together in a same sentence similar to the SVO methods. In addition, the proposed method is able to extract 10 potential relations for concept pairs that occur from difference sentences. The generated concept pairs are based on group of predicates. This experiments shows that the proposed method can be used to increase number of relations TABLE VIII  E VALUATION OF SVO  T RIPLES M ETHOD AND P ROPOSED M ETHOD  Method Number of Concept pair Number of Non-taxonomic Relations SVO Triples 65.38 45.45 Proposed Method 84.61 77.27  We then evaluate the precision of the results in Table VII with the domain expert. In Table VIII, second column indicates the precision of the methods according to total number of concept pairs obtain Meanwhile, the third column shows the percentages the number of non-taxonomic relations obtains for each method. From Table VIII, the results of the proposed method indicate that it is able to increase the number of relations extracted to represent the whole domain texts 978-1-61284-353-7/11/$26.00 ©2011 IEEE 104 


 VI  CONCLUSIONS  AND  FUTURE  WORK We have presented a method to identify and extract nontaxonomic relations between concepts in different sentences Given texts of a domain as input, text pre-processing is applied on it to identified relevant concepts and predicates of the domain. Each predicate with similar meaning are grouped together. We represented each sentence into rules that consist of predicate and concept. For each groups of predicate, all rules that contain same predicate are extracted. Then, all concepts in the extracted rules are grouped as subject and object based on position in the text and the most frequent concepts from each group \(i.e. subject and object\are generated as concept pairs. We defined support count to find the most suitable predicates to label the relationships.   The experiment results have shown that this method is useful to identify relations between concepts even the pair of concepts are in the different sentences  However, it is not sufficient by considering only the most frequent concepts to be accepted as the concept pairs  Even though the proposed method is useful to extract non-taxonomic relations from texts but further research is needed to label the relations appropriately   R EFERENCES   1  R. Agrawal, T. Imielinski, and A. Swami 223 Mining association rules between sets of items in large databases,\224 In proceedings of the1993 ACM SIGMOD international conference on management of data \(pp 207-216\ New York, NY, USA: ACM Press, 1993 2  E. Brill, \223A simple rule-based part-of-speech tagger 224 In Third Conference on Applied Natural Language Processing, 1992 3  A. Imsombut, \223Statistical Approach for Semantic Relation Extraction\224 Eighth International Symposium on Natural Language Processing pg\(54-58\, 2009 4  Jibin Fu, Xiaozhong Fan, Jintao Mao, and Xiaoming Liu, \223Two Stage Relation Extraction\224, Ninth International Conference on Hybrid Intelligent Systems, pg\(327-331\ 2009 5  M. Kavalec, A. Maedche, V. Svatek, \223Discovery of Lexical Entries for Non-taxonomic Relations in Ontology Learning\224, in SOFSEM \226 Theory and Practice of Computer Science, Springer LNCS 2932, 2004 6  M. Kavalec, and V. Svatek, \223A study on Automated Relation Labeling in Ontology learning\224 In: P. Buitelaar, P. Cimiano, B. Magnini \(eds Ontology Learning and Population, IOS Press, 2005 7  D. Lin, \223MINIPAR: a minimalist parser,\224 In Maryland Linguistics Colloquium. University of Maryland, College Park, 1999 8  A. D. Maedche, \224Ontology learning for semantic Web,\224 Norwell, MA USA: Kluwer Academic Publishers, 2002 9  A. Maedche, and R. Volz, \223The ontology extraction and maintenance framework: Text-to-Onto,\224 In Proceeding of the I EEE international conference on data mining, California, USA, 2001   G. A. Miller, 1994, \223Wordnet: An on-line lexical database,\224 International Journal of Lexicography, vol 3\(4\ Special Issue, 1994   R. Navigli, and P. Velardi, \224Learning domain ontologies from document warehouses and dedicated Web sites,\224 Computational linguistic, 30\(2 151-179, 2004   M. F. Porter, \223An algorithm for suffix stripping,\224 Program, Vol. 14 No.3 pp. 130-137\ 1980   J. Punuru,. and J. Chen, \223Extraction of non-hierarchical relations from domain texts,\224 Computational Intelligence and data mining, CIDM 2007, IEEE Symposium on  March 1 2007- April 5 2007. \(pp. 444-449 2007   G. Salton, and C. Buckley, \224Term weighting approaches in automatic text retrieval,\224 Information ,Processing and Management, 24\(5\ 513523, 1988   D. Sanchez,  and A. Moreno, \223Learning non-taxonomic relationships from web documents for domain ontology construction,\224 Data and Knowledge Engineering, 64\(3\ 600-623, 2008   M. Shamsfard, and A. A. Barforoush, \223The state of the art in ontology learning: A framework for comparison 224 Knowledge Engineering Review, 18\(4\, 293-316, 2003   J. Villaverde, A. Persson, D. Godoy, and A. Amandi, \223Supporting the discovery and labeling of non-taxonomic relationships in ontology learning,\224 Expert Systems with Applications, DOI=10.1016/i.eswa 2009.01.048, 2009   E. M. Voorhees. \223Using WordNet to disambiguate word senses for text retrieval,\224 In SIGIR\22293: Proceedings of the 16 th annual international ACM SIGIR conference on research and development in information retrieval \(00.171-180\, New York, NY, USA:ACM Press, 1993  978-1-61284-353-7/11/$26.00 ©2011 IEEE 105 


VII  C ONCLUSION AND F UTURE W ORK  Subgroup discovery is referring to discovery of relations among attributes and predicted classes. This problem has been generally studied in the past with techniques enabled by statistics, datamining and human experts. It is considered as a hybrid between predictive modeling and descriptive analysis where subgroups of similar data are formed pertaining to predicting a particular target class. In this paper, we proposed a novel method for subgroup discovery by using Bayesian network. By this method, probabilities of likenesses for each relation can be explicitly calculated \(that has an advantage of white-box modeling\ and each subgroup can be represented by rules that are readily interpretable for modeling the relations We verified this method by using a small example and reasonable results are produced preliminarily. In the future, we would be working on constructi ng a software prototype that implements this new scheme. We will be putting it to work on actual datasets in large volume so that their results can be further evaluated and compared against other subgroup discovery algorithms for benchmarking. We are also working on evaluating the performance of various quality functions other than WRAcc\ for the purpose of subgroup discovery Considering the good results that Bayesian network has achieved in classification, it is believed that it can yield good results in subgroup discovery scheme as well  R EFERENCES   1  J. Han, M. Kamber, "Data Mining: Concepts and Techniques", Morgan Kaufmann, August 2000 2  N. Friedman, D. Geiger and M. Goldszmidt, "Bayesian Network Classifiers", Machine Learning, 29 \(2/3\, 1997, pp.131-163 3  Heckerman, D., "A tutorial on learning Bayesian networks", Technical Report MSR-TR-95-06, 1995, Microsoft Research 4  Lavrac, N., Kavsek, B., Flach, P., and Todorovski, L., "Subgroup discovery with CN2-SD", Journal of Machine Learning Research, 5 2004, pp.153188 5  Gamberger, D., Lavrac, N., "Generating Actionable Knowledge by Expert-guided Subgroup Discovery", Principles of Data Mining and Knowledge Discovery, LNAI 2431 \(PKDD\ Springer, 2002, pp.163 174 6  Lavrac, N., Kavsek, B., Flach, P., and Todorovski, L., "Subgroup discovery with CN2-SD", Journal of Machine Learning Research, 5 2004, pp.153188 7  Branko Kavsek, Nada Lavrac, and Viktor Jovanoski, "Apriori-sd Adapting association rule learning to subgroup discovery", In Proceedings of the Fifth International Symposium on Intelligent Data Analysis, 2003, Springer, pp.230241 8  Willi Kl¨osgen, "Explora: A multipattern and multistrategy discovery assistant", Advances in Knowledge Discovery and Data Mining, MIT Press, 1996, pp.249271 9  Stefan Wrobel, "An algorithm for multi-relational discovery of subgroups", In Proceedings of the First European Conference on Principles of Data Mining and Knowledge Discovery, Springer, 1997 pp.7887   Atzmueller, M. and Puppe, F., "SD-Map - A fast algorithm for exhaustive subgroup discovery", In Proceddings of the 10th European Conference on Principles and Practice of Knowledge Discovery in Databases \(PKDD 2006\, Berlin, Springer-Verlag, Lecture Notes in Computer Science, 4213, 2006, pp.6-17   Gregory F. Cooper and Edward Herskovits, "A Bayesian Method for the Induction of Probabilistic Networks from Data", Machine Learning 9 1992, pp.309-347   Atzmueller, M., Puppe, F. and Buscher, H. P., "Towards KnowledgeIntensive Subgroup Discovery", In Proceedings Lernen Wissensentdeckung und Adaptivität Workshop \(LWA'04\, 2004, Berlin Germany, pp.117-123   Klösgen, W., "Subgroup Discovery", In Klösgen, W. & Zytkow, J.\(Eds Handbook of Data Mining and Knowledge Discovery, 2002, New York Oxford University Press, pp.354-364   Gamberger, D. and Lavrac, N., "Expert-guided subgroup discovery Methodology and application", Journal Of Artificial Intelligence Research, 17, 2002, pp.1-27  161 


B b \(6 Fig. 2. ARAM neural network If any of the inequalities of \(6 inhibited, if all nodes are inhibited, a new uncommitted node is added. The Match Tracking process is started if needed When each match criterion is satisfied in the respective module, resonance occurs and the learning process follows During learning the selected node K learns to encode the input and target vectors by adjusting its weight vectors W aK and W bK similarly to \(5 B. Multi-label Extensions It has been shown in [7] that standard algorithms do not perform well on the muti-label datasets due to the use of the WTA rule \(2 been proposed: A set of Nb best categories with the largest activation values is chosen according to the rule: a category k is included in the set, if the relative difference \(TK?Tk is below a predefined fraction t of the activation range r = TK ? Tmin, where Tmin is the minimum activation of committed neurons. Activations of the Nb categories are subsequently normalized, uk = TkPN b s=1 Ts The resulting distributed output pattern P is calculated as follows P Nb s=1 usps. \(7 where for FAM ps = W br with r such that W ab sr = 1 which means that between neurons s of ARTa and r of ARTb an association in the Map field exists, and ps = W bs for ARAM. Thus, P contains a score for each label that is proportional to the number of neurons among the Nb best categories predicting this label. Since the fast learning of ART networks leads to varying performance with the input presentation order, voting across several networks trained with different orderings of a training set improves classi 


fication performance. The sum over the output of Equation 7 pattern P , which is used to determine the predicted classes Finally, a postprocessing filter method [12] is applied: the signals P are sorted descendingly, then all corresponding output classes are included in the multi-label up to the point of maximum decrease in the signal size from one class to the next A small modification is made in the ARTb weights, which now count label occurrences during learning by increasing their values by 1 each time the corresponding multi-label is presented. This modification leads to changes in the ARTb activation calculation of ML-FAM which is Tk = |B?W bk Another difference between the multi-label and the standard algorithms is that the former ones do not use Match Tracking with raising vigilance: The winner is simply inhibited C. Comparison of Classifiers To compare the two ART-based networks with other MLclassifiers, we chosen ML-kNN described in [8] and BoosTexter [9] which is an implementation of Boosting for the field of text categorization, based on the well-known AdaBoost algorithm [15]. ML-kNN and BoosTexter were chosen since these popular MC algorithms are nearest-neighbor- and rulebased, respectively, and therefore allow a comparison of the results of ML-FAM and ML-ARAM with algorithms based on other approaches than neural networks IV. PROXIMITY MEASURES FOR HIERARCHIES Approaches for quantitative comparison of graphs and trees are either defined on an abstract level, taking into account only the pure graph structure, or make use of the field specific semantics encoded in the graph. From the former category, we utilized the Constrained Tree Edit Distance CTED  whereas Taxonomic Overlap \(TO  field of concept representation, which also deals with hierarchical structures encoded in graphs and trees. Additionally the Lowest Common Ancestor Path Distance \(LCAPD new tree distance measure, developed especially for the type of hierarchies common in HMC. A description of the mutual differences between these measures and the motivation for the development of a new metric are given at the end of this section 


A. Constrained Tree Edit Distance CTED [10] is based upon the idea of transforming one hierarchy into another via certain local editing operations The distance between two hierarchies is the minimum total number of operations needed for transforming the one into the other. Three modification operations are considered: A node i is deleted by transmitting its children to its parent and removing i from the hierarchy. Inserting is the complement of deleting: Inserting i as a child of j makes i the parent of some subset of the children of j. Changing a node means changing its label. In order to make computation in polynomial time possible, the constraint that disjoint subtrees have to be mapped to disjoint subtrees is included in the definition [10], [16 The original definition does not include any normalization For two hierarchies with q labels each, 2q is the highest possible CTED  corresponding to deleting all labels of the first hierarchy and inserting all labels of the second hierarchy We normalize the CTED by 12q which results in distances in 0, 1 B. Taxonomic Overlap TO [11] compares the nodes of two hierarchies according to how many ancestors and descendants they share. We describe a version adapted to our experiments. Define semantic cotopy as SC\(i,H i j Given two hierarchies H1 and H2, the corresponding overlap for i ? L is defined as O\(i,H1, H2 SC\(i,H1 i,H2 SC\(i,H1 i,H2 Note that this is a symmetric expression in H1 and H2 with values in [0, 1]. The TO of H1 and H2 is the average of all overlaps TO\(H1, H2 1 q  i?L O\(i,H1, H2 For two identical hierarchies, TO is 1, while it is 0 if H1 and H2 are totally unrelated. Since the two other hierarchy 


proximity measures used in the experiments are distances with smaller values indicating higher similarity TO? := 1? TO to simplify comparisons C. LCA-Path Tree Distance Since in a hierarchy a parent is a more general concept than any of its children, the locations of the same label i in two hierarchies H1 and H2 can be compared by how far one has to travel up the chain of ancestors in both hierarchies until a common ancestor is found. For a label i ? L the depth dH\(i 0 dH\(i pH\(i a1, . . . , av the ancestors of i in H1, such that a1 = pH1\(i a2 = pH1\(a1 i common ancestor of i in H1 and H2, lca\(i,H1, H2 first ancestor of i in H1 which is also an ancestor of i in H2 j? := min  j | j ? {1, . . . , v} such that aj ? AH2\(i  lca\(i,H1, H2 Since 0 is an ancestor of all labels in all hierarchies, the LCA always exists. Note that usually lca\(i,H1, H2 lca\(i,H2, H1 We use the LCA to measure how far apart the positions of a label in both hierarchies are: If a label i has the same parent in both hierarchies it is regarded as being in the same position, otherwise the distances of i to its LCA in both hierarchies are used to measure how far apart both locations are. The cost for i is defined as d\(i,H1, H2 2 k=1 dHk\(i lca\(i,H1, H2 D\(i,H1, H2  0, if pH1\(i i d\(i,H1, H2 8 This can be seen as the length of the path from i to lca\(i,H1, H2 i,H1, H2 As D is not symmetric, the complete LCA-path distance 


between H1 and H2 is the mean value D\(H1, H2 1 W  i?L 1 2  D\(i,H1, H2 i,H2, H1  0 1 2 3 a 0 2 1 3 b Fig. 3. Sample hierarchies where W is a normalization factor: The worst case for a misplaced label i is that lca\(i,H1, H2 8 i,H1, H2 i i holds accordingly for D\(i,H2, H1 i?L dH1 \(i i H1, H2  D. Comparison All three hierarchy proximity measures presented above reflect different concepts of tree similarity. It is thus not surprising that CTED and TO*, although they perform well in the domains they were designed for, may produce counterintuitive results when used in the field of HE. This is demonstrated by the hierarchies shown in Figure 3: Despite the fact that the relationships between the nodes in both hierarchies are completely different, their CTED and TO are 0.33 and 0.44, respectively. Their LCAPD, on the other hand, is 1.00. Thus only LCAPD marks both hierarchies with the highest possible distance Some hierarchies used in our experiments contain nodes with exactly one child \(single-child labels that TO* does not distinguish between such labels and their children, in the following sense: Given a hierarchy H and a single-child node i, we denote with H ? the hierarchy 


that is obtained from H by swapping i and its child. Then TO?\(H,H CTED or LCAPD V. EXPERIMENTS We tested the proposed data mining system with four multi-label classifiers: ML-FAM, ML-ARAM, ML-kNN and BoosTexter on three real-world datasets with increasing complexity from the text-mining field. In our experiments we compared extracted hierarchies to the original hierarchy by means of three hierarchy proximity measures: LCAPD CTED, and TO The experimental setup of ML-FAM and ML-ARAM had the following parameter values: choice parameter 0.0001; learning rates ?a,b = 1.0 for fast learning; vigilance parameters ?a = 0.9 and ?b = 1.0. The parameter t was chosen to be 0.05 for the 20 newsgroups dataset and 0.02 for the other datasets. The number of voters V was set to 9 Following [8], we used 10 nearest neighbors \(k = 10 Laplace smoothing \(s = 1 BoosTexter was trained using 500 boosting rounds as in 8] and the threshold for converting rankings into multi-labels was set to 0 [9 A. Multi-label Classification Performance Measures We used a large set of performance measures for evaluation of the MC experiments: First, two example-based measures for multi-label predictions: Accuracy \(A measure \(F  of the predicted labels are actually present while F-measure is the harmonic mean of precision and recall calculated on the per-instance basis. The larger the A and F values, the better the MC performance Then two label-based measures were calculated on the basis of binary counts for each label: the numbers of true positives, true negatives, false positives, and false negatives We used the micro-averaged version of F1 with the binary measures counted on the whole test set. The perfect performance corresponds to F1 = 1. Additionally, micro-averaged precision and recall were used for computing the Area Under a Precision-Recall Curve \(AUPRC  precision corresponds to the proportion of predicted labels in the test set that are correct and recall to the proportion of labels that are correctly predicted. AUPRC has been claimed 


to be a well-suited performance measure for MC tasks where the number of negative instances significantly exceeds the number of positive instances [6]. Another advantage of AUPRC is its global nature and independence of a certain threshold value. The closer the AUPRC value is to 1, the better the performance Since these measures are based on the comparison of multi-labels, they depend on a transformation from rankings to classes. As a contrast we also used four wellknown ranking-based performance measures: One-Error OE RL C cision \(AP  for all ranking-based performance measures except AP. OneError evaluates how many times the top-ranked label is not in the set of proper labels of the instance. Ranking Loss is defined as the average fraction of pairs of labels that are ordered incorrectly. Coverage evaluates how far we need, on average, to go down the list of labels in order to cover all the proper labels of the instance. Average Precision evaluates the average fraction of labels ranked above a particular label i ? mt which actually are in mt And finally, the special hierarchical loss function H-loss 2] were utilized. Following [3], normalized costs were calculated: ci := 1/|c\(p\(i i ? L i of all direct children of i. Hierarchical loss \(H-loss consider mistakes made in subtrees of incorrectly predicted labels and penalizes only the first mistake along the path from the root to a node. The smaller the H-loss value, the better the performance B. 20 Newsgroups Dataset We modified the popular single-label dataset 20 Newsgroups [18], [19] by considering eight additional labels corresponding to the intermediate levels of the hierarchy faith, recreation, recreation/sport, recreation/vehicles, politics, computer, computer/hardware, science. This dataset is a collection of almost 20,000 postings from 20 newsgroups sorted by date into training \(60 40 data were preprocessed by discarding all words appearing only in the test documents and all words found in the stop word list [20]. Afterwards, all but the 2%-most-frequent words were eliminated to reduce the dimensionality. Documents were represented using the well-known TF-IDF \(Term 


Frequency  Inverse Document Frequency scheme [19]. The TF-IDF weights were then normalized to the range of [0, 1]. Conversion to TF-IDF and normalization were performed separately for training and test data. This resulted in the 1,070-dimensional dataset with 11,256 training instances, 7,493 test ones and 28 labels To test the performance of two HE algorithms, we first extracted hierarchies from the True Test Multi-Labels \(TTML and calculated the corresponding proximity measures. Both algorithms successfully extracted the original hierarchy We studied the performance of the multi-label classifiers and their ability to infer the class hierarchies in the presence of only partly available hierarchical information. We performed a series of HE experiments with multi-labels having a decreasing number of inserted non-leaf labels describing the levels in the hierarchy. We randomly removed such labels from 20%, 30%, and 40% of the training instances leaving them single-labeled. The results for predicted test multilabels are shown in Table I where the bold face marks the best classifier, and the first column \(left result of HE by Voting and the second \(right Thresholding \(referred as GT Comparing classification performance, one can see that the ART-based networks are superior to both the other classifiers in terms of most performance measures and that ML-FAM slightly outperforms ML-ARAM. Taken together they win on at least 6 and at most 8 out of 9 evaluation measures. BoosTexter has the second best performance, but its predictive power degrades more quickly with the increase in the number of single-label instances. The poorest MC results were shown by ML-kNN, its performance decreased very fast with any reduction in the number of multi-labels For example, F1 decreased by 15% while removing 40% of labels instead of 30%. It is also interesting to note that when trained on the dataset with 40% removed labels, ML-FAM and ML-ARAM significantly outperformed ML-kNN trained on the original dataset with all labels The hierarchy proximity measures confirm the good quality of predictions produced by the ART-based networks: The hierarchies were correct extracted by both HE algorithms of Section II-B even with 40% removed labels. The predictions of ML-kNN were the worst: The Voting variant of the HE 


algorithm could not extract the correct hierarchy with 30 assigning five labels incorrectly to the root label. None of the HE algorithms could extract the correct hierarchy in the absence of 40% multi-labels. With 40% and Voting, the number of labels falsely assigned to the root was 13, while with GT it was only three. For BoosTexter, Voting assigned two labels wrongly to the root label in the experiment with TABLE I 20 NEWSGROUPS ALL, -20%, -30% AND -40% RESULTS Measure all 20% 30% 40%ARAM FAM kNN BoosT. ARAM FAM kNN BoosT. ARAM FAM kNN BoosT. ARAM FAM kNN BoosT A 0.635 0.638 0.429 0.549 0.613 0.633 0.383 0.456 0.596 0.619 0.322 0.412 0.563 0.591 0.255 0.387 F1 0.694 0.696 0.565 0.677 0.675 0.688 0.528 0.604 0.662 0.677 0.469 0.566 0.640 0.657 0.392 0.542 F 0.691 0.692 0.480 0.605 0.671 0.688 0.429 0.507 0.658 0.676 0.364 0.465 0.630 0.652 0.296 0.441 OE 0.221 0.220 0.336 0.222 0.259 0.236 0.387 0.275 0.273 0.259 0.415 0.301 0.301 0.291 0.434 0.316 RL 0.100 0.098 0.124 0.073 0.108 0.110 0.128 0.077 0.098 0.103 0.132 0.079 0.101 0.106 0.135 0.082 C 4.188 4.168 6.080 4.164 4.397 4.446 6.184 4.286 4.246 4.340 6.326 4.328 4.334 4.463 6.397 4.379 AP 0.789 0.790 0.677 0.778 0.774 0.782 0.657 0.758 0.769 0.774 0.645 0.747 0.759 0.764 0.638 0.740 AUPRC 0.775 0.772 0.618 0.749 0.743 0.727 0.581 0.691 0.733 0.722 0.555 0.671 0.715 0.708 0.535 0.660 H-loss 0.103 0.123 0.121 0.094 0.102 0.098 0.124 0.108 0.106 0.103 0.132 0.117 0.115 0.111 0.145 0.122 Wins 1 5 0 3 1 6 0 2 2 6 0 1 2 6 0 1 LCAPD 0 0 0 0 0 0 0 0 0 0 0.12 0 0.05 0 0 0 0.51 0.26 0.17 0 CTED 0 0 0 0 0 0 0 0 0 0 0.14 0 0.07 0 0 0 0.50 0.21 0.21 0 TO* 0 0 0 0 0 0 0 0 0 0 0.11 0 0.05 0 0 0 0.39 0.18 0.15 0 30% removed labels and and six labels in the experiment with 40% removed labels. GT resulted in zero distances in the both cases. Assigning more labels to the root creates more shallow and wider hierarchies \(trivial case as stated before The good hierarchy extraction with ART networks demonstrates the system robustness  even with strongly damaged data the system can rebuild the original hierarchy C. RCV1-v2 Dataset The next experiment was based on the tokenized version of 


the RCV1-v2 dataset introduced in [21]. Only the topics label set consisting of 103 labels arranged in a hierarchy of depth four is examined here. Documents of the original training set of 23,149 were converted to TF-IDF weights and normalized Afterwards the set was splitted in 15,000 randomly selected documents as training and the remaining as test samples In this case, the Voting variant of HE applied to the TTML resulted in the LCAPD, CTED and TO* values 0.12, 0.15 and 0.13, respectively. The corresponding values of the GT variant are 0.05, 0.07 and 0.05. The poor performance of the Voting method is due to the fact that for the TTML only very high threshold values succeed in removing enough noise The Voting results are thus dominated by bad hierarchies extracted for all but the highest thresholds The classification and HE results for this dataset are shown in Table II. ML-ARAM has better performance results on this data set in all points than ML-FAM except for RL being the best of all classifiers in terms of the multi-label performance measures. BoosTexter is the best in terms of all ranking measures For both HE algorithms the distances of BoosTexter are the best, those of ML-FAM second, followed ML-ARAM and ML-kNN. All three distance measures correlate. Interesting is also that for ML-kNN the distance values obtained by both HE methods are almost the same The hierarchy extracted by GT from the TTML has much lower distances values as compared with the hierarchies extracted by both methods from predicted multi-labels. This reflects a specific problem of HE, since only a small fraction of the incorrectly classified multi-labels can prevent building of a proper hierarchy. For example, 16.5% of misassigned labels in the extracted hierarchy are responsible for about 80% of LCAPD calculated from the predictions of MLARAM. This large part of the HE error is caused by only 4% of the test data. Under these circumstances the other distances behave analogically. Most labels were not assigned making them trivial edges, but six labels were assigned to a false branch. This can happen when labels have a strong correlation and in the step Hierarchy Construction of the basic algorithm the parent is not unique in the confidence matrix. BoosTexters results suffer less from this problem because it generally sets more labels for each test sample 


Both HE algorithms behaved similarly on the predictions of the ART networks. They constructed a deeper hierarchy than the original one and wrongly assigned the same 11 labels to the root node. The higher distances come from Voting assigning more labels to the wrong branch. For MLkNN both algorithms again create very similar hierarchy trees, both misassigned 28 labels to the root label. For BoosTexter it was seven with Voting and eight with GT Voting produced a deeper hierarchy here D. WIPO-alpha Dataset The WIPO-alpha dataset1 comprises patent documents collected by the World Intellectual Property Organization WIPO ments. Preprocessing was performed as follows: From each document, the title, abstract and claims texts were extracted stop words were removed using the list from [20] and words were stemmed using the Snowball stemmer [22]. All but the 1%-most-frequent stems were removed, the remaining stems were converted to TF-IDF weights and these were normalized to the range of [0, 1]. Again, TF-IDF conversion and normalization were done independently for the training and the test set. The original hierarchy consists, from top to bottom, of 8 sections, 120 classes, 630 subclasses and about 69,000 groups. In our experiment, only records from the sections A \(5802 training and 5169 test samples H \(5703 training and 5926 test samples 1http://www.wipo.int/classifications/ipc/en/ITsupport/Categorization dataset/wipo-alpha-readme.html August 2009 TABLE II RCV1-V2 RESULTS Measure ARAM FAM kNN BoosT A 0.748 0.731 0.651 0.695 F1 0.795 0.777 0.735 0.769 F 0.805 0.787 0.719 0.771 OE 0.077 0.089 0.104 0.063 RL 0.087 0.086 0.026 0.015 C 11.598 11.692 8.563 5.977 AP 0.868 0.860 0.839 0.873 AUPRC 0.830 0.794 0.807 0.838 H-loss 0.068 0.077 0.097 0.081 Wins 4 0 0 5 LCAPD 0.29 0.22 0.25 0.20 0.34 0.34 0.21 0.18 


CTED 0.32 0.23 0.28 0.22 0.38 0.37 0.24 0.20 TO* 0.27 0.18 0.22 0.17 0.31 0.30 0.21 0.17 document in the collection has one so-called main code and any number of secondary codes, where each code describes a group the document belongs to. Both main and secondary codes were used in the experiment, although codes pointing to groups outside of sections A and H were ignored. We also removed groups that did not contain at least 30 training and 30 test records \(and any documents that only belonged to such small groups 7,364 test records with 924 attributes each and a label set of size 131 In this case, the Voting variant of the HE algorithm applied to the TTML resulted in the LCAPD, CTED and TO* values of 0.13, 0.12 and 0, respectively. GT showed the same values. Remarkable are the TO* distances, which are equal to 0. This is due to the fact that the WIPO-alpha hierarchy contains 16 single-child labels that are not partitioned by the true multi-labels: whenever a single-child label j is contained in a multi-label, so is its child, and vice versa. It is therefore theoretically impossible to deduce from the multilabels which of them is the parent of the other. As a result the HE algorithms often choose the wrong parent, resulting in higher LCAPD and CTED values. TO*, as described above is invariant under such choices The results obtained on the WIPO-alpha dataset are shown in Table III. The classification performance of the ART-based networks on this dataset is slightly worse than that of BoosTexter. Mostly in the terms of OE, RL, C, AP, AUPRC, and H-loss measures BoosTexter is better because its rankings are better and it assigned more labels to each sample. But the ART networks have better HE results because their predicted labels are more consistent with the original hierarchy. MLkNN has the worst classification results and distance values again. The reason for the high relative difference between LCAPD as well as CTED and TO* obtained for the ART networks or BoosTexter as compared to the results of the other datasets is because most of the labels were assigned in the right branch but not exactly where they belong Both HE algorithms extracted the same hierarchy from the predictions of ML-ARAM and a very similar hierarchy for ML-FAM. About 5% labels were assigned wrongly to the 


root label in the hierarchies of the ART networks. For MLTABLE III WIPO-ALPHA\(AH Measure ARAM FAM kNN BoosT A 0.588 0.590 0.478 0.564 F1 0.694 0.691 0.614 0.693 F 0.682 0.682 0.593 0.679 OE 0.052 0.057 0.110 0.042 RL 0.135 0.136 0.056 0.025 C 25.135 25.269 22.380 11.742 AP 0.790 0.785 0.724 0.802 AUPRC 0.720 0.684 0.688 0.762 H-loss 0.090 0.093 0.149 0.079 Wins 1 2 0 6 LCAPD 0.16 0.16 0.17 0.17 0.32 0.38 0.21 0.21 CTED 0.18 0.18 0.19 0.19 0.38 0.53 0.27 0.27 TO* 0.05 0.05 0.07 0.07 0.24 0.32 0.08 0.08 kNN both HE methods wrongly assigned about the half of the labels and about 20% of total labels were assgined to the root label. Here, GT extracted a much worse hierarchy as shown by CTED being 0.15 higher for GT than for Voting For BoosTexter both HE methods built the same hierarchy and no label was wrongly assigned to the root. All extracted hierarchies were one level deeper than the original one Although Voting produced worse hierarchies than GT on two previous datasets, this time its distance values were comparable or even better. In comparison to Voting, GT has higher values for all distances on the multi-labels of MLkNN. Voting has the advantage of being a much simpler method and of being more dataset independent. Still the tree distances have the same ranking order for all classifiers for both HE methods VI. CONCLUSION In this paper we studied Hierarchical Multi-label Classification \(HMC tive was to derive hierarchical relationships between output classes from predicted multi-labels automatically. We have developed a data-mining-system based on two recently proposed multi-label extensions of the FAM and ARAM neural networks: ML-FAM and ML-ARAM as well as on a Hierarchy Extraction \(HE algorithm builds association rules from label co-occurrences 


and has two modifications. The presented approach is general enough to be used with any other multi-label classifier or HE algorithm. We have also developed a new tree distance measure for quantitative comparison of hierarchies In extensive experiments made on three text-mining realworld datasets, ML-FAM and ML-ARAM were compared against two state-of-the-art multi-label classifiers: ML-kNN and BoosTexter. The experimental results confirm that the proposed approach is suitable for extracting middle and large-scale class hierarchies from predicted multi-labels. In future work we intend to examine approaches for measuring the quality of hierarchical multi-label classifications REFERENCES 1] M. Ruiz and P. Srinivasan, Hierarchical text categorization using neural networks, Information Retrieval, vol. 5, no. 1, pp. 87118 2002 2] N. Cesa-Bianchi, C. Gentile, and L. Zaniboni, Incremental algorithms for hierarchical classification, The Journal of Machine Learning Research, vol. 7, pp. 3154, 2006 3] , Hierarchical classification: combining Bayes with SVM, in Proceedings of the 23rd international conference on Machine learning ACM New York, NY, USA, 2006, pp. 177184 4] F. Wu, J. Zhang, and V. Honavar, Learning classifiers using hierarchically structured class taxonomies, in Proceedings of the 6th International Symposium on Abstraction, Reformulation And Approximation Springer, 2005, p. 313 5] L. Cai and T. Hofmann, Hierarchical document categorization with support vector machines, in Proceedings of the thirteenth ACM international conference on Information and knowledge management ACM New York, NY, USA, 2004, pp. 7887 6] C. Vens, J. Struyf, L. Schietgat, S. Dz?eroski, and H. Blockeel Decision trees for hierarchical multi-label classification, Machine Learning, vol. 73, no. 2, pp. 185214, 2008 7] E. P. Sapozhnikova, Art-based neural networks for multi-label classification, in IDA, ser. Lecture Notes in Computer Science, N. M Adams, C. Robardet, A. Siebes, and J.-F. Boulicaut, Eds., vol. 5772 Springer, 2009, pp. 167177 8] M. Zhang and Z. Zhou, ML-kNN: A lazy learning approach to multilabel learning, Pattern Recognition, vol. 40, no. 7, pp. 20382048 2007 9] R. Schapire and Y. Singer, BoosTexter: A boosting-based system for text categorization, Machine learning, vol. 39, no. 2, pp. 135168 


2000 10] K. Zhang, A constrained edit distance between unordered labeled trees, Algorithmica, vol. 15, no. 3, pp. 205222, 1996 11] A. Maedche and S. Staab, Measuring similarity between ontologies Lecture notes in computer science, pp. 251263, 2002 12] G. Carpenter, S. Martens, and O. Ogas, Self-organizing information fusion and hierarchical knowledge discovery: a new framework using ARTMAP neural networks, Neural Networks, vol. 18, no. 3, pp. 287 295, 2005 13] A.-H. Tan and H. Pan, Predictive neural networks for gene expression data analysis, Neural Networks, vol. 18, pp. 297306, April 2005 14] G. Carpenter, S. Grossberg, N. Markuzon, J. Reynolds, and D. Rosen Fuzzy ARTMAP: A neural network architecture for incremental supervised learning of analog multidimensional maps, IEEE Transactions on Neural Networks, vol. 3, no. 5, pp. 698713, 1992 15] Y. Freund and R. Schapire, A decision-theoretic generalization of online learning and an application to boosting, Journal of computer and system sciences, vol. 55, no. 1, pp. 119139, 1997 16] K. Zhang and T. Jiang, Some MAX SNP-hard results concerning unordered labeled trees, Information Processing Letters, vol. 49 no. 5, pp. 249254, 1994 17] G. Tsoumakas and I. Vlahavas, Random k-labelsets: An ensemble method for multilabel classification, Lecture Notes in Computer Science, vol. 4701, p. 406, 2007 18] K. Punera, S. Rajan, and J. Ghosh, Automatic construction of nary tree based taxonomies, in Proceedings of IEEE International Conference on Data Mining-Workshops. IEEE Computer Society 2006, pp. 7579 19] T. Joachims, A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization, in Proceedings of the Fourteenth International Conference on Machine Learning. Morgan Kaufmann Publishers Inc. San Francisco, CA, USA, 1997, pp. 143151 20] A. McCallum, Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering, 1996 http://www.cs.cmu.edu/ mccallum/bow 21] D. Lewis, Y. Yang, T. Rose, and F. Li, RCV1: A new benchmark collection for text categorization research, The Journal of Machine Learning Research, vol. 5, pp. 361397, 2004 22] M. Porter, Snowball: A language for stemming algorithms, 2001 http://snowball.tartarus.org/texts/introduction.html 


the US census data set. The size of pilot sample is 2000, and all 50 rules are derived from this pilot sample. In this experiment the ?xed value x for the sample size is set to be 300. The attribute income is considered as a differential attribute, and the difference of income of husband and wife is studied in this experiment. Figure 3 shows the performance of the 5 sampling 331 6DPSOLQJ9DULDQFH             9D UL DQ FH R I V WL PD WL RQ  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW    


      6D PS OL QJ  RV W 9DU 9DU 9DU 5DQG b 6DPSOLQJ$FFXUDF          5  9DU 9DU 9DU 5DQG c Fig. 2. Evaluation of Sampling Methods for Association Rule Mining on the Yahoo! Dataset procedures on the problem of differential rule mining on the US census data set. The results are also similar to the experiment results for association rule mining: there is a consistent trade off between the estimation variance and sampling cost by setting their weights. Our proposed methods have better performance than simple random sampling method 


We also evaluated the performance of our methods on the Yahoo! dataset. The size of pilot sampling is 2000, and the xed value x for the sample size is 200. The attribute price is considered as the target attribute. Figure 4 shows the performance of the 5 sampling procedures on the problem of differential rule mining on the Yahoo! dataset. The results are very similar to those from the previous experiments VI. RELATED WORK We now compare our work with the existing work on sampling for association rule mining, sampling for database aggregation queries, and sampling for the deep web Sampling for Association Rule Mining: Sampling for frequent itemset mining and association rule mining has been studied by several researchers [23], [21], [11], [6]. Toivonen [23] proposed a random sampling method to identify the association rules which are then further veri?ed on the entire database. Progressive sampling [21], which is based on equivalence classes, involves determining the required sample size for association rule mining FAST [11], a two-phase sampling algorithm, has been proposed to select representative transactions, with the goal of reducing computation cost in association rule mining.A randomized counting algorithm [6] has been developed based on the Markov chain Monte Carlo method for counting the number of frequent itemsets Our work is different from these sampling methods, since we consider the problem of association rule mining on the deep web. Because the data records are hidden under limited query interfaces in these systems, sampling involves very distinct challenges Sampling for Aggregation Queries: Sampling algorithms have also been studied in the context of aggregation queries on large data bases [18], [1], [19], [25]. Approximate Pre-Aggregation APA  categorical data utilizing precomputed statistics about the dataset Wu et al. [25] proposed a Bayesian method for guessing the extreme values in a dataset based on the learned query shape pattern and characteristics from previous workloads More closely to our work, Afrati et al. [1] proposed an adaptive sampling algorithm for answering aggregation queries on hierarchical structures. They focused on adaptively adjusting the sample size assigned to each group based on the estimation error in each group. Joshi et al.[19] considered the problem of 


estimating the result of an aggregate query with a very low selectivity. A principled Bayesian framework was constructed to learn the information obtained from pilot sampling for allocating samples to strata Our methods are clearly distinct for these approaches. First strata are built dynamically in our algorithm and the relations between input and output attributes are learned for sampling on output attributes. Second, the estimation accuracy and sampling cost are optimized in our sample allocation method Hidden Web Sampling: There is recent research work [3 13], [15] on sampling from deep web, which is hidden under simple interfaces. Dasgupta et al.[13], [15] proposed HDSampler a random walk scheme over the query space provided by the interface, to select a simple random sample from hidden database Bar-Yossef et al.[3] proposed algorithms for sampling suggestions using the public suggestion interface. Our algorithm is different from their work, since our goal is sampling in the context of particular data mining tasks. We focus on achieving high accuracy with a low sampling cost for a speci?c task, instead of simple random sampling VII. CONCLUSIONS In this paper, we have proposed strati?cation based sampling methods for data mining on the deep web, particularly considering association rule mining and differential rule mining Components of our approach include: 1 the relation between input attributes and output attributes of the deep web data source, 2 maximally reduce an integrated cost metric that combines estimation variance and sampling cost, and 3 allocation method that takes into account both the estimation error and the sampling costs Our experiments show that compared with simple random sampling, our methods have higher sampling accuracy and lower sampling cost. Moreover, our approach allows user to reduce sampling costs by trading-off a fraction of estimation error 332 6DPSOLQJ9DULDQFH      


     V WL PD WL RQ R I 9D UL DQ FH  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW          6D PS OL QJ  RV W 9DU 9DU 


9DU 5DQG b 6DPSOLQJ$FFXUDF          5  9DU 9DU 9DU 5DQG c Fig. 3. Evaluation of Sampling Methods for Differential Rule Mining on the US Census Dataset 6DPSOLQJ9DULDQFH             9D UL DQ FH R I V WL 


PD WL RQ  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW          6D PS OL QJ  RV W  9DU 9DU 9DU 5DQG b 6DPSOLQJ$FFXUDF         


    5  9DU 9DU 9DU 5DQG c Fig. 4. Evaluation of Sampling Methods for Differential Rule Mining on the Yahoo! Dataset REFERENCES 1] Foto N. Afrati, Paraskevas V. Lekeas, and Chen Li. Adaptive-sampling algorithms for answering aggregation queries on web sites. Data Knowl Eng., 64\(2 2] Rakesh Agrawal and Ramakrishnan Srikant. Fast algorithms for mining association rules. In Proceedings of the 20th International Conference on Very Large Data Bases, pages 487499, 1994 3] Ziv Bar-Yossef and Maxim Gurevich. Mining search engine query logs via suggestion sampling. Proc. VLDB Endow., 1\(1 4] Stephen D. Bay and Michael J. Pazzani. Detecting group differences Mining contrast sets. Data Mining and Knowledge Discovery, 5\(3 246, 2001 5] M. K. Bergman. The Deep Web: Surfacing Hidden Value. Journal of Electronic Publishing, 7, 2001 6] Mario Boley and Henrik Grosskreutz. A randomized approach for approximating the number of frequent sets. In ICDM 08: Proceedings of the 2008 Eighth IEEE International Conference on Data Mining, pages 4352 Washington, DC, USA, 2008. IEEE Computer Society 7] D. Braga, S. Ceri, F. Daniel, and D. Martinenghi. Optimization of Multidomain Queries on the Web. VLDB Endowment, 1:562673, 2008 8] R. E. Ca?isch. Monte carlo and quasi-monte carlo methods. Acta Numerica 7:149, 1998 9] Andrea Cali and Davide Martinenghi. Querying Data under Access Limitations. In Proceedings of the 24th International Conference on Data Engineering, pages 5059, 2008 10] Bin Chen, Peter Haas, and Peter Scheuermann. A new two-phase sampling based algorithm for discovering association rules. In KDD 02: Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 462468, New York, NY, USA, 2002 ACM 


11] W. Cochran. Sampling Techniques. Wiley and Sons, 1977 12] Arjun Dasgupta, Gautam Das, and Heikki Mannila. A random walk approach to sampling hidden databases. In SIGMOD 07: Proceedings of the 2007 ACM SIGMOD international conference on Management of data pages 629640, New York, NY, USA, 2007. ACM 13] Arjun Dasgupta, Xin Jin, Bradley Jewell, Nan Zhang, and Gautam Das Unbiased estimation of size and other aggregates over hidden web databases In SIGMOD 10: Proceedings of the 2010 international conference on Management of data, pages 855866, New York, NY, USA, 2010. ACM 14] Arjun Dasgupta, Nan Zhang, and Gautam Das. Leveraging count information in sampling hidden databases. In ICDE 09: Proceedings of the 2009 IEEE International Conference on Data Engineering, pages 329340 Washington, DC, USA, 2009. IEEE Computer Society 15] Loekito Elsa and Bailey James. Mining in?uential attributes that capture class and group contrast behaviour. In CIKM 08: Proceeding of the 17th ACM conference on Information and knowledge management, pages 971 980, New York, NY, USA, 2008. ACM 16] E.K. Foreman. Survey sampling principles. Marcel Dekker publishers, 1991 17] Ruoming Jin, Leonid Glimcher, Chris Jermaine, and Gagan Agrawal. New sampling-based estimators for olap queries. In ICDE, page 18, 2006 18] Shantanu Joshi and Christopher M. Jermaine. Robust strati?ed sampling plans for low selectivity queries. In ICDE, pages 199208, 2008 19] Bing Liu. Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data \(Data-Centric Systems and Applications Inc., Secaucus, NJ, USA, 2006 20] Srinivasan Parthasarathy. Ef?cient progressive sampling for association rules. In ICDM 02: Proceedings of the 2002 IEEE International Conference on Data Mining, page 354, Washington, DC, USA, 2002. IEEE Computer Society 21] William H. Press and Glennys R. Farrar. Recursive strati?ed sampling for multidimensional monte carlo integration. Comput. Phys., 4\(2 1990 22] Hannu Toivonen. Sampling large databases for association rules. In The VLDB Journal, pages 134145. Morgan Kaufmann, 1996 23] Fan Wang, Gagan Agrawal, Ruoming Jin, and Helen Piontkivska. Snpminer A domain-speci?c deep web mining tool. In Proceedings of the 7th IEEE International Conference on Bioinformatics and Bioengineering, pages 192 199, 2007 24] Mingxi Wu and Chris Jermaine. Guessing the extreme values in a data set a bayesian method and its applications. VLDB J., 18\(2 25] Mohammed J. Zaki. Scalable algorithms for association mining. IEEE Transactions on Knowledge and Data Engineering, 12:372390, 2000 


333 



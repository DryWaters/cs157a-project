  Decision Rule Acquisition Algorithm based on Association-Characteristic Information Granular Computing  JianFeng Xu  1 Lan Liu 1  GuangZuo Zheng  2  Yao Zhang  2  1 NanChang University, Jiangxi, 330031, P.R.China  2 Galway-Mayo Institute of Technology, Ireland  E-mail: jianfeng_x@ncu.edu.cn liulanxf@sohu.com cryingzgz@gmail.com, you1gerenaiwo@gmail.com   Abstract This is a article of research which bases on the classical granular computing and the Association Rules focus on the association rules and decision-making rules 
of the information system. Firstly, defines a associationrule characteristic Information Granule, which can be treated as a sub-definition of the Information Granule and a association-rule characteristic Information Granularity matirx is defined as well. Secondly, we present a new approach of computing on support degree and confidence degree, which are commonly used in problems of association-rule and decision-rule in information systems. Finally we build a whole knowledge-obtaining algorithm for the association rules and decision-making, and test its availability by numerous experiments  1. Introduction  Granular Computing is a fast-developing subject 
and it is a fusion of the rouge set, fuzzy mathematic and Artificial Intelligence 1,2,3,4 Base on the philosophical thinking, it builds the granular structure of the realworld problem, and finds the solution of that problem by setting the computing model on the granular structure. It is a combination of Philosophical Thinking Methodology and Computing Model. Studying the granular computing methods and building the granular computing models, under the guide of the philosophical thinking, is the main research direction of Granular Computing in the future 
In this article, we present the definitions of the association-rule Information Granularity matrix, the association-rule Information Granul, the association-rule Information Granularity matrix, and the Algorithm that based on the theories above  2. Primary Definitions  All printed material, including text, illustrations, and charts, must be kept within a print area of 6-1/2 inches 16.51 cm\wide by 8-7/8 inches \(22.51 cm\igh. Do not write or print anything outside the print area. All text  must be in a two-column format. Columns are to be 31/16 inches \(7.85 cm\wide, with a 3/8 inch \(0.81 cm 
space between them. Text must be fully justified A format sheet with the margins and placement guides is available as both Word and PDF files as format.doc> and <format.pdf>. It contains lines and boxes showing the margins and print areas. If you hold it and your printed page up to the light, you can easily check your margins to see if your print area fits within the space allowed Definition 1 Information system S  031 U 031 AT 031 the U 
is the dataset of training samples AT is attribute set One of the records of the training sample in S is event T  U T 002 021  Definition 2 granulating the information system information system S 031 set B 002 AT according to whether B has a value, actual range VB 1, 0 Then B 
can decompose into binary granularity set according to the quotient set U/IND  B   And the combination of all the Information Granul is GM 031 granularity matrix 031  For example: in different events, the property B which is in the information system S is set to 1 KøKøKøKøKøKøKøKøKøKøK 00100100110, then B can be decomposed into a binary granulation b 1 
100100100110 J  For example:three atributes a  b and c which are in the information system S are set value of 101000011001 KøKøK 100101001101 110101000101 then these atributes can be converted into 3 binary granulation a 101000011001 b 100101001101 c 110101000101 And they can be convert into the matrix GM J  
2010 IEEE International Conference on Granular Computing 978-0-7695-4161-7/10 $26.00 © 2010 IEEE DOI 10.1109/GrC.2010.38 812 


   000 000 000 000 000 000  01 1101010001 01 1001010011 01 1010000110 GM  Definition 3 Granular degree of binary information granule. Assuming the amount of digit 1 in a binary information granule of attribute P is the granular degree of this information granule P then, the support number of an itemset of this attribute P is equal to the granular degree P For example, the granular degree a of binary information granule a 101000011001, is 5 Definition 4  I k K itemset  and its granulating. In the information system S the set which contains the associating K attributes is called K itemset. Its granulating is the conjunctive of those k binary granule of attributes, And the outcome is a binary Information Granule whose granular degree is much smaller For example L\006 information system S K C 1  C 2  C k are the binary information  granules of those K atributes Then C 1  003  C 2 003  003 C k are K itemset K its granular degree is C 1  003  C 2 003  003 C k   Definition 5 L\006 support degree L\006 The support degree of the k itemset, is the probability of the k itemset in U  equal to P  I k  I k  U  J The granular degree of the itemset is its support number Definition 6  K Item association-rule. The support degree of I k  which is bigger than an assigned value J  Definition  7 L\006 Confidence degree Assume C is the condition attribute of the association-rule D is the decision-making attribute of the association-rule, then confidence degree of C 001 D is P  D  C  L\011  D  003  C  C  000\003 Definition 8 decision-making rules. The associationrule which satisfies the minimum-support-degree and minimum-confidence-degree at the same time, the rule C 001 D is called decision-making rule  3  The Basic Theory of Association-rule Characteristic Information Granule  Definition 9 the granulating of associationcharacteristic of I k is the binary bunch whose length is  AT which is associated with the attributes subscript  The binary bunch value will be set to '1  whose position relative with the attribute appears in I k t otherwise it will be set to '0 All of the association-characteristic information granule in I k could be combined into a matrix RM k  K We will use association-characteristic information granule P ki to represent associated I Ki P ki is a line of RM k K For example, in the information system S  AT  a,b,c 2 item-set LG a,b LILG  b,c LI  a,c means P 21 L\011K K K 110 P 22  KôKõK 011 P 23  KôK 101 its 2 itemset's association-rules martix  000 000 000 000 000 000  101 011 110 2 RM  Theorem 1 the amount of atributes in the information system S is N K 000  AT  L\011  N K its 1 itemset associationrule matrix is N steps matrix.For example: in the information system S  AT  a,b,c 1 itemset association-rule matrix is 000 000 000 000 000 000  001 010 100 1 RM  Definition 10 the granulating of the K itemset's association rules.:same with definition 9 Theorem 2: the granule degree of P k iS P ki  GM  P ki 003 GM j   If P ki 003 GM j  L\011 P ki K then P ki 003 GM j  L\011 1, otherwise  P ki 003 GM j  L\011 0 Prove  000 if P ki 003 GM j  L\011  P ki   means the jth event satisfy the association rules P ki 000 the Information Granule which P ki stands for should be set to 1, otherwise should be 0 000 if P ki 003 GM j  000  P ki stand for the number jth event do not satisfy the itemset association P ki 000 so P ki so the Information Granule which P ki stands for should be set to 1  004 the granule degree of P k   P k  L\011 P ki  GM  000  003 U j j ki GM P 1  Theorem 3 Assume RM ki  RM kj as two item association-characteristic information granule,and  RM ki 005 RM kj  L\011 K 1 000 RM ki 005 RM kj are k 1 item association-characteristic information granule Definion 4 K items association-rules information granule P k is a combined with condition attribute set C  and decision-making attribute set D  D k C k k P P P   006  the support degree of decisionmaking rules C 001 D  L\011  P k  P k-D    4. Decision Rule Acquisition Algorithm based on Associat ion-Characteristic   Assume that there are n attributes and m events in the information system S  Step 1: Granulating the information system S create the GM of the information system  Step 2: Build RM 1 based on Theorem 1 
813 


  Step 3:According to Definition 5 and Theorem 2 calculate the support degree of the GM 1   Step 4:Delete the association-characteristic information granule form the matrix whose support degree is below the specified minimum-support-degree  Step 5: FOR i L\011 1 i  L\011 n K i  K   According to Theorem 3, can obtain the i+1 associationcharacteristic information granule matrix RM i+1\, form RM i  Delete the association-characteristic information granule whose support degree is below specified minimum K support K degree If the matrix is empty, then break  step6: According to Theorem 5 computing the decisionmaking rules  5. Simulation Experiment  Information system S as the Table 1 Table1. list of the experiment information of the system U  AT  T 1  a,b,d T 2  a,b,c,e T 3  a,c T 4  a,b,c T 5  a,c,d T 6  a,b,d,e T 7  a,b T 8  a,c,f T 9  a T 10  b,c T 11  c,g  STEP1: according to definition 7, granulating the existence of each attribute in database,  obtain the binary granule of all the attribute sets. The result is shown below L\006  a L\006 11111111100 b L\006 11010110010 c L\006 00111001011 d L\006 11001100000 e L\006 01000100000 f L\006 00000000100 g L\006 00000000001 Combine information granule of the attributes above to the following information granule matrix 000 000 000 000 000 000 000 000 000 000 000 000 000 000  1 0000000000 0 0000000010 0 0100010000 0 1100110000 1 0011100101 0 1101011001 0 1111111110 g f e d c b a GM    STEP2 build RM1 based on Theorem 1 as follows  000 000 000 000 000 000 000 000 000 000 000 000 000 000  000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000  0000001 0000010 0000100 0001000 0010000 0100000 1000000 7  1 6  1 5  1 4  1 3  1 2  1 1  1 1 P P P P P P P RM  STEP3: according to Definition 5 and Theorem 2 calculate the support degree of the GM 1   P 1 K 1  GM L\011 100000 GM  000  003 11 1 6  1 j j GM P 9 P 1 K 2  GM L\011 010000 GM  000  003 11 1 6  1 j j GM P 6 P 1 K 3  GM L\011 001000 GM  000  003 11 1 6  1 j j GM P 7 P 1 K 4  GM L\011 000100 GM  000  003 11 1 6  1 j j GM P 3 P 1 K 5  GM L\011 000010 GM  000  003 11 1 6  1 j j GM P 2 P 1 K 6  GM L\011 000001 GM  000  003 11 1 6  1 j j GM P 1 P 1 K 7  GM L\011 000000 GM  000  003 11 1 6  1 j j GM P 1 STEP4: If the association-characteristic granule whose support number is below 2\(e.g P 1 K 6 and P 1 K 7 will be deleted from matrix. And then obtains a new matrix RX 1  as the follows 000 000 000 000 000 000 000 000 000 000  0000100 0001000 0010000 0100000 1000000  1 RX  STEP5  According to Theorem 3, obtain Two item association-characteristic in formation granule matrix RM 2 and two item association-characteristic information granule matrix RM 2 of association-rule\(as shown in Figure 1 and Figure 2\hen obtain the RM 3 RM 3 RM 4 and RM 4 as the same way\(as shown in Figure 3,4,5,6\.It 
814 


  is shown that the RM 4 is empty, which means, RM 3 is the target  000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000  0001100 0010100 0011000 0100100 0101000 0110000 1000100 1001000 1010000 1100000 2 RX  Figure 1:RM 2    000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000  0001100 0100100 0101000 0110000 1000100 1001000 1010000 1100000  2 RX  Figure 2: RM2   000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000 000  0101100 0110100 0111000 1001100 1101000 1001100 1010100 1011000 1100100 1101000 1110000 3 RX  Figure 3: RM3   000 000 000 000 000 000  1011000 1101000 1110000  3 RX  Figure 4: RM3    1111000 4  RX  Figure 5: RM4    007   4 RX  Figure 6: RM4  Since  RX 4   L\011 0 RX 3 is the target , and from RX3 we can get 3 association rules: {a,b,e:2 K a,b,d:2 K a,b,c:2 STEP6: assume the value of minimum-confidence is 30 KòK according to Theorem 5, calculates the decisionmaking rules. Obtains the decision-making rule as the following process  a,b,e:2 L\006 p\(be|a\9 p\(ae|b\6  , p\(ab|e\2 p\(a|be\2  p\(b|ae\2, p\(e|ab\5 a,b,d:2 L\006 p\(bd|a\9 p\(ab|d\3  , p\(ad|b\6 p\(a|bd\2   p\(d|ab\5 p\(b|ad\3 a,b,c:2 L\006 p\(bc|a\9 p\(ab|c\7 p\(ac|b\6 p\(a|bc\3   p\(b|ac\5  p\(c|ab\5 Then delete the one whose support degree is below 30 and get the final result ae KøKøKøK 001 ab 001 a 001 be b 001 ae e 001 ab ab 001 d  ad K 001 b  a KøKøKøKøK 001 bd d 001 ab b 001 ad ac 001 b a 001 bc b 001 ac KøJ c 001 ab  6  Algorithm Analysis L\006  To show the advancements of this algorithm experiment is taken under the environment of Intel core 2.0 GHz, 3 GB memory, Windows7 operation system and the programming language is C++. The screenshot of the experiment is Figure 7   Figure 7 The screenshot of the experiment  The system use dataset which is collected from a financial company. There are 5000 records and 90 attributes in database Compares the algorithm in our artical with Apriori algorithm, figure 8 offers distinguish of execution time between the two algorithms when their support degrees are different. Fgure 9 shows that, the less support degree is, the shorter execution time of our algorithm will be, it figures out that our algorithm will be much faster when the support degree is small, and it will be more effective when the records in database are huge 000\023 000\025 000\027 000\031 000\033 000\024 000\023 000\025\000\023\000\010 000\026\000\023\000\010 000\027\000\023\000\010 000\030\000\023\000\010 000&\000O\000D\000V\000V\000L\000F\000D\000O\000\003 000$\000S\000S\000U\000R\000D\000F\000K 000$\000U\000W\000L\000F\000O\000H\000\003 000$\000S\000S\000U\000R\000D\000F\000K  Figure 8, comparison of time cost while the support degrees are different   
815 


  000\023 000\024 000\023 000\025 000\023 000\026 000\023 000\027 000\023 000\030 000\023 000\031 000\023 000\032 000\023 000\025\000\023\000\010 000\027\000\030\000\010 000\032\000\023\000\010 000\024\000\023\000\023\000\010 000&\000O\000D\000V\000V\000L\000F\000D\000O 000\003 000$\000S\000S\000U\000R\000D\000F\000K 000$\000U\000W\000L\000F\000O\000H\000\003 000$\000S\000S\000U\000R\000D\000F\000K  Figure 9, comparison of time cost while the records are different   The algorithm that we presented in the article does not need to store all the candidate itemsets, it just needs to save boolean type 0 and 1 as bit mode. As a result, this will save more memory, and with better spatial features    7   Conclusion Under the background of granule computing, our research team present a new algorithm to solve the problems of association-rule and decision-making rule in data mining. The results of the experiments prove that our algorithm is feasible and efficient. There are still a lot of work to do to improve the efficiency of  our algorithm, such as the reduction of the granule matrix in step 5. Overall, the work of research show the promising future of granule computing     8. References  1 D u o q ia n m i a o G uoy in,w a ng .G r a nula tion c o m puti n g  the  past K now and  futrue[M  pe ik ing  2 00 7:p p 1 5 4  1 6 0  2 qi ng liu R o ug hR o u g h t he s e t inf e r e nc e  M  pe k ing  s i c i e n c e  publishing house ,2001:pp100~116 3 Za de h L o tf i A   G r a nula r c o m puting a nd r oug h s e t  theory[C te rna tio na l C onf e r e n c e on R oug h Se ts a n d  Intelligent Systems Paradigms, RSEISP 2007 K Warsaw Poland K pp.1~4 4 X i e K M KøK Chen ZH Xie G,et al.BGRC for superheated steam temperature system modeling in power plant[C T h e 2006IEEE International Confedence on Granular Computing,,Atlanta,USA,2006: pp708~711 5 Q i ng L i u, S  L  J i a n g  R e a s onin g a bout I n f o r m a tion G r a nule s  Based on Rough Logic[C  R S C T C 2002,L N A I 2475  pp.139~143 6 Yiy u Ya o G r a nula r Com puting a nd Co ng nitiv e  Information[C I C C I 20 06 V o l.I  pp1 7 1 8      
816 


Step 4 Identify the error estimate by running the remaining one-third of dataset through the tree and compute the correctness Algorithm Decision tree classifier Decision classifier consists of a collection of individual tree classifier. The general concept has been given below 1 Select N the number of trees to grow, and m a number no larger then the number of variables 2 for i=1 to N Call Train set 3 Draw a bootstrap sample from the data, term those not in the bootstrap sample as out-of-bag data 4 Grow a random tree, where at each node the best set is chosen among m randomly selected variables. The tree is grown to a maximum size and it should not be pruned 5 Use the tree to predict out-of-bag data 6 In the end use the predictions on out-of-bag data to form majority votes 7 Prediction of test data is done by majority votes from predictions from the ensemble of trees By applying the concept of decision tree classifier a three class classifier to classify the transactional database objects as normal, benign and malignant IV R ESULTS AND D ISCUSSION A Classification Figure 7. Represents segmented output image of shape prior technique created image which is segmented from binary output image \(figure 6 then Classification involves segregating the data into segments which are non-overlapping Any approach to classification assumes some knowledge about the data termed as training. Performance of classification assignment has been measured in terms of classification accuracy. The outcome of classification can be described as  True positive TP\: A row t i predicted to be in class C j and is actually in it  False positive FP\: A row t i predicted to be in class C j but is actually not in it  True negative TN\: A row t i not predicted to be in class C j but is actually not in it  False negative FN\: A row t i not predicted to be in class C j but is actually in it  The precision and recall are used to determine the accuracy of the classifier Fig. 6 Binary output image Fig.7. Segmented output image   FP TP TP Precision    3  FN TP TP Recall   4 B. Confusion Matrix The accuracy of the classification technique has been indicated using the confusion matrix. When the system contains s number of matrix, the confusion matrix is in the form of sxs matrix. If there exists any entry for example C j means it represents the number of rows assigned to a class C j instead of the classification C i The general form of the confusion matrix is given in the following table I. The proposed system consists of three classes for classification like Normal, Benign and Malignant. The confusion matrix that represents the association rule 3 under the decision tree classification is a 3x3 matrix. This association rule consists of 200 rules for instances means then 151 are normal, 27 are malignant and 22 are benign TABLE I GENERAL TWO CLASS CONFUSION MATRIX Human provision Category Yes No Yes TP FP Classifier provision No FN TN 


TABLE II CONFUSION MATRIX FOR DECISION TREE CLASSIFIER USING 3X3 MATRIX Confusion matrix NBM N 151\(C 11  000\(C 12  000\(C 13  B 007\(C 21  020\(C 22  000\(C 23  M 007\(C 31  015\(C 32  015\(C 33  The following table II gives the number of correctly classified decisions using confusion matrix C. Precision and Recall An important truth to be notices is that both the association rule mining and the decision tree classifier performs relatively well on the transactional database. Using the equation \(3\ and 4\ precision and recall values are computed for the data stored in the database. The following graph gives the precision and recall value for the proposed system compared with the neural network and associative classifier. Figure 8 represents the precision and recall graph D. Classifier efficiency Using the TP, TN, FP, FN values the classifier efficiency can be determined in the form of accuracy, specificity and sensitivity. The classifier efficiency compared with the other type of classifier has been given in the following table III Fig. 8 Precision and Recall graph TABLE III COMPARATIVE PERFORMACE OF ALGORITHMS Measure Proposed Method Association Rule NN Accuracy 90 87 83 Sensitivity 97 96 88 Specificity 96 92 85 Accuracy= \(TP + TN\/\(TP+TN+FP+FN\;Sensitivity = TP/\(TP +FN Specificity = TN/\(TN+FP V C ONCLUSION In the proposed system CT-Scan brain images has been proven to be a significant way to detect the brain tumor. The new technique called Shape priori algorithm for pre-processing of images has given the efficient features to be stored in the transactional database. The feature selection using Association rule mining algorithm has given the best way of identifying the rule to be used for classification phase. Decision tree classifier classifies the rules according to the class labels and it assists the physicians for taking the better decision R EFERENCES 1 B a k i  K o yu n c u  a n d A l p e r Pa s h a    G e n er a t i n g co nt ou r s o f br a i n t u m o r  images by using their optical density information and image correlation techniques, Journal of X-ray Science and Technology 15\(2007\ 1-7 2 S er ha t O z ek e s   A  Y i l m e z C a m u r c u   C om pu t e r a i d e d d e t e ct i o n o f  Mammographic masses on CAD digital Mammograms stanbul Ticaret niversitesi Fen Bilimleri  2005/2  pp.87-97 3 H a r is  K a n d  E f s t r a tia d i s  S  N   H y b r i d i m a g e  s e g m e n ta ti o n u s i n g  Watersheds and fast region merging IEEE Trans.on Image Processing vol.7, No.12 Dec 1998 pp.1684 - 1699 4 G o n z a l e z  R  C and  W oods  R  E  D i gi t a l i m a g e  p r oc es s i ng  P e a r s o n  Education, Singapore, 2002 5 Z ex uan Z h u Y e wSo on O n g   M a no r a nj an D a s h   W r a p p e r f i l t e r  f e at ur e selection algorithm using a memtic framework, IEEE transactions on System, Man, and Cybernetics Part B, Cybernetics : a publication of the IEEE systems, man and cybernetics society 2007: 37\(1 6 L  Y u  H  L i u   E f f i c i ent l y  ha n d l i ng  f e a t u r e r e du nda n c y i n  hi gh dimensional data, in. proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining KDD-03\, Washington, DC, August, 2003, pp. 685-690 7 J  R   C a no  F H e r r e r a a n d  M  L o z a no   E vo l u t i on ar y s t r a t i f i e d t r ai n i ng set selection for extracting classification rules with trade off precisioninterpretability, Data and Knowlegde Engineering, Vol. 60, No. 1 pp.90-108, 2007 8 X   B  L i  J   S w e i ga r t  J  T e n g  J  D o no hu e a nd L  T h o m b s   A D y na m i c  programming based pruning method for decision trees , INFORMS. J computing, Vol.13, pp. 332-344, 2001 9 E  K l a s s e n A   S r i v a s t a va  W  Mi o  a n d S  J o s h i    A na l y s i s o f pl a n a r  shapes using geodesic paths on shape spaces IEEE Trans. Pattern Anal. Mach. Intell., vol. 26, no. 3 Mar. 2003, pp. 372383  P  C a nc el a  F  R e yes   P  R o d r  g uez  G  R a nd al l  a n d  A   Fe r n nd ez  Automatic object detection using shape information in ultrasound images in Proc. 3rd Int. Conf. Image Process., 2003 pp. 417420  W  O  H e r r i ng  D  C  Mi l l e r  J  K  B e r t r a nd and L  L  B e n y s h e k   E v al ut i on of Machine, Technician and interpreter effects on ultrasonic measures of back-fat and longissimus muscle area in beef Cattle, J.Animal Sci., Vol72, No. 9,1994, pp. 2216-2226 12 A g r a w a l R   S r ik a n t R. F a s t A l g o r i t h m s f o r M i n i n g A s s o c ia t i o n Ru le s      VLDB. Sep 12-15 1994, Chile, pp.487-499 13 C M  K u o k  A  F u   M  H W o n g  M i n i n g F u z z y Asso c i a t i o n  Ru l e s i n Databases ACM SIGMOD Record Volume 27 Number 1 March 1998, pp.41-46  P a ngN i n g T a n   Mi c h a e l  S t e i nb ach   V i p i n K u m a r  I n t r o d u c t i on t o     data mining Addison Wesley Longman, 2006  J i aw e i H a n   M i ch el i n e K a mbe r   D a t a M i n i ng  C o n cep t s a n d T e c h n i q u es   Second Edition. Morgan Kaufmann, 2006 





meani n g u s i ng t h e C ohen d ze Threats t o ity concern f actors t hat can inßuence our obs erv a t i ons  A l t hough bot h a s s o ci at i o n r ul e d i s co v e r y an d G r a n g e r cau sality test can statistically in f e r c o changes b et w een  l es or t e mporal l y cons equent changes  as in th e case o f G r a n g e r th is w o u l d n o t allo w t o c laim an yt hi ng about caus e ef fect rel a t i ons hi ps about changes o ccurri ng on a  l e and o n t hos e h a v i n g a change-coupl i n g re l a t i o n w i t h i t  Threats t o ex t e r n a l v a l i d i t y concern t he general i zat i o n of our  ndi ngs  A l t hough w e performed our anal ys es on four di f ferent s ys t e ms  b el ongi ng t o di f ferent domai ns and de v e l oped w i t h di f ferent p rogrammi ng l a nguages  w e are aw a r e t h a t a f u r t h e r e m p i r i c a l v a l i d a t i o n o n a l a r g e r s e t o f sy st e m s w o u l d b e b e n e  c i a l t o b e t t e r su p p o r t o u r  n d i n g s R TED W K As s t a t e d b y B o h n e r a n d Ar n o l d  1 5  am a j o r g o a l o f impact analys is is to identify the s oftw ar e w or k p r oducts af f ect ed by pr opos ed c hang es  Mos t of t h e e xi s t i n g c hange i m pact anal ys i s t echni ques aim a t e x p l o itin g t h e p r esen ce o f d e p e n d e n c ies i n t h e so u r ce code i dent i  ed by means o f s t a t i c anal ys i s 2  dynami c 3 or s p eci  c t echni ques s uch a s s t a t i c and or dynami c s l i c i n g 16  S o me i m pact anal ys i s t echni ques c ope wi t h p r o b l e m s s p e c i  c o f p a r t i c u l a r k i n d s o f a r t i f a c t s  for e xampl e  U ML model s 17  T here i s a l ar ge corpus of s t udi es rel a t e d t o c hange i m pact anal ys i s  h o w e v er a compl e t e s u rv e y of t h em i s be yond t h e s cope of t h i s paper  As m e n t i o n e d i n t h e i n t r o d u c t i o n  o n e l i m i t a t i o n o f e x i s t in g im p a c t a n a ly s is te c h n iq u e s is th a t th e y w o r k a s s u m in g the p res ence o f d ependencies b etween artif acts  Alternati v e approaches e x i s t t o o v e rcome s uch a l i m i t a t i on S o me of 4 18  are b as ed on info rmation r etrie v al i e the y ex p l o i t t h e t ex t u a l c o n t e n t o f t h e a r t i f a c t s  a s s u m i n g t h a t ac h a n g e t o a s o f t w a r e a r t i f a c t w i l l i m p a c t o t h e r  t e x t u a l l y sim ilar a r tif acts Th e w eak n e ss i s t h a t t h e se a p p r o a c h e s mi g h t f a i l t o  n d p e r t i n e n t l i n k s w h e n t h e s i mi l a r i t y i s lo wÑwh ile ar tif acts a r e  i n d eed r elatedÑor m ight nd fa l s e p o s i t i v e s w h e n u n r e l a t e d a r t i fa c t s a r e t e x t u a l l y s i m i l a r  Ot h e r a p p r o a c h e s t h a t d o n o t r e l y o n c o d e d e p e n d e n c i e s a r e bas e d o n e xpert j udgment a nd code i n s p ect i o n 19  ho w ev e r  s ev e r a l s t u d i e s h av e s h o w n t h a t e x p e r t p r e d i c t i o n s a r e frequently incorrect or at leas t b ias e d b y s ubjecti v enes s  20  and s ource code i n s p ect i o n can be prohi bi t i v e l y e xpens i v e 21  The  rs t s t udi es ai med a t i dent i fyi ng l ogi cal change coupl i ngs w e re performed by G a l l al r s t o n c h a n g e releas es of a t elecommunication s ys tem  22  a nd then on commit h is tories e x tracted from C VS logs 23   T o o v er co m e th e lim itatio n s o f th e p r e v i o u s ch an g e im p act analys is approaches  a nd abo v e all t o c omplement t he recommendat i ons t h at coul d b e p ro vi ded b y t radi t i onal c hange impact analys is approaches  t wo a p p r o a c h e s w e r e d e v e l o p e d in p a r a lle l b y tw o d if f e r e n t r e s e a r c h g r o u p s  n a m e ly Y in g et  5 a nd Zi mmermann et al 1 6  B o t h us e a s s oci a t i o n r u les d isco v e r y  a wellk n o wn d a tam in in g p r acticeÑth at we s u mmari zed i n S ect i o n II-B t o d et ermi ne s e t s of  l es th a t w e r e c h a n g e d to g e th e r f r e q u e n tly in th e p a s t f r o m th e change hi s t ory o f t he code bas e  T he hypot hes i s i s t hat t he change patterns i nferred b y m eans o f a s s o ciation r ules i.e l e s c o c h a n g i n g i n t h e s a m e c h a n g e s e t  c a n b e u s e d t o recommend pot ent i a l l y rel e v a nt s ource code t o a d e v el oper performi n g a change T he y found t h at i n man y cas es t h e precis i on in the p erformed pr ediction i s o ften abo v e 70 and i n s ome cas es higher t han 90 w hile the r ecall o ften lo w e r th a n 2 5   a n d in s o m e c a s e s b e lo w 1 0   In a p re vi ous paper 7 w e i n t roduced t h e i dea o f u s i ng th e m u lti v a r i ate tim e s er ies f o r p r ed ictin g t h e im p act o f ac h a n g e  T h i s p a p e r c o n t i n u e s t h ee a r l y w o r k p r e v i o u s l y pr e s e nt e d a s f ol l o w s   we p r e s e n t a n e m p i r i c a l e v a l u a t i o n  t h r o u g h c h a n g e s fro m fo u r s o ft w a re s y s t e m s  o f G ra n g e r c a u s a l i t y t e s t  its co m p ar iso n with asso ciatio n r u le d isco v e r y  a n d th e ove r l a p o f t h e i r r e s u l t s  T h e p r e v i o u s w o r k o n l y s h o w e d th e a p p licab ility o f th e a p p r o ach o n a s u b s y s tem o f t h e a 7  md  o m p o s e d o f a b o u t 3 0  l e s o n l y   to tr ain t h e m u lti v a r i ate tim e s er ies m o d e l i n a w a y t h a t pro v i d es t h e  s t rengt h of t h e c hange coupl i n g rel at i on we u s e  l e c h a n g e f r e q u e n c i e s  i n s t e a d o f B o o l e a n va r i a b l e s i n d i c a t i n g w h e t h e r o r n o t  l e s c h a n g e d   we d e  n e a h y b r i d a p p r o a c h t h a t c o m b i n e s r a n k i n g o f bot h a s s o ci at i o n r ul es and G ranger  C AND W K IN P S In recent y ears  As s o ciation r ule d is co v e ry 11  has b een su c c e ssf u l l y a p p l i e d t o p r e d i c t c h a n g e c o u p l i n g s a m o n g  l e s by mi ni ng dat a from s oft w are repos i t o ri es 1  5  Thi s paper p erforms a n e mpirical comparis on of as s o ciation r ule di s c o v e ry w i t h a t echni que bas e d o n m ul t i v a ri at e t i m e s eri e s an aly s is a n d sp eciÞcally o n th e G r a n g e r cau sality test  8   Re s u l t s o f a n e m p i r i c a l s t u d y p e r f o r m e d o n c h a n g e d a t a ex t r a c t e d f r o m C V S r e p o s i t o r i e s o f f o u r d i f f e r e n t s o f t w a r e sy st e m s F r e e B S D i 3 8 6  M y l y n  S q u i d  a n d R h i n o  sh o w th at  i o v e r a ll asso ciatio n r u le d isco v e r y e x h ib it a h ig h e r p r ecisio n th an Gran g e r cau sality test w h ile th e r ecall o f Gr an g e r cau sality test is i n m o s t cases h ig h e r f o r Gr an g e r cau sality o r at least c o m p a r a b l e an d  ii th e n u m b e r o f tr u e r eco m m e n d a tio n s p r o v id ed b y Gr an g e r cau sality test is h ig h e r th a n f o r a s s o c ia tio n r u le s  a n d a b o v e a ll th e tw o te c h n iq u e s p r o v id e a s e t o f r e c o m m e n d a tio n s h a v in g a v e r y lo w in te r s e c tio n  The a bo v e res u l t s s ugges t t h e opport uni t y of combi n i n g th e tw o te c h n iq u e s  A h y b r id te c h n iq u e o b ta in e d b y c o m bi ni ng ranki ng s c ores pro v i d ed by as s o ci at i o n rul es and b y Gran g e r cau sality allo w t o o b t ain  i a F measu r e a n d a r ecall 7 http://w w w  s am ba o r g 


hi gher t han t he t w o t echni ques a l one a nd i i  a p reci s i on i n bet w een t h e t w o  In s ummary  t he performed s t udy s ugges t s th e p o te n tia l o f m u lti v a r ia te tim e s e r ie s a n a ly s is to s u g g e s t change coupl i ngs compl e ment ary t o t hos e p ro vi ded b y a s so c i a t i o n r u l e s a n d t h e a d v a n t a g e s o f c o m b i n i n g t h e t w o te c h n iq u e s  Wo r k i n p r o g r e s s a i m s a t  i  u s i n g e n h a n c e d w a y s o f co m b in in g t h e tw o t ech n i q u e s  ii f u r t h e r v alid atin g t h e combi n ed t echni ques t hrough more cas e s t udi es as w e l l as by in v e stig atin g h o w ch an g e s t en d t o b e p r o p a g a ted i n p r o jects ha ving a d if ferent or ganizati on and  iii better unders tanding th e n atu r e o f c h a n g e co u p lin g i n f er r e d b y G r a n g e r cau sality te s t a s o p p o s e d to th o s e in f e r r e d b y m in in g a s s o c ia tio n r u le s  R EF ER EN C ES 1 T  Z i m m e rm a n n  P  W e i s g e rb e r  S  D i e h l  a n d A  Z e l l e r  Mi n i n g v er si on hi st or i e s t o gui de sof t w a r e changes  i n E 0 4  P r o c e e d i n g s o f t h e 2 6 t h In t e r n a t i o n a l C o n f e r e n c e o n Sof t w ar e E ngi neeri n g 2 0 0 4  p p  5 6 3  5 7 2  2 R  S  A rn o l d a n d S  A  B o h n e r   Im p a c t a n a l y s i s t o w a rd s a frame w o rk fo r c o m p a riso n   i n Pr o c e e d i n g s o f t h e C o n f e r e n c e on Sof t w ar e M ai nt enance  I C SM 1993 Mont r  eal  Quebec Ca n a d a  S e p t e m b e r 1 9 9 3 1 9 9 3  p p  2 9 2  3 0 1  3 J  L a w a n d G  R o t h e rm e l   W h o l e p ro g ra m p a t h b a s e d d y nami c i mpact anal ysi s   i n Pr o c e e d i n g s o f t h e 2 5 t h I n t e r n a tio n a l C o n fe r e n c e o n S o ftw a r e E n g in e e r in g  M a y 3 1 0  2 0 0 3  Po r t l a n d  O r e g o n  U S A I E E E C o m p u t e r S o c i e t y  2 0 0 3  p p  308Ð318  G  C anfora and L  C erul o Impact anal ysi s by mi ni ng sof t w a r e and c hange r e quest r e posi t o r i es  i n 11t h I E E E In t e r n a t i o n a l S y m p o s i u m o n S o f t w a r e M e t r i c s M E T R IC S 2005  1922 Sept em ber 2005 C om o I t al y I E E E C o m p u t e r So c i e t y  2 0 0 5  p  2 9  5 A  T  T  Y i n g  G  C  M u rp h y  R  N g  a n d M  C  C h u C a rro l l  P r ed i ct i n g s o u r ce co d e ch an g es b y m i n i n g r e v i s i o n h i s t o r y   IE E E T r a n s a c t i o n s o n S o f t w a r e E n g i n e e r i n g v o l  3 0  p p  5 7 4  586 S e p 2004 6 T  Z i m m e rm a n n  P  W e i  g e rb e r  S  D i e h l  a n d A  Z e l l e r  Mi n i n g v er si on hi st or i e s t o gui de sof t w a r e changes  IEEE Tr a n s  S o f t w a r e E n g  v o l 3 1 n o  6 p p  4 2 9  4 4 5  2 0 0 5  7 M  C eccarelli L Ceru lo  G C an fo ra a n d M  Di P e n t a  An ecl ect i c approach for c hange i m pact anal ysi s   i n Pr o c e e d i n g s of t h e A C M  I E E E 32r d I nt ernat i onal C onf er ence on Sof t w ar e En g i n e e r i n g  I C S E 1 0 1 0  N e w I d e a s a n d Em e r g i n g Re s u l t s N IE R  T r a c k  2 8 M a y 2 0 1 0  C a p e T o w n  S o u t h A f r i c a t o appear A C M P r e s s  2 0 1 0  ht t p    w w w  r cost  uni sanni o i t  md i p e n t a  p a p e r s  n i e r 2 0 1 0  p d f  8 C  W  J  G ra n g e r   In v e s t i g a t i n g c a u s a l re l a t i o n s b y e c o n o met r i c model s and cr o ssspect r al m et hods  a  vo l  3 7  n o  3  p p  4 2 4  4 3 8  1 9 6 9   N  D  M ukhopadhyay a nd S  Chatterjee Causality and pat h w a y s earch i n mi croarray t i me s eri e s e xperi ment   s v o l 2 3 n o  4 p p  4 4 2  4 4 9  2 0 0 7  1 0  A  H i n d l e  M  W  G o d fre y  a n d R  C  H o l t   M i n i n g re c u rre n t act i v i t i es  F o u r i er an al y s i s o f ch an g e e v en t s   i n ernatio n a l C o n fe r e n c e o n S o ftw a r e E n g in e e r in g  I C S E 2 0 0 9  M a y 1624 2009 V ancouver  C anada C om pani on V ol um e  pp 295Ð298 1 R Ag ra w a l T  Imie lin sk i a n d A  N  S w a mi  M i n i n g a s soci at i o n r ul es bet w een set s of i t ems i n l ar g e d at abases  in Pr o c e e d i n g s o f t h e 1 9 9 3 A C M S I G M O D I n t e r n a t i o n a l Co n f e r e n c e o n M a n a g e m e n t o f D a t a  W a s h i n g t o n  D  C  M a y 1993 A C M P r e s s  1 9 9 3  p p  2 0 7  2 1 6  2 J  D  H a m i l t o n  Ti m e S e r i e s A n a l y s i s P r i n c e t o n U n i v e r s i t y Pr e s s  J a n u a r y 1 9 9 4  3 J H Le e   Co m b i n i n g mu ltip le e v id e n c e fro m d if fe re n t propert i es o f w ei ght i n g s chemes  i n Pr o c e e d i n g s o f t h e 1 8 t h annual i n t e rnat i onal A C M S I G I R conf er ence on R e sear c h and de vel opm ent i n i nf orm a t i o n r et ri e v al N e w Y o r k  N Y  U S A  AC M  1 9 9 5  p p  1 8 0  1 8 8  4 D  S h e s k i n  Ha n d b o o k o f P a r a me t r i c a n d N o n p a r a me t r i c St at i s t i c al P r ocedur es  f ourt h edi t i on C h a p m a n  A l l  2007 5 R  A rn o l d a n d S  B o h n e r  Sof t w ar e C hang e I m pact A nal ysi s  Wi l e y I E E E C o m p u t e r S o c i e t y  1 9 9 6   M Kamkar   An o v ervi e w and comparat i v e cl assi  cat i o n o f pr ogr am sl i c i n g t echni ques  J S y s t  S o f t w  v o l 3 1 n o  3  1995 7 L  C  B ri a n d  Y  L a b i c h e  L  O S u l l i v a n  a n d M  M  S  ow ka A u t o m a t e d i m p a c t a n a l y s i s o f U M L m o d e l s   f Syst em s and Sof t w ar e v o l  7 9  n o 3  p p  3 3 9  3 5 2  2 0 0 6  1 8  A  C h e n  E  C h o u  J  W o n g  A  Y  Y a o  Q  Z h a n g  S  Z h a n g  and A  M i c hai l  C V S S ear ch S ear chi n g t hr ough sour ce code usi n g C V S comment s  i n ICSM 01 P r oceedi ngs of 17t h IE E E In t e r n a t i o n a l C o n f e r e n c e o n S o f t w a r e M a i n t e n a n c e  364  M L i ndv al l a nd K S a ndahl   P r act i cal i m pl i cat i ons of t r ace Sof t w ar eÑP r act i c e and E x peri ence v o l  2 6 n o 1 0  pp 1161Ð1180 O c t  1996 0     H o w w e l l d o e x p e ri e n c e d s o ft w a re d e v e l o p e rs p re d i c t soft w a re change J S y s t  S o f t w  v o l 4 3  n o 1  p p  1 9  2 7  1998 1 S L Pße e g e r  Sof t w ar e E ngi neeri ng T h eory and P r act i c e  Up p e r S a d d l e R i v e r  NJ  P r e n t i c e Ha l l  1 9 9 8   H Gal l  K Haj ek and M  J azayeri  Det ect i o n o f l ogi cal coupl i n g b ased on pr oduct r el ease h i s t o r y   i n Pr o c e e d i n g s o f th e I n te r n a tio n a l C o n fe r e n c e o n S o ftw a r e M a in te n a n c e  I C S M 98 1 9 9 8 p p  1 9 0  1 9 7   H Gal l  M Jazayeri  and J  K raj e wski   CVS r el ease h i s t o ry dat a f o r d et ect i n g l ogi cal coupl i ngs  i n 6t h I nt ernat i onal Wo r k s h o p o n P r i n c i p l e s o f S o f t w a r e E v o l u t i o n  I W P S E 2 0 0 3   12 S ept e m b er 2003 H e l s i n ki  F i n l and I E E E C o m p u t e r So c i e t y  2 0 0 3  p p  1 3  2 3  


                        






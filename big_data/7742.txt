Research on the Improvement of Apriori Al gorithm and Its Application in Intrusion Detection System  Jigang Zheng Department of Mathmatic Baoshan College Baoshan, Yunnan, 678000, China e-mail: 6913641@qq.com Lin Yang Department of Computer Science and Technology Baoshan College, Baoshan Yunnan, 678000, China 13523768@qq.com    Abstract  The traditional association rule mining Apriori algorithm in time overhead, in view of the shortcomings of the Apriori algorithm, based on the theory of relational algebra using relationship matrix and related operations are the search for frequent item sets of association rules based on relational algebra theory of mining algorithm, by simulation experiment to compare the execution time of the two algorithms, data sample size and minimum support degree on the performance of the algorithm effect is discussed. Through a lot of simulation experiments prove that the improved Apriori algorithm is efficient, and the operation time of mining data set is reduced Keywords-data mining;efficiency;improvement;relational matrix;association rule I   I NTRODUCTION  Apriori algorithm is a classical algorithm of association rule discovery in data mining,1993 by Agrawal, imielinski and Swami presents the concepts of association rule mining,1994 Agrawal and Srikant proposed Apriori algorithm[1 u s e d  to f i n d in t e r e stin g ass o ci ati on  ru les o r  relationships among the data items in a given data set. Table 1 is an example of a supermarket shopping basket  Ea ch row in the table corresponds to a transaction that contains a unique identifier TID and a collection of goods purchased by the customer  TABLE I  S HOPPING B ASKET  TID  Commodity collection 1 {Bread,Milk 2 {Bread,Diaper,Beer,Egg 3 {Milk,Diaper,Beer,Cola,Salt 4 {Bread,Diaper,Beer 5 {Bread,Milk,Diaper,Salt      The following rules are obtained by using Apriori algorithm  Diaper Beer  support=2%,confidenc   The rule's support support=2% shows that 2% of customers are buying diapers an d beer,and the credibility of confidence=40% means that 40% of customers who buy diapers are also buying beer.To help decision makers to design, discover new cross marketing opportunities or to develop other related business decisions through the discovery of association rules Intrusion detection system \(IDS\by scanning of the operating system audit data or network data packet information detection not authorized or illegally entering the user behavior of the system, the system by means of system audit records, analysis and detection of network traffic to identify system in the presence of the illegal invasion, and timely manner to determine, record and alarm, the system managers to take timely and effective measures to make up for the loopholes in the system[3    II  B ASIC C ONCEPTS  A  Association Rule Association rule is "if...... So......" Form, to get the useful rules, it also needs to be two and rules related to the important information support, rules of probability is how much credibility rules right what is the probability. Support is a measure of the importance of the association rules which shows that the association rules in all transactions are much more representative, the more support, the more important the association rules. Credibility is a measure of the accuracy of the association rules, although some of the rules of the association rules are very high, but the degree of support is very low, indicating that the association rule is very small, so it is not important 105 ____________________________ ________ 978-1-4 7 8126 0 1  31 00 ©201 IEEE 


Definition1 Set      2 1 m I I I I is a collection of data items D transaction is a collection of all,A transaction T has a unique identifier TID If items,transaction support items claimed T set A also known as T transaction that contains the item set A  Definition2 Association rules are shaped like B A type of implication among them I A  I B and B A  Definition3 B A supports the association rule is defined as   100   sup   sup N B A port B A port  credibility is defined as   100   sup   sup   A port B A port B A confidence  Usually user according to mining need to specify minimum support degree \(min_sup\ and minimum confidence \(min_con\, minimum support degree describes the association rules of the lowest degree of importance and minimum confidence provides rules must meet the lowest possible. In fact, we are only interested in the association rules that satisfy the minimum support and minimum confidence level, This is called the strong association rules Definition4 If a k item set, its support degree >=min_sup, then calls the k item set for the frequent k itemsets, the collection of all frequent k itemsets k L  B Apriori Algorithm Apriori algorithm is based on the fact that the algorithm uses a priori knowledge of the frequent item sets, using an iterative method called "layer by layer" search, and the k set is used to explore the  1  k set. First, we find out the collection of 1 frequent itemsets, which is denoted as 1 L  1 L is used to find a collection of 2 sets of 2 L while 2 L is used to find 3 L so it cannot be found in the k set the specific description is as follows   In: Database D and sup min_  Out: Database D itemsets L  Algorithm 1 L Looking frequent two sets D  For k 2 1 k L  k   k C apriori_gen 1 k L  For each transaction D t     t C subset C k t  For each candidate c t C  count c    k L   k C c count c   Return L All k L  Algorithm for generating candidate k itemsets is apriori_gen 1 k L frequent\(k-1\-itemsets For each itemsets 1 1 k L l For each itemsets 1 2 k L l If  1   1    2   2    1   1   2 1 2 1 2 1 k l k l k l k l l l Then  1 l c 2 l  If has_infrequent_subset    1 k L c Then delete Else add c to k C   Return k C  C Bottleneck of Apriori Algorithm In search of 1 sets,2 sets k sets, each mining a layer of k L to scan the transaction database D again[5 k 106 


second scan, get k sets, due to D in a short period of time with little change or no change, do is repeat scanning. When the transaction database D is large, the overhead of Apriori algorithm is relatively large, which is to reduce the I/O overhead. The Apriori algorithm is improved in this paper III I MPROVEMENT OF A PRIORI A LGORITHM A Ideas In view of the deficiency of Apriori algorithm, based on relational algebra theory, the relationship matrix and correlation operation are obtained by Optimization Relation Association Rule\(ORAR\ [6 th is a l g o rith m on ly n e eds t o  scan the database once, and overcomes the shortcoming of the Apriori algorithm which needs to scan the database for many times Definition5     2 1 m t t t T is transaction data collection     2 1 n i i i I is a collection of data items the relational matrix R is defined as   item  in   the  appears not dit   Item  0   item  in   the  appears   Item  1   k j k j kj t i t i r R Among them m k   2  1  n j   2  1  R is the T to I matrix That is mn m m n n r r r r r r r r r R 2 1 2 22 21 1 12 11  The value of ij r is 0 or 1, indicates that the i transaction data contains or does not contain j data item Data item table 1 of the shopping basket transaction is converted to the corresponding relationship matrix R 1 0 0 0 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 1 1  Definition6 According to relational matrix R the support for the j data item as the 1 set is  m r m i ij 1 100 B ORAR Algorithm In:Database D and sup min_  Out:Database D itemsets L  Algorithm 1 a find_frequent_1-itemsets R  For i 2 i  n  i  For Each frequent itemsets n i i i i c c c c 1 12 11 1    For h 1 h  n  h  For j 1 h  m  j  Calculation 1 ii jc r and jh r  If h c ji  1 support degree>=min_sup Then h c c c ii i i     1 2 1 is a i set For each i item set ji j j j c c c c    2 1 For k 1 k  m  k  If i item set j c support degree>=min_sup Then out i item set j c  IV A PPLICATION OF I MPROVED A LGORITHM IN I NTRUSION D ETECTION S YSTEM In order to improve the efficiency of the Apriori algorithm and the classical Apriori algorithm, the experiment is done under the same suppor t with different data and the same amount of data Experimental environment Intel Core I3 CPU 3.1GHz memory 3G, hard disk 320G; Microsoft Windows 7 system algorithm with Java7.0 SQL Server 2008 implementation Experimental data sets from KDDCUP.data_10_percent data sets of KDDCUP99 subsets [7 4 9402 1 r e c o rd s  th e subset data is Wenkole etc. after further processing of these raw data obtained, they use bro preprocessing of the raw data packets, thus the network data processing into connection records, with 41 attribute valu es and a attack class type 107 


identifies the feature set, we selected the 18 main attribute 8   The minimum support degree was 15%, the minimum feasible degree is 50%, respectively in 5000, 10000, 50000 100000, 200000 and 400000 data set experiment, by Figure1 you can see, when test data is small \(5000\ improved algorithm ORAR advantages nature of the obvious, when the sample number is gradually increasing, the superiority of the algorithm ORAR began to manifest With a sample data set \(100000\ respectively with minimum support degree s=10%, s=20%, s=25% and s=30 experiment, from Figure2 can be seen, with the minimum support increases, the execution time of the Apriori algorithm and the ORAR algorithm gradually declines V C ONCLUDING R EMARKS This article in the analysis of mining association rules of the classical algorithm Apriori and improved algorithm ORAR. Through simulation experiments to compare the two algorithm execution time, discusses the data sample size and minimum support degree of two algorithms performance effect. The experimental results show that application of improved algorithm ORAR can effectively improve mining frequent item set efficiency, improve the performance of intrusion detection system R EFERENCES 1 R  A g r a w al and  R S r ik a n t    Fast algorithm for mining association rules  in Proceeding 1994 International conference Very Large Data Base\(VLDB94 Santiago, Chile, Sept, 1994, pp. 487-499 2 P  N Ta n an d  M  S t ei nb ach   Introduction to data mining  Beijing People's Posts and Telecommunications Press, 2006, pp. 201-204 3 C h  Z h e n   Research on the intrusion detection systems based on the improved apriori algorithm  Journal of Hainan Normal University\(Natural Science Edition\, vol. 1, no. 25, pp. 41-45 2012 4 J  W  Han and  M  K a m b er   Data mining concepts and techniques  Beijing: Machinery Industry Press, 2007, pp. 151-154 5 X  B L i  Y Q  Z h u  an d X Z h   L u o   Research and improvement for apriori algorithm of association rule mining  Computer Knowledge and Technology, vol. 5, no. 19, pp. 5084-5085 2009 6 C h L i a n d J  C h   Association rule mining algorithm based on relation Algebra theory  Journal of Northwest University \(Natural Science Edition\, vol. 35, no. 6, pp. 692-694 2005 7 U n i vers i t y of C a li forn i a  K DD C u p  1 999 Da ta   E B OL    http://kdd.ics.uci.edu/databases/KDDCUP99/KDDCUP99.html,199910-28 8 A  N Dez h i    The application of improved Apriori in IDS  Journal of Hebei Politechnic University\(Natural Science Edition\, vol. 1, no 33, pp. 95-99+71 2011 Figure 1 Comparison of performance of different data volume algorithms Figure 2 Comparison of the efficiency of different support algorithms 108 


database to identify coverage holes for next coverage closure step  C  Automatically Generated Test Specification for ITBA The coverage goal for the given example is described using System Verilog Functional Coverage Syntax h o w n in Figure 8a. It is a cross coverage between 3 variables namely \(out, pos, a\with iff \(! rst\ditional guard for the cross coverage calculation. Cross coverage of a set of N coverage points is defined as the coverage of all combinations of all bins associated with the N coverage points, that is, the Cartesian product of the N sets of coverage point bins or exa m ple t h e cov e r g rou p i n  Figure 8a identifies a cross coverage between two 1bit variables \(a, out\e 3bits variables \(pos\ystem Verilog implicitly creates a coverage point for each variable. \(a, out\ill both have a cover point with 2 bins namely au  w h ile pos ill h a ve a co v e r poin t  with 8 bins, au t o [7  T h e cros s of ou t pos an d a  labeled out_XX_pos_XX_a\, therefore, has 32 cross products, and each cross product is a bin of out_XX_pos_XX_a    Figure 8: a. Cross-Coverage Declaration, b. Illegal Cross Points Combinations  The real difficulty in defining cross coverage goals is to get the exclusions correct, and this can be really difficult when the variables in the cross coverage have some constraints that determine the relationships that must be maintained between them. If these exclusions are not properly identified then the ability to accurately judge the actual coverage achieved becomes impossible since the missing coverage may contain a significant percentage of illegal cases. To illustrate the difficulty lets consider our simple three variable example: Our coverage goal is to test all of the legal combinations of all three variables \(out, pos and a\he definition of the legal cross coverage goals is not trivial even for this case, since we have to determine which combinations of \(out, pos, a\ are unreachable. Analyzing RTL implementation of the design Figure3, the illegal combinations turn out to be the ones listed in Figure 8b This leaves 5 valid combinations out of a total of 32, which would mean that if the exclusions are not specified then the maximum coverage attainable is 15  The proposed frame work passes the automatically extracted design constraints from the mining of the simulation data to the ITBA tool, Questa inFact, which respects those constraints and can provide an accurate count of the legal solutions in a cross. So if the following automatically generated constraint as explained in the data mining step ,constraint assum_all {if\(!rst && \(pos 3'b001 || pos == 3'b010 || pos == 3'b011 \& a == 1'b1 out == 1'b0;}}, is given to the ITBA, it will guide the tool to identify correct unreachable bins as indicated in Figure 9a and will result in the suppression of the test paths that violates the above constraint, i.e tests for cross coverage combination in which out==1b0 where pos 3b000..3b111 and a= 1b0 or tests in which out 1b0 where pos==3b000..3b111 and a==1b1 as indicated in Figure 9b. So respecting such constrain resulted in the suppression of 15 test scenarios that are unreachable for the DUV and focus to cover more meaningful coverage targets As more constraints are added the more the ITBA will be guided for better tests generation     Figure 9:  a. Constraints-aware Cross-Coverage Declaration b. Ignorable Cross-Coverage Combinations by ITBA Step  Finally Formal reach-ability analysis is used to identify unreachable coverpoints after ITBA step. The formal verifier reads the coverage results from ITBA simulation coverage database, then it leverages the formal engines under the hood to flag the coverage items that are unreachable so it can be  safely ignored and list them in coverage exclusion file that can be used to refine final coverage calculations  As a conclusion the initial simulation coverage of the running example from which the design constraints have been extracted was 65.6% which was boosted to 87.5% after the algorithmic test stimulus generation phase and finally applying formal exclusions resulted in final coverage of 98.5  2015 10th International Design & Test Symposium \(IDT 64 


Table  1: Progress of Coverage Ratios Increase During the Proposed Framework IV  E XPERIMENTAL R ESULTS  In this experiment, the proposed verification framework has been exercised against a group of industrial designs downloaded from Opencores [22 b tain ed f r o m a set of  in-house regression test suites Table 1 lists some information about the designs under study such as the number of design modules, design size in LOC \(line of code\d the number of design covergroups and coverbins Table 1 illustrates the number of design constraints that have been extracted during the mining step and have been verified/proven by formal verification. It demonstrates the coverage results progress from the initial random simulation runs to the tests coverage after constraintsguided test stimulus generation step and finally the impact of applying formal exclusions \(formally proven unreachable cover items\e ITBA simulation runs and how each step contributes in the coverage closure of designs under verification V  C ONCLUSION  Due to the increasing complexity of modern circuit designs, a complementary set of functional verification techniques should work together to assure complete and fast verification cycle. This paper introduces a complete framework to accelerate coverage closure for the DUV which makes use of the initial simulation data analysis to identify frequent patterns as design input constraints and to extract coverage holes. The coverage holes as well as formally proven un-reachable coverage goals are used to automatically identify test specification to guide ITBA for better test scenarios and effective coverage closure. Our experimental results show the feasibility of proposed framework to achieve good increments in coverage closure cycle using many industrial designs  VI  R EFERENCES  1  S. Fine, A. Freund, I. Jaeger, Y. Mansour, Y. Naveh, A. Ziv Harnessing Machine Learning to Improve the Success Rate of Stimuli Generation, IEEE Transactions on Computer, Vol 55, pp1344-1355, November 2006 2  C. Ioanides , K. I. Eder Coverage-Directed Test Generation Automated by Machine Learning-A Review, ACM Transactions on Design Automation of Electronic Systems , Vol 17, Jan. 2012 3  S. U R S., Y.Y ADIN Micro architecture coverage directed generation of test programs, In Proc. of the Design Automation Conference \(DAC\ pp. 175180,1999 4  D. Geist, M. Farkas, A. Landver, Y. Lichtenstein, S. Ur, Y Wolfsthal. Coverage-Directed Test Generation Using Symbolic Techniques , Formal Methods in Computer-Aided Design, pp. 143158, 1996 5  Nina Saxena, Jacob A. Abraham, Avijit Saha. Causality based generation of directed test cases, In Proc. Asia and South Pacific Design Automation Conference, pp. 503-508, 2000 6  P. Mishra, N. D. Dutt, Functional Coverage Driven Test Generation for Validation of Pipelined Processors , In Proc. Design Automation and Testing in Europe, pp. 678-683, 2005 7  S. Fine, A. Ziv., Coverage directed test generation for functional verification using bayesian networks, In Proc. Design Automation Conference, pp. 286-291, 2003 8  I. Wagner, V. Bertacco, T. Austin, Microprocessor verifcation via feedback-adjusted markov models, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, Vol. 26 pp. 1126-1138, June 2007 9  G. Squillero,MicroGP An evolutionary assembly program generator, Genetic Programming and Evolvable Machines, Vol 6 pp. 247-263, Sept. 2005   H.-W. Hsueh, K. Eder, Test Directive Generation for Functional Coverage Closure Using Inductive Logic Programming, In Proc High- Level Design Validation and Test Workshop, pp. 11-18,2006   J.H Perkins, and M.D Ernst,Efficient Algorithms for Dynamic Detection of Likely Invariants, Proc. ACM SIGSOFT Symposium on the Foundations of Software Engineering,  pp. 2332, 2004   S. Hangal, N. Chandra, S. Narayanan, and S. Chakravorty, Iodine: a tool to automatically infer dynamic invariants for hardware designs in the Proc. of Design Automation Conference\(DAC\, pp. 775778 2005   S. Vasudevan, D. Sheridan, S. Patel, D. Tcheng, B. Tuohy, D Johnson, GoldMine: Automatic assertion generation using data mining and static analysis, In Design, Automation & Test in Europe Conference & Exhibition \(DATE\, pp. 626-629, 2010   P.H Chang, Li.C Wang,Automatic assertion extraction via sequential data mining of simulation traces., Proceedings of the 15th Asia South Pacific Design Automation Conference\( ASPDAC\, pp. 607-612,2010   E. El-Mandouh, A. G. Wassal, Automatic Generation of Hardware Design Properties from Simulation Traces.,  Proceedings of  IEEE International Symposium on Circuits and Systems \(ISCAS\ pp 2317-2320,2010   Test Specification Language  the past, present and the future http://www.cvcblr.com/blog/?p=857 , 2014   Mentor Graphics Proposes New Accellera Standards Committee for Graph-Based Test Specification Standard https://www.mentor.com/company/news/mentor-accellera-standardsgraph-based-test-specs , 2014   J. Ayres, J. Flannick, J. Gehrke, T. Yiu, Sequential Pattern mining using a bitmap representation, In Proc. Knowledge Discovery and Data Mining \(KDD , pp. 429-435, 2002   C. Borgelt,Efficient Implemantation of Apriori and Eclat.,In FIMI Proceedings of the IEEE ICDM Workshop on Frequent Item Set Mining,2003   Accellera Organization, Inc. Unified Coverage Interoperability Standard \(UCIS\. Accellera Organization, Inc http://www.accellera.org/downloads/standards/ucis, June 2012   IEEE 1800-2012, System Verilog Unified Hardware Design Specification and Verification Language http://standards.ieee.org/getieee/1800/download/1800-2012.pdf   Opencores benchmarks http://opencores.org 2015 10th International Design & Test Symposium \(IDT 65 


VI Tanbeer, S. K., Ahmed, C. F., Jeong, B.-S., & Lee, Y.-K, \215Sliding window-based frequent pattern mining over data streams,\216 Information Sciences, 179\(22\, pp. 3843\2053865, 2009 9 Chang, J., & Lee, W. S, \215Finding recently frequent itemsets adaptively over online transactional data streams,\216 Information Systems, 31\(8\, pp. 849\205869, 2006 4 Agrawal, R., & Srikant, R, \215Fast algorithms for mining association rules,\216 In Proc. VLDB int. conf. very large databases \(pp. 487\205 499\, 1994 3 Tsai, P. S. M, \215Mining frequent itemsets in data streams using the weighted sliding window model,\216 Expert Systems with Applications, 36\(9\, pp. 11617\20511625, 2009  minimum change threshold Y. Chi, H. Wang, P. S. Yu and R. R. Muntz. Catch the moment maintaining closed frequent itemsets over a data stream sliding window. In KAIS, 10\(3\: pp. 265-294, 2006 6 V. kumar, S. satapathy, \215A review on algorithms for mining frequent itemsets over data stream,\216 in ijarcsse V3 I4, 2013 8 CONCLUSION AND FUTURE WORK  Considering the continuousness of a data stream, the traditional methods or techniques for finding frequent itemsets in conventional data mining methodology may not be valid in a data stream. This is because we cannot consider whole data and must identify when a data becomes obsolete or invalid As the old information of a data stream may be no longer useful or possibly invalid at present.  In order to support various requirements of mining data stream, the mining window or the interesting recent range of a data stream needs not to be defined static but must be flexible. Based on this range, a data mining method can be able to identify when a transactions becomes stale or needs to be disregarded  In this paper, we have investigated the problem of mining frequent itemset over data stream using flexible size sliding window model and proposed a new algorithm for this problem. The size of sliding window is adaptively adjusted based on the amount of observed concept change in the underlying properties of incoming data stream. The size of window enlarges or increase when there is no significant amount of change observed. While the window size reduced or decrease when there is considerable amount of concept change or significant change in set of frequent itemsets occurs Based on the value of given by user, the size of window is being controlled. After every pane insertion the set of frequent itemsets are updated and value of concept change is calculated. If the value exceeds the given minimum change threshold the window gets smaller by deleting all the obsolete information before a point defined called checkmark  Experimental results shows that our algorithm tracks the concept change efficiently while mining data stream and is more adaptive to recent frequent itemsets than fixed size sliding window models or time fading window models. For the future work, we are trying to enhance the performance by using fuzzy sets for minimum change threshold value so that the values like low, medium, high and very high instead of certain value between ranges of 0 to 1 R EFERENCES  1                    H. Li, S. Lee, and M. Shan, \215An Efficient Algorithm for Mining Frequent Itemsets over the Entire History of Data Streams\216, In Proc. of First International Workshop on Knowledge Discovery in Data Streams, 2004  F. Nori, M. Deypir, M. Sadreddini, \215A sliding window based algorithm for frequent closed itemset mining over data streams\216 journal of system and software, 2012  Zaki, M. \(2000\. Scalable algorithms for association mining. IEEE Transactions on Knowledge and Data Engineering, 12\(3\, 372\205 390  Woo H. J., & Lee, W. S. \(2009\. estMax: Tracing maximal frequent item sets instantly over online transactional data streams IEEE Transactions on Knowledge and Data Engineering, 21\(10 1418\2051431  Mozafari B, Thakkar H, Zaniolo C, \215Verifying and mining patterns from large windows over data streams,\216 In Proc. Int. conf. ICDE pp. 179-188, 2008  Koh, J.- L., & Lin, C.- Y, \215Concept shift detection for frequent itemsets from sliding window over data streams\216, lecture notes in computer science: Database systems for advanced applications \(pp 334\205348\ DASFAA Int. Workshops, Springer-Verlag.2009  Han, J., Cheng, H., Xin, D., & Yan, X. Frequent pattern mining Current status and future directions. Data Mining and Knowledge Discovery, 15\(1\, pp.  55\20586, 2007 5 C. Giannella, J. Han, J. Pei, X. Yan, and P. S. Yu. Mining frequent patterns in data streams at multiple time granularities. In Kargupta et al.: Data Mining: Next Generation Challenges and Future Directions, MIT/AAAI Press, 2004 7 2014 IEEE International Advance Computing Conference IACC 510 J. H. Chang and W. S. Lee. estWin: Adaptively Monitoring the Recent Change of Frequent Itemsets over Online Data Streams. In Proc. of CIKM, 2003  J. Yu, Z. Chong, H. Lu, and A. Zhou. False Positive or False Negative: Mining Frequent Itemsets from High Speed Transactional Data Streams. In Proc. of VLDB, 2004      Aggarwal, C, \215A framework for diagnosing changes in evolving data streams,\216 In Proc. ACM SIGMOD int. conf. on management of data \(pp. 575\205586\ 2003 2 Manku, G. S., & Motwani, R. Approximate frequency counts over data streams. In Proc. VLDB int. conf. very large databases \(pp 346\205357\ 2002  


002 
                          
R. Agrawal and R. Srikant. Fast algorithms for mining association rules in large databases. In Proc. VLDB, pages 487499, 1994 2 R. J. Bayardo, Jr. Efficiently mining long patterns from databases SIGMOD Rec., pages 8593, 1998 3 M. Zaki, S. Parthasarathy, M. Ogihara, and W. Li. Parallel algorithms for discovery of association rules. Data Min. and Knowl. Disc., pages 343373, 1997 4 J. Dean and S. Ghemawat. MapReduce: Simplified data processing on large clusters. In Proc. OSDI. USENIX Association, 2004 5 Apache hadoop. http://hadoop.apache.org/, 2013 6 Jiawei Han and Micheline Kamber. Data Mining, Concepts and Techniques. Morgan Kaufmann, 2001 7 M. Zaharia, M. Chowdhury, T. Das, A. Dave, J. Ma, M. McCauley M. Franklin, S. Shenker, and I. Stoica. Resilient distributed datasets A fault-tolerant abstraction for in-memory cluster computing Technical Report UCB/EECS-2011-82, EECS Department University of California, Berkeley, Jul 2011 8 M. Zaharia, M. Chowdhury, M. J. Franklin, S. Shenker, and I. Stoica Spark: Cluster Computing with Working Sets. In HotCloud, 2010 9 J. Han, J. Pei, and Y. Yin: Mining Frequent Patterns without Candidate Generation. In: Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data, 29\(2\:1-12, 2000 10 M. J. Zaki. Parallel and distributed association mining: A survey IEEE Concurrency, pages 1425, 1999 11 J. Li, Y. Liu, W.-k. Liao, and A. Choudhary. Parallel data mining algorithms for association rules and clustering. In Intl. Conf. on Management of Data, 2008 12 E. Ozkural, B. Ucar, and C. Aykanat. Parallel frequent item set mining with selective item replication. IEEE Trans. Parallel Distrib Syst., pages 16321640, 2011 13 B.-H. Park and H. Kargupta. Distributed data mining: Algorithms systems, and applications. 2002 14 L. Zeng, L. Li, L. Duan, K. Lu, Z. Shi, M. Wang, W. Wu, and P. Luo Distributed data mining: a survey. Information Technology and Management, pages 403409, 2012 15 Li L. & Zhang M. \(2011\. The Strategy of Mining Association Rule Based on Cloud Computing. Proceeding of the 2011 International Conference on Business Computing and Global Informatization BCGIN 11\. Washington, DC, USA, IEEE: 475- 478 16 Li N., Zeng L., He Q. & Shi Z. \(2012\. Parallel Implementation of Apriori Algorithm Based on MapReduce. Proc. of the 13th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel & Distributed Computing SNPD 12\. Kyoto, IEEE: 236  241 17 Lin M., Lee P. & Hsueh S. \(2012\. Apriori-based Frequent Itemset Mining Algorithms on MapReduce. Proc. of the 16th International Conference on Ubiquitous Information Management and Communication \(ICUIMC 12\. New York, NY, USA, ACM: Article No. 76 18 Yang X.Y., Liu Z. & Fu Y. \(2010\. MapReduce as a Programming Model for Association Rules Algorithm on Hadoop. Proc. of the 3rd International Conference on Information Sciences and Interaction Sciences \(ICIS 10\. Chengdu, China, IEEE: 99  102 19 S. Hammoud. MapReduce Network Enabled Algorithms for Classification Based on Association Rules. Thesis, 2011 20 Synthetic Data Generation Code for Associations and Sequential Patterns. Intelligent Information Systems, IBM Almaden Research Center http://www.almaden.ibm.com/software/quest/Resources/index.shtml 21 C.L. Blake and C.J. Merz. UCI Repository of Machine Learning Databases. Dept. of Information and Computer Science, University of California at Irvine, CA, USA. 1998 http://www.ics.uci.edu/mlearn/MLRepository.html 22 HadoopApriori. https://github.com/solitaryreaper/HadoopApriori 2 3 H.V. Nguyen, E. Muller, K. Bohm. 4S: Scalable Subspace Search Schema Overcoming Traditional Apriori Processing. 2013 IEEE International Conference on Big Data. 2013 24 S. Moens, E. Aksehirli and Goethals. Frequent Itemset Mining for Big Data. University Antwerpen, Belgium. 2013 IEEE International Conference on Big Data. 2013 25 Y. Bu et al . HaLoop: E cient iterative data processing on large clusters. Proceedings of the VLDB Endowment, 3\(1-2\:285296 2010 26 Frequent itemset mining dataset repository. http://fimi.us.ac.be/data 2004   
002 
Our experiments show that YAFIM is about 18 faster than Apriori algorithms implemented in MapReduce framework Furthermore, we can achieve a better performance in both sizeup and speedup for different datasets. In addition, we also evaluated YAFIM for medical application and revealed that YAFIM outperforms MRApriori about 25 speedup  A CKNOWLEDGMENT  This work is funded in part by China NSF Grants \(No 61223003\, and the USA Intel Labs University Research Program R EFERENCES  1 
002 
1671 



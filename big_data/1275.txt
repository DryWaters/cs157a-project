html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">Proceedings  of the 5Ih World Congress an Intelligent Control and Automation, June 15-19, 2004, Hangzhou, P.R. China An Intelligent Algorithm of Data Pre-processing in Web Usage Mining Zhang Huiying, Liang Wei School of Management University of Tianjin zhanghuiying@nankai,edu.cn Tianjin, 300072, P.R.China Abstract - Web Usage Mining is the application of data mining techniques to usage logs of large Web data repositories in order to produce results used in some aspects, such as Web site design, Web server design, users classification, creating adaptive Web sites and Web site personalization. Data preprocessing is a critical step in Web Usage Mining. The results of data Preprocessing is relevant to the next steps, such as transaction identification, path analysis, association rules mining, sequential patterns mining, and so forth. An algorithm called "USIA" was presented and its advantage and disadvantage were analyzed USIA is experimentally evaluated that not only its eficiency is high, but also it can identify user and session exactly Index Terms - Web Usage Mining; Dub Pre-processing; Users idenrificution; Session Identification I. INTRODUCTION The data source of Web usage mining is Web log files from which we can realize users' browse patterns by Web usage mining. The patterns can be used in some aspects, such as 1 2 pagesfor them 3 promotion to different users to improve ROI 4 other application The early methods of web usage mining can he seen in [ 11 and [Z]. Data pre-processing is the first step of Web usage mining. The results of data pre-processing directly impact the results of next steps including transaction identification, path analysis, association rules mining and sequential patterns mining. In a word, if we get better result from the first step we will improve the mined patterns' quality and save algorithm's running time. It is especially important to web log files, in respect that the structure of web log files are not the same as the data in database or data warehouse. They are not structured and complete due to various causations. So it .is especially necessary to pre-process web log files in web usage mining. Through data pre-processing, web log can be transformed into another data structure, which is easy to he mined. Figure 1 shows an integrated process of web usage mining. It includes data pre-processing, mode mining, mode analysis and mode visualization. This paper will focus on the module of data pre-processing consisted of data cleaning users identification, session identification and path completion, just as Figure 1 showed 11. DATA PREPROCESSING A. Data Cleaning The purpose of data cleaning is to eliminate irrelevant items, and these kinds of technique are of importance forany type of web log analysis not only data mining. The discovered associations rules or reported statistics are useful none but the data represented in the server log gives an accurate picture of the user accesses to the Web site On account of that the HTTP protocol requires separate connections for every file requested from the Web server. A user's request to view a particular page.often results in several log entries since graphics and scripts are downloaded in addition to the HTML file. In most cases, only the log entry of the HTML file request is relevant and should he kept to the user session file, for as much as, in general, a user does not 


user session file, for as much as, in general, a user does not explicitly request all of the graphics on a Web page, which are automatically downloaded due to the HTML tags. Since the main intent of Web Usage Mining is to get a picture of the user's behaviour, other than include file requests that the user did not explicitly request, elimination of the items deemed irrelevant can be reasonably accomplished by checking the suffix of the URL name. For instance, all log entries with filename suffixes such as gif, jpeg, GIF, PEG, jpg, JPG, and I I I r i z &amp; z q 1111l E Fig. 1 Procedure of Web Usage Mining 3119 0-7803-8273-0/04/$20.00 02004 IEEE map can be ignored. In addition, common scripts such as  count.cgi  can also be ignored Removing the irrelevant items can reduce the data that will be analysed and increase the analysis  s speed. It also can decrease the irrelevant items  negative influence to the mining process. For example, the size of total Web log file of Tianjin University  s Web site \(http:Nwww.tju.edu.cfl from Mar. I 2003 to Mar 7, 2003 is 105M byte, containing 1,174,093 records before data cleaning. After removing irrelevant items it remain 378,747 records, therewith we can see this step can remove a mass of irrelevant items B. Useys Identification Users identification is, to identify who access Web site and which pages are accessed. If users have login of their information, it is easy to identify them. In fact, there are lots of user do not register their information. What  s more, there are great numbers of users access Web sites through, agent several users use the same computer, firewall  s existence, one user use different browsers, and so forth. All of problems make this task greatly complicated and very difficult, to identify every unique user accurately. We may use cookies to track users  behaviours. But considering individual privacy many users do not use cookies..So it is necessary to find other methods to solve this problem For users who use the same computer or use the same agent, bow to identify them? As presented in [3], it uses heuristic method to solve the problem, which is to test if a page is requested that is not directly reachable by a hyperlink from any of the, pages visited by the user, the heuristic assumes that there is another user with the same computer or with the same IP address. Ref. [4] presents a method called navigation patterns to identify users automatically. But all of them are not accurate because  they only consider a few aspects that influence the process of users identification Considering this actuality, we presented a new algorithm called  USIA\(User and Session Identification  It analyses more factors, such as user  s IP address, Web site  s topology browser  s edition, operating system and referrer page. This algorithm possesses preferable precision and expansibility. It can not only identify users but also identify session. Session identification will be discussed in next section C. Session Identification For logs that span long periods of time, it is very likely that users will visit the Web site more than once. The goal of session identification is to divide the page accesses of each user at a time into individual sessions. A session is a series of Web pages user browse in a single access The simplest method of achieving session is through a timeout, where if the time between page requests exceeds a certain time limit, it is assumed that the user is starting a new session. Many commercial products use 30 minutes as a default timeout. Because this method is easy and has been tested by some experiments, we use 30 minutes as timeout in 


tested by some experiments, we use 30 minutes as timeout in our experiment D. Path Completion  3120 Another critical step in data preprocessing is path completion. There are some reasons result in path  s incompletion, for instance, .local cache, agent cache  post   technique and browser  s  back  button can result in some important accesses not recorded in the access log file, and the number of URLs recorded in log maybe less than the real one This problem is referred to path completion, which will influence next steps  efficiency and accuracy if it is not solved properly Methods similar to those used for users identification can be used for path completion. If a page request is made that is not directly linked to the last page a user requested, the log can be checked to,see what page the request came from. If the page is in the user  s recent.request history, the assumption is made that the user called up cached versions of the pages with the  back button available on most browsers until a new page was requested. If the log is not clear, the site topology can be used to the same effect. lf more than one page in the user  s history contain a link to the requested page, it is assumed that the page closest to,the previously requested page is the source of the new request [5]. Missing page references inferred through this method are added to the user session file Although the method referred above cannot achieve 100 percent preciseness rate, but it was tested to obtain better result, and is available method. Another method is to use protocol HTTP/1.1 to avoid those problems come from local cache A.  Algorithm S Thinking USIA is an Algorithm about users identification and session identification. There are a lot of sequential records come from the same IP address in Web log files. If we use algorithm to check every record mentioned above, it will decrease algorithm  s efficiency. If the current record  s IP address is the same as previous record  s, then we assume that the two record come from the same user. Now some definitions are given Definition 1: Usersi=\(User_ID, User-IP, User-Url User-Time, User-Referer-Page, User-Agent is the number of total users; User-ID is users  ID have been identified; User-IP is user  s 1P address; User-Url is Web pages user  accessed; User-Time is time user accessed User-Referer-Page is the last page the user requested User-Agent is agent user used We can identify a unique user through all of the factors mentioned above Definition 2: Sessionsi=\(User-ID, Sj,[urljl,urlj2 urljk User-ID stands for users  ID that have been identified; Sj stands for one of the user  s sessions; urljk stands for a aggregate of Web pages in session Sj Definition 3: Cube=\(User_ID, Sj, User-IP,[\(urljl, tjl urlj2, tj2 urljk, tjk users and sessions that have been identified by algorithm User-IP stands for user  s IP address; tjk stands for the time user accessed urljk In USIA, User-ID, Sj and urljk are the same as definition 2. The detail expression of algorithm is given as Fig. 2 B. Procedure of USIA Input: Web log files; Timeout- Timespan Output: User  s ID- User-ID; User  s Session- Session Considering detailed algorithm will need more space, we only list framework of the algorithm String[ , , ] Cube; //Define a three-dimensional array Using it to store User-ID ,r.IP, r.Url \(Web pages  urls r.Time\(time which user access the Web page total Web pages in a single session 


total Web pages in a single session Procedure foreach \(Record rELog in Web log files   if \(r.IPoLast-r.IP  s IP address is not the same as previous record  s IP address. Where Last-r.IP is previous record  s 1P address  if \( isExistedIP \( Cube, r.IP address and there isn  t the IP address in the user  s aggregate that have been identified Storing User-ID, r.IP , r.Url, r.Time User-ID SaveCube \( i, j, k, User-ID, ID, r.Ur1 r.Time i else if \( issameuser \( Usersi, r Current user is the same user in the Usersi that have been identified i if \( r.Time - Cube [ i, j, 1 ]&lt; TimeSpan the time between page requests is not exceeds a certain limit it is assumed that it is a single session  j=j+l Cube [ i, j, 0 ]= r,Url Cube [ i, j, 1 ]= r.Time i else //If the time between page requests exceeds a certain limit, it is assumed that the user is starting a new session  Cube [ i, 0, 1 ]= j - 2; //Where j - 2 is the number of total Web pages user accesses in a single session i = i + 1 k t e j= 0; /lj=O  because there is a new SaveCube \( i, j ,  k, User-ID, r.IP, r.Ur1 session r.Time  i else //The current user is not the same as previous user  User-ID = User-ID + I i= i+ 1 SaveCube \( i, j, k, User-ID, rJP, r.Ur1 r.Time 1 i else // Current record  s IP address is the same as previous record  s IP address Then assume that the two records are made by one user  j= j+ 1 Cube [ i, j, 0 ]= r.Url Cube [ i, j, 1 ]= r.Time i i Procedure isExistedIP \( Cube, r.1P User-Listi which is a user  s aggregate has been identified, just like definition 3. If r.IP is exist in the User-Listi then retum true, else retum false Procedure issameuser \( Usersi, r Usersi . If current user is the same user in Usersi then retum true and k which is number of the user  s sessions else retum false SaveCube \( i, j, . k, User-ID, r P ,  r.Ur1 


SaveCube \( i, j, . k, User-ID, r P ,  r.Ur1 r.Time Procedure Cube [ i, j ,  0 I= User-ID   k; // k is number of Cube [ i, j+l, 0]= r.IP Cube [ i, j+2,0 ]= r.Ur1 Cube [ i, j+2, 1 ]= r.Time  the user  s sessions i The hypothesis of above algorithm is based on two preconditions as followed I  s Precision: In order to examine users identification  s precision, we chose 200 sequential records from Web log files randomly.. Every sequential part comes from different IP address. Using hypothesis it is assumed those records are made by 200 different users. Using IsExistedIP and IsSameUser algorithms to analyze those records, we identified 202 different users Comparing the two results, the hypothesis is acceptable 2 avoid checking up lots of records stage by stage and it can save a lot of time C. Algorithm s Advantage andoisadvantage 1 used as criterion to identify user and algorithm  s precision was unacceptable. On the contrary, we check User-ID User-IP, User-Url, User-Time, User-Referer-Page and User_Agent to identify unique user. So there is a good precision 3121 No Fig. 2 Algonthm'r Flow Chalt 2 user and session at the same time and avoid low efficiency by accomplishing that separately 3 identified by USIA, we construct a three-dimensional dynamic array to store User-ID, r. IP, r. Url and r. Time, avoiding store space's waste. In Fig&amp; 3, the axis of Users - Sessions are users and sessions, where n is number of total users identified and k is the user's the k-th session. 1-1, 2-1, 3-1, n-k stands for different user's sessions. The same user may have more than one session From Fig. 3 we can see that user 3 have two sessions: 3-1 and 3-2. Where IPn is the n-th user's IP address. The axle of IP - Urls is a sequence of Web pages' url in a single session such as A, B, C, D, E, F and so forth. The axle of time is the time user accesses' Web page. For example, 2003-3-1 10:21:36 is the time user 1 accessed Web page A. Where "12 is a number of total Web pages user 1 accessed in session' 1-1 All of the results identified have been stored in the cube and it will facilitate next analysis remarkably 4 factors when it judge whether the current user is the same user in Usersi or not, it results in more time needed. But analysing Web log files in real time is not needed, 'so the algorithm's speed is not the most important. Comparing speed and precision, we think precision is more important  me c I 0 I ill ill 1-1.. . . . .I.. . . . . i . . . ...I.. . . . . i ...../'A IP_urls Fig. 3 Representation of storage smctllre of Users and Session IV. EXPERIMENTAL RESULT Our data source is Web log file of Tianjin University's 


Web site \(http://www.tju.edu.cni to Mar. 7, 2003. The size of total Web log file is 105M bytes After data cleaning it remain 378,747 records. Experimental condition is AMD Athlon \( tm memory USIA identified 55,625 users and 78,566 sessions. If we only use IP address as criterion to do it, we identified 52,870 users. That is to say there are 55,625 - 52,870 = 2,755 users neglected. It is obvious that USIA possess better precision From marketing manager's angle, if the 2,755 users are identified precisely, it will bring great benefit to company Because they can adopt corresponding methods to attract their attention then turn them into loyal customers V. CONCLUSION Our work focus on data pre-processing of Web usage mining and we also laid particular emphasis on algorithm's realization. USIA checks User-ID, User-IP, User-Url User-Time, User-Referer-Page and User-Agent to identify unique user. So there is a better precision than traditional methods. We hope our work can be helpful to other researchers. We will consider user clustering [6] in the future and we think it will help us to get more precise experiment's result There are lots of researchers are studying Web usage mining. But few of them make great progress. We are sure there will be more and more researchers and fund go into this area because this area has great' conimercial value, wide application prospect and relevant technique's development prospect. The emphases of study will continue focus on mode analysis, result's visualization and man-machine interaction REFERENCES I ]  H. Mamila, H Toivonen, and A. I. Verkamo, "Discovering Frequent Episodes in Sequences", Proc. of the Is1 lnl. Conj on Knowledge DiseoveryondDoto Mining, Montreal, Canada, August 1995 I. Pitkow, "In search of reliable usage data on the \\YWW'', Proc. 6th Int WWWGej,  Santa Carla, CA, pp. 451463,  1997 P. Piralli, J. Pitkow, and R. h a ,  "Silk from a sow's ear: Extracting usable slmchlres f" the Web", Pmc. of 1996 Conferace on Humon 2 3 3122 Factors in Computing Systems \(CHI-96 Canada, 1996 4] R.Cooley, B.Mobasher, and J.S  vastava  Grouping Web page references into transactions for mining world wide Web browsing panems  Proc. of the IEEE Knowledge and Data Engineering Exchange Workshop \(KDEX-97 5 ]  W. Gaul and L. Schmidt-Thieme  Mining Web navigation path fragments  Proceedings of the Workshop on Web Mining f o ~  E  Commerce -- Chollenge~ and Oppormnilies, Boston, MA, Aug. 2000 6] Ypma, A., Heskes, T  Categorization of Web Pages and User Clustering with mixtures of Hidden Markov Models  Proceedings of the Inlemotionol Workshop on Web Knowledge Discovery and Dola Mininz, WEBKDD  OZ, July 23 2002, Edqonlon, Canada 3123 pre></body></html 


memory consuming. It is also interesting to note that treebased schemes \(e.g., CLOSET, REPT using FP-tree or prefix tree based algorithms\(e.g., CHARM, RERII efficient on the data that we use 6. Conclusions In this paper, we have proposed two new algorithms RERII and REPT, to discover frequent closed patterns Several experiments showed that the proposed algorithms are faster than existing algorithms, including CLOSET CHARM, CLOSET+ and CARPENTER References 1] C. Creighton and S. Hanash. Mining gene expression databases for association rules. Bioinformatics, 19, 2003 2] F. Pan, G. Cong, A. K. H. Tung, J. Yang, and M. J. Zaki. CARPENTER: Finding closed patterns in long biological datasets In Proc. ACM SIGKDD Int  l Conf. on Knowledge Discovery and Data Mining\(KDD 3] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal. Discovering frequent closed itemsets for association rules. In Proc. 7th Int  l Conf. Database Theory \(ICDT 4] J. Pei, J. Han, and R. Mao. CLOSET: An efficient algorithm for mining frequent closed itemsets. In Proc. ACMSIGMOD Int  l Workshop Data Mining and Knowledge Discovery \(DMKD 5] F. Rioult, J.-F. Boulicaut, B. Cremileux, and J. Besson. Using transposition for pattern discovery from microarray data. In Proc. ACM-SIGMOD Int  l Workshop Data Mining and Knowledge Discovery \(DMKD 6] J. Wang, J. Han, and J. Pei. CLOSET+: Searching for the best strategies for mining frequent closed itemsets. In Proc ACM SIGKDD Int  l Conf. on Knowledge Discovery and Data Mining \(KDD 7] M. J. Zaki and C. Hsiao. CHARM: An efficient algorithm for closed association rule mining. In Proc. SIAM Int  l Conf. on Data Mining \(SDM 8] Z. Zhang, A. Teo, B. Ooi, and K.-L. Tan. Mining deterministic biclusters in gene expression data. In 4th Symposium on Bioinformatics and Bioengineering, 2004 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


entries Consider the first leaf entry &lt;1,10100&gt; in the B-tree of R1 Its sketch 10100 equals the OR for sketches of r1 and r2 i.e., 10000, 10100, respectively each intermediate R-tree entry Ri, its sketch at any time t is the OR of sketches of all the regions in the subtree \(of Ri incremental maintenance algorithms follow those of the aRB-tree due to the similarity of the structures R-tree for the R 1 R2 r1 r2 r 3 r4 spatial dimensions 4B-tree for r 10000110002100001 1010043 3110001 10100 1B-tree for r 11100011002100001 1010054 4111001 11100 1B-tree for R 11100111002101001 1010154 4111001 11101 2B-tree for r 11000100003101001 1000154 4101001 11001 N 4 N 2 N 1 N 3 3B-tree for r 11111100002010001 5 5110001 11111 2B-tree for R 10100100003110001 4 5110001 11111 111115 Figure 3.3: A sketch index example 3.3 Query processing using the sketch index A straightforward algorithm for answering DC queries using the sketch index is to perform the search in a way similar to that in the aRB-tree. To illustrate this, we assume, for simplicity, the same extents of regions \(r1 r2  r4 R1, R2 in Figure 2.2a. Consider again the query q with window qr \(shown in Figure 2.2a  search algorithm initiates a result sketch RS with all bits set to 0, and gradually updates it. Specifically, the search starts from the root of the R-tree. Since R1 is contained in qr, we fetch the root N1 of its B-tree, where the first entry lt;1,11100&gt; indicates that the OR of all sketches in its subtree during [1,3] is 11100, which becomes the new value of RS. The child node N2 of the second root entry must be searched. Inside this node, entry &lt;4,11100&gt; qualifies qt and thus its sketch is OR-ed with RS \(which, however incurs no change to RS the R-tree and, since R2 partially intersects qr, accesses its child node, in which the only entry intersecting qr is r4 Hence, it visits N3 and N4 producing the final sketch RS=11100. In Figure 3.3, the visited B-tree nodes are shaded The above algorithm applies spatial and temporal conditions \(using qr and qt respectively ignores the pruning power of the sketches themselves Notice that in the previous example RS is already set to 11100 \(i.e., the final result search process \(i.e., after accessing the root of the B-tree 


search process \(i.e., after accessing the root of the B-tree of R1 not affect the final result at all. This motivates the following pruning heuristic Heuristic 3.1: Let RS be the current result sketch, and e an intermediate B-tree entry whose associated sketch is se Then, the sub-tree of e can be pruned if \(se OR RS  Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE According to this rule, the processing of the above query can avoid visiting node N4 because the sketch \(10100 its parent entry &lt;3,10100&gt; satisfies 10100 OR RS = RS The implication is that, in order to maximize the effectiveness of Heuristic 3.1, we should first try to maximize the 1's in RS, before descending intermediate B-tree  postpone  visiting nodes that may be pruned later as more bits of RS are set The next question is: which node accesses are avoidable and which ones are necessary To answer this question, let SRE be the set of R-tree entries whose B-trees must be accessed. Equivalently, each entry e in SRE satisfies the following conditions: \(i covered by query rectangle qr \(or its MBR intersects qr if e is a leaf ii i In the example of Figure 3.3, SRE={R1,r4}. Evidently accesses to the roots of their respective B-trees are unavoidable1. Hence we visit all of them \(in Figure 3.3 nodes N1 and N3 of these entries allow us to set \(possibly many without any further node access. The first entry of N1 has lifespan [1,3] \(3 is derived from the timestamp of the next entry 4 we can immediately update RS to its sketch 11100 Similarly, the lifespan [1,2] of the first entry in N3 is also contained in qt; hence its sketch 11000 is also taken into account, but does not change RS Now let us consider the remaining entries in N1 and N3 namely, &lt;4,11101&gt; and &lt;3,10100&gt;. Although, their lifespans are not contained in qt=[1,4], Heuristic 3.1 eliminates &lt;3,10100&gt;. Nevertheless, &lt;4,11101&gt; is not pruned by the heuristic because 11101 OR RS = 11101 RS. However, recall that our objective is not to retrieve the complete final RS. Instead, we are interested in the position of the left-most bit that is still 0. What is the possible left-most position \(of the final RS Given the current RS=11100 and entry &lt;4,11101&gt;, the answer is 4 \(i.e., the left-most 0 must be at the 4-th bit since the first 3 bits of both RS and the entry  s sketch are all 1. Therefore, the access to the child node of this entry can also be avoided, because \(even if we actually visit it the only possible change to RS is to set the 5-th bit to 1 which does not affect our estimation. This observation leads to another heuristic Heuristic 3.2: Let SU be the OR of the sketches of the entries whose sub-trees cannot be pruned so far. If p is the position of the left-most 0 in \(RS OR SU tree of an intermediate \(B-tree sketch se satisfies the following condition    1 1 AND 1...10...0  OR  AND 1...10...0e p p RS RS s       1 


1 Unlike the aRB-tree, we do not store sketches in the R-tree entries because this would decrease the node fanout Heuristic 3.2 subsumes 3.1 by providing a more general condition. Specifically, instead of requiring all bits of RS and \(RS OR se p?1 bits \(of the these sketches where p is decided by RS and SU together indicates a good access order for the child nodes of entries not pruned by Heuristic 3.2 Heuristic 3.3: Given a set of qualifying entries, we visit their child nodes in descending order of the number of 1  s in their sketches We use a heap to manage the entries which cannot be pruned yet, using the numbers of 1  s in their sketches as the sorting keys. As an example, consider another query whose \(i r1, r2, r3, r4 and contains the MBR of R1 but not R2, and \(ii qt=[1,4]. In this case, the algorithm first visits the roots of the B-trees of R1, r3, r4, after which RS=11100, and the heap contains two entries &lt;1,11111&gt; \(from the root of r3  s B-tree the second entry in the B-tree of R1 visit the child node of &lt;1,11111&gt; next since it has more 1  s. Figure 3.4 illustrates the pseudo-code of the improved algorithm \(referred to as sketch-prune in the sequel algorithm sketch_prune \(qr, qt 1.   initiate a  max  heap H accepting entries of the form lt;B-tree entry e, key&gt;;  set all bits of RS to 0 2. obtain the set SRE of R-tree entries whose B-trees must be searched 4. for each of entry e in SRE 5.  for each entry e' in the root of e.btree 6.   process_intermediate\(e', SRE, H 7. while \(H is not empty 8.  SU = the OR of the sketches of the entries in H 9.  p = the position of  the left-most 0 of SRE OR SU 10.  remove the top entry &lt;e, key&gt; from H; let the sketch of e be se 11.  let s be a sketch whose left-most \(p?l while the others are 0 12.  if \(RS OR se AND s RS AND s 13.   for each entry e' in e.child  \(its sketch se 14.          if \(e.child is leaf e'.lifespan intersects qt 15.     RS=se' OR RS 16.     if \(e' is an intermediate node 17.      process_intermediate\(e', Sfinal, H 18. let k be the position of the left-most 0 in RS 19. return 1.29  2k end sketch_prune Algorithm process_intermediate \(e, Sfinal, H e is an intermediate entry in the B-tree with sketch se; RS is the current result sketch; qt is the query interval; H is the heap 1. if e.lifespan is contained in qT  then RS=RS OR se 2. else if \(e.lifespan intersects qT 3.  insert &lt;e, number of  1  in se&gt; into H end process_intermediate Figure 3.4: The sketch-prune algorithm Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE Heuristic 3.3 provides a reasonably  good  access order but other more sophisticated and potentially better access orders exist. For instance, the order may be decided according to the number of additional bits in RS that may be set \(to 1 and two sketches 11100 and 00110; then according to this order, the second sketch will be processed first \(although it has fewer 1  s while the first sketch can set only one bit adjusting the sorting keys of the entries in the heap as the algorithm proceeds \(and RS changes 


algorithm proceeds \(and RS changes expensive if the heap size is large The description so far assumes that only one sketch is maintained per B-tree entry; however, the sketch-prune algorithm can be easily modified to support multiple sketches \(which, as discussed in Section 2.1, leads to higher accuracy are applied individually for each sketch to prune the entries that qualify the heuristic conditions in all sketches Then, Heuristic 3.3 determines the access order with respect to the total number of 1  s in all the sketches of an entry. The storage of the sketch index at each timestamp is linear to \(i ii log2n of each sketch, and \(iii used. As a result, the total space complexity \(for all T timestamps in the history m  R  T  logn 3.4 Supporting distinct sum queries The proposed method for DC \(distinct count can be applied to DS \(distinct sum the sketches of the leaves. The resulting sketches are then indexed and queried in exactly the same way as described in the previous section. Hence, it suffices to illustrate the specialized algorithm for creating the sum sketches Specifically, the problem is stated as follows: given a dataset with \(possibly duplicate object o, measure w distinct objects. That is, if an object appears with the same measure several times, its measure is added only once We solve this problem by reducing it to DC processing Given an input record \(o, w generation algorithm by inserting w different elements o,?1,w o,?2,w  o,?w,w to distinguish these elements. Consequently, the estimated  count  using FM is actually the sum of the w  s of distinct records \(o, w comparing both o and w problem2. The disadvantage of this approach is that, if w is large, inserting w different elements will be expensive Here we briefly describe an alternative algorithm for generating sum-sketches that remedies this problem \(more 2 An alternative approach is to insert elements of the form o,?i  count  is the sum of the maximum w  s for each distinct o details and proofs may be found in [CLKB04 idea is to leverage the observation of [FM85] that the first few \(say x almost estimator is only concerned with the first 0 in the final sketch, we only need to consider the part \(of the sketch starting at the \(x+1 ignore the insertion of those elements \(let their number be y function \(used by FM probability of setting the i-th bit equals 2?i, each element has probability ?xi=1\(2?i any of Hence, y follows the Binomial distribution3 Bin\(w, ?xi=1 2?i in order to decide how many bits after the x-th one is set and obtain the resulting sketch. Let the left-most 0 of this sketch be at position k'; then the corresponding position k in the sketch of inserting all w elements equals x+k There remains only one question: what is a good value for x? The analysis of [FM85] observes that inserting w distinct items sets the first x = log2 w?2 log2 log2 w bits of the resulting sketch to 1 with high probability. This value is adopted in our implementation. Finally, we note that this method can also be combined with PCSA to improve accuracy, as shown in Figure 3.5 algorithm  sum_PCSA \(DS, h, m, r dataset DS={\(o1,w1 o2,w2  h is a random function such that, Prob[h\(o,w the number of bits in each sketch 


the number of bits in each sketch 1. init m sketches s1, s2  sm, each with r bits, all set 0 2. for each \(o, w 3.       randomly pick a sketch si \(1?i?m 4. x = log2w  2log2log2w 5.       for j=1 to x 6.            si[j] = 1 7.       for j=1 to w?Bin\(w, ?xi=1\(2?i 8.            si[x+h\(o,j 9. k=0 10.  for i=1 to m do 11.       for  j=1 to r do 12.              if  si[j] = 0 then 13. k = k + j 14. break;  // go to the next sketch 15. return \( 1.29m  2 k/ m end  sum_PCSA Figure 3.5: Sketch generation and estimation for DS 4. Extensions In this section we present the application of the proposed techniques to related spatio-temporal problems. Section 4.1 uses sketches to reduce the size of general spatiotemporal databases and enhance the performance of 3 For Binomial distribution x~Bin\(n,p Prob[x=m] is \(nm 1?p Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE aggregate processing. Section 4.2 applies sketches to mine spatio-temporal association rules 4.1 Approximating general moving data The discussion in Section 3 assumes a set of regions that constitute the finest aggregation granularity, which may not be the case for the conventional spatio-temporal databases. In this scenario, each object o reports its location \(x,y maintains a tuples in the form &lt;o,x,y,t&gt;. Evidently, the size of the database table grows continuously, so that eventually it becomes prohibitively large \(especially if the number of monitored objects is high space complexity O\(n  T where n is the number of objects, and T is the number of timestamps in the history this deteriorates query performance. In the sequel, we show that, if the goal is to support aggregate queries, we can reduce the size and query overhead significantly, at the trade-off of some small error \(around 15% as shown in our experiments We manually impose a res  res regular grid over the data space \(i.e., each cell of the grid has length 1/res of the total axis extent resolution. Then, the sketch index is directly applicable by treating the grid cells as the finest aggregate granularity. It is worth mentioning that if the number of cells is relatively small \(i.e., low resolution approximation tends to over-estimate the actual result because an object, which does not fall in the query rectangle qr, but in a cell intersecting qr, will also be counted. This problem can be alleviated by setting res to a sufficiently large value \(e.g., 50 in our implementation is easy to verify that the space complexity is O\(\(res  T  logn T  logn further improvement, observe that we can actually remove the R-tree from the sketch index, because the cells indexed by the R-tree are regular. Specifically, it suffices to introduce a hierarchical decomposition as shown in Figure 4.1, where the grid at level i has resolution 2i, and the maximum level equals log2res Level 0 Level 1 Level L B-tree 


B-tree B-tree B-tree B-tree B-tree Figure 4.1: Grid-based approximation Note that, this hierarchy implicitly defines the parentchild relation among cells of different levels \(e.g., the shaded cell at level 0 is the ancestor of all the shaded cells in the lower levels associated with a B-tree managing the historical sketches about objects in its extent \(cells in intermediate levels resemble intermediate entries in the R-tree of a sketch index of cells \(in a particular grid i ii index, descending the hierarchy is only necessary for case i ii can be proven that, given the finest resolution res, the algorithm accesses O\(res  hB for any query hB is the maximum height of the B-tree 4.2 Mining spatio-temporal association rules Consider a user in region ri at time t. What is the probability p that this user will appear in region rj by time t+T? We denote such a spatio-temporal association rule with the syntax \(ri,T,p important in practice. For example, in mobile computing they can identify trends in user movements and lead to better allocation of antenna bandwidth to cater for potential network congestions in the near future Additional constraints, such that ri and rj must be within certain distance, may also be specified By maintaining the sketches of all regions at each timestamp as in Figure 3.2, we can answer the following question easily: given specific ri, rj, and a timestamp t how many users that are in ri at t, appear in rj at any of the following T timestamps \(i.e., t+1  t+T t sketch of ri at time t, and sj\(t t+T rj at the subsequent T timestamps. We first estimate the number n1 of objects at ri at time t \(using si\(t number n2 of objects at rj during time interval [t+1, t+T using ORt+Ti=t+1\(sj\(t+i number n3 of objects that appeared either in ri \(at time T or in rj during [t+1, t+T] \(using ORt+Ti=t+1\(sj\(t+i t Then, the number of objects that appear in ri at time t and then appear in rj during [t+1, t+T] equals n1+n2?n3. This idea naturally leads to a simple brute-force algorithm for discovering the association rules, which as shown in Figure 4.2, checks all possible instances of \(ri, rj, t algorithm associate_rule_mining \(T, p, c T is the horizon; p is the appearance probability; c is the confidence factor 1. for each region ri 2.  for each region rj 3.   sample=0; witness=0 4.   for each timestamp t in history 5.    sample 6.    s' = sj\(t+1 t+2 t+T 7.     n1=FM estimate from si\(t n3=estimate from si\(t 8.    if \(n1+n2?n3 9.   if \(witness/sample&gt;c ri,T,p end associate_rule_mining Figure 4.2: Algorithm for mining association rules Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE 5. Experiments This section experimentally evaluates the proposed methods. First, Section 5.1 examines the efficiency of the sketch-index in answering aggregate queries. Then 


sketch-index in answering aggregate queries. Then Section 5.2 studies the effect of approximating spatiotemporal data, while Section 5.3 presents preliminary results for mining association rules 5.1 Performance of sketch-indexes Due to the lack of real spatio-temporal datasets we generate synthetic data in a way similar to [SJLL00 TPS03] aiming at simulation of air traffic. We first adopt a real spatial dataset [Tiger] that contains 10k 2D points representing locations in the Long Beach county \(the data space is normalized to unit length on each dimension These points serve as the  airbases  At the initial timestamp 0, we generate 100k air planes, such that each plane \(i uniformly generated in [200,300], \(ii, iii destination that are two random different airbases, and iv  the velocity direction is determined by the orientation of the line segment connecting its source and destination airbases move continually according to their velocities. Once a plane reaches its destination, it flies towards another randomly selected also uniform in [0.02, 0.04 reports to its nearest airbase, or specifically, the database consists of tuples in the form &lt;time t, airbase b, plane p passenger # a&gt;, specifying that plane p with a passengers is closest to base b at time t A spatio-temporal count/sum query has two parameters the length qrlen of its query \(square number qtlen of timestamps covered by its interval. The actual extent of the window \(interval uniformly in the data space \(history, i.e., timestamps 0,100 air planes that report to airbases in qr during qt, while a sum query returns the sum of these planes  passengers. A workload consists of 100 queries with the same parameters qrlen and qtlen The disk page size is set to 1k in all cases \(the relatively small page size simulates situations where the database is much more voluminous specialized method for distinct spatio-temporal aggregation, we compare the sketch-index to the following relational approach that can be implemented in a DBMS. Specifically, we index the 4-tuple table lt;t,b,p,a&gt; using a B-tree on the time t column. Given a count query \(with window qr and interval qt SELECT distinct p FROM &lt;t,b,p,a&gt WHERE t?qt &amp; b contained in qr The performance of each method is measured as the average number of page accesses \(per query processing a workload. For the sketch-index, we also report the average \(relative Specifically, let acti and esti be the actual and estimated results of the i-th query in the workload; then the error equals \(1/100 set the number of bits in each sketch to 24, and vary the number of sketches The first experiment evaluates the space consumption Figure 5.1 shows the sketch index size as a function of the number of sketches used \(count- and sum-indexes have the same results more sketches are included, but is usually considerably smaller than the database size \(e.g., for 16 signatures, the size is only 40% the database size 0 20 40 60 80 


80 100 120 140 160 8 16 32 number of sketches size \(mega bytes database size Figure 5.1: Size comparison Next we demonstrate the superiority of the proposed sketch-pruning query algorithm, with respect to the na  ve one that applies only spatio-temporal predicates. Figure 5.2a illustrates the costs of both algorithms for countworkloads with qtlen=10 and various qrlen \(the index used in this case has 16 sketches also illustrate the performance of the relational method which, however, is clearly incomparable \(for qrlen?0.1, it is worse by an order of magnitude we omit this technique Sketch-pruning always outperforms na  ve \(e.g., eventually two times faster for qrlen=0.25 increases with qrlen, since queries returning larger results tend to set bits in the result sketch more quickly, thus enhancing the power of Heuristics 3.1 and 3.2. In Figure 5.2b, we compare the two methods by fixing qrlen to 0.15 and varying qtlen. Similar to the findings of [PTKZ02]4 both algorithms demonstrate  step-wise  growths in their costs, while sketch-pruning is again significantly faster The experiments with sum-workloads lead to the same observations, and therefore we evaluate sketch-indexes using sketch-pruning in the rest of the experiments 4 As explained in [PTKZ02], query processing accesses at most two paths from the root to the leaf level of each B-tree regardless the length of the query interval Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE sketch-pruning naive relational 0 100 200 300 400 500 600 700 800 900 0.05 0.1 0.15 0.2 0.25 number of disk accesses query rectangle length 300 0 100 200 400 500 600 1 5 10 15 20 number of disk accesses query interval length a qtlen=10 b qrlen=0.15 Figure 5.2: Superiority of sketch-pruning \(count As discussed in Section 2, a large number of sketches reduces the variance in the resulting estimate. To verify this, Figure 5.3a plots the count-workload error of indexes 


using 8-, 16-, and 32- sketches, as a function of qrlen qtlen=10 error \(below 10 it increases slowly with qrlen used, however, the error rate is much higher \(up to 30 and has serious fluctuation, indicating the prediction is not robust. The performance of 16-sketch is in between these two extremes, or specifically, its accuracy is reasonably high \(average error around 15 much less fluctuation than 8-sketch 32-sketch 16-sketch 8-sketch relative error 0 5 10 15 20 25 30 35 0.05 0.1 0.15 0.2 0.25 query rectangle length relative error 0 5 10 15 20 25 30 35 1 5 10 15 20 query interval length a qtlen=10, count b qrlen=0.15, count relative error query rectangle length 0 5 10 15 20 25 0.05 0.1 0.15 0.2 0.25 relative error query interval length 0 5 10 15 20 25 30 1 5 10 15 20 c qtlen=10, sum d qrlen=0.15, sum Figure 5.3: Accuracy of the approximate results The same phenomena are confirmed in Figures 5.3b where we fix qrlen to 0.15 and vary qtlen 5.3d \(results for sum-workloads number of sketches improves the estimation accuracy, it also leads to higher space requirements \(as shown in Figure 5.1 Figures 5.4a and 5.4b show the number of disk accesses for the settings of Figures 5.3a and 5.3b. All indexes have almost the same behavior, while the 32-sketch is clearly more expensive than the other two indexes. The interesting observation is that 8- and 16-sketches have 


interesting observation is that 8- and 16-sketches have almost the same overhead due to the similar heights of their B-trees. Since the diagrams for sum-workloads illustrate \(almost avoid redundancy 32-sketch 16-sketch 8-sketch number of disk accesses query rectangle length 0 50 100 150 200 250 300 350 400 0.05 0.1 0.15 0.2 0.25 number of disk accesses query interval length 0 50 100 150 200 250 300 350 1 5 10 15 20 a qtlen=10 b qrlen=0.15 Figure 5.4: Costs of indexes with various signatures Summary: The sketch index constitutes an effective method for approximate spatio-temporal \(distinct aggregate processing. Particularly, the best tradeoff between space, query time, and estimation accuracy obtained by 16 sketches, which leads to size around 40 the database, fast response time \(an order of magnitude faster than the relational method average relative error 5.2 Approximating spatio-temporal data We proceed to study the efficiency of using sketches to approximate spatio-temporal data \(proposed in Section 4.1 as in the last section, except that at each timestamp all airplanes report their locations to a central server \(instead of their respective nearest bases maintains a table in the form &lt;time t, plane p, x, y&gt;, where x,y with parameters qrlen and qtlen distinct planes satisfying the spatial and temporal conditions. For comparison, we index the table using a 3D R*-tree on the columns time, x, and y. Given a query, this tree facilitates the retrieval of all qualifying tuples, after which a post-processing step is performed to obtain the Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE number of distinct planes \(in the sequel, we refer to this method as 3DR method introduces a regular res  res grid of the data space, where the resolution res is a parameter. We adopt 16 sketches because, as mentioned earlier, this number gives the best overall performance Figure 5.5 compares the sizes of the resulting sketch indexes \(obtained with resolutions res=25, 50, 100 the database size. In all cases, we achieve high compression rate \(e.g., the rate is 25% for res=25 evaluate the query efficiency, we first set the resolution to the median value 50, and use the sketch index to answer workloads with various qrlen \(qtlen=10 


workloads with various qrlen \(qtlen=10 size \(mega bytes database size 0 20 40 60 80 100 120 140 160 25 50 100 resolution Figure 5.5: Size reduction Figure 5.6a shows the query costs \(together with the error in each case method. The sketch index is faster than 3DR by an order of magnitude \(note that the vertical axis is in logarithmic scale around 15% error observations using workloads with different qtlen Finally, we examine the effect of resolution res using a workload with qrlen=0.15 and qtlen=10. As shown in Figure 5.6c, larger res incurs higher query overhead, but improves the estimation accuracy Summary: The proposed sketch method can be used to efficiently approximate spatio-temporal data for aggregate processing. It consumes significantly smaller space, and answers a query almost in real-time with low error 3D Rsketch number of disk accesses query rectangle length 1 10 100 1k 10k 0.05 0.1 0.15 0.2 0.25 16 14% 15 15% 13 relative error number of disk accesses query interval length 1 10 100 1k 10k 1 5 10 15 20 16 15% 15% 12% 11 relative error a qtlen=10, res=25 b qrlen=0.15, res=25 0 500 1000 1500 2000 2500 25 50 100 number of disk accesses resolution 20% 15% 14 relative error c qrlen=0.15, qtlen=10 


c qrlen=0.15, qtlen=10 Figure 5.6: Query efficiency \(costs and error 5.3 Mining association rules To evaluate the proposed algorithm for mining spatiotemporal association rules, we first artificially formulate 1000 association rules in the form \(r1,T,90 with 90% confidence i randomly picked from 10k ones, \(ii in at most one rule, and \(iii Then, at each of the following 100 timestamps, we assign 100k objects to the 10k regions following these rules. We execute our algorithms \(using 16 sketches these rules, and measure \(i  correct  rules divided by the total number of discovered rules, and \(ii successfully mined Figures 5.7a and 5.7b illustrate the precision and recall as a function of T respectively. Our algorithm has good precision \(close to 90 majority of the rules discovered are correct. The recall however, is relatively low for short T, but gradually increases \(90% for T=25 evaluated in the previous sections, the estimation error decreases as the query result becomes larger \(i.e., the case for higher T 78 80 82 84 86 88 90 92 94 96 5 10 2015 25 precision HT 78 80 82 84 86 88 90 92 94 96 5 10 2015 25 recall HT a b Figure 5.7: Efficiency of the mining algorithm Summary: The preliminary results justify the usefulness of our mining algorithm, whose efficiency improves as T increases Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE 6. Conclusions While efficient aggregation is the objective of most spatio-temporal applications in practice, the existing solutions either incur prohibitive space consumption and query time, or are not able to return useful aggregate results due to the distinct counting problem. In this paper we propose the sketch index that integrates traditional approximate counting techniques with spatio-temporal indexes. Sketch indexes use a highly optimized query algorithm resulting in both smaller database size and faster query time. Our experiments show that while a sketch index consumes only a fraction of the space required for a conventional database, it can process 


required for a conventional database, it can process queries an order of magnitude faster with average relative error less than 15 While we chose to use FM sketches, our methodology can leverage any sketches allowing union operations Comparing the efficiency of different sketches constitutes a direction for future work, as well as further investigation of more sophisticated algorithms for mining association rules. For example, heuristics similar to those used for searching sketch indexes may be applied to improve the brute-force implementation ACKNOWLEDGEMENTS Yufei Tao and Dimitris Papadias were supported by grant HKUST 6197/02E from Hong Kong RGC. George Kollios, Jeffrey Considine and were Feifei Li supported by NSF CAREER IIS-0133825 and NSF IIS-0308213 grants References BKSS90] Beckmann, N., Kriegel, H., Schneider, R Seeger, B. The R*-tree: An Efficient and Robust Access Method for Points and Rectangles. SIGMOD, 1990 CDD+01] Chaudhuri, S., Das, G., Datar, M., Motwani R., Narasayya, V. Overcoming Limitations of Sampling for Aggregation Queries. ICDE 2001 CLKB04] Jeffrey Considine, Feifei Li, George Kollios John Byers. Approximate aggregation techniques for sensor databases. ICDE, 2004 CR94] Chen, C., Roussopoulos, N. Adaptive Selectivity Estimation Using Query Feedback. SIGMOD, 1994 FM85] Flajolet, P., Martin, G. Probabilistic Counting Algorithms for Data Base Applications JCSS, 32\(2 G84] Guttman, A. R-Trees: A Dynamic Index Structure for Spatial Searching. SIGMOD 1984 GAA03] Govindarajan, S., Agarwal, P., Arge, L. CRBTree: An Efficient Indexing Scheme for Range Aggregate Queries. ICDT, 2003 GGR03] Ganguly, S., Garofalakis, M., Rastogi, R Processing Set Expressions Over Continuous Update Streams. SIGMOD, 2003 HHW97] Hellerstein, J., Haas, P., Wang, H. Online Aggregation. SIGMOD, 1997 JL99] Jurgens, M., Lenz, H. PISA: Performance Models for Index Structures with and without Aggregated Data. SSDBM, 1999 LM01] Lazaridis, I., Mehrotra, S. Progressive Approximate Aggregate Queries with a Multi-Resolution Tree Structure. SIGMOD 2001 PGF02] Palmer, C., Gibbons, P., Faloutsos, C. ANF A Fast and Scalable Tool for Data Mining in Massive Graphs. SIGKDD, 2002 PKZT01] Papadias,  D., Kalnis, P.,  Zhang, J., Tao, Y Efficient OLAP Operations in Spatial Data Warehouses. SSTD, 2001 PTKZ02] Papadias, D., Tao, Y., Kalnis, P., Zhang, J Indexing Spatio-Temporal Data Warehouses ICDE, 2002 SJLL00] Saltenis, S., Jensen, C., Leutenegger, S Lopez, M.A. Indexing the Positions of Continuously Moving Objects. SIGMOD 2000 SRF87] Sellis, T., Roussopoulos, N., Faloutsos, C The R+-tree: A Dynamic Index for MultiDimensional Objects. VLDB, 1987 TGIK02] Thaper, N., Guha, S., Indyk, P., Koudas, N Dynamic Multidimensional Histograms 


SIGMOD, 2002 Tiger] www.census.gov/geo/www/tiger TPS03] Tao, Y., Papadias, D., Sun, J. The TPR*Tree: An Optimized Spatio-Temporal Access Method for Predictive Queries. VLDB, 2003 TPZ02] Tao, Y., Papadias, D., Zhang, J. Aggregate Processing of Planar Points. EDBT, 2002 TSP03] Tao, Y., Sun, J., Papadias, D. Analysis of Predictive Spatio-Temporal Queries. TODS 28\(4 ZMT+01] Zhang, D., Markowetz, A., Tsotras, V Gunopulos, D., Seeger, B. Efficient Computation of Temporal Aggregates with Range Predicates. PODS, 2001 ZTG02] Zhang, D., Tsotras, V., Gunopulos, D Efficient Aggregation over Objects with Extent PODS, 2002 Proceedings of the 20th International Conference on Data Engineering \(ICDE  04 1063-6382/04 $ 20.00  2004 IEEE pre></body></html 



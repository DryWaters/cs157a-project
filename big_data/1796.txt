Implementing Geographic Information Systems \(GIS\in Spreadsheet Models: What, Why, and How  Jeffrey Keisler UMass, Boston Jeff.Keisler@umb.edu   Roger Blake UMass, Boston Roger.Blake@umb.edu   Janet Wagner Stockton College 
Janet.Wagner@stockton.edu  Abstract  Geographic Information Syst ems \(GIS\, computerbased systems that allow decision makers to incorporate geographically based data into their analyses, are widespread and powerful tools in many business and scientific settings today.   In this paper we discuss ways in which GIS functionality can be implemented w ithin the spreadsheet environment. We show the straightforward and natural analogy between 
several GIS functions with spreadsheet functions particularly for raster based data. We present two realistic examples meshing analytical models with GIS methods --- an integration which is greatly enhanced by the remarkable development platform provided by spreadsheets.  We discuss the many benefits of the spreadsheet enabled seamless integration of 
geographical data, mathematical analysis, and mapping displays  1. Introduction  Geographic Information Systems \(GIS\mputerbased systems that allow decision makers to incorporate geographically based data into their analyses, are widespread and powerful tools in many business and scientific settings today.   Geographic information systems --- broadly defined as systems that 
can store, retrieve, map, and analyze geographic data have grown dramatically in the past decade, helped in large part by the advent of affordable applications for the desktop. The field has also benefited from the increased availability of free and low cost data distributed easily on the internet. GIS have spread from their traditional domains of military applications utility management, environmental and resource 
management to fields such as marketing \(Sohovich  in s u ra n ce an d real es tate as s e s s m e n t s ee L ong le y  Clarke D A applica tion s f o r f i eld w ork a n d  even human rights work \(O Sullivan i f  n o t  most, U.S. and Canadian government agencies as well as states in the U.S. now have GIS departments and 
publicly available GIS data on the web. Organizations are making use of exciting new interactive web-based packages that allow for easy deployment of maps and spatial data. However, there is still a need to expand the use of GIS within organizations, particularly corporations, and to allow for more interaction between GIS experts and other departments The idea that will be explored in this paper is that 
Figure 1. Raster maps implemented in a spreadsheet Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 1 978-0-7695-3450-3/09 $25.00 © 2009 IEEE 


GIS analyses, particularly those based on raster data can --- in fact --- be done in spreadsheets.  This paper will then investigate what GIS applications can be done within spreadsheets, why one might use the spreadsheet platform for GIS functionality, and how to do it. The applications in this paper are developed with Excel 2003. The ideas should be easily implemented in any spreadsheet program, and in particular, can approach power-user level resolution with Excel 2007 We note that Microsoft has a mapping program MapPoint, which can be linked to Excel.  However, we are suggesting a different kind of interaction, where raster data is analyzed and displayed in the spreadsheet itself GIS applications almost always involve linking analytical models in one application with stand alone and often black box GIS in a separate application The contribution of this paper is to show how realistic GIS-all-within-a-spreadsheet applications can be developed to provide the seamless integration of geographic data, mathematical analysis, and mapping displays.  Our applications demonstrate how to tie the analytical power of spreadsheets to geographically defined data.  We discuss the reasons why we expect advantages of implementing GIS in spreadsheets.  Our examples will then present the details of how and illustrate the what   2. Motivation Why   Seamlessly integrating GIS into spreadsheets is motivated by several strengths of the most common spreadsheet, Microsoft Excel. Excel has a very large user base --- in the hundreds of millions compared to around one million users for a widely used GIS product suite \(Carav h e Ex cel u s er ba s e e x ten d s  deeply within and broadly across organizations, and there are many power users able to conduct sophisticated analyses or develop sophisticated applications. Numerical models for DSS are easily developed within Excel.  Furthermore, because of its large commercial use, Microsoft has invested in developing a large number of features supporting quantitative analysis and information project management for use with Excel Having GIS in the spreadsheet modeling toolkit will   increase the functionality of spreadsheet based systems   extend the reach of possible applications for spreadsheet prototyping   allow creative merging of mathematical and GIS methods and technologies, and   enhance the ability of non-technical spreadsheet end-users to understand and accept analytical work and results involving geographical data  3. GIS Models and their Ties to Spreadsheets What   GIS were initially developed as an interdisciplinary field combining elements from the field of computer science with geography and mapmaking.   The use of computers for mapping applications was initially developed during the 1960 s for a survey of land use and planning in Canada in an effort headed by Roger Tomlinson \(sometimes called the Father of GIS geographer in an aerial survey company who had dabbled with the use of computers for mapping \(see GeoWorl f o r an in teres t i ng interview with Roger Tomlinson\.  GIS has now become its own specialty, with numerous stand-alone GIS departments and programs.   Resources providing an overview of the field of GIS and its capabilities include a nice layperson introduction to GIS by the U.S. Geological Service [6 d num erou s GIS textbooks, for example Lo and Yeun d L ong l e y     GIS data itself has become an area of interest on its own.  GIS data is now stored in a number of standard data formats or protocols, including those for the systems from ESRI \(shapefiles\nd GRASS \(runlength encoding for rasters\. GIS systems increasingly read, store and create standardized metadata and make these data files available and accessible over the web to the general public. Many GIS systems use a database such as Oracle to store enterprise-wide spatial attribute data. A DBMS, such as ESRI s SDE, allows for full integration of data and map elements There have been a few previous discussions in the literature specifically exploring the concept of implementing GIS in spreadsheets.  Although never quite using maps per se Klosterman   e l oped a  number of spreadsheet models for urban and regional analysis some of which include demographic economic, and other geographically based data sets.  In the early 1990 s, Raub o n s trated t h e con c ept  of importing GIS raster data into Excel as a pedagogical device, and their students were able to develop models with it, although it was not intended as an actual application.  Charles Ehlschlaege  developed an application involving a promising method of piping linear programming functionality from Mathematica, an Excel Plug-in, into a GIS Co w rote a h e lpfu l pa per f o cu s i n g on t h e  technical aspects of using spreadsheets to produce maps from scratch including drawing map objects and coloring them so as to display spatial data Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 2 


Supporting the overall theme of this paper, Cole writes that spreadsheets Can be used to prepare acceptable maps rather quickly and gives more dir ect links between data analysis, and mapping, enabling more effective GIA \(geographic information analysis\, and can be used for quite large-scale applications  Later in his paper Cole concludes Spreadsheets provide a tool to explore ideas for novel interfaces or operations, and avoiding some of the continuing frustrations of mainstream GIS but which might subsequently be implemented within GIS as part of students own research or professional kit bag.  Important here is the direct link to the other facilities of spreadsheets for data processing and model construction  Although it didn t use spreadsheets, we note a Decision Support System \(DSS\nvolving operations research and management science \(OR/MS\iques used on geographical data developed by Keisler Sundell   w a s t h e reco g n i tion t h at th e abili t y  to operate on GIS data directly from Excel was possible and would have greatly simplified the development of the Keisler & Sundell DSS that provided the impetus for this paper. In that application several additional features could have been incorporated had the models been developed in the faster DSS prototyping environment provided by Excel  4. Implementaion of Spreadsheet Based GIS How   In this section we will describe the technical details of how several basic GIS functions can be implemented in spreadsheets and how to incorporate common GIS based data types into spreadsheets These technical ideas will be the building blocks used to develop the Section 5 applications incorporating these GIS functions into OR/MS analyses  4.1  Basic Mapping Functions  One of the basic GIS data types for storing mapping information is known as raster data  involving square or rectangular pixels also, even in the GIS world, called cells ged in rows and columns where the logical position in the data array corresponds to a physical position.  In raster data formats, each cell contains a single value.  Often this value is a color, but it can also be a numerical value indicating values such as land use or elevation above sea level.  Assuming the pixels contain colors, a raster display will the produce what we would recognize as a map  The analogy between a raster display and a spreadsheet is then straightforward.  By treating each cell of the spreadsheet as a pixel, sizing the cells as squares or small rectangles, and using the cell contents to specify a color property \(or other appearance spreadsheets can be used to produce maps.  The spreadsheet function of conditional formatting of cells which changes the appearance of a cell depending on its contents, is a critical capability for this application With conditional formatting \(available from Format on Excel s toolbar\s possible to change the color of the background, the border, and the font and color of cell values shown; for our purposes, we simply change the background color and make the cell border invisible by having it appear in the same color Figure 1 shows a spreadsheet based representation of a map of the U.S. The map on the left is filled with random integers \(using the equation INT\(RAND\(\*12\+2 between 2 and 13, and the cells representing border of the region contain a value of 1. The cells are sized to a height and width of 8 pixels, and the format applied makes a cell blue if it contains a 1, yellow if its value is in the range from 4 to 8, red if its value is in the range from 9 to 12, and white otherwise \(i.e., if its value is 2 or 3\ the GIS world, the standard approach is to store different elements of geographical information in layers example layers might be elevations, town borders roads, and population.  Again, there is a natural analogy between raster layers and spreadsheet worksheets In Microsoft Excel 2003, each worksheet has 256 columns and conditional formatting \(used for the models in this paper\ limited to three possible different conditions per cell, which although acceptable for the examples in this paper is inadequate for professional quality graphics. Excel 2007 allows 16,384 columns and 1,048,576 rows and up to 256 conditions, each which can be used for setting colors Thus, it provides resolution allowing for professional applications. Other popular spreadsheets range from the current Google Spreadsheets and Open Office which have size and condition limitations like those of Excel 2003, to Quattro Pro and Lotus 1-2-3 which are more powerful Another basic mapping function is known in the GIS world as map algebra, and again there is a natural analogy with spreadsheet cell functions.  Spreadsheet cell formulas provide considerable flexibility in defining new map layers.  With a few keystrokes users can create a new worksheet \(layer\with formulas involving values from cells of other worksheets layers\.  Using formulas such as AVERAGE or SUM allows map smoothing and aggregation.  For example in Figure 1 in the screen on the right, we applied a map layer that smoothes out the pattern in the first sheet by summing values over small regions. Cell AE9 on Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 3 


Sheet2 contains the formula SUM\(Sheet1!AD8:AF10 and this cell was copied to all cells up to EC 150. The conditional formatting applied makes the cell green if its value is less than 50 orange if its value is between 50 and 75 and red if its value is above 75 Additionally, IF statements can be used for filtering map layers.  For example, if Sheet1 contains buildings and Sheet2 contains roads, we can calculate the places available for building \(not on top of buildings or roads\ Sheet3 with the formula IF\(Sheet1!a1=0,IF\(Sheet2!a1=0,1,0 Thus the combination of using spreadsheet cells as pixels, conditional formatting to modify cell appearance, worksheets as data layers, and cell formulas as map algebra already gives considerable GIS functionality to spreadsheet models.  Cole [12  used some similar ideas for using spreadsheets to produce maps, and invoked the metaphor of spreadsheet mapping as word processing in colors  It is important to note that due to the large size of typical GIS raster displays, efficient calculation strategies within the spreadsheet become increasingly important.  Depending on the size of the spreadsheet and the parameters of the hardware on which it is running, some of the approaches described here could lead to slow calculations. The main factor driving calculation speed is the large number formulas that must be computed for each cell. Simple formulas, such as the conditional formatting take only a few seconds for a large area. Complex formulas, as would be used in layers of maps, will take longer. To facilitate efficient calculation it is possible to keep an equation in one cell and use Excel s copy-paste-values command to freeze the remaining values when they are not in use. This also reduces memory requirements Another way to speed calculation is to shift the spreadsheet to manual calculation mode, and calculate one sheet at a time.  Of course, smaller raster displays will use less memory and compute faster; if a grid of 100x100 suffices for a particular application the smaller/coarser representation should be used  4.2  Incorporating Existing GIS Data Sets into GIS Spreadsheets  In this internet age, there is a wealth of existing and publicly available GIS data out there.  Merely brushing the surface, government agencies such as the U.S. Geological Survey \(USGS\d the Canadian Geospatial Data Infrastructure \(CGDI\ave extensive sets of geographic information and analyses of their own countries and the world.  There are also major GIS open source and user groups \(such as GRASS\, and GIS companies \(such as ESRI\which create and make available extensive libraries of GIS data.   With a search engine and an internet connection, there s a good chance the geographic information needed for pretty much any application is available.  The issue however, is how to get it into a spreadsheet The technique we develop in this paper, which is only one of several that could be used, is based on the fact that bitmap images are made of pixels.  Thus any map display can be imported, pixel by pixel into a spreadsheet simply by picking up the color of the pixel as a cell value.  Alternatively, raster data from an existing GIS could be converted directly into a database file that could be imported into the spreadsheet. Source maps can then, through either mechanism, be reproduced within a worksheet. We used a small piece of VBA code \(available on request for this process, linking to a user-specified bitmap file bmp\d reproducing the map within a worksheet For the examples later in this paper, this VBA subroutine was used to import our campus map \(from our campus website\d a population density map of the eastern portion of Massachusetts \(from the U.S Census website This bitmap conversion procedure has limitations however.  The first, as mentioned before as an issue with spreadsheet based GIS, is dimensionality This method can also make building layers a bit difficult, as the pixel reading process just takes what it sees, and so for example doesn t differentiate between a pixel containing a population density value from a pixel that s black indicating a road \(which we d prefer on a different layer\lso, the pixel by pixel method can make it hard to align data layers \(e.g. from different sources\wever this alignment issue can be circumvented in some cases.  For example the census site allows a user to set up a particular map and then display various values on it \(population density of different races, income data\which, if brought in with this method, would already be aligned A deeper issue is that as well as raster based displays, GIS data often comes as vector data which defines objects using various coordinate schemes.  The population density in the census data set is, in fact vector based data.  Population in the census is not counted per square mile \(which would be a raster representation\ but by irregularly-shaped census blocks a vector representation\.  The population density map is then a rasterized display of vector data, and is then only an approximation.  In general though, since vector data sets all refer back to some kind of grid-based coordinate system, converting vector based data sets to raster displays should be possible There are numerous existing standard GIS data formats \(e.g. a specific protocol or procedure used to store and manage data \(Gardels T h es e data  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 4 


formats include ESRI shapefiles, ArcInfo coverages MapInfo files, GeoTiff, GRASS run-length encoding for rasters, various digital elevation formats \(DEMS SDTS, etc\d various GRID and image formats Some of these are binary raster formats in which data items accompany the image data, which can solve some of the alignment issues noted above.  Although beyond the scope of this paper, it would certainly be quite possible to develop VBA macros to import data from common schemes for raster and even vector based geographic data  4.3 Additional Spreadsheet Based GIS Functionality  Within the raster display, regions \(sets of cells can be created, named, and referred to in formulas. The region is selected by holding the control key while dragging the mouse over cells or clicking on cells, and when the region is selected, the user chooses Insert Name -- Define from Excel s menu. Rectangular regions can be defined by dragging the mouse, and can include border lines, and are named the same way. This feature could be useful for customizing maps for example, it would be possible to select a region \(using the go to command\d then assign a different conditional formatting scheme to that region. It is also possible to convert parametrically defined shapes into raster representations, for example, after defining a rectangular area in terms of its upper left corner xorigin, yorigin\th and width, we could populate the cells within the rectangle with 1 s by using the formula IF\(AND\(row\(\y,row\(\y+length,column\(\,co lumn\(\+width We could define other shapes similarly, e.g circles. Regions could also be the basis for an implementation of vector based data.  Assuming the boundary issues can be worked out, for example, a data layer could be produced which gives the town, or census block, or other vector based identification of each pixel.   Such a data layer would then allow considerations of topology, namely determining relationships of how different vectors are contiguous or connected, since adjacent vector blocks could be determined by looking for a difference in value between adjacent cells.  Another idea is that shapes stored as vector data could be converted to a pixel representation using a map layer that uses algebraic formulas to define vector objects. For example, a circle is defined by a center and a radius, and the formula identifies a point as being in the circle if its distance from the center is less than or equal to the radius.  In addition Excel drawing objects have associated parameters that may be manipulated and converted to parameters for generating pixel shapes using VBA Objects themselves may be stretched or moved by hand or using VBA, although it would be inelegant Another common GIS function, transformations between coordinate systems and projections by rotating and stretching map regions is also straightforward to implement in a spreadsheet. The row and column numbers are treated as Cartesian coordinates. To transform the coordinates, we select the appropriate cells in a source worksheet using the offset function Rotation is achieved using sine and cosine of coordinates rounded to the n earest integer to generate the new coordinates. Figure 2 illustrates this concept In figure 2 a segment of the filter sheet described above has been rotated by 70 degrees and transformed using this technique.  Here, we filled the cells in the top row of a sheet with the numbers 1, 2, 3 and also filled the first column of the sheet with the numbers 1 2, 3 Then in the cell B2, we entered the formula OFFSET\(Filter!A1,xfactor*B$1,yfactor*$A2\, where xfactor is the sine of the angle and yfactor is the cosine of the angle                     4.4 Spreadsheet GIS for Communication Support  For GIS to be used effectively within organizations, particularly corporations, there needs to be easy interactions between GIS experts and other departments.  We believe that spreadsheet based GIS systems, even just as think pieces or prototypes, are exactly the solution to the organizational challenge of maximizing the sharing and use of GIS data and information throughout an agency. Historically, GIS Cell B2: =OFFSET Filter!B2,Cos\(Rotation\*Zoom_Ratio*Column_Index Sin\(Rotation\*Zoom_Ratio*Row_Index  Figure 2.  Rotation using sine and cosine functions Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 5 


has been separated from the rest of the organization because of its complexity and its special technology needs \(large workstations, plotters, etc.\ have described GIS as a back-office technology \(e.g Cas m u r f it [16 We pro pos e th at s p reads h eet  based GIS may provide exactly the means to bring GIS to OR/MS analysts, financial analysts, data mining experts, project managers, and even the corner office The language of spreadsheets facilitates crossfunctional communication and sharing of expertise Broader acceptance could then increase overall understanding of the benefits available from analyzing spatial data There are a number of spreadsheet functions that should support GIS integration and communication For example  Exporting graphics: a screen can be converted to a bitmap image using the Control-Shift-PrintScreen keys to copy the screen image and then paste it into Powerpoint, Paint, or other compatible graphics programs \(including Microsoft Word as was used in this paper Web-publishing: spreadsheets may be saved as web pages that can be viewed using Microsoft Internet Explorer. When the spreadsheet is saved the user can specify the level of access \(values formulas, modifiable formulas\vailable to viewers. Similarly, it is easy to embed web links within a spreadsheet Use of real time data: Excel supports live web queries, and in Office XP, also provides rich support for the use of real-time data on the worldwide web. Earlier versions of Excel connect to real-time financial data. One illustrative possibility would be applying real-time regional weather information to a map stored within the spreadsheet, by incorporating weather parameters in the cell formulas  Collaboration: Excel has reasonable functionality supporting sharing and distributing of workbooks These allow multiple users to access and modify the same sheet. The versioning support is built in as are personalized views, annotation and access rights. Security features such as protection and hiding of sheets are also available. Auditing tools help individual or multiple users trace a model s logic, which can aid in debugging Security functions: within a spreadsheet individual cells, ranges or worksheets can be protected.  This could be useful if certain data is not to be modified by some operation \(e.g., only edges are affected\ well as for public data and collaboration \(if different people are allowed to modify different data or scenarios\imilarly specified cells, ranges, columns, and rows or whole worksheets can be hidden \(and locked Notes attached to cells may also be hidden along with the indicator showing the presence of a note which could be useful for private annotation of sensitive information  5. Applications What   This section provides two examples of how spreadsheets can be used to integrate analytical calculations and GIS data. Each of these short examples demonstrates techniques discussed above Both are based on importing a raster image into Excel and then applying various worksheets as layers onto that imported image. Both use combinations of Excel functions such as ROW, COLUMN, and INDIRECT to access and manipulate data from that image.  Other than the VBA subroutine which imports the image neither example is dependent upon any additional macros  5.1 Parking Lot Analysis  The first example presents a GIS based spreadsheet designed to facilitate easy data input and analysis.  This example was motivated by an issue faced by many organizations, namely how to cope with demands for parking. In our university, the primary parking facility was a 1,500 space parking garage which was found to be structurally unsound and therefore closed, putting a tremendous premium on parking on our campus. Our parking squeeze, while exacerbated by a unique situation, is not especially unique among colleges and universities. This example presents a rapid prototype of a tool to assist facilities and similar managers to size and place new parking facilities.  Figure 3 \(left\ shows the raster data  Figure 3. Bitmap campus map \(left\sweet spot" analysis \(right  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 


representing a map of the campus that was imported into a worksheet. Although the 256 pixel width limitation renders the names buildings difficult to read the overall map and building locations are clear. On a separate worksheet \(Table 1\ the user enters a value for the size of a parking space \(usually a value larger than the square feet covered by a parked car to allow for lot circulation\, the cell size \(based on the scale of the map\d a location for the campus center The user then interacts live with the map by constructing shapes directly on the worksheet representing existing and proposed parking facilities, either by directly shading parking areas to a specified color, or by inserting a predefined value which conditional formatting then uses to set the background shade of cells to that same color  Showing the advantage of using a spreadsheet instead of a paper map and a pencil\seful characteristics of a given parking configuration are then easily and dynamically calculated and displayed Our example interactively calculates and displays total parking coverage, expected parking spots, and average distance to the center of campus for any given configuration of parking areas.  We envision this application enabling charrette type sessions, where groups of people participate in a meeting where various alternative parking schemes are discussed and refined Technically, each of the shaded cells \(pixels represents a specific square footage for parking based on the scale of the imported bitmap, and therefore a portion of a single parking space. A second worksheet uses the map scale to calculate the distance from each cell to the cell represented the center of campus, and a third worksheet has a formula for each cell which produces a 0 if the cell is not part of parking space, or 1 if it is. The average distance to the center of campus is therefore proportional to the average value of product of the cells in the second and third worksheets The total number of parking spaces, total parking square feet, and parking lot coverage is based on the sum of the cells in the third worksheet To demonstrate how this prototype could be easily extended, we introduced some additional factors into this example. Instead of calculating a single average distance to the center of campus, we calculated the distance to each building on campus. To accomplish this task, an additional overlay worksheet for each building was created. We then added parameters which were estimates of the percentage of traffic going to each building These parameters were used to calculate a value function for a proposed configuration of parking spaces, instead of an average distance to a single point This value function, whose calculations were stored in another overlay worksheet, presumed the value of each parking space to be inversely proportional to the weighted distances from destination buildings, and was of the form V i p i d i   where V is the value of a parking space p i is the proportion of traffic going to building i d i is the distance from the parking space to building i, and  is a weighting exponent for distance The value for  was entered as a parameter and for the example we used a value of 2 The addition of this value function enabled us to use conditional formatting to produce a contour map of the potential parking value of each location on campus We could then compare the original imported bitmap of the campus map with the plot of the value of having parking in each location. We termed this the sweet spot analysis, and a sample is shown as Figure 3 right Finally we added a cost function intended to offset the value function, again represented in an overlay worksheet. This cost function was a straightforward calculation based on parameters for cost per square foot of parking spaces, the number of square feet in a parking space and pixel, and the total number of parking spaces for a given configuration.  \(Table 1  4.3  Retail Store Location  This second example was motivated by the problem of determining retail store locations, which one of the authors has previously confronted for  Parameters Square feet per parking space 325 Square feet per pixel 30 Weighted distance esponent 20 Cost per sq foot of parking 1.50 Buildin g Location Wei g ht Quinn Hall CS 122 5 Healey Library BU 167 10 McCormack Hall BF 208 20 Wheatley Hall BD 277 20 Science Building CN224 10 Clark Gym ER 119 5 Student Center DH 295 30 100 Outputs Total parking spaces on campus 1,389  Percentage parking of total area 12 Weighted average value 17,570  Total configuration cost 14,069 Table 1: Parking Analysis Parameters and Outputs Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 


several retail chains. The scenario represented in this example is that of a big box retailer seeking to locate two stores in the Boston area where we postulated a competitor had already located one store Huff s model i n e d e s t i m a t i o n s o f t r adi ng areas based on distances to stores and completeness of merchandise selection, and many variations of his model have been used over the years for many retail site selection analyses. \(For example, see Stanley and Sewa d Ga u t s c h i 1 9 com m o n to t h es e  models is a determination of retail potential as an inverse function of distance, with an underlying assumption that the attraction of a retail store diminishes with distance. In our example, we used a logit-demand model which estimated the proportion of potential customers who will consider shopping at a retail store to be related to distance from that store as p i 1 / \(1 + d i   and the total proportion of potential customers shopping at the store as x i p i  J p j  where p i is the probability a customer will shop at retail store i d i is the distance to retail store i  is an empirically determined constant. There have been previous attempts to estimate this constant; for our example, we chose a value for   of 1.5, and J is the set of store locations Using this model, a share is calculated for each retail store, including competitive stores, and for a presumed store at a fixed distance from all customers The distance of the presumed store is set at a figure somewhat beyond the expected trading areas of an actual store and its demand represents customers who find all of the stores too far away, and either turn to other channels such as mail-order, or constitute unfulfilled demand In order to apply this model, we needed to have population data. The most suitable population data we could find was from the U.S. Census Bureau [20   which was for population counts by 5-digit zip code for the year 2000. We downloaded a graphic of this for the Boston area and imported it into our spreadsheet; the result is shown as Figure 4. At the time this graphic was imported, a population density value was attached to each cell based on the image s legend. This was somewhat of a manual effort, and an example of a difficulty that could be overcome through use of the binary raster format. Unfortunately, we could find no readily accessible graphics for population in this format The overlay sheets for the store analysis included one for each retail store which contained a calculation of the distance from each point on the imported map to that store, and one for the competitor s store location Another overlay sheet represented the probabilities of customers shopping at each store location \(including the competitor s\ and one was used to determine the proportion of market share that would accrue to the two stores in the configuration. The sum of the portion of market share for the two stores, from the last overlay sheet, was taken as an estimate of total sales. The input parameters and sample output of the potential sales estimate are displayed in Table 2   Figure 4 Population Density \(left\ales Potential \(right  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 


Parameters Location of store 1 FS113 Location of store 2 EE204 Location of competitor DJ136 Pixels per mile 3 Distance parameter \(miles 35 Market size \(per capita 90 Outputs Estimated total potential sales 1,552,820  Working with these parameters, the user could locate stores in any cells and determine an estimate of total sales. This interactive nature can be highly effective in practice, as often the user wishes to include considerations that are not likely to be part of a model but still wishes to see the impact of various location scenarios on the model s output.  Using conditional formatting, the sales estimate was displayed on an overlay sheet that could be compared to the original imported raster image. Figure 4 on the right shows sample results, in which the candidate store locations were north and south of the center, and the competitor s location was west of the center. This figure shows the trading areas around each of the candidate locations, and demonstrates how the strength of those trading areas diminishes with distance, and also with proximity to the competitor s outlet located to the left of center in the map Reasonable extensions to this example would have been to use Solver iteratively find the store locations with global maximum projected sales, write a VBA macro to find the best locations through exhaustive enumeration, or implement a different technique for finding the best set of locations such as a genetic algorithm  6. Implementation Details  As we were working through these examples, we of course encountered both interesting opportunities and some interesting challenges There were occasional areas where limitations of the spreadsheet implementation we were using \(Excel 2003\limited the GIS functionality we were able to implement.  For example, the limitation on worksheet size in Excel 2003, restricted the size of the maps we were able to handle.  We suggested doing the maps in strips with different strips in different worksheets however that seemed a clumsy solution at best.  More vexingly, the limitation of only three conditions in conditional formatting \(limitin g us to four map colors seriously limited our options for our maps.  Happily Excel 2007 expands both maximum worksheet size and conditional formatting conditio ns, thus by a software upgrade greatly enhancing our GIS abilities Translating bitmap pictures into raster maps \(using a small amount of VBA-code\wed us import and then manipulate pretty much any map-like object for which we could find a picture. Unfortunately, although this bit-by-bit technique captures each pixel, it doesn t give any information \(other than the color\t the bits.  In the Boston map, for example, we had no way of telling if any particular bit was representing the town Framingham or Newton.  Traditional geo-coded raster data that would address that concern, and such data could also easily be imported into a spreadsheet with a slightly different macro of VBA-code In summary, the authors are all experienced spreadsheet modelers.  We didn t find any particular new spreadsheet functionality we hadn t known; we just combined techniques in new ways.  Spreadsheets are touted for their flexibility, and indeed we found that in general pretty much any technical problem could be overcome \(either in the spreadsheet or with visual basic programming if necessary\if one has sufficient determination and is willing to experiment  7. Conclusion and Discussion  We are certainly not claiming that spreadsheet based GIS implementations are going to replace the entire industry \(proprietary and open-source\at currently exists for GIS technology.  The relatively slow calculation rate for applications involving large number of cells, and the issue of forcing a general purpose tool \(spreadsheets\ery specific purpose \(GIS\ill make spreadsheet based GIS systems useful only in certain circumstances However, to the non-GIS expert, existing GIS technology is complex and daunting.  Interacting with GIS systems implemented within spreadsheets avoids the need to utilize a potentially complex and expensive formal GIS application, and opens up GIS functionality quickly and intuitively to the millions of business and other spreadsheet users across the globe Democratizing GIS in this way allows spreadsheetcapable professionals to better utilize GIS as end-users and as developers, creating the potential for wider intra- and inter-organizational collaboration on GIS We also note the potential of this integrated application for classroom purposes; in our experience these visual displays are engaging and accessible to students and really help them grasp the importance of the underlying models In this paper, we ve shown the straightforward and natural analogy between several GIS functions with Table 1. Location analysis parameters and out p uts Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 


spreadsheet functions, particularly for raster based data.  We ve discussed ways in which this GIS functionality can be implemented within the spreadsheet environment.  The examples we ve produced show the useful synergy that comes from meshing OR/MS methods with GIS methods --- an integration which is greatly enhanced by the remarkable development platform provided by spreadsheets Future work will focus on meshing advanced techniques with GIS data.  We ve mentioned the possibility of using optimization techniques for the store location problem.  Another intriguing possibility is to use the random number generation functions in Excel to set up geographically based stochastic simulations Perhaps the most promising aspect of the use of Excel for geographical analysis is its modeling capabilities, particularly dynamic and stochastic modeling. We see applications for time series modeling and for scenario analysis in the use of Excel in conjunction with data that has been processed in a traditional GIS environment. The opportunity for a larger population of modelers to develop shared spreadsheet-based geographic decision support tools is wide open. We hope this dynamic will draw more people to think of GIS and quantitative analysis together  8. References  1 Sohovich, Martin.  2002. Business and IT Ramifications of Geocoding in Customer Data Integration. Directions Magazine. URL www.directionsmag.com/article.asp?ArticleID=174   o n g l e y P., C l ark e G., ed s  1995 GIS f o r Business and Service Planning. John Wiley & Sons New York 3] O Sullivan, Gerald Satellite Imagery and Human Rights Working paper. American University School of Communications  a llo, D. 200 2. ESRI Corporation  Em ail Correspondence. March 4  orl d 20 04 www.geoplace.com/gw/1996/0496/0496feat2.asp    Geolog ical S e rv ice, Geog raph ic Inf or m atio n  Systems \(GIS\oster erg.usgs.gov/isb/pubs/gis_poster   o C h or Pan g an d Albert K.W. Yeu n g  2006 Concepts and Techniques of Geographic Information Systems, 2nd Edition.  Prentice Hall, Englewood, N.J  o n g l e y Pau l  A  a n d Mic h ael F  Goodch ild, Dav i d J. Maquire, and David W. Rhind.  2005. Geographic Information Systems and Science. John Wiley & Sons New York  term a n  R i c h ard E., R i ch ard K. Brail an d Eric G. Bossard.  \(eds.\93.  Spreadsheet Models for Urban and Regional Analysis.  Center for Urban Policy Research, Rutgers University, New Brunswick, NJ 10 Ra ub a l  M a r t i n  G a up m a nn B e r n ha r d a n d K u hn  Warner. 1997. Teaching Raster GIS Operations with Spreadsheets. Journal of Geography. 96, 5  ls ch laeg er, C h arles T h e GR A S S  Mat h e m a tica Link: Developing Hydrological Models in Geographic Information Systems Interfaced with Algebra Systems Champaign, Illinois: U.S. Army Construction Engineering Research Lab  o le, S   199 8.  Of m a ps  an d m acros obj ectoriented spreadsheet GIS.  Environment and Planning B: Planning and Design.  Vol. 25, pp. 227-243  ler Jef f r e y M. a n d S u n d ell R o n a ld C  1997 Combining Multi-Attribute Utility and Geographic Information for Boundary Decisions: An Application to Park Planning Journal of Geographic Information and Decision Analysis, Vol 1.2, pp. 101- 118  d els Ken  T h e Open GIS A pproach to Distributed Geodata and Geoprocessing URL www.regis.berkeley.edu/gardels/envmodle.htm   a s tle, Gil. 2002 A Ga m e of In f o r m a tion  Arbitrage. Directons Magazine. URL www.directionsmag.com/article.asp?ArticleID=142   m u r f it, Mic h ael. 1995 Us ing a GIS as a D S S  Generator. Working paper. Department of Management Information Systems, Graduate School of Business, University College, Dublin  f f  D. 1964. Def i n i ng a n d Es ti m a ti n g a T r adin g  Area. Journal of Marketing, Vol. 28 No. 3, pp. 34-38  t an le y  T  an d S e w a ll M. 197 6. Im ag e I n pu t s to a Probabilistic Model: Predicting Retail Potential Journal of Marketing, Vol. 40, No. 3, pp. 48-53  t s c h i D. 1981. S p ecif i cation of Patron ag e Models for Retail Center Choice, Journal of Marketing Research, Vol. 18 No. 2, pp. 162-174   C e n s us Bu reau 2006. Am erica n F act Fin d er Thematic Maps.  URL factfinder.census.gov/servlet/DatasetMainPageServlet _program=DEC&_submenuId=&_lang=en&_ts   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


Figure 15  ISM Data Flow serializer highlighted in yellow the design to ensure the clock-to-outputs of the individual serial signals were all matched indicating that at least on chip the design had no skew Finally we used a test bed layout with HyperLynx to prove that our part to part latencies were within acceptable ranges given the high design speed FPGA Design Rate The FPGA design used to verify the design speed was a relatively simple 8-bit latch and shift register shown in Figure 14 Figure 14 shows that the base clock is twice as fast as the output clock which is meant to simulate a recovered clock This is not necessarily a design requirement but would be necessary if the telemetry clock were an input to the design as was the case on the WISE mission This implies that the maximum frequency given by the timing tool for the design is twice the output clock Figure 14 shows only an 8-bit shift register but naturally depending on how the memory was organized more might be required The more bits used in the shift register the more internal clock skew slows the design If a wider bus were required it would be better to increase the depth of the input registers to maintain a high-speed design as opposed to increasing the number of output shift registers The results of this test were a maximum device clock speed of 336.7 MHz double data rate and a maximum output clock speed of 168.35 MHz in the Actel RTAX2000S as given by Actel Timing Designer This meets our requirement of 150 MHz on the clock signal with a margin of 12 FPGA Design Skew Using this same prototype design and mapping the outputs to physical pins we ensured the pin-to-pin skew was matched This skew is the amount of time it takes the edge to propagate from the internal logic to the physical pin on the part The results were as follows Path 1 gse clk:CLK to GSE CLK P Clock to Out ns 7.014 Path 2 gse clk:CLK to GSE CLK N Clock to Out ns 7.014 Path 3 gse data:CLK to GSE DATA P Clock to Out ns 7.014 Path 4 gse data:CLK to GSE DATA N Clock to Out ns 7.014 The clock-to-output skews are all matched indicating the clock and data signals leave the part simultaneously and no delay is caused by mismatched skew Board Latency Simulation After a preliminary board layout was completed board simulations were performed on the signals from the FPGA to the LVDS repeater and ultimately to the front panel as shown in Figure 16 All of these simulations were performed in HyperLynx Boardsim 8.0 with manufacturer-provided IBIS models for the Integrated Circuits ICs The waveform given in Figure 17 is captured at the FPGA Figure 16  ISM Data Flow buffer highlighted in yellow Figure 17  FPGA LVDS output waveform simulations green/red  single-ended clock at FPGA blue  differential clock at destination The HyperLynx simulation was performed using a signal switching speed of 180 MHz to ensure adequate margin for the desired signal frequencies The rise times given in Table 9 are roughly one-tenth the simulated signal period 5.5 ns at 180 Mhz indicating they will not impede the switching frequency by slowing the time to the threshold voltage at the receiver The simulated scope shots for these signals indicate crisp edges and transitions The receiving part is an LVDS bus repeater meant to protect the radiation-hardened FPGA from any front-panel transients that might inadvertently occur during testing At the input to the repeater the simulated signal waveform is given in Figure 18 The transition regions for LVDS are shown as blue lines in Figure 18 While there is a considerable amount of overshoot 11 


Figure 18  LVDS signals at buffer input difference shown and re\003ections on the signal line from the repeater the transition region of the signal is very clean even simulated at 180 MHz This will easily meet our 150 MHz frequency requirement Signal characteristics are tabulated in Table 9 Signal Rise Time ps Fall Time ps Undershoot mV Overshoot mV Margin mV CLK 729.0 698.4 212 250 288 CLK903.1 685.4 256 150 244 DATA 738.9 702.8 216 250 284 DATA876.4 717.8 256 150 244 Table 9  FPGA LVDS output signal characteristics In addition to signal characteristics and waveforms the signal-to-signal skew was measured at the buffer input Obviously these values should be as small as possible to prevent modifying the board Like most differential signaling modes LVDS requires matched impedance signal pairs to function optimally HyperLynx was used to 002ne tune the termination on each differential pair and to match all of the trace impedances to this termination The skew was minimal Table 10 First LVDS Signal Second LVDS Signal Receiving Rise Skew ps Receiving Fall Skew ps CLK DATA 58.32 50.54 Table 10  LVDS rising and falling skew measured at receiver The Receiving Rise and Fall skews are the values for skew between the two signals as each signal passes the LVDS threshold voltage measured at the FPGA The time difference between these two crossings is the number shown in Table 10 Rise skew is measured on the rising edge and fall skew is measured on the falling edge as illustrated in Figure 19 Figure 19  LVDS receiver slew measurement Given that these skews were measured at 180 MHz skew between signals at 150 MHz will not inhibit data transfer by allowing the clock and data lines to get out of sync 6 C ONCLUSIONS It is clear that there are many places where timing is of great concern in the ISM data 003ow The initial data input is driven by the instrument interface timing the bandwidth of the FPGA FIFO buffers the speed of the formatter FPGA and the bandwidth of write accesses to the 003ash-memory The transmitter side of the data 003ow is dependent on the bandwidth of the read accesses to the 003ash-memory the FPGA FIFO buffer bandwidth the FPGA serializer frequency and the physical signal characteristics of the FPGA to the frontpanel interface A table summarizing all of these bandwidths in the order they occur in the data 003ow is presented in Table 11 Data Flow Block Bandwidth Units INSTRUMENT INPUT FPGA FIFO Buffer Rd BW 1080 Mbps Formatter FPGA Bandwidth 328 Mbps Flash-memory Write Bandwidth 104 Mbps TRANSMITTER OUTPUT Flash-memory Read Bandwidth 866 Mbps FPGA FIFO Buffer Rd BW 1080 Mbps FPGA Serializer Bandwidth 168 Mbps Table 11  Bandwidth summary In order to support our study signal integrity analysis was performed on the portions of the data 003ow affected by physical delays including into and out of the 003ash-memory and from the FPGA to the front panel These physical interfaces are robust enough to support high data throughput rates The ISM is capable of interfacing to an instrument with up to 104 Mbps of continuous data throughput and is capable of 12 


sourcing data to a transmitter at a bandwidth up to 168 Mbps This allows data to be stored to the ISM during the orbital encounter period and downlinked periodically as communications are available R EFERENCES  223R T AX-S/SL RadT olerant FPGAs 224 Actel Corporation Mountain View CA 2008 A v ailable http://www.actel.com/products/milaero/rtaxs/docs.aspx  223Prototyping R T AX-S Using Axcelerator Devices,\224 2003 A v ailable http://www.actel.com/techdocs/appnotes/rtaxs.aspx  223K9XXG08XXM Datasheet 2G x 8 Bit  4G x 8 Bit  8G x 8 Bit NAND Flash Memory,\224 Samsung Electronics 2007  223UT54A CS164245S/SE Schmitt CMOS 16-bit Bidirectional MultiPurpose Transceiver Datasheet,\224 Aero\003ex Corporation Colorado Springs CO 2009 Available http://aero\003ex.com/ams/pagesproduct/prodshirel-16bitlogic.cfm B IOGRAPHY  John Dickinson is a Research Engineer at Southwest Research Institute Having studied Electrical Engineering at Johns Hopkins University with a focus on control systems and signals he began work at SwRI in the Avionics Systems Group of the Space Science and Engineering Division He was the lead Ground Support Equipment GSE Test Engineer for the WISE and Kepler Mission Unique Boards MUB for which he compiled and integrated the GSE hardware developed the test scripts and wrote and veri\002ed the GSE code He is the Lead Engineer for the JUNO JADE Instrument Processor Board a lowpower RAD-HARD 3U Compact PCI single-board computer that utilizes the Atmel LEON2 SPARC v8 processor and provides direct instrument and spacecraft serial interfaces He has supported integration systems engineering and promotional efforts on a variety of programs and is currently pursuing a Master's Degree in Electrical and Computer Engineering from Georgia Institute of Technology Charlie Howard  a Principal Engineer in the Department of Space Systems at Southwest Research Institute excels as system architect and digital designer with particular expertise in FPGA and ASIC design Mr Howard has 002lled an active role in the hardware/software architecture for the MMS Mass Memory Module MMM and is the designer of the Mass Memory Controller FPGA Mr Howard is the architect and designer of WISE Mission Unique Board MUB the Kepler Command and Telemetry Board CTB and the Orbital Express CTB and provided multiple FPGA designs for OE Kepler WISE and MMS As Kepler CTB lead he incorporated new simulation capabilities allowing the customer to verify advanced features of the Kepler CTB prior to delivery As an ASIC and FPGA designer Mr Howard 002lled roles in RTL design functional and gate level veri\002cation for high reliability systems including space telecom and defense applications His other interests are worst-case timing and signal integrity analyses Steven Torno is an Electrical Engineer at Southwest Research Institute He studied Electrical Engineering at the Rose-Hulman Institute for Technology with a focus on digital signal processing and he began work at SwRI in the Avionics Systems Group of the Space Science and Engineering Division in 2009 He was the Ground Support Equipment GSE Test Engineer for a Control and Telemetry Board CTB demo in partnership with ATK Space Systems where he integrated existing GSE hardware with custom test software he wrote and veri\002ed He is currently an Electrical Engineer for the Robotic Lander Test Bed project working on the Low Voltage Power Supply LVPS board He is currently pursuing a Master's Degree in Electrical and Computer Engineering from the University of Texas at San Antonio 13 


John Wiley 10. McKnight, H.D. and N.L. Chervany. What is Trust? A Conceptual Analysis and an Inderdisciplinary Model. in Americas Conference on Information Systems \(AMCIS Beach California 11. Zand, D.E., The leadership Triad - Knowledge Trust, and Power. 1997: Oxford University Press 12. Shaw, R.B., Trust in the Balance. Building Successful Organizations on Results, Integrity and Concern. 1997, San Francisco: Jossey-Bass 13. McAllister, D.J., Affect and cognition-based trust as foundations for interpersonal cooperation in organizations. Academy of Management Journal 1995. 38\(1 14. Levin, D.Z., R. Cross, and L.C. Abrams, Trust and knowledge sharing: a critical combination 2002, IBM Institute for Knowledge-Based Organizations 15. Levin, D.Z., R. Cross, and L.C. Abrams, Why should I trust you? 2002 16. Cook, J. and T. Wall, New work attitude measures of trust, organizational commitment and personal need non-fulfillment. Journal of Occupational Psychology, 1980. 53: p. 39-52 17. De Furia, G.L., A Behavioral Model of Interpersonal Trust. 1996, St. John's University Springfield, LA 18. De Furia, G.L., Facilitator's guide to the interpersonal trust surveys. 1997: Pfeiffer &amp; Co 19. Bakker, M., et al., Is trust really social capital Knowledge sharing in product development projects. The Learning Organization, 2006 13\(6 20. Binney, D., The knowledge management spectrum - understanding the KM landscape Journal of Knowledge Management, 2001. 5\(1 p. 33-42 21. Hansen, M.T., N. Nohria, and T. Tierney, What's your strategy for managing knowledge? Harvard Business Review, 1999. 77\(2 22. Dennis, A.R. and I. Vessey, Three knowledge management strategies: knowledge hierarchies knowledge markets, and knowledge communities MIS Quaterly Executive, 2005. 4\(4 23. Swan, J., et al., Knowledge Management and innovation:networks and networking. Journal of Knowledge Management, 1999. 3\(4 24. Denning, S. What is knowledge management 1998  [cited; Available from http://www.worldbank.org/ks/index.html  or 25. Know-Net. The approach. [Web site] 2000 cited; Available from: http://www.know-net.org 26. Natarajan, G. and S. Shekhar, Knowledge management: Enabling Business growth. 2000 New Delhi: Tata McGraw-Hill 27. Zack, M.H. and S. Michael. Knowledge Management and Collaboration Technologies 1998  [cited; Available from http://www.lotus.com/services/institute.nsf/55013 7bfe37d25a18525653a005e8462/000021ca 28. Wick, C., Knowledge management and leadership opportunities for technical communicators. Technical Communications 2000. 47\(4 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 29. Ribi  re, V., Assessing Knowledge Management Initiative Successes as a Function of Organizational Culture, in Engineering Management and Systems Engineering Department. 2001, The George Washington 


Department. 2001, The George Washington University: Washington DC. p. 158 30. Jennex, M.E. and L. Olfman. Assessing Knowledge Management Success/Effectiveness Models. in 37th Hawaii International Conference on System Sciences. 2004: IEEE 31. Delone, W.H. and E.R. McLean, Information Systems Success: The Quest for the Dependent Variable. Information Systems Research, 1992 3: p. 60-95 32. Bots, P.W.G. and h. Bruiin. Effective Knowledge Management in Professional Organizations Going by the rules. in 35th Hawaii International Conference on System Sciences. 2002: IEEE Computer Society Press 33. Massey, A.P., M.-W. M.M., and T.M. O'Driscoll Knowledge Management in Pursuit of Performance: Insights from Nortel Networks MIS Quaterly, 2002. 26\(3 34. Lindsey, K. Measuring Knowledge Management Effectiveness: A Task-Contingent Organizational Capabilities Perspective. in Eighth Americas Conference on Information Systems. 2002 35. Jennex, M.E. and L. Olfman. A Knowledge Management Success Model: An Extension of DeLone and McLean's IS Success Model. in Ninth Americas Conference on Information Systems. 2003 36. Davenport, T., D.W. De Long, and B.M. C Successful Knowledge Management Projects Sloan Management Review, 1998. 39\(2 57 37. KPMG Consulting, Knowledge Management Research Report. 2000 38. Nelson, K.M. and J.G. Cooprider, The Contribution of Shared Knowledge to IS Group Performance. MIS Quaterly, 1996. 20\(4 432 39. Politis, J.D., The connection between trust and knowledge management: what are its implications for team performance. Journal of Knowledge Management, 2003. 7\(5 40. Teoh, K.K. and M. Avvari, Integration of TAM Based Electronic Commerce Models for Trust Journal of American Academy of Business, 2004 5\(1/2 41. Davis, F.D., Perceived Usefulness, Perceived Ease Of Use, And User Acceptance of Information Technology. MIS Quaterly, 1989 13\(3 42. McKnight, D.H., V. Choudhury, and C. Kacmar Developing and Validating Trust Measures for eCommerce: An Integrative Typology. Information Systems Research, 2002. 13\(3 43. Bahmanziari, T., J.M. Pearson, and L. Crosby, Is trust important in technology adoption? A policy capturing approach. The Journal of Computer Information Systems, 2003. 43\(4 44. Welch, J., Jack Welch's lessons for success, in Fortune. 1993. p. 86-91 45. Delmonte, A.J. and J.E. Aronson, The Relationship Between Social Interaction And Knowledge Management System Success. Journal of Knowledge Management Practice, 2004. 5 46. Choi, B. and H. Lee, An empirical investigation of KM styles and their effect on corporate performance. Information &amp; Management, 2002 40\(5 47. McDermott, R., Why Information Technology Inspired but Cannot Deliver Knowledge Management. California Management Review 


1999. 41\(4 48. Ribi  re, V., Le r  le primordial de la confiance dans les d  marches de gestion du savoir, in GREFI. 2005, Universit  Paul C  zanne: Aix en Provence \(France 297 49. Williams, S. Building and repairing trust.  2004 cited May 2005]; Available from http://www.wright.edu/~scott.williams/LeaderLet ter/trust.htm   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


21] N. M. Dixon, Common knowledge : how companies thrive by sharing what they know. Boston: Harvard Business School Press, 2000 22] K. Knorr Cetina, The Manufacture of Knowledge: An essay on the constructivist and contexutal nature of science. Oxford: Pergamon Press, 1981 23] R. J. J. Boland, "An Ecology of Distributed Practice Involving Knowledge Work," in The Social Study of Information and Communication Technology: Innovation Actors, and Contexts C. Avgerou, C. Ciborra, and F. Land Eds. Oxford: Oxford University Press, 2004 24] M. Agar, Speaking of Ethnography. Beverly Hills Sage Publications, 1986 25] J. Van Maanen, "The Fact of Fiction in Organizational Ethnography," ASQ, vol. 24, pp. 539-550, 1979 26] M. B. Miles and A. M. Huberman, Qualitative Data Analysis: A Sourcebook of New Methods. Beverly Hills Sage Publications, 1984 27] S. R. Barley, "Technology as an Occasion for Structuring: Evidence from Observation of CT Scanners and the Social Order of Radiology Departments," ASQ, vol 31, pp. 78-108, 1986 28] M. L. Markus, "Toward a Theory of Knowledge Reuse: Types of Knowledge Reuse Situations and Factors in Reuse Success," Journal of Management Information Systems, vol. 18, pp. 57 - 94, 2001 29] W. J. Orlikowski, "Knowing in practice:  Enacting a collective capability in distributed organizing Organization Science, vol. 13, pp. 249?273, 2002 30] C  sterlund and P. Carlile, "Relations in Practice Sorting through practice theories on knowledge sharing in complex organizations," The Information Society, vol. 21 pp. 91-107, 2005 31] L. A. Suchman, Plans and Situated Actions: The problem of human-machine communication. Cambridge Cambridge University Press, 1987 32] M. S. Ackerman and C. Halverson, "Organizational Memory: Processes, Boundary Objects, &amp; Trajectories CSCW, vol. 13, pp. 155-189, 2004 33] R. J. Boland, "Information System Use as a hermeneutic process," in Information Systems Research Contemporary Approaches and Emergent Traditions, H.-E Nissen, H. K. Klein, and R. A. Hirchheim, Eds Amsterdam: North-Holland, 1991, pp. 439-464  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 11 pre></body></html 


paper-based presentation and interactive paper prototyping tool. In Proceedings of the 1st international Conference on Tangible and Embedded interaction \(TEI ?07 Baton Rouge, Louisiana. New York: ACM, 2007  18] Tanabe, K., Yoshihara, M., Kameya, H., Mori, S Omata, S., Ito, T., Automatic Signature Verification Based on the Dynamic Feature of Pressure. Proceedings of the Sixth International Conference on Document Analysis and Recognition \(ICDAR ?01 Computer Society, 2001   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


The HyspIRI mission utilizes innovative techniques to both reduce the amount of data that must be transmitted to the ground and accommodate the required data volume on the ground The infrastructure and techniques developed by this mission will open the door to future high data volume science missions The designs presented here are the work of the authors and may differ from the current HyspIRI mission baseline A CKNOWLEDGMENTS This research was carried out at the Jet Propulsion Laboratory California Institute of Technology and was sponsored by the Space Grant program and the National Aeronautics and Space Administration R EFERENCES  K W ar\002eld T  V  Houten C Hee g V  Smith S Mobasser B Cox Y He R Jolly C Baker S Barry K Klassen A Nash M Vick S Kondos M Wallace J Wertz Chen R Cowley W Smythe S Klein L Cin-Young D Morabito M Pugh and R Miyake 223Hyspiri-tir mission study 2007-07 002nal report internal jpl document,\224 TeamX 923 Jet Propulsion Laboratory California Institute of Technology 4800 Oak Grove Drive Pasadena CA 91109 July 2007  R O Green 223Hyspiri summer 2008 o v ervie w  224 2008 Information exchanged during presentation  S Hook 2008 Information e xchanged during meeting discussion July 16th  R O Green 223Measuring the earth wi th imaging spectroscopy,\224 2008  223Moore s la w Made real by intel inno v ation 224 http://www.intel.com/technology/mooreslaw/index.htm  T  Doggett R Greele y  S Chein R Castano and B Cichy 223Autonomous detection of cryospheric change with hyperion on-board earth observing-1,\224 Remote Sensing of Environment  vol 101 pp 447\226462 2006  R Castano D Mazzoni N T ang and T  Dogget 223Learning classi\002ers for science event detection in remote sensing imagery,\224 in Proceedings of the ISAIRAS 2005 Conference  2005  S Shif fman 223Cloud detection from satellite imagery A comparison of expert-generated and autmatically-generated decision trees.\224 ti.arc.nasa.gov/m/pub/917/0917 Shiffman  M Griggin H Burk e D Mandl and J Miller  223Cloud cover detection algorithm for eo-1 hyperion imagery,\224 Geoscience and Remote Sensing Symposium 2003 IGARSS 03 Proceedings 2003 IEEE International  vol 1 pp 86\22689 July 2003  V  V apnik Advances in Kernel Methods Support Vector Learning  MIT Press 1999  C Bur ges 223 A tutorial on support v ector machines for pattern recognition,\224 Data Mining and Knowledge Discovery  vol 2 pp 121\226167 1998  M Klemish 223F ast lossless compression of multispectral imagery internal jpl document,\224 October 2007  F  Rizzo 223Lo w-comple xity lossless compression of h yperspectral imagery via linear prediction,\224 p 2 IEEE Signal Processing Letters IEEE 2005  R Roosta 223Nasa jpl Nasa electronic parts and packaging program.\224 http://nepp.nasa.gov/docuploads/3C8F70A32452-4336-B70CDF1C1B08F805/JPL%20RadTolerant%20FPGAs%20for%20Space%20Applications.pdf December 2004  I Xilinx 223Xilinx  Radiation-hardened virtex-4 qpro-v family overview.\224 http://www.xilinx.com/support/documentation data sheets/ds653.pdf March 2008  G S F  Center  223Tdrss o v ervie w  224 http://msp.gsfc.nasa.gov/tdrss/oview.html 7  H Hemmati 07 2008 Information e xchanged during meeting about LaserComm  223W orldvie w-1 224 http://www digitalglobe.com/inde x.php 86/WorldView-1 2008  223Sv albard ground station nor way.\224 http://www.aerospacetechnology.com/projects/svalbard 7 2008  223Satellite tracking ground station 224 http://www.asf.alaska.edu/stgs 2008  R Flaherty  223Sn/gn systems o v ervie w  224 tech rep Goddard Space Flight Center NASA 7 2002  223Geoe ye-1 f act sheet 224 http://launch.geoeye.com/launchsite/about/fact sheet.aspx 2008  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-720 Transmitter  5 2007 PDF Spec Sheet for the T720 Ku-Band TDRSS Transmitter  L-3 Communications/Cincinnati Electronics Space Electronics 7500 Innovation Way Mason OH 45040 T-722 X-Band  7 2007 PDF Spec Sheet for the T-722  J Smith 07 2008 Information e xchanged during meeting about GDS  J Carpena-Nunez L Graham C Hartzell D Racek T Tao and C Taylor 223End-to-end data system design for hyspiri mission.\224 Jet Propulsion Laboratory Education Of\002ce 2008  J Behnk e T  W atts B K obler  D Lo we S F ox and R Meyer 223Eosdis petabyte archives Tenth anniversary,\224 Mass Storage Systems and Technologies 2005 Proceedings 22nd IEEE  13th NASA Goddard Conference on  pp 81\22693 April 2005 19 


 M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolving a ten year old data system,\224 Space Mission Challenges for Information Technology 2006 SMC-IT 2006 Second IEEE International Conference on  pp 8 pp.\226 July 2006  S Marle y  M Moore and B Clark 223Building costeffective remote data storage capabilities for nasa's eosdis,\224 Mass Storage Systems and Technologies 2003 MSST 2003 Proceedings 20th IEEE/11th NASA Goddard Conference on  pp 28\22639 April 2003  223Earth science data and information system esdis project.\224 http://esdis.eosdis.nasa.gov/index.html  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Evolution of the earth observing system eos data and information system eosdis\\224 Geoscience and Remote Sensing Symposium 2006 IGARSS 2006 IEEE International Conference on  pp 309\226312 31 2006Aug 4 2006  223Earth science mission operations esmo 224 http://eos.gsfc.nasa.gov/esmo  E Masuoka and M T eague 223Science in v estig ator led global processing for the modis instrument,\224 Geoscience and Remote Sensing Symposium 2001 IGARSS 01 IEEE 2001 International  vol 1 pp 384\226386 vol.1 2001  M Esf andiari H Ramapriyan J Behnk e and E So\002nowski 223Earth observing system eos data and information system eosdis 227 evolution update and future,\224 Geoscience and Remote Sensing Symposium 2007 IGARSS 2007 IEEE International  pp 4005\2264008 July 2007  D McAdam 223The e v olving role of tape in the data center,\224 The Clipper Group Explorer  December 2006  223Sun microsystems announces w orld s 002rst one terabyte tape storage drive.\224 http://www.sun.com/aboutsun/pr/200807/sun\003ash.20080714.2.xml July 2008  223P anasas 227 welcome 224 http://www panasas.com  R Domikis J Douglas and L Bisson 223Impacts of data format variability on environmental visual analysis systems.\224 http://ams.confex.com/ams/pdfpapers/119728.pdf  223Wh y did nasa choose hdf-eos as the format for data products from the earth observing system eos instruments?.\224 http://hdfeos.net/reference/Info docs/SESDA docs/NASA chooses HDFEOS.php July 2001  R E Ullman 223Status and plans for hdfeos nasa's format for eos standard products.\224 http://www.hdfeos.net/hdfeos status HDFEOSStatus.htm July 2001  223Hdf esdis project.\224 http://hdf.ncsa.uiuc.edu/projects/esdis/index.html August 2007  223W elcome to the ogc website 224 http://www.opengeospatial.org 2008  223Open gis Gis lounge geographic information systems.\224 http://gislounge.com/open-gis Christine M Hartzell received her B.S in Aerospace Engineering for Georgia Institute of Technology with Highest Honors in 2008 She is currently a PhD student at the University of Colorado at Boulder where she is researching the impact of solar radiation pressure on the dynamics of dust around asteroids She has spent two summers working at JPL on the data handling system for the HyspIRI mission with particular emphasis on the cloud detection algorithm development and instrument design Jennifer Carpena-Nunez received her B.S in physics in 2008 from the University of Puerto Rico where she is currently a PhD student in Chemical Physics Her research involves 002eld emission studies of nanostructures and she is currently developing a 002eld emission setup for further studies on nano\002eld emitters The summer of 2008 she worked at JPL on the HyspIRI mission There she was responsible for the science analysis of the data handling system speci\002cally de\002ning the data level and processing and determining potential mission collaborations Lindley C Graham is currently a junior at the Massachusetts Institute of Technology where she is working towards a B.S in Aerospace Engineering She spent last summer working at JPL on the data handling system for the HyspIRI mission focusing on developing a data storage and distribution strategy 20 


David M Racek is a senior working toward a B.S in Computer Engineering at Montana State University He works in the Montana State Space Science and Engineering Laboratory where he specializes in particle detector instruments and circuits He spent last summer working at JPL on compression algorithms for the HyspIRI mission Tony S Tao is currently a junior honor student at the Pennsylvania State University working towards a B.S in Aerospace Engineering and a Space Systems Engineering Certi\002cation Tony works in the PSU Student Space Programs Laboratory as the project manager of the OSIRIS Cube Satellite and as a systems engineer on the NittanySat nanosatellite both of which aim to study the ionosphere During his work at JPL in the summer of 2008 Tony worked on the communication and broadcast system of the HyspIRI satellite as well as a prototype Google Earth module for science product distribution Christianna E Taylor received her B.S from Boston University in 2005 and her M.S at Georgia Institute of Technology in 2008 She is currently pursing her PhD at the Georgia Institute of Technology and plans to pursue her MBA and Public Policy Certi\002cate in the near future She worked on the ground station selection for the HyspIRI mission during the summer of 2008 and looks forward to working at JPL in the coming year as a NASA GSRP fellow Hannah R Goldberg received her M.S.E.E and B.S.E from the Department of Electrical Engineering and Computer Science at the University of Michigan in 2004 and 2003 respectively She has been employed at the Jet Propulsion Laboratory California Institute of Technology since 2004 as a member of the technical staff in the Precision Motion Control and Celestial Sensors group Her research interests include the development of nano-class spacecraft and microsystems Charles D Norton is a Principal Member of Technical Staff at the Jet Propulsion Laboratory California Institute of Technology He received his Ph.D in Computer Science from Rensselaer and his B.S.E in Electrical Engineering and Computer Science from Princeton University Prior to joining JPL he was a National Research Council resident scientist His work covers advanced scienti\002c software for Earth and space science modeling with an emphasis on high performance computing and 002nite element adaptive methods Additionally he is leading efforts in development of smart payload instrument concepts He has given 32 national and international keynote/invited talks published in numerous journals conference proceedings and book chapters He is a member of the editorial board of the journal Scienti\002c Programming the IEEE Technical Committee on Scalable Computing a Senior Member of IEEE recipient of the JPL Lew Allen Award and a NASA Exceptional Service Medal 21 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 






Mining Motifs in Massive Time Series Databases Pranav Patel Eamonn Keogh Jessica Lin Stefano Lonardi University of California  Riverside Computer Science  Engineering Department Riverside CA 92521 USA patel eamonn jessica stelo}@cs uti-.edu Abstract The problem of eficiently locating previously known patterns in a time series database i.e query by content\has received much attention and may now largely be regarded as a solvedproblem However from a knowledge discovery viewpoint a more interesting problem is the enumeration of previourly unknown frequently occurring patterns We call such 
patterns 223motifs\224 because of their close analogv to their discrete counterparts in computation biologv An eflcient motif discovery algorithm far time series would be usefur as a tool for summarizing and visualizing massive time series databases In addition it could be used as a subroutine in various other data mining tasks including the discovery of association rules, clustering and classijication In this work we carefully motivate, then introduce a non trivial definition of time series motifs We propose an eflcient algorithm to discover them and we demonstrate the utilih, and eficiencv of our amroach 
on several real world 1 Introduction The problem of efficiently locating previously defined patterns in a time series database i.e query by content has received much attention and may now be essentially regarded as a solved problem I 8 13 21 22 23 35 401 However from a knowledge discovery viewpoint a more interesting problem is the detection of previously unknown frequently occurring patterns We call such patterns motif because of their close analogy to their discrete counterparts in computation biology I 1 16 30 
34 361 Figure 1 illustrates an example of a motif discovered in an astronomical database An efficient motif discovery algorithm for time series would he useful as a tool for summarizing and visualizing massive time series databases In addition it could he used as subroutine in various other data mining tasks for instance The discovery of association rules in time series first requires the discovery of motifs \(referred to as 221>primitive shapes\224 in 91 and 221yequent patterns\224 in IE However the current solution to finding the motifs is 
either high quality and very expensive or low quality hut cheap 191 Several researchers have advocated K-means clustering of time series databases 1141 without adequately addressing the question of how to seed the initial points or how to choose K Motifs could potentially be used to address both problems In addition seeding the algorithm with motifs rather than random points could speed up 0-7695-1754-4102 17.00 0 2002 IEEE 370 convergence 121 Several time series classification algorithms work hy constructing typical prototypes of each class 241 
While this approach works for small datasets, the construction of the prototypes which we see as motifs\requires quadratic time as is thus unable to scale to massive datasets In this work we carefully motivate, then introduce a non trivial definition of time series motifs We further introduce an efficient aleorithm to discover them 0 5 15 25 C Qf 0 20 40 ea ea Irn 1m Figure 1 An astmnomical time series above contains 3 near identical subsequences A 223zoom-in\224 below\reveals just how similar 
to each other the 3 subsequences are The rest of this paper is organized as follows In Section 2 we formally define the problem at hand and consider related work In Section 3 we introduce a novel low-dimensional discrete representation of time series, and prove that it can he used to obtain a lower hound on the true Euclidean distance Section 4 introduces our motif-finding algorithm, which we experimentally evaluate in Section 5 In Section 6 we consider related work, and finally in Section 7 we draw some conclusions and highlight directions for future work 2 Background 
and Related Work The following section is rather dense on terminology and definitions These are necessary to concretely define the problem at hand and to explain our proposed solution. We begin with a definition of our data type of interest time series  Definition 1 Time Series A time series T  I  Jm is an ordered set of m real-valued variables Time series can he very long sometimes containing billions of observations 1151 We are typically not interested in any of the global properties of a time series; rather, data 


miners confine their interest to subsections of the time series I 20,231 which are called subsequences Definition 2 Subsequence Given a time series T of length m a subsequence C of T is a sampling of length n  rn of contiguous position from T that is C  tp  t for I<p 5 m-n 1 A task associated with Subsequences is to determine if a given subsequence is similar to other subsequences I 2 3 8 13 19 21 22 23 24 25 27 29 35 401 This idea is formalized in the definition of a match Definition 3 Match Given a positive real number R called range and a time series T containing a subsequence C beginning at positionp and a subsequence M beginning at 9 if D\(C M I R then M is called a matching subsequence of C The first three definitions are summarized in Figure 2 illustrating a time series of length 500 and two subsequences oflength 128 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 c 0 50 100 150 200 210 300 350 100 450 SO0 best-motif-count-so-far  0 beat_motif-location_*o_far  null for i  1 to length\(T n  1 count  0 pointers  null for j  1 to 1engthIT n  1 if non-trivial-~tch\(Tli:,.,.,i T[j:,.n.,j R count  count  1 pointers  append\(pointers,j end end if count  best-motif-count-so-tar best-motif-count-so-fa  Count best-motif-location-so-far  i motif-matches E pointers end end Figure 2 A visual intuition of a time series T light line a subsequence C bold line\and a match M bold gray line For the time being we will ignore the question of what distance function to use to determine whether two subsequences match We will address this in Section 3.3 The definition of a match is rather obvious and inmifive but it is needed for the definition of a rrivial match One can observe that the hest matches to a subsequence apart from itself tend to be the subsequences that begin just one or two points to the left or the right of the subsequence in question Figure 3 illustrates the idea Figure 3 For almost any subsequence C in a time series, the best matches are the trivial subsequences immediately to the left and right of C Intuitively any definition of motif should exclude the possibility of over-counting these trivial matches, which we define more concretely below Definition 4 Trivial Match Given a time series T containing a subsequence C beginning at position p and a matching subsequence M beginning at 9 we say that M is a trivial match to C if either p  9 or there does not exist a subsequence M beginning at 9 such that D\(C M  R and eitherq<q'<porp<q'<q We can now define the problem of enumerating the K most significant motifs in a time series 371 


3.1 Dimensionality Reduction A time series C of length n can be represented in a w dimensional space hy a vector C=C  F The f\222 element of cis calculated hy the following equation  3 t-l c 8   cc 1 Simply stated to reduce the time series from n dimensions tow dimensions the data is divided into w equal sized 223frames\224 The mean value of the data falling within a frame is calculated and a vector of these values bewmes the data-reduced representation The representation can be visualized as an attempt to approximate the original time series with a linear combination of box hasis hnctions as shown in Figure 4 Figure 4 The PAA representation can be readily visualized as an attempt to model a sequence with a linear wmbination ofbox basis functions In this case a sequence oflength 128 is reduced to 8 dimensions The PAA dimensionality reduction is intuitive and simple yet has been shown to rival more sophisticated dimensionality reduction techniques like Fourier transforms and wavelets S 22 401 In addition it has several advantages over its rivals including being much faster to compute and being able to support many different distance functions including weighted distance functions 24 arbitrary Minkowski norms 40 and dynamic time warping 3.2 Discretization Having msformed a time series database into the PAA we can apply a further transformation to obtain a discrete representation For reasons that will become apparent in Section 4 we require a discretization technique that will produce symbols with equiprobability This is easily achieved since normalized time series have a Gaussian distribution To illustrate this we extracted subsequences of length 128 from 8 different time series and plotted a normal probability plot of the data as shown in Figure 5 Given that the normalized time series have highly Gaussian distribution we can simply determine the 223breakpoints\224 that will produce a equal-sized areas under Gaussian curve 31 0 ow n me DB om 4 02 c D om f DZ 0 111 IDI na om 0 om 10 0 10 Figure 5 A normal probability plot of the distribution of values from subsequences of length 128 from 8 different datasets The highly linear nature of the plot strongly suggests that the data came from a Gaussian distribution Definition 6 Breakpoints breakpoints are a sorted list of numbers B  p pel such that the area under a N\(0,I Gaussian curve from 4 to B  l/a Po and p are defined as  and  respectively These breakpoints may be determined by looking them up in a statistical table For example Table 2 gives the hreakooints for values of a from 3 to IO k3 4\2225 6 7 8 9 10 PI PI 6.84 I 0.97 I 1.07 I 1.15 I 1.22 I 1.28 P2 0.43 I 0 4.25 1-0.43 1-0.57 14.67 14.76 14.84 4.43 I 0.67 PI P4 Pr P6 P7 Pa P9 Table 2 A lookup table that wntains the breakpoints that divide a Gaussian distnbution in an arbitrary number from 3 to IO ofequiprobable regions Once the breakpoints have been obtained we can discretize a time series in the following manner We first obtain a PAA of the time series All PAA coefficients that are below the smallest breakpoint are mapped to the symbol 223a\224 all coefficients greater than or equal to the smallest breakpoint and less than the second smallest breakpoint are mapped to the symbol 223b etc Figure 6 illustrates the idea Figure 6 A time series is discretized by first obtaining a PAA approximation and then using predetermined breakpoints to map the PAA coefficients into symbols In the example above, with n  128 w  8 and 0  3 the time series is mapped to the word bnabeebc 372 


Note that in this example the 3 symbols 223a\224 223b\224 and 223e\224 are approximately equiprobable as we desired We call the concatenation of symbols that represent a subsequence a word Definition 7 Word A subsequence C of length n can be represented as a word e  as follows Let alphq denote the i\222 element of the alphabet i.e alpha  a and alpha2  b hen the mapping from a PAA approximation  to a word is obtained as follows e  alpha  iif PI C PI 2 We have now defined the two representations required for our motif search algorithm the PAA representation is merely an intermediate step required to obtain the symbolic representation 3.3 Distance Measures Having considered various representations of time series data we can now define distance measures on them By far the most common distance measure for time series is the Euclidean distance S 22,23 32,401 Given two time series Q and C of the same length n Eq 3 defines their Euclidean distance, and Figure 7.A illustrates a visual intuition of the measure D@,C I 3 If we transform the original subsequences into PAA representations Q and F using Eq 1 we can then obtain a lower bounding approximation of the Euclidean distance between the original subseauences bv This measure is illustrated in Figure 7.B A proof that DR\(Q,C lower bounds the true Euclidean distance appears in 22 an alternative proof appears in 1401 If we further transform the data into the symbolic representation we can define a MINDIST function that returns the minimum distance between the original time series of two words  MnvorsT\(h,Ai~~~:=,\(disl I 5 The function resembles Eq 4 except for the fact that the distance between the two PAA coefficients has been replaced with the sub-function disc The dist function can be implemented using a table lookup as illustrated in Table 3 awl b c 0.86 0 Table 3 A lookup table used by the MINDIST function This table is for an alphabet of cardinality i.e a  3 The distance between two symbols can be read off by examining the corresponding row and column For example disf\(a,b  0 and disf\(a,c  0.86 The value in cell r,c for any lookup table of can he calculated by the following expression 6 0 ifIr-cl<l i Pmu\(r  Pmin\(r.c otherwise cell  For a given value of the alphabet size a the table need only be calculated once then stored for fast lookup The MINDIST function can be visualized is Figure 7.C D m UI 60 I mm e  baabccbc 0  babcacca  t.zS+tr I A 221 C Figure 7 A visual intuition of the three representations discussed in this work and the distance measures defined on them A The Euclidean distance between two time series can be visualized as the square root of the sum of the squared differences of each pair of corresponding points B The distance measure defined for the PAA approximation can be seen as the square root of the sum of the squared differences between each pair of corresponding PAA coefticients multiplied by the square root of the compression rate C The distance between two symbolic representations of a time series requires looking up the distances between each pair of symbols squaring them summing them taking the square root and finally multiplying by the square root of the wmpression rate 4 Efficient Motif Discovery Recall that the brute force motif discovery algorithm introduced Table I requires O\(m2 calculations of the distance function As previously mentioned the symmetric property of the Euclidean distance measure could be used to half the number of calculations by storing D\(Q,C and re using the value when it is necessw to find D\(C,Q In fact further optimizations would be possible under this scenario We now give an example of such optimization Suppose we are in the innermost loop of the algorithm attempting lo enumerate all possible matches within R  1 to a particular subsequence Q Further suppose that in previous iterations we had already discovered that D\(C.,Cb  2 As 373 


we go through the innermost loop we first calculate the distance D\(Q,CJ and discover it to be 7 At this point we should continue on to measure D\(Q,Cb\hut in fact we don't have to do this calculation We can use the triangular inequality to discover that D\(Q,Cb\could not he a match to Q The triangular inequality requires that 2,22,33 7 D\(Q,C 5 aQ,cb  D\(c,cb Filling in the known values give us Rearranging the terms gives us But since we are only interested in subsequences that are a distance less than I unit away there is no point in determining the exact value of D\(Q,Cb which we now know to be at least 5 units away The first formalization of this idea for fast searching of nearest neighbors in matrices is generally credited to Burkhard and Keller 151 More efficient implementations are possible; for example, Shasha and Wang 33 introduced the Approximation Distance Map ADM algorithm that pre computes an arbitmy set of distances instead of using just one randomly chosen reference point For the problem at hand however the techniques discussed above seem of little utility since as previously noted we are unlikely to have O\(m space in which to store the entire matrix We propose to use just such a technique as a subroutine in our motif discovery algorithm. Our idea is to create only a small portion of the matrix at a time and exploit the techniques above to search it Our contribution comes from the method we use to construct the small matrix As we will demonstrate we can use our MNDIST function to create a matrix much smaller than O\(m2 which is paranfeed to contain all the subsequences which are within R of a promising candidate for a motif In addition to all the matching sequences to a promising candidate, the small matrix will generally contain some non matching subsequences, or false hits We use Shasha and Wang's ADM algorithm to eficiently separate the true matches to the false hits There is a possibility that a promising candidate for a motif will pan out That is after searching the small matrix we will discover that most or all of the subsequences don't match In this case we will have to construct a new small matrix and continue the search with the next most promising motif If the new small matrix has any overlap with the previous matrix we reuse the calculated values rather than recalculating them Constructing these small matrices would he of limited utility if their total size added up to O\(m While this is possible in pathological cases we can generally search a space much smaller in total size and still guarantee that we have returned the true best K-Motifs This in essence is the intuition behind our motif discovery algorithm We will achieve speed up by Searching a set of smaller matrices, whose total size is much less than the narve O\(m matrix Within the smaller matrices, using ADM to prune away a large fraction of the search space We will concretely define our algorithm which we call EMMA Enumeration of Motifs through Matrix Approximation in the next section 4.1 The EMMA Algorithm 7  D\(Q,C  2 8 5 6 D\(Q,cb 9 As before we only discuss the algorithm for finding the I Motif The generalization of the algorithm to finding K motifs is obvious and omitted for brevity and clarity of presentation The pseudocode for the algorithm is introduced in Table 4 The line numbers in the table are used in the discussion of the algorithm that follows The algorithm begins by sliding a moving window of length n across the time series \(line 4 The hash function h line 5 normalizes the time series converts it to the symbolic representation and computes an address h\(C,w,a  1  c I ord\(?J 1 x 0-1 IO Where ord\(C is the ordinal value of E Le ord\(a  I ord\(b  2 and so on The hash function computes an integer in the range 1 to w and a pointer to the subsequence is placed in the corresponding bucket \(line 6  1 2 3 4 5 6 7 0 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  Algorithm Find-1-Motif Index T n R w a1 lest-motif-count  0 iest_moeif_location  null inished  FALSI or i  1 to lengthiT  n  1 11 maah pomters hash-val  hiTu  w,al  11 ro subsewences appendibucket hash-Val pointers i  indi MPC  addIesSilargestibucket1 11 rid mc neighborhood  bucketlMPC rhile not finished for i  1 to Ip I BVild eigmorhod emp E bucketiil pointers 11 me DC if MINDISTIMPC. bucketii 1  R 11 amund neighborhood  appendineigMorhood,temp end end Imotif_cntr.countl= ADM\(T,neighborhoad.R i if count  largest_unexplored_neighborhood 11 Search neigMDrhDod far motifs best-motif-location  motif-cntr best_mofif_count  Count finished  TRW MPC  addressilargest_unexploredlbucketl neighborhood  buCketiMPC 01s  create che nexr neighhornaod KO search and md Table 4 The Find-I-Motif-Index algorithm At this point we have simply rearranged he data into a hash table with w addresses and a total of size O\(m This arrangement of the data has the advantage of approximately grouping similar subsequences \(more accurately, pointers to similar subsequences together We can use this information as a heuristic for motif search, since if there is a truly over represented pattern in the time series we should expect that most, if not all copies of it hashed to the same location We call the address with the most hits the Most Promising Candidate MPC line 8 We can build a list of all subsequences that mapped to this address \(line 9 but it is possible that some subsequences that hashed to different addresses are also within R of the subsequences contained in MPC We can use the MINDIST function that we defined in Section 3.3 to determine which addresses could possibly contain such subsequences \(line 12 All such subsequences are added to the list of subsequences that need to be examined in our small matrix line 14 We call the contents 374 


of a promising address, together with the contents of all the addresses within a MINDIST of R to it a neighborhood At this point we can pass the list of similar subsequences into the ADM subroutine \(line 17 We will elucidate this algorithm later in Section 4.2 For the moment we just note that the algorithm will return the hest motif from the original MPC subset with a count of the number of matching subsequences If we wish to implement the algorithm as an online algorithm, then at this point we can report the current motif as a tentative answer hefore continuing the search Such 223anytime\224 behavior is very desirable in a data-mining algorithm 7 Next, a simple test is performed. If the number of matches to the current best-so-far motif is greater than the largest unexplored neighborhood line IS we are done We can record the hest so far motif as the true best match \(line 19 note the number of matching subsequences line 20 and then abandon the search \(line 21 If the test fails however, we must set the most promising candidate to be the next largest bucket line 23 initialize the new neighborhood with the contents of the bucket line 24 and loop hack to line II where the full neighborhood is discovered lines 13 and 14 and the search continues For simplicity the pseudocode for the algorithm ignores the following possible optimization it is possible in fact likely\that the neighborhood in one interaction will overlap with the neighborhood in the next In this case we can reuse the subset of calculated values from iteration to iteration 4.2 The ADM Algorithm The algorithm we use for searching the small neighborhood matrix is a minor modification of the Shasha and Wang\222s ADM algorithm 33 The algorithm begins by pre-computing an arbitrary set of distances A matrix ADM is maintained of which each entry ij is either the exact distance between objects i and j i.e those that are pre computed or the lower hound for the distance between i and j The algorithm utilizes the property of triangle inequality to find the lower-hound distances Details on how to construct the matrix ADM can he found in 1331 After the matrix ADM is constructed, we scan the matrix and compute the actual distance hetween i and j if ADM[ij is a lower hound that is smaller than R because the true distance might he greater than R and omit it if it\222s greater than R For each object we keep track of the number of items smaller than R Finally the algorithm returns the hest matching motif i.e one with the most items within R with a count of number of matching subsequences 5 Experimental Evaluation We hegin by showing some motifs discovered in a variety of time series. We deliberately consider time series with very different properties of noise, autocorrelation, stationarity etc Figure 8 shows the I-Motif discovered in various datasets together with a much larger subsequence of the time series to give context. Although the subsequences are normalized before testing to see if they match we show the unnormalized subsequences for clarity We next turn our attention to evaluating the efficiency of the proposed algorithm For simplicity we have only considered the problem of speeding up motif search when 80 I  A 222O t 0 10 20 30 40 2 1.9 1.8 1.7 1.6 1.5 1.4 1.3 0 40 80 120 160  200 Figure 8 The I-Motif discovered in various publicly available datasets From top to bottom, \223Network\224 and \223Burst\224 Details about the datasets are available from the UCR time series data mining archive The small inset boxes show a subsequence of length 500 to give context to the motif the whole time series fits in main memory \(we intend to address efficient disk-based algorithms in future work So we can evaluate the efficiency of the proposed algorithm by simply considering the ratio of how many times the Euclidean distance function must be evaluated by EMMA over the number of times it must he evaluated by the brute force algorithm described in Table 1 11 numbar of me EMU4 cds Euchdem disl eflcienq  nvrnkr of nmes bma-force colls Euclndmn dw This measure ignores the cost of building the hash table but this needs he done only once \(even if the user wishes to try sevd values of R and is in any case linear in m The efficiency depends on the value of R used in the experiments In the pathological case of R  m only one 223small\224 matrix would be created, but it would be O\(m even if we could fit such a large matrix in main memory the only speed-up would come from ADM algorithm The other pathological case of R  0 would make our algorithm behave very well, because only a few very small matrices would be created and the triangular inequality pruning of ADM algorithm would he maximally efficient Of course, neither of these scenarios is meaningful the former would result in a Motif with every \(non-trivial\subsequence in the time series included and the latter case would almost certainly result in no motif being found since we are dealing with real numbers In order to test with realistic values of R we will consider the efficiency achieved when using the values used to create the results shown in Figure 8 The results are shown in Table 5 Dataset I Network I Burst I efficiencv I 0.0018 I 0.0192 I Table 5 The efficiency of the EMMA algorithm on various datasets These results indicate a one to two order of magnitude speedup over the brute force algorithm 375 


6 Related work To the best of our knowledge, the problem of finding repeated patterns in time series has not been addressed or even formulated in the literature Several researchen in data mining have addressed the discovery of reoccurring patterns in event streams 391 although such data sources are often referred to as time series 38 The critical difference is that event streams are sequentially ordered variables that are nominal have no natural ordering and thus these researchers are concerned with similar subsets not similar subsequences. Research by Indyk et al 20 has addressed the problem of finding representative trends in time series, this work is more similar in spirit to our work However, they only consider trends not more general patterns and they only consider locally representative trends, not globally occurring motifs as in our approach While there has been enormous interest in efficiently locatingpreviowly known panerns in time series I 2 3 8 13 19 22 23 24 27 29 32 35 401 our focus on the discovery of previously unknown patterns is more similar to and was inspired by work in computational biology, which we briefly review below In the context of computational biology pattern discovery refers to the automatic identification of biologically significant patterns or mot by statistical methods The underlying assumption is that biologically significant words show distinctive distribution patterns within the genomes of various organisms, and therefore they can be distinguished from the others During the evolutionary process living organisms have accumulated certain biases toward or against some specific motifs in their genomes For instance, highly recurring oligonucleotides are often found in correspondence to regulatory regions or protein binding sites of genes Vice vena rare oligonucleotide motifs may be discriminated against due to S~IUC~UIX constraints of genomes or specific reservations for global transcription conhnls Pattern discovery in computational biology originated with the work of Rodger Staten 1341 Along this research line a multitude of panerns have been variously characterized and criteria algorithms and software have been developed in correspondence We mention a few representatives of this large family of methods without claiming to be exhaustive CONSENSUS 16 GIBBS SAMPLER 261 WINNOWER 30 PROJECTION 36 VERBUMCLLUS 14 281 These methods have been studied from a rigorous statistical viewpoint see e.g 1311 for a review and also employed successfully in practice see e.g I71 and references therein While there are literally hundreds ofpapen on discretizing symbolizing, tokenizing\time series 2 3,9 13 19 25 271 see IO for an extensive survey\and dozens of distance measures defined on these representations none of the techniques allows a distance measure which lower bounds a distance measure defined on the original time series 7 Conclusions We have formalized the problem of finding repeated panerns in time series and introduced an algorithm to efficiently locate them In addition, a minor contribution of this paper is to introduce the first discrete representation of time series that allows a lower bounding approximation of the Euclidean distance This representation may be of independent interest to researchen who use symbolic representations for similarity search 3 19 25 27 291 change voint detection 1131 and extractina rules from time   series 9,181  There are several directions in which we intend to extend this work As previously noted, we only considered the problem of speeding up main memory search Techniques for dealing with large disk resident data are highly desirable 6 On large datasets, the number of returned motifs may be intimidating; we plan to investigate tools for visualizing and navigating the results of a motif search Our motif search algorithm utilizes the Euclidean metric and can be trivially modified to use any Minkowski metric 40 However recent work by several authors has suggested that the Euclidean may be inappropriate in some domains 21 291 We hope to generalize our results to work with other more robust distance measures such as Dynamic Time Warping 1291 It may be possible to extend our work to multi dimensional time series i.e trajectories 37 8 References I Agrawal R Faloulsos C  Swami A 1993 Efficient similarity search in sequence databases In proceedings of the th Int'l Conference on Foundationr of Data Organization and Algorithm Chicago IL Ocl 13-15 pp 69-84 2 Agrawal R Psaila G Wimmers E L  Zait M 1995 Querying shapes of histories In proceedings ofthe 21 Int'l Conference on Very Large Doiahes Zurich Switzerland Sept 11-15 pp502-514 3 AnaWJdnsson H  Badal D 11997 Using signature files for querying time-series data In proceedings of Principles of Data Mining and Knowledge Discovery I European Symposium Trondheim Norway Jun 24-27 pp 21 1-220 4 Apostolico A Bock M E  Lonardi S 2002 Monotony of surprise and large-scale quest for unusual words extended abstract Myers G Hannenhalli S Istrail S Pevmer P  Waterman M editors In proceedings of the 62h lnt'l Conference on Research in Computational Molecular Biology Washington Dc April 18-21 pp 22-31 SI Burkhard W A  Keller R M 1973 Some approaches to best-match tile searching Comrnun ACM April Vol 16\(4 pp 230-236 6 Bohm C Bramuller B Krebs F  Kriegel H P 2002 Epsilon grid order An algorithm for the similarity join on massive high-dimensional data In proceedings of ACM SIGMOD Ini Con on Management ofData Santa Barbara 7 Bradley P S Fayyad U M  Rein C A 1998 Scaling clustering algorithms to large databases In proceedings ofthe dh Int'l Conference on Knowledge Discovery and Data Mining New York NY Aug 27-31 pp 9-15 81 Chan K  Fu A W 1999 Eificient time series matching by wavelets In proceedings of the 15 IEEE Inl'l Conference I A slightly expanded version of this paper in available by emailing the authors 376 


on Dolo Engivewing Sydney Australia Mar 23-26 pp 126 133 9 Das G Lin K Mannila H Renganathan G  Smyth P 1998 Rule discovery from time series Inproceedings of the Inf'l Conjrence on Knowledge Discovery and Data Mining New York, NY Aug 27-31 pp 16-22 IO Daw C S FiMey C E A Tracy E R 2001 Symbolic analysis of experimental data Review of Scientific Inrhrmentr To appear Eddy S Krogh A  Mitchison G 1998 Biological sequence analysis probabilistic models of proteins and nucleic acids Cambridge University Press 1121 Fayyad U Reina C  Bradley P 1998 Initialization of iterative refinement clustering algorithms In Proceedings of the Sh nterMfiOM/ Confireme on Knowledge Discovery and Data Mining New York,NY Aug27-31 pp 194-198 I31 Ge X  Smyth P 2000 Deformable Markov model templates for time-series pattern matching In proceedings of the 6 ACM SIGKDD lnleTMlioMl Conference on Knowledge Discovery andData Mining Boston MA Aug 20-23 pp 81 90 1141 Goune C Toft P Rosmp E Nielsen F.A  Hansen L.K 1999 Onclustering fMRl time series Neurolmage 9\(3 pp 298-310 IS Hegland M Clarke W  Kahn M 2002 Mining the MACHO dataset Computer Physics Communications Vol 142\(1-3 December 15 pp 22-28 I61 Hertz G  Stormo G 1999 Identifying DNA and protein panerns with statistically significant aliments of multiple sequences Bioinfoormfics Vol 15 pp 563-577 1171 van Helden J Andre B  Collado-Vides J 1998 Extracting regulatory sites from the upstream region of the yeast genes by computational analysis of oligonucleotides J Mol Bml Vol 281 pp 827-842 1181 H6ppner F 2001 Discovery oftemporal panem  learning rules abaut the qualitative behavior of time series In Proceedings of the 5 European Conference on Principles and Practice OfKnowledze Discoverv in Databases Freiburn Ill Durbin R I  Germany pp 192-203 I91 Huang Y  Yu P S 1999 Adaptive query processing for time-series data In oroceedinm ofthe 5 Int'l Conference on I Knowledge Discovery ond Data Mining San Diego CA Aug 15-18 pp282-286 20 Indyk P Koudas N  Muthuknshnan S 2000 Identifying representative trends in massive time series data sets using sketches In proceedings of the 2Sh In17 Conference on Very Large Dolo Bases Cairo Egypt Sept 10-14 pp 363-372 21 Kalpakis K Gada D  httagunta V 2001 Distance measures for effeclive clustering of ARlMA time-series In proceedings of fhe 2001 IEEE Infernational Conjerence on Data Mininx San Jose CA Nov 29-Dec 2 pp 273-280 1221 Keogh E Chakrabarti K Pawani M  Mehrotra 2000 Dimensionality reduction for fast similarity search in large time series databases Journal of Knowledge and Information Systems pp 263-286 1231 Keogh E Chakrabarti K Pazzani M  Mehrotr4 S 2001 Locally adaptive dimensionality reduction for indexing large time series databases In proceedings of ACM SIGMOD Confirence on Monamnent ofDofa Santa Barbara CA. Mav Y 21-24 pp 151-162 1241 Keogh E  Pauanr M 1998 An enhanced rewesentation   of time series which allows fast and accurate classification clustering and relevance feedback In proceedings of the 4 Inf'l Conference on Knowledge Discovery and Data Mining NewYork,NY,Aug27-31 pp239-241 1251 Koski A Juhola M  Meriste M 1995 Syntactic recognition of ECG signals by allributed finite automata Patfern Recognilion 28 12 pp 1927-1940 26 Lawrence C.E Altschul S F Boguski M S Liu J S Neuwald A F  Wwnon 1 C 1993 Detecting subtle sequence signals A Gibbs sampling svategy for multiple alignment Science Oct Vol 262 pp 208-214 1271 Li C Yu P S  Castelli V 1998 MALM a framework for mining sequence database at multiple abstraction levels In proceedings of the 7'h ACM CIKM International Conference on Information and Knowledge Managemenr Bethesda MD pp 267-272 1281 Lonardi S 2001 Global Detectors of Unusual Words Design Implementation and Applications to Panem Discovery in Biosequences PhD thesis Department of Computer Sciences hrdue University August 2001 29 Pemg C Wang H Zhang S  Parker S 2000 Landmarks a new model for similarity-based panem querying in time series databases In proceedings of 16 Intet-~ti~~l Conference on Doto Engineering 1301 Pevzner P A  Sze S H 2000 Combinatorial approaches to finding subtle signals in DNA sequences Inproceedings of the th lnternafionol Conference on hrelligenf Systems for Moleculm Biolog La lolla CA, Aug 19-23 pp 269-278 31 Reinert G Schbath S  Waterman M S 2000 Probabilistic and statistical propenies of words An overview J Comput Bio Val 7 pp 1-46 132 Roddick J F Hornsby K  Spiliopoulou M 2001 An Updated Bibliography of Temporal Spatial and Spatio Temporal Data Mining Research In Post Workshop Proceedings of the InlerMlioml Workrhop on Temporal Spafiol and Spotio-Temporal Data Mining Berlin Springer Lecture Notes in Artificial Intelligence 2007 Roddick J F andHomsby K E 147-163 1331 Shasha D  Wang T 1990 New techniques for best-match retrieval ACM Tram on Informarion Systems Vol 8\(2 pp 140-1 58 34 Staden R 1989 Methods for discovering novel motifs in nucleic acid sequences Comput. Appl Bimci Val 5\(5 pp 293-298 1351 SuUrik 2 R  Siebes A 1999 Measuring time series similarity through large singular features revealed with wavelet transformation In proceedings of the 1lYh International Work&p on Dafabase  Erperr Systems Applicatiom pp 162-166 36 Tompa M  Buhler I 2001 Finding motifs using random projections In proceedings of the 5 In17 Conference on cOmpU~al~OM Molecular Biology Montreal Canada Apr 22-25 pp 67-74 1371 Vlachos M Kollios G  Gunapulos G 2002 Discoverin similar multidimensional trajectories In proceedings 16 hltrnatfoM Confireme on Dota Engineering pp 673-684 1381 Wang W Yang J and Yu P 2001 Meta-paneins revealing hidden periodical panems In Proceedings of the I IEEE International Conference on Data Mining pp 550-557 39 Yang J Yu P Wang W and Han J 2002 Mining long sequential pauems in a noisy environment In proceedings SIGMOD lnternor;onal Conference on MaMgemenf of Dam Madison WI 1401 Yi B K  Faloutsos C 2000 Fast time sequence indexing for arbitraq Lp norms Inproceedings of the 26*'1nrl Conference on Very Large Datoboses pp 385-394 f 377 


In Figures 10 and 11 we see MAFIA is approximately four to five times faster than Depthproject on both the Connect-4 and Mushroom datasets for all support levels tested down to 10 support in Connect-4 and 0.1 in Mushroom For Connect-4 the increased efficiency of itemset generation and support counting in MAFIA versus Depthproject explains the improvement Connect 4 contains an order of magnitude more transactions than the other two datasets 67,557 transactions amplifying the MAFIA advantage in generation and counting For Mushroom the improvement is best explained by how often parent-equivalence pruning PEP holds especially for the lowest supports tested The dramatic effect PEP has on reducing the number of itemsets generated and counted is shown in Table 1 The entries in the table are the reduction factors due to PEP in the presence of all other pruning methods for the first eight levels of the tree The reduction factor is defined as  itemsets counted at depth k without PEP   itemsets counted at depth k with PEP In the first four levels Mushroom has the greatest reduction in number of itemsets generated and counted This leads to a much greater reduction in the overall search space than for the other datasets since the reduction is so great at highest levels of the tree In Figure 12 we see that MAFIA is only a factor of two better than Depthproject on the dataset Chess The extremely low number of transactions in Chess 3196 transactions and the small number of frequent 1-items at low supports only 54 at lowest tested support muted the factors that MAFIA relies on to improve over Depthproject Table 1 shows the reduction in itemsets using PEP for Chess was about an order of magnitude lower compared to the other two data sets for all depths To test the counting conjecture we ran an experiment that vertically scaled the Chess dataset and fixed the support at 50 This keeps the search space constant while varying only the generation and counting efficiency differences between MAFIA and Depthproject The result is shown in Figure 13 We notice both algorithms scale linearly with the database size but MAFIA is about five times faster than Depthproject Similar results were found for the other datasets as well Thus we see MAFIA scales very well with the number of transactions 5.3 Effects Of Compression To isolate the effect of the compression schema on performance experiments with varying rebuilding threshold values we conducted The most interesting result is on a scaled version of Connect-4, displayed in Figure 14 The Connect-4 dataset was scaled vertically three times so the total number of transactions is approximately 200,000 Three different values for rebuilding-threshold were used 0 corresponding to no compression 1 compression immediately and all subsequent operations performed on compressed bitmaps\and an optimized value determined empirically We see for higher supports above 40 compression has a negligible effect but at the lowest supports compression can be quite beneficial e.g at 10 support compression yields an improvement factor of 3.6 However the small difference between compressing immediately and finding an optimal compression point is not so easily explained The greatest savings here is only 11 at the lowest support of Conenct-4 tested We performed another experiment where the support was fixed and the Connect-4 dataset was scaled vertically The results appear in Figure 15 The x-axis shows the scale up factor while the y-axis displays the running times We can see that the optimal compression scales the best For many transactions \(over IO6 the optimal re/-threshold outperforms compressing everywhere by approximately 35 In any case both forms of compression scale much better than no compression Compression on Scaled ConnectAdata Compression Scaleup Connectldata ALL COMP 0 5 10 15 20 25 30 100 90 80 70 60 50 40 30 20 10 0 Min Support  Scaleup Factor Figure 14 Figure 15 45 1 


6 Conclusions We presented MAFIA an algorithm for finding maximal frequent itemsets Our experimental results demonstrate that MAFIA consistently outperforms Depthproject by a factor of three to five on average The breakdown of the algorithmic components showed parent-equivalence pruning and dynamic reordering were quite beneficial in reducing the search space while relative compressiodprojection of the vertical bitmaps dramatically cuts the cost of counting supports of itemsets and increases the vertical scalability of MAFIA Acknowledgements We thank Ramesh Agarwal and Charu Aggarwal for discussing Depthproject and giving us advise on its implementation We also thank Jayant R Haritsa for his insightful comments on the MAFIA algorithm and Jiawei Han for providing us the executable of the FP-Tree algorithm This research was partly supported by an IBM Faculty Development Award and by a grant from Microsoft Research References I R Agarwal C Aggarwal and V V V Prasad A Tree Projection Algorithm for Generation of Frequent Itemsets Journal of Parallel and Distributed Computing special issue on high performance data mining to appear 2000 2 R Agrawal T Imielinski and R Srikant Mining association rules between sets of items in large databases SIGMOD May 1993  R Agrawal R Srikant Fast Algorithms for Mining Association Rules Proc of the 20th Int Conference on Very Large Databases Santiago Chile, Sept 1994  R Agrawal H Mannila R Srikant H Toivonen and A 1 Verkamo Fast Discovery of Association Rules Advances in Knowledge Discovery and Data Mining Chapter 12 AAAVMIT Press 1995 5 C C Aggarwal P S Yu Mining Large Itemsets for Association Rules Data Engineering Bulletin 21 1 23-31 1 998 6 C C Aggarwal P S Yu Online Generation of Association Rules. ICDE 1998: 402-41 1 7 R J Bayardo Efficiently mining long patterns from databases SICMOD 1998: 85-93 8 R J Bayardo and R Agrawal Mining the Most Interesting Rules SIGKDD 1999 145-154 9 S Brin R Motwani J D Ullman and S Tsur Dynamic itemset counting and implication rules for market basket data SIGMOD Record ACM Special Interest Group on Management of Data 26\(2\1997 IO B Dunkel and N Soparkar Data Organization and access for efficient data mining ICDE 1999 l 11 V Ganti J E Gehrke and R Ramakrishnan DEMON Mining and Monitoring Evolving Data. ICDE 2000: 439-448  121 D Gunopulos H Mannila and S Saluja Discovering All Most Specific Sentences by Randomized Algorithms ICDT 1997: 215-229 I31 J Han J Pei and Y Yin Mining Frequent Pattems without Candidate Generation SIGMOD Conference 2000 1  12 I41 M Holsheimer M L Kersten H Mannila and H.Toivonen A Perspective on Databases and Data Mining I51 W Lee and S J Stolfo Data mining approaches for intrusion detection Proceedings of the 7th USENIX Securiry Symposium 1998 I61 D I Lin and Z M Kedem Pincer search A new algorithm for discovering the maximum frequent sets Proc of the 6th Int Conference on Extending Database Technology EDBT Valencia Spain 1998 17 J.-L Lin M.H Dunham Mining Association Rules: Anti Skew Algorithms ICDE 1998 486-493 IS B Mobasher N Jain E H Han and J Srivastava Web mining Pattem discovery from world wide web transactions Technical Report TR-96050 Department of Computer Science University of Minnesota, Minneapolis, 1996 19 J S Park M.-S Chen P S Yu An Effective Hash Based Algorithm for Mining Association Rules SIGMOD Conference 20 N Pasquier Y Bastide R Taouil and L Lakhal Discovering frequent closed itemsets for association rules ICDT 99 398-416, Jerusalem Israel January 1999 21 J Pei J Han and R Mao CLOSET An efficient algorithm for mining frequent closed itemsets Proc of ACM SIGMOD DMKD Workshop Dallas TX May 2000 22 R Rastogi and K Shim Mining Optimized Association Rules with Categorical and Numeric Attributes ICDE 1998 Orlando, Florida, February 1998 23 L Rigoutsos and A Floratos Combinatorial pattem discovery in biological sequences The Teiresias algorithm Bioinfomatics 14 1 1998 55-67 24 R Rymon Search through Systematic Set Enumeration Proc Of Third Int'l Conf On Principles of Knowledge Representation and Reasoning 539 550 I992 25 A Savasere E Omiecinski and S Navathe An efficient algorithm for mining association rules in large databases 21st VLDB Conference 1995 26 P Shenoy J R Haritsa S Sudarshan G Bhalotia M Bawa and D Shah: Turbo-charging Vertical Mining of Large Databases SIGMOD Conference 2000: 22-33 27 R Srikant R Agrawal Mining Generalized Association Rules VLDB 1995 407-419 28 H Toivonen Sampling Large Databases for Association Rules VLDB 1996 134-145 29 K Wang Y He J Han Mining Frequent Itemsets Using Support Constraints VLDB 2000 43-52 30 G I Webb OPUS An efficient admissible algorithm for unordered search Journal of Artificial Intelligence Research 31 L Yip K K Loo B Kao D Cheung and C.K Cheng Lgen A Lattice-Based Candidate Set Generation Algorithm for I/O Efficient Association Rule Mining PAKDD 99 Beijing 1999 32 M J Zaki Scalable Algorithms for Association Mining IEEE Transactions on Knowledge and Data Engineering Vol 12 No 3 pp 372-390 May/June 2000 33 M. J. Zaki and C Hsiao CHARM An efficient algorithm for closed association rule mining RPI Technical Report 99-10 1999 KDD 1995: 150-155 1995 175-186 3~45-83 1996 452 



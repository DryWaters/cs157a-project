html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">AN FP-SPLIT  METHOD FOR FAST ASSOCIATION RULES MINING Chin-Feng Lee Department of Information Management Chaoyang University of Technology No. 168, Jifong E.Rd., Wufong Township Taichung County 41349, Taiwan \(R.O.C E-mail: lcf@cyut.edu.tw Abstract Recently, most of the studies on association rules mining focused on improving the efficiency of frequent itemsets generation. To our best knowledge, the FP-growth algorithm which i s  based on the FP-tree to generate frequent itemsets is time-efticient. Currently, rdevant studies are introduced to improve tbe FP-growth algorithm. However, they ignore the fact that the FP-tree construction may spend much time. Therefore the goal of our research is to propose a fast algorithm called frequent pattern split, simply FP-split, for improving the process o f  the FP-tree construction. The proposed FP-split algorithm contains two main steps. The first step is to scan I transaction database only once for generating equivalence classes of frequent items. The second step is to sort these equivalence classes of frequent items in descending order so as to construct the FP-split tree. Through detailed experimental evaluations under various system conditions, our method shows excellent performance in terms of execution efficiency and scalability Index Terins4ata mining, association rule, frequent pattern growth, frequent pattern tree I. INTRODUCTION s competition among enterprises turns heated, information technology is playing an increasingly important role Applying IT in an effective way would assure enhanced enterprise competitiveness and increased profit. As leading and key IT to successful data mining, it aims to fetch, analyze and create useful information or knowledge from databases or data warehouses to help enterprise make decisions. Data mining techniques come in association rule [I][2], clustering[3] and classification[4] and association d e  is the one of frequent research and application on analysis of transaction data[5 The method of association rule mining comes in two phases The first phase refers to calculating frequency of appearance of items in the database for generating of frequent itemsets. The second phase is to generate the association rules with frequent itemsets. However, as he first phase generates frequent itemsets the repeated scanning of the database for calculating a large number of candidate itemsets, will suffer from much I/O time Therefore, most of the current studies aim to improve the efficiency of frequent itemsets generation. The method of association rule mining, frequent pattern growth \(FP-growth algorithm proposed by Jiawei Han [6][7] performs better. The FP-growth algorithm bases on frequent pattern tree \(FP-tree A Tsung-Hsien Shen Department of Information Management Chaoyang University of Technology No. 168, Jifong E.Rd., Wufong Township Taichung County 41349, Taiwan \(R.O.C E-mail: s9214613@cyut.edu.tw for mining frequent itemsets. The FP-tree construction needs to scan the database twice for frequent itemsets on a same frequent pattern tree. Then, with the FP-growth algorithm, the frequent itemsets can be further exploited from the FP-tree Currently, relevant studies are introduced to improve FP-growth algorithm for upgraded mining efficiency [8 However, they ignore the fast that the FP-tree construction may spend much time. As solution, we are proposing a method to improve the FP-tree construction algorithm: we propose an approach called FP-split algorithm for saving time in constructing tree. The FP-split algorithm adopts the divide-and-conquer strategy to construct a tree by means of the intersection and difference of itemsets. The proposed FP-split 


intersection and difference of itemsets. The proposed FP-split algorithm excels the FP-tree algorithm in three ways 1 .  Only once scanning of the database 2. No filtering and sorting of each item of the transaction 3. No repeatedly searching the header table for maintaining links, while inserting a new node into tree A.  Association Rules Association rules represent interesting relationships among items in a data set. For example, if customers are buying bread they are also likely to buy milk on the same trip. Accordingly an association rule should be denoted as bread+milk. The defmition of association rules was as follows [1][2]: Let I= { i l 12, . , ., in Tl, , . ., T,,J be a set of transactions. Each transaction T contains a set of items in I. An association rule means an implication of theX+YwhereXCI, Y C I ,  andXnY= 0. TheruleX+Ymust satisfy two criteria: the support and the confidence. A support s% i s  the percentage of the associated transactions XU Y in the database. The confidence c% means that the percentages of transactions in database containingXalso containing Y. If both of the support and confidence of the ruleX+Y are greater than user specified minimum support and minimum confidence, the rule X+Y is strong. Only a strong rule can be seen as an associational rule Association rules mining methods have two main phases The first phase is to extract frequent itemsets from a large 0-7803-8932-8/05/$20.00 8 2005 IEEE 459 number of transactions in a database. The second phase is to generate association rules from frequent itemsets. These mining methods can be classified into two categories. One category exploits frequent itemsets with candidate generation 1    cost is the need to generate huge candidate itemsets and the second one suffer from the repeating scans of database for pattern matching. The other category exploits frequent itemsets without candidate generation in advance [6][7][11][12 Therefore, the performance of the latter category for discovery of association rules will be better than the former one. Recently to our best knowledge, the FP-growth algorithm based on the FP-tree to generate the complete set of fkquent itemsets without candidate generation and thus has the lowest cost in time B. FP-tree and FP-growth Algorithm The FP-tree and FP-growth algorithms were proposed for enhancing the efficiency of association rules mining [6][7]. The FP-growth algorithm based on the FP-tree to exploit a set of frequent itemsets without candidate itemsets generation and the FP-tree construction algorithm scans databases only twice Hence, the FP-tree and FP-growth Algorithm save a lot of I/O Phase2: Calculating support to filter out non-frequent items Phase3: Constructing the FP-split tree using equivalence classes of frequent items. In the construction phase of FP-split algorithm with no more database scan, it mainly deals with the intersection and difference of itemsets for fast operations in the memory, and then efficiently deals with the linkage maintenance. Therefore, a lot of time can be saved for successful constructing the FP-split tree Phase 1 Generating #he Equivalence Classes of Items Let W = { i l ,  iz, .. ., in database. D= {bl, t2, ..., t ,],  and let D be the transaction database. The transaction record ti includes two parts: one is the transaction identifier Taand the other is an associated itemsets I where IC W We use the equivalence class of item to represent the occurrence of item 1. The equivalence class of item I can be defined as follows Defnition 1 The Equivalence Class of Item Let the equivalence class of item be EC,= {T id  I Tg are the identifier of transaction ti; 1 is an item of t i time to advance mining efficiency. The following algorithms are presented for FP-tree construction and frequent itemsets generation 


generation Example 1: Table 1 shows a transaction database. The field TID denotes as transaction identifier and the field Itemset stands for the transaction itemset. The item  a  appears in first second, third and forth records and item a  s equivalence class is I Scan the database for generating frequent items Store the set of frequent items into a l f f  labeled as  r  ECt= \(21, ECg= {3 5  and ECi? { 6 EC,= {l, 2, 3,4}. Likewise, the remaining equivalence classes of items are ECb= {1,3,4], ECG= { 5 , 6 } ,  ECd= {2,4},  EC,= { 11 a bj H and is sorted by their supports TABLE 1: A TRANSACTION DATABASE 4 Construct a FP-tree in the following two substeps: The First is to create a root labeled with  hull  The second is to scan database a second time. The items in each transaction are processed in L order and a branch of tree is created for each transaction. If a new branch shares a common prefix with the existing pattern for some transactions, the count of each node along the common prefix is incremented by one and node for the items following the prefm are created and linked accordingly 2 0 length k2 1 b pattern base 4 Exploit the conditional FP-tree for generating frequent itemsets with length k+l nr. THE PROPOSED METHOD The FP-split algorithm comes in three phases. Phasel Scanning the database to create equivalence class of item Itemset Phase 2 Colculufing Support The support of each item I- refers to the number of records contained in the equivalence class EC,. Let pCLl denote the support of the equivalence class EC,. After calculating the supports of items, we delete the items whose supports are below the predefined minimum support because these items are not frequent. Eventually, the set of frequent items in a list labeled as  L  are sorted in descending order by their supports Example 2: Have EC,= {1,2,3,4} as an example and item  a   appears in four transaction records, namely record 1,2,3 and 4 That is to say, a  s support is 4, suggesting ECal = 4. Likewise 1 and lECjl = 1. Next, delete the equivalence classes that fail to pass through the minimum support. Let mini-sup denoted as the minimum support, suggesting 2. The equivalence classes EC ECf, EC,, ECh, ECi would be deleted and items  a    b    c   and  8  are frequent. Finally, sort the set of all frequent items lECb I 3, IEC,l= 2, pC,l= 2, IEC,l= 1, lECd = 1, pC,l = 1, pclJ 460 into list L with L= \(\(a:4 b:3 c:2 d:2 Phase 3 Constructing FP-split tree After generating frequent items, the equivalence class of item is then converted into nodes for the construction of FP-split tree. To facility tree traversal, a header table is built in advanced so that each item can point to its first occurrence in the FP-split tree. There are two entries for each item in the header table. The first entry is store the frequent item and the second entry is used to link to the occurrence of the associated item in the FP-split tree This phase is mainly to use the tree structure to store frequent items in all transaction records. Each frequent item can be saved in one node or be split into a number of nodes. Split nodes are linked for further discovering frequent itemsets The node structure of FP-split tree is shown in Fig. 1. There are five entries. They are Content, List, Count, Link-sibling and Link-child. The entry of Confent is to store frequent item 1. The 


Link-child. The entry of Confent is to store frequent item 1. The entry of List is to store EC,. The entry of Count is to record the support of item I, that is to say, PCrl. The entry ofLink-sibling is a pointer, as it is mainly used for the connection of the nodes with the same item in the entry of Content. The entry of Link-child is also a pointer for the connection of child nodes Link-child Figure 1: Node structure While constructing the FP-split tree, a root will be generated which is a dummy node. The construction is different from the one given in Fig. 1, as it only contains one Link-child entry for the connection of all subtrees There are the four rules for the constructing of FP-split tree wherep stands for a specific node in the FP-split tree. Let n be a new node about to be added into the FP-split tree. Each time to add a new node n into the FP-split tree, all four rules should be taken into consideration i. Rule I If \( p  is root andp.Link-child= null Else End if p.link-child f n Call Compare \(p.Link-childList, n.list When nodep is a root and node p has no child nodes, node n would directly become a child node ofnodep, or node H would be compared to the child node of nodep Example 3: To begin with, the equivalence class EC, of item  a  is converted into node N1 and entry Link of item  a  in the header table links node NI. As defined in Rule 1, as root has no child nodes, NI is a child node to root, as shown in Fig. 2. I header table F A a : 4 1,2,3,4 Figure 2: Insert node N1 into the FP-split tree ii. Rule 2 If \( n.list c p. l i s t  andp.Link-child = null Else End if p.Link-child n Call Cumpare \(p.link-child.List, n.Lisf When the List of nodep completely covers the List of node n that is to say, ti. List E p. List, if nodep has no child node at all node n would be a child node of node p, or the child node of nodep and node n wodd have to be collated Example 4: By converting EC, into node N2 and connect Link of item  b  in the header table to node N2. As the List of node N1 completely covers that of List of node N2, that is to say N2.List E NI.List, and node NI has no child node. As suggested by Rule 2, node N2 becomes a child node of node N 1 as shown in Fig. 3 header table m wl __-- - -  pJ72, 1 2 3 4 1 2 3 4 1 3 4 _ _  N2 Figure 3: Insert node N2 into the FP-split tree iii. Rule 3 If \( n.List n p.List= 0 andp.Link-siblings null Else End if p.Link-sibling t n Call Compare \(p.Link-child.List, n.LW When the List of node p is completely different from that of node n, n.L&amp; fl p.List=P all, node n would become a sibling node of nodep, or node n would be collated with other sibling nodes of nodep Example 5: By converting EC, into node N3 and connect Link of item  c  in the header table to node N3. As the List of node N3 is completely different from that of node NI, that is to say N3.List # NI.List, and node N1 has no sibling node. As suggested by Rule 3, node N3 becomes a sibling node of node 


suggested by Rule 3, node N3 becomes a sibling node of node H NI, as shown in Fig. 4 header table  1 3.4 Figure 4: Insert node N3 into the FP-split tree 461 iv. Rule 4 If \(p.List n n.List # 0 andp.List - n.List # 0 End if Call split \( n When the List of node n resembles that of node p in some areas, that is to say n.List n p.List # 0 and n.LM fp.List ,  node n would be split into two nodes, that is to say node nl and node nZ. The item stored in the entry Content of node nl is the same to the item stored in the entry Content of node n2. That is nl,Contenf- nz,Content=n,Content. The areas which the List of node nl resembles that of node p by the operation of intersection, as shown in expression \(I List of node nz is different from that of node n and node p, the difference operation will be taken as shown in expression \(2 After splitting, the entry of Link-sibling of node nz will be connected to the node connected by Link-sibling ofnode n and then Link-sibling of node nl is immediately connected to node n2, thus retaining the connection nl.List = n.L&amp; fl p.L&amp; \(1 n2.List= n.List - p. l is t  \( 2 Next, node nl will first, by following the definition of Rule 2 decide whether to become child node of nodep, or whether to compare to the child nodes of node p. Node n2 will, by following the definition of Rule 3, decide whether to become the sibling node of nodep or whether to compare to the sibling nodes of nodep Example 6: Eventually, ECd is converted into node N4 and Link of item  8  in the header table is connected to node N4 As N4List c NlList and node N1 has the child node N2 defined by Rule 2, node N4 and node N2 are collated As the List of node N4 resembles partially that of node N2 that is to say, N4.List n N2.Lisr # 0 and N4.List - N2.List # 0 Defmed by Rule 4, node N4 wilI be split into two nodes, as shown in Fig. 5 T D N Figure 5 :  Split node N4 Suggested by expression \(l be {4] and the Count value is 1. According to expression \(2 List of the second node is \(2 item in the entry Content of the two nodes is the same to the item in the entry Content of node N4. After the dividing point the Link-sibing of the second node will be connected to the node connected by Link-sibing of the first node, and then Link-sibing of the first node will be connected to the second node, thus assuring the connection between the nodes. Defmed by Rule 4, the first node will be collated with the child nodes of node N2 and then the second node is collated with the sibling nodes of node N2. Defined by Rule 2, as node N2 has no child node, the first node will become a child node of node N2 Defined by Rule 3, as node N2 has no sibling node, the second node becomes the sibling node of node N2, as shown in Fig. 6 I Average length of transaction record Number of transactions in the database Number of items in the database header table ARer the FP-split tree is constructed completely, we could use the FP-growth algorithm [7] or the TD-FP-growth algorithm [8] based on the FP-split tree to generate all frequent itemsets III. EXPERIMENT In this chapter, we show the proposed FP-split algorithm is 


more efficient than FP-tree construction algorithm by a variety of data parameters. The data set are generated from the Assmgen [13]. The data parameters are state in Table 2. Here we are using Java programming language \(J2SDK 1.4.1 implementing algorithm on PCs. The PCs are equipped with Intel P4-2.8G CPU, 2GB memory and the operating system is Windows 2000 Professional. According to the version of Java the memory we have now is up to 1.5G TABLE 2: DATA PARAMETERS I Parametercode I Description 1 I I 1 Average length of frequent itemset I In Fig. 7, we have the test comparison by T20.110.DlOOk.Nlk. The efficiency of FP-split algorithm and FP-tree construction algorithm is evaluated by adjusting the minimum support value. The execution time on display in Fig 7 includes the time spent in scanning the database and constructing the tree. When the minimum support is set to be 2%, FP-split algorithm saves its many as four times in execution time than that of FP-tree construction algorithm. When the minimum support goes up to lo%, the difference between the two algorithms is double. In the figure, we can tell that FP-split algorithm performs much faster than FP-tree construction algorithm. FP-split algorithm does not increase the time spent in building the tree because of the minimum support goes down because FP-split algorithm only scans the database once and it does not repeatedly search header table while inserting a new node to tree for maintaining the linkage. Hence, FP-split approach can save a lot of execution time In Fig. 8, we have the efficiency evaluation when the data parameter is 110.D100k.Nlk and the minimum support is 7 by setting different average transaction items. The figure shows that out proposed FP-split algorithm is superior to FP-tree 462 2 3 4 5 6 7 x 9 10 Support threshold 1000 6 800 600 6 - 400 0 FP-tree h FP-split P 2 200 ei 10 1 5  20 25 Average transaction size FP-tree FP-split 100 200 300 400 500 Number of transactions \(K Figure 7: Scalability with threshold Figure 8: Scalability with average tmnsaction size Figure 9  Scalability with number of transactions construction algorithm. There are three reasons such that the proposed method outperformed. The first reason is the more the average transaction size is, the longer time FP-tree construction algorithm takes to execute. This is because the longer the transaction is, the more time it takes to scan. The second ane is that a longer average transaction size in database will generate more frequent itemsets. Accordingly, more time is spent in repeated search header table for maintaining the linkage. The last one is that FP-split method does not filter the non-frequent items by checking the transaction record, and nor does it reorder those frequent items in each transaction record. On the contrary, FP-tree construction algorithm does need to do SO In Fig. 9, by adjusting different parameters of transaction numbers, we have the efficiency evaluation when the data parameter is T20.110.Nlk and the minimum support 7%. It shows that the more the transaction data in the record is, the more time it takes to execute and at the same time, time difference between FP-split algorithm and FP-tree construction algorithm increases from tens of seconds spent for 100,000 transactions to hundreds of seconds for 500,000 h-ansactions 


transactions to hundreds of seconds for 500,000 h-ansactions As FP-split algorithm only scans the database once but not twice as the FP-tree construction algorithm does, the FP-split algorithm saves more time. In the event of large number of transaction data, the I/O cost remains much less compared with that of FP-tree construction algorithm. On the other hand FP-tree construction algorithm is required to filter the non-frequent items by checking the transaction record and it reorder those frequent items in each transaction record. On the contrary, FP-split algorithm doesn  t need to do so Ev. CONCLUSIONS In this paper, we have proposed an adaptive FP-tree construction algorithm - the FP-split algorithm. The FP-split algorithm is superior to FP-tree construction algorithm. There are three reasons such that the proposed method outperformed FP-tree construction algorithm in terms of tree construction The first one is that our proposed method scans the database only once. The second one is that filtering out and sorting the items in each transaction record will no longer be employed in our method. The thud one is that the header table and links will not be repeatedly searched, while adding a new node in the FP-split tree. Our future work is to develop one modified FP-split method for native XML databases ACKNOWLEDGMENT This work is supported by National Science Council of Taiwan, NSC- 93-2213-E-324-006 REFERENCES R. Agrawal, T. Imielinski, and A. Swami  Mining Association Rules between Sets of Items in Large Databases  Proceedings ofthe ACM SIGMOD conference OR Management ofData, 1993, pp. 207-2 16 R. Agrawal and R. Srikant  Fast AIgorithms for Mining Association Rules  Proceedings of the 20th Intemaiional Conference on Vety Large Databnses, 1994 R. Agrawal, J. Gehrke, D. Gunopulos, and P. Raghavan  Automatic Subspace Clustering of High Dimensional Data for Data Mining Applications  Proceedings of ihe ACM SIGMOD Conference on Monugement ofDota, 1998, pp. 94-105 K. Wan&amp; S. Zhoy and S. C. Liew  Building Hierarchical Classifiers Using Class Proximity  Proceedings of ihe 25th International Conference on Very Large Daiu Bmes, 1999, pp. 363-374 J. Han and M. Kamber, Data Mining: Concepts and Techruques, CA Morgan Kauham Publishers, 2001 J. Han, J, Pei, and Y, Yin  Mining Frequent Patterns Without Candidate Generation  Proceedings of ?he ACM SIGMOD Intemaiional Conference on Management ofData, 2000, pp. 1-12 J. Han, J. Pei, Y .  Yin, and R. Mao  Mining FreCperit Patterns without Candidate Generation: A Frequent-Pattern Tree Approach  In DataMining andKnowledge Discovery, 2004, Vol. 8, pp, 53-87 K. Wang, L, Tang, J .  Him, and J. Liu  Top Down FP-Growth for Association Rule Mining  Proceedings of che 6ih Pac$c-Asia Conference on Advances in Knowledge Dircove?y ondData Mining, 2002 J, S. Park, M. S. Chen, and P. S. YU  An Effective Hash Based Algorithm for Mining Association Rules  Proceedings of the ACM pp. 334-340 S  GMOD, 1995, PP. 175-186 IO] S.  Y. Wur and Y: Leu  An Effective Boolean Algorithm for Mining Association Rules in Large Databases  The 62h Internutional Confirenee on Database Sysfems for Advanced Applications, 1999, pp. 179-1 86 1 1 1 1  R. Agarwal, C. Agganval, and V. V. V Prasad  A Tree Projection Algorithm for Generation of Frequent Itemsets  Journal on PurafIel and Disrributed Computing, 2000, Vol. 61, pp, 350-371 U]  I. Pei, J. Han, H .  Lu, S. Nishio, S. Tang, and D. Yang  H-Mine: Hyper Structure Mining of Frequent Patterns in Large Database  Proceedings of the 1st IEEE Intemotionul Conference on Dafa Mining, 2001, pp 441-448 I131 IBM Almaden Research Center, Quest synthetic data generation http://www.almaden .ibm.comlsoRware/quest/Resources/dataset html, 2005 463 pre></body></html 


pre></body></html 


 The required delivery date is a Range constraint any date within the next 30 days Attribute Required-Delivery-Date  today today+30 days Attribute S&H query\(UPS Product   say it is 59.95 Attribute Value  query\(Catalog Product  Attribute Price  Attribute Total  Inter-attribute constraints in PO14 Price  Quantity  Value  1-x Total  Price  S&H  1.088 Total  Total1  Total4 In this case the Quantity attribute value has changed to 2 by adding both requests together Furthermore the Delivery-Date attribute value is a result of finding a common range of the two The obvious saving in this case is 2*$39.95 59.95\1.088  21.71 Whether a bunch of POs should be aggregated in a particular way depend on whether costing savings can be achieved while satisfying all the constraints 6.2 Intelligent Aggregation of Purchase Orders in e-Procurement with Negotiations Aggregation under dynamic negotiation is harder because supplier side could be revising its own strategies and parameters on the fly While human intervention in the aggregation process is possible we focus on automated aspects of the aggregation in this paper Suppose we have a simple supplier side rule buy one and get second one half price from LT a supplier of mice keyboard and trackball Suppose we have requests to buy Mice as follows PO5 Attribute Buyer  Organization 223B\224 User 223Joe\224 Location 223PS\224 Attribute Supplier  mpany 223LT\224 Catalog  http://\205/LT Attribute Product  223Optical Mouse\224 Attribute Quantity 1 Attribute Required-Delivery-Date  01/21/05 02/21/05   a r an g e of dat e s  order dat e  deadline d Attribute S&H9  query\(UPS Product   say it\222s 4.95 Attribute Value  query\(Catalog Product  Attribute Price10  Value  say it\222s 29.95 Attribute Total10  Total10  Price10  S&H10  1 tax rate results in a value 29.95  4.95\1.088  39.97 PO6 Attribute Buyer  Organization 223C\224 User 223Al\224 Location 223PS\224 Attribute Supplier  mpany 223LT\224 Catalog  http://\205/LT Attribute Product  223Optical Mouse\224 Attribute Quantity 1 Attribute Required-Delivery-Date  01/25/05 02/28/05   a r an g e of dat e s  order dat e  deadline d Attribute S&H10  query\(UPS Product   say it\222s 4.95 Attribute Value  query\(Catalog Product sayit\222s 29.95 per mouse Attribute Price10 Value Attribute Total10  Total10  Price10  S&H10  1 tax rate results in a value 29.95  4.95\1.088  39.97 6.2.1 PO Aggregation Under Negotiation The rule-based aggregation engine uses the Negotiation service to understand supplier\222s offers and tries to take advantage of the terms in the offers For example by aggregating PO5 and PO6 can be aggregated as follows PO56 Attribute Buyer  Organization B C User 223Joe\224 223Al\224 Location 223PS\224 Attribute Supplier  mpany 223LT\224 Catalog  http://\205/LT Attribute Product  223Optical Mouse\224 Attribute Quantity 2 Attribute Required-Delivery-Date  01/25/05 02/21/01 Attribute S&H10  query\(UPS Product   say it\222s 4.95 Attribute Value  query\(Catalog Product sayit\222s 29.95 per mouse Attribute Price10 1.5*Value Attribute Total10  Total10  Price10  S&H10  tax  1.5 29.95  4.95\1.088  54.26 A saving of 39.97  2 54.26  25.68 or over 32 of savings Note the changes of the 223Quantity\224 and 223RequiredDelivery-Date\224 attributes after aggregation The quantities are added up and the required delivered dates are merged for a common range Due to the constraints on object attributes aggregation may require complex constraint solving Proceedings of the 2005 Ninth IEEE International ED OC Enterprise Computing Conference \(EDOC\22205 0-7695-2441-9/05 $20.00 \251 2005  IEEE 


7 Conclusions and Future Work This paper describes an Intelligent Aggregation facility in enterprise e-Procurement process This facility introduces an information model a rule-based aggregation engine corporate agreement policies and negotiation in aggregating large volume of POs in enterprise eprocurement to reduce cost and maximize efficiency This information model includes extensive use of constraints for and among attributes in a PO These constraints guard the integrity of POs as they are aggregated The intelligent aggregation facility can be inserted as a value-added service in the enterprise e-Procurement workflow An enterprise generates millions of POs every year but the number of distinct products and services the enterprise purchases is actually much smaller in the hundreds rather than in the millions This presents cost saving opportunities by aggregating POs that makes best use of terms and conditions in corporate agreements or supplier offers Some concrete examples are used to show the idea of automated aggregation and the opportunities in reducing procurement cost As millions of POs are generated even a small percentage of savings would mean substantial savings for large enterprises The ideas described in this paper have not been fully implemented in our prototype One area needs more work is the formal representation of policies in corporate agreements which would allow the aggregation engine to automatically explore aggregation opportunities before POs are made to suppliers Another is the semantic model of products which would enable more semantics-based aggregation of POs 8 References  e bX M L  h t t p   w w w ebxml  org  2 e n g  J  S u  S  Y  W  L a m H   a n dH e l a l S   223Achieving Dynamic Inter-Organizational Workflow Management by Integrating Business Processes Events and Rules,\224 Proceedings of the 35th Hawaii International Conference on System Sciences HICSS35 Hawaii USA January 2002 3 u  S  Y  W  L a m H   L e e  M  B a i S   a n dS h e n  Z   An Information Infrastructure and E-services for Supporting Internet-based Scalable E-business Enterprises Proceedings of the 5th International Enterprise Distributed Object Computing Conference Seattle Washington USA September 2001 4 S u S Y  W   H ua ng C  H a mme r J   H u a ng Y   L i  H   Wang,L.,LiuY.,Pluempitiwiriyawej,C.,Lee,M and Lam H 223An Internet-based Negotiation Server for E-commerce,\224 VLDB Journal Vol 10 No 1 2001 pp.72-90 5 M o r r i s S l o m a n  223 P o l i c y D ri v e n M an ag em e n t f o r Distributed Systems\224 Journal of Network and Systems Management Plenum Press Vol 2 No 4 1994  M aarten S teen  J oh n D errick  223 For m ali s ing ODP Enterprise Policies\224 Proceedings of the 3 rd International nterprise Distributed Object Computing Conference Mannheim Germany IEEE CS Press September 1999  J am e s H a ns on  Z oran M i l o s e v i c 223 C o n v e r s at i onOriented Protocols for Contract negotiations\224 Proceedings of the 7th International Enterprise Distributed Object Computing Conference Brisbane Australia IEEE CS Press September 2003  S  N eal J  C ole P.F L i n i ng ton  Z  Milose v i c S Gibson S Kulkarni 223Identifying Requirements for Business Contract Language a Monitoring Perspective\224 Proceedings of the 7th International Enterprise Distributed Object Computing Conference Brisbane Australia IEEE CS Press September 2003 9 T  D im itrak o s  I  D j o rd j e v i c Z  Milo sev i c A  J o san g  C Phillips 223Contract Performance Assessment for Secure and Dynamic Virtual Collaborations\224 Proceedings of the 7th International Enterprise Distributed Object Computing Conference Brisbane Australia IEEE CS Press September 2003 Proceedings of the 2005 Ninth IEEE International ED OC Enterprise Computing Conference \(EDOC\22205 0-7695-2441-9/05 $20.00 \251 2005  IEEE 


absolute values. The results can vary on other computers. But it can be guaranteed that performance ratio of the algorithms will remain the same After making the comparisons with sample data, we came to the conclusion that PD algorithm performs significantly better than the other two especially with larger datasets. PD outperforms DCP and PIP regarding running time. On the other hand, since PD reduces the dataset, mining time does not necessary increase as the number of transactions increases and experiments reveals that PD has better scalability than DCP and PIP. So, PD has the ability to handle the large data mine in practical field like market basket analysis and medical report documents mining 5. References 1] R. Agrawal and R. Srikant, "Fast algoritlnns for mining association rules", VLDB'94, pp. 487-499 2] R. J. Bayardo, "Efficiently mining long patterns from databases", SIGMOD'98, pp.85-93 3] J. Pei, J. Han, and R. Mao, "CLOSET: An Efficient Algorithm for Mining Frequent Closed Itemsets \(PDF Proc. 2000 ACM-SIGMOD International Workshop on Data Mining and Knowledge Discovery, Dallas, TX, May 2000 4] Qinghua Zou, Henry Chiu, Wesley Chu, David Johnson, "Using Pattern Decomposition\( PD Finding All Frequent Patterns in Large Datasets", Computer Science Department University of California - Los Angeles 5] J. Han, J. Pei, and Y. Yin, "Mining Frequent Patterns without Candidate Generation \(PDF  SIGMOD International Con! on Management of Data SIGMOD'OOj, Dallas, TX, May 2000 6] S. Orlando, P. Palmerini, and R. Perego, "The DCP algoritlnn for Frequent Set Counting", Technical Report CS2001-7, Dip. di Informatica, Universita di Venezia 2001.Available at http://www.dsi.unive.itl?orlando/TR017.pdf 7] MD. Mamun-Or-Rashid, MD.Rezaul Karim, "Predictive item pruning FP-tree algoritlnn", The Dhaka University  Journal of Science, VOL. 52, NO. 1, October,2003, pp. 3946 8] Park, J. S., Chen, M.-S., and Yu, P. S, "An Effective Hash Based Algoritlnn for Mining Association Rules", Proc ofthe 1995 ACM-SIGMOD Con! on Management of Data 175-186 9] Brin, S., Motwani, R., Ullman, J., and Tsur, S, "Dynamic Itemset Counting and Implication Rules for Market Basket Data", In Proc. of the 1997 ACM-SIGMOD Conf On Management of Data, 255-264 10] Zaki, M. J., Parthasarathy, S., Ogihara, M., and Li, W New Algoritlnns for Fast Discovery of Association Rules In Proc. of the Third Int'l Con! on Knowledge Discovery in Databases and Data Mining, 283-286 11] Lin, D.-I and Kedem, Z. M., "Pincer-Search: A New Algoritlnn for Discovering the Maximum Frequent Set", In Proc. of the Sixth European Conf on Extending DatabaseTechnology, 1998 12] R. Ramakrishnan, Database Management Systems University of Wisconsin, Madison, WI, USA; International Edition 1998 pre></body></html 


tors such as union, di?erence and intersection are de?ned for pairs of classes of the same pattern type Renaming. Similarly to the relational context, we consider a renaming operator ? that takes a class and a renaming function and changes the names of the pattern attributes according to the speci?ed function Projection. The projection operator allows one to reduce the structure and the measures of the input patterns by projecting out some components. The new expression is obtained by projecting the formula de?ning the expression over the remaining attributes [12 Note that no projection is de?ned over the data source since in this case the structure and the measures would have to be recomputed Let c be a class of pattern type pt. Let ls be a non empty list of attributes appearing in pt.Structure and lm a list of attributes appearing in pt.Measure. Then the projection operator is de?ned as follows ls,lm c id s m f p ? c, p = \(pid, s, d,m, f In the previous de?nition, id ing new pids for patterns, ?mlm\(m projection of the measure component and ?sls\(s ned as follows: \(i s usual relational projection; \(ii sls\(s and removing the rest from set elements. The last component ?ls?lm\(f computed in certain cases, when the theory over which the formula is constructed admits projection. This happens for example for the polynomial constraint theory 12 Selection. The selection operator allows one to select the patterns belonging to one class that satisfy a certain predicate, involving any possible pattern component, chosen among the ones presented in Section 5.1.1 Let c be a class of pattern type pt. Let pr be a predicate. Then, the selection operator is de?ned as follows pr\(c p Join. The join operation provides a way to combine patterns belonging to two di?erent classes according to a join predicate and a composition function speci?ed by the user Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE Let c1 and c2 be two classes over two pattern types pt1 and pt2. A join predicate F is any predicate de?ned over a component of patterns in c1 and a component of patterns in c2. A composition function c pattern types pt1 and pt2 is a 4-tuple of functions c cStructureSchema, cDataSchema, cMeasureSchema, cFormula one for each pattern component. For example, function cStructureSchema takes as input two structure values of the right type and returns a new structure value, for a possible new pattern type, generated by the join. Functions for the other pattern components are similarly de?ned. Given two patterns p1 = \(pid1, s1, d1,m1, f1 p2 = \(pid2, s2, d2,m2, f2 p1, p2 ned as the pattern p with the following components Structure : cStructureSchema\(s1, s2 Data : cDataSchema\(d1, d2 Measure : cMeasureSchema\(m1,m2 Formula : cformula\(f1, f2 The join of c1 and c2 with respect to the join predicate F and the composition function c, denoted by c 1   F  c  c 2   i s  n o w  d e  n e d  a s  f o l l o w s    F  c  c 2     c  p 1   p 2   p 1    c 1  p 2    c 2  F   p 1   p 2     t r u e   5.1.3. Cross-over database operators OCD Drill-Through. The drill-through operator allows one to 


Drill-Through. The drill-through operator allows one to navigate from the pattern layer to the raw data layer Thus it takes as input a pattern class and it returns a raw data set. More formally, let c be a class of pattern type pt and let d be an instance of the data schema ds of pt. Then, the drill-through operator is denoted by c c Data-covering. Given a pattern p and a dataset D sometimes it is important to determine whether the pattern represents it or not. In other words, we wish to determine the subset S of D represented by p \(p can also be selected by some query the formula as a query on the dataset. Let p be a pattern, possibly selected by using query language operators, and D a dataset with schema \(a1, ..., an ible with the source schema of p. The data-covering operator, denoted by ?d\(p,D responding to all tuples in D represented by p. More formally d\(p,D t.a1, ..., t.an In the previous expression, t.ai denotes a speci?c component of tuple t belonging to D and p.formula\(t.a1, ..., t.an instantiated by replacing each variable corresponding to a pattern data component with values of the considered tuple t Note that, since the drill-though operator uses the intermediate mapping and the data covering operator uses the formula, the covering ?\(p,D D = ?\(p not be equal to D. This is due to the approximating nature of the pattern formula 5.1.4. Cross-over pattern base operators OCP Pattern-covering. Sometimes it can be useful to have an operator that, given a class of patterns and a dataset, returns all patterns in the class representing that dataset \(a sort of inverse data-covering operation Let c be a pattern class and D a dataset with schema a1, ..., an pattern type. The pattern-covering operator, denoted as ?p\(c,D all patterns in c representing D. More formally p\(c,D t.a1, ..., t.an true Note that: ?p\(c,D p,D 6. Related Work Although signi?cant e?ort has been invested in extending database models to deal with patterns, no coherent approach has been proposed and convincingly implemented for a generic model There exist several standardization e?orts for modeling patterns, like the Predictive Model Markup Language \(PMML  eling approach, the ISO SQL/MM standard [2], which is SQL-based, and the Common Warehouse Model CWM  ing e?ort. Also, the Java Data Mining API \(JDMAPI 3] addresses the need for a language-based management of patterns. Although these approaches try to represent a wide range of data mining result, the theoretical background of these frameworks is not clear. Most importantly, though, they do not provide a generic model capable of handling arbitrary cases of pattern types; on the contrary only a given list of prede?ned pattern types is supported To our knowledge, research has not dealt with the issue of pattern management per se, but, at best, with peripheral proximate problems. For example, the paper by Ganti et. al. [9] deals with the measurement 


per by Ganti et. al. [9] deals with the measurement of similarity \(or deviation, in the authors  vocabulary between decision trees, frequent itemsets and clusters Although this is already a powerful approach, it is not generic enough for our purpose. The most relevant research e?ort in the literature, concerning pattern management is found in the ?eld of inductive databases Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE meant as databases that, in addition to data, also contain patterns [10], [7]. Our approach di?ers from the inductive database one mainly in two ways. Firstly, while only association rules and string patterns are usually considered there and no attempt is made towards a general pattern model, in our approach no prede?ned pattern types are considered and the main focus lies in devising a general and extensible model for patterns Secondly, di?erently from [10], we claim that the peculiarities of patterns in terms of structure and behavior together with the characteristic of the expected workload on them, call for a logical separation between the database and the pattern-base in order to ensure e?cient handling of both raw data and patterns through dedicated management systems Finally, we remark that even if some languages have been proposed for pattern generation and retrieval 14, 11], they mainly deal with speci?c types of patterns \(in general, association rules sider the more general problem of de?ning safe and su?ciently expressive language for querying heterogeneous patterns 7. Conclusions and Future Work In this paper we have dealt with the issue of modelling and managing patterns in a database-like setting Our approach is enabled through a Pattern-Base Management System, enabling the storage, querying and management of interesting abstractions of data which we call patterns. In this paper, we have \(a de?ned the logical foundations for the global setting of PBMS management through a model that covers data patterns and intermediate mappings and \(b language issues for PBMS management. To this end we presented a pattern speci?cation language for pattern management along with safety constraints for its usage and introduced queries and query operators and identi?ed interesting query classes Several research issues remain open. First, it is an interesting topic to incorporate the notion of type and class hierarchies in the model [15]. Second, we have intentionally avoided a deep discussion of statistical measures in this paper: it is more than a trivial task to de?ne a generic ontology of statistical measures for any kind of patterns out of the various methodologies that exist \(general probabilities Dempster-Schafer, Bayesian Networks, etc. [16 nally, pattern-base management is not a mature technology: as a recent survey shows [6], it is quite cumbersome to leverage their functionality through objectrelational technology and therefore, their design and engineering is an interesting topic of research References 1] Common Warehouse Metamodel \(CWM http://www.omg.org/cwm, 2001 2] ISO SQL/MM Part 6. http://www.sql99.org/SC32/WG4/Progression Documents/FCD/fcddatamining-2001-05.pdf, 2001 3] Java Data Mining API http://www.jcp.org/jsr/detail/73.prt, 2003 4] Predictive Model Markup Language \(PMML http://www.dmg.org 


http://www.dmg.org pmmlspecs v2/pmml v2 0.html, 2003 5] S. Abiteboul and C. Beeri. The power of languages for the manipulation of complex values. VLDB Journal 4\(4  794, 1995 6] B. Catania, A. Maddalena, E. Bertino, I. Duci, and Y.Theodoridis. Towards abenchmark for patternbases http://dke.cti.gr/panda/index.htm, 2003 7] L. De Raedt. A perspective on inductive databases SIGKDD Explorations, 4\(2  77, 2002 8] M. Escobar-Molano, R. Hull, and D. Jacobs. Safety and translation of calculus queries with scalar functions. In Proceedings of PODS, pages 253  264. ACMPress, 1993 9] V. Ganti, R. Ramakrishnan, J. Gehrke, andW.-Y. Loh A framework for measuring distances in data characteristics. PODS, 1999 10] T. Imielinski and H. Mannila. A database perspective on knowledge discovery. Communications of the ACM 39\(11  64, 1996 11] T. Imielinski and A. Virmani. MSQL: A Query Language for Database Mining. Data Mining and Knowledge Discovery, 2\(4  408, 1999 12] P. Kanellakis, G. Kuper, and P. Revesz. Constraint QueryLanguages. Journal of Computer and SystemSciences, 51\(1  52, 1995 13] P. Lyman and H. R. Varian. How much information http://www.sims.berkeley.edu/how-much-info, 2000 14] R.Meo, G. Psaila, and S. Ceri. An Extension to SQL for Mining Association Rules. Data Mining and Knowledge DiscoveryM, 2\(2  224, 1999 15] S. Rizzi, E. Bertino, B. Catania, M. Golfarelli M. Halkidi, M. Terrovitis, P. Vassiliadis, M. Vazirgiannis, and E. Vrachnos. Towards a logical model for patterns. In Proceedings of ER 2003, 2003 16] A. Siblerschatz and A. Tuzhillin. What makes patterns interesting in knowledge discovery systems. IEEE TKDE, 8\(6  974, 1996 17] D. Suciu. Domain-independent queries on databases with external functions. In Proceedings ICDT, volume 893, pages 177  190, 1995 18] M.Terrovitis, P.Vassiliadis, S. Skadopoulos, E. Bertino B. Catania, and A. Maddalena. Modeling and language support for the management of patternbases. Technical Report TR-2004-2, National Technical University of Athens, 2004. Available at http://www.dblab.ece.ntua.gr/pubs Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE pre></body></html 


The reason of the hiding failure of SWA is the same in Fig.8 Notice the result at x = 0.7646 in Fig.14, because the hiding failure is occurred at the seeds of the sensitive patterns, a high weakness is produced As shown in Fig.15 and Fig.16, the misses cost and dissimil arity of our work decreases as RL2 increases. This is because the larger RL2 is, the less effect on non-sensitive patterns. Also weakness and dissimilarity of SWA are independent of RL2 5. Conclusion In the paper, a novel method improving the balance between sensitive knowledge protecting and discovery on frequent patte rns has been proposed. By setting entries of a sanitization matrix to appropriate values and multiplying the original database by the matrix with some probability policies, a sanitized database is gotten. Moreover, it can avoid F-I Attack absolutely when the confidence level given by users approximates to 1. The experimental results revealed that although misses cost and dissimilarity between the original and sanitized database of our process are little more than SWA, ours provide more safely protection than SWA. Unlike SWA, our sanitization process could not suffer from F-I Attack and the probability policies in our approach also take the minimum support into account, the users only need to decide the confidence level which affects the degree of patterns hiding 6. Reference 1] M. Atallah, E. Bertino, A. Elmagarmid, M. Ibrahim and V. Verykios Disclosure Limitation of Sensitive Rules", Proc. of IEEE Knowledge and Data Engineering Exchange Workshop 1999 2] R. Agrawal and R. Srikant. Fast algorithms for mining association rules. VLDB, Santiago, Chile, 1994 3] R. Agrawal and R. Srikant. Privacy preserving data mining. In ACM SIGMOD, Dallas, Texas, May 2000 4] E. Dasseni, V. Verykios, A. Elmagarmid and E. Bertino, Hiding Association Rules by Using Confidence and Support", Proc. of 4th Intl Information Hiding Workshop \(IHW 5] A. Evfimievski, J. Gehrke, and R. Srikant. Limiting Privacy Breac hed in privacy preserving data mining. SIGMOD/PODS, 2003 6] A. Evfimievski, R. Srikant, R. Agrawal, and J. Gehrke. Privacy preserving mining of association rules. KDD 2002 7] M. Kantarcioglu and C. Clifton. Privacy-preserving distributed mining of association rules on horizontally partitioned data. In ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery, June 2002 8] Guanling Lee, Chien-Yu Chang and Arbee L.P Chen. Hiding sensitive patterns in association rules mining. The 28th Annual International Computer Software and Applications Conference 9] Y. Lindell and B. Pinkas. Privacy Preserving Data mining. In CRYPTO, pages 36-54, 2000 10] S. R. M. Oliveira and O. R. Za  ane. Privacy Preserving Frequent Itemset Mining. In Proc. of IEEE ICDM  02 Workshop on Privacy Security, and Data Mining 11] S. R. M. Oliveira and O. R. Za  ane. Algorithms for Balancing Priv acy and Knowledge Discovery in Association Rule Mining. IDEAS  03 12] S. R. M. Oliveira and O. R. Za  ane. Protecting Sensitive Knowledge By Data Sanitization, ICDM  03 13] S. R. M. Oliveira, O. R. Za  ane and Y  cel Saygin. Secure Association Rule Sharing, PAKDD-04 14] Benny Pinks. Cryptographic Techniques For Privacy-Preserving D ata Mining. ACM SIGKDD Explorations Newsletter Vol. 4, Is. 2, 2002 15] S. J. Rizvi and J. R. Haritsa. Maintaining data privacy in association rule mining. VLDB, 2002 16] J. Vaidya and C. W. Clifton. Privacy preserving association rule mining in vertically partitioned data. KDD2002 17] Verykios, V.S.; Elmagarmid, A.K.; Bertino, E.; Saygin, Y.; Dasseni E. Association rule hiding. IEEE Transactions On Knowledge And Data Engineering, Vol. 16, No. 4, April 2004 Proceedings of the 29th Annual International Computer Software and Applications Conference  COMPSAC  05 0730-3157/05 $20.00  2005 IEEE pre></body></html 


pre></body></html 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



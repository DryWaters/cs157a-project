Finding Symmetric Association Rules to Support Medical Qualitative Research Razan Paul, Abu Sayed Md. Latiful Hoque Department of Computer Science and Engineering Bangladesh University of Engineering and Technology, Dhaka 1000, Bangladesh razanpaul@yahoo.com, asmlatifulhoque@cse.buet.ac.bd Abstract In medical qualitative research, medical researchers analyze historical patient data to verify known relationships and to discover unknown relationships among medical attributes. All the existing algorithms to solve this problem use measures which are asymmetric measure, so only one direction of the rule\(  P -> Q or Q->P into account. However, medical researchers are interested to find both asymmetric and symmetric relationship among medical attributes. We have developed pruning strategies and devised an efficient algorithm for the symmetric relationship problem We propose measuring interestingness of known symmetric relationships and unknown symmetric relationships via the correlation measure of antecedent items and consequent items. We have demonstrated its effectiveness by testing it on real dataset 1. Introduction In medical qualitative research, medical researchers are interested in finding association rules to see relationship among specified items and to see how a group of items is related with a different group of items. For instance, a medical researcher can discover relationship between the age and the HbA1c% of a patient. Medical researchers are interested to find relationship among various diseases, lab tests, symptoms, etc. Due to high dimensionality of medical data, conventional association mining algorithms [1-8] discover a very high number of rules with many attributes, which are tedious, redundant to medical researchers and not among their desired set of attributes. Medical researchers may need to find the relationship between rare   and high frequent medical items, but 


conventional mining processes for association rules explore interesting relationships between data items that occur frequently together [1-7 Rare item problem is presented in [9]. According to this problem if   minimum support is set too high the algorithms produce rules eliminating all infrequent item sets. On the other hand, if we set minimum support too low, the algorithms produce far too many rules that are meaningless. In order to deal with this problem many algorithms have been proposed to mine rare associations [10-13 However, these algorithms do not find the relationship between rare  and high frequent medical items. In [7], the authors propose few algorithms that allow a user to specify Boolean expressions over the presence or absence of items in association rule or to specify a certain hierarchy [6] of items in association rule. These approaches are not enough to mine desired rules for medical researchers All the existing algorithms [14-18] to discover interesting association rules in medical data only find asymmetric pattern, whereas medical researchers are interested to find both asymmetric and symmetric relationship among medical attributes. For these reasons, we have proposed an association-mining algorithm, which will find rules among the attributes of the researcherV interest, so that it can help in decision making of the researchers. The problem in discovering relationships is to avoid redundant relationships and control the quality of them. This algorithm allows the researchers to define the following constraints:  group information of attributes, minimum confidence and support for each group, which item will appear in antecedent and which item will appear in consequent and which attributes will appear in both. One attribute can belong to several groups 2. Mapping complex medical data to mineable items For knowledge discovery, the medical data have to be transformed into a suitable transaction format to discover knowledge. We have addressed the 


problem of mapping complex medical data to items using domain dictionary and rule base as shown in figure 1. The medical data are types of categorical continuous numerical data, boolean, interval percentage, fraction and ratio. Medical domain 978-1-4244-7571-1/10/$26.00 2010 IEEE 81 experts have the knowledge of how to map ranges of numerical data for each attribute to a series of items For example, there are certain conventions to consider a person is young, adult, or elder with respect to age. A set of rules is created for each continuous numerical attribute using the knowledge of medical domain experts. A rule engine is used to map continuous numerical data to items using these developed rules We have used domain dictionary approach to transform the data, for which medical domain expert knowledge is not applicable, to numerical form. As cardinality of attributes except continuous numeric data are not high in medical domain, these attribute values are mapped to integer values using medical domain dictionaries. Therefore, the mapping process is divided in two phases. Phase 1:  a rule base is constructed based on the knowledge of medical domain experts and dictionaries are constructed for attributes where domain expert knowledge is not applicable, Phase 2:  attribute values are mapped to integer values using the corresponding rule base and the dictionaries          If age <= 12 then 1 If 13<=age<=60 then 2 If 60 <=age then 3 If smoke = y then 1 


If smoke = n then 2 If Sex = M then 1 If Sex = F then 2  Rule Base Actual Data Data suitable for Knowledge Discovery Original value Mapped value Headache  1 Fever 2  Patient ID Age Smoke Diagnosis 1020D 2 1 1 1021D 3 2 2  Patient ID Age Smoke Diagnosis 1020D 33 Yes Headache 1021D 63 No Fever  Actual data Generate dictionary for each categorical attribute Medical domain knowledge Original value Mapped value Yes  1 No 2  Dictionary of Diagnosis attribute Dictionary of 


Smoke attribute Map to integer items using rule base and dictionaries Figure 1. Data transformation of medical data 3. The proposed algorithm The main theme of this algorithm is based on the following two statements. Interesting relationships among various medical attributes are concealed in subsets of the attributes, but do not come out on all attributes taken together. All interesting relationships among various medical attributes have not same support and confidence. The algorithm constructs a candidate   itemsets based on groups constraint and use the corresponding support of each group in candidate selection process to discover all possible desired itemsets of that group. The goals of this algorithm are the following: finding desired rules of medical researcher and running fast. The features of this proposed algorithm are as follows x It allows grouping of attributes to find relationship among medical attributes. This provides control on the search process x Minimum confidence and support can vary from one group to another group x One item can belong to several groups x Attributes are constrained to appear on either antecedent or consequent or both side of the rule x It does not generate subsets on full desired itemset, but generates subsets for items that can appear in both consequent and antecedent x Uninteresting relationships among medical attributes are avoided in the candidate generation phase which reduces number of rules, finds out only interesting relationships and makes the algorithm fast Confidence is not the perfect method to rank symmetric medical relationships because it does not account for the consequent frequency with the antecedent. For the ranking of medical relationship, a direct measure of association rule between variables 


is a perfect scheme. For a medical relationship s ? t s is a group of medical items where each item is constrained to be appear in antecedent or both and t is a group of medical attributes where each item is appear to be in consequent or both. Moreover s ? t = . For this relationship, the support is defined as support = P?s, t? and the confidence is defined as = P?s, t?/P?t? where P is the probability The correlation coefficient \(also known as the ?coefficient between two random variables by measuring the degree of linear interdependency. It is defined by the covariance between the two variables divided by their standard deviations:?st = Cov\(s, t Here Cov\(s, t two variables and ?X and ?Y are stand for standard 82 deviation .The covariance measures how two variables change together Cov?s, t? = P?s, t? ? P?s?P?t As we know, standard deviation is the square root of its variance and variance is a special case of covariance when the two variables are identical.?s = ?Var?s? = ?Cov?s, s P?s, s? ? P?s?P\(s s Similarly, ?t = ?P?t? ? P\(t s t Here P?s, t? is the support of itemset consists of both s and t. Let the support of the itemset be Sst Here p?s? and p?t? is the support of antecedent s and antecedent t respectively. Let the support of antecedent s and consequent t be Ss andSt . The value of Sst , Ss and St are computed during the desired itemset generation of our proposed algorithm. Using these values, we can calculate the correlation of every medical relationship rule between a group of medical items to another group of medical items. The correlation value will indicate medical researchers how strong a medical relationship is in perspective of historical data.  ?st = Sst ? Ss St?Ss ? Ss2 ? St ? St2 So putting the value of ??? , ?? and ?? in association rule generation phase, we have found the single metric, correlation coefficient, to represent how much antecedent and consequent are medically 


related with each other. For each medical relationship or rule, this metric has been used to indicate the degree of strong relationship between a group of items to another group of items to support medical qualitative research. The ranges of values for ??? is between -1 and +1. If two variables are independent then ??? equals 0. When ??? equals +1 the variables are considered perfectly positively correlated. A positive correlation is the evidence of a general tendency that when   a group of  attribute values s for a patient happens, another group of attribute values y for the same patient happens. More positive value means the relationship is more strong When ??? equals -1 the variables are considered perfectly negatively correlated Figure 2 shows the association-mining algorithm to support medical research. Like Apriori, our algorithm is also based on level wise search. The major difference in our proposed algorithm is candidate generation process with Apriori. Each item consists of attribute name and its value. Having retrieved information of a 1-itemset, we make a new 1-itemset   if this 1-itemset is not created already otherwise update its support. The 1-itemset can belong to zero or more groups. 1-itemset   is selected if it has support greater or equal to one of its corresponding group support. As medical attribute value contains patient information that is multidimensional, the algorithm performs the count operation by comparing the value of attributes instead of determining presence or absence of values of attributes to calculate support 3.1. Candidate Generation and Selection The intuition behind candidate generation of all level-wise algorithms like Apriori is based on the following simple fact: Every subset of a frequent itemset is frequent so that they can reduce the number of itemsets that have to be checked However, the idea behind candidate generation of proposed algorithm is   every item in the itemset has to be in the same group. This idea makes the new candidates that consist of items in the same group 


and keeps itemsets consist of both rare items and high frequent items. If all the items in a new candidate set are in the same group, then it is selected as a valid candidate, otherwise the new candidate is not added to valid candidate itemsets Here for each group there are different support and confidence. Each candidate itemset belongs to a particular group. After finding group id of a candidate itemset, the algorithm uses corresponding support for candidate selection where as Apriori uses a single support threshold for all the candidate itemsets. By this way, itemsets are explored which are desired   to medical researchers 3.2. Generating association rules Let AC\(item of three  values: 1 if item   is constrained to be  in the antecedent of a rule, 2 if it  is constrained to be  in the consequent and 0 if it can be in either. Using this function, itemset is partitioned into antecedent set consequent set and both set. Moreover, it does not use subset generation to itemsets to form rules like conventional association mining algorithm; it only uses subset generation to both set. Each subset of both set is added in antecedent part in one rule and is added in consequent part in another rule. Each itemset belongs to a particular group. In addition to there is a different confidence for each group whereas Apriori uses a single confidence for all the itemsets. After finding group id of an itemset, the algorithm uses corresponding confidence to form rules. By this way, rules are explored which are desired of medical researchers 83 Algorithm:  Find itemsets which has high support and are in the same group Input: Data and metadata files Output :  Itemsets which are desired to Medical Researchers 1. K=1 2. Read the metadata about which attributes can only appear in the antecedent of a rule,  can only appear in the consequent and   can appear in either 


3. Read Groups Information along with each group support and confidence from configuration file and make  dictionary , here key is the attribute number and value is a list of group numbers on whcih the corresponding attribute belongs to 4. Ik = Select 1-itemsets that have support greater or equal to one of its corresponding group support 5. While\(Ik ??\f 5.1 K 5.2 CK = Candidate_generation\(Ik-1 5.3 CalculateCandidatesSupport\(Ck 5.4 Ik  = SelectDesiredItemSetFromCandidates\(CK GroupSupports 5.5 I  = I U Ik 6. return I procedure Candidate_generation\(Ik-1: frequent \(k-1 itemsets 1. for each Itemset i1 ?,k-1 1.1for each Itemset i2 ?,k-1 1.1.1 newcandidate, NC = Union\(i1,i2 1.1.2 if  size of  NC  is k 1.1.2.1  isInSameGroup =TestWhetherAll TheItemsInSameGroup\(NC 1.1.2.2  if \(isInSameGroup == true 1.1.2.2.1 add  NC to Ck othewise remove it 2. return Ck  procedure  SelectDesiredItemSetFromCandidates CK, GroupSupports 1.1 j=FindGroupNoWhichHasMinimum SupportIfMultipleGroupsExist \(c 1.2  If c.support >=   GroupSupports[j 1.3 Add it to I 2. return I Algorithm : Find assosiation rules for decision supportability of medical reasearcher Input:  I  : Itemsets , GroupConfidences Output: R: Set of rules 1. R 2. For each X ? I 2.1 j =FindGroupNoWhichHasMinimum 


ConfideceIfMultipleGroupsExist\(X 2.2 Both Set B  = \(b1, b2En X   and AC\(bi QWHFHGHQWVHW$6 DVDVDVQ\f where   asi ?;DQG$&DVi 2.4 Consequent  set CS = \(cs1, cs2FVn where  csi ? X and AC\(csi 2.5 For each subset Y  of  B 2.5.1 Y1 = B-Y 2.5.2 AS1 =AS U Y 2.5.3 CS1 = CS U Y1 2.5.4   if  \(support \(AS1 ? CS1 AS1  2.5.4.1  AS1 ? CS1 is a valid rule 2.5.4.2 R = R U \(AS1 ? CS1 2.5.5 AS2 =AS U Y1 2.5.6 CS2 = CS U Y 2.5.7   if  \(support \(AS2 ? CS2 AS2  2.5.7.1  AS2 ? CS2 is a valid rule 2.5.7.2 R = R U \(AS2 ? CS2 Figure 2: Association mining algorithm to support medical research 3.2.1. Lemma 1. Number of rules is equal to   ? 2L\(D2i itemsets and L is function, which determines number of items in an itemset. D2 is the both set. Number of discarded rules =  mp ? ? 2L\(D2i Proof: Let I = {i1, i2Ln} be the set of items. Let G= {g1,g2,g3Jq} be the set of groups.  Let R r1,r2,r3Us} be the set of restrictions. GS is the function, which finds groups with the smallest confidence. If not all items are in the same group, the GS returns NULL. 1-itemset is selected if S\( 1itemset GS\(1-itemset which returns support for an itemset. Let C= {c1, c2 c3Fx} be the set of  candidate itemsets. A new candidate NC is added to C LI*61&\f?18 ci is selected for rule generation if S\(C GS\(C three parts. D = {D0, D1, D2}. D0 is mapped to anticipated items, D1 is mapped to consequent items D2 is mapped to both. Each subset of D2, d, is added to both antecedent and consequent. When d is added 


to antecedent then D2-d is added to consequent. On the other hand, when d is added to consequent then D2-d is added to antecedent. L is a function, which determines number of items in a itemset. Number of rules from D =2?\(?2 2 itemsets. Let m is the average number of distinct value, each multidimensional attribute holds. P is the number of attributes. Number of possible different rules = ?? . Number of discarded rules =  ?? ?? 2?\(?2 4. Results and discussion The experiments were done using PC with core 2 duo processor with a clock rate of 1.8 GHz and 3GB of main memory. The operating system was Microsoft Vista and implementation language was c#.  We used 1 dataset to verify our method. The data set of interest is patient dataset collected and preprocessed from Bangladeshi hospitals, which has 50273 instances and 514 attributes \(included 150 discrete and 364 numerical attributes categories of healthcare data: ratio, interval, decimal integer, percentage etc. All these data are converted into mineable items \(integer representation domain dictionary and rule base. We have taken an 84 average value from 10 trials for each of the test result Table 1. Test result for patient dataset Number of groups 4 8 Support for  each group .55 64 76,.45 47,.84, .66 55,.85, .94 86,.35 Correlation for each group .71 41 51,.61 63, .85,.82 76,.91, .73 82, .71 Number of Items to be constrained in antecedent for 


each group 4,4,4,4 5,4,5,6 4,5,5,7 Number of Items to be constrained in consequent  for each group 1,2,2,1 1,2,2,1 1,2,2,1 Number of Items to be constrained in both for each group 0,0,0,0 1,1,1,1 1,1,1,0 Total number of desired itemsets 125 311 Total number of desired rules 21 28 Time\(Seconds Table 1 shows test result for patient dataset, after running the program of the  proposed algorithm with different parameters. Second column of the table presents the test result, where we used 4 groups minimum support of 45%-76% and correlation of 41-.71 to mine symmetric association rules for medical researcher. The maximum number of items in a rule  was 6.  125 desired itemsets were generated in total. 21 rules were discovered in total. It took about 3461 seconds to find these rules. Third column of the table presents the test result, where we used 8 groups, minimum support of 35%-94% and correlation of .63-.91 to mine symmetric association rules for medical researcher. The maximum number of items in a rule  was 8. 311 desired itemsets were generated in total. 28 rules were discovered in total It took about 11122 seconds to find these rules Figure 3: Time comparison of the proposed algorithms for the patient dataset based on number of groups Figure 3 shows how time is varied with different number of groups for the medical research algorithm We measured the performance of Medical Research algorithm in terms of number of groups keeping group size constant, support and confidence of each group constant, antecedent and consequent 


constrains on attributes constant. Time is not varied significantly because the number of groups has no lead to reduce disk access. This is because number of groups has no lead to the number of candidate generations phases and to the number of support calculation phases. The number of groups has only lead to the number of valid candidate generations and it can save some CPU time Figure 4: Time comparison of the proposed algorithms for the patient dataset based on Group Size Figure 4 shows how time is varied with different group size for medical research algorithm. Here we measured the performance of Medical Research algorithm in terms of group size keeping number of groups constant, support and confidence of each group constant, antecedent and consequent constrains on attributes constant. Time is varied significantly because group size has lead to reduce disk access. This is because group size has   lead to the number of candidate generations phases and to the number of support calculation phases Figure 5: Accuracy of test result for the patient dataset based on correlation Figure 5 illustrates accuracy results for our proposed algorithm. The value of correlation for each presented result is also indicated. For accuracy measurement, we intentionally discovered relationships among attributes for which trends are known. Here we calculated accuracy as the ratio between the number of correct discovered relationships and total number of discovered relationships. A discovered relationship is correct if it is one of the known trends of medical domain. It shows that an average accuracy of 55% is achieved with correlation 0.5. The proposed algorithm with correlation 0.7 achieves an average accuracy of 85.66%. The proposed algorithm with correlation 0.7 achieves an average accuracy of 94.66%. As 0 1000 2000 


4 8 12 T im e S e co n d s Number of Groups Group Size 4 Group Size 10 Group Size 18 0 2000 4 8 12 T im e S e co n d s Group Size 4 Groups 8Groups 12 Groups 0 0.5 1 0.5 0.7 0.85 A cc u ra cy Correlation Group Size 4 Group size 10 Group Size 18 85 accuracy refers to the rate of correct values in the data, the figure represents the success of our 


proposed  data mining algorithm 5. Conclusion Medical Researchers are interested to find relationship among various diseases, lab tests symptoms, etc. Due to high dimensionality of medical data, conventional association mining algorithms discover a very high number of rules with many attributes, which are tedious, redundant to medical researchers and not among their desired set of attributes. In this paper, we have proposed an association rule mining algorithm for finding symmetric association rules to support medical qualitative research. The main theme of this algorithm is based on the following two statements interesting relationships among various medical attributes are concealed in subsets of the attributes but do not come out on all attributes taken together and all interesting relationships among various medical attributes have not same support and correlation. The algorithm constructs a candidate item sets based on groups constraint and use the corresponding support of each group in candidate selection process to discover all possible desired item sets of that group. We propose measuring interestingness of known symmetric relationships and unknown symmetric relationships via the correlation measure of antecedent items and consequent items. The proposed algorithm has been applied to a real world medical data set. We have shown significant accuracy in the output of the proposed algorithm. Although we have used levelwise search for finding symmetric association rules each step of our algorithm is different from any level-wise search algorithm. Rules generation from desired item sets is also different from conventional association mining algorithms 6. References 1] R. Agrawal and R. Srikant, "Fast Algorithms for Mining Association Rules in Large Databases," in Proceedings of the 20th International Conference on Very Large Data Bases, San Francisco, CA, USA 1994, pp. 487 - 499 


2] S. Brin, R. Motwani, J. D. Ullman, and S. Tsur Dynamic Itemset Counting and Implication Rules for Market Basket Data," in Proceedings of the 1997 ACM SIGMOD international conference on Management of data, Tucson, Arizona, United States 1997, pp. 255-264 3] J. S. Park, M. S. Chen, and P. S. Yu, "An Effctive Hash based Algorithm for mining association rules in Prof. ACM SIGMOD Conf Management of Data New York, NY, USA, 1995, pp. 175 - 186 4] R. Agrawal, T. ,PLHOL?VNL DQG $. Swami, "Mining Association Rules between Sets of Items in Very Large Databases," in Proceedings of the 1993 ACM SIGMOD international conference on Management of data, Washington, D.C., 1993, pp. 207-216 5] H. Mannila, H. Toivonen, and A. I. Verkamo Efficient Algorithms for Discovering Association Rules," in AAAI Workshop on Knowledge Discovery in Databases, 1994, pp. 181-192 6] R. Srikant and R. Agrawal, "Mining Generalized Association Rules," in In Proc. of the 21st Int'l Conference on Very Large Databases, Zurich Switzerland, 1995 7] R. Srikant, Q. Vu, and R. Agrawal, "Mining association rules with item constraints," in In Proc 3rd Int. Conf. Knowledge Discovery and Data Mining, 1997, pp. 67--73 8] A. Savasere, E. Omiecinski, and S. B. Navathe, "An Efficient Algorithm for Mining Association Rules in Large Databases," in Proceedings of the 21th International Conference on Very Large Data Bases 1995, pp. 432 - 444 9] H. Mannila, "Database methods for data mining," in The Fourth International Conference on Knowledge Discovery and Data Mining, 1998 10] B. Liu, W. Hsu, and Y. Ma, "Mining Association Rules with Multiple Minimum Supports.," in SIGKDD Explorations, 1999, pp. 337--341 11] H. Yun, D. Ha, B. Hwang, and K. H. Ryu, "Mining association rules on significant rare data using relative support.," Journal of Systems and Software archive vol. 67, no. 3, pp. 181 - 191, 2003 


12] M. Hahsler, "A Model-Based Frequency Constraint for Mining Associations from Transaction Data Data Mining and Knowledge Discovery, vol. 13, no 2, pp. 137 - 166, 2006 13] L. Zhou and S. Yau, "Association rule and quantitative association rule mining among infrequent items," in International Conference on Knowledge Discovery and Data Mining, San Jose, California 2007, pp. 156-167 14] C. Ordonez, C. Santana, and L. d. Braal, "Discovering Interesting Association Rules in Medical Data," in Proccedings of ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery, 2000, pp. 78-85 15] L. J. Sheela and V. Shanthi, "DIMAR - Discovering interesting medical association rules form MRI scans," in 6th International Conference on Electrical Engineering/Electronics, Computer Telecommunications and Information Technology 2009, pp. 654 - 658 16] C. Ordonez, N. Ezquerra, and C. A. Santana Constraining and summarizing association rules in medical data," Knowledge and Information Systems vol. 9, no. 3, pp. 259 - 283, September 2005 17] H. Pan, J. Li, and Z. Wei, "Mining Interesting Association Rules in Medical Images," Lecture Notes In Computer Science, vol. 3584, pp. 598-609, 2005 18] S. Doddi, A. Marathe, S. S. Ravi, and D. C Torney Discovery of association rules in medical data Medical Informatics and the Internet in Medicine, vol 26, no. 1, pp. 25-33, January 2001 86 


the time needed for execution exceeded 100000 seconds Thus, from this analysis we see that FPrep, which uses FCM clustering, clearly outperforms the CLARANS and CURE based methods on the basis of speed. The execution times for CLARANS and CURE mentioned in fig. 7 and Table II do not include the time required to create fuzzy sets, and calculate the membership value  for each numerical data point in every fuzzy set for the numerical attribute under consideration. These times also do not take into account the time required to transform crisp numerical attributes to fuzzy attributes, and derive the fuzzy dataset from the original crisp dataset The fuzzy partitions generated for each of the five numerical attributes for the USCensus1990raw dataset are shown in Table III. Coincidentally, generating three fuzzy partitions for each numerical attribute seemed a perfect fit In addition to the superior speeds achieved by FPrep, as illustrated in fig. 7 and Table II, Table III indicates the semantics and the quality of the fuzzy partitions generated by FPrep. Moreover, the number of frequent itemsets generated by a fuzzy ARM algorithm \(like fuzzy ARMOR and fuzzy Apriori minimum support threshold, is illustrated in fig. 8   Fig. 7. Algorithm, numerical attribute comparison based on speed \(log10 seconds   Fig. 8. Number of frequent itemsets for various minimum support values  B. Results from Second Dataset We have also applied FPrep on the FAM95 dataset http://www.stat.ucla.edu/data/fpp transactions. Of the 23 attributes in the dataset, we have used the first 18, of which six are quantitative and the rest are binary. For each of the six quantitative attributes, we have generated fuzzy partitions using FPrep. A thorough analysis with respect to execution times, has already been performed on the USCensus1990raw dataset \(which is manifolds bigger in size than the FAM95 dataset both on the basis of number of transactions and number of unique values for numerical 


attributes dataset has been done solely to provide further evidence of the quality and semantics of the fuzzy partitions generated by FPrep. The details of the same are in Table IV. In this case, the number of fuzzy partitions is different for different numerical attributes. Thus, the number and type of fuzzy partitions to be generated is totally dependent on the attribute under consideration. A graphical representation of the fuzzy partitions generated for the attribute Age has already been provided in fig. 5, and clearly shows the Gaussian nature of the fuzzy partitions. The nature and shapes of fuzzy partitions for the rest of the attributes are also similar. Last, the number of frequent itemsets generated for different minimum support values is illustrated in fig. 8  C. Analysis of Results With FPrep, we can analyze and zero in on the number and type of partitions required based on the semantics of the numerical attributes, which the methods detailed in [19 20] do not necessarily facilitate. Then, FPrep, backed by FCM clustering, takes care of the creating the fuzzy partitions, especially assigning membership values for each numerical data point in each fuzzy partition. In section 8.A we have already shown that FPrep is nearly 9 to 44 times faster than the CURE-based method, and 2672 to 13005 times faster than the CLARANS-based method. FPrep is not only much faster than other related methods, but also generates very high quality fuzzy partitions \(Table III and IV much user-intervention. We have created a standard way of representing any fuzzy dataset \(converted from any type of crisp dataset efficacy of the same is corroborated by the successful implementation of Fuzzy Apriori and Fuzzy ARMOR on the fuzzy dataset \(converted from crisp version of FAM95 dataset an initial implementation of Fuzzy ARMOR, are very encouraging. FPrep, when used in conjunction with these fuzzy ARM algorithms, generates a pretty good number of high-quality frequent itemsets \(fig. 8 frequent itemsets generated for a particular minimum support is same, irrespective of the fuzzy ARM algorithm 


used IX. CONCLUSIONS In this paper we have highlighted our methodology, called FPrep, for ARM in a fuzzy scenario. FPrep is meant for seamlessly and holistically transforming a crisp dataset into a fuzzy dataset such that it can drive a subsequent fuzzy ARM process. It does not rely on any non-fuzzy techniques and is thus more straightforward, fast, and consistent. It facilitates user-friendly automation of fuzzy dataset 1 0 1 2 3 4 5 Age - 91 Hours - 100 Income3 4949 Income2 13707 Income1 55089 Ti m e lo g1 0 se co nd s Numerical Attribute - Number of Unique Values FCM CURE CLARANS 0 500 1000 1500 2000 2500 


3000 0.075 0.1 0.15 0.2 0.25 0.3 0.35 0.4 N o o f F re qu en t I te m se ts Minimum Support USCensus1990 FAM95 generation through FCM, and subsequent steps in preprocessing with very less manual intervention and as simple and straightforward manner as possible. This methodology involves two distinct steps, namely creation of appropriate fuzzy partitions using fuzzy clustering and creation of fuzzy records, using these partitions, to get the fuzzy dataset from the original crisp dataset FPrep has been compared with other such techniques, and has been found to better on the basis of speed. We also illustrate its efficacy on the basis of quality of fuzzy partitions generated and the number of itemsets mined by a fuzzy ARM algorithm which is preceded by FPrep. This preprocessing technique provides us with a standard method of fuzzy data \(record that it is useful for any kind of fuzzy ARM algorithm irrespective of how the algorithm works. Furthermore, this pre-processing methodology has been adequately tested with two disparate fuzzy ARM algorithms, Fuzzy Apriori and Fuzzy ARMOR, and would also work fine with other fuzzy ARM algorithm REFERENCES 1] Zadeh, L. A.: Fuzzy sets. Inf. Control, 8, 338358 \(1965 2] Chen G., Yan P., Kerre E.E.: Computationally Efficient Mining for Fuzzy Implication-Based Association Rules in Quantitative Databases. International Journal of General Systems, 33, 163-182 


2004 3] Hllermeier, E.: Fuzzy methods in machine learning and data mining Status and prospects. Fuzzy Sets and Systems. 156, 387-406 \(2005 4] De Cock, M., Cornelis, C., Kerre, E.E.: Fuzzy Association Rules: A Two-Sided Approach. In: FIP, pp 385-390 \(2003 5] Yan, P., Chen, G., Cornelis, C., De Cock, M., Kerre, E.E.: Mining Positive and Negative Fuzzy Association Rules. In: KES, pp. 270-276 Springer \(2004 6] De Cock, M., Cornelis, C., Kerre, E.E.: Elicitation of fuzzy association rules from positive and negative examples. Fuzzy Sets and Systems, 149, 7385 \(2005 7] Verlinde, H., De Cock, M., Boute, R.: Fuzzy Versus Quantitative Association Rules: A Fair Data-Driven Comparison. IEEE Transactions on Systems, Man, and Cybernetics - Part B: Cybernetics 36, 679-683 \(2006 8] Dubois, D., Hllermeier, E., Prade, H.: A systematic approach to the assessment of fuzzy association rules. Data Min. Knowl. Discov., 13 167-192 \(2006 9] Dubois, D., Hllermeier, E., Prade, H.: A Note on Quality Measures for Fuzzy Association Rules. In: IFSA, pp. 346-353. Springer-Verlag 2003 10] Hllermeier, E., Yi, Y.: In Defense of Fuzzy Association Analysis IEEE Transactions on Systems, Man, and Cybernetics - Part B Cybernetics, 37, 1039-1043 \(2007 11] Agrawal, R., Imielinski, T., Swami, A.N.: Mining Association Rules between Sets of Items in Large Databases. SIGMOD Record, 22, 207216 \(1993 12]  Agrawal, R., Srikant, R.: Fast Algorithms for Mining Association Rules. In: VLDB, pp. 487-99. Morgan Kaufmann \(1994 13] Han, J., Pei, J., Yin, Y.: Mining Frequent Patterns without Candidate Generation. In: SIGMOD Conference, pp. 1-12. ACM Press \(2000 14] Han, J., Pei, J., Yin, Y., Mao, R.: Mining Frequent Patterns without Candidate Generation: A Frequent-Pattern Tree Approach. Data Mining and Knowledge Discovery, 8, 5387 \(2004 15] Pudi V., Haritsa J.R.: ARMOR: Association Rule Mining based on Oracle. CEUR Workshop Proceedings, 90 \(2003 16] Dunn, J. C.: A Fuzzy Relative of the ISODATA Process and its Use in Detecting Compact, Well Separated Clusters. J. Cyber., 3, 32-57 1974 17] Hoppner, F., Klawonn, F., Kruse, R, Runkler, T.: Fuzzy Cluster Analysis, Methods for Classification, Data Analysis and Image Recognition. Wiley, New York \(1999 


18] Bezdek J.C.: Pattern Recognition with Fuzzy Objective Function Algorithms. Kluwer Academic Publishers, Norwell, MA \(1981 19] Fu, A.W., Wong, M.H., Sze, S.C., Wong, W.C., Wong, W.L., Yu W.K. Finding Fuzzy Sets for the Mining of Fuzzy Association Rules for Numerical Attributes. In: IDEAL, pp. 263-268. Springer \(1998 20] Kaya, M., Alhajj, R., Polat, F., Arslan, A: Efficient Automated Mining of Fuzzy Association Rules. In: DEXA, pp. 133-142. Springer \(2002 21] Mangalampalli, A., Pudi, V. Fuzzy Association Rule Mining Algorithm for Fast and Efficient Performance on Very Large Datasets In FUZZ-IEEE, pp. 1163-1168. IEEE \(2009 22] Kaya, M., Alhajj. Integrating Multi-Objective Genetic Algorithms into Clustering for Fuzzy Association Rules Mining. In ICDM, pp. 431434. IEEE \(2004  Table II. Algorithm, numerical attribute comparison based on speed \(seconds  Algorithm Age - 91 Hours - 100 Income3 - 4949 Income2 - 13707 Income1 - 55089 FCM 0.27 0.3 3.13 6.28 79.4 CURE 0.25 0.25 28.67 163.19 3614.13 CLARANS 1.3 1.34 8363.53 78030.3 Table III. Attributes and their fuzzy partitions  Attribute Fuzzy Partitions Age Old Middle Aged Young Hours More Average Less Income1 High Medium Low Income2 High Medium Low Income3 High Medium Low  Table IV. Attributes and their fuzzy partitions  Attribute Fuzzy Partitions AGE Very old Around 25 Around 50 Around 65 Around 35 HOURS Very High Zero Around 40 Around 25 INCHEAD Very less Around 30K Around 50K Around 100K INCFAM Around 60K Around 152K Around 96K Around 31K Around 8K TAXINC Around 50K Around 95K Around 20K Very less FTAX Around 15K Very less Around 6K Very high Around 33K  


the US census data set. The size of pilot sample is 2000, and all 50 rules are derived from this pilot sample. In this experiment the ?xed value x for the sample size is set to be 300. The attribute income is considered as a differential attribute, and the difference of income of husband and wife is studied in this experiment. Figure 3 shows the performance of the 5 sampling 331 6DPSOLQJ9DULDQFH             9D UL DQ FH R I V WL PD WL RQ  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW    


      6D PS OL QJ  RV W 9DU 9DU 9DU 5DQG b 6DPSOLQJ$FFXUDF          5  9DU 9DU 9DU 5DQG c Fig. 2. Evaluation of Sampling Methods for Association Rule Mining on the Yahoo! Dataset procedures on the problem of differential rule mining on the US census data set. The results are also similar to the experiment results for association rule mining: there is a consistent trade off between the estimation variance and sampling cost by setting their weights. Our proposed methods have better performance than simple random sampling method 


We also evaluated the performance of our methods on the Yahoo! dataset. The size of pilot sampling is 2000, and the xed value x for the sample size is 200. The attribute price is considered as the target attribute. Figure 4 shows the performance of the 5 sampling procedures on the problem of differential rule mining on the Yahoo! dataset. The results are very similar to those from the previous experiments VI. RELATED WORK We now compare our work with the existing work on sampling for association rule mining, sampling for database aggregation queries, and sampling for the deep web Sampling for Association Rule Mining: Sampling for frequent itemset mining and association rule mining has been studied by several researchers [23], [21], [11], [6]. Toivonen [23] proposed a random sampling method to identify the association rules which are then further veri?ed on the entire database. Progressive sampling [21], which is based on equivalence classes, involves determining the required sample size for association rule mining FAST [11], a two-phase sampling algorithm, has been proposed to select representative transactions, with the goal of reducing computation cost in association rule mining.A randomized counting algorithm [6] has been developed based on the Markov chain Monte Carlo method for counting the number of frequent itemsets Our work is different from these sampling methods, since we consider the problem of association rule mining on the deep web. Because the data records are hidden under limited query interfaces in these systems, sampling involves very distinct challenges Sampling for Aggregation Queries: Sampling algorithms have also been studied in the context of aggregation queries on large data bases [18], [1], [19], [25]. Approximate Pre-Aggregation APA  categorical data utilizing precomputed statistics about the dataset Wu et al. [25] proposed a Bayesian method for guessing the extreme values in a dataset based on the learned query shape pattern and characteristics from previous workloads More closely to our work, Afrati et al. [1] proposed an adaptive sampling algorithm for answering aggregation queries on hierarchical structures. They focused on adaptively adjusting the sample size assigned to each group based on the estimation error in each group. Joshi et al.[19] considered the problem of 


estimating the result of an aggregate query with a very low selectivity. A principled Bayesian framework was constructed to learn the information obtained from pilot sampling for allocating samples to strata Our methods are clearly distinct for these approaches. First strata are built dynamically in our algorithm and the relations between input and output attributes are learned for sampling on output attributes. Second, the estimation accuracy and sampling cost are optimized in our sample allocation method Hidden Web Sampling: There is recent research work [3 13], [15] on sampling from deep web, which is hidden under simple interfaces. Dasgupta et al.[13], [15] proposed HDSampler a random walk scheme over the query space provided by the interface, to select a simple random sample from hidden database Bar-Yossef et al.[3] proposed algorithms for sampling suggestions using the public suggestion interface. Our algorithm is different from their work, since our goal is sampling in the context of particular data mining tasks. We focus on achieving high accuracy with a low sampling cost for a speci?c task, instead of simple random sampling VII. CONCLUSIONS In this paper, we have proposed strati?cation based sampling methods for data mining on the deep web, particularly considering association rule mining and differential rule mining Components of our approach include: 1 the relation between input attributes and output attributes of the deep web data source, 2 maximally reduce an integrated cost metric that combines estimation variance and sampling cost, and 3 allocation method that takes into account both the estimation error and the sampling costs Our experiments show that compared with simple random sampling, our methods have higher sampling accuracy and lower sampling cost. Moreover, our approach allows user to reduce sampling costs by trading-off a fraction of estimation error 332 6DPSOLQJ9DULDQFH      


     V WL PD WL RQ R I 9D UL DQ FH  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW          6D PS OL QJ  RV W 9DU 9DU 


9DU 5DQG b 6DPSOLQJ$FFXUDF          5  9DU 9DU 9DU 5DQG c Fig. 3. Evaluation of Sampling Methods for Differential Rule Mining on the US Census Dataset 6DPSOLQJ9DULDQFH             9D UL DQ FH R I V WL 


PD WL RQ  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW          6D PS OL QJ  RV W  9DU 9DU 9DU 5DQG b 6DPSOLQJ$FFXUDF         


    5  9DU 9DU 9DU 5DQG c Fig. 4. Evaluation of Sampling Methods for Differential Rule Mining on the Yahoo! Dataset REFERENCES 1] Foto N. Afrati, Paraskevas V. Lekeas, and Chen Li. Adaptive-sampling algorithms for answering aggregation queries on web sites. Data Knowl Eng., 64\(2 2] Rakesh Agrawal and Ramakrishnan Srikant. Fast algorithms for mining association rules. In Proceedings of the 20th International Conference on Very Large Data Bases, pages 487499, 1994 3] Ziv Bar-Yossef and Maxim Gurevich. Mining search engine query logs via suggestion sampling. Proc. VLDB Endow., 1\(1 4] Stephen D. Bay and Michael J. Pazzani. Detecting group differences Mining contrast sets. Data Mining and Knowledge Discovery, 5\(3 246, 2001 5] M. K. Bergman. The Deep Web: Surfacing Hidden Value. Journal of Electronic Publishing, 7, 2001 6] Mario Boley and Henrik Grosskreutz. A randomized approach for approximating the number of frequent sets. In ICDM 08: Proceedings of the 2008 Eighth IEEE International Conference on Data Mining, pages 4352 Washington, DC, USA, 2008. IEEE Computer Society 7] D. Braga, S. Ceri, F. Daniel, and D. Martinenghi. Optimization of Multidomain Queries on the Web. VLDB Endowment, 1:562673, 2008 8] R. E. Ca?isch. Monte carlo and quasi-monte carlo methods. Acta Numerica 7:149, 1998 9] Andrea Cali and Davide Martinenghi. Querying Data under Access Limitations. In Proceedings of the 24th International Conference on Data Engineering, pages 5059, 2008 10] Bin Chen, Peter Haas, and Peter Scheuermann. A new two-phase sampling based algorithm for discovering association rules. In KDD 02: Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 462468, New York, NY, USA, 2002 ACM 


11] W. Cochran. Sampling Techniques. Wiley and Sons, 1977 12] Arjun Dasgupta, Gautam Das, and Heikki Mannila. A random walk approach to sampling hidden databases. In SIGMOD 07: Proceedings of the 2007 ACM SIGMOD international conference on Management of data pages 629640, New York, NY, USA, 2007. ACM 13] Arjun Dasgupta, Xin Jin, Bradley Jewell, Nan Zhang, and Gautam Das Unbiased estimation of size and other aggregates over hidden web databases In SIGMOD 10: Proceedings of the 2010 international conference on Management of data, pages 855866, New York, NY, USA, 2010. ACM 14] Arjun Dasgupta, Nan Zhang, and Gautam Das. Leveraging count information in sampling hidden databases. In ICDE 09: Proceedings of the 2009 IEEE International Conference on Data Engineering, pages 329340 Washington, DC, USA, 2009. IEEE Computer Society 15] Loekito Elsa and Bailey James. Mining in?uential attributes that capture class and group contrast behaviour. In CIKM 08: Proceeding of the 17th ACM conference on Information and knowledge management, pages 971 980, New York, NY, USA, 2008. ACM 16] E.K. Foreman. Survey sampling principles. Marcel Dekker publishers, 1991 17] Ruoming Jin, Leonid Glimcher, Chris Jermaine, and Gagan Agrawal. New sampling-based estimators for olap queries. In ICDE, page 18, 2006 18] Shantanu Joshi and Christopher M. Jermaine. Robust strati?ed sampling plans for low selectivity queries. In ICDE, pages 199208, 2008 19] Bing Liu. Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data \(Data-Centric Systems and Applications Inc., Secaucus, NJ, USA, 2006 20] Srinivasan Parthasarathy. Ef?cient progressive sampling for association rules. In ICDM 02: Proceedings of the 2002 IEEE International Conference on Data Mining, page 354, Washington, DC, USA, 2002. IEEE Computer Society 21] William H. Press and Glennys R. Farrar. Recursive strati?ed sampling for multidimensional monte carlo integration. Comput. Phys., 4\(2 1990 22] Hannu Toivonen. Sampling large databases for association rules. In The VLDB Journal, pages 134145. Morgan Kaufmann, 1996 23] Fan Wang, Gagan Agrawal, Ruoming Jin, and Helen Piontkivska. Snpminer A domain-speci?c deep web mining tool. In Proceedings of the 7th IEEE International Conference on Bioinformatics and Bioengineering, pages 192 199, 2007 24] Mingxi Wu and Chris Jermaine. Guessing the extreme values in a data set a bayesian method and its applications. VLDB J., 18\(2 25] Mohammed J. Zaki. Scalable algorithms for association mining. IEEE Transactions on Knowledge and Data Engineering, 12:372390, 2000 


333 



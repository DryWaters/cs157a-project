Improving Information Retrieval Precision by Finding Related Queries with similar Information Need using Information Scent  Suruchi Chawla  Research Scholar  Dr Punam Bedi  Reader   sur_chawla@rediffmail.com  pbedi@cs.du.ac.in    Abstract  Web is a valuable source of information and it is expanding at an enormous speed. Search engines provide the interface to access to this vast pool of information. Users express their information need 
through the input query to retrieve the relevant information which does not prove to be effective as input query entered by the user is too short to get the information need of the user. To retrieve the information according to a particular information need from a big pool of information available on the web is a big challenge. This paper proposes a method to find the related queries which approximate the information need of the input query issued to the search engine This is accomplished using Information scent and content of clicked pages in query sessions mining Information scent is derived from the Information 
Foraging theory in which user behavior in the information environment is guided by information scent. Information Need of the query sessions is modeled using Information Scent and content of clicked URLs and query sessions with similar information need are clustered. The clusters which closely approximate the information need of input query are used to suggest queries with similar information need for a given input query. The suggested queries are ranked in order of their degree of relevance with respect to information need of the input query.  Retrieval   precision of search engine is 
improved as suggested queries help to retrieve document relevant to the need of user efficiently and quickly. Experimental study has been conducted on the dataset collected from "Google" search engine Web History to confirm the improvement of precision of Information Retrieval   Key Words  Information Scent, Information Retrieval, Clustering, Search engine  1  Introduction Current search engines retrieve too many documents of which only a small fraction is relevant to 
a user query N o w a da y t h e w e b s e a r c h e n g i n e s  provide the user-friendly interface by which user can issue queries that are simply a list of keywords. From a study of the log of a popular search engine in i t w a s  concluded that most queries are short and imprecise Due to ambiguity of query terms and short length of query, keywords of query could not determine the information need associated to the query. As a result many documents are retrieved which are not relevant to the input query and retrieval precision is degraded 
In order to overcome this problem work has been done in [4 w h ic h i m p r o v e th e  i n f o r m a tio n  r e t r ie v a l precision by recommending set of similar queries in response to the input query and set of suggested queries are ranked according to the relevance criterion but it is realized that precision can be improved further if recommended queries are selected using the information need of past query sessions issued on the search engine. According to the information foraging theory the user is guided in the information 
environment by information scent. Users tend to click those retrieved pages in search results which match their information need and those pages have Information scent associated with it with respect to their information need. More the page is satisfying the information need of user, more will be the information scent associated to it. High Information Scent pages are more relevant than low scent pages with respect to the information need of the user. Information need of the query sessions is accessed not only from content 
but also from information scent of clicked page with respect to the information need of user which is not considered in [4  I n  1 0  co n cep t o f I n f o r m a t i o n S cen t is introduced in the field of information retrieval to improve the precision by improving the rank of those pages in result set which are relevant to the user information need. In this paper the Information scent is 
First International Conference on Emerging Trends in Engineering and Technology 978-0-7695-3267-7/08 $25.00 © 2008 IEEE DOI 10.1109/ICETET.2008.23 486 


used to infer the information need of the query sessions using Information Scent of the clicked pages in the query sessions and related queries are recommended using the query sessions with the similar information need. Information Scent is used to infer the information need of the query session by identifying the high and low scent clicked documents as every document clicked by the user in the query session is not equally relevant to the information need of query session some clicked documents are more relevant to information need of query session than others which is captured through information scent. Information Scent is used to access the relevancy of the clicked page with respect to the information need of the user. The solution proposed in this paper is used to model the information need of the query sessions using information scent and content of clicked URLs in the sessions. Information Scent helps to infer the information need of the query session using the uniqueness of frequently clicked documents in the session associated with the query. Query sessions modeled using information scent and content of clicked URLs are clustered to generate clusters of query sessions where each cluster represent a unique information need. The input query is then used to select the clusters which closely represent the information need of the input query. The selected clusters contain set of queries similar in information need to be used as recommendation to the user. Web history of “Google” search engine keep track of queries and URLs selected by users when they are finding useful data through the search engines. The data is extracted from the web history and loaded into database which is preprocessed to find the query sessions. The query sessions modeled using Information Scent and content of clicked URLs are clustered to group the query sessions with similar information need. During online searching the queries are recommended in order of their relevancy with respect to the information need of input query Recommended queries help the user to find the relevant documents which are closed to his needs and which he could not get from initial query issued. The recommended queries are those queries which are different from initial query in term of keywords used but they are satisfying the information need similar to initial query. This paper is organized as follows Section 2 describes the Information Scent, Section 3 explains the Clustering Query sessions with similar Information Need using Information Scent, Section 4 gives the proposed algorithm for Improving the Information Retrieval precision using Related Queries with similar Information Need, Experimental Study is presented in Section 5 and Section 6 Concludes the paper  2. Information Scent On the web, users search for information by navigating from page to page along the web links Their actions are guided by their information need Information scent is the subjective sense of value and cost of accessing a page based on perceptual cues with respect to the information need of user. More the page is satisfying the information need of user, more will be the information scent associated to it. The interaction between user needs, user action and content of web can be used to infer information need from a pattern of surfing  8  9   2.1. Information Scent Metric The Inferring User Need by Information Scent IUNIS  s  us e d i n  t h e p r o p o s e d a ppr o a c h t o  weigh each clicked page vector in query sessions using the combined effect of two factors. The factors are page access PF.IPF weight and TIME both of them are used to quantify the information scent associated with the page. In page access PF.IPF the PF is the access frequency of the clicked page in the given query session and the IPF is the ratio of total query sessions in the log to the number of query sessions in which this page is clicked. This helps to reduce the Information Scent of those pages that are accessed in many query sessions and may not be very relevant to the information need associated with the current query session. The second factor that is taken is Time spent on a page in a given query session. By including the time more weightage is given to those pages that consume more user attention. The information scent s id is calculated for each page P id  in a given query session Q i as follows  id s  1..n d  Pid  Time   Pid  PF.IPF 001 002 1   log\(M/m   max\(f f  PF.IPF\(P Pid Pid Pid id    d 002 1..n                   \(2   PF.IPF\(P id PF correspond to the page P id normalized frequency f Pid in a given query session Q i  and IPF correspond to the ratio of total number of query  sessions M in the whole log to the number of query sessions m Pid that contain the given page P id   Time\(P id It is the ratio of time spent on the page P id in a given session Q i to the total duration of session Q i   
487 


3. Clustering Query sessions with similar Information Need using Information Scent Clustering is the process of grouping the data into classes or clusters so that objects within a cluster have high similarity in comparison to one another, but are very dissimilar to objects in other clusters Dissimilarities are accessed based on attribute values describing the objects. In this paper weighted query session vector is used for clustering where each page P id in query session Q i is defined as follows  P id Content id for each document id  Content id The content vector of a page P id is a weighted keyword vector \(w 1,id w 2,id w 3,id w v,id  where v is the number of terms in the vocabulary set V describing the content of the page P id Vector Model [3 i s u s ed f o r  r e p r es en t i n g co n t e n t feature of each page P id in all query sessions. Each page P id is represented by vector w 1,id w 2,id w 3,id w v,id where v is the number of terms in the vocabulary set V TF.IDF \(term frequency * inverse document frequency\ term weighing scheme is used to represent the content vector for a given page P id  T h e  importance of each item of V in a given page P id is calculated using TF.IDF item weight. Vocabulary V is a set of distinct terms found in all distinct clicked pages in whole dataset relevant to a content feature The TF.IDF term weight is calculated as number of times a term appears in the given page weighted by the ratio of the number of all pages to the number of the pages that contain the given item The information scent associated with the given clicked page is calculated by using two factors i.e PF.IPF page access and TIME. Each query session is constructed as linear combination of vector of each page P id scaled by the weight s id which is the information scent associated with the page P id in session i. That is  n Q i  000 s id P id 3 d=1 In above formula n is the number of distinct clicked pages in the data set and s id information scent\ is calculated for each page P id present in a given session Q i  Each query session Q i is obtained as weighted vector using formula \(3\. This vector is modeling the information need associated with the query session Q i   3.1. Clustering Queries  Query sessions are clustered using k-means algorithm because of its good performance for document clustering [5   Q u e r y s e s s i o n s i n o u r approach are similar to the vectors of web pages and hence can be clustered using the methods for clustering pages A score or criterion function measures the quality of resulting clusters. This is used by common vector space implementation of k-means algorithm [13 Th e  function measures the average similarity between vectors and the centroid of clusters that are assigned to Let C p be a cluster found in a k-way clustering process\(p 001 1..k\ and let c p be the  centroid of pth cluster The criterion function I is defined as follows k I=1/M 003  003 sim \(v i c p 4 p=1     v i 001 C p  where v i is the vector representing some query session belonging to the cluster C p and centroid  c p of the cluster C p is defined as given below  c p  003 v i C p 5 v i  001 C p where M is the total number of query sessions in all clusters and |C p denotes the number of query sessions in cluster C p sim \(v i c p is calculated using cosine measure  4. Algorithm for Finding Related Queries with similar Information Need  The algorithm is based on clustering process that defines neighborhood of similar query sessions driven by similar information need using information scent and content vector of clicked URLs/pages in the query sessions. Each query session consist of a query along with the clicked URLs in its answer  querysession=\(query,\(clicked URLs    where clicked URLs are those URLs which user clicked before submitting another query  4.1. Algorithm  1  Offline Preprocessing phase at regular and periodical intervals 1.1  Extract the queries and associated clicked URLs from the data set 1.2  Preprocess the Extracted Queries to find the query sessions 
488 


1.3  Model the Information need associated to each query session using information scent and weighted vector of content of 3 1.4  Cluster the Query sessions using information need associated to each query session using k-means 1.5  For each cluster C j create a list of queries Q j in cluster C j  2  Online searching 2.1  Find the C j cluster to which input query q belongs 2.2  if   no cluster found then 2.2.1  Find the C j cluster which is most similar to term weight vector of input query q as per the threshold value set for similarity measure  2.3  Rank the list of queries Q j associated with selected cluster C j in order of their relevance to input query q upto certain similarity threshold value 2.4. Return the ranked set of queries The rank of queries in set Q j is calculated using similarity measure of each query vector x in Q j to input query vector q such that those queries with high value of similarity to input query q are ranked higher than those queries with low value of similarity to input query q where sim\(x, q\ is calculated using cosine measure between vector x and q  Rank\(x\ = {sim\(x, q 002 x 001 Q j 6  5. Experimental Study  Experiment was performed on the data set containing the clicked documents associated with queries issued on the Google search engine. The data set was collected from the web history of Google search engine. The data set was generated by users who had expertise in specific domains The web history contains the following fields  1.  Time of the Day 2.  Query terms 3.  Clicked URLs The data set generated from web history contains several thousand entries out of which we have extracted 5325 entries. In the experiment only those queries in data set were selected which had at least one click in their answer. The data set generated from web history is loaded into database to be processed further On the submission of input query, Google search engine returns result page consists of URLs with information about URLs. Query sessions considered consists of query terms along with clicked URLs. The clicked URLs are those URLs which user clicked before he submits another query. The number of distinct URLs in data set was found to be 3795.The data set was preprocessed to get 895 query sessions. In this experiment similarity of any two query sessions was calculated using cosine measure. The query sessions were clustered using k-means algorithm and it was executed several times for different values of k and criterion function was computed for each value of k. The criterion function was found to have maximum value at k=67.The threshold value set for similarity of two vectors was 0.5. The experiment was performed on randomly selected test queries which were categorized into trained queries set and untrained queries set. The trained queries were those input queries which had sessions associated with them in data set and untrained queries were those input queries which did not have sessions associated with them in data set. Some of the test queries in each of the category are given  in Table 1  Table 1  Sample of Queries taken in each of the category  The experiment was performed on Pentium IV PC with 512 MB RAM under Windows XP using Java and Oracle database. WebSphinx crawler was used to fetch the clicked documents of query sessions in the data set Each query session was transformed into the vector representation using Information Scent and content of clicked URLs. The k-means algorithm was executed to generate cluster of query sessions. Each cluster of Category Queries Untrained Set Moviesong,Spacefood,novels magazine movies,Numbness, Nature familyplay Games, movie pictures, software download online tutorial Trained  Set Homeloan distanceeducation online, free pics, cgi perl tutorial, moons of neptune how to play .vcd files, .vcd file, .api com, mpeg movies dragonball,intranet helpdeskmanagerjob description, free software 
489 


query sessions was represented by mean value of vector of terms. The Table 2 shows the cluster to which query "Games" and "hollywood video store belongs. The first column shows the input query and second column shows the queries which belong to the selected cluster for a given input query. The queries in cluster are shown in order of their relevance to input query  The relevance of recommended queries in the selected cluster to input query is decided by some anonymous user having knowledge in domain to which input query belongs. The relevance is judged by analyzing the answer of recommended queries from the result set showing top 10 answers and determined the URL in answers which are relevant to input query  The experiment was performed on randomly selected 21 trained queries and 35 untrained queries The average precision of queries of trained and untrained query set was calculated for different number of recommended queries from the result set showing the top 10 answers. The experimental result shows that ordering the recommended queries according to their relevance to input query with respect to its information need using information scent shows promising result  The Fig 1 and Fig 2 shows the precision of search results without using query recommendation and proposed approach on the trained and untrained set of queries and it shows that recommended queries help the user to find the relevant document which the user could not find it from initial input query as keywords of the query given by him were few to retrieve the relevant documents. Recommended queries help to handle ambiguity by expressing the information need using alternative queries that are satisfying the information need similar to the input query but different in the keyword used    Trained queries 0 0.2 0.4 0.6 0.8 02 468 NoOfRecommendedQueries Avgprecision proposed approach w ith query recommendation w ithout query recommendation    Fig 1. AvgPrecision of Trained Queries for different number of Recommended Queries  UntrainedQueries 0 0.2 0.4 0.6 0.8 02468 NoOfRcommendedQueries AvgPrecision proposed approach w ith query recommendation w ithout query recommendation    Fig 2. AvgPrecision of Untrained Queries for different number of Recommended Queries    Table 2. Queries in Selected Cluster for input Query “Games” and “Hollywood video store     6. Conclusion  In this paper efforts have been made to satisfy the Information need of user and improve the information retrieval precision by recommending related queries which approximate the information need associated to the input query using Information Scent. The information need associated to the query is modeled using information scent and content feature of clicked pages in the session. The suggested queries help the user to retrieve the documents relevant to his information need which he could not get through his Test Query Other Queries in Cluster Games Games download Internet games PC games Free online games Download play station games Downloadable games Free kid online games Hunting games Skies of arcadia pictures Xbox Mankind game  Hollywood video store Hollywood  movie store Movie store Video store Hollywood long movie Hollywood entertainment Hollywood video 
490 


initial query. Experimental results confirm the improvement of the information retrieval precision    7. References  1  E. Agichtein, E. Brill, S. Dumais,  “Improving Web Search Ranking by Incorporating User behaviour”. In Proceedings of the ACM Conference on Research and Development on Information Retrieval \(SIGIR\2006   2  E H. Chi, P. Pirolli, K. Chen and J. Pitkow Using Information Scent to model User Information Needs and Actions on the Web  In Proc. ACM CHI 2001 Conference on Human Factors in Computing Systems, 2001,pp. 490-497  3  R. Baeza-Yates and B. Ribeiro-Neto,”Modern Information Retrieval “ Addison Wesley, 1999  4  R. Baeza-Yates, C.A. Hurtado and M Mendoza  “Query Recommendation using query logs in Search engines  In Advances in Web Intelligence, Second International Atlantic Web Intelligence Conference, AWIC 2004, pp. 164-175  5  R J. Wen, ,Y J. Nie, J H Zhang, “Query Clustering Using User Logs  ACM Transactions on Information Systems,vol 20,No 1,2002,pp. 59-81  6  J. Heer and E.H. Chi, “Identification of Web User Traffic Composition using Multi-Modal clustering and Information Scent  In Proc of Workshop on Web Mining. SIAM Conference on Data Mining, 2001,pp. 51-58  7  M. Jansen, A. Spink , J. Bateman and T Saracevic, “Real life Information retrieval: a Study of user queries on the web  ACM SIGIR Forum 32\(1\,1998, pp. 5-17  8  P.Pirolli “Computational models of information scent-following in a very large browsable text collection  In Proc. ACM CHI 97 Conference on Human Factors in Computing Systems, 1997,pp. 3-10  9  P. Pirolli ,“ The use of proximal information scent to forage for distal content on the world wide web.” In Working with Technology in Mind Brunswikian. Resources for Cognitive Science and Engineering, Oxford University Press, 2004    Punam Bedi and Suruchi Chawla, “Improving Information Retrieval Precision using Query log mining and Information Scent”, Information Technology Journal 6\(4\:584-588 Asian Network for Scientific Information  2007    V N. Gudivada , V V. Raghavan,  W. Grosky and  R. KasanaGottu ,” Information  Retrieval on World Wide Web  IEEE expert, 1997, pp. 58-68    Y. Zhao and G. Karypis, “Comparison of agglomerative and partitional document clustering algorithms  In SIAM Workshop on Clustering High-dimensional Data   and its Applications, 2002    Y, Zhao and Y, Karypis . “Criterion functions for document clustering  Technical report University of Minnesota, Minneapolis, MN, 2002 
491 


abnormalities between test and training data and also to identify the critical system parameters 5 FAULT ISOLATION DOMINANT VARIABLES USING PROJECTION PURSUIT ANALYSIS The model space is designed to capture the data that varies the most whereas the residual space is designed to capture the data that does not vary but contributes to a faulty state The residual space can therefore detect changes in the distribution from variables that are degrading or have faults and are not effecting the variance Below are the principal components for the entire subspace S Each principal component is composed of the eight parameters with a particular weighting as shown in Table 5 The model/signal subspace is composed of the first four principal components This was chosen based on iterative experimentation to best capture the faults The decision of how many principal components are chosen to represent the model/signal space is based on experience and understanding of the data at hand There are computational/statistical techniques that can provide estimates for the selection of the number of PCs to optimized results The remaining columns span the residual subspace Each variable is represented by each respective row of matrix S The first row shows the contributions of the fan speed and the rest show the CPU temperature motherboard temperature video card temperature C2 state C3 state oCPU usage and 0%OCPU throttle from top to bottom in matrix S Table 5 Principal Component of subspace S and parameter contribution S PCI PC2 PC3 PC4 PC5 PC6 PC7 PC8 Fan 0.999 0.019 0.001 0.001 0.001 0.002 0.004 0.001 Speed CPTm 0.005 0.076 0.042 0.048 0.000 0.484 0.856 0.153 Mother board 0.830 Temp Video card 0.000 0.048 0.107 0.093 0.002 0.670 0.490 0.537 Temp 00C2 0.001 0.060 0.018 0.091 0.994 0.001 0.002 0.001 State 00C3 0.015 0.730 0.384 0.554 0.102 0.005 0.025 0.011 StateI CPU 0.013 0.661 0.271 0.690 0.028 0.114 0.019 0.000 Usage CPU 0.001 0O13 0.872 0.439 0.033 0.166 0.038 0.OOS Throttle From the decomposition of S we can see that the model space variations should be dominated by the fan speed followed by C3 state OCPU throttle and usage In the residual subspace the temperature components are dominant We expect that the temperature variables to be highly dominant Changes in the temperature are expected in turn to be less obvious to changes in system variance and should contribute to the shape of the multivariate data distribution Such a distribution can be modeled as Gaussian mixtures but in general a hard task Intuitively if the fan speed is not functioning we expect that the temperature of the system will rise and become abnormally high This is at first hand validated by the dominance of the temperatures components as observed in the residual subspace in S Mathematically this is also validated through the parameter contribution plots to the T2 and SPE respectively as illustrated in the contribution plots shown in Figure 4 The contribution plots tell us which parameter is contributing the most to the projection onto each subspace 70 70 60 60 50 5040~~~~~~~~~~~~~3 U 4~~~~~~~~~~~~~~0 10 Parameters 0 0.002 0.035 0.077 0.079 0.004 0.523 0.158 Parameter Figure 4 Contribution plot of each parameters towards T2 on right and SPE on left It is shown that on the model space the fan speed is highly dominant and varies the most in terms of standard deviation This phenomenon masks the effect on parameters that are also exhibiting abnormalities but are overpowered by dominant parameters such as the fan speed The residual space statistic SPE captures the inverse information and identifies the parameters that are indeed abnormal but are not dominating in terms of variance Also interesting is the fact that the mathematics validate our intuition that because the fan isn't functioning properly the temperature sensors would be experiencing unusual readings Note that these results are based on picking the model space using k=4 that is the first four PCs in matrix S The selection of more PCs for the model space and consequently fewer PCs for the residual space will change the results slightly If all eight PCs are used to construct the model space then the SPE will be rendered ineffective although the results for the Hotelling T2 will improve Even though the results from the Hotelling T2 improve with the selection of more PCs the information available through the SPE is lost There are ways to select the optimum number of PCs necessary to optimize the information captured from both subspaces often the selection is purely based on experience or experimentation although there are statistical methods such as the maximum likelihood estimator MLE which can estimate the optimum number of PCs to use 6 CONCLUSIONS A set of experiments were conducted to establish the healthy or normal operation on a set of notebook computers subjected to range of usages and environmental conditions A test computer was then subjected to field use conditions and evaluated in-situ using Mahalanobis Distance and Projection Pursuit analysis techniques The Projection Pursuit analysis method was also used to identify 7 


key parameters for root cause analysis of anomalies This study emphasizes that the defined baseline can be used to characterize a new computer model This will allow us to characterize a new notebook computer regardless of the model and reduce the time for analysis In this study PPA and MD were independently used to identify the similarity of new observations to healthy data PPA performed this analysis in a reduced dimension based on an optimization criterion maximum variance It was also found that PPA can identify the faulty parameters based on the data whereas MD requires an understanding of the system The strength of PPA lies in the ability to decompose the signal and extract additional information not originally available used to identify faults in the system PPA overcomes masking effects when working with highly correlated data The strength of the MD method is that it preserves all the information available because it does not reduce the original dimensionality of the data The drawbacks of using just the MD method are that it cannot be used directly for fault identification and it is susceptible to masking effects With the MD results and our understanding of the system functionality four critical parameters were empirically identified the fan speed and the three temperature components CPU temperature motherboard temperature and videocard temperature In parallel in the PPA approach the principal component space also identified the fan speed as the most dominant and from the residual principal component space three temperature parameters were identified to be dominant mathematically confirming the earlier empirical conclusion The cross-validated result shows that these two algorithms can be used for fault detection and isolation The MD method can be used for quick fault detection at a system level and fault isolation can be made if related fault to MD signatures are available PPA can also be used when system faults are not known and where critical parameters need to be identified ACKNOWLEDGEMENT This work is sponsored by the members of the CALCE Prognostics and Health Management Consortium at the University of Maryland College Park REFERENCES 1 N Vichare P Rodgers V Eveloy and M Pecht Environment and Usage Monitoring of Electronic Products for Health Assessment and Product Design International Journal of Quality Technology and Quantitative Management 2\(4 235-250 2007 2 J Gu N Vichare T Tracy and M Pecht Prognostics Implementation Methods for Electronics 53rd Annual Reliability  Maintainability Symposium RAMS Florida 2007 3 G Zhang C Kwan R Xu N Vichare and M Pecht An Enhanced Prognostic Model for Intermittent Failures in Digital Electronics IEEE Aerospace Conference Big Sky MT March 2007 4 N Vichare and M Pecht Enabling Electronic Prognostics Using Thermal Data Proceedings of the 12th International Workshop on Thermal Investigation of ICs and Systems Nice Cote d'Azur France 27-29 September 2006 5 N Vichare P Rodgers and M Pecht Methods for Binning and Density Estimation of Load Parameters for Prognostics and Health Management International Journal of Performability Engineering Vol 2 No 2 April 2006 6 A Fraser N Hengartner K Vixie and B Wohlberg Incorporating Invariants in Mahalanobis Distance based Classifiers Application to Face Recognition in International Joint Conference on Neural Networks IJCNN Portland OR USA Jul 2003 7 J Edward Jackson Govind S Mudholkar Control Procedures for Residuals Associated With Principal Component Analysis Technometrics Vol.21 No.3 1979 8 J Liu Khiang-Wee Lim R Srinivasan and X Doan On-Line Process Monitoring and Fault Isolation Using PCA Proceedings of the 2005 IEEE International Symposium on Mediterranean Conference on Control and Automation pp 658 661 2005 9 G Taguchi S Chowdhury and Y Wu The Mahalanobis-Taguchi System New York McGrawHill 2001 10 E B Martin A J Morris and J Zhang Process Performance Monitoring Using Multivariate Statistical Process CSontrol IEE Proc Control Theory Application Vol 143 No.2 March 1996 11 H Chen G Jiang C Ungureanu and K Yoshihira Failure Detection and Localization in Component Based Systems by Online Tracking KDD 2005 12 H Wang Z Song and P Li Fault Detection Behavior and Performance Analysis of Principal Component Analysis Based Process Monitoring Methods American Chemical Society Vol 41 pp 2455 2464 2002 13 H H Yue S.J Qin Reconstruction-Based Fault Identification Using a Combined Index American Chemical Society Vol 40 pp 4403-4414 2001 8 


BIOGRAPHY Sachin Kumar received the B.S degree in Metallurgical Engineering from the Bihar Institute of Technology and the M.Tech degree in Reliability Engineering from the Indian Institute of Technology Kharagpur He is currently pursuing the Ph.D degree in Mechanical Engineering at the University of Maryland College Park His research interests include reliability electronic system prognostics and health and usage monitoring of systems Vasilis Sotiris received the B.S degree in Aerospace Engineering from Rutgers University in New Brunswick New Jersey and the M S degree in Mechanical Engineering from Columbia University in New York He worked as a Systems Engineer for Lockheed Martin Corporation concentrating on software development projects for the Federal Aviation Administration He is currently pursuing the Ph.D degree in Applied Mathematics at the University of Maryland College Park His research interests are in the field of applied statistics and computational mathematics related to diagnostics and prognostics for electronic systems   _ n Acoustics an M.S in Electrical _  in Engineering Mechanics from the g  University of Wisconsin at Madison He is a Professional Engineer an IEEE Fellow and an ASME Fellow He has received the 3M Research Award for electronics packaging the IEEE Award for chairing key Reliability Standards and the IMAPS William D Ashman Memorial Achievement Award for his contributions in electronics reliability analysis He has written over twenty books on electronic products development use and supply chain management He served as chief editor of the IEEE Transactions on Reliability for eight years and on the advisory board of IEEE Spectrum He has been the chief editor for Microelectronics Reliability for over eleven years and an associate editor for the IEEE Transactions on Components and Packaging Technology He is a Chair Professor and the founder of the Center for Advanced Life Cycle Engineering CALCE and the Electronic Products and Systems Consortium at the University of Maryland He has also been leading a research team in the area of prognostics and formed the Prognostics and Health Management Consortium at the University of Maryland He has consulted for over 50 major international electronics companies providing expertise in strategic planning design test prognostics IP and risk assessment of electronic products and systems 9 


SPARQL query discussed in more detail in Section 6 has retrieved the SEAS Plane model information for a particular F-15 instance gure  Mvlititary Asset utnology A number of other military ontologies also exist The MilOrg ondology describes military and related political organizations as well as particular Roles they play in military affairs Tasks they are required to perform and specialized military Actions that perform them MilGeo defines a military perspective on geography with emphasis on terrain polpulation and cultural features of interest to military operations MilGeo contains classes that describe military facilities including Forts Airbases NavalPorts and Forward Operating Locations The MilSit ontology describes Conflicts Campaigns Missions Plans and similar concepts It also defines exactly what constitutes a situation and classifies various types of situations Specialized ontologies relating to military information and communications exist and may be imported in some cases to provide increased detail for those concerns Finally to support military Modeling and Simulation applications the MilSim ontology provides a platform for importing relevant ontologies for a particular study or exercise and a location to create concepts peculiar to individual simulations 10 


impodt Top Leve M d Ile Level Dom1ain Lave i 1po Scenwd1o Level Figure 8 Ilium Ontology Suite typical It is possible and in fact common to employ only a few of these ontologies in particular studies For example many studies are only concerned with physical platforms and therefore only need the MilAsset ontology which imports IlumAsset IliumFramework and DUL Figure 8 illustrates the existing Ilium Ontology Suite and a typical import pattern for a complex Modeling and Simulation application scenario Currently the illustrated suite less Millnfo MilComm and UAV defines 1240 OWL Classes 274 OWL Object Properties and 188 OWL Datatype Properties 6 AN EXAMPLE APPLICATION We are currently using the described approach to conduct systems requirements and other engineering analyses for military aerospace systems In these investigations it is useful to consider detailed aspects of the system design or software prototype behavior in the context of large scale network-centric military operations In the past year in particular we have assembled a collection of well known and widely accepted military simulations to prepare for an extensive investigation of requirements for autonomy in unmanned military platforms It is believed that useful insights in the study will be sensitive to important details of system behavior supporting sensor platform and communications technologies as well as the combined effects of these technologies on an advanced highly networked military force Thus the study environment must provide a means to reliably model and evaluate significant technical detail and to measure the effects as well as propagation of those effects throughout a broad operational context 11 


I r Z  Figure 9 A Military Modeling and Simulation Configuration of the Ilium Framework To do that we have assembled a collection of trusted military simulations that span the range of such applications from fine-grained simulations that focus on detailed interactions between two entities to coarse-grained simulations of military campaigns Figure 9 illustrates the Ilium Framework configured to accommodate those simulations as well as representative prototype systems In this case the legacy applications are simulations analysis systems and design tools Prototypes are notional UAV autopilots route planners decision support systems and similar applications The Framework augments these applications with control objects and agents that coordinate computations in the composed system and specialize agents that typically represent the characteristics of a new system or technology that cannot be easily or adequately simulated in any of the component legacy systems In our current study the following systems have Ilium Framework plugins and are used as components in the study environment 12 Al f<cOmmi.ain FIa 1A  


THUNDER is a campaign simulation that models national military forces and military operations that extend over months 30  Characteristics of individual systems are evaluated statistically and their effects on the overall campaign are not explicitly known Political social and cultural objects and concepts are not included in the model In this configuration THUNDER is used to generate force level tasking mission orders and to evaluate and adjust for the results of missions with respect to campaign plans SEAS is a force level simulation that simulates battles between major forces in combat operations that typically last for hours and as much as a day SEAS features a flexible rules based decision logic that can influence behavior at both the commander and individual combatant level SEAS executes the missions requested by THUNDER and provides a manageable dynamic context for examining the behavior of prototypes in a range of typical operational situations  31 A dynamic plug-in supports interaction with the Framework and other pugged-in components EADSIM is a trusted model of air defense systems that is in particular sensitive to many important design attributes of individual systems In certain modified forms it can reference advanced sensor and engagement decision models In our study configuration EADSIM simulates enemy air defenses in selected e.g significant to our investigation portions of the virtual battle A dynamic plug-in supports system control as well as interaction with the Framework and other pugged-in components A prototype aircraft mission planning system plug-in supports virtual real time mission plan creation and updates In particular the system provides automatic route planning for selected platforms that have been assigned missions by THUNDER and that are subsequently executed in simulation in SEAS and EADSIM The Ilium Framework itself provides software agents that are used to model notional or experimental UAV characteristics and behaviors Depending on the objectives of a particular study the Framework may also provide agents that address advanced Command and Control concepts to coordinate the interaction of the various component systems We maintain a semantic consistency among the plugged-in component applications by developing a single operational scenario as initial input for a study and deriving the necessary application configuration data from that source We create an RDF model of the scenario based on the Ilium suite of ontologies that includes political context issues objectives sensitivities etc military context centers of gravity campaign objectives etc geophysical environment military units order of battle unit equipment lists etc command and control assets platforms weapons ISR systems etc Figure 11 below is an excerpt from an operational scenario set in the Southwest U.S depicting a description of an Air Force Wing assigned to a notional Joint Task Force The Wing is based at Bishop Air Base and has six Fighter Squadrons assigned to it Additional detail about each of those squadrons as well as the base is found in the model in this case an rdf:resource  associated with it morg:AirForceWing rdf:ID="USAF_366 Air_Exp Wg dc:creator>Doug Holmes</dc:creator mgeo:basedAt rdf:resource="#BishopAB geo:positionedAt rdf:resource="#BishopAB_pos morg:assignedOrg rdf:resource="#USAF 390_Ftr_Sq morg:assignedOrg rdf:resource="#USAF_494_Ftr_Sq dc date I 0/20/07</dc date morg:assignedOrg rdf:resource="#USAF_496 Ftr_Sq rdfs:comment>366 AEW F-22 F-15 KC-135 130]</rdfs:comment morg:assignedOrg rdf:resource="#USAF 389_Ftr_Sq morg:assignedOrg rdf:resource="#USAF 391 Ftr_Sq morg:assignedOrg rdf:resource="#USAF 495_Ftr_Sq rdfs:label>366 Air Expeditionary Wing</rdfs:label morg:AirForceWing ab9 7P.b ii uI1 L L CFigure 11 An RDF model of a notional USAF Wing Figure 12 is another excerpt from the same scenario illustrating a model of a particular Fighter Squadron and one of the F-15E aircraft it operates Figure 10 Legacy Components in the Ilium Framework 13 suka 


morg:AirliorceSquadron rd:lD U SAF _8 htr Sq rdfs:label>8th Fighter Squadron</rdfs:label geo:positionedAt rdf:resource="#GeorgeAB_pos msim:hasSeasModel rdf:resource="#BAFGA mast:hasModel rdf:resource="#BAFGA rdfs:comment>An F15E Squadron</rdfs:comment dc:date>9/26/07</dc:date dc:creator>Doug Holmes</dc:creator mgeo:basedAt rdf:resource="#GeorgeAB morg:AirForceSquadron F1 5E rdf:ID="F1 5E 05 dul:isReferenceOfRealization rdf:resource="#AirObj ect_2007 mast:equipment-of rdf:resource="#USAF 7 Ftr_Sq dc:creator>Doug Hollmes</dc:creator dc:date>9/26/07</dc:date msim:hasSeasPlane rdf:resource="#F15E mgeo:basedAt rdf:resource="#GeorgeAB geo:positionedAt rdf:resource="#GeorgeAB-pos rdfs:label>F-15E 005</rdfs:label F-15E Figure 12 An RDF model of a Fighter Squadron and one of its aircraft Note that these models also have associated SEAS models that contain information peculiar to the SEAS simulation about these entities This information is used to configure SEAS to properly represent these particular entities We are also able to insert objects and information that may be of interest in our study that is not represented in any of the component simulations or other applications Where those objects are related to an object that is simulated that relationship permits inferences about the effects on them as a result of actions that are computed in a simulation For example it is possible to indicate that GeorgeAB defends the capital city and lend special significance to the actions of aircraft that are based there even though none of the simulations in the composite system have any notion of capital city Finally the operational scenario provides an explicit record of the assumptions that underly the study and can also include and explicit representation of system and study goals This practice improves analysis and may enable future knowledge based analytical tools Throughout the process of constructing the operational scenario and when it is complete we use one or more Description Logic Reasoners to ensure the logical consistency of the the model A number of these automatic theorem provers are freely available including Pellet 32 33 FaCT  34 and OWLIM 35 are used in the Framework to compute logical entailments and to complete RDF models as well as to ensure the consistency of models In the later capacity frequent checks will identify errors in the construction some e.g Pellet also indicate the source of the error and aid in repairing it As a result we are confident that the operational scenario is a sound model The primary use of the Reasoners allows us to significantly extend the explicit RDF model that is created For example a squadron is explicitly specified as assignedTo a wing and that relationship is the inverse of assignedOrg then the system can infer that the wing has the squadron as an assigned organization even though that fact has never been asserted Similarly if the same relationship is defined as a transitive relationship it is possible to infer that a flight that is assigned to the squadron is also assigned to the wing Once we have an operational scenario that has been classified by a Reasoner we then use the completed model to configure the composite system Ilium and the pluggedin systems to execute the simulation We use SPARQL a W3C standard query language designed to access RDFL to extract data from the scenario to create the input files needed to configure the various applications.[36 SELECT name pos long lat alt vis W1HLERE name rdf:type mast SeasLocation name geo:positionedAt pos pos pos:long long pos pos:lat lat pos pos:alt alt name msim:Visible vis  Figure 13 A typical SPARQL query In a similar fashion SPARQL is used to extract data from the scenario to create the necessary Ilium java surrogate control and agents SPARQL can also be used to review the scenario and answer questions that have arisen since the inception of the study At this point we are able execute the scenario with confidence that it will produce reliable results 7 CONCLUSIONS We have developed a methodology and supporting tools for creating an operational scenario that supports the semantic interoperability of an ad hoc collection of legacy applications and extends their capabilities The method depends on and ensures the logical integrity of the composite system Therefore when we assemble as a collection of legacy component systems that were not originally intended to interoperate with other systems we can be confidant that the composite system will produce consistent results Logical consistency implies that to the degree that we trust the interpretation underlying the model the results of operations on the model are trustworthy If for example the model is based on a Newtonian interpretation of physics the model ought to provide reliable answers to questions about automotive and even aeronautical engineering but probably not to all questions in astronomy or cosmology This methodology extends the utility of trusted simulations allowing integration of finegrained simulations that are sensitive to design requirements with high level coarse-grained simulations that are sensitive to acquisition issues and policy The potential benefits of 14 


this sort of interoperation may range from obvious production efficiencies to clearer insights into system requirements Finally an important side-effect of the approach is the OWL/RDF knowledge base formed by the combination of the operational scenario and the results of the operations of the legacy systems That knowledge base and the use of SPARQL queries and SWRL rules effectively expands the functionality of the system and greatly improves the analysis of the output of the system of cooperating simulations and tools We have prepared a foundation for the application of Semantic Web and other knowledge based tools in the analysis and design of unmanned systems We anticipate the development and application of these tools and the addition of autonomy directed Multiple Agent Systems MAS that use RDF/XML inter-agent communications in the coming year REFERENCES 1 NAFCAM 2001 Exploiting EManufacturing:Ineroperability of Software Systems Used by U.S Manufacturers available at 12 Protege Ontology Editor documentation available at http proteae.stanf6rd.edu 13 Top Braid Composer Datasheet available at 14 W and Nicola Guarino 2001 Support for Ontological Analysis of Taxonomic Relationships J Data and Knowled 39\(1 October 2001 15 Natalya F Noy and Deborah L McGuinness Ontology Development 10 1 A Guide to Creating Your First Ontology  Stanford University Stanford CA 94305 16 Alan Rector Modularisation of Domain Ontologies Implemented in Description Logics and related formalisms including OWL K-CAP'03 October 23-25 2003 Sanibel Island Florida USA pp 121-8 2003 17 Cyc Homepage available at htc.c 18 Open Cyc home page available at 19 SUMO Description and Home Page available at 19 SENSUS Description and Home Page available at 2 Bemers-Lee Tim Hendler Jim Lasilla Ora The Semantic Web Scientific American available at 20 DOLCE A Descriptive Ontology for Linguistic and Cognitive Engineering ontology and documents available at 3 Bemers-Lee Tim Blog on Design Issues available at 4 RDF Primer available at s chema/#ref-rdf-primer 5 Lacey Lee OWL Representing Information Using the Web Ontology Language Trafford Publishing 2005 6 OWL Web Ontology Language Guide available at Jten pHomewPage availal adt 7 Jena Home Page available at 8 Protege Home Page available at h1ttp  protegest nftanford.edu,X 1 9 Baader Calvanese McGuiness Nardi and PatelSchnieder Description Logic Handbook 10 Oberle Daniel Semantic Management of Middleware Springer 2006 OWL Web Ontology Language Guide available at 21 Nicola Gauarino Claudio Masolo Stefano Borgo Aldo Gangemi and Alessandro Oltramari Ontology Infrastructure for the Semantic Web Wonder World Deliverable DI 8 Laboratory for Applied Ontology Trento Italy 2001 available on line at ht X1t1 22 DUL.owl ontology available at www.1oa23t og DLl 23 Amy Knutilla Steven Polyak Craig Schlenoff Austin Tate Shu Chiun Cheah Steven Ray and Richard Anderson Process Specification Language An Analysis of Existing Representations NIST report available at http llwww.mel.nlist.gov/msid.librarZ/d.oc/psl-1 _.df 24 Process Specification Language Ontology available at http-//www,55,me l.nit gov/psl 25 Ontology for Geography Markup Language GML3.0 owl ontology available at ok i.cae.drexel.edu./-wbs/onltology/2004/09/ogc-gmI1 26 Ontology for Geography Markup Language GML3.0 of Open GIS Consortium OGC Home Page available at 15 


 Peter Maguire Using THUNDER for Campaign Studies DSTO-TN-0303 DSTO Melbourne August 2000 28 User Manual SEAS Version 3.7 U.S Air Force SMC/XR February 2007 29 Bijan Parsia and Evren Sirin Pellet and OWL DL Reasoner MINDSWAP Research Group University of Maryland College Park available at 30 Pellet Home Page available at 31 FaCT Home Page available at 32 OWLIM Home Page available at 3 A SPARQL Tutorial available at BIOGRAPHY Douglas Holmes is co-founder and Senior Partner of Java Professionals Inc In the past twenty-two years he has managed and participated in numerous artificial intelligence and knowledge-based programs for DARPA and other research agencies as well as commercial applications in the petroleum and other sectors He is currently developing ontologies and applying Semantic Web technology to support research and development of military unmanned systems He also has over twenty years experience as an Air Force Fighter Pilot and Fighter Weapons School Instructor Mr Holmes has a B.S in Mathematics and Basic Sciences from the U.S Air Force Academy and a M.S in Management Information Systems from Golden Gate University Richard Stocking is the lead Program Investigator/PM for Net Centric Operations Warfare Analysis efforts for Lockheed Martin Aeronautics Advanced Development Programs The Skunk WorksTM He is currently leading efforts researching autonomous UAV operations Current efforts include the integration of Multiple Agent Systems and other autonomy systems within the Ilium Framework He has over thirty years experience and over 11,000 flight hours with multiple C4ISR systems in the US Army and US Navy Mr Stocking has a M.S in Systems Technology from the Naval Postgraduate School 16 


 17    J. Ta usc h  S. T y son a n d T T a i r ba nks  Multigenerational Radiation Response Trends in SONOSb ased NROM Flash Memories with Neutron Latch-up Mitigation," in NSREC Radiation Effects Workshop Honolulu, 2007, pp. 189-193 9  Semico n du c to r In du str y A s sociatio n SIA  2 008   August\ Home. [Online  www.itrs.net  1  S. Ty s o n P ri v a t e C o m m uni que Tra n sEl  Semiconductor, Albuquerque, NM, 2008 1  T. M i k o l a ji c k  and C U Pi n n o w  2 00 8 N o vem b er Indo-German Winter Academy, 2008, Course 3 Onlin http://www.leb.eei.unierlangen.de/winterakadem ie/2008/courses/course3_ material/futureMemory/Mikolajick_TheFutureofNV M.pdf   BAE System s North Am erica, [Data Sheet Microcircuit, CMOS, 3.3V, NVRAM 8406746, April 28, 2008, Rev A 1  N Ha dda d a n d T Scot t  A da pt i n g C o m m erci al  Electronics to the Natura lly Occurring Radiation Environment," in IEEE Nuclear and Space Radiation Effects Conference Short Course Tucson, 1994, pp iv-14 1  D. R  R o t h a n d et _al S EU a n d TI D Test i n g of t h e Samsung 128 Mbit and the Toshiba 256 Mbit flash memory," in Radiation Effects Data Workshop  Reno, 2000 1  F. I r o m and D N guy e n  S i n gl e E v ent  Ef fe ct  Characterization of High Density Commercial NAND and NOR Nonvolatile Flash Memories Honolulu, 2007 1  C Ha fer M  L a hey a n d et _al R adi a t i o n H a rd ness  Characterization of a 130nm Technology," in Proceedings IEEE Nuclea r and Space Radiation Effects Conference Honolulu, 2007 17  T. R O l dh am J. Fr iend lich  an d et_ a l, "TID  an d SEE Response of an Advanced Samsung 4Gb NAND Flash Memory," , Honolulu, 2007  R. C. Lac o e C MOS Scaling, Desi gn Princi ples a n d Hardening-by-Design Methodologies," in Nuclear and Space Radiation Effects Conference Short Course Notebook Monterey, 1993, pp. II-1 thru II142 1 J. Pat t e rs o n a n d S  Gue rt i n   E m e rgi ng S E F I M o des and SEE Testing for Highly-Scaled NAND FLASH Devices," in Proceedings 2005 Non-Volatile Memory Technology Symposium vol. CD-ROM, Dallas, TX 2005, pp. G-3, Session G ; Paper 3 2 J. Ta usc h  S. T y son a n d T F a i rba nks  Mulitgenerational Radiation Response Trends in SONOSb ased NROM Flash Memories with Neutron Latch-up Mitigation," in Honolulu Radaition Effects Data Workshop, NSREC, 2007, pp. 189-193 2 M Janai  B Ei t a n A Sha p pi r I B l o o m and G  Cohen, "Data Retention Reliability Model of NROM Nonvolatile Memory Products IEEE Transactions on Device and Materials Reliability vol. 4, no. 3, pp 404-415, September 2004 2 D N g uy en a n d F I r o m Tot al Io ni zi n g  Do se \(T ID  Tests on Non-Volatile Memories: Flash and MRAM," in 2007 IEEE Radiation Effects Workshop  vol. 0, Honolulu, 2007, pp. 194-198  G. Noree n  a n d et_al L ow Cost Deep Space Hybrid Optical/RF Communications Architecture," , Big Sky, Montana, 2009, Pre-print 2 T. Sasa da a n d S. I c hi kawa  A p p l i cat i o n o f  Sol i d  State Recorders to Spacecraft," in Proceedings, 54th International Astronautical Cogress Bremen, 2003 2 H Ka nek o  E rr or C o nt r o l C odi ng f o r  Semiconductor Memory Systems in the Space Radiation Environment," in Proceedings, 20th IEEE International Symposium in Defect and Fault Tolerance in VLSI Systems, DFT2005 Monterey 2005 2 T. Sasa da a n d H Ka nek o  D evel o p m e nt an d Evaluation of Test Circuit for Spotty Byte Error Control Codes," in Proceedings, 57th International 


 18  Astronautical Congress Valencia, 2006 27  Bu reau  In tern atio n a l d e s Po ids et Mesures. \(2 008  August\SI Base Units. [On http://www.bipm.org/en/si/base_units   B IOGRAPHY  Author, Karl Strauss, has been employed by the Jet Propulsion Laboratory for over 22 years.  He has been in the Avionics Section from day One.  He is considered JPL\222s memory technology expert with projects ranging from hand-woven core memory \(for another employer\o high capacity solid state designs.  He managed the development of NASA\222s first Solid State Recorder, a DRAM-based 2 Gb design currently in use by the Cassini mission to Satu rn and the Chandra X-Ray observatory in Earth Orbit.  Karl was the founder, and seven-time chair of the IEEE NonVolatile Memory Technology Symposium, NVMTS, deciding that the various symposia conducted until then were too focused on one technology.  Karl is a Senior IEEE member and is active in the Nuclear and Plasma Scie nce Society, the Electron Device Society and the Aerospace Electronic Systems Society Karl is also an active member of SAE Karl thanks his wonderful wife of 28 years, Janet, for raising a spectacular family: three sons, Justin, Jeremy Jonathan.  Karl\222s passion is trains and is developing a model railroad based upon a four-day rail journey across Australia\222s Northern Outback   


 19 Bollobás, B. 2001. Random Graphs. Cambridge University Press; 2nd edition. 500pp  Cawley, G. C., B. L. C. Talbot, G. J. Janacek, and M. W Peck. 2006. Sparse Bayesian Ke rnel Survival Analysis for Modeling the Growth Domain of Microbial Pathogens  Chiang C. L. 1960. A stochastic study of life tables and its applications: I. Probability distribution of the biometric functions. Biometrics, 16:618-635  Cox,  D. R. 1972. Regression models and life tables J. R Stat. Soc. Ser. B 34:184-220  Cox, D. R. 1975.   Partial likelihood Biometrika 62:269276  Cox, D. R. & D. Oakes. 1984 Analysis of Survival Data  Chapman & Hall. London  Cressie, N. A. 1993 Statistics for Spatial Data John Wiley Sons. 900pp  Duchesne, T. 2005. Regression models for reliability given the usage accumulation history. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty Y. Armijo. pp.29-40. World Scientific, New Jersey  Eleuteri, A., R. Tagliaferri, L. Milano, G. Sansone, D D'Agostino, S. De Placido,  M. Laurentiis. 2003.  Survival analysis and neural networks. Proceedings of the International Joint Conference on Neural Networks, Vol. 4 20-24 July 2003 Page\(s\:2631 - 2636  Ellison, E., L. Linger, and M Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013, 1997  Fleming, T. R. & D. P. Harrington. 1991. Counting process and survival analysis. John Wiley & Sons. 429pp  Graver, J. and M. Sobel 2005. You may rely on the Reliability Polynomial for much more than you might think Communications in Statistics: Theory and Methods  34\(6\1411-1422  Graves, T. and M. Hamada. 2005. Bayesian methods for assessing system reliability: models and computation. In Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson, et al. pp.41-53  Grimmett, G. 2006 The Random-Cluster Model Springer  Grimmett, G. 1999 Percolation Springer  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis.  Springer. 481pp  Jin Z. 2005. Non-proportional semi-parametric regression models for censored data. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.279-292 World Scientific  Kalbfleisch, J. D. & R. L. Prentice. 1980 The Statistical Analysis of Failure Time Data John Wiley & Sons.  New York. 1980  Kalbfleisch, J. D. &  R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data.  Wiley-InterScience, 2nd ed 462pp  Lisboa, P. J. G. and H. Wong. 2001. Are neural networks best used to help logistic regression? Proceedings of International Joint Conference on Neural Networks, IJCNN 01. Volume 4, 15-19,  July 2001. Page\(s\:2472 - 2477 vol.4  Kauffman, R. J. and B. Wang. 2002. Duration in the Digital Economy. Proceedings of th e 36th Hawaii International Conference on System Sciences \(HICSS’03\ Jan 2003  Kaplan, E. L. & P.  Meier.  1958.  Nonparametric estimation from incomplete observations J. Amer. Statist. Assoc  53:457-481  Klein, J. P. and P. K. Goel 1992. Survival Analysis: State of the Art.  Kluwer Academic Publishes. 450pp  Klein, J. P. and  M. L Moeschberger. 20 03. Survival analysis techniques for ce nsored and truncated data Springer  Krings, A. and Z. S. Ma. 2006.  "Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks MILCOM 2006, Military Communications Conference, 2325 October, 7 pages, 2006  Krings, A. W. 2008.  Survivable Systems.  in Information Assurance: Dependability and Security in Networked Systems Yi Qian, James Joshi, David Tipper, and Prashant Krishnamurthy, Morgan Kaufmann Publishers. \(in press  Lawless, J. F. 1982. Statistical models and methods for lifetime data.  John Wiley & Sons. 579pp  Lawless, J. F. 2003. Statistical models and methods for lifetime data.  John Wiley & Sons. 2nd ed. 630pp  Li, M. and P. Vitanyi. 1997. Introduction to  Kolmogorov Complexity and Its Applications. 2nd ed, Springer  Ma, Z. S. 1997.  Survival analysis and demography of Russian wheat aphid populations.  Ph.D dissertation, 307pp University of Idaho Moscow, Idaho, USA 


 20 Ma, Z. S., and E. J. Bechinski. 2008.  Developmental and Phenological Modeling of Russian Wheat Aphid Annals of Entomological Soc. Am In press  Ma, Z. S. and A. W. Krings. 2008a. The Competing Risks Analysis Approach to Reliability Survivability, and Prognostics and Health Management.  The 2008 IEEEAIAA AeroSpace Conference. BigSky, Montana, March 18, 2008. \(In Press, in the same volume  Ma, Z. S. and A. W. Krings 2008b. Multivariate Survival Analysis \(I\e Shared Frailty Approaches to Reliability and Dependence Modeling. The 2008 IEEE-AIAA AeroSpace Conference. BigSky Montana, March 1-8, 2008 In Press, in the same volume  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(II\ Multi-State Models in Biomedicine and Engineering Reliability. 2008 IEEE International Conference on Biomedical Engineering and Informatics BMEI 2008\27th-30th, 2008 Accepted   Mani, R., J. Drew, A. Betz, P. Datta. 1999. Statistics and Data Mining Techniques for Lifetime Value Modeling ACM Conf. on Knowledge Discovery and Data Mining  Mazzuchi, T. A., R Soyer., and R. V Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Meeker, W. Q. and L. A. Escobar. 1998. Statistical Methods for Reliability Data. Wiley-Interscience  Munson, J. C. 2003. Software Engineering Measurement Auerbach Publications  Nelson, W. 1969. Hazard plotting for incomplete failure data J. Qual. Tech 1:27-52  Nakagawa, T. 2006.  Shock and Damage Models in Reliability Theory. Springer  Osborn, B. 2005. Leveraging remote diagnostics data for predictive maintenance.   In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp. 353-363  Pena, E. A. and E. H. Slate. 2005. Dynamic modeling in reliability and survival analysis. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.55-71  Reineke, D. M., E. A. Pohl, and W. P. Murdock. 1998 Survival analysis and maintenance policies for a series system, with highly censore d data.  1998 Proceedings Annual Reliability and Maintainability Symposium. pp 182-188  Schabenberger, O. and C. A. Gotway. 2005. Statistical Methods for Spatial Data Analysis.  Chapman & Hall/CRC  Severini, T. A. 2000. Likelihood methods in statistics Oxford University Press  Shooman, M. L. 2002. Reliability of Computer Systems and Networks: Fault Tolerance, Analysis and Design. John Wiley and Sons. 551pp  Stillman, R. H. and M. S. Mack isack, B. Sharp, and C. Lee 1995. Case studies in survival analysis of overhead line components. IEE Conferen ce of the Reliability and Distribution Equipment. March 29-31, 1995. Conference Publication No. 406. pp210-215  Therneau, T. and P. Grambsch. 2000 Modeling Survival Data: Extending the Cox Model Springer  Wilson, A.  N. Limnios, S Kelly-McNulty, Y. Armijo 2005. Modern Statistical and Mathematical Methods in Reliability. World Scientific, New Jersey  Xie, M. 1991. Software Reliability Modeling. World Scientific Press    B IOGRAPHY   Zhanshan \(Sam\ Ma holds a Ph.D. in Entomology and is a Ph.D. candidate in Computer Science at the University of Idaho. He has published approximately 30 journal and 30 conference papers, mainly in the former field.  Prior to his recent return to academia, he worked as senior network/software engineers in software industry.  His current research interests include reliability and survivability of wireless sensor networks, fault tolerance survival analysis, evolutionary game theory, evolutionary computation and bioinformatics  Axel W. Krings is a professor of Computer Science at the University of Idaho.  He received his Ph.D. \(1993\ and M.S 1991\ degrees in Computer Science from the University of Nebraska - Lincoln, and his M.S. \(1982\ in Electrical Engineering from the FH-Aachen, Germany.  Dr. Krings has published extensively in the area of Computer Network Survivability, Security, Fault-Tolerance and Realtime Scheduling. In 2004/2005 he was a visiting professor at the Institut d'Informatique et Mathématiques Appliquées de Grenoble, at the Institut National Polytechnique de Grenoble, France.  His work has been funded by DoE/INL DoT/NIATT, DoD/OST and NIST 


States\nWAb-3.4: NEW RESULTS IN THE ANALYSIS OF DECISION-FEEDBACK 2118\nEQUALIZERS\nAhmed Mehana, Samsung Electronics, Co Ltd., United States; Aria Nosratinia, University of Texas at \nDallas, United States\nWAb-5: TARGET TRACKING II\nWAb-5.1: POSTERIOR DISTRIBUTION PREPROCESSING FOR PASSIVE 2125\nDTV RADAR TRACKING: SIMULATED AND REAL DATA\nEvan Hanusa, Laura Vertatschitsch, David Krout, University of Washington, United States\nWAb-5.2: DEPTH-BASED PASSIVE TRACKING OF SUBMERGED SOURCES  ............................................2130\nIN THE DEEP OCEAN USING A VERTICAL LINE ARRAY\nLisa Zurk, John K. Boyle, Jordan Shibley, Portland State University, United States\nWAb-5.3: GENERALIZED LINEAR MINIMUM MEAN-SQUARE ERROR 2133\nESTIMATION WITH APPLICATION TO SPACE-OBJECT TRACKING\nYu Liu, X. Rong Li, Huimin Chen, University of New Orleans, United States\nWAb-5.4: FEATURE-AIDED INITIATION AND TRACKING VIA TREE SEARCH ..........................................2138\nHossein Roufarshbaf Jill Nelson, George Mason University, United States\nxxxiii\nWAb-6: DIRECTION OF ARRIVAL ESTIMATION\nWAb-6.1: A SELF-CALIBRATION TECHNIQUE FOR DIRECTION 2145\nESTIMATION WITH DIVERSELY POLARIZED ARRAYS\nBenjamin Friedlander, University of California, Santa Cruz, United States\nWAb-6.2: CRAMER-RAO PERFORMANCE BOUNDS FOR SIMULTANEOUS  ..............................................2150\nTARGET AND MULTIPATH POSITIONING\nLi Li, Jeff Krolik, Duke University, United States\nWAb-6.3: COPY CORRELATION DIRECTION-OF-ARRIVAL ESTIMATION  .................................................2155\nPERFORMANCE WITH A STOCHASTIC WEIGHT VECTOR\nChrist Richmond, Keith Forsythe, MIT Lincoln Laboratory, United States; Christopher Flynn, Stevens nInstitute of Technology, United States\nWAb-6.4: LOCATING CLOSELY SPACED COHERENT EMITTERS USING 2160\nTDOA TECHNIQUES\nJack Reale, Air Force Research Laboratory / Binghamton University, United States; Lauren Huie, Air \nForce Research Laboratory, United States Mark Fowler, State University of New York at Binghamton, \nUnited States\nWAb-7: ENERGY- AND RELIABILITY-AWARE DESIGN\nWAb-7.1: LOW-ENERGY ARCHITECTURES FOR SUPPORT VECTOR 2167\nMACHINE COMPUTATION\nManohar Ayinala, Keshab K Parhi, University of Minnesota, United States\nWAb-7.2: TRUNCATED MULTIPLIERS THROUGH POWER-GATING FOR 2172\nDEGRADING PRECISION ARITHMETIC\nPietro Albicocco, Gian Carlo Cardarilli, University of Rome Tor Vergata, Italy; Alberto Nannarelli, \nTechnical University of Denmark Denmark; Massimo Petricca, Politecnico di Torino, Italy; Marco Re, \nUniversity of Rome Tor Vergata Italy\nWAb-7.3: A LOGARITHMIC APPROACH TO ENERGY-EFFICIENT GPU 2177\nARITHMETIC FOR MOBILE DEVICES\nMiguel Lastras Behrooz Parhami, University of California, Santa Barbara, United States\nWAb-7.4: ON SEPARABLE ERROR DETECTION FOR ADDITION ..................................................................2181\nMichael Sullivan, Earl Swartzlander, University of Texas at Austin, United States\nWPb-1: PAPERS PRESENTED IN 2012\nWPb-1.1 DYNAMICALLY RECONFIGURABLE AVC DEBLOCKING FILTER  .............................................2189\nWITH POWER AND PERFORMANCE CONSTRAINTS\nYuebing Jiang, Marios Pattichis, University of New Mexico\nxxxiv\n 


on science teams for numerous planetary missions including Magellan, Mars Observer, Mars Global Surveyor and Rosetta. He was the US Project Scientist for the international Mars NetLander mission, for which he was also principal investigator of the Short-Period Seismometer experiment, and is currently the Project Scientist for the Mars Exploration Rovers. He led the Geophysics and Planetary Geology group at JPL from 1993-2005, and is the JPL Discipline Program Manager for Planetary Geosciences. He has held several visiting appointments at the Institut de Physique du Globe de Paris. He has a BS in physics and a PhD in geophysics from the University of Southern California  David Hansen is a member of the technical staff in the Communications Systems and Operations Group at the Jet Propulsion Laboratory. Current work includes the development of the telecom subsystem for the Juno project. David received a B.S. in Electrical Engineering from Cornell University and an M.S. in Electrical Engineering from Stanford University  Robert Miyake is a member of the technical staff in the Mission and Technology Development Group at the Jet Propulsion Laboratory. Current work includes the development of thermal control subsystems for interplanetary flagship missions to Jupiter and Saturn missions to Mars and the Earth Moon, and is the lead Thermal Chair for the Advanced Project Design Team Robert graduated with a B. S. from San Jose State University, with extensive graduate studies at UCLA University of Washington, and University of Santa Clara  Steve Kondos is a consultant to the Structures and Mechanisms group at the Jet Propulsion Laboratory. He currently is generating the mechanical concepts for small Lunar Landers and Lunar Science Instrument packages in support of various Lunar mission initiatives. He also provides conceptual design, mass and cost estimating support for various Team X studies as the lead for the Mechanical Subsystem Chair. Steve is also involved with various other studies and proposals and provides mentoring to several young mechanical and system engineers. He graduated with a B.S. in Mechanical Engineering from the University of California, Davis and has 28 years of experience in the aerospace field ranging from detail part design to system of systems architecture development. He has worked both in industry and in government in defense, intelligence commercial and civil activities that range from ocean and land based systems to airborne and space systems. Steve has received various NASA, Air Force, Department of Defense and other agency awards for his work on such projects as the NASA Solar Array Flight Experiment, Talon Gold, MILSTAR, Iridium, SBIRS, Mars Exploration Rovers ATFLIR, Glory Aerosol Polarimeter System and several Restricted Programs  Paul Timmerman is a senior member of technical staff in the Power Systems Group at the Jet Propulsion Laboratory Twenty-five years of experience in spacecraft design including 22 at JPL, over 250 studies in Team-X, and numerous proposals. Current assignments include a wide variety of planetary mission concepts, covering all targets within the solar system and all mission classes. Paul graduated from Loras College with a B.S. in Chemistry in 1983  Vincent Randolph is a senior engineer in the Advanced Computer Systems and 


the Advanced Computer Systems and Technologies Group at the Jet Propulsion Laboratory. Current work includes generating Command and Data Handling Subsystem conceptual designs for various proposals and Team X.  He also supports Articulation Control and Electronics design activities for the Advanced Mirror Development project. Vincent graduated from the University of California at Berkeley with a B.S. in Electrical Engineering 18  pre></body></html 


i models into time and covariate dependent dynamic counterparts  ii models and reliability analysis in a more realistic manner  iii level  whether or not functional components \(loyal generals diagnose correctly and take proper actions such as fault mask of failed components \(traitors asymmetric  iv survivability analysis. Evolutionary game modeling can derive sustainable or survivable strategies \(mapped from the ESS in EGT such as node failures such as security compromise level modeling in the so-called three-layer survivability analysis developed in Ma \(2008a this article  v offer an integrated architecture that unite reliability survivability, and fault tolerance, and the modeling approaches with survival analysis and evolutionary game theory implement this architecture. Finally, the dynamic hybrid fault models, when utilized to describe the survival of players in EGT, enhance the EGT's flexibility and power in modeling the survival and behaviors of the game players which should also be applicable to other problem domains where EGT is applicable  5. OPERATIONAL LEVEL MODELING AND DECISION-MAKING  5.1. Highlights of the Tactical and Strategic Levels  Let's first summarize what are obtainable at both tactical and strategic levels. The results at both tactical and strategic levels are precisely obtainable either via analytic or simulation optimization. With the term precisely, we mean that there is no need to assign subjective probabilities to UUUR events. This is possible because we try to assess the consequences of UUUR events \(tactical level ESS strategies \(strategic level time prediction of survivability. The following is a list of specific points. I use an assumed Wireless Sensor Network WSN  i of UUUR events: \(a actions which can be treated as censored events; \(b Cont' of Box 4.2 It can be shown that the replicator differential equations are equivalent to the classical population dynamics models such as Logistic differential equation and LotkaVolterra equation \(e.g., Kot 2001 Logistic equation, or the limited per capital growth rate is similar to the change rate of the fitness  xfxfi which can be represented with the hazard function or survivor functions introduced in the previous section on survival analysis.  This essentially connects the previous survival analysis modeling for lifetime and reliability with the EGT modeling. However, EGT provides additional modeling power beyond population dynamics or survival analysis approaches introduced in the previous section. The introduction of evolutionary theory makes the games played by a population evolvable. In other words, each player \(individual 


other words, each player \(individual agent and players interact with each other to evolve an optimized system Box 4.3. Additional Comments on DHF Models  The above introduced EGT models are very general given they are the system of ordinary differential equations. Furthermore, the choice of fitness function f\(x complexity to the differential equation system.  The system can easily be turned into system of nonlinear differential equations. The analytical solution to the models may be unobtainable when nonlinear differential equations are involved and simulation and/or numerical computation are often required  In the EGT modeling, Byzantine generals are the game players, and hybrid fault models are conveniently expressed as the strategies of players; the players may have different failure or communication behaviors Furthermore, players can be further divided into groups or subpopulations to formulate more complex network organizations. In the EGT modeling, reliability can be represented as the payoff \(fitness, the native term in EGT of the game. Because reliability function can be replaced by survivor function, survival analysis is seamlessly integrated into the EGT modeling. That is, let Byzantine generals play evolutionary games and their fitness reliability function  The evolutionary stable strategy \(ESS counterpart of Nash equilibrium in traditional games ESS corresponds to sustainable strategies, which are resistant to both internal mutations \(such as turning into treason generals or nodes such as security compromises represent survivable strategies and survivability in survivability analysis. Therefore, dynamic hybrid fault models, after the extension with EGT modeling, can be used to study both reliability and survivability 13 risks such as competing risks which can be described with CRA; \(c captured with the shard frailty.  We believe that these UUUR events are sufficiently general to capture the major factors/events in reliability, security and survivability whose occurrence probabilities are hard or impossible to obtain  Instead of trying to obtain the probabilities for these events which are infeasible in most occasions, we focus on analyzing the consequences of the events.  With survival analysis, it is possible to analyze the effects of these types of events on survivor functions. In addition, spatial frailty modeling can be utilized to capture the heterogeneity of risks in space, or the spatial distribution of risks \(Ma 2008a d UUUR events introduced previously. These approaches and models that deal with the effects of UUUR events form the core of tactical level modeling  To take advantage of the tactical level modeling approaches it is obviously necessary to stick to the survivor functions or hazard functions models. In other words, survival analysis can deal with UUUR events and offer every features reliability function provides, but reliability function cannot deal with UUUR events although survivor function and reliability function have the exactly same mathematical definition. This is the junction that survival analysis plays critical role in survivability analysis at tactical level. However, we 


recognize that it is infeasible to get a simple metric for survivability similar to reliability with tactical level modeling alone. Actually, up to this point, we are still vague for the measurement of survivability or a metric for survivability. We have not answered the question: what is our metric for survivability? We think that a precise or rigorous definition of survivability at tactical level is not feasible, due to the same reason we cited previously  the inability to determine the probabilities of UUUR events However, we consider it is very helpful to define a work definition for survivability at the tactical level  We therefore define the survivability at tactical level as a metric, Su\(t t function or reliability function with UUUR events considered. In the framework of three-layer survivability analysis, this metric is what we mean with the term survivability. The "metric" per se is not the focus of the three-layer survivability analysis. It is not very informative without the supports from the next two levels  strategic and operational models.  However, it is obvious that this metric sets a foundation to incorporate UUUR effects in the modeling at the next two levels  Due to the inadequacy of tactical level modeling, we proposed the next level approach  strategic level modeling for survivability. As expected, the tactical level is one foundation of strategic level modeling ii objectives: \(a affect survivability which survival analysis alone is not adequate to deal with; \(b survivability at tactical level is necessary but not sufficient for modeling survivability, we need to define what is meant with the term survivability at strategic level  With regard to \(a behaviors or modes which have very different consequences. These failure behaviors can be captured with hybrid fault models. However, the existing hybrid fault models in fault tolerance field are not adequate for applying to survivability analysis. There are two issues involved: one is the lack of real time notion in the constraints for hybrid fault models \(e.g., N&gt;3m+1 for Byzantine Generals problem synthesize the models after the real-time notions are introduced. The solution we proposed for the first issue is the dynamic hybrid fault models, which integrate survivor functions with traditional hybrid fault models. The solution we proposed for the second issue is the introduction of EGT modeling  With regard to \(b modeling our problem at strategic level, EGT modeling is essentially a powerful optimization algorithm.  One of the most important results from EGT modeling is the so-called evolutionary stable strategies \(ESS We map the ESS in EGT to survivable strategies in survivability analysis.   Therefore, at the strategic level, our work definition for survivability refers to the survivable strategies or sustainable strategies in the native term of EGT, which can be quantified with ESS  In addition to integrating dynamic hybrid fault models another advantage for introducing EGT modeling at strategic level is the flexibility for incorporating other node behaviors \(such as cooperative vs. non-cooperative those behaviors specified in standard hybrid fault models, as well as anthropocentric factors such as costs constraints  Without UUUR events, both tactical and strategic level 


Without UUUR events, both tactical and strategic level models default to regular reliability models. This implies that, in the absence of UUUR events, reliable strategies are sustainable or survivable.  This also implies that three-layer survivability analysis defaults to reliability analysis however, the three-layer approach does offer some significant advantages over traditional reliability analysis, as discussed in previous sections. Nevertheless, when UUUR events exist, reliable strategies and survivable strategies are different. This necessitates the next operational level modeling  5.2. Operational Level Modeling and Decision-Making  When UUUR events are involved, we cannot make real time predictions of survivability at tactical and strategic levels This implies that the implementations of survivable 14 strategies need additional measures that we develop in this section.  Box 5.1 explains the ideas involved with possibly the simplest example  Figure 4 is a diagram showing a simplified relationship between action threshold survivability \(TS survivability \(ES view since both TS and ES are multidimensional and dynamic in practice. Therefore, the sole purpose of the diagram is to illustrate the major concepts discussed above The blue curve is the survivability when survivable strategies specified by ESS are implemented at some point before time s.  The system is then guaranteed to hold survivability above ES. In contrary, if no ESS implemented before time s, then the system quickly falls below to the survivable level at around 40 time units  T i m e 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 1 0 0 Su rv iv ab ili ty M et ric S u t 0 . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 . 0 E S S  i s  I m p lm e n t e d N o  E S S  is  I m p lm e n t e d ts E S T S  Figure 4. A Diagram Showing the Relationship Between TS and ES, as well as timing of s and t, with s &lt; t  6. SUMMARY  The previous sections discussed the major building blocks 


The previous sections discussed the major building blocks for the new life-system inspired PHM architecture. This section first identifies a few minor aspects that have not been discussed explicitly but are necessary for the implementation of the architecture, and then we summarize the major building blocks in a diagram  6.1. Missing Components and Links  Optimization Objectives  Lifetime, reliability, fault tolerance, and survivability, especially the latter two, are application dependent. Generally, the optimization of reliability and survivability are consistent; in that maximization of reliability also implies maximization of survivability. However, when application detail is considered, optimization of lifetime is not necessarily consistent with the optimization of reliability. Consider the case of the monitoring sensor network as an example. The network reliability is also dependent on connectivity coverage, etc, besides network lifetime. What may be further complicated is the time factor. All of the network metrics are time-dependent. A paradoxical situation between lifetime and reliability could be that nodes never 'sleep                                                   


          Box 5.1 Operational Level Modeling  Assuming that the ESS solution for a monitoring sensor network can be expressed with the following simple algebraic conditions: survivability metric at tactical level SU = 0.7, Router-Nodes in the WSN &gt; 10%, Selfish Nodes &lt; 40%. Even with this extremely simplified scenario, the ESS strategies cannot be implemented because we do not know when the actions should be taken to warrant a sustainable system.  These conditions lack a correlation with real time  The inability to implement ESS is rooted in our inability to assign definite probabilities to UUUR events, which implies that we cannot predict when something sufficiently bad will jeopardize the system survivability What we need at the operational level is a scheme to ensure ESS strategy is in place in advance  The fundamental idea we use to implement the ESS strategy is to hedge against the UUUR events. The similar idea has been used in financial engineering and also in integrated pest management in entomology. This can be implemented with the following scheme  Let us define a pair of survivability metrics: one is the expected survivability \(ES threshold survivability or simply threshold survivability \(TS ES is equivalent to the survivability metric at tactical level. ES corresponds to ESS at strategic level, but they are not equivalent since ESS is strategy and ES is survivability. TS is the survivability metric value \(at tactical level and TS can be obtained from strategic level models. For example, TS = SU\(s t condition for the implementation of ESS. In other words, the implementation of strategies that ensures TS at time s will guarantee the future ES level at time t.  To make the implementation more reliable and convenient multiple dynamic TSs can be computed at time s1, s2 sk, with si &lt; t for all i.  These TS at times s1, s2, ..., sk should be monitored by some evaluation systems  Unlike tactical and strategic levels, the operational level modeling is approximate. The term "approximate means that we cannot predict the real time survivability or we do not know the exact time an action should be taken. Instead, the action is triggered when the monitored survivability metric SU\(r survivability \(TS scheme of TS and ES, we ensure the ES by taking preventative actions \(prescribed by ESS and triggered by the TS consequences of UUUR events  Figure 4 is a diagram showing the above concepts and the decision-making process involved 15 This wakefulness \(never 'sleep short period but at the expense of network lifetime. Of course, when the network is running out of lifetime, network reliability ultimately crashes. This example reminds us that 


reliability ultimately crashes. This example reminds us that multi-objective optimization should be the norm rather than exception  Constraints and Extensions  Many application specific factors and constraints are ignored in this article. For example, we mentioned about spatial heterogeneity of environment, but never present a mathematical description The spatial heterogeneity can be modeled with the so-called spatial frailty in multivariate survival analysis \(Ma 2008a  Evolutionary Algorithm  Evolutionary game modeling when implemented in simulation, can be conveniently implemented with an algorithm similar to Genetic Algorithms \(GA ESS in the evolutionary game model with simulation is very similar to GA. Dynamic populations, in which population size varies from generation to generation \(Ma &amp; Krings 2008f of node failures. Another issue to be addressed is the synchronous vs. asynchronous updating when topology is considered in the simulation. This update scheme can have profound influences on the results of the simulation. Results from cellular automata computing should be very useful for getting insights on the update issue  6.2. Summary and Perspective  To recapture the major points of the article, let us revisit Figure 3, which summarizes the principal modules of the proposed life-system inspired PHM architecture. The main inspiration from life systems is the notion of individuals and their assemblage, the population. Population is an emergent entity at the next level and it has emergent properties which we are often more concerned with. Survival analysis, which has become a de facto standard in biomedicine, is particularly suitable for modeling population, although it is equally appropriate at individual level. Therefore, survival analysis \(including competing risks analysis and multivariate survival analysis comprehensively in the context of PHM in a series of four papers presented at IEEE AeroSpace 2008 \(Ma &amp; Krings 2008a, b, c, &amp; d proposed architecture. Survival analysis constitutes the major mathematical tools for analyzing lifetime and reliability, and also forms the tactical level of the three-layer survivability analysis  Besides lifetime and reliability, two other major modules in Figure 3 are fault tolerance and survivability. To integrate fault tolerance into the PHM system, Dynamic Hybrid Fault DHF 2008e, Ma 2008a make real-time prediction of reliability more realistic and make real-time prediction of fault tolerance level possible DHF models also unite lifetime, reliability and fault tolerance under a unified modeling framework that consists of survival analysis and evolutionary game theory modeling  DHG models also form the partial foundation, or strategic level, for the three-layer survivability analysis. At the strategic level, the Evolutionary Stable Strategies \(ESS which is mapped to survivable or sustainable strategies, can be obtained from the evolutionary game theory based DHF models. When there is not any UUUR event involved reliability and survivability are consistent, and reliable strategies are survivable. In this case, the strategic level modeling up to this point is sufficient for the whole PHM system modeling, and there is no need for the next level  operational level modeling  When there are UUUR events in a PHM system, the 


When there are UUUR events in a PHM system, the inability to determine the occurrence probabilities of UUUR events makes the operational level modeling necessary Then the principle of hedging must be utilized to deal with the "hanging" uncertainty from UUUR events. In this case reliability strategies are not necessarily survivable strategies At the operational level modeling, a duo of survivability metrics, expected survivability \(ES survivability \(TS the survivable strategies \(ESS level are promptly implemented based on the decisionmaking rules specified with the duo of survivability metrics then the PHM system should be able to endure the consequences of potentially catastrophic UUUR events. Of course, to endure such catastrophic events, the cost may be prohibitively high, but the PHM system will, at least, warn decision-makers for the potentially huge costs.  It might be cheap to just let it fail  Figure 3 also shows several other modules, such as security safety, application systems \(such as Automatic Logistics CBM+, RCM, Life cycle cost management, Real-time warning and alert systems architectures, but we do not discuss in this paper. Generally the new architecture should be fully compatible with existing ones in incorporating these additional modules. One point we stressed is that PHM system can be an ideal place to enforce security policies. Enforcing security policies can be mandatory for PHM systems that demand high security and safety such as weapon systems or nuclear plant facilities.  This is because maintenance, even without human-initiated security breaches, can break the security policies if the maintenance is not planned and performed properly  In perspective, although I did not discuss software issues in this paper, the introduced approaches and models should provide sufficient tools for modeling software reliability and survivability with some additional extension. Given the critical importance of software to modern PHM systems, we present the following discussion on the potential extension to software domain. Specifically, two points should be noted: \(1 architecture to software should be a metric which can 16 replace the time notion in software reliability; I suggest that the Kolmogorov complexity \(e.g., Li and Vitanyi 1997 be a promising candidate \(Ma 2008a change is because software does not wear and calendar time for software reliability usually does not make much sense 2 software reliability modeling.  Extending to general survivability analysis is not a problem either. In this article I implicitly assume that reliability and survivability are positively correlated, or reliability is the foundation of survivability. This positive correlation does not have to be the case. A simplified example that illustrates this point is the 'limit order' in online stock trading, in which limit order can be used in either direction: that stock price is rising or falling.  The solution to allow negative or uncorrelated relationships between reliability and survivability are very straightforward, and the solutions are already identified in previous discussions. Specifically, multiple G-functions and multi-stage G-functions by Vincent and Brown \(2005 very feasible solution, because lifetime, reliability and survivability may simply be represented with multiple Gfunctions. Another potential solution is the accommodation of the potential conflicts between reliability and survivability with multi-objective GA algorithms, which I previously suggested to be used as updating algorithms in the optimization of evolutionary games  


 The integration of dynamic hybrid fault models with evolutionary game modeling allows one to incorporate more realistic and detailed failure \(or survival individual players in an evolutionary game. This is because dynamic hybrid fault models are supported by survival analysis modeling, e.g., time and covariate dependent hazard or survivor functions for individual players. If necessary, more complex survival analysis modeling including competing risks analysis and multivariate survival analysis, can be introduced.  Therefore, any field to which evolutionary game theory is applicable may benefit from the increased flexibility in modeling individual players.  Two particularly interesting fields are system biology and ecological modeling.  In the former field, dynamic hybrid fault models may find important applications in the study of biological networks \(such as gene, molecular, and cell networks 2008g conjecture that explains the redundancy in the universal genetic code with Byzantine general algorithm. In addition they conducted a comparative analysis of bio-robustness with engineering fault tolerance, for example, the strong similarity between network survivability and ecological stability \(Ma &amp; Krings 2008g survivability analysis can be applied for the study of survivals or extinctions of biological species under global climate changes \(Ma 2008b  In this paper, I have to ignore much of the details related to the implementation issues to present the overall architecture and major approaches clearly and concisely. To deal with the potential devils in the implementation details, a well funded research and development team is necessary to take advantages of the ideas presented here. On the positive side I do see the great potential to build an enterprise PHM software product if there is sufficient resource to complete the implementation. Given the enormous complexity associated with the PHM practice in modern engineering fields, it is nearly impossible to realize or even demonstrate the benefits of the architecture without the software implementation. The critical importance of PHM to mission critical engineering fields such as aerospace engineering, in turn, dictates the great value of such kind software product  6.3. Beyond PHM  Finally, I would like to raise two questions that may be interested in by researchers and engineers beyond PHM community. The first question is: what can PHM offer to other engineering disciplines? The second question is: what kinds of engineering fields benefit most from PHM? Here, I use the term PHM with the definition proposed by IEEE which is quoted in the introduction section of the paper  As to the first question, I suggest software engineering and survivability analysis are two fields where PHM can play significant roles. With software engineering, I refer to applying PHM principles and approaches for dealing with software reliability, quality assurance, and even software process management, rather than building PHM software mentioned in the previous subsection. For survivability analysis, borrowing the procedures and practices of PHM should be particularly helpful for expanding its role beyond its originating domain \(network systems that control critical national infrastructures is a strong advocate for the expansion of survivability analysis to PHM. Therefore, the interaction between PHM and survivability analysis should be bidirectional. Indeed, I see the close relationships between PHM, software engineering, and survivability as well-justified because they all share some critical issues including reliability survivability, security, and dependability  


 The answer to the second question is much more elusive and I cannot present a full answer without comparative analysis of several engineering fields where PHM has been actively practiced. Of course, it is obvious that fields which demand mission critical reliability and dependability also demand better PHM solutions. One additional observation I would like to make is that PHM seems to play more crucial roles for engineering practices that depend on the systematic records of 'historical' data, such as reliability data in airplane engine manufacturing, rather than on the information from ad hoc events.  This may explain the critical importance of PHM in aerospace engineering particularly in commercial airplane design and manufacturing.  For example, comparing the tasks to design and build a space shuttle vs. to design and manufacture commercial jumbo jets, PHM should be more critical in the latter task  17    Figure 2. States of a monitoring sensor node and its failure modes \(after Ma &amp; Krings 2008e     Figure 3. Core Modules and their Relationships of the Life System Inspired PHM Architecture    REFERENCES  Adamides, E. D., Y. A. Stamboulis, A. G. Varelis. 2004 Model-Based Assessment of Military Aircraft Engine Maintenance Systems Model-Based Assessment of Military Aircraft Engine Maintenance Systems. Journal of the Operational Research Society, Vol. 55, No. 9:957-967  Anderson, R. 2001. Security Engineering. Wiley  Anderson, R. 2008. Security Engineering. 2nd ed. Wiley  Bird, J. W., Hess, A. 2007.   Propulsion System Prognostics R&amp;D Through the Technical Cooperation Program Aerospace Conference, 2007 IEEE, 3-10 March 2007, 8pp  Bock, J. R., Brotherton, T., W., Gass, D. 2005. Ontogenetic reasoning system for autonomic logistics. Aerospace Conference, 2005 IEEE 5-12 March 2005.Digital Object Identifier 10.1109/AERO.2005.1559677  Brotherton, T., P. Grabill, D. Wroblewski, R. Friend, B Sotomayer, and J. Berry. 2002. A Testbed for Data Fusion for Engine Diagnostics and Prognostics. Proceedings of the 2002 IEEE Aerospace Conference  Brotherton, T.; Grabill, P.; Friend, R.; Sotomayer, B.; Berry J. 2003. A testbed for data fusion for helicopter diagnostics and prognostics. Aerospace Conference, 2003. Proceedings 2003 IEEE  Brown, E. R., N. N. McCollom, E-E. Moore, A. Hess. 2007 Prognostics and Health Management A Data-Driven Approach to Supporting the F-35 Lightning II. 2007 IEEE AeroSpace Conference  Byington, C.S.; Watson, M.J.; Bharadwaj, S.P. 2008 Automated Health Management for Gas Turbine Engine Accessory System Components. Aerospace Conference 2008 IEEE, DOI:10.1109/AERO.2008.4526610 


2008 IEEE, DOI:10.1109/AERO.2008.4526610 Environment Covariates &amp; Spatial Frailty Applications: AL; Life Cycle Mgmt; Real-Time Alerts CBM+, RCM, TLCSM; Secret Sharing and Shared Control 18 Chen, Y. Q., S. Cheng. 2005. Semi-parametric regression analysis of mean residual life with censored survival data Biometrika \(2005  29  Commenges, D. 1999. Multi-state models in Epidemiology Lifetime Data Analysis. 5:315-327  Cook, J. 2004. Contrasting Approaches to the Validation of Helicopter HUMS  A Military User  s Perspective Aerospace Conference, 2004 IEEE  Cook, J. 2007. Reducing Military Helicopter Maintenance Through Prognostics. Aerospace Conference, 2007 IEEE Digital Object Identifier 10.1109/AERO.2007.352830  Cox, D. R. 1972. Regression models and life tables.  J. R Stat. Soc. Ser. B. 34:184-220  Crowder, M. J.  2001. Classical Competing Risks. Chapman amp; Hall. 200pp  David, H. A. &amp; M. L. Moeschberger. 1978. The theory of competing risks. Macmillan Publishing, 103pp  Ellison, E., L. Linger, and M. Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013  Hanski, I. 1999. Metapopulation Ecology. Oxford University Press  Hallam, T. G. and S. A. Levin. 1986. Mathematical Ecology. Biomathematics. Volume 17. Springer. 457pp  Hess, A., Fila, L. 2002.  The Joint Strike Fighter \(JSF concept: Potential impact on aging aircraft problems Aerospace Conference Proceedings, 2002. IEEE. Digital Object Identifier: 10.1109/AERO.2002.1036144  Hess, A., Calvello, G., T. Dabney. 2004. PHM a Key Enabler for the JSF Autonomic Logistics Support Concept. Aerospace Conference Proceedings, 2004. IEEE  Hofbauer, J. and K. Sigmund. 1998. Evolutionary Games and Population Dynamics. Cambridge University Press 323pp  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Huzurbazar, A. V. 2006. Flow-graph model for multi-state time-to-event data. Wiley InterScience  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis. Springer. 481pp  Kacprzynski, G. J., Roemer, M. J., Hess, A. J. 2002. Health management system design: Development, simulation and cost/benefit optimization. IEEE Aerospace Conference Proceedings, 2002. DOI:10.1109/AERO.2002.1036148  Kalbfleisch, J. D., and R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data. Wiley-InterScience, 2nd ed  Kalgren, P. W., Byington, C. S.   Roemer, M. J.  2006 Defining PHM, A Lexical Evolution of Maintenance and Logistics. Systems Readiness Technology Conference 


Logistics. Systems Readiness Technology Conference IEEE. DOI: 10.1109/AUTEST.2006.283685  Keller, K.; Baldwin, A.; Ofsthun, S.; Swearingen, K.; Vian J.; Wilmering, T.; Williams, Z. 2007. Health Management Engineering Environment and Open Integration Platform Aerospace Conference, 2007 IEEE, Digital Object Identifier 10.1109/AERO.2007.352919  Keller, K.; Sheahan, J.; Roach, J.; Casey, L.; Davis, G Flynn, F.; Perkinson, J.; Prestero, M. 2008. Power Conversion Prognostic Controller Implementation for Aeronautical Motor Drives. Aerospace Conference, 2008 IEEE. DOI:10.1109/AERO.2008.4526630  Klein, J. P. and M. L. Moeschberger. 2003. Survival analysis techniques for censored and truncated data Springer  Kingsland, S. E. 1995. Modeling Nature: Episodes in the History of Population Ecology. 2nd ed., University of Chicago Press, 315pp  Kot, M. 2001. Elements of Mathematical Ecology Cambridge University Press. 453pp  Krings, A. W. and Z. S. Ma. 2006. Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks Military Communications Conference, 23-25 October, 7 pages, 2006  Lamport, L., R. Shostak and M. Pease. 1982. The Byzantine Generals Problem. ACM Transactions on Programming Languages and Systems, 4\(3  Lawless, J. F. 2003. Statistical models and methods for lifetime data. John Wiley &amp; Sons. 2nd ed  Line, J. K., Iyer, A. 2007. Electronic Prognostics Through Advanced Modeling Techniques. Aerospace Conference 2007 IEEE. DOI:10.1109/AERO.2007.352906  Lisnianski, A., Levitin, G. 2003. Multi-State System Reliability: Assessment, Optimization and Applications World Scientific  Liu, Y., and K. S. Trivedi. 2006. Survivability Quantification: The Analytical Modeling Approach, Int. J of Performability Engineering, Vol. 2, No 1, pp. 29-44  19 Luchinsky, D.G.; Osipov, V.V.; Smelyanskiy, V.N Timucin, D.A.; Uckun, S. 2008. Model Based IVHM System for the Solid Rocket Booster. Aerospace Conference, 2008 IEEE.DOI:10.1109/AERO.2008.4526644  Lynch, N. 1997. Distributed Algorithms. Morgan Kaufmann Press  Ma, Z. S. 1997. Demography and survival analysis of Russian wheat aphid. Ph.D. dissertation, Univ. of Idaho 306pp  Ma, Z. S. 2008a. New Approaches to Reliability and Survivability with Survival Analysis, Dynamic Hybrid Fault Models, and Evolutionary  Game Theory. Ph.D. dissertation Univ. of Idaho. 177pp  Ma, Z. S. 2008b. Survivability Analysis of Biological Species under Global Climate Changes: A New Distributed and Agent-based Simulation Architecture with Survival Analysis and Evolutionary Game Theory. The Sixth 


International Conference on Ecological Informatics. Dec 25, 2008. Cancun, Mexico  Ma, Z. S. and E. J. Bechinski. 2008. A Survival-Analysis based  Simulation Model for Russian Wheat Aphid Population Dynamics. Ecological Modeling, 216\(2 332  Ma, Z. S. and A. W. Krings. 2008a.  Survival Analysis Approach to Reliability Analysis and Prognostics and Health Management \(PHM  AIAA AeroSpace Conference, March 1-8, 2008, Big Sky, MT, 20pp  Ma, Z. S. and A. W. Krings. 2008b. Competing Risks Analysis of Reliability, Survivability, and Prognostics and Health Management \(PHM  AIAA AeroSpace Conference, March 1-8, 2008.  Big Sky, MT. 20pp  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(I Dependence Modeling", Proc. IEEE  AIAA AeroSpace Conference, March 1-8, 2008, Big Sky, MT. 21pp  Ma, Z. S. and A. W. Krings., R. E. Hiromoto. 2008d Multivariate Survival Analysis \(II State Models in Biomedicine and Engineering Reliability IEEE International Conference of Biomedical Engineering and Informatics, BMEI 2008.  6 Pages  Ma, Z. S. and A. W. Krings. 2008e. Dynamic Hybrid Fault Models and their Applications to Wireless Sensor Networks WSNs Modeling, Analysis and Simulation of Wireless and Mobile Systems. \(ACM MSWiM 2008 Vancouver, Canada  Ma, Z. S. &amp; A. W. Krings. 2008f. Dynamic Populations in Genetic Algorithms. SIGAPP, the 23rd Annual ACM Symposium on Applied Computing, Ceara, Brazil, March 16-20, 2008. 5 Pages  Ma, Z. S. &amp; A. W. Krings. 2008g. Bio-Robustness and Fault Tolerance: A New Perspective on Reliable, Survivable and Evolvable Network Systems, Proc. IEEE  AIAA AeroSpace Conference, March 1-8, Big Sky, MT, 2008. 20 Pages  Ma, Z. S.  and A. W. Krings. 2009. Insect Sensory Systems Inspired Computing and Communications.  Ad Hoc Networks 7\(4  MacConnell, J.H. 2008. Structural Health Management and Structural Design: An Unbridgeable Gap? 2008 IEEE Aerospace Conference, DOI:10.1109/AERO.2008.4526613  MacConnell, J.H. 2007. ISHM &amp; Design: A review of the benefits of the ideal ISHM system. Aerospace Conference 2007 IEEE. DOI:10.1109/AERO.2007.352834  Marshall A. W., I. Olkin. 1967. A Multivariate Exponential Distribution. Journal of the American Statistical Association, 62\(317 Mar., 1967  Martinussen, T. and T. H. Scheike. 2006. Dynamic Regression Models for Survival Data. Springer. 466pp  Mazzuchi, T. A., R. Soyer., and R. V. Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Millar, R.C., Mazzuchi, T.A. &amp; Sarkani, S., 2007. A Survey of Advanced Methods for Analysis and Modeling of 


of Advanced Methods for Analysis and Modeling of Propulsion System", GT2007-27218, ASME Turbo Expo 2007, May 14-17, Montreal, Canada  Millar, Richard C., "Non-parametric Analysis of a Complex Propulsion System Data Base", Ph.D. Dissertation, George Washington University, June 2007  Millar, R. C. 2007. A Systems Engineering Approach to PHM for Military Aircraft Propulsion Systems. Aerospace Conference, 2007 IEEE. DOI:10.1109/AERO.2007.352840  Millar, R. C. 2008.  The Role of Reliability Data Bases in Deploying CBM+, RCM and PHM with TLCSM Aerospace Conference, 2008 IEEE, 1-8 March 2008. Digital Object Identifier: 10.1109/AERO.2008.4526633  Nowak, M. 2006. Evolutionary Dynamics: Exploring the Equations of Life. Harvard University Press. 363pp  Oakes, D. &amp; Dasu, T. 1990. A note on residual life Biometrika 77, 409  10  Pintilie, M. 2006. Competing Risks: A Practical Perspective.  Wiley. 224pp  20 Smith, M. J., C. S. Byington. 2006. Layered Classification for Improved Diagnostic Isolation in Drivetrain Components. 2006 IEEE AeroSpace Conference  Therneau, T. and P. Grambsch. 2000. Modeling Survival Data: Extending the Cox Model. Springer  Vincent, T. L. and J. L. Brown. 2005. Evolutionary Game Theory, Natural Selection and Darwinian Dynamics Cambridge University Press. 382pp  Wang. J., T. Yu, W. Wang. 2008. Research on Prognostic Health Management \(PHM on Flight Data. 2008 Int. Conf. on Condition Monitoring and Diagnosis, Beijing, China, April 21-24, 2008. 5pp  Zhang, S., R. Kang, X. He, and M. G. Pecht. 2008. China  s Efforts in Prognostics and Health Management. IEEE Trans. on Components and Packaging Technologies 31\(2             BIOGRAPHY  Zhanshan \(Sam scientist and earned the terminal degrees in both fields in 1997 and 2008, respectively. He has published more than 60 peer-refereed journal and conference papers, among which approximately 40 are journal papers and more than a third are in computer science.  Prior to his recent return to academia, he worked as senior network/software engineers in semiconductor and software industry. His current research interests include: reliability, dependability and fault tolerance of distributed and software systems behavioral and cognitive ecology inspired pervasive and 


behavioral and cognitive ecology inspired pervasive and resilient computing; evolutionary &amp; rendezvous search games; evolutionary computation &amp; machine learning bioinformatics &amp; ecoinformatics                 pre></body></html 



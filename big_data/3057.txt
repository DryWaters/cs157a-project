Implementation of a Least Fixpoint Operator for Fast Mining of Relational Databases Hasan M Jarnil Department of Computer Science Mississippi State University USA jamilQcs.msstate.edu Abstract Recent resenrch has focused on computing large item sets for association de mining using SQL3 least Erpoint computa tion and by exploiting the monotonic nature of the SQL3 aggregate functions such as sum and create view recursive constructs Such approaches allow us to view mining as an ad hoc querying ezercise and treat the eficiency issue as on optimization 
pmblem In this paper we present a recursive implementation of a recently proposed least Erpoint operator for computing large item sets from object-relational databases We present experimental evidence to show that our implemen tation compares well with seweml well-regarded and contempo mry algorithms for large item set genemtion 1 Introduction the recursion Two approaches were proposed In 3 41 we have investigated computation of large item sets using a computationally expensive recursive join computation But it was shown that unlike apriori like approaches it can be made to compute only non-redundant large item sets In 
5 an apriori like fixpoint computation was also proposed This approach required the development of a Tp like operator usually found in deductive database literature The idea for such an operator was captured in the following representative SQL3 view definition for large item sets called the ILtable In the following SQL3 expressions t.table\(TranID Items is supplied as the input transaction table where TranID is the transaction ID and Items is a set of items \(readers may refer to 5 for a complete discussion on these expresions and the fixpoint computation approach create view f-table as iselect Items countiltems\\lm as Suooort 
I  from 1-table group by create sequence seq increment by create view recursive lztoble as select Items sum\(Suppor1 as Support from flatten\(se1ect sub\(ltems  I as Items, Support erouD bv Items The importance and need for integrating data mining with relational databases have been addressed in several articles such as 7 91 The authors convincingly argue that without such integration data mining technology may not find itself in a viable position in the years to come To be a successful and feasible tool for the analysis of business data in relational databases such technology must be made available 
as part of database query engines in a declarative way Start with 1 from f-table Declarative computation of association rules were iuvesti gated in works such as 6 8 91 Meo et al 6 proposes a new SQL like declarative query language for association rule mining which ap ears to be heavily oriented towards trans action databasff  In their extended language they blend a rule mine operator with SQL and other additional features The series of research reported in 8 91 spear headed by IBM researchers mostly addressed the mining issue itself They attempted to compute the large item sets by generating can didate sets 
testing for their admissibility based on their MC model combination and GatherJoin operators Essentially these works represent a faithful encoding of apriori like algo rithms using SQL, and like 6 become too specific In a series of recent research 13 4 51 we have shown that association NI can be easily computed as ad hoc SQL3  queries without requiring any specialized relational operators or language Constructs SQL3's recursive view construct was particularly useful in developing the least fixpoint queries that involved the monotonic aggregate function sum inside  Research supported in pan by National Science Foundation grants EPS-0082979 
and EPS-0132618 It is important to note that association ruler may be computed for virtually my type of database, transaction or not P 0-7695-1754-4102 17.00 Q 2002 IEEE 633 I having sum\(Support 2 6 union all select t.ltems sum\(t.Support\as Support from f-table as U flatten distinct\(se1ect sub\(f.ltems Lltems i.Degree from f-table as f Ltable as 1 as Items select Seq.Neztwal as Degree from iteration as i I.ltems c f.ltems as t where siseof\(l.ltems  i.Degree  I 
and where t.ltems E u.ltems group by t.ltems having sum\(t.Support 2 6 What is interesting about these two approaches specially the approach in 3 41 is that unlike those in 6 8 91 only traditional SQL3 coustructs were used and in particular no mining specific features were needed And as such these approaches offer excellent opportunities for query optimization Even the expressions above and in 51 use only one user defined function sub which implements the selection of a set with a specific cardinality and membership from a power set of a given set of elements 


Initial experiments show that the SQLS apriori approach just outlined outperforms the recursive join approach in 3 41 as the farmer incorporates the stronger apriori pruning heuristics In 151 the following recursive relational operator Q was also proposed to abstract the apriori type hpoint encoding above Definition 1.1 Fixpoint Operator Let It and Su be two column names in a transaction database V with corre sponding item set and support type domains 6 be the min imum support threshold and n be the maximum cardinality of the item sets in It of 222D Then the large item sets operator e is defined as follows e:t,su\(D  S,>S,\(I~~S,=,,,\(S e?t.s.\(D  e;&\(v U 0se6 I:~s\224=.\224,\(s\224,\(\(~;t\(~D w\222 V The large item set operator Q is defined in terms of two other operators  called step and Wk called distance-k item set join defined as follows Let 1 be the set of all item and  be a total ordering on the labels of the items in Z Also let k-sub be a function that for any given item set s Z and k such that 15 k 5 IsI it returns all distance-k subsets of s For any two sets S and s s is said to be a degme-k subset of S ifs E P\(S and Is1  k Additionally s is called a distancek subset of S if k  IS1  1.1 Using this function we define the degree-k subsets of an item set relation as follows Definition 1.2 Let T be a relation such that its scheme includes a set valued attribute Items Then for any k 2 0 the degree-k subset of r is defined as f:tems\(T  t I v\(u E TA v E k-sub\(u[ltems A t  U u[R  Items For any two Sets of item sets SI and s2 in 9 SI is said to be a strict distance-k superset of sz if sz c SI Is  Is21  k and Vu,v\(u E SI A v E s2 AD  U  v  U Intuitively st is an increasing superset of sz For example abc is a strict distance1 superset of ab but not ac when we consider the ordering a  b  c    Let 5r be a binary Boolean operator that returns true if SI is a strict distance4 superset of SZ i.e s15ksz  true Finally we define a distance-k item set join w operator as follows Definition 1.3 Let T and s be two relations on scheme Items Support Then the distance item set join of T and 8 is defined as r w!be  fl-.ltmv.supso-t\(T Wr,ltema,ka.ltcma  S Notice that T Wk s returns all tuples in r such that there is a tuple in s that has an item set for which the item set in tuple of r is a distance-k superset Other tuples are not selected There is a more subtle issue here By defining and using the notion of strict distance-k supersets we have practically facilitated a 223beamed\224 join of item sets That is item sets will join with only another item set that has an increasing cardinality and order This is largely due to the ordering relation we insisted upon the item sets in 1 as a technical requirement Intuitively the item set join based on strict distance-k supersets works as follows Consider an input transaction table t-table and the corresponding large item set table Ltable as shown below for a support threshold 6  0.25 le Support __ 29 71 43 29 43 29 29 43 29 29  large item set tab Notice that in this example when a is a large item set in table t-table we need to generate the candidates ab and ac as b and e are also large Also because there are database entries that contain ab and ac This suggests that we need to consult the large item sets and the database entries to generate these candidates In this way we will not generate ad or a f  for example Again, when we consider b as a large item set we may want to consider generating ab one more time because it is a possibility But it is not necessary as we have already created ab as part of processing a The question that remains however is how do we implement this 223memory\224 in a set based setup such as relational algebra or SQL? One way to accomplish this is to apply SQL\222s distinct feature and make them unique but this is an inherently expensive and wasteful operation The strict distance-k supersets based item set join we have proposed help capture the idea by mimicking the affinity of the item sets large or candidate as shown in figure 1 during join processing in a set based setting Figure 1 beamed candidate generation path Exploration tree of input t-table showing In the remainder of the paper it is our goal to present a procedural implementation of Q and compare its performance with two leading approaches  FP-tree 2 and apriori l We proceed as follows In section 2 we present a recursive implementation of the operator followed by a comparative analysis in section 3 and conclusion in section 4 2 Implementation of the Fixpoint Operator In this section we present a simple algorithm that implements the least fix point operator Q with the hope of demonstrating that even this primitive implementation performs well and is 634 


comparable to leading algorithms and approaches in its class available in the literature such as 19 8 61 2.1 A Depth-First Recursive Algorithm The algorithm we are about to present exploits the so called beamed join technique for Wk operator that not only facilitates faster join but also allows us to explore the item set lattice discussed in 3 in a depth first manner in fact it reduces to a forest of trees Thus we trade time for space to avoid memory swaps This also allows us to explore the forest one tree at a time Let us first explain the basic idea of the algorithm using the example tables t-table and ILtable and a support threshold 6 2 0.25 The large item set operator necessitates that a set of distinct operations need to be performed in a sequence to compute the large item sets First we need to compute the large one item sets the exit rule We do so by scanning the database once and creating the list shown in figure 2 In this list for every one item set we list the record pointers to which an item set belongs Notice that e is not a large item set since its support is less than 6 marked with a box around the node and thus is taken out of the list L1 layer one list Figure 2 Generation of Litem sets Then we take one node at a time in the list LI and explore its subtree in a depth first manner Note that a node created in such a fashion will never be created in another branch in the forest and hence there is no duplication of node expansion To create the next level of a node we proceed as follows We scan the tid list of the node X and fetch the item sets one at a time We generate a new node with id Y only if the node id Y is larger than the current node id X in the  relation and it has not been created already. In the figure 3 below we expand the tree for node a followed by the tree for bin figure 4 Note that when we are at level 2 figure 3 we discard node e but continue to keep node b when we are exploring c We delete both band c when we exit from a but keep a until we move below a B Figure 3 Exploring the a-tree  depth first expansion shown from left to right The generation of next level nodes the way we did by checking for the satisfaction of the order relation  among the items implements W and EL when we are at level k The grouping is achieved by structuring the nodes in a tree as we did that always pushes an item set in one single branch of a tree The summing of the support is done hy counting the tids in the tid list and then checking if the node met the minimum threshold If it did then we expand it further if not we mark it dead marked with a box around a node and return to the parent node If the node is large we output the sequence from the root to the node as a large item set with its support count The algorithm we have just described is presented in figure 5 T Figure 4 Exploration of the btree 3 Performance Comparison In this section we present experimental evaluations of our framework as proof of its viability as a computing paradigm for association rules in relational databases In our performance study we compared our algorithm with apriori and FP-tree two leading competitors We have also implemented apriori and FP-tree ourselves to be fair by eliminating the experience factor of the programmer in the comparison We developed our algorithm in C on a PC with AMD Athlon Processor 1.2G processor running Windows NT with 196 MB memory 764 MB bytes virtual memory and lOGB hard drive We have used the IBM data sets T25110DlOK and T25120D100K for our evaluation These synthetic datasets were extensively used almost as a benchmark to compare relative performance of most association rule mining algorithms These data sets feature long patterns even for very small thresholds such as 0.1 and as such algorithms must explore almost all possible combinations of item sets Also these data sets intersect with each other overlap so heavily that the possible set of combinations is truly huge The graphs in figure 6 show the total execution times of our algorithm on these data sets and confirm that our algorithm performs better than apriori and almost approximates FP tree But so do many other algorithms The real question is does our algorithm perform better than other algorithms in its class  that is those which also take an approach based on relational computation of large item sets We would like to answer these questions in two steps First we think our approach can only be compared with works such as SI Unfortunately we could not run a comparative analysis using their data sets But from the published literature their method appears to be more expensive than our algorithm Their running times are listed in excess of 10,000 seconds in some cases while ours are expected to be lower As can be seen even for the large T25120D100K data set our total running time is less than 635 


algorithm forest.expension input A transaction table D support threshold 6 output Large item sets Lz ILtable begin scan D and generate a large 1-item set list LI while LI is not empty do with a tid list for every item in which they appear call the node pointed by LI X call procedure node-expansion remove node X from LI endwhile end algorithm node-expansion input A node X and item list in the path I output Void begin let the item in node X he U count the tid list T if the count is greater than 6 then output large item set I Uu and its count for every tid in the tid list T do fetch the item set s at T from D for every item i in s do if U  i and there is no child node Y at create a node Y with item i copy the ti in Y from T in which call procedure node-expansion X with item i then I U U U i appears else return mark X dead end Figure 5 Algorithms for the large item set operator 8,000 seconds for 0.1 support threshold \(note however that the hardware used is different Secondly we believe that novel indexing techniques will help improve the performance of our algorithm significantly We are currently developing an indexing scheme called the S trees for set valued domains that aids fast set operations such as c E 3 nand U Recall that W require such a join based on strict distance-k superset relationships Our hope is that such an indexing scheme will help us locate specific portions of the database that is relevant for the computation at hand thereby increasing performance 4 Conclusions It was our goal to demonstrate that association rules can be computed using existing SQL3 machineries which we believe we have done successfully We have of course used a couple of built-in functions for set operations that current SQL systems do not possibly support but we believe that future enhancements of SQL will These functions can be easily implemented using SQL's create function statements as we have done We have demonstrated that SQL's create view Figure 6 Total execution time of fixpoint on the data sets T25110DlOK and T25120D100K as compared to apriori l and FP-tree 2 recursive clause can simulate apriori effortlessly once the idea of a least fixpoint operator for apriori was at hand As a second step we have also attempted to support our conviction with an implementation of the large item set operator e that we have proposed The initial performance results show that our algorithm does better than apriori and possibly better than 9 We believe that new techniques for computing Wk based on set indexing would be useful and efficient In this connection we are current1 investigating query optimization issues involving e and W operators in relational algebra expressions Y References l Rakesh Agrawal and Ramakrishnan Srikant Fast algo rithms for mining association rules in large databases In VLDB pages 487-499 1994 2 Jiawei Han Jian Pei, and Yiwen Yin Mining frequent patterns without candidate generation In Pmc ACM SIGMOD pages 1-12 2000 3 Hasan M Jamil Ad hoc association rule mining as SQL3 queries In IEEE ICDM pages 609-612 2001 141 Hasan M Jamil Mining first-order knowledge bases for association rules In IEEE ICTAI pages 218-227 2001 51 Hasan M Jamil On the equivalence of top-down and bottom-up data mining in relational databases In Dn WnK pages 41-50 Munich, Germany 2001 6 Rosa Meo Giuseppe Psaila and Stefan0 Ceri An extension to SQL for mining association rules DMKD 2\(2 1998 7 Amir Netz Surajit Chaudhuri Usama M Fayyad and Jeff Bernhardt Integrating data mining with SQL databases In IEEE ICDE 2001 8 Karthick Rajamani Alan Cox Bala Iyer and Atul Chadha Efficient mining for association rules with relational database systems In IDEAS pages 148-165 1999 9 Sunita Sarawagi Shiby Thomas and Mesh Agrawal Integrating mining with relational database systems Alternatives and implications In Proc ACM SIGMOD pages 343-354 1998 636 


Proceedings of the First International Conference on Machine Learning and Cybernetics Beijing 4-5 November 2002 Atmbutes Product Purchase Records  Customer Purchase Records  Leaf Node preference has no matching taste in another preference it will be deleted 3 The method of taste aggregating is alike with that of learning preferences \(see Section 2.3 15 130 16 4 Product recommendation The goal of the recommendation system is to generate a recommendation set for active customer of which the products most closely match active customer profile In our method both customer profiles and products are represented as the same model So it is fairly convenient to compute the similarity between a customer profile and a product Preference  TI twl T2 twz  T twn Product  41 awl Az aw2  A awn If Ti\(Ai has numerical value Ti vl v2 and Ai v the similarity between Ti and Ai can be computed by 12v-v v I Tastesimilarity  I v2 v1 If it has literal value then Ti  tl tw1 tz twz  The similarity between Ti and Ai can be calculated by the et twn CUI awl 2 wp  a awn following Cosine function 2 tw x awi  Tastesimilarity  i=l  i=l i=l So the similarity of preference and product is  TasteSimilarity x tasteweight In the end the recommendation set for active customer can be obtained by RecommendationSet   Product I PreferenceSimilarity t where t is a threshold of preference similarity PreferenceSimilarity n i=l 5 Experiments The dataset is extracted from http://www.amazon.com http://www prime. wines corn http://www.needmorebeer.com http://www.cornwellcoffee.com From these Web sites we construct a product hierarchy Based on this product hierarchy we set up a virtual Web store Then 11 persons are invited to the experiments as customers and everyone generates about 15-30 purchase records on different products. The main parameters of the dataset are listed in Table 1 Table 1 Dataset Nodes of Product Hierarchy Tree I 87 Leaf Nodes I 58 Products I233 Customers I 11 Based on the approaches denoted in previous sections we implement a system prototype to construct customers profiles In order to check the incremental learning of our approaches we select different number of purchase records First we use 8-10 records to construct the original profiles and then add 5-7 records into database to update customer profiles An example of customer profiles constructed by our prototype is listed below Preference1D:lO PreferenceName: AccountingBook Preference Weight 0.26 TasteNwn I1 TasteName  TasteType  Tastevalue  Tasteweight Title O/NULUO Price U45.5-84.3 0.1 Manufacturer ONULL  0.05 Discount UO 7/0.1 Content O/Fimncia,O.5.Accounting,0.3,Accounting Practices,O.Z  0.4 Author O/Charles W Mulford.O.4,Raig D Shoulders.0.2 Eugene E Comiskey,O.Z Robert J Freemn,O.Z 0.05 Pagecount 1/305-407/0.02 Edition O/Hardcover,O.7, Paperback,O.3  0.01 6 Conclusions In this paper we define business data and customer profile based on product hierarchy for E-commerce recommendation application Especially we analyze the differences between preference profile and de profile, and propose an incremental approach to construct customer preference profiles In the end we conduct experiment to validate our methods There are several problems we need to investigate further. These issues include  more customer behavior data should be used, especially the clickstream, because the Web clickstream contains very important information about how a customer likes products  Web content mining techniques can be employed to extract customer preferences  more reco,mendation experiments and the comparisons with other techniques such as user-based and item-based collaborative filtering, should be conducted in details References l Eric Schmitt Harley Manniny Yolanda Paul and Sadaf Roshan Commerce Software Takes Off Forrester Report, March 2000 Joe Pine Mass Customization 1993 2 1079 


Proceedings of the First International Conference on Machine Learning and Cybernetics Beijing 4-5 November 2002 r31 r41 51 61 71 P31 91 B Mittal and W Lassar The Role of Personalization in Service Encounters. Journal of Retailing, 72 l 95 125,1996 Mulvenma M.D Annual S.S and Buchner A.G Personalization on the Net Using Web Mining Communication of the ACM, 43\(8 122-125,2000 Y.-F Kuo L.-S Chen Personalization Technology Application to Internet Content Provider Expert Systems with Applications 21\(2001\203-215 Jonathan L Herlocker Joseph A Konstan AI Borachers and John Riedl An Algorithmic Framework for Performing Collaborative Filtering SIGlR\22299 Badnal Sarwar George Karypis, Joseph Konstan, and John Riedl Item-based Collaborative Filtering Recommendation Algorightms. WWW10, Hongkong ACM, 1-5 May 2001 Jiawei Han, Micheline Kamber. Data miningconcepts and Techniques. Morgan kanfmam Press, 2001 C.-H Lee Y.-H Kim P.-K Rhee Web Personalization Expert with Combining Collaborative Filtering and Association Rule Mining Technique Expert System with Applications, 21\(2001\131-137 lo Bamshad Mobasher Hoghum Dai TaoLuo Yuqing Sun and JiangZhu Integrating Web Usage and Content Mining for More Effective Personalization ll Kang-Lun Wu Cham C. Aggawal, and Philip S Yu Personalization with Dynamic Profile. 2001 IEEE  Chan C Aggarwal Zheng Sun and Philip S Yu Online Algorithms for Finding Profile Association Rules. CIKM\22298  131 Gediminas Adomavicius and Alexander Tuzbilin Using Data Mining Methods to Build Customer Profiles IEEE Computer, 2001 1080 


References 1 A garw al, R., Aggarw al, C., an d Prasad V., A tree projection algorithm for generation of frequent itemsets. In Proceedings of High Performance Data Mining Workshop Puerto Rico, 1999 2 A graw al R an d Srikan t, R F a st al go rith ms f o r mining association rules In Proceedings of the 20 th VLDB conference pp. 487-499, Santiago Chile, 1994 3 B uc hne r  A  a nd M u l v e nna M   D  D i sc ov e r i n g internet marketing intelligence through online analytical Web usage mining SIGMOD Record  4\ 27, 1999 4 C har n iak  E  Statistical language learning MIT Press, 1996 5 C l i f t o n, C a n d Co ol e y R., T opCa t  da t a  m i ni ng for topic identification in a text corpus. In Proceedings of the 3rd European Conference of Principles and Practice of Knowledge Discovery in Databases Prague, Czech Republic, 1999 6  Coole y  R M obasher  B., an d Sr iv astav a J., Data preparation for mining World Wide Web browsing patterns Journal of Knowledge and Information Systems 1\ 1, 1999 7 C hen, M  S Par k J. S a nd Y u  P S  Data mining for path traversal patterns in a Web environment In Proceedings of 16th International Conference on Distributed Computing Systems  1996 8 Han, E H, Bole y  D., Gini, M Gr oss R   Hastings, K., Karypis, G., Kumar, V., and Mobasher, B., More, J., Document categorization and query generation on the World Wide Web using WebACE Journal of Artificial Intelligence Review January 1999 9 Her lock er  J K onstan, J., B o r c her s, A., Rie d l, J  An algorithmic framework for performing collaborative filtering. To appear in Proceedings of the 1999 Conference on Research and Development in Information Retrieval August 1999 10 Han, E H, K a r y pis, G., K u m a r  V., and M o basher  B., Clustering based on association rule hypergraphs. In Proccedings of SIGMOD\22297 Workshop on Research Issues in Data Mining and Knowledge Discovery \(DMKD\22297 May 1997 11 Han, E H, K a r y pis, G., K u m a r  V., and M o basher  B., Hypergraph based clustering in highdimensional data sets: a summary of results IEEE Bulletin of the Technical Committee on Data Engineering 21\ 1, March 1998 12 Jo ach im s T F r eitag  D., Mitch e ll T   WebWatcher: A Tour Guide for the World Wide Web. In Proceedings of the International Joint Conference in AI \(IJCAI97 August 1997 1 L i eb e r man   H Letizia: an agen t th at assists W e b browsing. In Proceedings of the 14 th International Joint Conference in AI \(IJCAI95 AAAI Press Menlo Park, California, 1995 14 Nasr a oui O F r i g ui, H., Jos h i, A., K r ishnap u r a m  R., Mining Web access logs using relational competitive fuzzy clustering. To appear in the Proceedings of the Eight International Fuzzy Systems Association World Congress August 1999 15 Pe r k ow i t z M  a nd E t z i oni O A d a p t i v e W e b sites: automaticlly synthesizing Web pages. In Proceedings of Fifteenth National Conference on Artificial Intelligence Madison, WI, 1998 16 Sp ilio p o u l o u  M a n d  F a u l stich  L  C., W U M: A Web Utilization Miner In Proceedings of EDBT Workshop WebDB98 Valencia, Spain, LNCS 1590, Springer Verlag, 1999 17 Sc he c h t e r  S., K r i s hna n, M a nd Sm i t h M  D   Using path profiles to predict HTTP requests. In Proceedings of 7th International World Wide Web Conference Brisbane, Australia, 1998 1 Sh ard a n a n d   U., Maes, P So cial inf o rmatio n filtering: algorithms for automating "word of mouth." In Proceedings of the ACM CHI Conference 1995 1 Sh ah ab i C., Zarkesh  A. M Ad i b i J  and  Sh ah V., Knowledge discovery from users Web-page navigation. In Proceedings of Workshop on Research Issues in Data Engineering  Birmingham, England, 1997 2 Yan  T  Jaco b s en M Garcia-Mo lin a, H., Da y a l U., From user access patterns to dynamic hypertext linking. In Proceedings of the 5 th International World Wide Web Conference, Paris France, 1996 


results are shown in Table 4 6 Conclusions mem \(M mem M associative classification 1 efficiency at handling huge Table 4 The comparison of CBA and CMAR on main memory usage Dataset Auto Hypo Ion0 Sick Please note that in this experiment we disable the lim itation of number of rules in CBA In such a setting CBA and CMAR generate all the rules necessary for classifica tion and thus are compared in a fair base From the table one can see that on average CMAR achieves 77.12 sav ing on main memory usage The saving in main memory usage can be explained from two apsects First CMAR uses CR-tree The compactness of CR-tree brings significant gain in storing a large set of rules where many items in the rules can be shared On the other hand CR-free is also an index structure of rules Before a rule is inserted into a CR-tree CMAR checks if there is a general rule or some more specific rules in the tree If so related pruning is pursued immediately Such a pruning techique also contributes to the saving of main memory To test the scalability of CMAR we compare the run time of CBA and CMAR on six data sets The results are shown in Figure 5 Again we disable the limit on number of rules in CBA In the experiments CBA spends a large portion of runtime on YO  attr  cls  rec CBA runtime CMAR runtime 25 7 205 612s 408s 25 2 3163 92s 19s 34 2 351 150s 89s 29 2 2800 74s 13s Sonar I 60 I 2  208 1 226s 145s Table 5 The runtime of CBA and CMAR As can be seen from the table CMAR is faster than CBA in many cases Please be note that the machine we use for testing is with relatively small size of main memory 128M Both CBA and CMAR can be expected running significantly faster if more main memory is available racy 2 it prunes rules effectively based on confidence correlation and database coverage and 3 its efficiency is achieved by extension of an efficient frequent pat tern mining method FP-growth construction of a class distribution-associated FP-tree and applying a CR-tree structure to store and retrieve mined association rules effi ciently Our experiments on 26 databases in UCI machine learning database repository show that CMAR is consis tent highly effective at classification of various kinds of databases and has better average classification accuracy in comparison with CBA and C4.5 and is more efficient and scalable than other associative classification methods References I R Agrawal and R Srikant Fast algorithms for mining as 2 P Clark and T Niblett The CN2 induction algorithm Ma 3 G Dong X Zhang L Wong and J Li Caep Classifi sociation rules In VLDB\22294 Chile Sept 1994 chine Learning 3:261-283,1989 cation by aggregating emerging patterns In DS\22299 LNCS I72 I Japan Dec 1999 4 R Duda and P Hart Pattern Classification and Scene Anal ysis John Wiley  Sons 1973 5 J Han J Pei and Y Yin Mining frequent patterns without candidate generation In SIGMOD\222OO Dallas TX May 2000 6 B Lent A Swami, and J Widom Clustering association rules In ICDE\22297 England April 1997 7 W Li Classification based on multiple association rules M.Sc Thesis Simon Fraser University April 2001 8 T.-S Lim W.-Y Loh and Y.-S Shih A comparison of prediction accuracy complexity and training time of thirty-three old and new classification algorithms Machine Learning 39,2000 9 B Liu W Hsu and Y Ma Integrating classification and association rule mining In KDD\22298 New York NY Aug 1998 IO J R Quinlan C4.5 Programs forkfachine Learning Mor gan Kaufmann 1993 I I K. Wang S Zhou and Y He Growing decision tree on support-less association rules In KDD\222OO Boston MA Aug 2000 376 


of the query expression without ha ving the global view of the in ten tion There is a big c hance that the enco ded pro cedure ma y not b e the b est w a y to compute the rules dep ending on the database instance F urthermore as w e understand it their prop osals require p oten tially large n um ber of name generation for relations and attributes The names that are needed are usually database dep enden t and th us p ossibly cannot b e gathered at query time An additional pro cess needs to b e completed to gather those v ariables b efore actual computations can b egin 5  9 Optimization Issues While it w as in tellectually c hallenging to dev elop a declarativ e expression for asso ciation rule mining from deductiv e databases there are sev eral op en issues with great promises for resolution In the w orst case the least xp oin tneedsto generate n 2 tuples in the rst pass alone when the database size is n  Theoretically  this can happ en only when eac h transaction in the database pro duces an in tersection no de and when they are not related b y subset-sup erset relationship In the second pass w e need to do n 4 computations and so on The question no w is can w e a v oid generating and p erhaps scanning some of these com binations as they will not lead to useful in tersections F or example the no de b 0 3 in gure 11 is redundan t A signican t dierence with apriori lik e systems is that our system generates all the item sets top do wn in the lattice without taking their candidacy as a large item set in to consideration Apriori on the other hand do es not generate an y no de if their subsets are not large item sets themselv es and thereb y prunes a large set of no des Optimization tec hniques that exploit this so called an ti-monotonicit y prop ert y of item set lattices similar to apriori could mak e all the dierence in our setup The k ey issue w ould b e ho ww e push the selection threshold minim um supp ort inside the top do wn computation of the no des in the lattice in our metho d F or the momen t and for the sak e of this discussion let us consider a higher supp ort threshold of 60 for the database T of gure 9 No w the l-en v elop e will b e the one sho wn in ligh ter dashed lines in gure 11 and the no des under this line will b e the large item sets Notice that no ww eha v eto discard no des ad 2 0 and d 0 2 to o This raises the question is it p ossible to utilize the supp ort and condence thresholds pro vided in the query and prune candidates for in tersection an y further Ideas similar to magic sets transformation 3  24 ma y be b orro w ed to address this issue The only problem is that pruning of an y no de dep ends on its supp ort coun t whic h ma y come at a later stage By then all no des ma y already ha v e b een computed and th us pushing selection conditions inside aggregate op erator ma y b ecome non-trivial Sp ecial data structures and indexes ma y also aid in dev eloping faster metho ds to compute ecien t interse ction joins that w e ha v e utilized in this pap er W e lea v e these questions as op en issues that should be tak en up in the future F ortunately though there has been a v ast b o dy of researc h in optimizing Datalog programs including recursiv e programs suc h as the one w e ha v e used in this pap er and hence the new questions and researc h 5 Recall that their prop osal requires one to express the mining problem to the system using sev eral queries and up date statemen ts that utilizes information ab out the database con ten ts to ac hiev e its functionalit y  c hallenges that this prop osal raises for declarativ e mining ma y exploit some of these adv ances Needless to emphasize a declarativ e metho d preferably a formal one is desirable b ecause once w e understand the functioning of the system w e will then be able to select appropriate pro cedures dep ending on the instances to compute the seman tics of the program whic hw e kno wis in tended once w e establish the equiv alence of declarativ e and pro cedural seman tics of the system F ortunately  w e ha v e n umerous pro cedural metho ds for computing asso ciation rules whic h complemen t eac h other in terms of sp eed and database instances In fact that is what declarativ e systems or declarativit y buy us  a c hoice for the most ecien t and accurate pro cessing p ossible 10 Conclusion Our primary goal for this pap er has b een to demonstrate that mining asso ciation rules from an y rst-order kno wledge base is p ossible in a declarativ ew a y  without help from an y sp ecial to ols or mac hinery  and that w e can no wha v ea v ery in tuitiv e and simple program to do so W eha v esho wn that it is indeed p ossible to mine declarativ ekno wledge b y exploiting the existing mac hinery supp orted b ycon temp orary inference engines in programming languages e.g Prolog or kno wledge base systems e.g RelationLog XSB LD L  CORAL All w e require is that the engine b e able to supp ort set v alued terms grouping aggregate functions and set relational op erators for comparison functionalities whic hmostofthesesystemscurren tly supp ort W e ha v e also demonstrated that our formalism is grounded on a more mathematical foundation with formal prop erties on whic h the seman tics of the R ULES system rely  W e ha v e also raised sev eral op en issues related to eciency and query optimization whic h should b e our next order of business As future researc h w e plan to dev elop optimization tec hniques for mining queries that require non-trivial lo ok ahead and pruning tec hniques in aggregate functions The dev elopmen ts presen ted here also ha v e other signican t implications F or example it is no w p ossible to compute c hi square rules 4 using the building blo c ks pro vided b y our system Declarativ e computation of c hi square rules to our kno wledge has nev er b een attempted for the man y pro cedural concepts the computation of c hi square metho d relies on In a separate w ork 2 w e sho w that the coun ting metho d prop osed in this pap er can be eectiv ely utilized to generate the exp ectations needed in order to compute suc h rules rather easily  These are some of the issues w e plan to address in the near future The motiv ation imp ortance and the need for in tegrating data mining tec hnology with relational databases has b een addressed in sev eral articles suc h as 12  13 They con vincingly argue that without suc h in tegration data mining tec hnology ma y not nd itself in a viable p osition in the y ears to come T o b e a successful and feasible to ol for the analysis of business data in relational databases suc htec hnology m ust b e made a v ailable as part of database engines and as part of its declarativ e query language Our prop osal for declarativ e mining bears merit since it sheds ligh t on ho w rst order databases can be mined in a declarativ e and pro cedure indep enden t w a y so that the optimization issues can b e delegated to the underlying database engine Once suc h argumen ts are accepted sev eral systems 9 


related issues b ecome prime candidates for immediate atten tion F or example traditionally database systems supp orted declarativ e querying without the necessit y to care ab out the pro ceduralit y of the queries In this pap er w eha v e actually demonstrated that asso ciation rule mining can b e view ed as a Datalog query  It is immediate that a direct mapping from the Datalog expressions presen ted in this pap er to SQL can be dev elop ed with no problem at all W e can then rely on ecien t database pro cessing of the query in an optimized fashion Hence w ecomeclose to the essence of the visions expressed b y the leading database researc hers and practioners 12  References 1 Rak esh Agra w al and Ramakrishnan Srik an t F ast algorithms for mining asso ciation rules in large databases In VLDB  pages 487{499 1994 2 Anon ymous A declarativ e metho d for mining c hisquare rules from deductiv e databases T ec hnical rep ort Departmen t of Computer Science Anon ymous Univ ersit y USA F ebruary 2001 3 C Beeri and R Ramakrishnan On the po w er of magic In Pr o c e e dings of the 6th A CM Symp osium on Principles of Datab ase Systems  pages 269{283 1987 4 Sergey Brin Ra jeev Mot w ani and Craig Silv erstein Bey ond mark et bask ets Generalizing asso ciation rules to correlations In Pr o c A CM SIGMOD  pages 265 276 1997 5 D Chimen ti et al The LD L system protot yp e IEEE Journal on Data and Know le dge Engine ering  2\(1 90 1990 6 Jia w ei Han Jian P ei and Yiw en Yin Mining frequen t patterns without candidate generation In Pr o c A CM SIGMOD  pages 1{12 2000 7 Marcel Holsheimer Martin L Kersten Heikki Mannila and Hann uT oiv onen A p ersp ectiv e on databases and data mining In Pr o c of the sixth A CM SIGKDD Intl Conf  pages 150{155 Mon treal Queb ec 1995 8 Flip Korn Alexandros Labrinidis Y annis Kotidis and Christos F aloutsos Ratio rules A new paradigm for fast quan tiable data mining In Pr o c of 24th VLDB  pages 582{593 1998 9 Brian Len t Arun N Sw ami and Jennifer Widom Clustering asso ciation rules In Pr o c of the 3th ICDE  pages 220{231 1997 10 Mengc hi Liu Relationlog At yp ed extension to datalog with sets and tuples In John Llo yd editor Pr oc e e dings of the 12th International L o gic Pr o gr amming Symp osium  pages 83{97 P ortland Oregon Decem ber 1995 MIT Press 11 Rosa Meo Giusepp e Psaila and Stefano Ceri An extension to SQL for mining asso ciation rules Data Mining and Know le dge Disc overy  2\(2 1998 12 Amir Netz Sura jit Chaudh uri Je Bernhardt and Usama M F a yy ad In tegration of data mining with database tec hnology  In Pr o c e e dings of 26th VLDB  pages 719{722 2000 13 Amir Netz Sura jit Chaudh uri Usama M F a yy ad and Je Bernhardt In tegrating data mining with SQL databases In IEEE ICDE  2001 14 Ra ymond T Ng Laks V S Lakshmanan Jia w ei Han and Alex P ang Exploratory mining and pruning optimizations of constrained asso ciation rules In Pr o c A CM SIGMOD  pages 13{24 1998 15 Jong So o P ark Ming-Sy an Chen and Philip S Y u An eectiv e hash based algorithm for mining asso ciation rules In Pr o c A CM SIGMOD  pages 175{186 1995 16 Karthic k Ra jamani Alan Co x Bala Iy er and A tul Chadha Ecien t mining for asso ciation rules with relational database systems In Pr o c e e dings of the International Datab ase Engine ering and Applic ations Symp osium  pages 148{155 1999 17 R Ramakrishnan D Sriv asta v a and S Sudarshan CORAL  Con trol Relations and Logic In Pr o c of 18th VLDB Confer enc e  pages 238{250 1992 18 Konstan tinos F Sagonas T errance Swift and Da vid Scott W arren XSB as an ecien t deductiv e database engine In Pr o c of the A CM SIGMOD Intl Conf  pages 442{453 1994 19 Sunita Sara w agi Shib y Thomas and Rak esh Agra w al In tegrating mining with relational database systems Alternativ es and implications In Pr o c A CM SIGMOD  pages 343{354 1998 20 Ashok a Sa v asere Edw ard Omiecinski and Shamk an tB Nav athe An ecien t algorithm for mining asso ciation rules in large databases In Pr o c of 21th VLDB  pages 432{444 1995 21 Pradeep Sheno y  Ja y an t R Haritsa S Sudarshan Gaura v Bhalotia Ma y ank Ba w a and Dev a vrat Shah T urb o-c harging v ertical mining of large databases In A CM SIGMOD  pages 22{33 2000 22 Abraham Silb ersc hatz Henry F Korth and S Sudarshan Datab ase System Conc epts  McGra w-Hill third edition 1996 23 Shib y Thomas and Sunita Sara w agi Mining generalized asso ciation rules and sequen tial patterns using SQL queries In KDD  pages 344{348 1998 24 J D Ullman Principles of Datab ase and Know le dgeb ase Systems Part I II  Computer Science Press 1988 25 Mohammed J Zaki Generating non-redundan t association rules In Pr o c of the 6th A CM SIGKDD Intl Conf  Boston MA August 2000 1 0 


OM OM 006 OD8 01 012 014 016 018 02 022 False alarm demity Figure 9 Percentage of tracks lost within 200 seconds using three-scan assignment with PD  0.9 TI  O.ls Figure 11 T2  1.9s and T  Is ij  20 and 0  0.1 24 1 22  20  E fls 0  8l 16 0 n 14  12  0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 T1/12 PD Average track life of three-scan assignment with PD varying TI  0-ls T2  1.9s T  Is X  0.02 ij LO and   0.1 mareuvenng index Figure 12 Percentage of lost tracks of 4-D assipment in 200 seconds with maneuvering index varying X  0.01 Ti  0.1 T2  1.9s and T  IS PD  0.98 Figure 10 Percentage of lost tracks of 4-D assignment in 200 SeoDllCls with TI and T2 varying PD  0.98 X  0.02 q 20 and 0  0.1 4-1607 


Figure 13 Average gate size for Kalman filter Figure is relative as compared to nq and curves are parametrized by ij/r with unit-time between each pair of samples 1.2 Iy I 1.1 0.5 I A CRLB for he unifm samiina I  0.4 0.35 d 3 03 i7 3 0.25 0 0.M 0.04 0.06 008 0.1 0.12 0.14 0.16 0.18 0.2 False A!am DemW V I    Figure 14 CramerRao Lower Boundfor Mean Square Error of uniform and nonuniform sampling schemes with Ti  O.ls T2  1.9s T  IS PD  0.9 ij  5 and U  0.25 1 unifon sampling r-ls ked i non-uniform sampling loge inlewi I ti non-uniform sampling shod interva I 0.9 0.8 I Figure 15 MSE comparison of three-scan assignment with Ti and T2 varying I'D  1 X  0.01 ij  20 and U  0.1 4-1608 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



Performing Combinatorial Testing on Web Servicebased Software  Chengying Mao School of Software Jiangxi University of Finance and Economics 330013 Nanchang, China E-mail:  maochy@yeah.net    Abstract Although Web service-based software \(WSBS possesses a lot of merits such as loose coupling and good interoperability, its some new characters also bring challenges to latter maintenance activities inevitab ly. In the paper, we proposed a combinatorial testing framework for the WSBS which mainly includes test cases generation and knowledge-based debugging. For the former, naÔve method and ìgreedy backtrackingî method are detailedly addressed. At the stage of debugging, rough set reasoning is adopte d to generate association rules, which can help maintainers to locate faults in the WSBS by using dynamic slicing technology. In addition, the feasibility and effectiveness of our approach is validated by some working examples and experiments Keywords-Web service; combin atorial testing; test cases generation; rough set; debugging I  I NTRODUCTION  Web services \(WS\ has been widely adopted in constructing new-style software systems during it development Although Web service-based software \(WSBS\a lot of merits such as good interope rability, easy integration, reuse and evolvement, its some new characters also bring challenges to latter maintenance activiti es inevitably. Therefore, exploring new testing methods and strategies is a hot issue in the field of  Web service is an independent software component with a specific function, thus dev elopers of Web service-based software can access its interface merely through the related standards and protocols such as WSDL, SOAP and UDDI Furthermore, the whole system may contain several kinds of heterogeneous service units \(i.e components\run in an open context. If testing problems of this system is taken into account, black-box testi ng \(also called functional testing  should be a preferred method during testing process. The service component or integrated system of some service units can be viewed as a black box, and testers can only change the value of its interface parameters during testing process. In order to ensure its high quality, the generated test cases should have the ability of covering combin atorial pairs of input parameters as many as possible, which is so-called combinatorial testing Combinatorial testing \(CT y defines ways to select values for individual input parameters and combines them to form complete test It is not hard to find that, this method can achieve satisfactory coverage via the possible minimum number of test cases. Thus, it is a rational way for increasing efficiency and effectiveness of testing. In the paper we adopt this testing strategy to test the WSBS according to the characters of this new kind of software. Furthermore, a debugging method based on rou gh set reasoning is proposed to locate faults The rest of the paper is organi zed as follows: In the next section, we address the foundation and running example for testing. In Section 3, the method of performing combinatorial testing on Web service-based software is discussed, and the framework of whole testing process is also introduced. The debugging method based on rou gh set reasoning is presented in Section 4. Section 5 presents the conclusions and future work in this area II P RELIMINARY K NOWLEDGE AND R UNNING E XAMPLE  Combinatorial testing has been extensively used across many disciplines includi ng medicine, agriculture manufacturing, etc., and was recently applied to software   As show n in Figu re 1, we use 12    n X xx x 002 002 to indicate the set of all input variables identified for use in testing WSBS. Let i p denotes the number of parameters that have i v values 1  ik 003\003 Note that 1 k i i np 002 002 004 Without loss of generality, we assume that i v are listed in descending order \(i.e ij vv 005 if ij 005 hus, the testing problem can be uniquely represented as 12 12   pp CT Pvv 002 002   k p k v       Figure 1. WSBS with set of input variables X  
2008 International Conference on Computer Science and Software Engineering 978-0-7695-3336-0/08 $25.00 © 2008 IEEE DOI 10.1109/CSSE.2008.1284 755 


In combinatorial testing, the conservative strategy is to test all possible combinations of in put variables. For the model 5 4 it needs 5 1024 4  002 test cases. Since the size of test suite will grow large very quickly, this strategy is not practical in most cases. Instead one can create test suites that guarantee t way 2 tn 003\003 ge or pair-wise \(a.k.a. 2-way testing\5   In n-way testing, a set of test cases is generated to cover a subset of the possible combinati ons of the systemês input variables, rather than attempting to cover all possible combinations. While the tr ade-off between fault detection effectiveness \(FDE\ is considered, pair-wise testing method seems better, and this paper only discusses this case In order to address the steps of our method clearly, we take a simple Web service-based application as an example. The application only contains one Web service component, with main function of date judgment and calculation. It has four input parameters: the former three are year  month  date  and flag The value types of input parameters are listed as following T ABLE 1  V ALUES OF I NPUT P ARAMETERS IN E XAMPLE  Para. Abbr Description Y1 Y%100==0 && Y%400!=0 Y2 Y%400==0 Year Y Y3 Y%100!=0 M1 M in the set 1,3,5,7,8,10,12 M2 M in the set {2 Month M M3 M in the set {4,6,9,11 D1 D <= 28 D2 29 <= D <= 30 Date D D3 D ==31 F1 Leap year judgment function F2 Function for getting previous date Flag F F3 Function for getting next date Itês obvious that this testing pr oblem for the simple Web service-based application can be modeled as 4 3 CT P 002 In most cases, the internal structural information of Web service component canêt be obtained by WSBS developers and testers who can only extract interface information from WSDL files This step usually can be automatically employed because WSDL is a universal standard for all service unit developers. In the following sections, combin atorial testing method and related debugging strategy will be addressed according to this abstract representation III C OMBINATORIAL T ESTING FOR WSBS A Test Cases Generation After obtaining interface information of Web service or WSBS, the crucial step of testing WSBS is to generate test cases which can cover the interactions between the input parameter pair. When interactions are considered, the number of possible tests grows very rapidly leading to a combinatorial explosion. In this situation, testers may try to manually identify çimportanté input combinations to create a reasonable number of tests [6   How to generate the minimum co mbinatorial test suite is a NP-hard problem and ha snêt been pe rfe ctly resolved u n til today. For WSBS combinatorial testing issues, the paper provides two naÔve methods fi rst, and then gives our primary settlement 1 NaÔve methods for WSBS testing In fact, test cases that cover all pair-wise interface interactions can be viewed as a 2-factor design in experimental design theory. Therefore, the validated orthogonal tables arrays rences to generate test s u ite  For the working example, testers can look up a 4-factor and 3level orthogonal table in ma thematics handbook, and then convert each row in the table into a test case according to the candidate values of parameters The limitation of this method lies in that, this algebraic approach mainly handles the case of all parameters having the same number of values, and nearly canêt deal with the case where parameters have different numbers of values D. M. Cohen et al. proposed a heuristic search-based approach to generate pair-wise te st suite, and designed an automatic efficient test gene rator \(AETG to help worldwide testers to perform comb inatorial testing. This system can be accessed via Web, so we can input testing indicators into it to gain the combinatorial resu lts for the WSBS under test. This method has been wi dely adopted and proven to be high effectiveness. However, the AETG adopts a greedy search technique to find a pool of test cases, so it doesnêt always produce test suites wi th known covering array numbers For this reason, we add a backtracking procedure to greedy algorithm to avoid Local optimization problem 2 A greedy + backtracking method In order to overcome pure gr eedy algorithmês difficulties in finding global optimal soluti on, we introduce the backtracking strategy into the process of greedy search. Suppose the initial situation is 0 C we enumerate k kinds of parameter pair coverage first, and then apply greedy search to each enumeration. Subsequently, the çbesté one is selected from all enumerations according to some specific rule, so we can get a new situation 1 C Similarly, we can apply the above calculation process to 1 C recursively until all pairs of parameter values are covered. Two selection rules are introduced into above algorithm, the primary one is defined as the cardinality of projective set of covered parameter value pairs \(denoted as C P  dispersed degree of the redupli cate pairs. Furthermore, the factor k is set as 2 n C where 4 n 002  It is well known that backtracking is a time-consuming process, so we only adopt one step backtracking in the above search algorithm to ensure rational efficiency. We have employed experiments on some sample problem, the results showed that the greedy algorithm with one step backtracking was good at searching, which significantly reduced search time compared with all-backtracking method. According to our proposed method, nine test cases shown in Table 2 are generated and have been used in testing activity. In the example WSBS, some statements are mutated to validate 
756 


testing methods. The sixth column in Table 2 shows that this testing method can reveal some seeded faults. It should be noted that 0 represents the corresponding test case without failures E1é and çE2 represent two kinds of runtime exceptions T ABLE 2  T EST C ASES AND R ESULTS OF THE E XAMPLE  No. Y M D F Results x1 1 1 1 1 E1 x2 1 2 3 2 E1 x3 1 3 2 3 E1 x4 2 1 3 3 0 x5 2 2 2 1 E2 x6 2 3 1 2 0 x7 3 1 2 2 0 x8 3 2 1 3 0 x9 3 3 3 1 0  B Testing Framework for WSBS Due to the transparency of internal structure of WSBS traditional testing methods especially white-box testing methods, canêt be used to find faults. However, combinatorial testing can satisfy such requir ement, and has high coverage ability. Here, we summarize the whole implementation process of that testing method in following figure WSDL Files SOAP Files Architecure Spec Extract interface parameter info Construct CT model Generate test cases Orthogonal arrays AETG method Greedy+back tracking method      Test suite Execute Test results  Rough set-based diagnosis Debug rules  Repair  Figure 2. Combinatorial testing framework for WSBS At first, testers can extract interface information about Web services or WSBS according to files such as WSDL and architecture specification. Then they can construct combinatorial testing model for Web service-based application based on such information. Accordi ng to the abstract model testers can generate test cases by naÔve methods or çgreedy backtrackingé method. Subsequently they can treat test cases as input to execute the WSBS unde r test and gather test results While considering some complex WSBS, the number of interface parameters and their values maybe very large, so the size of test cases must be huge. Naturally, test results will be too large to be analyzed in manual style. For this reason, we proposed a debugging method based on rough set reasoning Each test case and its result can be viewed as the subset of conditional attributes and subset of decision attributes in information system respectively Then rule mining algorithms can be utilized to discov er some useful rules for latter debugging activity IV R OUGH S ET BASED D EBUGGING  Generally speaking, Web servi ce-based software is viewed as a black box during functional testing. The relation between programês input and output is the typical cause-effect mapping rule. For software debuggers, the chief task is to find the causes of software failure. In the other perspective, the problem can be induced into the process of mining rule such as reason 002 failure type Extracting rules from information system is the main task in the field of data mining or knowledge reasoning. Here, we mainly use rough set-based reasoning to explore association rules from test results, and then employ these rules to program debugging Rough set-based WSBS debugging can be divided into two phases: \(1\ining rules based on rough set reasoning, and \(2 Locating faults based on association rules For the working example \(i.e., Table 2 following classifications throu gh considering the values of conditional and decisi on attributes 123 46789 5  UD xxx xxxxx x 002  123 456 789  Y UInd xxx xxx xxx 002  147 258 369  M UInd xxx xxx xxx 002  168 249 357  D            UInd xxx xxx xxx 002  159 267 348 F UInd xxx xxx xxx 002  Y 123789  Pos D x x x x x x 002  M  Pos D 002\006  D  Pos D 002\006  F  Pos D 002\006  Compared with attribute M, D and F, the positive domain of attribute Y isnêt null. Therefore, we choose Y as the gist for getting decision rules. In case of considering the objects 123789  x xxxxx in Y  Pos D the following rule can be achieved Y1 E1 D 002\007 002  Y3 0 D 002\007 002  Subsequently, a new decision ta ble \(DT\n be produced after removing the objects in Y  Pos D Based on the new DT we can further explore the poten tial rules in information system V C ONCLUDING R EMARKS  Web service-based system is a prevailing software form in recent years. Although its new features such as loose coupling and good interoperability can he lp developers to construct software systems, they also bring challenges to latter maintenance activities. Accordin g to the black-box characters of WSBS, we introduce combinat orial testing method to verify this kind of software. For the ke y step in testing activities, i.e test cases generation, two solutions are proposed in the paper One is to adopt naÔve met hods such as orthogonal arrays and AETG, the other is an improved greedy algorithm called greedy+backtrackingé method. In or der to analyze test results effectively and improve debugging efficiency, a new debugging method based on rou gh set reasoning is presented to help maintainers to lo cate faults in WSBS. Finally, a combinatorial testing framewo rk for WSBS is addressed. The current study only provide an im portant starting point, but experiments on larger and more complex WSBS should be employed in further 
757 


A CKNOWLEDGMENT  This work was supported in part by China Postdoctoral Science Foundation under Grant No.20070410946, the Postdoctoral Science Found ation of HUST, the Science Foundation of Jiangxi Educational Committee under Grant No.GJJZ-2007-267, and the Youth Foundation of Jiangxi University of Finance and Economics R EFERENCES  1 M. Ao ya m a S  Weerawa rana, H  M a ru ya m a  and et al W eb Service s  Engineering: Promises and Challengesé, Proc of ICSEê02, ACM Press 2002, pp. 647-648  P. Am m a nn and J. Offutt, Intr oduction to Software Testing, Cambridge University Press, Cambridge UK, 2008, pp23-26  M. Drindal, J. Offutt, and S. E. Andler, çCo m bination Testing Strategies  A Surveyé, Software Testing, Ver ification and Reliability, 2005, vol.15 167-199  M. B. Cohen, P B. Gibbons, W   B Mugridge, and C J. Colbourn Constructing Test Suites for Interaction Testing Proc. of ICSEê03 2003, pp.38-48  E. Dustin, çOrthogonally Speaking  STQE, September-October, 2001 vol.3, no.5, pp.46-51  P. J. Sch roeder an d B Korel, çBlack-Box Test Reduction Using InputOutput Analysisé, Proc. of ISST Aê00, 2000, pp.173-177  G. Seroussi and N. H. Bshouty Vect or Sets for Exhaustive Testing of Digital Circuitsé, IEEE Transactions on In formation Theory, 1988, 34\(3 513-522  A. Heday at, N. Sloane, and J Stufken, Orthogonal Arrays, SpringerVerlag, New York, 1999  D M Cohen S R Dalal  M   L  Fr ed m a n and G C  Patton T he AE T G  System: An Approach to Testing Based on Combinatorial Design IEEE Transactions on Software Engineer ing, 1997, 23 7  F T i p, çA Sur vey of Pr ogr a m Slicing T echniques  Pr ogr a m m i n g  Languages, Vol.3, No. 3 1995, pp. 121-189  Chengy ing M a o Xiaohua Hu and Ya nsheng L u   T owar ds a Softwar e Diagnosis Method Based on Rough Set Reasoningé, Proc. of the IEEE 8th International Conference on Computer and Information Technology CITê08\, Sydney, Australia, July 8-11, 2008  
758 


  Proceedings of the Sev e nth Inter n ational Conference on Ma c h ine Lear ning and Cyber n etics  K u nming, 12-15 J u ly 2008  less th an th e t r u e sup port by at m o st N f  and i t s support   3.4.   T h e Al gori t hm Algorithm DSCFCI Inpu t: Data strea m  ite m co n s train t s DS B a sup por t  t h reshol d an error param e ter s 001 where   den o t e s t h e c u rre nt l e n g t h  of t h e st ream i  e., t h e num ber  of transactions seen so far    N Proof: Suppos e that the r e are  bat c he s o f dat a  i n  stream seen s o fa r  For a cl os ed item s et i X its suppo r t  i s re duc ed  by   altoget h er  According t o procedure  Prun e_ DSCFC I tree, it is ev iden t th at  Com b ined with t h e fact t h at the c u rr en t leng th  of strea m is and the lengt h of each batc h is k i k 003 N  001 003  Procedure Print_FCI I npu t the gl obal DSCFCI-tree of the first  b a tch e s r t thresho l d an error param e ter tree DSCFCI 212 i s 001  Out put  A l i s t  of  fre que nt cl o s ed i t e m s et s al on g wi t h t h ei r  est i m at ed support   M e t hod  1. Sca n   bo tto m u p sear ch  for each node tree DSCFCI 212 001  Ou tp u t A list o f freq u e n t clo s ed item s ets satisfyin g  B   M e t hod  1. Di vi de dat a  st ream  i n to  b a tc h e s  with   DS  2  1   i N i   i N 001 was set to  Item  const r aints 1 2 3  4 r e pr esen ted fou r item s w h ich wer e selected random l y from t h e 30 i t e m s cam e up fi rst   s 1  0  4 3   2 1  001 1 we in fer that  N i i 001 001 001  327 327 003 1 Therefore N k f  2. If 1   isfci f and   sup  001 f 212 002 s port 327 327 i  001 1   th en  ou tpu t th e item s et rep r esen ted b y th e pat h f r o m  t h e di rect chi l d  n ode of t h e r o ot t o  001 1 or 001 1 n  where  is a p o s itiv e in teg e r    n 278 2. For each batch  i N 3  Call procedure Buil d_i DSCFCIt r ee to construct  the local DSCFCI-tree of  i N 4  C a l l pr oce d u r e U p dat e _ D S C FC It ree t o  construct t h e global DSCFCI-tree of t h e first  bat c h i 5   C a l l  pr o cedu r e Pr une _DSCFCIt ree to prune the  gl obal DSC F C I-t ree 6     I f nee d e d cal l pr oce d u r e Pri n t _ FC I t o pr od uce a  list o f freq u e n t clo s ed item s ets satisfyin g  B  Notice When t h e le ngt h of ea ch batch is  001 1 n in pr oce d u r e P r une _ D SC FC It r ee, t h e val u e of fi el d  p ort sup  of each node is reduced by  i n st ead of 1  n 4.   E x peri mental  E val uati on 4.1.   T e st E n vi r o nment and Datasets Our algo rith m was written i n VC 6  0   All of ou r expe ri m e nt s were pe rf orm e d on a PC usi ng a 1 7 GHz  Pent i u m IV p r ocess o r   38 4M B of R A M   T h e o p er at i ng sy st em i n use was W i ndows XP  Th r e e sep a rate d a ta sets T 1 5 I 10D 100 0k  T15 I 7 D 10 00k T7I 4 D1 000 k  w e r e g e n e rated b y the I B M  sy nt het i c dat a gene rat o r   Here  T  rep r esent e d t h e  avera g e le ngt h of transactions  I r e p r es e n ted th e av er a g e len g t h o f  p o t en tial frequ en t i t e m sets, an d D represen ted  th e to tal n u m b e r of transactio n s i n d a ta set s Th ere were 1K distinct item s in each dat a sets, and the  defa ult value  fo r al l ot her p a ram e t e rs of t h e sy nt het i c d a t a gene rat o r  were used The stream s were broken int o batc hes of siz e 50,000 tran saction s  Th e su ppo rt thresh o l d  was va ried \(as to be desc ri be d b e l o w  a n d t h e err o r  param e t e r s 005 004 005  B 4.2.   E x peri mental  Resul t s    time \(s S=0.001 S=0.0015 S=0.002 num ber of dat a st ream segm ent s  Fi gure 1 The execut i on t i m e of  T15I7D1000k 


  Proceedings of the Sev e nth Inter n ational Conference on Ma c h ine Lear ning and Cyber n etics  K u nming, 12-15 J u ly 2008          In fi g u re 1, t h e y ax is represen ts t h e tim e spen t in  readi ng i n a bat c h of st r e am const r uc t i ng i t s l o cal  DSC F C I t ree  up dat i n g t h e gl o b al DSC F C I-t ree  an d pr o duci n g f r e que nt cl o s ed i t e m s et s sati sfy i ng i t e m  constraints B The y axis i n figure 2 re presents the  me m o ry capacity used for storing the gl obal  DSCFCI-tree As ca n be see n fr om t h e t w o f i gu res whe n t h e val u e of s u pp o r t   i s fi xe d, t h e t i m e and space re qui rem e nt s of t h e algorithm grow as th e stream progre sses, but tend to sta b ilize. For e x am ple, the m e m o ry re qui red by the  global DSC F CI-tree with su ppo r t 0  00 15  in cr eases relativ ely q u i ck ly as th e first sev e n  b a tch e s o f st ream arriv e and tend s to stab ilize at ro ugh ly 3  8MB with sm a l l  bum ps. T h is is because the num b er of pote ntial fre que nt clo s ed item s e t s satisfyin g ite m co n s trai n t s g o es up  relativ ely q u i ck ly at first, and b e co m e s relativ ely stead y  later th ro ugh in tr odu cing p r un ing tech no log y Th e stab ility resu lts are qu ite n i ce as th ey p r o v id e ev id en ce th at th e algorith m can  h a n d l e lon g  d a ta strea m s. As t h e v a lu e o f suppo r t   dec r eases the e x ecution tim e in fig u re 1 a n d t h e m e m o ry requi red by  DS CFCI-tree in  figure 2 inc r ea ses quickly  This is because t h ere are m o re p ot ent i a l  f r e que nt cl ose d i t e m s et s sati sfy i ng i t e m  const r ai nt s wi t h sl ower support    s s Fi gu re 1 an d F i gu re 2 sh o w t h e e x peri m e nt al res u l t s  o f  d a ta sets T1 5I7 D 1 000k  Th e ex per i m e n t al r e su lts of  o t h e rs two d a ta sets are sim ilar to th ese fig u r es                           Fig u re 3 shows th e av erag e t i m e sp en t i n  up d a ting  t h e gl obal DS C F C I-t ree o n c e  with three dif f eren t ite m con s t r ai nt s c onst r ai nt  0 n o c onst r ai nt s co nst r ai nt  1  co nst r ai nt 2   e  can dra w a c o nclusi on that w ith t h e reinforcem en t o f th e constraints 222  degree the num b er of fre que nt close d  ite m s ets satis fyin g co rrespo nd ing item co n s t r ain t s d ecreases, and th e tim e sp en t i n  up d a ti ng  th e g l o b a l DSCFCI-tree dec r eases t o o. M o re ove r  the space  requirem ent of t h e global DSCFCI-tree go es d o wn  sim u l t a neousl y The r ef ore  i n t e g r at i ng i t e m const r ai nt s in to t h e m i n i n g algorith m can  reduce t h e e x ecution tim e  and space com p lexity of the algorithm    4 3   2 1  005 005 005 5.   Concl u si ons In this pa per   we propose a n ef ficient algorith m for m i ni ng fre q u e n t cl ose d i t e m s et s i n dat a st ream s. The co n t r i bu tio n s of ou r stud y in clu d e 1 pro posin g a no v e l  dat a  st r u ct ure  DSC F C I t re e, fo r st ori n g pot e n t i a l   fre que nt cl ose d i t e m s et s, and de vel o pi n g  a new m e t hod  for increm ental updating DSCFCI-t ree ef ficiently 2 appl y i n g a  pr u n i n g t e c hni que f o r ef fi ci ent  p r u n i n g gl obal  DSCFCI-tree  to reduce the s p ace re quire m e nt of t h e  DSCFCI-tree an d th e tim e sp en t in trav ersi n g the DSCFCI-tree dram atica l l y 3  teg r ating ite m con s t r ai nt s i n t o t h e m i ni ng a l go ri t h m and t hus  red u ci n g  furthe r t h e e x ecution tim e and sp ace co m p lex ity of th e const r ai nt 0 S=0.001 T ime\(s S=0.0015  const r ai nt 1 const r ai nt 2 S=0.002  N umber of data stream segments Fi gu re 3 c o m p ari s on of e x ecut i o n  t i m e wi t h di f f erent const r ai nt s\(s=0.0015 Figure 2.The m e m o ry usage of DSCFCI-tree   279 005 004 005 4 3 2 1 


  Proceedings of the Sev e nth Inter n ational Conference on Ma c h ine Lear ning and Cyber n etics  K u nming, 12-15 J u ly 2008  al gori t h m   Our performance st udy shows  that DSCFCI  algorithm is ef ficient and ef fective  Refer e nces 1] C Gia nnel l a, J Ha n, J  Pei, et al. Mi ning fre quent p a ttern s i n  d a t a stream s at mu ltip le tim e g r an u l arities  G]. In  H Kar g up ta, A Jo sh i, K Siv a ku m a r  et al, ed s Next  Ge nerat i on Dat a M i ni ng C a m b ri dg e, M a ss  M I T Press, 2003  2 G S Mank u, R Mo t w an i. App r ox im a t e f r e q u e n c y cou n t s ove r st ream i ng dat a  C    The 28 th Int 222 l Confere n ce on V e ry Lar g e Data Bases \(VL D B 2002 HongKong, 2002 3  Aras u A M a nk u G S  A p pr oxi m a t e co unt s a n d  q u a n tiles ov er slid in g wi n d o w s. In Pro c eed ing s  o f  th e 23 rd ACM S I G M OD SI G AC T S I G A R T  Sym posi u m on Pri n ci pl es o f  Dat a base Sy st e m s. Pari s France  AC M Press, 2004 4 Datar M, Gio n i s A, In d y k P   Mo t w an i  R. Main tain in g str eam stat is tics o v e r slid in g  w i ndow s In  Proceedi ngs of the 13 th A nnu al ACMSIA M  Sy m p o s iu m on  Discrete Al g o rith m s San Fran cisco   USA  AC M Press, 2002 5 N Pas quier  Y Bastide  R T a ouil, et al Discoveri n g freq u e n t clo s ed item s e t s fo r asso ciatio n ru les[C]. In   Beeri C, et al, eds  Proc of the 17 th I n t 222 l Co nf  on Dat a base Theory B e rl i n  Spri nger V e rl ag, 1999  6  W a n g Jian yon g. Clo s et sear ch ing fo r t h e b e st st rat e gi es f o r m i ni ng f r e que nt cl ose d i t e m s et s. In  Pr oc. N i n t h A C M SIGK DD In t\222 1 Co nf  on  K now ledg e D i scov er y an d  D a t a Min i n g  W a shi ngt on,DC Aug.2003    280 


association mining The Likelihood Ratio Test fails to extract features also belonging to common vocabulary and it makes the extraction dependent on the feature position in the sentence leading to low recall The dBNP and bBNP based methods yield low recall due to the fact that the product features do not occur with the article the in front of them very often The Association Mining approach returns all frequent nouns which decreases precision Our results suggest that the choice of algorithm to use depends on the targeted dataset If it consists of mainly on-topic content the results of Table 10 indicate that the Association Mining algorithm is better suited for this task due to its high recall If the dataset consists of a mixture of onand off-topic content our results suggest that the Likelihood Ratio Test based algorithm would perform better due to its ability to distinguish and 002lter out the off-topic features For future work we plan to extend the Likelihood Ratio Test methods especially the dBNP based approach by other determiners such as a or this  which should increase the recall of this method Another possibility which we will investigate regards the BNP patterns The current Likelihood Ratio Test approach is not capable of dealing with discontinuous feature phrases for example in 5 the quality of the pictures is great the feature would be picture quality  This problem could be addressed by introducing wildcards in the BNP patterns We will also investigate whether there are any methods in order to calculate an optimal threshold for the candidate feature extraction in order to increase the recall of the Likelihood Ratio Test based algorithm We plan to investigate whether a deeper linguistic analysis e.g with a dependency parser can improve the feature extraction Acknowledgements The project was funded by means of the German Federal Ministry of Economy and Technology under the promotional reference 01MQ07012 The authors take the responsibility for the contents The information in this document is proprietary to the following Theseus Texo consortium members Technische Universit  at Darmstadt The information in this document is provided as is and no guarantee or warranty is given that the information is 002t for any particular purpose The above referenced consortium members shall have no liability for damages of any kind including without limitation direct special indirect or consequential damages that may result from the use of these materials subject to any liability which is mandatory due to applicable law Copyright 2008 by Technische Universit  at Darmstadt References  R Agra w al and R Srikant F ast algorithms for mining association rules Proc 20th Int Conf Very Large Data Bases VLDB  1215:487ñ499 1994  K Bloom N Gar g and S Ar g amon Extracting a ppraisal expressions In HLT-NAACL 2007  pages 308ñ315 2007  R Bruce and J W iebe Recognizing subjecti vity a case study in manual tagging Natural Language Engineering  5\(02 1999  K Da v e S La wrence and D Pennock Mi ning the peanut gallery opinion extraction and semantic classi\002cation of product reviews In Proceedings of the 12th International Conference on World Wide Web  pages 519ñ528 New York NY USA 2003 ACM  T  Dunning Accurate methods for the statistics of surprise and coincidence Computational Linguistics  19\(1 1993  O Feiguina and G Lapalme Query-based summ arization of customer reviews In Canadian Conference on AI  pages 452ñ463 2007  C Fellbaum Wordnet An Electronic Lexical Database  MIT Press 1998  A Ferraresi Building a v ery lar ge corpus of english obtained by web crawling ukwac Master's thesis University of Bologna Italy 2007  M Gamon A Aue S Corston-Oli v er  and E Ringger  Pulse Mining customer opinions from free text In Proceedings of the 6th International Symposium on Intelligent Data Analysis IDA-2006  Springer-Verlag 2005  N Glance M Hurst K Nig am M Sie gler  R Stockton and T Tomokiyo Deriving marketing intelligence from online discussion In Proceedings of the 11th ACM SIGKDD International Conference on Knowledge Discovery in Data Mining  pages 419ñ428 New York USA 2005 ACM  M Hu and B Liu Mining opinion features in customer reviews In Proceedings of 9th National Conference on Arti\002cial Intelligence  2004  N K obayashi K Inui K T atei shi and T  Fukushima Collecting evaluative expressions for opinion extraction In Proceedings of IJCNLP 2004  pages 596ñ605 2004  S Morinag a K Y amanishi K T ateishi and T  Fukushima Mining product reputations on the Web In Proceedings of KDD-02 8th ACM International Conference on Knowledge Discovery and Data Mining  pages 341ñ349 Edmonton CA 2002 ACM Press  A.-M Popescu and O Etzioni Extracting product features and opinions from reviews In Proceedings of HLT-EMNLP-05 the Human Language Technology Conference/Conference on Empirical Methods in Natural Language Processing  pages 339ñ346 Vancouver CA 2005  H Schmid T reetagger a language independent part-ofspeech tagger Institut fur Maschinelle Sprachverarbeitung Universitat Stuttgart  1995  J W iebe R Bruce and T  O'Hara De v elopment and use of a gold-standard data set for subjectivity classi\002cations In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics  pages 246ñ253 Association for Computational Linguistics Morristown NJ USA 1999  J Y i T  Nasuka w a R Bunescu and W  Niblack Sentiment analyzer Extracting sentiments about a given topic using natural language processing techniques In Proceeding of ICDM-03 the 3ird IEEE International Conference on Data Mining  pages 427ñ434 Melbourne US 2003 IEEE Computer Society 
160 
151 


Figure 4 Expected and real number of extracted patterns using two promoter sequence datasets Horizontal axis minimum support vertical axis number of patterns 
85 
85 


a frequency constraint and according to the structure of the dataset These proposals are all based on a global analytical model i.e an interesting approach that needs however to develop complex and speci\036c models As a result they cannot be easily extended to handle complex conjunctions of constraints to incorporate different symbol distributions or different semantics for pattern occurrences To the best of our knowledge no method has been proposed to estimate the number of patterns satisfying a constraint while avoiding to develop a global analytical model Our approach requires only to know how to compute for a given pattern its probability to satisfy the constraint this can be obtained in many situations and it remains ef\036cient in practice by adopting a pattern space sampling scheme 6 Conclusion Using constraints to specify subjective interestingness issues and to support actionable pattern discovery has become popular Constraint-based mining techniques are now well studied for many pattern domains but one of the bottlenecks for using them within Knowledge Discovery processes is the extraction parameter tuning This is especially true in the context of differential mining where domain knowledge is used to provide different datasets to support the search of truly interesting patterns From a user perspective a simple approach would be to get graphics that depict the extraction landscape i.e the number of extracted patterns for many points in the parameter space We developed an ef\036cient technique based on pattern space sampling that provides an estimate on the number of extracted patterns This has been applied to non trivial substring pattern mining tasks and we demonstrated by means of many experiments that the technique is effective It provides reasonable estimates given execution times that enable to probe a large number of points in the parameter space Notice that domain knowledge is also exploited here when selecting the distribution model Future directions of work include to adapt the approach to other pattern domains and to different constraints Another interesting aspect to investigate is the use of more sophisticated sampling schemes e.g that could b e incorporated in the approach when more complex syntactical constraints are handled e.g a grammar to specify the shape of the patterns Acknowledgments This work is partly funded by EU contract IQ FP6-516169 Inductive Queries for Mining Patterns and Models and by the French contract ANR-MDCO14 Bingo2 Knowledge Discovery For and By Inductive Queries We thank Dr Olivier Gandrillon from the Center for Molecular and Cellular Genetics CNRS UMR 5534 who provided the DNA promoter sequences References  J F  Boulicaut L De Raedt and H  M annila e ditors Constraint-Based Mining and Inductive Databases  volume 3848 of LNCS  Springer 2005  C  B resson C K e ime C F a ure Y  Letrillard M  B arbado S San\036lippo N Benhra O Gandrillon and S GoninGiraud Large-scale analysis by SAGE revealed new mechanisms of v-erba oncogene action BMC Genomics  8\(390 2007  L  C ao and C  Z hang Domain-dri v e n actionable kno wledge discovery in the real world In Proceedings PAKDD’06 volume 3918 of LNCS  pages 821ñ830 Springer 2006  G  D ong and J  L i Ef 036cient mining of emer ging patterns discovering trends and differences In Proceedings ACM SIGKDD’99  pages 43ñ52 1999  F  Geerts B  G oethals and J  V  d en Bussche T ight upper bounds on the number of candidate patterns ACM Trans on Database Systems  30\(2 2005  U  K eich and P  A  P e vzner  S ubtle motifs de\036ning the limits of motif 036nding algorithms Bioinformatics  18\(10 2002  S  K ramer  L De Raedt and C  Helma M olecular f eature mining in HIV data In Proceedings KDD’01  pages 136 143 2001  L  L hote F  Rioult and A  S oulet A v e rage number of frequent closed patterns in bernouilli and markovian databases In Proceedings IEEE ICDM’05  pages 713ñ716 2005  I  M itasiunaite a nd J.-F  B oulicaut Looking for monotonicity properties of a similarity constraint on sequences In Proceedings of ACM SAC’06 Data Mining  pages 546ñ552 2006  I Mitasiunaite and J F  Boulicaut Introducing s oftness i nto inductive queries on string databases In Databases and Information Systems IV  pages 117ñ132 IOS Press 2007  I Mitasiunaite C Rigotti S Schicklin L  M e yniel J F  Boulicaut and O Gandrillon Extracting signature motifs from promoter sets of differentially expressed genes Technical report LIRIS CNRS UMR 5205 INSA Lyon France 2008 23 pages Submitted  G Ramesh W  M aniatty  a nd M J Zaki F easible itemset distributions in data mining theory and application In Proceedings ACM PODS’03  pages 284ñ295 2003  F  Zelezn  y Ef\036cient sampling in relational feature spaces In Proceedings ILP’05  volume 3625 of LNCS  pages 397 413 Springer 2005 
86 
86 



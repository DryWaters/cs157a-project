 Feature-level Sentiment Analysis for Chinese Product Reviews   Haiping Zhang, Zhengang Yu, Ming Xu, Yueling Shi Dept. of Computer Science Hangzhou Dianzi University Hangzhou, China, 310018 zhanghp@hdu.edu.cn, kingchdu@gmail.com, mxu@hdu.edu.cn, xiaoshi@hdu.edu.cn   Abstract  The sentiment analysis for English product reviews has been widely researched in recent years, followed with many important achievements. Due to the special language traits of Chinese, the study on Chinese product reviews is 
much more difficult than the former. In this work, we focus on the finer-grained sentiment analysis for Chinese product reviews, that is feature-level based sentiment analysis. We propose a hybrid method which combines association rules and point-wise mutual information  to extract the product features and then take advantage of the sentiment dictionaryÑHowNet to analyze the opinion orientation expressed on the product features. The experiment result obtained shows the effectiveness and efficiency of our approach Keywords- feature extracting; feature-level sentiment analysis; Chinese product reviews I   I NTRODUCTION  The dramatic development of Web 2.0 technology in the 
past few years has greatly changed peopleês life styles especially peopleês shopping patterns have experienced a significant change. People who want to purchase something get used to viewing a large number of network reviews about the relative products or services beforehand, so that they can make reliable decisions. Mining valuable information from these product reviews not only provides some necessary purchase information for the potential consumers but also helps producers track the feedbacks of users on time. The feedback information contributes producers to maintain the good characteristics of products and improve the inferior products timely, and finally make them gain competitiveness 
in the near future However, the huge number of network comments also makes mining useful information to be a new challenge. It is hard and unrealistic for human to tackle all the reviews and classify them to positive or negative manually. Under this situation, automatic sentiment analysis technology has significant meaning. Via this approach, we can automatically extract the opinion which the author expressed on the product or its features Although researchers have made some important achievements on English product reviews, studies on the Chinese product reviews are still in its infancy. The great language differences existing between English and Chinese 
make the results obtained under English area can not be applied to Chinese comments directly. In this research, we mainly focus on the technology of feature extraction and its sentiment tendency analysis based on Chinese product reviews As is known, document-level and sentence-level based sentiment analysis are usually used to judge the overall evaluations of the special product. In order to obtain much more finer-grained and detailed product information, featurelevel sentiment analysis is essential. There are two major topics involved in feature-level sentiment analysis 1  Extracting the product features which the user concerned. For example, in the sentence 
   The tone quality of this mobile phone is good   tone quality the productês feature 2  Analyzing the sentiment orientation of the product features. That is, classifying the authorês evaluations expressed on the product feature into positive emotion, negative emotion or neutral. In the above sentence, the evaluation on the feature is positive The remaining of the paper is arranged as follows. In section II, we introduce the previous related researches on feature-level sentiment analysis. In section III, we will 
illustrate our method in detail. The corpus used in our experiment and the experiments result will be presented in section IV. Section V draws the conclusion of our research and then proposes the future work II  R ELATED W ORK  Sentiment analysis or opinion mining has attracted many researchersê interests. One of the most important issue of sentiment analysis is how to extract the opinions on the product features in the review, which is feature-level sentiment analysis The purpose of feature-level sentiment analysis for network product reviews is obtaining the opinions expressed 
on the  product features. By this process, users can focus on the product features they most concerned A crucial aspect involved in feature-level sentiment analysis is product feature extraction. Many important achievements have been made in this area Hu and Liu in propo s e d  a m e thod base d o n  association rule to mine the product features. It took the ___________________________________ 978-161284 840-2  11 26.00 ©201 1 IEEE  


 advantage of the phenomenon that people always use the same opinion word to describe the same feature in his/her comments. The author drew the conclusion that the frequent noun and noun phrase \(çitem setsé\ are probably to be product feature words. Popescu and Etzioni in [2 tract features by computing pair-wise mutual information between noun phrases and a set of metonymy discriminators associated with the product category. Different from the algorithm  and [2] that utili zed word co o ccu r ren ce, [3 applied a language model approach with the assumption that product features are mentioned more often in a product review than they are mentioned in generic English Kobayashi et al. in their research [4 u s ed  a patter n  m i n ing  method to extract the features. The patterns which mined from a large corpus using pattern mining are the relations between feature and opinion pairs s e d a bootstrapping iterative learning strategy to identify product features and opinion words. Besides, they exploited linguistic rules to find low frequent features and opinion words In the most recent researches, Qiu et al. in [6 se d a double propagation method, which took advantage of certain syntactic relations of opinion words and product features The extraction rules are designed based on different relations between opinion words and features, and among opinion words and features themselves. The relations are described by dependency grammar. It runs well for mediumÖsize corpora. But for large corpora, this method may extract many nouns/noun phrases which are not features. Thus the precision of the method drops. To improve the results in  Zhang et al. in their research [7 s ed  a n o vel m e t h od t o  mine product features, which consisted of two steps: feature extraction and feature ranking. In the feature extraction step they utilized part-whole relation patterns and a çnoé pattern to enhance the performance. And in the feature ranking step they ranked feature candidates by feature importance Similar to general information extraction, the traditional rule-based method and statistical-based method can also be adopted to feature extraction. The popular models of statistical methods are Conditional Random Fields \(CRF\8   Maximum Entropy Models \(ME  and so o n  Other related researches on feature extraction mainly utilize topic modeling or clustering to capture features in reviews \([10  11 However  topic m o de l i n g or clus terin g  is  only able to find some general or rough features, it is difficult to extract finer-grained or precise features As is described in textua l s enti m e n t  a n a l y s is can be  classified into three types: document-based, sentence-based and feature-based sentiment analysis. Feature-based sentiment analysis is to determine the opinion tendency on the features. As it is most related to the practical applications we put the emphasis on the feature-based sentiment analysis The approaches used in the document-based and sentencebased sentiment analysis can apply here too. An efficiency way to conduct feature sentiment analysis is called lexiconbased approach 14   L exico n-base d m e t h od s are usua l l y  involved with sentiment lexicons and some linguistic features. The sentiment lexicons comprise of several seed words or just a big dictionary. In this research, we use the sentiment dictionary provided by HowNet 1 to conduct sentiment analysis III  O UR A PPROACH  In this section, we will present our approach in detail Firstly, we use the Apriori association mining rules to extract the candidate product features, then adjust the orders of some candidate product feature words. Finally, we use point-wise mutual information \(PMI\ methods to filter feature words so as to obtain the meaningful product feature words. After get the feature words, we use the sentiment dictionary provided by HowNet to analyze the sentiments expressed on the features A  Feature Words Extacting Based on Apriori The algorithm of Apriori association rules was first proposed by Agrawal and Srikant [1 s  one o f  t he m o s t  classical association rules used to mine frequent item sets The core part of the Apriori algorithm is the two-stage recursive process 1  Identify all the frequent item sets in the transaction database whose support are greater than or equal to the user defined threshold 2  Use the frequent item sets produced above to construct the rules that meet the minimum confidence Fig. 1 shows the Apriori algorithm in detail. Here D is the transaction database C k is the candidate item sets and the function apriori_gen\(\used to generate candidate item sets of length k from item sets of length k 1. Then pruning the candidates those who have infrequent sub pattern In this research, we adopt the Apriori algorithm to extract product feature words. The product feature words can be seemed as frequent item sets to some extends. It is no necessary to construct the associate rules further              Figure 1  The Apriori algorithm B  Feature Wordsê Order Adjustment In some cases, the candidate feature words extracted via Apriori algorithm may not have the normal sequence. This is because the procedure of merging previous item sets into new candidate feature words ignores the wordês semantic   1  http://www.keenage.com/html/c_index.html   L 1 frequent 1-item sets for  k 2 L k-1     k  do begin   C k apriori_gen L k-1   for any transaction t  D  do begin   C t subset C k  t   for any candidate item c   C t  do    c.count   end   L k  c   C k  c.count  min_supp  end  


 For example, the candidate feature word    Resolution Screen is generated from the frequent 1-item    Resolution nd  Screen However, the normal sequence of these two words after combined should to be   Screen Resolution  In this research, we use a statistical method to adjust the candidate feature wordsê unreasonable order Given the candidate item set f and f is composed of 1item sets w 1  w 2  w k The position of w i in the comment sentence is noted as s i Then re-arrange the word sequence in f by ascending order based on w i  s value. Symbol f   means the new sequence after re-arranging, and the position of w i in f   is noted as s i  Finally, we identify all product reviews which containing the feature words of candidate item set f  then sum each featureês s i  value so as to get the result pos  w i  The value of pos  w i ermines the candidate featuresê final sequence For instance, suppose the candidate item set f  thus w 1    w 2  Given the product review   This mobile phoneês screen is big and its resolution is also very high  After Chinese segmentation, it turns to be r n u n d a n d d aé. As can be seen w 1 and w 2 appears in this review, and s 1 7 s 2 4 Then according to the value of s i to adjust the sequence of candidate item set f We can get the new feature set f    as s 2 4 s 1 7. Therefore, the position of word w 1 in f  is s 1  2, and w 2 in f  is s 2  1 Suppose there are 4 reviews contain the item set f  Among these reviews  appears before the word  only in one review, which means s 1   1 s 2  2. In the left three reviews  appears behind the word thus s 1   2 s 2   1. As a result pos  w 1      4  1 s 1+2+2+2 = 7 and pos  w 2    4  2 s  2+1+1+1 = 5. Hence, after processing all of the reviews which contain the feature f the final sequence of f is adjusted to be  as 5 < 7 C  Feature Wordsê Filtering Based on PMI Since the algorithm is calculated based on the noun or noun phraseês frequency, the çproduct featureé mined in this way may have no practical meanings. The senseless features will become noises and they will affect the efficiency and effect of the extracting procedure. Therefore, it is necessary to do further job to filter senseless product feature words extracted by the Apriori algorithm after the order adjusting To solve this problem, we take advantage of the Google search engine combined with the approach which used pointwise mutual information \(PMI\oposed by Turney  PMI is used to mine the semantic correlations between the candidate product feature words and product words. By calculating the PMI value, then a proper threshold will be obtained. Thus, some candidate product feature words will be abandoned if their PMI value are below the threshold The definition of PMI is given in Equation 1          log    2 1 2 1 2 2 1 word p word p word word p word word PMI   1  Here p  word 1  word 2 is the co-occurrence probability of word 1 and word 2 and p  word 1  p  word 2 ives the probability that the two words co-occurring if they are statistically independent. The ratio between p  word 1  word 2  and p  word 1  p  word 2 is thus a measure of the degree of statistical dependence between the words. The log of this ratio is the amount of information that we acquire about the presence of one of the words when we observe the other Based on  the Equation \(1\e improved the formulation to calculate the PMI value between the product feature and product itself         log    2 feature hit product hit feature product hit feature product PMI  2 In \(2 hit  x is the number of relative links returned by the search engine when query some keywords. For example hit  product A is the number of links returned when search the keyword çproduct A hit  product  feature tands for the link numbers returned when use the çproducté and featureé together as the query keywords. Due to the actual value of hit  product  hit  feature may be very large, here we extract the square root value of the denominator so as to be suitable for computer handling Equation \(2\ illustrates that the larger the PMI value is which means the more sufficient mutual information of candidate product features and product itself, the more likely these candidate product features to be the real features of the product. Suppose the threshold is  and if PMI  product  feature    then we can draw the conclusion in statistically that the feature is the real part of the product  Otherwise, the feature will be removed from the candidate feature words D  Feature-level Sentiment Analysis Based on HowNet Sentiment Dictionary The feature-level sentiment analysis task can be divided into two sub tasks 1  Identifying product features 2  Determining whether the opinions on the features are positive, negative or neutral In this section, we focus on the second sub task as the product features have been identified through above steps. In our methodology, we utilize unsupervised learning method based on sentiment dictionary to identify the opinions expressed on the features. The sentiment dictionary used is provided by the HowNet 2 In this research, we only make use of the Chinese evaluation and sentiment words in this dictionary The processing procedure is shown in Fig. 2. Detailed process of feature sentiment analysis is described as follows   2  http://www.keenage.com/html/c_index.html  


  Input next product review Feature words matching Feature words appear in the review Sentiment words identifying Analyzing context polarity of the sentiment word is ahead of sentiment word Reverse the polarity Figuring out the final sentiment polarity The feature words have been extracted HowNet positive evaluation/sentiment words Feature words matching N Y N Y HowNet negative evaluation/sentiment words  Figure 2  The processing steps in determing featureês opinion 1  Word segmentation and POS tagging to the reviews The tool used here is ICTCLAS system 3 which is developed by the Institute of Computing Technology of Chinese Academy of Sciences 2  Feature words matching. It takes advantage of the product feature words obtained through the Apriori association rule mining algorithm and PMI filtering algorithm to identify the product feature words appeared in the review. Potential feature mining is not be taken into account in this research. Hence, if there is no obvious product feature word found in the review, then go to step \(1\ to process the next review 3  Classifying sentiment wordês polarity. To the reviews which contains any product feature word extracting a adjective word before or behind it as the opinion word using the result of word segmentation and POS tagging. Then determining the opinion word appears in which category of the sentiment dictionary provided by HowNet. That is, the opinion word will be classified into positive if it falls in the scope of positive evaluation words or positive sentiment words. Otherwise, it will be grouped into negative 4  Analyzing sentiment wordês context polarity. As is known, the sentiment orientation will be opposite to the original one in most cases if negative word appears ahead. We utilize the word no\ as the   3  http://ictclas.org/Download.html  prefix negative word which appears frequently in Chinese product reviews 5  Figuring out the final sentiment polarity of the product feature. Considering there may be different opinions expressed on the same feature, it is necessary to sum up the various views IV  E XPERIMENTS  A  Data Sets We select 6 different products reviews which are collected from the website IT168 4 as the experiment corpus In the corpus, there are 3 different brands, and each brand has 2 similar type products. The 6 different products are including Lenovo G450M-TFO laptop Lenovo IdeaPad  laptop Panasonic EZ35 digital camera Panasonic LX3  digital camera Nokia 5230 mobile phone and Nokia 5800 XM mobile phone. The number of each type product review is 100 B  Experiment of Feature Words Extacting Based on Apriori In this experiment, suppose one product type to be the training data, then the other product with the same brand is taken as the testing data. The arrangement of training data and testing data is shown in Table I TABLE I  T HE T RAINING D ATA AND T ESTING D ATA  The reviews in training sets The reviews in testing sets Nokia 5800XM  mobile phone Nokia 5230 mobile phone Lenovo IdeaPad laptop Lenovo G450M-TFO laptop Panasonic LX3 digital camera Panasonic EZ35 digital camera Generally speaking, the product feature words are noun or noun phrases. To avoid many senseless words and improve the efficiency of the Apriori algorithm, only the noun or noun phrase are left in the experiment Through times of verification in the training sets, we find that the feature words in 3-item set or above 3 extracted based on the Apriori algorithm are almost nonsense words Therefore, only the 1-item set and the 2-item set are extracted so as to decrease the runtime consuming of the Apriori algorithm TABLE II  T HE R ESULTS OF A PRIORI E XTRACTIONG  Product Recall Precision F1 value Panasonic EZ35 digital camera  62.5  71.4  66.7 Lenovo G450M-TFO laptop  70.4  73.1  71.7  Nokia 5230 mobile phone  80.8  72.4% 76.4   4  http://www.it168.com  


 The performance of the experiment depends greatly on the support value of the Apriori. We adopt the support value as the threshold which makes the F1 value gain the optimum in the training set. Here, the support threshold in Panasonic EZ35 is 5, in Lenovo G450M-TFO is 6, and in Nokia 5230 is 7. The result is shown in Table II. It shows that the average F1 value is 71.6 C  Experiment of Feature Wordsê Order Adjustment The consequence of  the feature wordsê order adjustment is listed in Table III. It can be seen that the average F1 value of the 3 product after adjustment is 75.1% comparing to 71.6% before adjustment. The adjustment step improves the overall performance TABLE III  T HE R ESULTS OF F EATURE W ORD  S O RDER A DJUSTMENT  Product Recall Precision F1 value Panasonic EZ35 digital camera 68.8 78.6 73.4 Lenovo G450M-TFO laptop 74.1 76.9 75.4 Nokia 5230 mobile phone 80.8 72.4 76.4 D  Experiment of Feature Wordsê Filtering Based on PMI The purpose of this experiment is to identify the PMI threshold by use of the Google search engine so that filtering the nonsense feature words more effectively. The PMI threshold value is obtained through times of experiments in the training sets. Here, the PMI threshold in Panasonic EZ35  is -3.02, in Lenovo G450M-TFO is -4.61, and in Nokia 5230  is -3.57. The performance after PMI filtering is illustrated in Table IV. As is shown in the table, the average F1 value of the 3 product is 75.4%. Comparin g to the initial result 71.6 gained by the Apriori algorithm, the performance after series processing has been enhanced obviously TABLE IV   T HE R ESULTS OF F EATURE W ORD  S F ILTERING  Product Recall Precision F1 value Panasonic EZ35 digital camera 68.8 81.5 74.6 Lenovo G450M-TFO laptop 70.4 82.6 76.0 Nokia 5230 mobile phone 76.9 74.1 75.5 E  Experiment of Feature-level Sentiment Analysis Based on HowNet Sentiment Dictionary In this experiment, we take advantage of the sentiment dictionary provided by HowNet to analysis the opinion orientation of the product feature. The mining result is presented in the form of \(çproduct featureé, çsemantic polarityé\, such as Cannon lens  positive Table V gives the average performance of the experiment   TABLE V  T HE R ESULTS OF F EATURE LEVEL S ENTIMENT A NALYSIS  Product Recall Precision F1 value Panasonic EZ35 digital camera 67.1 79.2 72.6 Lenovo G450M-TFO laptop 70.4 81.3 75.5 Nokia 5230 mobile phone 69.2 83.5 75.7 The experiment results demonstrate that the simplicity approach proposed in this paper performs well on the Chinese product reviews. But the recall is low. The reasons lead to this phenomenon are mainly due to   Some reviews contain the feature words but have no opinion words modifying the features   Some opinion words are ambiguity in different situations. This will make the approach in this paper miss the right sentiment words expressed on the product feature   Lacking of semantic analysis. A case in point is that we ignored the potential feature word mining such as in the review The G2 mobile phone is so dear the potential feature is çprice   The network words appeared in the product reviews changes so quickly that the sentiment dictionary can hardly cover them completely and timely V  C ONCLUSIONS AND F URTURE W ORK  The approach we proposed in this paper takes advantage of the Apriori association rule algorithm to extract candidate product feature words. After adjusting the order of the candidate features and then filtering nonsense features based on the improved PMI, the performance of products feature extraction has been improved significantly In most cases, customers need more detailed information about the products or their features. This research utilize the sentiment dictionary of HowNet to conduct feature-level analysis since the feature words have been obtained. The approach is simplicity and efficiency in Chinese product processing. Due to lacking of deeply semantic analysis of on the reviews, the overall performance of the method needs to improve In the near future, we will put more emphasis on the feature extracting. Some classical models such as Conditional Random Field\(CRF\, Maximum Entropy\(ME and other machining methods will be utilized comprehensively. In the feature-level analysis phase, we will employ the semi-supervise learning method which combines the advantages of supervise learning and unsupervised learning methods. This is extremely adapted to the situation when there are less annotated data and lots of un-annotated data. Besides, the semantic and sentence rules will also be taken into consideration A CKNOWLEDGMENT  This paper is supported by the State Key Program of Major Science and Technology \(Priority Topics\ of Zhejiang Province, China under Grant No 2010C11050 


 R EFERENCES  1  M. Hu and B. Liu. Mining and summarizing customer reviews Proceedings of SIGKDD. 2004 2  A. M. Popescu and O. Etzioni. Extracting product features and opinions from reviews. Proceedings of EMNLP. 2005 3  C. Scaffidi, K. Bierhoff, E. Chang, M. Felker, H. Ng and C. Jin. Red opal: Product-feature Scoring fr om Reviews. Proceedings of EC 2007 4  N. Kobayashi, I. Kentaro and Y. Matsumoto. Extracting AspectEvaluation and Aspect-of Relations in Opinion Mining. In Proceedings of EMNLP. 2007 5  B. Wang, and H. F. Wang. Bootstrapping both Product Features and Opinion Words from Chinese Customer Reviews with Cross-Inducing Proceedings of IJCNLP. 2008 6  G. Qiu, B. Liu, J. Bu and C. Chen. Expanding Domain Sentiment Lexicon through Double Propagation Proceedings of IJCAI. 2009 7  L. Zhang, S.H. Lim, B. Liu, and E. O'Brien-Strain. Extracting and Ranking Product Features in Opinion Documents. Proceedings of COLING. 2010 8  J. Lafferty, A. McCallum and F. Pereira. Conditional Random Fields Probabilistic Models for Segmenting and Labeling Sequence Data Proceedings of ICML. 2001 9  H. L. Chieu, and H.-T. Ng. Name Entity Recognition: a Maximum Entropy Approach Using Global Information. Proceedings of the 6th Workshop on Very Large Corpora. 2002 10  Q. Z. Mei, X. Ling, M. Wondra, H. Su and C.X. Zhai. Topic Sentiment Mixture: Modeling Facets and Opinions in Weblogs Proceedings of WWW. 2007 11  Q. Su, X. Y. Xu., H. L. Guo, Z.L. Guo, X. Wu, X.X. Zhang, B. Swen and Z. Su. Hidden Sentiment Association in Chinese Web Opinion Mining. Proceedings of WWW. 2008 12  B. Liu. Sentiment analysis and subjectivity. Handbook of Natural Language Processing, second edition. 2010 13  M. Hu and B. Liu. Mining and summarizing customer reviews Proceedings of the ACM Conference on Knowledge Discovery and Data Mining \(KDD\2004 14  X. Ding, B. Liu, and P. S. Yu. A holistic lexicon-based approach to opinion mining. Proceedings of the Conference on Web Search and Web Data Mining \(WSDM\. 2008 15  R.Agrawal, and R.Srikant. Fast Algorithms for Mining Association Rules. In Proceedings of VLDB.1994 16  P. D. Turney. Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews. Proceedings of ACL. 2002                                        


representing its significance. In this paper weight of page pi is denoted as w\(pi  IV. THE  PROPOSED APPROACH In the proposed approach, weight system exist in the server side and all the information that are required to calculate the weight of a web page can be derivative from websites Web logs. We presume that web logs are preprocessed and users session is identified. Since this recommendation system is based on user navigation behavior so that the weight for each web page could be calculated based on users previous visit to that page. When a user comes, the system will first retrieve the users interest from the database If the user is new, the system will give a registration option for the registration for that site. If the user is new, the system will give an option for the registration for that web site. After the registration whenever user visits first time there will be no option for recommendation path traversal. The user can visit on any page just by clicking on link found on that page and the system will calculate the weight for each page based on users navigation behavior. Now according to weight association rule greater weight indicates the more interest on that page. The proposed system will recommend web path traversal for that web site based on weight associated with each web page Let U= {u1, u2 un} denote the set of web pages accessed by a user and each of them is distinctively recognized by its related URL. The weight can be calculated in number of ways The primary sources of data are server access logs The proposed approach consists of two algorithms designed for finding Web path Traversal of Web pages visited by a user  A. FREQUENY BASED PAGE WIGHT ALGORITHM The Frequency Based Page Weight \(FPW called FPW, is based on Visiting Frequency of a Web page The Visiting Frequency of a page u is the number of times that a page visited after page v. There is an important feature that can never be neglected is to calculate the Visiting Frequency of a web page is the PageRank of that page. It is obvious that a page with large in-degree has more probability to be visited than a page with small one. The frequency weight \(FW defined in \(4 


 FW \(u u 4  Where PR represents the page rank of a particular page and calculated with the help of \(3 4 for the calculation of weight of each web page and that weight of a page will be equal to the frequency weight given in \(5  W\(u u 5  The algorithm FPW is described as follows                B. FREQUENY AND TIME SPENT BASED PAGE WIGHT ALGORITHM The Frequency and Time Spent based Page Weight algorithm \(FTPW Time Spent on a Web page Time spent on a page replicates the relative consequence of each page, because a user generally spend more time on a useful page and quickly skip to other page. The transfer rate and web page size are two important factors used to calculate the real time spent on a page. If we assume a steady transfer rate of acquiring information from pages for a user, the time Algorithm: FPW Input: Web traversal path database Output: Weight for each page 1 Calculate PageRank for each page \(PRi 3 2 Initially Set W\(Pi 


3 Check the user is registered or not, if YES then 4       whether the user is first time visitor, if YES then 5  return W\(Pi 6    else 7      calculate FW\(Pi 4 8 SET   W\(Pi Pi 9 return W\(Pi 2010 5th International Conference on Industrial and Information Systems, ICIIS 2010, Jul 29 - Aug 01, 2010, India 197 spent on a page is inversely proportional to the degree of information useful to user. The formula to calculate the weight based on time spent on each page is given in \(6  TW?u? = T??? ????? ?? ? ???????/P??? S??? ????????U?T??? ????? ?? ? ???????/P S??? ????                  \(6  The Frequency and Time spent based page Weight FTPW spent on a particular page, as biasing factors. Frequency and Time spent based page Weight can be calculated by the formula given in \(7  W\(u u u 7  Where FW\(u which can be computed from \(4 u page based on time spent on a page which can be computed from equation \(6 u based on frequency and time spent both The Pseudo code of FPW algorithm given as follows            


   V. PERFORMANCE EVALUATIONS The performance of the proposed approach in terms of various parameters is discussed in this section A.  Data Set We have evaluated the performance of proposed algorithms by using the synthetic data set for different users to calculate the weight of each web page. Consider the structure of a web site consisting of four web pages namely A, B, C and D and their respective interconnection shown by direct edges as shown below in Figure 1       Figure 1: Web Site Structure The following factors are considered for performance evaluation Outbound links which shows the out degree of nodes for the graph of Figure1 Page Rank \(PR which can be calculated on the basis of the equation \(3 Number of visit shows the visiting frequency of each web page by user, it can be decided on the basis data received from web log Page Size defines the size of page on the basis of information content of the web page, which can be measured in bytes Time spent describes the resumption of a particular web page by user in seconds  The above parameters used in proposed experimental set up for the Web Path Traversal, by considering the graph mentioned in Figure1 B. Evaluation Method The attributes considering for the training data set for each user of a web site is represented in terms of time spent on each page and frequency. From these data sets we are 


calculating the weight for each web page for respective web site. The proposed approach uses Visiting Frequency and Time Spent on a Web page as two parameters to measure the weight of each web page To estimate the performance of the proposed two algorithms i.e. FPW and FTPW, discussed in section IV based on the above parameters involved in estimation C. Experimental Results The performance of the proposed approach can be evaluated by comparing the performance of FPW and FTPW algorithms which differ in number of parameters considered for experimentation. The comparison is made by taking the attribute like Visiting Frequency in FPW, and further Visiting Frequency and Time spent on a web page are clubbed together in FTPW as another attribute. The experimental setup uses five users and weights are plotted against various parameters Figure 2 shows the plot of Visiting Frequency v/s Weight of a web page              Figure 2: Plot between frequency and weight Algorithm: FTPW Input: Web traversal path database Output: Weight for each page 1 Calculate PageRank for each page \(PRi 3 2 Initially Set W\(Pi 3 Check the user is registered or not, if YES then 4       whether the user is first time visitor, if YES then 5  return W\(Pi 6    else 7      calculate FW\(Pi 4 


8            calculate TW\(Pi 6 9   SET   W\(Pi Pi Pi 10   return W\(Pi A C B    D 0 0.05 0.1 0.15 0.2 0 5 10 15 20 w ei gh t Visiting Frequency User1 User2 User3 user4 User5 2010 5th International Conference on Industrial and Information Systems, ICIIS 2010, Jul 29 - Aug 01, 2010, India 198  Using the weights calculated in Figure the higher weight for more frequently visited information in FPW algorithm the different the scenario described in Figure 1 for all th plotted in Figure 3            


   Figure 3: Recommendation for Web Path Trave Algorithm  The weight assigned to various pages Visiting Frequency and Time spent on web Figure 4                  Figure 4: Plot between \(frequency + time sp  The Figure 5 gives the details of recomm Traversal for different users by FTPW a weights calculated by considering two para and time spent in Figure 4 which indicates for more frequently visited pages and in term on web pages  0 0.02 0.04 0.06 0.08 0.1 0.12 


0.14 0.16 0.18 W ei gh t Web Pages Us Us Us Us Us 0 0.2 0.4 0.6 0.8 1 1.2 1.4 W ei gh t FTPW \(Frequecy  and 2 which indicate pages. Using this traversal paths in e users have been rsal based on FPW by combining the page is plotted in ent ended Web Path lgorithm and use meters frequency the higher weight s more time spent    


         Figure 5: Recommendation W Algo Figure 6 shows the relative on the synthetic data sets, in w more efficient than FPW algor performance of proposed a increase the complexity of alg and provide better Web Path Tr    Figure 6: Relative Access  The proposed FTPW algorithm parameters which otherwise ar FPW algorithm. A matrix dep comparison between above two parameters are performance ce show that the performance o increase the number of param FPW algorithm to FTPW algori The experimental results d better and provides a methodo optimized Web path traversal past navigation behavior by c page 0 1 2 3 4 5 1 2A 


cc es si bi lit y Ti m e fo r M or e re qu ir ed In fo rm at io n er1\(A->C->D->B er2\(D->B->A->C er3\(D->B->C->A er4\(C->B->A->D er5\(B->A->D->C Time User1 User2 User3 User4 User5 0 0.2 0.4 0.6 0.8 1 1.2 


W ei gh t Web Pages eb Path Traversal based on FTPW rithm  execution for FPW and FTPW hich we can see that FTPW is ithm. Hence, it is clear that the lgorithm increases when we orithm in terms of parameters aversal in less time  ibility time for FPW and FTPW consists of clubbing of various e not available in first proposed icted in the Figure 7 describes proposed algorithms. Here the ntric and a comparison results f the system improves as we eters i.e. when we move from thm rawn for FTPW algorithms are logy for effective, efficient and for various users based on their omputing weight for each web 3 4 5 User FTPW FPW User1\(C->B->A->D User2\(A->B->C->D User3\(B->C->A->D User4\(D->A->C->B User5\(B->D->A->C 2010 5th International Conference on Industrial and Information Systems, ICIIS 2010, Jul 29 - Aug 01, 2010, India 199 Figure 6: Comparison Matrix VI.  CONCLUSION & FUTURE WORK 


 Web Usage Mining have been used in improving Web site design and marketing decision support, user profiling, and Web server system performance. Web page prediction technique is a very important role in web technologies. This paper proposes efficient algorithms for web path recommendation based on Weighted Association Rule. Two factors frequency and time spent were used to decide the web path traversal. The experimental results show that in the proposed approach when we increase the number of parameters for finding the web path the accuracy of the system is enhanced drastically and FTPW produces more accurate results than those achieved by FPW In the future, we shall improve the Web Path Traversal by considering the parameter Data Transfer Rate to provide the accurate Web Path traversal REFERENCES 1] M. S. Chen, X. M. Huang and I. Y. Lin, Capturing User Access Patterns in the Web for Data Mining, Proceedings of the IEEE International Conference on Tools with Artificial Intelligence, pp. 345348, 1999 2]  R. Cooley, B. Mobasher, and J. Srivastava, Web Mining: Information and Pattern Discovery on the World Wide Web, Proceedings of the 9th IEEE International Conference on Tools with Artificial Intelligence, pp 558-567, 1997 3]  B. Mobasher,N. Jain,E. Han et al, Web mining: pattern discovery from World Wide Web transactions, Tech Rep: TR96-050, 1996 4]  C. Shahabi, A. Zarkesh, J. Abidi, V. Shah, Knowledge discovery from user's Web-page navigation,  in Proceedings of the 7th IEEE International Workshop on Research Issues in Data Engineering, 1997 5]  Yue-Shi Lee, Show-Jane Yen, Ghi-Hua Tu and Min-Chi Hsieh, Web Usage Mining: Integrating Path Traversal Patterns and Association Rules, Proceedings of International Conference on Informatics Cybernetics, and Systems \(ICICS'2003 6]  Yue-Shi Lee, Show-Jane Yen, Ghi-Hua Tu and Min-Chi Hsieh, Mining Traveling and Purchasing Behaviors of Customers in Electronic Commerce Environment, Proceedings of IEEE International Conference on e-Technology, e-Commerce and e-Service \(EEE'2004 pp. 227-230, 2004 7]  J. Srivastava, et al. Web Usage Mining: Discovery and Applications of Usage Patterns from Web Data. SIGKDD Explorations, pp. 12-23 2000 


8]  Sergey Brin and Lawrence Page. The anatomy of a large-scale hypertextual Web search engine. Proceedings of the seventh international conference on World Wide Web 7: pp. 107-117, 1998 9]  J. Pei, J. Han, B. Mortazavi-Asl and H.Zhu, Mining Access Patterns Efficiently from Web Logs, Proceedings of the Pacific-Asia Conference on Knowledge Discovery and Data Mining, pp. 396-407 2000 10]  C. H. Cai, A. W. C. Fu, C.H. Cheng and W. W. Kwong, Mining Association Rules with Weighted Items, In Database Engineering and Applications Symposium, Proceedings IDEAS'98, pp. 68  77, 1998 11]  F. Tao, F. Murtagh and M. Farid, Weighted Association Rule Mining using Weighted Support and Significance Framework, In Proceedings of the 9th SIGKDD conference, 2003 12]  Show-Jane Yen, An Efficient Approach for Analyzing User Behaviors in a Web-Based Training Environment, International Journal of Distance Education Technologies, Vol. 1, No. 4, pp.55-71, 2003 13]  Show-Jane Yen, Yue-Shi Lee and Chung-Wen Cho, Efficient Approach for the Maintenance of Path Traversal Patterns, In Proceedings of IEEE International Conference on e-Technology, eCommerce and e-Service \(EEE 14]  M. Spiliopoulou and L. C. Faulstich, Wum: A web utilization miner EDBT Workshop WebDB98, Springer Verlag, 1996 15]  M. S. Chen, J. S. Park and P. S. Yu, Efficient data mining for path traversal patterns,  IEEE Transactions on Knowledge and Data Engineering, pp. 209-221, 1998 16]  H. Yao,H. J. Hamilton, and C. J. Butz, A Foundational Approach to Mining Itemset Utilities from Databases, Proceedings of the 4th SIAM International Conference on Data Mining, Florida, USA, 2004 17]  Z. Chen, R. H. Fowler and A. Wai-Chee Fu, Linear Time Algorithm for Finding Maximal Forward References, Proceedings of International Conference on Information Technology. Computers and Communications  \(ITCC'2003 18]  T. Jing, Wan-Li Zou and Bang-Zuo Zhang, An Efficient Web Traversal Pattern Mining algorithm Based On Suffix Array, Proceedings of the 3rd International Conference on Machine Learning and Cybernetics , pp 1535-1539, 2004 19]  Show-Jane Yen, Yue-Shi Lee and Min-Chi Hsieh, An efficient incremental algorithm for mining Web traversal patterns, Proceedings of the 2005 IEEE International Conference on e-Business Engineering ICEBE05 20]  L. Zhou, Y. Liu, J. Wang and Y. Shi, Utility-based Web Path  Traversal Pattern Mining, Seventh  IEEE International Conference on Data 


Mining Workshops, pp. 373-378, 2007 21]  C. F. Ahmed, S. K. Tanbeer, Byeong-Soo Jeong and Young-Koo Lee Efficient mining of utility-based web path traversal patterns, 11th International Conference on Advanced Communication Technology ICACT09 22]   http://en.wikipedia.org/wiki/PageRank 23] en.wikipedia.org/wiki/Association_rule_mining  Attributes? FPW Algorithm FTPW Algorithm Recognition of User behavior Visiting Frequency Page Rank Time Spent on Web page Page Size Accessibility of required information in less time Improving Web navigation and system design of Web applications  Enhancing server performance 2010 5th International Conference on Industrial and Information Systems, ICIIS 2010, Jul 29 - Aug 01, 2010, India 200 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



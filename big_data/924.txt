A fault tolerance honeypots network for securing E-government   Shahriar Mohammadi                             Bahman Nikkhahan Smohammadi40@yahoo.com                       bahman616@gmail.com Information Technology Engineering Group Department of Industrial Engineering K. N. Toosi University of Technology, Tehran, Iran  Abstract  One of the big challenges of E-government adoption among citizens is security. Numerous security approaches exist in E-commerce, and all of them are applicable to E-government. Usually government networks can communicate to each other better than business networks, because, most of them are connected for transferring information, but businesses are competitors and they don't disclose their sensitive information. Utilizing "honeypots" is a good solution for tracing hackers and revealing their tools. In this paper, "connectedness" of E-government networks and honeypots are employed to propose an approach for securing a fault tolerance E-government network. This framework solves the problem of low interaction and high interaction honeypots. It creates an environment for hackers that they can use many of the available resources; at the same time, it prevents them from misusing those resources for future attacks  1. Introduction  Information and Communication Technologies ICT\ is transforming the governmental processes in serving citizens \(G2C\businesses \(G2B\and governments \(G2G\. Different authors have different definition of E-government [5   000x  Whitson and Davis \(2001\ "Implementing cost-effective models for citizens, industry federal employees, and other stakeholders to conduct business transactions online 000x  Tapscott \(1996\: “An inter-networked government 000x  Luling \(2001\ “online government services that is, any interaction one might have with any government body or agency, using the Internet or the World Wide Web Inter-networked government is the best definition for the purpose of this paper While E-government is subject to the same threats as e-business, E-government operates within different constraints. Most businesses deal only with a subset of the population, and they can choose the how and the when they do it. But the government must deal with everyone [7 Th erefo r e  i n o r d e r to t h e h u g e nu m b er  of users and transactions, and sensitivity of this field like citizen's private information or government's secret information, and other issues, securing governmental networks is more important than businesses. One of the main issues of trust in Egovernment implementation is security [8  C itizens  prefer to use traditional ways rather than using an unsecured web site. On 14 June 2002 the UK’s Inland Revenue withdrew its online tax filing service amid complaints that users could see other people’s tax returns. This public humiliation, however temporary reveals part of the price paid when E-government initiatives are not secure [7   Wimmer and Bredow \(2001\proposed a holistic concept that integrates security aspects from the strategic level down to the data and information level in order to address different security aspects of Egovernment in a comprehensive way. Their holistic approach consists of 4 layers: strategic, process level interaction and information [9 Hof and Reichstädter surveyed security peculiarities and implementations of security requirements within governmental structures, based on three interaction points \(citizen to government C2G government to government G2G and government to citizen G2C\ [3   This paper introduces a fault tolerance honeynet to strengthen the security of governmental network. At first, honeypots and honeynet are described, and then proposed framework proposed  2. Honeypots  Honeypots are a security resource whose value lies in being probed, attacked or compromised [6  Th e primary purpose of a honeypot is to proactively gather 
2009 International e-Conference on Advanced Science and Technology 978-0-7695-3672-9/09 $25.00 © 2009 IEEE DOI 10.1109/AST.2009.12 11 
2009 International e-Conference on Advanced Science and Technology 978-0-7695-3672-9/09 $25.00 © 2009 IEEE DOI 10.1109/AST.2009.12 13 
2009 International e-Conference on Advanced Science and Technology 978-0-7695-3672-9/09 $25.00 © 2009 IEEE DOI 10.1109/AST.2009.12 13 


information about security threats by providing a real system with real applications and services for the attacker to interact with, but with no production value we can safely watch and learn from an intruder without fear of compromising our systems [1 Honeypots can run any operating system and any number of services. The configured services determine the vectors available to an adversary for compromising or probing the system [4    Honeypots are categorized by the level of interaction into high-interaction and low-interaction A high-interaction honeypot provides a real system the attacker can interact with. It can be compromised completely, allowing an adversary to gain full access to the system and use it to launch further network attacks In contrast, a low-interaction honeypots simulates only some parts — for example, the network stack These honeypots simulate only services that cannot be exploited to get complete access to the honeypot. A low-interaction honeypot often implements just enough of the Internet protocols, usually TCP and IP to allow interaction with the adversary and make her believe she is connecting to a real system [4  We also differentiate between physical and virtual honeypots  2.1. Physical honeypot  Physical honeypot means that the honeypot is running on a physical machine. Physical often implies highinteraction, thus allowing the system to be compromised completely. They are typically expensive to install and maintain. For large address spaces, it is impractical or impossible to deploy a physical honeypot for each IP address. In that case, we need to deploy virtual honeypots [4    2.2. Virtual honeypot  Compared to physical honeypots, this approach is more lightweight. Instead of deploying a physical computer system that acts as a honeypot, we can also deploy one physical computer that hosts several virtual machines that act as honeypots. This leads to easier maintenance and lower physical requirements. Usually VMware or User-Mode Linux \(UML\ are used to set up such virtual honeypots. These two tools allow us to run multiple operating systems and their applications concurrently on a single physical machine, making it much easier to collect data [4  2.3. Advantages and disadvantages of various kinds of honeypots  With the help of a high-interaction honeypot, we can collect in-depth information about the procedures of an attacker [4 e  can  watc h ho w sh e attack s an d  what kinds of tools and approaches she uses High-interaction honeypots — both virtual and physical — also bear some risks. In contrast to a lowinteraction honeypot, the attacker can get full access to a conventional computer system and begin malicious actions. For example, she could try to attack other hosts on the Internet starting from your honeypot, or she could send spam from one of the compromised machines [4 Low-interaction honeypots can be used to detect known exploits and measure how often your network gets attacked. The advantages of low-interaction honeypots are manifold. They are easy to set up and maintain. They do not require significant computing resources, and they cannot be compromised by adversaries. The risk of running low-interaction honeypots is much smaller than running honeypots that adversaries can break into and control. On the other hand, that is also one of the main disadvantages of the low-interaction honeypots. They only present the illusion of a machine, which may be pretty sophisticated, but it still does not provide an attacker with a real root shell [4   One disadvantage of virtual honeypot is the attacker can differentiate between a virtual machine and a real one. It might happen that an advanced attacker compromises a virtual honeypot, detects the suspicious environment, and then leaves the honeypot again Moreover, she could change his tactics in other ways to try to fool the investigator. So virtual honeypots could lead to less information about attackers [4   2.4. Honeynet and Honeywall  Honeynet is a group of linked honeypots behind a special firewall called a honeywall [1 Us ually   a honeynet consists of several honeypots of different type \(different platforms and/or operating systems This allows us to simultaneously collect data about different types of attacks. Usually we can learn indepth information about attacks and therefore get qualitative results of attacker behavior [4 Also, the Honeywall is normally set up as a transparent bridge that limits the amount of malicious 
12 
14 
14 


traffic that can leave the honeynet, keeping an attacker from attacking other machines on the Internet [1  3. The proposed model of a Fault tolerance honeynet for securing e-government  Securing E-government networks is similar to other networks. Many approaches like cryptography, PKI firewalls, digital signatures are employed in these networks. However, as mentioned above, Egovernment is an inter-networked government. In most of the cases, government agencies in a country are connected to each other for communicating the information about citizens. This is one of the main differences between government networks and business networks. Because, the businesses are competitor and do not disclose their network to each other, but in most of the governments, co-operation is more critical than competition. So we can use this connectedness to set up a honeynet The main goal of honeypots is to trace the hackers and obtain information about their approaches and tools. One of the most important challenges of honeypots is the degree of their interaction. If we use low-interaction honeypots, a hacker cannot utilize all of the resources of the system, so she probably won't be able to use all of her approaches and tools Therefore we will lose a suitable opportunity for obtaining information. In the other side if she can completely utilize all of the resources, maybe she can use the information that she obtained from the honeypot for attacking other hosts or send spam from one of the compromised machine [4  As  a resu l t  t h is trade off must be managed effectively Security in the governmental networks is more critical than business networks. So if we want to use honeypots in these networks, we must consider trade off related to interaction, precisely. We need at least a high-interaction honeypot for each agency's network So we have a network of honeypots through the government, called honeynet. With this network we can increase the possibility of attacks; because our honeypots are dispersed all over the government and all of them are high-interaction. Furthermore we have a Honeycentre server. This server is the manager of the honeynet. It aggregates all of the honeypots logs and then summarizes the results. Honeycentre then informs the web servers about the results, so the administrators of those web servers make an appropriate defensive decision to cover the security holes Now we have a network that traces the attacks, all over the government, with a high degree of interaction to hackers. On the other hand, we can cover our security holes as soon as possible Honeypots are subject to damage. So, various attacks may disable the honeypots. So we must have a fault tolerance network to predict these problems and react as soon as possible. For this purpose Honeycentre can help. Honeycentre is gathering information and logs from honeypots all of the times When a honeypot is down, Honeycentre cannot receive the logs from that honeypot, so it informs the web server of that network and simultaneously assigns a virtual honeypot instead of the damaged honeypot Honeycentre allots IP address of the damaged honeypot to the virtual honeypot. We may have an additional server for assigning these virtual honeypots figure1   Figure 1: Fault tolerance honeynet for securing egovernment  In figure 1, other network components like user stations, gateways, routers, and connections between agencies are not shown for avoiding complexities As mentioned in section 2.2, virtual honeypots are more lightweight than a high-interaction or low interaction honeypot. At a given time, we may have some damaged honeypots in the network, and we cannot fix all of them very soon. In the other hand we cannot assign some high or low interaction honeypot instead of all damaged honeypots to the network because maybe they are too many and we don't have required resources. So if we use virtual honeypots temporarily, we can solve this problem with just one additional server  
13 
15 
15 


  Figure 2: The flowchart of the framework in Honeycentre These virtual honeypots must act like the original honeypot. So each government agency replicates its minimum data into Honeycentre or additional server in every specified period of time. These data are minimum, because they should only help the system work, until the problem is solved and the real honeypot returns back to its logical position Such a situation enables the Honeycentre to create a real fault tolerant system which would be strong enough to deal with attacks without any interruption Figure 2 shows this process in the Honeycentre Honeycentre wants to gather data from all of the honeypots; for this purpose, Honeycentre checks responses from all of the honeypots. If a honeypot did not respond in a specific period of time, Honeycentre finds out a problem with that honeypot. So, it sends an error report to the administrator of the network, then allocates a virtual honeypot for that network and finally updates honeylist. Honeylist consists of addresses of all honeypots and their related web servers and administrators of their networks. If the honeypot responds, Honeycentre downloads data about hackers from the honeypot. Then it downloads required governmental data into additional server for running virtual honeypot, if needed When Honeycentre collected the data from all honeypots, processes them and converts these data to useful information. Then, it sends information to all of the web servers. This information consists of approaches and tools that hackers employ and their anti hack solutions With this framework, we can consider the interaction trade off, that mentioned above, effectively From one point of view, we utilize high interaction honeypots and from other point of view, we create boundaries to prevent hackers from doing more than their permission  4. Conclusion  Designing and implementing more effective approaches for securing E-government is an important issue, because, the governmental information is usually so sensitive. Furthermore, security has an important role in trust formation of citizens and their adoption of e-government. In this paper, one of the main differences of government and business networks is exploited: connectedness. This useful property used to form a network of honeypots. Furthermore, this honeynet is fault tolerance; so if some honeypots are damaged, the Honeycentre allots some virtual honeypots with minimum resources needed, and evicts the damaged honeypot from the network. So the proposed framework causes interaction with the hackers completely and simultaneously prevents them from damaging the network  Honeycentre downloads minimum governmental data required 
14 
16 
16 


  5. References  1 A B a rfa r   S M oha m m a di, “Honeypots: Intrusion deception ISSA Journal 2007, pp. 28-31   W h it e, “E-government and Cyber Security: The Role of Cyber Security exercises  Proceedings of the 39th Annual Hawaii International Conference on  System Sciences, HICSS '06 4, 2006    P. Reichs tädter Securing e-Government EGOV 2004 Springer-Verlag, 2004, pp. 336-341   N. Provos, T  Ho lz Virtual Honeypots: From Botnet Tracking to Intrusion Detection Addison Wesley Professional, 2008   H S h arif i, B. Za r e i, “An adaptiv e  approach f o r implementing E-government in I.R. Iran Journal of Government Information 30\(5-6\pp. 600-619   L. Spit z n er  Tracking Hackers Addison Wesley Professional, 2002   tibbe, “E-governm e n t se curity  Infosecurity Today  2\(3\-10   h e E-governm e nt handbook f o r developing countries Infodev 2002   i m m e r, B. von  Bredow E Gove rnm e nt Aspects  of Security on Different Layers Proceedings of the 12th International Workshop on Database and Expert Systems Applications \(DEXA’01 2001     
15 
17 
17 


 6 LOSSLESS COMPRESSION ALGORITHM CURRENT Z DOUBLE BUFFER Zx1x2 FPGA UNCOMPRESSED DATA IN EXTERNAL RAM THREE UPPER Y AND PREVIOUS Z PIXEL BUFFER\(S Zx1X4 LOCAL MEAN DIFFERENCE CURRENT Z PREVIOUS y and z ROWS WEIGHT MULTIPLIER DELTA ESTIMATE ENCODE PACKER LOSSLESS COMPRESSED DATA Figure 6 Block diagram of the FPGA implementa tion of Fast Lossless Compressor  DELTA block subtracts the value of current  pixel data from the Estimate to adjust the WE IGHT and also used as an input to the ENCODER ENCODER is made up of a Comparator, of length Z number of spectral bands\ up to 14 bits FIFO, a Look Up Table and miscellaneous circuitry. Output of the Encoder is used to determine the width of data to be packed PACKER includes Virtex IV distributed RAM and multiplexers. Distributed RAM is used for Look Up Table to adjust the compressed data into the final packed data word. Compressed data is packed and outputted as 32-bits words using the using Golomb   The basic concept of the data flow for the FPGA implementation \(Fig. 6\ is as follows. Initially raw imagery data of each spectral \(Z\row is streamed one row at a time into the \223CURRENT Z DOUBLE BUFFER\224. This buffer is configured as 2Z by up to 14 bits wide shift register. Two rows of length Z are stored in \223CURRENT Z DOUBLE BUFFER\224. New data is shifted in as pixel data is compressed Three upper spatial pixels Y-1,Y and Y+1 and previous spectral pixel Z are needed to comp ress the current pixel data. For the first pixel \(x=0, y=0 values are fed through the compressor and packed without compression. Current pixel data being compressed is also shifted out in parallel to the external RAM to produce an efficient pipeline. This data is inputted back to the \223THREE UPPER Y AND PREVIOUS Z\224 internal FPGA pixel buffers for subsequent pixel processing Compression of one pixel of the data happens once every FPGA clock cycle. Compressed data is fed to the PACKER module which packs the compressed data into 32 bits data words. Each 32 bits data word may contain several pixels of data. Also, a compressed pixel may fall into two 32-bit data words boundaries, which in turn will be decoded by the decompression algorithm accordi ngly. The implementation assumes an external fast link to bring the raw data to the FPGA such as a ring bus \(of up to 800 Mbits/sec 4  P ERFORMANCE AND BENCHMARKS  Our FPGA implementation was benchmarked on the Xilinx Virtex IV LX160 device and por ted to a Xilinx prototype board \(Figure 7\ implementation has a critical path of 29.5 nsec which dictated a clock speed of 33MHz The critical path delay is a nd-to-end measurement between the uncompressed input data and the output compressed data stream as shown in Figure 6. The implementation compresses one sample every clock cycle, which results in a speed of 33MSample/sec or 33 times faster than the software implementation running on a Pentium IV machine The implementation has a rather low device utilization of the Xilinx Virtex IV LX160 as shown in the table 1 making the total power consumption of the implementation about 1.27 watts 


 7  Figure 7  FPGA Development Board   Table 1  LX160 Device Utilization  Available Used Used BUFGs 32 2 6 DSP48s 96 6 6 FIFO16s 288 1 1 External IOBs 768 79 10 OLOGICs 960 21 2 RAMB16s 288 8 2 Slices 67584 3577 5  Our FPGA implementation is easily portable to other FPGA platforms and to an ASIC implementation.  It can also be scaled for faster processing 5  S UMMARY  We presented in this paper an FPGA implementation of a novel hyperspectral data compression algorithm, the JPL adaptive Fast Lossless comp ressor. The implementation targets the Xilinx Virtex IV FPGAs and provides an acceleration of at least 33 times the software implementation, making the use of this compressor practical for satellites and planet orbiting missions with hyperspectral instruments. Future development will provide multiple implementations and options to deploy various versions of the algorithm to accommodate data from different instrument types A CKNOWLEDGEMENTS  The work described in this publication was carried out at the Jet Propulsion Laborator y, California Institute of Technology, under a contract with the National Aeronautics and Space Administration. This work was funded by Air Force Research Laboratory th rough the grant, entitled \223Fast Lossless On-Board Hypersp ectral Data Compression\224 Special thanks to Randy Odle, program manager, who also supported this research at JPL, and to Ian Ferguson for his technical support to this research R EFERENCES   W. Campbell, N. M. Short 223Remote Sensing Tutorial\224, 2004 http://www.fas.org/irp/imin t/docs/rst/Sect13/Sect13_9.html   J. Venbrux, J. Ga mbles, D. Wiseman, G. Zweigle, W. H Miller, and P.-S. Yeh, \223AVLSI Chip Set Development for Lossless Data Compression,\224 Ninth AIAA Computing in Aerospace Conference, San Diego, California, October 19\22621 1993  Lossle ss Da ta Compre ssion Re c o mme nda tion for space data system standard s vol. 121.0-B-1: CCSDS, 1997  http://public.ccsds.org   M. Klimesh, \223Low-Compl exity Lossless Compression of Hyperspectral Imagery via Adaptive Filtering,\224 The Interplanetary Network Progr ess Report, vol. 42-163, Jet Propulsion Laboratory, Pasa dena, California, pp.1\22610 November 15, 2005   A Gersho 223 A daptive filtering with binary reinforcem ent\224 IEEE Transactions on Information Theory IT-30\(2 March 1984   B Widrow, J. R. Glover, J M. McCool, J. Kaunitz, C. S Williams, R. C. Goodlin, J. R. Zeidler, R. H. Hearn, and E Dong. \223Adaptive Noise Cancelling: Principles and Applications\224 The Proceedings of the IEEE 63\(12 1716, December 1975  F  Rizzo, B. Carpentieri, G. M o tta, and J  A. S t orer. \223 L owcomplexity lossless compression of hyperspectral imagery via linear prediction\224 IEEE Signal Processing Letters 12\(2 141, February 2005  B. Aiazzi, L. Alparone, and S  Baronti 223 N ear-los s l es s  compression of 3-D optical data\224 IEEE Transactions on Geoscience and Remote Sensing 39\(11 2001  N Lin X Nie and R Unbehauen, \223Two-Dimensional LMS Adaptive Filter Incorporating a Local-Mean Estimator for Image Processing,\224 IEEE Transactions on Circuits and Systems\227II: Analog and Digital Signal Processing vol. 40, no 7, pp. 417\226428, July 1993  R.G. Gallager and D.C. Van Voorhis. \223Optimal source codes for geometrically distributed integer alphabets\224 IEEE Transactions on Information Theory IT-21 \(2 March 1975  Kiely  N Aranki M Klimesh H Xie  Hy perspectral Data Compression based on the Three Dimensional Wavelet Transform," NASA New Technology Report NPO-42835  Kiely  M Klimesh H  Xie, N. Aranki, "Context Modeler for Compression of Wavelet-Tran sformed Hyperspectral Data NASA New Technology Report NPO-43239  Kiely  M Klimesh H Xie N Aranki  ICER-3D Hyperspectral Data Compre ssion Software," NASA New Technology Report NPO-43238  N. Aranki, C. Villalpando J. Namkung, A. Kiely, M Klimesh, H. Xie, "Hyperspectral Data Compression on Reconfigurable Platforms NASA New Technology Report NPO-42834  Yu T Vladimirova X Wu M N Sweeting 223A New High-Level Reconfigurable Lossless Image Compression System for Space Applications\224, In NASA/ESA Conference on Adaptive Hardware and System s, 2008. AHS 2008. 22-25 June 2008, pp 183-190. IEEE Computer Society  J.L. Nunez-Yanez; X. Chen N. Canagarajah; R. Vitulli 223Statistical Lossless Compression of Space Imagery and General Data in a Reconfigurable Architecture\224 In NASA/ESA 


 8 Conference on Adaptive Hardware and Systems, 2008. AHS 08. 22-25 June 2008, pp 172-177. IEEE Computer Society  J L Nunez-Yanez V A Chouliaras V A 223 A configurable statistical lossless compression core based on variable order Markov modeling and arithmetic coding\224 In IEEE Transactions on Computers. Volume 54, Issue 11, Nov. 2005 pp.1345 \226 1359  Pen-Shu Yeh, P. Armbruster A. Kiely, B. Masschelein, G Moury, C. Schaefer, C. Thiebaut, \223The New CCSDS Image Compression Recommendation\224, In IEEE Aerospace Conference 2005, 5-12 March 2005 pp.4138 \226 4145. IEEE  G.W. Donohoe, D.M. Buehler K.J. Hass, W Walker, Y. PenShu, \223Field Programmable Pro cessor Array: Reconfigurable Computing for Space\224, IEEE Aerospace Conference 2007, 3-10 March 2007, pp:1 \226 6. IEEE  PS Yeh, J Venbrux, \223A High Performance Image Data Compression Technique for Space Applications\224, In NASA Earth Science Technology Conference, 2003   J.L. Nunez, S. Jones. \223 Gbit/s lossless data compression hardware\224 In IEEE Transactions on Very Large Scale Integration \(VLSI\stems, Vo lume: 11, Issue: 3, pp. 499 510, June 2003  ALDC1-40S-M, Data Sheet, IBM Corporation, IBM Microelectronics Division, New York, 1994   AHA3580 22380 Mby t es/s ALDC Data Compression Coprocessor IC\224, Advanced Hardware Architectures Inc Pullman, WA, 1997 http://www.aha.com/tech.php   AHA3211 \22340 Mby t es/s DCLZ Data Compression Coprocessor IC\224, Advanced Hardware Architectures Inc Pullman, WA, 1997 http://www.aha.com/tech.php   9630 \223300 Mby t es/s Data Compression Processor\224 Hi/fn Inc Los Gatos, CA, 1999 http://www.hifn.com  B IOGRAPHY   Nazeeh Aranki received the BSEE MSEE and Ph.D. in Electrical Engineering from the Caltech and USC Nazeeh has 25 years of experience in design and implementation of digital and FPGA based systems. Since he joined JPL in 1994, his research interests have included reconfigurable hardware, digital signal and image processing, data compression, parallel processing, evolvable hardware, and neural networks. Nazeeh developed algorithms for compression of hyperspectral data and their implementations on reconfigurable platforms. He was awarded a patent and the NASA Space Act award for his contribution in the development of an FPGA-based neuroprocessor for automotive applications in control and diagnostics. He also served as the principal investigator and task Manager on a number of NASA,  DARPA and AFRL projects related to data compression and power aware computing and communications. Nazeeh is currently a senior member of the engineering and research team of the Avionics Equipment Section at JPL  Alireza Bakhshi is technical expert in FPGA/ASIC and high speed Digital circuit design for real-time DSP application on FPGA.  In addition Alireza has twenty years of experience in embedded applications, Digital circuits and Systems design in Space Radiation Hardened, Airport systems and Commercial avionics environments. He has contributed to multiple NASA missions as lead of the digital electronics such as the Microwave Limb Sounder \(MLS\, Mars Exploration Rover \(MER\, Ocean Surface Topography Mission \(OSTM\, Mars Science Laboratory \(MSL\ flight projects and technology projects such as Ultra Long Life ULL and, Operation of FPGAs in extreme low temperatures. He is president and CEO of B&A Engineering Inc Didier Keymeulen received the BSEE MSEE and Ph.D. in Electrical Engineering and Computer Science from the Free University of Brussels, Belgium in 1994. In 1996 he joined the computer science division of the Japanese National Electrotechnical Laboratory as senior researcher. Currently he is principal member of the technical staff of JPL in the Bio-Inspired Technologies Group. At JPL, he is responsible for DoD and NASA applications on evolvable hardware for adaptive computing that leads to the development of fault-tolerant electronics and autonomous and adaptive sensor technology. He participated also as test electronics lead, to Tunable Laser Spectrum instrument on Mars Science Laboratory. He served as the chair, cochair, and program-chair of the NASA/ESA Conference on Adaptive Hardware. Didier is a member of the IEEE Matthew Klimesh received B.S.E M.S.E., and Ph.D. degrees, all in electrical engineering from the University of Michigan in Ann Arbor, in 1989, 1990, and 1995, respectively.  He spent one year as a research fellow postdoc\ at Michigan. Since 1996 he has been with the Information Processing Group at Caltech's Jet Propulsion Laboratory, working primarily on research and development of data compression algorithms for space applications.  His research interests include source coding data compression, network coding, rate-distortion theory channel coding, probability, and discrete mathematics 


  9 Italy, in 2008. In 2002 she joined the Istituto per il Rilevamento Elettromagnetico dell\222Ambiente \(IREA Institute of the Italian National Research Council \(CNR Napoli, where she currently holds a Researcher Position She was a Visiting Research in 2004 at the German Aerospace Centre \(DLR\ and in 2007 at the Rosenstiel School of Marine and Atmospheric Science, Division of Marine Geology and Geophysics, University of Miami USA\. Her research interests concern the differential SAR interferometry data processing and applications for the monitoring of surface displacements, such as those produced by subsidence, volcano activity and earthquakes   


5 M  G a e dke  M. N u s s ba um e r a n d E. T o nk in  W e b Co m p o s i tio n  Service Linking System: Supporting development, federation and evolution of service-oriented Web applications  3 rd Int. Workshop on Web-oriented Software Technology \(IWWOST 2003\, 2003 6 I T M a n a g em en t an d W e b E n gin eeri n g R e s e a r ch G r ou p  MWRG\, "WebComposition Service Linking System http://mwrg.tm.uni-karlsruhe.de/wsls 02-10-2008 7 R F i e l ding  A r c hi te ct ur al S t y l e s  an d the D e s i g n o f N e tw o r kbased Software Architectures", University of California, Irvine 2000 8 L  Ric h ar d s o n  an d S  R u by RES T f u l W e b S e r v ice s  O  Re il ly  2007 9 A  H e il and M  G a e dke  W e b Co m p o s it io n  D G S  S uppo r t ing  Web2.0 Developments With Data Grids  IEEE International Conference on Web Services \(ICWS 2008  Beijing, China, 2008   C   M  M a c K en zi e K   L a s k e y  F   M c C a b e  and R  M e t z   Reference Model for Service Oriented Architecture 1.0 http://www.oasis-open.org/committees/soa-rm   T  B e r n er s Lee Un i v er s a l R e s o u r c e  I d en t i f i e r s in W W W    http://www.ietf.org/rfc/rfc1630.txt 11-24-2007-2007  T  B e r n er s Lee M et a d at a A r c h it ec t u r e   http://www.w3.org/DesignIssues/Metadata.html 05-31-2008 13 J a p a n El e c tr o n i c s  an d I n f o r m atio n T e chno l o g y  I ndus tr ie s  Association, "Exchangeable image file format for digital still cameras: Exif Version 2.2", 2002 14 L  A ndr e s e n  D ubl i n  Co r e Me ta da ta El e m e n t S e t, V e r s io n 1.1: Reference Description http://dublincore.org/documents/dces  02-18-2008 15 H  K i l o v  F r o m s e m a ntic to O b j e cto r ie nte d D a ta Mo de l i ng    First international Conference on Systems Integration  Morristown NJ, USA, 1990, pp. 385-393 16 J  F u tr e l l e  H a r v e s ting RD F T r ipl e s    International Provenance and Annotation Workshop \(IPAW'06  Chicago, Il USA, 2006, pp. 64-72  V. T a n  P G r ot h  S   M i les  S  J i an g S. Mun r oe S T s a s ak ou  and L. Moreau, "Security Issues in a SOA-based Provenance System  International Provenance and Annotation Workshop IPAW'06  Chicago, Il, USA, 2006, pp. 203-21 18 J  G r e g o r io M. H a dl e y M. N o tt i n g h a m  an d D  O r c h ar d   URI Template http://tools.ietf.org/id/draft-gregorio-uritemplate03.txt 02-06-2008  T  B e r n er s Lee  L i n k e d Da ta   http://www.w3.org/DesignIssues/LinkedData.html 02-20-2008 20 D  Br ic kl ey and L  Mil l e r  F OA F V o cabul ar y S p e c if ic at io n 0.9 http://xmlns.com/foaf/spec/20070524.html 06-03-2008   37 s i gna ls L L C  B a c kp ac k    http://www.backpackit.com 0219-2008  A m a z on W e b Servi c e s  L L C   A m a zon Si m p le St ora ge Service Developer Guide http://docs.amazonwebservices.com/AmazonS3/2006-03-01 0603-2008  F  Sha n ah an  A m a z on  c om  M a s h u p s   B i rm in gha m  UK  W r o x  Press Ltd., 2007 24 H  K r aw c z y k M  Be l l a r e an d R Ca ne tt i H MA C K e y e dHashing for Message Authentication http://www.ietf.org/rfc/rfc2104.txt 06-03-2008 25 H  L o ckhar t  S  A n de r s e n S  J  B o hr e n Y  S v e r dl o v  M  Hondo, H. Maruyama, A. Nadalin, N. Nagaratnam, T. Boubez, K S. Morrison, C. Kaler, A. Nanda, D. Schmidt, D. Walters, H Wilson, L. Burch, D. Earl, S. Baja, and H. Prafullchandra, "Web Services Federation Language \(WS-Federation\", 2006 26 M  G a e dke  J  Me i n e c ke an d M N u s s b au m e r    A  Mo de l i ng  Approach to Federated Identity and Access Management  14 th  International World Wide Web Conference \(WWW'05  Chiba Japan, 2005, pp. 1156-1157 27 J   Me ine c ke a n d M  G a e dke  M o de l i ng F e de r a tio ns o f W e b Applications with WAM  Third Latin American Web Congress LA-WEB 2005  Buenos Aires, Argentina, 2005, pp. 23-31  J  M e i n eck e  M  N u s s b au m e r and  M  G a ed k e   B ui ldi n g Blocks for Identity Federations  Fifth International Conference on Web Engineering \(ICWE 2005  Sydney, Australia, 2005, pp. 203208 29 I T M anag e m e n t an d W e b E n g i ne e r ing Re se ar ch G r o up MWRG\, "Home of the IT-Management and Web Engineering Research Group http://mwrg.tm.uni-karlsruhe.de 03-06-2008  w e b e n g i n eeri n g org T h e W e b E n gi n e eri n g C o m m u n i t y Si t e  WebEngineering.org http://www.webengineering.org 06-032008  I n t e rn a t i o n a l Soc i et y for Web E ngi n eeri n g e V  I S W E    International Societe for Web Engineering e.V http://www.isweev.de 06-03-2008  A m a z on W e b Servi c e s  L L C   A m a zon Si m p leDB Deve lop e r Guide", 2008 33 P  C a str o  P r o je ct A s to r i a T h e  A r chite ct ur e Jo ur nal  pp. 1217, 2007 34  M N u s s ba um e r  E ntw i c k l ung  u n d E v o l utio n diensteorientierter Anwendungen im Web Engineering Universität Karlsruhe \(TH\, Karlsruhe, 2007 35  R. G e am bas u  C  C h e u ng A  Mo s h c h u k  S  D  G r ibbl e  a n d H. M. Levy, "Organizing and Sharing Distributed Personal WebService Data  15 th International World Wide Web Conference WWW 2008  Bejing, China, 2008, pp. 755-754  G oogl e I n c   Op en Soc i a l   http://code.google.com/apis/opensocial 06-03-2008  G oogl e I n c   Goog le Da t a A P I s    http://code.google.com/apis/gdata 02-17-2008  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


transform spectrometry,\224 A pplied Optics  vol 46 no 21 pp 4774\2264779 2007 B IOGRAPHY Dmitriy Bekker r eceived his M.S and B.S degrees in Computer Engineering from Rochester Institute of Technology in 2007 He has been at JPL as a summer student in 2006 and now is a full time employee since February 2008 in the Instrument Software and Science Data Systems section His areas of interest include FPGAs embedded systems digital signal processing and system architecture He has co-op and work experience at Draper Laboratory NASA Dryden Flight Research Center Syracuse Research Corporation and Brookhaven National Laboratory He is a member of IEEE Dr Jean-Francois Blavier 002 rst joined the JPL-MkIV Team in August 1985 as a contractor from Ball Aerospace He participated in the MkIV campaigns in McMurdo Antarctica ground-based and from Punta Arenas Chile NASA DC8 In late 1987 he started graduate work with Profs Delbouille and Dubois at the University of Li 036 ege Belgium His research tasks included installing the Fourier transform spectrometers at the International Scienti\002c Station of the Jungfraujoch Switzerland for atmospheric measurements and at the Institute of Astrophysics in Li 036 ege for laboratory measurements He was hired by JPL in August 1990 as MkIV cognizant engineer and participated in all the MkIV campaigns since then one DC-8 campaign 20 balloon campaigns Dr J.-F Blavier obtained his Ph.D in Physics from the University of Li 036 ege in July 1998 Dr Geoffrey Toon  after receiving his B.A degree in Physics at Oxford University in 1978 obtained a D Phil in Atmospheric Physics in 1984 also from Oxford University He then came to JPL as an NRC post-doctoral Researcher and worked on the assembly and testing of the JPL MkIV interferometer and on analysis of ATMOS Spacelab-3 data Since becoming a JPL employee in 1986 he has worked almost exclusively on the MkIV project becoming the Principal Investigator in 1988 This work has earned seven NASA Achievement Awards and has resulted in more than 100 peer-reviewed journal articles Dr Christian Servais 002 rst joined the Institute of Astrophysics at the University of Li 036 ege in 1982 designing a digital 002lter for a prototype Fourier transform infrared spectrometer installed at the high altitude international scienti\002c station of the Jungfraujoch Switzerland In April 1984 he moved to the chemistry department of the University of Li 036 ege and developed time-of-\003ight and Photoion-Photoelectron coincidence experiments for his PhD thesis that he obtained in September 1994 He then returned to the Institute of Astrophysics were he has been since overseeing all experimental developments at the Laboratory of Atmospheric and Solar Physics located at the Jungfraujoch He is now specially involved in the design of improved Fourier transform spectrometer acquisition chains and remotely controlled hardware adapted to harsh environmental conditions 11 


departments on average\ignificant differences were found regarding the age of the applications. The variables for the coverage of the products and processes were not included in this test because the overlap was computed using these two variables implying that there is a significant relation between the respective variables\his lends some support to proposition P2.4 stating that involvement of more users leads to greater overlap of applications. The proposition that older applications also exhibit a higher degree of overlap was not supported \(P1.4  A.2. Results from analyzing impacts of AA complexity  Impacts of interdependency-related AA complexity A Kruskal-Wallis test \(Table 4\ealed a statistically significant difference in operations cost as well as maintenance cost across the three different interdependency-groups of applications. The more interdependent group \(i.e. applications with 3-7 or with 8 or more interfaces\igher median of operations \(Md=119,000 and 363,000 EUR respectively\ and maintenance costs \(Md=326,000 and 506,000 EUR respectively\ than the less interdependent group \(fewer than 3 interfaces applications \(Md=52,000 EUR operations costs and 64,000 EUR maintenance costs\. This supports the proposition \(P3.1\ that more interdependent applications also incur higher IT \(operations and maintenance\ts  Impacts of diversity-related AA complexity   Regarding OS-related diversity, a Mann-Whitney U test \(Table 5\howed no significant difference between the operations costs of more \(Md=93,890 n=105\d less diverse applications \(Md=131,540 n=27\09.5, z=-1.174, p=.24. The same holds for maintenance costs \(Md=166,400; n=121 vs Md=116,900; n =31\782, z=-.43; p=.668 To measure DBMS-related diversity, a MannWhitney U test was conducted \(Table 5\d revealed no significance difference in operations costs of more Md=129,985; n=85\d less diverse applications Md=154,777; n=16\5, z=-.237, p=.813. The same holds for maintenance costs \(Md=210,500 n=98 vs. Md=245,700; n=19\36, z=-.704 p=.481. Hence, the proposition \(P3.2\ that diversityrelated AA complexity leads to higher IT costs is not supported  Impacts of deviation-related AA complexity   Regarding deviation from the standard OS, a MannWhitney U test \(Table 6\revealed no significant difference between the maintenance costs and operations costs for standard-compliant \(Md=83,581 n=94 for operations cost and Md=148,300; n=113 for maintenance cost\nd non-compliant applications Md=180,147; n=38 for operations cost and Md=166,400; n=39 for maintenance cost z=-1.921, p=.055 for operations cost and U=2116 z=-.371, p=.711 for maintenance cost Concerning deviation from the standard DBMS, a Mann-Whitney U test \(Table 6\ealed a significant difference between maintenance costs for standardcompliant \(Md=373,100; n=59\d non-standardcompliant applications \(Md=170,200; n=58 U=1303, z=-2.231, p=.026. It is remarkable that the non-compliant applications had lower maintenance costs than the compliant applications. The difference between operations costs for compliant Md=109,978; n=51\d non-compliant applications Md=180,147; n=50\s not significant, U=1196.5 z=-.533, p=.594 Thus, the proposition \(P3.3\at application that deviate from technology standards incur higher IT costs is not supported. In contrast, for DBMSstandard deviation, we observed significantly lower maintenance cost for non-compliant than for compliant applications  Impacts of overlap/redundancy-related AA complexity a Kruskal-Wallis test \(Table 7\ showed significant differences in operations costs across the applications with a low \(less than 34 overlaps Md=90,442; n=37\edium \(35-79 overlaps Md=55,770; n=56\ and high level of overlap/redundancy \(more than 80 overlaps Md=129,985; n=61 6.862, p=.032. It is striking to see that the applications with medium overlaps have a lower median operations cost than those with a low or high-level of overlap, implying a non-linear U-shape relation between overlap and operations cost. Interestingly, the same holds true for maintenance cost. Applications with a low degree of overlap exhibited a median maintenance cost of 96,600 \(n=59\, those with a medium level of overlap incurred a median of 81,300 \(n=58\d highly overlapping applications a median of 248,700 \(n=67 9.791, p=.007. Hence, the proposition \(P3.4\at applications with a greater degree of overlap also exhibit higher IT costs is not supported  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 12 


Interdependency Number of interfaces \(gp3_y4_sum_intf  2 22 2 22 Df 047 000 000 016 000 000 Asymp. Sig 6.134 22.298 20.875 8.331 17.018 18.917 N Median 46 45 43 46 27 37 41 41 41 41 36 38 2 intf 8 intf 1.0000 2.2000 1.0000 1.0000 52.3020 64.4000 2.0000 7.8000 4.0000 2.0000 363.9885 506.3500 2 intf 8 intf Mean rank 55.89 47.03 44.13 56.13 33.67 37.77 2 intf 73.46 83.40 76.61 76.21 60.89 68.89 8 intf 40 39 33 40 30 34 3 7 intf 1.0000 3.2000 2.0000 1.0000 119.3940 326.2000 3 7 intf 63.63 59.97 56.50 60.54 42.33 58.22 3 7 intf  Business requirements Causes of complexity Impacts of complexity  No. of IB products covered y24_#_IB_ bankprod Application age y14_age No. of user departments y19_#_ user_dpts No. of IB process covered \(y26_ IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost 2  Table 4: Results of Kruskal-Wallis test for causes and impacts of interdependency-related AA complexity    Diversity Number of OS/DBMS used by an application Operating systems \(gp2_y7a_OS DBMS \(gp2_y8a_DBMS 2,726.500 18,302.500 1.503 133 1,087.500 1,318.500 1.362 173 3,308.000 902 367 543.000 7,446.000 3.925 000 2,642.000 2,536.000 3,202.000 855 392 757.500 7,198.500 2.187 029 2,884.500 18,460.500 965 335 1,216.500 1,447.500 583 560 1,209.500 6,774.500 1,174 240 654.500 790.500 237 813 1,782.000 9,163.000 430 668 836.000 5,687.000 704 481 Wilcoxon W Z Asymp. Sig N Median Mean rank Mann-Whitney U Wilcoxon W Z Asymp. Sig Mann-Whitney U 21 1.0000 125 1.0000 75.30 62.79 20 8.0500 117 2.2000 63.64 100.35 19 3.0000 113 1.0000 63.70 83.13 21 1.0000 125 1.0000 74.27 68.93 16 154.7770 85 129.9850 51.30 49.41 19 245.7000 98 210.5000 58.03 64.00 N Median 1 DBMS 2 DBMS 1 DBMS 2 DBMS Mean rank 1 DBMS 2 DBMS Data not shown as no significance found  Business requirements Causes of complexity Impacts of complexity  No. of IB products covered \(y24_#_ IB_bankprod Application age y14_age No. of user departments y19_#_user_dpts No. of IB process covered \(y26_#_ IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost  Table 5: Results of Mann-Whitney test for causes and impacts of diversity-related AA complexity  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 13 


 Deviation degree of deviation from standard OS/DBMS Operating systems \(gp2_y7b_OS_Dev DBMS \(gp2_y8b_DBMS_Dev 2,780.000 16,146.000 3.681 000 163 49 1.0000 2.0000 99.06 131.27 2,611.000 5,312.000 227 820 73 1.0000 73 1.0000 72.77 74.23 3,970.500 2.107 035 151 47 3.2000 2.2000 104.18 84.48 2,102.000 4,587.000 1.074 283 70 2.2000 67 3.5000 72.63 2,842.500 65.53 2,902.000 4,030.000 1.509 131 143 47 2.0000 1.0000 98.71 85.74 1,551.500 3,829.500 3.041 002 67 1.0000 65 3.0000 76.13 57.16 3,103.500 16,469.500 2.698 007 163 49 1.0000 2.0000 101.04 124.66 2,610.000 5,311.000 232 816 73 1.0000 73 1.0000 72.75 74.25 1,404.000 5,869.000 1.921 055 94 38 83.5815 180.1470 62.44 76.55 1,196.500 2,522.500 533 594 50 180.1470 51 109.9780 49.46 52.57 2,116.000 8,557.000 371 711 113 39 148.3000 166.4000 75.73 78.74 1,303.000 3,014.000 2.231 026 58 170.2000 59 373.1000 65.92 51.97  Wilcoxon W Z Asymp. Sig N Median No deviation \(1.0 Deviation 1.1 No deviation \(1.0 Deviation 1.1 Mean rank Mann-Whitney U No deviation \(1.0 Deviation 1.1 Wilcoxon W Z Asymp. Sig N Median No deviation \(1.0 Deviation \(>1.0 No deviation \(1.0 Deviation \(>1.0 Mean rank Mann-Whitney U No deviation \(1.0 Deviation \(>1.0  Business requirements Causes of complexity Impacts of complexity  No. of IB products covered \(y24_#_ IB_bankprod Application age y14_age No. of user departments y19_#_user_dpts No. of IB process covered \(y26_#_ IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost  Table 6: Results of Mann-Whitney test for cause s and impacts of deviation-related AA complexity  Overlap/redundancy \(gp3_overlap_count 22 22 Df 216 001 032 007 Asymp. Sig 3.066 13.139 6.862 9.791 2 N Median 90 81 37 59 79 78 61 67 34 80 2.2000 1.0000 90.4420 96.6000 2.6000 2.5000 129.9850 248.7000 34 80 Mean rank 129.29 113.80 82.76 87.25 34 137.18 144.50 85.66 108.10 80 86 85 56 58 35 79 2.2000 1.0000 55.7705 81.3000 35 79 118.22 110.61 65.14 79.82 35 79  Not applicable Not applicable Business requirements Causes of complexity Impacts of complexity  No. of IB products covered \(y24_ _IB_bankprod Application age y14_age No. of user departments y19_#_ user_dpts No. of IB process covered \(y26_ _IB_bankproc Operations cost \(y36_ ops_cost Maintenance cost \(y37_ Maint_cost  Table 7: Results of Kruskal-Wallis test for causes and impacts of overlap-/redundancy-related AA complexity Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 14 


  15 R EFERENCES    http://www.w3.org/XML/Schema   eb Orchestration with BPEL\224 http://www.idealliance.org/pa pers/dx_xml03 papers/0406-01/04-06-01.html  Hi bernat e hom e page www.hibernate.org   Al l a rd, Dan and Hut c herson, Joe, \223C om m uni cat i ons Across Complex Space Networks\224, IEEE Aerospace Conference, March 1-8, 2008  W e b Servi ce Defi ni t i on Language http://www.w3.org/TR/wsdl   B a uer, C h ri st i a n and Ki ng Javi n Java Persi s t e nce for Hibernate, New York: Manning Publications, 2007 7] \223Software Agents An Overview\224 http://www.sce.carleton.ca/netm anage/docs/AgentsOverview ao.html  e thodology.org  http://www.riaspot.com artic les/entry/What-is-Ajax  http://www.json.org 11 h ttp to m cat.ap ach e.o r g   12] http://java.sun com/products/servlet  http://www.w3.org/Sty le/CSS    B IOGRAPHY  Dan Allard has worked as a software engineer at the Jet Propulsion Laboratory for the past 17 years.   He currently leads the development of core JPL accountability systems applications and infrastructure Other recent work includes the development of a message-based ground data system for the Mars Science Laboratory as well as research and development of ontologybased distributed communications     Dr. Charles D \(Chad\ards, Jr received his A.B degree in Physics from Princeton University in 1979 and his Ph.D. in Physics from the Calif ornia Institute of Technology in 1984.  Since then he has worked at NASA\222s Jet Propulsion Laboratory, where he currently serves as Manager of the Mars Network Office and as Chief Telecommunications Engineer for the Mars Exploration Program, leading the development of a dedicated orbiting infrastructure at Mars providing essential telecommunications and navi gation capabilities in support of Mars exploration.  Prior to that he managed the Telecommunications and Mission Operations Technology Office, overseeing a broad program of research and technology development in support of NASA\222s unique capabilities in deep space communications and mission operations.  Earlier in his career, Dr. Edwards worked in the Tracking Systems and Applications section at JPL where he carried out research on novel new radio tracking techniques in support of deep space navigation, planetary science, and radio astronomy  


  16  


Thank you Questions 


 18  Astronautical Congress Valencia, 2006 27  Bu reau  In tern atio n a l d e s Po ids et Mesures. \(2 008  August\SI Base Units. [On http://www.bipm.org/en/si/base_units   B IOGRAPHY  Author, Karl Strauss, has been employed by the Jet Propulsion Laboratory for over 22 years.  He has been in the Avionics Section from day One.  He is considered JPL\222s memory technology expert with projects ranging from hand-woven core memory \(for another employer\o high capacity solid state designs.  He managed the development of NASA\222s first Solid State Recorder, a DRAM-based 2 Gb design currently in use by the Cassini mission to Satu rn and the Chandra X-Ray observatory in Earth Orbit.  Karl was the founder, and seven-time chair of the IEEE NonVolatile Memory Technology Symposium, NVMTS, deciding that the various symposia conducted until then were too focused on one technology.  Karl is a Senior IEEE member and is active in the Nuclear and Plasma Scie nce Society, the Electron Device Society and the Aerospace Electronic Systems Society Karl is also an active member of SAE Karl thanks his wonderful wife of 28 years, Janet, for raising a spectacular family: three sons, Justin, Jeremy Jonathan.  Karl\222s passion is trains and is developing a model railroad based upon a four-day rail journey across Australia\222s Northern Outback   


 19 Bollobás, B. 2001. Random Graphs. Cambridge University Press; 2nd edition. 500pp  Cawley, G. C., B. L. C. Talbot, G. J. Janacek, and M. W Peck. 2006. Sparse Bayesian Ke rnel Survival Analysis for Modeling the Growth Domain of Microbial Pathogens  Chiang C. L. 1960. A stochastic study of life tables and its applications: I. Probability distribution of the biometric functions. Biometrics, 16:618-635  Cox,  D. R. 1972. Regression models and life tables J. R Stat. Soc. Ser. B 34:184-220  Cox, D. R. 1975.   Partial likelihood Biometrika 62:269276  Cox, D. R. & D. Oakes. 1984 Analysis of Survival Data  Chapman & Hall. London  Cressie, N. A. 1993 Statistics for Spatial Data John Wiley Sons. 900pp  Duchesne, T. 2005. Regression models for reliability given the usage accumulation history. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty Y. Armijo. pp.29-40. World Scientific, New Jersey  Eleuteri, A., R. Tagliaferri, L. Milano, G. Sansone, D D'Agostino, S. De Placido,  M. Laurentiis. 2003.  Survival analysis and neural networks. Proceedings of the International Joint Conference on Neural Networks, Vol. 4 20-24 July 2003 Page\(s\:2631 - 2636  Ellison, E., L. Linger, and M Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013, 1997  Fleming, T. R. & D. P. Harrington. 1991. Counting process and survival analysis. John Wiley & Sons. 429pp  Graver, J. and M. Sobel 2005. You may rely on the Reliability Polynomial for much more than you might think Communications in Statistics: Theory and Methods  34\(6\1411-1422  Graves, T. and M. Hamada. 2005. Bayesian methods for assessing system reliability: models and computation. In Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson, et al. pp.41-53  Grimmett, G. 2006 The Random-Cluster Model Springer  Grimmett, G. 1999 Percolation Springer  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis.  Springer. 481pp  Jin Z. 2005. Non-proportional semi-parametric regression models for censored data. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.279-292 World Scientific  Kalbfleisch, J. D. & R. L. Prentice. 1980 The Statistical Analysis of Failure Time Data John Wiley & Sons.  New York. 1980  Kalbfleisch, J. D. &  R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data.  Wiley-InterScience, 2nd ed 462pp  Lisboa, P. J. G. and H. Wong. 2001. Are neural networks best used to help logistic regression? Proceedings of International Joint Conference on Neural Networks, IJCNN 01. Volume 4, 15-19,  July 2001. Page\(s\:2472 - 2477 vol.4  Kauffman, R. J. and B. Wang. 2002. Duration in the Digital Economy. Proceedings of th e 36th Hawaii International Conference on System Sciences \(HICSS’03\ Jan 2003  Kaplan, E. L. & P.  Meier.  1958.  Nonparametric estimation from incomplete observations J. Amer. Statist. Assoc  53:457-481  Klein, J. P. and P. K. Goel 1992. Survival Analysis: State of the Art.  Kluwer Academic Publishes. 450pp  Klein, J. P. and  M. L Moeschberger. 20 03. Survival analysis techniques for ce nsored and truncated data Springer  Krings, A. and Z. S. Ma. 2006.  "Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks MILCOM 2006, Military Communications Conference, 2325 October, 7 pages, 2006  Krings, A. W. 2008.  Survivable Systems.  in Information Assurance: Dependability and Security in Networked Systems Yi Qian, James Joshi, David Tipper, and Prashant Krishnamurthy, Morgan Kaufmann Publishers. \(in press  Lawless, J. F. 1982. Statistical models and methods for lifetime data.  John Wiley & Sons. 579pp  Lawless, J. F. 2003. Statistical models and methods for lifetime data.  John Wiley & Sons. 2nd ed. 630pp  Li, M. and P. Vitanyi. 1997. Introduction to  Kolmogorov Complexity and Its Applications. 2nd ed, Springer  Ma, Z. S. 1997.  Survival analysis and demography of Russian wheat aphid populations.  Ph.D dissertation, 307pp University of Idaho Moscow, Idaho, USA 


 20 Ma, Z. S., and E. J. Bechinski. 2008.  Developmental and Phenological Modeling of Russian Wheat Aphid Annals of Entomological Soc. Am In press  Ma, Z. S. and A. W. Krings. 2008a. The Competing Risks Analysis Approach to Reliability Survivability, and Prognostics and Health Management.  The 2008 IEEEAIAA AeroSpace Conference. BigSky, Montana, March 18, 2008. \(In Press, in the same volume  Ma, Z. S. and A. W. Krings 2008b. Multivariate Survival Analysis \(I\e Shared Frailty Approaches to Reliability and Dependence Modeling. The 2008 IEEE-AIAA AeroSpace Conference. BigSky Montana, March 1-8, 2008 In Press, in the same volume  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(II\ Multi-State Models in Biomedicine and Engineering Reliability. 2008 IEEE International Conference on Biomedical Engineering and Informatics BMEI 2008\27th-30th, 2008 Accepted   Mani, R., J. Drew, A. Betz, P. Datta. 1999. Statistics and Data Mining Techniques for Lifetime Value Modeling ACM Conf. on Knowledge Discovery and Data Mining  Mazzuchi, T. A., R Soyer., and R. V Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Meeker, W. Q. and L. A. Escobar. 1998. Statistical Methods for Reliability Data. Wiley-Interscience  Munson, J. C. 2003. Software Engineering Measurement Auerbach Publications  Nelson, W. 1969. Hazard plotting for incomplete failure data J. Qual. Tech 1:27-52  Nakagawa, T. 2006.  Shock and Damage Models in Reliability Theory. Springer  Osborn, B. 2005. Leveraging remote diagnostics data for predictive maintenance.   In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp. 353-363  Pena, E. A. and E. H. Slate. 2005. Dynamic modeling in reliability and survival analysis. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.55-71  Reineke, D. M., E. A. Pohl, and W. P. Murdock. 1998 Survival analysis and maintenance policies for a series system, with highly censore d data.  1998 Proceedings Annual Reliability and Maintainability Symposium. pp 182-188  Schabenberger, O. and C. A. Gotway. 2005. Statistical Methods for Spatial Data Analysis.  Chapman & Hall/CRC  Severini, T. A. 2000. Likelihood methods in statistics Oxford University Press  Shooman, M. L. 2002. Reliability of Computer Systems and Networks: Fault Tolerance, Analysis and Design. John Wiley and Sons. 551pp  Stillman, R. H. and M. S. Mack isack, B. Sharp, and C. Lee 1995. Case studies in survival analysis of overhead line components. IEE Conferen ce of the Reliability and Distribution Equipment. March 29-31, 1995. Conference Publication No. 406. pp210-215  Therneau, T. and P. Grambsch. 2000 Modeling Survival Data: Extending the Cox Model Springer  Wilson, A.  N. Limnios, S Kelly-McNulty, Y. Armijo 2005. Modern Statistical and Mathematical Methods in Reliability. World Scientific, New Jersey  Xie, M. 1991. Software Reliability Modeling. World Scientific Press    B IOGRAPHY   Zhanshan \(Sam\ Ma holds a Ph.D. in Entomology and is a Ph.D. candidate in Computer Science at the University of Idaho. He has published approximately 30 journal and 30 conference papers, mainly in the former field.  Prior to his recent return to academia, he worked as senior network/software engineers in software industry.  His current research interests include reliability and survivability of wireless sensor networks, fault tolerance survival analysis, evolutionary game theory, evolutionary computation and bioinformatics  Axel W. Krings is a professor of Computer Science at the University of Idaho.  He received his Ph.D. \(1993\ and M.S 1991\ degrees in Computer Science from the University of Nebraska - Lincoln, and his M.S. \(1982\ in Electrical Engineering from the FH-Aachen, Germany.  Dr. Krings has published extensively in the area of Computer Network Survivability, Security, Fault-Tolerance and Realtime Scheduling. In 2004/2005 he was a visiting professor at the Institut d'Informatique et Mathématiques Appliquées de Grenoble, at the Institut National Polytechnique de Grenoble, France.  His work has been funded by DoE/INL DoT/NIATT, DoD/OST and NIST 



  1  A 320 Mbps Flexible Image Data Compressor for Space Applications   Paul Winterrowd 1 Chad Orbe 1 Jack Venbrux 1 Sterling Whitaker 1 Eric Cameron 1 Ronald  Nelson 1 Gary Maki 1 Dave Fisher 2 Pen-Shu Yeh 2 
 1 CAMBR/U. Idaho, address 721 Lochsa Street Ste. 8, Post Falls, Idaho 83854, USA, pwinter@cambr.uidaho.edu 
corbe@cambr.uidaho.edu, whitaker@cambr.uidaho.edu ecameron@cambr.uidaho.edu, ronels@cambr.uidaho.edu gmaki@cambr.uidaho.edu 
2 NASA/GSFC, Code 567, Greenbelt, MD 20771, USA david.y.fisher@nasa.gov, penshu.yeh@nasa.gov   Abstract 227 A 320 Mbps radiation-tolerant image data compression application specific integrated circuit \(ASIC chip set has been developed 12 The ASIC chip set implements the Consultativ e Committee for Space Data Systems \(CCSDS\mendation for Image Data Compression It is applicable to both near-Earth pushbroom 3 sensors as well as frame sensors used in exploration 
and deep space applications The compressor can process sensor data in both lossless and lossy compression modes  The compression chip set implements a discrete wavelet BPE Compression modes including on-the-fly reconfiguration can be easily configured onboard potentially offering capabilities requiring integration of intelligent processing with compression  The ASIC chip set designs are implemented in 0.25um CMOS utilizing radiation-hardness-by-design \(RHBD technique. The chip set has been verified both in functions and radiation characteristics and is being qualified for a NASA mission.  The measured power consumption at room 
temperature for the chip set is 0.17 watt/Msamples/sec with sample up to 16-bit Table of Contents 1  I NTRODUCTION 1  2  ASIC  D ESCRIPTION 1  3  ASIC  I MPLEMENTATION T ECHNOLOGY 3  4  
ASIC  T ESTING 4  5  C ONCLUSION 5  A CKNOWLEDGEMENT 5  R EFERENCES 5  B IOGRAPHY 5     1 978-1-4244-3888-4/10 25.00 \2512010 IEEE 
2 IEEEAC paper#1311 Version 2, Updated 2009:10:30 3 Push-broom sensor uses the sate llite along-track motion to sweep a onedimensional sensor array for 2-dimensional ground coverage 1  I NTRODUCTION  The CCSDS Image data compression recommendation  released in 2005 is a two-dimensional compression technique based on wavelet transform. Selection of the algorithm not only addresses good rate-distortion performance [2 m an d ates lim ited  p o w er consumption of less than 1 watt/Msamples/sec then as one of the requirements for consideration during the 
standardizati It shoul d be not ed t h at  t h e current state of space electronics will achieve much better performance. Other requirements that impact the hardware architecture include the capability to compress both framebased sensor data, as well as push-broom sensors and the input dynamic range from 4-bit to 16-bit A radiation-tolerant ASIC development that conforms to the recommendation and fulfills power consumption and pushbroom sensor requirement has been successfully completed In Section 2, we describe the ASIC development. The ASIC implementation technology is provided in Section 3 Section 4 describes a hardware test sub-system and performance based on the ASICs  
2  ASIC  D ESCRIPTION  A decision was made earlier in the ASIC development process to implement the two functional modules of the algorithm: the DWT and the BPE, in two separate ASICs This decision was necessary b ecause the available radiationhardness-by-design \(RHBD\echnology available at the time of project start is based on the 0.25\265 CMOS process which through our analysis will be too tight to implement both functional modules while maintaining a top throughput requirement of 20Msamples/sec  2.1 Discrete Wavelet Transform ASIC 


single stage 2-d DW of LL2 subband c d LH1 HL1 LL1 LH1 HH1 HL1 LH1 HH1 HL1   2  The CCSDS recommendation specifies two DWTs: An integer DWT and a floating DWT, the latter is referred to as float DWT in the recommendation. Both are 9-tap/7-tap filters to compute the low-pass output and the high-pass output. Each filter is referred to as a \2239/7\224 DWT. The difference is that the floating-point filter requires floatingpoint calculations which provide improved rate-distortion performance at low bit rates, while the integer filter allows lossless compression and requires no floating-point operations The specified DWT consists of 3 levels: the first level DWT is computed by first applying the one-dimensional DWT to the rows of the image, and then to the columns of the transformed image. Level 2 and level 3 DWTs  are applied to the low-pass horizontal / low-pass vertical sub-band output from the previous stage, producing the ten sub-band structure illustrated in Figure 1 To implement the 3-level 2-D DWT for a target rate of 20 Msamples/sec, external memory is utilized to store intermediate computation result. External memory is also used in the BPE processing stage, as illustrated in Figure 2  The DWT ASIC contains seven major blocks illustrated in Figure 3. The serial interface is used to configure the processing mode, the vertical/horizontal processor controls the read/write direction from/to external memory so that each of the DWT level in eith er horizontal or vertical direction can be computed in the MAC 4 module and the output module re-orders the DWT coefficients in the sequence appropriate for the BPE module  To fulfill the push-broom sensor input requirement, a specific feature was designed in the DWT ASIC to continuously process in-coming scan-lines without the need to form a frame or a tile from the input data. Thus DWT is calculated locally, until the end-of-image signal is pulsed   4 MAC: multiply-accumulate Input Data Coded Data DWT ASIC BPE ASIC SRAM SRAM Figure 2 \226 DWT and BPE with External Memory Modules To/From RAM Serial I/F BPE Data Data In Figure 3 \226 DWT ASIC Major Modules DWT FIFO Control Memory Interface MAC Vertical Horizontal Processors Serial I/F Output   HH2 HL2 LH2 HH1 LL2 HH2 HL2 HH3 HL3 LH2 LH3 LL3  Figure 1 Example of 3-Level Two-Dimensional DW T Decomposition of an Image \(from   T of original image single stage 2-d DWT of LL1 subband single stage 2-d DW T original image a 


  3  The DWT calculation will th en fold in the boundary condition according to [1] to complete the processing The output of the DWT is weight-shifted for the integer DWT by using the standard weights from or usersupplied weighting; it is rounded to the nearest integer for the float DWT. The ASIC orders the output of local DWT coefficients from all ten sub-bands into a 64-element block  illustrated in Figure 4 as the 64-colored sub-band components. Each local DWT block contains one DC component and 63 AC components.  These DWT blocks serve as input to the following BPE ASIC  The DWT ASIC currently supports image/scan-line width up to 8192 pixels. The minimum image size it can process is 32x32. Detailed DWT ASIC information is available in  2.2 Bit Plane Encoder ASIC  The BPE processes wavelet coefficients in groups of 64 local DWT coefficients formed into blocks. The BPE will process blocks in the order th ey are presented to the chip Several blocks are grouped into a segment which is the basic unit for computing compression ratio or quality desired by an application. T hus each segment is compressed independently of others  Major functional blocks of the BPE ASIC are illustrated in Figure 5.  The chip can be confi gured either by a serial or a parallel interface. Data from the DWT ASIC are presented to the BPE as 24-bit 2\222s complement data. The INIT module first calculates the number of binary bits required to represent AC coefficients in th e block and routes it with the DC component to the DCAC module. The 63 AC coefficients are sent to the DATA PROC module for bit plane encoding. Coded data are written to external RAM in specific locations which are later read-back by the READ module in sequences conformant to the recommendation\222s bit stream order and accordi ng to the desired compression rate or quality index. The DC coefficients are coded in the DC ENCODER module. Compressed bit stream is concatenated and output from the FIFO module Besides the compression function, another major function of the BPE ASIC is to provide users with the ability to control how compression is performed: based on desired compression rate entered as a number of coded output words, or as a quality index designated by a stopping point in the compression process at certain bit-plane or stages BPE also writes header information in the output stream such that decoding can be done based on the header information in the coded bit stream Header control in the BPE ASIC is sufficiently versatile to allow users to modify parameters specified in the Part 2 and Part 3 headers of the reco mmendation for every segment These include compressed output words, quality output point and even the segment size in terms of blocks. With these features on-the-fly compression mode reconfiguration can be executed for every segment, providing the most flexibility for future onboard applications. These applications may involve other onboard processing functions such as signature an alysis and feature extraction for data quality analysis, which can be used to control the compression output rate Several Part 4 header paramete rs can be re-configured for every image \(in frame-mode\thout having to re-set the BPE chip. These include DWT type, image bit depth number of segments in one image, image width, and usersupplied integer DWT weights Detailed BPE ASIC information is available in [5 3  ASIC  I MPLEMENTATION T ECHNOLOGY  The designed ASICs are implemented in a 0.25\265 CMOS process utilizing radiation-hard-by-design \(RHBD techniques developed at CAMBR/U. Idaho and elsewhere  Figure 4 \226 A local DWT block formed from the 64 shaded pixels taken from ten sub-bands \(from   To RAM From RAM Serial I/F Parallel I/F Coded Bit Stream Data Input Figure 5 \226 BPE ASIC Major Modules BPE INIT DATA PROC DCAC WRITE DATA READ DATA FIFO DC ENCODER 


  4  The memory cells utilized in the design are based on the SERT \(Single Event Resistant Topology\l As i t s  name implies, this cell is immune to single bit state changes and, due to internal redundancy, is able to return to its initial state after a single node upset In order to attenuate the eff ects of single event transients SETs\in the logic, the HDL was synthesized to a dual rail implementation.  This allows the memory cells to determine 0,0\ invalid values 0,1 1,0 For global signals where dua l rail redundancy would have been costly, such as the clock tree, the drivers were all sized sufficiently large so as to be immune to SET up to the targeted Linear-Energy-Transfer \(LET 5 onset threshold 4  ASIC  T ESTING  4.1 Test Setup A set of the fabricated ASIC s, packaged in a commercialgrade package has been implemented on a compression subsystem test board. To test the high-throughput rate at 20 Msamples/sec, a high-speed interface card from National Instrument \(NI\tilized to pass test data to and collect compressed data from the ASICs. Figure 6 shows the compression test board Test data used includes images provided by CCS at  different bit-depth and dimensions The collected compressed data was sent back to the lab computer via the high-speed interface card. It is then compared with software cr eated data for bit-by-bit comparison.  In addition, software decompression was performed to validate the complete chain of compression/decompression processing 4.2 ASIC Power Measurement The power consumption of each of the ASICs was first measured while sweeping the clock rate through the full operating frequency range.  At room temperature and  in the lab environment, both chips have tested successfully with more than 40% margin above the target rate of 20 Msamples/sec.  The total power consumption for both chips is measured at 0.17 watts/Msamples/sec, giving the power consumption at 20 Msamples/sec of 3.4 watts, well below the requirement established by the CCSDS compression working group 4.3 Compression Mode   5 LET expressed in MeV-cm 2 mg We have tested various modes including the following 1  lossless compression: The decompressed image is tested exactly the same as the original. The coded bit stream also compares exactly to the coded stream generated by software. This mode is tested using integer DWT 2  lossy compression:  differe nt compression rates and quality stopping point s are tested. The compressed bit stream comp ares exactly as the bit stream created by software. This mode has been tested with integer DWT so far 3  Push-broom mode: This was performed by repeating the input test images many times as if they were from a push-broom sensor, then terminating the processing by using either realtime reconfiguration of BPE parameters or pulsing one BPE control pin 4  Frame mode: This mode treats the test image as one single segment for BPE processing 5  Dynamic Reconfiguration: This tests performs onthe-fly reconfiguration of several BPE parameters The parameters that are allowed to be updated before the compressed bits for a segment is formatted for output include \(1\ze of the segment 2\pression qua lity output stopping point \(3\pression ratio expressed in compressed number of words \(4\output header type and \(5\put frequency In the test, a compression ratio is initially assigned. As the processing continues, desirable compression ratios for several segments of the BPE were re-configured during the processing without the need to re-set or stop the BPE processing. The compressed output was validated correctly by software simulation Dynamic reconfiguration of compression ratio during the compression process can be used in situations when rate allocation for an instrument needs to change in real time in a collaborated environment involving other instruments or changing bandwidth allocation The ASIC testing is still in progress as more scenarios are designed.  Results from all tests compare exactly to the bit stream created by software with bit-to-bit precision when integer DWT is used.  Testing with float DWT is on-going and expected to confirm the compression performance listed in [2 


  5   5  C ONCLUSION  A high-speed low-power flex ible space ready compression ASIC chip set was successfully developed at over 20 Msamples/sec.  The chip set implements the CCSDS Image Data Compression recommendation. The power consumption was measured at 0.17 watts/Msamples/sec The top speed of the ASIC chip set is currently limited by the access time of the external rad-hard SRAM modules.  It is expected the processing rate can be much increased with faster SRAMs The ASIC chip set has been tested in a compression test board in various configurations. This chip set is applicable to a variety of imaging instruments, and is suitable for pushbroom sensors requiring real-time processing of sensor data The ASIC chip set is fully immune to single-event-latchup and single-event-upset as validat ed by testing at the Texas A&M University\222s radiation test facility. This chip set is currently under qualification at Aerofl for a NASA mission A CKNOWLEDGEMENT  Portions of the research described in this paper were conducted by Penshu Yeh for the U. S. Government.  The support of the Space Communication and Navigation SCaN\office at the National Aeronautics and Space Administration is greatly appreciated R EFERENCES    Image Data Compression Recommendation for Space Data Systems Standards, CCSDS 122.0-B-1, Blue Book Issue 1. Washington D.C.: CCSDS, November, 2005 available from www.ccsds.org   Image Data Compression Information Report for Space Data Systems Standards, CCSDS 120.1-G-1, Green Book Issue 1. Washington D.C.: CCSDS,  June 2007, available from www.ccsds.org    Pen-Shu Yeh, Phi l i ppe Arm b rust er, Aaron Ki el y B a rt  Masschelein, Gilles Moury Christoph Schaefer, Carole Thiebaut, \223 The New CCSDS Image Data Compression Recommendation\223 Proc. of the IEEE 2005 Aerospace Conference Big Sky, Montana, March 2005  T Prelim inary Specification Version 0.6, available from CAMBR, 721 Lochsa Street Ste. 8, Post Falls, Idaho 83854  B P E Speci fi cat i on, avai l a bl e from  C A M B R  721 Lochsa Street Ste. 8, Post Falls, Idaho 83854  Paul W i nt errowd, C h ad Orbe, St erl i ng W h i t a ker Eri c  Cameron, Ronald Nelson, Gary Maki, Dave Fisher Penshu Yeh, \223A 320 Mbps Flexible Discrete Wavelet Transform Processor for Extreme Environments\224 Proc. of the IEEE 2010 Aerospace Conference Big Sky, Montana March, 2010  Q. Shi G. M a ki 223New Desi gn Techni ques for SEU Immune Circuits\224 Proc. of the 9 th Nasa Symposium on VLSI Design Pages 7.4.1-7.4.16, November 2000  Orderi ng i n form at i on for qual i fi e d DW T and B P E ASIC s joe.feeley@frontiernet.net B IOGRAPHY   Paul Winterrowd received his B.S.E.E degree from the University of Idaho Moscow in 1990.  He worked as a VLSI design engineer for Advanced Hardware Architectures from 1992 to 1998, for Hewlett-Packard from 1998 to 2004 and most recently at the Center for Advanced Microelectronics and Biomolecular Research from 2004 to present Chad Orbe received his B.S.E.E degree from the University of Idaho Moscow in 2001.  He worked internships at both Micron and Agilent He was a VLSI design engineer for Advanced Hardware Architectures before joining the staff of the Center Figure 6 \226 Compression Test Board 


  6  for Advanced Microelectronics and Biomolecular Research where he led the design of an image compression chip for space applications based on the bit plane encoding algorithm. He currently leads the development of a companion bit plane decoding chip Sterling R. Whitaker S'76M'77-SM'97\ received the B S.E.E. degree from Brigham Young University, Provo, UT, in 1977, and the M.S. and Ph.D degrees, both in electrical engineering from the University of Idaho, Moscow, in 1982 and 1988, respectively.  He is currently a Research Professor with the Center for Advanced Microelectronics and Biomolecular Research.  He was previously an Associate Professor at the University of New Mexico, Albuquerque His industrial experience includes American Microsystems Inc. \(1977-1985\ and AKM DesignTek \(1995-1997\.  His current research interest is in high-performance application-specific processors for the space environment He holds 13 U.S. patents, has published 95 papers, and has been a key contributor on 73 in tegrated circuit designs    Eric Cameron graduated from the University of New Mexico in 1994 with a Bachelor of Science in Computer Science with a minor in Mathematics He is currently employed with the Center for Advanced Microelectronics and Biomolecular Research at the University of Idaho as a research engineer and information systems administrator.  His main areas of interest include biosensor work, particularly at the device-computer interface computer systems security and data integrity, and computer modeling of custom integrated circuits Ron Nelson received his B.S.E.E and M.S.E.E. from the University of Idaho, Moscow in 1997 and 2000 respectively.  He has been a research engineer with the Center for Advanced Microelectronics and Biomolecular Research since 2003 and is working on electronic biosensor development and low power electronics for space applications.  His professional interests include power electronics, distribution, and power flow control, time domain electromagnetic simulations, and automated instrumentation design  Gary K. Maki S'63-M'69SM'02\ received the B.S.E.E degree from Michigan Technological University Houghton, and the M.S. and Ph.D degrees in electrical engineering from the University of Missouri, Rolla.  He is currently a professor emeritus in the Electrical and Computer Engineering Department at the University of Idaho, Moscow.  Before retiring he held the position of director for the Center for Advanced Microelectronis and Biomolecu lar Research for several years.  He held a similar position at the University of New Mexico, Albuquerque.  Current research interests range from high performance electronics to biomolecular electronic sensors.  He has served on boards with the Hewlett Packard Laboratories Science Advisory Board University Space Research Association Technology Board the NASA Data System Working Group and the USDA national nanotechnology grant se lection board.  He has authored in excess of 75 papers and holds 7 patents Dave Fisher has worked for NASA Goddard Space Flight Center since 1995. He has been developing high-speed digital subsystems in applications involving receiver telemetry processing as well as technology development projects for space communica tion.  He has developed and demonstrated over Gbps channel coding and over 430 Mbps band-width efficient modul ation subsystems utilizing ASICs designed by the CAMBR U Idaho. Most recently he has completed a 320 Mbps reconfigurable data compression test bed for testing the DWT and BPE ASICs Pen-Shu Yeh works for NASA\222s Goddard Space Flight Center. She has been leading the development of data compression and onboard processing technology for over twenty years at Goddard. She has supported various space missions in implementing data compression and currently represents GSFC to the Data Compression Working Group within CCSDS. Pen-Shu Yeh received a Ph.D in Electrical Engineering in 1981 from Stanford University after completing a BSEE at the National Taiwan University and a MSEE at the University of Washington in Seattle. Her research interests include signal processing, pattern recognition, computer vision and implementation using radiation-hard space electronics   


  7  T Prelim inary Specification Version 0.6, available from CAMBR, 721 Lochsa Street Ste. 8, Post Falls, Idaho 83854  Q. Shi G. M a ki 223New Desi gn Techni ques for SEU Immune Circuits\224 Proc. of the 9 th Nasa Symposium on VLSI Design Pages 7.4.1-7.4.16, November 2000 6 S. G. Mallat, \223A Th eo ry fo r Mu ltireso l u tio n Sig n al Decomposition: The Wavelet Representation,\224 IEEE Transactions on Pattern Analysis and Machine Intelligence vol. 11, no. 7, pp. 674--693, July 1989   JPEG2000: Image Compression Fundamentals Standards and Practice D. Taubman, M. Marcellin Kluwer Academic Publishers, 2002   A R  C a l d erbank, I Daubechi e s, W Swel dens, B L. Yeo 223Wavelet Transforms that Ma p Integers to Integers,\224 Appl. Comput. Harmon. Anal vol. 5, pp. 332\226369, July 1998  Joi n t Phot ographi c Expert s Group  ISO/IEC JTC 1/SC 29/WG 1 - Coding of Still Pictures \(SC 29/WG 1 Structure  http://www.jpeg.org  10] Alcatel Space Industries presentation information 2002  Saji d B a l o ch, Tughrul Arsl an, Adri an St oi ca R adi a t i on Hardened Coarse-Grain Rec onfigurable Architecture for Space Applications," ipdps, pp.189, 2007 IEEE International Parallel and Distributed Processing Symposium, 2007  See product spec for JPEG2000 vi deo codec http://www.analog.com  B IOGRAPHY   Paul Winterrowd received his B.S.E.E degree from the University of Idaho Moscow in 1990.  He worked as a VLSI design engineer for Advanced Hardware Architectures from 1992 to 1998, for Hewlett-Packard from 1998 to 2004 and most recently at the Center for Advanced Microelectronics and Biomolecular Research from 2004 to present Chad Orbe received his B.S.E.E degree from the University of Idaho Moscow in 2001.  He worked internships at both Micron and Agilent He was a VLSI design engineer for Advanced Hardware Architectures before joining the staff of the Center for Advanced Microelectronics and Biomolecular Research where he led the design of an image compression chip for space applications based on the bit plane encoding algorithm. He currently leads the development of a companion bit plane decoding chip Sterling R. Whitaker S'76M'77-SM'97\ received the B S.E.E. degree from Brigham Young University, Provo, UT, in 1977, and the M.S. and Ph.D degrees, both in electrical engineering from the University of Idaho, Moscow, in 1982 and 1988, respectively.  He is currently a Research Professor with the Center for Advanced Microelectronics and Biomolecular Research.  He was previously an Associate Professor at the University of New Mexico, Albuquerque His industrial experience includes American Microsystems Inc. \(1977-1985\ and AKM DesignTek \(1995-1997\.  His current research interest is in high-performance application-specific processors for the space environment He holds 13 U.S. patents, has published 95 papers, and has been a key contributor on 73 in tegrated circuit designs Eric Cameron graduated from the University of New Mexico in 1994 with a Bachelor of Science in Computer Science with a minor in Mathematics He is currently employed with the Center for Advanced Microelectronics and Biomolecular Research at the University of Idaho as a research engineer and information systems administrator.  His main areas of interest include biosensor work, particularly at the device-computer interface computer systems security and data integrity, and computer modeling of custom integrated circuits Ron Nelson received his B.S.E.E and M.S.E.E. from the University of Idaho, Moscow in 1997 and 2000 respectively.  He has been a research engineer with the Center for Advanced Microelectronics and Biomolecular Research since 2003 and is working on electronic biosensor development and low power electronics for space applications.  His professional interests include power electronics, distribution, and power flow control, time domain electromagnetic simulations, and automated instrumentation design  


  8 Gary K. Maki S'63-M'69SM'02\ received the B.S.E.E degree from Michigan Technological University Houghton, and the M.S. and Ph.D degrees in electrical engineering from the University of Missouri, Rolla.  He is currently a professor emeritus in the Electrical and Computer Engineering Department at the University of Idaho Moscow.  Before retiring he held the position of director for the Center for Advanced Microelectronis and Biomolecular Research for several years.  He held a similar position at the University of New Mexico, Albuquerque.  Current research interests range from high performance electronics to biomolecular electronic sensors.  He has served on boards with the Hewlett Packard Laboratories Science Advisory Board, University Space Research Association Technology Board, the NASA Data System Working Group and the USDA national nanotechnology grant selection board.  He has authored in excess of 75 papers and holds 7 patents Pen-Shu Yeh works for NASA\222s Goddard Space Flight Center. She has been leading the development of data compression and onboard processing technology for over twenty years at Goddard. She has supported various space missions in implementing data compression and currently represents GSFC to the Data Compression Working Group within CCSDS. Pen-Shu Yeh received a Ph.D in Electrical Engineering in 1981 from Stanford University after completing a BSEE at the National Taiwan University and a MSEE at the University of Washington in Seattle. Her research interests include signal processing, pattern recognition, computer vision and implementation using radiation-hard space electronics Dave Fisher has worked for NASA Goddard Space Flight Center since 1995. He has been developing high-speed digital subsystems in applications involving receiver telemetry processing as well as technology development projects for space communica tion.  He has developed and demonstrated over Gbps channel coding and over 430 Mbps band-width efficient modul ation subsystems utilizing ASICs designed by the CAMBR U Idaho. Most recently he has completed a 320 Mbps reconfigurable data compression test bed for testing the DWT and BPE ASICs   


memory module, creating a bottle-neck in the memory accesses Besides, both OpenMP and SMPSs require scheduling schemes that although conscious of the locality \(and this is somehow a quite static feature adapt to other sources of imbalance in the systems. More specific for SMPSs, increasing the threshold of number of tasks in the graph would enable to better exploit the temporal locality that appears in computations far away in the original source code Acknowledgments The authors acknowledge the financial support of the Comision Interministerial de Ciencia y Tecnologa \(CICYT Contract TIN2007-60625 research agreement References 1] cOMPunity. The community of OpenMP users researchers, tool developers and provider website http://www.compunity.org/, 2006 2] E. Ayguade  N. Copty, A. Duran, J. Hoeflinger, Y. Lin, and G. Zhang. A proposal for task parallelism in OpenMP. In Proceedings of the 3rd International Workshop on OpenMP June 2006 3] J.M. Perez, R.M. Badia, and J.Labarta. A dependencyaware task-based programming environment for multi-core architectures. In Proceedings of IEEE Cluster Computing 2008, 2008 4] E. Ayguade  A. Duran, J. Hoeflinger, F. Massaioli, and X. Teruel. An experimental evaluation of the new openmp tasking model. In Proceedings of the 20th International Workshop on Languages and Compilers for Parallel Computing 2007 5] J. M. Perez, P. Bellens, R. M. Badia, and J. Labarta. CellSs Programming the Cell/B.E. made easier. IBM Journal of Research and Development, 51\(5 6] M. Frigo, C. E. Leiserson, and K. H. Randall. The implementation of the cilk-5 multithreaded language. SIGPLAN Notices, 33\(5  223, 1998 7] M. Gonzalez, E. Ayguade  X. Martorell, and J. Labarta Exploiting pipelined executions in OpenMP. In Proceedings of the 32nd Annual International Conference on Parallel Processing, pages 153  160, Oct 2003 8] A. Duran, J.M. Perez, E. Ayguade, R.M. Badia, and J. Labarta. Extending the OpenMP tasking model to allow dependent tasks. In Proceedings of the 4th International Workshop on OpenMP, 2008 9] G. Juckeland, M.S. Muller, W.E. Nagel, and S Pflu. Accessing data on sgi altix: An experience with reality. In Proceedings of WMPI 2006, 2006 10] A. Kayi, E. Kornkven, T. El-Ghazawi, and G. Newby. Application performance tuning for clusters with ccnuma nodes In Computational Science and Engineering, 2008. CSE  08 11th IEEE International Conference on, pages 245  252, July 2008 11] R. Ferrer, M. Gonza  lez, F. Silla, X. Martorell, and E. Ayguade  Evaluation of memory performance on the cell be with the sarc programming model. In Proceedings of MEDEA workshop \(PACT 12] HPCS. The hpc challenge benchmark http://icl.cs.utk.edu/hpcc/index.html 13] Jesu  s Labarta, Sergi Girona, Vincent Pillet, Toni Cortes and Luis Gregoris. DiP: A parallel program development environment. In Proceedings of the 2nd International EuroPar Conference \(EuroPar 96 445 pre></body></html 


in preferences for a category of items. The selection of segment is done by selecting highly rated popular items with similar characteristics. Segmented attack is focused on those users who have highly rated majority of the selected items present in the segment For example, group of users who have highly rated at least any three of the five most popular animation movies form a segment of users interested in animation movies. An attacker with intent to promote a new animation movie will find it beneficial to mount a segmented attack against a segment of user interested in animation movies In our work, we study the effect of our filler item strategies in further improving the effectiveness of insegment attacks against both user-based and itembased attacks. In segment attack, filler items are randomly selected and assigned the minimum value in the rating scale. The reasoning behind assignment of minimum value to the filler item has not been explained in detail in any of the literature on segmented attack.  We provide below details of our filler item strategies for segment attack  7.1 Strategy SUL  This strategy is followed when a segment attack is mounted against a user-based CF system and the target item falls in TL category. In our approach to improve effectiveness of the attack, we need to create malicious users that are similar to those genuine users who have rated the target item with a lower value and also belong to the segment of users targeted by the segmented attack. So, to improve similarity, a randomly selected filler item is assigned the average rating given to it by those users who have rated any of the items that define the segment and have also rated the target item at a lower scale. For example for an attack against a segment of users interested in animation movies i.e., those users who have rated highly at least any three of the five most popular movies in animation genre, a filler item is assigned the average rating given to it by those users who have rated the target item at a lower rating and have rated highly at least one of the five animation movies that define the segment  7.2 Strategy SUH This strategy is followed when a segment attack is mounted against a user-based CF system and the target item falls in TH category. To improve effectiveness of a segment attack, a randomly selected filler item is assigned the average rating given to it by those users who have rated any of the items that define the segment and have also rated the target item at a higher scale  7.3 Strategy SIL  This strategy is followed when a segment attack is mounted against an item-based CF system and the target item falls in TL category. To improve effectiveness of a segment attack, we select filler items from the set of items which are highly rated by those users who have rated target item at a lower scale. The strategy used is similar to Strategy IL Filler items are selected the way explained in section 6.1  7.4 Strategy SIH  This strategy is followed when a segment attack is mounted against an item-based CF system and the 


target item falls in TH category. To improve effectiveness of a segment attack, we select filler items from the set of items which are highly rated by those users who have rated target item at a higher Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 scale. The strategy used is similar to Strategy IH Filler items are selected the way explained in section 6.2  8. Experimental evaluation and discussion  We performed the experimental evaluation of our strategies on the publicly available MovieLens data set [8]. This is the most widely used dataset in recommender systems research. MovieLens consists of 100,000 ratings made by 943 users on 1682 movies. Each user in the data set has rated at least 20 movies and each movie has been rated at least once A timestamp value is associated with each user movie, and rating combination. The data set also contains information on the demographic detail \(age sex, occupation, and zip code information \(genre and release date The ratings are made in a scale of 1 to 5, where 5 indicate extreme likeness for an item and 1 dislike We evaluated effectiveness of the proposed strategies on user-based and item-based collaborative algorithm. For similarity calculation and prediction in user-based CF algorithm, equations 1 and 2 stated in section 3 were used. Similarly, equations 3 and 4 stated in section 3 were used for computing similarity and prediction value for item-based CF algorithm We used a neighborhood size of k = 20 for prediction calculation. Case amplification value of 10 was used while calculating correlation and only positive correlations values were considered for computing predictions To conduct our evaluation, we selected a sample 20 items. Out of the 20 items, 10 items belonged to TL  category while remaining 10 items to TH category All the 20 items were selected randomly from a larger set of items belonging to each category. We also randomly selected a sample of 50 target users Target users selected were those who have never rated any of the 20 test items. Each of the target items was attacked individually and the prediction shift was calculated by averaging the prediction shift observed for each user. The final prediction shift for the attack is the average prediction over all items used in the test. Equation 6 was used to calculate the metric For implementation of segmented attack we followed the same guidelines as stated in [3]. Horror segment was selected as the target segment. Five of the most popular horror movies were selected to represent the segment. These five movies selected formed the selected item set in the attack profiles constructed. The five movies are Alien, Psycho, The Shining, Jaws, and The Birds. Users who have given a rating of 4 or 5 to at least any 3 of the five movies were identified as the target segment against which the attack was focused. For calculating prediction shift we selected 50 of the users from this target segment to form the test user set. While implementing the segment attack, selected items were given a rating of 5 and the randomly selected filler items were assigned a value 1 All experiments were conducted for ?Size of attack? values 1%, 3%, 6%, 12%, and 15%.  ?Size of attack? represents number of attack profiles added as a percentage of pre-attack profiles. 1% ?Size of attack? implies 10 attack profiles were added to a 


attack? implies 10 attack profiles were added to a system of 1000 genuine users. On the basis of the results reported in [4] that best results are reported when a filler size of 3% is used in an average attack we used a filler size of 3% for all our tests i.e., 3 % of 1682 items which is approximately 50 filler items For attacks against user-based collaborative filtering systems we used six strategies: Strategy UL, Strategy UH, Strategy SUL, Strategy SUH, segment attack and average attack. Similarly, for attacks against item based collaborative filtering systems we used six strategies: Strategy IL, Strategy IH Strategy SIL Strategy SIH, segment attack and average attack. For average attack, filler item strategy used was the same as in an average attack i.e., the mean of the filler item was assigned to it. Segment attack was implemented as explained earlier. Category TL, Category TH Strategy UL, Strategy UH, Strategy IL, Strategy IH Strategy SUL, Strategy SUH, Strategy SIL and Strategy SIH were implemented the way explained earlier in section 4, section 5, section 6 and section 7 respectively. For attacks against item-based CF while selecting filler items from set IF, only items with minimum frequency count of 10 were considered Figure 2 and Figure 3 show the effectiveness of our attacks when calculated for all users against systems using user-based collaborative filtering for recommendations.  Figure 2 shows the prediction shift values of attacks Strategy UL and average attack for items belonging to TL category. From the graph it?s obvious that for items in TL category, Strategy UL outperforms average attack model for all values of attack size. Similarly, Figure 3 shows the prediction shift values for the attack strategies Strategy UH and average attack for items belonging to TH category From the graph it can be concluded that for items belonging to TH category, Strategy UH performs much better than average attack over lower values of attack size. At attack size of 12 % and 15% both attack have similar effectiveness Figure 4 and Figure 5 show the effectiveness of our attacks when calculated for all users against systems using item-based collaborative filtering for recommendations.  Figure 4 shows the prediction shift values of Strategy IL and average attack for Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 items belonging to TL category. Similarly, Figure 5 shows the prediction shift values for the Strategy IH and average attack for items belonging to TH category. From Figure 4 and 5 it can be concluded that both Strategy IL and Strategy IH perform substantially better than average attack over all values of attack size. It can also be observed that our attack strategies are more effective against itembased systems than user-based systems Figure 6, 7, 8, and 9 show the effectiveness of our filler based attack strategies for in-segment users. We observe that for attacks against both user-based and item-based CF systems the effectiveness of our filler based strategies is comparable to the best available attack model for in-segment attacks i.e., segment attack. However, in Figure 8 we observe that filler item strategy SIL performs better than segment attack. Because of the low knowledge cost involved in segment attack, we can conclude that for most scenarios segment attack is a better attack model for in-segment attacks than filler based attack models Experimental results clearly show that our approach of selecting a strategy based on target item rating distribution outperforms the best available attack model i.e., average model. One drawback of 


attack model i.e., average model. One drawback of our attack strategies is its high knowledge cost However, automated software agents can help diminish the cost. One approach that can be used to decrease the cost is to use a subset of users while selecting filler items. For example, in attacks against item-based systems, while implementing Strategy IH instead of selecting all users who have rated target item as 4 or 5 as members of the set UH. , we only select 20 users. Selection of items for set IF will then be performed using the data of the 20 users in set UH Similarly, in case of attacks against user-based systems, while implementing Strategy UH instead of assigning a filler item IF the average rating given to it by the set of users UH. , we assign IF the average rating given to it by a subset of 5 randomly selected users from UH. In future work we plan to experimentally verify the effectiveness of these cost reduction approaches    Figure 2:   Attack on TL category of items against user-based collaborative filtering system   Figure 3:   Attack on TH   category of items against user-based collaborative filtering system   Figure 4:   Attack on TL category of items against item-based collaborative filtering system  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8  Figure 5:   Attack on TH category of items against item-based collaborative filtering system   Figure 6:   Attack on TL category of items against user-based collaborative filtering system   Figure 7:   Attack on TH   category of items against user-based collaborative filtering system    Figure 8:   Attack on TL category of items against item-based collaborative filtering system   Figure 9:   Attack on TH category of items against item-based collaborative filtering system  9. Conclusion  This paper provides an effective approach towards constructing attack models. We show the importance of target item and filler items in construction of successful attack strategies. Through experiments we show that our approach of intelligent selection of filler items based on target item rating distribution results in substantial improvement over the baseline average attack. We also compare our approach with the well known in-segment approach and conclude that our approach gives slightly improved results. In future, we plan to examine the filler items strategies for other attack models, and also create algorithms to improve robustness and stability of recommender systems against shilling attacks 


systems against shilling attacks  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9  10. References  1] Lam, S., and Riedl, J. 2004. Shilling Recommender Systems for Fun and Profit, In Proceedings of the 13th International WWW Conference 2] Mehta, B., Hofmann, T., and Nejdl, W. 2007. Robust Collaborative Filtering, In Proceedings of the 2007 ACM Conference on Recommender Systems, 49-56 3] Mobasher, B., Burke, R., Bhaumik, R., and Williams C. 2007. Towards Trustworthy Recommender Systems: An Analysis of Attack Models and Algorithm Robustness, ACM Transactions on Internet Technology, 7\(2007 4] Burke, R., Mobasher, B., and Bhaumik, R. 2005 Limited Knowledge Shilling Attacks in Collaborative Filtering Systems, In Proceedings of Workshop on Intelligent Techniques for Web Personalization 5] Konstan, J., Miller, B., Maltz, D., Herlocker, J Gordon, L., and Riedl, J. 1997.  GroupLens: Applying Collaborative Filtering to Usenet News Communications of the ACM, 40, 3\(1997 6] Herlocker, J., Konstan, J., Borchers, A., and Riedl J.1999. An Algorithm Framework for Performing Collaborative Filtering, In Proceedings of  SIGIR ACM, 77-87 7] Sarwar, B., Karypis, G., Konstan, J., and Riedl, J 2001. Item-based Collaborative Filtering of Recommendation Algorithms. In Proceedings of the 10th International WWW Conference 8] MovieLens data set,www.grouplens.org  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


 Current Time \(min  Healthy Failure Expected Just-in-time line Actual Remaining Life  Figure 17. Results of failure prognosis 0 100 200 300 400 500 600 700 800 900 1000 0 0.02 0.04 0.06 0.08 0.1 0.12 Time \(min Sp al l S iz e  m m 2 Interpolation of spall growth according to feature values 0 100 200 300 400 500 600 700 800 900 1000 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Time \(min Fe a tu re V a lu e    Interpolation of feature value with noise Interpolation of feature vlaue snapshot with ground truth data 11 CONCLUSIONS This paper shows that enhancements to diagnostic techniques are desirable as well as attainable additions to Health and Usage Monitoring Systems \(HUMS particularly in the case of rotorcraft component monitoring Enhancements like those presented support CBM efforts primarily in two ways: reduce the sensitivity of diagnostic processes to both signal noise and variations in environmental and operating conditions, and improve the performance of detection systems as well as the task of fault identification \(e.g., severity quantification instantiation of reliable prognostics Representative examples, motivated by the interest of the U.S. Army in transitioning from time-based \(using TBO definitions drive train bearing, illustrates the potential benefits of 


pursuing an integrated approach to diagnostics and prognostics, combining technologies for enhanced data preprocessing, advanced diagnostic-support algorithms, fusion at the sensor/feature levels, and an adequate framework for false alarm mitigation and uncertainty management. An architecture for achieving such integration is presented, with emphasis on supporting a robust performance of diagnostics operations, even in the presence of such kinds of disturbances as those observed in data acquired by HUMS vibration sensors. The present study also gives relevance to seeded fault because the technologies discussed can integrate knowledge about damage mechanism interactions or physics-of-failure models, as well as make use of multiple-sensor and multiple-feature data sets representative of known fault conditions For this reason, the team behind this project is evaluating a potential opportunity to perform a series of tests on rotorcraft drive train bearings with varying fault severities and under multiple, though realistic, operating conditions Such tests are being planned to provide algorithm/model validations, as well as diagnostic/prognostic performance assessments, in support of providing the U.S. Army with technologies that make detection systems more robust allow for the implementation of prognostics, and extend the useful life of drive train components. Component degradation testing thus remains as future, follow-up work to the research reported in this document ACKNOWLEDGMENTS This work has been partially supported with a cooperative agreement by the Army Research Laboratory under contract number W911NF-07-2-0075. In addition to the primary authors, we would like to thank government and contractor representatives from organizations supporting the Army Utility \(Blackhawk Estes, Mr. Carlos Rivera, and Dr. Jon Keller. This work has also benefitted greatly from consultations with other Army Research Laboratory and NASA Glenn researchers such as Dr. Timothy Krantz, Dr. David Lewicki, Dr. Harry Decker Dr. Hiralal Khatri, Mr. Ken Ranney and Mr. Kwok Tom REFERENCES 1] Branhof, R.W., Grabill, P., Grant, L., and Keller, J.A  Application of Automated Rotor Smoothing Using Continuous Vibration Measurements  American Helicopter Society 61st annual forum, Grapevine, Texas June 1  3, 2005 2] Dora, R., Wright, J., Hess, R., and Boydstun, B  Utility of the IMD HUMS in an Operational Setting on the UH60L Blackhawk  American Helicopter Society 60th annual forum, Baltimore, Maryland, May 7  10, 2004 3] Zakrajsek, J.J., Dempsey, P.J., et al  Rotorcraft Health Management Issues and Challenges  NASA report TM  2006-214022. February, 2006 4] Suggs, D.T., and Wade, D.R  Vibration Based Maintenance Credits for the UH-60 Oil Cooler Fan Assembly  American Helicopter Society, CBM Specialists Meeting, Huntsville, Alabama, February 13 2008 5] Baker, C., Marble, S., Morton, B.P., and Smith, B.J  Failure Modes and Prognostic Techniques for H-60 Tail Rotor Drive System Bearings  IEEEAC paper #1122 IEEE, 2007 6] Keller, J.A., Branhof, R., Dunaway, D., and Grabill, P  Examples of Condition Based Maintenance with the Vibration Management Enhancement Program   American Helicopter Society 61st Annual Forum Grapevine, Texas, June 1  3, 2005 7] Zhang, B., Sconyers, C., Byington, C.S., Patrick, R Orchard, M.E., and Vachtsevanos, G.J  Anomaly Detection: A Robust Approach to Detection of 


Detection: A Robust Approach to Detection of Unanticipated Faults  International Conference on Prognostics and Health Management, Denver, Colorado October 6-9, 2008 8] Byington, C.S., Watson, M., Lee, H., and Hollins, M  Sensor-level Fusion to Enhance Health and Usage Monitoring Systems  American Helicopter Society, 64th Annual Forum, Montreal, Canada, April 29-May 1, 2008 9] Engel, S.J., Gilmartin, B.J., Bongort, K., and Hess, A  Prognostics, the Real Issues Involved With Predicting Life Remaining  Proceedings of the IEEE Aerospace Conference, Big Sky, Montana, March 18-25, 2000 12 BIOGRAPHY Romano Patrick is a Project Manager at Impact Technologies. He received a Ph.D. in Electrical Engineering from the Georgia Institute of Technology specializing in model-based machine health diagnostics and prognostics. He also holds an MBA from Georgia Tech and degrees from U Texas, Arlington and U. Panamericana, Mexico. With career focus on interdisciplinary integration of technologies, his recent work involves practicable diagnostics/prognostics design for complex systems, such as rotorcraft drive trains Past experience includes automation and design for a variety of industrial and government sponsors \(DARPA, Lockheed Martin, Northrop Grumman, etc and program coordination at U. Panamericana, and some entrepreneurial R&amp;D Matthew J. Smith is a Senior Project Engineer at Impact Technologies. During his tenure with Impact, Matthew has performed multiple efforts pertaining to bearing vibration analysis, diagnostic and prognostic system development, and experimental study of faulted system reponse and fault progression. Previously, as a research assistant at Penn State and the NASA Glenn Research Center, Matthew performed experimental and analytical oil-free bearing analyses Matthew received his B.S. and M.S. degrees in Mechanical Engineering from The Pennsylvania State University. His research interests include: prognostic health assessment for bearing and actuator systems, grease degradation modeling and fault classifier development Bin Zhang received his Ph.D. degree from Nanyang Technological University, Singapore in 2007. He received his BE and MSE degrees from Nanjing University of Science and Technology, China, in 1993 and 1999, respectively. He is a senior member of IEEE. From 2005 to present, he has been a Post-Doc with the School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta GA His current research interests are fault diagnosis and failure prognosis, systems and control, digital signal processing learning control, intelligent systems and their applications to robotics, power electronics and various mechanical systems Carl S. Byington is a Professional Engineer and the Director of Systems Engineering at Impact Technologies. He directs R&amp;D in pursuit of advanced, automated systems health management for land-based, shipboard, and airborne machinery for military and commercial customers. He is Chairman of the Machinery Diagnostics &amp; Prognostics Committee of ASME and a member of IEEE, AIAA, SAE and AHS. He has a BS degree in Mechanical Engineering from the University of Pennsylvania and an MS in Aeronautical Engineering from George Washington University, and has published over 60 papers, book chapters, magazine and journal articles related to diagnostics and prognostics technologies George Vachtsevanos is Professor Emeritus at the Georgia Institute of Technology and also serves as the Chief Scientist at Impact Technologies, LLC. He directed the Intelligent Control Systems laboratory at Georgia Tech for the past 28 years where faculty and students are conducting research in fault diagnosis/prognosis and fault-tolerant control of engineering systems, intelligent control of industrial 


engineering systems, intelligent control of industrial processes, neurotechnology and cardiotechnology, and unmanned systems. His research work has been sponsored by government and industry and has published over 250 technical papers in his area of expertise. He is the lead author of a book on "Intelligent Fault Diagnosis and Prognosis of Engineering Systems" published by Wiley in 2006. He is the recipient of the Georgia Tech Interdisciplinary Activities award and the ECE Distinguished Professor award Romeo de la Cruz del Rosario, Jr. is the Chief of the Electronics Technology Branch at the U.S. Army Research Laboratory. He also serves as the Army Technology Objective ATO P&amp;D Operational Readiness and Condition Based Maintenance He received the B.E.E. degree from the Catholic University of America, Washington, D.C., and the M.S.E. and Ph.D degrees in Electrical and Computer Engineering from the Johns Hopkins University, Baltimore, MD. Since 1991 he has been an engineer at the Harry Diamond Laboratory then U.S Army Research Laboratory working in several areas including high power microwave technology characterization &amp; modeling of heterostructure RF devices and fabrication and failure analysis of electron devices and circuits  pre></body></html 


movies. In the case of the volume of critical reviews however, there was no big difference between mainstream and non-mainstream movies. WOM and critical reviews were usually positive H1 and H2 tested the relationship between WOM and weekly box office revenue, and the results supported the hypotheses. The volume of WOM was positively related to weekly box office revenue, while the valence of WOM had no significant effect. H3 H4a, and H4b tested the impact of critical reviews, and the results also supported the hypotheses except H4b The volume and valence of critical reviews had no consistent significances to weekly box office revenue H3 H4b. Table 7 showed that the number of critical reviews was statistically significant to aggregate box office revenue \(H4a for the attitude of critical reviews \(H4b the result more detail, an additional test was performed using only those factors related to critical reviews as independent variables. The result of the additional test supported H4, but the signs were reversed, i.e. positive critical reviews had minus signs, and negative critical reviews had plus signs. This reversed signs imply that the preference of critical reviewers is very similar to that of normal moviegoers. H5s and H6s tested the different effects of WOM and critical reviews on mainstream and non-mainstream movies. The result failed to determine that WOM give different impact on mainstream and non-mainstream movies, so H5a and H5b were rejected. H6, however, was supported, i.e the effects of critical reviews were different for mainstream and non-mainstream movies. There were no significant relationships between critical reviews and aggregate box office revenue in mainstream movies. For non-mainstream movies, however, the volume of critical reviews and the percentage of negative critical reviews were significant. Nonmainstream movies have fewer sources from which consumers can get information, and this might explain the results The above findings lead to several managerial implications. First, producers and distributors of movies could forecast weekly box office revenue by looking at previous weeks? volume of WOM. It does not matter what attitude people have when they spread WOM, the important factor is its volume. Therefore producers and distributors need to develop an appropriate strategy to manage WOM for their movies For example, the terms related to WOM marketing such as buzz and viral marketing are easily found Second, for the distributors who usually distribute less commercial and more artistic movies, and consequently have a smaller market compared to the major distributors, critical reviews can impact their movies box office revenues in a significant way. There are usually fewer sources for information for nonmainstream movies than mainstream movies, and so small efforts could leverage the outcomes. Finally, for those who are dealing with mainstream movies, the finding that the valence of WOM and critical reviews do not have significant relationship with box office revenue can have certain implications. Particularly, the attitude of critical reviews showed reversed effects Therefore, they may need to concentrate on other features rather than attitude of moviegoers or critical reviews, such as encouraging moviegoers to spread WOM This study contributes to the understanding of the motion picture industry, especially the relationship between box office revenue and WOM including critical reviews. There are existing studies that already 


critical reviews. There are existing studies that already dealt with similar issues, but this study has some differentiated features compare to prior studies. First the data used in this study was collected from South Korea, while most of the relevant studies usually focus on the North American market. This helps to provide the opportunity to understand the international market especially the Asian market, even though South Korea is a small part of it in terms of the motion picture industry. Second, movies were categorized to two groups, i.e. mainstream and non-mainstream and this study attempted to determine how WOM impacts these categories differently by testing several hypotheses In this study, there are also several limitations that could be dealt with in future research. First, using box office revenue as a dependent variable is more meaningful for distributers rather than producers. Due to there is close correlation between box office revenue and number of screens, one of producers? main concerns is how many screens their movies can be played on. Moreover, DVD sales are also important measurement for success of movies these days, and so it also could be a dependent variable. Therefore, it could be possible to give more fruitful managerial implications to various players in the motion picture industry by taking some other dependent variables Second, in this study, movies were categorized simply as mainstream and non-mainstream movies, but there could be further studies with diverse techniques of movie categorizations. For example, it would be possible to study the varying influence of WOM or critical reviews on different genres or movie budgets Third, an interesting finding of this study is that positive critical reviews could have negative relationship with box office revenue while negative critical reviews could have positive relationship. This study tried to provide a reasonable discussion on the issue, but more studies could be elaborate on it  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 References  1] Dellarocas, C., The Digitization of Word of Mouth Promise and Challenges of Online Feedback Mechanisms Management Science, 2003. 49\(10 2] Bone, P.F., Word-of-mouth effects on short-term and long-term product judgments. Journal of Business Research 1995. 32\(3 3] Swanson, S.R. and S.W. Kelley, Service recovery attributions and word-of-mouth intentions. European Journal of Marketing, 2001. 35\(1 4] Hennig-Thurau, F., et al., Electronic word-of-mouth via consumer-opinion platforms: What motivates consumers to articulate themselves on the internet? Journal of Interactive Marketing, 2004. 18\(1 5] Fong, J. and S. Burton, Electronic Word-of-Mouth: A Comparison of Stated and Revealed Behavior on Electronic Discussion Boards. Journal of Interactive Advertising, 2006 6\(2 6] Gruen, T.W., T. Osmonbekov, and A.J. Czaplewski eWOM: The impact of customer-to-customer online knowhow exchange on customer value and loyalty. Journal of Business Research, 2006. 59\(4 7] Garbarino, E. and M. Strahilevitz, Gender differences in the perceived risk of buying online and the effects of receiving a site recommendation. Journal of Business Research, 2004. 57\(7 8] Ward, J.C. and A.L. Ostrom, The Internet as information minefield: An analysis of the source and content of brand information yielded by net searches. Journal of Business Research, 2003. 56\(11 


9] Goldsmith, R.E. and D. Horowitz, Measuring Motivations for Online Opinion Seeking. Journal of Interactive Advertising, 2006. 6\(2 10] Eliashberg, J., A. Elberse, and M. Leenders, The motion picture industry: critical issues in practice, current research amp; new research directions. HBS Working Paper, 2005 11] S&amp;P, Industry surveys: Movies and home entertainment 2004 12] KNSO, Revenue of Motion Picture Industry 2004 Ministry of Culture, Sports, and Tourism, 2004 13] Duan, W., B. Gu, and A.B. Whinston, Do Online Reviews Matter? - An Empirical Investigation of Panel Data 2005, UT Austin 14] Zhang, X., C. Dellarocas, and N.F. Awad, Estimating word-of-mouth for movies: The impact of online movie reviews on box office performance, in Workshop on Information Systems and Economics \(WISE Park, MD 15] Mahajan, V., E. Muller, and R.A. Kerin, Introduction Strategy For New Products With Positive And Negative Word-Of-Mouth. Management Science, 1984. 30\(12 1389-1404 16] Moul, C.C., Measuring Word of Mouth's Impact on Theatrical Movie Admissions. Journal of Economics &amp Management Strategy, 2007. 16\(4 17] Liu, Y., Word of Mouth for Movies: Its Dynamics and Impact on Box Office Revenue. Journal of Marketing, 2006 70\(3 18] Austin, B.A., Immediate Seating: A Look at Movie Audiences. 1989, Wadsworth Publishing Company 19] Bayus, B.L., Word of Mouth: The Indirect Effects of Marketing Efforts. Journal of Advertising Research, 1985 25\(3 20] Faber, R.J., Effect of Media Advertising and Other Sources on Movie Selection. Journalism Quarterly, 1984 61\(2 21] Eliashberg, J. and S.M. Shugan, Film critics: Influencers or predictors? Journal of Marketing, 1997. 61\(2 22] Reinstein, D.A. and C.M. Snyder, The Influence Of Expert Reviews On Consumer Demand For Experience Goods: A Case Study Of Movie Critics. Journal of Industrial Economics, 2005. 53\(1 23] Gemser, G., M. Van Oostrum, and M. Leenders, The impact of film reviews on the box office performance of art house versus mainstream motion pictures. Journal of Cultural Economics, 2007. 31\(1 24] Wijnberg, N.M. and G. Gemser, Adding Value to Innovation: Impressionism and the Transformation of the Selection System in Visual Arts. Organization Science, 2000 11\(3 25] De Vany, A. and W.D. Walls, Bose-Einstein Dynamics and Adaptive Contracting in the Motion Picture Industry Economic Journal, 1996. 106\(439 26] Bagella, M. and L. Becchetti, The Determinants of Motion Picture Box Office Performance: Evidence from Movies Produced in Italy. Journal of Cultural Economics 1999. 23\(4 27] Basuroy, S., K.K. Desai, and D. Talukdar, An Empirical Investigation of Signaling in the Motion Picture Industry Journal of Marketing Research \(JMR 2 295 28] Neelamegham, R. and D. Jain, Consumer Choice Process for Experience Goods: An Econometric Model and Analysis. Journal of Marketing Research \(JMR 3 p. 373-386 29] Lovell, G., Movies and manipulation: How studios punish critics. Columbia Journalism Review, 1997. 35\(5 30] Thompson, K., Film Art: An Introduction. 2001 McGraw Hill, New York 31] Zuckerman, E.W. and T.Y. Kim, The critical trade-off identity assignment and box-office success in the feature film industry. Industrial and Corporate Change, 2003. 12\(1 


industry. Industrial and Corporate Change, 2003. 12\(1 27-67 32] KOFIC, Annual Report of Film Industry in Korea 2006 Korean Film Council, 2006 33] Sutton, S., Predicting and Explaining Intentions and Behavior: How Well Are We Doing? Journal of Applied Social Psychology, 1998. 28\(15 34] Basuroy, S., S. Chatterjee, and S.A. Ravid, How Critical Are Critical Reviews? The Box Office Effects of Film Critics Star Power, and Budgets. Journal of Marketing, 2003. 67\(4 p. 103-117  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 






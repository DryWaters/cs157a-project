  Sequential Pattern Mining on Library T r ansaction D a ta  I m as Suk aesih Si tang g a ng  C o m put er S c i e n ce D e part m e nt  Bog o r A g ric u lt u r al Un i v ers i t y  Bog o r, In don es ia e-m a il: i m as s itan g g an g  ip b  ac.id   Anita Ag ust i na  F acu l t y of  C o m put er S c i e n ce an d In f o r m at i o n T ech n o l ogy Un i v ersiti P u tra Mala y s ia  4340 0 S e rdan g S e l a ng or, Mal a y s i a  e m ail: a n ita.aj a g m a i l co m   Nor Azur a Hus i n  F acu l t y of  C o m put er S c i e n ce an d In f o r m at i o n T ech n o l ogy Un i v ersiti P u tra Mala y s ia  4340 0 S e rdan g S e l a ng or, Mal a y s i a  e m ail: n azu ra1112 gm ail.co m  Nag h m e h Mahm oodian  Is la m i c A zad U n iv er s i t y  Mas h h a d B r an ch Iran e m ail: n a g h m e h  m a  g m a il.co m  Ab stra ct   A ppl i c at i o n of dat a m i ni ng t e c hni q u e s i n l i b r a r y 
dat a  r e s ul t s i n t e r e s t i ng an d us e f ul pat t e r ns t h at c a n b e u s e d t o  i m p r ov e ser v i ces i n u n i v ersi t y l i b rari e s   T h i s p a p e r  p r es en t s  resu l ts of th e w o rk i n a p p l y i n g th e se q u en ti al p a tte rn  m i n i n g  a l go r i th m n a m e ly Apr i o r iAll o n a  li b r ar y tr an s a c t ion d a t a se t F r e q ue nt s e q u e n t i al  pat t e r n s c o nt ai ni ng b o o k s e q u e n c e s  bo r r o w e d by s t u d e n t s ar e g e ne r a t e d f o r  m i ni m u m s u pp or t s 0  3   0.2 0 15 a n d 0.1. T h e s e  p a t t ern s ca n  h e l p lib ra r y in  p r ov id i n g bo o k r e c o mm e n dat i o n t o s t u d e n t s  c o nd uc t i ng bo o k p r o c u r e m e 
n t  b a se d  o n re ad er s n e e d as w e ll a s  m a n a gin g bo ok s la you t   K e y w or ds  Se q u e n ti al Pa tte rn Minin g Apri oriAll  Li bra r y  Transac t i o n Da ta I   I NT R O DUC T I ON  No w a da y s un iv er s i t y libraries h a v e u til ized com p u t erb as ed  sy s t e m s t o prov i d e bet t e r s e rv i ces t o u s ers  H u g e num bers  of  library data are recorded in t h e s y s t e m s i n cl u d ing bo ok  dat a s e t  book t r an s act i o n  a n d u s er prof i l e s  E x t r act i n g  u s e f ul  an d in tere sti n g p a tter n s f r o m l a rg e lib rar y d a ta is a n i m p o r ta n t  t a s k i n order t o k n o w s t u d en t  s beh a v i or i n t h ei r book  s l o an records  A n al y z i n g t h e t r ans a ct i o n of book dat a ca n be us ed t o  det e rm i n e t h e f r eq u e n t 
l y borro w e d book s s o t h at l i b rari ans  can  deci de w h i c h book s are n e eded t o con s i d er i n t h e book  procu r em e n t   D a t a m i n i n g  t e c h ni qu es h a v e been w i del y  appl i e d t o  ex t r act  in teresti n g p a ttern s f r o m tra n sactio n d a tasets i n  m a n y ar eas s u c h as cu s t o m er s h oppi n g beh a v i or an al y s i s In t h i s t a s k w e  f i n d as s o ciation r u les repres en ti n g ite m s th a t are f r equ e n t l y  as s o ciated or pu rch a s e d tog e t h er  A s s o ci at i on ru l e m i n i ng h a s been u s ed to an al y ze library data.  L i a n d C h e n 200 8 ex t r act ed s t rong as s o ci at i o n ru l e s  f r o m book reader s l o an records u s i n g t h e A p ri ori al g o ri t h m  an d Wang 2007  di s c ov ered u s efu l kn o w l e dge f r om l i b rar y ci rcu l at i o n dat a  u s 
i n g th e i m prov ed as s o ciatio n ru le al g o rithm   In ad d itio n to asso ciatio n ru le m i n i n g seq u e n tial p a ttern  m i n i ng can be applied to ex tract n e w us efu l an d in teres t i n g p a ttern s f r o m l i b r ary d a ta i n  w h ich t i m e p a ra m e ter i s in v o lv e d   In s e qu e n tial pattern  m i n i n g   w e ta k e ti m e s t a m p into accou n t  th en  f i n d th e proper ru les  for ex a m ple f o r th os e cu s t o m ers  w hos e pu rc h a s e co m p u t ers  t h e y a l s o t e n d t o buy a n t i v i r u s s o f t w a re w i t h i n  a w e e k  S e qu en t i al  pat t e rn m i ni ng  deal s w i t h  a s e qu en ce dat a bas e con s i s t i n g of s e qu en ce s of order e d  ele m e n ts or ev en t s In th e ca s e of cu s t o m er pu rch a s e a n al ys is  in a s u per m ark e t, a record in a s e qu en ce databas e cons is t s  of  tran sactio n d 
a te an d ite m s b o u g h t i n th e tra n sacti o n    S e qu en t i al pat t e rn  m i ni ng al g o ri t h m s  h a v e bee n appl i e d i n  m a ny areas s u c h as cu s t o m er s h oppi n g  f i n d i n g t e l e ph o n e callin g p a ttern s w e b l o g cl ic k strea m s, a n d DN A seq u e n ces an d g e n e s t ru ct u r es  Sequ e n tial pattern m i n i ng f r o m  alar m dat a al s o can be perf or m e d i n  f i n d i n g probl e m s  i n n e t w or k s  an d pos s i bl y i n predi c t i n g  s e vere f a u l t s   Se q u e n t i a l  p a t t e r n mi ni ng i s  t h e mi ni n g  o f fr e q ue nt l y  occu rri n g ordered ev en t s or s ubs equ e n c e s as pat t e rn  e  s e qu ent i a l pat t e rn  m i ni ng probl em  w a s f i r s t i n t r odu ced by  A g ra w a l an d S r i k a n t i n 1995 2 
  T h e y propos ed t w o alg o rithm s  A p rioriSo m e an d A p riori A ll to ex tract s e qu en t i al  pattern s f r o m a databas e of cu s t o m er tra n s actio n s Each tran sactio n i n t h e d a tab a se c o n s is ts o f t h e f o llo w i n g  f i el d s  cu sto m eri d  tra n sactio n ti m e an d ite m s p u rch a sed in t h e tran s actio n   A l l trans action of a c u s t o m er can tog e t h er be  v i e w ed as a s e qu e n ce w h ere each trans action corres pon d to a set o f ite m s an d th e list o f tran sactio n s o r d e red  b y in creas in g  tran sactio n ti m e co rresp o n d s to a seq u en ce Seq u e n tial p a t t e r n  mi ni n g a l go r i t h ms f i n d a l l fr e q ue nt  sub s e q ue nc e s i  e   s u bs eq u e n c e s  w h o s e occu rrence f r equ e n c y i n t h e datas e t w i th n o l e s s t h a n u s er s peci f i ed m i n i m u m su pport t h resh ol d  
T h is w o rk ap p lies t h e seq u e n tial p a ttern  m i n i n g al g o rith m  n a m e l y  A p ri ori A l l propos ed by  A g ra w a l a n d S r i k a n t 1995  2  n th e lib rar y tran sactio n d a taset to d i sco v er th e m o st com m o n book  s l o a n pat h s b y s t u d en t s an d f r o m t h i s  i n f o r m at i o n a l i b rar y ca n recom m e n d on e or m o re book s t o  s t u d e n ts a f ter t h e y borro w a n oth e r book In addition  a librar y  can arrang e book s pos ition i n  w h ic h book s i n a s e q u en ce a r e lo cated o n ad j acen t p o s itio n su ch t h at st u d en t s can  f i n d t h e s e book s eas i l y    T h e pa per a r e org a n i zed as f o llo w s Sectio n 2 ex plain s  ab o u t literatu re rev i e w relate d to seq u en tial p a ttern  m i n i n g  f o cu s o n th e A p rio r iAll alg o r ith m  Sectio n 3  w ill d i sc u s s  978-1-4244-6716-7/10/$26.00 ©2010 IEEE 


   about the preprocessing phase for the library dataset.  Result and discussion are summarized in Section 4. Conclusion is given in Section 5 II  SEQUENTIAL PATTERN MINING  In Agrawal et al. \(1993\he problem of discovering “what items are bought together in a transaction” over basket data was introduced [1  T h e p r o b le m o f f i n d in g  w h at ite m s  are  bought together from an unordered set of items is concerned with finding intra-transaction patterns. Sequential pattern mining deals with data represented as sequences \(a sequence contains ordered sets of items\equential patterns indicate the correlation between transactions T h e pr oblem of finding sequential patterns is concerned with extracting intertransaction patterns [2 In seq u en tial p a ttern  m i n i n g th e  input data is a set of sequences in which a sequence represents a list of transactions.  Each transaction is a set of items Many works have been performed in developing sequential pattern mining algorithms.  Some algorithms for sequential mining problem are AprioriSome, AprioriAll, DynamicSome  e ralized S e qu en tial P a ttern GS P  9 S P IR IT  Sequential Pattern Mining with Regular Expression Constraints S P A D E: An Ef ficient A l g o rithm f o r Mini n g  Frequent Sequences ixSpan [7 L P M in er An  Algorithm for Finding Frequent Sequential Patterns using Length-Decreasing Support Constraint d C l osed S equential Pa ttern Mining \(CloSpan  There are some important terminologies related to the task as described as follows [5 e t I  i 1 i 2 i n be a set of all items An itemset is a subset of items. A sequence is an ordered list of itemsets. A sequence s is denoted by <s 1 s 2 s l  where s j is an itemset.  S j is also called an element of the sequence, and denoted as \(x 1 x 2 x m here x k is an item Number of instances of items in a sequence is called the length  of the sequence.  A sequence with length l is called an lsequence A sequence  a 1 a 2 a n is called a subsequence  of another sequence  b 1 b 2 b n and  a super-sequence  of  denoted as      if there exist integers 1  j 1   j 2      j n   m such that a 1   b j1 a 2   b j2 a n   b jn 5  A n i t e m s e t  with minimum support is called a large itemset or litemset 2 A  AprioriAll The AprioriAll algorithm was widely used for identifying patterns in customer transactions in the retail industry. Given a database D of customer transactions, the problem of mining sequential patterns is to find the maximal sequences among all sequences that have a certain user specified minimum support Each maximal sequence represents a sequential pattern. A sequence satisfying the minimum support constraint is called a large sequence.  There are five steps in the AprioriAll algorithm: sort phase, litemset phase, transformation phase sequence phase, and maximal phas th e s o rt ph as e w e  sort the database D, with customer-id as the major key and transaction time as the minor key and then the original transaction database is converted into a database of customer sequences.  In the litemset phase, the set of all litemsets L is found and the set of all large 1-sequences {<l >|l  L} is simultaneously obtained.   The set of litemset is then mapped to a set of contiguous integers.  The purpose of the mapping is to reduce the time required to check if a sequence is contained in a customer sequen tra n s f or m a tio n ph a s e, ea ch  customer sequence is transformed into an alternative representation.  Each transaction is replaced by the set of all litemsets contained in the transaction based on the following conditions [2   If a transaction does not contain any litemset, it is not retained in the transformed sequence   If a customer sequence does not contain any litemsets, this sequence is dropped from the transformed database In the sequence phase, multiple passes over the data are performed.  In each pass, we start with a seed set of large sequences. New potentially large sequences called candidate sequences are generated based on the seed.  At the end of the pass, the large candidate sequences are determined and a large candidate becomes the seed for the next pass.  All Support for sequences are counted while the algorithm passes the data The sequence phase involves the Count-all method based on the Apriori algorithm.  Figure 1 shows the AprioriAll algorithm  L 1 large 1-sequences for k=2; L k-1   k++\o begin C k New candidates generated from L k-1 foreach customer-sequence c in the database do  Increment the count of all candidates in C k  that are contained in c L k Candidate in C k with minimum support end Answer = Maximal Sequences in   Fig. 1.  AprioriAll Algorithm  Below as the Apriori Candidate Generation applied in the AprioriAll algorithm insert into C k  select p.litemset 1 p.litemset k-1 q.litemset k-1 from  L k-1 p  L k-1 q  where p.litemset 1 q.litemset 1  p.litemset k-2 q.litemset k-2   Fig. 2.  Apriori Candidate Generation [2  In the maximal phase, the maximal sequences among the set of large sequences are generated.  In a set of sequences, a sequence s is maximal if s is not contained in any other sequen III  D ATA P RAPROCESSING  A  Dataset Each record in the dataset represents book’s code that a student borrows in a particular date. The dataset consists of 7799 records and three attributes: transaction ID \(Tid\ book’s code \(Item\nd transaction date \(Date\when a student borrow a book.   Tid and book’s code are categorical, and Date is represented in date format \(dd/mm/yyyy\An example  


   of transaction ID \(Tid\s A14103005.  A Tid contains 9 characters.  The first digit is a character denoting major of a student.  This digit is followed by some number representing code of year when a student enrolls to the university and sequence number to identify a student in a particular major Book’s code \(Item\s represented in 3 digits, for example 631 311, 512 and so on.  The first digit represents general topic the second one is more specific than the first, and the last one is more specific than the second one B  Data Transformation A book’s code consisting three digits represents a category of book’s subject.  For examples: 512 for Algebra, 632 for Plant disease, and 664 for Food technology.  Each digit in book’s code is related to a book’s subject.  The first two digits represent more general book’s subjects compared to code containing three digits.  For example, the code 510 \(denoted as 51 in the following discussion\ is used for Mathematics book meanwhile the code 512 is used for Algebra books.  As we know Algebra is one of area in mathematics.  Figure 3 shows the hierarchy of book’s code It is difficult to find interesting book transaction patterns from the dataset at such raw or lowest level data \(level 3 in Figure 3\.  For example, a transaction in which a student borrows a book Algebra \(code: 512\nd then she/he borrows two books: macro economic \(339\ and finance economic science \(code: 332\ may occur in a small fraction in the dataset Therefore it may be difficult to be a frequent sequence involving these specific items.  For that, we use the second level as a generalization of the third level of book’s code in the sequential pattern mining   Fig. 3.  Hierarchy of book’s code  In sequential pattern mining, all book transaction of a student can together be viewed as a sequence, where each transaction corresponds to a set of book items, and list of book transactions corresponds to a sequence, ordered by increasing transaction-time.  To prepare the dataset containing Tid, Date and lists of book items, we develop a computer program using SAP. The program will concatenate a book item \(code\ to others if the transactions containing items have the same Tid and date of transaction \(Date\.  Table I represents list of book item sequences. A list of items in brackets, for example \(65, 63 33\ represents a sequence of book’s code borrowed by a student in the same date. The dataset contains 1037 list of sequences TABLE I  LIST OF BOOK  S ITEM SEQUENCES  Tid List of Book’s item A14103005 63, 63, 63 A14103010 63, 33, \(65, 63, 33 A14103013 63 A14103019 33, 65, \(33, 65 A14103023 65, \(68, 51   We developed a computer program using SAP to find frequent \(large\uences from the library dataset using the AprioriAll algorithm. We performed experiment using some values of minimum support threshold i.e. 0.3, 0.2, 0.15 and 0.1.  There are no frequent sequences generated for minimum support above 0.3  IV  RESULT AND DISCUSSION  Mining sequential patterns using AprioriAll is conducted in five phases:  Sort phase, litemset phase, transformation phase sequence phase, and maximal phas t h e s o rt ph a s e t h e  dataset is sorted, with Student-id \(Tid\ as the major key and transaction-time as the minor key in order to create a database of customer sequences. This step has been done in the preprocessing phase.  In the litemset phase we find the set of all litemsets L. We also simultaneously determine the set of all large 1-sequences, since this set is just l  l  L}.  In the transformation phase each transaction is replaced by the set of all litemsets contained in that transaction.  If a transaction does not contain any litemset, it is not retained in the transformed sequence.  If a sequence does not contain any litemset, this sequence is dropped from the transformed databases.  But it still contributes to the count of total number of transactions The set of litemsets is mapped to a set of contiguous integers in order to reduce the time required in executing the algorithm Some records in the dataset before and after the transformation phase and after mapping as well are given in Table II.  In this table, the original dataset includes infrequent litemsets printed in bold.  These infrequent itemsets will be removed to result transformed dataset TABLE II  T RANSFORMED DATASET AND DATASET AFTER MAPPING  Original dataset Transformed dataset After Mapping 61,63 61,63\, \(61,63 61,\(61,63\,63 61,63,\(61,63 61,63,\(61,63\\,\(61,63 61,63\\,\(61,63,\(61,63 61,\(61,63,\(61,63\\, 63 3,4,10\,\(3,4,10 3,4,10 3,4,10\,3,\(3,4,10\,4 50  53 57 53  53  57 2 61,63\,61,61,61,63,63 61,63,\(61,63\\,61,61,6 1,63,63 3,4,10\,3,3,3,4,4 61,63\,\(61,63,67\,61 66, \(63,66 61,63,\(61,63\\,\(61,63 61,66,\(63,66,\(63,66 3,4,10\,\(3,4\,3,6 4,6, \(4,6 53 66,66 57,65  66,66 6,6 57,63\,63,63,63,63,63 57,63,\(57,63\\,63,63,6 3,63, 63 2,4,9\,4,4,4,4,4 66 54,61  66,61 6,3 67,67  69 63 67  63,67  63,63 4,4  The sequence phase applies the AprioriAll algorithm on the mapping dataset.  We used some values of minimum support to find l large sequences l 2, 3, 4.  For minimum support 


   0.3, 0.2, and 0.15, 2-large sequence is 33 63, 33 63, and 33 57 respectively. Large lsequences l 2, 3, and 4, for minimum support 0.1 are given in Table III TABLE III  L ARGE L SEQUENCE  FOR L    2  3  4 AND MINIMUM SUPPORT 0.1   2-large sequence 3- large sequence 4- large sequence 33 57, 33 65, 33 66, 57 63, 57 66 63 65, 63 66, 57 \(57,63 63 \(57,63 33 57 63 33 63 66 57 63 66 57 63 \(57,63 33 \(61,63\ 61 63   After we have 1-large sequences, 2-large sequences and so on, we find maximal sequences among the set of large sequences.  Maximal sequences for minimum support 0.3, 0.2 and 0.15 are <33 63>, <33 63>, and <33 57> respectively Maximal sequences for minimum support 0.1 are <33 65 63 65>, <33 57 63>, <33 63 66>, <57 63 66>, <57 63 57,63\d <33 \(61,63\1 63 This maximal sequences represent sequential pattern of books that frequently borrowed by students. By observing/utilizing this maximal sequences, a university Library can improve its services.  Based on above result books that frequently borrowed by students are 33 \(Economic Chemistry Technology\d 61 \(Medical Science\ Therefore library should increase number of copies for these books to support students in learning subjects related to Economic science Agriculture, Life science, Chemistry Technology and Medical Science The results also show student’s behavior in borrowing books in the library. For example, students who borrow the book 33 \(Economic science\ will also borrow the book 63 Agriculture\n the following day\(s\his pattern is supported by 30% records in the transaction.  Another result is that 10% transactions have the maximal sequence <57 63 66 It means a student who borrow the book 57 \(Life science\ in the following day\(s\she/he will borrow 63 \(Agriculture\d followed by 66 \(Chemistry Technology\ in the next time period.  Based on this sequence, library may provide readers who borrow Life science book recommendation to read Agriculture and Chemistry Technology next days.  In addition library may locate Life science, Agriculture and Chemistry Technology books in the same cluster or put close together to provide easy access and convenient for readers in searching these books  V  CONCLUSION  This paper discusses the application of classical sequential pattern mining algorithm AprioriAll on a library dataset to extract frequent book sequences borrowed by students.  One of the results show that students who borrow the book 33 Economic science\will also borrow the book 63 Agriculture\ the following day\(s\or minimum support 0.3.  The patterns can be used by library in order to improve its services to students effectively.  Number of copies for books occurred in the frequent sequences can be increased to support students in learning related subjects. Library may also give readers recommendations to read other books after they finish reading a certain book.  Based on the book occurrences in frequent sequences, layout of books can be arranged such that readers can find easily the books  R EFERENCES  1  R. Agrawal, T. Imielinski and A. Swami, “Mining association rules between sets of items in large databases,” Proceeding of the ACM SIGMOD Conference on Management of Data, Washington, D.C., May 1993, pp. 207-216 2  R. Agrawal and R. Srikant, “Mining sequential patterns,” Proceeding of the 11 th Int’l conference on Data Enggineering, Taipei, Taiwan, March 1995 3  M. N. Garofalakis,  R. Rastogi and K. Shim, “ SPIRIT: Sequential pattern mining with regular expression constraints,” Proceedings of the 25 th VLDB Conference Edinburgh, Scotland, 1999 4  J. Han and M. Kamber, “Data mining concepts and tchniques,” San Diego, USA: Morgan-Kaufmann,  2006 5  J. Han, J. Pei, and X. Yan, “Sequential pattern mining by patterngrowth: principles and extensions,”  2005 6  J. Li and P. Chen, “The application of Association rule in Library system,” IEEE, 2008, pp. 248-251 7  J. Pei, J. Han, B. Mortazavi-Asl and H. Pinto, “PrefixSpan: mining sequential patterns efficiently by prefix-projected pattern growth 2001 8  M. Seno and G. Karypis, “SLPMiner: an algorithm for finding frequent sequential patterns using length-decreasing support constraint,” 2002 9  R. Srikant, and R. Agrawal, “Mining sequential patterns: generalizations and performance improvements,” Springer-Verlag Proceeding 5th International Conference, 1996   P. Wu, W. Peng and M. Chen, “Mining sequential alarm patterns in a telecommunication database,”  Proceeding of the International Workshop on Databases in Telecommunications \(VLDB 2001\ Roma Italy, 10 September 2001   X. Yan, J. Han, and R. Afshar, “CloSpan: mining closed sequential patterns in large datasets,”  2003   M. J.  Zaki, “SPADE: an efficient algorithm for mining frequent sequences,”  Machine Learning, 0, 1-31 \(2000\ Kluwer Academic Publishers, Boston, 2000   Q. Zhao and S. S. Bhowmick, “Sequential pattern mining: a survey Technical Report, CAIS, Nanyang Technological University, Singapore No.2003118, 2003   Z. Zhu and J. Wang, “Book recommendation service by improved association rule mining algorithm,” IEEE The Sixth International Conference on Machine Learning and Cybernetics, Hong Kong, 19-22 August 2007,  pp. 3864-3869  


TABLE  I T HE  T F-IDF  AND  F UZZY  T F-IDF  V ALUES  FOR  E ACH  C ONCEPT  IN  S IX  D OCUMENTS D-ID Concept Frequencies No. of docu ments TF-IDF Fuzzy TFIDF C 1 2 2 0.954 0.318 C 2 1 3 0.301 0.151 C 3 1 4 0.176 0.117 C 6 1 1 0.778 0.129 D1  C 4 1 6 0.0 0.0 C 3 2 4 0.352 0.235 C 4 2 6 0.0 0.0 D2  C 5 3 5 0.237 0.197 C 2 2 3 0.602 0.301 C 3 4 4 0.704 0.469 C 4 1 6 0.0  0.0   D3  C 5 1 5 0.079 0.066 C 1 3 2 1.431 0.477 C 4 1 6 0.0 0.0  D4  C 5 5 5 0.395 0.329 C 3 3 4 0.528 0.352 C 4 2 6 0.0 0.0 D5  C 5 2 5 0.158 0.132 C 2 3 3 0.903 0.452 C 4 1 6 0.0 0.0  D6  C 5 4 5 0.316 0.263 1\he first effect of the fuzzy wei ghting schema, since the high weighted values are given to the concepts that are more occurrences in documents. For example, the concept C 6 is in two different orders as shown in Table II and Table III. The weighing schema considered the concept C 6 an important concept although it o ccurred only one time in all documents 2\he second effect of the fuzzy weighting schema is the appearing of new concepts with high fuzzy weighted values in the top of the list For example, in Table II the concept C 5 does not satisfy the threshold weight value although C 5 occurred 5 times in D4 In contrast in Table III the concept C 5 has a high fuzzy weighted value and exists in the top of the table C. Association Rule Mining \(ARM\ Phase The D-EART system designed to extract association rules base d o n concepts by using a new GARC algorithm. The algorithm overcomes the drawbacks of the Apriori algorithm by employing the power of data structure called Hash Table The hashing function h v oncepts number N  considered the key factors in hash table building and search performance. The GARC algorithm is utilized with dynamic hash table 1\ Generating Association Rules Algorithm Based on Concepts \(GARC  The proposed GARC algorithm as in Fig 5 employs the following two main steps: \(1\the number of concepts N ents, a dictionary table was constructed as shown in Table IV for N 6 concepts, and 2\There are also two main processes for a dynamic hash table: the building process, and the scanning process. The mining process for GARC algorithm includes the two processes \(building and scanning process\XML file that contains all concepts    TABLE  II T HE  C ONCEPTS  WITH  T HEIR  T F-IDF TABLE  III  Concept Documents TF-IDF Concept Documents Fuzzy TFIDF C 1 D4 1.431 C 1 D4 0.477 C 1 D1 0.954 C 3 D3 0.469 C 2 D6 0.903 C 2 D6 0.452 C 6 D1 0.778 C 3 D5 0.352 C 3 D3 0.704 C 5 D4 0.329 C 2 D3 0.602 C 1 D1 0.318 C 3 D5 0.528 C 2 D3 0.301 C 5 D4 0.395 C 5 D6 0.263 C 3 D2 0.352 C 3 D2 0.235 C 5 D6 0.316 C 5 D2 0.197 C 2 D1 0.301 C 2 D1 0.151 C 5 D2 0.237 C 5 D5 0.132 C 3 D1 0.176 C 6 D1 0.129 C 5 D5 0.158 C 3 D1 0.117 C 5 D3 0.79  C 5 D3 0.066 T HE  C ONCEPTS  WITH  T HEIR  F UZZY  T F-IDF  TABLE  IV T HE  D ICTIONARY  T ABLE  FOR  S IX  C ONCEPTS  IN  D OCUMENTS Dictionary Table Concept' s name Abbreviation Location Breast Cancer Docetaxel Tamoxifen Methotrexate Alopecia Fatigue C 1 C 2 C 3 C 4 C 5 C 6 0 1 2 3 4 5  The hash function h v  v mod N where v is a key location of primary concept\is us ed to build a primary bucket of the hash table. The algorithm scans only the XML file that contained all important concepts not the original documents The scanning process is done as follows 1\l possible combinations of concepts then d eterm ine their locations in the dynamic hash table by using the hash function h v  


2\pts and conceptsets in a hash table and update their frequencies, the process continues until there is no concept in the XML file 3\ve the dynamic hash table into secondary storage media 4\ic hash tab le to determine the large freque nt conceptsets that satisfy the threshold support GARC_algorithm 1 Input minimum support s minimum confidence \(c the number of concepts N  2 Build a primary bucket of hash table 3 IF there is no EOF THEN  4 FOR each document  D  d 1 d 2 d  n  DO 5 Select each concept c 1 c 2 c  N  6 Create all combinations of conceptset with their occurrences 7 Insert all conceptsets with their occurrences in hash table by using h v  8 IF there is  document D  THEN 9 Goto line 4 10 ELSE 11 Goto line 17 12 ENDIF 13 ENDFOR  14 ELSE 15 Goto line 19 16 ENDIF 17 Determine all large frequent conceptsets that satisfies the minimum support 18 Extract all Association Rules that satisfies minimum confidence 19 STOP Fig. 5 The GARC algorithm 2\ The Advantages of the GARC Algorithm  The advantages of the GARC algorithm summarize as follows 1\he algorithm permits the end user to change the threshold support an d confidence factor 2\all size of dynamic hash table, since with changing the size of c onceptsets the size of dynamic hash table will change 3\s number of conceptsets, since there is no conceptsets with zero occurrences will occupy a size in a dynamic hash table 3\ The GARC Algorithm Case Study  The D-EART system run on a collection of 100 online XML documents selected from MEDLINE by thresholds values: support s 2% and confidence c 50%. The number of concepts N 30 resulted from the indexing process a nd used for building a dynamic hash table. Fig. 6 shows the number of all fuzzy weighted concepts that labeling each document. Fig. 7 shows the number of the resultant association rules with c 50% which is equal to 64 rules The D-EART system can do different queries on the extracted asso ciation rules. The query s upports the medical researchers by a model of important relationships within the concept features. This model might identify relations between the disease and the suitable treatments, and relations between a treatment and its side effects. Fig. 8 shows the query screen which includes both the categories information and the queries result icons. The user can dete rmine which the categories will get the relations between them. The query results can be saved on the hard disk thro ugh the export icon  Fig.6 The number of fuzzy weighted concepts  Fig. 7 The resultant rules that satisfy c 50  Fig. 8 Query Screen The advantages of D-EART system are as follows 1 The user can access XML textual documents online 2  The design of the D-EART system is based on concept represe ntation and considers the synonymy as a characteristic of the natural language characteristics 3 It is flexible to work on specific or all parts of the documents with the same structure. Moreover it is not fully domain-independent so we can apply it on other domains 4 The proposed GARC algorithm overcomes the drawbacks of the previous algorithms 5 It extracts three types of the associ ation rules depending on the analysis of relations between the concepts only words only and concepts with words. In addition different queries are available on the extracted association rules IV  E XPERIMENTAL  R ESULTS The experiments are performed to compare the p e rformance of both D-EART system and Apriori-concept system for the number of extracted association rules and the execution time. Finally, evalu ate the performance of D-EART system at the three semantic levels: concepts only, words 


only, and concepts with words The corpus of the PubMed abstracts that used in the experim ents is consists of 10000 biomedical abstracts with keyword search breast cancer treatments and side effects   All experim e nts are applied on the 10000 docum ents after divided them into six documentsets 50, 100, 500, 1000 5000, and all 10000 documents. The systems are implemented by using VS .Net 2005 \(C#\a nd the experiments were performed on Intel Core2 Duo, 1.8 GHz system with Windows XP and 2 Giga of RAM A large number of association rules can be extracted by sel ecting the values of minimum support and confidence in the mining process.  The D-EART system gives the best results by using low support and high confidence values Moreover, the number of concepts that entered to the mining process is fewer by using the fuzzy weighting schema. Table V shows the experiments that are applied on various documentsets by different threshol d values. It noticed that the number of extracted association rules in D-EART system is useful and always less than that in Apriori-concept system The reason returns to the strong effect of using the fuzzy weighting schema in D-EART system Fig. 9 and Fig. 10 show that the execution time of Aprioriconcep t system is increased regular ly when the documentsets are increased compared to D-EART system. The mining process in Apriori-word system takes more time for less number of concepts in the documents. The reason is that the mining process in Apriori algor ithm depends on the size of documents rather than the number of concepts. The results show that the execution time of Apriori-concept system is about seventh fold of D-EART system. The D-EART system scans the documents only one time as the number of documents increased. Therefore the size of documents does not influence in the mining process. Finally, the results reveal that the execution time for D-EART system is much better than that of the Apriori-concept system in all cases  TABLE  V   T HE  N UMBER  OF  A SSOCIATION  R ULES  FOR  A PRIORIC ONCEPT  AND  D EART  S YSTEMS Minimum Support s  Minimum Confidence c  No. of Documents Systems s 1 c 50 3 50 7 60 10 50 500 Apriori-concept D-EART 183 71 76 31 17 5 10 2 1000 Apriori-concept D-EART 227 86 91 34 11 4 8 3 5000 Apriori-concept D-EART 239 92  75 27 20 4 15 2 10000 Apriori-concept D-EART 345 135 102 39 37 10 30 7   D5000 0,00 5,00 10,00 15,00 20,00 25,00 30,00 Apriori-concept D-EART Time in minutes s=1, c=50 s=3, c=50 s=7, c=60 s=10, c=50 Fig. 9 Execution time of Apriori-concept and D-EART systems at D=5000 D10000 0,00 5,00 10,00 15,00 20,00 25,00 30,00 35,00 40,00 Apriori-concept D-EART Time in minutes s=1, c=50 s=3, c=50 s=7, c=60 s=10, c=50 Fig. 10 Execution time of Apriori-concept and D-EART systems at D=10000 V  C ONCLUSIONS  AND  F UTURE  W ORK This paper presented a new text mining system for extracting ass o ciation rules based on concepts representation from online textual documents. This system overcame some of the problems in the prev ious EART system and the drawbacks of the Apriori algorithm by using the data structure hash table in the mining process. The results of comparing DEART and Apriori-concept syst ems reveal that the number of extracted association rules in D-EART system is always less than that in Apriori-concept system. Moreover, the execution time for D-EART system is mu ch better than that of Aprioriconcept system in all cases. So concept technique would be suitable to apply to any large corpus of medical text such as portions of the web. The future work will apply D-EART on PDF full text document with figures and images instead of using only the abstract part R EFERENCES  Fast algorithms for mining association rules,” In Jorge B Bocca, Matthias Jarke, and Carlo Zaniolo, editors Proc. 20 th Int. conf. of very Large Data Bases, VLDB Santigo, Chile 1994, pp. 487-499  T. I m ielinski, and A. Swa m i, “Mining association rules between Sets of items in large databases,” In Buneman, Peter and 


Jajodia, Sushil \(Eds Proc. of the ACMSIGMOD Int. Conf. on Management of Data, Washington D.C., 1993, pp. 207–216  e m ettinen, and A. Verka m o, “Applying data mining technique for descriptive phrase extraction in digital document collections,” in Proc. of IEEE Forum on Research and technology Advances in Digital Libraries Santa Barbra CA, 1998  m adzadeh, M. Rahgozar and A. Zarnani, “A new model for discoveri ng XML association rules from XML documents,” in Proc. 3 rd Int. Conf. on Knowledge Mining, ICKM Prague, Czech Republic, 2006 Aug. 25-27, pp. 365-369  i r, Y. Aum a nn, R Feldman, and M. Fresko Maximal association rules: A tool for mining associations in text Journal of Intelligent Information Systems 25:3, pp. 333-345, 2005  A  Ca m p i   M. Kl e m ettinen, and P  L   Lanzi M i n ing association rules fro m XML data,” in Proc. of the 4 th Int. Conf.  on Data Warehousing and Knowledge Discovery Aixen-Provence, France September 4-6, 2002  a m p i, S. Ceri, M. Kl emettinen, and P. L. Lanzi, “A tool for extracting XML as sociation rules,” in Proc. of the 14 th IEEE Int. Conf. on Tools  with Artificial Intelligence \(ICTAI’02 2002, pp. 57–64  and E. Meglio A Text M ining Strategy based on local contexts of words JADT 2004: 7 th Journées internationales d’Analyse statistique des Données Textuelles, 2004  r own Della Piet ra V J deSouza, and P V. Lai, “Class-based ngram models of natural language Computational Linguistics vol. 18 pp. 467–479, 1992  A. Napoli  and Y. T oussaint, “Towards a text mining methodology using association rule extraction,” Published online: 31 May 2005 © Springer-Verlag 2005  i cords and J. Lumpkin, “Der iving general association rules from XML data in Proc. of Fourth ACIS Int. Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel Distributed Computing SNPD'03\Lübeck, Germany, October 16-18 2003  m a n and I. Dagan, “Knowledge discover y in textual databases KDT\ in Proc. 1 st Int. Conf. on Knowledge Discovery and Data Mining 1995  R. Feld m a n, and H. Hir s h, “Mini ng associations in text in the presence of backgr ound knowledge,” in Proc. 2 nd Int. Conf. on Knowledge Discovery and Data Mining Portland, USA, 1996  m a n and I. Dagan and H Hirs h, “Mining text using keyword distributions Journal of Intelligent Systems 10, pp. 281-300, 1998  H. Zhang Q Qiu, and Z. Wang, “PCAR an ef ficient approach for mining association rules 5 th Int. Conf. on Fuzzy Systems and Knowledge Discovery, IEEE 2008  Fürnkranz, “A study using n-gram features for text categorization Austrian Research Institute for Artificial Intelligence Technical Report  OEFAI-TR-98-30 Schottengasse 3 A-1010 Wien, Austria, 1998  Bauer, J Mostafa M. Palakal, and S. Mukhopadhyay C oncept extraction and association from cancer literature WIDM’02  Mclean, Virginia, USA, November 8, 2002  J. Han, J. Pei, and Y Yin, “Mining frequent patt erns without candidate generation,” In W. Chen, J. Naughton, and P. A. Bernstein, editors, 2000 ACM SIGMOD Intl. Conf. on Management of Data ACM Press, 05 2000, pp. 1-12  W  Jin, R. K. Sr ihar i, and X Wu, “Mining concept associations for knowledge discov ery through concept chain queries,” Z.-H. Zhou, H. Li and Q. Yang \(Eds.\2007 LNAI 4426, pp. 555–562 2007.Springer-Verlag Berlin Heidelberg 2007 20  R. Joshi, X. Li , S. Ramachandaran and T. Leong \(2004\. “Automatic Model Structuring from Text using BioMedical Ontology Available http://www.aaai.org/Papers/Workshops/2004/WS-0401/WS04-01-013.pdf   Agrawal, and R. Sr ikant, “Discovering Trends in Text Databases,” in Proc of KDD, Int. Conf. on Knowledge Discovery  NewPort Beach, CA, , August 14-17, 1997, pp. 227-230  A. Dasigi, R. Dingledine, and B Ciliax, “T ext analysis of Medline for discovering functional relationships among genes: evaluation of keyword extraction weighting schemes Int J. Data Mining and Bioinformatics Vol. 1, No 1, 2006  i ve s, and J. Oliveira Concept-based knowledge discovery in texts extracted from the web ACM SIGKDD pp.29-39, July 2000  u b and D. R s n er, “Mining as sociation rules fro m  unstructured documents,” in Proc. 3 rd Int. Conf. on Knowledge Mining ICKM Prague, Czech Republic, Aug. 25-27, 2006, pp. 167-172  D. Rösner, N Is m a il, and F. Torkey  A text m i ning  technique using a ssociation rules extraction Int. J. of Computational Intelligence WASET, Vol. 4, Nr.1, 2007  a ju m d er, M  M i tra, and B. Chaudhuri, “N-gram: a language independent appr oach to IR and NLP Int. Conf. on Universal Knowledge and Language  ICUKL India November 2002  K. Ober m a y e r \(2 009\of concept based keyw ord extraction for tag recomm Available http://www.kde.cs.unikassel.de/ws/dc09/papers/paper_17.pdf   2009 a l library of Medi cine website [Online Available http://www.nlm.nih.gov   a k, “Discovering know le dge from XML documents,” In Wong John, Eds. Encyclopedia of Data Warehousing and Mining. Idea Group Publications 2005  onstrained association rules to predict heart disease,” in Pr oc. IEEE Int. Conf. on Data Mining, ICDM 2001, San Jose, CA, USA , 2001, pp. 433–440  Yong Youn, and U Kim, “A new method for mining association rules from a collection of XML documents ICCSA 2005 LNCS 3481, pp. 936–945, 2005 Springer-Verlag Berlin Heidelberg 2005  I W itten, S  Cunningha m  and G. Buchanan S calable browsing f or large collections: a case study 5 th Conf. digital Libraries  Texas, pp.215-218, 2000   M. Roche J´erom e Az´e, O. Matte-Tailliez, and Y. Kodratoff  Mining texts by association rules discovery in a technical corpus  Intelligent Information Processing and Web Mining Proc. of the Int. IIS: IIPWM'04  Conf held in Zakopane, Poland, May 17-20, 2004      M ining association rules fro m a collection of XML documents using cross filtering algorithm Int. Conf. on Hybrid Information Technology \(ICHIT'06 IEEE, 2006    W   W a n, and G. Dobbie Extr acting association rules from XML documents using XQuery,” in Proc. of the 5th ACM Int. Workshop on Web Information and Data Management \(WIDM’03 2003, pp.94–97  e iss, N Indurkhya, T. Zhang and F. Damerau TEXT MIN ING Predictive Methods for Analyzing Unstructured Information Springer Science-business Media, Inc. 2005  Li a nd T. Leong, “Automated kno wledge extraction for decision model construction: A data mining approach AMIA  Annual  Symposium Proc pp. 758-762, 2003  2009 bMed website [Online]. Available http://www.ncbi.nlm.nih.gov/pubmed  


To resolve this problem, we proposed a new KDD model. It consists of two steps: the first organizes the database records in homogeneous clusters having common properties which permit to deduce the data’s semantic. This step consists of TAH’s and MTAH generation of relieving attributes. The second permits to Discovering Knowledge. It consists to deduce the Fuzzy  Cluster Lattice corresponding to MTAH lattice generated in the first step, then traverse this lattice to extract the Meta Knowledge \( Set of fuzzy associations meta-rules on the clusters \, and in end deduce the rules modeling the Knowledge \(Set of fuzzy associations rules on the attributes\While basing on the hierarchical structure offered by the lattices, we proceed to discover the Knowledge in a hierarchical way. Thus, according to the degree of detail required by the user, this approach proposes a level of knowledge and different views of this knowledge Moreover, this solution is extensible; the user is able to choose the fuzzy method of classification according to the domain of his data and his needs This solution reduced considerably the number of generated rules, offered a better interpretation of the data and optimized both the space memory and the execution time As futures perspectives of this work, we mention 1\o test our approach on several the large data set, and 2\ to define a new intelligent method of evaluation of requests which takes into account the Meta knowledge and/or the knowledge base generated by our KDD model XI  R EFERENCES  1  P. Berkhin, “Survey of clustering data mining techniques“, Technical report, Accrue Software, 2002 2  M. Zaki, “Mining Non-Redundant Association Rules”, Data Mining and Knowledge Discovery, No 9, 2004, p. 223–248 3  G. Stumme, R.Taouil, Y. Bastide, N. Pasquier, and     L. Lakhal Intelligent structuring and reducing of association rules with formal concept analysis”, Proceedings of KI’2001 Conference, Vienna Austria, Lecture Notes in Artificial Intelligence 2174, SpringerVerlag, September 2001, p. 335–350 4  N. Pasquier “Data Mining : Algorithmes d'Extraction et de Réduction des Règles d'Association dans les Bases de Données”, Thèse Département d’Informatique et Statistique, Faculté des Sciences Economiques et de Gestion, Lyon, 2000 5  R. Agrawal, T. Imielinski, and Swami A., “Mining Association Rules between sets of items in large Databases”, Proceedings of the ACM SIGMOD Intl. Conference on Management of Data, Washington USA, June 1993, p. 207-216 6  R. Agrawal, and R. Skirant. “Fast algoritms for mining association rules”. In Proceedings of the 20th Int'l Conference on Very Large Databases, pages 478-499, June 1994 7  N. Pasquier, Y. Bastide, R.Taouil, and L. Lakhal,          “ Efficient Mining of Association Rules Using Closed Itemset Lattices Information Systems Journal, vol. 24, no 1, 1999, p. 25-46 8  M. J. Zaki, and C. J. Hsiao, “ CHARM : An Efficient Algorithm for Closed Itemset Mining ”, Proceedings of the 2nd SIAM International Conference on Data Mining, Arlington, April 2002, p. 34-43 9  G. Stumme, R. Taouil, Bastide Y., Pasquier N., and L. Lakhal, “Fast Computation of Concept Lattices Using Data Mining Techniques BOUZEGHOUB M., KLUSCH M., NUTT W., SATTLER U., Eds Proceedings of 7th Intl. Workshop on Knowledge Representation Meets Databases \(KRDB’00\Berlin, Germany, 2000, p. 129-139 10  G. Stumme, R.Taouil, Y. Bastide, N. Pasquier, and     L. Lakhal Computing Iceberg Concept Lattices with TITANIC”, J. on Knowledge and Data Engineering \(KDE\ vol. 2, no 42, 2002, p. 189222 11  S. Ben Tekaya, S. Ben Yahia, and Y. Slimani. “Algorithme de construction d`un treillis des concepts formels et de détermination des générateurs minimaux”, ARIMA journal, Novembre 2005, Numéro spécial CARI'04, pages: 171-193, 2005 12  T. Hamrouni, S. Ben Yahia, and Y. Slimani. “Prince : Extraction optimisée des bases génériques  de règles sans calcul de fermetures In Proceedings of the Intl. INFORSID Conference, Editions Inforsid Grenoble, France, pages : 353--368, 24-27 May 2005 13  B. Ganter, and R. Wille, Formal Concept Analysis: mathematical foundations. \(translated from the German by Cornelia Franzke Springer-Verlag, Berlin-Hei delberg 1999 14  T.Thanh, H.Siu Cheung, and C. Tru Hoang, “A Fuzzy FCA-based Approach to Conceptual Clustering for Automatic Generation of Concept Hierarchy on Uncertainty Data.” ,CLA 2004, pp. 1–12 ISBN 80-248-0597-9 15  L. Zadeh. Fuzzy sets. Inform ation and Control, \(69\338-353, June 1965 16  M. Sassi, M., A. Grissa Touzi, and H. Ounelli, “ “Interpretting Fuzzy Clustering Results based on Fuzzy Formal Concept Analyis”, IEEE International Conference on Fuzzy Systems. Imperial College London, UK, 2007 17  A. Grissa Touzi, M. Sassi, and H. Ounelli,  “Using Formal Concept Analysis for Flexible Querying Optimization”, 23nd International Conference on Computers and Their  Applications, \(CATA’08 Mexico, Avril 2008 18  A. Grissa Touzi, M. Sassi, and H. Ounelli, “An innovative contribution to flexible query through the fusion of conceptual clustering, fuzzy logic, and formal concept analysis”, International Journal of Computers and Their Applications. Volume. 16, N°. 4, pp 220-233, December, 2009 19  M. Sassi, A. Grissa Touzi, and H. Ounelli, “A Fuzzy Linguistic Database Summarization Approach”, Fuzzy Systems Conference IEEE International Conference on Fuzzy Systems.   Hong Kong, Juin 2008 20  J.C,  Bezdeck,  R.Ehrlich,  and  W.Full,  "FCM: The Fuzzy  C-Means Clustering Algorithm", Computers and Geoscience, vol. 10, no. 2-3 pp. 191–203, 1984 21  N. Pasquier, Y. Bastide, R.Tou il, and L.Lakhal, “Pruning closed itemset lattices for association rules”, Proceedings of 14th International Conference Bases de Données Avancées, Hammamet Tunisia, 26–30 October 1998, p. 177–196 22  M. J. Zaki, “Generating Non-Redundant Association Rules Proceedings of the 6th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Boston, MA, August 2000, p 34-43 23  Y. Bastide, R.Taouil, N. Pasquier, G. Stumme, and L.Lakhal Mining frequent patterns with counting inference”, SIGKDD Explorations, vol. 2, no 2, 2000, p. 66-75 24  B. Ganter, “Two basics algorithms in concept analysis”, Technical report, Darmstadt, 1984 
134 


   


                        






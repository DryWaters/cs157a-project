Wrist SmartPhone Kranz Mathematics assau y forename.surname@uni-passau.de Ferscha Computing ersity Austria e.at Abstract vide wadays ositioning indoor ence 
the a on ork accurate orld printing techniques of e system ords 
ositioning Computing I N important SmartHomes auused f 2 3 SmartHomes autonomously the a o and 
reliable of can comconditioning the appliames security The v ast majority of today s indoor their and utilize with 
usable settings be y cona gligible R D W K clustered oning ii proximity sensing 6 iii triangulation i v trilateration 7 and v 002ngerprinting analysis The use of W i-Fi signals for positioning 
years mainly APs spot ed estimation RSSI database One admanabhan  The y proposed an in-b uilding user location and tracking data error 
a ed as al By using the b uilt-in orientation the 1.82m E T D N be fully e daily room 
is 10 m 2 least 3 002 3 m our i-Fi which reliable 3m 9 10 11 
The Third IEEE International Workshop on Sensing Systems and Application\s Using Wrist Worn Smart Devices, 2017 978-1-5090-4338-5/17/$31.00 \2512017 IEEE 


indoor Android reuse if The permanently and location that not pros II a i-Fi settings for ienabled an werline into wer thus i-Fi the I I T S mini 4.1.2 A9 RAM 4\224 the information pro vided by most of the information training we in assamples north vice samples of 3 002 24 samples data i-Fi or between orientation OS II M O S T W H P D C S possible a SmartPhone e The scan report i-Fi 11 100dBm SmartPhone magnetic as SmartPhone elopment e on is III-A III D H S T P L  036   013   f  north 315 016  45 016 east 45 016 024  135 016 south 135 016 024  225 016 west 225 016 024 036 024 315 016 000 60 016  60 016 000 45 016  45 016 vice the same SmartPhone same of distinguish atch the V Extension atches enabled that 1 iFi The Third IEEE International Workshop on Sensing Systems and Application\s Using Wrist Worn Smart Devices, 2017 


IV D H S T P L  036  013  f  north 315 016  45 016 east 45 016 024  135 016 south 135 016 024  225 016 west 225 016 024 036 024 315 016 care f 000 45 016 or f 025 45 016 V D H S T W H Acceleration a z comment 0 a z 025 6  0 m=s 2 alignment the y 1 a z  6  0 m=s 2 alignment looking ays the positioning needed i3-axis detect change is record our using i-Fi from 1 R S study system indoor ery rooms indoor Fig ed used with  2 002 2 m and 3 002 3 m aluate approach gy s classi\002er crosseka wing omitted  NaiveBayes   1  presented arm VI  L a   P PolyKernel 1.0  A R first-last  M 2 10-fold dataset ariance e the Medium with 3 002 3 m boxplot it the samples location on data The alue is 000 45 m range ference is SmartPhone erformance test 10The Third IEEE International Workshop on Sensing Systems and Application\s Using Wrist Worn Smart Devices, 2017 


of 3 002 3 m  atch presents with 3 002 3 m correct for The the setup only pointing the of classi\002cations Orientation ered information Orientation The the mode 4,3 used only of 025 95 as of 3 002 3 m test with 2 002 2 m only of 71  1 tested size the House the bigger training dataset prediction from 68  9 to 87  5 comlocations Summary the positioning test 002ngerprint 3 ferent y Medium of 3 002 3 m use get  95 positioning table s to analysis found the The Third IEEE International Workshop on Sensing Systems and Application\s Using Wrist Worn Smart Devices, 2017 


with/without  test types ays for medium of 3 002 3 m results the House demonstrated size form positioning the arm i-Fi outdoors and typically iAPs the arm the of 10 002 10 m the SmartPhone atch thus that  C N our i of ol information the Medium at least 3 002 3 m minimum is 10 m 2 than 3 002 3 m hat least a usautomatic run-time a feasible once users ii of  the The Third IEEE International Workshop on Sensing Systems and Application\s Using Wrist Worn Smart Devices, 2017 


VI S S  size SmartPhone ea 3AP Comment arm 30 002 80 m 2400 m 2 10 002 10 m 100 m 2 82  5%\(73  74  6%\(69  56  2%\(51  1 Not locations ge 10 002 20 m 200 m 2 2  5 002 2  5 m 6  25 m 2 41  1%\(40  36  9%\(33  27  7%\(28  1 too ge APs 2 002 2 m 4 m 2 63  9%\(68  56  5%\(66  47  1%\(63  8 issues House 10 002 16 m 160 m 2  2 002 2  4 m 2 83  5%\(87  79  3%\(86  73  2%\(81  1 been form 6 2 002 2 m 4 m 2 67  1%\(70  53  5%\(67  35  0%\(61  2 of 2 002 2 m small Medium 6 002 6 m 36 m 2 3 002 3 m 9 m 2 91  1%\(96  86  3%\(95  75  7%\(93  6 4 002cient Small 3  5 002 3  5 m 12  25 m 2 1  75 002 3  5 m 6  13 m 2 98  97  2%\(99  91  3%\(97  8 has locations SmartPhone most 5 APs the able a 36 m 2 ith  95 using 3 002 3 m s in m 2 use of of 3 m  X AP  A 10 1 1 e A in m 2  002nfor limitations  030 Home gy this is seen for SmartPhone This vides positioning ger at be et has accurate orld is manatch As  implementations that personsensor platform R S  G Hoelzl M K urz P  Halbmayer  J Erhart M Matschek o A Ferscha rubber in utonomic USA 2012  G Hoelzl A Ferscha P  Halbmayer  and W  Pereira 223Goal oriented in on and September 2014  P  Halbmayer  G Hoelzl and A Ferscha 223 A dynamic service module in 6th and Italy 2014 79\22684  G Deak K Curran and J Condell  223 A surv e y of act i v e and passi v e 224 Communications 16 2012  H Bao and W C W ong 223 An indoor dead-reck oning algorithm with in Computing International 1534\226 1539  R W ant A Hopper  V  F alcao and J Gibbons 223The acti v e badge 224 OIS  1992  H M Khoury and V  R Kamat 223Ev aluation of position tracking 224 Construction 2009  Y  Luo O Hoeber  and Y  Chen 223Enhancing wi-\002 002ngerprinting for 224 HumanSciences 2013  P  Bahl and V  P admanabhan 223Radar an in-b uilding rf-based user in Annual Societies IEEE ol.2  E Chan G Baciu and S C Mak 223Orientation-based wi-\002 positioning in NetInternational on 392\226397  Y  Chen and H K obayashi 223Signal strength based indoor geolocation 224 in ence on 436\226439 The Third IEEE International Workshop on Sensing Systems and Application\s Using Wrist Worn Smart Devices, 2017 


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination EEE   7  crafted-feature-based methods. However, the lack of seman tic information provided by the category labels cannot guarantee the best discrimination ability between classes because unsupervised feature learning methods do not make  formance, we still need to use labeled data to develop super vised feature learning methods, which will be reviewed below, to extract more powerful features s Most of the current state-of-the-art approaches generally feature representations. Especially in 2006, a breakthrough in deep feature   engineered features with trainable multilayer networks and impressive feature representation capability for a wide range of appli  13], [17], [45], [50], [82], [143]\226[158 On the one hand, in comparison with traditional hand crafted features that require a considerable amount of engi neering skill and domain expertise, deep learning features are automatically learned from data using a general-purpose learning procedure via deep-architecture neural networks This is the key advantage of deep learning methods. On the other hand, compared with aforementioned unsupervised shallow-struc tured models \(e.g., sparse coding that are composed of multiple processing layers can learn more powerful feature representations of data with multiple levels of abstraction [159]. In addition, deep feature learning methods have also turned out to be very good at discovering intricate structures and discriminative information hidden in high-dimensional data, and the features from toper lay ers of the deep neural network show semantic abstracting properties. All of these make deep features more applicable Currently, there exist a number of deep learning mod   convolutional neural networks \(CNNs   on. Limited by the space, here we mainly review two widely  deep learning methods 1  model that has been successfully applied for remote sens  of multiple layers of autoencoders in which the outputs of each layer are wired to the inputs of the successive layer. To   layer on raw input data to obtain parameters and transfer the raw data into an intermediate vector consisting of activa tions of the hidden units. Then, this process is repeated for subsequent layers by using the output of each layer as input the parameters for the remainder of the model. To obtain better results, after  to tune the parameters of all layers at the same time with a smaller learning rate. Compared to a single autoencoder as mentioned in the previous subsection, the feature repre  This can be easily explained: with the composition of multi ple autoencoder that each transforms the representation at one level \(starting with the raw input at a higher, slightly more abstract level, we can learn very powerful representations. This has been proven in literature 13], [134], [169]\226[171 2 CNNs are designed to process data that come in the form of multiple arrays, for example, a multispectral image composed of multiple 2-D arrays containing pixel  the impressive success of AlexNet [163], many representa   been proposed in the literature. There exist four key ideas behind CNNs that take advantage of the properties of natu ral signals, namely, local connections, shared weights, pool ing, and the use of many layers [159 The architecture of a typical CNN is structured as a series of layers 1   Convolutional layers: They are the most important  edges lines, and corners features \(such as structures objects, and shapes 2   Pooling layers: Typically, after each convolutional layer, there exist pooling layers that are created by computing some local nonlinear operation of a par ticular feature over a region of the image. This pro cess ensures that the same result can be obtained even when image features have small translations or  tion and detection 3   Normalization layers: They aim to improve generali zation inspired by inhibition schemes presented in the real neurons of the brain 4   Fully as  straints, they can better summarize the information  decision. As a fully connected layer occupies most of  vent this, the dropout method was employed   163 


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination 8   EEE  CNNs in various remote sensing applications, such as geo      For instance, to address the problem of object rotation vari ations, Cheng et al       explicitly enforces the feature representations of the train  each other. Castelluccio et al 152] and Nogueira et al       best performing strategy on small-scale data sets V   T  T   dedicated toward the construction of various data sets [9], [11], [17], [33], [38  tion. Despite the remarkable progress made so far, as we  all existing remote sensing image data sets have a number of of scene classes numbers the lack of scene variations and diversity, and the saturation  popular UC Merced data set with deep CNN features [82 These limitations have severely limited the development of new data-driven algorithms and also prohibited the wide use of deep learning methods because almost all deep learning models are required to be trained on large training data sets Under such a circumstance, proposing a large-scale data set with big image variations and diversity is highly desirable   which is a freely and publicly available benchmark data set 5 t                 data set. These 45 scene classes are as follows: airplane, air port, baseball diamond, basketball court, beach, bridge, chap     overpass, palace, parking lot, railway, railway station, rec   court, terrace, thermal power station, and wetland   form, including land-use and land-cover classes \(e.g., commer cial area, farmland, forest, industrial area, mountain, and resi    ice terns, some homogeneous with respect to texture, some homo geneous with respect to color, others not homogeneous at all t    includes 700 images with a size of 256     256 pixels in the red\226   except for the classes of island, lake, mountain, and snow         Earth by the superimposition of images obtained from satel       shows two samples of each class from this data set   1        and publicly available benchmark data set, which covers 31   500      


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination EEE   9 ig. 2 eathers anslation c 


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination 10   EEE     the state of the arts 2 image variations  system, be it human or machine. However, most of the existing data sets are not very rich in terms of image vari ations. On the contrary, our images were carefully selected condi tions, imaging conditions, and scales. Thus, for each scene category, our data set possesses much rich variations in translation, viewpoint, object pose and appearance, spatial resolution, illumination, background, occlusion, etc 3 Similarity Many top-performing methods built upon deep  accuracy on most of the existing data sets owing to their sim plicity, or rather the lack of variations and diversity. With this in mind, our new data set is rather challenging with high within-class diversity and between-class similarity. To of conditions  and rectan basket ball court and tennis court, and so on V   B  S    s        Color histograms histograms is almost the simplest handcrafted feature that has been   because of its simplicity. Each channel is quantized into  64 bins for a total histogram feature length of 192. The his tograms are normalized to have an L1 norm of one 2   frequencies of local patterns in subregions. For an image, it   N   neighbors: when the neighbor\222s value is bigger than the value of center pixel output 1, otherwise, output 0. This forms an   N   decimal  obtained by computing the histogram of the decimal num bers over the image and results in a feature vector with   2   N     dimensions. In our implementation, we set   N     8   hence 3      is then averaged over 16 nonoverlapping regions arranged on a   4 _  _  4   grid. The resulting image representation is a 512-dimensional feature vector 4  popular visual features during the last decade. Owing to its  widely used by the community for geographic image clas  a   Patch extraction: With an image as input, the out puts of this step are image patches. This step is implemented via sampling local areas of images in a dense or sparse manner b   Patch the outputs of this step are their feature descriptors such as the c   Codebook generation: The inputs of this step are feature and the output is a visual codebook. The codebook is usually formed by unsupervised   k   means clustering over all feature d   Feature encoding: Given feature descriptors and codebook as input, this step quantizes each feature descrip tor into a visual word in the codebook e   Feature pooling: This step pools encoded local descriptors into a global histogram representation for each image 5 SPM     then concatenates them to represent the image. In our implementation, we divide each image into   1 _  _  1   and   2 _  _  2    subregions. Thus, given a codebook with the size   K   we can obtain a   5 K   dimensional feature vector for each image by 6 LLC variation of sparse coding       


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination EEE   11 simply by   k   means clustering without optimization. Therefore  7  Krizhevsky et al and was the winner of ImageNet large-scale     layers follow both response normalization layers and the   employ nonsaturating neurons, GPU implementation of the  feature from the second fully connected layer, which results in a feature vector of 4096 dimensions 8     former one because of its simpler architecture and slightly   CNN feature was also extracted from the second fully con nected layer to obtain a feature vector of 4096 dimensions 9 GoogLeNet is another representa tive CNN architecture that achieved new state of the art for  The main hallmark of its architecture is the improved utili  carefully crafted design, the depth and width of the network were increased while keeping the computational budget con of  more spatial information; and b to over  inside has 12 times fewer parameters than AlexNet. In our work, we extracted the GoogLeNet CNN feature from the last pooling layer to form a feature vector of 1024 dimensions 10    obtain better performance without using any data augmenta      gress while not clobbering the initialization p To make a comprehensive evaluation, two training\226test ran domly split into 10% for training and 90% for testing \(70 training samples and 630 testing samples per class 20%\22680%: the data set was randomly divided into 20% for training and 80% for testing \(140 training samples and 560 testing samples per class   each image patch with the patch size set to be   16 _  _  16   pix els and the grid spacing to be 8 pixels to balance the speed of 86]. The sizes of visual codebooks were set to be 500, 1000 2000, and 5000, respectively, to study how they affected the  GoogLeNet model, which were pretrained on ImageNet  caffe/wiki/Model-Zoo for deep CNN feature extraction To further improve their generalization capability, we also  Table   2. All three CNN models were implemented on a PC       C     1        scene class by treating the images of the chosen class as posi  s There exist three widely used, standard evaluation met   able 2    


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination 2   EEE  which class they belong to, divided by the total number of   matrix is an informative table used to analyze all the errors and confu sions between different classes which is generated by count  test samples and accumulating the results in the table the same image number per class, so the value of overall accu this paper, we just used the metrics of overall accuracy and  addition, in order to obtain reliable results for the metrics of overall accuracy and confusion matrix, we repeated the and report the mean and standard deviation of the results ts            all based on these optimal parameter settings Tables 3\2266 show the overall accuracies of three hand crafted global features, three unsupervised feature learning  CNN features, respectively, under the training ratios of 10 and 20%. The following can be seen in Tables 3\2266 1   Handcrafted low-level features have the relatively    tures. Actually, they act as mid-level image features that are ig. 3 W+SPM, and  0%; and  able                 


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination EEE   13  hence provide more semantic and more robust represen  semantic gap 3   Deep CNN features outperform all handcrafted features and unsupervised feature learning methods in very big margins \(at least 30% performance improvement  This demonstrates the huge superiority of the current-dom inated deep learning methods in comparison with previous state-of-the-art methods   els, the accuracy was further boosted by at least six percent age points, resulting in the highest accuracy matrices of different methods under the training ratios of 10% and 20%, respec tively, where the entry in the   i   th row and   j   th column denotes the rate of test samples from the   i   as the   j   th class. Limited by the space, we here just report the confusion matrices with the highest overall accuracies selected from features unsupervised feature learning methods, CNN features, and  the following 1 per-class accuracies, unsupervised feature learning methods take the second place, and deep-learning-based CNN features have the highest per-class accuracies 2 sions happen between \223golf court\224 and \223meadow\224 because they are characterized by green color  relatively big confusions happen between \223church\224 and \223pal    may be deep-learning-based methods in combination with dis criminative attributes oriented methods such as [23 I   ON            ig. 4 6 6 


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination 14   EEE        future research    cover in a given region. In fact, the more recent develop    of social media especially the online photo sharing web  collecting sorts of information of ground objects from geo                   Earth using the \223what\224 and \223where\224 aspects of the infor  the ground photos uploaded by user hold higher resolu    additional information is in fact very useful for the classi    future work, we need to explore new methods and sys  information coming from social media and spatial tech     6 6 


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination EEE   15 S            2   H    EEE      3   L   e  EEE      4   P l  EEE        224  s      6   G d                   l 224        9   L gs         r  s        224          s          s       l  s       e         e r 224       7   Q  r 224            g h 224 s        d         h       1   J i l r         2   G  l e  224        l            e   t                6   A e 224        7   G  d n          a l  e         h s         264  264 l g  e                    f 224          e          h          n   s       n                  e         224  t 0    0   M   224    0        t     2   R             g   s      4   G g l e  224        5   G g   224  s   


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination 16   EEE   6   J  e d 224      7   J n l s  d 224           n 224 g      r 224        n d 224        l 224         n l       3   Y g l     s       4   Y   d y  s                 e 224 n P         224        d g 224 e       9   L d d    226       224         g  g      2   E l e  e                4   M  c s    s        224        y  m         e d  e        224       9   L t 224          T S       e  0     tr g s       l d 224         n  a       d n e      g 224 y         n y           s      x         0   H  n d a 224   0     e        2   O s  l n  s        n  S      4   L  n y 224 s       s        n 224 s                   e  g      9   L e s   s       s  g         e  e    


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination EEE   17      e  224         l  h          224 s      264  264 d e           224 h        g y         d e   a                e 224        r n            e       3   G   e   t  1     e  n        g 224       6   T   l 224        7   A e c 224        8   D            t         t         n o l      224 s       224 s         n  t  3         7    6   C e    g      7   G    n          n n 224          d 224  s          224  s      n  224 n e      2   L D e         224         e          r e  e        d    t      g 224        e          r   s       r 224           224 s      2   W    224 s        g e e          e       5   I  s        A  s   


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination 8   EEE     h  e       p 224 s       d 224 n          224        1   G t g  e      2   J  r n   t      l  224 s          e       5   I c 264  t 224         l                  8   Y e  l        9   D            0   M d  g  e       A 224         l e A v a i l a b l e  2    3   K    6 n  A v a i l a b l e  h t t p s   a r x i v o r g  7    4   G r  n   t       g     0      224 n a       g 224        n   s        e       f  ut        r   ut        l h a   s  0     p   t            nt       n  nt      l h   t                  f n l  0      n  o   5                224        n  t      n    s       l n  t       e n E t       224    1 


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination EEE   19 S Gong Cheng om Xidian  in 2007 and the M.S. and technical  3   He is currently an Associate Professor with Northwestern Polytechnical University. His main research interests are computer vision and pat tern recognition ei Han ently techni ch The ersity cher at the Uni His omputer vision, multi and brain imaging analysis. He es such as IEEE T C t T IONS  ON P A t t T ERN  A A YSIS  AND M CHINE  I I N t T ELLIGENCE AMI I I N t T ER NA t T IONAL J OURNAL  OF  C C O m p MP U t T ER V ISION V T C t T IONS  ON  I I m M GE P SSING  TIP C C ONFERENCE  ON  C C O m p MP U t T ER V ISION  AND P A t t T ERN  R R OGNI t T ION VPR I I N t T ERNA t T IONAL  C C ONFERENCE  ON  C C O m p MP U t T ER V ISION V I I N t T ERNA t T IONAL J OIN t T  C C ONFER ENCE  ON  A A R t T IFICIAL  I I N t T ELLIGENCE IJCAI Prof. Han is an Associate Editor of the I E E E IEEE T RANSAC t T IONS  ON  H H U m M AN M ACHINE  S S YS t T E m M S  Neurocomputing   Processing and Machine Vision and Applications  u ently f  tor ests include emote sensing om e eas  international journal, including Neurocomputing Elsevier Cognitive  Computation Springer International Journal of Image and Graphics  World of Scientific 



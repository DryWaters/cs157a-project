Aarti Sathyanarayana, Jaideep Srivastava, and Luis Fernandez-Luque 
Qatar Computing Research Institute 
COMPUTER 
 PUBLISHED BY THE IEEE COMPUTER SOCIETY  0018-9172/17/$33.00 \251 2017 IEEE 
Lack of sleep can erode mental and physical well-being often exacerbating health problems such as obesity 
30  
Wearable devices that capture and analyze sleep quality through predictive methodologies can help patients and medical practitioners make behavioral health decisions that can lead to better sleep and improved health 
ith the increased pace of daily living sleep has become essential to academic and workplace performance. Sleep depri vation can result in catastrophic events 
W 
for those in professions that require high accuracy and safety levels, such as construction crane operators or school bus drivers, and driving in general can be danger ous with little or no sleep. In the US alone, an estimated 037\036\035,\035\035\035 sleep-related collisions per year result in \036,\034\035\035 fatalities and cost \033\036\032 billion 036 Studies also con\031rm that lack of sleep worsens a variety of health problems\227 
from obesity, diabetes, and sleep apnea to Alzheimer\222s and cancer 030\027\034 Other studies show that sleeplessness is becoming more widespread 026 In light of these \031ndings, systematic sleep studies have become a high priority. Sleep science is a multi disciplinary research area, with contributions from endo crinology, pulmonology, and public health. Increased 
knowledge of the importance of sleep is fostering the inclusion of sleep education \(also known as sleep hygiene as part of patient education for diseases such as diabetes 025  In addition, healthcare providers are developing appli cations that act as sleep coaches for cancer patients 034 and otherwise healthy people with sleep disorders 
032,\024 In all these developments, technology is proving to be a crucial element in sleep health\227particularly wearable devices Wearables are unique in that they spread sleep aware ness beyond clinicians and researchers to include the 
The Science of Sweet Dreams: Predicting Sleep E\037ciency from Wearable Device Data 


Bioelectromagnetics www.computer.org computermultimedia  The next three decades saw an explo sion of sleep knowledge and insights into sleep characteristics, which led to a new era in sleep science and its clinical aspects. In \034\030\026\025, G.W. Vogel observed that narcolepsy patients have di\032erent EEG patterns during sleep as compared to healthy subjects. By the mid 034\030\025\025s, sleep laboratories began to appear that were dedicated to studying sleep related disorders such as rest less legs syndrome, sleep obstructive apnea, narcolepsy, and insomnia These labs resulted in more sys tematic sleep studies and the evo lution of polysomnography \(PSG\, a sleep study methodology that incor porates various sensor to capture brain activity, leg movement, oxygen saturation, breathing frequency, and snoring 034\024 Although it is a major diag nostic tool that is considered the gold standard for sleep research, PSG is performed only in sleep laboratories in hospitals. During a PSG test, the patient spends at least one night in the unnatural environment of a sleep lab oratory monitored by a clinician and attached to multiple sensors. On one hand, PSG is a high 027delity test; on the other hand, it is challenging to scale too expensive for many individuals does not consider physical activity which is tightly linked to sleep quality and does not provide insights into the patient\222s behaviors in a natural envi ronment or during daily routines. As a result, PSG cannot keep pace with the growing number of sleep disorders and large segments of the population still su\032er from inadequate sleep 31 SLEEP SCIENCE\222S EVOLUTION  See  for 037 multimedia content related to this article      Early sleep studies Wearable devices provide the \027rst hope of solving these problems because they can be used to study sleep and physical activity for longer periods and outside the laboratory or hospital. Because a wearable moni tors the patient\222s body continuously collected signals can be used to deter mine sleep quality and screen for sleep disorders Actigraphy devices, such as the GT\024X from ActiGraph \(actigraph  corp.com/support/activity monitors  gt\024x\, are clinical grade wearables approved for sleep studies that use inertial sensors to collect physical activity and sleep data. As of mid  January \033\025\034\031, actigraphy was being used in more than \034\025\025 clinical trials registered in the US clinical trials database \(www.clinicaltrials.gov\. In many applications, actigraphy can be a cheaper and simpler alternative to PSG, and actigraphy devices are already advancing sleep science in areas such as obesity, diabetes, can cer, and mental and public health Machine learning applied to actigra phy data is widely used to study sleep patterns and characteristics 036\035\034\034 million users who rely on health appli cations to track their physical activity and sleep. These users often integrate their physical activity and sleep data in mobile health repositories, such as Apple\222s HealthKit\227which can subse quently be integrated into electronic health records \(EHRs\. Consequently the study of sleep e\037ciency is becom ing a data science problem Traditional sleep analysis based on wearables\222 data is limited in scale and cannot keep pace with the explosion of wearable use for health monitor ing and analysis 036\035\034\034 To address this scale problem, we conducted a study to explore an innovative approach that combines deep learning with an algo rithm that automates human activ ity recognition \(HAR\o predict sleep quality from wearables\222 physical activ ity data 034\033 Because our approach can scale to the wide deployment of sleep data analytics based on wearables, it can serve as the foundation for tools that noninvasively screen for sleep disorders, diagnose their nature, and identify the lifestyle factors a\032ecting a particular disorder We conducted a series of exper iments to statistically compare our approach with the traditional approach of actigraphy combined with a sleep expert\222s annotations\227the cur rent technique for studying sleep and physical activity patterns from a wear able motion sensor that tracks an indi vidual\222s activities. Relative to this sleep expert, our approach showed up to a twofold improvement in the area under the curve \(a statistical predictor of best model\. These results are evidence that our method can greatly enhance \(and  perhaps even revolutionize\pplica tions that assist patients and medical practitioners in making critical behav ioral health decisions For centuries, researchers have been exploring the elements of sleep. In published in \034\031\030\034 Luigi Galvani explained how electric currents from neurons passed signals to active muscles in frogs. His work relating electricity to the nervous sys tem eventually led to Hans Berger\222s 034\030\033\030 report of the \027rst human electroencephalograms \(EEGs\or brain study. A decade later, Alfred L. Loomis published a study describing di\032er ent EEG patterns during sleep, which became the basis for de\027ning sleep stages. Gradually, new signals evolved to characterize other sleep aspects such as rapid eye movement \(REM Actigraphy and \037rst wearables MARCH 2017 


COMPUTING CHALLENGES New wearables, new possibilities Area Subcategories Potential contribution Computing areas that can enhance sleep science computer interaction New insights into the role of human factors, such as usability, in adopting complex health technologies to analyze and treat sleep-related disorders, which typically involve multiple stakeholders and a range of patient behaviors Electronics, wireless communication, and embedded systems Pervasive and ubiquitous computing, wireless sensor networks, the Internet of Things \(IoT Design/development of sensors and actuators to capture contextual information about sleep, including integration of sensors in a body area network and in the IoT Biomedical engineering and medical devices Development of novel medical devices to monitor sleep and aid sleep-disorder treatment Machine learning and AI Machine learning, pattern recognition, real-time analysis and event recognition New insights into sleep that will help disease and disorder diagnosis, prognosis, and treatment Data storage and curation Data quality and management \(annotation, validation redundancy, and so on New techniques for data annotation and for handling duplications Security to ensure data privacy, including anonymization in clinical studies Advanced anonymization techniques and security that can prevent the use of biosignals such as an electrocardiogram \(ECG Data interoperability and semantic integration, data fusion Techniques that enable semantic interoperability and the subsequent integration of sleep data that is currently in various silos, such as electronic health records \(EHRs\and \037tness companies Applications and services Data visualization Novel visualization techniques that can facilitate the understanding of sleep data sources with complex multidimensional and temporal characteristics User modeling and adaptation of applications for consumers and professionals Data-driven approaches for developing more personalized applications\227for example, recommender systems\227that support decision making for patients\222 such as sleep coaches\ and clinicians \(such as clinical decision support systems Human factors and human The importance of data for health research has become mainstream in recent years, and sleep science is no exception. The National Institutes of Health \(NIH\reated the National Sleep Research Resource 035\034,\035\033 a portal aimed at integrating heterogeneous data sources for clinical sleep research www.sleepdata.org\. The portal, part of the well-known Big Data to Knowl edge \(BD\032K\nitiative, contains a wide variety of datasets for sleep research COMPUTER   WWW.COMPUTER.ORG/COMPUTER TABLE 1 Sleep analytics is no longer restricted to researchers and clinicians, as the pervasiveness of health and well ness applications attests. Millions of people use a\037ordable wearables to track their physical activity and sleep, and companion apps inte grate tracked data into mobile health repositories, such as Apple\222s Health Kit. These repositories enable inte gration with other medical devices such as heart-rate monitors, and even with EHRs. Along with the myriad 036tness trackers and smart watches that can monitor sleep are context sensors, such as Aura from Withings www.withings.com/ca/en/products  aura/sleep-sensor-accessory\, which includes a sensing mat for sleep mon itoring that integrates with the Nest Internet of Things platform \(nest.com to automatically adjust room tempera ture for optimal sleep quality The Apple Watch has an instru ment suite to collect data on various bodily functions, including tri-axial movement and heart rate. The watch seamlessly syncs with iOS devices enabling a variety of applications to use the collected data. With appropri ate permissions, Apple\222s HealthKit API allows queries to the collected data as well as its use in new applications Other smart-device manufactur ers, such as Samsung, have created wearable platforms based on their respective OSs, and specialized wear ables companies like Fitbit have devel oped their own platforms 031 32  


327 Processed data Raw data RAHAR Other HAR methods Human activity recognition \(HAR Sequentia l Deep learning Classical models Other feature-space manipulation Consumer F itbit Clinical ActiGraph Apple Wa tch Jawbone P ebble Aggregated and cross-sectional Consumer T ime-aware recommendation system  for cognitive behavioral therapy C linical Precision medicine through risk strati\037cation  for diagnostic screening Proposed \037ow for capturing and analyzing data from wearables to enhance sleep e\036ciency. Data from wearables is pro cessed using algorithms for human activity recognition \(HAR\ed to classical models such as aggregated and sequential techniques or to deep-learning models. These models then serve as the foundation for consumer and clinical applications. RAHAR Robust Automated Human Activity Recognition algorithm  is small and is signi\037cantly larger Moreover, because the accelerometers or gyroscopes track every movement with equal weight, raw data is noisy Deep-learning models can e\032ec tively handle raw data characteristics but classical aggregated models \(such as linear or logistic regression, support vector machines, and random forest sequential models \(such as sequential pattern mining\, and decision trees also require feature construction to assist in data interpretation. HAR summarizes the behavior of individ uals over the time series into clean interpretable features. Our algorithm Robust Automated Human Activity Correlating wearable-sensed human activity with sleep patterns can pro vide insights to clinicians and indi viduals for the early diagnosis of sleep problems, which in turn can help identify which behaviors directly in\035uence an individual\222s sleep qual ity. In addition to the analysis of actigraphy data in studying sleep characteristics, the development of sensors and pervasive computing solutions enable sleep diagnostics in the home 036\034 As Figure \036 shows, wearables can be clinical or consumer devices. Clinical devices are validated through clini cal trials in which a ground truth has been established. These devices are used for research studies and clinical evaluation. Consumer devices have popular appeal and target a wider audi ence. These devices encourage self monitoring and empower their users to make behavioral changes to improve their \037tness and quality of life Both device types generate volumes of data in real time and at a high veloc ity. For example, a GT\033X wearable gen erates \036\034 Mbytes of data each day for one individual. Analyzing this data to build descriptive and predictive mod els and provide actionable knowledge for practitioners and users is a big data challenge The data consists of features from multiple sensors collected over an extended period. Depending on the analytical goal and thus model type data can be presented in either its raw form or with preprocessing. Raw data generally has a small number of features \(triaxial accelerometers, for example, have three coordinates, gyro scopes have three rotational veloci ties, and so on\ollected at thousands or more points in time. The result is a time series of 33  dimensions, where Application Modeling W earable devices F eature-space construction n n m As consumer health, wellness, and 037tness data combines with EHRs, inte gration is becoming more problematic The demand to fuse information from multiple wearable sensors, such as an accelerometer and heart-rate monitor requires new algorithms. Research is still far from producing fully inte grated smart analytics for hetero geneous sleep-related data sources but as Table \036 shows, computer science can further sleep medicine in multiple ways, particularly in addressing big data analytics, predictive modeling and activity recognition m Big data analysis MARCH 2017 FIGURE \037 


RAHAR: AUTOMATING ACTIVITY RECOGNITION Predictive modeling Sleep-period annotation 34  COMPUTER   WWW.COMPUTER.ORG/COMPUTER Human activity recognition RAHAR begins by detecting the sleep period from the HAR time series which it identi\035es by scanning for periods of no accelerometer move ment. A sleep period is \037\027 continuous minutes of no movement; an awake period is \025\030 minutes of continuous movement. In our sleep experiments each dataset contained a continuous time series \(that is, we told partici pants not to remove the device\, so we used recorded sleep-period eval uation as the ground truth for pre dicting sleep quality. Our evaluation method for predicting sleep quality based on physical activity is based Recognition \(RAHAR\, is a scalable method for extracting knowledge from wearable activity sensors 037\036 Because human movement is a key feature in recognizing activity, many HAR applications construct a feature space from raw triaxial accelerome ter data by labeling portions of a per son\222s physical-activity time series Depending on the application area the activity labels can be activity type sitting, walking, jumping, running and so on\r exertion level \(sedentary light, moderate, vigorous, and so on Multiple activity types might require the same exertion level; conversely the same activity type might occur at di\033erent exertion levels Categorizing raw accelerometer output in this way abridges the fea ture space, which removes noise and summarizes output. It also rebalances data dimensions and can thus improve predictive model quality. Activity cat egories can either be aggregated as percentages over a time segment or be interpreted as an event sequence Current HAR methods have been tested primarily on simulated rather than natural behavior, with most methods using data collected from sen sors attached to an individual in a labo ratory. The participant is instructed to complete a series of preassigned activi ties, and the algorithms scan through the raw sensor data, attempting to identify and label these activities The algorithms require a high level of supervision, do not generalize well to natural daily behavior, and focus on event type rather than exertion level The latter drawback is trouble some because exertion is of particu lar interest in sleep science research which seeks to more fully understand the relationship between physical activity levels and sleep. Researchers have established that physical activ ity and sleep in\032uence the production of many physiological processes, such as hormone production, and thus the relationship can in\032uence important health aspects, such as metabolism and the immune system. In teenagers for example, sleep deprivation is high which can increase obesity and reduce academic performance Scalability and expense are also concerns. In sleep studies, a special ist typically performs HAR on a sin gle individual with the aid of software such as ActiLife\227a process that is impractical and ine\031cient for largescale clinical trials. The Precision Medicine Initiative announced by the Obama administration in \036\030\037\027 was designed to collect genetic, environ mental, and behavioral data from more than a million individuals 037\026 Manu ally annotating wearable data from a cohort this size would be impractical and subject to human error and bias Our motivation for developing RAHAR was to reduce the bottlenecks of ana lyzing wearable data and automate the process of identifying and label ing activity periods based on an indi vidual\222s exertion levels. The resulting HAR data segments can then be used to build predictive models Figure \036 shows RAHAR\222s process for translating raw accelerometer data from actigraphy sensors into output suitable for modeling. Because RAHAR does not require a sleep specialist\222s supervision, it can be built into mobile applications for self-monitoring Predicting sleep quality is import ant for behavior modi\035cation. While an automated version of actigraphy enables interpretation of sleep quality from data collected while the user wore the device to sleep, it would not enable the user to adjust his or her behavior to ensure improved sleep quality. A cognitive behavioral therapy system or application that not only monitors physical activity but also provides rec ommended behaviors can empower users to improve their quality of life Moreover, many users do not like to wear devices while they sleep Clinicians looking to screen their patients for sleep disorders need a high-\035delity prediction model \(such as a deep-learning model\o provide insight before exacerbation 037\034 Addi tionally, using RAHAR in combina tion with sequential pattern mining could help sleep researchers identify behavioral patterns that lead to good or poor sleep. For users who wear their device regularly, data can be collected for weeks or months, thus allowing for personalized pattern identi\035cation and precise sleep treatment 


Change-point detection Steps in the RAHAR algorithm. From wearables\222 raw sensor data, RAHAR detects periods of low activity and uses a state machine to annotate sleep periods, essentially dividing activity time into segments. It then identi\037es the point during wakefulness at which an individual changes activity-exertion levels during wakefulness. The last step is to label activities. RAHAR output is suitable for  a variety of models, from classical prediction to machine learning latency  sleep duration FIGURE \036 In this phase, RAHAR identi\037es changes between activity-exertion lev els within the awake period. To person alize activity segmentation according to the individual\222s unique behavior \(as opposed to generalizing over all par ticipants\, RAHAR uses hierarchical divisive estimation 034\033 in which each change point is the basis for dividing each of the multiple awake periods into subintervals. Each subinterval corre sponds to a physical exertion level Its ability to identify behavior changes speci\037c to an individual makes RAHAR robust to diverse pop ulations. For example, the raw accel erometer output of a physically \037t 036\032-year-old woman and an overweight 031\033-year-old man might be the same but the physical exertion levels would not be interpreted as equal 35  RAHAR output can be used as the feature space for classical models such as logistic regression, that aim to predict sleep quality when activ ity data within the sleep period is not available. Many wearable devices including the Apple Watch\require overnight charging, which precludes the direct tracking of sleep behavior Moreover, machine-learning applica tions require sleep-quality prediction to provide real-time feedback that can change a user\222s behavior to opti mize sleep Ra w data Sleep-period annotation T ime-series segmentation Change-point detection Activity c lassication Output suitable for modeling on sleep science de\037nitions and gold standards 036\035 RAHAR segments the time series at the endpoints of all sleep periods, so each segment contains a period of awake time, followed by a sleep period It then evaluates both the awake and sleep periods to predict sleep quality RAHAR determines each subinterval\222s activity classi\037cation by calculating the statistical mode of labels deter mined by cutpoints 034\036 over each data point in a change-point interval. By automating activity labeling, RAHAR eliminates the need for cumbersome annotation by sleep experts, enabling the widespread evaluation required in large clinical trials Many metrics are suitable for quan tifying sleep quality, such as the time between falling asleep and waking up WASO\, the time spent awake during the sleep period; and  the time between trying to sleep and actually falling asleep. However, sleep e\030ciency\227the ratio of sleep dura tion minus WASO to sleep duration minus latency\227is most the e\027ective sleep-quality benchmark 034\034 because it involves all three metrics To evaluate RAHAR, we conducted a series of experiments to assess its use with traditional machine-learning algorithms and to explore the poten tial of deep learning in sleep-quality prediction. The health and behavioral dataset we used is small enough that additional runtime for training is negligible. Thus, all our results are in terms of predictive performance Our experimental dataset con sisted of data collected in a one-week observational trial involving \035\034 male and female adolescents from ages \036\033 to \036\031. The trial, conducted by Weill Cornell Medical College in Qatar employed the GT\026X, which uses a tri axial accelerometer to collect data on physical activity and sleep features from inertial sensors. The dataset was the seven-day vertical-axis time series extracted from the accelerometer Generalizing our results from this dataset might be problematic, as sleep quality changes across regions and ages. Although our data had a high ratio of teenagers with poor sleep to those with good sleep, that ratio might be di\027erent in other countries In one of our experiments, the goal was to evaluate RAHAR as a tool for constructing features that can be useful for models that attempt to pre dict sleep quality 036\034 Table \034 shows the results of RAHAR in predicting sleep quality versus the traditional approach of using a sleep expert plus ActiLife software \(SE+AL\. We evalu ated the usefulness of activity label ing in SE+AL and RAHAR as input to 037ve models: adaptive boosting, ran dom forest, support vector machines SVM\, and logistic regression. Each model returned a binary classi\037cation through a likelihood score for belong ing to the positive class\227the class Activity classi\037cation Output MARCH 2017 Usefulness in  feature construction Time-series segmentation PREDICTIVE SLEEP EXPERIMENTS wake after sleep onset 


Identifying sleep problems Model AUC\037ROC F1 score Sensitivity Speci\036city SE+AL RAHAR SE+AL RAHAR SE+AL RAHAR SE+AL RAHAR Adaptive boosting 0.7489 0.8132 0.5574 0.6885 0.5484 0.5526 0.7759 0.9333 Random forest 0.8115 0.8746 0.6885 0.7500 0.6774 0.6316 0.8448 0.9333 Support vector machines 0.7497 0.7895 0.3721 0.7077 0.2581 0.6053 0.9310 0.8667 Logistic regression 0.5884 0.8649 227 0.6875 227 0.5789 227 0.8667 AUC\037ROC: area under the curve\037receiver operating characteristic \(measure of best model\. Dashes in metrics for logistic regression denote cases in which results produced uniform classi\036cation predictions ROC curves for predicting sleep e\037ciency using a sleep expert plus ActiLife soft ware \(SE+AL\epresents the traditional method of gauging sleep quality. Although this method is accurate, it is hard to scale to large clinical trials or mass deployment Results for two statistical methods when using a sleep expert plus ActiLife software \(SE+AL\nd the Robust Automated Human Activity Recognition RAHAR\ algorithm as input for models that predict sleep e\037ciency Deep learning can be important in sleep science, primarily for \033rst-pass screening of potential sleep problems which can be con\033rmed by alternative analytics and a clinical encounter with a health professional. Deep-learning models have the best predictive power for estimating sleep quality based on an individual\222s behavior. These high 033delity black-box models can inter pret raw accelerometer data without RAHAR or any preprocessing, reduc ing overall work\032ow. However, these models contain hidden layers and thus are not transparent about the predictive process or any justi\033cation for the output In our experiment to explore deep learning, we used the feature construction experiment dataset and applied deep learning methods 031\035 To train our model to decrease over\033tting we randomly partitioned the dataset 030\037 percent for training and \027\036 percent each for testing and validation Table \035 shows results from feeding raw accelerometer data using logis tic regression as a baseline into four deep-learning models: multilevel per ceptron, convolutional neural net work, simple recurrent neural network RNN\, and long short-term memory LSTM\NN. We also included a timebatched version of LSTM to read the input time series in batches rather than individual epochs. This allows the model to incorporate long-time dependencies in the data without a vanishing gradient 031\035 When the model must be explain able, standard analytic models are more suitable for analysis than deep learning models. These algorithms can predict the expected sleep quality of individuals based on their physi cal activity and provide insight into the contributing factors. This insight COMPUTER   WWW.COMPUTER.ORG/COMPUTER 36  TABLE 2 that represented good sleep quality The threshold was \037.\036. Figures \035 and \034 show the curves of false and true posi tives for SE+AL and RAHAR for each of these models F alse positive rate 1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 0 0.2 0.4 0.6 0.8 1.0 T rue positive rate   Adaptive boosting Logistic regressio n Random forest Support vector machines  Random prediction   FIGURE \037 


vol. \036\025, no. \030 e\036\033\030; doi: \036\032.\035\036\024\025/jmir.\033\031\035\036 030  D.J. Buysse, \223Sleep Health: Can We De\037ne It? Does It Matter?,\224 Logistic regression \(baseline 0.6463 0.8193 0.7083 0.9714 0.7231 Multilevel perceptron 0.9449 0.9118 0.9394 0.8857 0.8929 Convolutional neural network 0.9456 0.9444 0.9189 0.9714 0.9286 Simple recurrent neural network \(RNN 0.7143 0.7711 0.6667 0.9143 0.6607 Long short-term memory LSTM\ RNN 0.8531 0.8500 0.7556 0.9714 0.7857 Time-batched LSTM 0.9714 0.9211 0.8537 1.0000 0.8929 Reads the input time series in batches, allowing the model to incorporate long-time dependencies in the data without a vanishing gradient ROC curves for predicting sleep e\037ciency using RAHAR. Accuracy remains high, and automated activity labeling prevents human error and bias in the volumes of data that wearables generate for a large population REFERENCES  supplement S\033\027S\025, \035\032\032\024 doi: \036\032.\036\032\036\025/j.sleep.\035\032\032\024.\032\034.\032\032\030 033  T. Arora and S. Taheri, \223Sleep Optimi zation and Diabetes Control: A Review of the Literature,\224 Sleep Medicine Using deep learning to predict sleep e\037ciency 37 T Model AUC-ROC F1 score Precision Recall Accuracy  he expanding \037eld of sleep science is a multidisciplinary research area focused on under standing sleep in human health. As sleep science progresses, we can start to understand the link between sleep and many health conditions such as obesity and cancer. In many ways these advancements have been rely ing on the process of engineering and computer science as increasing amounts of data is being captured from new technologies Our analysis, which involved col laborating with practicing sleep sci entists in a clinical setting, ensured that our results were realistic and that they could signi\037cantly impact healthcare practices. Future research will be required to integrate our work in systems for helping professionals and patients with decision making including algorithmic performance human factors and usability, devel opment of pervasive and persuasive applications for behavioral change and generalization of our models in other populations can be leveraged to make recommen dations for behavioral modi\037cation with the goal of improving quality of life. In diagnostic screening, however explanation is not as critical as classi 037cation accuracy, which makes deep learning an excellent screening tool to identify sleep behaviors 036  A. Sassani et al., \223Reducing Motor-Vehicle Collisions, Costs, and Fatalities by Treating Obstructive Sleep Apnea Syndrome,\224   vol. \035\034, no. \033, \035\032\032\031, pp. \031\030\033\027\031\030\026 035  E. Bixler, \223Sleep and Society: An Epidemiological Perspective,\224  vol. \025, no. \031, \035\032\036\030, pp. \031\035\030\027\031\025\026 031  Y.H. Min et al., \223Daily Collection of Self-Reporting Sleep Distur bance Data via a Smartphone App in Breast Cancer Patients Receiv ing Chemo  therapy: A Feasibility Study,\224  Sleep Diabetes Therapy MARCH 2017 FIGURE \037 JMIR mHealth for Data Col lection and Research Sleep F alse positive rate 1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 0 0.2 0.4 0.6 0.8 1.0 T rue positive rate Adaptive boosting Logistic regressio n Random forest Support vector machines  Random prediction TABLE 3 


Journal of Medical Internet Research JMIR mHealth & uHealth Knowledge-Based Intelligent Infor mation and Engineering Systems: Part III UbiComp \035\032 034\033\035\032, pp. \027\036\037\030\027\026\032 036  J.K. Min et al., \223Toss\222n\222Turn: Smart phone as Sleep and Sleep Quality Detector,\224  CHI \035\032\, \034\033\035\032, pp. \032\036\036\030\032\026\027 026  R.J. Cole et al., \223Automatic Sleep Wake Identi\025cation from Wrist Activity,\224 vol. \037\036, no. \035, \034\033\035\032, pp. \031\030\035\036 027  S. Abdullah et al., \223Towards Circa dian Computing: Early to Bed and Early to Rise Makes Some of Us Unhealthy and Sleep Deprived,\224 COMPUTER 38  is a PhD student in the University of Minnesota\222s Department of Computer Science. While conducting the research reported in this article, she was a researcher at the Qatar Computing Research Institute QCRI\at Hamad Bin Khalifa University. Her research interests include deep learning, data mining, machine learning, and health informatics. Sathyanarayana received an MS in computer science from the University of Minnesota. She is a student member of IEEE. Contact her at sathy005@umn.edu is research director of QCRI. His research interests include social computing, health informatics, and machine learning. Srivastava received a PhD in computer science from the University of California, Berkeley He is an IEEE Fellow, a member of ACM and the American Academy for the Advancement of Science, and on the editorial board of Con tact him at jsrivastava@hbku.edu.qa is a scientist at QCRI and cofounder of Salumedia a Spanish digital health start-up. His research interests include health informat ics, mobile and pervasive health, and social media. Fernandez-Luque received a PhD in computer science from the University of Troms\370. He is a member of IEEE and the IEEE Engineering in Medicine and Biology Society \(EMBS\, cochair of the Social Media Working Group in the International Medical Informatics Association, and an editor of the   and Contact him at lluque@hbku.edu.qa Proc. ACM SIGCHI Conf Human Factors in Computing Systems Sleep Medicine: A Com prehensive Guide to Its Development Clinical Milestones, and Advances in Treatment J. Sleep Medicine Clinics J. Statistical Software JMIR Mhealth and Uhealth AAAI \033\024\, vol. \024, \034\033\033\024, pp. \035\024\032\035\030\035\024\032\027 035\035  J. Baek et al., \223Accelerometer Signal Processing for User Activity Detec tion,\224 JAIDEEP SRIVASTAVA  vol. \027\034, no. \036, \034\033\035\024; doi: \035\033.\035\026\027\037\036/jss  v\033\027\034.i\033\036 034\035  R.P. Troiano et al., \223Physical Activ ity in the United States: Measures by Accelerometer,\224 Proc ACM Int\222l Joint Conf. Pervasive and Ubiquitous Computing Sleep Medicine Rev   WWW.COMPUTER.ORG/COMPUTER LUIS FERNANDEZ\037LUQUE Sleep and Biological Rhythms Proc. Conf Applications of Arti\037cial Intelligence New England J. Medicine J. Medicine and Science in Sports and Exercise vol. \037\036\034 no. \031, \034\033\035\024, pp. \036\031\037\030\036\031\024 035\031  A. Sadeh, \223The Role and Validity of Actigraphy in Sleep Medicine: An Update,\224 vol. \035\024, no. \024, \035\031\031\034 pp. \032\027\035\030\032\027\031 031  M. Enomoto et al., \223Newly Developed Waist Actigraphy and Its Sleep Wake Scoring Algorithm,\224 vol. \036, no. \035, \034\033\033\031 pp. \035\036\030\034\034 035\033  N. Ravi et al., \223Activity Recognition from Accelerometer Data,\224 S. Chokroverty and M. Bil liard, eds., Springer, \034\033\035\024, pp. \031\035\030\035\033\033 035\032  D.A. Dean et al., \223Scaling Up Sci enti\025c Discovery in Sleep Medi cine: The National Sleep Research Resource,\224 vol. \037\031, no. \024, \034\033\035\027 pp. \035\035\024\035\030\035\035\027\032 035\024  R. Budhiraja et al., \223The Role of Big Data in the Management of Sleep-Disordered Breathing,\224 vol. \035\035, no. \034, \034\033\035\027 pp. \034\032\035\030\034\024\024 035\027  B. Vandenberghe and D. Geerts 223Sleep Monitoring Tools at Home and in the Hospital: Bridging Quanti\025ed Self and Clinical Sleep Research,\224  vol. \035\035, no. \026, \034\033\035\032, pp. \035\034\033\037\030\035\034\033\031 035\026  F.S. Collins and H. Varmus, \223A New Initiative on Precision Medicine,\224 vol. \035\024 no. \032, pp. \034\024\031\030\034\027\036 034\033  N.A. James and D. Matteson, \223Ecp An R Package for Nonparametic Mul tiple Change Point Analysis of Mul tivariate Data,\224 Annals Am. Thorasic Soc JMIR vol. \032\033 no. \035, \034\033\033\026, pp. \035\026\035\030\035\026\026 034\034  D.L. Reed and W.P. Sacco, \223Measur ing Sleep E\023ciency: What Should the Denominator Be?,\224 Network Science Proc. \036th Int\222l Conf. Per vasive Computing Technologies for Healthcare J. Clinical Sleep Medicine PervasiveHealth \035\024 034\033\035\024, pp. \035\024\037\030\035\027\033 035\036  H. Chawla et al., \223Physical Activ ity as a Predictor of Thirty-Day Hospital Readmission after a Dis charge for a Clinical Exacerbation of Chronic Obstructive Pulmonary Disease,\224 ABOUT THE AUTHORS A ARTI SATHYANARAYANA M.G. Negoita, R.J. Howlett, and L.C Jain, eds., Springer, \034\033\033\032, pp. \027\035\033\030\027\035\036 035\034  A. Sathyanarayana et al., \223Robust Automated Human Activity Recog nition and Its Application to Sleep Research,\224 \034\033\035\027; arxiv.org/abs   035\027 033\036.\033 032 026\027\036 035\037  M. Hirshkowitz, \223The History of Polysomnography: Tool of Scienti\025c Discovery,\224 vol. \035\034, no. \034, \034\033\035\027 pp. \034\027\037\030\034\027\027 034\037  A. Sathyanarayana et al., \223Sleep Quality Prediction from Wearable Data Using Deep Learning,\224 vol.\022\032, no. \032 034\033\035\027, e\035\034\024; doi:\035\033.\034\035\031\027/mhealth  027\024\027\034 Sleep Sleep 


 2012 251\320272  B D u C L i u W  Z hou Z  Hou and H  X iong 322Catch m e if you can n  nnd gory o gory  y ne rk C USION and t d ed s f ticalnr ble e  n s f o  s here her d y an s ng A NT ers s R ES  E  C  T aylor a nd C K J ones  Ft Ft Ft Ft  hnol hnol hnol n This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination 10 TEMS core 2007  M  U ts unom iya J  Attanucci a nd N H M W ils on 322Potential u s e s e 323 119\320126 2006  X  M a Y  J  W u Y  W a ng F  Chen a nd J  L i u 322Mining s m a rt card 323 2014 8 M  P  P e lletier  M  T r 216panier  and C  M or enc y  322 S m ar t car d d ata u s e 323 1 2 3 4 e g s a h l erage nn e are rd day ng s   2013  M  T r\216panier  N  T ranchant a nd R Ch tination 323  2013  Y  Z heng L  Capra O W o lfs on and H  Y ang 322Urban com puting 323  2011 hat s on  ining ho packetro others o e uch ng s s onger e t  d USA n aly ces e que ance anomaly ter n nomaly emporal features    2016 87\32096  L  S un K W  Axhaus en D  H L ee and X  H uang 322Unders tanding 323 


nd n puter e ciate lobal tif ale puting intelligence  otes 19\32033  S  Is aacm an R  B eck er  R  C 207ceres  S  K obouro v  J  R o w land and n 88\32093  K  D u f k o v 207 J  Y  L e B oudec L  K e ncl and M  B jelica 322P r e dicting u s e r in rt 323 hang 16th ining 19th  2012  C Morenc y  M T r 216panier  and B A gard 322 Meas uring t rans it us e 323 2005  K  K  A  Chu R Chapleau a nd M  T r epanier  322D r i v e r as s i s t ed b u s e 323 2010  Y  A s akur a T  I r yo Y  N a kajim a and T  K us akabe 322E s tim ation o f 323 2012  F  Z h ang J  Z h ao C T ian C Xu X  L iu a nd L  Rao 322Spatiotem poral 323 2016  J  Z h ao 2015 O  A v a ilable http://w w w  s ciencedir ect  c om s c i en ce a r t i c l e  p ii  S0968090X15000030  S  I s aacm an 2015  V  Chandola A Banerjee and V  K um 323 2009  V  J  H odge and J  A us tin 322 A s urv e y o f outlier d etection m ethodologies  323 2004  L  X P a ng S Cha w la W  L iu a nd Y  Z h eng 322On d etection o f e m e r g ing 323 17\32019  X Ma and Y  W ang 322De v elopm ent o f a data-dri v e n p latform f or trans i t 323 459\320468  S Bhattacharya S  P hithakkitnuk oon P  Nurm i A Klam i M V e los o  s n 1189\3201198  Y  G e  H  X iong A  T u zhilin K  X iao M G r utes er  a nd M P azzani n 2010 899\320908  Y  Y e  Y  Z heng Y  Chen J  F eng life in 2  J  G  L ee J  H a n and X  L i 322T r a jector y outlier d etection A p ar titionin 1733\3201736  Y  Bu L  C hen A W  C F u and D  L iu 322 E f 336cient anom aly m onitoring n 159\320168  P  J  Rous s eeuw  322Silhouettes  A g raphical aid t o t he interpretation a nd 323 tity onnments  2105 2009  B Agard C Morenc y  and M  T r\216panier  322 Mining public trans port u s e r n 1\32010  S  L i u Q  Q u  a nd S  W a ng 322Rationality analytics f r o m t r a jector ies  323 Zhao Qu  2014  L  S un D  H  L ee A  E r ath and X  H uang 322U s i ng s m ar t car d d ata poral f n  142\320148  T  K u s a kabe T  Iryo and Y  A s a kura 322E s tim ation m ethod for r ail w ay w 323  2016  L  Sun J  G J i n D H L ee K W  Axhaus en a nd A E r ath 323  239\320252 A v a ilable 659  S  I s aacm an  140\320149 A v a ilable 2  Y  Ge H  X iong Z  H Z hou H Ozdem i r  J  Y u a nd K C L e e n Mobile Comput HotMobile ata l INCOM  C ublic p int Comput   Int Mining ath Comput etropolitan in uazhong 2007 ity incoln r  topics urban puting he ity urrently enzhen cadant  to put ning S 11 9 M  A  M unizaga a nd C P a lm a 322E s tim ation o f a dis a ggr e g ate m ultim odal ata 323 3 2007  M Bagchi and P  R W hite 322 T h e potential o f public trans port s m a rt 323 1 1987  hnol    19\32024  A v a ilable http://doi acm  o r g 10 1145/173 4583 173 4589  R Ganti M Sri v ats a  A  R anga an in 24 2012  X  L  M a Y  H  W ang F  Chen a nd J  F  L iu 322 T r ans i t s m a r t car d d ata i 323 2014 A v a ilable 82X  L  Sun Y  L u  J  G  J in D  H L ee and K  W  A xhaus en 322 An inte grated 323 87 2013  Y  Z h eng H Z h ang and Y  Y u 322D m in O This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination al al al  djunct ublication C hnol  Commun PERC shops d tation hnol hnol  licy licy Data MDM 


e 1993 f State adjunct nced he nd has papers s loud ance nd CM f he ecipient ber T N C TERS  T ON P AND D UTED S TEMS EEE T ON C LOUD C NG  bComputing This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination 12 TEMS  Liu ciences d Xu he Sc ngineering  ity  s cial eting 


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   13     en-US n en-US  en-US 1 en-US en-US nen-US rther en-US  en-US 5 en-US  en-US  en-US i en-US en-US en-US ch en-US  en-US  en-US 4.3.1  en-US es en-US  en-US ed en-US ion en-US r en-US non en-US en-US t en-US  en-US is en-US  en-US e en-US y en-US  en-US  en-US  en-US  en-US nd en-US  en-US  en-US  en-US ed en-US  en-US logic en-US en-US ed en-US ion en-US  en-US n en-US non en-US en-US i en-US en-US a en-US y en-US em en-US en-US  en-US h en-US  en-US o en-US ion en-US  en-US en-US width en-US iciency en-US 2 en-US oben-US nonlinea en-US ren-US o en-US  en-US i en-US en-US  en-US ion en-US  en-US  en-US  en-US  en-US 4.4  en-US  en-US ing en-US  en-US  en-US  en-US ion en-US  en-US  en-US D en-US ion en-US  en-US  en-US in en-US  en-US en-US s en-US  en-US  en-US n en-US 3 en-US he en-US en-US  en-US  en-US g en-US een-US  en-US u en-US high en-US en-US rity en-US reen-US cking en-US en-US ion en-US  en-US i en-US en-US  en-US y en-US  en-US ck en-US en-US to en-US en-US  en-US  en-US  en-US en-US e en-US h en-US en-US  en-US  en-US en-US  en-US 4 en-US in en-US  en-US 5 en-US  en-US  en-US llo en-US  en-US ck en-US ion en-US  en-US  en-US oben-US  en-US t en-US en-US e en-US en-US he en-US  en-US c en-US er en-US  en-US 6 en-US  en-US he en-US i en-US en-US en-US  en-US i en-US on en-US  en-US  en-US e en-US en-US en-US highly en-US d en-US  en-US 7 en-US  en-US  en-US ion en-US  en-US  en-US o en-US en-US  en-US ion en-US  en-US  en-US en-US  en-US e en-US  en-US e en-US  en-US  en-US l en-US cen-US re en-US en-US  en-US  en-US er en-US en-US ed en-US ion en-US  en-US  en-US t en-US  en-US  en-US y en-US  en-US ed en-US ion en-US  en-US n en-US  en-US 8 en-US o en-US en-US e en-US  en-US c en-US  en-US  en-US  en-US c en-US t en-US en-US ed en-US o en-US en-US ilen-US een-US ion en-US  en-US en-US  en-US ion en-US  en-US he en-US  en-US y en-US ilien-US en-US  en-US ion en-US  en-US elioen-US ion en-US  en-US y en-US  en-US work en-US  en-US l en-US eren-US non en-US en-US  en-US non en-US en-US op en-US oben-US ic en-US ion en-US  en-US en-US  en-US 9 en-US b en-US comen-US re en-US  en-US cking en-US ion en-US  en-US ien-US i en-US en-US  en-US i en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  14      en-US a en-US k en-US ck en-US en-US to en-US en-US en-US en-US  en-US ion en-US  en-US  en-US i en-US  en-US en-US  en-US  en-US ion en-US e en-US cy en-US  en-US 0 en-US  en-US  en-US n en-US igen-US  en-US en-US in en-US  en-US 5 en-US  en-US  en-US ion en-US la en-US  en-US en-US  en-US  en-US t en-US  en-US n en-US en-US ck en-US en-US to en-US en-US  en-US o en-US en-US ien-US n en-US en-US e en-US  en-US rs en-US en-US  en-US  en-US hen-US in en-US  en-US 0 en-US  en-US in en-US  en-US 1 en-US  en-US  en-US ll en-US en-US cova en-US nce en-US 2 en-US  en-US ion en-US 3 en-US  en-US Cov en-US nion en-US  en-US 3 en-US  en-US  en-US  en-US  en-US r en-US  en-US he en-US oen-US  en-US en-US rien-US he en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US o en-US  en-US  en-US  en-US  en-US  en-US  en-US  en-US en-US low en-US en-US en-US F en-US  en-US  en-US elow en-US  en-US Cross en-US en-US on en-US  en-US  en-US s en-US en-US  en-US 2    1 5 4  en-US  en-US  en-US y en-US Y   whe re X  a nd  Y  a r e t he ra nd om v ect or s   E  is  ex en-US  en-US      en-US  en-US  en-US    en-US  en-US      10   en-US on en-US Co en-US  en-US  en-US 3 en-US  en-US  en-US  en-US KF en-US  en-US a en-US  en-US  en-US o en-US  en-US  en-US  en-US  en-US  en-US coen-US io en-US  en-US     11    en-US en-US   12   en-US H en-US ere en-US en-US  en-US  en-US  en-US on en-US  en-US  en-US in en-US  en-US 3 en-US  en-US en-US en-US  en-US  en-US  en-US  en-US y en-US en-US  en-US oth en-US en-US  en-US nd en-US  en-US en-US e en-US   en-US  en-US  en-US      en-US  en-US nd en-US       en-US  en-US re en-US   en-US  en-US  en-US   en-US  en-US  en-US en-US  en-US ion en-US  en-US l en-US en-US  en-US ien-US in en-US en-US ion en-US  en-US  en-US or en-US  en-US  en-US ion en-US  en-US 5    1 5 5  en-US  en-US  en-US cking en-US ion en-US  en-US  en-US ynen-US  en-US cking en-US ion en-US  en-US  en-US er en-US  en-US re en-US en-US en-US  en-US  en-US  en-US In en-US  en-US  en-US 9 en-US o en-US en-US  en-US n en-US  en-US 6 en-US  en-US  9 i    


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   15     en-US  en-US e en-US  en-US t en-US e en-US g en-US eful en-US ion en-US  en-US e en-US  en-US  en-US 4.4.1  en-US es en-US  en-US in en-US ions en-US  en-US re en-US  en-US h en-US n en-US en-US er en-US  en-US inen-US ct en-US otion en-US en-US ed en-US ion en-US  en-US en-US ion en-US  en-US 9 en-US  en-US  en-US  en-US en-US u en-US  en-US  en-US H en-US owe en-US  en-US ccuen-US en-US l en-US een-US T en-US re en-US he en-US i en-US en-US en-US cking en-US  en-US in en-US  en-US 4    1 4 6     1 5 7     1 5 8  en-US  en-US  en-US  en-US en-US en-US  en-US lly en-US  en-US  en-US ib en-US en-US r en-US  en-US  en-US T en-US  en-US ion en-US  en-US  en-US O en-US s en-US  en-US  en-US  en-US  en-US ion en-US  en-US  en-US 5  en-US E en-US  en-US D en-US ATA FUS en-US ION en-US  en-US T en-US DS en-US  en-US e en-US on en-US en-US ion en-US  en-US  en-US ion en-US  en-US o en-US ic en-US t en-US  en-US ent en-US  en-US  en-US ion en-US  en-US en-US s en-US  en-US I en-US  en-US ion en-US  en-US  en-US  en-US re en-US ion en-US  en-US  en-US how en-US p en-US  en-US nce en-US ion en-US  en-US  en-US  en-US 5.1  en-US s en-US ed en-US s en-US  en-US elf en-US en-US  en-US own en-US  en-US ence en-US  en-US  en-US  en-US o en-US  en-US  en-US en-US  en-US y en-US a en-US  en-US or en-US  en-US ource en-US  en-US  en-US c en-US  en-US  en-US riving en-US  en-US ion en-US  en-US ine en-US  en-US hing en-US a en-US  en-US le en-US  en-US  en-US ict en-US  en-US  en-US of en-US  en-US ion en-US  en-US ehicle en-US s en-US  en-US r en-US  en-US elf en-US en-US elen-US t en-US  en-US re en-US  en-US y en-US gy en-US an en-US inen-US elop en-US ing en-US  en-US en-US rive en-US en-US his en-US  en-US ed en-US he en-US e en-US en-US of en-US en-US rt en-US ion en-US  en-US en-US ing en-US  en-US ing en-US  en-US  en-US a en-US comen-US  en-US  en-US t en-US ics en-US  en-US ed en-US by en-US  en-US en-US n en-US 9 en-US  en-US en-US  en-US ing en-US  en-US in en-US 0 en-US  en-US  en-US n en-US 1    1 6 2  en-US inen-US  en-US  en-US hing en-US en-US p en-US en-US en-US ri en-US in en-US 3 en-US  en-US which en-US es en-US  en-US  en-US in en-US 4 en-US  en-US  en-US icyen-US i en-US en-US n en-US 5 en-US  en-US  en-US  en-US in en-US 5 en-US  en-US ge en-US  en-US cten-US  en-US 6 en-US  en-US in en-US 7 en-US  en-US T en-US  en-US leen-US d en-US en-US s en-US  en-US en-US  en-US  en-US  en-US riven-US in en-US 8 en-US  en-US her en-US  en-US on en-US e en-US  en-US re en-US  en-US ove en-US  en-US e en-US ny en-US  en-US en-US ges en-US  en-US  en-US ien-US r en-US inct en-US  en-US c en-US en-US en-US  en-US en-US nce en-US en-US e en-US en-US r en-US  en-US  en-US  en-US  en-US  en-US 9 en-US  en-US  en-US 0 en-US  en-US elf en-US en-US en-US  en-US en-US rive en-US en-US ed en-US  en-US  en-US n en-US ion en-US  en-US n en-US ion en-US 1 en-US  en-US  en-US he en-US  en-US ve en-US  en-US ed en-US  en-US r en-US  en-US h en-US ion en-US  en-US  en-US ion en-US  en-US ing en-US  en-US re en-US  en-US er en-US  en-US  en-US ion en-US  en-US re en-US ring en-US a en-US  en-US r en-US en-US  en-US  en-US  en-US  en-US 5.2  en-US ing en-US  en-US sion en-US  en-US rning en-US  en-US  en-US  en-US  en-US ion en-US r en-US ied en-US  en-US rning en-US  en-US  en-US  en-US  en-US ha en-US e en-US t en-US  en-US  en-US c en-US  en-US  en-US ni en-US z en-US ions en-US  en-US or en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  16      en-US  en-US 1 en-US D en-US ning en-US  en-US rnen-US el en-US he en-US l en-US  en-US t en-US  en-US ke en-US s en-US  en-US  en-US lly en-US r en-US reen-US o en-US  en-US ediction en-US s en-US  en-US  en-US rning en-US  en-US  en-US el en-US  en-US  en-US  en-US g en-US  en-US el en-US  en-US  en-US which en-US help en-US s en-US  en-US hink en-US  en-US  en-US  en-US rning en-US  en-US  en-US lly en-US  en-US h en-US ceen-US b en-US on en-US  en-US rning en-US  en-US 2 en-US t en-US  en-US rning en-US  en-US r en-US  en-US  en-US  en-US  en-US he en-US he en-US  en-US comen-US ion en-US ources en-US  en-US g en-US ine en-US ing en-US  en-US e en-US  en-US  en-US 3 en-US  en-US rning en-US  en-US in en-US 3    1 7 4  en-US  en-US i en-US en-US 9  cr it ica lly ex p la in s  t he p re s ent  s t a t e en-US en-US of en-US en-US elen-US in en-US rning en-US  en-US  en-US n en-US rning en-US  en-US n en-US 0  a u t hor s  d is cu s s  t he p a s t  a nd  P res ent  of  en-US  en-US rning en-US  en-US o en-US rnen-US ing en-US  en-US rning en-US  en-US n en-US 5    1 7 6  en-US  en-US e en-US ed en-US  en-US ion en-US  en-US u en-US nen-US n en-US w en-US  en-US ery en-US ce en-US rning en-US  en-US rning en-US  en-US king en-US inen-US o en-US  en-US ion en-US  en-US in en-US  en-US l en-US ly en-US  en-US l en-US  en-US ning en-US  en-US in en-US 7 en-US en-US 9 en-US  en-US en-US n en-US 4 en-US  en-US eo en-US  en-US g en-US in en-US 0 en-US  en-US  en-US  en-US rning en-US  en-US  en-US 6   d ee p  f u lly convolu t iona l neu ra l  en-US rth en-US  en-US  en-US ion en-US  en-US in en-US 1 en-US  en-US  en-US  en-US work en-US 2 en-US r en-US ion en-US 4 en-US en-US R en-US en-US he en-US  en-US ion en-US  en-US en en-US  en-US in en-US t en-US he en-US  en-US  en-US 2 en-US  en-US  en-US  en-US  en-US e en-US rning en-US  en-US  en-US ion en-US  en-US  en-US  en-US  en-US lica en-US  en-US in en-US  en-US  en-US s en-US  en-US n en-US  en-US ion en-US  en-US 3 en-US  en-US ion en-US  en-US f en-US  en-US 4 en-US  en-US l en-US ion en-US  en-US in en-US 5 en-US  en-US n en-US  en-US 6 en-US  en-US  en-US  en-US  en-US in en-US o en-US ing en-US  en-US rning en-US  en-US o en-US  en-US  en-US ion en-US  en-US  en-US  en-US en-US ing en-US  en-US  en-US rning en-US  en-US  en-US v en-US  en-US  en-US rning en-US  en-US  en-US  en-US  en-US  en-US rning en-US  en-US re en-US as en-US  en-US ion en-US  en-US  en-US 5.3  en-US  en-US  en-US es en-US  en-US en-US  en-US lif en-US n en-US en-US  en-US eren-US a en-US  en-US en-US  en-US l en-US w en-US  en-US ing en-US 7    1 8 8  en-US  en-US he en-US en-US  en-US lly en-US en-US  en-US ge en-US en-US  en-US  en-US y en-US en-US  en-US 6 en-US  en-US en-US  en-US in en-US  en-US  en-US y en-US ien-US  en-US en-US v en-US ed en-US  en-US e en-US  en-US  en-US rning en-US  en-US  en-US  en-US nen-US re en-US 9 en-US  en-US in en-US 0 en-US y en-US in en-US rt en-US e en-US  en-US recen-US  en-US en-US how en-US en-US een-US e en-US en-US who en-US  en-US en-US e en-US en-US who en-US  en-US A en-US d en-US  en-US in en-US 1 en-US  en-US  en-US  en-US  en-US 2 en-US en-US 4 en-US  en-US  en-US 5 en-US  en-US  en-US  en-US 6 en-US en-US 8 en-US  en-US 9 en-US en-US 1 en-US  en-US s en-US re en-US 2 en-US en-US 4 en-US  en-US en-US r en-US ocieen-US e en-US s en-US  en-US 5    2 0 6  en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   17     en-US 2 en-US  en-US oT en-US en-US v en-US l en-US l en-US ions en-US  en-US 7 en-US  en-US s en-US  en-US 8 en-US  en-US 9 en-US  en-US 0 en-US en-US 3 en-US  en-US en-US ices en-US  en-US 4 en-US  en-US len-US ove en-US  en-US 5 en-US en-US 8 en-US  en-US e en-US en-US ourcing 1 en-US  2 en-US  en-US hoc en-US en-US rp en-US es en-US 6    2 1 9  en-US en-US s en-US  en-US 0 en-US s en-US 1 en-US  en-US  en-US 2 en-US  en-US cience en-US 3 en-US  en-US cy en-US 4 en-US  en-US  en-US t en-US  en-US l en-US 4 en-US  en-US 5 en-US  en-US 6 en-US  en-US  en-US nning 8 en-US  en-US  en-US hone en-US  en-US ches en-US  en-US  en-US t en-US en-US en-US g en-US  en-US la en-US ion en-US he en-US er en-US rt en-US  en-US  en-US  en-US n en-US gyroen-US  en-US  en-US nd en-US  en-US a en-US xen-US or en-US  en-US conen-US t en-US en-US heir en-US  en-US  en-US ion en-US  en-US enen-US  en-US ices en-US  en-US ion en-US 6 en-US  en-US in en-US 7    2 2 8  en-US  en-US  en-US hen-US o en-US e en-US s en-US  en-US en-US ies en-US Very en-US  en-US ion en-US  en-US on en-US he en-US  en-US here en-US r en-US t en-US en-US  en-US ap en-US d en-US ed en-US ion en-US  en-US le en-US  en-US nd en-US  en-US  en-US s en-US rt en-US c en-US  en-US f en-US len-US ove en-US en-US d en-US  en-US  en-US s en-US rt en-US c en-US m en-US en-US en-US nen-US  en-US  en-US 6  en-US C en-US O en-US LUSION en-US  en-US y en-US  en-US en-US  en-US s en-US en-US ig en-US  en-US nen-US nd en-US  en-US en-US  en-US een-US nen-US  en-US ellig en-US  en-US  en-US en-US  en-US  en-US o en-US  en-US en-US l en-US hen-US  en-US s en-US  en-US  en-US  en-US ien-US f en-US  en-US ed en-US ed en-US r en-US  en-US s en-US o en-US  en-US ic en-US en-US ed en-US en-US  en-US d en-US  en-US  en-US re en-US  en-US o en-US ed en-US  en-US en-US ed en-US ch en-US  en-US  en-US A en-US ENT en-US  en-US  en-US he en-US er en-US  en-US  en-US he en-US ing en-US iz en-US  en-US y en-US h en-US  en-US  en-US ing en-US  en-US  en-US  en-US a en-US  en-US  en-US R en-US ES en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US vey en-US en-US s en-US  en-US 7 en-US en-US  en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US 437 en-US en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US TU en-US en-US TU en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US nc en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US  en-US the en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US EE en-US E en-US ess en-US  en-US 5 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US i en-US en-US n en-US  en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US  en-US en-US  en-US ew en-US i   Ava i l a bl e   en-US o en-US 3 en-US en-US the en-US en-US r en-US en-US of en-US en-US the en-US en-US net en-US en-US of en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US  en-US vey en-US en-US s en-US  en-US 7 en-US en-US  en-US  en-US  en-US  en-US 10 en-US  en-US  en-US  en-US en-US  en-US  en-US a en-US vey en-US en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 11 en-US  en-US  en-US Al en-US en-US  en-US  en-US en-US  en-US  en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  18      en-US S en-US v en-US  en-US  en-US  en-US 12 en-US  en-US  en-US  en-US en-US  en-US ti en-US en-US  en-US en-US sors en-US  en-US 1 en-US en-US  en-US  en-US  en-US 13 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US  en-US l en-US  en-US  en-US  en-US 14 en-US  en-US  en-US  en-US en-US n te en-US en-US of en-US en-US the en-US en-US  en-US en-US n en-US  en-US 28 en-US en-US  en-US  en-US  en-US 15 en-US  en-US  en-US N en-US en-US  en-US en-US  en-US en en-US  en-US en-US  en-US vey en-US en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 16 en-US  en-US  en-US ez en-US en-US  en-US en-US  en-US e en-US  en-US  en-US en-US sors en-US  en-US  en-US  en-US  en-US 17 en-US  en-US  en-US  en-US en-US  en-US ti en-US en-US  en-US en-US sors en-US n en-US  en-US 1 en-US en-US  en-US  en-US  en-US 18 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 19 en-US  en-US  en-US  en-US en-US  en-US T en-US en-US  en-US  en-US  en-US 73 en-US en-US  en-US  en-US  en-US 20 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 15 en-US en-US  en-US  en-US  en-US 21 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US i en-US  en-US  en-US  en-US  en-US 22 en-US  en-US  en-US  en-US i en-US en-US n en-US  en-US  en-US  en-US  en-US 23 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US  en-US  en-US  en-US  en-US 24 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 540 en-US en-US  en-US  en-US  en-US 25 en-US  en-US  en-US  en-US en-US  en-US t en-US  en-US  en-US en-US l en-US  en-US 8 en-US en-US  en-US  en-US  en-US 26 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US n en-US  en-US 7 en-US en-US  en-US  en-US  en-US 27 en-US  en-US  en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US i en-US en-US B\256 en-US  en-US  en-US  en-US  en-US 29 en-US  en-US  en-US  en-US  en-US  en-US  en-US ew en-US en-US  en-US  en-US  en-US  en-US  en-US 30 en-US  en-US  en-US r en-US en-US e en-US en-US ti en-US en-US  en-US n en-US en-US  en-US ess en-US  en-US 807 en-US en-US  en-US  en-US  en-US 31 en-US  en-US  en-US  en-US  en-US  en-US en-US ted en-US en-US 2015 en-US s en-US  en-US 7 en-US en-US  en-US  en-US  en-US 32 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US no en-US  en-US 1 en-US en-US  en-US  en-US  en-US 33 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 34 en-US  en-US  en-US  en-US en-US  en-US l en-US  en-US en-US  en-US 190 en-US en-US  en-US  en-US  en-US  en-US 35 en-US  en-US  en-US  en-US en-US nt en-US en-US  en-US  en-US  en-US en-US  en-US en-US  en-US IC en-US  en-US  en-US  en-US  en-US  en-US  en-US 36 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 37 en-US  en-US  en-US  en-US en-US s en-US  en-US  en-US en-US EE en-US en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 38 en-US  en-US  en-US  en-US en-US er en-US en-US  en-US en-US  en-US eo en-US  en-US  en-US 6 en-US en-US  en-US  en-US  en-US 39 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US EE en-US en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 40 en-US  en-US  en-US  en-US en-US ti en-US en-US t en-US  en-US n en-US en-US P en-US  en-US 1 en-US en-US  en-US  en-US  en-US 41 en-US  en-US  en-US  en-US en-US ti en-US en-US e en-US en-US  en-US  en-US en-US rol en-US  en-US 7 en-US en-US  en-US  en-US  en-US 42 en-US  en-US  en-US L en-US en-US  en-US en-US t en-US  en-US  en-US en-US 0 en-US  en-US  en-US  en-US 43 en-US  en-US  en-US  en-US n en-US  en-US ey en-US en-US  en-US  en-US  en-US 44 en-US  en-US  en-US L en-US en-US  en-US en-US  en-US ti en-US en-US n en-US en-US  en-US  en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 45 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US n en-US en-US s en-US  en-US 6 en-US en-US  en-US  en-US  en-US  en-US 46 en-US  en-US  en-US  en-US en-US  en-US ng en-US en-US  en-US en-US  en-US ess en-US 2 en-US  en-US 2 en-US en-US  en-US  en-US  en-US 47 en-US  en-US  en-US en en-US  en-US i en-US en-US n en-US  en-US  en-US  en-US  en-US 48 en-US  en-US  en-US  en-US en-US  en-US ver en-US e en-US en-US  en-US  en-US en-US rks en-US  en-US  en-US  en-US 49 en-US  en-US  en-US  en-US en-US  en-US e en-US en-US  en-US  en-US en-US rks en-US  en-US  en-US  en-US 50 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 51 en-US  en-US  en-US  en-US en-US r en-US n en-US en-US  en-US 7 en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   19     en-US  en-US  en-US  en-US 52 en-US  en-US  en-US  en-US en-US e en-US ti en-US en-US  en-US  en-US en-US  en-US 4 en-US en-US  en-US  en-US  en-US 53 en-US  en-US  en-US  en-US en-US  en-US  en-US DA en-US en-US  en-US  en-US  en-US  en-US 54 en-US  en-US  en-US  en-US en-US e en-US n en-US  en-US en-US  en-US v en-US en-US  en-US  en-US  en-US 55 en-US  en-US  en-US  en-US en-US k en-US en-US thm en-US en-US  en-US ron en-US  en-US 0 en-US en-US  en-US  en-US 5 en-US 6 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US n en-US  en-US  en-US  en-US 57 en-US  en-US  en-US  en-US en-US ti en-US en-US T en-US  en-US n en-US en-US  en-US  en-US  en-US  en-US  en-US 58 en-US  en-US  en-US  en-US en-US  en-US Pre en-US en-US  en-US t en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 3 en-US en-US 1 en-US  en-US  en-US  en-US 59 en-US  en-US  en-US t en-US  en-US  en-US n en-US en-US  en-US  en-US en-US  en-US OS en-US  en-US 2 en-US en-US  en-US  en-US  en-US 60 en-US  en-US  en-US  en-US en-US  en-US ti en-US  en-US t en-US en-US  en-US 4 en-US en-US  en-US  en-US  en-US 61 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US ess en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 62 en-US  en-US  en-US  en-US en-US X en-US en-US ng en-US en-US s en-US  en-US en-US  en-US  en-US i    en-US x en-US en-US e en-US en-US i en-US en-US r en-US en-US is en-US en-US 2 en-US en-US Dec en-US en-US 6  en-US  en-US  en-US 63 en-US  en-US  en-US i en-US  en-US en-US  en-US  en-US en-US h en-US i   Av a i l a bl e   en-US e en-US en-US is en-US en-US ng en-US en-US a en-US en-US nd en-US en-US b en-US en-US r en-US en-US the en-US en-US net en-US en-US of en-US en-US 0 en-US en-US Dec en-US en-US 6  en-US  en-US  en-US 64 en-US  en-US  en-US BI en-US en-US  en-US en-US e en-US  en-US  en-US en-US er en-US  en-US i    en-US du en-US en-US es en-US en-US new en-US en-US ai en-US en-US nd en-US en-US net en-US en-US of en-US en-US s en-US en-US ves en-US en-US 6 en-US en-US 0 en-US en-US Dec en-US en-US 6  en-US  en-US  en-US 65 en-US  en-US  en-US  en-US en-US Su en-US  en-US  en-US en-US a en-US  en-US 9 en-US en-US  en-US  en-US  en-US  en-US 66 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US s en-US  en-US  en-US  en-US  en-US 67 en-US  en-US  en-US  en-US en-US  en-US a en-US en-US ve en-US en-US a en-US  en-US 383 en-US en-US  en-US  en-US  en-US 68 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US ess en-US  en-US 7 en-US en-US  en-US  en-US  en-US 69 en-US  en-US  en-US  en-US en-US  en-US vey en-US en-US  en-US ri en-US s en-US  en-US 77 en-US en-US  en-US  en-US  en-US 70 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 71 en-US  en-US  en-US o en-US  en-US  en-US ne en-US en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 72 en-US  en-US  en-US  en-US en-US  en-US n en-US e en-US  en-US en-US  en-US n en-US  en-US 6 en-US en-US  en-US  en-US  en-US 73 en-US  en-US  en-US  en-US en-US  en-US  en-US hy en-US  en-US en-US  en-US n en-US  en-US 6 en-US en-US  en-US  en-US  en-US 74 en-US  en-US  en-US  en-US en-US  en-US t en-US en-US I en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 75 en-US  en-US  en-US  en-US en-US  en-US ty en-US en-US  en-US en-US  en-US f en-US en-US  en-US  en-US  en-US  en-US 76 en-US  en-US  en-US a en-US  en-US en-US ti en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 96 en-US en-US  en-US  en-US  en-US 77 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US 0 en-US 8 en-US en-US  en-US  en-US ess en-US  en-US 85 en-US en-US  en-US  en-US  en-US 78 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US  en-US  en-US  en-US  en-US  en-US 79 en-US  en-US  en-US hen en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 80 en-US  en-US  en-US  en-US en-US ng en-US en-US  en-US  en-US  en-US en-US s en-US  en-US  en-US 6 en-US en-US  en-US  en-US  en-US 81 en-US  en-US  en-US N en-US  en-US  en-US en-US  en-US  en-US en-US 2011 en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 82 en-US  en-US  en-US  en-US  en-US en-US o en-US  en-US  en-US en-US 2011 en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 83 en-US  en-US  en-US  en-US en-US  en-US s en-US  en-US  en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 84 en-US  en-US  en-US  en-US en-US  en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  20      en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 85 en-US  en-US  en-US F en-US  en-US en-US  en-US  en-US en-US  en-US 0 en-US  en-US 5 en-US en-US  en-US  en-US  en-US 86 en-US  en-US  en-US h en-US  en-US  en-US l en-US en-US  en-US en-US  en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 87 en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US  en-US d en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 88 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US 6 en-US  en-US 263 en-US en-US  en-US  en-US  en-US 89 en-US  en-US  en-US  en-US en-US tem en-US en-US OTA en-US  en-US 6 en-US  en-US 6 en-US en-US  en-US  en-US  en-US  en-US 90 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US m en-US  en-US 87 en-US en-US  en-US  en-US  en-US  en-US 91 en-US  en-US  en-US e en-US  en-US  en-US en-US  en-US  en-US en-US  en-US m en-US  en-US 87 en-US en-US  en-US  en-US  en-US  en-US 92 en-US  en-US  en-US  en-US en-US  en-US a en-US  en-US  en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 93 en-US  en-US  en-US  en-US en-US  en-US r en-US en-US  en-US  en-US en-US  en-US 195 en-US en-US  en-US  en-US  en-US 94 en-US  en-US  en-US Wei en-US en-US xi en-US ng en-US en-US eng en-US en-US  en-US en-US  en-US k en-US en-US to en-US en-US  en-US  en-US en-US ess en-US  en-US 1 en-US en-US  en-US  en-US  en-US 95 en-US  en-US  en-US  en-US en-US  en-US c en-US r en-US en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 96 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US r en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 97 en-US  en-US  en-US  en-US  en-US  en-US en-US e en-US en-US  en-US r en-US en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US  en-US m en-US en-US s en-US en-US 3 en-US  en-US 3 en-US en-US  en-US  en-US  en-US 98 en-US  en-US  en-US a en-US en-US  en-US en-US  en-US ter en-US en-US  en-US  en-US en-US l en-US  en-US  en-US  en-US  en-US 99 en-US  en-US  en-US a en-US  en-US en-US  en-US  en-US  en-US en-US  en-US BE en-US  en-US 1 en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US e en-US  en-US  en-US  en-US  en-US 1 en-US  en-US  en-US e en-US en-US  en-US ter en-US en-US  en-US  en-US  en-US  en-US 2 en-US  en-US  en-US e en-US en-US  en-US ter en-US en-US the en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US  en-US ter en-US en-US  en-US ti en-US en-US n en-US en-US  en-US n en-US  en-US 3 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US th en-US  en-US  en-US ter en-US en-US  en-US  en-US en-US s en-US  en-US 7 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US en en-US en-US  en-US n en-US  en-US  en-US en-US 4 en-US  en-US 4 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US e en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US ter en-US en-US  en-US tem en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US  en-US en-US  en-US a en-US en-US  en-US en-US  en-US S en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US  en-US  en-US en-US ter en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 72 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US n en-US en-US a en-US  en-US 5 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US W en-US  en-US en-US  en-US  en-US nty en-US en-US  en-US ON en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US  en-US Se en-US  en-US en-US  en-US l en-US  en-US 334 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US Int en-US en-US y en-US  en-US  en-US  en-US 249 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US en-US  en-US d en-US en-US  en-US 1 en-US 1 en-US 52 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US  en-US te en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US en-US r en-US  en-US 34 en-US en-US  en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   21     en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US i en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US s en-US  en-US  en-US  en-US 2 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US 1 en-US 77 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US d en-US en-US a en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US 2 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US o en-US  en-US en-US  en-US  en-US en-US s en-US  en-US 0 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US s en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US en-US a en-US  en-US 321 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US K en-US en-US t en-US en-US  en-US en-US  en-US  en-US s en-US en-US dy en-US en-US matics en-US  en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US  en-US res en-US  en-US  en-US  en-US 9 en-US  en-US  en-US R en-US n en-US en-US  en-US en-US  en-US  en-US en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US n en-US en-US  en-US en-US n en-US  en-US  en-US  en-US en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US man en-US en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US d en-US en-US s en-US 2 en-US  en-US 46 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US ti en-US en-US ti en-US en-US  en-US n en-US en-US n en-US  en-US 1 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US n en-US en-US n en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US en-US 2 en-US  en-US ron en-US  en-US 351 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US Semi en-US en-US  en-US  en-US en-US  en-US S en-US s en-US en-US  en-US  en-US  en-US 2 en-US en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US ex en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 9 en-US  en-US  en-US nt en-US en-US  en-US en-US  en-US  en-US a en-US  en-US en-US  en-US r en-US  en-US 7 en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US EEE en-US  en-US 6 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US s en-US  en-US 7 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US n en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US ene en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 7 en-US en-US  en-US  en-US 4 en-US  en-US  en-US en-US  en-US ti en-US en-US  en-US en-US  en-US  en-US 8 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US i en-US  en-US  en-US en-US  en-US dy en-US en-US  en-US n en-US y en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US  en-US  en-US en-US IE en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US ter en-US en-US n en-US en-US  en-US l en-US en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US  en-US  en-US n en-US en-US  en-US en-US  en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US  en-US the en-US  en-US en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  22      en-US Inte en-US  en-US  en-US 132 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US n en-US en-US  en-US I en-US en-US  en-US  en-US  en-US 69 en-US en-US 8 en-US  en-US  en-US  en-US 2 en-US  en-US  en-US r en-US en-US  en-US en-US k en-US en-US to en-US en-US  en-US  en-US en-US r en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US t en-US en-US n en-US en-US n en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US i   en-US m en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US k en-US en-US to en-US en-US  en-US tr en-US  en-US n en-US en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US en-US a en-US i   en-US d en-US en-US a en-US en-US c en-US en-US es en-US 2 en-US en-US n en-US en-US 7  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US dy en-US en-US  en-US n en-US y en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US  en-US en-US  en-US vey en-US en-US  en-US  en-US 13 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US n en-US en-US  en-US n en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US 2010 en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US  en-US o en-US n en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US B en-US  en-US en-US A en-US ti en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 6 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US e en-US en-US s en-US  en-US  en-US  en-US en-US  en-US n en-US  en-US 1 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US f en-US en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US e en-US en-US  en-US  en-US  en-US 1 en-US 68 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US f en-US en-US  en-US ew en-US en-US e en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US i en-US  en-US  en-US en-US  en-US n en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US h en-US en-US er en-US i   Av a i l a bl e   en-US p en-US en-US ten en-US en-US hn en-US y en-US en-US ends en-US en-US l en-US en-US the en-US en-US l en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US en-US  en-US en-US re en-US  en-US 6 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US y en-US en-US  en-US e en-US en-US  en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US en-US re en-US  en-US 6 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US en-US t en-US  en-US earn en-US  en-US 9 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 34 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US Lef en-US  en-US en-US  en-US  en-US ti en-US en-US  en-US en-US V en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US Pro en-US  en-US  en-US  en-US 34 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US ng en-US en-US ti en-US en-US  en-US  en-US  en-US en-US  en-US 1 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US O en-US en-US M en-US  en-US en-US l en-US en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US N en-US s en-US  en-US en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US  en-US to en-US en-US  en-US en-US n en-US  en-US  en-US  en-US 5 en-US  en-US  en-US D en-US  en-US  en-US en-US nt en-US en-US  en-US en-US  en-US en-US  en-US  en-US  en-US  en-US 6 en-US en-US  en-US 2 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US edes en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US t en-US  en-US en-US  en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access   23     en-US  en-US 22 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US t en-US en-US  en-US vey en-US en-US  en-US  en-US ne en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US  en-US  en-US tbed en-US en-US  en-US en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US G en-US  en-US en-US o en-US en-US  en-US en-US  en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US e en-US en-US ent en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US a en-US en-US z en-US en-US  en-US dez en-US en-US z en-US en-US  en-US en-US  en-US a en-US  en-US  en-US en-US  en-US 26 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US a en-US en-US a en-US en-US o en-US en-US  en-US a en-US en-US  en-US en-US o en-US en-US F en-US en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 8 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US  en-US  en-US en-US  en-US en-US  en-US 2015 en-US b en-US 5 en-US  en-US 9 en-US en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US o en-US en-US  en-US en-US  en-US  en-US en-US n en-US  en-US  en-US 45 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US k en-US  en-US  en-US en-US  en-US  en-US  en-US 0 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US r en-US  en-US 86 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US y en-US en-US by en-US en-US  en-US en-US  en-US s en-US  en-US 1 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US  en-US dez en-US en-US  en-US en-US n en-US en-US  en-US en-US  en-US n en-US y en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US en-US  en-US tem en-US en-US  en-US ti en-US en-US ve en-US en-US  en-US  en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US ty en-US en-US  en-US en-US  en-US  en-US  en-US 5 en-US  en-US 2 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US en en-US en-US  en-US  en-US  en-US en-US ess en-US  en-US 831 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US  en-US en-US ti en-US en-US  en-US ne en-US en-US  en-US e en-US en-US  en-US  en-US 26 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US en-US  en-US ve en-US  en-US  en-US en-US  en-US rk en-US  en-US 7 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US  en-US en-US Sy en-US  en-US  en-US en-US  en-US  en-US  en-US es en-US  en-US 1 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US  en-US  en-US r en-US rks en-US  en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US n en-US  en-US  en-US 9 en-US 0 en-US  en-US 411 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  en-US tems en-US en-US  en-US  en-US  en-US  en-US n en-US  en-US en-US  en-US v en-US es en-US  en-US  en-US 3 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US en en-US en-US  en-US  en-US en-US  en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US m en-US en-US  en-US  en-US th en-US en-US  en-US en-US  en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 4 en-US en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US en-US ng en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US  en-US 4 en-US  en-US  en-US  en-US  en-US rk en-US  en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 8 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US  en-US en-US  en-US t en-US dy en-US en-US n en-US s en-US  en-US  en-US 9 en-US en-US  en-US  en-US  en-US 8 en-US  en-US  en-US  en-US en-US  


2169-3536 \(c http://www.ieee.org/publications_standards/publications/rights/index.htm\l for more information This article has been accepted for publication in a future issue of this\ journal, but has not been fully edited. Content may change prior to fin\al publication. Citation information: DOI 10.1109/ACCESS.2017.2697839, IEEE Access  24      en-US  en-US i en-US  en-US en-US  en-US  en-US 9 en-US  en-US 2 en-US en-US  en-US  en-US  en-US 9 en-US  en-US  en-US  en-US en-US  en-US n en-US en-US n en-US  en-US t en-US 7 en-US  en-US  en-US 5 en-US en-US  en-US  en-US  en-US 0 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US n en-US en-US E en-US ess en-US  en-US 858 en-US en-US  en-US  en-US  en-US 1 en-US  en-US  en-US  en-US en-US  en-US  en-US en-US ess en-US  en-US 1 en-US en-US  en-US  en-US  en-US  en-US 2 en-US  en-US  en-US  en-US  en-US en-US  en-US  en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 3 en-US  en-US  en-US  en-US  en-US  en-US o en-US en-US  en-US en-US in en-US  en-US  en-US  en-US l en-US en-US  en-US g en-US  en-US 0 en-US en-US  en-US  en-US  en-US 4 en-US  en-US  en-US Ben en-US  en-US  en-US en-US  en-US  en-US en-US  en-US  en-US 7 en-US en-US  en-US  en-US  en-US 5 en-US  en-US  en-US  en-US en-US f en-US  en-US  en-US dy en-US en-US  en-US 11 en-US en-US  en-US  en-US  en-US 6 en-US  en-US  en-US  en-US  en-US en-US T en-US en-US  en-US o en-US  en-US en-US  en-US  en-US 1 en-US en-US  en-US  en-US  en-US 7 en-US  en-US  en-US z en-US en-US  en-US en-US ti en-US en-US  en-US  en-US  en-US en-US sort en-US  en-US  en-US 5 en-US  en-US  en-US  en-US 8 en-US  en-US  en-US z en-US en-US  en-US en-US  en-US f en-US en-US the en-US en-US  en-US  en-US en-US  en-US  en-US  en-US  en-US 121 en-US en-US  en-US  en-US  



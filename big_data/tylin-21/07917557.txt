d C g i r a h r a n r a g t y t s  
g l d o t s d o s y 
h 6 r l  I N g g n e 6   1 5   O n t h e o t h e r l 
t  m 6  H o w e v e r  m  9  I n d o o r m a p s a n d s e m a n t i c u n d e r s t a n d i n g n 
e t l e g n l s n 2 a s t h e c o r e o f o u r p r o c e s s i n g p i p e l i n e  T h e f 
f e s n 9   2 2    9    1 3   n g 7 a n d p l a c e s  1  t h a t  e 
g  d n  d l n n d g e 
n 4  D e e p C r o w d L a b e l r e t r o 002 t s t h e p r e t r a i n e d m o d e l s e 
The Fourth International Workshop on Crowd Assisted Sensing, Pervasive S\ystems and Communications 2017 978-1-5090-4338-5/17/$31.00 \2512017 IEEE 


C o  R D W K 3 a n d S e n s e L o c k  1 0  u t i l i z e s e n s o r d a t a f r o m m s 1 a n d  2 6  a t t e m p t t o c a t e g o r i z e p l a c e s b y t r a i n i n g m e k 5 t r i e s t o c o n n e c t t h e t e x t i n t h e c r o w d s e n s e d p i c t u r e s  4 a i m s t o a u t o m a t i c a l l y i d e n t i f y t h e n a m e o f t h e d o r 7 t h a t a t t e m p t s t o i d e n t i f y e e n  e l n  g g e  M D e l o 2  S e c o n d  t h e n d s r o d s  s e l 8  W e a d o p t e x i s t i n g p r a c t i c e i n D N N m o d e l i n g  8  a n d a p p l y t h e m t o o u r l o c a t i o n s r e o t d d  n s p  d  T  e  l s e s  s r  d e 4  F o r t h i s l a y e r  P  y  j j X i  e w j X T i P n k  1 e  w k X T i   e X i l e i  w i s  y d n j 2 N e  j N j 1 t r a i n e d 7 i s 0 a  4 a n d a p p l y t h e p r i o r d  P s  y  j j X i   y 2 L  001 P  y  j j X i  P L 1  y 2 L  001 P  y  j j X i   e    d L f t s P s  y  j j X i  n r X i s j 2 L  l M e N n l M e L 032 N e The Fourth International Workshop on Crowd Assisted Sensing, Pervasive S\ystems and Communications 2017 


h e  g s h t m  s 1  2 t 5 w i t h 0 h 5 e n l w t e  L 032 N  e  L 6\032 N  n L t s e N t n L h n N e  e s 8  I n t h i s a p p r o a c h w e k e e p t h e s 1 y y d s g e e L h  e s l f e s  T G c l  h d e 1 s n 8   1 1   W e p a s s t h e o u t p u t o f t h e s e e d  e  o e e t f e r s o 0 y d y e e e y   e 7 a s t h e a c t i v a t i o n g d 8  L D A Y C D S G n e e l n k e g d  t P I  y  j j X k i  r  e i t n k r X k i t 000 k n k l  P 000  y  l j 000 k  1 j 000 k j X X k i 2 000 k P I  y  j j X k i    e P 000  y  l j 000 k  n k r t  e t 000 k y   The Fourth International Workshop on Crowd Assisted Sensing, Pervasive S\ystems and Communications 2017 


r s l e 013  d M 1   A 9  9 A 5   A 5   A t  5   4 d a t a s e t  2 0 5  2  5 M  E t  0  6 7  1 5  6 K  A t  t   s    E t  t    E 013     l    M   l k x l P 000  y  l j 000 k   g l r s y P  y  p  j 000 k l  E G M E S E  n e y  e d r e s n n s s a t  e f l 1 o r V G G N e t  2 3  a r e m o r e t h a n 0 r 0 B y t 2 t h a t t a k e s a d v a n t a g e o f t h e w e i g h t s f o r m a t i n a t r a i n e d t t l h  030 y 5 n e  r  D A C D D T P N  m 6 t  n d s e  e 0 e 0 s t s n   a e l a s y d a   f o t 1  m 4 002 4 e 6 002 6   y 1  W i t h o u t t h i s s c h e m e  o u r n e t w o r k s u f f e r s   The Fourth International Workshop on Crowd Assisted Sensing, Pervasive S\ystems and Communications 2017 


r s  e  d   y t  t 6  n 5  e 4  y 4  n   s e  e 5  p 3  e 3  p 3  n   e p  p 1  e 5  t 3  m 2  t   e e  e 6  t 6  y 5  a 5  o   a e  e 5  p 3  m 2  n 2  k   W p  e 1  l 7  p 6  t 4  e V E N  d m 6 e  e  d r 6  5 f d 1 n d  o  r s e r 4 e e y e 1 n n n e   e y y   s The Fourth International Workshop on Crowd Assisted Sensing, Pervasive S\ystems and Communications 2017 


w e e s n 0 s y y e t  C D F K m s h l  l s s f y e r e e s f f e g r y  R S 1 M i t s c e n e c n n s  h t t p    p l a c e s  c s a i l  m i t  e d u  2 Q u a n t i z a t i o n o f d e e p n e u r a l m o d e l s  h t t p s    p e t e w a r d e n  c o m  2 0 1 6  0 5   3 M a r t i n A z i z y a n  I o n u t C o n s t a n d a c h e  a n d R o m i t R o y C h o u d h u r y  S u r n e g  4 C M B i s h o p  B i s h o p p a t t e r n r e c o g n i t i o n a n d m a c h i n e l e a r n i n g  2 0 0 1  5 Y o h a n C h o n  Y u n j o n g K i m  a n d H o j u n g C h a  A u t o n o m o u s p l a c e m n  n  6 Y o h a n C h o n  N i c h o l a s D L a n e  F a n L i  H o j u n g C h a  a n d F e n g Z h a o  g n n g  7 J i a D e n g  W e i D o n g  R i c h a r d S o c h e r  L i J i a L i  K a i L i  a n d L i F e i n E n  8 Y a n g q i n g J i a  E v a n S h e l h a m e r  J e f f D o n a h u e  S e r g e y K a r a y e v  J o n a t h a n  n s a  9 J u s t i n J o h n s o n  A n d r e j K a r p a t h y  a n d L i F e i F e i  D e n s e c a p  F u l l y  t 1  0 D o n n i e H K i m  Y o u n g h u n K i m  D e b o r a h E s t r i n  a n d M a n i B S r i v a s t a v a  n d s  1 A l e x K r i z h e v s k y  I l y a S u t s k e v e r  a n d G e o f f r e y E H i n t o n  I m a g e n e t n s s  2 Y a n n L e C u n  Y o s h u a B e n g i o  a n d G e o f f r e y H i n t o n  D e e p l e a r n i n g  e  3 L i J i a L i  R i c h a r d S o c h e r  a n d L i F e i F e i  T o w a r d s t o t a l s c e n e u n d e r c n R n  4 R u f e n g M e n g  S h e n g S h e n  R o m i t R o y C h o u d h u r y  a n d S r i h a r i N e l a k u  n s  5 M  M  M o a z z a m i  D  E  P h i l l i p s  R  T a n  a n d G  X i n g  O r b i t  A  E g  6 M o h a m m a d M a h d i M o a z z a m i  D e n n i s E P h i l l i p s  R u i T a n  a n d G u o l i a n g d n s  7 V i n o d N a i r a n d G e o f f r e y E H i n t o n  R e c t i 002 e d l i n e a r u n i t s i m p r o v e n l g  8 S i n n o J i a l i n P a n a n d Q i a n g Y a n g  A s u r v e y o n t r a n s f e r l e a r n i n g  E g  9 L i n g P e i  R o b e r t G u i n n e s s  R u i z h i C h e n  J i n g b i n L i u  H e i d i K u u s n i e m i  r  s  0 A r i a d n a Q u a t t o n i a n d A n t o n i o T o r r a l b a  R e c o g n i z i n g i n d o o r s c e n e s  n E n  1 P i o t r S a p i e z y n s k i  A r k a d i u s z S t o p c z y n s k i  R a d u G a t e j  a n d S u n e  e  2 A l i S h a r i f R a z a v i a n  H o s s e i n A z i z p o u r  J o s e p h i n e S u l l i v a n  a n d S t e f a n n d s  3 K  S i m o n y a n a n d A  Z i s s e r m a n  V e r y d e e p c o n v o l u t i o n a l n e t w o r k s f o r  R  4 C h r i s t i a n S z e g e d y  W e i L i u  Y a n g q i n g J i a  P i e r r e S e r m a n e t  S c o t t R e e d  w n e n  5 V 351 a s e t a m b i 351 n S C H U M  T h e e v i d e n t i a l f o u n d a t i o n s o f p r o b a b i l i s t i c  6 D a v i d K o f o e d W i n d  P i o t r S a p i e z y n s k i  M a g d a l e n a A n n a F u r m a n  a n d  e  7 A m i r R o s h a n Z a m i r  A f s h i n D e h g h a n  a n d M u b a r a k S h a h  V i s u a l n a   8 X u Z h a n g  F e l i x X i n n a n Y u  S h i h F u C h a n g  a n d S h e n g j i n W a n g   t 1  9 B o l e i Z h o u  A g a t a L a p e d r i z a  J i a n x i o n g X i a o  A n t o n i o T o r r a l b a  a n d s n s  The Fourth International Workshop on Crowd Assisted Sensing, Pervasive S\ystems and Communications 2017 


S Yang et al  Semantic Inference on Clinical Documents Combining Machine Learning Algorithms With an Inference Engine  classi\034cation model each time when new instances arrive the classi\034cation algorithms support incremental learning and thus reduce the cost in terms of the time and error rate This section 034rst introduces popular machine learning algorithms including Hoeffding Tree Hoeffding Adaptive Tree Hoeffding Option Tree and iOVFDT and then it presents a new classi\034cation algorithm to perform the classi\034cation task 1\051 HOEFFDING TREE Hoeffding tree 050HT\051 is an incremental learning algorithm It constructs a decision tree by using d ata streams as training datasets provided that the statistical distribution of the instances always stays the same 46 The Hoef fding tree does not store any instance in the main memory and thus it requires only the space that is proportional to the size of the tree and the associated suf\034cient statistics It updates the tree model whenever a new piece of data arrives HT guarantees that an optimal splitting attribute can be acquired based on a partial dataset rather than on a complete dataset An obvious merit of HT is that its output is asymptotically nearly identical to that of a non-incremental learner using in\034nite many instances This idea is mathematically supported by the Hoeffding bound 050HB\051 which selects attributes as test nodes by using a training dataset that is as small as possible which produces the same result as the result that would be chosen using an in\034nite dataset with high con\034dence 050e.g the con\034dence in Weka is 1-1.0E-7\051 In fact HB states that with a probability of 1 000 016  a random variable in the range R will not differ from the estimated mean after n observations by more than HB D q  0501  2 n 051 R 2 ln 0501 016 051  0501\051 where R is the class distribution and n is the number of instances that fall into a leaf Note that the Hoeffding bound is a monotonically decreasing function of instance number n Assume that X i is the attribute that has the highest evaluation value E i 050e.g the information gain or Gini Index\051 and X j is the attribute that has the second highest evaluation value E j  When E i 000 E j  HB  X i is chosen as the best splitting attribute at the current node with a con\034dence of 0501 000 016 051 2\051 HOEFFDING ADAPTIVE TREE AND HOEFFDING OPTION TREE The Hoeffding Adaptive Tree 050HAT\051 uses the ADWIN algorithm to monitor the performance of the branches during the period of tree construction In HAT when the accuracies of the old branches are lower than those of the new branches they are replaced This approach places an adaptive window of instances at each node which raises an alert whenever a change in the attribute-class statistics is detected at the node The essence of the AD WIN algorithm is the following whenever two large enough sub-windows of a sliding window W display distinct enough averages it is con\034dent that their corresponding expected values are different and the older portion of the window must be discarded  The Hoef fding bound is e v entually updated as follo ws m D 2  1  j W 0 j C 1  j W 1 j 0502\051 HB D p  0501  2 m 051 001 ln\0504 j W j 016 051  0503\051 where m is the harmonic mean of the length of subwindows j W 0 j and j W 1 j  and 016 is a con\034dence bound that indicates how con\034dent we want to be in the algorithm's output Hoeffding Option Trees 050HOT\051 are normal Hoeffding trees which contain option nodes that apply different tests An instance travels down multiple paths of the decision tree and arrives at multiple leaves HO T is capable of simultaneously representing multiple trees in a single structure It introduces another parameter 016 0  for deciding when to add another split option beneath a node that has already been split A ne w option can be added if the best unused attribute looks better than the current best existing option according to the N G criterion and a Hoeffding bound with con\034dence 016 0  016 0 can be expressed in terms of a multiplication factor 013  which speci\034es a fraction of the original Hoeffding bound 016 0 D e 013 2 ln 016 0504\051 HB D q   1  2 n  001 R 2 001 ln 0501 016 0 051  0505\051 3\051 iOVFDT iOVFDT optimizes the process of tree construction via functional tree leaf and incremental optimization to obtain a tradeoff between the accuracy and tree size iOVFDT utilizes a weighted Na\357ve Bayes classi\034er to reduce the effect of having an imbalanced class distribution where the classi\034er on the leaf can further enhance the prediction accuracy via the embedded classi\034er It chooses the class that has the maximum possibility computed by the weighted Na\357ve Bayes as the predictive class in a leaf p ijk D  ijk P 050 x ij j y k 051 001 P 050 y k 051  P 050 x ij 051 where  ijk D n ijk  P K k D 1 n ijk 0506\051 where x ij is the j th value of attribute X i  and y k is the k th class value Here n ijk is the suf\034cient statistic that re\035ects the number of instances that have attribute X i equal to x ij and class value equal to y k  4\051 VOTED ENSEMBLE MULTI-CLASSIFICATION ALGORITHM Ensemble methods merge several models whose individual predictions are combined in a certain manner 050e.g averaging\051 The output of this method is a 034nal prediction that has better accuracy and convenience to scale and parallelize compared with single classi\034er methods Among the current ensemble methods component classi\034ers are merged into an ensemble that has a 034xed size and models are built from relatively small subsets of the data Once the ensemble is full new classi\034ers are added only if they satisfy some quality VOLUME 5 2017 3535 


S Yang et al  Semantic Inference on Clinical Documents Combining Machine Learning Algorithms With an Inference Engine   Algorithm 1 Voted Ensemble Multi-Classi\034cation Algorithm  Input  data stream different classi\034ers 050e.g Hoeffding Tree\051 Output  a decision tree  Set classi\034er model T D null while more data points are available read j X i j instances between samples of the learning performance  j X i j is the sample frequency for each classi\034er C j in ensemble E if 050 T i 000 1 2 T 6D null 051  T i 000 1 is a temporary classi\034er model in the last iteration update temporary classi\034er model T i 000 1 using C j on X i and acquire T i  update not re-construct model elseif 050temporary model T i 000 1 D null 051 build a new model T i using C j on X i  if 050Quality\050 C j 051  Quality\050 C j 000 1 051\051 modify votes T i D T ij   T ij is created by the classi\034er C j with the best quality 050e.g accuracy or Kappa statistic in E 051 end_for save temporary classi\034er model T i  end_while  criterion 050e.g accuracy\051 which is based on their estimated ability to improve the ensemble's performance Due to the 034xed size of the ensemble one of the existing classi\034ers must be removed Then a tree is iteratively built upon upcoming data Performance estimations are conducted by testing the new tree 050and the existing ensemble\051 on the next chunk of data points In our voted ensemble multi-classi\034cation 050VEMC\051 algorithm as shown in Algorithm 1 decision trees are constructed by different classi\034ers that are designed for data stream mining Initially each classi\034er receives equally weighted votes With upcoming instances based on the error rate or prediction accuracy the weighted vote for each classi\034er is adjusted dynamically based on the computing quality of the corresponding classi\034er The basic idea of the VEMC algorithm is based on two assumptions 0501\051 the classi\034cation quality of an ensemble classi\034er is better than an ad hoc classi\034er and 0502\051 with successive upcoming instances the performance of an ensemble classi\034er improves The two assumptions above can be demonstrated by a simple case We use HT algorithms with different numbers of instances that a leaf should observe 050i.e grace period\051 between split attempts as different classi\034ers Assume that HT 1 and HT 2 with 200 and 100 grace periods respectively are applied on two cancer datasets with 34200 and 342000 instances each From Table 1 in the 034rst dataset 05034200 instances\051 HT 2 is better than HT 1 in terms of accuracy and stability but its performance becomes worse in the second dataset 050342000 instances\051 Thus it is advisable to use an ensemble classi\034er because the performance of different classi\034ers could be changed with different datasets TABLE 1 A simple case Moreover the classi\034er quality is positively correlated with the number of instances B EXPERT EXPERIENCE In addition to the rules that are generated from the decision tree it is also important to model the knowledge that medical experts use for clinical diagnosis This approach is important because of some speci\034c cases such that cases in which several diseases that are inferred by the rules in a decision list could have probabilities that are not signi\034cantly different from one another 050i.e p 025 0  05\051 Medical experts are encouraged to enter new rules or edit existing rules to provide a solid decision Rules that are directly provided by medical experts are given different priorities based on what stage in the diagnosis and treatment protocol the newly created/modi\034ed rule pertains to This paper designs a rule editor to facilitate medical experts to enter rules VI SEMANTIC INFERENCE The whole procedure of semantic inference on clinical documents in the inference engine can be segmented into two stages The 034rst stage focuses on disease detection which relies on knowledge that is learned from clinical document content and the rules transformed from decision trees as inputs to infer the type of disease The second stage makes an inference on disease treatment using the diagnosis output of the 034rst stage and then comparing between the clinical document and historical medical records with similar symptoms To implement these two stages a semantic inference algorithm with defeasible logic as an inference strategy is proposed in this section In the following sections we 034rst discuss the inference strategy that is used in our semantic inference scheme and then we discuss how to translate different types of semantic relations in our clinical tabular document into rules Finally the semantic inference algorithm that is used in the inference engine is given A INFERENCE STRATEGY 1\051 DEFEASIBLE LOGIC In the semantic inference scheme defeasible logic is applied for rule reasoning which handles both strict and defeasible rules especially the priority 050e.g a progressive relation in a document\051 It is a simple rule-based approach to reasoning with incomplete and inconsistent information 3536 VOLUME 5 2017 


S Yang et al  Semantic Inference on Clinical Documents Combining Machine Learning Algorithms With an Inference Engine  TABLE 2 Mapping strategy between SR and RS 050partial\051 Based on different structures of rules the Tabdoc rule syntax is used to de\034ne the rules as dif ferent technical components such as 050i\051 normal rule  each normal rule has a head and a body  The head part proceeds to the keyword THEN  whereas the body part follows the keyword IF and precedes the THEN part 050ii\051 fact  a fact is a special rule that has no body part When de\034ning a fact only the head part is given 050iii\051 semantic relation  different semantic relations stand for different functional relationships between the constituents in a document Before performing semantic inference on a clinical tabular document its semantic relations should be represented by different types of rules 050e.g facts queries or normal rules\051 This mapping from semantic relations to rules is explicitly discussed in Table 2 050iv\051 function  functions used in the head of a Tabdoc rule are called responders and they usually implement functionalities such as assignment or query Functions used in the body of a Tabdoc rule are called testers and they judge whether conditions are true or false 050v\051 queries and answers  queries are special rules without heads When de\034ning queries only the body part of a Tabdoc rule is given The answer to a query is often modeled as a set of facts 050vi\051 processes  a process is a conditional sequence of activities 050or operations\051 and is heterogeneous in different parties Different parties are likely to design heterogeneous processes that might be applicable and adaptable for speci\034c contexts Activities can be divided into three categories private community and public Private activities are internally de\034ned operations of a party and cannot be understood by the outside world Community activities are mutually understandable within a group of parties Public activities are public operations that are understandable by all parties In this paper a clinical document template corresponds to an activity that is de\034ned in the design phase of the document template By utilizing the ConexNet concept representation users can collaboratively create new concepts in vocabularies for activity de\034nition when creating processes For example a process could be similar to the following IF activity 1 050doc 1 051 THEN activity 2 050doc 2 051 where an activity contains a clinical document as its real parameter Having received a clinical tabular document 050CTD\051 it is required to process the document and extract a series of components as the input to an inference engine Table 2 partially summarizes the mapping strategy between each type of semantic relation 050SR\051 in CTD and the rules used in the inference engine 2\051 FUNCTIONALITY OF RULES In an inference engine the priority in the execution order of the rules is determined by their corresponding functionalities In this paper rules have the following functionalities 050i\051 basic conditions 050 R c 051 transformed from a new medical record 050ii\051 decision rules 050R dr 051 to generate the temporary result set TRS 050iii\051 expert rules 050 R epr 051 for the temporary result set update and decision 050iv\051 rules for a temporary treatment strategy 050 R ts 051 and 050v\051 rules for a treatment strategy 050 R emr 051 update The priority of rules with different functionalities is de\034ned as  R c  R dr  R epr  R ts  R emr  B SEMANTIC INFERENCE ALGORITHM 050SIA\051 Based on the inference strategy in Section 6.1 this section describes a Semantic Inference Algorithm 050SIA\051 that is used in the inference engine in the clinical diagnosis and treatment system 050CDTS\051 The goal of the algorithm is to implement a diagnosis and determine a treatment strategy with an input clinical tabular document and the corresponding rules 050e.g decision rules in a decision list\051 1\051 PRECONDITION OF SIA SIA has preconditions as follows R c V a set of rules about patient basic conditions 050e.g patient symptoms\051 that are transformed from a clinical tabular document 050as shown in Table 2\051 in a logical format 050e.g facts queries\051 DS 050Data source\051 historical medical records of patients in the form of arff or.csv R dr  decision rules transformed from the decision tree generated by the voted ensemble multi-classi\034cation algorithm R epr  expert rules created by medical experts for decision making R ts  R emr  a set of rules to query/update a treatment strategy VOLUME 5 2017 3537 


S Yang et al  Semantic Inference on Clinical Documents Combining Machine Learning Algorithms With an Inference Engine   Algorithm 2 SIA  1 BEGIN 2 P cd D Transform\050 clinical document 051 THEN  003 transform received clinical document into a medical record in a compatible form with DS 003  3  040 040 040 Cluster\050DS 2 P cd 051  003 cluster a new medical record into a group with similar historical medical records and form a new dataset  003  4 TRS 040 040 040 Apply\050r:R c 2 r:R dr 051  003 Apply decision rules 050R dr 051 on basic conditions 050R c 051 to get temporary result set 050TRS\051 003  5 IF j TRS j D 0 6 THEN send error message  7 ELSE  8 IF j TRS j D 1  003 j TRS j D 1 means the number of 034nal result is only one 003  9 THEN  1 TRS 040 040 040 TRS  10 ELSE 11 IF 050R epr  D NULL\051 12 1 TRS 040 040 040 Apply\050TRS 2 r R epr 051  003 Apply expert rules 050 R epr 051 on TRS to update j TRS j  003   13 FINAL  FRS 040 040 040 Query\050 2 R ts 051  003 Apply treatment strategy rules R ts on  based on 1 TRS and get disease treatment set 050FRS\051 003  14 IF 050R emr  D NULL\051 15 1 FRS 040 040 040 FRS 2 r:R emr   003 Use emergent rules R emr to update the treatment strategy in FRS 003  16 END  2\051 POST-CONDITION OF SIA The post-condition of SIA is the inferred results 050e.g disease diagnosis and treatment strategy\051 3\051 SIA ALGORITHM Based on the inference algorithm SIA as shown in Algorithm 2 the whole inference procedure is mainly divided into three steps as follows Step 1 050line 1-9\051 This step 034rst uses a clustering technique to form a group  where the medical record of a new patient is clustered into the group together with similar historical medical records in terms of patient symptoms This paper takes the COBWEB method as the clustering algorithm which is based on a category utility 050CU\051 function that measures the clustering quality The de\034nition of CU is CU  C 1  C 2      C k  D P l Pr C l  P i P j 050Pr a i D v ij j C l  2 000 Pr  a i D v ij  2 051  k 0507\051 where C 1  C 2      C k are the k clusters the outer clusters summation is over these clusters the next inner one sums over the attributes and a i is the i th attribute and it takes on the values v i 1  v i 2       which are addressed by the sum over j TABLE 3 Groups of manifestations in lung cancer 050lc\051 Note that the probabilities are obtained by summing over all of the instances Then the decision rules 050R dr 051 are created by our classi\034cation algorithm 050see Section 5.1.4\051 and are applied to basic conditions 050R c 051 to infer possible diagnoses generating a temporary result set TRS 050e.g TRS D diabetes mellitus breast mass}\051 If the number of inferred diseases in TRS is zero then it sends an error message If the number of components in TRS is one then it takes the TRS as the 034nal diagnosis 050 1 TRS\051 Step 2 050Line 10-12\051 This step is to exclude the unlikely inferences by using expert rules 050R epr 051 namely deducing the number of components in TRS and 034nally outputting the updated result set 050 1 TRS\051 as the diagnosis This step can be ignored if R epr is empty Step 3 050Line 13-16\051 The purpose of this step is to 034nd suitable previous patient treatment records for a new patient A query is executed on historical patient records  about the same disease in 1 TRS by using the rules R ts  and then it stores the treatment strategy of the best matching record in the disease treatment set 050FRS\051 If there is a set of emergent rules 050R emr 051 that are designed by clinicians it then uses R emr to dynamically update FRS and thereby output the new treatment strategy 1 FRS In this step we must compute the similarity degree among the different medical records Speci\034cally the similarity between the medical records is evaluated based on the symptoms Table 3 shows some of the symptoms 050i.e manifestations\051 of lung cancer Due to the complexity of the pathology the symptoms of each patient can be regarded as a combination of speci\034c manifestations Mathematically the calculation of a similarity degree between the symptoms in two medical records is essentially the comparison of two arrays We can use a matrix to represent the comparison result For simplicity we assume that different symptoms are independent of one another Thus when all of the symptoms are represented by symbols such as a b      z aa bb      and sorted in alphabetical order only 3538 VOLUME 5 2017 


S Yang et al  Semantic Inference on Clinical Documents Combining Machine Learning Algorithms With an Inference Engine  TABLE 4 Comparison of symptoms between two medical records the principal diagonal elements in the matrix are likely to be non-zero Table 4 shows an example of a comparison between two medical records The similarity computation 050 Sim or S 051 between two medical records is based on the similarity measurement 050 S att 051 for each pair of attributes 050 att 2 Attributes 051 The following formula shows one example of a similarity calculation between two medical records Sim  src  trg  D 1  n X att 2 Attributes 050 W a 003 S att  src  trg  051  0508\051 where src 050source\051 is a historical medical record and trg 050target\051 is a new patient record Sim\050src trg\051 represents the similarity degree for the symptoms in the two records 050 src and trg 051 Here n is the number of attributes 050i.e symptoms\051 in these two records S att represents the similarity degree for a certain attribute in the two records W a is the weight of attribute a  which represents the correlation degree between attribute a and the class attribute 050i.e the disease type\051 W a D GainRatio D InfoGain 050 a 051  P a 2 Attributes InfoGain 050 a 051 0509\051 The higher the value of W a  the more correlated that attribute a is with the class Thus it is necessary to consider the weight of the attribute when judging the similarity degree of two medical records In a decision tree an attribute that has a high correlation degree with the class attribute is close to the root node InfoGain  a  is the information gain of attribute a InfoGain  a  D I  S 1  S 2      S m  000 E  a  05010\051 where I  S 1  S 2      S m  is the information amount that is required to split a dataset I  S 1  S 2      S m  D 000 X m i D 1 p i log 2 p i 05011\051 where S i is the number of samples in classes C i 050i D 1  2      m\051 and p i means the probability of the instances in S D f S 1  S 1      S m g that belong to class C i  E  a  is the information amount for splitting a sub-dataset by attribute a E  a  D X v j D 1 050 s 1 j C s 2 j C    C s mj 051  s 002 I 000 s 1 j  s 2 j      s mj 001 05012\051 where s ij is the set of instances whose class values are C i in the subset of f s j j a D a j  j 2 1  2      v  s j 2 S g  I 000 s 1 j  s 2 j      s mj 001 means the average information amount that is required to identify the class labels for all of the instances in s j  I 000 s 1 j  s 2 j      s mj 001 D 000 X m i D 1 p ij log 2 050 p ij 051  05013\051 where p ij is the probability that the instances in s j belong to the class value C i  The value of S att depends on the data type of attribute att  If attribute att is a numeric attribute then S att  x  y  D min f x att  y att g  B a 05014\051 where B a is the breadth of the range of attribute att  and x att  y att  B a are all mapped into the interval 0 This approach is applicable because the range of every numerical attribute in this application is bounded If attribute att is a nominal attribute then S att  x  y  D 032 1  iff x D y 0  iff x 6D y 05015\051 where x  y 2 f true  false  yes  no  and so on g  Table 4 can be abstracted as a matrix called a similarity measurement matrix as shown below  D a b c d e 2 6 6 6 6 4 S a 0 0 0 0 0 S b 0 0 0 0 0 S c 0 0 0 0 0 S d 0 0 0 0 0 S e 3 7 7 7 7 5 05016\051 Similarity measurement matrix  is a diagonal matrix while the range of the value of the diagonal elements is in 0 and the v alues of the non-diagonal elements are zero 1 means that the values of the two medical records regarding the same attribute are equal while 0 means that they are unequal We take the historical medical record whose matrix  has the maximum rank as the best matching case for the new medical record in the treatment inference phase The rank is the number of non-zero rows in the reduced row echelon form of the matrix The rank could vary because different medical records could have different values on the same symptoms Speci\034cally if any one value out of two medical records regarding the same symptom 050e.g attribute a 051 is null then the diagonal element becomes 0 The diagonal element becomes 1 if the attribute a is nominal and the two values on a are the same If attribute a is numerical then a probability will be given to describe the similarity between the records VII EXPERIMENTS Our aim is the evaluation of CDTS for disease detection and treatment suggestions with machine learning algorithms 050e.g clustering and classi\034cation\051 and an inference engine A EXPERIMENTAL DATA AND EVALUATION MATRICES 1\051 DATA SOURCE The dataset has been crawled from the website of the Cancer Data Access System 050CDAS https://biometry.nci.nih.gov cdas/\051 which records data from the NLST 050National Lung Screening Trial\051 PLCO 050Prostate Lung Colorectal and VOLUME 5 2017 3539 


S Yang et al  Semantic Inference on Clinical Documents Combining Machine Learning Algorithms With an Inference Engine  FIGURE 5 Snapshot for GUI-based clinical tabular document template designer Ovarian Cancer Screening Trial\051 and IDATA 050Interactive Diet and Activity Tracking in AARP study\051 cancer studies It includes 342 outpatient records with 31 attributes by integrating several datasets such as Lung Cancer Spiral CT Comparison Read Abnormalities and Diagnostic Procedures through the patient's ID as a key The attributes of each medical record include the lung cancer grade cancer position treatment type and abnormality type 2\051 EVALUATION MATRICES This paper uses the accuracy and kappa statistic as the evaluation matrices that are most commonly used in machine learning algorithm evaluation The accuracy 050Acc\051 is de\034ned as the number of true positives 050T P 051 over the number of true positives plus the number of false positives 050F P 051 as de\034ned in formula 05017\051 Acc D T p  T p C F p 05017\051 The kappa statistic 050 024 051 measures the agreement of a prediction with the true class where 1.0 means complete agreement as de\034ned in formula 05018\051 024 D p o 000 p e  1 000 p e 05018\051 where p o is the relative observed agreement among the raters and p e is the hypothetical probability of a chance agreement B EXPERIMENTAL PROCEDURE The experimental procedure includes the following steps Step 1 050Data Preprocessing\051 This step focuses on two types of data transformation One type is to transform historical medical records 050HMR\051 to historical patient instances in arff or csv format The other type is to transform a new DocLang-based clinical tabular document into a patient instance in arff or csv format where the language terms that are present in the template become attributes whose corresponding values are textual terms that are input from users 050e.g clinicians\051 Because the clinical document is based on the clinical tabular document model 050CTDM\051 which guarantees semantic consistency through the term chain and semantic relation chain the transformation of clinical documents among heterogeneous contexts does not cause semantic loss Fig 5 shows the GUI of the clinical tabular document template designer 050CTDTD\051 CTDTD generates customized clinical document templates that enable clinicians to design a variety of clinical tabular documents according to their particular needs For example a template that allows patients to enter their symptoms about lung cancer can be made in such a way that new medical records can be created for online consultation In this case a rei\034ed clinical document corresponds to a record in a dataset 050e.g a row in an arff or csv 034le\051 Standard windows data entry elements 050e.g check boxes radio buttons input boxes and combo boxes\051 can also be inserted into the templates To further facilitate the data input a semantic input method 050SIM\051 is also inte grated in CTDTD Any term that is input through SIM is referred from the CONEX dictionary 41 by selecting the e xact meaning from a drop-down list Each concept in the CONEX dictionary has a unique identi\034er 050 iid 051 that points to the same meaning regardless of the context The information to 3540 VOLUME 5 2017 


S Yang et al  Semantic Inference on Clinical Documents Combining Machine Learning Algorithms With an Inference Engine  TABLE 5 Examples of patient records in dataset   exchange is the logical combination 050i.e the logical structure in the CTDM model\051 of iid\050s\051 of different concepts CTDTD consists of several frames The frame of the Subtable form lists the most-often used basic sub-table forms The Template Preview frame is an operation platform for designing the layout structure of the clinical tabular documents The users drag the required sub-table forms to the console in the Template Preview frame or manually create the sub-table forms by merging or splitting the table cells Each type of sub-table form has to be mapped to at least a certain type of semantic relation managed by the attribute  st  in the Property List frame  which is identi\034ed by a group identi\034er GID The semantic relations of manually created sub-table forms should be set in the Property List frame by the users themselves In addition clicking on any cell in the Template Preview frame will pop up the Property List frame that shows all of its denoters All of the sub-table forms in the Template Preview frame construct a complete clinical tabular document template The Logical Structure frame shows the logical data model in a tree-based pattern Step 2 050Clustering\051 Compare the new patient instance with historical ones to acquire a set of the same or similar instances and form a group Two assumptions are de\034ned for simplicity of discussion The 034rst is that patients with the same or similar attributes 050i.e physical examination parameters\051 and corresponding values are very likely to have the same disease The second is that different hospitals have the same examination protocol on symptoms of the same disease The purpose of these two assumptions is to ensure that all of the patients with the same class of diseases are clustered into the same group as much as possible The group that the new patient instance falls into is taken as a new dataset Step 3 050Classi\034cation\051 Different diseases can share similar symptoms 050e.g fever white blood cell counting increase and so on\051 Thus patients who have the same or similar symptoms could have different diseases According to the new dataset  050i.e the group\051 acquired in step 2 a decision tree is constructed via running the voted ensemble multiclassi\034cation algorithm on   For example if the new patient being tested has lung cancer the new dataset  as input for classi\034cation includes 342 outpatient records of the data source 050see Section VIIA1\051 Each record in  contains 31 attributes with the attribute lc_grade 050see Table 3\051 as a class The class attribute has 034ve categories which indicate the severity of lung cancer Table 5 exempli\034es 034ve historical patient records in the dataset   TABLE 6 Decision tree vs decision rules Step 4 050Rule Set Creation\051 Extract rules from the decision tree and form a decision list to be used as the rule base for inference Then the decision list will be the input of the inference engine Table 6 shows an iOVFDT-generated decision tree and its decision rules Step 5 050Disease Detection\051 Predict the type of disease for the new patient instance by using the rules in the decision list and then store the inferred possible diseases in TRS Fig 6 shows the GUI of the disease detector to cluster similar cases and infer possible diseases The top frame contains a detailed description of the recovered cases while the leftbottom frame contains inferred diseases with probability values followed Once similar instances are recovered by clicking the clustering button at the bottom right users 050e.g doctors\051 can select the most similar ones As shown on the top frame in Fig 6 each instance is followed by a multiple choice box When the clustering button is clicked multiple choice boxes of all instances are selected because the system by default considers all cluttering-generated instances to be similar to the new one After that the classi\034cation button is clicked to show the probabilities of inferred diseases Then the doctor is encouraged to judge whether the inferred diagnosis is correct or not Initially the check box followed by Primary disease detection is selected When the doctor considers that any disease in Other disease detection has high probability the VOLUME 5 2017 3541 


S Yang et al  Semantic Inference on Clinical Documents Combining Machine Learning Algorithms With an Inference Engine  FIGURE 6 Snapshot for GUI-based disease detector corresponding check box can be selected If diagnosis by the doctor does not appear in the inferred results it can be manually typed using the Expert decision input box with a probability Once disease detection output is revised by the doctor the new instance including the diagnoses will be stored to a TRS Step 6 050Disease Revision\051 Doctors need to make a definite clinical decision by designing the negative as failure in defeasible logic 050i.e negative rules\051 through a rule editor 050see Fig 7\051 to avoid impossible cases in TRS For example if score on one symptom is higher 050or lower\051 than certain value it is unlikely to be certain disease Repeat this procedure until only one disease is left and we obtain updated temporary result set 1 TRS Step 7 050Treatment Strategy Reasoning\051 Different diseases have different treatment protocols In addition even for the same disease because the physical conditions of a patient are ever-changing during the treatment period the treatment strategies could vary frequently and cannot be determined dynamically by most traditional CDSS Thus we must de\034ne more general rules In the following section we 034rst propose an assumption before giving two general rules as an example for treatment strategy reasoning Assumption different patients have different treatment strategies A treatment strategy can be divided into different phases as shown below FIGURE 7 Rule editor Rule 1 If the symptoms of a patient at the current stage of treatment match those of a historical medical record during the same period then the patient takes the corresponding treatment from that old record as the strategy in the current phase Rule 2 If no historical medical records match the new medical record in terms of symptoms at the current treatment phase then according to the symptoms of the new patient in all previous treatment phases 7  we collect a group  with records that share similar symptoms with 7 in previous phases The next step is to compare the symptoms of a new patient at the current stage with phases of each record in  3542 VOLUME 5 2017 


S Yang et al  Semantic Inference on Clinical Documents Combining Machine Learning Algorithms With an Inference Engine  TABLE 7 Comparison of different classifiers used in CDTS and determine the one whose symptoms are the closest to those of the new patient at this stage and its corresponding treatment strategy is hereby applied to the patient at this stage It is of note that the treatment phase numbers of the old and new medical records might not be the same in this case Afterward the treatment phase number for the new patient is adjusted to the historical medical record's next treatment phase number Repeat Rule1 until the patient fully recovers For example a dataset  will be established when the symptoms of a new patient in the third phase do not match the historical records at the same time point Then we go through all of the records again and if any two phases of one historical record share similar symptoms with the 034rst two phases of the new patient it will be kept in   Given that any historically successful treatment 021 has m treatment phases on average the comparison procedure will be conducted C 2 m D m\050m 000 1\051  2 times at most If there are n cases then the time complexity is O\050n 003 m 2 051 This method is used to capture extended similar historical cases After the establishment of   all of the phases of the cases in  are compared with the third phase of the new patient treatment on the symptoms to 034nd the most similar one with the maximum rank at the similarity measurement matrix   which determines the treatment strategy for the new patient at the third phase C RESULTS AND ANALYSIS To enlarge the training dataset we randomly resample the dataset 1000 times without replacement by using the 034lter Resample in Weka In Table 7 iOVFDT constructs the smallest tree model compared with the other three classi\034ers in terms of the nodes leaves and depth HT and HAT also perform well in the construction of a nice tree model with 97 and 116 nodes 50 and 58 leaves and 21 and 23 depths respectively HOT has the largest tree size with more nodes and leaves which implies training dataset over\034tting As shown in Figs 8 and 9 Hoeffding-based tree classi\034ers have better performance compared to iOVFDT in terms of the classi\034cation correctness 050i.e accuracy\051 and kappa statistic 050i.e stability\051 With continuous incoming instances the accuracy and stability of Hoeffding-based tree classi\034ers rise with some 035uctuation while the performance of iOVFDT is kept at a horizontal level Similar to HAT the voted ensemble FIGURE 8 Comparison of classification correctness FIGURE 9 Comparison of the Kappa statistic FIGURE 10 Comparison of the evaluation time of the CPU multi-classi\034cation algorithm 050VEMCA\051 also performs well in terms of accuracy and stability and outperforms HAT when the number of instances is larger than 340000 Figs 10 and 11 compare the evaluation time of the CPU and the memory cost of the 034ve classi\034cation algorithms iOVFDT shows the fastest speed and the smallest memory cost among the 034ve classi\034cation algorithms HT gives better performance than HAT and HOT with 6.93 seconds in CPU occupation and a 0.91-Mb memory cost VEMCA's evaluation time and memory are 20.73 seconds and 1.62 Mb respectively VOLUME 5 2017 3543 


S Yang et al  Semantic Inference on Clinical Documents Combining Machine Learning Algorithms With an Inference Engine  FIGURE 11 Comparison of the memory cost VIII CONCLUSIONS Modern techniques such as CDSS and HIS have substantially facilitated clinical diagnosis and treatment However some of the emergent problems remain to be considered The 034rst problem is challenging the traditional data analysis techniques due to rapidly increasing amounts of multidimensional clinical data The second is the dif\034culty of clinical information integration Clinical information from different contexts are heterogeneous in terms of structure and semantics For the bene\034t of patients and long-term clinical development it is very promising to integrate clinical information 050e.g outpatients medical records\051 from different clinicians or hospitals to assist in clinical decision-making The third problem is the call for personalized medicine and professional medical treatment because different doctors or hospitals are good at diagnosing and treating different diseases and the patients have the freedom to choose among them To solve the three problems above this paper proposes a clinical diagnosis and treatment system 050CDTS\051 that assists patients in choosing clinicians or hospitals according to their requirements 050e.g distance from home to hospital\051 The foundation for disease detection in CDTS consists of decision trees that are created by our voted ensemble multiclassi\034cation algorithm that enables decision-tree-based data stream mining Furthermore to integrate clinical documents and heterogeneous health information systems a new clinical tabular document model is proposed which represents clinical documents in tabular format and maintains consistent vocabulary terms and semantic relations among different contexts through the term chain and semantic relation chain Additionally a novel semantic inference algorithm is designed for disease detection and treatment suggestion based on the rules that are generated by decision trees and similarity computations among medical records The contribution of this paper can be summarized as follows 342 A uni\034ed clinical tabular document model 050CTDM\051 implemented by a new clinical tabular document language 050DocLang XML based\051 facilitates the interoperability among different clinical decision support systems 050CDSS\051 342 A new voted ensemble multi-classi\034cation algorithm is proposed in terms of running multiple decision treebased classi\034cation algorithms simultaneously on the same data stream and voting for the best output The results are associated with statistical information on the accuracy of classi\034cation which provides proof of optimization 342 A novel clinical diagnosis and treatment system with a newly designed semantic inference algorithm supports clinicians in the decision making process as well as saving time and expense for the patients For future work it is necessary to expand DocLang to become a more comprehensive markup language by importing more semantic relation types for more complex clinical documents These studies are in progress and are expected to present valuable results later REFERENCES   M A Makary and M Daniel Medical error\026The third leading cause of death in the US BMJ  vol 353 p i2139 May 2016   D Kopec M H Kabir D Reinharth O Rothschild and J A Castiglione Human errors in medical practice Systematic classi\034cation and reduction with automated information systems J Med Syst  vol 27 no 4 pp 297\025313 Aug 2003   L T Kohn J M Corrigan and M S Donaldson Eds To Err is Human Building a Safer Health System  Washington DC USA National Academy Press 2000   D W Bates et al  The Costs of adverse drug events in hospitalized patients JAMA  vol 277 no 4 pp 307\025311 1997   H Singh et al  Types and origins of diagnostic errors in primary care settings JAMA Internal Med  vol 173 no 6 pp 418\025425 Mar 2013   W Rogers B Ryack and G Moeller Computer-aided medical diagnosis Literature review Int J Biomed Comput  vol 10 no 4 pp 267\025289 Aug 1979   D Kopec and D Michie Mismatch Between Machine Representations and Human Concepts Dangers and Remedies  Brussels Belgium Forecasting and Assessment in Science and Technology 1992   D Wallace and D R Kuhn Software quality lessons from medical device failure data U.S Dept Commerce Technol Admin Nat Inst Standards Technol Gaithersburg MD USA Tech Rep NISTIR 6407 1999   D L Bates et al  Effect of computerized physician order entry and a team intervention on prevention of serious medication errors JAMA  vol 280 no 15 pp 1311\0251316 1998   W G Baxt Application of arti\034cial neural networks to clinical medicine Lancet  vol 346 pp 1135\0251138 Oct 1995   M S Hossain Cloud-supported cyber\025physical localization framework for patients monitoring IEEE Syst J  to be published A v ailable http://dx.doi.org/10.1109/JSYST.2015.2470644   E S Berner Ed Clinical Decision Support Systems Theory and Practice  2nd ed New York NY USA Springer 2007 pp 3\02522   B Rothman J C Leonard and M M Vigoda Future of electronic health records Implications for decision support Mount Sinai J Med  vol 79 no 6 pp 757\025768 2012   M H Trivedi et al  Barriers to implementation of a computerized decision support system for depression An observational report on lessons learned in real world clinical settings BMC Med Inform Decision Making  vol 9 p 6 Jan 2009   C S\341ez A Bres\363 J Vicente M Robles and J M Garc\355a-G\363mez An HL7-CDA wrapper for facilitating semantic interoperability to rule-based clinical decision support systems Comput Methods Programs Biomed  vol 109 no 3 pp 239\025249 Mar 2013   B Rothman J C Leonard and M M Vigoda Future of electronic health records Implications for decision support Mount Sinai J Med J Transl Person Med  vol 79 no 6 pp 757\025768 Nov./Dec 2012   J Gholap V P Janeja and Y Yesha Uni\034ed framework for clinical data analytics 050U-CDA\051 in Proc IEEE Int Conf Big Data 050Big Data\051  Oct./Nov 2015 pp 2939\0252941 3544 VOLUME 5 2017 


S Yang et al  Semantic Inference on Clinical Documents Combining Machine Learning Algorithms With an Inference Engine    S Hussain and S Lee Semantic transformation model for clinical documents in big data to support healthcare analytics in Proc 10th Int Conf Digit Inf Manage 050ICDIM\051  Oct 2015 pp 99\025102   M Herland T M Khoshgoftaar and R Wald Survey of clinical data mining applications on big data in health informatics in Proc 12th Int Conf Mach Learn Appl 050ICMLA\051  vol 2 Dec 2013 pp 465\025472   A Bifet and R Gavald\340 Adaptive learning from evolving data streams in Proc Int Symp Intell Data Anal  Aug 2009 pp 249\025260   R J Quinlan C4.5 Programs for Machine Learning 050Morgan Kaufmann Series in Machine Learning\051 San Mateo CA USA Morgan Kaufmann Jan 1993   L Breiman J Friedman R Olshen and C Stone Classi\034cation and Regression Trees  Monterey CA USA Wadsworth 1994   P Domingos and G Hulten Mining high-speed data streams in Proc 6th ACM SIGKDD Int Conf Knowl Discovery Data Mining  Aug 2000 pp 71\02580   N Oza and S Russell Online bagging and boosting in Arti\034cial Intelligence and Statistics  San Mateo CA USA Morgan Kaufmann 2001 pp 105\025112   A Bifet G Holmes B Pfahringer R Kirkby and R Gavalda New ensemble methods for evolving data streams in Proc 15th ACM SIGKDD Int Conf Knowl Discovery Data Mining 050KDD\051  New York NY USA 2009 pp 139\025147   E Ocampo M Maceiras S Herrera C Maurente D Rodr\355guez and M A Sicilia Comparing Bayesian inference and case-based reasoning as support techniques in the diagnosis of acute bacterial meningitis Expert Syst Appl  vol 38 no 8 pp 10343\02510354 2011   I Watson Applying Case-Based Reasoning Techniques for Enterprise Systems  San Mateo CA USA Morgan Kaufmann 1997   L OtavioAlvares Racioc\355nio Baseadoem Casos in Inform\341tica UFRGS  2006 A v ailable http://www inf.ufsc.br 030 luis.alvares INE5633/RaciocinioBC.pdf   A Aamodt and E Plaza Case-based reasoning Foundational issues methodological variations and system approaches AI Commun  vol 7 no 1 pp 39\02559 2004   R L De Mantaras et al  Retrieval reuse revision and retention in casebased reasoning Knowl Eng Rev  vol 20 no 3 pp 215\025240 2005   J Kolodner Case-Based Reasoning  San Mateo CA USA Morgan Kaufmann 1993   S K Pal and S C K Shiu Foundations of Soft Case-Based Reasoning  Hoboken NJ USA Wiley 2004   T Cerquitelli S Chiusano and X Xiao Exploiting clustering algorithms in a multiple-level fashion A comparative study in the medical care scenario Expert Syst Appl  vol 55 pp 297\025312 Aug 2016   M Ben Alaya S Medjiah T Monteil and K Drira Toward semantic interoperability in one M2M architecture IEEE Commun Mag  vol 53 no 12 pp 35\02541 Dec 2015   I Lemmens J P Koster and S Valera Achieving interoperability at semantic level in On the Move to Meaningful Internet Systems 050Lecture Notes in Computer Science\051 vol 9416 I Ciuciu et al  Eds Cham Switzerland Springer 2015   A O Shigarov Table understanding using a rule engine Expert Syst Appl  vol 42 no 2 pp 929\025937 2015   G Xiao Semantic document exchange for electronic business through user-autonomous document sense-making Ph.D dissertation Univ Macau Zhuhai China 2015   S Yang and J Guo A multi-viewed document representation for semantic document exchange in Proc IEEE 12th Int Conf e-Bus Eng 050ICEBE\051  Oct 2015 pp 154\025159   A M Namboodiri and A K Jain Document structure and layout analysis in Digital Document Processing  London U.K Springer 2007 pp 29\02548   A K Jain and B Yu Document representation and its application to page decomposition IEEE Trans Pattern Anal Mach Intell  vol 20 no 3 pp 294\025308 Mar 1998   J Guo Collaborative conceptualisation Towards a conceptual foundation of interoperable electronic product catalogue system design Enterprise Inf Syst  vol 3 no 1 pp 59\02594 2009   S Nam S Lee J G B Kim and H G Kim STEP An ontology-based smart clinical document template editing and production system Expert Syst Appl  vol 41 no 6 pp 3005\0253015 2014   Z Gong M Muyeba and J Guo Business information query expansion through semantic network Enterprise Inf Syst  vol 4 no 1 pp 1\02522 2010   J Guo L Xu Z Gong C P Che and S S Chaudhry Semantic inference on heterogeneous e-marketplace activities IEEE Trans Syst Man Cybern A Syst Humans  vol 42 no 2 pp 316\025330 Mar 2012   C S G Khoo and J.-C Na Semantic relations in information science Annu Rev Inf Sci Technol  vol 40 no 1 p 157 2006   G Hulten and L Spencer PedroDomingos Mining time-changing data streams in Proc ACM SIGKDD Int Conf Knowl Discovery Data Mining  2001 pp 97\025106   I H Witten and E Frank Data Mining Practical Machine Learning Tools and Techniques  San Mateo CA USA Morgan Kaufmann 2005   A Bifet Adaptive learning and mining for data streams and frequent patterns ACM SIGKDD Explorations Newslett  vol 11 no 1 pp 55\02556 2009   B Pfahringer G Holmes and R Kirkby New options for hoeffding trees in Proc AI  2007 pp 90\02599   B Pfahringer G Holmes and R Kirkby New options for hoeffding trees in Proc Austral Joint Conf Artif Intell  Dec 2007 pp 90\02599   H Yang and S Fong Incrementally optimized decision tree for noisy big data in Proc 1st Int Workshop Big Data Streams Heterogeneous Source Mining Algorithms Syst Program Models Appl  Aug 2012 pp 36\02544   W N Street and Y Kim A streaming ensemble algorithm 050SEA\051 for large-scale classi\034cation in Proc 7th ACM SIGKDD Int Conf Knowl Discovery Data Mining  Aug 2001 pp 377\025382  Cancer Data Access System of American National Cancer Institute  accessed on May 25 2016 A v ailable https://biometry  nci.nih.gov/cdas   S Tsumoto Automated extraction of hierarchical decision rules from clinical databases using rough set model Expert Syst Appl  vol 24 no 2 pp 189\025197 2003   S Yang and J Guo A novel approach for cross-context document reasoning in e-commerce in Proc 6th IEEE Int Conf Softw Eng Service Sci 050ICSESS\051  Sep 2015 pp 1018\0251025   J Guo SDF A sign description framework for cross-context information resource representation and interchange in Proc Enterprise Syst Conf 050ES\051  Aug 2014 pp 255\025260   Y Zhang M Chen D Huang D Wu and Y Li iDoctor Personalized and professionalized medical recommendations based on hybrid matrix factorization Future Generat Comput Syst  vol 66 pp 30\02535 Jan 2016   Y Zhang D Zhang M M Hassan A Alamri and L Peng CADRE Cloud-assisted drug recommendation service for online pharmacies Mobile Netw Appl  vol 20 no 3 pp 348\025355 2015   M Chen Y Ma J Song C.-F Lai and B Hu Smart clothing Connecting human with clouds and big data for sustainable health monitoring Mobile Netw Appl  vol 21 no 5 pp 825\025845 2016   M Chen NDNC-BAN Supporting rich media healthcare services via named data networking in cloud-assisted wireless body area networks Inf Sci  vol 284 pp 142\025156 Nov 2014   J Wan C Zou S Ullah C.-F Lai M Zhou and X Wang Cloud-enabled wireless body area networks for pervasive healthcare IEEE Netw  vol 27 no 5 pp 56\02561 Sep./Oct 2013   X Chen L Wang J Ding and N Thomas Patient 035ow scheduling and capacity planning in a smart hospital environment IEEE Access  vol 4 pp 135\025148 2016 SHUO YANG 050M'15\051 received the master's degree in software engineering from Dalian Jiaotong University Dalian China in 2013 He is currently pursuing the Ph.D degree in E-commerce technology with the Department of Computer and Information Science University of Macau His research interests include document engineering and semantic inference mainly applied to the 034eld of E-commerce E-marketplace and clinical area VOLUME 5 2017 3545 


S Yang et al  Semantic Inference on Clinical Documents Combining Machine Learning Algorithms With an Inference Engine  RAN WEI received the master's degree in pharmaceutical engineering from the New Jersey Institute of Technology Newark NJ USA in 2011 He is currently pursuing the Ph.D degree in biomedical sciences with the Department of Microbiology Rutgers University Newark His research interest focuses on the quantitative analysis of epigenetic pathways in vitamin D-regulated lung immune responses JINGZHI GUO 050M'05\051 received the the B.Econ degree in international business management from the University of International Business and Economics Beijing China in 1988 the M.Sc degree in computation from The University of Manchester Manchester U.K in 2010 and the Ph.D degree in internet computing and e-commerce from Grif\034th University Brisbane Australia in 2005 He is currently an Associate Professor in eCommerce Technology with the University of Macau Macau China His research interests include concept representation semantic integration and collaboration systems mainly applied to the 034elds of e-commerce e-marketplace e-banking and the virtual world LIDA XU 050M'86\025SM'11\051 is currently an Academician of the Russian Academy of Engineering He was recognized as a Highly Cited Researcher by Thomson Reuters 050Clarivate\051 in 2016 3546 VOLUME 5 2017 


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination EEE   19 S Gong Cheng om Xidian  in 2007 and the M.S. and technical  3   He is currently an Associate Professor with Northwestern Polytechnical University. His main research interests are computer vision and pat tern recognition ei Han ently techni ch The ersity cher at the Uni His omputer vision, multi and brain imaging analysis. He es such as IEEE T C t T IONS  ON P A t t T ERN  A A YSIS  AND M CHINE  I I N t T ELLIGENCE AMI I I N t T ER NA t T IONAL J OURNAL  OF  C C O m p MP U t T ER V ISION V T C t T IONS  ON  I I m M GE P SSING  TIP C C ONFERENCE  ON  C C O m p MP U t T ER V ISION  AND P A t t T ERN  R R OGNI t T ION VPR I I N t T ERNA t T IONAL  C C ONFERENCE  ON  C C O m p MP U t T ER V ISION V I I N t T ERNA t T IONAL J OIN t T  C C ONFER ENCE  ON  A A R t T IFICIAL  I I N t T ELLIGENCE IJCAI Prof. Han is an Associate Editor of the I E E E IEEE T RANSAC t T IONS  ON  H H U m M AN M ACHINE  S S YS t T E m M S  Neurocomputing   Processing and Machine Vision and Applications  u ently f  tor ests include emote sensing om e eas  international journal, including Neurocomputing Elsevier Cognitive  Computation Springer International Journal of Image and Graphics  World of Scientific 



   
 
 
 
 
  
  
   


             


                 


                   


      


 structure Fig.7 \(I\. As output, the local Hasse diagram associated with the m 1 s conditional Itemset-tree\ be drawn incrementally. Indeed the in-depth of the 1 m L list enables to connect, first, the closed itemsets {m 1 m 3 m 4 m 5 and m 1 m 2 m 3 m 4 m 5 and second to connect {m 1 m 3 m 4 m 5 and m 1 m 3 m 4 m 5 m 6 Fig. 7 \(g, H, I Thus, we can extract the local associated association rules The Same process is repeated for the other itemsets written in bold in the extraction list from Table II m 1 3  m 2 3; m 3 4 m 4 4 ; m 5 3 ; m 6 3  Finally, we have all sub-ordered structures and their corresponding local association rules, then we merge the local generic association rules to derive a global one and analyze this new base to detect faulty node and generate useful statistics F  Derivation of Generic Bases of Association Rules Association rules describe how events occur together in the data and are used to represent and identify dependencies between items in the transaction database. The problem of the relevance and usefulness of the extracted association rules is of primary importance. Indeed, in most real life databases thousands and even millions of high-confidence rules are generated among which many may be redundant. We chose to use association rules because there exist efficient algorithms [1 4, 5 t o m i n e  th em f r om l a rg e c o r p or a  In th is p a pe r w e  ar e interested in generic association rules defined as follows Definition1 Minimal exact association rule   g Y g    where Y is a closed itemset and g is a minimal generator of Y  Definition2 Minimal approximate association rule   1 g Y g    g is a minimal generator of a closed itemset Y and Y 1 is a closed itemset Y  Y 1  Y 1 is a successor of Y 2    Fig 6. Node Structure in the Sub Structure Graph       Step 5   Fig. 7.  States of Nodes for the Construction of the Ordered Structure Associated to the 1-itemset m1/3 In the ordered structures generated and shown in Fig.7 \(I each closed itemset is accompanied with its associated list of minimal generators. Indeed, approximate rules represent intervehicles relationship deductions, assorted with statistical information, i.e., the confidence, starting from a given vehicle in an ordered structure from a sub-closed-itemset to a superclosed-itemset. Inversely, exact rules are intra-vehicle implications extracted from each vehicle data in the ordered structure. If we apply those definitions, we can extract the following the rules shown in Table IV, computed from the ordered structures generated in Fig. 7 \(I G  Post Processing of the Results \(Association Rules The visualization and post processing of the association rules is the main part of our appr oach. In this phase the relevant itemsets should be located in a large collection of potentially interesting itemsets. Consequently analyzing the results at this stage is essential. Therefore, pertinent decisions may be taken after the extraction of the association rules to re-establish the right relationships T ABLE IV  L OCAL T EMPORAL A SSOCIATION R ULES A SSOCIATED TO F IG   7  I Minimal exact association rules Minimal approximate association rules 1 5 4 3 1 m m m m     confidence  3 3 100 4 5 4 3 2 1 m m m m m     confidence  3 1 33.3 2 5 4 3 2 1 m m m m m     confidence  1 1 100 5 6 5 4 3 1 m m m m m     confidence  3 2 66.6 3 5 4 3 6 1 m m m m m     confidence  2 2 100   1  Interpretation and Utilization of the Results From our running example, we extracted exact and approximate association rules \(see Table IV a  Minimal Exact Rules From the exact association rule 5 4 3 1 m m m m  Table IV. \(1 we assume that if we receive an event from vehicle 1 m then there is 100 percent chance we will receive the same event from vehicles 5 4 3  m and m m within  units of time. If we do not receive the expected events from one of them, we conclude that the unresponsive vehicle is faulty. This kind of formulation captures the temporal relationships between the corresponding vehicles 5 4 3 1   m and m m m The analysis of the association rules allows VARM to identify correlated vehicles that can be used to estimate the values expected from another vehicle, forecast the future sources of events, and detect faulty vehicles b  Minimal Approximate Rules The approximate rules are useful to mine strong approximate dependencies. The idea is that it is interesting to measure not only exact dependencies but also approximate dependencies. In \(Table IV. \(5\, if an event occurs in 1 m within  unit of time, the expected sources of futures events are 6 5 4 3   m and m m m with 66.66% chance. If VARM detects the faulty vehicle correctly, it will react efficiently and rapidly by re-establishing the right relationships 832 


 H  Predesigned Protection 1: N In the technique 1: N relationships are reserved in advance When a failure arises, other relationships which are preprovisioned are used.  Therefore 1: N protection, which is similar to 1:1 except for that one relationship is used to protect N relationships. This reactive solution has the advantage to decrease resources demand but introduces a delay. When VARM detects a faulty vehicle, it will proceed to use backup relationships to avoid considering the faulty vehicle. We plan to study the generalization of 1: N to K: N where K protection relationships are used to protect N working relationships Moreover, we will investigate the possibility to use network coding as done in [1 V  P ERFORMANCE STUDY  In this section, we will evaluate the performance of the proposed mining association rules mechanism \(VARM\ We compare the Itemset_tree, FP_tree[4  a nd C a t s _ t r ee [5   structures in term of compactness when we use different types of datasets \(sparse or dense\. We chose to compare the last structures using sparse and dense benchmark transaction databases that can be found in  to sh o w the e f fic i e n c y o f  the  structure and the mining algorithm used to extract minimal association rules   Fig.8. Real Size of the Sparse \(a\ and Dense \(b\ Transaction Dataset Versus Itemset-Tree In Fig. 8-\(a\, we observed that sparse datasets in average are represented by itemset-tree at most with 24.4% of their original size. While in Fig. 8-\(b\, dense datasets, in average, are represented at most with 18.8% of their original size. This is very interesting for avoiding technical problems related to itemsets-storage In Fig. 9, we chose to evaluate the execution time of the database chess when varying the number of nodes because this database extends on depth and it needs more memory to compute association rules. It is worth noting that in VANETs the transactions database extracted for 27 vehicles or 40 vehicles is similar to sparse datasets. However, if we prove that the structure is also efficient for dense datasets, it would be interesting as this case might be met with numbers such as  200 vehicles  Fig.9. Dense database \(chess\ / nodes number  Fig. 10. Size of the Itemset-Tree Versus Those of Cats-tree and FP-tree Fig. 10 shows the performance of the itemset-tree structure compared to the FP-tree and cats-tree in terms of compactness the original size versus the advanced structure size\ We remark that itemset-tree is by far more compact than the other structures proposed in literature  TABLE  V  F RACTION OF S IZE S PARSE D ENSE D ATASET AND I TEMSET T REE  Extract context Original base size in Ko Avg num.of transact Avg Num of items in transact ItemsetTree size in Ko  Approx T10I4D1K 38.0 10000 10 nodes 10.00 25 T25I10D10 947.7 9966 25 nodes 229,7 25 T10I4D100K 3993.6 10000 10 nodes 839.00 25 Retail 4198.4 10000 10 nodes 767.81 21 T40I10D100K 15257.6 100000 25 nodes 3806.10 26 C20 160 306 35-75 nodes 11,41 7 Chess 337.4 3196 35-75 nodes 44,83 13 Mushroom 565 1099 35-75 nodes 48 9 Connect 2700 17945 35-75 nodes 1180 43 C73 3174.4 6242 35-75 nodes 512,84 17 Pumsb 16384 21959 35-75 nodes 1900 24 Vehicles 27 1 11 2-25 nodes 0 100 Vehicles 40 1 11 2-37 nodes 0 100 833 


  In table V, we can see how the itemset-tree structure is compact. We observed that with 27 and 40 vehicles network the last two lines in the table V this structure is very efficient and suitable. Also, when we compute the exact and approximate association rules, the program is rapidly executed and provides interesting results and pertinent information which leads to identify events correlation and therefore detect faulty and/or malicious vehicles The following example presents approximate and exacts associations extracted in a network of 27 vehicles 1  3 15 16 17 24 25 26             0 1 2 3 4 8 11 12 16 17 20 21 24 25 26 3/4  2  3 15 16 17 24 25 26            0 1 2 3 4 5 7 8 11 12 16 17 20 21 24 25 26 1/4  3  3 15 16 17 24 25 26            0 1 2 3 4 6 8 9 10 11 12 13 14 16 17 18 19 20 21 22 23 24 25 26 2/4  4  3 15 16 17 24 25 26             0 2 3 4 8 11 12 16 17 20 21 24 25 26 [3/4 5  3 15 16 17 24 25 26             0 1 3 9 10 13 14 16 17 18 19 22 23 24 25 26 [3/4 6  3 15 16 17 24 25 26              2 3 4 8 11 12 16 17 20 21 24 25 26 [3/4 7  3 15 16 17 24 25 26                0 3 16 17 24 25 26 [4  The second approximate association rule is not interesting because it appears with confidence equal ¼, which is smaller than the minimum confidence fixed a priori to 50%. However the association rule number 7 is an exact association rule with confidence equals to 1. Therefore, there is 100 percent chance that these vehicles are correlated. Moreover, we expect that if events happen with vehicles on the left side of a rule, vehicles on the right of the same associatio n rule will be source of events in case of no failure. Otherwise if a vehicle does not generate the expected event, it is then considered either faulty or malicious. In order to distinguish between both cases, we introduce other association rules for this vehicle in order to decide if the vehicle provides false information or is faulty VI  C ONCLUSION  In this paper, we proposed a rule-based data mining fault detection technique to detect faulty/malicious vehicles in VANETs based on exchanged routine messages. A side advantage of VARM scheme is that correlated information displayed via association rules, are easy to understand and subsequently easy to log by humans. In future work, we plan to verify the accuracy of events correlation extraction by a learning technique to lear n the historical period    R EFERENCES  1 S B e n Y a h i a  Y Sli m an i  a n d  J   R ezgu i  A Di vi d e  a nd C onqu er approach for deriving partially ordered sub-structures", in Proc. of PAKDD'2005, Hanoi, Vietnam, The Ninth Pacific-Asia, 2005 2  J  Re z g ui  C o n t r i bu tio n f o r de r i v i ng  g e ne r i c bas e s o f as s o cia tio n r u l e s    Master, University of Science in Tunis, Tunisia, Novembre 2004 3  N  P a s q uie r  Y  B a s t ide   R T a o u il   L   L a khal   E f f i c i e n t Mi ni ng o f  Association Rules Using Closed Itemset Lattices", Information Systems Journal 24, pp. 2546, 1999 4  J  H a n  J  P e i Y  Y i n   M ini n g f r eq u e n t pa tt er n s w i th ou t ca nd ida t e generation", in Proc. of the ACM-SIGMOD Intl. Conference on Management of Data, Dallas, Texas, pp.112, 2000 5  W  Che u ng  O  Z a ia ne   I ncr e m e ntal  m i n i ng o f f r e que n t  pa tte r n s w itho u t  candidate generation or support constraint", in Proc. of the Seventh International Database Engineering and Applications Symposium IDEAS\g Kong, China, 2003 6  G   G r ahne  J  Z h u  E f f i c i e n tl y us i n g pr e f ix t r e e s in m i ni ng f r e que nt  itemsets", in Proc. of the Workshop on Frequent Itemset Mining Implementations \(FIMI\, Florida, USA, 2003 7  K  K   L o o   I   T o ng  B K a o  and D  Che n ung   O nl ine A l go r ithm s f o r  Mining Inter-Stream Associations from Large Sensor Networks", in Proc. of  PAKDD'2005, Hanoi, Vietnam, The Ninth Pacific-Asia, 2005 8  A  Bo uc ke r c he  an d S  S a m a r a h  A no v e l al g o r ithm f o r m i n i ng  Associations rules in Wireless Ad Hoc Sensor Networks", Parallel and Distributed Systems, IEEE Transactions on, july 2008 9  S  H a kam i e t al   D e t e c tio n a n d I d e n tif i c a tio n o f A n o m al ie s in W i r e l e s s  Mesh Networks Using Principal Component Analysis \(PCA\ ", in Proc of Parallel Architectures, Algorithms, and Networks, pp. 266-271, 2008 10  A l K of ahi O  M  a nd A  E  K a m a l   N e t w o r k Co di ng B as e d P r o t e c tio n o f  Many-to-One Flow Networks", in Proc. of IEEE Mobile Adhoc and Sensor Systems \(MASS\, pp. 1-10, 2007 11  R L i n E  K h al as tc hi an d G  A  K a m i nk a  D e t e c ti ng a n o m al ie s i n  unmanned vehicles using the Mahalanobis distance", in Proc. of ICRA pp. 3038-3044, 2010   J  R ezgu i S  Ch er k a o u i  and O  Cha k r oun  D et er m i n i s t ic A c c e s s f o r  DSRC/80211.p Vehicular Safety Communication", in Proc. of  The 7th International Wireless Communications and Mobile Computing Conference \(IWCMC 2011\ 2011  D J i an g et a l   Des i gn of 5  9 gh z d s rc b a s ed veh i c u la r s a fet y  communication", Wireless Communications, IEEE, Vol. 13, pp. 36-43 2006 14  H  C h ing L i ng e t al   A dap tiv e  in te r v e h icl e co mmu ni ca tio n co ntr o l f o r  cooperative safety systems", Network, IEEE, Vol. 24, pp. 6-13, 2010  T  Z h ou  et  a l   Pri vac y Pr e s e r v i ng Det e c t i o n of Sy b i l A t t a c k s in  Vehicular Ad Hoc Networks", in Proc. of the Fourth Annual International Conference on Mobile and Ubiquitous Systems: Networking Services MobiQuitous\ pp.1-8, 2007   M   E  Za r k i  et a l    S ec u r it y i s s u es i n a f u tu r e veh i cu la r  n e t w or k   i n  Proc. of  EuroWireless, 2002 17  M  Ray a an d J  P  H u ba ux   T he s e cu r ity o f ve hicul a r  ad ho c ne tw o r k s    in Proc. of  SASN, 2005  K  Sa m p i g et ha y a  et a l   Ca r a v an Provi d i n g loc a t i o n  p r i v ac y for va n e t    in Proc. of  ESCARworkshop, 2005  J  Y Ch oi   M  J a k o b s s on  a nd S  W e t z e l  B a l a n c i n g  a u d i t a b i lit y a nd privacy in vehicular networks", in Proc. of  Q2SWinet, 2005 20  E Co r o na do S  C h e r kao u i A s e cur e s e r v ice ar ch ite c t ur e to s u p p o r t wireless vehicular networks", Special Issue on "Security, Trust, and Privacy in DTN and Vehicular Communications", International Journal of Autonomous and Adaptative Communications Systems \(IJAACS Inderscience, Vol3, No.2, pp 136-158, 2010 21  I EEE V e h i cu l a r T e ch n o l o g y S o cie t y  5  9 G H z D e d i cate d S h o r t Ra n g e  Communications \(DSRC\:. http://grouper.ieee.org.groups/scc32/dsrc 834 


owl:Class rdf:ID="H def-ar:Defeats  def-ar:support="5.100 def-ar:confidence="60.100 rdf:Description rdf:about="#H def-ar:subclassOf rdf:resource="#A rdf:Description def-ar:Defeats II. FORMAL FRAMEWORK We have explained in the introduction that our approach relies on inducing a theory in some logic of formulae with an interpretation on association rules. For a formal definition of the semantics of association rules, the reader is referred to [1 A family of non-monotonic logic formalisms for defeasible reasoning on incomplete knowledge with a well defined sceptical reasoning process has been defined [3]. A defeasible logic theory is a collection of rules, formed upon a set of atoms as a body and an atom as a head, that allows the reasoning on sets of given facts. In defeasible logic, the rules constituting a theory represent assertions whose truth is indisputable, and assertions whose truth is problematic. As a consequence, two sorts of conclusions are obtained from the reasoning process indisputable or defeasible More formally, a defeasible logic theory is composed of a set of strict rules \(rules that are indisputably true rules \(rules whose application is considered problematic defeaters \(counter-arguments to defeasible conclusions superiority relation among rules \(as a disambiguation mechanism It was shown that the problem of deciding if an atom is a member of the extension of a defeasible theory can be efficiently implemented since it demands linear time and space 22]. Besides, it has been shown that the absence of a superiority relation does not compromise the expressive power of defeasible logic [4]. Within our approach, thus, we are interested in defeasible rules and defeaters only, and, since our targets for reasoning are association rules, we incorporate a notion of threshold covering to the reasoning process; if an association rule is concluded with some threshold values for support and confidence, the same association is concluded for any smaller value down to 0, provided there is no defeater for the rule with a value in-between In the example above, the association rule 3 \(A ? I 


concluded upon the association rule 6 \(AC ? I confidence and ? 0.05 as support, according to the "defeasible rule" pattern encountered in the example. Thus, A ? I is also implicitly support. However, if a defeater for rule A ? I is simultaneously asserted with ? 0.04 the A ? I would not be concluded with ? 0.5 as confidence and ? 0.03 as support. This choice is important for a better understanding of the theories obtained. Within our approach, we consider defeasible rules that allow us to conclude that an association rule defeasibly holds, with independence of the conformance with given support and confidence thresholds, provided that other association rules also hold conforming the thresholds Defeaters are included here to prevent the erroneous conclusion of an association not conforming the given thresholds A. Logic for Associations We want to represent the set of all given association rules among itemsets through a defeasible theory. Thus, the domain on which formulae in our logic are built is founded structurally on the set of all itemsets formed upon the set of items involved with exception of the null itemset. This way, terms in our logic constants and variables number of items DEFINITION 1: \(Itemset Term term is a construct of any of the forms i1 in, a ground itemset term, where i1in is a nonempty list of items Vm,M, a variable itemset term, where Vm,M is an itemset variable, 0 ? m ? M. The pair m, M indicates the class of itemsets involved  with size between m and M .When the pair is absent, the pair \(0 t1 ?  ? tn, a itemset union term, where t1 ,, tm is a non-empty list of itemset terms, and ? is an itemset infix function name with set union as fixed interpretation. t1 ?  ? tn implies that all ti, i=1..n, are mutually disjoint DEFINITION 2: \(Association a is an atom of the form a: S where \( _ itemset terms \(that fill the _ positions Ant\(a a 


consequent of a Association predicates are parametric. The pair  parameters: ? the support threshold, and ? the confidence threshold. Both parameters must be rational numbers. This way, there would be as many association predicates \(countable infinite  logic. An association S the atom S ? T ? holds Finally, we call a schema an association with at least one itemset variable DEFINITION 3: \(Assumption the form B  B the body of assumption association schemas with no arithmetic operators used in thresholds H the head of the assumption association schema, such that every variable appearing in H also appears in B An assumption is head-relevant if each atom in the body shares at least one non-ground term with the head or has a ground itemset term with a non-empty intersection with a ground itemset term in the head EXAMPLE 5: The following assumption ?1 corresponds to the meta-rule induced in Example 2 1:  X1,1 ? Y1,1 ?\(0.05, 0.6 0.05, 0.6 where X1,1, Y1,1and Z1,1are itemset variables of item-size = 1 Assumption ?1 is head-relevant DEFINITION 4: \(Defeater form d:  X ?\(s, p where X ? \(s,p association X ?\(s, p context of a proof system, a defeater has priority over conclusions obtained from the application of assumptions EXAMPLE 6: The defeater d1: A ?\(0.05,0.6 first counter-argument introduced in relation with Example 2 B. The Reasoning Framework In order to reason appropriately with programs made of associations, assumptions and defeaters, a non-monotone inference mechanism is presented, and theories are defined on 


it. Programs in this framework are inspired from [3], and can be translated in linear-time on the number of their ground instances into definite programs of clausal logic [4], with a linear-time ground inference procedure [15] on the same basis DEFINITION 5: \(Compaction Program program ? is a 3ary-tuple \(AR, Das, Dft associations, Das is a set of assumptions, and Dft is a set of defeaters DEFINITION 6: \(Closure  AR, Das Dft associations ?, recursively satisfying the following           and there exists an index k ? 1, such that ? [k] = S closure Cl AR, Das, Dft set AR+, where AR+ is the set of all ground associations derivable from program III. INDUCTIVE DEFEASIBLE COMPACTION In this section we present the main result of our paper: we present the notion of inductive defeasible compaction of a set of association rules and an algorithm for finding such compaction of a given set of discovered associations. The input is assumed a complete set of associations, with maximum values for confidence and support thresholds; no holding association rule should miss to be interpreted by an association atom in the input set, and, for all association atom in the input set, no association rule holds with support and confidence greater that the thresholds given in the atom DEFINITION 7: \(Inductive Defeasible Compaction constant k > 0 and a set of ground associations AR, complete for a given database D, a pair parameters, an inductive defeasible compaction of the set AR is a program ?: \(ARmin, Das, Dftmin 


relevant assumptions, with no more than k atoms in the bodies that  satisfies that i. Cl ii. #ARmin + #Dftmin + #{atoms iii. there not exists a program ?: \(AR, Das, Dft that Cl 2 A. The Induction Algorithm A PTIME algorithm that computes a compaction of a complete set of ground associations by inducing a set Das, and producing appropriate sets ARmin and Dftmin for the induced set Das is presented in Fig. 1. We discuss here the underlying ideas, and details related with its correctness and time complexity The algorithm begins with a procedure, detailed in Fig. 2 that greedily tries to produce all ground head-relevant assumptions, increasing the possible body size, variable j in the algorithm, from 1 to k. Each association in AR is considered there the head of a potential ground assumption, and all groups with a body size that equals j are considered as potentially bodies, provided the union of the itemsets that appear in the antecedent and the consequent of all members of the group covers the union of the itemsets of the antecedent and the consequent of the selected head rule                   Figure 1.  Induction Algorithm 


 For all 0 ? i ? k - 1 if ? [i + 1] = X 1  and ? X ? \(s,p for any p, s | 1  s ? ?, 1  p ? ?;     or 2 H  for some and ? X ? \(s,p for any p, s | 1  s ? ?, 1  p and for each V  j, 1 ? j ? i, ? [j] = V for some ?? ?, ?? ?.            \(1 For 1 ? i ? k Derive forests from all head-relevant ground assumptions with body size not > k, forming a dependency graph from body rules into head rules of each assumption Find all clases of isomorphic forests generalising isomorphic forests into classes of candidate assumptions Das, generating a fresh variable per leaf in each forest class and a substitution per leaf in each instance of the forest class Loop Search for a set Dftmin of defeaters for assumptions in Das attaching all substitutions and candidate  conflict-ting assumptions used for inferring each defeater Loop adjusting the classes by variable sizes and confidence and support, reducing the number of defeaters in Dftmin Choose a maximal elimination order for the rule depen-dency graph Prune rules in the order produced If the compaction criterion is fulfilled exit the algorithm returning Das, ARmin and Dftmin If there is no conflicting assumptions exit the algorithm returning failure Choose a conflicting assumption to prune from and delete it from      


              Figure 2.  Forests Derivation Next, the procedure proceeds to build, for each ground assumption, a set of forests of trees of itemset terms, with 1 one forest for the head, with one tree for the antecedent and one tree for the consequent; and 2 body, with a tree for the antecedent and consequent of each atom in the body. The leaves of the trees in the forests contain the subsets that are produced from the complete intersection of the prospective head of the assumption and the prospective bodies, considering the antecedent and the consequent of each rule separately Then, fresh variables are assigned to leaves; the forest becoming a structural representation of an assumption candidate for the set Das It is simple to see that the time complexity of the procedure detailed in Fig. 2 is O\(n k  The next step consists in finding isomorphisms among the forests, with the linear time algorithm of [2], leaving one assumption per isomorphic class in the set Das; the step demanding O\(m 2  all ground instances of each class on a list attached to the class in a manner that the substitutions applied to each variable can be deduced from them easily The algorithm proceeds next to find defeaters, the set Dftmin 


from the set of assumptions  forest classes -, applying them greedily to the given associations, according to the condition established in equation \(1 an atom to be defeated are then attached to the defeater with the substitutions applied. The method employed works satisfying the property iii in equation \(2 a minimal set of defeaters can always be obtained using the assumptions and the complete given set AR; the defeaters inferred from Das is independent of the level of pruning applied to AR, provided no information loss occurs in that pruning. This step takes O\(n k  An optimisation is attempted for set Das, with the reduction of the number of defeaters in Dftmin as a goal. The algorithm loops, trying to find the better set of assumptions, by successive adjustments. The substitutions applied to form ground assumptions are contrasted with the substitutions applied to form defeaters. Adjustments in variables sizes hitherto unlimited  and in thresholds of the assumptions are operated, producing if possible: 1 variables that exclude the size of variables of defeaters; 2 maximum of confidence and support thresholds for bodies in the assumptions that prevent the formation of one or more defeaters. It is easy to see that the step is polynomial in the size of set AR The pruning of AR is then accomplished. A candidate for pruning results any association that appears as head of a ground instance of an assumption in Das \(recall they were attached to assumptions in step one have cycles, cycles are identified and broken by eliminating one node of each cycle. An elimination order is therefore produced, by a systematic remove of ears in the graph considering only nodes candidate for pruning. Associations are then pruned from AR in the elimination order, forming the set ARmin. Note that this technique ensures properties i and iii to hold for set ARmin. Finding cycles in a graph, the hard part of this step is known to have a polynomial time complexity in the number of nodes, so it is this step in the number of given associations, since the nodes in the graph are the associations themselves Finally, the test: #ARmin + #Dftmin + #{atoms 


AR is made. If the answer is positive the algorithm ends successfully  the program returned satisfying property ii \(in addition to i and iii among those contributing in producing a defeater is chosen for elimination \(the most employed when producing defeaters is chosen first new set Das. If there are no assumptions to prune, the algorithm ends with failure. This step has constant time provided the sizes has been stored, and the number of loops, if they resulted necessary, cannot exceed O\(n k  IV. EXPERIMENTAL RESULTS Our approach has been experimented on three different highly correlated transaction database cases: case 1: \(PtC 2: \(DSP Arry commerce companies respectively, with a total of 2.9, 3.2 and 0.22 millions of records each, a number of 10502, 4135, and 1550 items. The experiments were developed running the algorithm A-Priori on each of the sets, varying the support down from 0.25 to 0.1, and confidence down from 0.7 to 0.99 Form a graph G with one vertex for each rule a in AR and an edge \(a, b itemsets\(a b Form an ordered list L of all items in vertices of G For each vertex a of G Create a pair of indices pointing to the first and the last items of vertex a in list L For j=1..k For each vertex a of G For each group g of j vertices of G adjacent to a s.t. there exist a sequence of vertices b1,,bj s.t. last\(bi, L bi+1, L first\(b1, L a, L last\(a, L bj, L Form a disjoint partition P\(a, g, j itemsets in a and all itemsets in each rule b in g Form a forest head\(a, g, j headAnt\(a, g, j a, g, j with itemsets Ant\(a a and each subset of itemsets Ant\(a a in P\(a, g, j 


For each vertex b in g form j forests body\(a, g, i s.t. bodyAnt\(a, g, i a, g, i with itemsets Ant\(b b and each subset of itemsets Ant\(b b in P\(a, g, j Assign to each leaf l of trees bodyAnt\(a, g, i bodyCons\(a, g, i a fresh variable Vm,M, m, M = size\(itemset\(l Assign to each leaf l of tree headAnt\(a, g, j the variable assigned to itemset l in some leaf of some tree bodyCons\(a, g, i TABLE II.  EXPERIMENTAL DATA Conf. #rules #pruned #dftrs PtC 0.5 6604 2985 1114 0.6 2697 2081 25 0.75 1867 1606 10 0.8 1266 1176 0 0.95 892 866 1 0.98 705 699 1 DSP 0.5 2473 1168 268 0.6 1696 869 64 0.75 1509 844 89 0.8 1290 1030 29 0.95 1032 889 15 0.98 759 723 1 Arry 0.5 770 492 82 0.6 520 353 60 0.75 472 327 39 0.8 408 287 22 0.95 361 255 25 0.98 314 243 30  Our induction algorithm has been launched for each combination of thresholds. Our scheme eliminates all redundant rules in the sense of [25, 31], i.e. those association rules that are not in the covers. All the meta-rule deductive schemes implicitly included in [25] and [31] are induced by our method. The percentage of pruning, thus, outperforms [25 


The results produced for k=3, support 0.25 and confidences between 0.7 and 0.99 are shown in Fig. 3, in terms of pruning percentage \(vertical axis when applied to low confidences \(from 0.7 to 0.9 The percentage of pruning achieved diminishes as the confidence is superior to 0.9. Nevertheless, the pruning is effective with confidence of 0.99 in the majority of cases Pruning at Support = 0.25 0,00 5,00 10,00 15,00 20,00 25,00 30,00 35,00 40,00 45,00 50,00 0,7 0,8 0,9 0,95 0,99 Confidence P ru n in g L e v e l Case 1 Case 2 Case 3  Figure 3.  Pruning experiences at support 0.25  V. DISCUSSION AND CHALLENGES It is important to discuss the technique presented here with focus on the purpose the technique pursues:  to produce semantic recommendation The reader should have noticed that the algorithm presented 


relies strongly on "choice". For instance, the algorithm chooses ears in the graph to form an order for elimination, and the choice is arbitrary. This strategy is essential to maintain low complexity \(polynomial practical. Nevertheless, a warned reader may conclude that this arbitrary choice implies that there are many compactions to produce and therefore the approach as a whole does not show to produce an optimal solution. And the reader is right in this conclusion. Since the goal is compaction, the search for an optimal solution can be bypassed provided a substantial level of pruning is achieved To complete the whole view, we describe how web service descriptions are complemented with the association rules as recommendations. In effect, under our scheme, the document describing the web service is augmented with a set of OWL/RDF/S triples that only incorporate the non-pruned rules with the format of Example 1, that is, the set ARmin of the compaction program obtained by our algorithm, together with the thresholds applied to the mining process and a registered URI of a registered description service. The assumptions and defeaters are not added to the web service description. If the associations encoded in the triples are not sufficient for the client \(a search engine, for instance widening of the response to the description service identified by the given URI, and then the assumptions and defeaters are produced. The reasoning task required for deriving all the implicitly published rules is client responsibility Notice that, under this scheme, the actual rules that appear as members of the set initial ARmin set are irrelevant; the only important issue is the size of the set The developed scheme also supports an extension of the algorithm that admits the assignment of priorities to rules and to itemsets, in order to allow the user to produce a more controlled program as output. Nonetheless, the importance of the extension has not been already tested, and therefore it is beyond the subject of the present paper It would be also interesting to design a scheme that supports queries where the client provides an itemset class and values for support and confidence and the engine produces a maximal class of inferred associated itemsets as a response. This scheme is also under development, so we have not discussed this aspect here 


VI. CONCLUSION In this paper, we have presented a defeasible logic framework for managing associations that helps in reducing the number of rules found in a set of discovered associations. We have presented an induction algorithm for inducing programs in our logic, made of assumption schemas, a reduced set of association rules and a set of counter-arguments to conclusions called defeaters, guaranteeing that every pruned rule can be effectively inferred from the output. Our approach outperform those of [17], because all reduction compactions presented there can be expressed and induced in our framework, and several other patterns, particular to the given datasets, can also be found. In addition, since a set of definite clauses can be obtained from the induced programs, the knowledge obtained can be modularly inserted in a richer inference engine Abduction can be also attempted, asking for justifications that explain the presence of certain association in the dataset The framework presented can be extended in several ways Admitting defeaters to appear in the head of assumption, to define user interest Admitting arithmetic expressions within assumptions for adjustment in pruning Admitting set formation patterns as itemset constants Extending the scope, to cover temporal association rules REFERENCES 1]  R. Agrawal, and R. Srikant: Fast algorithms for mining association rules In Proc. Intl Conf. Very Large Databases. \(1994 2]  A. V. Aho, J. E. Hopcroft, J. Ullman. The design and analysis of computer algorithms, Addison-Wesley, 1974 3]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher, A. Rock: A Family of Defeasible Reasoning Logics and its Implementation. ECAI 2000: 459-463 4]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher: Representation results for defeasible logic. ACM Trans. Comput. Log. 2\(2 2001 5]  A. Basel, A. Mahafzah, M. Al-Badarneh: A new sampling technique for association rule mining, Journal of Information Science, Vol. 35, No. 3 358-376 \(2009 6]  R. Bayardo and R. Agrawal: Mining the Most Interesting Rules. In Proc of the Fifth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 145-154, \(1999 


7]  R. Bayardo, R. Agrawal, and D. Gunopulos: Constraint-based Rule Mining in Large, Dense Databases. Data Mining and Knowledge Discovery Journal, Vol. 4, Num-bers 2/3, 217-240. \(2000 8]  A. Berrado, G. Runger: Using metarules to organize and group discovered association rules. Data Mining and Knowledge Discovery Vol 14, Issue 3. \(2007 9]  S. Brin, R. Motwani, J. Ullman, and S. Tsur: Dynamic itemset counting and implication rules for market basket analysis. In Proc. ACMSIGMOD Intl Conf. Management of Data. \(1997 10] L. Cristofor and D.Simovici: Generating an nformative Cover for Association Rules. In ICDM 2002, Maebashi City, Japan. \(2002 11] Y. Fu and J. Han: Meta-rule Guided Mining of association rules in relational databases. In Proc. Intl Workshop on Knowledge Discovery and Deductive and Object-Oriented Databases. \(1995 12] B. Goethals, E. Hoekx, J. Van den Bussche: Mining tree queries in a graph. KDD: 61-69. \(2005 13] G. Governatori, D. H. Pham, S. Raboczi, A. Newman and S. Takur: On Extending RuleML for Modal Defeasible Logic. RuleML, LNCS 5321 89-103. \(2008  14] G. Governatori and A. Stranieri. Towards the application of association rules for defeasible rules discovery In Legal Knowledge and Information Systems, JURIX, IOS Press, 63-75. \(2001 15] J. Han, J. Pei and Y. Yin: Mining frequent patterns without candidate generation. In Proc. ACM-SIGMOD Intl Conf. Management of Data 2000 16] C. Hbert, B. Crmilleux: Optimized Rule Mining Through a Unified Framework for Interestingness Measures. DaWaK: LNCS 4081, 238247. \(2006 17] E. Hoekx, J. Van den Bussche: Mining for Tree-Query Associations in a Graph. ICDM 2006: 254-264 18] R. Huebner: Diversity-Based Interestingness Measures For Association Rule Mining. Proceedings of ASBBS Volume 16 Number 1, \(2009 19] B. Johnston, Guido Governatori: An algorithm for the induction of defeasible logic theories from databases. Proceedings of the 14th Australasian Database Conference, 75-83. \(2003 20] P. Kazienko: Mining Indirect Association Rules For Web Recommendation. Int. J. Appl. Math. Comput. Sci., Vol. 19, No. 1, 165 186. \(2009 21] M. Klemettinen, H. Mannila, P. Ronkainen, H. Toivonen, and A Verkamo: Finding interesting rules from large sets of discovered association rules. In Proc. 3rd Intl Conf. on Information and Knowledge 


Management. \(1994 22] M. J. Maher, A. Rock, G. Antoniou, D. Billington, T. Miller: Efficient Defeasible Reasoning Systems. International Journal on Artificial Intelligence Tools 10\(4 2001 23] C. Marinica, F. Guillet, and H. Briand: Post-Processing of Discovered Association Rules Using Ontologies. The Second International Workshop on Domain Driven Data Mining, Pisa, Italy \(2008 24] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal: Closed sets based discovery of small covers for association rules. In Proc. BDA'99 Conference, 361-381 \(1999 25] N. Pasquier, R. Taouil, I. Bastide, G. Stume, and  L. Lakhal: Generating a Condensed Representation for Association Rules. In Journal of Intelligent Information Systems, 24:1, 29-60 \(2005 26] P. Pothipruk, G. Governatori: ALE Defeasible Description Logic Australian Conference on Artificial Intelligence.  110-119 \(2006 27] J. Sandvig, B. Mobasher Robustness of collaborative recommendation based on association rule mining, Proceedings of the ACM Conference on Recommender Systems \(2007 28] W. Shen, K. Ong, B. Mitbander, and C. Zaniolo: Metaqueries for data mining. In Fayaad, U. et al. Eds. Advances in Knowledge Discovery and Data Mining. \(1996 29] I. Song, G. Governatori: Nested Rules in Defeasible Logic. RuleML LNCS 3791, 204-208 \(2005 30] H. Toivonen, M. Klemettinen, P. Ronkainer, K. Hatonen, and H Mannila: Pruning and grouping discovered association rules. In ECML Workshop on Statistics, Machine Learning and KDD. \(1995 31] M. Zaki: Generating Non-Redundant Association Rules. In Proc. of the Sixth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 34-43, \(2000 32] w3c. OWL Ontology Web Language Reference. In http://www.w3.org/TR/2004/REC-owl-ref-20040210 33] w3c. RDF/XML Syntax Specification. In: http://www.w3.org/TR/rdfsyntax-grammar 34] w3c. RDF Schema. In: http://www.w3.org/TR/rdf-schema      


 8   2  3\f            8  D    F  \b 1 8 & #J      b 1  1  4    2  


4 1    9  E 1  2 4 1    9 1   4      8 2  8 1  D 1        1 1  b 


     b b b b b  K            8          2 D 9   F  \b 1 8 ,+J  9 


     b 1     1 2  9 1  12 L 1   9  8       1  2      2   


     b b b b b  K            2  0 \b f  b\f      9       


  8 2   E 1   1     M13 31L 1    b  8E 1   1 #3\b?### 1  1     E 1   1 \b?###3        


1   1   b 1  2 2 18 2     8              1    2 \b 1    2  


    2          2   1 L 2 1   1   L 2 2    2 1  2        


    8  2H D \b A             2  2H D \b A 2 \f 3%\f  f   4%\f f !  , \f\b  C    2    2 


 6    3 1      253 6   1 L 2    6   1         f\b3\f       


               1     1     8 2    E       2  1   


     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



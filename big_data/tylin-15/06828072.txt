Organizations are paying huge amount only for the sake of securing their confidential data from attackers or intruders. But the hackers are Big Bosses and are very sharp enough to crack the security of the organization. Therefore before they made security breach, let us hunt down them and make the alert for organization, so that they can save their confidential data. For the above mentioned purpose, Intrusion 
One-Stop:  A Novel Hybrid Model for Intrusion Detection System Bilal Maqbool Beigh Department of Computer Science University of Kashmir Srinagar, India bilal.beigh@gmail.com   
Abstract  
 Keywords  
detection system came into existence. But the current systems are not capable enough to detect all the attacks coming towards them. In order to fix the problem of detecting novel attacks and reducing number of false alarm, here in this paper, we have proposed a hybrid model for intrusion detection system, which have enhanced quality of detecting the unknown attack via anomaly based detection and also have module which will try to reduce the number of false alarm generated by the system Intrusion, detection, integrity, confidentiality 
availability, information, attack, mitigate 
I 
  
 I NTRODUCTION  As we know that the current world\220s maximum transactions are done in digital format thus increases the digital data after every nano second. Thus make an opportunity for attacker to attack more and more on that data. According to a well removed agency of security namely CERT, the number of attacks that happens on the digital data triples in number every year thus makes it very difficult of any organization or individual to detect all these attacks [1  2    In v i ew of th e  above reason, it now became a prime job for researchers to maintain the data\220s confidentially, integrity and availability in 
 
  
every aspect whether the information/ data is critical to an organization or not. Every organization has critical data eg Policies, new upcoming schemes, record of ammunition military data, national security etc and having enemy at the gates which wants their data. Thus needs a mechanism to protect the confidentiality, integrity and availability of valuable data. The mechanism which provides these characteristics is known as intrusion Detection system. Up   to this stage of research, intrusion detection system can be classified mainly in two categories as: [3  1 Mis-Use Based Intrusion Detection 
Anomaly Based Intrusion Detection 2 
The attack mechanisms defined above  if run independently will detect only certain types of attacks i.e rule based will only detect known attacks while as anomaly will check  from behaviour weather attack exists or not.  Thus are not fully efficient to detect all kind of attacks. Also these systems will make false alarm [23  In o r d er t o m itig ate th e a b ov e  mentioned problems, we have proposed a hybrid model which combines the implementation of both the techniques plus some additional features which will boost the detection \(positive true\ of the attacks made to a system / Network. We have given the name of call this system as One-stop i.e. which detects all the attacks under single roof. Therefore involves hybrid 
approach to filter the streams for intrusion detection. This paper consists of five sections. Section I is the introduction to the current topic as well as problems, section II will elaborate the architecture of both the techniques i.e anomaly and rule based intrusion detection system. Section III will discuss the proposed hybrid architecture in detail with working of each part and Section IV  will provides some merits of One-Stop and finally last section will enlighten the core theme of OneStop and its future insight  II 
 
A NOMALY BASED INTRUSION D ETECTION T ECHNIQUE  Attackers are very smart, genius people. They often program 
such kind of vulnerabilities whose signature will not be available easily. They know how to beat the IDS by crafting new exploits, thus it became very much important to block or detect these attacks. [3 1  T h e m ech an is m k n o w n as A n o m aly  detection can be used for this purpose. Anomaly based detection technique uses profile matching mechanism i.e normal behaviour and abnormal behaviour. Anything that is deviated from baseline of \215NORMAL\216 will be treated as anomaly. Normal behaviour can be feeded into the system based on offline learning and research and the online learning while processing the network traffic. This technique consists of two phases Training phase and testing phase. In training phase 
Pre-processing 2 
Profiling 3 
Detection 
002 
 The architecture of anomaly based detection is based on three important steps 1 
 
Architecture of Anomaly Bas ed Intrusion Detection System 
   
A 
798 978-93-80544-12-0/14/$31.00 c 
the normal traffic profile are defined while as in testing phase the learned profiles are applied to new data  2014 IEEE 


Read Data and Preprocess Detection Engine After converting the input raw data into some format, the next phase is to organize the data achieved from decoding phase into some structured format or pattern. Once the data is formatted in strict structure defined, it may be further broken down into classification which will totally depend up one schema used. Also in this phase, the data is concatenated and assembled in a pre-defined detection template [8 9    S IGNITURE BASED INTRUSION D ETECTION T ECHNIQUE   This technique is based on pre-defined set of rules. These rules are made by looking on some specific patterns which they got from incoming packets or command sequences. The attacks which are known and whose signatures are in the database can only detect the attacks coming towards the network or system Thus there is no such mechanism available which can detect the novel attacks coming towards the network or system  It read the raw data/ packets coming towards the network or from TCP dump provided by DARPA \(1998 or 1999\. The main aim of this module is to capture the raw data in some pattern which will be uniform. I.e the string should start with tcp/ip or udp etc  The aim of this block is to decode the incoming packet or data into the standard format on which detection can be made possible. The decoding is very important, because if a normal is decoded wrongly, it may lead to generate a false alarm. Thus it became very much important for developer to take care of decoding module while programming the same.[5  6    Up to this level, all is set to detect the anomaly. Here in this phase, the string or structure that we achieved from previous phase will be matched with the pre-defined profile using some matching algorithm. If the string deviates from the base-line drawn for normal behaviour stored in the trained profile database, then string is said to anomaly or if it doesn\220t deviate the traffic may be treated as normal  In the architecture depicted above, there are certain blocks which consist of many sub-blocks inside. We will discuss the functionality of each block in detail present in general architecture of the Anomaly based detection techniques. The functionality of blocks is as    Profile Database Detection Engine B A  Pre-Processing Read Data Alert Drawbacks of Using Anomal y-Based Detection Alone Architecture of Signiture Based Intrusion Detection system Among the important steps if 1 and 2 have some done something wrong it will affect detection process. Example, if the data is pre-processed wrongly, accordingly its profiling will get affected. so need to be very careful while transformation  The General architecture of Anomaly based intrusion detection system is give as below    Fig. 1:  Architecture of Anomaly based intrusion detection Decoding and Preprocessing If matched 2014 International Conference on Computing for Sustainable Global Development INDIACom Read data Signature Database If found   Decode 799  Since every anomaly may not be intrusion, for the same reasons, the security professionals need some additional resources to crosscheck the attack/ intrusion is genuine or not The main issues while using anomaly based intrusion detection system are as [24    200 As we know that Anomaly-based IDS are generating large number of false alarms   200 Due to abstraction used in profiling the intrusion generated may not contain enough information for developers or security professionals to develop the counter measures for the same in well-defined time [25    200 It takes longer time to analyze the normal behaviors of an activity than rule based detection system [2   III  The general architecture of Signature based intrusion detection system is as under                   Fig. 2:  Signature Based Intrusion Detection System Read Data Alarm Detection Engine 


This is very important module of our proposed model because it helps us in reducing false alarm. The working of this module is as : if the anomaly based detection technique detects the data as anomaly and signature based does not  detect it as intrusion  also if anomaly is not present in the known anomaly database then said anomaly string is fragmented in a format after that arranged and concatenated in a pre-defined format for rules and do transformation if needed. Finally stored the new rules  in the rule database of the signature based detection technique, so that next time when such anomaly occurs, it will be detected at very first step TABLE II: RULE GENERATION FORMAT  IP Source IP Dest Protocol Msg content port Rule ID Anomaly Based Detection System ii Anomaly Based Detection System ii 800 Elseif \(Anomaly AND Not Intrusion\ then If \(Anomaly in Anomaly Known Database\ then  215Normal Traffic\216 Else  Make entry in the table for new signature  Generation   215Generate Alarm\216 END IF END IF ELSE   215Normal Traffic\216 END IF             Rule Generation Module   I MPLEMENTATION OF O NE S TOP  The hybrid model One-stop has been developed keeping in view the number of false alarm. The model is fully implemented in java. The data preprocessing is done by JCap A Step 1:  Input Raw Data for i Known Anomaly Database P ROPOSED H YBRID M ODEL  As we discussed in our last section that there are certain drawbacks in both the detection techniques, i.e huge number of false alarms, detection of only known attacks etc. In order to deal/ mitigate/solve the above mentioned problems, we have proposed a hybrid model called One-Stop, which combines the properties of both anomaly detection techniques and signature based plus have been added with some more blocks which will result in reduction of false alarm generated by anomaly detection methods and add new rules to the signature detection method. The Architecture of proposed model is show in figure III.  The proposed model consists of many modules and we have elaborated all the modules except Known anomaly database and Rule Generation module. Here in this section, we will elaborate only the new sections attached to the model Signature Based Detection System Step 2: Decode and Pre-processing for i Signature Based Detection System Step 3: Detection in Both Phases i If\( Anomaly AND Intrusion\ Then 215Generate Alarm\216 ii 2014 International Conference on Computing for Sustainable Global Development INDIACom    This is a simple database table having all the parameters as columns which are used for profile matching, here whenever we know the incoming string data is not an anomaly, but the system returns it as an anomaly, we will have to manually insert the detected string in current database in pre-defined format  TABLE I:  FORMAT FOR KNOWN ANOMALY DATABASE  IP Source IP Dest Protocol Msg content port Anomaly type   A LGORITHM  ONE S TOP I NTRUSION D ETECTION  Working One-Stop is a novel hybrid model which not only detects the novel attacks but keep on updating the rules of the for signature based technique. The working algorithm of OneStop hybrid model is as under The Architecture depicted in figure II has same processing up to detection phase, but in detection instead of using detecting anomaly, we use the pattern matching mechanism. If the pattern matches in the signature data base, then it is an intrusion if not matched, then it is not intrusion.[11 2   IV The necessary working of the model goes like the algorithm mentioned above. Let us discuss it fully. First both the techniques i.e anomaly and signature based will decode and pre-processor the raw data packet, then the formatted data will be given to detection engine which will use databases for the purpose of detecting intrusion or anomaly. IF both techniques triggered alarm for intrusion, then general alarm will be activated. IF anomaly based Detection alerts anomaly and signature based detection method does not detect the intrusion we will go for the another checking before declaring it as an anomaly and alert alarm. We will check whether the current Anomaly matches with some known Anomaly saved in our Known Anomaly Database \(i.e false alarm \215the data which has been detected as anomaly but are not intrusion\216\f found then it is not an anomaly but if not found in database, then the current string is passed to rule generation module which generates new rules for the current anomaly for signature based intrusion detection system. Also an Alert Alarm will get generated. This step will help us to solve the problem of false alarm and also novel intrusion will be detected. Also if both the both the detection mechanisms do not detect the anomaly or intrusion, then No alert will be generated i.e \215Normal Traffic\216 V 


Detection Engine Fig 3: An Architecture of One-stop Hybrid Model Anomaly Based  Anomaly Database unit which pre-process the data and format the incoming stream or the dump into the format, by which the other modules will understand it easily. This step is important because if the pre-processing of data is done wrongly, we will not get the desired format which will be later used for the comparison purpose The function used for detecting the anomaly is named as anomaly detection. The glimpses of the functions are as under  Add rules to Database If Found in anomaly DB  Input Stream Not Detected Not Detected A Alarm public class anomaly  public static final String HOST = "127.0.0.1 public static final int PORT = 9199                                             public static final String NAME = "anom_kddcup public void execute\(\ throws Exception   Connect to Server Known Anomaly Not Detected Detected Detected Detected System / Network Decoding & pre-processing If Not found in Anomaly DB Check for Known Anomaly Normal Decoding & pre-processing Signature Based 801 2014 International Conference on Computing for Sustainable Global Development INDIACom Signature Database Alarm Norma l Rule Generator Detection Engine nomalyClient client  new AnomalyClient\(HOST PORT, 5  Prepare learning data Datum datum = null TupleStringFloat result = null Try  BufferedReader br = new BufferedReader\(new FileReader\(FILE_PATH + TEXT_NAME                                             


802 is the type of attack in which the nonlegitimate user at the first time gains access to any normal users account by any common method like password sniffing etc. Then this un-legitimate user try to gain the access of the root director/ parent directory through known or unknown vulnerabilities 19   is the attack in which the attacker kept the memory very much busy. The main aim of keeping memory busy is to deny the authorized user to get access to machine. Different types of DOS attacks are used in the test beds [1 1 8     Denial of Services List  strL = new ArrayList List  doubleL = new ArrayList String myline read the data row by row until the last one while \(\(myline = br.readLine\(\ != null   strL.clear doubleL.clear split the data items in each row String strAry = lin e.sp lit      main method starts from here public static void main\(String  ar gs  thr ow s Exception  new anomaly.execute System.exit\(0  The functions of the signature based module are as under  Public class sigids  Boolean check_intrusion\( \ throws Exception  check for known intrusion using existing signatures   The new module which has been added in the system is ultimately responsible for the output i.e, wheather the data stream is an attack or not. Some functions of this module are as  Boolean check_for_intrusion\( Boolean anomaly , Boolean signature  If \( anomaly==1 && signature ==1 Alert  Else if \( anomaly ==1 && signature==0  open connection with known anomaly database if found then no alert will be generated Else if not found then generate alarm and also invoke the rule generation function   Remote to Local attack E VALUATION OF O NE S TOP  As lot of research has been done on intrusion detection, which takes different datasets into consideration i.e  1998, 1999, 2000 etc.  Thus most of the evaluation in intrusion detection systems is based on the data and results received after implementation The main problem behind releasing data stems is the very much sever concern i.e Privacy concern. In order to reduce the impact of this problem Lincoln Laboratory \(LL\, under sponsorship of DARPA, created the IDEVAL datasets that serves as an evaluation benchmark [1  T h e m ain m o tiv e behind introducing 1998 DARPA intrusion detection system was to develop and distribute a dataset for the purpose of evaluation of intrusion. The famous 1998 DARPA intrusion detection system data set was generated and recorded on a network which simulated an operational network connected to the Internet. Which uses automatically generated traffic generated by more than 22 or more networks and include the attackson these, like dns, finger, ftp, http, ident, ping, pop smtp, snmp, telnet, time [16    The section describes the experimental setup and data set used. In this paper, we use KDD 99 data set for experiment evaluation. The mentioned dataset is very large and consists of many components. The components are as un  KDD Cup 1999 KDDcup.data_10_percent KDD.newtestdata.unlabled_10_percent_unlabled and corrected  The structured views of component used from data set are as under TABLE III Structured Analysis Of Dataset   Among the above mentioned components, we have used KDD.data_10_percent component as training dataset and Corrected as testing dataset. The training data consists of 494020 records. Out of the 494020, 97280 records are labeled as normal records. In testing dataset, total numbers of records are 311029 among which 60593 are normal. Since there are four \(4\  categories of attacks records available in data set viz DOS, U2R, probes and R2L. The brief description of all the attack mentioned are as under: [12     User to Root Attack 2014 International Conference on Computing for Sustainable Global Development INDIACom Test data correcte d 60593 229850 228 4166 16192 311029 is the type of attack in which the attacker gain access over the packet over the network instead of machine and then configures the attack for the system. These Data Set Norma l DOS U2R Probe R2L Total KDD.dat a_10_pe rcent 97280 391460 60 4105 1126 494021 VI 


One-stop 96.4 One-stop 3.24 Type Detection Rate Type Detection Rate 95 95.5 96 96.5 97 97.5 98 98.5 99 Snort Onestop 98.45 98.5 98.55 98.6 98.65 Snort Onestop Iteration 1 Iteration 2 In iteration first which is the start of the experiment, we have default signatures in the database and also the known anomaly in known anomaly database are limited , thus our results are very low in detection and have higher rate of false alarm . We have compared our results with the SNORT results, because SNORT is very efficient open source tool for detecting intrusion detection. As per the results, in first go, SNORT outperformers our model in both the cases I.e detection rate and false alarm as shown in table and figures below  TABLE IV: DETECTION RATE is not actually considered as an attack. Instead it is a program which automatically scans the entire network and collects all the desire information about all the vulnerabilities in that particular network for which the program is scanning    VII SNORT 98.6 803 detection rat e   SNORT 1.33 onestop 2014 International Conference on Computing for Sustainable Global Development INDIACom In iteration second, there is drastic change in the results as we have inserted known anomalies in the database , also for anomalies signatures have been added in previous iteration which means that detection rate will increase marginally. As per the results acquired from the experiment done, we can see that there is increase in the detection rate of our model which is 98.5 approximately equal to the SNORT. The results for detection \( In percentage form\own in table below  FIGURE 5:   FALSE ALARM Probes    A 98.6 98.5 Fig. 4: Detection Rate As per the results, SNORT detects at the rate of 98.6 % while as our proposed model detects at the rate of 96.2.Also in generating false alarm rate SNORT shows better results than One-Stop TABLE V: FALSE ALARM Fig. 6: Detection Rate snort attacks are usually carried out on not well configures      \(Misconfigured\ systems. [20                  B                     SNORT  R ESULTS AND D ISCUSSION  The paper shows incremental approaches in accordance to the percentage of decrease false alarm and increase in detection rate. Here in this paper we have repeated our experiment five times but the results came similar after three iteration .Also we will observe the change in the results because as discussed in our proposed architecture, after every anomaly identified by the anomaly detection engine and not found in both databases i.e Known anomaly and Signiture database, then it will add a new rule to Signiture database and next time it will be directly detected as intrusion. We will show the enhancement as under TABLE VI: DETECTION RATE  iteration 2 One-stop Series1 Type Percentage of False Alarm 


2014 International Conference on Computing for Sustainable Global Development INDIACom Type Detection Rate As per the third iteration, the detection rate of the one-stop is much better than SNORT. The results of the third iteration are shown as under in table VIII  TABLE VIII: DETECTION RATE Iteration 3 Also as per the results, there is decrease in the rate of false alarm generation. The results of false alarm generation for second iteration are as shown in table below  TABLE VII: FALSE ALARM  C       SNORT SNORT SNORT 98.2 98.4 98.6 98.8 99 99.2 99.4 Snort Onestop Journal of Security Engineering\ 5, no. 4 \(2008\: 8 http://www.sersc.org/journals/JSE/vol5_no4_2008/3.p   Successful Real-Time Security Monitoring, Riptech  Inc. white paper September 2001 4 iteration 3  A CKNOWLEDGMENT  I would like to thanks Prof.S.M.K.Quadri for his valuable support R EFERENCES   1 Lazarevic, A., Ertoz, L., Kumar, V., Ozgur, A., & Srivastava, J. \(2003 May\. A comparative study of anomaly detection schemes in network intrusion detection. In Proceedings of the third SIAM international conference on data mining  \(Vol. 3,  pp. 25-36\. Society for Industrial Applied 3 onestop Fig. 8 Detection Rate  Also there is great decrease in the false alarm rate, which is important as far as intrusion detection systems are concerned The figures of false alarm generation at third iteration are as given in table below  TABLE IX: FALSE ALARM After third iteration the results came same for other iterations too. i.e detection rate = 99.2% and false alarm rate =0.99 VIII 1.33 1.22 98.6 99.2 1.33 0.99                                    Fig. 7:False Alarm detection rate snort snort 804 onestop Fig. 9:  False Alarm  2 SAKURAI, Kouichi, and Tai-hoon Kim. "A Trend in IDS researches  One-stop One-stop One-stop Anderson, James P. Computer security threat monitoring and surveillance. Vol. 17. Technical report, James P. Anderson Company Fort Washington, Pennsylvania, 1980 Type Percentage of False Alarm Type Percentage of False Alarm C ONCLUSION  The current research if focused on mitigating false alarm and design of a new hybrid model which will adopt both the techniques. In this paper, we have proposed a new hybrid model which combines both the modules i.e anomaly and signature based also we have added few more modules which will check for false alarm and will add new rules to the signature database automatically thus we can say, it is a model which will detects novel intrusion made on the system and is reducing the number of false alarm. In future, we will try to implement the model for intrusion preventions also. We will also try to build the model using machine learning also 


Zanero, Stefano. \215Analyzing TCP Traffic Patterns Using Self Organizing Maps\216. Image analysis and Processing-ICIAP 2005 Springer Berlin Heidelberg, 2005. 83-90  2014 International Conference on Computing for Sustainable Global Development INDIACom L. Kuang, "DNIDS: A Dependable Network Intrusion Detection System Using the CSI-KNN Algorithm", Master thesis, Queen\220s University Canada, September 2007   5 Haines JW, Lippman R, Fried DJ, Zissman MA, Tran E, Boswell SB 1999 DARPA intrusion detection evaluation: design and procedures MIT Lincoln Laboratory Technical Report, TR-1062, Massachusetts USA; 2001  Bloedorn, E., Christiansen, A. D., Hill, W., Skorupka, C., Talbot, L. M Tivel, J. \(2001\. Data mining for network intrusion detection: How to get started. MITRE Technical Report 7 Rakes, T. R., Deane, J. K., & Paul Rees, L. \(2012\. IT security planning under uncertainty for high-impact events. Omega, 40\(1\, 79-88 9 Tavallaee, Mahbod, et al. "A detailed analysis of the KDD CUP 99 data set." Proceedings of the Second IEEE Symposium on Computational Intelligence for Security and Defence Applications 2009. 2009  Gudadhe, M., Prasad, P., & Wankhade, K. \(2010, September\. A new data mining based network intrusion detection model. In Computer and Communication Technology \(ICCCT\, 2010 International Conference on \(pp. 731-735\. IEEE  Mahoney MV, Chan PK. An Analysis of the 1999 DARPA/Lincoln laboratory evaluation data for network anomaly detection. Recent advances in intrusion detection. In Sixth international symposium, Raid 2003, Pittsburgh, PA, USA; 8\20510 September 2003. p. 220\20539  Bilal Maqbool Beigh, Uzair Bashir and Manzoor Chahcoo. Article Intrusion Detection and Prevention System: Issues and Challenges International Journal of Computer Applications 76\(17\:26-30, August 2013. Published by Foundation of Computer Science, New York, USA  Roesch, M. \(1999, November\ Snort: Lightweight Intrusion Detection for Networks. In LISA \(Vol. 99, pp. 229-238 6 805 Carl, Glenn, et al. "Denial-of-service attack-detection techniques Internet Computing, IEEE 10.1 \(2006\2-89                       Chandola, V., Banerjee, A., & Kumar, V. \(2009\. Anomaly detection: A survey. ACM Computing Surveys \(CSUR\ 41\(3\ 15  O'Mahony, Michael P., Neil J. Hurley, and Gu\351nol\351 CM Silvestre Recommender systems: Attack types and strategies." AAAI. 2005  Wu, H., Schwab, S., & Peckham, R. L. \(2008\ U.S. Patent No 7,424,744. Washington, DC: U.S. Patent and Trademark Office 8 Ghorbani, Ali A., Wei Lu, and Mahbod Tavallaee. "Evaluation Criteria Network Intrusion Detection and Prevention. Springer US, 2010. 161183  Denning, D. E. \(1987\. An intrusion-detection model. Software Engineering, IEEE Transactions on, \(2\, 222-232  Beigh, B. M., & Peer, M. A. \(2011\. Intrusion Detection and Prevention System: Classification and Quick  Patcha, Animesh, and Jung-Min Park. "An overview of anomaly detection techniques: Existing solutions and latest technological trends Computer Networks 51.12 \(2007\: 3448-3470  Lippman R, Haines JW, Fried DJ, Korba J, Das K. Analysis and results of the 1999 DARPA off-line intrusion detection evaluation. In Proceedings of the third international workshop on recent advances in intrusion detection, Toulouse, France; 2\2054 October 2000. p. 162\20582  Kendall K. A database of computer attacks for the evaluation of intrusion detection systems. Master Thesis, Massachusetts Institute of Technology, Lexington, MA; 1999  Data set, DARPA intrusion detection evaluation data set;1999.<http://www.ll.mit.edu/IST/ideval/data/1999 1999_data_index.html  


1 2 3 3 3 3 1 3 1 1 1 1 1 1 2 1 1 1 1 1 2 G G G G G G G c g f k G G G h h G G i G G G G G G V V v u V v V v v G v v v G V v G u v u v V v v V V E E V V E V v V E v V u V u v V V u T T s V T s  T T V G G i E E E E u E i i i i i i i i i i i i i i i i i i i i i i i i i i i i i d d i d d i d i i i i i i i i i i i i 212 i i 212 i i f G   and and and and and and and can be handled similarly In such a way Type-2 nodes can be effectively reduced in is generated from two can be computed In c G c G c G in in in itself is an is still a vertex cover of in line 4 of Algorithm 3 by joining in into into in in the in the next iteration of  In the following we introduce techniques to re duce the nodes and edges when constructing G  Thus the key point to reduce the I/O cost of the  when adding nodes into from  before adding can be removed from is removed can be removed from and Get SCC and there is no need to add v G v G v G v G v G v G v G v G v G v G v G h G h G h G h G E in each graph in each graph Example 6.1  when generating can be removed because  we check whether Node Reduction has been covered by node b e l j VII I/O C OST M INIMIZATION In this section we show how to optimize our contractionexpansion based is a Type-1 node from constructed in the from which is computed using can only hold                                                                                                                                                                             Type-2 nodes are order sensitive i.e if node in line 8-9 of Algorithm 3 for each edge smallest nodes using operator line 2 of Algorithm 3 A sequential scan of Fig 5 shows the process of the graph expansion phase to expand the graphs in order of  when constructing  if there does not exit another node may not be a Type-2 node Note that our aim is to reduce nodes in To remove Type-1 node  we only keep the nodes with both using a dictionary  In addition it is straightforward that each edge denoted by light gray nodes and has already been computed using Algorithm 3 the following two types of nodes can be removed from are Type-2 nodes after scanned suppose G are the removed nodes when constructing denoted by dark gray nodes In with a single node Finally there are two in Algorithm 3 Such an operation does not generate any extra I/O cost in Algorithm 3 In order to reduce Type-2 nodes when scanning all edges in which many not reside entirely in the main memory Suppose algorithm on approach by further reducing the I/O cost The I/O cost can be reduced in two ways 1 to reduce the number of graphs constructed in the graph contraction phase and 2 to reduce the number of nodes and edges for each graph s in later iterations A Type-2 node th graph contraction phase without increasing the I/O complexity Although sSCC g g f i i c k b l k i j G c d e b a l g f h i k j m SCC f g e c f c e f g b i l j k d or 0 Any node with              6 4                       1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 212    Thus     in later iterations as  Since SCC SCC SCC SCC SCC SCC SCC nodes respectively has been added into  Such edges can be reduced in a lazy way when generating Type-1 For a node Type-2 For a node is a valid node set of with  Similarly the with with with will be removed in with G G needs to be added after line 2 of Algorithm 3 to eliminate parallel edges in  0 We develop two methods to reduce the edge size in order to reduce the intermediate results We will discuss the ef\336ciency in our performance studies Firstly for parallel edges with the same form out out out out out out out out 0 deg deg deg deg deg deg deg deg nbr nbr nbr nbr nbr nbr nbr nbr u G u v u v u v u v u w v>u in in in in in in in in in in in i i i i i i i i i i i i i  all nodes nodes in memory since a node with higher degree are less possible to be removed from 4 3 2 1  However such a solution needs to check whether Semi u>v generated in the graph contraction phase in Fig 4 The dashed circles in each graph algorithm is to reduce the number of nodes and number of edges cannot be combined with other nodes to form new  According to the node selection condition in Lemma 5.1 without generating any extra I/O cost in Algorithm 3 can be removed because when  Given graph such that Lemma 7.1 can reside entirely in the main memory By doing so we can reduce the number of Type-2 nodes in Edge Reduction can be removed from 0 SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC s are computed namely 002 212 002 002   024    002 002 002 004 004   002       wehave to make sure that th iteration According to the stop condition of graph contraction reducing the number of graphs is equivalent to reducing the number of nodes Omitted due to lack of space is an  and there is no need to include again The situation for to cover the edge Given  0  Fig 5 Graph Expansion Example computed according to Lemma 6.4 This can be done in line 8 of Algorithm 4 by checking whether 216 if  By applying the  for node s of node  for node  Thus node with a single node in without introducing new I/O cost thus we only reduce those Type-1 and Type-2 nodes that are easy to be identi\336ed The following lemma can be used to reduce Type-1 nodes or or  we only maintain the top  only one of them needs to be kept in 212 1 2  suppose  200  200   A Type-1 node  4 3 2 1 4 3 3 4 3 2 1 1 1 1 G E  G G V V V V E V V v V V v v V V   V V V  V E  E w            0  0     and nodes  If so edge  we introduce two ways to reduce the number of edges when generating  it is possible that G   017      Proof Sketch Ext Ext 002 002 002 002 g G G  


Size of Largeincrease The reasons are twofold Firstly when increases according to the node selection scheme to construct decrease There are two reasons Firstly when the memory size increases the stop condition for graph contraction is easier to be satis\336ed since more nodes can 336t in memory Secondly when the memory size increases the costs of the external sorts in both graph contraction and graph expansion phases decrease  Average Degree Number of Largeincreases the time and I/O consumptions for both increases the number of iterations in graph contraction increases This is because when number of edges increases the cost to sort and scan edges in each iteration increases thus more time and I/Os are consumed in each iteration                                     2 4 1 u E  V v E    u v  G  V E M V M V K G V V M KB Range 25M,50M,100M,150M,200M 2,3,4,5,6 200M,300M,400M,500M,600M 400K 8K 20,30,40,50,60 30,40,50,60,70 10K to in the operator in line 4 both in line 4 and augmented in all nodes in in line 5-7 VIII P ERFORMANCE S TUDIES In this section we conduct experimental studies by comparing four external algorithms for is the number of bytes to keep a node in memory We set the max time cost to be 24 hours If a test does not stop in the time limit we will denote it using until all nodes form an to Size of Small The results are shown in Fig 7\(a and Fig 7\(b for time and I/O costs respectively When the memory size increases the time and I/O costs for both 100M 400M 40 1 1 50 TABLE I R ANGE AND D EFAULT V ALUE FOR P ARAMETERS Parameter in all cases since more nodes/edges are removed in each iteration in Operator  operator speci\336es a unique total order among all nodes in the graph operator in line 9 when generating algorithm needs to hold and and and and and used in introduced in 26  w h i ch is cu r r e n tly th e m o s t I O ef 336cien t sem i e x t er n a l algorithm for and  Secondly when and out out out out out out out Fig.6\(a and Fig 6\(b show the time and I/O costs when varying the number of edges of WEBSPAM-UK2007 from 20 to 100 respectively v G v G v G v G v G v G v G v G v G v G v G v G v G v G 002 212 327 327  002 002 327 327 327 327 327       2 cannot stop in the time limit even if the graph contains only 20 of the edges When Size of 8 our e x t e rnal cont ract i on-e xpans i o n b as ed algorithm Algorithm 2 and our algorithm by applying the optimization techniques introduced in Section VII in new edges are added into In Algorithm 3 in order to make use of the new s The graphs contain nodes from 25M to 200M with average degree varying from 2 to 6 A synthetic graph is generated as follows We construct a graph computation namely the external contraction based 13 t he e x t e rnal DFS based by randomly selecting all nodes in SCC SCC SCC SCC SCC SCC  we apply the algorithm computation The  Finally additional random nodes and edges are added to the graph The parameters for synthetic datasets and their default values are shown in Table VIII outperforms 1PB 1PB since it cannot stop in all cases Memory Size need to be computed in Ext Ext Ext Ext EM Ext EM Ext Ext Ext Ext Ext Ext Ext Ext    3  002  For the semi-external algorithm  In our experiments we use a real large web graph and several synthetic datasets The real web graph is WEBSPAM-UK2007 4  which consists of 105,896,555 web4 barcelona.research.yahoo.net/webspam/datasets/uk2007/links   4H   8H   12H   16H   20H   24H   INF   20   40   60   80   100   Time\(hour Ext-SCC-Op   Ext-SCC                           DFS-SCC                 Largein in in in in in in 2 plus one disk block in the main memory that is Size of MassiveNumber of Massive\(a Time Vary Memory   1M   2M   3M   4M   5M   6M   7M   8M   INF   400M   600M   800M   1G   Number of I/Os Ext-SCC-Op   Ext-SCC                       DFS-SCC               iff one of the following three conditions holds 1 b I/Os Vary Memory Fig 7 WEBSPAM-UK2007 Varying Memory Size pages in 114,529 hosts in the UK domain The graph contains 105,895,908 nodes and 3,738,733,568 edges with the average degree 35 per node For synthetic data we generate 3 different kinds of datasets denoted Massive.The 4K,6K,8K,10K,12K 6K,8K,10K,12K,14K u w u G u G u G u G u G u G u G  For any  containing different sizes of and Small 327     V i i i i i d d d i i De\036nition 7.1 DFS Op Op Op Op Op Op 217 before adding  The default memory size is  In our experiments we do not show the results of  thus more iterations are needed according to the stop condition of graph contraction in 327 Semi add Datasets Exp-1 Performance on WEBSPAM-UK2007 in Algorithm 3 more nodes will be selected in id id 200K,300K,400K,500K,600K as follows DFS SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC  By considering  All the algorithms are implemented using Visual C 2005 and tested on a PC with Intel Core2 Quar 2.66GHz CPU and 3.5GB memory running Windows XP The disk block size is  according to Theorem 5.3 nodes with small degrees are removed when constructing 256 400   256 400 Default INF 327 deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg deg  4 w V V E V G V G   u  v V G G E E E E G where can be further reduced We rede\336ne the operator Number of SmallD M s s s i i i i i i i 1 1 1 1 1 1 u>v 4  Secondly using operator  and for each removed node  s 336rst Then we add edges among the nodes in an  We vary the memory size from                     a Time Vary Graph Size   1M   2M   3M   4M   5M   6M   7M   8M   INF   20   40   60   80   100   Number of I/Os Ext-SCC-Op   Ext-SCC                           DFS-SCC                 b I/Os Vary Graph Size Fig 6 WEBSPAM-UK2007 Varying Graph Size Percent   4H   8H   12H   16H   20H   24H   INF   400M   600M   800M   1G   Time\(hour Ext-SCC-Op   Ext-SCC                       DFS-SCC               


SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC increases the time and I/O costs for both dataset dataset The results for both Largedatasets are similar to those in the Massive When either the average   800 105 895 908 8  256  847 200 600 25 200 50 12 30 70 f I/Os SmallTo test the synthetic data we vary the memory size M   K  M M M M M M M M M M D D D D K s s s of nodes from 2 to 6 The time and I/O costs on Largedo not have signi\336cant impact on the ef\336ciency of our algorithms as long as by 20 on average for both time and I/O consumptions Fig 8\(c and Fig 8\(d show the results on Large 1 1 4  the costs for both d I/Os Vary Degree   c Time Vary Degree   25 327         Size and G M G M V V V V V V V K E G Wevary the node size decrease sharply The reason is that in order to process the graph using in all test cases to to is smaller the decrease rate is larger This is because when is smaller more iterations are needed for both to  and the time and I/O costs are shown in Fig 9\(a and Fig 9\(b respectively When to to respectively Fig 9\(g and Fig 9\(h show the time and I/O costs when varying the number of 4   s and and and and and and and and Wevary the average degree Size   Size   Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os Time\(hour Number of I/Os 2H   3H   4H   5H   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 200K   400K   600K   800K   1M   1.2M   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 1H   2H   3H   4H   5H   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 200K   400K   600K   800K   1M   1.2M   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 1H   2H   3H   4H   5H   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 200K   400K   600K   800K   1M   1.2M   INF   200M   300M   400M   500M   600M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 8H   12H   16H   20H   INF   25M   50M   100M   150M   200M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 1M   2M   3M   4M   5M   INF   25M   50M   100M   150M   200M   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 2H   4H   6H   8H   10H   INF   2   3   4   5   6   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 400K   600K   800K   1M   1.2M   INF   2   3   4   5   6   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 2H   3H   4H   5H   INF   4K   6K   8K   10K   12K   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 400K   600K   800K   1M   INF   4K   6K   8K   10K   12K   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 2H   3H   4H   5H   INF   30   40   50   60   70   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 400K   600K   800K   1M   INF   30   40   50   60   70   Ext-SCC-Op   Ext-SCC                           DFS-SCC                 e Time Small,andwhen increase This is because when n in Synthetic Data in Synthetic Data DFS DFS DFS Exp-5 Vary Op Op Op Op Op Op Op Op Op Op Op Op Ext  The time and I/O costs on Massiveare shown in Fig 9\(c and Fig 9\(d respectively When decrease When f I/Os Vary Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext Ext  V  V Number in Synthetic Data c Time Large\(a Time Vary e Time Vary cannot stop in limited time in all cases Similar to the results on the real dataset in Fig 7 when dataset and Fig 8\(e and Fig 8\(f show the results on Smallconsume less than 1 hour increases the time and I/O consumptions for both consumes more than 20 hours while both are the number of nodes and the number of edges of the graph As a result the size of memory is needed thus when the memory size is dataset are shown in Fig 8\(a and Fig 8\(b respectively dataset and this is true for all the remaining test cases when varying other parameters in synthetic data In the following due to the lack of space we only show the test results on the Large and in the graph contraction phase the contraction rate decreases when the number of iterations increases since the graph becomes denser with larger number of iterations is larger and the cost on each iteration to scan and   Exp-4 Vary Average Degree in Synthetic Data from from increases the time and I/O consumptions for both and the number of outperforms outperforms cannot stop within the time limit when outperforms in all cases When the memory increases from increases the time and I/O costs for both When a Time Massive\(b I/Os Massiveis larger is larger the gap between is larger This is because when number of edges is larger more edges can be pruned by the edge reduction techniques used in increases the number of edges increases As a result more iterations are needed and larger cost is consumed in each iteration as analyzed in Exp-1 when varying the graph size size increases or the number of are not in\337uenced much As anal yzed in Section VII the key factors that in\337uence the cost of Num   Num Fig 9 Synthetic Data Largecan be directly applied on the original graph to output all                       Fig 8 Synthetic Data Vary Memory Size outperforms  and Smallincrease This is because the stop condition for graph contraction is harder to be satis\336ed when  sort nodes/edges is larger when   Fig 9\(e and Fig 9\(f show the time and I/O costs when varying the average no iteration is needed and size from SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC 1H   4H   200K   1H   200K   1H   200K   sfrom b I/Os Vary g Time Vary h I/Os Vary        218 d I/Os LargeSemi Semi Exp-2 Vary Memory Size Exp-3 Vary Node Size   


are 336xed This also explains why the results in the three datasets Massiveis a primitive operation in directed graph exploration which has been studied for both internal memory model and external memory model In the internal memory model strongly connected components of a directed graph can be computed in s for a directed graph with the assumption that the nodes of the graph cannot reside entirely in memory We overcome the de\336ciencies of the existing external    sort sort computation algorithms and propose a new two-phase algorithm with graph contraction followed by graph expansion We analyze the I/O cost of our approach and show that our algorithm can signi\336cantly reduce the number of random I/Os We propose techniques to further reduce the I/O cost of our algorithm and con\336rm the I/O ef\336ciency of our approaches using extensive experiments on both real and synthetic web scale graphs The work was supported by grant of the Research Grants Council of the Hong Kong SAR China No 418512 R EFERENCES  J  A bello A  L  Buchs baum  a nd J  W e s t brook A f unctional a pproach to external graph algorithms s of a graph Zhang et al 26 i mpro v e s uch a n a l gori t h m by constructing and maintaining a special in-memory spanning tree of the graph The semi-external algorithms 23 an d  2 6  are introduced in details in Section III Other than the problem of 336nding time based on DFS 12  A naive way to externalize the internal DFS algorithm requires s Such an algorithm may end up an in\336nite loop and cannot compute all  33\(2 2001  H  Y ildir im  V  C haoji and M  J  Z aki Grail Scalable reachability index for large graphs s repeatedly until the graph 336ts in memory then an internal memory algorithm is used to 336nd the 336nal sor DFS tree on external directed graphs several problems in the external memory model are studied in the literature Dementiev et al 14 p ro vi de an i m pl ement a t i o n o f a n e xt ernal m emory minimum spanning tree algorithm based on the ideas of 22 which performs extremely well in practice even though theoretically inferior to the algorithms of 1   1 0   A jw an i e t al 4 6  propos e i mpl e ment at i ons of e x t e rnal undi rect ed breadth-\336rst search algorithm with the idea from 18 Ul rich Meyer et al 20 21  19  des i gn and i mpl e ment pract i c al I/O-ef\336cient single source shortest paths algorithm on general undirected sparse graphs Surveys about designing I/O ef\336cient algorithms for massive graphs can be found at 24 5  X C ONCLUSIONS In this paper we study I/O ef\336cient algorithms to 336nd all  3\(1 2010  J  Hellings  G  H  F letcher  and H  H averkort Ef\336cient external-memory bisimulation on dags In  3\(1 2010  Z  Z h ang J  X Y u  L  Q in L  C hang a nd X L i n I/O e f 336 cient Computing sccs in massive graphs In scan by maintaining the list of nodes that should not be traversed using tournament trees 17 and b uf fered repos i t o ry t rees 8  respectively Despite their theoretical guarantees these algorithms are considered impractic al for general directed graphs that encountered in real applications Cosgaya-Lozano and Zeh 13 p res e nt a c ont ract i o n b as ed al gori t h m w hi ch cont ract s V M E B V B 2 are similar as stated in Exp-2 IX R ELATED W ORK Finding strongly connected components of a directed graph V G V G E G E V E E V E  14\(1 1985  T  H  Cor m en C  S tein R  L  R i v es t and C  E  L eis e r s on  2003  U Me yer a nd N Z e h I/O-ef 336c ient undirected shortest paths with unbounded edge lengths In s Both DFS based algorithm 8 and c ont ract i o n b as ed algorithm 13 a re i n t roduced i n det a i l s i n S e ct i o n III In addition to external algorithms there are semi-external algorithms for ACM Comput Surv Introduction to Algorithms IFIP TCS         Proc of ESA\22202 Proc of ESA\22206 SIAM J Comput Commun ACM Proc of SIGMOD\22213  32\(3 2002 2 A  A ggar w a l a nd J  S  V itter  T h e i nput/output com p le xity of s o r ting and related problems  31\(9 1988  A  V  A ho J  E  Hopcroft a nd J  D Ullm an I/Os Chiang et al 10 propos e a n a l gori t h m with I/O complexity  Addison-Wesley 1983 4 D  A jw ani R D e m e ntie v  and U  M e y er  A com putational s tudy of external-memory bfs algorithms In  2006  D  A jw ani a nd U Me yer   6\(1 2011  A  L  Buchs baum  M  H  G oldw a sser S Venkatasubramanian and J Westbrook On external memory graph traversal In  2002  J  S  V itter  E x ter n al m e m o r y algor ithm s and d ata s tr uctur e s   2007 7 E  A ngel R Cam p igotto a nd C L a f o r e s t  A nalys i s a nd com p ar is on of three algorithms for the vertex cover problem on large graphs with low memory capacities  1995  N  Chiba a nd T  N i s h izeki A r bor icity and s ubgr aph lis ting algor ithm s   2009  R Dem e ntie v  P  Sanders  D  S chultes  and J  F  S ibe y n E ngineering an external memory minimum spanning tree algorithm In  2012  V  K u m a r a nd E  J  Schw abe Im pro v e d a lgorithm s and d ata s tructures for solving graph problems in external memory In  2002  U  M e yer a nd V  O s ipo v  D es ign a nd im plem entation o f a pr actical i/o-ef\336cient shortest paths algorithm In  2009  U Me yer a nd N Z e h I/O-ef 336c ient undirected shortest paths In  2006  J  F  S i be yn E x ter n al connected com p onents  I n  2013 A CKNOWLEDGMENT  Algorithmic Operations Research          267        and computation which assume that all nodes of the graph can 336t in the main memory Sibeyn et al 23 propose a semi-external DFS  which can be used to 336nd all og  pages 457\320468 2012  Y  J  C hiang M T  Goodrich E  F  Gro v e  R  T am as s i a D E  V e ngrof f and J S Vitter External-memory graph algorithms In  Proc of ALENEX\22207 Proc of SIGMOD\22212 Proc of SODA\22295 Proc of SEA\22209 PVLDB Proc of ALENEX\22209 Proc of ESA\22203 PVLDB                    McGraw-Hill 2001  A  Cos g ayaL o zano a nd N  Z e h A h eur i s tic s t r o ng connecti vity algorithm for large graphs In Algorithmica LargeProc of SPAA\22202 G O O O O Algorithmics of Large and Complex Networks Data Structures and Algorithms SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC SCC  Later Kumar and Schwabe 17 a nd B u chs b aum e t a l  8  i mprove the I/O complexity to  chapter 1 Design and Engineering of External Memory Traversal Algorithms for General Graphs Springer 2009  D  A jw ani U Me yer  and V  O s i po v  Im pro v e d e xternal m em ory b fs implementation In  2000  J  Cheng Y  K e  S  Chu and C Cheng E f 336 cient p roces s i ng of distance queries in large graphs a vertex cover approach In  2004  W  F a n J  L i  S  M a H W a ng and Y  W u Graph hom om orphis m revisited for graph matching  1996  K Mehlhorn a nd U Me yer  E xtern al-memory breadth-\336rst search with sublinear i/o In  2004  J  F  Sibe yn J  Abello a nd U Me ye r Heuristics for semi-external depth 336rst search on directed graphs In Proc of SWAT\22204  and SmallProc of SODA\22206 Proc of SODA\22200 219 Proc of SPDP\22296 Proc of SIGMOD\22212 


                  


             


 





 17  Jar r e n  A   B al d w i n  is  a  Ch i c a g o  n a t i v e  a n d  c u r r e n t l y  se r v e s a s t h e  l e a d  E l e c t r i c a l  En g i n e e r  a t  B a y  A r e a  s t a r t u p   Oc u l e v e  I n c   He  g r a d u a t e d  fr o m  t h e  U n i v e r s i t y  o f Il l i n o i s  wi t h  a  B  S   i n  2 0 0 9  an d  r ecei v ed  an  M  S   i n  El e c t r i c a l  En g i n e e r i n g  f r  St a n f o r d  U n i v e r s i t y  i n  2 0 1 2   Ja r r e n  d e v e l o p e d  h a r d w a r e  a n d  so f t w a r e  sy st e m s f o r  a  w i d e  ra n g e  o f  f i e l d s   i n c l u d i n g  s p a c e  s c i e n c e  s y s t e m s  a n d  m e d i c a l  de vi c e s  a s  a N A S A  A m es  i nt e r n i n t he  In t e l l i g e n t  S y s t e m s     1  2  3   4   5   6   7   8   9   10   11   12   13   


                        


                           


   












































     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



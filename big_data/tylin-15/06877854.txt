JUST COMPRESS AND RELAX HANDLING MISSING VALUES IN BIG TENSOR ANALYSIS J.H Marcos  Dept of ECE Univ of Minnesota Minneapolis MN 55455 USA N.D Sidiropoulos  Dept of ECE Univ of Minnesota Minneapolis MN 55455 USA ABSTRACT In applications of tensor analysis missing data is an important issue that is usually handled via weighted least-squares tting imputation or iterative expectation-maximization The resulting algorithms are often cumbersome and tend to fail when the percentage of missing samples is large This paper proposes a novel and refreshingly simple approach for handling randomly missing values in big tensor analysis The stepping stone is random multi-way tensor compression which enables indirect tensor factorization via analysis of compressed replicas of the big tensor A Bernoulli model for the misses and two opposite ends of the tensor modeling spectrum are considered independent and identically distributed i.i.d tensor elements and low-rank and in particular rank-one tensors whose latent factors are i.i.d In both cases analytical results are established showing that the tensor approximation error variance is inversely proportional to the number of available elements Coupled with recent developments in robust CP decomposition these results show that it is possible to ignore missing values without losing the ability to identify the underlying model Index Terms  Tensor decomposition multi-way arrays missing elements missing values big data CANDECOMP  PARAFAC tensor completion imputation 1 INTRODUCTION Tensors are data structures indexed by three or more indices       a generalization of matrices whose elements are indexed by two indices     for row,column respectively Tensors have found numerous and diverse applications across science and engineering and recent adv ances in lar ge-scale web-enabled data collection and mining have made tensor analysis even more important Missing data is an important issue and a growing concern in many applications of matrix and tensor analysis especially those relying on user input e.g ratings in recommender systems or webcrawling for data collection Data can be randomly missing  meaning that the misses are more-or-less independent of one another in which case we often talk of missing elements or missing values or systematically missing  roughly meaning that misses are structured follow certain patterns and entire blocks or pieces of the data can be missing The latter case is typically more challenging The simplest possible model of random misses is that of repeated Bernoulli trials or simply a Bernoulli model  Tensor decomposition with missing data has been considered in and later in 3 for the most basic rank decomposition model   E-mail marc0312@umn.edu  E-mail nikos@umn.edu Tel 16126251242 Fax 16126254583 Supported in part by NSF IIS-1247632 known as parallel factor analysis PARAFAC  or canonical decomposition CANDECOMP no w adays often abbre viated as CP for CANDECOMP-PARAFAC There are two basic ways to handle missing data i t the model only to the available data instead of forcing it to produce zeros or other arbitrary values at places where data is missing or ii try to ll-in the missing data rst then t the model to the full data Fitting the model only to what is available can be accomplished by 0-1 weighting of the cost function Alternating optimization and Gauss-Newton type CP algorithms for missing data were considered in while a more lightweight rstorder method was proposed in One important problem is that weighting usually complicates the tting algorithm when additional constraints are imposed often forcing one to employ small-block coordinate updates which are slow Missing data interpolation on the other hand is often ad-hoc without full regard to the underlying model and it may introduce serious artifacts in the nal solution Iterative model tting and data interpolation is often performed using expectation-maximization b u t this entails a hea vier computational burden and requires a fairly accurate statistical model as prior information In the absence of any side information optimal interpolation of the missing data reduces to estimating the model from the available data and using the estimated model to interpolate in which case there is no point in iterating since the interpolated data are a perfect match to the estimated model This paper proposes a novel and refreshingly simple approach for handling randomly missing values in big tensor analysis The stepping stone is random multi-way tensor compression a tool that was recently introduced in to enable analyzing big tensors that do not otherwise t in fast memory and to parallelize their analysis The main idea is as follows Every compressed sample in the reduced tensor replica\(s is a weighted sum of elements of the big data tensor with weights determined by the random mode compression matrices Normalized by the number of terms this can be viewed as a sample average that converges to its expected value under appropriate conditions When data is missing it may still be possible to accurately estimate the expectation limits provided there is enough data available irrespective of how much data is missing A suitable ergodic property is all that is needed for sample averages to converge to ensemble averages For analysis purposes statistical models for the full data and the miss process should be adopted A simple Bernoulli model for the misses and two opposite ends of the tensor modeling spectrum are considered independent and identically distributed i.i.d tensor elements and low-rank and in particular rank-one tensors whose latent factors are i.i.d In both cases analytical results are established showing that the tensor approximation error variance is inversely proportional to the number of available elements Coupled with recent results on robust CP decomposition 9 ensuring that small perturbation in the data corresponds to small perturbation in the latent factors these developments show that it is possible to ig231 ISCCSP 2014 978-1-4799-2890-3/14/$31.00 ©2014 IEEE 569 ISCCSP 2014 978-1-4799-2890-3/14/$31.00 ©2014 IEEE 2183 ISCCSP 2014 978-1-4799-2890-3/14/$31.00 ©2014 IEEE 873 ISCCSP 2014 978-1-4799-2890-3/14/$31.00 ©2014 IEEE 218 ISCCSP 2014 978-1-4799-2890-3/14/$31.00 ©2014 IEEE 


nore missing values without losing the ability to identify the underlying model 2 TENSOR DECOMPOSITION AND COMPRESSION Notation A scalar is denoted by an italic letter e.g   A column vector is denoted by a bold lowercase letter e.g  whose  th entry is      A matrix is denoted by a bold uppercase letter e.g  with     th entry       A tensor is denoted by an underlined bold uppercase letter e.g    with      th entry        For three vectors                   their outer product      is an      three-way tensor with      th element              Such a tensor is simple  in the sense that all its    columns are constant multiples of a single column and the same is true for its rows and its bers and even for its matrix slabs along any one of its three modes This is a rank-one tensor in direct analogy to a rank-one matrix which is the outer product of two vectors The vec    operator stacks the columns of its matrix argument in one tall column  is the Kronecker product and  stands for the Khatri-Rao column-wise Kronecker product Rank decomposition for tensors The rank of tensor  is the smallest number of rank-one tensors that sum up to                012 This relation can be expressed element-wise as                          012  comprises  slabs of size     denoted         With    vec        vec      it can be shown that         012   vec          012  where             and similarly for     012 is a vector of all 1ês and we have used the vectorization property of the Khatri-Rao product vec              where     is a diagonal matrix with the vector  as its diagonal The above rank decomposition model for tensors is known as PARAFAC CANDECOMP or CP  A mong man y remarkable tensor proper ties perhaps the most useful one is that low rank tensor decomposition i.e CP is often unique even for moderately high ranks see e.g 11 I L M I J J L K M X N Y _ _ U V T K N W T T Fig 1  Illustration of tensor compression from a tensor  of size      to smaller tensor 015 of size     015 Tensor compression With the goal of enabling efìcient CP decomposition of big tensors proposed compressing  into a far smaller tensor 015  and showed that when the latent components the columns of       are sparse then it is possible to recover them from the latent components of 015  They proposed to multiply every slab of  with   from the  mode with   from the  mode and with   from the  mode They proposed using random compression matrices             and     015  with         015   and  015    see Fig 1 Using random compression matrices helps to ensure identiìability in this setting With   denoting the  th column of     the  th column of  and   the  th column of   the elements of the compressed tensor can be expressed as 015        012                       012 Notice that the overall effect of compression is trilinear with respect to the elements of the compression matrices but linear in        Furthermore due to the fact that the overall compression is separable across modes if  admits a CP decomposition parametrized by        then 015 will admit a CP decomposition parametrized by            with                      Notice that the number of components  number of columns is the same for both decompositions When  has sparse columns then it is possible to recover  from the seemingly under-determined linear system       by exploiting sparsity This last step fails when the columns of  are not sparse A simple but instrumental idea in 7 is that one can instead spa wn a number of independently compressed replicas of  in this case analyze them in parallel and combine the results to over-determine the problem without recourse to sparsity With or without sparsity the results in open a completely new way to compute the CP decomposition of big tensors that offers decoupled parallelization in-memory processing for the parallel threads and compatibility with cloud computing and storage The results in suggest using i.i.d zero-mean matrices for compressing the different modes of the tensor Here we will instead advocate using nonzero-mean compression matrices and show how this simple and seemingly inconsequential modiìcation allows us to effectively handle missing elements without any other alterations 3 MAIN RESULTS Deìne 015                          and 012              is available   and let   be the tensor calculated using the available elements of   i.e          012                          1 If we normalize the compressed tensor 015 by the number of elements of   and similarly normalize  015 by the expected number of available elements    012   we get  015       015    012                          015          012     012                         2 Note that we use the subscript    rather than the more common n for normalization to avoid confusion with the index n The reason we choose to normalize by the expected number of available 232 570 2184 874 219 


elements    012    rather than the actual number  012   is because it yields an unbiased estimator whose statistics are easier to analyze as  012  is itself a random variable In practice we can use the actual number of elements  012   as an estimate of the expected number of elements    012    In order to evaluate this approximation we deìne the normalized error tensor  015 as the difference between the compressed tensor  015 and its estimate from available elements only   015  i.e  015    015   015  Deìne               012     if       012   if        012 3                012            015  4 This allows us to rewrite   015 and  015 as   015          012                                  015                                      We assume a Bernoulli model for the available elements with parameter          012  The elements of    and  are all independently drawn according to                            and              where       and   are continuous marginal densities Deìne            and likewise for     We have the following result proofs are deferred to the journal version due to space limitations Claim 1       015              015           015                if  is random i.i.d             if  is rank-F w i.i.d loadings Claim 2 For i.i.d               where         is an arbitrary probability distribution we get    015             015          5    015         015             015               015                 015                015                 015                  015                    015     6 where                       When        015         015           015                                   else for    we have                         Claim 3 Fo r                           assuming that the elements of      and   are all i.i.d random variables drawn from                             and                with                                  and         we have    015             015                                015         015                                015                                  015                                    015                                    015                                    015                                      015                                        015                         015         015           015                                               when         are all    otherwise                         For low-enough   applying theorem 2.3 in we get that the reconstructed loadings also have the same rate of convergence up to a scaling polynomial that is independent of   015    4 SIMULATION RESULTS All simulation results reported here are averaged over  012 MonteCarlo trials For every trial we generate new      and  drawn from an i.i.d Gaussian distribution and a new i.i.d Bernoulli 012 For    and  we x       012  for   these parameters are depicted in the gures We deìne 015   015                      and simulate ve different sizes of the original tensor including three symmetric and two asymmetric cases In all cases we compress to       Figs 2 3 and 4 show the theoretical and actual SNR of 015 using normalization by the expected number of elements as analytically derived and also using the actual number of elements for i.i.d and rank-1   Notice that the SNR with normalization by the actual number of elements is better than the one that uses the expected number of elements for     but this is not necessarily true for small   Figs.\(4\and 5 show the SNR of the compressed tensors and the reconstructed loadings of  using PARACOMP 7 Note that the symmetric cases yield higher SNR for the reconstructed loadings for the same number of elements 015   5 CONCLUSIONS We presented a novel and simple way to handle missing elements in factor analysis of big tensors The main idea is to randomly compress the tensor while ignoring the missing values except for normalization Assuming random Bernoulli misses we proved that the 233 571 2185 875 220 


     10 5                   10 4                   10 3                   10 2                   10 1                   10 0 20   10   0   10   20   30   40   50 Bernoulli Density parameter   SNR Y dB SNR of Y for X IID   X   X 0  1  1   Actual SNR using expected number of available alements Actual SNR using actual number of available alements Theoretical SNR Lower bound Theoretical SNR \(Exact I = J = K = 200 I =4 0 0, J = K = 5 0 I = J = K = 50 Fig 2  SNR of compressed tensor 015 for different sizes of i.i.d      10 5                   10 4                   10 3                   10 2                   10 1                   10 0 10   0   10   20   30   40   50   60   70 Bernoulli Density parameter   SNR Y dB SNR of Y for X IID   X   X 1  1   Actual SNR using expected number of available alements Actual SNR using actual number of available alements Theoretical SNR Lower bound Theoretical SNR \(Exact I = J = K = 200 I = J = K = 50 I = 400, J = K = 50 Fig 3  SNR of compressed tensor for different sizes of i.i.d  error variance in the compressed domain is inversely proportional to the number of available elements for two stochastic tensor models i.i.d and low-rank with i.i.d latent loadings For both cases we provided analytical formulas for the SNR in the compressed domain and conìrmed our analysis with simulations Our simulations also conìrmed that the latent loadings can be recovered this way even with a large percentage of missing elements 6 REFERENCES  A.K Smilde R Bro and P  Geladi Multi-way Analysis Applications in the Chemical Sciences  Wiley 2004  G T omasi and R  Bro P ARAF A C and missing v alues  Chemometrics and Intelligent Laboratory Systems  vol 75 no 2 pp 163Ö180 2005  E Acar  D.M Dunla vy  T G K o lda and M Mrup Scalable tensor factorizations for incomplete data Chemometrics and Intelligent Laboratory Systems  vol 106 no 1 pp 41Ö56 2011  R.A Harshman F oundations of the P ARAF A C procedure Models and conditions for an explanatory multimodal factor analysis UCLA Working Papers in Phonetics  vol 16 pp 1Ö84 1970  J.D Carroll and J.J Chang  A nalysis of indi vidual dif ferences in multidimensional scaling via an n-way generalization of Eckart-Young decomposition Psychometrika  vol 35 no 3 pp 283Ö319 1970     10 5                   10 4                   10 3                   10 2                   10 1                   10 0 10   0   10   20   30   40   50   60   70 Bernoulli Density parameter   SNR Y dB SNR of Y for rank  X 1  X   X 1  1   Actual SNR using expected number of available alements Actual SNR using actual number of available alements Theoretical SNR Lower bound Theoretical SNR \(Exact I = J = K = 50 I = 400 J = K = 50 I = J = K = 200 Fig 4  SNR of compressed tensor for different sizes of rank-one      10 5                   10 4                   10 3                   10 2                   10 1                   10 0 5   0   5   10   15   20   25   30   35   40   45 Bernoulli Density parameter   SNR A dB SNR of loadings A for rank  X 1  X   X 1  1   I,J,K 200,200,200 I,J,K 100,100,100 I,J,K 50,50,50 I,J,K 200,100,50 I,J,K 400,50,50 Fig 5  SNR of recovered loadings for different sizes of rank-one   N.D Sidiropoulos and A K yrillidis Multi-w ay compressed sensing for sparse low-rank tensors IEEE Signal Processing Letters  vol 19 no 11 pp 757Ö760 2012  N.D Sidiropoulos E.E P apale xakis and C F aloutsos A P a rallel Algorithm for Big Tensor Decomposition Using Randomly Compressed Cubes PARACOMP in Proc IEEE ICASSP 2014 May 4-9 Florence Italy submitted  N.D Sidiropoulos E.E P apale xakis and C F aloutsos P Arallel RAndomly COMPressed Cubes PARACOMP A Scalable Distributed Architecture for Big Tensor Decomposition IEEE Signal Processing Magazine  Jan 2014 submitted  A Bhaskara M Charikar  a nd A V ijayaragha v a n Uniqueness of tensor decompositions with applications to polynomial identiìability http://arxiv.org/abs/1304.8087  Apr 2013  A Bhaskara M Charikar A Moitra and A V ijayaraghavan Smoothed Analysis of Tensor Decompositions http://arxiv.org/abs/1311.3651  Nov 2013  J.B Kruskal Three-w ay arrays Rank and uniqueness of trilinear decompositions with application to arithmetic complexity and statistics Linear Algebra and its Applications  vol 18 no 2 pp 95Ö138 1977  N.D Sidiropoulos and R Bro On the uniqueness of multilinear decomposition of N-way arrays Journal of chemometrics  vol 14 no 3 pp 229Ö239 2000 234 572 2186 876 221 


Agents have to be able to perform several competing tasks to respond to di fferent requests. For this purpose every agent has the possib ility to implement different behavior types, ranging from those simple ones, performed only once to those performed until a certain condition is fulfilled, unless otherwise specified. Th e Figure 6 shows the JADE framework behavior hierarc hy. [8 The  beha vior al state has to be contained in corresponding agents. Every agent cares about its behavioral state, such as the action completion and the action blockage  Behaviour Composite Behaviour Simple Behaviour FMS Behaviour Sequential Behaviour Parallel Behaviour OneShot Behaviour Cyclic Behaviour Waker Behaviour Ticker Behaviour Figure 6 The Jade behavior hierarchy The FIPA has specified interaction protocol stacks used for inter-agent communication. For every conversion, the JADE differentiates between the roles of the initiator and the agent replying Responder essages. The Figure 7 shows inter-agent commun ication structure. The Initiator sends the message, and the responder may reply with the message ìnot understoodî, refuse to reply with the message refuseî or agree with the message via ìagreeî. If the agent replies with ìagreeî, the messag e is sent so quickly that it can be considered as an unnecessary burde communicative act not-understood refuse reason agree failure reason inform Done\(action Inform iota x\(result action\ x Figure 7 The Interaction Protocol Homogeneous Structure IV I NSURANCE MAS EXAMPLE This example comes from the Insurance domain and describes one of many situations in which employees need information to make a decision about th eir business actions This is a problem not only for employees working in headquarters or static wo rkers in other offices, but also for mobile employees. As the number of mobile and online users in the world continues to grow so do the ways in which mobile users can gath er the right information. All employees, ranging from a CEO to a seller, can request and obtain, automatically or on demand, a critical alert or information that is important for their business operations to their mobile phone or a sm art phone. Every mobile phone equipped with appropriate software becomes a mobile agent capable of imitating communi cation with the headquarter agent who will resp ond to their queries To demonstrate this, we have developed two agents with different roles using the JADE architecture. One of them has a double role and rep resents the most important agent in the process since it discovers knowledge and upon discovering it, it sends it as information to mobile agents. Mobile agent is the second agent that only initiates communication The database includes two tables: one, titled ìPolicies includes the concluded policies, and the second, titled Personsî that contains data of the policy holders. The Figure 8 indicates the database structure PERSONS ID PK  Surname Place Name  POLICIES Number PK  Person  FK Price Figure 8 Database structure The Agent that discovers knowledge, called the ìMain agent, obtains the statistical figures regarding the number of issued insurance policies and the realized premium. When the ìMainî agent finds the right information it sends it to mobile agents, known as the ìSellerî agents. The Main agent offers to the Seller agent available information that it has and offers the Seller agent to accept or refuse it depending on the Sellerís needs. The Seller agent performs the ìSellerìbehavior, send ing the query on the schedule time passing through the corresponding communication steps Figure 9\. Every step requires corresponding behavior depending on the message type The next code snippet covers a part of communication between the Main agent and the Seller agent if \(messageRecieve.getPerformative ACLMessage.CFP messageAnswer.setPerforma tive\(ACLMessage.INFORM messageAnswer.setConversationId\("policy messageAnswer.setContent\("MAIN: Available Sent message myAgent.send\(messageAnswer else if messageRecieve.getPerformative ACLMessage.ACCEPT_PROPOSAL messageAnswer.setPerformative ACLMessage.PROPOSE messageAnswer.setConversationId\("policy messageAnswer.setContent\("MAIN: Number Send message myAgent.send\(messageAnswer In the first step, the Seller agent sends the CFP \(Call for Proposal available statistics. The behavior defining the CFP message is ÑSendCfpRequestì. The Main agent grasps that this is a CFP message and sends back the INFORM message, informing the Seller agen t about the available statistics 1122 


Figure 9 JADE Communication between Seller and Main Agent The Seller agent accepts the proposal from the Main agent via ìReceiveCfpRequestî behavior and returns the message ACCEPT_PROPOSAL. The behavior defining the proposal is ìCofirmRequestî, whereby th e Main agent, using the appropriate methods, contacts the distributed databases and by performing the queries \(SQL select\he Main agent sends the corresponding information via the message PROPOSE. Then, the Seller agent accepts the statistics via the ìAcceptStatisticsî behavior and prints them to the console After running the application, th e console displays the following  Agent container Main-Container@10.170.2.57 is ready SELLER: Request for statistic MAIN: Available statistics are number of sold policies and premium SELLER: Accept! Give me all statistics MAIN  Number of sold policies: 8 Premium: 2900.0  V C ONCLUSION Due to the large amount of information, intelligent software agents organized in the Multi Agent Systems represent a solution to the problem of gathering, processing and using information. Intelligent software agents are a collection of technology that ensure development of advanced services because it enables creation of intelligent services, tailor-made to the needs of a user. By using software agents, certain tasks, otherwise performed independently by users, can now be automated. Intelligent software agents support business processes due to their great potential, especially in terms of processing and ma intenance of large amounts of informa tion stored in heterogeneous dislocated information sources. Implementation of a business process solution th rough the Multi Agent System based on the JADE framework, such as the one presented in the paper, is straightforward and intuitive. With the development and spread of new mobile hardware, problems such as detection of individu al system entities and users and their communication are entering into a new phase. New trends and increase in the number of users of smart devices result in larger number of services these devices can provide. The fact that each user has a smart device in his/her immediate vicinity and that he/she can store new data at any moment, indicates the need to synchronize this data with other systems, as well as the need for various data access VI R EFERENCES  Inform ation 2020: Big Data and Bey ond  http://www.gartner.com/, Business Intelligence & Information Management, Featured Webinar  An Overview of B u siness Inteligence Technology Communication of the ACM August 2011, Vol. 54, DOI: 10.1145/1978542.1978562, Surajit Chaudhuri, Umeshwar Dayal, Vivek Narasayya  Data W a rehousing Data m i ning OLAP and OLTP technologies are essential elements to support decision-making process in industries, \(IJCSE l Journal on Computer Science and Engineering, Vol. 02 No. 09, 2010, 2865-2873 G.Satyanarayana Reddy, Rallabandi Srinivasu, M.Poorna Chander Rao, Srikanth Reddy Rikkula, ISSN: 0975-3397  OLAP Council http://www.olapcouncile.com  Cloud-hoste d databases: technologie s, challenges and opportunities, Sherif Sakr, Springer Science+Business Media New York 2013  CAP Tw elwe Years Later How th e rules have changed, Eric Brewer, University of California, Berkeley, Computer magazine, February 2012  An Overview of Data W a rehousing and OLAP Technology  Surajit Chaudhuri, Umeshwar Dayal  Developing Multi-Agent Syste m s wit h JADE Fabio Bellifemine, Telecom Italia, Italy Giovanni Caire, Telecom Italia, Italy Dominic Greenwood, Whitestein Technologies AG, Switzerland  JADE Ad m inistrat ion Tutorial http://jade.tilab.com/doc/tutorials/JADEAdmin/index.html Author: David Grimshaw \(Ryerson Univer sity\ 26, 2010  JADE P r ogra m m e rís Guide  http://jade.tilab.com/doc/programmersguide.pdf Fabio Bellifemine, Giovanni Caire, Tiziana Trucco \(TILAB formerly CSELT\, Giovanni Rimassa \(University of Parma 08-April-2010. JADE 4.0  http://www.fipa.org Foundation for intelligent physical agents 1123 


                    


         


    


         


Figure 4  Payload Allocation Figure 5  Procurement vs Hosted Payloads Hosted payloads vs 100 procurement This case study focuses on the impact of including hosted payloads as part of the system Figure 5 presents an extended representation of the tradespace where hosted payload architectures are included The 002rst immediate conclusion that can be drawn is that based on the cost model from hosted payloads offer the possibility of signi\002cant cost reductions 050between 15 and 30%\051 As a result all architectures on the Pareto front rely on hosted payload architectures On the other hand concerns about using hosted payload assets for critical applications like astronaut support have been 003agged as a major caveat In this case an optimal solution would entail using a portfolio of hosted payloads and privately owned satellites and schedule the communications through ones or the others according to operational constraints Therefore building this portfolio can be done by analyzing what communication payloads are better suited for hosted payload con\002gurations Figure 6 presents the tradespace of architectures that mix hosted payload and procured assets Results indicate that including hosted payload assets in the system does not have a major impact on its performance but requires disaggregating the monolithic satellites identi\002ed as optimal in the previous case study That being the case the next questions arise Figure 6  Portfolios of hosted payload and procured assets Which payload obtains better savings when being hosted How many payloads do you want to 003y in a hosted payload approach The answer for the 002rst question can be obtained by analyzing the non-dominated architectures from 002gure 6 and estimating the cost savings when hosting the different types of antennas that are considered in this analysis Results indicate that hosting an optical payload can potentially save an 28 of the cost while a low data rate antenna 050S-band\051 only obtains a 16 cost reduction 050note that these numbers are based on the system life-cycle cost and are heavily in\003uenced by the hosted payload cost model\051 Therefore it seems to be more advisable to put high data rate payloads like optical terminals in commercial satellites and retain control of S-band communications 050which in turn ensures that contingency event will be addressed by privately owned assets not constrained by the operational limitations of host platforms\051 Finally 002gure 7 presents the tradespace of hosted payload architectures color coded by the number of antennas that are being hosted By looking at the Pareto front it can be seen that almost all architectures host one single antenna as opposed to two in order to minimize the burden on the host platform This burden is also contingent on the mass and power of the hosted communication payload This is the main reason why optical terminals become so attractive for hosted payload architectures as opposed to low frequency systems that require big parabolic antennas and power ampli\002ers to close the link budgets 6 C ONCLUSION Summary This paper has presented the 002rst set of results obtained through the developed architectural tool to evaluate space communication networks It has 002rst provided a high level overview of the tool with a description of four main constitutive elements An STK model an architecture generator an architecture evaluator and a resource manager Next it has described the newly developed scheduling algorithm based on a rule-based expert system that ef\002ciently allocates the network resources to satisfy near-Earth mission communication requirements Then a discussion on the conducted validation exercise has 11 


Figure 7  Portfolios of hosted payload and procured assets been presented in order to gain some level of con\002dence on the results that the tool outputs This discussion has focused on the validation of the scheduling algorithm by benchmarking it with operational schedules from the TDRSS Finally this paper has presented two case studies for future implementations of the TDRSS system Based on a demand forecast for the network a 002rst case study has considered the problem of selecting the frequency band to be supported and how to allocate them into the relay satellites It has been shown that maximum performance architectures require a mix of optical and RF payloads that support high throughput communications as well as reliable low data rate communications If the traditional procurement strategy is assumed 050NASA buys and operates the relay satellites\051 then monolithic architectures are preferable unless more than two high gain antennas render the resulting satellite con\002guration too complex In turn the second case study has extended this analysis by introducing architectures with hosted payloads It has been shown that according to the current available pricing model hosted payload architectures are clearly preferable than the traditional procurement strategy with cost savings between 15 to 30 for the same level of system performance It has then been discussed the advantages of having mixed procured and hosted payload architectures as a compromise to obtain networks with reduced lifecycle costs that can still address the requirements of highly sensitive and reliable applications Results have demonstrated that high data rate payloads 050speci\002cally optical payloads\051 are the best candidates to be hosted 050with savings up to 28%\051 thanks to their reduced mass and power requirement On the other hand low data rate communication payload should be allocated in privately owned satellites as they require bigger antennas and power ampli\002ers that increase the burden on the host platform Future Work The main streams of future work are as twofold On one hand additional features should be added to the model in order to better capture the complexity of the network con\002gurations 050e.g coupling between the costs of the communication payloads depending on the level of on-orbit processing the they perform\051 Additionally the size of the tradespace is currently limited to less than two thousand architectures due to computational limitations a stringent limitation given the possible combinations from the identi\002ed architectural decisions The solution currently under development is to include a genetic algorithm that alleviates this problem by iteratively generates new populations of architectures by combining the best previously evaluated networks On the other hand the other main stream of future work is related to exercising the tool in a variety of architectural decisions and mission scenarios In the presented case studies only geosynchronous constellations were considered although the tool allows comparing them with systems that place relays in MEO and LEO orbits Additionally the tool can also provide insight in valuing inter-satellite links and how the cost of putting in orbit their extra communication payloads can be leveraged by reducing the number of operating ground stations Moreover couplings between the payload allocation and fractionation strategy should also be further explored so as to understand if monolithic architectures still become preferable if relay satellites can be decomposed in clusters of independent antennas and payloads Finally supplementary what-if analysis can be conducted based on 0501\051 the demand forecast for the 2020-2030 time frame 0502\051 granted spectrum allocations to NASA and 0503\051 technology improvements that increase the spectral ef\002ciency of the communication payloads 12 


A PPENDIX Table 7  Acronyms Arch Architecture CER Cost Estimating Relationship DESDYNI Deformation Ecosystem Structure and Dynamics of Ice DSN Deep Space Network EIRP Equivalent Isotropically Radiated Power GEO Geosynchronous Orbit GRTG Guam Remote Ground Terminal GSFC Goddard Space Flight Center HD High De\002nition HP Hosted Payloads ISL Intersatellite Link ISS International Space Station LCC Life Cycle Cost LEO Low Earth Orbit MEO Medium Earth Orbit MIT Massachusetts Institute of Technology MOC Mission Operating Center MPCV Multi-Purpose Crew Vehicle NASA National Aeronautics and Space Administration NCCDS Network Control Center Data System NDA Non-Disclosure Agreement NEN Near Earth Network NISN NASA Integrated Services Network NOAA National Oceanic and Atmospheric Administration RF Radio Frequency SA Single Access SBRS Space based Relay Study SCaN Space Communication and Navigation SN Space Network STGT Second TDRSS Ground Terminal STK Systems ToolKit TDRSS Tracking and Data Relay Satellite System TT&C Telemetry Tracking and Command USGS United States Geological Survey WSGT White Sands Grount Terminal A CKNOWLEDGMENTS This project is funded by NASA under grant NNX11AR70G Special thanks for Gregory Heckler David Milliner and Catherine Barclay at NASA GSFC for their help getting the dataset and their feedback on our study R EFERENCES   National Aeronautics and Space Administration 223Space Communications and Navigation 050SCaN\051 Network Architecture De\002nition Document 050ADD\051 Volume 1  Executive Summary,\224 Tech Rep 2011   227\227 A v ailable http   www.nasa.gov/directorates/heo/scan   e a Sanchez Net Marc 223Exploring the architectural trade space of nasas space communication and navigation program,\224 in Aerospace Conference 2013 IEEE  2013   P Brown O  Eremenko 223Fractionated space architectures a vision for responsive space,\224 Tech Rep   S M V  D C E Teles J 223Overview of TDRSS,\224 Advances in Space Research  vol 16 pp 67\22676 1995   Analytical Graphics Inc A v ailable http   http://www.agi.com   D Selva Valero 223Rule-Based System Architecting of Earth Observation Satellite Systems by,\224 Ph.D dissertation Massachusetts Institute of Technology 2012   K D W  S P Davidson A 223Pricing a hosted payload,\224 in Aerospace Conference 2012 IEEE  2012   W J Larson and J R Wertz Space mission analysis and design  Microcosm Inc 1992   M Adinol\002 and A Cesta 223Contributed Paper Heuristic Scheduling of the DRS Communication System,\224 vol 8 1995   National Aeronautics and Space Administration Space Network Users Guide 050 SNUG 051  2007 no August 2007   e a Tran J J 223Evaluating cloud computing in the nasa desdyni ground data system,\224 in Proceedings of the 2nd International Workshop on Software Engineering for Cloud Computing  2011 B IOGRAPHY  Marc Sanchez Net is currently a second year M.S student in the department of Aeronautics and Astronautics at MIT His research interests include machine learning algorithms and rule-based expert systems and their suitability to the 002elds of system engineering and space communication networks Prior to his work at MIT Marc interned at Sener Ingenieria y Sistemas as a part of the team that develops and maintains FORAN a CAD/CAM/CAE commercial software for shipbuilding Marc received his degrees in both Industrial engineering and Telecommunications engineering in 2012 from Universitat Politecnica de Catalunya Barcelona Dr Daniel Selva received a PhD in Space Systems from MIT in 2012 and he is currently a post-doctoral associate in the department of Aeronautics and Astronautics at MIT and an adjunct Assistant Professor in the Sibley School of Mechanical and Aerospace Engineering at Cornell University His research interests focus on the application of multidisciplinary optimization and arti\002cial intelligence techniques to space systems engineering and architecture Prior to MIT Daniel worked for four years in Kourou 050French Guiana\051 as a member of the Ariane 5 Launch team Daniel has a dual background in electrical engineering 13 


and aeronautical engineering with degrees from Universitat Politecnica de Catalunya in Barcelona Spain and Supaero in Toulouse France He is a 2007 la Caixa fellow and received the Nortel Networks prize for academic excellence in 2002 Dr Bruce Cameron is a Lecturer in Engineering Systems at MIT and a consultant on platform strategies At MIT Dr Cameron ran the MIT Commonality study a 16 002rm investigation of platforming returns Dr Cameron's current clients include Fortune 500 002rms in high tech aerospace transportation and consumer goods Prior to MIT Bruce worked as an engagement manager at a management consultancy and as a system engineer at MDA Space Systems and has built hardware currently in orbit Dr Cameron received his undergraduate degree from the University of Toronto and graduate degrees from MIT Dr Edward F Crawley received an Sc.D in Aerospace Structures from MIT in 1981 His early research interests centered on structural dynamics aeroelasticity and the development of actively controlled and intelligent structures Recently Dr Crawleys research has focused on the domain of the architecture and design of complex systems From 1996 to 2003 he served as the Department Head of Aeronautics and Astronautics at MIT leading the strategic realignment of the department Dr Crawley is a Fellow of the AIAA and the Royal Aeronautical Society 050UK\051 and is a member of three national academies of engineering He is the author of numerous journal publications in the AIAA Journal the ASME Journal the Journal of Composite Materials and Acta Astronautica He received the NASA Public Service Medal Recently Prof Crawley was one of the ten members of the presidential committee led by Norman Augustine to study the future of human space\003ight in the US Bernard D Seery is the Assistant Director for Advanced Concepts in the Of\002ce of the Director at NASA's Goddard Space Flight Center 050GSFC\051 Responsibilities include assisting the Deputy Director for Science and Technology with development of new mission and measurement concepts strategic analysis strategy development and investment resources prioritization Prior assignments at NASA Headquarters included Deputy for Advanced Planning and Director of the Advanced Planning and Integration Of\002ce 050APIO\051 Division Director for Studies and Analysis in the Program Analysis and Evaluation 050PA&E\051 of\002ce and Deputy Associate Administrator 050DAA\051 in NASA's Code U Of\002ce of Biological and Physical Research 050OBPR\051 Previously Bernie was the Deputy Director of the Sciences and Exploration Directorate Code 600 at 050GSFC\051 Bernie graduated from Fair\002eld University in Connecticut in 1975 with a bachelors of science in physics with emphasis in nuclear physics He then attended the University of Arizona's School of Optical Sciences and obtained a masters degree in Optical Sciences specializing in nonlinear optical approaches to automated alignment and wavefront control of a large electrically-pumped CO2 laser fusion driver He completed all the course work for a PhD in Optical Sciences in 1979 with emphasis in laser physics and spectroscopy He has been a staff member in the Laser Fusion Division 050L1\051 at the Los Alamos National Laboratories 050LANL\051 managed by the University of California for the Department of Energy working on innovative infrared laser auto-alignment systems and infrared interferometry for target alignment for the HELIOS 10 kilojoule eight-beam carbon dioxide laser fusion system In 1979 he joined TRW's Space and Defense organization in Redondo Beach CA and designed and developed several high-power space lasers and sophisticated spacecraft electro-optics payloads He received the TRW Principal Investigators award for 8 consecutive years Dr Antonios A Seas is a Study Manager at the Advanced Concept and Formulation Of\002ce 050ACFO\051 of the NASA's Goddard Space Flight Center Prior to this assignment he was a member of the Lasers and Electro-Optics branch where he focused on optical communications and the development of laser systems for space applications Prior to joining NASA in 2005 he spent several years in the telecommunication industry developing long haul submarine 002ber optics systems and as an Assistant Professor at the Bronx Community College Antonios received his undergraduate and graduate degrees from the City College of New York and his doctoral degree from the Graduate Center of the City University of New York He is also a certi\002ed Project Management Professional 14 


 





 17  Jar r e n  A   B al d w i n  is  a  Ch i c a g o  n a t i v e  a n d  c u r r e n t l y  se r v e s a s t h e  l e a d  E l e c t r i c a l  En g i n e e r  a t  B a y  A r e a  s t a r t u p   Oc u l e v e  I n c   He  g r a d u a t e d  fr o m  t h e  U n i v e r s i t y  o f Il l i n o i s  wi t h  a  B  S   i n  2 0 0 9  an d  r ecei v ed  an  M  S   i n  El e c t r i c a l  En g i n e e r i n g  f r  St a n f o r d  U n i v e r s i t y  i n  2 0 1 2   Ja r r e n  d e v e l o p e d  h a r d w a r e  a n d  so f t w a r e  sy st e m s f o r  a  w i d e  ra n g e  o f  f i e l d s   i n c l u d i n g  s p a c e  s c i e n c e  s y s t e m s  a n d  m e d i c a l  de vi c e s  a s  a N A S A  A m es  i nt e r n i n t he  In t e l l i g e n t  S y s t e m s     1  2  3   4   5   6   7   8   9   10   11   12   13   


                        


                           


   












































     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



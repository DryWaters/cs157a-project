HDW: A High Performance Large Scale Data Warehouse  Jinguo You 1 Jianqing Xi 1 Chuan Zhang 1 Gengqi Guo 1, 2  1 School of Computer Science and Engineering South China University of Technology  Guang Zhou 510641, China 2 Guangdong Communication Polytechnic, Guang Zhou 510641, China jgyou@126.com; csjqxi@scut.edu.cn; c huanzh69@yahoo.com.cn ggengqi@tom.com   Abstract 002   As data warehouses grow in size, ensuring adequate database performance will be a big challenge. This paper presents a solution, called HDW, based on Google infrastructure such as GFS, Bigtable MapReduce to build and manage a large scale distributed data warehouse for high performance OLAP analysis. In addition, HDW provides XMLA standard interface for front end applications. The results show that HDW achieves pretty good performance and high scalability, which has been demonstrated on at least 18 nodes with 36 cores Keywords  data warehouse, GFS, Bigtable MapReduce, high performance  1  Introduction  With information generated consistently, data warehouses grow in size [1  T h i s c h a l l e nge s c u r r e nt  data warehouse systems. To accommodate and analyze vast quantities of data over time become more difficult than ever. In some business scenarios, data warehouses and business intelligence applications are required to answer exactly the types of ad hoc OLAP queries that users would like to pose against real time data. Further  pro pos ed C S t ore, a colu m n o riented DB MS, w h ic h  outperforms the current traditional DBMSs in read optimization. As data warehouses are read-mostly, the new data warehouses design needs to consider and incorporate the C-Store feature Recently, Google provides server infrastructure such as GFS t able [4] an d MapR edu ce [5] to h a n d le with large amounts of data on thousands of low cost commodity machines. Considering Google’s searching information over the very large worldwide web, how about using the infrastructure to build a huge data warehouses This paper presents a solution built upon the Google infrastructure, called HDW. HDW is a large scale distributed data warehouse where high performance OLAP analysis is executed. It uses GFS and Bigtable to store data. Also it uses MapReduce to parallelized computation tasks such as data cube construction   002 The research is sponsored by the Science & Technology Program of Guangdong Province, China \(NO. 2006B11301001, NO 2006B80407001\ and The International Science &Technology Cooperation Program of Guangdong Province, China \(NO 2007A050100026 OLAP query answering  HDW is different from other previous parallel data warehouse and OLAP systems. The most comparable system with HDW is Panda [6, 7  T h e y all ai m at a high performance scalable parallel OLAP system built on low cost share nothing clusters. But they have quite a few differences in implementation. Panda constructs ROLAP data cubes mainly based on the pipesort algorithm, while HDW builds a MOLAP data cubes around the closed cube algorithm a n d a an d m o s t  other systems [10, 11, 12 e m pl o y MPI Message Passing Interface municate between a node and another node. They need to take extra consideration about data partitioning, load balance and failure tolerance, which are automatically handled by GFS and Mapreduce used in HDW. In addition, for high availability, HDW provides XMLA \(XML for Analysis standard API for front end applications. Thus, all visualization tools which support XMLA can be easily plugged into HDW system without much modification  2. Design Overview 2.1 Architecture  The HDW system consists of four layers as illustrated in Figure 1: the storage layer, the calculation layer, the message layer and the presentation layer  Figure 1. The layers of HDW  The storage layer stores metadata and summary data in GFS or Bigtable. Large data is split into blocks which are spread across different machines. The storage layer also extracts data from a relational database The calculation layer uses MapReduce framework to parallelize computation tasks such as the data cube storage layer message layer presentation layer calculation layer GFS / Bigtable RDB MapReduce XMLA Engine JPivot   Excel i Manager l   
2008 International Muitsymposiums on Computer and Computational Sciences 978-0-7695-3430-5/08 $25.00 © 2008 IEEE DOI 10.1109/IMSCCS.2008.16 200 
2008 International Multi-symposiums on Computer and Computational Sciences 978-0-7695-3430-5/08 $25.00 © 2008 IEEE DOI 10.1109/IMSCCS.2008.16 200 


construction \(i.e. aggregate data into a data cube\d OLAP queries. The calculation layer accesses data in the storage layer via the read / write interface provided by the storage layer, pre-aggregates the data and stores the aggregated data to the storage layer The message layer includes an XMLA engine which processes requests from users and invokes the calculation layer to execute parallel computation tasks Through XMLA, the message layer provide a unify interface for client applications. Metadata discovery OLAP query and pre-computation etc. are all wrapped into two standard methods: discover and execute  In the presentation layer, users can make analysis via JPivot, Excel pivot table, etc. visualization tools that support the XMLA specification. The system also provides a management console to manage the GFS Bigtable, create data warehouse schema metadata, send query request, and monitor the execution   2.2 Interface  The storage layer provides the data access interface for the calculation layer. The Map tasks and Reduce tasks read data in Bigtable via TableInputFormat and write TableOutputFormat. When the table is from a relational database, the interface is DbInputFormat and DboutputFormat. For files, the access of GFS is wrapped as FileInputFormat and FileOutputFormat In the calculation layer, the interface for the data cube construction is CubingMap and CubingReduce The OLAP querying interface is QueryMap and QueryReduce. These interfaces are all invoked by the message layer’s interface: Discover and Execute, two methods defined in XMLA  3. Implementation Detail 3.1 Storage Structure  If the summary data in the data cube is structured, it is stored in a distributed table which we called Cubetable. Cubetable is built and managed by Bigtable Therefore Cubetable is column oriented, which is more efficient for storage and querying of data cubes since data cubes are sparse in most situations  Figure 2. A slice of C ubetable conceptual view  The Cubetable conceptual view is shown in Figure 2 The data cube unique name acts as the row name. The dimension unique name acts as the column family name while the level unique name in the dimension the qualifier of the column family. As soon as a record of the data cube is inserted into Cubetable, each cell in the same row for the record is under the same version, i.e the same timestamp. When the record has a special value ALL or * in a dimension, the cell value is set NULL  3.2 Data Cube Construction  Because the closed cube is very efficient in the data compression ratio, we used it to implement the data cube construction  For the input data in files or tables specified by FileInputFormat or TableInputFormat respectively, the system partitions them into data blocks. As shown in Figure 3, every block’s content as a whole is an input value with a unique id. The map function accepts the pairs and computes every local data cube by calling DFS function \(see DFS definition in [9 T h e cells are stored in a local data cube closedCells. Finally the closedCells identified by a blockid are output and stored in the GFS/Bigtable. The CubingReduce does nothing except only outputting the closed cube   Figure 3. The pseudocode of the cubing interface  The data cube is locally constructed. As the id keys of local data cubes are small and unique, the subsequently partitioning merging of these keys produces little communication overhead and little data swap between nodes We conducted the experiments for the data cube construction in an 18-node PC cluster with total 36 cores, 18 GB RAM, 540GB disk volumes. Although the cluster is not large, but it is easy to add more nodes \(say reach 100 -1000 cores and 1 terabyte disk volume\ince it is share nothing For a fact table with 60 million rows \(stored in text file with the size 1.37G\e data cubes are constructed in less than 5 minutes and output the 2.98G file spread over 18 nodes. Even when the number of rows reaches 100 million, the construction time is about 7 minutes The speedup is almost linear within at least 36 cores For high dimensions, say the fact table with 12 dimensions and 20 million rows, the construction time is only 273 seconds  3.3 OLAP Query  The same query is sent to every data node. The parallel query task includes the QueryMap class and the QueryReduce class. As shown in Firgure 4, the \(blockid closedcells\air from files/tables is the input of the map  V 21  dimension2:level1 001\001   V 1  data cube1  dimension1    dimension2:level2 001\001   V 22  t 1  V 21 003    t 1 t 1 t 2 data cube1 Class CubingMap local variable closedCells map\(InputKey blockid, InputValue blockdata 1. cl = \(ALL, …, ALL 2. call DFS\(cl, blockdata, 0\enerating and collecting the closed cells 3 emit\(blockid closedCells 
201 
201 


function. The query strings are stored in a file which can be accessed by all map functions. Then the map function searches every queried cell in its local data cube and emits a \(cell, msr\ntermediate key/value pair These intermediate pairs are partitioned by the key, i.e the name of cell, so the measures are grouped by cells Finally, the measures for a cell are reduced to one measure by applying the aggregate function \(e.g. sum   Figure 4. The pseudocode of the querying interface  Even though the OLAP query involves in each node the result sets are small. Thus the partitioning merging for the results causes little communication For the fact table with 60 million rows, the 1,000 point queries answering time is only 203 seconds \(the experimental environment is the same as the data cube construction environment\ point query answering time is 0.2 seconds in average. Also the time approaches linear speedup when the number of nodes increases from 5 to 17  3.4 The Code Base  We implemented our system based on Hadoop [1   Hadoop is a software platform that allows one to easily write and run parallel or distributed applications that process vast amounts of data. It incorporates features similar to those of the Google File System and of MapReduce. Hadoop also includes HBase which is a column-oriented store model like Bigtable Although Hadoop is implemented in Java, the map and reduce computation tasks were all coded in C because of the efficiency of C++. The C++ program communicates with Hadoop thro ugh Ha doop Streaming   4. Conclusions  HDW aims at building a large scale data warehouse that accommodates terabytes data atop inexpensive PC clusters with thousands of nodes. As the limited experimental condition, at present we demonstrated it on only 18 nodes with 36 cores. But in view of Hadoop’s successfully sorting 20 terabytes on a 2000-node cluster within 2.5 hours w e bel i e v e t h at  HDW has the same potential ability which will be proved in the next step. The data extraction transformation and loading \(ETL\ill be considered to incorporate into HDW   References  1 Da v i d J. De W itt, Sa m u e l Ma dde n Mic h a e l  S t o n e b ra k e r   How to Build a High-Performance Data Warehouse. http db.lcs.mit.edu/madden/high_perf.pdf  M i c h ael S t on eb raker et al   C-S t o r e A Co l u m n Ori e n t e d  DBMS. In proceedings of VLDB, 2005 3 Sa nja y  G h em aw a t H o w a r d  G obi of f  ShunT a k L e ung T h e  Google file system. In 19th Symposium on Operating Systems Principles, 2003  F a y Ch an g Je f f r e y  Dean  S a n j a y  G h e m a w at et al  Bi gt ab l e   A Distributed Storage System for Structured Data. In 7th Symposium on Operating System Design and Implementation 2006  Jef f r e y De an  S a n j ay  G h e m a w at  M a p R ed u ce S i m p l i f i e d  Data Processing on Large Clusters. In Symposium on Operating Systems Design and Implementation, 2004 6 P A ND A   http pr o je c t s.c s da l  c a  pa nda   7 Y i ng C h e n Fr a n k D e hne  T odd Ea v i s e t a l  P a r a lle l  ROLAP Data Cube Construction on Shared-Nothing Multiprocessors. Distributed and Parallel Databases, 2004 8 F r an k Dehn e T o dd E a vi s, A n d r ew R a u C h ap l i n  Th e  cgmCUBE project: Optimizing parallel data cube generation for ROLAP. Distributed and Parallel Databases, 2006  L a ks V  S  L a ksh m an an  Ji an P e i  Y a n Z h ao  QCT r ees  A n  Efficient Summary Structure for Semantic OLAP. SIGMOD 2003 10 Sa nja y  G o il, A l ok C houd ha r y H i g h pe r f or m a nc e OLA P  and data mining on parallel computers. Journal of Data Mining and Knowledge Discovery, 1\(4\:391–417, 1997 11 Sa nja y  G o il, A l ok Cho u dha ry A pa ra lle l sc a l a b le  infrastructure for OLAP and data mining. In Proc International Data Engineerin g and Applications Symposium IDEAS’99\, Montreal, 1999 12 R a y m ond T  N g A l a n W a g n e r Y u Y i n I c e b e r g c ube  Computation with PC Clusters. SIGMOD, 2001 13  A p a c h e o r g  Ha do op htt p l uc e n e  a p a c h e  or g  ha do op  Class QueryMap map\(InputKey blockid, InputValue closedcells 1. get queried cells from a file 2. for each cell in queried cells 3. msr = query\(cell, closedcells\ //query cell in closedcells 4.  emit\(cell, msr Class QueryReduce reduce\(InputKey cell, InputValue msrlist 1. result = 0 2. for each msr in msrlist 3.   result += msr 4. emit  cell  result   
202 
202 


R k max X i A k 2   X i G 001\031 k    002 Formula 3-2 002  And then  establish adjacent table for each thickness grid, records  all its adjacent grid, and used markers  to  mark the  dense grid  for use  after Computing  the distance of the two grid center d ij 2 001  p k jk ik x x 1 2          002 Formula 3-3 002  Judge  whether  the two grid  are the  dense grids is base in take  A i A j 2 003\004 cen   and d\(G i d\(G j   003\004 den 002 in here 004 cen R i R j 002 0.75 002  004 den min{ d\(G i  002 d\(G j 0.2: If the conditions are met dense grid then merge  the  two densely populated block After the merger, computing the center A k   and the radius R k of the new densely populated block       A k          j i j j i i G d G d G d A G d A       002 Formula 3-4 002  R k max{R i 002 R j  2   2 j i A A      002 Formula 3-5 002  Record the new value of the A k  and R k  Its algorithm processes are as follows 0017 Start 0018 Read the value of A k R k D\(G k  0019 If A i A j 2 003\004 cen and d\(G i d\(G j   003\004 den    then Merger them, and then computing the value of the ne w A k R k D \(G k  001 Record the value of new A k R k D\(G k  002  001 End Determine whether it is necessary to improve the form clusters by use of computing the distance between some  data point  X i and the center A k of densely populated blocks X i A k 2 003\004 dis  002 004 dis    8.0 k k G d R 002 If the requirements are met absorbing this point and every point X i  absorption by adding a dense grid currently adjust   the statistical information of the grid in time Th e formula for computing the new centre and the radius  are as follows A k  1       k i k k G d X A G d           002 Formula 3-6 002  R k max{R k 002 X i A k 2      002 Formula 3-7 002  Its algorithm processes are as follows 0017 Start 0018 Read in x i A k R k D\(G k  002  0019  If X i A k 2 003  004 dis   then  Merger them  and then computing the value of the new A k R k D \(G k  001 Record the value of new A k R k D\(G k  002  001 End Considering the close distance and the location of point,also the shape and size of cluster data and o ther factors Calculations, if D j R j 002  set the value by  005 1 0.5 003 1\0131 002 R j D j 003°\003 1 002 1 002 R j D j 003 0131  if R j D j 2R 002 set the value by  005 2 0.5 002 1 002 D j 013R j  006 2R j  002  if D j 2R j 002 set the value by  005 3 0.5 002 1 002 exp\(D j 013R j  001    Each receives a new data it is necessary to calculate it in the membership function mapping the  value of membership and in accordance with its 004  attribution determine the cluster’s ownership If membership values exceeds a given threshold 004 is that the data belongs to the corresponding cluster at t he same time to amend the statistical information of t he cluster When the point of all membership values have not achieved 004 record it into the grid information table, as isolated existence Timing scanning the grid information table found a spot on the grid cluster  concentration more than the minimum concentration requirements we generate a new cluster the cluste r record in the table registration relevant statisti cal information. Its algorithm processes are as follows   0017 Read in x j A k R k D\(G k   0018 Computing the distance D j  between  x j  and Clustering centre  0019 If  D j R j 002 then computing the value of m 1 002 goto  001   001 If D j R j   and D j 2R j 002 then computing the value of m 2   goto  001   001 Computing the value of m 3   001 If 005  004 002 then computing the value of  A k R k D\(G k   001 Record them into  grid information table in isolation, or as a new cluster  001 The end 4  Test results and analysis  According to the Guangzhou University of Traditional Chinese Medicine Research Group to provide the clinical cases the paper of the lung card category of simulation experiments using Visual C    6.0 as a development platform, and to establish the network diagnosis model Choose six of a total of 180 cases of card sample data for clinical samples Each sample consisted of  chest pain, chest tightness, cough, Tan Zhi, sputum less Jiubuyushi long have asthma or shortness of breath  and other symptoms of information 33 Sample data 
80 


permit classification as follows: 26 cases of lung cold beam, the cold drink in 30 cases, table 34 cases of cold heat heat Obstructing evil pulmonary 30 cases 28 cases of lung phlegm Yun, 32 cases of lung Tanreqin g Yu For six cards each for 10 cases of data as a traini ng sample of 120 patients with final data for testing  First data on 180 cases of normalized data processing the value of all the data transformatio n between [0,1   60 cases of training samples were divided into 28 groups produce  28 cluster centers including the threshold 007   0.3 It means that the hidden nodes desirable 28 Requirements for the experimental results were divided into six categories, set six output nodes Output 1,0,0,0,0,0 0,1,0,0,0,0 0,0,1,0,0,0 0,0,0  1,0,0 0,0,0,0,1,0 0,0,0,0,0,1 were identified that s ection 1,2,3,4,5, Category 6, so  the construction of netw ork structure is 33-28-6 Procedures use the follow rule for the output of th e network the output node with 6 dimension choose it s maximum value and then set 1 to it the other five  output set value to 0. Error use 2 1 1  2 N k k E e   001 N is the number of samples the program settings  when error  or the number of training are  more than 10,000 ,en d  the training, that is the end of the proceedings Experimental operating results  as shown in table 2. When the training times reach to 3935, errors E 0 procedural convergence verified  120 samples  and  the recognition rate was 92 and operating time for  two seconds From the results  after the clustering algorithm embed into the model, it can effectively search for the importation sample data  The clustering algorithm  can quickly cluster data for the high-dimension and big date Therefore the clustering algorithm  has a fa st convergence and a stronger ability to identify al so a stronger generalization ability, and other characte ristics It has  achieved the desired objectives Table 2   Asthma" dialectical test results Annotations: TN is the number of training  samples 002 TT is training times 002 HNN is the number of hidden nodes 002 Cer is convergence error 002 TSN is the number of testing samples 002 RR is recognition rate ; RT is running time\(second  5  Conclusion This paper mainly aimed at the characteristics that  the data type of tongue diagnosis system of TCM is diverse and the data volume is extremely huge and applied the algorithm integration with  the process of grid clustering and the thought of rough set An improvement of grid-based on fuzzy clustering algorithm was used in the data mining of the tongue  diagnosis of TCM This fuzzy clustering algorithm through acceleration the process of clustering tole rated the noise data so it  overcame shortcomings of expensive time-consuming in the traditional fuzzy clustering algorithm.The clustering mechanisms of combination of software and hardware were to overcome their own insufficient, making the process of enhancing the clustering accuracy and flexibility The algorithm was used in the tongue diagnosis system o f TCM so that the reasoning of the learning process could quickly and accurately obtain useful informat ion timely search the database of experience diagnosis  The algorithm was easy to adapt to different issues and environmental requirements and improved the diagnostic accuracy rate and speed  R eferences  1  Shao Feng-jing,Yu zhong-qing. Data Mining and Algorithm. China Water Conservancy and Hydropower P ress a ~ 271 ~ 30,197 2  J i a n g  W e i   c l u s t e r i n g  a l g o r i t h m  b a s e d  o n  t h e  r e search and application of. Master's degree thesis, Liaoning En gineering Technology University. 2004.2: 8 3  Zhexue Huang  Extensions To the K-Means Algorithm for Clustering Large Data Sets with Categorical Val ues. Data Mining and Knowledge Discovery 2 002 1998 002 283 003\032 304 002  4 J i a n n  X i a o y i 002  Karin Abennlen 002 Horst Bunke 002 Dynamic computation of generalized median strings 002 Pattern Anal 000\003 Application 002 2003,\(6 002 185 002  5  P a n  Y u q i   a n d  o t h e r s   F u z z y  c l u s t e r i n g  b a s e d  o n the analysis of the data retrieval application  Microel ectronics and Computer. 2005,22 \(6\: 167 ~ 172 6  G u  J u n h u a   e t c   F u z z y  c l u s t e r i n g  m e t h o d s  i n  t h e analysis of DNA sequence classification of. Computer simulat ion 2005,10:108 to 111 TN  TT HNN  Cer  TSN  RR RT  60  3935  28 0 120 92  2 
81 


 6 In Case 1.2, the modulation automatically adapts to the current SNR which significantly reduced the packet losses. In fact, 1.05% of packet losses all occurred during the mode change. If the packet losses that occurred during the mode change are eliminated \(requiring a minor software fix 0 In Case 1.3, DM was disabled and ARQ was enabled instead. Despite ARQ\222s retransmission attempts \(up to 7 7% of packets were lost. This demonstrates that during long fades, even 7 retransmissions were not enough to save those 7% of packets. The average latency of 951 msec indicates each packet is retransmitted about 1.3 times on average Note that the propagation delay is 250 msec and each retransmission adds 550 msec to the latency since the retransmission interval is 550 msec. Therefore, the average number of retransmissions is roughly estimated as \(951250\550 002 1.3. The maximum latency reflects the maximum number of retransmissions plus processing time and queuing delays. Compared to Case 1.1, the ARQ scheme reduced the PLR by about 50% at the cost of increased latency In Case 1.4, both DM and ARQ were enabled. Most of the packets made it through the fading channel, and the small number of packets dropped during the mode change was recovered by ARQ, which resulted in zero PLR. The increases in the average and maximum latencies compared to those from Cases 1.1 and 1.2 were due to retransmission of lost packets during the mode change In Cases 2.1 through 2.4, the channel fluctuated much faster than in the previous cases. Case 2.1 lost about 11% of packets, which is comparable to case 1.1 In Case 2.2, despite the DM scheme, about 9% of packets were lost. This was because it took some time for the DM scheme to measure the current SNR and determine a new modulation until the new modula tion was in effect, which took at least one round-trip time \(500 msec\Therefore, DM was not able to keep up with the channel In both cases 2.3 and 2.4, the ARQ scheme effectively recovered all of the lost packets caused by channel fades Case 2.4 achieved smaller latencies with the help of DM RxRate in Case 2.4 \(0.94 Mbps\urned out to be less than expected and thus needs further investigation Performance Evaluation with Real-Time Video Streaming In this scenario, cross-laye r performance of DM, ARQ, and ACA techniques is evaluated using a real-time streaming video application. The configuration presented in Figure 2 was used in this emulation. A VLC application running at VIDEO SERVER transmits an MPEG4-encoded video stream at the rate of 875 kbps to another VLC application running at VIDEO CLIENT via SALEM2, DELAY STRETCH, and SALEM1 nodes in sequence. A VLC application at VIDEO CLIENT displays the incoming video together with MPEG frame statistics. Note that in this emulation, the SNR was manually lowered to a certain level to emulate a channel fade Table 3 shows the test results from various cases. Each case was defined by a combination of DM, ARQ, and ACA options and an SNR value. The data rate in the table indicates the measured data rate by VIDEO CLIENT. VQI ranges between 0 and 100. The higher the VQI value, the better the quality of the video. In the following discussion, a frame refers to an MPEG frame, not a link-layer frame Initially, SNR was set to 36 dB and modulation was set to 16 QAM. Case 3.1 shows the result with the initial setup Since no frames were lost in this case, the result indicates the best-case scenario, as captured in Figure 11 \(a In Case 3.2, the noise level was increased to make SNR=18.1 dB and DM was not yet enabled. Since DM was not enabled, the modulation remained at 16 QAM, which caused more than 50% of the pack ets to be lost, as the data rate of 344 kbps and the frame rate of 10 fps indicate. The Table 2. Test Results with N2X Case ID Channel Fade DM ARQ PLR  RxRate Mbps Avg. Lat msec Max. Lat msec 1.1 Long OFF OFF 14.07 0.83 252 253 1.2 Long ON OFF 1.05 0.99 253 255 1.3 Long OFF ON 7.05 0.91 951 5568 1.4 Long ON ON 0 1.0 328 1317 2.1 Short OFF OFF 11.27 0.84 252 253 2.2 Short ON OFF 8.83 0.82 253 255 2.3 Short OFF ON 0 0.98 1528 3506 2.4 Short ON ON 0 0.94 1188 3144 Table 3. Test Results with Real-Time Streaming Video Case ID DM ARQ ACA SNR Modulation Data Rate Kbps Frame Rate FPS Avg. Frame Size \(Byte VQI Case 3.1 OFF OFF OFF 36 dB 16 QAM 873 31.2 2661 100 Case 3.2 OFF OFF OFF 18.1 dB 16 QAM 344 10.0 2126 45.4 Case 3.3 ON OFF OFF 18.1 dB QPSK 580 19.8 2144 51.9 Case 3.4 ON OFF ON 18.1 dB QPSK 579 29.9 1349 89.4 Case 3.5 ON ON ON 18.1 dB QPSK 628 33.6 1448 99.8 


 7 VQI dropped down to 45.4 and th e video was unintelligible as captured in Figure 11 \(b Case 3.3 enabled DM, and thus the modulation was switched to QPSK. In this case, since QPSK is more robust even with an SNR level of 18 1 dB, more packets survived as indicated by the data rate of 580 kbps and the frame rate of 19.8 fps. However, now the bandwidth of the channel was reduced by 50% and thus a lot of packets were still dropped, resulting in video quality that was still very poor This is indicated by a VQI of 51.9 and the screen capture in Figure 11 \(c Therefore, in Case 3.4, the application codec was commanded to reduce the data rate by half, which is reflected in the average frame size shortened by half. The VQI then significantly improved to 89.4 as well as the quality of the video, as shown in Figure 11 \(d\me packets were still lost, however, due to imperfect channel conditions and thus we turned on ARQ in Case 3.5 ARQ\222s retransmission mechanis m adds more packets onto the channel upon packet losses and thus we doubled the channel bandwidth without changing the modulation in Case 3.5. According to Table 3, the data rate and the frame rate in Case 3.5 are about 10% larger than those from Case     b c   d e Figure 11 226 Screen Captures from VLC CLIENT a  


 8 3.4, which reflects ARQ\222s recove ry of lost packets. Average frame size indicates that the a pplication codec generates the same streaming rate. The VQI improved to almost 100 and the quality of the video was also almost perfect, as shown in Figure 11 \(e\e that Case 3.1 captured better video quality than did Case 3.5 even though their VQI values are almost the same. This is because in Case 3.5 the video was generated in a lower resolution mode to achieve a lower data rate, which is reflected in the smaller average frame size in Case 3.5  In the emulation scenario with real-time video streaming, a combination of all three mitigation techniques significantly improved the quality of a streaming video over a certain noise level 4  C ONCLUSION  In this paper, we introduced a real-time emulation test bed by integrating STRETCH and SALEM, both of which are unique capabilities developed in-house at The Aerospace Corporation. Using this test bed, various combinations of three mitigation techniques DM, ACA, and ARQ were applied to a stream of raw UDP packets and a real-time streaming video. The test results demonstrate that a combination of DM and ACA works well with long durations of channel fades However, for a fading channel of short duration, the DM and ACA requiring SNR measurements do not adapt fast enough to mitigate the impairments. ARQ, however, works well in this scenario when lost frames can be retransmitted. In the real-time streaming video test, the combination of all three techniques achieved the best performance R EFERENCES   E Grayver and P Dafesh, \223Multi-Modulation Programmable Transceiver System with Turbo Coding,\224 IEEE Aerospace, Big Sky, MT, 2005   E M c Donal d R Speel m a n, E. Gray ver,  and N. W a gner 223Real-Time Hardware/Softw are Approach to Phase Noise Emulation,\224 IEEE Aerospace, Big Sky, MT, 2006  J. Kim  J. Hant, and V. Swam inathan 223Real-Tim e Emulation of Internet Applications over Satellite Links Using the SAtellite Link EMulator \(SALEM\AIAA San Diego, CA, 2008   VideoLAN- VLC m e dia play er, http://www.videolan.org   E Gray ver, J. C h en, and A. Ut t e r, \223Appl i cat i on-l a y e r Codec Adaptation for Dynamic Bandwidth Resource Allocation,\224 IEEE Aerospace, Big Sky, MT, 2008 B IOGRAPHY  Dr. Eugene Grayver received a BS degree in electrical engineering from Caltech and a PhD degree from UCLA in 2000. He was one of the founding team of a fabless semiconductor company working on low-power ASICs for multi-antenna 3G mobile receivers.  In 2003 he joined The Aerospace Corporation, wher e he is currently working on flexible communications pl atforms.  His research interests include reconfigurable implementations of digital signal processing algorithms, adaptive computing, lowpower VLSI circuits for communications, and system design of wireless data communication systems. Lately, he has been concentrating on the interaction between nonlinear amplifiers and modern error correction codes.  He is also participating in the software-defined radio community trying to define a common configuration standard and determine optimal partitioning between software and hardware  Dr. Joseph Kim received a BS degree in computer science from Seoul National University, Korea, and a PhD degree in electrical & computer engineering from University of California, Irvine in 1988 and 1998, respectively. He joined The Aerospace Corporation in July 2005 His current responsibilities incl ude architecture, design development, and integration of SAtellite Link EMulator SALEM\advanced space communication and networking pr otocols and applications under various satellite channels with interference. He has been supporting the Transformational Satellite Communications System \(TSAT\he Global Positioning System III programs. Prior to joining The Aerospace Corporation, he wo rked for several companies including several start-ups. The areas of work included HomePNA, HomePlug, WiFi, WiBro, ATM, CDMA2000 Satellite Digital Multimedia Broadcasting \(DMB\eoon-Demand \(VOD Service \(QoS\DVD/VCD Encoder/Decoder, MPEG, real-time scheduling and resource allocation, etc  Dr. Jiayu Chen received his BS degree in electrical engin eering from National Taiwan University in 1981. He received his MS and PhD degrees, both in electrical engineering from the University of Southern California USC\in 1983 and 1986, respectively He joined The Aerospace Cor poration in July 2005. His responsibilities include various satellite communication networking areas such as network protocols, QoS resource management, routing, etc. Prior to joining The Aerospace  


 9 Corporation, he worked for AT&T Labs \(formerly AT&T Bell Labs\for 19 years as a Senior Technical Specialist. He played an important role in the transformation of the AT&T telephony network including dynamic routing evolution and circuit switching to packet switching transition. His work included voice over IP \(VoIP\network architecture dynamic routing, numbering planning, network integration and testing. He received nine US patents as a result of his work at AT&T Labs. At USC, his research area included optical and radar target detection and medical applications of robotics  Dr. Eric McDonald received his BS degree in electrical engineering from the University of Pittsburgh in 1998, where he studied VLSI design. He continued his education at Cornell University and received his PhD in electrical and computer engineering in 2004. He focused on methods for synthesizing low-power analog circuits using floating-gate transistors while also gaining a breadth of knowledge in networking as well as asynchronous and synchronous digital design. He joined The Aerospace Corporation\222 s Digital Communication Implementation Department in November 2005 Alex Utter received a BSE degree from Harvey Mudd College in 2005, and an MS degree in electrical engineering from Stanford University in 2007. He joined The Aerospace Corporation in 2007.  His areas of expertise include software and hard ware design for digital electronic systems, especially design of FPGA- and microprocessor-based systems Dr. James Hant received a BS degree in biomedical engineering from the University of California, at San Diego \(UCSD\in 1993 and MS and PhD degrees in electrical engineering from the University of California, Los Angeles UCLA\in 1996 and 2000 respectively. From June 2000 to June 2001, he was a Systems Software Engineer at Conexant Systems in Newport B each, CA, designing and implementing speech recogniti on software for internet applications. He joined the Aerospace Corporation in June 2001, where he has worked on the simulation, modeling and design of satellite communication systems. Dr. Hant\222s research interests include networking, satellite payload design, and speech signal processing David Kun received his B.S. and M.S degrees in electrical engineering from the University of Minnesota-Twin Cities and the University of Illinois at UrbanaChampaign, respectively. Prior to joining The Aerospace Corporation in 2006, he worked as a system engineer and later as a design/test engineer for Northrop Grumman Space Technology. His research interests include signal detection and estimation theory, FPGA hardware prototyping of digital signal processing algorithms, and software defined radios    All trademarks, service mark s, and trade names are the property of their respective owners  


SPARQL query discussed in more detail in Section 6 has retrieved the SEAS Plane model information for a particular F-15 instance gure  Mvlititary Asset utnology A number of other military ontologies also exist The MilOrg ondology describes military and related political organizations as well as particular Roles they play in military affairs Tasks they are required to perform and specialized military Actions that perform them MilGeo defines a military perspective on geography with emphasis on terrain polpulation and cultural features of interest to military operations MilGeo contains classes that describe military facilities including Forts Airbases NavalPorts and Forward Operating Locations The MilSit ontology describes Conflicts Campaigns Missions Plans and similar concepts It also defines exactly what constitutes a situation and classifies various types of situations Specialized ontologies relating to military information and communications exist and may be imported in some cases to provide increased detail for those concerns Finally to support military Modeling and Simulation applications the MilSim ontology provides a platform for importing relevant ontologies for a particular study or exercise and a location to create concepts peculiar to individual simulations 10 


impodt Top Leve M d Ile Level Dom1ain Lave i 1po Scenwd1o Level Figure 8 Ilium Ontology Suite typical It is possible and in fact common to employ only a few of these ontologies in particular studies For example many studies are only concerned with physical platforms and therefore only need the MilAsset ontology which imports IlumAsset IliumFramework and DUL Figure 8 illustrates the existing Ilium Ontology Suite and a typical import pattern for a complex Modeling and Simulation application scenario Currently the illustrated suite less Millnfo MilComm and UAV defines 1240 OWL Classes 274 OWL Object Properties and 188 OWL Datatype Properties 6 AN EXAMPLE APPLICATION We are currently using the described approach to conduct systems requirements and other engineering analyses for military aerospace systems In these investigations it is useful to consider detailed aspects of the system design or software prototype behavior in the context of large scale network-centric military operations In the past year in particular we have assembled a collection of well known and widely accepted military simulations to prepare for an extensive investigation of requirements for autonomy in unmanned military platforms It is believed that useful insights in the study will be sensitive to important details of system behavior supporting sensor platform and communications technologies as well as the combined effects of these technologies on an advanced highly networked military force Thus the study environment must provide a means to reliably model and evaluate significant technical detail and to measure the effects as well as propagation of those effects throughout a broad operational context 11 


I r Z  Figure 9 A Military Modeling and Simulation Configuration of the Ilium Framework To do that we have assembled a collection of trusted military simulations that span the range of such applications from fine-grained simulations that focus on detailed interactions between two entities to coarse-grained simulations of military campaigns Figure 9 illustrates the Ilium Framework configured to accommodate those simulations as well as representative prototype systems In this case the legacy applications are simulations analysis systems and design tools Prototypes are notional UAV autopilots route planners decision support systems and similar applications The Framework augments these applications with control objects and agents that coordinate computations in the composed system and specialize agents that typically represent the characteristics of a new system or technology that cannot be easily or adequately simulated in any of the component legacy systems In our current study the following systems have Ilium Framework plugins and are used as components in the study environment 12 Al f<cOmmi.ain FIa 1A  


THUNDER is a campaign simulation that models national military forces and military operations that extend over months 30  Characteristics of individual systems are evaluated statistically and their effects on the overall campaign are not explicitly known Political social and cultural objects and concepts are not included in the model In this configuration THUNDER is used to generate force level tasking mission orders and to evaluate and adjust for the results of missions with respect to campaign plans SEAS is a force level simulation that simulates battles between major forces in combat operations that typically last for hours and as much as a day SEAS features a flexible rules based decision logic that can influence behavior at both the commander and individual combatant level SEAS executes the missions requested by THUNDER and provides a manageable dynamic context for examining the behavior of prototypes in a range of typical operational situations  31 A dynamic plug-in supports interaction with the Framework and other pugged-in components EADSIM is a trusted model of air defense systems that is in particular sensitive to many important design attributes of individual systems In certain modified forms it can reference advanced sensor and engagement decision models In our study configuration EADSIM simulates enemy air defenses in selected e.g significant to our investigation portions of the virtual battle A dynamic plug-in supports system control as well as interaction with the Framework and other pugged-in components A prototype aircraft mission planning system plug-in supports virtual real time mission plan creation and updates In particular the system provides automatic route planning for selected platforms that have been assigned missions by THUNDER and that are subsequently executed in simulation in SEAS and EADSIM The Ilium Framework itself provides software agents that are used to model notional or experimental UAV characteristics and behaviors Depending on the objectives of a particular study the Framework may also provide agents that address advanced Command and Control concepts to coordinate the interaction of the various component systems We maintain a semantic consistency among the plugged-in component applications by developing a single operational scenario as initial input for a study and deriving the necessary application configuration data from that source We create an RDF model of the scenario based on the Ilium suite of ontologies that includes political context issues objectives sensitivities etc military context centers of gravity campaign objectives etc geophysical environment military units order of battle unit equipment lists etc command and control assets platforms weapons ISR systems etc Figure 11 below is an excerpt from an operational scenario set in the Southwest U.S depicting a description of an Air Force Wing assigned to a notional Joint Task Force The Wing is based at Bishop Air Base and has six Fighter Squadrons assigned to it Additional detail about each of those squadrons as well as the base is found in the model in this case an rdf:resource  associated with it morg:AirForceWing rdf:ID="USAF_366 Air_Exp Wg dc:creator>Doug Holmes</dc:creator mgeo:basedAt rdf:resource="#BishopAB geo:positionedAt rdf:resource="#BishopAB_pos morg:assignedOrg rdf:resource="#USAF 390_Ftr_Sq morg:assignedOrg rdf:resource="#USAF_494_Ftr_Sq dc date I 0/20/07</dc date morg:assignedOrg rdf:resource="#USAF_496 Ftr_Sq rdfs:comment>366 AEW F-22 F-15 KC-135 130]</rdfs:comment morg:assignedOrg rdf:resource="#USAF 389_Ftr_Sq morg:assignedOrg rdf:resource="#USAF 391 Ftr_Sq morg:assignedOrg rdf:resource="#USAF 495_Ftr_Sq rdfs:label>366 Air Expeditionary Wing</rdfs:label morg:AirForceWing ab9 7P.b ii uI1 L L CFigure 11 An RDF model of a notional USAF Wing Figure 12 is another excerpt from the same scenario illustrating a model of a particular Fighter Squadron and one of the F-15E aircraft it operates Figure 10 Legacy Components in the Ilium Framework 13 suka 


morg:AirliorceSquadron rd:lD U SAF _8 htr Sq rdfs:label>8th Fighter Squadron</rdfs:label geo:positionedAt rdf:resource="#GeorgeAB_pos msim:hasSeasModel rdf:resource="#BAFGA mast:hasModel rdf:resource="#BAFGA rdfs:comment>An F15E Squadron</rdfs:comment dc:date>9/26/07</dc:date dc:creator>Doug Holmes</dc:creator mgeo:basedAt rdf:resource="#GeorgeAB morg:AirForceSquadron F1 5E rdf:ID="F1 5E 05 dul:isReferenceOfRealization rdf:resource="#AirObj ect_2007 mast:equipment-of rdf:resource="#USAF 7 Ftr_Sq dc:creator>Doug Hollmes</dc:creator dc:date>9/26/07</dc:date msim:hasSeasPlane rdf:resource="#F15E mgeo:basedAt rdf:resource="#GeorgeAB geo:positionedAt rdf:resource="#GeorgeAB-pos rdfs:label>F-15E 005</rdfs:label F-15E Figure 12 An RDF model of a Fighter Squadron and one of its aircraft Note that these models also have associated SEAS models that contain information peculiar to the SEAS simulation about these entities This information is used to configure SEAS to properly represent these particular entities We are also able to insert objects and information that may be of interest in our study that is not represented in any of the component simulations or other applications Where those objects are related to an object that is simulated that relationship permits inferences about the effects on them as a result of actions that are computed in a simulation For example it is possible to indicate that GeorgeAB defends the capital city and lend special significance to the actions of aircraft that are based there even though none of the simulations in the composite system have any notion of capital city Finally the operational scenario provides an explicit record of the assumptions that underly the study and can also include and explicit representation of system and study goals This practice improves analysis and may enable future knowledge based analytical tools Throughout the process of constructing the operational scenario and when it is complete we use one or more Description Logic Reasoners to ensure the logical consistency of the the model A number of these automatic theorem provers are freely available including Pellet 32 33 FaCT  34 and OWLIM 35 are used in the Framework to compute logical entailments and to complete RDF models as well as to ensure the consistency of models In the later capacity frequent checks will identify errors in the construction some e.g Pellet also indicate the source of the error and aid in repairing it As a result we are confident that the operational scenario is a sound model The primary use of the Reasoners allows us to significantly extend the explicit RDF model that is created For example a squadron is explicitly specified as assignedTo a wing and that relationship is the inverse of assignedOrg then the system can infer that the wing has the squadron as an assigned organization even though that fact has never been asserted Similarly if the same relationship is defined as a transitive relationship it is possible to infer that a flight that is assigned to the squadron is also assigned to the wing Once we have an operational scenario that has been classified by a Reasoner we then use the completed model to configure the composite system Ilium and the pluggedin systems to execute the simulation We use SPARQL a W3C standard query language designed to access RDFL to extract data from the scenario to create the input files needed to configure the various applications.[36 SELECT name pos long lat alt vis W1HLERE name rdf:type mast SeasLocation name geo:positionedAt pos pos pos:long long pos pos:lat lat pos pos:alt alt name msim:Visible vis  Figure 13 A typical SPARQL query In a similar fashion SPARQL is used to extract data from the scenario to create the necessary Ilium java surrogate control and agents SPARQL can also be used to review the scenario and answer questions that have arisen since the inception of the study At this point we are able execute the scenario with confidence that it will produce reliable results 7 CONCLUSIONS We have developed a methodology and supporting tools for creating an operational scenario that supports the semantic interoperability of an ad hoc collection of legacy applications and extends their capabilities The method depends on and ensures the logical integrity of the composite system Therefore when we assemble as a collection of legacy component systems that were not originally intended to interoperate with other systems we can be confidant that the composite system will produce consistent results Logical consistency implies that to the degree that we trust the interpretation underlying the model the results of operations on the model are trustworthy If for example the model is based on a Newtonian interpretation of physics the model ought to provide reliable answers to questions about automotive and even aeronautical engineering but probably not to all questions in astronomy or cosmology This methodology extends the utility of trusted simulations allowing integration of finegrained simulations that are sensitive to design requirements with high level coarse-grained simulations that are sensitive to acquisition issues and policy The potential benefits of 14 


this sort of interoperation may range from obvious production efficiencies to clearer insights into system requirements Finally an important side-effect of the approach is the OWL/RDF knowledge base formed by the combination of the operational scenario and the results of the operations of the legacy systems That knowledge base and the use of SPARQL queries and SWRL rules effectively expands the functionality of the system and greatly improves the analysis of the output of the system of cooperating simulations and tools We have prepared a foundation for the application of Semantic Web and other knowledge based tools in the analysis and design of unmanned systems We anticipate the development and application of these tools and the addition of autonomy directed Multiple Agent Systems MAS that use RDF/XML inter-agent communications in the coming year REFERENCES 1 NAFCAM 2001 Exploiting EManufacturing:Ineroperability of Software Systems Used by U.S Manufacturers available at 12 Protege Ontology Editor documentation available at http proteae.stanf6rd.edu 13 Top Braid Composer Datasheet available at 14 W and Nicola Guarino 2001 Support for Ontological Analysis of Taxonomic Relationships J Data and Knowled 39\(1 October 2001 15 Natalya F Noy and Deborah L McGuinness Ontology Development 10 1 A Guide to Creating Your First Ontology  Stanford University Stanford CA 94305 16 Alan Rector Modularisation of Domain Ontologies Implemented in Description Logics and related formalisms including OWL K-CAP'03 October 23-25 2003 Sanibel Island Florida USA pp 121-8 2003 17 Cyc Homepage available at htc.c 18 Open Cyc home page available at 19 SUMO Description and Home Page available at 19 SENSUS Description and Home Page available at 2 Bemers-Lee Tim Hendler Jim Lasilla Ora The Semantic Web Scientific American available at 20 DOLCE A Descriptive Ontology for Linguistic and Cognitive Engineering ontology and documents available at 3 Bemers-Lee Tim Blog on Design Issues available at 4 RDF Primer available at s chema/#ref-rdf-primer 5 Lacey Lee OWL Representing Information Using the Web Ontology Language Trafford Publishing 2005 6 OWL Web Ontology Language Guide available at Jten pHomewPage availal adt 7 Jena Home Page available at 8 Protege Home Page available at h1ttp  protegest nftanford.edu,X 1 9 Baader Calvanese McGuiness Nardi and PatelSchnieder Description Logic Handbook 10 Oberle Daniel Semantic Management of Middleware Springer 2006 OWL Web Ontology Language Guide available at 21 Nicola Gauarino Claudio Masolo Stefano Borgo Aldo Gangemi and Alessandro Oltramari Ontology Infrastructure for the Semantic Web Wonder World Deliverable DI 8 Laboratory for Applied Ontology Trento Italy 2001 available on line at ht X1t1 22 DUL.owl ontology available at www.1oa23t og DLl 23 Amy Knutilla Steven Polyak Craig Schlenoff Austin Tate Shu Chiun Cheah Steven Ray and Richard Anderson Process Specification Language An Analysis of Existing Representations NIST report available at http llwww.mel.nlist.gov/msid.librarZ/d.oc/psl-1 _.df 24 Process Specification Language Ontology available at http-//www,55,me l.nit gov/psl 25 Ontology for Geography Markup Language GML3.0 owl ontology available at ok i.cae.drexel.edu./-wbs/onltology/2004/09/ogc-gmI1 26 Ontology for Geography Markup Language GML3.0 of Open GIS Consortium OGC Home Page available at 15 


 Peter Maguire Using THUNDER for Campaign Studies DSTO-TN-0303 DSTO Melbourne August 2000 28 User Manual SEAS Version 3.7 U.S Air Force SMC/XR February 2007 29 Bijan Parsia and Evren Sirin Pellet and OWL DL Reasoner MINDSWAP Research Group University of Maryland College Park available at 30 Pellet Home Page available at 31 FaCT Home Page available at 32 OWLIM Home Page available at 3 A SPARQL Tutorial available at BIOGRAPHY Douglas Holmes is co-founder and Senior Partner of Java Professionals Inc In the past twenty-two years he has managed and participated in numerous artificial intelligence and knowledge-based programs for DARPA and other research agencies as well as commercial applications in the petroleum and other sectors He is currently developing ontologies and applying Semantic Web technology to support research and development of military unmanned systems He also has over twenty years experience as an Air Force Fighter Pilot and Fighter Weapons School Instructor Mr Holmes has a B.S in Mathematics and Basic Sciences from the U.S Air Force Academy and a M.S in Management Information Systems from Golden Gate University Richard Stocking is the lead Program Investigator/PM for Net Centric Operations Warfare Analysis efforts for Lockheed Martin Aeronautics Advanced Development Programs The Skunk WorksTM He is currently leading efforts researching autonomous UAV operations Current efforts include the integration of Multiple Agent Systems and other autonomy systems within the Ilium Framework He has over thirty years experience and over 11,000 flight hours with multiple C4ISR systems in the US Army and US Navy Mr Stocking has a M.S in Systems Technology from the Naval Postgraduate School 16 


 17    J. Ta usc h  S. T y son a n d T T a i r ba nks  Multigenerational Radiation Response Trends in SONOSb ased NROM Flash Memories with Neutron Latch-up Mitigation," in NSREC Radiation Effects Workshop Honolulu, 2007, pp. 189-193 9  Semico n du c to r In du str y A s sociatio n SIA  2 008   August\ Home. [Online  www.itrs.net  1  S. Ty s o n P ri v a t e C o m m uni que Tra n sEl  Semiconductor, Albuquerque, NM, 2008 1  T. M i k o l a ji c k  and C U Pi n n o w  2 00 8 N o vem b er Indo-German Winter Academy, 2008, Course 3 Onlin http://www.leb.eei.unierlangen.de/winterakadem ie/2008/courses/course3_ material/futureMemory/Mikolajick_TheFutureofNV M.pdf   BAE System s North Am erica, [Data Sheet Microcircuit, CMOS, 3.3V, NVRAM 8406746, April 28, 2008, Rev A 1  N Ha dda d a n d T Scot t  A da pt i n g C o m m erci al  Electronics to the Natura lly Occurring Radiation Environment," in IEEE Nuclear and Space Radiation Effects Conference Short Course Tucson, 1994, pp iv-14 1  D. R  R o t h a n d et _al S EU a n d TI D Test i n g of t h e Samsung 128 Mbit and the Toshiba 256 Mbit flash memory," in Radiation Effects Data Workshop  Reno, 2000 1  F. I r o m and D N guy e n  S i n gl e E v ent  Ef fe ct  Characterization of High Density Commercial NAND and NOR Nonvolatile Flash Memories Honolulu, 2007 1  C Ha fer M  L a hey a n d et _al R adi a t i o n H a rd ness  Characterization of a 130nm Technology," in Proceedings IEEE Nuclea r and Space Radiation Effects Conference Honolulu, 2007 17  T. R O l dh am J. Fr iend lich  an d et_ a l, "TID  an d SEE Response of an Advanced Samsung 4Gb NAND Flash Memory," , Honolulu, 2007  R. C. Lac o e C MOS Scaling, Desi gn Princi ples a n d Hardening-by-Design Methodologies," in Nuclear and Space Radiation Effects Conference Short Course Notebook Monterey, 1993, pp. II-1 thru II142 1 J. Pat t e rs o n a n d S  Gue rt i n   E m e rgi ng S E F I M o des and SEE Testing for Highly-Scaled NAND FLASH Devices," in Proceedings 2005 Non-Volatile Memory Technology Symposium vol. CD-ROM, Dallas, TX 2005, pp. G-3, Session G ; Paper 3 2 J. Ta usc h  S. T y son a n d T F a i rba nks  Mulitgenerational Radiation Response Trends in SONOSb ased NROM Flash Memories with Neutron Latch-up Mitigation," in Honolulu Radaition Effects Data Workshop, NSREC, 2007, pp. 189-193 2 M Janai  B Ei t a n A Sha p pi r I B l o o m and G  Cohen, "Data Retention Reliability Model of NROM Nonvolatile Memory Products IEEE Transactions on Device and Materials Reliability vol. 4, no. 3, pp 404-415, September 2004 2 D N g uy en a n d F I r o m Tot al Io ni zi n g  Do se \(T ID  Tests on Non-Volatile Memories: Flash and MRAM," in 2007 IEEE Radiation Effects Workshop  vol. 0, Honolulu, 2007, pp. 194-198  G. Noree n  a n d et_al L ow Cost Deep Space Hybrid Optical/RF Communications Architecture," , Big Sky, Montana, 2009, Pre-print 2 T. Sasa da a n d S. I c hi kawa  A p p l i cat i o n o f  Sol i d  State Recorders to Spacecraft," in Proceedings, 54th International Astronautical Cogress Bremen, 2003 2 H Ka nek o  E rr or C o nt r o l C odi ng f o r  Semiconductor Memory Systems in the Space Radiation Environment," in Proceedings, 20th IEEE International Symposium in Defect and Fault Tolerance in VLSI Systems, DFT2005 Monterey 2005 2 T. Sasa da a n d H Ka nek o  D evel o p m e nt an d Evaluation of Test Circuit for Spotty Byte Error Control Codes," in Proceedings, 57th International 


 18  Astronautical Congress Valencia, 2006 27  Bu reau  In tern atio n a l d e s Po ids et Mesures. \(2 008  August\SI Base Units. [On http://www.bipm.org/en/si/base_units   B IOGRAPHY  Author, Karl Strauss, has been employed by the Jet Propulsion Laboratory for over 22 years.  He has been in the Avionics Section from day One.  He is considered JPL\222s memory technology expert with projects ranging from hand-woven core memory \(for another employer\o high capacity solid state designs.  He managed the development of NASA\222s first Solid State Recorder, a DRAM-based 2 Gb design currently in use by the Cassini mission to Satu rn and the Chandra X-Ray observatory in Earth Orbit.  Karl was the founder, and seven-time chair of the IEEE NonVolatile Memory Technology Symposium, NVMTS, deciding that the various symposia conducted until then were too focused on one technology.  Karl is a Senior IEEE member and is active in the Nuclear and Plasma Scie nce Society, the Electron Device Society and the Aerospace Electronic Systems Society Karl is also an active member of SAE Karl thanks his wonderful wife of 28 years, Janet, for raising a spectacular family: three sons, Justin, Jeremy Jonathan.  Karl\222s passion is trains and is developing a model railroad based upon a four-day rail journey across Australia\222s Northern Outback   


 19 Bollobás, B. 2001. Random Graphs. Cambridge University Press; 2nd edition. 500pp  Cawley, G. C., B. L. C. Talbot, G. J. Janacek, and M. W Peck. 2006. Sparse Bayesian Ke rnel Survival Analysis for Modeling the Growth Domain of Microbial Pathogens  Chiang C. L. 1960. A stochastic study of life tables and its applications: I. Probability distribution of the biometric functions. Biometrics, 16:618-635  Cox,  D. R. 1972. Regression models and life tables J. R Stat. Soc. Ser. B 34:184-220  Cox, D. R. 1975.   Partial likelihood Biometrika 62:269276  Cox, D. R. & D. Oakes. 1984 Analysis of Survival Data  Chapman & Hall. London  Cressie, N. A. 1993 Statistics for Spatial Data John Wiley Sons. 900pp  Duchesne, T. 2005. Regression models for reliability given the usage accumulation history. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty Y. Armijo. pp.29-40. World Scientific, New Jersey  Eleuteri, A., R. Tagliaferri, L. Milano, G. Sansone, D D'Agostino, S. De Placido,  M. Laurentiis. 2003.  Survival analysis and neural networks. Proceedings of the International Joint Conference on Neural Networks, Vol. 4 20-24 July 2003 Page\(s\:2631 - 2636  Ellison, E., L. Linger, and M Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013, 1997  Fleming, T. R. & D. P. Harrington. 1991. Counting process and survival analysis. John Wiley & Sons. 429pp  Graver, J. and M. Sobel 2005. You may rely on the Reliability Polynomial for much more than you might think Communications in Statistics: Theory and Methods  34\(6\1411-1422  Graves, T. and M. Hamada. 2005. Bayesian methods for assessing system reliability: models and computation. In Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson, et al. pp.41-53  Grimmett, G. 2006 The Random-Cluster Model Springer  Grimmett, G. 1999 Percolation Springer  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis.  Springer. 481pp  Jin Z. 2005. Non-proportional semi-parametric regression models for censored data. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.279-292 World Scientific  Kalbfleisch, J. D. & R. L. Prentice. 1980 The Statistical Analysis of Failure Time Data John Wiley & Sons.  New York. 1980  Kalbfleisch, J. D. &  R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data.  Wiley-InterScience, 2nd ed 462pp  Lisboa, P. J. G. and H. Wong. 2001. Are neural networks best used to help logistic regression? Proceedings of International Joint Conference on Neural Networks, IJCNN 01. Volume 4, 15-19,  July 2001. Page\(s\:2472 - 2477 vol.4  Kauffman, R. J. and B. Wang. 2002. Duration in the Digital Economy. Proceedings of th e 36th Hawaii International Conference on System Sciences \(HICSS’03\ Jan 2003  Kaplan, E. L. & P.  Meier.  1958.  Nonparametric estimation from incomplete observations J. Amer. Statist. Assoc  53:457-481  Klein, J. P. and P. K. Goel 1992. Survival Analysis: State of the Art.  Kluwer Academic Publishes. 450pp  Klein, J. P. and  M. L Moeschberger. 20 03. Survival analysis techniques for ce nsored and truncated data Springer  Krings, A. and Z. S. Ma. 2006.  "Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks MILCOM 2006, Military Communications Conference, 2325 October, 7 pages, 2006  Krings, A. W. 2008.  Survivable Systems.  in Information Assurance: Dependability and Security in Networked Systems Yi Qian, James Joshi, David Tipper, and Prashant Krishnamurthy, Morgan Kaufmann Publishers. \(in press  Lawless, J. F. 1982. Statistical models and methods for lifetime data.  John Wiley & Sons. 579pp  Lawless, J. F. 2003. Statistical models and methods for lifetime data.  John Wiley & Sons. 2nd ed. 630pp  Li, M. and P. Vitanyi. 1997. Introduction to  Kolmogorov Complexity and Its Applications. 2nd ed, Springer  Ma, Z. S. 1997.  Survival analysis and demography of Russian wheat aphid populations.  Ph.D dissertation, 307pp University of Idaho Moscow, Idaho, USA 


 20 Ma, Z. S., and E. J. Bechinski. 2008.  Developmental and Phenological Modeling of Russian Wheat Aphid Annals of Entomological Soc. Am In press  Ma, Z. S. and A. W. Krings. 2008a. The Competing Risks Analysis Approach to Reliability Survivability, and Prognostics and Health Management.  The 2008 IEEEAIAA AeroSpace Conference. BigSky, Montana, March 18, 2008. \(In Press, in the same volume  Ma, Z. S. and A. W. Krings 2008b. Multivariate Survival Analysis \(I\e Shared Frailty Approaches to Reliability and Dependence Modeling. The 2008 IEEE-AIAA AeroSpace Conference. BigSky Montana, March 1-8, 2008 In Press, in the same volume  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(II\ Multi-State Models in Biomedicine and Engineering Reliability. 2008 IEEE International Conference on Biomedical Engineering and Informatics BMEI 2008\27th-30th, 2008 Accepted   Mani, R., J. Drew, A. Betz, P. Datta. 1999. Statistics and Data Mining Techniques for Lifetime Value Modeling ACM Conf. on Knowledge Discovery and Data Mining  Mazzuchi, T. A., R Soyer., and R. V Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Meeker, W. Q. and L. A. Escobar. 1998. Statistical Methods for Reliability Data. Wiley-Interscience  Munson, J. C. 2003. Software Engineering Measurement Auerbach Publications  Nelson, W. 1969. Hazard plotting for incomplete failure data J. Qual. Tech 1:27-52  Nakagawa, T. 2006.  Shock and Damage Models in Reliability Theory. Springer  Osborn, B. 2005. Leveraging remote diagnostics data for predictive maintenance.   In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp. 353-363  Pena, E. A. and E. H. Slate. 2005. Dynamic modeling in reliability and survival analysis. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.55-71  Reineke, D. M., E. A. Pohl, and W. P. Murdock. 1998 Survival analysis and maintenance policies for a series system, with highly censore d data.  1998 Proceedings Annual Reliability and Maintainability Symposium. pp 182-188  Schabenberger, O. and C. A. Gotway. 2005. Statistical Methods for Spatial Data Analysis.  Chapman & Hall/CRC  Severini, T. A. 2000. Likelihood methods in statistics Oxford University Press  Shooman, M. L. 2002. Reliability of Computer Systems and Networks: Fault Tolerance, Analysis and Design. John Wiley and Sons. 551pp  Stillman, R. H. and M. S. Mack isack, B. Sharp, and C. Lee 1995. Case studies in survival analysis of overhead line components. IEE Conferen ce of the Reliability and Distribution Equipment. March 29-31, 1995. Conference Publication No. 406. pp210-215  Therneau, T. and P. Grambsch. 2000 Modeling Survival Data: Extending the Cox Model Springer  Wilson, A.  N. Limnios, S Kelly-McNulty, Y. Armijo 2005. Modern Statistical and Mathematical Methods in Reliability. World Scientific, New Jersey  Xie, M. 1991. Software Reliability Modeling. World Scientific Press    B IOGRAPHY   Zhanshan \(Sam\ Ma holds a Ph.D. in Entomology and is a Ph.D. candidate in Computer Science at the University of Idaho. He has published approximately 30 journal and 30 conference papers, mainly in the former field.  Prior to his recent return to academia, he worked as senior network/software engineers in software industry.  His current research interests include reliability and survivability of wireless sensor networks, fault tolerance survival analysis, evolutionary game theory, evolutionary computation and bioinformatics  Axel W. Krings is a professor of Computer Science at the University of Idaho.  He received his Ph.D. \(1993\ and M.S 1991\ degrees in Computer Science from the University of Nebraska - Lincoln, and his M.S. \(1982\ in Electrical Engineering from the FH-Aachen, Germany.  Dr. Krings has published extensively in the area of Computer Network Survivability, Security, Fault-Tolerance and Realtime Scheduling. In 2004/2005 he was a visiting professor at the Institut d'Informatique et Mathématiques Appliquées de Grenoble, at the Institut National Polytechnique de Grenoble, France.  His work has been funded by DoE/INL DoT/NIATT, DoD/OST and NIST 


States\nWAb-3.4: NEW RESULTS IN THE ANALYSIS OF DECISION-FEEDBACK 2118\nEQUALIZERS\nAhmed Mehana, Samsung Electronics, Co Ltd., United States; Aria Nosratinia, University of Texas at \nDallas, United States\nWAb-5: TARGET TRACKING II\nWAb-5.1: POSTERIOR DISTRIBUTION PREPROCESSING FOR PASSIVE 2125\nDTV RADAR TRACKING: SIMULATED AND REAL DATA\nEvan Hanusa, Laura Vertatschitsch, David Krout, University of Washington, United States\nWAb-5.2: DEPTH-BASED PASSIVE TRACKING OF SUBMERGED SOURCES  ............................................2130\nIN THE DEEP OCEAN USING A VERTICAL LINE ARRAY\nLisa Zurk, John K. Boyle, Jordan Shibley, Portland State University, United States\nWAb-5.3: GENERALIZED LINEAR MINIMUM MEAN-SQUARE ERROR 2133\nESTIMATION WITH APPLICATION TO SPACE-OBJECT TRACKING\nYu Liu, X. Rong Li, Huimin Chen, University of New Orleans, United States\nWAb-5.4: FEATURE-AIDED INITIATION AND TRACKING VIA TREE SEARCH ..........................................2138\nHossein Roufarshbaf Jill Nelson, George Mason University, United States\nxxxiii\nWAb-6: DIRECTION OF ARRIVAL ESTIMATION\nWAb-6.1: A SELF-CALIBRATION TECHNIQUE FOR DIRECTION 2145\nESTIMATION WITH DIVERSELY POLARIZED ARRAYS\nBenjamin Friedlander, University of California, Santa Cruz, United States\nWAb-6.2: CRAMER-RAO PERFORMANCE BOUNDS FOR SIMULTANEOUS  ..............................................2150\nTARGET AND MULTIPATH POSITIONING\nLi Li, Jeff Krolik, Duke University, United States\nWAb-6.3: COPY CORRELATION DIRECTION-OF-ARRIVAL ESTIMATION  .................................................2155\nPERFORMANCE WITH A STOCHASTIC WEIGHT VECTOR\nChrist Richmond, Keith Forsythe, MIT Lincoln Laboratory, United States; Christopher Flynn, Stevens nInstitute of Technology, United States\nWAb-6.4: LOCATING CLOSELY SPACED COHERENT EMITTERS USING 2160\nTDOA TECHNIQUES\nJack Reale, Air Force Research Laboratory / Binghamton University, United States; Lauren Huie, Air \nForce Research Laboratory, United States Mark Fowler, State University of New York at Binghamton, \nUnited States\nWAb-7: ENERGY- AND RELIABILITY-AWARE DESIGN\nWAb-7.1: LOW-ENERGY ARCHITECTURES FOR SUPPORT VECTOR 2167\nMACHINE COMPUTATION\nManohar Ayinala, Keshab K Parhi, University of Minnesota, United States\nWAb-7.2: TRUNCATED MULTIPLIERS THROUGH POWER-GATING FOR 2172\nDEGRADING PRECISION ARITHMETIC\nPietro Albicocco, Gian Carlo Cardarilli, University of Rome Tor Vergata, Italy; Alberto Nannarelli, \nTechnical University of Denmark Denmark; Massimo Petricca, Politecnico di Torino, Italy; Marco Re, \nUniversity of Rome Tor Vergata Italy\nWAb-7.3: A LOGARITHMIC APPROACH TO ENERGY-EFFICIENT GPU 2177\nARITHMETIC FOR MOBILE DEVICES\nMiguel Lastras Behrooz Parhami, University of California, Santa Barbara, United States\nWAb-7.4: ON SEPARABLE ERROR DETECTION FOR ADDITION ..................................................................2181\nMichael Sullivan, Earl Swartzlander, University of Texas at Austin, United States\nWPb-1: PAPERS PRESENTED IN 2012\nWPb-1.1 DYNAMICALLY RECONFIGURABLE AVC DEBLOCKING FILTER  .............................................2189\nWITH POWER AND PERFORMANCE CONSTRAINTS\nYuebing Jiang, Marios Pattichis, University of New Mexico\nxxxiv\n 


on science teams for numerous planetary missions including Magellan, Mars Observer, Mars Global Surveyor and Rosetta. He was the US Project Scientist for the international Mars NetLander mission, for which he was also principal investigator of the Short-Period Seismometer experiment, and is currently the Project Scientist for the Mars Exploration Rovers. He led the Geophysics and Planetary Geology group at JPL from 1993-2005, and is the JPL Discipline Program Manager for Planetary Geosciences. He has held several visiting appointments at the Institut de Physique du Globe de Paris. He has a BS in physics and a PhD in geophysics from the University of Southern California  David Hansen is a member of the technical staff in the Communications Systems and Operations Group at the Jet Propulsion Laboratory. Current work includes the development of the telecom subsystem for the Juno project. David received a B.S. in Electrical Engineering from Cornell University and an M.S. in Electrical Engineering from Stanford University  Robert Miyake is a member of the technical staff in the Mission and Technology Development Group at the Jet Propulsion Laboratory. Current work includes the development of thermal control subsystems for interplanetary flagship missions to Jupiter and Saturn missions to Mars and the Earth Moon, and is the lead Thermal Chair for the Advanced Project Design Team Robert graduated with a B. S. from San Jose State University, with extensive graduate studies at UCLA University of Washington, and University of Santa Clara  Steve Kondos is a consultant to the Structures and Mechanisms group at the Jet Propulsion Laboratory. He currently is generating the mechanical concepts for small Lunar Landers and Lunar Science Instrument packages in support of various Lunar mission initiatives. He also provides conceptual design, mass and cost estimating support for various Team X studies as the lead for the Mechanical Subsystem Chair. Steve is also involved with various other studies and proposals and provides mentoring to several young mechanical and system engineers. He graduated with a B.S. in Mechanical Engineering from the University of California, Davis and has 28 years of experience in the aerospace field ranging from detail part design to system of systems architecture development. He has worked both in industry and in government in defense, intelligence commercial and civil activities that range from ocean and land based systems to airborne and space systems. Steve has received various NASA, Air Force, Department of Defense and other agency awards for his work on such projects as the NASA Solar Array Flight Experiment, Talon Gold, MILSTAR, Iridium, SBIRS, Mars Exploration Rovers ATFLIR, Glory Aerosol Polarimeter System and several Restricted Programs  Paul Timmerman is a senior member of technical staff in the Power Systems Group at the Jet Propulsion Laboratory Twenty-five years of experience in spacecraft design including 22 at JPL, over 250 studies in Team-X, and numerous proposals. Current assignments include a wide variety of planetary mission concepts, covering all targets within the solar system and all mission classes. Paul graduated from Loras College with a B.S. in Chemistry in 1983  Vincent Randolph is a senior engineer in the Advanced Computer Systems and 


the Advanced Computer Systems and Technologies Group at the Jet Propulsion Laboratory. Current work includes generating Command and Data Handling Subsystem conceptual designs for various proposals and Team X.  He also supports Articulation Control and Electronics design activities for the Advanced Mirror Development project. Vincent graduated from the University of California at Berkeley with a B.S. in Electrical Engineering 18  pre></body></html 


i models into time and covariate dependent dynamic counterparts  ii models and reliability analysis in a more realistic manner  iii level  whether or not functional components \(loyal generals diagnose correctly and take proper actions such as fault mask of failed components \(traitors asymmetric  iv survivability analysis. Evolutionary game modeling can derive sustainable or survivable strategies \(mapped from the ESS in EGT such as node failures such as security compromise level modeling in the so-called three-layer survivability analysis developed in Ma \(2008a this article  v offer an integrated architecture that unite reliability survivability, and fault tolerance, and the modeling approaches with survival analysis and evolutionary game theory implement this architecture. Finally, the dynamic hybrid fault models, when utilized to describe the survival of players in EGT, enhance the EGT's flexibility and power in modeling the survival and behaviors of the game players which should also be applicable to other problem domains where EGT is applicable  5. OPERATIONAL LEVEL MODELING AND DECISION-MAKING  5.1. Highlights of the Tactical and Strategic Levels  Let's first summarize what are obtainable at both tactical and strategic levels. The results at both tactical and strategic levels are precisely obtainable either via analytic or simulation optimization. With the term precisely, we mean that there is no need to assign subjective probabilities to UUUR events. This is possible because we try to assess the consequences of UUUR events \(tactical level ESS strategies \(strategic level time prediction of survivability. The following is a list of specific points. I use an assumed Wireless Sensor Network WSN  i of UUUR events: \(a actions which can be treated as censored events; \(b Cont' of Box 4.2 It can be shown that the replicator differential equations are equivalent to the classical population dynamics models such as Logistic differential equation and LotkaVolterra equation \(e.g., Kot 2001 Logistic equation, or the limited per capital growth rate is similar to the change rate of the fitness  xfxfi which can be represented with the hazard function or survivor functions introduced in the previous section on survival analysis.  This essentially connects the previous survival analysis modeling for lifetime and reliability with the EGT modeling. However, EGT provides additional modeling power beyond population dynamics or survival analysis approaches introduced in the previous section. The introduction of evolutionary theory makes the games played by a population evolvable. In other words, each player \(individual 


other words, each player \(individual agent and players interact with each other to evolve an optimized system Box 4.3. Additional Comments on DHF Models  The above introduced EGT models are very general given they are the system of ordinary differential equations. Furthermore, the choice of fitness function f\(x complexity to the differential equation system.  The system can easily be turned into system of nonlinear differential equations. The analytical solution to the models may be unobtainable when nonlinear differential equations are involved and simulation and/or numerical computation are often required  In the EGT modeling, Byzantine generals are the game players, and hybrid fault models are conveniently expressed as the strategies of players; the players may have different failure or communication behaviors Furthermore, players can be further divided into groups or subpopulations to formulate more complex network organizations. In the EGT modeling, reliability can be represented as the payoff \(fitness, the native term in EGT of the game. Because reliability function can be replaced by survivor function, survival analysis is seamlessly integrated into the EGT modeling. That is, let Byzantine generals play evolutionary games and their fitness reliability function  The evolutionary stable strategy \(ESS counterpart of Nash equilibrium in traditional games ESS corresponds to sustainable strategies, which are resistant to both internal mutations \(such as turning into treason generals or nodes such as security compromises represent survivable strategies and survivability in survivability analysis. Therefore, dynamic hybrid fault models, after the extension with EGT modeling, can be used to study both reliability and survivability 13 risks such as competing risks which can be described with CRA; \(c captured with the shard frailty.  We believe that these UUUR events are sufficiently general to capture the major factors/events in reliability, security and survivability whose occurrence probabilities are hard or impossible to obtain  Instead of trying to obtain the probabilities for these events which are infeasible in most occasions, we focus on analyzing the consequences of the events.  With survival analysis, it is possible to analyze the effects of these types of events on survivor functions. In addition, spatial frailty modeling can be utilized to capture the heterogeneity of risks in space, or the spatial distribution of risks \(Ma 2008a d UUUR events introduced previously. These approaches and models that deal with the effects of UUUR events form the core of tactical level modeling  To take advantage of the tactical level modeling approaches it is obviously necessary to stick to the survivor functions or hazard functions models. In other words, survival analysis can deal with UUUR events and offer every features reliability function provides, but reliability function cannot deal with UUUR events although survivor function and reliability function have the exactly same mathematical definition. This is the junction that survival analysis plays critical role in survivability analysis at tactical level. However, we 


recognize that it is infeasible to get a simple metric for survivability similar to reliability with tactical level modeling alone. Actually, up to this point, we are still vague for the measurement of survivability or a metric for survivability. We have not answered the question: what is our metric for survivability? We think that a precise or rigorous definition of survivability at tactical level is not feasible, due to the same reason we cited previously  the inability to determine the probabilities of UUUR events However, we consider it is very helpful to define a work definition for survivability at the tactical level  We therefore define the survivability at tactical level as a metric, Su\(t t function or reliability function with UUUR events considered. In the framework of three-layer survivability analysis, this metric is what we mean with the term survivability. The "metric" per se is not the focus of the three-layer survivability analysis. It is not very informative without the supports from the next two levels  strategic and operational models.  However, it is obvious that this metric sets a foundation to incorporate UUUR effects in the modeling at the next two levels  Due to the inadequacy of tactical level modeling, we proposed the next level approach  strategic level modeling for survivability. As expected, the tactical level is one foundation of strategic level modeling ii objectives: \(a affect survivability which survival analysis alone is not adequate to deal with; \(b survivability at tactical level is necessary but not sufficient for modeling survivability, we need to define what is meant with the term survivability at strategic level  With regard to \(a behaviors or modes which have very different consequences. These failure behaviors can be captured with hybrid fault models. However, the existing hybrid fault models in fault tolerance field are not adequate for applying to survivability analysis. There are two issues involved: one is the lack of real time notion in the constraints for hybrid fault models \(e.g., N&gt;3m+1 for Byzantine Generals problem synthesize the models after the real-time notions are introduced. The solution we proposed for the first issue is the dynamic hybrid fault models, which integrate survivor functions with traditional hybrid fault models. The solution we proposed for the second issue is the introduction of EGT modeling  With regard to \(b modeling our problem at strategic level, EGT modeling is essentially a powerful optimization algorithm.  One of the most important results from EGT modeling is the so-called evolutionary stable strategies \(ESS We map the ESS in EGT to survivable strategies in survivability analysis.   Therefore, at the strategic level, our work definition for survivability refers to the survivable strategies or sustainable strategies in the native term of EGT, which can be quantified with ESS  In addition to integrating dynamic hybrid fault models another advantage for introducing EGT modeling at strategic level is the flexibility for incorporating other node behaviors \(such as cooperative vs. non-cooperative those behaviors specified in standard hybrid fault models, as well as anthropocentric factors such as costs constraints  Without UUUR events, both tactical and strategic level 


Without UUUR events, both tactical and strategic level models default to regular reliability models. This implies that, in the absence of UUUR events, reliable strategies are sustainable or survivable.  This also implies that three-layer survivability analysis defaults to reliability analysis however, the three-layer approach does offer some significant advantages over traditional reliability analysis, as discussed in previous sections. Nevertheless, when UUUR events exist, reliable strategies and survivable strategies are different. This necessitates the next operational level modeling  5.2. Operational Level Modeling and Decision-Making  When UUUR events are involved, we cannot make real time predictions of survivability at tactical and strategic levels This implies that the implementations of survivable 14 strategies need additional measures that we develop in this section.  Box 5.1 explains the ideas involved with possibly the simplest example  Figure 4 is a diagram showing a simplified relationship between action threshold survivability \(TS survivability \(ES view since both TS and ES are multidimensional and dynamic in practice. Therefore, the sole purpose of the diagram is to illustrate the major concepts discussed above The blue curve is the survivability when survivable strategies specified by ESS are implemented at some point before time s.  The system is then guaranteed to hold survivability above ES. In contrary, if no ESS implemented before time s, then the system quickly falls below to the survivable level at around 40 time units  T i m e 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 1 0 0 Su rv iv ab ili ty M et ric S u t 0 . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 . 0 E S S  i s  I m p lm e n t e d N o  E S S  is  I m p lm e n t e d ts E S T S  Figure 4. A Diagram Showing the Relationship Between TS and ES, as well as timing of s and t, with s &lt; t  6. SUMMARY  The previous sections discussed the major building blocks 


The previous sections discussed the major building blocks for the new life-system inspired PHM architecture. This section first identifies a few minor aspects that have not been discussed explicitly but are necessary for the implementation of the architecture, and then we summarize the major building blocks in a diagram  6.1. Missing Components and Links  Optimization Objectives  Lifetime, reliability, fault tolerance, and survivability, especially the latter two, are application dependent. Generally, the optimization of reliability and survivability are consistent; in that maximization of reliability also implies maximization of survivability. However, when application detail is considered, optimization of lifetime is not necessarily consistent with the optimization of reliability. Consider the case of the monitoring sensor network as an example. The network reliability is also dependent on connectivity coverage, etc, besides network lifetime. What may be further complicated is the time factor. All of the network metrics are time-dependent. A paradoxical situation between lifetime and reliability could be that nodes never 'sleep                                                   


          Box 5.1 Operational Level Modeling  Assuming that the ESS solution for a monitoring sensor network can be expressed with the following simple algebraic conditions: survivability metric at tactical level SU = 0.7, Router-Nodes in the WSN &gt; 10%, Selfish Nodes &lt; 40%. Even with this extremely simplified scenario, the ESS strategies cannot be implemented because we do not know when the actions should be taken to warrant a sustainable system.  These conditions lack a correlation with real time  The inability to implement ESS is rooted in our inability to assign definite probabilities to UUUR events, which implies that we cannot predict when something sufficiently bad will jeopardize the system survivability What we need at the operational level is a scheme to ensure ESS strategy is in place in advance  The fundamental idea we use to implement the ESS strategy is to hedge against the UUUR events. The similar idea has been used in financial engineering and also in integrated pest management in entomology. This can be implemented with the following scheme  Let us define a pair of survivability metrics: one is the expected survivability \(ES threshold survivability or simply threshold survivability \(TS ES is equivalent to the survivability metric at tactical level. ES corresponds to ESS at strategic level, but they are not equivalent since ESS is strategy and ES is survivability. TS is the survivability metric value \(at tactical level and TS can be obtained from strategic level models. For example, TS = SU\(s t condition for the implementation of ESS. In other words, the implementation of strategies that ensures TS at time s will guarantee the future ES level at time t.  To make the implementation more reliable and convenient multiple dynamic TSs can be computed at time s1, s2 sk, with si &lt; t for all i.  These TS at times s1, s2, ..., sk should be monitored by some evaluation systems  Unlike tactical and strategic levels, the operational level modeling is approximate. The term "approximate means that we cannot predict the real time survivability or we do not know the exact time an action should be taken. Instead, the action is triggered when the monitored survivability metric SU\(r survivability \(TS scheme of TS and ES, we ensure the ES by taking preventative actions \(prescribed by ESS and triggered by the TS consequences of UUUR events  Figure 4 is a diagram showing the above concepts and the decision-making process involved 15 This wakefulness \(never 'sleep short period but at the expense of network lifetime. Of course, when the network is running out of lifetime, network reliability ultimately crashes. This example reminds us that 


reliability ultimately crashes. This example reminds us that multi-objective optimization should be the norm rather than exception  Constraints and Extensions  Many application specific factors and constraints are ignored in this article. For example, we mentioned about spatial heterogeneity of environment, but never present a mathematical description The spatial heterogeneity can be modeled with the so-called spatial frailty in multivariate survival analysis \(Ma 2008a  Evolutionary Algorithm  Evolutionary game modeling when implemented in simulation, can be conveniently implemented with an algorithm similar to Genetic Algorithms \(GA ESS in the evolutionary game model with simulation is very similar to GA. Dynamic populations, in which population size varies from generation to generation \(Ma &amp; Krings 2008f of node failures. Another issue to be addressed is the synchronous vs. asynchronous updating when topology is considered in the simulation. This update scheme can have profound influences on the results of the simulation. Results from cellular automata computing should be very useful for getting insights on the update issue  6.2. Summary and Perspective  To recapture the major points of the article, let us revisit Figure 3, which summarizes the principal modules of the proposed life-system inspired PHM architecture. The main inspiration from life systems is the notion of individuals and their assemblage, the population. Population is an emergent entity at the next level and it has emergent properties which we are often more concerned with. Survival analysis, which has become a de facto standard in biomedicine, is particularly suitable for modeling population, although it is equally appropriate at individual level. Therefore, survival analysis \(including competing risks analysis and multivariate survival analysis comprehensively in the context of PHM in a series of four papers presented at IEEE AeroSpace 2008 \(Ma &amp; Krings 2008a, b, c, &amp; d proposed architecture. Survival analysis constitutes the major mathematical tools for analyzing lifetime and reliability, and also forms the tactical level of the three-layer survivability analysis  Besides lifetime and reliability, two other major modules in Figure 3 are fault tolerance and survivability. To integrate fault tolerance into the PHM system, Dynamic Hybrid Fault DHF 2008e, Ma 2008a make real-time prediction of reliability more realistic and make real-time prediction of fault tolerance level possible DHF models also unite lifetime, reliability and fault tolerance under a unified modeling framework that consists of survival analysis and evolutionary game theory modeling  DHG models also form the partial foundation, or strategic level, for the three-layer survivability analysis. At the strategic level, the Evolutionary Stable Strategies \(ESS which is mapped to survivable or sustainable strategies, can be obtained from the evolutionary game theory based DHF models. When there is not any UUUR event involved reliability and survivability are consistent, and reliable strategies are survivable. In this case, the strategic level modeling up to this point is sufficient for the whole PHM system modeling, and there is no need for the next level  operational level modeling  When there are UUUR events in a PHM system, the 


When there are UUUR events in a PHM system, the inability to determine the occurrence probabilities of UUUR events makes the operational level modeling necessary Then the principle of hedging must be utilized to deal with the "hanging" uncertainty from UUUR events. In this case reliability strategies are not necessarily survivable strategies At the operational level modeling, a duo of survivability metrics, expected survivability \(ES survivability \(TS the survivable strategies \(ESS level are promptly implemented based on the decisionmaking rules specified with the duo of survivability metrics then the PHM system should be able to endure the consequences of potentially catastrophic UUUR events. Of course, to endure such catastrophic events, the cost may be prohibitively high, but the PHM system will, at least, warn decision-makers for the potentially huge costs.  It might be cheap to just let it fail  Figure 3 also shows several other modules, such as security safety, application systems \(such as Automatic Logistics CBM+, RCM, Life cycle cost management, Real-time warning and alert systems architectures, but we do not discuss in this paper. Generally the new architecture should be fully compatible with existing ones in incorporating these additional modules. One point we stressed is that PHM system can be an ideal place to enforce security policies. Enforcing security policies can be mandatory for PHM systems that demand high security and safety such as weapon systems or nuclear plant facilities.  This is because maintenance, even without human-initiated security breaches, can break the security policies if the maintenance is not planned and performed properly  In perspective, although I did not discuss software issues in this paper, the introduced approaches and models should provide sufficient tools for modeling software reliability and survivability with some additional extension. Given the critical importance of software to modern PHM systems, we present the following discussion on the potential extension to software domain. Specifically, two points should be noted: \(1 architecture to software should be a metric which can 16 replace the time notion in software reliability; I suggest that the Kolmogorov complexity \(e.g., Li and Vitanyi 1997 be a promising candidate \(Ma 2008a change is because software does not wear and calendar time for software reliability usually does not make much sense 2 software reliability modeling.  Extending to general survivability analysis is not a problem either. In this article I implicitly assume that reliability and survivability are positively correlated, or reliability is the foundation of survivability. This positive correlation does not have to be the case. A simplified example that illustrates this point is the 'limit order' in online stock trading, in which limit order can be used in either direction: that stock price is rising or falling.  The solution to allow negative or uncorrelated relationships between reliability and survivability are very straightforward, and the solutions are already identified in previous discussions. Specifically, multiple G-functions and multi-stage G-functions by Vincent and Brown \(2005 very feasible solution, because lifetime, reliability and survivability may simply be represented with multiple Gfunctions. Another potential solution is the accommodation of the potential conflicts between reliability and survivability with multi-objective GA algorithms, which I previously suggested to be used as updating algorithms in the optimization of evolutionary games  


 The integration of dynamic hybrid fault models with evolutionary game modeling allows one to incorporate more realistic and detailed failure \(or survival individual players in an evolutionary game. This is because dynamic hybrid fault models are supported by survival analysis modeling, e.g., time and covariate dependent hazard or survivor functions for individual players. If necessary, more complex survival analysis modeling including competing risks analysis and multivariate survival analysis, can be introduced.  Therefore, any field to which evolutionary game theory is applicable may benefit from the increased flexibility in modeling individual players.  Two particularly interesting fields are system biology and ecological modeling.  In the former field, dynamic hybrid fault models may find important applications in the study of biological networks \(such as gene, molecular, and cell networks 2008g conjecture that explains the redundancy in the universal genetic code with Byzantine general algorithm. In addition they conducted a comparative analysis of bio-robustness with engineering fault tolerance, for example, the strong similarity between network survivability and ecological stability \(Ma &amp; Krings 2008g survivability analysis can be applied for the study of survivals or extinctions of biological species under global climate changes \(Ma 2008b  In this paper, I have to ignore much of the details related to the implementation issues to present the overall architecture and major approaches clearly and concisely. To deal with the potential devils in the implementation details, a well funded research and development team is necessary to take advantages of the ideas presented here. On the positive side I do see the great potential to build an enterprise PHM software product if there is sufficient resource to complete the implementation. Given the enormous complexity associated with the PHM practice in modern engineering fields, it is nearly impossible to realize or even demonstrate the benefits of the architecture without the software implementation. The critical importance of PHM to mission critical engineering fields such as aerospace engineering, in turn, dictates the great value of such kind software product  6.3. Beyond PHM  Finally, I would like to raise two questions that may be interested in by researchers and engineers beyond PHM community. The first question is: what can PHM offer to other engineering disciplines? The second question is: what kinds of engineering fields benefit most from PHM? Here, I use the term PHM with the definition proposed by IEEE which is quoted in the introduction section of the paper  As to the first question, I suggest software engineering and survivability analysis are two fields where PHM can play significant roles. With software engineering, I refer to applying PHM principles and approaches for dealing with software reliability, quality assurance, and even software process management, rather than building PHM software mentioned in the previous subsection. For survivability analysis, borrowing the procedures and practices of PHM should be particularly helpful for expanding its role beyond its originating domain \(network systems that control critical national infrastructures is a strong advocate for the expansion of survivability analysis to PHM. Therefore, the interaction between PHM and survivability analysis should be bidirectional. Indeed, I see the close relationships between PHM, software engineering, and survivability as well-justified because they all share some critical issues including reliability survivability, security, and dependability  


 The answer to the second question is much more elusive and I cannot present a full answer without comparative analysis of several engineering fields where PHM has been actively practiced. Of course, it is obvious that fields which demand mission critical reliability and dependability also demand better PHM solutions. One additional observation I would like to make is that PHM seems to play more crucial roles for engineering practices that depend on the systematic records of 'historical' data, such as reliability data in airplane engine manufacturing, rather than on the information from ad hoc events.  This may explain the critical importance of PHM in aerospace engineering particularly in commercial airplane design and manufacturing.  For example, comparing the tasks to design and build a space shuttle vs. to design and manufacture commercial jumbo jets, PHM should be more critical in the latter task  17    Figure 2. States of a monitoring sensor node and its failure modes \(after Ma &amp; Krings 2008e     Figure 3. Core Modules and their Relationships of the Life System Inspired PHM Architecture    REFERENCES  Adamides, E. D., Y. A. Stamboulis, A. G. Varelis. 2004 Model-Based Assessment of Military Aircraft Engine Maintenance Systems Model-Based Assessment of Military Aircraft Engine Maintenance Systems. Journal of the Operational Research Society, Vol. 55, No. 9:957-967  Anderson, R. 2001. Security Engineering. Wiley  Anderson, R. 2008. Security Engineering. 2nd ed. Wiley  Bird, J. W., Hess, A. 2007.   Propulsion System Prognostics R&amp;D Through the Technical Cooperation Program Aerospace Conference, 2007 IEEE, 3-10 March 2007, 8pp  Bock, J. R., Brotherton, T., W., Gass, D. 2005. Ontogenetic reasoning system for autonomic logistics. Aerospace Conference, 2005 IEEE 5-12 March 2005.Digital Object Identifier 10.1109/AERO.2005.1559677  Brotherton, T., P. Grabill, D. Wroblewski, R. Friend, B Sotomayer, and J. Berry. 2002. A Testbed for Data Fusion for Engine Diagnostics and Prognostics. Proceedings of the 2002 IEEE Aerospace Conference  Brotherton, T.; Grabill, P.; Friend, R.; Sotomayer, B.; Berry J. 2003. A testbed for data fusion for helicopter diagnostics and prognostics. Aerospace Conference, 2003. Proceedings 2003 IEEE  Brown, E. R., N. N. McCollom, E-E. Moore, A. Hess. 2007 Prognostics and Health Management A Data-Driven Approach to Supporting the F-35 Lightning II. 2007 IEEE AeroSpace Conference  Byington, C.S.; Watson, M.J.; Bharadwaj, S.P. 2008 Automated Health Management for Gas Turbine Engine Accessory System Components. Aerospace Conference 2008 IEEE, DOI:10.1109/AERO.2008.4526610 


2008 IEEE, DOI:10.1109/AERO.2008.4526610 Environment Covariates &amp; Spatial Frailty Applications: AL; Life Cycle Mgmt; Real-Time Alerts CBM+, RCM, TLCSM; Secret Sharing and Shared Control 18 Chen, Y. Q., S. Cheng. 2005. Semi-parametric regression analysis of mean residual life with censored survival data Biometrika \(2005  29  Commenges, D. 1999. Multi-state models in Epidemiology Lifetime Data Analysis. 5:315-327  Cook, J. 2004. Contrasting Approaches to the Validation of Helicopter HUMS  A Military User  s Perspective Aerospace Conference, 2004 IEEE  Cook, J. 2007. Reducing Military Helicopter Maintenance Through Prognostics. Aerospace Conference, 2007 IEEE Digital Object Identifier 10.1109/AERO.2007.352830  Cox, D. R. 1972. Regression models and life tables.  J. R Stat. Soc. Ser. B. 34:184-220  Crowder, M. J.  2001. Classical Competing Risks. Chapman amp; Hall. 200pp  David, H. A. &amp; M. L. Moeschberger. 1978. The theory of competing risks. Macmillan Publishing, 103pp  Ellison, E., L. Linger, and M. Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013  Hanski, I. 1999. Metapopulation Ecology. Oxford University Press  Hallam, T. G. and S. A. Levin. 1986. Mathematical Ecology. Biomathematics. Volume 17. Springer. 457pp  Hess, A., Fila, L. 2002.  The Joint Strike Fighter \(JSF concept: Potential impact on aging aircraft problems Aerospace Conference Proceedings, 2002. IEEE. Digital Object Identifier: 10.1109/AERO.2002.1036144  Hess, A., Calvello, G., T. Dabney. 2004. PHM a Key Enabler for the JSF Autonomic Logistics Support Concept. Aerospace Conference Proceedings, 2004. IEEE  Hofbauer, J. and K. Sigmund. 1998. Evolutionary Games and Population Dynamics. Cambridge University Press 323pp  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Huzurbazar, A. V. 2006. Flow-graph model for multi-state time-to-event data. Wiley InterScience  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis. Springer. 481pp  Kacprzynski, G. J., Roemer, M. J., Hess, A. J. 2002. Health management system design: Development, simulation and cost/benefit optimization. IEEE Aerospace Conference Proceedings, 2002. DOI:10.1109/AERO.2002.1036148  Kalbfleisch, J. D., and R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data. Wiley-InterScience, 2nd ed  Kalgren, P. W., Byington, C. S.   Roemer, M. J.  2006 Defining PHM, A Lexical Evolution of Maintenance and Logistics. Systems Readiness Technology Conference 


Logistics. Systems Readiness Technology Conference IEEE. DOI: 10.1109/AUTEST.2006.283685  Keller, K.; Baldwin, A.; Ofsthun, S.; Swearingen, K.; Vian J.; Wilmering, T.; Williams, Z. 2007. Health Management Engineering Environment and Open Integration Platform Aerospace Conference, 2007 IEEE, Digital Object Identifier 10.1109/AERO.2007.352919  Keller, K.; Sheahan, J.; Roach, J.; Casey, L.; Davis, G Flynn, F.; Perkinson, J.; Prestero, M. 2008. Power Conversion Prognostic Controller Implementation for Aeronautical Motor Drives. Aerospace Conference, 2008 IEEE. DOI:10.1109/AERO.2008.4526630  Klein, J. P. and M. L. Moeschberger. 2003. Survival analysis techniques for censored and truncated data Springer  Kingsland, S. E. 1995. Modeling Nature: Episodes in the History of Population Ecology. 2nd ed., University of Chicago Press, 315pp  Kot, M. 2001. Elements of Mathematical Ecology Cambridge University Press. 453pp  Krings, A. W. and Z. S. Ma. 2006. Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks Military Communications Conference, 23-25 October, 7 pages, 2006  Lamport, L., R. Shostak and M. Pease. 1982. The Byzantine Generals Problem. ACM Transactions on Programming Languages and Systems, 4\(3  Lawless, J. F. 2003. Statistical models and methods for lifetime data. John Wiley &amp; Sons. 2nd ed  Line, J. K., Iyer, A. 2007. Electronic Prognostics Through Advanced Modeling Techniques. Aerospace Conference 2007 IEEE. DOI:10.1109/AERO.2007.352906  Lisnianski, A., Levitin, G. 2003. Multi-State System Reliability: Assessment, Optimization and Applications World Scientific  Liu, Y., and K. S. Trivedi. 2006. Survivability Quantification: The Analytical Modeling Approach, Int. J of Performability Engineering, Vol. 2, No 1, pp. 29-44  19 Luchinsky, D.G.; Osipov, V.V.; Smelyanskiy, V.N Timucin, D.A.; Uckun, S. 2008. Model Based IVHM System for the Solid Rocket Booster. Aerospace Conference, 2008 IEEE.DOI:10.1109/AERO.2008.4526644  Lynch, N. 1997. Distributed Algorithms. Morgan Kaufmann Press  Ma, Z. S. 1997. Demography and survival analysis of Russian wheat aphid. Ph.D. dissertation, Univ. of Idaho 306pp  Ma, Z. S. 2008a. New Approaches to Reliability and Survivability with Survival Analysis, Dynamic Hybrid Fault Models, and Evolutionary  Game Theory. Ph.D. dissertation Univ. of Idaho. 177pp  Ma, Z. S. 2008b. Survivability Analysis of Biological Species under Global Climate Changes: A New Distributed and Agent-based Simulation Architecture with Survival Analysis and Evolutionary Game Theory. The Sixth 


International Conference on Ecological Informatics. Dec 25, 2008. Cancun, Mexico  Ma, Z. S. and E. J. Bechinski. 2008. A Survival-Analysis based  Simulation Model for Russian Wheat Aphid Population Dynamics. Ecological Modeling, 216\(2 332  Ma, Z. S. and A. W. Krings. 2008a.  Survival Analysis Approach to Reliability Analysis and Prognostics and Health Management \(PHM  AIAA AeroSpace Conference, March 1-8, 2008, Big Sky, MT, 20pp  Ma, Z. S. and A. W. Krings. 2008b. Competing Risks Analysis of Reliability, Survivability, and Prognostics and Health Management \(PHM  AIAA AeroSpace Conference, March 1-8, 2008.  Big Sky, MT. 20pp  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(I Dependence Modeling", Proc. IEEE  AIAA AeroSpace Conference, March 1-8, 2008, Big Sky, MT. 21pp  Ma, Z. S. and A. W. Krings., R. E. Hiromoto. 2008d Multivariate Survival Analysis \(II State Models in Biomedicine and Engineering Reliability IEEE International Conference of Biomedical Engineering and Informatics, BMEI 2008.  6 Pages  Ma, Z. S. and A. W. Krings. 2008e. Dynamic Hybrid Fault Models and their Applications to Wireless Sensor Networks WSNs Modeling, Analysis and Simulation of Wireless and Mobile Systems. \(ACM MSWiM 2008 Vancouver, Canada  Ma, Z. S. &amp; A. W. Krings. 2008f. Dynamic Populations in Genetic Algorithms. SIGAPP, the 23rd Annual ACM Symposium on Applied Computing, Ceara, Brazil, March 16-20, 2008. 5 Pages  Ma, Z. S. &amp; A. W. Krings. 2008g. Bio-Robustness and Fault Tolerance: A New Perspective on Reliable, Survivable and Evolvable Network Systems, Proc. IEEE  AIAA AeroSpace Conference, March 1-8, Big Sky, MT, 2008. 20 Pages  Ma, Z. S.  and A. W. Krings. 2009. Insect Sensory Systems Inspired Computing and Communications.  Ad Hoc Networks 7\(4  MacConnell, J.H. 2008. Structural Health Management and Structural Design: An Unbridgeable Gap? 2008 IEEE Aerospace Conference, DOI:10.1109/AERO.2008.4526613  MacConnell, J.H. 2007. ISHM &amp; Design: A review of the benefits of the ideal ISHM system. Aerospace Conference 2007 IEEE. DOI:10.1109/AERO.2007.352834  Marshall A. W., I. Olkin. 1967. A Multivariate Exponential Distribution. Journal of the American Statistical Association, 62\(317 Mar., 1967  Martinussen, T. and T. H. Scheike. 2006. Dynamic Regression Models for Survival Data. Springer. 466pp  Mazzuchi, T. A., R. Soyer., and R. V. Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Millar, R.C., Mazzuchi, T.A. &amp; Sarkani, S., 2007. A Survey of Advanced Methods for Analysis and Modeling of 


of Advanced Methods for Analysis and Modeling of Propulsion System", GT2007-27218, ASME Turbo Expo 2007, May 14-17, Montreal, Canada  Millar, Richard C., "Non-parametric Analysis of a Complex Propulsion System Data Base", Ph.D. Dissertation, George Washington University, June 2007  Millar, R. C. 2007. A Systems Engineering Approach to PHM for Military Aircraft Propulsion Systems. Aerospace Conference, 2007 IEEE. DOI:10.1109/AERO.2007.352840  Millar, R. C. 2008.  The Role of Reliability Data Bases in Deploying CBM+, RCM and PHM with TLCSM Aerospace Conference, 2008 IEEE, 1-8 March 2008. Digital Object Identifier: 10.1109/AERO.2008.4526633  Nowak, M. 2006. Evolutionary Dynamics: Exploring the Equations of Life. Harvard University Press. 363pp  Oakes, D. &amp; Dasu, T. 1990. A note on residual life Biometrika 77, 409  10  Pintilie, M. 2006. Competing Risks: A Practical Perspective.  Wiley. 224pp  20 Smith, M. J., C. S. Byington. 2006. Layered Classification for Improved Diagnostic Isolation in Drivetrain Components. 2006 IEEE AeroSpace Conference  Therneau, T. and P. Grambsch. 2000. Modeling Survival Data: Extending the Cox Model. Springer  Vincent, T. L. and J. L. Brown. 2005. Evolutionary Game Theory, Natural Selection and Darwinian Dynamics Cambridge University Press. 382pp  Wang. J., T. Yu, W. Wang. 2008. Research on Prognostic Health Management \(PHM on Flight Data. 2008 Int. Conf. on Condition Monitoring and Diagnosis, Beijing, China, April 21-24, 2008. 5pp  Zhang, S., R. Kang, X. He, and M. G. Pecht. 2008. China  s Efforts in Prognostics and Health Management. IEEE Trans. on Components and Packaging Technologies 31\(2             BIOGRAPHY  Zhanshan \(Sam scientist and earned the terminal degrees in both fields in 1997 and 2008, respectively. He has published more than 60 peer-refereed journal and conference papers, among which approximately 40 are journal papers and more than a third are in computer science.  Prior to his recent return to academia, he worked as senior network/software engineers in semiconductor and software industry. His current research interests include: reliability, dependability and fault tolerance of distributed and software systems behavioral and cognitive ecology inspired pervasive and 


behavioral and cognitive ecology inspired pervasive and resilient computing; evolutionary &amp; rendezvous search games; evolutionary computation &amp; machine learning bioinformatics &amp; ecoinformatics                 pre></body></html 



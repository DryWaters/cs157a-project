Abstract 
    
a,b a a b b 
Yinan Yu  Tomas McKelvey S.Y Kung 
Kernel SODA A Feature Reduction Technique Using Kernel Based Analysis 
A feature extraction technique called Successively Orthogonal Discriminant Analysis SODA has been recently proposed to overcome the limitation of Linear Discriminant Analysis LDA whose objective is to nd a projection vector such that the projected values of data from both classes 
Signals and Systems Chalmers University of Technology Gothenburg Sweden yinan tomas.mckelvey chalmers.se Electrical Engineering Princeton University Princeton USA yinany kung princeton.edu 
have maximum class separability However in LDA only one such vector can be found due to the rank deìciency for binary classiìcation problems On the other hand as a feature extraction technique the proposed algorithm SODA attempts to obtain a transformation matrix instead of a vector In this paper the kernel version of SODA is presented in both intrinsic space and empirical space To obtain the solution without sacriìcing numerical efìciency we propose a relaxed formulation and data selection for large scale computations Simulations are conducted on 5 data sets from UCI database to verify and evaluated the new approach 
Keywords 
Feature extraction SODA Kernel Discriminant Analysis big data 
I I NTRODUCTION As a solution to the curse of dimensionality feature reduction for classiìcation has been a popular topic for decades There are many reasons why we should care about the dimensionality 1 Overìtting is unevadable for 
high dimensional feature space which might ruin the generalization ability of the classiìer 2 When the number of variables is too large high storage capacity is required and computational complexity is yet another issue 3 In many cases high dimensionality causes computational instability and singularity 4 Class separability is v ery lik ely to be enhanced by eliminating redundant information There are two types feature reduction techniques feature selection and feature extraction Feature selection is to select a subset of the variables with respect to some criteria On the other hand feature extraction attempts to nd a function R R R R 
002 
  
m k m 
f x 
 which transforms data from the original space to a low dimensional feature space 
k 
 where  In this paper we focus on the development of a feature extraction technique for classiìcation The proposed approach is the kernel extension of a previously presented technique called Successively Orthogonal Discriminant Analysis SODA The original technique is closely related to Linear Discriminant Analysis LDA and Principal Component Analysis PCA 6 The paper is organized as follows Section II reviews the relation between LDA PCA and SODA Section III presents the formulations of Kernel SODA in both intrinsic space and empirical space For simple numerical implementations a relaxed KSODA algorithm is developed in Section IV The experimental results are shown in the last section to verify the proposed technique II R ELATED W ORK Linear Discriminant Analysis LDA has a very long history The underlying idea is based on Fisher criteria for 
A Linear Discriminant Analysis LDA 
m>k 
003  X    
   1 
maximizing the class separability Given class label 
c c 1 c N c B W W 
c    N  
and training data  the class separability is measured using the between-class scatter matrix and the within-class scatter matrix  which are respectively deìned as 
x x S S S 
x  x  x  x  
i 1 i i T N  002 j 1 j j 
    
    N      
N  002     1    
   
     
T B T T B 
            J 
1 where and are the mean vector estimated from the corresponding class and  In LDA we would like to nd a vector that maximizes the following Fisher score 
S w w S w 
  
w 
T W B W W 
 002 
2 and the solution vector is the generalized eigenvector corresponding to the largest generalized eigenvalue of the problem  However problems occur when the within matrix is singular There are many ways of tackling this problem 8 and one w ay is to compute the eigenvector of the Fisher matrix  We will adopt this method in this paper 
S w S w S w S F S W  S B 
2013 12th International Conference on Machine Learning and Applications 978-0-7695-5144-9/13 $26.00 © 2013 IEEE DOI 10.1109/ICMLA.2013.20 72 
2013 12th International Conference on Machine Learning and Applications 978-0-7695-5144-9/13 $31.00 © 2013 IEEE DOI 10.1109/ICMLA.2013.20 72 
2013 12th International Conference on Machine Learning and Applications 978-0-7695-5144-9/13 $31.00 © 2013 IEEE DOI 10.1109/ICMLA.2013.20 72 
2013 12th International Conference on Machine Learning and Applications 978-0-7695-5144-9/13 $31.00 © 2013 IEEE DOI 10.1109/ICMLA.2013.20 72 


003 004 003 004 003 004 002 002 002 003 004 
1 1 1 1 1 1 1    1 1 1 1 1 
 004 003 002  002 R 004 003 002 002  003       002 R 004 003 002 002 002 
k T i i i i  T i i i T T k m k T i B i T i W i i i  T i i i W W W T k c 002 B 002 W 002 B 002 002  002 002  002 W c 002   c N c j c j 002 c c j 002 c 002 c c N c j c j k J k T i 002 B i T i 002 W i i i  T i i i 002 W 002 W 002 W T 
w i w i u i 
    C C 003 003 003 003   c  N c N 003 003  N 003  003 003  003 
One of the most famous dimensionality reduction techniques is the Principal Component Analysis PCA which nds the subspace with the largest variation PCA can be formulated in an iterative fashion Namely we are trying to nd a matrix whose columns satisfy maximize subject to Span 3 where is the covariance matrix of the training data and Span denotes the range space of matrix  When the dimensionality of the data vector is high PCA can be implemented iteratively without computing the covariance matrix  The solution of PCA pro vides a transformation matrix that projects the data to a low dimensional subspace where the data representation is enhanced The data vector in the principal component space is thus represented as 4 Successively Orthogonal Discriminant Analysis SODA integrates the ideas of LDA and PCA Deìned as a successive approach SODA adopts the Fisher discriminant score as its objective function for each iteration The output of SODA is a transformation matrix that projects the data onto a new feature space with enhanced class separability Similarities and differences of LDA PCA and SODA can be found in Table I The formulation of SODA is illustrated as follows SODA formulation  5 Similarly the resulting data vector is mapped to a reduced feature space 6 SODA and PCA share the same concept of optimal subspace projection PCAês optimality enjoys the advantage of having a global criterion however it does not take into account of teacherês information On the other hand SODA takes full account of teacherês information but its optimality is formulated and executed step by step Both PCA and LDA have their kernelized variance called KPCA and KDA This motivates us to extend SODA to its kernel model The existing feature reduction techniques based on discriminant analysis mostly depend on the number of classes  For binary classiìcation problem e  due to rank deìciency a transformation matrix can not be found On the other hand SODA overcomes this limitation by modifying the searching space More details can be found in later sections III T HEORY OF KERNEL SODA In kernel based analysis we deìne a function  which maps the data vector from the original space to intrinsic space to obtain a better separation KSODA can be formulated in the intrinsic space with an explicit expression of  The transformation matrix is denoted by in the intrinsic space Let denote the class label and the total training size of class  we can deìne the between-class scatter matrix and within-class scatter matrix in the intrinsic space as follows 8 where 9 KSODA intrinsic space  10 In this case the data vector is transformed in the following way 11 Note that after the transformation  the SODA algorithm can be applied directly 
W w w w Sw w w w w w S S XX S S S x W x W w w w S w w S w w w w w w S S S x W x x x x U u u S S S m m m m S m m m x U u u u S u u S u u u u u u S S S x x U x x x 
B Principal Component Analysis PCA C Successively Orthogonal Discriminant Analysis The matrix deìnes a map R  whose columns satisfy maximize subject to Span where Span denotes the range space of matrix  A KSODA in Intrinsic Space The matrix deìnes a map R  whose columns satisfy maximize subject to Span where Span denotes the range space of matrix  
T 7 T 
 1       1     2           1     1    1           
73 
73 
73 
73 


          1            0  1                 
     002       
003  003 003 003  003 j i    N  k  k 003  i j  k k  003 k   i k 
m m k m k i N i N j j i,j i N i,j th i i th N T c  c c T c c c j N c N c t j c t c c T c T k T i i T i T i j T i i k T T T i i i T i T i i i i T i i i i i 
003H  H       005 006  002 002   
w W U u u a 002a 002 a a u U U 002A A a a M N M M M M M N K I E K M M x x K K 002 002 E x 002 x a a a Ma a i Na a Ka a Ka U U 002 a a x x A x U x A x Q N D K 003 M M a a Q 003 003 Q KQ 003 D D a a Q Q D ND 
LDA PCA SODA Type Classiìer Feature Reduction Feature Reduction Output Purpose Enhance Class Separability Enhance Data Description Enhance Class Separability Objective Function Direct Direct Successive Implementation Direct Direct  Iterative Iterative Table I T HE RELATION BETWEEN LDA PCA AND SODA When the Gaussian RBF kernel is adopted the dimension of the intrinsic space is inìnity and hence computations can not be carried out directly In this case it is necessary to resort to a kernel learning model proposed below From the theory of Reproducing Kernel Hilbert Space RKHS 13 14 each v ector can be written as a linear combination of all the training data drawn from  e we have 12 where is the training data matrix the scalar is the element of vector  Similar to the SODA formulation vector is the column of the transformation matrix that can be written as 13 where As a result of plugging Equation 12 into Equation 10 deìne matrices and  14 and 15 where the row vectors of are written as  Matrix denotes the kernel matrix and is a matrix with all ones as its entries This leads to an equivalent Kernel SODA learning model in the empirical space Denote  we formulate KSODA in the empirical space as KSODA empirical space  16 Therefore in the empirical space the transformation follows 17 Equivalence The empirical formulation is a direct result of kernelization of the intrinsic formulation whose equivalence is straightforward e  IV I MPLEMENTATION AND APPROXIMATION For userês choice we describe two variance of kernelized SODA learning models There are two major steps involved in the algorithm Initialization 18 Step 1 Computing and normalization 19 Step 2 Let  update according to 20 Go to Step 1 until  For numerical efìciency we introduce two approximation strategies Relaxation on orthogonality condition Data selection for big data scenario and the purpose of numerical invertibility They are elaborated below 
002 003 004 003 004 002 005 003 004 006 
1 1 1 1    1 1 1 1 0  0          1    1  1  1  1 
B KSODA in Empirical Space Find optimal vectors  such that maximize a i subject to The optimal transformation matrix can be written as A KSODA implementation B Approximation 
74 
74 
74 
74 


 0   j 1      003     007    1 k  002      007     002 002  003 003 1   003 003   j  1 0  5 4 
1 1 1  0 1 0             1    1    1 3 1  1  1  002 002 
 005 i 006 003       N 007  003  003   003  N  we would like to nd a basis matrix  003 005 l i j with i 006 
a i 
Due to the complexity of the weighted orthogonality constraint we deìne a relaxed formulation called KSODA II 21 22 The optimization problem stated in 21 can be solved by Algorithm KSODA\(II Similar proof can be found in Construct the matrix  Deìne output dimension k  Compute and from Eq 14 and 15 respectively Let For i Solve for where 002 is the largest and only eigenvalue of  Let be the deîation matrix Form matrix Transformation of the features From the RKHS theories the solution vectors can be written as a linear combination of all the training data namely  That means the size of the kernel matrix we have to compute is in the order of the training size N  Furthermore the solution of Formulation KSODA is based on the pseudo-inverse of a N matrix  which results in a N computational complexity To tackle this problem we choose a subset G to approximate the span of the whole training space We call such matrix the basis matrix Note that without ambiguity we use capital letter for the set of some training patterns e.g  and boldface letter for the corresponding matrix e.g  Figure 1 An intuitive illustration of the basis selection If two vectors 002 i An illustrative example can be found in Figure IV-C As we know that similarities between vectors always cause singularity and hence numerical instability Therefore by nding such basis matrix  the robust invertibility of the matrix is enhanced Practically the idea can be implemented as shown in Algorithm Basis  V E XPERIMENTAL R ESULTS In this section we conduct simulations on 5 UCI data sets to compare the classiìcation results using original space PCA Kernel PCA SODA KSODA and KSODA II The classiìer we used is Support Vector Machine SVM with rbf k ernel  005  We also compared the classiìcation results with LDA and Kernel LDA The parameter 005 for the kernel based methods are set to be for consistent and fair comparison The reduced dimensionality for the feature reduction techniques under comparison is k  This is chosen based on cross validation on the data set arcene and then applied to the rest of the data sets 
A KA I a a a Ma a Na a a a a a N N N x 003 a a x X x x M N N N F N M F a a F D I a a N D N D F N M A a a x 003 A K X  x u u 002a N G 002 G G G 004  where 004 is a full rank matrix and G N G 
1 Relaxation on orthogonality Find optimal vectors  such that maximize subject to Span where Span denotes the range space of matrix and the transformed data vector is represented as C Data selection and numerical invertibility 
T k T i i T i T i j T i i i k 004 T k N 010 i i i i i i i m  m i T i i i i  i i i k 010 T i i i N N 004 t  t n 004  such that for some small number 004  T 
i i  x j  002 k  x i  x i  002 k  x j  x j  i,j l,l 004  
KSODA II  Algorithm KSODA\(II Parameter setting 
and 002 j are very similar to each other we assume that the spaces they span are collinear and there is no point to include both of them into the basis matrix G  The similarity measure is naturally deìned by normalizing the kernel function k  x  By excluding similar vectors we could reduce the number of vectors in the basis matrix The idea is described as follows In the intrinsic space given normalized vectors 003 
75 
75 
75 
75 


002 
G 
G c 
Data description Testing method Testing results 
4 
err 
10 4 200 60\(4 208 30\(4 259 18\(4 199 18\(4 219 18\(4 218 18\(4 212 19\(4 330 19\(4 330 19\(4 330 19\(4 330 19\(4 330 19\(4 330 19\(4 330  100 0 5 1  1 2    10000 50 
Data set Dimension Original PCA KPCA LDA KLDA SODA KSODA KSODAII arcene 50 21.67  18.75  37.48 13.81 31.99 15.62  13.63  sonar 27.52 33.89  35.83  27.83 19.88 25.42 20.38  17.43  wdbc 9.17 7.35  5.38  3.84 7.18 3.44 2.44  2.36 vehicle van 3.27 12.23  17.86  2.01 8.42 2.39 1.83  1.51 saab 17.38 26.20  28.19 13.55 18.19 13.97 12.16  10.55 bus 2.23 11.78  10.40 3.21 2.39 3.10 1.92  1.21 opel 17.28 27.53  27.48  13.04 14.43 12.99 11.67  10.34 segment brickface 0.87 6.91 5.96 0.67 1.05 0.62 0.59  0.53 sky 0.25 0.47 0.26 0.21 1.78 0 0 0.01 foliage 2.94 7.69 9.68 4.03 4.91 3.28 2.08  2.05  cement 1.74 8.09 7.46 3.65 4.89 1.83 1.45  1.45 window 3.83 10.20 9.83 4.34 6.77 3.66 3.12  2.46 path 0.42 3.31 5.73 0.60 1.01 0.56 0.33  0.32 grass 0.58 0.37 0.42 0.42 0.21 0.39 0.21  0.19 Table II C LASSIFICATION ERROR COMPARISON BETWEEN DIFFERENT FEATURE REDUCTION TECHNIQUES N OTETHATTHE KSODA IS ALREADY SUBSTANTIAL BETTER THAN SODA H OWEVER  KSODA II OFFERS NOTICEABLE FURTHER IMPROVEMENT OVER KSODA There are another two parameters to choose for Kernel SODA algorithms which are the size of the basis matrix and the tolerant ratio  These selections depend on the capacity of the computational device the kernel parameters and the data properties Here we choose and is selected for each data set by cross-validation The data sets we used are arcene sonar wdbc vehicle and segment The basic properties of the data sets are summarized in Table II Vehicle and segment have more than two classes Since we focus on the study of binary classiìcation in this paper the results shown are based on the averaged error rate of one-versus-one scheme for all classes from the data sets We divide each data set randomly into training set 80 and testing set 20 This procedure is repeated for 10 times Furthermore at the rst time of the tests 20 of the training set is left out for cross validation The classiìcation results in terms of error probabilities shown in Table II are based on the average error of the two classes of misclassiìed testing data in class of testing data in class 25 On 13 out of 14 data sets KSODA\(II has achieved the best classiìcation results in terms of the averaged classiìcation error deìned in Equation 25 First the original space of data set arcene has variables It is obvious that it suffers from overìtting using SVM with rbf kernel which results in a 50 error probability In such scenarios PCA/KPCA with extremely low dimensionality will do an even better job than the original space However when the number of original variables is reasonably small compared to the number of samples PCA/KPCA do not achieve a better performance in general LDA outperforms SVM on original space for roughly cases Since the parameter selection of kernel SVM is a key for high performance LDA enjoys the advantage of simplicity On average SODA/Kernel SODA algorithms give the 
              003 003  
004 N 004   P c c  
76 
76 
76 
76 


003 004 006 
1 2 2 2  K tt  
  010 010 010 010 005 010 010 005 006 
min 
N G G G G G G k ij ij i j t t t t G 
003 
  m N 004 K N k i N i k 006 j k N K K  003 003  i j 003 K  003 t<i 004 i j t  i k j 006 k k k 
G X x x X X X K X x K K x x x x x X X 
Let  construct an empty matrix  Choose a small number as the threshold Choose a kernel function and the size of the basis  Set counter  for Let   for For given kernel function  compute 23 Normalization 24 where is the norm of vector   on intrinsic space if K 002 ij   let and return to   else let  end end Replace the matrix in Algorithm KSODA\(II by  best classiìcation accuracy The reason is that they do not only take into consideration of the class separability on the best one dimensional subspace but also extend the development on dimensions which allow high exibility that LDA does not provide Kernel SODA on the other hand uses the kernel trick to further explore the intrinsic nonlinear structure in the data and therefore results in an even lower classiìcation error rate Examples of visualization for these feature reduction techniques on data sets sonar wdbc vehicle and segment can be found in Figure 1 and 2 VI A CKNOWLEDGMENT This material is based on research sponsored by DARPA under agreement number FA8750-12-2-0126 The U.S Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon This work is also sponsored by the Swedish Research Council VR which is gratefully acknowledged R EFERENCES  Fukumizu K Bach F  R and Jordan M I Dimensionality Reduction for Supervised Learning with Reproducing Kernel Hilbert Spaces 
 The Journal of Machine Learning Research Vol 5 pp 73-99 Jan 2004  Hastie T  T ibshirani R and Friedman J The Elements of Statistical Learning Data Mining Inference and Prediction  Second Edition Springer Feb 2009  Guyon I and Elisseef f A An introduction to variable and feature selection  The Journal of Machine Learning Research vol 3 pp 1157-1182 March 2003  Y u Y  Mck elv e y T  and K ung S.Y  A Classiìcation Scheme for High-Dimensional-Small-Sample-Size Data Using SODA and Ridge-SVM with Microwave Measurement Applications  Proceeding of IEEE International Conference on Acoustics Speech and Signal Processing ICASSP Vancouver Canada May 2013  Duda R.O Hart P E and Stork D.G Pattern Classiìcation  2nd Edition John Wiley  Sons New York 2011  Jollif fe I.T  Principal Component Analysis  Series Springer Series in Statistics 2nd ed Springer 2002  Hoerl A E and K ennard R W   Ridge Regression Biased Estimation for Nonorthogonal Problems Technometrics vol 12 No 1 pp 55-67 Feb 1970  Y ang J and Y ang J Why can LDA be performed in PCA transformed space Pattern Recognition vol 36 no 2,pp 563-566 Feb 2003  Diamantaras K I K ung S.Y  Principal component neural networks theory and applications  John Wiley  Sons 1996  Mika S Ratsch G W eston J Scholk opf B and Mullers K R Fisher discriminant analysis with kernels  Proceedings of the IEEE Signal Processing Society Workshop in Neural Networks for Signal Processing IX pp 41 48 Aug 1999  Nie F  Xiang S Liu Y  Hou C and Zhang C Orthogonal vs uncorrelated least squares discriminant analysis for feature extraction  Pattern Recognition Letters vol 33 pp 485491 2012  Sla v akis K Theodoridis S Y amada I Online classiìcation using kernels and projection-based adaptive algorithms  IEEE Transactions on Signal Processing vol 56\(7 pp 2781-2797 2008  Bouboulis P  and Theodoridis S Extension of Wirtinger Calculus to Reproducing Kernel Hilbert Spaces and the complex kernel LMS  IEEE Transactions on Signal Processing vol 53\(3 pp 964-978 2011  Sla v akis K Bouboulis P  Theodoridis S Online Learning in Reproducing Kernel Spaces  E-reference for Signal Processing Elsevier 2013  K ung S.Y  Kernel Methods and Machine Learning  Cambridge University Press 2013  http://archi v e.ics.uci.edu/ml  Ma vroforakis M Theodoridis S A Geometric Approach to Support Vector Machine SVM Classiìcation  IEEE Transaction on Neural Networks vol 17\(3 pp.671-683 2006 
Algorithm Basis 
 1 1      1                 1 
77 
77 
77 
77 


0.2 0.1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.3 0.2 0.1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 Kernel PCA 0.8 0.6 0.4 0.2 0 0.2 0.4 0.6 0.5 0.4 0.3 0.2 0.1 0 0.1 0.2 0.3 0.4 Linear PCA   2 1 0 1 2 3 4 5 6 x 10 3 0 0.002 0.004 0.006 0.008 0.01 0.012 0.014 Kernel SODA   0.005 0 0.005 0.01 0.015 0.02 0.025 0.03 0.005 0 0.005 0.01 0.015 0.02 0.025 0.03 0.035 Linear SODA   Class +: Training Class ä: Training Class +: Testing Class ä: Testing 0.3 0.2 0.1 0 0.1 0.2 0.3 0.4 0.5 0.4 0.3 0.2 0.1 0 0.1 0.2 0.3 Kernel PCA 0.15 0.1 0.05 0 0.05 0.1 0.15 0.2 0.25 0.3 0.2 0.15 0.1 0.05 0 0.05 0.1 0.15 Linear PCA   7.7254 7.7255 7.7256 7.7257 7.7258 7.7259 7.726 7.7261 7.7262 x 10 4 8.121 8.1215 8.122 8.1225 8.123 8.1235 8.124 x 10 4 Kernel SODA 5.2 5 4.8 4.6 4.4 4.2 4 x 10 4 6 5.8 5.6 5.4 5.2 5 4.8 4.6 4.4 x 10 4 Linear SODA   Class +: Training Class ä: Training Class +: Testing Class ä: Tesing 
Figure 2 Visualization of the rst two components of data set sonar and wdbc using different feature reduction techniques Figure 3 Visualization of the rst two components of one example from data set vehicle and segment using different feature reduction techniques 
0.5 0.4 0.3 0.2 0.1 0 0.1 0.2 0.3 0.4 0.5 0.45 0.4 0.35 0.3 0.25 0.2 0.15 0.1 0.05 Kernel PCA 0.4 0.3 0.2 0.1 0 0.1 0.2 0.3 0.15 0.1 0.05 0 0.05 0.1 Linear PCA   6.85 6.8 6.75 6.7 6.65 6.6 6.55 6.5 6.45 6.4 6.35 x 10 5 8 7.9 7.8 7.7 7.6 7.5 7.4 7.3 7.2 7.1 7 x 10 5 Kernel SODA 0.06 0.055 0.05 0.045 0.04 0.035 0.03 0.035 0.03 0.025 0.02 0.015 0.01 Linear SODA   Class +: Training Class ä: Training Class +: Testing Class ä: Testing 1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 0.4 0.2 0 0.2 0.4 0.6 0.8 1 Kernel PCA 0.8 0.6 0.4 0.2 0 0.2 0.4 0.6 0.8 0.6 0.4 0.2 0 0.2 0.4 0.6 Linear PCA 1.524 1.5235 1.523 1.5225 1.522 1.5215 1.521 1.5205 1.52 1.5195 x 10 3 2.643 2.644 2.645 2.646 2.647 2.648 2.649 x 10 3 Kernel SODA   0.005 0.01 0.015 0.02 0.025 0.004 0.006 0.008 0.01 0.012 0.014 0.016 0.018 0.02 0.022 Linear SODA   Class +, Training Class ä, Training Class +, Testing Class ä, Testing 
78 
78 
78 
78 


user is reached a trigger is red Our platform supports this kind of approaches being build as a framework for developers not as a stand alone application like Google Now or Microsoft On X  VI C ONCLUSIONS AND F URTHER W ORK With the advent of mobile devices such as smartphones and tablets that contain various types of sensors like GPS compass microphone camera proximity sensors etc the shape of context-aware or pervasive systems changed Previously context was only collected from static sensor networks where each sensor had a well-deìned purpose and the format of the data returned was well-known in advance and could not change regardless of any factors Nowadays mobile devices are equipped with multimodal sensing capabilities and the sensor networks have a much more dynamic behavior due to the high levels of mobility and heterogeneity Context Aware Framework is designed to support such requirements In a pervasive world where the environment is saturated with all kinds of sensors and networking capabilities support is needed for dynamic discovery of and efìcient access to context sources of information Such requirements are mediated in our case through a dedicated context management layer which is responsible for discovering and exchanging context information We presented the context storage system architecture for data management that includes an additional set of components This supports the mapping between metainformation describing the context and the actual context data stored in BlobSeer data caching and handling requests coming from a distinct set of users or city area and connecting the metadata management layer to context-aware applications In addition we presented a layer that is responsible for creating and accessing the metadata information that describes the context data schema used by a particular application and allows the mobile application to write retrieve and store context data It is also responsible for supporting userês mobility The components support several requirements userês mobility and provisioning of data according to his/her locality real-time guarantees for data provisioning allow efìcient access to the data in terms of speed of access as well as support for complex queries discovery and registration of data sources and access to data using different granularities and scalability VII A CNOWLEDGMENT The research presented in this paper was supported by the INRIA Associated Team DataCloud@work This work was also partially supported by project ERRIC Empowering Romanian Research on Intelligent Information Technologies/FP7REGPOT-2010-1 ID 264207 and by the Sectoral Operational Programme Human Resources Development 20072013 of the Romanian Ministry of Labour Family and Social Protection through the Financial Agreement POSDRU/89/1.5/S/62557 The authors would like to thank Luc Bouge and the entire KerData team The experiments presented in this paper were carried out using the Grid5000/ALADDIN-G5K experimental testbed an initiative of the French Ministry of Research through the ACI GRID incentive action INRIA CNRS RENATER and other contributing partners see http://www.grid5000.fr R EFERENCES  Google no w  Accessed February 9th 2013  Gridê5000 Accessed February 9th 2013  Microsoft onX Accessed February 9th 2013  San francisco taxi dataset http://crawdad.cs.dartmouth.edu/meta.php name=epî/mobility   A M Aly  A Sallam B M Gnanasekaran L.-V  Nguyen-Dinh W G Aref M Ouzzani and A Ghafoor M3 Stream processing on main-memory mapreduce In 
  
Proceedings of the 2012 IEEE 28th International Conference on Data Engineering Proceedings of the 2011 International Conference on P2P Parallel Grid Cloud and Internet Computing ACM Trans Database Syst Proceedings of the 2011 International Conference on Cloud and Service Computing Proceedings of the 2009 EDBT/ICDT Workshops 
 ICDE 12 pages 1253 1256 Washington DC USA 2012 IEEE Computer Society  C Dobre Capim A platform for conte xt-a w are computing In  3PGCIC 11 pages 266Ö272 Washington DC USA 2011 IEEE Computer Society  T  M Ghanem A K Elmagarmid P A Larson and W  G Aref Supporting views in data stream management systems  35\(1 Feb 2008  R Hecht and S Jablonski Nosql e v aluation A use case oriented surv e y  In  CSC 11 pages 336Ö341 Washington DC USA 2011 IEEE Computer Society  S L Kiani A Anjum M Knappme yer  N Bessis and N Antonopoulos Federated broker system for pervasive context provisioning 2012  B Nicolae G Antoniu and L Boug  e Blobseer how to enable efìcient versioning for large object storage under heavy access concurrency In  EDBT/ICDT 09 pages 18Ö25 New York NY USA 2009 ACM  D P  P  Pïïkknen Report on scalability of database technologies for entertainment services http://virtual.vtt.ì/virtual nextmedia/Deliverables-2011/D1.2.3.3 MUMUMESE Report 20on%20Scalability%20of%20database%20technologies%20for 20entertainment%20services.pdf  2012 
100 
100 


  9  A X    S C H EM A TI C E S U M M A R Y O F M A JO R H ELI O LI B I N TER F A C ES     H ELI O LI B ES  S Y N TA C TI C  I N TER F A C ES   enum  DataType     OBJECT  DOUBLE  S TRING  TIME  VECTORIJK    Indexable R   R get int  index   public  int  size    DataArray<T extends  Indexable<T     DataIdentity getIdentity   DataType getType   MaplikeMetadata getMetadata    Table   String getName   IMaplikeMetada ta getTableMetadata   int  getNumCols   DataArray<?> getColumn int  i     TableWithTime extends  Table     int  getTimeArrayIndexForColumn int  dataColIndex    TableWithDetailedTime extends  TableWithTime     int  getMeasurementWindowColIndex int  data ColIndex   int  getExposureTimeColIndex int  dataColIndex   ITimeSystem<?> getTimeSystem     MagneticFieldData extends  TableWithDetailedTime     MagColIndices getMagColIndices   MagDatasetContentInfo getDatasetContentInfo    


  10  RE P RE S E NT AT I V E  H B S NCE C  IN T E R F A C E S   MA G N E T I C  F I E L D  D A T A   MagDatasetContentInfo extends  CoordFrameSrc     boolean  hasBTotal   boolean  hasBTotalUncertainty   boolean  hasBVector\(ICoordFrame frame   boolean  hasBVectorUncertainties\(ICoordFrame fram e   String getDataSetName    MagneticFieldData extends  TableWithDetailedTime     MagColIndices getMagColIndices   MagDatasetContentInfo getDatasetContentInfo     EN ERG ET I C  PART I C L E D AT A   PChannelInfo     String getParameterKey   String get Name   String getDescription   Set<IParticleCalibration> getCalibrations   IParticleSpecies getSpecies   IParticleChannelBounds getBounds   IFOVKey getFOVKey    ParticleInfoSrc extends  ICoordFrameSrc     int  getNumChannels   IPCh annelInfo getChannelInfo int  chnlIdx   String getDataName   ISpectralInfo getSpectralInfo    ParticleData extends  TableWithDetailedTime, ParticleInfoSrc     int  getValueColumnIndexForChannel int  channelIndex, ParticleCalibration cal   int  getU ncertColumnIndexForChannel int  channelIndex, ParticleCalibration cal  int  getParticleFlowDirectionVec torIJKIndex int  channelIndex, ICoordFrame coordFrame     EVEN T  D AT A h a s  n o  i n t e r f a c e   i t  s  j u s t  a n d   I n f o   i n t e r f a c e  a d d e d  t o  a  T a b l e W i t h T i m e  


  11   CONDUIT  I n te r fac e s   Timestamp  public  abstract  boolean  hasTimestamp  public  abstract  TSEpoch getEpoch  boolean  hasMET  public  abstract  MET getMET    PacketHeader extends  Timestamp  int  offsetBytesToCargo   void  movePositionToStartOfNextPacket\(ByteBuff er inputBuffer   int  cargoLength    TelemetryRecord extends  Timestamp   int  getNumFields   Field getField int  fieldNum   Field getField\(String fieldName      TelemetryRecordSource   int  getNumberOfRecords   TelemetryRecord getTelemetryRecord int  recordNum   Object getPacketType this is usually an instrument specific enum  value    Subpacket extends  Comparable<Subpacket>,TelemetryRecordSource   IPacketHeader getIPacketHeader       


   12 The scenario tests are designed through a process o f grouping the FM requirements into sequences. The pr ocess is performed using a requirements-to-test allocatio n matrix in which each requirement is assigned to a test or group of tests The selection of which tests form the incomp ressible test suite is performed through consultation and it eration of the core test list with the systems engineering tea m Following the allocation of all requirements to the  various tests, individual test plans are developed that inc lude a set of starting conditions and high-level outline of test and verification activities. Each test plan includes th e following information test name document number tier desig nation test objective, requirements fully or partially ver ified by the test, minimum spacecraft component set required to run the test, initial conditions for the test, required sup port, planning notes, and the high-level test outline   Figure 12 shows the activity flow for each scenario  test during the system-level test phase  Following the development of the system-level verification and te st plan individual test procedures are generated for each t est. A test procedure is a configuration managed document that describes the detailed information necessary to run  the test on the spacecraft and the list of steps taken to ex ecute the test. The test procedure is also the as-run documen t used by the test conductor or FM lead engineer to document the major milestones of the test When possible the te st procedure will be dry run on the high-fidelity simu lators to identify and correct procedural errors. The test pr ocedure is then executed on the observatory during I&T \(eventu ally the procedure is run on both spacecraft Any deviation s from the test procedure are documented within the test p rocedure as red lines \(i.e., permanent changes to the test p rocedure\ or black lines i.e changes for the current procedur e If the test fails due to test procedure errors the test p rocedure is corrected and the process is repeated However if the test fails due to an implementation error in flight hard ware flight software or autonomy a formal discrepancy is documented in the Anomaly/Problem Failure Reporting  APFR system any changes or corrections to autono my flight software, or hardware are implemented and th e test is re-run until the anomaly is resolved and the test r uns to successful completion After the completion of each  test a review of the test procedure as-run information a nd spacecraft data is performed by a member of the FM team Following the review of the test data, the FM lead engineer signs the test procedure confirming that the test w as run and the review accurately described the success or fail ure of the test  n	\r\n\n  n        n   n\r     n r\r\n\r r\n\r r\r\n\r    0/-1  23  n  4      Figure 12:  Fault Protection System-Level Test Proc ess Flow 4  CONCLUSION The RBSP spacecraft are designed to operate for mul tiple years in the extreme environment of the Earthís rad iation belts.  To facilitate this mission, a robust fault management system is integrated into the system architecture f rom the earliest stages of the design.  This fault manageme nt system was rigorously tested during I&T and the results o f this testing show that the RBSP spacecraft are protected against on-orbit fault conditions and therefore have a hig h probability of meeting the mission objectives  The  RBSP fault management design, implementation and test ap proach demonstrate that robust fault-tolerant designs are  achievable for complex systems operating in harsh environments even for systems with only limited or  selective redundancy 5  REFERENCES  1  J   S t r a t t o n  a n d  N   F o x   R a d i a t i o n  B e l t  S t o r m  P robes RBSP\ Mission Overview Proc. of the 2012 IEEE Aerospace Conf. Vol. 027 No. xxx Big Sky, Montana USA, March 2012. The Johns Hopkins University Applied Physics Laboratory, Laurel, MD 20723   2  K   K i r b y  e t  a l   R a d i a t i o n  B e l t  S t o r m  P r o b e s   R B SP Spacecraft and impact of environment on observatory  design Proc. of the 2012  IEEE Aerospace Conf.,Vol  027 No. 1759 Big Sky, Montana, USA, March 2012 The Johns Hopkins University Applied Physics Laboratory, Laurel, MD 20723  


WeD6 \226 Queuing Theory Visitor Center   Chair Starobinski, David Boston University On the Channel-Sensitive Delay Behavior of LIFO-Backpressure 715  Si, Wei Boston University  Starobinski, David Boston University  Transient Flow Level Models for In terference-Coupled Cellular Networks 723  326hmann, David Technische Universit\344t Dresden  Fehske, Albrecht Technische Universit\344t Dresden  Fettweis, Gerhard Technische Universit\344t Dresden  When do Redundant Requests Reduce Latency 731  Shah, Nihar B University of California, Berkeley  Lee, Kangwook University of California, Berkeley  Ramchandran, Kannan University of California, Berkeley  Scheduling in Cooperative Cognitive Radio Networks 739  Das, Dibakar Rensselaer Polytechnic Institute  Abouzeid, Alhussein A Rensselaer Polytechnic Institute  Codreanu, Marian University of Oulu  Batch Job Scheduling for Reducing Water Footprints in Data Center 747  Ren, Shaolei Florida International University  Bits through Bufferless Queues 755  Tavan, Mehrnaz Rutgers University  Yates, Roy D Rutgers University  Bajwa, Waheed U Rutgers University  ThA1 \226 Information-Theoretic Security Library   Chair Kiyavash, Negar University of Illinois  Organizer\(s Ba ar, Tamer University of Illinois  Kiyavash, Negar University of Illinois Networked Cyber-Physical Systems: Interdep endence, Resilience and Information Exchange 763  Zhu, Quanyan Princeton University  Bushnell, Linda University of Washington  On the Secure Interference Channel 770  Somekh-Baruch, Anelia Bar-Ilan University  How Many Antennas does a Cooperative Jammer Need for Achieving the Degrees of Freedom of Multiple Antenna Gaussian Channels in the Presence of an Eavesdropper 774  Nafea, Mohamed Pennsylvania State University  Yener, Aylin Pennsylvania State University  Distributed Consensus with Byzantine Adversaries n/a  Liu, Xiangyang University of Maryland  Gao, Peixin University of Maryland  Baras, John University of Maryland  


Why Cyber-Insurance Contracts Fail to Reflect Cyber-Risks 781  Schwartz, Galina University of California, Berkeley  Shetty, Nikhil Insieme Networks  Walrand, Jean University of California, Berkeley  Performance-Aware IP Address Randomi zation in Moving Target Defense n/a  Clark, Andrew University of Washington  Sun, Kun George Mason University  Poovendran, Radha University of Washington  ThA2 \226 Distributed Stor age: Theory and Practice Solarium   Chair Milenkovic, Olgica University of Illinois  Organizer\(s Dimakis, Alex University of Texas, Austin  Milenkovic, Olgica University of Illinois Explicit Maximally Recoverable Codes with Locality n/a  Gopalan, Parikshit Microsoft Research  Huang, Cheng Microsoft Research  Jenkins, Bob Microsoft Research  Yekhanin, Sergey Microsoft Research  On the Interior Points of the Storage-Repa ir Bandwidth Tradeoff of Regenerating Codes 788  Sasidharan, Birenjith Indian Institute of Science  Kumar, P. Vijay Indian Institute of Science  A Family of Locally Recoverable Codes n/a  Tamo, Itzhak University of Maryland  Barg, Alexander University of Maryland  Locality and Availability in Distributed Storage n/a  Rawat, Ankit Singh University of Texas, Austin  Papailiopoulos, Dimitris University of Texas, Austin  Dimakis, Alex University of Texas, Austin  Vishwanath, Sriram University of Texas, Austin  Data Secrecy in Distributed Storage Systems under Exact Repair n/a  El Rouayheb, Salim Illinois Institute of Technology, Chicago  Goparaju, Sreechakra Princeton University  Poor, H. Vincent Princeton University  Calderbank, A. Robert Duke University  LRC Erasure Coding in Windows Storage: From Cloud to Desktop n/a  Huang, Cheng Microsoft Research  ThA3 \226 Information Theory II Butternut   Chair  Walsh, John MacLaren Drexel University Matroid Bounds on the Region of Entropic Vectors 796  Li, Congduan Drexel University  Walsh, John MacLaren Drexel University  Weber, Steven Drexel University  


Groups and Information Inequalities in 5 Variables 804  Markin, Nadya Nanyang Technological University  Thomas, Eldho Nanyang Technological University  Oggier, Fr\351d\351rique Nanyang Technological University  Superadditivity of Quantum Channel Coding Rate with Finite Blocklength Quantum Measurements 810  Chung, Hye Won Massachusetts Institute of Technology  Zheng, Lizhong Massachusetts Institute of Technology  Information Rates in the Optica l Nonlinear Phase Noise Channel 818  Dar, Ronen Tel Aviv University  Shtaif, Mark Tel Aviv University  Feder, Meir Tel Aviv University  An Outer Bound of the Capacity Re gion of Biometric Systems under Keys, Secrets, and Privacy Requirements 824  Lai, Po-Hsiang Washington University in Saint Louis  O'Sullivan, Joseph A Washington University in Saint Louis  Generalized Cut-Set Bounds for Broadcast Networks 832  Salimi, Amir Texas A&M University  Liu, Tie Texas A&M University  Cui, Shuguang Texas A&M University  ThA4 \226 Sensor Networks Pine   Chair Scaglione, Anna University of California, Davis How to Sleep, Control and Transfer Data in an Energy Constrained Wireless Sensor Network 839  Venkateswaran, Vijay Alcatel-Lucent Bell Labs  Kennedy, Irwin O Alcatel-Lucent Bell Labs  Network Observability and Localization of the So urce of Diffusion based on a Subset of Nodes 847  Zejnilovic, Sabina Carnegie Mellon University  Gomes, Jo\343o Instituto Superior T\351cnico  Sinopoli, Bruno Carnegie Mellon University  The Central Detection Officer Problem: SALS A Detector and Performance Guarantees 853  Li, Xiao University of California, Davis  Poor, H. Vincent Princeton University  Scaglione, Anna University of California, Davis  A New Graph Model with Random Edge Values: Connectivity and Diameter 861  La, Richard J University of Maryland, College Park  Kabkab, Maya University of Maryland, College Park  


ThA5 \226 Source Coding Lower Level   Chair Cohen, Asaf Ben-Gurion University Correlated Sources with Actions 869  Sabag, Oron Ben Gurion University  Permuter, Haim H Ben Gurion University  Cohen, Asaf Ben Gurion University  Non-Asymptotic Bounds on Fixed Leng th Source Coding for Markov Chains 875  Hayashi, Masahito Nagoya University  Watanabe, Shun University of Tokushima  Efficient Similarity Queri es via Lossy Compression 883  Ochoa, Idoia Stanford University  Ingber, Amir Stanford University  Weissman, Tsachy Stanford University  Results on the Optimal Memory-Assisted Univer sal Compression Performance for Mixture Sources 890  Beirami, Ahmad Georgia Institute of Technology  Sardari, Mohsen Georgia Institute of Technology  Fekri, Faramarz Georgia Institute of Technology  Interactive Function Computation with Reconstruction Constraints 896  Ebrahim Rezagah, Farideh Polytechnic Institute of New York University  Erkip, Elza Polytechnic Institute of New York University  Distortion Rate Function of Sub-Nyquist Sa mpled Gaussian Sources Corrupted by Noise 901  Kipnis, Alon Stanford University  Goldsmith, Andrea J Stanford University  Weissman, Tsachy Stanford University  Eldar, Yonina C Technion - Israel Institute of Technology  ThB1 \226 Dynamic Games Library   Chair Liu, Mingyan University of Michigan Joint Control of Transmission Power and Channel Switching against Adaptive Jamming 909  Wang, Qingsi University of Michigan  Liu, Mingyan University of Michigan  Characterization and Computation of Loca l Nash Equilibria in Continuous Games 917  Ratliff, Lillian J University of California, Berkeley  Burden, Samuel A University of California, Berkeley  Sastry, S. Shankar University of California, Berkeley  Multiagent Inverse Reinforcement Learni ng for Zero-Sum Stochastic Games n/a  Beling, Peter University of Virginia  Cogill, Randy University of Virginia  Lin, Xiaomin University of Virginia  A Dynamic VCG Mechanism for Random Allocation Spaces 925  Balandat, Maximilian University of California, Berkeley  Tomlin, Claire J University of California, Berkeley  


Nonstationary Resource Sharing with Imperfect Binary Feedback An Optimal Design Framework for Cost Minimization 932  Xiao, Yuanzhang University of California, Los Angeles  van der Schaar, Mihaela University of California, Los Angeles  ThB2 \226 Topics in Information Theory III Solarium   Chair Viswanath, Pramod University of Illinois  Organizer\(s Viswanath, Pramod University of Illinois  De Novo RNA Shotgun Sequencing: Fundamental Limits n/a  Kannan, Sreeram University of Illinois  Pachter, Lior University of California, Berkeley  Tse, David University of California, Berkeley  Queue Length as an Implicit Communication Channel 940  Park, Se Yong University of California, Berkeley  Sahai, Anant University of California, Berkeley  Polytope Codes for Large-Alphabet Channels 948  Fan, Xiaoqing Cornell University  Wagner, Aaron B Cornell University  Ahmed, Ebad LSI Corporation  Data-Driven Management of Infrastructure Networks n/a  Rajagopal, Ram Stanford University A Derivation of the Asymptotic Random-Coding Prefactor 956  Scarlett, Jonathan University of Cambridge  Martinez, Alfonso Universitat Pompeu Fabra  Guill\351n i F\340bregas, Albert ICREA and Universitat Pompeu Fabra  ThB3 \226 Discrete Event Systems Butternut   Chair  Tarraf, Danielle C Johns Hopkins University On Exploiting Algebraic Structure in Control of Finite State Machines 962  Tarraf, Danielle C Johns Hopkins University  A Bridge between Decentralized and Coordination Control 966  Komenda, Jan Czech Academy of Sciences  Masopust, Tom\341\232 Czech Academy of Sciences  A Model Checking Framework for Linear Time Invariant Switching Systems using Structural Systems Analysis 973  Ramos, Guilherme Instituto Superior T\351cnico  Pequito, S\351rgio Carnegie Mellon University and Instituto Superior T\351cnico  Aguiar, A. Pedro University of Porto  Ramos, Jaime Instituto Superior T\351cnico  Kar, Soummya Carnegie Mellon University  


Robust Supervisory Control of Ne tworked Discrete Event Systems 981  Wang, Fei Tongji University  Shu, Shaolong Tongji University  Lin, Feng Wayne State University  Probability Bounds for False Alarm Anal ysis of Fault Detection Systems 989  Hu, Bin University of Minnesota  Seiler, Peter University of Minnesota  ThB4 \226 Network Inference Pine   Chair Sanghavi, Sujay University of Texas, Austin  Organizer\(s Kiyavash, Negar University of Illinois  Sanghavi, Sujay University of Texas, Austin Robust Structure Estimation of M aximum Causal Entropy Processes 996  Ziebart, Brian D University of Illinois, Chicago  The Squared-Error of Generalized LASSO: A Precise Analysis 1002  Oymak, Samet California Institute of Technology  Thrampoulidis, Christos California Institute of Technology  Hassibi, Babak California Institute of Technology  Localized Minimax Complexity of Stochastic Convex Optimization n/a  Zhu, Yuancheng University of Chicago  Lafferty, John University of Chicago  Non-Convex Inference via Alternatin g Minimization: Provable Guarantees n/a  Sanghavi, Sujay University of Texas, Austin  Loop Calculus and Bootstrap-Belief Propagatio n for Perfect Matchings on Arbitrary Graphs n/a  Chertkov, Michael Los Alamos National Laboratory  Gelfand, Andrew University of California, Irvine  Shin, Jinwoo Massachusetts Institute of Technology  ThB5 \226 Control and Optimization Problems in Electrical Energy Systems I Lower Level   Chair Dominguez-Garcia, Alejandro University of Illinois  Organizer\(s Dominguez-Garcia, Alejandro University of Illinois  A Rank Minimization Algorithm to Enhance Semidefinite Rel axations of Optimal Power Flow 1010  Louca, Raphael Cornell University  Seiler, Peter University of Minnesota  Bitar, Eilyan Cornell University  Power System Structure and Confidenti ality Preserving Transformation of Optimal Power Flow Model 102 1  Borden, Alexander R University of Wisconsin, Madison  Molzahn, Daniel K University of Michigan  Lesieutre, Bernard C University of Wisconsin, Madison  Ramanathan, Parmeswaran University of Wisconsin, Madison  


Incentive Design for Direct Load Control Programs 1029  Alizadeh, Mahnoosh University of California, Davis  Xiao, Yuanzhang University of California, Los Angeles  Scaglione, Anna University of California, Davis  van der Schaar, Mihaela University of California, Los Angeles  Energy Positioning: Control and Economics \226 Part 1 n/a  Kirschen, Daniel University of Washington  Hiskens, Ian University of Michigan  Pandzic, Hrvoje University of Washington  Qiu, Ting University of Washington  Wang, Yishen University of Washington  Energy Positioning: Control and Economics \226 Part 2 n/a  Hiskens, Ian University of Michigan  Kirschen, Daniel University of Washington  Xue, Mengran University of Michigan  Almassalkhi, Mads Root3 Technologies Ltd  Felder, Jennifer University of Michigan  The Redistribution of Power Flow in Cascading Failures 1037  Lai, Chengdi California Institute of Technology  Low, Steven H California Institute of Technology  ThB6 \226 Multiuser Detecti on and Estimation Theory Visitor Center   Chair Chowdhury, Mainak Stanford University Phase and Power Estimation for Per-Hop MultiUser Detection in Frequency-Hopping Systems 1045  Qiu, David MIT Lincoln Laboratory  Royster, Thomas C MIT Lincoln Laboratory  Block, Frederick J MIT Lincoln Laboratory  Non-Coherent Multi-User Detection of DPSK Signals after Differential Demodulation 1052  Qiu, David MIT Lincoln Laboratory  Block, Frederick J MIT Lincoln Laboratory  The Incidence and Cross Methods for Efficient Radar Detection 1059  Fish, Alexander University of Sydney  Gurevich, Shamgar University of Wisconsin, Madison  Capacity Analysis of Uplink Multi-User SC-FDMA System with Frequency-Dependent I/Q Imbalance 1067  Ishaque, Aamir RWTH Aachen University  Sakulkar, Pranav RWTH Aachen University  Ascheid, Gerd RWTH Aachen University  Reliable Uncoded Communication in th e Underdetermined SIMO MAC with Low-Complexity Decoding 1 075  Chowdhury, Mainak Stanford University  Goldsmith, Andrea Stanford University  Weissman, Tsachy Stanford University  


ThC1 \226 Networks, Ga mes and Algorithms III Library   Chair  Williams, Steven R University of Illinois  Organizer\(s Hajek, Bruce University of Illinois  Srikant, R University of Illinois Competitive Equilibrium in Electricity Markets wi th Heterogeneous users and Ramping Constraints n/a  Malekian, Azarakhsh Massachusetts Institute of Technology  Ozdaglar, Asu Massachusetts Institute of Technology  Wei, Ermin Massachusetts Institute of Technology  A Lyapunov Optimization Approach to Repeated Stochastic Games 1082  Neely, Michael J University of Southern California  Road Traffic Networks: Optimal Transport and Incentives 1090  Mandayam, Chinmoy V Stanford University  Prabhakar, Balaji Stanford University  Online Stochastic Ad Allocation: Simu ltanenous and Bicriteria Approximations n/a  Mirrokni, Vahab Google Research  A Processor-Sharing Heuristic fo r Multipath Congestion Control n/a  Walton, Neil Stuart University of Amsterdam  Anselmi, Jonatha Basque Center for Applied Mathematics  D'Auria, Bernardo Universidad Carlos III de Madrid  ThC2 \226 Distributed and Controlled Sensing I Solarium   Chair Nedich, Angelia University of Illinois  Organizer\(s Ba ar, Tamer University of Illinois  Nedich, Angelia University of Illinois Veeravalli, Venugopal University of Illinois  Asymptotic Optimality Results for Controlled Sequential Estimation 1098  Atia, George University of Central Florida  Aeron, Shuchin Tufts University  Even Symmetric Parallel Linear Determinis tic Interference Channels are Inseparable 1106  Mukherjee, Pritam University of Maryland  Tandon, Ravi Virginia Polytechnic Institute and State University Ulukus, Sennur University of Maryland  Estimation Over the Collision Channel: Structural Results 1114  Vasconcelos, Marcos M University of Maryland  Martins, Nuno C University of Maryland  Physical Watermarking and Authenti cation in Cyber-Physical Systems n/a  Weerakkody, Sean Carnegie Mellon University  Mo, Yilin California Institute of Technology  Sinopoli, Bruno Carnegie Mellon University  


Distributed Linear Estimation of Dynamic Random Fields 1120  Das, Subhro Carnegie Mellon University  Moura, Jos\351 M.F Carnegie Mellon University  ThC3 \226 Active Learning, Search and Visual Recognition Butternut   Chair Raginsky, Maxim University of Illinois  Co-Chair Lazebnik, Svetlana University of Illinois   Organizer\(s Javidi, Tara University of California, San Diego  Lazebnik, Svetlana University of Illinois Raginsky, Maxim University of Illinois  Working Title: Learning to Recognize Everything n/a  Berg, Alexander C University of North Carolina, Chapel Hill  Visual Attributes for Enhanced Human-Machine Communication 1126  Parikh, Devi Virginia Polytechnic Institute and State University Active Learning of Linear Separators n/a  Balcan, Maria Florina Georgia Institute of Technology  Discriminative Value of Information for Structured Prediction n/a  Taskar, Ben University of Washington  Extrinsic Jensen\226Shannon Divergence and Noisy Bayesian Active Learnin\g 1128  Naghshvar, Mohammad University of California, San Diego  Javidi, Tara University of California, San Diego  Chaudhuri, Kamalika University of California, San Diego  Universal Random Number Generators for Finite Memory Sources n/a  Seroussi, Gadiel Universidad de la Rep\372blica, Uruguay  Weinberger, Marcelo J Center for Science of Information  ThC4 \226 Information Theory III Pine   Chair Avestimehr, Salman Cornell University Approximate Capacity of the Two-User MI SO Broadcast Channel with Delayed CSIT 1136  Vahid, Alireza Cornell University  Maddah-ali, Mohammad Ali Alcatel-Lucent Bell Labs  Avestimehr, A. Salman Cornell University  K-User Symmetric MIMO Distributed Full-D uplex Network via Wireless Side-Channels 1144  Bai, Jingwen Rice University  Dick, Chris Xilinx, Inc  Sabharwal, Ashutosh Rice University  Degrees of Freedom Region for MIMO Interferen ce Channel with Limite d Receiver Cooperation 1152  Ashraphijuo, Mehdi Columbia University  Aggarwal, Vaneet AT&T Labs-Research  Wang, Xiaodong Columbia University  


Degrees of Freedom of the MIMO Rank-Def icient Interference Channel with Feedback 1159  Chae, Sung Ho Korea Advanced Institute of Science and Technology  Suh, Changho Korea Advanced Institute of Science and Technology  Chung, Sae-Young Korea Advanced Institute of Science and Technology  On the Optimality of Trea ting Interference as Noise 1166  Geng, Chunhua University of California, Irvine  Naderializadeh, Navid Cornell University  Avestimehr, A. Salman Cornell University  Jafar, Syed A University of California, Irvine  Asymmetric Compute-and-Forward 1174  Ntranos, Vasilis University of Southern California  Cadambe, Viveck R Massachusetts Institute of Technology  Nazer, Bobak Boston University  Caire, Giuseppe University of Southern California  ThC5 \226 Pricing and Contractive Mechanisms for Wireless Data Services Lower Level   Chair Wang, Qiong University of Illinois  Organizer\(s Andrews, Matthew Alcatel-Lucent Bell Labs  Baryshnikov, Yuliy University of Illinois Wang, Qiong University of Illinois  Smart Data Pricing for the Internet: Agenda & Research Directions 1182  Sen, Soumya University of Minnesota  Market Structures for Wirele ss Service with Shared Spectrum 1188  Berry, Randall Northwestern University  Honig, Michael Northwestern University  Subramanian, Vijay Northwestern University  Nguyen, Thanh Northwestern University  Vohra, Rakesh Northwestern University  Fostering Wireless Spectrum Sharing via Subsidization 1192  Yuksel, Murat University of Nevada, Reno  Quint, Thomas University of Nevada, Reno  Guvenc, Ismail Florida International University  Saad, Walid University of Miami  Kapucu, Naim University of Central Florida  Stable Real-Time Pricing and Sc heduling for Serving Opportunistic users with Deferrable Loads 1200  Dalkilic, Ozgur Ohio State University  Eryilmaz, Atilla Ohio State University  Lin, Xiaojun Purdue University  Implementing Sponsored Conten t in Wireless Data Networks 1208  Andrews, Matthew Alcatel-Lucent Bell Labs  


ThC6 \226 Deletion Codes: Bounds and Applications Visitor Center   Chair Kiyavash, Negar University of Illinois  Organizer\(s Dolecek, Lara University of Califo rnia, Los Angeles  Kiyavash, Negar University of Illinois A Practical Framework for Efficient File Synchronization 1213  Bitouz\351, Nicolas University of California, Los Angeles  Sala, Frederic University of California, Los Angeles  Tabatabaei Yazdi, S.M. Sadegh University of California, Los Angeles  Dolecek, Lara University of California, Los Angeles  An Improvement of the Deletion Channel Capacity Upper Bound 1221  Rahmati, Mojtaba Arizona State University  Duman, Tolga M Arizona State University and Bilkent University  On the Number of Subsequences Obtained via the Deletion Channel n/a  Yuvalal, Liron The Open University of Israel  Langberg, Michael State University of New York, Buffalo Efficient Interactive Algorithms for F ile Synchronization under General Edits 1226  Venkataramanan, Ramji University of Cambridge  Narasimha Swamy, Vasuki University of California, Berkeley  Ramchandran, Kannan University of California, Berkeley  ThD1 \226 Sparse Data Analysis Library   Chair Studer, Christoph Rice University Recovering Sparse Low-Rank Bloc ks in Tandem Mass Spectrometry n/a  Studer, Christoph Rice University  Pope, Graeme ETH Zurich  Navarro, Pedro Johannes Gutenberg University Mainz  Baraniuk, Richard Rice University  GROTESQUE: Noisy Group Testing \(Quick and Efficient 1234  Cai, Sheng The Chinese University of Hong Kong  Jahangoshahi, Mohammad Sharif University of Technology  Bakshi, Mayank Institute of Network Coding  Jaggi, Sidharth The Chinese University of Hong Kong  Compressed Sensing of Streaming Data 1242  Freris, Nikolaos M 311cole Polytechnique F\351d\351rale de Lausanne  326\347al, Orhan 311cole Polytechnique F\351d\351rale de Lausanne  Vetterli, Martin 311cole Polytechnique F\351d\351rale de Lausanne  A Fast Hadamard Transform for Signals with Sub-Linear Sparsity 1250  Scheibler, Robin 311cole Polytechnique F\351d\351rale de Lausanne  Haghighatshoar, Saeid 311cole Polytechnique F\351d\351rale de Lausanne  Vetterli, Martin 311cole Polytechnique F\351d\351rale de Lausanne  


Sample-Optimal Average-Case Sparse Fo urier Transform in Two Dimensions 1258  Ghazi, Badih Massachusetts Institute of Technology  Hassanieh, Haitham Massachusetts Institute of Technology  Indyk, Piotr Massachusetts Institute of Technology  Katabi, Dina Massachusetts Institute of Technology  Price, Eric Massachusetts Institute of Technology  Shi, Lixin Massachusetts Institute of Technology Guarantees of Total Variation Mi nimization for Signal Recovery 1266  Cai, Jian-Feng University of Iowa  Xu, Weiyu University of Iowa  ThD2 \226 Distributed and Controlled Sensing II Solarium   Chair Veeravalli, Venugopal University of Illinois  Organizer\(s Ba ar, Tamer University of Illinois  Nedich, Angelia University of Illinois Veeravalli, Venugopal University of Illinois  Adaptive Stochastic Convex Optimization Over Networks 1272  Towfic, Zaid J University of California, Los Angeles  Sayed, Ali H University of California, Los Angeles  A Routing Problem in a Simple Queueing Syst em with Non-Classical Information Structure 1278  Ouyang, Yi University of Michigan  Teneketzis, Demosthenis University of Michigan  On the Necessary Conditions for Distributed Observability n/a  Doostmohammadian, Mohammadreza Tufts University  Khan, Usman A Tufts University  Sequential Supervised Learning n/a  Wang, Joseph Boston University  Trapeznikov, Kirill Boston University  Saligrama, Venkatesh Boston University  Fusion Center Feedback for Quasi-Decentr alized Estimation in Sensor Networks 1285  Michelusi, Nicol\362 University of Southern California  Mitra, Urbashi University of Southern California  ThD3 \226 Information Theory IV Butternut   Chair Bhashyam, Srikrishna Indian Inst. of Tech, Madras The Gaussian Two-Way Diamond Channel 1292  V, Prathyusha Indian Institute of Technology, Madras  Bhashyam, Srikrishna Indian Institute of Technology, Madras  Thangaraj, Andrew Indian Institute of Technology, Madras  Capacity to within a Constant Gap fo r a Class of Interference Relay Channels 1300  Bassi, Germ\341n Sup\351lec  Piantanida, Pablo Sup\351lec  Yang, Sheng Sup\351lec  


The State-Dependent Broadcast Channel with Cooperation 1307  Dikstein, Lior Ben Gurion University of the Negev  Permuter, Haim H Ben Gurion University of the Negev  Steinberg, Yossef Technion - Israel Institute of Technology An Analysis of the Joint Compute-and-Forward Decoder for the Binary-Input Two-Way Relay Channel 1314  Hern, Brett Texas A&M University  Narayanan, Krishna Texas A&M University  The Generalized Degrees of Freedom of the Int erference Relay Channel with Strong Interference 1321  Gherekhloo, Soheyl Ruhr Universit\344t Bochum  Chaaban, Anas Ruhr Universit\344t Bochum  Sezgin, Aydin Ruhr Universit\344t Bochum  Optimal Jamming Over Additive No ise: Vector Source-Channel Case 1329  Akyol, Emrah University of California, Santa Barbara  Rose, Kenneth University of California, Santa Barbara  ThD4 \226 Control and Optimization Problems in Electrical Energy Systems II Pine   Chair Dominguez-Garcia, Alejandro University of Illinois  Organizer\(s Dominguez-Garcia, Alejandro University of Illinois  Distributed Stopping in Average Consensus via Event-Triggered Strategies 1336  Manitara, Nicolaos University of Cyprus  Hadjicostis, Christoforos N University of Cyprus  Stochastic Models and Control fo r Electrical Power Line Temperature 1344  Bienstock, Daniel Columbia University  Blanchet, Jose Columbia University  Li, Juan Columbia University  Applicability of Topology Control Algorit hms \(TCA\e Power System 1349  Goldis, Evgeniy A Boston University  Li, Xiaoguang Boston University  Caramanis, Michael C Boston University  Keshavamurthy, Bhavana PJM  Patel, Mahendra PJM  Rudkevich, Aleksandr M Newton Energy Group Ruiz, Pablo A  Charles River Associates Retail Pricing for Stochastic Demand with Unknown Parameters An Online Machine Learning Approach 1353  Jia, Liyan Cornell University  Zhao, Qing University of California, Davis  Tong, Lang Cornell University  Virtual Oscillator Control for Voltage Source Inverters 1359  Dhople, Sairaj V University of Minnesota  Johnson, Brian B National Renewable Energy Laboratory  Hamadeh, Abdullah O Rutgers University  


ThD5 \226 Networks, Gam es and Algorithms IV Lower Level   Chair Lu, Yi University of Illinois  Organizer\(s Hajek, Bruce University of Illinois  Srikant, R University of Illinois Contagion and Observability in Security Domains 1364  Bachrach, Yoram Microsoft Research Cambridge Draief, Moez Imperial College  Goyal, Sanjeev University of Cambridge  Targeted Matrix Completion n a  Ruchansky, Natali Boston University  Crovella, Mark Boston University  Terzi, Evimaria Boston University  Random Matrix Theory Approach to Spectral Clustering n/a  Lelarge, Marc INRIA and \311cole Normale Sup\351rieure Optimal Distributed Scheduling in Wirele ss Networks under SINR Interference Model 1372  Chaporkar, P Indian Institute of Technology, Mumbai  Proutiere, A KTH Royal Institute of Technology  Load Balancing with Deadlines and Graph Constraints n/a  Moharir, Sharayu Arun University of Texas, Austin  Sanghavi, Sujay University of Texas, Austin  Shakkottai, Sanjay University of Texas, Austin  Curbing Delays in Datacenters Need Time to Save Time n/a  Alizadeh Attar, Mohammadreza Insieme Networks  Katti, Sachin Stanford University Prabhakar, Balaji Stanford University  ThD6 \226 Topics in Cryptography Vistior Center   Chair Prabhakaran, Manoj University of Illinois  Organizer\(s Duursma, Iwan University of Illinois  Prabhakaran, Manoj University of Illinois How to Encrypt Software  n/a  Sahai, Amit University of California, Los Angeles  On the Cost of Information-Theoretic Cryptography n/a  Ishai, Yuval Technion - Israel Institute of Technology From Unprovability to Environmentally Friendly Protocols n/a  Canetti, Ran Boston University and Tel Aviv University  Lin, Huijia Massachusetts Institute of Technology and Boston University  Pass, Rafael Cornell University  Cryptography, Causality, and Coding n/a  Smith, Adam Pennsylvania State University  


Obfuscation for Evasive Functions n/a  Canetti, Ran Boston University and Tel Aviv University  Bitansky, Nir Tel Aviv University  Barak, Boaz Microsoft Research  Kalai, Yael Microsoft Research  Paneth, Boaz Microsoft Research  Sahai, Amit University of California, Los Angeles FrPP - Plenary Talk:  C odes for the Storage Cloud Library   Chair Ba ar, Tamer University of Illinois Codes for the Storage Cloud n a  Ramchandran, Kannan University of California, Berkeley  FrA1 \226 Wireless Communications II   Chair Duel-Hallen, Alexandra North Carolina State University Small Cell Networks: Speed based Power Allocation 1380  Kavitha, Veeraruna Indian Institute of Technology, Bombay  Capdevielle, Veronique Alcatel-Lucent Bell Labs  Gupta, Manu K Indian Institute of Technology, Bombay  Distributed Power Control in Femto Ce lls using Bayesian Density Tracking 1388  Hanif, Ahmed Farhan Institut Mines-T\351l\351com-T\351l\351com SudParis  Tembine, Hamidou Sup\351lec  Assaad, Mohamad Sup\351lec  Zeghlache, Djamal Institut Mines-T\351l\351com-T\351l\351com SudParis  Renewable Energy Scheduling for Fading Ch annels with Maximum Power Constraint 1394  Wang, Zhe Columbia University  Aggarwal, Vaneet AT&T Labs-Research  Wang, Xiaodong Columbia University  Analysis and Design of Spectrum Sh aring in Cognitive Femtocell Networks 1401  Zhou, Xiangwei Southern Illinois University, Carbondale  Al-Hraishawi, Hayder Southern Illinois University, Carbondale  Jia, Yupeng National Instruments  Channel-Adaptive Spectrum Detection and Sensin g Strategy for Cognitive Radio Ad Hoc Networks 1408  Lu, Yuan North Carolina State University  Duel-Hallen, Alexandra North Carolina State University  Quantized Auction Schemes for Secondary Spectrum Markets 1415  Palguna, Deepan Purdue University  Love,  David J Purdue University  Pollak, Ilya Purdue University  Performance Analysis of Coexisting Secondary users in Heterogeneous Cognitive Radio Network 1422  Li, Xiaohua State University of New York, Binghamton  Xiong, Chengyu State University of New York, Binghamton  


FrA2 \226 Statistical Signal Processing Solarium   Chair  Bajwa, Waheed U Rutgers University Nearly Optimal Sample Size in Hypothesis Testing for High-Dim ensional Regression 1427  Javanmard, Adel Stanford University  Montanari, Andrea Stanford University  Distributed Online Big Data Classifi cation using Context Information 1435  Tekin, Cem University of California, Los Angeles  van der Schaar, Mihaela University of California, Los Angeles  Compressed Hypothesis Testing: To Mix or Not to Mix 1443  Xu, Weiyu University of Iowa  Lai, Lifeng Worcester Polytechnic Institute  Sparse Signal Recovery under Poisson Statistics 1450  Motamedvaziri, Delaram Boston University  Rohban, Mohammad H Boston University  Saligrama, Venkatesh Boston University  Efficient Probabilistic Group Testing based on Traitor Tracing 1458  Laarhoven, Thijs Eindhoven University of Technology  Computational and Statistical Tradeoffs via Convex Relaxation n/a  Chandrasekaran, Venkat California Institute of Technology  Jordan, Michael I University of California, Berkeley  Time-Variant Regularization in Affine Projection Algorithms 1466  Ba, Amadou IBM Research  McKenna, Sean IBM Research  Cloud K-SVD: Computing Data-Adaptive Representations in the Cloud 1474  Raja, Haroon Rutgers University  Bajwa, Waheed U Rutgers University  FrA3 \226 Information Aggregation Over Social Networks Butternut   Chair Hassanzadeh, Farzad University of Illinois  Organizer\(s Milenkovic, Olgica University of Illinois  Yaakobi, Eitan California Institute of Technology The Maximum Likelihood Approach to Voting on Social Networks 1482  Conitzer, Vincent Duke University  Building Consensus via Iterative Voting n/a  Farnoud \(Hassanzadeh California Institute of Technology  Yaakobi, Eitan California Institute of Technology  Touri, Behrouz Georgia Institute of Technology Bruck, Jehoshua California Institute of Technology  CP-Nets with Indifference  1488  Allen, Thomas E University of Kentucky  


Computing Parametric Rankin g Models via Rank-Breaking n/a  Azari Soufiani, Hossein Harvard University  Parkes, David Harvard University  Xia, Lirong Rensselaer Polytechnic Institute  On the Dynamics of Influence Networks via Reflected Appraisal n/a  Bullo, Francesco University of California, Santa Barbara Social Group Utility Maximization Game with Applications in Mobile Social Networks 1496  Gong, Xiaowen Arizona State University  Chen, Xu Arizona State University  Zhang, Junshan Arizona State University  Credibility Optimization and Power Co ntrol for Secure Mobile Crowdsourcing 1501  Ahmed, Kishwar Florida International University  Ren, Shaolei Florida International University  Turnewitsch, Vance Marietta College  Vasilakos, Athanasios V National Technical University of Athens  Group Learning and Opinion Diffusion in a Broadcast Network 1509  Liu, Yang University of Michigan  Liu, Mingyan University of Michigan  FrA4 \226 Network Coding Pine   Chair Dimakis, Alex University of Southern California Secure Network Coding with Erasures and Feedback 1517  Czap, L\341szl\363 311cole Polytechnique F\351d\351rale de Lausanne  Fragouli, Christina 311cole Polytechnique F\351d\351rale de Lausanne  Prabhakaran, Vinod M Tata Institute of Fundamental Research  Diggavi, Suhas University of California, Los Angeles  Index Coding Problem with Side Information Repositories 1525  Shanmugam, Karthikeyan University of Texas, Austin  Dimakis, Alexandros G University of Texas, Austin  Caire, Giuseppe University of Southern California  Complexity and Rate-Distortion Tradeoff via Successive Refinement 1531  No, Albert Stanford University  Ingber, Amir Stanford University  Weissman, Tsachy Stanford University  On a Capacity Equivalence Between Mult iple Multicast and Multiple Unicast 1537  Wong, M.F California Institute of Technology  Langberg, M State University of New York, Buffalo Effros, M California Institute of Technology  On the Capacity of Sum-Networks 1545  Rai, Brijesh Kumar Indian Institute of Technology, Guwahati  Das, Niladri Indian Institute of Technology, Guwahati  


Duality Codes and the Integral ity Gap Bound for Index Coding 1553  Yu, Hao University of Southern California  Neely, Michael J University of Southern California  On the Structure of Approximately Optimal Schedules for Half-Duplex Diamond Networks 1561  Brahma, Siddhartha 311cole Polytechnique F\351d\351rale de Lausanne  Fragouli, Christina 311cole Polytechnique F\351d\351rale de Lausanne  326zg\374r, Ayfer Stanford University  FrA5 \226 Topology and Control Lower Level   Chair Baryshnikov, Yuliy University of Illinois  Co-Chair Belabbas, Mohamed-Ali University of Illinois   Organizer\(s Baryshnikov, Yuliy University of Illinois  Belabbas, Mohamed-Ali University of Illinois Double Bracket Flows, Toda Flows and Rigid Body Toda 1567  Bloch, Anthony M University of Michigan  Gay-Balmaz, Fran\347ois 311cole Normale Sup\351rieure  Ratiu, Tudor S 311cole Polytechnique F\351d\351rale de Lausanne  Topological Obstructions to Dist ributed Feedback Stabilization 1573  Mansouri, Abdol-Reza Queen's University  Contact Geometry of Optimal Control Problems n/a  Ohsawa, Tomoki University of Michigan, Dearborn  Equivariant Morse Theory for Formation Control 1576  Helmke, Uwe University of W\374rzburg  Anderson, Brian D.O Australian National University  Towards Discrete Geometric Boundary Co ntrol of Lagrangian Field Theories n/a  Leok, Melvin University of California, San Diego  Structure and Geometry of Minimum-Tim e Trajectories for Planar Rigid Bodies 1584  Futuna, Andrei A Dartmouth College  Wang, Weifu Dartmouth College  Lyu, Yu-Han Dartmouth College  Balkcom, Devin Dartmouth College  Real and Apparent Synchronization n/a  Brockett, Roger Harvard University  Rauch and Bonnet-Myers Type Comparison Theorems in Sub-Riemannian Geometry n/a  Zelenko, Igor Texas A&M University  


FrA6 \226 Privacy and Big Data Visitor Center   Chair Oh, Sewoong University of Illinois  Organizer\(s Duchi, John University of California, Berkeley  Oh, Sewoong University of Illinois Viswanath, Pramod University of Illinois  Local Privacy and Statistical Minimax Rates 1592  Duchi, John C University of California, Berkeley  Jordan, Michael I University of California, Berkeley  Wainwright, Martin J University of California, Berkeley  Differential Privacy, Equilibrium, and Efficient Allocation of Resources 1593  Roth, Aaron University of Pennsylvania  A Bayesian Method for Matching Tw o Similar Graphs without Seeds 1598  Pedarsani, Pedram 311cole Polytechnique F\351d\351rale de Lausanne  Figueiredo, Daniel R Federal University of Rio de Janeiro  Grossglauser, Matthias 311cole Polytechnique F\351d\351rale de Lausanne  Privacy as a Coordination Game 1608  Ghosh, Arpita Cornell University  Ligett, Katrina California Institute of Technology  De-Anonymizing Private Data by Matching Statistics 1616  Unnikrishnan, Jayakrishnan 311cole Polytechnique F\351d\351rale de Lausanne  Movahedi Naini, Farid 311cole Polytechnique F\351d\351rale de Lausanne  Robust Subspace Iteration and Privacy-Preserving Spectral Analysis 1624  Hardt, Moritz IBM Research Almaden  Privacy-Utility Tradeoff und er Statistical Uncertainty 1627  Makhdoumi, Ali Massachusetts Institute of Technology  Fawaz, Nadia Technicolor   


Copyright © 2009 Boeing. All rights reserved Advanced Arrival Procedures with Active Abatement Potentials   9/23/10  32 Backup Slides 


Copyright © 2009 Boeing. All rights reserved  Initial Approach Initial Investigations  Apache Solr/Lucene  Data Warehouse Evaluate Hadoop in the future 


Copyright © 2009 Boeing. All rights reserved  Using SOLR Uncompress Track Information Messages To use with Solr  Transforming track messages from their  original schema to Solr required building a ìkey, valueî list using an XSTL  Queries made against this list of ìkey, valueî pairs Transformation Process  One day of data ~ 4.5 hours Once transformation complete search/query performance very good Geo spatial queries using  unique query language 


Copyright © 2009 Boeing. All rights reserved  Representation Aviation data is frequently represented in more than one form 



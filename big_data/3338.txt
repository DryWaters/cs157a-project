Mining Double-Connective Association Rules from Multiple Tables of Relational Databases   Xunwei Zhou 1 Hong Bao 2  1.Institute of Information Technology,                2. College of Information Beijing Union University                        Beijing Union University Beijing, China                                 Beijing, China E-mail zhouxunwei@263.net E-mail baohong@buu.com.cn   Abstract Single-dimensional association rule and multidimensional association rule in conventional association rule mining are single-connective association rules, because they have only one connective 002 In this paper, based on mutually-inversistic logic, an algorithm for double-connective association rule mining is proposed, mining the association rule in the form of student\(Sno 003 1 course\(Cno 004 1 study\(Sno, Cno\, read for all students Sno, there exists course Cno such that Sno study Cno”, where 003 1 and 004 1 are connectives, Sno is the primary key of the table transformed from the entity Student, Cno is the primary key of the table transformed from the entity Course, \(Sno, Cno\ is the primary key of the table transformed from the binary relationship Study. A three-table relational database naturally embraces double-connective association rules    Keywords--mutually-inversistic logic, double-connective association rule, relational database, multiple tables, data mining  I.   INTRODUCTION In data mining   g led i m e n s i o n al  association rule is in the form of buys\(X, “computer 002 buys\(X, “financial_management_software where there is only one connective 002 It is a single-connective association rule. A multidimensional association rule is in the form of age\(X, “30…39 004 income\(X, “42K…48K 002 buys\(X, “high_resolution_TV”\lassical logi  deems that 004 and 002 are all connectives, so in the multidimensional association rule in question, there are two connectives. Mutually-inversistic logi  deems that   004  005 are compounders, used from simpler facts to form a more complex fact 003 1 mutually inverse implication, in mutually-inversistic logic, universal quantifier is not introduced, man\(x 003 1 mortal\(x\ponds to 006 x\(man\(x 002 mortal\(x in classical logic 004 1 mutually inverse conjunction in mutually-inversistic logic, existential quantifier is not introduced, even_number\(x 004 1 prime_number\(x corresponds to 007 x\(even_number\(x 004 prime_number\(x\n classical logic\nectives, representing the connection of two facts. From the viewpoint of mutually-inversistic logic, a multidimensional association rule is still a single-connective association rule, having only one connective 002 Single-connective association rule mining can only mines the association between frequent item sets. It cannot mine the association between the primary keys of a database Database ery  can query quantitative information such as “thirty-five students study the course of Principle of Database”, but it cannot query qualitative information such as “many students study some courses”. Some query information are predeterminate, so that SQL statements can be written for them. But some information are not perdeterminate, it cannot be queried  In order to remedy the deficits of both 
2008 International Conference on Computer Science and Software Engineering 978-0-7695-3336-0/08 $25.00 © 2008 IEEE DOI 10.1109/CSSE.2008.559 271 
2008 International Conference on Computer Science and Software Engineering 978-0-7695-3336-0/08 $25.00 © 2008 IEEE DOI 10.1109/CSSE.2008.559 271 


single-connective association rule mining and database query, this paper proposes double-connective associ ation rule mining. A double-connective association rule is in the form of p’\(x 010 1 q’\(y 010 2 r’\(x, y\, where p’\(x\d q’\(y unary predicates, r’\(x, y\ is a binary predicate 010 1 and 010 2 are connectives 003 1 or 004 1 For example course\(Cno 004 1 student\(Sno 003 1 study\(Sno, Cno is a double-connective association rule, meaning that there exists a course Cno such that for all students Sno, Sno study Cno. Another example is teacher\(Tno 003 1 course\(Cno 004 1 teach\(Tno, Cno\meaning that for all teachers Tno there exists a course Cno such that Tno teach Cno In relational databases, some tables are transformed from entities in ER diagram, we call such tables the entity table. Other tables are transformed from binary relationships in ER diagram we call such tables binary relationship table. We take the primary keys of two entity tables \(they are bound to have a primary attribute each\ the unary predicate p’\(x\d q’\(y\ke the primary key of the binary relationship table \(it is bound to have two primary attributes\ the binary predicate r’\(x, y obtain a double-connective association rule. This is to say, a relational database naturally embraces double-connective association rules. The algorithm for mining double-connective association rule is divided into three levels. The top level is table determination algorithm that is to determine which tables embrace the double-connective association rule. The middle level is attribute determination algorithm that is to determine which attributes embrace the double-connective association rule. The bottom level is connective determination algorithm that is to determine 010 1 and 010 2 in p’\(x 010 1 q’\(y 010 2 r’\(x y\ are 004 1 or 003 1 respectively The rest of this paper is organized as follows Section 2 gives a relational database of Study and Teaching, Section 3 gives the table determination algorithm, Section 4 gives the attribute determination algorithm, Section 5 gives the connective determination algorithm, Section 6 is the concluding remarks    II.DATABASE OF STUDY AND TEACHING The database of Study and Teaching is shown in Fig. 1  Observing Fig. 1, we see that the primary key Sno of Table 0, the primary key Cno of Table 1, the primary key <Sno, Cno> of Table 2 form the double-connective association rule student\(Sno 010 1 course\(Cno 010 2 study\(Sno, Cno\ikewise, the primary key Tno of Table3, the primary key Cno of Table 1, the primary key <Tno, Cno> of Table 4 form the double-connective association rule teacher\(Tno 010 1 course\(Cno 010 2 teach\(Tno, Cno\The following sections are to mine these rules. Take student\(Sno 010 1 course\(Cno 010 2 study\(Sno, Cno\ an example, the table determination algorithm in Section 3 will determine that take Table 0 and Table 1 as the entity tables, take Table 2 as the binary relationship table we can mine the rule. The attribute determination algorithm in Section 4 will determine that the attribute 1 in both Table 0 and Table 1, the attributes 1 and 2 in Table 2 embrace the rule. The connective determination algorithm in Section 5 will determine whether 010 1 and 010 2 in student\(Sno 010 1 course\(Cno 010 2 study\(Sno, Cno 004 1 or 003 1 respectively  III. TABLE DETERMINATION ALGORITHM The table determination algorithm is shown in Fig. 2, where R denotes the serial number of the binary relationship table, E 1 denotes the serial number of the first entity table, E 2 denotes the serial number of the second entity table,0 through N-1 denote Tables 0 through N-1, N denotes the number of tables The table determination algorithm uses brutal force method, i.e. for every three tables, it tries to find a double-connective association rule 000\003 
272 
272 


0007\000D\000E\000O\000H\000\003\000\023\000\003\000\003\000\003\000\003\0006\000W\000X\000G\000H\000Q\000W\000\003\000W\000D\000E\000O\000H 000\003\000\003\000\003 000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003 0007\000D\000E\000O\000H\000\003\000\024\000\003\000\003\000\003\000\003\000&\000R\000X\000U\000V\000H\000\003\000W\000D\000E\000O\000H 000\003\000\003 0006\000Q\000R\000\003 0006\000Q\000D\000P\000H\000\003 0006\000D\000J\000H\000\003 000\003\000\003\000\003\000\003\000\003 000&\000Q 000R 000&\000Q\000D\000P\000H\000\003 000&\000U\000H\000G\000L\000W\000\003 0006 000\024 000\003 000<\000R\000Q\000J\000\003\000/\000L\000\003 000\025\000\023\000\003 000\003 000 000\024 000\003 000'\000D\000W\000D\000E\000D\000V\000H\000\003 000\026\000\003 0006 000\025 000\003 000&\000K\000H\000Q\000\003\000/\000L\000X\000\003 000\024\000\034\000\003 000\003 000 000\025 000\003 0000\000D\000W\000K\000H\000P\000D\000W\000L\000F\000D\000O\000\003\000$\000Q\000D\000O\000\\\000V\000L\000V\000\003 000\027\000\003 0006 000\026 000\003 0000\000L\000Q\000\003\000:\000D\000Q\000J\000\003 000\024\000\033\000\003 000\003 000 000\026 000\003 000*\000H\000Q\000H\000U\000D\000O\000\003\0003\000K\000\\\000V\000L\000F\000V\000\003 000\025\000\003 0006 000\027 000\003 000<\000D\000Q\000\003\000=\000K\000D\000Q\000J\000\003 000\024\000\034\000\003 000\003 000 000\027 000\003 000&\000R\000Q\000W\000U\000R\000O\000\003\0007\000K\000H\000R\000U\000\\\000\003 000\026\000\003 0006 000\030 000\003 0003\000L\000Q\000J\000\003\000=\000K\000R\000X\000\003 000\025\000\023\000\003 000\003\000\003\000\003 000\003 000\003 000\003 0007\000D\000E\000O\000H\000\003\000\025\000\003\000\003\000\003\000\003\0006\000W\000X\000G\000\\\000\003\000W\000D\000E\000O\000H\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\000\003\0007\000D\000E\000O\000H\000\003\000\026\000\003\000\003\000\003\000\003\0007\000H\000D\000F 000K\000H\000U\000\003\000W\000D\000E\000O\000H\000\003\000\003 000\003 000\003 000\003 Fig.1  The database of Study and Teaching 0006\000Q\000R\000\003 000&\000Q\000R\000\003 000*\000U\000D\000G\000H\000\003 0006 000\024 000\003\000 000\024 000\003\000\034\000\025\000\003 0006 000\024 000\003\000 000\025 000\003\000\033\000\030\000\003 0006 000\025 000\003\000 000\024 000\003\000\033\000\033\000\003 0006 000\025 000\003\000 000\026 000\003\000\034\000\023\000\003 0006 000\026 000\003\000 000\024 000\003\000\033\000\023\000\003 0006 000\027 000\003\000 000\025 000\003\000\032\000\031\000\003 0006 000\030 000\003\000 000\024 000\003\000\034\000\026\000\003 0006 000\030 000\003\000 000\027 000\003\000\032\000\023\000\003 0007\000Q\000R\000\003 0007\000Q\000D\000P\000H\000\003 000:\000R\000U\000N\000\003\000/\000R\000D\000G\000\003 0007 000\024 000\003 0006\000D\000Q\000\003\000=\000K\000D\000Q\000J\000\003 000\032\000\003 0007 000\025 000\003 0006\000L\000\003\000/\000L\000\003 000\033\000\003 0007 000\026 000\003 000:\000X\000\003\000:\000D\000Q\000J\000\003 000\023\000\003 0007\000Q\000R\000\003 000&\000Q\000R\000\003 0007\000H\000[\000W\000E\000R\000R\000N\000\003 0007 000\024 000\003\000 000\024 000\003 0003\000U\000L\000Q\000F\000L\000S\000O\000H\000\003\000R\000I\000\003\000'\000D\000W\000D\000E\000D\000V\000H 0007 000\024 000\003\000 000\025 000\003 000+\000L\000J\000K\000H\000U\000\003\0000\000D\000W\000K\000H\000P\000D\000W\000L\000F\000V\000\003 0007 000\025 000\003\000 000\025 000\003 000&\000D\000O\000F\000X\000O\000X\000V\000\003 0007 000\025 000\003\000 000\026 000\003 0008\000Q\000L\000Y\000H\000U\000V\000L\000W\000\\\000\003\0003\000K\000\\\000V\000L\000F\000V\000\003 0007 000\025 000\003\000 000\027 000\003 000,\000Q\000G\000X\000V\000W\000U\000L\000D\000O\000\003\000$\000X\000W\000R\000P\000D\000W\000L\000R\000Q 0007\000D\000E\000O\000H\000\003\000\027\000\003\000\003\000\003\000\003\0007\000H\000D\000F\000K\000L\000Q\000J\000\003\000W\000D\000E\000O\000H\000\003 
273 
273 


000\\000L\000J\000\021\000\025\000\003\000\003\0007\000D\000E\000O\000H\000\003\000G\000H\000W\000H\000U\000P\000L\000Q\000D\000W\000L\000R\000Q\000\003\000D\000O\000J\000R\000U\000L\000W\000K\000P\000\003 Start R=0,E 1 1,E 2 2 R=N 002  E 1  002 R-1 002 mod N E 2 R 002  Call the attribute determination algorithm E 2  002 E 2 1 002 mod N End E 1  002 E 1 1 002 mod N E 2  002 E 1 1 002 mod N R=R+1 E 1  002 R+1 002 mod N E 2  002 E 1 1 002 mod N Y N Y N Y N 
274 
274 


000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 000\003 Start e 1 1, e 2 1, r 1 1, r 2 2 e 1 0010 L 002  e 2 0010 M 002  r 1 0010 N-l 002  r 2 0010 N 002   e 1 and r 1   and  e 2 and r 2  have the same name 002 e 1 e 2 r 1 r 2 entity integrity check Check passed 002 Call connective determination algorithm  e 1 and r 2   and  e 2 and r 1  have the same name 002 e 1 e 2 r 1 r 2 entity integrity check Check passed 002 Call connective determination algorithm r 2 r 2 1  End r 1 r 1 1 r 2 r 1 1  e 2 e 2 1 r 1 1  r 2 1  e 1 e 1 1 e 2 1  r 1 1 r 2 2  N N N N Y Y Y Y Y Y Y Y N N N N Fig.3  Attribute determination algorithm 
275 
275 


As to the database Fig. 1, when mining student\(Sno 010 1 course\(Cno 010 2 study\(Sno, Cno\he three tables the table determination algorithm determines are R=0, E 1 1, E 2 2 \(i.e. R equals Table 0, E 1 equals Table 1, E 2 equals Table 2 R=0, E 1 1, E 2 3 R=0, E 1 1, E 2 4 R=0, E 1 2, E 2 3 R=0, E 1 2, E 2 4 R=0, E 1 3, E 2 4 R=1, E 1 2, E 2 3  R=4, E 1 2, E 2 3  IV. ATTRIBUTE DETERMINATION ALGORITHM The attribute determination algorithm is shown in Fig. 3, where e 1 and e 2 are the serial numbers of the current attributes of Tables E 1 and E 2 respectively, r 1 and r 2 are the serial numbers of the first and the second attribute of the current attribute pair of Table R, L, M, N are the number of attributes of Tables E 1  E 2 and R respectively The attribute determination algorithm uses brutal force method, i.e. for every two pairs of attributes, it tries to find a double-connective association rule. If it finds that e 1 and r 1 have the same attribute name and e 2 and r 2 have the same attribute name or that e 1 and r 2 have the same attribute name and e 2 and r 1 have the same attribute name, then it goes on entity integrity check for each attribute. If the check passes, then these attributes indeed embrace a double-connective association rule For student\(Sno 010 1 course\(Cno 010 2 study\(Sno, Cno the first two pairs of attributes the algorithm determines embraces it  V. CONNECTIVE DETERMINATION ALGORITHM We take student\(Sno 010 1 course\(Cno 010 2 study\(Sno, Cno\ an example to study the connective determination algorithm. Let 010 1 and 010 2 be  004 1 or 003 1 respectively, and exchange the positions of student\(Sno 010 1 and course\(Cno 010 2 we obtain 8 double-connective association rules DCAR1: student\(Sno 003 1  course\(Cno 003 1  study\(Sno, Cno DCAR2: course\(Cno 004 1  student\(Sno 003 1  study\(Sno, Cno DCAR3: student\(Sno 003 1  course\(Cno 004 1  study\(Sno, Cno DCAR4: student\(Sno 004 1  course\(Cno 003 1  study\(Sno, Cno DCAR5: course\(Cno 003 1  student\(Sno 004 1  study\(Sno, Cno DCAR6: student\(Sno 004 1  course\(Cno 004 1  study\(Sno, Cno DCAR7: course\(Cno 003 1  student\(Sno 003 1  study\(Sno, Cno DCAR8: course\(Cno 004 1  student\(Sno 004 1  study\(Sno, Cno Because DCAR7  is equivalent with DCAR1, DCAR8  is equivalent with DCAR6, we only study DCAR1  through DCAR6 003 1 denotes “for all”. This requirement is too strong, we lower its requirement by setting certainty factors cf 1 and cf 2 they are percentages\ for 010 1 and 010 2 respectively. If the percentage is no less than the certainty factor, then 003 1 holds, denoting “for many If the percentage is less than the certainty factor but greater than 0, then 004 1 holds, denoting “there are some 
276 
276 


Since the attribute determination algorithm has determined that the attribute Sno in Table 0, the attribute Cno in Table 1, and the attributes <Sno Cno> in Table 2 embrace the double-connective association rule student\(Sno 010 1 course\(Cno 010 2 study\(Sno, Cno\he connective determination algorithm make the relational matrix shown in Fig. 4 according to the binary relationship table of Table 2   C1 C2 C3 C4 S1   T  T  F  F S2   T  F  T  F S3   T  F  F  F S4   F  T  F  F S5   T  F  F  T   Fig. 4 The relational matrix made from Table 2  Fig. 4 is made like this: Table 2 has the tuple S1, C1>, then at the cross of the row S1 and the column C1, a T is filled; Table 2 does not have tuple S1, C3>, then at the cross of the row S1 and the column C3, a F is filled Suppose the cardinality of student\(Sno\s M, in this example 5, i.e. S1 to S5; the cardinality of course\(Cno\n this example 4, i.e. C1 to C4 The algorithms for DCAR1 through DCAR6 are as follows The algorithm for DCAR1 If in Fig. 4 there is M*cf 1 rows, N*cf 2 columns submatrix, in which all elements are Ts, then DCAR1 holds The algorithm for DCAR2 If in Fig. 4 there is at least one column, in which there are at least M*cf 1 Ts, then DCAR2 holds The algorithm for DCAR3 If in Fig. 4 at least M*cf 1 rows have Ts, then DCAR3 holds The algorithm for DCAR4 If in Fig. 4 there is at least one row, in which there are at least N*cf 2 Ts, then DCAR4 holds The algorithm for DCAR5 If in Fig. 4 at least N*cf 2 columns have Ts, then DCAR5 holds The algorithm for DCAR6    DCAR6   DCAR3  DCAR5     DCAR2  DCAR4   DCAR1 Fig. 5 The complement lattice formed by DCAR1 through DCAR6 
277 
277 


000\003 000\\000L\000J\000\021\000\031\000\003\000\003\000&\000R\000Q\000Q\000H\000F\000W\000L\000Y\000H\000\003\000G\000H\000W\000H\000U\000P\000L\000Q\000D\000W\000L\000R\000Q\000\003\000D\000O\000J\000R\000U\000L\000W\000K\000P\000\003 Start Call DCAR1 000D\000O\000J\000R\000U\000L\000W\000K\000P  DCAR1 holds 002  Call DCAR2 000D\000O\000J\000R\000U\000L\000W\000K\000P  Output DCAR1,2,3,4,5,6 End DCAR2 holds 002  Output DCAR2,3,6 Call DCAR3 000D\000O\000J\000R\000U\000L\000W\000K\000P  DCAR3 holds 002  Output DCAR3,6 Call DCAR4 000D\000O\000J\000R\000U\000L\000W\000K\000P  DCAR4 holds 002  Call DCAR5 000D\000O\000J\000R\000U\000L\000W\000K\000P  Output DCAR4,5,6 End DCAR5 holds 002  Call DCAR6 000D\000O\000J\000R\000U\000L\000W\000K\000P  Output DCAR5,6 End DCAR6 holds 002  Output DCAR6 End Error Y N N Y Y N N Y Y N N Y 
278 
278 


If in Fig. 4 there is at least one T, then DCAR6 holds DCAR1 through DCAR6 forms a complement lattice shown in Fig. 5 In Fig. 5, the lower rule implies the upper rule That is, if DCARj is reachable from DCARi via an ascending path, and DCARi holds, then DCARj holds Because DCAR1 through DCAR6 satisfies Fig 5, their algorithms can be merged into one algorithm called connective determination algorithm, shown in Fig. 6 Suppose cf 1 80%, cf 2 75%. In Fig. 4, for the column of C1, there are M*cf 1 5*80%=4 elements whose values are T \(namely, S1, S2, S3, S5 Therefore, DCAR2: course\(Cno 004 1  student\(Sno 003 1  study\(Sno, Cno\olds. From Fig. 5, we know that DCAR3 and DCAR6 also hold. In Fig. 4, there are at least N*cf 2 4*75%=3 columns which have value T \(namely, in the column of C1 there is S1, in the column of C2 there is S1, in the column of C3 there is S2, in the column of C4 there is S5 therefore DCAR5: course\(Cno 003 1  student\(Sno 004 1  study\(Sno, Cno  VI. CONCLUDING REMARKS 1\ Double-connective association rule mining is different from single-connective association rule mining. The former mines the association among the primary keys of the two entity tables and the primary key of the binary relationship table. The latter mines the association between frequent item sets 2\. 4 is different from data cubes in data warehouses. The elements in Fig. 4 are T or F. The elements in the data cubes are data 3\The differences between double-connective association rule and database query are that, first, the query information in databases are predeterminate while the information to be mined by double-connective association rule is not predeterminate, it is implied. Secondly, database query needs to write SQL statements, while double-connective association rule mining is automatic. Thirdly, the information obtained by database query is quantitative, while the information obtained by double-connective association rule mining is qualitative such as “for many”, “there are some  REFERENCES 1 Ji a w ei H a n   M i ch eli n e K a m b er   D a t a  M i n i n g C onc ep t s  a nd Techniques, Higher Education Press, Beijing, 2001, Morgan Kaufmann Publishers, 2000 2 A  G  Ha m i lt on  L o gi c for M a th em a t i c ia ns R evi s ed E d i t i o n   Cambridge University Press, 1988, Tsinghua University Press Beijing, 2003 3 X unw e i Z h o u   Br ie f I ntr o du c t io n  to  Mu t u al l y I nve r s is tic Logic”, 1999 European Summer Meeting of the Association for Symbolic Logic, Utrecht, The Netherlands, August 1-6 1999 4 u n w ei Zh ou F i r s t leve l exp l i c i t m u lt ip le i ndu ct i v e composition”, 2005 Spring Meeting of the Association for Symbolic Logic, The Westin St. Francis Hotel, San Francisco CA. USA, March 25-26, 2005 5 A b rah a m S i lb ers c ha t z  Hen r y  F  Kort h  S S u da rs ha n Dat a b a s e  System Concepts \(Fourth Edition\, Higher Education Press Beijing, 2002, McGraw-Hill Companies, 2002  
279 
279 


support pruning gene expression classifier with an accurate and compact fuzzy rule base for microarray data analysis Biosystems vol 85 computationally challenging As training set sizes increase it is likely that these difficulties will also increase VI RELATED WORK While operating on a microarray dataset current CAR 1 2 3 4 and other pattern/rule 20 21 mining algorithms perform a pruned and/or compacted exponential search over either the space of gene subsets or the space of sample subsets Hence they are generally quite computationally expensive for datasets containing many training samples or genes as the case may be BSTC is explicitly related to CAR-based classifiers but requires no expensive CAR mining BSTC is also related to decision tree-based classifiers such as random forest 19 and C4.5 family 9 methods It is possible to represent any consistent set of boolean association rules as a decision tree and vice versa However it is generally unclear how the trees generated by current tree-based classifiers are related to high confidence/support CARs which are known to be particularly useful for microarray data 1 2 6 7 11 BSTC is explicitly related to and motivated by CAR-based methods To the best of our knowledge there is no previous work on mining/classifying with BARs of the form we consider here Perhaps the work closest to utilizing 100 BARs is the TOPRULES 22 miner TOP-RULES utilizes a data partitioning technique to compactly report itemlgene subsets which are unique to each class set Ci Hence TOP-RULES discovers all 100 confident CARs in a dataset However the method must utilize an emerging pattern mining algorithm such as MBD-LLBORDER 23 and so generally isn't polynomial time Also related to our BAR-based techniques are recent methods which mine gene expression training data for sets of fuzzy rules 24 25 Once obtained fuzzy rules can be used for classification in a manner analogous to CARs However the resulting fuzzy classifiers don't appear to be as accurate as standard classification methods such as SVM 25 VII CONCLUSIONS AND FUTURE WORK To address the computational difficulties involved with preclassification CAR mining see Tables IV and VI we developed a novel method which considers a larger subset of CAR-related boolean association rules BARs These rules can be compactly captured in a Boolean Structure Table BST which can then be used to produce a BST classifier called BSTC Comparison to the current leading CAR classifier RCBT on several benchmark microarray datasets shows that BSTC is competitive with RCBT's accuracy while avoiding the exponential costs incurred by CAR mining see Section VB Hence BSTC extends generalized CAR based methods to larger datasets then previously practical Furthermore unlike other association rule-based classifiers BSTC easily generalizes to multi-class gene expression datasets BSTC's worst case per-query classification time is worse then CAR-based methods after all exponential time CAR mining is completed O SlS CGl versus O Si CGi As future work we plan on investigating techniques to decrease this cost by carefully culling BST exclusion lists ACKNOWLEDGM[ENTS We thank Anthony K.H Tung and Xin Xu for sending us their discretized microarray data files and Top-k/RCBT executables This research was supported in part by NSF grant DMS-0510203 NIH grant I-U54-DA021519-OlAf and by the Michigan Technology Tri-Corridor grant GR687 Any opinions findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding agencies REFERENCES 1 G Cong K L Tan A K H Tung and X Xu Mining top-k covering rule Mining SDM 2002 5 R Agrawal T Imielinski and A Swami Mining associations between sets of items Y Ma Integrating classification and association rule mining KDD 1998 11 T McIntosh and S Chawla On discovery of maximal confident rules without pp 43-52 1999 24 S Vinterbo E Kim and L Ohno-Machado Small fuzzy and interpretable pp 165-176 2006 1071 pp 207-216 1993 6 G Dong pp 273-297 t995 9 pp 5-32 2001 20 W Li J R Quinlan Bagging boosting and c4.5 AAAI vol 1 V Vapnik Support-vector networks the best strategies for mining frequent closed itemsets KDD 2003 4 M Zaki and C Hsiao Charm L Wong Identifying good diagnostic genes or gene expression data SIGMOD 2005 2 G Cong A K H Tung X Xu F Pan and J Yang Farmer Finding interesting rule gene expression data by using the gene expression based classifiers BioiiiJcrmatics vol 21 l and Inrelligent Systenis IFIS 1993 16 Available at http://sdmc.i2r.a-star.edu.sg/rp 17 The dprep package http:/cran r-project org/doclpackages dprep pdfI 18 C Chang and C Lin Libsvm a library for support vector machines 2007 Online Available www.csie.ntu.edu.tw cjlin/papers/libsvm.pdf 19 L Breiimnan Random forests Maclh Learn vol 45 no 1 M Chen and H L Huang Interpretable X Zhang 7 J Li and pp 725-734 2002 8 C Cortes and Mac hine Learming vol 20 no 3 in microarray data SIGKDD Worikshop on Dtra Mining in Bioinfrrnatics BIOKDD 2005 12 R Agrawal and R Srikant Fast algorithms for mining association rules VLDB pp 1964-1970 2005 25 L Wong and J Li Caep Classification by aggregating emerging patterns Proc 2nd Iat Coif Discovery Scieice DS 1999 gene groups from pp 487-499 t994 13 Available ot http://www-personal umich edu/o markiwen 14 R Motwani and P Raghavan Randomized Algoriitlms Caim-bridge University Press 1995 15 S Sudarsky Fuzzy satisfiability Intl Conf on Industrial Fuzzy Contri J Han and J Pei Cmar Accurate and efficient classification based on multiple class-association rules ICDM 2001 21 F Rioult J F Boulicaut B Cremilleux and J Besson Using groups for groups in microarray datasets SIGMOD 2004 3 concept of emerging patterns BioinformJotics vol 18 transposition for pattern discovery from microarray data DMKD pp 73-79 2003 22 J Li X Zhang G Dong K Ramamohanarao and Q Sun Efficient mining of high confidence association rules without S Y Ho C H Hsieh H pp 725-730 1996 10 B Liu W Hsu and support thresholds Principles f Drata Mining aind Knowledge Discovery PKDD pp 406 411 1999 23 G Dong and J Li Efficient mining of emerging patterns discovering trends and differences KDD J Wang J Han and J Pei Closet Searching for An efficient algorithm for closed association rule mining Proc oJ the 2nd SIAM Int Con on Data in large databases SIGMOD 



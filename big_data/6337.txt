Load Balancing for Privacy-Preserving Access to BigDatainCloud Peng Li and Song Guo The University of Aizu Aizu-Wakamatsu Japan  pengli sguo  u-aizu.ac.jp Abstract In the era of big data many users and companies start to move their data to cloud storage to simplify data management and reduce data maintenance cost However security and privacy issues become major concerns because third-party cloud service providers are not always trusty Although data contents can be protected by encryption the access patterns that contain important information are still exposed to clouds or malicious attackers In this paper we apply the ORAM algorithm to enable privacy-preserving access to big data that are deployed in distributed le systems built upon hundreds or thousands of servers in a single or multiple geo-distributed cloud sites Since the ORAM algorithm would lead to serious access load unbalance among storage servers we study a data placement problem to achieve a load balanced storage system with improved availability and responsiveness Due to the NP-hardness of this problem we propose a low-complexity algorithm that can deal with large-scale problem size with respect to big data Extensive simulations are conducted to show that our proposed algorithm nds results close to the optimal solution and signiìcantly outperforms a random data placement algorithm I I NTRODUCTION Big data has emerged in vari ous domains including science engineering and commerce For example the amount of photos currently stored by Facebook is over 20 petabytes and it continues to grow with 60 terabytes each week In the era of big data cloud becomes a perfect candidate for data storage by providing virtually unlimited storage that can be accessed over network By outsourcing large volumes of data to cloud storage such as Google Drive Dropbox and Amazon S3 users can simplify their data management and reduce data maintenance cost due to the pay-as-you-use model However some users and companies still hesitate to move their data to cloud because of security and privacy concerns Although encryption can protect the data conìdentiality it is insufìcient because access patterns can also leak important information For instance over 80 of encrypted email queries can be identiìed according to access pattern in The access privacy problem is rst addressed by private information retrieval PIR technique t hat a l l o ws a u s e r t o retrieve a block from a database of N items held by a server that learns nothing about this block Unfortunately Sion et al 4 h a v e s h o wn th at e x istin g P I R sch e m e s w ill n e v e r b e m o r e efìcient than a trivial PIR scheme of downloading the entire database The extremely poor performance of PIR makes it inapplicable in cloud storage with big data Oblivious RAM ORAM is later proposed to hide data access privacy with improved performance Its basic idea is to periodically reshufîe data blocks stored in an untrusted server such that user access cannot be tracked Goodrich et al  h a v e p ropos ed an O R A M al gori t h m w i t h O   N  client storage to achieve O log N  amortized cost i.e each oblivious read or write leads to O log N  data access operations on average Shi et al f urt h er reduce t he cl i e nt s t orage t o O 1  In this paper we apply the ORAM algorithm to enable privacy-preserving access to big data in clouds To deal with the challenge of accommodating huge volume of data that continuously grows in high velocity big data are stored in distributed le systems built upon hundreds or thousands of servers in a single or multiple geo-distributed cloud sites When ORAM is directly applied on such distributed storage systems we observe that even if all data blocks are evenly accessed by users access load on servers would be seriously unbalanced i.e lots of data access requests are sent to several servers but only a few to others The servers with high load are apt to be system bottleneck or failure points in the system Motivated by this observation we exploit the data access characteristics of ORAM and propose a data placement algorithm to achieve load balance thus improving overall system availability and responsiveness The main contributions of this paper are summarised as follows First we study the privacy-preserving data access to big data in an untrusted cloud by applying the ORAM algorithm In conjunction with encryption ORAM-based solutions can hide not only data contents but als o access patterns from thirdparty cloud service provider and malicious attackers Second we investigate a load balance problem in applying ORAM on distributed le systems This problem is proved to be NPhard and formulated as a mixed integer linear programming MILP problem We propose a low-complexity algorithm that can deal with large-scale problem instances with respect to big data Third extensive simulations are conducted to show that the performance of our proposed algorithm is close to the optimal solution and signiìcantly outperforms a random data placement algorithm The rest of this paper are organized as follows We review important related work in Section II Section III presents some necessary preliminaries about ORAM algorithm and our motivation The system model and problem formulation are given in Section IV followed by an efìcient algorithm proposed in Section V We show extensive simulation results in Section VI Section VII nally concludes this paper 2014 IEEE INFOCOM Workshops: 2014 IEEE INFOCOM Workshop on Security and Privacy in Big Data 978-1-4799-3088-3/14/$31.00 ©2014 IEEE 524 


II R ELATED WORK A Cloud storage Cloud storage has attracted a lot of attentions from both industry and academic Many well-known cloud service providers have started their cloud storage services during past few years such as Microsoft SkyDrive Amazon S3 and Google Drive RAID Redundant Array of Inexpensive Disks technique is integrated in HAIL  t h at manages r emot e le integrity and availability across a collection of servers Similarly Dabek et al u s e R A ID l i k e t echni ques t o e ns ure the availability and durability of data in distributed systems To improve the reliability and security of cloud storage Bessani et al  ha v e propos ed a d i s t r i b ut ed s t orage s ys t e m cal l e d DEPSKY that integrates encryption encoding and replication IRIS i s propos ed as an aut h ent i cat ed  l e s ys t e m t hat lets enterprises store data in the cloud with resilience against potentially untrusted cloud providers There are several proposals dealing with data availability by constructing distributed storage systems across several cloud sites Wu et al  have proposed SPANStore a key-value storage system that exports a uniìed view of storage services in geo-graphically distributed data centers It minimizes an application providerês cost with three key techniques i.e exploiting pricing discrepancies across providers estimating application workload at the right granularity and minimizing the usage of computational resources B Oblivious RAM As originally proposed by Goldreich and Ostrovsky  ORAM allows a trusted processor to use an untrusted RAM Most existing ORAM solutions use the basic memory structure suggested by Ostrovskyês Hierarchical Scheme T he ORAM is arranged in a series of progressively larger caches Each cache consists of a hash table of buckets When a block is requested the algorithm checks a bucket at each level of the hierarchy If the block is found the search continues for a dummy block such that the location of his desired block is hidden Finally the block is reins erted into the top-level cache When a cache is close to overîowing it is obliviously shufîed into the cache below it Recent ORAM work has explored optimisations of the classic Hierarchical Scheme  14 i ncl udi ng t h e u s e of cuckoo hashing 15 an d B lo o m lter s  1 6   W illiam s et al  ha v e pres ent e d S R O R A M as t h e  rs t s i ngl e-round-t r i p polylogarithmic time ORAM that requires only logarithmic client storage Taking only a single round trip to perform a query SR-ORAM has an online communication/computation cost of O log n log log n   Lorch et al  ha v e pres ented Shroud a general storage system that hides data access patterns from the servers Shroud uses many secure coprocessors acting in parallel as client proxies in the data center III P RELIMINARIES AND MOTIVATION In this section we rst present some necessary background about ORAM and then show the load unbalance phenomenon that motivates our proposal    Fig 1 ORAM-based cloud storage A The ORAM algorithm We consider a client that would like to store and retrieve its big data in cloud that is honest but curious In other words the cloud cannot tamper with or modify the data but could learn information about the data The data are divided into blocks each of which is iden tiìed by a unique address For example a typical value of block size is 64KB or 256KB Data stored on cloud are organized as a tree where each node is referred to as a bucket that stores several data blocks An example of a binary tree structure is shown in Fig 1 Note that any arbitrary tree structure is applicable in ORAM Following the work in  w e t rans late each read or write operation i nto two primitives ReadAndRemove and Add that are deìned as follows ReadAndRemove u   given an address u speciìedbythe client the cloud returns the corresponding data block and removes it from storage Add u  d   the client writes block d to address u at the client storage With above two primitives each read u  operation can be replaced by a ReadAndRemove u  followedbyan Add u  d  that writes the same data block back to address u  Similarly to implement a write u d  operation we conduct a redundant ReadAndRemove u  before Add u  d   Although the number of access operations are doubled in ORAM it prevents the untrusted cloud from distinguishing read and write operations The implementation of ReadAndRemove u  and Add u  d  is critical for hiding access patterns in ORAM When a data block is written into the cloud storage it is always inserted into the root bucket in the level 0 as shown in Fig 1 As more data blocks are being added in the root bucket it will eventually be full without residual capacity to accommodate new blocks To avoid overîowing data blocks in each nonleaf bucket are periodically evicted to its children buckets We assign a random number called designator to each newly added data block to indicate which leaf bucket it is evicted to along the tree Note that only the client knows the mapping between block address and its associated designator At each level of the 2014 IEEE INFOCOM Workshops: 2014 IEEE INFOCOM Workshop on Security and Privacy in Big Data 525 


tree the client randomly chooses several buckets to evict In order to prevent the cloud from tracking the eviction process dummy blocks are inserted into other children buckets that do not receive the real data block To read a data block the client rst looks up its corresponding designator in local storage and then reads all buckets along the path between the root and t he leaf bucket indicated by this designator in the tree When the data block is found we remove it from its current bucket and write it back to the root bucket with a new designator In such a way the cloud cannot infer which block is read because repeated reads for the same block will produce different lookup paths through the tree B Motivation To deploy an ORAM-based storage in a distributed system we need to partition the corresponding tree structure into multiple parts each of which is stored in a server For example we consider to store the ORAM tree shown in Fig 1 into three servers each of which can accommodate at most 5 buckets A partition scheme is shown in Fig 1 Since the root bucket is accessed in each read and write operation the server A holding the root bucket has the highest access load On the other hand each read operation only involves one leaf node leading to the lowest load on server B that stores ve leaf nodes in level 3 From this example we observe that ORAMbased storage would lead to serious unbalanced data access load among servers without a delicate bucket placement which motivates us to develop an algorithm to optimize the data placement in next section IV S YSTEM MODEL AND PROBLEM FORMULATION We consider to deploy an ORAM-based storage with n buckets of size B to m servers residing in multiple clouds Some authorized users generate a set of access requests that have been translated into a serious of ReadAndRemove u  and Add u  d  operations Each bucket is the minimum storage unit and is associated with an access rate a i due to the read write and eviction operations in ORAM Note that the access rate of each bucket can be estimated according to the characteristics of the ORAM algor ithm such as tree structure and eviction probability The i th server can accommodate at most C i buckets Based on the system model our load balance problem can be described as a max-min problem as follows Deìnition 1 The problem of load balance for deploying ORAM-based storage in clouds LBOC given a tree-based ORAM structure and a set of storage servers the LBOC problem seeks a data placement such that the maximum access load among all servers is minimized Since a bucket is the minimum access unit in ORAM we deìne binary variables x ij to describe bucket placement as follows x ij   1  if the i th bucket is placed on the j th server 0  otherwise  We also deìne a variable y j to represent the total access rate in the j th server and the LBOC problem can be formulated as a mixed integer linear programming MILP as follows min Y y j  Y  1  j  m  1 y j  n  i 1 a i x ij   1  j  m  2 m  j 1 x ij 1   1  i  n  3 n  i 1 x ij  C j   1  j  m  4 x ij  0  1    1  i  n 1  j  m In above formulation variable Y denotes the maximum access rate of all servers which is guaranteed by constraint 1 The calculation of total access rate y j of each server is represented by constraint 2 We impose constraint 3 because each bucket has to be placed at only one server Finally the capacity constraint of each server is represented by 4 In the following we analyze the hardness of the LBOC problem by proving its NP-hardness in a formal way Theorem 1 The LBOC problem is NP-hard Proof In order to prove an optimization problem to be NP-hard we need to show the NP-completeness of its decision form i.e we attempt to nd a bucket placement such that the maximum access load is no greater than Y  It is easy to see that such a problem is in NP class as the objective associated with a given solution can be evaluated in a polynomial time The remaining proof is done by reducing the well-known 2-partition problem i.e given a set of numbers S   s 1 s 2   s n   we attempt to divide them into two sets S 1 and S 2 such that  s i  S 1 s i   s j  S 2 s j  We now describe the reduction from the 2-partition problem to an instance of the LBOC problem We create an ORAM storage with n buckets each of which has an access rate a i  s i  There are two severs each of which can store at most n buckets Finally we let Y  1 2  s i  S s i  It is easy to verify that the 2-partition problem has a solution if and only if the constructed LBO problem has a solution that satisìes the load requirements V A LGORITHM DESIGN Due to the NP-hardness we design an efìcient heuristic algorithm to solve the LBOC problem in this section Our basic idea is to rst solve the MILP problem formulated in last section by relaxing all integer variables and then nd a feasible integer solution by rounding the results Although the time complexity of this algorithm is polynomial additional challenges arise in dealing with big data storage The ORAM tree would contain a large number of buckets to accommodate big data resulting in too many variables and constraints in the formulation Solving such a large-scale linear programming even with all real variables would be time-consuming or even impossible because of physical me mory constraints on some computers 2014 IEEE INFOCOM Workshops: 2014 IEEE INFOCOM Workshop on Security and Privacy in Big Data 526 


To overcome this difìculty we propose a low-complexity algorithm called ILB Iterative Load Balancer to iteratively place buckets on servers such that we only need to deal with a small-scale linear programming in each iteration The pseudo code of our algorithm is shown in the following Algorithm 1 Algorithm 1 The ILB algorithm 1 C res j  C j   1  j  m  2 y curr j 0   1  j  m  3 while there are buckets that havenêt been placed do 4 put a set of unplaced buckets in set N   5 solve the following linear programming min Y y j  y curr j  Y  1  j  m  5 y j   i  N  a i x ij   1  j  m  6 m  j 1 x ij 1   i  N   7  i  N  x ij  C res j   1  j  m  8 0  x ij  1   i  N   1  j  m 9 6 sort variables x ij in a descending order according to their results 7 for each x ij in the sorted order do 8 if the i th bucket in N  hasnêt been placed and C res j  0 then 9 place this bucket on the j th server 10 C res j  C res j  1  11 y curr j  y curr j  y j  12 end if 13 end for 14 end while We use two variables C res j and y curr j to maintain the residual capacity and current access load on the j th server respectively After their initialization in lines 1 and 2 we conduct bucket placement in iterations in the following while loop In each iteration we consider a set of buckets N  and solve a linear programming with respect to N   current access load and C res j on each server Different from the MILP in last section we relax x ij by letting it be a real variable between 0 and 1 as shown in 9 In addition we take current access load y curr j into consideration in constraint 5 and constrain the capacity of each server with C res j in 8 After solving this linear programming we sort variable x ij in a descending order according to their results We place the i th bucket in set N  to the server with maximum value of x ij among all servers Such placement is expected to achieve comparable performance to the optimal solution because the real value x ij would represent the probability of the corresponding optimal data placement Finally we nish current iteration by updating the values of C res j and y curr j   1  j  m  in lines 10 and 11  1 2 3 4 5 6 7 8 9 10 0 500 1000 1500 2000 2500 3000 3500 Instance Maximum access load   OPT ILB RAND Fig 2 Comparison with optimal solution in 10 random instances VI P ERFORMANCE EVALUATION In this section we study the performance of our proposed algorithm under various network settings For comparison we also show the performance of a random placement algorithm denoted by RAND All simulations are conducted using Matlab in a computer equipped with 3.4 GHz Intel Core i7 CPU and 8G memory We rst evaluate the performance of ILB by comparing its results with the optimal solution We consider to deploy 200 data buckets to 10 servers and show the results of 10 random instances in Fig 2 In average the performance of ILB is 1.15 times of optimal solution while the corresponding ratio of RAND is 1.91 We then study the performance of our proposed algorithm by averaging results over 50 random instances The inîuence of number of buckets is rst investigated by changing its value from 600 to 1000 and the number of servers is xed to 10 The server capacity is randomly speciìed as a Gaussian distribution with mean of 100 and variance of 20 In each iteration of ILB we consider data placement for 100 buckets As shown in Fig 3 the performance of both algorithms shows as an increasing function of bucket number Moreover the performance gap between two algorithms increases as the bucket number grows For example when the number of buckets is 600 the maximum access rate of RAND is 17 higher The performance gap increases to 33 as bucket number grows to 1000 The results indicate that ILB can effectively reduce the maximum access rate because of our delicate design We then study the effect of different variance of server capacity in instances with 1000 buckets and 10 servers The mean value of server capacity is xed to 100 As shown in Fig 4 although the performance of both algorithms increases as the variance grows their performance gap becomes small That is because the servers with sm all capacity quickly becomes full during data placement wh ile lots of buckets have to be accommodated in the servers with large capacity which leading to high access load Finally we investigate the time complexity of our proposed 2014 IEEE INFOCOM Workshops: 2014 IEEE INFOCOM Workshop on Security and Privacy in Big Data 527 


   600 700 800 900 1000 3000 4000 5000 6000 7000 8000 9000 Number of buckets Maximum access rate   RAND ILB Fig 3 Maximum access rate versus different number of buckets   10 20 30 40 50 5000 6000 7000 8000 9000 10000 11000 Variance Maximum access rate   RAND ILB Fig 4 Maximum access rate versus different variance of server capacity algorithm by comparing it with the one denoted by ILB-S that solves a single linear programming taking all buckets into consideration We show execution time under different instance scales in Fig 5 When there are 1000 buckets and 10 servers denoted by  1000  10  in the gure ILB and ILB-S consume 0.14s and 0.18s respectively In instances with the largest scale i.e  4000  40   the ILB-S needs 10.2s which is 3.4 times of ILB VII C ONCLUSION In this paper we apply the ORAM algorithm to achieve privacy-preserving access to big data in clouds We observe a load unbalance phenomenon after deploying ORAM-based storage to multiple servers which motivates us to investigate a data placement problem to achie ve load balance This problem is proved to be NP-hard We propose a low-complexity algorithm to solve this problem with respect to large data volumes Simulation results show that the performance of our proposed algorithm is close to optimal solution and it outperforms a random data placement algorithm R EFERENCES  D  B ea v e r  S K u m a r  H C L i  J  S obel and P  V ajgel Finding a needle in haystack Facebookês photo storage in USENIX OSDI  2010 pp 1Ö8   1000,10 2000,20 3000,30 4000,40 0 2 4 6 8 10 12 Problem scale Execution time \(sec   ILB ILBäS Fig 5 Execution time under different instance scales 2 M  I s l am  M  K uzu and M  K antar c ioglu  A cces s p atter n dis c los u r e on searchable encryption Ramiìca tion attack and mitigation in Network and Distributed System Security Symposium  2012  B  C hor  E  K us hile vitz O  G oldreich a nd M Sudan Pri v a te inform ation retrieval Journal of the ACM JACM  vol 45 no 6 pp 965Ö981 1998 4 R  S ion a nd B Car b unar  O n t he com putational p r acticality of pr i v ate information retrieval in Proceedings of the Network and Distributed Systems Security Symposium  2007 pp 2006Ö06  M  T  G oodrich a nd M Mitzenm ach er Mapreduce parallel cuckoo hashing and oblivious ram simulations CoRR  vol abs/1007.1259 2010 6 E  S hi T  H  H  Chan E  S tef a no v  and M  L i O bli v ious r a m w ith o logn 3 worst-case cost in Advances in CryptologyÖASIACRYPT 2011  Springer 2011 pp 197Ö214 7 K  D  B o w er s  A  J u els  and A  O pr ea H ail A h igha v ailability and integrity layer for cloud storage in Proceedings of the 16th ACM Conference on Computer and Communications Security  2009 pp 187 198 8 F  D abek M  F  K aas hoek D  K a r g er  R  M or r i s  and I  S toica W idearea cooperative storage with cfs in ACM Symposium on Operating Systems Principles  2001 pp 202Ö215  A  B es s a ni M  C orreia B  Q uares m a F  Andr  e and P Sousa Depsky Dependable and secure stor age in a cloud-of-clouds in Proceedings of the Sixth Conference on Computer Systems  2011 pp 31Ö46  E  S t ef ano v  M  v an D ijk A  J uels  a nd A  O p r ea I r i s  A s calable cloud le system with efìcient integrity checks in Proceedings of the 28th Annual Computer Security Applications Conference  2012 pp 229Ö238  Z  W u  M  B utkie w icz D  P e r k ins  E  K a tzB as s e tt and H  V  M adhyastha Spanstore Cost-effective geo-replicated storage spanning multiple cloud services in ACM Symposium on Operating Systems Principles  2013 pp 292Ö308  O  G o ldr e ich T o w ar ds a t heor y o f s of tw ar e p r o tection a nd s i m u lation by oblivious rams in ACM symposium on Theory of computing ACM 1987 pp 182Ö194  R Os tro v s k y  E f  cient c om putation o n obli v ious ram s   in Proceedings of ACM STOC  1990 pp 514Ö523  O  G o ldr e ich a nd R O s tr o v s k y  S of tw ar e p r o tection a nd s i m u lation on oblivious rams Journal of the ACM JACM  vol 43 no 3 pp 431Ö473 1996  E  K u s h ile vitz S  L u and R  O s t r o vs k y   O n the  in s ecur ity of has h based oblivious ram and a new balancing scheme in ACM-SIAM SODA  2012 pp 143Ö156  P  W illiam s  R  S ion and B  C ar b unar  Building cas tles out of m ud practical access pattern privacy and correctness on untrusted storage in Proceedings of the 15th ACM conference on Computer and communications security  2008 pp 139Ö148  P  W illiam s and R  S ion S ingle r ound acces s p ri v a c y on outs ourced storage in ACM CCS  2012 pp 293Ö304  J  R L o r c h B P a r no J  M i ck ens  M  Rayk o v a and J  S chif f m an Shroud ensuring private access to large-scale data in the data centers in USENIX FAST  2013 pp 199Ö213 2014 IEEE INFOCOM Workshops: 2014 IEEE INFOCOM Workshop on Security and Privacy in Big Data 528 


component. The responsibilities of this component include the validation of the input information from the user interpretation of the requests, and the request categorization The user input can be invalidated for instance if the specified data source does not exist or file format is currently not supported or the specified path is wrong. Though currently not implemented, we want to perform other tasks in the future such as document clustering, file structure organization, etc. In that case, the artifact extraction definition component will be responsible for the categorization of the input request based on the data or document extraction needs of the user. When the request is validated, the artifact extraction definition component then interprets the request as topics extraction or terms extraction. The interpreted request is then sent to the layer The goal of the semantic engine layer is to pass the request through series of reviews that w ill improve the quality of the data mining result. In the current version of the AaaS, we treat as keywords that the user wants to extract from the data source. Typical cases of topics extraction can be looking for data source. The semantic engine will not have much to do in this case but to pass the topics for extraction at the next stage However extraction involves a lot more because terms consider a specified keyword plus possible dependency keywords for interpretation. For example, when the artifact therefore the mining process will have to consider the latter keywords as well. This latter requirement convinced us to design the terms extraction as an extension on the topics. The consideration of the latter keyword can be specified by the user as part of the specification process on the input layer or left for the AaaS layer to decide and later the user can refine the result In order to clearly explain the workings of the semantic engine to the reader we provide Table II as an example that we shall use to discuss the remaining sub-components necessarily need to understand what the word mean from the line. The first problem that arises here is the presence of semantic issues where the mining process can potentially en the user actually wants be a result with a lot of False Negatives. This will eventually affect the and of the result as we shall see later in the evaluation section So, when an artifact is validated and sent to the semantic engine, the latter considers that artifact as a This topic is then forwarded to the where the actual meaning 
artifacts such as çContracté, çEconomyé, çSportsé, etc. from a Contracté is specified, it can also mean çAgreement Assuming the keyword çContracté is the specified term, we userês perspective. In the English Language, çContracté can be synonymous to çAgreementé and the other words in Table II or can be synonymous to çAfflicté and the other words in similar return terms involving çAcquireé wh Agreementé. Even if we assume that the extracted terms should just return everything on çContracté, the outcome will 
Fig. 3 The architectural design of our Analytics-as-a-Service \(AaaS\ tool The requests are first routed to the 
Topics Terms accuracy specificity 
Semantic Engine Topic Parser Request Parser Search Criteria Search Criteria Association Rules Topics Mapping HTML/RDF Data Sources SQL API Interface Definitions Extracted Artifacts Tagging Filtering Output Layer Web Browser Mobile e.g Notebooks Tablets Dashboard  REST API SOAP API MAPREDUCE SQL QUERY TAG DEFINITIONS TEXT PARSER User   Input Layer Display 
Artifact Extraction Definition Semantic Engine Topic Topic Parser 
Thesaurus Dictionary 
Textual Content e.g PDF Artifact Extraction Definition Topics Terms Search Algorithm NoSQL Serializer Clustering Data JSON Search Criteria Visualization Topics Clustering Terms Clustering 
186 


  
Keywordé: çContract Synonymé: çAgreement 
Dictionary Thesaurus Bloom Filtering Linear/Random Search algorithm Parallel/Concurrency Search algorithm Pessimistic and Optimistic Search algorithms 
002 002 002 002 002 002 002 
Artifact Synonyms Antonyms 
Arrangement Disagreement Agreement Misunderstanding Compact Break-off Settlement Fired Pact Contract Acquire Give Afflict Indispose Develop Disorder The dictionary contains predefined artifact in English, their corresponding synonyms, and antonyms. However, another concern at this point is how to make the dictionary adaptive To achieve the adaptability of the dictionary, we build a separate lexical component which is the thesaurus Adaptability in our case means that the topics and terms process should be extended or expanded to other domains outside the English Language. For instance, in the medical domain there are jargons that are not in the English dictionary or there are medical specific lexicons. To make our AaaS framework as generic as possible, the thesaurus only need to be populated with the domain specific jargons such as the case of the medical domain Since the dictionary and thesaurus are both tabular, we need to establish relationship between the artifacts. This requires a network \(or graph\ of inter-connected words because, for each word, we need to know all other artifacts that are dependencies either as synonyms or antonyms. Here is where we define a component called 
can be çSettlementé as shown in Table II which means that ill have dependency such as çContracté. So, going 
of the artifact is defined in order to generate an enhanced result. The topic parser is also important for the minimization of the other tasks ahead such as data cleansing. The topic parser has two components which are the and the These two components are storages which are built in DETS \(a disk storage facility in Erlang\to keep a tabular structure as Table II TABLE II S AMPLE A RTIFACT Contract where words are linked to each other based on the relationship that exists between the words. The topics mapping component is a script running on a methodology. Considering the vast amount of data that can exist in the lexicon \(such as the thesaurus\, it will be time consuming to go through the entire table in search for the synonyms and antonyms. Another way to imagine this scenario is: an artifact will have a synonym and the same synonym can later be an artifact which means the previous artifact becomes a synonym. For example, an artifact artifact w through the thesaurus based on sequential indexing will generate a complexity of O\(n 2 Thus, the Bloom Filtering methodology is adapted to rather build pointers between the words. In that case, for every word, we can determine the dependency keywords through referencing After the determination of all dependencies through topics mapping, an is established where the user request is matched against the topics mapping. For example the following Association Rules can be defined \(there are lot more Association Rules that can be defined based on the corporate/enterprise domain Extract all terms based on the antonyms Extract all terms based on synonyms Extract terms based on a specific synonym only These rules are contained in a JSON script internally; for example, in the case of the third rule, the JSON will be as shown below The establishment of the Association Rule prepares the semantic engine for the extraction. The rule-based JSON file is then passed to the layer. The search algorithm determines wh ich methodology to apply when searching through the data sources. As an ongoing work and discussions with some of our research partners there are proposals for the following algorithms which are adapted from    This means the data sources should be searched sequentially but after the implementation, we found the methodology is slow and causes a lot of waiting queues This works by determining the number of data sources and applying the data extraction to all the data sources simultaneously. This aided us to reduce the waiting queue Though we have explored these options in other ongoing works, we have not implemen ted it in the current work It will be considered later. Optimistic search aids the system to specify only directories which should be searched while pessimistic search allows the specification of directories that should not be searched As discussions are advanced, other search algorithms can/will be considered The search algorithm specification activates the layer. Here is where the queries are generated, constructed, and issued for the specific data sources For instance, SQL query cannot be issued for a NoSQL specified database nor a Map/Reduce query for SQL database This means for every supported data store, the query style that is specific to that data source must be issued. In the current implementation, the following Application Programming 
Topics Mapping Association Rule Terms Search Algorithm API Interface Definition 
187 


odbc:start\(\             //to start the ODBC ok, Ref} = odbc:connect\("DSN=sql-bigserver; UID bigdata; PWD=conf           t o c onn ec t to th e  da taba s e  
002 002 002 
Normalization Grouping Integration Topic Clustering Terms Clustering Windows 7 System 32, 4.12 3.98 GHz, 16GB RAM, 1TB HDD Processor: Intel Xeon, CPU E5410 @ 2.33GHz, 2.41GHz, RAM: 1.70GB System 32-bit operating system 
Data Sources Extracted Artifacts Serializer Tagging Filtering Clustering Visualization 
Interfaces \(APIs\ are defined and fully functional. This is the part that is crucial to the developers because the understanding of the APIs is what will allow the customization of the queries for the specific mining task The REpresentational State Transfer \(REST API is defined for NoSQL databases that support clear semantic queries. These databases support HTTP operations such as GET \(to read data\ POST \(to create records\, PUT \(to update existing records\, and so on. Also, there are publicly available NoSQL service providers that expose their services end-point as REST. Examples are Amazon S3, etc The SOAP API support SOA-based data stores over Web services calls. The returned result for the SOAP API query is in XML format. The SOAP requests are all sent using the HTTP POST method. Amazon Services and most existing legacy services are running on the SOAP protocol The Map/Reduce API is employed to make the REST-based query much simplified on the AaaS. For example, Map/Reduce involves filtering and sorting for NoSQL systems such as Hadoop, CouchDB, etc. and this leads to processing workload. So, instead of delegating the Map/Reduce functionality to the data store to process, we allow the processing to be done by the AaaS. Thus, when the request reaches the data store, the only workload is the processing of the request \(i.e., the workload regarding the request construction is offloaded to the AaaS This is where queries are constructed for the structured and schema oriented databases such as the SQL. In the Erlang environment, the connection to the SQL is over ODBC as shown below This API is defined for tag-based data sources \(i.e., file databases\ such as XML, HTML, and RDF These styles of databases are described as semi-structured because though the content is textual, the texts are defined within specific tags. Thus, the text mining can be done by defining tags This API is designed for purely text-based files with no structure. Examples are PDF files, .DOC, etc. The Text Parser API considers the specified artifact \(i.e., Topic or Term\ and does scanning through th e file in order to read the occurrences of those artifacts The completion of the query construction opens the connection to the specified database on the layer This layer is not necessarily on the same environment as the AaaS framework. The data source can be on remote servers within the same organization, outside repositories, or on the same server as the AaaS. For every request that is issued by the specific API interface to the data source, a response is expected which is passed to the layer The extracted artifact layer is where the Knowledge Discovery in Database \(KDD\ process starts. The goal here is to determine existential evid ence of topic and terms relationship through the KDD process. The data which is returned from the data source through the API interface is passed to the component. There are cases where the returned data is from multiple API interfaces especially when the data mining process involves multiple data sources. Thus the Serializer is the first compon ent that receives the data and performs the following macro activities reducing the redundancy of the data and establishing relationship between the artifacts Organizing similar artifacts into categories and Merging the artifacts into a format that gives single dimensional overview of the search result After the Serializer is done is performed the data Tagging involves determining the sources of each data occurrences of specific artifacts, frequency of artifact occurrences etc. for statistic al purposes. Once the tagging process is complete, the data is passed to the component. Here is where the topics and terms are organized based on relevance. For instance, we can determine relevance based on the frequency of occurrences of terms from the tagging process; and only report results based on certain thresholds such as top 100 terms an d so on. The filtered data is then organized based on where the data is modelled in JSON format for easy passing. Depending on the data mining need as specified by the user, the JSON data is parsed as or to the layer. For instance, Fig. 4 gives a tag cloud visualization of from over 3 million HTML-based sources on the Web from North America. The visualization reports 42 most relevant measured relevance based on the rate of recurrence of those keywords from the various sites. Currently we are aiming at integrating our visualization with the InfoVis framework Results from the visualization layer are sent to the Output layer which is primarily the platform of choice that the user prefers to view the result. Currently, results can be viewed as a browser content, on tablet and notebooks, and as dashboard In the next section, we discuss some of our preliminary results after evaluating the AaaS tool V E VALUATION The AaaS framework is evaluated based on the quality of term mining from the various data sources. The accuracy of the terms being extracted is measured in the NoSQL, Web, and SQL environments. We deployed our framework on our Window-based system with the following specifications  We considered a training data s et of 30 million entries which is spread across 30 different NoSQL databases \(CouchDB\ with file attachments which are de ployed on an Amazon EC2 instance with the following specifications The 30 million medical related records are divided into 30 groups where 1 million records are 
terms extraction related to çPsychiatryé using our AaaS tool keywords that form part of the term çPsychiatryé. We 
REST API SOAP API MAPREDUCE SQL QUERY TAG DEFINITIONS TEXT PARSER 
188 


choice of a userês 
Linear Search Parallel Search Pessimistic Search Optimistic Search True Positive 94.80 94.27 87.21 88.07 False Positive 2.60 2.81 2.34 3.20 True Negative 100.00 100.00 97.28 96.56 False Negative 0.34 0.77 41.31 23.32 Precision 97.33 97.11 97.39 96.49 Recall \(Sensitivity 99.64 99.19 67.86 79.06 Specificity 97.47 97.27 97.65 96.79 Accuracy 98.51 98.19 80.87 87.44 F1 Score 98.47 98.14 79.98 86.91 TABLE IV A NALYZING THE E XTRACTED T ERMS FROM THE W EB Linear Search Parallel Search Pessimistic Search Optimistic Search True Positive 91.61 96.33 75.55 74.09 False Positive 5.23 8.34 6.85 5.89 True Negative 95.85 97.09 99.44 99.03 False Negative 4.79 5.23 24.86 28.45 Precision 94.60 92.03 91.69 92.64 Recall \(Sensitivity 95.03 94.85 75.24 72.25 Specificity 94.83 92.09 93.56 94.39 Accuracy 94.93 93.44 84.66 83.45 F1 Score 94.81 93.42 82.65 81.19 TABLE V A NALYZING THE E XTRACTED T ERMS FROM THE SQL Linear Search Parallel Search Pessimistic Search Optimistic Search True Positive 97.33 97.81 93.74 94.55 False Positive 1.06 1.01 0.40 0.20 True Negative 99.97 99.91 99.93 99.90 False Negative 0.01 0.01 0.11 0.11 Precision 98.92 98.98 99.58 99.79 Recall \(Sensitivity 99.99 99.99 99.88 99.88 Specificity 98.95 99.00 99.60 99.80 Accuracy 99.46 99.49 99.74 99.84 F1 Score 99.45 99.48 99.73 99.84 
stored in each CouchDB database.  This dataset is a validated data which is used in the experiments in [34  Th en  w e  crawled some medical information websites such as healthcare providers, facilities, locations, specializations, etc. from approximately 5000 websites. This information forms the basis of our training datasets in this experiment. It is important to state that the information collected is just for test purposes of our tool and not for any other reason By focusing on the various data sources, we perform the terms extraction based on the proposed mining algorithms such as Linear Search, Parallel Search, Pessimistic Search, and Optimistic Search. In Table III, we report the evaluation from the NoSQL databases. The Pessimistic Search and Optimistic Search are dependent on the user who is performing the experiments because the choice of selection is subjective. For instance, the data source not to be searched may be different from the choice of another user. From the result, the Pessimistic Search and the Optimistic Search shows high false negative because of the user selection. In cases where the user thinks there can be terms, that is not the case This also applies to the cases where the user thinks terms may not be found somewhere. The advantage of the two methodologies however is the ability to perform quick search when the user has an idea about the location of the specified term TABLE III A NALYZING THE E XTRACTED T ERMS FROM THE N O SQL 
189 


research in web intelligence, mining the 2nd International Conference on Web Intelligence, Mining and Semantics \(WIMS '12\. ACM, New York, NY, USA, , Article 0 , 5 pages. DOI=10.1145/2254129.2254131 http://doi.acm.org/10.1145/2254129.2254131 3 P  C  Z I K O PO U L O S  C  E A T ON D d e R OOS T  DE UT SC H A N D G   Hill Companies 2012 https://www.ibm.com/developerworks/community/wikis/home?lang=en wiki/Big%20Data%20University/page/FREE%20ebook%20%20Understanding%20Big%20Data 4 http://www.information-management.com/newsletters/data-miningunstructured-big-data-youtube--10022781-1.html 5 Analytics-as-a-Service Platform http://researcher.ibm.com/researcher/view_project.php?id=3992 6 Data tutorial at Semtech 2012, Jun 07, 2012. Available http://www.slideshare.net/juansequeda/linked-data-tutorial-at-semtech2012 7 G oo gl e  K now le dg e G r aph A v ail a bl e   http://www.google.ca/insidesearch/features/search/knowledge.html 8 N oSQ L  h t tp  n os q l d at ab a s e org 9 E M C   rney to Big Data with Business Analyticsas-a http://www.emc.com/collateral/white-papers/h11259emc-accelerates-journey-big-data-ba-wp.pdf  Analytics as a Service http://www.sas.com/offices/europe/uk/resources/brochure/aaas_research _brief.pdf  X SUN B G AO  L  F A N  A ND W  A N   A C os t E ffec t i ve A p p r oa c h to Delivering Analytics as a Service," IEEE 19th International Conference on Web Services \(ICWS 2012\, vol., no., pp.512,519, 24-29 June 2012, doi: 10.1109/ICWS.2012.79 12 P. D EEPA K  P. M  D ES H PA N D E A N D  K  M U RT H Y Co n fig u ra b l e  and Extensible Multi-flows for Providing Analytics as a Service on the Cloud," 2012 Annual SRII Global Conference \(SRII\, , vol., no pp.1,10, 24-27 July 2012, doi: 10.1109/SRII.2012.11 13 F S  GH AR E evaluation of unstructured data: text mining versus natural language Technologies \(AICT\, 2011 5th International Conference on , vol., no pp.1-4, 12-14 Oct. 2011, doi: 10.1109/ICAICT.2011.6111017  performance Text Conference on Computer Systems and Technologies  S V. VI NC HUR KA R  A ND S  M  N I R K H I   of Emerging Technology and Advanced Engineering, \(ISSN 2250-2459 Volume 2, Issue 1, January 2012  Mine 2003\, pp. 10-17  Based Information Mining from July 1997  M  DE L GA DO M   M A R T  N B A U T I S T A   D S NC HE Z   A ND M   Detection and Discovery, Lecture Notes in Computer Science, 2002 Volume 2447/2002, 175-186, DOI: 10.1007/3-540-45728-3_11 
evidently clear that çBig Dataé has come to stay. This is 
The Linear Search and Parallel Search however shows consistent result since the focus is on the entire specified data source. The false negative values are small and the true positive index is also high. An observation however is that, the false positive and false native results in the Linear Search also re-occur in the Parallel Search. This can be attributed to the fact that the Linear Search is the underlying methodology on which the Parallel Search is running In Table IV, the result from crawling some selected websites are shown. This websites are for health care providers. Using similar types of terms from the NoSQL, we perform similar searches on the Web. The accuracy index dropped because there were higher false positive and false values. This is more likely due to the fact that the web is wide with similar written terms but with different meanings. Since not all the keywords from the web are captured in the Dictionary/Thesaurus, most of the specified terms were mislabeled In Table V, we report the results from the search in the SQL database. The data here is a fraction of the NoSQL version. The results in the structured data source show very high accuracy in comparison to the rest of the data sources This is not because the proposed framework works better with structured data source but, because the data itself is very small in comparison to the rest. Further, we know where to find most of the terms we were looking for so narrowed our database choice in the case of the Pessimistic and Optimistic Search methodologies VI C ONCLUSION With the present direction of corporate transactions, it is because most traditional business transactions which use to be paper-based are all being digitized. Besides, user generated content across different spectrum of the enterprise landscape is increasing in volume at an exponential rate. While Big Data has its tremendous advantages, the fact that the data is heterogeneous \(i.e., variety\poses new challenges Previously, the data mining and knowledge discovery in database \(KDD\procedures were designed for schema-oriented databases. However, the data today is multifaceted and has no schema. Though the NoSQL databases have been proposed to accommodate the data, not many tools are available that performs data mining and analytics from such storages Our work details an Analytics-as-a Service \(AaaS\ tool that performs terms mining and analytics from multiple data sources. Currently, the following data sources are supported NoSQL \(e.g., document style storages such as CouchDB SQL, Tag/Flat file storage \(HTML, XML, RTF\, and Textual Documents \(e.g., PDF\ Furthermore, we conducted experiments using the various styles of storage such as NoSQL, Web, and SQL. The pilot testing shows an encouraging result especially from the NoSQL domain. Our future extension aims at incorporating learning and adaptability features. This will further facilitate the ability to do recommendations for users based on their term and topic mining requirements R EFERENCES  M R WI GA N A N D R   C L A R K E  B i g D a ta  s  B i g Uni nt e nd ed Consequences," Computer , vol.46, no.6, pp.46-53, June 2013, doi 10.1109/MC.2013.195 2 
R. AKERKAR, C. BADICA, AND C. B. BURDESCU, çDesiderata for and semanticsé. In Proceedings of LAPIS, çUnderstanding Big Data: Analytics for Enterprise Class Hadoop and Streaming Data,é Published by McGraw K. RUPANAGUNTA, D. ZAKKAM, AND H. RAO, çHow to Mine Unstructured Data,é Article in Information Management, June 29 2012 IBM Research Available J. SEQUEDA AND DANIEL P. MIRANKER, çLinked Data,é Linked EMC Accelerates Jou Service SAS Customer Experiences HCHOPOGH, AND Z. A. KHALIFELU, çAnalysis and processing,é Application of Information and Communication V. TUNALI, AND T. T. BILGIN, çPRETO: A High Mining Tool for Preprocessing Turkish Texts,é 2012 International Feature Extraction of Product from Customer Feedback through Blog,é International Journal D. KUONEN, çChallenges in Bioinformatics for Statistical Data rs,é Bulletin of the Swiss Statistical Society, Vol. 46 \(October J. Y. HSU, AND W. YIH, çTemplate HTML Documents,é American Association for Artificial Intelligence VILA, çMining Text Data: Special Features and Patterns,é Pattern 
190 


 ing: A Singapore, No. 2003116 , 2003 20 W  A BRA MO W I CZ T   K A C Z MA R E K  A N D  M K O W A L K I E W I C Z  Australasian Journal of Informati on Systems, Special Issue 2003/2004 Vol 11, No 1  Conference on Communication, Computing & Security \(ICCCS '11 ACM, New York, NY, USA, 397-402  Bioinformatics 2010, 11:549 doi:10.1186/1471-2105-11-549  text min Analytics for Noisy Unstructured Text Data \(AND '09\. ACM, New York, NY, USA, 107-114  Packard Development Company L.P  S G ODB O L E   I  B HAT T A C H A R YA   A  G UP T A  AND A  VE R M A   usable dictionary repositories for realIn Proceedings of the 19th ACM international conference on Information and knowledge management \(CIKM '10\. ACM, New York NY, USA, 1189-1198  R  F E L DM A N M  F R E S K O  H H I R S H Y A UM A NN O  Practical Aspects of Knowledge Management \(PAKM98\, Basel Switzerland, 29-30 Oct. 1998  R  F E L DM A N M  F R E S K O  Y KI N A R  Y  L I NDE L L  O  Principles of Data Mining and Knowledge Discovery \(PKDD'98  J  DESI-III Workshop Barcelona, Monday June 8, 2009  J  L E E  D G R OSSM A N  O F R I E DE R  A ND M  C  M C C A B E  Proc. of Information Technology: Coding and Computing, 2000 International Conference on , vol., no., pp.264-269, 2000  Intelligence, VOL. 1, NO. 1, AUGUST 2009  E r la n g Progra m i n g L a n gu a ge h t t p www  e rla n g org   R  K  L OM OT E Y AND R  DE T E RS Analytics-as-a-Service \(AaaS Tool for Unstructured Data Mining of the 2014 IEEE International Conference on Cloud Engineering \(IC2E 14\ pages: 6 March 10-14, 2014. Boston, Massachusetts, USA  R  K  L OM OT E Y A ND R  DE T E R S  RSenter: Tool for Topics and Terms Extraction from Unstructured Data Debris Proc. of the 2013 IEEE International Congress on Big Data \(BigData Congress 2013 pp:395-402, Santa Clara, California, 27 June 2 July 2013  R  K  L OM OT E Y A ND R  DE T E RS RSenter: Terms Mining Tool from Unstructured Data Sources To Appear in: International Journal of Business Process Integration and Management \(IJBPIM 
Q. ZHAO AND S. S. BHOWMICK, çAssociation Rule Min Survey,é Technical Report, CAIS, Nanyang Technological University Supporting Topic Map Creation Using Data Mining Techniques B. JANET, AND A. V. REDDY, çCube index for unstructured text analysis and mining,é In Proceedings of the 2011 International L. HAN, T. O. SUZEK, Y. WANG, AND S. H. BRYANT, çThe Text mining based PubChem Bioassay neighboring analysis,é BMC L. DEY, AND S. K. M. HAQUE, çStudying the effects of noisy text on ing applications,é In Proceedings of the Third Workshop on A. BALINSKY, H. BALINSKY, AND S. SIMSKE, çOn the Helmholtz Principle for Data Mining,é Hewlett Building re world text mining LIPHSTAT, Y. SCHLER, AND M. RAJMAN, çKnowledge Management: A Text Mining Approach,é Proc. of the 2nd Int. Conf. on LIPHSTAT, M. RAJMAN, Y. SCHLER, AND O. ZAMIR, çText mining at the term level,é Proc. of the 2nd European Symposium on C. SCHOLTES, çText Mining: The next step in search technology Integrating structured data and text: a multi dimensional approach V. GUPTA AND G. S. LEHAL, çA Survey of Text Mining Techniques and Applications,é Journal of Emerging Technologies in Web  Proc      
191 


             


      


 14   Variable name="Request_ID" kind="linkToIndication" dataType="UINT16" units="none   Variable name="Result" kind="indication" dataType="UINT16" units="none   Enumeration    Option name="No_Error value="1 description Request was successful  are valid   Option name="Failure value="2 description Request could not be fulfilled  Variables returned are invalid   Enumeratio n   Variable   Variable name="Device_ID" kind="ID" dataType="UINT16" units="none    Variable name="RSSI" kind="signalStrength" dataType="UINT16" units="none    Variable name="Battery_Status" kind="batteryLife" dataType="UINT16" units none    Variable name="Architecture" kind="hardwareArchitecture" dataType="UINT08" units="none     Enumeration   Option name="cc2430" value="1" description="The device is a TI cc2430 board   Option name="cc2530" value="2 description="The device is a TI cc2530 board   Enumeration    Variable    Variable name="TIM_Type" kind="nodeType" dataType="UINT08" units="none     Enumeration   Option name="coordinator" value="1" description="The node is a cting as a ZigBee  coordinator   Option name="router" value="2" description="The node is acting as a ZigBee  router     name="end device value="3 description="The node is acting as a ZigBee  end device   Enumeration    Variable   DataReplyMsg   Request   Interface     Interface id="3" name="Thermistor" description="Thermistor service interface   Request   CommandMsg id="1" name="DVS_GET_TEMPERATURE.request   Variable name="Re quest_ID" kind="linkToIndication" dataType="UINT32" units="none   Variable name="Device_ID" kind="ID" dataType="UINT32" units="none   CommandMsg   DataReplyMsg id="1" name="DVS_GET_TEMPERATURE.indication   Variable name="R equest_ID" kind="linkToIndication" dataType="UINT32" units="none   Variable name="Result" kind="indication" dataType="UINT08" units="none   Enumeration   Option name="No_Error value="1 description="Request was successful  are valid   Option name="Failure value="2 description="Request could not be fulfilled  Variables returned are invalid   Enumeration   Variable   Variable name="Temperature kind="tempera ture dataType="FLOAT64 units="F rangeMin="0 rangeMax="100" accuracy="0.10   Variable name="Thermistor_Status" kind="thermistorStateIndication" dataType="UINT08" units="none   Enumeration   Option name="No_Error" value 1" description="The device has detected no errors   Option name="Error" value="2" description="The device has detected an error   Enumeration   Variable   DataReplyMsg   Request   Request   Command Msg id="2" name="DVS_GET_SENSOR_RATE.request   Variable name="Request_ID" kind="linkToIndication" dataType="UINT32" units="none   Variable name="Device_ID" kind="ID" dataType="UINT32" units="none   CommandMsg   DataReplyMs g id="2" name="DVS_GET_SENSOR_RATE.indication   Variable name="Request_ID" kind="linkToIndication" dataType="UINT32" units="none   Variable name="Result" kind="indication" dataType="UINT08" units="none   Enumeration    Option name="No_Error value="1 descr iption="Request was successful  are valid   Option name="Failure value="2 description Request could not be fulfilled  Variables returned are invalid   Enumeration   Variable   Variable name="Sensor_Publish_Rate" kind="duration" dataType="FLOAT64" units="s   DataReplyMsg   Request   Request  


 15   CommandMsg id="3" name="DVS_SET_SENSOR_RATE.request   Variable name="Request_ID kind="linkToIndication" dataType="UINT32" units="none   Variable name="Device_ID" kind="ID" dataType="UINT32" units="none    Variable name="Sensor_Publish_Rate" kind="rateChangeRequest" dataType="FLOAT64" units="s   CommandMsg    DataReplyMsg id="3" name="DVS_SET_SENSOR_RATE.indication   Variable name="Request_ID" kind="linkToIndication" dataType="UINT32" units="none   Variable name="Result" kind="indication" dataType="UINT08" units="none   Enumerat ion   Option name="No_Error value="1 descri ption="Request was successful Variables returned are valid   Option name="Failure value="2 description Request could not be fulfilled  Variables returned are invalid   Enumeration   Variable   Variable name="Sensor_Publish_Rate" kind="duration" dataType="FLOAT64" units="s    Variable name="Sensor_Publish_Rate_Status kind="PublishRateStateIndication dataType="UINT08 units="none   Enumer ation   Option name="Not_Supported value="1 description="The sensor device does not implement this rate   Option name="Rate_Changed value="2 description="The sensor device has updated its publish rate   Enumerat ion   Variable   DataReplyMsg   Request   Notification   DataMsg id="1" msgRate="1" msgArrival="PERIODIC" name="DVS_GET_TEMPERATURE_PERIODIC.indication   Variable name="Temperature kind="temperature dataType="FLOAT64  units="F rangeMin="0 rangeMax="100" accuracy="0.10   Variable name="Thermistor_Status" kind="thermistorStateIndication" dataType="UINT08" units="none   Enumeration   Option name="No_Error" value="1" description="The de vice has detected no errors   Option name="Error" value="2" description="The device has detected an error   Enumeration   Variable   DataMsg   Notification   Interface  xTEDS    


 16  ES   1 a   Gi l s t r a p    Ba l d w i n   S      Fa u l t  T o l e r a n c e  i n  e  Wi r e l e s s  S e n s o r  Ne t wo r k s    I E E E  Ae r o s p a c e   2 0 1 0  P 1 4 8 0 5  2 Al e n a   R  a  F  O s s e n f o r t  J  I nt e l l i ge nt  W i r e l e s s  Se n s o r  N e t w o r k s  f o r  Sp a c e c r a f t  H e a l t h  M o n i t o r i n g    AA  In fo t e c h  C o n fe re n c e  2 0 1 2  3 C om pl e t e  s t a nda r d doc um e nt s  a nd w hi t e  pa pe r s  a r e  av ai l ab l e at  t h e e o r g  w e b  p a g e   e o r g S ta n d a r d s  Zi g B e e Ne t wo r k De v i c e s  Ov e r vi e w  a s px  4 G 133 1 2013  S pa c e  P l ug d Pl a y  A r c h i t e c t u r e  St a n d a r d s  D e v e l o p m e n t G u id e b o o k P u b lis h e d 2 0 1 3  5 P l u g d Pl a y   Pn P  St r u c t u r e s  f o r  Sa t e l l i t e  A p p l i c a t i o n s   ht t p   w w w  a f s bi r s t t r  c om  P ubl i c a t i ons  D oc um e nt s  I nnov n 042309 Sp a c e W o r k s 6 pdf  6 I EEE  ht t p   w w w  ni s t  gov e l  i s d i e e e  i e e e 1451 c f m  7 Z a ck  r ef er en ce U R L   ht t p   v as t  u ccs  ed u  p r o j ect s  t r au m ag p s _ f i l es  d o cs  ch i p co n  Z k f   8 C C 2 530 R e f e r e nc e  U R L   www t i  c o m  l i t  d s  s y m l i n k  cc2 4 3 0 f   9 R ef er en ce A r ch i t ect u r e f o r  S p ace I n f o r m at i o n  Ma n a g e m e n t   C C S D S  3 1 2  0 G 0  Gr e e n  B o o k   M a r c h  2013  0 D DS  r e f e r e n c e  UR L   p o r t a l s  g  dds    1 A AC  M i c r o t e c  r e f e r e n c e  UR L   p p n p a a c m ic r o te c c o m in d e x p h p in tr o d u c tio n to ug d pl a y ht m l  2 D ig i r e f e r e n c e U R L  ht t p   w w w  di gi  c om  pr oduc t s  Zi g B e e   3 P B o o n m a a n d J S u z u k i  T o w ar d  I n t er o p er ab l e Pu b l i s h  Su b s c r i b e  C o m m u n i c a t i o n  b e t w e e n  W i r e l e s s  Se n s o r  N e t w o r k s  a n d  A c c e s s  Ne t wo r k s    I n  Pr o c   o f  IE E E  In t e r n a t i o n a l  W o r k s h o p  o n  In f o r m a t i o n  R e t r i e v a l  i n  Se ns or  N e t w or k s   I R SN  L a s V e g a s N V J a n u a r y 2 0 0 9   B IO G R A P H Y  Ri c h a r d  L   Al e n a  is  a   En g i n e e r  i n  t h e  I n t e l l i g e n t  S y s t e m s  Di v i s i o n  a t  NAS A Am e s   M r   Al e n a  wo r k e d  o n  t h e G r o u n d  D at a Sy s t e m  a n d  p e r f o r m e d  Co m m u n i c a t i o n s  A n a l y s i s  d u r i n g  ope r a t i ons  f or  t he  L C R O S S  L una r  Mi s s i o n  a n d  o n  a v i o n i c s  a n d  s o f t w a r e  a r c h i t e c t u r e s  f o r  Lu n a r  S u r f a c e  S y s t e m s  f o r  h u m a n  m i s s i o n s   H e  w a s  t h e  c o le a d  f o r  th e  A d v a n c e d  D ia g n o s tic  S y s te m s  f o r  I n l Sp a c e  St a t i o n   I SS  Pr o j e c t   d e v e l o p i n g  m o d e l d di a gnos t i c  t ool s  f or  s pa c e  ope r a t i ons   H e  w a s  t he  c hi e f  ar ch i t ect  o f  a f l i g h t  ex p er i m en t  co n d u ct ed  ab o ar d  S h u t t l e an d  M i r  u s i n g  l ap t o p  co m p u t er s   p er s o n al  d i g i t al  as s i s t an t s  an d  s er v er s  i n  a w ir e le s s  n e tw o r k  f o r  th e  I S S  H e  w a s  a ls o  th e  te c h n ic a l le a d  f o r  th e  D a ta b u s  A n a ly s is  T o o l f o r  In t e rn a t i o n a l  S p a c e  S t a t i o n  o n or bi t  di a gnos i s   H e  w a s  gr oup l e a d f or  I nt e l l i ge nt  M obi l e  T e c hnol ogi e s   de ve l opi ng pl a ne t a r y e xpl or a t i on s ys t e m s  f or  f i e l d s i m ul a t i  Al e n a  h o l d s  a n  M  S   i n  E l e c t r i c a l  E n g i n e e r i n g  a n d  Co m p u t e r  S c i e n c e  f r o m  t h e  U n i v e r s i t y  o f  Ca l i f o r n i a   Be r k e l e y   H e  i s  t h e  w i n n e r  o f  t h e  N A S A  S i l v e r  S n o o p y  Awa r d  i n  2 0 0 2   a  NAS A Gr o u p  Ac h i e v e m e n t  Awa r d  i n  1998 f or  hi s  w or k on t he  I S S  P ha s e  1 P r ogr a m T e a m a n d  a  Sp a c e  Fl i g h t  A w a r e n e s s  A w a r d  i n  1 9 9 7    Joh n  O s s e n f or t  is  a C om put e r  S ci en t i s t  an d  em p l o y ee o f     at  N A S A  A m es  R es ear ch  Ce n t e r    cu r r en t l y  w o r k i n g   th e  D is c o v e r y  a n d  S y s te m s  H e a lth  re s e a rc h  a re a  in te g r a tin g  f a u lt ma n a g e me n t  t e c h n ol ogi e s  w i t h ad v an ced  t es t i n g  an d  de m ons t r a t i on of  t he  O r i on M ul t i pur pos e  C r e w  V e hi c l e   I n  th e  p a s t h e  h a s  wo r k e d  i n  n e t wo r k i n g  a n d  s y s t e m s  ad m i n i s t r at i o n  o n  s ev er al  ex p l o r at i o n  p r o j ect s  an d  pa r t i c i pa t e d i n ous  fi e l d  s i m u l a t i o n s   a s s i s t i n g  i n  a l l  p ect s  o f  w i r ed  an d  w i r el es s  n et w o r k  d es i g n   d ep l o y m en t   tr o u b le s h o o tin g  a n d  m a in te n a n c e  J o h n  h a s  a  d u a l B A  de gr e e  i n A nt hr opol ogy a nd E a s t  A s i a n S t udi e s  f r om  Wa s h i n g t o n  U n i v e r s i t y  i n  S t   L o u i s    Th o m  S t o n e  is  a  S e n io r  C o m p u te r  Sc i e n t i s t  w i t h  C o m p u t e r  Sc i e n   h  Ba c h e l o r s  d e g r e e  a t  SU NY  St o n y  B r o o k   Mr   S t o n e  h a s  be e n a t  N A S A  A R C  e m pl oye d by va r i ous  c ont r a c t or s  s i nc e  1989  wo r k i n g  on a dva nc e d ne t w or ki ng  He  wa s  a n  e n g i n e e r  wi t h  t h e  NAS A Sc i e n c e  I n t e r n e t  p r o j e c t  o f f i c e  w h e r e  h e l ed  t h e p r o j ect  t h at  b r  re l i a b l e  In t e rn e t  c o n n e c t i o n s  t o  re m o t e  l o c a t i o n s  i n c l u d i n g  U  S   ba s e s  i n A nt a r c t i c a  i nc l udi ng M c M ur do S t a t i on a nd Am u n d s o n  S c o t t  S o u t h  P o l e  S t a t i o n   He  wa s  p r i n c i p a l  en g i n eer  f o r  co m m u n i cat i o n s  f o r  t h e N A S A  S ear ch  f o r  t er r es t r i al  I n t el l i g en ce  S E T I   p r o j ect  an d  w as  a s en i o r  en g i n eer  f o r  t h e S p ace S t at i o n  B i o l o g i cal  R es ear ch  P r o j ect   Be f o r e  h i s  i n v o l v e m e n t  w i t h  N A S A   S t o n e  w a s  e m p l o y e d  i n  th e  c o m p u te r  a n d  c o m m u n ic a tio n s  in d u s tr y  a n d  ta u g h t te le c o m m u n ic a tio n s a t th e u n d e r g ra d u a t e  l e v e l    


 17  Jar r e n  A   B al d w i n  is  a  Ch i c a g o  n a t i v e  a n d  c u r r e n t l y  se r v e s a s t h e  l e a d  E l e c t r i c a l  En g i n e e r  a t  B a y  A r e a  s t a r t u p   Oc u l e v e  I n c   He  g r a d u a t e d  fr o m  t h e  U n i v e r s i t y  o f Il l i n o i s  wi t h  a  B  S   i n  2 0 0 9  an d  r ecei v ed  an  M  S   i n  El e c t r i c a l  En g i n e e r i n g  f r  St a n f o r d  U n i v e r s i t y  i n  2 0 1 2   Ja r r e n  d e v e l o p e d  h a r d w a r e  a n d  so f t w a r e  sy st e m s f o r  a  w i d e  ra n g e  o f  f i e l d s   i n c l u d i n g  s p a c e  s c i e n c e  s y s t e m s  a n d  m e d i c a l  de vi c e s  a s  a N A S A  A m es  i nt e r n i n t he  In t e l l i g e n t  S y s t e m s     1  2  3   4   5   6   7   8   9   10   11   12   13   


                        


                           


   












































     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



2006 IEEE International Conference on Systems Man and Cybernetics October 8-11 2006 Taipei Taiwan Mining Fuzzy Multiple-level Association Rules under Multiple Minimum Supports Yeong-Chyi Lee Tzung-Pei Hong and Tien-Chin Wang Abstract-Finding association rules in transaction databases is most commonly seen in data mining In real applications different items may have different support criteria to judge their importance taxonomic relationships among items may appear and data may have quantitative values This paper thus proposes a fuzzy multiple-level mining algorithm for extracting knowledge implicit in quantitative transactions with multiple minimum supports of items Items may have different minimum supports and the 
maximum-itemset minimumtaxonomy support constraint is adopted to discover the large itemsets Under the constraint the characteristic of downward-closure is kept such that the original Apriori algorithm can be easily extended to find fuzzy large itemsets The proposed algorithm adopts a top-down progressively deepening approach to derive large itemsets It can also discover cross-level fuzzy association rules under the maximum-itemset minimum-taxonomy support constraint An example is also given to demonstrate that the proposed mining algorithm can derive the multiple-level association rules under multiple item supports in a simple and effective way I INTRODUCTION Among the data-mining technologies finding association 
rules in transaction databases is most commonly seen 1 2][3][7][8 An association rule is expressed as the form A a B where A and B are sets of items such that the presence of A in a transaction will imply the presence of B in the same transaction It is initially applied to market basket analysis for getting relationships of purchased items The mined knowledge about the items tending to be purchased together can then be passed to managers as a good reference in planning store layout and market policy Transaction data in real-world applications usually consist of quantitative values so designing 
a sophisticated data-mining algorithm able to deal with quantitative data presents a challenge to workers in this research field 3][8 Recently fuzzy set theory has been used more and more frequently in intelligent systems because of its simplicity and similarity to human reasoning In real applications different items may have different This research was supported by the National Science Council of the Republic of China under contract 
T P Hong is with the Department of Electrical Engineering National University of Kaohsiung Kaohsiung 81 1 
NSC 94-2213-E-390-005 Y C 
Lee is with the Department of Information Engineering I-Shou University Kaohsiung 84008 Taiwan R.O.C e-mail d9003OO7\(stmail isu.edu.tw 
Taiwan R.O.C corresponding author phone 886+7+5919191 fax 886+7+5919374 e-mail tphong nuk.edu.tw T 
Management I-Shou University Kaohsiung 84008 Taiwan R.O.C e-mail tcwang@isu.edu tw criteria to judge their importance The support requirements thus vary with different items For example the minimum supports for cheaper items may be set higher than those for more expensive ones Liu et al 6 proposed an approach for mining association rules with non-uniform minimum support values Their approach allowed users to specify different minimum supports to different items Wang et al 9 proposed a mining approach which grouped items into disjoint sets called bins and items within the same bin were 
C Wang is with the Department of Information 
regarded as non-distinguishable with respect to the specification of a minimum support We also proposed a simple and efficient algorithm based on the Apriori approach to generate large itemsets under the maximum constraints of multiple minimum supports 4][5 Furthermore taxonomic relationships among items often appear in real applications For example wheat bread and white bread are two kinds of bread Bread is thus a higher level of concept than wheat bread or white bread The information needed by decision makers in some applications is not necessary to be detailed to the primitive concept level but at a higher one For example the association rule bread milk may 
be more helpful to decision makers than the rule wheat bread juice milk Discovering association rules at different levels may thus provide more information than that only at a single level 2][7 This paper thus proposes a fuzzy multiple-level mining algorithm with multiple supports of items for extracting implicit knowledge from transactions stored as quantitative values The proposed algorithm adopts a top-down progressively deepening approach to finding large itemsets It integrates fuzzy-set concepts data-mining technologies and multiple-level taxonomy to find fuzzy association rules in given transaction data sets Each primitive item is given a predefined support threshold and the minimum support of 
an item at a higher level and an itemset is determined by the maximum of the support thresholds of the items contained in it The mined rules are expressed in linguistic terms which are more natural and understandable for human beings II REVIEW OF RELATED MINING ALGORITHMS In this section some related researches about mining multiple-level association rules and mining association rules with multiple minimum supports are reviewed in this section A Mining Multiple-Level Association Rules Previous studies on data mining focused on finding association rules at a single-concept level Mining association rules at multiple concept levels may however lead to 1-4244-0100-3/06/$20.00 C2006 IEEE 4112 


discovery of more general and important knowledge from data Relevant item taxonomies are usually predefined in real-world applications and can be represented as hierarchy trees Terminal nodes on the trees represent actual items appearing in transactions internal nodes represent classes or concepts formed from lower-level nodes A simple example is given in Fig 1 Food Dairyland Foremost Fig 1 OldMills Wonder A taxonomy example Han and Fu 2 proposed a method for finding level-crossing association rules at multiple levels Their method could find flexible association rules not confined to strict pre-arranged conceptual hierarchies Nodes in predefined taxonomies are first encoded using sequences of numbers and the symbol  according to their positions in the hierarchy tree For example the internal node Milk in Fig 1 is represented by 1  the internal node Chocolate by 11 and the terminal node Dairyland by I l 1 A top-down progressively deepening search approach is used and exploration of level-crossing association relationships is allowed Candidate itemsets at certain levels may thus contain items at lower levels For example candidate 2-itemsets at level 2 are not limited to containing only pairs of large items at level 2 Instead large items at level 2 may be paired with large items at level 1 to form candidate 2-itemsets at level 2 such as 1 2 B Mining Association Rules with Multiple Minimum Supports A variety of mining approaches based on the Apriori algorithm were proposed each for a specific problem domain a specific data type or for improving its efficiency In these approaches the minimum supports for all the items or itemsets to be large are set at a single value But in real applications different items may have different criteria to judge its importance Liu et al 6 proposed an approach for mining association rules with non-uniform minimum support values Their approach allowed users to specify different minimum supports to different items The minimum support value of an itemset is defined as the lowest minimum supports among the items in the itemset This assignment is however not always suitable for application requirements For example assume the minimum supports of items A and B are set at 20 and 40 0 respectively As mentioned above the minimum support of an item means that the occurrence frequency of the item must be larger than or equal to it for being considered in the next mining steps If the support of an item is not larger than or equal to the support threshold this item is not worth considering When the minimum support value of an itemset is defined as the lowest minimum supports of the items in it the itemset may be large but items included in it may be small In this case it is doubtable whether this itemset is worth considering For the example described above if the support of item B is 30 smaller than its minimum support 40%0 then the 2-itemset A B should not be worth considering It is thus reasonable in some sense that the occurrence frequency of an interesting itemset must be larger than the maximum of the minimum supports of the items contained in it Wang et al 9 then generalized the above idea and allowed the minimum support value of an itemset to be any function of the minimum support values of items contained in the itemset They proposed a bin-oriented non-uniform support constraint Items were grouped into disjoint sets called bins and items within the same bin were regarded as non-distinguishable with respect to the specification of a minimum support Although their approach is flexible in assigning the minimum supports to itemsets the mining algorithm is a little complex due to its generality Although Wang et al.'s approach can solve this kind of problems the time complexity is high Besides their approach does not consider items with quantitative values and organized into multiple levels In our previous work 4][5 a simple algorithm based on the Apriori approach was proposed to find the large-itemsets and association rules under the maximum constraint of multiple minimum supports The proposed algorithm is easy and efficient when compared to Wang et al.'s under the maximum constraint Below we will propose an efficient algorithm based on fuzzy sets and Han's mining approach for multiple-level items to generate the fuzzy large itemsets level by level III THE PROPOSED ALGORITHM The proposed mining algorithm integrates fuzzy set concepts data mining and multiple-level taxonomy to find fuzzy association rules in a given transaction data set The knowledge derived is represented by fuzzy linguistic terms and thus easily understandable by human beings In the proposed algorithm items may have different minimum supports and taxonomic relationships and the maximumitemset minimum-taxonomy support constraint is adopted to discover the large itemsets Each primitive item is given a predefined support threshold minimum support The minimum support for an itemset is set as the maximum of the minimum supports of the items contained in the itemset while the minimum support for an item at a higher taxonomic concept is set as the minimum of the minimum supports of the items belonging to it Under the constraint the characteristic of downward-closure is kept such that the original Apriori algorithm can be easily extended to find the fuzzy large itemsets 4113 


The proposed fuzzy mining algorithm first encodes items nodes in a given taxonomy as Han and Fu's approach did 2 It then filters out unpromising itemsets in two phases In the first phase an item group is removed if its occurring count is less than the support threshold In the second phase the count of a fuzzy region is checked to determine whether it is large In this phase a set of membership functions are used to transform the quantitative transactions into fuzzy values The proposed algorithm then finds all the large itemsets for the given transactions by comparing the fuzzy count of each candidate itemset with its support threshold Furthermore some pruning strategies are used to reduce the number of candidate itemsets generated The framework for mining fuzzy multi-level association rules is shown in Fig 2 The details of the proposed fuzzy mining algorithm under the maximum constraint are described below Fig ji RJ J2 Rjh using the given membership functions where I  1 to n h is the number of fuzzy regions for jk Rk is the 1-th fuzzy region of I 1  I  h and fv is V s fuzzy membership value in region Rj STEP 7:Collect the fuzzy regions linguistic terms with membership values larger than zero to form the candidate set Clk Calculate the scalar cardinality count k of each fuzzy region R k in the transaction data as n count j  fi I i=l STEP 8:Check whether the value coun  of each region R.k in C1k is larger than or equals to the threshold rj which is the minimum of minimum supports of the primitive items descending from it If R satisfies k the threshold put it into the large 1-itemset Li  for level k That is Lk  Rk CoUntk 2k 5 Rk ERk Cl I j I j IJ STEP 9:If k reaches the level number of the taxonomy go to STEP 16 to find association rules otherwise if LIk is 4114 2 The framework for mining fuzzy multi-level association rules The mining algorithm for fuzzy multiple-level association rules under the maximum-itemset minimum-taxonomy support constraint of multiple minimum supports INPUT A body of n quantitative transaction data D a predefined taxonomy with the primitive items assigned their own minimum supports a set of membership functions and a minimum confidence value A OUTPUT A set of fuzzy multiple-level association rules under maximum constraints of multiple minimum supports STEP 1 Encode the predefined taxonomy using a sequence of numbers and the symbol  with the 1-th number representing the branch number of a certain item at level 1 STEP 2:Translate the item names in the transaction data according to the encoding scheme STEP 3 Set k  1 where k is used to store the level number being processed STEP 4:Group the items with the same first k digits in each transaction Di and add the amounts of the items in the same groups in Di Denote the amount of thej-th group IJkfor Di as v  STEP 5 Calculate the count occurring number of each group in all the transactions Check for each group ijk whether its count is larger than or equals to the support threshold Tk that is the minimum of minimum supports of the primitive items descending from it Remove the group with their counts less than their respective support thresholds STEP 6:For each remaining group 1jk transform the Vk quantitative value V of Ijk in each transaction datum Di into a fuzzy set f1 represented as k  I  


null set k  k  1 and go to STEP 4 otherwise do the next step STEP 10 Generate the candidate set C2k from L1  L12  L k to find level-crossing large itemsets The generated candidate set C2k has to satisfy following conditions 1 2-itemset in C2f must contain at least one item in LIk 2 two regions in a 2-itemset may not have the same item name 3 The two item names in a 2-itemset may not be with the hierarchy relation in the taxonomy 4 Both of the support values of the two large I itemsets comprising a candidate 2-itemset must be larger than or equal to the maximum of the minimum supports of the two large 1 itemsets STEP 11 Do the following substeps for each newly formed candidate 2-itemset s with regions SI S2 in C2k a Calculate the fuzzy value of s in each transaction Di as fs  fs A s  where fj5 is the membership value of region sj in Di Assume the minimum operator is used for intersection then fis  min\(fis J  b Calculate the scalar cardinality of s in all the transaction data as n counts  fisf c If countS is larger than or equals to the maximum of the minimum supports of the items contained in it put s into L2 STEP 12 Set r 2 where r is used to represent the number of regions stored in the current large itemsets STEP 13 If Lrk is null then set k  k  1 and go to STEP 4 otherwise do the next step STEP 14 Generate the candidate set C'1 from Lrk in a way similar to that in the Apriori algorithm 1 That is the algorithm first joins Lk and Lk assuming that r1 regions in the two itemsets are the same and the other one is different There is a difference from the Apriori algorithm in that the supports of all the large r-itemsets comprising a candidate rl-l I must be larger than or equal to the maximum of the support thresholds of these large r-itemsets Store in Ck all the itemsets with all their sub-r-itemsets in 14 and satisfying the above conditions STEP 15 Do the following substeps for each newly formed r+1 s with regions\(s1 S2  Sr+i in Ck a Calculate the fuzzy values of s in each transaction Di as fis  f5sl A f;sf A A f5  where f is the membership value of region sj in Di Assume the minimum operator is used for intersection then r+1 fs min fs j=1 J b the scalar cardinality of s in all the transaction data as n counts  E tis i=l c If count is larger than or equals to the maximum of the minimum supports of the regions contained in it put s into L4 STEP 16 Set r  r  1 and go to STEP 13 STEP 17 Construct the fuzzy association rules for all large q-itemset s containing regions sI S2  Sq q  2 by the following substeps a Form all possible association rules as follows SI A...ASr-i ASr+i A...ASq Sr r I toq b Calculate the confidence values of all association rules by n fs Z\(Jisi A--A f Jsrl s  A Jisq STEP 18 Output the rules with confidence values larger than or equal to the predefined confidence value A Note that since the hierarchical relationship of the items in a candidate 2-itemset has been checked in STEP 10 the candidate 3-itemsets will not need to be checked for it according to a lemma in 7 All the large itemsets will thus exclude the hierarchical relationship of items IV AN EXAMPLE In this section a simple example is given to demonstrate the proposed fuzzy mining algorithm which generates a set of fuzzy taxonomic association rules from a given quantitative transaction dataset under the maximum-itemset minimumtaxonomy support constraint of multiple minimum supports Assume the quantitative transaction dataset includes the ten transactions as shown in Table 1 Each transaction includes a transaction ID and some purchased items Each item is represented by a tuple item name item amount Assume the predefined taxonomy is shown in Fig 1 Also assume that the predefined minimum support values of items minsup are given in Table 2 and the minimum confidence value is set at 0.8 Assume that the fuzzy membership functions are the same for all the items and are shown in Fig 3 Note that the proposed algorithm can also process items with different membership functions In this example amounts are represented by three fuzzy regions Low Middle and High Thus three fuzzy membership values are produced for each item amount according to the predefined membership functions Each item name is first encoded using the predefined taxonomy The results are shown in Table 3 All the items in the transactions are first grouped at level one and their corresponding amounts are added The count of each group is then checked with its own support threshold that is the minimum of minimum supports of the primitive items 4115 


milk milk milk minsup 2.5 2.0 2.3 77 chocolate Present descending from it TABLE 1 1.7 Membership green 77 lemon Item chocolate lemon co e cookes cookies cookies cookies minsup 1.5 1.7 tea beverage tea beverage tea beverage tea beverage minsup 1.2 2.1 1.5 1.4 1.5 1.4 1.5 Present 1.8 Item Old Mills Wonder Old Mills Wonder em white bread white bread wheat bread wheat bread minsup 1.6 1.9 Item Linton black Nestle black Linton green THE TEN TRANSACTIONS USED fN THE EXAMPLE ID Items TI Wonder wheat bread 2 Linton black tea beverage 4 Old Mills white bread 9 Linton black tea beverage I Old Mills wheat bread 3 T2 Nestle green tea beverage 5 Old Mills white bread 5 Nestle black tea beverage 2 T3 Wonder wheat bread 2 Wonder white bread 4 77 lemon cookies 5 Nestle black tea beverage 3 Present chocolate cookies 3 Old Mills white bread 4 T4 Wonder white bread 2 Diaryland chocolate milk 3 Linton black tea beverage 7 Nestle black value 0 0 items Fig 3 The membership functions used in the example For example the item 1  includes the items 11 1 1 12 121 and 122 its minimum support is then calculated as min\(2.5 2.4 2.3 2.1  2.1 according to the minimum supports given in Table 2 The group 1  is then removed since its count is only 2 less than 2.1 In this example 2 3 and 4 are larger than their support thresholds TABLE 3 ENCODED TRANSACTION DATA IN THE EXAMPLE ID Items Ti 222,2 411,4 211,9 T2 411,1 412,2 422,5 211,5 221,3 T3 222,2 212,4 322,5 412,3 T4 311,3 111,3 212,2 211,4 411,7 412 1 T5 412,6 322,3 T6 322,1 212,2 422,3 311,9 T7 221,6 311,5 T8 111,7 122,3 T9 222,4 321,3 421,2 TI1 421,8 321,7 211,2 212,8 221,3 The quantitative values of the items at level 1 are represented as fuzzy sets by the given membership functions Take the first item in transaction T5 as an example The amount of 4  6 is mapped to the membership function Low in Fig 3 with value 0 to Middle with value 0.8 and to High with value 0.2 The fuzzy set transformed is then represented as 0.0 0.8 0.2 4**.Low 4**.Middle 4**.High where the notation item term is called a fuzzy region The fuzzy regions with membership values larger than zero are collected as the candidate set C The scalar cardinality of each region in Cll is then calculated as its count value Take the fuzzy region 2**.Middle as an example Its cardinality  0.4  0.8  0.8  0.8  0.67 3.47 This step is repeated for the other regions The count of each region is checked against the minimum of minimum supports of items included in it According to the predefined minimum supports of items shown in Table 2 the minimum supports of 2 3 and 4 are 1.4 1.6 and 2.1 respectively Since the count values of 2**.Middle 2**.High 3**.Low 3**.Middle 4**.Low and 4**.Middle satisfy their respective minimum supports they are put into LI1 Since LI is not null the candidate 2-itemset C21 is generated from LI1 Note that 2**.Middle 2**.High 3**.Low 3**.Middle and 4**.Low 4**.Middle are not formed since they have the same item names In addition the 2-itemset 3**.Low 4**.Low is not a candidate since the count value of 3**.Low 2.0 is not larger than the minimum support of 4 2.1 Some pruning can thus be done in this way The fuzzy membership values of the candidate 2-itemsets are calculated for each transaction data Here the minimum operator is used for intersection Take 2**.Middle 3**.Middle as an example The derived membership value of 4116 Foremore Item chocolate chocolate plain milk plain Nestle tea beverage 1 T5 Nestle black tea beverage 6 77 lemon cookies 3 T6 77 lemon cookies 1 Wonder white bread 2 Nestle green tea beverage 3 Present chocolate cookies 9 T7 Old Mills wheat bread 6 Present chocolate cookies 5 T8 Diaryland chocolate milk 7 Foremost plain milk 3 T9 Wonder wheat bread 4 Present lemon cookies 3 Linton green tea beverage 2 Linton green tea beverage 8 Present lemon cookies 7 T10 Old Mills white bread 2 Wonder white bread 8 Old Mills wheat bread 3 TABLE 2 THE PREDEFINED MINIMUM SUPPORT VALUES FOR ITEMS Diaryland Foremore Diaryland 


2**.Middle 3**.Middle for transaction T2 is calculated as min\(0.8 1 0.8 The scalar cardinality count of each candidate 2-itemset in C2 is calculated Since only the count value of 2**.Middle 3**.Middle is larger than its support threshold the maximum of the minimum supports of items it is then put into the set of large 2-itemsets L2 That is L21  2**.Middle 3**.Middle Since there is only one 2-itemset in L2 the candidate 3-itemsets generated at level 1 is null The mining process is iteratively executed until the level number of the predefined taxonomy is met In the process of generating candidate itemsets the ones in the following five cases may be pruned Case 1 An itemset is pruned if any of its subset is not large For example the 3-itemset 21 Middle 22*.Low 32*.Middle is pruned since its subset 21 Middle 32*.Middle is not a large 2-itemset Case 2 An itemset is pruned if the fuzzy regions contained in it have the same item name For example 22*.Middle and 22*.Low can not be formed as a 2-itemset 22*.Middle 22*.Low since both of regions have the same item name 22 Case 3 An itemset is pruned if its regions possess the hierarchical relation in the given item taxonomy For example 2**.Middle and 22*.Low can not be formed as a 2-itemset 2**.Middle 22*.Low since 2 is the antecedent of 221 Case 4 An itemset is pruned if the support value of any fuzzy region in the itemset is smaller than the maximum of minimum supports of the items For example the fuzzy counts of the two fuzzy regions 32*.Middle and 42*.Middle are 2.27 and 1.73 which are respectively larger than their own minimum supports 32*.Middle and 42*.Middle are thus large 1-itemsets The 2-itemset 32*.Middle 42*.Middle however is not likely to be a large itemset since the count value 1.73 of the region 42*.Middle is smaller than the maximum 2.5 of minimum supports of these two items The 2-itemset 32*.Middle 42*.Middle is thus pruned Case 5 An itemset is pruned if its count value is smaller than the maximum of minimum supports of the items included in it For example the count 1.47 of the candidate 2-itemset 21*.High 22*.Low at level 2 is smaller than the maximum 1.5 of the minimum supports of 21  and 22 The itemset 21 High 22*.Low  is then discarded The proposed algorithm can thus find the large itemsets level by level without backtracking minimum support for an itemset is set as the maximum of the minimum supports of the items contained in the itemset The rational for using the two kinds of support constraints has also been well explained and this constraint may be suitable to some mining domains The proposed fuzzy mining algorithm can thus generate large itemsets level by level and then derive fuzzy association rules from quantitative transaction data An example is also given to demonstrate that the proposed mining algorithm can derive the multiple-level association rules under multiple item supports in a simple and effective way Currently we are working on the experiments for evaluating the efficiency of the proposed algorithm REFERENCES 1 R Agrawal T Imielinksi and A Swami Mining association rules between sets of items in large database The 1993 ACM SIGMOD Conference on Management of Data Washington DC USA 1993 pp 207-216 2 J Han and Y Fu Discovery of multiple-level association rules from large databases The International Conference on Very Large Databases 1995 pp 420 431 3 T P Hong C S Kuo and S C Chi A data mining algorithm for transaction data with quantitative values Intelligent Data Analysis Vol 3 No 5 1999 pp 363-376 4 Y C Lee T P Hong and W Y Lin Mining fuzzy association rules with multiple minimum supports using maximum constraints The Eighth International Conference on Knowledge-Based Intelligent Information and Engineering Systems 2004 Lecture Notes in Computer Science Vol 3214 pp 1283-1290 2004 5 Y C Lee T P Hong and W Y Lin Mining association rules with multiple minimum supports using maximum constraints International Journal of Approximate Reasoning Vol 40 No 1 pp 44-54 2005 6 B Liu W Hsu and Y Ma Mining association rules with multiple minimum supports in Proceedings of the 1999 International Conference on Knowledge Discovery and Data Mining pp 337-341 1999 7 R Srikant and R Agrawal Mining generalized association rules in Proceeding of the 21st International Conference on Very Large Data Bases pp 407-419 1995 8 R Srikant and R Agrawal Mining quantitative association rules in large relational tables The 1996 ACM SIGMOD International Conference on Management of Data Monreal Canada June 1996 pp 1-12 9 K Wang Y H and J Han Mining frequent itemsets using support constraints in Proceedings of the 26th International Conference on Very Large Data Bases pp 43-52 2000 V CONCLUSION In this paper we have integrated fuzzy set concepts data mining multiple-level taxonomy and multiple minimum supports to find fuzzy association rules in a given quantitative transaction data set Using different criteria to judge the importance of different items managing taxonomic relationships among items and dealing quantitative data sets are three issues that usually occur in real mining applications In the proposed algorithm the minimum support for an item at a higher taxonomic concept is set as the minimum of the minimum supports of the items belonging to it and the 4117 


 ASSOAGS the set of association extracted from AGS   ML md1 the ML of md1   EFF_ASSO effective associations which are those allowed to invoke md1   EFF_VAR_ASSO common effective associations       of the variables in the computation  ASSO_SRCVAR i the set of associations extracted from the labels of the i th variable in src   ASSO_DES the set of associations extracted from the labels of des   asso an association  VARS a set of variable  LBLS a set of labels algorithm if AGS is empty then the information flow is not secure, exit algorithm end if  EFF_ASSO  ASSOAGS  002 i  ASSO_SRCVAR i  002  ASSO_DES  if EFF_VAR_ASSO is empty then no common association exists among variables in the computation the information flow is not secure, exit algorithm end if  VARS  des  005  src  for each association asso in EFF_VAR_ASSO do  LBLS  lbl  lbl is the label of an element in VARS whose association is asso  if applying LBLS to the computation causes the secure condition true then the information flow is secure, exit algorithm end if end for     the information flow in not secure, exit algorithm  The algorithm first checks whether \223obj1\224 and 223obj2\224 coexist in an AG. If the check fails, the statement cannot be executed. If they coexist in one or more AGs, the algorithm checks whether the method \223md1\224 can be invoked under the associations of the AGs the objects coexist \(by comparing the associations in the AGs with the ML of \223md1\224\ no association in the AGs is allowed to invoke the method, the statement cannot be executed. If one or more associations are allowed to invoke the method the algorithm identifies the common associations of the variables involved in the statement. If no common association is identified, labels of the statement are incomparable and the statement cannot be executed. If one or more common associations among the variables are identified, labels with any common association can be selected to check information flow security. If a common association causes the secure flow condition true, the information flow is considered secure. This consideration is reasonable. For example, if a worker is assigned to a manager and they are friends, the manager can play the role of either a manager or a friend to invoke the worker\222s methods  6. Case study  The example described in section 2 is revisited here We use the proposed model to label the application The labeling result is shown in Example 1. We simplify the example by hiding the possibly complicated structure of an attribute. For example the attributes \223general_info\224 of the object \223worker\224 may be as complicated as a C structure. Let\222s trace Example 1 to prove that the information flow control requirements described in section 2 are fulfilled Requirement 1 When a manager monitors a worker assigned to him, the manager can read the worker\222s general information, hour pay, and work hours This requirement is accomplished by the manager\222s method \223monitor\224 and the labels with the association \223assigned\224. To get the information of a worker, the manager\222s method \223monitor\224 invokes the worker\222s method \223get_info\224 using the manager\222s attributes \223worker_general_info\224 223worker_work_hour\224, and \223worker_hour_pay\224 as arguments. Comparing the label of 223worker_general_info\224 with that of the worker\222s attribute \223self_general_info\224, the secure flow condition mentioned in section 4.4 is true \(note that the labels with the association \223assigned\224 are used here\herefore, the statement \223g_info self_general_info;\224 within the worker\222s method 223get_info\224 can be executed. Moreover, the statements \223w_hour := work_hour;\224 and \223h_pay hour_pay;\224 within \223get_info\224 can be executed after a similar comparison Requirement 2 If a manager browses the information of a worker assigned to him, the manager can only read the worker\222s general information This requirement is accomplished by the method 223browse\224 of the object \223manager\224 and the labels with the association \223assigned\224. To get the general information of a worker assigned to a manage, the method \223browse\224 invokes the worker\222s method 223get_self_general_info\224 using the manager\222s attribute \223others_general_info\224 as an argument Proceedings of t he 36th Ha waii International Conf erence on S y st e m Sciences \(HICSS\22203 0 76 95 18 745/0 3 1 7.00 251 20 02  I E EE 002 ML md1  if EFF_ASSO is empty then md1 is not allowed to invoke under the associations the information flow is not secure, exit algorithm end if  EFF_VAR_ASSO  EFF_ASSO  002   


The statement \223g_info := self_general_info;\224 within the worker\222s method 223get_self_general_info\224 can be executed after comparing labels. Note that the manager\222s method 223browse\224 cannot read the worker\222s \223work_hour\224 and \223hour_pay\224. The rationale is described in the last paragraph of section 4.4 Requirement 3 If a worker is not assigned to a manager, the manager can only read the worker\222s general information This requirement is accomplished by the method 223browse\224 of the object \223manager\224 and the labels with the association \223not_assigned\224. To get the general information of a worker not assigned to a manager, the method \223browse\224 invokes the worker\222s method \223get_self_general_info\224 using the manager\222s attribute \223others_general_info\224 as an argument. The statement \223g_info self_general_info;\224 within the worker\222s method 223get_self_general_info\224 can be executed after comparing labels Requirement 4 If a worker and a manager are friends, they can read each other\222s general information This requirement is achieved by the labels with the association \223friend\224. For example, a worker can read his manager friend\222s general information through the worker\222s method 223get_others_general_info\224, which invokes the manager\222s \223get_self_general_info\224 using the worker\222s attribute \223others_general_info\224 as an argument. After comparing the label of the worker\222s attribute \223others_general_info\224 and the manager\222s attribute \223self_general_info\224, one can see that the secure flow condition is true. The statement \223g_info := self_general_info;\224 within the manager\222s method \223get_self_general_info;\224 can be executed Requirement 5 Periodically, the company invokes foreign objects to compute the salaries and taxes of workers This requirement is fulfilled by the stubs \223stub1\224 and stub2\224 in Example 1. Please refer to the description in section 4.3. Moreover, the three rules mentioned in section 3.2 prevent the foreign objects from becoming Trojan horses  7. Evaluation  We implemented a prototype system to evaluate the model. The system uses reusable software repository to simulate foreign object control. Moreover, it uses the language shown in Example 1 to write programs A program written in the language is first pre-processed to produce a program without labels and MLs. The program produced by the preprocessor is conceptually composed of two parts. One is the program before labeling and the other a security monitor The latter checks information flows of the former using Algorithm 1 during program execution Currently, the security monitor checks security dynamically, which contradicts the proposal of static checking [1, 12, 24  N e ve r t he l e ss d yna mi c c he c ki n g  cannot be totally avoided because objects and AGs may be dynamically instantiated or removed during program execution To evaluate the model, we used the example described in section 2 as an assignment to students of different grades and experiences. The students are required to develop a program, namely program a  without the proposed model embedded and another program, namely program b with the model embedded. We then collected and averaged the following metrics data: 1\ LOC \(lines of code\f programs a and b, 2\ecution time of programs a and b, and 3\numbers of non-secure statements found in program b. The collected data showed that the averaged LOC and execution time of program b are respectively 3.2 and 3.8 times those of program a Nevertheless, the data also showed that 2.3 non-secure information flows \(per 100 LOC\n average are identified from program b. Although the runtime overhead seems high, we still think that the model is valuable because of the ability to identify non-secure statements. Nevertheless, reducing the overhead should be an important future work  8. Related work  The simplest information flow control approach is DAC. Since DAC fails to avoid Trojan horses, the multilevel security approach was proposed [6-9  The approach is generally categorized as MAC MAC was criticized as too restricted [5 T o lo o s en  the restriction, quite a few approaches have been proposed. Below we survey some researches The model proposed in t rol s t h e  information flows in object-oriented systems. It uses ACL of objects to compute the ACL of executions. A message filter is used to filter out possibly non-secure information flows. Since the computation of an execution\222s ACL takes information propagation into consideration, no Trojan horses will result Moreover, interactions among executions are categorized into five modes including synchronized unrestricted, synchronous restricted, asynchronous deferred reply unrestricted, and deferred reply restricted. Different modes result in different ACLs Proceedings of t he 36th Ha waii International Conf erence on S y st e m Sciences \(HICSS\22203 0 76 95 18 745/0 3 1 7.00 251 20 02  I E EE 


which loosens the restriction of MAC. More flexibility is added to the model by allowing exceptions during or after method execution [10-11 The purpose-oriented model [21-22 pro pos es  that invoking a method may be allowed for some methods but disallowed for other methods, even when the invokers belong to the same object. This consideration is correct, because the security levels of methods in an object may be different Different methods can thus access information in different security levels The decentralized label approach [1-4 m a rk s t h e  security levels of variables using labels. A label is composed of one or more policies, which should be simultaneously obeyed. A policy in a label is composed of an owner and zero or more readers that are allowed to access the data. When computation are applied to data, join operation is used to compute the label of the result data. This avoids Trojan horses Another feature proposed by this approach is that declassification \(downgrading of security level provided. This allows non-sensitive data, which are in high security level, to be accessed by low security level processes. The model also takes write access control into consideration [4 rren t l y t h e m o d e l  has been used to develop a programming language Jflow [1 ad d itio n   th e m o d e l h a s b e e n  u s ed i n a  distributed system with untrusted hosts through secure program partitioning [30  Role-based access control models [19, 27, 33  define the roles a subject can play. A role is a collection of permissions \(i.e., access rights  When a subject plays a role, it possesses the rights belonging to the role. A subject can play multiple roles and even change role during a session Inheritance and other relationships can be established among roles [27 t o s t ru ct u re t h e m Moreov er  constraints, such as two specific roles should be mutually exclusive, can be attached to roles. The advantage of role-based access control is that subjects can change roles dynamically, which facilitates obeying the \223need-to-know\224 principle. It seems that the role-based models operate well in an application that protects not too many resources because roles should be defined before the application\222s execution. In case that many resources should be protected \(such as every variable in a program should be protected\ining roles becomes tedious and the access control may become imprecise From the survey, we identified many necessary features for controlling information flows in object-oriented systems such as Trojan horse prevention, declassification, purpose-oriented method invocation, and so on. In fact, our model offers those features, although we do not present them in this paper. What we present in this paper are the control of information flows among objects and foreign objects. According to our survey, no model offers the control well  9. Conclusions  This paper proposes a model to control information flows among objects. The model uses associations and method limitations \(ML\ to control information flows among objects. Information flows are controlled by attaching labels to variables. Trojan horses are avoided by join operations. Within an application, every variable and literal is associated with one or more labels. If a variable is associated with multiple labels, each label enforces the security policy of an association. To check the security of an information flow, labels are compared. An information flow is secure if the comparison causes the secure flow condition true In addition to controlling objects developed by programmers, the model also controls foreign objects which are pre-existing objects for reused. Since the details of a foreign object are unknown, our model only prevents foreign objects from becoming Trojan horses. We use the \223Suppression rule\224, \223No ML rule\224 and \223Stuck to rules\224 to control foreign objects We implemented a prototype system to evaluate the model. From the data collected, we found that the model does facilitate identifying non-secure information flows. We thus believe that the model is useful in spite of runtime overhead  Acknowledgement  This research is sponsored by the National Science Council in Taiwan under Grant NSC91-2213-E-259-006  References  1  A  C. My e r s 223 J Flow  P r a c tic a l Mostly S ta tic  Information Flow Control\224 Proc. 26\222th ACM Symp Principles of Programming Language pp. 228-241 1999  A  C M y ers an d B L i sko v  223A De cen t r al i zed M o d e l f o r Information Flow Control\224 Proc. 17\222th ACM Symp Operating Systems Principles pp. 129-142, 1997 3 A  My e r s a nd B  L i s k ov 223 C om ple t e  Sa f e I n f o r m a tion  Flow with Decentralized Labels\224 Proc. 14\222th IEEE Symp Security and Privacy pp. 186-197, 1998 4 A My e r s a nd B. L i sk ov 223 P rote c ting  P r iv a c y using the  Proceedings of t he 36th Ha waii International Conf erence on S y st e m Sciences \(HICSS\22203 0 76 95 18 745/0 3 1 7.00 251 20 02  I E EE 


Decentralized Label Model\224 ACM Trans. Software Eng Methodology vol. 9, no. 4, pp. 410-442, 2000  C J M c Co ll u m  J R M e ssin g  an d L  No tar g iaco m o   223Beyond the Pale of MAC and DAC - Defining New Forms of Access Control\224 Proc. 6\222th IEEE Symp Security and Privacy pp. 190-200, 1990  D E  Bel l a n d L  J L a P a d u l a 223S ecu re Co m p u t er  Systems: Unified Exposition and Multics Interpretation\224 technique report, Mitre Corp Mar. 1976 http://csrc.nist.gov/publications/history/bell76.pdf 7 D  E  D e nn ing  223 A L a ttic e Mode l of Se c u r e I n f o r m a tion Flow\224 Comm. ACM vol. 19, no. 5, pp. 236-243, 1976 8 D  E  D e n n ing a n d P  J  D e nning 223 C e r tif ic a tion of  Program for Secure Information Flow\224 Comm. ACM vol 20, no. 7, pp. 504-513, 1977  D  F  C  Brew er  an d M  J  Nash  223T h e Ch i n ese W a l l  Security Policy\224 Proc. 5\222th IEEE Symp. Security and Privacy pp. 206-214, 1989 10 E Ferrari P   Sam a r a ti, E. Bertin o  an d S. Jajo d i a  223Providing Flexibility in Information Control for Object-Oriented Systems\224 Proc. 13\222th IEEE Symp Security and Privacy pp. 130-140, 1997 11 E B e r tin o Sa br i n a  de C a pita ni di V i m e r c a ti, E  Ferrari, and P. Samarati, \223Exception-based Information Flow Control in Object-Oriented Systems\224 ACM Trans Information System Security vol. 1, no. 1, pp. 26-65 1998 1  F  B S chu ei d er  223E n f o r ceab l e S ecu ri t y P o l i cy 224  ACM Trans. Information System Security vol. 3, no. 1, pp 30-50, 2000 1 G  B o o c h  Object-Oriented Analysis and Design with Application second edition, The Benjamin/Cummings Publishing Company, 1994 1 G  S m i t h an d D  V o l p an o 223S ecu re In f o r m at i o n F l o w  in a Multi-Thread Imperative Language\224 Proc. 25th ACM Symp. on Principles of Programming Languages  pp. 355-364, 1998 15 H M De ite l a n d a n d P  J D e ite l C: How to Program  Prentice-Hall, 2001 16 O M G  223 T he C o m m on O bje c t R e que s t B r ok e r   Architecture and Specification\224 http://doc.ece.uci.edu/CORBA 17 J  A g a t 223 T r a nsf o r m ing out  T i m i ng Le ak s 224  Proc. 27th ACM Symp. on Principles of Programming Languages  pp. 40-53, 2000 1 J Ru m b au gh  M  Bl ah a  W  P r em erl a n i  F  E d d y  an d  W Lo r en s en   Object-Oriented Modeling and Design  Prentice-Hall, 1991 19 K  I z a k i, K  T a na k a a nd M  T a k i z a w a 223 I nf or m a tion Flow Control in Role-Based Model for Distributed Objects\224 Proc. 8\222th International Conf. Parallel and Distributed Systems pp. 363-370, 2001 20 M. D. Mc Ilr o y a nd J A  R e e d s, \223 M ultile v e l Se c u rity  in the UNIX Tradition\224 Software - Practice and Experience vol. 22, no. 8, pp. 673-694, 1992 2  M  Y asu d a T  T ach i k a w a an d M  T aki za w a  223Information Flow in a Purpose-Oriented Access Control Model\224 Proc. 1997 International Conf. Parallel and Distributed Systems pp. 244-249, 1997 22 M. Y a s uda   T   T a c h ik aw a, a nd M  T a k i z a w a  223A  Purpose-Oriented Access Control Model\224 Proc. 12\222th International Conf. Information Networking pp. 168-173 1998 23  P  Sa m a ra ti, E. Be rtino   A  Cia m pic h e tti, a n d S  Jajodia, \223Information Flow Control in Object-Oriented Systems\224 IEEE Trans. Knowledge Data Eng vol. 9, no 4, pp.524-538, Jul./Aug. 1997 24 R  F o c a r di a n d R  G o r r i e r i, \223 T he C o m pos itiona l  Security Checker: A Tool for the Verification of Information Flow Security Properties\224 IEEE Trans Software Eng vol. 23, no. 9, pp. 550-571, 1997 2 G r au b a rt  223On t h e Need f o r a T h i r d  F o rm o f A cce ss  Control\224 Proc. 12\222th Nat\222l Computer Security Conf pp 296-303, 1989 26 R  S  Sa nd hu 223 L a ttic e B a sed A c c e s s C ontr o l M ode ls 224   IEEE Computer vol. 26, no. 11, pp. 9-19, Nov. 1993 27 R  S  S a n d h u  E  J  C o y n e  H  L  F e i n s t e i n  a n d C  E   Youman, \223Role-Based Access Control Models\224 IEEE Computer vol. 29, no. 2, pp. 38-47, 1996 2  S  Jaj o d i a and B  Ko gan  223In t egrat i n g an  Object-Oriented Data Model with Multilevel Security\224 Proc. 6\222th IEEE Symp. Security and Privacy pp. 76-85 1990 29  S. N Fo ley  223A Mo d e l f o r S e cu re In f o rmatio n Fl o w 224  Proc. 5\222th IEEE Symp. Security and Privacy pp. 248-258 1989 30  S. Z d a n c e w ic L Zhe n g N N y s t ro m a nd A C. My e r s   223Untrusted Hosts and Confidentiality: Secure Program Partitioning\224 Proc. 18th ACM Symp. Operating Systems Principles 2001 3 T   T ach i k a w a M  Y asu d a an d M   T aki za w a  223 A  Purposed-Oriented Access Control Model in Object-Based Systems\224 Trans. Information Processing Society of Japan vol. 38, no. 11, pp. 2362-2369, 1997 32 V  V a ra d h a r a j a n a nd S Bla c k 223 A Multile v e l Se c u rity  Model for a Distributed Object-Oriented System\224 Proc 6\222th IEEE Symp. Security and Privacy pp. 68-78, 1990 3 Z   T a ri an d S  W  Ch an 223A Ro l e Bas ed Acces s  Control for Intranet Security\224 IEEE Internet Computing  vol. 1, no. 5, pp. 24-34, 1997 Proceedings of t he 36th Ha waii International Conf erence on S y st e m Sciences \(HICSS\22203 0 76 95 18 745/0 3 1 7.00 251 20 02  I E EE 


absolute values. The results can vary on other computers. But it can be guaranteed that performance ratio of the algorithms will remain the same After making the comparisons with sample data, we came to the conclusion that PD algorithm performs significantly better than the other two especially with larger datasets. PD outperforms DCP and PIP regarding running time. On the other hand, since PD reduces the dataset, mining time does not necessary increase as the number of transactions increases and experiments reveals that PD has better scalability than DCP and PIP. So, PD has the ability to handle the large data mine in practical field like market basket analysis and medical report documents mining 5. References 1] R. Agrawal and R. Srikant, "Fast algoritlnns for mining association rules", VLDB'94, pp. 487-499 2] R. J. Bayardo, "Efficiently mining long patterns from databases", SIGMOD'98, pp.85-93 3] J. Pei, J. Han, and R. Mao, "CLOSET: An Efficient Algorithm for Mining Frequent Closed Itemsets \(PDF Proc. 2000 ACM-SIGMOD International Workshop on Data Mining and Knowledge Discovery, Dallas, TX, May 2000 4] Qinghua Zou, Henry Chiu, Wesley Chu, David Johnson, "Using Pattern Decomposition\( PD Finding All Frequent Patterns in Large Datasets", Computer Science Department University of California - Los Angeles 5] J. Han, J. Pei, and Y. Yin, "Mining Frequent Patterns without Candidate Generation \(PDF  SIGMOD International Con! on Management of Data SIGMOD'OOj, Dallas, TX, May 2000 6] S. Orlando, P. Palmerini, and R. Perego, "The DCP algoritlnn for Frequent Set Counting", Technical Report CS2001-7, Dip. di Informatica, Universita di Venezia 2001.Available at http://www.dsi.unive.itl?orlando/TR017.pdf 7] MD. Mamun-Or-Rashid, MD.Rezaul Karim, "Predictive item pruning FP-tree algoritlnn", The Dhaka University  Journal of Science, VOL. 52, NO. 1, October,2003, pp. 3946 8] Park, J. S., Chen, M.-S., and Yu, P. S, "An Effective Hash Based Algoritlnn for Mining Association Rules", Proc ofthe 1995 ACM-SIGMOD Con! on Management of Data 175-186 9] Brin, S., Motwani, R., Ullman, J., and Tsur, S, "Dynamic Itemset Counting and Implication Rules for Market Basket Data", In Proc. of the 1997 ACM-SIGMOD Conf On Management of Data, 255-264 10] Zaki, M. J., Parthasarathy, S., Ogihara, M., and Li, W New Algoritlnns for Fast Discovery of Association Rules In Proc. of the Third Int'l Con! on Knowledge Discovery in Databases and Data Mining, 283-286 11] Lin, D.-I and Kedem, Z. M., "Pincer-Search: A New Algoritlnn for Discovering the Maximum Frequent Set", In Proc. of the Sixth European Conf on Extending DatabaseTechnology, 1998 12] R. Ramakrishnan, Database Management Systems University of Wisconsin, Madison, WI, USA; International Edition 1998 pre></body></html 


tors such as union, di?erence and intersection are de?ned for pairs of classes of the same pattern type Renaming. Similarly to the relational context, we consider a renaming operator ? that takes a class and a renaming function and changes the names of the pattern attributes according to the speci?ed function Projection. The projection operator allows one to reduce the structure and the measures of the input patterns by projecting out some components. The new expression is obtained by projecting the formula de?ning the expression over the remaining attributes [12 Note that no projection is de?ned over the data source since in this case the structure and the measures would have to be recomputed Let c be a class of pattern type pt. Let ls be a non empty list of attributes appearing in pt.Structure and lm a list of attributes appearing in pt.Measure. Then the projection operator is de?ned as follows ls,lm c id s m f p ? c, p = \(pid, s, d,m, f In the previous de?nition, id ing new pids for patterns, ?mlm\(m projection of the measure component and ?sls\(s ned as follows: \(i s usual relational projection; \(ii sls\(s and removing the rest from set elements. The last component ?ls?lm\(f computed in certain cases, when the theory over which the formula is constructed admits projection. This happens for example for the polynomial constraint theory 12 Selection. The selection operator allows one to select the patterns belonging to one class that satisfy a certain predicate, involving any possible pattern component, chosen among the ones presented in Section 5.1.1 Let c be a class of pattern type pt. Let pr be a predicate. Then, the selection operator is de?ned as follows pr\(c p Join. The join operation provides a way to combine patterns belonging to two di?erent classes according to a join predicate and a composition function speci?ed by the user Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE Let c1 and c2 be two classes over two pattern types pt1 and pt2. A join predicate F is any predicate de?ned over a component of patterns in c1 and a component of patterns in c2. A composition function c pattern types pt1 and pt2 is a 4-tuple of functions c cStructureSchema, cDataSchema, cMeasureSchema, cFormula one for each pattern component. For example, function cStructureSchema takes as input two structure values of the right type and returns a new structure value, for a possible new pattern type, generated by the join. Functions for the other pattern components are similarly de?ned. Given two patterns p1 = \(pid1, s1, d1,m1, f1 p2 = \(pid2, s2, d2,m2, f2 p1, p2 ned as the pattern p with the following components Structure : cStructureSchema\(s1, s2 Data : cDataSchema\(d1, d2 Measure : cMeasureSchema\(m1,m2 Formula : cformula\(f1, f2 The join of c1 and c2 with respect to the join predicate F and the composition function c, denoted by c 1   F  c  c 2   i s  n o w  d e  n e d  a s  f o l l o w s    F  c  c 2     c  p 1   p 2   p 1    c 1  p 2    c 2  F   p 1   p 2     t r u e   5.1.3. Cross-over database operators OCD Drill-Through. The drill-through operator allows one to 


Drill-Through. The drill-through operator allows one to navigate from the pattern layer to the raw data layer Thus it takes as input a pattern class and it returns a raw data set. More formally, let c be a class of pattern type pt and let d be an instance of the data schema ds of pt. Then, the drill-through operator is denoted by c c Data-covering. Given a pattern p and a dataset D sometimes it is important to determine whether the pattern represents it or not. In other words, we wish to determine the subset S of D represented by p \(p can also be selected by some query the formula as a query on the dataset. Let p be a pattern, possibly selected by using query language operators, and D a dataset with schema \(a1, ..., an ible with the source schema of p. The data-covering operator, denoted by ?d\(p,D responding to all tuples in D represented by p. More formally d\(p,D t.a1, ..., t.an In the previous expression, t.ai denotes a speci?c component of tuple t belonging to D and p.formula\(t.a1, ..., t.an instantiated by replacing each variable corresponding to a pattern data component with values of the considered tuple t Note that, since the drill-though operator uses the intermediate mapping and the data covering operator uses the formula, the covering ?\(p,D D = ?\(p not be equal to D. This is due to the approximating nature of the pattern formula 5.1.4. Cross-over pattern base operators OCP Pattern-covering. Sometimes it can be useful to have an operator that, given a class of patterns and a dataset, returns all patterns in the class representing that dataset \(a sort of inverse data-covering operation Let c be a pattern class and D a dataset with schema a1, ..., an pattern type. The pattern-covering operator, denoted as ?p\(c,D all patterns in c representing D. More formally p\(c,D t.a1, ..., t.an true Note that: ?p\(c,D p,D 6. Related Work Although signi?cant e?ort has been invested in extending database models to deal with patterns, no coherent approach has been proposed and convincingly implemented for a generic model There exist several standardization e?orts for modeling patterns, like the Predictive Model Markup Language \(PMML  eling approach, the ISO SQL/MM standard [2], which is SQL-based, and the Common Warehouse Model CWM  ing e?ort. Also, the Java Data Mining API \(JDMAPI 3] addresses the need for a language-based management of patterns. Although these approaches try to represent a wide range of data mining result, the theoretical background of these frameworks is not clear. Most importantly, though, they do not provide a generic model capable of handling arbitrary cases of pattern types; on the contrary only a given list of prede?ned pattern types is supported To our knowledge, research has not dealt with the issue of pattern management per se, but, at best, with peripheral proximate problems. For example, the paper by Ganti et. al. [9] deals with the measurement 


per by Ganti et. al. [9] deals with the measurement of similarity \(or deviation, in the authors  vocabulary between decision trees, frequent itemsets and clusters Although this is already a powerful approach, it is not generic enough for our purpose. The most relevant research e?ort in the literature, concerning pattern management is found in the ?eld of inductive databases Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE meant as databases that, in addition to data, also contain patterns [10], [7]. Our approach di?ers from the inductive database one mainly in two ways. Firstly, while only association rules and string patterns are usually considered there and no attempt is made towards a general pattern model, in our approach no prede?ned pattern types are considered and the main focus lies in devising a general and extensible model for patterns Secondly, di?erently from [10], we claim that the peculiarities of patterns in terms of structure and behavior together with the characteristic of the expected workload on them, call for a logical separation between the database and the pattern-base in order to ensure e?cient handling of both raw data and patterns through dedicated management systems Finally, we remark that even if some languages have been proposed for pattern generation and retrieval 14, 11], they mainly deal with speci?c types of patterns \(in general, association rules sider the more general problem of de?ning safe and su?ciently expressive language for querying heterogeneous patterns 7. Conclusions and Future Work In this paper we have dealt with the issue of modelling and managing patterns in a database-like setting Our approach is enabled through a Pattern-Base Management System, enabling the storage, querying and management of interesting abstractions of data which we call patterns. In this paper, we have \(a de?ned the logical foundations for the global setting of PBMS management through a model that covers data patterns and intermediate mappings and \(b language issues for PBMS management. To this end we presented a pattern speci?cation language for pattern management along with safety constraints for its usage and introduced queries and query operators and identi?ed interesting query classes Several research issues remain open. First, it is an interesting topic to incorporate the notion of type and class hierarchies in the model [15]. Second, we have intentionally avoided a deep discussion of statistical measures in this paper: it is more than a trivial task to de?ne a generic ontology of statistical measures for any kind of patterns out of the various methodologies that exist \(general probabilities Dempster-Schafer, Bayesian Networks, etc. [16 nally, pattern-base management is not a mature technology: as a recent survey shows [6], it is quite cumbersome to leverage their functionality through objectrelational technology and therefore, their design and engineering is an interesting topic of research References 1] Common Warehouse Metamodel \(CWM http://www.omg.org/cwm, 2001 2] ISO SQL/MM Part 6. http://www.sql99.org/SC32/WG4/Progression Documents/FCD/fcddatamining-2001-05.pdf, 2001 3] Java Data Mining API http://www.jcp.org/jsr/detail/73.prt, 2003 4] Predictive Model Markup Language \(PMML http://www.dmg.org 


http://www.dmg.org pmmlspecs v2/pmml v2 0.html, 2003 5] S. Abiteboul and C. Beeri. The power of languages for the manipulation of complex values. VLDB Journal 4\(4  794, 1995 6] B. Catania, A. Maddalena, E. Bertino, I. Duci, and Y.Theodoridis. Towards abenchmark for patternbases http://dke.cti.gr/panda/index.htm, 2003 7] L. De Raedt. A perspective on inductive databases SIGKDD Explorations, 4\(2  77, 2002 8] M. Escobar-Molano, R. Hull, and D. Jacobs. Safety and translation of calculus queries with scalar functions. In Proceedings of PODS, pages 253  264. ACMPress, 1993 9] V. Ganti, R. Ramakrishnan, J. Gehrke, andW.-Y. Loh A framework for measuring distances in data characteristics. PODS, 1999 10] T. Imielinski and H. Mannila. A database perspective on knowledge discovery. Communications of the ACM 39\(11  64, 1996 11] T. Imielinski and A. Virmani. MSQL: A Query Language for Database Mining. Data Mining and Knowledge Discovery, 2\(4  408, 1999 12] P. Kanellakis, G. Kuper, and P. Revesz. Constraint QueryLanguages. Journal of Computer and SystemSciences, 51\(1  52, 1995 13] P. Lyman and H. R. Varian. How much information http://www.sims.berkeley.edu/how-much-info, 2000 14] R.Meo, G. Psaila, and S. Ceri. An Extension to SQL for Mining Association Rules. Data Mining and Knowledge DiscoveryM, 2\(2  224, 1999 15] S. Rizzi, E. Bertino, B. Catania, M. Golfarelli M. Halkidi, M. Terrovitis, P. Vassiliadis, M. Vazirgiannis, and E. Vrachnos. Towards a logical model for patterns. In Proceedings of ER 2003, 2003 16] A. Siblerschatz and A. Tuzhillin. What makes patterns interesting in knowledge discovery systems. IEEE TKDE, 8\(6  974, 1996 17] D. Suciu. Domain-independent queries on databases with external functions. In Proceedings ICDT, volume 893, pages 177  190, 1995 18] M.Terrovitis, P.Vassiliadis, S. Skadopoulos, E. Bertino B. Catania, and A. Maddalena. Modeling and language support for the management of patternbases. Technical Report TR-2004-2, National Technical University of Athens, 2004. Available at http://www.dblab.ece.ntua.gr/pubs Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE pre></body></html 


The reason of the hiding failure of SWA is the same in Fig.8 Notice the result at x = 0.7646 in Fig.14, because the hiding failure is occurred at the seeds of the sensitive patterns, a high weakness is produced As shown in Fig.15 and Fig.16, the misses cost and dissimil arity of our work decreases as RL2 increases. This is because the larger RL2 is, the less effect on non-sensitive patterns. Also weakness and dissimilarity of SWA are independent of RL2 5. Conclusion In the paper, a novel method improving the balance between sensitive knowledge protecting and discovery on frequent patte rns has been proposed. By setting entries of a sanitization matrix to appropriate values and multiplying the original database by the matrix with some probability policies, a sanitized database is gotten. Moreover, it can avoid F-I Attack absolutely when the confidence level given by users approximates to 1. The experimental results revealed that although misses cost and dissimilarity between the original and sanitized database of our process are little more than SWA, ours provide more safely protection than SWA. Unlike SWA, our sanitization process could not suffer from F-I Attack and the probability policies in our approach also take the minimum support into account, the users only need to decide the confidence level which affects the degree of patterns hiding 6. Reference 1] M. Atallah, E. Bertino, A. Elmagarmid, M. Ibrahim and V. Verykios Disclosure Limitation of Sensitive Rules", Proc. of IEEE Knowledge and Data Engineering Exchange Workshop 1999 2] R. Agrawal and R. Srikant. Fast algorithms for mining association rules. VLDB, Santiago, Chile, 1994 3] R. Agrawal and R. Srikant. Privacy preserving data mining. In ACM SIGMOD, Dallas, Texas, May 2000 4] E. Dasseni, V. Verykios, A. Elmagarmid and E. Bertino, Hiding Association Rules by Using Confidence and Support", Proc. of 4th Intl Information Hiding Workshop \(IHW 5] A. Evfimievski, J. Gehrke, and R. Srikant. Limiting Privacy Breac hed in privacy preserving data mining. SIGMOD/PODS, 2003 6] A. Evfimievski, R. Srikant, R. Agrawal, and J. Gehrke. Privacy preserving mining of association rules. KDD 2002 7] M. Kantarcioglu and C. Clifton. Privacy-preserving distributed mining of association rules on horizontally partitioned data. In ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery, June 2002 8] Guanling Lee, Chien-Yu Chang and Arbee L.P Chen. Hiding sensitive patterns in association rules mining. The 28th Annual International Computer Software and Applications Conference 9] Y. Lindell and B. Pinkas. Privacy Preserving Data mining. In CRYPTO, pages 36-54, 2000 10] S. R. M. Oliveira and O. R. Za  ane. Privacy Preserving Frequent Itemset Mining. In Proc. of IEEE ICDM  02 Workshop on Privacy Security, and Data Mining 11] S. R. M. Oliveira and O. R. Za  ane. Algorithms for Balancing Priv acy and Knowledge Discovery in Association Rule Mining. IDEAS  03 12] S. R. M. Oliveira and O. R. Za  ane. Protecting Sensitive Knowledge By Data Sanitization, ICDM  03 13] S. R. M. Oliveira, O. R. Za  ane and Y  cel Saygin. Secure Association Rule Sharing, PAKDD-04 14] Benny Pinks. Cryptographic Techniques For Privacy-Preserving D ata Mining. ACM SIGKDD Explorations Newsletter Vol. 4, Is. 2, 2002 15] S. J. Rizvi and J. R. Haritsa. Maintaining data privacy in association rule mining. VLDB, 2002 16] J. Vaidya and C. W. Clifton. Privacy preserving association rule mining in vertically partitioned data. KDD2002 17] Verykios, V.S.; Elmagarmid, A.K.; Bertino, E.; Saygin, Y.; Dasseni E. Association rule hiding. IEEE Transactions On Knowledge And Data Engineering, Vol. 16, No. 4, April 2004 Proceedings of the 29th Annual International Computer Software and Applications Conference  COMPSAC  05 0730-3157/05 $20.00  2005 IEEE pre></body></html 


pre></body></html 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



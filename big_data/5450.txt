 An Adaptive Method for Discover ing Maximal Frequent Itemsets To large databases  V.Chandra Shekhar Rao  P. Geetha    P.K.Vaishali 2-1-29/b, Saraswathinagar            1-7-1329, Advocates colony  2-10-1286 Hanamkonda, Dist Warangal Hanamkond a, Dist Warangal  Jyothinagar, Karimnagar Andhra Pradesh, India, 506001 Andhra Pradesh, Indi a, 506001 Andhra Pradesh, India  vcsrao.kitswgl@gmail.com  Geetha_pallepati@yahool.com  vaishali5599@gmail.com  09052452294  09866661646    0970255599          Abstract 
 A novel adaptive method included two phases for discovering maximal freque nt itemsets is roposed. A flexible hybrid search method is given, which exploits key advantages of both the top-down strategy and the bottomup strategy. Information gathered in the bottomup can be used to prune in the other top-down direction. Some efficient decomposition and pruning strategies are implied, which can reduce the original search space rapidly in the iterations. The compressed bitmap technique is employed in the counting of itemsets support. According to the big space requirement for the saving of intact bitmap, each bit vector is partitioned into some blocks, and hence every 
bit block is encoded as a shorter symbol. Therefore the original bitmap is impacted efficiently. Experimental and analytical results are presented in the end  Key words frequent items, apriori, support count Association rule mining, Datamining  1.Introduction  Frequent itemsets mining was first proposed by Agrawal[1  f or market basket analysis in the form of association rule mining A major challenge in mining frequent itemsets from a large data set is the fact that such mining often generates a huge number of patterns satisfying the 
min _ sup threshold, especially when min _ sup is set low. This is because if a pattern is frequent, each of its subsets is frequent as well. A large pattern will contain an exponential number of smaller frequent subpatterns. To overcome this problem closed frequent itemsets\(CFI\d maximal frequent itemsets\(MFI\ning were proposed A n i t e m se t _ is a maximal frequent itemset or max-itemset t D if _ is frequent, and there exists no super-pattern 
_ such that _  _ and _ is frequent in D For the same min _ sup threshold, the set of max-itemsets, which is more compact, contains the complete information regarding to its corresponding frequent itemsets  1.1  Existing methods  In this paper first discussed on association rule mining, compared some algorithms on frequent itemsets mining. Frequent itemsets mining is first proposed by Agrawa r market ba s k e t ana l ysi s i n  the for m  of 
association rule mining. A major challenge in mining frequent itemsets from a large data set is the fact that such mining often generates a huge number of patterns satisfying the min _ sup threshold, especially when min _ sup is set low. This is because if a pattern is frequent, each of its subsets is frequent as well. A large pattern will contain an exponential number of smaller frequent sub patterns  To achieve this problem, closed frequent itemsets   CFI\maximal frequent itemsets \(MFI mining ere proposed t e m se t  is  a  m a xim a l    requent itemset \(or max-itemset\n set 
D if á is frequent, and there exists no super-pattern â such that and â is frequent in D For the same min _ sup threshold, the set of max-itemsets, which is more compact, contains the complete information regarding to its corresponding frequent itemsets. Mining max itemsets was first studied by Bayardo w h ere an Apriori-based, level-wise, breadth first search method was proposed to find max-itemset by performing superset frequency pruning and subset infrequency pruning for search space reduction 
 The above  zlgorithms approach is bottom up but the Pincer Search algorithms approach is both the bottom up and top down method. Pincer- Search uses horizontal data format. It not only constructs the candidates in a bottom-up manner like Apriori, but also starts a top-down search at the same time, maintaining a candidate set of maximal patterns. Depth-Project finds long itemsets using a depth first search of a lexicographic tree of itemsets, and uses a counting method based on transaction projections along its branches  
2010 International Conference on Advances in Recent Technologies in Communication and Computing 978-0-7695-4201-0/10 $26.00 © 2010 IEEE DOI 10.1109/ARTCom.2010.56 421 


 Mafia anot her ef f i cient m e thod formining the MFI, which uses three pruningstrategies to remove non-maximal sets and a vertical bit-vector data format to improve performance. Both Depth Project and Mafia mine a superset of the MFI, and require a post pruning toeliminate non-maximal patterns this algorithm isespecially efficient when the itemsets in the database are very long  FP-Growth[7 use s t h e no ve l fr eq uen t  pa tte rn tree  FP-tree\ructure, which is a compressed representation of all the transactions in the database, and a recursive divide-and conquers and database projection approach to mine long patterns. A portioning-based, divide and conquer method is used to decompose the mining task into a set of smaller tasks for mining confined patterns in conditional databases, which dramatically reduces the search space  The complexity of enumerating maximal itemsets is shown to be NP-hard. Ramesh et al h ara c terize d the length distribution of frequent and maximal frequent itemset collections  1.2 Proposed System  A modern adaptive approach method proposed included two phases for discovering maximal frequent itemsets is proposed. A flexible hybrid search method is given, which exploits key advantages of both the topdown strategy and the bottom up strategy. Information gathered in the bottom-up can be used to prune in the other topdown direction. Some efficient decomposition and pruning strategies are implied, which can reduce the original search space rapidly in the iterations. The compressed bitmap technique is employed in the counting of itemsets support. According to the big space requirement for the saving of intact bitmap, each bit vector is partitioned into some blocks, and hence every bit block is encoded as a shorter symbol Therefore the original bitmap is impacted efficiently   1.2  Contributions  Firstly, support counting is a confessed bottleneck in the association rules mining, which requires a great I/O and computing cost. A novel compressed bitmap index technique to speed up the counting process is employed The presented algorithm could reduce both the number oftimes the database is scanned and the search space rapidly. Secondly, a flexible hybrid search method is given, which exploits key advantages of both top-down and bottom-up strategies.  The rest of this paper is organized as follows. Section 2 discusses the problem of itemset support counting based on compressed bitmap technology. Section 3 introduces the description and decomposition strategies of search space. Section 4 presents the algorithm and some pruning strategies. The feasible optimizations and experimental results are presented Section 5. Finally, we conclude this paper in Section 6  2. Itemset Support Counting  The bitmap technique was proposed in the 1960’s and has been used by a variety of products. A typical context is the modern relational DBMS[10  I t a l s o h a s  been applied in association mining. The key idea of the approach is to use a bitmap index to determine which transactions contain which itemsets. Each transaction has one unique offset position in the bitmap. A bit vector \X,bit=\(b 1 b 2 b n  is associated to each itemset X  In X Bit the ith bit i bi is set to 1 if the transaction I contains the itemset X and otherwise i b is set to 0. It should be noted that i b is set to null if itemsets or transaction does not exist. The ordered collection of these bit vectors composes the bitmap. In a bitmap, a line represents a transaction, while a column corresponds to a given k itemset. During the supports counting, Intensively manipulates bit vectors requires a lot of disk space and main memory. So, it is necessary to compress the bitmap in advance. A new block strategy is proposed to encode and decode the bitmap which is similar to the pagination technology in operating systems. In this approach, every bit vector is partitioned into fractions, called blocks, that can be encoded respectively, so that a bitmap is divided into granules. Each block should have an appropriate size, if the size is too small, the impact is not remarkable otherwise the encoding is not straightforward. In order to take full advantage of Logical Calculation Units, the block size should be an exponential to 2. Each block is represented as  \(p:W  is the number of the block, and W is the block bit vector. Let l be the block size m the number of transactions in database D In this way each bit vector B=\(b 1 b 2 b i b m can be partitioned into p INT\( m ll blocks \( INT is the integer function\. The k th block vector Wk=\(w 1 w 2 w j j=MOD\(I,l\=i-i*\(k-l MOD is the mode function  Encoding each block as a shorter code can reduce the space demanding. The encoding principle which should be conformed is that each block can be represented uniquely. As a part of the initial bit vector B each block vector W is also a binary bit vector. The conversion between binary, octal, decimal and hexadecimal can be implemented conveniently, hereby every block can be represented a binary, octal, decimal or hexadecimal code. We use a hexadecimal code, i.e. every four bits in a block encode a hexadecimal code. As each itemset is associated to a binary bit vector, the support of a given itemset is the total number of 1 in the vector. For the sake of efficient counting the number of 1, we previously store the binary block in a bit array Bit[1  l is the block size\ and the hexadecimal 
422 


 blocks in an array ABit[1..p   p is the number of blocks\ The value in ABit  is the hexadecimal code of the i th block. Implementation of this support counting algorithm follows  2.1 Proposed algorithm to Itemset support Counting  Algorithm 1 Itemsets Support Counting Algorithm Countsupport  X 1 X 2 Begin Support 0 For i 1 i  p  i do If X 1 ABit  i    0 and X 2 ABit  i  For j 1; j l  j do X1  Bit  j   X 2 Bit  j  X 2 Bit  j  Support  X  Bit  j  Endfor X  ABit  i   X 1 ABit  i  X 2 ABit  i  Else X  ABit  i  0   endif;   end  3. Description of the Search Space  With only a limited amount of main memory in practice, we should decompose the original search space into some smaller pieces, such that each one can be solved independently in main memory. Following the above description and partition mechanisms, the original enormous search space could be partitioned into some little ones as flexibly as possible Furthermore, theorem1 can be used to prune the search space. The search space for item set I  a  b  c  d is S  I   I t c an b e part it ione d in to s o m e li tt l e  one s s t ep b y  step. The iterative results of a hierarchy of search space are shown in figure 1      For a given item set I in database D and the minimum support threshold min_sup the tas k of mining FI or MFI is in the follow: finding the set \(x\\x 002  Supp\(x\minsup in the search space S  I    4. Discovering Max-itemsets  4.1 Search and Pruning Strategy In general, it is possible to search for the maxitemsets either top-down or bottom-up The bottom-up approach is good for the case when all max-itemsets areshort, and the top-down approach is good when all maxitemsetsare long. If some max-itemsets are long and some are short in the mining database, then both search approaches will not be efficient. A key idea of our hybrid approach is the use of information gathered in the search in the bottom-up to prune search space during the top down search. It uses infrequent itemsets found in the search in the bottom-up to prune search space during the topdown search For search space S  X  Y   if t h e numbe r of infrequent itemsets containing X is large, the scale of S will be reduced rapidly  4.2 The Hybrid Max-Itemsets Search Algorithm There are two phases in this hybrid approach: the search in bottom-up direction and the other in topdowndirection for every pass. Max-itemsets are enumerated in both bottom-up and top-down directions Consider a pass k the set of frequent k itemsets Lk and the set of infrequent k itemsets Lk are to be classified in the bottom-up direction. This procedure repeatedly uses Apriori-gen algorithm to generatecandidates like the Aprior D u rin g t h e k th pass, every search space S• •[X er e X is an itemset of size k 1 can be decomposed into some little pieces, whose ancestors are k itemsets. For search spa p-d o wn  procedure check whether the border element \(i.e XUY  f S is frequent firstly, if not S is decomposed Implementation of this hybrid approach is shown in algorithm2  Algorithm2. Algorithm fo r Max-itemsets Mining Procedure: MFI Search \(Transaction Set D Item  
423 


     5. Experimental and Analytical Results  In this algorithm bitmap technology is used to count the support of every itemset instead of scanning the entire transaction database. Figure 2 shows the relative times at varying numbers of transactions for databases where the average size of transactions is 10 and the average size of potential max-itemsets is 4   When the average size of transactions or the average size of max-itemsets increase, there has much more itemsets \(or search spaces\to be tested. therefore the total time will increase. Figure 3 shows the relative times of this hybrid algorithm at varying minimal supports on the datasets of T15.I8.D10K      To illustrate expandability of this algorithm, we performed an experiment varying the database size from 5K to 20K. The average size of transactions is 10 and the average size of potential max-itemsets is 6. For the experiment we fixed a minimum support of 4 Figure 4 shows the result for the datasets    As we have shown, there are three search strategies for discovery MFI. Figure 5 shows the relative times of the three approaches for the tests at varying minimal supports on T10.I6.D10K. From the experiments, we could see that when minimal support is greater than 2 the performances of the bottom-up is little better than the hybrid. The main reason is that the number of itemsets generated is small with the increasing of minimal support. As the minimal support decreases MFI becomes longer, which results in an increase in the number of counting itemsets. In such a case, the hybrid has performances. We can also see performance of the bottom-up approach is lower than the others. The most primary factor is almost all the max-itemsets are expected to not be long in this T10.I6.D10K dataset The experiment illustrates the fact that top-down search might be efficient for the long maxi temsets       
424 


 6. Conclusions  We use an improved compacting bitmaps database format. Support of itemset can be counted by means of binary bit vectors intersections, which minimizes the I/O and computing cost. To reduce the disk and main memory space demanding, we break the bitmap down into some little blocks, which can be encoded as a shorter code. The blocks of bitmaps are fairly adaptable Hence the additional space decreases rapidly. The hybrid approach exploits key advantages of both the top-down strategy and the bottom-up ones, which can discovery both longer max-itemsets and the shorter ones in earlier passes. And the infrequent \(or frequent itemsets discovered in the bottom-up can also be used to prune the search space in the other top-down direction. Furthermore, this algorithm can be parallelized easily on this hierarchical search space organization. We note that using ~Lk to prune the search space is not the only technique. If it would be more efficient to decompose and prune the search space using Lk rather than ~Lk   Too many candidate itemsets and a large database would create a performance bottleneck,  if we apply the pipeline methodology using hardware.  So we effectively reduce the frequency of loading the database into the hardware  Acknowledgements  Thnks very much to prof Fu-zan Chen,and prof Min-qiang Li published lot of research work in this rea  References   R   A g ra w a l T. Im ieli nSk i A  Sw ami Mi n i ng Association rules between sets of items in large database. Proc. of the ACMSIG2 MOD International Conference on Management of Data Washington, DC.1993, 2 : 207-216   e i H a n, e t a l  F r equent pat t ern m i ning cur r en t  status and future directions, Data mining and Knowledge Discovery, 2007 V\(15\6  3 a rd o R  Ef fi ci en tly  mi n i ng  l o ng pat t ern s f r o m  databases. In: Proc. of the ACM  IGMOD, Int’l Conf On Management of Data. New York: ACM Press. 1998 85-93  4 a o I Li n  Zaki  M Ked e m  Pi n c er S earch A New Algorithm for Discovering the Maximum Frequent Set Proceedings of the 6th International Conference on Extending Database Technology. 1998. 105-119  5   Ag r a wal   C. Ag arwal D e p t h f i rst gen e rat i o n  o f  Long patterns, 7th International conference on Knowledge discovery and Data mining. 2000. 108-118   B u r d i c k, M   Calimlim  an d J. Gehrke MAFIA: A  Maximal Frequent Itemset Algorithm for Transactional Databases, Proc. of the 17th Int' l Conf. on Data Engineering. 2001. 443-452   P  H a n  Y   Y i n  M i n i n g  freque n t  pa t t er ns w i t h o u t  candidate generation. In ACM SIGMOD Conf., May 2000. 1-12  8 i z h e n Y a n g   Th e co mpl e xi t y of mini ng ma xi ma l  frequent itemsets and maximal frequent patterns. In Proceeding of the 2004 ACM SIGKDD international conference on knowledge discovery in databases KDD’04\eattle,WA, 344–353   e sh G, Maniatty W A Zaki MJ \(2003\Feasible itemset distributions in data mining: theory and application. In: Proceeding of the 2003 ACM symposium on principles of database systems PODS’03\an Diego, CA, 284–295  10 Mi kol a j Mo rz y  Hi e r arc h i cal  B i t m ap Ind e x An Efficient and Scalable Indexing Technique for Set Valued Attributes, ADBIS 2003, LNCS 2798, 2003 236–252  11 R y m on E 19 92 S e arch t h ro u gh S y stem at i c S et Enumeration, In Proc. Of tjird Int conf on Principles of Knowledge representation and Reasong.593-550  Agarwal R,Srikant R919950 Mining Sequential patterns in proceedings of the 1995 International conference on data engineering\(ICDE’95\ Taipei, Taiwan,pp 3-14  Han J.Kamber M\(2006\ata Mining concepts techniques, 2 nd edn. Morgan Ksufmann  Kamber. M. Han J.Chiang JY\(1997\tarule-guidd mining of multi-dimensional association rules using data cubes, In: Proceeding of the 2005 ACM SIGKDD international conference on knowledge discovery and data mining\(KDD’97\Newport,Beach,CA,pp 207-210  A Hybrid method for discovering Maximal frequent Itemsets Fu-zan Chen, Min-quang Li,Fifth International conference on fuzzy systems and knowledge discovery 970-07695-3305-6108 2008 IEEE  A Two-way Hybrid Algorithm for Maximal Frequent Itemsets Mining, Fu-zan Chen, Min-qiang Li, School of Management, Tianjin University Tianjin, 300072 China        
425 


  0   5   10   15   20   25   30   0   5   10   15   20   25   30   35 Speed of threads alignmena \(untied fft \(untied   floorplan \(manual-untied   health \(manual-tied   nqueens \(manual-untied  sort \(untied   sparselu \(for-tied  strassen \(nocutoff-tied   Figure 3 Benchmark suite results as base code version These results give an idea of the performance behavior for each application We have applications  NQueens or SparseLU  which have an almost linear speed-up and other applications  Strassen  Health or FFT  which quickly reach a saturation phase B Cut-off mechanism comparison Due to the recursive nature of some benchmarks see Section III-B we can group cut-off mechanisms into two groups 002rst we include cut-off mechanisms which are based on the task depth i.e the recursion level Such kind of cut-off is usually implemented in the application itself Our benchmark suite implements when possible these cutoff mechanisms In the second group we can 002nd cut-off mechanisms based on the total number of tasks already created the number of tasks ready to be executed etc Such pruning mechanisms can be easily implemented in the OpenMP runtime itself   0   5   10   15   20   25   30   1   2   4   8   16   24   32 Speed-up of threads with if clause cut-off with manual cut-off  with no cut-off   Figure 4 Queens benchmark using different cut-off mechanisms Figure 4 shows the speed-up s obtained using these different cut-offs for the NQueens benchmark 017 manual cut-off  prunes the generation of tasks in the application code itself Compiler and runtime are not aware of the possibility of creating a task or not 017 pragma if cut-off  uses the OpenMP clause if  as a part of the task creation directive task  When the condition evaluates to false the task will not be created But the runtime still has to do some management in order to keep consistency e.g task hierarchy and dependence in order to execute properly a taskwait  017 no-cutoff  the application does not provide a cut-off and only the one implemented by the runtime if any is in use The Intel Compiler uses a cut-off based on the number of tasks We can see in the results that with the Intel Compiler programming a manual cut-off is more effective than using an if clause or relying on their runtime cut-off Being a very new compiler these results were expected Hopefully as the task implementations mature these differences will disappear thus reducing the burden on the programmer C Tied vs untied tasks The OpenMP programming model speci\002es that tasks can be labeled with the untied clause establishing two different kinds of tasks tied and untied A tied task is a task that when it is suspended can be resumed only by the same thread that suspended it whereas untied tasks can be resumed by any thread Tiedness of a task does not only imply which thread can resume a task but it also implies some task scheduling constraints which can also impact on the application performance   0   5   10   15   20   25   30   1   2   4   8   16   24   32 Speed-up of threads alignment tied alignment untied  nqueens tied  nqueens untied   Figure 5 Benchmark suite results using tied and untied tasks The suite comes with versions for all applications with tied and untied tasks to compare their behavior Figure 5 shows the results obtained using tied and untied tasks 
129 
129 


with the Alignment and NQueens benchmarks Results are similar with both versions Although a deeper analysis will be needed the results suggest two main hypothesis 017 The Intel Compiler does not implement thread switching and thus untied tasks cannot bene\002t from this feature which should avoid imbalances This is particularly evident in the Alignment benchmark which has been reported to scale 017 Task scheduling constraints do not seem to impact signi\002cantly the performance results at most there is a 4 difference between the versions The other applications show a similar behavior D Other opportunities for analysis The Intel Compiler does not implement mechanisms that allow the user choose among different task scheduling policies but other OpenMP compilers e 16 that have such capabilities One interesting study is to 002nd how task scheduling policies and how they can mantain locality across tasks can affect the performance results of the benchmarks of the suite In previous sections we have discussed how implementing a cut-off mechanism can affect application performance but we have not discussed due to space limitations how the different cut-off values i.e at which point in the recursion we cut relate with the creation of parallelism and the overall performance Choosing a low cut-off value can restrict parallelism opportunities but choosing a high cut-off value can saturate the system with a large amount of tasks which have no thread available to execute them The right choice depends many times of the input data set Comparing the application behaviour using different cut-off values or testing runtime features which allow to modify dynamically the cut-off can also be interesting analyses The quality of implementations for different task generation schemes e.g in the SparseLU benchmark which can use a single or multiple generator scheme taskwait constructs or other task related implementation details could also be analyzed with our benchmark suite proposal V C ONCLUSIONS AND F UTURE WORK We have presented BOTS  Barcelona OpenMP Task Suite  built with the double motivation of coping with the great characteristics of the multicore processors and offer a set of benchmarks to evaluate OpenMP tasking We think that BOTS will help implementors and programmers to have a better understanding of the OpenMP tasking model and its performance implications Each of these benchmarks comes also with different versions to test different aspects of the tasking model For example they can be used to evaluate task scheduling alternatives tiedness   Also a number of input sets are provided so that benchmarks can be used as tests or really stress the processors and memory system in your machine It is interesting to note that we have tried to select benchmarks with diverse characteristics In this paper we have highlighted the differences and we have shown their evaluation on an SGI Altix machine with up to 32 processors and we report some of their characteristics per task e.g operations memory writes    Their evaluation also shows that there is plenty of work to do at all levels  architecture compiler runtime system programming model to improve certain benchmarks given that their current scalability is very limited This suite can be used to obtain useful data of the strenghts and weaknesses of an OpenMP implementation that can help developers to improve it Currently we are working to add new benchmarks to the suite to cover more problem domains and scenarios We are as well planning to do a full cross-vendor evaluation to 002nd which is the current state of the OpenMP tasking implementations A CKNOWLEDGMENTS This research was supported by the Spanish Ministry of Science and Innovation contracts no TIN2007-60625 and CSD2007-00050 the European Commission in the context of the SARC project contract no 27648 the HiPEAC Network of Excellence contract no IST-004408 the IBM CAS Program and the Mare Incognito project under the BSC-IBM collaboration agreement R EFERENCES  O ARB OpenMP Applicati on Program Interf ace v  3.0  May 2008  J M Bull Measuring Synchronizati on and Scheduling Ov er heads in OpenMP in First European Workshop on OpenMP  September 1999  LLNL OpenMP Performance Suite Description 2001 A v ailable https://computation.llnl.gov/casc/RTS Report/openmp perf.html  A Dorta C Rodriguez F  de Sande and A Gonzalez The OpenMP Source Code Repository Euromicro Conference on Parallel Distributed and Network-Based Processing  vol 0 pp 244–250 2005  C Bienia S K umar  J P  Singh and K Li The P ARSEC Benchmark Suite Characterization and Architectural Implications in Proceedings of the 17th International Conference on Parallel Architectures and Compilation Techniques  2008 pp 72–81  H Jin M Frumkin and J Y an The OpenMP Implementation of NAS Parallel Benchmarks and Its Performance NASA Ames Research Center Technical Report NAS-99-011 1999 A v ailable citeseer.ist.psu.edu/408248.html 
130 
130 


 D H Baile y  E  Barszcz J T  Barton D S Bro wning R L Carter D Dagum R A Fatoohi P O Frederickson T A Lasinski R S Schreiber H D Simon V Venkatakrishnan and S K Weeratunga The NAS Parallel Benchmarks The International Journal of Supercomputer Applications  vol 5 no 3 pp 63–73 Fall 1991 A v ailable citeseer.nj.nec.com/bailey95nas.html  H Jin and R F  V  der W ijng aart Performance Characteristics of the Multi-zone NAS Parallel Benchmarks J Parallel Distrib Comput  vol 66 no 5 pp 674–685 2006  V  Aslot M Domeika R Eigenmann G Gaertner  W  B Jones and B Parady SPEComp A New Benchmark Suite for Measuring Parallel Computer Performance Lecture Notes in Computer Science  vol 2104 pp 1  10 2001  A v ailable citeseer nj.nec.com/aslot01specomp.html  C Bienia S K umar  and K Li  P ARSEC vs SPLASH-2 A Quantitative Comparison of Two Multithreaded Benchmark Suites on Chip-Multiprocessors IEEE International Symposium on Workload Characterization 2008  pp 47–56 2008  K K usano S  Satoh and M Sato Performance Ev aluation of the Omni OpenMP Compiler in Prooceedings of the Third International Symposium on High Performance Computing  2000 pp 403–414  S Shah G Haab P  Petersen and J Throop Fle xible Control Structures for Parallellism in OpenMP in 1st European Workshop on OpenMP  September 1999  P  C Fischer and R L Probert Ef 002cient Procedures for Using Matrix Algorithms in Proceedings of the 2nd Colloquium on Automata Languages and Programming  SpringerVerlag 1974 pp 413–427  M Frigo C E Leiserson and K H Randall The Implementation of the Cilk-5 Multithreaded Language in Proceedings of the ACM SIGPLAN 1998 conference on Programming Language Design and Implementation  1998 pp 212–223  E A yguad  e N Copty A Duran J Hoe\003inger Y Lin F Massaioli E Su P Unnikrishnan and G Zhang A Proposal for Task Parallelism in OpenMP in Proceedings of the 3rd International Workshop on OpenMP  Beijing China June 2007  X T eruel X Martorell A Duran R Ferrer  and E A yguad  e Support for OpenMP Tasks in Nanos v4 in CAS Conference 2007  October 2007  E A yguad  e A Duran J Hoe\003inger F Massaioli and X Teruel An Experimental Evaluation of the New OpenMP Tasking Model in Proceedings of the 20th International Workshop on Languages and Compilers for Parallel Computing  October 2007  A Duran J Corbal  an and E Ayguad  e Evaluation of OpenMP Task Scheduling Strategies in Proceedings of the 4th International Workshop on OpenMP  2008  H L v an der Spek E M Bakk er  and H A W ijshof f Char acterizing the performance penalties induced by irregular code using pointer structures and indirection arrays on the intel core 2 architecture in Computing Frontiers 2009  May 2009  M Burtscher  P  Carribault M K ulkarni K Ping ali C Cascaval and C von Praun Lonestar benchmark suite http://iss.ices.utexas.edu/lonestar 2009  B Chamberlain J Feo J Le wis and D Mizell An Application Kernel Matrix for Studying the Productivity of Parallel Programming Languages in W3S Workshop 26th International Conference on Software Engineering  May 2004 pp 37–41  M C and A Rogers Softw are Caching and Computation Migration in Olden 1995  G Myers and S Selznick and Z Zhang and W  Miller Progressive Multiple Alignment with Constraints in RECOMB 97 Proceedings of the 002rst annual international conference on Computational molecular biology  New York NY USA 1997 pp 220–225  J Coole y and J T uk e y  An Algorithm for the Machine Calculation of Complex Fourier Series Mathematics of Computation  vol 19 pp 297–301 1965  S R Das and R M Fujimoto A Performance Study of the Cancelback Protocol for Time Warp SIGSIM Simul Dig  vol 23 no 1 pp 135–142 1993  S G Akl and N Santoro Optimal P arallel Mer ging and Sorting Without Memory Con\003icts IEEE Transactions on Computers  vol 36 no 11 pp 1367–1369 1987  A Duran J Corbal  an and E Ayguad  e An Adaptive Cut-off for Task Parallelism in Proceedings of the 2008 ACM/IEEE conference on Supercomputing  IEEE Press 2008  J Bal art A Duran M Gonz 036 alez X Martorell E Ayguad  e and J Labarta Nanos Mercurium a Research Compiler for OpenMP in Proceedings of the European Workshop on OpenMP 2004  October 2004 
131 
131 



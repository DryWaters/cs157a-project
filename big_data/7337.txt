Review of Frequent Itemsets Mining in High Dimensional Dataset  Mohammad Arsyad Mohd Yakop Faculty of Computer and Mathematical Sciences Universiti Teknologi Mara 40450 Shah Alam, Malaysia arsyadyakop@live.com Sofianita Mutalib, Shuzlina Abdul Rahman Faculty of Computer and Mathematical Sciences Universiti Teknologi MARA 40450 Shah Alam, Selangor, Malaysia sofi, shuzlina}@tmsk.uitm.edu.my   Abstract   Nowadays, there are abundant of big data collection and to understand its patterns would need a thorough analysis Analyzing big data would depend highly on the purpose and the tasks involved would be various. One of the significant tasks is frequent itemsets mining and 
the strategy has been evolved in many ways in order to improve the efficiency and effectiveness of the mining process In this paper, we briefly reviewed mining frequent itemsets algorithms from year 1998 until year 2013 that focus on maximal and closed frequent itemsets. We discussed thes e algorithms based on three main areas namely: the searching st rategy, space reduction method and data representation. These three main areas are concluded as the optimization strategy and are designed to improve the efficiency and scalability using a different approach in different areas to adapt to numerous growth of the dataset This work is beneficial for researchers in designing and enhancing the algorithm based on their own purposes 
Keywords- Data mining; high-dimensional dataset; frequent itemsets I  I NTRODUCTION   Mining frequent itemsets is the basic process in association rule mi The aim is to discover t h e frequent patterns that exist with a frequency not less than the minimum support of thresholds determined by a user [1-5   Mining frequent pattern can be represented in several structures such as substructure graph and itemset. Apriori and Frequent Pattern-Tree \(FP-Tree\the classic algorithms of frequent itemset mining. Till date, there are numerous algorithms that have been proposed in discovering the frequent itemsets, and they are usually constructed based on these two classical algorithms. The target is to have better efficiency and scalable mining 
algorithm of useful patterns in discovering knowledge  The need for analyzing the high-dimensional \(big data data has been asserted since the emerging of various new  the tasks in data mining is to mine frequent itemsets. Frequent itemsets is a group of items in the dataset that o ccur frequently with the given thresholds of the minimum support. Most algorithms are Apriori variants, which enumerate all possi ble frequent items  In a dataset, it contains 2 n where n is the number of items in the dataset\bsets of frequent itemsets to be mine. In a real world domain for instance, gene expression studies, network intrusio n, web content and usage mining contain typical long items 
For example, if a dataset contains five items, it generates 32 \(2 5 ubset of frequent patterns where it still looks effortless to compute.  However in real-world application, a data set might contain 40 items or even more than that and these will generate 1,099,511,627,776 \(2 40 ets which obviously giving a computational problem. Further more, full set of frequent itemsets contains redundant information that causes a large num   In order to understand and facilitate other researchers we reviewed several algorithms and propose a table of summarization on these algorithms. This review paper will discuss the available algorithms that have been developed for 
frequent itemsets mining. In section 2, we describe on big data and the effects of these criteria in mining frequent itemsets. In section 3, we presen t the algorithms and in section 4, the analysis of the optimization strategy is discussed. Finally, we conclude with the summary of this review paper in section 5 II. B IG D ATA A ND I TS I MPACT O N A LGORITHMS   Lately, we have been introduced by many active researches to the term of èBig Dataê. Big Data is described as the very huge and based on the three V  s data volume, data velocity and data variety and these three 
Vês based ha The m a ssive huge  volume of data is obviously givi ng a problem in analyzing the data. If our objective is to mine the frequent itemsets then the increment of data size is affecting the efficiency in mining task. Big Data are characterized by two factors namely, high-dimensionality and large samp   These characteristics are referred to data volume where the numbers of features \(dimensionality\ber of records rows\assively expand to hi gh volume depends on the applications. When the data set has thousands of dimensions or samples, it will create a great challenge to developer in producing a good algorithm to analyze the data. For example, the searching method in Big Data is time consuming and when we used conventional method, it might not be practically efficient 
in high volume of data   mining the big data. The first challenge is the curse of dimensionality, when the dimensionality becomes large; the volume of the search space is increasing. Due to this problem, the existing data representation is inefficient and many not applicable to work with a high dimensional space or not. How the algorithm managed to load these huge of 2014 4th International Conference on Artificial Intelligence with Applications in Engineering and Technology 978-1-4799-7910-3/14 $31.00 © 2014 IEEE DOI 10.1109/ICAIET.2014.19 57 


dimension into the memory for mining process is questionable A nothe r issue fr om this challenge is the  processing time since the computational time increases as dimension increases. The main memory consumptions can affect the algorithmês effic large dataset are mining, it requires more memory space. The second challenges that may arise is the specificity of similarity between points in high dimensional space. We havenêt looked into the second challenge because it is more related to the clustering issue and beyond our scope. From the first challenge, it has driven many researchers to come out with novel mining algor ithm to handle these dataset characteristic problems since the traditional algorithm becomes incompetent III. F REQUENT I TEMSETS A LGORITHMS   Frequent itemsets are discovered by determining the minimum support value and occurred in investigating dataset. It is part of associati on rules mining whi ch involves two main tasks 1 Find all frequent itemsets in the dataset 2 Each itemset found, generate all association rules with confidence equal or larger than minimum_confidence that has been determined  Currently, there are two scopes to mine these frequent itemsets problems instead mining all possible frequent itemsets. The first scope is by mining only the maximal frequent itemsets. Maximal frequent itesets are frequent pattern that has no frequent superset [7  The second problem scope is to mine closed frequent patterns. Closed frequent patterns is a frequent pattern that has no superset with the same  The idea to mine the closed and maximal frequent itemsets is to speed up the searching of all frequent itemsets, without to enumerate all possible frequent itemsets. Example of closed and maximal frequent itemsets is, letês say a transaction dataset has only two a, b, c, d the minimum support thresholds = 1. We find two closed frequent itemsets \(CFI\ncy = {\(a, b, c, d, e, f a, b, c, d\e, in maximal frequent itemsets there is only 1 frequent itemset MFI = {\(a, b, c, d, e, f, g Itemsets {a, b, c, d} is not included because it has frequent superset {a, b, c, d, e, f, g  With these two problems scopes introduced divided frequent itemsets algor ithms into three categories which are 1\ mining frequent itemsets, 2\ mining maximal frequent itemsets, and 3\ining closed frequent itemsets. In this paper, we briefly review the evolution of closed frequent itemsets and maximal freque nt itemsets within 16 years starting year 1998 until year 2013 by focusing on large scale dataset. We did not claim this work as a complete review rather it is a partial review that an alysed the work that related to our interest A Maximal Frequent Itemsets Algorithms  One of the earliest algorithms that used mine maximal frequent set is Pincer-Search Pincer-Search is a combination of bottom-up and top-down search directions The authors introduced a novel of auxiliary data structure called maximum frequent candidate set \(or MFCS\der to create new efficient top-down searching. The algorithm showed a significant result in reducing the number of times to read the database and number of times to enumerate the candidates. However, there is still a slight problem in discovering maximal frequent set when maximal frequent itemsets are distributed in a scattered manner  is another algorithm  that m i nes only the  maximal frequent itemset. By mining maximal frequent itemset, we can find out all frequent itemset from the maximal frequent itemset sin ce all frequent itemset is a subset of maximal frequent items The success of this algorithm is by evading a stri ct bottom-up traversal of the search space and uses the heuristic to search long frequent itemsets. To work out a good lower-bound on the number of transactions contain in the itemset, MaxMiner used a technique to identify the new candidate itemsets before accessing the database by retrieving the stored information that has been collected from  i n e s m a xima l frequent itemsets by adaping the vertical bitmap data representation for counting and pruning mechanisms in searching the itemsets lattice. The algorithm implements a pruning technique to boost the efficiency of mining maximal frequent itemsets.  Three pruning techniques were introduced which are parent equivalence pruning \(PEP\quent head union tail \(FHUT\d HUTMFI. The analysis has shown pruning techniques applied to the algorithm such as PEP and FHUT were very useful in reducing the search space MAFIA can also generate frequent itemsets and closed frequent itemsets  SmartMiner has been introduced by  to find the exact maximal frequent itemset for large datasets SmartMiner uses tail informat ion similar to depth-first search strategy. Nevertheless, it works a bit different from dynamic reordering depth-fi rst search strategies \(DFS\reby the SmartMiner will only create a node if the prior node is checked. Moreover, SmartMiner uses heuristic select function where the tail information and the frequency of the each item as their condition. With these additional features SmartMiner creates less subtrees compare with dynamic DFS and skip the superset checking by passing the tail information  FPMax algorithm is a v a riation of the FP-gr owth  which aims to find maxim um length frequent itemsets FPMax uses a global data stru cture called Maximal Frequent Item set tree \(MFI-tree\keep track the frequent pattern and apply the novel Lattice Grap h maximum length itemsets to prune the search space more efficiently  ithm that used backtracking search to enumerate all maximal pattern expeditiously. The algorithm applied the novel progressive focusing technique to eradicate non-maximal pattern a nd diffuse propagation to boost up the frequent checki ng. This progressive focusing technique narrows the search space to only the most related maximal itemsets by adding the check_status flag where superset checking is performed only if the flag is true. The idea behind diffset propagation is to avoid from storing all each tidset into combination set 58 


LFIMiner is an algorithm that min es the maximal frequent  ation such as Conditional Pattern base Pruning \(CPP\requent Item Pruning \(FIP Dynamic Reordering \(DR\re implemented to make the pruning search space efficient in LFIMiner. To reduce the TP-tree size, DR is used by keeping more frequent item closer to the root while to make the pruning search space efficiently CPP and FIP method are used B Closed Frequent Itemsets Algorithms  Mining closed frequent ite msets looks more sensible and we can still generate all the frequent itemsets together with their support pattern algorithm that has been proposed unable to deal with a dataset that contain a high number of items \(example 10,000 or more items Lee [22 has categorized the closed frequent itemsets mining algorithms into four categories which were te st-and-generate, divide-andconquer, hybrid, and hybrid without-duplication  A-Close [1 i s an al gori t h m  in m i ni ng freq u e nt i t e m s et s based on pruning closed itemset lattices concept. The main idea of this algorithm is to reduce the search space and memory consumption by implementing closed itemset lattices that mining closed frequent itemsets instead of mining all frequent items   is another algorithm  to find the closed frequent itemsets. It is different from the other mining algorithms which focus on itemset search space.  CHARM explores both itemset space and transaction space concurrently. The novel searchi ng method gives CHARM the ability to skip levels to find the closed frequent itemsets Furthermore, by using union and in tersection of two itemsets space and transaction space, CHARM is able to identify where the itemsets is located and does not require the internal data structure like Hash-trees or Tries  is an algorith m to discover a closed frequent itemsets that applied three main techniques which are applying compress frequent pattern in the FP-tree structure for mining closed itemsets without candidate generation developing single prefix pa th compression technique to identify frequent closed itemset faster and exploring a partition-based projection mechan ism for scalable mining in large databases. Wang et al  has pr oposed Closet which is an enhancement of Close that mines only closed frequent itemsets. Closet+ uses FP-tree to represent the frequent pattern and search it by Depth-First-Search \(DFS strategy  The Carpenter has propose and the design is to mine closed frequent itemsets in biological dataset such as microarray. Experiments have sh own the Carpenter outperforms its competitor such as CHARM and the CLOSET which was tested on biological dataset. The Carpenter used a novel search strategy where it enumerates frequent pattern using row rather than by column enumeration. It consists of two main parts which are transposing the data into tab le and creating row enumeration tree search  m that m i ned close d frequent itemsets targeted for dense and parse dataset. The COBBLER is a combination of row enumeration and column enumeration searching strategi es. It is designed to dynamically switch betw een row and column enumeration while mining the closed frequent itemsets.  The idea of these algorithms is to mine closed frequent itemsets for a dataset that have different characteristics. Row enumeration is used for dense dataset that have a large number of columns and a few rows while column enumeration is for fewer numbers of columns and huge amount of rows. TFP are closed frequent itemsets mining al gorithm that mines base on topk mining. Instead of mining frequent itemsets that above the min_support thresholds, it uses top-k frequent itemsets with a minimum length min_l where k is a user defined value  m  that m i ned closed frequent itemsets for high di mensional dataset which has a small number of rows and high numbers of columns. This algorithm used novel row enumera tion tree which is more suitable for high dimensional dataset. The beauty of the TDClose is by using the novel top-down search strategy where it speed up the frequent closed itemset searching and reducing the memory usage  is an algor ithm that mined closed frequent itemsets based on two key feat ures: prefix graph and pruning strategy \(inter-node and intr a-node pruning\ in order to reduce the search space. Analysis has shown, PGMiner uses low memory usage even at the low support thresholds  PTClose or Pa the PT Array  Technique to reduce the tree scanning Patricia Tree structure is a compact representation of the information frequency in the dataset. By using th is data representation, PTClose algorithm required less memory and time consumption  is an algorithm to find cl osed fre quent  itemsets by mining closed inter-transaction itemsets. The algorithm implements a novel data structure called itemsetdataset pair \(ID-pair\the ai m is to store information in inter-transaction dataset tree or known as the ID-tree  m that mi ned closed frequent itemsets based on top-d own searching strategy. The key feature of this algorithm is the row enumeration tree in top-down approach that minim izes the number of scanning Additionally, TTD-Close implem ents a pruning technique called closeness-checking and other several pruning strategies targeting to reduce the search space. TTD-Close is aiming to mine in a very high dimensional dataset  is an algorithm  that m i ned closed fre quent  itemsets, targeted to overcome the drawback of the FP-tree CFIM-P maximizes the mini ng closed frequent pattern by eliminating the redundant patte rns and minimizing the depth of the tree without losing important information. This algorithm works in three stages.  In the first stage, it eliminates the null transactions to reduce the processing time. In the second stage, it generates closed frequent itemsets and lists all the rel evant itemsets. Lastly, all the frequent itemsets are formed based on the closed frequent itemsets that has been discovered  Different with previous algori thms, Moment uses to  mine closed frequent itemsets and claimed as the first that mine over data stream slid ing windows. The authors highlighted new data structure closed enumeration tree  59 


TABLE I E VOLUTION S EARCHING S TRATEGY   MaxMiner \(Bayardo , 1998 Pincer-Search \(Lin, 1998 A-Closed \(Pasquier, 1998 CHARM \(Zaki, 1999 Closet \(Pei, 2000 MAFIA \(Burdick, 2001 SmartMiner \(Zou, 2002 FPMax\(Grahne, 2003 Closet+ \(Wang, 2003 Carpenter \(Pan, 2003 Cobbler \(Pan, 2004 GenMax \(Gouda, 2005 TFP \(Wang, 2005 Moment \(Chi, 2006 TD-Closed \(Liu, 2006 PGMiner \(Moonesinghe, 2006 PT-Closed \(Nezhad, 2007 ICMiner \(Lee, 2008 LFIMiner \(Hu, 2008 TTD-Closed \(Liu, 2009 PCP-Miner \(Lee, 2010 CFIM-P \(2011 A-NewMoment \(Min, 2013 data representation                        search strategy                        space reduction method                 CET\store all closed frequent itemsets in the current sliding window. Because of the CET, the Moment algorithm create the number of nodes less than total number closed frequent itemsets  A-NewMomen is an al gorithm that used to m i ne closed frequent itemsets in data streams. The A-NewMoment introduced novel combinative data structure called bit-vector dictionary frequent itemsets list or known as BV-DFIlist which consist of bit-vector a rray, dictionary list and hash table. This algorithm is aime d to improve the time-efficiency problem while mining closed frequent itemsets in data streams. Using the novel data structure BV-DFIlist, this algorithm however required more memory space in order to have fast computational time A-NewMoment algorithms creates smaller search space compared to Moment after applying its new data struct ure strategy. Next, we will discuss the analysis of features of each algorithm and optimization strategy IV. A NALYSIS AND D ISCUSSSION  Finding frequent itemsets is a crucial task in several application fields such as in rules discovery, market basket analysis, collaborative filtering etc. Numerous algorithms have been proposed to mine freque nt itemsets efficiently Many approaches have been proposed in literatures with the aim to optimize these frequent itemsets mining algorithms such as minimizing the memory cost by using compression data representation \(FP-tree\and reducing search space by applying the pruning method \(i nter-node and intra-node pruning Based on these litera tures, we conclude d that there are three main approaches that were commonly discussed, namely searching strategy, space reduction method, and data representation.  Table I summarizes the approaches for both closed and maximal frequent itemsets The next subsections discussed each of these approaches A Searching strategy  Majority researchers are trying to improve the frequent pattern mining by introducing a novel search stragegy where we defined method as searching of candidates or without candidates of frequent itemsets. Various tree search strategies have been applied into the algorithms such as column enumeration, row enu meration, top-down traversal bottom-up traversal, breadth-first-search and depth-firstsearch. For instance CLOSET+ that uses hybrid tree projection automatically build tree either bottom-up tree for dense dataset or top-do wn tree for the pa Novel row enumeration has been veri fied by Mutalib  where searching frequent itemsets in very high dimensional dataset where the numbers of columns are larger than the number of rows work efficiently compared to columns enumaration. While the SmartMiner made an additional feature by introducing tail inform ation to guide the depthfirst-search \(DFS  Obviously, the depth-first-s earch is mostly applied in developing mining frequent ite msets algorithms. In breadthfirst-search, the searching was done by visiting all nodes in each level of the tree and made a new dataset scanning to count the kitemsets support. Different from the depth-firstsearch that search in depth-first order, it will check the current node k itemset\not, if the node is frequent, it will traverse to the nodeês subtree k 1 itemset\to this multiple dataset scanning by breathfirst-search, depth-first-search is more suitable in mining long patterns items  B Space reduction method  Based on our review, pruning technique is used to reduce the search space reduction where it is an important feature in frequent itemsets mining algorithm to overcome the efficiency problem. Taking the advantage of the pruning power, we could summarize that all suggested algorithms 60 


used pruning techniques to reduce the search space and the generated candidates, are also to speed up the searching itemsets. We also noticed that mo st of the algorithms use the novel pruning technique such as item_skiping in the CLOSET+, MinePattern used by Carpenter, set-enumeration pruning applied in MaxMiner and many more. Pruning is a technique used to remove unn ecessary branch from different data representation, either tree or lattice. The power of pruning is for improving th e frequent itemsets searching even though the dataset becomes complex by reducing the search space and ignoring the unnecessary itemsets C Data representation  When the dataset grows exponentially, the size of the data becomes a problem and memory cost is increasing and this will lead to another problem, which is memory size There are limited algorithms that are focusing on the problem. FPMax for example utilized the maximal frequent itemsets tree \(MFI-tree\keep track all maximal frequent itemsets. Another example is the implementation ID-pair and ID-tree in ICMiner that can accelerate the speed in the mining process. We noticed that many of these novel algorithms enhance the data representation since it gives high impact in efficiency of searching frequent itemsets. The existing algorithm nowadays are using frequent pattern tree FP-tree\ventricle TID-list, and vertical bit vectors as data repre By creatin g a ne w data compression and representation such as vertical bit-vector vertical representation, MFI-t ree \(modification of the FPtree\approach to cater the memory problem. Moreover, A-NewMoment showed the contradictory relation between time efficiency and memory usage where it uses more memory space to perform the computational to get batte r computational time. There are two key features for an efficient maximal frequent itemsets algorithm which is the pr uning technique and the representation of the data so it can perform fast com The M A FIA uses ve rtical bitm aps to compress the data representation. Each bitmap represents an itemset in the dataset.  For example, if we have an itemset of A, B}, it simply performs AND op eration on all of the bits in the bitmaps for A and B to check either itemset {A, B exist in corresponding transaction or not  There are two types of fo rmats in recording the transaction data. The first format is called horizontal data format where the items are recorded into particular transaction-id and the second format is the vertical data format where transaction-id is recorded into particular items Both data formats have their own advantages. Using vertical format, the frequent itemsets can be counted using transaction-id intersection compare to horizontal format that used complex internal data structure like candidate    Horizontal format also look s relevant if the suitable compressed structure is applied in the FP-tree, which is not used so much memory space since the itemsets have common prefix that sharing the same path. Since Pasquier  introduc ed subset lattice m o st of the propose d algorithms nowadays used tree-base structure in their algorithm implementation.  Based on our analysis, PGMiner  a pplied different a p pr oach for its com pression and representation in mining closed frequent itemsets known as PrefixGraph.  This lead to a new exploration strategy in improving the efficiency of th e algorithms and also in improving the scalability to mine the large dataset, by reducing memory usage or reduci ng computational time in mining frequent itemsets \(all it emsets, closed itemsets and maximal itemsets mmary, a good representation structure and compression method ar e crucial for an efficient algorithm beside the pruning technique used V. C ONCLUSION  In this paper, we briefly described the key features of frequent item mining algorithms focusing on maximal and closed frequent itemsets.  We then identified key features into three approaches, which are searching strategy, space reduction method and data representation/compression. We believed that, these three approaches influence the design of the algorithm strategy. From our observation, all the reviewed algorithms were designed to improve the efficiency and scalability of the algorithm by using different approaches to accommodate the growth and the complexity of datasets We strongly believe that understanding the dataset characteristic also is the key in having better algorithms. In future, we plan to propose an algorithm in mining frequent itemsets following these particular approaches A CKNOWLEDGMENT  The authors would like to thank to Research Management Institute, Universiti Teknologi MARA, and Malaysia for the research grant under PSI 600-RMI/DANA 5/3/PSI \(65/2013  R EFERENCES    J. T Nezhad an d M. Sadr eddini, çPTclose: A novel algorithm for generation of closed frequent itemsets from dense and sparse datasets,é in Proceedings of the World Congress on Engineering 2007, vol. 1  B. Goethals, çSurvey on frequent pattern mining,é Univ. of Helsinki 2003  J. Han, H. Cheng D. Xin, and X Yan, çFrequent pattern mining current status and future directions,é Data Mining and Knowledge Discovery, vol. 15, no 1, pp. 55Ö86, 2007  W   W a ng and J. Yang, çM ining high-dimensional data,é in Data Mining and Knowledge Discovery Handbook Springer, 2005, pp 793Ö799  R. Patel Ni m i sha and S Me hta, çA Survey on Mining Algorithms 2013  X. Deng, B W a ng, H. W e i and M. Chen, çThe Key Data Mining Models for High Dimensional Data,é in Proceedings of the 2012 International Conference on Communication, Electronics and Automation Engineering 2013, pp. 321Ö327  M. J. Zaki, ç1 Mining Clo sed Maximal Frequent Itemsets,é NSF CAREER Award IIS-0092978, DOE Early Career Award DE-FG0202ER25538, NSF gr ant EIA-0103708  J. Fan, F. Han, an d H. Li u, çChallenges of Big Data Analysis,é arXiv preprint ar Xiv:1308.1479, 2013  D. Laney 3D data m a nagem ent: C ontrolling data v o l u m e velocity  and variety,é META Group Research Note, vol. 6, 2001 61 


 M Verl eysen D   Francois, G   Si m o n, and V  We rtz  O n the effects  of dimensionality on data analysis with neural networks,é in Artificial Neural Nets Problem solving methods Springer, 2003, pp. 105Ö112   P D Shenoy K Sr inivasa a nd A O. T h o m as, çCo m p ress and M i ne An Efficient Graph Based Algorithm to Generate Frequent Itemsets 2004  N. Pasquier, Y. B a stide, R Taouil, and L. Lakhal, çEfficient mining of association rules using closed itemset lattices,é Information systems, vol. 24, no 1, pp. 25Ö46, 1999  F. Hadzic  H Ta n, and T. S Dillo n M ining m a xim a l  and closed frequent subtrees,é in Mining of Data with Complex Structures Springer, 2010, pp. 191Ö199   R M a r ghoubi A. Boulm akoul and K. Zeitouni The Use of the Galois lattice for the extraction and the visualization of the spatial association rules,é in Signal Processing and Information Technology 2006 IEEE International Symposium on, 2006, pp. 606Ö611  D.-I. Lin and Z M  Kede m   P incer-s earch: an efficient algorith m for discovering the maximum frequent set,é Knowledge and Data Engineering, IEEE Transactions on, vol 14, no. 3, pp. 553Ö566 2002  R. J. Bayardo Jr Efficiently mining long patterns from databases in ACM Sigmod Record, 1998, vol 27, no. 2, pp. 85Ö93   D. Bur dick, M Calim li m  and J. Gehrke, çMAFIA: A maximal frequent itemset algorithm for transactional databases,é in Data Engineering, 2001. Proceedings. 17t h International Conference on 2001, pp. 443Ö452  Q Zou, W. W   Chu, and B. Lu, çSmartM iner: A depth first algorithm guided by tail information for mining maximal frequent itemsets,é in Data Mining, 2002. ICDM 2003. Proceedings. 2002 IEEE International Conference on 2002, pp. 570Ö577   D. H V. V. R. P.C S.Nagendra setty, çImproved Maximal Length Frequent Item Set Mining,é 2012  K. Gouda and M. J. Zaki Genmax: An efficient algorithm for mining maximal frequent itemsets,é Data Mining and Knowledge Discovery, vol. 11, no. 3, pp. 223Ö242, 2005   T. Hu S. Y. Sung H Xiong, and Q. Fu, çDiscovery of maximum length frequent itemsets,é Information Sciences vol. 178, no. 1, pp 69Ö87, 2008   A. J. Lee, C  S  W a ng W  Y Weng, Y.-A. Chen, and H.-W. Wu An efficient algorithm for mining closed inter-transaction itemsets Data \\& Knowledge Engineering, vol. 66 no. 1, pp. 68Ö91, 2008   S. Pr abha, S. Shan m ugapr iy a and K. Duraiswamy, çA Survey on Closed Frequent Pattern Mining  M. J  Zaki and C. Hsiao, çCha rm  a n efficient algorith m for closed association rule mining,é 1999  J. Pei, J Han, an d R Mao, çCLOSET: An Efficient Algorithm for Mining Frequent Closed Itemsets.,é in ACM SIGMOD workshop on research issues in data mining and k nowledge discovery, 2000, vol. 4 no. 2, pp. 21Ö30  J. W a ng, J Han, and J. Pei, çCloset+: Searching for the best strategies for mining frequent closed itemsets,é in Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining, 2003, pp. 236Ö245   F. Pan G. Cong A K. Tung, J. Yang, and M. J. Zaki, çCarpenter Finding closed patterns in long biological datasets,é in Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining 2003, pp. 637Ö642  F. Pan, A Tung G. Cong, and X. Xu Cobbler: Combining column and row enumeration for closed pattern discovery,é in Scientific and Statistical Database Management, 2004. Proceedings. 16th International Conference on 2004, pp. 21Ö30  J. W a ng, J Han, Y. Lu and P. Tzvetkov, çTFP: An efficient algorithm for mining top-k frequent closed itemsets,é Knowledge and Data Engineering, IEEE Tr ansactions on, vol. 17, no 5, pp. 652Ö663 2005   H Liu, J. Han, D. Xin, and Z Shao, çMining fr equent patter ns fr o m  very high dimensional data: A top-down row enumeration approach in Proceeding of the 2006 SIAM international conference on data mining \(SDMê06\, Bethesda, MD, 2006, pp. 280Ö291  H. Moonesinghe, S Fodeh, and P.-N. Tan, çFrequent closed itemset mining using prefix graphs with an efficient flow-based pruning strategy,é in Data Mining, 2006 ICDMê06. Sixth International Conference on, 2006, pp. 426Ö435   H  L i u X  W a ng, J He J  Han D. Xin and Z   Shao T opdown  mining of frequent closed patterns from very high dimensional data Information Sciences, vol. 179 no. 7, pp. 899Ö924, 2009  B. Nair and A. K  Tripathy A ccel erating Closed Fre quent Ite m set Mining by Elimination of Null Tr ansactions,é Journal of Emerging Trends in Computing and Information Sciences, vol. 2, no. 7, pp 317Ö324, 2011  R. Agrawal and R. Srikant Fast algorithms for mining association rules,é in Proc. 20th int. conf very large data bases, VLDB, 1994 vol. 1215, pp. 487Ö499  M K Sohrabi and A. A Barforoush, çE fficient colossal pattern mining in high dimensional datasets,é Knowledge-Based Systems vol. 33, pp. 41Ö52, 2012  D. Burdick, M. Calim li m  J Flannick, J. Gehrke, and T. Yiu, çMafia A maximal frequent itemset algorithm,é Knowledge and Data Engineering, IEEE Transactions on, vol 17, no. 11, pp. 1490Ö1504 2005  M. J  Zaki and K. Gouda Fast vertical mining using diffsets,é in Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining, 2003, pp. 326Ö335   Y M M a o, Z   G Chen and L  X L i u Fast M i ning of Cl osed  Frequent Itemsets in Data Streams,é Applied Mechanics and Materials, vol. 263 pp. 231Ö240, 2013  Y. Chi H Wang S. Y. Philip, and R. R Muntz C atch the m o m e nt  maintaining closed frequent itemsets over a data stream sliding window,é Knowledge and Information Systems, vol. 10, no. 3, pp 265Ö294, 2006  S. Mutalib S. Ab dul-Rah m an and A. Mohamed, çTowards Mining Frequent Patterns in Genome Wide Association,é in Computational Science and Engineering \(CSE\2013 IEEE 16th International Conference on, 2013, pp. 1096Ö1100   62 


VI Tanbeer, S. K., Ahmed, C. F., Jeong, B.-S., & Lee, Y.-K, \215Sliding window-based frequent pattern mining over data streams,\216 Information Sciences, 179\(22\, pp. 3843\2053865, 2009 9 Chang, J., & Lee, W. S, \215Finding recently frequent itemsets adaptively over online transactional data streams,\216 Information Systems, 31\(8\, pp. 849\205869, 2006 4 Agrawal, R., & Srikant, R, \215Fast algorithms for mining association rules,\216 In Proc. VLDB int. conf. very large databases \(pp. 487\205 499\, 1994 3 Tsai, P. S. M, \215Mining frequent itemsets in data streams using the weighted sliding window model,\216 Expert Systems with Applications, 36\(9\, pp. 11617\20511625, 2009  minimum change threshold Y. Chi, H. Wang, P. S. Yu and R. R. Muntz. Catch the moment maintaining closed frequent itemsets over a data stream sliding window. In KAIS, 10\(3\: pp. 265-294, 2006 6 V. kumar, S. satapathy, \215A review on algorithms for mining frequent itemsets over data stream,\216 in ijarcsse V3 I4, 2013 8 CONCLUSION AND FUTURE WORK  Considering the continuousness of a data stream, the traditional methods or techniques for finding frequent itemsets in conventional data mining methodology may not be valid in a data stream. This is because we cannot consider whole data and must identify when a data becomes obsolete or invalid As the old information of a data stream may be no longer useful or possibly invalid at present.  In order to support various requirements of mining data stream, the mining window or the interesting recent range of a data stream needs not to be defined static but must be flexible. Based on this range, a data mining method can be able to identify when a transactions becomes stale or needs to be disregarded  In this paper, we have investigated the problem of mining frequent itemset over data stream using flexible size sliding window model and proposed a new algorithm for this problem. The size of sliding window is adaptively adjusted based on the amount of observed concept change in the underlying properties of incoming data stream. The size of window enlarges or increase when there is no significant amount of change observed. While the window size reduced or decrease when there is considerable amount of concept change or significant change in set of frequent itemsets occurs Based on the value of given by user, the size of window is being controlled. After every pane insertion the set of frequent itemsets are updated and value of concept change is calculated. If the value exceeds the given minimum change threshold the window gets smaller by deleting all the obsolete information before a point defined called checkmark  Experimental results shows that our algorithm tracks the concept change efficiently while mining data stream and is more adaptive to recent frequent itemsets than fixed size sliding window models or time fading window models. For the future work, we are trying to enhance the performance by using fuzzy sets for minimum change threshold value so that the values like low, medium, high and very high instead of certain value between ranges of 0 to 1 R EFERENCES  1                    H. Li, S. Lee, and M. Shan, \215An Efficient Algorithm for Mining Frequent Itemsets over the Entire History of Data Streams\216, In Proc. of First International Workshop on Knowledge Discovery in Data Streams, 2004  F. Nori, M. Deypir, M. Sadreddini, \215A sliding window based algorithm for frequent closed itemset mining over data streams\216 journal of system and software, 2012  Zaki, M. \(2000\. Scalable algorithms for association mining. IEEE Transactions on Knowledge and Data Engineering, 12\(3\, 372\205 390  Woo H. J., & Lee, W. S. \(2009\. estMax: Tracing maximal frequent item sets instantly over online transactional data streams IEEE Transactions on Knowledge and Data Engineering, 21\(10 1418\2051431  Mozafari B, Thakkar H, Zaniolo C, \215Verifying and mining patterns from large windows over data streams,\216 In Proc. Int. conf. ICDE pp. 179-188, 2008  Koh, J.- L., & Lin, C.- Y, \215Concept shift detection for frequent itemsets from sliding window over data streams\216, lecture notes in computer science: Database systems for advanced applications \(pp 334\205348\ DASFAA Int. Workshops, Springer-Verlag.2009  Han, J., Cheng, H., Xin, D., & Yan, X. Frequent pattern mining Current status and future directions. Data Mining and Knowledge Discovery, 15\(1\, pp.  55\20586, 2007 5 C. Giannella, J. Han, J. Pei, X. Yan, and P. S. Yu. Mining frequent patterns in data streams at multiple time granularities. In Kargupta et al.: Data Mining: Next Generation Challenges and Future Directions, MIT/AAAI Press, 2004 7 2014 IEEE International Advance Computing Conference IACC 510 J. H. Chang and W. S. Lee. estWin: Adaptively Monitoring the Recent Change of Frequent Itemsets over Online Data Streams. In Proc. of CIKM, 2003  J. Yu, Z. Chong, H. Lu, and A. Zhou. False Positive or False Negative: Mining Frequent Itemsets from High Speed Transactional Data Streams. In Proc. of VLDB, 2004      Aggarwal, C, \215A framework for diagnosing changes in evolving data streams,\216 In Proc. ACM SIGMOD int. conf. on management of data \(pp. 575\205586\ 2003 2 Manku, G. S., & Motwani, R. Approximate frequency counts over data streams. In Proc. VLDB int. conf. very large databases \(pp 346\205357\ 2002  


002 
                          
R. Agrawal and R. Srikant. Fast algorithms for mining association rules in large databases. In Proc. VLDB, pages 487Ö499, 1994 2 R. J. Bayardo, Jr. Efficiently mining long patterns from databases SIGMOD Rec., pages 85Ö93, 1998 3 M. Zaki, S. Parthasarathy, M. Ogihara, and W. Li. Parallel algorithms for discovery of association rules. Data Min. and Knowl. Disc., pages 343Ö373, 1997 4 J. Dean and S. Ghemawat. MapReduce: Simplified data processing on large clusters. In Proc. OSDI. USENIX Association, 2004 5 Apache hadoop. http://hadoop.apache.org/, 2013 6 Jiawei Han and Micheline Kamber. Data Mining, Concepts and Techniques. Morgan Kaufmann, 2001 7 M. Zaharia, M. Chowdhury, T. Das, A. Dave, J. Ma, M. McCauley M. Franklin, S. Shenker, and I. Stoica. Resilient distributed datasets A fault-tolerant abstraction for in-memory cluster computing Technical Report UCB/EECS-2011-82, EECS Department University of California, Berkeley, Jul 2011 8 M. Zaharia, M. Chowdhury, M. J. Franklin, S. Shenker, and I. Stoica Spark: Cluster Computing with Working Sets. In HotCloud, 2010 9 J. Han, J. Pei, and Y. Yin: Mining Frequent Patterns without Candidate Generation. In: Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data, 29\(2\:1-12, 2000 10 M. J. Zaki. Parallel and distributed association mining: A survey IEEE Concurrency, pages 14Ö25, 1999 11 J. Li, Y. Liu, W.-k. Liao, and A. Choudhary. Parallel data mining algorithms for association rules and clustering. In Intl. Conf. on Management of Data, 2008 12 E. Ozkural, B. Ucar, and C. Aykanat. Parallel frequent item set mining with selective item replication. IEEE Trans. Parallel Distrib Syst., pages 1632Ö1640, 2011 13 B.-H. Park and H. Kargupta. Distributed data mining: Algorithms systems, and applications. 2002 14 L. Zeng, L. Li, L. Duan, K. Lu, Z. Shi, M. Wang, W. Wu, and P. Luo Distributed data mining: a survey. Information Technology and Management, pages 403Ö409, 2012 15 Li L. & Zhang M. \(2011\. The Strategy of Mining Association Rule Based on Cloud Computing. Proceeding of the 2011 International Conference on Business Computing and Global Informatization BCGIN è11\. Washington, DC, USA, IEEE: 475- 478 16 Li N., Zeng L., He Q. & Shi Z. \(2012\. Parallel Implementation of Apriori Algorithm Based on MapReduce. Proc. of the 13th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel & Distributed Computing SNPD è12\. Kyoto, IEEE: 236 Ö 241 17 Lin M., Lee P. & Hsueh S. \(2012\. Apriori-based Frequent Itemset Mining Algorithms on MapReduce. Proc. of the 16th International Conference on Ubiquitous Information Management and Communication \(ICUIMC è12\. New York, NY, USA, ACM: Article No. 76 18 Yang X.Y., Liu Z. & Fu Y. \(2010\. MapReduce as a Programming Model for Association Rules Algorithm on Hadoop. Proc. of the 3rd International Conference on Information Sciences and Interaction Sciences \(ICIS è10\. Chengdu, China, IEEE: 99 Ö 102 19 S. Hammoud. MapReduce Network Enabled Algorithms for Classification Based on Association Rules. Thesis, 2011 20 Synthetic Data Generation Code for Associations and Sequential Patterns. Intelligent Information Systems, IBM Almaden Research Center http://www.almaden.ibm.com/software/quest/Resources/index.shtml 21 C.L. Blake and C.J. Merz. UCI Repository of Machine Learning Databases. Dept. of Information and Computer Science, University of California at Irvine, CA, USA. 1998 http://www.ics.uci.edu/mlearn/MLRepository.html 22 HadoopApriori. https://github.com/solitaryreaper/HadoopApriori 2 3 H.V. Nguyen, E. Muller, K. Bohm. 4S: Scalable Subspace Search Schema Overcoming Traditional Apriori Processing. 2013 IEEE International Conference on Big Data. 2013 24 S. Moens, E. Aksehirli and Goethals. Frequent Itemset Mining for Big Data. University Antwerpen, Belgium. 2013 IEEE International Conference on Big Data. 2013 25 Y. Bu et al . HaLoop: E cient iterative data processing on large clusters. Proceedings of the VLDB Endowment, 3\(1-2\:285Ö296 2010 26 Frequent itemset mining dataset repository. http://fimi.us.ac.be/data 2004   
002 
Our experiments show that YAFIM is about 18 faster than Apriori algorithms implemented in MapReduce framework Furthermore, we can achieve a better performance in both sizeup and speedup for different datasets. In addition, we also evaluated YAFIM for medical application and revealed that YAFIM outperforms MRApriori about 25 speedup  A CKNOWLEDGMENT  This work is funded in part by China NSF Grants \(No 61223003\, and the USA Intel Labs University Research Program R EFERENCES  1 
002 
1671 



Web Services Composition for Distributed Data Mining Ali Shaikh Ali Omer F Rana and Ian J Taylor School of Computer Science and Welsh e-Science Centre Cardiff University UK  Ali.Shaikhali,Omer.F.Rana,Ian.J.Taylor  cs.cardiff.ac.uk Abstract A Web Services-based toolkit for supporting distributed data mining is presented A workîow engine is provided within the toolkit to enable a user to compose Web Services to implement particular point solutions Three types of Web Services are provided to impl ement data mining functions 
1 classiìers 2 clustering algorithms and 3 association rules Additional capability is made available through GNUPlot and Mathematica to enable visualisation of the output Data sets may be read from the local lespace or streamed from a remote location provided the algorithm being used has support for streaming A study is presented to illustrate the use of the toolkit 1 Introduction Data is currently being collected and accumulated at a dramatic pace in a number of different scientiìc areas This data accumulation can vary from the long time archiving of the entire collection of raw data to the persistent storage 
of summary statistics only The type of data being analysed can also vary in content from text-based data streams to numeric data and increasingly image-based data managed in distributed le systems or structured databases It is therefore becoming necessary to provide effective analysis mechanisms for such data There is often a distinction made between machine learning algorithms/statistical analysis and data mining the former is seen as the set of theories and computational methods needed to deal with a variety of different analysis problems whereas the latter is seen as a means to encode such algorithms in a form that can be efìciently used in real world applications Often data mining applications and toolkits contain a variety of machine 
learning algorithms that can be used alongside a number of other components such as those needed to sample a data set read/write output from/to data sources and visualise the outcome of analysis algorithms in some meaningful way Visualisation is also often seen as a key component within many data mining applications as the results of data mining applications/toolkits are often used by individuals not fully conversant with the details of the algorithm deployed for analysis Further users of results of data mining are generally domain experts and not algorithm experts 
and often some albeit limited support is needed to allow such a user to chose an algorithm The basic problem addressed by the data mining process is one of mapping low-level data which are typically too voluminous to understand into other forms that might be more compact for example a short report more abstract for example a descriptive approximation or model of the process that generated the data or more useful for example a predictive model for estimating the value of future cases At the core of the process is the application of speciìc data-mining methods for pattern discovery and extraction This process is often structured from interactive and 
iterative stages within a discovery pipeline/workîow At these different stages of the discovery pipeline a user needs to access integrate and analyse data from disparate sources to use data patterns and models generated through intermediate stages and feed these models to further stages in the pipeline Consider for instance a breast-cancer data set acquired by a cancer research centre where a physician carries out a series of experiments on breast cancer cases and records the results in a database The data now needs to be analysed to discover knowledge of the possible causes or trends of breast cancer One approach is to use a classi 
cation algorithm However applying an appropriate classiìcation algorithm requires some preliminary understanding of the approach used in the classiìcation algorithm and in the instance where the size of data is large for processing of the data to be carried out on computational resources suitable to handle the large volume of data The availability of Web Service standards such as WSDL SOAP 10 and t hei r adopt i o n b y a number of communities including the Grid community as part of the Web Services Resource Framework WSRF indicates that development of a data mining toolkit based on Web Ser 
vices is likely to be useful to a signiìcant user community Providing data mining Web Services also enables these to be integrated with other third party services allowing data mining algorithms to be embedded within existing applications We present a data mining toolkit that makes use Proceedings of  the 2005 International Conference on Parallel Processing Workshops \(ICPPWê05 1530-2016/05 $20.00 © 2005 IEEE 


of Web Services composition with the widely deployed Triana workîow environment 3 Mos t o f t he W e b S er vices are derived from the WEKA data mining library of algorithm 4  a nd cont ai n a pproxi mat el y 7 5 d i f ferent al gorithms primarily classiìers clustering algorithms and association rules Additional capability is provided to support attribute search and selection within a numeric data set and 20 different approaches are provided to achieve this such as a genetic search operator Visualisation capability is provided by wrapping the GNUPlot software additional capability is supported through the deployment of a Mathematica Web Service developed using the MathLink software Other visualisation routines include a decision tree and a cluster visualiser 2 Related Work Data mining and knowledge discovery can best be summarized as an infrastructure that uses a selection of different algorithms and statistical methods to nd interesting and novel patterns within large databases In literature generally three generations of knowledge discovery tools are reported The rst-generation of tools typically provide users with a single data mining algorithm operating on data stored in a local le Examples include the use of classiìcation algorithms such as C4.5 clustering algorithms such as Kmeans and other single hierarchical clustering and association rule based algorithms Such tools were provided primarily as standalone executables generally obtaining input from the command line or via a conìguration le They soon proved inadequate and inconvenient for more complex discovery tasks and were often limited by the scope of the single algorithm that was provided Such approaches are still popular in scientiìc computing where a particular clustering algorithm is tuned to execute on a parallel machine to be applied on a particular family of data sets Secondgeneration tools combined a collection of different algorithms for data mining under a common framework and enabled users to provide input from various data sources An example of such tools is WEKA a w i del y u s e d t ool ki t that contains a large collection of state-of-the-art machine learning algorithms written in Java WEKA contains tools for classiìcation regression cl ustering association rules visualization and data pre-processing However such tools typically operate under the closed world data mining model which assumes that the data and the data mining process are taking place on the same machine Subsequently third generation tools started to address the limitations that are imposed by the closed-world model An example of a thirdgeneration tool is Grid WEKA 11  e ssen tially a m o d i cation to the WEKA toolkit that enables the use of multiple computational resources when performing data analysis In Grid WEKA execution of the following tasks can be distributed across several computers contained within an adhoc Grid labelling of test data using a previously built classiìer testing a previously built classiìer on a dataset building a classiìer on a remote machine and cross-validation Another example of a third-generation tool is Discovery Net 8 Dis co v e ry Net pro vides a s ervice-oriented computing model for knowledge discovery allowing users to connect to and use data analysis software as well as data sources that are made available online by third parties Discovery Net however is based on a much wider vision and aims to support the complete scientiìc process from data capture to visualization Discovery Net however is not meant to be used as a toolkit for direct use by a scientist instead the developers of Discovery Net require the scientist to work alongside them to manage scientiìc discovery A related recent project is GridMiner 7 which als o pro vides a c ollection of services to support data mining GridMiner provides specialist support for connecting to structured databases using the OGSA-DAI libraries al t hough t h e number of analysis algorithms supported are very limited A recently established Special Interest Group on eScience Data Mining 12 i s d e v el opi ng a s et of cri t e ri a f or al l o wi ng us e o f G ri denabled data mining services essentially services which are published in the UK eScience registry and services that can be executed over resources provided by the UK eScience centres Our Web Services tool kit shares common themes with GridMiner and Discovery Net in that it allows a variety of services to be combined to achieve a particular data mining task Similar to these projects we also utilize a workîow engine to achieve the composition of services A significant difference from Discovery Net is that our toolkit is intended for use by an end user thereby allowing the user to integrate services provided in the toolkit with local service available to the user or obtained from third parties key difference with GridMiner is the much wider number of algorithms supported in our toolkit along with specialist visualization capability provided through GNUPlot and Mathematica-based Web Services Use of the Triana workîow engine 3 a lso allo ws u s to u tilize th e Sig n a l P r o cessing toolbox available with algorithms such as Fast Fourier Transform and various spectral analysis algorithms and the ability to export the workîow graph in XML the GriPhyN DAX standard is also supported Additional support is provided to enable service hierarchy i.e a single service made up of a number of others and made available as a single interface and through a design pattern library consisting of structural and behavioural patterns and operators 9 t h a t allo w m an ip u l atio n o f t h e w o rk o w  Proceedings of  the 2005 International Conference on Parallel Processing Workshops \(ICPPWê05 1530-2016/05 $20.00 © 2005 IEEE 


3 Requirements of a Distributed Knowledge Discovery Framework We deìne a Distributed Knowledge Discovery Framework DKDF as A computational system that provides a complete and convenient set of high level tools for knowledge discovery The DKDF should allow users to deìne and modify problems choose solution strategies interact with and manage appropriate distributed resources visualize and analyze results and record and coordinate extended knowledge discovery tasks Furthermore interaction with the user needs to be in a way that is intuitive to the way a user solves problems and must not necessitate the understanding of a particular operating system programming language or network protocol We identify a list of requirements that inîuenced our framework design and divide these into two broad categories Category 1 Knowledge Discovery Speciìc Requirements  Handling different types of data As data sources can vary we may expect that the framework should offer a set of tools to manipulate different data types For instance the framework should have a tool for converting data formats i.e Comma Separated Values CSV to Attribute Relation File Format ARFF and vice versa  Choosing a data mining algorithm A variety of algorithms exist from machine l earning algorithms that operate on data such as neural networks to statistical algorithms such as regression Although an extremely challenging task we should require the toolkit to provide some support in algorithm choice based on the characteristics of the problem being investigated  Expression of various kinds of data mining results the framework should enable the discovered knowledge to be analysed from different perspectives For instance the framework should enable expressing the result from a classiìcation algorithm in the form of a decision tree as well as a textual summary  Mining information from different sources of data the framework should enable data mining from different sources of formatted or unformatted data supporting a diverse set of data semantics For example the framework should allow the streaming of data from a remote machine along with the capability to process the data locally Data streaming is particularly important when large volumes of data cannot be easily migrated to a remote location  Utilise users experience the wide range of data mining tools introduces a new challenge for selecting the right tool for solving a speciìc problem The framework should assist the users to make use of previous experience to select the appropriate tool  Testing the discovered knowledge the discovered knowledge may not always be accurate Therefore the framework should have a set of tools to test the discovered knowledge with real data and produce a result for the accuracy of the knowledge The requirements identiìed above are generally also valid for data mining tools that do not make use of Grid resources Category 2 Distributed Framework Speciìc Requirements  Problem-oriented the framework should allow specialists to concentrate on their discipline without having to become experts in computer science issues such as networks or Grid computing  Collaborative an increasing number of science and engineering projects are performed in collaborative mode with physically distributed participants It is therefore necessary to support interaction between such participants in a seamless way  Visualisation the use of graphics and visuals can enhance the usability of the framework for example through animated tables and directed graphs to visualize the state of the application  Fault Tolerant the use of distributed resources can provide additional capability The framework must therefore include the ability to complete the task if a fault occurs by moving the job to another resource Such job migration should make use of Grid infrastructure where available  Service Monitoring the framework should allow users to monitor the progress of their jobs as they are executed on distributed resources Such feedback is dependent however on the availability of monitoring tools on the resources being used 3.1 Workîow-based knowledge discovery Although workîow plays an important role in data mining as speciìed in the stages below there still needs to be support provided for user interaction between stages as it is often necessary for a user to make decisions during the process depending on partial results of each stage The workîow can involve signiìcant iteration and can contain loops Generally the following steps are involved 1 The rst stage involves the selection of a data set The data set may be in a variety of different formats such Proceedings of  the 2005 International Conference on Parallel Processing Workshops \(ICPPWê05 1530-2016/05 $20.00 © 2005 IEEE 


as Comma Separated File Format CSV Attribute Relation File Format ARFF etc and often converters may be necessary to convert to a format required by the data mining algorithm A library of such converters may be necessary 2 In the second stage a data mining algorithm is selected The selection of an algorithm depends on the nature of the data set and the required knowledge to be extracted from the data set The selection process could be automated through the use of pre-deìned rules It could also be based on the past experience of a user This stage can be skipped if the user knows which algorithm to select This is often a difìcult decision to make and generally little support is provided in existing toolkits for this The user is often presented with available algorithms and has to make a choice manually 3 The third stage involves the selection of the resources on which the data mining algorithm needs to be executed The choice may be automated by the underlying resource management system if multiple instances of the same algorithm can be found or the user needs to manually request access to a particular algorithm on a speciìc resource 4 The data mining algorithm is now executed and often the data set is also migrated to the remote resource 5 The generated model from the data mining algorithm is now presented textually or graphically to the user The model may now be veriìed through the use of a test set 4 Data Mining Toolkit Our data mining toolkit aims to address the requirements outlined in Section 3 above It consists of a set of data mining services exposed via an Application Programming Interface API a set of tools to interact with these services and a workîow system that can be used to assemble these services and tools to build a point solution for a problem The workîow system that we use to assemble the components is Triana an open source problem solving environment developed as part of the European GridLab project Triana has an extensive user base in the astrophysics community See 3 f or more details about T r iana Figure 1 illus trates the composition tool provided for the data mining workspace On the left hand side the user is provided with a collection of pre-deìned folders containing tools grouped according to functions The tools in the Common folder for example performs tasks such as inputting and viewing strings On the right hand side the user is provided with workspace for composing applications by dragging and dropping the tools from the toolboxes Tasks are the components that can be graphically connected to create a particular data ow algorithm The connection between tasks is made by dragging a cable from the output node right-hand side of the sending task to the input node left-hand side of the receiving task Once a network has been created it can be executed A Web Service is imported to the workspace by providing its WSDL interface Once the interface is provided Triana creates a tool for each operation provided by the service These tools are used to invoke the service operations and are similar to the pre-deìned tools but have a different colour in the workspace 4.1 Data Mining Services Several data mining services are implemented to support the data mining process The following is a description of these Web Services Classiìer Web Services Each classiìcation algorithm available in the WEKA toolkit was converted into a Web Service For example a J48 Web Service that implements a decision tree classiìer based on the C4.5 algorithm The J48 service has two key options 1 classify and 2 classify graph The classify operation is used to apply the J48 algorithm to a data set speciìed by the user The data set must be in the ARFF format which essentially involves a description of a list of data instances sharing a set of attributes The result of invoking the classify operation is a textual output specifying the classiìcation decision tree The classify graph option is similar to the classify option but the result is a graphical representation of the decision tree created by the J48 algorithm The graph can then be plotted using an appropriate vis ualizer a service to achieve this is also provided This is a useful approach if only a single algorithm is to be used such as one used extensively by a scientist for a given type of data The drawback of this approach however is that as there are thousands of classiìcation algorithms it is now necessary to implement a Web Service for each algorithm This is a time consuming process and requires the scientist to have some understanding of Web Services Therefore we have opted to implement a general Classiìer Web Service to act as a wrapper for a complete set of classiìers available in WEKA The general Classiìer Web Service has the following operations 1 getClassiìers 2 getOptions and 3 ClassifyInstance In order to use the Web Service the following operations need to be performed by a user the user needs rst to obtain the list of the available classiìers by invoking the getClassiìer operation The Web Service will return a list of available classiìers known to it Once a classiìer has been selected the user should obtain the properties that need to be speciìed for that classiìer This is achieved by using the getOption operation The Proceedings of  the 2005 International Conference on Parallel Processing Workshops \(ICPPWê05 1530-2016/05 $20.00 © 2005 IEEE 


Figure 1 Data mining workîow Web Service will return a list of the required and optional properties that the user should pass to the Web Service The last step will involve invoking the classify operation on a speciìed data set instance The classify operation has 4 inputs Classiìer name options data set in ARFF format and attribute name that the classiìer should classify the data on Clustering Web Services Similar to classiìcation algorithms Web Services have been developed and deployed for a variety of different clustering a lgorithms For example a Web Service was implemented for the Cobweb Clustering algorithm The Web Service has the following operations 1 cluster 2 getCobwebGraph The cluster operation is used to apply the algorithm on a speciìed data le The data set must be in the ARFF format The result of invocation is a textual output describing the clustering results The getCobwebGraph operation is similar to the equivalent operation for the clustering algorithm but the result is a tree created by the Cobweb algorithm The graph can be then plotted using an appropriate tree plotter 4.2 Mathematical and Plotting Web Services A set of Web Services that graph the output are also provided An example of these services is the Mathematica Web Service The latter is an interface implementation for Mathematica 2 The m ost i mportant operation i n t his W eb Service is the plot3D operation This operation is used to Figure 2 The Components of the Data Mining Toolbox plot data points sent as a CSV le in three dimension and return the plotted graph as an image le PNG format to the user 4.3 Data Manipulation Tools In order to create a workîow and use the developed Web Services additional support for data mining has been implemented for data handling The toolbox consists of three types of tools see Figure 2 Proceedings of  the 2005 International Conference on Parallel Processing Workshops \(ICPPWê05 1530-2016/05 $20.00 © 2005 IEEE 


 Data set manipulation tools These tools are used to convert data sets from one format to another and include a tool for loading a dataset into Triana and sending it to a Web Service tool to convert CSV le into ARFF format for example this conversion process is particularly useful for using data sets obtained from commercial software such as MS-Excel  Processing tools These tools are used to process data generated as output from a Web Service The processing tools include a tool to visualize the classiìers list coming from the Classiìer Web Service as a tree according to their types a tool to assist the user to select the options list and a tool to visualize the attributes embedded in a dataset  Visualization tools These tools implement various visualization services based on the output generated by a particular Web Service This visualization tools include Tree plotter Image Plotter and Cluster Visualize Figure 2 describes the overall architecture of the toolbox The key component in this is the Triana workîow engine and composition environment which interacts with a number of third party libraries and Services Libraries include the existing set of tools available in Triana such as signal and image processing algorithms e.g a Fast Fourier Transform Additional tools being provided into the data management library a set of visualisation tools and a collection of algorithms obtained from WEKA 4.4 Invoking a Web Service within the Triana For demonstration purposes we use the general Classiìer Web Service as our working example The other Web Services could be invoked similarly The stages of invoking the Classiìer Web Service in Triana is illustrated Figure 1 and involve the following 1 A user rst selects theçgetClassiìer operation This allows the selection of a number of different classiìcation algorithms supported by the Web Service The getClassiìer operation is connected with a ClassiìerSelector tool The latter is used to display the classiìcation algorithms in the workplace to allow the user to select an algorithm 2 Once a classiìcation algorithm has been selected the user now needs to know the parameters that need to be passed to this algorithm These are generally run time parameters associated with the algorithm For instance in the case of a neural network backpropagation algorithm such run-time options include the number of neurons in the hidden layer the momentum and the learning rate As each algorithm has different parameters the user is required to invoke the getOptions operation and pass the selected algorithm in the input parameter of this operation The operation returns a list of parameters that can be viewed using the OptionSelector tool 3 The ClassifyInstance is the main classiìcation operation The operation has four inputs dataset classiìer name classiìer parameters and attribute name For the rst input we use the local dataset tool to select a local dataset stored on the local machine The tool is connected with the rst input of the ClassifyInstance operation For the second and the third inputs we pass the selected classiìcation algorithm obtained from step 1 and the parameters obtained from step 2 For the fourth input we use the attributeSelector tool to select an attribute from the dataset The selected attribute is passed to the fourth input 4 Finally the last stage the treeViewer in Figure1 displays the output to the user Here the user is presented with the option of either graphing the output in a decision tree or generating the output in a textual form 4.5 Remote Execution A key capability is remote execution of data mining Web Services Generally the provider of the particular classiìer or clustering service is also expected to manage the deployment of the service The Web Service needs to be made available by publishing the WSDL document corresponding to the service using an Apache/Axis Web server for instance Interaction between the workîow engine and each Web Service instance is supported through pre-deìned SOAP messages If a user positions the cursor over a particular Web Service placed on the composition area a URL specifying the location of the WSDL document can be seen along with the data types that are necessary to invoke the particular Web Service It was discovered that repeated invocations of a particular Web Service often resulted in a signiìcant performance penalty For instance when the J48 Web Service was invoked a number of times an instance of the service was created as an object for each invocation if an object already existed this had to be re-built from its serialised state on disk On completion of the invocation the state of the object was recorded it was serialised and stored to disk Each subsequent call required this set of operations to be re-executed Although most data mining services only require a single invocation of a data analysis algorithm to which data set is then transferred if an interactive session was expected this performance penalty was a severe limitation To overcome this performance penalty a harness Proceedings of  the 2005 International Conference on Parallel Processing Workshops \(ICPPWê05 1530-2016/05 $20.00 © 2005 IEEE 


was implemented that maintain ed an algorithm instance object in memory thereby preventing the Web Services infrastructure from serialising the obj ect at the completion of each invocation improvement in performance 4.6 Availability The data mining Web Services are hosted at the Welsh eScience Centre Information on how to invoke the services are available at 1 The T r i ana t ool ki t can be do wnl oaded under the GNU Public License To use the toolkit the Triana workîow engine needs to be downloaded and installed Once installed the data mining toolkit can then be installed as a folder within Triana and can be downloaded from 3 Installation instructions are also provided A user can also add additional Web Services to the data mining toolbox Access to the UDDI registry for inquiry is available at http://agents-comsc.grid.cf.ac.uk:8334/juddi/inquiry 5 Case Study To demonstrate the use of the toolkit a case study is presented in this section Precisely we use the general classiìer Web Service to classify a data set The case study also shows how the various data mining tools can be used in conjunction with the classiìer Web Service for processing data and visualising the results 5.1 Environment Overview The Classiìer Web Service is deployed on a Windows platform The processor is Pentium 4 memory is 1 GB and network bandwidth is 1 Gb/s We use Tomcat 5.0 with Axis 1.2 for hosting the Web Service The data used in the case study is obtained from the UCI Machine Learning Repository The datas et contains information about a number of different breast cancer cases with patient data being anonymised It includes 201 instances of one class and 85 instances of another class The instances are described by 9 attributes some of which are linear and others nominal Information about the attributes and the instances in the breast cancer dataset is provided in Figure 3 The dataset is already in the ARFF le format Therefore we do not need to use any tool to convert the data format the Classiìer Web Service requires a dataset in the ARFF format 5.2 Extracting knowledge from the dataset In order to use the Classifer Web Service we rst need to obtain the available classiìers that the Web Service supports and the options for the sel ected classiìcation algorithm The supported classiìers algorithms are obtained by Num Instances 286 Num Attributes 10 Num Continuous 0 Int 0  Real 0 Num Discrete 10 Missing values 9  0.3 name type enum ints real missing distinct 1 age Enum 100 0 0 0  0 6  2 2 menopause Enum 100 0 0 0  0 3  1 3 tumor-size Enum 100 0 0 0  0 11  4 4 inv-nodes Enum 100 0 0 0  0 7  2 5 node-caps Enum 97 0 0 8  3 2  1 6 deg-malig Enum 100 0 0 0  0 3  1 7 breast Enum 100 0 0 0  0 2  1 8 breast-quad Enum 100 0 0 1  0 5  2 9 irradiat Enum 100 0 0 0  0 2  1 10 Class Enum 100 0 0 0  0 2  1 Figure 3 Information about the Breast cancer data Figure 4 Visualising the C4.5 decision tree for the beast-cancer data set invoking the getClassiìers operation For our case study we select the J48 classiìer The options that the J48 requires are obtained by invoking the getOptions operation Once the classiìer algorithm and the options have been identiìed we can invoke the classifyInstance operation 5.3 Results The result of the classiìcation in this instance is viewed in a text viewer Subsequently the decision tree can be plotted using the TreeVisualizer tool Figure 4 shows the results obtained from the Classiìer Web Service In this instance the attribute node-caps has been chosen to lie at the root of the tree The attribute selection process can also be automated through the use of a genetic search service This example involved the use of four Web Services 1 a Web Service to read the data le from a URL and convert Proceedings of  the 2005 International Conference on Parallel Processing Workshops \(ICPPWê05 1530-2016/05 $20.00 © 2005 IEEE 


this into a format suitable for analysis 2 a Web Service to perform the classiìcation i.e one that implements the C4.5 classiìer  3 a Web Service to analyse the output generated from the decision tree and 4 a Web Service to visualise the output These Web Services are implemented as standalone service that can be composed using the Triana workîow tool 5.4 Conclusion A data mining toolkit is described that enables composition of Web Services from a pre-deìned toolbox Web Services have been developed from the Java-based templates provided in the WEKA library of algorithms Using a workîow based enactor data analysis can be undertaken on both local and remote data sets A variety of additional services to facilitate the entire data mining process are also supported for data translation visualisation and session management A case study is reported which demonstrate the use of the toolkit on publicly available data sets at the UCI Machine Learning repository Work is underway to include access to relational databases through the OGSA-DAI services available in GridMiner References  Federated Analys is En vironment for Heterogeneous Intelligent Mining Web site at http://users.cs.cf.ac.uk/Ali.Shaikhali/faehim Last viewed March 2005 2 M ath ematica A v ailab le at http://www.wolfram.com/products/mathematica index.html Last viewed March 2005 3 T h e T r ian a P ro b l em So lv in g E n v iro n m en t A v ailab le at http://www.trianacode.org Last viewed March 2005  The W EKA t ool ki t  Uni v ers i t y of W a i k at o Available at http://www.cs.waikato.ac.nz/ml/weka Last viewed November 2004   UC I Machine Learning R e pos itory  S ee W e b s ite at http://www.ics.uci.edu mlearn MLRepository.html  M Ant oni ol et t i and M J ackson OGSA-DAI Product Overview http://www.ogsadai.org.uk/docs/current/OGSADAI-USER-UG-PRODUCT-OVERVIEW.pdf   P  B rezan y  J  Hofer  A  M  Tjoa and A W oehrer  T owards an open service architecture for data mining on the grid Conference on Database and Expert Systems Applications  September 2003  V  C urcin M Ghanem Y  Guo M K ohler  A  R o w e J Syed and P Wendel Discovery Net Towards a Grid of Knowledge Discovery Proceedings of KDD2002 The 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining July 2002  M C  Gomes  O  F  R ana and J  C  C unha P a ttern operators for grid environments Journal of Scientiìc Programming  IOS Press August 2004  S  Graham S  S i meono v  T  B oubez D Da vis  G Daniels Y Nakamura and R Neyama Building Web Services with Java Making sense of XML SOAP WSDL and UDDI Sams Publishing  2002  R  Khous s a i n o v  X  Z uo and N K u s hmeri ck Gri d enabled Weka A Toolkit for Machine Learning on the Grid ERCIM News  No 59 October 2004  B  Mann S p eci al Int eres t G roup on eScience Data Mining See Web site at http://www.nesc.ac.uk/resources/sigs/esdmsig/index.html Proceedings of  the 2005 International Conference on Parallel Processing Workshops \(ICPPWê05 1530-2016/05 $20.00 © 2005 IEEE 


can test whether the hyperlinks on a page have been placed appropriately by analyzing significant navigational patterns \(association rules In our experiments the percentage of hyperlinks confirmed by rules was calculated by dividing the number of common items in hyperlink sets and whole ranking lists for a given page, by the number of hyperlinks on the page separately for direct, indirect and complex rules \(Fig. 8 Note that the number of hyperlinks was put in the denominator as opposed to calculations in section 7.4 where it was ranking length 48 89%87 0 20 40 60 80 100 direct indirect complex Figure 8. The average percentage of all hyperlinks confirmed by rules Proceedings of the 2005 5th International Conference on Intelligent Systems Design and  Applications \(ISDA  05 0-7695-2286-06/05 $20.00  2005 IEEE The average percentage of hyperlinks confirmed by direct rules amounted to only 48%, probably because there were too few of them. Indirect and complex rules, on the other hand, confirmed many more hyperlinks  87% and 89%, respectively, due to their larger quantity. These relatively great values that we received may have resulted from the enormous differences between the average number of hyperlinks on a page  10 and the average ranking length: 51, 177, 180 for direct, indirect and complex rules respectively. Concluding, indirect and complex rules appear to be better at assessing the usefulness of hyperlinks compared to direct rules Note that in any case at least 11% of hyperlinks were not confirmed by any rule, so they may be recommended to be removed from the content of pages 8. Conclusions and future work Complex rules combining both direct and indirect rules usually increase the length of rankings compared to those based on direct associations. This helps overcome the problem of a multitude of pages with too short rankings Fig. 5 quested ranking length \(Fig. 6 rules substantially change the order of ranking lists \(Fig. 2 and 3 greater extent only confirm hyperlinks existing on web pages compared to lists extracted from complex rules, for short and long ranking lengths \(Fig. 7 of rules, especially indirect and complex ones, can be useful for the assessment of hyperlinks Concluding, far more diverse indirect rules can significantly improve potential value of recommendation. Nevertheless, to confirm the usefulness of indirect rules for end users, some tedious tests with their participation are required Acknowledgements The authors are indebted to thank Marcin Pilarczyk for providing cleansed data about hyperlinks on WUT pages 9. References 1] Agrawal R., Imieli?ski T., Swami A.: Mining association rules between sets of items in large databases. ACM SIGMOD Int. Conference on Management of Data, ACM Press 1993 2] Boley D., Gini, M., Gross, R., Han, E.H., Hastings, K Karypis, G., Kumar, V., Mobasher, B., Moorey, J.: Document Categorization and Query Generation on the World Wide Web Using WebACE. Artificial Intelligence Review 


Wide Web Using WebACE. Artificial Intelligence Review 13 \(5-6 1999 3] Cho Y.H., Kim J.K., Kim S.H.: A personalized recommender system based on web usage mining and decision tree induction. Expert Systems with Applications 23 \(3 2002 4] Chun J., Oh J.-Y., Kwon S., Kim D.: Simulating the Effectiveness of Using Association Rules for Recommendation Systems. AsiaSim 2004. LNCS 3398, Springer Verlag 2005 5] G  ry M., Haddad M.H.: Evaluation of web usage mining approaches for user's next request prediction. WIDM 2003 ACM Press \(2003 6] Ha S.H.: Helping Online Customers Decide through Web Personalization. IEEE Intelligent Systems 17 \(6 2002 43 7] Hamano S., Sato M.: Mining Indirect Association Rules ICDM 2004. LNCS 3275, Springer Verlag \(2004 8] Kazienko P.: IDARM - Mining of Indirect Association Rules. IIS: IIPWM  05. Advances in Soft Computing Springer Verlag \(2005 9] Kazienko P.: Multi-agent Web Recommendation Method Based on Indirect Association Rules. KES  2004. Part II LNAI 3214, Springer Verlag \(2004 10] Kazienko P., Product Recommendation in E-Commerce Using Direct and Indirect Confidence for Historical User Sessions. DS  04. LNAI 3245, Springer Verlag \(2004 269 11] Kazienko P., Kiewra M.: Link Recommendation Method Based on Web Content and Usage Mining. IIS: IIPWM  03 Advances in Soft Computing, Springer Verlag \(2003 534 12] Kazienko P., Kiewra M., Personalized Recommendation of Web Pages. Chapter 10 in: Nguyen T. \(ed Technologies for Inconsistent Knowledge Processing. Advanced Knowledge International, Adelaide, South Australia 2004 13] Kazienko P., Kolodziejski P.: WindOwls - Adaptive System for the Integration of Recommendation Methods in Ecommerce. AWIC  05, LNAI, Springer Verlag \(2005 14] Kazienko P., Matrejek M.: Adjustment of Indirect Association Rules for the Web. SOFSEM 2005. LNCS 3381 Springer Verlag \(2005 15] Kendall, M. G.: Rank correlation methods. London: Charles Griffin &amp; Company, Ltd., London \(1948 16] Lu Z., Yao Y., Zhong N.: Web Log Mining. Chapter 9 in Zhong N., Liu J., Yao Y. \(eds Berlin, New York \(2003 17] Mobasher B., Cooley R., Srivastava J.: Automatic Personalization Based on Web Usage Mining. Communications of the ACM, 43 \(8 2000 18] Tan P.-N., Kumar V.: Mining Indirect Associations in Web Data. WEBKDD 2001. LNCS 2356, Springer Verlag \(2002 145-166 19] Tan P.-N., Kumar V., Srivastava J.: Indirect Association Mining Higher Order Dependencies in Data. PKDD 2000 LNCS 1910, Springer Verlag \(2000 20] Wan Q., An A.: Efficient Mining of Indirect Associations Using HI-Mine. AI 2003. LNCS 2671, Springer Verlag 2003  221 21] Wang D., Bao Y., Yu G., Wang G.: Using Page Classification and Association Rule Mining for Personalized Recommendation in Distance Learning. ICWL `02. LNCS 2436 Springer Verlag \(2002 22] Yang H., Parthasarathy S.: On the Use of Constrained Associations for Web Log Mining. WEBKDD 2002. LNCS 2703 Springer Verlag \(2003  118 Proceedings of the 2005 5th International Conference on Intelligent Systems Design and  Applications \(ISDA  05 0-7695-2286-06/05 $20.00  2005 IEEE pre></body></html 


pre></body></html 


lossless frequent patterns representations with borders. In practice, they are also much more concise than representations based on closed itemsets and approximate representations. In this paper, we offered three methods of deriving an upper bound on the length of sets in such representations. We proved that the upper bound on the length of a longest generalized disjunction-free set depends logarithmically on the number of records in the database. The obtained result is of high importance as it guarantees that any generalized disjunction-free set representation for all patterns \(both frequent and infrequent scans, where n is the number of records in the database irrespectively how strong or weak correlations among items in the database are and irrespectively of the lengths of records and number of distinct items The modifications of the basic estimation take into account the support threshold of the representation to be found or, additionally, the information on the length of longest sets of the representation already calculated for a higher support threshold. Though these estimations are more accurate than the basic one, they are still quite rough. Further improvements of the quality of estimating the length of longest itemsets in generalized disjunctionfree representations is subject to further research References 1] R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, A.I Verkamo  Fast Discovery of Association Rules   Advances in Knowledge Discovery and Data Mining AAAI, CA, 1996 2] J. Baptiste, J.-F. Boulicaut  Constraint-Based Discovery and Inductive Queries: Application to Association Rule Mining  Pattern Detection and Discovery, Springer London, UK, September 2002, pp. 110-124 3] E. Baralis, S. Chiusano, P. Garza  On Support Thresholds in Associative Classification  SAC, ACM, Taipei Taiwan, March 2004, pp. 553-558 4] Y. Bastide, N. Pasquier, R. Taouil, G. Stumme, L. Lakhal  Mining Minimal Non-redundant Association Rules Using Frequent Closed Itemsets  Computational Logic, 2000 pp. 972  986 5] J.-F. Boulicaut, A. Bykowski, C. Rigotti  Approximation of Frequency Queries by Means of Free-Sets  PKDD Springer, Lyon, France, September 2000, pp. 75-85 6] A. Bykowski, C. Rigotti  A Condensed Representation to Find Frequent Patterns  PODS, ACM, Santa Barbara USA, May 2001, pp. 267-273 7] T. Calders, Axiomatization and Deduction Rules for the Frequency of Itemsets, Ph.D. Thesis, University of Antwerp, 2003 8] T. Calders, B. Goethals  Mining All Non-derivable Frequent Itemsets  PKDD, Springer, Helsinki, Finland August 2002, pp. 74?85 9] T. Calders, B. Goethals  Minimal k-free Representations of Frequent Sets  ECML/PKDD, Springer, CavtatDubrovnik, Croatia, September 2003, pp. 71-82 10] J. Han, M. Kamber, Data Mining: Concepts and Techniques, Morgan Kaufmann Publishers, 2000 11] S.K. Harms, J. Deogun, J. Saquer, T. Tadesse  Discovering Representative Episodal Association Rules from Event Sequences Using Frequent Closed Episode Sets and Event Constraints  ICDM, IEEE Computer Society, San Jose, California, USA, November-December 2001, pp. 603  606 12] M. Kryszkiewicz  Closed Set Based Discovery of Representative Association Rules  IDA, Springer Cascais, Portugal, September 2001, pp. 350-359 13] M. Kryszkiewicz  Concise Representation of Frequent Patterns based on Disjunction  free Generators  ICDM IEEE Computer Society, San Jose, California, USA 


IEEE Computer Society, San Jose, California, USA November-December 2001, pp. 305  312 14] M. Kryszkiewicz M  Inferring Knowledge from Frequent Patterns  Soft-Ware, Springer, Belfast, Northern Ireland April 2002, pp. 247  262 15] M. Kryszkiewicz  Concise Representations of Association Rules  Pattern Detection and Discovery, Springer London, UK, September 2002, pp. 92-109 16] M. Kryszkiewicz, Concise Representation of Frequent Patterns and Association Rules, Habilitation Thesis Publishing House of Warsaw University of Technology 2002 Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE 17] M. Kryszkiewicz  Reducing Infrequent Borders of Downward Complete Representations of Frequent Patterns  Proc. of The First Symposium on Databases Data Warehousing and Knowledge Discovery, Scientific Publishers OWN, Baden-Baden, Germany, July, 2003, pp 29-42 18] M. Kryszkiewicz  Closed Set Based Discovery of Maximal Covering Rules  International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems Vol. 11. World Scientific Publishing Company, Singapore September 2003, pp. 15-29 19] M. Kryszkiewicz  Reducing Borders of k-Disjunction Free Representations of Frequent Patterns  SAC, ACM Taipei, Taiwan, March 2004, pp. 559  563 20] M. Kryszkiewicz  Reducing Main Components of k-Disjunction Free Representations of Frequent Patterns   Proc. of IPMU  2004 \(in print 21] M. Kryszkiewicz, M. Gajek  Concise Representation of Frequent Patterns based on Generalized Disjunction  Free Generators  PAKDD, Springer, Taipei, Taiwan, May 2002, pp. 159-171 22] M. Kryszkiewicz, M. Gajek  Why to Apply Generalized Disjunction-Free Generators Representation of Frequent Patterns  ISMIS, Springer, Lyon, France, June 2002, pp 383  392 23] M. Kryszkiewicz, H. Rybi?ski, M. Gajek  Dataless Transitions between Concise Representations of Frequent Patterns  Journal of Intelligent Information Systems JIIS Netherlands, 2004, pp. 41-70 24] N. Pasquier, Data mining: Algorithmes d  extraction et de R  duction des R  gles d  association dans les Bases de Donn  es, Th  se de Doctorat, Universit  Blaise Pascal   Clermont  Ferrand II, 2000 25] N. Pasquier, Y. Bastide, R. Taouil, L. Lakhal  Efficient Mining of Association Rules Using Closed Itemset Lattices  Journal of Information Systems, Vol. 24, No. 1 1999, pp. 25  46 26] N. Pasquier, Y. Bastide, R. Taouil, L. Lakhal  Discovering Frequent Closed Itemsets for Association Rules  ICDT, Springer, Jerusalem, Israel, January 1999 pp. 398  416 27] J. Pei, G. Dong, W. Zou, J. Han  On Computing Condensed Frequent Pattern Bases  ICDM, IEEE Computer Society, Maebashi City, Japan, December 2002 pp. 378-385 28] V. Phan-Luong V  Representative Bases of Association Rules  ICDM, IEEE Computer Society, San Jose California, USA, November-December 2001, pp. 639-640 29] A. Savinov  Mining Dependence Rules by Finding Largest Itemset Support Quota  SAC, ACM, Taipei Taiwan, March 2004, pp. 525-529 30] M.J. Zaki, C.J. Hsiao  CHARM: An Efficient Algorithm for Closed Itemset Mining  SIAM, Arlington, 2002 


for Closed Itemset Mining  SIAM, Arlington, 2002 Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE pre></body></html 


                                                  S J       


                                                      


                         L A                                        


          L A  Table 7. Table of Granules at left-hand-side is isomorphic to  at right- hand-side: By Theorem  3.1 one can ?nd patterns in either table as a single generalized concept  Internal points  are:[4]\(1, 1, 0, 0 tions; [5]\(0, 1, 1, 0  0, 1, 0, 1  0, 1, 1, 1  1, 1 1, 0  1, 1, 0, 1  1, 0, 1, 1 11]\(1, 1, 1, 1 form and simplify them into disjoint normal forms 1  T E N    S J    T E N    S J 2  T W E N T Y    L A    T H I R T Y   A 3  T W E N T Y      T H I R T Y   A 4  T W E N T Y            L A 5  T E N      T W E N T Y    L A    T E N    T W E N T Y   A   S J    T W E N T Y   A      T H I R T Y    L A     Y 7  T E N      T W E N T Y      T H I R T Y   L A    T E N   L A    S  J   A 8  T W E N T Y      T E N      T W E N T Y    L A    T E N   T W E N T Y      T H I R T Y 9  T W E N T Y    N Y    T E N    S J    T H I R T Y    L A      T W E N T Y    L A  1 0  T W E N T Y    N Y    T W E N T Y    L A    T H I R T Y   A    J 1 1  T W E N T Y          T W E N T Y    L A   T H I R T Y    L A    a l l If the simpli?ed expression is a single clause \(in the original symbols non-generalized the following associations 1   T E N     S J    T E N    S J  2. SJ   J 4   L A    T W E N T Y    L A    T H I R T Y    6 Conclusions Data, patterns, method of derivations, and useful-ness are key ingredients in AM. In this paper, we formalize the current state of AM: Data are a table of symbols. The patterns are the formulas of input symbols that repeat. The method of derivations is the most conservative and reliable one, namely, mathematical deductions. The results are somewhat surprising 1. Patterns are properties of the isomorphic class, not an individual relation - This implies that the notion of patterns may not mature yet and explains why there are so many extracted association rules 2. Un-interpreted attributes \(features can be enumerated 3. Generalized associations can be found by solving integral linear inequalities. Unfortunately, the number is enormous. This signi?es the current notion of data and patterns \(implied by the algorithms 4. Real world modeling may be needed to create a much more meaningful notion of patterns. In the current state of AM, a pattern is simply a repeated data that may have no real world meaning. So we may need to introduce some semantics into the data model [12],[10],[11 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE References 1] R. Agrawal, T. Imielinski, and A. Swami  Mining Association Rules Between Sets of Items in Large Databases  in Proceeding of ACM-SIGMOD international Conference on Management of Data, pp. 207216, Washington, DC, June, 1993 


216, Washington, DC, June, 1993 2] Richard A. Brualdi, Introductory Combinatorics, Prentice Hall, 1992 3] A. Barr and E.A. Feigenbaum, The handbook of Arti?cial Intelligence, Willam Kaufmann 1981 4] Margaret H. Dunham, Data Mining Introduction and Advanced Topics Prentice Hall, 2003, ISBN 0-13088892-3 5] Fayad U. M., Piatetsky-Sjapiro, G. Smyth, P. \(1996 From Data Mining to Knowledge Discovery: An overview. In Fayard, Piatetsky-Sjapiro, Smyth, and Uthurusamy eds., Knowledge Discovery in Databases AAAI/MIT Press, 1996 6] H Gracia-Molina, J. Ullman. &amp; J. Windin, J, Database Systems The Complete Book, Prentice Hall, 2002 7] T. T. Lee  Algebraic Theory of Relational Databases  The Bell System Technical Journal Vol 62, No 10, December, 1983, pp.3159-3204 8] T. Y. Lin  Deductive Data Mining: Mathematical Foundation of Database Mining  in: the Proceedings of 9th International Conference, RSFDGrC 2003 Chongqing, China, May 2003, Lecture Notes on Arti?cial Intelligence LNAI 2639, Springer-Verlag, 403-405 9] T. Y. Lin  Attribute \(Feature  The Theory of Attributes from Data Mining Prospect  in: Proceeding of IEEE international Conference on Data Mining, Maebashi, Japan, Dec 9-12, 2002, pp. pp.282-289 10] T. Y. Lin  Data Mining and Machine Oriented Modeling: A Granular Computing Approach  Journal of Applied Intelligence, Kluwer, Vol. 13, No 2, September/October,2000, pp.113-124 11] T. Y. Lin, N. Zhong, J. Duong, S. Ohsuga  Frameworks for Mining Binary Relations in Data  In: Rough sets and Current Trends in Computing, Lecture Notes on Arti?cial Intelligence 1424, A. Skoworn and L Polkowski \(eds 12] E. Louie,T. Y. Lin  Semantics Oriented Association Rules  In: 2002 World Congress of Computational Intelligence, Honolulu, Hawaii, May 12-17, 2002, 956961 \(paper # 5702 13  The Power and Limit of Neural Networks  Proceedings of the 1996 EngineeringSystems Design and Analysis Conference, Montpellier, France, July 1-4, 1996 Vol. 7, 49-53 14] Morel, Jean-Michel and Sergio Solimini, Variational methods in image segmentation : with seven image processing experiments Boston : Birkhuser, 1995 15] H. Liu and H. Motoda  Feature Transformation and Subset Selection  IEEE Intelligent Systems, Vol. 13 No. 2, March/April, pp.26-28 \(1998 16] Z. Pawlak, Rough sets. Theoretical Aspects of Reasoning about Data, Kluwer Academic Publishers, 1991 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207ñ216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intíl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intíl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 






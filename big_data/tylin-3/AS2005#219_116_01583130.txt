Learning and exploiting invariants for multi-target tracking and data association Ruggero Frezza  and Alessandro Chiuso Department of Information Engineering University of Padova Via Gradenigo 6/b 35131 Padova Italy ruggero.frezza@unipd.it chiuso@dei.unipd.it Abstract  Methods for solving multi target tracking and data association problems in presence of clutter and occlusions are based on models that describe the target dynamics and the measurements statistics Most often the dynamics of the targets are assumed to be independent from each other In 
many applications however the motion of the targets may be coordinated We introduce a statistical concept of shape or coordination in terms of invariants w.r.t the motion of the targets Assuming that the rules of coordination may slowly change over time we study the interplay among the shape and the target dynamics I I NTRODUCTION In many applications from air trafﬁc control to tracking features on the image plane of a camera there is the problem of tracking a multitude of targets while they are moving in space Each target is seen by one or more sensors which generate measurements of its position in space at every time 
step The problem is difﬁcult because the dynamics of the targets are uncertain and the sensors generate unlabelled and similar measurements of their positions It is therefore not trivial to associate measurements to targets The problem is often rendered even more difﬁcult by clutter which consists of the presence of false measurements and occlusions which happen when some targets are hidden from the sensors and do not generate measurements for some time intervals In the literature the problem is known with the name of multi-target tracking and data association There is a vast number of papers addressing it from many different facets since the late 60ies early 70ies Standard methods are 
described for instance in Most algorithms exploit two forms of information a dynamic model describing the motion of the targets and a statistical model of the measurements The data association is solved by jointly examining the positions of all the received measurements w.r.t their predictions on the basis of the dynamic model Probably the most well known algorithm is the JPDA Joint Probability Data Association which evaluates the probabilities of all possible associations and combines them accordingly in order to compute the updated estimate of the targets position The MHT Multiple Hypothesis Tracking is more po werful than the JPD A because it 
evaluates the probability of the associations on a whole time interval It nally selects the most likely association to update the state estimate The complexity of the MHT is however much higher and a latency in the generation of the estimate is necessarily introduced The MMF Multiple Model Filter is applied when the targets go through aggressive maneuvers Multiple dynamic models are used to better describe the different phases of the maneuvers and improve the state predictions It is clear that the more accurate the dynamic model is the easier is the data association problem In recent years in the scientiﬁc literature on computer vision a number of papers on tracking have appeared In 
vision the multi-tar get tracking problem is fundamental to reconstruct the trajectories of features or objects in the image plane In particle lters and the condensation algorithm have been proposed in order to estimate non-Gaussian and multi-modal posterior probability densities which arise in case of ambigous data associations In the problem of proper re-sampling of the densities is addressed by integrating the tracker with information on the measurements which eases the data association problem In 12  statistical learning techniques ha v e been applied to the problem The authors of 13 in particular  h a v e proposed a method for learning the joint probability density of the position of the targets in space The approach is complementary to the standard methods such as the JPDA There 
is no local information on the trajectories and consequently no assumptions on their regularity All the information is collected in the joint probability density and the association events are independent in time The computational complexity of learning the joint probability density is exponential with the size of the maximum clique of the graph describing the conditional dependencies among targets In order to make the problem manageable a triangulate structure is assumed This means that the graph is composed by cliques of order three or less The advantage of this approach is that it models statistical dependencies among targets which with the standard algorithms such as the JPDA are neglected in favor of local coherence of trajectories described by 
independent dynamic models The goal of our research is to combine the advantages of both approaches The main drawback of the statistical learning methods is that they require the acquisition and the labeling of a large training set for each action of interest such as a walking person The learning set may be used for other instances of the same action but cannot be extrapolated to other subjects or scenes Proceedings of the 44th IEEE Conference on Decision and Control, and the European Control Conference 2005 Seville, Spain, December 12-15, 2005 WeC15.1 0-7803-9568-9/05/$20.00 ©2005 IEEE 6053 


The classical techniques based on model based lters and assuming independence are more general in this sense as they do not require particular training but since they do not model coordination among targets they might produce highly segmented tracks In 11 3 4 an ef fort to include information on shape or coordination among targets in the JPDA has been done with some success The advantage of these approaches is that coordination may be learned during those segments of the targets trajectories which are succesfully labeled by the JPDA and then it can be integrated in the scheme in order to solve the data association problem better In this paper we continue along the line of research introduced in 4 W e assume the e xistence of symmetries of motion among some of the targets Think at for example airplanes ying in formation The shape of the formation is invariant w.r.t the motion of each aircraft and it is an important feature for solving the data association problem We model these symmetries as some functions f i for i 1 p of the dynamical state of the targets which are constant in time or slowly varying We then apply standard parameter estimation methods for estimating their statistics and by properly adjusting the forgetting factors we can adapt the scheme to slowly varying parameters II T HE MULTI TARGET TRACKING AND DATA ASSOCIATION PROBLEM With the purpose of introducing some notation which will be used throughout the paper we provide a short introduction to the probabilistic approach to data association We refer the reader to the classic book for a thorough description Consider the problem of tracking over time a set of N T moving targets y i  k  shall denote the position of target i  1   N T  at time instant 1 k  Z  In many real-world scenarios one has available at each time instant k  a set of unlabelled measurements  z i  k    i 1   M k  this means that in general no knowledge is available regarding a which measurement has been originated by which target 2  b which target has generated no measurement in which case we shall say that the target is occluded  and c which measurements are false detections in the sense that they have not been generated by any of the targets in the literature these measurements are said to be originated from clutter  Note that at each time k the number of measurements M k is in general different from the number of targets N T  Dealing with a b and c is the data association problem Traditionally the solution is based on assuming that the position of each target y i is a hidden Markov process whose dynamical state is x i deﬁned by its probability density at the initial time p  x i 0 and by its transition density p  x i  t 1  x i  t   The observations are the positions of the targets They are modeled by the conditional density 1 Without loss of generality we assume that measurements are gathered uniformly in time with unit sample time and that only the positions of targets at those time instant are observed 2 A standard assumption is that each target can originate at most one measurement p  y i  x i   The ltering problem consists in the computation of the following Bayesian recursion p  x  k   Y k  p  y  k   x  k  p  x  k   Y k  1   p  y  k   Y k  1   p  y  k   x  k   p  y  k   x  k  1 p  x  k  1  Y k  1  dx  p  y  k   x  k  p  x  k   Y k  1  dx where with the capital letter Y k we mean the  algebra generated by all the position measurements from the initial time to time k  In the linear Gaussian setting the above recursion is solved by the Kalman lter The problem is that at each time instant k  a set of unlabeled measurements z arrives and the association to the targets is unknown It is customary to denote with  k an association event or hypothesis at time 3 k and with  k the set of all possible association events at time k  Under the hypothesis  k  j  i  k  shall denote the index of the measurement associated to target i  i.e y i  k  z j  i k   k   II.1 If the target i is occluded then j  i  k   II.2 It is sometimes useful to use the index 0 do denote clutter and therefore j 0  k  will denote the set 4 of false measurements under  k  Some approaches are based on hard decisions  where at each time only the most likely possible association is considered unfortunately these fail in the presence of strong clutter and occlusions The Joint Probabilistic Data Association Filter JPDAF hereafter see for a thorough description is a probabilistic method which integrates 1 a dynamical model for the motion of targets 2 a model for the clutter false detections and 3 the probability of occlusions A key observation is that under an association hypothesis  k  estimating the position 5 of each target is the standard ltering problem described above The main idea behind the JPDAF is to fuse the information from 2 and 3 above in order to attach a weight a posterior probability to the possible associations Then an estimate of the position of the targets can be obtained by conditionally weighting the state estimates on all possible 6 associations We shall denote with z  k  z 1  k    z M k  k  the set of measurements available at time k  The symbol Z k will denote the set of measurements up to time k included i.e Z k   z  s  s  0 k    In the gaussian linear case the position y i  k  of the i th target are described by a linear state space model of the 3 Note that since the number of measurements may change over time also the set of possible associations changes over time 4 As explained above under each  k  j  i  k  is a well deﬁned function of i  1 N T  while j 0  k  is in general a set 5 Or more generally the state of a dynamical system describing its motion 6 It is customary to consider only a subset of association which corresponds to large enough weights posterior probabilities This is usually done employing suitable validation regions for each target see for details 6054 


form  x i  k 1  F i  x i  k  v i  k  y i  k  H i  x i  k  w i  k  II.3 The model and measurement noises v i and w i are assumed to be white zero mean and uncorrelated gaussian distributed with covariances Q i and R i respectively The generalization to nonlinear independent dynamics implies the use of nonlinear ltering methods like for example the Extended Kalman Filter or particle lters like the condensation algorithm Our interest ho we v e r  is focused on the data association problem which is unaffected by the fact that the dynamics are linear or not We assume therefore that at time k  1 the conditional density of the state x i  k  1 given all measurements up to time k  1 is Gaussian with mean  x i  k  1 and covariance matrix P i  k  1  i.e p  x i  k  1  Z k  1  N  x i  k  1 P i  k  1  Once measurements at time k become available these estimates can be updated conditionally on an association event   by using standard Kalman lter formulas with measurements 7 y i  z j  i k   We denote with  x i k  k  and P i k  k  the updated mean and covariance conditionally on the association  k  initialized from initial conditions at time k  1   x i  k  1 and P i  k  1  since the dynamics are described by a Gauss-Markov model II.3 the conditional density p  x i  k    k Z k  is Gaussian with mean  x i k  k  and covariance matrix P i k  k   A simple application of the Total Probability Theorem provides the conditional probability density function p  x i  k   Z k    k   k p  x i  k    k Z k  p   k  Z k  II.4 which turns out to be a mixture of Gaussian densities In order to make the computation tractable this Gaussian mixture is approximated in the Kullback-Leibler sense for instance by a Gaussian density with mean  x i  k  and covariance P i  k  according to         x i  k    k  x i k  k   p   k  Z k  P i  k    k P i k  k   p   k  Z k     k  x i k  k    x i  k    x i k  k     x i  k    p   k  Z k  II.5 This allows to start again at time k with a Gaussian posterior for each target and iterate the procedure just described This last approximation step is implicit in the classical description of JPDAF see where only second order moments  x i  k   P i  k  are considered The only point left is to compute the posterior association probabilities p   k  Z k   Assume that a prior p   k  on the association events is available 8  the posterior p   k  Z k  can 7 If under association  k no measurement is associated to target i then only the prediction will be computed 8 We shall not discuss this choice in the paper We refer the reader to for details Sufﬁces it to say that p   k  usually depends on the probability that each target is detected on the number of detected targets and on the number of false measurements be computed using Bayes formula as follows p   k  Z k  cp  z  k    k Z k  1  p   k  Z k  1   cp  z  k    k Z k  1  p   k  II.6 where the last equality holds because associations at time k are conditionally independent upon measurements up to time k  1  The constant c is a normalization factor which does not play a role From now on we shall omit the time index k unless needed according to the notation introduced above Z shall denote the set of past and present measurements while Z  only the past Similarly  x  i will denote the prediction of the state at time k given Z  and P  i its conditional error covariance In order to evaluate p  z   Z    it is convenient to introduce the set 9 D  containing the indices of all the detected targets 10  consequently we shall denote with z T   z j  i  i  D   the set of true measurements i.e measurements which have been associated to some target and with z F the complementary set of false measurements attributed to clutter Similarly we deﬁne the set of occluded target indexes 11 as M   Postulating conditional independence p  z   Z   can be factored in the form p  z   Z   p  z T   Z   p  z F   Z    The term p  z F   Z   describing clutter is usually taken to be uniform over the volume V of interest i.e p  z F   Z    1  V 012 N F    II.7 where N F    is the number of false measurements under hypothesis   As the term p  z T   Z   is concerned it is sufﬁcient to recall that z T   z j  i  i  D     y i i  D    Let us deﬁne the vectors y D    y i i  D   and y M    y i i  M   containing respectively the detected and occluded targets Therefore p  z T   Z    p  y D   Z     y i  z j  i  i  D  II.8 which is the marginal of p  y 1   y N T  Z   p  y D   y M   Z   with respect to y M   p  y D   Z   015 p  y D   y M   Z   d y M   II.9 Under the assumption that the target positions are conditionally independent we have that p  z T   Z    i  D   p  y i  Z     y i  z j  i  II.10 The density p  y i  Z   describes the prediction of the position of target i given past measurements From the 9 Remind that since  depends on time k we should use the notation D  k 10 I.e targets to which a measurements has been associated under hypothesis  11 M stands for missing Note that D   M  1   N T   6055 


assumption that x i conditionally on Z  is Gaussian with mean  x  i and covariance P  i it follows from II.3 that p  y i  Z   is a Gaussian density with mean  y i  H i  x  i and covariance matrix   i  H i P  i H  i  R i  Remark 2.1 Equation II.10 is fundamental in computing the association probabilities It relies on the fact that targets are assumed to be conditionally independent given past measurements which is not certainly true when there is coordination between targets In a shape model has been integrated into the JPDAF algorithm When the posterior density of the positions includes the shape model the marginalization II.9 is not trivial We applied Monte Carlo or equivalently particle methods to implement this step III M OTION SYMMETRIES During their motion the targets may be coordinated where by coordination we mean the existence of some statistical dependence among them Quantifying statistical dependence is a difﬁcult problem The correlation coefﬁcient for example can only be applied to pairs of random variables and only measures linear dependence In the literature there exist a number of measures of statistical dependency In for example a generalization of Pearson’s  2 measure is proposed  2  015 x  X N p  x    N i 1 p  x i  x  1 as well as a measure based on the Kullback-Leibler pseudo distance among the joint distribution and the product of the marginals Both measures if the targets are statistical independent are null otherwise they can even be unbounded The problem with these kinds of measures is that they cannot be easily computed from the experimental observations It would be necessary to estimate the joint density p  x  but this is a formidable task unless particular structures of the conditional dependence graph are assumed It is customary to assume either a tree or a triangular structure The former implies that the maximum cliques are of order two while the latter implies that they are of order three They are both manageable computationally but the triangular structure is more robust w.r.t occlusions A single occlusion in fact cuts a tree structured graph This is the reason why a triangular structure was chosen in 13 We take a different approach We do not try to estimate the joint density of the ensemble of targets but we search for invariants in the motion of the ensemble of targets When a number of aircrafts are ying in formation or a set of markers are attached to a rigid body the position of three non collinear targets fully determines the position of all the others The motion of the whole ensemble of targets can in this case be factored in the motion of any triple of points and on a local invariant representation of the others w.r.t the rst three In other words the motion of the ensemble can be factored in a rigid body motion and an invariant description of the shape of the ensemble In terms of statistical dependency among targets the conditional density of the position of the targets given a triple is degenerate and in absence of noise it is deterministic In presence of noise it can be modeled reasonably well by a Gaussian mixture Besides rigid motion other interesting coordinated motions generate symmetries or equivalently invariants Any kind of link or joint among articulated bodies can be described by some invariants In general we can model holonomic and non-holonomic constraints with invariants If for example the targets are all moving along straight lines the directions of motion are invariants or if the targets are orbiting about a xed point then its coordinates are the seeked invariants Our purpose is to exploit these symmetries in order to solve the data association problem This paper is in particular on the estimate of the statistics of the motion invariants and how to combine this information with that provided by the independent dynamical models II.3 in order to solve the data association problem For consistency the independent dynamical models are assumed to describe the transition density of each target They describe therefore the marginal probability density of each target In general let us assume that there exist some features f i for i 1 p that are functions of the dynamical state of the targets f i  f i  x 1 x n  which are invariant w.r.t the motion of the targets so that df i dt  t   f i       x 1  x 2     x n      0  Two important problems arise 1 nd or identify from the data the invariants f i  2 estimate the statistics of the invariants f i in presence of noise and uncertainties The rst problem is also very difﬁcult and it is not within the scope of this paper even if it is one of the main objectives of our research We assume a list of possible invariants and while tracking we check if there exist group of targets that satisfy them An example of the deﬁnition of an invariant description is the procedure proposed by Kendall to represent the shape of an ensemble of N points It consists of the following steps 1 determine the center of mass of the points y cm   N i 1 y i and move the origin of the reference frame in y cm  2 rotate by R the reference frame so that the N dimensional vector 0  0  1 T becomes the right kernel of the matrix  S    y 1  y cm    y n  y cm   R 3 eliminate the last row of matrix  S  the 3  N  1 matrix S obtained in this fashion is a representation of shape and it is an invariant of rigid motion The invariant proposed by Kendall is unfortunately not robust w.r.t occlusions so in the list of possible invariants we also include distances among pairs of targets and angles between target velocities We assume therefore that the form 6056 


of the invariants f i is known and we address the problems of verifying their existence in the motion of the ensemble of the targets and of estimating their statistics The existence of a speciﬁc invariant is formulated as an hypothesis test the null hypothesis being that the invariant is true The statistic on which the test is performed is the variance of f i  When an invariant is declared true we update the estimate of its mean and covariance with a recursive estimator which is described in the following section and on the other we add links between the correspondent targets to a coordination graph which describes the dependencies among targets It often happens that the invariants of motion last only for short time intervals or show slow dynamics Can they still be exploited for the data association problem We assume that the statistics of the invariants may slowly drift in time This wants to be an initial model describing the dynamics of shape While shape in fact might be evanescent and persist in time brieﬂy it can still carry a lot of information helpful for solving the data association problem We defacto  implement an adaptive scheme that adjusts to changing coordination strategies among targets The coordination graph collects information on the structure of the dependency among targets If the targets are for example all attached to a rigid body the coordination graph will be complete It is used for two reasons book keeping and as a topological support to the data association We have in the past implemented a graph matching algorithm to solve the data association problem but it only helps when the structure of the graph is complex with more than one clique of relatively high order This is usually the situation when the scene is composed by articulated bodies In other situations like a single rigid body the graph is complete i.e it is a clique and the matching algorithm does not provide any information for labeling the measurements IV E STIMATING THE STATISTICS OF SLOWLY VARYING INVARIANTS In estimation theory it is customary to model slowly varying parameters with a linear model   k 1  A  k    k    k  f  k  H  k    k  w  k  IV.1 where the matrix A  k  is close to the identity while  and w are independent gaussian white noises We approximate the matrix A  k  assuming that it is the identity and we assume that the observation matrix H  k  is constant The covariances of the process and measurement noises are assumed unknown Under our hypothesis the extended forgetting factor recursive least squares estimator EFRLS becomes   k    k  1  L  k   f  k   H  k  1 L  k  P  k  1 H T  I  HP  k  1 H T   1 P  k  1    I  L  k  H  P  k  1 IV.2 The choice of the forgetting factor  is based on the following considerations  should be large and close to one whenever the process noise covariance or when the measurement noise covariance is large In the rst case past measurements contain information in the second averaging over more samples in time reduces the covariance of the estimate   however should not be too large or we loose adaptability to slow drifts of the mean of f  An hypothesis test is then performed based on the estimated covariance HP  k  H T of the invariant If the norm of the estimated covariance is larger than an appropriate threshold then the alternative hypothesis is considered true and the invariant is considered not true V I NTEGRATION OF SHAPE IN THE JPDA In order to compute the posterior probability of a given association event  we need to compute the likelihood of the true measurements z T  The overall observation model can be written as follows p  y D   z T  y M   Z   c   i  D  p  z j  i   Z  i     i  M  p  y i  Z  i   p  i 1 p  f i  y D   y M   V.1 which yields p  z T   Z   c   i  D  p  z j  i   Z  i    015  i  M  p  y i  Z  i   p  i 1 p  f i  y D   y M   d y M  V.2 As in we solv e the inte gral in V 2 by a Monte Carlo approach The reason is twofold First it is simple and consistent Second as a byproduct it yields for free a set of fair samples from the posterior distribution of the occluded points positions This allows to compute mean and covariance and hence provides a natural gaussian approximation of the more complicated posterior We draw an appropriate number N s of independent and identically distributed samples y  n  M    y  n  i i M    i  M  p   Z  i  n 1   N s V.3 and compute the n th weight through the following expression   n   p  i 1 p  f i  y D   z T  y M   y  n  M   V.4 Finally the integral is computed as follows   i  M  p  y i  Z  i     p i 1 p  f i  y D   z T  y M   d y M    N s n 1   n  V.5 which substituted in V.2 yields p  z T   Z    The conditional state estimates of a detected point are computed combining the Kalman updates on the basis of all the feasible associations as in the JPDA The fundamental difference being that the symmetries f i are instrumental in computing the likelihood of the association events The conditional state estimates of an occluded point are instead computed exploiting the shape information starting from 6057 


the measurements generated by the detected points It is fundamentally different than in standard approaches where it is taken equal to the state predictions VI R ESULTS The multi-target tracking algorithm proposed in this paper is currently being implemented on a optical motion capture system We implemented the algorithm in matlab and we tested it on data previously acquired with the motion capture system Twentytwo markers have been attached to a human subject three on the head two on the shoulders two on each arm ve on the torso and four on each leg A rigid object with six markers on it was held by the subject in his hand during the acquisition of motion The total of 28 markers was tracked by a six 50 Hz camera motion capture system for approximately two minutes i.e for about 6000 frames The rst 2000 frames were used to determine and initialize the estimate of the invariants of motion All the markers attached to the rigid body held by the subject in his hand satisfy the mutual distance invariants and even Kendall’s invariant when there are no occlusions The coordination graph clearly exhibits the articulation structure of the human body All the markers on the torso for example belong to the same clique of maximum order equal to ve The markers on the feet all belong to a complete subgraph This is because the subject was asked not to move his feet in order to check adaptability to changes in the coordination and the effect of the forgetting factor As an example the statistics of some invariants are described in the following table  Invariant distance among two targets Mean Std Persistence interval max frames Targets 1 and 3 both on the head 16.8cm 0.12cm All Targets 12 and 13 on the left arm 29.7cm 0.57cm 786 The total number of trajectories segments has been taken as a performance index of the data association algorithm Ideally the number of trajectories should have been equal to the total number of markers i.e 28 An implementation of the JPDA alone generated 112 segments The number of trajectory segments is furthermore highly dependent on the choice of noise covariances in the Kalman lters If the covariances are set too small the measurements do not fall within the validation gates and are associated to clutter If the covariance is set too large the data association becomes very difﬁcult because the number of possible associations increases After a few trials we found a choice that led to the best result of 112 segments The shape integrated JPDA generated 36 segments where most of the wrongly labeled segments were produced because of the incorrect invariants detected between the feet of the subject Tuning the forgetting factor  for the invariants is important to obtain signiﬁcant results A small  leads to the creation of invariants which persist in time very brieﬂy A large  renders the scheme rigid and not adaptable so that wrong invariants declared as such because of not sufﬁciently exciting dynamics lead to wrong data association VII C ONCLUSIONS This paper continues along the research line presented in  The spirit is to include information due to the statistical dependence among the targets in standard algorithms multi target tracking algorithms that otherwise treat targets as independent This information is of great help in solving the data association problem The proposed schemes should also improve on the techniques proposed in the computer vision literature based on statistical learning methods which do not imply any local coherence in time of the targets trajectories Coordination among targets has been models by the means of motion symmetries or invariants The shape description proposed by Kendall is used as an invariant but since this is not robust w.r.t occlusions it has been integrated with pairwise distances among targets and angles between target velocities The possibility of slow drifts in time of the invariants is dealt with by introducing forgetting factors in the estimate of their statistics In experiments with a motion capture system segmentation of the tracks has been substantially reduced compared to the standard JPDA assuming the possibility of learning the invariants on a sufﬁciently long time interval with persistently exciting dynamics R EFERENCES  Y  Bar Shalom and T  F ortman Tracking and data association  Academic Press 1988  D B Reid An algorithm for tracking multiple targets  IEEE Trans on Automatic Control 25  No 6 pp 843-854 1979  G Gennari A Chiuso F  Cuzzolin and R Frezza Integrating shape and dynamic probabilistic models for data association and tracking  IEEE Conference on Decision and Control 2002  G Gennari A Chiuso F  Cuzzolin and R Frezza Integration of shape constraints in data association lter  IEEE Conference on Decision and Control 2004  I N Goodman and D H Jonson Orthogonal decompositions of multivariate statistical dependence measures  Int Conf on Acoustics Speech and Signal Processing ICASSP 2004 Montreal CA May 2004  I Gordon and D G Lo we Scene modelling recognition and tracking with invariant image features  International Symposium on Mixed and Augmented Reality ISMAR Arlington VA Nov 2004 pp 110-119  D G K endall A survey of the statistical theory of shape with discussion  Statist Sci 4  1989 pp 87-120  M Isard and A Blak e Condensation  conditional density propagation for visual tracking  Int J Computer Vision 1998  K Okuma A T ale ghani N De Freitas J J Little and D G Lo we A Boosted Particle Filter Multitarget Detection and Tracking  European Conference on Computer Vision ECCV Prague May 2004 pp 2839  C Rasmussen and G.D Hager  Joint probabilistic techniques for tracking multi-part objects  Int Conf on Computer Vision and Pattern Recognition 1998  C Rasmussen and G.D Hager  Probabilistic data association methods for tracking complex visual objects  IEEE Transaction on Patter Analysis and Machine Intelligence 23 2001 560–576  Y  Song L Gonca v es E Di Bernardo and P  Perona Monocular perception of biological motion detection and labelling  Int Conf on Computer Vision 1999 pp 805–812  Y  Song L Gonca v e s and P  Perona Unsupervised learning of human motion  IEEE Transaction on Patter Analysis and Machine Intelligence 25 2003 1–14  Y  Zhu Efﬁcient Recursive State Estimator for Dynamic Systems without Knowledge of Noise Covariances  IEEE Transaction on Aerospace and Electronic Systems 35 1999 102–114 6058 


2          f o r  a l l  c a t e g o r i c a l              let          3          f o r  a l l  c a t e g o r i c a l              let           4   G i v e n  a n  m d i  o f       f o r  a l l  n u m e r i c       let           Given                   a n d                r       f o r  e a c h  c a t e g o r i c a l       a n d        o r       f o r  e a c h  c a t e g o r i c a l       from \(1 3 4 t h e  d e n s e n e s s  b e i n g  a  M I N T  m e a s u r e         f o r  e a c h  n u m e r i c       a n d        f o r  e a c h  n u m e r i c       Accordi n g l y         a n d         a n d  t h e  j o i n            g i v e s the upper bounds of       m a y  n o t  b e  u n i q u e   s i n c e  m u l tiple mdrs  s  c a n  b e  d e r i v e d   A l s o    m a y  n o t  e x i s t   s i n c e      c a n  b e  o b t a i n e d  i n   1    o r  t h e  m d r   can not exist, i.e      i n   4    F i g u r e  1  d e p i c t s  t h e s e  c a s e s   I n Figure 1. Derivation of  by join a  o f  t h e  c o m b i n e d  i t e m s e t    i s  m u l t i p l e  d u e  t o  t h e  l a c k of uniformity of     even if  and  of the original itemsets are unique respectively. In \(b  


nal itemsets are unique respectively. In \(b  does not exist due to the low denseness of       A c c o r d i n g l y    rived via       i s  a  f a m i l y  o f  s e t s  i n  g e n e r a l   T h e n  w e  o b t a i n  t h e  j o i n  o p e r a t i o n         b y  E q   2    F r o m  t h e  a b o v e d i s c u s s i o n                      a n d  t h u s       i l a r l y          T h i s  i n d i c a t e s  t h a t  t h e  j o i n      g i v e s  t h e upper bound of    a n d  a n  u p p e r  s e m i l a t t i c e    Based on this de?nition of join operation on families of sets with denseness and the de?nitions of support and con?dence, the most of the standard algorithms of the Basket Analysis whose complexity is       c a n  b e  a p p l i e d  t o  d e rive generic QARs from data 3.2. Implementation To assess the basic features of QARMINT, we used the standard Apriori-TID algorithm [1], since it is principally an algorithm running on memory, and its computational features are well known. Instead of hash tables, the trie data structure as depicted in Fig. 2 was used under lexicographically ordered itemsets. If any subsets of the joined s e t                a r e  n o t  f r e q u e n t  a c c o r d i n g  t o  a  g i v e n      i s  p r u n e d  b e f o r e  i t s  m d r   is computed. Moreover, after computing the mdr      i s  p r u n e d  i f    i s  n o t frequent. The pruning by these checks are indicated by the slashed itemsets in Fig. 2. A difference from the original Apriori-TID algorithm is that the join of two itemsets    within a family depicted by a solid box is not allowed, and t h e  i t e m s e t s   s  o b t a i n e d  f r o m  a  p a i r  o f  f a m i l i e s    l o n g  t o  a n  i d e n t i c a l  f a m i l y     A n o t h e r  d i f f e r e n c e  i s  t h a t  a join of     c a n  g e n e r a t e  m u l t i p l e  i t e m s e t s   s  a s  d e p i c t e d  i n a dashed box The most expensive process in QARMINT is to derive the mdr  s  o f  j o i n e d  i t e m s e t     W e  i n t r o d u c e  a n  i t e r a t i v e approach to reduce the required computation time. Given                     r s t   a l l  t r a n s a c t i o n s  i n  are sorted for each attribute   i n     T h i s  i s           T h e n  the mdis on the number line of  


are computed from the transactions without taking into account the other attributes When multiple mdis are obtained, one of them is focused and the transactions in the mdi is retained. Next, the identiProceedings of the The 2005 Symposium on Applications and the Internet Workshops \(SAINT-W  05 0-7695-2263-7/05 $20.00  2005 IEEE Figure 2. Trie data structure Figure 3. Time complexity cal process is applied to   and this recursively continues in depth ?rst search \(DFS   is computed, the process continues again from  until the mdi of every              c o n v e r g e s   T h e  m d i s  a l w a y s  c o n v e r g e to these of the mdr  because the denseness is a MINT measure. After the convergence, the search is backtracked to the next mdr  The computation of mdis in each step requires       t i m e  a t  m o s t   I n  t h e  w o r s t  c a s e   o n l y  o n e t r a n s a c t i o n  i s  d r o p p e d  i n  e a c h  s t e p   a n d    s t e p s  r e q u i r e d until the mdis converge. Thus         H o w e v e r   t h i s  d o e s not likely occur. Practically, only a portion of the transact i o n s  a r e  r e t a i n e d  i n  e a c h  s t e p   L e t          b e  a n  e x pected rate of transactions retained in each step the required steps for convergence. The process to search an mdr stops at the latest when the number of retained transa c t i o n s     b e c o m e s  l e s s  t h a n   By solving the equation       w i t h   is        A c cordingly, the expected time complexity of this most expensive process is         4. Performance Evaluation The performance of QARMINT has been evaluated through both arti?cial data and real bench mark data Sets of arti?cial data have been generated under various conditions. The characteristics of the computation time is simlilar to the conventional Basket Analysis except for       T h e  t i m e  m o d e r a t e l y  i n c r e a s e s  w h e n s of all attributes are increased. This is because wider permissible ranges increases the number of mdrs. Figure 3 shows the dependency of the computation time on the n u m b e r  o f  t r a n s a c t i o n      T h e  c u r v e  a l m o s t  f o l l o w s  t h e  r e lation         The real bench mark data  Labor relations Database  in UCI Machine Learning Repository [3] was analyzed by QARMINT. It contains 57 instances, 8 numeric attributes and 8 categorical attributes and many missing values. We ignored the attributes of missing values in each instance and transformed the data into transactions. Though the size 


and transformed the data into transactions. Though the size of this data is quite small, we found many interesting QARs associated with the labor conditions under      and      w h i c h  i s  1 0   o f  t h e  m a x i m u m  a n d  m i n i mum values of each  in the data. The following two are examples                                                                                                                  These rules indicate that the workers having longer durat i o n  c o n t r a c t s  a n d  e v a l u a t i n g  t h e i r  l a b o r  c o n d i t i o n  a s   admit longer working times and less wage increase. These evaluations indicate the suf?cient tractability and the practical applicability of QARMINT 5. Conclusion The mathematical characterization and the extension of the Basket Analysis presented in this paper are expected to provide variety of new approaches of data mining. Their potential has demonstrated by a novel approach called QARMINT for complete mining of generic QARs within a low time complexity. We are implementing QARMINT in a more ef?cient algorithm and evaluating its performance in near future Acknowledgement This research has conducted under the support of JSPS Kiban Kenkyuu \(B 2 References 1] R. Agrawal and R. Srikant. Fast algorithms for mining association rules. Proc. of 20th Int. Conf. on Very Large Data Bases VLDB  499, 1994 2] R. Srikant and R. Agrawal. Mining quantitative association rules in large relational tables. Proc. of 1996 ACM SIGMOD Int. Conf. on Management of Data, pages 1  12, 1996 3] U. C. I. \(UCI http://www.ics.uci.edu/ mlearn/MLRepository.html, 2004 4] J. Wijsen and R. Meersman. On the complexity of mining quantitative association rules. Data Mining and Knowledge Discovery, 2\(3  281, September 1998 Proceedings of the The 2005 Symposium on Applications and the Internet Workshops \(SAINT-W  05 0-7695-2263-7/05 $20.00  2005 IEEE 


0-7695-2263-7/05 $20.00  2005 IEEE pre></body></html 


n M L N n t n t n t n t L M L t L t L tt L t kkkk kkkk kkk kkkk kkkkkkkkP VK VK VK VK PP       kkP t 31 where L  s the error covariance associated with the state estimate t i    kkLX  tt kkk P1  00 0  0                     s s sss s s sss s s sssss N n t n t n 


n t n N n t n t n t n N n t n t n t n t n t n c t L kkkkkk kkkkk kP VKVK VKVK  32 4. Simulations One has run simulations comparing the sequential implementations of MSJPDA algorithm and the new algorithm here. A typical multisensor multitarget tracking environment is assumed in the simulations. According to article [1,3], One known that the performance of sequential MSJPDA is better than the performance of parallel MSJPDA. Therefore, the performance of parallel MSJPDA algorithm will not be compared here There are three sensors, which are fixed in three platforms. Regarding the 2nd sensor as fusion centre situation of the other sensors are: =?-500m?-500m 0m??N =?-500m? 500m?0m??The distance error of each sensor is: =300m, =200m, =100m?The bear error of each sensor is 0.03rad, =0.02rad, =0.01rad?The of sample is T=1s?The nonparametric model of clutter is used in the simulations, and expected number of false measurement is m=1.8 1 sN 3 s 1r 2 2r 3 3r 1 Simulations have been run for racking two targets. The true initialization state of the targets is X1?[-29500m,400m/s,34500m,-400m/s X ?[-26250m,296m/s,34500m,-400m/s]'? 2 The two targets will cross above 31seconds later. To evaluate tracking performance, 50 Monte Carlo runs were performed for three case of the target detection probability Pd=0.97 ? Pd=0.76 ? Pd=0.58. In every run, the total simulation time is 140 steps 


simulation time is 140 steps            Figure 1  RMS position error in case of Pd=0.97          Figure 2  RMS velocity error in case of Pd=0.97       Figure 3  RMS position error in case of Pd=0.76 567 Proceedings of  the Fourth International Conference on Machine Learning and Cybernetics  Guangzhou, 18-21 August 2005         Figure 4  RMS velocity error in case of Pd=0.76         Figure 5  RMS position error in case of Pd=0.58          Figure 6  RMS velocity error in case of Pd=0.58  Table 1 The emanative times comparison for sequential MSJPDA and SD-CMSJPDA algorithm  Pd N A  0.97 0. 76 0.58 Sequential MSJPDA 2 11 17 SD-CMSJPDA 0 3 5 Pd denotes detection probability, N denotes emanative 


Pd denotes detection probability, N denotes emanative times, A denotes the kind of algorithm Table 1 shows the summation of emanative times for sequential MSJPDA and SD-CMSJPDA algorithm in 50 Monte Carlo simulations. From table 1 , it is shown that the stability of SD-CMSJPDA is better than that of sequential MSJPDA as the detection probability varied Figure 1,2 show the RMS errors for position and velocity in case of Pd=0. 97, respectively; Figure 3,4 show the RMS errors for position and velocity in case of Pd=0.76 respectively; Figure 3,4 show the RMS errors for position and velocity in case of Pd=0.58, respectively. From the figures we can see that the average RMS position error is lower for the SD-CMS JPDA algorithm. We also see that the state estimation precision of sequential MSJPDA get worse as the detection probability decreases The reasons for these simulation results lies:1 state estimation precision will get worse when the detection probability decrease;2 algorithm is to process measurement from each sensor using single sensor JPDA algorithm sequentially. Therefore the estimation error from each sensor will be accumulated Moreover, the sequential MSJPDA algorithm can  t improve the joint detection probability of the multisensor system The estimation error of the SD- CMSJPDA  algorithm will not be accumulated for it processes the measurement from each sensor directly in the mean time .What  s more the new method can greatly improve the joint detection probability of the multisensor system. Therefore, the tracking performance of SD-CMSJPDA algorithm is better than that of sequential MSJPDA. Algorithm All of the simulations are run in the personal computer with a 2.0G CPU and a 256M memory. The average cost time per step is 0.0251 in the sequential implementations of MSJPDA algorithm. And the average cost time per step is 0.0282 in the sequential implementations of MSJPDA algorithm. According to the results we can see that there is few difference in real time between the new method and the sequential   MSJPDA when there is not so many sensors and targets 568 Proceedings of  the Fourth International Conference on Machine Learning and Cybernetics  Guangzhou, 18-21 August 2005  5. Conclusion In order to solve the problem of multisensor multi target tracking, a new centralized multisensor  joint probabilistic data association  algorithm is proposed in this paper. The simulation results shows that the tracking performance of the new algorithm is better than that of the sequential MSJPDA algorithm The computational complexity of the new method will increase as the number of sensors and targets grow Therefore, how to improve the real time of SD- CMSJPDA algorithm will be pay attention References 1] He You, Wang Guohong, Lu Dajin, Peng Yingning Multisensor Information Fusion With Application[M Publishion House of Electronics Industry. 2000, Beijing.  [11] B..Zhou and N.K.Bose Multitarget  Tracking in Clutter:Faste Algorithms for Data Association .IEEE Transaction on Aerospace and Electronic Systems 1993,29\(2 2] Bar-shalom,Y\(Ed Applications and Advances,2: Norwood,MA Artech  House, 1992 3] L.Y. Pao, C.W.Frei. A Comparison of Parallel and Sequential Implementation of a Multisensor Multitarget Tracking Algorithm. Proc. 1995 American Control Conf. Seattie, Washington,June 1995 1683~1687 


4] K. Chang, C. Chong, Bar-Shalom, Joint Probabilistic Data Association in Distributed Sensor Networks IEEE Transactions on Automatic Control, AC-31\(10 octobre 1986 5] Bar-shalom, Multitarget Multisensor Tracking Advanced Application ,:YBS Publishing, 1990 6] Bar-shalom, Multitarget Multisensor Tracking Principles and Techenices ,:YBS Publishing, 1995 7] Hu Wenlong, Mao shiyi, Multisensor Data Association Based on Combinatorial Optimization[J]. Journal of Systems Engineering and Electronics . 1997 NO.1,1~9 8] Pattipati K R, Passive Multisensor Data Association Using a New Relaxation Algorithm.In Multitarget-Multisensor Tracking: Advanced and Applications,Y.Barshalom,Norwood,MA:Aretech,199 0 9] Deb S,et al, An S-Dimentional Assignment Algorithm for Track Initiation ,Proc. Of the IEEE Int. Conf Systems Engineering, Kobe, Japan,Sept 1992 527~530 10] Deb S,et al, A Multisensor-Multitarget Data Association Algorithm for Heterogeneous Sensors[J].IEEE Trans. on AES 1993 ,29 \(2 560~568 12] Bar-shalom,Y.,and Fortmann,T.E  Tracking and Data Association  New York:Academic press,1988 13] J,A,Roecher and G.L.Phillis,Suboptimal Joint Probabilistic Data Association .IEEE Transaction on Aerospace Electronic Systems.1993,29\(2 14] J,A,Roecker,A Class of Near Optimal JPDA Algorithm IEEE Transaction on Aerospace and Electronic Systems,1994,30\(2 15] Han Yanfei, Analysis and Improvement of Multisensor Multitarget Probabbilistic Data Association Filting Algorithm[J].  Journal of Systems Engineering and Electronics, 2002, Vol.24, 36~38  569 pre></body></html 


dense data sets for evaluating pattern mining algorithms These two data sets are obtained from IBM Almaden at http://www.almaden.ibm.com/cs/quest/demos.html. Recently, theMAFIA algorithm [6] was proposed to ef?ciently discover maximal frequent patterns. As shown in their paper, MAFIA can be several orders better than some alternatives, such as DepthProject, for mining maximal frequent patterns. Hence, we chose MAFIA as the base line for our performance evaluation. Finally, please note that only the size-2 patterns are generated in the ?rst BFS phase Experimental Platform We implemented the MHP algorithms using C++ and all experiments were performed Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE on a Pentium III    MHz PC machine with    megabytes main memory, running Linux Redhat 6.1 operating system 5.2. A Performance Comparison 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 1e+10 1e+11 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C he ck ed P at te rn s Support threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 


Figure 4. The Number of Checked Patterns on the Pumsb* Data Set 10 100 1000 10000 100000 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 R un T im e s ec  Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 5. The RunTime Comparison on the Pumsb* Data Set Figure 4 shows the number of patterns that MHP and MAFIA have to check during the pattern mining process on the pumsb* data set. As can be seen, for MHP, the number of checked patterns is increased with the decrease of the h-con?dence threshold. However, the number of checked patterns of MHP can be signi?cantly smaller than that of MAFIA even if a low h-con?dence threshold is speci?ed To check a pattern, we need to count the support of the patterns. Counting the support of a pattern is the most timeconsuming task during the pattern mining process, since we need to retrieve all the transactions which include one of its sub-pattern, or for Ma?a, retrieve all the bit of the bitmap of this pattern [6]. Therefore, an algorithm is more ef?cient if smaller number of patterns need to be checked 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N 


um be r o f C he ck ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 6. The Number of Checked Patterns on the Pumsb Data Set 10 100 1000 10000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 R un T im e s ec  Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 7. The RunTime Comparison on the Pumsb Data Set The runtime comparison of MHP and MAFIA on the Pumsb* data set is shown in Figure 5. In the ?gure, we can observe that the runtime of MHP can be signi?cantly reduced with the increase of h-con?dence thresholds. Also the runtime of MHP can be several orders of magnitude less than that of MAFIA even if the h-con?dence threshold is as low as 0.3. The reason is that the number of checked patterns of MHP is sign?cantly smaller than that of MAFIA Similar results are also obtained from the pumsb data set as shown in Figure 6 and Figure 7. For the pumsb data set the number of checked patterns of MHP is much smaller 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207ñ216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intíl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intíl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 






Approximate Inverse Frequent Itemset Mining Privacy Complexity and Approximation  Yongge Wang Xintao Wu UNC Charlotte  yonwang xwu  uncc.edu Abstract In order to generate synthetic basket datasets for better benchmark testing it is important to integrate characteristics from real-life databases into the synthetic basket datasets The characteristics that could be used for this purpose include the frequent itemsets and association rules The problem of generating synthetic basket datasets 
from frequent itemsets is generally referred to as inverse frequent itemset mining In this paper we show that the problem of approximate inverse frequent itemset mining is NP complete Then we propose and analyze an approximate algorithm for approximate inverse frequent itemset mining and discuss privacy issues related to the synthetic basket dataset In particular we propose an approximate algorithm to determine the privacy leakage in a synthetic basket dataset Keywords data mining privacy complexity inverse fre 
quent itemset mining 1 Introduction Since the seminal paper 1 as s o ciation rule and frequent itemset mining received a lot of attention By comparing ve well-known association rule algorithms using three real-world data sets and the artiìcial data set from IBM Almaden Zheng et al 12 found out t h at t h e a l gori t h m p er formance on the artiìcial data sets are very different from their performance on real-world data sets Thus there is a great need to use real-world data sets as benchmarks However organizations hesita te to provide their realworld data sets as benchmarks due to the potential disclosure of private information One potential approach to ad 
dress this problem is to generate synthetic basket datasets for benchmarking purpose by integrating characteristics from real-world basket datasets that may have inîuence on the software performance The frequent sets and their supports deìned as the number of transactions in the basket  Supported by NSF CCR-0310974 dataset that contain the items can be considered to be a reasonable summary of the real-world data set As observed by Calders 3 as s o ciation rules for bas k e t datas et can be described by frequent itemsets Thus it is sufìcient to consider frequent itemsets only Ramesh et al recently 
investigated the relation between the distribution of discovered frequent set and the performance of association rule mining It suggests that the performance of association rule mining method using the original data set should be very similar to that using the synthetic one compatible with the same frequent set mining results Informally speaking in this approach one rst mines frequent itemsets and their corresponding supports from the real-world basket datasets These frequent itemset support constraints are used to generate the synthetic mock dataset which could be used for benchmarking For this 
approach private information should be deleted from the frequent itemset support constraints or from the mock database The authors of 7 3 i n v e s t i g at e t he probl em whet her there exists a data set that is consistent with the given frequent itemsets and frequencies and show that this problem is NP complete The frequency of each frequent itemset can be taken as a constraint over the original data set The problem of inverse frequent set mining then can be translated to a linear constraint problem Linear programming problems can be commonly solved today in hundreds or thousands of variables and constraints However the number of 
variables and constraints in this scenario is far beyond hundreds or thousands e.g 2 t where t is the number of items Hence it is impractical to apply linear programming techniques directly Recently the authors of 11 i n v es tigated a heuristic method to generate synthetic basket data set using the frequent sets and their supports mined from the original basket data set Instead of applying linear programming directly on all the items it applies graph-theoretical results to decompose items into independent components and then apply linear programming on each component One poten 
tial problem here is the number of items contained in some components may be still too large especially when items are highly correlated each other which makes the application of linear programming infeasible Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


The authors of 9 propos ed a m et hod t o generat e bas k e t data set for benchmarking when the length distributions of frequent and maximal frequent itemset collections are available Though the generated synthetic data set preserves the length distributions of frequent patterns one serious limitation is that the size of transaction databases generated is much larger than that of origi nal database while the number of items generated is much smaller We believe the sizes of items and transactions are two important parameters as they may signiìcantly affect the performance of association rule mining algorithms Instead of using the exact inverse frequent itemset mining approach we propose an approach to construct transaction databases which have the same size as the original transaction database and which are approximately consistent with the given frequent itemset constraints These approximate transaction databases are sufìcient for benchmarking purpose In this paper we consider the complexity problem the approximation problem and privacy issues for this approach We rst introduce some terminologies I is the nite set of items A transaction over I is deìned as a pair  tid I  where I is a subset of I and tid is a natural number called the transaction identiìer A transaction database D over I is a nite set of transactions over I  For an item set I  I and a transaction  tid J   we say that  tid J  contains I if I  J  The support of an itemset I in a transaction database D over I is deìned as the number of transactions T in D that contains I  and is denoted support  I D  The frequency of an itemset I in a transaction database D over I is deìned as freq  I D  def support  I D  D  Calders 2 de ned t h e fol l o wi ng probl ems t hat are related to the inverse frequent itemset mining FREQSAT Instance  An item set I and a sequence  I 1 f 1    I 2 f 2      I m f m  where I i I are itemsets and 0  f i  1 are nonnegative rational numbers for all 0  i  m  Question  Does there exist a transaction database D over I such that freq  I i  D  f i for all 0  i  m  FFREQSAT Fixed size FREQSAT Instance Aninteger n  an item set I  and a sequence  I 1 f 1    I 2 f 2      I m f m  where I i I are itemsets and 0  f i  1 are nonnegative rational numbers for all 0  i  m  Question  Does there exist a transaction database D over I such that D contains n transactions and freq  I i  D  f i for all 0  i  m  FSUPPSAT Instance Aninteger n  an item set I  and a sequence  I 1 s 1    I 2 s 2      I m s m  where I i I are itemsets and s i  0 are nonnegative integers for all 0  i  m  Question  Does there exist a transaction database D over I such that D contains n transactions and support  I i  D  s i for all 0  i  m  Obviously the problem FSUPPSAT is equivalent to the problem FFREQSAT Calders 2 sh o w ed th at FREQSA T i s NP complete and the problem FSUPPSAT is equivalent to the Intersection Pattern problem IP  given an n  n matrix C with integer entries do there exist sets S 1 S n such that  S i  S j   C  i j   Though it is known that IP is NP hard it is an open problem whether IP belongs to NP  In this paper we will consider the problem of generating transaction databases that approximately satisfy the given frequent itemset support constraints Section 2 discusses the computational complexity of approximating transaction databases Section 3 proposes an algorithm to approximately generate a approximate transaction database Section 4 discusses privacy issues Finally Section 5 draws conclusions 2 Approximations Though it is an interesting problem to study whether there exists a size n transaction database that satisìes a set of given frequency constraints it is sufìcient for benchmarking purpose to construct a transaction database that is approximately at the size of n and that approximately satisìes the set of given frequency constraints Thus we deìne the following problem ApproSUPPSAT Instance Aninteger n  an item set I  and a sequence  I 1 s 1    I 2 s 2      I m s m  where I i I are itemsets and s i  0 are nonnegative integers for all 0  i  m  Question  Does there exist a transaction database D of n  transactions over I such that  n  n    O  m  and  support  I i  D   s i   O  m  for all 0  i  m  Note that in the above deìnition the approximation errors are based on the parameter m instead of n since for most applications m is small and n is bigger Indeed n could be at the exponential order of m  For performance testing purpose it is not meaningful to use n as the parameter in these situations It also straightforward to show that the problem ApproSUPPSAT is equivalent to the following problem given an integer n  an item set I  and a sequence  I 1 s 1    I 2 s 2      I m s m   decide whether there exists a transaction database D over I with n transactions and 0  support  I i  D   s i  O  m  for all 0  i  m  In the following we show that ApproSUPPSAT is NP complete Note that for the non-approximate version FSUP2 Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


PSAT of this problem we do not know whether it is in NP  Lemma 2.1 ApproSUPPSAT  NP  Proof  Since the size of the transaction database is n which might be exponential in the size of the instance input description it is not possible to guess a transaction database in polynomial time and check whether it satisìes the constraints In the following we use other techniques to show that the problem is in NP Let I be the collection of item sets and  I 1 s 1    I 2 s 2      I m s m  be the sequence of support constraints Assume that I  t Let J 0 J 1   J 2 t  1 be an enumeration of the 2 t subsets of I in particular let J 0   and J 2 t  1  I  and X 0 X 1    X 2 t  1 be 2 t variables corresponding to these itemsets Assume that a transaction database D with n   n  O  m  transactions contains X i itemset J i for each 0  i  2 t and D approximately satisìes the support constraints  I 1 s 1    I 2 s 2      I m s m   Then there exists an integer k such that the following equations 1 hold for some integer values X 0 X 2 t  1  Z 0    Z m  Similarly if there is an integer k and an integer solution to the equations 1 then there is a transaction database D with n   n  O  m  transactions that approximately satisìes the support constraints  I 1 s 1      I m s m   X 1 X 2 t  0  Z 0    Z 1    Z m  km  2 t i 0 X i  Z 0  n  I 1  J i X i  Z 1  s 1   I m  J i X i  Z m  s m 1 where k is a large enough integer In another word if the given instance of the ApproSUPPSAT problem is satisìable then the equations 1 have an integer solution That is the solution space for the equation 1 is a non-empty convex polyhedron A simple argument 1 could then be used to show that there is an extreme point  X 0 1 X 0 2 t  not necessarily an integer point on this convex polyhedron that satisìes the following property  There are at most m 1 non-zero values among the variables X 0 1    X 0 2 t  Z 0    Z m  Let Y i  X 0 i  be the closest integer to X 0 i for 1  i  2 t and D Y be the transaction database that contains Y i copies of the itemset J i for each 0  i  2 t Then D Y contains n  O  m  transactions and  support  I i  D   s i   O  m  for all 0  i  m  1 Similar argument has been used to prove the fundamental theorem of linear optimization in linear programming See e.g 4 8  In another word the given instance of the ApproSUPPSAT problem is satisìable if and only if there exist itemsets J 1 J m 1 and an integer sequence x 1 x m 1 such that the transaction database D consisting of x i copies of itemset J i for each i  m witnesses the satisìability Thus ApproSUPPSAT  NP which completes the proof of Lemma Q.E.D Lemma 2.2 ApproSUPPSAT is NP hard Proof The proof is based on an ampliìcation of the reduction in the NP hardness proof for FREQSAT in 2 whi ch is alike the one given for 2SAT in 5 In t h e f ol l o wi ng we reduce the NP complete problem 3-colorability to ApproSUPPSAT Given a graph G  V E   G is 3-colorable if there exists a 3-coloring function c  V  R G B  such that for each edge  u v  in E we have c  u  012  c  v   For the graph G  V E   we construct an instance A  G  of ApproSUPPSAT as follows Let m 6  V  3  E   and n  k 0 m 2 for some large k 0 note that we need k 0 k for the constant k we will discuss later Let the itemset I   R v G v B v  v  B  and the m support constraints are deìned as follows For each vertex v  V  support   R v   n 3   support   G v   n 3   support   B v   n 3   support   R v G v  0  support   R v B v    support   G v B v  0  For each edge  u v   E  support   R u R v    support   G u G v    support   B u B v    In the following we show that there is a transaction database D satisfying this ApproSUPPSAT problem if and only if G is 3-colorable Suppose that c is a 3-coloring of G Let T be a transaction deìned by letting T 1   C v  v  V  where C v  def    R v if c  v  R  G v if c  v  G  B v if c  v  B Let transactions T 2 and T 3 be deìned by colorings c  and c  resulting from cyclically rearranging the colors R G B in the coloring c  Let the transaction database D consist of  n 3  copies of each of the transaction T 1 T 2 and T 3 we may need to add one or two additional copies of T 1 if 3 n 3  012  n  Then D satisìes the ApproSUPPSAT problem A  G   Suppose D is a transaction database satisfying the ApproSUPPSAT problem A  G   We will show that there is a 3 Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


transaction T in D from which a 3-coloring of G could be constructed Let I 1 be the collection of itemsets deìned as I 1   R v G v    R v B v    G v B v   v  V   R u R v    G u G v    B u B v   u v   E   That is I 1 is the collection of itemset that should have 0 support according to the support constraints Since D satisìes A  G   for each I  I 1  support  I   D 0 is approximately satisìed Thus there is a constant k 1  0 such that at most k 1 m I 1  3 k 1 m   V    E   transactions in D contain an itemset in I 1 Let D 1 be the transaction database obtained from D by deleting all transactions that contain itemsets from I 1 Then D 1 contains at least n  3 k 1 m   V    E   transactions For each vertex v  V  we say that a transaction  tid J  in D does not contain v if J does not contain any items from  R v G v B v  Since D satisìes A  G   for each v  V  approximately one third of the transactions contain R v  G v  B v  respectively Thus there is a constant k 2  0 such that at most 3 k 2 m  V  transactions in D do not contain some vertex v  V  In another word there are at least n  3 k 2 m  V  transactions J in D such that J contains v for all v  V  Let D 2 be the transaction database obtained from D 1 by deleting all transactions J such that J does not contain some vertex v  V  The above analysis shows that D 2 contains at least n  3 k 1 m   V    E    3 k 2 m  V  transactions Let k max  k 1 k 2  Thenwehave D 2  n  3 km   V    E    3 km  V   n  km 6  V  3  E    n  km 2 3  k 0 m 2  km 2 By the assumption of k 0 at the beginning of this proof we have D 2  1  For any transaction J in D 2  we can deìne a coloring c for G by letting c  v     R if J contains R v G if J contains G v B if J contains B v By the deìnition of D 2  the coloring c is deìned unambiguously That is G is 3-colorable This completes the proof for NP hardness of ApproSUPPSAT Q.E.D Theorem 2.3 ApproSUPPSAT is NP complete Proof This follows from Lemma 2.1 and Lemma 2.2 Q.E.D We showed that the problem ApproSUPPSAT is NP hard In the proof of Lemma 2.2 we use the fact that the number n of transactions of the target basket database is larger than the multiplication of the number m of support constraints and the approximate error O  m  that is n is in the order of O  m 2   In practice the number n may not be larger than km 2  Then one may wonder whether the problem is still NP complete If n is very small for example at the order of O  m   then obviously the problem ApproSUPPSAT becomes trivial since one can just construct the transaction database as the collection of n copies of the itemset I that is the entire set of items This is not a very interesting case since if n is at the order of m  one certainly does not want the approximate error to be at the order of n also A reasonable problem could be that one deìnes a constant number  to replace the approximate error O  m   Then the proof in Lemma 2.2 shows that the problem ApproSUPPSAT with approximate error  instead of O  m   is still NP complete if n>m  Tighter bounds could be achieved if weighted approximate errors for different support constraints are given 3 Generating approximate transaction databases In this section we design and analyze a linear program based algorithm to approximate the NP complete problem ApproSUPPSAT Let I   e 1 e t  be the collection of items n be the number of transactions in the desired database D and  I 1 s 1    I 2 s 2      I m s m  be the sequence of support constraints According to the proof of Lemma 2.1 if this instance of ApproSUPPSAT is solvable then there is a transaction database D  consisting of at most m 1 itemsets J 1 J m 1  that satisìes these constraints Let X 1 X m 1 be variables representing the numbers of duplicated copies of these itemsets in D respectively That is D contains X i copies of J i for each i  For all i  m and j  m 1 let x i,j and y i,j be variables with the property that x i,j  X j  y i,j and y i,j   1 if I i  J j  0 otherwise 2 Then we have support  I i  D  x i 1    x i,m 1 and the above given ApproSUPPSAT instance could be formulated as the following question minimize z 1  z 2    z m 3 subject to                  X 1  X 2    X m 1  n s i  z i  x i 1    x i,m 1  y i,j 1 if I i  J j and y i,j 0 otherwise x i,j  X j  y i,j  z i X j are nonnegative integers  4 4 Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


for i  m and j  m 1  The condition set 4 contains the nonlinear equation x i,j  X j  y i,j and the nonlinear condition speciìed in 2 Thus in order to approximate the given ApproSUPPSAT instance using linear program techniques we need to convert these conditions to linear conditions We rst use characteristic arrays of variables to denote the unknown itemsets J 1 J m 1  For any itemset I  I letthe t ary array   I   0  1  t be the characteristic array of I Thatis,the i th component   I  i  1 if and only if e i  I Let   J 1   u 1  1 u 1 t       J m 1   u m 1  1 u m 1 t  be a collection of  m 1 t variables taking values from  0  1   representing the characteristic arrays of J 1 J m 1 respectively In order to convert the condition speciìed in 2 to linear conditions we rst use inner product constraints to represent the condition I i  J j  For two characteristic arrays  1 and  2  their inner product is deìned as  1   2   1 1   2 1     1  t    2  t   It is straightforward to show that for two itemsets I,J I wehave   I     J   min  I    J  and   I     J   I  if and only if I  J  Now the following conditions in 5 will guarantee that the condition in 2 is satisìed   I i  y i,j    J j     I i   y i,j   I i  1 y i,j u j,k  0  1  5 for all i  m  j  m 1 and k  t  The geometric interpretation of this condition is as follows If we consider    J j     I i  y i,j  as a point in the 2-dimensional space  x y  shown in Figure 1 then  I i  y  x deìnes points below the line passing the points 0  0 and   I i   1 and x  y   I i  1 deìnes the points above the line passing through the points   I i  1  0 and   I i   1  Thus y i,j 1 if and only if   J j     I i   I i  Thatis y i,j 1 if and only if I i  J j    y x 0,0 Ii|,1 Ii|ä1,0 Figure 1 Triangle The nonlinear equations x i,j  X j  y i,j can be converted to the following conditions consisting of inequalities                  x i,j  ny i,j  0  X j  x i,j  ny i,j  X j  x i,j  n x i,j  0  y i,j  0  1   6 for all i  m and j  m 1  The constant n is used in the inequalities due to the fact that X j  n for all j  m 1  The geometric interpretation for the above inequalities is described in the following If we consider  x i,j y i,j X j  as a point in a 3-dimensional space  x y X  shown in Figure 2 then 1 x  ny 0 deìnes the plane passing through points 0  0  0  0  0 n  and  n 1 n   Thus x i,j  ny i,j  0 guarantees that x i,j 0 if y i,j 0  2 X  x deìnes the points above the plane passing through points 0  0  0  0  1  0 and  n 1 n  This condition together with the condition y i,j  0  1  guarantees that x i,j  X j when y i,j 1  3 ny  X  x  n deìnes the points below the plane passing through points 0  1  0  0  0 n  and  n 1 n   This condition together with the condition y i,j  0  1  guarantees that x i,j  X j when y i,j 1  Together with the condition 2 we have x i,j  X j when y i,j 1      0, 0, 0 n, 1, n 0, 0, n x y X 0,1,0 Figure 2 Tetrahedron Note  For the reason of convenience we introduced the intermediate variables y i,j  In order to improve the linear program performance we may combine the conditions 5 and 6 to cancel the variables y i,j  Thus the integer programming formulation for the given ApproSUPPSAT instance is as follows minimize z 1  z 2    z m 7 5 Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


subject to conditions 5 6 and        X 1  X 2    X m 1  n s i  z i  x i 1    x i,m 1  z i X j are nonnegative integers  8 for i  m and j  m 1  We rst solve the linear relaxation of this integer program That is replace the second equation in the condition 5 by 0  y i,j u j,k  1 for all i  m j  m 1  and k  t and replace the third equation in the condition 8 by z i X j  0  Let o     u  j,k y  i,j x  i,j z  i X  j  i  m j  m 1 k  t  denote an optimal solution to this relaxed linear program There are several ways to construct an integer solution  o from o  Let OP T  z  I  denote the optimal value of z 1    z m for a given ApproSUPPSAT instance I and OP T  z  I  be the corresponding value for the computed integer solution For an approximation algorithm one may prefer to compute a number  such that OP T  z  I   OP T  z  I   Theorem2.3showsthatitis NP hard to approximate the ApproSUPPSAT by an additive polynomial factor Thus OP T  z  I  is not in the order of O  m  in the worst case for any polynomial time approximation algorithms and it is not very interesting to analyze the worst case for our algorithm In the full version of this paper we will describe several simple rounding methods to get an integer solution  o from o   We will also discuss improved randomized and derandomized rounding methods in the full version of the paper Complexity analysis of the approximation algorithm In the integer linear program formulation of our problem we have t  m 1 variables u j,k  m 1 variables X j  m  m 1 variables x i,j  m  m 1 variables y i,j and m variables z i Intotal,wehave t  m 1\+2 m 2 4 m 1 variables There are  m  2 m  t  constraints in the condition 5 4 m  m 1 constraints in the condition 5 and 3 m 2 constraints in the condition 8 Thus we have 6 m 2 9 m  mt  t 2 constraints in total Generally the rounding randomized and derandomized rounding algorithms the reader is referred to the full version of this paper could be nished in O  tm 3  steps Thus the major challenge is to solve the relaxed continuous variables linear program According to 6 hundreds of t housands of continuous variables are regularly solved Thus our approximation algorithm are efìcient when m and t takes reasonable values 4 Privacy issues Wang Wu and Zheng 10 cons i d ered general i nformation disclosure in the process of mock database generation In this section we discuss privacy disclosures in synthetic transaction databases Conìdential information in transaction databases may be speciìed as a collection of itemsets and their corresponding support frequency intervals Let P be a set deìned as follows P    I i s i S i  I i I i  l   We say that a synthetic transaction database D does not disclose conìdential information speciìed in P if one cannot infer that s i  support  I i  D   S i for all  I i s i S i  P  Similarly we say that a support constraint set S    I  1 s 1    I  m s m   does not disclose conìdential information speciìed in P if for each element  I i s i S i  P  there is a transaction database D i that satisìes all support constraints in S and support  I i  D i     s i S i   For the synthetic transaction database generation there are two scenarios for potential private information disclosure In the rst scenario the database owner uses the following procedure to generate the synthetic transaction database 1 use a software package to mine the real-world transaction database to get a set of itemset support frequency constraints 2 use a software package based on our linear program methods to generate a synthetic transaction database D from the support frequency constraints 3 release the synthetic transaction database D to the public In this scenario the mined support frequency constraints are not released to the public and only the synthetic transaction database is released In this case it is straightforward to protect the conìdential information speciìed in P The database owner proceeds according to the above steps until step 3  Before releasing the synthetic transaction database D  he can delete the conìdential information as follows 6 Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


 For each  I i s i S i  P  chooses a random number r i  n where n is the total number of transactions We distinguish the following two cases 1 If u i  support  I i  D   r i  0  then chooses a random series of  u i transactions t j that do not contain the itemset I i  and modify these transactions to contain the itemset I i  2 If u i  support  I i  D   r i  0  then chooses a random series of u i transactions t j that contain the itemset I i  and modify these transactions in a random way so that they do not contain the itemset I i  After the above process the resulting transaction database contains no conìdential information speciìed in P and the database owner is ready to release it In the second scenario the database owner uses the following procedure to generate the synthetic transaction database 1 use a software package to mine the real-world transaction database to get a set of itemset support frequency constraints 2 release the support frequency constraints to the public 3 a customer who has interest in a synthetic transaction database generates a synthetic transaction database D from the published support frequency constraints using a software package based on our linear program methods In this scenario the mined support frequency constraints are released to the public directly Thus the database owner wants to make sure that no conìdential information speciìed in P is contained in these support frequency constraints Without loss of generality we assume that there is a single element  I,s,S  in P and the mined support constraints are S    I i s i  i  m   S contains the conìdential information  I,s,S  if and only if for each transaction database D which is consistent with S wehave support  I  D    s S   In another word S does not contain the conìdential information  I,s,S  if and only if there exists an integer s  with s  s or S<s  n such that S  I,s    is consistent That is there is a transaction database D that satisìes all support constraints in S  I,s     In the following we show that there is even no efìcient way to approximat ely decide whether a given support constraint set contains conìdential information We rst deìne the problem formally ApproPrivacy Instance Aninteger n  an item set I  a support constraint set S    I  1 s  1      I  m s  m   andaset P    I i s i S i  I i I i  l   Question  For all transaction database D of n transactions over I with  support  I  i  D   s  i   O  m  for all 0  i  m dowehave support  I i  D    s i S i  for all i  l If the answer is yes we write S  a P  By Theorem 2.3 we have the following result Similar NP hardness results for exact frequency constraints inference have been obtained in 2 3 7 Theorem 4.1 ApproPrivacy is co NP complete Proof S 012   a P if and only if there is a transaction database D andanindex j  l such that D satisìes S  I j  support  I j  D  s i   or D satisìes S   I j  support  I j  D  S i   approximately Thus the theorem follows from Theorem 2.3 Q.E.D Thus there is no efìcient way for the database owner to decide whether a support constraint set S leaks conìdential information speciìed in P  In practice however we can use the linear program based approximation algorithms that we have discussed in Section 3 to compute the conìdence level about private information leakage as follows 1 Convert the condition S  I,s   s  s or S s   n  to an integer linear program in the format of 8 Note that the condition  s  s or S s   n  is equivalent to the existential clause  s   s  s  015  S<s   n   Thus it is straightforward to convert it to integer linear program conditions 2 Let the conìdence level be c   m i 1 z i  The smaller c  the higher conìdence In the ideal case of c 0  we have found an itemset transaction database D that witnesses that no conìdential information speciìed by  I,s,S  is leaked in S  If the database owner thinks that the conìdence value c   m i 1 z i obtained in the above procedure is too larger thus conìdence level is too low He may use the following procedure to delete potential conìdential information from the support constraint set 1 Let i be the number that maximizes max  I i s i  S  I  I i   2 Modify the value s i to be a random value 3 Approximately revise support constraint values in S to make it consistent For example to make it satisfy the monotonic rule Since it is NP hard to determine whether a support constraint set is consistent we can only revise the set S to be approximately consistent 7 Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


It should be noted that after the above process the resulting support constraint set may become inconsistent Thus in the next round the value c   m i 1 z i may be larger If that happens the larger value c does not interpret as the privacy conìdence level Instead it should be interpreted as an indicator for inconsistency of the support constraint set Thus the above privacy deletion procedure should only be carried out one time We should note that even if the conìdence level is higher that is c   m i 1 z i is small there is still possibility that the conìdential information speciìed by  I,s,S  is leaked in theory That is for each transaction database D that satisìes the constraints S wehave support  I D    s S   However no one may be able to recover this information since it is NP hard to infer this fact Support constraint inference has been extensively studied by Calders in 2 3 It would be interesting to consider conditional privacypreserving synthetic transaction database generations That is we say that no private information is leaked unless some hardness problems are solved efìciently This is similar to the methodologies that are used in public key cryptography For example we believe that RSA encryption scheme is secure unless one can factorize large integers In our case we may assume that it is hard on average to efìciently solve integer linear programs Based on this assumption we can say that unless integer linear programs could be solved efìciently on average no privacy speciìed in P is leaked by S if the computed conìdence level c   m i 1 z i is small 5 Conclusions In this paper we discussed the general problems regarding privacy preserving synthetic transaction database generation for benchmark testing purpose In particular we showed that this problem is generally NP hard Approximation algorithms for both synthetic transaction database generation and privacy leakage conìdence level approximation have been proposed These approximation algorithms include solving a continuous variable linear program According to 6 l i n ear probl ems ha vi ng hundreds of t housands of continuous variables are regularly solved Thus if the support constraint set size is in the order of hundreds of thousands then these approximation algorithms are efìcient on regular Pentium-based computers If more constraints are necessary then more powerful computers are needed to generate synthetic transaction databases References 1 R  A g r a w al T  Imilien sk i an d A  S w a mi Min in g association rules between sets of items in large databases In Proc of ACM SIGMOD International Conference on Management of Database  pages 207Ö216 1993  T  C a lders  Axiomatization and Deduction Rules for the Frequency of Itemsets  PhD Thesis Universiteit Antwerpen 2003  T  C a l ders  C omput at i onal compl e x i t y of i t e ms et frequency satisìability In Proc 23rd ACM PODS 04  pages 143Ö154 ACM Press 2004  R  F agi n J  Hal pern and N Me gi ddo A l ogi c f or reasoning about probabilities Information and Computation  87 1,2\78Ö128 1990  G Geor gak opoul os  D  K a v v a di as  a nd C  P a padi mitriou Probabilistic satisìability J of Complexity  4 1Ö11 1988  Li near P r ogrammi ng F r equent l y As k e d Q ues t i ons  http://www-unix.mcs.anl.gov/otc Guide/faq/linear-programming-faq html  T  M ielik  ainen On inverse frequent set mining In Proc of 2nd Workshop on Privacy Preserving Data Mining PPDM  pages 18Ö23 IEEE Computer Society 2003  C  P o t t s  A nal ys i s of a l i n ear programmi ng heuri s t i c for scheduling unrelated parallel machines Discrete Appl Math 10 155Ö164 1985 9 G  R amesh  W  Man iatty  a n d M Zak i Feasib le itemset distributions in data mining theory and application In Proc 22nd ACM PODS  pages 284Ö295 2003  Y  W a ng X W u  a nd Y  Zheng P r i v ac y p res ervi ng data generation for database application performance testing In Proc 1st Int Conf on Trust and Privacy in Digital Business TrustBus 04 together with DEXA  LNCS 3184 pages 142-151 2004 Springer-Verlag  X W u  Y  W u Y  W a ng and Y  Li P ri v a c y a w are mar ket basket data set generation a feasible approach for inverse frequent set mining In Proc 5th SIAM International Conference on Data Mining  April 2005  Z Zheng R  K oha vi  a nd L Mas on R eal w o rl d performance of association rule algorithms In Proc of the ACM-SIGKDD International Conference on Knowledge Discovery and Data Mining  pages 401 406 ACM Press 2001 8 Proceedings of the Fifth IEEE International Conference on Data Mining \(ICDMê05 1550-4786/05 $20.00 © 2005 IEEE 


Discovery, 8, 2004, pp. 7-23 20] W. Teng, M. Hsieh, and M. Chen. On the Mining of Substitution Rules for Statistically Dependent Items Proceedings of IEEE International Conference on Data Mining \(ICDM  02 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


14] Kryszkiewicz, M., and Rybinski, H. \(1999  Incomplete Database Issues for Representative Association Rules  ISBN: 3-540-65965-X, pp. 583-591 15] Little, R.J.A., and Rubin, D.B. \(2002 analysis with missing data, Wiley, New York, ISBN 0471183865 16] Omiecinski, E.R. \(2003  Alternative interest measures for mining associations in databases  IEEE TKDE vol. 15, no. 1, pp.57-69 17] Piramuthu, S. \(1998  Evaluating feature selection methods for learning in data mining applications  in the Proceedings of the Thirty-First Annual Hawaii International Conference on System Sciences, vol. 5, pp. 294-301 18] Pyle, D. \(1999 Morgan Kaufmann Publishers, Inc.ISBN:1-55860-529-0 19] Ragel, A., and Cremilleux, B. \(1999  MVC - A preprocessing Method to deal with missing values   knowledge based system, vol. 12, pp.285-291 20] Ramoni, M., and Sebastiani, P. \(2000  Bayesian Inference with Missing Data Using Bound and Collapse   Journal of Computational and Graphical Statistics, vol. 9, no 4, pp. 779-800 21] Ramoni, M., and Sebastiani, P. \(2001  Robust Bayes Classifiers  AI, vol. 125, no. 1-2, pp. 207-224 22] Ramoni, M., and Sebastiani, P. \(2001  Robust Learning with Missing Data  Machine Learning, vol. 45, no 2 , pp. 147-170 23] Scott, R.E. \(1993 Logic and Practice, SAGE Publications, ISBN: 0803941072 24] Zaki, M.J., and Hsiao, C.J. \(2002  CHARM: An efficient algorithm for closed itemset mining  in the Proceedings of the Second SIAM International Conference on Data Mining Proceedings of the Fourth International Conference on Hybrid Intelligent Systems \(HIS  04 0-7695-2291-2/04 $ 20.00 IEEE pre></body></html 


13: else 14: E|i?1| = E|i?1| ? s The backward process in Algorithm 1, generates level-wise every possible subset starting from the borProceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE der de?ned by Edge without getting into equivalence classes which have been already mined \(Line 10 such subset satis?es the constraint then it can be added to the output \(Line 12 reused later to generate new subsets \(Line 14 have a monotone constraint in conjunction, the backward process is stopped whenever the monotone border B+\(Th\(CM Lines 3 and 8 4.3. Closed Constrained Itemsets Miner The two techniques which have been discussed above are independent. We push monotone constraints working on the dataset, and anti-monotone constraints working on the search space. It  s clear that these two can coexist consistently. In Algorithm 2 we merge them in a Closet-like computation obtaining CCIMiner Algorithm 2 CCIMiner Input: X,D |X , C, Edge,MP5, CAM , CM X is a closed itemset D |X is the conditional dataset C is the set of closed itemsets visited so far Edge set of itemsets to be used in the BackwardMining MP5 solution itemsets discovered so far CAM , CM constraints Output: MP5 1: C = C ?X 2: if  CAM \(X 3: Edge = Edge ?X 4: else 5: if CM \(X 6: MP5 = MP5 ?X 7: for all i ? flist\(D |X 8: I = X ? {i} // new itemset avoid duplicates 9: if  Y ? C | I ? Y ? supp\(I Y then 10: D |I= ? // create conditional fp-tree 11: for all t ? D |X do 12: if CM \(X ? t 13: D |I= D |I ?{t |I  reduction 14: for all items i occurring in D |I do 15: if i /? flist\(D |I 16: D |I= D |I \\i // ?-reduction 17: for all j ? flist\(D |I 18: if supD|I \(j I 19: I = I ? {j} // accumulate closure 20: D |I= D |I \\{j 21: CCIMiner\(I,D |I , C,B,MP5, CAM , CM 22: MP5 = Backward-Mining\(Edge,MP5, CAM , CM For the details about FP-Growth and Closet see [10 16]. Here we want to outline three basic steps 1. the recursion is stopped whenever an itemset is found to violate the anti-monotone constraint CAM Line 2 2  and ? reductions are merged in to the computation by pruning every projected conditional FPTree \(as done in FP-Bonsai [7 Lines 11-16 3. the Backward-Mining has to be performed to retrieve closed itemsets of those equivalence classes which have been cut by CAM \(Line 22 5. Experimental Results The aim of our experimentation is to measure performance bene?ts given by our framework, and to quantify the information gained w.r.t. the other lossy approaches 


approaches All the tests were conducted on a Windows XP PC equipped with a 2.8GHz Pentium IV and 512MB of RAM memory, within the cygwin environment. The datasets used in our tests are those ones of the FIMI repository1, and the constraints were applied on attribute values \(e.g. price gaussian distribution within the range [0, 150000 In order to asses the information loss of the postprocessing approach followed by previous works, in Figure 4\(a lution sets given by two interpretations, i.e. |I2 \\ I1 On both datasets PUMBS and CHESS this di?erence rises up to 105 itemsets, which means about the 30 of the solution space cardinality. It is interesting to observe that the di?erence is larger for medium selective constraints. This seems quite natural since such constraints probably cut a larger number of equivalence classes of frequency In Figure 4\(b built during the mining is reported. On every dataset tested, the number of FP-trees decrease of about four orders of magnitude with the increasing of the selectivity of the constraint. This means that the technique is quite e?ective independently of the dataset Finally, in Figure 4\(c of our algorithm CCIMiner w.r.t. Closet at di?erent selectivity of the constraint. Since the post-processing approach must ?rst compute all closed frequent itemsets, we can consider Closet execution-time as a lowerbound on the post-processing approach performance Recall that CCIMiner exploits both requirements \(satisfying constraints and being closed ing time. This exploitation can give a speed up of about to two orders of magnitude, i.e. from a factor 6 with the dataset CONNECT, to a factor of 500 with the dataset CHESS. Obviously the performance improvements become stronger as the constraint become more selective 1 http://fimi.cs.helsinki.fi/data Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE Information loss Number of FP-trees generated Run time performance 0 2 4 6 8 10 12 14 x 10 5 10 0 10 1 10 2 10 3 10 4 10 5 10 6 m I 2 I 1  PUMSB@29000 CHESS @ 1200 0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 6 10 


10 1 10 2 10 3 10 4 10 5 10 6 10 7 m n u m b e r o f fp t re e s PUMSB @ 29000 CHESS @ 1200 CONNECT@11000 0 2 4 6 8 10 12 14 x 10 5 10 0 10 1 10 2 10 3 10 4 m e x e c u ti o n  ti m e  s e c  CCI Miner  \(PUMSB @ 29000 closet         \(PUMSB @ 29000 CCI Miner  \(CHESS @ 1200 closet         \(CHESS @ 1200 CCI Miner  \(CONNECT @ 11000 closet         \(CONNECT @ 11000 a b c Figure 4. Experimental results with CAM ? sum\(X.price 6. Conclusions 


6. Conclusions In this paper we have addressed the problem of mining frequent constrained closed patterns from a qualitative point of view. We have shown how previous works in literature overlooked this problem by using a postprocessing approach which is not lossless, in the sense that the whole set of constrained frequent patterns cannot be derived. Thus we have provided an accurate de?nition of constrained closed itemsets w.r.t the conciseness and losslessness of this constrained representation, and we have deeply characterized the computational problem. Finally we have shown how it is possible to quantitative push deep both requirements \(satisfying constraints and being closed process gaining performance bene?ts with the increasing of the constraint selectivity References 1] R. Agrawal, T. Imielinski, and A. N. Swami. Mining association rules between sets of items in large databases In Proceedings ACM SIGMOD, 1993 2] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules in LargeDatabases. InProceedings of the 20th VLDB, 1994 3] R. J. Bayardo. E?ciently mining long patterns from databases. In Proceedings of ACM SIGMOD, 1998 4] F. Bonchi, F. Giannotti, A.Mazzanti, andD. Pedreschi Adaptive Constraint Pushing in frequent pattern mining. In Proceedings of 7th PKDD, 2003 5] F. Bonchi, F. Giannotti, A.Mazzanti, andD. Pedreschi ExAMiner: Optimized level-wise frequent pattern mining withmonotone constraints. InProc. of ICDM, 2003 6] F. Bonchi, F. Giannotti, A.Mazzanti, andD. Pedreschi Exante: Anticipated data reduction in constrained pattern mining. In Proceedings of the 7th PKDD, 2003 7] F. Bonchi and B. Goethals. FP-Bonsai: the art of growing and pruning small fp-trees. In Proc. of the Eighth PAKDD, 2004 8] J. Boulicaut and B. Jeudy. Mining free itemsets under constraints. In International Database Engineering and Applications Symposium \(IDEAS 9] C. Bucila, J. Gehrke, D. Kifer, and W. White DualMiner: A dual-pruning algorithm for itemsets with constraints. In Proc. of the 8th ACM SIGKDD, 2002 10] J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In Proceedings of ACM SIGMOD, 2000 11] L.Jia, R. Pei, and D. Pei. Tough constraint-based frequent closed itemsets mining. In Proc.of the ACM Symposium on Applied computing, 2003 12] H. Mannila and H. Toivonen. Multiple uses of frequent sets and condensed representations: Extended abstract In Proceedings of the 2th ACM KDD, page 189, 1996 13] R. T. Ng, L. V. S. Lakshmanan, J. Han, and A. Pang Exploratory mining and pruning optimizations of constrained associations rules. In Proc. of SIGMOD, 1998 14] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal. Discovering frequent closed itemsets for association rules In Proceedings of 7th ICDT, 1999 15] J.Pei, J.Han,andL.V.S.Lakshmanan.Mining frequent item sets with convertible constraints. In \(ICDE  01 pages 433  442, 2001 16] J. Pei, J. Han, and R. Mao. CLOSET: An e?cient algorithm formining frequent closed itemsets. InACMSIGMODWorkshop on Research Issues in Data Mining and Knowledge Discovery, 2000 17] J. Pei, J. Han, and J. Wang. Closet+: Searching for the best strategies for mining frequent closed itemsets. In SIGKDD  03, August 2003 18] L. D. Raedt and S. Kramer. The levelwise version space algorithm and its application to molecular fragment ?nding. In Proc. IJCAI, 2001 


ment ?nding. In Proc. IJCAI, 2001 19] R. Srikant, Q. Vu, and R. Agrawal. Mining association rules with item constraints. In Proceedings ACM SIGKDD, 1997 20] M. J. Zaki and C.-J. Hsiao. Charm: An e?cient algorithm for closed itemsets mining. In 2nd SIAM International Conference on Data Mining, April 2002 Proceedings of the Fourth IEEE International Conference on Data Mining \(ICDM  04 0-7695-2142-8/04 $ 20.00 IEEE pre></body></html 


4] K. Chang, C. Chong, Bar-Shalom, Joint Probabilistic Data Association in Distributed Sensor Networks IEEE Transactions on Automatic Control, AC-31\(10 octobre 1986 5] Bar-shalom, Multitarget Multisensor Tracking Advanced Application ,:YBS Publishing, 1990 6] Bar-shalom, Multitarget Multisensor Tracking Principles and Techenices ,:YBS Publishing, 1995 7] Hu Wenlong, Mao shiyi, Multisensor Data Association Based on Combinatorial Optimization[J]. Journal of Systems Engineering and Electronics . 1997 NO.1,1~9 8] Pattipati K R, Passive Multisensor Data Association Using a New Relaxation Algorithm.In Multitarget-Multisensor Tracking: Advanced and Applications,Y.Barshalom,Norwood,MA:Aretech,199 0 9] Deb S,et al, An S-Dimentional Assignment Algorithm for Track Initiation ,Proc. Of the IEEE Int. Conf Systems Engineering, Kobe, Japan,Sept 1992 527~530 10] Deb S,et al, A Multisensor-Multitarget Data Association Algorithm for Heterogeneous Sensors[J].IEEE Trans. on AES 1993 ,29 \(2 560~568 12] Bar-shalom,Y.,and Fortmann,T.E  Tracking and Data Association  New York:Academic press,1988 13] J,A,Roecher and G.L.Phillis,Suboptimal Joint Probabilistic Data Association .IEEE Transaction on Aerospace Electronic Systems.1993,29\(2 14] J,A,Roecker,A Class of Near Optimal JPDA Algorithm IEEE Transaction on Aerospace and Electronic Systems,1994,30\(2 15] Han Yanfei, Analysis and Improvement of Multisensor Multitarget Probabbilistic Data Association Filting Algorithm[J].  Journal of Systems Engineering and Electronics, 2002, Vol.24, 36~38  569 pre></body></html 


dense data sets for evaluating pattern mining algorithms These two data sets are obtained from IBM Almaden at http://www.almaden.ibm.com/cs/quest/demos.html. Recently, theMAFIA algorithm [6] was proposed to ef?ciently discover maximal frequent patterns. As shown in their paper, MAFIA can be several orders better than some alternatives, such as DepthProject, for mining maximal frequent patterns. Hence, we chose MAFIA as the base line for our performance evaluation. Finally, please note that only the size-2 patterns are generated in the ?rst BFS phase Experimental Platform We implemented the MHP algorithms using C++ and all experiments were performed Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE on a Pentium III    MHz PC machine with    megabytes main memory, running Linux Redhat 6.1 operating system 5.2. A Performance Comparison 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 1e+10 1e+11 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C he ck ed P at te rn s Support threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 


Figure 4. The Number of Checked Patterns on the Pumsb* Data Set 10 100 1000 10000 100000 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 R un T im e s ec  Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 5. The RunTime Comparison on the Pumsb* Data Set Figure 4 shows the number of patterns that MHP and MAFIA have to check during the pattern mining process on the pumsb* data set. As can be seen, for MHP, the number of checked patterns is increased with the decrease of the h-con?dence threshold. However, the number of checked patterns of MHP can be signi?cantly smaller than that of MAFIA even if a low h-con?dence threshold is speci?ed To check a pattern, we need to count the support of the patterns. Counting the support of a pattern is the most timeconsuming task during the pattern mining process, since we need to retrieve all the transactions which include one of its sub-pattern, or for Ma?a, retrieve all the bit of the bitmap of this pattern [6]. Therefore, an algorithm is more ef?cient if smaller number of patterns need to be checked 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N 


um be r o f C he ck ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 6. The Number of Checked Patterns on the Pumsb Data Set 10 100 1000 10000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 R un T im e s ec  Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 7. The RunTime Comparison on the Pumsb Data Set The runtime comparison of MHP and MAFIA on the Pumsb* data set is shown in Figure 5. In the ?gure, we can observe that the runtime of MHP can be signi?cantly reduced with the increase of h-con?dence thresholds. Also the runtime of MHP can be several orders of magnitude less than that of MAFIA even if the h-con?dence threshold is as low as 0.3. The reason is that the number of checked patterns of MHP is sign?cantly smaller than that of MAFIA Similar results are also obtained from the pumsb data set as shown in Figure 6 and Figure 7. For the pumsb data set the number of checked patterns of MHP is much smaller 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207ñ216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intíl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intíl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 






NWTM Interface - The Next Wave Marketing and Technology Programme of the Department of Trade and Industry Intelligent Data Analysis for Wellbeing Monitoring Basim Majeed, Nicholas Clarke and Beum-Seuk Lee BT Laboratories, UK Trevor Martin, Bristol University, UK The IEE Printed and published by the IEE, Michael Faraday House, Six Hills Way Stevenage, Herts SG1 2AY, UK 


12 


INTELLIGENT DATA ANALYSIS FOR WELLB EING MONITORING Basim Majeed, Trevor Martin, Nicholas Clarke and Beum-Seuk Lee BT Laboratories, UK, Bristol University, UK, BT Laboratories, UK, BR Laboratories, UK ABSTRACT This paper explains how data analysis algorithms combined with a well-being modelling methodology are being employed to develop a new generation of telecare aimed at helping older people remain living more independently in their own homes for longer.  Intelligent data analysis in the form of fuzzy systems, trend analysis, pattern discovery, and association rules are applied to data obtained from non-invasive sensors to capture comprehensive information about a person’s daily activities. The Graphical User Interface \(GUI components of the Intelligent Wellbeing Monitoring System serve as a tool that increases the amount of information available to care professionals. These tools do not provide recommendations for action or make judgements as to the wellbeing of a client, instead they provide the means for a carer to investigate and track a client’s wellbeing KEY WORDS Wellbeing Analysis, Telecare Systems, Intelligent Monitoring, Intelligent Data Analysis, Sensor Network, Intelligent Environment, Fuzzy Reasoning INTRODUCTION The “Care in the Community” research programme has developed a range of low cost sensors which can detect simple events in a house, such as movement in a room, opening and closing of doors and usage of household appliances and furniture. At the same time, a high level model of well-being has been produced, highlighting a number of activities such as eating and sleeping well, social interactions etc. which can be used as indicators of a person’s general well-being. Clearly it is not possible to convert very low level data, such as the times that kitchen appliances are used, into high level statements \(the client is eating well certainty. The role of intelligent data analysis in monitoring well-being is to bridge this gap. We combine human expertise with sensor data to draw conclusions about well-being indicators with a high degree of accuracy and to draw attention to changes in behaviour \(e.g. the client is sleeping significantly less during the night Telecare and telemedicine systems have been the centre of a number of research initiatives and commercial ventures over the past few years as a result of the desire to develop intelligent systems that support independent living for the elderly and the ill. There are currently a number of systems that enable the monitoring of specific physiological parameters \(e.g. heart rate and blood pressure using sensors that are connected to a central monitoring agency over a telecommunications Nelwan, et al. \(2\from normal readings trigger alarms that the care agency or emergency services can respond to. However the concept of wellbeing is not merely defined by physiological data being w ithin normal boundaries In order to provide proper care provision for elderly people at their homes, their wellbeing must be defined more generally in terms of their physical mental, social and environmental status. A change in wellbeing is usually reflected by changes in the daily activities of the person, which may not be immediately observable, but can be detected over a longer period of time. The technology survey in Haigh and Yanco \(3\mprehensive overview of a number of research programmes that focus on recognising behavioural changes and raising alerts if appropriate British Telecommunications plc \(BT established research track record in telecare with a number of projects and trials to investigate whether lifestyle monitoring could be used to provide a proactive support service to older or vulnerable people in the community \(Garner, at al. \(4\Barnes et al. \(5 6 7\most recent BT effort in this area is its Centre for Care in the Community, under the 'Next Wave Technologies and Markets' Programme sponsored by the Department of Trade and Industry DTI\r-related activities. The first of these is carried out by the Domain Specific Modelling \(DSM responsible for developing an overall model of wellbeing in a number of vulnerable target groups and to identify activities of daily living that are potentially affected by the deterioration of the wellbeing status \(Brown, et al. \(8\ second 13 


activity is concerned with the selection of sensor hardware that can be used to monitor the identified activities, and to set-up a sensor network in the home of the monitored person \(Neild, et al. \(9 The third part of the project is to develop an intelligent monitoring and analysis system. This system is responsible for analysing sensor data in order to detect subtle changes in the ability of a person to carry out their daily living activities, and to relate these to specific aspects of their wellbeing status The rest of this paper is dedicated to the design issues and results of the work carried out on the intelligent monitoring and analysis system. Section II provides an overview of the system. Section III outlines the data analysis techniques used, and delves into the details of the pre-processing and analysis required for one of the monitored activities. Section IV describes the GUI components and their reporting functionality Section V discusses how video observations are used to validate the results of the data analysis while section VI contains the conclusions of this paper SYSTEM OVERVIEW The sensor network employed in the early phase of this project included passive infrared \(PIR\sensors to pick up occurrences of movement in various rooms, supplemented by a few toggle switch sensors to detect when windows, entrances, and the fridge-freezer are opened. Although this provided a very restricted dataset consisting of few specific details about household events, plenty of information could still be inferred as to the general level of activity within the home, and the changing location of the client. This made it possible to determine the state of a number of activities of daily living. Data collected from the sensor network is stored in a logging unit in the home, then later transmitted in batches to the service provider over standard communication networks for placement on a database server. Results are analysed and updated automatically on the server each day. To access the information, carers make use of a user-friendly web interface where they can examine behaviours on a daily basis or changing trends in activities over time. The interface program runs entirely within the browser, which performs none of the analysis Instead results are retrieved from the database server, enabling a carer with permissions to access the data from any Internet linked computer Simplified summaries of key wellbeing indicators are also available for retrieval and display on PDA devices, adding extra convenience to those who spend much of their day out of office visiting clients. The overall structure of the system is shown in Figure 1  User Interface Interface to Sensor Network Sensor Object Management Analysis Algorithms Raw Data Preprocessing Pre-Processed Data Report Data Sensor Information Report Generator Figure 1 - System Structure The system receives data from the sensor network and the “Raw Data” database gets updated daily This data is then pre-processed to remove inconsistencies and to convert it to a more suitable format for use by the analysis algorithms. Whilst the sensors deployed in each home are very reliable, on occasion sensor information is missed through interference, multiple sensor messages blocking each other, or some physical reason preventing detection. The pre-processing stage takes care of these problems by filling in the logical gaps and by filtering out implausible data. Logical gaps refer, for example, to missing OFF events in a toggle switch resulting in two consecutive ON events. Implausible data usually results from 14 


incorrect sensor firing or communication network errors The sensor management unit is responsible for organising the sensors into activity-based sensor groups, which correspond with the activities of daily living that the domain specific modelling work has identified as essential for the wellbeing status \(8\mple one group lists all sensors monitoring the home entrances, such that the system can attempt to infer when visitors arrive and the client goes out. All sensor specific information is stored in a sensor library so that it can be retrieved, modified, extended or deleted allowing the system to adapt to sensor network changes Aside from activity groups, sensor information includes sensor type \(PIR, toggle switch boolean real,…etc\ormation can then be used during pre-processing to help detect any inconsistencies in data received and to flag instances of sensor failure The system is equipped with a number of data analysis methods that convert the pre-processed data into answers to specific well-being status questions. These answers are conveyed to the user by the report generator through the main graphical user interface DATA ANALYSIS TECHNIQUES The work of the DSM group concluded that the focus of this project should restrict itself to the frail elderly target group, and limit the number of monitored activities to just six \(8\mely  Leaving and returning home  Receiving visitors  Preparing food and eating  Sleeping patterns  Personal appearance  Leisure activities A thorough understanding of each of these activities was needed in order to build a system that can monitor them. A number of questions relating to each of the activities were generated and posed to the data analysis team in order to provide answers that can indicate the status of the activity and its contribution to the well-being of the client The analysis methods include fuzzy reasoning statistics, association analysis, and trend analysis 11\Kruse, et al. \(12\The following subsection describes in detail the data pre-processing and analysis approach taken to address one example of activity monitoring, namely the client’s interaction with visitors. Similar methods have been used to monitor the other activities listed Visitor Detection Process The purpose of the visitor detection process is to discover periods of time during which visitors are present in the house of a single-occupant client. The absence of intrusive sensing hardware such as personal identification tags and video cameras has introduced a degree of ambiguity in terms of the identity of the person performing an activity, and in terms of the number of people in the home at any one period of time. As a result, fuzzy reasoning methods are employed by the visitor detection process to establish a degree of confidence in the existence of visitors at any moment of time. The detection process runs through the input database in time order, noting important entrance events and periods classed as either active or inactive. Each time an entrance event is discovered in the database, the system analyses the periods immediately prior and subsequent to this event such that changes in behaviour, perhaps caused by visitors can be assessed. This is achieved by scanning forwards and backwards through the summarised entrance data between periods where the house is recorded as empty, combining evidences of people entering and leaving to produce confidences of multiple occupancy at any one time Behavioural Comparisons The simplified data in Figure 2 shows motions detected \(white a one-hour period in the home of a single occupancy client. The data segment has been split into three regions \(A, B, C entrance events observed, such that each region denotes a time during which the number of persons in the home should remain constant. By comparing behaviours exhibited in reg ions neighbouring an entrance event, it is possible to determine those likely to correspond with persons arriving, leaving or simply interacting with someone on the doorstep Figure 2 - An Example of Household Motion Detectors Data Several characteristics of neighbouring regions may be compared, the choice of which is constrained by the type of data available. From the data gathered so far in the trials, we made the fuzzy comparisons 15 


following. Figure 2 serves as an example case, but note that regions A and C continue beyond the boundaries of the graphic  ined as the proportion of time in which motion or object use was detected so visually this is the average density of the white areas in the combined row for regions in Figure 2 The assumption made is that as more people enter the home, so on average the number of activities detected will rise, and this difference in levels between the regions is converted to a fuzzy value for use in visitor detection rules Using an early section of the data as a training set the system is able to normalise observed changes and also adjust the default fuzzy sets to increase or decrease sensitivity as needed. In general, the more active the client, the more sensitive the system must be, as visitors cause less obvious observable impact on the data. Figure 3 shows an example of changes in sensitivity. The left side shows the default set definitions, best suited to a uniform distribution of activity changes. On the right, a more sensitive trained set was formed by averaging the default sets with the sets produced from the training data of one client Figure 3 - Fuzzy Sets Denoting Change in Activity Levels. Default sets \(top\and Learned sets \(bottom Note that we average an absolute \(default distribution with a relative \(data\on, to avoid two main problems. The first is poor levels of sensitivity using absolute values, and the second is the problem of equal data splitting in the training set \(e.g. Assuming 20% of changes in the training set are “big rises” is clearly not correct\also important to realise that every home will have an individual set of sensors recording information meaning that the amount of data collected can vary greatly from home to home. Depending on the type of data collected, some homes will need more sensitive visitor detection than others. In a similar manner, the “Changing Rooms” measure \(see below\onverted to fuzzy values. An example value returned from the learned set based on the data in Figure 2 is A  B = Big Rise 1.00 2. Changing Rooms Level m e asure of how often the room in which activities are currently detected changes. It is assumed that as visitors enter the home, some activities will take place simultaneously in different rooms, causing the data to apparently show very frequent changes. The value returned is based on the weighted average of three measures. 50% of the result is based upon the rate of apparent room changes. 25% comes from the ratio of those room changes deemed impossible for one person to make, e.g. lounge to bathroom without passing through the hall. The last 25 comes from the longest sequence of impossible room changes. With a single occupant this level is usually very low, but in the case of two people in two separate rooms far apart in the home, long sequences of impossible room changes occur very frequently, in contrast making all three measures very high. For the example in Figure 2, there is no evidence of any impossible room changes; hence the changing rooms levels are not at all extreme Knowledge regarding impossible room changes is derived using two pieces of information, the first is the sensor installation information, which provides accessibility information about each sensor location. The second piece of information is developed during the training period, and it shows the probability of room changes during that period The result returned for regions A and B in this case is A  B = Steady 0.189, Rise 0.811 3. Delay Time is a measure of how long it takes before the activity level shows signs of the change recorded. This is obtained by use of a sliding window, and the delay is the time taken before the activity level within the window is closer to the activity level for the second region than the first Figure 4 - Activity Levels for Regions A, B, and a Sliding Window W In Figure 4, the very first window has an activity level closer to that of region B than A, hence the delay time in this case is zero, an instantaneous change. Short delays such as this are consistent with changes to the number of persons in the home while long delays are more consistent with a 16 


coincidental later change in behaviour, such as a person becoming more active to cook dinner A  B = Short 1.000 4. Hallway Time either side of a door event adds more clues, such as whether or not a person has been let in, seen out, or is taking off and unpacking some items after coming inside. Unfortunately the data used to calculate this period is difficult to accurately assess, as the data may show a change in room because of a single person leaving the hall, or a second person moving in another room. The current implementation may cause occasional underestimates of the true value, whereas an implementation using a window either side of an entrance event would cause overestimates. Again values for the data in Figure 2 are given Before: A  B = Zero After: A  B = Short 1.000 5. Door Open Time is the time during which the door was open. Longer times imply a higher likelihood of visitors remaining outside if there is no evidence of others entering the home; otherwise a long time is consistent with guests bringing items inside A  B = Short 1.000 Note that the various parameter values and default settings listed in this analysis are not hard-coded and are instead stored in a parameter database. This allows for simple manual changes to the algorithms and the possibility of creating a data-scanning program that could determine the optimal settings Applying the Fuzzy Rules Once the data has been converted into fuzzy descriptions, fuzzy rules can be applied to describe the likelihood that visitors did indeed arrive and leave during those door events. These rules are mainly derived by domain experts, with the help of sensor and data analysis experts. For example, as the house is occupied by at least one person in regions A & B the visitor entry rules matching the data given by the AB door event are listed below. \(Note that the output of the rules is a fuzzy set Rule 1 If hallway time before a door event is zero then visitors = likely. \(Implies visitor is also a key holder  Membership for Likely = 1 Rule 2 If delay time is short, and activity levels are some rise, and changing rooms levels are some rise, and time in hallway after door shuts is short then visitors arrived = probably Membership for Probably = 0.811 Rule 3 If delay time is short, and activity levels are a big rise, and changing rooms levels are steady and time in hallway after door shuts is short, then visitors arrived = fifty-fifty Membership for Fifty-Fifty = 0.189 Note: “some rise” is a fuzzy set whose function is equivalent to the sum of the functions used for rise” and “big rise”. The functions “rise” and “big rise” are also defined such that where these sets overlap, the sum of their membership functions is always 1 Figure 5 - Fuzzy Output for Visitor Entry at the AB Door Event As shaded grey in Figure 5, employing various rules can result in differing assessments of the data To defuzzify these results, the horizontal centre of gravity of the shaded area, denoted c in the graph is taken as the consensus of opinion. Dependant on its use, either the value 0.841 or a description such as “quite likely” could be returned As no person was detected in the hall immediately before the door event, it could be argued a visitor must have arrived. However, this may have been caused by a sensor failing to detect the person which occasionally happens. By taking account of multiple pieces of evidence, the results returned are much more reliable, suffering from fewer large errors The door event BC also has a high probability for visitors leaving at that point. This would be considered along with the AB result to reach a conclusion that there is a strong likelihood that the twenty-minute period of region B was associated with a visitor in the home THE USER INTERFACE \(GUI COMPONENTS Users interact with the system using a number of GUI components such as the sensor management component and the parameter setting component The component of main interest however, is the data display and analys is component which displays the analysis results to the caregiver. The GUI is split into two main components, namely the calendar view and the analysis reporting views 17 


These views are discussed below together with some of the data analysis aspects behind them The Calendar View The calendar view is shown in Figure 6 in greyscale. The original view uses a colouring scheme to convey information to the user. This view allows the user to select individual days for detailed examination, and highlights days where unusual activity has taken place. The coloured controls on the calendars indicate the normality of the daily patterns. The dates in any of yellow, blue or green colours are likely to contain unusual events in comparison to the learnt normal behaviour according to the following scheme \(unfortunately it is difficult to see these effects on the greyscale image  Yellow indicates the amount of normally occurring events that are missing  Blue represents the amount of unusual extra events observed  Green illustrates a combination of both missing and extra events  Pale Red means the day is ignored in the analysis process, usually because the day doesn’t have enough data due to sensor or communication failure The intensity of colour \(apart from red the degree of abnormality, so a brighter yellow indicates a greater number of missing events for example. The normal behaviour is learnt from the history of the data using a combination of fuzzy logic, statistics and association rule mining Figure 6 - The Calendar View THE ANALYSES REPORTING VIEWS A number of views provide specific information regarding the well-being status questions discussed earlier. The first daily activity plot displays sensor data and inferred activities of the client on the currently selected day. This is composed of the control panel on the left side and a 24-hour coloured plot of data on the right, as shown in Figure 7 \(Note that the original view is colour intensive\ contains three groups of information from the pre-processed sensor data each of which are fully listed for selection in the control panel 1 Activity group - The first group, forming the majority of the view, lists all the individual sensors, for example, front door open/close bed occupied, kitchen PIR, etc. This first group also contains the 'activity' level constructed as the aggregate of all PIR sensor firings in 5 minute periods silence' \(long periods where no data was observed 2 Location group - The second group lists all the individual PIR sensors Their data is condensed onto one timeline with coloured stripes representing the rooms where and when motions were detected 3 Abstract group - The third group contains the abstracted activities such as ASLEEP OUT, INACTIVE, VISITOR, and BATH The VISITOR activity differs from the others in that its colour is displayed brighter toward yellow\idence for a visitor being present increases. The confidence level is a result of applying fuzzy reasoning as described in detail in Section III. In addition to ASLEEP, there are also the minor activities of DRIFTING WAKING, and STIRRING events that indicate the periods before, after and disturbances during the sleep periods respectively. These and all other activities are inferred by analysing the data from the relevant sensor activity group 18 


Figure 7 - Daily Activity View Another important view is used to display changes of the wellbeing-related values such as sleeping eating, going out, and having visitors. Original values, their moving average, plus changes in trend can all be shown. To make the system userfriendly, analyses are chosen from a list of questions relating to wellbeing and derived from the wellbeing model of the DSM group. For example, “Is the duration of the main sleep-period increasing or decreasing?” has been selected in Figure 8, and the time the client has spent sleeping over the past month is automatically displayed Figure 8 - Trend Plot of the Sleep Activity RESULTS VALIDATION For validation, simple diary style records are collected by occasionally telephoning the client about their day over a period of several weeks supplemented by a week of video footage where clients will be filmed doing non-private activities in limited areas of their home. The first purpose of validation is to assess the system, both in terms of sensor performance and activities detected. The second is to help identify how the sensor network could be improved such that clearer data is produced. Currently five major activity types are inferred. These are sleeping, going out, hosting visitors, extended bathroom use, plus inactivity Some video evidence has been examined, although due to the restrictions on the allowed camera position, there is no video with which to confirm sleeping or bathroom activities. Inactive periods are simply defined by an absence of sensor data, and the video shows the client almost motionless usually reading or watching television during these times. Of the remaining activities, the video has so far shown the telecare system correctly determines 19 


periods when the client is out and visitors are in the home, although the system can on occasion be fooled into inferring a visitor by unusual client behaviour Example Going Out Known Start Time Known End Time Inferred Start Time Inferred End Time 22/08/05, 14:16:00 17:08:00  14:16:44 17:07:59 23/08/05, 13:53:00 15:52:00  13:53:04 15:52:43 Example Visitors The column “Conf.” lists the confidence with which the system believes a visitor is present. The confidence figure is a percentage representation of the fuzzy value resulting from applying the rules for example a centre of gravity of 50 is displayed as 50 Known Start Time Known End Time Inferred Start Time Inferred End Time Conf 30/08/05, 11:03:39 11:35:21 11:03:39 11:35:21 61 N/A N/A 30/08/05, 11:35:21 11:42:39 48 30/08/05, 11:42:49 11:47:56 11:42:39 11:47:56 75 In the above case, the system has given a 48 confidence of a visitor being present during a period when there was none. This is in large part due to the system assuming that one possibility to explain the data is that the time from 11:03:39 to 11:47:56 is just one long visit, and the period 11:35:21 to 11:42:39 is simply a quieter period with less apparent room changes and coincidental entrance events Figure 9 compares the data from the periods described above \(left\nd data from 23/08/05 starting from 10:20 am and continuing till 11:20 am right\idences of the visitor periods illustrated in this second case are 57% and 49 respectively, and their data looks very similar to that of the first visitor period starting at 11:03am on 30/08/05. The second case was caused by the client cleaning the home, starting with the entrance causing an entrance event to be associated with a significant change in household activity Figure 9 - Similar Data from Actual Visits \(left\an d Cleaning by th e Client \(right In both cases it appears possible that early in the periods one person could be using the bathroom whilst the other is elsewhere in the home. However the rest of the data shows virtually no evidence of 20 


two rooms being occupied at once, although compared to data outside the range of these graphics, the activity level is significantly higher between the relevant entrance events. The system thus reports visiting periods with relatively low confidences to reflect the level of uncertainty Several parameters within the visitor detection process can be changed, and by comparing data from further actual visits to detected visits, optimal values for each of our parameters can be reached So far however, too few actual visits have been identified with which to confidently determine adjustments that would increase accuracy in the majority of cases Aside from the activities already discussed, the recently extended sensor network has also provided the opportunity to infer further activities relating to food preparation and piped water usage, plus watching television and using the phone. However detailed validation information has only very recently become available, and the time-consuming examination and comparisons with sensor reported and inferred results continues along with development of their inference methods. However current observations indicate that phone usage is detected very accurately and television viewing is largely inferred correctly, although as these sensors record interaction with the devices, this is as expected Example Television Watching The major assumption made about watching television is that the client would be seemingly inactive for several minutes at a time, hence this is basically an adaptation from the inactivity detection Known Start Time Known End Time Inferred Start Time Inferred End Time 20/08/05, 17:15:33 17:23:40 20/08/05, 17:15:19 18:26:14 20/08/05, 17:24:58 18:26:18 20/08/05, 18:37:05 00:09:45  N/A N/A 20/08/05, 21:01:30 21:07:52  20/08/05, 21:01:45 21:08:42 20/08/05, 21:19:09 21:32:14  20/08/05, 21:14:20 21:32:03 20/08/05, 22:05:35 22:36:20  20/08/05, 22:08:12 22:33:19 The first watching period has had two separate periods inferred, as between these periods the client is very active presumably cleaning up after finishing the snack eaten during the first period The second short viewing period was not detected because the client was constantly active after a phone call and then left the room. The third period was detected very accurately, and the fourth period is only “inaccurate” in starting time because the client was reading a newspaper for five minutes whilst having the television on. The fifth inferred period is a slightly smaller than the actual period due to the high activity whilst the client settles down and later begins to leave the room Note that errors with determining television viewing occur because we have no knowledge as to whether or not the television is actually on nor can we tell if the client is actually looking at the television or just has it on in the background. We do have several methods for easily increasing the accuracy of these specific results, but more validation data needs to be examined before we can be justified in applying these methods to all the data CONCLUSIONS Telecare systems aim to carry out intelligent analyses of a person’s wellbeing using data about their daily activities. This is a very challenging task for a number of reasons. First of all, the sensors were designed to be completely non-intrusive which excludes the use of any form of tagging for personal identification. This means that the decision reached by any analysis algorithm will always contain a degree of ambiguity in terms of the identity of the person performing an activity, and in terms of the number of people in the home at any one period of time The second issue is related to the fact that people tend to change their behaviour and perform unpredictable actions that cannot be learnt Combined with the type of sensors that can be used this means that the ability of the data analysis engine to make decisions has a significant error rate. For example, consider the bed sensors, which cannot distinguish between a person lying in bed from a heavy object placed on the bed. The fact is that no matter how many sensors are installed, the decision making process will always be associated with some uncertainty. This is why all the data is processed using the techniques of fuzzy systems 21 


which exploit the tolerance for imprecision and uncertainty The third factor is related to evidence collection for the purpose of learning and validation of the analysis results. In this project, simple diary style records are collected by occa sionally telephoning the client about their day over a period of several weeks, supplemented by a week of video footage where clients are filmed doing non-private activities in limited areas of their home. The problem with the diary records is that they introduce an element of intrusion that can become a nuisance for the clients after a period of time and leads to them not treating it seriously enough to record their activities correctly. As for the video evidence, cameras were not installed in bedrooms or bathrooms for privacy reasons and thus they provide an incomplete picture of the activities In spite of limited sensor information, we have shown that it is possible to answer the majority of questions regarding a person’s behaviour and wellbeing. Periods of sleep and where the client leaves the home are easily monitored, allowing for effective normality modelling and long-term trend analyses of these periods Although many other important events such as preparing meals, preparing to go out, and hosting visitors have proved more difficult to accurately infer, the measures produced are still worthy of tracking over time. If for instance there is a decrease in the amount and confidence of visits detected, it is likely that visitor numbers have indeed dropped, and the rough data has thus served its desired purpose. Eliminating all uncertainties is clearly impossible with the sensors employed in this study, and it is likely that no matter what sensors are deployed in a fully non-invasive system, this problem will remain to a certain degree. The challenge therefore remains of how to extract the maximum amount of knowledge using a system that imposes a minimum level of intrusion REFERENCES 1 Website http://www.americantelecare.com 2 S. P. Nelwan et al, 2002, “Ubiquitous mobile access to real-time patient monitoring data”. Computers in Cardiology vol. 29, pp. 557-560 Sept. 2002 3 K. Z. Haigh and H. A. Yanco, 2002 Automation as caregiver: A survey of issues and technologies”. AAAI 02 Workshop “Automation as Caregiver” , pp 39-53 July 2002 4 P. Garner et al, 1997, “The application of telepresence in medicine”. Journal of Telemedicine and Telecare, vol. 15, No. 4 pp.181-187, Oct. 1997 5 N. Barnes et al, 1998, “Lifestyle Monitoring technology for supported independence Computing & Control Engineering Journal vol.9, No.4, pp. 169-174, Aug. 1998 6 D. Nauck and B. Majeed, 2004, “Automatic Intelligent Data Analysis in Sensor Networks for iSpaces”, BT Technology Journal, vol. 22, No.3, July 2004, pp 216224 7 D. Rose, B. Egan and P. Yung, 2003 Modelling of PIR data from a Telecare trial”. BT Technology Journal, vol. 21, No 2, April 2003, pp 101-111 8 S. Brown, N. Hine, A Sixsmith and P Garner, 2004, “Care in the Community”, BT Technology Journal, vol. 22, No.3, July 2004, pp 56-64 9 I. Neild, D. Heatley, R. Kalawsky and P Bowman, 2004, “Sensor Networks for Continuous Health Monitoring”, BT Technology Journal, vol. 22, No.3, July 2004, pp130-139 10 M. Berthold and D. Hand, 1999, “Intelligent Data Analysis”, Springer, 1999 11 L. Zadeh, 1994, “Soft computing and fuzzy logic”, IEEE Software, vol. 11, No. 6 November 1994, pp 48-56 12 R. Kruse, J. Gebhardt and F. Klawonn F 1994, “Foundations of Fuzzy Systems Wiley, Chichester,1994 22 


1 client using UIR 100 clients using UIR 200 clients using UIR Figure 5. The percentage of reduced uplink requests scheme and the UIR scheme. Generally speaking, using our CMIP scheme, the percentage of reduced uplink requests increases as the cache size increases. After the cache size reaches 120, the percentage no longer changes. This can be explained as follows. As the cache size increases, more and more important data items having high access probability can be stored in the cache. When the cache size is still not large enough, the cache hit ratio will increase sharply when cache size increases. As a result, the rate of reduced uplink requests is higher than the arrival rate of new requests Thus, the percentage of reduced uplink requests has a trend of increasing. When the cache size is big enough to hold all the items within our prefetch sets, the rate of reduced uplink requests is no long signi?cant to the arrival rate of new requests. Hence, the percentage of reduced uplink requests no longer changes after reaching a certain cache size From Figure 5, we also notice that although the trend of the percentage of reduced uplink requests is increasing there are some ups and downs. For example, when the number of clients is 200, the percentage of reduced uplink requests reaches the peak when the cache size is about 50 As the cache size continues increasing, the percentage begins to decrease a little bit, and then it increases again. This can be explained as follows. As the cache size increases more queries can be served within the cache. So, the number of reduced uplink requests keeps increasing. Depending on the access patterns of the clients, the number of reduced uplink requests may increase at a rate higher or lower than the increase of the number of requests. If the rate is higher, the percentage of reduced uplink requests will increase. If the rate is lower, the percentage will decrease instead. Thus, there are some ups and downs in the percentage of reduced uplink requests, although the trend is increasing Figure 5 also shows that our CMIP scheme outperforms the UIR scheme with various cache sizes and various number of mobile clients. The percentage of reduced uplinks using the CMIP scheme is twice as much as that of usProceedings of the 2004 IEEE International Conference on Mobile Data Management \(MDM  04 0-7695-2070-7/04 $20.00  2004 IEEE ing the UIR scheme. In term of percentage of reduced uplink request, even the worst case of the CMIP scheme is better than the best case of the UIR scheme. For instance the CMIP scheme has the worse performance when there is one mobile client and the percentage of reduced uplinks is about 6% \(7.5% at best achieves its best performance when there are 200 mobile clients with about 3% of reduced uplinks. This is because the CMIP scheme can better predict the future access of the clients and prefetch them in advance than the UIR scheme Hence, the CMIP scheme can reduce the uplink requests at a percentage much higher than the UIR scheme 3.2.3. The Percentage of Additional Traf?c. The percentage of additional traf?c is de?ned as the ratio of the number of prefetches from the broadcast channel to the number of requests. As we know, downloading a data item from the channel also consumes a lot of system resources such as the bandwidth and the power. So the prefetch scheme should not do aggressive prefetching; otherwise it will consume too much system resources. This is especially important in mobile environments, where the system resource is very limited One argument about this metric is that the percentage of additional traf?c depends on the number of requests that are quite application-dependent and it does not make much sense to compare on this metric. We argue that this met 


sense to compare on this metric. We argue that this metric, when combined with other metric, such as the cache hit ratio, can well describe a prefetch scheme  s ef?ciency and predictability. A good prefetch scheme should be able to improve the cache hit ratio without incurring too much additional traf?c \(or prefetches pares the two schemes in term of the percentage of additional traf?c Figure 6\(a more additional traf?c to the system. For example, the percentage of additional traf?c for UIR scheme is up to 20 when there are 200 clients. This is because the UIR scheme is an aggressive prefetch scheme. Whenever a data item within the cache has been updated and is broadcasted on the channel, the client will download it and update the cache But for the CMIP scheme, the percentage of additional traf?c to the system is negligible, as shown in Figure 6\(b example, the percentage is lower than 0.5% when cache size becomes larger than 100. Why the percentage of additional traf?c is so small is due to the characteristic of our CMIP scheme. Using the CMIP scheme, only those data items which are within our prefetch sets are prefetched The data items within prefetch sets are got from association rules with a high con?dence and support. So the set of data items to be prefetch is small and the number of prefetches is also small. This explains why the percentage of additional traf?c is negligible Figure 6\(c percentage of additional traf?c when there are 200 mobile clients. From 6\(c curs only a fraction of 20 of the percentage of additional traf?c incurred by the UIR scheme. By far, we can say that our CMIP scheme is much better than the UIR scheme and the NOPRE scheme in terms of increased cache hit ratio reduced uplink requests and negligible additional traf?c 4. Related Work In the literature, prefetch technique is widely employed to reduce the access latency in WWW environments [17 16, 8, 12, 9]. [17] presents a predictive prefetching scheme for the World Wide Web in which the server tells the clients which ?les are likely to be requested by the user, and the clients decide whether to prefetch these ?les or not based on local considerations \(such as the contents of the local cache  posed. This scheme predicts the ?les  future access probabilities based on the access history and the network condition. The scheme allows the prefetching of a ?le only if the access probability of the ?le is greater than a function of the system bandwidth, delay and retrieval time. In [9], Cohen and Kaplan investigate three other types of prefetching in web: pre-resolving host-names \(pre-performing DNS lookup prefetching TCP connections prior to issuance of HTTP request sending a  dummy  HTTP HEAD request to Web servers  velops a new method for prefetching Web pages into the client cache. Clients send reference information to the Web server, which aggregates the reference information in nearreal-time and then disperses the aggregated information to all clients, piggybacked on GET responses. The information indicates how often hyperlink URLs embedded in pages have been previously accessed relative to the embedding page. Based on the knowledge about which hyperlinks are generally popular, clients initiate prefetching of the hyperlinks and their embedded images according to any algorithm they prefer Most of these work were not designed for mobile environments and did not consider the constraints of mobile environments. Recently, several prefetch schemes have been proposed as a client-side technique to reduce the access latency in mobile environments [1, 13, 6, 19]. In [1], a simple prefetching heuristic, called PT, computes the value of 


ple prefetching heuristic, called PT, computes the value of a page by taking the product of the probability \(P cessing of the page with the time \(T fore that page appears on the broadcast again. PT ?nds the page in the cache with the lowest pt value and replaces it with the current broadcast page if the latter has a higher pt value. However, this time-based prefetch scheme is expensive to implement since it computes the pt for each item in Proceedings of the 2004 IEEE International Conference on Mobile Data Management \(MDM  04 0-7695-2070-7/04 $20.00  2004 IEEE 0 5 10 15 20 0  50  100  150  200  250  300 Th e pe rc en ta ge o f a dd iti on al tr af fic Cache size 1 client using UIR 100 clients using UIR 200 clients using UIR 0 0.5 1 1.5 2 2.5 3 3.5 4 0  50  100  150  200  250  300 Th e pe rc en ta ge o f a dd iti on al tr af fic Cache size 1 client using CMIP 100 clients using CMIP 200 clients using CMIP a b 0 5 10 15 


20 0  50  100  150  200  250  300 Pe rc en ta ge o f a dd iti on al tr af fic Cache size 200 clients using CMIP 200 clients using UIR c Figure 6. The percentage of additional traf?c the cache at every clock tick. A similar scheme has been proposed in [13], which uses fv, a function of the access rate of the data item only, to evaluate the value of each data item i that becomes available to the client on the channel If there exists a data item j in the client  s cache such that fv\(i j replaced with i A prefetch scheme based on the cache locality, called UIR scheme, was proposed in [7]. It assumes that a client has a large chance to access the invalidated cache items in the near future. It proposes to prefetch these data items if it is possible to increase the cache hit ratio. In [6], Cao improves the UIR scheme by reducing some unnecessary prefetches based on the prefetch access ratio \(PAR scheme, the client records how many times a cached data item has been accessed and prefetched, respectively. It then calculates the PAR, which is the number of prefetches divided by the number of accesses, for each data item. If the PAR is less than one, it means that the data item has been accessed a number of times and hence the prefetching is useful. The clients can mark data items as non-prefetching when PAR &gt; b, where b is a system tuning factor. The scheme proposes to change the value of b dynamically according to power consumption. This can make the prefetch scheme adaptable, but no clear methodology as to how and when b should be changed. Yin et al. [19] proposed a power-aware prefetch scheme, called value-based adaptive prefetch \(VAP the number of prefetches based on the current energy level to prolong the system running time. The VAP scheme de?nes a value function which can optimize the prefetch cost to achieve better performance These existing schemes have ignored the following characteristics of a mobile environment: \(1 query some data items frequently, \(2 during a period of time are related to each other, \(3 miss is not a isolated events; a cache miss is often followed by a series of cache misses, \(4 eral requests in one uplink request consumes little additional bandwidth but reduces the number of future uplink requests. In this paper, we addressed these issues using a cache-miss-initiated prefetch scheme, which is based on association rule mining technique. Association rule mining is a widely used technique in ?nding the relationships among data items. The problem of ?nding association rules among items is clearly de?ned by Agrawal et al. in [5]. However in the mobile environment, one cannot apply the existing association rule mining algorithm [4] directly because it is too complex and expensive to use This makes our algorithm different from that of [4] in 


This makes our algorithm different from that of [4] in twofold. First, we are interested in rules with only one data item in the antecedent and several data items in the consequent. Our motivation is to prefetch several data items which are highly related to the cache-miss data item within Proceedings of the 2004 IEEE International Conference on Mobile Data Management \(MDM  04 0-7695-2070-7/04 $20.00  2004 IEEE the cache-miss initiated uplink request. We want to generate rules where the antecedent is one data item, but the cache-missed data item and the consequent is a series of data items, which are highly related to the antecedent. If we have such rules, we can easily ?nd the data items which should also be piggybacked in the uplink request. Second in mobile environment, the client  s computation and power resources are limited. Thus, the rule-mining process should not be too complex and resource expensive. It should not take a long time to mine the rules. It should not have high computation overhead. However, most of the association rule mining algorithms [4, 5] have high computation requirements to generate such rules 5. Conclusions Client-side prefetching technique can be used to improve system performance in mobile environments. However, prefetching also consumes a large amount of system resources such as computation power and energy. Thus, it is very important to only prefetch the right data. In this paper, we proposed a cache-miss-initiated prefetch \(CMIP scheme to help the mobile clients prefetch the right data The CMIP scheme relies on two prefetch sets: the alwaysprefetch set and the miss-prefetch set. Novel association rule based algorithms were proposed to construct these prefetch sets. When a cache miss happens, instead of sending an uplink request to only ask for the cache-missed data item, the client requests several items, which are within the miss-prefetch set, to reduce future cache misses. Detailed experimental results veri?ed that the CMIP scheme can greatly improve the system performance in terms of increased cache hit ratio, reduced uplink requests and negligible additional traf?c References 1] S. Acharya, M. Franklin, and S. Zdonik. Prefetching From a Broadcast Disk. Proc. Int  l Conf. on Data Eng., pages 276  285, Feb. 1996 2] S. Acharya, M. Franklin, and S. Zdonik. Balancing Push and Pull for Data Broadcast. Proc. ACM SIGMOD, pages 183  194, May 1997 3] S. Acharya, R. Alonso, M. Franklin, and S. Zdonik. Broadcast disks: Data Management for Asymmetric Communication Environments. Proc. ACM SIGMOD, pages 199  210 May 1995 4] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In J. B. Bocca, M. Jarke, and C. Zaniolo editors, Proc. 20th Int. Conf. Very Large Data Bases, VLDB pages 487  499. Morgan Kaufmann, 12  15 1994 5] R. Agrawal, Tomasz Imielinski, and Arun Swami. Mining Association Rules Between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207  216, Washington, D.C May 1993 6] G. Cao. Proactive Power-Aware Cache Management for Mobile Computing Systems. IEEE Transactions on Computers, 51\(6  621, June 2002 7] G. Cao. A Scalable Low-Latency Cache Invalidation Strategy for Mobile Environments. IEEE Transactions on Knowledge and Data Engineering, 15\(5 ber/October 2003 \(A preliminary version appeared in ACM MobiCom  00 8] K. Chinen and S. Yamaguchi. An Interactive Prefetching Proxy Server for Improvement of WWW Latency. In Proc INET 97, June 1997 9] E. Cohen and H. Kaplan. Prefetching the means for docu 


9] E. Cohen and H. Kaplan. Prefetching the means for document transfer: A new approach for reducing web latency. In Proceedings of IEEE INFOCOM, pages 854  863, 2000 10] R. Cooley, B. Mobasher, and J. Srivastava. Data preparation for mining world wide web browsing patterns. Knowledge and Information Systems, 1\(1  32, 1999 11] C. R. Cunha, Azer Bestavros, and Mark E. Crovella. Characteristics of WWW Client Based Traces. Technical Report TR-95-010, Boston University, CS Dept, Boston, MA 02215, July 1995 12] D. Duchamp. Prefetching hyperlinks. In USENIX Symposium on Internet Technologies and Systems \(USITS  99 1999 13] V. Grassi. Prefetching Policies for Energy Saving and Latency Reduction in a Wireless Broadcast Data Delivery System. In ACM MSWIM 2000, Boston MA, 2000 14] S. Hameed and N. Vaidya. Ef?cient Algorithms for Scheduling Data Broadcast. ACM/Baltzer Wireless Networks \(WINET  193, May 1999 15] Q. Hu and D. Lee. Cache Algorithms based on Adaptive Invalidation Reports for Mobile Environments. Cluster Computing, pages 39  48, Feb. 1998 16] Z. Jiang and L. Kleinrock. An Adaptive Network Prefetch Scheme. IEEE Journal on Selected Areas in Communications, 16\(3  11, April 1998 17] V. Padmanabhan and J. Mogul. Using Predictive Prefetching to Improve World Wide Web Latency. Computer Communication Review, pages 22  36, July 1996 18] N. Vaidya and S. Hameed. Scheduling Data Broadcast in Asymmetric Communication Environments. ACM/Baltzer Wireless Networks \(WINET  182, May 1999 19] L. Yin, G. Cao, C. Das, and A. Ashraf. Power-Aware Prefetch in Mobile Environments. IEEE International Conference on Distributed Computing Systems \(ICDCS 2002 Proceedings of the 2004 IEEE International Conference on Mobile Data Management \(MDM  04 0-7695-2070-7/04 $20.00  2004 IEEE pre></body></html 


um be r o f C he ck ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 6. The Number of Checked Patterns on the Pumsb Data Set 10 100 1000 10000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 R un T im e s ec  Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 7. The RunTime Comparison on the Pumsb Data Set The runtime comparison of MHP and MAFIA on the Pumsb* data set is shown in Figure 5. In the ?gure, we can observe that the runtime of MHP can be signi?cantly reduced with the increase of h-con?dence thresholds. Also the runtime of MHP can be several orders of magnitude less than that of MAFIA even if the h-con?dence threshold is as low as 0.3. The reason is that the number of checked patterns of MHP is sign?cantly smaller than that of MAFIA Similar results are also obtained from the pumsb data set as shown in Figure 6 and Figure 7. For the pumsb data set the number of checked patterns of MHP is much smaller 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207–216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Int’l Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Int’l Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 






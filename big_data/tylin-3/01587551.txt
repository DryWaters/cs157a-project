I College of Information Engineering  2~epartment of Computer Science Shenzhen University Shenzhen P R Chin Jilin University Changchun P R China  1unanzu  edu.cn  cgzhou@lu  edu.cn wang-zhe2 Chun-Guang  Zhou2 Jing-Zhou Zhou  The issues in the  Jield of association rules mining with  specific items are discussed first To solve the problems in the ordinary algorithm we put forward a new but  efticient mining algorithm with item constraints, called  EclatII We then give an analysis on the performance of the algorithm as well as on its strategy The  experimefital result shows that the  Eclat11 algorithm is more robust in items of using low support and long pattern association rules than others Key words data mining association rules item constrains; frequent item-set; lattice theory 2  Ck  X Apriori C Let  which is obtained Proceedings of the 2005 International Conference on Cyberworlds \(CW\22205 0-7695-2378-1/05 $20.00 \251 2005  IEEE Ck This formula indicates that all lengths of the  subsets in Direct Eclat Apriori Eclat Eclat EclatII 2 Constraint algorithm in association rules mining 2.1 Constraint algorithm K-1 Abstract The topic of association rules mining is one of the important data mining  subjects which aims at exploring the association or relation of item-set on transaction database or relational databases For instance if 90 of potential customers purchase product A then they would also purchase product B This statement exemplifies the association rules are recurrent, but X itself must be tested for frequency by scanning the database The number of scanning the database in Lk XI  k,sup\(X  X  1 Introduction A Nan Lu  typical application of the association rules mining is to analyze the sale. Though the mining algorithm based on association rules have solved the problem of how to step up the generation of frequent item-set  effi~ientl~['~[~~[~I in reality we will have to deal with the massively increasing rules which can't be tackled by ordinary mining methods due to the expanding of a databases over time So in application the user is normally interested in a specific subset of association rules rather than the total association rules as it is more convenient for the user to go through the rules where the number of the rules has been trimmed down Thus introducing some proper constrains in the algorithm can effectively guide the mining process thus making it more  efficient So it is necessary for the user to settle these problems via the exploration of association rules mining and the specific item or item set The first problem to be solved by using the association rules mining is locating all frequent item sets in the transaction database rapidly Efficiency is a key concern in performing the algorithm Some researchers, such as Agrawal, propose several mining methods on processing the item  constraint One method simply titled algorithm directly generates the candidate set However if the candidate set contains a larger number of element the performing algorithm's efficiency will decrease while computing the support for the item-set The algorithm proposed by  Zaki is a counter-part of classical algorithm which greatly enhances the performing efficiency However the algorithm does not solve the association rules mining problems when using constraints In this paper we mainly discuss the method of introducing the item constraint into an algorithm adopting the vertical structure database and conceptual lattice theory to partition the candidate set into small  sub grids Then we utilize the co-relation among the neighboring grids to conduct item-set pruning As each sub-grid is designed to be processed separately in memory we in turn reduce  UO costs allowing us to maximum frequent item-sets while simultaneously the association rules mining problem with item constraint low support and long pattern can be  efficiently solved by this  algorithm given in this paper algorithm is determined by the length of the maximum frequency sets There are two phases in each scan: In first phase the  is created by     11  min-sup Direct Apriori Research on Association Rules Mining Algorithm With Item Constraints  based on be the set which includes all of the possible k item-sets which we call the candidate set of frequent k-item-set represented as  


Lz 1 by the k-l'th scanning ie by generating an element in  c Lk-I L3 a b c a b  prune set I Lk Ck  Apriori join step join step join step joint step L2 a  c e Direct class Apriori Direct C4={{a b c  d  1 As  which are the same as the elements in the number of  items The creation of an algorithm for this candidate set guarantees that  In the second phase the database is scanned, and the elements in the candidate set contained in each record are determined by utilizing the data structure of Hash-Tree The counter of these elements is increased by  After scanning all of the records we can determine which item-set is frequent through examining the element counter in the candidate set The creation of the candidate set utilizes the property called which formulates that if an item-set is frequent then all of its subsets are also frequent. The creation of  If this is not the case then the element should be eliminated We use the following example to illustrate the process Example1 Let  after process we get  So we eventually have  If an item constraint exists the above mentioned operation is incomplete For example we are only interested in mining the association rules containing item 2  in  item set which meets the constraint B contains at least a can be obtained through computation of support for the elements in the set When the iteration ends all the frequent sets satisfying method based on conceptual lattice theory in the B K+I L using connection of two randomly chosen elements in  process follows  1 the subsets are within  The since its subset b is not involved in  and then generating all the item-sets meeting S For example each item-set contains at least one element from  S finally filtering these item-sets with B This method is in-efficient, since too many elements exist in the candidate-set due to usage of constraint algorithm has a rather high  efficiency rate due to the utilization of constraint item subset which meets unless each disjunction with the truth value of non-negative elements Assume that  X F resulting  does not satisfy  should be deleted 2 does not play a role of pruning for  since all item subsets satisfying into  getting  can be obtained Through analysis we find an existing defect when using the method  constraint algorithm belongs to the The so called vertical Lj Lk joint set a b c e Multi-joints Recorder X b V d  cZb a b  b d  c  d  d  e  B d  Prune L  x F Direct Eclat  tid-list a  b C4  C4 a b c  d a b c e  B a a b  c c prune step a c e  c b d  L2 a  b  b  c  a  c Direct true I={a b c d  e  B=\(a  A d  e a  d b  d  c  d a  b  Direct to is eliminated from     L  d 3 Direct due to the existence of the constraint Therefore the algorithm of association rules mining must be modified Thereafter we will discuss a variety of mining algorithms with item constraint There are normally three processing item constraint methods  1 To generate  prune is the super set of  for generating candidate-set in algorithm By using the vertical database structure and the equivalent relationship based on prefix the whole searching space conceptual lattice is split up into smaller subsets \(sub-conceptual lattice Each sub-conceptual lattice can be processed in memory by performing the algorithm if the number of database scans is reduced  thereby greatly improving the efficiency of association rules mining  Lk-I Ck be    database tid-list Eclat e e d   Vertical among the elements of  created by the Assuming all items are ordered alphabetically, the following SQL-like language specifies the method of Inset into  Cwl Select  p.iterm  piterm eliminates the element But if the is to generate the element 2 and The first two methods are similar in performance since they have the same item-sets in computing the support They all adopt the following method: creating a selected item-set S based on to generate the candidate  setIS1 In contrast the to directly generate the candidate set. The algorithm is based on the following facts Any in X has exactly and all of the items in I are frequent, then we get  first we need to perform  are frequent. At last we put algorithm For example we still have too many elements in the candidate-set To perform "support computation for a larger number of item-sets we would have to lower the algorithm's efficiency mining algorithm Though introducing the item constraint can speed up the algorithm performance and make the mining result meet the user's requirement algorithm also has a limit in the process of mining low support long pattern association rules On the basis of algorithm Zaki has suggested database means that each record in the database is constructed by the item and all the existing transaction records This makes any frequent set's support obtained through the operation on meet set The transaction database in Proceedings of the 2005 International Conference on Cyberworlds \(CW\22205 0-7695-2378-1/05 $20.00 \251 2005  IEEE    L 7 2.2 ck k+l 2 the k'th item set will undergo the 1 Ck B B D B B K-Z I K p.item-I  q.item.1  From  P  q One must verify that all we require 


 Dl ABCDE Tld  Transactron Id  14 P\(I E DE Apriori Eclat Table2 the  verhcal the  table1 Table1  I AB denotes the top element record represents the author of the book purchased by in the conceptual lattice, and denotes the bottom the customer Table 2 illustrates its The following lemmas are given by  and join Lemma 2 all of the subsets of the frequent set are operations are disjunction and conjunction frequent respectively Any subset of  satisfying join and meet operation of the  fi.equent set is closed This is meet operations The set constituted by all frequent a solid foundation of prune set in the process of sets is semi-meet conceptual lattice The set frequent computing As any support of K item-set constituted by all un-frequent sets is semi-join can be computed through the meet operation of tid table between any two  operation For the frequent sets in  algorithm adopts a classification method based on prefix For example  algorithm in a counter order of the classification aiming at performing the prune operation for all  from  is also infrequent  Therefore there is no need to perform the  algorithm the operating  In  the picture  the  closed  item  sets  represent time of algorithm is decreased algorithms frequent item sets and the opened item sets represent are suitable for mining low support and long Proceedings of the 2005 International Conference on Cyberworlds \(CW\22205 0-7695-2378-1/05 $20.00 \251 2005  IEEE Po tid-list ABCE 5 A 1345 D yg  El For any  In lemma 1 if X can be expressed by a join-set of B  123456 support by computing the meet-set of these D 1356 For  set  subsets for computing all conceptual lattice since the set constituted by all frequent sets is closed through the of two frequent sets is still a support of all the item-sets  fiom bottom to top layer by layer Meanwhile all the frequent sets satisfying frequent set Whereas, any where I is a set constituted by item sets tid tables into the memory at the same time all of the items Therefore it is useless using the above method for  subsets For instance, after the process of  in  If P  Po Po El tramaction database dotted lines lead out are un-frequent The largest  form of K-1 X  A],[B],[C].[D],[E C  C  table 1 illustrates an example of a database Each un-frequent item sets format element The connecting line in the picture is drawn assume that ABCDEF represent the first letter of six in a top-down way The nodes from which the solid authors' names respectively lines lead out are  frequent and those from which the  recurring lines in the picture are They form an important foundation for computing item set 4 the elements in J then we can compute the  X's c  2456 E 12345 elements tid table Here J  YE  indicates the set constituted by atoms of  the  ordered  set  denotes  the  power  set  represents  the  su~~ort  for  In the case that the bias-order has set  tid containing relation  6 and meet  A is called a complete This deduction is inferred based on the fact that the conceptual lattice if the  a direct way is to compute the example any large  five equal sub-conceptual lattices The After  is split up into smaller sub-conceptual lattices each equivalent class will be processed using the to prune the element I  operation By doing this the number of operations of meet for corresponding tid Picture 1 complete conceptual lattice  table will be decreased Compared with   ABCDE support 6 BCDF Lemma  1 X join L\(DE D E P\(7,J Po Po Frn I  is larger it is hard to put all conceptual lattice  into  is infrequent, then       __  _   P  I  ABDE Items  Trd-bt  I&=l  UYEJLO I P\(I meet Eclat C E C D  E  Eclat E Eclat we can use the element 221     5         XE  of two un-frequent sets is still an un-frequent set the minimum support specified by the user can be Picture 1 illustrates an example of a complete obtained Actually as  We get an idea of partitioning the space of conceptual lattice constituted by  We then split  C  P  ifX=U  PQ meet P\(I DE I then A\(P\(I Y  I     V      I conceptual lattice theory and  represents  the of set  Zaki 


  Eclat  II P\(0 A A L J which tackles the problem existing in association rules mining with the item constraint 1 implementing strategy Normally let  em ma 2 the frequent set of each disjunctive item in When enumerating two item sets we numerate all the two item sets containing can have the form of  when  XY D I n-\(m-k B  B=\(A  A B  A AB ABC K+L K-1 K+L>>K-2 K-1 n>>m K 1/2\(2n-m rn-l A  2,...,in 3 pattern association rules However situations concerning item constraint pose unresolved issues Therefore we have improved the Eclat algorithm and make it more optimal and propose the algorithm Eclat  fl represent the item constraint disjunctive terms we take all the first elements as the first should be the order of first elements of first disjunctive items Each disjunctive item is then ordered according to order of I Lemma 1 assume that will be ordered in front equivalent classes The closer an equivalent class is placed to the front the more item sets will exist Additional work needs to be done concerning the meet operation between the tid tables Therefore the algorithm's  efficiency can be raised by adding constraints in the large equivalent classes In  Eclais numerating method for frequent top-down sets the iteration decomposing method is adopted when processing each equivalent class This method decomposes large classes into small equivalent classes Numeration allows the meeting set of all the atomic terms in each equivalent class to be layered because we know that the first corresponding disjunctive item in first-class constraint decomposes into the corresponding equivalent class We make the searching space smaller for the equivalent class corresponded by single a disjunctive item Pruning method for above mentioned conceptual lattice assume that  must be contained in the equivalent class When enumerating three item-sets we enumerate all three item sets containing Theorem when  B I  il,i  I C  P\(4 A A  J K+L-I L>1 K-2 A  L=l as the first class constraint After introducing the first class constraint the items in item-set I need to be ordered In ordering process we first delete the disjunctive terms constituted by all the item's complement in B For example say there are and order it alphabetically The remaining is The reason for doing this is that we can pass through all frequent sets satisfying the disjunctive item through the meet computation among the atomic terms from top to bottom Theorem 1 to those  to prune the equivalent class space of the pruning proportion must be  the pruning proportion is about  The lost quantity of the subset with the length of  and  D2  B m-k m-k then all the frequent sets to be obtained to satisfy the constraint must exist in the first m equivalent classes in  into the corresponding equivalent class The performed ordering operations guarantee that the disjunctive items in the pruning method used in conceptual lattice space guarantees that top to bottom search methods pass through all the frequent sets satisfying a single disjunctive item constraint The proportion of the pruning the ratio of the item set number in  any item set with the length and the length of Y is 2 Description of the algorithm The search algorithm adopted is the same as Eclat for the equivalent class without the disjunctive constraint The only difference is that instead of putting the frequent-set of the equivalent class into the set of frequent-set we need to mark which of these are frequent and which are not For equivalent class with constraint we adopt the Eclat  and  Kl  A  K2  Dm A~AA~A...AAJ in[A  A  A   A  A  A   AI  A  A2  A B B=DI  B k B B B B B B B A A A  A2  A A J 2 2.3 algorithm A   A   11 denote the set of all items denotes the Boolean expression of I and the disjunctive norm  Each disjunctive term  can be expressed as a conjunctive norm  Ordering operation Take the first elements of conjunction from any two disjunctive items in elements of elements in must also be alphabetized After re ordering the items in I the order of the disjunctive items in belongs to the first class constraint After obtaining frequent set of each disjunctive item we obtain all the frequent sets which satisfy the constraint must be contained in equivalent class corresponding to the first term of the disjunctive items If m disjunctive items exist in These two lemmas show that we can decompose the disjunctive item  satisfying the constraint is still a conceptual lattice and the first term of the disjunctive item in According to the above statement all the frequent set satisfying When enumerating four item-sets we enumerate all item sets containing Theorem 2 according to the above method and using disjunctive item  where n is the number of the items in I When  in equivalent class pruned by disjunctive item  where the length  ofxis  and~i&&,X  in the item set will be algorithm From the above algorithm we can see that  hold under the circumstance of the longer frequent set existing in the database Although there few subsets are lost and cannot be pruned the operation of pruning is still efficient due to the existence of the most existing subsets. However Proceedings of the 2005 International Conference on Cyberworlds \(CW\22205 0-7695-2378-1/05 $20.00 \251 2005  IEEE 


3 Ca LBKx Len B=\(1  An An  Eclat  II Direct Recorder S Eclat  Direct Direct Hash Tree Eclat  Recorder LI-L3 300  AAAI and by using  Len fl algorithm is based on the prototype of A  Inkeri Verkamo Fast discovery of association rules In U Fayyad and et al editors Advances in Knowledge Discovery and Data Mining page 307-328  AAAI when L is small the increase of the number of the subsets lost will lead to the extra computation cost The enumerating space shrinks when using the item constraint, though the algorithm is still efficient When the such as  which is consistent with the equivalent class in In this way the number of processing the candidate item sets can be reduced Although the For the candidate item set with a length greater than  F in we use the  kequent  items meet set to generate k item set So the number of the candidate sets is reduced long pattern 1 4 1,3 Eclat  Direct Apriori 2 L3={{1,2,3  Recorder LenaiienD Eclat  II Eclat  Eclat Recorder Apriori Lk 2 2 is  and larger databases The number of database scans based on the algorithm is  to frequent item set 3 where  B 1,2,5  1 fl algorithm can generate  S Ck and The reason for doing this is that the quantity of the candidate sets in association rules mining will be the key factor affecting the speed of performing the algorithm The larger the candidate set the more complex the computation The main differences of the algorithm is as follows and the longest length contained in B itself is  The and are based on the prototype of The former cannot use the and  I  R.Agrawa1  T.Imielinski and  A.Swami Mining Association Rules Between Set of Items in Large Database Proc 1993 ACM SIGMOD int'l Conf Management of Data pp.207-216 Washington D.C May 1993 2 H Mannila H Toivonen, and A.I Verkamo Efficient Algorithm for Discovering Association Rules Proc  3   we still adopt the method  S={I  LIE  1},{2  L,={{l  2  I  30  11 S 3 Comparison of the algorithms 1 4 Conclusion We now introduce a comparison among the number of candidate sets obtained by performing the algorithms When the contrary item is contained in B the size of  In general the chosen item set in the algorithm We assume that the frequent 4 item set is not included in the data set Eff~cient Algorithm for Mining Association Rules in Large Database." Proc 1995 Int'l Conf Very Large Data Base pp  432443 Zurich, Sept 1995  S Srikant R Vu Q and Agrawal R Mining Association Rules with Item  Constrants In Proc Of the Third Int'l Conf on Knowledge Discovery in Databases and Data Mining, 67-73,1997  6 R Agrawal H  Mannila R Srikant H Toivonen A V A A LenD+I By introducing the constraints in association rules mining the process of mining can be performed to meet the main requirement of the user This deters superfluous mining The association rules mining with item constraint is a  hndamental rule in mining. Our research augments and completes the related techniques in association rules mining Additionally our methods develop and inherit the research methods in association rules mining, playing an important role in research and application on association rules and data mining Continued development of high performance algorithms is key in ensuring  efficient association rules mining techniques 94 Workshop Knowledge Discovery in  Database\(KDD  94 pp. 181-192 Seattle July 1994 3 J.S Park M.S Chen and P.S Yu Efficient Hash Based Algorithm for Mining Association Rules Proc 1995 ACM SIGMOD Int'l Conf Management of Data pp  175 186 San Jose Calif May 1995  A Savasere E Omiecinski and S Navathe Press  Menlo Park  1996 7 Mohammed J  Zaki Scalable Algorithm for Association Mining Knowledge and Data Engineering  12\(2 2000 Proceedings of the 2005 International Conference on Cyberworlds \(CW\22205 0-7695-2378-1/05 $20.00 \251 2005  IEEE References  11 requires only two database scans The number of database scans directly affects algorithm efficiency Since we can partition the conceptual lattice space the larger memory space can hold the entire sub-conceptual lattice and the performance efficiency thus improved The following examples illustrate the differences among these algorithms Assume        2  3  B K-1 B=\(I  algorithm needs to generate an additional chosen item set  according to the constraint the chosen item set may be  may approach item set I Whereas the algorithm has adopted the method of directly generating the candidate item set the number of the candidate item set to be processed compared with algorithm is quite large. Since the longest length satisfying the pattern in then we have  algorithm to generate the candidate item set Whereas in algorithm database structure but rather utilizes the simple meet operation Therefore it is more robust and flexible providing us with the following three advantages 1 low support depends on the length of the largest pattern The algorithm indicate sets  kom frequent item set 


0 mrmmeASAIu.1 ma Tnne\(WC4 ;"* e...... * 7 ; p  1 . -  * .  . .  I .  . .  . .   . .  r I . .  . . .  . . .  ..: i i  . .  . -  . .  . .  . .  . +  .  . .  . .  . .  I  I I :  . i I *  . .  . .  . .  I  . .  .. I c 1 Conclusion The paper proposed a user-association mining frame _ _ based on two-stage count called TSCF and by using concept lattice we implemented a user-association mining algorithm TSCF-CL designed for recommendation. The contributions of the paper are: f a t ,  TSCF frame not only uses the current user to constrain the rule form, but also partitions the rating table in mining process, so that the efficiency of mining user-associations is increased. Second TSCF frame can be implemented by using existing algorithms for mining association rules. Third, TSCF-CL algorithm is implemented by using the incremental concept lanice, which can reach better time capacity Acknowledgements This paper is supported by NSFC of China \(project number: 60373098, 60173006 project number: 2003AA118020 Province \(20020303-2 e 0  C ASARM T S G - U 1 7 - - -  J nl a2 uf wl Us u6 u7 UB OP 010 Ber Figures Ihe execotiag time for 10 users References 111 I21 131 41 151 161 Paul Resnick, Hal R.Varian.. Recommender Systems Communications of the ACM, 40\(3 1997 David Goldberg, David Nichols, Brian M. Ob Douglas Terry. Using Collaborative Filtering to Weave an Information Tapestry. Communication of the ACM, 35\(12 Marko Balabanovi'c, Yoav Shoham Fab:Content-Based, Collaborative Recommendation Communications of the ACM, 40\(3 1997 Upendra Shardanand, Pattie Maes. Social Information Filtering: Algorithms for Automating "Word of Mouth". In: Proceedings of CHI'95 Conferenceon Human Factors in Computing Systems, ACM Press, 1995 John SBreese, Davia Heckerman, Carl Kadie Emperical Analysis Of Pridictive Algorithms For Collaborative Filtering. In: Proceedings of the Fourteenth Annual Conference on Unceltainty in Artificial Intelligence, pages 43-32, July 1998 Weiyang Lin, Sergio A. Alvarez, Carolina Ruiz Collaborative Recommendation Via Adaptive Association Rule Mining. 6th Intemational Conference on Knowledge Discovery and Data 1133 Proceedqs of the Third Intemational Conference on Machine Learning and Cybemetics, Shanghai, 2629 August 2004 Mining Workshop on Web Mining for E-Commerce WebKDD-2000 7] Weiyang Lin, Sergio A. Alvarez, Carolina Ruiz 


7] Weiyang Lin, Sergio A. Alvarez, Carolina Ruiz Efficient Adaptive-Support Association Rule Mining for Recommender Systems. Data Mining and Knowledge Discovery, 683--105,2002 SI Xiaobin Fu, Jay Budzik and Kristian J. Hammond Mining Navigation History for Recommendation In: Proceedings of Intelligent User Interfaces 2000 106-112, ACM Press, 2000 9] B. Sarwar, G. Karypis, J. Konstan, J. Riedl Item-based collaborative filtering recommendation algorithms. In Roceedings of WWWlO Conference pages 28s-295, Hong Kong, May, 2001 lo] Bing Liu, Wynne Hsu, Yiming Ma. Integrating Classification and Association Rule Mining. KDD-98 1998, pages 80--86.1998 ll] Robert Godin, Rokia Missaoui. Hassan Alaoui Incremental concept formation algorithms based on Galois\(concept Intelligence, 1 l\(2  1134 pre></body></html 


15] N. Davies, K. Cheverst, K. Mitchell, and A. Efrat  Using and determining location in a context-sensitive tour guide  ZEEE Computer, vol. 34, issue 8, pp.35-41 Aug. 2001 pre></body></html 


 The required delivery date is a Range constraint any date within the next 30 days Attribute Required-Delivery-Date  today today+30 days Attribute S&H query\(UPS Product   say it is 59.95 Attribute Value  query\(Catalog Product  Attribute Price  Attribute Total  Inter-attribute constraints in PO14 Price  Quantity  Value  1-x Total  Price  S&H  1.088 Total  Total1  Total4 In this case the Quantity attribute value has changed to 2 by adding both requests together Furthermore the Delivery-Date attribute value is a result of finding a common range of the two The obvious saving in this case is 2*$39.95 59.95\1.088  21.71 Whether a bunch of POs should be aggregated in a particular way depend on whether costing savings can be achieved while satisfying all the constraints 6.2 Intelligent Aggregation of Purchase Orders in e-Procurement with Negotiations Aggregation under dynamic negotiation is harder because supplier side could be revising its own strategies and parameters on the fly While human intervention in the aggregation process is possible we focus on automated aspects of the aggregation in this paper Suppose we have a simple supplier side rule buy one and get second one half price from LT a supplier of mice keyboard and trackball Suppose we have requests to buy Mice as follows PO5 Attribute Buyer  Organization 223B\224 User 223Joe\224 Location 223PS\224 Attribute Supplier  mpany 223LT\224 Catalog  http://\205/LT Attribute Product  223Optical Mouse\224 Attribute Quantity 1 Attribute Required-Delivery-Date  01/21/05 02/21/05   a r an g e of dat e s  order dat e  deadline d Attribute S&H9  query\(UPS Product   say it\222s 4.95 Attribute Value  query\(Catalog Product  Attribute Price10  Value  say it\222s 29.95 Attribute Total10  Total10  Price10  S&H10  1 tax rate results in a value 29.95  4.95\1.088  39.97 PO6 Attribute Buyer  Organization 223C\224 User 223Al\224 Location 223PS\224 Attribute Supplier  mpany 223LT\224 Catalog  http://\205/LT Attribute Product  223Optical Mouse\224 Attribute Quantity 1 Attribute Required-Delivery-Date  01/25/05 02/28/05   a r an g e of dat e s  order dat e  deadline d Attribute S&H10  query\(UPS Product   say it\222s 4.95 Attribute Value  query\(Catalog Product sayit\222s 29.95 per mouse Attribute Price10 Value Attribute Total10  Total10  Price10  S&H10  1 tax rate results in a value 29.95  4.95\1.088  39.97 6.2.1 PO Aggregation Under Negotiation The rule-based aggregation engine uses the Negotiation service to understand supplier\222s offers and tries to take advantage of the terms in the offers For example by aggregating PO5 and PO6 can be aggregated as follows PO56 Attribute Buyer  Organization B C User 223Joe\224 223Al\224 Location 223PS\224 Attribute Supplier  mpany 223LT\224 Catalog  http://\205/LT Attribute Product  223Optical Mouse\224 Attribute Quantity 2 Attribute Required-Delivery-Date  01/25/05 02/21/01 Attribute S&H10  query\(UPS Product   say it\222s 4.95 Attribute Value  query\(Catalog Product sayit\222s 29.95 per mouse Attribute Price10 1.5*Value Attribute Total10  Total10  Price10  S&H10  tax  1.5 29.95  4.95\1.088  54.26 A saving of 39.97  2 54.26  25.68 or over 32 of savings Note the changes of the 223Quantity\224 and 223RequiredDelivery-Date\224 attributes after aggregation The quantities are added up and the required delivered dates are merged for a common range Due to the constraints on object attributes aggregation may require complex constraint solving Proceedings of the 2005 Ninth IEEE International ED OC Enterprise Computing Conference \(EDOC\22205 0-7695-2441-9/05 $20.00 \251 2005  IEEE 


7 Conclusions and Future Work This paper describes an Intelligent Aggregation facility in enterprise e-Procurement process This facility introduces an information model a rule-based aggregation engine corporate agreement policies and negotiation in aggregating large volume of POs in enterprise eprocurement to reduce cost and maximize efficiency This information model includes extensive use of constraints for and among attributes in a PO These constraints guard the integrity of POs as they are aggregated The intelligent aggregation facility can be inserted as a value-added service in the enterprise e-Procurement workflow An enterprise generates millions of POs every year but the number of distinct products and services the enterprise purchases is actually much smaller in the hundreds rather than in the millions This presents cost saving opportunities by aggregating POs that makes best use of terms and conditions in corporate agreements or supplier offers Some concrete examples are used to show the idea of automated aggregation and the opportunities in reducing procurement cost As millions of POs are generated even a small percentage of savings would mean substantial savings for large enterprises The ideas described in this paper have not been fully implemented in our prototype One area needs more work is the formal representation of policies in corporate agreements which would allow the aggregation engine to automatically explore aggregation opportunities before POs are made to suppliers Another is the semantic model of products which would enable more semantics-based aggregation of POs 8 References  e bX M L  h t t p   w w w ebxml  org  2 e n g  J  S u  S  Y  W  L a m H   a n dH e l a l S   223Achieving Dynamic Inter-Organizational Workflow Management by Integrating Business Processes Events and Rules,\224 Proceedings of the 35th Hawaii International Conference on System Sciences HICSS35 Hawaii USA January 2002 3 u  S  Y  W  L a m H   L e e  M  B a i S   a n dS h e n  Z   An Information Infrastructure and E-services for Supporting Internet-based Scalable E-business Enterprises Proceedings of the 5th International Enterprise Distributed Object Computing Conference Seattle Washington USA September 2001 4 S u S Y  W   H ua ng C  H a mme r J   H u a ng Y   L i  H   Wang,L.,LiuY.,Pluempitiwiriyawej,C.,Lee,M and Lam H 223An Internet-based Negotiation Server for E-commerce,\224 VLDB Journal Vol 10 No 1 2001 pp.72-90 5 M o r r i s S l o m a n  223 P o l i c y D ri v e n M an ag em e n t f o r Distributed Systems\224 Journal of Network and Systems Management Plenum Press Vol 2 No 4 1994  M aarten S teen  J oh n D errick  223 For m ali s ing ODP Enterprise Policies\224 Proceedings of the 3 rd International nterprise Distributed Object Computing Conference Mannheim Germany IEEE CS Press September 1999  J am e s H a ns on  Z oran M i l o s e v i c 223 C o n v e r s at i onOriented Protocols for Contract negotiations\224 Proceedings of the 7th International Enterprise Distributed Object Computing Conference Brisbane Australia IEEE CS Press September 2003  S  N eal J  C ole P.F L i n i ng ton  Z  Milose v i c S Gibson S Kulkarni 223Identifying Requirements for Business Contract Language a Monitoring Perspective\224 Proceedings of the 7th International Enterprise Distributed Object Computing Conference Brisbane Australia IEEE CS Press September 2003 9 T  D im itrak o s  I  D j o rd j e v i c Z  Milo sev i c A  J o san g  C Phillips 223Contract Performance Assessment for Secure and Dynamic Virtual Collaborations\224 Proceedings of the 7th International Enterprise Distributed Object Computing Conference Brisbane Australia IEEE CS Press September 2003 Proceedings of the 2005 Ninth IEEE International ED OC Enterprise Computing Conference \(EDOC\22205 0-7695-2441-9/05 $20.00 \251 2005  IEEE 


absolute values. The results can vary on other computers. But it can be guaranteed that performance ratio of the algorithms will remain the same After making the comparisons with sample data, we came to the conclusion that PD algorithm performs significantly better than the other two especially with larger datasets. PD outperforms DCP and PIP regarding running time. On the other hand, since PD reduces the dataset, mining time does not necessary increase as the number of transactions increases and experiments reveals that PD has better scalability than DCP and PIP. So, PD has the ability to handle the large data mine in practical field like market basket analysis and medical report documents mining 5. References 1] R. Agrawal and R. Srikant, "Fast algoritlnns for mining association rules", VLDB'94, pp. 487-499 2] R. J. Bayardo, "Efficiently mining long patterns from databases", SIGMOD'98, pp.85-93 3] J. Pei, J. Han, and R. Mao, "CLOSET: An Efficient Algorithm for Mining Frequent Closed Itemsets \(PDF Proc. 2000 ACM-SIGMOD International Workshop on Data Mining and Knowledge Discovery, Dallas, TX, May 2000 4] Qinghua Zou, Henry Chiu, Wesley Chu, David Johnson, "Using Pattern Decomposition\( PD Finding All Frequent Patterns in Large Datasets", Computer Science Department University of California - Los Angeles 5] J. Han, J. Pei, and Y. Yin, "Mining Frequent Patterns without Candidate Generation \(PDF  SIGMOD International Con! on Management of Data SIGMOD'OOj, Dallas, TX, May 2000 6] S. Orlando, P. Palmerini, and R. Perego, "The DCP algoritlnn for Frequent Set Counting", Technical Report CS2001-7, Dip. di Informatica, Universita di Venezia 2001.Available at http://www.dsi.unive.itl?orlando/TR017.pdf 7] MD. Mamun-Or-Rashid, MD.Rezaul Karim, "Predictive item pruning FP-tree algoritlnn", The Dhaka University  Journal of Science, VOL. 52, NO. 1, October,2003, pp. 3946 8] Park, J. S., Chen, M.-S., and Yu, P. S, "An Effective Hash Based Algoritlnn for Mining Association Rules", Proc ofthe 1995 ACM-SIGMOD Con! on Management of Data 175-186 9] Brin, S., Motwani, R., Ullman, J., and Tsur, S, "Dynamic Itemset Counting and Implication Rules for Market Basket Data", In Proc. of the 1997 ACM-SIGMOD Conf On Management of Data, 255-264 10] Zaki, M. J., Parthasarathy, S., Ogihara, M., and Li, W New Algoritlnns for Fast Discovery of Association Rules In Proc. of the Third Int'l Con! on Knowledge Discovery in Databases and Data Mining, 283-286 11] Lin, D.-I and Kedem, Z. M., "Pincer-Search: A New Algoritlnn for Discovering the Maximum Frequent Set", In Proc. of the Sixth European Conf on Extending DatabaseTechnology, 1998 12] R. Ramakrishnan, Database Management Systems University of Wisconsin, Madison, WI, USA; International Edition 1998 pre></body></html 


tors such as union, di?erence and intersection are de?ned for pairs of classes of the same pattern type Renaming. Similarly to the relational context, we consider a renaming operator ? that takes a class and a renaming function and changes the names of the pattern attributes according to the speci?ed function Projection. The projection operator allows one to reduce the structure and the measures of the input patterns by projecting out some components. The new expression is obtained by projecting the formula de?ning the expression over the remaining attributes [12 Note that no projection is de?ned over the data source since in this case the structure and the measures would have to be recomputed Let c be a class of pattern type pt. Let ls be a non empty list of attributes appearing in pt.Structure and lm a list of attributes appearing in pt.Measure. Then the projection operator is de?ned as follows ls,lm c id s m f p ? c, p = \(pid, s, d,m, f In the previous de?nition, id ing new pids for patterns, ?mlm\(m projection of the measure component and ?sls\(s ned as follows: \(i s usual relational projection; \(ii sls\(s and removing the rest from set elements. The last component ?ls?lm\(f computed in certain cases, when the theory over which the formula is constructed admits projection. This happens for example for the polynomial constraint theory 12 Selection. The selection operator allows one to select the patterns belonging to one class that satisfy a certain predicate, involving any possible pattern component, chosen among the ones presented in Section 5.1.1 Let c be a class of pattern type pt. Let pr be a predicate. Then, the selection operator is de?ned as follows pr\(c p Join. The join operation provides a way to combine patterns belonging to two di?erent classes according to a join predicate and a composition function speci?ed by the user Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE Let c1 and c2 be two classes over two pattern types pt1 and pt2. A join predicate F is any predicate de?ned over a component of patterns in c1 and a component of patterns in c2. A composition function c pattern types pt1 and pt2 is a 4-tuple of functions c cStructureSchema, cDataSchema, cMeasureSchema, cFormula one for each pattern component. For example, function cStructureSchema takes as input two structure values of the right type and returns a new structure value, for a possible new pattern type, generated by the join. Functions for the other pattern components are similarly de?ned. Given two patterns p1 = \(pid1, s1, d1,m1, f1 p2 = \(pid2, s2, d2,m2, f2 p1, p2 ned as the pattern p with the following components Structure : cStructureSchema\(s1, s2 Data : cDataSchema\(d1, d2 Measure : cMeasureSchema\(m1,m2 Formula : cformula\(f1, f2 The join of c1 and c2 with respect to the join predicate F and the composition function c, denoted by c 1   F  c  c 2   i s  n o w  d e  n e d  a s  f o l l o w s    F  c  c 2     c  p 1   p 2   p 1    c 1  p 2    c 2  F   p 1   p 2     t r u e   5.1.3. Cross-over database operators OCD Drill-Through. The drill-through operator allows one to 


Drill-Through. The drill-through operator allows one to navigate from the pattern layer to the raw data layer Thus it takes as input a pattern class and it returns a raw data set. More formally, let c be a class of pattern type pt and let d be an instance of the data schema ds of pt. Then, the drill-through operator is denoted by c c Data-covering. Given a pattern p and a dataset D sometimes it is important to determine whether the pattern represents it or not. In other words, we wish to determine the subset S of D represented by p \(p can also be selected by some query the formula as a query on the dataset. Let p be a pattern, possibly selected by using query language operators, and D a dataset with schema \(a1, ..., an ible with the source schema of p. The data-covering operator, denoted by ?d\(p,D responding to all tuples in D represented by p. More formally d\(p,D t.a1, ..., t.an In the previous expression, t.ai denotes a speci?c component of tuple t belonging to D and p.formula\(t.a1, ..., t.an instantiated by replacing each variable corresponding to a pattern data component with values of the considered tuple t Note that, since the drill-though operator uses the intermediate mapping and the data covering operator uses the formula, the covering ?\(p,D D = ?\(p not be equal to D. This is due to the approximating nature of the pattern formula 5.1.4. Cross-over pattern base operators OCP Pattern-covering. Sometimes it can be useful to have an operator that, given a class of patterns and a dataset, returns all patterns in the class representing that dataset \(a sort of inverse data-covering operation Let c be a pattern class and D a dataset with schema a1, ..., an pattern type. The pattern-covering operator, denoted as ?p\(c,D all patterns in c representing D. More formally p\(c,D t.a1, ..., t.an true Note that: ?p\(c,D p,D 6. Related Work Although signi?cant e?ort has been invested in extending database models to deal with patterns, no coherent approach has been proposed and convincingly implemented for a generic model There exist several standardization e?orts for modeling patterns, like the Predictive Model Markup Language \(PMML  eling approach, the ISO SQL/MM standard [2], which is SQL-based, and the Common Warehouse Model CWM  ing e?ort. Also, the Java Data Mining API \(JDMAPI 3] addresses the need for a language-based management of patterns. Although these approaches try to represent a wide range of data mining result, the theoretical background of these frameworks is not clear. Most importantly, though, they do not provide a generic model capable of handling arbitrary cases of pattern types; on the contrary only a given list of prede?ned pattern types is supported To our knowledge, research has not dealt with the issue of pattern management per se, but, at best, with peripheral proximate problems. For example, the paper by Ganti et. al. [9] deals with the measurement 


per by Ganti et. al. [9] deals with the measurement of similarity \(or deviation, in the authors  vocabulary between decision trees, frequent itemsets and clusters Although this is already a powerful approach, it is not generic enough for our purpose. The most relevant research e?ort in the literature, concerning pattern management is found in the ?eld of inductive databases Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE meant as databases that, in addition to data, also contain patterns [10], [7]. Our approach di?ers from the inductive database one mainly in two ways. Firstly, while only association rules and string patterns are usually considered there and no attempt is made towards a general pattern model, in our approach no prede?ned pattern types are considered and the main focus lies in devising a general and extensible model for patterns Secondly, di?erently from [10], we claim that the peculiarities of patterns in terms of structure and behavior together with the characteristic of the expected workload on them, call for a logical separation between the database and the pattern-base in order to ensure e?cient handling of both raw data and patterns through dedicated management systems Finally, we remark that even if some languages have been proposed for pattern generation and retrieval 14, 11], they mainly deal with speci?c types of patterns \(in general, association rules sider the more general problem of de?ning safe and su?ciently expressive language for querying heterogeneous patterns 7. Conclusions and Future Work In this paper we have dealt with the issue of modelling and managing patterns in a database-like setting Our approach is enabled through a Pattern-Base Management System, enabling the storage, querying and management of interesting abstractions of data which we call patterns. In this paper, we have \(a de?ned the logical foundations for the global setting of PBMS management through a model that covers data patterns and intermediate mappings and \(b language issues for PBMS management. To this end we presented a pattern speci?cation language for pattern management along with safety constraints for its usage and introduced queries and query operators and identi?ed interesting query classes Several research issues remain open. First, it is an interesting topic to incorporate the notion of type and class hierarchies in the model [15]. Second, we have intentionally avoided a deep discussion of statistical measures in this paper: it is more than a trivial task to de?ne a generic ontology of statistical measures for any kind of patterns out of the various methodologies that exist \(general probabilities Dempster-Schafer, Bayesian Networks, etc. [16 nally, pattern-base management is not a mature technology: as a recent survey shows [6], it is quite cumbersome to leverage their functionality through objectrelational technology and therefore, their design and engineering is an interesting topic of research References 1] Common Warehouse Metamodel \(CWM http://www.omg.org/cwm, 2001 2] ISO SQL/MM Part 6. http://www.sql99.org/SC32/WG4/Progression Documents/FCD/fcddatamining-2001-05.pdf, 2001 3] Java Data Mining API http://www.jcp.org/jsr/detail/73.prt, 2003 4] Predictive Model Markup Language \(PMML http://www.dmg.org 


http://www.dmg.org pmmlspecs v2/pmml v2 0.html, 2003 5] S. Abiteboul and C. Beeri. The power of languages for the manipulation of complex values. VLDB Journal 4\(4  794, 1995 6] B. Catania, A. Maddalena, E. Bertino, I. Duci, and Y.Theodoridis. Towards abenchmark for patternbases http://dke.cti.gr/panda/index.htm, 2003 7] L. De Raedt. A perspective on inductive databases SIGKDD Explorations, 4\(2  77, 2002 8] M. Escobar-Molano, R. Hull, and D. Jacobs. Safety and translation of calculus queries with scalar functions. In Proceedings of PODS, pages 253  264. ACMPress, 1993 9] V. Ganti, R. Ramakrishnan, J. Gehrke, andW.-Y. Loh A framework for measuring distances in data characteristics. PODS, 1999 10] T. Imielinski and H. Mannila. A database perspective on knowledge discovery. Communications of the ACM 39\(11  64, 1996 11] T. Imielinski and A. Virmani. MSQL: A Query Language for Database Mining. Data Mining and Knowledge Discovery, 2\(4  408, 1999 12] P. Kanellakis, G. Kuper, and P. Revesz. Constraint QueryLanguages. Journal of Computer and SystemSciences, 51\(1  52, 1995 13] P. Lyman and H. R. Varian. How much information http://www.sims.berkeley.edu/how-much-info, 2000 14] R.Meo, G. Psaila, and S. Ceri. An Extension to SQL for Mining Association Rules. Data Mining and Knowledge DiscoveryM, 2\(2  224, 1999 15] S. Rizzi, E. Bertino, B. Catania, M. Golfarelli M. Halkidi, M. Terrovitis, P. Vassiliadis, M. Vazirgiannis, and E. Vrachnos. Towards a logical model for patterns. In Proceedings of ER 2003, 2003 16] A. Siblerschatz and A. Tuzhillin. What makes patterns interesting in knowledge discovery systems. IEEE TKDE, 8\(6  974, 1996 17] D. Suciu. Domain-independent queries on databases with external functions. In Proceedings ICDT, volume 893, pages 177  190, 1995 18] M.Terrovitis, P.Vassiliadis, S. Skadopoulos, E. Bertino B. Catania, and A. Maddalena. Modeling and language support for the management of patternbases. Technical Report TR-2004-2, National Technical University of Athens, 2004. Available at http://www.dblab.ece.ntua.gr/pubs Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE pre></body></html 


The reason of the hiding failure of SWA is the same in Fig.8 Notice the result at x = 0.7646 in Fig.14, because the hiding failure is occurred at the seeds of the sensitive patterns, a high weakness is produced As shown in Fig.15 and Fig.16, the misses cost and dissimil arity of our work decreases as RL2 increases. This is because the larger RL2 is, the less effect on non-sensitive patterns. Also weakness and dissimilarity of SWA are independent of RL2 5. Conclusion In the paper, a novel method improving the balance between sensitive knowledge protecting and discovery on frequent patte rns has been proposed. By setting entries of a sanitization matrix to appropriate values and multiplying the original database by the matrix with some probability policies, a sanitized database is gotten. Moreover, it can avoid F-I Attack absolutely when the confidence level given by users approximates to 1. The experimental results revealed that although misses cost and dissimilarity between the original and sanitized database of our process are little more than SWA, ours provide more safely protection than SWA. Unlike SWA, our sanitization process could not suffer from F-I Attack and the probability policies in our approach also take the minimum support into account, the users only need to decide the confidence level which affects the degree of patterns hiding 6. Reference 1] M. Atallah, E. Bertino, A. Elmagarmid, M. Ibrahim and V. Verykios Disclosure Limitation of Sensitive Rules", Proc. of IEEE Knowledge and Data Engineering Exchange Workshop 1999 2] R. Agrawal and R. Srikant. Fast algorithms for mining association rules. VLDB, Santiago, Chile, 1994 3] R. Agrawal and R. Srikant. Privacy preserving data mining. In ACM SIGMOD, Dallas, Texas, May 2000 4] E. Dasseni, V. Verykios, A. Elmagarmid and E. Bertino, Hiding Association Rules by Using Confidence and Support", Proc. of 4th Intl Information Hiding Workshop \(IHW 5] A. Evfimievski, J. Gehrke, and R. Srikant. Limiting Privacy Breac hed in privacy preserving data mining. SIGMOD/PODS, 2003 6] A. Evfimievski, R. Srikant, R. Agrawal, and J. Gehrke. Privacy preserving mining of association rules. KDD 2002 7] M. Kantarcioglu and C. Clifton. Privacy-preserving distributed mining of association rules on horizontally partitioned data. In ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery, June 2002 8] Guanling Lee, Chien-Yu Chang and Arbee L.P Chen. Hiding sensitive patterns in association rules mining. The 28th Annual International Computer Software and Applications Conference 9] Y. Lindell and B. Pinkas. Privacy Preserving Data mining. In CRYPTO, pages 36-54, 2000 10] S. R. M. Oliveira and O. R. Za  ane. Privacy Preserving Frequent Itemset Mining. In Proc. of IEEE ICDM  02 Workshop on Privacy Security, and Data Mining 11] S. R. M. Oliveira and O. R. Za  ane. Algorithms for Balancing Priv acy and Knowledge Discovery in Association Rule Mining. IDEAS  03 12] S. R. M. Oliveira and O. R. Za  ane. Protecting Sensitive Knowledge By Data Sanitization, ICDM  03 13] S. R. M. Oliveira, O. R. Za  ane and Y  cel Saygin. Secure Association Rule Sharing, PAKDD-04 14] Benny Pinks. Cryptographic Techniques For Privacy-Preserving D ata Mining. ACM SIGKDD Explorations Newsletter Vol. 4, Is. 2, 2002 15] S. J. Rizvi and J. R. Haritsa. Maintaining data privacy in association rule mining. VLDB, 2002 16] J. Vaidya and C. W. Clifton. Privacy preserving association rule mining in vertically partitioned data. KDD2002 17] Verykios, V.S.; Elmagarmid, A.K.; Bertino, E.; Saygin, Y.; Dasseni E. Association rule hiding. IEEE Transactions On Knowledge And Data Engineering, Vol. 16, No. 4, April 2004 Proceedings of the 29th Annual International Computer Software and Applications Conference  COMPSAC  05 0730-3157/05 $20.00  2005 IEEE pre></body></html 


pre></body></html 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



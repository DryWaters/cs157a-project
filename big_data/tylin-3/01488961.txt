The Research of Data Mining Based on Extension Sets Lu Qing Yu Yongquan Institute of Intelligent Engineering Guangdong University of Technology, Guangzhou, 510090, China E-mail: lulu201@sina.com.cn Abstract Extension data mining is a new method that is based on the extension analysis method of Extenics. Extenics is a new disciplinary and a new branch of artificial intelligence. Data mining techniques have their origins in methods from statistics, pattern recognition, databases 
artificial intelligence, high performance and parallel computing and visualization. This paper presents how to deal with multiple data formats and unify data representation based on extenics Keyword matter-element, databases, extension data mining, association rules  Introduction Extenics was first brought out by the famous researcher Cai Wen in 1983 in China, the major goal of this subject is to solve the 
incompatible problems through studying the extension probability of things. Matter-element is the logic cell of extenics and puts the matter the characteristics and their measure together into consideration   Data mining has gained popularity in the database field recently, it has been mostly used by statisticians, data analysts and so on. Data 
mining techniques can be divided into five classes of methods: predictive modeling clustering; data summarization and change and deviation detection  Some of these techniques are beginning to be scaled to operate on databases This paper presents how to deal with multiple data formats and unify data representation based on extenics. Also a general method of mining correlative matter-element 
based on association rules is valuable and easy to be implemented Matter-element and Correlative matter-element In the real world, things are entity of quality and quantity. The quantitative change and qualitative change of one thing are interrelated closely and interact on each other. Classical mathematics consider only the quantity and forms of objects, it studies quantitative relation 
and spatial forms. As a result, classical mathematics has its limitation in dealing with contradictory problems, which is associated with the qualitative change Extension theory can be used to describe the thinking process associated with both quantitative change and qualitative change, it regards the objective world as a world of matter-element  We use an ordered triad R=\(N c, v\ as the basic element for describing thing 
called matter-element, where N represents the matter; c, the characteristics; v is the Nês measure about the characteristic c; the expression v=c\(N\cribes the relation between quality and quantity. A matter has many characteristic-elements, which can be described by n-dimensional matter-elements R Definition 1 For a certain matter-element R=\(N 
m m v c v c v c  2  2 1  1  N Proceedings of the Third International Conference on Information Technology and Applications \(ICITAê05 0-7695-2316-1/05 $20.00 © 2005 IEEE 


c, v\, if existing another matter-element Rê=\(N cê, vê\ the same thing that is closely relevant to R, and the relevant degree of the two matter-element is bigger than the predefined valve value r, then matter-element Rê is labeled as the correlative matter-element of matter-element R Definition 2 Existing the matter-element set W m R 1 R 2 R m R i i=1, 2,É, m\ is labeled as a n-dimensional matter-element that is relevant to the specific problem  Extension method of data  processing In this section, we will discuss the data formats and representation based on matter-element; relation operation and extension method; E-R chart and matter-element chart 1 data and matter-element Relation database is a set of table, a table has many fields, in the term of relation model table is also called relation, field is called attribute. A relation S is a attribute set{C 1 C 2 C n S also can be looked as a n-dimensional matter-element R=\(N,C,V C=\(C 1 C 2 C n  V\(C 1  C 2  C n  V\(Ci Dom\(Ci\m\(Ci\e value domain of attribute,. A row on S is a correspondingly map of R. Relation database q is correspond a matter-element set W m that is consisted of many n-dimensional matter-element R n  For example there is a customer relation in bank database schema. This relation has three fields: customer-name, customer-city customer-telephone. We can represent this relation in a single structure in 3- dimensional matter-element R=\(N, C, V\ this case N=customer, C 1 is customer-name, C 2 is customer-city, C 3 is customer-tel We can give an instance as following Customer  Customer-name  a1   Customer-city   b1 R Customer-tel   c1 2 relation operation based on matter element Suppose there is a relation database q= W m R 1 R 2 R m R i i, j=1, 2, É, m\ is a n-dimensional matter-element, R 0 is a n dimensional matter-element. R i and R j are tables of q. Relation operations based on matter-element are defined as follows 1\ion operation: R i R j R|R 0 R i R 0 R j  2\tersect operation: R i R j R| R 0 R i  R 0 R j  3\ference operation: R i R j R| R 0 R i R 0  R j  4\Project operation: R 0 is the n- dimensional matter-element that contains the characteristics we want to know  R0 R i   R0 R j present that we find the R 0 from R i or R j 5\ Select operation: if a condition F is given for rows of data table R i or R j then F R i  F R j  0 R i or R 0 R j R 0 is satisfied with F 6\ Joint operation: R i R j R|R i R 0 R j R 0 R 0 is the n- dimensional matter-element that contains the characteristics getted by the combination of R i and R j  In extenics, we can use the extension methods of matter-element to correspond the relation operation. For example, one characteristic many matters 1 have the project relation operation function  3 E-R chart and matter-element chart In database model theory, now the Entity-Relationship \(E-R for shortly\ chart is widely used in database field, the following Proceedings of the Third International Conference on Information Technology and Applications \(ICITAê05 0-7695-2316-1/05 $20.00 © 2005 IEEE 


chart is an E-R chart of order Figure 1. E-R chart of order According to the definition of matter-element and extension set  we can see the ordering relationship as a matter-element set It includes three submatter-elements. We also see the ordering relationship as a matter-element R that N is ordering matter, its characteristics are other matter-elements If we import three matter-element: R 1 N 1  C 1 V 1  2 N 2 C 2 V 2  3 N 3 C 3 V 3 ey respectively represent equipment, provider and order form, and use the rectangle frame represent matter-element, we can get the Fig 2 and Fig 3 Figure 2. E-R chart of matter-element Figure 3. Matter-element chart We can see from the Fig 2 and fig3 that the matter-element chart is simpler and the description is more close to the real world, it is easy to be transformed to relation database. It composes some each other include and non-intersect rectangles. Each rectangle is a matter-element, each other non-included rectangle is equal matter-element. In matter-element chart, each rectangle is a relation or a data table. Matter-element chart is easier to be transformed to relation data model  Find the correlative matter element based on association rules When we use the matter-element to describe things, we will get much information in the form of matter-elements. How can we find useful and interesting information? When we are confronted with many matter-elements, some matter-elements are relevant to the useful or interesting matter-element. We call these matter-elements the correlative matter-elements We will discuss how to find these correlative matter-elements subsequently. Details of algorithm of finding correlative matter-element and their application may be seen in reference 5 Association rules came from efforts to discover useful patterns in customers transaction databases. The very famous example is: 87%of the customers that have bought beer have also bought chips   Suppose C C 1 C 2 C n is n-dimensional characteristics of class-thing N D={e 1 e 2 e n is a set of measure results Where e i represents the specific n-dimensional matter-element that are obtained through measuring the n-dimensional characteristics of a certain case N i of  class-thing N and e i R 1 R 2  R n  1 i N R R 1 R 2 R 3 R 1 R 2 R 3 order Proceedings of the Third International Conference on Information Technology and Applications \(ICITAê05 0-7695-2316-1/05 $20.00 © 2005 IEEE 


Association rule is an implication formula that is defined as A 1 A 2  A n B 1 B 2 B n where A i B i 1 i n represent a set of matter-element of different value of characteristic C i of N, and C\(A 1   C\(A 2    C\(A n   C\(B 1   C\(B 2    C\(B n   where C\(A i  C\(B i t the operation of getting the characteristic of matter-element A i and B i  Support-degree is defined as following Sd A 1 A 2 A n B 1 B 2 B n P\(A 1  A 2   A n  B 1  B 2  B n  Confidence-degree is defined as following Cd A 1 A 2 A n B 1 B 2 B n P\(B 1  B 2   B n A 1  A 2   A n       2 1 2 1 2 1 n n n A A A P B B B A A A P         1\. The characteristics can generally be classified into two kinds: the quantitative and the qualitative characteristics The quantitative characteristic should be discretized before processing. Interval value, for instance 0 10 10 20 20 30 and so on ,can be used to replace the specific value of temperature character  2\d the frequent matter-element sets The appearance frequency of a certain matter-element set is the number of the measure result in D that contains it. If the appearance frequency of a matter-element set is bigger than or equal to min\(Sd\e call it satisfies the minimum support degree min\(Sd\ called frequent matter-element set  3\ the correlative matter-element  For every of the subset of frequent matter-element L, if Sd\(L\\(s min\(Sd\, then output association rule çs L-sé. we can draw that those matter-element that are contained by the two matter-element sets s and L-s are closely related, compute the association value S RiRj R i  L s R j  s\d find the correlative matter-element that satisfy the requirement J I R R S     D R R P j i  where P\(R i  R j  represents the number of measure results that contain both R i and R j D| represents the number of measure results in D. If S RiRj r r represents the valve value, and it can generally be set as 0.5 then matter-element R i is labeled as the correlative matter-element of matter-element R j  V. Conclusions In this paper, we have presented a new method to deal with multiple data formats and data representation by using matter-element, a general method of mining correlative matter-element based on association rules has been given. Extension data mining is based on mater-element and different from other traditional methods, it has a good application prospect Acknowledgements The authors are grateful to National Natural Science Foundation of China \(60272089\d Guangdong Provincial Natural Science Foundation of China \(980406 for decisive support Reference 1 Ca i W e n. Ex te ns ion t h e o ry a nd its a pplic a t i on  Chinese Science Bulletin. 44\(17\, 1999 2  U s a m a Fay y a d, P a ul S t ol or z  D a ta  m i ning a nd KDD: Promise and challenges, Future Generation Computer Systems 13 \(1997\ 99-115 3 Ca i W e n. Ex te nsio n se t a nd n on-c om pa tible  problem, Advances Mathematics and Mechanics in China \(in Chinese\ol.2, Beijing: International Academic Publishers, 1990,1-21 4 F  Bo do n, L  R ony a i T r ie An Alternative Data Structure for Data Mining Algorithms, Mathematical and Computer Modeling 38\(2003\ 739-751 5 L u Qing Y u Y ong q u a n  Corre l a tiv e Ma tte r e l e m e n t and Their Application in Extension Detecting. Journal of Guangdong University of Technology No.2 \(2005 Proceedings of the Third International Conference on Information Technology and Applications \(ICITAê05 0-7695-2316-1/05 $20.00 © 2005 IEEE 


tion t is associated with an identi?er TID, a time information tt indicating the time when the transaction occurred, and a set of items tc such that tc ? I. Let D be divided into a sequence of n partitions, P1, P2 and Pn, each Pi containing a set of transactions occurring in the corresponding time period Ti with the duration being that of the smallest time granularity. Mining fuzzy temporal association rules in a database is to discover interesting patterns from the partitions divided in D, with corresponding time periods weighted by their matching degrees to the queried fuzzy calendar. The fuzzy temporal association rules discovered should have weighted support and con?dence greater than the user-speci?ed support and con?dence thresholds, respectively Let FC be the speci?ed fuzzy calendar, and wi be the matching degree, or weight, of the time period Ti corresponding to partition Pi in the database D where wi is calculated as in Eq.\(10 set I ? I, a transaction t is said to contain I if and only if I ? tc. Let |Pi\(I taining itemset I in partition Pi. The weighted count of an itemset I in D, denoted ?D\(I D\(I n k=1 Pk\(I  wk 11 We say that an itemset I is frequent, with respect to a support threshold of s% if D\(I n k=1 Pk  wk  s% \(12 where |Pk| denotes the number of transactions in partition Pk. The term n k=1\(|Pk  wk  s% is called the weighted count threshold of D. A fuzzy temporal association rule with respect to a fuzzy calendar, FC, is an implication of the form X ?FC Y \(13 where X ? I, Y ? I, and X ? Y = ?. As usual [1 X and Y are required to be non-empty and a rule thus contains at least two items. The association rule X?FCY is said to have weighted support s% in the database D if D\(X?Y n k=1 Pk  wk  s%. \(14 For an association rule X?FCY , let D\(X?Y X 15 The rule is said to hold in D with weighted con?dence c For a given pair of con?dence and support thresholds, c% and s%, and a given fuzzy calendar FC, the problem of mining fuzzy temporal association rules from the database D is to ?nd out all the association rules that have weighted con?dence and support greater than or equal to c% and s%, respecitvely. As usual, two subproblems are involved. The ?rst subproblem is to ?nd, with respect to FC, all frequent itemsets in D. The second subproblem is, from the set of frequent itemsets, to ?nd out all the association rules that have a weighted con?dence value greater than or equal Proceedings of the 11th International Symposium on Temporal Representation and Reasoning  TIME  04 1530-1311/04 $20.00  2004 IEEE to c%. Given a frequent itemset I, associated rules related to I are constructed as follows. Let I be decomposed into X and Y such that X?Y = I and X?Y 


posed into X and Y such that X?Y = I and X?Y X?FCY is an association rule if ?D\(I X Since the solution to the second subproblem is straightforward [1], major research e?orts have been spent on the ?rst subproblem, i.e., ?nding frequent itemsets Therefore, our research mainly focuses on the ?rst subproblem. Given the support threshold s%, our mining system ?nds out the set L  X |X ? I??D\(X n k=1 Pk  wk  s  16 from the temporal database D. For convenience, an itemset that contains exactly k items is called a kitemset. The set of frequent k-itemsets is commonly denoted by Lk. Note that the fuzzy temporal association rules de?ned above are identical to traditional association rules if the weights of all the time periods in D are set to the same value 3.2. Mining Fuzzy Temporal Association Rules In mining a time-variant database, traditional mining methods treat transactions in di?erent time periods individually and process them with the same procedure without fully considering the time-variant characteristics of the items and transactions. Consequently some interesting rules may not be discovered. We provide a method to remedy this disadvantage. The fuzzy calendar algebra is used to describe desired temporal requirements, and then PWM \(Progressive Weighted Miner  ciation rules from a database In general, a database is too large to be held in main memory. Thus, the data mining techniques applied to very large databases have to be highly scalable for e?cient execution. By partitioning a transaction database into n partitions, P1, P2, . . . , Pn, PWM employs a progressive ?ltering scheme to generate the set of candidate itemsets for the database. One partition is considered at a time, and the cumulated information discovered in previous partitions, including a progressive candidate set of 2-itemsets, C2, their partial occurrence counts, and the corresponding partial supports required, is carried over along to the subsequent partitions. When all the partitions have been processed, the set of candidate itemsets, C, for the database can be obtained For each frequent itemset I, there must exist some partition Pk, 1 ? k ? n, such that I is frequent from partition Pk to Pn. Suppose E is a candidate 2-itemset Partition Date TID Items 1 A,C,D,E,F P1 2003/09/15 2 B,D,F Mon 4 A,B,D,E,F D P2 2003/09/16 5 A,B,C,E,F Tue 7 A,D,E,F P3 2003/09/17 8 A,B,D,F Wed Table 1. A transaction database from Pk to Pt, 1 ? k ? t ? n. Let the current partition be Pt+1. If we detect that E is not frequent from Pk to Pt+1, then E can be deleted from C2. If E is indeed frequent, it must be frequent in some later partition Pk? , k? &gt; k, and we can add it to C2 again with starting partition being Pk? . Therefore, after each partition, Pi, is processed, new partial frequent 2-itemsets 


tition, Pi, is processed, new partial frequent 2-itemsets may be added into C2, with their starting partition and partial counts being recorded. Furthermore, the old itemsets in C2 are checked if they are continually frequent from its starting partition to Pi. If a candidate 2-itemset is no longer partially frequent, this itemset is removed from C2. After all partitions have been processed, the set of candidate 2-itemsets, C2, which is close to the set of frequent 2-itemsets, is obtained Based on C2, all candidate k-itemsets, k &gt;= 3, are generated. Finally, one database scan is applied to calculate the supports of all candidate itemsets and frequent itemsets are determined. Fuzzy temporal association rules can then be formed from the discovered frequent itemsets 3.3. An Example We give an example for illustration. Consider the database D, shown in Table 1, which contains 9 transactions and is segmented into three partitions, P1, P2 and P3, each containing 3 transactions. Let the support and con?dence thresholds be 40% and 75%, respectively. Assume that the queried fuzzy calendar is the fuzzy calendar c1 given in Section 2, i.e., c1 represents \(\(in themiddle of amonth and at the end of a year or \(at the end of a week and at the beginning of a year The membership function of c1 is shown in Eq.\(6 sume that  mm  ey  ew , and  by are the membership functions shown in Figure 1 Firstly, we calculate the weights w1, w2, and w3 for partitions P1, P2, and P3, respectively. The time interval T1 of P1 is 2003/09/15 \(Mon degrees of T1 with respect to  mm  ey  ew , and  by Proceedings of the 11th International Symposium on Temporal Representation and Reasoning  TIME  04 1530-1311/04 $20.00  2004 IEEE P1 itemset start count AD 1 1.34 AE 1 1.34 DE 1 1.34 DF 1 1.34 Table 2. Candidate 2-itemsets generated from partition P1 are  mm\(15  ey\(9  ew\(1  by\(9 w1  mm\(15 ey\(9  ew\(1 by\(9   mm\(15 ey\(9    ew\(1 by\(9 1.0  0.67 0.0  0.0 1.0  0.67  0.0  0.0 Similarly, we have T2 of P2 being 2003/09/16 \(Tue and T3 of P3 being 2003/09/17 \(Wed w2  mm\(16 ey\(9  ew\(2 by\(9   mm\(16 ey\(9    ew\(2 by\(9 1.0  0.67 0.0  0.0 1.0  0.67  0.0  0.0 w3  mm\(17 ey\(9  ew\(3 by\(9   mm\(17 ey\(9    ew\(3 by\(9 0.8  0.67 0.0  0.0 0.8  0.67  0.0  0.0 Now we generate candidate 2-itemsets C2 for D partition by partition  Processing of P1. The weighted count threshold for P1 is 0.4  3  0.67 = 0.804. The accumulative weighted count threshold for P1 is also 0.804 Among all the possible combinations of 2-itemsets in P1, only AD, AE, DE, and DF have accumulative weighted counts greater than or equal to 0.804. Therefore, these 2-itemsets, together with their accumulative weighted counts \(count starting partitions \(start 


starting partitions \(start in Table 2  Processing of P2. The weighted count threshold for P2 is m2 = 0.4  3  0.67 = 0.804. The accumulative weighted count threshold from partition P1 to partition P2 is 0.804 + 0.804 = 1.608. We ?nd that 5 new 2-itemsets, AB, AF , BE, BF , and EF in P2 have weighted counts greater than m2, so they are added to C2. Furthermore, the old itemsets AD, AE, DE, and DF have their accumulative weighted counts greater than 1.608. Therefore, they are retained in C2. The information kept after processing P2 is shown in the left part of Table 3 P2 P3 itemset start count itemset start count AB 2 1.34 AB 2 1.87 AD 1 2.01 AD 1 3.61 AE 1 2.68 AE 1 3.21 AF 2 1.34 AF 2 2.94 BE 2 1.34 BF 2 2.54 BF 2 2.01 DE 1 2.54 DE 1 2.01 DF 1 3.61 DF 1 2.01 EF 2 1.87 EF 2 1.34 Table 3. Candidate 2-itemsets generated after scanning partition P2 and P3, respectively  Processing of P3. The weighted count threshold for P3 is 0.4  3  0.536 = 0.643. All new 2-itemsets generated in P3 have weighted counts less than 0.643. The itemsets generated in P1 all have accumulative weighted counts greater than 2.25 and the itemsets generated in P2, except BE, have accumulative weighted counts greater than 1.45, so they are retained in C2 and BE is deleted from C2. The resulting candidate 2-itemsets after processing P3 are shown in the right part of Table 3 Therefore, we have C2 = {AB,AD,AE,AF,BF,DE,DF,EF C3 = {ABF,ADE,ADF,AEF,DEF C4 = {ADEF Ck = ?, k ? 5 By scanning D once, we have the sets of frequent kitemsets, Lk, k ? 2, of D along with their counts to be L2 = {\(AD, 3.61 AE, 3.21 AF, 3.61 BF, 3.21 DE, 2.54 DF, 3.61 EF, 2.54 L3 = {\(ADE, 2.54 ADF, 2.94 AEF, 2.54 Lk = ?, k ? 4 and L = L2?L3. The association rules can then be obtained from the frequent itemsets in L 4. Experimental Results In this section, experimental results obtained with a PC with AMD Athlon XP CPU and 1.0G memory are presented 4.1. Experiment 1 In this experiment, we compare our fuzzy calendar algebra with the calendar algebra proposed in [16]. The Proceedings of the 11th International Symposium on Temporal Representation and Reasoning  TIME  04 1530-1311/04 $20.00  2004 IEEE Figure 4. Performance comparison between the calendar algebra and our fuzzy calendar algebra with a simple calendar calendar algebra de?nes operators such as dicing, slicing, and ?atten to construct complex calendars. The time intervals are obtained from a speci?ed calendar and the calendric association rules are discovered in these time intervals. For a complex calendar, the calendar algebra decomposes the calendar into basic ones 


endar algebra decomposes the calendar into basic ones and then the time intervals of each basic calendar are separately searched. This approach is not e?cient since one time interval may be searched with several di?erent basic calendars. On the contrary, our fuzzy calendar algebra checks each time interval only once and can easily ?nd out all the time intervals in a given calendar. Repetitive and unnecessary searches in a time interval can be avoided, and the performance is improved We use 1825 time intervals collected in 5 years, with each time interval representing one day in a year. The execution time for ?nding out the desired time intervals by the calendar algebra and the fuzzy calendar algebra, respectively, is shown in Figure 4. The calendar algebra searches each time interval twice while the fuzzy calendar algebra searches each time interval only once, and thus we can clearly see that our method is more e?cient in interpreting calendars. For more complicated calendars, i.e., containing more basic calendars, our fuzzy calendar algebra performs even better as shown in Figure 5 4.2. Experiment 2 In this experiment, we  d like to show the e?ectiveness of our strategy for mining fuzzy temporal patterns. The number of candidates and frequent itemsets discovered are reported. The execution time for discovering the itemsets is also presented. The dataset Figure 5. Performance comparison between the calendar algebra and our fuzzy calendar algebra with complicated calendars support number of number of threshold candidate itemsets frequent itemsets 0.02 1889 1167 0.03 1043 796 0.04 911 633 0.05 635 512 0.06 327 243 0.07 245 182 0.08 179 115 Table 4. TheNumber of candidates and frequent itemsets discovered T 10.I4.D100K.C10%, containing synthetic data [1] is used, where T is the mean size of a transaction, I is the mean size of potential maximal frequent itemsets D is the number of transactions in units of K, i.e 1000, and C is the correlation between items in terms of percentage. The dataset is partitioned into 200 partitions and there are 500 transactions in each partition. To infer from these partitions with our fuzzy calendar algebra, we assume the ?rst partition being the time interval of 2003/01/01, the second partition being of 2003/01/02, . . . , and so on. The calendar we are interested in is the one given in Eq.\(6 ber of candidates and frequent itemsets discovered are given in Table 4 and the execution time for discovering these itemsets is shown in Figure 6. From Table 4 and Figure 6, proper numbers of frequent itemsets can be discovered in acceptable time with our method 5. Conclusion We have presented the fuzzy calendar algebra which supports fuzzy queries on calendars. Fuzzy calendars Proceedings of the 11th International Symposium on Temporal Representation and Reasoning  TIME  04 1530-1311/04 $20.00  2004 IEEE Figure 6. Execution time with di?erent support thresholds are natural and easy for use in the sense that they capture the way in which human beings reason with time requirements. To accommodate temporal expressions with multiple time granularities, ?ve operations, and 


with multiple time granularities, ?ve operations, and or, not, xor, and sub, are introduced We have shown the usefulness of the fuzzy calendar algebra by incorporating it with PWM to mine fuzzy temporal association rules from temporal databases Firstly, the transactions of the database are divided into a sequence of partitions. Then the weight of each partition is inferred, denoting the matching degree of the corresponding time period to the fuzzy calendar speci?ed in the user  s queries. Temporal patterns in the divided time periods of di?erent matching degrees are then e?ciently produced, and the number of database scans can be e?ectively reduced. Experimental results have shown that this approach of ?nding fuzzy temporal association rules is very e?ective References 1] R. Agrawal and R. Srikant. Fast algorithms for mining association rules. InProceedings of the International Very Large Database Conference , pages 487-499, 1994 2] C. Antunes and A. Oliveira. Temporal data mining: an overview. In Proceedings of KDD Workshop on Temporal Data Mining, pages 1  13, 2001 3] W. H. Au and K. C. C. Chan. Farm: A data mining system for discovering fuzzy association rules. In Proceedings of the 8th IEEE International Conference on Fuzzy Systems, pages 1217  1222, 1999 4] C. Bettini, C. E. Dyreson,W. S. Evans, and R. T. Snodgrass. A glossary of time granularity concepts. Temporal Databases: Research and Practice, Lecture Notes in Computer Science, \(1399  413, 1998 5] C. Bettini and R. D. Sibi. Symbolic representation of user-de?ned time granularities. Annals of Mathematics and Arti?cial Intelligence, 30\(1-4  92, 2000 6] C.Bettini,X.S.Wang, andS.Jajodia. Temporal semantic assumptions and their use in databases. IEEETrans Knowledge and Data Engineering, 10\(2  296, 1998 7] R. Chandra, A. Segev, and M. Stonebraker. Implementingcalendars and temporal rules innext generation databases. InProceedings of 10th International Conference on Data Engineering, pages 264  273, 1994 8] C.E.Dyreson,W.S.Evans,H.Lin, andR.T. Snodgrass E?ciently supporting temporal granularities. IEEE Trans. Knowledge and Data Engineering, 12\(4  587, 2000 9] G. Becher, F. Clerin-Debart and P. Enjalbert. A model for time granularity in natural language. In Proceedings of the 5th International Workshop on Temporal Representation and Reasoning, pages 29  36, 1998 10] C. Giannella, J. Han, J. Pei, X. Yan, and P. S. Yu. H Kargupta, A. Joshi, K. Sivakumar, and Y. Yesha \(eds Next Generation DataMining, chapterMiningFrequent Patterns in Data Streams at Multiple Time Granularities. 2003 11] I. A. Goralwalla, Y. Leontiev, M. T. Ozsu, D. Szafron and C. Combi. Temporal granularity: Completing the puzzle. Journal of Intelligent Information Systems 16\(1  63, 2001 12] C. M. Kuok, A. W. C. Fu, and M. H. Wong. Mining fuzzy association rules in databases. SIGMOD Record 27\(1  46, 1998 13] C. H. Lee, J. C. Ou, , and M. S. Chen. Progressive weightedminer: An e?cientmethod for time-constraint mining. In Proceedings of 7th Paci?c-Asia Conference on Knowledge Discovery and Data Mining, pages 449  460, 2003 14] I. Merlo, E. Bertino, E. Ferrari, S. Gadia, and G. Guerrini. Querying multiple temporal granularity data. In Proceedings of the Seventh International Workshop on Temporal Representation and Reasoning, pages 103  114, 2000 15] P. Ning, X. S.Wang, and S. Jajodia. An algebraic repre 


15] P. Ning, X. S.Wang, and S. Jajodia. An algebraic representation of calendars. Annals of Mathematics and Arti?cial Intelligence, 36\(1-2  38, 2002 16] S. Ramaswamy, S. Mahajan, and A. Silberschatz. On thediscovery of interesting patterns in association rules InProceedings of the International Very Large Database Conference, pages 368  379, 1998 17] J. F. Roddick and M. Spiliopoulou. A survey of temporal knowledge discovery paradigms and methods. IEEE Trans. Knowledge and Data Engineering, 14\(4  767, 2002 18] M.D. Soo, R.T. Snodgrass, C. E. Dyreson, C. S. Jensen and N. Kline. Architectural extensions to support multiple calendars. TechnicalReportTR-32,Computer Science Department, University of Arizona, 1992 19] L.A.Zadeh. Fuzzy sets. Information andControl, 8:338  353, 1965 20] R. J. Zhang and E.Unger. Calendar algebra. Technical Report TR-CS-96-1, Kansas State University, 1996 Proceedings of the 11th International Symposium on Temporal Representation and Reasoning  TIME  04 1530-1311/04 $20.00  2004 IEEE pre></body></html 


Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining 7 Conclusion and Future Work References frontier  pages 487\320499 Morgan Kaufmann 1994  W orkshop on frequent itemset mining implementations 2003 http://\336mi.cs.helsinki.\336/\336mi03  W orkshop on frequent itemset mining implementations 2004 http://\336mi.cs.helsinki.\336/\336mi04  J  Han J  Pei and Y  Y in Mining frequent patterns without candidate generation In Proceedings of 20th International Conference on Very Large Data Bases VLDB VLDB Journal Very Large Data Bases Data Mining and Knowledge Discovery An International Journal Lecture Notes in Computer Science  2004  J W ang and G Karypis Harmon y Ef 336ciently mining the best rules for classi\336cation In The Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining KDD\32504 Symposium on Principles of Database Systems 2 b Average time taken per frequent itemset shown on two scales T10I4D100K is increased and hence the number of frequent items decreases Figure 5\(c also shows that the maximum frontier size is very small Finally we reiterate that we can avoid using the pre\336x tree and sequence map so the only space required are the itemvectors and the minSup SIAM International Conference on Data Mining required drops quite quickly as ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery 2000 ACM SIGMOD Intl Conference on Management of Data Figure 5 Results  8\(3\3204 2000  F  P an G C ong A T ung J Y ang and M Zaki Carpenter Finding closed patterns in long biological datasets In  2121:236 2001  M Steinbach P N T an H Xiong and V  K umar  Generalizing the notion of support In a Runtime ratios T10I4D100K c Number of Itemvectors needed and maximum frontier size T10I4D100K  pages 1\32012 ACM Press May 2000  F  K orn A Labrinidis Y  K otidis and C F aloutsos Quanti\336able data mining using ratio rules  Morgan Kaufmann 2003  J Pei J Han and L Lakshmanan Pushing convertible constraints in frequent itemset mining We showed interesting consequences of viewing transaction data as itemvectors in transactionspace and developed a framework for operating on itemvectors This abstraction gives great 337exibility in the measures used and opens up the potential for useful transformations on the data Our future work will focus on 336nding useful geometric measures and transformations for itemset mining One problem is to 336nd a way to use SVD prior to mining for itemsets larger than  pages 205\320215 2005  We also presented GLIMIT a novel algorithm that uses our framework and signi\336cantly departs from existing algorithms GLIMIT mines itemsets in one pass without candidate generation in linear space and time linear in the number of interesting itemsets Experiments showed that it beats FP-Growth above small support thresholds Most importantly it allows the use of transformations on the data that were previously impossible  That is the space required is truly linear  D Achlioptas Database-friendly random projections In  2001  R Agra w al and R Srikant F ast algorithms for mining association rules In  8:227\320252 May 2004  J Pei J Han and R Mao CLOSET An ef 336cient algorithm for mining frequent closed itemsets In  pages 21\32030 2000  S Shekhar and Y  Huang Disco v ering spatial colocation patterns A summary of results 


mator from sensor 1 also shown 6. CONCLUSIONS This paper derives a Bayesian procedure for track association that can solve a large scale distributed tracking problem where many sensors track many targets. When noninformative prior of the target state is assumed, the single target test becomes a chi-square test and it can be extended to the multiple target case by solving a multidimensional assignment problem. With the noninformative prior assumption, the optimal track fusion algorithm can be a biased one where the regularized estimate has smaller mean square estimation error. A regularized track fusion algorithm was presented which modifies the optimal linear unbiased fusion rule by a less-than-unity scalar. Simulation results indicate the effectiveness of the proposed track association and fusion algorithm through a three-sensor two-target tracking scenario 7. REFERENCES 1] Y. Bar-Shalom and W. D. Blair \(editors Tracking: Applications and Advances, vol. III, Artech House, 2000 2] Y. Bar-Shalom and H. Chen  Multisensor Track-to-Track Association for Tracks with Dependent Errors  Proc. IEEE Conf. on Decision and Control, Atlantis, Bahamas, Dec. 2004 3] Y. Bar-Shalom and X. R. Li, Multitarget-Multisensor Tracking Principles and Techniques, YBS Publishing, 1995 4] Y. Bar-Shalom, X. R. Li and T. Kirubarajan, Estimation with Applications to Tracking and Navigation: Algorithms and Software for Information Extraction, Wiley, 2001 5] S. Blackman, and R. Popoli  Design and Analysis of Modern Tracking Systems  Artech House, 1999 10 15 20 25 30 35 40 45 50 55 60 2 4 6 8 10 12 14 Time N o rm a li z e d e s ti m a ti o n e rr o r s q u a re d Target 1 Sensor 1 Centralized Est Track Fusion 10 15 20 25 30 35 40 45 50 55 60 0 2 


2 4 6 8 10 12 14 Time N o rm a li z e d e s ti m a ti o n e rr o r s q u a re d Target 2 Sensor 1 Centralized Est Track Fusion Fig. 7. Comparison of the NEES for centralized IMM estimator \(configuration \(i estimators \(configuration \(ii sensor 1 also shown 6] H. Chen, T. Kirubarajan, and Y. Bar-Shalom  Performance Limits of Track-to-Track Fusion vs. Centralized Estimation: Theory and Application  IEEE Trans. Aerospace and Electronic Systems 39\(2  400, April 2003 7] H. Chen, K. R. Pattipati, T. Kirubarajan and Y. Bar-Shalom  Data Association with Possibly Unresolved Measurements Using Linear Programming  Proc. 5th ONR/GTRI Workshop on Target Tracking Newport, RI, June 2002 8] Y. Eldar, and A. V. Oppenheim  Covariance Shaping Least-Square Estimation  IEEE Trans. Signal Processing, 51\(3 pp. 686-697 9] Y. Eldar  Minimum Variance in Biased Estimation: Bounds and Asymptotically Optimal Estimators  IEEE Trans. Signal Processing, 52\(7 10] Y. Eldar, A. Ben-Tal, and A. Nemirovski  Linear Minimax Regret Estimation of Deterministic Parameters with Bounded Data Uncertainties  IEEE Trans. Signal Processing, 52\(8 Aug. 2004 11] S. Kay  Conditional Model Order Estimation  IEEE Transactions on Signal Processing, 49\(9 12] X. R. Li, Y. Zhu, J. Wang, and C. Han  Optimal Linear Estimation Fusion  Part I: Unified Fusion Rules  IEEE Trans. Information Theory, 49\(9  2208, Sept. 2003 13] X. R. Li  Optimal Linear Estimation Fusion  Part VII: Dynamic Systems  in Proc. 2003 Int. Conf. Information Fusion, Cairns, Australia, pp. 455-462, July 2003 14] X. D. Lin, Y. Bar-Shalom and T. Kirubarajan  Multisensor Bias Estimation Using Local Tracks without A Priori Association  Proc SPIE Conf. Signal and Data Processing of Small Targets \(Vol 


SPIE Conf. Signal and Data Processing of Small Targets \(Vol 5204 15] R. Popp, K. R. Pattipati, and Y. Bar-Shalom  An M-best Multidimensional Data Association Algorithm for Multisensor Multitarget Tracking  IEEE Trans. Aerospace and Electronic Systems, 37\(1 pp. 22-39, January 2001 pre></body></html 


20 0  50  100  150  200  250  300 Pe rc en ta ge o f a dd iti on al tr af fic Cache size 200 clients using CMIP 200 clients using UIR c Figure 6. The percentage of additional traf?c the cache at every clock tick. A similar scheme has been proposed in [13], which uses fv, a function of the access rate of the data item only, to evaluate the value of each data item i that becomes available to the client on the channel If there exists a data item j in the client  s cache such that fv\(i j replaced with i A prefetch scheme based on the cache locality, called UIR scheme, was proposed in [7]. It assumes that a client has a large chance to access the invalidated cache items in the near future. It proposes to prefetch these data items if it is possible to increase the cache hit ratio. In [6], Cao improves the UIR scheme by reducing some unnecessary prefetches based on the prefetch access ratio \(PAR scheme, the client records how many times a cached data item has been accessed and prefetched, respectively. It then calculates the PAR, which is the number of prefetches divided by the number of accesses, for each data item. If the PAR is less than one, it means that the data item has been accessed a number of times and hence the prefetching is useful. The clients can mark data items as non-prefetching when PAR &gt; b, where b is a system tuning factor. The scheme proposes to change the value of b dynamically according to power consumption. This can make the prefetch scheme adaptable, but no clear methodology as to how and when b should be changed. Yin et al. [19] proposed a power-aware prefetch scheme, called value-based adaptive prefetch \(VAP the number of prefetches based on the current energy level to prolong the system running time. The VAP scheme de?nes a value function which can optimize the prefetch cost to achieve better performance These existing schemes have ignored the following characteristics of a mobile environment: \(1 query some data items frequently, \(2 during a period of time are related to each other, \(3 miss is not a isolated events; a cache miss is often followed by a series of cache misses, \(4 eral requests in one uplink request consumes little additional bandwidth but reduces the number of future uplink requests. In this paper, we addressed these issues using a cache-miss-initiated prefetch scheme, which is based on association rule mining technique. Association rule mining is a widely used technique in ?nding the relationships among data items. The problem of ?nding association rules among items is clearly de?ned by Agrawal et al. in [5]. However in the mobile environment, one cannot apply the existing association rule mining algorithm [4] directly because it is too complex and expensive to use This makes our algorithm different from that of [4] in 


This makes our algorithm different from that of [4] in twofold. First, we are interested in rules with only one data item in the antecedent and several data items in the consequent. Our motivation is to prefetch several data items which are highly related to the cache-miss data item within Proceedings of the 2004 IEEE International Conference on Mobile Data Management \(MDM  04 0-7695-2070-7/04 $20.00  2004 IEEE the cache-miss initiated uplink request. We want to generate rules where the antecedent is one data item, but the cache-missed data item and the consequent is a series of data items, which are highly related to the antecedent. If we have such rules, we can easily ?nd the data items which should also be piggybacked in the uplink request. Second in mobile environment, the client  s computation and power resources are limited. Thus, the rule-mining process should not be too complex and resource expensive. It should not take a long time to mine the rules. It should not have high computation overhead. However, most of the association rule mining algorithms [4, 5] have high computation requirements to generate such rules 5. Conclusions Client-side prefetching technique can be used to improve system performance in mobile environments. However, prefetching also consumes a large amount of system resources such as computation power and energy. Thus, it is very important to only prefetch the right data. In this paper, we proposed a cache-miss-initiated prefetch \(CMIP scheme to help the mobile clients prefetch the right data The CMIP scheme relies on two prefetch sets: the alwaysprefetch set and the miss-prefetch set. Novel association rule based algorithms were proposed to construct these prefetch sets. When a cache miss happens, instead of sending an uplink request to only ask for the cache-missed data item, the client requests several items, which are within the miss-prefetch set, to reduce future cache misses. Detailed experimental results veri?ed that the CMIP scheme can greatly improve the system performance in terms of increased cache hit ratio, reduced uplink requests and negligible additional traf?c References 1] S. Acharya, M. Franklin, and S. Zdonik. Prefetching From a Broadcast Disk. Proc. Int  l Conf. on Data Eng., pages 276  285, Feb. 1996 2] S. Acharya, M. Franklin, and S. Zdonik. Balancing Push and Pull for Data Broadcast. Proc. ACM SIGMOD, pages 183  194, May 1997 3] S. Acharya, R. Alonso, M. Franklin, and S. Zdonik. Broadcast disks: Data Management for Asymmetric Communication Environments. Proc. ACM SIGMOD, pages 199  210 May 1995 4] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In J. B. Bocca, M. Jarke, and C. Zaniolo editors, Proc. 20th Int. Conf. Very Large Data Bases, VLDB pages 487  499. Morgan Kaufmann, 12  15 1994 5] R. Agrawal, Tomasz Imielinski, and Arun Swami. Mining Association Rules Between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207  216, Washington, D.C May 1993 6] G. Cao. Proactive Power-Aware Cache Management for Mobile Computing Systems. IEEE Transactions on Computers, 51\(6  621, June 2002 7] G. Cao. A Scalable Low-Latency Cache Invalidation Strategy for Mobile Environments. IEEE Transactions on Knowledge and Data Engineering, 15\(5 ber/October 2003 \(A preliminary version appeared in ACM MobiCom  00 8] K. Chinen and S. Yamaguchi. An Interactive Prefetching Proxy Server for Improvement of WWW Latency. In Proc INET 97, June 1997 9] E. Cohen and H. Kaplan. Prefetching the means for docu 


9] E. Cohen and H. Kaplan. Prefetching the means for document transfer: A new approach for reducing web latency. In Proceedings of IEEE INFOCOM, pages 854  863, 2000 10] R. Cooley, B. Mobasher, and J. Srivastava. Data preparation for mining world wide web browsing patterns. Knowledge and Information Systems, 1\(1  32, 1999 11] C. R. Cunha, Azer Bestavros, and Mark E. Crovella. Characteristics of WWW Client Based Traces. Technical Report TR-95-010, Boston University, CS Dept, Boston, MA 02215, July 1995 12] D. Duchamp. Prefetching hyperlinks. In USENIX Symposium on Internet Technologies and Systems \(USITS  99 1999 13] V. Grassi. Prefetching Policies for Energy Saving and Latency Reduction in a Wireless Broadcast Data Delivery System. In ACM MSWIM 2000, Boston MA, 2000 14] S. Hameed and N. Vaidya. Ef?cient Algorithms for Scheduling Data Broadcast. ACM/Baltzer Wireless Networks \(WINET  193, May 1999 15] Q. Hu and D. Lee. Cache Algorithms based on Adaptive Invalidation Reports for Mobile Environments. Cluster Computing, pages 39  48, Feb. 1998 16] Z. Jiang and L. Kleinrock. An Adaptive Network Prefetch Scheme. IEEE Journal on Selected Areas in Communications, 16\(3  11, April 1998 17] V. Padmanabhan and J. Mogul. Using Predictive Prefetching to Improve World Wide Web Latency. Computer Communication Review, pages 22  36, July 1996 18] N. Vaidya and S. Hameed. Scheduling Data Broadcast in Asymmetric Communication Environments. ACM/Baltzer Wireless Networks \(WINET  182, May 1999 19] L. Yin, G. Cao, C. Das, and A. Ashraf. Power-Aware Prefetch in Mobile Environments. IEEE International Conference on Distributed Computing Systems \(ICDCS 2002 Proceedings of the 2004 IEEE International Conference on Mobile Data Management \(MDM  04 0-7695-2070-7/04 $20.00  2004 IEEE pre></body></html 


um be r o f C he ck ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 6. The Number of Checked Patterns on the Pumsb Data Set 10 100 1000 10000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 R un T im e s ec  Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 7. The RunTime Comparison on the Pumsb Data Set The runtime comparison of MHP and MAFIA on the Pumsb* data set is shown in Figure 5. In the ?gure, we can observe that the runtime of MHP can be signi?cantly reduced with the increase of h-con?dence thresholds. Also the runtime of MHP can be several orders of magnitude less than that of MAFIA even if the h-con?dence threshold is as low as 0.3. The reason is that the number of checked patterns of MHP is sign?cantly smaller than that of MAFIA Similar results are also obtained from the pumsb data set as shown in Figure 6 and Figure 7. For the pumsb data set the number of checked patterns of MHP is much smaller 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207ñ216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Intíl Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Intíl Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 






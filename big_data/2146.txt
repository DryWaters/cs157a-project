Semantics Oriented Association Rules 0-7803-7280-8/02/$10.00 02002 IEEE 956 Eric Louie IBM Almaden Research Center 650 Harry Road San Jose CA 95 120 ewlouie@almaden.ibm.com Abstract  It is well known that relational theory carries very little semantic To mine deeper semantics, additional modeling are necessary In fact some 223pure\224 association rules are found exist even in a randomly generated data In this paper we consider the relational database in which every attribute value bas some additional information such as price fuzzy degree 
neighborhood, or security compartment and levels Two types of additions are considered one is structure added the other is valued-added Somewhat a surprise the additional cost in semantics checking is found very well compensated by the pruning of non-semantic rules 1 INTRODUCTION In relation theory attribute domains are Cantor sets the interactions among members of real world objects are 223forgotten.\224 For data mining additional modeling of attribute domains are needed to organize deeper semantics of the data We will term such addition to the existing data model semantic added modeling. In this paper we will consider two aspects; one is 
structure added, the other value added 2 MOTIVATION ASSOCIATION RULES IN RANDOM DATA In the experiment 4 a totally discrete data are randomly generated Somewhat a surprise we find some association with substantial supports of length 2 though they did not meet our artificial high requirement of supports This computation implies that frequency itself may not be an adequate criterion for meaningful pattems see the Table 3 in Experiments Report, Section 7 So semantic modeling seems necessary for database mining 3 SEMANTIC 
ADDED MODELING What would be the 223correct\224 mathematical structure to capture the semantics of real world objects? This is a question that has many ad hoc answers we decide to consult the history. Model theory of the first order logic uses a cantor set together with relational structures and functions to model the real world. We will follow it; attribute domains are assumed to have all such structures Previously we have explored the simplest structure namely one binary relation is added to each attribute domains  6 9 lo 12 ll 7 
totally they induce finitely many binary relations on the universe of eneitites In 3 we consider one real valued function for each domain In this paper we combine the two T Y Lin Department of Mathematics and Computer Science San Jose State University San Jose CA 95 192 tylin@cs.sj su.edu namely on each domain we have one binary relation and one function 4 STRUCTURE ADDED DATA MODEL BINARY RELATIONS We will examine the case each attribute domain is assumed to have one binary relation. Its geometric corresponding concept 
is called a binary neighborhood system \(BNS\In the case of equivalence relation a BNS is a partition. The binary relation on each attribute domain in turns induced a binary relation on the universe So on the universe there are finitely many binary relations. We will examine the impact of such added structure on data mining 4.1 Crisp/Fuzzy binary neighborhood systems 4.1.1 A binary relation BR is a subset B cVxU It defines a set called elementary \(basic 
or binary\neighborhood at p E V 4.1.2 A binary neighborhood system BNS denotes either the map B: p  Bp, or the family BP 1 p E V The map B has also been called a binary granulation\(BG The set V together with BNS is called a BNS-space on U or simply BNS-space if V and U is the same Proposition BNS BR and BG are equivalent to each other 
4.1.3 The induced equivalence relation Note that BG B:p E V Bp\200 2u induces a partition as follows The collection of complete inverse images B-l\(Bp forms a partition on V and hence an equivalence on V We use EB to denote this equivalence relation. We may drop the subscript if B is understood 4.1.4 Fuzzifications Binary relation and neighborhood system can be fkzified in other words instead of being a 


subset of V x U it could be a fuzzy subset a membership hction FB V x U O 11  4.2 Structure Added Data Models A traditional relation instance can be viewed as a knowledge representation that maps each entity to a tuple of attribute values Table 1 illustrates the notion 0f.a relation instance on the universe U={ul u2 u3, u4, u5  U I K I S i STATUS j CITY UI I  1 SI  TWENTY  CI Table 1 An Information Table; arrows and 3 I j I S3 i TEN Q I j I S4 i TWENTY i C1 I US I j I S5 j THIRTY C3 Table 1 An Information Table; arrows and parentheses will be suppressed In geographical attribute domain, one can use binary relation to capture the near semantics So on CITY attribute we assume a binary relation holds in the domain see Table 2 CITY I CITY C1 I c1 I c1 I c2 I I c2 I c1 I L IJ tC3 I c2 I c3 I c3 Table 2 near"-Binary Relation In numerical attribute, such as STUATS we have the order binary relation 5 Next we express both B and 5  in BNS format Note that attributes can be regarded as projections. The CITY attribute is a map denoted by CITY again CITY: U  Dom\(CITY Which in each tuple of Table 1, assigns the element in the first column to the element in the last column The inverse map CITY-1 induces a BNS on U So we have Each binary relation, say B induced an equivalence relation E In this case the neighborhood is an equivalence class We should have similar results for 4 we denote it by 0 order binary relation Definition. The 3-tuple U Aj Dom\(Aj\j=1,2   n is called structure added data model where U is the universe AJ is the attributes For the example in Table 1 the structure added model is U, B Cl C2, C3 0 TEN, TWENTY, THIRTY 4.3 The Impact ofAdded Structure to Data Mining In mining such a data model first concern is the cost in checking the added structure So experiments have been conduct in  Somewhat a surprise the cost is well compensated by the saving It does have cost in checking the continuity of association rules, however, the pruning of non continuous rules save the time in computing the long rules One beauty of continuity is that the compositions of continuous rules are also continuous so the only cost is at the length 2 0-7803-7280-8/02/$10.00 02002 JEEE 957 


Table 4 is generated with some embedded semantics. That is some associations are embedded in the algorithm of generating the test data From the table it is clear finding 223pure\224 association rules is expensive In Table 5 some neighborhoods \(one binary relation are generated Based on such a structure the cost of finding continuous association rule is greatly reduced From the artificial data, it \223proves\224 that this BNS theory is promising The next step is to test on real world applications 5 VALUED ADDED DATA MODEL In this section we will consider the case the function valued will be part of the model 5.1 Valued Added Granular Data Model Definition. The 4-tuple U Aj Xj Dom\(Aj j=1,2   n is a Value Added Granular Data Model or VA-Granular Data Model where for each AJ a value add function is defined on each domain Dom\(AJ  Xj  Dom\(Aj  M where M is either a Cantor set W the security lattice SC real numbers or 0 11 Proposition 1 If M is 2\222 then X j is a binary neighborhood system, which is equivalent to a binary relation Proposition 2 If M is SC the security lattice then Xj is a classification and the granular data model is a MLS data model Proposition 3 If M is real number then Xj is a random variable Random variable is not a variable varies randomly it is merely a function whose numerical values are determined by chance; please see for connecting the mathematics to intuition Proposition 4 If M is 0 13 then X j could be a grade of fizziness In this case the granular data model is a fizzy database 5.2 The Impact of Added Structure Model to Data Mining The difference between this and last sections is that the values of the function do participate in computing For example the existing of real valued function implies the existing of a neighborhood system on an attribute domain D a topological space\However, the imposed constraints are imposed more than on the structure of D we use the real values. Table 5 and 6 say the computing of VA-association is quite expensive if we use values alone We would like to comment that by assigning the 223nearest\224 or 223smallest\224 neighborhood at each point we have a BNS. In next, project we will use this BNS called nearest neighborhood system and values 6 PATTERNS PRESERVING STRUCTURES We collect some generalized \223standard patterns 5 Let A and B be two attributes of a relation-with-additional semantics. Let c d be two values of A and B respectively Let NEIGH\(c NEIGH\(d be the respective elementary granules  It is clear that c  NAME\(NEIGH\(c and d  NAME NEIGH\(d Let Card  the cardinal number of a set 0 Structure added association rules 1 A formula c  d is a continuous or semantic decision rule if the inclusion NEIGH\(c E NEIGH\(d is continuous 2 A formula A  B is a continuous or semantic universal decision rule iff V c E A 3 d E B such that NEIGH\(c cNEIGH\(d This rule is equivalent to extension hctional dependence 3 A formula c  d is a robust continuouslsemantic decision rule, if NEIGH\(c ENEIGH\(d and Card\(Pc 2 threshold SI 4 A formula c  d is a soft continuouslsemantic decision rule strong rule if NEIGH\(c is softly included in NEIGH\(d NEIGH\(c 0 NEIGH\(d 5. Weak association rule: A pair \(c d\is an association rules if Card \(NEIGH\(c n NEIGH\(d 2 threshhold 6 A pair \(c d\is said to be in a relation or database if it is a sub-tuple of a tuple that belongs to a relation \(or database 7 A pair c d in a given relation is one-way c d continuous or semantic if every x E Bc, there is at least one y E Bd such that x y is in the given relation 8 A pair \(c, d\in a given relation is a two way continuous \(or semantic if c +d and \(d +c are both continuous 0-7803-7280-8/02/$10.00 02002 IEEE 958 


9 Semantic association rule A pair c d is an association rule iff the pair is an association rule and two way continuous 10 Soft association rule A pair c d is a soft association rule if Card NEIGH\(c n NEIGH\(d 2 threshhold 5 61 Valued added association rules 1 1. In-the-average-association rule: Two attributes Ai and Aj is associated in the average if JE\(Xi E\(Xj I where E is the expected value, and I I is the absolute value 12 Fuzzy decision rule A formula c  d is a fuzzy decision rule, if E G Ed and X\(c I X\(d\where E and Ed are the equivalence classes of c and d In other words, c and d are the names of the equivalence class E and Ed 13 Security leak rule A formula c  d is a security leak decision rule if E c Ed and X\(c I X\(d 14 Value added association rule \(VA-association rule 3 14.1. Sum-version A granule \(sub-tuple b=\(bl nb2 n  nb  is a q-VA-association rule if Sum\(b 2 sq  where where xjo  P\222\(bj q sum  j ,j,*p\(xJo  qj=1 P\222Cbj 14.2 Min-version: A granule \(sub-tuple b=\(bl nb2 n   nb  is a q-VA-association rule if Min\(b  2 sq  where Min\(b\=Minj xjo*p\(xjo  Minq i=lh\(bj q 14.3 Max-version A granule \(sub-tuple b=\(bl nb2 n  nb  is a q-VA-association rule if Max\(b  2 sq  where Max\(b\=Maxj xJo*p\(xJ0  Maxqi=l\(f\(b-i 9 14.4 Traditional: The Max and Min-versions are the traditional one iff the profit function is the constant=l Recall that we are concerning only with the supports so association rules have no directions Since we are using granules a q-association rule is equivalent to a q-large granule the former q means the length of tuple, the latter q means the length of the intersections The frequency of an itemset is the cardinal number of a granule  a finite intersection of elementary granules In general there are no apriori criteria for value added case. However, if we require the thresholds increase with the lengths, that is Then there are apriori criteria: q-large implies all sub-tuples are \(q-+large where i 2 0 Value added granular data model allows us to import many probability theory into data mining. We list a sample here and more work will be reported in the near future 7 EXPERIMENT REPORTS Here are the ACRONYMNs q= length; c =candidate; a=association rules; s=support count 6  time need to generated next rows \(in seconds 7.1 Random Data Table 3 is the results of finding association rules on randomly generated data 1 The relation has 100000 rows and 16 columns we 2. The distinct attribute is limited to 10; there are real world require the support to be 12000 items medical data meet this constraints Table 3 Randomly generated data 7.2 Structure Added Computing Table 4 and 5 is the same as Table 3 except the distinct attribute is limited to 20 0.000s 0.661s 0.000s 120 0.000s 120 0.040s I I I120 I 0.000s I 13 I560 I I I 0.000s I II I560 I I 0.190s I II I I560 I 0.000s 1 14 I1820 I I I 0.090s I 0-1803-1280-8l02/$10.00 02002 IEEE 959 


I I1820 I I 0.741s 1 6 I106 I 0.010s 7 106 0.000s 43 0.000s 43 0.030s I I43 I 0.000s 8 I10 I 0.000s 7 8 11440 76.330s 11440 7.020s 11440 0.000s 12870 164 477s 91 10 0.000s 0.000s 1 0.000s 10 11440 8.633s 11440 0.000s 8008 149.795s I I I 0.000s 12 4368 3.946s 4368 0.000s 1820 1.783s 1820 11.616s 14 560 0.591s 560 0.000s 120 0.070s 9c 00 1 S a 6 0.000s 95 0.010s 15 12 0 0.140s 120 0.000s 16 0.000s 16 0.020s 16 0.000s a 49 49 0.000s 500 0.OlOS 0.070s 0 0 0.000s 6 0 0.000s 0 1.452s 0 0.010s 13993 25.397s 6567 1 1 0.000s 0.000s 65535 65535 725.563s 5 I27832 I I 1198.886s 1 lo I 2.824s 1 152 0.671s 16 16 0.000s 2 120 0.070s 0 0.020s 0 2.614s 4 33066 338.647s 120 0.040s 2 0.010s 3 119445 I 1150.716s Io I 1.312s 102228 0 0.180s 197 0.000s 0.000s 49 335 726.995s 0.000s 1.082s 4368 2.073s 4368 0.000s 13.339s II I8008 I I 4.376s I I I I I8008 I 0.000s I I I10 I I 0.010s I I12870 I I 8.792s I I12870 I 0.000s 110 lo I I I 0.000s I 19 I11440 I I I 199.597s I I lo 10 I 0.000s I semantic rules is inexpinsive II I I8008 I 0.000s I 7.3 Valued Added Computing Table 6 is the results of finding association rules based on data with real valued function 1. The relation has 500 rows and 8 columns we require the 2 The distinct attribute is limited to 20 weights greater than 5.9 I I I I1820 I 0.000s I 17 I4000 I I I 0.561s I 16 11 I I I 0.000s 1 11 I 0.010s I I I lo I 0.460s I I I Table 4 Finding \223pure\224 association rule is expensive 10 0 I I I 0.000s I I54 I 0.000s I 13 I118 I I I 0.000s I II I I87 I 0.010s I 0.000s 0.011s 0.060s 0.000s 0.010s 166 0.080s 0-7803-7280-8/02/$10.00 02002 lEEE 960 


8 CONCLUSIONS The advantage of data mining by granular computing are 1 it is fast in mining classical relations, granular computing is faster than Apriori 13  because the database scan" are replaced by bit operations 2 the use of granular computing is extend to Yea1 world databases semantically richer relations its cost is well compensated by pruning Such extra semantics may be able to use for analyzing unexpected, peculiar rules  151 3 Granular structure is the mathematical structure of the real world So this method is mining directly on the real world not on its representations REFERENCES l R Agrawal T Imielinski and A Swami Mining Association Rules Between Sets of Items in Large Databases in Proceeding of ACM-SIGMOD international Conference on Management of Data pp 207-216 Washington, DC, June, 1993  P Halmos Measure Theory Van Nostrand, 1950 3 T Y Lin Y Y Yao and E Louie Value Added Association Rules  6 Pacific-Asia Conference, Taipei Taiwan May 6-8,2002  T Y Lin Y Y Yao, and E Louie Association Rules with Additional Semantics Modeled by Binary Relations In Rough Set Theory and Granular Computing physica Verlag Shusaku Tsumoto Masahiro Inuiguchi and Shoji Hirano Eds to appear 5 T Y Lin Data Mining and Machine Oriented Modeling A Granular Computing Approach Journal of Applied Intelligence Kluwer Vol 13,No 2 September/October,2000, pp 1 13-124 6 T Y Lin, "Data Mining: Granular Computing Approach In Methodologies for Knowledge Discovery and Data Mining Lecture Notes in Artificial Intelligence 1574 Third Pacific-Asia Conference, Beijing April 26-28 1999  Granular Computing on Binary Relations I Data Mining and Neighborhood Systems In Rough Sets In 24-33 Knowledge Discovery A Skowom and L Polkowski eds Physica-Verlag 1998, 107-121 8 T Y. Lin, "Rough Set Theory in Very Large Databases Symposium on Modeling Analysis and Simulation CESA'96 IMACS Multi Conference Computational Engineering in Systems Applications Lille France July 9 T Y Lin, Neighborhood Systems and Approximation in Database and Knowledge Base Systems Proceedings of the Fourth International Symposium on Methodologies of Intelligent Systems  Poster Session October 12-15, pp lo T Y Lin Neighborhood Systems and Relational Database Abstract Proceedings of CSC 88 February 1988, pp. 725 ll T Y Lin and M Hadjimichael Non-classificatory Generalization in Data Mining Proceedings of The Fourth Workshop on Rough Sets Fuzzy Sets and Machine Discovety Tokyo, Japan, November 8- 10,1996,404-4 1 1 12 T Y Lin and Y.Y Yao Mining Soft Rules Using Rough Sets and Neighborhoods In Symposium on Modeling Analysis and Simulation IMACS Multiconference Computational Engineering in Systems Applications\Lille, France, July 9-12 1996 Vol 2 of 2  Eric Louie and T.Y Lin Finding Association Rules using Fast Bit Computation: Machine-Oriented Modeling In Proceeding of 12th Intemational Symposium ISMIS2000 Charlotte, North Carolina Oct 1 1-14 2000 Lecture Notes in AI 1932.486-494 14 E Louie T Y Lin and A Data Mining Approach using Machine Oriented Modeling Finding Association Rules using Canonical Names In Proceeding of 14th Annual International Symposium Aerospace/Defense Sensing Simulation, and Controls  SPIE Vol 4057, Orlando April  Balaji Padmanabhan and Alexander Tuzhilin "Finding Unexpected Patterns in Data In Data Mining and Granular Computing T Y Lin Y.Y Yao and L Zadeh eds Physica-Verlag to appear 9-12, 1996, Vol 2 of 2,936-941 75-86 1989 1095 1 100 24-28,2000 pp.148-154 0-7803-7280-8/02/$10.00 02002 IEEE 961 


because they will not appear in any large itemset in the later iteration At any k-th iteration some items in db or DB which is not needed for finding large itemsets in the next iteration can be identified and hence removed At any k-th iteration during the scan in the incre ment db while FUP is counting the support for sets in the candidate sets C and W for each transaction TI the Reduce-db function is called It counts for each I E TI the number of sets in C and W which contain I This number gives an upper bound on the num ber of large k-itemsets that contain I If this number is smaller than k then I cannot belong to any large k+l and hence can be removed from all the transactions Using this number Reduce-db can prune off some items from db After the set C has been pruned against db it can be seen that any items in DB which does not belong to any set in Lk or C will not belong to any large IC  l-itemset Therefore in the scanning of DB to compute the supports of sets in C all items that do not belong to any set in Lk or C can be removed In the FUP algorithm, the function Reduce-DB performs this reduction In FUP we have also integrated the direct hashing technique in 9 which further reduces the number of the candidate sets used in iteration two 4 Performance Study In order to assess the performance of FUP experi ments are conducted to compare its performance with that of Apriori and DMP The experiments were per formed on an AIX system on an RS/6000 workstation with model 410 As will be presented in the follow ing the result shows that FUP is much faster than the most successful mining algorithm with respect to updating association rules FUP performs 2 to 6 times faster than DHP for a moderate size database of 100,000 transactions When the database is scaled up to 1,000,000 transactions the speed-up is 2 to 16 times As explained before the key of the speed-up lies on the much smaller amount of candidate sets In some cases the number of candidate sets generated were counted, and it was found that the amount gen erated in FUP is reduced to the range of 1.5  5 of that in DHP This is a very significant reduction As mentioned above we also tested FUP with some very large databases It was found that FUP actually performs much better in larger databases 4.1 Generation of synthetic data The databases used in our experiments are syn thetic data generated using the same technique intro duced in l and modified in 9 The parameters used ILI Number of transactions in database DB Number of transactions in the increment d Mean size of the transactions Mean size of the maximal potentially large itemsets Number of potentially large itemsets Number of items Table 1 Parameter Table TlO.l4.DlOO.dl 3 8.00 1 1 a E 6.00 E 4.00 0 z 2*oo 3 0.00 6.00 4.00 2.00 1.00 0.75 W Minimum support DHPFUP  pri01-i Figure 2 Performance Ratio are similar to those in 9 except that the size of the increment is an additional parameter Table 1 is a list of the parameters used in our synthetic database In the following we use the notation Tx.Iy.Dm.dn modified from the one used in 9 to denote a database in which D  m thousands d  n thousands IT1  x and 111  y In our experiments we set ILI  2000 N  1000 and the secondary parameters S  5 P  50 and Mj  2000 S is the clustering size used in the generation of potential large itemsets P is the pool size to store potential large itemsets from which transactions will receive their items Mj is the multiplying factor associated with the pool Readers not familiar with these parameters please refer to l The way we create our increment is a straight for ward extension of the technique used to synthesize the database In order to do comparison on a database of size D with an increment of size d A database of size D  d is first generated and then the first D transactions are stored in the database DB and the remaining d transactions is stored in the increment db Since all the transactions are generated from the same statistical pattern, it models very well real life 91 112 


11 0.14.01 0O.dl 5 0.06 a 0.05 f 0.04 Z 8 0.03 C 0 0 5 0.02 g 8 0.01 K 0.00 6.00% 4.00 2.00 1.00 0.75 Minimum Support 0 FUP/DHP FUP/APRIORI i3 E 3 Q 2.5 e 2 1.5 4 15K 25K 75K 125K 175K 250K 350K In creme n t Size Figure 3 Reduction on Candidate Sets Figure 4 Speed Up Ratio vs Increment Size updates 4.2 We have compared the performance of FUP against that of DHP and Apriori The first comparison was done on an updated database T10.14.DlOO.dl The performance ratios between them are shown in Fig ure 2 In our implementation of the DHP a hash table of size 100 is used and hashing is only used in the generation of the size-2 candidate sets This is the same policy used in 9 For small support FUP is 3 to 6 times faster than DHP and 3 to 7 times faster than Apriori For larger support, it is less costly to re-run the mining algorithm on the updated database since the number of large itemsets is relatively smaller In terestingly FUP is still 2 to 3 times faster in this case 4.3 Reduction on the number of candi As explained before FUP substantially reduces the number of candidate sets generated The effect is par ticularly significant at the first iteration In Figure 3 the chart shows the ratio of the number of candidate sets generated by FUP when comparing with the two mining algorithms The amount of reduction ranges from 98 to 95% when FUP is compared to DHP It is even greater when it is compared with Apriori 4.4 Performance of FUP with large incre ment In general the larger the increment is the longer it would take to do the update Also the gain in speed up would slow down Two sets of experiments have been performed to support this analysis A database T10.14.DlOO.dmwith updates of lK 5K and 10K were generated and different updates with different sup ports were done by FUP and DHP For the same sup FUP versus DHP and Apriori date sets port the speed-up ratio decreases when update size increases For example when the support is 2 the ratio decreases from 5.8 to 3.7 We also want to find out whether the decreas ing of the performance ratio as the size increases in the update would eventually bring the performance of FUP down to that of DHP In the same setting of T10.14.DlOO.dm we increase the increment size m from 10K gradually to 350K for comparison The per formance ratio is plotted in Figure 4 A gradually level off only appears when the increment size is about 3.5 times the size of the original database The fact that FUP still exhibits performance gain when the incre ment is much larger than the original database shows that it is very efficient 4.5 Small overhead of FUP We also have done some experiments for the pur pose of analyzing the overhead incurred by the FUP In general if the time to compute the set L\222 from an updated database DB U db is added to the time to compute the original set L of large itemsets from the database DB by a mining algorithm the sum would be larger than that if the same mining algorithm was applied directly on DBUdb to compute L\222 The differ ence of these two time values is a measurement of the overhead of the update If the overhead is small, then it indicates that the update was done very efficiently We have designed some experiments to analyze the overhead of FUP by measuring this difference It was found that the bigger the increment is the smaller this overhead becomes In our experiment what was dis covered is that when the increment is much smaller than the original database, the 0verhea.d percentage 113 


ranges around 10  15 Once the increment is larger than the original size the overhead decreases very rapidly from 10 to 5 This is a very encouraging result because it shows that FUP not only can benefit update with small increment it actually works very well in the case of large increment 4.6 Performance in scaled-up databases Our last experiment is done in a scaled-up database The database is T10.I4.D1000.d10 which contains 1 million transactions The performance ratio between DHP and FUP in this scaled-up database ranges from 3 to 16 The result shows that the gain from FUP will in fact increase if the database becomes larger This shows that FUP is very adaptive to size increase and can be applied to very large databases 5 Discussion and Conclusions We studied an efficient fast incremental updating technique for maintenance of the association rules dis covered by database mining The developed method strives to determine the promising itemsets and hope less itemsets in the incremental portion and reduce the size of the candidate set to be searched against the original large database The method is implemented and its performance is studied and compared with the best algorithms for mining association rules studied so far The study shows that the proposed incremen tal updating technique has superior performance on database updates in comparison with direct mining from an updated database The incremental updating technique is applicable to the databases which allow frequent or occasional updates when new transaction data are added to a transaction database We have also investigated the cases of deletion and modification of a transaction database Recently there have been some interesting stud ies at finding multiple-level or generalized association rules in large transaction databases 6 111 The exten sion of our incremental updating technique for mainte nance of multiple-level or generalized association rules in transaction databases is an interesting topic for fu ture research References R Agrawal T Imielinski and A Swami Mining Association Rules between Sets of Items in Large Databases In Proc 1993 ACM-SIGMOD Int Conf Management of Data 207-216 May 1993 R Agrawal and R Srikant Fast algorithms for mining association rules. In Proc 1994 Int Conf Very Large Data Bases pages 487-499 Santiago Chile September 1994 D.W Cheung A W.-C Fu and J Han Knowledge discovery in databases A rule-based attribute-oriented approach In Proc 1994 Int 2221 Symp on Methodologies for Intelligent Systems pages 164-173 Charlotte North Carolina Octo ber 1994 U M Fayyad G Piatetsky-Shapiro P Smyth and R Uthurusamy Advances in Knowledge Dis covery and Data Mining AAAI/MIT Press 1995 J Han Y Cai and N Cercone Data driven discovery of quantitative rules in relational databases IEEE Trans. Knowledge and Data En gineering 5:29-40 1993 J Han and Y Fu Discovery of multiple-level association rules from large databases In Proc 1995 Int Conf Very Large Data Bases Zurich Switzerland Sept 1995 M Klemettinen H Mannila P Ronkainen H. Toivonen and A I Verkamo Finding inter esting rules from large sets of discovered associa tion rules In Proc 3rd Int\222I Conf on Informa tion and Knowledge Management pages 401-408 Gaithersburg Maryland Nov 1994 R Ng and J Han Efficient and effective cluster ing method for spatial data mining In Proc 1994 Int Conf Very Large Data Bases pages 144-155 Santiago Chile September 1994 J.S Park M.S Chen and P.S Yu An effec tive hash-based algorithm for mining association rules In Proc 1995 ACM-SIGMOD Int Conf Management of Daia San Jose CA May 1995 G Piatetsky-Shapiro and W J Frawley Knowl edge Discovery in Ratabases AAAI/MIT Press 1991 R Srikant and R Agrawal Mining generalized association rules In Proc 1995 Int Conf Very Large Data Bases Zurich Switzerland Sept 1995 114 


The disadvantage of this rule-oriented control strategy is that it imposes a restriction on the mixing of forward and backward chaining rules such that a forward chaining rule cannot read any data written by backward chaining rules STO87 To describe this problem let the following be a series of rules Ra to Rd and the resuls REa to REd derived by these rules Ra Rb Rc Rd DB  R  REb  R  REd Also let Ra and Rb be defined as backward chaining rules and Rc and Rd as forward chaining rules If the original database DB is updated rules Rc and Rd though they are forward chaining rules will not be triggered to update the result REd until someone requests the data of REb Thus REd may be iriconsistent with the base data To overcome this problem we use a result-oriented control strategy in which we specify for each result derived subdatabase whether it is to be pre-evaluated or post evaluated The same rule may follow the forward or backward chaining strategy depending on whether the derived subdatabae is to be pre or post-evaluated To illustrate by the example above assume that REd is defined as pre-evaluated and REb is defined as post evaluated Whenever the database DB is updated the rules Ra Rb Rc and Rd will be triggered in the forward chaining fashion to keep REM which is explicitly stored up-to-date REb on the other hand will be evaluated whenever a retrieval operation is issued against it In this case the rules Ra and Rb that derive REb are applied in the backward chaining fashion Thus Ra and Rb follow one control strategy when deriving RFxl and the other control straregy when deriving REb This technique offers more flexibility and alleviates the restriction in POSTGRES described above 7 Conclusion In this paper we have introduced the induced generalization association construct and presented a deductive rule-based language for object-oriented databases The world of subdatabases is closed under this language which facilitates defining inference chains in which each rule derives a new subdatabase based on the subdatabases derived by previous rules in the chain The transitive closure operation can be specified in our language in the form of looping rather than in a recursive form A result-oriented control strategy to be used as the underlying implementation technique has also been introduced in this paper ACKNOWLEDGEMENTS Research on the rule-based language was supported by the U.S West Advanced Technologies grant number UPN 88071315 Work on the Object-Oriented Query Language OQL was supported by the Navy Manufacturing Technology Program through the National Institute of Standards and Technology formerly the National Bureau of Standards grant number 60NANB4wO17 and by the National Science Foundation grant number DMC-8814989 The development efforts are supported by the Florida High Technology and Industry Council grant number UPN 85100316 BIBLIOGRAPHY ALA89a A.M Alashqur S.Y.W Su and H Lar OQL A Quy Language for Manipulating Object-onented Datah Accepted for Publication the 15th VLDB Int Con 1989 ALA89b A.M Alashqur A Query Model and Query and Knowledge Definition Langwi~es for Object-oriented Databases a Ph.D BAN87 BAT85 cER86 CHA84 COD79 DEL88 DIT86 HS87 FOR88 GAL84 HAM81 m7 JAR84 LAM89 MAI88 RAS88 STO87 SU89 TY88 U85 VAS84 Thesis Univedty if Florida 1989 Jay Banerjee et al Data Model Issues for Object-Oriented Aplications ACM Trans on Ofice Information Systems January 1987 D Batory and W Kim Modeling Concepts for VLSI CAD objects ACM TODS September 1985, pages 322-346 Stefan0 Ceri George Gottlob and Gio Wiederhold Interfacing Relational Databases and Prolog Efficiently Roc of the 1st Intl Con on Expert Database Systems 1986 C L Chang and A Walker PROSQL a PROLOG Programming Interface with SQLDS F'mxdngs of the 1st Intl Workshop on Expert Database Systems 1984 E Codd Extend~ng the Database Relational Model to Capture More Meaning ACM TODS Vol 4 No 4 1979 Lois ML Delcambre and James N Etheredge A self Controlling Interpreter for the relational Production Language Roceedings of ACM SIGMOD Conference on Management of Data 1988, pages 396403 KR Dimich Object-oriented Database Systems the Notion and Issues Roc of rhe Intl Workshop on Object-Oriented Database Systems califomia September 1986 D.H Fishman et al Iris An Object-Oriented Database Management System ACM Transaction on Oftixe Informarion Systems January 1987 Pages 4869 S Ford et al Zeitgeist Database support for object-oriented rogramming in the F  gs of the Second International Workshq on Object-oriented Database Systems 1988 Heme Gallaire Jack Mier and Jean-Marie Nicolas Logic and Databases A Deductive Approach ACM Computing Surveys June 1984 Pages 153-185 M Hammer and D McLeod Database Description with SDM A Semantic Associon Model ACM TODS Sepember 1981 R Hull and R King Semantic Database Modeling Survey Applications and Research Issues ACM Computing Surveys September 1987 Mauhias Jark Jim Clifford and Yannis Vassiliou An Optimizing hlog Front-End to a Relational Query System Roc of ACM SIGMOD Con on Management of Data 1984 H.M Lam S Su and A.M Alashqur Integrating the Concepts and Techniqws of Semantic Data Modeling and the Objectdented wradigm Roc of the 13th Intl Computex Software and ApptiCationS Conference COMSAC 89 1989 Christcphe de Maindreville and Eric Simon A Production Rule Based Approach to Deductive Databases Roc of the 4th Intl Con on Data Engineering California 1988 L Raschid and S.Y.W Su A Transaction-oriented Mechanism to Control Precessing in a Knowledge Base Management System Pmc of the Intl Con on Expert Database Systems 1988 Michael Stonebraker Eric Hanson and Chin-Heng Hong The Design of the POSTGRES Rules System Roc of the 3rd Intl Con on Data Engineering California 1987 S.Y.W Su V KrishnamurIhy and H Lam An Object oriented Semantic Association Model OsAM appearing in A.I in Indus&l Engineering and Manufacturing Theoretid Issues and Applications S Kumara et al eds American Institute of Industrial Engineering 1989 Frederick Ty G-OQL Graphics Interface to the Object Oriented Query Language OQL Master thesis University of Florida 1988 Jeffrey ullman Implementation of Logical Query Languages for Databases ACM TODS September 1985 Y Vassiliou J Clifford and M Jark Access to Specific Declarative Knowledge by Expert Systems The Impact of hg"'ning Decision Suppat Systems 1 1 1984 67 


 s_suppkey s_nationkey ps_partkey ps_suppkey ps_supplycost p_partkey p_name   l_partkey l_discount l_quantity l_orderkey l_suppkey l_extendedprice o_orderkey o_orderdate n_nationkey n_name p_partkey p_name   246\262 1 2 3 4 5 7 6 8 9 10,#11,#12,#13 14 15 16 17 18 1 2 Figure 11 Execution plan of TPC-D query 9 for transposed files 2 0 20 40 60 80 100 0 50 100 150 200 Time [s CPUusage NetSend NetRecv Disk 10 8 6 4 0 Throughput [MB/s CPU usage 8 9 10 13 Figure 12 Execution trace of TPC-D query 9 with transposed files 11 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


of I/O But the resulting speedup compared with the previous plans exceeds 2 which is quite satisfactory Table 3 shows the results of above right-deep rd left-deep ld and transposed file tp methods along with the reported results of other commercial systems for 100GB TPC-D query 9 Because our system lacks the software and maintenance price metrics the overall system price can\220t be determined accurately Hardware components themselves cost less than 0.5M We can observe that our system achieves fairly good performance Above all the execution time with the transposed files is twelve times as short as the most powerful commercial platform These results strongly support the effectiveness of the commodity PC based massively parallel relational database servers  System Exec Time Price Teradata on NCR 5100M 160 000 133MHz Pentium 20GB Main Memory 400 Disk Drives 953.3 17M Oracle 7 n DEC AlphaServer 8400 12 000 437MHz DECchip 21164 24GB Main Memory 84 Disk Drives 1884.9 1.3M Oracle 7 n SUN UE6000 24 000 167MHz UltraSPARC 5.3GB Main Memory 300 Disk Drives 2639.3 2.1M IBM DB2 PE on RS/6000 SP 306 96 000 112MHz PowerPC 604 24GB Main Memory 96 Disk Drives 2899.4 3.7M Oracle 7 n HP9000 EPS30 12 000 120MHz PA7150 3.75GB Main Memory 320 Disk Drives 7154.8 2.2M Our Pilot System 100 000 200MHz Pentium Pros 6.4GB Main Memory 100 Disk Drives rd 193.7 ld 177.2 tp 77.1 see text Table 3 Execution time of 100 GB TPC-D Q9 on several systems 12 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


4 Data mining 4.1 Association rule mining Data mining which is a recent hot research topic in the database field is a method of discovering useful information such as rules and previously unknown patterns existing behind data items It enables more effective utilization of transaction log data which have been just archived and abandoned Among the major applications of data mining is association rule mining so called 217\217basket analysis.\220\220 Each of the transaction data typically consists of a set of items bought in a transaction By analyzing them one can derive some association rule such as 217\21790 of the customers who buy both A and B also buy C.\220\220 In order to improve the quality of obtained rules a very large amount of transaction data have to be examined requiring quite a long time to complete First we introduce some basic concepts of association rule Let 000 000 001 000 1 001\000 2 001\002\002\002\001\000 000 002 be a set of items and 003 000 001 003 1 001\003 2 001\002\002\002\001\003 001 002 be a set of transactions where each transaction 003 002 is a set of items such that 003 002 004\000  n itemset 004 has support 005 in the transaction set 003 if 005  f transactions in 003 contain 004  here we denote 005 000 005\006\007\007\b\t 003 001 004 002 An association rule is an implication of the form 004 005 n  where 004\001 n 004 000  and 004 006 n 000 007  Each rule has two measures of value support and confidence  The support of the rule 004 005 n is 005\006\007\007\b\t 003 001 004 b n 002  The confidence 013 of the rule 004 005 n in the transaction set 003 means 013 of transactions in 003 that contain 004 also contain n  which can be written as 005\006\007\007\b\t 003 001 004 b n 002 f\005\006\007\007\b\t 003 001 004 002  For example let r 1 000 001 1 001 3 001 4 002  r 2 000 001 1 001 2 001 3 001 5 002  r 3 000 001 2 001 4 002  r 4 000 001 1 001 2 002  r 5 000 001 1 001 3 001 5 002 be the transaction database Let minimum  support and minimum confidence be 60 and 70 respectively First all itemsets that have support above the minimum support called large itemsets  are generated In this case the large itemsets are 001 1 002 001 001 2 002 001 001 3 002 001 001 1 001 3 002  Then for each large itemset 004  n association rule 004 t n 005 n 001 n 004 004 002 is derived if 005\006\007\007\b\t 003 001 004 002 f\005\006\007\007\b\t 003 001 004 t n 002 n minimum confidence  The results are 1 005 3 001 005\006\007\007\b\t 003 000 60 001 b\016\017 000\020\021\016\013\021 000 75 002 and 3 005 1 001 005\006\007\007\b\t 003 000 60 001 013\b\016\017 000\020\021\016\013\021 000 100 002  The most well known algorithm for association rule mining is the Apriori algorithm[1 We have studied several parallel algorithms for mining association based on Apriori One of these algorithms called HPA Hash Partitioned Apriori is discussed here Apriori first generates candidate itemsets and then scans the transaction database to determine whether each of the candidates satisfies the user specified minimum support and minimum confidence Using these results the next candidate itemsets are generated This continues until no itemset satisfies the minimum support and confidence The most naive parallelization of Apriori would copy the candidates over all the processing node and make each processing node scan the transaction database in parallel Although this works fine when the number of candidates is small enough to fit in the local memory of a single processing node memory space utilization efficiency of this method is very poor For large scale data mining the storage required for the candidates exceeds the available memory space of a processing node This causes memory overflow which results in significant performance degradation due to an excessive amount of extra I/Os HPA partitions the candidate itemsets among the processing nodes using a hash function as in the parallel hash join which eliminates broadcasting of all the transaction data and can reduce the comparison workload significantly Hence HPA works much better than the naive parallelization for large scale data mining The 022 th iteration pass 022  f the algorithm is as follows 1 Generate the candidate itemsets Each processing node generates new candidate itemsets from the large itemsets of the last  001 022 t 1 002 th iteration Each of the former itemsets contains 022 items while each of the latter itemsets contains 001 022 t 1 002 items They are called 022 itemsets and 001 022 t 1 002 itemsets respectively The processing node applies the hash function to each of the candidates to determine the destination node ID If the candidate is for the processing node itself it is inserted into the hash table otherwise it is discarded 13 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


 30 40 50 60 70 80 90 100 110 120 30 40 50 60 70 80 90 10 0 Execution Time [s Number of Nodes Figure 13 Execution time of HPA program pass 2 on PC cluster 2 Scan the transaction database and count the support count Each processing node reads the transaction database from its local disk 000 itemsets are generated from that transaction and the same hash function used in phase 1 s applied to each of them Each of the 000 itemsets is sent to certain processing node according the hash value For the itemsets received from the other nodes and those locally generated whose ID equals the node\220s ID the hash table is searched If hit its support count value is incremented 3 Determine the large itemset After reading all the transaction data each processing node can individually determine whether each candidate 000 itemset satisfy user-specified minimum support or not Each processing node sends large 000 itemsets to the coordinator where all the large 000 itemsets are gathered 4 Check the terminal condition If the large 000 itemsets are empty the algorithm terminates Otherwise the coordinator broadcasts large 000 itemsets to all the processing nodes and the algorithm enters the next iteration 4.2 Performance evaluation of HPA algorithm The HPA program explained above is implemented on our PC cluster Each node of the cluster has a transaction data file on its own hard disk Transaction data is produced using data generation program developed by Agrawal designating some parameters such as the number of transaction the number of different items and so on The produced data is divided by the number of nodes and copied to each node\220s hard disk The parameters used in the evaluation is as follows The number of transaction is 5,000,000 the number of different items is 5000 and minimum support is 0.7 The size of the data is about 400MBytes in total The message block size is set to be 16KBytes according to the results of communication characteristics of PC clusters discussed in previous section The disk I/O block size is 64KBytes which seems to be most suitable value for the system Note that the number of candidate itemset in pass 2 s substantially larger than for the other passes which relatively frequently occurs in association rules mining Therefore we have been careful to parallelize the program effectively especially in pass 2 so that unnecessary itemsets to count should not be generated 14 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


The execution time of the HPA program pass 2 is shown in figure 13 as the number of PCs is changed The maximum number of PCs used in this evaluation is 100 Reasonably good speedup is achieved in this application as the number of PCs is increased 5 Conclusion In this paper we presented performance evaluation of parallel database processing on an ATM connected 100 node PC cluster system The latest PCs enabled us to obtain over 110Mbps throughput in point-to-point communication on a 155Mbps ATM network even with the so-called 217\217heavy\220\220 TCP/IP This greatly helped in developing the system in a short period since we were absorbed in fixing many other problems Massively parallel computers now tend to be used in business applications as well as the conventional scientific computation Two major business applications decision support query processing and data mining were picked up and executed on the PC cluster The query processing environment was built using the results of our previous research the super database computer SDC project Performace evaluation results with a query of the standard TPC-D benchmark showed that our system achieved superior performance especially when transposed file organization was employed As for data mining we developed a parallel algorithm for mining association rules and implemented it on the PC cluster By utilizing aggregate memory of the system efficiently the system showed good speedup characteristics as the number of nodes increased The good price/performance ratio makes PC clusters very attractive and promising for parallel database processing applications All these facts support the effectiveness of the commodity PC based massively parallel database servers Acknowledgment This project is supported by NEDO New Energy and Industrial Technology Development Organization in Japan Hitachi Ltd technically helped us extensively for ATM related issues References  R Agrawal T Imielinski and A Swami Mining association rules between sets of items in large databases In Proceedings of ACM SIGMOD International Conference on Management of Data  pages 207--216 1993  R Agrawal and R Srikant Fast algorithms for mining association rules In Proceedings of International Conference on Very Large Data Bases  1994  A C Arpaci-Dusseau R H Arpaci-Dusseau D E Culler J M Hellerstein and D A Patterson High-performance sorting on Networks of Workstations In Proceedings of International Conference on Management of Data  pages 243--254 1997  D.S Batory On searching transposed files ACM TODS  4\(4 1979  P.A Boncz W Quak and M.L Kersten Monet and its geographical extensions A novel approach to high performance GIS processing In Proceedings of International Conference on Extending Database Technology  pages 147--166 1996 15 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


 R Carter and J Laroco Commodity clusters Performance comparison between PC\220s and workstations In Proceedings of IEEE International Symposium on High Performance Distributed Computing  pages 292--304 1995  D.J DeWitt and J Gray Parallel database systems  The future of high performance database systems Communications of the ACM  35\(6 1992  J Gray editor The Benchmark Handbook for Database and Transaction Processing Systems  Morgan Kaufmann Publishers 2nd edition 1993  J Heinanen Multiprotocol encapsulation over ATM adaptation layer 5 Technical Report RFC1483 1993  M Kitsuregawa M Nakano and M Takagi Query execution for large relations on Functional Disk System In Proceedings of International Conference on Data Engineering  5th pages 159--167 IEEE 1989  M Kitsuregawa and Y Ogawa Bucket Spreading Parallel Hash:A new parallel hash join method with robustness for data skew in Super Database Computer SDC In Proceedings of International Conference on Very Large Data Bases  16th pages 210--221 1990  M Laubach Classical IP and ARP over ATM Technical Report RFC1577 1994  D.A Schneider and D.J DeWitt Tradeoffs in processing complex join queries via hashing in multiprocessor database machines In Proceedings of International Conference on Very Large Data Bases  16th pages 469--480 1990  T Shintani and M Kitsuregawa Hash based parallel algorithms for mining association rules In Proceedings of IEEE International Conference on Parallel and Distributed Information Systems  pages 19--30 1996  T Sterling D Saverese D.J Becker B Fryxell and K Olson Communication overhead for space science applications on the Beowulf parallel workstaion In Proceedings of International Symposium on High Performance Distributed Computing  pages 23--30 1995  T Tamura M Nakamura M Kitsuregawa and Y Ogawa Implementation and performance evaluation of the parallel relational database server SDC-II In Proceedings of International Conference on Parallel Processing  25th pages I--212--I--221 1996  TPC TPC Benchmark 000\001 D Decision Support Standard Specification Revision 1.1 Transaction Processing Performance Council 1995 16 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


In accordance with 1910.97 and 1910.209 warning signs are required in microwave areas For work involving power line carrier systems this work is to be conducted according to requirements for work on energized lines Comments s APPA objects to the absolute requirement implied by the word ensure regarding exposure to microwave radiation and recommends revision of s l iii to read when an employee works in an area where electromagnetic radiation levels could exceed the levels specified in the radiation protection guide the employer shall institute measures designed to protect employees from accidental exposure to radiation levels greater than those permitted by that guide  I1 an employee must be stationed at the remote end of the rodding operation Before moving an energized cable it must be inspected for defects which might lead to a fault To prevent accidents from working on the wrong cable would require identification of the correct cable when multiple cables are present Would prohibit an employee from working in a manhole with an energized cable with a defect that could lead to a fault However if the cable cannot be deenergized while another cable is out employees may enter the manhole but must protect against failure by some means for example using a ballistics blanket wrapped around cable Requires bonding around opening in metal sheath while working on cable Underaround EIectrical Installations t Comments t This paragraph addresses safety for underground vaults and manholes The following requirements are contained in this section Ladders must be used in manholes and vaults greater than four feet deep and climbing on cables and hangers in these vaults is prohibited Equipment used to lower materials and tools in manholes must be capable of supporting the weight and should be checked for defects before use An employee in a manhole must have an attendant in the immediate vicinity with facilities greater than 250 volts energized An employee working alone is permitted to enter briefly for inspection housekeeping taking readings or similar assuming work could be done safely Duct rods must be inserted in the direction presenting the least hazard to employees and APPA recommends that OSHA rewrite section 7\regarding working with defective cables This rewrite would include the words shall be given a thorough inspection and a determination made as to whether they represent a hazard to personnel or representative of an impending fault As in Subsection \(e EEI proposes the addition of wording to cover training of employees in emergency rescue procedures and for providing and maintaining rescue equipment Substations U This paragraph covers work performed in substations and contains the following requirements Requires that enough space be provided around electrical equipment to allow ready and safe access for operation and maintenance of equipment OSHA's position A2-16 


is that this requirement is sufficiently performance oriented to meet the requirements for old installations according to the 1987 NEW Requires draw-out circuit breakers to be inserted and removed while in the open position and that if the design permits the control circuits be rendered inoperative while breakers are being inserted and removed stated in the Rules and requests that existing installations not be required to be modified to meet NESC APPA recommends that Section u 4 i which includes requirements for enclosing electric conductors and equipment to minimize unauthorized access to such equipment be modified to refer to only those areas which are accessible to the public Requires conductive fences around substations to be grounded Power Generation v Addresses guarding of energized parts  Fences screens, partitions or walls This section provides additional requirements and related work practices for power generating plants  Entrances locked or attended Special Conditions w  Warning signs posted  Live parts greater than 150 volts to be guarded or isolated by location or be insulated  Enclosures are to be according to the 1987 NESC Sections llOA and 124A1 and in 1993 NESC  Requires guarding of live parts except during an operation and maintenance function when guards are removed barriers must be installed to prevent employees in the area from contacting exposed live parts Requires employees who do not work regularly at the substation to report their presence Requires information to be communicated to employees during job briefings in accordance with Section \(c of the Rules Comments U APPA and EEI provide comments as follows Both believe that some older substations \(and power plants would not meet NESC as This paragraph proposes special conditions that are encountered during electric power generation, transmission and distribution work including the following Capacitors  Requires individual units in a rack to be short circuited and the rack grounded  Require lines with capacitors connected to be short circuited before being considered deenergized Current transformer secondaries may not be opened while energized and must be bridged if the CT circuit is opened Series street lighting circuits with open circuit voltages greater than 600 volts must be worked in accordance with Section q\or t and the series loop may be opened only after the source transformer is deenergized and isolated or after the loop is bridged to avoid open circuit condition Sufficient artificial light must be provided where insufficient naturals illumination is present to enable employee to work safely A2-17 


US Coast Guard approved personal floatation devices must be supplied and inspected where employees are engaged in work where there is danger of drowning Required employee protection in public work areas to include the following  Warning signs or flags and other traffic control devices  Barricades for additional protection to employees  Barricades around excavated areas  Warning lights at night prominently displayed Lines or equipment which may be sub to backfeed from cogeneration or other sources are to be worked as energized in accordance with the applicable paragraphs of the Rules Comments w APPA submits the following comments regarding this Special Conditions section Recommends that the wording regarding capacitors be modified to include a waiting period for five minutes prior to short circuiting and grounding in accordance with industry standards for discharging of capacitors For series street light circuits, recommends that language be added for bridging to either install a bypass conductor or by placement of grounds so that work occurs between the grounds Recommends modification of the section regarding personal floatation devices to not apply to work sites near fountains decorative ponds swimming pools or other bodies of water on residential and commercial property Definitions x This section of the proposed Rules includes definitions of terms Definitions particularly pertinent to understanding the proposal and which have not previously been included are listed as follows Authorized Employee  an employee to whom the authority and responsibility to perform a specific assignment has been given by the employer who can demonstrate by experience or training the ability to recognize potentially hazardous energy and its potential impact on the work place conditions and who has the knowledge to implement adequate methods and means for the control and isolation of such energy CZearance for Work  Authorization to perform specified work or permission to enter a restricted area Clearance from Hazard  Separation from energized lines or equipment Comments x The following summarizes the changes in some of the definitions which APPA recommends Add to the definition for authorized employee It the authorized employee may be an employee assigned to perform the work or assigned to provide the energy control and isolation function  Recommends that OSHA modify the definition for a line clearance tree trimmer to add the word qualified resulting in the complete designation as a qualified line clearance tree trimmer Recommends that OSHA modify the definition of qualified employee" to remove the word construction from the definition since it is felt that knowledge of construction procedures is beyond the scope of the proposed rule resulting in APPA's new A2-18 I 


wording as follows more knowledgeable in operation and hazards associated with electric power generation transmission and/or distribution equipment Recommends that OSHA add a definition for the word practicable and replace the word feasible with practicable wherever it appears in the proposed regulations and that practicable be further defined as capable of being accomplished by reasonably available and economic means OTHER ISSUES Clothing OSHA requested comments on the advisability of adopting requirements regarding the clothing worn by electric utility industry employees EEI has presented comments which indicates research is underway prior to establishing a standard for clothing to be worn by electric utility employees However EEI's position is that this standard has not developed to the extent that it could be included in the OSHA Rules Both APPA and EEI state that they would support a requirement that employers train employees regarding the proper type of clothing to wear to minimize hazards when working in the vicinity of exposed energized facilities Grandfathering Due to the anticipated cost impact on the utility industry of the proposed Rules requiring that existing installations be brought to the requirements of the proposed Rules both APPA and EEI propose that the final Rules include an omnibus grandfather provision This provision would exempt those selected types of facilities from modification to meet the new rules EEI states that if the grandfathering concept is incorporated that electric utility employees will not be deprived of proper protection They propose that employers be required to provide employees with a level of protection equivalent to that which the standard would require in those instances in which the utility does not choose to modify existing facilities to comply with the final standard Rubber Sleeves OSHA requests comments from the industry on whether it would be advisable to require rubber insulating sleeves when gloves are used on lines or equipment energized at more than a given voltage EEI states its position that utilities should continue to have the option of choosing rubber gloves or gloves and sleeves to protect employees when it is necessary to work closer to energized lines than the distances specified in the clearance tables Preemuting State Laws EEI requests that the final Rules be clear in their preempting state rules applicable to the operation and maintenance work rules for electric power systems. This is especially critical since some states now have existing laws which are more stringent than the proposed OSHA Rules Examples are 1 in California and Pennsylvania where electric utility linemen are prohibited from using rubber gloves to work on lines and equipment energized at more than certain voltages and 2 in California and Connecticut where the live line bare hand method of working on high voltage transmission systems is prohibited One utility Pacific Gas  Electric has obtained a variance from the California OSHA to perform live line bare-hand transmission maintenance work on an experimental basis Coiiflicts Between the Rilles and Part 1926 Subpart V Since many of the work procedures in construction work and operation and maintenance work are similar and difficult to distinguish between EEI requests that the final order be clear in establishing which rule has jurisdiction over such similar work areas A2-19 v 


IMPACTS ON COSTS AND ASSOCIATED BENEFITS In its introduction to the proposed rules OSHA has provided an estimate of the annual cost impact on the electric utility industry for the proposed des of approximately 20.7 million OSHA estimates that compliance with this proposed standard would annually prevent between 24 and 28 fatalities and 2,175 injuries per year The utilities which have responded to this proposed standard through their respective associations have questioned the claims both of the magnitude of the cost involved and the benefit to the industry in preventing fatalities and lost-time injuries Both EEI and APPA feel that the annual cost which OSHA estimates are significantly lower than would be realized in practice Factors which APPA and EEI feel were not properly addressed include the following OSHA has not accurately accounted for cost of potential retroactive impacts including retrofitting and modifying existing installations and equipment OSHA has not consistently implemented performance based provisions in proposed rules  many portions require specific approaches which would require utilities to replace procedures already in place with new procedures Estimates were based on an average size investor-owned utility of 2,800 employees and an average rural cooperative of 56 employees, which are not applicable to many smaller systems such as municipal systems OSHA has not adequately addressed the retraining which would be necessary with modifying long-established industry practices to be in accordance with the OSHA rules EEI claims that OSHA's proposed clearance requirements would not allow the use of established maintenance techniques for maintaining high voltage transmission systems and thus would require new techniques For an example of the cost which is estimated to be experienced as a result of the new Rules one of the EEI member companies has estimated that approximately 20,000 transmission towers would need to be modified to accommodate the required step bolts in the Rules at an estimated cost of 6,200,000 Additionally this same company estimates that the annual cost of retesting live line tools for its estimated 1,000 tools would be 265,000 Additionally, both EEI and APPA question the additional benefits which OSHA claims would result from implementation of the new Rules APPA questions the estimates of preventing an additional 24 to 28 fatalities annually and 2,175 injuries per year in that it fails to account for the fact that the industry has already implemented in large part safety measures which are incorporated in the Rules EEI and APPA also point out that many preventable injuries cannot be eliminated despite work rules enforcement and safety awareness campaigns since many such accidents which result in fatalities are due to employee being trained but not following the employer's training and policies PRESENT STATUS OF RULES According to information received from the OSHA office in February 1993 the final Rules are to be published no later than July 1993 and possibly as soon as March 1993 OSHA closed their receipt of comments in March 1991 and no further changes in the rules are thought possible A2-20 


CONCLUSION The OSHA 1910.269 which proposes to cover electric utility operation and maintenance work rules affects a multitude of working procedures as are summarized in this paper It is not possible at the present time to assess the final structure of the Rules as may be proposed in 1993 or subsequent years Since the comments from the utility associations APPA and EEI were made following the initial release of the proposed OSHA Rules in 1989 a significant amount of time has elapsed where other events have occurred which may affect the form of the final Rules The 1993 NESC went into effect in August 1992 and includes some of the requirements to which the commenters objected For example a significant requirement in the Part 4 of the 1993 NESC requires that rubber gloves be utilized on exposed energized parts of facilities operating at 50 to 300 volts This requirement is in conflict with EEl\222s proposed change to the OSHA Rules which would still allow working such secondary facilities without the use of rubber gloves Electric utilities are advised to review the January 31 1989 proposed operation and maintenance Rules as summarized in this paper and to review their procedures which would be affected by application of the Rules Many of the procedures proposed in the Rules provide valuable guidance in electric utilities\222 operation and maintenance activities Where the cost impact is not significant, it is recommended that utilities consider implementing such procedures in expectation of the Rules being published in the next few months Also it would be appropriate for electric utilities to review the 1993 edition of the NESC since there are portions of the Rules which have resulted in changes in the NESC These changes mainly occur in Part 4 Rules for the Operation of Electric Supply and Communications Lines and Equipment The concerns which the commenters have addressed regarding the cost impact and the resulting benefits experienced as a result of the promulgation of the Rules are real ones and must be addressed in the final Rules As a result this paper cannot present a conclusion regarding the full impact of the Rules The development of such Rules continue to be an ongoing matter and will undoubtedly require later analysis when the final rules are published A2-21 



Distributed Classification using Class-Association Rules Mining Algorithm Djamila Mokeddem Dept. of Computer Sciences, LSSD Laboratory University of Sciences and Technologies Mohamed Boudiaf Oran, Algeria D-Mokeddem@univ-usto.dz Hafida Belbachir Dept. of Computer Sciences, LSSD Laboratory University of Sciences and Technologies Mohamed Boudiaf Oran, Algeria H_belbach@yahoo.com Abstract  Associative classification algorithms have been successfully used to construct classification systems. The major strength of such techniques is that they are able to use the most accurate rules among an exhaustive list of class-association rules This explains their good performance in general, but to the detriment of an expensive computing cost, inherited from association rules discovery algorithms. We address this issue by proposing a distributed methodology based on  FP-growth algorithm. In a shared nothing architecture, subsets of classification rules are generated in parallel from several data partitions. An inter-processor communication is established in order to make global decisions. This exchange is made only in the first level of recursion,  allowing each machine to subsequently process all its assigned tasks independently The final classifier is built by a majority vote This approach is illustrated by a detailed example, and an analysis of communication cost Keywords- Distributed data mining; Association rule mining Class-association rules; FP-growth algorithm I I NTRODUCTION Many of data mining algorithms are suitable for distributed computing for two reasons: scaling up this algorithms, or mining inherently distributed data. This paper focuses on classification algorithms based on association rules, a.k.a Associative Classification  algorithmsé \(AC\hich is a promising  approach in data mining that utilizes the association rule mining techniques to construct classification systems Several studies [1   2  3  h a v e p r ov id e d evi d ence th at su ch  algorithms are able to extract classifiers competitive with those produced by many of traditional classifiers like decision trees rule induction and probabilistic approaches. The advantage of this approach lies in  \(1\ its simplicity compared to other mathematical classification methods, and its competitive results in term of accuracy \(2\ the  exhaustive quest for all rules allows to find many interesting and useful rules not being discovered  by the state-of-the-art classification systems like C4.5 [4   3  pr o d u c es an  u n de rs tan d  m odel bas e d on  u s er specified constraints. A typical associative classification system is constructed in two stages: \(1\ generating the complete set of class association rules \(CARs\at satisfy the user-specified minimum support \(called minSup\and minimum confidence \(called minConf\; \(2\electing the most accurate rules to build the classifier \(pruning phase\. The major strength of such systems is that they are able to use the most accurate rules for classification because their rule generators aim to find all rules. However, when datasets contain a large number of rows and/or columns, both rule generation and rule selection in such systems are time consuming. To address this issue, we  propose a distributed algorithm for  associative classification based on FP-growth algorithm [5  T h e r e m ainde r  of this paper is organized as fo llows the next section gives an outline on AC  algorithms, the section 3 provides a review of related works. In section 4, a detailed framework of the proposed distributed algorithm is described, following by a conclusion and discussion  on the tracks which always deserve to be explored II A SSOCIATIVE CLASSIFICATION ALGORITHMS Classification is one task of data mining which allows predicting if a data instance is member of a predefined class. In a more general objective, the task of association rule discovery focus on finding rules of the form AB relating disjoint set of databa se attributes, which is interpreted to mean çif the set of attributevalues, or çitemset A is found together in a database record, then it is likely that the itemset B will be present also The discovering of çrules in these two tasks is a strong common point which has inspired several researchers  to explore the possibility of using association rule discovery methods in  classification. The basic idea is to view classification rules as a special case of association rules, in which only the class attri bute is considered in the ruleês consequent.   In order to build classifier, an AC algorithm uses a training data set D to produce class association rules \(CARs in the form of Xy where XI the set of çitemsé, and yY the set of class labels. An item is described as an attribute name Xi and a value xi, denoted X  x   The rule R Xy has support s, denoted as supp\(R\, if s of the cases in D contain X and are labeled with class y A rule R Xy holds in D with confidence c, denoted as conf\(R\, if c of cases in D that contain X are labeled with class y  The main goal is to construct a set of CARs that satisfies the minimum support minSup and minimum confidence minConf constraints and  that is able to predict the classes of previously unseen data the test data set\, as accurately as possible. Other measures can be used like the conviction which take into account  the class frequency, it is defined as conv\(X  y  1  supp\(y  1  conf\(X  y  where  supp\(y\ is the frequency of the class label  y in D 334 978-1-4244-8611-3/10/$26.00 ©2010 IEEE 


A Generating rules for classification To find the complete set of classification rules passing certain support and confidence thresholds, AC systems mine the training data set using a variant association rule discovery method. Several AC approaches, e.g. CBA [1 h a ve b e en  adopted from Apriori algorithm 6  w h ich is bas e d on an iterative process:  generate candidates, and generate frequent itemsets. This method is computationally expensive because it needs  repetitive scans of the data base.  Others, like CMAR 2   a r e bas e d on  F P g r o w t h  algo r ith m   5  on e of  th e  m o st  efficient serial algorithms to mine frequent item sets. The effectiveness of FP-growth algorithm comes from its FP-tree structure which   compresses a large  database into a compact form, and its divide-and-conquer methodology.  Furthermore, it avoids candidate generation, and needs only two scans of the entire data base B Pruning Rules Pruning techniques rely on the elimination of rules that are either redundant or misleading from taking any role in the prediction process of test data objects. The removal of such rules can make the classification process more effective and accurate. A survey of pruning methods is documented by Thabtha in [3  III R ELATED WORK The design of distributed associative classification systems does not differ too much from the design of distributed association rule mining methods, at least in the first step generation of CARs\ For this reason, a set of recent works on distributed FP-growth algorithm will be presented. These approaches proposed  for association rules discovery in distributed computing environment, may be adapted to generate the class-association rules in a distributed classification context A Class-Association Rule minin g based on serial FP-growth In AC algorithms using  FP-growth, classification rules are generated by adapting this algorithm to take into account the class label. The key idea used in CMAR system [2 f o r  example is to store the class label in the FP-tree structure. We illustrate this by the following example \(fig. 1\, where minSupp = 2 \(66%\. First, the training data set is scanned to find the list of frequent items F-list sorted by descending order of supports. A second scan is done to construct the FP-tree where  each frequent item in each record is inserted in the tree according to the order of  F-list. This operation allows to represent a shared prefix of several records only once, like the prefix a1a2 shared by the first and second records. Support counts are summed in each node, and class label is attached to the last node in the path. In the phase of frequent CARs mining, frequent items are recursively mined as follows construct  conditional pattern base \(CPB\ for each item in Flist, construct conditional FP-tree \(CFP-tree\ from CPB. When the conditional FP-tree contains a single path, the recursion is stopped and frequent patterns are enumerated using a combining method. This process is more detailed in [5  Onc e  a  frequent item is found, rules containing this item can be generated immediately, by merging class values in the lower branches of the considered item. For example, to find rules having  b3,  CPB is built by enumerating prefixes of b3 in the initial FP-tree:{a1a2\(y1:1\; a1\(y1:1 Figure 1 An example of bulding FP-tree taking into account the class labels Then CFP-tree is obtained considering only frequent items in  CPB. In this case, CFP-tree contains only one node  a1:2 and the CARs generated are: b3  y1,  and  b3a1  y1 obtained by combining the node a1 of CFP-tree, and the considered item b3. The two rules have support 2 and confidence 100%. The remaining rules can be mined similarly B Distributed  association ru le mining based on fp-growth algorithm In very large databases and with low value of minimum support, the used FP-tree structure may not fit into the main memory. Several algorithms have been proposed in the literature to address the problem of frequent itemset mining in parallel and distributed environment. Many of them are based on apriori algorithm, e.g. CD and DD strategies [7   bu t th ey  still suffer from sequential a priori limitations. Inspired by its intrinsic divide-and-conquer nature, and its performance gain over a priori-based methods, FP-growth has been the subject of several studies in parallel and distributed frequent itemsets mining. The main goal is to reduce the time spent in computation, with a minimum of interaction between data sites A compromise between memory constraint and inter-processor communication cost is difficult to obtain in distributed frequent itemset mining. The ideal state is a model that allows a çtotal independent processing between data sites. This may be possible generally if a certain form of data replication is assumed like in [8  Oth er w o rk s a r e  base d on  an in f o rm ati on  exchange in different forms: lo cal conditional pattern bases [9  or sub-trees [10  Cle a rly th er e a r e t r a d e o f f s  be tw een th ese t w o  different approaches. Algorithm designers must compromise between approaches that copy local data globally and approaches which retrieve information from remote machines as needed C Distributed a ssociative classification To our knowledge, and up to the writing of these lines there are been  few published studies that have focused on distributed associative classification. Thakur [11 p r o pos ed a  parallel model for CBA system [1  T h e pa ra lle l C A R  generation phase is an adaptation of CD approach [7 f o r  mining CARs in associative classification.  The training data set is partitioned among P processors, and in each iteration each site calculates local counts of the same set of candidates and broadcasts these to all other processors. After a synchronization step, CARs are generated from frequent itemsets. This strategy inherits two major limitations of CD approach : a   tight synchronization at the end of each step, and the duplication of the entire set of candidates at each site 335 


IV T HE PROPOSED MODEL The goal of this work is to propose a distributed model for the associative classification technique. We start by presenting a simple sequential algorithm based on FP-growth approach A The sequential associa tive classification algorithm In the sequential version \(Algorithm 1\ the list of CARs is generated by FP-growth algorithm like in CMAR. To evaluate the rank of a rule, a total order is defined as follows: Given two rules r1 and r2, r1 is said having higher rank than r2, denoted as r1  r1\conv\(r2\; \(2\conv\(r1 conv\(r2\ut conf\(r1\conf\(r2\; \(3\ conv\(r1\=conv\(r2 conf\(r1\conf\(r2\ but supp\(r1\>supp\(r2\; or \(4\ The convictions, confidences and supports of  r1 and r2 are the same, but r1 has fewer attribute values in its left hand side than r2 does. The use of conviction measure might give more information on the rule rank,  because the class frequency is taken into account \(cf. 2 Algorithm 1 Sequential AC Input training data set D  minSup  minConf Output the list of CARs 1 Scan D and build F-list  2 Scan D and build FP-tree structure, storing also  the class labels of each record 3 For each item in F-list construct CPB and CFP-tree  4 Mine recursively each CFP-tree by extracting CARs 5 Sort the CARs Seeing that this algorithm will be parallelized, we propose to build the classifier by all the rules without any pruning operation. The classification  of a new record will be made as follows:  go through the list of all sorted rules until the first rule that covers the example is found a rule r covers an instance d if d satisfies all conditions of the rule body of r  classify the example according to the class at the right -hand side of the rule. If no rule covers this example, mark the example as unclassified B Associative Classification in a distributed environment In this scheme \(Algorithm 2  processors work in parallel on a shared-nothing architecture. The processors begin with counting local support for each item. This counts are then exchanged across the group in order to each processor calculates their sum. After discarding globally infrequent items each processor  constructs the F-list structure sorted by descending order of frequent item supports \(lines 2-4\. In the next phase, local CFP-trees are built by scanning local data partitions and considering only local items belonging to F-list  The class label is attached to the last node in the path \(line 5 Thereafter, the local CFP-trees are used in parallel to generate local conditional pattern bases CPBs in each processor, for each item in F-list line 6 This partial information will be communicated between the processors and merged to generate the initial global CPB for each item. A trivial method to assign tasks to different processors is to perform a bloc-cyclic item distribution, so that the item i will be assigned to the processor number   1   Thereby, each processor will send its local CPBs to corresponding processors avoiding to send çallé to çallé \(line 7 9 Algorithm 2 Distributed AC Input  P data partitions a training data set D  minSup, minConf  Output  A classifier Cl maj representing a majority vote between P  classifiers   1 For  0  to  1  do in parallel in processors    012  2 Scan local data partition D j and count  local support for each item   015      3 Broadcast 015     for each item   4 Build  sorted in support descending order, by a global reduction 015      015      let  the size of   5 Scan local data partition and build local  with local items, according to the order of   6 For each item  in  which belongs to the local partition, build local conditional pattern base       7 The  items of F-list are equitably assigned to each processor according a block-cyclic data distribution 8 Send      to the corresponding processors 9 Merge received and local     for assigned items   10.Delete local   and local     for not assigned items i 11.Apply Sequential AC algorithm serially and independently on assigned items 12.Sort locally the subset of rules CAR j  13  End do in parallel  This data distribution strategy  could çcontributeé to balance the load between the processors, because generally the amount of work needed to process an item of F-list increases for the items with low supports, thus those having longer prefixes.  After this communication, each machine independently mines recursively its assigned items, without any  need of synchronization. At this level, several data structures can be deleted from distributed main memories local CFP-trees and local CPBs for the items assigned to other processors \(line 10\t the end, if each site products a subset of CARs the union of all subsets must be exactly the total rule set obtained in the serial vers ion of the algorithm To classify a new record d, a simple and intuitive technique consists in performing a majority vote between the P components of the final composite model. This strategy was used successfully in ensemble learning methods, with e.g. decision trees as base classifier 12 T h e in sta n ce to classi f y is prese n ted to ea ch classifier Clj, \(j= 1..P\e in the sequential version, thus it will be classified according to the prediction of the majority denoted by Cl   d   argmax    I!Cl  c    where c is a class label, Clj is the classif ier obtained in the processor j and I\(A\s an indicator function that returns 1 if A is true and 0 otherwise The example in \(f ig.2, a\strates the parallel construction of  F-list structure in three processors. After communicating local counts, proce ssors compute the sum and discard non global frequent items. Instead of building a global FP-tree which may not fit in main memory, local FP-trees are constructed in each processor \(fig.2, b\with the same method 336 


presented in figure 1, but considering only global frequent items, i.e. belonging to F-list Figure 2 An example of generating CARs in a shared-nothing architecture Thereafter, local CPBs are built in each processor, for each item in F-list structure, and communicated to corresponding processors using a bloc-cyclic distribution strategy. So, the items {b3, b2} will be assigned to processor P0; {a1, c3} to P1; and  {a2, b1} to P2. The process of local CARs mining will be executed independently in the three processors resulting on the classifier Cl 1  Cl 2  Cl 3 For example \(fig.2, c in the first recursion level, processor P0 generates the CAR b3  y1é for the assigned item b3. On the other hand processor P2 repeats  the recu rsion on the built CFP-tree for the item a2,  until obtaining one branch C Communication cost analysis In the proposed algorithm, the information exchange allows to build the initial global F-list, and the initial CPBs The  first communication phase is not very expensive because each processor broadcasts only support counts for all items \(q items\he processors \(P pr ocessors\ this stage there are P!P-1"q messages exchanged.  All this information exchanged is integer v alued and its volume is very small. On the other hand, the major communication cost comes from the exchange of the initial CPBs ac ross all processors. This can be optimized by avoiding an all-to-all strategy. Each processor has information on what it must send to each  other processor such as the CPB for the item i  \(i 1..k\e processor number \(i-1 In this phase, each processor send  k/P  CPBs to corresponding proce ssors, so the total number of  messages is k. The larger of these messages depends on the maximum size of CPB. In the worst case, the item is present in all transactions of the data partiti on, with the largest prefix of size m  1 m is the number of attributes\e maximum message size in this communication phase is O&\(m-1  n/P    where n is the total number of re cords in the training data set D V C ONCLUSION Many distributed algorithms have been proposed for classification algorithms like decision trees, but so far, there are few  works   in associative classification. In this paper, we have presented a distributed model which allows the  classassociation rules discovery in  a shared-nothing architecture Our solution embraces one of the fastest known sequential algorithms \(FP-growth d extends it to generate classification rules  in a parallel setting. The divide-andconquer nature of this latter facilitates the parallelization process, however, since the data set is distributed, global decision making becomes a difficult task. To avoid the replication of data in the sites, we have chosen to communicate the needed information. This exchange is made only in the first level of recursion,  allowing each machine to subsequently process all its assigned tasks independently. At the end, a global classifier is bu ilt by all discovered rules,  and applying a majority vote strategy. In order to evaluate this choices, it is imperative to carry out an experimental evaluation which permits us in the future to analyze several important costs: accuracy, scalability, speedup, memory usage, communication, synchronization, and also the load balancing  R EFERENCES 1 B L i u, W  H s u Y   Ma   Integrating classification and association rule mining  Proceedings of the International Conference on Knowledge Discovery and Data Mining. New York, NY: AAAI Press, pp. 80  86 1998 2 W  L i J. H a n  J  Pe i   CMAR: Accurate and efficient classification based on multiple-class association rule  Proceedings of the International Conference on Data Mining , San Jose, CA, pp. 369  376 2001 3 F  T h a b ta h  Pruning techniques in associative classification: Survey and comparison  Journal of Digital Information Management 4, pp. 202  205, 2006 4 J  R  Q u in la n   C4.5 Programs for Ma chine Learning,é Morgan Kaufmann Publishers, Inc., 1993 5 J  Han  J  Pei  Y Yin    Mining frequent patterns without candidate generation  Proceedings of the ACM SIGMOD International Conference on Management of Data. Dallas, TX: ACM Press, pp. 1  12 2000 6 R  Ag r a wa l  R   Srikant Fast algorithms for mining association rule  Proceedings of the 20th International Conference on Very Large Data Bases, Morgan Kaufmann, Santiago, Chile, pp. 487  499, 1994 7 K  M  Yu J  Z h ou W  C  Hs ia o   Load balancing approach parallel algorithm for frequent pattern mining  PaCT , pp. 623-631, 2007 8 R  A g ra w a l J S h a rfe r   Parallel Mining of Association Rules  IEEE Transaction on Knowledge and Data Engineering, 8\(6\, pp. 962  969 1996 9 G Bu e h re r, S Par t h a sara t h y  S Tatikonda, T. Kurc, J. Saltz  Toward terabyte pattern mining: An architecture-conscious solution  Proceedings of the 12th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, pp. 2  12, 2007  H D K  M oon es i n g h e C  M oon J un g T   P a n g-Nin g  Fast Parallel Mining of Frequent Itemsets Technical Report MSU CSE-06-29. Dept of Computer Science and Engineering, Michigan State University, 2006 11 G  T h ak u r  C J R a me sh    A Framework For Fast Classification Algorithms  International Journal Information Theories & Applications V..15, pp. 363-369, 2008 12 N  C h aw l a, S   Esc hr ic h L  O  H a l l    Creating Ensembles of Classifiers  IEEE International Conference on Data Mining,  pp. 580-581, 2001 337 


2  R. Alhajj, M. Kaya, çMulti-objective genetic algorithms based automated clustering for fuzzy association rules mining Journal of Intelligent Information Systems Vol. 31, No. 3, pp. 243-264, 2008 3  C. C. Chan and W. H. Au, çMining fuzzy association rules The Conference on Information and Knowledge Management Las Vegas pp. 209-215, 1997 4  C. H. Chen, T. P. Hong and Vincent S. Tseng, çA Modified Approach to Speed up Genetic-Fuzzy Data Mining with Divide-and-Conquer Strategy The IEEE Congress on Evolutionary Computation pp. 1-6 2007 5  C. H. Chen, T. P. Hong, Vincent S. Tseng and C. S. Lee, çA geneticfuzzy mining approach for items with multiple minimum supports Soft Computing Vol. 13, No. 5, pp. 521-533, 2009 6  C. H. Chen, T. P. Hong and Vincent S. Tseng, çAn improved approach to find membership functions and multiple minimum supports in fuzzy data mining Expert Systems with Applications  Vol 36, No. 6, pp. 10016-10024, 2009 7  F. Herrera, M. Lozano and J. L. Verdegay, çFuzzy connectives based crossover operators to model genetic algorithms population diversity Fuzzy Sets and Systems Vol. 92, No. 1, pp. 21-30, 1997 8  T. P. Hong, C. H. Chen, Y. L. Wu and Y. C. Lee, çA GA-based fuzzy mining approach to achieve a trade-off between number of rules and suitability of membership functions Soft Computing   Vol. 10, No 11, pp. 1091-1101. 2006 9  C. Kuok, A. Fu and M. Wong, çMining fuzzy association rules in databases SIGMOD Record Vol. 27, No. 1, pp. 41-46, 1998   Y. C. Lee, T. P. Hong and W. Y. Lin, çMining fuzzy association rules with multiple minimum supports using maximum constraints Lecture Notes in Computer Science Vol. 3214, pp. 1283-1290, 2004   J. B. McQueen, çSome Methods of Classification and Analysis of Mutivariate Observations Proceedings of the 5th Berkeley Symposium on Mathematical Satistics and Probability pp. 281-297 1967   William Siler and J. James Fuzzy Expert Systems and Fuzzy Reasoning John Wiley & Sons, 2004   H. Zhang and D. Liu Fuzzy Modeling and Fuzzy Control Springer Verlag, 2006  
536 


 
work a supervised multivariate discretization procedure is presented, which is specially indicated for class association rules \(CARs\. Our proposal evaluates the importance of the attributes on the classification and split simultaneously their values into intervals by means of a procedure that takes as reference the clusters generated by a supervised clustering algorithm. The algorithm produces the most suitable rules for prediction, due to the supervised discretization and the use of the most important attributes in discriminating the different values of the class attribute, which constitutes the consequent part of the rules. Our experiments demonstrated that, in the studied application field, associative classification methods combined with a good discretization procedure overcome widely to the classic supervised learning methods R EFERENCES  1  R. Agrawal, T. Imielinski and A. Swami, ìDatabase mining. A performance perspectiveî, IEEE Trans. Knowledge and Data Engineering, vol. 5, \(6\. 914-925,1993 2  R. Agrawal, T. Imielinski and A. Swami, ìMining associations between sets of items in large databasesî, Proc. of ACM SIGMOD Int Conference on Management of Data, Washinton, D.C., pp. 207-216 1993 3  R. Agrawal and R. Srikant, ìFast algorithms for mining association rules in large databasesî, Proc. of 20 th Int. Conference on Very Large Databases, Santiago de Chile, pp. 487-489, 1994 4  Y. Aumann and Y. Lindell, ìA statistical theory for quantitative association rulesî, Journal of Intelligent Information Systems, 20 \(3\, pp 255-283, 2003 5  R. Bayardo, R. Agrawal and D. Gunopulos, ìConstraint-based rule mining in large, dense databaseî, Proc. of. 15 th Int. Conference on Data Engineering, pp. 188-197, 1999 6  R. Bayardo and R. Agrawal, ìConstraint-based rule mining in large dense databaseî. Proc. Mining the most interesting rules, Proc. of ACM SIGKDD Int. Conf. Knowledge Discovery in Databases, ACM Press NY, pp. 145-154, 1999 7  J.J. Dolado, ìA validation of the component-based method for software size estimationî, IEEE Transactions on Software Engineering 26 \(10 pp. 1006-1021, 2000 8  U.M. Fayyad and K.B. Irani, ìMulti-interval discretization of continuous valued attributes for classification learningî, Proc. of the Thirteenth International Joint Conference on Articial Intelligence, IJCAI93 Chambery, France, pp. 1022-1027, 1993 9  J. Li and H. Shen and R. Topor, ìMining the smallest association rule set for predictionsî, Proc. of IEEE International Conference on Data Mining ICDMí01\, 2001   W. Li, J. Han and J. Pei, ìCMAR. Accurate and efficient classification based on multiple class-association rulesî, Proc. of the IEEE International Conference on Data Mining, \(ICDM í01\, California, pp 369-376, 2001   W. Lian, D.W. Cheung and S.M. Yiu, ìAn efficient algorithm for dense regions discovery from large-scale data streamsî, Computers Mathematics with Applications, 50, pp. 471-490, 2005   B. Liu, W. Hsu and Y. Ma, ìIntegration classification and association rule miningî, Proc. of 4 th Int. Conference on Knowledge Discovery and Data Mining, pp. 80-86, 1998   H. Liu, F. Hussain, C.L.Tan and M. Dash, ìDiscretization. An enabling techniqueî, Data Mining and Knowledge Discovery, vol. 6, pp. 393-423 2002   Mineset userís guide, v. 007-3214-004, 5/98. Silicon Graphics,1998   M.N. Moreno, L.A. Miguel, F.J. GarcÌa and M.J. Polo, ìBuilding knowledge discovery-driven models for decision support in project managementî, Decision Support Systems, 38 \(2\, pp. 305-317, 2004   M.N. Moreno, F.J. GarcÌa, and M.J. Polo, ìMining interesting association rules for Prediction in the Software Project Management Areaî, Proc. of 6th International Conference on Data Warehousing and Knowledge Discovery \(DaWaK 2004\. Lectures Notes in Computer Science, LNCS 3181, pp.341-350, 2004   M.N. Moreno, I. Ramos, F.J.GarcÌa and M. Toro, ìAn association rule mining method for estimating the impact of project management policies on software quality, development time and effortî, Expert Systems with Applications, 34 \(2\. 522ñ529, 2008   R. Srikant, and R. Agrawal, ìMining quantitative association rules in large relational tablesî, Proc. of ACM SIGMOD Conf. pp. 1-12, 1996   C.R. Symons, Software sizing and estimating MKII FPA, John Wiley and Sons, 1991   H. Verlinde, M. De Cock and R. Boute, ìFuzzy versus quantitative association rules. A fair data-driven comparisonî, IEEE Transactions on Systems, Man, and Cybernetics - Part B. Cybernetics, vol. 36, pp. 679684, 2006   J. Verner and G. Tate, ìA software size modelî, IEEE Transaction of Software Engineering, 18 \(4\ pp. 265-278, 1992   Y. Wang and A.K.C. Wong, ìFrom association to classification Inference using weight of evidenceî, IEEE Transactions on Knowledge and Data Engineering, 15, pp. 764-767, 2003   X. Yin and J. Han, ìCPAR. Classification based on predictive association rulesî, In. SIAM International Conference on Data Mining SDMí03\. pp. 331-335, 2003  
 


Figure 3 Precision-recall curve in ROI-250 image dataset 5.3 Experiment 3 Mammograms-1080 image dataset This experiment employed a dataset composed by 1080 mammograms images collected in the Clinical Hospital of University of Sao Paulo at Ribeiro Preto The dataset was previously classi\002ed into 4 levels of breast tissue density 0501\051 mostly fatty 050362 images\051 0502\051 partly fatty 050446 images\051 0503\051 partly dense 050200 images\051 and 0504\051 mostly dense 05072 images\051 Figure 4 Precision-recall curve in Mammography-1080 image dataset Breast density is an important risk factor in the development of breast cancer In this experiment the images are represented by the feature set proposed in b uilding a vector of 85 features including shape and size of the breast the conditions of the breast contour nipple position and the distribution of 002broglandular tissue This dataset was divided in training set and test set The training set is composed of 720 images and test set is composed of 360 images Figure 4 shows the P&R curves over test dataset and also the number of features selected in each method Again the proposed methods reached the highest values of precision and select the smallest number of features 050a\051 050b\051 050c\051 050d\051 Figure 5 Queries in Mammography dataset 050a\051 226 is the query image 050b\051 using the features selected through 002tness function F cB  050c\051 using the features selected through classi\002cation error of C4.5 and 050d\051 using the all features extracted Results for the retrieval of the 5 most similar images from a query image are also provided in this experiment as illustrated in Figure 5 The image 5.\050a\051 is the query image taken from the mostly fatty image class Images shown in 5.\050b\051 are the 5 most similar images retrieved for the proposed 002tness function F cB  The row 050c\051 shows the results for C 4  5 classi\002er whereas 050d\051 illustrate the images resulting from all features 050no selection applied\051 In Figure 5 the images surrounded by dashed lines are false positives 050not relevant images\051 For this query the proposed method achieved the highest precision 050100%\051 when compared the results of C4.5 and the original feature vector 050precision of 40%\051 


6 Conclusions This work proposed a novel genetic feature selection framework for CBIRs It employs a wrapper strategy that searches for the best reduced feature set while optimizing 050or preserving\051 the quality of the solution From a ranking evaluation function three new 002tness functions namely F cA  F cB and F c have been proposed and evaluated in three experiments The proposed genetic feature selection approach which encompasses F cA  F cB and F c  has been compared with 050a\051 traditional methods found in the literature 050b\051 the StARMiner feature selector and 050c\051 the whole feature vector and signi\002cantly outperformed them The proposed approach has been able to optimize the accuracy of similarity queries while selecting a signi\002catively reduced number of features Additionally the proposal of combining the quality of the query results with the criterion of minimizing the number of selected features F cA and F cB  led to high accurate query answers while reducing the number of features more than the 002tness function F c  Therefore the 002nal processing cost of the queries is also reduced References  P  M d Aze v edo-Marques N A Rosa A J M T raina C Traina-Jr S K Kinoshita and R M Rangayyan Reducing the semantic gap in content-based image retrieval in mammography with relevance feedback and inclusion of expert knowledge International Journal of Computer Assisted Radiology and Surgery  3\0501-2\051:123\226130 June 2008  R Baeza-Y ates and B Ribeiro-Neto Modern Information Retrieval  Addison-Wesley Essex UK 1999  B Bartell G Cottrell and R Bele w  Optimizing similar ity using multi-query relevance Journal of the American Society for Information Science  49:742\226761 1998  O Cord 264 on E Herrera-Viedma C L 264 opez-Puljalte M Luque and C Zarco A review on the application of evolutionary computation to information retrieval International Journal of Approximate Reasoning  34:241\226264 July 2003  J G Dy  C E Brodle y  A Kak L S Broderick and A M Aisen Unsupervised feature selection applied to content-based retrieval of lung images IEEE Transactions on Pattern Analysis and Machine Intelligence  25\0503\051:373\226 378 March 2003  W  F an E A F ox P  P athak and H W u The ef fects of 002tness functions on genetic programming-based ranking discovery for web search Journal of the American Society for Information Science and Technology  55\0507\051:628\226636 2004  W  F an P  P athak and M Zhou Genet ic-based approaches in ranking function discovery and optimization in information retrieval a framework Decision Support Systems  2009  D E Golber g Genetic algorithms in search optimization and machine learning  Addison Wesley 1989  R L Haupt and S E Haupt Practical Genetic Algorithms  John Wiley  Sons New Jersey United States second edition edition 2004  J Horng and C Y eh Applying genetic algorit hms to query optimization in document retrieval Information Processing  Management  36:737\226759 2000  S K Kinoshita P  M d Aze v edo-Ma rques R R PereiraJr J A H Rodrigues and R M Rangayyan Contentbased retrieval of mammograms using visual features related to breast density patterns Journal of Digital Imaging  20\0502\051:172\226190 June 2007  F  K orn B P agel and C F aloutsos On the  dimensionality curse and the self-similarity blessing IEEE Trans on Knowledge and Data Engineering  13\0501\051:96\226111 2001  H Liu and L Y u T o w ard inte grating feature select ion algorithms for classi\002cation and clustering IEEE Transactions on Knowledge and Data Enginnering  17\0504\051:491\226502 April 2005  M X Ribeiro A J M T raina C T raina-Jr  and P  M Azevedo-Marques An association rule-based method to support medical image diagnosis with ef\002ciency IEEE Transactions on Multimedia  10\0502\051:277\226285 2008  U S Cancer Statistics W orking Group United states cancer statistics 1999-2005 incidence and mortality webbased report atlanta 050ga\051 Department of health and human services centers for disease control and prevention and national cancer institute 2009 Available in http://apps.nccd.cdc.gov/uscs   L T amine C C and M Boughanem Multiple query evaluation based on an enhanced geneticnext term algorithm Information Processing  Management  39\0502\051:215\226 231 2003  R S T orres A X  F alc 230 ao M A Gonc\270alves J P Papa Z B W Fan and E A Fox A genetic programming framework for content-based image retrieval Journal of the American Society for Information Science and Technology  42\0502\051:283\226292 2009  A Tsymbal P  Cunningham M P echenizkiy  and S Puuronen Search strategies for ensemble feature selection in medical diagnostics In Proceedings of the 16th IEEE Symposium on Computer-Based Medical Systems  pages 124\226 129 June 2003  A Tsymbal M Pechenizkiy  and P  Cunningham Sequential genetic search for ensemble feature selection In Proceedings of the International Joint Conferences on Arti\002cial Intelligence  pages 877\226882 August 2005  C.-M W ang a and Y F  Huang Ev olutionary-based feature selection approaches with new criteria for data mining A case study of credit approval data Expert Systems with Applications  36\0503 Part 2\051:5900\2265908 2009  H Y an J Zheng Y  Jiang C Peng and S Xiao Selecting critical clinical features for heart diseases diagnosis with a real-coded genetic algorithm Applied Soft Computing  8:1105\2261111 2008  T  Zhao J Lu Y  Zhang and Q Xiao Feature selection based on genetic algorithm for cbir In IEEE Congress on Image and Signal Processing  volume 2 pages 495\226499 2008 


     Figure 9. Argumentation Tree For Open GL  A1 The current system in flash does not have the functionality of dynamic allocation of particles like mine or clutter. It places them randomly  A1.1 That is not of much importance because it still gives a new position to mine and clutter particles A2 Current system in flash has faster response time as compared to system in Adobe Director A3 The current system doesnêt satisfy many of the features required for the new system like database A4 Adobe Flash cannot communicate with database A4.1 Flash doesnêt support database but database support is very important and critical A4.1.1 The system should be able to generate evaluation reports for trainee based on pr evious records stored in the database A5 Flash doesnêt create sound clips  A5.1 We donêt need sound creating features as the sys tem has to generate sound. We can play externally recorded sound files using Adobe Flash A6 Flash can provide good visual effects as compared to Adobe Director A7 The developer has good knowledge in development using Flash so the system can be developed quickly B1 We could reuse the system already developed for sound generation, as it is developed using Adobe Audition for analysis which is somehow related to Adobe Director B1.1 The current system is better synthesized in terms of sound production and the sound produced is also instantaneous rather than discrete B1.2 That current system has certain performance issues like slow response time B1.3 The current system in Adobe Director has the feature of producing dynamic coloring scheme on approaching a mine. This kind of scheme is highly preferable and is not present in Adobe Flash system B2 Adobe Director can provide more functionality as compared to the current flash system. E.g. Multiple sounds while detecting mines   B2.1 Adobe Director can provide better visual effects as compared to flash e.g. in case of GUIês   B2.2 A modified version of the current system in flash can also provide the same functionality B2.2.1 We cannot integrate code developed in other platforms with Flash, but Flash can be integrated in Adobe Director B3 The interface provided by flash is not professional enough. It is too simple and straight forward for doing more things in future   B4 Easily available plug-ins can help integrate the tracking system developed in C# with Adobe Director  B4.1 Code developed in Open GL/AL can also be integrated using Adobe Director using suitable stubs   B5 A new sound recognition algorithm is being developed in Adobe Audition which can be integrated with Adobe Director but not with Open GL or Flash Evidence supported B6 If the current system is reused; the project deadline can be met easily B7 The developer has very little experience in development using Adobe Director   B7.1 The developer can take help from the already developed system in Adobe Director C1 The tracking software already developed is coded in C#/NX5. We could reuse that and develop our system in Open GL/AL C1.1 Open GL has C# libraries which can be used to develop the system C2 Because the platform used is for high end application development, it can provide good GUI and database support C2.1 Open GL/AL can help us generate dynamic surfaces for mine detection and training which the original system in flash does not have C4 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C3 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C4 The time taken for developing the project using open GL will be comparatively more as the whole system would have to be developed from scratch C4.1 If Open GL has support for C# libraries, and then the system could be develope d faster as developer is quite familiar with programming languages like C 151 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        






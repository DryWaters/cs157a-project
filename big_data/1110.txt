1 Dependable Real-time Data Mining Bhavani Thuraisingham 1, 2 Latifur Khan 1 Chris Clifton 2, 3  John Maurer 2 Marion Ceruti 4 1 The University of Texas at Dallas 2 The MITRE Corporation 3 Purdue University 4 Space and Naval Warfare Systems Center, San Diego Code 24121 Abstract In this paper we discuss the need for real-time data mining for many applications in government and industry and describe resulting research issues. We also discuss dependability issues including incorporating security, integrity, timeliness and fault tolerance into data mining. Several different data mining outcomes are described with regard to their implementation in a real-time environment. These outcomes include clustering, association-rule mining link analysis and anomaly detection. The paper describes how they would be used together in various parallel-processing architectures. Stream mining is discussed with respect to the challenges of performing data mining on stream data from sensors. The paper concludes with a summary and discussion of directions in this emerging area 1 Introduction Data mining is the process of posing various queries and extracting useful and often previously unknown and unexpected information, patterns, and trends from large quantities of data, generally stored in databases. These data could be accumulated over a long period of time or they could be large data sets accumulated simultaneously from heterogeneous sources such as different sensor types. The goals of data mining include improving marketing capabilities detecting abnormal patterns, and predicting the future based on past experiences and current trends. There is clearly a need for this technology for many applications in government and industry. For example a marketing organization may need to determine who their potential customers are. There are large amounts of current and historical data being stored. Therefore as databases become larger, it becomes increasingly difficult to support decision making. In addition, the data could be from multiple sources and multiple domains. There is a clear need to analyze the data to support planning and other functions of an enterprise Query Processor 
 Stable Sensor Data Storage Sensor Data Manager Update Processor Processes input data Carries out action, Stores some data in stable storage Throws away transient data Query Processor Processes continuous queries and gives responses periodically Input Data Transient Data Data to and from Stable Storage Continuous Query Response 
Stable Sensor Data Storage Sensor Data Manager Update Processor Processes input data Carries out action, Stores some data in stable storage Throws away transient data Checks access control rules and constraints Query Processor Processes continuous queries and gives responses periodically Checks access control rules and constraints Input Data Transient Data Data to and from Stable Storage Continuous Query Response 
Data Mining Mines the data and extracts patterns in real-time Query Processor Stable Sensor Data Storage Sensor Data Manager Update Processor Processes input data Carries out action, Stores some data in stable storage Throws away transient data Query Processor Processes continuous queries and gives responses periodically 
Input Data Transient Data Data to and from Stable Storage Continuous Query Response Stable Sensor Data Storage Sensor Data Manager Update Processor Processes input data Carries out action, Stores some data in stable storage Throws away transient data Checks access control rules and constraints Query Processor Processes continuous 
queries and gives responses periodically Checks access control rules and constraints Input Data Transient Data Data to and from Stable Storage Continuous Query Response Query Processor Stable Sensor Data Storage Sensor Data Manager Update Processor 
Processes input data Carries out action, Stores some data in stable storage Throws away transient data Query Processor Processes continuous queries and gives responses periodically Input Data Transient Data Data to and from Stable Storage Continuous Query Response 
Stable Sensor Data Storage Sensor Data Manager Update Processor Processes input data Carries out action, Stores some data in stable storage Throws away transient data Checks access control rules and constraints Query Processor Processes continuous queries and gives responses periodically Checks access control rules and constraints Input Data Transient Data Data to and from Stable Storage Continuous Query Response Data Mining Mines the data and extracts patterns in real-time Figure 1. Concept of Operation for Real-time Data Management and Data Mining Much of the focus on data mining has been for analytical applications. However there is a clear need to mine data for applications that have to meet timing constraints. For example, a government agency may need to determine whether a terrorist activity will happen within a certain time or a financial institution may need to give out financial quotes and estimates within a certain time. That is, we need tools and techniques for real-time data mining. Consider for example a medical application where the surgeons and radiologists have to work together during an operation Here, the radiologist has to analyze the images in realProceedings of the Eighth IEEE International Symposium on Object-Oriented Real-Time Distributed Computing \(ISORCê05 0-7695-2356-0/05 $ 20.00 IEEE 


2 time and give inputs to the surgeon. In the case of military applications, images and video may arrive from the war zone. These images have to be analyzed in real-time so that advice is given to the war fighter The challenge is to determine which data to analyze and which data to discard for future analysis in non real-time. In the case of counter-terrorism applications the system has to analyze the data about the passenger from the time the passenger gets ticketed until the plane is boarded, and give proper advice to the security agent. For all of these applications there is an urgent need for real-time data mining. Figure 1 illustrates a concept of operation for real-time data management and mining where some data are discarded, other data are analyzed and a third data set is stored for future use Thuraisingham, et al. introduced the notion of realtime data mining in on mining multimedia data, which is an aspect of realtime data mining. Since then there have been many developments in sensor data management as well as stream data mining. Furthermore, the need for realtime data mining is more apparent especially due to the need for counter-terrorism applications. In this paper we continue with out investigation of real-time data mining issues and challenges The organization of this paper is as follows. Some issues in real-time data mining including a discussion of real-time threats are given in Section 2. Adapting data mining techniques to meet real-time constraints is described in Section 3. Parallel and distributed realtime data mining is discussed in section 4. Techniques in dependable data mining that integrate security realtime processing and fault tolerance are given in Section 5. Stream data mining is discussed in Section 6 Summary and directions are provided in Section 7 2 Issues in Real-time Data Mining As stated in Section 1, data mining has typically been applied to non-real-time analytical applications Many applications, especially for counter-terrorism and national security, need to handle real-time threats Timing constraints characterize real-time threats. That is, such threats may occur within a certain time and therefore we need to respond to them immediately Examples of such threats include the spread of smallpox virus, chemical attacks, nuclear attacks network intrusions, and bombing of a building before The question is, what types of data mining techniques do we need for real-time threats Data mining can be applied to data accumulated over a period of time. The goal is to analyze the data make deductions and predict future trends. Ideally it is used as a decision support tool. However, the real-time situation is entirely different. We need to rethink the way we do data mining so that the tools can produce results in real-time For data mining to work effectively, we need many examples and patterns. We observe known patterns and historical data and then make predictions. Often for real-time data mining as well as terrorist attacks we have no prior knowledge. So the question is, how do we train the data mining tools based on, say, neural networks without historical data? Here we need to use hypothetical data as well as simulated data. We need to work with counter-terrorism specialists and get as many examples as possible. When we have gathered the examples and start training the neural networks and other data mining tools, the question becomes what sort of models do we build? Often the models for data mining are built before hand. These models are not dynamic. To handle real-time threats, we need the models to change dynamically. This is a big challenge Data gathering is also a challenge for real-time data mining. In the case of non real-time data mining, we can collect data, clean data, format the data, build warehouses and then carry out mining. All these tasks may not be possible for real-time data mining due to time constraints. Therefore, the questions are what tasks are critical and what tasks are not? Do we have time to analyze the data? Which data do we discard How do we build profiles of terrorists for real-time data mining? How can we increase processing speed and overall efficiency? We need real-time data management capabilities for real-time data mining From the pervious discussion it is clear that a lot has to be done before we can perform real-time data mining. Some have argued that there is no such thing as real-time data mining and it will be impossible to build models in real-time. Some others have argued that without accurate data we cannot do effective data mining. These arguments may be true. However others have predicted the impossibility of technology e.g. air travel, internet Granted. Our challenge is to then perhaps redefine data mining and figure out ways to handle real-time threats   Integrate data sources in real-time Build real-time models Examine Results in Real-time Report final results Data sources with information about terrorists and terrorist activities Mine the data Rapidly sift through data and discard irrelevant data Integrate data sources in real-time Build real-time models Examine Results in Real-time Report final results Data sources with information about terrorists and terrorist activities Mine the data Rapidly sift through data and discard irrelevant data Figure 2. Real-time Data Mining Cycle Proceedings of the Eighth IEEE International Symposium on Object-Oriented Real-Time Distributed Computing \(ISORCê05 0-7695-2356-0/05 $ 20.00 IEEE 


3 As we have stated, there are several situations that have to be managed in real-time. Examples are the spread of smallpox, network intrusions, and analyzing data sensor data. For example, surveillance cameras are placed in various places such as shopping centers and in front of embassies and other public places Often the data from these sensors must be analyzed in real-time to detect/prevent attacks. We discuss some of the research directions in the remaining sections Figure 2 illustrates the cycle for real-time data mining 3 Real-time Data-Mining Techniques In this section we examine the various data mining outcomes and discuss how they could be applied for real-time applications. The outcomes include making associations, link analysis, cluster formation classification and anomaly detection. The techniques that result in these outcomes are based on neural networks, decisions trees, market basket analysis techniques, inductive logic programming, rough sets link analysis based on the graph theory, and nearest neighbor techniques. As we have stated in the methods used for data mining are top-down reasoning where we start with a hypothesis and then determine whether the hypothesis is true or bottom-up reasoning where we start with examples and then form a hypothesis Let us start with association mining techniques Examples of these techniques include market basket  is to find which items go together. For example, we may apply a datamining tool to a data set and find that John comes from Country X and he has associated with James who has a criminal record. The tool also outputs the result that an unusually large percentage of people from Country X have performed some form of terrorist attacks Because of the associations between John and Country X, as well as between John and James, and James and criminal records, one may conclude that John has to be under observation. This is an example of an association. Link analysis is closely associated with making associations. Whereas association-rule based techniques are essentially intelligent search techniques link analysis uses graph theoretic methods for detecting patterns. With graphs \(i.e., nodes and links one can follow the chain and find links. For example A is seen with B and B is friends with C and C and D travel a lot together and D has a criminal record. The question is what conclusions can we draw about A Now, for real-time applications we need associationrule mining and link analysis techniques that out put the associations and links in real-time Relevant research is in progress. Incremental association rule mining techniques were first proposed in [CHNW More recently data-stream techniques for mining association have been proposed CW Section 6. Whereas they address some of the issues faced by real-time data mining, the key issue of time-critical need for results has not been addressed. The real-time database researchers have developed various techniques including real-time scheduling and approximate-query processing. We need to examine similar techniques for association-rule mining and link analysis and determine the outcomes that can be determined in real time. Are we losing information by imposing real-time constraints? How can we minimize errors when we impose real-time constraints? Are approximate answers accurate enough to base decisions on them Figure 3. Real-time Data Mining Outcomes Next, let us consider clustering techniques. One could analyze the data and form various clusters. For example, people with origins from country X and who belong to a certain religion may be grouped into Cluster I. People with origins from country Y and who are less than 50 years old may form another Cluster II These clusters could be formed based on their travel patterns, eating patterns, buying patterns, or behavior patterns. Whereas clustering techniques do not rely on any pre-specified condition to divide the population  Real-time Data Mining Outcomes Association  Find who travels with whom within 10 minutes Link Analysis  Find all links within 60 minutes Anomaly Detection  Find out anomalous behavior within 20 minutes Clustering Divide population based on travel patterns within 3 hours Classification  Build profiles of terrorist and classify terrorists within 24 hours Proceedings of the Eighth IEEE International Symposium on Object-Oriented Real-Time Distributed Computing \(ISORCê05 0-7695-2356-0/05 $ 20.00 IEEE 


4 classification divides the population based on some predefined condition. The condition is found based on examples. For example, we can form a profile of a terrorist. He could have the following characteristics Male less than 30 years of a certain religion and of a certain ethnic origin. This means all males less than 30 years belonging to the same religion and the same ethnic origin will be classified into this group and possibly could be placed under observation. The examples of clustering and classification discussed above are for analytical applications. For real-time applications the challenges is to find the important clusters in real-time. Again, data stream techniques may provide a start. Another approach is iterative techniques. Classical clustering methods such as k means and EM could refine answers based on the time available rather than terminating on distance-based criteria. The question is, how much accuracy and precision are we sacrificing by imposing timing constraints Another data mining outcome is anomaly detection A good example here is learning to fly an airplane without wanting to learn to takeoff or land. The general pattern is that people want to get a complete training course in flying. However there are now some individuals who want to learn flying but do not care about take off or landing. This is an anomaly. Another example is John always goes to the grocery store on Saturdays. But on Saturday October 26, 2002 he goes to a firearms store and buys a rifle. This is an anomaly and may need some further analysis as to why he is going to a firearms store when he has never done so before. Is it because he is nervous after hearing about the sniper shootings or is it because he has some ulterior motive? If he is living, say, in the Washington DC area, then one could understand why he wants to buy a firearm, possibly to protect him. But if he is living in say Socorro, New Mexico, then his actions may have to be followed up further. Anomaly detection faces many challenges even ignoring time constraints; a prime example is approaches for Intrusion Detection and [AX99 for surveys of the problem, and [W for a recent discussion of anomaly detection approaches.\Adding real-time constraints will only exacerbate the difficulties.  In many cases the anomalies have to be detected in real-time both for cyber security as well as for physical security. The technical challenge is to come up with meaningful anomalies as well as meet the timing constraints; however, a larger issue is to define the problems and surrounding systems to take advantage of anomaly detection methods in spite of the inevitable?\false negatives. Figure 3 illustrates examples of real-time data mining outcomes 4. Parallel, Distributed, Real-Time Data Mining For real-time data-mining applications, perhaps a combination of techniques may prove most efficient For example, association-rule techniques could be applied either in series or in parallel with clustering techniques, which is illustrated in Figure 4. In series the association-rule technique may provide enough information to issue a real-time alert to a decision maker before having to invoke the clustering algorithms Figure 4. Data-mining tasks executing in concert on separate platforms with direct link to the control program By using parallel processing software that executes on one or more hardware platforms with multiple processors, several real-time data-mining techniques can be explored simultaneously rather than sequentially. Among the many ways to implement this two basic categories emerge: First, one can execute real-time data-mining programs simultaneously but on separate processors and input the results to a control program that compares the results to criteria or threshold values to issue alert reports to a decision maker The second category is an architecture in which the programs execute in parallel, either on the same hardware platform or over a network, as depicted in Figure 5, where  a central program would format and parse data inputs to the various processors running the programs to determine the different data-mining outcomes. For example, when clusters start to form in the output of the cluster-detection processor, these clusters could be compared to the associations found in the association-rule processor. Similarly, the patterns formed by the link analysis processor could be input into the anomaly detector for examination to see if the pattern is the same or different from those expected The various processors could all process the same data  Classification Association Rules Anomaly Detection Link Analysis Clustering Control Program Proceedings of the Eighth IEEE International Symposium on Object-Oriented Real-Time Distributed Computing \(ISORCê05 0-7695-2356-0/05 $ 20.00 IEEE 


5  Anomaly Detection Control Program Classification Link Analysis in different ways, or they could process data from different sources. The central control program could compare the results to the criteria or thresholds and issue alerts even before the slower algorithms have finished processing. The control program would continue to send newly emerging results to the decision maker while the response to the threat is in progress Figure 5. Distributed data-mining tasks executing on a network The method of parallel processing depicted in Figure 6 is potentially the fastest and most efficient method of real-time data mining because the software that implements every data-mining outcome executes on the same hardware platform without any of the delays associated with communications networks routers, etc. It is also the most versatile, challenging and potentially best implement using artificial intelligence \(AI\pattern recognition and algorithm coordination. These AI techniques could include rule-based reasoning, case-based reasoning and Bayesian networks Figure 6. Data-mining tasks executing on a parallel machine 5.   Dependable Data Mining For a system to be dependable it must be secure fault tolerant, meet timing deadlines, and manage high quality data. However, integrating these features into a system means that the system has to meet conflicting requirements determined by the policy makers and the applications specialists.  For example, if the systems make all the access control checks, then it may miss some of its deadlines. The challenge in designing dependable systems is to design systems that are flexible. For example, in some situations it may be important to meet all the timing constraints while in some other situations it may be critical to satisfy all the security constraints The major components of dependable systems include dependable networks, dependable middleware including infrastructures, dependable operating systems, dependable data managers and dependable applications. Data mining, which can be regarded as an aspect of information and data management, has to be dependable also. This means that the data mining algorithms have to have the ability to recover from faults as well as maintain security, and meet real-time constraints all in the same program Sensor data may be available the form of streams Special data-management systems are needed to process stream data. For example, much of the data may be transient data. Therefore, the system has to analyze the data, discard unneeded data, and store the necessary data all in real time. Special query processing strategies including query optimization techniques are needed for data-stream management Many of the queries on stream data are continuous queries Aggregating making sense out of the sensor data is a major research challenge. The data may be incomplete or sometimes inaccurate. Many data prove to be irrelevant, thus increasing the noise of the detection-in-clutter task. We need the capability to deal with uncertainty and reason with incomplete data Information management includes extracting knowledge and models from data as well as mining and visualizing the data. Much work has been accomplished in information management the last several years. For example, sensor data must be visualized for a better understanding of the data. We need to develop intelligent, real-time visualization tools for the sensor data. One may also need to aggregate the sensor data and possibly build repositories and warehouses. However, much of the sensor data may be transient. Therefore, we need to determine which data to store and which data to discard. Data may also have to be processed in realtime. Some of the data may be stored and possibly warehoused and analyzed for conducting analysis and predicting trends. That is, the sensor data from surveillance cameras must be processed within a certain time. The data may also be warehoused for subsequent analysis Control 6 5 4 2 3 1 Clustering Association Rules Proceedings of the Eighth IEEE International Symposium on Object-Oriented Real-Time Distributed Computing \(ISORCê05 0-7695-2356-0/05 $ 20.00 IEEE 


6 Sensor and stream data mining are becoming an important areas. We need to examine the data-mining techniques such as association rule mining, clustering and link analysis for sensor data and data streams from sensors and other devices. One important consideration is to select the level of granularity at which to mine the data. For example, should we mine raw sensor data or data processed at a higher level of aggregation? For example, patterns found in images are easily detected only when observed in the image context where the relationships between image features are preserved These features are not recognized easily by analyzing a series of pixels from the image As we have stressed, we need to manage sensor data in real-time. Therefore, we may need to mine the data in real-time also. This means not only building models ahead of time so that we can analyze the data in real-time, we may also need to build models in realtime. That is, the models have to be flexible and dynamic. Model formation represents the aggregation of information at a very high level.  This is a major challenge. As we have stated in section 2, we also need many training examples to build models. For example we need to mine sensor data to detect, and possibly prevent, terrorist attacks. This means that we need training examples to train the neural networks classifiers and other tools so that they can recognize in real-time when a potential anomaly occurs. Sensordata mining is a fairly new research area and we need a research program for sensor-data management and data mining. The mining of data streams is discussed in Section 6 Data mining may be a solution to some dependability issues. Most data mining techniques generate aggregates over large quantities of data averaging out random errors. Systematic errors pose a greater challenge, but randomization approaches to privacy-preserving data mining, knowing something about the source of errors allows high quality data mining even if we cannot reconstruct correct data. Many techniques are nondeterministic; the similarity or dissimilarity of results of repeated runs provides a measure of dependability This was used to minimize errors in anomaly  i ning has the potential to improve the dependability of decisions based on data even if each datum taken separately is not dependable Data mining has also come under fire, perhaps unfairly, because of perceived impacts on privacy Researchers are developing techniques for privacypreserving data mining as well as for s handling the inference problem that occurs through data mining  e dat a m i ning problem s involve sensitive data; privacy will remain an issue. Many privacy-preserving data mining approaches come at a significant computational cost; we need to integrate security techniques with real-time data mining so that we can develop algorithms for dependable data mining. In particular, methods that trade off security for time constraints may be appropriate for particular problems. A passenger trying to catch a plane may be willing to accept some loss of privacy in return for a faster çanomaly detectioné check, however information of people used to develop the data mining model \(who have nothing to gain from the faster check\must not be disclosed. Such asymmetric privacy and security requirements raise new challenges 6.  Mining Data Streams In recent years, advances in hardware technology have made it easy to store and record numerous transactions and activities in everyday life in an automated way. Such processes result in data streams that often grow without limit, referred to as data streams. Stream data could come from sensors, video and other continuous media including transactions Some research has been performed on mining stream data. Several important problems recently have been explored in the data stream domain. Clustering projected clustering, classification, and frequent pattern mining on data streams are a few examples Clustering is a form of data management which must be undertaken with considerable care and attention.  The idea behind clustering is that a given set of data points can be organized into groups of similar objects through the use of a distance function.  By defining similarity through a distance function, an entire data stream can be partitioned into groups of similar objects.  Methods that do this view the problem of partitioning the data stream into object groups as an application of a one-pass clustering algorithm. This has some merit, but a more careful definition of the problem, with far better results, will view the data stream as an infinite process with data continually evolving over time.  Consequently, a process is needed which can de novo and continuously, establish dominant clusters apart from distortions introduced by the previous history of the stream. One way to accomplish this is to resize the data set periodically to include new data sampling and processing from time to time. The operator could set parameters such as how to include old data processed along with the new, at what level of granularity and during what time period. It is important that past discoveries do not bias future searches that could miss newly formed \(or rarely formed An interesting proposal for a two component process for clustering data streams is found in Aggarwal et al. [AHW com ponents are Proceedings of the Eighth IEEE International Symposium on Object-Oriented Real-Time Distributed Computing \(ISORCê05 0-7695-2356-0/05 $ 20.00 IEEE 


7 an on-line micro-clustering process and an off-line macro-clustering process. The first of these, the on-line micro-clustering component, is based on a procedure for storing appropriate summary statistics in a fast data stream.  This must be very efficient.  The summary statistics consist of the sum and square of data values and is a temporal extension of the cluster feature  ith respect to the offline component, user input is combined with the summary statistics to afford a rapid understanding of the clusters whenever this is required, and because this only utilizes the summary statistics it is very efficient in practice Flexibility to consider the way in which the clusters evolve over time is a feature of this two-phased approach, as is an opportunity for users to develop insight into real applications. The question of how individual clusters are maintained online is discussed in Aggarwal et al. Using an iterative approach, the algorithm for high-dimensional clustering is able to determine continuously new cluster structures, while at the same time re-defining the set of dimensions included in each cluster. A normalization process, with the aim of equalizing the standard deviation along each dimension, is used for the meaningful comparison of dimensions. As the data stream evolves over time, the values might be expected to change as well, making it necessary to re-compute the clusters and the normalization factor on a periodic basis. A period for this re-computation can be taken as an interval of a certain number of points For projected clustering on data streams, Aggarwal AHW  et al. have propose a m e thod of highdimensional projected-data-stream clustering called HPStream.é HPStream relies upon an exploration of a linear update philosophy in projected clustering achieving both high scalability and high clustering quality. Through HPStream, consistently high clustering quality can be achieved due to the programês adaptability to the nature of the real data set, where data their reveal its tight clustering behavior only in different subsets of dimension combinations For classification of data streams, Aggarwal AHW et al propose data-st ream m i ning in the context of classification based on one-pass mining Changes that have occurred in the model since the beginning of the stream construction process are not generally recognized in one pass mining. However, the authors propose the exploitation of incremental updating of the classification model, which will not be greater than the best sliding window model on a data stream, thus creating micro-clusters for each class in the training stream. Such micro-clusters represent summary statistics of a set of data points from the training data belonging to the same class, similar to the clustering model in the off-line component AHW To classify the test stream in each instance, a nearest neighbor classification process is applied after identifying various time horizons and/or segments. When different time horizons determine different class labels, majority voting is applied With regard to frequent pattern mining on data stream, Han algorithms at multiple time granularities. They first discuss the landmark model of Motwani and others  landm ark m odel considers a stream from start to finish. As a result the model is not appropriate for time sensitive data where the patterns such as video patterns as well as transactions may be sensitive to time. Therefore, they focus on data streams over certain intervals depending on the time sensitivity and describe algorithms for extracting frequent patterns in stream data. In particular they consider three types of patterns frequent patterns, sub frequent patterns, and infrequent patterns. They argue that due to limited storage space with sensor devices, one cannot handle all kinds of patterns. Therefore, they focus on frequent patterns and sub frequent patterns as the sub frequent patterns could become frequent patterns over time. They illustrate tree-building algorithms, which essentially develop a structure that is a pattern tree with a time window. Such a structure is what they call an FPStream. This technique essentially relies on the FPstreams Besides these, Demers, Gehrke et al. use the notion of an information sphere that exist within an agency and focused on mining the multiple high-speed data streams within discuss the global information spheres that span across the agencies and focus on joining multiple data streams One major difference is noted between what we have called real-time data mining and the data-stream mining defined by Han and others. In the case of realtime data mining, the goal is to mine the data and output results in real-time. That is, the data-mining algorithm must meet timing constraints and observe deadlines. In the case of stream mining, the goal is to find patterns over specified time intervals. That is, the patterns may be time sensitive but the result may not necessarily lead to an urgent action on the part of a decision maker unless the pattern were to emerge in time to allow appropriate follow-up action. We can also see the similarities between the two notions. That is, while stream mining has to find patterns within a specified time interval, it may also imply that after the interval has passed, the patterns may not be of much value. That is, stream mining also has to meet timing constraints in addition to finding patterns with time sensitive data. Essentially what we need is a taxonomy Proceedings of the Eighth IEEE International Symposium on Object-Oriented Real-Time Distributed Computing \(ISORCê05 0-7695-2356-0/05 $ 20.00 IEEE 


8 for real-time data mining that also includes stream mining 7.   Summary and Directions We introduced the notion of real-time data mining  h ereas the focus of that paper was on mining multimedia data, in this paper we discuss dependability issues for data mining. Recently much emphasis has been placed on data mining algorithms meeting timing constraints as well as mining timesensitive data. For example, how much do we lose by imposing constraints on the data mining algorithms? In some situations it is critical that analysis be completed and the results reported within few seconds rather than say, a few hours We first discussed issues of real-time data mining and then we examine various data mining techniques such as associations and clustering and discussed how they may meet timing constraints. We also discussed issues of using parallel processing techniques and mining data streams. This is because streams come from sensor and video devices and the patterns hidden in the streams may be time sensitive. We also discussed dependability issues for data mining Since we introduced the notion of real-time data mi u ch interest has em erged in the field. Many applications, including counterterrorism and financial analysis, clearly need this type of data mining.. Our paper has provided some initial directions. M any opportunities and challenges remain in real-time data mining Acknowledgements The authors thank Dr. Rick Steinheiser for valuable comments. The authors also thank the Office of Naval Research and the SSC-SD Science and Technology initiative for financial support. This work is approved for public release with an unlimited distribution Finally the authors thank Lei Wang for formatting the paper References   C. Aggarwal, J. Han, J. Wang, and P. S. Yu, çA Framework for Clustering Evolving Data Streams Proc 2003 Int. Conf. on Very Large Data Bases \(VLDB'03 Berlin, Germany, Sept. 2003  n, J. Wang, and P S Yu On Demand Classification of Data Streams Proc. 2004 Int Conf. on Knowledge Discovery and Data Mining \(KDD'04 Seattle, WA, Aug. 2004  C. Aggarwal,  J. Han J. Wang,  and  P S Yu A Framework for Projected Clustering of High Dimensional Data Streams Proc. 2004 Int. Conf. on Very Large Data Bases \(VLDB'04  Rakesh Agrawal and Ramakrishnan Srikant Privacy-Preserving Data Miningé, Proceedings of the 2000 ACM SIGMOD international conference on Management of data, Dallas, Texas, pp.439 Ö 450  S. Axelsson, Research in Intrusion Detection Systems: A Survey,. TR 98-17 \(revised in 1999\Chalmers University of Technology, 1999  D.W. Cheung, J. Han, V. Ng, and C.Y Wong Maintenance of discovered association rules in large databases: An incremental updating technique. In Proc. 1996 Int. Conf. Data Engineering, pages 106 -114, New Orleans Louisiana, Feb. 1996  Chris Clifton, çChange Detection in Overhead Imagery using Neural Networksé, International Journal of Applied Intelligence 18\(2\er Academic Publishers Dordrecht, The Netherlands, March 2003   Yun Chi Haixun Wang, Philip S. Yu, Richard R Muntz, Moment: Maintaining Closed Frequent Itemsets over a Stream SlidingWindow , ICDMê04  Demers A J. Ge hrke, and M. Riedewald Research Issues in Mining and Monitoring Intelligene Data Next Generation Data  Mining, AAAI Press, 2004. \(Editors H. Kargupta et al  W. Lee and W. Fan, Mining Sy stem Audit Data Opportunities and Challenges, SIGMOD Record 30\(4 44, 2001  k, and R. Motwani Maintaining stream statistics over sliding windows. Proc 13th SIAM-ACM Symp. on Discrete Algorithms, 2002  Thuraisingham, B., C. Clifton, M. Ceruti, and J Maurer,  Real-time Multimedia Data Mining, Proceedings of the ISORC Conference, Magdeberg, Germany, 2001   Thuraisingham, B., Data Mining for Business Intelligent and Counter-terrorism, CRC Press, 2003  Jaideep Vaidy a and Chris Clifton, çPrivacy Preserving Data Mining: Why, How, and What For?é, IEEE Security & Privacy, New York, NY, November/December 2004   K Wang S. Stolfo, Anomalous Pay load-based Network Intrusion Detection, RAID, 2004  T. Zhang, R. Ramakrishanan M Livny  BIRCH An Efficient Data Clustering Method for Very Large Databases,é Proc. of ACM SIGMOD Conference, 1996 Proceedings of the Eighth IEEE International Symposium on Object-Oriented Real-Time Distributed Computing \(ISORCê05 0-7695-2356-0/05 $ 20.00 IEEE 


1,2}, {2,3} and {1,2,3 tell which other entries contain item 2? We maintain for each item an index list as a P-tree \(called an index P-tree item exists in. For example, item 1 will have the following index list \(it will be stored as a P-tree but we are just listing the entries in a list for convenience 1,0,1,0,1,0,1. In other words, viewing the nodes of the SE tree in node creation order, item 1 occurs in node positions 1, 3, 5 and 7. Every new node added to the SE tree results in the expansion of all index P-trees by either a 1, if the corresponding item is in the new node added, or a 0, otherwise Going back to the previous scenario where the joining of item 4 with node {2} results in firing at least one pruning condition and thus node {2} need to be added to TL4, we simply OR the index P-tree of item 2 with TL4. In general, if we want to add node {x y  z} to some taboo list, TLI, we AND the index Ptrees for all items in the node \(i.e. AND index P-tree of x with that of y  with that of z us where item set {x, y  z} occurs. We then OR the resulting P-tree index with TLI which results in appending node {x, y  z} to TLI We maintain the taboo lists and index lists as Ptrees as this will give us faster logical operations and compression. In addition, in the case of taboo lists, it could speed the node traversal especially in cases where there many consecutive 1  s. For example suppose the entries in a taboo list are: 1111 0011 Figure 5 below shows the corresponding P-tree of the given taboo list Figure 5. The resulting taboo list in P-tree format In this example, instead of going through the first four nodes sequentially and then skipping them because they are flagged, using a P-tree to represent the taboo list, we can directly skip the first 4 entries because they form a pure-1 node on 2nd level of the Ptree It is worth mentioning that our traversal through the itemset space using taboo lists is very similar to a popular approach used in AI literature and known as Tabu search [13]. The idea in Tabu search is to traverse the space in a more effective manner by avoiding moves that result in revisiting points in the space previously visited whose outcome is known not to be acceptable \(hence the name "tabu   union of I and X produces an infrequent itemset implies that future joins of I with any superset of X will produce an infrequent itemset; a scenario similar in essence to revisiting a point in the search space whose outcome is known to be unsatisfactory and which could be circumvented by putting the point on a Tabu list. Because of the difference in context and problem definition, we refer to our lists as taboo lists instead of Tabu lists 5.3.  Comparison analysis To the best of our knowledge, no previous work has attempted to mine the type of rules we are considering We find [5] to be particularly interesting as it proposes an algorithm called Dense-Miner which is capable of mining association rules with fixed consequents at very low support thresholds. For the lack of a better benchmark, we will compare our approach with DenseMiner; however, we have to emphasize that a number 1                  0 0                    1 0 Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence  ICTAI 2004 


ICTAI 2004 1082-3409/04 $20.00  2004 IEEE of fundamental differences exists between the two approaches which we briefly outline next   D e n s e M i n e r  m i n e s  a l l  a s s o c i a t i o n  r u l e s  w h i l e  w e  only mine minimal, confident rules   D e n s e M i n e r  u s e s  s u p p o r t  a s  a  p r u n i n g  m e c h a n i s m  while this is not the case in our work \(In reality we also use support pruning, but in our case, the support threshold is always set to 2  as an absolute threshold In terms of rule overlap between the two approaches, all rules produced by our approach that have a support value greater than the minimum support threshold used for Dense-Miner will be produced by Dense-Miner also Table 2. Data sets description Table 3 Connect-4 Dataset 0 500 1000 1500 2000 2500 3000 3500 20 30 40 50 60 70 80 90 100 Confidence Threshold Ti m e s  P-tree based Dense Miner PUMSB Dataset 0 500 1000 1500 2000 2500 40 50 60 70 80 90 100 Confidence Threshold T im e s  P-tree based Dense Miner Figure 6. Speed comparison All experiments were conducted on a P-II 400 with 128 SDRAM running Red hat Linux 9.1.  C++ was used for coding. We experimented on two real-life dense data sets, Connect-4 and PUMSB, which are available at the UCI data repository. Table 2 below briefly describes the two datasets by listing the number of transactions, items, and items per transaction for each data set Connect-4 Dataset 0 50 100 150 200 250 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 99 99 5 Confidence Threshold 


N um be r of ru le s PUMSB-4 Dataset 0 20000 40000 60000 80000 100000 120000 140000 160000 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 91 91 5 Confidence Threshold N u m be r of ru le s Figure 7. Number of rules produced Figure 6 shows the time in seconds needed to mines rules at different confidence thresholds by our approach \(P-tree based aforementioned, Dense-Miner mines all rules using support pruning. It uses a variant of support referred to as coverage and defines the minimum coverage threshold as the minimum support divided by support of the fixed consequent. Results for Dense-Miner are observed with minimum coverage threshold fixed at 1% and 5%, respectively Our approach, on the other hand, mines only minimal rules without using any support pruning. It is very clear from the figure that users interested in minimal rules without support would prefer our approach as the time needed is many orders of magnitude less than that of Dense-Miner The user might notice from both parts of Figure 6 how the two approaches differ in the way they produce the rules. Dense-Miner takes more time at lower confidence while our approach takes more time at higher confidence thresholds. This is mainly because our approach mines minimal rules using only confidence pruning and the higher the confidence threshold, the more difficult it would be to get confident rules high in the SE tree; as a result, the SE tree grows deeper and thus requires more time to traverse. Dense-Miner, on the other hand, mines all Trans. Items Items per trans Connect-4 67557 129 43 PUMSB 49046 7117 74 Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence  ICTAI 2004 1082-3409/04 $20.00  2004 IEEE rules and it is very logical to have more rules satisfying lower confidence thresholds \(and vice versa obviously requires more time to mine The number of rules produced by Dense-Miner ranges from around 500,000 rules to less than 10 rules over both data sets. Figure 7 shows the number of rules produced by our approach over the two data sets at the 


produced by our approach over the two data sets at the different confidence thresholds. The same discussion presented in the previous paragraph applies here regarding the larger \(smaller produced at higher \(lower 6. Conclusion In this paper we proposed a framework based on SE-trees and the P-tree technology for extracting minimal, confident rules using fixed-consequent ARM Our methodology relieves the user from the burden of specifying a minimum support threshold by extracting the highest support rules that satisfy user confidence threshold. Albeit, to the best of our knowledge, no previous work has attempted to mine minimal confident rules with fixed consequents, we provide a comparison analysis study showing how well we compare to other close approaches in the literature In terms of limitations, we acknowledge that our approach suffers in situations where the desired rules lie deep in the tree because a large number of nodes and levels need to be traversed then. A future direction in this area targets finding measures for estimating the probability of rule availability along certain branches and quitting early in cases where such probability is low 7. References 1] R. Agrawal, T. Imielinski, and A. Swami, Mining association rules between sets of items in large databases Proceedings of the ACM SIGMOD \(Washington, D.C 1993 2] R. Agrawal and R. Srikant, Fast algorithms for mining association rules. Proceeding of the VLDB \(Santiago, Chile 1994 3] K. Ahmed, N. EI-Makky and Y. Taha  A note on  Beyond Market Baskets: Generalizing association rules to correlations  ACM SIGKDD Explorations, Vol. 1, Issue 2 pp. 46-48, 2000 4] Y. Bastide, N. Pasquier, R. Taouil, G. Stumme, and L Lakhal, Mining Minimal Non-Redundant Association Rules using Frequent Closed Item sets. Proceedings of the First International Conference on Computational Logic \(London UK 5] R. Bayardo, R. Agrawal, and D. Gunopulos, ConstraintBased Rule Mining in Large, Dense Databases. Proceedings of the IEEE ICDE \(Sydney, Australia 6] R. Bayardo and R. Agrawal, Mining the most interesting rules. Proceedings of the ACM SIGKDD \(San Diego, CA 1999 7] C. Becquet, S. Blachon, B. Jeudy, JF. Boulicaut, and O Grandrillon  Strong-association-rule mining for large-scale gene expression data analysis: a case on human SAGE data   Genome Biology, 3\(12 8] F. Coene, P. Leng, and S. Ahmed  Data Structure for Association Rule Mining: T-Tree and P-Trees  IEEE transactions on Knowledge and Data Engineering 16\(6 778, 2004 9] E. Cohen, M. Datar, S. Fujiwara, A. Gionis, P. Indyk, R Motwani, J. D. Ullman, and C. Yang  Finding interesting associations without support pruning  IEEE Transactions on Knowledge and Data Engineering, 13\(1  78, 2001 10] Q. Ding, M. Khan, A. Roy, and W. Perrizo, The p-tree algebra. Proceedings of the ACM SAC, Symposium on Applied Computing \(Madrid, Spain 11] Qin Ding, Qiang Ding, and W. Perrizo, Association Rule Mining on Remotely Sensed Images Using P-trees Proceedings of the PAKDD, Pacific-Asia Conference on Knowledge Discovery and Data Mining, Springer-Verlag Lecture Notes in Artificial Intelligence 2336, 66-79, May 2002 12] S. Fujiwara, J. D. Ullman and R. Motwani, Dynamic 


12] S. Fujiwara, J. D. Ullman and R. Motwani, Dynamic Miss-Counting Algorithms: Finding Implications and Similarity Rules with Confidence Pruning. Proceedings of the IEEE ICDE \(San Diego, CA 13] F. Glover  Tabu Search for Nonlinear and Parametric Optimization \(with Links to Genetic Algorithms  Discrete Applied Mathematics 49 \(1-3 14] M. Klemettinen, H. Mannila, P. Ronkainen, H Toivonen, and A. Verkamo, Finding interesting rules from large sets of discovered association rules. Proceedings of the ACM CIKM, International Conference on Information and Knowledge Management \(Kansas City, Missouri 1999 15] C. Ordonez, C. Santana, and L. de Braal, Discovering Interesting Association Rules in Medical Data. Proceedings of the IEEE Advances in Digital Libraries Conference Baltimore, MD 16] W. Perrizo, Peano count tree technology lab notes Technical Report NDSU-CS-TR-01-1, 2001 http://www.cs.ndsu.nodak. edu /~perrizo classes/785/pct.html. January 2003 17] Ron Raymon, An SE-tree based Characterization of the Induction Problem. Proceedings of the ICML, International Conference on Machine Learning \(Washington, D.C 275, 1993 18] N. Shivakumar, and H. Garcia-Molina, Building a Scalable and Accurate Copy Detection Mechanism Proceedings of the International Conference on the Theory and Practice of Digital Libraries, 1996 19] P. Tan, and V. Kumar, Interestingness Measures for Association Patterns: A Perspective, KDD  2000 Workshop on Post-processing in Machine Learning and Data Mining Boston, 2000 20] H.R. Varian, and P. Resnick, Eds. CACM Special Issue on Recommender Systems. Communications of the ACM 40 1997 Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence  ICTAI 2004 1082-3409/04 $20.00  2004 IEEE pre></body></html 


per by Ganti et. al. [9] deals with the measurement of similarity \(or deviation, in the authors  vocabulary between decision trees, frequent itemsets and clusters Although this is already a powerful approach, it is not generic enough for our purpose. The most relevant research e?ort in the literature, concerning pattern management is found in the ?eld of inductive databases Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE meant as databases that, in addition to data, also contain patterns [10], [7]. Our approach di?ers from the inductive database one mainly in two ways. Firstly, while only association rules and string patterns are usually considered there and no attempt is made towards a general pattern model, in our approach no prede?ned pattern types are considered and the main focus lies in devising a general and extensible model for patterns Secondly, di?erently from [10], we claim that the peculiarities of patterns in terms of structure and behavior together with the characteristic of the expected workload on them, call for a logical separation between the database and the pattern-base in order to ensure e?cient handling of both raw data and patterns through dedicated management systems Finally, we remark that even if some languages have been proposed for pattern generation and retrieval 14, 11], they mainly deal with speci?c types of patterns \(in general, association rules sider the more general problem of de?ning safe and su?ciently expressive language for querying heterogeneous patterns 7. Conclusions and Future Work In this paper we have dealt with the issue of modelling and managing patterns in a database-like setting Our approach is enabled through a Pattern-Base Management System, enabling the storage, querying and management of interesting abstractions of data which we call patterns. In this paper, we have \(a de?ned the logical foundations for the global setting of PBMS management through a model that covers data patterns and intermediate mappings and \(b language issues for PBMS management. To this end we presented a pattern speci?cation language for pattern management along with safety constraints for its usage and introduced queries and query operators and identi?ed interesting query classes Several research issues remain open. First, it is an interesting topic to incorporate the notion of type and class hierarchies in the model [15]. Second, we have intentionally avoided a deep discussion of statistical measures in this paper: it is more than a trivial task to de?ne a generic ontology of statistical measures for any kind of patterns out of the various methodologies that exist \(general probabilities Dempster-Schafer, Bayesian Networks, etc. [16 nally, pattern-base management is not a mature technology: as a recent survey shows [6], it is quite cumbersome to leverage their functionality through objectrelational technology and therefore, their design and engineering is an interesting topic of research References 1] Common Warehouse Metamodel \(CWM http://www.omg.org/cwm, 2001 2] ISO SQL/MM Part 6. http://www.sql99.org/SC32/WG4/Progression Documents/FCD/fcddatamining-2001-05.pdf, 2001 3] Java Data Mining API http://www.jcp.org/jsr/detail/73.prt, 2003 4] Predictive Model Markup Language \(PMML http://www.dmg.org 


http://www.dmg.org pmmlspecs v2/pmml v2 0.html, 2003 5] S. Abiteboul and C. Beeri. The power of languages for the manipulation of complex values. VLDB Journal 4\(4  794, 1995 6] B. Catania, A. Maddalena, E. Bertino, I. Duci, and Y.Theodoridis. Towards abenchmark for patternbases http://dke.cti.gr/panda/index.htm, 2003 7] L. De Raedt. A perspective on inductive databases SIGKDD Explorations, 4\(2  77, 2002 8] M. Escobar-Molano, R. Hull, and D. Jacobs. Safety and translation of calculus queries with scalar functions. In Proceedings of PODS, pages 253  264. ACMPress, 1993 9] V. Ganti, R. Ramakrishnan, J. Gehrke, andW.-Y. Loh A framework for measuring distances in data characteristics. PODS, 1999 10] T. Imielinski and H. Mannila. A database perspective on knowledge discovery. Communications of the ACM 39\(11  64, 1996 11] T. Imielinski and A. Virmani. MSQL: A Query Language for Database Mining. Data Mining and Knowledge Discovery, 2\(4  408, 1999 12] P. Kanellakis, G. Kuper, and P. Revesz. Constraint QueryLanguages. Journal of Computer and SystemSciences, 51\(1  52, 1995 13] P. Lyman and H. R. Varian. How much information http://www.sims.berkeley.edu/how-much-info, 2000 14] R.Meo, G. Psaila, and S. Ceri. An Extension to SQL for Mining Association Rules. Data Mining and Knowledge DiscoveryM, 2\(2  224, 1999 15] S. Rizzi, E. Bertino, B. Catania, M. Golfarelli M. Halkidi, M. Terrovitis, P. Vassiliadis, M. Vazirgiannis, and E. Vrachnos. Towards a logical model for patterns. In Proceedings of ER 2003, 2003 16] A. Siblerschatz and A. Tuzhillin. What makes patterns interesting in knowledge discovery systems. IEEE TKDE, 8\(6  974, 1996 17] D. Suciu. Domain-independent queries on databases with external functions. In Proceedings ICDT, volume 893, pages 177  190, 1995 18] M.Terrovitis, P.Vassiliadis, S. Skadopoulos, E. Bertino B. Catania, and A. Maddalena. Modeling and language support for the management of patternbases. Technical Report TR-2004-2, National Technical University of Athens, 2004. Available at http://www.dblab.ece.ntua.gr/pubs Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE pre></body></html 


The reason of the hiding failure of SWA is the same in Fig.8 Notice the result at x = 0.7646 in Fig.14, because the hiding failure is occurred at the seeds of the sensitive patterns, a high weakness is produced As shown in Fig.15 and Fig.16, the misses cost and dissimil arity of our work decreases as RL2 increases. This is because the larger RL2 is, the less effect on non-sensitive patterns. Also weakness and dissimilarity of SWA are independent of RL2 5. Conclusion In the paper, a novel method improving the balance between sensitive knowledge protecting and discovery on frequent patte rns has been proposed. By setting entries of a sanitization matrix to appropriate values and multiplying the original database by the matrix with some probability policies, a sanitized database is gotten. Moreover, it can avoid F-I Attack absolutely when the confidence level given by users approximates to 1. The experimental results revealed that although misses cost and dissimilarity between the original and sanitized database of our process are little more than SWA, ours provide more safely protection than SWA. Unlike SWA, our sanitization process could not suffer from F-I Attack and the probability policies in our approach also take the minimum support into account, the users only need to decide the confidence level which affects the degree of patterns hiding 6. Reference 1] M. Atallah, E. Bertino, A. Elmagarmid, M. Ibrahim and V. Verykios Disclosure Limitation of Sensitive Rules", Proc. of IEEE Knowledge and Data Engineering Exchange Workshop 1999 2] R. Agrawal and R. Srikant. Fast algorithms for mining association rules. VLDB, Santiago, Chile, 1994 3] R. Agrawal and R. Srikant. Privacy preserving data mining. In ACM SIGMOD, Dallas, Texas, May 2000 4] E. Dasseni, V. Verykios, A. Elmagarmid and E. Bertino, Hiding Association Rules by Using Confidence and Support", Proc. of 4th Intl Information Hiding Workshop \(IHW 5] A. Evfimievski, J. Gehrke, and R. Srikant. Limiting Privacy Breac hed in privacy preserving data mining. SIGMOD/PODS, 2003 6] A. Evfimievski, R. Srikant, R. Agrawal, and J. Gehrke. Privacy preserving mining of association rules. KDD 2002 7] M. Kantarcioglu and C. Clifton. Privacy-preserving distributed mining of association rules on horizontally partitioned data. In ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery, June 2002 8] Guanling Lee, Chien-Yu Chang and Arbee L.P Chen. Hiding sensitive patterns in association rules mining. The 28th Annual International Computer Software and Applications Conference 9] Y. Lindell and B. Pinkas. Privacy Preserving Data mining. In CRYPTO, pages 36-54, 2000 10] S. R. M. Oliveira and O. R. Za  ane. Privacy Preserving Frequent Itemset Mining. In Proc. of IEEE ICDM  02 Workshop on Privacy Security, and Data Mining 11] S. R. M. Oliveira and O. R. Za  ane. Algorithms for Balancing Priv acy and Knowledge Discovery in Association Rule Mining. IDEAS  03 12] S. R. M. Oliveira and O. R. Za  ane. Protecting Sensitive Knowledge By Data Sanitization, ICDM  03 13] S. R. M. Oliveira, O. R. Za  ane and Y  cel Saygin. Secure Association Rule Sharing, PAKDD-04 14] Benny Pinks. Cryptographic Techniques For Privacy-Preserving D ata Mining. ACM SIGKDD Explorations Newsletter Vol. 4, Is. 2, 2002 15] S. J. Rizvi and J. R. Haritsa. Maintaining data privacy in association rule mining. VLDB, 2002 16] J. Vaidya and C. W. Clifton. Privacy preserving association rule mining in vertically partitioned data. KDD2002 17] Verykios, V.S.; Elmagarmid, A.K.; Bertino, E.; Saygin, Y.; Dasseni E. Association rule hiding. IEEE Transactions On Knowledge And Data Engineering, Vol. 16, No. 4, April 2004 Proceedings of the 29th Annual International Computer Software and Applications Conference  COMPSAC  05 0730-3157/05 $20.00  2005 IEEE pre></body></html 


pre></body></html 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



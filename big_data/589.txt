Data Fusion and Prediction for CBRN Transport and Dispersion for Security  Sue Ellen Haupt*\206, George S. Young\206, Kerrie J Long*, Anke Beyer-Lout\206, Andrew J. Annunzio*\206 haupts2@asme.org, young@meteo.psu.edu, kj l203@psu.edu, aub166@psu edu, aja199@psu.edu  Applied Research Laboratory 206Department of Meteorology P.O. Box 30         Walker Building The Pennsylvania State University    The Pennsylvania State University State College, PA  16804      University Park, PA  16802  Abstract\227 If a toxic contaminant is released in the atmosphere, either by accident or by terrorist activity, the responsible agency must rapidly identify the source forecast the path and fate of 
the contaminant, warn the public or military command, and take action to protect the public, military personnel and equipment, and infrastructure. This process could be difficult if the location and type of source are not known and if there is not a dense network of meteorological stations. If, however, there are contaminant sensors, then the source and meteorological conditions can be back-calculated using a genetic algorithm-based software package and the transport and dispersion of the contaminant better predicted by applying data assimilation methods. This paper describes a technique for developing a sensor data fusion/meteorological data assimilation hybrid system. Th is work also analyzes the impact of noise in the data and assesses how much data are needed to perform the desired calculations 1 2  T 
ABLE OF C ONTENTS  1  I NTRODUCTION 1  2  S ENSOR D ATA F USION   D ATA A SSIMILATION  1  3  S OURCE C HARACTERIZATION 3  4  A SSIMILATION D EMONSTRATION 5 
 5  A PPLICATION TO N OISY D ATA 6  6  A NALYSIS OF D ATA R EQUIREMENTS 7  7  S UMMARY AND C ONCLUSIONS 8  R EFERENCES 8  B IOGRAPHIES 9 
 1  I NTRODUCTION  In the event of a toxic CBRN \(chemical, biological radiological, or nuclear\amin ant release, it is necessary to predict the path and fate of the contaminant plume in order to take appropriate steps to protect the public and to mitigate the source.  Often modelers may not know the correct source data required to initialize the predictive models. If field measurements of the contaminant concentrations are available they can be used to estimate 1  1 1-4244-1488-1/08/$25.00 \2512008 IEEE 2 IEEEAC paper #1195, Version 4, Updated December 20, 2007 
the location and strength of the source as well as the meteorological parameters that determine atmospheric transport and dispersion.  Such data can be recovered from concentration data monitored by a network of sensors  The process described above re quires the ability to compute atmospheric transport and disp ersion of the contaminant The difficulty with accurately predicting that transport and dispersion stems from various causes of uncertainty Specifically 200  Source information is often inexact or incomplete 200  The meteorological data may not be appropriate to the specific locale of the release 200  Monitored concentration data contain errors 200 
 There are inherent uncertainties in modeling turbulent dispersion 
200  Transport and dispersion models compute the ensemble average of many realizations of an event while the goal is to reproduce a specific single realization of the ev ent in real time 200  The wind field evolves in time and space Although these considerations imply a rather formidable problem, this work seeks to m eet these issues head-on by assimilating field data into the atmospheric transport and dispersion models using techniques from sensor data fusion and meteorological data assimilation. The National Research Council has recognized these difficult issues and commissioned a committee of expe rts to delineate the best   
 This paper describes a software system that back-calculates the modeling parameters then uses those parameters with the concentration data to initialize an atmospheric transport and dispersion model.  The resulting predictions will be useful for decision-makers in a homeland defense scenario or a military theatre. Specifically, the methodology uses atmospheric and transport and dispersion modeling and the monitored data, coupled by a genetic algorithm to backcalculate source strength, source location, time of release source height, wind direction, and wind speed.  Once the source and atmospheric conditions are determined, they can be used to predict the transport and dispersion of the toxic contaminant. The wind field, however, can still evolve in    1 


time and space. This difficulty can again be ameliorated by assimilating the monitored data into a dispersion model The assimilation process is demonstrated using techniques representing both meteorological data assimilation and multi-sensor data fusion  In addition, this paper analyzes the issues related to how much data is necessary to a ttain accurate predictions.  The sensor network must be sited st rategically or be evolvable to capture the plume of toxic contaminant.  This paper discusses the issues involved in siting a stationary network Specifically, the data requir ements for source estimation and wind field assimilation are assessed  Section 2 describes the sensor data fusion and data assimilation paradigm.  The source and meteorological characterization is demonstrated in section 3. Section 4 is devoted to demonstrating both multi-sensor data fusion and data assimilation in a time varying wind field. The impact of noise in the data is discussed in section 5 while section 6 assesses the data requirements of performing these data fusion and assimilation processes. Section 7 provides a summary and discussion 2  S ENSOR D ATA F USION   D ATA A SSIMILATION  Framework Both multi-sensor data fusion and meteorological data assimilation provide a framework for combining observations with forecasts to better estimate contaminant dispersion. In multi-sensor data fusion the state of an entity is identified, while in data assimilation the state of a field variable is estimated.  These two approaches give differing formulations for the problem.  Multi-sensor data fusion uses association techniques to decipher which observations belong to an entity via hypothe sis generation, evaluation and selection.  Since the focus is on the entity, the framework is Lagrangian in nature. In contrast, data assimilation techniques estimate field variables by using interpolation to compensate for the lack of data.  The field variable focus implies an Eulerian approach  While the estimation algorithms are nearly identical, the problem formulation differs between the methods since an entity has more observations than unknowns while field variables typically have more unknowns than observations As a result, multi-sensor data fusion is formulated for an over-determined problem whereas data assimilation is applied to an under-determined problem. The problem of estimating transport and dispersion modeling parameters from sensor data is an ideal testbed for studying the similarities and differences between multi-sensor data fusion and data assimilation    Mathematical Paradigm  The simplest way to pose the time rate of change of the dynamical system of an atmospheric transport and dispersion system is  x Mx t 002 003  003  1  where x is the field being predicted \(concentration and wind x t 002 003  003 2  where 0 x is the observed value of the field and f x is the forecast field G  is an adjustment function that specifies how the field is to be \223nudged\224 toward the observations.  If G is applied sufficiently gra dually, the dynamical system has a chance to adjust toward an equilibrium state.  If M is replaced or augmented by a no nlinear operator, nonlinear dynamical systems theory app lies: that is, there may be system behaviors such as bifurcations, multiple equilibria and sensitivity to initial conditions  Our goal is to define an optimal G for problems in atmospheric transport and dispersion.  There are numerous ways to do that.  This is the problem that both meteorological assimilation techniques and multi-sensor data fusion techniques strive to solve.  Our objectives are to 003 003 is its time rate of change or tendency M is a linearized operator based on the potentially nonlinear dynamics, and 002 is a stochastic noise term representing the errors in the model and the unresolved subgrid processes  One way to look at incorporating measured information into the model is  0   f x M xGxx t 200  define the essential dynamics M of \(1 problem 200  find ways of computing the functional operator G  in \(2 200  define the stochastic noise 002 so that it can be used to both estimate and minimize uncertainty Implicit in this process is evaluating and incorporating uncertainty in both the dynamics and the measurements  For atmospheric transport and dispersion, we can separate the problem into the wind equations and the concentration equation and define two separate G functions.  The first modifies the meteorological variables while the second modifies the concentration variables. Both functions depend on the meteorological data forecasts and measurements and also on the concentration fo recasts and measurements Mathematically, \(2\ be separated into     2 


004\004 004   212    5     3 002 003  003   3       of o f CCC C M vC G v v C C t       of o f vvv v M vv G v v C C t 002 003  003  4  where denotes a continuous two- or three-dimensional wind field, and C is the two- or three-dimensional concentration field \(We assume there is a single species and that no chemical interacti ons occur\pts v and C on the dynamics operator M denote the separation of the dynamics operator into a meteorological operator and a dispersion operator.  Both dynamics operators are functions of the wind field but only \(4\on the concentration field. There are two separate adjustment functions G Both of these depend on forecast \(superscript f observed measurements \(superscript o nd and concentration fields. That is, not only must the winds must be adjusted based on the difference between the observed and forecast wind fields, but they must also incorporate information on the difference of the concentration field from that forecast Similarly, the concentration adjustments depend on wind field differences as well as co ncentration differences.  This system is dynamic, coupled, and nonlinear.  Note that at each time step, the dynamics operator for concentration C  must be adjusted accordin g to the new estimate of v v In addition, both adjustment operators operate on the most recent forecast of both \(3\and \(4  essential interaction between the coupled systems; that is updates to the wind field are necessary to correct the concentration field. Note that the reverse is not generally true: the concentration field does not affect the wind field for a passive tracer. We can however, use information from the concentration field to infer properties of the wind field 3  S OURCE C HARACTERIZATION  Before using the dynamical system to forecast the concentration, we must first define the model parameters We can combine sensor data and the dispersion model predictions to iteratively determine the source and meteorological parameters that produce a pattern that best matches the monitored sensor data. The application of data assimilation to that problem is described here In prior work we demonstrated that coupling an atmospheric transport and dispersion model with an inverse model using a genetic algorithm \(GA\ is an effective approach for attributing concentration cont ribution at a receptor to each of a specified num  Thi s m e t h odol ogy  was tested using a basic Gaussian plume dispersion model on synthetic data for circular source configurations and with actual source configuration for Logan, Utah. The methodology was then validated using Monte Carlo techniques to determine the c onfidence intervals [3].  The robustness of the methodology was also studied by considering the effects of both additive and multiplicative white noi It was found t h at even when t h e noi s e was the same magnitude of the signal, the GA coupled model could correctly apportion the pollutant to the correct source The next step was to replace the Gaussian plume dispersion model with an operational puff model The GA coupled model performed as well with SCIPUFF computing the dispersion as with the Gaussian plume model. That enhanced coupled model was then tested on field test data [4 ith in th e lim itatio n s o f th e d a ta, th e coupled model still performed admirably. The cases where performance was disappointing were traced to difficult situations during the field test that would be expected to impact data quality.  For those cases, prior comparisons of model results to the measured concentrations were also quite poor   The reform ul at i on of t h e probl e m t o  additionally compute the wind direction appears in That  work was extended to include wind speed and effective plume height in  whi c h al so deri ved a t h eory for assessing how much data are re quired to accurately estimate model parameters in the presence of noisy data discussed further in section 6 The inverse problems in these prior studies were all solved using a GA.  The parameters to be optimized by the GA are the input values for the dispersion model.  Thus, for each potential solution, the results of the dispersion model with those optimized parameters ar e compared to the monitored concentration pattern. Related work includes Cartwright and Harris who earlier used a GA to back-calculate source strength in the absence of a wi nd field and Krysta, et al who back-calculated the two dimensional wind in addition to source characteristics using variational data assimilation in the context of best matching the dispersion in a wind tunnel model of a radionuclide release  This current work uses a continuous parameter GA, that is one in which the parameters are real numbers.  More details of the technique are found in  m aintains the best solution computed in the population unchanged into the next generation.  Based on prior sensitivity studies [6 w e choose a population size of 1200 and use 100 iterations of the GA to produce a best guess solution.  This is repeated 10 times and averaged. We apply a hybrid GA, which uses the GA to find the correct basi n of the minimum and then the Nelder-Meade Downhill Simplex \(NMDS\ethod to complete finding the minimum point of that basi   Here we show that the GA can compute the six essential parameters required for transport and dispersion specifically: two dimensional location of the source \(x,y source strength, time of the release, wind speed, and wind direction.  The cost function to be minimized by the GA is    5TR 2 1r1 5 2 11 ln ln cost ln   rr t TR r tr CR R 


 Figure 1. Location of dispersed puff 18 min after release demonstrated on a 16 km  Table 1 lists the different resolutions studied. The domain remains at 16 km where C r is the forecast concentra tion as predicted by the Gaussian puff equation R r is the observed concentration retrieved from receptor, and a and are constants used to avoid taking the logarithm of zero.  The cost function is summed over all receptors and over five time steps \(6, 12 18, 24, and 30 min. after the release  Figure 1 shows a typical domain \226 in this case for a 16 16 grid for a 225\260 wind direction.  The contaminant puff is shown 18 min. after the release 327  327 16 km grid 327 16 km, but the spacing of the receptors is varied.  The source is sited at the center of the grid.  The model is tested in the context of an identical twin experiment; that is, synthetic data are created by the same model that is used for the inverse problem. Sensors are sited at each intersection of the grid lines This approach allows careful testing of the methodology on data with a known solution.  Tests of two different wind directions will be described 212 180\260 where the centerline of the puff is in between the sensors and 225\260 where the centerline travels directly over a line of sensors.  Further studies \(not shown verified that results are not sensitive to wind direction [17   Table 1.  Grid configurations modeled Grid Size Grid Spacing 2x2 8000 m 4x4 4000 m 8x8 2000 m 16x16 1000 m 32x32 500 m 64x64 250 m  Results appear in Table 2.  E ach result is the average of ten separate GA runs.  The top portion of the table reports results for the 180\260 wind direction while the bottom portion is for 225\260.  For each of the six grid spacings, results are reported for both the GA alone and then for the GA followed by the NMDS method.  The third column indicates the average value of the cost function after 10 GA runs each of which completed 100 iterations The cost function is a measure of convergence of the search and closeness to the true concentration field.  The fourth column lists the independent skill score, computed by comparing the source characterization solution to the known truth.  The lower the skill score, the closer is the solution to the truth.  As expected, the denser the sensor network, the more accurate is the solution  Table 2. Averaged results of ten runs of the GA for calculating the source characteristics and the meteorological data.  Small skill scores are desired 180\260 Wind Direction Solution Type Grid Size Cost Function Skill Score GA Alone GA+NMDS 2 327 16 1.8e-3 3.4e-6 0.0908 0.0502 GA Alone GA+NMDS 32 327 32 1.4e-3 3.1e-7 0.0828 0.0342 GA Alone GA+NMDS 64 327 64 1.7e-3 7.6e-9 0.0674 0.0334 225\260 Wind Direction GA Alone GA+NMDS 2 327 16 3.7e-3 2.0e-6 0.1023 0.0833 GA Alone GA+NMDS 32 327 32 2.9e-3 9.0e-6 0.1469 0.0593 GA Alone GA+NMDS 64 327 64 2.5e-3 2.7e-6 0.1011 0.0154  Figure 2 illustrates the drop in skill score as grid resolution increases.  Even with a resolution as low as 4 327 4, the GA produces an excellent skill score for the 225\260 wind direction, but a higher resolution is needed for the more challenging 180\260 case. Note that it is only when resolution is adequate that the NMDS improves on the GA solution The computation requires enough information for the GA to find the correct basin of the minimum before the NMDS can improve on the solution  This demonstration problem has treated the concentration data as a field variable and, hence, is more akin to meteorological data assimilation.  It is most similar to the    4 327 4 2.6e-3 1.1e-9 0.1877 0.3088 GA Alone GA+NMDS 8 327 8 3.5e-3 4.6e-8 0.0969 0.0666 GA Alone GA+NMDS 16 327 2 1.8e-1 1.0e-1 0.3972 0.5611 GA Alone GA+NMDS 4 327 8 2.3e-3 1.5e-6 0.1309 0.0196 GA Alone GA+NMDS 16 327 2 7.4e-4 5.7e-10 0.4324 0.4510 GA Alone GA+NMDS 4 327 4 8.7e-4 2.3e-5 0.1143 0.1926 GA Alone GA+NMDS 8 


four dimensional variational approach \(4DVAR  But  rather than setting up a matrix problem to compute the Jacobian cost function, it \223leaps\224 directly to solving the cost function via an artificial intelligence technique.  The GA approach is much more straightforward to define than the more traditional 4DVAR and it consistently provides excellent solutions if the data network is sufficient. Section 6 revisits the issue of data requirements with noisy data for this problem   a  b Figure 2. Variation of skill score with grid resolution. a 180\260 and b\ind  4  A SSIMILATION D EMONSTRATION  The previous section illustra ted the methodology and data requirements to solve the first part of the problem \226 backcalculating the source information in an unknown meteorological field.  The second part of the problem recognizes the temporal and sp atial variability of the wind field and computes the wind field from concentration measurements in order to assimilate those measurements into the forcing condition for the transport and dispersion model.  The wind field not only advects, or transports, the contaminant, but it also impacts the lateral and vertical dispersion  Note that there is a long history of assimilating monitored data into meteorological models Here we si m p l y  seek to optimize the wind direction to produce a predicted concentration field closest to that monitored \(wind direction is typically the variable that produces the largest change in concentration pattern\e GA method is most akin to the variational approaches to assimilation, but rather than using the variational formalism, leaps directly to computing the best match as was done for the source and meteorological characterization above. In this case, we assume that the source characteristics are known and seek to compute the time evolving wind direction.  The identical twin experiment is a meandering concentration puff that grows in time and is embedded in a sinusoidally varying wind field The domain is 5 km 327 5 km with sensors sited every 125 m The synthetic data is produced with an integration time interval of 20 s  GA Eulerian Assimilation  Two separate approaches to assimilation of wind direction are taken.  The first approach us es an Eulerian field variable approach similar to meteorological data assimilation. The cost function fit is identical to \(5\and is accomplished with a GA. Figure 3 compares this assimilated puff plotted every five time steps \(b\to the actual puff progression to be matched \(a\at the end of the assimilation period using all of the sensor data.  The patterns are indistinguishable.  The GA match to the actual wind direction is indicated in Figure 4. Except for the initial time, the two appear identical Figure 6 shows that the puff cen terline as computed by the GA is indistinguishable from the truth  FEWN Lagranigan Approach The second approach to assimilation is to treat the puff as an entity and to use a multi-sensor data fusion Lagrangian approach to compute the wind field differences.  One of the frequently used data assimilation techniques in Numerical Weather Prediction \(NWP\plications is Newtonian Relaxation or Nudgi Nudgi ng i s  a com p ut at i o nal l y  efficient technique that relaxe s the model state toward the observations by adding artificial tendency terms to the prognostic equatio whi c h i s equivalent to the forcing term of \(1\ng assimilates only those variables that are modeled explicitly. Thus, we require a method to link the concentration field with th e wind field.  Here feature extraction provides that missing link between concentration observations and the wind field. Wind field errors are extracted from differences in concentration observations and the concentration forecast This approach produces a direction and magnitude of the error so that the system can then be nudged towards that corrected wind field by defining Combining this feature extraction technique with Nudging \(referred to as FEWN below\des a strategy that is both simple to implement and computationally v G    5 


 a  b Figure 3. Puff concentration plotted every 100 s for a the truth track and b Figure 4. Assimilated match to the wind direction  efficient. It can handle low sensor density and asynchronous observations  The FEWN method was applied to the concentration puff at complete spatial and temporal resolution. Figure 5 shows the FEWN-assimilated puff plotted every 100 s for the full 1000 s integration and should be compared to Figure 3a The puff trajectory shows a phase shift due to the diagnosed wind direction always being one time step behind the integration. Figure 4 compares the computed wind direction at each time.  The diagnosed wind for FEWN is relatively close to the truth and nudging keeps the wind direction in tandem with the exact wind direction, although the solution is not as smooth as the GA assimilation approach. The puff centerline is tracked in Fi gure 6. The FEWN trajectory generally follows the truth trajectory rather closely, with jagged deviations. We conclude that the FEWN approach to assimilating concentration is successful, relatively quick and shows promise when we can define discrete features that can be tracked Figure 5. Puff concentration predicted for meandering puff every 100 s for assimilation using feature extraction with nudging \(FEWN 5  A PPLICATION TO N OISY D ATA  Many chemical sensors currently in use display a rectangular bar-shaped readout for the concentration that provides at best an order of magnitude precisi  Errors in observations can also result from uncertainty in the meteorological data as well as from the chaotic nature inherent in turbulent flow as discussed in  In order t o  simulate a more realistic environment, we corrupt the observation data with both additive and multiplicative noise at six signal-to-noise ratios \(SNRs\ 100, 10, 5, 2, 1, and 0.1. The two validations presented previously were run without noise, that is at an SNR of infinity. The signal and the noise are of equal magnitudes for an SNR of 1. For an SNR of 0.1, the noise is ten tim es greater than the signal and at this point we expect the model to fail. The complete results for both additive and multiplicative noise can be found in the thesis by  We used a clipped Gaussian additive noise: that is    6 


concentrations below 0 are set to 0. Figure 7  plots the skill score for additive noise at ev ery grid size for the 225\260 wind direction. Results \(not shown\te similar for the 180\260  wind direction [17 Sk ill sco r e v alu es o f  0  1  o r  less correspond to good results whereas skill score values of 0.2 or greater indicate less accurate solutions. The results for SNR of 100, 10, and 5 are very similar to the model results without noise. When the noise is close to the magnitude of the signal \(SNR = 2\any of the solutions found by the hybrid GA are outside the domain and the model begins to fail. At an SNR of 1 and 0.1, solutions are often unphysical and the model fails. Figure 7  also illustrates that the 2 x 2 grid size is too small to produce good solutions and that the model fails for that resolution. Results for multiplicative noise are similar to those for additive noise [17   Figure 6. Location of the puff centroid plotted as a trajectory in time comparing the truth \(black solid FEWN, and the GA leap variational assimilation   Figure 7. Contours of skill score for additive noise for the 225\260 wind direction case 6  A NALYSIS OF D ATA R EQUIREMENTS  In order to quantify how many receptors are necessary to obtain a good solution, we examine heuristic methods for developing information measures. This work is inspired by the field of information theory \(IT\itiated by Shannon in  The goal i s t o  defi ne an i n form at i o n m easure t h at  quantifies the amount of independent information in a data analysis. In this case, it means that we want to define how fine the grid resolution must be for a given amount of noise in the data in order for our method to obtain a sufficiently close solution. We define two correlations 2 1  22 1  1 tt cc n FIT r r 005\006 212 b 6  where  tt r is the squared correlation between the noiseless concentration field with the one at the next time step where t is the time step and 2  ncc r  is the squared correlation between the concentration field with and without noise, both averaged over all time steps.  Both correlations are functions of grid resolution and signal to noise ratio and are determined from the model runs that produced Figure 7 plus similar plots for the 180\260 wind direction case. We define an information measure, FIT, as  007 005 and 006 are powers to be determined and 007  is a threshold value such that the quantity yielded produces a successful solution.  The first factor is designed to measure the amount of information that can be extracted from the puff transport and dispersion and the second factor is designed to measure the degree to which the pattern remains uncontaminated by noise  FIT generates a binary matrix that is a function of grid resolution and signal to noise ratio.  It is then compared with the successful model configurations matrix, defined as those grid size/noise combinations where the ten run median value of every parameter is found within a strict tolerance  By minimizing the difference between the FIT and the successful configurations, we can determine the values of 005  006 and 007 that produce a model setup whose solutions are within strict tolerances, determining the minimum number of receptors needed to obtain such a solution in a specified noise environment. The fit to the parameters is not unique Considering both wind directions, a possible solution was computed with a genetic algorithm is 005 0.1 006 4, and 007 0.85.  These values indicat e that the squared correlation between the concentration field with and without noise is a critical factor in determin ing how many receptors are necessary.  In a noiseless or low noise environment, an 8x8 grid is sufficient to back-calculate our parameters.  When the noise is within a factor of two of the signal, the GA can no longer distinguish the source and meteorological parameters accurately.  This analysis provides guidance for configuring a receptor grid to provide enough data for this GA-based model to back-calculate source and    7   


meteorological parameters.  It is problem dependent 7  S UMMARY AND C ONCLUSIONS  In this paper, we have demonstrated the relevance and practicality of assimilating monitored sensor data into transport and dispersion mode ls. A general paradigm was developed then tested on two types of applications. The first application used a genetic algorithm and the dispersion model to back-calculate source and meteorological parameters. The algorithm was successful in assimilating the sensor data to compute source location \(x,y\strength time of release, wind direction, and wind speed. As shown in section 5, the success continued to be realized with substantial amounts of noise added to the data. That information was then integrated in section 6 to determine how much data are necessary for a successful reconstruction of the event. The required data depends on the correlations between the different measuring times and the correlations with the noise The second application showed how the paradigm could be applied to a meandering plume problem. Both the Lagrangian entity approach of sensor data fusion and the Eulerian field approach taken in meteorological data assimilation showed considerable success in reconstructing the time varying wind directions This study indicates that even with a modest amount of noisy data, one could reconstruct the contaminant release determine the dynamic wind, and make good estimates of the progression of a contaminant downwind from the source. This information could be disseminated to decisionmakers to determine the best mitigative and evacuative actions in the case of a contaminant release Note that this study used the identical twin experiment approach that is valid for verifying and validating numerics It should, however, be confirmed in the context of field monitored data and that effort is in progress. In addition this study does not include the characteristics of real sensors, another issue that is currently being studied A CKNOWLEDGEMENTS  This effort has been supported by the Defense Threat Reduction Agency under grant number W911NF-06-C0162.  We would particularly like to thank John Hannan and Christopher Kiley as well as our colleagues at the University of Buffalo, Tarun Singh and Peter Scott. We wish to thank John Wyngaard Joel Peltier, David Stauffer Luna Rodriguez, Lili Lei,  and Yuki Kuroki for helpful discussions R EFERENCES   1  National Research Council Tracking and Predicting the Atmospheric Dispersion of Hazardous Material Releases. Implications for Homeland Security The National Academies Press, Washington, D.C., 2003  2  S.E. Haupt, \223A Demonstration of Coupled Receptor/Dispersion Mode ling with a Genetic Algorithm,\224 Atmospheric Environment vol. 39, pp 7181-7189, 2005  3  S. E. Haupt, G. S. Young, and C. T. Allen, \223Validation of a Receptor/Dispersion Mode l Coupled with a Genetic Algorithm Using Synthetic Data,\224 J. Appl. Meteor  45  476\226490, 2006  4  C. T. Allen, S.E. Haupt, and G. S. Young, \223Source Characterization With a Genetic Algorithm-Coupled Receptor/Dispersion Model Incorporating SCIPUFF\224  J Appl. Meteor 2007, in press  5  J.C Chang, P. Franzese, K. Chayantrakom, and S. R Hanna, \223Evaluations of CALPUFF, HPAC, and VLSTRACK with Two Mesoscale Field Datasets\224 J Appl. Meteor  42 453-466, 2003  6  C.T. Allen, G.S. Young, and S.E. Haupt, \223Improving Pollutant Source Characterization by Optimizing Meteorological Data with a Genetic Algorithm\224, to Atmospheric Environment 2007, in press  7  K.J. Long, S.E. Haupt, and G.S. Young, \223Improving Meteorological Forcing and Contaminant Source Characterization Using a Genetic Algorithm.\224 Submitted to Journal of Environmental Management  2007  8  H. M. Cartwright and S. P. Harris, \223Analysis of the distribution of airborne pollution using GAs,\224 Atmos Environ  27A 1783-1791, 1993  9  M. Krysta, M. Bocquet, B. Sportisse, and O. Isnard 223Data assimilation for short-range dispersion of radionuclides: An application to wind tunnel data 223 Atmos Environ  40 7267-7279, 2006  10   R. L. Haupt and S. E. Haupt Practical Genetic Algorithms 2 nd edition with CD. John Wiley & Sons New York, NY, 2004  11  J. A. Nelder and R. Mead, \223A Simplex Method for Function Minimization\224 Computer Journal  7 308313, 1965     8 


12  E. Kalnay Atmospheric Modeling, Data Assimilation and Predictability Cambridge University Press Cambridge, 136-204, 2003  13  R. Daley Atmospheric Data Assimilation Cambridge University Press, Cambridge, 457 pp., 1991  14  J.E. Hoke, and R.A. Anthes, \223The Initialization of Numerical Models by a Dynamic Initialization Technique,\224 Mon. Wea. Rev  104 1551-1556, 1976  15  D.R. Stauffer, and N.L. Seaman, \223Multiscale FourDimensional Data Assimilation,\224 J. Appl. Meteor  33  416-434, 1993  9  16  P. Robins, Rapley, V., Thomas, P., \223A Probabilistic Chemical Sensor Model for Data Fusion,\224 Dstl Salisbury, UK, 2005  17  K.J. Long Improving Contaminant Source Characterization and Meteorological Data Forcing with a Genetic Algorithm M.S. Thesis, Dept. of Meteorology, The Pennsylvania State University, 55 pp 2007    C.E. Shannon, \223A m a t h em at i cal t h eory of communication,\224 Bell System Technical Journal  27  379-423 and 623-656, 1948  B IOGRAPHIES  Sue Ellen Haupt is Head of the Department of Atmospheric and Oceanic Physics at the Applied Research Laboratory of The Pennsylvania State University and Associate Professor of Meteorology. She received her Ph.D. in Atmospheric Science from the University of Michigan, M.S. in Mechanical Engineering from Worcester Polytechnic Institute and B.S. in Meteorology from Penn State. In addition to PSU, she has been at New England Electric System, the National Center for Atmospheric Research, University of Colorado/Boulder University of Nevada, Reno, and Utah State University. Dr Haupt co-chaired the IEEE Ae rospace Conference Junior Conference for six years George S. Young is Professor of Meteorology at The Pennsylvania State University specializing in artificial intelligence applications to weather prediction and observational studies atmospheric flow structures.  He has served on the faculty of the Pennsylvania State University since receiving his Ph.D. in Atmospheric Sciences from Colorado State University in 1986.  He also holds B.S and M.S. degrees in Meteorology from Florida State University.  He has published 1 book, 3 book chapters 74 journal papers and 99 conference papers as well as advised 33 graduate students.  He chaired the National Science Foundation / University Corporation for Atmospheric Research observing Facilities Advisory Panel in 2000 and has been a member of the American Meteorological Society's committees on Mountain Meteorology \(1992-1995\ and Boundary Layers and Turbulence \(1999-2002 Kerrie J. Long is a Research Assistant in the Department of Atmospheric and Oceanic Physics of the Applied Research Laboratory at Penn State. She has worked on atmospheric dispersion problems particularly source characterization using artificial intelligence techniques. She earned a B.S. in Physics from the University of Massachusetts Dartmouth and M.S. in Meteorology from Penn State Anke Beyer-Lout is a graduate student in the Department of Meteorology at the Pennsylvania State University. She graduated with a Bachelors of Science degree in Meteorology from the University of Hamburg in Germany in August 2005 and came to Penn State in January 2006. Anke is currently working with George S Young and Sue Ellen Haupt on a project concerning data assimilation and dispersion modeling. She expects to graduate with a M.S. in Meteorology in December 2007  Andrew Annunzio is a meteorology graduate student at the Pennsylvania State University.  He graduated from the Ohio State University in 2006 with honors and distinction in Geography and minored in Mathematics.  Andrew began studies at Penn State in Fall 2006, and is now in pursuit of his masters under Sue Ellen Haupt and George Young.  After obtaining the M.S. in May 2008, he wishes to pursue a Ph.D. in Meteorology with a minor in Mathematics 


13 P Embrechts C Kluppelberg and T Mikosch Modelling Extremal Events Springer-Verlag Berlin 1997 14 L Tarassenko P.R Bannister and D A Clifton Novelty Detection in K Worden ed Encylopaedia of Structural Health Monitoring Wiley 2008 15 D.A Clifton Density Estimation for Novelty Detection in Jet Engine Vibration Data Technical Report Oxford BioSignals Ltd UK 2006 16 R.L Smith Extreme Value Analysis of Environmental Time Series Statistical Science 4\(4 pp.367-377 1989 17 S.J Roberts Novelty Detection Using Extreme Value Statistics IEE Proceedings 146\(3 1999 18 S.J Roberts Extreme Value Statistics for Novelty Detection in BiomedicaDataprocessing IEE Proceedings on Science Measurement and Technology 147\(6 2000 19 A R Webb Statistical Pattern Recognition Wiley 2002 20 S.G Coles and E A Powell Bayesian Methods in Extreme Value Modelling A Review and New Developments International Statistical Review  Revue Intemationale de Statistique Vol 64 No 1 pp 119-136 1996 21 D.A Clifton P.R Bannister and L Tarassenko A Framework for Novelty Detection in Jet Engine Vibration Data in L Garibaldi S Surace K Holford eds Key Engineering Materials 347:305-312 2007 22 D.A Clifton B Haskins P.R Bannister and L Tarassenko Specific and Generic Models for GasTurbine Novelty Detection Proc of 4th IET Int Conf on Condition Monitoring Harrogate UK 2007 23 S.W Utete D.A Clifton and L Tarassenko Trending Performance Parameters for Aircraft Condition Monitoring Proc of 4th IET Int Conf on Condition Monitoring Harrogate UK 2007 BIOGRAPHY David A Clifton is a DPhil candidate in Engineering Science at Oxford University and Senior Engineer at university spin-out company Oxford BioSignals Ltd His research interests include statistical pattern recognition for health monitoring of biomedical and industrial systems for which he has been the awarded many of the UK's leading student engineering awards including those from the IEE the Institute of Physics the Royal Academy of Engineering the European Commission Hewlett-Packard Europe Shell UK and the UK Engineering Council His current research part-funded by the UK Department of Trade and Industry involves devising novelty detection systems for modern civil and military aircraft engines including the Eurofighter EJ200 the Airbus A380 Trent 900 and the Boeing Dreamliner Trent 1000 Nick McGrogan is Technical Manager for the Industrial division of Oxford BioSignals Ltd He holds an M.Sc degree in Engineering and Computing Science and a D.Phil degree in Engineering Science both from Oxford University He is also a member of the Institution of e ngineering and Technology JET His D.Phil research was in the area of advanced signal processing for the detection of epileptic seizures in long-term recordings of brain activity While completing his D.Phil degree he joined Oxford BioSignals when the company was founded to progress the development of medical signal processing products and progressed to leading the industrial division in the development of techniques for health monitoring of aircraft engines In his current role he is responsible for Oxford BioSignal's technology strategy and manages the company's research projects Lionel Tarassenko Lionel Tarassenko was born in Paris France in 1957 He received the B.A degree in engineering science in 19 78 and the Ph D degree in medical engineering in 1985 both from Oxford University Oxford U.K After graduating he worked for Racal Research Ltd on the development of digital signal processing techniques principally for speech coding He then held a number of positions in academia and industry before taking up a University Lecturership at Oxford in 1988 Since then he has devoted most of his research effort to the development of neural network techniques and their application to signal processing diagnostic systems andparallel architectures He has held the Chair in Electrical Engineering at Oxford University since October 1997 He was elected to a Fellowship of the Institution of Electrical Engineers IEE in 1996 when he was also awarded the IEE Mather Premium for his work on neural networks and to a Fellowship of the Royal Academy of Engineering RAE in 2000 10 


Dennis M King is the RollsRoyce PLC Company specialist in Engine Health Monitoring specialising in the vibration aspects of EHM He was awarded an MSc in Engineering Mechanics in 1976 by the Cranfield Institute of Technology UK and Chartered Engineer in 1988 RAeS After graduating he joined RollsRoyce in Derby working in Stress analysis and design before moving to the vibration laboratories and taking on the role of consulting on the design build and balance of aero engines Over the last twenty years he has been actively involved in developing EHM technology including Hardware software fault recognition and diagnostics He has the experience of applying this technology globally within the R-R business He has been awarded the R-R Component Engineering Quality award 1997 R-R Chairman's team awardfor technical innovation 2001 a member of the Institute for Engineering Technology IET Having worked in Rolls-Royce since 1979 he has built up many years experience working in advanced signal processing methods Data Mining Neural Networks and equipment health monitoring Steve's current post is within the Company's Global EHM Capability Group Prior to this he spent 12 years working in the Company's Corporate Strategic Research Centre with responsibility for the development and application of Computational Intelligence techniques across all business areas of Rolls-Royce He was awarded the Rolls-Royce Chairman's awardfor Technical Innovation in 2001 and is named on three patents He is also a member of the International Scientific Committee of the International Conference for Condition Monitoring Paul Anuzis has spent five years of his working career at Rolls-Royce in Germany helping to establish a new and highly sucessful RollsRoyce business unit in Germany based initially in Munich now established in Dahlewitz on the outskirts of Berlin Paul returned in late 1997 to take up his current position of Chief Reliability Engineer for Rolls-Royce Civil Aerospace Airlines He holds a degree in Physics and second degree in Electronics is a Chartered Physicists Chartered Scientist Chartered Engineer and a Fellow of the Institute of Physics and has twice won the Rolls-Royce Chairman's awardfor Technical Innovation He has extensive applied research experience from several years of runing DTI technology programs The most sucessful programs spanning eight years working with the Universities of Oxford Nottingham and Cranfield on engine health monitoring technologies which are about to enter service with the latest Trent 900/A380 application Steve P.King is a Specialist for advanced Engine H ealth Monitoring Method at Rolls-Royce plc He holds a degree in Mathematics and Computer Science and a PhD in the use of Expert Systems fo r Vibration Analysis He is a Chartered Engineer and 11 


  12  Figure 1:  Lunar South Pole Elevation Map from GSSR 2006 Digital Elevation Model  Figure 2:  Lunar North Pole Elevation Ma p from GSSR 1997 Digital Elevation Model 


  13  Figure 3:  Shackleton Crater T opographic Map, with Base Sites  Figure 4: Solar Lines-of-Si ght at Lunar South Pole 


  14  Figure 5:  Site B1 Terrain horizon ma sk with 1 degree azimuth spacing  Figure 6:  Site B1 Terrain horizon mask with 1 de gree azimuth spacing, in e quatorial coordinates 


  15  Figure 7: Lunar South Pole Solar Illumination Yearly Average  Figure 8:  Lunar South Pole DTE Visibility Yearly Average 


  16  Figure 9: Lunar North Pole Sola r Illumination Yearly Average  Figure 10:  Lunar North Pole D TE Visibility Yearly Average 


  17  Figure 11: Site A1 Elevation Topography  Figure 12: Site A1 Yearly Average Solar Illumination and DTE visibility, Medium Resolution 


  18   Figure 13:  Site LB Te rrain Horizon Mask  Figure 14:  Theory and Computed values of Average Yearly Solar Illumination 


  19  Figure 15:  Theory and Computed values of Average Yearly DTE Communication  Figure 16:  Heliostat Mirror Design to Eliminate Cable Wrap 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



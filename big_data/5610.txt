Mining Generalized Fuzzy Association Rules via Determining Minimum Supports     Abstract Association rule mining is based on the assumption that users can specify the minimum-support for mining their databases. It has been identified that setting the minimum support is a difficult task to users. This can hamper the widespread applications of these algorithms. This paper proposes a method for computing minimum supports for each item. It therefore will run the fuzzy multi-level mining algorithm for extracting knowledge implicit in quantitative transactions immediately. More specifically, our algorithms automatically generate actual minimum-supports according to users’ mining requirements. In order to address this need, the new approach can express tow profits includes computing the minimum support for each item regarding to characteristic for each item in database and making a system automation. We considered an algorithm that can cover the multiple level association rules under multiple item supports. We experimentally examine the algorithms using a dataset, and demonstrate that our algorithm fittingly approximates actual minimum-supports from the commonly-used requirements  Keywords Fuzzy data mining; minimum confidence multiple minimum supports; membership functions association rule 1. Introduction In information age, people face more and more information problems such as data saving, organizing and indexing etc. These problems have the characteristic as more complication in hierarchy, more spacious in working space, faster in time and more abroad and far reaching in results and influences. Data mining is a new field in data treating. It is a process to find models outlines and educing values from data set. It is a crossdiscipline, dealing with database technique, machine learning, statistics, neural network, knowledge engineering, high performance calculation etc. and is widely used in industry, agriculture, commerce, business and iatrical etc [1    Association rule mining finds interesting association or correlation relationship among a large data set of items 2  T h e d i sco v er y o f i n t e r e st i n g ass o ci at i o n r u l e s can b e  of help in decision making process. Market basket analysis is considered as a typical example of association rule mining. In market basket analysis, customers buying habit is analyzed for finding association between different items customers put together in their shopping cart. Two different items, A and B, in an itemset are assumed to have a relation if they are purchased together in the same transaction [3   I n t h i s case i t  can  b e  co n s i d er ed as i f o n e  customer buys A is the reason he/she buys B and vice versa. More two items are purchased together in the same transaction, more they have stronger relation. The discovery of such associations can help retailers develop marketing strategies by gaining insight into which items are frequently purchased together by customers [3   Recently,  the  fuzzy  set  theory  [4 h a s b een u s ed  more and more frequently in intelligent systems because of  its simplicity and  similarity to human reasoning [5  Several  fuzzy  learning  algorithms  for  inducing  rules from given sets of data have been designed and used  to good effect with specific domains [6   7   A s t o f u zz y   data  mining,  Hong  and  Kuo  proposed  a mining approach  that  integrated  fuzzy-set  concepts with the Apriori mining algorithm [8 to f i n d  in te re s t in g ite m s e t s  and fuzzy association rules in transaction data with quantitative values However, these mining algorithms are mostly based on the assumption that users can specify the minimum support appropriate to their databases, and thus referred to as the Apriori-like algorithms [9   1 0    H a n et al  1 1   have pointed out that setting the minimum support is quite subtle, which can hinder the widespread applications of these algorithms. Our own experiences of mining transaction databases also tell us that the setting is by no means an easy task. With existing algorithms that presume a single minimum support, the best that one can do is to apply such algorithms at the lowest minimum support specified and filter the result using the other minimum supports. This approach will generate many candidates that are later discarded [12  H o n g  an d et al  proposed a method for Multi-level fuzzy mining with multiple minimum supports [13  1 4   b u t in th is i s s u e  user must be specified minimum support for each item Ehsan Vejdani Mahmoudi  Vahid Aghighi  Masood Niazi Torshiz  Mehrdad Jalali  Mahdi Yaghoobi    Young Researchers Club, Mashhad Branch, Islamic Azad University, Mashhad, Iran, e.vejdani@mshdiau.ac.ir  Department of computer Engineering, Mashhad Branch, Islamic Azad University, Mashhad, Iran, vd.aghighi@gmail.com  Department of computer Engineering, Mashhad Branch, Islamic Azad University, Mashhad, Iran, niazi@mshdiau.ac.ir  Department of computer Engineering, Mashhad Branch, Islamic Azad University, Mashhad, Iran, jalali@mshdiau.ac.ir  Department of Electrical Engineering, Mashhad Branch, Islamic Azad University, Mashhad, Iran, yaghobi@mshdiau.ac.ir 


Furthermore, taxonomic relationships among items often appear in real applications. For example, wheat bread and white bread are two kinds of bread. Bread is thus a higher level of concept than wheat bread or white bread. The information needed by decision makers in some applications is not necessary to be detailed to the primitive concept level, but at a higher one. For example the association rule “bread milk” may be more helpful to decision makers than the rule “wheat bread juice milk”. Discovering association rules at different levels may thus provide more information than the one at a single level [15   1 6   Basically, fuzzy mining algorithms first used membership functions to transform each quantitative value into a fuzzy set in linguistic terms and then used a fuzzy mining process to find fuzzy association rules. This paper consists two phases. First phase, computing minimum supports for each item in database with its own features. In the second phase, starting fuzzy multiple level mining algorithm with multiple minimum supports of items for extracting implicit knowledge from transactions stored as quantitative values The remaining parts of this paper are organized as follows. Multiple level mining and compute minimum support for each item discussed in Section 2. The proposed algorithm modified framework multiple level fuzzy mining with multiple minimum supports is described in Section 3.  Numerical simulations are shown in Section 4. Conclusion is given in Section 5 2. Preliminary In this section, we explain the concept of multiple level mining. Afterward, we illustrate how one can compute minimum support for each item 2.1 Mining multiple level association rules Previous studies on data mining focused on finding association rules at a single concept level. Mining association rules at multiple concept levels may however, lead to discovery of more general and important knowledge from data. Relevant item taxonomies are usually predefined in real-world applications and can be represented as hierarchy trees. Terminal nodes on the trees represent actual items appearing in transactions internal nodes represent classes or concepts formed from lower-level nodes [17  A s i m p l e e x a m pl e i s  gi ve n i n  F i g  1 In Fig. 1, the root node for “Food” is at level 0, the internal nodes representing categories \(such as “Milk are at level 1, the internal nodes representing flavors such as “Chocolate”\ are at level 2, and the terminal nodes representing brands \(such as “Kaleh”\ are at level 3. Only terminal nodes appear in transactions. Han and Fu proposed a method for finding level-crossing association rules at multiple levels [16 T h e i r m e t h o d  could find flexible association rules not confined to strict pre-arranged conceptual hierarchies. Nodes in predefined taxonomies are first encoded using sequences of numbers and the symbol “*” according to their positions in the hierarchy tree [13  F o r e x a m p l e t h e i n t e r n al n o d e  Milk” in Fig. 1 is represented by 1**, the internal node Chocolate” by 11*, and the terminal node “Pegah” by 111. A top-down progressively deepening search approach is used and exploration of “level-crossing association relationships is allowed [13     Fig. 1: The predefined taxonomy 2.2 Computing the multiple minimum support A variety of mining approaches based on the Apriori algorithm were proposed, each for a specific problem domain, a specific data type, or for improving its efficiency [18   I n t h ese a p p r o a ch es t h e m i n i m u m supports for all the items or itemsets to be large are set at a single value. Liu et al. proposed an approach for mining association rules with non-uniform minimum support values [19    In reality, however, there are many good reasons that the minimum support is not uniform. First, deviation and exception often have much lower support than general trends [12  F o r ex a m p l e r u l e s f o r acci d e n t s ar e m u ch  less supported than rules for non-accidents, but the former are often more interesting than the latter. Second the support requirement often varies with the support of items contained in an itemset. Rules containing bread and milk usually have higher support than rules containing food processor and pan. Third, item presence has less support than item absence. Fourth, the support requirement often varies at different concept levels of items [15    1 6   F i f t h  h i er ar ch i cal cl a s si f i c a t i o n l i k e  2 0   requires feature terms to be discovered at different concept levels, thereby, requiring a non-uniform minimum support. Finally, in recommender systems  recommendation rules are required to cater or both big and small groups of customers. In general, rules of high support are well-known to the user, and it is the rules of low support that may provide interesting insights and need to be discovered [12  H o n g e t a l  p r o p o s e d  m u ltip le  level fuzzy mining with multiple minimum supports [13  14   I n  t h e i r m e t hod   u s e r m u s t be s p e c i f y i n g m i ni m u m support for each item. But, it has been recognized that setting the minimum support is a difficult task to users This can hinder the widespread applications of these algorithms. In this paper we propose a method for computing minimum support for each item with own characterize in databases. There are significant criteria for computing minimum support like, the number that each item happened in database and sum of values for each item in database. For example, suppose the number that item A happened in database is 10 and sum values is 20 


and also the number that item B happened in database is 2 and sum values is 20. Clearly in mining process item A valuable than item B. We computing minimum support for item B until this item can’t satisfying minimum support. As mentioned above, we suggested in \(1\ as below       1 Let I = {i1, i2, ..., im} be a set of items and D = {t1 t2, ... , tn} be a set of transactions. N is total number of transaction data. T is the number that each item happened in database. Si is sum values of an item in database D. P is constant digit with respect to the interval [0, 1   3. The Proposed Algorithm The proposed algorithm modified framework multilevel fuzzy mining with multiple minimum supports [13   14   T h e p r o p o s ed m i n i n g  al g o r i t h m  i n t e g r a t es f u zz y s e t  concepts, data mining and multiple-level taxonomy to find fuzzy association rules in a given transaction data set. The knowledge derived is represented by fuzzy linguistic terms, and thus easily understandable by human beings. In spite of proposed algorithm [13   1 4  w h i c h  user must be specified minimum support for each item we computed minimum support for each item with own characteristics. Minimum supports are computed by a pre-processing on all items. Since, in real world applications, like applications which work on transactional data of chain stores, items have different quantities. Hence, using different minimum supports for each item in order to mining association rules is an efficient idea. The minimum support for an itemset is set as the maximum of the minimum supports of the items contained in the itemset  while the minimum support for an item at a higher taxonomic concept is set as the minimum of the minimum supports of the items belonging to it [13  T h e  p r o p os e d f u z z y m i n i n g  algorithm first encodes items \(nodes\ in a given taxonomy as Han and Fu’s approach did [1  I t t h e n  filters out unpromising itemsets; the count of a fuzzy region is checked to determine whether it is larger than support threshold. In this phase, a set of membership functions are used to transform the quantitative transactions into fuzzy values. The proposed algorithm then finds all the large itemsets for the given transactions by comparing the fuzzy count of each candidate itemset with its support threshold Input A body of n quantitative transaction data D predefined taxonomy with the primitive items, a set of membership functions, P is constant digit with respect to the interval [0, 1  an d a m i n i m u m co n f i d en c e  v a l u e  Output A set of fuzzy association rules Step 1  Encode the predefined taxonomy using a sequence of numbers and the symbol “*”, with the lth number representing the branch number of a certain item at level l Step 2  Translate the item names in the transaction data according to the encoding scheme Step 3  Compute minimum support for each item in \(1    1 Let I = {i1, i2, ..., im} be a set of items and D = {t1 t2, ... , tn} be a set of transactions. N is total number of transaction data. T is number of occurrence an item in the database. Si is sum values of an item in database D. P is constant digit with respect to the interval [0, 1   Step 4  Set k = 1, where k is used to store the level number being processed Step 5  Group the items with the same first k digits in each transaction and add the amounts of the items in the same groups in Denote the amount of the j-th group for as  Step 6  For each group transform the quantitative value of in each transaction datum into a fuzzy set represented as    using specified membership functions in Step 3, where  I=l to n h is the number of fuzzy regions for  is the lth fuzzy region of   and  is s fuzzy membership value in region  Step 7  Collect the fuzzy regions \(linguistic terms\ with membership values larger than zero to form the candidate set Calculate the scalar cardinality  of each fuzzy region in the transaction data by \(2    2 Step 8  Check whether the value  of each region in is larger than or equals to the threshold which is the minimum of minimum supports of the primitive items descending from it. If satis  es the threshold, put it into the large 1-itemset for level k That is    Step 9  If k reaches the level number of the taxonomy go to Step 17 to find association rules; otherwise, if is null, set k = k + 1 and go to Step 4; otherwise, do the next step Step 10  Generate the candidate set from  to  nd ‘‘level-crossing’’ large itemsets. The generated candidate set has to satisfy following conditions a  Each 2-itemset in must contain at least one item in  b  The two regions in a 2-itemset may not have the same item name c  The two item names in a 2-itemset may not be with the hierarchy relation in the taxonomy d  Both of the support values of the two large 1itemsets comprising a candidate 2-itemset must be larger than or equal to the maximum of the minimum supports of the two large 1-itemsets Step 11  Do the following sub steps for each newly formed candidate 2-itemset s with regions \(s 1 s 2   


a  Calculate the fuzzy value of s in each transaction as  where is the membership value of region in Assume the minimum operator is used for intersection, then   b  Calculate the scalar cardinality of s in all the transaction data as    c  If counts is larger than or equals to the maximum of the minimum supports of the items contained in it, put s into  Step 12  Set r = 2, where r is used to represent the number of regions stored in the current large itemsets Step 13  If is null, then set k = k + 1 and go to Step 6; otherwise, do the next step Step 14  Generate the candidate set  from in a way similar to that in the Apriori algorithm [22 Th a t is   the algorithm first joins and assuming that  regions in the two itemsets are the same and the other one is different. There is a difference from the Apriori algorithm in that the supports of all the large r-itemsets comprising a candidate \(r + 1\-itemset I must be larger than or equal to the maximum of the support thresholds of these large r-itemsets. Store in  all the itemsets with all their sub-r-itemsets in and satisfying the above conditions Step 15  Do the following sub steps for each newly formed \(r+1\emset s with regions    in   a  Calculate the fuzzy values of s in each transaction as, where is the membership value of region in  Assume the minimum operator is used for intersection then \(3\ follow as     3  b  Calculate the scalar cardinality of s in all the transaction With in \(4    4  c  If  is larger than or equals to the maximum of the minimum supports of the regions contained in it, put s into   Step 16  Set r = r + 1 and go to Step 13 Step 17  Construct the fuzzy association rules for all large q-itemset s containing regions    by the following substeps a  Form all possible association rules by \(5\ as follows        5 b  Calculate the confidence values of all association rules by \(6      6 Step 18  Output the rules with confidence values larger than or equal to the predefined confidence value  Note that since the hierarchical relationship of the items in a candidate 2-itemset has been checked in Step 10, the candidate 3-itemsets will not need to be checked for it according to a lemma in [15  Al l  t h e l a r g e i t e m s et s  will thus exclude the hierarchical relationship of items 4. Numerical simulations To evaluate our work we have compared our algorithm with two previously proposed approaches: Mining Fuzzy Multiple-Level Association Rules from Quantitative Data 2  a n d M u l t i l e v e l  f u z z y  m i ni ng w i t h  m u l t i p l e m i n i m u m  supports [13  T h e  e xpe r i m e nt s w e r e  i m pl e m e n t e d i n  MATLAB R2008b on a computer with Intel Core\(TM\2 Duo Processor 2.66GHz and 4 GB main memory, running the Microsoft Windows 7 operating system. We used Dataset w i t h a t o t a l o f 64 i t e m s  a n d 10,00 0  transactions. The dataset [2 c o nt a i ne d q u a nt i t a t i v e  transactions about the products sold in the chain store. The parameters in three algorithms were set as follows: the minimum confidence was set 0.5 for three algorithms, the defined minimum support for algorithm w a s  s e t  2 1   and for proposed algorithm in [13 m i n i m u m s u ppor t s  must specified by expert user, which is a very difficult task. The minimum supports for our approach is computed by \(1\. The value of constant P was set 0.27*10 6 as mentioned in \(1 The number of association rules along with different number of transactions was extracted for three algorithms and the result is shown in Fig. 2. It’s clear that our proposed method produces equal rules in contrast with the algorithm in [23 in th e i n te rv a l  o f 6 0 0 0  to 8 0 0 0  transactions, but it remarkably produces more rules after 8000 transactions. The reason is that we consider the items characteristics for determining the minimum support and as a result we expect to obtain more association rules It is also clear that the proposed method generates fewer rules in comparison with algorithm in [13 in th e  in te rv a l  of 6000 to 8000 transactions. But, it doesn’t mean that the algorithm in [13 i s b e t t e r t h an o u r ap p r o ach  b e c a u s e t h e minimum supports are specified by an expert user and thus it may lead to better results accidentally. On the other hand, our method has much better result in producing more association rules after 8000 transactions as you can see in Fig. 2   Fig. 2: The number of association rules along with different numbers of transactions 0 10 20 30 40 50 60 70 80 90 6000 7000 8000 9000 10000 Number of association rules Number of transactions The Proposed algorithm in [23 The proposed algorithm The proposed algorithm [13 


Furthermore, the number of association rules along with different values of confidence threshold is shown in Fig. 3. The number of transactions for the three algorithms is constant and equal to 9500. It can be easily seen that the number of rules is decreasing as we increase the confidence threshold value. It is also vivid that the proposed method has much more association rules than the others. In what follows, we will show that our algorithm has also better accuracy in spite of generating more association rules   Fig. 3: the number of association rules along with different values of Confidence threshold  Figure 4 shows the accuracy of algorithms along with different numbers of transactions. The number of transactions is again considered constant and it is equal to 10000. The accuracy means that how much an extracted rule is appeared in our data base transactions. Regarding this definition, our proposed algorithm has much more accuracy in the interval of 8000 to 10000 in contrast with the other two approaches. But, it has less accuracy in comparison with algorithm in [13  a n d t h e s a me accu r a c y  with algorithm in [2   A s  pr e v i o u s l y me n t i one d  t h e  minimum support is determined with an expert user which makes it a difficult task and may sometimes lead to better results   Fig. 4: Accuracy along with different numbers of transactions The Execution times are calculated for the three algorithms and it is shown in Fig. 5. The execution time of the proposed method is equal to its value for the algorithm in [23  b u t i s  le s s th a n its v a lu e fo r t h e  algorithm in [1 i n t h e i n t e r v a l  o f 60 00 t o 8000  transactions. But, the execution time is higher for the proposed method in the interval of 8000 to 10000 transactions as the number of association rules increases For demonstrating the performance of our approach we define a new parameter which is a proportion of total number of rules to execution time. This parameter is called time ratio and is discussed in more details in the next paragraph   Fig. 5: execution time of algorithms  The time ratio along with different values of confidence threshold is obtained for the algorithms and is shown in Fig. 6. Note that the number of transactions is again equal to 10000. As you can see, the proposed method has lower time ratio among the other two approaches. This means that our algorithm has the best overall performance   Fig. 6: time ratio along with different values of Confidence threshold 5. Conclusions When users have stated their mining requirements for frequent itemsets, the term ‘frequent’ has already been a 0 20 40 60 80 100 120 0 0.2 0.4 0.6 0.8 Number of association rules Confidence  threshold The proposed algorithm in [23 The proposed algorihtm The proposed algorithm in [13 0 50000 100000 150000 200000 250000 300000 350000 400000 450000 500000 6000 7000 8000 9000 10000 Accuracy Number of transactions The proposed algorithm in [23 The proposed algorithm The proposed algorithm in [13 0 10 20 30 40 50 6000 7000 8000 9000 10000 Execution time \(second Number of transactions The proposed algorithm in [23 The proposed algorithm The proposed algorithm in [13 0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 0 0.2 0.4 0.6 0.8 Time ratio Confidence threshold The proposed algorithm in [23 The proposed algorithm The proposed algorithm in [13 


threshold from a fuzzy viewpoint. However, existing Apriori-like algorithms still require users to specify the actual minimum-support appropriate to the databases to be mined. Unfortunately, it is impossible to specify the minimum-support appropriate to the database to be mined if users are without knowledge concerning the database On the other hand, even though a minimum-support is explored under the supervision of an experienced miner we cannot examine whether or not the results are really what the users want. In this paper, we have proposed mining algorithm integrates fuzzy set concepts, data mining and multiple level taxonomy to find fuzzy association rules in a given transaction data set and also it consists two phases. First phase, computing minimum supports for each item in database with own features and in the second phase, starting fuzzy multiple level mining algorithm with multiple minimum supports of items for extracting implicit knowledge from transactions stored as quantitative values. Our mining strategy is different from existing Apriori-like algorithms because our mining strategy allows users to specify their mining requirements in commonly used modes and our algorithms automatically earned the specified threshold into actual minimum-support \(appropriate to a database to be mined\. Thus, Our approach have two profits includes computing the minimum support for each item regarding to characteristic for each item in database and making a system automation. To evaluate our approach, we have conducted some experiments. The results have demonstrated the effectiveness and efficiency of our mining strategy References  1  A  M  Wa ng et al Research on Data Mining Algorithms Based on Fuzzy Theory 2008 4th International Conference on Wireless Communications, Networking and Mobile Computing, Vols 1-31 pp. 11660-11663, 2008 2  J  Ha n a n d  M   Ka m b e r   Data Mining: Concepts and Techniques  The Morgan Kaufmann Series, 2001 3  R  Int a n  A n Al g o r i t h m f o r Ge ne r a t i ng S i ngl e  Di m e n s i o na l  F u z z y  Association Rule Mining Journal Informatika vol. 7, pp. 61- 66 2006 4  L  A  Z a d e h   F u z z y  s e t s    Information and Control vol. 8, pp 338- 353, 1965 5  K a n d el   F u zzy ex p e r t  s y s t e m s   CRC Press pp. 8- 19, 1992 6  A   G o n zalez A  lear n i n g  m e th o d o l o g y i n u n cer tai n an d  im p r ecis e  environments international Journal of intelligent Systems vol 10, pp. 357- 371, 1995 7  T  P  Ho ng a n d  J   B  C h e n   P roc e s s i n g i n d i vi d u a l fu z z y a t t r i but e s  for fuzzy rule induction Fuzzy Sets and Systems vol. 112, pp 127- 140, 2000 8  T  P  H o ng et al Trade-off between time complexity and number of rules for fuzzy mining from quantitative data International Journal of Uncertainty Fuzziness and KnowledgeBased Systems vol. 9, pp. 587- 604, 2001 9 S  Z h a n g et al A fuzzy-logic-based method to acquire user threshold of minimum-support for mining association rules International Journal of Information Sciences vol. 164, pp. 1- 16 2004 10  C  Z h a n g a n d S  Z h a n g  A s s o c i a t i on r u l e s  m i ni ng M o d e l s  a n d  algorithms Lecture notes in computer science Springer-Verlag vol. 2307, p. 243, 2002  J   H a n et al Mining top-k frequent closed patterns without mini mum support In Proceedings of the 2002 IEEE international conference on data mining pp. 211- 218, 2002  K   W a ng et al Pushing support constraints into association rules mining Ieee Transactions on Knowledge and Data Engineering vol. 15, pp. 642-658, May-Jun 2003   Y  C L e e et al Multi-level fuzzy mining with multiple minimum supports Expert Systems with Applications vol. 34, pp 459-468, Jan 2008   Y  C L e e et al Mining multiple-level association rules under the maximum constraint of multiple minimum supports Advances in Applied Artificial Intelligence, Proceedings vol 4031, pp. 1329-1338, 2006   R. S r ika n t an d R  A g r a w a l M i n in g g e n e r a l i zed as s o ciatio n r u les   Future Generation Computer Systems vol. 13, pp. 161-180, Nov 1997 16  J  Ha n a n d  Y  F u   D i s c o ve ry of  m u l t i p l e l e v e l a s s o c i a t i on r u l e s  from large databases," in the international conference on very large databases Zurich, Switzerland, 1995, pp. 420- 431  T   P   H ong et al Fuzzy data mining for interesting generalized association rules Fuzzy Sets and Systems vol. 138, pp. 255-269 Sep 1 2003  Y   C   L e e et al Mining association rules with multiple minimum supports using maximum constraints International Journal of Approximate Reasoning vol. 40, pp. 44-54, Jul 2005  B  L i u et al Mining association rules with multiple minimum supports In Proceedings of the international conference on knowledge discovery and data mining pp. 337- 341, 1999  K  W a n g et al Building Hierarchical Classifiers Using Class Proximity Proceeding Very Large Data Bases Conf. \(VLDB pp 363- 374, 1997   H   V a r i a n a n d P   Re s n i c k  R e c om m e n d e r  S y s t e m s I n tr o duc tio n to the Special Section Comm. ACM vol. 40, pp. 56- 58, 1997  R  A g r a w a l et al Database Mining - a Performance Perspective Ieee Transactions on Knowledge and Data Engineering vol. 5, pp. 914-925, Dec 1993  T   P   H o n g et al Mining fuzzy multiple-level association rules from quantitative data Applied Intelligence vol. 18, pp. 79-90 Jan-Feb 2003   T  P  H o ng et al An ACS-based framework for fuzzy data mining Expert Systems with Applications vol. 36, pp. 1184411852, Nov 2009   


represents this naming convention Id  0 IV Editor 0 96 000\000\000 Id  0 F igure 0 H  IV EditorF igure 95 000\000\000 Id  0 IV Editor 0 H  IV EditorF igure 95 000\000\000 Id  0 IV Editor 0  Id  0 F igure 0 The 002rst rule expresses that if a class contains the identi\002er IVEditor it most likely contains Figure as well The other rules express that classes in the hierarchy of IVEditorFigure should follow the naming convention Note that while these three rules have a high con\002dence there exists a single exception to these rules Further inspection of the rules revealed that one class IVEFigureRootCollection  did not obey the regularity and was therefore corrected to IVEditorFigureRootCollection  2 FreeCol Similar to the IntensiVE case study we identi\002ed a number of interesting naming conventions within FreeCol One example is the following group Id  0 Action 0  Im  getID  H  F reeColAction H  F reeColAction  Id  0 Action 0 H  F reeColAction  Im  actionP erf ormed  Id  0 Action 0 H  F reeColAction  Im  shouldBeEnabled  Id  0 Action 0 FreeCol implements a hierarchy of classes that represent user interface actions In addition to the fact that all of these actions belong to the hierarchy FreeColAction  they all share the naming convention that they contain the identi\002er Action in their class name Note that this group does not include a rule that concludes the hierarchy from the identi\002er as this is not the case in the source code For example there exist classes like ActionManager that  while they contains the proper identi\002er  do not implement a user interface action B Complementary methods The second kind of regularity that was identi\002ed by our approach are groups of methods that all contribute to the implementation of a particular concept These rules represent regularities of the form If a class implements a method named M then it should also implement a method named N 1 IntensiVE a Compilation One instance of this kind of regularity that we identi\002ed in IntensiVE was the saving mechanism Crosscutting the entire implementation of IntensiVE there are classes that represent objects that can be compiled To achieve this IntensiVE offers a small framework that is customized by each compilable object Our approach identi\002ed a fairly large group of 21 implication rules that demonstrate the use of this framework Some of the rules that were part of this group are Im  compileF ooterOn   Im  compileDef initionOn  Im  compileCachingOn   Im  save  Im  compileHeaderOn   Im  compileF ooterOn   Im  compileSpecif icsOn  Im  f ullname  Im  save  Im  generateSelector    This regularity describes the set of methods that need to be overridden by an object in order to be compilable If a developer overrides one of these methods then most likely all others should also be overridden b Undo The actions that can be performed within the user interface of IntensiVE are implemented by means of a Command design pattern A subset of these actions are undoable This is indicated in the source code by the fact that these actions implement the method isUndoable  However in such cases the undoable action should also implement the method undoAction that performs the actual undo Furthermore undoable actions are allowed to implement the optional redoAction method in order to perform a redo Our approach identi\002ed a group with two rules hinting at the above regularity Im  isU ndoable  Im  undoAction Im  redoAction  Im  name Im  undoAction 2 FreeCol Within FreeCol we identi\002ed a group that contains a single association rule In particular this group expressed that Im  readF romXM LImpl 96 000\000\000 Im  getXM LElementT agN ame A closer inspection of the source code identi\002ed that FreeCol offers serialization of game objects to XML 002les In order to properly work an object needs to implement both the readFromXMLImpl and getXMLElementTagName methods There were two exceptions to this rule which represent abstract classes that implement readFromXMLImpl  but that require their concrete subclasses to specify getXMLElementTagName  Note that this regularity could not be captured by a Java interface it does not suf\002ce for a class to inherit an implementation of getXMLElementTagName  each class that implements readFromXMLImpl should implement its own getXMLElementTagName method C Interface de\002nitions The third kind of regularity that we identi\002ed are interface de\002nitions These are represented by association rules of the form If a class belongs to hierarchy C then it should implement methods named M and N 1 IntensiVE IntensiVE is implemented in the dynamic language Smalltalk which does not offer the language construct of an interface As such some of the best-documented regularities in IntensiVE are interface de\002nitions Our approach was able to extract some of these interface de\002nitions automatically from the source code For example IntensiVE offers the concept of fuzzy quanti\002ers These are quanti\002ers such as almost all most and many Within the implementation of IntensiVE these fuzzy quanti\002ers have to implement a particular interface to indicate that they are a fuzzy quanti\002er and to calculate their truth degree One of the groups of association rules that was identi\002ed by our approach contained the following implication rule that expresses this interface de\002nition H  F uzzyQuantif ier  Im  crispQuantif ier  Im  holdsW ithT ruth  total  Im  f uzzyDegreeW ithT ruth  total  The above rule describes the exact intent of the regularity in IntensiVE namely that all classes in the hierarchy of FuzzyQuantifier should implement the correct interface 
28 


2 FreeCol The colonization game contains the concept of Locations  the various kinds of tiles in the game such as colonies settlements and so on Internally in the implementation this concept is represented by an interface de\002nition named Location that speci\002es that locations need to provide an implementation for methods getGoodsContainer and getLocationName  While this regularity is therefore explicitly veri\002ed by the Java language itself our approach was able to identify it in the source code More speci\002cally we found a group containing amongst others the following rules H  Location 80 000\000\000 Im  getGoodsContainer H  Location 80 000\000\000 Im  getLocationN ame Notice that this rule has a con\002dence of only 80 because there exist an abstract class in the implementation of FreeCol that delegates the implementation of the methods to its subclasses Our approach did not mine the opposite rule where the implementation of the methods concludes the interface because of the presence of sub-interfaces of Location that require additional methods to be implemented D Discussion 1 Grouping of rules One of the contributions of our approach is the fact that we propose to group rules of which the matches show a signi\002cant amount of overlap In both case studies this grouping of rules offered next to condensing the amount of information that needs to be processed by a developer the added bene\002t of allowing the evaluation of association and implication rules in a particular context Section V-B1a presents an example of this We discussed the regularity that in order to correctly compile an entity that entity's class needs to implement a set of methods This regularity was described by means of a large number of association rules If the association rules would have been inspected individually it would have been easy to miss that all of these rules actually belong together and describe the implementation of a particular concept In other words the groups aid in discovering the intent of a particular regularity by grouping all of its properties 2 Heterogenous versus homogenous groups Most of the identi\002ed groups were heterogenous meaning that the rules in these groups did not exclusively describe a naming convention an interface de\002nition or complementary methods This is not that surprising since our technique groups together rules based on their matches Consequently a group reported by our approach does often not align with a single regularity but rather consists of multiple regularities that are applicable to the same set of entities 3 Finding violations and improvements using the mined rules One of the strengths of association rule mining  which motivated our choice for this technique  is its resilience to deviations in the data set In other words in order for a regularity to be discovered by our approach it is not necessary that this regularity is strictly obeyed throughout the entire source code During our analysis we found that most of these imperfect regularities were caused by the fact that the regularity itself is not always applicable i.e there exist exceptions to the general rule we were also able to identify a number of violations of the regularities For example as we discuss in section V-A1b our approach amongst others identi\002ed a violation of one of the naming conventions within IntensiVE While not discussed above in the FreeCol case study we identi\002ed a refactoring opportunity in the graphical interface where a dedicated subclass of JPanel was used For no apparent reason some classes in the interface did not use this dedicated class but extended the JPanel class directly 4 Choice of properties and in\003uence on mined regularities Since it was our goal to demonstrate the feasibility of our approach for now we restricted our analysis to classes and opted to only include three simple properties of classes As a consequence the different kinds of regularities that can be discovered based on these properties is rather limited We can observe that most of the reported rules describe the vocabulary that is used in the application While this provides interesting information regarding the application for example to novice developers a wide range of regularities are currently not mined by our approach For example calling relationships usage of particular classes framework specialization constraints and so on are not found We plan further experimentation where we will not restrict our analysis to classes but also include methods Furthermore we will investigate the use of properties such as calling relationships method overrides typing information and statement ordering 5 Amount of manual effort Possible scalability issues of our approach are not caused by the complexity of computing the actual association rules but rather by the manual analysis of the resulting groups While our approach aims at minimizing the amount of effort that needs to be invested by a developer by extensive 002ltering and grouping of rules it still requires a considerable effort to extract the rationale behind the grouping In order to identify the intent of a group a developer needs to inspect the various rules in that group along with the source code entities that match the rule and the exceptions to this rule Especially in the case of an unfamiliar system this can be time consuming Although such a manual analysis has to be performed only once for a particular system we plan to further circumvent this problem in future work by allowing the mining and analysis to be done in a more incremental way during the development process We envision a tool that extends a standard IDE in such a way that when browsing a particular source code entity the developer is also shown the groups and association rules in which this source code entity is involved either as a match to a rule or as a deviation This way a manual post-processing step of the results of our approach is no longer necessary but the analysis can be done incrementally during development 6 Correctness of the results From a technical point of view all rules mined by our approach are correct with respect to the system that is analyzed Nevertheless without the 002ltering that is offered by our approach the use of association rule mining can still result in a large number of trivial 
29 


rules Since we restrict our rules to those that are supported by a suf\002cient number of matches and that exhibit a high con\002dence and low degree of error we are able to prune a signi\002cant number of these trivial rules This however does not provide any insights into the quality of the mined results from a usability perspective are the groups of rules identi\002ed by our tool of interest to developers While we were able to identify interesting regularities in both case studies such an analysis of the usefulness of our approach is highly subjective In future work we will validate our approach by mining for regularities in a number of open-source systems and involve the original developers of these systems in a user study 7 Comparison with known regularities in IntensiVE For the IntensiVE tool a fairly large number of regularities were already documented While our approach was not able to 002nd all of these regularities due to restricted scope of our experiment we were able to identify a majority 10 out of 15 of the documented naming conventions complementary methods and interface de\002nitions For example the compilation scheme the undoable actions and the quanti\002er naming convention discussed above were all documented already using the IntensiVE tool Furthermore eight interesting regularities such as the fuzzy quanti\002er interface and part of the user interface protocol were identi\002ed by our approach but were not previously documented Our approach however failed to identify the naming conventions and interface de\002nitions related to the implementation of a Factory design pattern within IntensiVE The reason for this is the fact that due to the small number of classes that have to respect these regularities association rules that involved the classes implementing the factory were removed from the result by our pruning 002lters 8 Choice of thresholds Our approach can result in false negatives as consequence of the aggressive 002ltering scheme where we expect at least 4 matches for the rule a con\002dence of 70 and a degree of error lower than 45 While this 002ltering strategy allows us to limit the amount of noise it can result as illustrated in the previous point that certain interesting regularities are 002ltered out First our choice for expecting at least 4 matches for a rule was inspired by the observation that a lower threshold would include casual correlations of properties therefore increasing the amount of noise produced by our approach Second we experimented with different con\002dence and degree of error thresholds Both these thresholds have an impact on the number of entities that get reported by our tool and were determined after experimentation For example using a con\002dence threshold of 50 on the IntensiVE case study only resulted in 40 more association rules and 2 extra groups However we observed that this lower threshold resulted in the introduction of random association rules in the groups that were caused by seemingly unrelated properties Although the con\002dence of these rules was higher than the threshold both condition and conclusion exhibited a large number of exceptions Similar observations can be made for the degree of error While a lower degree would result in less groups/rules and a number of interesting regularities would be eliminated too high a degree of error would allow for rules that are too generic coincidental While experiments resulted in the same thresholds for both case studies this does not imply that these thresholds are optimal for the analysis of any system We hypothesize that since the size of both systems is similar the same thresholds yielded satisfying results in spite of the fact that the systems were written in different languages VI R ELATED WORK A Approaches using association rule mining Our work is not the 002rst one to propose the use of association rule mining for extracting knowledge from source code For example Michail uses association rules to mine library reuse patterns library components that are reused together Similar to our approach this work analyzes classes and basic relationships between these classes Furthermore this approach also proposes some heuristics to 002lter rules that are not adding information Thummalapental and Xie mine association rules obtained from exception handling code The association rules that are obtained by their approach are composed of sequences of method calls that occur together Bruch et al propose the use of frequent itemset analysis and association rule analysis to remove irrelevant recommendations in code completion PR-Miner by Li and Zhou use association rules to identify violations to correlations between function calls Similar to our approach they offer a grouping mechanism theirs is based on the antecedent of the rules The above approaches are similar to our approach in that they use the same mining technique and similar input data However the nature of the problem tackled differs While previous approaches aim at 002nding accurate examples or detecting exceptions we aim at presenting the mined association rules in a condensed format to ease the interpretation of the rationale behind these rules Therefore the 002ltering and grouping strategies we propose differ from previous ones B Mining for structural regularities There are several approaches specialized in mining certain types of source code regularities For instance aspect mining techniques look for frequent scattering patterns ho wever these approaches tend to be dif\002cult to interpret and intolerant to exceptions Another set of approaches has been proposed to detect features i.e the implementation of user-perceivable functionality However feature detection is generally based on data that is dif\002cult to extract such as vectors of words that characterize source code entities and data and control 003ow relations 20 Other feature identi\002cation techniques rely on traces 7 22 which require intense 002ltering to separate the calls to auxiliary methods from those that indeed implement the feature Furthermore there are several approaches to mine for API usages 23 24 25 ho we v er  the results tend to be very low-level implementation rules which are dif\002cult to interpret as domain/application speci\002c rules Finally there are approaches that aim at extracting domain/application design rules such as ne v ertheless the scalability of this approach 
30 


is limited To summarize in comparison to our approach previous regularity mining approaches tend to be specialized for a single type of regularity while our approach would 002nd as many and diverse regularities as properties analyzed In contrast to the approaches presented ours is a lightweight approach which is resilient to exceptions and provides hints to interpret the rationale of the results VII C ONCLUSIONS Structural source code regularities such as idioms naming conventions interface de\002nitions play an important role in easing software maintenance and evolution Unfortunately such regularities are often only implicitly known and not documented Furthermore automatic extraction of such structural regularities from source code is not a trivial task due to the overwhelming amount of information that mining techniques might present a user and the inherent presence of exceptions to the structural regularities in the source code In this paper we have presented a novel approach for mining such regularities that is based on association rule mining The contributions of our approach are 1  Resilience to exceptions in the source code due to the nature of the applied association rule mining technique 2  A comprehensible representation of the mined rules due to an elaborate post-\002ltering and grouping of rules 3  An intentional description of the mined regularities due to the fact that we mine for relations between properties of source code entities and not between the actual entities As a proof-of-concept of the feasibility of our approach we have applied it to two open-source systems one in Smalltalk and one in Java Despite the fact that we only considered three simple properties of the analyzed classes identi\002ers implemented methods inheritance relationships our qualitative analysis of the resulting groups of association rules indicated that our approach is able to discover interesting structural source code regularities Currently we are extending the experiment to methods and relations between those methods A CKNOWLEDGEMENTS This work has been performed under the scope of the MinDeR bilateral project sponsored by MINCyT Argentina and FWO Flanders Angela Lozano is funded by the ICT Impulse Programme of the Institute for the encouragement of Scienti\002c Research and Innovation of Brussels ISRIB Andy Kellens is funded by a research mandate provided by the Institute for the Promotion of Innovation through Science and Technology in Flanders IWT Vlaanderen This work has also been supported by the Interuniversity Attraction Poles IAP Programme of the Belgian State  Belgian Science Policy R EFERENCES   K Bennett and V Rajlich Software maintenance and evolution a roadmap in The Future of Software Engineering  2000 pp 73–87   T Matsumura A Monden and K Matsumoto The detection of faulty code violating implicit coding rules in Workshop on Principles of Software Evolution  2002   K Gallagher and J Lyle Using program slicing in software maintenance IEEE Trans Softw Eng  vol 17 no 8 pp 751–761 1991   K Chen and V Rajlich Case study of feature location using dependence graph in Intl Workshop on Program Comprehension  2000 pp 241–247   M Robillard and G Murphy Concern graphs 002nding and describing concerns using structural program dependencies in Intl Conf on Software Engineering  ACM 2002 pp 406–416   K Mens I Michiels and R Wuyts Supporting software development through declaratively codi\002ed programming patterns Elsevier Journal on Expert Systems with Applications  vol 23 no 4 pp 405–431 2002   T Eisenbarth R Koschke and D Simon Locating features in source code IEEE Trans Softw Eng  vol 29 no 3 pp 210–224 2003   R Agrawal T Imielinski and A Swami Mining association rules between sets of items in large databases in Intl Conf on Management of Data  ACM SIGMOD 1993 pp 207–216   J Han and M Kamber Data Mining Concepts and Techniques  Morgan Kaufmann 2000   B Ganter and R Wille Formal Concept Analysis Mathematical Foundations  Springer Verlag 1999   E Gamma R Helm R Johnson and J Vlissides Design Patterns Elements of Reusable Object-Oriented Software  1995   J Maletic and A Marcus Supporting program comprehension using semantic and structural information in Intl Conf on Software Engineering  IEEE/ACM 2001 pp 103–112   A Michail Data mining library reuse patterns using generalized association rules in Intl Conf on Software Engineering  ACM 2000 pp 167–176   S Thummalapenta and T Xie Mining exception-handling rules as sequence association rules in ICSE 09 Proc of the 2009 IEEE 31st International Conference on Software Engineering  Washington DC USA IEEE Computer Society 2009 pp 496–506   M Bruch M Monperrus and M Mezini Learning from examples to improve code completion systems in European Software Engineering Conf and the symposium on the Foundations of Software Engineering  ACM 2009 pp 213–222   Z Li and Y Zhou Pr-miner automatically extracting implicit programming rules and detecting violations in large software code in European software engineering conference/International symposium on Foundations of software engineering  ACM 2005 pp 306–315   A Kellens K Mens and P Tonella A survey of automated code-level aspect mining techniques Transactions on Aspect-oriented Development TAOSD  2007   K Mens A Kellens and J Krinke Pitfalls in aspect mining in Working Conf on Reverse Engineering  IEEE 2008 pp 113–122   A Marcus and J Maletic Recovering documentation-to-source-code traceability links using latent semantic indexing in Intl Conf on Software Engineering  2003 pp 125–135   B Dagenais S Breu F Warr and M Robillard Inferring structural patterns for concern traceability in evolving software in Automated Software Engineering ASE  ACM 2007 pp 254–263   N Wilde M Buckellew H Page and V Rajlich A case study of feature location in unstructured legacy FORTRAN code in European Conf on Software Maintenance and Reengineering  2001 pp 68–76   G Antoniol and Y Gu  eh  eneuc Feature identi\002cation A novel approach and a case study in Intl Conf on Software Maintenance  2005 pp 357–366   C Williams and J Hollingsworth Automatic mining of source code repositories to improve bug funding techniques Transactions on Software Engineering  vol 31 no 6 pp 466–480 2005   T Xie and J Pei MAPO Mining API usages from open source repositories in Mining Software Repositories  ACM 2006 pp 54–57   H Kagdi M Collard and J Maletic An approach to mining call-usage patterns with syntactic context in Intl Conf on Automated Software Engineering  2007 pp 457–460   P Lam and M Rinard A type system and analysis for the automatic extraction and enforcement of design information in European Conference on Object-Oriented Programming  Springer 2003 pp 275–302 
31 


14] Ji exunLi, GuoqingC hen. "ASAR-based interesting rule mining algorithm" [J].Fuzzy Information Processing Society, 2002 Proceedings.N AFIPS.2002 Annual Meeting of the North American 2002,pp. 178-183 12L IS] J. Han, J. Pei, and Y. Yin, "Mining Frequent Patterns without Candidate Generation," Proc. ACM-SIGMOD Int'l Coni Management of Data, pp. 1-12, May 2000 16] Vaarandi Risto ,"A Breadth-First Algorithm for Mining Frequent Patterns from Event Logs ",Department of Computer Engineering Tallinn University of Technology 


Why Data Mining  N ecessit y is the mother o f inventio n yf Huge Datasets Tera to Peta bytes multi dimensional distributed interrelated semi structured and rapidly growing Requirements Exploratory analysis mining hidden novel patterns knowledge driven analysis Associative IDS for NextGen Frameworks Dr S Dua LA Tech 12 


KDD Process Classification Classification Classifying or predicting Clustering Clustering Finding new classes Feature Selection  Extraction Feature Selection  Extraction Finding the features most strongly Classifying or predicting outcomes based on patterns/behavior in data Finding new classes or refining existing ones Finding the features most strongly related to a particular class Preprocessing Selection Initial Data Target Interpretation Data Transfor Data Mining Pre Processed Transformed Data Model Preprocessing Selection Initial Data Data Interpretation Transfor mation Data Mining Data Data Model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 13 


Dimensionality Reduction Challenges Dimensionality Reduction Challenges Noise Sall la ge oble S ma ll n l ar g e p pro bl em Multidimensional Mapping Estimating Information Loss Gain Ubl d Dt t Dimensionality Reduction F eatu r e Ex t r act i o n U n b a l ance d D a t ase t s Validation through Post Data Mining Cl t i F idi bi l i l l fi i Feature Extraction Feature Selection Cl us t er i ng F i n di ng new bi o l og i ca l c l asses or re fi n i ng existing ones Classification Classifying diseases or predicting outcomes based on gene expression patterns Associative IDS for NextGen Frameworks Dr S Dua LA Tech 14 


Aiti l i dt ii A ssoc i a ti on ru l e i n d a t a m i n i ng Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 15 


Introduction to Association Mining Introduction to Association Mining Association rule mining is a data mining application to extract patterns Reveals interesting relationships called associations in a potentially large database Example Supermarket checkout information about customer purchases used to measure customer purchasing behavior customer purchasing behavior  Evaluation of this information can help retailers devise more efficient and personalized marketing strategies Association Rule Example Milk Beer  Diapers Find all the rules X Y with minimum support and confidence Support  s probability that a transaction contains X and Y Confidence  c conditional probability that a transaction Associative IDS for NextGen Frameworks Dr S Dua LA Tech 16 Image Source budlight.com pampers.com 


Associations as Higher Order Associations as Higher Order Features Hypothesis Associative relationships among features have more discriminatory power than individual/raw features Goal Use these associative relationships for supervised learning classification  Specific Aims Represent associative relationships as features  higher order features Challenges Challenges Not as straightforward as regular classification Rules to higher order feature transformation Rules to higher order feature transformation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 17 


Higher Order Classification Higher Order Classification Extracting Association Rules Each instance represented as idiid ld b Build a new feature space from these rules i n di v id ua l d ata b ase rules Use these higher order features for classification with existing classifier Raw Features Query Instance Query Instance Class Label Features Classifier Extract Rules Rule R epresentation New Feature Space Classifier R epresentation Rules to Higher order Feature Representation Schema Associative IDS for NextGen Frameworks Dr S Dua LA Tech 18 


Aiti T A ssoc i a ti on T ypes Basic Association Rules Enhanced Inter Transaction Association Rules Complex Spatio Temporal Association Rules 19 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 19 


Basi Association Rles Basi c  Association R u les Association is basically connecting or tying up occurrences of Association is basically connecting or tying up occurrences of events Ol dib t f ilt t O n l y d escr ib e se t s o f s i mu lt aneous even t s Cannot describe patterns that iterate over time e g  itemset a  0  b  0  g    Eg If you sense higher data rates on the downlink than normal AND New Route generated Implies high chances of Intrusion AND New Route generated Implies high chances of Intrusion Associative IDS for NextGen Frameworks Dr S Dua LA Tech 20 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



Gene-set Cohesion Analysis Tool \(GCAT\ a Literature Based Web Tool for Calculating Functional Cohesiveness of Gene Groups Lijing Xu, Ramin Homayouni Bioinformatics Program The University of Memphis Memphis, TN e-mail lijingxu@memphis.edu Nicholas A Furlotte Computer Science Department University of California Los Angeles, CA Kevin E. Heinrich Computable Genomix LLC Memphis, TN E. Olusegun George Department of Mathematics The University of Memphis Memphis, TN Michael W. Berry Department of Computer Science University of Tennessee Knoxville, TN Abstract Numerous algorithms exist for producing gene sets from high-throughput genomic and proteomic technologies However, analysis of the functional significance of these groups of genes or proteins remains a big challenge. We developed a web based system called Gene-set cohesion analysis tool \(GCAT\timating the significance level of the functional cohesion of a gi ven gene set. The method utilizes Latent Semantic Indexing LSI\ene-gene literature similarities to determine if the functional coherence of a gene set is statistically significant compared to that expected by chance. The robustness of the method was determined by evaluating the functional cohesion for over 6000 Gene Ontology categorie s. Here, we demonstrate the utility of GCAT for analysis of microarray data from previously published experiments in which embryonic fibroblasts were treated with interferon. Using GCAT, we found the highest literature cohe sion p-value \(p= 1.37E-63 corresponded to a set of genes that were differentially regulated > 2-fold and had a t-test p-value <0.05, compared to genes that were only changed >2-fold \(literature pvalue=2.2E-44\or had a p-value <0.05 \(literature pvalue=6.0E-32\s a control, gen es that were changed less than 2-fold or had a p-value >0.05 did not show a significant literature cohesion. These results demonstrate that GCAT can provide an objective literature-based measure to evaluate the biological significan ce of gene sets identified by different criterions. GCAT is available at http://motif.memphis.edu/gcat Genomics, Text-mining, Microarray 


  2 Software errors are also among the highest risks that could potentially lead to a loss of the Space Shuttle, where software errors continue to be discovered in Space Shuttle flight control software.  Since the Shuttle started operation in 1980, sixteen Critical-1 so ftware errors have been discovered in the released software. These problems occurred despite NASA having one of the most thorough and sophisticated software development and verification processes in existence The risk of software errors can be reduced through automated software verification and validation using formal methods This research has evolved two formal method approaches for automated software verification and validation model checking and static analysis, with extensions of the approaches for multiple languages including Java, C and C++.   These methods are used to reduce risks in various phases of the software life-cycle   Requirements Validation of software requirements with consistency and completeness checks to detect missing or ambiguous requirements    D esign Detection of software design errors by testing c onformance of design to requirements including detection of component interaction errors through component integration testing    Implementation Detection of software coding errors through runtime error checking, conformance testing of implementations to requirements and design, and detection of implementation-specific errors such as timing, memory usage and performance This paper describes two of the formal methods tools we are using for verification of aeros pace software. The first one called Java PathFi or JPF, i s  a m odel  checker for Java programs. The second one, called C Global Surveyor 4,5 o r CGS, is a static analyzer for C programs. The subsequent sections of this paper will describe the technical approach used in these two tools, followed by case examples of their applicati on to aerospace systems, and conclusions 2  J AVA P ATH F INDER  Java PathFinder \(JPF\an an alysis tool that can perform software model checking on Java programs. Since its inception, it has been extended with capabilities to perform symbolic execution, model check ing of Statecharts, and to deal with user interface issues This section presents an overview of model checking and JPF in layman’s terms Model checking Model checking is a technique that was invented for formally verifying communication protocols expressed as finite state systems [9 strated in Fig u r e 2  th is is achieved by verifying that a logical property \(derived from the requirements\s a model of the system being checked i.e., a model derived from the design phase or by abstraction of the code, or, the code itself property is said to be satisfied by the system. Properties are often expressed as temporal logic formulas, but simple assertions can also be checked In practice, assertions are easier to check than temporal properties, even though they require annotating the system under test with assert statements Explicit state model checking \(which is what we are using in this work\ses an explicit representation of the system's global state graph, usually given by a state transition function. An explicit state model checker evaluates the validity of temporal properties over the model by exploring all state transitions \(which are roughly equivalent to program statements in software model checking\Property validation amounts to a partial or complete exploration of the state space  Figure 2. Model checking process An important characteristic of explicit-state model checking is that it explores systemati cally every reachable state from the root. If one considers the example of a sequential program, this corresponds to a trace through the system. If one considers a multi-threaded program \(as in Figure 3 then it corresponds to exploring all the possible interleavings of the threads in the program as well as all the possible numerical values for unbounded \(or restricted to a range of\nputs 


  3 Figure 3. The exploration process Traditionally, the search follo ws a depth-first-search pattern. However, there have been attempts at using different search strategies including breadth-first-search and some based on heuristics Lastly, linear temporal logic properties are the properties most often checked by exp licit-state model checkers Temporal logic properties express temporal properties over an execution trace. Temporal ope rator can express the fact that   something always happens in a trace   something happens next in a trace, and   something will eventually happen in the trace This allows a user to expre ss properties such as “Always after p there is eventually q This particular example is interesting since it corresponds to a response property which is often used in specification for embedded systems especially in control\. In practice, users have problems expressing specification in Lin ear Time Logic \(LTL often explicit-state model ch eckers are used to verify assertions \(at some program point\ems due to multi-threading \(deadlocks race conditions, and so on The JPF model checker As mentioned previously  i s  an expl i c i t st at e m odel  checker loosely based on the SPIN model checker In SPIN, the Promela language is used to specify the model; it therefore requires a transla tion pass to check software programs   However, several approaches have been designed recently to make explicit-state model checking work directly on code. In our case, JPF is a model checker that works directly on Java bytecode. In JPF, as shown in Figure 3, the bytecodes of the program describe the state transitions, the state being defined by the actual state of the program at each program point \(o r by an abstraction of this state Figure 4 illustrates the JPF process from a user’s point of view. The user defines three elements 1  a set of data abstractions, which are used to make the model checking problem more scalable 2  a virtual machine \(VM definition of the property being checked during exploration 3  a set of scheduling decision, which defines data ranges that need to be explored as well as the scheduling of threads These three elements are then plugged into the JPF virtual machine \(JPF-VM\ilar to a regular Java virtual machine, except that it has the capacity of choosing its own scheduling, memorizing states, and a few other features necessary for the mode l checking process. The user also needs to indicate a search strategy \(e.g., depth first breadth first, or others\his is done, JPF starts exploring paths until it hits a violation of the property being checked. The path leading to th e error is then recorded and displayed as a trace through the program to the user. Note that JPF accepts bytecode as inputs \(and not the Java source files\ allows for the exploration of libraries used by the code. Of course, one might choose to give abstractions for these libraries so that the state space stays relatively small JPF extensions JPF has been extended so that it can go beyond its original purpose \(i.e., model checking Java programs\e are describing some of these extensions The Constellation program at NASA is in charge of the development of Orion \(Crew Exploration Vehicle Cargo Launch Vehicle\issions have selected a model-based development process for software. This means that software systems are first designed using models \(often Statecharts or Starcharts-lik e models\hen code is generated from the models. So, it is important for NASA to have the ability to check Statecharts models, and therefore JPF has been extended to deal with Statecharts. Since these models will often be incomplete, JPF also offers the user the 


  4 possibility of defining scripts that restrict the exploration to some specific region of the models. This JPF feature is used in the work described in  JPF also offers a symbolic execution capability. Symbolic execution manipulates symbolic representation of variable values instead of concrete values during state exploration This gives the user the ability of gathering constraints on the inputs and decision points chosen during the exploration of a given path. These constraints can then be used to generate test cases automatically 3  C  G LOBAL S URVEYOR  C Global Surveyor \(CGS atic program analyzer for C programs. CGS can analyze C software and identify memory corruption errors su ch as buffer overruns, out-ofbound array accesses, or null point er de-references. It has been shown to scale up to 540 thousands lines of code KLOCs Static analysis The goal of static analysis is to assess code properties without executing the code. Several techniques can be used to perform static analysis, such as theorem proving, data flow analysis  const r ai nt sol v i ng [8  and abst ract  interpretation [9,10  In  th is p a p e r we p r esen t CGS wh ich is based on abstract interpretation The theory of Abstract Interpretation pioneered by Patrick and Radhia Cousot in the mid 70's provides algorithms for building program analyzers wh ich can detect all runtime errors by exploring the text of the program  The program is not executed and no test case is needed. A program analyzer based on Abstract Interpretation is a kind of theorem prover that infers properties about the execution of the program from its text \(the source code\and a formal specification of the semantics of the language \(which is built in the analyzer undamental result of Abstract Interpretation is that program analyzers obtained by following the formal framework defined by Patrick and Radhia Cousot are guaranteed to cover all possible execution paths. Runtime erro rs are errors that cause exceptions at runtime. Typically, in C, either they result in creating core files or they cau se data corruption that may cause crashes The price to pay for exhaustive coverage is incompleteness the analyzer can raise false alarms on some operations that are actually safe. However if the analyzer deems an operation safe, then this property holds for all possible execution paths. The program analyzer can also detect certain runtime errors which occur every time the execution reaches some point in the pr ogram. Therefore, there are basically two complementary uses of a program analyzer   as a debugger that detects runtime errors statically without executing the program   as a certification tool which identifies safe areas of the code and regions with poten tially dangerous operations that have to be checked by a traditional validation process \(code reviewing, test writing, and so on For the second use the tool should achieve a good selectivity - the percentage of operations which are proven to be safe by the program analyzer. Indeed, if 80% of all operations in the program are marked as potentially dangerous by the analyzer, there are no benefits to using such technique. Figure 5 shows the place of static analysis in the software development lifecycle  Figure 4: The JPF model checking process 


  5 Figure 5. Static analysis in the SW development lifecycle  CGS overview CGS is a static analyzer for C programs. Actually, CGS has been tuned for embedded systems, such as those used or developed at NASA. In practice, CGS works like a smart compiler; it   parses the source code   creates a call graph of all the routine calls in the program   computes a control flow graph \(CFG\each of the routines in the program \(not e that a CFG represents all possible branching, like loops and if-then-else statements, in a program   defines numerical equati ons for each of the nodes which corresponds to program statements\n the CFGs to represent memory accesses \(start and length of the memory region being accessed and indices within this region   solves these equations, first the routine level, and second at the program level   computes safety reports for each operation in the program Figure 6. Static analysis vs. testing  So, the results of an analysis by CGS is a report classifying each operation into being safe \(all the time\unsafe \(in in some contexts that may be un-realizable\6 compares static analysis to traditional testing. The main difference is in the exhaustive coverage of static analysis for some error classes \(runtime errors\sure that all possible executions have been covered. In sound and complete \(as in CGS\alysis, one obtains an accurate picture of the safe, unsafe and potentially unsafe regions Extension to C CGS was created to analyze C programs. So far the flight software for most NASA missions has been developed in C However, C++ is being introduced both into flight and ground software. Therefore, we are developing a version of CGS that will be able to analyze C++. Furthermore, we will complement the C++ static an alyzer with a model checker MCP\mbolic execution engine \(TPGEN\e that prototypes already exis t for MC and TPGEN. All tools will be developed on top of the low-level virtual machine \(LLVM\ framework, which is an open-source framework for designing C++ analysis tools 4  C ASE E XAMPLES  In this section, we briefly describe some of the examples we have analyzed with JPF and CGS. They span a wide spectrum of aerospace applications ranging from space Mars missions, Space Shuttle, International Space Station to aeronautics examples DEOS example DEOS is a portable micro-kernel-based real-time operating system used at Honeywell fo r the Primus Epic avionics product line. It supports flexible, integrated modular 


  6 avionics applications by pr oviding space partitioning at the process level and time partitioni ng at the thread level. Space partitioning ensures that no process can modify the memory of another process without au thorization. Time partitioning ensures that a thread access to its CPU time budget cannot be impaired by actions of any other threads. These partitioning capabilities are important since they provide the ability for applications to shar e the same hardware without interfering with each other In DEOS, time partitioning is enforced by using the traditional rate monotonic scheduling \(RMA\In RMA, the threads with the most stringent real-time requirements have highest priorities. In theory, RMA guarantees that all threads can be scheduled if the sum of their utilities \(i.e., the ratio of computing time by the scheduling period\s below a certain threshold Our experiment consisted of fi rst translating the DEOS code from C++ to Java so that we could use JPF. It resulted in a Java program of 1400 lines with 20 classes and 6 threads. In order to analyze the kernel itself, additional code was written to simulate the behavior of user applications and the hardware environment. The re quirement was encoded as a method that observed the states of the kernel and asserted that budgets were allocated in each scheduling unit. The calls to this method were inserted whenever the kernel schedules an application process Then, we ran JPF until a d eadlock was reached. This deadlock is a real error that Honeywell had found after many analysis hours. They did not tell us where or what the error was. Fortunately, JPF found the error, but not at the first try. First, JPF ran out of memory; the state space being explored was too large. We therefore performed a sign abstraction on some of the integer variables in DEOS and re-ran the analysis. The sign abst raction abstracts values to their sign \(positive, negative, or zero\. Thus, it can abstract an unbounded value range to a range with three values. This abstraction was critical to allowing us to find the error Mars mission flight software The MPF \(Mars PathFinder\ily consists of flight software systems that were developed based on the flight software system for the Mars PathFinder mission They were re-used in the Deep Space One and Mars Exploration Rover \(MER\issions. We used this software family as a tune-up for CGS. Results are described in details    From a static analysis point of view, the three systems are quite similar since they use th e same \(object-oriented even though they were developed in C\ software architecture as well as some modules \(such as the quaternion library\For example, all systems are multi-threaded and they use the threading package of VxWo rks. Communication between threads is done using message queues. Even though messages are quite complex \(e.g., they contain not only data but also references to callback replies into arrays of integers. Thus, in some cases, the analysis loses information about for example the call flow, or the sizes of matrices passed from one module to the next. This was a major source of imprecision in our analyses. Another important factor is the size of these applications. Overall the increased complexity of the missions was reflected in the size of each application. As Table 2 shows, the size ranges from 140 KLOCs to 540 KLOCs and the number of threads increased from 23 to more than one hundred in MER Table 2. Software complexity for MPF family MPF DS1 MER Size \(in KLOCs 140 280 540 threads 23 40 100  The results for the MPF family were very good. This is not surprising since we design CGS to work well for this family. In fact, we used th e MPF and DS1 software as testbeds during the development of CGS. Overall, we obtained about 85% precision \(the percentage of checks that are classified with certainty as correct, incorrect, or unreachable\The average running times were about 1.5 hours for MPF and about 3 hours for DS1. The analysis of MER took much longer \(about 24 hours\There are two major reasons for that. First, the sheer size of MER \(540 KLOCs\s a big factor. The second reason for the slow response times lies in the imprecision of our alias analysis International Space Station examples The application of CGS to flight software for the shuttle and the International Space Station \(ISS technology infusion effort  W e anal y zed fi ve m odul es 1  The Application Processor \(AP\odule is part of the flight software for the Advanced Video Guidance Sensor \(AVGS as experiments on two Space Shuttle missions and will be the primary sensor for the close-proximity operation in the DART mission. The DART mission seeks to advance the state of the art in safe and reliable autonomous rendezvous capabilities at NASA. The AP module represents about 12 KLOCs of C code 2  The IO Processor \(IOP\odule is also part of the AVGS. It represents 7 KLOCs of C code 3  The goal of the Materials Science Research Rack MSRR\oard the ISS is to offer capabilities to facilitate a wide range of materials science investigations. For example, the facility will provide the common subsystems and interfaces required for the 


  7 operation of experiment hardware, accommodate telescience capabilities, and provide the capability for simultaneous on-orbit processing. This application consists of 55 KLOCs of C code 4  The Urine Processor Assembly UPA life support in the ISS. The UPA controller consists of 47 KLOCs of C code 5  Finally, the last module is the boot loader BOOTLDR\for the shuttle engine controller. It consis of 7 KLOC of C code. The MSFC development team is also in the proce ss of using static analyzers including CGS\o analyze the whole controller However, we do not have re sults for this experiment The analysis response times of these analyses were quite satisfying. Each analysis was only a matter of minutes on laptop \(i.e., machines that are slower and have less memory than the desktops we use fo r the analysis of the MPF family\Second, the precision was quite good \(around 85 On-board abort executive for CEV This section describes how we analyze the On-board Abort Executive \(OAE\JPF. Once again OAE was written in C and therefore we first had to translate it into Java. Fortunately, OAE is a small piece of software \(about 650 lines of code\plexity of OAE does not come from its size, but from the combination of abort conditions covered by th e software. This makes OAE difficult to validate by hand, hence, our use of JPF Actually, we did not try to model check OAE. Our goal was to show that we can use JPF \(and its symbolic execution capability\ generate test cases that cover all abort conditions, thus providing an unusual coverage criterion i.e., abort statement coverage We have generated 131 test cases that provide full coverage for all single flight rule failures in OAE. The first OAE prototype that we analyzed is only designed to handle single flight rule failures NASA's Guidance, Navigation, and Control group at Johnson Space Center used these test cases to identify some significant bugs in OAE, which resulted in rewrites of parts of the OAE code.  We are now analyzing the latest version of OAE \(with multiple faults test cases for that code. Results are not available at time of writing 5  C ONCLUSIONS  Formal method approaches for automated software verification and validation model checking and static analysis for Java, C and C++ are increasingly being utilized to improve software quality assurance in human-rated missions.  These methods have been successfully used on a number of aerospace applica tions ranging from space \(Mars missions, Space Shuttle, International Space Station\to aeronautics examples.  Software quality assurance is improved through creation of comprehensive test cases and identification of faults; as well as through reduced software development costs through automation of testing with increasingly higher precision ra tes reaching 85%.  Future work will continue to not only improve the performance of formal methods \(e.g., coverage, precision, speed scalability\ut also to improve the ease of use making such techniques a routine software quality assurance technique used in aerospace software development projects A CKNOWLEDGEMENTS  The work described in this paper was conducted by a team of computer scientists and software engineers in the reliable software engineering groups of the USRA Research Institute for Advanced Computer Science and the Intelligent Systems Division of the NASA Ames Research Center This paper is based upon work supported by NASA under awards NCC2-1426 and NNA07BB97C R EFERENCES    W  Vi sser, K. Havel und, G. B r at S. Park and F Lerda Model Checking Programs.” Automated Software Engineering Journal,volume 10, number 2, April 2003  G.J. Hol z m a nn, “The SPIN  M odel  C h ecker Addi sonWesley, 2004   S Thom pson G. B r at The M C P M odel C h ecker submitted to PEPM’08  Bound Checking for Large Embedded C Programs International Conference on Programming Language Design and Implementati on Proceedings, 231–242, 2004  G. Brat and A. Venet, “Preci se and scalable static program analysis of NASA flight softwa re”. In Proceedings of the 2005 IEEE Aerospace Conference, Big Sky, MT, 2005  G. B r at and W  Vi sser , “C om bi ni ng St at i c Anal y s i s and Model Checking for Software Analysis,” Proceedings of ASE2001. San Diego, November 2001  W  Landi Int erprocedural Aliasing in the Presence of Pointers Ph.D. thesis Rutgers University, 1992   A Ai ken and M  Fähndri c h, “Program Anal y s i s usi ng Mixed Term and Set Constraints”. In Proceedings of the 4 th International Static Analysis Symposium SAS’97 1997  P. C ousot and R  C ousot  St a t i c  Det e rm i n at i on of Dynamic Properties of Programs”. In Proceedings of 2 nd  International Symposium on Programming pages 106130, 1976 


  8  P. C ousot and R  C ousot Abst r act Int e rpret a t i on  a Unified Lattice Model for Static Analysis of Programs by Construction or Approximation of Fixpoints”. In Proceedings of 4 th Symposium on Principles of Programming Languages pages 238-353, 1977   E.M  C l arke, O. Grum berg, and, D.A. Pel e d, “M odel  Checking”. MI  G B r at  M   Gheorghi u D. Giannakopoulou, “Verification of plans and procedures,” submitted to IEEE Aerospace’08   G B r at M  Gheorghi u, D. Gi annakopoul ou Verification of plans and procedures,” submitted to IEEE Aerospace’08  Hergert  Paul M i ssi on Anom al y Dat a base \(1986  2004\elease Four," Prepared for the NASA Engineering for Complex Systems Program, April, 2004   B IOGRAPHY  Dr. David Bell is Director and Senior Scientist at the Research Institute for Advanced Computer Science, located at the NASA Ames Research Center Prior to working at NASA, David worked for ten years at the Xerox Palo Alto Research Center, and previously held an appointment at MIT where he led a research program in the Center for Innovation in Product Developmen t.  David is co-inventor of multiple patent and patentpending information system technologies, including XML query technologies related to NETMARK and the NASA Program Management Tool, and extensible blog technology called Sparrow Web; as well as co-inventor of distributed knowledge management software called Eureka.  David received his Ph.D. from Cornell University with a dissertation on the dynamics of product development processes  Dr. Brat received his Ph.D. in Electrical & Computer Engineering in 1998 \(The University of Texas at Austin USA\. He has specialized on the application of static analysis to software verification. From 1997 to June 1999, he worked at MCC where he led a project that developed static analysis tools for software verification. In June 1999, he joined the Automated Software Engineering group at the NASA Ames Research Center and focused on the application of static analysis to the verification of la rge software systems. He codeveloped and applied static analysis tools based on abstract interpretation to the verification of software for Mars missions at JPL, various ISS controllers at MSFC and the ISS Biological Research Project at the NASA Ames Research Center   


9 when attempting to adaptively cancel an interference with time-varying relative geometry, such as would occur with a spacecraft orbiting a distant planet Compensation of Antenna Pointing Errors Pointing error is also a significant source of gain loss for the large antennas of the DSN at 32 GHz. Presently a complex monopulse pointing system is used to aid in pointing the DSN 34-meter antennas at 32 GHz. The blind pointing requirement on the antennas is driven by the pull-in range of this monopulse system requiring elaborate pointing models and calibration.  Use of a focal plane array eliminates the need for a monopulse system entirely, and greatly reduces the requireme nts on blind pointing accuracy and associated calibration effort Figure 8 shows the gain of the 70-meter antenna for signals appearing off bore-site when a single corrugated horn is used as the feed, and for th e case of an 81-element array used with a re-imaging magnification factor of three. The response for the single horn feed effectively is that of a uniform aperture, resulting in a 3-dB beamwidth of approximately 7.5 mdeg. Theref ore in practice the antenna must be pointed, without feedback, to approximately this accuracy before an active pointi ng control system such as a monopulse system or CONSCAN can be employed to actively point to the beam peak.  On the other hand, the response of the focal plane array to off-axis signals is quite forgiving, as illustrated by the black curve on the figure. In this case the response is not limited by the inherent beamwidth of the antenna, but rather by the field of view of the array. For this particular magnification and array size pointing errors of greater than +/- 20 mdeg can be accommodated  by the array with essentially no gain loss These pointing requirements are consistent with typical 8 GHz \(X-Band\ues, allowing operation of the 70-meter antenna at 32 GHz with no requirement for an additional active pointing system or improvements to the present blind pointing performance of the antenna. While illustrated here for the 70-meter antenna, exactly the same advantages exist for application of the FPA on a smaller, 34-meter DSN antenna. Relaxation of antenna pointing requirements is considered a major advantage of the focal plane array over a single horn feed 3  S UMMARY AND C ONCLUSION  The operational advantages of a focal-plane array receiver for use on large antennas of the Deep Space Network have been discussed. Examples of gravity compensation of the 70-m antenna during 32-GHz operation has been used to illustrate these advantages. In addition, an adaptive 


10 algorithm for optimal combining of focal-plane array signals in a noisy environment, including interference, has been described and evaluated via simulation. Finally mitigation of antenna pointing errors via focal-plane array processing is illustrated, providing additional benefits over the use of a single receiving horn A CKNOWLEDGMENT  The research described in this paper was carried out at the Jet Propulsion Laboratory, California Institute of Technology, under a contract with the National Aeronautics and Space Administration R EFERENCES    V Vi l n rot t e r and Fort Dem onst r at i on and Eval uat i on of the Ka-Band Array Feed Compensation System on the 70-Meter Antenna at DSS 14," TMO PR 42-139, JulySeptember 1999, pp. 1-17, November 15, 1999    V Khai ki n, E. M a jorova, Yu. Pari jski j, M  Parnes, R   Shifman, V. Dobrov, V. Volkov, and S. Uman, “7x8 Element MMIC Array at 26-30 GHz for Radio Astronomy Applications,” in Proceedings of International Conference Perspective on Radio Astronomy: "Technologies for Large Antenna Arrays", The Netherlands, April 1999, pp.171182V  3 er, P. W In itial Stu d i es o f Array Feed s fo r th e 70-Meter Antenna at 32 GHz," TDA PR 42-104, OctoberDecember 1990, pp. 50-67, February 15, 1991  4 b r iale, W  A., M. J. Britcliffe, an d M. Bren n e r Gravity Deformation Measurements of NASA's Deep Space Network 70-Meter Reflector Antennas," IPN PR 42147, July-September 2001, pp. 1-15, November 15, 2001    L. Stutzm an and G.A Thiele  Antenna Theory and Design John Wiley and Sons Inc., New York, pp 210-218   V. Khai ki n, V. Dobrov, M  Parnes, V Vol kov A Golovkov, Yu. Rybakov, “Mu lti-channel array receiver modules for a radio telescope at 26-30 GHz,” in Proceedings of URSI/IEEE XXVII Convention on Radio Science, pp.176-178, Espoo, Finland, Oct.2002  7 ro tter, an d M. Srin iv asan Larg e Array Ch an n e l Capacity in the _Presence of Interference,” IPN PR 42-164 Jet Propulsion Laboratory, February 15, 2006  8 ro tter, V. A., Ro d e m i ch E. R., Dolinar, S. J., “Realtime combining of residual carrier array signals using ML weight estimates,” IEEE Tran sactions on Communications Volume 40, Issue 3, March 1992, pp. 604-615 B IOGRAPHY  Victor Vilnrotter  M'79, SM’02 received his Ph.D. in electrical engineering and communications theory from the University of Southern California in 1978.  He joined the Jet Propulsion Laboratory, Pasadena, Calif., in 1979, where he is a Principal Engineer in the Communications Systems Research section. His research interests include el ectronic compensation of large antennas with focal-plane arrays, adaptive combining algorithms for large antenna arrays, optical communications through atmospheric turbulence, and the application of quantum communications to deep-space optical links. He has published extensively in conferences and refereed journals, and has received numerous NASA awards for technical innovations   Michael Britcliffe earned the Bachelors of Science degree in Applied Physics from California State University Northridge in 1988. He has worked at the Jet Propulsion Laboratory since 1989 He is currently Technical Group Supervisor of the Antenna Microwave and Low Noise Amplifier group in the Ground Communications section   Daniel Hoppe received the BS and MS degrees in Electrical Engineering from the University of Wisconsin Madison in 1982 and 1983, and the Ph.D. from UCLA in 1994. In 1984 he joined the Jet Propulsion Laboratory in Pasadena CA where he is currently a Principal Engineer. At JPL he has developed software for the solution of electromagnetic scattering problems, designed microwave components for the large antennas of the Deep Space Network, and antennas for spacecraft applications Recently he worked on diffraction modeling of large spacebased telescopes. Dr. Hoppe is a part time lecturer teaching courses in electromagnetics and antennas at UCLA 


 11 R EFERENCES     Reddy, M.K. and S.M. Reddy 223Detecting FET Stuck-Open Faults in CMOS Latc hes and Flip-Flops,\224 IEEE Design and Test of Computers Vol. 3 , No. 5 , pp. 17-26, October 1986   2 R Mad g e , M. Vilg is, a nd V. Bhide, "Achieving Ultra High Quality and Reliability in Deep Sub-Micron Technologies using Metal Layer Configurable Platform ASICs", MAPLD 2005    Kewal Sal u ja, \223Di g i t a l Sy st em Fundam e nt al s, Lect ure 11\224, Department of Electrical Engineering, University of Wisconsin Madison    Yu W e i  Papos ng  M oo Ki t Lee Peng W e ng Ng C h i n  Hu Ong, \223IDDQ Test Challenges in Nanotechnologies: A Manufacturing Test Strategy\224, Asian Test Symposium 2007. ATS apos;07. 16 th Volume , Issue , 8-11 Oct. 2007 Page\(s\211 \226 211  NASA GSFC Advi sory NA-GSFC 2004-06   Dan El ft m a nn, Sol o m on W o l d ay and M i nal  Sawant  New Burn In \(BI\ethodology for Testing of Blank and Programmed Actel 0.15 \265m RTAX-S FPGAs MAPLD 2005   M i nal Sawant Dan El ft m a nn,  W e rner van den Abeel an John McCollum, Solomon Wolday and Jonathan Alexander 223Post Programming Burn-in of Actel O.25um FPGA\222s\224 MAPLD 2002  B IOGRAPHY   John worked 2 years at Faichild R&D on bipolar switching performance specifically platinum dopedlife time control and the development of Ion Implantation.  He worked 15 years at Intel developing Intel's first bipolar PROM, Ion Implantation, the world's first 16K DRAM, as well as 64K and 256K DRAMs.  Mr. McCollum developed Intel's first dual layer metal CMOS technology for the 386 microprocessor.  He co-founded Actel and worked the last 20 years on process, antifuse and flash cell development and FPGA Architecture at Actel.  He holds over 50 patents   covering Process Technology, Antifuse and NVM technology, FPGA Architecture, Analog Processing and Radiation Hardening.  He has presented numerous papers at IEDM, MAPLD, CSME, SPWG, and the FPGA Symposium. He is currently a Fellow in the Technology Development Department 


Time Time 50 350   10 0                   10 1                   10 2 12.5 50 350   10 0                   10 1  12 expected from Figure 7, the width of the uncertainty region is compressed by the curvature of the monopulse response resulting in a detection-primitive with greater uncertainty than the variance admits.  A filter lag or so-called cluster tracking can easily result in a 5% or greater offset and degraded consistency.  After 300 seconds the curves peak up because the target is appr oaching a low-elevation beampoint limit.  This occurs anytime a target is tracked into the edge of the radar\222s field of re gard and can lead to radar-toradar handover difficulty         300 300 80  s D 2 k,1 k y    s D 2 k,1 k y   100 150 200 250 10 1                    10 5 1 0  Figure 8 - Consistency versus distance from beam center Monopulse Mismatch The next set of curves plotted in Figure 9 show the sensitivity of detection-primitive consistency to a mismatch in the monopulse slope.  All of these curves were generated using a linear monopulse response derived from the slope of the true monopulse response at beam center.  The slope of the 80% curve is 0.8 times th e beam-center slope; the 90 curve is 0.9 times the beam-center slope; and so on for 100%, 110% and 120%.  Again, the order of curves in the graph is the same as the legend order A steep slope tends to expand y I 222s uncertainty while a gentle slope tends to compress it.  An expanded uncertainty leads to a smaller consistency while a compressed uncertainty leads to a larger consistency.  This behavior can be observed in the family of curves in Figure 9.  Curves for the steeper slopes are on the botto m while curves for more gentle slopes are on top.  The notable feature of this set of curves is that the sensitivity to a mismatch in the monopulse slope is not very significant       100 150 200 250 10 1                    90 100 110 120  Figure 9 - Consistency versus monopulse mismatch Range-Bias Error The complex nature of the monopulse radar models presents ample opportunity to introduce errors in the software implementation.  One such e rror introduced in a \275 rangecell-width bias in the detection-primitive range which in turn resulted in a significant degradation to 2 9 k D The fact that 2 9 k D is measured in different coordinates compared to the bias made it difficult to determine which value or algorithm was to blame.  Examining the intermediate consistency values led directly to the error source A comparison between biased 2 1 k D  2 2 k D and 2 3 k D values and unbiased 2 2 k D values is shown in Figure 10.  The unbiased 2 2 k D is the bottom-most curve and the biased 2 3 k D is the top-most curve with a value around 80.  This large value for 2 3 k D indicates that there is a lot more uncertainty in the range measur ements compared to what is predicted by the range varian ce.  Since the range-variance calculation is easy to confirm, the problem must be in the algorithms that model or manipulate range A notable feature of Figure 10 is the sensitivity of the centroiding algorithm to range bias in the detection primitives.  The range bias is ba rely noticeable in the biased 2 1 k D and 2 2 k D curves.  Of course, if the unbiased 2 2 k D  curve existed as a baseline it would be relatively easy to spot the error 


Time Time Time 50 350   10 0                   10 1                   10 2 50 350   10 1                   10 0                   10 1 50 350   10 0                   10 1  13         Isolated No SNR Adjust  Figure 11 - Centroiding for isolated range cells Filter Tuning Now that the centroided m easurements are reasonably consistent, the parameters that govern track filtering can be examined.  As previously promised, the effects and corrections for atmospheric refr action and sensor bias have been disabled so that 2 8 k D can be analyzed using a sliding window.  Of course the full analysis would include these effects and 2 8 k D at each time step would be collected and averaged over many trials Plots of the effect of changing process noise in a nearlyconstant-velocity filter are shown in Figure 12 and Figure 13 for Cartesian position and velocity respectively.  In both figures, the plotted values have been divided by 3 so that the desired value is always 1.  Increasing the process noise up to a point should increase the updated uncertainty and reduce 2 8 k D values.  Except near th e end of the trajectory when the measurements are off of beam center, the curves in Figure 12 and Figure 13 appear inconclusive for this expected trend If 2 8 k D values are way out of range there are additional intermediate filter values that can be examined.  For example, the state extrapolati on algorithms can be examined by comparing the consistency of 1 210 Isolated With SNR Adjust 300 300 300 0.005 212 212 212 212 212 kkkk T kkkk D xhzSxhz 35        s D 2 k Range   D 2 k,2 biased D 2 k,1 biased D 2 k,2  Figure 10 - Range bias error in detection primitive Centroiding Algorithm From Section 3, assuming that the centroided-range uncertainty for an isolated range cell is the same as its detection-primitive uncertainty may be incorrect Collecting and plotting 2 3 k D values only from isolated range-cell measurements can be used to analyze such assumptions.  The plots in Figure 11 compare differences between the isolated-cell algorithm defined in Section 3, an algorithm that modifies the uncertainty based on the SNR in the isolated cell, and the 2 3 k D values from all measurements 34\was used to modify the range uncertainty for the upper line labeled Isolated with SNR Adjust    4 22  2 2  resRi o R R Rn bdp bm  s D 2 k,3 Range    s D 2 k,8 Position     212 1 can also be examined using \(35 The residual is also commonly used to determine the assignment cost  212 kk z  P  k  k1 with z k The consistency of the innovation covariance k T kkkkk RHPHS 100 150 200 250 10 1                    D 2 k,3 biased 100 150 200 250 10 2                    100 150 200 250 10 1                    0.5 50  Figure 12 \226 Position consistency, filter tuning example  r  t t 34 If the All Centroided curve \(middle\as the baseline doing nothing \(lower\imates the uncertainty and 33\imates the uncertainty.  Dividing by the square root of the observed SNR leads to a more consistent covariance; however, there is currently no statistical evaluation to justify it             210 210 1 1 1 2 All Centroided 


Time 50 350   10 1                   10 0                   10 1  14         300 0.005  s D 2 k,8 Velocity   100 150 200 250 10 2                    0.5 50  Figure 13 \226 Position consistency, filter tuning example 5  C ONCLUSION  Calculating and observing the behavior of covariance consistency at different levels  in the radar signal processing chain represents a very powerfu l tool that can be used to assess the accuracy and softwa re implementation of radar signal-processing algorithms.  Analyzing covariance consistency is applicable to radar systems both in the field and in simulations.  The primary challenge in both arenas comes down to properly accounting for the true target states that contribute to detections, detection primitives measurements, and state estimates For a fielded radar syst em, achieving covariance consistency is usually a s econdary consideration behind achieving and maintaining track s.  Indeed, until recently radar specifications did not even include requirements for covariance consistency.  Recent covariance consistency requirements stem from the fact that the use of radar systems in sensor netting applications is on the rise Currently the combined e ffects of off-beam-center measurements, atmospheric correction, bias correction clustering and centrioding, data association, and filtering on state covariance consistency throughout a target\222s trajectory are not well known.  This is particularly true for radars using wideband waveforms and multiple hypotheses or multiple frame trackers.  Numerical results presented here indicate that algorithms early in the radar signal processing chain can significantly degrad e covariance consistency and that some errors are better tolerated than others For a simulated target in a modeled system, truth relative to some global reference is known. However, transforming truth through different refere nce frames and accounting for changes that occur during various radar processing algorithms is not as simple as it appears.  The techniques in this paper help expose this hidden complexity and provide a framework for discussing and expanding the future development of covariance consistency techniques.  Such future developments include issues related to mapping truth through the convolution operation typically used to simulate wideband signal processing and the fast Fourier transforms typically used in pulse-Doppler processing.  Sophisticated tracking algorithms that carry multiple hypotheses, associate across multiple frames, or weight the association of multiple targets within a single frame pose significant challenges in properly associating truth with state estimates.  Additional work, including an investigation of track-to-truth assignment, is needed before covariance consistency techniques can be applied to these algorithms Another area that needs furthe r analysis is the use of a sliding window to approximate the covariance behavior expected during a set of Monte-Carlo trials.  Various timedependent variables such as the target\222s range and orientation, the transmit waveform, the radar\222s antenna patterns toward the target, missed detections, and false alarms could easily viol ate the assumption that measurement conditions are nearly stationary over the time of the window.  It is importa nt to understand the conditions when this assumption is violated Finally, the examples presented here included a relatively benign arrangement of targets.  Further analysis in dense target environments with the related increase in merged detections, merged measurements, and impure tracks is needed.  Further analysis for targets traveling over different trajectories is also needed Even so, the techniques presented here can be extended to many of these analyses R EFERENCES  1  S. Blackman and R. Popoli Design and Analysis of Modern Tracking Systems Artech House, 1999 2  Y. Bar-Shalom and X. R. Li Multitarget-Multisensor Tracking: Principles and  Techniques YBS Publishing, Storrs, CT, 1995 3  Y. Bar-Shalom, Editor Multi-target-Multi-sensor Tracking: Advanced Applications and  Vol. I Artech House, Norwood, MA, 1990 4  D. B. Reid, \223An Algorithm for Tracking Multiple Targets,\224 IEEE Trans. on Automatic Control Vol. 24 pp. 843-854, December 1979 5  T. Kurien, \223Issues in the Design of Practical Multitarget Tracking Algorithms,\224 in Multitarget-Multisensor Tracking Y. Bar-Shalom \(ed.\43-83, Artech House, 1990 6  R.P.S. Mahler, Statistical Multisource-Multitarget Information Fusion, Artech House, 2007 


 15 7  B.-N. Vo and W.-K. Ma, \223The Gaussian Mixture Probability Hypothesis Density Filter,\224 IEEE Trans Signal Processing Vol. 54, pp. 4091-4104, November 2006 8  B. Ristic, S. Arulampalam, and N. Gordon Beyond the Kalman Filter Artech House, 2004 9  Y. Bar-Shalom, X. Rong Li, and T. Kirubarajan Estimation with Applications to Tracking and Navigation, New York: John Wiley & Sons, pg. 166 2001 10  X. R. Li, Z. Zhao, and V. P. Jilkov, \223Estimator\222s Credibility and Its Measures,\224 Proc. IFAC 15th World Congress Barcelona, Spain, July 2002 11  M. Mallick and S. Arulampalam, \223Comparison of Nonlinear Filtering Algorithms in Ground Moving Target Indicator \(GMTI Proc Signal and Data Processing of Small Targets San Diego, CA, August 4-7, 2003 12  M. Skolnik, Radar Handbook, New York: McGrawHill, 1990 13  A. Gelb, Editor Applied Optimal Estimation The MIT Press, 1974 14  B. D. O. Anderson and J. B. Moore Optimal Filtering  Prentice Hall, 1979 15  A. B. Poore, \223Multidimensional assignment formulation of data ass ociation problems arising from multitarget and multisensor tracking,\224 Computational Optimization and Applications Vol. 3, pp. 27\22657 1994 16  A. B. Poore and R. Robertson, \223A New multidimensional data association algorithm for multisensor-multitarget tracking,\224 Proc. SPIE, Signal and Data Processing of Small Targets Vol. 2561,  p 448-459, Oliver E. Drummond; Ed., Sep. 1995 17  K. R. Pattipati, T. Kirubarajan, and R. L. Popp, \223Survey of assignment techniques for multitarget tracking,\224 Proc  on Workshop on Estimation  Tracking, and Fusion: A Tribute to Yaakov Bar-Shalom Monterey CA, May 17, 2001 18  P. Burns, W.D. Blair, \223Multiple Hypothesis Tracker in the BMD Benchmark Simulation,\224 Proceedings of the 2004 Multitarget Tracking ONR Workshop, June 2004 19  H. Hotelling, \223The generalization of Student's ratio,\224 Ann. Math. Statist., Vol. 2, pp 360\226378, 1931 20  Blair, W. D., and Brandt-Pearce, M., \223Monopulse DOA Estimation for Two Unresolved Rayleigh Targets,\224 IEEE Transactions Aerospace Electronic Systems  Vol. AES-37, No. 2, April 2001, pp. 452-469 21  H. A. P.  Blom, and Y. Bar-Shalom, The Interacting Multiple Model algorithm for systems with Markovian switching coefficients IEEE Transactions on Au tomatic Control 33\(8  780-783, August, 1988 22  M. Kendall, A. Stuart, and J. K. Ord, The Advanced Theory of Statistics, Vol. 3, 4th Edition, New York Macmillan Publishing, pg. 290, 1983 23  T.M. Cover and P.E. Hart, Nearest Neighbor Pattern Classification, IEEE Trans. on Inf. Theory, Volume IT-13\(1 24  C.D. Papanicolopoulos, W.D. Blair, D.L. Sherman, M Brandt-Pearce, Use of a Rician Distribution for Modeling Aspect-Dependent RCS Amplitude and Scintillation Proc. IEEE Radar Conf 2007 25  W.D. Blair and M. Brandt-Pearce, Detection of multiple unresolved Rayleigh targets using quadrature monopulse measurements, Proc. 28th IEEE SSST March 1996, pp. 285-289 26  W.D. Blair and M. Brandt-Pearce, Monopulse Processing For Tracking Unresolved Targets NSWCDD/TR-97/167, Sept., 1997 27  W.D. Blair and M. Brandt-Pearce, Statistical Description of Monopulse Parameters for Tracking Rayleigh Targets  IEEE AES Transactions, Vol. 34 Issue 2,  April 1998, pp. 597-611 28  Jonker and Volgenant, A Shortest Augmenting Path Algorithm for Dense and Sparse Linear Assignment Problems, Computing, Vol. 38, 1987, pp. 325-340 29  V. Jain, L.M. Ehrman, and W.D. Blair, Estimating the DOA mean and variance of o ff-boresight targets using monopulse radar, IEEE Thirty-Eighth SSST Proceedings, 5-7 March 2006, pp. 85-88 30  Y. Bar-Shalom, T. Kirubarajan, and C. Gokberk 223Tracking with Classification-Aided Multiframe Data Association,\224 IEEE Trans. on Aerospace and Electronics Systems Vol. 41, pp. 868-878, July, 2005   


 16 B IOGRAPHY  Andy Register earned BS, MS, and Ph  D. degrees in Electrical Engineering from the Georgia Institute of Technology.  His doctoral research emphasized the simulation and realtime control of nonminimum phase mechanical systems.  Dr. Register has approximately 20 years of experience in R&D with his current employer, Georgia Tech, and product development at two early-phase startups. Dr. Register\222s work has been published in journals and conf erence proceedings relative to mechanical vibration, robotics, computer architecture programming techniques, and radar tracking.  More recently Dr. Register has b een developing advanced radar tracking algorithms and a software architecture for the MATLAB target-tracking benchmark.  This work led to the 2007 publication of his first book, \223A Guide to MATLAB Object Oriented Programming.\224  Mahendra Mallick is a Principal Research Scientist at the Georgia Tech Research Institute \(GTRI\. He has over 27 years of professional experience with employments at GTRI \(2008present\, Science Applications International Corporation \(SAIC Chief Scientist \(2007-2008\, Toyon Research Corporation, Chief Scientist 2005-2007\, Lockheed Martin ORINCON, Chief Scientist 2003-2005\, ALPHATECH Inc., Senior Research Scientist 1996-2002\, TASC, Principal MTS \(1985-96\, and Computer Sciences Corporation, MTS \(1981-85 Currently, he is working on multi-sensor and multi-target tracking and classification bas ed on multiple-hypothesis tracking, track-to-track association and fusion, distributed filtering and tracking, advanced nonlinear filtering algorithms, and track-before-detect \(TBD\ algorithms He received a Ph.D. degree in  Quantum Solid State Theory from the State University of New York at Albany in 1981 His graduate research was also based on Quantum Chemistry and Quantum Biophysics of large biological molecules. In 1987, he received an MS degree in Computer Science from the John Hopkins University He is a senior member of the IEEE and Associate Editor-inchief  of the Journal of Advances in Information Fusion of the International Society of Information Fusion \(ISIF\. He has organized and chaired special and regular sessions on target tracking and classific ation at the 2002, 2003, 2004 2006, 2007, and 2008 ISIF conferences. He was the chair of the International Program Committee and an invited speaker at the International Colloquium on Information Fusion \(ICIF '2007\, Xi\222an, China. He is a reviewer for the IEEE Transactions on Aerospa ce and Electronics Systems IEEE Transactions on Signal Pr ocessing, International Society of Information Fusion, IEEE Conference on Decision and Control, IEEE Radar Conference, IEEE Transactions on Systems, Man and Cybernetics, American Control Conference, European Signal Processing Journal and International Colloquium on Information Fusion ICIF '2007   William Dale Blair is a Principal Research Engineer at the Georgia Tech Research Institute in Atlanta, GA. He received the BS and MS degrees in electrical engineering from Tennessee Technological University in 1985 and 1987, and the Ph.D. degree in electrical engineering from the University of Virginia in 1998. From 1987 to 1990, he was with the Naval System Division of FMC Corporation in Dahlgren, Virginia. From 1990 to 1997, Dr Blair was with the Naval Surface Warfare Center, Dahlgren Division NSWCDD\ in Dahlgren, Virg inia. At NSWCDD, Dr Blair directed a real-time experiment that demonstrated that modern tracking algorithms can be used to improve the efficiency of phased array radars. Dr Blair is internationally recognized for conceptualizing and developing benchmarks for co mparison and evaluation of target tracking algorithms Dr Blair developed NSWC Tracking Benchmarks I and II and originated ONR/NSWC Tracking Benchmarks III and IV NSWC Tracking Benchmark II has been used in the United Kingdom France, Italy, and throughout the United States, and the results of the benchmark have been presented in numerous conference and journal articles. He joined the Georgia Institute of Technology as a Se nior Research Engineer in 1997 and was promoted to Principal Research Engineer in 2000. Dr Blair is co-editor of the Multitarg et-Multisensor Tracking: Applications and Advances III. He has coauthored 22 refereed journal articles, 16 refereed conference papers, 67 papers and reports, and two book chapters. Dr Blair's research interest include radar signal processing and control, resource allocation for multifunction radars, multisen sor resource allocation tracking maneuvering targets and multisensor integration and data fusion. His research at the University of Virginia involved monopulse tracking of unresolved targets. Dr Blair is the developer and coordinator of the short course Target Tracking in Sensor Systems for the Distance Learning and Professional Education Departmen t at the Georgia Institute of Technology. Recognition of Dr Blair as a technical expert has lead to his election to Fellow of the IEEE, his selection as the 2001 IEEE Y oung Radar Engineer of the Year, appointments of Editor for Radar Systems, Editor-InChief of the IEEE Transactions on Aerospace and Electronic Systems \(AES\, and Editor-in- Chief of the Journal for Advances in Information Fusion, and election to the Board of Governors of the IEEE AES Society,19982003, 2005-2007, and Board of Directors of the International Society of Information Fusion   


 17 Chris Burton received an Associate degree in electronic systems technology from the Community College of the Air force in 1984 and a BS in Electrical Engineering Technology from Northeastern University in 1983.  Prior to coming to the Georgia Institute of Technology \(GTRI\ in 2003, Chris was a BMEWS Radar hardware manager for the US Air Force and at MITRE and Xontech he was responsible for radar performance analysis of PAVE PAWS, BMEWS and PARCS UHF radar systems Chris is an accomplished radar-systems analyst familiar with all hardware and software aspects of missile-tracking radar systems with special expertise related to radar cueing/acquisition/tracking for ballistic missile defense ionospheric effects on UHF radar calibration and track accuracy, radar-to-radar handover, and the effects of enhanced PRF on radar tracking accuracy.  At GTRI, Chris is responsible for detailed analysis of ground-test and flight-test data and can be credited with improving radar calibration, energy management, track management, and atmospheric-effects compensation of Ballistic Missile Defense System radars   Paul D. Burns received his Bachelor of Science and Masters of Science in Electrical Engineering at Auburn University in 1992 and 1995 respectively. His Master\222s thesis research explored the utilization of cyclostationary statistics for performing phased array blind adaptive beamforming From 1995 to 2000 he was employed at Dynetics, Inc where he performed research and analysis in a wide variety of military radar applications, from air-to-air and air-toground pulse Doppler radar to large-scale, high power aperture ground based phased array radar, including in electronic attack and protection measures. Subsequently, he spent 3 years at MagnaCom, Inc, where he engaged in ballistic missile defense system simulation development and system-level studies for the Ground-based Midcourse defense \(GMD\ system. He joined GTRI in 2003, where he has performed target tracking algorithm research for BMD radar and supplied expertise in radar signal and data processing for the Missile Defense Agency and the Navy Integrated Warfare Systems 2.0 office.  Mr. Burns has written a number of papers in spatio-temporal signal processing, sensor registration and target tracking, and is currently pursuing a Ph.D. at the Georgia Institute of Technology  


  18 We plan to shift the file search and accessibility aspect outside of the IDL/Matlab/C++ code thereby treating it more as a processing \223engine\224. SciFlo\222s geoRegionQuery service can be used as a generic temporal and spatial search that returns a list of matching file URLs \(local file paths if the files are located on the same system geoRegionQuery service relies on a populated MySQL databases containing the list of indexed data files. We then also plan to leverage SciFlo\222s data crawler to index our staged merged NEWS Level 2 data products Improving Access to the A-Train Data Collection Currently, the NEWS task collects the various A-Train data products for merging using a mixture of manual downloading via SFTP and automated shell scripts. This semi-manual process can be automated into a serviceoriented architecture that can automatically access and download the various Level 2 instrument data from their respective data archive center. This will be simplified if more data centers support OPeNDAP, which will aid in data access. OPeNDAP will also allow us to selectively only download the measured properties of interest to the NEWS community for hydrology studies. Additionally OpenSearch, an open method using the REST-based service interface to perform searches can be made available to our staged A-Train data. Our various services such as averaging and subsetting can be modified to perform the OpenSearch to determine the location of the corresponding spatially and temporally relevant data to process. This exposed data via OpenSearch can also be made available as a search service for other external entities interested in our data as well Atom Service Casting We may explore Atom Service Casting to advertise our Web Services. Various services can be easily aggregated to create a catalog of services th at are published in RSS/Atom syndication feeds. This allows clients interested in accessing and using our data services to easily discover and find our WSDL URLs. Essentially, Atom Service Casting may be viewed as a more human-friendly approach to UDDI R EFERENCES   NASA and Energy and W a t e r cy cl e St udy NEW S website: http://www.nasa-news.org  R odgers, C  D., and B  J. C onnor \(2003 223Intercomparison of remote sounding instruments\224, J Geophys. Res., 108\(D3 doi:10.1029/2002JD002299  R ead, W G., Z. Shi ppony and W V. Sny d er \(2006 223The clear-sky unpolarized forward model for the EOS Aura microwave limb sounder \(MLS Transactions on Geosciences and Remote Sensing: The EOS Aura Mission, 44, 1367-1379  Schwartz, M. J., A. Lam b ert, G. L. Manney, W  G. Read N. J. Livesey, L. Froidevaux, C. O. Ao, P. F. Bernath, C D. Boone, R. E. Cofield, W. H. Daffer, B. J. Drouin, E. J Fetzer, R. A. Fuller, R. F. Jar not, J. H. Jiang, Y. B. Jiang B. W. Knosp, K. Krueger, J.-L. F. Li, M. G. Mlynczak, S Pawson, J. M. Russell III, M. L. Santee, W. V. Snyder, P C. Stek, R. P. Thurstans, A. M. Tompkins, P. A. Wagner K. A. Walker, J. W. Waters and D. L. Wu \(2008 223Validation of the Aura Microwave Limb Sounder temperature and geopotential height measurements\224, J Geophys. Res., 113, D15, D15S11  Read, W G., A. Lam b ert, J Bacmeister, R. E. Cofield, L E. Christensen, D. T. Cuddy, W. H. Daffer, B. J. Drouin E. Fetzer, L. Froidevaux, R. Fuller, R. Herman, R. F Jarnot, J. H. Jiang, Y. B. Jiang, K. Kelly, B. W. Knosp, L J. Kovalenko, N. J. Livesey, H.-C. Liu1, G. L. Manney H. M. Pickett, H. C. Pumphrey, K. H. Rosenlof, X Sabounchi, M. L. Santee, M. J. Schwartz, W. V. Snyder P. C. Stek, H. Su, L. L. Takacs1, R. P. Thurstans, H Voemel, P. A. Wagner, J. W. Waters, C. R. Webster, E M. Weinstock and D. L. Wu \(2007\icrowave Limb Sounder upper tropospheric and lower stratospheric H2O and relative humidity with respect to ice validation\224 J. Geophys. Res., 112, D24S35 doi:10.1029/2007JD008752  Fetzer, E. J., W  G. Read, D. W a liser, B. H. Kahn, B Tian, H. V\366mel, F. W. Irion, H. Su, A. Eldering, M. de la Torre Juarez, J. Jiang and V. Dang \(2008\omparison of upper tropospheric water vapor observations from the Microwave Limb Sounder and Atmospheric Infrared Sounder\224, J. Geophys. Res., accepted  B.N. Lawrence, R. Drach, B.E. Eaton, J. M. Gregory, S C. Hankin, R.K. Lowry, R.K. Rew, and K. E. Taylo 2006\aintaining and Advancing the CF Standard for Earth System Science Community Data\224. Whitepaper on the Future of CF Governance, Support, and Committees  NEW S Data Inform ation Center \(NDIC http://www.nasa-news.org/ndic 


  19   Schi ndl er, U., Di epenbroek, M 2006 aport a l based on Open Archives Initiative Protocols and Apache Lucene\224, EGU2006. SRef-ID:1607-7962/gra/EGU06-A03716 8] SciFlo, website: https://sci flo.jpl.nasa.gov/SciFloWiki 9 ern a, web s ite: h ttp tav ern a.so u r cefo r g e.n et  Java API for XM L W e b Services \(JAX-W S https://jax-ws.dev.java.net  Di st ri but ed R e source M a nagem e nt Appl i cat i on DRMAA\aa.org  Sun Gri d Engi ne, websi t e   http://gridengine.sunsource.net  W 3 C R ecom m e ndat i on for XM L-bi nary Opt i m i zed Packaging \(XOP\te: http://www.w3.org/TR/xop10  W 3 C R ecom m e ndat i on for SOAP M e ssage Transmission Optimization Mechanism \(MTOM website: http://www.w3.org/TR/soap12-mtom  W 3 C R ecom m e ndat i on for R e source R e present a t i on SOAP Header Block, website http://www.w3.org/TR/soap12-rep 16] OPeNDAP, website: http://opendap.org  Yang, M Q., Lee, H. K., Gal l a gher, J. \(2008 223Accessing HDF5 data via OPeNDAP\224. 24th Conference on IIPS  ISO 8601 t h e Int e rnat i onal St andard for t h e representation of dates and times http://www.w3.org/TR/NOTE-datetime 19] ITT IDL, website http://www.ittvis.com/ProductServices/IDL.aspx 20] Python suds, website: h ttps://fedorahosted.org/suds  The gSOAP Tool ki t for SOAP W e b Servi ces and XM LBased Applications, website http://www.cs.fsu.edu/~engelen/soap.html  C hou, P.A., T. Lookabaugh, and R M Gray 1989 223Entropy-constrained vector quantization\224, IEEE Trans on Acoustics, Speech, and Signal Processing, 37, 31-42  M acQueen, Jam e s B 1967 e m e t hods for classification and analysis of multivariate observations\224 Proc. Fifth Berkeley Symp Mathematical Statistics and Probability, 1, 281-296  C over, Thom as. and Joy A. Thom as, \223El e m e nt s of Information Theory\224, Wiley, New York. 1991  B r averm a n, Am y 2002 om pressi ng m a ssi ve geophysical datasets using vector quantization\224, J Computational and Graphical Statistics, 11, 1, 44-62 26 Brav erm a n  A, E. Fetzer, A. Eld e rin g  S. Nittel an d K Leung \(2003\i-streaming quantization for remotesensing data\224, Journal of Computational and Graphical Statistics, 41, 759-780  Fetzer, E. J., B. H. Lam b rigtsen, A. Eldering, H. H Aumann, and M. T. Chahine, \223Biases in total precipitable water vapor climatologies from Atmospheric Infrared Sounder and Advanced Microwave Scanning Radiometer\224, J. Geophys. Res., 111, D09S16 doi:10.1029/2005JD006598. 2006 28 SciFlo Scien tific Dataflo w  site https://sciflo.jpl.nasa.gov  Gi ovanni websi t e   http://disc.sci.gsfc.nasa.gov techlab/giovanni/index.shtml  NASA Eart h Sci e nce Dat a Sy st em s W o rki ng Groups website http://esdswg.gsfc.nasa.gov/index.html   M i n, Di Yu, C h en, Gong, \223Augm ent i ng t h e OGC W e b Processing Service with Message-based Asynchronous Notification\224, IEEE International Geoscience & Remote Sensing Symposium. 2008 B IOGRAPHY  Hook Hua is a member of the High Capability Computing and Modeling Group at the Jet Propulsion Laboratory. He is the Principle Investigator of the service-oriented work presented in this paper, which is used to study long-term and global-scale atmospheric trends. He is also currently involved on the design and development of Web Services-based distributed workflows of heterogeneous models for Observing System Simulation Experiments OSSE\ to analyze instrument models. Hook was also the lead in the development of an ontology know ledge base and expert system with reasoning to represent the various processing and data aspects of Interferometric Synthetic Aperture Radar processing. Hook has also been involved with Web Services and dynamic language enhancements for the Satellite Orbit Analysis Program \(SOAP\ tool.  His other current work includes technology-portfolio assessment, human-robotic task planning & scheduling optimization, temporal resource scheduling, and analysis He developed the software frameworks used for constrained optimization utilizing graph search, binary integer programming, and genetic algorith ms. Hook received a B.S in Computer Science from the University of California, Los  


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



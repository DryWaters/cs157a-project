A Hybrid Approach for Mining Maximal Hyperclique Patterns Yaochun Huang Computer Science Univ. of Texas - Dallas yxh038100@utdallas.edu Hui Xiong Computer Science University of Minnesota huix@cs.umn.edu Weili Wu, Zhongnan Zhang Computer Science Univ. of Texas - Dallas weiliwu, zxz021000  @utdallas.edu Abstract A hyperclique pattern [12] is a new type of association pattern that contains items which are highly af?liated with each other. More speci?cally, the presence of an item in one transaction strongly implies the presence of every other item that belongs to the same hyperclique pattern. In this paper, we present a new algorithm for mining maximal hyperclique patterns, which are desirable for pattern-based clustering methods [11]. This algorithm exploits key advantages of both the Depth First Search \(DFS the Breadth First Search \(BFS the equivalence pruning method, one of the most ef?cient pruning methods of the DFS strategy, into the process of the BFS strategy. As demonstrated by our experimental results the performance of our algorithm can be orders of magnitude faster than standard maximal frequent pattern mining algorithms, particularly at low levels of support Keywords Data Mining, H-con?dence, Hyperclique Pattern 1. Introduction The association-rule mining problem [3] is concerned with ?nding relationships among the items in a largescale data set. In the past decade, association-rule mining has been the subject of extensive research in data mining 1, 2, 3, 4, 8]. Given a set of transactions, the objective of association-rule mining is to extract all rules of the form  where and are sets of items, that satisfy user-speci?ed minimum support and minimum con?dence thresholds. Support measures the fraction of transactions that obey the rule, while con?dence provides an estimate 


of the conditional probability that a transaction contains  given that it contains Both metrics are useful because they provide an indication of the strength and statistical signi?cance of an association rule Standard association-rule mining algorithms have the 1This work was partially supported by NSF grant # ACI-0305567. The content of this work does not necessarily re?ect the position or policy of the government and no of?cial endorsement should be inferred emphasis on discovering frequent patterns. However, these approaches may lose ef?ciency when the support threshold is low. Also, frequent patterns usually contain objects which are weakly related to each other [12]. Instead, a hyperclique pattern [12] was proposed as a new type of association pattern that contains items that are highly af?liated with each other. Speci?cally, the presence of an item in one transaction strongly implies the presence of every other item that belongs to the same hyperclique pattern. The h-con?dence measure captures the strength of this association and is de?ned as the minimum con?dence of all association rules of an itemset. An itemset is a hyperclique pattern if the hcon?dence of this pattern is greater than a user-speci?ed minimum h-con?dence threshold. A hyperclique pattern is a maximal hyperclique pattern if no superset of this pattern is a hyperclique pattern Maximal hyperclique patterns are desirable for pattern preserving clustering [11], which can produce easily interpretable clustering results. However, to our best knowledge there is no ef?cient algorithm for mining maximal hyperclique patterns in the literature. As a result, the objective of this paper is to design an ef?cient algorithm for mining maximal hyperclique patterns in large-scale data sets In general, for association pattern mining, there are two search strategies: Breadth First Search \(BFS First Search \(DFS search in a level-wise manner. In other words, it ?rst discovers all the size-1 patterns at level 1, followed by all the size2 patterns at level 2, and so on, until no pattern is generated at a particular level. If mining maximal hyperclique patterns using the BFS strategy, we could apply        


that is, an itemset can be pruned if one of its subsets is not a hyperclique pattern. This pruning is based on the anti-monotone property of support and h-con?dence measures. The drawback of this strategy is that we need to generate all the subsets of a maximal hyperclique pattern In contrast, the DFS strategy avoids generating all the intermediate patterns and can directly ?nd maximal hyperclique patterns. For the DFS strategy, a lot of pruning methods such as equivalence pruning, leftmost pruning, full pruning and dynamic ordering [4, 6, 9], can be applied. However Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE the DFS strategy cannot apply the  method, since we do not generate all subsets of a candidate pattern for this strategy In this paper, we exploit key advantages of both the DFS strategy and the BFS strategy and design a hybridMaximal Hyperclique Pattern \(MHP lustrates our MHP algorithm, which has two phases. In the rst BFS phase, for a given depth L, we use the Apriorilike approach [2] to generate all the size-L hyperclique patterns. In the second phase, the MHP algorithm takes the DFS search strategy. All the DFS pruning methods will be used in this phase. Also, since we have all the size-L hyperclique patterns, an itemset can be pruned by prevalence pruningmethod if any of its size-L subset has not been generated. Considering the DFS strategy is much more ef?cient than the BFS strategy for ?nding maximal patterns and the major computation savings of the DFS strategy is due to the equivalent pruning method [1, 6, 9], we adapt the equivalent pruning method to our algorithm. In addition, we prove the correctness and completeness of our MHP algorithm Finally, our experimental results show that the MHP algorithm can be orders of magnitude faster than maximal frequent pattern mining algorithms, such as MAFIA [6], particularly at low level of support NULL 1 2 1st Phase BFS 3 4 1, 4 1, 2, 3, 4 1, 2, 3 1, 2, 4 1, 3, 4 2, 3, 4 3, 42, 42, 31, 2 1, 3 2nd Phase DFS Figure 1. An Illustration of the Hybrid Mining Overview: The remainder of this paper is organized as follows. Section 2 de?nes some basic concepts. In section 


3, we propose a framework for miningmaximal hyperclique patterns. We describe the algorithm details and prove the correctness and completeness of the algorithm in Section 4 Our experimental results are presented in Section 5. Finally in section 6, we draw conclusions and suggest future work 2. Basic Concepts To facilitate our discussion, we ?rst present some basic concepts in this section De?nition 1 The h-con?dence of an itemset          d e n o t e d  a s            i s  a  m e a s u r e  t h a t  r e ects the overall af?nity among items within the item             where     is the classic de?nition of association rule con?dence [2 De?nition 2 An itemset  is a hyperclique pattern if and          " # , where ! is a user-speci?ed minimal support threshold and " # is a userspeci?ed minimal h-con?dence threshold De?nition 3 For a hyperclique pattern, HP, if none of its supersets is a hyperclique pattern, we say HP is a Maximal Hyperclique Pattern \(MHP MHP  P $ HP and ' P’ \( P, P De?nition 4 The order of items: for two different item    and the name of  is preceding of the name of in the lexicographic order, we  is lexicographic before We write it as   In the rest of this paper, we arrange the items in an itemset in order, except for special mention De?nition 5 The order of patterns: for two different patterns 


     and  if   1 m,  + 2 and  +  , '   3 *  *  4 3 5 5   we say lexicographic before   . It could be also written as  3. A Framework for Mining Maximal Hyperclique Patterns In this section, we present a two-phase maximal hyperclique pattern mining framework. In the ?rst BFS phase we retrieve all the size-L hyperclique patterns. In other words, the ?rst L levels of the   7  10 will be searched using Apriori-like methods [2]. In the second phase, we apply the DFS strategy to extract all the Maximal Hyperclique Patterns \(MHP 3.1. Basic De?nition For a pattern, there are three concepts related to items of this pattern: the item set, the equivalence item set, and the tail item set. We ?rst introduce these three concepts De?nition 6 The Item Set \(  .item set of all the items in the pattern De?nition 7 The Tail Item Set \(  .tail set of items which can be used to generate the super pattern of this pattern in the DFS phase In the DFS phase, we retrieve all the patterns by generating the super patterns of a given pattern items [10, 1]. All tail items are included in  .tail Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE De?nition 8 For a pattern  , if an item appears in all the 


transactions that contain  .item, but not in  .item, we say that this item is an equivalence item with Table 1 shows a sample data set and Table 2 shows the support of items in the sample data set. Also, for this sample data set, Figure 2 illustrates the two-phase maximal hyperclique pattern mining process. In the ?gure, a node represents a pattern,  . As can be seen, in the upper layer numbers represent the items in  .item and numbers in the braces are the items in  .equivalence. In addition, numbers following the short line represents the items in  .tail There are two rows in the lower part of the ?gure: the ?rst one shows the support of patterns and the second row shows the corresponding h-con?dence of patterns Table 1. A Sample Data Set TID Items 1 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 2 3, 4, 7, 8, 9, 11 3 3, 4, 5, 6, 7, 8, 9, 11 4 1, 2, 3, 4, 5, 6, 7, 8, 9, 11 5 1, 3, 4, 7, 8, 9 6 2, 3, 4, 7, 8 7 3, 4, 7, 9 8 3, 4, 8, 9 9 3, 7, 8, 9 10 4, 7, 8, 9 Lemma 1 If an item is an equivalence item of a pattern, it should also be an equivalence item of its super patterns Table 2. Support of Items in the Sample Data Set Item TID Support 1 1, 4, 5 0.3 2 1, 4, 6 0.3 3 1, 2, 3, 4, 5, 6, 7, 8, 9 0.9 4 1, 2, 3, 4, 5, 6, 7, 8, 10 0.9 5 1, 3, 4 0.3 6 1, 3, 4 0.3 7 1, 2, 3, 4, 5, 6, 7, 9, 10 0.9 8 1, 2, 3, 4, 5, 6, 8, 9, 10 0.9 9 1, 2, 3, 4, 5, 7, 8, 9, 10 0.9 10 1 0.1 11 1, 2, 3, 4 0.4     0.15         


   0.55 If an item  is an equivalence item with a pattern  and    a minimum h-con?dence threshold, then the union of "  # and  .item cannot be a hyperclique pattern De?nition 9 If an item is an equivalence item of a pattern and the union of this item and  .item is also a hyperclique pattern, we say this item is a Pure Equivalence Item PE item, of the pattern If we generate the closed frequent itemset or maximal frequent Itemset with the DFS approach, the               m e t h o d  c o u l d  m o v e  t h e  P E  i t e m from  .tail to the  .item directly [6, 9]. However, the direct use of this method may break the limitation of h-con?dence when we generate super patterns. As shown in the sample data set, item for " 1, 5 # . In other words, item 5 # , since we do not know whether the super patterns of 5 # have item the equivalence pruningmethod in the BFS phase. Consider that adding items may change the size of patterns, we need to maintain a set to store a pattern’s PE items 0.2,0.67 1,2 0.2,0.67 1,2\(5,6 0.7,0.78 3,4,7,8,9 Tail Set3,4\(8,9 0.6,0.67 Equivalent Set Item Set H?confidence Support 1,5\(6 0.2,0.67 2,5\(6 0.2,0.67 0.2,0.67 1,6 0.2,0.67 


2,6 0.8,0.89 3,4 0.8,0.89 3,7 0.8,0.89 3,8 0.8,0.89 3,9 0.8,0.89 4,7 0.8,0.89 4,8 0.8,0.89 4,9 0.8,0.89 7,8 0.8,0.89 7,9 0.8,0.89 8,9 0.7,0.78 3,4,7 0.7,0.78 3,4,8 0.7,0.78 3,4,9 0.7,0.78 3,7,8 0.7,0.78 3,7,9 0.7,0.78 3,8,9 0.7,0.78 4,7,8 0.7,0.78 4,7,9 0.7,0.78 4,8,9 0.7,0.78 7,8,9 0.7,0.78 3,7,8?9 0.7,0.78 4,7,8?9 0.7,0.78 3,4,8?9 0.7,0.78 3,4,7?8,9 0.6,0.67 


3,4,7,8?9 0.9,1 9 0.9,1 8 0.9,1 7 0.9,1 4 0.9,1 311 0.4,1 0.3,1 6 0.3,1 5 0.3,1 210 0.1,1 0.3,1 1 0.3,0.75 6\(11 6,11 0.3,0.75 0.2,0.5 2,11 0.2,0.5 1,11 6 is transferred B FS Phase D FS Phase 5 is absorbed Absorb Null Figure 2. An Illustration of the Two-Phase Maximal Hyperclique Pattern Mining Process De?nition 10 The Equivalence Item Set of a pattern equivalence, is the item set for storing  ’s PE items If we ?nd an item is a PE item of a pattern  , we could add it to  .equivalence. While the super patterns of are generated, they will succeed their own PE items from equivalence. In this case, the items of  are separated in  .item and  .equivalence, and the target pattern of should be  .item *  .equivalence De?nition 11 Union of a pattern,  .union, is             u n i o n  i s  t h e  t a r g e t  i t e m s e t  o f     I n d e e d  support\(  .union item Proceedings of the 16th IEEE International Conference on Tools with 


Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE De?nition 12 Size of a Pattern\(P P on the size of P.item, no matter how many items in P.equivalence De?nition 13 Sub pattern: For two pattern      , if item is a subset of   .item, we say that   is a sub pattern of   , even   .union is not a subset of   .union, and is a super pattern of   . If the size of   is smaller than the size of   ,   is a pure sub pattern of De?nition 14 For a Pattern   , if i’ is   ’s equivalence item and all the items in    .item are lexicographic before item   , we say item   is a Pro equivalence item of De?nition 15 For a Hyperclique Pattern    , if item   is both    ’s PE item and Pro equivalence item, the item is a Pro Pure equivalence item \(PPE item 3.2. Pruning Methods in the BFS phase At the initial stage, the algorithm generates the size1 patterns and counts the support of these patterns All the items which have support less than the userspeci?ed support threshold are pruned. Meanwhile, these items are sorted during this stage. For instance, consider the example dataset shown in Table 1, item      Also, as shown in Figure 2, the algorithm constructs the size-1 hyperclique patterns and sort all items in lexicographic order In the BFS phase, the algorithm applies an apriori-like approach to generate the size-L hyperclique patterns from size-\(L-1 strategies applied in this phase as the following Prevalence Pruning. In the apriori-like algorithm a size-k pattern generated by joining two size-\(k-1  and     If   "  and  


exist, the algorithm rst checks whether all the other size-\(k-1 exist. If one of the sub patterns does not exist,   is not a hyperclique pattern and can be pruned. This is a standard pruning method [1 H-con?dence Pruning. Before generating a size-k pattern   , we could calculate the ratio   If this ratio is less than 1 2 , hconf 2 , since support   as shown in Figure 2, support\(1 3 hconf\(  1,3  4 5 6   5   6   5  7  7 2 therefore the pattern  1,3  is pruned Equivalence Pruning. We apply the 9    method to reduce the number of patterns generated. If support  should be a PPE item of    "  , and be absorbed into    "  .equivalence. In Figure 2, support\(  5 6 5 set and prune  5, 6 When generating a size-k hyperclique pattern    , if the items in its size-\(k-1 lence sets are PE items of    ,    can succeed these items to its own equevalence set. For instance, in Figure 2, both  1, 5  and  2, 5  succeed item 6 from 


5  .equivalence, but do not succeed item   since it would break the limitatin of h-con?dence When    "  absorbing item   , all the equivalence items of the other size-\(k-1 5               5                    "      , are also equivalence items of    "  .    "  could tranfer these items to    "  .equivelance if they are PE items. In Figure 2, while generating the pattern  1, 2, 5  from  1, 2  ,  1 5  and  2, 5  , the pattern  1, 5  will absorb item  , and transfer item   from the pattern  1, 5 Indeed, when generating    , if item   is in   equivalence, it is unnecessary to generate the but transfer the PE items in the other size-\(k-1 equivalence set to    "  .equvialence After generating the size-k hyperclique patterns, we could check all the size-\(k-1 graphic order. For a size-\(k-1 is not a subset of any size-k pattern’s union, it will be impossible to generate a hyperclique pattern whose union is the superset of    "  .union in the following process. If this union is not a subset of an itemset in current Maximal Hyperclique Pattern Set \(MHPS is a maximal hyperclique pattern and could be added to the MHPS. For example, in Figure 2, after generating the size-2 patterns, the union of  1, 2  is  1, 2, 5, 6  , and no superset in either size-3 patterns’ union or MHPS. Hence, the algorithm adds the union into MHPS. For pattern  1, 5  , the union of this pattern is  1, 5, 6  , and this pattern has no superset in size-3 patterns’ union, but has a superset in MHPS hence this pattern is pruned 3.3. Pruning Methods in the DFS phase In the BFS phase, the algorithm has identi?ed all the size-L hyperclique patterns. At the beginning of the DFS phase, the algorithm adds the tail items to these patterns’ tail sets. For a size-L hyperclique pattern item=             @  , if there is an item   such that: \(1 item   A B   .equivalence, \(2 lexicographic before i’, and \(3   have been generated, the algorithm adds item   to   .tail. For instance, in Figure 2, item 8 and 9 are added to  3, 4, 7  ’s tail set The super patterns of a hyperclique pattern generated with the item in   .tail, and succeed the PE item from   .equivalence Proceedings of the 16th IEEE International Conference on Tools with 


Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE EquivalencePruning. Similar to the BFS phase, if a tail item   is a PE item, we will add   the pattern’s equivalence set. If the size-1 pattern     ’s equivalence set is not null the super patterns will succeed PE items from this set Full Pruning. When we process the Pattern   , if the union of   .item,   .equivalence and   .tail is a subset of a pattern in current MHPS, all of the patterns generated by   cannot be MHP since they have a super Hyperclique Pattern. We could prune this pattern directly. In Figure 2 when we process  3, 7, 8  , which tail set is  9  ,  3, 4, 7, 8 9  has already been added toMHPS.Wewill ?nd   is a subset of  3, 4, 7, 8, 9  , and prune  3, 7, 8 LeftMost Pruning. When processing a hyperclique pattern   , if the pattern in the end of this path is found to be MHP, all the patterns in the other paths should not be MHP In this case, we could skip these patterns[6]. In Figure 2 the end of left most path of  3, 4, 7  is  3, 4, 7, 8, 9  , and we ?nd this pattern isMHPS, we can skip all the other paths of  3, 4, 7  , and continue to process the next pattern Dynamic Reordering. Bayardo showed that the bene?t of dynamically reordering super patterns of   is signi?cant [5]. The mining speed will be 2 to 4 times faster. We sort the super patterns in the increasing order of support H-con?dence Pruning. Similar to the BFS phase, for a tail item     we could prune   from   .tail Prevalence Pruning. Since we have generated the sizeL hyperclique patterns in the BFS phase, for a hyperclique pattern   , if one size-L sub pattern of   is not generated, we need not generate it In the DFS phase, if a hyperclique pattern cannot generate any super hyperclique pattern, or none of these super hyperclique patterns could succeed all the items in its equivalence set, it will be impossible to ?nd a super union of this pattern’s union in the future. We will check this union with MHPS. If there is no super pattern in MHPS, we will add the union to MHPS 


4. The MHP Algorithm Figure 3 shows an overview of the hybrid MHP algorithm for mining maximal hyperclique patterns. As can be seen, there are two phases: the BFS phase and the DFS phase in the algorithm 4.1. Algorithm Description In the ?rst BFS phase, Initial Function generates the size-1 frequent patterns, which are also size-1 hyperclique patterns, and items are sorted in order. In Generate and Prune Super Function, the prevalence pruning, hcon?dence pruning, and equivalence pruning are applied to prune the search space and size-k hyperclique patterns are generated from size-\(k-1 ter extracting the size-k patterns, the algorithm extracts all size-\(k-1 union in size-k hyperclique patterns to       ! . In Check and Add Function, the algorithm checks the patterns in       ! , if their unions are not subsets in MHPS these unions are added into MHPS In the second phase, the Append Tail Function adds the size-L patterns’ tail item. Extract MHP is the major function for DFS mining. The traditinal optimal methods, full pruning, leftmost pruning, and equivalence pruning, and new methods, prevalence pruning and hcon?dence pruning, are implemented in Function Generate and Prune Super. The Sort and Append Tail Function implements the dynamic sorting and add tail items for the super patterns. Finally, the algorithm checks whether the pattern being processed is in MHPS or not by the function Check and Add 4.2. Completeness and Correctness Here, we prove the completeness and correctness of our MHP algorithm. To facilitate our discussion, we ?rst introduce some lemma and a new concept, Covering Pattern Lemma 2 If a hyperclique pattern   ! is generated in the BFS phase, none of the item in   ! .itemset could be a PPE item of any sub pattern of Proof: This lemma proof as well as some following lemma proofs are presented in our Technical Report [7 Lemma 3 When a hyperclique pattern   ! is generated in the BFS phase and the size of   !  " , if # an item i 1 2 3 i’  is also a hyperclique pattern,   ! .item i’  will be generated by our algorithm Lemma 4 If a hyperclique pattern   ! is generated in the BFS phase, all of its PPE items would be added to the  


equivalence by the algorithm Lemma 5 For an equivalence item which is transferred by a hyperclique pattern   , it could also be added to equivalence set with absorbing or succeeding if we do not use transferring method Lemma 6 For a hyperclique pattern   , all items in equivalence are PPE items of some sub pattern of this pattern De?nition 16 For a hyperclique pattern  ! , if \(1 is a hyperclique pattern, \(2 item, and \(3 item,  $ is a Covering Pattern of  ! . Obviously support\(  $ .item item union Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE MHS ALGORITHM Input: \(a b c d The retrieve level of the BFS phase Output: \(1 MHPS with support hconf and its superset without both such two properties Variables: k: the itemset size  a set of size hyperclique patterns   a set of size candidate maximal hyperclique patterns set of maximal hyperclique patterns a set of superset generate from Phase I: generate Hyperclique Patterns by BFS 1.    = Initial  2. for \(k=1 k 3  Generate and Prune Super  4 


  set of patterns in without superset union in  5. Check and Add     Phase II: extract Maximal Hyperclique Patterns from    by DFS 6. Append Tail 7. for 8. Extract MHP Function Extract MHP\(Pattern 9.       =Generate and Prune Super 10. Sort and Append Tail 11. for  item 12. Extract MHP 13. if  .union haven’t a super union in 14. Check and Add\(  ,MHPS Figure 3. Overview of the MHP Algorithm Lemma 7 If a pattern is a hyperclique pattern, one of its Covering Pattern must be generated Lemma 8 TheMHP algorithm is complete. In other words all the Maximal Hyperclique Patterns will be identi?ed by the MHP algorithm Lemma 9 The MHP algorithm is correct. In other words any patterns identi?ed by the MHP algorithm are maximal hyperclique patterns Note that if we set the search depth in the BFS phase large enough, our algorithmbecomes a pure BFS algorithm This means equivalence pruning will work correctly in an apriori-like algorithm for mining maximal hyperclique pattern. Additionally, if we set the h-con?dence threshold to zero, the algorithm ?nds maximal frequent itemsets 5. Experimental Evaluation In this section, we present extensive experiments to evaluate the performance of the MHP algorithm. Speci?cally we demonstrate: \(1 son between the MHP algorithm and standard maximal frequent pattern mining algorithms and \(2 MHP algorithm on ?nding maximal hyperclique patterns 5.1. The Experimental Setup Our experiments were performed on two real-world date sets    ! " and    ! " # , which are benchmark 


dense data sets for evaluating pattern mining algorithms These two data sets are obtained from IBM Almaden at http://www.almaden.ibm.com/cs/quest/demos.html. Recently, theMAFIA algorithm [6] was proposed to ef?ciently discover maximal frequent patterns. As shown in their paper, MAFIA can be several orders better than some alternatives, such as DepthProject, for mining maximal frequent patterns. Hence, we chose MAFIA as the base line for our performance evaluation. Finally, please note that only the size-2 patterns are generated in the ?rst BFS phase Experimental Platform We implemented the MHP algorithms using C++ and all experiments were performed Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE on a Pentium III    MHz PC machine with    megabytes main memory, running Linux Redhat 6.1 operating system 5.2. A Performance Comparison 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 1e+10 1e+11 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C he ck ed P at te rn s Support threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 


Figure 4. The Number of Checked Patterns on the Pumsb* Data Set 10 100 1000 10000 100000 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 R un T im e s ec  Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 5. The RunTime Comparison on the Pumsb* Data Set Figure 4 shows the number of patterns that MHP and MAFIA have to check during the pattern mining process on the pumsb* data set. As can be seen, for MHP, the number of checked patterns is increased with the decrease of the h-con?dence threshold. However, the number of checked patterns of MHP can be signi?cantly smaller than that of MAFIA even if a low h-con?dence threshold is speci?ed To check a pattern, we need to count the support of the patterns. Counting the support of a pattern is the most timeconsuming task during the pattern mining process, since we need to retrieve all the transactions which include one of its sub-pattern, or for Ma?a, retrieve all the bit of the bitmap of this pattern [6]. Therefore, an algorithm is more ef?cient if smaller number of patterns need to be checked 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N 


um be r o f C he ck ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 6. The Number of Checked Patterns on the Pumsb Data Set 10 100 1000 10000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 R un T im e s ec  Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 7. The RunTime Comparison on the Pumsb Data Set The runtime comparison of MHP and MAFIA on the Pumsb* data set is shown in Figure 5. In the ?gure, we can observe that the runtime of MHP can be signi?cantly reduced with the increase of h-con?dence thresholds. Also the runtime of MHP can be several orders of magnitude less than that of MAFIA even if the h-con?dence threshold is as low as 0.3. The reason is that the number of checked patterns of MHP is sign?cantly smaller than that of MAFIA Similar results are also obtained from the pumsb data set as shown in Figure 6 and Figure 7. For the pumsb data set the number of checked patterns of MHP is much smaller 


than that of MAFIA and the runtime of MHP can be significantly less than that of MAFIA 5.3. The Effect of the MHP Algorithm on Finding Maximal Hyperclique Patterns Figure 8 and Figure 9 show the number of maximal patterns identi?ed byMHP andMAFIA on Pumsb* and Pumsb data sets respectively. As can be seen, the number of maximal hyperclique patterns identi?ed by MHP can be orders of magnitude smaller than the number of maximal frequent patterns identi?ed by MAFIA. In other words, the number Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 100 1000 10000 100000 1e+06 1e+07 1e+08 1e+09 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 0.06 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0 Min_Conf=0.1 Min_Conf=0.3 Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 8. The Number of MFI/MHP Patterns in the Pumsb* Data Set 100 1000 10000 100000 1e+06 


1e+07 1e+08 0.1 0.2 0.3 0.4 0.5 0.6 0.7 N um be r o f C ou nt ed P at te rn s Support Threshold Mafia Min_Conf=0.5 Min_Conf=0.7 Min_Conf=0.9 Figure 9. The number of MFI/MHP Patterns in the Pumsb Data Set of maximal hyperclique patterns is much easier to manage than that of maximal frequent patterns. Indeed, in realworld applications, it is dif?cult to interpret several million maximal frequent patterns. However, it is possible to interpret the results of maximal hyperclique pattern mining In addition, due to the memory limitation, we cannot extract maximal frequent patterns with MAFIA on the Pumsb data set if the support threshold is less than 0.4, as shown in Figure 7. In contrast, MHP can identify maximal hyperclique patterns when the support threshold is 0.1, if we set the h-con?dence threshold to 0.5. In other words, MHP has the ability to identify patterns which can be dif?cult to identify for MAFIA. Hence, MHP can better explore the pattern space and ?nd interesting patterns at low levels of support 6. Conclusions and Future Work In this paper, we present a two-phase Maximal Hyperclique Pattern \(MHP best features of both the BFS strategy and the DFS strategy. More speci?cally, we adapted DFS pruning methods such as equivalence pruning, to an apriori-like approach In addition, we proved the correctness and completeness of the MHP algorithm. Finally, our experimental results show that the MHP algorithm can be several orders of magnitude faster than standard maximal frequent pattern mining algorithms and has the ability to identify patterns at extremely low levels of support in dense data sets There are several directions for future work. First, in 


this paper, we only generate the size-2 patterns in the BFS phase. It will be interesting to investigate the impact on the performance if the ?rst phase is stopped at a deeper level Also, the projection is a very ef?cient method for ?nding patterns, especially for parallel implementation of pattern mining algorithms [1]. We plan to adapt the projection ideas into our algorithm and design an ef?cient parallel algorithm for mining maximal hyperclique patterns References 1] R. Agarwal, C. Aggarwal, and V. Prasad. A Tree Projection Algorithm For Generation of Frequent Itemsets. pages 350 371, Feb 2001 2] R. Agrawal, T. Imielinski, and A. Swami. Mining Association Rules between Sets of Items in Large Databases. In Proc. of the ACM SIGMOD Conference on Management of Data, pages 207–216,May 1993 3] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. In Proc. of the 20th Int’l Conference on Very LargeData Bases, 1994 4] R. Bayardo. Ef?ciently mining long patterns from databases In Proc. of the ACM SIGMOD Conference, 1998 5] R. Bayardo and R. Agrawal. Mining the Most Interesting Rules. In Proc. of the ACM SIGKDD Conference, 1999 6] D. Burdick, M. Calimlim, and J. Gehrke. Ma?a: AMaximal Frequent Itemset Algorithm for Transactional Databases. In Proc. of IEEE Conf. on Data Engineering, 2001 7] Y. Huang, H. Xiong, W. Wu, and Z. Zhang. A Hybrid Approach for Mining Maximal Hyperclique Patterns. In In Technical Report UTDCS-34-04, Department of computer science, University of Texas - Dallas, 2004 8] J.Han, J.Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In Proc. of the ACM SIGMOD International Conference on Management of Data, 2000 9] M.J.Zaki and C.Hsiao. ChARM: An ef?cient algorithm for closed itemset mining. In Proc. of 2nd SIAM International Conference on Data Mining, 2002 10] R.Rymon. Search through Systematic Set Enumeration. In Proc. Third Int’l Conference on Principles of Knowledge Representation and Reasoning, 1992 11] H. Xiong, M. Steinbach, P.-N. Tan, and V. Kumar. HICAP: Hierarchial Clustering with Pattern Preservation. In Proc. of 2004 SIAM International Conference on Data Mining \(SDM 12] H. Xiong, P.-N. Tan, and V. Kumar. Mining Strong Af?nity Association Patterns in Data Set with Skewed Support. In Proc. of the Third IEEE International Conference on Data Mining \(ICDM Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI 2004 1082-3409/04 $20.00 © 2004 IEEE 






Analyzing Time-Series Data by Fuzzy Data-Mining Technique Chun-Hao Chen Tzung-Pei Hong and Vincent S Tseng Abstract-Time series analysis has always been an important and interesting research field due to its frequent appearance in different applications In this paper we attempt to use the data mining technique to analyze time series Many previous studies on data mining have focused on handling binary-valued data Time series data however are usually quantitative values We thus extend our previous fuzzy mining approach for handling time-series data to find linguistic association rules The proposed approach first uses a sliding window 
to generate continues subsequences from a given time series and then analyzes the fuzzy itemsets from these subsequences Appropriate post-processing is then performed to remove redundant patterns Experiments are also made to show the performance of the proposed mining algorithm Since the final results are represented by linguistic rules they wir be friendlier to human than quantitative representation Index Terms-time series data mining fuzzy set association rule I INTRODUCTION T IME series analysis has always been an important and interesting research field due to its frequent appearance in different applications Some domains such as bioinformatics 2 13 medical 
treatment 27 and finance 7 especially emphasize it for making good prediction and decision A time series is usually composed of lots of data points each of which represents a value at a certain time In the past many approaches based on regression 22 neural networks 16 25 31 and other mathematical models 10 were proposed to analyze the time series Recently the data mining technique has also been used in analyzing time series For example Das et al proposed a mining algorithm to discovery basic shapes patterns from time series 12 The rule format found out was If A occurs 
then B occurs within time T where A and B were patterns and T was a time duration In addition Yuan et al proposed a quantitative movement-pattern mining algorithm Chun-Hao Chen is with the Department of Computer Science and Information Engineering National Cheng-Kung University Tainan 701 Taiwan e-mail chchen@idb.csie.ncku.edu.tw Tzung-Pei Hong is with the Department of Computer Science and Infornation Engineering National University of Kaohsiung Kaohsiung 811 Taiwan corresponding author phone 886+7+5919031 fax 886+7+5919049 e-mail tphong\(nuk.edu.tw Vincent S Tseng is with the Department of Computer Science and Information Engineering National Cheng-Kung University Tainan 701 Taiwan e-mail 
tsengsm\(mail.ncku.edu.tw for time series 30 The rule mined out was represented as If the rate of exchange of some stock rises 15 then its closing price may rise 10 Many previous studies on data mining have focused on handling binary-valued data Time series data however are usually quantitative values so designing a sophisticated data-mining algorithm able to deal with this type of data presents a challenge to workers in this research field Recently fuzzy set theory 33 has been used more and more frequently in intelligent systems because of its simplicity and similarity to human reasoning 20 The theory 
has been applied in fields such as manufacturing engineering diagnosis economics among others 15 20 24 29 Several fuzzy learning algorithms for inducing rules from given sets of data have been designed and used to good effect with specific domains Hong et al proposed a fuzzy mining approach 16 to find fuzzy interesting itemsets and fuzzy association rules from quantitative data The mining results obtained could be smooth due to the fuzzy membership characteristics In this paper we thus extend our previous approach 16 and propose a fuzzy mining algorithm for time series to find linguistic association rules The proposed approach first 
uses a sliding window to generate continues subsequences from a given time series and then analyzes the fuzzy itemsets from these subsequences Appropriate post-processing is also performed to remove redundant patterns Since the final results are represented by linguistic rules they will be friendlier to human than quantitative representation II REViEW OF RELATED MNING APPROACHES Data mining is most commonly used in attempts to induce association rules from transaction data 6 The goal is to discover important associations among items such that the presence of some items in a transaction will imply the presence of some other items To achieve this 
purpose Agrawal and his co-workers proposed several mining algorithms based on the concept of large itemsets to find association rules in transaction data 3-6 They divided the mining process into two phases In the first phase if the number of an itemset appearing in the transactions was larger than a pre-defined threshold value called minimum support the itemset was considered a large itemset In the second phase association rules were induced from the large itemsets found in the first phase All possible association combinations for each large itemset were formed and those with calculated confidence values larger than a 0-7803-9017-2/05/$20.00 C2005 IEEE 112 


predefined threshold called minimum confidence were output as association rules Das et al proposed a mining algorithm for time-series analysis 12 Their approach composed of two phases time-series discretization and association-rule generation In the discretization phase the approach used a clustering method to find basic shapes from time series and then transformed the time series into a discretized series based on the basic shapes found In the second phase an Apriori-like method was used to generate association rules The rules found out in the above way were different from traditional association rules The rule format was If A occurs then B occurs within time r which meant the occurrence of B was followed by A within T time units In addition Yuan et al proposed a mining algorithm for discovering quantitative movement pattern from time series A rule mined out might be like this If the rate of exchange of some stock rises 15 then its closing price may rise 10 As to fuzzy data mining Hong et al proposed several fuzzy mining algorithms to mine linguistic association rules from quantitative data 16 19 23 They transformed each quantitative item into a fuzzy set and used fuzzy operations to find fuzzy rules Their proposed algorithm focused on transaction data Cai et al proposed a weighted mining approach to reflect different importance to different items 8 Each item was attached a numerical weight given by users Weighted supports and weighted confidences were then defined to determine interesting association rules Yue et al then extended their concepts to fuzzy item vectors 32 In handling time-series data Song et al proposed a fuzzy stochastic fuzzy time series and its models by assuming its values are fuzzy sets 26 Chen et al proposed a two-factor time-variant fuzzy time series model to deal with forecasting problems 9 Au and Chan proposed a fuzzy mining approach to find fuzzy rules for time series classification 1 Watanabe exploited the Takagi-Sugeno model to build a time-series model 28 Thus in this paper we proposed the fuzzy association rules mining algorithm that to mine rules among data points in the given window size III MINING Fuzzy ASSOCIATIoN RULES FOR TIME SERIES In this section the proposed fuzzy mining algorithm integrates the fuzzy sets the Apriori mining algorithm and the time-series concepts to find out appropriate linguistic association rules is described below The proposedfuzy time-series mining algorithm INPUT A time series S with k data points a set of h membership functions for data values a predefined minimum support x a predefined minimum confidence 2 and a sliding-window size w OUTPUT A set of fuzzy association rules with confidence values from S STEP 1 Transform the time series S into a set of subsequences W\(S according to the sliding-window size w That is W\(S  s s  d4 d   d  1 to k-w+13 where dp is the value of the p-th data point in S STEP 2 Transform thej-th i  1 to w quantitative value Vpj in each subsequence sp p  1 to k-w 1 into a fuzzy set fpj represented as pLL  fpj 2   fpjh Rjl Rj2 Rjh using the given membership functions where Rjl is the l-th fuzzy region of the j-th data point in each subsequence h is the number of fuzzy memberships and fpj is vpj's fuzzy membership value in region Rjl Each Rjl is called a fuzzy item STEP 3 Calculate the scalar cardinality of each fuzzy item Rjl as k-w+1 count1 Efpjl p=1 STEP 4 Collect each fuzzy item to form the candidate l-itemsets C1 STEP 5 Check whether the support value  countjl  k-w+1 of each Rjl p j p+w-1 and I  I  h in C1 is larger than or equal to the predefined minimum support value a If Rjl satisfies the above condition put it in the set of large 1-itemsets L1 That is LI  Rjl countjl a j<p+w-1 and I I<h STEP 6 IF L1 is not null then do the next step otherwise exit the algorithm STEP 7 Set r  1 where r is used to represent the number of fuzzy items in the current itemsets to be processed STEP 8 Join the large r-itemsets Lr to generate the candidate r+1 Cr+i in a way similar to that in the apriori algorithm 6 except that two items generated from the same order of data points in subsequences cannot simultaneously exist in an itemset in Cr+i Restated the algorithm first joins Lr and Lr under the condition that r-1 items in the two itemsets are the same and the other one is different It then keeps in Cr+j the itemsets which have all their sub-itemsets of r items existing in Lr and do not have any two items Rjp and Rjq of the same j STEP 9 Do the following substeps for each newly formed r+l I with fuzzy items II I2  Ir+j in Cr+j a Calculate the fuzzy value of I in each subsequence sp as fis f PA f P A Af  where fP is the membership value of fuzzy item Ij in sp If the minimum operator is used for the intersection then r+1 f-SP  Minfijp b Calculate the count of I in all the subsequences as k-w+1 count ZfIp p=1 c If the support  count1 k-w+1 of Iis larger than or equal to the predefined minimum support 113 


THIS EXAMPLE 1 6 9 8 4 3 7 9 6 4 2 4 7 8 3 The time series in Table I contains 15 data points Each data point represents a value at a certain time For example the second data point in the time series means the value obtained at time 2 is 6 Assume the fuzzy membership functions for the data values are defined as shown in Fig 1 There are three fuzzy membership functions Low Middle and High used in this example For the time series given in Table I the proposed mining algorithm proceeds as follows STEP 1 The given time series is first transformed into a set of subsequences according to the predefined window size Assume the given window size is 5 There are totally 11 15-5+1 subsequences obtained from the time series The results are shown in Table II STEP 2 The data values in each subsequence are then transformed into fuzzy sets according to the membership fimctions given in Fig 1 Take the first value v11 1 in the subsequence sj as an example The value 1 is converted into the fuzzy set where Ai.term is a fuzzy region of the i-th data in the subsequences and is called a fuzzy item This step is repeated for the other data points and subsequences Membership value Low Middle High 0 0 2 5 6 9 data value Fig 1 The membership fimctions used in this example STEP 3 The scalar cardinality of each fuzzy item is calculated as its count value Take the fuzzy item A Low as an example Its scalar cardinality  1  0  0 0  0.33 0.67  0 0 0 0.33 1  3.33 This step is repeated for the other fuzzy items STEP 4 All the fuzzy items are collected as the candidate l-itemsets TABLE II THE SUBSEQUENCES OBTAINED FROM THE GIVEN TIME SERIES FOR W  5 SI 1,6,9,8,4 s7 7,9,6,4,2 52 6,9,8,4,3 S8 9,6,4,2,4 S3 9,8,4,3,7 S9 6,4,2,4,7 S4 8,4 3 7 9 Sio 4 2,4 7 8 S5 4 3 7 9 6 SI 2,4 7 8 3 valuea put it in Lr STEP 10 IF Lr+j is null then do the next step otherwise set r  r 1 and repeat STEPs 8 to 10 STEP 11 Shift each large itemsets II I2  Iq q  2 into II I2   Iq such that the fuzzy region Rjl in I will become RI in II and a fuzzy region Ri in the other items becomes R\(i-+j,t where Rj1 is the l-th fuzzy region of thej-th data point in each subsequence STEP 12 Remove redundant large itemsets from the results after STEP 11 STEP 13 Construct the association rules for each large q-itemset I after STEP 12 with items II I2  Iq q  2 using the following substeps a Form each possible association rule as follows IIA...AIk IAIk+lA...AAIq  Ik 1kl toq b Calculate the confidence values of all association rules by the following formula k-w+1 USED IN p=1 k-w+l E\(ffsPA  A fstP f4P A  fA  p=l STEP 14 Output the association rules with confidence values larger than or equal to the predefined confidence threshold A Note that in STEP 2 the transformation from data values to fuzzy sets in each subsequence can be simplified by removing the first fuzzy set from the previous subsequence and add the fuzzy set derived from the last data point in the current one IV AN EXAMPLE In this section a simple example is given to show how the proposed algorithm can generate fuzzy association rules from the given time series Assume the data points in the time series are given as shown in Table I TABLE I THE TIME SERIES s6 3 7 9 6 4 STEP 5 For each fuzzy item its count is checked against the predefined minimum support value a Assume in this example ais set at 30 Since the support values of Al.Low A,.Middle A2.Middle A3.Middle A3.High A4.Middle A5.Low and A5.Middle are all larger than 30 these items are thus put in LI Table III TABLE III THE SET OF LARGE 1-ITEMSETS Li FOR THIS EXAMPLE A1.Low 0.303 A3.High 0.303 A1.Middle 0.425 A4.Middle 0.485 A2.Middle 0.485 A5.Low 0.303 A3.Middle 0.455 A5.Middle 0.485 STEP 6 Since LI is not null the next step is then done STEP 7 Set r=1 where r is the number of fuzzy items in the current itemsets to be processed STEP 8 In this step the candidate set Cr+l is generated from Lr C2 is then first generated from LI as follows A1.Low A2.Middle A1.Low A3.Middle A,.Low A3.High A1.Low A4.Middle A,.Low A5.Low A,.Low A5.Middle Aj.Middle A2.Middle Al.Middle A3.Middle Al.Middle 114 


A3.High A1.Middle A4.Middle Ai.Middle As.Low A1.Middle A5.Middle A2.Middle A3.Middle A2.Middle A3.High A2.Middle A4.Middle A2.Middle As.Low A2.Middle As.Middle A3.Middle A4.Middle A3.Middle As.Low A3.Middle As.Middle A3.High A4.Middle A3.High As.Low A3.High As.Middle A4.Middle As.Low and A4.Middle A s.Middle Note that no two fuzzy items with the same Ai are put in a candidate 2-itemset STEP 9 The following substeps are done for each newly formed candidate itemset a The fizzy membership value of each candidate itemset in each subsequence is calculated Here assume the minimum operator is used for the intersection Take Aj.Low A2.Middle as an example The derived membership value for this candidate 2-itemset in sp is calculated as min\(I.0 0.67 The results for the other subsequences are shown in Table IV TABLE IV THE MEMBERSHIP VALUES FORA1.LOW n A2.MIDDLE 1 1 1 D__1.0 2 0 0 0.0 3 0 0.33 0.0 4 0 0.67 0.0 5 0.33 0.33 0.33 6 0.67 0.67 0.67 7 0 0 0.0 8 0 1 0.0 9 0 0.67 0.0 10 0.33 0 0.0 11 1 0.67 0.67 The results for the other 2-itemsets can be derived in a similar way b The scalar cardinality count of each candidate 2-itemset in the time series is then calculated in the same way c The supports of the above candidate itemsets are then calculated and compared with the predefined minimum support 30 In this example only the two itemsets A1.Middler'A4.Middle and A2.MiddlerA5.Middle satisfy this condition They are thus kept in L2 STEP 10 Since L2 is not null in the example r  r  1  2 STEPs 7 to 9 are then repeated to find L3 C3 is first generated from L2 In this example no candidate 3-itemsets can be formed L3 is thus an empty set STEP 11 then begins STEP 11 The large 2-itemset A2.Middle n As.Middle is then shifted into AI.Middle r A4.Middle since its first region occurs in A2 STEP 12 The two large itemsets A1.Middle n A4.Middle and A 1.Middle r A4.Middle are the same and only one of them is kept STEP 13 The association rules for each large itemset are then constructed by the following substeps a All the possible association rules are first formed from the large itemsets In this example only the large 2-irmeset A,.Middle n A4.Middle exists The following two possible association rules are then formed 1 If AI  Middle then A4  Middle 2 If A4  Middle then AI  Middle b The confidence values of the above association rules are then calculated Take the first association rule as an example The fuzzy counts of A Middle and A4.Middle are calculated as 4.67 and 3.34 The confidence of the association rule  If A1  Middle then A4  Middle is then calculated as 11 A Middle n A4 Middle 3.34 p   0.d715 AI.Middle  4.67 p 1 Results for the other rule is shown below  If A4  Middle then Al  Middle  with a confidence of 0.626 STEP 14 The confidence values of the above association rules are then compared with the predefined confidence threshold 2 Assume A is set at 0.65 The following rule is thus output to users 1 If AI  Middle then A4  Middle with a confidence factor of 0.72 This rule can be easily explained as if the value of a data point is middle then the value of a data point after three time units will be also middle with a high probability The above rule can thus be used as the meta-knowledge concerning the given time series V EXPERIMENTAL RESULTS AND DIscussIoNs In this section the experiments made to show the performances of the proposed method are described They were implemented in Visual C 6.0 at a personal computer with Intel Pentium IV 3.00GHz and 512MB RAM The dataset consisted of the first 100 stock prices in Japan Nikkei 225 market 1 1 from June 30 1989 The sliding-window size is set at5 Experiments were first made to show the relationships between numbers of association rules and minimum support values along with different minimum confidence values Results are shown in Fig 2 From Fig 2 it is easily seen that the numbers of association rules decreased along with the increase in minimum support values Also the curve of numbers of association rules with larger minimum confidence values was smoother than that of those with smaller minimum confidence values meaning that the minimum support value had a large effect on the number of association rules derived from small minimum confidence values The relationship between numbers of association rules and minimum confidence values along with various minimum support values is shown in Fig 3 From Fig 3 it is easily seen that the numbers of association rules decreased along with an increase in minimum confidence 115 


0 0.1 0.15 0.2 0.25 0.3 coif=0 3 wnf=0.5  coi60.7 conflJ.9 confl _ Fig 2 The relationship between numbers of rules and minimum supports of numbers of rules are not high At last experiments were made to compare the numbers of rules generated with and without Step 12 of removing redundant large itemsets The results are shown in Fig 5 From Fig 5 it can be easily observed that removing redundant large itemsets during the mining process has its efficacy Without this step too many redundant rules may be generated and may make users confused 250 to 200  w=9 l I we expect when the size of sliding-windows increases the number of rules also increases However the increasing ratios VI CONCLUSION AND FuTuRE WORKS In this paper we have attempted to use the data mining technique to analyze time series We proposed a fuzzy time-series mining algorithm that integrates the fuzzy sets the Apriori mining algorithm and the time-series concepts to find out appropriate linguistic association rules The proposed approach first uses a sliding window to generate continues subsequences from a given time series and then analyzes the fuzzy itemsets from these subsequences Appropriate post-processing is then performed to remove redundant patterms Experiments are also made to show the relationships between numbers of association rules minimum supports and minimum confidences Since the final results are represented by linguistic rules they will be more friendly to human than quantitative representation The rules thus mined exhibit quantitative regularity in time series and can be used to provide some suggestions to appropriate supervisors They can be used in two ways prediction and post-analysis For instance if a rule like IfA1 is Low and A3 is Middle then A5 is High  is mined it can be used to predict the behavior ofA5 from A and A3 On the contrary if a rule like If Al is Low and A5 is High then A3 is Middle  is mined it can be used for post-analysis The proposed approach thus provides another altemative to analyze time series Although the proposed method works for time series it is just a beginning There is still much work to be done in this field Our method assumes that the membership functions are known in advance In 17 18 we proposed some fuzzy leaming methods to automatically derive the membership functions In the future we will attempt to dynamically adjust the membership functions in the proposed mining algorithm to avoid the bottleneck of membership-function acquisition We will also continuously attempt to enhance the mining algorithm for more complex problems 116 so 40 n 30 2 20 10 0 0.3 O.S 0.7 0.9 Cca,Edmoe In s0 40 j 30 0 60 10 0 1 40 M 30 20 10 0.3 0.5 0.7 0.9 Confidence 4-5 uw 6 A w=7 values The curve of numbers of association rules with larger minimum support values was smoother than that for smaller minimum support values meaning that the minimum confidence value had a larger effect on the number of association rules when smaller minimum support values were used All of the various curves approximate to 0 as the minimum confidence value approached 1 50 40 I 30 IE 20 10 0,7 Confidence Fig 5 The numbers of rules between with and without removing redundant step 0 50 5.9 1 With 9emoVinz RaeJan-.Step Wi&tht RnUt RMddantStep C.3 0.5 sup=0.1 n sup=].15 sup-0.20 rsLp=0.25 x op=0.30 Fig 3 The relationship between numbers of rules and minimum confidences Fig 4 The relationship between numbers of rules and minimum confidences among different sliding-windows Fig 4 shows numbers of rules along with different sliding-window sizes when the minimum support is set at 20 As 


ACKNOWLEDGMENT This research was supported by the National Science Council of the Republic of China under contract NSC93-2213-E 390-001 REFERENCES 1 W H Au and K C C Chan Mining fuzzy rules for time series classification The 2004 IEEE International Conference on Fuzzy Systems Vol 1 2004 pp 239-244 2 J Aach and G Church Aligning gene expression time series with time warping algorithms Bioinformatics Vol 17 2001 pp 495-508 3 R Agrawal T Imielinksi and A Swami Mining association rules between sets of items in large database The 1993 ACM SIGMOD Conference Washington DC USA 1993 pp.207-216 4 R Agrawal T Imielinksi and A Swami Database mining a performance perspective IEEE Transactions on Knowledge and Data Engineering Vol 5 No 6 1993 pp 914-925 5 R Agrawal R Srikant and Q Vu Mining association rules with item constraints The Third International Conference on Knowledge Discovery in Databases and Data Mining Newport Beach California 1997 pp 67-73 6 R Agrawal and R Srikant Fast algorithm for mining association rules The International Conference on Very Large Databases 1994 pp 487-499 7 F L Chung T C Fu R Luk and V Ng Evolutionary time series segmentation for stock data mining 2002 IEEE International Conference on Data Mining 9-12 Dec 2002 pp:83-90 8 C H Cai W C Fu C H Cheng and W W Kwong Mining association rules with weighted items The International Database Engineering and Applications Symposium 1998 pp 68-77 9 S M Chen J R Hwang Temperature prediction using fuzzy time series IEEE Transactions on Systems Man and Cybernetics-Part B Cybernetics Vol 30 No 2,2000 pp 263-275 10 B Chiu E Keogh S Lonardi Research track Probabilistic discovery of time series motifs Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining 2003 11 S H Chen C H Yeh Using Genetic Programming to Model Volatility in Financial Time Series The Case of Nikkei 225 and S&P 500 The SecondAnnual Conference on Genetic Programming 1997 pp 58-63 12 G Das K Lin H Mannila G Renganathan P Smyth Rule discovery from time series In proceedings of the 4 the International Conference on Knowledge Discovery and Data Mining New York NY 1998 pp 16-22 13 S Erdal 0 Ozturk D Armbruster H Ferhatosmanoglu and W.C Ray A time series analysis of microarray data Fourth IEEE Symposium on Bioinformatics andBioengineering 2004 pp 366-375 14 W J Frawley G Piatetsky-Shapiro and C J Matheus Knowledge discovery in databases an overview The AAAI Workshop on Knowledge Discovery in Databases 1991 pp 1-27 15 I Graham and P L Jones Expert Systems Knowledge Uncertainty and Decision Chapman and Computing Boston 1988 pp 1 17-158 16 T P Hong C S Kuo and S C Chi Mining association rules from quantitative data Intelligent Data Analysis Vol 3 No 5 1999 pp 363-376 17 T P Hong C H Chen Y L Wu and Y C Lee  Using divide-and-conquer GA strategy in fuzzy data mining  The Ninth IEEE Symposium no 3 1993 pp 269-277 27 J P C Valente and L L Chavarrias Discovering similarpatterms in time series Proceedings of the sixth ACMSIGKDD international conference on Knowledge discovery and data mining 2000 pp 497-505 28 N Watanabe A fuizzy rule based time series model IEEE Annual Meeting of the Fuzzy Information Vol 2 2004 pp 936-940 29 R.Weber Fuzzy-ID3 a class of methods for automatic knowledge acquisition The Second International Conference on Fuzzy Logic and Neural Networks Iizuka Japan 1992 pp 265-268 30 X J Yuan Y N Kang X R Wang C J Yu Mining association rules of quantitative movement pattem in databases 2001 International Conferences on Info-tech and Info-net Vol 3 2001 pp 32-37 31 Y Yang and G Liu Multivariate time series prediction based on neural networks applied to stock market 2001 IEEE International Conference on Systems Man and Cybernetics Vol 4 2001 pp 2680 32 S Yue E Tsang D Yeung and D Shi Mining fizzy association rules with weighted items The IEEE International Conference on Systems Man and Cybernetics 2000 pp 1906-1911 33 L A Zadeh Fuzzy sets Information and Control Vol 8 No 3 1965 pp 338-353 117 on Computers and Communications 2004 18 T P Hong C H Chen Y L Wu and Y C Lee  Fining active membership functions in fizzy data mining  The Fourth Workshop on the Foundation of Data Mining and Discovery in The 2004 IEEE International Conference on Data Mining 2004 pp 65-71 19 T P Hong C S Kuo and S C Chi Trade-off between time complexity and number of rules for fuzzy mining from quantitative data International Journal of Uncertainty Fuzziness and Knowledge-based Systems Vol 9 No 5,2001 pp 587-604 20 A Kandel Fuzzy Expert Systems CRC Press BocaRaton 1992 pp.8-19 21 S T Li and Y P Chen Natural partitioning-based forecasting model for fuzzy time-series 2004 IEEE International Conference on Fuzzy Systems Vol 3 2004 pp.1355-1359 22 H Lei and V Govindaraju Regression time warping for similarity measure of sequence The Fourth International Conference on Computer and Information Technology September 2004 pp 826-830 23 Y C Lee T P Hong and W Y Lin Mining fuzTy association rules with multiple minimum supports using maximum constraints Lecture Notes in Computer Science Vol 3214 2004 pp 1283-1290 24 E H Mamdani Applications of fuzzy algorithms for control of simple dynamic plants  IEEE Proceedings 1974 pp.1585-1588 25 Y Q Peng Y Zhang and H S Tian Research of time series pattern finding based on artificial neural network 2003 International Conference on Machine Learning and Cybernetics Vol 3 2003 pp 1385-1388 26 Q Song B S Chissom Fuzzy time series and its models Fuzzy Sets System Vol 54 


References Knowledge and Information Systems Proc of the 14th Intl Joint Conf on AI Proc of the 14th Intl Conf on Data Engineering Proc of the 9th Intl Conf on Cooperative Information Systems Comm of ACM Proc of the 15th Intl Symposium on Foundations of Intelligent Systems Proc of the 10th Intl Conf on Travel Behaviour Research Data Knowledge Engineering Journal of Information and Control  pages 924\320 929 1995 8 D  O la ru a n d B  S mith  M o d e llin g D a ily Ac ti v ity Sc h e d u le s with Fuzzy Logic In 1 R  C ool e y  B  M obasher  a nd J S r i v ast a v a  D at a P r e par a t i o n for Mining World Wide Web Browsing Patterns a c 5 0 0 0 Formal Concept Analysis Mathematical Foundations User Modeling and User-Adapted Interaction 0 1 2 4 Figure 4 Performance results based on satisfaction Proc of the 8th Intl Symposium on Temporal Representation and Reasoning     1\(1\:5\32032 1999 2 M  E irin a k i a n d M  V a z ir g ia n n is We b M in in g f o r We b P e r sonalization  3\(1\:1\32027 2003 3 B G a n te r a n d R W ille   40\(3\:77\32087 1997 5 D  L i a nd J S  D e ogun D i sco v e r i ng Par t i a l P er i odi c S equential Association Rules with Time Lag in Multiple Sequences for Prediction In  2003  B  O zden S  R amasw amy  and A S i l b erschat z C ycl i c Association Rules In  13\(4\:311\320372 2003  C S h ahabi  F  B Kashani  Y  S  C hen and D  M cL eod Yoda An Accurate and Scalable Web-Based Recommendation System In  42\(2\:189\320222 2002  L  A  Z a deh F u zzy S e t s   8:338\320353 1965 u13 u36 u48 u82 0 10 20 30 40 50 60 70 80 90 100 1 23456 Number of Personalized Resources Satisfaction u13 u36 u48 u82 0 10 20 30 40 50 60 70 80 90 100 1 23456 Number of Personalized Resources Satisfaction u13 u36 u48 u82 0 10 20 30 40 50 60 70 80 90 100 1 23456 Number of Personalized Resources Satisfaction u13 u36 u48 u82  Springer-Verlag 1997 4 J  A  K o n s ta n  B N M ille r  D M a ltz  J  H e r lo c k e r  L  G o r don and J Riedl Grouplens Applying Collaborative Filtering to Usenet News  pages 332\320341 2005 6 Y  L i  P  N i ng X  S  W a ng and S  J aj odi a D i sco v e r i ng Calendar-Based Temporal Association Rules In  pages 111\320118 2001 7 H  L ie b e rma n  L e tiz ia  A n A g e n t th a t Assists W e b Bro w sing In  pages 412\320421 1998  D  P i er r a k o s G  Pal i our as C  P apat heodor ou and C  D  Spyropoulos Web Usage Mining as a Tool for Personalization A Survey  pages 418\320432 2001  G  S t umme R  T aoui l  Y  B a st i d e N  Pasqui er  a nd L Lakhal Computing Iceberg Concept Lattices with TITANIC b d d  d  d  d  0 10 20 30 40 50 60 70 80 90 100 1 23456 Number of Personalized Resources Satisfaction ACM TOIT alization using periodic access p atterns of individual users Different from non-periodic approaches the proposed approach can ef\336ciently determine which resources a user is most probably interested in during a given period without the use of the user\325s current access information This makes it possible to perform more costly personalized resource preparation in advance rath er than in real-time The experimental results have shown that the proposed approach has achieved very effective web personalization evaluated by the applicability and satisfaction measures for the prede\336ned period conditions 


G f d O??Et c f d tb ? f} g ? h c h d h Figure 2. A frequency tree example After we built a frequency tree, we then use the Quick-split technique to calculate the maximal frequent sets The Quick-split algorithm is given here Input: A frequency tree r Output: An array of BitSets representing Itemsets Quick-split\(Tree r 1: if\(r is leaf   2: for all x E r.subs do 3: subres[x] = Quick-split\(x x 4: result =newBSO 5: for all x E r.subs do 6: result = result &amp; subres[x 7: remove b E result, b.size:::; k 8: return result To speed up calculation, an itemset is represented by a bitset with 0 and I for specifying the absence or presence of an item at a corresponding position respectively. The Quick-split performs a calculation on a frequency tree and returns an array of bitsets, which represent a group of decomposed itemsets. Splitting is accomplished by calculating bitset results in a bottom  up fashion in the tree. In the above example, we have 8 items a, b, . . .  , h corresponding to positions 0-7 in a 8bit bitset. So p.JS = abcdefgh = {I III I Ill}; abcd ll1 10000}; bcdefgh = {OllillII}. The size of the bitset is the number of items in p.JS which is usually much smaller than the total item size in the dataset For the frequency tree in Figure 2, for the itemset abcdefgh and infrequent 3-itemsets {aef, aeg, aeh, afg ajh, agh, abe, abf, abg, abh, ace, acf, acg, ach, ade adf, adg, adh} , Quick-split returns the possible maximal frequent sets {abcd, bcdefgh The PD Algorithm Input: transaction dataset T Output: frequent patterns PD \( transaction-set T I : D 1 = {&lt;t, 1&gt;1 t E T}; k= I 2: while \(Dk   3: for all p E Dk do II counting 4: for all k-itemset s c;;; p.JS do 5: Sup\(s IDk 6: decide Lk and ?Lk Ilbuild Dk 7: Dk+]= PD-rebuild\(Dk, Lk , ?Lk 8: k 9: end 10: Answer = u Lk As shown above, PD is the top-level function that accepts a transaction dataset as its input and returns the union of all frequent sets as the result. At the kth pass steps 3-6 count for every k itemset of each pattern in Dk and then determine the frequent and infrequent sets Lk and ? Lk; step 7 uses Dk , Lk and ?Lk to rebuild Dk PD stops when Dk is empty The PD-rebuild Algorithm Input: Dataset Db frequent Lk, infrequent ?Lk Output: Dataset DB PD-rebuild \(Dlo Llo ?Lk 1: Dk  ht = an empty hash table 2: for all p E Dk do begin 3: / / q k, ?q k can be taken from previous counting qk={sls E p. JS nLk}; ?qk={tltE p. JS n ?Lk 4: u = PD-decompose\(p.JS, ?qk 5: v ={s E ul s is k-item independent in u 


5: v ={s E ul s is k-item independent in u 6: add &lt;u-v, p.Occ&gt; to Dk+1 7: for all s E v do 8: if sin ht then ht. s. Occ += p. Occ 9: else put &lt;S,p.Occ&gt; to ht 10: end 11: Dk+] = Dk+] u {p E ht The PD-rebuild shown above is to determine DB by Dk, Lk and ?Lk' For each pattern p in Db step 3 computes its qk and ?qk; step 4 calls PD-decompose algorithm to decompose p by ?qk. Note that qk is not used here for decomposing p. In steps 5 to 9, we use pattern separation rule to separate p. In steps 7 to 9 PD-rebuild merges the patterns separated from p with their identical ones via a hash table ht. Since PD follows the pattern decomposition rule to decompose patterns and the pattern separation rule for merging identical patterns that yield same support, the answers generated by PD are correct 3. Comparative Study Our experiments were performed on a 600 MHz Pentium PC machine with 256 MB main memory running on Microsoft Windows XP. All three algorithms were written in C++ language. The test dataset was generated in the same fashion as the IBM Quest project . We used dataset T25.I10.DIOOK . In the dataset, the number of items N was set to 1000. The corruption level for a seed large itemset was fixed obtained from a normal distribution with mean 0.5 and variance 0.1. In the dataset, half of all items were corruptible. In the dataset, the average transaction size ITI and average maximal potentially frequent itemset size III are set to 25 and 10, respectively, while the number of transactions IDI in the dataset is set to lOOK 3.1. Comparison of PD with DCP  Pattern Decomposition algorithm does not need to generate candidate sets which are the main improvement on DCP; the reduced dataset contains only itemsets whose subsets are all frequent  PD generates all frequent sets whether it is not certain in DCP. PD significantly reduces the dataset in each pass by reducing the number of transactions and their size to give better performance. So counting time is clearly less than DCP in a reduced dataset  PD is much more scalable than the DCP 8000 7000 6000 5000 lt;.i OOO E f OOO 2000 Minimum Support PD DCP Figure 3. Performance comparison 8 6 4 2 PD DCP owa_L??_L??_L??_L??_L??_L?? o 50 100 150 200 250 Number of Transactions\(k Figure 4. Scalability comparison Figure 3 shows the execution times for different 


Figure 3 shows the execution times for different minimum support. We can see that PD is about 15 times faster than DCP with minimal support at 2% and about 8 times faster than DCP at 0.25%. In Figure 4, to test the scalability with the number of transactions experiments on dataset D are used. The support threshold is set to 0.75 3.2. Comparison of PD with PIP  Predictive item pruning FP-tree algorithm has a complicated data structure in comparison to PD algorithm  PD works by decomposing transactions into short itemsets. Then regular patterns are combined together. Hence data set is being reduced at every pass. As a result, space efficiency is improved. On the other hand, PIP FP-tree, although prunes infrequent items, its hit ratio is not as efficient as PD. So, obviously its space efficiency is not better than PD  As PD always concerns with the current data set less time is required in comparison to PIP FP-tree algorithm  PD is more scalable than the PIP 100r  E F  60 40 0 20 PD  PIP Minimum Support Figure 5. Performance comparison 500 r 400 300 E F  oo 0 100     Number of Transactions\(k   PD  PIP   Figure 6. Scalability comparison 160 In Figure 5, both PIP and PD have good performance on D. But PIP takes substantially more time when minimum support in the range from 0.6% to 2%. When minimum support is less than 0.6%, the number of frequent patterns increased quickly and thus the execution times are comparable. In Figure 6, we compared the scalability of PD with PIP on the dataset D with minimum support = 0.75%. PD was clearly more scalable than that of PIP 4. Conclusion The programs were implemented in C++ very efficiently. Since really large datasets or data warehouse was not available for us, we run the programs of these three algorithms by using test datasets. So performance comparisons are not the absolute values. The results can vary on other 


absolute values. The results can vary on other computers. But it can be guaranteed that performance ratio of the algorithms will remain the same After making the comparisons with sample data, we came to the conclusion that PD algorithm performs significantly better than the other two especially with larger datasets. PD outperforms DCP and PIP regarding running time. On the other hand, since PD reduces the dataset, mining time does not necessary increase as the number of transactions increases and experiments reveals that PD has better scalability than DCP and PIP. So, PD has the ability to handle the large data mine in practical field like market basket analysis and medical report documents mining 5. References 1] R. Agrawal and R. Srikant, "Fast algoritlnns for mining association rules", VLDB'94, pp. 487-499 2] R. J. Bayardo, "Efficiently mining long patterns from databases", SIGMOD'98, pp.85-93 3] J. Pei, J. Han, and R. Mao, "CLOSET: An Efficient Algorithm for Mining Frequent Closed Itemsets \(PDF Proc. 2000 ACM-SIGMOD International Workshop on Data Mining and Knowledge Discovery, Dallas, TX, May 2000 4] Qinghua Zou, Henry Chiu, Wesley Chu, David Johnson, "Using Pattern Decomposition\( PD Finding All Frequent Patterns in Large Datasets", Computer Science Department University of California - Los Angeles 5] J. Han, J. Pei, and Y. Yin, "Mining Frequent Patterns without Candidate Generation \(PDF  SIGMOD International Con! on Management of Data SIGMOD'OOj, Dallas, TX, May 2000 6] S. Orlando, P. Palmerini, and R. Perego, "The DCP algoritlnn for Frequent Set Counting", Technical Report CS2001-7, Dip. di Informatica, Universita di Venezia 2001.Available at http://www.dsi.unive.itl?orlando/TR017.pdf 7] MD. Mamun-Or-Rashid, MD.Rezaul Karim, "Predictive item pruning FP-tree algoritlnn", The Dhaka University  Journal of Science, VOL. 52, NO. 1, October,2003, pp. 3946 8] Park, J. S., Chen, M.-S., and Yu, P. S, "An Effective Hash Based Algoritlnn for Mining Association Rules", Proc ofthe 1995 ACM-SIGMOD Con! on Management of Data 175-186 9] Brin, S., Motwani, R., Ullman, J., and Tsur, S, "Dynamic Itemset Counting and Implication Rules for Market Basket Data", In Proc. of the 1997 ACM-SIGMOD Conf On Management of Data, 255-264 10] Zaki, M. J., Parthasarathy, S., Ogihara, M., and Li, W New Algoritlnns for Fast Discovery of Association Rules In Proc. of the Third Int'l Con! on Knowledge Discovery in Databases and Data Mining, 283-286 11] Lin, D.-I and Kedem, Z. M., "Pincer-Search: A New Algoritlnn for Discovering the Maximum Frequent Set", In Proc. of the Sixth European Conf on Extending DatabaseTechnology, 1998 12] R. Ramakrishnan, Database Management Systems University of Wisconsin, Madison, WI, USA; International Edition 1998 pre></body></html 


tors such as union, di?erence and intersection are de?ned for pairs of classes of the same pattern type Renaming. Similarly to the relational context, we consider a renaming operator ? that takes a class and a renaming function and changes the names of the pattern attributes according to the speci?ed function Projection. The projection operator allows one to reduce the structure and the measures of the input patterns by projecting out some components. The new expression is obtained by projecting the formula de?ning the expression over the remaining attributes [12 Note that no projection is de?ned over the data source since in this case the structure and the measures would have to be recomputed Let c be a class of pattern type pt. Let ls be a non empty list of attributes appearing in pt.Structure and lm a list of attributes appearing in pt.Measure. Then the projection operator is de?ned as follows ls,lm c id s m f p ? c, p = \(pid, s, d,m, f In the previous de?nition, id ing new pids for patterns, ?mlm\(m projection of the measure component and ?sls\(s ned as follows: \(i s usual relational projection; \(ii sls\(s and removing the rest from set elements. The last component ?ls?lm\(f computed in certain cases, when the theory over which the formula is constructed admits projection. This happens for example for the polynomial constraint theory 12 Selection. The selection operator allows one to select the patterns belonging to one class that satisfy a certain predicate, involving any possible pattern component, chosen among the ones presented in Section 5.1.1 Let c be a class of pattern type pt. Let pr be a predicate. Then, the selection operator is de?ned as follows pr\(c p Join. The join operation provides a way to combine patterns belonging to two di?erent classes according to a join predicate and a composition function speci?ed by the user Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE Let c1 and c2 be two classes over two pattern types pt1 and pt2. A join predicate F is any predicate de?ned over a component of patterns in c1 and a component of patterns in c2. A composition function c pattern types pt1 and pt2 is a 4-tuple of functions c cStructureSchema, cDataSchema, cMeasureSchema, cFormula one for each pattern component. For example, function cStructureSchema takes as input two structure values of the right type and returns a new structure value, for a possible new pattern type, generated by the join. Functions for the other pattern components are similarly de?ned. Given two patterns p1 = \(pid1, s1, d1,m1, f1 p2 = \(pid2, s2, d2,m2, f2 p1, p2 ned as the pattern p with the following components Structure : cStructureSchema\(s1, s2 Data : cDataSchema\(d1, d2 Measure : cMeasureSchema\(m1,m2 Formula : cformula\(f1, f2 The join of c1 and c2 with respect to the join predicate F and the composition function c, denoted by c 1   F  c  c 2   i s  n o w  d e  n e d  a s  f o l l o w s    F  c  c 2     c  p 1   p 2   p 1    c 1  p 2    c 2  F   p 1   p 2     t r u e   5.1.3. Cross-over database operators OCD Drill-Through. The drill-through operator allows one to 


Drill-Through. The drill-through operator allows one to navigate from the pattern layer to the raw data layer Thus it takes as input a pattern class and it returns a raw data set. More formally, let c be a class of pattern type pt and let d be an instance of the data schema ds of pt. Then, the drill-through operator is denoted by c c Data-covering. Given a pattern p and a dataset D sometimes it is important to determine whether the pattern represents it or not. In other words, we wish to determine the subset S of D represented by p \(p can also be selected by some query the formula as a query on the dataset. Let p be a pattern, possibly selected by using query language operators, and D a dataset with schema \(a1, ..., an ible with the source schema of p. The data-covering operator, denoted by ?d\(p,D responding to all tuples in D represented by p. More formally d\(p,D t.a1, ..., t.an In the previous expression, t.ai denotes a speci?c component of tuple t belonging to D and p.formula\(t.a1, ..., t.an instantiated by replacing each variable corresponding to a pattern data component with values of the considered tuple t Note that, since the drill-though operator uses the intermediate mapping and the data covering operator uses the formula, the covering ?\(p,D D = ?\(p not be equal to D. This is due to the approximating nature of the pattern formula 5.1.4. Cross-over pattern base operators OCP Pattern-covering. Sometimes it can be useful to have an operator that, given a class of patterns and a dataset, returns all patterns in the class representing that dataset \(a sort of inverse data-covering operation Let c be a pattern class and D a dataset with schema a1, ..., an pattern type. The pattern-covering operator, denoted as ?p\(c,D all patterns in c representing D. More formally p\(c,D t.a1, ..., t.an true Note that: ?p\(c,D p,D 6. Related Work Although signi?cant e?ort has been invested in extending database models to deal with patterns, no coherent approach has been proposed and convincingly implemented for a generic model There exist several standardization e?orts for modeling patterns, like the Predictive Model Markup Language \(PMML  eling approach, the ISO SQL/MM standard [2], which is SQL-based, and the Common Warehouse Model CWM  ing e?ort. Also, the Java Data Mining API \(JDMAPI 3] addresses the need for a language-based management of patterns. Although these approaches try to represent a wide range of data mining result, the theoretical background of these frameworks is not clear. Most importantly, though, they do not provide a generic model capable of handling arbitrary cases of pattern types; on the contrary only a given list of prede?ned pattern types is supported To our knowledge, research has not dealt with the issue of pattern management per se, but, at best, with peripheral proximate problems. For example, the paper by Ganti et. al. [9] deals with the measurement 


per by Ganti et. al. [9] deals with the measurement of similarity \(or deviation, in the authors  vocabulary between decision trees, frequent itemsets and clusters Although this is already a powerful approach, it is not generic enough for our purpose. The most relevant research e?ort in the literature, concerning pattern management is found in the ?eld of inductive databases Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE meant as databases that, in addition to data, also contain patterns [10], [7]. Our approach di?ers from the inductive database one mainly in two ways. Firstly, while only association rules and string patterns are usually considered there and no attempt is made towards a general pattern model, in our approach no prede?ned pattern types are considered and the main focus lies in devising a general and extensible model for patterns Secondly, di?erently from [10], we claim that the peculiarities of patterns in terms of structure and behavior together with the characteristic of the expected workload on them, call for a logical separation between the database and the pattern-base in order to ensure e?cient handling of both raw data and patterns through dedicated management systems Finally, we remark that even if some languages have been proposed for pattern generation and retrieval 14, 11], they mainly deal with speci?c types of patterns \(in general, association rules sider the more general problem of de?ning safe and su?ciently expressive language for querying heterogeneous patterns 7. Conclusions and Future Work In this paper we have dealt with the issue of modelling and managing patterns in a database-like setting Our approach is enabled through a Pattern-Base Management System, enabling the storage, querying and management of interesting abstractions of data which we call patterns. In this paper, we have \(a de?ned the logical foundations for the global setting of PBMS management through a model that covers data patterns and intermediate mappings and \(b language issues for PBMS management. To this end we presented a pattern speci?cation language for pattern management along with safety constraints for its usage and introduced queries and query operators and identi?ed interesting query classes Several research issues remain open. First, it is an interesting topic to incorporate the notion of type and class hierarchies in the model [15]. Second, we have intentionally avoided a deep discussion of statistical measures in this paper: it is more than a trivial task to de?ne a generic ontology of statistical measures for any kind of patterns out of the various methodologies that exist \(general probabilities Dempster-Schafer, Bayesian Networks, etc. [16 nally, pattern-base management is not a mature technology: as a recent survey shows [6], it is quite cumbersome to leverage their functionality through objectrelational technology and therefore, their design and engineering is an interesting topic of research References 1] Common Warehouse Metamodel \(CWM http://www.omg.org/cwm, 2001 2] ISO SQL/MM Part 6. http://www.sql99.org/SC32/WG4/Progression Documents/FCD/fcddatamining-2001-05.pdf, 2001 3] Java Data Mining API http://www.jcp.org/jsr/detail/73.prt, 2003 4] Predictive Model Markup Language \(PMML http://www.dmg.org 


http://www.dmg.org pmmlspecs v2/pmml v2 0.html, 2003 5] S. Abiteboul and C. Beeri. The power of languages for the manipulation of complex values. VLDB Journal 4\(4  794, 1995 6] B. Catania, A. Maddalena, E. Bertino, I. Duci, and Y.Theodoridis. Towards abenchmark for patternbases http://dke.cti.gr/panda/index.htm, 2003 7] L. De Raedt. A perspective on inductive databases SIGKDD Explorations, 4\(2  77, 2002 8] M. Escobar-Molano, R. Hull, and D. Jacobs. Safety and translation of calculus queries with scalar functions. In Proceedings of PODS, pages 253  264. ACMPress, 1993 9] V. Ganti, R. Ramakrishnan, J. Gehrke, andW.-Y. Loh A framework for measuring distances in data characteristics. PODS, 1999 10] T. Imielinski and H. Mannila. A database perspective on knowledge discovery. Communications of the ACM 39\(11  64, 1996 11] T. Imielinski and A. Virmani. MSQL: A Query Language for Database Mining. Data Mining and Knowledge Discovery, 2\(4  408, 1999 12] P. Kanellakis, G. Kuper, and P. Revesz. Constraint QueryLanguages. Journal of Computer and SystemSciences, 51\(1  52, 1995 13] P. Lyman and H. R. Varian. How much information http://www.sims.berkeley.edu/how-much-info, 2000 14] R.Meo, G. Psaila, and S. Ceri. An Extension to SQL for Mining Association Rules. Data Mining and Knowledge DiscoveryM, 2\(2  224, 1999 15] S. Rizzi, E. Bertino, B. Catania, M. Golfarelli M. Halkidi, M. Terrovitis, P. Vassiliadis, M. Vazirgiannis, and E. Vrachnos. Towards a logical model for patterns. In Proceedings of ER 2003, 2003 16] A. Siblerschatz and A. Tuzhillin. What makes patterns interesting in knowledge discovery systems. IEEE TKDE, 8\(6  974, 1996 17] D. Suciu. Domain-independent queries on databases with external functions. In Proceedings ICDT, volume 893, pages 177  190, 1995 18] M.Terrovitis, P.Vassiliadis, S. Skadopoulos, E. Bertino B. Catania, and A. Maddalena. Modeling and language support for the management of patternbases. Technical Report TR-2004-2, National Technical University of Athens, 2004. Available at http://www.dblab.ece.ntua.gr/pubs Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE pre></body></html 


The reason of the hiding failure of SWA is the same in Fig.8 Notice the result at x = 0.7646 in Fig.14, because the hiding failure is occurred at the seeds of the sensitive patterns, a high weakness is produced As shown in Fig.15 and Fig.16, the misses cost and dissimil arity of our work decreases as RL2 increases. This is because the larger RL2 is, the less effect on non-sensitive patterns. Also weakness and dissimilarity of SWA are independent of RL2 5. Conclusion In the paper, a novel method improving the balance between sensitive knowledge protecting and discovery on frequent patte rns has been proposed. By setting entries of a sanitization matrix to appropriate values and multiplying the original database by the matrix with some probability policies, a sanitized database is gotten. Moreover, it can avoid F-I Attack absolutely when the confidence level given by users approximates to 1. The experimental results revealed that although misses cost and dissimilarity between the original and sanitized database of our process are little more than SWA, ours provide more safely protection than SWA. Unlike SWA, our sanitization process could not suffer from F-I Attack and the probability policies in our approach also take the minimum support into account, the users only need to decide the confidence level which affects the degree of patterns hiding 6. Reference 1] M. Atallah, E. Bertino, A. Elmagarmid, M. Ibrahim and V. Verykios Disclosure Limitation of Sensitive Rules", Proc. of IEEE Knowledge and Data Engineering Exchange Workshop 1999 2] R. Agrawal and R. Srikant. Fast algorithms for mining association rules. VLDB, Santiago, Chile, 1994 3] R. Agrawal and R. Srikant. Privacy preserving data mining. In ACM SIGMOD, Dallas, Texas, May 2000 4] E. Dasseni, V. Verykios, A. Elmagarmid and E. Bertino, Hiding Association Rules by Using Confidence and Support", Proc. of 4th Intl Information Hiding Workshop \(IHW 5] A. Evfimievski, J. Gehrke, and R. Srikant. Limiting Privacy Breac hed in privacy preserving data mining. SIGMOD/PODS, 2003 6] A. Evfimievski, R. Srikant, R. Agrawal, and J. Gehrke. Privacy preserving mining of association rules. KDD 2002 7] M. Kantarcioglu and C. Clifton. Privacy-preserving distributed mining of association rules on horizontally partitioned data. In ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery, June 2002 8] Guanling Lee, Chien-Yu Chang and Arbee L.P Chen. Hiding sensitive patterns in association rules mining. The 28th Annual International Computer Software and Applications Conference 9] Y. Lindell and B. Pinkas. Privacy Preserving Data mining. In CRYPTO, pages 36-54, 2000 10] S. R. M. Oliveira and O. R. Za  ane. Privacy Preserving Frequent Itemset Mining. In Proc. of IEEE ICDM  02 Workshop on Privacy Security, and Data Mining 11] S. R. M. Oliveira and O. R. Za  ane. Algorithms for Balancing Priv acy and Knowledge Discovery in Association Rule Mining. IDEAS  03 12] S. R. M. Oliveira and O. R. Za  ane. Protecting Sensitive Knowledge By Data Sanitization, ICDM  03 13] S. R. M. Oliveira, O. R. Za  ane and Y  cel Saygin. Secure Association Rule Sharing, PAKDD-04 14] Benny Pinks. Cryptographic Techniques For Privacy-Preserving D ata Mining. ACM SIGKDD Explorations Newsletter Vol. 4, Is. 2, 2002 15] S. J. Rizvi and J. R. Haritsa. Maintaining data privacy in association rule mining. VLDB, 2002 16] J. Vaidya and C. W. Clifton. Privacy preserving association rule mining in vertically partitioned data. KDD2002 17] Verykios, V.S.; Elmagarmid, A.K.; Bertino, E.; Saygin, Y.; Dasseni E. Association rule hiding. IEEE Transactions On Knowledge And Data Engineering, Vol. 16, No. 4, April 2004 Proceedings of the 29th Annual International Computer Software and Applications Conference  COMPSAC  05 0730-3157/05 $20.00  2005 IEEE pre></body></html 


pre></body></html 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



Research on Attribute Discreti zation for One Airborne Radar Intelligence System Based on Improved FCM Clustering  Jian Cui, Qiang Li Department of Early Warning Surveillance Intelligence  Wuhan Radar Institute HuBei, WuHan, China, 430019 ldxycj@sina.com Jun Wang Key Research Lab Wuhan Radar Institute HuBei, WuHan, China, 430019 junwang@nudt.edu.cn   Da-Wei Zong Add Science & Technology Development CO., LTD Wuhan East Lake Development Zone HuBei, WuHan, China, 430074 Whadd-zdw@163.com  Abstract To address the information loss problem in the process of discretizing continuous attributes for one airborne radar 
intelligence system, this paper proposes a discretization method based on the improved FCM\(Fuzzy c means\lgorithm through an analysis of the existing attribute discretization methods. This method improves the original algorithm by introducing the fuzzy decision theory and the validity index kwon V which is based on the geometric structure of the dataset, and uses this method to make the continuous attributes fuzzy. It overcomes the shortcomings that the conventional fuzzy clustering method must use two prespecified parametersóthe weighted index m and the number of clusters c and does not consider the specified attribute values of the dataset. We use the proposed method to discretize the 
continuous attributes in the airborn radar intelligence database and experimental results show that the scheme is feasible and effective Keywords- fuzzy c means; attributes discretization; weighted index; optimal clustering number; fuzzy decision theory I  024   Lc-\024\035§\015_\035\016EQLÀEí\030;> \004œ\010u,X\016r\016Ó\002»\004{*Û\004Z\016˚G£,X\026 030y\033D\031B\002»\021⁄\033D\031B\030Í\031l\030T\035\003\024È\0079\026ô\030y\007⁄\035d\023∆\027‰\004\016\025ô'\012\001ƒ'\0125 014¸\033D\031B\030Í\031l\011ÿ2O1k"©\004\001\002»\016Ó\033D1k"©F—\011æ6—\021Õ/è\0337\010Í,X\033D\031B 2O\015_EØ> \016 XE≤4¡\0222\025˚\012`\007⁄2O\0222\025˚\001ƒ\004Ù4≥/è\0337\010Í\016 AöEØ> ,X\002»\021ç\033Á\011´\004é\023π\014¥2Ù,X\024F\030D\002»\003ËE≤4¡\0222\025˚,X\034‘\004 0337\010Í\034\003\003‘\003 NP 021`\007<K¬Nl  002»HH\004bAπ\035\016EQLÀEí,X\021rL\031\026 007â\002»L‘?U-Ë0J\003‘/°/•\021:\034›\033\034,XE≤4¡\0222\025˚/è\0337\033ç"©\001  E≤4¡\0222\025˚/è\0337\010Í\034\003\021⁄\(M\021n,XE≤4¡\0222\025˚,X\006\020\015≥8◊\014»\007Ê\007 027‰\003‘\004o/è\0337\010Í\011\016K»\002»\007a*¸\003·\011‡,X0˙\011À\027Í\033H\033D\006\020\004∑><\0222\004b 003˛\011\016K»,X\0222\025˚\006\020 2 001ƒ,¬\010!\004é\004¿\023∆4£\031§\007Œ\004Z\016Ó/°\007G\004bE≤4¡\0222 
025˚,X/è\03371k"©\001ƒ\017V Srikant 012 Agrawal 3 031§\007Œ,X1\035C±/è\012`1\035 Ne Miller 012 Yang 007 Birch 6.2O 4 1k"©\0359.BAx\0222\025˚\007Ê\007⁄\002»\024J\005S 015Œ\004bC±/è,X\007G6\(?ò\007Ì\033\015EØ\0222\025˚K»Lh,XA¡\004\035\002 Lent 5 1\035\004é\031 X6.2O\033ç"©\021Õ\033D\006\020\015_\0222\025˚EØ> \007Ê\007⁄\002 Guha 6 1\035\004é\031§\007Œ\003‘/°P¨\033\034,X CURE 6.2O1k"©\021ÕE≤4¡\0222\025 EØ> \007Ê\007⁄\002»\024JAï\033‚\004Z!81k"©\004Ï\004b\033Ω\034Û\031§\007Œ,X\007J\004™1k"©\001  022\0211u\003ﬁEƒ\033ç"©6—\016Û\021ÕE≤4¡\0222\025˚EØ> /è\0337\010Í\002»\005\032\034\003\004Ó\014 007Ê\007⁄\0222\025˚K»Lh\004\037K»\007Œ\J‰Eç+ \001\001,XK¬Nl\002»\024J+\005!8\004 033D\031BLö,X\001\000\005µ\026C\0313\017\005\001\001K¬Nl 7 001ƒ?∑\007á!8K¬Nl,X\033ç"©\022\005\034\003\021 037ı2ûLö\\0337\037ı\015_\002»\024G$•/è\0337\010Í\011‚,X\0222\025 K»Lh\001 Zadeh  034‘\033Ω\024È\0079\037ı2û\Eõ\005S*¸#‰EØLä\0222\024z 024Œ0üA¡?‘\006\020NM,X\037ı2ûEç+ \002 Yager 
 007˝*¸\037ı2ûA¡?‘\006\020\021Õ\003 011‡,X\0222\025˚EØ> 1T\010Í\002◊\035\000\033[G FCM 6.2O1k"©\021ÕAπ\035\016EQL Eí\026ô\030yE≤4¡\012`\007⁄2O\0222\025˚EØ> /è\0337\010Í\002»4ß\011‹\037ı2û\007á1*\\012 011√6—\025˚\007Ê\007⁄'â\034›\033\034\007—\033D\021r\\021 FCM 1k"©\004\001\010t\035\027\030€\033D m X 034‘\004ÏE›\011™\002»EÓEõ\034›\033\034\025˚\030€\035 kwon V E¡\004∑E§1k\025k\010\004\034‘\005G6.2O\033D  c 002»\007\037\034·\011s1k"©\004é\023πE›\011™\011ñ\033D,XK¬Nl\002»FS\007!1k"©\033ÁLK\0079 022\024Fº\034‘\004Ï\001ƒ\034‘\011‚\007˝*¸!81k"©\021Õ\035§\035\016EQLÀEí\026ô\030yE≤4¡\0222\025˚E 0337\010Í\002»\024J\021Õ\004{*Û,X\0222\025˚\037ı2û\007Ê\007⁄\024Œ0üLä\0222\024z\007—\033D\001  II  FCM 6.2O1k"©\011û\034›\033\034\025˚\007—\033D  A  015Œ\004b,¬\035€\007—\033D,X\037ı2 c\015\033\006\0206.2O\007Ê\007  FCM 1k"©\034\003\003‘/°6—7æ\010|\021Õ\033D\031B\036\013\035\000EØ> \007⁄2O,X\033 002»\021WEÓEõ\004Ï\010Í,¬\035€\007—\033D\025k\010\004\021Õ!£\003˛\036\013\035\000&ç\021Õ2O\004\001\025ó,XL 0222\024z\002»\004¢5‡\007á\021n\036\013\035\000&ç,X\025&\0222 10 001ƒ1k"©\031£Eƒ\017V\003ﬂ\002  004 12     
s n Xxx x R 002 034\003\033D\031BLö\002 n 034\003\033D\031BLö\004\001\007\027 2Ù,X\003˛\033D\002 c 034\0036.2O\004\001\025ó\033D 1  cn  002 ij i j dxv  000&\000 034\003\036\013 035\000 i x 012`6.2O\004\001\025 j v X ˚\024„C±/è\002 1  s j vR jc 003\004\004 001 ij u 034\0031\000 i 003˛\036\013\035\000\0222\004b1\000 j 003˛\004\001\025ó,XLä\0222\024z\002  ij U   034\003\003‘\003 nc  X\037ı2 c 007Ê\007⁄-ΩL\011\002 12   c vvv v  
034\003\003‘\003 s c  X\037 2û6.2O\004\001\025ó-ΩL\011\001  021n\004\035 000\024  Cá\024„\002 1 002≈,X\004œ\026„\003‘\003 fc UM 003 022\005\021n\004\035\004Z\033D\031B L X X\003‘\003˛\037ı2 c 007Ê\007⁄\001  11 0,1    1   0   cc s fc ij ij ij ii M UR ij j ni   003 003 005 005 005 000¶\000   002 1 002  U L\011\004\001,X!£\003‘> \007\0272 1  ij j n  004\004 021n\004\035\004Z X 004\001,X\003‘\003 037ı2û6.2O\021$L 
l S 000\004 001  11 2 2 ln   ll l n Sxx x     000\004 000   002 2 002  007J\004\001 ij  0161\000 j 003˛\036\013\035\000 j x Lä\0222\004b6.2O l S 000\004 X/ﬂ\024z\001  021n\004\035 000\025  014 FCM 6.2O1k"©\004\001\002»,¬\035€\007—\033D  m J Uv 005\024 002 3 002≈\007á\021n\001  National natural science foundation No: 60736009  
2010 International Conference on Electrical and Control Engineering 978-0-7695-4031-3/10 $26.00 © 2010 Crown Copyright DOI 10.1109/iCECE.2010.1332 5482 
2010 International Conference on Electrical and Control Engineering 978-0-7695-4031-3/10 $26.00 © 2010 Crown Copyright DOI 10.1109/iCECE.2010.1332 5482 


2 11  nc m mijij ij J Uv d   006 000¶\000  1  m 003\007  002 3 002  FCM 1k"©\022\005\034\003\005S Pickard E¡\004∑\033\012\033/\010\004\003‘\003˛\035U\021„&ç\002»E 5‡\005S,¬\035€\007—\033D m J X\035U\021„\010Í\002»\034‘4ú\025k\010\004 X X\003‘\003˛\037ı2 c 007 007⁄-ΩL\011  U 001  B  6.2O\034›\033\034\025˚\007¯\007ˇ\007—\033D  010t\035\027\011ñ\033D m 012`6.2O\033D c 003¯\003˛\011ñ\033D,XE›\011™\034\003\011˙\011‹\\004b 6.2O\034›\033\034\025˚A|Aé,X8◊+H\002»\004\016!8 R.Krishnapuram 012 M.Keller 021⁄\011√6—\025˚\007⁄\023◊\031£Eƒ\014¥\021$*¸\004b6.2O\034›\033\034\025˚,X\007¯\007 1 001 000\003 021n\004\035 000\026  4≠\021n\003‘\003˛\011√6—\025˚\007⁄\023        12 12 n n xx x    000  002 4 002  011√6—\025˚\007⁄\023◊\031£Eƒ\014¥\021$\021n\004\035\027‰\002   2 1 1 n i i n i i PDD      000 000  002 5 002  011√6—\025˚\007⁄\023◊\031£Eƒ\014¥\021$\011°\033Ù\004Z\011√6—\025˚\007⁄\023◊,X\024G\015\033\011√6 025˚\001ƒ+\005\004b Trauwaert 030€\007Œ\004Ù4≥,X6.2O\034›\033\034\025˚\007—\033D  F Uc X 034‘\016˚\006\020\024JM2\026\017\034\003\021Õ\024h\034‘\005G6.2O\033D\002»E≠><\033‚\007Ê\007⁄2œ\033D\003·\021`\007 E÷\011‹6.2O\034›\033\034\025˚\007¯\007á\001ƒ\011√6—\025˚\007Ê\007⁄'â\022\005\034\0034ß\011‹\011√6—\025 033\015EØ\004Z,X\037ı2û6.2O\034›\033\034\025˚\007—\033D\001  021n\004\035 000\027  021Õ\004b4≠\021n,X6.2O\004\001\025ó\033D c 012`Lä\0222\024z-ΩL\011 U 002»\011 6—\025˚\007Ê\007⁄'â\021n\004\035\027   11 11 1  log nc ij ij a nn ij ij ij ii HUc c      006 000¶\000 000¶\000  002 6 002  0056.2O,X\034›\033\034\025˚\011√-π\002»\034‘\021„,X\030€\035€\006\020\002»\011G  min    H Uc 021Õ\024h-\024\034‘\005G6.2O\033D\002»!8\033 ,X6.2O\033D c 021Õ\024h-\024 EW\021„,X\037ı2û\033D m 004π></\016EW\021„,X\037ı2û\025˚\001  003ﬂM64≠\007Œ,X\034›\033\034\025˚\030€\035 kwon V 003‚\033D\031BLö,X4ß\035X\(M\025U\034 031y,X6\(2œ\001ƒ\021⁄E≠\003¯2O\034›\033\034\025˚\007—\033D*¸\004b1k"©\004\001\002»Eí\010\004\024G>51k 2í.B\025˚\012`1k"©\033 K»\016·\035\026\024z,X,¬,X\001  021n\004\035 000\030  015Œ\004b\033D\031BLö\007¥\005\4ß\035X,X\037ı2û6.2O\034›\033\034\025˚\030€\035€\002  22 11 1 2 1  min cn c m ij j i i ij i kwon ij ij vx vv c VUvc vv    010     000¶\000 000 000&\000 000&\000 000&\000  002 7 002  034›\033\034\025˚\030€\035 kwon V 007\037\034·\004Z Xie-Beni 034›\033\034\025˚\030€\035 x ie V 014¸\025 cn 011 033 \011\\007£\031yE•\004b 0 X\025\005&ç\002»\021Õ.B\021n\034‘\005G6.2O\033D  c 034›EW\025\016,XRU\036¶\025˚\012`\007¯\007á\010s6 12 001ƒ\024„\002 7 002≈,X\007⁄\021$\004\001,X1\000\004 NM\034\003\024È\0079,X\026Ω5.\007—\033D\001ƒ\025 cn 011 033 \002»Aπ\030€\035€6—\034›\033\034\015\004\030e\010\012 030€\035€\006\020\003ﬂL!,XC_\010ì\003Ë"\014\003·\004\016 0 002»\030€\035€\006\020\011™\034‘\021„\006\020\033 \021Õ\024h,X c 022\005\034\003\034‘\005G6.2O\033D\001  021n\\000\003 021Õ\004b 000\\000&\0000 1k"©\034›\002»\025 1 m 011 033 \002»\000\\000&\0000 6.2O1k E‘\010Í\027 c 015\033\006\0206.2O1k"©\002◊\025 1 m  033 \002»\000\\000&\0000 6.2O1k"©\011¨\027  c 015\033\006\0206.2O1k"©\002◊\025 m 011\007 033 \002»\000\\000&\0000 6.2O1k"©,X6.2O4 035p\034\003\034‘\037ı2û,X\002»\011G 1 ij c   001ƒ\000\003 005!8\011√?ï\002»\010t\035\027\030€\033D m 031{\010\012-\024\036\013\035\000\014¸\037ı2û2OK»,X\007⁄\004 024z\001ƒ\017V\035p m 030€E›\011™\003·\011‹E÷\002»\022\005\004Ó\025E\012 FCM 1k"©,X\033\012\033 025˚\002»\021Õ\037ı2û6.2O,X\025˚6—\004{*ÛG°?U\025E\012°\002»\034‘4ú\033¥"©\025k\010\004\017Q,X 037ı2û\007Ê\007⁄\002»\033¥"©\025k\010\004\034‘\004Ï,X6.2O\033D  c 001  III  033\015E FCM 6.2O1k"©\011ûE≤4¡\0222\025˚\037ı2û\007Ê\007⁄1k  A  034‘\005G\010t\035\027\030€\033D  m 012`\034‘\004Ï6.2O\033D  c X.B\021n  015Œ\004b\003ﬁEƒ\007⁄\035d\002»\035\000\033[AíAu\003‘/°\015Œ\004b\037ı2û\007á1*\Aé\012`\034 004\016\034›\033\034,X\011√6—\025˚\007Ê\007⁄'â\0050\004\016\034›\033\034\007—\033D9ã\011™\034‘\005G\010t\035\027\030€\033D  m X\033ç"©\002»\011‡\033 E›\030Ω\015Œ\004b\033D\031BLö\007¥\005\\035X,X\034›\033\034\025˚\030€\035 kwon V 026?∑\034‘\004Ï6.2O\033D  c 006\020\002»\016r\025\0166.2O4ß\035p,X\007ö.B\025˚\001  004 Bellman 012 Zedeh 031§\007Œ,X\037ı2û\007á1*\\005q\031B\002 007 m X\004ÏE›K¬NlL‘?U\035XEÙ\011‹E÷,X\037ı2û,¬\035€\001√\037ı2û4z\0353\012 024h,XLä\0222\024z\007—\033D\001ƒ\021n\004\035\037ı2û,¬\035 G 004\016,¬\035€\007—\033D  m J Uv 002 037ı2û4z\0353 C 004\016\011√6—\025˚\007Ê\007   H Uc 001ƒ\004b\034\003\002»\007G\004b\034‘\005G\010t 035\027\030€\033D  m X\037ı2û\007á1*\011√\004π></\016\004\016\002     min    arg     min m m JUv m stH U c 005 000 000 000 000  000 000 011 000 000 000Ø\000  002 12 002  021⁄K¬NlE@\010Í\004\016\023˙4z\0353,XM24ì\025˚?ò\007ÊK¬Nl\001ƒ\017V!8\022\005\011√\004 EÓEõ\037ı2û\007á1*.B\021n\034‘\005G\010t\035\027\030€\033D,X\006\020\001  031y\003ﬂ\0359\021n\004\035\037ı2û,¬\035 G 012`\037ı2û4z\0353 C XLä\0222\024z\007—\033D\007 007ˇ\004\016 G  012 C  002»*¸\003ﬂM6,X\007@\024„EØ> ></\016\002     exp 1.5 max    m G m m JUv m J Uv  005 000 000 000 000  000 000 000 000 000Ø\000  002 13 002       1/110 max    c m HUc m HUc  005 000ß\000 000ß\000 000®\000 000®\000  000®\000 000®\000 000©\000 000©\000  002 14 002  007Ì\034‘\004Ï\010t\035\027\030€\033D  m X\037ı2û\007á1*\011™\006\020\004\016 G 012 C 030\024\021Õ\024h X\037ı2û\021$Lö,X\004xLö\004\001\034‘\016˚Lä\0222\024z\030\024\021Õ\024h,X m 006\020\001ƒ\014¥!8\002»\034 004Ï\010t\035\027\030€\033D  m 005\024„\002 15 002≈\025k\010\004\002        arg max min     GC m mmm  005   002 15 002  014¸\004Ù4≥\033ç"©\004\001+\005\004b c 006\020+\005\004é\023πE›\011™\002»\030\024\004π\003·6—\005±Aï\034 4ú,X6.2O4ß\035p\034\003\034‘\004Ï\007Ê\007⁄\002»\035\000\033[\007˝*¸\034›\033\034\025˚\030€\035€EØ\003‘!9\021 007Ò\017ü6.2O\033D c EØ> E¡\004∑E§1k\002»\021r\.B\021n6.2O\004\001\025ó\003 033D\002»\034‘\011‚\010\004\034‘\004Ï6.2O\033D  c 001  007˝*¸\024„\002 7 002≈\021n\004\035,X\034›\033\034\025˚\007—\033D kwon V B\021n\034‘\004Ï6.2O\033D  c X1k"©Eõ/ﬂ\017V\003ﬂ\002ƒAí\007Ò\017ü\010t\035\027\030€\033D8◊\014»\004\016 1.0,1.1  mk  000 002 0.1 step  002≈\002  1 007Ò\017ü6.2O\033D 2 c  002  2 007Ò\017ü\010Í6.2O\004\001\025 i v 002 1 2  ic  000 002  3 E¡\004∑ ı\033D 0 p  002»Au1k\011ÿ\003˛\033D\031B\010\0046.2O\004\001\025ó,XC ij d 002»Au1kLä\0222\024z\007—\033D-ΩL\011 0 0  ij U   002»\007J\004\001 
5483 
5483 


1 2  ic  000 002 1 2  j n  000 002 ij  034\003-ΩL\011 U X1\000 i 1\000 j 007 007\0272Ù\002»\004∑><1\000 j 003˛\033D\031B\021Õ1\000 i 003˛6.2O\004\001\025ó,XLä\0222\024z\001ƒ4z\0353 007G2œ?ï\024„\002 1 002≈\002  4 G°\033ÑAu1k c 003˛6.2O\004\001\025 i v 002 1 2  ic  000 002  5 G°\033ÑAu1kLä\0222\024z\007—\033D-ΩL\011 U 002  6 Au1k,¬\035€\007—\033D   p m J Uv L\007 012`\011√6—\025˚\007Ê\007    p H Uc 002»\017V\035p   1   pp mm JuvJ uv 012  004 002    1   pp HuvH uv 012  004 002»></\016\033\012\033/\002»\007Ì!86.2O\033DE¡\004 4ß\0353\002»\011˙\007Ì\002 1 p p  002»E@\011Â!9Px\002 4 002≈\002  7 017V\035p\034›\033\034\025˚\030€\035 kwon V Eí\010\004\033\012\033/\0355\004 \002»\007ÌEõ/ﬂ4 0353\002»\025k\010\004\025'\010 m 006\020\003ﬂ\022\024Fº\034‘\004Ï,X6.2O\033D  m c 001√\035U\021„,¬\035€\007 033D   m J Uv 012`\035U\021„\011√6—\025˚\007Ê\007   m H Uc 001ƒ\011˙\007Ì\002»6.2O\033D 1 cc  002»'\012\011‚E@\011Â!9Px\002 2 002≈\002  8\ 0.1 mm  002»\017V\035p mk 004 002»E@\011Â!9Px\002 1 002≈\001ƒ\011˙\007 Eõ/ﬂ4ß\0353\002»\036\015\031B\024„\002 13 002≈\001√\002 14 002≈Au1k\025k\010\004!£\003 m X  G m  012  C m  002»+\005\024„\002 15 002≈\025k\010\004\034‘\005G\010t\035\027\030€\033D  m 002  m 021Õ\024h,X\022\024Fº\034‘\004Ï6.2O\033D  m c 011G\004\016\034‘\004Ï6.2O\033D  c 001  B  0222\025˚\037ı2û\007Ê\007  Gõ*¸\003ﬁEƒ\033\015EØ,X FCM 6.2O1k"©\021Õ\035§\035\016EQLÀEí\026ô\030yE 4¡\0222\025˚EØ> \037ı2û\007Ê\007⁄\002»\006\033Aí\034›\017V\003ﬂ\021n\004\035\002  004∏\033D\031B\024g\036\013\035\000   12  n D xx x  000 002»\007J\004\001 12  n xx x 000 003 011‡,X\033D\031B\024gAÑ\025 n 004\016AÑ\025\\002   12  r QA q q q  000 004\016 033D\031B\024g\004\001E≤4¡\0222\025˚\002 r 004\016E≤4¡\0222\025˚\003˛\033D\002   12  iiini D Sxx x  000 004\016 n 0355\033D\031B\024gAÑ\025\\021Õ\024h\0222\025 i q X 0222\025˚\006\020Lö\011‹\002   12  r F PFPFP FP  000 004\016\030\024\034›\0222\025˚\034‘4ú\037ı2 007Ê\007⁄,XLö\011‹\002   12  ic F Pff f  000 004\016\011\\003˛E≤4¡\0222\025 i q X\037 2ûLö\002 c 004\016\037ı2ûLö\003˛\033D\001  021Õ\004b4≠\021n,X\035\016EQLÀEí\026ô\030y\033D\031B\024g\036\013\035\000 D 002»\005S*¸\003ﬁEƒ1k 021 D 004\001\0222\025 i qQA 003 030\024\021Õ\024h,X\0222\025˚\006\020Lö\011‹EØ> 6.2O\007 007⁄\002»\004π\025k\010\004\0222\025 i q X\034‘\005G\037ı2û\007Ê\007 i F P 011û\007J\037ı2 c 007Ê\007 L\011  ijkinc Ux    002»\007J\004\001  j kji x  016\0222\025 i q 1\000 j X\0222\025 006\020\0222\004b\037ı2ûL ki f FP 003 XLä\0222\024z\002   12  iii ic vvv v  000 004\016\037ı2 007Ê\007⁄,X\004\001\025ó\001ƒ\007J\004™\0222\025˚,X\007Ê\007⁄\004π!82O\031|\001  035§\035\016EQLÀEí\026ô\030y\033D\031B\0222\025˚,X\037ı2û\007Ê\007⁄\004{*Û1k ARIAFDG 017V\003ﬂ\002  for each  1 2   i qQAi r 003 000  read i D S 002 max m 002 FCM 033\015EØ1k"©\004\001 m X\003ﬁL$\002  i F P 002 i U 002 i v newFCM max  ii qDSm  for each partition ki f FP 003  label k f appropriately 002ƒ\037ı2ûLö\030'\035€\002  C  0222\025˚\037ı2ûLö,XLä\0222\024z\007—\033DAu1k  025k\010\004\030\024\034›E≤4¡\0222\025˚,X\037ı2û\007Ê\007⁄\011‚\002»4ß\011‹\011ÿ\0222\025˚\037ı2ûL XLä\0222\024z  002»Au1k\030\024\034›E≤4¡\0222\025˚\037ı2ûLö,XLä\0222\024z\007—\033D\001  004π\003ﬁ8V\004\001 i q 0222\025˚\011û\007J\037ı2û\007Ê\007 i F P 004\016\005_\002»\033ç"©\017V\003ﬂ\002  A     1 k ipipkpijkji Xx x xj c  013\005\003 000 002»\014   k ik Xv 000 004\001\030R\007Œ\005!\004b2O\004\001\025 k v 003¯\005{,XLä\0222\024z\034‘\021„,X\0222\025 006\020\002»Aí\023∫\005{Lä\0222\024z\034‘\021„,X\0222\025˚\006\020\004\016 li x 002»Lä\0222\024z\004\016  lk li x  002»\023∫\005{Lä\0222\024z\034‘\021„,X\0222\025˚\006\020\004\016 ri x 002»Lä\0222\024z\004\016  rk ri x  002»\007Ì1\000 k 003˛\037ı2ûLö\021Õ\024h,X\003›?¶\037ı2û\033D   k av b 004\016\002    1    1 0 k lk li k li k li lk li k rk ri k ri k ri rk ri xa axv xv x va ax x bx fx v x b xv x bv bx x xaxb      000 004\004 000   000 000  000  000  000 004\004 000Æ\000   000∞\000  000∞\000   000 000 000 026  D  037ı2ûAÑ\025\Lö*Û\027  014¸\021`\027‰\0222\025˚\037ı2û\007Ê\007⁄\011‚\002»\0050\004\016\0222\025˚/è\0337,X\034‘\011‚!9Px\002 007˝*¸\011ÿ\037ı2ûLö,XLä\0222\024z\007—\033D\021⁄\011s\017ü\033D\031B\024g,XAÑ\025 037ı2ûAÑ\025\Lö\002»!8Eõ/ﬂ\0043\034\003\011‚4¡\033D\031B\030Í\031l\033ç"©,X\025ô?U!9Px\001  017V\035pAÑ\025\2O\0222\025˚\002»\007Ì\021⁄\021Õ\024h,XAÑ\025 NM\030›';\0222\025˚,X\007⁄2O\003˛\033D\007Ê\007⁄\002»!£\003˛\021$NM\006\020\030›';\030\024\02222O\007ˇ\004\016 Lä\0222\024z   01   K 001ƒ\016r\010t\017V\003ﬂ0˙\011À\021n\004\035\002    12   q CA c c c  000 004\016\033D\031B\024g\004\001\007⁄2O\0222\025˚\002 CCAQA  000 004\016\0222\025˚Lö\011‹\002 D 014 004\016\025YE@\0316\033D\031B\024g D XEõ#ı\011 G£\002 E 004\016E@\0316\011‚,X\034‘4ú\033D\031B\024g\001  035§\035\016EQLÀEí\026ô\030y\033D\031B\024g,X\037ı2ûAÑ\025\\004{*Û1k ARIFRSG 017V\003ﬂ\030\024/\016\002  D D 014   D 014\014 015  for each i cC 003  if 1 2   i cCAi q 003 000  for each record  1 2   j xD j n 014 003 000   x 014 replace value v ij by ij    01 003 K  D xD 014\014 014 014\014  000    if 1 2   i cQAi r 003 000  for each record  1 2   j xD j n 014 003 000  for each x i f FP 003 corresponding i c  1,2 ks  000  ijk  membership corresponding to value v ijk  in fuzzy partition 002 attribute 002 x f according to triangle membership function     k av b  x 014 replace v ijk by ijk   D xD 014\014 014 014\014  000  D D 014\014\014   D 014\014 015  E D 014   EÓEõ\003ﬁEƒEõ/ﬂ\011s\017üAÑ\025\L D E@\0316\027‰\037ı2ûAÑ\025 E 001  
5484 
5484 


IV  021rP`4ß\035p\003‚\007⁄\035d  E›\011™Aπ\035\016EQLÀEí,XFº\007⁄\004”,Û\026√\021–\0222\025˚\011û\007J\004”,Û\033D\031B\021 030\024Eƒ\033ç"©EØ> \011√> \025˚\003‚\034›\033\034\025˚\007⁄\035d\001ƒ\017V 1 030\024/\016\002»\007J\004\001 12 5  aa a 000 007⁄\007ˇ\004\016EQ\035\016\026√\021–\033D\031B\0222\025˚\002÷EQ\035\0164£\024z\001√EQ\035\0164 024z\001√EQ\035\016P¨\024z\002ƒ2G\002≈\001√EQ\035\016EÛ\024z\002ƒ2G  002≈\012`EQ\035\016\005√\004 002»\007<Fº\004\016E≤4¡\0222\025˚\002 6 a 016"∂\03532O\015_\002»\004\016\007⁄2O\0222\025˚\001   1 EQ\035\016\026√\021–\033D\031B\024gFº\007⁄AÑ\025  ID 1 a  2 a  3 a  4 a  5 a  6 a  1 118.74126 31.05182 8398 142.67 5.883 M 2 118.74107 31.05149 8396 141.45 6.004 M 3 118.73994 31.04358 8397 141.44 5.960 M 4 118.73852 31.04393 8397 141.43 5.982 M 005q\031B\035\000\033[\033ç"©\021Õ\0222\025˚EØ> \037ı2û\007Ê\007⁄\002»\017V 2 030\024/\016\002   2 0222\025˚\011û\007J\037ı2û\007Ê\007   037ı2û\007Ê\007  1 a  118.40 118.532 118.715 118.756 118.95  2 a  30.532 30.753 31.054 31.075 31.084 31.11 3 a  6523 7400 7968 8397 9982  4 a  140.25 141.44 142.90    5 a  4.325 5.845 6.982 7.1445   007⁄2O\0222\025˚"∂\03532O\015_\034›\003›2O\011™\006\020\002÷\001\000 P 001\001\002»\001\000 B 001\001\002 001\000 M 001\001\002»\011√>\007Ê\007⁄\027‰\003›\003˛\037ı2ûLö\002 P 001 B 012 M 002»\037ı2ûL P 021n\004\035\004\016\002÷\025'\011™\006\020\004\016 P 033 \004\016 1 002»\011™\006\020\004\016 B 027 M 033 \004\016 0 002◊\037ı2 L B 012 M 021n\004\0352O\005\020\001ƒ\007J\004 5 003˛\0222\025˚\015\033>\007Ê\007⁄\027‰,Ã\024h,X\037 2ûLö\001ƒ!£\003˛\037ı2ûLö*¸\003›?¶\037ı2û\033D></\016\002 3 007Î\007Œ\004Z\0222\025 1 a 012 3 a X\003›?¶\037ı2û\033D\011ñ\033D\001   3 0222\025 1 a 012 3 a X\003›?¶\037ı2û\033D\011ñ\033D  014 1 004\016\0222\025˚\001\000\026√\021–4£\024z\001\001,X\037ı2û\007Ê\007⁄,X\014“\0256></\016\001  118 118.2 118.4 118.6 118.8 119 119.2 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1     014 1 0222\025˚\001\000\026√\021–4£\024z\001\001,X\037ı2û\007Ê\007   4 007Î\007Œ\004Z\0222\025˚\001\000\026√\021–4£\024z\001\001\012`\001\000"∂\03532O\015_\001\001,X\010!\004h 0355\033D\031B\024gAÑ\025\\037ı2ûAÑ\025\\03164ß\035p\001   4 Fº\007⁄\0222\025˚AÑ\025\,X\037ı2û*Û\027‰AÑ\025  1 a  6 a  0.532 0.25 0 0 0 1 0 0 0.75 0.15 0 0 0 1 0 0 0.9 0 0 0 0 1 0 0 0 0.31 0.68 0 0 0 1 0 0 0 0 0.70 0.24 0 0 1 V  4ßA  035§\035\016EQLÀEí\026ô\030y\033D\031B\010Ÿ\011ˇ\016˚G£,XE≤4¡\0222\025˚\012`\007⁄2O\0222 025˚\002»\004\016\004Z\014¸\0222\025˚/è\0337\010ÍEõ/ﬂ\004\001\007\037\034·\001\000\021ÍJ‰Eç+ \001\001K¬Nl\002»\035\000 033[\014¸\010!\004é-Ë0J4ß\035p,X\015Œ.\024\004\037\003ﬁ\031§\007Œ\004Z\003‘/°\015Œ\004b FCM 1k XE≤4¡\0222\025˚\037ı2û\007Ê\007⁄\033ç"©\002»EÓEõ7æ\010|.B\021n\034‘\005G\010t\035\027\030€\033D  m 012`\034‘\004Ï\007⁄2O\033D  c 002»\007\037\034·\004Z,¬\010!\0222\025˚\037ı2û\010Í\033ç"©L‘?U\004 004\016.B\021n\007Ê\007⁄2O\033D\001√\007¥\004"\003·5◊<%\033D\031B\007¥\005\E 004”,Û\033D\031BEØ> ,X\021rP`4ß\035p\0359,ﬂ\002»\035\000\033[\030\024Eƒ\033ç"©6—\016ÛJ\\\021ÕA 035\016EQLÀEí\026ô\030y\033D\031B7æD\(M&çEØ> \0222\025˚\037ı2û/è\0337\002»\004\016EØ\003‘!9 021ÕAπ\035\016EQLÀEí\026ô\030y\033D\031BEØ> \033D\031B\030Í\031l\007⁄\035d\030'\003ﬂ\003‘\003˛8C\017Q,X 015Œ.\024\001  References  1  H. S. NGUYEN, A. SKOWRON, ìQuantization of real values attributes: rough set and Boolean reasoning approach,î Proc of the 2nd Joint Annual Conference on Information Sciences. Wrightsville Beach s. n   19 95 pp 34 37  2  Yue Chi, Yao Dong, Kewen Xia, Jin Shi, ìContinuous attribute discretization based on quantum PSO algorithm,î  Proc of the 7th World Congress on Intelligent Control and Automation, 2008, pp. 6187ñ6191 3  R. Srikant and R. Agrawal, ìMining quantitative association rules in large relational tables,î Proc. of ACM SIGMOD, 1996, pp. 1ñ12 4  R. J. Miller, Y. Yang, ìAssociation rules over interval data,î Proc. of the ACM SIGMOD, 1997, pp. 452ñ461 5  B. Lent, A. Swami And J. Widom, ìClustering association rules,î Proc of IEEE ICDE, 1997, pp. 220ñ231 6  S. Guda, R. Rastogi And K. Shim, ìCURE: An efficient clustering algorithm for large databases,î Information Systems, 2001, vol. 26, no 1, pp. 35ñ58 7  Bai-Gen Zhu, Pei-Zhi Li, Ban Wang, ìAttribute discretization method based on rough set theory and information entropy,î Application Research of Computers, 2008, vol. 25, no. 6, pp. 1701ñ1703 8  L. A. Zadeh, ìFuzzy sets,î Information and Control, 1965, vol. 8, pp 338ñ353 9  R. R. Yager, ìFuzzy summaries in database mining,î Proc. of the Conference on Artificial Intelligence for Application, 1995, pp. 265ñ269   Kong-sheng Zhang, Bai-nian Li, Jian Xu and Li-bin Wu, ìNew Modification of Fuzzy c-Means Clustering Algorithm,î Fuzzy Information and Engineering,  2009, vol. 54, pp. 448ñ455   J. Kim, R. Krishnapunn and R. Dave, ìApplication of the least trimmed squares technique to prototype-based clustering,î PRL, 17, 1996, pp 633ñ641   S. H. Kwon, ìCluster Validity Index for Fuzzy Clustering,î Electronics Letters, 1998, vol 34, no. 22, pp. 2176ñ2177   003›?¶\037ı2û\011ñ\033D  1 a  118.10 118.403 118.532 118.403 118.532 118.715 118.532 118.715 118.756 118.715 118.756 118.95 118.75 118.95 119.23 3 a  5300 6523 7396 6525 7400 7954 7412 7968 8395 7971 8397 9980 8413 9982 1135 
5485 
5485 


support 0 0 D test is the set of suf\037xes of classes and smurf K 1 m K d x d d C 000 audit records for the training from KDDCUP\22299 dataset randomly which contains 5 000 intrusion audit records including two kinds of attacks 0  2826 m P k is de\037ned by 6 0 dx dx k  dx K Value Minimum support Value C P k m k k 13 where x k x K con f idence k 14 new connection data To evaluate the performance of the proposed algorithm the simulations are conducted using intrusion detection database of KDDCUP1999\(KDDCUP\22299 Till now it still served as a reliable benchmark data set for many network-based intrusion detection algorithms KDDCUP\22299 intrusion detection dataset contains a standard set of data to be audited And each record represents a TCP/IP network connection with total 41 features All the connections can be divided into 5 categories including normal network connection and other four categories are Denial of Service Attack\(DoS User to Root Attack\(U2R Remote to Local Attack\(R2L and Probing Attack In our experiments the parameter setting of GNP are summarized in Table 2 The population size of GNP is set at 120 Due to the complexity of intrusion detection the number of processing nodes and judgment nodes are set at 10 and 100 respectively in order to diversifying the GNP structure to extract more interesting rules Additionally we used 1 1 1 0 0 6 We choose 10 80 0 0 1 Fig 5 The number of rules extracted generation by generation Fig 6 The 037tness curve for GA based pruning which are not included in the training dataset Validation data is also randomly selected from the database whose size is 1000 The proposed GA-based two phase rule pruning method 037lters the redundant rules to make intrusions detect more ef\037cient and effective The parameters in Table 3 are used in the proposed GA-based two phase rule pruning Since the system obtains the rules from all the classes during the training phase it can detect intrusive attacks as well anomalous attacks By evolving the GNP individuals generation by generation a lot of interesting class association rules can be discovered Fig 5 shows the the number of rules extracted in each generation by all GNP individuals It extracted 31920 normal rules and Mutation rate Mutation rate Mutation rate is represented as follow C d f Parameter Population size Generation size Processing nodes Judgement nodes Crossover rate Minimum con f idence Minimum Parameter Population size Generation size Crossover rate threshold k C D test 63 8 and 120 1000 10 100 63 000 normal audit records and 5 100 neptune d smurf 0 20 40 60 80 100 3.5 4 4.5 5 5.5 6 generation fitness value 0 200 400 600 800 1000 0 0.5 1 1.5 2 2.5 3 3.5 4 x 10 4 d  d d  1 as the standards to extract interesting rules As to crossover rate and mutation rate we selected 1 5 for crossover 1 3 for mutation rate1 and 1 3 for mutation rate2 Table 2 Parameters for Fuzzy GNP 5 3 3 1 8  Testing data contain 10  Table 3 Parameters for GA 2 1 0 5 SIMULATIONS neptune and belongs to class 1  is the set of suf\037x of testing data Hence the probability that does not belong to class 1 1 2 000 audit records which are also randomly selected from KDDCUP\22299 dataset There are another nine types of attacks except and 1 1 1 0 2 2 P D test 0 


7 7 92.00 93.00 94.00 95.00 96.00 97.00 98.00 DR Accuracy without rule pruning with rule pruning as well as lower values of R R R R R R as well as lower are calculated before two phase rule pruning and after two phase rule pruning respectively 0.00 1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00 NFR PFR without rule pruning with rule pruning 2827 C C Network NFR NFR NFR NFR NFR and 7648 18 54 65 10000 95 64 15 186 7888 182 1930 7648 18 10000 94 7792 110 55 45 10000 97 91 19 7888 182 107 1930 7792 110 10000 96 and Springer-Verlag Berlin Heidelberg IEEE Trans on Software Engineering Normal Known Unknown Normal Known Unknown Normal Known Unknown Normal Known Unknown and Accuracy Accuracy DR DR C C Accuracy Accuracy PFR 5685 misuse rules In addition the growth of the number of rules was slowed down to some extent as the generation goes on After implementing the 037rst phase rule pruning that is the matching degree-based method 3445 rules are reserved in the rule pool which are 2651 intrusion rules and 794 normal rules Then GA-based pruning phase is implemented to select more effective rules to test the detection ability on the basis of classi\037er constructed Higher values of In Table 4 and Table 5 Fig 7 DR and Accuracy Fig 8 NFR and PFR Generally the hybrid rules extracting method using Fuzzy set theory is effective for discovering more interesting rules for IDS However too many rules include much irrelevant and redundant even misleading information when distinguishing new audit data Therefore we proposed a GA-based two phase rule pruning scheme which utilizes both the statistical information among rules and global search ability of the evolutionary algorithm In this paper a two phase rule pruning scheme is implemented using hybrid rules To verify the effectiveness of this scheme a multi-dimensional probability classi\037er is modeled based on the pruned rules pool The simulation results show the better results of the proposed method compared with the conventional approach without rule pruning  D E Denning 224An intrusion detection model\224 Total Total Total Total 1779 95 56 1930 186 7648 54 7888 99 65 18 182 2064 7808 128 10000 1789 34 107 1930 51 7792 45 7888 17 55 110 182 1857 7881 262 10000 PFR PFR DR  vol 8 pp 2641 1994  A Ghosh and L C Jain 224Ev olutionary computation in data mining\224 PFR PFR DR  53 16 82 17 45 18 Table 5 Classi\037cation results after two phase rule pruning 84 20 31 21 91 22 The classi\037er based on two phase rule pruning is effective compared with the method without rule pruning since it can get higher  vol 13 pp 222-232 1987  B Mukherjee L T  Heberlein and K N Le vitt 224Network Intrusion Detection\224  Printed in Germany 2005  X Y ao and Y  Xu 224Recent Adv ances in Ev olutionDR 99 95 17 and represent better performance of the algorithm Finally 1671 rules are used to construct the classi\037er Fig 6 is the 037tness curve of GA pruning Table 4 Classi\037cation results before two phase rule pruning  1779 3 56 1779 1789 51 0 34 1789 and  More importantly rule pruning is more ef\037cient for anomaly detection since the rules after pruning balances the normal rules and intrusion rules Fig 7 and Fig 8 shows the comparison of the rule pruning case with no rule pruning case It is clari\037ed from Fig 7 and Fig 8 that using two phase pruning scheme can easily 037nd the optimization solution globally C C 6 CONCLUSIONS REFERENCES Accuracy 


 O Nieto and A Badii 224Unsupervised Genetic Algorithm Deployed for Intrusion Detection\224  S Bojani 264 IEEE Trans on Information Forensics and Security  vol 15 no 3 pp 369-398 2007  K Shimada K Hirasa w a and J Hu 224Genetic network programming with acquisition mechanisms of association rules\224  vol 3 no 3 pp 381-389 2008  Y  Gong S Mab u C Chen Y  W ang and K Hirasawa 224Intrusion detection system combining misuse detection and anomaly detection using genetic network programming\224  vol 1 pp 89-100 2001  D P arikh and T  Chen 224Data fusion and cost minimization for intrusion detection\224  vol 41 no 1 pp 130-139 2011  N Lu S Mab u and K Hirasa w a 224Inte grated Rule Mining based on Fuzzy GNP and Probabilistic Classi\037cation for Intrusion Detection\224  New York Springer-Verlag 2000  Z Michale wicz Journal of Advanced Computational Intelligence and Intelligent Informatics In Proc of the SICE-ICASE International Joint Conference  pp 169-177 1985 6 Z  B a n k o vi 264  pp 3463-3467 2009  S Mab u K Hirasa w a and J Hu 224A graph-based evolutionary algorithm Genetic Network Programming\(GNP and its extension using reinforcement learning\224 c c Intelligent Optimization Techniques Genetic Algorithms Tabu Search Simulated Annealing and Neural Networks ary Computation\224 The 2003 Congress on Evolutionary Computation 2003 CEC 22203 Lecture Notes in Computer Science In Proc of the First International Conference on Genetic Algorithms Lawrence Erlbaum Associates Hillsdale HJ In Proc of the DISCEX II 2001 Anaheim IEEE Trans on Systems Man and Cybernetics Part C Genetic Algorithm+Data Structures=Evolution Programs Journal of Computer Science and Technology 2828 vol 21 no 1 pp 1-18 2006  K A De Jong 224Genetic algorithm a 10 year per spective\224  vol 5271/2008 pp 132-139 2008  W  Lu and I T raore 224Detecting ne w forms of network intrusion using genetic programming\224  vol 3 pp 2165-2172 2003  W  Lee S J Hershk op P  K Chan E Eskin W  F an M Miller S Hershkop and J Zhang 224Real Time Data Mining-based Intrusion Detection\224  vol 10 no 1 pp 102-111 2006  S Mab u C Chen N Lu K Shimada and K Hirasawa 224An intrusion detection model based on fuzzy class association rule mining using genetic network programming\224  accepted  D T  Pham and D Karabog a Journal of Advanced Computational Intelligence and Intelligent Informatic Evolutionary Computation MIT press  2nd extended ed New York Springer-Verlag 1994 


 source version. For our system, we used SwiftOWLIM, which has some limitations compared to BigOWLIM. For example, it doesnêt ensure the detection of contradictions   Every OWL ontology has some limitations regarding to the number of triples. The maximum number of triples, in such ontology can be 300-500 millions of triples, depending on the process of inference  Opportunities   Using OWLIM, we make our ontology and our detected association rules public. In this way they become interconnected with other sources from the Internet. Using the REST interface of Sesame, anybody can read or download our ontology. We can do in the same way with other sources from the Internet, we can merge our ontology with other ontologies generating new knowledge. The presented system allows semantic search of the concepts. It represents an open knowledge base   It opens the possibilities for pragmatic web where software agents can search, and even make shopping in the name of a person Threats   Nowadays, there is a relatively small number of companies, which adopt Semantic Web technologies. One reason is that the current systems use relational databases for storing and managing data. Mapping a relational database in an RDF knowledge base may require further works   Ontologies generate heterogeneous knowledge which supports semantic contradictions Semantic Web promotes the principle of AAAé \(Anyone can say Anything About Anything\This means, that anybody can define concepts and relationships between those concepts, according to his/her personal goals This may generate semantic conflicts and contradictions. Any contradiction may produce inconsistencies and will affect the ability of software \(agents, browsers, search engines, etc in the execution of decisions VI  CONCLUSIONS AND FUTURE DEVELOPMENT  The motivation for this research came from the limitations of traditional recommender systems. Building an effective recommender system is challenging. We believe that ontology is a good solution for modeling product and user data In the presented paper we described how can we use OWLIM custom rule-set in order to eliminate some of the shortcomings of a recommender system based on Apriori algorithm. To manage the product and user data, we applied to OWL ontology, which was uploaded in OWLIM semantic repository, thereby we could improve our system using the facilities offered by OWLIM. We applied to semantic web techniques to obtain an open, public ontology which allows interoperability As a future work, we would like to extend this system to an open recommender system using Linked Data. We can combine the described model with Liked Data. The term Linked Data refers to a set of best practices for publishing and connecting structured data on the we order to build a standardized system for publishing his data and connecting it to other data sources, we will follow the Linked Data principles w h ic h s p eci fy  h o w  to u s e t h e  different standards together A CKNOWLEDGMENT  The research presented in this paper is supported by the Gazepower project \(E-marketing and software quality management based on eye tracking analysis, code 2443/2009 funded by UEFISCSU-CNCSIS through the National Research Program IDEI R EFERENCES  1  L. Bing , Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data, vol.10.Issue 2, Springer, DCSA, SIGKDD Explorations 2  M.Adda,  R.Missauri, P.Valtchev, C.Djeraba, Recommendation Strategy based On Relation Rule Mining, 3 rd Workshop on Intelligent Techniques for Web Personalization 3  Z.Yu, Y.Nakamura, S.Jang, S.Kajita, K.Mase, Ontology-Based semantic recommendation for Context-Aware E-Learning, UIC 2007 LNCS 4611, pp. 898Ö907, Springer-Verlag Berlin Heidelberg 2007 4  I.Cantador, A. Bellogin, P.Castells, Ontology-based personalised and context-awarw recommendations of new items, WI-IAT '08 Proceedings of the 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology Ö Vol. 01 IEEE Computer Society Washington, DC, USA 2008 5  L.Zhuhadar, O.Nasraoui, R.Wyatt, E.Romero, Multi-model OntologyBased Hybrid Recommender System in E-learning Domain, in Web Intelligence and Intelligent Agent Technologies, 2009. WI-IAT '09 IEEE/WIC/ACM International Joint Conferences 6  N.Chalortham, P.Leesawat, M.Buranarach, T.Supnithi, Ontology development for pharmaceutical tablet production expert system, in Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology, 2008. ECTI-CON 2008. 5th International Conference 7  J. Yi,   B. Ji,   C. Chen,   X. Tian, Employing Ontology to Build the Engine Fault Diagnosis Expert System, Computer Science and Information Engineering, 2009 WRI World Congress 8  OWLIM Semantic Repository, Copyright 2005-2010 Ontotext AD, a Sirma Group company 9  Rule-basedinferencesé.Internet http://owlim.ontotext.com/display/OWLIMv42/OWLIMLite+Reasoner. Accessed on: 8.09.2011   Open source data visualization and analysis for novice and experts.é http://orange.biolab.si/doc/ofb/assoc.htm . Accessed on 16.06.2011   J.T.Pollock, \(2009\, Semantic Web for Dummies, Wiley Publishing Indianapolis, 2009  C. Bizer, T. Heath, and T. Berners-Lee, Linked data-the story so far Journal on Semantic Web and Information System  
144 


i in the next step. ? and ? are the parameters that control the level of consideration of the pheromone trail D. The algorithm of ABSSR In the following, we present our approach in the form of the algorithm. We suppose that the user is using service S and he wants to stop it Step 1: Service Cluster Selection Based on the service S, we know the service cluster of S is sc1. The cluster selection list is generated using association rules. Suppose the user selects sc2 as the cluster of next service Step 2: Parameters Initialization This step is pre-processing, in which the parameters of and Q are initialized for ant colony navigation model. Moreover, a time window for frequency is set Step 3: Heuristic Information Calculation The heuristic information ? is evaluated according to the connectedness between S and some feasible services in sc2 Suppose there are n services denoted as S1, S2, . . . , Sn, can be as the next selection from service S, a set of heuristic information {?SS1 , ?SS2 , . . . , ?SSn} is calculated using Eq.\(1 Step 4: Pheromone Trail Intensity Calculation 0 5 10 15 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 The connectedness between the service  i  and service  j   P ij Fig. 3. Pij variations by different value of the connectedness 1 1.5 2 2.5 3 3.5 4 4.5 5 0.48 0.49 


0.5 0.51 0.52 0.53 0.54 0.55 0.56 distanceij   P ij Fig. 4. Pij variations with the increment of distanceij 0 10 20 30 40 50 0.35 0.4 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 frequencyj   P ij Fig. 5. Pij variations with the increment of frequencyj 1 2 3 4 5 6 7 8 9 10 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 reputationj 


  P ij Fig. 6. Pij variations with the increment of reputationij Based on the attributes of service \(distance, frequency and reputation SS1 , ?SS2 , . . . , ?SSn} is calculated, according to Eqs.\(2-4 Step 5: Probability Calculation and Service Selection In this step the set of probability {PSS1 , PSS2 , . . . , PSSn are calculated on the basic of {?SS1 , ?SS2 , . . . , ?SSn} and SS1 , ?SS2 , . . . , ?SSn} using Eq.\(5 is generated in decreasing order of {PSS1 , PSS2 , . . . , PSSn Suppose that the user selects service S? in the list as the next service he wants Step 6: Updating After the user selects a service S? in the service selection list, the values of three attributes should be updated, including the connectedness between service S and S?, frequencyS and reputationS IV. EXPERIMENTAL RESULTS To evaluate the effectiveness of ABSSR, we utilize attributebased service recommendation to test the proposed ant colony navigation model. In the model, the probability in ant colony KB is related to the values of attributes of services Experiment 1: In this experiment, the impact on the probability from different values of the heuristic information ?ij In Eq.\(1 i to j. Without lose of generality, we set Cij from 1 to 15 In addition, in the service cluster of service j, there are four other services as the next service of service i, and they are set randomly between 1 and 15 With the parameters ? = 1 and ? = 8, the probability variation is illustrated in Fig. 3. From the result, with the same pheromone trail intensity, the more Cij is, the higher Pij is Experiment 2: In experiment 2, based on the same heuristic information ?ij, the relationship between Pij and the attributes will be analyzed. The change of attributes will impact on pheromone trail intensity ?ij. In the ABSSR, three attributes are considered: distance, frequency and reputation. If all of the attributes are inconsistent in the experiment, the results are confused. Consequently, we observe one attribute with 


two other remaining attributes be constant. To protect the same order among attributes, we fixed the parameters ? = 10 2500, ? = 1000, ? = 2 and ? = 1 In Fig. 4, the distance between the service i and j is increased from 1 to 5 \(kilometers attributes. From the figure, we can observe that the probability is decreased with the increment of the distanceij, and vice versa. Similarly, we varied the values of the frequencyj and reputationj to analyze the influence of Pij \(frequencyj is from 1 to 50, and reputationj is from 1 to 100 given in Fig. 5 and Fig. 6. The probability has an increase corresponding to the growths of frequencyj and reputationj V. CONCLUSION As the number of the users of networks has been increased greatly nowadays, the proactive service recommendation in m-commerce becomes an important issue. It is computed by the contextual information from sensor nodes. Although some researchers focus on context history, the attributes of a service have been ignored. In this paper, we have presented an attribute-based scheme for recommending services for consumers. For this end, we grouped all of the given services into several clusters, employed a cluster association model and an ant colony navigation model to track the consumers behaviors, and then calculate the degree of the influences from the attributes of services in relation to the recommendation After these, a service recommendation list is generated for consumers. The proposed models were implemented and the experimental results have shown that the varieties of the attributes do have affects on ranking lists. By refining the system, the proposed scheme could be further analyzed and potentially get its own place in practice REFERENCES 1] Smith, A.D.: Exploring m-commerce in terms of viability, growth and challenges. Int. J. Mobile Communications, 2006, 4\(6 2] Cao, Y., and Li, Y.: An intelligent fuzzy-based recommendation system for consumer electronic products. Expert Systems with Applications 2007, 33\(1 3] Buratti, C., Conti, A., Dardari, D., and Verdone, R.: An Overview on Wireless Sensor Networks Technology and Evolution, Sensors., 2009, 9 9 4] Hong, J., Suh, E.H., and Kim, J.: Context-aware system for proactive personalized service based on context history. Expert Systems with 


Applications, 2009, 36\(4 5] Sadeh, N.M., Chan, T.C., Van, L., and Kwon, O.: Creating an Open Agent Environment for Context-aware M-Commerce. In: Agentcities Challenges in Open Agent Environments, Ed. by Burg, Dale, Finin Nakashima, Padgham, Sierra, and Willmott, LNAI, Springer Verlag, 2003 pp. 152-158 6] Mayrhofer, R.: Context Prediction based on Context Histories: Expected Benefits, Issues and Current State-of-the-Art. In Proc. of the 1st Intl Workshop on Exploiting Context Histories in Smart Environments, May 2005 7] Samaan, N., and Karmouch, A.: A mobility prediction architecture based on contextual knowledge and spatial conceptual maps. IEEE Transactions on Mobile Computing, 2005, 4\(6 8] Jung, J.J.: Contextualized mobile recommendation service based on interactive social network discovered from mobile users. Expert Systems with Applications, 2009, 36\(9 9] Gong, R., Ning, K., and Li, Q.: Context modeling and measuring for proactive resource recommendation in business collaboration. Computers and Industrial Engineering , 2009, 57\(1 10] Kuo, M.H. Chen, L.C., and Liang, C.W.: Building and evaluating a location-based service recommendation system with a preference adjustment mechanism. Expert Systems with Applications, 2009, 36\(2 3543-3554 11] Luther, M., Fukazawa, Y., and Wagner, M.: Situational reasoning for task-oriented mobile service recommendation. The Knowledge Engineering Review, 2008, 23\(1 12] Kwon, O., and Kim, J.: Concept lattices for visualizing and generating user profiles for context-aware service recommendations. Expert Systems with Applications, 2009, 36\(2 13] Song, S., Hwang, K., Zhou, R., and Kwok, Y.K.: Trusted P2P transactions with fuzzy reputation aggregation. IEEE Internet Computing, 2005 9\(6 14] Wu, X.D., Kumar, V., Quinlan, J.R., Ghosh, J., Yang, Q., Motoda, H McLachlan, G.J., Ng, A., Liu, B., Yu, P.S., Zhou, Z.-H., Steinbach, M Hand, D.J., and Steinberg, D.: Top 10 algorithms in data mining, Knowl Inf. Syst., 2008, 14, \(1 15] Dorigo, M., and Gambardella, L.M.: Ant colony system: a cooperative learning approach to the traveling salesman problem. IEEE Trans. Evolut Comput. 1997,1\(1 16] Colorni, A., Dorigo, M. and Maniezzo, V.: Distributed optimization by ant colonies. Proc. of European Conf. on Artificial Life, \(Ed and Bourgine, P., Elsevier Publishing, Paris, France, 1991, pp. 134-142 


5 1559 8605 8 0 0 10172 4 1559 34172 129 1 4 2 35876 It can get the same frequent activities that PHP algorithm and improved PHP algorithm, in Tab.2 we can find that there is inverse ratio between frequent activity and minimum support count, when the minimum support counts decrease frequent activities increase, just as the real world. The cost of CPU time compared as Fig.2 of these two algorithms 213 124 89 73 57 53 52 65 0 40 80 120 160 200 240 4 5 6 7 Minimum Support Count T i m e  s e c o n d s  PHP Improved Fig.2 the compare CPU time cost of PHP and improved PHP From Fig.2, as support count decreasing, the CPU running 


time of these two algorithms gets increasing, but the PHP is much speeder than the other, especially when count in 6. so wen know the more frequent itemsets and their items, the more efficient of the algorithm V. THE APPLICATION After we got the frequent itemset by the improved PHP algorithm, we can generate the strong associate rule that satisfied minimum support and minimum confidence. The confidence can be computed by Confidence\(A ? B A | B A  B support_count\(A Support_count\(A  B support_count\(A And then we can use confidence threshold strengthen the association, we use improved PHP algorithm dig X company 2002 year sale data, minimum support is 5, 3-itemset, they are 83,549,915}, {485,558,1290}, {454,1097,1546 83,549,982}, {631,980,1490}, {454,1103,1546 810,1026,1469}, {360,830,1036}, and their none null subset as for frequent 3-item {83,549,915}, we can get 83 ? 549? 915,      confidence = 5/9 = 56 83 ? 915? 549,      confidence = 5/5 = 100 915 ? 549? 83,      confidence = 5/5 = 100 83? 915 ? 549,      confidence = 5/50 = 10 549? 83 ? 915,      confidence = 5/78 = 6 915? 83 ? 549,      confidence = 5/73= 7 If the minimum confidence threshold is 80%, only if 83 ? 915 ? 549and 915 ? 549 ? 83 can generate strong associate rules, after these rules, we can not only arrange the shelf of related goods in pairs or groups, but also combine those goods that have most consumers, promote the consumer the pretermission goods. For example, the stronger associate rule 83 ? 915? 549, from the database field product, we know product_id corresponding product_name, this stronger rule is pillow ? pillow clothe ? bedsheet , if there is someone bought pillow and pillow clothe, then promote good bedsheet is an efficient way of sale VI. CONCLUSION We put Hash candidates k-itemset into affair of Dk, that is itemset include in affair, so CPU running time decreased improved PHP algorithm is more efficiency, we can use this improved PHP algorithm in commercial database digging and 


other wide usages REFERENCES 1] YANG Xuejun. The application of CRM[J].computer application,2002\(5 2] CHEN Shuangqiu, LIU Dinghong, LI Hongxing, the costumer analysis and design based on data warehouse[J].computer engineering and application,2001\(4 3] Jawei Han and Micheline Kamber,Data Mining:Comcepts and Techniques \(2001 4] J.D.Holt,and S.M.Chung, Efficient Mining of Association Rules in Text Databases CIKM99,  Kansas City, USA, pp.234-242, \(Nov.1999 5] J.S.Park, M.S.Chen and P.S.Yu, Using a Hash-Based Method with Transaction Trimming for Mining Association Rules, IEEE Transactions on Knowledge and Data Engineering, Vol.9, No.5 Sept/Oct, 1997 6] S. A. zel and H. A. Gvenir, An Algorithm for Mining Association Rules Using Perfect Hashing and Database Pruning, in: Proceedings of  the Tenth Turkish Symposium on Artificial Intelligence and Neural Networks \(TAINN'2001 Eds Gazimagusa, T.R.N.C. \(June 2001 7] SUN Zhengxi, The theory and technology of Intelligent control M].Beijing Qinghua press, 1997 8] Mitani, Koji, CRM pursues economies of depth [J]. Japanese Journal of Diamond Harvard Business, 1999, \(617  the Tenth Turkish Symposium on Artificial Intelligence and Neural Networks \(TAINN'2001 Eds Gazimagusa, T.R.N.C. \(June 2001 7] SUN Zhengxi, The theory and technology of Intelligent control M].Beijing Qinghua press, 1997 8] Mitani, Koji, CRM pursues economies of depth [J]. Japanese Journal of Diamond Harvard Business, 1999, \(617  


algorithm could not extract the correct hierarchy with 30 assigning five labels incorrectly to the root label. None of the HE algorithms could extract the correct hierarchy in the absence of 40% multi-labels. With 40% and Voting, the number of labels falsely assigned to the root was 13, while with GT it was only three. For BoosTexter, Voting assigned two labels wrongly to the root label in the experiment with TABLE I 20 NEWSGROUPS ALL, -20%, -30% AND -40% RESULTS Measure all 20% 30% 40%ARAM FAM kNN BoosT. ARAM FAM kNN BoosT. ARAM FAM kNN BoosT. ARAM FAM kNN BoosT A 0.635 0.638 0.429 0.549 0.613 0.633 0.383 0.456 0.596 0.619 0.322 0.412 0.563 0.591 0.255 0.387 F1 0.694 0.696 0.565 0.677 0.675 0.688 0.528 0.604 0.662 0.677 0.469 0.566 0.640 0.657 0.392 0.542 F 0.691 0.692 0.480 0.605 0.671 0.688 0.429 0.507 0.658 0.676 0.364 0.465 0.630 0.652 0.296 0.441 OE 0.221 0.220 0.336 0.222 0.259 0.236 0.387 0.275 0.273 0.259 0.415 0.301 0.301 0.291 0.434 0.316 RL 0.100 0.098 0.124 0.073 0.108 0.110 0.128 0.077 0.098 0.103 0.132 0.079 0.101 0.106 0.135 0.082 C 4.188 4.168 6.080 4.164 4.397 4.446 6.184 4.286 4.246 4.340 6.326 4.328 4.334 4.463 6.397 4.379 AP 0.789 0.790 0.677 0.778 0.774 0.782 0.657 0.758 0.769 0.774 0.645 0.747 0.759 0.764 0.638 0.740 AUPRC 0.775 0.772 0.618 0.749 0.743 0.727 0.581 0.691 0.733 0.722 0.555 0.671 0.715 0.708 0.535 0.660 H-loss 0.103 0.123 0.121 0.094 0.102 0.098 0.124 0.108 0.106 0.103 0.132 0.117 0.115 0.111 0.145 0.122 Wins 1 5 0 3 1 6 0 2 2 6 0 1 2 6 0 1 LCAPD 0 0 0 0 0 0 0 0 0 0 0.12 0 0.05 0 0 0 0.51 0.26 0.17 0 CTED 0 0 0 0 0 0 0 0 0 0 0.14 0 0.07 0 0 0 0.50 0.21 0.21 0 TO* 0 0 0 0 0 0 0 0 0 0 0.11 0 0.05 0 0 0 0.39 0.18 0.15 0 30% removed labels and and six labels in the experiment with 40% removed labels. GT resulted in zero distances in the both cases. Assigning more labels to the root creates more shallow and wider hierarchies \(trivial case as stated before The good hierarchy extraction with ART networks demonstrates the system robustness  even with strongly damaged data the system can rebuild the original hierarchy C. RCV1-v2 Dataset The next experiment was based on the tokenized version of 


the RCV1-v2 dataset introduced in [21]. Only the topics label set consisting of 103 labels arranged in a hierarchy of depth four is examined here. Documents of the original training set of 23,149 were converted to TF-IDF weights and normalized Afterwards the set was splitted in 15,000 randomly selected documents as training and the remaining as test samples In this case, the Voting variant of HE applied to the TTML resulted in the LCAPD, CTED and TO* values 0.12, 0.15 and 0.13, respectively. The corresponding values of the GT variant are 0.05, 0.07 and 0.05. The poor performance of the Voting method is due to the fact that for the TTML only very high threshold values succeed in removing enough noise The Voting results are thus dominated by bad hierarchies extracted for all but the highest thresholds The classification and HE results for this dataset are shown in Table II. ML-ARAM has better performance results on this data set in all points than ML-FAM except for RL being the best of all classifiers in terms of the multi-label performance measures. BoosTexter is the best in terms of all ranking measures For both HE algorithms the distances of BoosTexter are the best, those of ML-FAM second, followed ML-ARAM and ML-kNN. All three distance measures correlate. Interesting is also that for ML-kNN the distance values obtained by both HE methods are almost the same The hierarchy extracted by GT from the TTML has much lower distances values as compared with the hierarchies extracted by both methods from predicted multi-labels. This reflects a specific problem of HE, since only a small fraction of the incorrectly classified multi-labels can prevent building of a proper hierarchy. For example, 16.5% of misassigned labels in the extracted hierarchy are responsible for about 80% of LCAPD calculated from the predictions of MLARAM. This large part of the HE error is caused by only 4% of the test data. Under these circumstances the other distances behave analogically. Most labels were not assigned making them trivial edges, but six labels were assigned to a false branch. This can happen when labels have a strong correlation and in the step Hierarchy Construction of the basic algorithm the parent is not unique in the confidence matrix. BoosTexters results suffer less from this problem because it generally sets more labels for each test sample 


Both HE algorithms behaved similarly on the predictions of the ART networks. They constructed a deeper hierarchy than the original one and wrongly assigned the same 11 labels to the root node. The higher distances come from Voting assigning more labels to the wrong branch. For MLkNN both algorithms again create very similar hierarchy trees, both misassigned 28 labels to the root label. For BoosTexter it was seven with Voting and eight with GT Voting produced a deeper hierarchy here D. WIPO-alpha Dataset The WIPO-alpha dataset1 comprises patent documents collected by the World Intellectual Property Organization WIPO ments. Preprocessing was performed as follows: From each document, the title, abstract and claims texts were extracted stop words were removed using the list from [20] and words were stemmed using the Snowball stemmer [22]. All but the 1%-most-frequent stems were removed, the remaining stems were converted to TF-IDF weights and these were normalized to the range of [0, 1]. Again, TF-IDF conversion and normalization were done independently for the training and the test set. The original hierarchy consists, from top to bottom, of 8 sections, 120 classes, 630 subclasses and about 69,000 groups. In our experiment, only records from the sections A \(5802 training and 5169 test samples H \(5703 training and 5926 test samples 1http://www.wipo.int/classifications/ipc/en/ITsupport/Categorization dataset/wipo-alpha-readme.html August 2009 TABLE II RCV1-V2 RESULTS Measure ARAM FAM kNN BoosT A 0.748 0.731 0.651 0.695 F1 0.795 0.777 0.735 0.769 F 0.805 0.787 0.719 0.771 OE 0.077 0.089 0.104 0.063 RL 0.087 0.086 0.026 0.015 C 11.598 11.692 8.563 5.977 AP 0.868 0.860 0.839 0.873 AUPRC 0.830 0.794 0.807 0.838 H-loss 0.068 0.077 0.097 0.081 Wins 4 0 0 5 LCAPD 0.29 0.22 0.25 0.20 0.34 0.34 0.21 0.18 


CTED 0.32 0.23 0.28 0.22 0.38 0.37 0.24 0.20 TO* 0.27 0.18 0.22 0.17 0.31 0.30 0.21 0.17 document in the collection has one so-called main code and any number of secondary codes, where each code describes a group the document belongs to. Both main and secondary codes were used in the experiment, although codes pointing to groups outside of sections A and H were ignored. We also removed groups that did not contain at least 30 training and 30 test records \(and any documents that only belonged to such small groups 7,364 test records with 924 attributes each and a label set of size 131 In this case, the Voting variant of the HE algorithm applied to the TTML resulted in the LCAPD, CTED and TO* values of 0.13, 0.12 and 0, respectively. GT showed the same values. Remarkable are the TO* distances, which are equal to 0. This is due to the fact that the WIPO-alpha hierarchy contains 16 single-child labels that are not partitioned by the true multi-labels: whenever a single-child label j is contained in a multi-label, so is its child, and vice versa. It is therefore theoretically impossible to deduce from the multilabels which of them is the parent of the other. As a result the HE algorithms often choose the wrong parent, resulting in higher LCAPD and CTED values. TO*, as described above is invariant under such choices The results obtained on the WIPO-alpha dataset are shown in Table III. The classification performance of the ART-based networks on this dataset is slightly worse than that of BoosTexter. Mostly in the terms of OE, RL, C, AP, AUPRC, and H-loss measures BoosTexter is better because its rankings are better and it assigned more labels to each sample. But the ART networks have better HE results because their predicted labels are more consistent with the original hierarchy. MLkNN has the worst classification results and distance values again. The reason for the high relative difference between LCAPD as well as CTED and TO* obtained for the ART networks or BoosTexter as compared to the results of the other datasets is because most of the labels were assigned in the right branch but not exactly where they belong Both HE algorithms extracted the same hierarchy from the predictions of ML-ARAM and a very similar hierarchy for ML-FAM. About 5% labels were assigned wrongly to the 


root label in the hierarchies of the ART networks. For MLTABLE III WIPO-ALPHA\(AH Measure ARAM FAM kNN BoosT A 0.588 0.590 0.478 0.564 F1 0.694 0.691 0.614 0.693 F 0.682 0.682 0.593 0.679 OE 0.052 0.057 0.110 0.042 RL 0.135 0.136 0.056 0.025 C 25.135 25.269 22.380 11.742 AP 0.790 0.785 0.724 0.802 AUPRC 0.720 0.684 0.688 0.762 H-loss 0.090 0.093 0.149 0.079 Wins 1 2 0 6 LCAPD 0.16 0.16 0.17 0.17 0.32 0.38 0.21 0.21 CTED 0.18 0.18 0.19 0.19 0.38 0.53 0.27 0.27 TO* 0.05 0.05 0.07 0.07 0.24 0.32 0.08 0.08 kNN both HE methods wrongly assigned about the half of the labels and about 20% of total labels were assgined to the root label. Here, GT extracted a much worse hierarchy as shown by CTED being 0.15 higher for GT than for Voting For BoosTexter both HE methods built the same hierarchy and no label was wrongly assigned to the root. All extracted hierarchies were one level deeper than the original one Although Voting produced worse hierarchies than GT on two previous datasets, this time its distance values were comparable or even better. In comparison to Voting, GT has higher values for all distances on the multi-labels of MLkNN. Voting has the advantage of being a much simpler method and of being more dataset independent. Still the tree distances have the same ranking order for all classifiers for both HE methods VI. CONCLUSION In this paper we studied Hierarchical Multi-label Classification \(HMC tive was to derive hierarchical relationships between output classes from predicted multi-labels automatically. We have developed a data-mining-system based on two recently proposed multi-label extensions of the FAM and ARAM neural networks: ML-FAM and ML-ARAM as well as on a Hierarchy Extraction \(HE algorithm builds association rules from label co-occurrences 


and has two modifications. The presented approach is general enough to be used with any other multi-label classifier or HE algorithm. We have also developed a new tree distance measure for quantitative comparison of hierarchies In extensive experiments made on three text-mining realworld datasets, ML-FAM and ML-ARAM were compared against two state-of-the-art multi-label classifiers: ML-kNN and BoosTexter. The experimental results confirm that the proposed approach is suitable for extracting middle and large-scale class hierarchies from predicted multi-labels. In future work we intend to examine approaches for measuring the quality of hierarchical multi-label classifications REFERENCES 1] M. Ruiz and P. Srinivasan, Hierarchical text categorization using neural networks, Information Retrieval, vol. 5, no. 1, pp. 87118 2002 2] N. Cesa-Bianchi, C. Gentile, and L. Zaniboni, Incremental algorithms for hierarchical classification, The Journal of Machine Learning Research, vol. 7, pp. 3154, 2006 3] , Hierarchical classification: combining Bayes with SVM, in Proceedings of the 23rd international conference on Machine learning ACM New York, NY, USA, 2006, pp. 177184 4] F. Wu, J. Zhang, and V. Honavar, Learning classifiers using hierarchically structured class taxonomies, in Proceedings of the 6th International Symposium on Abstraction, Reformulation And Approximation Springer, 2005, p. 313 5] L. Cai and T. Hofmann, Hierarchical document categorization with support vector machines, in Proceedings of the thirteenth ACM international conference on Information and knowledge management ACM New York, NY, USA, 2004, pp. 7887 6] C. Vens, J. Struyf, L. Schietgat, S. Dz?eroski, and H. Blockeel Decision trees for hierarchical multi-label classification, Machine Learning, vol. 73, no. 2, pp. 185214, 2008 7] E. P. Sapozhnikova, Art-based neural networks for multi-label classification, in IDA, ser. Lecture Notes in Computer Science, N. M Adams, C. Robardet, A. Siebes, and J.-F. Boulicaut, Eds., vol. 5772 Springer, 2009, pp. 167177 8] M. Zhang and Z. Zhou, ML-kNN: A lazy learning approach to multilabel learning, Pattern Recognition, vol. 40, no. 7, pp. 20382048 2007 9] R. Schapire and Y. Singer, BoosTexter: A boosting-based system for text categorization, Machine learning, vol. 39, no. 2, pp. 135168 


2000 10] K. Zhang, A constrained edit distance between unordered labeled trees, Algorithmica, vol. 15, no. 3, pp. 205222, 1996 11] A. Maedche and S. Staab, Measuring similarity between ontologies Lecture notes in computer science, pp. 251263, 2002 12] G. Carpenter, S. Martens, and O. Ogas, Self-organizing information fusion and hierarchical knowledge discovery: a new framework using ARTMAP neural networks, Neural Networks, vol. 18, no. 3, pp. 287 295, 2005 13] A.-H. Tan and H. Pan, Predictive neural networks for gene expression data analysis, Neural Networks, vol. 18, pp. 297306, April 2005 14] G. Carpenter, S. Grossberg, N. Markuzon, J. Reynolds, and D. Rosen Fuzzy ARTMAP: A neural network architecture for incremental supervised learning of analog multidimensional maps, IEEE Transactions on Neural Networks, vol. 3, no. 5, pp. 698713, 1992 15] Y. Freund and R. Schapire, A decision-theoretic generalization of online learning and an application to boosting, Journal of computer and system sciences, vol. 55, no. 1, pp. 119139, 1997 16] K. Zhang and T. Jiang, Some MAX SNP-hard results concerning unordered labeled trees, Information Processing Letters, vol. 49 no. 5, pp. 249254, 1994 17] G. Tsoumakas and I. Vlahavas, Random k-labelsets: An ensemble method for multilabel classification, Lecture Notes in Computer Science, vol. 4701, p. 406, 2007 18] K. Punera, S. Rajan, and J. Ghosh, Automatic construction of nary tree based taxonomies, in Proceedings of IEEE International Conference on Data Mining-Workshops. IEEE Computer Society 2006, pp. 7579 19] T. Joachims, A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization, in Proceedings of the Fourteenth International Conference on Machine Learning. Morgan Kaufmann Publishers Inc. San Francisco, CA, USA, 1997, pp. 143151 20] A. McCallum, Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering, 1996 http://www.cs.cmu.edu/ mccallum/bow 21] D. Lewis, Y. Yang, T. Rose, and F. Li, RCV1: A new benchmark collection for text categorization research, The Journal of Machine Learning Research, vol. 5, pp. 361397, 2004 22] M. Porter, Snowball: A language for stemming algorithms, 2001 http://snowball.tartarus.org/texts/introduction.html 


the US census data set. The size of pilot sample is 2000, and all 50 rules are derived from this pilot sample. In this experiment the ?xed value x for the sample size is set to be 300. The attribute income is considered as a differential attribute, and the difference of income of husband and wife is studied in this experiment. Figure 3 shows the performance of the 5 sampling 331 6DPSOLQJ9DULDQFH             9D UL DQ FH R I V WL PD WL RQ  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW    


      6D PS OL QJ  RV W 9DU 9DU 9DU 5DQG b 6DPSOLQJ$FFXUDF          5  9DU 9DU 9DU 5DQG c Fig. 2. Evaluation of Sampling Methods for Association Rule Mining on the Yahoo! Dataset procedures on the problem of differential rule mining on the US census data set. The results are also similar to the experiment results for association rule mining: there is a consistent trade off between the estimation variance and sampling cost by setting their weights. Our proposed methods have better performance than simple random sampling method 


We also evaluated the performance of our methods on the Yahoo! dataset. The size of pilot sampling is 2000, and the xed value x for the sample size is 200. The attribute price is considered as the target attribute. Figure 4 shows the performance of the 5 sampling procedures on the problem of differential rule mining on the Yahoo! dataset. The results are very similar to those from the previous experiments VI. RELATED WORK We now compare our work with the existing work on sampling for association rule mining, sampling for database aggregation queries, and sampling for the deep web Sampling for Association Rule Mining: Sampling for frequent itemset mining and association rule mining has been studied by several researchers [23], [21], [11], [6]. Toivonen [23] proposed a random sampling method to identify the association rules which are then further veri?ed on the entire database. Progressive sampling [21], which is based on equivalence classes, involves determining the required sample size for association rule mining FAST [11], a two-phase sampling algorithm, has been proposed to select representative transactions, with the goal of reducing computation cost in association rule mining.A randomized counting algorithm [6] has been developed based on the Markov chain Monte Carlo method for counting the number of frequent itemsets Our work is different from these sampling methods, since we consider the problem of association rule mining on the deep web. Because the data records are hidden under limited query interfaces in these systems, sampling involves very distinct challenges Sampling for Aggregation Queries: Sampling algorithms have also been studied in the context of aggregation queries on large data bases [18], [1], [19], [25]. Approximate Pre-Aggregation APA  categorical data utilizing precomputed statistics about the dataset Wu et al. [25] proposed a Bayesian method for guessing the extreme values in a dataset based on the learned query shape pattern and characteristics from previous workloads More closely to our work, Afrati et al. [1] proposed an adaptive sampling algorithm for answering aggregation queries on hierarchical structures. They focused on adaptively adjusting the sample size assigned to each group based on the estimation error in each group. Joshi et al.[19] considered the problem of 


estimating the result of an aggregate query with a very low selectivity. A principled Bayesian framework was constructed to learn the information obtained from pilot sampling for allocating samples to strata Our methods are clearly distinct for these approaches. First strata are built dynamically in our algorithm and the relations between input and output attributes are learned for sampling on output attributes. Second, the estimation accuracy and sampling cost are optimized in our sample allocation method Hidden Web Sampling: There is recent research work [3 13], [15] on sampling from deep web, which is hidden under simple interfaces. Dasgupta et al.[13], [15] proposed HDSampler a random walk scheme over the query space provided by the interface, to select a simple random sample from hidden database Bar-Yossef et al.[3] proposed algorithms for sampling suggestions using the public suggestion interface. Our algorithm is different from their work, since our goal is sampling in the context of particular data mining tasks. We focus on achieving high accuracy with a low sampling cost for a speci?c task, instead of simple random sampling VII. CONCLUSIONS In this paper, we have proposed strati?cation based sampling methods for data mining on the deep web, particularly considering association rule mining and differential rule mining Components of our approach include: 1 the relation between input attributes and output attributes of the deep web data source, 2 maximally reduce an integrated cost metric that combines estimation variance and sampling cost, and 3 allocation method that takes into account both the estimation error and the sampling costs Our experiments show that compared with simple random sampling, our methods have higher sampling accuracy and lower sampling cost. Moreover, our approach allows user to reduce sampling costs by trading-off a fraction of estimation error 332 6DPSOLQJ9DULDQFH      


     V WL PD WL RQ R I 9D UL DQ FH  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW          6D PS OL QJ  RV W 9DU 9DU 


9DU 5DQG b 6DPSOLQJ$FFXUDF          5  9DU 9DU 9DU 5DQG c Fig. 3. Evaluation of Sampling Methods for Differential Rule Mining on the US Census Dataset 6DPSOLQJ9DULDQFH             9D UL DQ FH R I V WL 


PD WL RQ  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW          6D PS OL QJ  RV W  9DU 9DU 9DU 5DQG b 6DPSOLQJ$FFXUDF         


    5  9DU 9DU 9DU 5DQG c Fig. 4. Evaluation of Sampling Methods for Differential Rule Mining on the Yahoo! Dataset REFERENCES 1] Foto N. Afrati, Paraskevas V. Lekeas, and Chen Li. Adaptive-sampling algorithms for answering aggregation queries on web sites. Data Knowl Eng., 64\(2 2] Rakesh Agrawal and Ramakrishnan Srikant. Fast algorithms for mining association rules. In Proceedings of the 20th International Conference on Very Large Data Bases, pages 487499, 1994 3] Ziv Bar-Yossef and Maxim Gurevich. Mining search engine query logs via suggestion sampling. Proc. VLDB Endow., 1\(1 4] Stephen D. Bay and Michael J. Pazzani. Detecting group differences Mining contrast sets. Data Mining and Knowledge Discovery, 5\(3 246, 2001 5] M. K. Bergman. The Deep Web: Surfacing Hidden Value. Journal of Electronic Publishing, 7, 2001 6] Mario Boley and Henrik Grosskreutz. A randomized approach for approximating the number of frequent sets. In ICDM 08: Proceedings of the 2008 Eighth IEEE International Conference on Data Mining, pages 4352 Washington, DC, USA, 2008. IEEE Computer Society 7] D. Braga, S. Ceri, F. Daniel, and D. Martinenghi. Optimization of Multidomain Queries on the Web. VLDB Endowment, 1:562673, 2008 8] R. E. Ca?isch. Monte carlo and quasi-monte carlo methods. Acta Numerica 7:149, 1998 9] Andrea Cali and Davide Martinenghi. Querying Data under Access Limitations. In Proceedings of the 24th International Conference on Data Engineering, pages 5059, 2008 10] Bin Chen, Peter Haas, and Peter Scheuermann. A new two-phase sampling based algorithm for discovering association rules. In KDD 02: Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 462468, New York, NY, USA, 2002 ACM 


11] W. Cochran. Sampling Techniques. Wiley and Sons, 1977 12] Arjun Dasgupta, Gautam Das, and Heikki Mannila. A random walk approach to sampling hidden databases. In SIGMOD 07: Proceedings of the 2007 ACM SIGMOD international conference on Management of data pages 629640, New York, NY, USA, 2007. ACM 13] Arjun Dasgupta, Xin Jin, Bradley Jewell, Nan Zhang, and Gautam Das Unbiased estimation of size and other aggregates over hidden web databases In SIGMOD 10: Proceedings of the 2010 international conference on Management of data, pages 855866, New York, NY, USA, 2010. ACM 14] Arjun Dasgupta, Nan Zhang, and Gautam Das. Leveraging count information in sampling hidden databases. In ICDE 09: Proceedings of the 2009 IEEE International Conference on Data Engineering, pages 329340 Washington, DC, USA, 2009. IEEE Computer Society 15] Loekito Elsa and Bailey James. Mining in?uential attributes that capture class and group contrast behaviour. In CIKM 08: Proceeding of the 17th ACM conference on Information and knowledge management, pages 971 980, New York, NY, USA, 2008. ACM 16] E.K. Foreman. Survey sampling principles. Marcel Dekker publishers, 1991 17] Ruoming Jin, Leonid Glimcher, Chris Jermaine, and Gagan Agrawal. New sampling-based estimators for olap queries. In ICDE, page 18, 2006 18] Shantanu Joshi and Christopher M. Jermaine. Robust strati?ed sampling plans for low selectivity queries. In ICDE, pages 199208, 2008 19] Bing Liu. Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data \(Data-Centric Systems and Applications Inc., Secaucus, NJ, USA, 2006 20] Srinivasan Parthasarathy. Ef?cient progressive sampling for association rules. In ICDM 02: Proceedings of the 2002 IEEE International Conference on Data Mining, page 354, Washington, DC, USA, 2002. IEEE Computer Society 21] William H. Press and Glennys R. Farrar. Recursive strati?ed sampling for multidimensional monte carlo integration. Comput. Phys., 4\(2 1990 22] Hannu Toivonen. Sampling large databases for association rules. In The VLDB Journal, pages 134145. Morgan Kaufmann, 1996 23] Fan Wang, Gagan Agrawal, Ruoming Jin, and Helen Piontkivska. Snpminer A domain-speci?c deep web mining tool. In Proceedings of the 7th IEEE International Conference on Bioinformatics and Bioengineering, pages 192 199, 2007 24] Mingxi Wu and Chris Jermaine. Guessing the extreme values in a data set a bayesian method and its applications. VLDB J., 18\(2 25] Mohammed J. Zaki. Scalable algorithms for association mining. IEEE Transactions on Knowledge and Data Engineering, 12:372390, 2000 


333 



Detecting Impolite Crawler by using Time Series Analysis 
Abstract 
Zhiqian Chen Dept. of Software Engineering Peking University Beijing, China imczq@pku.edu.cn Wenya Feng Dept. of Software Engineering Peking University Beijing, China pkuwenyafeng@gmail.com 
Numerous web crawlers especially impolite crawlers visit websites to get contents every day, which yields higher access frequency than the websites can hold. The big traffic of impolite crawlers causes a strong hazard on analysis of normal users and advertisement income. In this paper, we present a 
method to detect impolite crawlers by using time series analysis. This method is applied to real data of web server logs Compared with the old methods only using common log attributes as features, the method using time series features improves detection accuracy by at least 20 
Keywords-impolite crawlers; time series; web server log; data mining; web analysis 
 
 I NTRODUCTION  A new method is introduced to detect general impolite crawlers, which helps significantly improve accuracy. We use machine learning algorithms with features extracted by 
I 
using time series analysis The visitors are divided into three groups: normal users impolite crawlers and polite crawlers. Polite crawlers, such as Google robots, gently get contents from websites and are easy to detect, so they will not be discussed in this paper Impolite crawlers who quickly download resources from the target websites bring at least two types of harm. On one hand they disturb normal web analysis. If a huge amount of traffic from impolite crawlers cannot be identified, they could be considered as normal users. Finally it will lead to a bad decision. On the other hand, impolite crawlers access 
websites without reading advertisements, and they will not purchase anything including the advertisement, but the advertisers have paid for it In this paper, a general, simple and feasible method based on common server logs that meet the criterion of W3C log format is proposed. These servers are common, such as Apache, Lighttpd, and Nginx. Crawler access and normal user access are different. Generally, the crawlersê behaviors are regular, while the normal usersê behaviors are irregular A number of features that can deliver the degree of regularity are needed. From every single piece of log, its common 
attributes are extracted, such as access time, access URL referred URL, and user agent. In addition, some features are extracted by time series analysis that will show more information of a crawler and help us detect impolite crawlers more accurately The rest of this paper is organized as follows:  the related work is reviewed in section II. The proposed method is introduced in section III. The findings by applying the proposed method to real web server logs are discussed in section IV. Finally, the conclusions and future work are presented in section V II 
 
R ELATED W ORK  Machine learning algorithms are widely applied in detection of crawlers [1 2  by ex t r a c tin g m a ny f eatu res f r o m  a single log. Itês important that some priori conditions are needed in such research. Another interesting method describes all access traces in three-dimensional model [3  s o  crawlers can be easily detected by eyes. All these methods use common attributes of a single log as features, but there is a drawback that not all real crawlers may have these features For example, not all crawlers get all pages of a target website 
3 s o a m o re g e n e ral m e th od  is n e e d ed   III 
O UR A PPROACH  A single piece of log only reveals information about the characters of website visitors, while time series features gather behavioral information in a continuous time and reveal more comprehensive information about the visitors Crawlersê behaviors show obvious regularity, while other visitors show less regularity In the target website, each page is labeled in a numeric format \(the number only has categorical meaning\, we call 
A Why Time Series Features 
 
 
this number page-code for short, and it can be easy to present in time series diagram. After arranging every page-code of single user in chronological order, we get what Figure 1 shows. The x-axis represents time, while y-axis indicates the page-code. The figure shows a typical access time series of a normal user, it looks totally random, like white noise in signal processing field   Figure 1. Real User Access Page Time Series 
2013 IEEE 25th International Conference on Tools with Artificial Intelligence 1082-3409/13 $31.00 © 2013 IEEE DOI 10.1109/ICTAI.2013.28 123 


Figure 4. First-Order Difference of Impolite Crawlers Access Data 000\003 Figure 5. First-Order Difference of Real Users Access Data 
Time series of impolite crawlers are labeled by the same method, and several typical ones is presented in Figure 2 Obviously, these diagrams looks regular, although the 3 pieces of time series have different curve regularities  Figure 2. Impolite Crawler Access Page Time Series Figure 1 and Figure 2 show the regularity difference between real users and impolite crawlers. A model that can describe this regularity difference is needed. In time series analysis, some effective models are used for prediction. If these models are applied to predict all above time series, the prediction accuracy of real user is supposed to be not high because it is like white noise. That is to say, it has little regularity information and is hard to predict. On the contrary, the prediction accuracy of impolite crawlers should be much higher than that of real users, for it has more regularity information. The prediction model relies on periodicity, so it will be easier to predict As shown in Figure 3, the top time series shows a trace of an impolite crawler, which is also the same as the third one in Figure 2. In the bottom time series, thereês a prediction of two periods \(the time series surrounded by shadow\ based on the data of the first three periods Obviously, it is easy for time series model to predict crawler trace  Figure 3. Prediction of Impolite Crawlers Access There is another feature that also can distinguish the impolite crawlers and real users: first-order difference of timestamp time series First-order difference of timestamp time series shows the same effect as the access time series. The time series of impolite crawlers is more regular than that of real users, and is easier to predict When employing first-order difference to time series access data, and then making a distribution statistics, we find the two types of visitors are very different. As shown in Figure 4, the first-order difference of impolite crawler data concentrates on few kinds of numbers, while first-order difference of real user data distribute on a lot of different numbers 000\003 
124 


Two types of time series are used: access time series and first-order difference of access timestamp access. The two types of time series will generate features by using models Some widely used prediction models are adopted in time series analysis stage in this experiment, such as autoregressive integrated moving average ARIMA locally weighted scatterplot smoothing \(LOESS\ and Holt Winters exponential smoothing\. These models with the two types of time series are used to generate features. We will try to use the prediction results and model parameters as features Some popular and state-of-the-art tools will be employed in this experiment. Common algorithms [4 in m ach in e learning and data mining are used, such as decision tree random forest, support vector machine \(SVM\, linear regression, and neural network. Hadoop softwares is applied to extract data from raw web server logs, because it is powerful for huge data processing, and then Linux Shell and Hadoop are used to do some Extract, Transform and Load ETL\ork. Finally, the R software [10-13 a nd Ra t t l e   1 6 17  pack ag e w h ich are a l so  p opu la r an d  pow erf u l t o ols w ill be used to build the model and result chart  IV E XPERIMENT WITH R EAL D ATA  Our method is applied to a real big website with more than 200 million page views per day. This site has run into trouble with impolite crawlers, because numerous impolite crawlers access it every day. When report data fluctuates without no clear reason, it is very time-consuming and manpower-consuming to find out the specific reason from their big data including logs and databases. Detecting these impolite crawlers will help the administrator get rid of this problem First, we find that users grouped by access frequency are in a long tail distribution. In consideration of this, we group users by access frequency, such as 0-100 times per day, and 101-200 times per day, and extract data from every group for training, validating and testing. This sampling method will help cover all types of visitors This experiment will use both common log features and time series features. The same algorithms are applied in the two types of features and then their effects are compared In this experiment, we find it not suitable for neural network model to work in our application scenario, which is full of categorical attribute but without numerical attribute The data of neural network model will be ignored later in this experiment We sample the training and testing data, and divide them into a training set and a testing set, with a specific random seed each time. After training and testing, we obtain the results as shown in Table 1. The accuracy using time series attributes \(average 95.44%\s much higher than that using common attributes of logs \(average 72.91 T ABLE 1  A CCURACY C OMPARSION R ESULT  0005\000D\000Q\000G\000R\000P\000\003 0006\000H\000H\000G\000\003 000$\000O\000J\000R\000U\000L\000W\000K\000P\000\003 000&\000R\000P\000P\000R\000Q\000\003\000D\000W\000W\000U\000L\000E\000X\000W\000H\000V\000\003 0000\000H\000W\000K\000R\000G\000\003\0003\000U\000H\000F\000L\000V\000L\000R\000Q 002ƒ\000\010\002≈\000\003 0007\000L\000P\000H\000\003\0006\000H\000U\000L\000H\000V\000\003 0000\000H\000W\000K\000R\000G\000\003\0003\000U\000H\000F\000L\000V\000L\000R\000Q 002ƒ\000\010\002≈\000\003 0009\000D\000O\000L\000G\000D\000W\000H\000\003 0006\000H\000W\000\003 0007\000H\000V\000W\000\003 0006\000H\000W\000\003 0009\000D\000O\000L\000G\000D\000W\000H\000\003 0006\000H\000W\000\003 0007\000H\000V\000W\000\003 0006\000H\000W\000\003 000\024\000\023\000\003 000'\000H\000F\000L\000V\000L\000R\000Q\000\003\0007\000U\000H\000H\000\003 000\031\000\034\000\021\000\031\000\031\000\003 000\032\000\024\000\021\000\033\000\031\000\003 000\034\000\033\000\021\000\025\000\027\000\003 000\034\000\024\000\021\000\026\000\032\000\003 0005\000D\000Q\000G\000R\000P\000\003\000\\000U\000H\000V\000W\000\003 000\032\000\027\000\021\000\030\000\030\000\003 000\032\000\025\000\021\000\024\000\025\000\003 000\034\000\031\000\021\000\027\000\034\000\003 000\033\000\032\000\021\000\034\000\026\000\003 0006\0009\0000\000\003 000\032\000\026\000\021\000\030\000\025\000\003 000\032\000\026\000\021\000\024\000\027\000\003 000\034\000\033\000\021\000\025\000\027\000\003 000\034\000\026\000\021\000\024\000\023\000\003 000/\000L\000Q\000H\000D\000O\000\003\0005\000H\000J\000U\000H\000V\000V\000L\000R\000Q 000\032\000\025\000\021\000\025\000\026\000\003 000\032\000\025\000\021\000\024\000\025\000\003 000\024\000\023\000\023\000\003 000\034\000\024\000\021\000\026\000\032\000\003 0001\000H\000X\000U\000D\000O\000\003\0001\000H\000W\000Z\000R\000U\000N\000\003 000\032\000\026\000\021\000\023\000\023\000\003 000\032\000\030\000\021\000\032\000\023\000\003 000\031\000\033\000\021\000\027\000\025\000\003 000\030\000\024\000\021\000\032\000\025\000\003 000\027\000\025\000\003 000'\000H\000F\000L\000V\000L\000R\000Q\000\003\0007\000U\000H\000H\000\003 000\032\000\025\000\021\000\027\000\034\000\003 000\032\000\025\000\021\000\033\000\034\000\003 000\034\000\027\000\021\000\032\000\026\000\003 000\034\000\026\000\021\000\024\000\023\000\003 0005\000D\000Q\000G\000R\000P\000\003\000\\000U\000H\000V\000W\000\003 000\031\000\034\000\021\000\034\000\025\000\003 000\032\000\026\000\021\000\034\000\024\000\003 000\034\000\031\000\021\000\027\000\034\000\003 000\034\000\027\000\021\000\033\000\025\000\003 0006\0009\0000\000\003 000\032\000\024\000\021\000\027\000\031\000\003 000\032\000\030\000\021\000\027\000\027\000\003 000\034\000\033\000\021\000\025\000\027\000\003 000\024\000\023\000\023\000\003 000/\000L\000Q\000H\000D\000O\000\003\0005\000H\000J\000U\000H\000V\000V\000L\000R\000Q 000\032\000\026\000\021\000\025\000\031\000\003 000\032\000\026\000\021\000\027\000\023\000\003 000\034\000\033\000\021\000\025\000\027\000\003 000\034\000\027\000\021\000\033\000\025\000\003 0001\000H\000X\000U\000D\000O\000\003\0001\000H\000W\000Z\000R\000U\000N\000\003 000\032\000\026\000\021\000\025\000\031\000\003 000\032\000\030\000\021\000\024\000\034\000\003 000\031\000\027\000\021\000\034\000\024\000\003 000\031\000\030\000\021\000\030\000\024\000\003 000\031\000\023\000\023\000\003 000'\000H\000F\000L\000V\000L\000R\000Q\000\003\0007\000U\000H\000H\000\003 000\032\000\031\000\021\000\023\000\034\000\003 000\032\000\024\000\021\000\033\000\031\000\003 000\034\000\027\000\021\000\032\000\026\000\003 000\034\000\031\000\021\000\030\000\030\000\003 0005\000D\000Q\000G\000R\000P\000\003\000\\000U\000H\000V\000W\000\003 000\032\000\027\000\021\000\033\000\023\000\003 000\031\000\033\000\021\000\023\000\026\000\003 000\034\000\027\000\021\000\032\000\026\000\003 000\034\000\026\000\021\000\024\000\023\000\003 0006\0009\0000\000\003 000\032\000\033\000\021\000\031\000\031\000\003 000\032\000\025\000\021\000\033\000\034\000\003 000\034\000\031\000\021\000\027\000\034\000\003 000\034\000\031\000\021\000\030\000\030\000\003 000/\000L\000Q\000H\000D\000O\000\003\0005\000H\000J\000U\000H\000V\000V\000L\000R\000Q 000\032\000\031\000\021\000\023\000\034\000\003 000\031\000\034\000\021\000\030\000\031\000\003 000\034\000\031\000\021\000\027\000\034\000\003 000\034\000\027\000\021\000\033\000\025\000\003 0001\000H\000X\000U\000D\000O\000\003\0001\000H\000W\000Z\000R\000U\000N\000\003 000\032\000\034\000\021\000\027\000\026\000\003 000\032\000\026\000\021\000\027\000\023\000\003 000\030\000\032\000\021\000\033\000\034\000\003 000\031\000\026\000\021\000\032\000\034\000\003 Receiver operating characteristic \(ROC\ curve is used for the evaluation of machine learning algorithms. The area under the ROC curve \(AUC\is a measure of classifier performance, which is the area surrounded by the curve and the diagonal line, and its area size indicates the model performance, a big area size means a good performance. In comparison of AUCs between the two groups, the time series group \(average 0.99\s also obviously larger than that of the common attributes group \(average 0.79  Figure 6. The AOC chart of Common Attributes Group 
   
 
B The Two Kinds of Time Series in this paper C The Time Series Model Used in this paper D The Algorithms and  Tools Used in this paper 
125 


Marios Dikaiakos, Athena Stassopoulou, Loizos Papageorgiou Characterizing Crawler Behavior from Web Server Access Log, 2003 2 Marios Dikaiakos, Athena Stassopoulou, Crawler Detection 9 A Bayesian Approach, 2005 3 Jawaheer, Gawesh Kostkova, Patty.Web crawlers on a health related portal: detection, characterisation and implications.Developments in E-systems Engineering \(DeSE\ 2011 4 S. B. Kotsiantis.Supervised Machine Learning: A Review of Classification Techniques. Informatica 31:249 003\004 268 \(2007 5 Trevor Hastie, Robert Tibshirani, Jerome Friedman.The Elements of Statistical Learning. Springer, 2008 6 Roman Timofeev .Classi\002cation and Regression Trees \(CART Theory and Applications, 2004 7 John Ross Quinlan.C4.5: Programs for Machine Learning. Morgan Kaufmann, 1992 8 Kotsiantis, S. B. Supervised Machine Learning: A Review of Classification Techniques. Informatica, 2007, 31, 249-268 9 Robert B Cleveland, William S. Cleveland, Jean E. McRae, Irma Terpenning.STL :A Seasonal-Trend Decomposition Procedure Based on Loess.Journal Of Official Statistics,1990.,6\(1\ : 3-73  G.P. Nason,Introduction to R for Times Series Analysis http://www.metu.edu.tr/~ceylan/r-ts.pdf, 2005-09-28/2013-02-26  Bivand, Roger S., Pebesma, Edzer J., GÛmez-Rubio VirgilioXIV.Applied Spatial Data Analysis with R.Springer, 2008  Paul S. P. Cowpertwait,Andrew V. Metcalfe.Introductory Time Series with R.Springer, 2009  Robert H. Shumway,David S. Stoffer.Time Series Analysis and Its Applications -with R examples.Springer, 2011  C. C. Holt.Forecasting seasonals and trends by exponentially weighted moving averages, ONR Research Memorandum International Journal of Forecasting, 2004 ,Volume 20, Issue 1,: 5-10  P. R. Winters.Forecasting sales by exponentially weighted moving averages, Management Science Volume 6, 324Ö342, 1960  Graham Williams .Data Mining with Rattle and R.Springer, 2011  Graham J Williams.Rattle A Data Mining GUI for R. The R Journal 2009, Vol. 1/2  George E. P. Box, Gwilym M. Jenkins, Gregory C. Reinsel. Time series analysis: forecasting and control. Prentice Hall, 1999  
 
 Figure 7. The AOC chart of Time Series Group T ABLE 2  T HE AUC  C OMPARSION R ESULT  000$\000O\000J\000R\000U\000L\000W\000K\000P\000V\000\003 000&\000R\000P\000P\000R\000Q\000\003\000D\000W\000W\000U\000L\000E\000X\000W\000H\000V\000\003 0007\000L\000P\000H\000\003\0006\000H\000U\000L\000H\000V\000\003 000'\000H\000F\000L\000V\000L\000R\000Q\000\003\0007\000U\000H\000H\000\003 000\023\000\021\000\032\000\030\000\030\000\024\000\003 000\023\000\021\000\034\000\034\000\031\000\030\000\003 0005\000D\000Q\000G\000R\000P\000\003\000\\000U\000H\000V\000W\000\003 000\023\000\021\000\033\000\025\000\023\000\030\000\003 000\024\000\021\000\023\000\023\000\023\000\023\000\003 0006\0009\0000\000\003 000\023\000\021\000\032\000\034\000\033\000\032\000\003 000\023\000\021\000\034\000\034\000\032\000\032\000\003 000/\000L\000Q\000H\000D\000O\000\003\0005\000H\000J\000U\000H\000V\000V\000L\000R\000Q 000\003 000\023\000\021\000\032\000\033\000\030\000\031\000\003 000\023\000\021\000\034\000\032\000\034\000\025\000\003 V C ONCLUSION  This paper shows a new method using time series analysis that could detect impolite crawlers. Compared with old detecting methods, which only use common attributes extracted from every single log, the time series method could get much information. After analyzing some typical access records of real users and impolite crawlers, we find a reason for using time series features. The results also demonstrate our idea Two types of time series features are extracted: access time series and first-order difference of access timestamp time series. Then some popular time series models are used to generate time series features. The former detecting method is used to get common attributes, and the same machine learning algorithms are applied to the two groups of features The time series method shows an obvious advantage Therefore, time series features can help detect impolite crawlers. All knowledge in time series analysis can be applied in this topic for more attempts. It is also an interesting direction for future work R EFERENCES  1 
                  
126 


running-time on 4 computers running-time on computers 
Table III C LUSTERING ACCURACY Graph ARI NMI Graph-5k 0.997 0.999 Graph-10k 0.998 0.999 Graph-20k 0.969 0.977 Graph-40k 0.981 0.988 Graph-80k 0.971 0.987 Graph-160k 0.999 0.999 result the ARI and NMI values are both equal to 1 In general the larger the ARI and NMI values are the better the clustering quality is The clustering accuracy results are presented in Table III The results show that PSCAN can nd the clusters outliers or hubs in each graph effectively Especially for Graph-5k Graph-10k and Graph-160k PSCAN successfully identiìed nearly all of the clusters outliers or hubs in the graphs The reason is that PSCAN always produces the same result as the original SCAN algorithm which is v ery accurate for clustering large networks Therefore PSCAN performs effectively in clustering big graphs 
2 Running Time Performance m m m 
002 Relative speedup 
To this end we employ Barabasi graphs to evaluate the speedup scaleup and sizeup performance of our algorithm Since we will only evaluate the efìciency of PSCAN and not its accuracy we set the same when tested on different Barabasi graphs Moreover we set the number of iterations for nding connected components as six assuming of six degrees of separation To measure the speedup we kept the graphs constant and increased the number of computers in the system We have tested the speedup on different Barabasi graphs on different Hadoop clusters with 4 8 and 15 computers respectively In our experiments the relative speedup given by the larger system with computers is deìned as 1 The results are presented in Figure 1 As the gure shows our algorithm has a very good speedup performance From the relative speedup in Figure 1\(b we noticed that the larger graphs have an improved speedup performance The reason is that increasing the size of the graphs reduced the percentage of the overall time spent in communication and I/O operations Scaleup measures the ability to grow both the system and the graph size Speciìcally we have evaluated running time on Barabasi-1M on a Hadoop cluster with 4 computers running time on Barabasi-2M on a Hadoop cluster with 8 computers and running time on Barabasi-4M on a Hadoop cluster with 15 computers respectively Each running time a Speedup b Relative Speedup Figure 1 Speedup divided by running time on Barabasi-1M on the Hadoop cluster with 4 computers is the relative scaleup result The ideal scaleup is a horizontal line with value 1 in the vertical axis in relative scaleup result However ideal scaleup is difìcult to achieve because of the communication and I/O cost increasing when the scale of Hadoop cluster grows Figure 2 shows the scaleup results Clearly the PSCAN algorithm scales very well Similarly the larger graphs show a better scaleup performance To measure the performance of sizeup we hold the number of computers in the system constant and increase the size of graphs Sizeup measures how much longer it takes on a given system when the graph size is times larger than the original graph The relative sizeup is deìned 
   
m 
866 


running-time for clustering  running-time for clustering 
a Scaleup b Relative Scaleup Figure 2 Scaleup as follows 
Relative sizeup  
   
2 In evaluating sizeup of PSCAN we have xed the number of computers as 4 8 and 15 respectively Figure 3 shows the results on different scale of Hadoop clusters The graph shows that PSCAN has a very good sizeup performance Speciìcally the results in Figure 3\(b show that the sizeup of PSCAN is better when the scale of cluster and size of graphs become larger Since we run PSCAN on preprocessed Twitter dataset we apply certain post-processing to a Sizeup b Relative Sizeup Figure 3 Sizeup guarantee the accuracy of the clustering result For a large degree larger than 20 vertex in original Twitter network if its neighbors in the clustering result are assigned to different communities the vertex is classiìed as a hub according to the structural clustering theory If its neighbors in the clustering result are classiìed as outliers the large degree vertex should be the center of a community and the neighbors are identiìed as members in the community with the large degree vertex as the core based on the structural clustering theory Our experiments on the Twitter network found meaningful clusters A cluster obtained by PSCAN for Twitter network represents a group of people who share common interests and other features Manual investigation on some 
DB m 3 Results on Twitter 
m DB DB 
867 


of the clusters revealed that PSCAN identiìes two users of a cluster although there is no direct follower/following relation exists but sharing some common interests Such capability of PSCAN helped us to nd users from a city an organization or a country It is not feasible to discuss all the clusters here one of the interesting clusters is a cluster representing twitter pages of BBC weather channel and weather alerts The cluster of 20 members all representing BBC weather related pages is found There are many such clusters that represents a group of users who share some common interests There is no base line of communities in Twitter to measure accuracy of the clustering but our manual observations found the accuracy is signiìcant Moreover the experiment is designed to prove the feasibility of SCAN in MapReduce framework because SCAN is proved to be accurate enough for clustering The experiment on Twitter data proved the accuracy and scalability of PSCAN V C ONCLUSIONS AND F UTURE W ORK We present a parallel structural clustering algorithm PSCAN for big networks in MapReduce in this paper PSCAN identiìes clusters as well as vertices playing critical roles such as outliers and hubs in big networks with billions of edges in three steps namely calculating structural similarity of edges cutting off edges with low structural similarity and nding connected components All the steps can be executed in parallel in MapReduce The time complexity of PSCAN is linear with the number of edges in the graph Our empirical evaluation demonstrated an accurate clustering result and an excellent running time in terms of scaleup sizeup and speedup Moreover we applied PSCAN for analysis of a Twitter social network with over 40 million users and 1.4 billions of follower/following relationships The result shows that PSCAN can nd interesting communities of people sharing common interests or other features In the future we plan to further investigate the performance of PSCAN by applying it for the analysis of some really big networks in real world A CKNOWLEDGMENT This project was funded by Acxiom Corporation The authors are grateful for invaluable collaboration with Kevin Liles and Derek Leonard throughout the project This work was supported in part by the National Science Foundation under Grant CRI CNS-0855248 Grant EPS-0701890 Grant EPS-0918970 Grant MRI CNS-0619069 and OISE0729792 Weizhong Zhao would like to thank the support of the National Natural Science Foundation of China No 61105052 R EFERENCES  A Lancichinetti S F ortunato and F  Radicchi 
 Physical Review E 78 046110 2008  S Y ook H Jeong and A Barabasi  In PNAS Proceedings of the National Academy of Science pages 13382-13386 October 2002  L Hubert and P  Arabie  Journal of Classiìcation 193C 218 1985  A Strehl J Ghosh R Moone y   Proceedings of the workshop on artiìcial intelligence for web search pp 58-64 2000  X.Xu N.Y uruk Z Feng T  Schweiger  Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining pp 824-833 2007  Bin W u Y aHong Du  2010 International Conference on Artiìcial Intelligence and Computational Intelligence AICI vol.3 no pp.122-126 23-24 Oct 2010  Usha Nandini Ragha v an Rka Albert and Soundar K umara  Phys Rev E 76 036106 2007  M E J Ne wman and M Girv an  Phys Rev E 69 026113 2004  Jimmy Lin and Chris Dyer   Morgan and Claypool Publishers 2010 pp 94-101  Santo F ortunato  Physics Reports Volume 486 Issues 35 February 2010 Pages 75-174 ISSN 0370-1573 10.1016/j.physrep.2009.11.002  Jia wei Han Micheline Kamber  and Jian Pei  3rd edition Morgan Kaufmann 2011  B.W  K ernighan S Lin  Bell Syst Tech J 49 1970 291307  J Shi J Malik  IEEE Trans Pattern Anal Mach Intell 22 8 2000 888905  U Brandes D Delling M Gaertler  R G  orke M Hoefer Z Nikolski D Wagner  URL http://digbib ubka.unikarlsruhe.de/volltexte/documents/3255  A Clauset M.E.J Ne wman C Moore  Phys Rev E 70 6 2004 066111  G P alla I Der  enyi I Farkas T Vicsek  Nature 435 2005 814818  Martin Ester  Hans-Peter Krie gel J  org Sander Xiaowei Xu  Proceedings of the Second International Conference on Knowledge Discovery and Data Mining KDD-96 AAAI Press pp 226231 ISBN 1-57735004-9 
Benchmark graphs for testing community detection algorithms Modeling the internetês large scale topology Comparing partitions Impact of similarity measures on web-page clustering SCAN a structural clustering algorithm for networks Cloud-based Connected Component Algorithm Near linear time algorithm to detect community structures in large-scale networks Finding and evaluating community structure in networks Data-Intensive Text Processing with MapReduce Community detection in graphs Data Mining Concepts and Techniques An efìcient heuristic procedure for partitioning graphs Normalized cuts and image segmentation On modularity npcompleteness and beyond Finding community structure in very large networks Uncovering the overlapping community structure of complex networks in nature and society A density-based algorithm for discovering clusters in large spatial databases with noise 
868 


 Akshay U Bhat  http://www.akshaybhat.com/LPMR 2008  Hae w oon Kw ak Changhyun Lee Hosung P ark and Sue Moon  WWW 2010 April 2630 2010 
Scalable Community Detection using Label Propagation  Map-Reduce What is Twitter a Social Network or a News Media 
869 


state of innovation stakeholder  node PQ It  s a balanced node Based on this, we could calculate the  node PQ Calculation process is: set different inn ovation stakeholders state i U  and j U Value of ij 000T can be get from  innovation time difference. Innovation stakeholdersí social effect and industrial effect can be obtained upon ij B  and ij G set according to relation between innovation stakeholders  Model 4.1 points out  that the value of Gij  directly affects social benefits and sector benefits. Large Gij  can lead to increasing benefits of the entire industry and the entire social growth Bij reflects big organizationís impact on businesses. Only strengthening the inter agent association within big organization and enhancing the str ategic partnership between enterprises can jointly promote the development of the entire industry, and bring more social benefits, so that each agent can be improved   5 Summary This paper puts forward the concept of the big organization based on the CSM t heory. It introduces the basic implication of the big organization and theoretical framework of the big organization including: the big organization's perspective  overall perspective, dynamic perspective, and new resource perspective; the big organizat ionís sense  the purpose of the organizational structure is innovation, organizational activities around the flow of information, breaking the traditional organizational structure, encouraging self run structure, and blurring organizational boundaries; the big organizationís platform  the platform ecosystem of the big organization ; the big organizationís operation mode  borderless learning mode, and cluster effect; the big organizationís theory  active management theory  leading consumers, and culture  entropy reduction theory  negative culture entropy and humanistic ecology theory  inspiring humanity, and circuit theory  a virtuous circle, and collaborative innovation theory  collaborative innovation stakeholder. This paper also discusses culture entropy reduction theory of the big organization  negative culture entropy, and coordinated innovation theory  innovation stakeholders collaboration. Culture entropy change model and collaborative in novation model are constructed   The research has just begun for the big organization. It also needs further improvement but remains the trend of the times   Reference  1  Gordon Pellegrinetti, Joseph Bentsman. Nonlinear Control Oriented Boiler Modeling A Benchmark Problem for Controller De sign [J  I E E E tr a n s a c tio n s o n c o n tr o l s y s te m s te c h n o lo g y 2 0 1 0  4 1\57 65  2  Klaus Kruger, Rudiger Franke, Manfred Rode Optimization of boiler start up using a nonlinear 457 


boiler model and hard constraints [J  E n e r gy 201 1 29   22 39 2251  3  K.L.Lo, Y.Rathamarit  State estimation of a boiler model using the unscented Kalman filter [J  I E T  Gener. Transm. Distrib.2008 2 6\917 931  4  Un Chul Moon, Kwang. Y.Lee. Step resonse model development for dynamic matrix control of a drum type boiler turbine system [J IE E E  T ra nsactions on Energy Conversion.2009 24 2\:423 431  5  Hacene Habbi, Mimoun Zelmat, Belkacem Ould Bouamama. A dynamic fuzzy model for a drum boiler turbine system [J  A u to m a tic a 2 0 0 9 39:1213 1219  6  Beaudreau B C. Identity, entropy and culture J   J o ur na l  o f  economic psychology, 2006, 27\(2 205 223  7  YANG M, CHEN L. Information Technique and the Entropy of Culture J  A cad e m i c E x ch a n g e  2006, 7: 048  8  ZHANG Zhi feng. Research on entropy change model for enterprise system based on dissipative structure J  Ind ustrial  Engineering and  Management 2007, 12\(1\ :15 19  9  LI Zhi qiang, LIU Chun mei Research on the Entropy Change Model for Entrepreneurs' Creative Behavior System Based on Dissipative Structure J  C h i n a S of t S c i e n c e  2009   8  1 62 166   458 


A Global Solution COVERAGE North and South America EMEA and Asia White lines are flights in the masFlight platform from February 8, 2013 Yellow pins are weather stations feeding hour ly data to our platform Maps from Google Earth / masFlight masFlight tracks flights, airports and weather around the world  Global daily flight information capture  82,000 flights  350 airlines  1700 airports  Integrated weather data for 6,000 stations  Match weather to delays  Validate block forecasts at granular level  Add weather analytics to IRROPS review and scenario planning 


Example 1: Proposed FAA Tower Closures masFlight used big-data to link airport operations across three large data sets  Current and historical airline schedules  Raw Aircraft Situation Display to Industry \(ASDI\AA  Enhanced Traffic Management System Counts \(ETMS\Airport operations counts by type \(commercial, freight, etc TOWER CLOSINGS Dots indicate closures; Red dots have scheduled service Based on scheduled service March 1 7, 20 13; scheduled service includes scheduled charter flights, cargo flig hts, and passenger flights Dots  indicate  closures  Red  dots  have  scheduled  service Bas ed  o n sc h edu l ed  se rvi ce  M a r c h 1  7, 2013; scheduled se rvi ce includ es scheduled c harter fli g hts car g o fli g hts a nd passen g er fli g hts Findings: Proposed Tower Closings  From schedules database: 55 airports with scheduled passenger airline service  14 EAS Airports  From ASDI & ETMS: 10,600 weekly flights on a flight plan \(ex. VFR and local traffic  6,500 Part 91/125 weekly flights  4,100 Part 135/121 weekly flights  


Example 1: Big-Data Analytics Applied to ASDI and ETMS To Analyze Operations TOWER CLOSINGS  26 44 24 23 11 10 6 2 1 2 Up to 5 5-10 10-15 15-20 20-25 25-30 30-35 35-40 40-45 45 Count of Airports Average Number of Daily Operations with a Flight Plan Filed Distribution of Airports By Average Number of ìDailyî Impacted Flights Airports Affected by Tower Closures Source: ASDI radar data ñ Part 91 151 flying and Part 135/121 flying March 1-7, 2013; masFlight analysis Note: Average ìdailyì operations based on 5-day week 


Example 2: Aviation Safety Causal Factor For example, consider the following ASRS report \(ACN 1031837 Departing IAH in a 737-800 at about 17,000 FT, 11 m iles behind a 737-900 on the Junction departure over CUZZZ Intersection. Smooth air with wind on the nose bearing 275 degrees at 18 KTS We were suddenly in moderate chop which lasted 4 or 5 seconds then stopped and then resumed for another 4 or 5 seconds with a significant amount of ri ght rollingÖ I selected a max rate climb mode in the FMC in order to climb above the wake and flight path of the leading -900 We asked ATC for the type ahead of us and reported the wake encounter. The 900 was about 3,300 FT higher than we were  Synopsis  B737-800 First Officer reported wake encounter from preceding B737-900 with resultant roll and moderate chop What causal factors can be identified from this narrative that could be applied to future predictive applications CAUSAL FACTORS Data-mining algorithms can mine the text of safety reports to obtain specific data that can be used to analyze causal factors  


Example 2: Identifying Causal Factors CAUSAL FACTORS  Indicators ñ Data Element Methods ñ Identifying Context and Causes  Time of day  Date range \(month day  Aircraft type  Fix or coordinates  Originating airport  Destination airport  Weather notes We pinpoint the sequencing of flights on the IAH Junction Seven departure \(at CUZZZ\the specified wind conditions to find cases wher e a B737-900 at 20,000 feet precedes by 11 miles a B737-800 at 17,000 feet  Search related data sets including ASDI flight tracks, local traffic and congestion  Weather conditions for alter native causes \(winds aloft shear and convecti ve activity  Airline specific informati on \(repeated occurrence of event in aircraft type Big data gives us visibility into contextual factors even if specific data points are missing such as a specific date or route Big-data analytics gives us insight into unreported factors as well 


Example 3: Correlating Utilization and Delays  60 65 70 75 80 85 90 95 100 7 9 11 13 ONTIME DEPARTURE PERFORMANCE HOURS OF DAILY UTILIZATION 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Narrowbodies By Day of Week 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Widebodies by Day of Week Daily Utilization vs. On-time Departures January 2013 System Operations Correlation Coefficient -0.53 Includes AA, AC, AS B6 F9, FL, NK, UA, US VX and WN SOURCE masFlight \(masflight.com COMPARING OTP AND UTILIZATION 


 6.2 6.0 5.8 5.8 5.2 4.9 LGB JFK BOS MCO DCA FLL JetBlue Focus Average Daily Deps per Gate Used UTILIZATION BY HUB Example 4: Daily Utilization of Gates, by Hub Big-data analysis of different carriers daily departures per gate used SOURCE masFlight \(masflight.com June 1 through August 31, 2012 Gates with minimum 1x daily use 7.7 7.4 7.2 6.2 6.1 5.8 3.8 3.6 ORD LAX SFO EWR DEN IAH IAD CLE United Airlines Hubs Average Daily Deps per Gate Used 7.8 6.4 5.5 5.4 5.3 4.4 4.3 4.0 SEA SAN PDX ANC SFO GEG LAX SJC Alaska Airlines Hubs Average Daily Deps per Gate Used 7.2 6.9 6.8 6.4 5.0 2.7 ORD DFW LAX LGA MIA JFK American Hubs Average Daily Deps per Gate Used 7.2 6.9 6.6 4.9 4.2 CLT DCA PHL PHX BOS US Airways Hubs Average Daily Deps per Gate Used 6.6 5.9 5.5 4.7 MCO BWI ATL MKE AirTran Hubs Average Daily Deps per Gate Used ne pe 


Conclusions for Big Data in Aviation  Big-data transforms operational and commercial problems that were practically unsolvable using discrete data and on-premises hardware  Big data offers new insight into existing data by centralizing data acquisition and consolidation in the cloud and mining data sets efficiently  There is a rich portfolio of information that can feed aviation data analytics  Flight position, schedules, airport/gate, weather and government data sets offer incredible insight into the underlying causes of aviation inefficiency  Excessive size of each set forces analysts to consider cloud based architectures to store, link and mine the underlying information  When structured, validated and linked these data sources become significantly more compelling for applied research than they are individually  Todayís cloud based technologies offer a solution CONCLUSIONS 


Conclusions:  Our Approach  masFlightís data warehouse and analysis methods provide a valuable example for others attempting to solve cloud based analytics of aviation data sets  masFlightís hybrid architecture, consolidating secure data feeds in on-premises server installations and feeding structured data into the cloud for distribution, addresses the unique format, security and scale requirements of the industry  masFlightís method is well suited for airline performance review competitive benchmarking, airport operations and schedule design and has demonstrated value in addressing real-world problems in airline and airport operations as well as government applications CONCLUSIONS 






Frequent Itemset Mining to Generate Initial Solutions for Simulation-Based Optimization of Warehouse Product Placement Catarina Dudas, Tehseen Aslam, Amos Ng Virtual Systems Research Centre University of Skövde Skövde, Sweden catarina.dudas@his.se Warehouses are obliged to optimize their operations with regard to multiple objectives, such as maximizing effective use space equipment, labor, maximize accessibility of products, maximize amount of processed orders and all this should be achieved whilst minimizing order processing times, distance traveled, broken promises, errors and not to forget the operational cost. A product placement problem for a warehouse is in focus of this study and the main goal is to decrease the picking time for each pick run in order to gain higher efficiency To achieve this, a simulation model is built as a representation of the warehouse. As the complexity and the size of the number of input variable grow it is essential to use simulation-based optimization in order to receive a satisfying result. A set of initial solutions for the simulation-based optimization is needed; since the number of products to place in the warehouse is huge this solution ought to be intelligent. This paper describes a technique for generating such a set of solutions through searching for frequent itemsets in the transaction database. It is believed that frequent products usually picked simultaneously should be stored closed together Keywords-warehouse planning; frequent itemset; simulationbased optimization I I NTRODUCTION Simulation can be a very effective tool supporting the decision making process for the warehouse planner when analyzing different scenarios, e.g. check how the number of forklifts or how the product placement affects the throughput If the simulation model is a replication of the original warehouse it can also be used beneficially for educational purposes among the employees Several different parameters that might affect the efficiency of picking the orders include the product demand, the placement of the products, the layout of the warehouse, the picking and routing methods. A warehouse is normally a large area with numerous aisles of racks where a huge number of different products can be stored. Real-world problems are typically too complex to analyze analytically since they usually contains nonlinearities, combinatorial relationships and uncertainties. For these kinds of problems simulation becomes a valuable tool but is not sufficient by itself [1 T h e complexity of this problem makes it very suitable for simulation-based optimization. The most optimal solution is usually the simple solution but the increasing complexity of the warehouse makes it more complicated to find these simple solutions Simulation-based optimization is about finding the most favorable settings of the parameters for the problem. The evaluation of the system is then based on the output of the simulated parameters and this process is iterative, see Fig. 1 In a general simulation-based optimization system, an optimization procedure feeds input values into a simulation model that estimates the performance measures. Based on the evaluation feedback from the simulation, the optimization procedure generates a new set of parameter values and this process continues until a user-defined stopping criterion is satisfi   The performance measure in this problem is picking time and therefore the objective of this optimization is to minimize it. The adjustable parameters are the placement of products in the racks. For high-frequency and fast-moving products it is necessary that these are placed in the most well-located places The high-frequency product sets can be found by the use of a data mining technique called frequency itemsets, which was first applied within retailing to find which products to put on sale or how to place products on shelves in order to maximize profit [3  T h e f r e q u e n t item s ets can be  u s e d as th e in iti al  solutions in the optimization process. The optimization algorithm will then be given a more intelligent starting position than just random. This is believed to shorten the time required for the optimization process with maintained search space Therefore the aim of this paper is to describe the procedure used to generate frequent itemsets which can be used in the simulation-based optimization. The overall solution to the problem will be helpful for product placement planning and establishment of the warehouse, both for existing and future products This paper is structured as follows. The next section describes warehouse order picking in general and section III contains a description of the real-world problem. In section IV a presentation of the frequent itemset mining is given. Section V describes simulation-based optimization and the combination of simulation-based optimization and frequent itemsets Conclusions and further research steps are provided in section VI which concludes the paper 


Figure 1 The process of simulation-based optimization and the suggested approach II W AREHOUSE O RDER P ICKING Distribution warehouses play a crucial role in supply chains SC\, they are involved in accumulating and consolidating products from different manufacturing facilities, within a corporation or externally, and delivering them to the customers at the right time, in the right quantity and quality [4  Order picking is a process of retrieving products from storage locations in the warehouse according to customer demand and requirements. It has long been pointed out as a primary activity within a warehouse. Order picking systems can be divided into two groups orders picking employing humans or orders picking employing automated machines 4 The majority of warehouses employ humans for order picking and is the only considered order picking system in this paper One crucial aspect of order picking is the order picking time, warehouse managers strive to minimize the order pick times as this would mean that more orders would be processed and available for shipping to customers within their due time Missing a shipping due time could mean that the order cannot be shipped until the next shipping period and the warehouse might be subjected to a penalty cost. Another outcome of minimizing the order pick time is that it gives warehouse managers greater deal of flexibility in handling late changes in orders. The total order pick time of an order can in general be divided in to \(1\ravel time, which is the total time that a picker travels in order to assemble the order, \(2\ pick time which is the time when the picker is actually picking the item/product, \(3\ other time, which is the total time of remaining activities such as obtaining new pick lists, collecting a new empty carrier etc [5    Researchers [6   7  a n d   8 ha ve po i n t e d o u t  t h a t t h r ee main approaches could be used to improve warehouse operations and the order picking process efficiency, namely picking policies  routing policies and storage policies  A Picking policies The picking policy determines how the customer orders are clustered and scheduled into picking lists, in which each pick line defines a unique item in a certain quantity to be picked in order to fulfill the customer order. There are four main picking policies which are illustrated in Fig. 2 discrete  batch zone  and wave picking all other picking policies are a combination of these four policies [4 an d  8     Figure 2 Discrete, batch and zone picking policies In discrete order picking all items are picked one order at a time by one single picker \(see\ In the batch picking a single picker may pick many of the same items for multiple orders at the same time, separating them into different carriers. The general idea in zone picking is to assign multiple pickers to different areas within the warehouse where they are allowed to pick. The fourth of the main order picking policies is the wave picking which is a variation of batch picking and parallel picking but instead of picking one order at a time a group of orders are released simultaneously to the warehouse for picking 


and the next order release does not occur until the first wave has been processed B Routing policies The routing policy determines traveling route of a picker during a picking tour, the main objective of routing policies is to sequence the items that are to be picked in the pick list to ensure that the picker receives a good picking route. The routing problem is a special case of the Traveling Salesmen Problem TSP\called Steiner Traveling Salesmen Problem STSP\ In contrast to the TSP, where you have to visit each and every node, not more than once during your journey, in STPS you have the possibility to visit a node more than once or not at all [4   Six different routing strategies is presented in [4  traversal strategy, return strategy, midpoint strategy, largest gap strategy, composite strategy these strategies are commonly seen as heuristic routing policies see Fig. 3\ and the sixth strategy is the optimal routing policy            Figure 3 Heuristic routing policies One of the simplest routing strategies for order pickers is the traversal strategy where a picker starts by entering one end of an aisle and exists from the other end and aisles that don’t contain an item to be picked are not entered. In return strategy a picker enters and exits each aisle from the same end, and as previous strategy only those aisles are visited that contain an item to be picked. The midpoint strategy divides the warehouse in two sections, pickers are only allowed to access the front half from the front cross aisles and the back from the back aisles. The picker is only allowed to traverse the first or the last aisles to enter or exit the back aisles. The largest gap strategy and the midpoint strategy are quite similar from the exception that when applying the largest gap strategy a picker is allowed to enter an aisle as far as the largest gap within an aisle instead of the midpoint Composite strategy combines the desirable features from return and traversal strategies; it tries to minimize the traveling distance between the farthest picks in two neighboring aisles by using dynamic programming The other routing policy beside the above presented heuristic policies is the optimal routing policy This policy calculates the shortest picking route regardless of layout of the warehouse or location of the items. There are several researchers [9   1 0  an d 1 1 th at h a v e  dev e l o pe d o p ti m a l algorithms for solving the routing problem, however [12 points out that a optimal route is in general a hybrid between a traversal and largest gap strategy, optimal routing solutions may result in shorter routes and travel times but heuristic solutions benefit from their simplicity and familiarity to pickers. He continues to point out that heuristic strategy develops near optimal pick route solutions but with much less confusion, they are easy to comprehend and creates pick routes that are quite consistent in nature C Storage policies Up until now the different strategies within order picking and routing policies have been presented, another way to improve warehouse efficiency and operations is to study how items/products are stored in storage locations in the warehouse Storage assignment policies are a set of rules that govern where an item should be stored in the warehouse based on different strategies. There are several strategies for storage assignments 4  random storage, closest open location storage, dedicated storage, full turn over storage, family grouping and class based storage A commonly used approach to classify items is to perform an ABC analysis This constitutes that items are ranked according to annual dollar usage, which is the outcome of unit price multiplied by annual demand. ABC analysis is based on Vilfredo Pareto’s observation about the unbalanced distribution of incomes; according to Pareto a small portion of the population owned most of the wealth. He developed a rule known as the 80/20 rule; which denotes that 80% of the wealth is held by 20% of the population [13 f t i ng t h i s co nt e x t t o  warehouse control suggests that there are a few items in a warehouse which generate the majority of the picking activity The idea of ABC analysis is to cluster items into different classes where the fastest moving class could e.g. contain 10 of the most popular items in the warehouse but contribute to 70% of the picking activity 1  Th e f a s t es t m o v i n g item s are  often classified as A-items, the second fastest as B-item and so on. The classification of items is generally based on some kind of demand frequency of the items, e.g. pick volume or cubeper-order-index \(COI\, which is the ratio of an item’s storage space requirement and the item’s picking frequency [15  III P ROBLEM D ESCRIPTION The warehouse of the industrial partner in this study consists of a high-bay \(storage\nd low-bay \(picking\ea as can be seen in Fig. 4. The high-bay area supplies the low-bay area with products but the operators can also pick directly from the high-bay area for large volume orders. There are 24 forklifts in the low-bay area and there are some restrictions on how these forklifts are allowed to move. They start at the left vertical main aisle and stop at the end of the right vertical aisle and they are not allowed to move backwards more than two aisles. In the low-bay area there are 46 single aisles, one forklift at time, and 13 double aisles where two forklifts can pick at the same time. Each aisle consists of several levels and is six meters high. This gives a total of about 40 000 storage places. High frequency products can be stored on several places while seasonal and low-frequent products are stored in 


the high-bay area. The total number of products are about 50 000 The main objective is to place the products on more efficient locations. If a product with high frequency is placed in a location far away from the shipping area this will lead to nonvalue added activity in travel time. The storage policies are described in section II and the class based strategy is used by the industrial partner in this study Figure 4 The high-bay and low-bay areas in the warehouse IV F REQUENT I TEMSET M INING Frequent itemset mining is one of the most basic areas in data mining. It has a wide range of applications not only in its natural form, but also as a subroutine in various other problems, the most famous being association rule mining [16  In this study the frequent itemsets themselves are important since only the relationships between different products are of interest As mentioned in the introduction the first interest for finding frequent itemsets combined with association rules originates from the market basket analysis, i.e., study customer behavior in order to find purchasing patterns. Progress in barcode technology made it possible to store basket data that stores items purchased on a per-transaction basis which was up until then impossible [3 A sso ci ati o n  ru les d e sc ri b e s w h i c h  products are bought together and how likely it is that other products are bought at the same time. For example, an association rule “milk bread \(80%\ says that if a customer buys milk it is 80% certain that he also will buy bread. These type of rules can be helpful in the decision making process for managers concerning e.g., product pricing, promotions and store layout [17 A Definitions In order to find the frequent itemsets, the number of transactions they appear in has to be counted. In the frequent itemsets mining procedure there are some terms that need to be explained; an itemset is a collection of one or more items products\ a transaction is a collection of products made at the same time, i.e. an order line or a pick order, from the database the support is the number of occurrences of an itemset in the total set of transactions and is usually represented by a fraction and a frequent itemset is an itemset whose support is greater than a predetermined minimum threshold, typically 0.1% or 1 B Search Space The task of discovering all frequent itemsets can be quite a challenge since the number of transactions in the databases can be several millions and the search space is exponential to the number of unique items in the database. Consider an example set {A, B, C, D} where the search space is 24; which is illustrated in Fig. 5 Figure 5 All possible itemsets for an example set of items {A, B, C, D A transaction database can easily contain thousands of unique items and if the number of products is more than 300 the number of itemsets is greater than the number of atoms in the universe. In this particular warehouse transactional database the number of unique items is more than 50 000 which would generate a search space beyond imagination 


Obviously it will be impossible to search the entire space and several algorithms have been developed since the introduction of frequent itemsets mining in the beginning of the nineties. Among the best known and most commonly used algorithms for frequent itemsets mining is the Apriori algorithm w h i c h ha s b e e n re de ve l o p e d i n t o s e ver a l  variants 1 Apriori Algorithm The reason behind the successfulness of the Apriori algorithm is because a key principle found; if a set of items S is frequent \(i.e., has a support greater than the predetermined threshold\, then every subset of S is also frequent. The algorithm for finding large itemsets makes multiple passes over the data [18  In th e f i rst p a ss o f th e tr an sac t i o n s th e  frequencies of the single element sets are determined. Count the support of individual items and determine which of them are large, i.e. have a support greater than the threshold. In each subsequent pass, start with a seed set of itemsets found to be large in the previous pass. Then use this seed set for generating new potentially large itemsets, called candidate itemsets, and count the actual support for these candidate itemsets during the pass over the data. At the end of the pass, determine which of the candidate itemsets are actually large, and they become the seed for the next pass. This process continues until no new large itemsets are found or stop at some user-defined itemset size C Frequent Itemsets in the Warehouse Transaction Database In this study we have experimented with pick run data from a warehouse using the Apriori algorithm [1  T h e r e ar e a t o tal  of almost 4 million non-single pick runs and more than 50 000 unique products in the transaction database. The pick runs can vary much in size, from single product picks up to about 250 products. Only frequent itemsets of size greater than two are considered since we are searching for relationships between different products. In this kind of analysis, the quantity of each product picked is usually not considered meaning that a pick run containing one variant would be considered as the same as another pick run of 100 variant. Possible frequent itemsets are illustrated in Fig. 6 Figure 6 Example of possible pick runs in the warehouse V S IMULATION B ASED O PTIMIZATION To optimize real-world problems it is inevitable to take a step out of the traditional way of performing optimization. The complexity and randomness in the problems make it impossible to model them analytically [1 Th e s i m u lation m ode l t a k e s a  set of parameter values and returns a set of output performance measures, as illustrated in Fig. 1. Let the parameter values be represented by the vector x then the simulation model can be thought of as a function f\(x returning the output performance measures  Simulation-based optimization \(SBO\ is performed in two steps; the first one is to build a simulation model. The model needs to be a correct and authentic representation of the real-world system that is being modeled to get valid and accurate results from the optimization step, which is the second step in SBO. The past decade there have been a great interest in this area and several different algorithms has been developed for solving the optimization. The commonalty of these algorithms is that they need to be capable to learn from and adapt to the usefulness from previous evaluations of the optimization runs, and they should also be suitable for multi objective optimization since this is the nature of many realworld problems A Evolutionary Algorithms Evolutionary algorithms are optimization algorithms based on biological evolutionary theory and consist of selection and reproduction, i.e., mutation and crossover. The main characteristics of evolutionary algorithms are given below Individual solutions are traditionally generated randomly to form an initial population. A new generation is created by breeding from the previous generation based on the outcome of a fitness function where better suited or fitter solutions are picked. Mutation is used to keep the diversity maintained in the population and takes one solution from the pool of solutions and performs one or several changes, i.e., mutations. Crossover is also called recombination and uses pairs of solutions and it randomly swaps the segments between the two solutions to generate a new individual. The algorithm will be slow if only mutation is used. Applying crossover makes it considerable faster B Combining Frequent Itemset and Simulation Based Optimization The algorithm itself can be efficient but another way of making the optimization process even more efficient is to start in a favorable spot in the search space. This can be of essential benefit if the search space is enormous which the case for the warehouse problem is. As mentioned previously the traditional way of generating initial solutions for the optimization is by randomization. It is believed to be less time-consuming to start with more promising guess from data mining, instead of a set of random initial solutions The frequent itemsets mining can state which products are picked by one operator at the same time. This information can be applied in the generation of a set of initial solutions as an intelligent guess. Products which are more likely to be picked together should be placed close to each other in the same aisle in order to reduce non-value added tasks such as traveling time for the operator. The objective in the optimization is to minimize the picking time and one way to accomplish this is to put the products picked together closer to each other 


Finding relationships between the high-frequency products is a good starting point since they are the main contributor of the total picking time in the warehouse. Although these would be found in the simulation-based optimization all real-world applications are looking for time-efficiency in order to be useful in industry. The low-frequency product placements will most likely be found by the simulation-based optimization VI C ONCLUSIONS AND F UTURE W ORK Simulation based optimization is applied to various different real-world applications with increasing complexity This paper presents a novel way of improving the optimization procedure, not by develop the optimization algorithm itself but instead finding a new technique of generating a set of promising initial solutions. The concept is based on using frequent itemset mining to find relationships in historical data from the application considered and then use this information The next step is to verify this presented technique on several different applications, starting with the product picking time optimization problem for the warehouse presented in this paper R EFERENCES 1 J  A p ri l, M. B e t t er, F  G l o v er a n d J   Kel l y  Ne w a d va nc es for m a rry i n g  simulation and optimization”, In Proceedings of the 2004 Winter Simulation Conference, ed. R .G. Ingalls, M. D. Rossetti, J. S. Smith and B. A. Peters, 80-86. Washington, DC, 2004 2 A  P e rs s o n  M A n d e rs s o n  H. G r i m m  an d A  Ng M et a m od el-A s s i s t ed  Simulation-Based Optimization of a Real-World Manufacturing Problem”. In proceedings of the 17th International Conference on Flexible Automation and Intelligent Manufacturing, FAIM 2007. 950956, 2007 3 R  A g ra w a l T  I m i e li n s k i   a n d A   Sw a m i  M in in g a s s o c i a t i o n r u les  between sets of items in large databases”, Ed. P. Bunemann and S Jajodia, In proceedings of the 1993 ACM  SIGMOD Conference on Management of Data, 207-216, New York, ACM Press, 1993 4 R  de K o s t e r T  L e D uc, K  J  Ro o dbe r g e n  D e s ig n a n d co n t r o l o f  warehouse order picking: A literature review”, European Journal of Operational Research Vol. 182, No. 2, pp. 481-501, 2007 5 C.G P e te r s e n  C o n s i de r a tio ns  in o r de r pi ck ing z o ne co nf ig ur atio n   International Journal of operations and Production Management, Vol 22, No. 7, pp. 793-805, 2002 6 J  C  H  P a n P H S h ih  E va lua t i on of t h e t h rou g h pu t of a  m u lti p l epicker order picking system with congestion consideration”, Computers Industrial Engineering, Vol. 55, No. 2, pp. 379-389, 2008 7 B Mo l n r   M ul itcr ite r ia s c he dul i n g o f o r de r pic k ing  pr o c e s s e s w ith  simulation optimization”, Peridica Polytechnica Ser. Transp. Eng., Vol 33, No. 1-2, pp. 59-68, 2005 8 C  G  Pet e rs en and G  R  A a s e  A c o m p a r is on of p i cki n g, s t ora ge and routing policies in manual order picking", International Journal of Production Economics, Vol. 92 No.1, pp.11-19,  2004 9 H D Ra tl if f an d A  S  Ro s e nt hal   O r d e r p icki n g i n a r e ct a n g u l a r  warehouse: a solvable case of the travelling salesman problem Operations Research, Vol. 31 No. 3, pp. 507-21, 1983  M  G o et s c h a lc k x and H D Ra t l i f f  Or d er p i c k in g in an a i s l e  I I E  Transactions, Vol. 20 No. 1, pp. 53-62, 1988 11 M G o e t s c hal c kx a n d H  D   Ratl if f   A n e f f i cie n t al g o r ithm to cl us te r  order picking items in a wide aisle”, Engineering Costs and Production Economics, Vol. 13, pp. 263-71, 1988  R  W  Ha ll Di s t a nc e a p p r oxi m a t i o n s for rou t i n g m a nu a l  p i c k ers in a warehouse”, IIE Transactions, Vol. 25 No. 4, pp. 76-87, 1993  A  Ult s c h  Proof of Pa ret o s 8 0  20  L a w a n d Prec i s e L i m i t s for A B C Analysis”, Technical eport, University of Marburg, Germany, 2002 14 W  H  H a usm a n  L  B. S c hw ar z an d S  C  G r av e s  O ptim al sto r ag e  assignment in automatic warehousing systems”, Management science Vol. 22, No. 6, pp. 629-638, 1976 15 V  R M u pp an i a n d G  K A d il  E f f i ci e n t f o r m at io n o f sto r ag e cl ass a s f o r  warehouse storage location assignment: A simulated annealing approach”, International Journal of Management Science, Vol. 36, No 4, pp. 609-618, 2008 16 B R cz F   Bo do n L  S c hm id tT h ie m e  B e n chm a r k ing F r e que nt  Itemset Mining Algorithms: from Measurement to Analysis”, ed. B Goethals and S. Nijssen and M. J. Zaki, ACM SIGKDD Workshop on Open Source Data Mining Workshop \(OSDM'05\, 36 - 45, Chicago, IL USA, 2005 17 B. G o e t hal s S u r v e y o n F r e que nt P a t t e r n Mi n i ng  M a n u s c r i p t  A v ail abl e  via and accessed on 28:th of April 2010 http://www.adrem.ua.ac.be/~goethals/software/survey.pdf 18 R. A g r a w a l and R  S r i k a n t   F as t al g o r ithm s f o r m i ni ng as s o c i a t io n  rules”, ed. J.B. Bocca, M. Jarke and C. Zaniolo, Proceedings of 20th International Conference on Very Large Data Bases, 487-499, Morgan Kaufmann, Santiago de Chile, 1994  C   B o rgelt  A p ri ori p r ogra m  A v a i la b l e vi a  a nd a c c e s s ed on 2 8 th of  April 2010 <http://www.borgelt.net//apriori.html 


 7 The performances of both Apriori and proposed advanced version of Apriori are observed with respect to Execution time measured under number of PHP instruction norms The following Tables 1.and Table 2 shows experimental values of number of transactions and execution time for Original Apriori and proposed Advanced Apriori algorithms respectively  Table 1.  Original Apriori  Number of Transactions Execution Time\(Sec 15 7.3 20 12.91 25 17.18 30 22.25 35 38 40 110.22 45 378  Table 2. Proposed Algorithm  Number of Transactions Execution Time\(µsec 15 241 20 326 25 411 30 496 35 581 40 666 45 751 50 836  Graphs are plotted \(Figure 2. and Figure 3.\or the above two tables  Original Apriori 0 50 100 150 200 250 300 350 400 0 1020304050 No. of Transaction Ececution Time \(Sec   Figure  2. Original Apriori  Advanced Apriori 0 100 200 300 400 500 600 700 800 900 0204060 No. of Transactions Execution Time \(µ Sec   Figure 3. Proposed Algorithm  The graph shows the proposed method has improvement over original Apriori algorithm  7. Conclusions  In this paper, the advanced version of Apriori algorithm is proposed to overcome the deficiency of the basic 
244 


 8 Apriori algorithm. The basic Apriori algorithm follows Bottom-Up approach where as the proposed method follows organized transaction selection approach It avoids the generation of combinations of items which inturn reduces the number of database scans. The result shows improvement in execution time  8. References   Ji awei Han and  M i ch el i n e   K a m b er  Data Mining Concepts and Techniques  Morgan  Kaufmann Publishers,  2001  2 R. A g r a w a l T  I m ie linsk i, a nd A   Swami, “Mining Association Rules between sets of Items in Large Database”, Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data, Vol.22 Issue 2, 1993, pp.207-216   R Agra w a l an d R S r i k an t  F ast  Algorithms for Mining Association Rules Proceedings of the 20 th International Conference on Very Large Data Bases, 1994 pp. 487-499   Ji awei Han  Ji an  P e i  Yi w e n Yi n and Runying Mao, “Mining Frequent Pattern without Candidate Generation: A FrequentPattern Tree Approach”, Data Mining and Knowledge Discovery, Vol-8, 2004, pp.53-87   Ji awei Han  Ji an  P e i  M i n i n g F r eq u e n t  Patterns by Pattern-Growth :Methodology and Implications”, SIGKDD Explorations Volume 2, Issue 2, 2006, pp.30-36  6  WA NG  T ong a nd H E P i L ia n  W e b  Log Mining by Improved Apriori All Algorithm”, Transaction on Engineering Computing and Technology, V4, February 2005 ISSN 1305-5313. pp. 97-100  7  Wei Z h an g, Z h a n g Wei  Do n g me S u n Shaohua Teng, and Haibin Zhu, “An Algorithm to Improve Effectiveness of Apriori”, Proceedings of sixth International Conference on Cognitive Informatics, 2007 IEEE, pp.385-390     X i an g-W e i L i u an d P i L i a n He  T h e  Research of Improved Association Rules Mining Apriori Algorithm”, Proceedings of the third International Conference on Machine Learning and Cybernetics, Shanghai, 26-29 August 2004.pp. 1577-1579   Yiw u X i e Yuton g L i  Ch un li W a n g   Mingyu Lu, “The Optimization and Improvement of the Apriori Algorithm International Symposium on Intelligent Information Technology Application Workshops, 2008 IEEE, pp.1101-1103  10  Zha o  H ong  G a ng y a ng L e i Wang  a n d  Ying liu, “An Implementation of Improved Apriori Algorithm”, Proceedings of 8th International Conference on Machine Learning and Cybernetics, 2009 IEEE, pp 1565-1569    
245 


To resolve this problem, we proposed a new KDD model. It consists of two steps: the first organizes the database records in homogeneous clusters having common properties which permit to deduce the data’s semantic. This step consists of TAH’s and MTAH generation of relieving attributes. The second permits to Discovering Knowledge. It consists to deduce the Fuzzy  Cluster Lattice corresponding to MTAH lattice generated in the first step, then traverse this lattice to extract the Meta Knowledge \( Set of fuzzy associations meta-rules on the clusters \, and in end deduce the rules modeling the Knowledge \(Set of fuzzy associations rules on the attributes\While basing on the hierarchical structure offered by the lattices, we proceed to discover the Knowledge in a hierarchical way. Thus, according to the degree of detail required by the user, this approach proposes a level of knowledge and different views of this knowledge Moreover, this solution is extensible; the user is able to choose the fuzzy method of classification according to the domain of his data and his needs This solution reduced considerably the number of generated rules, offered a better interpretation of the data and optimized both the space memory and the execution time As futures perspectives of this work, we mention 1\o test our approach on several the large data set, and 2\ to define a new intelligent method of evaluation of requests which takes into account the Meta knowledge and/or the knowledge base generated by our KDD model XI  R EFERENCES  1  P. Berkhin, “Survey of clustering data mining techniques“, Technical report, Accrue Software, 2002 2  M. Zaki, “Mining Non-Redundant Association Rules”, Data Mining and Knowledge Discovery, No 9, 2004, p. 223–248 3  G. Stumme, R.Taouil, Y. Bastide, N. Pasquier, and     L. Lakhal Intelligent structuring and reducing of association rules with formal concept analysis”, Proceedings of KI’2001 Conference, Vienna Austria, Lecture Notes in Artificial Intelligence 2174, SpringerVerlag, September 2001, p. 335–350 4  N. Pasquier “Data Mining : Algorithmes d'Extraction et de Réduction des Règles d'Association dans les Bases de Données”, Thèse Département d’Informatique et Statistique, Faculté des Sciences Economiques et de Gestion, Lyon, 2000 5  R. Agrawal, T. Imielinski, and Swami A., “Mining Association Rules between sets of items in large Databases”, Proceedings of the ACM SIGMOD Intl. Conference on Management of Data, Washington USA, June 1993, p. 207-216 6  R. Agrawal, and R. Skirant. “Fast algoritms for mining association rules”. In Proceedings of the 20th Int'l Conference on Very Large Databases, pages 478-499, June 1994 7  N. Pasquier, Y. Bastide, R.Taouil, and L. Lakhal,          “ Efficient Mining of Association Rules Using Closed Itemset Lattices Information Systems Journal, vol. 24, no 1, 1999, p. 25-46 8  M. J. Zaki, and C. J. Hsiao, “ CHARM : An Efficient Algorithm for Closed Itemset Mining ”, Proceedings of the 2nd SIAM International Conference on Data Mining, Arlington, April 2002, p. 34-43 9  G. Stumme, R. Taouil, Bastide Y., Pasquier N., and L. Lakhal, “Fast Computation of Concept Lattices Using Data Mining Techniques BOUZEGHOUB M., KLUSCH M., NUTT W., SATTLER U., Eds Proceedings of 7th Intl. Workshop on Knowledge Representation Meets Databases \(KRDB’00\Berlin, Germany, 2000, p. 129-139 10  G. Stumme, R.Taouil, Y. Bastide, N. Pasquier, and     L. Lakhal Computing Iceberg Concept Lattices with TITANIC”, J. on Knowledge and Data Engineering \(KDE\ vol. 2, no 42, 2002, p. 189222 11  S. Ben Tekaya, S. Ben Yahia, and Y. Slimani. “Algorithme de construction d`un treillis des concepts formels et de détermination des générateurs minimaux”, ARIMA journal, Novembre 2005, Numéro spécial CARI'04, pages: 171-193, 2005 12  T. Hamrouni, S. Ben Yahia, and Y. Slimani. “Prince : Extraction optimisée des bases génériques  de règles sans calcul de fermetures In Proceedings of the Intl. INFORSID Conference, Editions Inforsid Grenoble, France, pages : 353--368, 24-27 May 2005 13  B. Ganter, and R. Wille, Formal Concept Analysis: mathematical foundations. \(translated from the German by Cornelia Franzke Springer-Verlag, Berlin-Hei delberg 1999 14  T.Thanh, H.Siu Cheung, and C. Tru Hoang, “A Fuzzy FCA-based Approach to Conceptual Clustering for Automatic Generation of Concept Hierarchy on Uncertainty Data.” ,CLA 2004, pp. 1–12 ISBN 80-248-0597-9 15  L. Zadeh. Fuzzy sets. Inform ation and Control, \(69\338-353, June 1965 16  M. Sassi, M., A. Grissa Touzi, and H. Ounelli, “ “Interpretting Fuzzy Clustering Results based on Fuzzy Formal Concept Analyis”, IEEE International Conference on Fuzzy Systems. Imperial College London, UK, 2007 17  A. Grissa Touzi, M. Sassi, and H. Ounelli,  “Using Formal Concept Analysis for Flexible Querying Optimization”, 23nd International Conference on Computers and Their  Applications, \(CATA’08 Mexico, Avril 2008 18  A. Grissa Touzi, M. Sassi, and H. Ounelli, “An innovative contribution to flexible query through the fusion of conceptual clustering, fuzzy logic, and formal concept analysis”, International Journal of Computers and Their Applications. Volume. 16, N°. 4, pp 220-233, December, 2009 19  M. Sassi, A. Grissa Touzi, and H. Ounelli, “A Fuzzy Linguistic Database Summarization Approach”, Fuzzy Systems Conference IEEE International Conference on Fuzzy Systems.   Hong Kong, Juin 2008 20  J.C,  Bezdeck,  R.Ehrlich,  and  W.Full,  "FCM: The Fuzzy  C-Means Clustering Algorithm", Computers and Geoscience, vol. 10, no. 2-3 pp. 191–203, 1984 21  N. Pasquier, Y. Bastide, R.Tou il, and L.Lakhal, “Pruning closed itemset lattices for association rules”, Proceedings of 14th International Conference Bases de Données Avancées, Hammamet Tunisia, 26–30 October 1998, p. 177–196 22  M. J. Zaki, “Generating Non-Redundant Association Rules Proceedings of the 6th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Boston, MA, August 2000, p 34-43 23  Y. Bastide, R.Taouil, N. Pasquier, G. Stumme, and L.Lakhal Mining frequent patterns with counting inference”, SIGKDD Explorations, vol. 2, no 2, 2000, p. 66-75 24  B. Ganter, “Two basics algorithms in concept analysis”, Technical report, Darmstadt, 1984 
134 


   


                        






978-1-4244-5858-5/10/$26.00 ©2010 IEEE                                                          ICALIP2010 414 Mining Association Rules Based on an Improved Apriori Algorithm Yanfei Zhou, Wanggen Wan  Junwei Liu, Long Cai School of Communication and Information Engineering, Shanghai University Shanghai 200072, China Email Address wanwg@staff.shu.edu.cn Abstract In this paper, we first describe the classical Apriori Algorithm. And then, we present the defects exist in this algorithm. Such as spending a lot of time to produce the candidate item-sets , scanning the database in a simple method, and so on. At last we promote our improved Apriori Algorithm which consists of three parts. The first part is reducing the number of judgments, and the second part is reducing the number of candidate frequent item-sets. The last part is optimizing the database. And the experimental results proved our improvement 1 Introduction With the popularization of computer and development of Database Technology, more and more data are stored in the large databases. Obviously speaking, it is impossible to find useful information without using efficient methods. And then, Data mining DM\niques have emerged as a reflection of this request. Association rules mining, an important research direction, is aim to find out the dependence of among multiple domains basing on a given degree of support and credibility  Association rules mining process is divided into two steps. The first step is to find the frequent item-sets which support degree is large than the initial support degree from the transaction database; the second step to generate the rules of value from the frequent item-sets and the acquisition of frequent item-sets is the key step during mining association rules procedure. In 1993, R Agrawal first promoted an association rule mining algorithm named apriori alg orithm \(AA\. And in the following year, Agrawal proposed two kinds of improved AA named AprioriTid algorithm and AprioriHybrid algorithm. What’s more, subsequent researchers have also given a lot of improvement for the AA. However, all of these improved algorithms have the following problems in varying degrees. The first problem is these algorithms need a lot of time to produce the candidate frequent item-sets. And the second one is these algorithms have to scan the transaction database many times to do the pattern-matching for candidate frequent item-sets These two issues are both the hotspots and difficulties during current research on mining association rules. In our paper, we promote a faster and more efficient algorithm based on the classical AA  2.Basic conception The concept of the association rules was first proposed by R. Agrawal. It is used to describe the patterns of customers' purchase in the supermarket. The association rules can be formally defined as Definition 1: Let      123 n Iiii i   be a set of items D is a transactional database. Where  k ik 123 n   is an item. Tid is the exclusive identifier of transaction T in transactional database Definition 2: The implication of the form XY  is called an association rules. Where XI   YI  and XY   Definition 3: Let D be a transactional database. If the percentage of transactions in D that contains XY  is s%, the rule XY  holds in D with Support s If the percentage of transactions in D containing X that also contain Y is c the rule XY  has Confidence c The definitions of probability are  Support X Y P X Y     Confidence X Y P Y X   Rules that satisfy both minimum support threshold min-sup\ and minimum confidence threshold min-conf\trong rules Definition 4: If the support of item-sets X is greater than or equal to minimum support threshold X is called frequent item-sets. If the support of item-sets X is smaller than the minimum support threshold, then X is called infrequent item-sets 


415 3 The basic idea of Apriori Algorithm Generally speaking, AA uses an iterative method to search the rules Layer by layer. We should find out the 1-item-set named 1 L at first, and then we use 1 L to identify the set of 2-item-set named 2 L Go on this operation until we can’t seek out the item-set. Here there are two parts during the AA a Connection Step Generate a new set of candidate item-set named k C here k is the length of candidate item-set k C is the produced through the connection operation of 1 k L   Here 1 k L  is a frequent item-set and 1 k  is the length of this frequent item-set. The connection rules reads as follows. Let 1 L and 2 L belong to the 1 k L  If all the items of these two frequent item-set are same except their last items, then they can be connected b Pruning Step Actually speaking, it is scanty that all the subset of k C fill the min-sup. As a result, we must determine how many subset of k C are belongs to k L by scanning the transaction database D That is to say, we should determine the support of every item-set in k C in order to delete the candidate item-set which can’t match the min-sup 4 Apriori Algorithm Performance Analysis From the Implementation of AA, we can find there are three fatal defects exist in this algorithm a First, we need to scan the database repeatedly That is, we need to scan the whole database every time when we calculate an item-set b The time complexity and space complexity are too high due to its large candidate item-sets c There exist many rules, discovered by the method which is based on the theory of credibility, which have no practical significance 5 Improvement of Apriori Algorithm In this paper, we decide to improve the performance of AA in the following three aspects a Reduce the number of judgments b Reduce the number of candidate frequent item-sets c Optimize the database 5.1 Reduce the number of judgments During the process of AA, all these transactions have already been sorted. Therefore, we can affirm that the candidate frequent item-set is ordered. And any comparison between the two candidate item-set  is ordered on the bit comparison .That is to say, we can reduce the number of judgments during the process of producing candidate frequent item-set  through the use of this property. The details are as follows  Definition 1: Let us compare two frequent item-set named lx and ly If            lx 1 ly 1 lx i 1 ly i 1 lx i ly i 1 i k 012 012  Then we can say that lx is smaller than ly  lx ly  If there exists m frequent item-sets and 12 m ll l     we can allege that these item-sets are ordered. There are many properties for this definition Property 1: For any item of k-item-set, there exists    l1 l2    Proof: Because l is an ordered item-set, so the property is proved Property 2: For any item of k-item-set  lx ly let 1x yzm   If           lx 1 ly 1 lx i 1 ly i 1 lx i ly i 1 i k 012 012  than we can get that    lx j lz i   while counter j is smaller than z and larger than 1 Proof: Because yz  so we can affirm ly lz   Therefore, if    ly i lz i     lx i lz i  is true when j equals to i which is a specific number. By the same token, if    ly i lz i     ly p lz p   is true when j equals to p which is a specific number We can optimize the link step by using the properties mentioned above  With regards to these two k-1 frequent item-set named lx and ly if these two item-set can’t be connected, then we can affirm that all the item-sets after lx and ly can’t satisfy the connection condition .As a result, there is no need to determine whether the item-sets which are behind the item-set lx and ly satisfy the connection conditions or not What’s more, both item-set lx and item-set ly get from k-item-set. So, repeated connection operations are existed during the Traversal process. That is, the result of connecting x and y is same to the result of connecting y to x. So, it is necessary to execute further optimization  12 declare TL TL  1K12K1 Set TL L TL L   1 f oreach lx TL 015 


416  2 f oreach ly TL 015        if lx 1 ly 1 lx i 2 ly i 2 012    lxk1 lyk1 012    clxly   kk CC c   22 TL TL x   Item-set lay behind ly can't connect to lx   5.2 Pruning the frequent item-sets  Frequent item-sets have the following properties Property 1: The necessary condition for a k-dimensional becomes a frequent item-set is that all the \(k-1\dimensional subsets are also frequent item-set Property 2: Let k-dimensional item-set     12 k xii i      K1 L jk1   is true when j belongs to X, then we can say that X is not a frequent item-set. Here  K1 L j  means the number of j in  K1 L j   Proof: Let X be a k-dimension item-set. Now we take any k1  elements from X Obviously, there are k possibilities. So, there are k1  project j in all the \(k-1\dimension item-set which are produced by X  As far as the above properties are considered, we can get a conclusion. The details are as follow Let c i 015  1  015 k L c here i is an project, c is an element and 1  K L  is a k-dimension frequent item-set . If the inequality  K1 L jk1   is established, then the candidate k-dimension 1  K C item-set produced by 1  K L  can’t be a frequent item-set. As a result, there is no need to let 1  K C participate in join operations Here is the new strategy for pruning the frequent item-set Calculate  K1 L j  Here  K1 L j  is the frequency of   K1 L j  and    k1 jL UAAL  015 015 Find the projects which frequency are smaller than k1   and then put them into a Set name  I  Get rid of the frequent item-set of K1 L  which contains the subset of  I than we can get a new K1 L  named  K1 L   5.3 Database optimization Mark a delete tag on all the transactions of item-set which not contains the k C during the calculation of k C  Therefore, there is no need to take these item-set into consideration in the following calculation. The efficiency can be more and more obvious with the growth of value k 6 Improved algorithm description Input: Transaction D Minimum support threshold min-sup Output L i Frequent item-set in D  Here is the flow chart 1   _ 1 _ _ 1 D itemset frequent find L   f ind the 1-itemset 2 1 2   k for k L k   3 sup min_   _ 1   K k L gen apriori C  K Create the candidate itemset C    5 kk L Citemset  6  7 k return L=UL Procedure apriori_gen 1 k L  min_sup 1  12 declare TL TL 2     k1 Get I i L i k 1   3  k1 k1 Set L L I   4  1k1 2 k1 Set TL L TL L   5 1 f oreach lx TL 015 6 2 f oreach ly TL 015 7      if lx 1 ly 1 lx 2 ly 2 012 8        lx k 2 ly k 2 lx k 1 ly k 1  012   10  clxly  12   _  k1 if has infrequent_itemset\(c,L   13  delete c  16   kk CC c  17 22 TL TL lx  18  19 else break  21 Has_infrequent_item-set c  K1 L   1 f or each \(k-1\ subset s of c  2 k1 if s L return true; else return false    7 Experimental Result  We compared the performance of our improved 


417 algorithm with the classical AA. The experimental platform is Intel Core\(TM\ 2 CPU 6600 2.4GHz 2.00G RAM Windows XP Operating System. It is based on Microsoft Sql database. The algorithm adopts C# program and compiles in Visual Studio 2005 experiment environment Our experiment uses a fictional supermarket transaction database which consists of 10000 TDs and 120 items Experiment 1 Number of items: 120 Number of TD: 10000  0 0.005 0.01 0.015 0 5000 10000 15000   Support Degree Elapsed Time Constrast1\(with different Support Degree AA IAA   Fig 1. Experiment Contrast with different Support degree From Fig 1, we can see that the execution time of IAA is shorter than AA while under different support degree Experiment 2 Support Degree:0.005 Number of items:120 0 2000 4000 6000 8000 10000 12000 0 1 2 3 4 5 6 7 x 10 4   Number of TD Elapsed Time Constrast2\(with different Number of TD AA IAA   Fig 2. Contrast with different Number of TD From Fig 2, we can see that the execution time of IAA is shorter than AA while under different number of trading services Experiment 3 Support Degree: 0.005 Number of TD: 10000 0 20 40 60 80 100 120 0 1 2 3 4 5 6 7 8 9 10 x 10 4  Number of Items Elapsed Time Constrast3\(with different Number of Items AA IAA   Fig 3. Contrast with different number of items From Fig 3, we can see that the execution time of IAA is shorter than AA while under different number of items The above three experiment results demonstrate that while comparing the classical AA, the IAA improves the overall performance by reducing the number of scanning the database, using the new data representation and adopting a new Connection method between items 8 Conclusions In this paper, an improved Apriori-based algorithm IAA is proposed. Our improvement consists of three parts which are reducing the number of judgments adopting new pruning strategy and optimize the transaction database. These improvements can greatly reduce the redundant operation while generating frequent item-sets and association rules in the database Validated by the experiments, the improvement is notable Acknowledgements The paper is supported by National Natural Science Foundation of China \(60872115\, Shanghai’s Key Discipline Development Program \(J50104 References 1 K un-M i ng  Y u  J i a L i ng Zho u  A W e ig hte d Load-Balancing Parallel Apriori Algorithm for Association Rule Mining”, Granular Computing, 2008. GrC 2008. IEEE International Conference on 26-28 Aug. 2008, pp.756-761 2 Coli n Co ope r  a n d Mic he le Zi to R e a listic Sy nthe tic Da ta  for Testing Association Rule Mining Algorithms for Market 


418 Basket Databases”, Knowledge Discovery in Databases PKDD 2007, Volume 4702/2007, pp.398-405 3 C h a o T ung Y a ng  W e nC h u n g Shih, a n d Sh ia nS h y ong Tseng, “A Heuristic Data Distribution Scheme for Data Mining Applications on Grid Environments”, Fuzzy Systems 2008. FUZZ-IEEE 2008. \(IEEE World Congress on Computational Intelligence\. IEEE International Conference on 1-6 June 2008, pp.2398-2404 4 A Sav asere, E O m iecin sk i, S Nav ath e. Min in g f o r stro n g  negative association in a large database of customer transactions [J  D a ta Eng ine e r ing IC D E 9 8 19 98  pp  494-502 5  T a or ong Q i u   Xia om ing B a i, L i ping Zha ng  A n A p r i or i algorithm based on granular computing and its application in Library management system”, Control & Automation, 2006 pp.218-221 6 Y a Ha n Hu, Y e nL i a n g Che n .Min ing a ssoc ia tion ru le s with multiple minimum supports: a new mining algorithm and a support tuning mechanism Decision Support Systems 2006, pp.1 -24 


Algorithm 1 Pseudocode for the S AMPLE C OUNT phase 1 procedure S AMPLE C OUNT  P s size   P is a stream of pairs each of which has associated a similarity value The length of P is known 2 S out   3 while There are elements in P do 4 S 0   5 S   6 t  0 7 S  the 002rst s 2 elements in P 8 while  t  size 2 000 s 2 do 9 i  the next element in P 10 Choose uniformly at random a number r 2 0   11 if r 024 s  s  2 t  2 then 12 Choose uniformly at random a victim from S and substitute it with i 13 end if 14 t  t  1 15 end while 16 initialize  S 0  S   S 0 is an associative array indexed on the distinct items present in S  initializing it means putting all its entries to 0 17 while  t  size  do 18 i  the next element in P 19 if i 2 S then 20 S 0  i   S 0  i   015 i 21 end if 22 t  t  1 23 end while 24 Choose the s topmost distinct items between S 0 out and S 0  and assign them to S 0 out 25 end while 26 Return S 0 out 27 end procedure IV A NALYSIS Let S i denote the set of transactions containing the element i  This means that S i  S j is the set of transactions containing the pair f i j g  Let S 1 i denote the set of transactions containing i in the current pre\002x of the stream Similarly S k i will denote the set of transactions containing i in C k  the chunk k of the suf\002x of the stream up to the point in which a new current pre\002x changes the counts of items occurrences So S k i  S i  C k De\002nition 5 Given x y 2 R we say that x  016 L  approximates y  written x 016;L  y  if and only if x 025 L implies x 2 1 000 016  y  1  016  y   016 The notation extends in the natural way to approximate inequalities In what follows we will use  016 L  approximations where L  C log mn  for a suitably large constant C depending on the accuracy 016 in Theorem 2 The task is to analyze the accuracy of the new approximation computed when the current pre\002x changes We introduce two random events G OOD P ERMUTATION GP and G OOD B ISAM S AM PLE GBS and bound the probability that they do not happen A permutation of the transactions is called good for f i j g  denoted GP i;j  if and only if the following conditions hold for the current pre\002x 1 j S 1 i j 016;L  j S i j  2 and j S 1 j j 016;L  j S j j  2  2 8 k j S k i  S k j j 016;L  j S i  S j j  2 k  Essentially goodness means that the frequencies of individual items are close in the 002rst and second half of the current pre\002x and the frequency of the pair is evenly spread over the chunks in the second part of the current pre\002x Lemma 6 Given 016 2 0 022 R  we have Pr[GP i;j  025 1 000 6 001 e 000j S i j 016 2 6 Proof An interesting property of the random variables j S 1 i j and j S k i  S k j j is that they are negatively dependent First of all we bound the probability that j S 1 i j is far from j S i  2 j  Using Chernoff bounds we can write Pr j S 1 i j 000 j S i j  2 j 024 016 j S i j   024 2 001 e 000 j S i j 016 2 6 1 
126 
126 


Looking at j S k i  S k j j we can write Pr j S k i  S k j j\000j S i  S j j  2 024 j 024 016 j S i  S j j  2 024  024 2 001 e 000 j S i  S j j 016 2 6 024 2 We use the fact that Chernoff bounds also holds for negatively dependent random variables Since the last bound is the weakest of the three the lemma follows We want GP i;j to hold with probability 1 000 o 1 n 2  whenever items i and j both have support   From Lemma 6 we get that this holds if j S i  S j j  C\024 log n  for some constant C depending on 016  If s  i j   2 024Lf     025 024L then j S i  S j j 025 2 024L  Hence a suf\002cient condition for the similarity is s  i j   024L  3 It remains to understand what is the probability that given a good permutation the pair sampler will take a number of samples for a given pair in each chunk k that leads to a 1 006 016  approximation of s  i j   We denote the latter event by GBS i;j;k  and want to bound the quantity Pr[GBS i;j;k j GP i;j   For this purpose consider the random variable X i;j;k de\002ned as the number of times we sample the pair f i j g in chunk k  Assuming GP i;j we have that over the randomness in the pair sampling algorithm E  X i;j;k  016;L   f  j S 1 i j  j S 1 j j  034 j S i  S j j  2 024  Since the occurrences of f i j g are independently sampled we can apply a Chernoff bound to conclude X i;j;k 016;L  E  X i;j;k   This leads to the conclusion Lemma 7 X i;j;k 016;L   f  j S 1 i j  j S 1 j j  034 j S i  S j j  2 024 016 Suppose that X i;j;k is close to its expectation Then we can use it with 1 006 016  approximations of j S i j and j S j j  to compute a 1 006 O  016  approximation of s  i j   This follows by analysis of the concrete functions f of the measures in Figure 1 A suf\002cient condition on the similarity needed for a 1 006 016  approximation of X i;j;k can be inferred from lemma 7 If s  i j  025 4 024L=\034 then E  X i;j;k  025 s  i j  034  4 024 025 L  So it suf\002ces to enforce s  i j  025 4 024L=\034  4 In order to have O  mb  pairs produced by the pair sampling phase we will choose 034  4 M  The expected number of pair samples from T t is less than j T t j 2 034 f      using that f is decreasing For all measures we consider f     024 1   so j T t j 2 034 f     024 j T t j 2 M 024 j T t j  It remains to understand which is the probability that a pair of items each with support at least   is not sampled by SampleCount Let the random variable X k represent the total number of samples taken in chunk k  The probability that a f i j g is sampled in chunk k is X i;j;k X k  so the probability that it does not get sampled in any evennumbered chunk is Q k 2  024 even  1 000 X i;j;k X k  s  We have seen before that X i;j;k 016;L 025 s  i j  034  4 024  For what concerns X k using a Chernoff bound we can get X k 016;L  E  X k  024 mb=\024  using the linear upper bound on the number of samples So we can compute Y k 2  024 even  1 000 X i;j;k X k  s 024 022 1 000 s  i j  034 024 2 024\015 i;j mb 023 s\024 2 024 022 1 000 s  i j  034 4 mb 023 s\024 2 024 C exp 024 000 s  i j  034 s\024 8 mb 025 In order for this probability to be small enough  O 1 m 2   we need to bound the similarity to s  i j  025 8 mbL s\024\034 5 To choose the best value of 024 we balance constraints 3 and 5 getting 024L   mbL s\024\034  024  r mbM s 6 From which we can deduce s  i j   L  max  r mbM s  M   7 V D ATASET CHARACTERISTICS We have computed for a selection of the datasets hosted on the FIMI web page 1  the ratios between the number of occurrences of single items and pairs in the 002rst half of the transactions and the total number of occurrences of the same items or pairs The values of some of this ratios the most representative are plotted 002gure 3 on the x axis items or pairs are spread evenly after they have been sorted according to their associated ratio The y axis represents the value of the ratios We have taken into account only items and pairs whose support is over 20 occurrences in the whole dataset in order to avoid the noise that could be generated by very rare elements As we can see the number of occurrences and co-occurrences are not so far from what would be expected under a random permutation of the transactions The synthetic data set behaves exactly like we would expect under a random permutation with the ratio being very close to 1  2 for almost all items/pairs This means that even for real data sets where the order of transactions is not random the sampling probabilities used in the pair sampling are reasonably close to the ones that would be obtained under the random permutation assumption VI C ONCLUSIONS We presented the 002rst study concerning the problem of mining similar pairs from a stream of transactions that does rely on the similarity of items and not only on the frequency of pairs A thorough experimental study of carefully engineered versions of the presented algorithm remains to be carried out 1 http://fimi.cs.helsinki.fi 
127 
127 


Figure 3 Plots of the ratios j S 1 i j  j S i j and j S 1 i  S 1 j j  j S i  S j j  R EFERENCES  E Cohen M Datar S Fujiwara A Gionis P Indyk R Motwani J D Ullman and C Yang Finding interesting associations without support pruning IEEE Trans Knowl Data Eng  vol 13 no 1 pp 64–78 2001  Y.-K Lee W.-Y Kim Y D Cai and J Han Comine Ef\002cient mining of correlated patterns in Proc IEEE International Conference on Data Mining ICDM 2003  IEEE Computer Society 2003 pp 581–584  E Omiecinski Alternative interest measures for mining associations in databases IEEE Trans Knowl Data Eng  vol 15 no 1 pp 57–69 2003  J Han and M Kamber Data Mining Concepts and Techniques 2nd edition  Morgan Kaufmann 2006  R Agrawal and R Srikant Fast algorithms for mining association rules in large databases in Proc International Conference On Very Large Data Bases VLDB 1994  Morgan Kaufmann Publishers Inc Sep 1994 pp 487–499  J Han J Pei Y Yin and R Mao Mining frequent patterns without candidate generation A frequent-pattern tree approach Data Min Knowl Discov  vol 8 no 1 pp 53 87 2004  N Jiang and L Gruenwald Research issues in data stream association rule mining SIGMOD Record  vol 35 no 1 pp 14–19 2006  Y Zhu and D Shasha Statstream Statistical monitoring of thousands of data streams in real time Morgan Kaufmann 2002 pp 358–369  G Cormode and S Muthukrishnan What's hot and what's not tracking most frequent items dynamically ACM Trans Database Syst  vol 30 no 1 pp 249–278 2005  E D Demaine A L  opez-Ortiz and J I Munro Frequency estimation of internet packet streams with limited space in Proc 10th Annual European Symposium Algorithms ESA 2002  2002 pp 348–360  J X Yu Z Chong H Lu Z Zhang and A Zhou A false negative approach to mining frequent itemsets from high speed transactional data streams Inf Sci  vol 176 no 14 pp 1986–2015 2006  A Chakrabarti G Cormode and A McGregor Robust lower bounds for communication and stream computation in STOC  C Dwork Ed ACM 2008 pp 641–650  S Guha and A McGregor Stream order and order statistics Quantile estimation in random-order streams SIAM Journal on Computing  vol 38 no 5 pp 2044–2059  N Alon Y Matias and M Szegedy The space complexity of approximating the frequency moments J Comput Syst Sci  vol 58 no 1 pp 137–147 1999  J Misra and D Gries Finding repeated elements Sci Comput Program  vol 2 no 2 pp 143–152 1982  R M Karp S Shenker and C H Papadimitriou A simple algorithm for 002nding frequent elements in streams and bags ACM Trans Database Syst  vol 28 pp 51–55 2003  M Charikar K Chen and M Farach-Colton Finding frequent items in data streams Theor Comput Sci  vol 312 no 1 pp 3–15 2004  A Campagna and R Pagh Finding associations and computing similarity via biased pair sampling in Proc 9th IEEE International Conference on Data Mining ICDM 2009    Finding associations and computing similarity via biased pair sampling Invited for publication in Knowledge an Information Systems  2010  E Kushilevitz and N Nisan Communication complexity  New York Cambridge University Press 1997  J S Vitter Random sampling with a reservoir ACM Trans Math Softw  vol 11 no 1 pp 37–57 1985  D Dubhashi and D Ranjan Balls and bins a study in negative dependence Random Struct Algorithms  vol 13 no 2 pp 99–124 1998 
128 
128 


Application of Chaotic Particle Swarm Optimization Algorithm in Chinese Documents Classification 763 Dekun Tan Qualitative Simulation Based on Ranked Hyperreals 767 Shusaku Tsumoto Association Action Rules and Action Paths Triggered by Meta-actions 772 Angelina A. Tzacheva and Zbigniew W. Ras Research and Prediction on Nonlinear Network Flow of Mobile Short Message Based on Neural Network 777 Nianhong Wan, Jiyi Wang, and Xuerong Wang Pattern Matching with Flexible Wildcards and Recurring Characters 782 Haiping Wang, Fei Xie, Xuegang Hu, Peipei Li, and Xindong Wu Supplier Selection Based on Rough Sets and Analytic Hierarchy Process 787 Lei Wang, Jun Ye, and Tianrui Li The Covering Upper Approximation by Subcovering 791 Shiping Wang, William Zhu, and Peiyong Zhu Stochastic Synchronization of Non-identical Genetic Networks with Time Delay 794 Zhengxia Wang and Guodong Liu An Extensible Workflow Modeling Model Based on Ontology 798 Zhenwu Wang Interval Type-2 Fuzzy PI Controllers: Why They are More Robust 802 Dongrui Wu and Woei Wan Tan Improved K-Modes Clustering Method Based on Chi-square Statistics 808 Runxiu Wu Decision Rule Acquisition Algorithm Based on Association-Characteristic Information Granular Computing 812 JianFeng Xu, Lan Liu, GuangZuo Zheng, and Yao Zhang Constructing a Fast Algorithm for Multi-label Classification with Support Vector Data Description 817 Jianhua Xu Knowledge Operations in Neighborhood System 822 Xibei Yang and Tsau Young Lin An Evaluation Method Based on Combinatorial Judgement Matrix 826 Jun Ye and Lei Wang Generating Algorithm of Approximate Decision Rules and its Applications 830 Wang Yun and Wu-Zhi Qiang Parameter Selection of Support Vector Regression Based on Particle Swarm Optimization 834 Hu Zhang, Min Wang, and Xin-han Huang T-type Pseudo-BCI Algebras and T-type Pseudo-BCI Filters 839 Xiaohong Zhang, Yinfeng Lu, and Xiaoyan Mao A Vehicle License Plate Recognition Method Based on Neural Network 845 Xing-Wang Zhang, Xian-gui Liu, and Jia Zhao Author Index 849 
xiii 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        






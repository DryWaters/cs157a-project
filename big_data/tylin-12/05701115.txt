A Study of Safety Third-Party Logistics Information Management Model Base d on Data Mining Wanhua Meng Economics and Management Department,Shaoxing Arts and Sciences College, Shaoxing, Zhejiang Province,312000,Chin a mengwanhua@163.com  Abstract By illustrating the classification rules and association ru les of data mining and taking into consideration of the content and requirement of third-party logistics information management and analyzing the security problems exist in third-party logistics information management, the paper 
suggests a safety third-party logistics information manageme nt model based on data mining. This mode l could provide better solution to the security problems in logistics information management, and help ensure the security of third-party logistics information management  Keywords 002 002 002 002 data mining; association rules third-party logistics; information management model I. INTRODUCTION With the globalization of supply chain and the development of competitive system and 
information technology, the logistics becomes more and more complex, and the cost of logistics increases and capital becomes more intensive. As a new model of logistics, the third-party logistics plays an important role in reducing the companyês logistics cost and in enhancing the competitive edge. Under the logistics information system, the third-party logistics corporations could build up the relationship between the various sectors of a company; the compan y and supplier; the company and the consum ers ; the company and 
government on the net, and coordinate and corporate between each other  When the third-party logistics information system serves as business running and decision making platform, the safety of the system is much worried by the decision makers, because any change and leaking of information resource or the destroy of information resource could bring to the company inestimable economy loss and even could endanger the companyês survival and development. Besides, logistics information management system, which based on traditional data-bank, neglects the analysis of 
information and it causes inconvenience to decision makers. The third-party logistics, as a complex system, yields a large amount of data every moment. The various data store in logistics information management system distributed in various data bank with different storage means and data format. Therefore, it turns out to be an important problem needed to be solved as how to make use of advanced data mining technology and to search useful information among multi-sources and heterogeneous data and ensure the safety of information management data, thus to better 
serve the third-party logistics in the aspect of decision making 003 004 004 004 004 THE ANALYSIS OF THE CONTENT AND SAFETY OF PRESENT THIRD-PARTY LOGISTICS INFORMATION MANAGEMENT The connection in logistics system is achieved through information. The dispatch of basic resource is achieved by sharing the information resource too. So the arrangement of logistics activities should base on information In order to make logistics activities go smoothly 
and regularly, it is important for us to ensure the safety and accessibility of these activities. The network of logistics information is just the way which aims to make the logistics information be shared by business sectors, various businesses and even businesses worldwide with the help of modern information technology. The logistics information management is the process to analyze, search, study, report, exchange logistics information and offer thes e services by planning organizing, commanding, coordinating and manipulating, so that it could effectively make use of manpower, materials and capital to reach 
an overall target of logistics management. It is a dynamic development concept, its denotative and connotative meanings will change along with the enhancement of logistics management practice and development of logistics management, along with the development of information technology, the logistics information system comes into being based on information technology. By adopting computer technology and communication technology, the logistics information management system is a 
2010 International Conference on Digital Manufacturing & Automation 978-0-7695-4286-7/10 $26.00 © 2010 IEEE DOI 10.1109/ICDMA.2010.67 127 


human-machine system which collects catalogues, processes, stores logistics information and offers service etc. It can exchange long-distance information and process huge data of information, and it can play an important role in e-commerce circulation accounting treatment and business management  According to the feat ures of information system and logistics, the functions of the third-party logistics information management model are shown as follows: data collecting and inputting, information storage, information process, information transmission, information searching and inquiring and outputting. It is quite obvious that information management requires processing and transmitting huge accurate data, such as market supply quantity supply price and demand quantity, demand price and storage quantity, assortment, quality and size Any missing or mistake in information can directly affect the decision making and carrying out the decisions, and eventually will influence the effect of logistics management and economy efficiency of company. The safety of the third-party logistics information management model includes the safety of external information exchange and the safety of internal information processing. The safety of information management is threatened when a company exchanges information with other companies such as acce pting the ordering sending back the information on the net. Some measures must be taken due to insecurity on the net, such as network att ack from hackers, virus spreading and unsafe network system. As for the safe internal information processing, firstly it must be done under the safe operating system this is the basic requirement of company logistics information. Secondly, it requires a qualified work team who are self-disciplined and law-abiding, which is key link to ensure the safety of information system operating  From the perspective of information system, the core of the safety of logistics information system is to ensure the normal operating of information system and the safety of data. Information system safety involves the problems of the safety of net, servers, storage device and operating system, reliability of back-up solution and clustering technique electrical supply, the co mputing environment computer virus and unauthorized access computer system management. Data safety refers to ensure the safety of data, which means the data would not miss and be changed and destroyed and stolen; the insecurity of data processing will cause great loss to business Although the information has the characteristics of sharing and not equaling to zero, the various businesses may get imbalanced information of the demand of market, so it will still erode the competitiveness of businesses if key information is leaked and will put the business at a serious disadvantage. So logistics information system safety is a safety project 003 005 005 005 005 Safety Third -Party Logistics Information Management Model Based on Data Mining A. The safety model of third-party information management   As what is discussed above, in order to make logistics activities go smoothly and regularly, it is important for us to ensure the safety and accessibility of these activities Third-party logistics information management model bears networking feature, and the information is transmitted through network, so the safety of network is quite important for the logistics information ma nagement. Because of the openness of network, insecurity of communications protocol, and because of data storage and data processing on the net and because users access data from many different sources distributed throughout network environment, it is more likely that data transmitted on the net is leaked or destroyed and the network is likely to be attacked severely We could adopt information Protection System or Dynamic Information Security Theory order to ensure the safety and accessibility of logistics information. We construct Information Protection System, that is, P2DAR model shown on Fig 1. This model provides an available method of securing logistics information management. P2DAR model consists of Policy, Protection, Detection Analyze and Response. Pr otection, Detection Analyze and Response combined to form a complete and dynamic safety cycle, which ensures the safety of information system under the safety guideline  Policy is the core of The P2DAR model in Fig 1. The security policy should be made in the company in order to carry out third-party 
128 


logistics information management dynamic network system. The security policy provides guideline and supporting means in the information management, while protection is achieved by adopting some traditional static security means such as firewalls, encryption and user authentication. Det ection is the foundation of the whole safety model and basis of dynamic analysis and response. It is also the powerful means to impose the security policy by continuously detecting and monitoring network and system and finding out the weakness and threat and at the same time it responds effectively and promptly through cycle feedback It often detects the weakness of the system and external threat. Analyze is the most important link in the model, it further abstracts and analyzes findings of detection and distinguishes the most dangerous actions affecting system from the complex reports of findings and builds up the most Öadvanced warning model, provides the users the friendly analysis of findings, so we could quickly locate the existing problems occurred in the network and respond readily to the problems according to defense system previously worked out. Response plays an important role in the safety system and it is the most effective method to solve potential security problems. It must make correct response in case insecurity hole or incident occurs   B. Third-party logistics information safety detection model based on data mining As suggested in the P2DAR model in Fig 1 detection is the foundation of the whole safety model and basis of dynamic analysis and response. It is also the powerful means to impose the security policy by continuously detecting and monitoring network and system and finding out the weakne ss and threat and at the same time it responds effectively and promptly through cycle feedback. The application of data mining technique to detecting network and system of third-party logistics information model would automatically result in brief and accurate detecting model based on huge data being checked. The Information Detecting Model based on the association rules and Apriori algorithm is suggested in Fig 2   In Fig 2, Packet Sniffe r aims to collect data and it is only a simple interface to get information; while data preprocessing is responsible for transferring the network data and data connecting into the data format required by data mining, the steps includes further filtering, noise clearing up, the known attack detected by the third-party detection tools Newdone Analyzer tries to find the new attack through association analysis and sequential analysis and sends abnormal behaviors to Rules Builder which extracts intrusive abnormal behavior patterns. Rule Bank is used to store the original intrusive behavior patterns and other intrusive behavior patterns which arise when Rules Builder is data mining. Rule Bank can also be used to data preprocessing Announciator make s announcement to third-party logistics information management system administrator in human-computer interface when deviant analysis reports abnormal behaviors 003 006 006 006 006\007 007 007 007  Data Mining and Its Applications Data mining means extracting hidden unknown and potential useful information and knowledge from huge, incomplete, noisy, vague and random data. The major task of data mining is to adopt and develop some relevant theories methods and tools to extract some useful and interesting knowledge and model by making full use of huge databases    A. Some concepts of Association Rule  Let I={i 1 010 i 2 010\011\010 i m be a set of items. Let D, the task-relevant data, be a set of database transactions where each transaction T is a set of items such that T 002 I. Each transaction is associated with an identifier, called TID. Let A be a set of items. A transaction T is said to contain A if and only if A 002 T. An association rule is an implication of the form A 002 B, where A 003 I,B 003 I, and 012\013\014\015 004 007 The rule A 002 B holds in the transaction set D with support s where s is the percentage of transactions in D that contain A 005 B\(i.e., both A and B\. This is taken to be the probability, P\(A 005 B\e rule A 002 B has confidence c in the transaction set D if c is the percentage of transaction in D containing A that also contain B. This is taken to be the conditional probability, P\(B|A\. that is Support\(A 002 A 005 B Confidence\(A 002 B|A When support account and confidence account is equal or greater than their threshold limit value respectively, we can see A is equal or greater than B. These two values are named as min sup and min conf. If support 016 A 002 B 017\020 min_sup and confidence 016 A 002 B 017 020 min_conf 010 association rule A 002 B is the strong rule. If not association rule A 002 B is the weak rule  B. The process of asso ciation rule mining  Association rule mining is to generate association rule which demands all support and confidence count exceeds min sup and min conf in itemsets D, that is, to satisfy support 016 A 002 B 017 020 min_sup and confidence 016 A 002 B 017\020 
129 


min_conf. Association rule mining is a two-step process 021  022 Find all frequent itemsets: By definition each of these itemsets will occur at least as frequently as a pre-determined minimum support count 003 023 Generate strong association rules from the frequent itemsets: By definition, these rules must satisfy minimum support and minimum confidence C The Apriori Algorithm  Apriori is an influential algorithm for mining frequent itemsets for Boolean association rules. Apriori employs an iterative approach known as a level-wise search, where k-itemsets are used to explore\(k+1 First, the set of frequent 1-itemsets is found This set is denoted L 1 L 1 is used to find L 2 the set of frequent 2-itemsets,which is used to find L 3 and so on, until no more frequent k-itemsets can be found. The finding of each L k requires one full scan of the database k-itemsets are the itemsets of {c 1 c 2  011 c k  L k refers to k-itemsets when support count is greater than minimum support count required by the users and it is also called frequent k itemsets. C k refers to k-itemsets candidate composing candidate item sets, L   Apriori Algorithm could help to input accounting itemsets D and user specified minimum support count and minimum confidence account and ou tput all association rule itemsets if support account and confidence account is greater than minimum support and minimum confidence respectively. Apriori Algorithm is shown as follows L 1 find_frequent_1-itemsets\(D for \(k=2; L k\024 025 004 k C k apriori_gen\(L k-1 min_sup for each transaction 026\027\030\003\031\003\032\032\033\034\035\036\003\030\003 037 !\003\034 "\036\026\033\003 003\003\003\003 026 015\033"$\033%\026  026\\003 003 003 003 003 032\032+%\026\003 026,%\003 033"$\033%\026\033\003 \037\003\026\003\026,\035\026\003\035!%\003\034\035\036-.-\035\026%\033\003 003\003\003\003\037 !\003%\035\034,\003\034\035\036-.-\035\026%\003\034\027 026 003 003\003\003\003\003\003\034\007\034 "\036\026//*\003 003\003\0030\003 1  015\031\034\027  2\034\007\034 "\036\0263\0154.\0365\033"60\003  return L 005 k L k  Apriori Algorithm should first find out itemsets, L 1 of frequent 1-itemsets and then L 2 of frequent 2-itemsets until some r-value appeared which make Lr empty. Then Apriori Algorithm will come to an end. In the cycle L k-1 is to generate candidate C k 010 thus to find out L k The Apriori_genprocedure generates the candidates and then uses the Apriori property to eliminate those having a subset that is not frequent. Itemsets in C k is to generate candidate itemsets which result in frequent itemsets. The final frequent itemsets L k must be a subset of C k  For each transaction, a subset function is used to find all subsets of the transaction that are candidates, and the count for each of these candidates is accumulated. Finally, all those candidates satisfying minimum support form the set of frequent itemsets, L. A procedure can then be called to generate association rules from the frequent itemsets 021  For each frequent itemset l generate all nonempty subsets of l  For every nonempty subsets of l output the rule çs 002  l 7 s conf s count port l count port min_   _ sup   _ sup 006 where support_count l number of transactions containing the itemset l   As Apriori Algorithm doesnêt consider the specific aspects in data accounting and detection it will result in a great number of useless rules or it is likely to miss some rule which infrequently appeared but with meaningful description of behavior patterns. So it is necessary to expand Apriori Algorithm by introducing some limiting characteristic attributes in the formation of rules. In association rule mining, characteristic attributes can restrict the formation process of candidate itemsets C k so that it makes each itemset of C k contain some characteristic attribute value  D samples To process data packet into association record format and save it as text file, and separate the variants by space, suggested as follows 192 8 168 8 1 8 8    tcp 25 exterpassive sf normal 192 8 168 8 1 8 65   tcp 25 exterpassive sf normal 192 8 168 8 1 8 106  tcp 25 exter active sf normal We adopt association rule data mining to generate rules according to 250 items of association r information record satisfying both minimum support 8% and minimum confidence 100%, it turns out a lot of less meaningful rules which can not suggest any meaningful association between association values. If we detect the system according to these rules, it will mislead the decision maki ng. So it is necessary to discard these meaningl ess rules, we can take 
130 


the following procedures 022  filter rules not including class type on the right side rules  2\ filter rule not including rules of TIP and Port on the left side rules    Some satisfying rules are achieved by taking above steps, shown as follows  left side rules  right side rules  support count 0169\017  confidence count 0169\017  192 8 168 8 1 8 12 80 sf normal          9.8           100 192 8 168 8 1 8 168 25 passive exter normal         16.5           100 192 8 168 8 88 8 217 80 active normal         25.2           100 192 8 168 8 114 8 48 tcp 25 sf normal         37.1          100 192 8 168 8 118 8 63 80 active normal         19.7           100 003     Conclusion  The safety of third-party logistics information involves many factors, and there are also multi - methods to ensure the safety. The paper discusses the content and safety of third-party logistics information management and constructs a third-party logistics information safety detection model based on data mining which applies data mining technique to information detection and analyze in order to judge whether the information management model is attacked or not. The paper suggests a useful method to further solve third-party information technique safety problem   REFERENCES 1 Zh en g 2 006   Network and Information Safety Qinghua University Press,11-23  ZHAO Wentao 010 YANG Jing 8  Information Management Model of Coal Mine Safety Data 8 Industry and Automation 010@"A\007 36-39 8\003  002 Security Model and Application of Logistics Information Management in the Environment of Networks  8 Logistics Technology 010 035\036 111-113 8  I=#FJK\0031%.\(LEK\003@.M.\036+\007 2006  Research on Information Management in the Third Party Logistics and Information Cooperation Model 007 Logistics Sci- Tech Oct.98-100 002  H U Jia n 010 YIN Xi. \(2007\The System Planning and Analysis of MIS for Third Party Logistics on The Perspective of SCM   China Business and Market 003@\035\036 10-13 6 Jiawei 010 KAMBR M 8 2001 Data Mining Concepts and Techniques 8 Higher Education Press, 227 N 236 8   Known Attack  Unknown Attack packet sniffer data preprocessing newdon analyzer  announciator Rule Bank Rules Builder Fig 2 Third-Party Logistics information safety detection model based on data mining  
131 


Moreover we can say that F C is comparable to E C and the modi\002ed version of E C i.e vE C  is correct and effective  The combinations of F C  E C  and vE C with 006 conf improve slightly F C  E C  vE C  and 006 conf  We can say that the sum of con\002dences is an important measure and these combined measures are useful in particular in the context where the accuracies of the classi\002cation by the sum of con\002dence by F C  and by E C are almost very good For conclusions 002rstly the adapted weight of evidence is a good class membership measure built on the gain of information F C  a measure built on the revisited 037 2 test provides another view of information gain It is comparable to the adapted weight of evidence The sum of con\002dence is a simple and natural measure with the good performance The combinations of the sum of con\002dence with the previous measures are interesting and useful to improve their performance Next based on the average accuracy values of different measures we recommend to use the combined measures because the average accuracy values of the combined measures are in general better than that of the non-combined measures Finally through the results on each dataset between the combined measures based on 037 2 and the weight of evidence we suggest the following propositions 017 For the 13 small datasets though the average accuracy value of cE C is slightly better than that of cF C  we can observe that cF C is much often wins cE C  Indeed cE C wins cF C on only 3 datasets while cF C wins cE C on 6 datasets Hence we can recommend cF C for the small datasets 017 For the 10 large datasets the average accuracy value of cvE C is slightly better than that of cF C  and cvE C wins cF C on 4 datasets and cF C wins cvE C 3 datasets Hence we can recommend cvE C for large datasets References  B Lent A Sw ami and J W idom Clustering association rules Proc Intl Conf on Data Engineering ICDE'97 IEEE Computer Society 1997 pp 220-231  W  Li J Han and J Pei CMAR Accurate and Ef 002cient Classi\002cation based on multiple class-association rules Proc IEEE Intl Conf on Data Mining ICDM'01 San Jose CA IEEE Computer Society 2001 pp 369-376  B Liu W  Hsu and Y  Ma Inte grating Classi\002cation and Association Rule Mining Proc 4th Intl Conf on Knowledge Discovery and Data Mining KDD'98 AAAI Press 1998 pp 80-86  Y  Sun Y  W ang and A.K.C W ong Boosting an Association Classi\002er in IEEE Transactions on Knowledge and Data Engineering vol 18 no 7 IEEE Computer Society 2006 pp 988-992  J W ang and G Karypis HARMONY  Ef 002ciently Mining the Best Rules for Classi\002cation Proc SIAM Intl Conf on Data Mining SDM'05 2005 pp 205-216  J W ang and G Karypis On Mining Instance-Centric Classi\002cation Rules in IEEE Transactions on Knowledge and Data Engineering vol 18 no 11 2006 pp 1497-1511  Y  W ang and A.K.C W ong From Association to Classi\002cation Inference using Weight of Evidence in IEEE Transactions on Knowledge and Data Engineering vol 15 no 3 2003 pp 764-767  F  Coenen The LUCS-KDD Implementations of the FOIL PRM and CPAR algorithms http://www.csc.liv.ac.uk frans/KDD/Software/FOIL PRM CPAR/foilPrmCpar.html Computer Science Department University of Liverpool UK 2004  Y  Basti de R T aouil N P asquier  G Stumme and L Lakhal Mining Frequent Patterns with Counting Inferences in ACM SIGMOD Explorations vol 2 no 2 2000 pp 66-75  R Agra w al and R Srikant F ast algorithms for mining association rules Proc 20th Intl Conf on Very Large Databases VLDB'94 Santiago Chile 1994 pp 487-499  V  Phan-Luong and R Messouci Building Classi\002ers with Association Rules based on Small Key Itemsets Proc 2nd IEEE International Conf on Digital Information Management ICDIM'07 France 2007 pp 200-205  J Quinlan and R Cameron-Jones FOIL A Midterm Report Proc European Conf on Machine Learning ECML'93 1993 pp 3-20  X Y in and J Han CP AR Classi\002cation based on Predicti v e Association Rules Proc 3rd SIAM Intl Conf on Data Mining SDM'03 San Francisco CA SIAM 2003 pp 369-376  C Cortes and V  V apnik Support-V ector Netw orks  in Machine Learning vol 20 no 3 1995 pp 273-297 
690 


Figure 3 Precision-recall curve in ROI-250 image dataset 5.3 Experiment 3 Mammograms-1080 image dataset This experiment employed a dataset composed by 1080 mammograms images collected in the Clinical Hospital of University of Sao Paulo at Ribeiro Preto The dataset was previously classi\002ed into 4 levels of breast tissue density 0501\051 mostly fatty 050362 images\051 0502\051 partly fatty 050446 images\051 0503\051 partly dense 050200 images\051 and 0504\051 mostly dense 05072 images\051 Figure 4 Precision-recall curve in Mammography-1080 image dataset Breast density is an important risk factor in the development of breast cancer In this experiment the images are represented by the feature set proposed in b uilding a vector of 85 features including shape and size of the breast the conditions of the breast contour nipple position and the distribution of 002broglandular tissue This dataset was divided in training set and test set The training set is composed of 720 images and test set is composed of 360 images Figure 4 shows the P&R curves over test dataset and also the number of features selected in each method Again the proposed methods reached the highest values of precision and select the smallest number of features 050a\051 050b\051 050c\051 050d\051 Figure 5 Queries in Mammography dataset 050a\051 226 is the query image 050b\051 using the features selected through 002tness function F cB  050c\051 using the features selected through classi\002cation error of C4.5 and 050d\051 using the all features extracted Results for the retrieval of the 5 most similar images from a query image are also provided in this experiment as illustrated in Figure 5 The image 5.\050a\051 is the query image taken from the mostly fatty image class Images shown in 5.\050b\051 are the 5 most similar images retrieved for the proposed 002tness function F cB  The row 050c\051 shows the results for C 4  5 classi\002er whereas 050d\051 illustrate the images resulting from all features 050no selection applied\051 In Figure 5 the images surrounded by dashed lines are false positives 050not relevant images\051 For this query the proposed method achieved the highest precision 050100%\051 when compared the results of C4.5 and the original feature vector 050precision of 40%\051 


6 Conclusions This work proposed a novel genetic feature selection framework for CBIRs It employs a wrapper strategy that searches for the best reduced feature set while optimizing 050or preserving\051 the quality of the solution From a ranking evaluation function three new 002tness functions namely F cA  F cB and F c have been proposed and evaluated in three experiments The proposed genetic feature selection approach which encompasses F cA  F cB and F c  has been compared with 050a\051 traditional methods found in the literature 050b\051 the StARMiner feature selector and 050c\051 the whole feature vector and signi\002cantly outperformed them The proposed approach has been able to optimize the accuracy of similarity queries while selecting a signi\002catively reduced number of features Additionally the proposal of combining the quality of the query results with the criterion of minimizing the number of selected features F cA and F cB  led to high accurate query answers while reducing the number of features more than the 002tness function F c  Therefore the 002nal processing cost of the queries is also reduced References  P  M d Aze v edo-Marques N A Rosa A J M T raina C Traina-Jr S K Kinoshita and R M Rangayyan Reducing the semantic gap in content-based image retrieval in mammography with relevance feedback and inclusion of expert knowledge International Journal of Computer Assisted Radiology and Surgery  3\0501-2\051:123\226130 June 2008  R Baeza-Y ates and B Ribeiro-Neto Modern Information Retrieval  Addison-Wesley Essex UK 1999  B Bartell G Cottrell and R Bele w  Optimizing similar ity using multi-query relevance Journal of the American Society for Information Science  49:742\226761 1998  O Cord 264 on E Herrera-Viedma C L 264 opez-Puljalte M Luque and C Zarco A review on the application of evolutionary computation to information retrieval International Journal of Approximate Reasoning  34:241\226264 July 2003  J G Dy  C E Brodle y  A Kak L S Broderick and A M Aisen Unsupervised feature selection applied to content-based retrieval of lung images IEEE Transactions on Pattern Analysis and Machine Intelligence  25\0503\051:373\226 378 March 2003  W  F an E A F ox P  P athak and H W u The ef fects of 002tness functions on genetic programming-based ranking discovery for web search Journal of the American Society for Information Science and Technology  55\0507\051:628\226636 2004  W  F an P  P athak and M Zhou Genet ic-based approaches in ranking function discovery and optimization in information retrieval a framework Decision Support Systems  2009  D E Golber g Genetic algorithms in search optimization and machine learning  Addison Wesley 1989  R L Haupt and S E Haupt Practical Genetic Algorithms  John Wiley  Sons New Jersey United States second edition edition 2004  J Horng and C Y eh Applying genetic algorit hms to query optimization in document retrieval Information Processing  Management  36:737\226759 2000  S K Kinoshita P  M d Aze v edo-Ma rques R R PereiraJr J A H Rodrigues and R M Rangayyan Contentbased retrieval of mammograms using visual features related to breast density patterns Journal of Digital Imaging  20\0502\051:172\226190 June 2007  F  K orn B P agel and C F aloutsos On the  dimensionality curse and the self-similarity blessing IEEE Trans on Knowledge and Data Engineering  13\0501\051:96\226111 2001  H Liu and L Y u T o w ard inte grating feature select ion algorithms for classi\002cation and clustering IEEE Transactions on Knowledge and Data Enginnering  17\0504\051:491\226502 April 2005  M X Ribeiro A J M T raina C T raina-Jr  and P  M Azevedo-Marques An association rule-based method to support medical image diagnosis with ef\002ciency IEEE Transactions on Multimedia  10\0502\051:277\226285 2008  U S Cancer Statistics W orking Group United states cancer statistics 1999-2005 incidence and mortality webbased report atlanta 050ga\051 Department of health and human services centers for disease control and prevention and national cancer institute 2009 Available in http://apps.nccd.cdc.gov/uscs   L T amine C C and M Boughanem Multiple query evaluation based on an enhanced geneticnext term algorithm Information Processing  Management  39\0502\051:215\226 231 2003  R S T orres A X  F alc 230 ao M A Gonc\270alves J P Papa Z B W Fan and E A Fox A genetic programming framework for content-based image retrieval Journal of the American Society for Information Science and Technology  42\0502\051:283\226292 2009  A Tsymbal P  Cunningham M P echenizkiy  and S Puuronen Search strategies for ensemble feature selection in medical diagnostics In Proceedings of the 16th IEEE Symposium on Computer-Based Medical Systems  pages 124\226 129 June 2003  A Tsymbal M Pechenizkiy  and P  Cunningham Sequential genetic search for ensemble feature selection In Proceedings of the International Joint Conferences on Arti\002cial Intelligence  pages 877\226882 August 2005  C.-M W ang a and Y F  Huang Ev olutionary-based feature selection approaches with new criteria for data mining A case study of credit approval data Expert Systems with Applications  36\0503 Part 2\051:5900\2265908 2009  H Y an J Zheng Y  Jiang C Peng and S Xiao Selecting critical clinical features for heart diseases diagnosis with a real-coded genetic algorithm Applied Soft Computing  8:1105\2261111 2008  T  Zhao J Lu Y  Zhang and Q Xiao Feature selection based on genetic algorithm for cbir In IEEE Congress on Image and Signal Processing  volume 2 pages 495\226499 2008 


     Figure 9. Argumentation Tree For Open GL  A1 The current system in flash does not have the functionality of dynamic allocation of particles like mine or clutter. It places them randomly  A1.1 That is not of much importance because it still gives a new position to mine and clutter particles A2 Current system in flash has faster response time as compared to system in Adobe Director A3 The current system doesnêt satisfy many of the features required for the new system like database A4 Adobe Flash cannot communicate with database A4.1 Flash doesnêt support database but database support is very important and critical A4.1.1 The system should be able to generate evaluation reports for trainee based on pr evious records stored in the database A5 Flash doesnêt create sound clips  A5.1 We donêt need sound creating features as the sys tem has to generate sound. We can play externally recorded sound files using Adobe Flash A6 Flash can provide good visual effects as compared to Adobe Director A7 The developer has good knowledge in development using Flash so the system can be developed quickly B1 We could reuse the system already developed for sound generation, as it is developed using Adobe Audition for analysis which is somehow related to Adobe Director B1.1 The current system is better synthesized in terms of sound production and the sound produced is also instantaneous rather than discrete B1.2 That current system has certain performance issues like slow response time B1.3 The current system in Adobe Director has the feature of producing dynamic coloring scheme on approaching a mine. This kind of scheme is highly preferable and is not present in Adobe Flash system B2 Adobe Director can provide more functionality as compared to the current flash system. E.g. Multiple sounds while detecting mines   B2.1 Adobe Director can provide better visual effects as compared to flash e.g. in case of GUIês   B2.2 A modified version of the current system in flash can also provide the same functionality B2.2.1 We cannot integrate code developed in other platforms with Flash, but Flash can be integrated in Adobe Director B3 The interface provided by flash is not professional enough. It is too simple and straight forward for doing more things in future   B4 Easily available plug-ins can help integrate the tracking system developed in C# with Adobe Director  B4.1 Code developed in Open GL/AL can also be integrated using Adobe Director using suitable stubs   B5 A new sound recognition algorithm is being developed in Adobe Audition which can be integrated with Adobe Director but not with Open GL or Flash Evidence supported B6 If the current system is reused; the project deadline can be met easily B7 The developer has very little experience in development using Adobe Director   B7.1 The developer can take help from the already developed system in Adobe Director C1 The tracking software already developed is coded in C#/NX5. We could reuse that and develop our system in Open GL/AL C1.1 Open GL has C# libraries which can be used to develop the system C2 Because the platform used is for high end application development, it can provide good GUI and database support C2.1 Open GL/AL can help us generate dynamic surfaces for mine detection and training which the original system in flash does not have C4 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C3 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C4 The time taken for developing the project using open GL will be comparatively more as the whole system would have to be developed from scratch C4.1 If Open GL has support for C# libraries, and then the system could be develope d faster as developer is quite familiar with programming languages like C 151 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        






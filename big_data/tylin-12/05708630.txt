An Approach to Privacy-Preserving Alert Correlation and Analysis Jin Ma, Xiu-zhen Chen, Jian-hua Li Electronic Information and El ectric Engineering School Shanghai Jiao Tong University Shanghai, China majin@sjtu.edu.cn Abstract Privacy issues are concerned when data holders share their detected security data for correlation and analysis purpose This paper proposes an approach to correlate and analyze intrusion alerts, while preserve privacy for alert holders. The raw intrusion alerts are protected by improved k-anonymity model which preserves the aler t regulation inside disturbed data records. With this privacy pr 
eserving technique, combing the typical FP-tree association rules mining algorithm, the approach provides the capacity of well ba lancing the alert correlation and the privacy preservation. Experimental results show that this approach works comparatively efficient and reaches a well balance between the alerts correlation and the privacy issues Keywords-privacy preserving; alert correlation; k-anonymity intrusion detection; frequent pattern I I NTRODUCTION Intrusion Detection Systems IDSs\widely deployed to defend against large-scale attacks and security threats. Existing IDSs, however, often trigger t oo ma  Moreover, the false alerts are mixed up with the true ones[1  making it more difficult to identify the real hidden attacks 
Alert correlation and analys is me have been investigated to get an in-depth insight into the threats and to build a higher level attack scenario across networks Meanwhile various communities such as organizations institutions and users are un willing to share their data for security analysis without pri vacy guarantees. Data holders have concerns that sharing detailed information will be at the risk of their own security, such as information around intranet topology structure, certai n services, and the security infrastructure deployment. Theref ore, privacy-preserving techniques are required in the process of IDS alerts correlation and analysis Existing privacy-preserving approaches usually 
perform transformation on origin al data to protect sensitive data before sharing and correlati  apply standard and keyed hash functions to ensure privacy for the sensitive attributes such as IP addresses. The approach is feasible even in large alert loads, wh ile it still has limitations in alerts correlation when usi ng different keys in keyed hashing  l hierarchy based approach to generalize original attributes to high-level concepts. The approach, however, is not easy to control the generalization process in complex circumstance. Xu and Ning also pr opose three methods to anonymize sensitive attributes of alerts and 
build attack scenarios. Their schemes include artificial alerts injection into original data se ts, attribute randomization and data set partitioning and randomization. But the correlation results will be highly influenced by the selection of parameters Therefore, a privacy-preserving correlation and analysis approach is proposed in this paper to discover efficient association rules among protected alert’s attributes. Within affordable calculation cost, it has been proved to be efficient to perform alert correlation and preserve sensitive attributes. The generated association rules can be used in operational IDSs to retrench intrusion events and react against attacks found Section 2 designs the framework for alert correlation and analysis with privacy-preserving capability. Section 3 proposes 
a privacy-preserving based alert correlation and analysis method. Section 4 shows experiments and performance comparison with classical alert correlation algorithm Conclusions and further work are shown in Section 5 II A LERT CORRELATION AND ANALYSIS FRAMEWORK WITH PRIVACY PRESERVING CAPABILITY Intrusion alert correlation and analysis closely rely on the collections of security data sets, which become sensitive when certain security or indi vidual information is involved. For instance, IP addresses and port numbers in IDS alerts might show intranet topology an d running services, which are considered sensitive for certain critical networks. These would 
also be the foundations for hackers to compromise the whole network step by step. In this section, a privacy-preserving alert correlation and analysis frame work is designed to obtain association rules among protect ed alert’s attributes for the purpose of alerts correlation The privacy-preserving alert correlatio n and analysis framework, which is shown in Fig. 1, is designed on the basis of the classical Common Intrusion Detection Framework CIDF h e external rectangle region represents the network domain relatively i ndependent to other ones. Detected intrusion alerts within this domain will be protected before being shared for security correla tion and analysis. Taking the different level of sensitivity of 
the variant attributes in the mining process of the alert correlation into account, kanonymity method[9 a cl assical privacy-preserving method, is improved to preserve the alert’s semantic as much as possible during the process of attributes anonymization With this improved privacy preserving method, combing the typical FP-tree association rules mining approach, the framework is set up Data and control flows among the components in the framework are denoted by the solid lines in Fig. 1. While the This research is funded by NFSC of China under grant number of 60702047 
2010 IEEE Asia-Pacific Services Computing Conference 978-0-7695-4305-5/10 $25.00 © 2010 IEEE DOI 10.1109/APSCC.2010.85 620 


 dashed line means the message shared for alerts correlation between network domains The whole framework is mainly composed of five components. The main components and their functions are given as follows  Data collector: to collect raw packets coming from the network and to provide them to analyzer for analysis Data collectors will be deployed in the nodes of high network flow, and amount of which depends on domain’s security policy  Data analyzer: to analyze collected data by means of pattern matching or other analysis methods to find intrusion events  Intrusion events da tabase: to store in trusion events and relevant datasets during the process of intrusion detection and analysis  Monitor: to supervise ru nning status of other components and to give reports to security administrator about security status  Privacy-preserving alert correlation and analysis agent to use a privacy preservation technique to protect the detected alert attributes before they are shared with the utility which are not je opardized. Afterwards, to perform alerts correlation and analysis algorithm to discover association rules or sequence patterns for explaining the global behavior of each attack, the result of which will be stored in intrusion events database and displayed on monitor component The work of this paper is to mainly focus on the marked area in Fig. 1. Experimental results have proved that this framework is valuable on global ly analyzing and ex plaining the data that IDS received with the consideration of sensitive attributes III P RIVACY PRESERVING BASED ALERT CORRELATION AND ANALYSIS APPROACH The goal of this section is to provide the privacy-preserving method for intrusion alerts, w ith the correlation and analysis process on the protected alert attributes, which can be described in the following two steps 002 A Step1:Protect sensitive alert attributes by the improved kanonymity method Privacy-preserving techniques such as data perturbation and data modification, are widel y developed and used in the area of data mining and knowle dge discovery in databases[11  tics of intrusion alerts correlation, k-anonymity met hod, a classical privacypreserving method, is improved to preserve the alert regulation inside disturbed data records Classical k-anonymity model uses the term quasi-identifier to help judging whether kanonymity properties are met. In the situation of protecting sensitive attributes in intru sion alerts, the sensitive fields are what we exactly care about for the purpose of protecting privacy, regardless of the quasi-identifier Before going into the details of the method proposed, some notions and definitions are clarified first Definition 1 Attributes Let AL\(A 1 A n  be an alerts set with a finite number of security alerts. The finite set of attributes of AL are A 1 A n   Definition 2 k-anonymity Let AL\(A 1 A n  be an alerts set and SD\(A i A j  be a set of sensitive attributes to be protected, and A i A j  002 A 1 A n   AL satisfies k-anonymity if and only if each sequence of values in SD appears with at least k occurrences in AL[SD  Let OA\(A 1 A n  be an original alerts set, the k-anonymity method is used for the selective modification of sensitive attributes in SD with all the other attributes remain unchanged The discrete values of sensitive alert attributes in OA are replaced by their generalization values which are predefined according to domain’s security policy. Uncertainty is introduced into alerts set but with semantics for preserving alerts regulation B Step2:Alert correlation and analysis method Frequent pattern mining technique[1  is highly suitable for alert analysis with the abili ty of deriving frequent itemsets and association rules. Especially, algorithm FP-Tree is good at efficient mining of frequent patterns in large database, which applying a compressed, frequent pattern tree FP-Tree structure for mining frequent patterns w ithout candidate generation. The FP-Tree algorithm mainly incl udes the following two algorithms: FP-Tree construction and FP-Growth   Emphasis will be put on met hod of mining association rules among protected alert’s attributes for retrenching and filtering intrusion events Figure 1. Alert Correlation Framework with Privacy-preserving Capability 
621 


The pseudo-code for privacy-preserving based alert correlation and analysis algorithm is given in Fig. 2. Some notations used in the algorithm are described as follows  VGH is a value generalization function for sensitive attributes  AL\(A 1 A Ng  is the protected intrusion alerts set of OA   All intrusion alerts share the same attribute vector date starttime, endtime, protocol, source IP address destination IP address, source port number destination port number, attackname IV E XPERIMENTAL R ESULTS In this section, we demonstrate a comparison of the approach this paper proposed w ith the classical association rules mining algorithm FP-tr ee without privacy-preserving capability. An intranet environmen t is constructed for the experiments which deploys 4 application servers \(Database Figure2. Privacy-preserving Based Aler t Correlation and Analysis Algorithm server, WEB server, FTP server and DNS server\and  of ou r intranet. To validate the effectiveness and scalability of our approach intrusion alerts are collected from SNORT deployed in the intranet. Table 1 summarizes the numbers and types of the alerts 4.1 Effectiveness A set of experiments is designed to evaluate the privacy of the attributes to be protected and the effectiveness of the alert association rules to discover before and after the privacy preserving method is applied Table 2A shows some of the intrusion alerts generated by the SNORT in the intranet. The example of association rule among these original alert attr ibutes finally discovered is given in Table 2B In the experiment, d_IP \(destina tion IP address\d_port destination port number the sensitive attributes Transformations are made to these attributes by the improved k-anonymity method, which are generalized to their more general values with most semantics. Therefore, sensitive attributes in original alerts are protected as Table 3A shows We can get the association rule that describes the same security information as classical FP-tree al gorithm discovers, which is shown in Table 3B The association rules discovery result comparison between our approach and classical FP-tree algorithm is illustrated in Table 4, which indicates high retrench ration on intrusion alerts of our approach TABLE 1 O RIGINAL I NTRUSION A LERTS IN E XPERIMENT Types of Intrusion Alerts Numbers of Alerts before Correlation MS-SQL Worm propagation attempt 4 HTTP ActiveX 1 ICMP PING 278 ICMP Echo Reply 115 ICMP Destination Unreachable Port Unreachable 266 WEB-MISC HTTP Dir ectory traversal 5 WEB-IIS Nsiislog.dll Access 2 MS-SQL version overflow attempt 1 BLEEDING-EDGE MS-SQL DOS Bouncing packets 4 TFTP Get 1 Port Scan 307 DNS Named Version Attempt 19 Input Original intrusion alerts set OA\(A 1 A n  set of sensitive attributes SD\(A i A j  k constraint; a minimum support threshold min-sup Output Association rules Assumes Consider each intrusion event as a transaction T  OA  003 k Method 1 for all sensitive attributes A i in SD do 2 VGH\(A i  generalizations of A i according to the security policy of th e organization 3 end for 4 for each alert in OA do 5: each A i over SD VGH\(A i  6 end for 7 AL\(A 1 A Ng     VGH\(OA with satisfation of k constraint 8: Support\(\Count_items\(\mset is built, and the support of each item is calculated 9 for each alert in AL do 10 for each item in an alert do 11  if Support min-sup then 12 add this item and its support into F  F is the list of frequent items 13  end if 14 end for 15 end for 16 FList Sort_supportdescending F rt F in support-descending order as FList 17 for each T in AL 18 Sort_item T rdered frequent items of T 19:          FP-tree:= FP-Tree_construction T  20 end for 21 002 FP-Growth\(FP-tree, null\r the set of frequent itemsets in the transaction database 22: Get association rules between attributes of alerts from 002  
622 


4.2 Scalability The runtime of our approach and classical FP-tree algorithm on 1000 experimental alerts with k 2 as the min-sup changes is shown in Fig. 3 In the experiment, classical FP-tree algorithm is only around 10% faster than our approach on discovering association rules among those alert attributes in average, which is easy to understand because our approach protects sensitive attributes in original alerts. As the min-sup is high, the set of frequent itemsets is not compara tively large, so the gap becomes even smaller. However, when the min-sup is small enough, our approach’s time cost is at the advantage because of the short list of frequent items in its generalization, which makes sensitive attributes actually different appear equal Fig. 4 shows the scalability of the two methods based on different number of intrusi on alerts. It illustrates the linear increase of runtime verses the number of alerts. Our approach gets the better runtime perfo rmance out of the same reason with small min-sup  V C ONCLUSIONS AND F UTURE W ORK Alert correlation and analysis is a key part in intrusion T ABLE 2 A E XAMPLE OF SNORT A LERTS T ABLE 2 B A SSOCIATION R ULE D ISCOVERED FROM O RIGINAL A LERTS date start_time end_time proto col s_IP d_IP s_port d_port attack_name 30.07.2010 14:20:45 16:00:20 TCP 172.020.026.061 192.168.13.253 51129 21 Port scan 30.07.2010 14:22:16 16:00:24 TCP 172.020.149.061 192.168.13.253 48914 80 Port scan 30.07.2010 14:23:33 16:00:24 TCP 172.020.149.061 192.168.13.253 52382 22 Port scan 30.07.2010 14:25:50 16:00:24 TCP 172.020.149.061 192.168.13.253 36343 25 Port scan If d_IP=192.168.13.253 and s_IP=172.020.149.061 then attack_name Port scan, support=30.6%, confidence=92.3 T ABLE 3 A E XAMPLE OF P ROTECTED SNORT A LERTS  K 2 date start_time end_time proto col s_IP d_IP s_port d_port attack_name 30.07.2010 14:20:45 16:00:20 TCP 172.020.026.061 192.168.13.* 51129 2 Port scan 30.07.2010 14:22:16 16:00:24 TCP 172.020.149.061 192.168.13.* 48914  Port scan 30.07.2010 14:23:33 16:00:24 TCP 172.020.149.061 192.168.13.* 52382 2 Port scan 30.07.2010 14:25:50 16:00:24 TCP 172.020.149.061 192.168.13.* 36343  Port scan T ABLE 3 B A SSOCIATION R ULE D ISCOVERED FROM P ROTECTED A LERTS If d_IP=192.168.13.* and s_IP 172.020.149.061 then attack_name=Por t scan, support=30.6%, confidence=92.3 Indexes Classical FP-tree Algorithm Our Approach Alerts Number before Correlation 1003 1003 Alerts Number after Correlation 287 243 Retrench ratio of Alerts 3.49:1 4.13:1 Alerts Type before Correlation 12 12 Alerts Type after Correlation 9 7 000\023 000\024\000\023\000\023 000\025\000\023\000\023 000\026\000\023\000\023 000\027\000\023\000\023 000\030\000\023\000\023 000\031\000\023\000\023 000\032\000\023\000\023 000\033\000\023\000\023 000\024\000\025\000\026\000\027\000\030\000\031\000\032\000\033 000P\000L\000Q\000\020\000V\000X\000S 000\003\000R\000I\000\003\000D\000O\000H\000U\000W\000\003\000D\000W\000W\000U\000L\000E\000X\000W\000H\000V 000\013\000\010\000\014 0005\000X\000Q\000W\000L\000P\000H\000\013\000P\000V\000\014 000&\000O\000D\000V\000V\000F\000L\000D\000O\000\003\000 0002\000X\000U\000\003\000D\000S\000S\000U\000R\000D\000F\000K Figure 3. Scalability with mins up over experimental alerts set T ABLE 4R ESULTS C OMPARISON  K 2 000\023 000\024\000\023\000\023 000\025\000\023\000\023 000\026\000\023\000\023 000\027\000\023\000\023 000\030\000\023\000\023 000\031\000\023\000\023 000\032\000\023\000\023 000\033\000\023\000\023 000\024\000\023\000\023 000\025\000\023\000\023 000\026\000\023\000\023 000\027\000\023\000\023 000\030\000\023\000\023 000\031\000\023\000\023 000\032\000\023\000\023 000\033\000\023\000\023 000\034\000\023\000\023 000\024\000\023\000\023\000\023 0001\000X\000P\000E\000H\000U\000\003\000R\000I\000\003\000$\000O\000H\000U\000W\000V 0005\000X\000Q\000W\000L\000P\000H\000\013\000P\000V\000\014 000&\000O\000D\000V\000V\000L\000F\000D\000O\000\003\000 000W\000U\000H\000H\000\013\000\023\000\021\000\023\000\024\000\010\000\014 0002\000X\000U\000\003\000D\000S\000S\000U\000R\000D\000F\000K\000\013\000\023\000\021\000\023\000\024\000\010\000\014 Figure 4 Scalability with Number of Intrusion Alerts 
623 


detection field. Privacy guarantees will accelerate the research developments in the according area, and make it more feasible This paper proposes the priv acy-preserving approach to correlate and analyze the intrusion alerts without the risk of sensitive information disclosu re during the process. The approach is proved to be effectiv e in utility with a favorite retrench ratio of alerts and affordable performance over massive intrusion alerts. An open question is that which causes a greater impact on the effectiveness of alert correlation: the number of attributes that is being anonymized or the privacypreserving algorithm that is being applied. In addition, the association rules with low support and low confidence are also useful for intrusion analysis. Therefore, personality mining is a future research direction worth researching R EFERENCES   H. De bar and A W e s p i Aggregation and correlation of intrusion-detection alerts 2001: Springer   A. Valdes and K. S k inner Probabilistic alert correlation Google Patents. 2001  F. Valeur G Vigna C. Kruegel and R. Ke mm erer A comprehensive approach to in trusion detection alert correlation IEEE Transactions on dependable and secure computing, 2004: pp. 146-169   C. Clif ton and G. Ge ng o Developing custom intrusion detection filters using data mining 2000 Citeseer   P. Lincoln, P Porras and V. Shm atikov  Privacypreserving sharing and correction of security alerts  2004: USENIX Association   D. Xu and P. Ning Privacy-preserving alert correlation: a concept hi erarchy based approach   D. X u and P   Ning A flexible approach to intrusion alert anonymization and correlation 2007: IEEE 8 C. Kahn P. Porras, S. Stan iford Ch en an d B. Tun g   A common intrusion detection framework Submitted to Journal of Computer Security, 1998   G. Ag garwal T Fede r, K  K e nthapadi R Motwani R Panigrahy, D. Thomas, and A. Zhu Approximation algorithms for k-anonymity Journal of Privacy Technology, 2005 2005112001   L Swee ney k-anonymity: A model for protecting privacy International Journal of Uncertainty Fuzziness and Knowledge Based Systems, 2002 10 5\p. 557-570   V. Ve rykios E. Bertino, I  Fovino, L Pr ovenza Y Saygin and Y. Theodoridis State-of-the-art in privacy preserving data mining ACM Sigmod Record, 2004 33 1\50-57   J. W a ng Y Luo, Y Zhao and J. Le A survey on privacy preserving data mining 2009: IEEE   J. Han, H  Cheng, D. Xin and X Yan  Frequent pattern mining: current st atus and future directions Data Mining and Knowledge Discovery, 2007 15 1 pp. 55-86   J. Han J. Pei Y Yin a nd R Mao Mining frequent patterns without candidat e generation: A frequentpattern tree approach Data mining and knowledge discovery, 2004 8 1\ 53-87  M Roesch Snort-lightweight in trusion detection for networks 1999: Seattle Washington 
624 


6 Dimensions and Facts Identifier This is the first subcomponent of the schema generator In the generatio n process of schema the first important step is the identification of dimensions and facts from the clu stered data For this important purpose the data in the sc hema generator goes to the Dimension and facts identifie r, which identifies the dimensions and facts present in the clustered data. It also identifies the cluster hierarchy and the numeric type of data which are the facts or key performance  indicators of the data Dimensions and Facts Separator The identifier component just identifies the various dimension and facts pre sent in the clustered data But in real life the dimension and the facts are to be separated in order to build the schema F or this purpose the Dimension and facts separator splits the identified dimensions and facts to be used for diff erent types of schema generation Schema Type Selector At the stage when dimensions and facts are identified and separated the Schema type selector component handles the designing of a specific type of schema This selector allows the selection of a par ticular type of schema which can be a star, snowflake or ga laxy Warehouse Builder After determining the schema type to be generated the dimensions and facts along with th e specific schema type goes in to another major and c ore unit of schema builder which is called the warehouse bui lder The warehouse builder as its name implies builds a warehouse of a particular schema type and consists of the following main sub-components. The functionality of each of the component in the warehouse builder is descri bed below Dimensional hierarchy handler It is the first component of the warehouse builder and it serves the purpose of handling the hierarchy in the dimensions As the clustered d ata has its own hierarchy and the dimensional data identifi ed and separated previously have to be in some hierarchica l order within each dimension The dimensional hierarchy is  different for different type of schemas that is why  this handler component handles the hierarchy present wit hin each dimension Dimension and fact table creator Because the warehouse builder automatically creates a warehouse in the fo rm of a database so the creation of the dimension and fact table is a must For this reason the dimension and fact table creator takes dimensional hierarchy from the previous compo nent and the facts separated by the separator component and create the tables according to the specific schema type Within each table created for a dimension the hiera rchy structure is determined and created using the hiera rchy handler output, which is different for each type of schema Table relationship manager For each type of schema the referencing of dimension and fact table is differen t. For star schema the dimensions are connected directly In Snowflake schema there exists a normalized relation ship between the dimensions whereas for Galaxy both type s of relationships are being made. To handle this comple xity of relationship among dimension and fact tables create d by the warehouse builder for a specific schema type the t able relationship manager plays its part and manages all kind of relationships among the tables accordingly Data population unit When all the tables are created along with the hierarchy within each dimension and the relationship is being created among the dimensions and fact tables, the data population unit comes into play. T he role of this unit is to load the clustered data in the sche ma intelligently Therefore this unit picks the clust ered data and inserts it in specific columns of the dimension and fact tables so that this data can be used later for the OLAP operations Schema Viewer This component takes the generated schema from the schema generator and gives the view  of the automatically generated schema in the form of s chema diagram IV IMPLEMENTATION AND EXPERIMENTAL DETAILS In this section, based on our implementation, we di scuss in details the steps involved in the implementation of  the proposed model Some tools and technologies have be en used for the implementation of each layer of the pr oposed model. Each step of the implementation phase is dis cussed individually in the following sub sections with the  help of an experiment For the experimental purpose ForestCoverType 23 d a t a  set has been chosen. This data set has 581,012 numb ers of instances and 54 attributes. The attribute breakdow n shows that it has 12 measures or facts with 54 columns of data from which 10 are quantitative variables 4 are bin ary wilderness areas and 40 binary soil type variables  The main purpose of the experiment is to demonstrate th e ability of using the proposed model with a real life data s et A Hierarchical clustering of data The proposed model starts with the layer of data mi ning and the technique used for data mining is the hierarchi cal clustering The first step of the implementation is  the hierarchical clustering of data. To serve the purpo se of step 1, we used Hierarchal Clustering Explorer \(HCE\ too l [24  for generating the hierarchical clusters of data T his tool takes input data file and allows the hierarchical c lustering of given data based on different clustering paramet ers At this point user can select the parameters of his/h er choice to perform specific type of hierarchical clustering  on the data Upon the selection of clustering parameters the data as a result is hierarchically clustered and the hi erarchy details are shown in the HCE tool We fed the ForestCoverType data set to the Hierarchical Clustering Explorer \(HCE\ tool. Various parameters can be set at this stage A visualization map of the 40 


7 ForestCoverType  data is shown in Figure 6 Appendix as an example The tool takes this data as input and produces the hierarchical clusters of data by setting different clustering parameters With the help of this tool user can see  the generated hierarchy of the clusters along with the data present in each cluster. For the experiment we sele cted the row wise clustering option and the algorithm used f or this type of clustering was the Euclidean algorithm. The reason for this choice is that Euclidean distance is the m ost commonly used type of distance measure in cluster analysis It uses raw data instead of standardized data to compute the distances Using the complete linkage method the hierarchal clusters are produced, it can be seen from the Figu re 2 that 3 distinct clusters are produced where each one of them is having its specific hierarchy B Automatic Schema generation In this step the cluster results file which was ex ported using the HCE tool becomes the input of the automat ic schema builder. We developed a prototype to automat e the process of schema generation The prototype takes t he clustered data and generates the schema of any part icular type such as star snowflake or galaxy/constellatio n The prototype has been developed using the C sharp C  programming language in Microsoft Visual Studio.net 2005 Once the hierarchical clustering has been done, the  next step is to extract this hierarchical information in the form of cluster information tables which are fed into the d eveloped prototype called Automatic Schema Generator Figure  3 depicts the main interface of the Automatic Schema Generator having the clustered relationship data C luster names are the abbreviations which are formed using the first letters of each cover type for example clus ter name for C1 is PCD, which means cover types of Ponderosa pine Cottonwood and Douglas-fir PCD All other names are abbreviated by using the first alphabetical letters  After reading the cluster relationship file the bu tton of Create Schema as shown in the following diagram displays the schema selection window. Figure 4 show s the schema selection window of automatic schema builder  Using this selector window cluster name and type o f schema can be selected to build database in the dat abase server. User can select from star, snowflake and ga laxy or constellation options of schema type using the radi o button The “Generate” button on the bottom of schema selec tor window performs the following major functions 1\Generates automatic database in the database serv er 2\Creates dimension and fact tables for the schema type selected 3\Manage relationships among the tables 4\Upload data in the fact and dimension tables from the clustered file After performing the above mentioned functions the  control is passed to the schema visualization windo w which gives a glimpse of the schema created automatically  as shown in Figure 5  Fig 2: Hierarchical clusters generated by HCE tool Fig 3 User interface of automatic schema builder Fig 4 Schema Selector window 41 


Fig 5 Schema visualization window V CONCLUSION AND FUTURE WORK In this paper we reviewed the literature regarding  the integration of OLAP with data mining and automatic generation of OLAP schema. Literature review reveal ed the fact that none of the previous works targeted at th e automatic schema generation from the mined data set  Furthermore the works in the past pose a number of limitations. The major limitation of the previous w ork was the absence of a model that can produce the three b asic types of OLAP schema star, snowflake and galaxy Based on these observations we presented the model for th e integration of data mining and OLAP along with the automatic generation of OLAP schema. We have develop ed a prototype for the automatic schema generation Th is developed prototype takes mined data and produces t he schema of user’s choice Finally we implemented the  proposed model and evaluated the results with the h elp of experiment It is evident from the result that the prototype system overcomes the manual schema design and implementation requirement in the data warehousing environment We are working on the enhancement of t he proposed model for automatic schema generation One  possible way of enhancement is the use of other dat a mining techniques along with OLAP for the schema generation. Further more, we are exploring how OLAP can be further extended and enhanced to meet the new challenges and to make it more effective efficient  and intelligent OLAP REFERENCES 1  S   C h a u d h u r i  a n d  U   D a y a l   A n  o v e r v i e w  o f  d a t a  warehousing and OLAP technology ACM SIGMOD Record  Vol 26 1997\, pp 6574 2  A   C u z z o c r e a   D   S a c c a  a n d  P   S e r a f i n o   A  h i e r a rchy driven compression technique for advanced OLAP visualizati on of multidimensional data cubes in Proc of 8th Int’l Conf on Data Warehousing and Knowledge Discovery \(DaWak Springer Verlag 2006\, pp. 106-119 3  S   M a n s m a n n  a n d  M   S c h o l l   E x p l o r i n g  O L A P  a g g r e gates with hierarchical visualization techniques, in Proc. of ACM Symposium on Applied Computing 2007\, pp. 1067-1073 4  F a y y a d  U  M   P i a t e s k y S h a p i n o  G    S m y t h  P   a n d  U thurusany R From datamining to knowledge discovery: An overvie w,”in Proc. of Advances in data mining and knowledge discovery MIT Press, pp. 134 5   S   G o i l  a n d  A   C h o u d h a r y    H i g h  p e r f o r m a n c e  O L AP and data mining on parallel computers Data Mining and Knowledge Discovery vol. 1, no. 4, pp. 391-417, Dec. 1997 6   S   A s g h a r   D   A l a h a k o o n  a n d  A   H s u    E n h a n c i n g  OLAP functionality using selforganizing neural networks  Neural, Parallel and Scientific Computations vol. 12, no. 1, pp. 1-20, March 2004 7   R   B   M e s s a o u d   O   B o u s s a i d  a n d  S   R a b a s e d a    A new OLAP aggregation based on the AHC technique,” in Proc. of the 7th ACM Int’l Workshop on Data Warehousing and OLAP DOLAP ACM New York, 2004, pp. 65-72 8   J   H a n    T o w a r d s  o n l i n e  a n a l y t i c a l  m i n i n g  i n  l arge databases ACM SIGMOD Record vol. 27, no. 1, pp. 97-107, March 1998 9   V   M a r k l   F   R a m a s a k  a n d  R   B a y e r    I m p r o v i n g  OLAP performance by multidimensional hierarchical clustering in Proc of the 1999 Int’l Symposium on Database Engineering and Applica tions IDEAS 1999, p. 165 10   V   M a r k l  a n d  R   B a y e r    P r o c e s s i n g  r e l a t i o n a l  OLAP queries with UB-trees and multidimensional hierarchical clusteri ng in Proc of the Int’l. Workshop on Design and Management of Dat a Warehouses DMDW\, 2000, pp. 1-10 11   N   K a r a y a n n i d i s   T   S e l l i s  a n d  Y   K o u v a r a s    CUBE file A file structure for hierarchically clustered OLAP cubes  Advances in Database Technology LNCS Springer Verlag Berlin-Heidelberg pp. 621-638, 2004 12   D   T h e o d o r a t o s  a n d  A   T s o i s    H e u r i s t i c  o p t i m ization of OLAP queries in multidimensionally hierarchically cluste red databases,” in Proc of the 4th ACM Int’l Workshop on Data Warehou sing and OLAP DOLAP\, ACM New York, 2001, pp. 48-55 13   K   H a n n   C   S a p i a  a n d  M   B a l a s c h k a    A u t o m a t i cally generating OLAP schemata from conceptual graphical models,” in  Proc. of the 3rd ACM Int’l Workshop on Data Warehousing and OLAP  DOLAP ACM New York, 2000, pp. 9-16 14   V   P e r a l t a   A   M a r o t t a  a n d  R   R u g g i a    T o w a r d s the automation of data warehouse design Technical Report TR-03-09 InCo Universidad de la República, Montevideo, Uruguay, J une 2003 15   N   T r y f o n a   F   B u s b o r g  a n d  J   G   B   C h r i s t i a n sen StarER A conceptual model for data warehouse design,” Proc of the 2nd ACM Int’l. Workshop on Dataarehousing and OLAP \(DOLAP ACM New York, 1999, pp. 3-8 16   Y   S o n g   e t   a l     S A M S T A R   A n  a u t o m a t i c  t o o l for generating star schemas from an entity-relationship diagram in Proc of the 27th Int’l. Conf. on Conceptual Modeling LNCS 2008, pp. 522-523 17   S   R   M a d d i  a n d  V   K h a n    C o m p a r a t i v e  a n a l y s i s of on-line analytical processing tools,” University essay from IT-uni versitetet I Göteborg, Sweden 2007 18   H   Z h u    O n l i n e  a n a l y t i c a l  m i n i n g  o f  a s s o c i a t ion rules Master Thesis, Simon Fraser University, 1998, pp. 1-117 19   J   F o n g   H   K   W o n g  a n d  A   F o n g    O n l i n e  a n a l ytical mining Webpages tick sequences J. of Data Warehousing vol. 5, no. 4, pp. 5967, 2000 20   S   D z e r o s k i   D   H r i s t o v s k i  a n d  B   P e t e r l i n    Using data mining and OLAP to discover patterns in a database of patients  with Y chromosome deletions,” in Proc. AMIA Symp 2000, pp. 215–219 21  F   D e h n e   T   E a v i s  a n d  A   R a u C h a p l i n    C o a r s e grained parallel online analytical processing OLAP for data mining in Proc of the Int’l Conf. on Computational Science ICCS\, 2001, 589-598 22   J   H a n   S   H   S   C h e e  a n d  J   Y   C h i a n g    I s s u es for on-line analytical mining of data warehouses,” in Proc. of the SIGMOND Workshop on Research Issues on Data Mining and Knowledge Discov ery DMKD\, Seattle, 1998, pp. 2:1-2:5 23   J   A   B l a c k a r d   D   J   D e a n  a n d  C   W   A n d e r s o n  Forest cover type The UCI KDD Archive http://kdd.ics.uci.edu   I r v i n e CA University of California Department of Information  and Computer Science \(1998 24   J   S e o   e t   a l     I n t e r a c t i v e  c o l o r  m o s a i c  a n d dendrogram displays for signal/noise optimization in microarray data analys is,” in Proc. of the Intl. Conf. on Multimedia and Expo-Volume 3 2003, pp. 461-464 42 


9 Appendix Fig 6: Forest Cover Types of the U.S. \(Source. USGS National Atlas of US Summary of Forest Cover Type Data Type Multivariate Abstract The forest cover type for 30 x 30 meter cells obtai ned from US Forest Service \(USFS\ Region 2 Resource Information System RIS\ data Data Characteristics The actual forest cover type for a given observatio n \(30 x 30 meter cell\ was determined from US Fores t Service \(USFS\ Region 2 Resource Information System RIS data Independe nt variables were derived from data originally obta ined from US Geological Survey \(USGS\ and USFS data. Data is in raw form \(not scaled\ and contains binary \(0 or 1 columns of data for qualitative independent variables \(wilderness areas and soil types Summary Statistics Number of instances observations 581012 Number of Attributes 54 Attribute breakdown 12 measures, but 54 columns of data \(10 quantitativ e variables, 4 binary wilderness areas and 40 binary soil type variables Missing Attribute Values None 43 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        






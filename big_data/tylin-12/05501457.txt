A Comparative Study Of Inference Engines Swapna Singh, Ragini Karwayun U.P.T.U.Lucknow  Inderprastha Engineering College Ghaziabad, India singhswapna@yahoo.com, raginik22@gmail.com    Abstract  Understanding and using the data and knowledge encoded in semantic web documents requires an inference engine. Inference engines, also called reasoners, are software applications that derive new facts or associations from existing information. Inference and inference rules allow for deriving new data from data that is already known. Thus, new pieces of knowledge can be added based on previous ones. By creating a 
model of the information and relationships, we enable reasoners to draw logical conclusions based on the model. The use of inference engines in the semantic web allows applications to inquire why a particular conclusion has been reached, i.e. semantic applications can give proof of their conclusions. Proof traces or explains the steps involved in logical reasoning.  This paper is a survey and study work which presents a comparison of different types of inference engines in context of semantic web. It will enable to differentiate among different types of inference engines which may be beneficial to realize the various proposed prototype 
systems with different ideas and views on what an inference engine for semantic web should do Key Words:  Inference Engine, Knowledge Representation Logical Reasoning, Semantic Web I  I NTRODUCTION  The inference engine can be described as a form of finite state machine with a cycle consisting of three action states match rules, select rules, and execute rules. In the first state match rules, the inference engine finds all of the rules that are satisfied by the current contents of the data store. When rules are in the typical condition-action form, this means testing the conditions against the working memory. The rule matchings that are found are all candidates for execution 
they are collectively referred to as the conflict set. Note that the same rule may appear several times in the conflict set if it matches different subsets of data items. The pair of a rule and a subset of matching data items is called an instantiation of the rule. The inference engine then passes along the conflict set to the second state, select rules. In this state, the inference engine applies some selection strategy to determine which rules will actually be executed. The selection strategy can be hard-coded into the engine or may be specified as part of the model. In the larger context of Artificial Intelligence these selection strategies as often referred to as heuristics Finally the selected instantiations are passed over to the third 
state, execute rules. The inference engine executes or fires the selected rules, with the instantiation's data items as parameters. Usually the actions in the right-hand side of a rule change the data store, but they may also trigger further processing outside of the inference engine \(interacting with users through a graphical user interface or calling local or remote programs, for instance\ Since the data store is usually updated by firing rules, a different set of rules will match during the next cycle after these actions are performed. The inference engine then cycles back to the first state and is ready to start over again. This control mechanism is referred to as the recognize-act cycle. The inference engine 
stops either on a given number of cycles, controlled by the operator, or on a quiescent state of the data store when no rules match the data A semantic reasoner, reasoning engine, rules engine, or simply a reasoner, is a piece of software able to infer logical consequences from a set of asserted facts or axioms. The notion of a semantic reasoner generalizes that of an inference engine, by providing a richer set of mechanisms to work with. The inference rules are commonly specified by means of an ontology language, and often a description language. In logic, a rule of inference \(also called a transformation rule\ is a function from sets of formulae to formulae. The argument 
is called the premise set \(or simply premises\ and the value the conclusion. They can also be viewed as relations holding between premises and conclusions, whereby the conclusion is said to be inferable \(or derivable or deducible\ from the premises. If the premise set is empty, then the conclusion is said to be a theorem or axiom of the logic. Many reasoners use first-order predicate logic to perform reasoning inference commonly proceeds by forward chaining and backward chaining There are two types of inference engines : forward chaining and backward chaining. Forward chaining starts with the available data and uses inference rules to extract more data \(from an end user for example\ until a goal is 
reached. An inference engine using forward chaining searches the inference rules until it finds one where the antecedent \(If clause\s known to be true. When found it can conclude, or infer, the consequent \(Then clause\, resulting in the addition of new information to its data. As the data determines which rules are selected and used, this method is also called data-driven, in contrast to goal-driven backward chaining inference Backward chaining starts with a list of goals \(or a hypothesis\and works backwards from the consequent to the antecedent to see if there is data available that will support 
2010 Seventh International Conference on Information Technology 978-0-7695-3984-3/10 $26.00 © 2010 IEEE DOI 10.1109/ITNG.2010.198 53 


any of these consequents. An inference engine using backward chaining would search the inference rules until it finds one which has a consequent \(Then clause\hat matches a desired goal. If the antecedent \(If clause\of that rule is not known to be true, then it is added to the list of goals \(in order for your goal to be confirmed you must also provide data that confirms this new rule\ As the list of goals determines which rules are selected and used, this method is also called goal-driven In the next section, we outline the functional description of various inference engines selected for our comparative study. Section III gives an exhaustive comparative chart for the selected inference engines measured on different performance metrics. Section IV concludes this paper with a discussion of the scope and limitations of the comparative study we have performed  II  I NFERENCE E NGINES  In our comparative analysis we have studied following inference engines A  Jess Jess[7 is a ru le en g i n e  an d sc r i p t in g en v i r o n m en t w r itten  entirely in Sun's Java language by Ernest Friedman-Hill at Sandia National Laboratories in Livermore, CA. Using Jess one can build Java software that has the capacity to "reason using knowledge you supply in the form of declarative rules Jess is small, light, and one of the fastest rule engines available. Its powerful scripting language gives you access to all of Java's Application Programming Interfaces. The reference implementation of Java Specification Request 94 is a driver for Jess; with it, you can connect Jess to Java software using the vendor-independent JSR 94 API B  Hoolet Hoolet[8 s  an i m pl em en t a t i on  of an W e b O n t o l o g y  Language – Description Logic \(OWL-DL\ reasoner that uses a first order logic. The ontology is translated to collection of axioms \(in an obvious way based on the OWL semantics and this collection of axioms is then given to a first order logic for consistency checking. Hoolet is implemented using the WonderWeb OWL API for parsing and processing OWL, and the Vampire logic for reasoning purposes. Hoolet has been extended to handle rules through the addition of a parser for Resource Description Framework rule syntax and an extension of the translator to handle rules. This is again a straightforward translation based on the semantics of Semantic Web Rule Language \(SWRL\ules C  Pellet Pellet  i s a n ope n s o ur ce  r e a s o n er f o r O W L 2 D L  i n  Java. It provides standard and cutting-edge reasoning services for OWL ontologies. For semantically-enabled applications that need to represent and reason about information using OWL, Pellet is the leading choice for systems where sound-and-complete OWL DL reasoning is essential. For example, OwlSight is a lightweight, ontology browser for OWL that uses Google Web Toolkit \(GWT\ and Pronto is a probabilistic DL reasoner integrated with Pellet Pellet is a core component of ontology-based data management applications. It also incorporates various optimization techniques, including novel optimizations for nominals, conjunctive query answering, and incremental reasoning D  SHER Scalable Highly Expressive Reasoner[10  SHER  is  a  breakthrough technology that provides ontology analytics over highly expressive ontologies \(OWL-DL without nominals\. SHER does not do any inferencing on load; hence it deals better with quickly changing data \(the downside is of course, that reasoning is performed at query time\ The tool can reason on approximately seven million triples in seconds, and it scales to data sets with 60 million triples responding to queries in minutes. It has been used to semantically index 300 million triples from medical literature. SHER tolerates logical inconsistencies in the data and it can quickly point you to these inconsistencies in the data and help you clean up inconsistencies before issuing semantic queries. The tool explains \(or justifies\ why a particular result set is an answer to the query; this explanation is useful for validation by domain experts E  KAON2 KAON2[11 is a su cc esso r t o th e KA ON p r o j ect  o f t en  referred to as KAON1\ The main difference to KAON1 is the supported ontology language: KAON1 used a proprietary extension of RDFS, whereas KAON2 is based on OWL-DL and Frame Logic \(F-Logic\ Please note that KAON2 is a completely new system, and is not backward-compatible with KAON1. KAON2 is an infrastructure for managing OWL-DL, SWRL, and F-Logic ontologies. KAON2 provides the following features: An API for programmatic management of OWL-DL, SWRL, and F-Logic ontologies A stand-alone server providing access to ontologies in a distributed manner using Remote Method Invocation, An inference engine for answering conjunctive queries expressed using SPARQL Protocol and RDF Query Language-SPARQL syntax\, A DL Implementation Group DIG\ interface, allowing access from tools such as Protege A module for extracting ontology instances from relational databases. KAON2 supports answering conjunctive queries although without true non-distinguished variables. This means that all variables in a query are bound to individuals explicitly occurring in the knowledge base, even if they are not returned as part of the query answer F  RacerPro RacerPro[1 s  a n OW L R e as o n er a n d I n fer e nce S e r v er for the Semantic Web. RACER stands for Renamed ABox and Concept Expression Reasoner. With RacerPro one can implement industrial strength projects based on the W3C standards RDF and OWL, and it is an ideal tool for research and development. RacerPro can process OWL Lite as well as OWL DL documents \(knowledge bases\. RacerPro is a knowledge representation system that implements a highly optimized tableau calculus for a very expressive description 
54 


logic. RacerPro also provides facilities for algebraic reasoning including concrete domains for dealing with min/max restrictions over the integers, linear polynomial equations over the reals or cardinals with order relations equalities and inequalities of strings G  Jena Jena[1  is  an  o p en s o u r ce Se m a n tic W e b f r am e w ork f o r  Java. It provides an API to extract data from and write to RDF graphs. The graphs are represented as an abstract model". A model can be sourced with data from files databases, URLs or a combination of these. A Model can also be queried through SPARQL and updated through SPARUL -SPARQL/Update is an extension to the SPARQL query language, that provides the ability to add, update, and delete RDF. Jena is similar to Sesame; though, unlike Sesame, Jena provides support for OWL \(Web Ontology Language\. The framework has various internal reasoners and also provides support for external reasoners through the DIG interface. In addition the Pellet reasoner \(an open source Java OWL-DL reasoner\can be set up to work in Jena without using the DIG interface. This allows for improved speed and overcomes some of the limitations in the DIG protocol H  FaCT FaCT \(Fast Classification of Terminologies\ is a Description Logic \(DL\ classifier that can also be used for modal logic satisfiability testing. The FaCT system includes two reasoners, one for the logic SHF \(ALC augmented with transitive roles, functional roles and a role hierarchy\ and the other for the logic SHIQ \(SHF augmented with inverse roles and qualified number restrictions\th of which use sound and complete tableaux algorithms. FaCT's most interesting features are one its expressive logic \(in particular the SHIQ reasoner\ SHIQ is sufficiently expressive to be used as a reasoner for the Dedicated Logic Register \(DLR\ogic, and hence to reason with database schemata; two its support for reasoning with arbitrary knowledge bases \(i.e., those containing general concept inclusion axioms\; three its optimised tableaux implementation \(which has now become the standard for DL systems\, and its Common Object Request Broker Architecture - CORBA based client-server architecture I  FaCT FaCT++[14 is th e n e w g e n e r a ti o n  o f th e w e llk n o w n  FaCT OWL-DL reasoner. FaCT++ uses the established FaCT algorithms, but with a different internal architecture Additionally, FaCT++ is implementated using C++ in order to create a more efficient software tool, and to maximise portability J  SweetRules SweetRules[15 s a uni q u e l y po w e r f ul i n t e g r at ed s e t o f  tools for semantic web rules and ontologies, revolving around the RuleML \(Rule Markup/Modeling Language emerging standard for semantic web rules, and supporting also the closely related SWRL \(Semantic Web Rule Language\, along with the OWL standard for semantic web ontologies, which in turn use XML and, optionally, RDF SWRL rules are essentially an expressive subset of RuleML rules\. SweetRules supports the powerful Situated Courteous Logic Programs extension of RuleML, including prioritized conflict handling and procedural attachments for actions and tests. SweetRules capabilities include semantics-preserving translation and interoperability between a variety of rule and ontology languages \(including XSB Prolog which is a Logic Programming and Deductive Database system for Unix and Windows., Jess production rules, HP Jena-2, and IBM CommonRules\, highly scaleable backward and forward inferencing, and merging of rulebases/ontologies K  OWLIM OWLIM OWLMemSchemaRepository[16  i s a hi ghperformance semantic repository developed in Java. It is packaged as a Storage and Inference Layer \(SAIL\ for the Sesame RDF database. OWLIM is based on Triple Reasoning and Rule Entailment Engine \(TRREE\tive RDF rule-entailment engine. The supported semantics can be configured through rule-set definition and selection. The most expressive pre-defined rule-set combines unconstrained RDFS with most of OWL Lite \(as indicated on the OWL fragments map L  F-OWL F-OWL[17 th e O W L in f e r e n ce en g i n e th at u s es a  Frame-based System to reason with OWL ontologies. FOWL is accompanied by a simple OWL importer that reads an OWL ontology from a URI and extracts RDF triples out of the ontology. The extracted RDF triples are converted to format appropriate for F-OWL’s frame style and fed into the F-OWL engine. It then uses flora rules defined in flora-2 language to check the consistency of the ontology and extract hidden knowledge via resolution M  BaseVISor BaseVISor i s a  f o r w a r d c h a i ni ng i n fer e nce e ngi ne based on a Rete network optimized for the processing of RDF triples. BaseVISor has been outfitted to process RuleML and R-Entailment rules. In the case of RuleML, nary predicates are automatically translated into binary predicates and refined statements that encapsulate the n-ary predicates’ arguments. For R-Entailment, the R-Entailment axioms, axiomatic triples and consistency rules are imported into the engine and then used to derive all triples entailed by a base set of triples. Operation of the system will be demonstrated using sample rule sets employing RuleML and R-Entailment         
55 


III  COMPARITIVE  CHART Free/ Open Source Non Free closed source 1.x Yes\(SWRL RuleML, Jess No Yes Rule Based R-entailment No BASEVISOR Free/opensource 0.3 Yes\(SWRL No Yes Tableau Yes F-OWL Free/ Open Source Non Free closed source 2.x/3.x Yes\(own Rule Format No No Rule Based R-entailment No OWLIM Free/opensource 2.1 Yes\(SWRL RuleML, Jess No No Rule Based No SWEETRULES Free/opensource 1.3.0 No Yes Yes Tableau SROIQ\(D Yes FACT Free/opensource No Yes Yes Tableau SHIQ Yes FACT Free/Opensource 2.5.4 Yes\(own Rule Format Yes Incomplete for OWLDL Rule Based Various reasoner incomplete for nontrivial description logics No complete reasoner included with standard distribution JENA NonFree/closedsource 1.9.2 Yes\(SWRL-not fully support SWRL Yes Yes Tableau Yes RACERPRO Free/closedsource Yes\(SWRL-DL Safe Rules Yes Resolution Datalog SHIQ\(D Yes KAON2 Free/Opensource Yes\(SWRL-DL Safe Rules Yes Yes Rule Based SHIN Yes SHER Free/ Open Source Non Free closed source 2.0 RC5 Yes\(SWRL-DL Safe Rules Yes Yes Tableau SROIQ\(D Yes PELLET Free/Opensource Yes\(SWRL No No FirstOrder Prover Yes HOOLET Non Free/Closedsource 7.1 Yes\(SWRL No Yes Rule Based Yes JESS Licencing Version Rule Support DIG Support Consistenc y Checking Reasoning Algorithm Supported Expressivity For Reasoning OWL-DL Entailment Search Engines Free/ Open Source Non Free closed source 1.x Yes\(SWRL RuleML, Jess No Yes Rule Based R-entailment No BASEVISOR Free/opensource 0.3 Yes\(SWRL No Yes Tableau Yes F-OWL Free/ Open Source Non Free closed source 2.x/3.x Yes\(own Rule Format No No Rule Based R-entailment No OWLIM Free/opensource 2.1 Yes\(SWRL RuleML, Jess No No Rule Based No SWEETRULES Free/opensource 1.3.0 No Yes Yes Tableau SROIQ\(D Yes FACT Free/opensource No Yes Yes Tableau SHIQ Yes FACT Free/Opensource 2.5.4 Yes\(own Rule Format Yes Incomplete for OWLDL Rule Based Various reasoner incomplete for nontrivial description logics No complete reasoner included with standard distribution JENA NonFree/closedsource 1.9.2 Yes\(SWRL-not fully support SWRL Yes Yes Tableau Yes RACERPRO Free/closedsource Yes\(SWRL-DL Safe Rules Yes Resolution Datalog SHIQ\(D Yes KAON2 Free/Opensource Yes\(SWRL-DL Safe Rules Yes Yes Rule Based SHIN Yes SHER Free/ Open Source Non Free closed source 2.0 RC5 Yes\(SWRL-DL Safe Rules Yes Yes Tableau SROIQ\(D Yes PELLET Free/Opensource Yes\(SWRL No No FirstOrder Prover Yes HOOLET Non Free/Closedsource 7.1 Yes\(SWRL No Yes Rule Based Yes JESS Licencing Version Rule Support DIG Support Consistenc y Checking Reasoning Algorithm Supported Expressivity For Reasoning OWL-DL Entailment Search Engines  Note : “-” instead of N/A means that the performance of the respective inference engine under the given criteria is not clear 
56 


IV  C ONCLUSION  We have briefly described how various inference engines fair when compared on different measurement criteria. We tried to be exhaustive in our study but there may be other engines which we have not discussed. Our comparative analysis may be further helpful in selecting various technologies while using ontology based inference engines for semantic web applications and for future research works  A CKNOWLEDGMENT  We would like to thank to our Director for providing the full cooperation, support and for helpful comments on an earlier draft of this paper. We sincerely thank Prof R.K.Bassi, for his guidance, help and motivation. Apart from the subject, we learnt a lot from him, which we are sure will be useful in different stages of our life. Finally, this paper would not have been possible without the confidence endurance and support of our family. Our family has always been a source of inspiration and encouragement  R EFERENCES  1  G. Antoniou, F.van Harmelen. A semantic web primer The MIT Press 2  T.Berners-Lee e.a., Semantic Web Tutorial Using N3 May 20,2003, www.w3.org/2000/10/swap/doc 3  J.Mayfield, T.Finin, and B.County,”Information retrieval on the semantic web: Integrating inference and retrieval,” in SIGIR Workshop on the Semantic web,Toronto,Canada,2004 4  J.D.Heflin, Towards the semantic web: knowledge representation in a dynamic, distributed environment, Dissertation 2001 5  G.Klyne, Nine by nine:Semantic Web Inference using Haskell, May 2003 6  www.ninebynine.org/Software/swish-0.1.html 7  http://www.jessrules.com 8  http://owl.man.ac.uk/hoolet 9  http://clarkparsia.com/pellet   Julian Dolby, Achille Fokoue, Aditya Kalyanpur, Edith Schonberg Kavitha Srinivas, “Scalable highly expressive reasoner \(SHER   http://kaon2.semanticweb.org   Volker Haarslev and Ralf Moller, “RACER: A Core Inference Engine for the Semantic Web   Michael Kifer, Georg Lausen, James Wu.  ”Logical Foundations of Object_Oriented and Frame_Based Languages http://jena.sourceforge.net/inference   http://owl.man.ac.uk/factplusplus   http://sweetrules.semwebcentral.org/ruleformat.pdf   Atanas Kiryakov, Damyan Ognyanov, Dimitar Manov, “OWLIM – a Pragmatic Semantic Repository for OWL   Youyong Zou, Tim Finin and Harry Chen, “F-OWL: an Inference Engine for the Semantic Web” supported by DARPA and NSF   Christopher J. Matheus, Robert Dionne, Douglas F. Parent , Kenneth Baclawski and Mieczyslaw M. Kokar “BaseVISor: A ForwardChaining Inference Engine Optimized for RDF/OWL Triples http://www.vistology.com/basevisor   Jakub Moskal, Northeastern University, Chris Matheus, Vistology Inc  Comparison of BaseVISor, Jena and Jess Rule Engines   Jess homepage. http://herzberg.ca.sandia.gov/jess   Michael Kifer, Georg Lausen, James Wu.  ”Logical Foundations of Object_Oriented and Frame_Based Languages http://jena.sourceforge.net/inference   
57 


  0   5   10   15   20   25   30   0   5   10   15   20   25   30   35 Speed of threads alignmena \(untied fft \(untied   floorplan \(manual-untied   health \(manual-tied   nqueens \(manual-untied  sort \(untied   sparselu \(for-tied  strassen \(nocutoff-tied   Figure 3 Benchmark suite results as base code version These results give an idea of the performance behavior for each application We have applications  NQueens or SparseLU  which have an almost linear speed-up and other applications  Strassen  Health or FFT  which quickly reach a saturation phase B Cut-off mechanism comparison Due to the recursive nature of some benchmarks see Section III-B we can group cut-off mechanisms into two groups 002rst we include cut-off mechanisms which are based on the task depth i.e the recursion level Such kind of cut-off is usually implemented in the application itself Our benchmark suite implements when possible these cutoff mechanisms In the second group we can 002nd cut-off mechanisms based on the total number of tasks already created the number of tasks ready to be executed etc Such pruning mechanisms can be easily implemented in the OpenMP runtime itself   0   5   10   15   20   25   30   1   2   4   8   16   24   32 Speed-up of threads with if clause cut-off with manual cut-off  with no cut-off   Figure 4 Queens benchmark using different cut-off mechanisms Figure 4 shows the speed-up s obtained using these different cut-offs for the NQueens benchmark 017 manual cut-off  prunes the generation of tasks in the application code itself Compiler and runtime are not aware of the possibility of creating a task or not 017 pragma if cut-off  uses the OpenMP clause if  as a part of the task creation directive task  When the condition evaluates to false the task will not be created But the runtime still has to do some management in order to keep consistency e.g task hierarchy and dependence in order to execute properly a taskwait  017 no-cutoff  the application does not provide a cut-off and only the one implemented by the runtime if any is in use The Intel Compiler uses a cut-off based on the number of tasks We can see in the results that with the Intel Compiler programming a manual cut-off is more effective than using an if clause or relying on their runtime cut-off Being a very new compiler these results were expected Hopefully as the task implementations mature these differences will disappear thus reducing the burden on the programmer C Tied vs untied tasks The OpenMP programming model speci\002es that tasks can be labeled with the untied clause establishing two different kinds of tasks tied and untied A tied task is a task that when it is suspended can be resumed only by the same thread that suspended it whereas untied tasks can be resumed by any thread Tiedness of a task does not only imply which thread can resume a task but it also implies some task scheduling constraints which can also impact on the application performance   0   5   10   15   20   25   30   1   2   4   8   16   24   32 Speed-up of threads alignment tied alignment untied  nqueens tied  nqueens untied   Figure 5 Benchmark suite results using tied and untied tasks The suite comes with versions for all applications with tied and untied tasks to compare their behavior Figure 5 shows the results obtained using tied and untied tasks 
129 
129 


with the Alignment and NQueens benchmarks Results are similar with both versions Although a deeper analysis will be needed the results suggest two main hypothesis 017 The Intel Compiler does not implement thread switching and thus untied tasks cannot bene\002t from this feature which should avoid imbalances This is particularly evident in the Alignment benchmark which has been reported to scale 017 Task scheduling constraints do not seem to impact signi\002cantly the performance results at most there is a 4 difference between the versions The other applications show a similar behavior D Other opportunities for analysis The Intel Compiler does not implement mechanisms that allow the user choose among different task scheduling policies but other OpenMP compilers e 16 that have such capabilities One interesting study is to 002nd how task scheduling policies and how they can mantain locality across tasks can affect the performance results of the benchmarks of the suite In previous sections we have discussed how implementing a cut-off mechanism can affect application performance but we have not discussed due to space limitations how the different cut-off values i.e at which point in the recursion we cut relate with the creation of parallelism and the overall performance Choosing a low cut-off value can restrict parallelism opportunities but choosing a high cut-off value can saturate the system with a large amount of tasks which have no thread available to execute them The right choice depends many times of the input data set Comparing the application behaviour using different cut-off values or testing runtime features which allow to modify dynamically the cut-off can also be interesting analyses The quality of implementations for different task generation schemes e.g in the SparseLU benchmark which can use a single or multiple generator scheme taskwait constructs or other task related implementation details could also be analyzed with our benchmark suite proposal V C ONCLUSIONS AND F UTURE WORK We have presented BOTS  Barcelona OpenMP Task Suite  built with the double motivation of coping with the great characteristics of the multicore processors and offer a set of benchmarks to evaluate OpenMP tasking We think that BOTS will help implementors and programmers to have a better understanding of the OpenMP tasking model and its performance implications Each of these benchmarks comes also with different versions to test different aspects of the tasking model For example they can be used to evaluate task scheduling alternatives tiedness   Also a number of input sets are provided so that benchmarks can be used as tests or really stress the processors and memory system in your machine It is interesting to note that we have tried to select benchmarks with diverse characteristics In this paper we have highlighted the differences and we have shown their evaluation on an SGI Altix machine with up to 32 processors and we report some of their characteristics per task e.g operations memory writes    Their evaluation also shows that there is plenty of work to do at all levels  architecture compiler runtime system programming model to improve certain benchmarks given that their current scalability is very limited This suite can be used to obtain useful data of the strenghts and weaknesses of an OpenMP implementation that can help developers to improve it Currently we are working to add new benchmarks to the suite to cover more problem domains and scenarios We are as well planning to do a full cross-vendor evaluation to 002nd which is the current state of the OpenMP tasking implementations A CKNOWLEDGMENTS This research was supported by the Spanish Ministry of Science and Innovation contracts no TIN2007-60625 and CSD2007-00050 the European Commission in the context of the SARC project contract no 27648 the HiPEAC Network of Excellence contract no IST-004408 the IBM CAS Program and the Mare Incognito project under the BSC-IBM collaboration agreement R EFERENCES  O ARB OpenMP Applicati on Program Interf ace v  3.0  May 2008  J M Bull Measuring Synchronizati on and Scheduling Ov er heads in OpenMP in First European Workshop on OpenMP  September 1999  LLNL OpenMP Performance Suite Description 2001 A v ailable https://computation.llnl.gov/casc/RTS Report/openmp perf.html  A Dorta C Rodriguez F  de Sande and A Gonzalez The OpenMP Source Code Repository Euromicro Conference on Parallel Distributed and Network-Based Processing  vol 0 pp 244–250 2005  C Bienia S K umar  J P  Singh and K Li The P ARSEC Benchmark Suite Characterization and Architectural Implications in Proceedings of the 17th International Conference on Parallel Architectures and Compilation Techniques  2008 pp 72–81  H Jin M Frumkin and J Y an The OpenMP Implementation of NAS Parallel Benchmarks and Its Performance NASA Ames Research Center Technical Report NAS-99-011 1999 A v ailable citeseer.ist.psu.edu/408248.html 
130 
130 


 D H Baile y  E  Barszcz J T  Barton D S Bro wning R L Carter D Dagum R A Fatoohi P O Frederickson T A Lasinski R S Schreiber H D Simon V Venkatakrishnan and S K Weeratunga The NAS Parallel Benchmarks The International Journal of Supercomputer Applications  vol 5 no 3 pp 63–73 Fall 1991 A v ailable citeseer.nj.nec.com/bailey95nas.html  H Jin and R F  V  der W ijng aart Performance Characteristics of the Multi-zone NAS Parallel Benchmarks J Parallel Distrib Comput  vol 66 no 5 pp 674–685 2006  V  Aslot M Domeika R Eigenmann G Gaertner  W  B Jones and B Parady SPEComp A New Benchmark Suite for Measuring Parallel Computer Performance Lecture Notes in Computer Science  vol 2104 pp 1  10 2001  A v ailable citeseer nj.nec.com/aslot01specomp.html  C Bienia S K umar  and K Li  P ARSEC vs SPLASH-2 A Quantitative Comparison of Two Multithreaded Benchmark Suites on Chip-Multiprocessors IEEE International Symposium on Workload Characterization 2008  pp 47–56 2008  K K usano S  Satoh and M Sato Performance Ev aluation of the Omni OpenMP Compiler in Prooceedings of the Third International Symposium on High Performance Computing  2000 pp 403–414  S Shah G Haab P  Petersen and J Throop Fle xible Control Structures for Parallellism in OpenMP in 1st European Workshop on OpenMP  September 1999  P  C Fischer and R L Probert Ef 002cient Procedures for Using Matrix Algorithms in Proceedings of the 2nd Colloquium on Automata Languages and Programming  SpringerVerlag 1974 pp 413–427  M Frigo C E Leiserson and K H Randall The Implementation of the Cilk-5 Multithreaded Language in Proceedings of the ACM SIGPLAN 1998 conference on Programming Language Design and Implementation  1998 pp 212–223  E A yguad  e N Copty A Duran J Hoe\003inger Y Lin F Massaioli E Su P Unnikrishnan and G Zhang A Proposal for Task Parallelism in OpenMP in Proceedings of the 3rd International Workshop on OpenMP  Beijing China June 2007  X T eruel X Martorell A Duran R Ferrer  and E A yguad  e Support for OpenMP Tasks in Nanos v4 in CAS Conference 2007  October 2007  E A yguad  e A Duran J Hoe\003inger F Massaioli and X Teruel An Experimental Evaluation of the New OpenMP Tasking Model in Proceedings of the 20th International Workshop on Languages and Compilers for Parallel Computing  October 2007  A Duran J Corbal  an and E Ayguad  e Evaluation of OpenMP Task Scheduling Strategies in Proceedings of the 4th International Workshop on OpenMP  2008  H L v an der Spek E M Bakk er  and H A W ijshof f Char acterizing the performance penalties induced by irregular code using pointer structures and indirection arrays on the intel core 2 architecture in Computing Frontiers 2009  May 2009  M Burtscher  P  Carribault M K ulkarni K Ping ali C Cascaval and C von Praun Lonestar benchmark suite http://iss.ices.utexas.edu/lonestar 2009  B Chamberlain J Feo J Le wis and D Mizell An Application Kernel Matrix for Studying the Productivity of Parallel Programming Languages in W3S Workshop 26th International Conference on Software Engineering  May 2004 pp 37–41  M C and A Rogers Softw are Caching and Computation Migration in Olden 1995  G Myers and S Selznick and Z Zhang and W  Miller Progressive Multiple Alignment with Constraints in RECOMB 97 Proceedings of the 002rst annual international conference on Computational molecular biology  New York NY USA 1997 pp 220–225  J Coole y and J T uk e y  An Algorithm for the Machine Calculation of Complex Fourier Series Mathematics of Computation  vol 19 pp 297–301 1965  S R Das and R M Fujimoto A Performance Study of the Cancelback Protocol for Time Warp SIGSIM Simul Dig  vol 23 no 1 pp 135–142 1993  S G Akl and N Santoro Optimal P arallel Mer ging and Sorting Without Memory Con\003icts IEEE Transactions on Computers  vol 36 no 11 pp 1367–1369 1987  A Duran J Corbal  an and E Ayguad  e An Adaptive Cut-off for Task Parallelism in Proceedings of the 2008 ACM/IEEE conference on Supercomputing  IEEE Press 2008  J Bal art A Duran M Gonz 036 alez X Martorell E Ayguad  e and J Labarta Nanos Mercurium a Research Compiler for OpenMP in Proceedings of the European Workshop on OpenMP 2004  October 2004 
131 
131 



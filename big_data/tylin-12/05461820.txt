An Efficient Online System of Concept Based Association Rules Mining Hany Mahgoub 1 Arabi Keshk 2 Fawzy Torkey 3 Nabil Ismail 4  Faculty of Computers and Info rmation, Menoufia University Shebin El-Kom, Egypt 1 h_mahgoub,@yahoo.com 2 arabikeshk@yahoo.com 3 fatorkey@yahoo.com  Faculty of Electronic Engineering, Menoufia University Menouf, Egypt  4 nabil_a_ismail@yahoo.com  Abstract  This paper presents a new text mining system for 
extracting association rules ba sed on concepts from online textual documents. The system is called developed extracting association rules from textual documents. The mathematical formula of weighting schema is used for labeling the documents automatically and its named fuzzy weighting schema. A new algorithm is proposed for generating association rules based on concepts and it used a data structure of hash table for the mining process. The experiments are applied on a collection of scientific documents that selected from MEDLINE for breast cancer treatments and side effects. The performance of proposed system is compared with the previous Apriori-concept system for the execution time and the evaluation of the extracted association rules. The results show that the number of extracted association 
rules in the proposed system is always less than that in Aprioriconcept system. Moreover, the execu tion time of proposed system is much better than Apriori-concept system in all cases  Keywords  Text mining, Data mining, Association rules mining Concept extraction, MEDLINE I  I NTRODUCTION The explosive growth of information in textual documents creates a great need of techniques for knowledge discovery from text collections. Collec ting, analyzing and extracting useful information from a very large amount of medical texts are difficult tasks for researchers in the medicine who need to 
keep up with scientific advan ces. Nowadays several domains in medical practice, drug devel opment, and health care require support for such actives such as bioinformatics, medical informatics, clinical genomics, and many other sectors Moreover, the examined textual data are generally unstructured as in the case of Medline abstracts in the available resources such as PubMed, search engine interfacing Medline and All t h e s e res o urces  do not provide adequate mechanisms for retrieving the required information and analyzing very la rge amount of text content Text Mining is a tool to su pport and automate the process of finding and extracting interesting information from the documents Selecting features are necessary and sufficient for 
constructing a model that can accurately predict future events or describe a problem. The models based on informative features will be easier to interpret from the other models which are based on uninformative features. The quality of the features must be described in terms of semantic richness For example breast cancer is a disease occurring in a particular part of the body. If a text mining system represented this phrase using the two individual features breast and cancer it would not capture the meaning of the phrase breast cancer  Thus, the concept feature breast cancer is semantically richer 
than the individual features breast and cancer Therefore increasing the information conten t or semantic richness of the features will increase the plausibility and usefulness of the extracted association rules In this paper, we present a new text mining system that called d eveloped extracting asso ciation rules from textual documents \(D-EART\ for extracting association rules from online structured and unstructured documents. The design of the D-EART system is based on concepts representation.  DEART is designed to overcome the drawbacks of the previous EART system that is presented in  The m a them atical weighting schema formula that used in the EART system is 
developed and is named fuzzy weighting schema. In addition generation association rules based concept algorithm \(GARC is used for the mining process instead of word based as in the traditional data mining algorithms. In the D-EART system MEDLINE abstracts are selected for the breast cancer  treatments and side effects as the main domain of online collecting documents. The system is consists of three phases that are Text  Preprocessing A ssociation Rule Mining \(ARM  and visualization  The reset of this paper is org anized as follows. Section 2 pr esents the related works. S 
ection 3 presents the D-EART system architecture. Experimental results are presented in section 4. Section 5 provides conclusions and future work II. R ELATED W ORKS There are several previous works i n the field of association rules mining from structured documents \(XML data\4   6       ecisely the ability to extract useful knowledge from XML data is needed because the numerous data have been represented and exchanged by XML. Thought there are some w orks to exploit XML within the knowledge discovery tasks, and most of them rely on 


legacy relational database with an XML interface. In addition mining knowledge in XML world is faced with more challenges than in the traditi onal well-structured world because of the inherent flexibility of XML. Extracting association rules from native XML documents called “XML association rules” was first introduced by  All the previous work s in this field ar e based on the word features or structured data consequently all extracted association rules are the relations between words 31]-[34 Recently, some works developed tools for extracting associat ion rules from XML docum  35  but both of  them are approaching from the view point of XML query language. This caused the problem of language-dependent association rules mining. Ding et. al in devel ope d a method to discover all of the possible rules, i.e. generalized association rules from XML documents. In this method, all of the possible combinations of XML nodes based on their multiple nesting are used to generate the relational transactions format. This method suffered from some shortcomings such as generation of redundant rules Moreover, it ignored the va luable tree structure of the documents A model for the effective extraction of generalized association rules from a collecti on of XML document is presented in [4  T h is m e thod does not used frequent subtree mining techniques in the discovery process and not ignored the tree structure of data in the final rules. The frequent subtrees based on the user that provide support and split to complement subtrees to form the rules. From the above previous works, we found that all works concentrated on the domain of Association Rules Mining \(ARM\d on words from XML data documents Therefore this research is concentrated on mining of association rules based on concepts from native XML text documents and deals with their tags In the field of ARM from unstruc tured documents, there is a la rge body of previous works Identifying info rmative features from natural language \(text\ can be difficult so that the problem is that there are many approaches use semantically poor features, such as words  14], [21]-[32]. These  approaches take bag of words as input to the association rule mining algorithm such as Apriori algorithm, and finds associations among single isolated words. These approaches have the advantage of domain independent and easy to implement. There are two drawbacks in these approaches: \(1 some concepts consist of mult iple words, thes e multiple words concepts cannot be found as a unit in the association rules, and 2\ber of association rules is tremendously large There are some approaches was concentrated on extracted association rules based on concepts instead of words as in   19  20  2 3  2 7  3 3  37  T h e identified proble m s  in these approaches are: \(1\he ambiguity of the language and can be overcome with human interaction. \(2\hey used the Apriori algorithm to generate association rules based on concepts. \(3\There are many systems based on word features representation and do not take into account the synonymy problem. These systems could ca use a text mining system to generate a misleading model of association rules The earlier work of association rules mining from text has explore d the use of manually assigned ke   1  1 4   They used keywords as features for generating association rules. The drawbacks of these approaches are that 1\It is time consuming to manually assign the keywords 2\The keywords are fixed \(i.e., t h ey do not change over the time or based on a particular user 3\As the keywords are manually assigned, they are s ubject to discrepancy 4\he textual resources are constrained to only those that have key words Therefore, the work is needed to automate indexing of the textu al document in order to allow the use of association extraction techniques on a large scale. Another research has been focused on constructing techniques to improve the quality of text-mined association rules. Most of these approaches generate a set of rules, and apply ranking techniques such as interestingne ss as in 10 15 22 h es, this research is focused on extracted the interesting set of the association rules. That rules are based on semantically richer representations. In mining area, most of previous studies adopt an Apriori for candidate set generation and test approach. However, candidate set generation is still costly, especially when there are a large number of patterns and/or long patterns g ra wal et al had first introduced the problem of association rules mining  e thods for as sociation rules m i ning from both st ruct u re d and unstructured documents have been well developed Apriori and AprioriTid Algorithms h ese  Algorithms, which are used for discovering large itemsets make multiple passes over the da ta. This is the main problem of the Apriori algorithm since it reduces the performance of the system by increasing the time and generating tremendously large association rules where most of them are not plausible and useful III  D EART  S YSTEM  A RCHITECTURE The D-EART system is automatically discove rs ass ociation rules from the collection of online structured and unstructured documents as shown in Fig. 1. It is designed to discover three types of relations such as 1 The association rules amongst concepts only 2  The association rules amongst the words only that are rem ained in the documents after extracted the concepts 3 Get the relations between th e concepts and words in the fo rm of complex rules The modifications in the D-EART that overcome the draw backs of the previous EART system in  25 ar e as follows 1 On-line documents collecting and it accepts all native XML documents 2 The system designed for concepts representation, and it tak es into account the characteristics of the natural language such as synonymy 3 The system automatically indexing documents by using t he developed fuzzy weighting schema without using the threshold weight value 


 Visualization Phase   4 The system designed ba sed on a new algorithm for extracting association rules based on concepts \(GARC The algorithm overcomes the drawbacks of the previous algorithms by employing th e power of data structure called hash table. Furthermore the system has the ability to perform different queries on the extracted association rules   The D-EART system is consists of three main phases beside the online documents collection.  The main phases are Text Preprocessing phase that include transformation, filtration stemming, synonymy and indexing of documents Association Rule Mining \(ARM\ phase that include a new GARC algorithm and visualization phase     Text Preprocessing Phase    Fig. 1 The D-EART system architecture A. Online Documents Collection The D-EART system works online so it is considered to be as a web-base d text mining system. The D-EART accepts the documents that in XML format \(structured\the unstructured documents. From the interface of the D-EART system, the user can online access the MEDLINE link and writes the search keywords. The selected documents and their tags are automatically loading into the system and the user selects the specific part of docume nts that will work on it B. Text Preprocessing Phase The D-EART system has the ab ility to deal with the native XML documents and the unstructured documents. The process of concept extraction is done an d the documents are filtered stemmed and synonym used. Finally, the XML documents are automatically indexed by using the fuzzy weighting schema 1\ Transformation  Once the online XML documents download into the system their tags are automatically extracted in a combobox as shown in Fig. 2. The user can determine his specific part of the documents \(for example the abstract part, </Abstract Text to work on it. Therefore the D-EART system is flexible to work on specific or all parts of documents. In the case of the unstructured documents, the DEART system transforms them to the XML format  Fig. 2 Selecting a specific tag of the documents 2\ Concept Extraction  The concept is a single word or a group of consecutive words that occurs frequently enough in the entire document co llection. It is important to appear the concepts as a unit in the extracted association rules. The process of concept extraction as shown in Fig. 3 can be done as follows: \(1\Splitting the documents into sentences by using the End-of-Sentence Detection Algorithm \(ESDA determine the sentence bounda 2 rm ine each concept candidate using n-grams m  16  26   W e  collect all the ordered pairs, or 2-grams, \(A, B\ such that words A and B occur in the same document in this order and the pair is frequent in the document collections. \(3\ng a list of all concepts in the D-EART system, and map the concepts from concept list with sentences in documents and then estimate their frequencies. \(4\concepts with their frequencies in XML file 3\ Filtration  The documents are filtered by removing the unimportant words from the documents. A list of unimportant words called stopwords is built. The system checks the Visualize Association Rules in tables or reports format  Native XML documents Unstructured documents  Online  MEDLINE Abstracts  Preprocessed documents       Association Rule Mining Phase Apply GARC algorithm on the indexed documents to generate all conceptsets whose support is greater than the user specified minimum support \(min_support  Generate all Association Rules that satisfied a user minimum confidence \(min_confidence  Concepts with frequencies  Stemming Lexicon Index documents by using the fuzzy weighting scheme Fuzzy TF-IDF for all concepts in all documents  Filtered XML documents  Filtration Concepts list Stop words Synonymy Lexicon Concepts extraction using n-grams XML file  Transforme Documents to XML format 


documents content and eliminates these unimportant words e.g. articles, pronouns, conj unctions, and common adverbs Moreover, the system replaces special characters, parentheses commas, etc., with distance between words and concepts in the documents  1 For each document in the corpus 2 Sentence boundary End of Sentence Detection Algorithm 3 Concept List 4 For each concept in the Concepts List 5 Count=0 6 For each sentence in the documents 7 N-grams concept in sentence Concep t in Concepts List 8 Count 9 End for 10 End for 11 Concept F ile Each Concept with its frequencies  Fig. 3 Concepts extraction process 4\ Stemming  After the filtration process had done, the DEART system automatically do word stemming based on the inflectional stemming algorithm wh ich illustrated  inflectional stemming algorithm consists of both part of rulebased and dictionary-based 5\ Synonymy In the synonymy pro cess, the D-EART system matches each concept in the documents with the augment synonymous list When the system finds a synonymy for the concept, it replaces the concept in all documents with its synonymy. For example, the phrase hair loss is synonymous with the medical concept alopecia The actual times occurs number of th is concept is the total number of times that hair loss and alopecia occurs in the text. Since a concept representation would unify the expression hair loss  with alopecia and thus account for synonymy. In contrast, the systems based on word repres entation would distribute the count between the three features hair  loss and alopecia The word based count would be smaller than the actual number of occurrences of the medical concept alopecia  6\ Indexing Ma thematical formula of weighting schema in D-EART system is developed an d used  named fuzzy weighting schema. This formula overcomes the drawbacks of the standard weig hting schema. All weighted concepts are store in XML file for using them as input to the mining process One of the drawbacks of the previous EART system is that th e value of the threshold weight is hard. So we developed the system to automatically compute the weight value for each word and select the actuall y important concepts without entering the threshold weight value M We developed the mathematical formula weighti ng schema and named it fuzzy weighting schema since the threshold weight value is replaced with the fuzzy membership va lue as shown in equation \(1  1  1 0  where C Nt j i j  Where de notes the number of do cuments in collection C  in which occurs at least once \(document frequency of the term and C denotes the number of the documents in collection C Therefore, the fuzzy weighting schema is defined as follows j Nt j t j t  2  0  0 1  log      2 j i j i j j i t Nd if t Nd if Nt C t Nd j i j i w Fuzzy  This formula caused developing in the system since the high weight ed values were given to the concepts that are more occurrences in the documents. Moreover, new concepts appeared with high fuzzy weighted values although they are disappeared by using the weighing schema. The D-EART system automatically eliminates 10 of all concepts that have low weighted values. After that the system stores all concepts without redundancy with their frequencies in XML file for using them as input to the mining process Consider the 6-collection of documents as shown in Fig. 4 In th e indexing process, the fuzzy weighted values are calculated for each concept in the 6 documents. The total number of concepts is equal to 21 concepts in all documents We summarized all concepts with their two weighted values in Table I Collection of Documents DID Concepts D1 D2 D3 D4 D5 D6 C 1 C 2 C 1 C 3 C 6 C 4 C 3 C 4 C 5 C 3 C 5 C 5 C 4 C 2 C 3 C 4 C 2 C 3 C 3 C 3 C 5 C 1 C 5 C 4 C 1 C 5 C 1 C 5 C 5 C 5 C 3 C 4 C 5 C 3 C 4 C 5 C 3 C 2 C 5 C 4 C 5 C 2 C 5 C 2 C 5 Fig. 4 The collection of 6 documents From Table I, it noticed that a concept C 4 has zero weighted values so that the system auto matically eliminates it from all documents. The system resorts the concepts based on their weighted values from the highest to the lowest. Table II shows all resorted concepts with th eir TF-IDF values. By choosing the threshold weight value M 50%, all concepts that in the shaded region had discarded. The system stores all accepted concepts without redundancy which are approximately 4 concepts C 1  C 2 C 3 and C 6 in XML file. Table III shows the same resorted concepts but w ith their Fuzzy TF-IDF values The concepts that appear in the shaded region had discarded since the less important concep ts with fewer frequencies always exist in the bottom of th e table. After that the system stores all concepts without redundancy with their frequencies which are approximately 4 concepts C 1  C 2 C 3 and C 5  XML file for using them as input in the mining process It noticed that the descending order of the concepts becomes differe nt from the order in Table II. The main reasons for the difference are   


TABLE  I T HE  T F-IDF  AND  F UZZY  T F-IDF  V ALUES  FOR  E ACH  C ONCEPT  IN  S IX  D OCUMENTS D-ID Concept Frequencies No. of docu ments TF-IDF Fuzzy TFIDF C 1 2 2 0.954 0.318 C 2 1 3 0.301 0.151 C 3 1 4 0.176 0.117 C 6 1 1 0.778 0.129 D1  C 4 1 6 0.0 0.0 C 3 2 4 0.352 0.235 C 4 2 6 0.0 0.0 D2  C 5 3 5 0.237 0.197 C 2 2 3 0.602 0.301 C 3 4 4 0.704 0.469 C 4 1 6 0.0  0.0   D3  C 5 1 5 0.079 0.066 C 1 3 2 1.431 0.477 C 4 1 6 0.0 0.0  D4  C 5 5 5 0.395 0.329 C 3 3 4 0.528 0.352 C 4 2 6 0.0 0.0 D5  C 5 2 5 0.158 0.132 C 2 3 3 0.903 0.452 C 4 1 6 0.0 0.0  D6  C 5 4 5 0.316 0.263 1\he first effect of the fuzzy wei ghting schema, since the high weighted values are given to the concepts that are more occurrences in documents. For example, the concept C 6 is in two different orders as shown in Table II and Table III. The weighing schema considered the concept C 6 an important concept although it o ccurred only one time in all documents 2\he second effect of the fuzzy weighting schema is the appearing of new concepts with high fuzzy weighted values in the top of the list For example, in Table II the concept C 5 does not satisfy the threshold weight value although C 5 occurred 5 times in D4 In contrast in Table III the concept C 5 has a high fuzzy weighted value and exists in the top of the table C. Association Rule Mining \(ARM\ Phase The D-EART system designed to extract association rules base d o n concepts by using a new GARC algorithm. The algorithm overcomes the drawbacks of the Apriori algorithm by employing the power of data structure called Hash Table The hashing function h v oncepts number N  considered the key factors in hash table building and search performance. The GARC algorithm is utilized with dynamic hash table 1\ Generating Association Rules Algorithm Based on Concepts \(GARC  The proposed GARC algorithm as in Fig 5 employs the following two main steps: \(1\the number of concepts N ents, a dictionary table was constructed as shown in Table IV for N 6 concepts, and 2\There are also two main processes for a dynamic hash table: the building process, and the scanning process. The mining process for GARC algorithm includes the two processes \(building and scanning process\XML file that contains all concepts    TABLE  II T HE  C ONCEPTS  WITH  T HEIR  T F-IDF TABLE  III  Concept Documents TF-IDF Concept Documents Fuzzy TFIDF C 1 D4 1.431 C 1 D4 0.477 C 1 D1 0.954 C 3 D3 0.469 C 2 D6 0.903 C 2 D6 0.452 C 6 D1 0.778 C 3 D5 0.352 C 3 D3 0.704 C 5 D4 0.329 C 2 D3 0.602 C 1 D1 0.318 C 3 D5 0.528 C 2 D3 0.301 C 5 D4 0.395 C 5 D6 0.263 C 3 D2 0.352 C 3 D2 0.235 C 5 D6 0.316 C 5 D2 0.197 C 2 D1 0.301 C 2 D1 0.151 C 5 D2 0.237 C 5 D5 0.132 C 3 D1 0.176 C 6 D1 0.129 C 5 D5 0.158 C 3 D1 0.117 C 5 D3 0.79  C 5 D3 0.066 T HE  C ONCEPTS  WITH  T HEIR  F UZZY  T F-IDF  TABLE  IV T HE  D ICTIONARY  T ABLE  FOR  S IX  C ONCEPTS  IN  D OCUMENTS Dictionary Table Concept' s name Abbreviation Location Breast Cancer Docetaxel Tamoxifen Methotrexate Alopecia Fatigue C 1 C 2 C 3 C 4 C 5 C 6 0 1 2 3 4 5  The hash function h v  v mod N where v is a key location of primary concept\is us ed to build a primary bucket of the hash table. The algorithm scans only the XML file that contained all important concepts not the original documents The scanning process is done as follows 1\l possible combinations of concepts then d eterm ine their locations in the dynamic hash table by using the hash function h v  


2\pts and conceptsets in a hash table and update their frequencies, the process continues until there is no concept in the XML file 3\ve the dynamic hash table into secondary storage media 4\ic hash tab le to determine the large freque nt conceptsets that satisfy the threshold support GARC_algorithm 1 Input minimum support s minimum confidence \(c the number of concepts N  2 Build a primary bucket of hash table 3 IF there is no EOF THEN  4 FOR each document  D  d 1 d 2 d  n  DO 5 Select each concept c 1 c 2 c  N  6 Create all combinations of conceptset with their occurrences 7 Insert all conceptsets with their occurrences in hash table by using h v  8 IF there is  document D  THEN 9 Goto line 4 10 ELSE 11 Goto line 17 12 ENDIF 13 ENDFOR  14 ELSE 15 Goto line 19 16 ENDIF 17 Determine all large frequent conceptsets that satisfies the minimum support 18 Extract all Association Rules that satisfies minimum confidence 19 STOP Fig. 5 The GARC algorithm 2\ The Advantages of the GARC Algorithm  The advantages of the GARC algorithm summarize as follows 1\he algorithm permits the end user to change the threshold support an d confidence factor 2\all size of dynamic hash table, since with changing the size of c onceptsets the size of dynamic hash table will change 3\s number of conceptsets, since there is no conceptsets with zero occurrences will occupy a size in a dynamic hash table 3\ The GARC Algorithm Case Study  The D-EART system run on a collection of 100 online XML documents selected from MEDLINE by thresholds values: support s 2% and confidence c 50%. The number of concepts N 30 resulted from the indexing process a nd used for building a dynamic hash table. Fig. 6 shows the number of all fuzzy weighted concepts that labeling each document. Fig. 7 shows the number of the resultant association rules with c 50% which is equal to 64 rules The D-EART system can do different queries on the extracted asso ciation rules. The query s upports the medical researchers by a model of important relationships within the concept features. This model might identify relations between the disease and the suitable treatments, and relations between a treatment and its side effects. Fig. 8 shows the query screen which includes both the categories information and the queries result icons. The user can dete rmine which the categories will get the relations between them. The query results can be saved on the hard disk thro ugh the export icon  Fig.6 The number of fuzzy weighted concepts  Fig. 7 The resultant rules that satisfy c 50  Fig. 8 Query Screen The advantages of D-EART system are as follows 1 The user can access XML textual documents online 2  The design of the D-EART system is based on concept represe ntation and considers the synonymy as a characteristic of the natural language characteristics 3 It is flexible to work on specific or all parts of the documents with the same structure. Moreover it is not fully domain-independent so we can apply it on other domains 4 The proposed GARC algorithm overcomes the drawbacks of the previous algorithms 5 It extracts three types of the associ ation rules depending on the analysis of relations between the concepts only words only and concepts with words. In addition different queries are available on the extracted association rules IV  E XPERIMENTAL  R ESULTS The experiments are performed to compare the p e rformance of both D-EART system and Apriori-concept system for the number of extracted association rules and the execution time. Finally, evalu ate the performance of D-EART system at the three semantic levels: concepts only, words 


only, and concepts with words The corpus of the PubMed abstracts that used in the experim ents is consists of 10000 biomedical abstracts with keyword search breast cancer treatments and side effects   All experim e nts are applied on the 10000 docum ents after divided them into six documentsets 50, 100, 500, 1000 5000, and all 10000 documents. The systems are implemented by using VS .Net 2005 \(C#\a nd the experiments were performed on Intel Core2 Duo, 1.8 GHz system with Windows XP and 2 Giga of RAM A large number of association rules can be extracted by sel ecting the values of minimum support and confidence in the mining process.  The D-EART system gives the best results by using low support and high confidence values Moreover, the number of concepts that entered to the mining process is fewer by using the fuzzy weighting schema. Table V shows the experiments that are applied on various documentsets by different threshol d values. It noticed that the number of extracted association rules in D-EART system is useful and always less than that in Apriori-concept system The reason returns to the strong effect of using the fuzzy weighting schema in D-EART system Fig. 9 and Fig. 10 show that the execution time of Aprioriconcep t system is increased regular ly when the documentsets are increased compared to D-EART system. The mining process in Apriori-word system takes more time for less number of concepts in the documents. The reason is that the mining process in Apriori algor ithm depends on the size of documents rather than the number of concepts. The results show that the execution time of Apriori-concept system is about seventh fold of D-EART system. The D-EART system scans the documents only one time as the number of documents increased. Therefore the size of documents does not influence in the mining process. Finally, the results reveal that the execution time for D-EART system is much better than that of the Apriori-concept system in all cases  TABLE  V   T HE  N UMBER  OF  A SSOCIATION  R ULES  FOR  A PRIORIC ONCEPT  AND  D EART  S YSTEMS Minimum Support s  Minimum Confidence c  No. of Documents Systems s 1 c 50 3 50 7 60 10 50 500 Apriori-concept D-EART 183 71 76 31 17 5 10 2 1000 Apriori-concept D-EART 227 86 91 34 11 4 8 3 5000 Apriori-concept D-EART 239 92  75 27 20 4 15 2 10000 Apriori-concept D-EART 345 135 102 39 37 10 30 7   D5000 0,00 5,00 10,00 15,00 20,00 25,00 30,00 Apriori-concept D-EART Time in minutes s=1, c=50 s=3, c=50 s=7, c=60 s=10, c=50 Fig. 9 Execution time of Apriori-concept and D-EART systems at D=5000 D10000 0,00 5,00 10,00 15,00 20,00 25,00 30,00 35,00 40,00 Apriori-concept D-EART Time in minutes s=1, c=50 s=3, c=50 s=7, c=60 s=10, c=50 Fig. 10 Execution time of Apriori-concept and D-EART systems at D=10000 V  C ONCLUSIONS  AND  F UTURE  W ORK This paper presented a new text mining system for extracting ass o ciation rules based on concepts representation from online textual documents. This system overcame some of the problems in the prev ious EART system and the drawbacks of the Apriori algorithm by using the data structure hash table in the mining process. The results of comparing DEART and Apriori-concept syst ems reveal that the number of extracted association rules in D-EART system is always less than that in Apriori-concept system. Moreover, the execution time for D-EART system is mu ch better than that of Aprioriconcept system in all cases. So concept technique would be suitable to apply to any large corpus of medical text such as portions of the web. The future work will apply D-EART on PDF full text document with figures and images instead of using only the abstract part R EFERENCES  Fast algorithms for mining association rules,” In Jorge B Bocca, Matthias Jarke, and Carlo Zaniolo, editors Proc. 20 th Int. conf. of very Large Data Bases, VLDB Santigo, Chile 1994, pp. 487-499  T. I m ielinski, and A. Swa m i, “Mining association rules between Sets of items in large databases,” In Buneman, Peter and 


Jajodia, Sushil \(Eds Proc. of the ACMSIGMOD Int. Conf. on Management of Data, Washington D.C., 1993, pp. 207–216  e m ettinen, and A. Verka m o, “Applying data mining technique for descriptive phrase extraction in digital document collections,” in Proc. of IEEE Forum on Research and technology Advances in Digital Libraries Santa Barbra CA, 1998  m adzadeh, M. Rahgozar and A. Zarnani, “A new model for discoveri ng XML association rules from XML documents,” in Proc. 3 rd Int. Conf. on Knowledge Mining, ICKM Prague, Czech Republic, 2006 Aug. 25-27, pp. 365-369  i r, Y. Aum a nn, R Feldman, and M. Fresko Maximal association rules: A tool for mining associations in text Journal of Intelligent Information Systems 25:3, pp. 333-345, 2005  A  Ca m p i   M. Kl e m ettinen, and P  L   Lanzi M i n ing association rules fro m XML data,” in Proc. of the 4 th Int. Conf.  on Data Warehousing and Knowledge Discovery Aixen-Provence, France September 4-6, 2002  a m p i, S. Ceri, M. Kl emettinen, and P. L. Lanzi, “A tool for extracting XML as sociation rules,” in Proc. of the 14 th IEEE Int. Conf. on Tools  with Artificial Intelligence \(ICTAI’02 2002, pp. 57–64  and E. Meglio A Text M ining Strategy based on local contexts of words JADT 2004: 7 th Journées internationales d’Analyse statistique des Données Textuelles, 2004  r own Della Piet ra V J deSouza, and P V. Lai, “Class-based ngram models of natural language Computational Linguistics vol. 18 pp. 467–479, 1992  A. Napoli  and Y. T oussaint, “Towards a text mining methodology using association rule extraction,” Published online: 31 May 2005 © Springer-Verlag 2005  i cords and J. Lumpkin, “Der iving general association rules from XML data in Proc. of Fourth ACIS Int. Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel Distributed Computing SNPD'03\Lübeck, Germany, October 16-18 2003  m a n and I. Dagan, “Knowledge discover y in textual databases KDT\ in Proc. 1 st Int. Conf. on Knowledge Discovery and Data Mining 1995  R. Feld m a n, and H. Hir s h, “Mini ng associations in text in the presence of backgr ound knowledge,” in Proc. 2 nd Int. Conf. on Knowledge Discovery and Data Mining Portland, USA, 1996  m a n and I. Dagan and H Hirs h, “Mining text using keyword distributions Journal of Intelligent Systems 10, pp. 281-300, 1998  H. Zhang Q Qiu, and Z. Wang, “PCAR an ef ficient approach for mining association rules 5 th Int. Conf. on Fuzzy Systems and Knowledge Discovery, IEEE 2008  Fürnkranz, “A study using n-gram features for text categorization Austrian Research Institute for Artificial Intelligence Technical Report  OEFAI-TR-98-30 Schottengasse 3 A-1010 Wien, Austria, 1998  Bauer, J Mostafa M. Palakal, and S. Mukhopadhyay C oncept extraction and association from cancer literature WIDM’02  Mclean, Virginia, USA, November 8, 2002  J. Han, J. Pei, and Y Yin, “Mining frequent patt erns without candidate generation,” In W. Chen, J. Naughton, and P. A. Bernstein, editors, 2000 ACM SIGMOD Intl. Conf. on Management of Data ACM Press, 05 2000, pp. 1-12  W  Jin, R. K. Sr ihar i, and X Wu, “Mining concept associations for knowledge discov ery through concept chain queries,” Z.-H. Zhou, H. Li and Q. Yang \(Eds.\2007 LNAI 4426, pp. 555–562 2007.Springer-Verlag Berlin Heidelberg 2007 20  R. Joshi, X. Li , S. Ramachandaran and T. Leong \(2004\. “Automatic Model Structuring from Text using BioMedical Ontology Available http://www.aaai.org/Papers/Workshops/2004/WS-0401/WS04-01-013.pdf   Agrawal, and R. Sr ikant, “Discovering Trends in Text Databases,” in Proc of KDD, Int. Conf. on Knowledge Discovery  NewPort Beach, CA, , August 14-17, 1997, pp. 227-230  A. Dasigi, R. Dingledine, and B Ciliax, “T ext analysis of Medline for discovering functional relationships among genes: evaluation of keyword extraction weighting schemes Int J. Data Mining and Bioinformatics Vol. 1, No 1, 2006  i ve s, and J. Oliveira Concept-based knowledge discovery in texts extracted from the web ACM SIGKDD pp.29-39, July 2000  u b and D. R s n er, “Mining as sociation rules fro m  unstructured documents,” in Proc. 3 rd Int. Conf. on Knowledge Mining ICKM Prague, Czech Republic, Aug. 25-27, 2006, pp. 167-172  D. Rösner, N Is m a il, and F. Torkey  A text m i ning  technique using a ssociation rules extraction Int. J. of Computational Intelligence WASET, Vol. 4, Nr.1, 2007  a ju m d er, M  M i tra, and B. Chaudhuri, “N-gram: a language independent appr oach to IR and NLP Int. Conf. on Universal Knowledge and Language  ICUKL India November 2002  K. Ober m a y e r \(2 009\of concept based keyw ord extraction for tag recomm Available http://www.kde.cs.unikassel.de/ws/dc09/papers/paper_17.pdf   2009 a l library of Medi cine website [Online Available http://www.nlm.nih.gov   a k, “Discovering know le dge from XML documents,” In Wong John, Eds. Encyclopedia of Data Warehousing and Mining. Idea Group Publications 2005  onstrained association rules to predict heart disease,” in Pr oc. IEEE Int. Conf. on Data Mining, ICDM 2001, San Jose, CA, USA , 2001, pp. 433–440  Yong Youn, and U Kim, “A new method for mining association rules from a collection of XML documents ICCSA 2005 LNCS 3481, pp. 936–945, 2005 Springer-Verlag Berlin Heidelberg 2005  I W itten, S  Cunningha m  and G. Buchanan S calable browsing f or large collections: a case study 5 th Conf. digital Libraries  Texas, pp.215-218, 2000   M. Roche J´erom e Az´e, O. Matte-Tailliez, and Y. Kodratoff  Mining texts by association rules discovery in a technical corpus  Intelligent Information Processing and Web Mining Proc. of the Int. IIS: IIPWM'04  Conf held in Zakopane, Poland, May 17-20, 2004      M ining association rules fro m a collection of XML documents using cross filtering algorithm Int. Conf. on Hybrid Information Technology \(ICHIT'06 IEEE, 2006    W   W a n, and G. Dobbie Extr acting association rules from XML documents using XQuery,” in Proc. of the 5th ACM Int. Workshop on Web Information and Data Management \(WIDM’03 2003, pp.94–97  e iss, N Indurkhya, T. Zhang and F. Damerau TEXT MIN ING Predictive Methods for Analyzing Unstructured Information Springer Science-business Media, Inc. 2005  Li a nd T. Leong, “Automated kno wledge extraction for decision model construction: A data mining approach AMIA  Annual  Symposium Proc pp. 758-762, 2003  2009 bMed website [Online]. Available http://www.ncbi.nlm.nih.gov/pubmed  


To resolve this problem, we proposed a new KDD model. It consists of two steps: the first organizes the database records in homogeneous clusters having common properties which permit to deduce the data’s semantic. This step consists of TAH’s and MTAH generation of relieving attributes. The second permits to Discovering Knowledge. It consists to deduce the Fuzzy  Cluster Lattice corresponding to MTAH lattice generated in the first step, then traverse this lattice to extract the Meta Knowledge \( Set of fuzzy associations meta-rules on the clusters \, and in end deduce the rules modeling the Knowledge \(Set of fuzzy associations rules on the attributes\While basing on the hierarchical structure offered by the lattices, we proceed to discover the Knowledge in a hierarchical way. Thus, according to the degree of detail required by the user, this approach proposes a level of knowledge and different views of this knowledge Moreover, this solution is extensible; the user is able to choose the fuzzy method of classification according to the domain of his data and his needs This solution reduced considerably the number of generated rules, offered a better interpretation of the data and optimized both the space memory and the execution time As futures perspectives of this work, we mention 1\o test our approach on several the large data set, and 2\ to define a new intelligent method of evaluation of requests which takes into account the Meta knowledge and/or the knowledge base generated by our KDD model XI  R EFERENCES  1  P. Berkhin, “Survey of clustering data mining techniques“, Technical report, Accrue Software, 2002 2  M. Zaki, “Mining Non-Redundant Association Rules”, Data Mining and Knowledge Discovery, No 9, 2004, p. 223–248 3  G. Stumme, R.Taouil, Y. Bastide, N. Pasquier, and     L. Lakhal Intelligent structuring and reducing of association rules with formal concept analysis”, Proceedings of KI’2001 Conference, Vienna Austria, Lecture Notes in Artificial Intelligence 2174, SpringerVerlag, September 2001, p. 335–350 4  N. Pasquier “Data Mining : Algorithmes d'Extraction et de Réduction des Règles d'Association dans les Bases de Données”, Thèse Département d’Informatique et Statistique, Faculté des Sciences Economiques et de Gestion, Lyon, 2000 5  R. Agrawal, T. Imielinski, and Swami A., “Mining Association Rules between sets of items in large Databases”, Proceedings of the ACM SIGMOD Intl. Conference on Management of Data, Washington USA, June 1993, p. 207-216 6  R. Agrawal, and R. Skirant. “Fast algoritms for mining association rules”. In Proceedings of the 20th Int'l Conference on Very Large Databases, pages 478-499, June 1994 7  N. Pasquier, Y. Bastide, R.Taouil, and L. Lakhal,          “ Efficient Mining of Association Rules Using Closed Itemset Lattices Information Systems Journal, vol. 24, no 1, 1999, p. 25-46 8  M. J. Zaki, and C. J. Hsiao, “ CHARM : An Efficient Algorithm for Closed Itemset Mining ”, Proceedings of the 2nd SIAM International Conference on Data Mining, Arlington, April 2002, p. 34-43 9  G. Stumme, R. Taouil, Bastide Y., Pasquier N., and L. Lakhal, “Fast Computation of Concept Lattices Using Data Mining Techniques BOUZEGHOUB M., KLUSCH M., NUTT W., SATTLER U., Eds Proceedings of 7th Intl. Workshop on Knowledge Representation Meets Databases \(KRDB’00\Berlin, Germany, 2000, p. 129-139 10  G. Stumme, R.Taouil, Y. Bastide, N. Pasquier, and     L. Lakhal Computing Iceberg Concept Lattices with TITANIC”, J. on Knowledge and Data Engineering \(KDE\ vol. 2, no 42, 2002, p. 189222 11  S. Ben Tekaya, S. Ben Yahia, and Y. Slimani. “Algorithme de construction d`un treillis des concepts formels et de détermination des générateurs minimaux”, ARIMA journal, Novembre 2005, Numéro spécial CARI'04, pages: 171-193, 2005 12  T. Hamrouni, S. Ben Yahia, and Y. Slimani. “Prince : Extraction optimisée des bases génériques  de règles sans calcul de fermetures In Proceedings of the Intl. INFORSID Conference, Editions Inforsid Grenoble, France, pages : 353--368, 24-27 May 2005 13  B. Ganter, and R. Wille, Formal Concept Analysis: mathematical foundations. \(translated from the German by Cornelia Franzke Springer-Verlag, Berlin-Hei delberg 1999 14  T.Thanh, H.Siu Cheung, and C. Tru Hoang, “A Fuzzy FCA-based Approach to Conceptual Clustering for Automatic Generation of Concept Hierarchy on Uncertainty Data.” ,CLA 2004, pp. 1–12 ISBN 80-248-0597-9 15  L. Zadeh. Fuzzy sets. Inform ation and Control, \(69\338-353, June 1965 16  M. Sassi, M., A. Grissa Touzi, and H. Ounelli, “ “Interpretting Fuzzy Clustering Results based on Fuzzy Formal Concept Analyis”, IEEE International Conference on Fuzzy Systems. Imperial College London, UK, 2007 17  A. Grissa Touzi, M. Sassi, and H. Ounelli,  “Using Formal Concept Analysis for Flexible Querying Optimization”, 23nd International Conference on Computers and Their  Applications, \(CATA’08 Mexico, Avril 2008 18  A. Grissa Touzi, M. Sassi, and H. Ounelli, “An innovative contribution to flexible query through the fusion of conceptual clustering, fuzzy logic, and formal concept analysis”, International Journal of Computers and Their Applications. Volume. 16, N°. 4, pp 220-233, December, 2009 19  M. Sassi, A. Grissa Touzi, and H. Ounelli, “A Fuzzy Linguistic Database Summarization Approach”, Fuzzy Systems Conference IEEE International Conference on Fuzzy Systems.   Hong Kong, Juin 2008 20  J.C,  Bezdeck,  R.Ehrlich,  and  W.Full,  "FCM: The Fuzzy  C-Means Clustering Algorithm", Computers and Geoscience, vol. 10, no. 2-3 pp. 191–203, 1984 21  N. Pasquier, Y. Bastide, R.Tou il, and L.Lakhal, “Pruning closed itemset lattices for association rules”, Proceedings of 14th International Conference Bases de Données Avancées, Hammamet Tunisia, 26–30 October 1998, p. 177–196 22  M. J. Zaki, “Generating Non-Redundant Association Rules Proceedings of the 6th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Boston, MA, August 2000, p 34-43 23  Y. Bastide, R.Taouil, N. Pasquier, G. Stumme, and L.Lakhal Mining frequent patterns with counting inference”, SIGKDD Explorations, vol. 2, no 2, 2000, p. 66-75 24  B. Ganter, “Two basics algorithms in concept analysis”, Technical report, Darmstadt, 1984 
134 


   


                        






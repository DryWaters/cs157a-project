 A survey of algorithms in FCIM   Maryam Shekofteh Islamic Azad University, Sarvestan Branch Shiraz,Iran maryam_shekofteh@yahoo.com     Abstract Frequent closed itemsets \(FCI\ is a condensed representation method for frequent item-sets. FCI reduces the redundant rules and increases the performance of mining In recent years, a large number of algorithms have been proposed about frequent closed itemsets mining due to the importance of them In this paper, we generally review and compare the most important FCI algorithms with each 
other. Results show that each algorithm based on its applied strategy has some advantages and disadvantages for mining in dense and sparse datasets. However, DCI-Closed algorithm is more effective than other ones Keywords-Association rule mining; frequent closed itemset I  Introduction Association rule mining \(ARM\ is one of the most important data mining techniques. ARM aims at extraction, hidden relation, and interesting associations between the existing items in a transactional database The main step in association rule mining is the mining frequent itemsets, and time cost in ARM is due to this 
step Frequent itemsets mining often generates a very large number of frequent itemsets and rules. As such, it not only reduces the efficiency, but also decreases the power of mining. To overcome the problem, in recent years condensed representation has been used for frequent itemsets. A popular condensed representation method is  using to frequent closed itemsets in which instead of mining all frequent itemsets, only association mining is required to mine the closed  frequent itemsets and their association rules. Compared with frequent itemsets, the frequent closed itemsets is a much more 
limited set but with similar power. In addition, it decreases redundant rules and increases mining efficiency In recent years, a large number of algorithms have been proposed about frequent closed itemsets mining due to the importance of them. Here, some of them are introduced and compared This article is structured as follows; frequent closed itemsets and relevant topics are introduced in section 2 Section 3 deals with the most important algorithms of frequent closed itemsets mining. Different classifications and algorithm comparison are sketched in section 4. Section 5 evaluates the experimental and 
section 6 concludes on the results II  Problem Development Let D be a transactional database. Each transactional database includes a set of transactions Each transaction t is represented by TID, x in which x is a set of items and TID is the unique identifier of transaction. Further, let us consider I i 1 i 2 i n as the complete set of distinct items in D Each non- empty subset y of I is termed an itemset, and if includes k  items, it would be called 
k itemset. The number of transactions existing in D including itemset y is called the support of itemset y denoted as sup\(y and it is usually represented in percentage. Given a minimum support min-sup an itemset y is frequent itemset, if sup\(y min-sup  Definition1- Closed Itemset: An itemset y is a closed itemset if there is not any superset of y like y    that sup\(y\ = sup\(y    The precise definition of closed itemset, however, is 
based on Relations \(1\ and \(2\ Let us consider T, y and then respectively I y D T  are subset of all items and transactions appeared in D Then functions f and g  are defined based on Relations \(1\ and \(2       t i T t I i T f  1       t i y i D t y g  2  Considering these two functions, an itemset y is a closed itemset, if and only if Relation \(3\ is held 
 h\(y \= f\(g\(y\\og\(y \= y  3  The combinational function h = fog is called closure operator. If a closed itemset is frequent, it is called frequent closed itemset Definition 2- Generator: An itemset p is a generator of a closed itemset y if p is one of the itemsets \(there may be more than one\ that determines y using Galois closure operator h\(p\ = y 
2010 International Conference on Data Storage and Data Engineering 978-0-7695-3958-4/10 $26.00 © 2010 IEEE DOI 10.1109/DSDE.2010.32 29 
2010 International Conference on Data Storage and Data Engineering 978-0-7695-3958-4/10 $26.00 © 2010 IEEE DOI 10.1109/DSDE.2010.32 29 


 III  Main algorithms in frequent closed itemsets mining The frequent closed itemsets mining algorithms can be put in two classes. The first class follows the breathfirst-search method, while the second class employs the depth-first-search method A  First Class Algorithms 1   A-Closed Algorithm A-close algorithm is a basic algorithm in frequent closed itemsets mining which is based on Apriori algorithm[1 i n  f r e que nt i t e m  mining. A-close operation is performed in the following two general steps: Producing frequent generators and achieving closure of frequent generators. For A-close algorithm, an itemset p is generator of closed itemset y  if p  is one of smallest itemsets \(it may be more than one  and it determines y with Galois closure operator h\(p\=y 5     To produce generators, a level-wise approach similar to that of Apriori algorithm is taken. Then three steps of pruning are conducted on candidate generators and useless generators are pruned thereby  T h e  operation of generator production is repeated until no other generator is produced After producing generators G 1 to G n  n is maximum generator size\, closure of all these frequent generators should be computed. The closure of all frequent generators results in all closed frequent itemsets. The method for computing closure is based on proposition 1 Proposition1  The closure of generator p which is achieved by applying function h from Relation \(3\on p  is intersection of all database transactions that include p A-close algorithm uses breath-first-search strategy for mining operation, and itemset lattice is analyzed in a bottom-up way. Its weak point is the great number of candid items and passes from dataset, leading to much time and memory in large datasets B  Second Class Algorithms These algorithms are totally different from those of first class. Due to depth traversal of itemset lattice, here there is no need to pass from dataset in each level, and the count of passes is usually one or two. Next, the dataset is changed to a tree-like structure, and mining is performed on it  1  Charm Algorithm Charm algorithm is different from other coexisting algorithms [9  I n  t h i s a l g o r i t h m   a vertical format is used for data. The vertical format includes a list of items that for each item a list of transactions in which the item is occurred is stored. This list reminds the function g in relation \(2\ All algorithms presented until that time and most algorithms after Charm use horizontal format for working with data. The horizontal dataset includes a list of transactions and each transaction has a list of transaction items Unlike all former association mining algorithms that mined only itemsets space, Charm performs mining in both spaces of items and transactions simultaneously Charm algorithm starts to build a lattices with the existing data available in dataset. It centers around the idea that each node in the lattice should be processed so that all its children are frequent. All infrequent ones and non-closed branches are pruned. The children of each node are created by combination of one node with its siblings that are located in the next branches. If one sibling is pruned due to being infrequent or non-closed it can be ignored. While usually a lexicographic order is considered for branching, it is shown that branching based on support ascending order increases the performance of Charm algorithm The lattice formation in Charms involves considering one branch and node for all single itemsets like x, and labeling it as x×g\(x g indicates function in relation2  Then, for combining two pairs such as   x 1 g 1 and its sibling  x 2 g 2  four conditions is considered[9   T h er e f o r e  al l f r e q u e n t cl o s e d i t e m s e t s  are mined 2  closet Algorithm The format and framework of Closet is based  on FP-growth [3  a l gor ithm i n f r e q ue nt itemsets mining [6  T h e m e tho d us e d  in this  al g o r i t h m  is depth-first-search, and it uses FP-tree[3  s t r u c t ur e   and narrows the mining from dataset to FP-tree mining The Closet operation is conducted in three steps a  Finding frequent items: In first step, like all algorithms the goal is searching frequent single items Therefore, a set of frequent single items and the support number related to support descending order is put in a list called f-list b   Partitioning the search space and forming conditional database: Like FP-growth algorithm whose search for frequent items is partitioned to n sub-problem n represents frequent single items\, here the space partitioning and formation of conditional database is performed based T h e pro c e s s  of  p a rt i t i o n i ng c a n be  recursive, and each sub-set or sub-problem for frequent closed itemsets can be partitioned further when necessary c  Identify the frequent closed itemsets from conditional databases: some lemmas and optimizations provides the theoretical foundation that closet can find frequent closed itemsets correctly[6   The Close algorithm uses many optimizations for saving time and memory. But its main problem like FPgrowth is that it requires a large memory in sparse databases, as in such databases FP-tree occupies large space due to limited  prefixes 
30 
30 


 3  Closet+ Algorithm: Closet+ was developed thanks to the best presented techniques at the time and adding some new optimal methods as well [7          Closet+ uses the divide-and-conquer method such as FP-growth for mining frequent closed itemsets. It follows the depth-first-search and it is attested that it is more efficient than breadth-first-search in mining closed itemsets. This algorithm uses FP-tree as compress technique. The calculation of frequent items with a specific prefix is done by a hybrid tree-projection which enhances the memory. In algorithms such as Closet the projection of conditional database in a bottom-up manner is used in mining the frequent closed itemsets. However, as noted earlier, Closet algorithm had drawback in sparse databases as it needed large memory. The hybrid tree-projection method creates the conditional databases by two ways: bottom-up physical tree-projection for dense databases, and top-down pseudo tree-projection for sparse databases.The Closet is the developed version of Closet algorithm aiming at solving its problem as far as large memory requirement concerned. This algorithm employs the horizontal format for recording transactions, and as such, it is analyzed along with Charm algorithm as one algorithm based on vertical format  In addition to hybrid tree-projection technique, this algorithm uses techniques like item skipping for pruning search space and increase of mining speed, and techniques of subset-checking which are combination of two methods of Two-level hash-indexed result tree for dense databases, and Pseudo-projection based upward checking for sparse databases in order to decrease the closure calculation cost Closet+ is generally an appropriate algorithm compared with other closed item mining algorithms and it runs with less time and memory due to employed optimal techniques. Compared with Closet, it also enjoys higher scalability both in database size and the count of single items. In sparse databases, however, it requires large memory    4  FP-Close Algorithm In order to conduct mining frequent closed itemsets, FP-Close algorithm mines frequent item from FP-trees. Then, to determine whether the frequent items are closed, it uses frequent closed itemsets tree, CFI-tree, which is a type of FP-tree    A  C F t r e e i s r e l a t e d t o a F P t re e  T x and it is shown as C x The tree C x always stores all found frequent closed itemsets which include x itemset. A newly found frequent itemset y which includes x should be compared with just existing frequent itemsets in  C x  If there is no superset of y in  C x with similar support then y is closed The main idea in FP-close is using FP-array technique. In Closet, Closet+, and FP-Close algorithms when the initial FP-tree is created from original database, the most important task is traversing FP-trees and creating conditional FP-trees. A number of different experiments show that 80% of CPU time is devoted to traversal of FP-trees. In FP-close, using FP-array by which a corresponding array with FP-tree is created traverse is removed from tree, and computation is conducted simply on the corresponding array. Hence, in most cases, FP-close has better performance than Closet+. When the time consumed for creating corresponding array from FP-tree is more than FP-tree traversal,  Closet+ performance is better than FP-Close Such case  occurs in databases with numerous items Like Close and Closet+, FP-Close requires large memory in sparse databases 5  DCI-Closed Algorithm DCI-Closed is another algorithm for mining frequent closed itemsets. This algorithm uses a depth-first-search method in search space, and uses a vertical format[4   Since detecting the duplicate closed items, i.e. items that have been formerly generated, is a critical issue in increasing the performance in mining the frequent closed itemsets, this algorithm suggests a general technique for quick detection and removal of duplicate closed items. This is an optimal technique from memory point of view as unlike formerly discussed algorithms, it does not need to keep all closed itemsets that have been mined so far. It detects the duplicate closed itemsets in another way In this algorithm a term ,i.e. equivalence classes in introduced. Two itemsets belong to the same class equivalence if and only if they have the same closure Some algorithms such as A-close choose minimum elements or key patterns of each equivalence class as closure generators. The key patterns form a lattice, and this lattice can be easily traversed by a simple algorithm like Apriori [1  B u t  a n e qui va l e nc e c l a s s c a n ha v e  m o r e  than one minimum element, and still leads to similar closed itemsets. Other algorithms use another technique called closure climbing Once a generator is determined, its closure is calculated. The new generators are formed as recently discovered closed itemsets supersets. As the closed itemsets are maximal elements of their own class, this strategy always guarantees to jump from an equivalence class to another. However, it does not guarantee that a new generator belongs to an equivalence class which has not been visited yet Hence, regardless of the strategy adopted, needed to use some duplicate checking  technique in order to avoid generating multiple times the same closed itemsets. It is not favored, like former algorithms, to keep all mined closed items in the memory and compare them with the new ones, as it requires much space and time. DCI-Closed uses a specific check on frequent itemsets in the algorithm that is used for detecting unique generators of each equivalence class to achieve all closed itemsets whose closure minimum is 
31 
31 


 required. This algorithm extracts a relation of total lexicographic order  among all search space itemsets and does not calculate closure of generators which are not matched with order preserving for preventing duplicate closed itemsets. DCI-Closed performs mining all frequent closed itemsets by 3 sets that name Closed-set, Pre-set, and post-set[4   IV  Classifying and comparing frequent closed itemsets A  Classifying different frequent closed itemsets As noted in different classes of  frequent closed itemsets mining algorithms, they can be categorized as following  1  Type of Search Strategy In the first classification, introduced in section 3, the closed itemsets mining algorithms are classified in two classes according to their search strategy. The first class use breadth-first-search strategy, and the second class employ depth-first-search strategy for mining operation The experiments imply that the latter are more successful 2  Type of  Data Format The algorithms use two vertical and horizontal formats for mining process Generally there is no straightforward position to decide which class is better 3  Type of Generator Selection Some algorithms choose minimum elements of each equivalence class as closure generators. In other algorithms that use closure climbing method. Therefore, closed itemsets mining algorithms can be divided in two classes minimum elements method, and closure climbing method Algorithms that use of with closure climbing method have better performance, as in these algorithms generators are recursively formed from closed itemsets and they are probably larger than other class generators including minimum elements. A larger generator requires less check to determine its closure, and therefore algorithms based on  closure climbing method are more efficient 4  Type of Closure Calculation Generators' closure calculation can be done both on-line and off-line. In the former case, the closure is calculated once a frequent generator is formed, whereas in the latter closure is calculated after all frequent generators are calculated Hence, frequent closed itemsets mining algorithms are put in two classes, i.e on-line and off-line The latter consider minimum elements strategy as the type of generator selection, while the former usually use the closure climbing method. Therefore, algorithms with on-line method are usually more successful than offline ones.  Table1 shows the algorithms' classification B  Comparison of frequent Closed Itemsets Mining Algorithms This section compares introduced algorithms for their performance. The first algorithm was A-close Table1. Classification of frequent Closed Itemsets mining Algorithms A-close has much considerable time. The main reason lies in the fact that it uses breath-first-search method in which for each level the database is read. In other words, the main problem of A-close is the high number of passes of database. Therefore, it requires much more time especially when the databases is large or min-support is low. Charm is the first algorithm that uses vertical format for mining process. It has higher performance compared with other previous algorithms Closet is another algorithm for frequent closed itemsets mining that employs FP-tree structure to narrow the database mining to FP-tree mining. In this algorithm some optimizations are proposed to enhance time and memory. Its main drawback, however, is that it requires large memory in sparse databases. Comparing Charm and Closet, it is noted that the former is mostly faster than the latter in dense databases, except when the minimum support is high. Closet+ is the developed version of Close that tries to remove Close drawback using two different structures for sparse and dense databases. This algorithm proves to have great performance with the help of existing strategies and some new optimization technique. Still it has some weak point in sparse databases as it needs large memory. Compared with Charm, Closet+ has smaller consumption memory and higher scalability. In execution time there are some variations. Sometimes Closet+ works better, and sometimes Charm. FP-close algorithm also uses FP-tree structure like Closet and Closet+. It decreases tree's traversal time using a new technique termed FP-array. Therefore, in most cases it needs less time compared with previous algorithms DCI-Closed algorithm which is introduced as the best and last closed itemsets mining algorithm uses various Type of Closure Calculation Type of Generator Selection Type of Data Format Type of  Search Strategy Algorithm off-line  minimum elem ents  horizonta l breadthfirst-search A-close on-line  closure climbing  vertical depthfirst-search Charm on-line  closure climbing  horizonta l depthfirst-search Closet on-line  closure climbing  horizonta l depthfirst-search Closet on-line  closure climbing  horizonta l depthfirst-search FP-Close on-line  closure climbing  vertical depthfirst-search DCIClosed 
32 
32 


 innovative optimizations in itemsets closure calculations and their support. Furthermore, employing an optimal technique in time and memory, it quickly detects and removes duplicate closed itemsets. This algorithm excels in time and memory all other algorithms in almost all situations  V  Experimental Evaluation Due to high number of discussed algorithms for frequent closed itemsets mining, just performance results of the best algorithms ,i.e.  Closet+, FP-close and DCI-Closed are shown. These results have been tested on databases Chess, Retail and  Pumsb  Chess and  Pumsb  are dense databases and Retail is among sparse databases  Figure 2,3, and 4 illustrate of the results of execution of  DCI-Closed, FP-Close, and  Closet+ on databases Chess, Retail ,and Pumsb  respectively  0 100 200 300 400 500 600 20 25 30 35 40 45 minimum support Runtime\(second  DCIClos ed FPClos e Closet  Figure2. Execution Time in Chess Database  0 10 20 30 40 50 60 70 0.01 0.02 0.03 0.04 0.05 0.06 minimum support Runtime \(second  DCI-Closed Closet FP-Close   Figure 3. Execution Time in Retail Database  0 100 200 300 400 500 600 700 800 900 8 101214161820 min imu m s u p p o rt Runtime \(second  DCI-Closed FPClos e Closet  Figure 4. Execution Time in Pumsb  Database As shown above, DCI-Close has better execution time compared with other two algorithms. In figures 2 and 4, the execution time of algorithm FP-Close is better than Closet+. But in figure 3, Closet+ works better than FP-Close. It is due to the fact that in Retail database the number of frequent items is high, and therefore the time given for formation of corresponding array from related FP-tree is high, whereas FP-tree traversal with optimized strategies employed in Closet consumes substantially less time VI  Conclusion A significant method of condensed representation involves using frequent closed itemsets as their number is fewer than frequent itemsets. The frequent closed itemsets are as powerful as all frequent itemsets, and they increase the effect of mining through removing redundant rules. In recent years, due to the importance of frequent closed itemsets mining many algorithms have been introduced which use various strategies. In this study, the most popular algorithms of frequent closed itemsets  mining have been analyzed. The experiments show that each algorithm has its own advantages and disadvantages regarding its use in different sparse and dense databases. Among them however, DCI-Close algorithm has higher performance due to various innovative optimizations in closure calculations of itemsets, preventing generation of duplicate closed itemsets, and no extra closure operation References 1  R. Agrawal and R. Srikant  Fast algorithms for mining association rules Proc. 20 th int'1 conf. very large data bases 1994  2  G. Grahne, and J. Zhu,  "Efficiently using prefix-trees in mining frequent itemsets IEEE ICDM Workshop on Frequent Itemset Mining Implementations 2003  3  J. Han, J. Pie, Y. Yin, and R. Mao, "Mining frequent pattern without candidate generation Data mining and knowledge discovery 2003  4  C. Lucchese, S. Orlando, and R. Perego, "Fast and memory efficient mining of frequent closed itemsets  IEEE Transaction On Knowledge And Data Engineering Vol. 18, No. 1, PP. 21-35, 2006  5  N. Pasquier, Y. Bastide,  R. Taouil, and L. Lakhal  Discovering frequent closed itemsets for association rules Proc. Int'l conf. Database Theory PP. 398416  1999  6  J. Pei,  J. Han, and R. Mao, " CLOSET: An efficient Algorithm for mining frequent closed itemsets ACM SIGMOD workshop research issue in Data mining and knowledge Discovery PP. 21-30, 2000  7  J. Wang, J. Han, and J. Pei, "CLOSET+: Searching for the best strategies for mining frequent closed itemsets proc. Int'l Conf. Knowledge Discovery and Data Mining PP. 236-245, 2003  8  J. Wang,  J. Han, Y.  Lu, and P. Tzvetkov,  "TFP: An efficient algorithm for Mining top-k frequent closed itemsets IEEE Transactions on knowledge and data engineering Vol. 17, No. 5, PP. 652-664, 2005  9  M.J.  Zaki, and C. Hsiao., "Charm: An efficient algorithm for closed itemset mining Proc. SIAM Int'l Conf. Data Mining PP. 457-473, 2002   
33 
33 


   015\015\01556   015 015  H 015  015 4 0150!/-<0!/-:\1#\015 132*1$\015\0153!\015A\015 015\015\015\015 015   015       015        015<\015!\015\015 7\015\015!\015 4   015   015    0!/-\(\015\015\015\0154 015!\015 \015  015  015 015 015 015 015 015H<\015\015   015 4\015   0153!\015 0154\015\015\015\015\015\015 01544\015\015\015\0154 015 \015\015!\015\015\015 W  J\012  012\01267K  015\0153!\015\015\015\015 015\015"\015\0154  F\015NN 015  015 015\015 0153!\015    015\015 0154  015 7J 015!\015\0153!\015\015  M?J 015 015 7J 015 56 015  4 015 4\015  015  4 56  015  015 015 015 015 015   015\015!\015\015\0154\015 015 0153!\015  0154  015\015 015 015\0150 \015!\015\015 015\015\015\015!\015\015 015\0154!\015\0153!\015 444\015 015\01504! \0153!\015 015\015\015!\0154\015\015 015\015\015\0154\015 015\015\015\015\015\015 0154\015\015T\0154\015\015 015\015H 015 0154  015 015\015     K7J6	EA6  015 \015\015\015\015 015    015 8  2\3\(%&3   6"666   5BJ0FD\012/\015 \015 015\015 0154  T4   015"T4G6<\015?4\015 \015/\015#%**\$W   BJD\01543!\015\015?T?4\015 \015 015D6<\015?4\015 \015/\015#%**2$W   K	JAD6<\015?4\01587\0156<\015?4\015VG J!4?\015  #-22&$W   E D\015 3   015\015 015   AJG 6\015    015#%**&$W\(-%3  AKD\012?7J7J	J\015	?4\015 G\015	A\015	\015\015 015A\015B\015\012\0154   0  J 7 A K 0 7  D 015 4  FI"\015G"II4\015F?\0154   07!J@??@\015 \0156A@\015\0150!B 00F?5JE5FJ45 A    D 015   6\015 A E   F\015   A\015  015 A 015G  015   6\015#%**:$W-\(-3  7\015455D/\0154!C\015G\015\0155 K 	\0156#-222$-++3 2 A07?J0J7AKD\01543!"II4  015  015 015G II4 015 F?\0154#%**:$:23   B  A 0 7  B  DF\015 015 K A 01547!JG6<\015?4\015 015/\015#%**2$W\('\(&\(223    015 0\015  5  015\0158SS 015 STST 4-Q\015   015\015  0\015 6<\015 B  5  015\0158SS 015 S\015 S<Q     A 015  2 015\0158SS   \015 S 63-3-\015   56 015  6  015 5 F\015  2 015\0158SSI S   4	JAE\0154	\015 8/E\015 015 B 015 0154  2 015\0158SS   3\015SSSS\01543\015\015343 3!\015\015\015   7J 0157!J!7JAJ 5%*-*$\015\015 8SS    \(S?!S?7JS  


   for overlooking the overall software development process and playing a crucial role in making important decisions  5.1.3. The Criterion Set As stated earlier, criterion is the attribute for which favorability of an alternativ e is calculated. The criterion set defined for this case study comprises of Reusability  Meeting Operational Requirements and Meeting Project Deadline By reusability, we mean, the amount of reuse of different functionalities that ca n be achieved from the previously developed system on Mine detection training tool. Meeting operational requirements implies how effectively a desired operational capability can be satisfied by an alternative. For example, some alternative might lack a certain operational capability like database support whereas another may support it with enhanced features. Meeting project deadline stresses on the fact whether the project requirements can be satisfactorily achieved within the stipulated deadline which in our case was around one year  5.1.4. The Alternatives To resolve the concerned issu e, the stakeholders decided to choose one software platfor m for developing the mine detection training tool among the three stated alternatives Adobe Director  Adobe Flash  Open GL were chosen as the three possible alternatives along with some justifications. Adobe Flash was chosen as one of the alternatives because; the stakeholders already had a previous developed system for mine detection developed using Adobe Flash    Figure 6. Mine Detection System Along With Three Alternatives One of the considerations involved here was to enhance this system rather than develop a new system from scratch. Same reason applied to choosing Adobe Director as one of the other alternatives. Open GL was picked up as one of the three alternatives in the case when a new development had to be started Open GL is an advanced software development platform and it could have served as a good platform for the mine detection training system  Figure 6 summarizes the pro ject and its three alternatives positions available  5.2. Prioritizing The Criteria  For an effective decision making, we had to weigh the criteria according to their im portance in the decision making process. For this, we choose Analytic Hierarchy process because of its effectiveness in performing pair wise comparison of elements .Table 2 shows the ranking table used for comparing the two criteria  Table 2. Criteria Comp arison Table For AHP  Value a ij  Comparison Description 1 Criteria i and j are of equal importance 3 Criteria i is weakly more important than j 5 Criteria i is strongly more important than j 7 Criteria i is very strongly more important than j 9 Criteria i is absolutely more important than j   Table 3. Comparison Values For Prioritizing Different Criteria   Reusability Meeting Operational Requirements Meeting project Deadline Reusability 1 1/5 3 Meeting Operational Requirements 5  1  7 Meeting Project Deadline  1/3 1/7  1   149 


   Table 4. Normalized Criteria Comparison Table In AHP   Reusability Meeting Operational Requirements Meeting project Deadline Reusability 0.157 0.148 0.272 Meeting Operational Requirements 0.789 0.744 0.636 Meeting Project Deadline 0.052 0.106 0.090  Table 3 and Table 4 show the weight values of the three criterions as compared to each other using the AHP process. These weights have been decided by the stakeholders after discussions among themselves Average weights can be derived from Table 4 as follows Reusability- 0.193 Meeting Operational Requirements- 0.724 Meeting Project Deadline- 0.083 These weights represent the priority of each criterion on a scale of 0 to 1  5.3. Argumentation Tree  We develop argumentation tree for each and every alternative separately. The ar guments are stated by stake holders and assembled under the alternative but they target a specific cr iterion. These arguments can either be supporting or attacking each other or their respective alternative nodes. We present three figures, where each figure represents the argumentation hierarchy for one alternative. Rectangular boxes represent the alternatives with the name of the alternative under it. Ovals represent the criteria with their descr iption. The arguments are specified by labels A, B, C for alternative Adobe flash, Adobe Director and Open GL respectively Along with the labels, the arguments also have indexes associated with them. Beneath the labels are two boxes The box on left shows the weight of the argument whereas the box on right shows the priority of the stakeholder who specifies the argument  Once the argument has been sp ecified, the user enters its weight. We first reassess the weights of the arguments using priority reassessment discussed in h e n us ing the techniques specified in [11 w e red u ce t h e arg u m e n t s  to a single level. Finally, the weighted summation of the arguments with the criteria weights helps us evaluate the final weights for the decision matrix. It is important to note here that, the aggregation method used for calculating the favorability is a weighted summation  The three argumentation hierarchies for the three alternatives are presented in the Figures 7, 8, and 9. The diagrams contain arguments, their weights and the stakeholders priorities     Figure 7. Argumentation Tree For Adobe Flash   Figure 8. Argumentation Tree For Adobe Director 150 


     Figure 9. Argumentation Tree For Open GL  A1 The current system in flash does not have the functionality of dynamic allocation of particles like mine or clutter. It places them randomly  A1.1 That is not of much importance because it still gives a new position to mine and clutter particles A2 Current system in flash has faster response time as compared to system in Adobe Director A3 The current system doesnt satisfy many of the features required for the new system like database A4 Adobe Flash cannot communicate with database A4.1 Flash doesnt support database but database support is very important and critical A4.1.1 The system should be able to generate evaluation reports for trainee based on pr evious records stored in the database A5 Flash doesnt create sound clips  A5.1 We dont need sound creating features as the sys tem has to generate sound. We can play externally recorded sound files using Adobe Flash A6 Flash can provide good visual effects as compared to Adobe Director A7 The developer has good knowledge in development using Flash so the system can be developed quickly B1 We could reuse the system already developed for sound generation, as it is developed using Adobe Audition for analysis which is somehow related to Adobe Director B1.1 The current system is better synthesized in terms of sound production and the sound produced is also instantaneous rather than discrete B1.2 That current system has certain performance issues like slow response time B1.3 The current system in Adobe Director has the feature of producing dynamic coloring scheme on approaching a mine. This kind of scheme is highly preferable and is not present in Adobe Flash system B2 Adobe Director can provide more functionality as compared to the current flash system. E.g. Multiple sounds while detecting mines   B2.1 Adobe Director can provide better visual effects as compared to flash e.g. in case of GUIs   B2.2 A modified version of the current system in flash can also provide the same functionality B2.2.1 We cannot integrate code developed in other platforms with Flash, but Flash can be integrated in Adobe Director B3 The interface provided by flash is not professional enough. It is too simple and straight forward for doing more things in future   B4 Easily available plug-ins can help integrate the tracking system developed in C# with Adobe Director  B4.1 Code developed in Open GL/AL can also be integrated using Adobe Director using suitable stubs   B5 A new sound recognition algorithm is being developed in Adobe Audition which can be integrated with Adobe Director but not with Open GL or Flash Evidence supported B6 If the current system is reused; the project deadline can be met easily B7 The developer has very little experience in development using Adobe Director   B7.1 The developer can take help from the already developed system in Adobe Director C1 The tracking software already developed is coded in C#/NX5. We could reuse that and develop our system in Open GL/AL C1.1 Open GL has C# libraries which can be used to develop the system C2 Because the platform used is for high end application development, it can provide good GUI and database support C2.1 Open GL/AL can help us generate dynamic surfaces for mine detection and training which the original system in flash does not have C4 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C3 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C4 The time taken for developing the project using open GL will be comparatively more as the whole system would have to be developed from scratch C4.1 If Open GL has support for C# libraries, and then the system could be develope d faster as developer is quite familiar with programming languages like C 151 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        






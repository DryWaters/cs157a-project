EVALUATING TECHNOLOGIES BASED ROUGH SET THEORY  VU THANH NGUYEN 1 NGUYEN THI LY SA 2  1 University of Information Techno logy, 34 Truong Dinh Str., 3 Dist, HoChiMinh City, VietNam 2 Colleague of Information Technology  EMAIL: nguyenvt@uit.edu vn, lysant80@gmail.com  Abstract Most data mining algorithms usually generate combining large rules, finding useful rules from rules set necessary and important. There have been several techniques proposed to assess the rule as useful measu re which is based on rough set theory as the RIM, ERIM measure On rough set theory has been studied, the article prop osed AWERIM measure which is improved from  ERIM measure and applied this specific measure to an application of the data mining problem about bank loans  Keywords RIM measure; ERIM measur e; AWERIM measure 1  Introduction  Discovered the combining rule is key areas in data mining and is used widely in many fields. However, these techniques often generate a large combined rules, how to choose the the rules which are really important? One solution to this problem is to use the interesting measures  orga nize and e v al uat e rules by these measures. The useful measures are divided into two main directions objective measure and the subjective measure. The subjective measure depends on the support of the people to evaluate the rule, the objective measure bases on statistics or the structure of the patterns. The Jiye Li proposed a measure based on rough set theory  The rule importance measure - RIM h e objective  measure, is defined similarly useful measure, is used to evaluate the importance of rule  The enhanced rule importance measure - ERIM a combination of two measure subjective and objective is defined based on the wei ght of condition attributes In this article, the authors evaluate the AWERIM Average of Weight based Rule Importance Measure proposed measure and measure ERIM, comparing the advantages of the suggested measure to the Jiye Liês measure by proposed a practical application of data on bank loans 2  Introduction about rough set theory The rough set theory was developed by Zdzisrule Pawlak be seen as a new approach to discover knowledge, and it forms a solid foundation for data mining applications. The h ighlights of issue of the rough set theory are making the id ea to solve ambiguity and uncertainty of information systems  The decision Table In rough set theory, data set is presented as a decision table with rows in th e table called objects and the columns in a table called attributes. Attributes in decision table is divided into two categorie s: condition attributes and decision attributes; the condition attributes are used to describe the conditions and decision attributes are used to describe the results when there are some certain satisfied conditions. A decision table T = \(U,C,D with the symbol U is the set of objects in decision table, C is the set of condition attributes and D is th e set of decision attributes The reduct and core The reduct and the core are two important concepts in rough set theory, the redu ct set of attributes typical conditions likely to classify the entire bo ard decision. A decision table may have reducts and their intersection is said the core, but it is a set of attributes needed for the whole data. Because reduct donêt contains redu ndant attributes therefore it is often used in the attributes selection process A decision table may have more than one reduct, the determination of all reducts is this problem which has complexity to be NP-hard and are interested by many researchers   1951 2010 IEEE 978-1-4244-6527-9/10/$26.00 Proceedings of the Ninth International Conference on Machine Learning and Cybernetics, Qingdao, 11-14 July 2010 


 3  Association rule Mining association rules to help find the relationship between the components in th e data. Mining field of association rule so far has been studied and developed in several different directions, in general problems of mining association rule are divided into two main stages: \(1\find all frequent itemsets, \(2\ining association rules from these frequent itemsets Definition With the transaction data set D, the association rule is implied operator X  Y in which X, Y are the item sets The X  Y Rule has the s support if s% of transactions in D which contains Y X    D Y X s   reliability if c% of transactions containing Y in transactions containing X  X Y X c   ng association rule is to find combinations of all rules X  Y which have s support greater than the threshold support of minSup and the c  reliability greater than the threshold of minConf  The conversion decision table to bitmap table The methods of mining association rules have been proposed to apply to transaction data with the value domain of the properties of 0 and 1 and these properties are considered as the item. To appl y this method to data defined in rough set theory, data in th e decision table with multiple values attributes to need to co nvert decision tab le to bitmap table with attributes to be th e name of the attribute in decision table associated with every its possible value When the objects in decision table is converted to bitmap table which has transactions with values associated for each attribute to be 0 or 1 Mining association rules from bitmap table There are several methods for mining association rules In this article, the authors use the IT-tree search mine the frequent item sets which have the threshold of minSup support after converting decision table to bitmap table. From these frequent item sets, the association rules set X  Y is arisen with minConf threshold of reliability and X  is the subset of C condition attributes set and Y is a subset of the D set of decision attributes Eliminate redundant rules Results of the process of mining association rules usually contain a lot of redund ant rules; need to remove redundant rules from the asso ciation rules set. A rule is considered redundant rule if it satisfies one of the following conditions 1  If there exists two rules of the form as Z Y r Z X r     2 1  I say the rule r 2 is the redundant rule if X subset of Y \(X  Y 2  If there exists two rules of the form as Z X r Y X r     2 1  I say the rule r 2 is the redundant rule if Z subset of Y \(Z  Y 4  Technical for evaluated rules Discovered the association rule is one of the main approaches of data mining but the number of rules discovered usually large while a small number of rules is actually useful from the user view. There are many proposed methods to choose the useful rules by using the utility measure as the interesting measure h e  m easure whic h  is based on rough set theory is proposed by the Jiye Li author  to include the rule important measure - RIM the enhance rule important measure - ERIM The interesting measure The interesting measure of a rule is a technique for evaluating the benefits, the usefulness of this rule. There are many useful measures as Support, Confidence, Lift, Laplace Conviction, Interest, Co sine and Jacquard However, no one of measures can give the best results in all applications The authors V. Kum pared a nd e v aluated 21 measures based on experimental tests and proposed some suitable areas RIM and ERIM measures Two these measures applied from rough set theory particularly the reducts, fo r evaluating the arisen association rules RIM measure  The reduct is a subset of the typical conditions attributes can describe the full meaning of the data set, so the association rules which are arisen from a reduct are typical knowledge A decision table often have more than one reduct, the rule arising from the various reduct may contain different typical in formation, if we only used a reduct to generate rule may to miss the other important information. Therefore, we sh ould use all reducts to generate rules, then some ru les will appear more frequently in the files of rule rules; and we can say that the rule often appears to be viewed is more important than the rule appear regularly. Based on this idea, the Li Jiye author 1952 Proceedings of the Ninth International Conference on Machine Learning and Cybernetics, Qingdao, 11-14 July 2010 


 proposed RIM measure to assess the importance of the rule This measure is defined as follows  n ruleset rule RuleSets ruleset RIM j i j i      Where n is the number of reducts RIM i is the importance of rule rule i ruleset j is the j-th rule set j arising from a j-th reduct and Rule Sets is the rule sets arising from reducts Can say that RIM measure is quite simple and easily calculated, providing a clear and direct view of the importance of a association rule. The measure is objective measure. However, the disadvantage of RIM is that when only one reduct from the decisi on table is found, then the value of RIM of all rules are found to be 100% \(that all rules are important as together not be able to evaluate the importance of rules based on the RIM measure ERIM measure The ERIM measure is proposed to efficiently measure of RIM, and this is a subjective measure which is defined based on the weight of condition attribute in decision table and the weight is evaluated by experts of this field According to experts, the attributes have the higher weighted more necessary so the rule which has greater weight is considered more important. The ERIM measure is defined as follows    i n k k i i w ERIM 1   Where ERIM i is the ERIM measure of the i-th rule \(rule i  i  the number of cond ition attributes in the rule i rules and w i,k  is  weight of k-th attribute of rule i rule The ERIM of rule is the total value of the weights of condition attribute in the rule; these rules which have higher ERIM measure are considered important. For convenience to compare the rules by the ERIM measure, instead of using the ERIM value the percentage of ERIM value is used to compare the maximal ERIM value in rule set The approach of ERIM measure includes three steps The first step is generated set of rules which use the RIM the second step is calculating the ERIM measure value for each rule in the obtained rule set in first step. Finally a combination of both RIM and ERIM measure to evaluate the rule. Advantages of this measure is co mbined subjective measure with  objective measure in evaluated rule process so its result can be better more than using other measures However, this measure depends on the key element of the evaluation which is received by experts. This process is spent many times on statistics process and sometime difficultly to implement The AWERIM measure As described above, the ERIM measure has disadvantages as follows: if two rules have equal RIM measure and weights of the condition attributes in the decision table are the same, then by definition of ERIM measure, then the ru le that has more number of condition attributes on the left side than the others will be  more important; this means that ERIM measure depends on the number of attributes on the left sides of the rule, the higher number of conditions attributes on the left sides is, the more important it will be. This is qu ite non reasonable because the condition attributes in both ru les have equally weighted To solve this problem the article proposed AWERIM measure \(Average of Weight based Enhanced Rule Importance Measure\ alternative measure to overcome the disadvantag es of ERIM measure. The AWERIM measure is defined as follows i n k k i i n w AWERIM i    1   Where the AWERIM measure is AWERIM of i-th rule rule i  i n the number of attributes in the conditions attributes in rule i and k i w  weight of k-th attribute of rule i  The AWERIM measure of rule is the average value of weight of the condition attributes in the rule; these rules have higher AWERIM measure to be considered important For convenience to compare the AWERIM measure of rules instead of using the AWERIM value, we use a percentage of AWERIM value compared with the value AWERIM maximal value in rule set. ERIM similar measure, approach of AWERIM measure also includes three steps: The first step generated rule set using the RIM measure; the second step calculated the value of AWERIM measure for each rule in the rule set obtained in the first step. Finally a combination of both RIM and AWERIM measure to evaluate the rule 5  Practical application The authors use data mining fo r bank loans to evaluate the advantages and the rule measure AWERIM that article suggested to RIM measure and ERIM measure   1953 Proceedings of the Ninth International Conference on Machine Learning and Cybernetics, Qingdao, 11-14 July 2010 


 Description of data set The application on the mining data set for bank loans to predict customers can be approved for a bank loan or not based on some information from customers. Data source which is mined has the 14 attri butes in which 13 conditional attributes \(2 continuous valuable attributes, 11 category valuable attributes\1 decision attribute are included List of attributes is presented in Table 1  T ABLE 1  D ESCRIPTION OF B ANK L OAN DATA  Attribute Type Attribute Name Interpretation Value Domain Name Amount customers want to borrow 0ÉN Continuous Value  Age Customer Age {0ÉN Interest rate Interest rate of loan \(unit 0.9, 0.98 1, 1.05, 1.1 1.12, 1.15 1.18, 1.2 1.3 Duration Period of Loan unit: month 12, 24, 36 48, 60, 72 84, 96 Repayment Repayment Schedule Month end of repayment Pay Interest Schedule for interest payment Every year, Every month Prestige Prestige of customer in the previous loans Yet, Yes No Number of previous loan Number of previous loans 0, 1, 2, 3 Marriage Marital status of Customer Single married Divorce Number of dependents Number of dependents of customer 0, 1, 2, 3 Conditional  attribute Categories  Ensured debt Guaranteed loan ratio \(value of loans against collateral 1, <1 Income Stable level of income of customers Stable Relatively Stable, Non Stable Afford Repayment ability of customer calculated = loan period*monthly income net other assets interest + loans a month * term loan\es of attributes:> = 1 1 1, <1 Decision Attribute To loan with interest Customer information on loan or not Yes, No Building applications Model Application is built by model in Pic.1. The first step, in the first phase incons istent and data will be processed, after that data is divided into tw o parts by the random method 70% data for Training and 30% data for to test. Because the data source of Bank Loan ha s two attributes whose values are continuous values so training data needs to carry out to discrete values by algorithm which is proposed by HungSon  phase of arising rule is association rule set after eliminating the redundant rules applied algorithm to exploit the ru les by IT-tree search for with minSup = 3%, minConf = 70%\rom obtained rule set calculating the RIM, ERIM, AWERIM measures for each rule and in build subclass for each measure. In the last step test data is used data to test the effectiveness of the subclasses that was built based on test accurate results. In this article, the authors use al gorithm for building subclasses  n put of t h is algorith m is rule set to be ordered by using measure, the output is the layer with this measure  1954 Proceedings of the Ninth International Conference on Machine Learning and Cybernetics, Qingdao, 11-14 July 2010 


  Figure 1. Building applications Model Weights of the condition attribu tes of Bank Loan are presented in Table 2. ERIM measure is defined se d  on the weight of attribut es, and these weights were determined to depend on the concept hierarchy, the attributes of the same hierarchy are same weight and equal weight of that hierarchy. But in this article the author is not set up the concept hierarchy because data source of Bank Loan has a few attributes T ABLE 2  W EIGHTS OF CONDITION ATTRIBUTES OF THE B ANK L OAN  Number Condition attribute Weight 1 Money 7 2 Interest 3 3 Period 3 4 Original payment 1 5 Interest payment 1 6 Prestige 7 7 Number of previous loans 4 8 Age 7 9 Marital Status 4 10 Number of dependent 4 11 Ensuring debit 8 12 Income 8 13 Afford to debit 8 Experimental result Table 3 is presented the results of 15 times for the experiment with three RIM, ERIM and AWERIM measures Fig.2 is represented by drawings about accuracy in cases for each measure from the data in Table 3  Discussion Although the number of rules using three RIM, ERIM and AWERIM measures lower th an entire set of rules if the rule set does not use any these measures but subclasses that are built by three measures give test results which are the more correct than when subclasses are not built by three these measures, especially when the AWERIM measure is used \(see table 3\IM measure is a advanced RIM measure but result of the ERIM measure is not the better result of RIM measure. Compared with the 2 measures proposed by Jiye Li \(RIM ERIM\AWERIM measure of this article almost gives the better results T ABLE 3  R ESULTS OF 15 TIMES FOR EXPERIMENTS WITH RIM  ERIM AND AWERIM MEASURES ON DATA SOURCE OF B ANK L OAN  All rules RIM ERIM AWERIM Number   of rules Accuracy   of rules Accuracy   of rules Accuracy   of rules Accuracy 1 185 71.32 131 87.84% 131 87.84 131 93.24 2 152 68.70%  144 84.21% 144 77.63 144 88.16 3 163 70.67 86 86.67% 86 81.33 86 89.33 4 196 70.37 131 87.65% 131 87.65 131 91.36 5 174 65.85%  164 75.61% 164 78.05 164 82.93 6 176 76.62%  128 85.71% 128 87.01 128 87.01 7 183 62.82% 162 78.21% 162 78.21 162 78.21 8 198 64.79 123 80.28% 123 80.28 123 81.69 9 167 70.51 98 83.33% 98 83.33 98 88.60 10 177 69.62 138 80.52% 138 80.52 138 80.52 11 198 72.37 152 77.63% 152 80.26 152 85.53 12 191 67.90 140 82.72% 140 82.72 140 87.65 13 178 64.38 118 82.19% 118 82.19 118 90.41 14 200 63.85 164 79.49 164 79.49 164 82.19 15 183 70.51%  150 93.59% 150 91.03 150 93.59 1955 Proceedings of the Ninth International Conference on Machine Learning and Cybernetics, Qingdao, 11-14 July 2010 


  Figure  2. The Chart compares the accuracy of the subclasses that are used RIM, ERIM, and AWERIM measures 6  Conclusion In the article, the authors pr esent technical evaluation based on the rough set theory of Li Jiye, RIM and ERIM measures, propose a AWERIM measure. Experimental results on data source of Bank Loan prove effectiveness of rule set used AWERIM measure and compare them with ERIM and RIM measures At the present the authors intend to build applications with multiple attributes of data source to test the AWERIM measure performance used concept hier n d develop other measure by combin ing two kind of subjective and objective measures to evaluate the rule Reference 1  Jiye Li, Nick Cercone, W. H . Wong, Lisa Jing Yan 2009 Enhancing Rule Importance Measure Using Concept Hierarchy Faculty of Computer Science and Engineering, York University 2  Jiye Li, Nick Cercone \(2005 Discovering and Ranking Important Rules Granular Computing, IEEE International Conference on Volume 2 3  P. Tan, V. Kumar, J. Sivastava \(2002 Selecting the Right Interestingness Measure for Association Patterns in SIGKDDê02 ACM 4  M. J. Zaki, C. J. Hsiao \(2005 Efficient Algorithms for Mining Closed Itemsets and Their Lattice Structure IEEE Transactions on Knowlegde and Data Engineering 5  Z. Pawlak \(1991 Rough Sets Ö Theoretical Aspects of Reasoning about Data Kluwer Academic Publishers, Dordrecht 6  A. Skowron, C. Rauszer \(1991 The Discernibility Matrices and Functions in Information Systems  7  Aleksander Ohrn \(1999 Discernibility and Rough Sets in Medicine: Too ls and Applications PhD thesis Department of Computer and Information and Science, Norwegian University of Science and Technology, Trondheim Norway. The ROSETTA Homepage, http://www.id i.ntnu.no/~aleks/rosetta 8  N. H. Son \(1997 Discretization of Real Value attributes A Boolean Reasoning approach. Thesis for Doctor of Philosophy 9  S. Mutter \(2004 Classification usin g Association Rules A thesis of Diploma of Computer Science at the University of Freiburg  1956 Proceedings of the Ninth International Conference on Machine Learning and Cybernetics, Qingdao, 11-14 July 2010 


7 ForestCoverType  data is shown in Figure 6 Appendix as an example The tool takes this data as input and produces the hierarchical clusters of data by setting different clustering parameters With the help of this tool user can see  the generated hierarchy of the clusters along with the data present in each cluster. For the experiment we sele cted the row wise clustering option and the algorithm used f or this type of clustering was the Euclidean algorithm. The reason for this choice is that Euclidean distance is the m ost commonly used type of distance measure in cluster analysis It uses raw data instead of standardized data to compute the distances Using the complete linkage method the hierarchal clusters are produced, it can be seen from the Figu re 2 that 3 distinct clusters are produced where each one of them is having its specific hierarchy B Automatic Schema generation In this step the cluster results file which was ex ported using the HCE tool becomes the input of the automat ic schema builder. We developed a prototype to automat e the process of schema generation The prototype takes t he clustered data and generates the schema of any part icular type such as star snowflake or galaxy/constellatio n The prototype has been developed using the C sharp C  programming language in Microsoft Visual Studio.net 2005 Once the hierarchical clustering has been done, the  next step is to extract this hierarchical information in the form of cluster information tables which are fed into the d eveloped prototype called Automatic Schema Generator Figure  3 depicts the main interface of the Automatic Schema Generator having the clustered relationship data C luster names are the abbreviations which are formed using the first letters of each cover type for example clus ter name for C1 is PCD, which means cover types of Ponderosa pine Cottonwood and Douglas-fir PCD All other names are abbreviated by using the first alphabetical letters  After reading the cluster relationship file the bu tton of Create Schema as shown in the following diagram displays the schema selection window. Figure 4 show s the schema selection window of automatic schema builder  Using this selector window cluster name and type o f schema can be selected to build database in the dat abase server. User can select from star, snowflake and ga laxy or constellation options of schema type using the radi o button The ìGenerateî button on the bottom of schema selec tor window performs the following major functions 1\Generates automatic database in the database serv er 2\Creates dimension and fact tables for the schema type selected 3\Manage relationships among the tables 4\Upload data in the fact and dimension tables from the clustered file After performing the above mentioned functions the  control is passed to the schema visualization windo w which gives a glimpse of the schema created automatically  as shown in Figure 5  Fig 2: Hierarchical clusters generated by HCE tool Fig 3 User interface of automatic schema builder Fig 4 Schema Selector window 41 


Fig 5 Schema visualization window V CONCLUSION AND FUTURE WORK In this paper we reviewed the literature regarding  the integration of OLAP with data mining and automatic generation of OLAP schema. Literature review reveal ed the fact that none of the previous works targeted at th e automatic schema generation from the mined data set  Furthermore the works in the past pose a number of limitations. The major limitation of the previous w ork was the absence of a model that can produce the three b asic types of OLAP schema star, snowflake and galaxy Based on these observations we presented the model for th e integration of data mining and OLAP along with the automatic generation of OLAP schema. We have develop ed a prototype for the automatic schema generation Th is developed prototype takes mined data and produces t he schema of userís choice Finally we implemented the  proposed model and evaluated the results with the h elp of experiment It is evident from the result that the prototype system overcomes the manual schema design and implementation requirement in the data warehousing environment We are working on the enhancement of t he proposed model for automatic schema generation One  possible way of enhancement is the use of other dat a mining techniques along with OLAP for the schema generation. Further more, we are exploring how OLAP can be further extended and enhanced to meet the new challenges and to make it more effective efficient  and intelligent OLAP REFERENCES 1  S   C h a u d h u r i  a n d  U   D a y a l   A n  o v e r v i e w  o f  d a t a  warehousing and OLAP technology ACM SIGMOD Record  Vol 26 1997\, pp 6574 2  A   C u z z o c r e a   D   S a c c a  a n d  P   S e r a f i n o   A  h i e r a rchy driven compression technique for advanced OLAP visualizati on of multidimensional data cubes in Proc of 8th Intíl Conf on Data Warehousing and Knowledge Discovery \(DaWak Springer Verlag 2006\, pp. 106-119 3  S   M a n s m a n n  a n d  M   S c h o l l   E x p l o r i n g  O L A P  a g g r e gates with hierarchical visualization techniques, in Proc. of ACM Symposium on Applied Computing 2007\, pp. 1067-1073 4  F a y y a d  U  M   P i a t e s k y S h a p i n o  G    S m y t h  P   a n d  U thurusany R From datamining to knowledge discovery: An overvie w,îin Proc. of Advances in data mining and knowledge discovery MIT Press, pp. 134 5   S   G o i l  a n d  A   C h o u d h a r y    H i g h  p e r f o r m a n c e  O L AP and data mining on parallel computers Data Mining and Knowledge Discovery vol. 1, no. 4, pp. 391-417, Dec. 1997 6   S   A s g h a r   D   A l a h a k o o n  a n d  A   H s u    E n h a n c i n g  OLAP functionality using selforganizing neural networks  Neural, Parallel and Scientific Computations vol. 12, no. 1, pp. 1-20, March 2004 7   R   B   M e s s a o u d   O   B o u s s a i d  a n d  S   R a b a s e d a    A new OLAP aggregation based on the AHC technique,î in Proc. of the 7th ACM Intíl Workshop on Data Warehousing and OLAP DOLAP ACM New York, 2004, pp. 65-72 8   J   H a n    T o w a r d s  o n l i n e  a n a l y t i c a l  m i n i n g  i n  l arge databases ACM SIGMOD Record vol. 27, no. 1, pp. 97-107, March 1998 9   V   M a r k l   F   R a m a s a k  a n d  R   B a y e r    I m p r o v i n g  OLAP performance by multidimensional hierarchical clustering in Proc of the 1999 Intíl Symposium on Database Engineering and Applica tions IDEAS 1999, p. 165 10   V   M a r k l  a n d  R   B a y e r    P r o c e s s i n g  r e l a t i o n a l  OLAP queries with UB-trees and multidimensional hierarchical clusteri ng in Proc of the Intíl. Workshop on Design and Management of Dat a Warehouses DMDW\, 2000, pp. 1-10 11   N   K a r a y a n n i d i s   T   S e l l i s  a n d  Y   K o u v a r a s    CUBE file A file structure for hierarchically clustered OLAP cubes  Advances in Database Technology LNCS Springer Verlag Berlin-Heidelberg pp. 621-638, 2004 12   D   T h e o d o r a t o s  a n d  A   T s o i s    H e u r i s t i c  o p t i m ization of OLAP queries in multidimensionally hierarchically cluste red databases,î in Proc of the 4th ACM Intíl Workshop on Data Warehou sing and OLAP DOLAP\, ACM New York, 2001, pp. 48-55 13   K   H a n n   C   S a p i a  a n d  M   B a l a s c h k a    A u t o m a t i cally generating OLAP schemata from conceptual graphical models,î in  Proc. of the 3rd ACM Intíl Workshop on Data Warehousing and OLAP  DOLAP ACM New York, 2000, pp. 9-16 14   V   P e r a l t a   A   M a r o t t a  a n d  R   R u g g i a    T o w a r d s the automation of data warehouse design Technical Report TR-03-09 InCo Universidad de la Rep˙blica, Montevideo, Uruguay, J une 2003 15   N   T r y f o n a   F   B u s b o r g  a n d  J   G   B   C h r i s t i a n sen StarER A conceptual model for data warehouse design,î Proc of the 2nd ACM Intíl. Workshop on Dataarehousing and OLAP \(DOLAP ACM New York, 1999, pp. 3-8 16   Y   S o n g   e t   a l     S A M S T A R   A n  a u t o m a t i c  t o o l for generating star schemas from an entity-relationship diagram in Proc of the 27th Intíl. Conf. on Conceptual Modeling LNCS 2008, pp. 522-523 17   S   R   M a d d i  a n d  V   K h a n    C o m p a r a t i v e  a n a l y s i s of on-line analytical processing tools,î University essay from IT-uni versitetet I Gˆteborg, Sweden 2007 18   H   Z h u    O n l i n e  a n a l y t i c a l  m i n i n g  o f  a s s o c i a t ion rules Master Thesis, Simon Fraser University, 1998, pp. 1-117 19   J   F o n g   H   K   W o n g  a n d  A   F o n g    O n l i n e  a n a l ytical mining Webpages tick sequences J. of Data Warehousing vol. 5, no. 4, pp. 5967, 2000 20   S   D z e r o s k i   D   H r i s t o v s k i  a n d  B   P e t e r l i n    Using data mining and OLAP to discover patterns in a database of patients  with Y chromosome deletions,î in Proc. AMIA Symp 2000, pp. 215ñ219 21  F   D e h n e   T   E a v i s  a n d  A   R a u C h a p l i n    C o a r s e grained parallel online analytical processing OLAP for data mining in Proc of the Intíl Conf. on Computational Science ICCS\, 2001, 589-598 22   J   H a n   S   H   S   C h e e  a n d  J   Y   C h i a n g    I s s u es for on-line analytical mining of data warehouses,î in Proc. of the SIGMOND Workshop on Research Issues on Data Mining and Knowledge Discov ery DMKD\, Seattle, 1998, pp. 2:1-2:5 23   J   A   B l a c k a r d   D   J   D e a n  a n d  C   W   A n d e r s o n  Forest cover type The UCI KDD Archive http://kdd.ics.uci.edu   I r v i n e CA University of California Department of Information  and Computer Science \(1998 24   J   S e o   e t   a l     I n t e r a c t i v e  c o l o r  m o s a i c  a n d dendrogram displays for signal/noise optimization in microarray data analys is,î in Proc. of the Intl. Conf. on Multimedia and Expo-Volume 3 2003, pp. 461-464 42 


9 Appendix Fig 6: Forest Cover Types of the U.S. \(Source. USGS National Atlas of US Summary of Forest Cover Type Data Type Multivariate Abstract The forest cover type for 30 x 30 meter cells obtai ned from US Forest Service \(USFS\ Region 2 Resource Information System RIS\ data Data Characteristics The actual forest cover type for a given observatio n \(30 x 30 meter cell\ was determined from US Fores t Service \(USFS\ Region 2 Resource Information System RIS data Independe nt variables were derived from data originally obta ined from US Geological Survey \(USGS\ and USFS data. Data is in raw form \(not scaled\ and contains binary \(0 or 1 columns of data for qualitative independent variables \(wilderness areas and soil types Summary Statistics Number of instances observations 581012 Number of Attributes 54 Attribute breakdown 12 measures, but 54 columns of data \(10 quantitativ e variables, 4 binary wilderness areas and 40 binary soil type variables Missing Attribute Values None 43 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        






Conﬁdence-based Concept Discovery in Relational Databases Yusuf Kavurucu 002 yusuf.kavurucu@ceng.metu.edu.tr Pinar Senkul  senkul@ceng.metu.edu.tr Ismail Hakki Toroslu  toroslu@ceng.metu.edu.tr Abstract Multi-relational data mining has become popular due to the limitations of propositional problem deﬁnition in structured domains and the tendency of storing data in relational databases Several relational knowledge discovery systems have been developed employing various search strategies heuristics language pattern limitations and hypothesis evaluation criteria in order to cope with intractably large search space and to be able to generate high-quality patterns In this work we improve an ILP-based concept discovery method namely Conﬁdence-based Concept Discovery C 2 D by removing the dependence on order of target instances in the relational database In this method the generalization step of the basic algorithm of C 2 D is modiﬁed so that all possible frequent rules in Apriori lattice can be searched in an efﬁcient manner Moreover this improved version directly nds transitive rules in the search space A set of experiments is conducted to compare the performance of proposed method with the basic version in terms of support and conﬁdence 1 Introduction Real life data intensive applications require the use of databases in order to store complex data in relational form The need for applying data mining and learning tasks on such data has led to the development of multi-relational learning systems that can be directly applied to relational data Relational upgrades of data mining and concept learning systems generally employ rst-order predicate logic as representation language for background knowledge and data structures The learning systems which induce logical patterns valid for given background knowledge have been investigated under a research area called Inductive Logic Programming ILP a subﬁeld of Machine Learning and Logic Programming 002 Middle East Technical University Computer Eng Dept  Contact author Middle East Technical University Computer Engineering Department 06531 Ankara Turkey  Middle East Technical University Computer Eng Dept Conﬁdence-based Concept Discovery C 2 D 5 is a predictive concept learning ILP system that employs relational association rule mining concepts and techniques to nd frequent and strong concept deﬁnitions according to given target relation and background knowledge C 2 D utilizes absorption operator of inverse resolution for generalization of concept instances in the presence of background knowledge and reﬁnes these general patterns into frequent and strong concept deﬁnitions with an Apriori-based specialization operator based on conﬁdence In this work C 2 D is improved by modifying the generalization step of the main algorithm to overcome the drawbacks of dependence on target instance order and limitations on constructing certain types of transitive rules This paper is organized as follows Section 2 presents the related work Section 3 gives an overview of C 2 D algorithm Section 4 describes the modiﬁcation in the algorithm Section 5 presents the experiments to discuss the performance of improved version according to the basic C 2 D algorithm Finally Section 6 includes concluding remarks 2 Related Work FOIL PROGOL and WARMR are some of the wellknown ILP-based systems in the literature FOIL is one of the earliest concept discovery systems It is a top-down relational ILP system which uses reﬁnement graph in the search process In FOIL negative examples are not explicitly given they are generated on the basis of CWA PROGOL is a top-do wn relational ILP system which is based on inverse entailment A bottom clause is a maximally speciﬁc clause which covers a positive example and is derived using inverse entailment PROGOL extends clauses by traversing the reﬁnement lattice Design of algorithms for frequent pattern discovery has become a popular topic in data mining Almost all algorithms have the same level-wise search technique known as APRIORI algorithm WARMR is a descripti v e ILP system that employs Apriori rule to nd frequent queries having the target relation by using support criteria C 2 D is similar to PROGOL as both systems produce concept deﬁnition from given target WARMR is another simi 
2009 World Congress on Computer Science and Information Engineering 978-0-7695-3507-4/08 $25.00 © 2008 IEEE DOI 10.1109/CSIE.2009.267 287 
2009 World Congress on Computer Science and Information Engineering 978-0-7695-3507-4/08 $25.00 © 2008 IEEE DOI 10.1109/CSIE.2009.267 282 


lar work in a sense that both systems employ Apriori-based searching methods Unlike PROGOL and WARMR C 2 D does not need input/output mode declarations It only requires type speciﬁcations of the arguments which already exist together with relational tables corresponding to predicates Most of the ILP-based systems require negative information whereas C 2 D directly works on databases which have only positive data Similar to FOIL negative information is implicitly described according to CWA Finally it uses a novel conﬁdence-based hypothesis evaluation criterion and search space pruning method PROGOL and WARMR can generate transitive rules only by using strict mode declarations In this improved version of C 2 D transitive rules are generated without the guidance of mode declarations 3C 2 D Conﬁdence-based Concept Discovery Method The proposed technique is an improved version of the concept discovery system named C 2 D 5 and is coupled with the rule generation heuristics of the system Therefore in this section we describe the outline and the important features of C 2 D C 2 D is a concept discovery system that uses rst-order logic as the concept deﬁnition language and generates a set of deﬁnite clauses having the target concept in the head When pure rst-order logic is used to generate patterns in learning systems it may also generate unreasonable clauses such as the ones in which predicates having arguments with different types are related C 2 D prevents this by disallowing predicate arguments with different types to be uniﬁed In C 2 D three mechanisms are effective for pruning the search space 1 The rst one is a generality ordering on the concept clauses based on 002 subsumption and is deﬁned as follows A deﬁnite clause C 002 subsumes a deﬁnite clause C 002  i.e at least as general as C 002  if and only if 002 002 such that head  C  head  C 002  and body  C 002  003 body  C  002  2 The second one which is novel in C 2 D is the use of conﬁdence as follows If the conﬁdence value of a clause is not higher than the conﬁdence values of the two parent clauses in the Apriori search lattice then it is pruned A similar approach is used in the Dense-Miner system for traditional association rule mining 3 The third pruning strategy utilizes primary-foreign key relationship between the head and body relations If such a relationship exists between the head and the body predicates the foreign key argument of the body relation can only have the same variable as the primary key argument of the head predicate in the generalization step Another new feature is the parametric structure for support conﬁdence recursion and f-metric deﬁnitions The user can set support and conﬁdence thresholds in order to nd rules having acceptable support and conﬁdence values Similarly it is possible to allow/disallow recursion in discovered concepts F-metric is the rule evaluation function whose deﬁnition is given in  The database given in Figure 1 is used as a running example in this section In this example daughter d is the concept to be learned and two concept instances are given Background facts of two relations namely parent p and female f are provided Finally types of the attributes of relations are listed Concept Instances Background Facts Type Declarations d\(mary ann p\(ann mary d\(person person d\(eve tom p\(ann tom p\(person person p\(tom eve f\(person f\(ann f\(mary f\(eve Figure 1 The daughter database The algorithm of C 2 D given in Figure 2 starts with selecting a positive concept instance The most general clauses with two literals one in the head and one in the body that entail the positive example are generated and then the concept rule space is searched with an Apriori-based specialization operator In the reﬁnement graph if support parameter is on and the frequency of a clause is below the support threshold it is pruned as an infrequent clause Additionally clauses whose conﬁdence values are not higher than their parents conﬁdence values are also eliminated When the maximum depth reached or no more candidate clause can be found if conﬁdence parameter is on then the clauses that have less conﬁdence value than the conﬁdence threshold are eliminated for the solution set Among the produced strong and frequent rules the best clause according to f-metric value is selected and the rule search is repeated for the remaining concept instances that are not in the coverage of the selected hypothesis clauses Generalization The generalization step is similar to the approach in After picking the rst unco v ered positi v e example C 2 D searches facts related to selected concept instance in the database including the related facts that belong to the target concept in order for the system to induce recursive rules Two facts are related if they share the same constant in the predicate argument positions of the same type Then the system generalizes the concept instance with all related facts In the daughter example C 2 D selects the rst concept instance which is daughter\(mary ann  and then nds the related fact set as  parent\(ann mary parent\(ann tom female\(ann female\(mary   The system generalizes daughter\(mary ann with each related fact For instance by applying absorption operator to the daughter\(mary ann and 
288 
283 


Input I  Concept Instance set BF  Background Facts from DB Output H  Hypothesis set initially H  003  Parameters min-sup  min-conf  B used in f-metric md  maximum depth body literal count Local Variables C i  Candidate clauses set at level i d level G  Generalization clauses FSC  Frequent and Strong clauses set Repeat until I is covered by H until I  003 r No more possible G can be found according to given parameters 1 Select p rst uncovered instance from I  2 GENERALIZATION Generate G of p by using BF 3 Initialize C 1  G  FSC  003  d 1 4 REFINEMENT OF GENERALIZATION While C d 004  003 and d 005 md a FSC  FSC 006 FREQ STR CLS\(C d  min-sup b C d 1  CAND GEN FSC  min-sup i.UNION For each clause pair in level d compute each possible union clause ii.For each union clause satisfying min-sup SPECIALIZATION Unify existential variables FILTERING Discard infrequent and less-conﬁdent clauses c d:=d+1 5 EVALUATION Eliminate clauses according to min-conf Select c best from FSC 6 COVERING Compute I c 007 I covered by c best 7 H:=H 006 c best  I:=I-I c Return H  Figure 2 C 2 D Algorithm parent\(ann,mary  the concept descriptions of the form  daughter  mary ann   parent  ann mary   002  1 2 are derived Reﬁnement of Generalization C 2 D reﬁnes the two literal concept descriptions with an Apriori-based specialization operator that searches the deﬁnite clause space in a topdown manner from general to speciﬁc As in Apriori the search proceeds level-wise in the hypothesis space and it is mainly composed of two steps frequent clause set selection from candidate clauses and candidate clause set generation as reﬁnements of the frequent clauses in the previous level The standard Apriori search lattice is extended in order to capture rst-order logical clauses and the candidate generation and frequent pattern selection tasks are customized for rst-order logical clauses In the daughter example for the concept instance daughter\(mary ann  two literal generalizations are generated in the presence of related facts and the rst level of the search lattice is populated with these generalizations With the support threshold value 0.8 the system eliminates the infrequent clauses Notice that among 18 clauses generated for daughter\(mary ann and parent\(ann mary  only 6 of them satisfy the threshold bold ones below Other clauses below are generated from other generalizations d\(A B p\(C mary  d\(A B p\(B A  d\(A B p\(C A  d\(A B p\(ann C  d\(A B p\(B C  d\(A B p\(C D  d\(A B p\(C tom d\(A B f\(A d\(A B f\(C The candidate clauses for the next level of the search space are generated in three important steps 1 Frequent clauses of the previous level are joined to generate the candidate clauses via union operator In order to apply the union operator to two frequent deﬁnite clauses these clauses must have the same head literal and bodies must have all but one literal in common 2 For each frequent union clause a further specialization step is employed that uniﬁes the existential variables of relations having the same type in the body of the clause By this way clauses with relations indirectly bound to the head predicate can be captured 3 Except for the rst level the candidate clauses that have conﬁdence value not higher than parent’s conﬁdence values are eliminated Evaluation For the rst instance of the target concept which has not been covered by the hypothesis yet the system constructs the search tree consisting of the frequent and conﬁdent candidate clauses that induce the current concept instance Then it eliminates the clauses having less conﬁdence value than the conﬁdence threshold Finally the system decides on which clause in the search tree represents a better concept description than other candidates according to f-metric deﬁnition Covering After the best clause is selected concept instances covered by this clause are removed from the concept instances set The main iteration continues until all concept instances are covered or no more possible candidate clause can be found for the uncovered concept instances In the daughter example the search tree constructed for the instance daughter\(mary ann is traversed for the best clause The clause d\(A B p\(B A f\(A with support value of 1.0 and the conﬁdence value of 1.0 f-metric=1.0 is selected and added to the hypothesis Since all the concept instances are covered by this rule the algorithm terminates and outputs the following hypothesis daughter  A B  parent  B A  female  A   4 Improved C 2 D C 2 Dv2 In the basic algorithm of C 2 D the experiments show that the selection order of the target instance the order in the target relation may change the result hypothesis set In each coverage set the induced rules depend on the selected target instance and the covered target instances in each step do not have any effect on the induced rules in the following coverage steps As a remedy to this problem a new mechanism is developed and used in the improved version of C 2 D namely C 2 D v2 For the target relation t\(a b  the induced rules has a head including either a constant or a variable for each argument of t  Each argument can be handled independently to nd the possible head relations for the hypoth 
289 
284 


esis set As an example for the rst argument a  a constant must be repeated at least min sup multiplied by number of uncovered instances in the target relation so that it can exist as a constant in a possible induced rule To nd the possible constants for a  the following SQL statement must be executed in the database SELECT a FROM t GROUP BY a HAVING COUNT 004 min sup  num of uncov inst For example in the PTE-1 database the tar get relation pte active has only one argument  arg1  At the beginning there are 298 uncovered instances in pte active  The min sup parameter is set as 0.05 However the following SQL statement returns an empty set which means there cannot be a constant for the argument arg1 of pte active  SELECT arg1 FROM pte active GROUP BY arg1 HAVING COUNT 004 298  0.05 The result of the SQL statement empty set means that the argument arg1 of pte active can only be a variable for the head of the solution hypothesis clauses In the same manner for a background relation r\(a b c  if a constant exists many times for the same argument in r  then it is a frequent value for that argument of r and may exist in a solution clause for the hypothesis set As an example in the PTE-1 database atom\(drug atom element integer charge is a background relation and possible constants which can exist in the hypothesis set can be found for each argument of atom by executing SQL statements The possible constants for each argument of atom are as follows drug empty set only variable atom empty set only variable element c h o also variable integer 3 10 22 also variable charge empty set only variable As a result the following clauses totally 1*1*4*4*1  32 different clause are created as candidate in the generalization step of the improved version pte active\(A atom\(A B c 3 C pte active\(A atom\(A B c 10 C pte active\(A atom\(A B c 22 C pte active\(A atom\(A B c C D pte active\(A atom\(A B h 3 D  Support and conﬁdence values for each clause are calculated and the infrequent clauses are eliminated The specialization and coverage steps are same as in the basic version Another drawback of the generalization step of the basic C 2 D algorithm is about generating transitive rules In the basic version only the related facts of the selected target instance are used in the algorithm If a background relation does not have any argument with same type of any argument of the target relation then that background relation is called an unrelated relation and has no effect in the result hypothesis set However as the modiﬁed version of C 2 D handles all the background relations independently it can nd the transitive rules in the search space In the daughter example the target and background relations can only have variables for the arguments in the hypothesis set So the following clauses are produced in the generalization step A,B A,C C,B C,D B,C C D A B C At the end of the rst coverage step the following clause which covers all the target instances is induced daughter  A B  parent  B A  female  A   5 Experimental Results 5.1 Constructing Transitive Rules The generation phase of basic C 2 D algorithm considers only related facts to construct the 2-predicate one head and one body predicate generalized rules However this approach falls short for the cases where the domain includes many unrelated facts Michalski’s trains problem is a typical case for this situation In this data set the target relation eastbound\(train is only related with has car\(train car relation The other background relations have an argument of type car and are only related with has car relation The basic version of C 2 D nds the following rules eastbound\(A has car\(B,car 11 eastbound\(A car\(east1,B eastbound\(A car\(B,car 12 eastbound\(A has car\(A,B eastbound\(A car\(B,car 13 eastbound\(A car\(B,C eastbound\(A car\(B,car 14 As seen above the generated rules are very general and can not include any information about the properties of the cars of the train However C 2 D v2 takes all of the background relations into consideration and can nd the following transitive rule in the search space eastbound\(A B s=5/5,c=5/7 5.2 Finite Element Mesh Design In Mesh Design the task is to learn the rules to determine the number of elements for a given edge in the presence of the background knowledge Four different structures called b-e in are used for learning in this e xperiment Then the structure a having 55 examples is used for testing the accuracy and coverage of the induced clauses For this experiment recursion is disallowed support threshold is set as 0.1 conﬁdence threshold is set as 0.1 B is set as 1 and maximum depth is set as 3 In this experiment C 2 D nds rules that cover 31 of the 55 records in the test data set The impro v ed v ersion C 2 D v2 nds rules that cover 29 of the records in the test 
290 
285 


Method Type Pred Acc C 2 D v2 improved ver ILP+DM 0.80 Ashby Chemist 0.77 PROGOL ILP 0.72 RASH Biological Potency An 0.72 C 2 D basic ver ILP+DM 0.69 TIPT Propositional ML 0.67 Bakale Chemical Reactivity An 0.63 DEREK Expert System 0.57 Figure 3 Predictive accuracies for PTE-1 data set However the accuracy of the rules found by C 2 D is 0.29 whereas the accuracy of the rules by C 2 D v2 is 0.49 In other words the improved version nds rules that have nearly same coverage but higher accuracy according to the basic version of C 2 D 5.3 Predictive Toxicology Evaluation The carcinogenecity tests of compounds are vital to prevent cancers however the standard bioassays of chemicals on rodents are really time-consuming and expensive In the National Toxicity Program the tests conducted on the rodents results in a database of more than 300 compounds classiﬁed as carcinogenic or non-carcinogenic Among these compounds 298 of them are separated as training set 39 of them formed the test set of PTE-1 and the other 30 chemicals constitute the test set of PTE-2 challenge In this experiment PTE-1 data set is used recursion is disallowed support threshold is set as 0.05 conﬁdence threshold as 0.7 B is set as 1 and max depth is set as 3 The predictive accuracies of the state-of-art methods and C 2 D with its improved version for PTE-1 data set are listed in Figure 3 As seen from the gure C 2 D v2 has a better predictive accuracy than the basic C 2 D algorithm In addition it nds the best results having highest accuracy with respect to other systems 6 Conclusion This work presents an improvement for an ILP-based concept discovery system named C 2 D which combines rule extraction methods in ILP and Apriori-based specialization operator By this way strong declarative biases are relaxed instead support and conﬁdence values are used for pruning the search space In addition C 2 D does not require user speciﬁcation of input/output modes of arguments of predicates and negative concept instances Thus it provides a suitable data mining framework for non-expert users who are not expected to know much about the semantic details of large relations they would like to mine which are stored in classical database management systems In C 2 D v2 generalization step of C 2 D is modiﬁed in such a way that most general rules are constructed by considering the number of occurrences of constant arguments in the rules By this mechanism the effect of target instance order on rule generation is eliminated and rule quality is improved Another improvement is on constructing transitive rules Since this new method does not differentiate related and non-related facts transitive rule generation is not limited to related facts The proposed system is tested on several benchmark problems including the Michaslki’s train problem mesh design and predictive toxicology evaluation test The experiments reveal promising test results that are comparable with the performance of basic C 2 D method and current state-ofthe-art knowledge discovery systems References  L Dehaspe and L D Raedt Mining association rules in multiple relations In ILP’97 Proceedings of the 7th International Workshop on Inductive Logic Programming  pages 125–132 London UK 1997 Springer-Verlag  B Dolsak and S Muggleton The application of Inductive Logic Programming to nite element mesh design In S Muggleton editor Inductive Logic Programming  Academic Press London 1992  S D  zeroski Multi-relational data mining an introduction SIGKDD Explorations  5\(1 2003  Y  Ka vurucu P  Senkul and I H T oroslu Aggre gation in conﬁdence-based concept discovery for multi-relational data mining In IADIS European Conference on Data Mining ECDM  Amsterdam Netherland July 2008  Y  Ka vurucu P  Senkul and I H T oroslu Conﬁdence-based concept discovery in multi-relational data mining In IAENG International Conference on Data Mining and Applications ICDMA  pages 446–451 Hong Kong March 2008  R Michalski and J Larson Inducti v e inference of vl decision rules In Workshop on Pattern-Directed Inference Systems  volume 63 pages 33–44 Hawaii 1997 SIGART Newsletter ACM  S Muggleton In v erse entailment and Progol New Generation Computing Special issue on Inductive Logic Programming  13\(3-4 1995  S Muggleton Inducti v e Logic Programming In The MIT Encyclopedia of the Cognitive Sciences MITECS  MIT Press 1999  J R Quinlan Learning logical deﬁnitions from relations Mach Learn  5\(3 1990  J Roberto J Bayardo R Agra w al and D Gunopulos Constraint-based rule mining in large dense databases Data Mining and Knowledge Discovery  4\(2-3 2000  A Srini v asan R D King S H Muggleton and M Sternberg The predictive toxicology evaluation challenge In Proceedings of the Fifteenth International Joint Conference on Artiﬁcial Intelligence IJCAI-97  pages 1–6 MorganKaufmann 1997 
291 
286 


R EFERENCES 1  T h abt a h, F  20 0 7 A r e v i ew of  A s s o ciat iv e Cl assif i cat io n Mi ni ng   The Knowledge Engineering Review Vol .22.1, 37-65 2  G a y l e  S  2 0 0 0  D a ta  Mi ni ng  in  the I n s u r a nce I ndus tr y  S A S  I n s t it ute  Inc 3  K i e t z  J.ÖU Re im e r U  S t a u dt, U  1 9 9 7  M i n i ng I n sur an ce D a t a  at Swiss Life Proceedings of the 23rd International Conference on Very Large Data Bases \(VLDB Pp. 562-566 4 Vi veros  M  S  Nea rh os  J  P  R o thm a n  M J   19 96  A p p l y i n g Da ta Mining Techniques to a Health Insurance Information System In Proceedings of the 22 nd VLDB Conference Mumbai \(Bombay India 5  Che n  Y  H u  L  200 5 S t u d y o n D a t a M i ni ng A ppl ic at io n in C R M  System Based on Insurance Trade International Conference on Electronic Commerce China: August 6  Z h ang J  Cu i, Y    L i u, W  2 0 0 9  S upe r v is e d L e ar ning Bas e d D a t a  Mining Technology with Its Application to Life Insurance Datasets Analysis International Journal of Business and Management Vol 2\(1 7 St a udt   M   K i et z J  U  R e im er U 19 97 A D L E R   A n  Environment for Mining Insurance Data KRDB 1997 pp16.1-16.9  St a udt   M  K i et z J  U  R e i m er U 1 998  A Da t a Mi nin g Sup p o r t  Environment and its Application on Insurance Data In Proceedings of Knowledge Discovery in Databases \(KDDê98 Pp105-115 9 Ha n  J  K a m b er  M  200 1 D a ta  M i n i n g  C o n c ept an d T e c h ni qu es  San Francisco: Morgan Kaufmann Publishers  A g ra w a l R  Srik an t R 199 4 F a s t A l g o ri t h m s for M i n i n g A s s o c i at i o n Rules, Very Large Databases Int. Cont. Proceedings, 1994    B o rgelt  C  200 3 A p ri ori F i nd in g A s s o c i a t i on Ru les  H y p er ed ges  with the Apriori Algorithm http://www10.brinskter.com  stevenyip/apriori/doc/apriori.html  K o t s i a n t i s  R   K a n e llop ou s  D 2006  A s s o c i at i o n Ru les M i ni n g A  Recent Overview GESTS International Transactions on Computer Science and Engineering  13  A g r a w a l  R., I m iel ins k i, T  Sw am i A  199 3. D a ta bas e  Mi ni ng  A  Performance Perspective,   \(Learning and discovery in knowledgebased databases IEEE Transactions on Knowledge and Data Engineering 5\(6\ pp914Ö925 1486 2010 10th International Conference on Inte lligent Systems Design and Applications 


Figure 3 Precision-recall curve in ROI-250 image dataset 5.3 Experiment 3 Mammograms-1080 image dataset This experiment employed a dataset composed by 1080 mammograms images collected in the Clinical Hospital of University of Sao Paulo at Ribeiro Preto The dataset was previously classi\002ed into 4 levels of breast tissue density 0501\051 mostly fatty 050362 images\051 0502\051 partly fatty 050446 images\051 0503\051 partly dense 050200 images\051 and 0504\051 mostly dense 05072 images\051 Figure 4 Precision-recall curve in Mammography-1080 image dataset Breast density is an important risk factor in the development of breast cancer In this experiment the images are represented by the feature set proposed in b uilding a vector of 85 features including shape and size of the breast the conditions of the breast contour nipple position and the distribution of 002broglandular tissue This dataset was divided in training set and test set The training set is composed of 720 images and test set is composed of 360 images Figure 4 shows the P&R curves over test dataset and also the number of features selected in each method Again the proposed methods reached the highest values of precision and select the smallest number of features 050a\051 050b\051 050c\051 050d\051 Figure 5 Queries in Mammography dataset 050a\051 226 is the query image 050b\051 using the features selected through 002tness function F cB  050c\051 using the features selected through classi\002cation error of C4.5 and 050d\051 using the all features extracted Results for the retrieval of the 5 most similar images from a query image are also provided in this experiment as illustrated in Figure 5 The image 5.\050a\051 is the query image taken from the mostly fatty image class Images shown in 5.\050b\051 are the 5 most similar images retrieved for the proposed 002tness function F cB  The row 050c\051 shows the results for C 4  5 classi\002er whereas 050d\051 illustrate the images resulting from all features 050no selection applied\051 In Figure 5 the images surrounded by dashed lines are false positives 050not relevant images\051 For this query the proposed method achieved the highest precision 050100%\051 when compared the results of C4.5 and the original feature vector 050precision of 40%\051 


6 Conclusions This work proposed a novel genetic feature selection framework for CBIRs It employs a wrapper strategy that searches for the best reduced feature set while optimizing 050or preserving\051 the quality of the solution From a ranking evaluation function three new 002tness functions namely F cA  F cB and F c have been proposed and evaluated in three experiments The proposed genetic feature selection approach which encompasses F cA  F cB and F c  has been compared with 050a\051 traditional methods found in the literature 050b\051 the StARMiner feature selector and 050c\051 the whole feature vector and signi\002cantly outperformed them The proposed approach has been able to optimize the accuracy of similarity queries while selecting a signi\002catively reduced number of features Additionally the proposal of combining the quality of the query results with the criterion of minimizing the number of selected features F cA and F cB  led to high accurate query answers while reducing the number of features more than the 002tness function F c  Therefore the 002nal processing cost of the queries is also reduced References  P  M d Aze v edo-Marques N A Rosa A J M T raina C Traina-Jr S K Kinoshita and R M Rangayyan Reducing the semantic gap in content-based image retrieval in mammography with relevance feedback and inclusion of expert knowledge International Journal of Computer Assisted Radiology and Surgery  3\0501-2\051:123\226130 June 2008  R Baeza-Y ates and B Ribeiro-Neto Modern Information Retrieval  Addison-Wesley Essex UK 1999  B Bartell G Cottrell and R Bele w  Optimizing similar ity using multi-query relevance Journal of the American Society for Information Science  49:742\226761 1998  O Cord 264 on E Herrera-Viedma C L 264 opez-Puljalte M Luque and C Zarco A review on the application of evolutionary computation to information retrieval International Journal of Approximate Reasoning  34:241\226264 July 2003  J G Dy  C E Brodle y  A Kak L S Broderick and A M Aisen Unsupervised feature selection applied to content-based retrieval of lung images IEEE Transactions on Pattern Analysis and Machine Intelligence  25\0503\051:373\226 378 March 2003  W  F an E A F ox P  P athak and H W u The ef fects of 002tness functions on genetic programming-based ranking discovery for web search Journal of the American Society for Information Science and Technology  55\0507\051:628\226636 2004  W  F an P  P athak and M Zhou Genet ic-based approaches in ranking function discovery and optimization in information retrieval a framework Decision Support Systems  2009  D E Golber g Genetic algorithms in search optimization and machine learning  Addison Wesley 1989  R L Haupt and S E Haupt Practical Genetic Algorithms  John Wiley  Sons New Jersey United States second edition edition 2004  J Horng and C Y eh Applying genetic algorit hms to query optimization in document retrieval Information Processing  Management  36:737\226759 2000  S K Kinoshita P  M d Aze v edo-Ma rques R R PereiraJr J A H Rodrigues and R M Rangayyan Contentbased retrieval of mammograms using visual features related to breast density patterns Journal of Digital Imaging  20\0502\051:172\226190 June 2007  F  K orn B P agel and C F aloutsos On the  dimensionality curse and the self-similarity blessing IEEE Trans on Knowledge and Data Engineering  13\0501\051:96\226111 2001  H Liu and L Y u T o w ard inte grating feature select ion algorithms for classi\002cation and clustering IEEE Transactions on Knowledge and Data Enginnering  17\0504\051:491\226502 April 2005  M X Ribeiro A J M T raina C T raina-Jr  and P  M Azevedo-Marques An association rule-based method to support medical image diagnosis with ef\002ciency IEEE Transactions on Multimedia  10\0502\051:277\226285 2008  U S Cancer Statistics W orking Group United states cancer statistics 1999-2005 incidence and mortality webbased report atlanta 050ga\051 Department of health and human services centers for disease control and prevention and national cancer institute 2009 Available in http://apps.nccd.cdc.gov/uscs   L T amine C C and M Boughanem Multiple query evaluation based on an enhanced geneticnext term algorithm Information Processing  Management  39\0502\051:215\226 231 2003  R S T orres A X  F alc 230 ao M A Gonc\270alves J P Papa Z B W Fan and E A Fox A genetic programming framework for content-based image retrieval Journal of the American Society for Information Science and Technology  42\0502\051:283\226292 2009  A Tsymbal P  Cunningham M P echenizkiy  and S Puuronen Search strategies for ensemble feature selection in medical diagnostics In Proceedings of the 16th IEEE Symposium on Computer-Based Medical Systems  pages 124\226 129 June 2003  A Tsymbal M Pechenizkiy  and P  Cunningham Sequential genetic search for ensemble feature selection In Proceedings of the International Joint Conferences on Arti\002cial Intelligence  pages 877\226882 August 2005  C.-M W ang a and Y F  Huang Ev olutionary-based feature selection approaches with new criteria for data mining A case study of credit approval data Expert Systems with Applications  36\0503 Part 2\051:5900\2265908 2009  H Y an J Zheng Y  Jiang C Peng and S Xiao Selecting critical clinical features for heart diseases diagnosis with a real-coded genetic algorithm Applied Soft Computing  8:1105\2261111 2008  T  Zhao J Lu Y  Zhang and Q Xiao Feature selection based on genetic algorithm for cbir In IEEE Congress on Image and Signal Processing  volume 2 pages 495\226499 2008 


     Figure 9. Argumentation Tree For Open GL  A1 The current system in flash does not have the functionality of dynamic allocation of particles like mine or clutter. It places them randomly  A1.1 That is not of much importance because it still gives a new position to mine and clutter particles A2 Current system in flash has faster response time as compared to system in Adobe Director A3 The current system doesnêt satisfy many of the features required for the new system like database A4 Adobe Flash cannot communicate with database A4.1 Flash doesnêt support database but database support is very important and critical A4.1.1 The system should be able to generate evaluation reports for trainee based on pr evious records stored in the database A5 Flash doesnêt create sound clips  A5.1 We donêt need sound creating features as the sys tem has to generate sound. We can play externally recorded sound files using Adobe Flash A6 Flash can provide good visual effects as compared to Adobe Director A7 The developer has good knowledge in development using Flash so the system can be developed quickly B1 We could reuse the system already developed for sound generation, as it is developed using Adobe Audition for analysis which is somehow related to Adobe Director B1.1 The current system is better synthesized in terms of sound production and the sound produced is also instantaneous rather than discrete B1.2 That current system has certain performance issues like slow response time B1.3 The current system in Adobe Director has the feature of producing dynamic coloring scheme on approaching a mine. This kind of scheme is highly preferable and is not present in Adobe Flash system B2 Adobe Director can provide more functionality as compared to the current flash system. E.g. Multiple sounds while detecting mines   B2.1 Adobe Director can provide better visual effects as compared to flash e.g. in case of GUIês   B2.2 A modified version of the current system in flash can also provide the same functionality B2.2.1 We cannot integrate code developed in other platforms with Flash, but Flash can be integrated in Adobe Director B3 The interface provided by flash is not professional enough. It is too simple and straight forward for doing more things in future   B4 Easily available plug-ins can help integrate the tracking system developed in C# with Adobe Director  B4.1 Code developed in Open GL/AL can also be integrated using Adobe Director using suitable stubs   B5 A new sound recognition algorithm is being developed in Adobe Audition which can be integrated with Adobe Director but not with Open GL or Flash Evidence supported B6 If the current system is reused; the project deadline can be met easily B7 The developer has very little experience in development using Adobe Director   B7.1 The developer can take help from the already developed system in Adobe Director C1 The tracking software already developed is coded in C#/NX5. We could reuse that and develop our system in Open GL/AL C1.1 Open GL has C# libraries which can be used to develop the system C2 Because the platform used is for high end application development, it can provide good GUI and database support C2.1 Open GL/AL can help us generate dynamic surfaces for mine detection and training which the original system in flash does not have C4 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C3 Open GL does not support connectivity with Adobe Audition. Adobe Audition is required for creating sound recognition algorithm C4 The time taken for developing the project using open GL will be comparatively more as the whole system would have to be developed from scratch C4.1 If Open GL has support for C# libraries, and then the system could be develope d faster as developer is quite familiar with programming languages like C 151 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        






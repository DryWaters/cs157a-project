Benefits of a Bayesian Approach to Anomaly and Failure Investigations William D Bjorndahl Northrop Grumman Space Technology One Space Park Redondo Beach CA 90278 bill bjorndahl ngc.com 
is often the case in failure and anomaly investi\255 gations that data is either limited or so wide ranging that it is difficult to bring focus to a key root cause For this reason a disciplined approach incorporating root cause trees Ishikawa Diagrams is usually taken to develop and track root cause hypotheses and analyses During the investigation statistical tools can be used to evaluate various hypotheses of failure 
Abstract-It 
However in many cases there is limited failure data and it is often necessary to set up accelerated life tests involving many samples in order to induce failures under controlled condi\255 tions so that a statistically significant population of failures can be obtained Root cause is sometimes achieved only af\255 ter extensive and expensive efforts to reduce the number of root cause hypotheses Other times root cause investigations are truncated to most probable cause based on the evidence available and expert opinion Bayesian analysis allows test or observation data to be com\255 bined with prior information to produce a posterior estimate of 
likelihood It can be a tool that provides a number of bene\255 fits to the root cause determination process The first benefit is to provide an estimate of the likelihood that certain hypothe\255 ses are true based on the limited data available This can pro\255 vide useful direction to the failure investigation For example it can provide an indication as to where more data collection might be valuable i.e tests of most likely hypothesis as op\255 posed to tests of all hypotheses in a root cause analysis It also can provide a way to assess the incremental impact of data as 
it becomes available to the decision making process Another benefit is to organize the logic once root cause has been determined that can lead to a more quantitative mea\255 sure of the likelihood of a future failure This latter benefit can help guide the decision making processes necessary for determining what corrective action if any might be neces\255 sary This paper provides an elementary introduction to a Bayesian approach to data analysis for anomaly and failure investiga\255 tions and provides a number of worked examples illustrating its utility 978-1-4244-2622-5/09/$25.00 2512008 IEEE 1 INTRODUCTION 
H 225\225\225 
a 
Root cause investigation is typically employed in the inves\255 tigation 
large amount of reliability and quality-control testing is needed in modem technology In some cases particularly in the aero-space field acquisition of a single data point can cost more than the yearly salary of a statistician Use of sta\255 tistical methods that fail to extract all the relevant informa\255 tion from a sample or fail to make use of relevant prior information is therefore not only illogical it can lead to stag\255 gering economic waste 1J 
of failures and anomalies One method is the use of a fishbone diagram Ishikawa diagram in an attempt to map out all the possible causes that may have led to an eventual failure or anomaly As the investigation proceeds data is col\255 lected and evaluated to determine whether or not a particular root cause is supported As more and more data is collected and perhaps more insightful experiments are conducted the potential root causes on the Ishikawa diagram are crossed out until only one remains During these investigations much data can be collected and often the analysis of the data is con\255 ducted with the 
intention of being able to come to precise conclusions This can sometimes lead to large sample sizes being evaluated for what may tum out to be ultimately un\255 likely root causes Analysis of data using Bayes theorem in order to improve de\255 cisions in situations where failures or defects have occurred is not new In fact many examples used in college level texts from the last half of the 20th century illustrate Bayes theo\255 rem using situations involving production defects and/or part supply chain defects For example Hadley 2 describes the case of a manufacturer trying to determine 
what the likeli\255 hood is that he has accepted a good or a bad lot based on a lot sample that contains a specified number of defects Mosteller Rourke and Thomas 3 give an example of trying to deter\255 mine which production machine likely produced a part that turns out bad More complex analysis can be performed as is illustrated by the separation of a signal from noise 4 In this particular case one might imagine a failure analysis where slight current increases might be separated out from the normal background and perhaps illustrate the initiation of a shorting event 


n E P H is given by the following equation which can be read as follows It is the probability that the hypothesis is true times the probability of event E occurring given that the hypothesis is true In equation 3 is called the likeli\255 hood and is the probability of event E occurring given that a particular hypothesis is true The denominator in equation 3 is a normalizing function The term on the left side of the equation is the posterior probability that the hypothesis is true given that event E has occurred and is the product of the prior probability times the likelihood divided by the normalizing function Examples will be give later however this simple illustration may help to clarify the concept Suppose that a component supplier has been collecting data from in-house tests that show the expected percentage of defective parts in each lot that they ship The supplier may keep this data in a discrete histogram format or they may try to fit the data to a continuous probability distribution For the purposes of the illustration this is the prior probability for a hypothesis that states given a particular lot the probability that a given per\255 centage of parts in this lot is defective is given by the data shown in a normalized histogram or fit to the continuous probability distribution Now suppose that a manufacturer buys a lot from the compo\255 nent supplier and conducts an in-house acceptance test on a sample of multiple parts drawn from the lot Given the num\255 ber of parts in the lot the number of parts in the sample and the number of failures in the acceptance test the manufac\255 turer calculates a probability distribution or likelihood for the expected percentage of discrepant parts in the lot purchased from the component supplier To give an even better esti\255 mate of the expected distribution of discrepant parts in the lot the manufacturer can use Bayes theorem to combine his data with the historical data the prior data from the part sup\255 plier The reader might ask why after lot testing the manu\255 facturer would need to combine the in-house acceptance data with the prior data As will be shown later the acceptance sampling scheme or plan unless all parts are tested only P E E    Hi    Equation 1 can be written Bayes rule is given by the following equation 3 Hi Hi Hi  I  I 2 is the probability of hypothesis i given that event E has occurred and n n P\(H i E 1 P\(H 1 P\(H i P\(EIH P Hi E i  is called the prior probability It is the probability that the hypothesis is true based on previously ex\255 isting information The term n nE P Bayesian analysis techniques can also be applied in other ways that are useful for evaluating data either gathered or generated during a failure investigation Many failure inves\255 tigations involve the assessment of what are considered to be normally distributed parameters Often an analysis of data involves calculating means and standard deviations of exper\255 imental or process control parameters When investigating failures since a process or material may not be exhibiting what is considered to be normal behavior it is probably more appropriate to think of the mean and variance as un\255 known parameters that each have a distribution associated with their true value Barrett and Green 5 and Gelman et al 6 provide a description of the Bayesian approach to this problem and later some examples are given using methods described by Albert 7 and implemented in R 8 which il\255 lustrate the utility of the approach While a traditional ap\255 proach to data analysis may get you to the same conclusions in process and material testing the use of a Bayesian ap\255 proach can I believe provide important insight focus and direction in failure investigations Although not addressed in this paper some investigators 9 10 5 have applied Bayesian analysis to failure data fol\255 lowing a Weibull distribution model in order to update relia\255 bility data and improve reliability estimation From a practi\255 cal standpoint the utility in a failure or root cause investiga\255 tion would be the incorporating of test results under acceler\255 ated life conditions in predicting future failure behavior For example consider the case of component failures during sys\255 tem verification testing Since the failures are fairly far down\255 stream from the component bum-in screens which should identify and remove a weak population and also downstream from assembly screen testing which should identify and re\255 move workmanship defects one is left with potential failure causes due to wear-out mechanisms gives a probability that the lot contains a given percentage or less of defects Knowledge of this percentage combined with the supplier's prior data can improve the manufacturer's knowledge concerning the expected number of defects in the lot In root cause investigations particularly when the failure of supplied parts must be considered as potential root causes the application of Bayesian analysis can prove to be valuable Later some examples will be provided to demonstrate this utility If assets are available the investigation team will want to investigate potential failure mechanisms by conducting tests that mimic the operating environment as closely as possible in terms of voltages currents temperature and duty cycle And if the tests are accelerated then the local technical ex\255 perts will want to ensure that they are accelerated within rea\255 sonable bounds of where the failure mechanism is likely to operate Also it would be desirable to add any pre-existing failure data to any failure data that is generated in testing as this data provides additional statistical evidence in determin\255 ing a cumulative failure distribution for the population of sus\(2 3 where 


0.30 0.05 2 0.70 0.15 Lot Sampling and an Available Discrete Prior Distribution 0.70 0.15 11  0.70  0.30 3 0.70 0.15 0.30 0.05 0.125 These new probabilities are called the posterior probabilities In effect available data Le the fall-out during burn-in at the supplier the likelihood that a failure will occur given that a part is from a specific supplier is multiplied with the prior probability which reflects the mix of resistors on hand that were available for the assembly process 70 from Supplier A and 30 from Supplier B The resulting products are then normalized to come up with posterior probabilities Compare this to an estimate without any prior knowledge of the burn-in drop-out at the supplier One would have estimated  1  1 Le the resistor came from Supplier A is true is 0.15 Similarly the probability of the event resistor failure given that is the failure of the resistor and there are two hypothesis with two different probabilities The first hypothesis is that the resistor came from Supplier A and the second hypothesis is that the resistor came from Supplier B The associated prior probabil\255 ities are 7 P H A simple example illustrating Bayes theorem follows Sup\255 pose that an assembly house obtains resistors from two sup\255 pliers Each of the suppliers subjects all resistors in a lot to a burn-in of 100 hours at elevated temperature and voltage stress If the burn-in fall-out is greater than 20 then the lot is failed It is known that Supplier A typically has a 15 fall\255 out in burn-in and Supplier B typically has a 5 fall-out in burn-in Since Supplier A typically charges less 70 of the resistors bought by the assembly house are from Supplier A The assembly house integrates the resistors into a higher level of assembly that then also goes through a burn-in This burn\255 in is at a slightly elevated temperature and is conducted for 300 hours During burn-in a resistor fails and before opening the unit up a parts materials and processes PM&P engi\255 neer makes an estimate of the probability that the resistor that failed came from Supplier A In this case the event 0.30 0.05 0.875 6 2 EXAMPLES lOne might question the use of the initial part-level bum-in yield in this situation as the initial bum-in should have screened out a number of workmanship-related defects that wouldn't then make it to an assembly-level bum-in However consider that the initial bum-in for both Supplier A and Supplier B reduces defects by a factor of 10 Using the yields for future assembly level bum-ins that this generates does not change the outcome of the calculations that are conducted since both the numerators and denomina\255 tors of the fractions are divided by the same number e.g 10 One might be more easily convinced that the calculations shown actually underestimate the difference between Supplier A and B since intuitively one might expect more downstream failures from Supplier A than from Supplier B because the initial bum-in yield was worse Now the PM&P engineer recognizes that the previously men\255 tioned burn-in yield history might also be helpful here Intu\255 itively the fact that Supplier A's resistors have a lower yield through the part level burn-in is an indication that they are less robust than Supplier B s resistors Therefore the engi\255 neer makes the assumption that the probability of the event Le resistor failure given that IE IE H 2 2 2  pect parts The results of the testing along with analysis can then be used to help determine a path forward U sing equation 3 the probability that the resistor came from either Supplier A or B can be calculated The examples that follow are realistic in that they describe situations that do arise in failure investigations The data upon which the examples are based are representative of real situations and not taken from any specific failure investiga\255 tion IE resistor came from Supplier B is true is 0.05 which is the fall-out at Supplier B during the initial burn-in P\(H HI E P\(H E P\(H P\(H 1  P\(H as 0.70 and as 0.30 One could extend this example a bit as was typically done in the references and texts like those listed above and perform a cost-benefits analysis of buying from Supplier B rather than A given that replacement costs on returned units are taken into account In another situation there is a failure of a capacitor on a board assembly that is only about a hundred hours into unit test Two similar failures had occurred in the previous three months and the capacitors which were of the same lot as the most recent failure were replaced Now however the pro\255 gram manager is worried that there may be a problem with the capacitor lot and is reluctant to continue manufacturing until a root cause is determined The PM&P engineer is asked to examine the available capacitor data and come back with an estimate as to whether the lot is good or bad The PM&P engineer recovers the lot data for the capacitor The capacitor comes from Supplier A and as part of the ac\255 ceptance tests a life test was conducted with 20 parts One failure was allowed and one failure did indeed occur The en\255 gineer also notes that the lot consisted of 1000 pieces The engineer is also curious about Supplier A's history in terms of delivering parts and asks the buyer to obtain information to that effect The buyer comes back with the following in\255 formation He tells the PM&P engineer that since Supplier A provides capacitors to customers with a wide range of re\255 quirements it is asked to perform a wide range of lot accep\255 tance tests and then to certify the results in a letter accom\255 panying the lot delivery They can't necessarily correlate pre\255 cisely the lot test results given the wide range of tests that they are asked to do however for their own benefit they do keep a tally in the following manner and with the following results Over the years they have found that 10 of the lots that they 4 5 


5 OC\(p P\(Y where 0.1 II L P\(Y P P 0.4 a 0.05 0.1 0.15 0.2 1 Operating Characteristic Curves for a lot size of kip N M a f 0.2 8 c depends on the kind of sampling that is done In the case of the life tests described above the samples would be taken 2Por the purpose of this exercise we won't pursue the question of what pro\255 portion of lots are scrapped but in a real situation that would be the next question to ask n=20 n  100 is the total lot size n is the sample size is the probability that the lot passes a specified sampling plan given that the proportion of defects in the population is p The acceptance number is c For ex\255 ample if a test of 20 parts is conducted and a single failure is allowed then the acceptance number is 1 The operating characteristic function is then the sum of the probability of observing no failures in the test sample plus the probability of observing one failure in the test sample given that the pro\255 portion of failures in the population is p The probability distribution function to use for 1000 II kip kip 0.9 is the number of failures in the lot and k is the number of failures within the tested sample 9 0.25 Figure kip n a a from the population and not replaced i.e not put back into the population after the completion of the test This is a case of sampling without replacement and the proper distribution to use would be the hypergeometric distribution which is Y  Y IV 0.3 k=O 0.7  0.5 or less The size of the sample taken from the lot without replacement is denoted by n The PM&P engineer now wishes to obtain a more quantita\255 tive number of the probability that the accepted lot was bad and uses Bayesian analysis to do so The prior probability is the historical fractional distribution data that the buyer has described The likelihood is the cumulative hypergeometric probability distribution shown for a sample size of 20 with 1 failure in Figure 1 The Bayesian analysis is summarized in Table 1 and illustrated in Figure 2 This figure illustrates that the likely lot fraction which was defective was higher than what was intended In fact by summing up the area below the normalized posterior defect probability distribution it is found that the probability that a good lot was accepted is only about 24 and the probability that a bad lot was accepted is about 76 After concluding the analysis the PM&P engineer explains to 4   parts and a rejection limit of where I L 1 L1 Lot Fraction Defective IV cf    For the two sample plan examples described above 100 sam\255 ples with a 5 failure limit and 20 samples with 1 failure limit the operating characteristic function was determined and the results are shown in Figure 1 After examining the operating characteristic curve for the lot sampling plan that his com\255 pany used 20 parts out of 1000 with 1 failure allowed the PM&P engineer realizes that there is a fairly good chance that the actual defect rate in the capacitor lot was higher than in\255 tended The PM&P engineer considers a lot of 1000 capacitors and two different acceptance schemes In the first scheme 100 capacitors are taken from the lot and put through a 1000 hour life test consisting of elevated temperature and voltage stress If greater than 5 of the capacitors fail then the lot is consid\255 ered to have failed In the second scheme 20 capacitors are removed from the lot and tested in a like manner If greater than one of the capacitors fails then the lot is considered to have failed Let us suppose that in both cases the lot passes It is a natural question to ask whether or not the acceptance of the sample might entail the acceptance of a lot which truly didn't meet the intended requirement of having 5 or less defects Intuitively one realizes that the more samples that are tested the less likely it is that one will make this er\255 ror To characterize this operating characteristic curves are constructed which provide the probability of accepting a lot given that a certain percentage of it is defective ship exhibit 5 or less defects during testing Thirty percent exhibit between 6 and 10 defects Forty percent show be\255 tween 11 and 15 defects and 20 show between 16 and 20 defects If a lot shows greater than 20 defects they scrap it 2 The PM&P engineer is somewhat surprised by the data in that it indicates that the quality of Supplier's A product is some\255 what variable and engages the buyer in more discussion The buyer says that although the variability in the quality of the lots from Supplier A appears to be high only those lots that meet the requirements of having fewer than 5  failures in the lot acceptance life test Le 0 or 1 failure out of 20 are shipped to the company's assembly line The buyer is com\255 fortable with the requirements and has no concern However the PM&P engineer is somewhat dubious and does further investigation into what the lot acceptance test really means 8 Following the exposition of Lindgren 11 the operating characteristic function is determined from Equation 0.8 0.6 


  Figure Lot Fraction Defective 3 Probability distribution for fractional lot defective from Supplier A after additional life testing has been con\255 ducted the program manager that the lot acceptance test plan likely did not adequately reflect the state of the purchased capacitor lot The program manager now has some data to make an as\255 sessment concerning the problem encountered on the produc\255 tion floor and is leaning toward recalling some product and performing remove and replace operations for assemblies still in manufacturing hopefully with a capacitor lot that had an improved lot acceptance test However because of the cost associated with the recall and remove-and-replace operations the program manager asks if anything else might be done to determine whether or not the capacitor lot was indeed truly bad The PM&P engineer thinks about this and and suggests that an additional life test be conducted to provide more infor\255 mation with which to make a decision The program man\255 ager asks how many capacitors from the lot would have to be tested and what kinds of results would be needed be\255 fore enough confidence could be gained that the capacitor lot demonstrated a likelihood of a 5  Normal Distributed Parameter with Both Mean and Variance Unknown Cumulative Hypergeometric Distribution n=l00 x=2 Prior Defect Probability for Supplier A Posterior Defect Probability 0.0 0.1 0.3 0.2 0.9 0.7 0.8 Figure I I I I o I I I I o I L 225 0.05 0.1 0.15 0.2 II II o 0 0.4 0.5 0.8 1.0 0.9 0.3 0.7 0.1 0.2 0.6 c Cumulative Hypergeometric Distribution n=20 x=l Prior Defect Probability for Supplier A Posterior Defect Probability 1.0 r----I I I r--Lot Fraction Defective  __._---___ 2 Prior and posterior probabilities for Supplier A with the lot acceptance test data of 1 failure in 20 As another example consider the case of a manufacturer who has recently experienced a number of failures in product test\255 ing The product that the manufacturer produces involves a number of processing steps and incorporates material from a number of suppliers In setting up the root cause diagram a number of possible failure mechanisms based on the nu\255 merous processes and potential changes in incoming material are proposed As part of the root cause investigation proce\255 dure the plant manager asks the engineering staff to gather as much data as possible from in-process checks and receiving material lot testing The plant manager knows that material lots vary in their 5 or less failure rate The PM&P engineer analyses the problem and determines that if 80 more parts are put into test for a total sample size of 100 parts when including the original lot acceptance test then with just one more failure the probability that the lot was good would rise to 88 Results of this analysis are shown in Figure 3 After consultation on the analysis and based on the cost of recall and other manufacturing costs the program manager decides for testing of 80 more parts In addition since the root cause has not been determined conclusively there is still a possibility that the lot is good and that there is another problem on the production line causing the defects Unfortunately the results are not good and the company has to implement a recall Note that in this example the PM&P engineer has not only used a Bayesian approach to evaluate the likelihood that the capacitor lot is good but he has also used the Bayesian ap\255 proach to determine the number of additional capacitors and allowable failures for further testing that if successful would lead to a different outcome A positive outcome would have had two implications First of all remove and replace opera\255 tions would not have been undertaken and secondly another root cause hypothesis for the production and test floor failures would have been needed The PM&P engineer is curious as to how the situation would have turned out had they ordered the capacitors from Supplier B The buyer provides the data shown in Table 2 It is appar\255 ent that Supplier B has a much tighter control on the qual\255 ity of the product than does Supplier A As the data bins are more finely divided it is also apparent that Supplier B does more than Supplier A in developing and keeping records of lot quality Had it been the case that Supplier B had provided the parts then the results as shown in Figure 4 would have resulted Note the influence of the prior lot data 0.5 c E Q 0.4 0.2 J 0.05 0.1 0.15 0.6 c Q 


Table 1 Combination of Supplier A Historical Data with Lot Sampling Information n=20 c=l Fraction of Probability of Acceptance Based Prior Defect Probability Probability of Acceptance x Posterior Defect Lot Defective on Lot Sampling Method for Supplier A Prior Defect Probability Probability 0 1.000 0.1 0.100 0.044 0.01 0.984 0.1 0.098 0.044 0.02 0.942 0.1 0.094 0.042 0.03 0.882 0.1 0.088 0.039 0.04 0.811 0.1 0.081 0.036 0.05 0.736 0.4 0.294 0.131 0.06 0.660 0.4 0.264 0.117 0.07 0.586 0.4 0.234 0.104 0.08 0.515 0.4 0.206 0.091 0.09 0.449 0.4 0.180 0.080 0.1 0.389 0.35 0.136 0.060 0.11 0.335 0.35 0.117 0.052 0.12 0.286 0.35 0.100 0.044 0.13 0.243 0.35 0.085 0.038 0.14 0.205 0.35 0.072 0.032 0.15 0.173 0.15 0.026 0.011 0.16 0.144 0.15 0.022 0.010 0.17 0.120 0.15 0.018 0.008 0.18 0.099 0.15 0.015 0.007 0.19 0.082 0.15 0.012 0.005 0.2 0.067 0.15 0.010 0.004 Total  2.254 1.000 Figure 4 Probability Distribution for Fractional Lot Defec\255 tive from Supplier B 0.2 0.15 ftI L'L C'---...\267 J2 2 0.2 0.05 0.1 0.6 2i 0.4 Fractional Lot Supplier B Fractional Distribution of Defective Bins Lots Supplier BLots 0 97 0.025 0.01 459 0.120 0.02 845 0.220 0.03 1032 0.269 0.04 568 0.148 0.05 427 0.111 0.06 205 0.053 0.07 165 0.043 0.08 43 0.011 0.09 0 0.000 0.1 0 0.000 Total 3841 1 Table 2 Supplier Bum-in Fall-out Data properties between different suppliers and also knows that over time even a constant supplier may not deliver a ma\255 terial with properties that are constant The plant manager also knows that processes are changed slightly on the floor to allow for the differences with incoming material property changes To roughly determine where the problem in the pro\255 cess stream might be data from a strength test that occurs halfway through the process is examined for any variation over time Because of the previously mentioned variability in the process and incoming materials the plant manager has an analyst look at the intermediate strength data as if the mean and the variance of the population were not known The idea would be that if a change has been noticed in the dispersion of the mean and variance parameters at the intermediate point o-+--a...Lot Fraction Defective o 6 J.I L a _l-:J 0.8 Cumulative Hypergeometric Distribution n=1oo c=5 _ Prior Defect Probability _ Posterior Defect Probability 


and the variance then the problem causing the failures is probably located up\255 stream of the testing rather than downstream and that knowl\255 edge helps to limit the scope of the investigation Table 3 shows two sets of strength data obtained from this test Two of the data sets come from records three months before prob\255 lems in acceptance test were observed and the other two sets of data are the most recently obtained For the purposes of the test strengths in excess of 300 Ibs were required so all were considered to have passed Table 3 Four Sets of Strength Values Determined at an Intermediate Step in the Fabrication Process Sets 1 and 2 come from data taken 3 months before failures were observed The data shown in Sets 3 and 4 were recently taken Set 1 Set 2 Set 3 Set 4 400 415 350 350 365 385 400 395 385 395 405 410 415 400 425 430 425 390 340 375 395 425 365 355 The approach that the analyst takes in analyzing the data is described by Gelman et al 6 A similar description of this problem has also been given by Barrett and Green 5 The joint posterior distribution The analysis is detailed in Albert 7 and makes use of the capabilities of R 8 to perform the calculations and generate the results The results of analysis are shown in Figures 5 through 8 Figures 7 and 8 which represent the most recent data show an increased dispersion of the variance and the mean for the strength values at this stage of the fabrication process Be\255 cause of this information the production line manager runs a few more tests and analyses to confirm that the difference exists and once confirmed decides to focus more attention in the investigation on potential root causes up-stream of the test 3 DISCUSSION For the examples concerning lot sampling and prior knowl\255 edge of a supplier's quality history the use of a Bayesian ap\255 proach in the investigation provided insight into a realistic probable failure cause It is interesting to consider the impli\255 cations for the particular manufacturer who was affected If the manufacturer had relied only on the lot sampling plan then what would have been the state of knowledge concerning the purchased lot Based on just the 20 piece sample alone the intuitive answer would be that the lot contains 5 defec\255 tive parts Taking into account the operating characteristic curve shown in Figure 1 one would realize that the proba\255 bility of passing the lot screen test is quite high even for lots with higher proportion of defects than what is desired This is called consumer's risk and can lead to a Type II error A Type II error is the error of accepting the hypothesis that a lot is good based on the lot sample test when in fact the lot is bad The operating characteristic curve gives the probability that the lot screen test will pass when there is a specified propor\255 tion of defects in the lot It would be nice to know what the sample test says about the proportion of defects in the lot This concern has been addressed by Graves et al 12 who define what they call a Bayesian consumer's risk This is the probability that a lot which is accepted will contain more than a designated level of defectives The determination of the Bayesian consumer's risk is essentially what was illus\255 trated previously when the area under the normalized poste\255 rior distribution shown in Figure 2 was determined in order to provide a probability of either a good lot 24 or a bad lot 76 To extract similar information from just the sampling test a uniform prior was assumed That is it was assumed that the probability of any specified proportion of defects within the lot population was equal to any other specified proportion of defects This seems reasonable as nothing a priori is known about the lot Using the sample data the hypergeometric dis\255 tribution n=20 c  1 gives the likelihood The results of this analysis show that after the sample test there is a 49 probability that the lot has more than 5 defects Although this sample test provided some information about the lot if the manufacturer had relied on it alone it would have been almost equally likely that a bad lot would be accepted as a good lot as defined by the desired defect proportion being less than 5 When the discrete prior information Supplier A history was considered the probability that a bad lot was accepted increased to 76 The use of Bayesian methodology highlighted the inadequacy of the lot acceptance testing and provided insight into the im\255 portance of understanding the quality of one's suppliers be\255 yond just the particular lot of items being procured In addi\255 tion it was seen that prior knowledge can be very beneficial in determining the path forward in a failure investigation When the program manager needed to understand how many more capacitors needed to be tested in the off chance that the pur\255 chased lot might actually be good the answer using Bayesian techniques was different in light of the prior information from the one that he would have gotten had only the particular lot in question been considered ly times the likelihood function The parameters of interest are the mean  2  a 2 225 7 p\(J.-l a 2 J.-l is proportional to a prior density 1 


It also is interesting to consider the different situation with Supplier B Supplier B more tightly controlled to lower de\255 fect proportions the lots that it supplied The prior data pro\255 vided more assurance that the accepted lot was good The comparison between the situations with Supplier A and Sup\255 plier B highlights the problem with particular lot sampling plans of not considering supplier history in the lot acceptance process For the example concerning the test failure of a manufac\255 tured item there was an opportunity using existing data to determine where more focus of the investigation should oc\255 cur In this case none of the test samples actually failed the in-line test however the observed dispersion in the variance and mean indicated that something upstream was providing more variance in the product This information gave the root cause investigation team an indication of where to apply more investigative resources 616 December 2005 11 B W Lindgren and G W McElrath Vienna Austria 2008 ISBN 3\255 900051-07 267\2670 9 Ronald E Giuntini and Michael E Giuntini Simulat8 ing a Wei bull Posterior Using Bayes Inference Data Analysis A Bayesian Tutorial R A Language and En\255 vironment for Statistical Computing Oxford University Press 2006 5 1 S Barrett and M A Green A Statistical Method for Evaluating Electrical Failures Macmillan third edition 1966 12 S B Graves D C Murphy and 1 L Ringuest Reeval\255 uating Producer's and Consumer's Risks in Acceptance Sampling 9\(3 1524-1530 July 1994 6 A Gelman lB Carlin H S Stem and D B Rubin Chapman Bill Bjorndahl is currently Director of Special Projects within Mission Excellence at Northrop Grumman Space Technology Bill attended Pierce Junior College in the San Fernando Val\255 ley and then UCLA where he obtained a B.S in Biochemistry and an M.S and Ph.D in Engineering Introduction to Probability and Statistical Decision Theory Pro\255 ceedings of the Annual Reliability and Maintainability Symposium 1996 30\(2 Computers indo Engng 54:612\255 http://bayes wustl.edu/etj/science pdf.html 1974 2 G Hadley Springer 2004 8 R Development Core Team 4 Holden-Day 1967 3 Jr Frederick Mosteller and Robert E K Rourke and George B Thomas Bayesian Data Analysis Probability Theory with Applications in Science and Engineering A Series of Informal Lectures Probability with Statistical Appli\255 cations E T Jaynes Bayesian Data Analysis CONCLUSIONS Some simple examples of the use of Bayesian analysis in fail\255 ure and anomaly investigations have been given They have illustrated the importance of considering prior information in determining answers to questions that typically come up dur\255 ing root cause investigations A Bayesian approach can pro\255 vide insight and point to fruitful directions in the pursuit of root cause REFERENCES IEEE Transactions on Power Delivery IEEE Transactions on Reliability pages 48-55 1993 10 Mark P Kaminskiy and Vasiliy V Krivstov A Sim\255 ple Porcedure for Bayesian Estimation of the Wei bull Distribution 1  Addison-Wesley 1961 4 D S Sivia and J Skilling R Foundation for Statistical  Introduction to Probability and Statistics Hall/CRC second edition 2004 7 Jim Albert 


Contour/Density plot for the mean and variance as determined from Set 3 data o o o o o g ro C\\I o o o o co o o o o o o o o o o o o o o g o o o to 8 Contour/Density plot for the mean and variance as determined from Set 4 data 9 v o o o C\\I o o o CX o o o o CO o o v o Q  o c ro  250 300 350 400 450 500 550 250 300 350 400 450 500 550 Mean Mean  I 250 300 I 350 o o o o o o C\\I o o o to o o o v o o o o o 5 Contour/Density plot for the mean and variance as determined from Set 1 data Figure Figure 7 Figure 250 300 350 400 450 500 550 Mean Mean CX o CX o 6 Contour/Density plot for the mean and variance as determined from Set 2 data 400 450 500 I 550 Figure g o g v o g C\\I 


an attribute specified for each transport channel TrCH and depending one limitation This limitation is that only one symbol In the special blocks description we also focused our attention parameters case where ensure the suitable end frame size which corresponds to the specified bit rate and the spreading factor After this Rate Matching RM is applied This process plays the key role in further procedures The matching ensure the right way for physical channels mapping and data processing After multiplexing all TrCHs into can be mapped onto we choose the size of transport block equal to 1280 bits Hence this step we can be eliminated from the system Next step in signal processing is presented by Frame segmentation element Figure 11 Example of pseudo code for radio frame segmentation module Frame segmentation should be done to we can avoid the presence of this procedure PhCH mapping process includes few items Data mapping Channelization and Scrambling As shown in the Figure 1 on SDR blocks work The step-by-step data exchange between one or more Coded Composite Transport Channels CCTrCH one or several PhCHs If one PhCH is used common and special blocks is presented in Figure 12 vi r fIJMT 4ooo o Figure 12 Data processing block scheme 10 READ module rfsegmentation DETERMINE number of frames SET input signal to particular input port IF number of frame more than 1 THEN EXTRACT first data bits of input bits sequence SET framel equals to input data bits PRINT length of framel EXTRACT next data bits of input bits sequence SET frame2 equals to next part PRINT length of frame2 EXTRACT last data bits of input data bits SET frameN equals to last data bits PRINT length of frameN SET output sequence equals to framel frame2 frameN ENDIF SET output port equals to output on two different modules for both chains spreading module for UMTS and IFFT256 for WiMAX Spread spectrum mechanism is the most important thing in whole signal processing chain of WCDMA PHY It is based on the Direct Sequence which provides the expending of one PhCH hence are calculated As ensures equality of the total bit rate after transport channel TrCH multiplexing to the total channel bit rate of the allocated dedicated physical channels PhCH The main parameter of the rate matching is on the upper layers During this step the determination of the spreading factor and the number of physical channels needed for the given number of TrCH we can map CCTrCH into Physical Channel but there is one CCTrCH we have we have to apply PhCH segmentation block In our system implementation we consider a QPSK mapping is used for Data Mapping in Physical channel mapping processing This scheme maps every two bits into signal END 1 E a result of fulfilling this step the correct form of TrCH multiplexing is selected that a bandwidth by unique channelization code This code should be generated by code-tree of orthogonal variable spreading factor OVSF codes Thus it guarantees the orthogonality between different channels during signal transmission 1 In OFDM chain the main role is played by IFFT256 that converts time domain presentation into frequency domain and provides orthogonal independency between adjacent subcarriers 4.3 Main Procedures between SDR blocks There are a set of inherent procedures in the system work which must be done during the signal transmission between SDR blocks 1 Verification the signal nature 2 Switching to particular signal path 3 Reconfiguration of the system according to required protocol scheme 4 Stepby-step signal processing 5 Signal transmission in the chosen mode These procedures present only basic process The BB processing which this paper is presented based more than 


This figure presents the data flow through main blocks that can be used a few times and special blocks that must execute only particular functions Here also Configurator of chain and Sequences library for WiMAX/UMTS modules are equipped First one is responsible for right construction of next processing path and second one stores necessary number of elements After signal verification system is reconfigured according to input data and with using the chosen protocol type The OUTPUT connects to radio link and then signal must be transmitted over one of six channel types And at the reception side we configure the receiver in relation to transmitted mode 5 HARDWARE PLATFORM SELECTION Current technologies in a hardware environment allow to test our system in real-time implementation There are a couple of DSP based platforms that can be selected for validation from Lyrtech Inc the Small Form Factor SFF Software Communication Architecture SCA Development the Small Form Factor SFF Softwaredefined Radio SDR Development Platform the Small Form Factor SFF Software-defined Radio SDR Evaluation Module 20 All these platforms are based on TMS320DM6446 DMP SoC from Texas Instruments 21 For the proposed SDR based system we chose the SFFSDR Evaluation board see Figure 13 as far as this platform supports WiMAX technology model based design tools accelerating prototyping implementation of all protocols layers for complete radio stacking extra boards operates with 297MHz ARM926EJ-s RISC CPU and 594MHz C64x DSP in sense of power management this module has MSP430 MCU Due to an availability of Virtex-4 SX35 FPGA from Xilinx 22 this module can perform implementation of full modem processing functions that is very important feature in meaning of multi-protocol architecture of our system We are able to vary our requirements to each protocol inside the same hardware structure Figure 13 SFF SDR development platform by Lyrtech 6 PROTOTYPING THE WiMAX/UMTS SYSTEM The WiMAX/UMTS system is implemented in high-level language as C with the class library The main accent was done on the correct form of the signal processing sequence The path for WiMAX or UMTS signal is determined in the beginning and system should verify its entity leads the system in a relevant direction The main goal of this software implementation is to check how our system can handle the input signal sequence The simulation was carried out for following parameters for each subsystem For UMTS we consider transport block with 1280 bits size frame size is 2400 bits channelization code with 16 chips sequence For WiMAX we generate the bit block is equal to 1280 bits however during channel coding operation this block is divided on turbo coding block that include 384 bits The size of turbo coding block forms from the block determination corresponding modulation type and number of subchannels During software verification we obtained that our proposed model can separate different paths subject to a type of an inter sequence in the software environment The framework of our WiMAX/UMTS system went through one scenario step and now we are directed to an extension of this model For the more detailed system visualization we integrate our C code modules into MATLAB library by means of proper dynamic linking libraries dll compiled by using the MATLAB C compiler Each block can be formed with extended parameters Modules with C code configurate the system work in a host This host implementation will present a prototype This prototype will help to analyze future real-time hardware implementation MATLAB prototype can also provide debugging of real system the result of real system must be equal to our MATLAB prototype Next step of the work development and verification is to implement it into the hardware platform based on DSP DSP based platform allows to organize signal processing in a digital presentation that serves SDR based part of our general system 7 CONCLUSIONS AND FUTURE WORK In this paper we considered the framework of WiMAX/UMTS baseband level system for mobile device in UL transmission direction We presented the different signal processing structures based on OFDM and WCDMA physical layer procedures Our research work is mainly devoted to developing the approach of seamless switching between different subsystems that can be realized by SDR technology implementation To this end we proposed a possible solution to allow coexistence of different data transmission technologies 11 


The position of SDR blocks in common UMTS/WiMAX architecture for mobile terminal was shown in this paper We presented the different blocks of each subsystem and have identified three blocks which can be implemented as common SDR blocks These blocks include channel coding module interleaver module and data mapping module We also demonstrated the work of our system in the software environment Next steps of the UMTS/WiMAX system development are preparation of the specification and implementation of all possible scenarios Each scenario will include particular blocks parameters and common description of main blocks But we have to be carefully in case of main blocks description because there are a plenty of features 8 ACKNOWLEDGMENTS We gratefully acknowledge the company Arslogica that kindly provided us the hardware support for our experimental studies 9 REFERENCES 1 A Samukic UMTS Universal Mobile Telecommunications System development of standards for the third generation Proc of 1998 IEEE GLOBECOM Conf Sydney AUS Nov 8-12 1998 vol.4 pp.19761983 2 N Fourty T Val P Fraisse and J.-J Mercier Comparative analysis of new high data rate wireless communication technologies From Wi-Fi to WiMAX Proc of the IEEE Autonomic and Autonomous Systems and International Conf on Networking and Services ICAS-ICNS 05 Oct 23-28 2005 pp.66-66 3 M Komara SDR Architecture Ideally Suited for Evolving 802.16 WiMAX AirNet Communications SDR Forum Exhibition 2004 4 I Held 0 Klein A Chen C.-Y Huang and V Ma Receiver Architecture and Performance of WLAN Cellular Multi-Mode and Multi-Standard Mobile Terminals Proc of 2004 IEEE VTC Fall Conf Los Angeles CA Sept 26-29 2004 vol 3 pp 2248 2253 5 IEEE Standard for Local and Metropolitan Area Networks Part 16 Air Interface for Fixed Broadband Wireless Access Systems 2004 6 R Weigel and L Maurer  D Pimingsdorfer A Springer RF Transceiver Architectures for W-CDMA Systems Like UMTS State of the Art and Future Trends Proc of the Intern Symp on Acoustic Wave Devices for Future Mobile Communication Systems Chiba JP March 5-7 2001 pp 25-34 7 P-W Fu and K.C Chen A Programmable Transceiver Structure of Multi-rate OFDM-CDMA for Wireless Multimedia Communications Proc of 2001 IEEE Vehicular Technology Conf VTC-Fall 2001 Atlantic City NJ Oct.7-11 2001 vol 3 pp 1942-1946 8 L Zhigang L Wei Z Yan G Wei A Multi-standard SDR Base Band Platform Proc of 2003 International Conference on Computer Networks and Mobile Computing Shanghai PRC Oct 20-23 2003 pp 461 464 9 C Moy A A Kountouris L Rambaud and P Le Corre  Full Digital IF UMTS Transceiver for Future Software Radio Systems  Proc of ERSA 01 Conf Las Vegas NV June 25-28 2001 10 3GPP TS 25.201 Physical layer general description 11 K.R Santhi and G.S Kumaran Migration to 4 G Mobile IP based Solutions Proc of International Conference on Internet and Web Applications and Services/Advanced International Conference Feb 2006 pp 76 76 12 S Zhu M Song Y Li J Song and F Ren Simulation platform of WCDMA based on software defined radio Proc of 2nd ACM International Conference on Mobile Technology Applications and Systems Nov 2005 pp 1-5 13 L Ma and D Jia The Competition and Cooperation of WiMAX WLAN and 3G Proc of 2nd International Conference on Mobile Technology Applications and Systems Nov 2005 pp 15 14 J Mitola III Software Radio Architecture ObjectOriented Approaches to Wireless Systems new ed Wiley New York 2004 15 R Seungwan 0 Donsung S Gyungchul and K Han Perspective of the next generation mobile communications and services Proc of IEEE 2004 Int Symp on Personal Indoor and Mobile Radio Communications PIMRC 2004 Barcelona SP 5-8 Sept 2004 vol.1 pp 643-647 16 E Biglieri Coding for Wireless Channels  Springer New York 2005 12 


17 3GPP TS 25.212 Multiplexing and channel coding FDD 18 IEEE Standard for Local and metropolitan area networks Part 16 Air Interface for Fixed and Mobile Broadband Wireless Access Systems Amendment 2 Physical and Medium Access Control Layers for Combined Fixed and Mobile Operation in Licensed Bands and Corrigendum 1 2006 pp 0_1 822 19 3GPP TS 25.211 Physical channels and mapping of transport channels onto physical channels FDD 20 Data sheet from Lyrtech Inc http available at htp c hwwkneopusff _.l/p.s/lrtehs _sr d21]D ateforomTdf 21 Data sheet from Texas Instruments http available at 22 Data sheet from Xilinx http available at httll/www.xilinx.com 23 L Hanzo W Webb and T Keller Singleand Multicarrier Quadrature Amplitude Modulation  Wiley New York 2000 titled Wireless and Satellite Communications  The research interests of Dr Sacchi are mainly focused on wideband mobile and satellite transmission systems based on space time andfrequency diversity multi-user receivers based on non conventional techniques neural networks genetic algorithms higher-order statistics-based receivers etc cross-layer PHY-MAC design and high-frequency broadband satellite communications He is currently local coordinator for University of Trento of research projects dealing with reconfigurable communication platforms based on MIMO techniques and space-time signal processing ICONA project funded by MIUR and with exploitation of W-band for broadband satellite communications WA VE programs funded by ASI Claudio Sacchi is author and co-author of more than 50 papers published in international journals and conferences and reviewer for international journals and magazines IEEE Transactions on Communications IEEE Transactions on Wireless Communications IEEE Communications Letters IEEE Transactions on Aerospace and Electronic Systems Electronics Letters Wireless Networks IEEE Communications Magazine etc Dr Sacchi is member of the Organizing Committees and Technical Program Committees of international conferences like ICIP ICC GLOBECOM ACM-MOBIMEDIA etc Claudio Sacchi is member of IEEE M'01 SM'07 BIOGRAPHIES Olga Zlydareva is a PhD student of the University of Trento Italy She obtained her Master degree in Design Electronics Systems with specialization in High Radio Frequency Devices from MATI Moscow State Aviation Technological University named after KE Tsiolkovsky Moscow Russia Her research interests have oriented on the Software Defined Radio Technology Wireless Technologies Cellular Technologies Tunable devices Multi-standard systems Multi-protocol systems Physical layer of mobile devices Reconfigurability and Reprogramming of mobile devices The recent research focuses on the development of the baseband level of multistandard mobile devices based on SDR technology Claudio Sacchi was born in Genoa Italy in 1965 He obtained the Laurea degree in Electronic Engineering and the Ph.D in Space Science and Engineering at the University of Genoa Italy Since August 2002 Dr Sacchi has been holding aposition as assistant professor at the Faculty of Engineering of the University of Trento Italy In 2004 he was appointed by the Department of Information and Communication Technology of the University of Trento as leader of the Research Program 13 


  14  Figure 5:  Site B1 Terrain horizon ma sk with 1 degree azimuth spacing  Figure 6:  Site B1 Terrain horizon mask with 1 de gree azimuth spacing, in e quatorial coordinates 


  15  Figure 7: Lunar South Pole Solar Illumination Yearly Average  Figure 8:  Lunar South Pole DTE Visibility Yearly Average 


  16  Figure 9: Lunar North Pole Sola r Illumination Yearly Average  Figure 10:  Lunar North Pole D TE Visibility Yearly Average 


  17  Figure 11: Site A1 Elevation Topography  Figure 12: Site A1 Yearly Average Solar Illumination and DTE visibility, Medium Resolution 


  18   Figure 13:  Site LB Te rrain Horizon Mask  Figure 14:  Theory and Computed values of Average Yearly Solar Illumination 


  19  Figure 15:  Theory and Computed values of Average Yearly DTE Communication  Figure 16:  Heliostat Mirror Design to Eliminate Cable Wrap 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



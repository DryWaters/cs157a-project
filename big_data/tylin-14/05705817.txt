   Mrs.K.Sumathi 1 Dr. S.Kannan 2 Mr.K.Nagarajan 3  1 Department of Computer Applications, K.L.N.C.I.T, Madurai 2 Department of Computer Science,DDE, Madurai Kamaraj University, Madurai 3 Chief Architect of Business Intelligence, Tata Consultancy Services, Chennai sumathirajkumar2006@rediffmail.com skannanmku@rediffmail.com http://in.linkedin.com/in/nagarajank Key words: Mining Maximal Frequent Itemsets ArrayGenMax An Array Based Approach for Mining Maximal Frequent Itemsets Abstract -Mining of frequent patterns is a basic problem in data mining applications. The algorithms which are used to generate the frequent patterns must perform efficiently. The objective was to propose a new algorithm which generates maximal frequent patterns in less time. We proposed an algorithm which was based on Array technique and combines a vertical tidset representation of the database with effective pruning mechanisms. It removes all the nonmaximal frequent itemsets to get exact set of MFI directly. It works efficiently when the number of itemsets and tidsets are more. The proposed approach has been compared with GenMax algorithm for mushroom dataset and the results show the proposed algorithm generates less number of candidate itemsets to find all MFIs. Hence, the proposed algorithm performs effectively and generates frequent patterns faster I. INTRODUCTION The association rule problem is a very important problem in the data-mining field with numerous practical 


applications, including consumer marketbasket analysis inferring patterns from web page access logs, and network intrusion detection. The association rule model and the support-confidence framework were originally proposed by Agrawal et al. [1,7,8,9,13,23,24]. Let I be a set of items we assume in the remainder of the paper without loss of generality I = {1,  , N we call X a k-itemset if the cardinality of itemset X is k Let database T be a multiset of subsets of I, and let support\(X X C Y. Informally, the support of an itemset measures how often X occurs in the database. If support\(X minSup, we say that X is a frequent itemset, and we denote the set of all frequent itemsets by FI. If X is frequent and no superset of X is frequent, we say that X is a maximally frequent itemset, and we denote the set of all maximally frequent itemsets by MFI. The process for finding association rules has two separate phases. In the first phase, we find the set of frequent itemsets \(FI database T. In the second step, we use the set FI to generate interesting patterns, and various forms of interestingness have been proposed. In practice, the first phase is the most time-consuming. Smaller alternatives to FI that still contain enough information for the second phase have been proposed including the set of frequent closed itemsets FCI [19, 21]. An itemset X is closed if there does not exist an itemset X such that X'C X and t\(X t\(X Y contain itemset Y. It is straightforward to see that the following relationship holds: MFI C FCI C FI. The set MFI is orders of magnitude smaller than the set FCI which itself is orders of magnitude smaller than the set FI Wherever there are very long patterns \(patterns containing many items to generate the entire set of frequent itemsets or closed itemsets . Also, there are applications where the set of maximal patterns is adequate, such as combinatorial pattern discovery in biological applications There is much research on methods for generating all frequent itemsets efficiently [ 5, 6,30] or just the set of maximal frequent itemsets [14,26,27,29]. When the frequent patterns are long \(more than 15 to 20 items 


and even FCI become very large and most traditional methods count too many itemsets to be feasible. Straight Apriori-based algorithms count all of the 2 k subsets of each k-itemset they discover, and thus do not scale for long itemsets. Other methods use lookaheads to reduce the number of itemsets to be counted. However, most of these algorithms use a breadth-first approach, i.e. finding all k-itemsets before considering \(k+1 approach limits the effectiveness of the lookaheads, since useful longer frequent patterns have not yet been discovered. Recently, the merits of a depth-first approach have been recognized The database representation is also an important factor in the efficiency of generating and counting itemsets Generating the itemset Z = \(X U Y Z t\(X Y support\(Z row layout, with the database organized as a set of rows and each row representing a transaction. The alternative vertical column layout associates with each item X a set of transaction identifiers \(tids X representation allows simple and efficient support counting 978-1-4244-5967-4/10/$26.00 2010 IEEE  II. RELATED WORKS The problem of mining frequent itemsets has been a topic of Intensive research. Since the number of such sets is huge, it is common and more efficient to restrict the search to closed item-sets, where a set is closed if all its supersets have strictly lower frequency in the database. The collection of frequent closed sets contains the same information as the overall collection of frequent item-sets but is much smaller. There is also a growing interest in mining structured data, such as graphs, and more generally multi-relational databases, and the notion of closed sets has also been imported to this richer setup. Another variation exist between mining in a single interpretation graph authors restrict the implication relation used in defining 


closures to range-restricted clauses only. In addition to these differences, the notion of a closed set can be coupled with a closure operator that takes a set and calculates its closure and there is more than one way to define such closures. The literature gives the impression that these different choices are unimportant and that algorithmic issues can be studied independently of the semantics. Our investigation shows that this impression is false and that semantics do matter. Methods for finding the maximal elements include All-MFS, which works by iteratively attempting to extend a working pattern until failure. A randomized version of the algorithm that uses vertical bit-vectors was studied, but it does not guarantee every maximal pattern will be returned Max Miner is another algorithm for finding the maximal elements. It uses efficient pruning techniques to quickly narrow the search. Max Miner employs a breadth first traversal of the search space; it reduces database scanning by employing a look ahead pruning strategy Depth Project finds long itemsets using a depth first search of a lexicographic tree of itemsets, and uses a counting method based on transaction projections along its branches. It returns a superset of the MFI and would require post-pruning to eliminate non-maximal patterns. FP growth uses the novel Frequent Pattern tree \(FP-tree structure, which is a compressed representation of all the transactions in the database Mafia is one of the recent methods proposed by Burdick D., M. Calimlim and J. Gehrke,[29] for mining the MFI Mafia uses three pruning strategies to remove non-maximal sets. The first is the look-ahead pruning first used in Max Miner. The second is to check if a new set is subsumed by an existing maximal set. The most important category of approaches in multi-relational classification is ILP \(Inductive Logic Programming probabilistic approaches are also popular for multirelational classification and modeling. The most important one is the probabilistic relational models PRM's handling relational data. PRM's can integrate the advantages of both logical and probabilistic approaches for knowledge representation and reasoning. An approach 


is proposed to integrate ILP and statistical modeling for document classification and retrieval Given this conceptual framework, we can describe the most recent approaches to the maximal frequent itemset problem. As a baseline, Apriori traverses the lattice in a pure breadth-first manner, discovering all frequent nodes at level k before moving to level \(k+1 support information by explicitly generating and counting each node. Max Miner performs a breadth-first traversal of the search space as well, but also performs look aheads to prune out branches of the tree. The look aheads involve superset pruning, using apriori in reverse \(all subsets of a frequent itemset are also frequent work better with a depth-first approach, but Max Miner uses a breadth-first approach to limit the number of passes over the database. Depth Project performs a mixed depth-first traversal of the tree, along with variations of superset pruning. Instead of a pure depth-first traversal Depth Project uses dynamic reordering of children nodes With dynamic reordering, the size of the search space can be greatly reduced by trimming infrequent items out of each nodes tail. Also proposed in Depth Project is an improved counting method and a projection mechanism to reduce the size of the database. The other notable maximal pattern methods are based on graph-theoretic approaches MaxClique and MaxEclat both attempt to divide the subset lattice into smaller pieces \(cliques these in a bottom-up Apriori-fashion with a vertical data representation. The VIPER algorithm has shown a method based on a vertical layout can sometimes outperform even the optimal method using a horizontal layout. Other vertical mining methods for finding FI are presented by Holsheimer and Savasere et al. The benefits of using the vertical tid-list were also explored by Ganti et al. GenMax is a backtrack search based algorithm which was proposed by Karam Gouda and Mohammed J. Zaki[32] for mining maximal frequent itemsets. GenMax uses a number of optimizations to prune the search space. It uses a novel technique called progressive focusing to perform maximality checking, and diffset propagation to perform fast frequency computation III. PROPOSED APPROACH 


The proposed approach focuses on Mining Maximal Frequent Itemset Generation. In this paper, Array based approach and Effective Pruning Mechanism is used for generating Maximal frequent patterns There are two main ingredients to develop an efficient MFI algorithm. The first is the set of techniques used to reduce the size of search space, and the second is the representation used to perform fast frequency computations. This paper describes how proposed algorithm achieves the same  In general the structure of the transactional database may be in two different ways -Horizontal data format and Vertical data format. Here, we are using vertical data format for storing the transactions in the database. In vertical data format, the data is represented as item-tidset format, where item is the name of the item and tidset is the set of transaction identifiers containing the item Consider our example database which includes six different items, I = {A, B, C, D, E, F} and six transactions T= {1, 2, 3, 4, 5, 6}. The vertical data format of the database DB is given below Table 1 : Vertical Data format of the transactional database DB All Frequent items are extracted first. The support is directly given by the number of transactions in the tidset of each item. Let us consider the minimum support to be 3 From the above structure, all items except F are frequent The items A, B, C, D and E are frequent items and will be considered to next level In the next level a dynamic array \(N intersecting the tidsets of every two frequent items. The constructed array \(N two frequent items. The size of the array will be n\(n+1 where n is the number of frequent items. Value of each and every cell in the array is initialized to zero. The value of cell N[i,j] is 1 if number of transaction occurred in the intersection of tidset of frequent item i and j satisfies the user specified minimum support. Otherwise the cell value is zero. Once the array is constructed successfully, all possible Maximal frequent itemsets\(PMFI from the array. The constructed array is given below N ABCD 


E D C B  Table 2: Dynamic array \(N frequent items The possible maximal frequent itemsets \(PMFI obtained from this array are considered to the next level All the other itemsets are pruned. The number of possible large itemsets is less than or equal to number of frequent itemsets. From this array, PMFIs are obtained in two ways. We can take all columns and first row. \(Columns A B, C, D and row E Rows E D, C, B and Column A One column entry or one row entry is a single PMFI. For example the itemset \(x,y,z itemset if and only if there is an entry 1 in both cells N[x,y] and N[x,z]. For example ADC is a PMFI because of the values of both cells N [A, D] and N [A, C] is 1 Once all PMFIs are retrieved from the array, they are arranged in descending order with respect to their size First column entries produce the PMFI that includes the frequent item A \(ADC the PMFI includes the frequent item B \(B entries produce the PMFI that includes the frequent item C CDE the frequent item D \(D PMFI that includes the frequent item E \(EC are arranged in descending order with respect to their size So the Itemsets in PMFI are ADC, CDE, EC, B, D The First itemset ADC has no superset in MFI and it is frequent. So ADC is a MFI\(with support count 3 added to MFI The Second itemset CDE has no superset in MFI and it is a infrequent item set. so all \(n-1 includes C CDE are generated. 2-itemsets of CDE are CD and CE.\(DE is not taken for test. It does not include the item C ignored. CE is frequent and it has no supersets in MFI. So it is added to MFI. CE is a MFI\(with support count 3 obtained from CDE 


The Third itemset EC is already included in MFI and it is ignored The Forth item B has no superset in MFI and it is a frequent item and it is added to MFI The Fifth item D has a superset in MFI and it is ignored From above example, MFIs with support count 3 are ADC, CE, B The process will be continued till testing all possible maximal frequent itemsets. The pruning can be done while finding the MFI itself, but not after finding FI completely The pseudo code for proposed algorithm is given below in figure 1  Item  Tidset A  T1, T2, T3, T4 B  T1, T4, T5 C  T1, T2, T3, T5, T6 D  T1, T2, T3 E  T2, T4, T5, T6 F  T6, T5    Pseudo code Find All MFI\(PMFIs,min_sup all Maximal Frequent Itemsets Inputs i Possible Maximal Frequent itemsets ii for mining process Interfacing Functions Output i Find All MFI\(PMFIs, min_sup For each x  PMFIs if x has a superset in MFI continue else if x is frequent MFI=MFI U x else Find MFI by obtaining Permutations\(x,min_sup For End return MFI 


Find MFI by obtaining Permutations \(PMFI, min_sup Function to find Maximum Frequent Itemsets form Kitemsets of PMFI Inputs i ii defined for mining process Interfacing Functions Figure 1. Pseudo code for ABMFI Algorithm Output i Find MFI by obtaining Permutations \(PMFI, min_sup n=number of items in PMFI k=n-1; // k-itemsets Freq_item={}; S={}; do In_Freq=0; //to check infrequent itemsets C=generate k-itemsets that includes first item of PMFI; Foreach x C if x has a superset in MFI S=S U x; continue; else if x is frequent Freq_item=Freq_item U x; else In_Freq=1; For End; If PMFI==unique\(Freq_item U S MFI=MFI U Freq_item; return; End if; K--; while\(In_freq!=0 && k!=0 The proposed algorithm performs better because MFI is being calculated directly before computing FI completely The Pruning mechanism works effectively and counting is not performed for the subset of MFIs. So, the time taken to compute MFI is negligible. As we are following vertical data format, support also need not be calculated separately In this case, support is directly given by the number of transactions in the tidlist of each FI. The vertical representation has the following major advantages over the horizontal layout: Firstly, computing the support of itemsets is simpler and faster with the vertical layout since it involves only the intersections of tidsets. Secondly, with the vertical layout, there is an automatic reduction of the database before each scan in that only those itemsets that are relevant to the following scan of the mining process are accessed from disk Pruning The Possible Maximal Frequent itemsets\(Maximal 


Candidate Itemsets array. All Maximal frequent itemsets are obtained from only these PMFIs. Other itemsets are pruned automatically. The pruning can be done while finding the MFI itself, but not after finding FI completely. The proposed approach applies superset checking to eliminate the non maximal frequent itemsets. Once all PMFIs are generated, each PMFI is checked whether it is a subset of any maximal pattern. If so the itemset is eliminated entirely. Counting is not performed for this itemset and next PMFI is taken for test IV. RESULTS The testing of the proposed algorithm has been carried out on the real dataset \(containing long itemsets the number of candidate itemsets taken by the proposed algorithm to find MFIs and it is compared to Genmax algorithm for various values of minimum support. The support is varied from 75 to 95. The proposed algorithm had been compared with GenMax algorithm and results show the proposed approach generates less number of candidate itemsets to find all MFIs Figure 2 illustrates that, the proposed approach generates less number of candidate itemsets and produces all MFIs very quickly than GenMax algorithm. Support is taken as x axis and the number of candidate itemsets taken to find all MFI is taken as y axis For Mushroom, the improvement is best explained by how the MFI is computed at each level and found directly without waiting for FI completely. This leads to a much greater reduction in the overall search space, since the reductions is so great at highest levels  Figure 2. Number of Candidate itemsets taken by ABMFI and GenMax Algorithm from Mushroom dataset This approach will be working very efficiently for any sparse and dense dataset, when the size of maximal frequent itemsets is close to the number of frequent itemsets V. CONCLUSION In this paper we have investigated an array based approach and algorithm \(ABMFI itemsets. The algorithm is straight forward  basic steps are finding frequent items from the database, Dynamic 


array construction and Pruning infrequent itemset obtaining Possible Maximal Frequent itemsets from array and finding MFIs from PMFIs. Our algorithm had been compared with GenMax algorithm and obtained that the proposed algorithm generates less number of candidate itemsets to find all MFIs. The vertical data format representation of the database, Dynamic array construction and directly computing MFIs from PMFIs are the added advantages of this algorithm REFERENCES 1]. Agrawal, R., T. Imielinski and A. Swami, 1998. Mining association rules between sets of items in very large databases In the Proceedings of the ACM SIGMOD International Conference on Management of Data, May 25-28, Washington D.C., US, pp: 207-216. http://doi.acm.org 10.1145/170035.170072. [2]. Jiawei Han and Micheline Kamber, 2001. Data Mining: Concepts and Techniques. 1st Edn., Morgan Kaufmann pp: 500. ISBN-10: 1558604898. [3 Ganti, V., J. Gehrke and R. Ramakrishnan, 2000. DEMON mining and monitoring evolving data. ICDE 2000, San Diego CA., pp: 439-448. http://wwwdb.cs.wisc.edu/dbseminar/spring00 / talks/demon_paper.pdf [4 Holsheimer M., M. Kersten, H. Mannila and H. Toivonen, 1995 A perspective on databases and data mining. Proceeding of the 1st International Conference on Knowledge Discivery and Data Mining, Aug. 1995, AAAI Press, Montreal, Canada, pp 150-155, http://www.cs.helsinki.fi/ research fdk/datamining/pubs/kdd95.ps.gz [5]. Savasere, A., E Omiecinski and S. Navathe, 1995.An efficient algorithm for mining association rules in large databases. Proceedings of 21 st International VLDB Conference on Very Large Data Bases, Sep. 11-15, Morgan Kaufmann Publishers Inc. San Francisco, CA, USA ., pp:432-444 http://portal/acm.org/citation.cfm?id=673300 [6]. Ramesh C Agarwal, Charu C. Aggarwal and V.V.V. Prasad, 2001. A tree projection algorithm for generation of frequent itemsets. J Parallel Distribut. Comput., 61: 350-371. DOI: 10.1006 jpdc.2000.1693 [7]. Agrawal, R. H. Mannila, R. Srikant, H Toivonen and A.I. Verkamo, 1996. Fast Discovery of Association Rules. In: Advances in Knowledge Discovery and Data Mining, Usama Fayyad, M.G.P. Shapiro, P. Smyth, and R 


Uthurusamy,\(Eds pp: 307 -28 I. SBN:0-262-56097-6 [8]. Aggarwal, C.C. and P.S Yu, 1998. Mining large itemsets for association rules. Bull IEEE Comput. Soc. Technical Committee Data Eng.,: 23-31 http://citeseerx.ist.psu.edu/viewdoc/summary?doi 10.1.1.48.306 [9]. Aggarwal, C.C. and P.S. Yu, 1998. Online generation of association rules. In Proceedings of the 14th International Conference on Data Engineering, Feb. 23-27,IEEE Xplore, Orlando, FL, USA., pp: 402-411. DOI 10.1109/ICDE.1998.655803 [10]. Mohammed J. Zaki, 2000 Scalable algorithms for association mining. IEEE Trans. Knowl Data Eng., 12: 372 390. DOI: 10.1109/69.846291. [11]. Shenoy, P., J. Haritsa, S. Sudarshan, G Bhalotia, M. Bawa and D. Shah, 2000. Turbo-charging vertical mining of large databases. Proceeding of ACM SIGMOD International Conference on Management of Data, June 2000, Dallas, Texas USA,pp:22-33.http://doi.acm.org/10.1145/ 335191.335376 [12 Gunopulos, D., H. Mannila and S. Saluja, 1997. Discovering all most specific sentences by randomized algorithms. In Proceedings of the 6 th International Conference on Database Theory, Jan. 08-10, Springer-Verlag London, UK pp:215-229. http://portal.acm.org/citation.cfm? id=65 6097 [13]. Agrawal, R and R. Srikant, 1994. Fast algorithms for mining association rules Proceedings of the 20th International Conference on Very Large Databases Sep. 12-15, Santiago de chile, Chile, pp: 487-499. DOI: 10.1.1.40.7506. [14 Lin, D.I. and Z.M. Kedem, 1998. Pincer search: A new algorithm for discovering the maximum frequent sets. In Proceedings of the 6 th International Conference on Extending Database Technology, Mar. 23-27, Springer-Verlag London, UK.,pp:105-119. http://portal.acm.org/citation.cfm id=645338.6503 96. [15]. Park, J.S., M.S. Chen, P.S. Yu, 1995. An effective hash based algorithm for mining association rules. ACM SIGMOD Record 24: 175-186. http://doi.acm.org/10.1145/ 68271.223813 [16]. Rin Popescul and Lyle H. Ungar and Steve Lawrence and David M. Pennock 2002. Towards structural logistic regression: Combining relational and statistical learning. In Proceedings of KDD2002 Workshop on Multi-Relational Data Mining 02, ACM, Alberta, Canada, pp: 130-141 http://citeseerx.ist.psu.edu/ viewdoc/summary?doi=10.1.1.19.6235 [17 Taskar, B., E. Segal and D. Koller, 2001. Probabilistic classification and clustering in relational data. In Proceedings of the 17 


th International Joint Conference on Artificial Intelligence 01, Lawrence Erlbaum Associates Ltd USA.,pp:870-876 http://direct.bl.uk/bld/PlaceOrder.do?UIN=107907 71&ETOC=RN&from=searchengine 18]. Dunkel, B. and N. Soparkar, 1999. Dataorganization and access for effcient data mining. In the Proceedings of the 15th International Conference on Data Engineering, Mar. 23-26, IEEE Xplore, Sydney, NSW, Australia, pp 522-529. DOI: 10.1109/ICDE.1999.754968 [19]. Mohammed Zaki, J. and C.J Hsiao, 2002. CHARM: An efficient algorithm for closed itemset mining. In Proceedings of SDM02Conference http://citeseerx.ist.psu.edu/viewdoc /summary?doi=10.1.1.111.520 20]. Bastide, Y., R. Taouil, N. Pasquier, G. Stumme and L. Lakhal, 2000 Mining frequent patterns with counting inference. ACM SIGKDD Explorations Newsletter,2:66-75. http://doi.acm.org/10.1145 /380995 381017 [21]. Pasquier, N., Y. Bastide, R. Taouil and L. Lakhal, 1999 Discovering frequent closed itemsets for association rules. In Proceedings of the 7 th International Conference on Database Theory,Jan. 10-12 Springer-Verlag London, UK., pp:398-416. http://portal acm.org/citation.cfm?id=645503.656256 [22]. Getoor, L., N. Friedman, D Koller and B. Taskar, 2001. Learning probabilistic models of relational structure. In Proceedings of International Conference on Machine Learning ICML'01 177.http://direct.bl.uk/bld/PlaceOrder.do?UIN=100556 121&ETOC=RN&from=searchengine [23]. Zaki, M.J., S Parthasarathy, M. Ogihara and W. Li, 1997. New algorithms for fast discovery of association rules. In Proceeding of the 3 rd International Conference on Knowledge Discovery and Data Mining 97, AAAI Press, pp: 283-286 http://citeseerx.ist.psu.edu/viewdoc/summary?doi 10.1.1.42.5143 [24]. Zaki, M.J., 2000. Generating non-redundant association rules. In Proceedings of the 6th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Aug. 20-23, Boston, Massachusetts, US., pp: 34-43 http://doi.acm.org/10.1145/347090.347101 [25]. Ganter B. and R. Wille, 1999. Formal Concept Analysis: Mathematical Foundations. 1st Edn., Springer-Verlag, USA., pp 284. ISBN-10: 3540627715 


26]. Gouda, K. and M.J. Zaki, 2001. Efficiently mining maximal frequent itemsets. In the Proceedings of International Conference on Data Mining, Nov 29-Dec. 02 2001, IEEE Computer Society Washington, DC, USA., pp 163-170. http://portal.acm.org/citation. cfm?id = 645496.6580 47&coll=GUIDE&dl=GUIDE [27]. Bayardo, R.J., 1998. Efficiently mining longpatterns from databases. In the Proceedings of the 1998 ACM SIGMOD International Conference on Management of Data, Seattle, June 001-04 Washington, United States, pp: 85-93 http://doi.acm.org/10.1145/276304.27631 [28]. Gunopulos, D., H. Mannila and S. Saluja, 1997. Discovering all the most specific sentences by randomized algorithms. In Intenational Conference on Database Theory, Jan 08-10, Springer-Verlag London,UK.,pp:215-229 http://portal.acm.org/citation.cfm?id=645502.6560 97 [29]. Burdick D., M. Calimlim and J. Gehrke, 2001. MAFIA: A maximal frequent itemset algorithm for transactional databases. In International Conference on Data Engineering, Apr. 02-06, IEEE Computer Society Washington, DC, USA pp:443-452 http://portal.acm.org/citation.cfm?id=645484.6563 86&coll=GUIDE&dl=GUIDE. [30]. Agrawal, R., C. Aggarwal and V Prasad, 2000. Depth first generation of long patterns. In the Proceedings of the 6th ACM SIGKDD international Conference on Knowledge Discovery and Data Mining, Aug. 20-23, Boston, Massachusetts, United States, pp: 108-118. http://doi.acm.org/10.1145/347090.347114 31]. A.M.J. Md. Zubair Rahman and P. Balasubramanie,2008 Kongu Engineering College, Perundurai, Tamilnadu, India An Efficient Algorithm for Mining Maximal Frequent Item Sets [32]. Karam Gouda and Mohammed J. Zaki, 2005. GenMax: An Efficient Algorithm for Mining Maximal Frequent Itemsets. In the Proceedings of the Data Mining and Knowledge Discovery, 11, 120, 2005. [33]. Han, J., J. Pei and Y. Yin, 2000. Mining frequent patterns without candidate generation In the Proceedings of the 2000 ACM SIGMOD International Conference on Management o f Data, May 15-18, Dallas, Texas, United States, pp 1-12 http://doi.acm.org/10.1145/342009.335372 


experts can start their ore deposits estimations with much clearer data which is easier to deal with XII. CONCLUSION We have presented how data mining can be applied to the borehole data coming from active mine area. We are certain that data mining has a huge potential for other types of borehole data. One of the important steps in data mining is the preparation of data into useful form for various algorithms. Together with domain experts we have identified a way for transforming data to a form acceptable to k-NN classification and association rules mining algorithms Although we have shown how the k-NN classification and association rules mining techniques can be applied here this framework will open new possibilities to perform other data mining tasks to this type of data. Our experimental results are very promising in this regard as they show that we are not only able to match the accuracy of the results with IDW method used in the mining industry, but also exceed it \(93.1% accuracy was obtained by 3-NN method while IDW gave 88.5% accuracy rules as a separate analysis tool can improve not only k-NN classification results but also IDW interpolation results. This is particularly important for convincing mining companies 119 of the benefits of data mining, as with a little effort they can improve the method they are already using As we have shown in this paper, not only choosing right classification techniques can help us to improve interpolation, but more general analysis on data like association rules can contribute a lot. Thus, the more knowledge we have on the hidden relationships and patterns the more accurately you can construct an interpolation. Moreover, discovering hidden correlations not only important for this task, but also can contribute to understanding about complex geological processes that this specific area undergone. Therefore data mining, which can discover useful knowledge purely from data is of great importance and will be area of research for next generation of exploration and mining specialists Finally, we have proposed to use mathematical morphology for filtering the results of rock type interpolation. In the example given here, we have seen that it performed well in removing relatively small objects and filtering out large 


areas of interest from rock types XIII. FUTURE WORK This paper provides a framework for using data mining techniques on the borehole data. Using this framework we would like to investigate possibilities of using other classification techniques on this type of data. We mentioned that borehole data can contain more information about the area besides spatial coordinates, rock types and metal grades so classification that utilizes this extra information will be on our immediate research agenda Application of mathematical morphology provides possibilities for further research on domaining \(filtering out large areas of interest be given also to this ACKNOWLEDGEMENT I want to thank the Director of the WH Bryan Mining and Geology Research Centre, at the University of Queensland Professor Alan Bye and his PhD student Mr Younes Fadakar Alghalandis for contributing their expertise to this research This work is supported by the AuScope National Collaborative Research Infrastructure Strategy by the Australian Commonwealth, the Queensland State Government and The University of Queensland REFERENCES 1] A. G. Journel and C. J. Huijbregts, Mining geostatistics Academic Press, London, 1978 2] D. Shepard, A two-dimensional interpolation function for irregularly-spaced data, in Proc. ACM Annual Conference 1968, pp. 517524 3] C. Caruso and F. Quarta, Interpolation methods comparison Computers Math. Applications., vol. 35, pp. 109126, 1998 4] K. Gibert, M. S?nchez-Marre`, and I. Rodr?guez-Roda, Short communication: Gesconda: An intelligent data analysis system for knowledge discovery and management in environmental databases, Environ. Model. Softwares, vol. 21, no. 1 pp. 115120, 2006 5] A. R. Solow, Mapping by simple indicator kriging, Mathematical Geology, vol. 18, no. 3, pp. 335352, 1986 6] M. Armstrong, Problems with universal kriging, Mathematical Geology, vol. 16, no. 1, pp. 101108, 1984 7] N. Roussopoulos, S. Kelley, and F. Vincent, Nearest neighbor queries, in Proc. SIGMOD Conference, 1995, pp. 7179 


8] M. Ankerst, H.-P. Kriegel, and T. Seidl, A multistep approach for shape similarity search in image databases, IEEE Trans Knowl. Data Eng., vol. 10, no. 6, pp. 9961004, 1998 9] K. S. Beyer, J. Goldstein, R. Ramakrishnan, and U. Shaft When is nearest neighbor meaningful? in Proc. of Database Theory - ICDT 99, 7th International Conference 1999, pp. 217235 10] P. Ciaccia and M. Patella, Pac nearest neighbor queries Approximate and controlled search in high-dimensional and metric spaces, in Proc. of ICDE, 2000, pp. 244255 11] X. Wu, V. Kumar, J. Quinlan, J. Ghosh, Q. Yang, H. Motoda G. McLachlan, A. Ng, B. Liu, P. Yu, Z.-H. Zhou, M. Steinbach, D. Hand, and D. Steinberg, Top 10 algorithms in data mining, Knowledge and Information Systems, vol. 14, no. 1 pp. 137, 2008 12] X. Cheng, R. Dolin, M. O. Neary, S. Prabhakar, K. Ravikanth D. Wu, D. Agrawal, A. El Abbadi, M. Freeston, A. K. Singh T. Smith, and J. Su, Scalable access within the context of digital libraries, in Proc of ADL, 1997, pp. 7081 13] C. Faloutsos, M. Ranganathan, and Y. Manolopoulos, Fast subsequence matching in time-series databases, in Proc. of SIGMOD Conference, 1994, pp. 419429 14] F. Korn, N. Sidiropoulos, N. Faloutsos, E. Siegel, and Z. Protopapas, Fast nearest neighbor search in medical image databases, in Proc. of VLDB, 1996, pp. 215226 15] T. Kahveci and A. K. Singh, Efficient index structures for string databases, in Proc. of VLDB, 2001, pp. 351360 16] M. Ankerst, G. Kastenmuller, H.-P. Kriegel, and T. Seidl Nearest neighbor classification in 3d protein databases, in Proc of International Conference on Intelligent Systems for Molecular Biology, ISMB, 1999, pp. 3443 17] R. Agrawal and R. Srikant, Fast algorithms for mining association rules in large databases, in Proc of VLDB, 1994 pp. 487499 18] B. Liu, W. Hsu, and Y. Ma, Integrating classification and association rule mining, in Proc of KDD, 1998, pp. 8086 19] J. Serra, Image Analysis and Mathematical Morphology Orlando, FL, USA: Academic Press, Inc., 1983 120 


http://datamining.buaa.edu.cn/TopKCos.pdf 14] M. Zaki, Scalable algorithms for association mining, TKDE, vol. 12, pp. 372390, 2000 


enhance item-based collaborative filtering, in 2nd IASTED International Conference on Information and Knowledge Sharing, Scottsdale, Arizona, 2003 476 2010 10th International Conference on Intelligent Systems Design and Applications 


Basi Association Rles Basi c  Association R u les Association is basically connecting or tying up occurrences of Association is basically connecting or tying up occurrences of events Ol dib t f ilt t O n l y d escr ib e se t s o f s i mu lt aneous even t s Cannot describe patterns that iterate over time e g  itemset a  0  b  0  g    Eg If you sense higher data rates on the downlink than normal AND New Route generated Implies high chances of Intrusion AND New Route generated Implies high chances of Intrusion Associative IDS for NextGen Frameworks Dr S Dua LA Tech 20 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



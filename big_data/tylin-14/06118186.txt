 exists in an  resulting in \215data rich while knowledge poor\216 220 databases and file de facto 003\004  of  jianxin.jiao@me.gatech.edu 003\004 005 strive to quickly develop families of customized products while using the available design and manufacturing capabilities. As stated in e.g  3, 4  o st of th e rep o rted stu d ies on produ ct f a m i l y  development are centered on two issues: 1\e design of physical components and their relationships and 2\ the articulation of customer needs and the subsequent transformation of these needs to the required functions Moreover, these studies assume design technologies predetermined, thus not addressing technology selection and the determination of technology details \(e.g., technology attributes, attribute values  In accordance with various individualized customer requirements, there are large volumes of function and technology data existing in firms 002 006 Definition 3 i.e   and I.  INTRODUCTION   In product development, design technologies deliver product functions by providing solution principles and determine the design of products and their components 1 In practice, it is not uncommon that multiple technology alternatives with different solution principles can deliver the exactly sa me function. From these alternatives, manufacturing firms select one \(or one set of technology for carrying out the subsequent development activities \(e.g., designing physical components\hese technology alternatives lead to very different product and component design, incurring different degrees of design and production complexity and cost. Therefore, decision making in technology selection plays a major role in achieving efficiency and effectiveness in downstream development activities, and in particular design and production. In this regard, technology selection and the corresponding detail determinatio n suggests itself to be a key in product development 2  To survive On one hand, d esign technologies provide solution principles to deliver product functions; on the other hand they play a major role in achieving efficiency and effectiveness in product design and production. Recognizing this importance of technologies in product development and in response to the lack of investigation, this study proposes an approach based on association rule mining to identify mapping relationships between functions and technologies Such mapping relationships not only help firms effectively decide on technologies and the corresponding details but also enable them to reuse proven knowledge about functions and technologies. A case study of microlithography machines is reported to demonstrate how the proposed approach identifies mapping relationships from given function and technology data and how these relationships help select technologies and determine details  5 e oth e r h a nd, reusing  k n o w led g e  f r o m  historical data suggests itself as a natural technique to facilitate solving problems. As a data mining technique association rule mining lends its elf to gaining knowledge from historical data, that is, to reveal previously unknown yet useful patterns of product family development 6, 7  In response to the lack of studies and in view of the importance of design technologies in developing products this study applies association rule mining technique to identify mapping relationships \(i.e., knowledge\ between functions and technologies, in attempting to assist technology selection and detail determination while leveraging upon existing d esign expertis e and production competence in product family development  II.  PROBLEM FORMULATION   i F generic functions In this regard, an represents a set of specific functions \(or fun ction variants\f the same type f F f G f F f G f F n f F n n ij R j F j i ij F F R F n i f F F  005 003\004 underpins an 005 002 A generic function Definition 1 Definition 2 Keywords A generic relationship exists between two generic functions 007 005 006 of generic relationships among generic functions ij R  1596 n A function family \(i.e., a group of functions systems. However, these data is not well organized in the way that can facilitate existing data management and new product design consists of all specific functions that comprise the offerings of a product family. In line with the theory of function decomposition 8  f ic functions featuring product variants can be organized at different levels of the respecti ve function hierarchies and a set 205 and is assumed by spec ific functions pertaining to product variants  As with a generic product structure representing the physical view of a product family, a represents A generic function structure in relation to a product family. It consists of a set    Linda L. Zhang 1 and Roger J. Jiao 2 Department of Management, IESEG School of Management, Lille, France The G.W. Woodruff School of Mechanical Engineeri ng, Georgia Institute of Technology, Atlanta, USA  l.zhang@ieseg.fr  Association rule mining, product development, generic rules, technology selection  Identifying Mapping Relationships between Functions and Technologies: an today\220s firm  Approach based on Associ ation Rule Mining 


005 n It is defined by the technology type 016 003\004   A generic relationship nfidence level The mapping relationship between an  is defined by a set of property and value pairs and a set contributes to the delivery of a function variant  technology attribute values  denotes the total number of values that can be assumed by the is defined as a tuple is characterized by the technology type, attributes, tools, and materials. In practice, a tool is a supporting device for implementing or testing a technology. It can be a physical one, software or the combination of both. A material is the fundamental material for applying a technology  Similarly, it represents a family of technologies of a specific type. A represents the total number of attributes that characterize the technology variant and as the corresponding generic function includes all technologies that can deliver the function family in relation to a product family. In the light of function similarities, similarities exist among technologies in the corresponding technology family  represents a set of specific technologies \(or technology variants\ the same type, i.e exists between and generic technology consists of a set denote the itemsets of function and technology data, respectively In the t t t f f  003\004   where items in the rule\220s condition and consequence, amon s denotes the total number of values that can be assumed by the and all   entails the instantiation of the generic mapping  with respect to the specif ic function property values  III.  MAPPING RELATIONSHIP MINING      among those containing the set of items in its precedence See more in 6   In traditional association rule mining, a f f f of a function family corresponds to a particular function variant, be it a basic type or a composite type. Each basic function is defined by specific values of the characterizing properties Based on these specific property values, corresponding technology details are deter mined in the technology domain. A composite function is formed by several child functions of basic types and/or composite types, which influence the determination of technology details. \(Note associated with a 003\004 007 005 f\r f\r 005 contains items that all belong to one single domain. In the context of mining association rules \(i.e., mapping relationships between functions and technologies, transaction data exists in both the function and technology domains besides interrelations within each individual domain. In other words, the v u st pv f u v s t F t G t G m t T m m ij i T j T j i ij T T T n i t T T L M M L av t n m xy m n x F T T F F T F T T F TDB TDB TDB f G TDB TDB rule\220s consequence 003\004  t 003\004 A. Association Rule Mining  represents the total number of properties that characterize the function variant and 007 005 013 n m xy av Definition 4 Definition 5 Definition 6 Definition 7 Definition 8 Definition 9 th property  Accordingly, function variants of the same type differ from one another in specific property values. In addition specific relationships between function variants of different types form generic relationships between the corresponding generic functions  and  and In this regard, the mapping between instances of and he confidence of a rule is the percentage of transactions which contain the set of items in the   and A generic technology d material where th attribute  Technology variants of the same type differ from one another in specific attribute values, tools, and materials The meaningful combination of technology variants of different types can deliver f unction variants featuring a product variant and further determines the product design The specific relationships between technology variants of different types form the generic relationships between the corresponding generic technologies  where  and  functions can be of either a basic or composite type. While a composite function is formed by more than one child function, a basic function cannot be decomposed further and is located at the lowest level of a branch of the hierarchy Mining mapping relationships between functions and technologies is thus carried out for these two general types of functions: basic and composite functions. Every transaction, Z, in the A function variant  can be organized to represent the corresponding technology family. It includes specific technologies, which are adop ted to deliver function variants in the corresponding function family A A technology family In accordance with technology similarities and the generic function structure, a generic technology structure a function family is the group of 1597 i.e    i.e wo measures in association rule mining. The support of a rule is the percentage of transactions, which contain the two sets of of generic relationships comprises two types of items   of generic technologies exists between two generic technologies A technology variant  In accordance with classification of all  c f\r 003\004 t f b t 007 n 005 t n 013 007 ij  a family of function variants of a same type. It is characterized by a number of properties            Among the reported mining algorithms, this study adopts the Apriori algorithm 9, 10  e to its eff icie n c y   This algorithm involves two steps. First, it finds all large itemsets, i.e., sets of items that have transaction support no less than the pre-defined minimum support Subsequently, it generates association rules from these identified itemsets. Rule generation is influenced by the specification of a minimum confidence. Note, a support level g all transactions in the transaction database     t f TDB  e specific tool 016 016 005 b 


Hierarchies of func variants     property values, and the corresponding product item. In a similar way, technologies associated with each product variant are identified and orga nized into a hierarchy, as shown in Step \(3\nology details are organized as technology data tables, as shown in Step \(4  TDB Item  Item  203 203\203 203 203\203 013  003\004 003\004 003 004   003\004 003\004 013 013 002 002 013 i a 007 005 005 3 i b i b i b  and 1598 3 technology data record includes the technology\220s name th property  or composite functions ID, description, type, materia l, tool, attribute values, and the corresponding product items. Based on the same product items that appear in both function data tables and technology data tables, the transaction database is formed as shown in Step \(5       017  43  24  11 pv  pv  pv  4 n  25  16 pv   pv  pv  variants, each  ch technologyrelated elements of E. Rule Mining for Basic and Composite Functions Tool  D. Organization of Function and Technology  Data 003\004 003 004 record contains the functio n\220s name, ID, description Matl  of 1 3 4 with   In practice, a basic function is usually delivered by more than one technology. Each technology is implemented based on a certain material and tested using a certain tool. It is defined by a set of attribute value pairs Thus, technology data associ ated with a basic function include the type  differ from one another in property values. In turn, property value differences lead to differences in child functions and in technologies as well If a   A composite function is jointly delivered by several technologies, which contribute to the delivery of its child functions. in this regard, the technology-related elements of The total number of transactions in the The function-related items in a 007 005 003\004 2 4 2  1 f  2 f  4 f  3 f  5 f  6 f  8 f  7 f  9 f  10 f                                is thus the same as that of basic function variants in the family  25  33 av  av i a i a is related to the child functions of the corresponding  xx xxx xx xxx xx xxx xx xxx Tech ID Descrip Attribute value pairs     xx xxx xx xxx xx xxx xx xxx Function ID Description Property value pairs     002 Transaction DB   Given function-related data in the form of basic functions  25  33 pv  pv        003\004 003\004 003 004   Technology Data Table      203 203  203 203 203 203 203      Hierarchies of tech variants 007 005 005 002  43  24  11 av  av  av  4 n  25  16 av   av  av  1 n  21  11 pv   pv  pv  1 n  21  11 av   av  av Type     013 013 Function Data Table     003\004   is the total number of possible values to be assumed by all variants in the family with respect to the function variants of a specific type, instead of all functions comprising the offerings of a product family  of attribute value pairs is the total number of technologies for delivering  is the total number of tech nologies for delivering  in the in a are formulated similar as these of a basic function equals to that of composite function variants in the family. The function-related items of each as follows th value instance of the aterial corresponds to a specific composite function variant, the total number of Z in the represents the databases and file systems. To ensure rule mining efficiency and effectiveness such data organization is geared towards a product family, instead of more than one product family  For each product variant of a chosen family, all functions are identified first. Also identified are connections between these functions and the corresponding product items. Subsequently, based on the identified connections and hierarchical product structures functions are organized into a hierarchy, as shown in Step 1\ the process of data organization and transaction database preparation in Fig. 1 The detailed function data pertaining to each product item is then organized in function data tables, as shown in Step \(2\ data firms\220 st pv   c     t  is the total number of values that can be assumed by the  B.  Itemset for Basic Functions TDB A n Z TDB n i Z v u st n i i pv a Z t s u v s n v L M n m xy av i Z q n m xy b b b q b n i i av L M t a Z q  C.  Itemset for Composite Functions m i b B i Z TDB B TDB i Z n m ij m i i b b Z n i Z l p o ef c c c l m i i av L M b Z l o c p e c  i f  2 f  3 f  4 f   1 f  2 f  3 f  4 f  1 i  2 i  3 i  4 i  1 t  2 t  3 t  4 t  1 i  2 i  3 i  4 i 1 1 M 2 M 3 M 4 M 1 L 2 L 3 L 4 L  i t  2 t  3 t  4 t      n i a m i b TDB v u st pv X 003\004 003\004   A composite function contains more than one child function and is delivered by all technologies contributing to the delivery of these child functions. Composite function variants  consists of two set of records of a basic function family th technology   VI.  MAPPING RELATIONSHIP MINING PROCEDURE  is the total number of child functions of  is total number of attributes featuring the is the total number of properties in the basic function family; and is related to a function variant  are described as a list of property value pairs are formulated as th attribute of the where  where where  of a family  the 003\004 003\004  1 t  2 t  4 t  3 t  5 t  6 t  8 t  7 t  9 t  10 t  1  2  3 4  5  5                             007 005 007 005 013 007 th property assumed by  th technology; and  For a given       where   Mining mapping rules starts with organizing the large volumes of function and technology data existing in  Fig. 1.  Data organization and transaction database preparation Product development databases/File systems 003\004 


r y x op r j r j r j av L M Y support and The result of rule generalization is a list of generic mapping rules between generic function and technology elements, along with selection conditions for each generic rule and its occurrence frequency. Thus mapping between functions and technologies is embodied by relationships of both spec ific and generic functions and technologies. This study develops a procedure to generalize generic mappings between generic functions and generic technologies based on specific ones as follows 016 the number of transactions in the is introduced to indicate the number of transactions in the for the property 1 to one or more than one generic technology the total number of transactions in the Specific functions Customer requirements Function hierarchy Existing function family Generic technologies Mapping relationships generic/specific Specific technologies Existing technology famiy Technology hierarchy for designing the customized products  003\004 003 004 003\004 003 004 003\004   Fig. 2.  Technology selection based on mapping relationships   Based on valid customer requirements and the past product development experi ence, all product functions that are necessary to satisfy customer requirements are first determined, as shown in Step 1\ In accordance with the generic function structure associated with the product family in consideration \(shown in Step \(2\ the functions can be organized as a hierarchy\( in Step \(3\\. By applying the generic mappings to th e above function hierarchy shown in Step \(4\e generic technologies \(i.e technology types\ be determined \(shown in Step \(5 Further applying the specific mappings \(shown in Step 6\ leads to determination of technology details, such as attribute values \(shown in Step \(7\. In accordance with the generic technology structure underpinning the technology family in relation to the product family shown in Step \(8\e selected technologies and the details can be organized into a hierarchy for designing the customized product \(shown in Step \(9   VI.  AN APPLICATION CASE  1599 007 020 020 020 005 013 c c Step 3   ist the set of nominal values for each such property; 4.6 Replace specific nominal values with the entire set; 4.7. In the condition of a rule, keep these properties, whose values are ranges, intact; 4.8. For these rules that have the exactly same consequence, combine the conditions of these rules as an OR relation and keep the consequence intact to form one unified generic rule; and 4.9. Specify the selection condition for this generic rule based on its instances f\r  relates a generic function 021 f\r    The mappings discovered above are related to specific function and technology variants. Such concrete and low level associations cannot explain variety mapping at a family \(or class\vel. It is thus necessary to generalize individual relations hips as generic associations at the class level. Each generic relationship red f\r s s color 6 8 3 5 9 2 4 where confidence and  A mapping relationship hence means that the occurrence of certain property values of functions is correlated to the occurrence of certain attribute values of technologies with is the total number of records in technology data tables. To calculate Count the occurrence frequency of each generic rule and compute the percentage of every generic rule against the total number of identified specific rules In the consequence of a rule, keep the technology types, material types and tool types intact replace attributes value pairs with attributes For each basic function group 4.1. In the condition of a rule, check the function properties with discrete values; 4.2. Specify the value range \(i.e., the lowest value and the highest value\f each such property; 4.3. Replace specific property values with the identified value ranges; 4.4. In the condition of a rule check the properties having nominal values; \(An example of a nominal value is For each composite function 5.1. Check the child function variants in the condition of each rule; 5.2. Replace child function variants with the corresponding generic functions; 5.3. For these rules with the exactly same consequence, combine all conditions of rules using an OR relations \(note: the same generic functions are only documented once\eep the consequence intact to form one unified generic rule; and 5.4. Specify the selection condition for each group according to the instances; and that contain all the records in that contain records from both and Step 4 Step 5 Step 1 Step 2 Step 6 Allocate the rules that have exactly the same consequence into a group, and count the total number of rules in each group 7 r Y X Count TDB X Y TDB X Count TDB X  F. Generalization of Mapping Relationships T F F T TDB TDB Count f\r   V.  MAPPING RELATIONSHIP DEPLOYMENT FOR TECHNOLOGY SELECTION   The mapping relationships between functions and technologies lend themselves to a mechanism to accommodate technology selection and detail determination for designing new product variants Fig. 2  shows the proposed process of selecting technologies and determining details for designing a customized product based on the mapping relationships List all specific association rules identified from a and 


a\ A microlithography machine b\ Examples of functions and technologies  a\ A microlithography machine b\ Examples of functions and technologies  ature\216 is a type of basic function characterized by Temperature control system techmology Temperature control system techmology  Temperature control system techmology relevant technology variants are used to demonstrate the proposed relationship To control wafer temperature To control wafer temperature To control wafer temperature Wafer handling temperature technolgoy Wafer handling temperature technolgoy Wafer handling temperature technolgoy To position the reticle in the imaging process To position the reticle in the imaging process To position the reticle in the imaging process example to demonstrate the proposed relationship deployment. Based on the customer requirements 1600 Technology examples Technology examples Technology examples In the case study, we apply the proposed relationship mining approach and deployment to a family of customized microlithography machines from a Dutch company. A microlithography machine \(shown in Fig 3\(a prints integrated circuit p atterns from a reticle onto a wafer through a projection lens. To fulfill this overall function, a number of functions at different levels are necessary. To deliver all these functions and ultimately the overall product function, a number of technologies are utilized. Some of these functions and technologies are shown in Fig. 3\(b  several properties, including the maximum nonuniformity in the wafer, the maximum offset of the air temperature inside the wafer stage compartment with respect to the wafer table, and the maximum offset of the air temperature inside the wafer stage compartment with respect to lens cool water. To deliver this function, three technology types are involved, including temperature control system technology, air conditioning system technology, and remote temperature sensing technology Each of these technologies is characterized by their unique attributes. For instan ce, temperature control system technology is characterized by four attributes including air temperature chill plate temperature, air temperature stability, and chill plate temperature stability  To deliver the 35 function variants, 35 technology variant groups are utilized. Each group includes variants of the above three technology types. The transaction database is established for these 35 function variants and the corresponding technology variant groups. \(Note the transaction database is available upon request. Due to the page issue, it is not incl uded in this paper  For this application, an association rule mining tool Magnum Opus http://www.giwebb.com opted Among all, one unique strength of Magnum Opus lies in the fact that it resembles th e confidence metric in the Apriori algorithm. All relevant data are extracted from the transaction database and is input as a text file into Magnum Opus. In the search setting, the maximum number of associations is set to be as large as 10000 to thoroughly search possible associations in transaction databases Fig. 4 shows the setting of search modes their metrics, and input windows for records of the transaction database mining approach. \215To control wafer To provide and conditi on the light for the imaging process To provide and conditi on the light for the imaging process To provide and conditi on the light for the imaging process of function: \215To control wafer temperature\216 and the 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 Remote temperature sensing technology Remote temperature sensing technology Remote temperature sensing technology function: \215To control wafer temperature\216 is used as an Function examples Function examples Function examples  Fig. 3.  A microlithography machine and examples of functions and technologies   For illustrative simplicity, a family of variants \(35 in total temper  Fig. 4.  Mapping relationship mining in Magnum Opus    The mining results are shown in Fig. 5 A total number of 46 rules are discovered that reveal the relationships between function properties and technology changes. Take Rule 16 as an ex ample. It indicates when the maximum non-uniformity in the wafer is 20mK, the measurement accuracy of the remote temperature sensing technology should be 0.1mK. The number in the parentheses indicates the number of instances that satisfy that rule. By following the proposed rule generalization procedure, generic associations are derived, revealing the relationships between generic function and technology elements  Fig. 5.  Mapping relationships discovered    A customized microlithography machine outside the data samples is adopted to test the application of the mapping relationships to select technologies and to determine technology attribute details. Similarly, the 


Association rule mining for product and process variety mapping,\216 Proc. the ACM SIGMOD Conf. on Mgmt of Data 487-499, Santiago de Chile Chile, 1994 10 Zh a n g   H Che n g   an d  X Chu   ning approach,\216 vol. 23, no. 7, pp. 673-686 2010     1601 Data Mining: Concepts and Techniques IJCIM IJCIM pertaining to this customized microlithography machine the specific variant of this function is determined. The maximum non-uniformity in the wafer of this function variant is 20mK; the maximum offset of the air temperature inside the wafer stage compartment with respect to lens cool water is 30mK; and the maximum offset of the air temperature inside the wafer stage compartment with respect to the wafer table is 30mK  By following the relationship deployment process in Fig. 2, technologies are selected and technology details are determined, as shown in Table I. The senior design engineers in the case company have confirmed these technology details TABLE I THE DETAILS OF TECHNOLOGIES THAT DELIVER THE FUNCTION VARIANT Chill plate temperature stability \(greater than 2.4mK/min Measurement accuracy \(0.1mK Sensing type \(Vacuum Proc. 20th Intl Conf. Very Large Data Bases Air temperature \(21.5, 22.1 temperature pp 207-216, 1993  J. Jiao  L  Z h an g Y Zh an g an d S   P o kh arel  IEEE Trans. Eng Mgmt Remote vol. 21, no. 1, pp. 111-124, 2009 8 Su h  Process platform planning for variety coordination from design to production in m 20, 2004 4 J. Jiao  L  Zh an g an d S   Po k h arel  VII.  CONCLUSIONS   This study proposed to identify and construct mapping relationships between functions and technologies and used microlithography machines to demonstrate the applicability of the propos ed relationship mining approach and deployment Organizing function and technology data as mapping relationships helps alleviate data redundancy resulting from the maintenance of a large amount of variant forms of function and technology structures. The mapping relationships between functions and technologies can also assist in making decisions about the selection of appropriate technology details, such as types, materials, tools, and attribute values  As a starting point, this study explores the feasibility and potential of the Apriori algorithm for identifying the implicit knowledge hidden in large volumes of function and technology data. More sophisticated association rule mining techniques may deserve scrutiny, in particular, in terms of computational efficiency, mining quality complexity, and other issues. While this study proposes a relationship deployment procedure, it does not touch on the process of technology selection and the influence of proceeding technology selection on the following technology selection. In this regard, another avenue for future research is to develo p or adopt suitable tools to model the dynamic process of technology selection  REFERENCES  1   P a h l   an d  W   Beitz   in  in  vol. 18, no 1, pp. 3 In press, 2011 Air conditioning system Aided analysis for quality function deployment with an Apriori-based data mi  ISBN13: 9780195134667, Oxford University Press, USA 2001 9 R. A g r a w a l, an d R. Srikan t vol. 54, no. 1, pp. 112-129, 2007 5 Ha n   a n d  M  Ka m b er Product platform design and customization: Status and promise 216 Air temperature stability \(greater than 12mK/min Temperature control system sensing Temperature offset with respect to the wafer table \(250mK 350mK 3  W   Si m p son   Attribute values Temperature offset with respect to lens cool water \(200mK 300mK 215 216 215 205 215 215 215 215 215 Axiomatic Design: Advances and Applications Air supply flow \(300m 3 hour, 450m 3 hour Chill plate temperature \(22.5, 23.1 Engineering Design: A Systematic Approach iation rules in large databases,\216  IJPR  Technology type Springer, 1996 2   A l b las L   Zh an g   an d  H  W o rtma n n   Pressure stability \(5mbar/s Representing function-technology platform based on the unified modeling language Fast algorithms for mining assoc AIEDAM ass customization manufacturing,\216 ets of items in large databases,\216 Mining association rules between s ISBN 13: 978-1-55860-901-3, Morgan Kaufmann Publishers, San Francisco, USA, 2006 6 R. A g r a w a l T  I m ielin sk i, a n d  A  Sw a m i 


datasets consist of 306 samples. Each data sample constituted 4 attributes: age of patient, patients year of operation number of positive auxiliary nodes detected and survival status. Survival status attribute contains only two values that are one and two to indicate the patient survived 5 years or longer and the patient died within 5 years, respectively. Table I gives all linguistic terms for 4 attributes in each pattern for this study The vigilance value in ART2 model will dominate the clustering results that in turn affect the number of patterns clustered to each cluster. Depending on the database size and the properties of the data, it is hard to decide the number of suitable clusters before executing the clustering job. In this study, mid-size clusters, such as 3 to 7, are tested for the medical data. In case only few data were found in a cluster, a check is performed to see whether they are outliers or not. For example, when analyzing datasets we found that one pattern 83, 58, 2, 2 remaining data. Therefore, only 305 patterns are used in the simulations to avoid the overhead of processing this outlier pattern First, we carry out the methodology by fuzzifying the input patterns using the labels of membership functions of 3, 3, 3 and 1 for four attributes, respectively \(case 1, the vigilance value is set to 3.6 illustrated in Fig. 2 for details. The cover range and the shape of membership functions may affect the results of association rules. Although those parameters can be further optimized by the genetic algorithm framework [14] they are not the goal of this research. In this example, all membership functions are empirically determined  Fig. 2. Linguistic terms of four attributes for case 1 After performing the fuzzy ART2, the data can be grouped into 3 clusters, in which clusters 1 to 3 contain 131, 115 and 59 patterns, respectively. We use DHP and interesting measures to find the association rules for each cluster Because of the differences among the volumes of patterns in clusters, minimum support \(min_sup confidence \(min_conf So, we pro rata set minimum support and confidence in accordance with percentage of the number of each cluster 


Fig. 3 illustrates two cases of the data ratio in the clusters. For example, cluster 1 in case 1 contains 43% of the 305 patterns so we set both minimum support and confidence to 57  Fig. 3. Cluster results for case 1 and case 2 The result of this case is compared with the case that only uses DHP to mine all 305 patterns without using Fuzzy ART2. Table II compares the results. Note that, min_sup and min_conf for mining all 305 patterns will be set lower than Acontainingtuples BandAbothcontainingtuplesBAconfidence ___ ______     that of each cluster because each cluster after clustering has the similar properties From Table II, we can see that the results of association rules of combining 3 clusters \(after mining separately clusters without fuzzy ATR2 time to process The purpose of the other experiment is to find out the effect of the number of membership functions on the association rules. The number of membership functions for the patient age attribute and the number of positive auxiliary nodes attribute will be respectively changed to 5 membership functions as shown in Fig. 4 \(case 2, the vigilance value is set to 3.4 case 1  Fig. 4. Linguistic terms of attribute 1 and attribute 3 for case 2 The results are presented in Table III and Table IV. In this case, the dataset is clustered into 5 clusters \(larger than that of case 1 57, 85 and 19. And the same as the case 1, the association rules are similar with or without using fuzzy ART2 Two cases take full advantage of fuzzy ART2 in finding association rules. It separates the dataset into some smaller groups to reduce the computational cost V. CONCLUSIONS 


This study proposes a novel approach for finding association rules from medical data. The combination of fuzzy model and ART2 neural network is developed to cluster the fuzzified dataset into several groups with similar properties. The groups are then particularly exploited for finding the association rules. The approach shows that the more computationally efficiency can be obtained by reducing processing time. An application considered is to group the patients who had undergone surgery for breast cancer into groups that have the similar properties to use group association rules. The experimental results show that the discovered association rules are exactly the same with the conventional approach. The merit of this research is that the computational time is significantly reduced and the approach can be applied to a variety of domains REFERENCES 1] M. H. Margahny and A. A. Mitwaly, Fast algorithm for mining association rules, in Proc. of ICGST Int. Conf. on Artificial Intelligent and Machine Learning, Cairo, Egypt, Dec. 2005 2] A. Savasere, E. Omieccinski and S.B. Navathe, An efficient algorithm for mining association rules in large databases, in Proc. 21th Int. Conf on Very Large Data Bases, Zurich, Switzerland, pp.432-444, Sep 1995 3] R. Li and Z. Wang, Mining classification rules using rough sets and neural networks, European Journal of Operational Research, vol. 157 no. 2, pp.439-448, Sep. 2004 4] A.J.C. Sharkey, G.O. Chandorth and N.E. Sharkey, A multi-net system for the fault diagnosis of a diesel engine, Journal of Neural Computing and Application, vol. 9, no. 2, pp.152-160, 2000 5] D. S. S. Lee, B. J. Lithgow and R. E. Morrison, New fault diagnosis of circuit breakers, IEEE Trans. on Power Delivery, vol. 18, no. 2, pp 454-459, Apr. 2003 6] J.M. Benitez, J.L. Castro and I. Requena, Are artificial neural networks black boxes, IEEE Trans. on Neural Networks, vol. 8, no. 5 pp.1156-1164, Sep. 1997 7] E.  Kolman and M. Margaliot, Are artificial neural networks white boxes, IEEE Trans. on Neural Networks, vol. 16, no. 4, pp.844-852 July 2005 8] Y.-P. Huang, T.-W. Chang, L.-J. Kao and F.E. Sandnes, Using fuzzy SOM strategy for satellite image retrieval and information mining Journal of Systemics, Cybernetics and Informatics, vol. 6, no. 1, pp.1-6 Nov. 2008 


9] S.A. Mingoti and J.O. Lima, Comparing SOM neural network with fuzzy c-means, k-means and traditional hierarchical clustering algorithms, European Journal of Operational Research, vol. 16, no. 3 pp.1742-1759, Nov. 2006 10] R.J. Kuo and Y.T. Su, Integration of ART2 neural network and fuzzy sets theory for market segmentation, Int. Journal of Operations Research, vol. 1, no. 1, pp.67-68, 2004 11] B.S. Ahn, S.S. Cho and C.Y. Kim, The integrated methodology of rough set theory and artificial neural network for business failure prediction, Expert Systems with Application, pp. 6574, 2000 12] G. Tayfur and V.P. Singh, ANN and fuzzy logic models for simulating event-based rainfall-runoff, Journal of Hydraulic Engineering, vol 132, no. 12, pp.1321-1330, Dec. 2006 13] A. Majumdar, P.K. Majumdar and B. Sarkar, Application of an adaptive neuro-fuzzy system for the prediction of cotton yarn strength from HVI fibre properties, Journal of the Textile Institute, vol. 96 no.1, pp.55-60, Jan. 2005 14] T.-P. Hong, C.-H. Chen, Y.-C. Lee and Y.-L. Wu, Genetic-fuzzy data mining with divide-and-conquer strategy, Journal of Evolutional Computation, vol. 12, no.2, pp.252-265, April 2008 15] R.J. Schalkoff, Artificial Neural Networks, McGraw-Hill, New York USA, 1997 16] J. Gao, S. Li and F. Qian, A method of improvement and optimization on association rules apriori algorithm, in Proc. 6th World Congress on Intelligent Control and Automation, Dalian, China, vol. 2 pp.5901-5905, June 2006 17] L. Ji, B. Zhang and J. Li, A new improvement on apriori algorithm, in Proc. of Int. Conf. on Computational Intelligence and Security, vol. 1 pp.840-844, Nov. 2006 18] Y.-P. Huang, L.-J. Kao and F.E. Sandnes, Efficient mining of salinity and temperature association rules from ARGO data, Expert Systems with Applications, vol. 35, no. 1-2, pp.59-68, Aug. 2008 19] L.V.S. Lakshmanan, C.K.-S. Leung and R.T. Ng, The segment support map: scalable mining of frequent itemsets, in Proc. of the ACM SIGKDD Explorations Newsletter, vol. 2 no. 2, pp.21-27, Dec 2000 20] J.S. Park, M.-S. Chen and P.S. Yu, Using a hash-based method with transaction trimming for mining association rules, IEEE Trans. on Knowledge and Data Engineering, vol. 9, no. 5, pp.813-825, Oct. 1997 21] J. Mata, J.L. Alvarez and J.C. Riquelme, Evolutionary computing and optimization: An evolutionary algorithm to discover numeric association rules, in Proc. of the 2002 ACM symposium on Applied 


computing, Madrid, Spain, pp.590-594, Mar. 2002 22] R. Natarajan and B. Shekar, A relatedness-based data-driven approach to determination of interestingness of association rules, in Proc. of  the 20th Annual ACM Symposium on Applied Computing, Santa Fe, New Mexico, USA, pp.551-552, Mar. 2005 23] http://archive.ics.uci.edu/ml    TABLE I ABBREVIATIONS OF THE PATIENT PARAMETERS Attribute No. Parameter Linguistic Term Age of patient 1 Ly Little_Young 2 Yo Young 3 Ma Middle_Aged 4 Se Senior 5 Ls Little_Senior Patients year of operation 1 Ol Old 2 Av Average 3 Re Recent Number of positive auxiliary nodes detected 1 Vs Very_Small 2 Sm Small 3 Me Medium 4 La Large 5 Vl Very_Large Survival status 1 Hi High  TABLE II THE ASSOCIATION RULES RESULTS FOR CASE 1 Cluster 1 Cluster 2 Cluster 3 Combining Cluster 1, 2, 3 All Dataset Sup. \(57 57 62 62 81 81 70 70 Hi <- Av  \(97.7, 97.7 82.6, 96.8 94.9, 98.2 97.7, 97.7 73.5, 96.9 Av <- Hi  \(97.7, 97.7 95.7, 83.6 98.3, 94.8 97.7, 97.7 96.4, 73.9 Ma <- Av  \(97.7, 100.0 82.6, 100.0 94.9, 100.0 97.7, 100.0 Hi  \(73.5, 100.0 


Av <- Ma  \(100.0, 97.7 100.0, 82.6 100.0, 94.9 100.0, 97.7 Ma  \(99.3, 74.0 Me <- Av  \(97.7, 100.0 82.6, 100.0 98.3, 100.0 97.7, 100.0 Hi  \(73.5, 100.0 Av <- Me  \(100.0, 97.7 100.0, 82.6 100.0, 98.3 100.0, 97.7 Me  \(100.0, 73.5 Ma <- Hi  \(97.7, 100.0 95.7, 100.0 93.2, 100.0 97.7, 100.0 Ma <- Av  \(96.4, 99.3 Hi <- Ma  \(100.0, 97.7 100.0, 95.7 94.9, 98.2 100.0, 97.7 Av <- Ma  \(99.3, 96.4 Me <- Hi  \(97.7, 100.0 95.7, 100.0 98.3, 94.8 97.7, 100.0 Me <- Av  \(96.4, 100.0 Hi <- Me  \(100.0, 97.7 100.0, 95.7 94.9, 98.2 100.0, 97.7 Me  \(100.0, 96.4 Me <- Ma  \(100.0, 100.0 100.0, 100.0 98.3, 94.8 100.0 100.0 99.3, 100.0 Ma <- Me  \(100.0, 100.0 100.0, 100.0 94.9, 100.0 100.0 100.0 100.0, 99.3 Ma <- Av Hi  \(95.4, 100.0 80.0, 100.0 100.0, 94.9 95.4 100.0 71.2, 100.0 Hi <- Av Ma  \(97.7, 97.7 82.6, 96.8 98.3, 100.0 97.7 97.7 73.5, 96.9 Av <- Hi Ma  \(97.7, 97.7 95.7, 83.6 100.0, 98.3 97.7 97.7 95.8, 74.4 Me <- Av Hi  \(95.4, 100.0 80.0, 100.0 93.2, 100.0 95.4, 100.0 71.2, 100.0 Hi <- Av Me  \(97.7, 97.7 82.6, 96.8 97.7, 97.7 73.5 96.9 Av <- Hi Me  \(97.7, 97.7 95.7, 83.6 97.7, 97.7 96.4 73.9 Me <- Av Ma  \(97.7, 100.0 82.6, 100.0 97.7, 100.0 73.5, 100.0 Ma <- Av Me  \(97.7, 100.0 82.6, 100.0 97.7, 100.0 73.5, 100.0 Av <- Ma Me  \(100.0, 97.7 100.0, 82.6 100.0, 97.7 99.3, 74.0 Me <- Hi Ma  \(97.7, 100.0 95.7, 100.0 97.7, 100.0 95.8, 100.0 Ma <- Hi Me  \(97.7, 100.0 95.7, 100.0 97.7, 100.0 96.4, 99.3 Hi <- Ma Me  \(100.0, 97.7 100.0, 95.7 100.0, 97.7 99.3, 96.4 


   TABLE III THE ASSOCIATION RULES RESULTS FOR CASE 2 Cluster 1 Cluster 2 Cluster 3 Cluster 4 Cluster 5 Sup. \(74 74 79 79 81 81 72 72 94 94 Hi <- Ma  \(78.2, 95.1 93.9, 95.2 94.7, 94.4 92.9, 97.5 100.0, 100.0 Ma <- Hi  \(94.9, 78.4 95.5, 93.7 94.7, 94.4 96.5, 93.9 100.0, 100.0 Av <- Ma  \(78.2, 98.4 93.9, 95.2 94.7, 100.0 92.9, 97.5 100.0, 100.0 Ma <- Av  \(97.4, 78.9 95.5, 93.7 100.0, 94.7 97.6, 92.8 100.0, 100.0 Vl <- Ma  \(78.2, 98.4 95.5, 95.2 94.7, 100.0 92.9, 100.0 100.0, 100.0 Ma <- Vl  \(98.7, 77.9 95.5, 95.2 100.0, 94.7 100.0, 92.9 100.0, 100.0 Av <- Hi  \(94.9, 97.3 89.4, 94.9 89.5, 100.0 96.5, 97.6 Yo Av  \(100.0, 100.0 Hi <- Av  \(97.4, 94.7 89.4, 94.9 94.7, 94.4 97.6, 96.4 Yo Vl  \(100.0, 100.0 Vl <- Hi  \(94.9, 98.6 90.9, 93.3 94.7, 94.4 96.5, 100.0 Av Vl  \(100.0, 100.0 Hi <- Vl  \(98.7, 94.8 100.0, 96.5 Vl <- Av  \(97.4, 98.7 97.6, 100.0 Av <- Vl  \(98.7, 97.4 100.0, 97.6 Av <- Ma Hi  \(74.4, 98.3 90.6, 97.4 Hi <- Ma Av  \(76.9, 95.0 90.6, 97.4 Ma <- Hi Av  \(92.3, 79.2 94.1, 93.8 Vl <- Ma Hi  \(74.4, 98.3 90.6, 100.0 Hi <- Ma Vl  \(76.9, 95.0 92.9, 97.5 Ma <- Hi Vl  \(93.6, 78.1 96.5, 93.9 Vl <- Ma Av  \(76.9, 98.3 90.6, 100.0 Av <- Ma Vl  \(76.9, 98.3 92.9, 97.5 Ma <- Av Vl  \(96.2, 78.7 97.6, 92.8 Vl <- Hi Av  \(92.3, 98.6 94.1, 100.0 Av <- Hi Vl  \(93.6, 97.3 96.5, 97.6 Hi <- Av Vl  \(96.2, 94.7 97.6, 96.4  


TABLE IV THE ASSOCIATION RULES FROM COMBINING 5 CLUSTERS FOR CASE 2 Combining 5 clusters All Datasets Sup. \(30 30 Hi <- Ma  \(78.2, 95.1 92.3, 79.2 40.5, 75.0 71.2, 41.7 Ma <- Hi  \(94.9, 78.4 74.4, 98.3 73.5, 41.3 30.4, 98.9 Av <- Ma  \(78.2, 98.4 76.9, 95.0 40.5, 96.0 39.2, 76.7 Ma <- Av  \(97.4, 78.9 93.6, 78.1 96.4, 40.3 72.2, 41.6 Vl <- Ma  \(78.2, 98.4 76.9, 98.3 40.5, 96.8 38.9, 96.6 Ma <- Vl  \(98.7, 77.9 76.9, 98.3 96.7, 40.5 39.2, 95.8 Av <- Hi  \(94.9, 97.3 96.2, 78.7 59.5, 72.5 93.1, 40.4 Hi <- Av  \(97.4, 94.7 92.3, 98.6 73.5, 58.7 43.1, 96.2 Vl <- Hi  \(94.9, 98.6 93.6, 97.3 59.5, 96.7 57.5, 72.2 Hi <- Vl  \(98.7, 94.8 96.2, 94.7 96.4, 59.7 71.2, 58.3 Vl <- Av  \(97.4, 98.7 89.5, 100.0 59.5, 96.7 43.1, 97.7 Av <- Vl  \(98.7, 97.4 94.7, 94.4 96.7, 59.5 57.5, 73.3 Yo <- Av  \(94.7, 100.0 94.7, 94.4 73.5, 96.9 72.2, 58.4 Av <- Yo  \(100.0, 94.7 90.6, 100.0 96.4, 73.9 57.5, 96.6 Yo <- Vl  \(94.7, 100.0 92.9, 97.5 73.5, 98.2 57.5, 96.6 Vl <- Yo  \(100.0, 94.7 96.5, 93.9 96.7, 74.7 93.1, 59.6 Yo <- Hi  \(92.9, 100.0 90.6, 100.0 96.4, 96.6 71.2, 98.2 Hi <- Yo  \(100.0, 92.9 92.9, 97.5 96.7, 96.3 72.2, 96.8 Av <- Ma Hi  \(74.4, 98.3 97.6, 92.8 30.4, 97.8 93.1 75.1 Hi <- Ma Av  \(76.9, 95.0 38.9, 76.5  


to be a well-suited performance measure for MC tasks where the number of negative instances significantly exceeds the number of positive instances [6]. Another advantage of AUPRC is its global nature and independence of a certain threshold value. The closer the AUPRC value is to 1, the better the performance Since these measures are based on the comparison of multi-labels, they depend on a transformation from rankings to classes. As a contrast we also used four wellknown ranking-based performance measures: One-Error OE RL C cision \(AP  for all ranking-based performance measures except AP. OneError evaluates how many times the top-ranked label is not in the set of proper labels of the instance. Ranking Loss is defined as the average fraction of pairs of labels that are ordered incorrectly. Coverage evaluates how far we need, on average, to go down the list of labels in order to cover all the proper labels of the instance. Average Precision evaluates the average fraction of labels ranked above a particular label i ? mt which actually are in mt And finally, the special hierarchical loss function H-loss 2] were utilized. Following [3], normalized costs were calculated: ci := 1/|c\(p\(i i ? L i of all direct children of i. Hierarchical loss \(H-loss consider mistakes made in subtrees of incorrectly predicted labels and penalizes only the first mistake along the path from the root to a node. The smaller the H-loss value, the better the performance B. 20 Newsgroups Dataset We modified the popular single-label dataset 20 Newsgroups [18], [19] by considering eight additional labels corresponding to the intermediate levels of the hierarchy faith, recreation, recreation/sport, recreation/vehicles, politics, computer, computer/hardware, science. This dataset is a collection of almost 20,000 postings from 20 newsgroups sorted by date into training \(60 40 data were preprocessed by discarding all words appearing only in the test documents and all words found in the stop word list [20]. Afterwards, all but the 2%-most-frequent words were eliminated to reduce the dimensionality. Documents were represented using the well-known TF-IDF \(Term 


Frequency  Inverse Document Frequency scheme [19]. The TF-IDF weights were then normalized to the range of [0, 1]. Conversion to TF-IDF and normalization were performed separately for training and test data. This resulted in the 1,070-dimensional dataset with 11,256 training instances, 7,493 test ones and 28 labels To test the performance of two HE algorithms, we first extracted hierarchies from the True Test Multi-Labels \(TTML and calculated the corresponding proximity measures. Both algorithms successfully extracted the original hierarchy We studied the performance of the multi-label classifiers and their ability to infer the class hierarchies in the presence of only partly available hierarchical information. We performed a series of HE experiments with multi-labels having a decreasing number of inserted non-leaf labels describing the levels in the hierarchy. We randomly removed such labels from 20%, 30%, and 40% of the training instances leaving them single-labeled. The results for predicted test multilabels are shown in Table I where the bold face marks the best classifier, and the first column \(left result of HE by Voting and the second \(right Thresholding \(referred as GT Comparing classification performance, one can see that the ART-based networks are superior to both the other classifiers in terms of most performance measures and that ML-FAM slightly outperforms ML-ARAM. Taken together they win on at least 6 and at most 8 out of 9 evaluation measures. BoosTexter has the second best performance, but its predictive power degrades more quickly with the increase in the number of single-label instances. The poorest MC results were shown by ML-kNN, its performance decreased very fast with any reduction in the number of multi-labels For example, F1 decreased by 15% while removing 40% of labels instead of 30%. It is also interesting to note that when trained on the dataset with 40% removed labels, ML-FAM and ML-ARAM significantly outperformed ML-kNN trained on the original dataset with all labels The hierarchy proximity measures confirm the good quality of predictions produced by the ART-based networks: The hierarchies were correct extracted by both HE algorithms of Section II-B even with 40% removed labels. The predictions of ML-kNN were the worst: The Voting variant of the HE 


algorithm could not extract the correct hierarchy with 30 assigning five labels incorrectly to the root label. None of the HE algorithms could extract the correct hierarchy in the absence of 40% multi-labels. With 40% and Voting, the number of labels falsely assigned to the root was 13, while with GT it was only three. For BoosTexter, Voting assigned two labels wrongly to the root label in the experiment with TABLE I 20 NEWSGROUPS ALL, -20%, -30% AND -40% RESULTS Measure all 20% 30% 40%ARAM FAM kNN BoosT. ARAM FAM kNN BoosT. ARAM FAM kNN BoosT. ARAM FAM kNN BoosT A 0.635 0.638 0.429 0.549 0.613 0.633 0.383 0.456 0.596 0.619 0.322 0.412 0.563 0.591 0.255 0.387 F1 0.694 0.696 0.565 0.677 0.675 0.688 0.528 0.604 0.662 0.677 0.469 0.566 0.640 0.657 0.392 0.542 F 0.691 0.692 0.480 0.605 0.671 0.688 0.429 0.507 0.658 0.676 0.364 0.465 0.630 0.652 0.296 0.441 OE 0.221 0.220 0.336 0.222 0.259 0.236 0.387 0.275 0.273 0.259 0.415 0.301 0.301 0.291 0.434 0.316 RL 0.100 0.098 0.124 0.073 0.108 0.110 0.128 0.077 0.098 0.103 0.132 0.079 0.101 0.106 0.135 0.082 C 4.188 4.168 6.080 4.164 4.397 4.446 6.184 4.286 4.246 4.340 6.326 4.328 4.334 4.463 6.397 4.379 AP 0.789 0.790 0.677 0.778 0.774 0.782 0.657 0.758 0.769 0.774 0.645 0.747 0.759 0.764 0.638 0.740 AUPRC 0.775 0.772 0.618 0.749 0.743 0.727 0.581 0.691 0.733 0.722 0.555 0.671 0.715 0.708 0.535 0.660 H-loss 0.103 0.123 0.121 0.094 0.102 0.098 0.124 0.108 0.106 0.103 0.132 0.117 0.115 0.111 0.145 0.122 Wins 1 5 0 3 1 6 0 2 2 6 0 1 2 6 0 1 LCAPD 0 0 0 0 0 0 0 0 0 0 0.12 0 0.05 0 0 0 0.51 0.26 0.17 0 CTED 0 0 0 0 0 0 0 0 0 0 0.14 0 0.07 0 0 0 0.50 0.21 0.21 0 TO* 0 0 0 0 0 0 0 0 0 0 0.11 0 0.05 0 0 0 0.39 0.18 0.15 0 30% removed labels and and six labels in the experiment with 40% removed labels. GT resulted in zero distances in the both cases. Assigning more labels to the root creates more shallow and wider hierarchies \(trivial case as stated before The good hierarchy extraction with ART networks demonstrates the system robustness  even with strongly damaged data the system can rebuild the original hierarchy C. RCV1-v2 Dataset The next experiment was based on the tokenized version of 


the RCV1-v2 dataset introduced in [21]. Only the topics label set consisting of 103 labels arranged in a hierarchy of depth four is examined here. Documents of the original training set of 23,149 were converted to TF-IDF weights and normalized Afterwards the set was splitted in 15,000 randomly selected documents as training and the remaining as test samples In this case, the Voting variant of HE applied to the TTML resulted in the LCAPD, CTED and TO* values 0.12, 0.15 and 0.13, respectively. The corresponding values of the GT variant are 0.05, 0.07 and 0.05. The poor performance of the Voting method is due to the fact that for the TTML only very high threshold values succeed in removing enough noise The Voting results are thus dominated by bad hierarchies extracted for all but the highest thresholds The classification and HE results for this dataset are shown in Table II. ML-ARAM has better performance results on this data set in all points than ML-FAM except for RL being the best of all classifiers in terms of the multi-label performance measures. BoosTexter is the best in terms of all ranking measures For both HE algorithms the distances of BoosTexter are the best, those of ML-FAM second, followed ML-ARAM and ML-kNN. All three distance measures correlate. Interesting is also that for ML-kNN the distance values obtained by both HE methods are almost the same The hierarchy extracted by GT from the TTML has much lower distances values as compared with the hierarchies extracted by both methods from predicted multi-labels. This reflects a specific problem of HE, since only a small fraction of the incorrectly classified multi-labels can prevent building of a proper hierarchy. For example, 16.5% of misassigned labels in the extracted hierarchy are responsible for about 80% of LCAPD calculated from the predictions of MLARAM. This large part of the HE error is caused by only 4% of the test data. Under these circumstances the other distances behave analogically. Most labels were not assigned making them trivial edges, but six labels were assigned to a false branch. This can happen when labels have a strong correlation and in the step Hierarchy Construction of the basic algorithm the parent is not unique in the confidence matrix. BoosTexters results suffer less from this problem because it generally sets more labels for each test sample 


Both HE algorithms behaved similarly on the predictions of the ART networks. They constructed a deeper hierarchy than the original one and wrongly assigned the same 11 labels to the root node. The higher distances come from Voting assigning more labels to the wrong branch. For MLkNN both algorithms again create very similar hierarchy trees, both misassigned 28 labels to the root label. For BoosTexter it was seven with Voting and eight with GT Voting produced a deeper hierarchy here D. WIPO-alpha Dataset The WIPO-alpha dataset1 comprises patent documents collected by the World Intellectual Property Organization WIPO ments. Preprocessing was performed as follows: From each document, the title, abstract and claims texts were extracted stop words were removed using the list from [20] and words were stemmed using the Snowball stemmer [22]. All but the 1%-most-frequent stems were removed, the remaining stems were converted to TF-IDF weights and these were normalized to the range of [0, 1]. Again, TF-IDF conversion and normalization were done independently for the training and the test set. The original hierarchy consists, from top to bottom, of 8 sections, 120 classes, 630 subclasses and about 69,000 groups. In our experiment, only records from the sections A \(5802 training and 5169 test samples H \(5703 training and 5926 test samples 1http://www.wipo.int/classifications/ipc/en/ITsupport/Categorization dataset/wipo-alpha-readme.html August 2009 TABLE II RCV1-V2 RESULTS Measure ARAM FAM kNN BoosT A 0.748 0.731 0.651 0.695 F1 0.795 0.777 0.735 0.769 F 0.805 0.787 0.719 0.771 OE 0.077 0.089 0.104 0.063 RL 0.087 0.086 0.026 0.015 C 11.598 11.692 8.563 5.977 AP 0.868 0.860 0.839 0.873 AUPRC 0.830 0.794 0.807 0.838 H-loss 0.068 0.077 0.097 0.081 Wins 4 0 0 5 LCAPD 0.29 0.22 0.25 0.20 0.34 0.34 0.21 0.18 


CTED 0.32 0.23 0.28 0.22 0.38 0.37 0.24 0.20 TO* 0.27 0.18 0.22 0.17 0.31 0.30 0.21 0.17 document in the collection has one so-called main code and any number of secondary codes, where each code describes a group the document belongs to. Both main and secondary codes were used in the experiment, although codes pointing to groups outside of sections A and H were ignored. We also removed groups that did not contain at least 30 training and 30 test records \(and any documents that only belonged to such small groups 7,364 test records with 924 attributes each and a label set of size 131 In this case, the Voting variant of the HE algorithm applied to the TTML resulted in the LCAPD, CTED and TO* values of 0.13, 0.12 and 0, respectively. GT showed the same values. Remarkable are the TO* distances, which are equal to 0. This is due to the fact that the WIPO-alpha hierarchy contains 16 single-child labels that are not partitioned by the true multi-labels: whenever a single-child label j is contained in a multi-label, so is its child, and vice versa. It is therefore theoretically impossible to deduce from the multilabels which of them is the parent of the other. As a result the HE algorithms often choose the wrong parent, resulting in higher LCAPD and CTED values. TO*, as described above is invariant under such choices The results obtained on the WIPO-alpha dataset are shown in Table III. The classification performance of the ART-based networks on this dataset is slightly worse than that of BoosTexter. Mostly in the terms of OE, RL, C, AP, AUPRC, and H-loss measures BoosTexter is better because its rankings are better and it assigned more labels to each sample. But the ART networks have better HE results because their predicted labels are more consistent with the original hierarchy. MLkNN has the worst classification results and distance values again. The reason for the high relative difference between LCAPD as well as CTED and TO* obtained for the ART networks or BoosTexter as compared to the results of the other datasets is because most of the labels were assigned in the right branch but not exactly where they belong Both HE algorithms extracted the same hierarchy from the predictions of ML-ARAM and a very similar hierarchy for ML-FAM. About 5% labels were assigned wrongly to the 


root label in the hierarchies of the ART networks. For MLTABLE III WIPO-ALPHA\(AH Measure ARAM FAM kNN BoosT A 0.588 0.590 0.478 0.564 F1 0.694 0.691 0.614 0.693 F 0.682 0.682 0.593 0.679 OE 0.052 0.057 0.110 0.042 RL 0.135 0.136 0.056 0.025 C 25.135 25.269 22.380 11.742 AP 0.790 0.785 0.724 0.802 AUPRC 0.720 0.684 0.688 0.762 H-loss 0.090 0.093 0.149 0.079 Wins 1 2 0 6 LCAPD 0.16 0.16 0.17 0.17 0.32 0.38 0.21 0.21 CTED 0.18 0.18 0.19 0.19 0.38 0.53 0.27 0.27 TO* 0.05 0.05 0.07 0.07 0.24 0.32 0.08 0.08 kNN both HE methods wrongly assigned about the half of the labels and about 20% of total labels were assgined to the root label. Here, GT extracted a much worse hierarchy as shown by CTED being 0.15 higher for GT than for Voting For BoosTexter both HE methods built the same hierarchy and no label was wrongly assigned to the root. All extracted hierarchies were one level deeper than the original one Although Voting produced worse hierarchies than GT on two previous datasets, this time its distance values were comparable or even better. In comparison to Voting, GT has higher values for all distances on the multi-labels of MLkNN. Voting has the advantage of being a much simpler method and of being more dataset independent. Still the tree distances have the same ranking order for all classifiers for both HE methods VI. CONCLUSION In this paper we studied Hierarchical Multi-label Classification \(HMC tive was to derive hierarchical relationships between output classes from predicted multi-labels automatically. We have developed a data-mining-system based on two recently proposed multi-label extensions of the FAM and ARAM neural networks: ML-FAM and ML-ARAM as well as on a Hierarchy Extraction \(HE algorithm builds association rules from label co-occurrences 


and has two modifications. The presented approach is general enough to be used with any other multi-label classifier or HE algorithm. We have also developed a new tree distance measure for quantitative comparison of hierarchies In extensive experiments made on three text-mining realworld datasets, ML-FAM and ML-ARAM were compared against two state-of-the-art multi-label classifiers: ML-kNN and BoosTexter. The experimental results confirm that the proposed approach is suitable for extracting middle and large-scale class hierarchies from predicted multi-labels. In future work we intend to examine approaches for measuring the quality of hierarchical multi-label classifications REFERENCES 1] M. Ruiz and P. Srinivasan, Hierarchical text categorization using neural networks, Information Retrieval, vol. 5, no. 1, pp. 87118 2002 2] N. Cesa-Bianchi, C. Gentile, and L. Zaniboni, Incremental algorithms for hierarchical classification, The Journal of Machine Learning Research, vol. 7, pp. 3154, 2006 3] , Hierarchical classification: combining Bayes with SVM, in Proceedings of the 23rd international conference on Machine learning ACM New York, NY, USA, 2006, pp. 177184 4] F. Wu, J. Zhang, and V. Honavar, Learning classifiers using hierarchically structured class taxonomies, in Proceedings of the 6th International Symposium on Abstraction, Reformulation And Approximation Springer, 2005, p. 313 5] L. Cai and T. Hofmann, Hierarchical document categorization with support vector machines, in Proceedings of the thirteenth ACM international conference on Information and knowledge management ACM New York, NY, USA, 2004, pp. 7887 6] C. Vens, J. Struyf, L. Schietgat, S. Dz?eroski, and H. Blockeel Decision trees for hierarchical multi-label classification, Machine Learning, vol. 73, no. 2, pp. 185214, 2008 7] E. P. Sapozhnikova, Art-based neural networks for multi-label classification, in IDA, ser. Lecture Notes in Computer Science, N. M Adams, C. Robardet, A. Siebes, and J.-F. Boulicaut, Eds., vol. 5772 Springer, 2009, pp. 167177 8] M. Zhang and Z. Zhou, ML-kNN: A lazy learning approach to multilabel learning, Pattern Recognition, vol. 40, no. 7, pp. 20382048 2007 9] R. Schapire and Y. Singer, BoosTexter: A boosting-based system for text categorization, Machine learning, vol. 39, no. 2, pp. 135168 


2000 10] K. Zhang, A constrained edit distance between unordered labeled trees, Algorithmica, vol. 15, no. 3, pp. 205222, 1996 11] A. Maedche and S. Staab, Measuring similarity between ontologies Lecture notes in computer science, pp. 251263, 2002 12] G. Carpenter, S. Martens, and O. Ogas, Self-organizing information fusion and hierarchical knowledge discovery: a new framework using ARTMAP neural networks, Neural Networks, vol. 18, no. 3, pp. 287 295, 2005 13] A.-H. Tan and H. Pan, Predictive neural networks for gene expression data analysis, Neural Networks, vol. 18, pp. 297306, April 2005 14] G. Carpenter, S. Grossberg, N. Markuzon, J. Reynolds, and D. Rosen Fuzzy ARTMAP: A neural network architecture for incremental supervised learning of analog multidimensional maps, IEEE Transactions on Neural Networks, vol. 3, no. 5, pp. 698713, 1992 15] Y. Freund and R. Schapire, A decision-theoretic generalization of online learning and an application to boosting, Journal of computer and system sciences, vol. 55, no. 1, pp. 119139, 1997 16] K. Zhang and T. Jiang, Some MAX SNP-hard results concerning unordered labeled trees, Information Processing Letters, vol. 49 no. 5, pp. 249254, 1994 17] G. Tsoumakas and I. Vlahavas, Random k-labelsets: An ensemble method for multilabel classification, Lecture Notes in Computer Science, vol. 4701, p. 406, 2007 18] K. Punera, S. Rajan, and J. Ghosh, Automatic construction of nary tree based taxonomies, in Proceedings of IEEE International Conference on Data Mining-Workshops. IEEE Computer Society 2006, pp. 7579 19] T. Joachims, A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization, in Proceedings of the Fourteenth International Conference on Machine Learning. Morgan Kaufmann Publishers Inc. San Francisco, CA, USA, 1997, pp. 143151 20] A. McCallum, Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering, 1996 http://www.cs.cmu.edu/ mccallum/bow 21] D. Lewis, Y. Yang, T. Rose, and F. Li, RCV1: A new benchmark collection for text categorization research, The Journal of Machine Learning Research, vol. 5, pp. 361397, 2004 22] M. Porter, Snowball: A language for stemming algorithms, 2001 http://snowball.tartarus.org/texts/introduction.html 


the US census data set. The size of pilot sample is 2000, and all 50 rules are derived from this pilot sample. In this experiment the ?xed value x for the sample size is set to be 300. The attribute income is considered as a differential attribute, and the difference of income of husband and wife is studied in this experiment. Figure 3 shows the performance of the 5 sampling 331 6DPSOLQJ9DULDQFH             9D UL DQ FH R I V WL PD WL RQ  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW    


      6D PS OL QJ  RV W 9DU 9DU 9DU 5DQG b 6DPSOLQJ$FFXUDF          5  9DU 9DU 9DU 5DQG c Fig. 2. Evaluation of Sampling Methods for Association Rule Mining on the Yahoo! Dataset procedures on the problem of differential rule mining on the US census data set. The results are also similar to the experiment results for association rule mining: there is a consistent trade off between the estimation variance and sampling cost by setting their weights. Our proposed methods have better performance than simple random sampling method 


We also evaluated the performance of our methods on the Yahoo! dataset. The size of pilot sampling is 2000, and the xed value x for the sample size is 200. The attribute price is considered as the target attribute. Figure 4 shows the performance of the 5 sampling procedures on the problem of differential rule mining on the Yahoo! dataset. The results are very similar to those from the previous experiments VI. RELATED WORK We now compare our work with the existing work on sampling for association rule mining, sampling for database aggregation queries, and sampling for the deep web Sampling for Association Rule Mining: Sampling for frequent itemset mining and association rule mining has been studied by several researchers [23], [21], [11], [6]. Toivonen [23] proposed a random sampling method to identify the association rules which are then further veri?ed on the entire database. Progressive sampling [21], which is based on equivalence classes, involves determining the required sample size for association rule mining FAST [11], a two-phase sampling algorithm, has been proposed to select representative transactions, with the goal of reducing computation cost in association rule mining.A randomized counting algorithm [6] has been developed based on the Markov chain Monte Carlo method for counting the number of frequent itemsets Our work is different from these sampling methods, since we consider the problem of association rule mining on the deep web. Because the data records are hidden under limited query interfaces in these systems, sampling involves very distinct challenges Sampling for Aggregation Queries: Sampling algorithms have also been studied in the context of aggregation queries on large data bases [18], [1], [19], [25]. Approximate Pre-Aggregation APA  categorical data utilizing precomputed statistics about the dataset Wu et al. [25] proposed a Bayesian method for guessing the extreme values in a dataset based on the learned query shape pattern and characteristics from previous workloads More closely to our work, Afrati et al. [1] proposed an adaptive sampling algorithm for answering aggregation queries on hierarchical structures. They focused on adaptively adjusting the sample size assigned to each group based on the estimation error in each group. Joshi et al.[19] considered the problem of 


estimating the result of an aggregate query with a very low selectivity. A principled Bayesian framework was constructed to learn the information obtained from pilot sampling for allocating samples to strata Our methods are clearly distinct for these approaches. First strata are built dynamically in our algorithm and the relations between input and output attributes are learned for sampling on output attributes. Second, the estimation accuracy and sampling cost are optimized in our sample allocation method Hidden Web Sampling: There is recent research work [3 13], [15] on sampling from deep web, which is hidden under simple interfaces. Dasgupta et al.[13], [15] proposed HDSampler a random walk scheme over the query space provided by the interface, to select a simple random sample from hidden database Bar-Yossef et al.[3] proposed algorithms for sampling suggestions using the public suggestion interface. Our algorithm is different from their work, since our goal is sampling in the context of particular data mining tasks. We focus on achieving high accuracy with a low sampling cost for a speci?c task, instead of simple random sampling VII. CONCLUSIONS In this paper, we have proposed strati?cation based sampling methods for data mining on the deep web, particularly considering association rule mining and differential rule mining Components of our approach include: 1 the relation between input attributes and output attributes of the deep web data source, 2 maximally reduce an integrated cost metric that combines estimation variance and sampling cost, and 3 allocation method that takes into account both the estimation error and the sampling costs Our experiments show that compared with simple random sampling, our methods have higher sampling accuracy and lower sampling cost. Moreover, our approach allows user to reduce sampling costs by trading-off a fraction of estimation error 332 6DPSOLQJ9DULDQFH      


     V WL PD WL RQ R I 9D UL DQ FH  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW          6D PS OL QJ  RV W 9DU 9DU 


9DU 5DQG b 6DPSOLQJ$FFXUDF          5  9DU 9DU 9DU 5DQG c Fig. 3. Evaluation of Sampling Methods for Differential Rule Mining on the US Census Dataset 6DPSOLQJ9DULDQFH             9D UL DQ FH R I V WL 


PD WL RQ  9DU 9DU 9DU 5DQG a timation 6DPSOLQJ&RVW          6D PS OL QJ  RV W  9DU 9DU 9DU 5DQG b 6DPSOLQJ$FFXUDF         


    5  9DU 9DU 9DU 5DQG c Fig. 4. Evaluation of Sampling Methods for Differential Rule Mining on the Yahoo! Dataset REFERENCES 1] Foto N. Afrati, Paraskevas V. Lekeas, and Chen Li. Adaptive-sampling algorithms for answering aggregation queries on web sites. Data Knowl Eng., 64\(2 2] Rakesh Agrawal and Ramakrishnan Srikant. Fast algorithms for mining association rules. In Proceedings of the 20th International Conference on Very Large Data Bases, pages 487499, 1994 3] Ziv Bar-Yossef and Maxim Gurevich. Mining search engine query logs via suggestion sampling. Proc. VLDB Endow., 1\(1 4] Stephen D. Bay and Michael J. Pazzani. Detecting group differences Mining contrast sets. Data Mining and Knowledge Discovery, 5\(3 246, 2001 5] M. K. Bergman. The Deep Web: Surfacing Hidden Value. Journal of Electronic Publishing, 7, 2001 6] Mario Boley and Henrik Grosskreutz. A randomized approach for approximating the number of frequent sets. In ICDM 08: Proceedings of the 2008 Eighth IEEE International Conference on Data Mining, pages 4352 Washington, DC, USA, 2008. IEEE Computer Society 7] D. Braga, S. Ceri, F. Daniel, and D. Martinenghi. Optimization of Multidomain Queries on the Web. VLDB Endowment, 1:562673, 2008 8] R. E. Ca?isch. Monte carlo and quasi-monte carlo methods. Acta Numerica 7:149, 1998 9] Andrea Cali and Davide Martinenghi. Querying Data under Access Limitations. In Proceedings of the 24th International Conference on Data Engineering, pages 5059, 2008 10] Bin Chen, Peter Haas, and Peter Scheuermann. A new two-phase sampling based algorithm for discovering association rules. In KDD 02: Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 462468, New York, NY, USA, 2002 ACM 


11] W. Cochran. Sampling Techniques. Wiley and Sons, 1977 12] Arjun Dasgupta, Gautam Das, and Heikki Mannila. A random walk approach to sampling hidden databases. In SIGMOD 07: Proceedings of the 2007 ACM SIGMOD international conference on Management of data pages 629640, New York, NY, USA, 2007. ACM 13] Arjun Dasgupta, Xin Jin, Bradley Jewell, Nan Zhang, and Gautam Das Unbiased estimation of size and other aggregates over hidden web databases In SIGMOD 10: Proceedings of the 2010 international conference on Management of data, pages 855866, New York, NY, USA, 2010. ACM 14] Arjun Dasgupta, Nan Zhang, and Gautam Das. Leveraging count information in sampling hidden databases. In ICDE 09: Proceedings of the 2009 IEEE International Conference on Data Engineering, pages 329340 Washington, DC, USA, 2009. IEEE Computer Society 15] Loekito Elsa and Bailey James. Mining in?uential attributes that capture class and group contrast behaviour. In CIKM 08: Proceeding of the 17th ACM conference on Information and knowledge management, pages 971 980, New York, NY, USA, 2008. ACM 16] E.K. Foreman. Survey sampling principles. Marcel Dekker publishers, 1991 17] Ruoming Jin, Leonid Glimcher, Chris Jermaine, and Gagan Agrawal. New sampling-based estimators for olap queries. In ICDE, page 18, 2006 18] Shantanu Joshi and Christopher M. Jermaine. Robust strati?ed sampling plans for low selectivity queries. In ICDE, pages 199208, 2008 19] Bing Liu. Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data \(Data-Centric Systems and Applications Inc., Secaucus, NJ, USA, 2006 20] Srinivasan Parthasarathy. Ef?cient progressive sampling for association rules. In ICDM 02: Proceedings of the 2002 IEEE International Conference on Data Mining, page 354, Washington, DC, USA, 2002. IEEE Computer Society 21] William H. Press and Glennys R. Farrar. Recursive strati?ed sampling for multidimensional monte carlo integration. Comput. Phys., 4\(2 1990 22] Hannu Toivonen. Sampling large databases for association rules. In The VLDB Journal, pages 134145. Morgan Kaufmann, 1996 23] Fan Wang, Gagan Agrawal, Ruoming Jin, and Helen Piontkivska. Snpminer A domain-speci?c deep web mining tool. In Proceedings of the 7th IEEE International Conference on Bioinformatics and Bioengineering, pages 192 199, 2007 24] Mingxi Wu and Chris Jermaine. Guessing the extreme values in a data set a bayesian method and its applications. VLDB J., 18\(2 25] Mohammed J. Zaki. Scalable algorithms for association mining. IEEE Transactions on Knowledge and Data Engineering, 12:372390, 2000 


333 



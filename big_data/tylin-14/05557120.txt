Notice of Retraction      After careful and considered review of the content of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles  We hereby retract the content of this pape r. Reasonable effort should be made to remove all past refere nces to this paper  The presenting author of this paper ha s the option to appeal this decision by contacting TPII@ieee.org   


The researches of Load Equalization Question in Information Construction of New Countryside  Ma Yu-bao, Mei Shen-xin Ding  Ren-yuan Dept of network engineering Anhui Agricultur al University Hefei, China E-mail mayb@ahau.edu.cn meisx@ahau.edu.cn Abstract i n the platform for the integration of information systems in new rural areas, the application of data mining technology to achieve load balancing. That is, according to historical records, in 
some way to forecast the upcoming visit of a request and in accordance with certain rules for dealing with pre-reading, to balance load and speed up access speed. At the same time, running on the service side of the monitoring process will be the regular collection of farmers and learn the history of the nodes within the cluster load of information, through the analysis of these data and mining, the server clustering within a reasonable variety of resources to optimize and re-configuration  Key words data mining; load balancing, response time I   
I NTRODUCTION  Township is the key to the new rural development nodes, the existing township basic information systems in vertical mode of operation, such as "Pioneer Network" and "Distance Education Network McKinnon project", "Chimura town of 100 projects such as one in th e township level of mutual separation not integration of the use of hardware and software resources. The new rural information integration platform to build, is based on the "composite two-story structure" to achieve the township information platform horizontal information integr ation, through the building 
such as office management, agriculture, construction project management, financial management of township infrastructure rural community personnel management, professionals such as population, land management system interface, integration of the threetier structure of hardware and software of information resources and improve rural comprehensive information management t echnology and services capabilities, to explore an integrated information technology to improve rural integrated a number of 
channels and operations maintenance mode Demonstration project ba sed in Jixi County completion of the project will be built with county and township \(town\v illage of the three-tier management and rural composite structure combining two of the eight major characteristics of the new information-based demonstration bases in rural areas formed to serve the "three rural issues ", effectively a two-pronged approach the core of community-based management pilot area, the establishment of related technical system and functi on modules, to adapt to 
economic, social and population, resources environment development, and promote the modernization of the new rural development. In project implementation, found that wh en a number of farmers at the same time learning of ten lead to long-distance Internet server-side load balancing problem system is relatively slow response time significantly affected the farmers interest in learning.  In this article to address this problem, explore in depth the theoretical and experimental analysis  II  REQUESTS FORECAST 
 Through the visit to the historical data and farmers learning habits of observati on, found that if the farmers of a fragment has been training content, then related or similar paragraph was very likely to continue the request. From this view, in terms of logic between the content of the existence of an association, which under a certain probability, we can predict the next farmers to access documents. It is this type of speculation, this paper presents data mining [2 applied t o t h e conce p t of load balancing system From the farmers to learn th e history of records and access logs, you can analyze a number of association 
rules between sentences, such as the existence of such a rule "Si => Sj", so if farmers request to the server file Si, documents should be considered ahead of time whether there is a need Sj ready, because the farmers is likely forthcoming visit to the document. Farmers to visit in a document, will be associated with a document in advance of a server on the other read, then after the end of the current file access can be switched to another server in the server, this document has been pre dealt with, so get a better response time 
2010 Second International Conference on Information Technology and Computer Science 978-0-7695-4074-0/10 $26.00 © 2010 IEEE DOI 10.1109/ITCS.2010.85 322 


   Fig ure 1 Transition probability sentences   III  A PPLICATION OF DATA MINING TECHNOLOGY TO ACHIEVE LOAD BALANCING  The use of the database can be recorded for each visit to the details of farm ers, the information in each visit are automatically uploaded to the server. All this information was retained in the history of a visit Learning History\ database table Judging from the current usage and get results statistics and analysis can be a relatively simple data For example, the number of households logs on, with an accumulated time and sub-line, each sentence was the number of trained and so on. Now, the needs of growing from this table to further tap such information and that is: farmers trained after a sentence, followed by the continuation of the training that there are several possible sentences, respectively, what is, and must be given the How big is the probability, as shown in Figure 1. Among them said from state to state transition probability, that is ij p i S j S i j t ij S S X P 1 1 S 11 p 12 p t X  1 S 2 S p For example, in Figure 1, the participants trained the probability of du plication of training is to continue to move th e probability of training is  To farmers in a first training course of the visit set off a collection of all sentences with the following vector. Among them, each sentence a boolean variables are described, 1 representative of the appropriate sentence to be trained, 0 on behalf have not been trained T 1  1  0  1  1  0  0  1  1  By analyzing these vectors will be able to know what the sentence will be consecutive visits, the records kept by the server side is very large, it will consider offering these cour ses and the sentence in accordance with the sub-directory in order to improve mining efficiency For example, the sentence Si trained farmers will be trained sentence Sj, then th e following association rules can be used to describe this model  60  2  Confidence Support S S j i  Among them, the support rate of 2%, indicating that farmers in the analysis of historical data in training two percent of rural households at the same time learning the Si and Sj, confidence is 60% indicated that 60% of farmers in the training will be followed after the Si Training Sj If the conclusion is consistent with the predicted value, or closer, it could be that the data mining algorithm is credible. In th eory, can be given minimum support threshold and minimum confidence threshold of the reference value to restrain the above rules, to meet the two thresholds,  to known as the meaningful association rules association rules. On ly to meet the minimum threshold of support for the use of association rules pre-sentence access, at the same time ignored those who have not reached the minimum threshold of trust ru   Before algorithm in the application of the abovementioned, the first of Learning History table sorting Apriori algorithm for data ne eded to prepare. The table all records or selected part of the record ID and training in accordance with the farmers time to reorder. In order to determine and collect a specific participant in a learning process the entire con tents of the visit will be to set a time interval threshold, which is lower than the threshold of learning records were identified as belonging to a collection of learning content, otherwise been identified to start a new round of study. After finishing a farmers Learning History table as shown below. To illustrate the problem, the table has been simplified, assuming a total of six records, which is 6 times to learn the history of the situation   S 4  S 2  S 1  S 3  S 5  p 23 p 33 p 12  p 11  p 24  p 14  p 34 p 51  p 45   
323 


Table 1: after pre-treatment visit historical table  Learning History Data Mining Table Learning HistoryID SentenceID LH_00000001 Sentence_1_1 Sentence_1_2  LH_00000002 Sentence_2_1 Sentence_2_2    LH_00000006 Sentence_6_1 Sentence_6_2  Table 2 support frequency and Item sets C1 L1 Item sets  support frequency  Item sets  support frequency  Sentence_1_1 1 Sentence_1_2 2 Sentence_1_2 2 Sentence_1_3 2 Sentence_1_3 2 Minimum support frequency      File 1 Part 1 File 1 Part 2 File 1 Part k File 1 Part n  File 2 Part 1 File 2 Part 1 File 2 Part 1 File 2 Part 1   File 2 Part 1 File 2 Part 1 File 2 Part 1 File 2 Part 1   Server 1 Server 2 Server k Server n  Figure2Schematicdiagramoffilestorage Fo llowing the excavation algorithm specific description Algorithm 1 is based on th e mining algorithm Aprori Step 1 of the first pass algorithm cycle, the database for each \(data\of all candidate I-item sets C1 elements Scan database to determine the C1 support of the various elements of the frequency Step 2 on the various elem ents of C1 through the minimum support for the frequency of choice, the L1 After these two steps, it will be carried out as shown in the table a set of data Step 3, Calculated to obtain  th e two K-1\ sets together to connect to produce a candidate Ck 1 1 k k L L St ep 4 using the above-mentioned removed Apriori nature could not produce frequent item sets designate options set a new Ck Step 5 on the various elements Ck support by minimizing the frequency of conducting trade-offs, the Lk Step 6 above Step 4 to Step 6 of the main work is done: keep the frequent use of \(K-1 have a candidate K-item sets Ck. Cycle of this process until no new end item sets  Through the above algorithm, ultimately available to meet the minimum support from the frequencydesignate set of options cons isting of frequent item sets The generation of association rules: In the excavation from the database all the frequent item sets you can more easily access to the corresponding association rules. That is, to produce to meet the minimum support and minimum confidence in the strong association rules, we can use the support of item sets to calculate the frequency of conditional probability, thereby gaining the confidence of association rules, the fo llowing type shown  i j i i j j i S Count Support S S Count Support S S P S S Confidence _ _   In this way, will be a set of rules Si => Sj, which the trust is greater than the minimum threshold of trust will be retained as a final output. Sj here that there can be many months, to select only the credibility of the largest that Sj, that is, for each Si and retain only the credibility of the largest that the rules  IV  STORAGE POLICY  Shared memory is a new rural information system integration platform for server clusters need to be addressed in one of the key issues, the system of storage capacity and access speed have higher requirements. The system of paper forms of organization have a more prominent feature of the material deposited mostly from video recording, live fragments. After pre-processi ng and compression, the original media files are in accordance with the sentence  
324 


cut to become a group of relatively small fragments of integrity. Based on this ch aracteristic,  in the general file system design document subparagraph \(File Stripping\ and file cache distributed storage strategy. Sub-media files will be stored on multiple servers can improve overall system performance, easier to achieve the various storage load balancing between nodes u ch as Fi gure 2 System of certain docume nts frequent high level visits, which is far greater than some of the other. Of all the server systems to save copies of all the documents is a simple, wo rkable solution, it is clear that the larger overhead, the pr ogram for the visit to the probability of a number of relatively small document is a waste of resources. To this end, the design of a redundancy document st orage strategy 1.x Through the above-mentioned data mining [7 a  result, it is not difficult to analyze statistics and are frequently accessed files. Based paper was the number of visits per hour for the frequency of visits recorded for the frequency of visits then if the larg er, is illustrated in these documents is to visit "hot spots" can be copied to mu ltiple servers. According to the frequency of visits to adjust the location of documents, making each server is basically the same value. This will not app ear on a server to store all the files are often visited, an d other servers on the file access probability are smaller. Monitor regularly get each server load, if we find that the value of comparison between the differences in wealth will start a process of adjusting the distribution of documents. For performance considerations, such adjustment can not in real time i f N i 1 i File _ N i i f 1 i f i f  EXPERIMENTAL AND TESTING   First of all, describe the experimental environment, a number of data files were ra ndomly distributed in more than one server, the documents themselves in terms of logic there is no correlation. In order to closer to the real application environment, using about 3-5M compressed audio files stored on each server 100 Using Python language write multi-threaded server program. The main process are responsible for monitoring the request, if a re quest arrived, then start a new thread for a subset of services, continue to monitor the main process. Services sub-threads through the link to read the overall table and buffer table documents on request information and the current server status information, and then give a response in accordance with the algorithm The client can be taken two ways to simulate the real visit farmers. One is by reading a document linked to triple, to be a need to access the documents, as well as the probability of the vis it. Subsequently, the client through a random proces s to the probability of access to files to the probability ij p  ij p j f 1  of random access a file. Another way what access to the real record of real farmer, to reproduce in the experiment, so as to achieve the purpose of the visit simulation farmers  5.1 ASSOCIATED DATA STRUCTURE  Triples visit to describe the current list of documents most likely continue to visit the next visit to the transfer of documents and its probability. Such linkages in the real environment will be to get through data mining and production, in other words, the purpose of data mining and the result is to generate and update the list of triples      ij j i p f f Am ong them is the representative of the current vi sit of the document is on behalf of most likely to vi sit a paper document is on behalf of the visit  followed the probability of accessing files Table 3 bel ow shows an example i f j f p ij i f j f File i File j Pij File_SVR_01_01 File_SVR_02_01 0.8 File_SVR_01_02 File_SVR_02_02 0.7 File_SVR_01_03 File_SVR_02_03 0.6  Table 3 File association Triples    
325 


5.2  B UFFER POOL DATA STRUCTURE  In order to more effectively manage the buffer zone we need to know what documents have been read into the buffer zone, the proportion of these documents and whether space is being used, such as basic information The definition of the following data structure used to describe the use of the buffer zone Algorithm 2 buffer class definition START class BufferPool def __init__ \(self  self.lock  threading.Lock   Mutex Semaphore self.pool  buffe r pool  def addToBuffer \(self, file\d into the buffer content self.lock.acquire \(\# critical region began  bufferBlock = \( 'name': filename, 'size': size, 'bytes bytes,' reference ': 0 File name, buffer size, the contents of the documents, citing a number of  self.lock.release \(\# end of critical region def readFromBuffer \(filename\ove the buffer content def isInBuffer \(filename\determine the file exists in the buffer zone END Each file is read into the buffer zone after which a new Buffer Block, in accordance with the above approach to the basic information into a buffer with Ikegami added. When the file is accessed by traversing the entire sequence can be informed of whether the document had been read into the buffer zone also need to modify the number of f iles, record the number of requests are visiting. Above modification and maintenance process between the mutually exclusive in order to control complicate d, we should introduce a semaphore mechanism, making all the modifications to the list of operations to keep pace 5.3  A NALYSIS OF EXPERIMENTAL RESULTS  Local tests, trials in this group, the client is located in a number of random requests for files on local disk the client records from the re quest sent to a file to receive the end of time interval. Tests were carried out twice, the first is not to take any strategy,  the second test is in the deployment of these strategies carried out by the server. Client, resp ectively, simulated 10 threads 20 threads, 30 threads, 40 threads and 50 concurrent threads on the circumstances. Abscissa in Figure 3 that the number of simultaneous threads, t hread-ordinate that the average response time. At the top of the curve is the first test results, the bottom of the curve is the result of the second test   Figure 3 results contrast map   From the data that the visit has not been preprocessing the request, with the concurrent degree of improvement in performance is obvious; and after a visit to the request of the forecast, the performance improved significantly 512M memory in a server network bottlenecks in the neglected cases, at the same time can support more than 20 concurrent requests, the numerical main memory size limit The next test of this group is in a real network environment, the client in accordance with the mining algorithm to sim u late the res u lts obtained acces s and the results compared with the random test algorithm. In this exper iment, the client simulated multicast mechanism, by reading a list of servers, each server to request the corresponding port. In practice this will be multicast protocols and multicast routers to achieve. Taking into account the request packet size compared with the response for the message can be ignored, so that the alternativ e test results will not be a visible impact. Experimental specific steps are below such as algorithm 3 3 Simulation Algorithm Client Access Step 1 client read associated ternary group, read the file list at the same time Step 2 program were randomly selected from a list of files in the document as a starting point to visit, a request to all servers Step 3 Process will read the list of associated tuples corresponding value, through a random process to the probability of visit tuples na med in a docu ment to the probability of random access a file Step 4 Repeat the process until the time they reach the required value, the end of the visit Figure 4 2 Gaussian curve representing the strategies mentioned in this article and random strategy to respond to the mean and variance, abscissa on behalf of the average probability density longitudinal coordinates  
326 


From the results can be seen that the dotted line without pretreatment client re sponse time, the mean is seconds  2.9254 1 variance is 1.2329 1  Solid line on behalf of a result of these algorithms to deal with the response time, the mean is seconds  2.5654 2 variance is 0.9690 2    Figure 4 based on the local multi-threaded concurrent access comparison   C ONCLUSION  The user needs is input Appl et through to the system Applet user to user demand Agent. Agent users in the analysis of the needs of users after the creation of data mining Agent for the task. Acco rding to the data mining tasks, moved to the local mach ine on data mining. In its move to the local machine, its management to create a local Agent to manage their own local registration, such as files data mining Agent migration in the local machine the local management of Agent will be removed. Data Mining Agent in accordance with the needs of the database data to a database of local Agent to issue requests for data, a database of local Agent, upon request, to query the database data, and return to the Data Mining Agen t. Data Mining Agent in the completion of the mission, the transfer request back-end data mining, the results will be re ported to the User Agent, User Agent that will result is a document or data sent to the formation of Applet chart shows  V  C ONCLUSION  Through all these experimental results and analysis, we can be seen after pretreatment of server response time curve given the mean and variance in the relatively small area. This article mentioned that the application of this strategy in response to the server speed and stability have improved larger Load balancing problem is th e building of agricultural information of one of the major problems in the research and analysis of the current popular ity of a variety of static and dynamic balance algorithm da ta mining-based load balancing method of thinking The use of historical records of the visit of the data mining results, so that the server has the ability to forecast the upcoming visit and make pretreatment. Papers on data mining methods and load balancing strategies were described and analyzed on the basis of tests and experiments, and achieved better results Of course, many cities in between the data access and synchronization will be implemented in specific operations also need to supplement the current strategy and modification A CKNOWLEDGMENT  In this paper, Anhui Province by the Office of Education Youth Education Fund, the subject of scientific research 2005jq1053\e corresponding author is Mei shen-xin R EFERENCES   Zhu Yongzhi. H e terogeneous Beo w ulf sy stem load balancing technology Research and Implementation. ,2008,7:60 Computer technology and development-62  h m for the practi ce of [M]. Beijing Higher Education Press, 2004   A high perform ance portable im ple m entation o f the m e ssage  l el Co m puting, 1996,22 \(6 828  mm i ng C, MPI and Ope n MP [M]. Beijin g Tsinghua University Press, 2005  W a ng Gang W a ng this y e ar  FNN and GAbased integr ation of data mining method. Computer technology and development ,2008,2:119125  i H Fukuda T, Shibata T et a1. Structure optim ization of Fuzzy Neural Network by Genetic Algorithm y Set s and Syste m s 1995,71 \(3\ :257-264  identification of sy stem s and its applications to modeling and cont rol on Systems, Man and Cybernetics, 1985,15 \(1\: l16-132   Li Yan g   hi gh Z h e n g g u an g L o r d Nic hol ls o f Birke n h ea d and inflammation. Based on neural networks and genetic algorithm data mining architecture Computer Engineering, 2004,30 \(6\55-15  
327 


 2173 


   2  6   &1   2   1      F  2 1 2  2                 6 


2  2  2 2  3   1       2 1              1  2   A 1 2  2 18- G        


f  3    2       6   1    2  2       2 2010 International Conference on Optoelectronics and Image Processing 978-0-7695-4252-2/10 $26.00  2010 IEEE DOI 10.1109/ICOIP.2010.250 251  2E  2  1     2   1   


     2 1  2  2     1  2      6     2 1 AA=A=H=A=A= \b\b !!\b   b\b HAA=A==HAA=A==\b !!\b \b  b\b HAA=A==HA=A= !! \b 1  2 b\b HAA=A==HA=A= !! \b b 2   1     


1    2   b\b HAA=A==HA=A= !!" \b b I  2 I#  2      1  2 b       2    2  18  C        6  2  


  1     D     1    2  f 9  2      2    6E    12    1    2 1&8   2   


  1 2      2   2    1      8  2        2 2   2 1       


  2   2 2   D                                


 7 .2     1    f    f      b b A b A b    2    2  2   1 1 2  81   


  18       6   G  6    1    6     0 1  1      1 1   6 


 2 \f 3%\f  f  f  f\b     2     2 1                 6    1  


   2    D    f 3\f             2           8 2   1 #-4 


     8 1        18    E 1  1          1   2   2 2 2      


        b b A252  b             8                


2        9    8         2 0     6  1      8 2  2  


 8   2  3\f            8  D    F  \b 1 8 & #J      b 1  1  4    2  


4 1    9  E 1  2 4 1    9 1   4      8 2  8 1  D 1        1 1  b 


     b b b b b  K            8          2 D 9   F  \b 1 8 ,+J  9 


     b 1     1 2  9 1  12 L 1   9  8       1  2      2   


     b b b b b  K            2  0 \b f  b\f      9       


  8 2   E 1   1     M13 31L 1    b  8E 1   1 #3\b?### 1  1     E 1   1 \b?###3        


1   1   b 1  2 2 18 2     8              1    2 \b 1    2  


    2          2   1 L 2 1   1   L 2 2    2 1  2        


    8  2H D \b A             2  2H D \b A 2 \f 3%\f  f   4%\f f !  , \f\b  C    2    2 


 6    3 1      253 6   1 L 2    6   1         f\b3\f       


               1     1     8 2    E       2  1   


     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



  A NOVEL ASSOCIATIVE CLASSIFICATION ALGORITHM: A COMBINATION OF LAC AND CMAR WITH NEW MEASURE OF WEIGHTED EFFECT OF EACH RULE GROUP PEI-YI HAO, YU-DE CHEN Department of Information Management National Kaohsiung University of Applied Sciences, Kaohsiung, Taiwan E-MAIL: haupy@cc.kuas.edu.tw 109734512 3@cc.kuas.edu.tw Abstract In recent, Association Classification not only has widely adopted but also has performed well in data mining. The literatures have been argued that the small disjunction and using multiple class-association rules have significant effect on classification accuracy. This paper is based on CMAR Classification based on Multiple Class-Association Rules Adriano Veloso proposed Lazy Associative Classifier algorithm for Small Disjunction mining. In addition, we collocate with a new weight calculation method in our algorithm to solve weight bias problem of CMAR. This paper uses UCI 26 data set for experiment on our proposed algorithm. The finally results convincingly demonstrated that our proposed algorithm is high accuracy Keywords  ssociative Classification; Association Rule; Data mining  Multiple Rules; CMAR; LAC  1  Introduction Associative classification was proposed by Bing Liu et al  CBA algorithm. It refers to Srikant and Agrawal proposed apriori association  apriori association rule is a way to deal with transaction data of associative mining. The main target is through it to find out those transaction items relationship. Beside, it can mine out knowledge with compreh ensibility in large data size situation so that it enables user to further research in potentially unknown rules. Th e CBA algorithm was proposed by Bing Liu et al That is inherited two indexes of apriori-support and confidence. Using both indexes become thresholds in rule mining and fu rther step for use of rules pruning. The purpose is in order to reduce redundant and harmful rules. The reason why it is to ensure all obtained rules are high quality and obtain good accuracy considered by efficiency and effectiveness. Subsequently, Wenmin Li et al proposed CMAR algorithm [4 Th e main d i f f er en ce  is adding a concept of multiple class-association rules in CMAR algorithm. In short, it is using two or more rules for predicting a class of test instance, and it replaces traditional method of using only one rule in classification phase. After calculating a weight, classifier will take the highest weight of class group, and then using it classifies a test instance Finally, it had been demons trated that using multiple rules classification can obtain good accuracy Small Disjunction problem had been argued by Robert C. Holte et al since 1980. The small disjunction problem is meaning that a rule may important for some instances but own low support so that the rules would be removed in rule mining phase. Therefore, it caused a problem that the accuracy may be decreased  M AR algorithm adopts support an d confidence been association rule threshold. It also lies in support characteristic of downward-closure to reduce calcu lation cost, so as to cut down the training cost. But, it may cause a problem that some important rules may be losing so that some instances may not be able to classified correctly. f only we decrease minsup to find out of those low support rules, that will meet a large number of rules and noise rules to be generated. The former causes calculating burden; the latter causes accuracy decrease The weight bias indicates that the weight calculation method is too overweight to reflect the fact. This paper is based on CMAR algorithm of using multiple class-Association rules for classification. In used Weighted X 2 it is batter than using chi-square test be rule weight because Weighted X 2 overcomes bias in some situation However, it still has had bias in some situation This paper is based on CMAR algorithm, and collocates with Adriano Veloso et al s lazy associative classification \(LAC\all disjunction rules mining Beside, we propose a new weight calculation method in order to improve CMAR Weighted X 2 bias problem \(which will be introduced in section 3\ and to obtain high classification accuracy The rest of this paper is arranged as follows. The 891 2011 IEEE 978-1-4577-0308-9/11/$26.00 Proceedings of the 2011 International Conference on Machine Learning and Cybernetics, Guilin, 10-13 July, 2011 


  section 2 introduces CMAR al gorithm and LAC algorithm The section 3 induces our proposed algorithm and discusses how to integrate LAC algorithm into our algorithm. The section 4 is experiment result of this paper. The section 5 is our conclusion 2  Materials and Methods 2.1  CMAR  CMAR algorithm was proposed by Wenmin Li et al since 2001  7]. The m a j o r feature is usi n g m u ltiple rules to classify an instance. In the past, the first thing is to sort all of the rules before the start of classification in associative classification. The so rting priority is order by confidence > support length of rule. It is in order to evaluate what rules have own the highest priority for using In classification phase, the first th ing is to scan rules from high priority to low, and then take the first-matched rule to classify test instance. After finding th e first-matched rule we will use the ruleês class to classify test instance  However, CMAR algorithm is unlike single rule classification method. It adopts multiple class-association rules to classify a test instance. The algorithm major concept is to pick out those matched rules which match test instance. According to thos e rules, algorithm will calculate their Weighted X 2 by rule class groups. Then, the class of the maximal Weighted X 2 of group is selected to classify test instance  In parts of classification phase, CMAR is a multiple class-association rules algorithm. When a test instance will be classified, CMAR algorithm will select a number of rules. Then, pick ou t the rule group which one of rule groups has own the highest Weighted X 2   More detail, the first thing is to collect rules, that the rules can correctly classify test instance. After that, we have to compare those rules whether all rules have same class. If totally obtained rules have same class, CMAR will use this class to classify test instance. Oppo sitely, if obtained rules are not same, those rules will be grouped by classes of rules Then, after calculated each groupês Weighted X 2 the CMAR will use own the highest Weighted X 2 value of groupês class to classify test instance      2 2 2 2 max  X X X X weighted  e T T c P c P X       sup  sup  sup  min{sup max 2 2    1  sup    sup   1  sup  sup   1  sup    sup 1  sup  sup 1 c T P T c P T c T P c P e          In parts of weighted calcu lation, CMAR algorithm adds X 2 testing conception called Weighted X 2 formula 1 In max  X 2 the CMAR paper has explanted that çThe max  X 2  is upper bound of X 2 value against rule The CMAR algorithm has three rule pruning methods but we have no explanation in this paper. The details can be seen in paper of CMAR.0  2.2  LAC Lazy Associative Classifier was proposed by Adriano Veloso et al. since 20 e subj ect is to so lve  small disjunction problem. LAC is a lazy learning algorithm. The algorithm gene rates rules only when the needing being classified instance is come in. The LAC algorithm can be divided into two phases: \(1\e first phase is data set filter, it retains the training instances which each instance has a tuple identical to the test instance at least one. That is to say, among the training set, if a training instance has no at least one tuple identical to the test instance, it will be removed. Otherwise, it will be retained 2\The second phase is using after phase one filtered training set to generate rules. Hen ce, the filtered training set will have absolute relation with test instance. And those rules of low support may have enough support to pass the threshold  Table 1. Data set, example sour Play Outlook Temperature Humidity Windy yes rainy cool normal false no rainy cool normal true yes overcast hot high false no sunny mild high false yes rainy cool normal false yes sunny cool normal false yes rainy cool normal false yes sunny hot normal false yes overcast mild high true no sunny mild high true yes hot low true     892 Proceedings of the 2011 International Conference on Machine Learning and Cybernetics, Guilin, 10-13 July, 2011 


  Table 2. Filtered data set, example sour Play Outlook Temperature Humidity Windy no   true yes overcast hot   yes hot   yes overcast   true no   true yes hot low true  Taking an example to explain the algorithm steps table 1 is a data set. The rows are training instances except last one is a test instance. Phase on e is to filter the training instances which have no at least one tuple identical to the test instance. In table 1, we can see the corresponding attribute {Outlook overcast}, {Temperature hot Humidity low} and {Windy true}. Therefore, the retained training set must to own those attributes at least one. The filtered training set has been presented in table 2 In phase two, it is using phase one results to start rules mining \(shown in table 2\. For minsup 40% situation, we get two rules and we can correctly classify test instance   1  outlook=overcastplay=yes 2  temperature=hotplay=yes  Oppositely, we use general associative classification method for rules mining in table 1. The minsup is identical to 40%, the result of rule mining as follows   1  windy=false and humidity=normalplay=yes 2  windy=false and temperature=coolplay=yes  A thing can be found from mined rules, the traditional associative classification method canêt satisfy test instance probably because of small disjunction problem  In order to accelerate the algorithm performance, LAC has a cache mechanism called pool of entries. Every rule and data are stored in items. A symbol {X C} represents a rule, and the item concept is <key, data>. Key={ X C data={Support, Confidence and Info.gain}. In the process of the LAC algorithm, first it checks whether a candidate rule is already in the cache. If an entry be found, th e entry will be used. Otherwise, the candid ate rule will be insert to entries pool and both su pport and confident after calculating and examining th is candidate rule. Moreover, it is in order to ensure that the rules will not exceed memory limit. It takes a coun t of the use frequen tly to decide which of the rule being discarded If quantity of entry will over the size, cache mechanism will discard least used entry, and then the new entry is added to cache. Hence, we can ensure that the memory will not beyond the limit 3  Methodology In section 3, we will discuss our proposed algorithm and experiment design. Our algorithm is based on CMAR algorithm, we adopt using multiple associative-rules classification and similar rules pruning method. On support calculation method, we adopts support calculation method of LAC algorithm to ove rcome small disjunction problem for raising the accuracy. Moreover, we propose a new weight calculation method. It is different than Weighted X 2 of CMAR algorithm so that we can overcome the weight bias problem 3.1  Rules Producing 1 items allRuleItmes\(dataSet 2 C 1 candidateGen items  3 F 1 dropLowLacSupportRules C 1 dataSet 4 CAR 1 dropLowConfdenceRules C 1  5   insertRulesToCR_Tree CAR 1 CR_Tree 6 For  k 2 F k 1  k  Do 7 C k candidateGen F k 1 items  8 F k dropLowLacSupportRules C k dataSet 9 CAR k dropLowConfdenceRules C k  10 CAR k delSpecificRules\(CAR k CR_Tree 11     insertRulesToCR_Tree CAR k CR_Tree 12 End 13 CARs  pruningRulesBasedOnDatabaseCoverage CARs  Figure 1. Rules producing pseudo code In our proposed algorith m, rule producing phase includes rules pruning and ru les mining. Our rules pruning is to cite from rules prunin g of CMAR algorithm. This paper adopts two kinds of rules pruning: \(1\ Only reserve general and high-confidence rul es. \(2\ Selecting rules based on database coverage  In parts of rules prod ucing, because the support calculation method of LAC algor ithm is different to traditional algorithm, so the variant FP-Growth of CMAR algorithm is not suitable for our algorithm. Therefore, this paper adopts apriori-like al gorithm to rules mining. In classification phase, classifier of this paper adopts a concept of using multiple rules from CM AR algorithm. Beside, the classifier collocates with our proposed new weight calculation method to achieve optimum accuracy  Rules producing pseudo code of this paper is shown in figure 1  Line 1 is to collect all attribute items from dataset for rule permutation using  There are some different than other algorithms  An example of CBA algorithm, its first 893 Proceedings of the 2011 International Conference on Machine Learning and Cybernetics, Guilin, 10-13 July, 2011 


  thing is to ob tain frequent items  That is to filter low support attribute items  If the support of attribute item is below threshold, it will be removed from item set  However we use LAC algorithm proposed support computing method so that we canêt filter an y attributes when start  Because of we depending on the LAC algorithm mechanism, the training set size will be changed when we filter the training set  Hence, the filter step must to be omitted by using LAC algorithm  Line 2 is to permute all attribute items for producing probable combination of rules  Line 3 is support testing  This support computing is progressing by LAC algorithm proposed support computing mechanism  That is that we will filter training set on ce before every computing support  It only reserves training instance rows that the training instance of attribute items fit with rule conditions at lease one  If a training instance has no reserve any attribute items, it would be remove d from training set  Hence, this training instance will not appear in current training set  More detail can be seen in LAC algorithm  In parts of support testing, if a candidate rule has not pass the support threshold, it will be removed from candidate rule set  This candidate rules will not continuously permute after removed. Beside, this rule will not be inserted into rule set  Line 4 is confidence testing  If a rule has not pass, it also will not be inserted into rule set  But this rule will permute continuously  Line 5 is to insert rule into CR-Tree  About CR-Tree more detail can be seen in paper of CMAR  Next line 6-12 is to produce k-items rule in loop way  Basically line 7-9, 11 is similar before we described  In parts of line 11, we add a specific rule testing  We reserve general rule but specific rule  Specific rule testing is progress in CR-Tree. The CR-Tree can avoid linear scanning in whole rules  It stores rules by tree structure so that it can accelerate specific rule testing executing time  In last of line 13, we start executing rules pruning that selecting rules based on database coverage, the more details can be seen in original paper of CMAR  3.2  Classification 1   matchedRules getMatchedRules\(CR_Tree target  2 If  matchedRulesês Class is same Then 3     isCorrect classifyTarget matchedRules.Class  target  4     return isCorrect  5 Else 6 For  i 0 matchedRules i  i  Do  7       groupWeighted class  getWeighted matchedRules i  8 End 9     maxGroup  getMaxGroupWeighted groupWeighted  10    isCorrect classifyTarget maxClassGroup.Class  target  11    return isCorrect  12 End If  Figure 2. Classification pseudo code In classification phase, this paper adopts CMAR algorithm proposed classification method of using multiple class-Association rules. It is to use one or more rules to classify a test instance. In addition, classification phase also collocates with a new weight mechanism to calculate each weight of rule groups. Thus, we can pick the best prediction out for classifying test instance Figure 2 is a classification phase pseudo code of this paper. Line 1 is to collect all of rules that the rule conditions are matched target test instance. Then, insert matched rules into matchedRules for storing. after storing matched rules Line 2 is to check matched rules whether all class of  rules is identical. If all class of rules were identical, we will use this class to classify target test instance. And we store the classified result in isCorrect and return them. Otherwise line 6-8 will be executed. Line 6-8 is to calculate the weight of rules, and to add up weigh t to the identical class of rule group. Line 9-11 is to pick maximal weight rule groups out and uses this class of rule group to classify target test instance. Finally, we store the classification result in isCorrect and return them In addition, this paper also has proposed a new weight calculating method, which is different than CMAR algorithm. The major objectiv e is to overcome the weight bias problem. The meaning of weight bias is that the weight may be not fair in some sit uation. In so me situation, the weight calculation may give some groups too more weight value so that it canêt reflect the fact. This paper adopts multiple class-Association rules of CMAR algorithm to be our classification method. The Weighted X 2 can solve some bias when directly using X 2 been our weight. However, it is still bias in some situation. We will demonstrate about this bias with an example Example 1: table 3 is a loan data set. This example has own two association rules   R1 job=no  rejected \(support=18 nfidence=60   R2 ed=univ approved \(support=190m nfidence=95  Table 3. An example of weight bias R1 approved rejected total job=yes 438 32 470 job=no 12 18 30 total 450 50 500  Intuitively, general classification method will pick high confidence rule for class ification between R1 and R2 Hence, rule R2 will be picked out because it has higher 894 Proceedings of the 2011 International Conference on Machine Learning and Cybernetics, Guilin, 10-13 July, 2011 


  confidence than R1. However, in example 1, R1 and R2 of X 2 value are 88.6 and 14.8 respectively. But, in CMAR algorithm, R1 and R2 of Weighted X 2 are 27.36 and 4.91 respectively. It can be seen from example 1 that using X 2 testing and Weighted X 2 can not actually reflect fact in this situation. In view of th is, this paper proposes a new weight method in association ru le so that the new weight can actually reflect fact and obtains better accuracy. This paper proposed a new weight calculation method is based on confidence. It is to utilize confidence itself provided quality information to be a base of weight calculation. And it also collocates with exponential function and power function for using. Therefore, it can readjust effect of confidence in rule grou p due to the functions decrease the effect of low quality rules This paper proposed weight calculation method is represented in formula 2. The p1 and p2 are adjustable argumen ts, it affects variation of rule weight value for each matched rules      exp 2 1 p conf p Weighted  2  Using example 1 to demonstrate, the arguments p1 and p2 are set to 2. The R1 and R2 are 2.05 and 6.08 respectively. R2 will be choice in our proposed method. But R1 will be choice in CMAR al gorithm. Thus, using our proposed weight calculation method can avoid bias of Weighted X 2 of CMAR in example 1 situation In parts of section 4, we test our proposed algorithm on 26 data sets from UCI Machine Learning Repository The 26 data sets has often been used to experiment of classification algorithm accuracy, and so are we 4  Experiment 4.1  Experiment Environment This paper uses UCI 26 data sets for experime  It is the most popular on classification algorithm. Those are anneal, austral, auto, breast, cleve, crx, diabetes, german glass, heart, hepatic, horse, hypo, iono, iris, labor, led7 lymph, pima, sick, sonar, tic tac, vehicle, waveform, wine and zoo data sets, respectively The experiment were performed on Windows 7 64bits and Intel i7-860\(OC 3.5G and 4GByte RAM. The program was constructed by Microsoft Visual C++ 2008 Express and was compiled into 64 bits. The experimentês arguments settings are according to the most common settings in associative classification algorithm. Th e support threshold  minsup dence threshold minconf o 50%, and coverage threshold to 4, and p 1 and p 2 of formula 3 is set to 2 4.2  Experiment  Result  In parts of rule producing limit, it is according to CMAR algorithm to limit the nu mber of rules on 9 data sets Other data sets will be completely mining. The limitation of number of rules is represented by table 4. In table 4, the condition is the meaning of number of X in rule X Y. For example, the number of conditions is 6 in data set of anneal It represents that permutation of attribute items will be end when the conditions of rule have more than 6 attribute items. Then, the algorithm will in to next phase. Due to that we can easily avoid that rules producing cannot be performed in finite resource when attribute items are too more Table 4. Limitation of the number of conditions Data Sets Conditions Data Sets Conditions Anneal 6 Sick 3 Auto 4 Sonar 4 Hypo 3 Vehicle 4 Iono 3 Zoo 6 Lymph 6    This paper of experiment compares to CBA ,CMAR LAC and L 3 8 algorit h m s. In parts of CB A a n d CMAR  algorithms results, we cited both data directly form paper of CMAR provided results. Bu t, LAC and L 3 algorithms data cite from their original papers The experiment results can be seen from table 5, we wi n 11 data sets over other algorithms. Our classification algorithm accuracy is 87.1 This paper proposed algorithm of accuracy is greater than CBA algorithm 2.41%, CMAR algorithm 1.88%, LAC algorithm 1.12% and L 3 1.01 5  Conclusion This paper is based on CMAR algorithm, and successfully integrates support calculation method of LAC algorithm into this paper. Th e experiment proves that using support calculation method of LAC algorithm to obtain small disjunction rule. Aft er combining with multiple associative-rule method, we can effectively raise the accuracy. On the other hand, this paper proposed a new weight calculation method not only greater than CMAR and LAC algorithm but also greater than L 3 algorithm 1.01%. In addition, this paper proposed algorithm usually has high accuracy whether the number of rules or number of candidates are high limitation or low limitation. Hence, the experiment demonstrates to us that our algorithm has features of stable and high accuracy In parts of follow-up, this paper has no perform all of 895 Proceedings of the 2011 International Conference on Machine Learning and Cybernetics, Guilin, 10-13 July, 2011 


  L 3 used data sets. Therefore, follow-up pursuer might consider performing more data set so that it could test our proposed algorithm whether it still has stable and high accuracy. Beside, using FP-Growth to mining rule is not suitable for support calculation method of LAC algorithm so far. Because of support calculation method of LAC algorithm is different than other classification algorithm But, we can still test other algorithm or data structure to combine with FP-Growth in rule mining. It might accelerate performed time in rule mining and support calculation so that the whole rule produci ng time could be cut down Table 5. Experiment results Data Sets CBA CMAR LAC L 3 Our Results Anneal 97.9 97.3 96.5 97.9 98.10 Austral 84.9 86.1 87.3 85.7 86.23 Auto 78.3 78.1 77.8 79 86.24 Breast 96.3 96.4 96.8 95.7 96.57 Cleve 82.8 82.2 84.4 82.2 82.48 Crx 84.7 84.9 85.8 84.8 85.07 Diabetes 74.5 75.8 80.3 78.7 77.34 German 73.4 74.9 76.6 74.2 74.9 Glass 73.9 70.1 74 77.6 75.78 Heart 81.9 82.2 83.1 84.4 83.33 Hepatic 81.8 80.5 82.9 85.8 86.50 Horse 82.1 82.6 85.5 84.2 83.12 Hypo 98.9 98.4 99 98.9 97.28 Iono 92.3 91.5 92.2 92 93.74 Iris 94.7 94 96.8 93.3 93.33 Labor 86.3 89.7 80.9 91.2 92.67 Led7 71.9 72.5 77.9 72.34 Lymph 77.8 83.1 80.9 85.1 87.19 Pima 72.9 75.1 78 78.3 78.39 Sick 97 97.5 98 95.5 95.86 Sonar 77.5 79.4 79.5 79.3 84.62 Tic-tac 99.6 99.2 99.4 99.5 98.75 Vehicle 68.7 68.8 71.1 72.2 74.00 Waveform 80 83.2 80.7 82.3 84.80 Wine 95 95 96.6 97.2 98.89 Zoo 96.8 97.1 93.5 92.1 97.09 Avg. 84.69 85.22 85.98  87.1 L 3 Avg 85.2 85.724 86.304 86.68 87.69 Win 0 1 11 3 11 References 1  Bing Liu, Wynne Hsu, Yiming Ma, çIntegrating Classification and Association Rule Mining Proceedings of the Fourth International Conference on Knowledge Discovery and Dat a Mining \(KDD-98  New York, USA, 1998, pp 80-86. \(The CBA system can be downloaded from http://www.comp.nus edu.sg/~dm2 2  Rakesh Agrawal, Tomasz Imie liski, and Arun Swami Mining Association Rules Between Sets of Items in Large Databases ACM SIGMOD Conference New York, USA, 1993, pp 207-216 3  Rakesh Agrawal, and Ramak rishnan Srikant, çFast algorithms for mining association rules in large databases Proceedings of the 20th International Conference on Very Large Data Bases\(VLDB  Santiago, Chile, September 1994, pp 487-499 4  W. Li, çClassication based on multiple association rules M.Sc. Thesis Simon Fraser University, April 2001 5  Adriano Veloso et al., çLazy Associative Classication Proceedings of the Sixth International Conference on Data Mining Washington, USA, 2006 pp 645-654 6  Robert C. Holte and Liane E. Acker and Bruce W Porter., çConcept  Learning  and  the Problem  of Small  Disjuncts In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence 1989, pp 813-818 7  W. Li, J Han, and J. Pei, çCMAR: Accurate and Efficient Classification Based on Multiple Class-Association Rules Proc. IEEE Intêl Conf. Data Mining \(ICDM ê01 San Jose, Califor nia, Nov. 2001 pp 369 8  Baralis, E., Chiusano, S., and Garza, P., çA Lazy Approach to Associative Classification Knowledge and Data Engineering, IEEE Transactions on Vol. 20 Issue.2, Feb. 2008 pp 156-171 9  UCI Machine Learning Repository http://archive ics.uci.edu/ml 1  Adriano Veloso et al Multi-label Lazy Associative Classification Proceedings of the 11th European conference on Principles and Practice of Knowledge Discovery in Databases Warsaw, Poland, 2007, pp 605-612 1  J. Han, J. Pei, and Y. Yin, çMining frequent patterns without candidate generation In SIGMOD Dallas TX, United States, May 2000, pp 1-12 1  Fayyad, U. M., And Irani, K B., çMulti-interval discretization of continuous-valued attributes for classification learning Proceedings of the 13th international joint conference on artificial intelligence  Chambery, France, Sep. 1 993, pp 1 022-1027 896 Proceedings of the 2011 International Conference on Machine Learning and Cybernetics, Guilin, 10-13 July, 2011 


for Data Mining in E-learning: The case of Open E-class ISBN:978-972-8924-97-3,2009 , pp 254-258 5] Jaideep Srivastava, Robert Cooley et al.,Web Usage Mining:Discovery and Applications of Usage patterns from Web Data, ACM SIGKDD, Vol 1, Issue 2, Jan 2000, pp 12-22 6] Khribi, M.K., Jemni M., Nasraoui O ,Automatic Recommendation for E-learning Personalization based on Web Usage mining techniques and information retrieval, Educational Technology and Society, I2\(4 7] Mei-Ling Shyu, Choochart Haruechaiyasak, Collaborative Filtering by Mining Association Rules from User Access Sequences,Proceedings of 2005 International workshop on challenges in web information retrieval and integration, 0-76952414-1/05,IEEE, 2005 8] Nasraoui, O. Soliman, M. Saka, E. Badia, A.Germain,  R A Web Usage Mining Framework for Mining Evolving User Profiles in  Dynamic  Web  Sites,IEEE  transaction   on Knowledge  and data engineering,Volume 20,Issue 2, Feb 2008 pp. 202-215 9]  Pasi   Franti,Olli   Virmajoki,   and   Ville   Hautamaki    Fast Agglomerative Clustering Using a k Nearest Neighbor graph,IEEE transaction on pattern analysis and machine intelligence.Vol 28,No11. November 2006, pp 1875-1881 10] Sathiya Moorthi V, Murali Bhaskaran V, Data preparation Techniques for Web Usage Mining in World Wide Web  an approach, International Journal of Recent Trends in Engineering Vol 2, No 4, November 2009 11] Sen Guo, Yongshen Liang et al.,Association Rule Retrieved from Web log based on Rough Set Theory, Fourth International conference on Fuzzy systems and Knowledge discovery, IEEE 2007 12] Siripom chimphlee,Naomie Salim,Mohd Salihin Bin Ngadiman, Witcha,Surat ,Rough Sets Clustering and  Markov Model for Web Access Prediction ,Proceedings of post graduate annual seminar 2006, pp. 470-474 13] Ying Cong, Changxu Ji, Application of Web-based Data Mining in Personalized online learning system, Proceedings of Wuhan International Conference on E-Business,pp150-156 


To be preserved, an association rule must satisfy two measures The support of an itemset A, denoted s\(A the frequency of the itemset A among the set of transactions T \(users history items in the context s\(A The con?dence of a rule X ? B, denoted c\(X ? B is defined by: c\(X ? B X?B s\(X Association rules are mined using the Apriori algorithm 15]. The liked and disliked items are first distinguished in the user history using their item ratings. This is done in order to gain a global view of the liked and disliked items For ratings between 1 and 5, values strictly lower than 4 are considered to represent disliked items. On the other hand values equal to or higher than 4 represent items that fit the users taste. Thus, items can be labeled with two values l like dislike users who have rated some of these items, we can obtain the extraction of the rules This module doesnt depend on a particular user. The computation is conducted generally for all users and is 6The insertion of multiple profiles under false identities in order to promote or denote the recommendation of a particular item performed periodically 2 aims at personalizing the association rules for the user The association rules are filtered according to the user by applying the following rules in the following order a of items contained in the users history \(this is a strong rule which can be relaxed  see Sect. V b the head because there is no sense in recommending an item he has already consulted c because there is no sense in recommending to the user an item he will not appreciate d as a consequence of \(b c Example: Let us consider movie recommendation Given a user u who rated and liked the movies F1, F3 and 


F5 denoted F l1, F l3 and F l5. The following rules are obtained r1 : {F l1, F l3} ? {F l5 r2 : {F l1, F l2} ? {F l4 r3 : {F l3, F l5} ? {F d6 r4 : {F l1, F l5} ? {F l3, F l7 By the application of \(b d kept. The rule r2 is also not kept by the application of \(a r3 is not kept after passing \(c d r?4 : {F l1, F l5} ? {F l7} because of \(b rule r?4 This result is justified because r1 leads to the recommendation of an item already consulted by the user, which is useless. r2 doesnt fit the user because he hasnt consulted all of the items contained in the body so we cannot make any conclusions. The recommendation of r3 is not accurate because the item is predicted as disliked. Finally, we can extract rule r4 which results in a possible recommendation the item F7 C. Semantic-Based Module This module is based on an ontology. An ontology is an explicit specification of a shared conceptualization [23]. It is used to formally describe domains by means of concepts and properties. Typically, concepts are classes and properties are relations characterizing the concepts. A property has a domain and a range. For example, the domain of the property hasActor\(Film,Actor Instances of concepts and properties are called individuals7 In the following, we denote C as the set of the concepts of the the ontology, and Rel as the set of properties \(relations We consider that an item is characterized by the concepts hes related to. Moreover, each concept has its proper influence on each user. This is why, the interest of a user 7The terms instance and individual are used without distinction 472 2010 10th International Conference on Intelligent Systems Design and Applications in an item is defined by his interest in the concepts related to the item. The user preference for a concept over another is learned by analyzing his profile. We do not explain this process in this paper Once the association rules concerning the user are identified, we use the ontology to compute the interests of each item in the head. This helps to refine the obtained results from the previous module. Indeed, before applying 


the semantic module, the recommendation is issued from collaborative filtering. While in some cases these recommendations can fit the user, it is possible that they dont suit his other interests. This semantic module performs the required adjustments and takes into account the user as a unique entity The prediction of the interest of these features of item f uses the following parameters for the user u the users valuations for the items which have at least one shared feature with f the number of occurrences of each feature of f among those rated by u This is done in two steps: the computation of the instance interest and then the computation of the concept interest 1 Definition: Given a user u, the interest of u for an instance i is a prediction based on the past valuations of u for the items connected to i by a certain relation R ? Rel An instance i is connected to 0 to n items in the users history. Thus, 0 to n valuations related to this instance are obtained. The interest of i is then estimated according to the valuations connected with it. This is done by computing the median of these valuations. Actually, median allows one to avoid extreme and unusual values which add some noise when computing a basic average of a set of values instanceInterest\(u, i median\({eval\(u, f f, i 1 where eval\(u, f f 2 Definition: Given a user u, the interest of u according to a concept c for an item f is based on the instance interests of the individuals of the concept c connected to f by a certain relation R ? Rel conceptInterestc\(u, f   i?{i? |?R?Rel R\(f,i i instanceInterest\(u, i ratioocc\(u, i   


i?{i? |?R?Rel R\(f,i i ratioocc\(u, i 1 2 where ratioocc\(u, i instance i among the instances of the same concept in the users history D. Frequency Module This module aims at detecting the frequent instances and the frequent associations of instances. Indeed, such a frequency depicts an important interest of the user for the concerned instances. Consequently, it is relevant to recommend items with these characteristics to the user 1 considers the profile of the user. It aims at detecting the most important features of interest for the user Regardless of the estimated interest of an instance for a user, we consider that if the user has in his history a significant percentage of items which have as a feature that particular instance, the interest of this instance is significant Unlike the previous computation, this computation ignores the users ratings for the items which have the instance as a feature Example: A user who has watched 80% of the films interpreted by the actor Tom Hanks should get the recommendation of the other 20% he has not seen even if some of the films of Tom Hanks in his history are badly rated 2 case with frequent instances described above, this part of the module deals not only with the profile of the user, but also with the set of items. It aims at discovering frequent associations between the features in the user history. It detects the features that often occur together in order to discover new recommendations. To achieve this, frequent sets of the instances related to the items in the users history are computed. Then, items with such instances are recommended to the user Example: A possible frequent association is the actor Johnny Depp and the director Tim Burton. A user who is interested in these two instances will be recommended the other films related to them E. Recommendation and explanation 


As explained in Sect. II, the collaborative and the semantic modules are in cascade. Consequently, the result is a set of recommendations rec1 which is mixed with the recommendations of the frequency module rec2 such that rec1 is presented before rec2 to the user. This order can be inverted according to user feedback. Concerning the explanation of the recommendations, this is done by highlighting the instances which have highly scored the interest of the user for the items of rec1, and by highlighting the frequent instances in the items of rec2 F. Example In this section, we illustrate the recommendation process for any user u, in the movie domain. We will simplify to preserve the clarity of the example 2010 10th International Conference on Intelligent Systems Design and Applications 473 Table I EXTRACT OF THE PROFILE OF THE USER u Film Rating Transformation Psycho 5 Psychol Rear Window 4 Rear Windowl Four Weddings and a Funeral 4 Four Weddings and a Funerall Monty Pythons Life of Brian 5 Monty Pythons Life of Brianl Carrie 3 Carried Stephen Kings The Langoliers 1 Stephen Kings The Langoliersd Pulp Fiction 4 Pulp Fictionl Dr. Strangelove 2 Dr. Strangeloved A Clockwork Orange 1 A Clockwork Oranged Let us consider u who has rated the movies in Tab. I Collaborative Filtering Module: Let us assume that the association rule mining result is r1 : {Psychol, Pulp Fictionl} ? {The Shiningl r2 : {Pulp Fictionl,Monty Pythons Life of Brianl Monty Python and the Holy Graill r3 : {Monty Python and the Holy Graill, Jurassic Parkl Indiana Jones and the Last Crusadel According to the rules introduced in Sect III-B2, we only keep the association rules r1 and r2 Semantic-Based Module: In this step, the interest of the user for each movie in the head of each rule from the last module is computed. The concerned movies are The Shining and Monty Python and the Holy Grail For The Shining, we obtain the following interest re 


sults conceptInterestActor \(u, TheShining conceptInterestDirector \(u, TheShining conceptInterestWriter \(u, TheShining conceptInterestGenre \(u, TheShining Unlike the prediction of the previous modules, it seems that The Shining is not a good recommendation for u Actually, this film shares its director with Dr. Strangelove and A Clockwork Orange which are negatively rated by u Moreover, it has a writer in common with Carrie and The Langoliers which are also movies disliked by u. The same reasoning is made about the concepts Actor and Genre Concerning Monty Python and the Holy Grail, the interests by concept are conceptInterestActor \(u, HolyGrail conceptInterestDirector \(u, HolyGrail conceptInterestWriter \(u, HolyGrail conceptInterestGenre \(u, HolyGrail This recommendation is a good one. The film shares its actors, writers and director with Monty Pythons Life of Brian which is highly rated by the user. The recommendation is thus justified Figure 3. Extract of the movie ontology Frequency Module: Let us assume that the user rated 60% of Alfred Hitchcocks films \(in Tab. I, Psycho and Rear Window are some of them recommended to u IV. EXPERIMENTAL EVALUATION A. Ontology Description For the experimentation, we built the ontology manually see Fig. 3 IMDB8. We focused only on a set of data which led to the concepts Film, Person, Actor, Director, Writer and Genre The connections between these concepts are Each movie is related to a certain number of persons who can be actors, directors or writers but it can also be related to other movies \(Example: Free Willy 2: The Adventure Home and Free Willy 3: The Rescue are related A person and a movie have a genre \(Action, Adventure Animation, Children, Comedy, Crime, etc B. Experimentation and Evaluation 


We use a subset of the dataset provided by MovieLens, the recommender system of GroupLens Research. The dataset contains a set of users, the set of items they have evaluated with a rating between 1 \(for the least liked for the most liked framework, we deal with a set of 86 movies, 934 users and 13 053 ratings. The dataset contains 3593 actors, 77 directors, 275 writers and 17 genres Using a 65% confidence and a 5% support, association rule mining resulted in 1472 rules after running the collaborative module. We evaluated the results obtained from the system by eighteen 20-50-year-old volunteers. The evaluation consisted exclusively in explicit valuations \(ratings 8http://www.imdb.com 474 2010 10th International Conference on Intelligent Systems Design and Applications Figure 4. Users evaluation of the system between 1 and 5 rated at the beginning between 11 and 31 films. For each recommended item, the user rates it as liked or disliked. If an item is rated as liked, the recommendation is considered as accurate. Otherwise, the system explains the reason why this item is recommended. The user can then agree with this explanation or not. Explanation of recommendation can be effective in convincing users in their appreciation of the items [24]. In our approach, the explanation aims at discovering if the detected patterns in the recommended item are accurate or not. Let us consider the following explanation in the recommendation of a film: This film may interest you because you frequently watched Tim Burtons films with Johnny Depp. If the user agrees with the explanation, that means that the association \(Tim Burton - Johnny Depp relevant but this particular film do not appeal to the user Otherwise, we consider that the detected association was purely a coincidence. In this case, the system will be able to ignore this pattern for this user in the future The results of this evaluation are depicted on Fig. 4. We can see that 84,9% of the recommendations satisfy the users Concerning the recommendations rated as disliked, 59,4% of the explanations are approved by users. Finally, 93,9% of the recommendations are satisfying or approved An average of 5 recommendations is obtained by running the collaborative and the semantic-based modules \(which is 


acceptable due to the low number of movies  86  in the dataset frequency module. This difference is due to the fact that the cascading modules \(collaborative and semantic-based are limited by the unique usage of the ratings to compute the association rules. The frequency module, on the other hand, is based on a statistical analysis of the item contents Consequently, it does not suffer from the sparsity of the user rating matrix like the previous modules The collaborative module results in some recommendations which are not liked by users. Fortunately, such recommendations are eliminated by the semantic-based module Other recommendations are eliminated by the semanticbased module though they appeal to users. We explain this because the concerned items dont share any features with the ones in the users history. This is why, we aim at introducing a semantic similarity measure to alleviate this problem \(see Sect. V module recommendations and 58,1% of the explanations of the disliked recommendations, satisfy the users. We can conclude that the combination of all the modules results in better recommendations V. CONCLUSION AND FUTURE WORK In our work, we propose a hybrid recommender system that combines collaborative filtering and semantic analysis of the items. The approach is based on many modules that refine the rules which progressively lead to a recommendation. A process targeting users with various interests is described. First, the collaborative filtering step is achieved using association rule mining which is a flexible way to classify the user. His history is then used to make the results more adapted to him. The semantic module aims at refining the recommendation issued from the rules. Finally, a frequency module is used to discover other items of interest for the user. Using distinct modules allows us to explain the recommendations to the user The results we have obtained from the evaluation experiments are promising. The combination of the collaborative and semantic modules improves the quality of the recommendations and the frequency module adds new ones. 93,9 of the recommendations are satisfying or approved In near future, we aim at defining the approach to learn 


the user profile in order to adapt the combination of the recommendation modules. We also plan to improve the semantic module by defining the semantic similarity between instances [25], [26]. Thus, when computing the interest by instance, those which are semantically similar to the current instance can be used when the instance is not present in the users history This similarity could also be used during the personalization of the association rules. The personalization rule \(a which consists in only keeping the rules which have a body composed of items contained in the users history, can be relaxed if the items violating \(a the items in the users history. The advantage of the semantic similarity is that it can be computed off-line which does not slow down the recommendation process Another improvement we want to introduce is the use of implicit data collected and based on the users behavior e.g. his search history, the time he spent looking at an item and his navigational patterns. This will help to increase the knowledge about the user and, in turn, lead to a better understanding of his expectations Finally, we plan to experiment the framework on other domains to confirm the domain-independence of the system REFERENCES 1] G. Adomavicius and A. Tuzhilin, Toward the next generation of recommender systems: A survey of the state-of-the-art and 2010 10th International Conference on Intelligent Systems Design and Applications 475 possible extensions, IEEE Trans. Knowl. Data Eng., vol. 17 no. 6, pp. 734749, 2005 2] R. Burke, Hybrid recommender systems: Survey and experiments, User Modeling and User-Adapted Interaction vol. 12, no. 4, pp. 331370, 2002 3] K. Lang, Newsweeder: Learning to filter netnews, in Proceedings of the 12th International Machine Learning Conference \(ML, 1995 4] M. J. Pazzani and D. Billsus, Content-based recommendation systems, in The Adaptive Web, P. Brusilovsky, A. Kobsa, and W. Nejdl, Eds., 2007, vol. 4321, pp. 325341 5] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and J. Riedl Grouplens: An open architecture for collaborative filtering of netnews, in Proceedings of ACM 1994 Conference on Computer Supported Cooperative Work, Chapel Hill, North 


Carolina, 1994, pp. 175186 6] B. Sarwar, G. Karypis, J. Konstan, and J. Reidl, Itembased collaborative filtering recommendation algorithms, in Proceedings of the 10th international conference on World Wide Web \(WWW 295 7] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl, Analysis of recommendation algorithms for e-commerce, in Proceedings of the 2nd ACM conference on Electronic commerce \(EC Minneapolis, Minnesota, USA, 2000, pp. 158167 8] M. Balabanovic and Y. Shoham, Fab: content-based, collaborative recommendation, Commun. ACM, vol. 40, no. 3, pp 6672, 1997 9] D. Billsus and M. J. Pazzani, User modeling for adaptive news access, User Modeling and User-Adapted Interaction vol. 10, no. 2-3, pp. 147180, 2000 10] M. J. Pazzani, A framework for collaborative, content-based and demographic filtering, Artif. Intell. Rev., vol. 13, no. 5-6 pp. 393408, 1999 11] S. Castagnos, A. Brun, and A. Boyer, Probabilistic association rules for item-based recommender systems, in Proceedings of the Fourth Starting AI Researchers Symposium STAIRS 12] W. Lin, Association rule mining for collaborative recommender systems, Masters thesis, Faculty of the Worcester Polytechnic Institute, 2000 13] J. J. Sandvig, B. Mobasher, and R. Burke, Robustness of collaborative recommendation based on association rule mining, in Proceedings of the 2007 ACM conference on Recommender systems \(RecSys 14] B. Mobasher, H. Dai, T. Luo, and M. Nakagawa, Effective personalization based on association rule discovery from web usage data, in Proceedings of the 3rd international workshop on Web information and data management \(WIDM Georgia, USA, 2001, pp. 915 15] R. Agrawal, T. Imielinski, and A. Swami, Mining association rules between sets of items in large databases, in Proceedings of the 1993 ACM SIGMOD international conference on Management of data, New York, NY, USA, 1993, pp. 207 216 16] B. Liu, W. Hsu, and Y. Ma, Integrating classification and association rule mining, in Knowledge Discovery and Data 


Mining, New York City, New York, USA, Aug. 1998, pp 8086 17] Y. Blanco-Fernandez, J. J. P. Arias, A. Gil-Solla, M. R Cabrer, M. L. Nores, J. G. Duque, A. F. Vilas, R. P. D Redondo, and J. B. Munoz, A flexible semantic inference methodology to reason about user preferences in knowledgebased recommender systems, Knowl.-Based Syst., vol. 21 no. 4, pp. 305320, 2008 18] S. E. Middleton, H. Alani, N. R. Shadbolt, and D. C. D Roure, Exploiting synergy between ontologies and recommender systems, in Semantic Web Workshop 2002 At the Eleventh International World Wide Web Conference, 2002 19] M. Zanker and M. Jessenitschnig, Case-studies on exploiting explicit customer requirements in recommender systems User Modeling and User-Adapted Interaction, vol. 19, no 1-2, pp. 133166, 2009 20] N. Ducheneaut, K. Partridge, Q. Huang, B. Price, M. Roberts E. H. Chi, V. Bellotti, and B. Begole, Collaborative filtering is not enough? experiments with a mixed-model recommender for leisure activities, in Proceedings of the 17th International Conference on User Modeling, Adaptation, and Personalization \(UMAP 21] H. Nguyen and P. Haddawy, The decision-theoretic interactive video advisor, in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence \(UAI 494501 22] B. Mobasher, Data mining for web personalization, in The Adaptive Web, ser. Lecture Notes in Computer Science P. Brusilovsky, A. Kobsa, and W. Nejdl, Eds. Springer Berlin Heidelberg, 2007, vol. 4321, ch. 3, pp. 90135 23] T. R. Gruber, A translation approach to portable ontology specifications, Knowl. Acquis., vol. 5, no. 2, pp. 199220 1993 24] N. Tintarev and J. Masthoff, The effectiveness of personalized movie explanations: An experiment using commercial meta-data, in Proceedings of the 5th international conference on Adaptive Hypermedia and Adaptive Web-Based Systems AH 25] R. Albertoni and M. D. Martino, Asymmetric and contextdependent semantic similarity among ontology instances Journal on Data Semantics, vol. 10, pp. 130, 2008 26] X. Jin and B. Mobasher, Using semantic similarity to 


enhance item-based collaborative filtering, in 2nd IASTED International Conference on Information and Knowledge Sharing, Scottsdale, Arizona, 2003 476 2010 10th International Conference on Intelligent Systems Design and Applications 


Basi Association Rles Basi c  Association R u les Association is basically connecting or tying up occurrences of Association is basically connecting or tying up occurrences of events Ol dib t f ilt t O n l y d escr ib e se t s o f s i mu lt aneous even t s Cannot describe patterns that iterate over time e g  itemset a  0  b  0  g    Eg If you sense higher data rates on the downlink than normal AND New Route generated Implies high chances of Intrusion AND New Route generated Implies high chances of Intrusion Associative IDS for NextGen Frameworks Dr S Dua LA Tech 20 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



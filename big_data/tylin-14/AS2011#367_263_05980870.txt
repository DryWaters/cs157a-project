978-1-61284-848-8/11/$26.00 ©2011 IEEE Extracting Spatial Association Rules from the Maximum Frequent Itemsets Based on Boolean Matrix Junming Chen 1,2 Guangfa Lin 1,2 Zhihai Yang 1,2 1 College of Geographical Sciences, Fujian Normal University 2 Fujian Provincial Engineering Research Center for Monitoring and Assessing Terrestrial Disasters Fuzhou, P. R. China Corresponding author, e-mail GuangfaLin@263.net  Abstract  Mining spatial association rules is one of the most important branches in the field of Spatial Data Mining \(SDM Because of the complexity of spatial data, a traditional method in extracting spatial association rules is to transform spatial database into general transaction database. The Apriori algorithm is one of the most commonly used methods in mining association rules at present. But a shortcoming of the algorithm is that its performance on the large database is inefficient. The present paper proposed a new algorithm by extracting maximum frequent itemsets based on a Boolean matrix. And a case study about extracting the spatial association rules between land cover and terrain factors was demonstrated to show the validation of the new algorithm. Finally, the conclusion was reached by the comparison between the Apriori algorithm and the new one which revealed that the new algorithm improves the efficiency of extracting spatial association rules Keywords-Boolean matrix Maximum frequent itemset Spatial association rule Apriori algorithm I I NTRODUCTION Spatial Data Mining \(SDM\s a process of spatial support decision, which aims at extr acting the im plicit, unknown potential, useful spatial and non-spatial knowledge from spatial data, including general geometry rules, spatial characteristics rules, spatial classification rules, spatial clustering rules, spatial association rules and so on [1  S p a tial ass o ciat ion ru l e  t e rm ed as spatial association location pattern [2  is on e of th e m o st  important branches in the SDM, which means a rule indicating certain association relationships among a set of spatial and nonspatial attributes of geographical objects. Because of the complexity of spatial data, the main idea of extracting spatial association rules is to mine spatial association rules in the transaction database categorized from spatial data using some mining algorithms  The Apriori algorithm [3  on e of  t h e most commonly used algorithms in mining association rules at present, and its typical application was market basket analysis to discover customer shopping patterns [4  Su bs eq u e nt ly th e  algorithm was extended towards SDM to discover multi-level spatial association rules based on progressive refinement [5 A   Salleb and C. Vrain extracted spatial and non-spatial association rules over multiple layers further [6 h ich w as th e  extension of the previous work [5 en Gang e t al  a l so  utilized the Apriori algorithm to extract the spatial association rules between terrain factors and mountain climate change and obtained some significant patterns [7  B u t a sh o r t c o m in g  abou t  the algorithm is that the performance is inefficient on the large database, especially, the deficiency is more obvious for an amount of spatial data. As a result, lots of scholars put forward some new algorithms: some resear ch focused on application of meta-rules in mining association rules. For example, Yongjian Fu et al. applied meta-rules as guidance at finding multiplelevel association rules in large relational database and Chunhong Yuan et al. put forward mining multiple-level spatial association rules meta-rule-guided based on progressive refinement [8 A lth ou g h th e m etar u les c a n re du ce  th e  computation of the number of unnecessary itemsets, the metarules were re-designed and users accepted them passively Therefore, two models were proposed to learn the prior knowledge from users  interactive feedback [10  J i a w ei Han et  al. came up with the FP-growth algorithm based on the FPTree structure [11  w h ich n o t on ly av oi d e d g e ne rat i n g l o ts  of  candidates, but also decreased times of scanning database, but the algorithm is more adapt to extracting long patterns Ronghua Ma et al. discussed a new approach, from top to bottom and deepening step by step, according to the concept hierarchy of spatial objects and the spatial predicates organized by spatial join index for predicates [12  L i z hen W a ng et  al presented a new approach to discover strong multi-level spatial association rules in spatial database based on partitioning the set of rows with respect to the spatial relations denoted as relation table R and proved th is new algorithm is efficient finally [13  A n t h o n y  J T. L e e et  al  als o pr o p o se d  a  n e w  algorithm, 9 DLT-Miner, which is applied in extracting spatial association rules from image database, and the result showed 9 DLT-Miner runs 2-5 times faster than the Apriori algorithm 14  Yue q in Z h ang ext r a cte d f r e q u e nt item sets bas e d on 0 1 matrix [15  bu t th is m ethod s till g e ne rat e d l o ts  of  can d i d a t es In this paper, a new algorithm was proposed that focus on extracting maximum frequent itemsets first based on the Boolean matrix of frequent length-1 itemsets that are generated using the Apriori algorithm, and then generating all the frequent itemsets from maximum frequent itemsets according to the nonempty sub-sets of frequent itemsets being still frequent. Finally, the comparison between the Apriori Supported by the Key Project of Chinese Mi nistry of Education \(No 210107  the Key Project of Department of Education of Fujian Province JA09056 and the Natural Science Foundation of Fujian Province, China 2010J01247 


algorithm and the proposed one by mining the spatial association rules between terrain factors and land cover was showed to validate the new algorithm s efficiency II T HE C OMPARISON OF THE P RINCIPLES OF THE A LGORITHMS The Apriori algorithm is one of the most influential algorithms used for mining association rules, which was proposed by R. Aglawal et al. in 1994. According to the principles of the Apriori algorithm in [3 it is c o m pose d of  t w o  steps, one is extracting all the frequent itemsets; the other is generating all the strong association rules from frequent itemsets [6 In f a ct  th e ess enc e is to it er ativ ely g e nera te th e set  of candidate itemsets of length k 1\ from frequent itemsets of lengthk and check their corresponding occurrence frequencies in the database to obtain frequent itemsets of length k 1\ at each level. Therefore it can be seen that there are two main reasons to low efficiency of the Apriori algorithm  It is required to generate lots of candidate itemsets for generating each frequent itemsets  It is essential to scan database many times for generating each frequent itemsets Thus the research presented a new algorithm of mining maximum frequent itemsets first based on the Boolean matrix of frequent length-1 itemsets The main idea of the algorithm is to create a Boolean matrix with frequent length-1 itemsets as row headings and transaction recordsê IDs as column headings TABLE I In the matrix, there are only two type of values 1  and 0  which means that the transaction record contains or not the corresponding frequent lengt h-1 itemset. Then it is necessary to calculate the number of value 1 in each column and the count of the columns with the same number of value 1 If the count of those columns is larger than the minimum support, in accordance, the number of value 1 in the column may be the size of maximum frequent itemset, vice versa Therefore, some values of which each may be the maximum frequent itemset  s length will be calculated Subsequently, a set of candidate itemsets used for extracting maximum frequent itemsets will be generated from frequent length-1 itemsets according to each maximum value and the support of each candidate itemset will be calculated based on the Boolean matrix If the support is larger than the minimum support, the candidate itemset is frequent, vice versa Finally, all the frequent itemsets will be extracted from maximum frequent itemsets according to the nonempty sub-sets of frequent itemsets being still frequent  Generally speaking, the main principles of the new algorithm include three aspects TABLE I A P ART OF THE B OOLEAN M ATRIX OF THE F REQUENT L ENGTH 1 I TEMSETS Frequent 1 itemsets The Transaction Records  ID 1 2 3 4 5 6 7 8 9 10 Mountain 1 1 1 0 1 1 0 0 1 1 Forest 0 1 0 1 1 1 1 1 1 1 Slope 1 1 0 0 0 1 0 1 1 1 Northwest 1 1 0 1 0 1 1 1 1 1 A Creating a Boolean Matrix According to Frequent Length-1 Itemsets All the frequent length-1 itemsets will be generated from transaction database using the Apriori algorithm when transaction database is scanned first time and for each frequent length-1 itemset, all the IDs of transaction records containing it need to be taken note in one array. Then the corresponding Boolean array with the length being the number of the transaction records in database will be created for each frequent length1 itemset. In each array, there are only two values, è0 and è1ê. If transaction record contains frequent length 1 itemset the value is 1 in the corresponding Boolean array, vice versa At last, a Boolean matrix will be constructed according to all the Boolean arrays of frequent length-1 itemsets 1 Definition 1 The corresponding Boolean array of each frequent length-1 itemset I m  N   B T 1  B T 2   B Tn 1 n N here I m is the m th frequent length-1 itemset N is the number of transaction records in database T n is ID of the n th transaction record respectively; and B Tn  s value is 0 or 1 only 2 Definition 2 The Boolean matrix of frequent length1 itemsets I M*N is I 1  N  I 2  N     I m  N   1 m M where I m  N  is th e Bo ol ean a r ray w ith  N dimensions of the m th frequent length-1 itemset M is the number of frequent length-1 itemsets 3 The pesudo codes of the first part \(Fig 1  Figure 1 The pesudo codes of the first part B Extracting Maximum Frequent Itemsets from Boolean Matrix Each column in the Boolean matrix represents one transaction record. Value 0 in the column means the corresponding transaction record contains the corresponding frequent length-1 itemset, vice versa. Therefore, the number of value 1 in each column indicates the corresponding transaction record contains the number of frequent length-1 itemsets together. If there is the number of transaction records with the same number of value 1 being larger than the minimum support the number of value 1 may be the size of maximum frequent 


itemset, vice versa. As a result, a set of values in which each one may be maximum frequent itemset  s length will be obtained. Then according to each of the values in descending order, a series of candidate itemsets will be generated from frequent length-1 itemsets and the support of each candidate itemset could be calculated according to the Boolean matrix of frequent length-1 itemsets. If the support of each candidate itemset is larger than the minimum support, the candidate itemset is frequent, vice versa. At last, if the maximum frequent itemsets generated from the set of candidate itemsets are not empty, the size of candidate itemset is required, that is length of maximum frequent itemset. Otherwise, it is necessary to continue the previous operation to check the next value until maximum frequent itemsets are not empty If all the maximum frequent itemsets are empty, the maximum length of frequent itemset is one 1 Definition 3 Max  n  s a n  a r r a y used for sto r i n g  some values of which each may be the length of maximum frequent itemset, where n is the size of Max  n  2 Definition 4  The set of candidate itemsets of maximum frequent itemsets C is I M 1  I M 2  I Mn therefore the corresponding Boolean matrix C Mn*N is I M 1  N  I M 2  N    I Mn  N  w h ere I Mn is candidate itemset 3 Definition 5  The support of candidate itemset C  Support C  I M1  N  And I M2  N  And  I Mn  N   F i g 3 sho w s t h e example of the logical Boolean operator çAndé between the Boolean arrays of candidate itemsets, where  And  is the logical Boolean operator, if there exists value 0,  then the calculation will be 0 4 The pesudo codes of the second part \(Fig 2   Figure 2 The pesudo codes of the second part Figure 3 The logical Boolean operator of the Boolean arrays of the set of candidate itemsets C Generating All the Frequent Itemsets from Maximum Frequent Itemsets All the frequent itemsets could be extracted from all the maximum frequent itemsets according to the nonempty subsets of frequent itemsets being still frequent. And the support of each frequent itemset could be calculated by Definition 5. At last, all the strong association rules can be mined from all the frequent itemsets III T HE I MPLEMENTS AND C OMPARISON OF THE A LGORITHMS In this part, a case study about extracting the spatial association rules between land cover and terrain factors was presented to validate the proposed algorithmês efficiency The slope and the aspect derived from DEM with the grid cell size of 100m and the land cover map extracted from the SPOT-5 remote sensing image were taken as experimental datasets; the Apriori algorithm and the new one were used to mine the spatial association rules from the above datasets and the efficiency between the two algorithms was be compared and analyzed at last A Spatial Data Preprocessing Spatial datasets need to be preprocessed to construct the transaction database before mining spatial association rules according to the main idea of mining spatial association rules at present. Imam Mukhlash and Benhard Sitohang put forward the framework of spatial data preprocessing, including feature spatial and non-spatial\ selection based on spatial parameters performing dimension reduction and selection of non-spatial attributes, performing data categorization based on non-spatial data parameters, performing join operations for spatial objects based on spatial parameters and transforming into output form 16   Th e r ef or e  all th e sp ati al d a t asets in th e c ase n e ed b e  preprocessed as the following three aspects 1 The preparation and preprocessing of spatial datasets The spatial datasets in the case included the elevation the slope and the aspect with the spatial resolution of 100m and the land cover map. The slope and the aspect were derived from the elevation and the land cover map was derived from the SPOT-5 remote sensing image. Fig. 4 shows the flow chart 


of the spatial data preprocessing. At last, all the spatial datasets are masked by the study region boundary layer to be sure the same spatial extent for each spatial dataset Figure 4 The flow chart of the spatial data preprocessing 2 The categorization of the attribute values for each spatial dataset According to the spatial data preprocessing framework, the attribute values of each spatial dataset must be generalized. Therefore, the elevation would be categorized into 5 types, including extremely High Mountain \(>5000m\, High Mountain \(3500~5000m\, Middle Mountain \(1000~3000m Low Mountain \(500~1000m\ and Plain and Hill \(<500m according to [1 n d  t h e sl o p e co ul d be ge ner a li z e d i n t o  4 types based on the slope steepness classification of International Geographical Union Geomorphological Survey and Mapping Council, including plain \(<2∞\, slope \(2∞~6 abrupt slope \(6∞~25∞\ and steep slope \(>25∞\ig. 5 shows the compass direction of the aspect. The land cover types included river, estuarine, reservoir, built-up land, farmland, gardens forest land mangrove, grass land and so on Figure 5 The compass direction of the aspect 3 The construction of the transaction database After completing the spatial data preprocessing, to construct the transaction database, each grid cell was treated as one transaction record with 5 parts including TID \(the grid cellês ID\the slope category, the aspect category, the elevation category and the land cover type. Then it  s required to read and classify quickly the attribute values of each grid cell from all the raster datasets to construct the attribute transaction table according to the categories of all the spatial datasets. At last the Apriori algorithm and the new one were applied to extracting the frequent itemsets from the constructed transaction database The program of all the above tasks was implemented by using of c# programming language Fig. 6 Figure 6 The procedure of the extracting the spatial association rules B Comparison of the Algorithms Efficiencies After the transaction database with the number of transaction records being 157155 was constructed, the procedure as shown in Fig. 6 was performed on the computer with Pentium \(R\l-Core2 60GHz CPU and 2GB memory to extract all the frequent itemsets with the minimum supports as 100, 200, 400, 800, 1600, 3200, 6400, 12800, 25600 and the spatial association rules with the minimum support and confidence being 2% and 30% re spectively. At last the output of the procedure was shown in Fig. 7. It can be seen obviously that the runtime of the new algorithm is less than the Aprioriês for each minimum support. As the minimum support grew smaller, the runtime of the two algorithms both increased continuously but the growth rate of the new algorithm  s runtime was much less than the Apriori  s. And the new algorithm not only reduced times of scanning transaction database, but also decreased the number of the set of candidate itemsets according to the comparison of the principles between two algorithms. Therefore, the proposed algorithm in this paper is superior to the Apriori 


Figure 7 The comparison of between the proposed algorithm and the Apriori IV C ONCLUSIONS The paper represented a new algorithm used for mining spatial association rules  extracting maximum frequent itemsets first based on a Boolean matrix. The algorithm not only reduced the times of scanning transaction database, but also decreased the number of the set of candidate itemsets However, some problems about the algorithm should still be taken into consideration further: First, in the Boolean matrix of frequent length-1 itemsets, there may be lots of successive values 0 so as to waste memory resource to some extent Although compressing the matrix can solve the problem, in contrast, uncompressing the matrix may lower the efficiency of the algorithm; Second, the algorithm is lack of evaluating the quality of frequent itemsets, especially, interpreting and understanding the significance of frequent itemsets, Jiawei Han et al. proposed it is necessary to solve that how to mine the compressed and high quality frequent itemsets and understand and interpret them [18  Th ir d th e  aut o c or re lat ion be tw e e n  spatial objects is not be considered in the new algorithm Jiangping Chen et al. discussed the influence the spatial autocorrelation has on extracting spatial association rules by comparing the extracted results between the spatial autocorrelation and the improved Apriori algorithm, and the result showed the effect is existed [19  Fin al ly th e a b ov e th r e e  aspects will be emphasized in the future work R EFERENCES 1 D   L i  S  W a n g  an d D  L i  S p a t ia l Da t a  Mi ni n g Th eor i es a nd Applications, Beijing: Publisher of Science, 2006, pp. 32-36 2 R Ma Y   P u, an d X  Ma, M i n i ng  S p ati a l  A sso ciatio n  P a t t e r ns f r o m GI S  Database, Beijing: Publisher of Science, 2007, pp. 68-69 3 R  A g r a w al T   I m e l inski  a n d A  S w ami  Mining Association Rules Between Sets of Items in Large Database  Proc. ACM-SIGM OD International Conference, pp. 208-216, 1993 4 J H a n a n d M. K a m b e r D a ta M i n i ng  Co nce p ts  an d T e ch ni que s   Be ij ing   China Machine Press, 2007, pp. 149-152 5 K K o pe r s ki a n d J  H a n    Discovery of spatial association rules in geographic information databases  Lecture Notes In Computer Science vol. 951, 1995, pp. 47-66 6 A  S a ll eb an d C  Vr a i n    An application of association rules discovery to geographic information systems  Proc. The 4th European Conference on Principles of Data Mining and Knowledge Discovery PKDD, pp 613-618 2000 7 G Che n Z  H e and  B. Y a ng   Spatial Association Rules Data Mining Research on Terrain Feature and Mountain Climate Change  Geography and Geo-Information Science, vol. 26\(1\, 2010, pp. 37-40 8 Y F u a n d J  H a n   Meta-Rule-Guided Mining of Association Rules in Relational Databases  Proc. In têl Workshop on Internation of Knowledge Discovery with Deductive and Objective and ObjectOriented Databases pp. 39-46 1995 9 C Y u an an d F  X i o n g    Meta-rule-guided Mining Multiple-level Spatial Association Rules Based on Progressive Refinement  Computer Engineering, vol. 30\(8\4, pp. 34-36 10 D  X i n, X  S h e n Q  Me i an d J  H a n  Discovering Interesting Patterns Through Userês Interactive Feedback Proc. ACM SIGKDD Int. Conf on Knowledge Discovery and Data Mining \(KDDê06 Philadelphia Pennsylvania, USA, August 20-23, 2006 11 J  H a n  J. P e i, Y  Y i n  a nd R Mao  Mining Frequent Patterns without Candidate Generation: A Frequent-Pattern Tree Approach  Data Mining and Knowledge Discovery, 2004, pp. 53-87 12 R. Ma X  M a  a n d Y   P u   Spatial Association Rule Mining from GIS Database  Journal of Remote Sensing, vol. 9\(6\, 2005, pp. 733-741  L   W a n g  K  Xi e T  C h en  a nd X  M a    Efficient discovery of multilevel spatial association rules using partitions  Information and Software Technology, vol. 47, 2005 pp. 829-840 14 A  J. T  L e e  R  H o n g  W  K o W  T sao, an d H  L i n    Mining spatial association rules in image databases  Information Sciences, vol. 177 2007, pp. 1593-1608  Y Z h a n g   Research of Frequent Itemsets Mining Algorithm Based on 0-1 Matrix  Computer Engineering and Design, vol. 30\(20\, 2009, pp 4662-4664  I  M ukh la s h and B  S i t ohan g   Spatial Data Preprocessing for Mining Spatial Association Rule with Conventional Association Mining Algorithms,é Proc The International Conference on Electrical Engineering and Informatics, Institute Teknologi Bandung, Indonesia pp. 531-534, June 17-19 2007 17 P h y s ical Re g i o n al iz at io n W o r k i n g C o mm ittee o f Ch ine s e A cade m y o f  Science, Geomorphological Regionalization of China, Beijing: Publisher of Science, 1959  J Ha n  H  Ch en g D Xi n an d X Yan   Frequent pattern mining: current status and future directions  Data Mining and Knowledge Discovery vol. 15, 2007, pp. 55-86  J  Ch en and B Hua n g    Application and Effects of Data Spatial Autocorrelation on Association Rule Mining  Journal of GeoInformation Science, vol. 13\(1\, 2011, pp. 109-117 


mendation process used for a user with various interests A user with various interests needs varying but adapted recommendations. Actually, such a user can be classified in many groups at the same time according to his interests. The usage of collaborative filtering is then justified for serendipity. After that, the personalization of the results should be performed using the semantics of the items and the frequency of their characteristics. Thus, a hybrid recommender system that is both collaborative and semantic-based is needed. Such a recommendation process is depicted in Fig. 2. It consists of the combination of different recommendation modules that lead to the explained recommendation of a set of items. The first step consists in performing collaborative filtering using user behaviors to generate a first set of rules. This is done by means of association rule mining and is detailed in Sect. III-B. In the semantic part described in Sect. III-C, the semantics of the items is used thanks to an ontology described in OWL4. The users interest for each concept is computed which helps to refine the users degree of interest for the candidate items and classify them according to the users 4http://www.w3.org/2004/OWL Figure 2. The recommendation process for a user with various interests history \(features which appear frequently in the user history are more weighted and this is used for sorting the items Finally, in Sect. III-D, we explain the use of a frequency module which finds relations between item features. What comes out at the end are items of interest for the user The sequencing of these successive modules and the storage of their results can explain the obtained recommendations Indeed, after passing each module, the sequence which led to the current result is saved. This provides a means for real semantics for the resulting recommendations A. Items and User Model According to the established user model, the users data are collected into user profiles5. The user profiles are updated automatically and explicitly \(the user gives the data himself by rating items and/or entering information in forms implicitly \(clickstream data and research are used to discover other interests of the user the user is considered as an entity, not as a member of a user group and on a long-term-basis \(the user profile is persistent 


history is contained in the system: a set of items with their valuations and this helps to identify their interests. In the following, we use valuation to refer to an implicit or explicit rating. The usage of implicit and explicit data is not the same in the different modules B. Collaborative Filtering Module 1 performed by computing association rules. Association rule mining is commonly used to perform market based analysis 15]. It is used to discover patterns linking items purchased 5A user profile is an instantiation of the user model 2010 10th International Conference on Intelligent Systems Design and Applications 471 together by customers. For example, a possible association rule may detect that most customers who buy cheese also buy red wine. Formally, an association rule is an expression X ? B where X ? I and B ? \(I \\ X respectively called body and head In the context of recommender systems, using association rule mining aims at discovering items that might interest the user based on the previous items he has rated and which have also been rated similarly by a group of users. Typically they discover sequential patterns between session profiles The problem is that a session profile is relevant in certain domains only \(webmarket for example a movie rental platform, a session profile has no meaning This is why, we expend the session profile to a short-term profile, which allows domain-independence There is a great deal of research dealing with association rule mining in recommender systems [22]. Association rule mining allows one to compute the rules off-line, which is significant as it reduces the recommendation process time Furthermore, model-based algorithms such as association rule mining, are more robust when dealing with profile injection attacks6 than memory-based algorithms \(k nearest neighbors whole set of users to generate recommendations while memory-based ones only use the most similar users who can have in this case attacker profiles [13]. Finally, association rule mining deals well with the scalability problem. Actually it is fast to implement and execute and it manages well large sets of data. This is why it represents the core of our collaborative module 


To be preserved, an association rule must satisfy two measures The support of an itemset A, denoted s\(A the frequency of the itemset A among the set of transactions T \(users history items in the context s\(A The con?dence of a rule X ? B, denoted c\(X ? B is defined by: c\(X ? B X?B s\(X Association rules are mined using the Apriori algorithm 15]. The liked and disliked items are first distinguished in the user history using their item ratings. This is done in order to gain a global view of the liked and disliked items For ratings between 1 and 5, values strictly lower than 4 are considered to represent disliked items. On the other hand values equal to or higher than 4 represent items that fit the users taste. Thus, items can be labeled with two values l like dislike users who have rated some of these items, we can obtain the extraction of the rules This module doesnt depend on a particular user. The computation is conducted generally for all users and is 6The insertion of multiple profiles under false identities in order to promote or denote the recommendation of a particular item performed periodically 2 aims at personalizing the association rules for the user The association rules are filtered according to the user by applying the following rules in the following order a of items contained in the users history \(this is a strong rule which can be relaxed  see Sect. V b the head because there is no sense in recommending an item he has already consulted c because there is no sense in recommending to the user an item he will not appreciate d as a consequence of \(b c Example: Let us consider movie recommendation Given a user u who rated and liked the movies F1, F3 and 


F5 denoted F l1, F l3 and F l5. The following rules are obtained r1 : {F l1, F l3} ? {F l5 r2 : {F l1, F l2} ? {F l4 r3 : {F l3, F l5} ? {F d6 r4 : {F l1, F l5} ? {F l3, F l7 By the application of \(b d kept. The rule r2 is also not kept by the application of \(a r3 is not kept after passing \(c d r?4 : {F l1, F l5} ? {F l7} because of \(b rule r?4 This result is justified because r1 leads to the recommendation of an item already consulted by the user, which is useless. r2 doesnt fit the user because he hasnt consulted all of the items contained in the body so we cannot make any conclusions. The recommendation of r3 is not accurate because the item is predicted as disliked. Finally, we can extract rule r4 which results in a possible recommendation the item F7 C. Semantic-Based Module This module is based on an ontology. An ontology is an explicit specification of a shared conceptualization [23]. It is used to formally describe domains by means of concepts and properties. Typically, concepts are classes and properties are relations characterizing the concepts. A property has a domain and a range. For example, the domain of the property hasActor\(Film,Actor Instances of concepts and properties are called individuals7 In the following, we denote C as the set of the concepts of the the ontology, and Rel as the set of properties \(relations We consider that an item is characterized by the concepts hes related to. Moreover, each concept has its proper influence on each user. This is why, the interest of a user 7The terms instance and individual are used without distinction 472 2010 10th International Conference on Intelligent Systems Design and Applications in an item is defined by his interest in the concepts related to the item. The user preference for a concept over another is learned by analyzing his profile. We do not explain this process in this paper Once the association rules concerning the user are identified, we use the ontology to compute the interests of each item in the head. This helps to refine the obtained results from the previous module. Indeed, before applying 


the semantic module, the recommendation is issued from collaborative filtering. While in some cases these recommendations can fit the user, it is possible that they dont suit his other interests. This semantic module performs the required adjustments and takes into account the user as a unique entity The prediction of the interest of these features of item f uses the following parameters for the user u the users valuations for the items which have at least one shared feature with f the number of occurrences of each feature of f among those rated by u This is done in two steps: the computation of the instance interest and then the computation of the concept interest 1 Definition: Given a user u, the interest of u for an instance i is a prediction based on the past valuations of u for the items connected to i by a certain relation R ? Rel An instance i is connected to 0 to n items in the users history. Thus, 0 to n valuations related to this instance are obtained. The interest of i is then estimated according to the valuations connected with it. This is done by computing the median of these valuations. Actually, median allows one to avoid extreme and unusual values which add some noise when computing a basic average of a set of values instanceInterest\(u, i median\({eval\(u, f f, i 1 where eval\(u, f f 2 Definition: Given a user u, the interest of u according to a concept c for an item f is based on the instance interests of the individuals of the concept c connected to f by a certain relation R ? Rel conceptInterestc\(u, f   i?{i? |?R?Rel R\(f,i i instanceInterest\(u, i ratioocc\(u, i   


i?{i? |?R?Rel R\(f,i i ratioocc\(u, i 1 2 where ratioocc\(u, i instance i among the instances of the same concept in the users history D. Frequency Module This module aims at detecting the frequent instances and the frequent associations of instances. Indeed, such a frequency depicts an important interest of the user for the concerned instances. Consequently, it is relevant to recommend items with these characteristics to the user 1 considers the profile of the user. It aims at detecting the most important features of interest for the user Regardless of the estimated interest of an instance for a user, we consider that if the user has in his history a significant percentage of items which have as a feature that particular instance, the interest of this instance is significant Unlike the previous computation, this computation ignores the users ratings for the items which have the instance as a feature Example: A user who has watched 80% of the films interpreted by the actor Tom Hanks should get the recommendation of the other 20% he has not seen even if some of the films of Tom Hanks in his history are badly rated 2 case with frequent instances described above, this part of the module deals not only with the profile of the user, but also with the set of items. It aims at discovering frequent associations between the features in the user history. It detects the features that often occur together in order to discover new recommendations. To achieve this, frequent sets of the instances related to the items in the users history are computed. Then, items with such instances are recommended to the user Example: A possible frequent association is the actor Johnny Depp and the director Tim Burton. A user who is interested in these two instances will be recommended the other films related to them E. Recommendation and explanation 


As explained in Sect. II, the collaborative and the semantic modules are in cascade. Consequently, the result is a set of recommendations rec1 which is mixed with the recommendations of the frequency module rec2 such that rec1 is presented before rec2 to the user. This order can be inverted according to user feedback. Concerning the explanation of the recommendations, this is done by highlighting the instances which have highly scored the interest of the user for the items of rec1, and by highlighting the frequent instances in the items of rec2 F. Example In this section, we illustrate the recommendation process for any user u, in the movie domain. We will simplify to preserve the clarity of the example 2010 10th International Conference on Intelligent Systems Design and Applications 473 Table I EXTRACT OF THE PROFILE OF THE USER u Film Rating Transformation Psycho 5 Psychol Rear Window 4 Rear Windowl Four Weddings and a Funeral 4 Four Weddings and a Funerall Monty Pythons Life of Brian 5 Monty Pythons Life of Brianl Carrie 3 Carried Stephen Kings The Langoliers 1 Stephen Kings The Langoliersd Pulp Fiction 4 Pulp Fictionl Dr. Strangelove 2 Dr. Strangeloved A Clockwork Orange 1 A Clockwork Oranged Let us consider u who has rated the movies in Tab. I Collaborative Filtering Module: Let us assume that the association rule mining result is r1 : {Psychol, Pulp Fictionl} ? {The Shiningl r2 : {Pulp Fictionl,Monty Pythons Life of Brianl Monty Python and the Holy Graill r3 : {Monty Python and the Holy Graill, Jurassic Parkl Indiana Jones and the Last Crusadel According to the rules introduced in Sect III-B2, we only keep the association rules r1 and r2 Semantic-Based Module: In this step, the interest of the user for each movie in the head of each rule from the last module is computed. The concerned movies are The Shining and Monty Python and the Holy Grail For The Shining, we obtain the following interest re 


sults conceptInterestActor \(u, TheShining conceptInterestDirector \(u, TheShining conceptInterestWriter \(u, TheShining conceptInterestGenre \(u, TheShining Unlike the prediction of the previous modules, it seems that The Shining is not a good recommendation for u Actually, this film shares its director with Dr. Strangelove and A Clockwork Orange which are negatively rated by u Moreover, it has a writer in common with Carrie and The Langoliers which are also movies disliked by u. The same reasoning is made about the concepts Actor and Genre Concerning Monty Python and the Holy Grail, the interests by concept are conceptInterestActor \(u, HolyGrail conceptInterestDirector \(u, HolyGrail conceptInterestWriter \(u, HolyGrail conceptInterestGenre \(u, HolyGrail This recommendation is a good one. The film shares its actors, writers and director with Monty Pythons Life of Brian which is highly rated by the user. The recommendation is thus justified Figure 3. Extract of the movie ontology Frequency Module: Let us assume that the user rated 60% of Alfred Hitchcocks films \(in Tab. I, Psycho and Rear Window are some of them recommended to u IV. EXPERIMENTAL EVALUATION A. Ontology Description For the experimentation, we built the ontology manually see Fig. 3 IMDB8. We focused only on a set of data which led to the concepts Film, Person, Actor, Director, Writer and Genre The connections between these concepts are Each movie is related to a certain number of persons who can be actors, directors or writers but it can also be related to other movies \(Example: Free Willy 2: The Adventure Home and Free Willy 3: The Rescue are related A person and a movie have a genre \(Action, Adventure Animation, Children, Comedy, Crime, etc B. Experimentation and Evaluation 


We use a subset of the dataset provided by MovieLens, the recommender system of GroupLens Research. The dataset contains a set of users, the set of items they have evaluated with a rating between 1 \(for the least liked for the most liked framework, we deal with a set of 86 movies, 934 users and 13 053 ratings. The dataset contains 3593 actors, 77 directors, 275 writers and 17 genres Using a 65% confidence and a 5% support, association rule mining resulted in 1472 rules after running the collaborative module. We evaluated the results obtained from the system by eighteen 20-50-year-old volunteers. The evaluation consisted exclusively in explicit valuations \(ratings 8http://www.imdb.com 474 2010 10th International Conference on Intelligent Systems Design and Applications Figure 4. Users evaluation of the system between 1 and 5 rated at the beginning between 11 and 31 films. For each recommended item, the user rates it as liked or disliked. If an item is rated as liked, the recommendation is considered as accurate. Otherwise, the system explains the reason why this item is recommended. The user can then agree with this explanation or not. Explanation of recommendation can be effective in convincing users in their appreciation of the items [24]. In our approach, the explanation aims at discovering if the detected patterns in the recommended item are accurate or not. Let us consider the following explanation in the recommendation of a film: This film may interest you because you frequently watched Tim Burtons films with Johnny Depp. If the user agrees with the explanation, that means that the association \(Tim Burton - Johnny Depp relevant but this particular film do not appeal to the user Otherwise, we consider that the detected association was purely a coincidence. In this case, the system will be able to ignore this pattern for this user in the future The results of this evaluation are depicted on Fig. 4. We can see that 84,9% of the recommendations satisfy the users Concerning the recommendations rated as disliked, 59,4% of the explanations are approved by users. Finally, 93,9% of the recommendations are satisfying or approved An average of 5 recommendations is obtained by running the collaborative and the semantic-based modules \(which is 


acceptable due to the low number of movies  86  in the dataset frequency module. This difference is due to the fact that the cascading modules \(collaborative and semantic-based are limited by the unique usage of the ratings to compute the association rules. The frequency module, on the other hand, is based on a statistical analysis of the item contents Consequently, it does not suffer from the sparsity of the user rating matrix like the previous modules The collaborative module results in some recommendations which are not liked by users. Fortunately, such recommendations are eliminated by the semantic-based module Other recommendations are eliminated by the semanticbased module though they appeal to users. We explain this because the concerned items dont share any features with the ones in the users history. This is why, we aim at introducing a semantic similarity measure to alleviate this problem \(see Sect. V module recommendations and 58,1% of the explanations of the disliked recommendations, satisfy the users. We can conclude that the combination of all the modules results in better recommendations V. CONCLUSION AND FUTURE WORK In our work, we propose a hybrid recommender system that combines collaborative filtering and semantic analysis of the items. The approach is based on many modules that refine the rules which progressively lead to a recommendation. A process targeting users with various interests is described. First, the collaborative filtering step is achieved using association rule mining which is a flexible way to classify the user. His history is then used to make the results more adapted to him. The semantic module aims at refining the recommendation issued from the rules. Finally, a frequency module is used to discover other items of interest for the user. Using distinct modules allows us to explain the recommendations to the user The results we have obtained from the evaluation experiments are promising. The combination of the collaborative and semantic modules improves the quality of the recommendations and the frequency module adds new ones. 93,9 of the recommendations are satisfying or approved In near future, we aim at defining the approach to learn 


the user profile in order to adapt the combination of the recommendation modules. We also plan to improve the semantic module by defining the semantic similarity between instances [25], [26]. Thus, when computing the interest by instance, those which are semantically similar to the current instance can be used when the instance is not present in the users history This similarity could also be used during the personalization of the association rules. The personalization rule \(a which consists in only keeping the rules which have a body composed of items contained in the users history, can be relaxed if the items violating \(a the items in the users history. The advantage of the semantic similarity is that it can be computed off-line which does not slow down the recommendation process Another improvement we want to introduce is the use of implicit data collected and based on the users behavior e.g. his search history, the time he spent looking at an item and his navigational patterns. This will help to increase the knowledge about the user and, in turn, lead to a better understanding of his expectations Finally, we plan to experiment the framework on other domains to confirm the domain-independence of the system REFERENCES 1] G. Adomavicius and A. Tuzhilin, Toward the next generation of recommender systems: A survey of the state-of-the-art and 2010 10th International Conference on Intelligent Systems Design and Applications 475 possible extensions, IEEE Trans. Knowl. Data Eng., vol. 17 no. 6, pp. 734749, 2005 2] R. Burke, Hybrid recommender systems: Survey and experiments, User Modeling and User-Adapted Interaction vol. 12, no. 4, pp. 331370, 2002 3] K. Lang, Newsweeder: Learning to filter netnews, in Proceedings of the 12th International Machine Learning Conference \(ML, 1995 4] M. J. Pazzani and D. Billsus, Content-based recommendation systems, in The Adaptive Web, P. Brusilovsky, A. Kobsa, and W. Nejdl, Eds., 2007, vol. 4321, pp. 325341 5] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and J. Riedl Grouplens: An open architecture for collaborative filtering of netnews, in Proceedings of ACM 1994 Conference on Computer Supported Cooperative Work, Chapel Hill, North 


Carolina, 1994, pp. 175186 6] B. Sarwar, G. Karypis, J. Konstan, and J. Reidl, Itembased collaborative filtering recommendation algorithms, in Proceedings of the 10th international conference on World Wide Web \(WWW 295 7] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl, Analysis of recommendation algorithms for e-commerce, in Proceedings of the 2nd ACM conference on Electronic commerce \(EC Minneapolis, Minnesota, USA, 2000, pp. 158167 8] M. Balabanovic and Y. Shoham, Fab: content-based, collaborative recommendation, Commun. ACM, vol. 40, no. 3, pp 6672, 1997 9] D. Billsus and M. J. Pazzani, User modeling for adaptive news access, User Modeling and User-Adapted Interaction vol. 10, no. 2-3, pp. 147180, 2000 10] M. J. Pazzani, A framework for collaborative, content-based and demographic filtering, Artif. Intell. Rev., vol. 13, no. 5-6 pp. 393408, 1999 11] S. Castagnos, A. Brun, and A. Boyer, Probabilistic association rules for item-based recommender systems, in Proceedings of the Fourth Starting AI Researchers Symposium STAIRS 12] W. Lin, Association rule mining for collaborative recommender systems, Masters thesis, Faculty of the Worcester Polytechnic Institute, 2000 13] J. J. Sandvig, B. Mobasher, and R. Burke, Robustness of collaborative recommendation based on association rule mining, in Proceedings of the 2007 ACM conference on Recommender systems \(RecSys 14] B. Mobasher, H. Dai, T. Luo, and M. Nakagawa, Effective personalization based on association rule discovery from web usage data, in Proceedings of the 3rd international workshop on Web information and data management \(WIDM Georgia, USA, 2001, pp. 915 15] R. Agrawal, T. Imielinski, and A. Swami, Mining association rules between sets of items in large databases, in Proceedings of the 1993 ACM SIGMOD international conference on Management of data, New York, NY, USA, 1993, pp. 207 216 16] B. Liu, W. Hsu, and Y. Ma, Integrating classification and association rule mining, in Knowledge Discovery and Data 


Mining, New York City, New York, USA, Aug. 1998, pp 8086 17] Y. Blanco-Fernandez, J. J. P. Arias, A. Gil-Solla, M. R Cabrer, M. L. Nores, J. G. Duque, A. F. Vilas, R. P. D Redondo, and J. B. Munoz, A flexible semantic inference methodology to reason about user preferences in knowledgebased recommender systems, Knowl.-Based Syst., vol. 21 no. 4, pp. 305320, 2008 18] S. E. Middleton, H. Alani, N. R. Shadbolt, and D. C. D Roure, Exploiting synergy between ontologies and recommender systems, in Semantic Web Workshop 2002 At the Eleventh International World Wide Web Conference, 2002 19] M. Zanker and M. Jessenitschnig, Case-studies on exploiting explicit customer requirements in recommender systems User Modeling and User-Adapted Interaction, vol. 19, no 1-2, pp. 133166, 2009 20] N. Ducheneaut, K. Partridge, Q. Huang, B. Price, M. Roberts E. H. Chi, V. Bellotti, and B. Begole, Collaborative filtering is not enough? experiments with a mixed-model recommender for leisure activities, in Proceedings of the 17th International Conference on User Modeling, Adaptation, and Personalization \(UMAP 21] H. Nguyen and P. Haddawy, The decision-theoretic interactive video advisor, in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence \(UAI 494501 22] B. Mobasher, Data mining for web personalization, in The Adaptive Web, ser. Lecture Notes in Computer Science P. Brusilovsky, A. Kobsa, and W. Nejdl, Eds. Springer Berlin Heidelberg, 2007, vol. 4321, ch. 3, pp. 90135 23] T. R. Gruber, A translation approach to portable ontology specifications, Knowl. Acquis., vol. 5, no. 2, pp. 199220 1993 24] N. Tintarev and J. Masthoff, The effectiveness of personalized movie explanations: An experiment using commercial meta-data, in Proceedings of the 5th international conference on Adaptive Hypermedia and Adaptive Web-Based Systems AH 25] R. Albertoni and M. D. Martino, Asymmetric and contextdependent semantic similarity among ontology instances Journal on Data Semantics, vol. 10, pp. 130, 2008 26] X. Jin and B. Mobasher, Using semantic similarity to 


enhance item-based collaborative filtering, in 2nd IASTED International Conference on Information and Knowledge Sharing, Scottsdale, Arizona, 2003 476 2010 10th International Conference on Intelligent Systems Design and Applications 


Basi Association Rles Basi c  Association R u les Association is basically connecting or tying up occurrences of Association is basically connecting or tying up occurrences of events Ol dib t f ilt t O n l y d escr ib e se t s o f s i mu lt aneous even t s Cannot describe patterns that iterate over time e g  itemset a  0  b  0  g    Eg If you sense higher data rates on the downlink than normal AND New Route generated Implies high chances of Intrusion AND New Route generated Implies high chances of Intrusion Associative IDS for NextGen Frameworks Dr S Dua LA Tech 20 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



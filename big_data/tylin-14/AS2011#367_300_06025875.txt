A Maintainable Model of Materialized View Based on Data Warehouse Xueyu Huang College of Applied Science JiangXi University of Science and Technology GanZhou, China Xueyu-h@163.com Qisheng Chen School of Information Engineering JiangXi University of Science and Technology GanZhou, China chenqisheng3392@sina.com Abstract Based on operator SPJ \(Select-Project-Join\ and the technology of self-maintainable view, this paper proposes a new maintainable model of materialized view; the proposed model contains two processes: the monitoring process and maintenance process, the first process is used to monitor the changes of basic tables; while the second process will automatically update the materialized view by auxiliary view, the results show that it can make the materialized view self-maintainable and reduce the storage space Keywords-data warehouse; materialized view; auxiliary view; message queue I I NTRODUCTION Data warehouse and on-line analytical processing OLAP\ as the core of decision support system \(DSS\ have been the hot issue of database domain; However the excessive data of data warehouse and the complexity of OLAP system  have severely affected the efficiency of data processing. Materialized view as the main information storage entity of data warehouse is based on pretreatment of projection, join and aggregate. It is different from the view” concept of database materialized view is not virtual but the real tables of data warehouse  which has been calculated, stored. Therefore, it is not necessary to take complex process of querying for OLAP; some simple calculations can improve the efficiency of querying II THE PROPOSAL OF MAINTENANCE OF MATERIALIZED VIEW In the traditional database environment, the issues of maintenance about view have been fully studied. But, most of them have built on the view manager and system control defined by view. While the source data changes, the system can lock the source tables and capture the changes and then send the corresponding results to view by the manager. However, in the data warehouse environment the definition of view is separated from the source database; the data warehouse can not capture the source database changes initiatively, so it may make the data of view inconsistent with the source database with traditional algorithms to maintain the view of data warehouse. Thus the maintainable technology of materialized views became an important research issue Thesis [1 tak es th e m a in tain a b le te ch n o l o g y b a se d  o n line compensation, The main idea is that the warehouse will record the updated event, and then send a compensatory query to eliminate the disagreement when the warehouse received a new updated message before returning the results of query. However this way will increase the communication load of the system, the cost of roll-back caused by compensation will be too high when maintenance was fails; Thesis [2  3 4 t a ke  a t e c hnol o g y  of response mechanisms and version control to coordinate updated operation between the database and the data warehouse based on the ideas of compensation; In thesis  D B G r o up w o r kgr o u p  o f  St a nfor d U n i v er si t y p r opo sed the maintainable architecture of data warehouse in their WHIPS project, it was divided into two parts: monitor and integrator; The monitor is responsible for analysis and submission of content changes based on data source tables While the integrator takes the compatible control algorithms to ensure the consistency of data This paper studies the maintainable view issue of data warehouse based on operator SPJ \(Select-Project-Join and proposes a new maintainable model of materialized view in data warehouse; In this model, it tracks the data source changes, and forms the corresponding message queue firstly, and then updates the auxiliary views and the global materialized view by the technology of auxiliary view to keep the freshness of data warehouse III RELATED TECHNOLOGY OF MAINTENANCE A Auxiliary view Based on the SPJ \(Select-Project-Join\ expression, and the basic relation  n R R R      2 1  we may define the materialized view V as follows       P R R R  n 2 1 1 Where  is the operation of projection  is a list of attributes of    is the operation of selection, and  is the conditions of  If the V  can be calculated by the V and   we can see that V is self-maintained when the basic relation  changes to   therefore, In addition to the   we hope to find a set of auxiliary view AR to make the expression AR V be self-maintained obviously, the  can be regarded as the auxiliary view but it occupies too much storage space. So we may define the auxiliary view of basic relationship i R as i R AR Pi     i i where AR AR  i   Ai contains a 978-1-61284-722-1/11/$26.00 ©2011 IEEE 2011 International Conference on Mechatronic Science, Electric Engineering and Compute r August 19-22, 2011, Jilin, China 1974 


partial properties of projection and conditions of join, thus there is no need to store these properties which been not defined by view; and Pi  is a partial conditions of selection, therefore it is also  not necessary to store these tuples that do not meet Pi  in auxiliary view So as to describe the generated algorithm of auxiliary view, we introduce some definitions as follows 1\ directed graph  012   G it is also called the join graphic of relation  V G composed by the basic relation  n R R R      2 1  where each relation of  is the vertex of  012   G if the definition of view contains a join condition B R A R j i    where B is the primary key of j R   V G will contain a directed edge   012  j i R R e  from i R to j R and mark this edge with  “RI 2\ Direct dependence  G R  Dep i it can be described as the direct dependent relation of i R The expression is shown as follows      G\(V  e   Dep i j i    j R R R G R 2 Based on the above definitions, so the generated algorithm of auxiliary view can be shown as follows Function aux  G R  Dep i  Input Direct dependence  G R  Dep i of i R  Output: auxiliary view i AR of i R  Initialization   i AR If    G R  Dep i i R AR Pi     i i Else       Dep aux   aux\(Dep tm ct t1 ct i i G R G R R AR i Pi           Return i AR  Where           2  1  ct m t S R S R L ct is the related Conditions of A S B R    A is the primary key of S, and    tm 2 t 1 t i     Dep R R R G R      Function Auxiliary-View \(V, AR Input Materialized view V Output: the set of auxiliary view AR Initialization:  directed graph  012   G of basic relation     AR  For each   i R Has  G R  Dep i  i AR aux  G R  Dep i   i AR add AR   Algorithm Auxiliary-View \(V, AR\lishes the direct dependent collection on the basis of relation  firstly, and then generates the corresponding auxiliary view i AR for each basic relation i R by function aux   G R  Dep i inally returns the set of auxiliary view AR. It provides a good platform for the materialized view IV A IMPROVED MAINTAINABLE MODEL  OF MATERIALIZED VIEW This model contains two components: the data source component and data warehouse component, and as shown in Figure 1 Figure 1 the maintainable model of materialized view Trigger as a part of data source tracks the changes of tables, and informs the monitor of data warehouse to monitor the statue of tables by message queue Data warehouse may contain monitor, integrator, and view manager; monitor sends mainly the message queue to integrator after detecting the changes, and modifies the updated time of message queue; integrator will associate the message queue with corresponding auxiliary view by a rule set which is usually from the tree of auxiliary view view manager takes charge maintenance of each view \(or rule\cluding auxiliary view, association rules between auxiliary view and materialized view A The related definition and data structure about materialized view In order to introduce the maintainable process of materialized view, some important data structure and definition will be shown as follows 1\ The original message queue M According to the updated message of basic tables, the original message queue M will become the symbol of changes about tables some properties is included in this queue M, such as the data source, tables and updated time 2\ The copy of message queue M1 The queue M1 is regarded as the interim message queue of queue M when the terminal message queue R is locked, if the queue R is unlocked, the corresponding R will be replaced by M1 3\ The terminal message queue R This queue R receives the queue M \(or M1\essage firstly and then sends it to the auxiliary view; It will provide the evidence for the update of materialized view 4\ associated rules between auxiliary view and basic tables\(ARAT These rules record mainly the relation between the auxiliary view and the basic tables \(or other  Data source Trigger Trigger  Monitor Data source Data warehouse Integrator View Manager  Data source  1975 


auxiliary views\ make the auxiliary view update automatically based on the terminal message queue R 5\ associated rules between auxiliary view and materialized view\(ARAM  These rules will be used to associate the auxiliary view with materialized view; it can make the materialized view self-maintainable based on auxiliary view In conclusion, the relation of maintainable process is shown in Figure 2 Figure 2 the relation of maintainable process According to the principle of versatility and flexibility the maintainable model is divided into two processes:  the monitoring process of source A and the maintainable process of materialized view B. It can solve effectively the accessing conflict which is caused by the OLTP and OLAP B Monitoring process of source In the process, the monitor of data warehouse traces the changes of tables by the original message queue M which is generated by trigger, it can harmonize the association among the queue M, queue M1 and queue R The monitoring algorithm of source is shown as follows 1 Firstly, trigger generates the original message queue M, and sets the updated time as T when the basic tables have some changes 2 Then, the monitor receives the queue M, and matches the corresponding item of the terminal message queue R \(the last updated time T2, the new updated time T3\ R is locked, go step \(3 else go step \(6 3 Delete the corresponding item of the queue M1 before T, push this item of queue M into queue M1, and change the updated time T as T1 4 For each item of the queue M1, if it is locked in the queue R, return step \(4\nd access next item else go step \(5 5 Detect the original queue M,  If there is a new corresponding message item in queue  M, go step\(6\e lock the corresponding item of the queue R,  copy the item message of queue M1 into the queue R, set T3=T2, T1=T3, and destroy the corresponding  item of M1 6 Lock the corresponding item of queue R, Update the message queue R with the item of queue M set T3=T2, T=T3, and delete the corresponding item of queue M1 C Maintainable process of materialized view Based on the SPJ expression, this process can update the auxiliary view and materialized view by monitoring the changes of the terminal message queue R, the maintainable algorithm is shown as follows 1 The view manager fetches materialized views periodically to form the set of materialized view VL1 2 For each materialized view V1 of VL1, and set the updated time as T4 3 According to the definition of materialized view association rules ARAM, and the algorithm of auxiliary view, we should create the auxiliary view AV1 of materialized view V1 firstly, and then push AV1 into stack by the principle of directed graph, and lock the corresponding item of message queue R 4 Based on the definition of auxiliary view and the association rules ARAT, it is necessary to fetch each auxiliary view AV1 1 the late updated time T2\ AV1, if the corresponding item of the terminal message queue R has changed, go step 5\, else do not change the auxiliary view, and return step \(4\e next auxiliary view will be used 5 Read the updated time T3 of message queue R fetch these data between T2 and T3 from data source, and update the corresponding auxiliary view AV1 1 according to the definition of auxiliary view, set the updated time as T5 6 If the AV1 1 has been updated, the next auxiliary view will be used. If the next auxiliary view is null \(the set of auxiliary view has been updated go step \(7\e return step \(4 7 Based on the association rules ARAM, update the materialized view V1, if has done, go step \(8 else return step \(7 8 Fetch the next materialized view of VL1, if the next is null, go step \(9\e return step \(2 9 The AV1 has done, unlock the terminal message queue R D Application  example We will take the materials purchasing  as an example the relation of tables is shown as follows Buyer \(buyer_id  name, sex, depart_id address Depart \(depart_id de_name Mater \(mater_id ma_name, model, supplier Order \(order_id mater_id buyer_id order_quantity order date Considering the theme: “statistic each supplier’s materials information purchased by different departments for example, the corporation cop-B’s materials information purchased by department NO.2 will be requested to statistic. In order to answer the question, some  measures are taken as follows Original message queue M Materialized view V1 Terminal message queue R ARAT Auxiliary view AV1 Materialized view set VL1 ARAM Process B Process A Copy of message queue M1 1976 


1 Initializing  the basic tables Firstly, we will initialize the basic tables, such as Buyer \(11, Miss Zhan, male, 1, Beijing\, Depart \(1, NO.2 Mater \(101, computer, dell, cop-B\, Order \(1, 101, 11, 20 2011-01-03 2 Having the direct dependence  G R  Dep i According to the relation of basic tables, the direct dependence  G R  Dep i is shown as follows TABLE I T HE RELATION OF BASIC TABLES i R Depart Buyer Mater Order   G R  Dep i  Depart  Buyer mater 3 Setting the auxiliary view The corresponding auxiliary view about the basic tables is set on the basis of direct dependence  G R  Dep i  depart AR  2   _ de _ de  _ depart depart NO name name id  015   depart id id depart name id AR _ depart _   _ buyer buyer  depart  AR  015  mate r lier lier el name a id ater  B cop  p sup p sup  mod  _ m  _ m mater AR  015   mater id mater buyer id buyer date order quantity order id ater AR AR _ _ _  _  _ m buyer_id order_id order  order  AR   015  4 The definition of materialized view Select c.name, c.order_id, c.order_date c.order_quantity,  c.model, c.supplier c.buyer_id, c.mater_id,c.de_name, c.ma_name From order AR as c  5 The process of maintenance If  some changes happen for example, insert into Buyer\(12, Miss Li, male, 1, chongqing insert into Order\(2 101, 12, 30, 2011-02-04 the process of maintenance is shown as follows a according to the updated message of tables trigger will generate the original message queue order M and buyer M and then   detect the corresponding item of queue R, if it is locked copy the message as order M1 and order M1 else update the corresponding item of order R and buyer R and set the last updated time as T2 the new updated time as T3 b Update the materialized view V1, and fetch its set of auxiliary view AR depart AR  buyer AR  mater AR  order AR so we need only to update the auxiliary view buyer AR and order AR according to the association rules ARAM c Fetch these updated data between T2 and T3 from the data source, so the data of buyer AR will be 12, Miss Li, 1, NO.2}, {Miss Zhan, 1 NO.2  order AR will be Miss Zhan, 1, 201101-03, 20, dell, cop-B, 11,101, NO.2, computer Miss Li, 2, 2011-02-04, 30, dell, cop-B, 12,101 NO.2, computer  d According to the defin ition of materialized view the data of theme will be extracted from order AR  V CONCLUSION Based on the deficiency of  analysis and evaluation of traditional off-line maintenance technology and online maintenance technology, this model makes the  OLTP and OLAP can access  data synchronically by setting appropriated control mechanism from data source to data warehouse; some specific characteristics  are shown as follows: Firstly, it can ensure effectively the selfmaintenance of view by the auxiliary mechanism, and minimize the storage space of materialized view, secondly it also make the update of data and maintenance of view synchronically by the mechanism of monitoring, so keep the freshness and consistency of data R EFERENCES 1 Z hang Ba il i, Z h u W e n. “T he s t udy o n m a i n te n a n c e pr o b l e m o f  materialized view,” modern electronic technique.2007 2 L i Z i m u L i L e i, X u  Mi ng  t he o n l i n e m a i n te na nce a n d que r y o f  data warehouse”. chinese journal  of  computers.1999 3 Q i a n zh i g en t h e s t ud y on m a in t e n a nc e t e c h n o log y of m a t e ri a l i z ed  view based timestamp”. Control and automation publication group.2009 4 Y a n g f a n Z h an g Hon g a  d e s i gn of f r a m ework on i n t e rop era b i lit y of data warehouse”. Control and automation publication group 2007,7-3,21-23 5 L iu qu n Z h a n g  Ch u n h a i  t he  m a i n te na nce s t r a te g y o f m a te r ial iz e d  view based on mode .jorunal of computer applications.2005 6 G e Xu eb i n  Zh ou L i j u an  a n e w d y n a m i c ad ju st m e n t a l gor i t h m of  materialized view in data warehouse”.computer engineering and applications .2010,46 8  7 L i z i y u Y a ng D o ng qi ng  t he s e l e ct io n o f M u l t i d im e n s i o n al d a t a  of materialized view in data warehouse”. journal of software.2008 8  Zh a n g x, Ru n Den  I n t e gra t i on th e m a int e n a n c e and synchronization of data warehouse using a cooperation framework 9 Y a o QS, A n A J  Us in g u s er ac c e s s pa tt ern s for s e m a nt i c  qu er y caching. In: Marik V, ed. Proc. of the 14th Int'1 Conf. on Database and Expert System Applications \(DEXA 2003\. Prague: SpringerVerlag, 2003. 737-74 1977 


Figures 8 and 9 depict the convergence of the MINICA algorithm in compared with the proposed algorithm in A cording to these figures, the proposed algorithm based on the ICA has better performance with least error with respect to the algorithm based on the GA for mining ARs problem Also, it able to reaches the optimal solution and it converges faster. But it has more computations. In the ICA, individuals have more interacted with each other and thus the algorithm is more likely to discover global solution  Figure 9  Convergence rate on the Nursery dataset The last test results in this paper have shown in Table IV, which is about the comparison of mean results obtained from MINICA and the genetic algorithm proposed in  with our fitness function The mean number of best different mined rule, the mean number of attributes contained in the rules and the mean of the support, confidence and cosine value of these rules are shown in this table. The cosine measure can be used for evaluating the interestingness of the ARs  According to this table, the proposed algorithm which is based on the imperialist competitive algorithm has better results compared to the association rules mining method in  A dis c ov ered ru le s  w ith appropriate s u pport an d  confidence value compared to proposed method based on GA. In addition the user’s comprehension of these rules and the rules interestingness for the user are acceptable; also the number of attributes obtained from this method is smaller As mentioned, larger rules are more likely to contain redundant information The results of all experiments in this work means that the algorithm of mining association rules based on the ICA is more capable of discovering global solution s in comparison with the mining ARs based on the genetic algorithm  V  C ONCLUSION AND FUTURE WORKS  In this paper, an effective algorithm based on ICA has been proposed to explore interesting and readable ARs that called MINICA. We improved modeling the assimilation policy and the deviational behaviors in ICA for problem of mining ARs. Then we have carried out several tests to evaluate our method behavior in different real datasets The results show the appropriate success of this method in comparison with the method of mining rules by the use of the genetic algorithm. Also, our method is more capable of discovering global solutions Contrary to the techniques used as usual, comprehensible and interesting ARs have directly been mined without generating frequent itemsets and without relying upon the minimum support and the minimum confidence thresholds which are hard to determine for each database Moreover this method is very flexible on changing fitness function, so user can define any normal objective in fitness function with support confidence and etc and obtains his/her interesting rules  The proposed method can able to mine ARs from transactional datasets. So, generalization of the MINICA algorithm is suggested for mining numerical and categorical rules as a future works. Moreover considering that only positive rules discovered in this method discovering both positive and negative rules is suggested  TABLE IV  C OMPARISONS OF THE RESULTS WITH THE PROPOSED METHOD IN 5   10 


R EFERENCES  1  R. Agrawal, T. Imielinski, and A. Swami, “Mining association rules between sets of items in large databases” in: Proceedings of ACM SIGMOD Conference on Management of Data, Washington, Vol. 22 No. 2, 1993, pp. 207–216 2  E Atashpaz-Gargari, and C. Lucas, “Imperialist Competitive Algorithm An Algorithm for Optimization Inspired by Imperialistic Competition”, IEEE Cogress on Evolutionary Compution, Singapore Jun 2007, pp.4661-4667 3  O. M. Badawy, M. I. Habib, and A. A. Sallam, "Quantitative Association Rule Mining Using a Hybrid PSO/ACO Algorithm PSO/ACO-AR\", ACIT'2008, Hammamet, Tunisia, Dec 2008, pp.1-9 4  S. Brin and R. Motwani and J.D. Ullman and S. Tsur, “Dynamic itemset counting and implication rules for market basket data,” Proc of ACM SIGMOD International Conf. on Management of Data Tucson, Vol. 26, No. 2, Jun 1997, pp. 255 – 264 5  A. Ghosh, and B. Nath, “Muti Objective Association Rule Mining Using Genetic Algorithm”, Elsevier Information Sciences, Vol. 163 No. 1, 2004, pp.123–133   6  J. Han, and M. Kamber, “Data Mining: Concepts and Techniques”\(2nd ed.\, Elsevier,  2006 7  M. Houtsma, and A. Swami, “Set-oriented mining of association rules”, Research Report RJ 9567, IBM Almaden Reseach Center 1993 8  J. Mata J.L. Alvarez, and J.C. Riquelme, “An evolutionary algorithm to discover numeric association rules” ,In Proceedings of the ACM symposium on Applied computing SAC, 2002, pp. 590–594 9  M.Nasiri, L.Taghavi, and B.Minaei, “Multi-Objective Rule Mining using Simulated Annealing Algorithm”, Soft Computing, JCDA journal Korea, Vol. 5, No. 1, Feb 2010, pp.60-68     SPSSInc. “Clementine 12.0 Algorithms Guide”. http://www.spss.com   X.Yan, CH. Zhang, and SH. Zhang, “Genetic algorithm-based strategy for identifying association rules without specifying actual minimum support”, Elsevier Expert Systems with Applications, Vol 36, No. 2, 2008, pp.3066-3076   11 


c\(k The distinguished feature of GNP is reusability of nodes based on the graph structure, so the nodes used in a certain transition can be shared with other node transitions. As a generation Rule pool extracted ?Ies are storJ in a rule pool generation+1 Fig. 3. Flow of rule extraction and evolution A'11 : LAND=1 A'12 : LAND=O A'21 : ProtocoUype=tcp A'22 : ProtocoUype=icmp A'23 : ProtocoUype=udp A'31 : Count>=threshold A'32 : Count<threshold Fig. 4. An Example of Sub-Attribute Utilization result, many kinds of association rules can be extracted by compact structures In addition, the extracted rules which satisfy the conditions of the measurements are stored in an association rule pool every generation. Therefore, as described before, the rule extraction of GNP is carried out throughout the generations in order to create the rule pool with sufficient rules. In other words, the aim of GNP is not to create the optimal individual which can extract good rules, but to extract many good rules by making use of all the individuals in all the generations and store the rules in the pool. Fig. 3 shows the whole procedure of the rule extraction and evolution C. Sub-Attribute Utilization There are various kinds of attributes in a network access database such as discrete and continuous attributes. So, these attributes need to be transformed in order for GNP to deal with them efficiently We use a sub-attribute utilization mechanism in order to keep the completeness of data information of binary, sym bolic and continuous attributes. Binary attributes are divided into two sub-attributes corresponding to judgment functions For example, the binary attribute AI\(=land Ail \(representing land= 1 representing land= 0 The symbolic attribute is divided into several sub-attributes 


Fig. 4 shows a division example of three kinds of attributes Normal access rule pool rule1 rule2 rule3 access data d  Class 2 Intrusion access rule pool rule1 rule2 rule3 calculate m1\(d average of all Match1\(d,r calculate m2\(d average of all Match2\(d,r r: a rule in a class Fig. 5. How to calculate average matching degrees Continuous attributes are divided into two sub-attributes \(the sub-attribute greater than or equal to a threshold and that smaller than the threshold deviation \(Ti of each continuous attribute Ai in the database are calculated to obtain the initial threshold Bi selected randomly from [J-li - \(Ti, J-li + \(Til. In addition, the initial threshold Bi is evolved by mutation every generation in order to find more association rules. The evolution of thresholds is controlled by an additional mutation probability which is set at 113 in this paper III. INTRUSION DETECTION WITH A MULTI-DIMENSIONAL PROBABILITY DISTRIBUTION A large number of rules of normal and intrusion accesses can be extracted from the training database [ 10] by the class association rule mining of GNP. Then, a classifier is built based on the extracted rules, which classifies new data into normal, known intrusion and unknown intrusion classes. The features of the proposed probabilistic classification are as follows. 1 built according to the matching degree of all the data with the rules of normal and intrusions. The matching degree of data with normal rules represents one dimension and that 


with intrusion rules represents the other dimension. 2 possible to classify data into the class which does not belong to either class. 3 by adjusting weights on the probabilities of belonging to each class A. Generating probability density function Before introducing the probability density function, the matching degree of data with a rule is defined as follows Nk\(d, r d, r Nk\(r 4 where, N k\(d, r with the antecedent part of rule r in class k \(in this paper, k E a o Fig. 6 0.2 0.4 ml\(d matching degree with normal rules \(X1 b An example of joint probability density function P2\(d normal, intrusion r the antecedent part of rule r Then, the average matching degree of the data with all the rules in class k is calculated as follows where, R k  shows a set of rules in class k. Fig. 5 shows how to calculate the matching degrees of data with the extracted rules and average matching degrees for a certain class Finally, a joint probability density function f\(Xl Xk, . . .  , XK matching degrees of all the training data d E Dtrain with the rules r E R k  for all k E C, where C = {I, . . .  , k, . . .  , K is a set of suffixes of classes and Dtrain is a set of training data. Fig. 6 \(a joint probability density function, where normal data gather around the right side of the figure because the normal data basically matches with normal rules and does not match intrusion rules, and intrusion data gather around the left side because the matching degree with intrusion rules is high and that with normal rules is low. On the other hand, the probability of the other area is low because there are few 


accesses which satisfy both normal and intrusion rules or neither rule. However, if a new data does not satisfy either rule, it could be regarded as unknown intrusion B. Classification based on the probability density function The probability Pk \(d Dtest is a set of testing data Po \(d calculated as follows Po 1 - z= Pk\(d 7 kEC Fig. 6 \(b probability density function shown in Fig. 6 \(a areas correspond to the probability of belonging to normal class and intrusion class, respectively. In Fig. 6 \(b axis shows the matching degree with normal rules and X2axis shows that with intrusion rules. The probabilities of belonging normal class k = 1, known intrusion class k = 2 and unknown intrusion class k = a are calculated by Eq. \(6 and \(7 Pl\( d P2\( d Po 11.0 1m1\(d m2\(d 1m2 \(d o ml\(d f \(Xl , X2 f \(Xl , X2 1 - \(Pl\( d d C. Modification of probability Pk \(d 8 9 10 In network intrusion detection, there is a trade-off between positive false rate \(PFR NFR increases when normal accesses are labeled as intrusion and NFR increases when intrusion accesses are labeled as normal. In order to realize the acceptable PFR and NFR the modification of the probability Pk \(d follows TABLE I PARAMETERS SETTING OF GNP 


Population Size 120 Generation 1000 Processing Node 10 Judgment Node 100 Crossover Rate 1/5 Mutation Rate Pm1 1/3 Mutation Rate Pm2 1/3 Wo = 2.0, Wl = 1.7 and W2 = 2.4 Normal Unknown intrusion f!N-OON matching degree with normal rules \(mN\(d Fig. 7. Other classification scheme considering mean and standard deviation of two one-dimensional probability density functions data in the training data with normal rules, and those of intrusion data with intrusion rules \(M and \(JJ data is classified into normal, known intrusion and unknown intrusion by the following conditions, where, mN\(d average matching degree of testing data d with normal rules mJ\(d 2.5 0.3 are coefficients if mN\(d JN then else if /-LN ?: /-LJ then d is normal else d is known intrusion if mJ\(d JJ then d is known intrusion else d is unknown intrusion P Wk?\(? k f-- wo Po \(d d 11 where, Wo , Wk \(k E C IV. SIMULATIONS In this section, the detection ability of the proposed method is evaluated by the intrusion detection simulations using KDD99CUP [10] network connection database. The parameters of GNP is shown in Table I. In addition, the comparison with other classification \(called conventional method in this paper in [9] is carried out. The conventional method uses mean and standard deviation of the distributions of normal and 


intrusion accesses, respectively, which is summarized as follows. The conventional method calculates mean /-LN and standard deviation \(IN of the matching degrees of normal trusion are shown in Fig. 7. The parameters have been appropriately determined through the simulations A. Simulation results The training data contains 5,000 normal access data and 5,000 intrusion access data including two kinds of attacks smurf and neptune. In KDD99Cup database, 41 attributes are included, however, 165 sub-attributes are assigned to the judgment functions in GNP after sub-attribute utilization described in II-C. As a result of the evolution, 19,372 rules including 1,786 normal rules and 17,586 intrusion rules are extracted 1 accesses and 499 intrusion accesses which are the same intrusion types as the training data. The classification of both TABLE II TESTING RESULTS OF THE PROPOSED METHOD IN SIMULATION 1 Normal \(T T T Normal \(C Intrusion \(C Total 481 501 18 1000 TABLE III TESTING RESULTS OF THE CONVENTIONAL METHOD IN SIMULATION 1 Normal \(T T T Normal \(C Intrusion \(C Total 474 525 1 1000 methods are based on the same normal rules and intrusion rules, and the classification results of these methods are shown in Table. II and III, respectively. Normal\(T T T unknown intrusion which are labeled by each classifica tion method, respectively, and Normal\(C C indicates correct labels of normal and known intrusion respevtively. So, in Table II for example, 481 normal accesses out of 501 are labeled as normal, 2 are labeled as known intrusion and 18 are labeled as unknown intrusion From the tables, detection rate DR, PFR, NFR and Accu racy of the proposed method are calculated as DR 


PFR NFR Accuracy 481 + \(499 + 0 2 + 18 0/499 = 0.0 481 + 499 and those of the conventional method are DR PFR NFR Accuracy 474 + \(499 + 0 26 + 1 0/499 = 0.0 474 + 499 DR shows how much the normal data are labeled as normal and the intrusion data are labeled as intrusion, and Accuracy shows how much the data belonging to certain classes are classified into the correct classes. The results show that the proposed method classifies the testing data correctly with better rate than the conventional method 2 mal accesses and 320 intrusion accesses including two kinds of unknown intrusions \(nmap and portsweep to two kinds of known intrusions. The classification results of the proposed method and the conventional method are shown in Table. IV and V, respectively. Here, Unknown \(C indicates the correct label of unknown intrusion TABLE IV TESTING RESULTS OF THE PROPOSED METHOD IN SIMULATION II Normal \(T T T Normal \(C known \(C Unknown \(C Total 759 246 63 1068 TABLE V TESTING RESULTS OF THE CONVENTIONAL METHOD IN SIMULATION II Normal \(T T T Normal \(C Known \(C Unknown \(C 


Total 741 280 47 1068 From the tables, DR, PFR and NFR of the proposed method are calculated as DR PFR NFR Accuracy 727 + 288 21/748 = 2.81 32/320 = 10.0 727 + 240 + 43 and those of the conventional method are DR PFR NFR Accuracy 712 + 291 36/748 = 4.81 29/320 = 9.06 712 + 240 + 42 We can see that the proposed method also shows better DR, PFR and Accuracy, however, NFR of the proposed method is larger than that of the conventional method in this simulation. Because this simulation deals with unknown intrusion, NFR becomes higher, so how to determine the weights on the probabilities of normal and intrusion accesses is an important problem which is related to the trade-off between PFR and NFR V. CONCLUSIONS In this paper, a classification method with a multi dimensional probability density function is proposed and ap plied to the network intrusion detection problem to evaluate its classification ability. The proposed method can classify data based on the probabilities that the data belongs to normal, known intrusion and unknown intrusion classes therefore, it becomes more flexible than the classification method which divides the classes based only on the mean and standard deviation of the distribution of each class Two kinds of simulations are carried out; one of them deals with the testing dataset containing normal and known intrusion accesses in order to confirm the detection ability for known patterns; and the other one deals with that containing 


unknown intrusion accesses in addition to normal and known intrusion accesses. From the simulation results, it is clarified that the proposed method shows higher detection rate and lower positive false rate in both simulations. But, there is a room for improvement of negative false rate by adjusting weights on the probabilities depending on the problems and also improvement of the classification as follows in the future. We will consider the problems which have more than two classes in order to confirm the general classification abil ity of the proposed method. For example, a known intrusion class can be divided into several classes corresponding to the types of attacks. Then, high dimensional probability density function can be created in order to improve the detection accuracy REFERENCES 1] S.-J. Han and S.-B. Cho, "Evolutionary neural networks for anamoly detection based on the behavior of a program," IEEE Trans. Syst Man, Cybern. B, vol. 36, no. 3, pp. 559-570, 2006 2] D. Parikh and T. Chen, "Data fusion and cost minimization for intru sion detection," IEEE Trans. on Information Forensics and Security vol. 3, no. 3, pp. 381-389, 2008 3] D. E. Denning, "An intrusion detection model," IEEE Trans. Software Eng., vol. 13, pp. 222-232, 1987 4] S. Mabu, K. Hirasawa, and J. Hu, "A graph-based evolutionary algorithm: Genetic network programming \(GNP using reinforcement learning," Evolutionary Computation, vol. 15 no. 3, pp. 369-398, 2007 5] K. Hirasawa, T. Eguchi, J. Zhou, L. Yu, and S. Markon, "A double deck elevator group supervisory control system using genetic network programming," IEEE Trans. Syst., Man, Cybern. C, vol. 38, no. 4, pp 535-550, 2008 6] T. Eguchi, K. Hirasawa, J. Hu, and N. Ota, "A study of evolutionary muitiagent models based on symbiosis," IEEE Trans. Syst., Man Cybern. B, vol. 36, no. 1, pp. 179-193, 2006 7] K. Shimada, K. Hirasawa, and J. Hu, "Genetic network programming with acquisition mechanisms of association rules," Journal of Ad vanced Computational Intelligence and Intelligent Informatic, vol. 10 no. 1, pp. 102-111,2006 8] Y. Gong, N. Lu, S. Mabu, C. Chen, Y. Wang, and K. Hirasawa Network intrusion detection system based on matching degree distri bution using genetic network programming," SICE Journal of Control Measurement and System Integration, submitted 


9] Y. Gong, S. Mabu, C. Chen, Y. Wang, and K. Hirasawa, "Intrusion detection system combining misuse detection and anomaly detection using genetic network programming," in Proc. of the SICE-ICASE International Joint Conference, 2009, pp. 3463-3467 10] "Kddcupl999 data. " [Online]. Available: kdd.ics.uci.eduldatabases kddcup99/kddcup99.htrn1 11] R. P. Lippmann, D. J. Fried, I. Graf, J. Haines, K. P. Kendall, D. Mc Clung, D. Weber, S. Webster, D. Wyschogrod, R. K. Cunningham and M. A. Zissman, "Evaluating intrusion detection systems: The 1998 darpa offline intrusion detection evaluation," in Proc. of DARPA Information Survivability Conference and Exposition 2000, vol. 2 IEEE Computer Society Press, 2000 12] K. Shimada, K. Hirasawa, and J. Hu, "Class association rule mining with chi-squared test using genetic network programming," in Proc. of the IEEE International Conference on Systems, Man and Cybernetics 2006, pp. 5338-5344 


n-dimension data cube\( I1  I k Support=sup_count/total_count 2 3 4. Performance Analysis Example 2 Lets talk about a practical problem just like the status of sales. Assume that we will mine the association rules involved 4 dimension attributes of sales, the minsup=25%. First of all, using OLAP technology to build a 4-D data cube and the 4 dimension attributes are: time location, item, and supplier. For location dimension which contains area, country and so on, we choose province level We use brand level for item dimension, company level for supplier dimension. Time dimension can be divided as Q1 1-3 4-6 7-9 10-12 location\(P1,P2,L1,L2 York, item\(B1,B2,B3,B4 C1,C2,C3 sales data cube can be generalized like this Graphic 2: The 4-Dimension Data Cube of Sales The details of this sales data cube are in the table follow: The amount of cells is 100 Location Time Item Supplier Count Cell-1 P1 Q1 B1 C2 5 Cell-2 P1 Q3 B1 C1 2 Cell-99 L1 Q3 B1 C1 3 Cell-100 L2 Q4 B1 C3 11 Table 2: The details data table of sales data cube We use original Apriori_Cube Algorithm to find frequent predicate set with minsup_num= 25%*100=25 According the data table we calculate that sup_count of every member of dimension L is \(P1:8, P2:5, L1:1, L2:24 and also T, I, S. So there is the process Graphic 3: The processes of old algorithm As we know, through comparing with the minsup_num dimension location has no one frequent 1-predicate set, so that there have no frequent 4-predicate set in the output by the original algorithm. But users are interested in the Candidate 1-Predicate set L T I S P1 P2 L1 


L2 Q1 Q2 Q3 Q4 B1 B2 B3 B4 C1 C2 C3 Frequent 1-Predicate set T I S Q1 Q3 B2 B3 C1 C2 I1 I 2 C1              C2                 C3 2 12 1 3 5 1 6 2 12 8 11 Q 1  Q 2  Q 3  Q 4 P 1 P 2 L 1 L 2 Candidate 2-Predicate set Q1,B2},{Q1,B3 Q1,C1},{Q1,C2 Q3,B2},{Q3,B3 


Q3,C1},{Q3,C2 Candidate 3-Predicate set Q1,B2,B3}{Q 1,Q3,B2},{Q3 C1,B2 Frequent 2-Predicate set Q1,B2}{Q1,B 3},{Q3,B2 Q3,C1 Output: 1L U 2L U 3L Frequent 3-Predicate set Q1,B2,C1},{Q1,B3,B2 Q1,B2,B3  6 level from the same dimension and SP to pruning Candidate 3 Set, pruning {Q1,Q3,B2}, keep {Q1,B2,B3} due to the special requirement on location B by users 7 1 max_support of every dimension 1 frequent 4-predicate set which contains location dimension And the candidate 3-predicate set {Q1,Q3,B2} is useless because when we mine multi-dimension association rules we should follow that one predicate set contains no more than one different level from the same dimension even the sup_count >minsup_num when there are no requirements from users. But this time, users require that different members from dimension item can exist at the same time So we redo this mining process by the improved Algorithm Graphic 4: The processes of improved algorithm At last, we got the frequent 4-predicate set which the users are interested in, and then can format the rules 5. Conclusion In this paper, we have studied issues and methods on efficient mining of multi-dimension association rules based on data cube. With the development of technology, the size 


of database has become much huge than ever before unimaginable. So the multi-dimension model of database based on data cube has become useful and popular relatively how to mine useful multi-dimension association rules based on this model has been important too. Among the algorithms for the problems we choose the most classify one to improve, to make it more efficient and useful An efficient algorithm, Apriori_Cube_Improved, has been developed which explores the multi-dimension association rules. First, we use max_support and min_support of every frequent 1-predicate set to check the levels of dimensions, and then adjust the data cube by roll-up and drill-down operation immediately. This step is embed in the process of mining association rules, so it makes the rules much more useful and flexible; second applying one predicate set contains no more than one different level from the same dimension and SP pruning can help reduce the amount of predicate set, especially with the great growing of the number. So the speed of algorithm improved is faster than ever At last, there are also many other interesting issues and flaws of the algorithm which call for further study including efficient mining multi-dimension association rules of complex measures and so on. Finally, I should thank all the people who have give me help for this paper Reference 1] Jiawei Han, Micheline Kamber. Data Mining Concepts and Techniques. China Machine Press, 2007 2] Agrawal R, Imielinski T and Swami A. Mining association rules between sets of items in large database. Proc. of the ACM SIGMOD Conf., Washington DC, 1993 3] Gao Xuedong, Wang Wenxian and Wu Sen. Multidimensional Association Rule Mining Method Based on Data Cube Computer Engineering, China,2003 4] Sheng Yingying, Yan Ren, Wang Jiamin and Li Jia. Research Multi-dimensional Association Rule Ming Based on Apriori Science Technology and Engineering, China, 2009 5] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. Proc. of the 20th Int.Conf. on VLDB Santiago, Chile, 1994 6] Guozhu Dong, Jiawei Han, Joyce Lam, Jian Pei and Ke Wang Mining Multi-Dimension Constrained Gradients in Data 


Cubes. Proc. of the 27th Int.Conf. on VLDB, Roma, Italy 2001 7] M. J. Zaki. Scalable Algorithms for Association Mining. IEEE Transactions on Knowledge and Data Engineering, 2000 Candidate 1-Predicate set L T I S P1 P2 L1 L2 Q1 Q2 Q3 Q4 B1 B2 B3 B4 C1 C2 C3 Candidate 1-Predicate set L T I S P L Q1 Q2 Q3 Q4 B1 B2 B3 B4 C1 C2 C3 Frequent 1-Predicate L T I S P L 


Q1 Q3 B2 B3 C1 C2 Frequent 4-Predicate set Q3,C1,B2,P},{Q1,B2,B3 Output L1 U L2 U L3 U L4 The Dimension need to be adjust Dimension: Location Operation: Roll-up to increase the level of this dimension Result P\(P1,P2 L1,L2 2 3 2 3 The Features Of Every 1-Predicate Set Location: min_support=13 max_support=25 Time: min_support=5 max_support=30 Item: min_support=10 max_support=25 Supplier: min_support=11 max_support=27 4 5 4 max_support of every dimension 5 minsup_num=25, and no one has to be adjusted Frequent 3-Predicate set Q3,C1,B2},{Q1,B2,L Q1,B3,L},{Q3,P,B2 Candidate 4-Predicate set 


Q3,C1,B2,P},{Q1,B2,B3,L}\(7 The Features of Every 1-Predicate Set Location: min_support=1 max_support=24 Time: min_support=5 max_support=30 Item: min_support=10 max_support=25 Supplier: min_support=11 max_support=27 Candidate 2-Predicate set Q1,B2},{Q1,B3},{Q1,C1 Q1,C2},{Q3,B2},{Q3,B3 Q3,C1},{Q3,C2},{P,Q1 P,Q3},{P,B2},{P,B3},{P,C1 P,C2},{L,Q1},{L,Q3 L,B2},{L,B3},{L,C1},{L,C2 Frequent 2-Predicate set Q1,B2}{Q1,B3},{Q3,B2 Q3,C1},{P,Q3},{L,Q1 6 Candidate 3 -Predicate set Q3,C1,B2},{Q3,C1,P},{Q1,B 2,L},{Q1,B3,L},{Q3,P,B2},{Q 1,B2,B3  6 level from the same dimension and SP to pruning Candidate 3 Set, pruning {Q1,Q3,B2}, keep {Q1,B2,B3} due to the special requirement on location B by users 7 1 max_support of every dimension 1 frequent 4-predicate set which contains location dimension And the candidate 3-predicate set {Q1,Q3,B2} is useless because when we mine multi-dimension association rules we should follow that one predicate set contains no more than one different level from the same dimension even the sup_count >minsup_num when there are no requirements from users. But this time, users require that different 


members from dimension item can exist at the same time So we redo this mining process by the improved Algorithm Graphic 4: The processes of improved algorithm At last, we got the frequent 4-predicate set which the users are interested in, and then can format the rules 5. Conclusion In this paper, we have studied issues and methods on efficient mining of multi-dimension association rules based on data cube. With the development of technology, the size of database has become much huge than ever before unimaginable. So the multi-dimension model of database based on data cube has become useful and popular relatively how to mine useful multi-dimension association rules based on this model has been important too. Among the algorithms for the problems we choose the most classify one to improve, to make it more efficient and useful An efficient algorithm, Apriori_Cube_Improved, has been developed which explores the multi-dimension association rules. First, we use max_support and min_support of every frequent 1-predicate set to check the levels of dimensions, and then adjust the data cube by roll-up and drill-down operation immediately. This step is embed in the process of mining association rules, so it makes the rules much more useful and flexible; second applying one predicate set contains no more than one different level from the same dimension and SP pruning can help reduce the amount of predicate set, especially with the great growing of the number. So the speed of algorithm improved is faster than ever At last, there are also many other interesting issues and flaws of the algorithm which call for further study including efficient mining multi-dimension association rules of complex measures and so on. Finally, I should thank all the people who have give me help for this paper Reference 1] Jiawei Han, Micheline Kamber. Data Mining Concepts and Techniques. China Machine Press, 2007 2] Agrawal R, Imielinski T and Swami A. Mining association rules between sets of items in large database. Proc. of the ACM SIGMOD Conf., Washington DC, 1993 3] Gao Xuedong, Wang Wenxian and Wu Sen. Multidimensional Association Rule Mining Method Based on Data Cube 


Computer Engineering, China,2003 4] Sheng Yingying, Yan Ren, Wang Jiamin and Li Jia. Research Multi-dimensional Association Rule Ming Based on Apriori Science Technology and Engineering, China, 2009 5] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. Proc. of the 20th Int.Conf. on VLDB Santiago, Chile, 1994 6] Guozhu Dong, Jiawei Han, Joyce Lam, Jian Pei and Ke Wang Mining Multi-Dimension Constrained Gradients in Data Cubes. Proc. of the 27th Int.Conf. on VLDB, Roma, Italy 2001 7] M. J. Zaki. Scalable Algorithms for Association Mining. IEEE Transactions on Knowledge and Data Engineering, 2000 Candidate 1-Predicate set L T I S P1 P2 L1 L2 Q1 Q2 Q3 Q4 B1 B2 B3 B4 C1 C2 C3 Candidate 1-Predicate set L T I S P L Q1 Q2 Q3 Q4 B1 B2 


B3 B4 C1 C2 C3 Frequent 1-Predicate L T I S P L Q1 Q3 B2 B3 C1 C2 Frequent 4-Predicate set Q3,C1,B2,P},{Q1,B2,B3 Output L1 U L2 U L3 U L4 The Dimension need to be adjust Dimension: Location Operation: Roll-up to increase the level of this dimension Result P\(P1,P2 L1,L2 2 3 2 3 The Features Of Every 1-Predicate Set Location: min_support=13 max_support=25 Time: min_support=5 max_support=30 Item: min_support=10 max_support=25 Supplier: min_support=11 max_support=27 4 5 


4 max_support of every dimension 5 minsup_num=25, and no one has to be adjusted Frequent 3-Predicate set Q3,C1,B2},{Q1,B2,L Q1,B3,L},{Q3,P,B2 Candidate 4-Predicate set Q3,C1,B2,P},{Q1,B2,B3,L}\(7 The Features of Every 1-Predicate Set Location: min_support=1 max_support=24 Time: min_support=5 max_support=30 Item: min_support=10 max_support=25 Supplier: min_support=11 max_support=27 Candidate 2-Predicate set Q1,B2},{Q1,B3},{Q1,C1 Q1,C2},{Q3,B2},{Q3,B3 Q3,C1},{Q3,C2},{P,Q1 P,Q3},{P,B2},{P,B3},{P,C1 P,C2},{L,Q1},{L,Q3 L,B2},{L,B3},{L,C1},{L,C2 Frequent 2-Predicate set Q1,B2}{Q1,B3},{Q3,B2 Q3,C1},{P,Q3},{L,Q1 6 Candidate 3 -Predicate set Q3,C1,B2},{Q3,C1,P},{Q1,B 2,L},{Q1,B3,L},{Q3,P,B2},{Q 1,B2,B3  


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



2011 3 rd Conference on Data Mining and Optimization \(DMO 28-29 June 2011, Selangor  Malaysia 978-1-61284-212-7/11/$26.00 \2512011 IEEE  Reducing Network Intrusi on Detection Association Rules Using Chi-Squared Pruning Technique Ammar Fikrat Namik 1 Zulaiha Ali Othman 2  School of Computer Science Faculty of Information Science and Technology University Kebangsaan Malaysia 43650 Bangi, Malaysia 1 ammar_fikrat@sun1.ftsm.ukm.my 2 zao@ftsm.ukm.my   Abstract 227Increasing number of computer networks now a day 
has increased the effort of putting networks in secure with various attack risk. Intrusion Detection System \(IDS\ a popular tool to secure network. Applying data mining has increased the quality of intrusion detection neither as anomaly detection or misused detection from large scale network traffic transaction. Association rules is a popular technique to produce a quality misused detection. However,  the weaknesses of association rules is the fact that it often produced with thousands rules which reduce the performance of IDS. This paper aims to show applying post-mining to reduce the number of rules and remaining the most quality rules to produce quality signature. The experiment conducted using two data set 
collected from KDD Cup 99.  Each data set is partitioned into 4 data sets based on type of attacks \(PROB, UR2, R2L and DOS Each partition is mining using Apriori Algorithm, which later performing post-mining using Chi-Squared 2 mputation techniques. The quality of rules is measured based on ChiSquare value, which calculated  according  the support confidence and lift of each association rule. The experiment results shows applying post-mining has reduced the rules up to 98% and remaining the quality rules Keywords- component; Association Rules; Intrusion DetectionSystem; Chi-Square; Apriori Algorithm 
 I   INTRODUCTION   The used of various type of internet application has dramatically increased the network traffic, which causes increasing the number of attacks and types of attacks. Now a day, network system exposes with a high level risk of security The first threat for a computer network system was realized in 1988 when 23 year old Robert Morris launched the first worm, which override over 6000 PCs of the ARPANET network. On February 7th, 2000 the first DOS attacks of great volume where launched, targeting the computer systems of large companies like Yahoo!, eBay Amazon, CNN, ZDnet and Dadet. More details on these 
attacks can be found at [1  Th es e th re ats o r m o re o t h ers a r e  likely to appear in the future. Therefore, various network protection systems have been developed to secure network such as like firewall, anti-virus, IDS, etc An intrusion detection system \(IDS\ inspects all inbound and outbound network activity and identifies suspicious patterns that may indicate a network or system attack from someone attempting to break into or compromise a system 2   Now a day, IDS is becoming a critical component to secure the network. Due to large of security audit data as well as complex and dynamic properties of intrusion behaviors optimizing performance of IDS becomes an important open problem that is receiving more and more attention from the 
research community [3  In 1980 Anderson, introduced the concept of intrusion detection in [4 fi ned a n i n t r usi o n at t e m p t  o r  a  t h re a t t o  be  the potential possibility of a deliberate unauthorized attempt to access information, manipulate information, or render a system unreliable or unusable. Since then, several techniques for detecting intrusions have been studied Most of the techniques used in IDS exploit to learn rules from the behavior of intrusions and normal activities. Many machine-learning paradigms including neural networks linear genetic programming, support vector machines bayesian networks, multivariate adaptive regression spline 
fuzzy inference systems, rough set theory, etc. have been applied to the design of IDS. Several data mining techniques including discovering association rules, have been applied to intrusion detection \(ID\. These rules can then be used for misuse detection and anomaly detection [5   Anomaly-based IDS detects activities that vary from established patterns for users and misuse-based IDS compares user's activities with the known behaviors of attackers. These approaches build detection models by applying data-mining algorithms to large data sets of audit data [30    Association rule is a popular data mining techniques to produce quality misused detection. However, the due to the 
large number of network traffics and its attribute, it causes the large number rules to present the pattern. These large numbers of rules has reduced the performance of the IDS However, there are many un-useful rules are produced Therefore, this paper aims to apply post mining technique to reduce the association rules by remaining the quality pattern The paper is divided into three sections.  Second section discusses the related work on IDS, Apriori Algorithm, Post Mining and Chi-Squared techniques. The third presents how 


 978-1-61284-212-7/11/$26.00 \2512011 IEEE  this experiment is conducted and finally presents the experiment results and conclusion II  RELATED  WORK A  Intrusion Detection System The objective of intrusion detection software is to determine intrusions into a computer or network via viewing various network actions or features. At this point intrusion refers to several set of actions that threatens the integrity availability or confidentiality of a network [6   T h e m a in  objective of IDS software is monitoring antagonistic operations of all kinds, whether individual \(hackers and crackers\ or programmatic \(viruses, Trojan horses\. IDS can function on a meticulous server or in a complete section of a network Fundamentally, there are couple approaches to intrusion detection model as described in [7 Mi s u s e d e te c t io n m o d e l refers to detection of intrusions that follow well defined intrusion models. It is very practical in detecting known attack models. Anomaly detection model refers to detection achieved by detecting changes in the models of operation or performance of the system. It can be used to detect identified and unidentified attack [8  In  o r d e r t o  d e tec t in t r u s i o n  actions, a lot of machine learning \(ML\ algorithms have been widely used to the massive amount of multifaceted and dynamic dataset to detect identified and unidentified intrusions, such as neural network, support vector machine genetic algorithm, fuzzy logic and data mining [9 B  Misuse detection Misuse detection based on wide knowledge of models associated with signature for known attacks supplied by individual authorities. This strategy is employed by the current generation of commercial intrusion detection systems. Misuse detection has low false positive rate, but cannot detect novel attacks. Some of the approaches for Misuse detection are pattern matching, data mining, and state transition analysis. Example misuse detection systems that use data mining include IDDM \(Intrusion Detection using Data Mining Technique\y are a realt i m e NIDS f o r  misuse and anomaly detection. It applies association rules Meta rules, and characteristic rules. It employs data mining to produce description of network data and uses this information for deviation analysis, MADAM ID \(Mining Audit Data for Automated Models for Intrusion Detection is one of the best known data mining projects in intrusion detection i s an offl i ne ID S t o produ ce an o m al y a n d  misuse intrusion detection models. Association rules and frequent episodes are applied in MADAM ID to replace hand-coded intrusion patterns and profiles with the learned rules and Automated Discovery of Concise Predictive Rules for Intrusion Detection C  Intrusion detection with Association rules Given the intrusion detection import problem, the international knowledge discovery and data mining group KDD\ provided a benchmark \(1999 KDD Cup Competition\ There are four main categories of attacks were classified according to the actions and goals of the attacker given in the KDD [12 T h e y  are d en i alo f s e r v i ce   DOS   probe, remote-to-local \(R2L\ user-to-root \(U2R Additionally, association rules mining, is measured as one of the most important tasks in knowledge discovery in databases A m o ng se t s o f i t e m s i n t r a nsa ct i o n da t a ba ses it aims at discovering implicative propensities that can be precious information for the decision maker. The Association Rule technique proposed by Agrawal is a most popular tool In [2 t h e y e v o l ved t h e A p ri or i A l go ri t h m fo r di sco v er i n g  association rules  The Apriori Algorithm requirements are Confidence and Support; these two values determine the degree of association that must hold. The Support shows how many times the items in the rule crop up together and it is the relation of transactions that include all the items in the antecedent and consequent to the number of whole transactions and the confidence shows the probability of both the antecedent and the consequent coming into view in the same transaction. Confidence is the relation of the rule support to the number of transactions that include the antecedent and it is the conditional probability of the consequent given the antecedent  Usually when both of the measures are high we need a third determent, in this case it is Lift to evaluate the quality of rules. Lift shows the power of a rule over the random co-occurrence of the antecedent and the consequent, given their individual support. It offers information about the development, the increase in probability of the consequent given the antecedent. Lift is defined as follows Rule Support  Lift =                                                                                           \(1 Support \(Antecedent\ * Support \(Consequent  In recent times, association rules have been used in pattern recognition problems like classification in [14 an d  15  In   1 5 p r op os ed a n o v e l  m odel n a m e ly clas s as s o cia t i o n rule \(CAR\as been used to solve the classification problems. A CAR set is a subset of association rules with the specified classes as their consequences. Boolean and fuzzy CARs are used for building classifiers, correspondingly. One of the Association Rules problem, that a huge amount of rules have been discovered and a big part is useless rules set D  The Interestingness of Association Rules Within the last decade the KDD society has recognized this face often referred to as interestingness as a significant and hard component of the process of KDD. For dealing with this problem, the most frequently approach is used based on the structure of interestingness measures \(called measure for short\. In association rules definition  i n t r od uc e s  t w o measures: support and confidence as we mentioned in the previous section. These are well modified to Apriori algorithm constraints, but are nonsufficient to capture the full features of the rule interestingness. The interestingness of the rules can be classified into two types: Subjective and Objective. Subjective measures and objective measures. The subjective measures rely on the goals, the knowledge, and the idea of the user. The objective measures are statistical indexes in reference Subjective measures explicitly depend 


 978-1-61284-212-7/11/$26.00 \2512011 IEEE  on the user's goals and his/her knowledge or attitudes. They are shared with specific supervised algorithms in order to evaluate the extracted rules with the user's expectations [16   Objective measures are numerical indexes that only rely on the data distribution. Interestingness refers to the quantity to which a discovered pattern is of interest to the user and is driven by issues such as innovation, utility, relevance and statistical significance [17   E  post-mining Post mining is a significant step in the process of knowledge discovery to refine discovered patterns and learned models and present functional and relevant knowledge to end users. In the last couple of years; a surge in research on improving the algorithmic performance of the originally proposed algorithms, among which the Apriorialgorithm is mostly used have seen. Till today, several successful applications illustrating their usefulness have been reported in the literature. Some methods were presented and different algorithms were established to reduce the number of item sets by generating closed, maximal or optimal item sets and several algorithms to reduce the number of rules, using pruning techniques or non redundant rules. However, postprocessing methods can develop the discovered rules selection. Different complementary post-processing methods may be used, like pruning, summarizing, grouping, or visualization [18  Pr uni ng consi s t s  o f re m o vi ng uni nt e r e s t i n g or unnecessary rules before a user is able to learn the rules and categorize interesting ones from them. Some pruning techniques has been proposed to reduce the huge amount of association rules such as Redundancy Removal, Pessimistic Error Rate, Closed Set, Chi-Square, subsumed rules Pruning can significantly decrease the discovered association\222s number; this number might still be very huge to be tractable. In summarizing, this technique, rules can be clustering into some abstraction stages, every one based on the users preference. Advanced level rules give an extra general summary of the discovered knowledge even as the lesser level rules can be browsed for additional facts. There are a lot of methods have been applied in summarizing such as taxonomies and direction setting rules. The grouping phase point is to look at some other characteristics of the rules and cluster them based on different dimensions. In this phase, the researchers are highlighted the grouping semantics via means of the descriptive scope of time and financial significance, A lot of techniques have been applied in this phase such as economic assessment and time based patterns. Visual investigation of the potentially attractive association rules is to be visualized as an integrated and main part of any exploratory data mining surroundings, each of the above alterations can be supported via means of visually improved mining tools. The visualization improves the readability of a large number of rules by using modified graphical representations. Though, most of the offered post-processing methods are commonly based on statistical information in the database While rule significance powerfully depends on user knowledge and objectives, these methods do not promise that the significant rules will be extracted. For instance, if the user looks for unpredicted rules, all the previously known rules should be pruned. Or, if the user needs to focus on exact schemas of rules, only this subset of rules should be selected Furthermore, as recommended in t h e r u l e  po st processing methods are supposed to be imperatively based on a strong interactivity with the user Pruning Technique The basic concept of pruning technique is reducing the huge quantity of rules is the exclusions of generated rules number because they are manifestations of several type of useless phenomenon, there is frequently a lot of association rules discovered from a dataset and it is needed to remove useless rules before a user is able to learn the rules and categorize interesting ones from them. There are several researches have been done in this area such as [20  p r es en t e d  a computation namely the minimum amount of improvement defined as: confRl - confR2. In [2 ha s  pro p o s e d e sse nt i a l  rule set to give up a minimal rule subset, which compactly encodes without information loss the classification knowledge available in a classification rule set Chi-Square Pruning technique Chi-Squared 2 an analysis technique that helpful in determining the association rules statistical significance level 22  C o m p u tin g th e ch is q u a r e s t atis tic f o r th e  co u p l e  o f  variables \(A, B\ involves constructing two contingency tables. The experimental contingency table for \(A, B\ has four cells, parallel to the four possible Boolean combinations of A, B. The value in every cell is the number of explanation samples\at competition the Boolean combination for that cell 2  212 212 003  3  The performance of Chi-Square has been used in many domains to prune the discovered association rules. In Biomedical Knowledge, in [23 ha s  pr opo sed a m e t hod Ch i Square association rule on Association Based on Classification ABC. The results show it significantly reduces irrelevant connection and saves a lot of computation time generates much fewer rules. In [24 ha s used  Chi S q uare  significance level to remove the insignificant rules for a huge 002\002 212 1 expected 2 expected, observed jio ji jiji  2 Consider two binary valued random variables A and B where i-th row and the j-th column is called the i,j and  Oi,j an observed frequency Ei,j = an expected \(theoretical\requency, asserted by the null hypothesis Chi-square analysis is a standard statistical technique that lets one to measure the degree of dependence between the variables A and B. The Chi-Squared statistic of equation 2 Satisfies the following Equation equality \(at any time the expression on the right hand side RHS is well defined Consequent\\ in [2   2 n \(Lift-1 2     Support Confidence Confidence Lift Confidence Support 


 978-1-61284-212-7/11/$26.00 \2512011 IEEE   amount of association rules are discovered for mixtures of transcription factor binding sites in the repeat sequences of the repeat database. The Apriori and AprioriTid have been applied to execute the associations from the mixtures of transcription factor binding sites in repeat sequences. The huge number of association rules makes it really hard for the user to recognize those interesting and functional ones. At last, the unnecessary rules are pruned and then the remaining rules are partitioned into cover and non-cover sets. For complex datasets described, [2 s i nt r od uc ed a n  association rule mining technique by both static and timedependent attributes, and apply this technique to find associations among sleep questionnaire responses, clinical summary information, and all-night polysomnographic recordings of sleeping human subjects. They have designed an extension of the Apriori association rule mining algorithm to deal with time-varying sequences and they used ChiSquared and P-value to get the meaningful associations among summary and polysomnographic time series variables III  EXPERIMENTED SETUPS  Figure 1, shows the steps conducted in this research. It consists of data collection, cleaning and pre-processing partitioning, mining and post- mining                        Figure 1  Steps Conducted A  Data Collection The Experiment used KDD CUP 99 training dataset which contained around 5000000 connection records, the 10% training dataset contained 494,021 records, which there were 97,278 normal connection records \(i.e. 19.69 sample of the dataset in appendix A. Every record contained value of 41 different attributes that describe the different feature of the corresponding connection and the value of the connection is labeled either as an attack with one specific attack type or as a normal. In 10% dataset there are 24 different attack types present, each one falls exactly into one of the following categories: normal,  probing, dos, u2r and r2l. In this research two datasets have been collected randomly \(which are 4000 and 2000\nstances from the 10 training dataset. The two data sets have partitioned into four parts based on attack types \(PROBE, DOS, R2L and U2R Excel sheet has been used to filter the datasets and partitioned  B  Data Cleaning and Preprocessing The data cleaning and pre-processing follow the step suggested by th e bias ed f eatu r es  w h ich  h a v e abn o r m al  values of distribution were removed more than 70% data distribution is same value. While in pre-processing performs three steps The first step converting the string and continues values to nominal numerical continues values. The second step is applying discretization using Disc-Chimerge algorithm. The KEEL 1.0 data mining tool is used for this purposed. The third step is applying feature selection technique based on Pvalue using a commercial tool known as PASW modeler 13 to select the most significant attribute C  Mining Process In the mining process Apriori Algorithm has been used to discover the association rules for intrusion detection system The Apriori Algorithm has been applied for the all random datasets, first group was the 4000 records \(PROBE1 DOS1 R2L1 and U2R1 datasets\nd the second group was 2000 records \(PROBE2, DOS2, R2L2 U2R2 datasets TANAGRA tool was used Apriori Algorithm and the parameters were; the minimum Support was between 0.25 \226 0.4 and the minimum Confidence was between 0.7 \226 0.9 as the literature show the rules with high confidence and support values are significant [26  A s w e l l a s t h e m a xi m u m l e ngt h o f  rules was 4 and Lift filtering was from 1.0 and above  Finally the association rules for each dataset which is discovered and contained from Antecedent, Consequent, Lift Support and Confidence D  Pruning the Association Rules The Pruning technique aims to eliminate remain the unnecessary association rules in each association rules datasets The pruning process has two steps to filter and prune the rules; the first step is removing the useless rules which did  TABLE I  CONFIDENCE INTERVAL FOR EACH RULES SET OF DATASET 1 Dataset 1 Confidence Intervals Class Before Pruning After Pruning 90.0  95.0  97.5  99.0  99 5 99 9 


 978-1-61284-212-7/11/$26.00 \2512011 IEEE  Probe 374 18    4 7 7 Dos 1923 83   30 9 18 26 R2L 257 26 12  2 10 1 1 U2R 757 34 5 - - 28 1  not contain any attack type \(probe, dos, r2l and u2r\ in the discovered association rules The second step is using one of the functional in determining the statistical significant level of association rules; it is Chi-Squared analysis 2   It is defined in terms of the entries of the observed and expected contingency tables as it seen in equation 2  Therefore 2 stand for a summed normalized square deviation of the observed values from the matching expected values. In the tables of the 2 distribution Statistical significance levels matching to specific 2 values may be found. The degrees\222 number of freedom is 1 because we are dealing with binary valued attributes. The 2 distributions with 1 degree of freedom have minimum 2  values for selected stages After mining, this makes easy computation of ChiSquared values in equation 3, smooth the pruning progress of the mined rule set based on statistical significance. It is computed directly from the values of Support, Confidence and Lift interest of the rules in question Each of rule set row is evaluated, either it is representing high significant rules.  The 2 value of each rule has compared with standard 2 distribution table as shown in table I below and 2 significant level was selected TABLE II  CHI SQUARE DISTRIBUTION TABLE  Confidence Interval 90 0 95 0 97 5 99  99 5 99 9 Tail Proba bility 0 80 0 70 0 50 0 30 0 20 0.1 0 0.0 5 0.0 25 0 01 0.0 05 0.0 01 Degre e of freedo m=1 0 06 0 15 0 46 1 07 1 64 2.7 1 3.8 4 5.0 2 6 64 7.8 7 10 83  Insignificant                                       Significan t   IV  EXPERIMENT  RESULTS Table II and Table III shows the experiments result of the number of rules before and after post mining process for data set 2000 and data set 4000 respectively.  The row class described the type of attacks; the second column shows the number of rules before post mining and the third column shows the significant rules set for each class. In the Confidence interval section, the rules concerted based on the percentage of each single rule. Table II below has shown the sets and numbers of rules before and after the pruning and the confidence interval for each rule sets for dataset 1 The quality of the rules after post-mining is evaluated by looking at the relationship between Chi-Squared values with the standard Chi-Squared distribution table. The results shows applying post-mining has reduced the rules up to 95 for PROBE data subset of dataset 1, 91% for DOS subset 89% for R2L and 97% for U2R remaining the quality rules Figure 2 shows the graph of the rules before and after pruning for dataset1 0 500 1000 1500 2000 Probe Dos R2L U2R Before Pruning After Pruni ng  Figure 2  Number of Rules Before and After Pruning for Data Set1 Table III has shown the total rules before and after pruning and the significant rules level with the confidence interval for each set of rules The reduction for dataset 2 was 97% for PROBE subset 96% for DOS, 90% for R2L and 90% as well for U2R. From the results it can be seen the significant levels of the rules start from 90% confidence interval and cumulative to 99.9 TABLE III  CONFIDENCE INTERVAL FOR EACH RULES SETOF DATAST 2 Dataset 2 Confidence Intervals Class Before Pruning After Pruning 90.0  95.0  97.5  99.0  99 5 99 9 Probe 378 8 8 Dos 2568 95 28 10 13 14 10 20 R2L 284 27 12 12  2 1 U2R 430 43 1  13 13 4 12 Figure 3 shows the graph of the rules before and after pruning for data set 2 0 500 1000 1500 2000 2500 3000 Probe Dos R2L U2R Before Pruning After Pruning  Figure 3  Number of Rules Before and After Pruning in for Data Set 2 V  CONCLUSION This paper has presented the important of post mining techniques in network intrusion detection. The use of 2  pruning techniques has reduced the number of rules of a 


 978-1-61284-212-7/11/$26.00 \2512011 IEEE  misused detection up to 98% with preserving the same quality of knowledge above 90% confident.  This research has shown the beneficial of applying post-mining in building a quality performance of IDS. The less number of rules the better performance of IDS  ACKNOWLEDGMENT This work is supported by 01-01-02-SF0598  REFERENCES  1  S. Entwisle,   http://www.securityfocus.com/news/2445, Security Focus Newsletter #184, 2003 2  T. Lappas, and K. Pelechrinis, Data Mining Techniques for \(Network Intrusion Detection Systems, Department of Computer Science and Engineering UC Riverside, Riverside CA 92521. 2007 3  H. Nguyen,  and D. Choi,  Application of data mining to network intrusion detection: classifier selection model. Springe  Verlag Berlin Heidelberg.pp, 399-408. 2008 4  J.P. Anderson, Computer Security Threat Monitoring and Surveillance. Technical report, James P Anderson Co., Fort Washington, Pennsylvania. April 1980 5  W. Xuren, H famie, X. Rongsheng, "Modeling Intrusion Detection System by Discovering Association Rule in Rough Set Theory Framework," cimca, pp.24, International Conference on Computational Inteligence for Modelling Control and Automation and International Conference on Intelligent Agents Web Technologies and International Commerce \(CIMCA'06\,2006 6  R. Ritchey, B. O'Berry, and S. Noel, \223Representing TCP/IP Connectivity for Topological Analysis of Network Security\224 Proceedings of 18th Annual Computer Security Applications Conference, Las Vegas, Nevada , USA, 9-13 December 2002, pp. 2531 7  B. Mukherjee, L.Todd Heberlein, Karl N.Levitt, \224Network Intrusion Detection\224,IEEE, June 1994 8  A. Adetunmbi, S. Falaki, O. Adewale, and B. Alese, Network Intrusion Detection Based On Rough Set And K-Nearest Neighbor International Journal of Computing and ICT Research, Vol. 2 No. 1 June 2008 9  M Sheikhan and Z. Jadidi, Misuse Detection Using Hybrid of Association Rule Mining and Connectionist Modeling, World Applied Sciences Journal 7 \(Special Issue of Computer & IT\: 31-37, 2009 ISSN 1818-4952   A. Tomas, "IDDM: INTRUSION Detection using Data Mining Techniques Technical report DSTO electronics and surveillance research laboratory, Salisbury, Australia, May2001   W. Lee and S. J.Stolfo, "A Framework for constructing features and models for intrusion detection systems ACM transactions on Information and system security \(TISSEC\, vol.3, Issue 4, Nov 2000   A. Sung H., and S. Mukkamala, \223Identifying important features for intrusion detection using support vector machines and neural networks,\224 In Proc. of International Symposium on Applications and the Internet \(SAINT 2003\, 2003, pp. 209-217   U. M Fayyad, S. G. Piatetsky, P. Smyth and R. Uthurusamy \(eds Advanced in Knowledge Discovery Data Mining. AAAI/MIT Press 1996   G. Florez, S.M. Bridges and R.B. Vaughn, 2002.An Improved Algorithm for Fuzzy Data Mining for Intrusion Detection. In the Proceedings of the North American Fuzzy Information Processing Society Conference, pp: 27-29   B. Liu, W. Hsu and Y. Ma, 1998. Integrating Classification and Association Rule Mining. In the Proceedings of KDD'98, pp: 80-86   H. Xuan Huynh, F. Guillet, T. Quyet Le and Briand H. Ranking objective interestingness measures with sensitivity value, VNU Journal of Science, Natural Sciences and Technology 24 \(2008\ 122132   G. Piatetsky-Shapiro and C. J. Matheus, The interestingness of deviations", AAAI'94, Knowledge Discovery in Databases Workshop 1994\, p. 25-36   B. Baesens, S. Viaene, and J. Vanthienen, 2000, \223Post-Processing of Association Rules,\224 Proc. Workshop Post-Processing in Machine Learning and Data Mining: Interpretation, Visualization, Integration and Related Topics with Sixth ACM SIGKDD, pp. 20-23, 2000   J. Blanchard, F. Guillet, and H. Briand, \223A User-Driven and QualityOriented Visualization for Mining Association Rules,\224 Proc. Third IEEE Int\222l Conf. Data Mining, pp. 493-496, 2003   Jr. R.J. Bayardo and R. Agrawal, "Mining the Most Interesting Rules", In Proc. Of the 5th ACM SIGKDD Int'l Conf on Knowledge D iscovery and Data Mining, San Diego, CA, USA, 1999   Baralis and Chiusano, Essential classification rule sets, ACM Transactions on Database Systems \(TODS\ archive Volume 29, table of contents Pages: 635 \226 674, 2004.  ISSN:0362-5915   A. Sergio Alvarez, Chi-squared computation for association rules preliminary results. Technical Report BC-CS-2003-01, July 2003 USA   G. Li and X. Zhang, Mining Biomedical Knowledge Using ChiSquare Association Rule, 2010 IEEE International Conference on Granular Computing   J. Tzong Horng,  Predicting regulatory elements in repetitive sequences using transcription factor binding sites. EJB Electronic Journal of Biotechnology ISSN: 0717-3458, 2000   Parameshvyas Laxminarayan, Carolina Ruiz, Sergio A. Alvarez and Majaz Moonis, Mining Associations over Human Sleep Time Series CBMS '05 Proceedings of the 18th IEEE Symposium on ComputerBased Medical Systems, 2005   M. Bahrololum and M. Khaleghi, Anomaly Intrusion Detection System Using Hierarchical Gaussian Mixture Model, IJCSNS International Journal of Computer Science and Network Security VOL.8 No.8, August 2008   L. Rodman,   J. Jackson, and   R. Meentemeyer, An Association Rule Discovery System Applied to Geographic Data, Lecture Notes in Geoinformation and Cartography 2010, 143-164, DOI: 10.1007/9783-540-88264-0_9   R. Agrawal, T. Imielinski and A. Swami, Mining association rules between sets of items in large databases. | Proc. ACM SIGMOD Int Conf. Management of Data, Washington, pp.207-216. 1993   Z. A. Othman,   A. Bakar and   I. Etubal,  Improving signature detection classification model using features selection based on customized features. Intelligent Systems Design and Applications ISDA\, 2010 10th International Conference on  Nov. 29 2010-Dec. 1 2010   M. Deraman, Jalil M.D., Zulaiha A.O., \223Multilayer Packet Tagging for Network Behaviour Analysis\224, in Proceedings of ITSIM10, Kuala Lumpur, Malaysia, IEEE Computer Society, pp. 909-913, June 2010    


have been generated randomly using uniform distributions on the respective domains. A single fact table suffices for the objectives of our experimentation While, in fact, the characteristics of the database instance e.g., total database volume and data distribution determinant in order to study the behavior of mining algorithms, this is not so when we are up to study incremental algorithms. Indeed, as simple complexity considerations point out, the important parameters from the viewpoint of the performance study of incremental algorithms are the selectivity of the mining constraints \(which determine the volume of data to be processed from the given database instance of the previous result set  Fig. 3  Item dependent incremental algorithm \(constraint selectivity Vs execution Fig. 3 reports the performances of the item dependent incremental algorithm \(ID mining constraints changes. The experimentation is carried out for different constraints on the item dependent attributes letting the constraints selectivity vary from 0% to 100% of the total number of items The Fig. 4 presented tests the same algorithm, but it lets vary the number of rules in the previous result set. Again we sampled twenty points \(in the range 0  220 figures report the total amount of time needed by the algorithm to complete In particular, the bars, which represent the single experiments, are divided in two components: the preprocessing time \(spent in querying the database to retrieve Incremental Update Strategy for Indexed Item Set Mining  522  and store in main memory the items that satisfy the constraints needed by the algorithm to read the previous result set and to filter out those rules that do not satisfy the constraints any more Fig. 5 and 6 report the performances of the context dependent CD time, specifying how much time was spent for preprocessing and for the core mining task 


  Fig. 4  Volume of previous result Vs execution time for Item dependent incremental algorithm It is worth noticing, that the CD incremental algorithm performs a greater amount of work with respect to the ID algorithm because the problem it solves is far more complex In fact, in the preprocessing phase the algorithm must retrieve all the group/item pairs satisfying the constraints and access to them in order to build and update the BHF data structure Only then, it can retrieve the results from the BHF structure  Fig. 5  Context dependent constraint selectivity Vs execution The execution times of both algorithms increase almost linearly with the increase of the two parameters \(constraint selectivity and previous results item dependent incremental algorithm runs much faster than its counterpart  Fig. 6  Volume of the previous result Vs execution time Both the algorithms are faster than the IMine algorithm which, is incapable of solving a class of more difficult problems of mining item set extraction from contextdependent constraints. IMine, as the most of the algorithms operates starting from scratch. Hence, comparisons of incremental update strategy with other mining algorithms on the field of context dependent constraints show better performance quantifying to 7% improvement Must be in two column format with a space of 4.22mm 0.17 V. CONCLUSIONS The proposed incremental update approach to constraintbased mining makes use of the information contained in previous results to answer new queries in frequently updating databases. The beneficial factors of the approach are that it uses both the previous results and the mining constraints, in order to reduce the item sets search space. It comprises of item dependent and context dependent constraints for extracting item sets Proposed approach makes a significant usage of available results of previous queries \(if the incremental approach results effective with respect to a conventional execution 


incremental option for a data mining algorithm is of course preferable in an inductive database system, since it allows the exploitation of all the available information in the system in order to speed up the response time The better performance of incremental algorithm depicted in the result section  worked on problems with item and context dependent constraint present a solution for item extraction from frequently updated database. This is done by running first the  Proceedings of the International Conference on Communication and Computational Intelligence 2010  523  mining algorithm of our choice \(on the problem defined by the query but without the context dependent constraints then applying the incremental algorithm on top of it \(with the addition of context dependent constraints whenever the mining constraints select a very small part of the original dataset, proposed incremental update strategy is likely to be very fast and efficient REFERENCES 1]  G. Grahne and J. Zhu, Mining Frequent Itemsets from Secondary Memory, IEEE Intl Conf. Data Mining \(ICDM 04 2]   J. Han, J. Pei, and Y. Yin, Mining Frequent Patterns without Candidate Generation, ACM SIGMOD, 2000 3]  Y.-L. Cheung, Mining Frequent Itemsets without Support Threshold With and without Item Constraints, IEEE Trans. Knowledge and Data Eng., vol. 16, no. 9, pp. 1052-1069, Sept. 2004 4]   G. Cong and B. Liu, Speed-Up Iterative Frequent Itemset Mining with Constraint Changes, IEEE Intl Conf. Data Mining \(ICDM 02 107-114, 2002 5] C.K.-S. Leung, L.V.S. Lakshmanan, and R.T. Ng, Exploiting Succinct Constraints Using FP-Trees, SIGKDD Explorations Newsletter, vol. 4 no. 1, pp. 40-49, 2002 6]  T. Uno, M. Kiyomi, and H. Arimura, LCM ver. 2: Efficient Mining Algorithms for Frequent/Closed/Maximal Itemsets, IEEE ICDM Workshop Frequent Itemset Mining Implementations \(FIMI 7]   J. Pei, J. Han, and L.V.S. Lakshmanan, Pushing Convertible Constraints in Frequent Itemset Mining, Data Mining and Knowledge Discovery, vol. 8, no. 3, pp. 227-252, 2004 8]   M. Botta, J.-F. Boulicaut, C. Masson, and R. Meo, A Comparison 


between Query Languages for the Extraction of Association Rules 9]  E. Baralis, T. Cerquitelli, and S. Chiusano, Index Support for  Frequent Itemset Mining in a Relational DBMS, 21st Intl Conf. Data Eng ICDE 10]   G. Liu, H. Lu, W. Lou, and J.X. Yu, On Computing, Storing and Querying Frequent Patterns, Ninth ACM SIGKDD Intl Conf Knowledge Discovery and Data Mining \(SIGKDD 


frequent, and there is no equal-support pruning in its subsets. So the Bitwise And Operation on binary strings of 0001100011 and 0001100011 is employed. As the result is 0001100011, the support of the itemset {G C, E} is 4, which is equal to {G, C}. E is put into the equal-support set of {G, C}, and does not need to add a new son node. When itemset {C, A, E} is checked, all of its subsets are frequent, and none of them is in the equal-support set. The corresponding two bit strings 0001101111 and 0011101011, are operated by &. The resultant string is 0001101011. The number of 1 in string 0001101011 is 5. So the support of itemset {C, A E} is 5, which is not equal to the support of {C, A}. So a new son node is added to {C, A}. The Trie after generation\(3  5 8 8 G C A E A 4 C 4 E 6 A 6 E 6 E 7 5 E 0001101011 E  Fig. 2. Trie after generation\(3 In generation\(4 therefore, the height of the Trie does not increase. All frequent itemsets are in Fig. 2. In the last step, all frequent itemsets are written out according to the Trie  5. EXPERIMENTAL RESULTS  


The proposed algorithm is tested on all the five datasets prepared by Roberto Bayardo, from UCI and PUMSB datasets. The datasets are available at http://fimi.cs.helsinki.fi. The characteristics of the datasets are shown in Table 6. The first column contains the names of the datasets. The second column shows the number of items contained in each dataset. The third column shows the average length of each transaction and the last column indicates the total number of transactions in each dataset TABLE 6 DATABASE CHARACTERISTICS Datasets Items Avg. length Records mushroom 119 23 8,124 chess 75 37 3,196 pusmsb* 2,088 50.4 49,046 connect 129 43 65,557 pusmsb 2,113 74.0 49,046 In order to illustrate the performance of the proposed algorithm, BitApriori is compared to the fast Apriori implemented in Ferenc [20], and another similar recently published, algorithm Index-BitTableFI proposed by Song [16]. In order to show the efficiency of the pruning technology employed in BitApriori another algorithm BitAprioriNE, which is the same as BitApriori, except that it does not use the special equal-support pruning, is designed. All of the above four algorithms are implemented in C++ and compiled with Microsoft Visual C++ 6.0. The experiments are performed on a Windows XP PC equipped with a Pentium 2.0 GHz CPU and 1.5 GB of RAM memory  For each dataset, a mass of different support thresholds are tested, and the five most important of them are chosen for reporting in this paper. The experimental results are shown in Fig. 3-7. In the figures, the y-coordinate denotes the execution time \(in seconds while x-coordinate denotes the support threshold 0 100 200 300 400 


500 600 0.05 0.06 0.07 0.08 0.09 0.1 0.11 Apriori BitApriori BitAprioriNE Index-BitTableFI  Fig.3 Execution time comparison on mushroom  0 200 400 600 800 1000 0.45 0.5 0.55 0.6 0.65 0.7 0.75 Apriori BitApriori BitAprioriNE Index-BitTableFI  Fig.4 Execution time comparison on chess  0 500 1000 1500 2000 2500 3000 3500 4000 0.25 0.3 0.35 0.4 0.45 0.5 0.55 Apriori BitApriori BitAprioriNE Index-BitTableFI  Fig.5 Execution time comparison on pusmsb 0 1000 


2000 3000 4000 5000 6000 0.65 0.7 0.75 0.8 0.85 0.9 0.95 Apriori BitApriori BitAprioriNE Index-BitTableFI  Fig.6 Execution time comparison on connect  0 500 1000 1500 2000 2500 0.675 0.725 0.775 0.825 Apriori BitApriori BitAprioriNE Index-BitTableFI  Fig.7 Execution time comparison on pusmsb  As shown in Fig. 3, BitApriori outperforms all other algorithms, and the dominance is apparent. In this dataset, the special equal-support pruning works efficiently. In Fig. 4, BitAprioriNE beats Apriori and Index-BitTableFI. In Fig. 5, the effectiveness of the proposed algorithm is verified, especially when the minimum support is low. In Fig. 6, BitAprioriWE exhausts the memory when the support threshold is lower than 0.8, but BitApriori does not. That means the special equal-support pruning contributes to save the memory. In Fig. 7, when the threshold is larger than 0.725, Apriori beats the BitApriori. But BitApriori outperforms the Apriori, when the threshold is lower than 0.725  


Apriori does not use the binary string and the special equal-support pruning. The BitTable is employed in Index-BitTableFI, but there is no special equal-support pruning, except for the frequent 2-itemsets BitAprioriNE outperforms Apriori in Fig. 3-5, but not in Fig. 6-7, because of the limitation of memory BitAprioriNE does better than Index-BitTableFI in Fig 4 and Fig. 5. In the mushroom, there is a vast number of equal-support itemsets for frequent 2-itemset. So Index-BitTableFI outperforms BitAprioriNE  On one hand, the special equal-support pruning is a useful technique for improving efficiency. The performance is improved significantly, especially when the databases contain many equal-support itemsets, such as the mushroom. It also reduces memory requirement On the other hand, the technique of binary string in BitApriori improves the efficiency of Apriori. These two techniques combine perfectly in BitApriori. So BitApriori has very good performance. It is the best for all of the five datasets  6. CONCLUSIONS  In this paper, two effective techniques are employed to improve the performance of Apriori, by reducing the cost of candidate generation, and by support counting The two effective techniques are integrated perfectly in BitApriori, and improve the computational efficiency significantly. Experimental results have shown that BitApriori outperforms the fast Apriori and Index-BitTableFI, especially when the minimum support threshold is low  When the database is large, the BitApriori may suffer the problem of memory scarcity. So how to solve the memory problem will be the question addressed in one of our future works. And another work is to improve Bitwise And Operation on the binary string, or replace it by some more effective techniques  REFERENCES 


 1] Agrawal R., T. Imielinski, A. Swami, Mining association rules between sets of items in large databases, in Proceedings of the ACM SIGMOD Conference on Management of Data. pp. 207-216 1993 2] Agrawal R., R. Srikant, Fast algorithms for mining association rules, The International Conference on Very Large Databases, pp. 487-499, 1994 3] Zaki M.J., S. Parthasarathy, M. Ogihara, W. Li New algorithms for fast discovery of association rules, in Proceedings of the 3rd International Conference on Knowledge Discovery and Data Mining, pp. 283-296, 1997 4] Han J., J. Pei, Y. Yin, Mining frequent patterns without candidate generation," in Proceedings of the 2000 ACM SIGMOD international conference on Management of data, ACM Press, pp. 1-12, 2000 5] Pork J.S., M.S. Chen, P.S. Yu, An effective hash based algorithm for mining association rules, ACM SIGMOD, pp. 175-186, 1995 6] Brin S., R. Motwani, J.D. Ullman, S. Tsur Dynamic itemset counting and implication rules for market basket data, in Proceedings of the ACM SIGMOD International Conference on Management of Data, pp. 255264, 1997 7] Brin S., R. Motwani, C. Silverstein, Beyond market baskets: generalizing association rules to correlations, in Proceedings of the ACM SIGMOD International Conference on Management of Data Tuscon, Arizona, pp. 265-276, 1997 8] Toivonen H., Sampling large databases for association rules, in Proceedings of 22nd VLDB Conference, Mumbai, India, pp. 134-145, 1996 9] Savasere A., E. Omiecinski, S.B. Navathe, An efficient algorithm for mining association rules in large databases, in Proceedings of 21th International Conference on Very Large Data Bases VLDB'95 10] Tsay Y.J., J.Y. Chiang, CBAR: an efficient method for mining association rules, Knowledge Based Systems, 18 \(2-3 


11] Liu G., H. Lu, W. Lou, Y. Xu, J.X. Yu, Efficient mining of frequent patterns using ascending frequency ordered prefix-tree, Data Mining Knowledge Discovery, 9 \(3 12] Grahne G., J. Zhu, Fast algorithms for frequent itemset mining using FP-Trees, IEEE Transaction on Knowledge and Data Engineering, 17 \(10 1347-1362, 2005 13] Zaki M.J., Scalable algorithms for association mining, IEEE Transactions on Knowledge and Data Engineering, 12 \(3 14] Zaki M.J., K. Gouda, Fast Vertical Mining Using Diffsets, in Proceedings of the ACM SIGMOD International Conference on Knowledge Discovery and Data Mining, pp. 326-335, 2003 15] Dong J., M. Han, BitTableFI: an efficient mining frequent itemsets algorithm, Knowledge Based Systems, 20 \(4 16] Song W., B.R. Yang, Z.Y. Xu, Index-BitTableFI An improved algorithm for mining frequent itemsets, Knowledge Based Systems, 21 \(6 507-513, 2008 17] Ferenc B., Surprising results of trie-based FIM algorithms, IEEE ICDM Workshop on Frequent Itemset Mining Implementations \(FIMI'04 CEUR Workshop Proceedings, vol. 90, G. Bart, J.Z Mohammed, and B. Roberto, Eds, Brighton, UK 2004 18] Ferenc B., A Survey on Frequent Itemset Mining Technical Report, Budapest University of Technology and Economic, 2006 19] Bart G., Survey on Frequent Pattern Mining Manuskript, 2002 20] Ferenc B., A fast APRIORI implementation IEEE ICDM Workshop on Frequent Itemset Mining Implementations \(FIMI'03 USA, 2003  


15] R. Agrawal and R. Srikant, "Fast algorithms for mining association rules in large Databases," presented at the Proceedings of the 20th International Conference on Very Large Data Bases, 1994 16] NKUDIC. \(June, 2006, National Kidney and Urologic Diseases Information Clearinghouse:Prostate Enlargement. Available http://kidney.niddk.nih.gov/kudiseases/pubs/prostateenlargement accessed on 10/06/2010 17] M. J. ZAKI, "Mining Non-Redundant Association Rules," Data Mining and Knowledge Discovery, 2004 18] Y. Xu and Y. Li, "Mining for Useful Association Rules Using the ATMS," presented at the International Conference on Computational Intelligence for Modelling, Control and Automation, and International Conference on Intelligent Agents, Web Technologies and Internet Commerce \(CIMCA-IAWTIC05 544 2010 10th International Conference on Intelligent Systems Design and Applications 


8]  Sergey Brin and Lawrence Page. The anatomy of a large-scale hypertextual Web search engine. Proceedings of the seventh international conference on World Wide Web 7: pp. 107-117, 1998 9]  J. Pei, J. Han, B. Mortazavi-Asl and H.Zhu, Mining Access Patterns Efficiently from Web Logs, Proceedings of the Pacific-Asia Conference on Knowledge Discovery and Data Mining, pp. 396-407 2000 10]  C. H. Cai, A. W. C. Fu, C.H. Cheng and W. W. Kwong, Mining Association Rules with Weighted Items, In Database Engineering and Applications Symposium, Proceedings IDEAS'98, pp. 68  77, 1998 11]  F. Tao, F. Murtagh and M. Farid, Weighted Association Rule Mining using Weighted Support and Significance Framework, In Proceedings of the 9th SIGKDD conference, 2003 12]  Show-Jane Yen, An Efficient Approach for Analyzing User Behaviors in a Web-Based Training Environment, International Journal of Distance Education Technologies, Vol. 1, No. 4, pp.55-71, 2003 13]  Show-Jane Yen, Yue-Shi Lee and Chung-Wen Cho, Efficient Approach for the Maintenance of Path Traversal Patterns, In Proceedings of IEEE International Conference on e-Technology, eCommerce and e-Service \(EEE 14]  M. Spiliopoulou and L. C. Faulstich, Wum: A web utilization miner EDBT Workshop WebDB98, Springer Verlag, 1996 15]  M. S. Chen, J. S. Park and P. S. Yu, Efficient data mining for path traversal patterns,  IEEE Transactions on Knowledge and Data Engineering, pp. 209-221, 1998 16]  H. Yao,H. J. Hamilton, and C. J. Butz, A Foundational Approach to Mining Itemset Utilities from Databases, Proceedings of the 4th SIAM International Conference on Data Mining, Florida, USA, 2004 17]  Z. Chen, R. H. Fowler and A. Wai-Chee Fu, Linear Time Algorithm for Finding Maximal Forward References, Proceedings of International Conference on Information Technology. Computers and Communications  \(ITCC'2003 18]  T. Jing, Wan-Li Zou and Bang-Zuo Zhang, An Efficient Web Traversal Pattern Mining algorithm Based On Suffix Array, Proceedings of the 3rd International Conference on Machine Learning and Cybernetics , pp 1535-1539, 2004 19]  Show-Jane Yen, Yue-Shi Lee and Min-Chi Hsieh, An efficient incremental algorithm for mining Web traversal patterns, Proceedings of the 2005 IEEE International Conference on e-Business Engineering ICEBE05 20]  L. Zhou, Y. Liu, J. Wang and Y. Shi, Utility-based Web Path  Traversal Pattern Mining, Seventh  IEEE International Conference on Data 


Mining Workshops, pp. 373-378, 2007 21]  C. F. Ahmed, S. K. Tanbeer, Byeong-Soo Jeong and Young-Koo Lee Efficient mining of utility-based web path traversal patterns, 11th International Conference on Advanced Communication Technology ICACT09 22]   http://en.wikipedia.org/wiki/PageRank 23] en.wikipedia.org/wiki/Association_rule_mining  Attributes? FPW Algorithm FTPW Algorithm Recognition of User behavior Visiting Frequency Page Rank Time Spent on Web page Page Size Accessibility of required information in less time Improving Web navigation and system design of Web applications  Enhancing server performance 2010 5th International Conference on Industrial and Information Systems, ICIIS 2010, Jul 29 - Aug 01, 2010, India 200 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



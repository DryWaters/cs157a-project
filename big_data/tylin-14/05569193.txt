978-1-4244-5934-6/10/$26.00 2010 IEEE                                 1418 2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery \(FSKD 2010 1 A Counting Mining Algorithm of Maximum Frequent Itemset Based on Matrix Haiwei Jin College of Computer&Information Engineering, Zhejiang Gongshang University Hangzhou, P.R. China jinhaiwei@mail.zjgsu.edu.cn  AbstractMining frequent itemset is an important research topic in association rule area. There are two main kinds of Algorithm: Apriori Algorithm and FP- growth Algorithm and their varieties. Generating candidate itemset of Apriori and traversing tree nodes of FP- growth affect the efficiency of data mining. This paper puts forward the new simplified algorithm: eliminating and plotting blocks to the matrix with simply counting rows and columns, thus, to find out maximal frequent itemset. The experiment results show that the algorithm can improve mining efficiency  Index Termsdata mining; association rule; maximal frequent patterns; support threshold I. INTRODUCTION Mining association rule is a very important research topic in the field of data mining. Finding frequent patterns is a key technology in association rule. R. Agrawal et al in 1993 first proposed the famous Apriori algorithm based on frequent itemset[1, 2], then  most algorithms are  based on the algorithm for improvement or derivative variant of the algorithm [6 , 7]. These algorithms are based on recursive statistics, shear and generate frequent itemset The frequent patterns generated at the process require to scan data sets several times and produce many candidates This will greatly reduce the efficiency of algorithms In view of Apriori algorithm shortcoming, J. Han et al proposed a new FP-growth algorithm with the data structure of the tree without candidate generation [3 Although the experimental analysis shows that FP-growth algorithm is faster than improved Apriori algorithm 3],the data structure of FP-tree and looking for 


conditional pattern base require a lot of time. This will affect the efficiency of FP-growth algorithm. Since then although there are some improved algorithms [4, 5], these ones have not changed basic idea on FP-growth algorithm This paper puts forward to a new algorithm: using matrix data structure to preserve transactional data and eliminating and divided into sub-matrix to matrix with simply counting rows and columns, thus, finding out maximal frequent itemset. In this way, it can greatly simplify complexity and enhance the efficiency II. THE BASIC CONCEPTS A. Frequent itemset and maximal frequent itemset Let I = \(I1, I2, ... ,Im number of items. Let D, the task-relevant data, be a set of database transactions where each transaction T is a set of items such that T?I. Each transaction is associated with an identifier, called TID. Let A be a set of items. A transaction T is said to contain A if and only if A?T. A set of items is referred to as an itemset. An itemset that contains k items is a k-itemset. Itemset A in the transaction database D appearing in D, the total number of accounts for the percentage of affairs, called the itemset support. The occurrence frequency of an itemset is the number of transactions that contain the itemset. This is also known, simply, as the frequency, support count, or count of the itemset. The itemset support is sometimes referred to as relative support, whereas the occurrence frequency is called the absolute support Definition 1 \(Frequent Itemset of an itemset I satisfies a prespecified minimum support threshold \(i.e., the absolute support of I satisfies the corresponding minimum support count threshold is a frequent itemset. The set of frequent k-itemset is commonly denoted by Lk. Mining frequent itemset is in transaction database to identify all frequent itemset and their actual support Definition 2 \(maximal frequent itemset itemset L supersets of all of them are non-frequent itemset, then called L for the maximal frequent itemset, or maximal frequent patterns, recorded as MFI \(Maximal Frequent Itemset B.Associated matrix data structure 


Different data structure will affect the description of the problem and the efficiency of mining algorithm. Here using the data structure of associated matrix to save the transaction database D. The structure of associated matrix is as follows: a row vector expresses a transaction in the transaction database D. If there are total of M different items in the transaction database D, a row vector is the length of M. If the first i item in the transaction emerges the place of the first i sets to 1, otherwise to 0. For an example, there is abcdef of six items, a current transaction for the ace, and then the current row vector is \(101010 is as shown in table 1 TABLE I.  ACE ROW VECTOR a b c d e f 1 0 1 0 1 0 Let there are M different items in all transactions and N transactions, the associated matrix is an N rows and M columns matrix. The structural matrix that the different transaction under the same item sets to the same column is convenience to find frequent itemset. At the same time 1419 2 using "1" and " 0 "to express a certain item in a transaction appears or not, so that the maximal frequent itemset can be identified through the counting method of the row and column C.The numerical nature of rows and columns in associated matrix The columns and rows on the associate matrix can be counted. Counting the number of 1 on the columns of matrix gets P1, P2, , Pm \(m for the total number of items gets Q1, Q2, , Qn \(n is the number of total transactions The value of Pi and Qi contains important information related with frequent itemset, thus maximal frequent itemset can found out with calculating Pi and Qi. The following defines Pi and Qi and discusses their nature Definition 3 \(one-itemset support Pi number of 1 on the ith column of associated matrix is called as one-itemset support or as the greatest possible support of one item In fact ? it is actual support when the minimum 


support threshold equals to 1. When the minimum support threshold min_s ? 1, it is not the actual support threshold So it is called as possible support. Pi reflected the relationship between all transactions on an item. Through calculating Pi the associated matrix can be simplified and the important columns can be selected out in advance In the matrix, each column represents one item, and then the number of column is on behalf of the number of items. The number of column is related with the length of maximal frequent itemset. So the number of column is a certain sense. When they meet certain conditions for each column, the number of column is the length of maximal frequent itemset Definition 4 \(one-transaction frequent itemset Qi Qi counting the number of 1 on the ith row of associated matrix is called as one-transaction frequent itemset. Qi reflected the relationship between all items on a transaction. Through calculating Qi the associated matrix can be simplified and the important rows can be selected out in advance Since the algorithm is to find maximal frequent itemset, thus the size of Qi is on behalf of the importance of this row creating the maximal frequent itemset. The larger is Qi, the larger is the possibility of that this row create maximal frequent itemset. So we may use the largest Qi to divide matrix or chose rows In the matrix, each row is on behalf of a transaction then, the number of row is on behalf of the number of transaction. It is related with minimum support According to the definition of minimum support, we can see that the minimum support threshold can be used to help determine the number of rows to choose III. ALGORITHM DESIGN A. Algorithm description The counting algorithm has the following eight steps Step 1: Setting up an associated matrix. Scanning transaction database D once sets up an associated matrix setting 0 or 1 of row vector in accordance with a given order for each transaction Step 2: Calculating all one-itemset support Pi and all one-transaction frequent itemset Qi. The one-itemset support can be gotten by counting the column value with 


1 and the one-transaction frequent itemsets Qi can be gotten by counting the row with 1 Step 3: Using elimination method to remove the rows and columns of the associated matrix according to following conditions There are four conditions The first condition: the one-itemset support Pi is less than the minimum support threshold. The ith column can be removed because not satisfying the minimum support threshold The second condition: the one-transaction frequent itemset Qi equals to 0 The third condition: the one-itemset support Pi equals to the number of the row The forth condition: one-transaction frequent itemset Qi equals to the number of the column The first two conditions can used to eliminate the columns and the rows of the non-frequent itemset If the rows and columns are met with the latter two conditions, the rows and columns can be selected out in advance in order to improve the efficiency of algorithm After the rows are selected out in advance, the standard eliminating columns will be changed. It should be one that minimum support threshold subtracts the number of rows selected out in advance. When the number of rows selected in advance is equal to the minimum support threshold, these rows make up the maximal frequent itemset The elimination method is as follows: First of all eliminating the columns which Pi is less than the minimum support threshold. Then, all Qi of rows are calculated. The rows which Qi is equal to 0 are eliminated. Repeat above process until the rows and columns can not be further eliminated In fact, step 3 is one simplifying associated matrix Step 4: Qi queue. Qi queue is by descending value of Qi. This step is to find the largest value of Qi Step 5: Divided into sub-matrixes. If the value of all Qi equals to the number of columns on the matrix, then stop otherwise, the matrix is divided into sub-matrixes The method is as follows At first, the first sub-matrix is divided out according to 


the largest Qi. This sub-matrix is composed of the corresponding rows with the 1 on the columns of Qi Then, continuing division from remaining sub-matrix Similarly, in the left sub-matrix, all Qi is calculated according to the largest Qi, until all the rows and columns are covered 1420 3 If there exists across the rows on a division, the columns of these rows with 1 form a new sub-matrix If there is more than the largest Qi, the Qi selected is one of Qi from top to bottom. The method is selecting the rows that at least one of their columns includes ones in the row of the largest Qi When divided into sub-matrixes, it is important that the union set of rows and columns in all sub-matrixes shall include rows and columns in the original matrix Note: the itemset of sub-matrixes after intersection operation must be empty. Otherwise, the intersection of the rows is divided into a new sub-matrix The following is an example of division of matrix. The initial matrix is as shown in table 2. Three sub-matrixes after the division are as shown in table 3, 4 and 5. Table 5 is the new sub-matrix composed by the intersection of the rows TABLE II.  INITIAL MATRIX I1 I2 I3 I4 I5 I6 1 1 1    3 1 1 1 3 1 1     2 1 1  2 1   1 2 2 2 2 2 2 2 TABLE III.  SUB- MATRIX 1 I1 I2 I3 1 1 1 3 1 1  2 1 1 2 2 2 TABLE IV.  SUB-MATRIX2 TABLE V.  SUB-MATRIX3  


        Step 6: Using elimination method in step 3 to the submatrixes and Qi queue  by decreasing order until no new sub-matrix can be divided out Step 7: Selecting the combination of rows in the submatrixes According to the minimum support threshold and rows and columns selected in advance in step 3, the number of row which Qi is more than minimum support threshold will be selected out. Selected rows will be combined. The number of possible combinations is r nC : n is the number of rows selected; r is the minimum support threshold Because there are rows or columns selected in advance in step 3, it is necessary to take into account this factor There are four cases discussed The case 1: there is no selected rows and columns in advance Because no selected rows and columns in advance, this case can be dealt with according to normal conditions The case 2: there is rows selected in advance Because there are the rows selected in advance, the number of rows to be selected can be reduced. The number of possible combinations is r t n tC  t is the number of rows selected in advance. In this way, computation can be reduced to improve the algorithm efficiency The case 3: there is columns selected in advance Because there are the columns selected in advance these columns become the part of the maximal frequent itemset. These columns do not change the method. In the 


end, these columns are only added to maximal frequent itemset selected The case 4: there are selected rows and columns in advance The case 4 is the combination of the case 2 and the case 3 According to the case 2, we can use the way to reduce the number of rows. By the case 3, we can use the way to add the columns selected in advance to the maximal frequent itemset, together with the composition of maximal frequent itemset Step 8: Searching for maximal frequent itemset. In accordance with the selected combination of rows, all of one-itemset supports Pi are computed out. The maximal frequent itemset is composed of itemset which the oneitemset supports Pi equals to minimum support threshold The number of the items in the itemset is the maximal frequent itemset length I4 I5 I6 1 1 1 3 1 1  2 1 1 2 2 2 I3 I6 1  1 1 1 1 1 2 2 2 1421 4 B.an example To explain the use of the above algorithm, the following will illustrate an example Transaction database D is as shown in table 6. Let minimum support threshold be min_s = 2 TABLE VI.  TRANSACTION DATABASE D       


     Step 1: Setting up an associated matrix. It is as shown in table 7 TABLE VII.  ASSOCIATED MATRIX             Step 2: Calculating the one-itemset support Pi and one-transaction frequent itemset Qj. All Pi are \(6,7,6,1,2 All Qj are  \(3,1,2,3,2,2,2,4,3 Step 3: Using elimination method to remove the rows and columns of the associated matrix according to certain conditions. Here are items for the I4 column and transaction for T800 row to be eliminated. The I4 column is eliminated by the first condition. The T800 row is eliminated by the forth condition. All Pi are \(5,6,5,1 Qj are \(3,1,2,2,2,2,2,3 is as shown in table 8 TABLE VIII.  COMPRESSED ASSOCIATION MATRIX TID I1 I2 I3 I5 T100 1 1  1 3 T200  1   1 T300  1 1  2 T400 1 1   2 T500 1  1  2 T600  1 1  2 T700 1  1  2 T900 1 1 1  3 5 6 5 1 


Step 4: Qi queue Step 5: Divided into sub-matrix. According to the first row, the matrix can divided into the two sub-matrixes They are as shown in table 9 and 10 TABLE IX.  FIRST SUB-MATRIX            TABLE X.  SECOND SUB-MATRIX         Step 6: Using elimination method to the sub-matrixes and Qi queue by descending order From table 8, T100 row may be eliminated by forth condition. It is as shown in table 11 TABLE XI.   FIRST SUB-MATRIX           As the two rows have been elected, and to meet the minimum support threshold, and therefore, Table 8 Sub 


Matrix task has been finished From table 10, T900 row may be eliminated by forth condition. It is as shown in table 12 TABLE XII.  SECOND SUB-MATRIX        TID Commodity ID T100 I1,I2,I5 T200 I2 T300 I2,I3 T400 I1,I2,I4 T500 I1,I3 T600 I2,I3 T700 I1,I3 T800 I1,I2,I3,I5 T900 I1,I2,I3 TID I1 I2 I3 I4 I5 T100 1 1   1 T200  1 T300  1 1 T400 1 1  1 T500 1  1 T600  1 1 T700 1  1 T800 1 1 1  1 T900 1 1 1 6 7 6 1 2 TID I1 I2 I5 T100 1 1 1 3 T200  1  1 T300  1  1 T400 1 1  2 T500 1   1 T600  1  1 T700 1   1 T900 1 1  2 5 6 1 


TID I1 I2 I3 T300  1 1 2 T500 1  1 2 T600  1 1 2 T700 1  1 2 T900 1 1 1 3 3 3 5 TID I1 I2 I5 T200  1  1 T300  1  1 T400 1 1  2 T500 1   1 T600  1  1 T700 1   1 T900 1 1  2 4 5 0 TID I1 I2 I3 T300  1 1 2 T500 1  1 2 T600  1 1 2 T700 1  1 2 2 2 4 1422 5 As the two rows have been elected, and to meet the minimum support threshold, and therefore, Table 9 SubMatrix task has been finished Step 7: Selecting the combination of rows Two rows of T100 and T800 make up new sub-matrix to search for maximal frequent itemset. It is as shown in table 13 TABLE XIII.  THE COMBINATION OF T100 AND T800 Two rows of T800 and T900 make up new sub-matrix to search for maximal frequent itemset. It is as shown in table 14 TABLE XIV.  THE COMBINATION OF T800 AND T900      Step 8: Searching for maximal frequent itemset 


The first maximal frequent itemset is \(I1,I2,I5 Table 12 The second maximal frequent itemset is \(I1,I2,I3 Table 14 IV. ALGORITHM PERFORMANCE COMPARISON All the experiments are performed on a AMD Athlon 64*2 Dual core processor 3800+ PC machine with 1G main memory, running on Microsoft Windows XP. All the programs are written in Microsoft Visual C++6.0 Experimental data is generated randomly by programming. And the number of items is 39 Experiment result shows that the efficiency of the counting algorithm is higher in comparison with Apriori algorithm and FP-tree algorithm. It is as shown in Figure 1               Figure 1.  Relationship of the support threshold with time consumption V. CONCLUSION The core of association mining is mining frequent itemset. Directly searching for maximal frequent itemset can increase efficiency of association mining algorithm This paper presents a new mining algorithm looking for Maximal Frequent Itemset. The algorithm with simply counting the value of rows and columns on associated matrix can find out the maximal frequent itemset and greatly simplifies the complexity of association mining algorithm. Analysis and experiments show that this algorithm has obvious advantages ACKNOWLEDGEMENTS 


The paper is supported by the Special Funds for Key Program of the China No. 2009ZX01039-002-001-04 2009ZX03001-016, 2009ZX03004-005  REFERENCES 1] R Agrawal. Mining Association Rules Between Sets of Items in Large Databases[ C] .Washington :Proceedings of the ACM SIGMOD International Conference Management of Data,1993 :207- 216 2] Agrawal R, Srikant R. Fast algorithms for mining association rules in large databases [A].Proc. of the 20th Intl Conf on Very Large Data Bases [C]. Santiago: Morgan Kaufmann, 1994:478~499 3] J. Han, M. Kambr. Data Mining Concepts and Techniques M] .Morgan Kaufmann Publishers, 2000 4] Y.Yan, Z.Lee, H.Chen. A Mining Maximal Frequent Itemsets in Depth-First algorithm [J]. Computer Research and Development, 2005, 42\(3 5] Z.Wu, W.Lee, P.He. Based on the matrix of maximal frequent pattern mining and its update algorithm [J Microelectronics and computer, 2007, 24\(12 6] Z.Xu,S. Zhang. Mining Association Rules in an optimized Apriori algorithm [J] Computer Engineering.2003 29\(19 7] G. Grahne, J.Zhu, Efficiently using prefix-trees in mining frequent itemsets. In Proc. ICDM03 Int. Workshop on Frequent Itemsets Mining Implementations \(FIMI03 Melbourne, FL, Nov. 2003     I1 I2 I3 I5 T100 1 1  1 T800 1 1 1 1 2 2 1 2 I1 I2 I3 I5 T800 1 1 1 1 T900 1 1 1 2 2 2 1 0 0.5 


1 1.5 2 2.5 3 3.5 4 0.15 0.16 0.17 Support threshold Runtime\(Seconds Apriori FP-tree Counting 


studies," Bioinformatics, vol. 26, pp. 30-37, Jan 1 2010  11] Noah A. Rosenberg, Jonathan K. Pritchard, James L Weber, Howard M. Cann, Kenneth K. Kidd, Lev A Zhivotovsky, Marcus W. Feldman, "Genetic structure of human populations," Science, vol. 298, pp. 2381-5, Dec 20 2002  12] C Ridruechai, S Mahasirimongkol, J Phromjai, H Yanai N Nishida, I Matsushita, J Ohashi, N Yamada, S Moolphate S Summanapan, C Chuchottaworn, W Manosuthi, P Kantipong, S Kanitvittaya, P Sawanpanyalert, N Keicho, S Khusmith and K Tokunaga, "Association analysis of susceptibility candidate region on chromosome 5q31 for tuberculosis," Genes and Immunity, 2010 323 


REFERENCES 1] R. Agrawal, T. Imielinski, and A. Swami, Mining association rules between sets of items in large databases, in SIGMOD 1993 2] C. Alexander, Market Models: A Guide to Financial Data Analysis. John Wiley & Sons, 2001 3] W. Kuo, T.-K. Jensen, A. Butte, L. Ohno-Machado and I. Kohane, Analysis of matched mrna measurements from two different microarray technologies Bioinformatics, vol. 18, p. 405C412, 2002 4] H. Xiong, X. He, C. Ding, Y. Zhang, V. Kumar, and S. Holbrook, Identi?cation of functional modules in protein complexes via hyperclique pattern discovery in PSB, 2005 5] J. Han, H. Cheng, D. Xin, and X. Yan, Frequent pattern mining: Current status and future directions DMKD, vol. 15, no. 1, pp. 5586, 2007 6] P.-N. Tan, M. Steinbach, and V. Kumar, Introduction to Data Mining. Addison-Wesley, 2005 7] S. Brin, R. Motwani, and C. Silverstein, Beyond market basket: generalizing association rules to correlations, in SIGMOD 1997, Tucson, AZ, 1997, pp 265276 8] E. Omiecinski, Alternative interestmeasures formining associations, TKDE, vol. 15, pp. 5769, 2003 9] H. Xiong, S. Shekhar, P.-N. Tan, and V. Kumar Exploiting a support-based upper bound of pearsons correlation coef?cient for ef?ciently identifying strongly correlated pairs, in KDD 2004, 2004, pp 334343 10] I. Ilyas, V. Markl, P. Haas, P. Brown, and A. Aboulnaga, Cords: Automatic discovery of correlations and soft functional dependencies, in SIGMOD 2004 2004, pp. 647658 11] J. Zhang and J. Feigenbaum, Finding highly correlated pairs ef?ciently with powerful pruning, in CIKM 2006, 2006, pp. 152161 12] H. Xiong, W. Zhou, M. Brodie, and S. Ma, Top-k correlation computation, JOC, vol. 20, no. 4, pp 539552, 2008 13] S. Zhu, J. Wu, and G. Xia, Top-k cosine similarity interesting pairs search, in 


http://datamining.buaa.edu.cn/TopKCos.pdf 14] M. Zaki, Scalable algorithms for association mining, TKDE, vol. 12, pp. 372390, 2000 


enhance item-based collaborative filtering, in 2nd IASTED International Conference on Information and Knowledge Sharing, Scottsdale, Arizona, 2003 476 2010 10th International Conference on Intelligent Systems Design and Applications 


Basi Association Rles Basi c  Association R u les Association is basically connecting or tying up occurrences of Association is basically connecting or tying up occurrences of events Ol dib t f ilt t O n l y d escr ib e se t s o f s i mu lt aneous even t s Cannot describe patterns that iterate over time e g  itemset a  0  b  0  g    Eg If you sense higher data rates on the downlink than normal AND New Route generated Implies high chances of Intrusion AND New Route generated Implies high chances of Intrusion Associative IDS for NextGen Frameworks Dr S Dua LA Tech 20 


Enhanced Inte r transaction Association Rules Enhanced Inter transaction Association Rules Enhanced Inter transaction Association Rules Extension of association rules Conditional relationships at multiple different time steps e.g itemset a\(0 0 1 2 You sense Higher data rate than normal AND You see New Route g enerated AND 1 minute a g o you detected checksum gg error packets AND 2 minutes ago your encountered wrong checksum   Implies High Chance of Intrusion Enhanced Rules and Confidence Associative IDS for NextGen Frameworks Dr S Dua LA Tech 21 


Complex Spatio temporal Association Complex Spatio temporal Association Rules Further extension of inter transaction association rules Describe event durations e.g itemset a\(0,X j,Y k,Z Eg  You sense high data rates for X seconds AND new route generated j minutes ago task completed in Y AND new route generated j minutes ago task completed in Y seconds AND checksum error packets received k minutes ago for Z seconds High Chance of Intrusion With highest confidence level in association rules  association rules  Associative IDS for NextGen Frameworks Dr S Dua LA Tech 22 


DMITAR Al ith ARD DMITAR Al gor ith m  ARD Problem Domain Problem Statement and Challenges Aiti Miig bd IDS A ssoc i a ti ve Mi n i n g b ase d IDS  Introduction to data mining Association rule in data mining DMITAR Algorithm  ARD New research Associative IDS for NextGen Frameworks Dr S Dua LA Tech 23 


DMITAR Algorithm DMITAR Difference Matrix Based Inter Transaction Association Rule Miner developed in DMRL Uses vertical data format Differences of the transaction IDs are used to generate extended itemsets Windowless mechanism Associative IDS for NextGen Frameworks Dr S Dua LA Tech 24 


Deep into the Mechanism The DMITAR algorithm is based on lhilii comp l ex mat h emat i ca l assoc i at i ve formulation and proofs Four major parts Four major parts Frequent 1 itemset generation Frequent 2 itemset generation Frequent k itemset generation k>2 Spatio temporal rule formation Associative IDS for NextGen Frameworks Dr S Dua LA Tech 25 


DMITAR, Datasets Used Stock Data Stock Data Daily stock information provided by Yahoo finance Wth Dt W ea th er D a t a Provided by the US Department of Commerce and National Climactic Data Center for 700 locations across US Synthetic Data Provided by a CRU weather generator that uses a Markov chain model to generate simulated weather data for 11 UK sites Associative IDS for NextGen Frameworks Dr S Dua LA Tech 26 


DMITAR Results 1/5 Varying Support DMITAR Results 1/5 Stock Database Support FITI ITPMine PROWL DMITAR 14 6424.7s 132.39s 3.03s 5.556s 16 2348.9s 67.14s 2.14s 4.015s 18 861.92s 34.62s 1.55s 2.89s 20 334.51s 18.89s 1.12s 2.07s 22 143 84s 10 87s 0 87s 1 45s 22 143  84s 10  87s 0  87s 1  45s 24 63.62s 7.15s 0.671s 1.04s Weather Database Support FITI ITPMine PROWL DMITAR 14 36362.6s 893.1094s 5.843s 19.8281s 36362.6s 893.1094s 5.843s 19.8281s 16 11913.04s 378.2188s 3.8906s 13.4375s 18 4116s 170.3438s 2.75s 9.1406s 20 1507s 86.5781s 2.14s 6.203s 22 859.2813s 63.3438s 1.7969s 5.7656s 24 378.5313s 36.1875s 1.4375s 3.5625s Synthetic Dataset Support FITI ITPMine PROWL DMITAR 14 1651.6s 199.843s 3.1406s 17.015s 16 574 32 119 32 2 0938 10 875 16 574  32 s 119  32 s 2  0938 s 10  875 s 18 416.109s 95.31s 1.6094s 7.39s 20 370.25s 83.31s 1.453s 5.8438s 22 265.78s 66.3438s 1.3594s 4.75s 24 133.96s 43.0781s 0.9219s 3.5781s 


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



An effective algorithm for mining association rules based on Imperialist Competitive Algorithm   Fariba Khademolghorani Department of Computer Engineering  Islamic Azad University, Najafabad Branch Isfahan, Iran Fariba.Khadem@sco.iaun.ac.ir   Abstract—Association rule mining is one of the most applicable techniques in data mining, which includes two stages. The first is to find the frequent itemsets; the second is to use them to generate association rules. A lot of algorithms have been introduced for discovering these rules. Most of the previous algorithms mine occurrence rules, which are not interesting and readable for the 
users. In this paper, we propose a new efficient algorithm for exploring high-quality association rules by improving the imperialist competitive algorithm. The proposed method mine interesting and understandable association rules without  relying upon the minimum support and the minimum confidence thresholds in only single run. The algorithm is evaluated with several experiments, and the results indicate the efficiency of our method Association Rules  Imperialist Competitive Algorithm  Evolutionary Algorithm   I   I NTRODUCTION  Association rule \(AR\ining is one of the most important tasks in data mining and indicates the relationships 
between attributes of records in ally A R s are shown in the form of A=>C in which A is antecedent itemsets of the rule and C is consequent itemset of the rule Two measures of support and confidence are introduced for evaluating ARs. These are calculated from \(1\d \(2 equations, respectively      TotalRcord C A C A Support          1           A SUP C A SUP C A Confidence     2  So far, many algorithms proposed for discovering ARs 
are based on Agrawal, Aprior S E T M  7 AI S  1 DI C  4  a n d  o t h e r m e t hod s  Ho w e v e r t h e s e al gor i t h m s ha ve t h e i r limitations. They have to mine ARs in two stages separately In these methods, rules with high occurrence in database are considered as the best rules, whereas most of these rules can easily be predicted by the users. Therefore, they are not interesting. Also, they mine occurrence rules with a large number of attributes, which are not understandable for the user. Hence, the user will never use them. In these methods two parameters, minimum support and minimum confidence 
thresholds, are always determined by the decision-maker or through trial-and-error; and hence, these algorithms lack both objectiveness and efficiency [7  In recent years, in addition to common methods, some evolutionary algorithms have been used with multi-objective functions. Evolutionary algorithms such as genetic, ant colony, simulated annealing and particle swarm optimization have been used for mining ARs The idea of using genetic algorithm for extracting frequent itmesets has been applied 8 n   11 h a s be e n e x tr ac te d ARs b a s e d o n t h e g e ne t i c algorithm. In a m e t hod  o f e xpl or i ng fre q u e n t i t e m se t s  has been proposed by combining PSO with Ant algorithm 
But it can discover only frequent itemsets such as the GAR algorithm in [8   In  9  sim u late d an n e alin g alg o r ith m h a s been used to develop a multi-objective rule mining method But there is no study this uses imperialist competitive algorithm \(ICA f o r m i ni ng A R s I n t h i s pap e r  w e  proposed an effective algorithm based on the ICA algorithm for discovering the best rules according to predetermined objectives. This method not requires to appointment minimum support and the minimum confidence. Also, it extracts ARs in once executed while previous methods mine ARs in two stages The rest of this paper is organized as follows. Section II 
briefly introduces the imperialist competitive algorithm Section III describes the proposed algorithms in detail, then the experiments and analyzing the results will be discussed in Section IV. Finally, conclusion and future works will be presented in Section V II  I MPERIALIST C OMPETITIVE A LGORITHM ICA Imperialist competitive algorithm is a socio-politically motivated global search strategy that has recently been introduced for solving different optimization problem ICA starts with an initial population. Each individual of the population is called a country in which some having the least cost are establish as imperialist and rest form the colonies of these imperialists. The division of all the 
colonies of initial countries is based upon the power of the imperialist. The colonies in each of the empire start moving towards their imperialist, based on assimilation policy. The total power of an empire is defined by the imperialist’s power and percentage of the colonies’ power. Then the imperialist competition begins. All empires try to take the colonies of other empires under their control. The imperialistic competition will gradually result in an increase in the power of powerful empires and a decrease in the power of weaker empires. This results in the collapse of weak empires. Fig. 1 shows a general schema of this part of the process 978-1-4577-1539-6/11/$26.00 ©2011 IEEE 6 


 Figure 1  The more powerful an empire is, the more likely it will possess the weakest colony of the weakest empi   Finally, these processes will successfully cause all the countries to converge to a situ ation in which there exist only one empire in the world and all the other countries are colonies of that empire and they have the same position and power as the imperialist III  MINICA ALGORITHM  In this work, imperialist competitive algorithm which is one of the new evolutionary algorithms is applied to explore interesting association rules from transactional databases This evolutionary algorithm which has been introduced as a method based on minimum value-finding, in this paper with minimal changes, was changed into a searcher of maximum value  Figure 2  MINICA algorithm The following of this section are some important parts of the proposed algorithm in this paper, which are explained countries encoding, assimilation policy and deviational behaviors, fitness function, and finally the last part of the section explains the pseudo-code of the algorithm proposed in this study which we called MINICA. Also, Fig. 2 shows the pseudo-code of this algorithm A  countries encoding In this paper, each country represents a rule and each rule contains of a series of decision variables which represent the status of every item in the rule According to Fig. 3 in the proposed algorithm, every country has n decision variables in lieu of n items in any dataset   Figure 3  Countries encoding This means that the i th  variable which is known as ES i  indicates the status of i th  item and can take values between 0 and 1. In this way, if 0.00  ES i  0.33, the i th  attribute is in the antecedent of the rule and if 0.33 ES i 0.66, this attribute is in the consequence of the rule and if 0.66 ES i 1 it means the lack of i th  attribute in the rule  B  Modeling the assimilation policy and the deviational behaviors Moving colonies toward the relevant imperialist is motivation of the assimilation policy. This means that one of the weaker individual s can move toward the better individual This causes the colonies to be like the relevant imperialist In the proposed method for modeling the assimilation policy for mining ARs problem, randomly some attributes of each imperialist is copied in to relevant colonies that is explained in Fig. 4 For each selected attributes in the imperialist if it has been in the antecedence part of the rule, now it must b e created a real random number between 0 and 0.33 for the same attribute in the colony Then, this random number is replacement in to related attribute value  Figure 4  Assimilation policy  7 


Similarly, if selected attributes in the imperialist has been in the consequence part of the rule, now it must be created a real random number between 0.33 and 0.66 for the same attribute in the colony and if it has not been in the rule now it must be created a real random number between 0.66 and 1 for the same attribute in the colony Moreover, the imperialist were seriously following the assimilation policy, the events didn’t happen according to their policy. Here, some colonies of an empire have deviated. We model colony deviation in the following manner: for each colony of an empire, a real random number is created. If the colony has the probability of being selected, the position of some attributes in the rule is changed, which has a great effect on the support, confidence and fitness value of that rule. This is done with the aim of moving the position of empires colonies to the global optimized solution. It should be noticed that in all procedures of the algorithm, after any changes in the dimensions of any individual in the population, its rule validity will be measured. That rule which has at least one attribute in the antecedent of the rule and one in the consequence of the rule is valid C  Fitness function The fitness function provided in this study is in \(3   M axField i d NumberFiel D C A Sup C Sup C A Sup A Sup C A Sup i fit        1              2 1          3  Since the mining association rule is a task that extracts some hidden information, it must discover those rules that have a comparatively less occurrence in the entire database which are more interesting for the users; discovering such rules is more difficult. For classification rules, measure like information gain, can be useful. But it is not efficient for evaluating the ARs. Therefore, interestingness measure in  is u s ed in th e f itn es s  f u n ction accordin g to th e f i rs t parameter. In this parameter |D| is the total number of records in the database. This relation has three parts Sup\(A  C\p\(A dicates th e probability  of creatin g  th e rule depending on the antecedent part; [Sup\(A  C\/Sup\(C shows the probability of creating rule depending on the antecedent part. In fact most of these are interesting rules in which the rate of acquired information is approximately the same in both antecedent and consequent parts of the rule. In this parameter the support count of the rule antecedent and the support count of the rule consequent are used. In the third part of this parameter, those rules which have a very high support count and high frequency will be less interesting, because such rules are easily predictable by the users The second parameter is used for number of attributes in rule and it rewards the shorter rules with a smaller number of attributes Numberfield\(i returns the number of attributes that exist in country i  This term is to lead to shorter rules. In result, readability and comprehensibility of rules that are im portant in data mining are increased. Larger rules are more likely to contain redundant information It should be noted that  1 and  2 will be specified by the percent of user interests and one might increase or decrease the effects of parameters of the fitness function. It means that they do not need to assign for each database in spite of some thresholds such as minimum support and minimum confidence  D  Description of MINICA algorithm As it was shown in Fig. 2, the algorithm is run as times as MaxRun Moreover, each run includes a number of generations. At the beginning of the algorithm, the DiscoveredBestRules set is empty. At the first iteration of algorithm, each country is initialized randomly as a rule Then, it selects nIMP of the best countries as imperialists. In such a way, the initial empires are created. The colonies in each of the empire start to move toward their imperialist based on assimilation policy. But some colonies show behaviors contrary to what the imperialist has expected according to section III part B. Then, if the fitness of an empire’s best colony is more than its imperialist, their positions will be exchanged by ExchangePosition function. Then, the empire, with the most likelihood gives the weakest colony of the weakest empires If an empire loses all of its colonies, it will collapse and its imperialist will, as a colony, be allocated to the winner empire in the previous step. In such a way, collapse mechanism is done. If the number of empires in a generation becomes 1, the algorithm will be stopped and this procedure will be repeated according to the MaxGen threshold IV  I MPLEMENTATION AND EXPERIMENTAL RESULTS  MINICA algorithm was implemented and executed on a PC with Intel Dual-Core 2.1 GHz operator on a 2GB Ram The setting of the used parameters is shown in Table I Weighted coefficients  1 and   2 that have been used in fitness function were  selected as 2 and 0.2, respectively. Be reminded these coefficients are specified  by the percent of user interests Hence they do not need to re-initialize for each database TABLE I  U SED PARAMETER VALUES FOR MINICA  Our method was executed and evaluated on four real datasets: Balance scale, Nursery, Car Evaluation, BasketMarket. For doing examinations we used the basket-market dataset existing in Clementine 12.0 tool [10 an d th ree  datasets in UCI at http://www.ics.uci.edu/~mlearn. The specifications of datasets used are given in Table II. All attributes in datasets are categorical except Basket-Market 8 


dataset; therefore we converted them into the Boolean datasets. It means that every attribute with any amount is considered as an item The specifications of datasets used from UCI TABLE II  T HE SPECIFICATIONS OF DATASETS    The basket-market dataset includes 11 binary attributes and it has the least attributes in this work.  Nursery dataset has the most records over than 10000 examples and also, it has the more attributes than the rest of the dataset. Fig. 5 shows a demonstration of the results gained in from our own tool on the basket-market dataset  Figure 5  A demonstration of the results of performing MINICA on the basket-market dataset  In the proposed method, we generalized the ICA for mining ARs problem. According to the section III part B we extended the modeling of the assimilation policy and the deviational behavior of colonies in the ICA for this purpose Figures 6 and 7 illustrate the MINICA convergence on two of the datasets. This experiment was done with 50 replications. So, we calculated the average of the results. In these figures, the lines show the fitness of the best imperialist lines show the fitness average of all imperialist and lines show the fitness of the worst imperialists in each generation. As it is seen, the proposed method has well performance with least error. Also the difference between the best and worst fitness average in figures is appropriate  Figure 6  Convergence of the algorithm on the Car Evaluation dataset  Figure 7  Convergence of the algorithm on the Nursery dataset The next experiments are evaluating the efficiency and usefulness of the algorithm provided in this study Therefore, we compare it with the method of mining association rules based on the genetic algorithm in TABLE III  U SED PARAMETER VALUES FOR GENETIC ALGORITHM IN 5    The initial setting of this algorithm’s parameters is given in Table III  Figure 8  Convergence rate on the Car Evaluation dataset 9 


Figures 8 and 9 depict the convergence of the MINICA algorithm in compared with the proposed algorithm in A cording to these figures, the proposed algorithm based on the ICA has better performance with least error with respect to the algorithm based on the GA for mining ARs problem Also, it able to reaches the optimal solution and it converges faster. But it has more computations. In the ICA, individuals have more interacted with each other and thus the algorithm is more likely to discover global solution  Figure 9  Convergence rate on the Nursery dataset The last test results in this paper have shown in Table IV, which is about the comparison of mean results obtained from MINICA and the genetic algorithm proposed in  with our fitness function The mean number of best different mined rule, the mean number of attributes contained in the rules and the mean of the support, confidence and cosine value of these rules are shown in this table. The cosine measure can be used for evaluating the interestingness of the ARs  According to this table, the proposed algorithm which is based on the imperialist competitive algorithm has better results compared to the association rules mining method in  A dis c ov ered ru le s  w ith appropriate s u pport an d  confidence value compared to proposed method based on GA. In addition the user’s comprehension of these rules and the rules interestingness for the user are acceptable; also the number of attributes obtained from this method is smaller As mentioned, larger rules are more likely to contain redundant information The results of all experiments in this work means that the algorithm of mining association rules based on the ICA is more capable of discovering global solution s in comparison with the mining ARs based on the genetic algorithm  V  C ONCLUSION AND FUTURE WORKS  In this paper, an effective algorithm based on ICA has been proposed to explore interesting and readable ARs that called MINICA. We improved modeling the assimilation policy and the deviational behaviors in ICA for problem of mining ARs. Then we have carried out several tests to evaluate our method behavior in different real datasets The results show the appropriate success of this method in comparison with the method of mining rules by the use of the genetic algorithm. Also, our method is more capable of discovering global solutions Contrary to the techniques used as usual, comprehensible and interesting ARs have directly been mined without generating frequent itemsets and without relying upon the minimum support and the minimum confidence thresholds which are hard to determine for each database Moreover this method is very flexible on changing fitness function, so user can define any normal objective in fitness function with support confidence and etc and obtains his/her interesting rules  The proposed method can able to mine ARs from transactional datasets. So, generalization of the MINICA algorithm is suggested for mining numerical and categorical rules as a future works. Moreover considering that only positive rules discovered in this method discovering both positive and negative rules is suggested  TABLE IV  C OMPARISONS OF THE RESULTS WITH THE PROPOSED METHOD IN 5   10 


R EFERENCES  1  R. Agrawal, T. Imielinski, and A. Swami, “Mining association rules between sets of items in large databases” in: Proceedings of ACM SIGMOD Conference on Management of Data, Washington, Vol. 22 No. 2, 1993, pp. 207–216 2  E Atashpaz-Gargari, and C. Lucas, “Imperialist Competitive Algorithm An Algorithm for Optimization Inspired by Imperialistic Competition”, IEEE Cogress on Evolutionary Compution, Singapore Jun 2007, pp.4661-4667 3  O. M. Badawy, M. I. Habib, and A. A. Sallam, "Quantitative Association Rule Mining Using a Hybrid PSO/ACO Algorithm PSO/ACO-AR\", ACIT'2008, Hammamet, Tunisia, Dec 2008, pp.1-9 4  S. Brin and R. Motwani and J.D. Ullman and S. Tsur, “Dynamic itemset counting and implication rules for market basket data,” Proc of ACM SIGMOD International Conf. on Management of Data Tucson, Vol. 26, No. 2, Jun 1997, pp. 255 – 264 5  A. Ghosh, and B. Nath, “Muti Objective Association Rule Mining Using Genetic Algorithm”, Elsevier Information Sciences, Vol. 163 No. 1, 2004, pp.123–133   6  J. Han, and M. Kamber, “Data Mining: Concepts and Techniques”\(2nd ed.\, Elsevier,  2006 7  M. Houtsma, and A. Swami, “Set-oriented mining of association rules”, Research Report RJ 9567, IBM Almaden Reseach Center 1993 8  J. Mata J.L. Alvarez, and J.C. Riquelme, “An evolutionary algorithm to discover numeric association rules” ,In Proceedings of the ACM symposium on Applied computing SAC, 2002, pp. 590–594 9  M.Nasiri, L.Taghavi, and B.Minaei, “Multi-Objective Rule Mining using Simulated Annealing Algorithm”, Soft Computing, JCDA journal Korea, Vol. 5, No. 1, Feb 2010, pp.60-68     SPSSInc. “Clementine 12.0 Algorithms Guide”. http://www.spss.com   X.Yan, CH. Zhang, and SH. Zhang, “Genetic algorithm-based strategy for identifying association rules without specifying actual minimum support”, Elsevier Expert Systems with Applications, Vol 36, No. 2, 2008, pp.3066-3076   11 


c\(k The distinguished feature of GNP is reusability of nodes based on the graph structure, so the nodes used in a certain transition can be shared with other node transitions. As a generation Rule pool extracted ?Ies are storJ in a rule pool generation+1 Fig. 3. Flow of rule extraction and evolution A'11 : LAND=1 A'12 : LAND=O A'21 : ProtocoUype=tcp A'22 : ProtocoUype=icmp A'23 : ProtocoUype=udp A'31 : Count>=threshold A'32 : Count<threshold Fig. 4. An Example of Sub-Attribute Utilization result, many kinds of association rules can be extracted by compact structures In addition, the extracted rules which satisfy the conditions of the measurements are stored in an association rule pool every generation. Therefore, as described before, the rule extraction of GNP is carried out throughout the generations in order to create the rule pool with sufficient rules. In other words, the aim of GNP is not to create the optimal individual which can extract good rules, but to extract many good rules by making use of all the individuals in all the generations and store the rules in the pool. Fig. 3 shows the whole procedure of the rule extraction and evolution C. Sub-Attribute Utilization There are various kinds of attributes in a network access database such as discrete and continuous attributes. So, these attributes need to be transformed in order for GNP to deal with them efficiently We use a sub-attribute utilization mechanism in order to keep the completeness of data information of binary, sym bolic and continuous attributes. Binary attributes are divided into two sub-attributes corresponding to judgment functions For example, the binary attribute AI\(=land Ail \(representing land= 1 representing land= 0 The symbolic attribute is divided into several sub-attributes 


Fig. 4 shows a division example of three kinds of attributes Normal access rule pool rule1 rule2 rule3 access data d  Class 2 Intrusion access rule pool rule1 rule2 rule3 calculate m1\(d average of all Match1\(d,r calculate m2\(d average of all Match2\(d,r r: a rule in a class Fig. 5. How to calculate average matching degrees Continuous attributes are divided into two sub-attributes \(the sub-attribute greater than or equal to a threshold and that smaller than the threshold deviation \(Ti of each continuous attribute Ai in the database are calculated to obtain the initial threshold Bi selected randomly from [J-li - \(Ti, J-li + \(Til. In addition, the initial threshold Bi is evolved by mutation every generation in order to find more association rules. The evolution of thresholds is controlled by an additional mutation probability which is set at 113 in this paper III. INTRUSION DETECTION WITH A MULTI-DIMENSIONAL PROBABILITY DISTRIBUTION A large number of rules of normal and intrusion accesses can be extracted from the training database [ 10] by the class association rule mining of GNP. Then, a classifier is built based on the extracted rules, which classifies new data into normal, known intrusion and unknown intrusion classes. The features of the proposed probabilistic classification are as follows. 1 built according to the matching degree of all the data with the rules of normal and intrusions. The matching degree of data with normal rules represents one dimension and that 


with intrusion rules represents the other dimension. 2 possible to classify data into the class which does not belong to either class. 3 by adjusting weights on the probabilities of belonging to each class A. Generating probability density function Before introducing the probability density function, the matching degree of data with a rule is defined as follows Nk\(d, r d, r Nk\(r 4 where, N k\(d, r with the antecedent part of rule r in class k \(in this paper, k E a o Fig. 6 0.2 0.4 ml\(d matching degree with normal rules \(X1 b An example of joint probability density function P2\(d normal, intrusion r the antecedent part of rule r Then, the average matching degree of the data with all the rules in class k is calculated as follows where, R k  shows a set of rules in class k. Fig. 5 shows how to calculate the matching degrees of data with the extracted rules and average matching degrees for a certain class Finally, a joint probability density function f\(Xl Xk, . . .  , XK matching degrees of all the training data d E Dtrain with the rules r E R k  for all k E C, where C = {I, . . .  , k, . . .  , K is a set of suffixes of classes and Dtrain is a set of training data. Fig. 6 \(a joint probability density function, where normal data gather around the right side of the figure because the normal data basically matches with normal rules and does not match intrusion rules, and intrusion data gather around the left side because the matching degree with intrusion rules is high and that with normal rules is low. On the other hand, the probability of the other area is low because there are few 


accesses which satisfy both normal and intrusion rules or neither rule. However, if a new data does not satisfy either rule, it could be regarded as unknown intrusion B. Classification based on the probability density function The probability Pk \(d Dtest is a set of testing data Po \(d calculated as follows Po 1 - z= Pk\(d 7 kEC Fig. 6 \(b probability density function shown in Fig. 6 \(a areas correspond to the probability of belonging to normal class and intrusion class, respectively. In Fig. 6 \(b axis shows the matching degree with normal rules and X2axis shows that with intrusion rules. The probabilities of belonging normal class k = 1, known intrusion class k = 2 and unknown intrusion class k = a are calculated by Eq. \(6 and \(7 Pl\( d P2\( d Po 11.0 1m1\(d m2\(d 1m2 \(d o ml\(d f \(Xl , X2 f \(Xl , X2 1 - \(Pl\( d d C. Modification of probability Pk \(d 8 9 10 In network intrusion detection, there is a trade-off between positive false rate \(PFR NFR increases when normal accesses are labeled as intrusion and NFR increases when intrusion accesses are labeled as normal. In order to realize the acceptable PFR and NFR the modification of the probability Pk \(d follows TABLE I PARAMETERS SETTING OF GNP 


Population Size 120 Generation 1000 Processing Node 10 Judgment Node 100 Crossover Rate 1/5 Mutation Rate Pm1 1/3 Mutation Rate Pm2 1/3 Wo = 2.0, Wl = 1.7 and W2 = 2.4 Normal Unknown intrusion f!N-OON matching degree with normal rules \(mN\(d Fig. 7. Other classification scheme considering mean and standard deviation of two one-dimensional probability density functions data in the training data with normal rules, and those of intrusion data with intrusion rules \(M and \(JJ data is classified into normal, known intrusion and unknown intrusion by the following conditions, where, mN\(d average matching degree of testing data d with normal rules mJ\(d 2.5 0.3 are coefficients if mN\(d JN then else if /-LN ?: /-LJ then d is normal else d is known intrusion if mJ\(d JJ then d is known intrusion else d is unknown intrusion P Wk?\(? k f-- wo Po \(d d 11 where, Wo , Wk \(k E C IV. SIMULATIONS In this section, the detection ability of the proposed method is evaluated by the intrusion detection simulations using KDD99CUP [10] network connection database. The parameters of GNP is shown in Table I. In addition, the comparison with other classification \(called conventional method in this paper in [9] is carried out. The conventional method uses mean and standard deviation of the distributions of normal and 


intrusion accesses, respectively, which is summarized as follows. The conventional method calculates mean /-LN and standard deviation \(IN of the matching degrees of normal trusion are shown in Fig. 7. The parameters have been appropriately determined through the simulations A. Simulation results The training data contains 5,000 normal access data and 5,000 intrusion access data including two kinds of attacks smurf and neptune. In KDD99Cup database, 41 attributes are included, however, 165 sub-attributes are assigned to the judgment functions in GNP after sub-attribute utilization described in II-C. As a result of the evolution, 19,372 rules including 1,786 normal rules and 17,586 intrusion rules are extracted 1 accesses and 499 intrusion accesses which are the same intrusion types as the training data. The classification of both TABLE II TESTING RESULTS OF THE PROPOSED METHOD IN SIMULATION 1 Normal \(T T T Normal \(C Intrusion \(C Total 481 501 18 1000 TABLE III TESTING RESULTS OF THE CONVENTIONAL METHOD IN SIMULATION 1 Normal \(T T T Normal \(C Intrusion \(C Total 474 525 1 1000 methods are based on the same normal rules and intrusion rules, and the classification results of these methods are shown in Table. II and III, respectively. Normal\(T T T unknown intrusion which are labeled by each classifica tion method, respectively, and Normal\(C C indicates correct labels of normal and known intrusion respevtively. So, in Table II for example, 481 normal accesses out of 501 are labeled as normal, 2 are labeled as known intrusion and 18 are labeled as unknown intrusion From the tables, detection rate DR, PFR, NFR and Accu racy of the proposed method are calculated as DR 


PFR NFR Accuracy 481 + \(499 + 0 2 + 18 0/499 = 0.0 481 + 499 and those of the conventional method are DR PFR NFR Accuracy 474 + \(499 + 0 26 + 1 0/499 = 0.0 474 + 499 DR shows how much the normal data are labeled as normal and the intrusion data are labeled as intrusion, and Accuracy shows how much the data belonging to certain classes are classified into the correct classes. The results show that the proposed method classifies the testing data correctly with better rate than the conventional method 2 mal accesses and 320 intrusion accesses including two kinds of unknown intrusions \(nmap and portsweep to two kinds of known intrusions. The classification results of the proposed method and the conventional method are shown in Table. IV and V, respectively. Here, Unknown \(C indicates the correct label of unknown intrusion TABLE IV TESTING RESULTS OF THE PROPOSED METHOD IN SIMULATION II Normal \(T T T Normal \(C known \(C Unknown \(C Total 759 246 63 1068 TABLE V TESTING RESULTS OF THE CONVENTIONAL METHOD IN SIMULATION II Normal \(T T T Normal \(C Known \(C Unknown \(C 


Total 741 280 47 1068 From the tables, DR, PFR and NFR of the proposed method are calculated as DR PFR NFR Accuracy 727 + 288 21/748 = 2.81 32/320 = 10.0 727 + 240 + 43 and those of the conventional method are DR PFR NFR Accuracy 712 + 291 36/748 = 4.81 29/320 = 9.06 712 + 240 + 42 We can see that the proposed method also shows better DR, PFR and Accuracy, however, NFR of the proposed method is larger than that of the conventional method in this simulation. Because this simulation deals with unknown intrusion, NFR becomes higher, so how to determine the weights on the probabilities of normal and intrusion accesses is an important problem which is related to the trade-off between PFR and NFR V. CONCLUSIONS In this paper, a classification method with a multi dimensional probability density function is proposed and ap plied to the network intrusion detection problem to evaluate its classification ability. The proposed method can classify data based on the probabilities that the data belongs to normal, known intrusion and unknown intrusion classes therefore, it becomes more flexible than the classification method which divides the classes based only on the mean and standard deviation of the distribution of each class Two kinds of simulations are carried out; one of them deals with the testing dataset containing normal and known intrusion accesses in order to confirm the detection ability for known patterns; and the other one deals with that containing 


unknown intrusion accesses in addition to normal and known intrusion accesses. From the simulation results, it is clarified that the proposed method shows higher detection rate and lower positive false rate in both simulations. But, there is a room for improvement of negative false rate by adjusting weights on the probabilities depending on the problems and also improvement of the classification as follows in the future. We will consider the problems which have more than two classes in order to confirm the general classification abil ity of the proposed method. For example, a known intrusion class can be divided into several classes corresponding to the types of attacks. Then, high dimensional probability density function can be created in order to improve the detection accuracy REFERENCES 1] S.-J. Han and S.-B. Cho, "Evolutionary neural networks for anamoly detection based on the behavior of a program," IEEE Trans. Syst Man, Cybern. B, vol. 36, no. 3, pp. 559-570, 2006 2] D. Parikh and T. Chen, "Data fusion and cost minimization for intru sion detection," IEEE Trans. on Information Forensics and Security vol. 3, no. 3, pp. 381-389, 2008 3] D. E. Denning, "An intrusion detection model," IEEE Trans. Software Eng., vol. 13, pp. 222-232, 1987 4] S. Mabu, K. Hirasawa, and J. Hu, "A graph-based evolutionary algorithm: Genetic network programming \(GNP using reinforcement learning," Evolutionary Computation, vol. 15 no. 3, pp. 369-398, 2007 5] K. Hirasawa, T. Eguchi, J. Zhou, L. Yu, and S. Markon, "A double deck elevator group supervisory control system using genetic network programming," IEEE Trans. Syst., Man, Cybern. C, vol. 38, no. 4, pp 535-550, 2008 6] T. Eguchi, K. Hirasawa, J. Hu, and N. Ota, "A study of evolutionary muitiagent models based on symbiosis," IEEE Trans. Syst., Man Cybern. B, vol. 36, no. 1, pp. 179-193, 2006 7] K. Shimada, K. Hirasawa, and J. Hu, "Genetic network programming with acquisition mechanisms of association rules," Journal of Ad vanced Computational Intelligence and Intelligent Informatic, vol. 10 no. 1, pp. 102-111,2006 8] Y. Gong, N. Lu, S. Mabu, C. Chen, Y. Wang, and K. Hirasawa Network intrusion detection system based on matching degree distri bution using genetic network programming," SICE Journal of Control Measurement and System Integration, submitted 


9] Y. Gong, S. Mabu, C. Chen, Y. Wang, and K. Hirasawa, "Intrusion detection system combining misuse detection and anomaly detection using genetic network programming," in Proc. of the SICE-ICASE International Joint Conference, 2009, pp. 3463-3467 10] "Kddcupl999 data. " [Online]. Available: kdd.ics.uci.eduldatabases kddcup99/kddcup99.htrn1 11] R. P. Lippmann, D. J. Fried, I. Graf, J. Haines, K. P. Kendall, D. Mc Clung, D. Weber, S. Webster, D. Wyschogrod, R. K. Cunningham and M. A. Zissman, "Evaluating intrusion detection systems: The 1998 darpa offline intrusion detection evaluation," in Proc. of DARPA Information Survivability Conference and Exposition 2000, vol. 2 IEEE Computer Society Press, 2000 12] K. Shimada, K. Hirasawa, and J. Hu, "Class association rule mining with chi-squared test using genetic network programming," in Proc. of the IEEE International Conference on Systems, Man and Cybernetics 2006, pp. 5338-5344 


n-dimension data cube\( I1  I k Support=sup_count/total_count 2 3 4. Performance Analysis Example 2 Lets talk about a practical problem just like the status of sales. Assume that we will mine the association rules involved 4 dimension attributes of sales, the minsup=25%. First of all, using OLAP technology to build a 4-D data cube and the 4 dimension attributes are: time location, item, and supplier. For location dimension which contains area, country and so on, we choose province level We use brand level for item dimension, company level for supplier dimension. Time dimension can be divided as Q1 1-3 4-6 7-9 10-12 location\(P1,P2,L1,L2 York, item\(B1,B2,B3,B4 C1,C2,C3 sales data cube can be generalized like this Graphic 2: The 4-Dimension Data Cube of Sales The details of this sales data cube are in the table follow: The amount of cells is 100 Location Time Item Supplier Count Cell-1 P1 Q1 B1 C2 5 Cell-2 P1 Q3 B1 C1 2 Cell-99 L1 Q3 B1 C1 3 Cell-100 L2 Q4 B1 C3 11 Table 2: The details data table of sales data cube We use original Apriori_Cube Algorithm to find frequent predicate set with minsup_num= 25%*100=25 According the data table we calculate that sup_count of every member of dimension L is \(P1:8, P2:5, L1:1, L2:24 and also T, I, S. So there is the process Graphic 3: The processes of old algorithm As we know, through comparing with the minsup_num dimension location has no one frequent 1-predicate set, so that there have no frequent 4-predicate set in the output by the original algorithm. But users are interested in the Candidate 1-Predicate set L T I S P1 P2 L1 


L2 Q1 Q2 Q3 Q4 B1 B2 B3 B4 C1 C2 C3 Frequent 1-Predicate set T I S Q1 Q3 B2 B3 C1 C2 I1 I 2 C1              C2                 C3 2 12 1 3 5 1 6 2 12 8 11 Q 1  Q 2  Q 3  Q 4 P 1 P 2 L 1 L 2 Candidate 2-Predicate set Q1,B2},{Q1,B3 Q1,C1},{Q1,C2 Q3,B2},{Q3,B3 


Q3,C1},{Q3,C2 Candidate 3-Predicate set Q1,B2,B3}{Q 1,Q3,B2},{Q3 C1,B2 Frequent 2-Predicate set Q1,B2}{Q1,B 3},{Q3,B2 Q3,C1 Output: 1L U 2L U 3L Frequent 3-Predicate set Q1,B2,C1},{Q1,B3,B2 Q1,B2,B3  6 level from the same dimension and SP to pruning Candidate 3 Set, pruning {Q1,Q3,B2}, keep {Q1,B2,B3} due to the special requirement on location B by users 7 1 max_support of every dimension 1 frequent 4-predicate set which contains location dimension And the candidate 3-predicate set {Q1,Q3,B2} is useless because when we mine multi-dimension association rules we should follow that one predicate set contains no more than one different level from the same dimension even the sup_count >minsup_num when there are no requirements from users. But this time, users require that different members from dimension item can exist at the same time So we redo this mining process by the improved Algorithm Graphic 4: The processes of improved algorithm At last, we got the frequent 4-predicate set which the users are interested in, and then can format the rules 5. Conclusion In this paper, we have studied issues and methods on efficient mining of multi-dimension association rules based on data cube. With the development of technology, the size 


of database has become much huge than ever before unimaginable. So the multi-dimension model of database based on data cube has become useful and popular relatively how to mine useful multi-dimension association rules based on this model has been important too. Among the algorithms for the problems we choose the most classify one to improve, to make it more efficient and useful An efficient algorithm, Apriori_Cube_Improved, has been developed which explores the multi-dimension association rules. First, we use max_support and min_support of every frequent 1-predicate set to check the levels of dimensions, and then adjust the data cube by roll-up and drill-down operation immediately. This step is embed in the process of mining association rules, so it makes the rules much more useful and flexible; second applying one predicate set contains no more than one different level from the same dimension and SP pruning can help reduce the amount of predicate set, especially with the great growing of the number. So the speed of algorithm improved is faster than ever At last, there are also many other interesting issues and flaws of the algorithm which call for further study including efficient mining multi-dimension association rules of complex measures and so on. Finally, I should thank all the people who have give me help for this paper Reference 1] Jiawei Han, Micheline Kamber. Data Mining Concepts and Techniques. China Machine Press, 2007 2] Agrawal R, Imielinski T and Swami A. Mining association rules between sets of items in large database. Proc. of the ACM SIGMOD Conf., Washington DC, 1993 3] Gao Xuedong, Wang Wenxian and Wu Sen. Multidimensional Association Rule Mining Method Based on Data Cube Computer Engineering, China,2003 4] Sheng Yingying, Yan Ren, Wang Jiamin and Li Jia. Research Multi-dimensional Association Rule Ming Based on Apriori Science Technology and Engineering, China, 2009 5] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. Proc. of the 20th Int.Conf. on VLDB Santiago, Chile, 1994 6] Guozhu Dong, Jiawei Han, Joyce Lam, Jian Pei and Ke Wang Mining Multi-Dimension Constrained Gradients in Data 


Cubes. Proc. of the 27th Int.Conf. on VLDB, Roma, Italy 2001 7] M. J. Zaki. Scalable Algorithms for Association Mining. IEEE Transactions on Knowledge and Data Engineering, 2000 Candidate 1-Predicate set L T I S P1 P2 L1 L2 Q1 Q2 Q3 Q4 B1 B2 B3 B4 C1 C2 C3 Candidate 1-Predicate set L T I S P L Q1 Q2 Q3 Q4 B1 B2 B3 B4 C1 C2 C3 Frequent 1-Predicate L T I S P L 


Q1 Q3 B2 B3 C1 C2 Frequent 4-Predicate set Q3,C1,B2,P},{Q1,B2,B3 Output L1 U L2 U L3 U L4 The Dimension need to be adjust Dimension: Location Operation: Roll-up to increase the level of this dimension Result P\(P1,P2 L1,L2 2 3 2 3 The Features Of Every 1-Predicate Set Location: min_support=13 max_support=25 Time: min_support=5 max_support=30 Item: min_support=10 max_support=25 Supplier: min_support=11 max_support=27 4 5 4 max_support of every dimension 5 minsup_num=25, and no one has to be adjusted Frequent 3-Predicate set Q3,C1,B2},{Q1,B2,L Q1,B3,L},{Q3,P,B2 Candidate 4-Predicate set 


Q3,C1,B2,P},{Q1,B2,B3,L}\(7 The Features of Every 1-Predicate Set Location: min_support=1 max_support=24 Time: min_support=5 max_support=30 Item: min_support=10 max_support=25 Supplier: min_support=11 max_support=27 Candidate 2-Predicate set Q1,B2},{Q1,B3},{Q1,C1 Q1,C2},{Q3,B2},{Q3,B3 Q3,C1},{Q3,C2},{P,Q1 P,Q3},{P,B2},{P,B3},{P,C1 P,C2},{L,Q1},{L,Q3 L,B2},{L,B3},{L,C1},{L,C2 Frequent 2-Predicate set Q1,B2}{Q1,B3},{Q3,B2 Q3,C1},{P,Q3},{L,Q1 6 Candidate 3 -Predicate set Q3,C1,B2},{Q3,C1,P},{Q1,B 2,L},{Q1,B3,L},{Q3,P,B2},{Q 1,B2,B3  6 level from the same dimension and SP to pruning Candidate 3 Set, pruning {Q1,Q3,B2}, keep {Q1,B2,B3} due to the special requirement on location B by users 7 1 max_support of every dimension 1 frequent 4-predicate set which contains location dimension And the candidate 3-predicate set {Q1,Q3,B2} is useless because when we mine multi-dimension association rules we should follow that one predicate set contains no more than one different level from the same dimension even the sup_count >minsup_num when there are no requirements from users. But this time, users require that different 


members from dimension item can exist at the same time So we redo this mining process by the improved Algorithm Graphic 4: The processes of improved algorithm At last, we got the frequent 4-predicate set which the users are interested in, and then can format the rules 5. Conclusion In this paper, we have studied issues and methods on efficient mining of multi-dimension association rules based on data cube. With the development of technology, the size of database has become much huge than ever before unimaginable. So the multi-dimension model of database based on data cube has become useful and popular relatively how to mine useful multi-dimension association rules based on this model has been important too. Among the algorithms for the problems we choose the most classify one to improve, to make it more efficient and useful An efficient algorithm, Apriori_Cube_Improved, has been developed which explores the multi-dimension association rules. First, we use max_support and min_support of every frequent 1-predicate set to check the levels of dimensions, and then adjust the data cube by roll-up and drill-down operation immediately. This step is embed in the process of mining association rules, so it makes the rules much more useful and flexible; second applying one predicate set contains no more than one different level from the same dimension and SP pruning can help reduce the amount of predicate set, especially with the great growing of the number. So the speed of algorithm improved is faster than ever At last, there are also many other interesting issues and flaws of the algorithm which call for further study including efficient mining multi-dimension association rules of complex measures and so on. Finally, I should thank all the people who have give me help for this paper Reference 1] Jiawei Han, Micheline Kamber. Data Mining Concepts and Techniques. China Machine Press, 2007 2] Agrawal R, Imielinski T and Swami A. Mining association rules between sets of items in large database. Proc. of the ACM SIGMOD Conf., Washington DC, 1993 3] Gao Xuedong, Wang Wenxian and Wu Sen. Multidimensional Association Rule Mining Method Based on Data Cube 


Computer Engineering, China,2003 4] Sheng Yingying, Yan Ren, Wang Jiamin and Li Jia. Research Multi-dimensional Association Rule Ming Based on Apriori Science Technology and Engineering, China, 2009 5] R. Agrawal and R. Srikant. Fast Algorithms for Mining Association Rules. Proc. of the 20th Int.Conf. on VLDB Santiago, Chile, 1994 6] Guozhu Dong, Jiawei Han, Joyce Lam, Jian Pei and Ke Wang Mining Multi-Dimension Constrained Gradients in Data Cubes. Proc. of the 27th Int.Conf. on VLDB, Roma, Italy 2001 7] M. J. Zaki. Scalable Algorithms for Association Mining. IEEE Transactions on Knowledge and Data Engineering, 2000 Candidate 1-Predicate set L T I S P1 P2 L1 L2 Q1 Q2 Q3 Q4 B1 B2 B3 B4 C1 C2 C3 Candidate 1-Predicate set L T I S P L Q1 Q2 Q3 Q4 B1 B2 


B3 B4 C1 C2 C3 Frequent 1-Predicate L T I S P L Q1 Q3 B2 B3 C1 C2 Frequent 4-Predicate set Q3,C1,B2,P},{Q1,B2,B3 Output L1 U L2 U L3 U L4 The Dimension need to be adjust Dimension: Location Operation: Roll-up to increase the level of this dimension Result P\(P1,P2 L1,L2 2 3 2 3 The Features Of Every 1-Predicate Set Location: min_support=13 max_support=25 Time: min_support=5 max_support=30 Item: min_support=10 max_support=25 Supplier: min_support=11 max_support=27 4 5 


4 max_support of every dimension 5 minsup_num=25, and no one has to be adjusted Frequent 3-Predicate set Q3,C1,B2},{Q1,B2,L Q1,B3,L},{Q3,P,B2 Candidate 4-Predicate set Q3,C1,B2,P},{Q1,B2,B3,L}\(7 The Features of Every 1-Predicate Set Location: min_support=1 max_support=24 Time: min_support=5 max_support=30 Item: min_support=10 max_support=25 Supplier: min_support=11 max_support=27 Candidate 2-Predicate set Q1,B2},{Q1,B3},{Q1,C1 Q1,C2},{Q3,B2},{Q3,B3 Q3,C1},{Q3,C2},{P,Q1 P,Q3},{P,B2},{P,B3},{P,C1 P,C2},{L,Q1},{L,Q3 L,B2},{L,B3},{L,C1},{L,C2 Frequent 2-Predicate set Q1,B2}{Q1,B3},{Q3,B2 Q3,C1},{P,Q3},{L,Q1 6 Candidate 3 -Predicate set Q3,C1,B2},{Q3,C1,P},{Q1,B 2,L},{Q1,B3,L},{Q3,P,B2},{Q 1,B2,B3  


DMITAR Rlt  DMITAR  R esu lt s 2  5 Rules Formed Associative IDS for NextGen Frameworks Dr S Dua LA Tech 28 


DMITAR Rl  Varying Maxspan DMITAR  R esu l ts 3  5 Varying Maxspan Associative IDS for NextGen Frameworks Dr S Dua LA Tech 29 


DMITAR Res lts 4/5 Vig Di i DMITAR  Res u lts  4/5 V ary i n g Di mens i ons Associative IDS for NextGen Frameworks Dr S Dua LA Tech 30 


DMITAR Rl  Varying Number of Transactions DMITAR  R esu l ts 5  5 Varying Number of Transactions Associative IDS for NextGen Frameworks Dr S Dua LA Tech 31 


N/C t Rh N ew C urren t R esearc h Problem Domain Problem Statement and Challenges Associative Mining based IDS Associative Mining based IDS Introduction to data mining ii lid ii Assoc i at i on ru l e i n d ata m i n i ng DMITAR Algorithm  ARD h New Researc h Associative IDS for NextGen Frameworks Dr S Dua LA Tech 32 


Further Research Further Research Objectives of Our Intrusion Detection System Development Objectives of Our Intrusion Detection System Development 1 Refine and scale the DMITAR algorithm to suit our application 2 Develop methods for dynamically altering the sensor parameters Our Focus is Securing the NextGen Frameworks with New Technology Technology Associative IDS for NextGen Frameworks Dr S Dua LA Tech 33 


Simulated Sensing Environment Simulated Sensing Environment Screenshots of Data C ollected from S ynthetic Sensors Screenshots of Data C ollected from S ynthetic Sensors Simulated in Our Laboratory Three Steps Slides Collect data Collect data from all sources  all attributes  Select Select the source and their hierarchical attributes attributes to be monitored and Select Select the source and their hierarchical attributes attributes to be monitored  and Sample Sample them at different rates different rates and process them Associative IDS for NextGen Frameworks Dr S Dua LA Tech 34 


Data Collection Simultaneous collection of data screen from ENTITIES aircrafts Associative IDS for NextGen Frameworks Dr S Dua LA Tech 35 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Parameter Selection Selection of an ENTITY/aircraft and monitoring its parameters and sensor readings Associative IDS for NextGen Frameworks Dr S Dua LA Tech 36 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Sensor Sampling Selecting one sensor/probe and reading it at different resolutions or sampling rates Associative IDS for NextGen Frameworks Dr S Dua LA Tech 37 Source PRTG Network Monitor software screen shot Demo info www.paessler.com 


Si l ti Nt k Si mu l a ti on on N e t wor k Most scenarios can be simulated on a computer or computer network network  The aircrafts and sensors are simulated on a computer network bllb b y ana l ogica l su b stitutions Sensors provide information at different rates Sensors provide information at different rates Need Based Sensor Prioritization NSP and Dynamic Sensing Rate Sampling Associative IDS for NextGen Frameworks Dr S Dua LA Tech 38 


Vulnerability Search Scan 39 Sample UQA script with Nmap performed in DMRL Associative IDS for NextGen Frameworks Dr S Dua LA Tech 39 Source Nmap screenshot with a pearl script  Find Namp on Nmap.org 


Modality Aspect Modality Aspect A Multimodal distribution is a continuous probability distribution with two or more modes of underlying data Mltil d i M u lti p l e mo d es i n our model Associative IDS for NextGen Frameworks Dr S Dua LA Tech 40 Source http://en.wikipedia.org/wiki/File:Bimodal bivariate small.png 


Multi Modality Modality Fusion 41 SENSITIVE  UNCLASSIFIED For Official Use Only Associative IDS for NextGen Frameworks Dr S Dua LA Tech 41 


Emphasis Emphasis Our approach emphasizes on pre empting the attack Our intent is NOT to perform an autopsy to discover attacks Instead we aim to detect and prevent in attacks in real time Associative IDS for NextGen Frameworks Dr S Dua LA Tech 42 


Techniques for Discriminative Rules Techniques for Discriminative Rules Resolution Analysis Features Analyzed at Different Depths Anti Monotonic Principle Modality Aspect Treading into Unexplored Feature spaces Associative IDS for NextGen Frameworks Dr S Dua LA Tech 43 


Representative Outcomes Representative Outcomes Illustration of the Final Analysis Our method shifts between modalities and sampling rates for optimization The blue parallelograms are actual intrusions 44 The blue parallelograms are actual intrusions The Red Green Blue Plots are response of system Associative IDS for NextGen Frameworks Dr S Dua LA Tech 44 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



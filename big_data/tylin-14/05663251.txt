Research on User Requirements Elicit 
ation Using Text Association Rule    Dong Lili,  Zhang Xiang,  Ye Na,   Wan Xiaoge College of Information and Control Engineering Xi’an University of Architecture and Technology Xi’an, 710055, China donglilixjd@163.com, zhangxiang1001@126.com, yenanaye@126.com, wanxiaoge@sina.com   Abstract User requirements obtained through text data mining are very important to improve the competitiveness of enterprises. In this paper an algorithm of acquiring user requirements in machinery products by using text association rule is proposed. In the algorithm, the user requirement documents are represented by vector space model. The feature words matrix is obtained by transposing the documents matrix 
An improved text association rule theory based on gray association rule is used to calculate the correlation degree between feature words and proper nouns of machinery industry. Then the matrix of candidates for proper noun is constructed by selecting a higher correlation degree word as a threshold. Finally, user requirements are obtained by using the weighted matrix. The experimental results suggest that the proposed method is feasible for user requirement elicitation Keywords-text association rule; user requirements;vector space model;gray association rule;mechanical products I   I NTRODUCTION  With the rapid development of the network technology Internet has become the main means of publishing and 
obtaining information. The user requirement is the motivation of technology development. Making full use of web resources to get user requirements has great importance to grasp the market trends correctly and improve the competitiveness of enterprises. The technology of acquiring user requirements based on text association rule is to put together all the requirement information of mechanical products, which is scattered on the Internet, and then extract the genuine and professional user requirements.  Data mining is the analysis of \(often large\ observational data sets to find unsuspected relationships and to summarize the data in novel ways that are both understandable and useful to the data owner. Text data mining is concerned with data mining 
methodologies applied to textual sources [1   In text mining text association is most widely used, in which semi-structured text data is transformed into computer representation model and then the association rule algorithm is used to extract knowledge. This paper presents a new text association rule algorithm based on gray theory to obtain the user requirements. First, documents of user requirements are represented by the vector space model, and then an improved gray association rule theory is used to calculate the correlation degree between feature words and proper nouns of machinery industry. Finally, user requirement is obtained by using the weighted matrix The rest of this paper is organized as follows: In section 2 we will discuss the process of obtaining user requirements 
Data preprocessing of user requirement is discussed in secion3. In section 4, representation model of user requirements is introduced. In section 5 002 we  will illustrate how to obtain proper nouns of machinery industry based on Gray association rule theory. In section 6, experimental steps and results are presented.  Some conclusions and ideas for further research are described finally II  T HE PROCESS OF OBTAINING USER REQUIREMENTS  The process of obtaining user requirements for machinery industry could be divided into three steps. The first step is data preprocessing. In this step  the messy user requirements are collected from Internet and rough 
dimension reduction of user requirements is achieved by Chinese words segmentation and the stop words elimination The second step is constructing requirements presentation model. In this step the user requirements is represented by vector space model \(VSM\ The third one is user requirements elicitation. According to the improved gray association rule, the correlation degree matrix of feature words can be acquired by considering many user requirement documents  and we can extract the real needs of users by weighted calculation .The process of obtaining user requirements is shown in figure 1 Figure 1  Flow diagram of the process of obtaining user requirements 
2010 International Symposium on Intelligence Information Processing and Trusted Computing 978-0-7695-4196-9/10 $26.00 © 2010 IEEE DOI 10.1109/IPTC.2010.72 357 


III  U SER REQUIREMENTS PREPROCESSING  Because there is  no obvious separator between Chinese words 002 so it is necessary to divide the user requirement documents which are collected from the Internet into proper words by Chinese words segmentation. ICTCLAS \(Institute of Computing Technology, Chinese Lexical Analysis System\sed to segment Chinese words, which is developed by Institute of Computing Technology, Chinese Academy of Sciences. After segmentation, a table which is called text representation dictionary and composed by a series of words is formed. In order to reduce data noise of text feature vectors and the scale of text representation dictionary, the stop words and low frequency words should be removed from the dictionary and synonymous words are merged, this procedure is called rough dimensional reduction. After this process, the representation dictionary whose dimensions have been reduced can be obtained [2 IV  R EPRESENTATION MODEL OF REQUIREMENTS  The representation of user requirements is a task of converting the dictionary presentation into vector form which the computer can process. At present, the text representation model mainly uses the VSM \(Vector Space Model\ [3 Its  bas i c id ea is r ep r es en tin g e ach  tex t as a v ec t o r         2 1 n w w w d   1 Where i w is the weight of feature term i in document d According to the vector space model, the representation model of user requirement documents can be expressed by      2 1 m d d d D   002 2 002  Each document i d could be denoted as     2 1 in i i i w w w d  m i  2  1  the weight ij w is adopted Boolean Weight, if the feature term appears in the document then the weight is 1,otherwise the weight is 0  The T D is the transpose of the matrix D      2 1 n T t t t D   002 3 002  The i t denotes a feature term which appears in the user’s requirement     2 1 im i i i w w w t  m i  1  The T D represents the situation, that is, how often the feature terms appear in every document  V  T HE ALGORITHM OF REQUIREMENT OBTAINING  BASED ON TEXT ASSOCIATION RULE  A  Calculation of Correlation Degree In 1982, the gray theory is put forward by Deng Julong and today gray theory has developed into a new subject Gray association rule is the uncertain association among the things or the uncertain factor associated with the main action[4 A c c o rd in g to th e m a trix  T D this paper  proposes a text association formula 002 4 002 based on the Gray association rule 0 0 0 0 2 1 2 1 s s s s i i i i      002  m i  1  002 4 002  Where 000     m k ok ik i w w s s 1 0  000    m k ik k oi w w s 1 0  0 s is  an industrial proper noun which is proposed by mechanical experts i s denotes the feature terms that come from the segmentation of user requirement, the correlation degree between feature words and proper nouns can be calculated by formula\(4\. Given the threshold T, if T i  0 002 then the feature term i s is selected as candidates for proper nouns  B  Calculation of Feature Weight Matrix of candidates for proper nouns is constructed by selecting a higher degree word from the correlation matrix Matrix of candidates can be simplified to a single column vectors by multiplying the weight column vector of proper nouns. Higher weight proper nouns can be selected from this single column vector 1  The candidate proper nouns matrix construction i 0 002 is the correlation degree  between feature word i s  and 0 s where i s is the feature word and 0 s is the proper noun of machinery industry. If the correlation degree T i  0 002 the feature word i s is selected as the row of the candidate proper nouns matrix M, the column of matrix M is the proper noun i w which is used to calculate the correlation degree of feature words. The candidate proper nouns matrix is deified as follows 000 000 000 000 000 000 000 000 000 000  nn n n M M M M M      0 0 00  5 Where ij M denotes the correlation degree between feature word i s and proper noun i w  2  The calculation of the weight of candidate proper nouns The n-dimensional vector wei is constituted by the proper nouns n w w  1 which are selected from a database of proper nouns    1 n weight weight wei  002 6 002  Where i weight is the weight of i w which denotes the importance of the proper feature noun for some machineries and it is given by the experience of Machinery industry experts. An n-dimension column vector v is the result of the multiplication of the M and the wei  v wei M T   002 7 002  
358 


Where T v denotes the comprehensive weighted value  weight of feature word i t The value T v considers both the correlation degree between the feature word and the proper feature noun and the weight of proper nouns .The comprehensive weighted value is normalized as 000   n j j i i weitht weight weig 1  002 8 002  In order to obtain a set of feature words which can describe a document, the feature words are often sorted by the comprehensive weighted values, from which the pre-k words are selected as feature words  The value k is decided by experts. Generally, about 30 words are needed to describe certain machine equipment  C  Algorithm description Algorithm 1 Text association rule for user requirements  Input the feature words matrix of user requirements T D  Thre the threshold of correlation degree, The specialized feature terms    1 n w w W  and their weights wei      2 1 n wight wight wight  002 the count of the final feature nouns k Output a set of specialized feature terms  T      2 1 k t t t 002  Step1 For 1  i to n do Step 1.1 Separately use i w as 0 s calculate the correlation degree of feature words which occur in the matrix T D  0 0 0 0 2 1 2 1 s s s s i i i i      002  Step 1.2 if Thre 0  i 002 then select i w to constitute a set of  candidate feature words s Step 2 Constitute the M of candidate feature words which come from s Step 3  v wei M T   according to the value of comprehensive weighted vector, the feature words i t should be ordered  Step 4 Select pre-k feature words as     2 1 k t t t T   Step 5 Output T VI  E XPERIMENT AND R ESULT  In our experiment, Java is adopted as the programming language. The developing platform is Eclipse 3.3. The version of JDK is 1.5. The experimental dataset is 657 user requirements for excavator of machinery industry. After user requirements preprocessing and model representation correlation degree of the feature words and proper noun can be calculated. When threshold of correlation degree is 0.7 there are 82 candidate feature words. Mechanical experts think that 30 proper noun are enough for describing the user requirements of mechanical equipment. So we select 30 proper nouns after weight calculation. According to 30 proper nouns, the mechanical expert constructs excavator by machine-aided design system, which is shown in figure 2.The result is consistent with the requirement document which is analyzed by experts Figure 2  Result of experiment VII  C ONCLUSION AND FUTURE WORKS  The paper proposes a method for obtaining user requirement in machinery industry based on text association rule. The first step is data preprocessing of user requirement Vector space model is used to describe the user requirement Secondly, an improved gray association rule theory is used to calculate the correlation degree between feature words and proper nouns of machinery industry. Then the matrix of candidates for proper nouns is constructed by selecting a higher correlation degree word. Finally, user requirement is obtained by using the weighted matrix. The experimental results show that the method for obtaining the user requirement is effective and efficient. Currently the dataset of user requirement on machinery industry is still relatively small. In the future, the study should be done on a large number of dataset to obtain more accurate experimental result  R EFERENCES  1  Jiawei Han. Data Mining: Concept and Techniques [M Mo r g a n  Kaufmann Publishers Inc.2001 2  Zhang Xiang , Zhou Mingquan , Geng Guohua and Ye Na. A Combined Feature Selection Method for Chinese Text Categorization 2009 International conference on Information Engineering and Computer Science.wuhan18-20 December2009:405-408 3  Salton G, Wong A, and Yang C S. A vector space model for automated indexing. Communications of the ACM.1975, 18\(1\620 4  Deng Julong. Foundation of Gray Theory [M u h a n ,H o n g Z h o n g  university of Science and thechology press,2002 9 in Chinese 9   
359 


non-redundant association rule set from [18], the produced association rules are then applied to sensor network databases of a traffic monitoring site for missing data estimation purpose, in which data missing by a sensor is estimated using the data generated by its related sensors Below, we review the related work for missing data estimation in sensor networks B. Missing Data Estimation in Sensor Networks Many articles have been published to deal with the missing data problem, and a lot of software has been developed based on these methods. Some of the methods totally delete the missing data before analyzing them, like listwise and pairwise deletion [17], while other methods focus on estimating the missing data based on the available information. The most popular statistical estimation methods include mean substitution, imputation by regression [4], hot deck imputation [7], cold deck imputation, expectation maximization \(EM  imputations [14, 15], etc But none of the above approaches is suitable for wireless sensor network environment, where streams of data are constantly sent from the sensors to the server, due to several reasons. First, how much old information should be based on to get the associated information for the missing data estimation? Using all of the old readings to perform the estimation is unreasonable, especially when using an iteration procedure until convergence to get the estimation like in the EM Algorithm. Second, which information should be used to perform the missing data estimation? In the wireless sensor network, data is collected within certain scopes and reported to the server during a certain period of time. Different sensors have different readings at different time periods. The current readings of one sensor may relate not only to its previous readings, but also to other sensors previous or current readings. Third, the missing data may or may not miss at random, while most of the statistical techniques are based on the MAR assumption [10 In [5], the authors proposed a model, called BBQ to provide efficient query answers in sensor networks. They use probabilistic models to answer queries. Such models can be learned from historical data using standard algorithms e.g. [12]. The basic model used in BBQ is a time-varying 


multivate Gaussians. First, the historical data is used to construct the initial representation of the Probability Density Function \(PDF answer queries can be answered using the model. The model is updated as new observations are obtained from the sensor network, and as time passes. There are various different models that may be more suitable in different environments and for different classes of queries As more and more data streaming applications emerge proper data estimation algorithms for streaming data are needed. In [13], the authors proposed using pattern discovery in multiple time-series to estimate missing data but it's not well suited for sensor networks, where the relationships between sensors are decided not only by the time trends, but also by some other factors, like locations and so on. In [6], the authors proposed the Window Association Rule Mining \(WARM estimating missing sensor data. WARM uses a modified Apriori Algorithm for association rule mining to identify sensors that report the same data for a number of times in a sliding window, called related sensors, and then estimates the missing data from a sensor by using the data reported by its related sensors. WARM has been reported to perform better than the mean substitution approach where the average value reported by all sensors in the window is used for estimation. However, there exist some limitations in WARM. First, it is based on 2-frequent itemsets modified Apriori association rule mining algorithm, which means it can discover relationships only between two sensors and ignores the cases where missing values are related with multiple sensors. Second, it fmds those relationships only when both sensors report the same value and ignores the cases where missing values can be estimated by the relationships between sensors that report different values V5-103 2010 2nd International Conference on Education Technology and Computer \(ICETC In view of the above challenges, we develop a technique to perform missing data estimation based on the post mining association rule sets between multiple sensor readings, in which data missing by a sensor is estimated using the data generated by its related sensors III. POST MINING OF NON-REDUNDANT ASSOCIATION 


RULES FOR SENSOR DATA ESTMATION In this section, we describe the notations and defmitions that are used in the proposed technique. Also we present the post mining non-redundant association rule technique and use it to perform missing data estimation in the wireless sensor network applications A. Preliminary Concepts In this subsection, we describe the notations and defmitions that are used in the proposed technique. Let I i h i2, ... , in} be a set of n items. A subset X ? I is called an itemset. A k-subset is called a k-itemset. Each transaction t is a set of items from 1. Given a set of transactions T, the support of an itemset X is the percentage of transactions that contain X. A frequent itemset is an itemset the support of which is above or equal to a user-specified support threshold Let T and X be subsets of all the transactions and items appearing in a data stream S, respectively. The concept of a closed itemset is based on the two following functions andg:j\(1 X E X, i E t}. Function/returns the set of itemsets included in all the transactions belonging to T, while function g returns the set of transactions containing a given itemset X An itemset X is said to be closed if and only if C\(X j{g\(X X is called Galois operator or closure operator [16 Let D = {db d2, ... , dn} be a set of n item identifiers, and V= {Vb V2,     , vm} be a set ofm item values. An itemJ is a combination of D and V, denoted as J= D.V. For example dn.vm means that an item with identifier dn has the value Vm An association rule is an expression X s,c and Y are interesting itemsets, and X n Y = <p. The parameter s represents the support of the rule which is the percentage of records that contain both X and Y in the database \(s = s\(Xuy Xuy percentage of records containing X that also contain Y called the confidence of the rule \(c = s\(XuY X Ig\(Xu y X association rules, the support and confidence of which are above or equal to a user-specified minimum support and confidence, respectively [1]. An association rule Xl sl,c1 


s2,c2 from Xl sl,c1  s,C association rule X3 s,c  B. Post Mining o/Non-redundant Association Rules /or Sensor Data Estiamtion In this subsection, we describe our proposed technique for post mining of non-redundant association rules for sensor data estimation purpose. This algorithm is developed based on non-redundant informative association rules which means all rules cannot be derived from other rules and the left hand side and right hand side of the selected rules contain the input itemset. There are some research works that can generate the closed itemsets and corresponding association rules using generated closed itemsets [3 , 18 Based on our previous works [8] we assume to have the non-redundant association rules ready and the criteria of selecting the rules from non-redundant rules further reduce the number of rules to the minimum In this algorithm, dn.vm is treated as one item in association rules. Dn represents the sensor which is indexed as n. Vm represents the value of the sensor n is read as m. In the following figure, Xinput is the itemset represent the current round of sensor readings, it can be represented by a set of dn.vm pairs. Xl and X2 are the itemsets in left hand side and right hand side of association rules. Z represents all items in X2/Xinput. Index\(z z and value of sensor value pair z. Confidence{Xl=>X represents the confidence of the rule Xl=>X2 Support\(Xl=>X2 C represents the confidence of association rule, dn V represents the identifier and value pair of the sensor dn Xestimate represents the returned estimation itemset which contains the senor identifiers with missing values in the current round of readings of stream data and their corresponding estimated values. Sspecify represents the user specified support, and Cspecify represents the user-specified confidence The algorithm is described as below. The input of the procedure Estimate includes the current round of sensor reading, current association rule confidence, user-specified minimum support and user-specified minimum confidence 


In line 4, all association rules that satisfy with the conditions of minimum support and confidence are selected The confidence of the select association rules are calculated in line 5. The condition of line 6 filters out the rules whose left hand side itemset Xl does not contain the itemset Xinput in this case, sensor identifier is filtered based on the enriched contextual information. The condition of line 7 filters out the rules whose right hand side itemset X2 does not contain new estimated items. Each new item was processed in line 8 and 9 so that missing sensor values are V5-104 2010 2nd International Conference on Education Technology and Computer \(ICETC modified and updated. At the end of this procedure, an iterative call of the same procedure keep on searching and processing for the new association rules that are able to make contribution on the sensor value estimation Input: \( 1 contains missing values 2 3 Output: Xestimste: a set containing the senor ids with missing values in the current round of sensor readings and their corresponding estimated values Method 1 Xestirnste = <\\l 2 Cinput=l 3 Procedure Estimate\(XinpUb Cinpub Sspecify, Cspecify 4 for all \(rule: X,=>X2 and Support\(X,=>X2 Confidence\(X,=>X2 5 C = Conjidence\(X,=>X2 6 if \(X,EAinput 7 if\(X2\\Xinput*<\\l 8 for all \(ZEX2\\Xinput and zE Xestimste 9 Xestimste = Xestimste U z 10 n = index\(z 1 1  d., v= dn v +C*value\(z 12 end for 13 end if 14 Estimate\(X2, C, Sspecify, Cspecify 15 end if 16 end for 17 end procedure 


Figure 1. The post mining of non-redundant association rule for sensor data estimation IV. EXPERIMENTAL STUDY The performance of our proposed approach is studied by means of simulation. Several different simulation experiments are conducted in order to evaluate the proposed technique and compare it with the Average Window Size A WS linear trend approach, and with the WARM approach, the state-of-the-art data estimation algorithm in sensor databases using 2-frequent itemsets based association mining [6]. We compared the estimation accuracy, running time and memory space usage when applying different methods to the application dataset The dataset was collected in year 2000 at various locations throughout the city of Austin, Texas. The data represents the current location, the time interval, and the number of vehicles detected during this interval. All sensor nodes report to a single server. The sensors are deployed on city streets, collect and store the number of the vehicles detected for a given time interval. The vehicle counts taken as sensor readings that are used as input for our simulation experiments are traffic data provided by [2 A. Performance Study of Estimation Accuracy The evaluation of the estimation accuracy of the missing values is done by using the average Root Mean Square Error RMSE I'\(xa, -Xe 1 ___ l __ lI_?''? ____ _ numStates # estimations where Xa; and Xe; are the actual value and the estimated value, respectively; #estimations is the number of estimations performed in a simulation run; and numStates is the number of subsets, in which the actual readings are distributed The expression u  xa, -Xe estimations error and is an estimate of the standard deviation under the assumption that the errors in the estimated values \(i.e. Xai Xei 


see the smaller the RMSE, the better the estimation accuracy From Figure 2, we can see that the proposed technique gives the best average estimation result of the above approaches regarding the accuracy, followed by the WARM approach. The linear interpolation, A WS, and linear trend approaches perform no better than WARM and the proposed approaches. From Figure 2, we can also see that the proposed technique gives the best estimation result on the maximum estimation accuracy, which is the root square error for the maximum difference between the estimated and accurate values 0.6 0.5 0.4 w n 0.3 cz 0.2  Average 0.1  Maximum 0 l' ?? 0" </.,oQ Figure 2. Perfonnance study of average and maximum estimation accuracy for traffic monitoring application B. Performance Study of Running Time Figure 3 illustrates the running time in seconds of A WS linear interpolation, linear trend, WARM and proposed approaches. The experimental results show that in terms of running time, the WARM and proposed approaches are outperformed by A WS, linear interpolation and linear trend V5-105 2010 2nd International Conference on Education Technology and Computer \(ICETC approaches. The proposed approach is faster than the WARM technique 0.03 v 0.025 0.02 E U.uJ c 0.01 0.005 0 a  r 


r r r  9  Figure 3. Performance study of running time for traffic monitoring application in seconds C. Performance Study of Memory Usage Figure 4 illustrates the memory usage of A WS, linear interpolation, linear trend, WARM and proposed approaches in MB. The experimental results show that in terms of memory space, the WARM approach is outperformed by all the other four approaches. The results of the simulation experiments show that for 108 sensors the needed memory space using WARM is much higher than that using proposed approach. This is because the closed lattice data structure uses less memory space than the cube data structures, and it only stores the condensed closed itemsets information Figure 4. Performance study of memory usage for traffic monitoring application in MB V. CONCLUSTIONS Sensor stream applications are becoming very common with the advances in technologies for sensor devices. In this paper we propose a method to post mine non-redundant association rules, and used the result to produce missing data estimation in sensor network applications. The objective is to further reduce the resulting rules from non redundant association rule mining based on the users request, and apply the retrieved meaningful information to perform missing data estimation in wireless sensor networks We have evaluated the proposed technique with real data from a wireless sensor network of a traffic monitoring site Our proposed method is able to estimate missing sensor value with both time and space efficiency, and greatly improves the estimation accuracy. Our performance study 


shows that proposed post mining of association rule mining technique for missing sensor data estimation is an area worth to explore REFERENCES 1] Agrawal, R., & Imielinski, T., & Swami, A., "Mining association rules between sets of items in massive databases", International Conference on Management of Data, 1993 2] Austin, F. I., "Austin Freeway ITS Data Archive", Retrieved January 2003 from http://austindata.tamu.eduidefauIt.asp 3] Bastide, Y., & Pasquier, N., & Taouil, R, & Stumme, G., & Lakhal L., "Mining minimal non-redundant association rules using frequent closed itemsets", First International Conference on Computational Logic, 2000 4] Cool, A. L., "A review of methods for dealing with missing data The Annual Meeting of the Southwest Educational Research Association, 2000 5] Deshpande, A., & Guestrin C., & Madden, S., "Using probabilistic models for data management in acquisitional environments", The Conference on Innovative Data Systems Research, 2005 6] Halatchev, M., & Gruenwald, L., "Estimating missing values in related sensor data streams", International Conference on Management of Data, 2005 7] Iannacchione, V. G., "Weighted sequential hot deck imputation macros", Proceedings of the SAS Users Group International Conference, 1982 8] Nan Jiang, "Discovering Association Rules in Data Streams Based On Closed Pattern Mining", SIGMOD Ph.D. Workshop on Innovative Database Research, 2007 9] Li, Y., & Liu, Z. T., & Chen, L., & Cheng, W., & Xie, C.H Extracting minimal non-redundant association rules from QCIL The 4th International Conference on Computer and Information Technology, 2004 10] Little, R 1. A., & Rubin, D. B., "Statistical analysis with missing data", New York: John Wiley and Sons, 1987 II] McLachlan, G., & Thriyambakam, K., "The EM algorithm and extensions", New York: John Wiley & Sons, 1997 12] Mitchell, T., "Machine Learning", McGraw Hill, 1997 13] Papadimitriou, S., & Sun, 1., & Faloutsos, C., "Streaming pattern discovery in multiple time-series", The International Conference on Very Large Databases, 2005 14] Rubin, D., "Multiple imputations for nonresponce in surveys", New York: John Wiley & Sons, 1987 


15] Shafer, 1., "Model-Based Imputations of Census Short-Form Items In Proceedings of the Annual Research Conference, 1995 16] Taouil, R., & Pasquier, N., & Bastide, Y., & Lakhal, L., "Mining bases for association rules using closed sets", International Conference on Data Engineering, 2000 17] Wilkinson & The AP A Task Force on Statistical Inference, 1999 18] Zaki, M. 1., Hsiao, C. 1., "Efficient algorithms for mining closed itemsets and their lattice structure", IEEE Transactions on Knowledge and Data Engineering, 2005 V5-106 


General Chair f!!\f  Organizing Chairs  f!!\f  f$% \f!!\f  Organizing Co-chairs f    f  f\f   f\f\f   f*!\f!\f.\f  f f  Program Committee Chairs  f\f\f   f!!\f  Publication Chair 0   


200 250 300  The size of dataset/10,000 R es po ns e tim e S    a 0 50 100 150 200  The size of dataset/10,000 R es po ns e tim e S    b 0 10 20 30 40 50 


60  The size of dataset/30,000 R es po ns e tim e S    c Fig. 9 The scalability of our algorithm compared with FP-growth  Paper [12] proposed a way to reduce times of scanning transaction database to reduce the cost of I/O IV. CONCLUSIONS AND FUTURE WORK This paper first discusses the theory of foundations and association rules and presents an association rules mining algorithm, namely, FP-growth algorithm. And then we propose an improved algorithm IFP-growth based on many association rules mining algorithms. At last we implement the algorithm we propose and compare it with algorithm FPgrowth algorithm. The experimental evaluation demonstrates its scalability is much better than algorithm FP-growth 177 Now, lets forecast something we want to do someday Firstly, we would parallelize our algorithm, because data mining needs massive computation, and a parallelable environment could high improve the performance of the algorithm; Secondly, we would apply our algorithm on much more datasets and study the run performance; At last, we would study the performance when the algorithm deal with other kinds of association rules  REFERENCES 1] S. Sumathi and S. N. Sivanandam. Introduction to Data Mining and its Applications, Springer, 2006 2] V. J. Hodge, J. Austin, A survey of outlier detection 


methodologies, Artificial Intelligence Review, 2004, 22 85-126 3] Han, J. and M. Kamber. Data Mining: Concepts and Techniques. Morgan Kaufmann, San. Francisco, 2000 4] Jianchao Han, Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases, Journal of Advanced Computational Intelligence and Intelligent Informatics 2006, 10\(3 5] Jiuyong Li, Hong Shen, Rodney Topor. Mining Informative Rule Set for Prediction. Journal of Intelligent Information Systems, 2004, 22\(2 6] Jianchao Han, and Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases. Journal of Advanced Computational Intelligence, 2006, 10\(3 7] Doug Burdick, Manuel Calimlim, Jason Flannick Johannes Gehrke, Tomi Yiu. MAFIA: A Maximal Frequent Itemset Algorithm. IEEE Transactions on Knowledge and Data Engineering, 2005, 17\(11 1504 8] Assaf Schuster, Ran Wolff, Dan Trock. A highperformance distributed algorithm for mining association rules. Knowledge and Information Systems, 2005, 7\(4 458-475 9] Mohammed J. Zaki. Mining Non-Redundant Association Rules. 2004, 9\(3 10] J.Han, J.Pei, Y.Yin, Mining frequent patterns without candidate generation, Proceedings ACM SIGMOD 2000 Dallas, TX, May 2000: 1-12 11] P.Viola, M.Jones. Rapid Object Detection Using A Boosted Cascade of Simple Features. Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 2001 12] Anthony K. H. Tung, Hongjun Lu, Jiawei Han, Ling FengJan. Efficient Mining of Intertransaction Association Rules. 2003, 154\(1 178 


For each vertex b in g form j forests body\(a, g, i s.t. bodyAnt\(a, g, i a, g, i with itemsets Ant\(b b and each subset of itemsets Ant\(b b in P\(a, g, j Assign to each leaf l of trees bodyAnt\(a, g, i bodyCons\(a, g, i a fresh variable Vm,M, m, M = size\(itemset\(l Assign to each leaf l of tree headAnt\(a, g, j the variable assigned to itemset l in some leaf of some tree bodyCons\(a, g, i TABLE II.  EXPERIMENTAL DATA Conf. #rules #pruned #dftrs PtC 0.5 6604 2985 1114 0.6 2697 2081 25 0.75 1867 1606 10 0.8 1266 1176 0 0.95 892 866 1 0.98 705 699 1 DSP 0.5 2473 1168 268 0.6 1696 869 64 0.75 1509 844 89 0.8 1290 1030 29 0.95 1032 889 15 0.98 759 723 1 Arry 0.5 770 492 82 0.6 520 353 60 0.75 472 327 39 0.8 408 287 22 0.95 361 255 25 0.98 314 243 30  Our induction algorithm has been launched for each combination of thresholds. Our scheme eliminates all redundant rules in the sense of [25, 31], i.e. those association rules that are not in the covers. All the meta-rule deductive schemes implicitly included in [25] and [31] are induced by our method. The percentage of pruning, thus, outperforms [25 


The results produced for k=3, support 0.25 and confidences between 0.7 and 0.99 are shown in Fig. 3, in terms of pruning percentage \(vertical axis when applied to low confidences \(from 0.7 to 0.9 The percentage of pruning achieved diminishes as the confidence is superior to 0.9. Nevertheless, the pruning is effective with confidence of 0.99 in the majority of cases Pruning at Support = 0.25 0,00 5,00 10,00 15,00 20,00 25,00 30,00 35,00 40,00 45,00 50,00 0,7 0,8 0,9 0,95 0,99 Confidence P ru n in g L e v e l Case 1 Case 2 Case 3  Figure 3.  Pruning experiences at support 0.25  V. DISCUSSION AND CHALLENGES It is important to discuss the technique presented here with focus on the purpose the technique pursues:  to produce semantic recommendation The reader should have noticed that the algorithm presented 


relies strongly on "choice". For instance, the algorithm chooses ears in the graph to form an order for elimination, and the choice is arbitrary. This strategy is essential to maintain low complexity \(polynomial practical. Nevertheless, a warned reader may conclude that this arbitrary choice implies that there are many compactions to produce and therefore the approach as a whole does not show to produce an optimal solution. And the reader is right in this conclusion. Since the goal is compaction, the search for an optimal solution can be bypassed provided a substantial level of pruning is achieved To complete the whole view, we describe how web service descriptions are complemented with the association rules as recommendations. In effect, under our scheme, the document describing the web service is augmented with a set of OWL/RDF/S triples that only incorporate the non-pruned rules with the format of Example 1, that is, the set ARmin of the compaction program obtained by our algorithm, together with the thresholds applied to the mining process and a registered URI of a registered description service. The assumptions and defeaters are not added to the web service description. If the associations encoded in the triples are not sufficient for the client \(a search engine, for instance widening of the response to the description service identified by the given URI, and then the assumptions and defeaters are produced. The reasoning task required for deriving all the implicitly published rules is client responsibility Notice that, under this scheme, the actual rules that appear as members of the set initial ARmin set are irrelevant; the only important issue is the size of the set The developed scheme also supports an extension of the algorithm that admits the assignment of priorities to rules and to itemsets, in order to allow the user to produce a more controlled program as output. Nonetheless, the importance of the extension has not been already tested, and therefore it is beyond the subject of the present paper It would be also interesting to design a scheme that supports queries where the client provides an itemset class and values for support and confidence and the engine produces a maximal class of inferred associated itemsets as a response. This scheme is also under development, so we have not discussed this aspect here 


VI. CONCLUSION In this paper, we have presented a defeasible logic framework for managing associations that helps in reducing the number of rules found in a set of discovered associations. We have presented an induction algorithm for inducing programs in our logic, made of assumption schemas, a reduced set of association rules and a set of counter-arguments to conclusions called defeaters, guaranteeing that every pruned rule can be effectively inferred from the output. Our approach outperform those of [17], because all reduction compactions presented there can be expressed and induced in our framework, and several other patterns, particular to the given datasets, can also be found. In addition, since a set of definite clauses can be obtained from the induced programs, the knowledge obtained can be modularly inserted in a richer inference engine Abduction can be also attempted, asking for justifications that explain the presence of certain association in the dataset The framework presented can be extended in several ways Admitting defeaters to appear in the head of assumption, to define user interest Admitting arithmetic expressions within assumptions for adjustment in pruning Admitting set formation patterns as itemset constants Extending the scope, to cover temporal association rules REFERENCES 1]  R. Agrawal, and R. Srikant: Fast algorithms for mining association rules In Proc. Intl Conf. Very Large Databases. \(1994 2]  A. V. Aho, J. E. Hopcroft, J. Ullman. The design and analysis of computer algorithms, Addison-Wesley, 1974 3]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher, A. Rock: A Family of Defeasible Reasoning Logics and its Implementation. ECAI 2000: 459-463 4]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher: Representation results for defeasible logic. ACM Trans. Comput. Log. 2\(2 2001 5]  A. Basel, A. Mahafzah, M. Al-Badarneh: A new sampling technique for association rule mining, Journal of Information Science, Vol. 35, No. 3 358-376 \(2009 6]  R. Bayardo and R. Agrawal: Mining the Most Interesting Rules. In Proc of the Fifth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 145-154, \(1999 


7]  R. Bayardo, R. Agrawal, and D. Gunopulos: Constraint-based Rule Mining in Large, Dense Databases. Data Mining and Knowledge Discovery Journal, Vol. 4, Num-bers 2/3, 217-240. \(2000 8]  A. Berrado, G. Runger: Using metarules to organize and group discovered association rules. Data Mining and Knowledge Discovery Vol 14, Issue 3. \(2007 9]  S. Brin, R. Motwani, J. Ullman, and S. Tsur: Dynamic itemset counting and implication rules for market basket analysis. In Proc. ACMSIGMOD Intl Conf. Management of Data. \(1997 10] L. Cristofor and D.Simovici: Generating an nformative Cover for Association Rules. In ICDM 2002, Maebashi City, Japan. \(2002 11] Y. Fu and J. Han: Meta-rule Guided Mining of association rules in relational databases. In Proc. Intl Workshop on Knowledge Discovery and Deductive and Object-Oriented Databases. \(1995 12] B. Goethals, E. Hoekx, J. Van den Bussche: Mining tree queries in a graph. KDD: 61-69. \(2005 13] G. Governatori, D. H. Pham, S. Raboczi, A. Newman and S. Takur: On Extending RuleML for Modal Defeasible Logic. RuleML, LNCS 5321 89-103. \(2008  14] G. Governatori and A. Stranieri. Towards the application of association rules for defeasible rules discovery In Legal Knowledge and Information Systems, JURIX, IOS Press, 63-75. \(2001 15] J. Han, J. Pei and Y. Yin: Mining frequent patterns without candidate generation. In Proc. ACM-SIGMOD Intl Conf. Management of Data 2000 16] C. Hbert, B. Crmilleux: Optimized Rule Mining Through a Unified Framework for Interestingness Measures. DaWaK: LNCS 4081, 238247. \(2006 17] E. Hoekx, J. Van den Bussche: Mining for Tree-Query Associations in a Graph. ICDM 2006: 254-264 18] R. Huebner: Diversity-Based Interestingness Measures For Association Rule Mining. Proceedings of ASBBS Volume 16 Number 1, \(2009 19] B. Johnston, Guido Governatori: An algorithm for the induction of defeasible logic theories from databases. Proceedings of the 14th Australasian Database Conference, 75-83. \(2003 20] P. Kazienko: Mining Indirect Association Rules For Web Recommendation. Int. J. Appl. Math. Comput. Sci., Vol. 19, No. 1, 165 186. \(2009 21] M. Klemettinen, H. Mannila, P. Ronkainen, H. Toivonen, and A Verkamo: Finding interesting rules from large sets of discovered association rules. In Proc. 3rd Intl Conf. on Information and Knowledge 


Management. \(1994 22] M. J. Maher, A. Rock, G. Antoniou, D. Billington, T. Miller: Efficient Defeasible Reasoning Systems. International Journal on Artificial Intelligence Tools 10\(4 2001 23] C. Marinica, F. Guillet, and H. Briand: Post-Processing of Discovered Association Rules Using Ontologies. The Second International Workshop on Domain Driven Data Mining, Pisa, Italy \(2008 24] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal: Closed sets based discovery of small covers for association rules. In Proc. BDA'99 Conference, 361-381 \(1999 25] N. Pasquier, R. Taouil, I. Bastide, G. Stume, and  L. Lakhal: Generating a Condensed Representation for Association Rules. In Journal of Intelligent Information Systems, 24:1, 29-60 \(2005 26] P. Pothipruk, G. Governatori: ALE Defeasible Description Logic Australian Conference on Artificial Intelligence.  110-119 \(2006 27] J. Sandvig, B. Mobasher Robustness of collaborative recommendation based on association rule mining, Proceedings of the ACM Conference on Recommender Systems \(2007 28] W. Shen, K. Ong, B. Mitbander, and C. Zaniolo: Metaqueries for data mining. In Fayaad, U. et al. Eds. Advances in Knowledge Discovery and Data Mining. \(1996 29] I. Song, G. Governatori: Nested Rules in Defeasible Logic. RuleML LNCS 3791, 204-208 \(2005 30] H. Toivonen, M. Klemettinen, P. Ronkainer, K. Hatonen, and H Mannila: Pruning and grouping discovered association rules. In ECML Workshop on Statistics, Machine Learning and KDD. \(1995 31] M. Zaki: Generating Non-Redundant Association Rules. In Proc. of the Sixth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 34-43, \(2000 32] w3c. OWL Ontology Web Language Reference. In http://www.w3.org/TR/2004/REC-owl-ref-20040210 33] w3c. RDF/XML Syntax Specification. In: http://www.w3.org/TR/rdfsyntax-grammar 34] w3c. RDF Schema. In: http://www.w3.org/TR/rdf-schema      


 8   2  3\f            8  D    F  \b 1 8 & #J      b 1  1  4    2  


4 1    9  E 1  2 4 1    9 1   4      8 2  8 1  D 1        1 1  b 


     b b b b b  K            8          2 D 9   F  \b 1 8 ,+J  9 


     b 1     1 2  9 1  12 L 1   9  8       1  2      2   


     b b b b b  K            2  0 \b f  b\f      9       


  8 2   E 1   1     M13 31L 1    b  8E 1   1 #3\b?### 1  1     E 1   1 \b?###3        


1   1   b 1  2 2 18 2     8              1    2 \b 1    2  


    2          2   1 L 2 1   1   L 2 2    2 1  2        


    8  2H D \b A             2  2H D \b A 2 \f 3%\f  f   4%\f f !  , \f\b  C    2    2 


 6    3 1      253 6   1 L 2    6   1         f\b3\f       


               1     1     8 2    E       2  1   


     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



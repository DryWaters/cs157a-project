Mining Association rules in Medical Data Based on Concept Lattice Wei Wang 1,2 Yaohua Wu 1  1\ School of Control Science and Engineering 2\School of Management Shandong University Shandong University of Technology Jinan, Shandong, China Zibo,Shandong, China 
ww@sdut.edu.cn Mike.wu@263.net ww@sdut.edu.cn   
 Concept lattice \(Galois lattice\n efficient tool for data analysis and rule extraction from multidimensional space.  This paper introduces some definitions of concept lattice and compares two methods of data inductive: AOI and concept lattice. After introduce the context, actual medical data is discretized and concept lattice and Hasse diagram are 
 Abstract 
constructed to generate the concept hierarchy, and finally some strategies is used to extract interesting association rules Experiment proves that concept lattice is an effective tools on mining association rules in medical database analysis 
  
Index Terms \226Concept lattice, association rules, data mining  I  I NTRODUCTION   Raw medical data are voluminous and heterogeneous. All these data-elements may bear upon the diagnosis, prognosis and treatment of the patient, and must be taken into account in data mining research d m o re m e dical i n s u rance institutes employ historical medical data as a guide tool, but the stored information becomes hardly to use if it is not available in an easily comprehensible format.  Thus, it is essential to develop methods for efficient mining in medical 
databases  Due to the sparsity of data in multidimensional space of medical databases, it is difficult to find strong associations among data items at low or primitive levels of abstraction in applications. Different users car e about association rules in different levels. Data mining systems should provide capabilities to mine association rules at multiple levels of abstraction and traverse easily among different abstraction spaces   The concept hierarchical structure defines a mapping sequence from low level/specifical concept sets to higher/more general level sets, from which association rules can be mined  In philosophy, concept is defined as a thought unit composed of two parts: extension and intention. Based on this philosophical thought, Wille opos ed th e f o r m al con c ept theory to discover and disclosure concepts in 1982. Concept lattice, also called the Galois lattice, its construction is the 
precondition of formal concept analysis. Each node in the concept lattice is a formal concept, which is composed of two parts: external part is the instances covered by the concept internal part is description of the concept which covers the common features of the instances  Researchers use Hasse diagram to describe the generalization and the specialization of concepts Consequently, concept lattice is used in varies areas information retrieval, software engineer and knowledge discovery, etc  This paper is organized as follows: first introduces some definitions of concept lattice and multilevel association rules and then compares two attribute induction methods: AOI and Concept lattice, and proposed an algorithm of construct concept lattice. In part IV, we generalized the actual medical data by concept lattice, and extract multilevel association rules from the Hasse Diagram II  
B ASIC D EFINITIONS   The basic definitions about concept lattice are introduced by many references  Def 1 Formal Context  Formal context is defined as a triple U,A,I  U is a set of objects A is a set of attributes 
002 
 I is the binary relation between U and A If   x aI 
 then x la denote as object x has attribute a  Def 2 Concept of Formal Context 
005 and  B X 
002\003\002 004 
 
    I B xx U a Bxa B A 
    I X aa A x Xxa X U 
002\003\002 004 
  If  X B 
 then we call  XB is a Formal Concept or Concept X is defined as E xtent of concept, and B 
  
 I ntent of concept Def 3 Concept Lattice  For Formal context, there is a unique partial-order set in relation I This partial-order set produce a lattice structure and this lattice L induced by context U,A,I is called Concept Lattice Def 4 Super Concept and Direct Super Concept If 12 12  X XBB 
004\006\007 then 22  X B is called the Super Concept of 11  X B 
is defined as or denote as 
 11 2 2  X BXB 
if 33  XB 
254\005 let 11  XB 
  When 11 2 2   X BXB 
 11  X B In Hasse diagram, it is presented as an edge 
b b b 33 22  XB XB b then 22  X B is called the Direct Super Concept of 


is the super concept of 11  X B  Fig.1 Super Concept and Direct Super Concept  Fig.1 shows the Super Concept and Direct Super Concept in which 44  XB but is not the direct super concept of 11  X B      mn XB  004  then start Depth-First Traversal along the path from bottom to up to find all super concept of C t he intent of some super concept is not in _ I na any more  22  XB  33  XB    11  XB  55  X B in the not too distant future  Then it will delay the observation of association rules between these diseases  Therefore, AOI induction method has some shortcoming when executes medical data. The obvious problems are as follow 1 Threshold setting: improper threshold setting will not upgrade to appropriate conceptual level. High threshold may miss the meaningful association rules in low level; low threshold may get quantities uninteresting rules which are hard to understand by users 2 Complex multi-layer relationship and multi-potential relationship of multi-attributes, is hard to induct by AOI method B. Attribute induction based on the Concept Lattice  In attribute induction process, concept lattice always keeps complete data information, not replacing attribute values by higher concepts [7 o n s equ e n t l y it can avoid  losing useful information during the induction process meanwhile, it can display the multi-layer or multi-potential relationship of attributes. So, it is an effective method to extract association rules from medical data  The main strategy of the attribute induction algorithm based on concept lattice is: discretize attributes in the medical database; construct the concept lattice and Hasse diagram users select interesting attribute set _ I na from the relational database, and then extract association rules from the Hasse diagram C. Construct Algorithms of Concept Lattice  Different construction of concept lattice can derive a unique lattice for the same data. Many algorithms have been proposed for generating the concept lattice from a binary relation. The algorithms are generally divided into two types batch and incremental. Bordat t er[9] an d Nou r in e[10  proposed different batch algorithms to construct the concept lattice  Incremental algorithms can actively adjust the concept lattice and Hasse diagram with new objects. When a new instance is occurs, the algorithm only adjust the corresponding parts, and not reconstruct the concept lattice from scratch. So for active data, incremental algorithms are more efficient than batch algorithms and the typical incremental algorithm is proposed by Godin  The time complexity has been discussed by many references r la rg e s cale con t e x t s o m e  u n i o n  algorithms are studied to construct concept lattice in parallel  t i s prov ed t h at  t w o  s a m e f i e l d an d co n s i s t e nt su b concept lattices can construct th e same concept lattice as the original one D. Extracting association rules from the Concept Lattice  This paper focuses on a method and an algorithm of mining association rules with concept lattice for medical database. Luxenburger discussed a method for extracting association rules with concept lattice [13  W a n g i m p r o v ed  Godin\222s incremental algorithm and formally proved that the association rules in their method are non-redundancy association rules a k i an d Og i h ara [15] s t u d ied th e theoretical foundation of association rules based on formal concept lattice and described a formal framework for mining association rules  Analyze each direct super concept of the bottom nodes in Hasse diagram. If exist concept C let _ I na IntentC  Def 5 Multilevel association rules  Rules generated from association rule mining with concept hierarchies are called multiple-level or multilevel association rules, since they co nsider more than one concept level III  A TTRIBUTE INDUCTION B ASED ON C ONCEPT L ATTICE  A. AOI method  Attribute Oriented Induction \(AOI\major method of attribute induction, which is first proposed in 1991  It i s a knowledge mining method based on generalization, oriented relational database query  The main thought of AOI is: use database query collect task-related data; then generalize each attribute by inspecting numbers of different value, construct corresponding concept hierarchy tree by relevant background knowledge. In generalization, if under the threshold, the lower level concept will be upgrade to a higher level along the concept tree and finally translate the results into logical rules. Each attribute has only one generalization path from the bottom to the top of the tree  Medical data have the specific characteristic that some diseases have low concurrency now, but will have high concurrency after a period of time. AOI method always ignores the instances whose concurrencies are under the threshold. This can ignore new diseases concurrency instances, which may increase fast  until  Record the traversal path, and then get the generalized path. If the extent number of some node is less than the threshold, then record the concept of this node IV  E XPERIMENT A NALYSIS  44  XB 


A. Context of medical data  In 2008, in order to understand the health insurance insured health and health interventions for the situation Wendeng medical insurance institutions do free checkup for retirees and older urban residents in high-risk insured populations by using the basic medical insurance fund and the balance of value-added parts  Checkup includes routine physical examination items and blood lipids, blood glucose, liver function, Hepatobiliary and Pancreatic spleen and lower abdominal color Doppler ultrasound, chest X-rays, electrocardiogram, etc. This paper mines the checkup data of Wendeng\222s retirees and older urban residents, with a view to mining the useful rules to help health interventions  Statistical sample has 12,406 cases, which has sample name, age, gender, home address, telephone number, past medical history, physical results and other properties. Among them,  checkup result including more than 70 kinds of disease hyperlipidemia, fatty liver, diabetes, coronary heart disease gallstones, cholecystitis, old myocardial infarction, cancer arrhythmia, bone hyperplasia, cerebral thrombosis, prostate disease, kidney stones, gastritis, lumbar disc herniation atherosclerosis, bronchitis, tuberculosis, breast cancer pulmonary heart disease and so on B. Data Discretization  Attributes in medical database might be categorical or quantitative. Categorical data has finite values. Quantitative data is numeric. To construct concept lattice, we need to discretize the numeric attributes in statistical database, and marked as class identity, for the interesting data, we create a new database D by query  The primary key of D is the sample number \(1-12406 Row or tuple is each sample record, and columns are the properties of the sample. If the person is suffering from some kind of disease, we only concern about whether the disease is or not. If the person has the disease, then the corresponding value in this tuple for the disease is 1, otherwise is 0. The name, telephone and other attributes are non-inductive, that is there is no higher level concept of them, so we remove them from the primitive datasheet D. Because the investigation is about the health of retirees, attribute \221age\222 is no longer need to generalized, so we also remove it from D. However, in concept lattice, the primary key of the datasheet generates the extent of the concept, so should not delete it.  Accordingly, we delete the attribute \221name\222, at the meanwhile add \221number\222 attribute as the primary key. Number is between 1 and 12406  In this paper, we choose eight common diseases of high incidence \(547.15 9.83 hose are hypertension  diabetes, coronary heart disease, hyperlipidemia, fatty liver gallstones, cholecystitis and myocardial infarction respectively. Our goal is to guide the health interventions by generalize these eight attributes with concept lattice and extract association rules  After the primary induction of D, the new data sheet  for next generalization is achieved, shown in Table I TABLE I N EW D ATASHEETS P ART O F  Id A B C D E F G H 1 1 1 0 1 1 0 0 1 2 1 0 1 1 1 1 0 1 3 1 1 1 1 0 0 1 0 4 0 1 1 1 0 1 1 0 5 1 1 1 0 1 0 1 1          12406 0 1 0 0 1 1 0 0 A-hypertension, B-diabetes,   C-coronary heart disease, D-hyperlipidemia E-fatty liver,  F-gallstones, G-cholecystitis,  H-myocardial infarction C. Construct concept lattice and Hasse diagram  For inductive attribute set _ I na We analyze the relationship between A~E, then _ I na A,B,C,D,E  The classic incremental algor ithm of constructing concept lattice is proposed by Godin di n g a n e w i n st an ce w e  just modify  part of the lattice without regenerating it from the begining. The method is suitable for the actual applications  Fig. 2 is the Hasse Graph of this case. It should be denoted that the Hasse Graph of table I is certainly a complex graph, it is just a part of the whole  Fig.2 Hasse Diagram of D D. Mining the association rules For example, we consider the association of A with B, D E firstly. From the bottom to the top, then we start at the node 1\,B,D,E}\ finding the supe r concept of this concept 1,5 A,B,E}\which are the super concept of\(\(1\,B,D,E Using the depth-first search method, we get several generalized paths between {A,B,D,E}  and {A A,B,D,E A,B,D AB A}, {A,B,D,E A,D,E AE A}, {A,B,D,E A,B,E AE A A,B,D,E A,B,E AB A All paths are shown in Fig. 3 


   sup   6.199 85.550 sup   7.246 port AB D port AB  A, B=>D= [support=6.199%, confidence=85.550  3     sup   5.626 80.486 sup   6.199 port ABD E port ABD A=>B= [support=54.715%, confidence=13.243  2  Fig.3  A, B,D=>E=[support=5.626%,confidence=80.486   From above association rules, it is obviously that strong association exists between A and B, D, E. That is, for retirees in Wendeng, hypertension is a common diseases, its incidence rate is 54.715%. For the retirees suffering from hypertension the probability of diabetes is 13.243%. For the Patients suffering from hypertension and diabetes, the probability of hyperlipidemia is 85.550%. It is proved that hyperlipidemia is a and other common diseases. Provides the procedure of total execute progress from attribute generalization, construction of Hasse diagram to mining association rules from it. Different strategies are considered. Mining result of the actual checkup data shows that concept lattice is efficient and effective in medical data mining  However, there are many variants and optimizations which are need to be considered. Such as discretize quantitative data, union of association rules in distributed medical databases, etc. Otherwise, medical data mining must copes with various data sources, data structures, and  D AB  E ABD complication for most people who are retiree and is suffering from hypertension and diabetes in Wendeng  Through the same process, we can derive other association rules about the complications of other diseases. By setting thresholds, we select the strong association rules to further analysis which are intuition, understandable and can help the health care institutions to grasp basic trends in data take the health interventions, and formulate rational decisions Concept lattice technique will play an increasing role in this area  V  C ONCLUSION  Vol.40, No.9, pp.7781  6  J. Han, Y. Cai, and N. Cercone, \223Knowledge discovery in databases: an attribute-oriented approach,\224 In Proceedings of the 18th International Conference on Very Large DataBases 1992, pp.547-559 7  Wang De-xing, Hu Xue-gang, et al, \223Attribute-Oriented Algorithm Based on Extended Concept Lattice,\224 Journal of Shanghaijiaotong University  Vol. 43, no.3, 2009, pp.446-484 8  Bordat, J.P, \223Practical Calculation of Lattice Galois correspondence,\224 Math\351matiques et Sciences Humaines 96, 1986, pp. 31-47 9  Ganter, B, \223Two Basic Algorithms in Concept Analysis,\224 Preprint 831 Technische Hochschule Darmstadt 1984   Norris, E. M, \223An Algorithm for Computing the Maximal Rectangles in a Binary Relation,\224 Revue Roumaine de Math\351matiques Pures et Appliqu\351es 23\(2\78, pp.243-250   R. Godin, R. Missaoui and H. Alaoui, \223Learning algorithms using a Galois lattice structure,\224 In Proc. 1991 IEEE International Conference on Tools for AI San Jose, CA  1991, pp.22-29   Zongtian Liu, Liansheng Li and Qing Zhang, \223Reasearch on a Union Algorithm of Multiple Concept Lattice,\224 RSFDGrC\22203 LNAI 2639 Berlin: Springer- Verlag Heidelberg  2003, pp.533-540   M.Luxenburger,\223Implications partielles dans un contexte,\224 Mathematiques Informatique et Sciences Humaines, 29\(113\, 1991 pp.35-55   Z.H. Wang, K.Y. Hu, X.G. Hu, Z.T. Liu, D.C. Zhang, \223Genernal and incremential algorithms of rule extraction based on concept lattice,\224 Computer Journal Vol.22 ,1999, pp.66-70   M.J. Zaki, M. Ogihara, \223Theoretical foundations of association rules,\224 Proceedings of the 3rd ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery Seattle, Washington, USA,1998 pp.1-8 t  t  t   eneralized paths between {A,B,D,E}  and {A If the threshold is 2, then we extract the following association rules about A and B, D,E : A=>B, A=>E, AE=>D AB=>D, AE=>B, etc. We calculate the confidence of them 2\d\(3 1 Confidence\(A=>B\\(B A   sup   7.246 13.243 sup   54.715 port A B port A     Journal of Tsinghua University  This paper adopts concept lattice to obtain a hierarchical expression of checkup medical data, achieving some association rules between hypertension unavoidable missing values for both technical and social reasons. These are interesting topics for future research  R EFERENCES  1  Krzysztof J. Cios, William Moore, \223Uniqueness of medical data mining,\224 Artificial Intelligence in Medicine 26, 2002, 1-24 2  J. Han, M. Kamber, \223Data mining: Concepts and Techniques, second edition,\224 Morgan Kaufmann   San Francisco  2006, pp.162-165 3  R. Wille, \223Restructuring lattice theory: An approach based on hierarchies of contexts,\224 In: I. Rival Editor Ordered Sets NATO ASI, No. 83 Reidel Dordrecht 1982, pp.445\226470 4  R.Godin, \223Incremental concept formation algorithm based on Galois concept\ lattices,\224 Computational Intelligence 1995, 11\(2\pp. 246-267 5  Hu Keyun, Lu Yuchang, and Shi Chunyi, \223Advances in concept lattice and its application,\224 


sets, ?t, where F ? ?t, i.e., the source ?les in F changed together To ?nd the pair of source ?les, fi and fj , such that fi  fj i.e. fj is impacted by a change in fi con?dence and support for each fi, fj ? S, with i = j, and consider the top N of the list of source ?le pairs ranked by their con?dence and support in decreasing order 2.2 Granger Causality Granger causality test is a technique for determining whether one time series is useful in forecasting another [4]. It has become popular in recent years in bioinformatics to discover gene and metabolic pathways of an organism [8]. The basic idea is that a cause cannot come after the e?ect, then if a variable x a?ects a variable z, the former should help improving the predictions of the latter variable. We use this notion to capture whether changes performed in a source le could cause, in a Granger sense, a change in another source ?le. Let fk\(t of the source ?le fk de?ned as fk\(t 8  1, fk ? ?t 0, fk /? ?t i.e., fk\(t otherwise. The simplest bivariate Granger test between two time series f1\(t t tion [5], which consists of the following bivariate and univariate autoregression, solved by estimating the ordinary least squares f2\(t t? 1 t? 2 t? p 1f2\(t? 1 t? 2 t? p t f2\(t t?1 t?2 t?p t where p is the lag length, which can be estimated with various criteria [5], u\(t t cally distributed random variables. To test whether f1\(t Granger-cause f2\(t H0: f1 does not Granger-cause f2 H0 : ?1 = ?2 =    = ?p = 0 which can be implemented by calculating the sum of squared residuals \(RSS RSS1 


TX t=1 bu\(t TX t=1 be\(t The null hypothesis is rejected if S RSS0 ?RSS1 RSS1/\(T ? 2p? 1 is greater than the 5% critical value for an F \(p, T ? 2p? 1 distribution 164            b   b               


 f                         Figure 1: Precision and Recall To ?nd the pair of source ?les, fi and fj , such that fi  fj fj is impacted by a change in fi i = j, we consider the top N in the list of pair of source ?les ranked by S in decreasing order 3. PRELIMINARY EMPIRICAL RESULTS This section reports an empirical study we performed with the aim of getting preliminary insights about the proposed change impact analysis approach. The goal of this study is to analyze to what extent Granger causality can be used as a complement to association rules to predict source code ?les change impact by using data from versioning systems. The quality focus is the increase of precision / recall in predicting change impacts, as well as the capability of di?erent techniques to detect complementary change impact sets. The perspective is of a maintainer interested to understand what 


les could be potentially a?ected by changes occurring in a given ?le. The context consists of change sets extracted from the versioning history of Samba1a well-known ?le and print service developed to ensure interoperability between Microsoft Windows and Unixes. Speci?cally, we analyzed 10531 snapshots, from release 1.9.16 to release 3.0.0 and restricted our analysis to ?les belonging to the Samba daemon \(i.e., smbd only 5265 dict change impacts, using the actual changes occurring in these snapshots as an oracle for evaluating the performances of our prediction Figure 1 shows, for di?erent values of top-n \(i.e., links with highest strength, increasing from the left to the right for di?erent techniques \(association rules, Granger causality, and the combination of both recall obtained when identifying the change impact of a class. Precision is de?ned as the ratio between the number predicted true changes and the total number of predicted changes, while recall is de?ned as the ratio between the number of predicted true changes and the total number of true changes As it can be seen, for lower values of n Granger starts with a high precision \(90 increasing top-n to about 70%, without positively increasing the recall. The precision for association rules starts lower 1http://www.samba.org       1  2 3 4 5 3 6 7 8 


9  4  3 2 8   7   3   A B C D @ A B E F G H D I F G H D I   A B C D  J K L M N M K O P Q M P R M M P P O M R K O J K Q M M M M O Q R K M O P K 


O S K S K O S M O L L R K O O Q O N S L R P O P R M S S N S K Q L O L Q Figure 2: True positive impacts for association rules Granger, and the combination of both 75 82%, then remains almost constant. Finally, the precision for the combination of the two techniques starts very high 100%, with, however, few links retrieved to ? 75%, and ?nally rises again to ? 82%. Overall, the combination of both techniques seems to exhibit the best precision/recall compromise, i.e., to start with a very high precision, but then to keep it as high as association rules The complementarity of the two techniques is even more evident when looking at Figure 2, which shows, for di?erent values of top-n, the number of true impacts found by Granger causality \(and not found by association rules association rules \(and not by Granger causality found by both techniques at the same time. This ?gure shows that the intersection between the two techniques is always lower \(from 7 vs 37 and 31 for top-100, up to 25 vs 50 and 56 for top-200 one technique only Finally, Figure 3 shows an excerpt of an impact graph highlighting impact relations identi?ed by association rules plain lines dotted lines bold lines related to Samba authentication \(auth_*.c responsible of handling errors providing requests 


to any connection to the Samba server dling user ids. As it can be noticed, auth_* ?les are strongly coupled, and exhibit dependencies highlighted by both techniques. Changes performed to auth_* ?les immediately impact on reply.c and on uid.c, as shown by relations identi?ed by association rules. Instead, the graph shows that changes are propagated only after a while to error.c: in fact the change impact relation is identi?ed by Granger causality only. For instance, on Aug 8, 2001 both auth_* ?les and reply.c \(revision 1.316 note \(smbd/auth server: Doco we want to use cli nt error here soon smbd/password.c management needs to be updated soon. This happened on Aug 27, 2001 \(commit note: . . . added automatic mapping between dos and nt error codes went a change \(to revision 1.6 The performed study su?ers of some threats to validity In particular, threats to internal validity, as this kind of impact analysis \(Granger test and its combination with as165 Figure 3: Excerpt of impact graph sociation rules signi?cant correlation between a change occurring to a ?le and future changes occurring to other ?les. Our approach is purely statistical, hence there is no guarantee to ensure source code change causality. Also, the study can su?er of threats to external validity, as this is only one, small preliminary study. Further, larger studies are desirable to better assess the performances and the scalability of the proposed approach 4. EMERGING RESEARCH DIRECTIONS Driven by bioinformatics, where the Granger causality test is largely used to derive causal relationships among different elements, such as genes and proteins, we have developed a novel change impact analysis method that uses the Granger causality test to learn impact relationships among software artifacts. The main idea of the method is to infer the mutual dependencies between software artifacts by measuring the statistical con?dence that the time series representing the history of changes of a software artifact can be used to predict the changes of another artifact. The problem is therefore posed as a statistical test, evaluating the quality 


of forecasting of a variable given another one In this paper the method has been compared with the application of association rules [9, 10], and the preliminary results suggest that the Granger causality test can be a viable approach to change impact analysis, as it complements existing approaches. As a matter of fact, while association rules capture co-changes, Granger causality helps learning consequent changes. While not shown in this paper for the sake of space, we have compared the results of the proposed impact analysis method against traditional methods based on static analysis, and also in this case we found that they are able to highlight complementary, yet useful, impact relationships. This opens the way towards an eclectic impact analysis approach that combines existing methods, to overcome the limitation of the individual methods, and provides software engineers with a richer set of information useful to assess the impact of a change There are several directions in which the work presented here can be expanded. Of course, a ?rst direction is the development of further empirical studies to fully understand advantages and limitation of the proposed method, to compare it with other \(traditional and to develop heuristics for improvement The application of Granger causality depends entirely on the appropriate selection of variables. In this paper we have used an impulsive \(0,1 in a snapshot. However, other variables should be explored for example the variation of some metric values. Furthermore, the method could be applied for object-oriented system, considering classes and methods instead of functions We are interested to compare the Granger causality approach against the dynamic Bayesian network inference, which is a well-known approach used to derive causal relationships. Finally, we are investigating the use of information theoretic approaches based on mutual information 5. REFERENCES 1] R. Agrawal, T. Imielinski, and A. N. Swami. Mining association rules between sets of items in large databases. In Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data Washington, D.C., May 26-28, 1993, pages 207216 ACM Press, 1993 


2] R. S. Arnold and S. A. Bohner. Impact analysis towards a framework for comparison. In Proceedings of the Conference on Software Maintenance, ICSM 1993 Montreal, Quebec, Canada, September 1993, pages 292301, 1993 3] G. Canfora and L. Cerulo. Impact analysis by mining software and change request repositories. In 11th IEEE International Symposium on Software Metrics METRICS 2005 page 29. IEEE Computer Society, 2005 4] C. W. J. Granger. Investigating causal relations by econometric models and cross-spectral methods Econometrica, 37\(3 5] J. D. Hamilton. Time Series Analysis. Princeton University Press, January 1994 6] A. Hindle, M. W. Godfrey, and R. C. Holt. Mining recurrent activities: Fourier analysis of change events In 31st International Conference on Software Engineering, ICSE 2009, May 16-24, 2009, Vancouver Canada, Companion Volume, pages 295298, 2009 7] J. Law and G. Rothermel. Whole program path-based dynamic impact analysis. In Proceedings of the 25th International Conference on Software Engineering May 3-10, 2003, Portland, Oregon, USA, pages 308318. IEEE Computer Society, 2003 8] N. D. Mukhopadhyay and S. Chatterjee. Causality and pathway search in microarray time series experiment. Bioinformatics, 23\(4 9] A. T. T. Ying, J. L. Wright, and S. Abrams. Source code that talks: an exploration of Eclipse task comments and their implication to repository mining In Proceedings of the 2005 International Workshop on Mining Software Repositories, MSR 2005, Saint Louis Missouri, USA, May 17, 2005. ACM, 2005 10] T. Zimmermann, P. Weisgerber, S. Diehl, and A. Zeller. Mining version histories to guide software changes. In ICSE 04: Proceedings of the 26th International Conference on Software Engineering pages 563572, 2004 166 


General Chair f!!\f  Organizing Chairs  f!!\f  f$% \f!!\f  Organizing Co-chairs f    f  f\f   f\f\f   f*!\f!\f.\f  f f  Program Committee Chairs  f\f\f   f!!\f  Publication Chair 0   


200 250 300  The size of dataset/10,000 R es po ns e tim e S    a 0 50 100 150 200  The size of dataset/10,000 R es po ns e tim e S    b 0 10 20 30 40 50 


60  The size of dataset/30,000 R es po ns e tim e S    c Fig. 9 The scalability of our algorithm compared with FP-growth  Paper [12] proposed a way to reduce times of scanning transaction database to reduce the cost of I/O IV. CONCLUSIONS AND FUTURE WORK This paper first discusses the theory of foundations and association rules and presents an association rules mining algorithm, namely, FP-growth algorithm. And then we propose an improved algorithm IFP-growth based on many association rules mining algorithms. At last we implement the algorithm we propose and compare it with algorithm FPgrowth algorithm. The experimental evaluation demonstrates its scalability is much better than algorithm FP-growth 177 Now, lets forecast something we want to do someday Firstly, we would parallelize our algorithm, because data mining needs massive computation, and a parallelable environment could high improve the performance of the algorithm; Secondly, we would apply our algorithm on much more datasets and study the run performance; At last, we would study the performance when the algorithm deal with other kinds of association rules  REFERENCES 1] S. Sumathi and S. N. Sivanandam. Introduction to Data Mining and its Applications, Springer, 2006 2] V. J. Hodge, J. Austin, A survey of outlier detection 


methodologies, Artificial Intelligence Review, 2004, 22 85-126 3] Han, J. and M. Kamber. Data Mining: Concepts and Techniques. Morgan Kaufmann, San. Francisco, 2000 4] Jianchao Han, Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases, Journal of Advanced Computational Intelligence and Intelligent Informatics 2006, 10\(3 5] Jiuyong Li, Hong Shen, Rodney Topor. Mining Informative Rule Set for Prediction. Journal of Intelligent Information Systems, 2004, 22\(2 6] Jianchao Han, and Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases. Journal of Advanced Computational Intelligence, 2006, 10\(3 7] Doug Burdick, Manuel Calimlim, Jason Flannick Johannes Gehrke, Tomi Yiu. MAFIA: A Maximal Frequent Itemset Algorithm. IEEE Transactions on Knowledge and Data Engineering, 2005, 17\(11 1504 8] Assaf Schuster, Ran Wolff, Dan Trock. A highperformance distributed algorithm for mining association rules. Knowledge and Information Systems, 2005, 7\(4 458-475 9] Mohammed J. Zaki. Mining Non-Redundant Association Rules. 2004, 9\(3 10] J.Han, J.Pei, Y.Yin, Mining frequent patterns without candidate generation, Proceedings ACM SIGMOD 2000 Dallas, TX, May 2000: 1-12 11] P.Viola, M.Jones. Rapid Object Detection Using A Boosted Cascade of Simple Features. Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 2001 12] Anthony K. H. Tung, Hongjun Lu, Jiawei Han, Ling FengJan. Efficient Mining of Intertransaction Association Rules. 2003, 154\(1 178 


For each vertex b in g form j forests body\(a, g, i s.t. bodyAnt\(a, g, i a, g, i with itemsets Ant\(b b and each subset of itemsets Ant\(b b in P\(a, g, j Assign to each leaf l of trees bodyAnt\(a, g, i bodyCons\(a, g, i a fresh variable Vm,M, m, M = size\(itemset\(l Assign to each leaf l of tree headAnt\(a, g, j the variable assigned to itemset l in some leaf of some tree bodyCons\(a, g, i TABLE II.  EXPERIMENTAL DATA Conf. #rules #pruned #dftrs PtC 0.5 6604 2985 1114 0.6 2697 2081 25 0.75 1867 1606 10 0.8 1266 1176 0 0.95 892 866 1 0.98 705 699 1 DSP 0.5 2473 1168 268 0.6 1696 869 64 0.75 1509 844 89 0.8 1290 1030 29 0.95 1032 889 15 0.98 759 723 1 Arry 0.5 770 492 82 0.6 520 353 60 0.75 472 327 39 0.8 408 287 22 0.95 361 255 25 0.98 314 243 30  Our induction algorithm has been launched for each combination of thresholds. Our scheme eliminates all redundant rules in the sense of [25, 31], i.e. those association rules that are not in the covers. All the meta-rule deductive schemes implicitly included in [25] and [31] are induced by our method. The percentage of pruning, thus, outperforms [25 


The results produced for k=3, support 0.25 and confidences between 0.7 and 0.99 are shown in Fig. 3, in terms of pruning percentage \(vertical axis when applied to low confidences \(from 0.7 to 0.9 The percentage of pruning achieved diminishes as the confidence is superior to 0.9. Nevertheless, the pruning is effective with confidence of 0.99 in the majority of cases Pruning at Support = 0.25 0,00 5,00 10,00 15,00 20,00 25,00 30,00 35,00 40,00 45,00 50,00 0,7 0,8 0,9 0,95 0,99 Confidence P ru n in g L e v e l Case 1 Case 2 Case 3  Figure 3.  Pruning experiences at support 0.25  V. DISCUSSION AND CHALLENGES It is important to discuss the technique presented here with focus on the purpose the technique pursues:  to produce semantic recommendation The reader should have noticed that the algorithm presented 


relies strongly on "choice". For instance, the algorithm chooses ears in the graph to form an order for elimination, and the choice is arbitrary. This strategy is essential to maintain low complexity \(polynomial practical. Nevertheless, a warned reader may conclude that this arbitrary choice implies that there are many compactions to produce and therefore the approach as a whole does not show to produce an optimal solution. And the reader is right in this conclusion. Since the goal is compaction, the search for an optimal solution can be bypassed provided a substantial level of pruning is achieved To complete the whole view, we describe how web service descriptions are complemented with the association rules as recommendations. In effect, under our scheme, the document describing the web service is augmented with a set of OWL/RDF/S triples that only incorporate the non-pruned rules with the format of Example 1, that is, the set ARmin of the compaction program obtained by our algorithm, together with the thresholds applied to the mining process and a registered URI of a registered description service. The assumptions and defeaters are not added to the web service description. If the associations encoded in the triples are not sufficient for the client \(a search engine, for instance widening of the response to the description service identified by the given URI, and then the assumptions and defeaters are produced. The reasoning task required for deriving all the implicitly published rules is client responsibility Notice that, under this scheme, the actual rules that appear as members of the set initial ARmin set are irrelevant; the only important issue is the size of the set The developed scheme also supports an extension of the algorithm that admits the assignment of priorities to rules and to itemsets, in order to allow the user to produce a more controlled program as output. Nonetheless, the importance of the extension has not been already tested, and therefore it is beyond the subject of the present paper It would be also interesting to design a scheme that supports queries where the client provides an itemset class and values for support and confidence and the engine produces a maximal class of inferred associated itemsets as a response. This scheme is also under development, so we have not discussed this aspect here 


VI. CONCLUSION In this paper, we have presented a defeasible logic framework for managing associations that helps in reducing the number of rules found in a set of discovered associations. We have presented an induction algorithm for inducing programs in our logic, made of assumption schemas, a reduced set of association rules and a set of counter-arguments to conclusions called defeaters, guaranteeing that every pruned rule can be effectively inferred from the output. Our approach outperform those of [17], because all reduction compactions presented there can be expressed and induced in our framework, and several other patterns, particular to the given datasets, can also be found. In addition, since a set of definite clauses can be obtained from the induced programs, the knowledge obtained can be modularly inserted in a richer inference engine Abduction can be also attempted, asking for justifications that explain the presence of certain association in the dataset The framework presented can be extended in several ways Admitting defeaters to appear in the head of assumption, to define user interest Admitting arithmetic expressions within assumptions for adjustment in pruning Admitting set formation patterns as itemset constants Extending the scope, to cover temporal association rules REFERENCES 1]  R. Agrawal, and R. Srikant: Fast algorithms for mining association rules In Proc. Intl Conf. Very Large Databases. \(1994 2]  A. V. Aho, J. E. Hopcroft, J. Ullman. The design and analysis of computer algorithms, Addison-Wesley, 1974 3]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher, A. Rock: A Family of Defeasible Reasoning Logics and its Implementation. ECAI 2000: 459-463 4]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher: Representation results for defeasible logic. ACM Trans. Comput. Log. 2\(2 2001 5]  A. Basel, A. Mahafzah, M. Al-Badarneh: A new sampling technique for association rule mining, Journal of Information Science, Vol. 35, No. 3 358-376 \(2009 6]  R. Bayardo and R. Agrawal: Mining the Most Interesting Rules. In Proc of the Fifth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 145-154, \(1999 


7]  R. Bayardo, R. Agrawal, and D. Gunopulos: Constraint-based Rule Mining in Large, Dense Databases. Data Mining and Knowledge Discovery Journal, Vol. 4, Num-bers 2/3, 217-240. \(2000 8]  A. Berrado, G. Runger: Using metarules to organize and group discovered association rules. Data Mining and Knowledge Discovery Vol 14, Issue 3. \(2007 9]  S. Brin, R. Motwani, J. Ullman, and S. Tsur: Dynamic itemset counting and implication rules for market basket analysis. In Proc. ACMSIGMOD Intl Conf. Management of Data. \(1997 10] L. Cristofor and D.Simovici: Generating an nformative Cover for Association Rules. In ICDM 2002, Maebashi City, Japan. \(2002 11] Y. Fu and J. Han: Meta-rule Guided Mining of association rules in relational databases. In Proc. Intl Workshop on Knowledge Discovery and Deductive and Object-Oriented Databases. \(1995 12] B. Goethals, E. Hoekx, J. Van den Bussche: Mining tree queries in a graph. KDD: 61-69. \(2005 13] G. Governatori, D. H. Pham, S. Raboczi, A. Newman and S. Takur: On Extending RuleML for Modal Defeasible Logic. RuleML, LNCS 5321 89-103. \(2008  14] G. Governatori and A. Stranieri. Towards the application of association rules for defeasible rules discovery In Legal Knowledge and Information Systems, JURIX, IOS Press, 63-75. \(2001 15] J. Han, J. Pei and Y. Yin: Mining frequent patterns without candidate generation. In Proc. ACM-SIGMOD Intl Conf. Management of Data 2000 16] C. Hbert, B. Crmilleux: Optimized Rule Mining Through a Unified Framework for Interestingness Measures. DaWaK: LNCS 4081, 238247. \(2006 17] E. Hoekx, J. Van den Bussche: Mining for Tree-Query Associations in a Graph. ICDM 2006: 254-264 18] R. Huebner: Diversity-Based Interestingness Measures For Association Rule Mining. Proceedings of ASBBS Volume 16 Number 1, \(2009 19] B. Johnston, Guido Governatori: An algorithm for the induction of defeasible logic theories from databases. Proceedings of the 14th Australasian Database Conference, 75-83. \(2003 20] P. Kazienko: Mining Indirect Association Rules For Web Recommendation. Int. J. Appl. Math. Comput. Sci., Vol. 19, No. 1, 165 186. \(2009 21] M. Klemettinen, H. Mannila, P. Ronkainen, H. Toivonen, and A Verkamo: Finding interesting rules from large sets of discovered association rules. In Proc. 3rd Intl Conf. on Information and Knowledge 


Management. \(1994 22] M. J. Maher, A. Rock, G. Antoniou, D. Billington, T. Miller: Efficient Defeasible Reasoning Systems. International Journal on Artificial Intelligence Tools 10\(4 2001 23] C. Marinica, F. Guillet, and H. Briand: Post-Processing of Discovered Association Rules Using Ontologies. The Second International Workshop on Domain Driven Data Mining, Pisa, Italy \(2008 24] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal: Closed sets based discovery of small covers for association rules. In Proc. BDA'99 Conference, 361-381 \(1999 25] N. Pasquier, R. Taouil, I. Bastide, G. Stume, and  L. Lakhal: Generating a Condensed Representation for Association Rules. In Journal of Intelligent Information Systems, 24:1, 29-60 \(2005 26] P. Pothipruk, G. Governatori: ALE Defeasible Description Logic Australian Conference on Artificial Intelligence.  110-119 \(2006 27] J. Sandvig, B. Mobasher Robustness of collaborative recommendation based on association rule mining, Proceedings of the ACM Conference on Recommender Systems \(2007 28] W. Shen, K. Ong, B. Mitbander, and C. Zaniolo: Metaqueries for data mining. In Fayaad, U. et al. Eds. Advances in Knowledge Discovery and Data Mining. \(1996 29] I. Song, G. Governatori: Nested Rules in Defeasible Logic. RuleML LNCS 3791, 204-208 \(2005 30] H. Toivonen, M. Klemettinen, P. Ronkainer, K. Hatonen, and H Mannila: Pruning and grouping discovered association rules. In ECML Workshop on Statistics, Machine Learning and KDD. \(1995 31] M. Zaki: Generating Non-Redundant Association Rules. In Proc. of the Sixth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 34-43, \(2000 32] w3c. OWL Ontology Web Language Reference. In http://www.w3.org/TR/2004/REC-owl-ref-20040210 33] w3c. RDF/XML Syntax Specification. In: http://www.w3.org/TR/rdfsyntax-grammar 34] w3c. RDF Schema. In: http://www.w3.org/TR/rdf-schema      


 8   2  3\f            8  D    F  \b 1 8 & #J      b 1  1  4    2  


4 1    9  E 1  2 4 1    9 1   4      8 2  8 1  D 1        1 1  b 


     b b b b b  K            8          2 D 9   F  \b 1 8 ,+J  9 


     b 1     1 2  9 1  12 L 1   9  8       1  2      2   


     b b b b b  K            2  0 \b f  b\f      9       


  8 2   E 1   1     M13 31L 1    b  8E 1   1 #3\b?### 1  1     E 1   1 \b?###3        


1   1   b 1  2 2 18 2     8              1    2 \b 1    2  


    2          2   1 L 2 1   1   L 2 2    2 1  2        


    8  2H D \b A             2  2H D \b A 2 \f 3%\f  f   4%\f f !  , \f\b  C    2    2 


 6    3 1      253 6   1 L 2    6   1         f\b3\f       


               1     1     8 2    E       2  1   


     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



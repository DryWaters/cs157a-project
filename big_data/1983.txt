html><head></head><body><pre style="word-wrap: break-word; white-space: pre-wrap;">Impact of  the memory hierarchy on shared memory architectures in multicore programming models Rosa M. Badia, Josep M. Perez, Eduard Ayguade  and Jesus Labarta Barcelona Supercomputing Center and Universitat Polite`cnica de Catalunya Barcelona, SPAIN rosa.m.badia, josep.m.perez, eduard.ayguade, jesus.labarta}@bsc.es Abstract Many and multicore architectures put a big pressure in parallel programming but gives a unique opportunity to propose new programming models that automatically exploit the parallelism of these architectures. OpenMP is a very well known standard that exploits parallelism in shared memory architectures. SMPSs has recently been proposed as a task based programming model that exploits the parallelism at the task level and takes into account data dependencies between tasks. However, besides parallelism in the programming, the memory hierarchy impact in many/multi core architectures is a feature of large importance. This paper presents an evaluation of these two programming models with regard to the impact of different levels of the memory hierarchy in the duration of the application. The evaluation is based on tracefiles with hardware counters on the execution of a memory intensive benchmark in both programming models Keywords: SMP Superscalar, programming models for multicore, task scheduling, locality exploitation 1. Introduction The new trends in computer fabrication have evolved towards machines at all levels \(from customer to HPC large systems chips. For this reason it is now, more than ever, true that there is a need for parallel programming models that enable to easily exploit the possibilities of these chips. There are several programming models that have been proposed with this objective. OpenMP [1] is a very well known standard that exploits parallelism in shared memory architectures. The recent version 3.0 [2] extends its functionality to include the support of task level parallelism. In a similar way, SMP Superscalar \(SMPSs  based programming model that exploits the parallelism at the task level and takes into account data dependencies between tasks. Both will be the focus in this paper. While previous studies [3], [4] have focused more on the performance achieved by the corresponding runtimes, this paper presents an evaluation of these two programming models with regard to the impact of different levels of the memory hierarchy in the duration of the application tasks. The evaluation is based on tracefiles with hardware counters on the execution of a set of benchmarks in both programming models The paper structure is as follows: section 2 outlines the main characteristics of SMPSs and OpenMP, section 3 outlines some related work, section 4 presents experimental results with the STREAM benchmark, section 5 outlines a new mechanism to further improve the locality exploitation in SPMSs and finally section 6 concludes the paper 2. Task Based Programming Models Since the focus of this paper is SMPSs and OpenMP the next two subsections present more detailed summary of these two programming models 2.1. SMP Superscalar Star Superscalar \(StarSs models \(SMPSs [3], CellSs [5] and others ming model is inspired by the behavior of superscalar processors that are able to execute more than one instruction during a clock cycle by simultaneously dispatching multiple instructions to redundant functional units on the processor For StarSs the unit of execution is not the instruction but a task, and a task is a function in the code without collateral effects \(only variables and parameters are accessed with enough grain \(this may depend on the final target architecture where StarSs is implemented, and can be tuned 


architecture where StarSs is implemented, and can be tuned by applying blocking for example StarSs is that tasks are defined by a sequential program and at runtime a Directed Acyclic Graph \(DAG each of the nodes of the DAG represent a task and edges represent data precedences that must be respected and that are automatically detected by the runtime library Tasks are identified by pragma annotations of the type pragma css task input \(in_var1, in_var2 output \(out_var in_out_var where input, output and inout denotes the direction of the parameters of the task. The case of study in this paper is SMP Superscalar \(SMPSs ticore processors or shared memory machines. The current Parallel, Distributed and Network-based Processing 1066-6192/09 $25.00  2009 IEEE DOI 10.1109/.55 437 PDP.2009.56 runtime is implemented in such a way that for an application that runs with N threads, the first thread \(main thread executes both the main sequential program and tasks \(if time is left worker threads execute tasks. The scheduling of each task is determined partially by the order in which the tasks are called, partially by the data dependences, and partially by the thread that executes the last predecessor of the task, with the objective of scheduling in the same core dependant tasks. This favors locality exploitation since a dependence denotes that the predecessor task is writing a piece of data that is going to be read by the successor task There exist N+1 ready lists, one main ready list and one additional for each of the threads \(including one for the main thread data dependences between the new task and former tasks. If these data dependences exist, the task is inserted in the DAG However, if the task does not hold any data dependency, then it is ready for execution and it is inserted in the main ready list. The behavior of the worker threads is that they always consume tasks from their ready list unless this is empty, then they consume tasks from the main ready list, and if this is also empty the threads will try to steal tasks from the ready lists of other workers. Threads consume tasks from their own ready list in LIFO order, consume tasks from the main ready list and from other threads  list in FIFO order. Whenever a task is finished, the threads update the corresponding data structures in the DAG and if the task completion has released all the remaining data dependences of one or more tasks those are inserted in the thread ready list 2.2. OpenMP OpenMP was born in the 1990s with the objective of bringing a standard to the different directive languages defined by a community of vendors. Thanks to a set of characteristics: simplicity of the interface, use of a shared memory model, and use of loosely-coupled directives to express the parallelism of a program, it is very well-accepted today. OpenMP is based on the insertion of directives in the sequential source code that give hints to the runtime library about the existent parallelism in the application. The OpenMP pragma annotation denoting a parallel loop is as follows pragma omp parallel for Version 3.0 of OpenMP includes a tasking model that fills a gap with regard the ways of expressing parallelism in an application. With the new OpenMP directives, the programmers can identify units of independent work \(tasks leaving the decision to how and when to execute them to the runtime system. This gives the programmers a way of expressing patterns of concurrency that do not match the worksharing constructs defined in the OpenMP 2.5 specification 


specification 3. Related work One of the task-based programming models is Cilk [6], a general-purpose programming language designed for multithreaded parallel programming. In Cilk, the programmer is responsible of exposing the application parallelism, identifying sections of the code \(tasks in parallel. Tasks are invoked with the spawn keyword and the sync keyword is used to wait until all previously spawned tasks have completed. Cilk supports recursivity at the task level \(tasks generate new tasks support automatic data dependence detection between them Therefore, data dependences have to be controlled by the programmer with the help of the sync keyword. The runtime in particular the scheduler, decides how to actually divide the work between processors. The work-stealing approach followed by the Cilk scheduler has been designed in such a way that naturally exploits the existent data locality, in particular for the recursive tasks Cilk initially only supported parallel tasks, however Cilk++ also supports parallel loops. OpenMP evolution is just the opposite: initially supported parallel loops, while the last version 3.0 also supports parallel tasks. Both systems support also recursivity at the task level. SMPSs does not support parallel loops, but supports task parallelism although does not support the recursivity at the task level The main difference between SMPSs and the previous two approaches is that SMPSs automatically detects the task dependences building a task DAG Besides, there have been steps towards the integration of task precedence [7] and task dependence [8] in OpenMP With regard to related work on studies the behavior of applications in ccNUMA shared memory systems, [9] presents the results of cache and memory performance studies on an SGI Altix 350. In [10] the authors present an study of the performance obtained \(with relation to the ccNUMA memory performance tunings that improve up to 30% the application performance. In [11] the authors present the evaluation of the SARC programming model on the Cell/BE architecture using the benchmarks STREAM and RandomAccess 4. Experiments The first part of the paper is focused in the description of the STREAM benchmark from the HPC Challenge collection [12]. We present alternative implementations to the original OpenMP one and an SMPSs implementation of this benchmark and an analysis of the results 4.1. STREAM implementation in OpenMP STREAM [12] is a simple synthetic benchmark program that measures sustainable memory bandwidth and the corresponding computation rate for a simple vector kernel 438 void tuned STREAM Copy  i n t j pragma omp p a r a l l e l f o r for \( j =0 ; j&lt;N; j c [ j ] = a [ j  Figure 1: Original copy function in STREAM void tuned STREAM Copy  i n t j i n t i pragma omp f o r s c h e d u l e \( s t a t i c , BSIZE f o r \( j =0 ; j&lt;N; j c [ j ] = a [ j  Figure 2: Modified OpenMP version of copy function in STREAM The original STREAM implementation already considers an OpenMP parallelization of four routines \(\(Copy, Scale 


an OpenMP parallelization of four routines \(\(Copy, Scale Add and Triad Copy function in STREAM For the purposes of this paper we have considered an alternative implementation as shown in figure 2, that mimics the behavior of the SMPSs implementation explained in the next section. This version statically distributes chunks of BSIZE iterations to each of the threads Additionally, a parallel pragma is inserted in the main program, as shown in figure 3. Besides, a dynamically scheduled version as shown in 4 is also considered The original benchmark includes in its prelude a par#pragma omp p a r a l l e l p r i v a t e \( k f o r \( k =0; k&lt;NTIMES ; k  tuned STREAM Copy tuned STREAM Scale \( s c a l a r tuned STREAM Add tuned STREAM Triad \( s c a l a r  Figure 3: Modified OpenMP version of main program in STREAM void tuned STREAM Copy  i n t j i n t i pragma omp f o r s c h e d u l e \( dynamic , BSIZE f o r \( j =0 ; j&lt;N; j c [ j ] = a [ j  Figure 4: OpenMP version of copy function in STREAM with dynamic scheduling pragma c s s t a s k i n p u t \( a c void c o p y t a s k \( double a [ BSIZE ] , double c BSIZE  i n t j f o r \( j =0 ; j &lt; BSIZE ; j c [ j ] = a [ j  void tuned STREAM Copy  i n t j f o r \( j =0 ; j&lt;N; j +=BSIZE c o p y t a s k \(&amp;a [ j ] , &amp;c [ j  Figure 5: Copy function in STREAM with SMPSs allelized loop where the data arrays are initialized. This initialization has been slightly modified to consider also the static and dynamic scheduling of BSIZE chunks of iterations. To compare with SMPSs, we will also include results where the initialization is done sequentially 4.2. STREAM implementation in SMPSs For the SMPSs version, we encapsulated chunks of consecutive iterations of the loops of functions Copy, Scale Add and Triad into SMPSs tasks. Figure 5 shows the code changes for function Copy The STREAM main code is a loop that calls the different functions. To mimic the same behavior as in the original benchmark, we have initially inserted explicit barrier synchronizations between the calls to Copy, Scale, ... as shown in figure 6. In this first version, all Copy tasks of one iteration are performed first, then all Scale tasks, etc. This not only mimics the original STREAM benchmark, but also models how a naive task scheduling algorithm will schedule 439 f o r \( k =0; k&lt;NTIMES ; k  tuned STREAM Copy pragma c s s b a r r i e r tuned STREAM Scale \( s c a l a r pragma c s s b a r r i e r 


pragma c s s b a r r i e r tuned STREAM Add pragma c s s b a r r i e r tuned STREAM Triad \( s c a l a r pragma c s s b a r r i e r  Figure 6: Main loop of STREAM for SMPSs version c [ j ] = a [ j ] ; / / Copy b [ j ] = s c a l a r ?c [ j ] ; / / S c a l e c [ j ] = a [ j ]+ b [ j ] ; / / Add a [ j ] = b [ j ]+ s c a l a r ?c [ j ] ; / / T r i a d Figure 7: Actual operations in STREAM for each element of the array tasks in SMPSs. Such a naive scheduler will have a single ready list and the ready tasks will be inserted in this list as soon as all the data dependences are released, and consumed by the threads in FIFO order However, since SMPSs automatically detect the dependences between the tasks, another version is possible, eliminating all the barrier synchronizations. This somehow perverts the original objectives of the benchmark, but enables us to measure how the current scheduling implemented in the SMPSs runtime exploits the locality of the application If we look at the basic code executed for each element of the vector we have the code listed in figure 7 In this code we can see that the data dependences define the following task precedence inside the iterations Copy Scale - Add - Triad, and additionally between iterations, a task precedence between the Triad of one iteration is defined with the Copy task of the next iteration. Therefore, with the scheduling strategy currently implemented in SMPSs, for a chunk of the array all the tasks operating on this chunk can be executed in the same core, exploiting the locality of the benchmark Additionally, to mimic the parallel initialization of data that the OpenMP version is able to do, we have encapsulated the initialization of the data arrays in a task \(each task initializes a chunk of BSIZE elements of the arrays Figure 8: Execution time of the STREAM benchmark with sequential initialization \(8 processors 4.3. Execution environment The results presented in this section have been executed in an SGI Altix 4700 at BSC with 128 core \(32 nodes with 2 dual-core processors We have run SMPSs versions of the experiments with SMPSs version 2.0 and extracted Paraver [13] tracefiles with hardware counters \(extracted with the support of PAPI library version 3.5.0 compiled with the native ICC compiler, version 10.0. This compiler was also used as back-end compiler for the SMPSs versions 4.4. Versions  Comparison The first experiments we have run consisted in the measurement of the execution time of all the aforementioned versions. We ran the different examples changing the array size, from 2 million elements to 321.93 million elements this is not an accidental number, since with this size the total amount of memory used is 7368.4MB which is roughly the 90% of memory available by each core of this machine With the objective of analyzing the impact of enlarging the size of the chunks of data assigned to each thread \(or task the chunks  size used is the 1% of the total size of the array We have also changed the number of processors, running the experiments with 8, 16 and 32 processors Figures 8, 9, and 10 show the comparison of the two OpenMP versions \(static and dynamic scheduling the two SMPSs versions \(with and without barriers doing the data arrays are sequentially initialized When using 8 processors, the OpenMP with static scheduling has the worst behavior, while the OpenMP with dynamic scheduling and SMPSs with barriers perform equally and the SMPSs without barrier slightly outperforms 


equally and the SMPSs without barrier slightly outperforms the previous. With 16 processors, the results are very similar with the difference that now the OpenMP version with dynamic scheduling is a bit better to the SMPSs version with 440 Figure 9: Execution time of the STREAM benchmark with sequential initialization \(16 processors Figure 10: Execution time of the STREAM benchmark with sequential initialization \(32 processors barriers. With 32 processors, although it is not clearly observable in the chart, besides the OpenMP version with static scheduling that gets the worst results, the rest of versions have the same behavior. Another important observation from these charts is that no improvement in the total execution time is observed when using more processors \(none of the cases scale with the number of processors Figures 11, 12, and 13 show the comparison of the two OpenMP versions \(static and dynamic scheduling the two SMPSs versions \(with and without barriers doing a parallel initialization of the data arrays When the arrays are initialized in parallel the situation changes since the physical memory in the SGI Altix is by default allocated on a first touch basis. With 8 processors the chart looks similar to the situation when using sequential initialization. However, the situation with 16 and 32 processors looks very different, with the OpenMP with static scheduling improving a lot and the OpenMP with dynamic scheduling behaving worst when increasing the number of processors. We would like to stress here that the SMPSs version without barriers shows a more stable behavior in all the cases, being the best or almost the best in all cases Figure 11: Execution time of the STREAM benchmark with parallel initialization \(8 processors Figure 12: Execution time of the STREAM benchmark with parallel initialization \(16 processors Figure 13: Execution time of the STREAM benchmark with parallel initialization \(32 processors 441 Figure 14: Tasks  scheduling in the SMPSs versions 4.5. Analysis of the results This section reports more in-depth analysis of the tracefiles. The first analysis is done by comparing the four cases when the data arrays are sequentially initialized. The objective of these first analysis is to understand why any of these versions is actually scaling with the number of processors. The analysis is done comparing traces with 8 16 and 32 processors Regarding the scheduling of the SMPSs versions when analyzing the traces it is observed that in the version with barriers all tasks of a type are executed one after the other to preserve the barriers but in the version without barriers tasks of different type are interleaved, preserving the datadependences and exploiting the locality of the chunks of data. This is shown in figure 14: the x-axis represents the timeline and each line corresponds to one thread. Different colors correspond to different tasks \(the small green flags indicate the begin of a new task We first had a look to the average time to execute each of the tasks in the different versions. This time is different for each of the tasks  type, as can be observed in figure 15. For this case, with a relatively small data array size, the case with barriers shows also a deviation in time between the first four threads and the other four. This deviation is not observed in the version without barriers since the locality is overall better exploited. This is due to the fact that the arrays are allocated and initialized in the sequential section of the benchmark by the first thread. Therefore, we can assume that the threads 1  4 are located in the first node and threads 5  8 in another node However, when analyzing the traces with a larger data array size, this difference between the version with barriers 


and without barriers is less evident. This can be observed in figure 16 for the SMPSs versions, when a array size of 32 million of elements is used To understand this difference in task time we had a look to the L3 and TLB miss ratio of the different cases Although these ratios did not show significant differences Figure 15: Average time per task and thread, with \(top without barriers \(bottom size of 2 million elements the bandwidth obtained by each of the threads in the different cases reflects the same difference, as can be seen in figure 17 In this figure, we see for the SMPSs version without barriers how the bandwidth with memory varies when we run the benchmark with 8, 16 and 32 processors. The figure shows not only the differences between the bandwidth obtained in the first 4 processors \(located in the first node others, but also how this difference is each time larger. In the case of 32 processors, the average bandwidth in the processors 4  31 is only 58.8 MB/s in this case. For the rest of the examples \(SMPSs with barriers and OpenMP the behaviour is similar and we do not show the results due to space and redundancy reasons. Clearly, the fact that the data arrays are initialized in one node creates a bottleneck in this node, and therefore in these systems it is a good idea to distribute the data initialization Another interesting fact that we wanted to understand from figures 11  13 is the behavior of the OpenMP 442 Figure 16: Average execution time of tasks per thread with SMPSs Figure 17: Bandwidth with memory for the SMPSs version without barriers static version. It is surprising that OpenMP with the static scheduling obtained the worst results with 8 processors and almost the best results with 32 processors. Given that the static scheduling distributes linearly the chunks of iterations this version should be able to exploit the data locality Also, one would expect a uniform access time for all processors. Looking at the tracefiles, no important imbalance was find is the static version, although some processors were executing one chunk of iterations more. Therefore, it was very surprising that although the L3 and TLB miss ratio indicators are perfectly balanced for all processors and were less than the 50% in the static version than in the dynamic version, the dynamic version was beating the static one with 8 processors We analysed the memory bandwidth obtained by the static and dynamic scheduling versions, which is shown in figures 18 and 19. While the static scheduling is able to achieve more or less the same bandwidth in the three cases with 8, 16 and 32 processors the bandwidth obtained by the example is each time smaller This explains the improvement of the static version with regard the dynamic version when higher number of processors Figure 18: Bandwidth with memory for the OpenMP version when using static scheduling is used. However, it is still not clear why the dynamic case is better than the static with 8 processors Since the arrays were split in chunks of data that are not multiple of the memory page size, a possible explanation would be that the first touch instantiation of a page does not necessarily guarantees that a chunk is local in the same module where the thread is running. We repeated the example with new sizes \(with chunks of size multiple of the memory page size the processors. In this case, the behavior of the example improves significantly, as well as the bandwidth achieved when using 8 processors as can be seen in figure 20. The peak of the curve is now centered on 1220 MB/s. Since the tracefiles with only one processor per node show that the peak bandwidth achievable with this example is 5000 MB/s we can not expect much more with 4 processors per node 


we can not expect much more with 4 processors per node Additionally, if all threads in the same node access memory at the same time they create conflicts between them 443 Figure 19: Bandwidth with memory for the OpenMP version when using dynamic scheduling Figure 20: Bandwidth with memory for the OpenMP version when using static scheduling \(impact of using data size multiple of memory page 5. Further exploiting the memory locality As seen in the previous section, exploiting the memory locality in ccNUMA based systems has a large impact in the performance results and that a dynamic scheduling conscious of the locality should be able to obtain good performance With the objective of further improving how SMPSs exploits the data locality we have made a modification in the way way tasks are assigned to the threads The existing mechanism in SMPSs exploits the locality by executing sequences of data dependent tasks in the same thread. However, the creation of these sequences of tasks can be interrupted either by the SMPSs runtime graph-creation mechanism \(that has a threshold on the maximum number of tasks in the graph for memory allocation reasons Figure 21: Execution time of the STREAM benchmark with when changing array size \(8 processors Figure 22: Execution time of the STREAM benchmark with when changing array size \(16 processors the program synchronization points \(i.e. barriers The new implemented mechanism is able to remember wich thread did the first touch of a given block of data Whenever a new task is added by the SMPSs runtime, if this task is ready, instead of inserting it in the main ready list is directly inserted \(in FIFO order the thread that first touched the data accessed by the task Figures 21, 22, and 23 compare a new set of versions, both for OpenMP and for SMPSs. First, the size of the arrays  chunks is now a multiple of a memory page size in all cases Also, the number of chunks by wich we divide the array is a multiple of the number of processors. Additionally, for the static scheduling version, the  nowait  clause is added in the pragmas. However, this clause can not be inserted when dynamic scheduling is used, since OpenMP does not preserve the data dependences and the benchmark does not validates. For the SMPSs versions, we changes as well the sizes of the arrays and chunks of data. Two versions are tested, which use the mechanism described above to map tasks to threads: one that performs the initialization of the data \(in parallel 444 Figure 23: Execution time of the STREAM benchmark with when changing array size \(32 processors initialization and a second one that does not insert any barrier A significant difference here is that the OpenMP version with static scheduling and the nowait clause outperforms the dynamic scheduling in all cases. Also, SMPSs versions with the new memory affinity mechanism, show better performance than the OpenMP cases for all processor counts 6. Conclusions The paper presents a comparison of how the benchmark STREAM can be implemented with OpenMP and with SMPSs and how the different scheduling mechanisms impact in the achievable memory bandwidth. With OpenMP, an evaluation of the impact in the performance in a memory intensive benchmark of the static and dynamic scheduling is presented. With SMPSs, results obtained with different versions inserting barriers and without inserting them is presented. For both OpenMP and SMPSs, the impact of initializing the data sequentially is analyzed and clearly for ccNUMA memory based systems this is a non-appropriate option since this will allocate all the data in the same memory module, creating a bottle-neck in the memory 


memory module, creating a bottle-neck in the memory accesses Besides, both OpenMP and SMPSs require scheduling schemes that although conscious of the locality \(and this is somehow a quite static feature adapt to other sources of imbalance in the systems. More specific for SMPSs, increasing the threshold of number of tasks in the graph would enable to better exploit the temporal locality that appears in computations far away in the original source code Acknowledgments The authors acknowledge the financial support of the Comision Interministerial de Ciencia y Tecnologa \(CICYT Contract TIN2007-60625 research agreement References 1] cOMPunity. The community of OpenMP users researchers, tool developers and provider website http://www.compunity.org/, 2006 2] E. Ayguade  N. Copty, A. Duran, J. Hoeflinger, Y. Lin, and G. Zhang. A proposal for task parallelism in OpenMP. In Proceedings of the 3rd International Workshop on OpenMP June 2006 3] J.M. Perez, R.M. Badia, and J.Labarta. A dependencyaware task-based programming environment for multi-core architectures. In Proceedings of IEEE Cluster Computing 2008, 2008 4] E. Ayguade  A. Duran, J. Hoeflinger, F. Massaioli, and X. Teruel. An experimental evaluation of the new openmp tasking model. In Proceedings of the 20th International Workshop on Languages and Compilers for Parallel Computing 2007 5] J. M. Perez, P. Bellens, R. M. Badia, and J. Labarta. CellSs Programming the Cell/B.E. made easier. IBM Journal of Research and Development, 51\(5 6] M. Frigo, C. E. Leiserson, and K. H. Randall. The implementation of the cilk-5 multithreaded language. SIGPLAN Notices, 33\(5  223, 1998 7] M. Gonzalez, E. Ayguade  X. Martorell, and J. Labarta Exploiting pipelined executions in OpenMP. In Proceedings of the 32nd Annual International Conference on Parallel Processing, pages 153  160, Oct 2003 8] A. Duran, J.M. Perez, E. Ayguade, R.M. Badia, and J. Labarta. Extending the OpenMP tasking model to allow dependent tasks. In Proceedings of the 4th International Workshop on OpenMP, 2008 9] G. Juckeland, M.S. Muller, W.E. Nagel, and S Pflu. Accessing data on sgi altix: An experience with reality. In Proceedings of WMPI 2006, 2006 10] A. Kayi, E. Kornkven, T. El-Ghazawi, and G. Newby. Application performance tuning for clusters with ccnuma nodes In Computational Science and Engineering, 2008. CSE  08 11th IEEE International Conference on, pages 245  252, July 2008 11] R. Ferrer, M. Gonza  lez, F. Silla, X. Martorell, and E. Ayguade  Evaluation of memory performance on the cell be with the sarc programming model. In Proceedings of MEDEA workshop \(PACT 12] HPCS. The hpc challenge benchmark http://icl.cs.utk.edu/hpcc/index.html 13] Jesu  s Labarta, Sergi Girona, Vincent Pillet, Toni Cortes and Luis Gregoris. DiP: A parallel program development environment. In Proceedings of the 2nd International EuroPar Conference \(EuroPar 96 445 pre></body></html 


in preferences for a category of items. The selection of segment is done by selecting highly rated popular items with similar characteristics. Segmented attack is focused on those users who have highly rated majority of the selected items present in the segment For example, group of users who have highly rated at least any three of the five most popular animation movies form a segment of users interested in animation movies. An attacker with intent to promote a new animation movie will find it beneficial to mount a segmented attack against a segment of user interested in animation movies In our work, we study the effect of our filler item strategies in further improving the effectiveness of insegment attacks against both user-based and itembased attacks. In segment attack, filler items are randomly selected and assigned the minimum value in the rating scale. The reasoning behind assignment of minimum value to the filler item has not been explained in detail in any of the literature on segmented attack.  We provide below details of our filler item strategies for segment attack  7.1 Strategy SUL  This strategy is followed when a segment attack is mounted against a user-based CF system and the target item falls in TL category. In our approach to improve effectiveness of the attack, we need to create malicious users that are similar to those genuine users who have rated the target item with a lower value and also belong to the segment of users targeted by the segmented attack. So, to improve similarity, a randomly selected filler item is assigned the average rating given to it by those users who have rated any of the items that define the segment and have also rated the target item at a lower scale. For example for an attack against a segment of users interested in animation movies i.e., those users who have rated highly at least any three of the five most popular movies in animation genre, a filler item is assigned the average rating given to it by those users who have rated the target item at a lower rating and have rated highly at least one of the five animation movies that define the segment  7.2 Strategy SUH This strategy is followed when a segment attack is mounted against a user-based CF system and the target item falls in TH category. To improve effectiveness of a segment attack, a randomly selected filler item is assigned the average rating given to it by those users who have rated any of the items that define the segment and have also rated the target item at a higher scale  7.3 Strategy SIL  This strategy is followed when a segment attack is mounted against an item-based CF system and the target item falls in TL category. To improve effectiveness of a segment attack, we select filler items from the set of items which are highly rated by those users who have rated target item at a lower scale. The strategy used is similar to Strategy IL Filler items are selected the way explained in section 6.1  7.4 Strategy SIH  This strategy is followed when a segment attack is mounted against an item-based CF system and the 


target item falls in TH category. To improve effectiveness of a segment attack, we select filler items from the set of items which are highly rated by those users who have rated target item at a higher Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 scale. The strategy used is similar to Strategy IH Filler items are selected the way explained in section 6.2  8. Experimental evaluation and discussion  We performed the experimental evaluation of our strategies on the publicly available MovieLens data set [8]. This is the most widely used dataset in recommender systems research. MovieLens consists of 100,000 ratings made by 943 users on 1682 movies. Each user in the data set has rated at least 20 movies and each movie has been rated at least once A timestamp value is associated with each user movie, and rating combination. The data set also contains information on the demographic detail \(age sex, occupation, and zip code information \(genre and release date The ratings are made in a scale of 1 to 5, where 5 indicate extreme likeness for an item and 1 dislike We evaluated effectiveness of the proposed strategies on user-based and item-based collaborative algorithm. For similarity calculation and prediction in user-based CF algorithm, equations 1 and 2 stated in section 3 were used. Similarly, equations 3 and 4 stated in section 3 were used for computing similarity and prediction value for item-based CF algorithm We used a neighborhood size of k = 20 for prediction calculation. Case amplification value of 10 was used while calculating correlation and only positive correlations values were considered for computing predictions To conduct our evaluation, we selected a sample 20 items. Out of the 20 items, 10 items belonged to TL  category while remaining 10 items to TH category All the 20 items were selected randomly from a larger set of items belonging to each category. We also randomly selected a sample of 50 target users Target users selected were those who have never rated any of the 20 test items. Each of the target items was attacked individually and the prediction shift was calculated by averaging the prediction shift observed for each user. The final prediction shift for the attack is the average prediction over all items used in the test. Equation 6 was used to calculate the metric For implementation of segmented attack we followed the same guidelines as stated in [3]. Horror segment was selected as the target segment. Five of the most popular horror movies were selected to represent the segment. These five movies selected formed the selected item set in the attack profiles constructed. The five movies are Alien, Psycho, The Shining, Jaws, and The Birds. Users who have given a rating of 4 or 5 to at least any 3 of the five movies were identified as the target segment against which the attack was focused. For calculating prediction shift we selected 50 of the users from this target segment to form the test user set. While implementing the segment attack, selected items were given a rating of 5 and the randomly selected filler items were assigned a value 1 All experiments were conducted for ?Size of attack? values 1%, 3%, 6%, 12%, and 15%.  ?Size of attack? represents number of attack profiles added as a percentage of pre-attack profiles. 1% ?Size of attack? implies 10 attack profiles were added to a 


attack? implies 10 attack profiles were added to a system of 1000 genuine users. On the basis of the results reported in [4] that best results are reported when a filler size of 3% is used in an average attack we used a filler size of 3% for all our tests i.e., 3 % of 1682 items which is approximately 50 filler items For attacks against user-based collaborative filtering systems we used six strategies: Strategy UL, Strategy UH, Strategy SUL, Strategy SUH, segment attack and average attack. Similarly, for attacks against item based collaborative filtering systems we used six strategies: Strategy IL, Strategy IH Strategy SIL Strategy SIH, segment attack and average attack. For average attack, filler item strategy used was the same as in an average attack i.e., the mean of the filler item was assigned to it. Segment attack was implemented as explained earlier. Category TL, Category TH Strategy UL, Strategy UH, Strategy IL, Strategy IH Strategy SUL, Strategy SUH, Strategy SIL and Strategy SIH were implemented the way explained earlier in section 4, section 5, section 6 and section 7 respectively. For attacks against item-based CF while selecting filler items from set IF, only items with minimum frequency count of 10 were considered Figure 2 and Figure 3 show the effectiveness of our attacks when calculated for all users against systems using user-based collaborative filtering for recommendations.  Figure 2 shows the prediction shift values of attacks Strategy UL and average attack for items belonging to TL category. From the graph it?s obvious that for items in TL category, Strategy UL outperforms average attack model for all values of attack size. Similarly, Figure 3 shows the prediction shift values for the attack strategies Strategy UH and average attack for items belonging to TH category From the graph it can be concluded that for items belonging to TH category, Strategy UH performs much better than average attack over lower values of attack size. At attack size of 12 % and 15% both attack have similar effectiveness Figure 4 and Figure 5 show the effectiveness of our attacks when calculated for all users against systems using item-based collaborative filtering for recommendations.  Figure 4 shows the prediction shift values of Strategy IL and average attack for Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 items belonging to TL category. Similarly, Figure 5 shows the prediction shift values for the Strategy IH and average attack for items belonging to TH category. From Figure 4 and 5 it can be concluded that both Strategy IL and Strategy IH perform substantially better than average attack over all values of attack size. It can also be observed that our attack strategies are more effective against itembased systems than user-based systems Figure 6, 7, 8, and 9 show the effectiveness of our filler based attack strategies for in-segment users. We observe that for attacks against both user-based and item-based CF systems the effectiveness of our filler based strategies is comparable to the best available attack model for in-segment attacks i.e., segment attack. However, in Figure 8 we observe that filler item strategy SIL performs better than segment attack. Because of the low knowledge cost involved in segment attack, we can conclude that for most scenarios segment attack is a better attack model for in-segment attacks than filler based attack models Experimental results clearly show that our approach of selecting a strategy based on target item rating distribution outperforms the best available attack model i.e., average model. One drawback of 


attack model i.e., average model. One drawback of our attack strategies is its high knowledge cost However, automated software agents can help diminish the cost. One approach that can be used to decrease the cost is to use a subset of users while selecting filler items. For example, in attacks against item-based systems, while implementing Strategy IH instead of selecting all users who have rated target item as 4 or 5 as members of the set UH. , we only select 20 users. Selection of items for set IF will then be performed using the data of the 20 users in set UH Similarly, in case of attacks against user-based systems, while implementing Strategy UH instead of assigning a filler item IF the average rating given to it by the set of users UH. , we assign IF the average rating given to it by a subset of 5 randomly selected users from UH. In future work we plan to experimentally verify the effectiveness of these cost reduction approaches    Figure 2:   Attack on TL category of items against user-based collaborative filtering system   Figure 3:   Attack on TH   category of items against user-based collaborative filtering system   Figure 4:   Attack on TL category of items against item-based collaborative filtering system  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8  Figure 5:   Attack on TH category of items against item-based collaborative filtering system   Figure 6:   Attack on TL category of items against user-based collaborative filtering system   Figure 7:   Attack on TH   category of items against user-based collaborative filtering system    Figure 8:   Attack on TL category of items against item-based collaborative filtering system   Figure 9:   Attack on TH category of items against item-based collaborative filtering system  9. Conclusion  This paper provides an effective approach towards constructing attack models. We show the importance of target item and filler items in construction of successful attack strategies. Through experiments we show that our approach of intelligent selection of filler items based on target item rating distribution results in substantial improvement over the baseline average attack. We also compare our approach with the well known in-segment approach and conclude that our approach gives slightly improved results. In future, we plan to examine the filler items strategies for other attack models, and also create algorithms to improve robustness and stability of recommender systems against shilling attacks 


systems against shilling attacks  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9  10. References  1] Lam, S., and Riedl, J. 2004. Shilling Recommender Systems for Fun and Profit, In Proceedings of the 13th International WWW Conference 2] Mehta, B., Hofmann, T., and Nejdl, W. 2007. Robust Collaborative Filtering, In Proceedings of the 2007 ACM Conference on Recommender Systems, 49-56 3] Mobasher, B., Burke, R., Bhaumik, R., and Williams C. 2007. Towards Trustworthy Recommender Systems: An Analysis of Attack Models and Algorithm Robustness, ACM Transactions on Internet Technology, 7\(2007 4] Burke, R., Mobasher, B., and Bhaumik, R. 2005 Limited Knowledge Shilling Attacks in Collaborative Filtering Systems, In Proceedings of Workshop on Intelligent Techniques for Web Personalization 5] Konstan, J., Miller, B., Maltz, D., Herlocker, J Gordon, L., and Riedl, J. 1997.  GroupLens: Applying Collaborative Filtering to Usenet News Communications of the ACM, 40, 3\(1997 6] Herlocker, J., Konstan, J., Borchers, A., and Riedl J.1999. An Algorithm Framework for Performing Collaborative Filtering, In Proceedings of  SIGIR ACM, 77-87 7] Sarwar, B., Karypis, G., Konstan, J., and Riedl, J 2001. Item-based Collaborative Filtering of Recommendation Algorithms. In Proceedings of the 10th International WWW Conference 8] MovieLens data set,www.grouplens.org  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


 Current Time \(min  Healthy Failure Expected Just-in-time line Actual Remaining Life  Figure 17. Results of failure prognosis 0 100 200 300 400 500 600 700 800 900 1000 0 0.02 0.04 0.06 0.08 0.1 0.12 Time \(min Sp al l S iz e  m m 2 Interpolation of spall growth according to feature values 0 100 200 300 400 500 600 700 800 900 1000 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Time \(min Fe a tu re V a lu e    Interpolation of feature value with noise Interpolation of feature vlaue snapshot with ground truth data 11 CONCLUSIONS This paper shows that enhancements to diagnostic techniques are desirable as well as attainable additions to Health and Usage Monitoring Systems \(HUMS particularly in the case of rotorcraft component monitoring Enhancements like those presented support CBM efforts primarily in two ways: reduce the sensitivity of diagnostic processes to both signal noise and variations in environmental and operating conditions, and improve the performance of detection systems as well as the task of fault identification \(e.g., severity quantification instantiation of reliable prognostics Representative examples, motivated by the interest of the U.S. Army in transitioning from time-based \(using TBO definitions drive train bearing, illustrates the potential benefits of 


pursuing an integrated approach to diagnostics and prognostics, combining technologies for enhanced data preprocessing, advanced diagnostic-support algorithms, fusion at the sensor/feature levels, and an adequate framework for false alarm mitigation and uncertainty management. An architecture for achieving such integration is presented, with emphasis on supporting a robust performance of diagnostics operations, even in the presence of such kinds of disturbances as those observed in data acquired by HUMS vibration sensors. The present study also gives relevance to seeded fault because the technologies discussed can integrate knowledge about damage mechanism interactions or physics-of-failure models, as well as make use of multiple-sensor and multiple-feature data sets representative of known fault conditions For this reason, the team behind this project is evaluating a potential opportunity to perform a series of tests on rotorcraft drive train bearings with varying fault severities and under multiple, though realistic, operating conditions Such tests are being planned to provide algorithm/model validations, as well as diagnostic/prognostic performance assessments, in support of providing the U.S. Army with technologies that make detection systems more robust allow for the implementation of prognostics, and extend the useful life of drive train components. Component degradation testing thus remains as future, follow-up work to the research reported in this document ACKNOWLEDGMENTS This work has been partially supported with a cooperative agreement by the Army Research Laboratory under contract number W911NF-07-2-0075. In addition to the primary authors, we would like to thank government and contractor representatives from organizations supporting the Army Utility \(Blackhawk Estes, Mr. Carlos Rivera, and Dr. Jon Keller. This work has also benefitted greatly from consultations with other Army Research Laboratory and NASA Glenn researchers such as Dr. Timothy Krantz, Dr. David Lewicki, Dr. Harry Decker Dr. Hiralal Khatri, Mr. Ken Ranney and Mr. Kwok Tom REFERENCES 1] Branhof, R.W., Grabill, P., Grant, L., and Keller, J.A  Application of Automated Rotor Smoothing Using Continuous Vibration Measurements  American Helicopter Society 61st annual forum, Grapevine, Texas June 1  3, 2005 2] Dora, R., Wright, J., Hess, R., and Boydstun, B  Utility of the IMD HUMS in an Operational Setting on the UH60L Blackhawk  American Helicopter Society 60th annual forum, Baltimore, Maryland, May 7  10, 2004 3] Zakrajsek, J.J., Dempsey, P.J., et al  Rotorcraft Health Management Issues and Challenges  NASA report TM  2006-214022. February, 2006 4] Suggs, D.T., and Wade, D.R  Vibration Based Maintenance Credits for the UH-60 Oil Cooler Fan Assembly  American Helicopter Society, CBM Specialists Meeting, Huntsville, Alabama, February 13 2008 5] Baker, C., Marble, S., Morton, B.P., and Smith, B.J  Failure Modes and Prognostic Techniques for H-60 Tail Rotor Drive System Bearings  IEEEAC paper #1122 IEEE, 2007 6] Keller, J.A., Branhof, R., Dunaway, D., and Grabill, P  Examples of Condition Based Maintenance with the Vibration Management Enhancement Program   American Helicopter Society 61st Annual Forum Grapevine, Texas, June 1  3, 2005 7] Zhang, B., Sconyers, C., Byington, C.S., Patrick, R Orchard, M.E., and Vachtsevanos, G.J  Anomaly Detection: A Robust Approach to Detection of 


Detection: A Robust Approach to Detection of Unanticipated Faults  International Conference on Prognostics and Health Management, Denver, Colorado October 6-9, 2008 8] Byington, C.S., Watson, M., Lee, H., and Hollins, M  Sensor-level Fusion to Enhance Health and Usage Monitoring Systems  American Helicopter Society, 64th Annual Forum, Montreal, Canada, April 29-May 1, 2008 9] Engel, S.J., Gilmartin, B.J., Bongort, K., and Hess, A  Prognostics, the Real Issues Involved With Predicting Life Remaining  Proceedings of the IEEE Aerospace Conference, Big Sky, Montana, March 18-25, 2000 12 BIOGRAPHY Romano Patrick is a Project Manager at Impact Technologies. He received a Ph.D. in Electrical Engineering from the Georgia Institute of Technology specializing in model-based machine health diagnostics and prognostics. He also holds an MBA from Georgia Tech and degrees from U Texas, Arlington and U. Panamericana, Mexico. With career focus on interdisciplinary integration of technologies, his recent work involves practicable diagnostics/prognostics design for complex systems, such as rotorcraft drive trains Past experience includes automation and design for a variety of industrial and government sponsors \(DARPA, Lockheed Martin, Northrop Grumman, etc and program coordination at U. Panamericana, and some entrepreneurial R&amp;D Matthew J. Smith is a Senior Project Engineer at Impact Technologies. During his tenure with Impact, Matthew has performed multiple efforts pertaining to bearing vibration analysis, diagnostic and prognostic system development, and experimental study of faulted system reponse and fault progression. Previously, as a research assistant at Penn State and the NASA Glenn Research Center, Matthew performed experimental and analytical oil-free bearing analyses Matthew received his B.S. and M.S. degrees in Mechanical Engineering from The Pennsylvania State University. His research interests include: prognostic health assessment for bearing and actuator systems, grease degradation modeling and fault classifier development Bin Zhang received his Ph.D. degree from Nanyang Technological University, Singapore in 2007. He received his BE and MSE degrees from Nanjing University of Science and Technology, China, in 1993 and 1999, respectively. He is a senior member of IEEE. From 2005 to present, he has been a Post-Doc with the School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta GA His current research interests are fault diagnosis and failure prognosis, systems and control, digital signal processing learning control, intelligent systems and their applications to robotics, power electronics and various mechanical systems Carl S. Byington is a Professional Engineer and the Director of Systems Engineering at Impact Technologies. He directs R&amp;D in pursuit of advanced, automated systems health management for land-based, shipboard, and airborne machinery for military and commercial customers. He is Chairman of the Machinery Diagnostics &amp; Prognostics Committee of ASME and a member of IEEE, AIAA, SAE and AHS. He has a BS degree in Mechanical Engineering from the University of Pennsylvania and an MS in Aeronautical Engineering from George Washington University, and has published over 60 papers, book chapters, magazine and journal articles related to diagnostics and prognostics technologies George Vachtsevanos is Professor Emeritus at the Georgia Institute of Technology and also serves as the Chief Scientist at Impact Technologies, LLC. He directed the Intelligent Control Systems laboratory at Georgia Tech for the past 28 years where faculty and students are conducting research in fault diagnosis/prognosis and fault-tolerant control of engineering systems, intelligent control of industrial 


engineering systems, intelligent control of industrial processes, neurotechnology and cardiotechnology, and unmanned systems. His research work has been sponsored by government and industry and has published over 250 technical papers in his area of expertise. He is the lead author of a book on "Intelligent Fault Diagnosis and Prognosis of Engineering Systems" published by Wiley in 2006. He is the recipient of the Georgia Tech Interdisciplinary Activities award and the ECE Distinguished Professor award Romeo de la Cruz del Rosario, Jr. is the Chief of the Electronics Technology Branch at the U.S. Army Research Laboratory. He also serves as the Army Technology Objective ATO P&amp;D Operational Readiness and Condition Based Maintenance He received the B.E.E. degree from the Catholic University of America, Washington, D.C., and the M.S.E. and Ph.D degrees in Electrical and Computer Engineering from the Johns Hopkins University, Baltimore, MD. Since 1991 he has been an engineer at the Harry Diamond Laboratory then U.S Army Research Laboratory working in several areas including high power microwave technology characterization &amp; modeling of heterostructure RF devices and fabrication and failure analysis of electron devices and circuits  pre></body></html 


movies. In the case of the volume of critical reviews however, there was no big difference between mainstream and non-mainstream movies. WOM and critical reviews were usually positive H1 and H2 tested the relationship between WOM and weekly box office revenue, and the results supported the hypotheses. The volume of WOM was positively related to weekly box office revenue, while the valence of WOM had no significant effect. H3 H4a, and H4b tested the impact of critical reviews, and the results also supported the hypotheses except H4b The volume and valence of critical reviews had no consistent significances to weekly box office revenue H3 H4b. Table 7 showed that the number of critical reviews was statistically significant to aggregate box office revenue \(H4a for the attitude of critical reviews \(H4b the result more detail, an additional test was performed using only those factors related to critical reviews as independent variables. The result of the additional test supported H4, but the signs were reversed, i.e. positive critical reviews had minus signs, and negative critical reviews had plus signs. This reversed signs imply that the preference of critical reviewers is very similar to that of normal moviegoers. H5s and H6s tested the different effects of WOM and critical reviews on mainstream and non-mainstream movies. The result failed to determine that WOM give different impact on mainstream and non-mainstream movies, so H5a and H5b were rejected. H6, however, was supported, i.e the effects of critical reviews were different for mainstream and non-mainstream movies. There were no significant relationships between critical reviews and aggregate box office revenue in mainstream movies. For non-mainstream movies, however, the volume of critical reviews and the percentage of negative critical reviews were significant. Nonmainstream movies have fewer sources from which consumers can get information, and this might explain the results The above findings lead to several managerial implications. First, producers and distributors of movies could forecast weekly box office revenue by looking at previous weeks? volume of WOM. It does not matter what attitude people have when they spread WOM, the important factor is its volume. Therefore producers and distributors need to develop an appropriate strategy to manage WOM for their movies For example, the terms related to WOM marketing such as buzz and viral marketing are easily found Second, for the distributors who usually distribute less commercial and more artistic movies, and consequently have a smaller market compared to the major distributors, critical reviews can impact their movies box office revenues in a significant way. There are usually fewer sources for information for nonmainstream movies than mainstream movies, and so small efforts could leverage the outcomes. Finally, for those who are dealing with mainstream movies, the finding that the valence of WOM and critical reviews do not have significant relationship with box office revenue can have certain implications. Particularly, the attitude of critical reviews showed reversed effects Therefore, they may need to concentrate on other features rather than attitude of moviegoers or critical reviews, such as encouraging moviegoers to spread WOM This study contributes to the understanding of the motion picture industry, especially the relationship between box office revenue and WOM including critical reviews. There are existing studies that already 


critical reviews. There are existing studies that already dealt with similar issues, but this study has some differentiated features compare to prior studies. First the data used in this study was collected from South Korea, while most of the relevant studies usually focus on the North American market. This helps to provide the opportunity to understand the international market especially the Asian market, even though South Korea is a small part of it in terms of the motion picture industry. Second, movies were categorized to two groups, i.e. mainstream and non-mainstream and this study attempted to determine how WOM impacts these categories differently by testing several hypotheses In this study, there are also several limitations that could be dealt with in future research. First, using box office revenue as a dependent variable is more meaningful for distributers rather than producers. Due to there is close correlation between box office revenue and number of screens, one of producers? main concerns is how many screens their movies can be played on. Moreover, DVD sales are also important measurement for success of movies these days, and so it also could be a dependent variable. Therefore, it could be possible to give more fruitful managerial implications to various players in the motion picture industry by taking some other dependent variables Second, in this study, movies were categorized simply as mainstream and non-mainstream movies, but there could be further studies with diverse techniques of movie categorizations. For example, it would be possible to study the varying influence of WOM or critical reviews on different genres or movie budgets Third, an interesting finding of this study is that positive critical reviews could have negative relationship with box office revenue while negative critical reviews could have positive relationship. This study tried to provide a reasonable discussion on the issue, but more studies could be elaborate on it  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 References  1] Dellarocas, C., The Digitization of Word of Mouth Promise and Challenges of Online Feedback Mechanisms Management Science, 2003. 49\(10 2] Bone, P.F., Word-of-mouth effects on short-term and long-term product judgments. Journal of Business Research 1995. 32\(3 3] Swanson, S.R. and S.W. Kelley, Service recovery attributions and word-of-mouth intentions. European Journal of Marketing, 2001. 35\(1 4] Hennig-Thurau, F., et al., Electronic word-of-mouth via consumer-opinion platforms: What motivates consumers to articulate themselves on the internet? Journal of Interactive Marketing, 2004. 18\(1 5] Fong, J. and S. Burton, Electronic Word-of-Mouth: A Comparison of Stated and Revealed Behavior on Electronic Discussion Boards. Journal of Interactive Advertising, 2006 6\(2 6] Gruen, T.W., T. Osmonbekov, and A.J. Czaplewski eWOM: The impact of customer-to-customer online knowhow exchange on customer value and loyalty. Journal of Business Research, 2006. 59\(4 7] Garbarino, E. and M. Strahilevitz, Gender differences in the perceived risk of buying online and the effects of receiving a site recommendation. Journal of Business Research, 2004. 57\(7 8] Ward, J.C. and A.L. Ostrom, The Internet as information minefield: An analysis of the source and content of brand information yielded by net searches. Journal of Business Research, 2003. 56\(11 


9] Goldsmith, R.E. and D. Horowitz, Measuring Motivations for Online Opinion Seeking. Journal of Interactive Advertising, 2006. 6\(2 10] Eliashberg, J., A. Elberse, and M. Leenders, The motion picture industry: critical issues in practice, current research amp; new research directions. HBS Working Paper, 2005 11] S&amp;P, Industry surveys: Movies and home entertainment 2004 12] KNSO, Revenue of Motion Picture Industry 2004 Ministry of Culture, Sports, and Tourism, 2004 13] Duan, W., B. Gu, and A.B. Whinston, Do Online Reviews Matter? - An Empirical Investigation of Panel Data 2005, UT Austin 14] Zhang, X., C. Dellarocas, and N.F. Awad, Estimating word-of-mouth for movies: The impact of online movie reviews on box office performance, in Workshop on Information Systems and Economics \(WISE Park, MD 15] Mahajan, V., E. Muller, and R.A. Kerin, Introduction Strategy For New Products With Positive And Negative Word-Of-Mouth. Management Science, 1984. 30\(12 1389-1404 16] Moul, C.C., Measuring Word of Mouth's Impact on Theatrical Movie Admissions. Journal of Economics &amp Management Strategy, 2007. 16\(4 17] Liu, Y., Word of Mouth for Movies: Its Dynamics and Impact on Box Office Revenue. Journal of Marketing, 2006 70\(3 18] Austin, B.A., Immediate Seating: A Look at Movie Audiences. 1989, Wadsworth Publishing Company 19] Bayus, B.L., Word of Mouth: The Indirect Effects of Marketing Efforts. Journal of Advertising Research, 1985 25\(3 20] Faber, R.J., Effect of Media Advertising and Other Sources on Movie Selection. Journalism Quarterly, 1984 61\(2 21] Eliashberg, J. and S.M. Shugan, Film critics: Influencers or predictors? Journal of Marketing, 1997. 61\(2 22] Reinstein, D.A. and C.M. Snyder, The Influence Of Expert Reviews On Consumer Demand For Experience Goods: A Case Study Of Movie Critics. Journal of Industrial Economics, 2005. 53\(1 23] Gemser, G., M. Van Oostrum, and M. Leenders, The impact of film reviews on the box office performance of art house versus mainstream motion pictures. Journal of Cultural Economics, 2007. 31\(1 24] Wijnberg, N.M. and G. Gemser, Adding Value to Innovation: Impressionism and the Transformation of the Selection System in Visual Arts. Organization Science, 2000 11\(3 25] De Vany, A. and W.D. Walls, Bose-Einstein Dynamics and Adaptive Contracting in the Motion Picture Industry Economic Journal, 1996. 106\(439 26] Bagella, M. and L. Becchetti, The Determinants of Motion Picture Box Office Performance: Evidence from Movies Produced in Italy. Journal of Cultural Economics 1999. 23\(4 27] Basuroy, S., K.K. Desai, and D. Talukdar, An Empirical Investigation of Signaling in the Motion Picture Industry Journal of Marketing Research \(JMR 2 295 28] Neelamegham, R. and D. Jain, Consumer Choice Process for Experience Goods: An Econometric Model and Analysis. Journal of Marketing Research \(JMR 3 p. 373-386 29] Lovell, G., Movies and manipulation: How studios punish critics. Columbia Journalism Review, 1997. 35\(5 30] Thompson, K., Film Art: An Introduction. 2001 McGraw Hill, New York 31] Zuckerman, E.W. and T.Y. Kim, The critical trade-off identity assignment and box-office success in the feature film industry. Industrial and Corporate Change, 2003. 12\(1 


industry. Industrial and Corporate Change, 2003. 12\(1 27-67 32] KOFIC, Annual Report of Film Industry in Korea 2006 Korean Film Council, 2006 33] Sutton, S., Predicting and Explaining Intentions and Behavior: How Well Are We Doing? Journal of Applied Social Psychology, 1998. 28\(15 34] Basuroy, S., S. Chatterjee, and S.A. Ravid, How Critical Are Critical Reviews? The Box Office Effects of Film Critics Star Power, and Budgets. Journal of Marketing, 2003. 67\(4 p. 103-117  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 






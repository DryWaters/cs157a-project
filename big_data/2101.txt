Fuzzy Data Mining for Discovering Changes in Association Rules over Time Wai-Ho Au Keith C.C Chan Department of Computing The Hong Kong Polytechnic University Hung Hom Kowloon Hong Kong E-mail  cswhau, cskcchan} @comp.polyu.edu.hk Abstract  Association rule mining is an important topic in data mining research Many algorithms have been developed for such task and they typically assume that the underlying associations hidden in the data are stable over time However in real world domains it is possible that the data characteristics and hence the associations 
change significantly over time Existing data mining algorithms have not taken the changes in associations into consideration and this can result in severe degradation of performance especially when the discovered association rules are used for classification prediction Although the mining of changes in associations is an important problem because it is common that we need to predict the future based on the historical data in the past existing data mining algorithms are not developed for this task In this paper we introduce a new fuzzy data mining 
technique to discover changes in association rules over time Our approach mines fuzzy rules to represent the changes in association rules Based on the discovered fuzzy rules our approach is able to predict how the association rules will change in the future The experimental results on a real-life database have shown that our approach is very effective in mining and predicting changes in association rules over time I INTRODUCTION Association rule mining is concerned with the discovery of interesting association relationships among different attributes in databases l 3 14-15 
Many algorithms have been developed for this task They typically assume that the underlying associations hidden in the data are stable over time and they therefore mine rules from the whole database However, in real world domains it is possible that the data characteristics and hence the underlying associations hidden in the data change significantly over time For example, there may be an interesting association between two attributes at time tl but the association is no longer interesting at time t2 Data mining without taking the changes over time into consideration can result in severe degradation of performance especially when the discovered association rules are used for classification \(prediction For example given a database containing the buyhell 
transactions of properties in Hong Kong in 1997, our task is to predict the price of properties in 1998 given their characteristics such as building age direction size etc In this case we mine a set of association rules fiom the transaction data in 1997 and then use the discovered rules to predict the price of properties in 1998 Nevertheless it is well known that there is an upward trend in the price of properties in or before 1997 but the trend has been changed from upward to downward afterwards in Hong Kong This renders the rules discovered from the buyhell transaction data in 1997 do not hold in 1998 and hence the prediction will not be accurate and 
the rules will not be useful to the user Since it is common that we need to predict the future based on the historical data in the past the mining of changes in association rules is an important problem Nevertheless existing data mining algorithms are not developed for this task In this paper we introduce a new fuzzy data mining technique to discover the regularities about changes in association rules over time Our approach employs residual analysis 4-81 to distinguish interesting changes in association rules fiom uninteresting ones The interesting changes are represented by fuzzy rules which can then be 
used to predict the changes in association rules in the future By predicting the changes in association rules we are able to provide accurate classification prediction based on the historical data In Section 11 we provide the related work An overview of the proposed approach and the details of how to mine and predict changes in association rules are given in Section I11 and IV respectively To evaluate the performance of our approach we applied it to a real-life database which contains all buyhell transactions of flats in a large private real estate in Hong Kong fiom 1991 to 2000 The experimental results are presented in Section V Finally 
in Section VI we conclude this paper with a summary This paper is organized as follows 11 RELATED WORK Association rule mining is originally defined in l over Boolean attributes in market basket data and has been extended to handle categorical and quantitative attributes  151 In its most general form, an association rule is defined over attributes of a database universal relation T It is an implication of the form X 3 Y where X and Y are conjunctions of conditions A condition is either Ai  ai 0-7803-7280-8/02/$10.00 02002 IEEE 890 


where ai E dom\(Ai if Ai is categorical or Ai E Ii ui E 93 if Ai is quantitative The association rule X a Y holds in T with support defined as the percentage of tuples satisfying X and Y and confidence defined as the percentage of tuples satisfymg Y given that they also satisfy X An association rule is interesting if its support and confidence are greater than or equal to the user-specified minimum support and minimum confidence respectively To handle quantitative attributes many data mining algorithms e.g 12 151 require the domain of these attributes to be discretized into crisp intervals The discretization can be performed as a part of the algorithms e.g 15 or as a pre-processing step before data mining e.g 12 After the domain of quantitative attributes has been discretized algorithms for mining Boolean association rules e.g l 3 141 can be used to discover rules in the discretized data The discovered association rules can be used later for user examinations and machine inferences, e.g classification  121 Existing data mining algorithms typically discover association rules from the whole database If there are additions, deletions or modifications of any tuples in the database after the discovery of a set of association rules one can mine the whole set of association rules from scratch or use some incremental updating techniques \(e.g FUP 9 to update the discovered association rules To deal with the data collected in different time periods the active data mining technique has been proposed in 2 to mine rules from the database in each time period These rules together with their parameters e.g support and confidence are stored in a rule base The changes in each parameter over time called history are represented by recursively combining a set of symbols \(called elementary shapes using shape operators The rule base can then be queried using predicates that select rules based on the shape of the history of some or all parameters This technique which provides a means to represent and to query the shape of the history of parameters for the discovered rules is not developed for mining and predicting changes in rules over time A statistical approach has been proposed in 13 to distinguish stable, semi-stable and trend rules from unstable ones discovered in different time periods A rule is stable if it does not change a great deal over time whereas it is a trend rule if it indicates some underlying systematic trends The semi-stable stable and trend rules are found based on z statistic chi-squared statistic and run test respectively Again, this approach which finds the rules that do not change significantly in different time periods \(stable and semi-stable rules and the rules that indicate some systematic trends trend rules based on a number of statistical tests is not developed for mining and predicting changes in rules over time Furthermore a framework has been proposed in Ill for measuring the difference between two datasets called deviation It makes use of a data mining algorithm to build two models one from each dataset The difference between the models is used as the measure of deviation between the underlying datasets The deviation measure employed in the framework can intuitively be considered as the amount of work required to transform one model to the other Although the datasets can be collected in different time periods and hence this framework can be used to measure the difference between the models over time, it is not developed to discover the regularities about changes in the models and it is therefore not developed to predict the changes 111 AN OVERVIEW OF THE PROPOSED APPROACH We provide an overview of our approach for mining changes in association rules in the following First of all a set of data is collected in each time period and they are stored in a database Let us suppose that there are n time periods tl  t and in each time period, a set of data Di i E  1  n is collected and stored in a database D The granularity of the time periods is application dependent Given the database D we can therefore divide it into a number of partitions DI  D according to the time periods tl  t in each of which the corresponding database partition is collected Secondly the domain of quantitative attributes is discretized using any discretization technique e.g lo and a set of association rules Ri i E  1    n is discovered in each database partition Di i E 1  n using any association rule mining algorithm e.g l 3 14-15 This results in a rule set R  RI v  v R Thirdly the missing supports and confidences of association rules in R are found Let us consider the case that a rule r E R appears in Ri but not in Rj i  j because r does not satisfy the minimum support and/or minimum confidence constraints in Di However for our approach to mine the changes in association rules in tl  t the supports and confidences of each rule in R in tl   t are required We therefore scan D once to find all the missing supports and confidences of each rule in R in all time periods Finally, after the supports and confidences of all rules in R in all time periods have been obtained we can mine a set of fuzzy rules to represent the changes in association rules during the period from tl to t Using the discovered fuzzy rules we can predict how the association rules are changed in Since the first and the third steps are straightforward and the user can choose any discretization technique and any association rule mining algorithm for the second step we will not further discuss them in this paper In the next section we will focus on the details of the final step tn+l IV MINING CHANGES IN ASSOCIATION RULES For each rule r E R we have a sequence of supports S  s  s where si E 10 11 i  1  n and a sequence of confidences C  cl  cn where ci E 0 13 i  1  n such that si and ci are support and confidence of Y in time 0-7803-7280-8/02/$10.00 02002 IEEE 891 


period ti respectively S can be converted to a set of subsequences SI    S   I where Si  si   Si   I i  1    n  w  1 by sliding a window of width w across the sequence Similarly C can be converted to a set of subsequences CI   Cn   I where C  c    c   I i  1  n  w  1 by sliding a window of width w across the sequence We can then mine a set of fuzzy rules in SI   Sn-w+l CI  C,,-,,,+I and predict the support confidence of r in t  1 i.e s  1 c  I using the discovered fuzzy rules For simplicity we only discuss how to mine fuzzy rules in subsequences SI   S   I and how to use the discovered rules to predict the value of s  in the rest of this section It is easy to extend the description to mine fuzzy rules in subsequences C1    C   1 and to predict the value of c  1 A Linguistic Terms Given subsequences SI    S   I where S  si  si   i  1   n  w  1 we define a set of linguistic terms over 0 13 which is the domain of each s i E 1   n Let us denote the linguistic terms as  v  1   h so that a corresponding fuzzy set L can be defined for each  The membership function of L is denoted as pLv and is defined as The fuzzy sets L v  1     h are then defined as L j for all x E 0 13 The degree of membership of some value x E 0 11 with some linguistic term  is given by pLV x  Using the above technique we can represent s i E  1   n  w  1  by a set of linguistic terms L    I v  1    h Since each linguistic term is represented by a fuzzy set we have a set of fuzzy sets L  tY I v  1  h Given a subsequence Si i E  1   n  w  1  and a linguistic term  E 4 which is in turn represented by a fuzzy set L E L the degree of membership of sj j E i    i  w  l in Si with respect to L;I is given by uLv si si in S can be represented by a set of ordered pairs gj such that   LI I   417 h where pui pL si  v  1  h and S can be represented by a fuzzy subsequence Gi such that G  s I 81  giw wheregij=g;+j-I,j 1  w Let Q be a subset of integers such that Q  U  j wherejl  j E 1  w l f   j and 14  U 2 1 We further suppose that gip gjj Ij E q Given any g it is associated with a set of linguistic terms L k  1  h Each L is defined by a set of linguistic terms L I L j E gij j E PA v E 1  hl The degree ILe G  to which Gi is characterized by the term  is defined as R'~\(Gi i+j-l I G,~\(i+j-l gij A~E Y~AVE I1,...,hI For any subsequence G i E 1  n  w  l let oLqLp Gi be the degree to which G is characterized by the linguistic terms  and L where  E L q E  1  h is associated with gi okqC Gi is defined as We further suppose that degLqL is the sum of degrees to which G i  1   n  w  1 characterized by the linguistic terms  and L degLwqL is given by n-wtl i=l B The Fuzzy Data Mining Algorithm It is important to note that a fuzzy rule can be of different orders A first-order fuzzy rule can be defined to be a rule involving one linguistic term in its antecedent; a second-order rule can be defined to have two and a third-order rule can be defined to have three linguistic terms etc Our approach is given in Fig 1 1 Fl   first-order fuzzy rules 2 for d=2 IFd-11 f  d do T each linguistic term in the antecedent of I 1 1 E Fd forall Q composed of d elements in T do q 6 calculate degL using 2 7 forall kq L do 8 begin 9 if interesting L then 10 11 end 12 end 13 F  uFd  Id Fd  Fd U rulegen Le    Fig 1 The hzzy data mining algorithm To mine interesting first-order rules our approach makes use of an objective interestingness measure introduced in Section C below ARer these rules are discovered, they are stored in F1 Fig 1 Rules in FI are then used to generate second-order rules that are then stored in F2 F2 is then used to generate third-order rules that are stored in F3 and so on for 4th and higher order Our approach iterates until no higher order rule can be found 0-7803-7280-8/02/$10.00 02002 IEEE 892 


The function interesting L computes an objective measure to determine whether the relationship between  and L is interesting If interesting Lek returns true a fuzzy rule is then generated by the rulegen function For each rule generated this function also returns an uncertainty measure associated with the rule see Section D All fuzzy rules generated by rulegen are stored in Fthat will then be used later for prediction or for the user to examine C Discovering Interesting Rules in Fuzzy Subsequences In order to decide whether a relationship between a linguistic term L and another linguistic term  is interesting we determine whether sum of degrees to which records characten zed by L and Lw sum of degrees to which records characten zed by Ld 3 pT\(Lw   is significantly diflerent from 4 sum of degrees to which records characterized by  M P   h h where A4  y,y,deg,ujL  If this is the case, we consider the relationship between L and  interesting The significance of the difference can be objectively evaluated based on the idea of the adjusted residual 4-81 defined as j=1 i=l where z is the standardized residual 4-81 and is given by where ehq is the sum of degrees.to which records are expected to be characterized by L and  It is defined as h h and yLqL6 is the maximum likelihood estimate 4-81 of the variance of zL and is given by w9  0-7803-7280-8/02/$10.00 02002 IEEE If dLwqL6  1.96 the 95 percentiles of the normal distribution we can conclude that the discrepancy between Pr I L and Pr is significantly different and hence the relationship between L and  is interesting Specifically, the presence of L implies the presence of  In other words it is more likely for a record having both L and  D Uncertainty Representation linguistic term wq we can form the following fuzzy rule Given that a linguistic term Lgk is associated with another where CO is the weight of evidence measure that is defined as follows Since the relationship between L and  is interesting there is some evidence for a record to be characterized by Lq given it has L The weight of evidence measure is defined in terms of an information theoretic measure known as mutual information Mutual information measures the change of uncertainty about the presence of  in a record given that it has L is in turn defined as 9 Based on mutual information the weight of evidence measure is defined in 4-81 as wLWq6 can be interpreted intuitively as a measure of the difference in the gain in information when a record with  characterized by  and when characterized by other linguistic terms The weight of evidence measure can be used to weigh the significance or importance of hzzy rules E Predicting Unknown Values Using Fuzzy Rules Given a subsequence d  a  a where q E 0 11 j  1  w a is the value to be predicted d can be represented by a fuzzy subsequence d  VI    Ow where 893 


P is a set of order pairs 4 PL aj 1  Lh PL a 11 j  1     w The value of a is given by the value of p To predict the correct value of pw our approach searches the fizzy rules with 6 E L as consequents For any combination of values ab w E p of d it is characterized by a linguistic term L to a degree of compatibility AL d  for each k E  1   h Given those rules implying the assignment of  L LWq oLwqL  for all k E c  1   h the evidence for such assignment is given by a  c wqL  AL 4 1 1 ks 4 Suppose that of the w  1 values excluding A only some combinations of them All  Ail  44 with I P I j E  1     w  1   are found to match one or more rules then the overall weight of evidence for the value of to be assigned to LH.4 is given by BEDRM LIVRM PRICE i=l Number of bed rooms Number of living rooms Price nf the flat As a result the value of is given by LI q  4 q    a In order to assign a crisp value to  the following method is used Given linguistic terms L1    4 and their overall weight of evidences q  a let U x be the weighted degree of membership of x E 0 11 to the fuzzy set L q E  1     h p x is given by 4 where x E 0 13 and q  1  h The defuzzified value F-'\(UL which provides an appropriate value for c is then defined as h q=l where pkuu x  max x p x for any fizzy sets X and Y V PERFORMANCE ANALYSIS To evaluate the performance of our approach we tested it on the property database provided by the Hong Kong ofice of a worldwide property valuation company The property database is extracted from the data warehouse maintained by the company It contains the details of all buyhell transactions of flats at Whampoa Garden in Hong Kong during the period between 199 1 and 2000 Whampoa Garden which is one of the largest private real estates in Hong Kong has been developed into 12 separate phases and there are 88 residential towers comprising 10,43 1 flats The database consists of 1 1,176 records in total Each of these records represents a buyhell transaction of a flat and is characterized by 11 attributes Of these attributes 3 are categorical and 8 are quantitative These attributes are summarized in Table 1 TABLE 1 ATTRIBUTES IN THEproperty DATABASE DERV-SIZE BUILD-AGE I Building age I Size of the flat I 0w I Size of hav window I The domain expert from the company aims at predicting the value of PRICE of a flat based on other attributes To perform this task we first divided the property database into 10 partitions D1  DI0 where Dl contains the buyhell transactions in 1991 02 contains the buyhell transactions in 1992 etc We then dmretized the domain of quantitative attributes into 5 intervals using lo and made use of Apriori 3 to discover 9 sets of association rules RI  Rg from the first 9 database partitions D1   Dg After that we scanned the 9 database partitions once to find the missing supports and confidences of the discovered association rules R  RI v   v R9 Finally we applied the fuzzy data mining algorithm described in Section IV to discover a set of fizzy rules which represents the regularities about changes in the support and confidence of each association rule in R Using the discovered fizzy rules we predicted how the support and confidence of each association rule in R changed This resulted in a set of association rules RI such that the support and confidence of each rule in R is predicted based on the changes in the association rules discovered in the time period between 1991 and 1999 We then used CBA to predict the value of PRICE in each record in the last database partition Dlo using R  Specifically, given a record in Dlo CBA classifies it into one of the 5 intervals and the mid-point of this interval is considered as the value of PRICE predicted by CBA In our experiments we used the percentage error as a performance measure Let N be the number of records in Dlo For any record ZE Dl0 let t,be the target value of PRICE in z and or be the value predicted by CBA The percentage error error is defined as 0-7803-7280-8/02/$10.00 02002 IEEE 894 


To hrther evaluate the performance of our approach we used the association rules discovered in 09 i.e R9 to predict the value of PRICE in the records in D~o Furthermore we also divided Dlo into two datasets one for training and the other for testing The training dataset contains 80 of records in Dl0 and the testing dataset contains the remaining 20 of records We then discovered a set of association rules RIO from the training dataset and used these rules to predict the value of PRICE in the records in the testing dataset This step is repeated ten times It is important to note that the prediction of the value of PRICE in the records in the testing dataset based on the association rules discovered in the training dataset is the ideal case because the training and testing datasets are randomly selected from DIO and they are therefore homogeneous All the experiments were performed on a Sun Ultra 5 workstation with 64 MB of main memory running Solaris 2.6 In our experiments we set the minimum support to 1 and the minimum confidence to 50 for the mining of association rules We also set the width of the sliding window w to 5 The experimental results are given in Table 2 TABLE 2 EXPERIMENTAL RESULTS ON THEproperty DATABASE Rule Set R9 R;\224 Percentage Error 16.7 15.1 224 I RIO I 14.2 I As shown in Table 2 the rule set produced by our approach i.e R  obtained better accuracy than the rule set discovered in 09 collected in 1999 i.e R9 in predicting the value of PRICE in the records in Dlo collected in 2000 Although the performance of our approach is not as good as the ideal case i.e RIO the experimental results shown that our approach is able to improve the performance of a data mining algorithm by discovering and predicting the changes in rules over time VI CONCLUSIONS Existing data mining algorithms typically assume that the underlying associations hidden in the data are stable over time and they therefore discover association rules from the whole database However it is possible that the data characteristics and the associations change significantly in different time periods Although it is an important problem existing data mining algorithms have not taken these changes into consideration In this paper we introduced a fuzzy approach for mining and predicting how the association rules changed over time To evaluate the performance of the proposed approach we have applied it to a database containing all buyhell transactions of flats in a large private real estate in Hong Kong during the period between 1991 and 2000 The experimental results shown that our approach is very effective in mining and predicting changes in association rules in such a way that it can improve the performance of existing data mining algorithms especially when the discovered rules are used for classification \(prediction ACKNOWLEGMENTS The research was supported in part by PolyU Grant A P209 and G-V918 REFERENCES R Agrawal T Imielinski, and A Swami 223Mining Association Rules between Sets of Items in Large Databases,\224 in Proc of the ACM SIGMOD Int ConJ on Management of Data Washington D.C 1993 R Agrawal and G Psaila, \223Active Data Mining,\224 in Proc of the 1st Int\222l Con on Knowledge Discovery and Data Mining Montreal Canada, 1995 R Agrawal and R Srikant, \223Fast Algorithms for Mining Association Rules,\224 in Proc of the 20th Int Con on Very Large Data Bases Santiago, Chile, 1994 pp 487499 W.-H Au and K.C.C Chan, \223An Effective Algorithm for Discovering Fuzzy Rules in Relational Databases,\224 in Proc of the 7th IEEE Inr\222l Con on Fuzzy Systems Anchorage Alaska, 1998 pp 1314-1319 W.-H Au and K.C.C Chan 223FARM A Data Mining System for Discovering Fuzzy Association Rules,\224 in hoc of the 8th IEEE Int Con on Fuzzy Systems Seoul Korea 1999 pp 1217-1222 W.-H Au and K.C.C Chan 223Classification with Degree of Membership A Fuzzy Approach,\224 in Roc of the Jst IEEE Int\222l ConJ on Data Mining San Jose, CA 2001 K.C.C Chan and W.-H Au 223Mining Fuzzy Association Rules,\224 in Proc of the 6th Int 222I ConJ on Information and Knowledge Management Las Vegas Nevada, 1997 pp 209-2 15 K.C.C Chan and W.-H Au 223Mining Fuzzy Association Rules in a Database Containing Relational and Transactional Data,\224 in A Kandel M Last and H Bunke Eds Data Mining and Computational Intelligence New York NY: Physica-Verlag 2001 pp 95-1 14 D.W Cheung J Han V.T Ng and C.Y Wong 223Maintenance of Discovered Association Rules in Large Databases An Incremental Updating Technique,\224 in Proc of the 12th In17 ConJ on Data Engineering New Orleans, Louisiana, 1996 pp 106-1 14 pp 207-216 lo J.Y Ching A.K.C Wong and K.C.C Chan 223Class-Dependent Discretization for Inductive Learning from Continuous and Mixed Mode Data,\224 IEEE Trans on Pattern Analysis and Machine Intelligence vol 17 no 6 pp 1-11 1995 I V Ganti J Gehrke, R. Ramakrishnan, and W.-Y Loh, \223A Framework for Measuring Changes in Data Characteristics,\224 in Proc of the 18th ACM SIGMOD-SIGACT-SIGART Symp on Principles of Database Systems Philadelphia PA 1999 pp 126-137 I21 B Liu W Hsu and Y Ma, \223Integrating Classification and Association Rule Mining,\224 in Proc of the 4th Inr ConJ on Knowledge Discovery andData Mining New York NY 1998 I31 B Liu Y Ma and R Lee 223Analyzing the Interestingness of Association Rules from the Temporal Dimension,\224 in hoc of the Jsr IEEE Int ConJ on Data Mining San Jose CA 2001 I41 H. Mannila H Toivonen, and A.I Verkamo, \223Efficient Algorithms for Discovering Association Rules,\224 in Proc of the AAAI Workshop on Knowledge Discovely in Databases Seattle Washington 1994 pp 15 R Srikant and R. Agrawal, \223Mining Quantitative Association Rules in Large Relational Tables,\224 in Proc of the ACM SIGMOD Int\222l ConJ on Management ofData Montreal Canada, 1996 pp 1-12 181-192 0-7803-7280-8102/$10.00 \(92002 IEEE 895 


Fragment 1 Fraamenl2 Fragment 3 CA 17.75 CA 17.75 CA 22.46 Ct/CM 0.061 CI/CM 0.062 CI/CM 0.092 Fragment 1 CA 11.0 Fragment 2 CA 11.9 CVCM 0.3 CVCM 0.4 Figure 7 The two largest fragments with a sulfur atom These fragments are common to I I of the 13 Dyes and Polyanions Figure 5 The three largest fragments containing a nitrogen atom Fraamenl 1 639762 CM 254064 MO2670 NIN:N A 0 A N:N Figure 6 One pmicular compound 254064 along with a repre sentative of the normal structure \(#602670 within approximately 20 minutes The three largest frag ments found are shown in Figure 5 Note how the first two fragments have essentially the same coverage The only difference is one additional com pound of class CI that contains fragment 2 In this com pound the three nitrogen atoms are connected to the 4 carbon-oxygen ring through an intermediate carbon This results in a fragment where the carbon connected to the three nitrogen atoms is part of a ring in all cases but one which prevents the search algorithm from closing the ring The ring was closed in the first fragment however, result ing in one less inactive compound being covered Figure 6 shows this specific compound along with another compound of class CA that exhibits the more typical structure The third fragments coverage is substantially different even though its structure is almost identical The only differ ence is the double bond between two carbons that closes the second ring in the fint fragment which is missing in Frag ment 3 However some active compounds have a single bond instead of a double bond between these carbons and hence not closing this ring results in a slightly smaller frag ment with a much higher coverage This fragment success fully picks out compounds of class Azido Pyrimidines a well-known inhibitor of HIV-I Below we will discuss how softening the matching criteria allows us to tolerate such small differences between otherwise identical fragments which makes this approach also more useful for chemists who tend lo regard such structures as similar 3.2 Sulfur based Fragments Next we seeded the algorithm with a sulfur atom We chose the thresholds support=lO% and complement=O.S which We used a Java implemenlalion of our algorithm on a lGhz Xeon Dual-Rocerror machine with IGB of main memory uringjrel.3.1 639763 CM a d t1639767 CA Fragment 2 639764 CI Q freq CA 33.3 freq CI/CM 3.0 a I It639772 CA Figure 8 Fragments left and corresponding compounds right containing a Selenium atom The two compounds of class CA are members of the group of Heavy Metal Compounds generated a list of 122 fragments in under one minute The first two which also happen to be the largest ones with 18 atoms and 19 bonds resp are shown in Figure 7 Note how these two fragments differ only in the loca tion of the SO3 group Both fragments exhibit a lift of well above 25 and pick out 1 I of the 13 molecules listed as Dyes and Polyanions We miss only two of the remaining Dyes and Polyanions \(it9617 and #65849 which contain uncom mon structures for this family of compounds 3.3 Selenium based Fragments An interesting effect of the current method to find fragments can he seen when seeding the algorithm with a Selenium atom Se Figure 8 left shows the two fragments that are found for a minimum support of 30 and a maximum complement support of 5 Clearly the first fragment is sufficient to pick out all 7 compounds from the database shown on the right of Fig ure 8 However, the second fragment covers one compound less 639766 and tries to complete the aromatic ring in both directions in parallel This results in a conflict with the nitrogen atom in compound 639766 and a fragment which is neither a subset of the other fragment nor has exactly the same coverage For our algorithm these two fragments are therefore unique and are not pruned 57 


single bond  aromatic bond single bOnd  aromatic bDnd d CBO Figure 9 Two fragments extracted from a sei of steroids On the left, single and aromatic bonds were treated as different bond types. on the right they were treated as the same bond type 3.4 Treatment of Aromatic Bonds An important aspect of molecular fragment mining is the treatment of aromatic rings Since ammaticity is not clearly defined and can be modeled differently i.e explicit aro matic bonds vs alternating single and double bonds it is desirable to be able to take it into account throughout the mining process itself We achieve this by modeling aro matic bonds as either single or double bonds with a flag that indicates aromaticity This allows us to choose to ignore this flag during mining and hence to find fragments that contain either aromatic or single resp double bonds The following example illustrates why this is desirable Using a small set of steroid compounds we derived frag ments that occur in ail of them support=100%\using the standard algorithm Figure 9 left shows the correspond ing fragment Note how only two rings with an incomplete third ring are discovered of the four ring structure that is typical for steroids However if we model aromatic bonds as single+flag and allow the algorithm to ignore this flag the resulting fragment contains all four rings see Figure 9 right For some steroids this fourth ring consists of sin gle bonds while others have an aromatic ring at this posi tion However most chemists still regard this as the same 4 ring structure Such selective 223tolerance\224 against some mis matches can therefore make the presented algorithm more useful for real applications 4 Conclusions We presented an algorithm to find relevant molecular frag ments in large chemical structure databases The algorithm allows us to focus on fragments that help to discriminate be tween different classes of molecules The underlying search method, which is based on a depth first search with struc tural pruning makes it possible to find such fragments effi ciently without the need for frequent reembeddings of frag ment candidates, which is a known problem of previously reponed approaches We have shown how the proposed method finds relevant fragments using data from a well known HIV-screening compound database The extracted fragments successfully model several of the activity classes known for this dataset Future work will focus on making the presented approach more meaningful for the underlying application In partic ular finding fragments that match exactly is not of prime interest to chemists As demonstrate above some types of ring structures are considered functionally equivalent which should be taken into account by the search algorithm as well We are currently exploring ways to include such 223fuzziness\224 into the underlying search algorithm directly References I R Agrawal T Imielienski and A Swami. Mining Associa tion Rules between Sets of Items in Large Databases Pmc Con on Management of Data 207-216 ACM Press New York NY USA 1993 Apriori  Finding Association Rules with the Apriori Algorithm free computer software under the GLPL http://fuzzy.cs.uni-magdeburg.de/borgeltiapriori 31 C Borgelt and R Kruse Induction of Association Rules Apriori Implementation Proc 14th Con on Computational Statistics \(COMPSTATJ Berlin Germany 2002 4 R.D Clark Relative and Absolute Diversity Analysis of Combinatorial Libraries Combinatorial Library Design and Evaluation 337-362 Dekker New York NY USA 2001 SI M Desphande M Kuramochi and G Karypis Automated Approaches for Classifying Structures Proc Workhop on Doto Mining in Bioinformatics BioKDD 11-18,2002 6 1 Hipp A Myka, R Wirth and U Giintzer A New Algo rithm for Faster Mining of Generalized Association Rules Proc 2nd Europ Symp on Principles of Data Mining and Knowledge Discovery fPKDD.98 Names France 74-82 LNAl 1510 Springer, Heidelberg Germany 1998 17 S Kramer L de Raedt and C Helma Molecular Feature Mining in HIV Data Pmc 7th In Cu.!f on Knowledge Dis covery and Data Mining fKDD-2JO Son Francisco CA 136-143 ACM Press New York NY USA 2001  C Borgelt 8 http:lldlp.nci.nih.gov/doc~aids/aid~.dat~.ht~l 191 I W Raymond E I Gardiner and P Willett. Heuristics for Similarity Searching of Chemical Graphs using a Maximum Common Edge Subgraph Algorithm Journal of Chemical Information ond Computer Sciences 42\(2 Amer ican Chemical Society Columbus, OH USA 2002 IO W J Streich and R Franke Topological Phmacophores New Methods and Their Application to a Set of Anti malarials Parl 1 The Methods LOGANA and LOCON Quant Strct.-Act Relat.,4:13-18 I Wiley  Sons.Chich ester United Kingdom 1985 Ill 0 Weislow R Kiser D Fine J Bader R Shoemaker and M Boyd New Soluble Formazan Assay for HIV-I Cytopathic Effects Application to High Flux Screening of Synthetic and Natural Products for AIDS Antiviral Activity Journal of the Notional Cancer Institute 81577-586 Ox ford University Press Oxford United Kingdom 1989 1121 M Zaki S Panhasarathy M Ogihara and W Li New Al gorithms for Fast Discovery of Association Rules Proc 3rd Inr Con on Knon,ledge Discovery and Data Mining KDD\22297J 283-296 AAA1 Press Menlo Park, CA USA 1997 58 


   0 100 200 300 400 500 600 700 800 65 70 75 80 85 90 95 100 Confidence threshold Execution time \(sec    0 100 200 300 400 500 600 700 800 65 70 75 80 85 90 95 100 Similarity threshold Execution time \(sec Wlog WlogP plinkF plinkT News dicD   0 50 100 150 200 65 70 75 80 85 90 95 100 Confidence Threshold Memory \(MB    0 50 100 150 200 65 70 75 80 85 90 95 100 Similarity Threshold Memory \(MB Wlog WlogP plinkF plinkT News dicD a b g h   e plinkT 0 100 200 300 400 500 600 700 65 70 75 80 85 90 95 100 Confidence threshold Time \(sec   c Wlog 0 100 200 300 400 500 600 700 65 70 75 80 85 90 95 100 Confidence threshold Time \(sec   f plinkT 0 100 200 300 400 500 600 700 65 70 75 80 85 90 95 100 Similarity threshold Time \(sec     d Wlog 0 100 200 300 400 500 600 700 65 70 75 80 85 90 95 100 Similarity threshold Time \(sec 100-bitmap 100%-base 100%-bitmap 100%-base Pre-scaning    i NewsP 0 50 100 150 200 65 70 75 80 85 90 95 100 Confidence threshold Time \(sec DMC-imp a-priori K-Min    j NewsP 0 50 100 150 200 65 70 75 80 85 90 95 100 Similarity threshold Time \(sec DMC-sim a-priori Min-Hash Figure 6 Experimental results 


polgar -> international polgar -> old polgar -> judit polgar -> champion polgar -> youngest polgar -> chess polgar -> kasparov polgar -> men polgar -> highest polgar -> top polgar -> soviet polgar -> players polgar -> federation polgar -> player polgar -> ranked polgar -> grandmaster polgar -> garri  j udit -> soviet j udit -> hungary kasparov -> chess kasparov -> game kasparov -> champion grandmaster -> soviet grandmaster -> champion grandmaster -> chess garri -> chess garri -> kasparov garri -> soviet garri -> championship garri -> champion Figure 7 Sample rules the memory optimization techniques for DMC and MinHash will not improve their performance signi\002cantly Fig 6\(i and j show the execution times of these algorithms The K-Min algorithm is a variant algorithm of Min-Hash  which can extract implication rules instead of similarity rules However it could not extract complete sets of true rules therefore we plotted the execution time when the number of false negatives was less than 10 The other algorithms including Min-Hash for 002nding similarity rules could extract complete sets of true rules In this experiment a-priori is best for 002nding implication rules with 75%-or-less con\002dence threshold and Min-Hash is best for 002nding similarity rules with 70%or-less similarity threshold respectively However the DMC algorithms are best for 002nding both implication and similarity rules with high threshold 6.3 Extracted rules Text-mining by using extracted implication rules with low-support pruning is one of the interesting applications for our algorithms Fig 7 shows sample rules we extracted from News with an 85 con\002dence threshold and with a support pruning less than 5 These rules are extracted by selecting all rules related to keyword Polgar and its successors recursively This set of rules indicates information about Miss Judit Polgar who is 12-years-old has been ranked No 1 in the women's world chess 7 Conclusion and future works We presented two new algorithms DMC-imp and DMCsim  for 002nding implication and similarity rules Our algorithms do not use support pruning but use con\002dence or similarity pruning which reduces the memory size signi\002cantly We also proposed the other pruning techniques row re-ordering  100%-rule pruning  columndensity pruning and maximum-hits pruning  In order to evaluate the performance of the algorithms we used 4 sets of data Web-access logs Web-page-link graph news documents and a dictionary The algorithms have been implemented on a Sun Ultra 2  2 002 200 MHz 256MB memory workstation According to the experimental results our algorithms can be executed in a reasonable time The algorithms that proposed previously can not execute on our data sets since the algorithms required more than 256MB memory Therefore we compared performance by using the News data sets by pruning by using support threshold 35 so that all counters for a-priori can 002t in main memory The comparison results shows that DMC-imp can execute 1.7 times faster than a-priori  and 1.9 times faster than K-Min  and that DMC-sim can execute 5.9 times faster than apriori  and 1.7 times faster than Min-Hash  in case of an 85 threshold The followings are future research topics 017 Our algorithm can not extract rules among more than two columns while a-priori can do so However by grouping similarity and implication rules as showed in Sec 6.3 we can get useful groups of rules among more than two columns This idea can be applied to other data sets which generates more interesting rules 017 The memory requirement for News with less than 80 con\002dence threshold exceeds 256MB To be scalable this algorithm a parallel algorithm based on a divideand-conquer technique such as FDM 6 f or a-priori  is necessary References 1 R  A g r a w al T  I mielin sk i an d A  S w a mi M in in g Association Rules Between Sets of Items in Large Databases In Proceedings of the ACM SIGMOD Conference on Management of Data 1993 pp 207\226 216  R  A gra w al and R  S ri kant  F as t A l gori t h ms for Mining Association Rules In Proceedings of the 20th 


International Conference on Very Large Databases 1994  R  J  B ayardo J r  R  A gra w al and D  G unopul os  Constraint-Based Rule Mining in Large Dense Databases In Proceedings of the 15th International Conference on Data Engineering 1999 pp 188\226197 4 S  B rin  R Mo tw an i J.D Ullman  a n d S Tsu r  Dynamic itemset counting and implication rules for market basket data In Proceedings of the ACM SIGMOD Conference on Management of Data 1997 pp 255\226264  A  B roder  On the r esemblance and c ontainment of documents In Compression and Complexity of Sequences SEQUENCES'97  1998 pp 21\22629  D  W  C heung J  H a n V  T  N g  e t a l  A Fast Distributed Algorithm for Mining Association Rules In Proceedings of Conference on Parallel and Distributed Information Systems 1996 pp 31\22642 7 E  C o h e n  Size-Estimatio n F rame w o rk with Applications to Transitive Closure and Reachability Journal of Computer and System Sciences 55 1997 441\226453 8 E  C o h e n  M Datar  S Fu jiw ara A Gio n i s et al Finding Interesting Associations without Support Pruning In Proceedings of the 16th International Conference on Data Engineering  2000  R O D uda and P E H art Pattern Classi\002cation and Scene Analysis  A Wiley-Interscience Publication New York 1973  A  G i oni s  P  Indyk and R  M ot w a ni  S i m i l a ri t y Search in High Dimensions via Hashing In Proceedings of the 25th International Conference on Very Large Databases 1999 11 D Go ld b e r g  D  Nich o l s B.M Ok i an d D  T erry  Using collaborative 002ltering to weave an information tapestry Communications of the ACM 55 1991 1\226 19  S  G uha R  R as t ogi  a nd K  S h i m  C U R E A n Ef\002cient Clustering Algorithm for Large Databases In Proceedings of the ACM-SIGMOD International Conference on Management of Data 1998 pp 73\22684  R  Mot w ani a nd P  R a gha v a n Randomized Algorithms Cambridge University Press 1995  J  S  P a rk M S  C hen and P S  Y u A n ef fect i v e hash-based algorithm for mining association rules In Proceedings of the ACM SIGMOD Conference on Management of Data 1995 pp 175\226186  P r oj ect G u t e nber g  http:..www.gutenberg.net  1999  N Shi v akumar and H  G arcia-Molina B u ilding a Scalable and Accurate Copy Detection Mechanism In Proceedings of the 3rd International Conference on the Theory and Practice of Digital Libraries  1996  H.R  V a rian and P  R esnick E ds C A C M S pecial Issue on Recommender Systems Communications of the ACM 40 1997 


User Anomaly Description programmer2 logs in from beta secretary logs in at night sysadm logs in from jupiter programmer1 becomes a secretary secretary becomes a manager programmer1 logs in at night sysadm becomes a programmer manager1 becomes a sysadm manager2 logs in from pluto Table 12 User Anomaly Description User Normal Anomaly programmer2 0.58 0.79 0.00 secretary  1  1  0.00 sysadm 0.84 0.95 0.00 programmer1 0.31 1.00 0.04 secretary 0.41 0.98 0.17 programmer1  1  1  0.00 sysadm 0.64 0.95 0.00 manager1 0.57 1.00 0.00 manager2 1.00 1.00 0.00 Table 13 Similarity with User's Own Pro\002le tivities of each time segment am pm and nt We treat the 5th week as the training period during which we compare the patterns from each session to the pro\002le of the time segment We record the normal range of the similarity scores during this week The data in the 6th week has some user anomalies as described in Table 12 For each of the anomalous sessions we compare its patterns against the original user's pro\002le and then compare the resulting similarity score against the recorded normal range of the same time segment In Table 13 the column labeled 223Normal\224 is the range of similarity of each user against his or her own pro\002le as recorded during the 5th week A 1 here means that the user did not login during the time segment in the 5th week The column 223Anomaly\224 is the similarity measure of the anomalous session described Table 12 We see that all anomalous sessions can be clearly detected since their similarity scores are much smaller than the normal range For example when the sysadm becomes programmer see Table 12 his/her patterns have zero matches with the sysadm's pro\002le while for the whole 5th week the pm similarity scores are in the range of 0.64 to 0.95 Unfortunately formal evaluation statistics are not available to determine the error rates of this approach However this initial test indicates a path worthy of future study 6 Related Work Network intrusion detection has been an on-going research area 17  M ore r ecent s ystems e g B ro 18   NFR 6  a n d EMERALD  1 9  a ll mad e e x ten s ib ility th eir primary design goals Our research focuses on automatic methods for constructing intrusion detection models The meta-learning mechanism is designed to automate the extention process of IDSs We share the same views discussed in 20 t h at an ID S s houl d b e b ui l t us i n g s t a ndard components We believe that the operating system and networking community should be responsible for building a robust 223Event\224 box In 10  a l gori t h ms for a nal y zi ng us er s h el l c ommands and detecting anomalies were discussed The basic idea is to 002rst collapse the multi-column shell commands into a single stream of strings and then string matching techniques and consideration of 223concept drift\224 are used to build and update user pro\002les We believe that our extended frequent episodes algorithm is a superior approach because it considers both the association among commands and arguments and the frequent sequential patterns of such associations 7 Conclusions and Future Directions In this paper we outline a data mining framework for constructing intrusion detection models The key idea is to apply data mining programs to audit data to compute misuse and anomaly detection models according to the observed behavior in the data To facilitate adaptability and extensibility we propose the use of meta-learning as a means to construct a combined model that incorporate evidence from multiple lightweight base models This mechanism makes it feasible to introduce new ID components in an existing IDS possibly without signi\002cant re-engineering We extend the basic association rules and frequent episodes algorithms to accommodate the special requirements in analyzing audit data Our experiments show that the frequent patterns mined from audit data can be used as reliable user anomaly detection models and as guidelines for selecting temporal statistical features to build effective classi\002cation models Results from the 1998 DARPA Intrusion Detection Evaluation Program showed our detection models performed as well as the best systems built using the manual knowledge engineering approaches Our future work includes developing network anomaly detection strategies and devising a mechanical procedure to translate our automatically learned detection rules into modules for real-time IDSs A preliminary project in collaboration with NFR has just started 12 


8 Acknowledgments We wish to thank our colleagues at Columbia University Chris Park Wei Fan and Andreas Prodromidis for their help and encouragement References 1 R  A g r a w a l  T  I m i e lin sk i a n d A  S w a m i  M in in g a sso c i a tion rules between sets of items in large databases In Proceedings of the ACM SIGMOD Conference on Management of Data  pages 207\226216 1993 2 P  K  C han a nd S  J S t ol f o  T o w ar d p ar al l e l a nd di st r i b u t e d learning by meta-learning In AAAI Workshop in Knowledge Discovery in Databases  pages 227\226240 1993 3 W  W  C ohen Fast ef f ect i v e r ul e i nduct i on I n Machine Learning the 12th International Conference  Lake Taho CA 1995 Morgan Kaufmann 4 U  F ayyad G P i at et sk yS h api r o and P  S myt h  T he KDD process of extracting useful knowledge from volumes of data Communications of the ACM  39\(11\:27\22634 November 1996 5 K  I l gun R  A K e mmer e r  and P  A  P or r a s S t at e t r a nsition analysis A rule-based intrusion detection approach IEEE Transactions on Software Engineering  21\(3\:181\226 199 March 1995 6 N  F  R  I n c  N etw o rk 003ig h t reco rd er  h ttp www n fr co m  1997 7 V  J acobson C  L e r e s and S  M cC anne t cpdump a v ai l a bl e via anonymous ftp to ftp.ee.lbl.gov June 1989 8 C  K o  G Fin k  a n d K  L e v itt Au to m a te d d e t e c tio n o f v u l nerabilities in privileged programs by execution monitoring In Proceedings of the 10th Annual Computer Security Applications Conference  pages 134\226144 December 1994 9 S  K umar and E  H  S paf f or d A s of t w ar e a r c hi t ect ur e t o support misuse intrusion detection In Proceedings of the 18th National Information Security Conference  pages 194\226 204 1995  T  L a ne and C  E  B r odl e y  S equence m at chi n g a nd l ear ni ng in anomaly detection for computer security In AAAI Workshop AI Approaches to Fraud Detection and Risk Management  pages 43\22649 AAAI Press July 1997  W  L e e a nd S  J S t ol f o  D at a m i n i n g a ppr oaches f o r i nt r u sion detection In Proceedings of the 7th USENIX Security Symposium  San Antonio TX January 1998  W  L ee S  J S t ol f o  a nd K W  Mok Mi ni ng i n a d at a\003 o w environment Experience in intrusion detection submitted for publication March 1999  T  L unt  D et ect i n g i nt r uder s i n comput er syst ems I n Proceedings of the 1993 Conference on Auditing and Computer Technology  1993  T  L unt  A  T amar u F  Gi l h am R  J agannat h an P  N eumann H Javitz A Valdes and T Garvey A real-time intrusion detection expert system IDES 002nal technical report Technical report Computer Science Laboratory SRI International Menlo Park California February 1992  H Manni l a and H  T oi v onen Di sco v e r i ng gener a l i zed episodes using minimal occurrences In Proceedings of the 2nd International Conference on Knowledge Discovery in Databases and Data Mining  Portland Oregon August 1996  H Manni l a  H  T oi v onen and A  I  V er kamo D i s co vering frequent episodes in sequences In Proceedings of the 1st International Conference on Knowledge Discovery in Databases and Data Mining  Montreal Canada August 1995  B M ukherjee L T  Heberlein and K  N  L e v itt Netw ork intrusion detection IEEE Network  May/June 1994  V  Paxon B r o  A syst em f o r d et ect i n g n et w o r k i n t r uder s in real-time In Proceedings of the 7th USENIX Security Symposium  San Antonio TX 1998  P  A P o r r a s a nd P  G Neumann E m er al d E v ent m oni t o r i ng enabling responses to anomalous live disturbances In National Information Systems Security Conference  Baltimore MD October 1997  S  S t ai nf or dC h en C ommon i nt r u si on det ect i o n f r a me w o r k  http://seclab.cs.ucdavis.edu/cidf  S  J S t ol f o  A  L  P r odr omi d i s  S  T sel e pi s W  L ee D W  Fan and P K Chan JAM Java agents for meta-learning over distributed databases In Proceedings of the 3rd International Conference on Knowledge Discovery and Data Mining  pages 74\22681 Newport Beach CA August 1997 AAAI Press  S unS of t  Mount ai n V i e w  C A  SunSHIELD Basic Security Module Guide  13 


 30 40 50 60 70 80 90 100 110 120 30 40 50 60 70 80 90 10 0 Execution Time [s Number of Nodes Figure 13 Execution time of HPA program pass 2 on PC cluster 2 Scan the transaction database and count the support count Each processing node reads the transaction database from its local disk 000 itemsets are generated from that transaction and the same hash function used in phase 1 s applied to each of them Each of the 000 itemsets is sent to certain processing node according the hash value For the itemsets received from the other nodes and those locally generated whose ID equals the node\220s ID the hash table is searched If hit its support count value is incremented 3 Determine the large itemset After reading all the transaction data each processing node can individually determine whether each candidate 000 itemset satisfy user-specified minimum support or not Each processing node sends large 000 itemsets to the coordinator where all the large 000 itemsets are gathered 4 Check the terminal condition If the large 000 itemsets are empty the algorithm terminates Otherwise the coordinator broadcasts large 000 itemsets to all the processing nodes and the algorithm enters the next iteration 4.2 Performance evaluation of HPA algorithm The HPA program explained above is implemented on our PC cluster Each node of the cluster has a transaction data file on its own hard disk Transaction data is produced using data generation program developed by Agrawal designating some parameters such as the number of transaction the number of different items and so on The produced data is divided by the number of nodes and copied to each node\220s hard disk The parameters used in the evaluation is as follows The number of transaction is 5,000,000 the number of different items is 5000 and minimum support is 0.7 The size of the data is about 400MBytes in total The message block size is set to be 16KBytes according to the results of communication characteristics of PC clusters discussed in previous section The disk I/O block size is 64KBytes which seems to be most suitable value for the system Note that the number of candidate itemset in pass 2 s substantially larger than for the other passes which relatively frequently occurs in association rules mining Therefore we have been careful to parallelize the program effectively especially in pass 2 so that unnecessary itemsets to count should not be generated 14 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


The execution time of the HPA program pass 2 is shown in figure 13 as the number of PCs is changed The maximum number of PCs used in this evaluation is 100 Reasonably good speedup is achieved in this application as the number of PCs is increased 5 Conclusion In this paper we presented performance evaluation of parallel database processing on an ATM connected 100 node PC cluster system The latest PCs enabled us to obtain over 110Mbps throughput in point-to-point communication on a 155Mbps ATM network even with the so-called 217\217heavy\220\220 TCP/IP This greatly helped in developing the system in a short period since we were absorbed in fixing many other problems Massively parallel computers now tend to be used in business applications as well as the conventional scientific computation Two major business applications decision support query processing and data mining were picked up and executed on the PC cluster The query processing environment was built using the results of our previous research the super database computer SDC project Performace evaluation results with a query of the standard TPC-D benchmark showed that our system achieved superior performance especially when transposed file organization was employed As for data mining we developed a parallel algorithm for mining association rules and implemented it on the PC cluster By utilizing aggregate memory of the system efficiently the system showed good speedup characteristics as the number of nodes increased The good price/performance ratio makes PC clusters very attractive and promising for parallel database processing applications All these facts support the effectiveness of the commodity PC based massively parallel database servers Acknowledgment This project is supported by NEDO New Energy and Industrial Technology Development Organization in Japan Hitachi Ltd technically helped us extensively for ATM related issues References  R Agrawal T Imielinski and A Swami Mining association rules between sets of items in large databases In Proceedings of ACM SIGMOD International Conference on Management of Data  pages 207--216 1993  R Agrawal and R Srikant Fast algorithms for mining association rules In Proceedings of International Conference on Very Large Data Bases  1994  A C Arpaci-Dusseau R H Arpaci-Dusseau D E Culler J M Hellerstein and D A Patterson High-performance sorting on Networks of Workstations In Proceedings of International Conference on Management of Data  pages 243--254 1997  D.S Batory On searching transposed files ACM TODS  4\(4 1979  P.A Boncz W Quak and M.L Kersten Monet and its geographical extensions A novel approach to high performance GIS processing In Proceedings of International Conference on Extending Database Technology  pages 147--166 1996 15 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


 R Carter and J Laroco Commodity clusters Performance comparison between PC\220s and workstations In Proceedings of IEEE International Symposium on High Performance Distributed Computing  pages 292--304 1995  D.J DeWitt and J Gray Parallel database systems  The future of high performance database systems Communications of the ACM  35\(6 1992  J Gray editor The Benchmark Handbook for Database and Transaction Processing Systems  Morgan Kaufmann Publishers 2nd edition 1993  J Heinanen Multiprotocol encapsulation over ATM adaptation layer 5 Technical Report RFC1483 1993  M Kitsuregawa M Nakano and M Takagi Query execution for large relations on Functional Disk System In Proceedings of International Conference on Data Engineering  5th pages 159--167 IEEE 1989  M Kitsuregawa and Y Ogawa Bucket Spreading Parallel Hash:A new parallel hash join method with robustness for data skew in Super Database Computer SDC In Proceedings of International Conference on Very Large Data Bases  16th pages 210--221 1990  M Laubach Classical IP and ARP over ATM Technical Report RFC1577 1994  D.A Schneider and D.J DeWitt Tradeoffs in processing complex join queries via hashing in multiprocessor database machines In Proceedings of International Conference on Very Large Data Bases  16th pages 469--480 1990  T Shintani and M Kitsuregawa Hash based parallel algorithms for mining association rules In Proceedings of IEEE International Conference on Parallel and Distributed Information Systems  pages 19--30 1996  T Sterling D Saverese D.J Becker B Fryxell and K Olson Communication overhead for space science applications on the Beowulf parallel workstaion In Proceedings of International Symposium on High Performance Distributed Computing  pages 23--30 1995  T Tamura M Nakamura M Kitsuregawa and Y Ogawa Implementation and performance evaluation of the parallel relational database server SDC-II In Proceedings of International Conference on Parallel Processing  25th pages I--212--I--221 1996  TPC TPC Benchmark 000\001 D Decision Support Standard Specification Revision 1.1 Transaction Processing Performance Council 1995 16 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


In accordance with 1910.97 and 1910.209 warning signs are required in microwave areas For work involving power line carrier systems this work is to be conducted according to requirements for work on energized lines Comments s APPA objects to the absolute requirement implied by the word ensure regarding exposure to microwave radiation and recommends revision of s l iii to read when an employee works in an area where electromagnetic radiation levels could exceed the levels specified in the radiation protection guide the employer shall institute measures designed to protect employees from accidental exposure to radiation levels greater than those permitted by that guide  I1 an employee must be stationed at the remote end of the rodding operation Before moving an energized cable it must be inspected for defects which might lead to a fault To prevent accidents from working on the wrong cable would require identification of the correct cable when multiple cables are present Would prohibit an employee from working in a manhole with an energized cable with a defect that could lead to a fault However if the cable cannot be deenergized while another cable is out employees may enter the manhole but must protect against failure by some means for example using a ballistics blanket wrapped around cable Requires bonding around opening in metal sheath while working on cable Underaround EIectrical Installations t Comments t This paragraph addresses safety for underground vaults and manholes The following requirements are contained in this section Ladders must be used in manholes and vaults greater than four feet deep and climbing on cables and hangers in these vaults is prohibited Equipment used to lower materials and tools in manholes must be capable of supporting the weight and should be checked for defects before use An employee in a manhole must have an attendant in the immediate vicinity with facilities greater than 250 volts energized An employee working alone is permitted to enter briefly for inspection housekeeping taking readings or similar assuming work could be done safely Duct rods must be inserted in the direction presenting the least hazard to employees and APPA recommends that OSHA rewrite section 7\regarding working with defective cables This rewrite would include the words shall be given a thorough inspection and a determination made as to whether they represent a hazard to personnel or representative of an impending fault As in Subsection \(e EEI proposes the addition of wording to cover training of employees in emergency rescue procedures and for providing and maintaining rescue equipment Substations U This paragraph covers work performed in substations and contains the following requirements Requires that enough space be provided around electrical equipment to allow ready and safe access for operation and maintenance of equipment OSHA's position A2-16 


is that this requirement is sufficiently performance oriented to meet the requirements for old installations according to the 1987 NEW Requires draw-out circuit breakers to be inserted and removed while in the open position and that if the design permits the control circuits be rendered inoperative while breakers are being inserted and removed stated in the Rules and requests that existing installations not be required to be modified to meet NESC APPA recommends that Section u 4 i which includes requirements for enclosing electric conductors and equipment to minimize unauthorized access to such equipment be modified to refer to only those areas which are accessible to the public Requires conductive fences around substations to be grounded Power Generation v Addresses guarding of energized parts  Fences screens, partitions or walls This section provides additional requirements and related work practices for power generating plants  Entrances locked or attended Special Conditions w  Warning signs posted  Live parts greater than 150 volts to be guarded or isolated by location or be insulated  Enclosures are to be according to the 1987 NESC Sections llOA and 124A1 and in 1993 NESC  Requires guarding of live parts except during an operation and maintenance function when guards are removed barriers must be installed to prevent employees in the area from contacting exposed live parts Requires employees who do not work regularly at the substation to report their presence Requires information to be communicated to employees during job briefings in accordance with Section \(c of the Rules Comments U APPA and EEI provide comments as follows Both believe that some older substations \(and power plants would not meet NESC as This paragraph proposes special conditions that are encountered during electric power generation, transmission and distribution work including the following Capacitors  Requires individual units in a rack to be short circuited and the rack grounded  Require lines with capacitors connected to be short circuited before being considered deenergized Current transformer secondaries may not be opened while energized and must be bridged if the CT circuit is opened Series street lighting circuits with open circuit voltages greater than 600 volts must be worked in accordance with Section q\or t and the series loop may be opened only after the source transformer is deenergized and isolated or after the loop is bridged to avoid open circuit condition Sufficient artificial light must be provided where insufficient naturals illumination is present to enable employee to work safely A2-17 


US Coast Guard approved personal floatation devices must be supplied and inspected where employees are engaged in work where there is danger of drowning Required employee protection in public work areas to include the following  Warning signs or flags and other traffic control devices  Barricades for additional protection to employees  Barricades around excavated areas  Warning lights at night prominently displayed Lines or equipment which may be sub to backfeed from cogeneration or other sources are to be worked as energized in accordance with the applicable paragraphs of the Rules Comments w APPA submits the following comments regarding this Special Conditions section Recommends that the wording regarding capacitors be modified to include a waiting period for five minutes prior to short circuiting and grounding in accordance with industry standards for discharging of capacitors For series street light circuits, recommends that language be added for bridging to either install a bypass conductor or by placement of grounds so that work occurs between the grounds Recommends modification of the section regarding personal floatation devices to not apply to work sites near fountains decorative ponds swimming pools or other bodies of water on residential and commercial property Definitions x This section of the proposed Rules includes definitions of terms Definitions particularly pertinent to understanding the proposal and which have not previously been included are listed as follows Authorized Employee  an employee to whom the authority and responsibility to perform a specific assignment has been given by the employer who can demonstrate by experience or training the ability to recognize potentially hazardous energy and its potential impact on the work place conditions and who has the knowledge to implement adequate methods and means for the control and isolation of such energy CZearance for Work  Authorization to perform specified work or permission to enter a restricted area Clearance from Hazard  Separation from energized lines or equipment Comments x The following summarizes the changes in some of the definitions which APPA recommends Add to the definition for authorized employee It the authorized employee may be an employee assigned to perform the work or assigned to provide the energy control and isolation function  Recommends that OSHA modify the definition for a line clearance tree trimmer to add the word qualified resulting in the complete designation as a qualified line clearance tree trimmer Recommends that OSHA modify the definition of qualified employee" to remove the word construction from the definition since it is felt that knowledge of construction procedures is beyond the scope of the proposed rule resulting in APPA's new A2-18 I 


wording as follows more knowledgeable in operation and hazards associated with electric power generation transmission and/or distribution equipment Recommends that OSHA add a definition for the word practicable and replace the word feasible with practicable wherever it appears in the proposed regulations and that practicable be further defined as capable of being accomplished by reasonably available and economic means OTHER ISSUES Clothing OSHA requested comments on the advisability of adopting requirements regarding the clothing worn by electric utility industry employees EEI has presented comments which indicates research is underway prior to establishing a standard for clothing to be worn by electric utility employees However EEI's position is that this standard has not developed to the extent that it could be included in the OSHA Rules Both APPA and EEI state that they would support a requirement that employers train employees regarding the proper type of clothing to wear to minimize hazards when working in the vicinity of exposed energized facilities Grandfathering Due to the anticipated cost impact on the utility industry of the proposed Rules requiring that existing installations be brought to the requirements of the proposed Rules both APPA and EEI propose that the final Rules include an omnibus grandfather provision This provision would exempt those selected types of facilities from modification to meet the new rules EEI states that if the grandfathering concept is incorporated that electric utility employees will not be deprived of proper protection They propose that employers be required to provide employees with a level of protection equivalent to that which the standard would require in those instances in which the utility does not choose to modify existing facilities to comply with the final standard Rubber Sleeves OSHA requests comments from the industry on whether it would be advisable to require rubber insulating sleeves when gloves are used on lines or equipment energized at more than a given voltage EEI states its position that utilities should continue to have the option of choosing rubber gloves or gloves and sleeves to protect employees when it is necessary to work closer to energized lines than the distances specified in the clearance tables Preemuting State Laws EEI requests that the final Rules be clear in their preempting state rules applicable to the operation and maintenance work rules for electric power systems. This is especially critical since some states now have existing laws which are more stringent than the proposed OSHA Rules Examples are 1 in California and Pennsylvania where electric utility linemen are prohibited from using rubber gloves to work on lines and equipment energized at more than certain voltages and 2 in California and Connecticut where the live line bare hand method of working on high voltage transmission systems is prohibited One utility Pacific Gas  Electric has obtained a variance from the California OSHA to perform live line bare-hand transmission maintenance work on an experimental basis Coiiflicts Between the Rilles and Part 1926 Subpart V Since many of the work procedures in construction work and operation and maintenance work are similar and difficult to distinguish between EEI requests that the final order be clear in establishing which rule has jurisdiction over such similar work areas A2-19 v 


IMPACTS ON COSTS AND ASSOCIATED BENEFITS In its introduction to the proposed rules OSHA has provided an estimate of the annual cost impact on the electric utility industry for the proposed des of approximately 20.7 million OSHA estimates that compliance with this proposed standard would annually prevent between 24 and 28 fatalities and 2,175 injuries per year The utilities which have responded to this proposed standard through their respective associations have questioned the claims both of the magnitude of the cost involved and the benefit to the industry in preventing fatalities and lost-time injuries Both EEI and APPA feel that the annual cost which OSHA estimates are significantly lower than would be realized in practice Factors which APPA and EEI feel were not properly addressed include the following OSHA has not accurately accounted for cost of potential retroactive impacts including retrofitting and modifying existing installations and equipment OSHA has not consistently implemented performance based provisions in proposed rules  many portions require specific approaches which would require utilities to replace procedures already in place with new procedures Estimates were based on an average size investor-owned utility of 2,800 employees and an average rural cooperative of 56 employees, which are not applicable to many smaller systems such as municipal systems OSHA has not adequately addressed the retraining which would be necessary with modifying long-established industry practices to be in accordance with the OSHA rules EEI claims that OSHA's proposed clearance requirements would not allow the use of established maintenance techniques for maintaining high voltage transmission systems and thus would require new techniques For an example of the cost which is estimated to be experienced as a result of the new Rules one of the EEI member companies has estimated that approximately 20,000 transmission towers would need to be modified to accommodate the required step bolts in the Rules at an estimated cost of 6,200,000 Additionally this same company estimates that the annual cost of retesting live line tools for its estimated 1,000 tools would be 265,000 Additionally, both EEI and APPA question the additional benefits which OSHA claims would result from implementation of the new Rules APPA questions the estimates of preventing an additional 24 to 28 fatalities annually and 2,175 injuries per year in that it fails to account for the fact that the industry has already implemented in large part safety measures which are incorporated in the Rules EEI and APPA also point out that many preventable injuries cannot be eliminated despite work rules enforcement and safety awareness campaigns since many such accidents which result in fatalities are due to employee being trained but not following the employer's training and policies PRESENT STATUS OF RULES According to information received from the OSHA office in February 1993 the final Rules are to be published no later than July 1993 and possibly as soon as March 1993 OSHA closed their receipt of comments in March 1991 and no further changes in the rules are thought possible A2-20 


CONCLUSION The OSHA 1910.269 which proposes to cover electric utility operation and maintenance work rules affects a multitude of working procedures as are summarized in this paper It is not possible at the present time to assess the final structure of the Rules as may be proposed in 1993 or subsequent years Since the comments from the utility associations APPA and EEI were made following the initial release of the proposed OSHA Rules in 1989 a significant amount of time has elapsed where other events have occurred which may affect the form of the final Rules The 1993 NESC went into effect in August 1992 and includes some of the requirements to which the commenters objected For example a significant requirement in the Part 4 of the 1993 NESC requires that rubber gloves be utilized on exposed energized parts of facilities operating at 50 to 300 volts This requirement is in conflict with EEl\222s proposed change to the OSHA Rules which would still allow working such secondary facilities without the use of rubber gloves Electric utilities are advised to review the January 31 1989 proposed operation and maintenance Rules as summarized in this paper and to review their procedures which would be affected by application of the Rules Many of the procedures proposed in the Rules provide valuable guidance in electric utilities\222 operation and maintenance activities Where the cost impact is not significant, it is recommended that utilities consider implementing such procedures in expectation of the Rules being published in the next few months Also it would be appropriate for electric utilities to review the 1993 edition of the NESC since there are portions of the Rules which have resulted in changes in the NESC These changes mainly occur in Part 4 Rules for the Operation of Electric Supply and Communications Lines and Equipment The concerns which the commenters have addressed regarding the cost impact and the resulting benefits experienced as a result of the promulgation of the Rules are real ones and must be addressed in the final Rules As a result this paper cannot present a conclusion regarding the full impact of the Rules The development of such Rules continue to be an ongoing matter and will undoubtedly require later analysis when the final rules are published A2-21 



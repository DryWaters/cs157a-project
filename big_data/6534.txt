Big Data Analysis System Concept for Detecting Unknown Attacks  Sung-Hwan Ahn*, Nam-Uk Kim*, Tai-Myoung Chung Department of Electrical and Computer Engineering, Sungkyunkwan University College of Information and Communication Engineering, Sungkyunkwan University shahn@imtl.skku.ac.kr, nukim@imtl.s kku.ac.kr, tmchung@ece.skku.edu  Abstract Recently, threat of previously unknown cyber-attacks are increasing because existing security systems are not able to detect them. Past cyber-attacks had simple purposes of leaking personal information by attack ing the PC or destroying the system. However, the goal of recent hacking attacks has changed from leaking information and destruction of services to attacking large-scale systems such as critical infrastructures and state agencies. In the other words, existing defence technologies to counter these attacks are based on pattern matching methods which are very limited. Because of this fact, in the event of new and previously unknown attacks, detection rate becomes very low and false negative increases. To defend against these unknown attacks, which cannot be detected with existing technology, we propose a new mode l based on big data analysis techniques that can extract information from a variety of sources to detect future attacks. We exp ect our model to be the basis of the future Advanced Persistent Threat\(APT\etection and prevention system implementations  Keywords  Computer crime, Alarm systems, Intrusion detection, Data mining  I  I NTRODUCTION  According to the Gartner report, sophisticated hacking attacks are continuou sly increasing in the cyber sp Hacking in the past leaked personal information or were done for just fame, but recent hacking targets companies government agencies. This kind of attack is commonly called APT\(Advanced Persistent Threat\APT targets a specific system and analyses vulnerabilities of the system for a long time. Therefore it is hard to prevent and detect APT than traditional attacks and could result massive dama   Up to today, detection and protection systems for defending against cyber-attacks were fi rewalls, intrusion detection systems, intrusion prevention sy stems, anti-viruses solutions database encryption, DRM solutions and etc. Moreover integrated monitoring technologies for managing system logs were used. These security solutions are developed based on signatures and blacklist. However, according to various reports, intrusion detection systems and intrusion prevention systems are not capable of protecting systems against APT attacks because there are no signa tures. Therefor e to overcome this issue, security communities are beginning to apply heuristic and data mining technologies to detect previously unknown attacks In this paper, we propose a new model based on big data analysis technology to prevent and detect previously unknown APT attacks. We compared pr evious researches which are based on data mining technology for predicting or analysing correlation between attack behaviours and explained its limits Furthermore we list various sources and their details that can be collected and explain attack predictions earned from applying big data technologies such as classification, text mining, clustering, and association rules. Finally, we propose new attack reaction model based on big data technologies and evaluate the model. We expect this research to be the basis for future implementation of APT attack detection and prevention systems based on big data analysis technologies II  R ELATED W ORK  In the current cyber-space sophisticated and intelligent threats are increasing. These previously unknown attacks cannot be detect or mitigated using existing pattern matching methods such as signature, rule, and black list based solutions For this reason, the anti-virus industry and research groups are combining technologies such as heuristic detection techniques and data mining techniques to detect attacks that are not detected with existin g pattern-matching techniques In this chapter, we explain the definition and characteristics of an APT attack and existing security solutions as well as big data analysis which is arising as a future solution for detecting unknown attacks A  APT Attacks APT attack is a special kind of attack that use social engineering, zero day vulnerabilities and other techniques to penetrate into the target system and persistently collect valuable information. It can give massive damage to national agencies or ent Recent APT attacks tend to target core industrial control systems instead of ordinary desktops or servers. Moreover APT attacks are used as cyber weapons between nations Cyber security is becoming a core aspect of national safety Attacking industrial systems and causing malfunctioning of theses infrastructures can cause public chaos to the nation Examples of recent APT attack s are Stuxnet, RSA Secure ID hacking and the Night Dragon. Stuxnet was a very intelligent malware that was developed to attack Iran’s nuclear facilities and make them malfunctio n. It is known to be acting ISBN 978-89-968650-3-2 269 February 16~19, 2014 ICACT2014 


in the wild for a few years until it was discovered by security researchers APT attack is usually done in four steps: intrusion searching, collection and attack. Figure 1 describes the attack process in detail   Figure 1  The sequence of APT attacks  In the intrusion step of an AP T attack, the hacker probes for information about the target sy stem and prepares the attack To get the access to the system, the attacker searches for users with high access privileges such as administrators and use various attack techniques such as SQL injection, phishing farming and social engineerin g to hijack their accounts Searching is done after the hacker gained access to the system. Hacker analyses system data such as system log for valuable information and look for security vulnerabilities than can be exploited for further malicious behaviours In the next step, after the hacker has located valuable information in the system such as confidential documents etc then, he installs malwares such as rootkits, backdoors to collect system data and maintain system access for the future In the final step, the hacker leaks data and destroys target system using acquired privileges. Leaked information can be used for developing other additional security vulnerability exploits. Because APT exploits use zero-day vulnerabilities and obfuscation methods, Anti-Virus program, IDS and IPS are difficult to detect such exploits B  Existing Information S ecurity Technologies Security researchers developed various security technologies to protect the sy stem from evolving attacks Typical solutions are firewall, IDS/IPS, WAF\(Web Application Firewall\\(Enterprise Security Management  1\  Firewall Firewall is a regulation device that controls the network traffic between separated networks and hosts. It is security technology based on access control. It decides whether to allow an access to th e internal IP addresses and port numbers. Administrator sets up this access control rules in adva Initial firewall is located at border of the network and can be used as a protector for the inner network. Also, firewall is used as a primary security solu tion to this day. Firewall has a simple rule system that allows administrators to control firewall easily. However, firewall cannot detect and analyse threats in the networ k but just blocks accesses according to IP addresses and port numbers defined by administrators Therefore a firewall only provides minimum protection from attacks  2\  IDS IDS is a report system that searches and reports threats according to defined rules and captured traffic. IDS observes and analyses network traffic and detects malicious traffic and unprivileged file access. IDS can be divided into NIDS\(Network-based Intrus ion Detection System HIDS\(Host-based Intrusion Detection System\DS can observe and analyse traffic in a mo re higher level than firewall using sniffing technology[4 HIDS can observe system states such as file modification file access, process in the host In contrast to NIDS, HIDS is installed on each host. It de tects abused resources and unprivileged access and reports to administrator IDS detect and alerts abnormal actions by pre-defined rule These rules are based on normal users’ behaviours and statistic information from system logs  3\  WAF A website is good hacking target due to publicly opened services. Web servers use a fixed port number on each service. Therefore, a security administrator cannot just block these port numbers to stop malicious access because it needs to provide service to legitimate connections. Furthermore, it is difficult for IDS to analyse encapsulated application data in the packet. Therefore, existi ng security solutions cannot effectively detect threats in application level in the network stack WAF detects and blocks attacks using both positive and negative access control. Positive access control is a technology that blocks everything except defined safe patterns and negative access control blocks only predefined malicious patterns  Security technologies such as firewall, IDS, WAF basically use pattern matching techniques that are based on pre-defined rules. Therefore, they may not detect or prevent attacks that are encrypted or obfuscated. Also, they have some problems regarding low-performance and false-positives by duplicated rules  C  Big Data Analysis Big d a ta has been a great issue in the IT industry for the last couple of years. It defines h uge, shortly created and atypical data in digital environment such as text, music, video, and so on. Big data analysis is a technology that searches useful information such as a relation rule, a hidden value from huge data[6  Big data analysis uses various existing analysis techniques such as machine-learning, artificial-intelligence, data-mining and etc. Among various techniques, we focus on four techniques – prediction, classi fication, relation rule, atypical ISBN 978-89-968650-3-2 270 February 16~19, 2014 ICACT2014 


data-mining. We think that these techniques are useful to detect unknown new attacks First, prediction is a technique that predicts the future possibility and trend. Regression analysis is a representative prediction technique. Researchers can predict attack possibilities using regressing anal ysis. Regressing analysis can predict similar behaviours from collected attack logs Second, classification is a technique that predicts the group of new attack from huge data. Classification helps security administrator to decide direction of protection and analysis Most used classification techniques are logistic regression analysis and SVM\(Support Vector Machine Third, relation rule is a technique that discovers hidden relations among data. The action of discovering relation rule is named association analysis or link analysis. The relation from time flow is named as sequence rule. This analysis technique can determine abnormal behaviour by analysing user or process behaviours Lastly, atypical data-mining an alyses data that cannot be expressed in numbers such as picture, video, audio, text and etc. Typical atypical data-minin g techniques are text-mining web-mining and social-mining  III   000i 000p\000n\000G 000k 000h\000{\000h\000G 000h 000u\000h\000s\000€\000z\000p\000z\000G 000z 000€\000z\000{\000l\000t\000G 000t 000v\000k\000l\000s  Previously unknown attacks such as APT are evolving to bypass existing security measures. These attacks are impossible to detect or prevent with current technologies which are explained in the Chapter 2. Therefore security incidents constantly occurs using state-of-the-art attack technologies. New security paradi gm to react to these attacks is in need. The new paradigm requires big data analysis techniques as a core and integration of defence technologies central security management, incident prediction technologies We propose a system model that uses big data analysis technology for extracting data from various sources to react to previously unknown attacks  000G Figure 2  Big Data Analysis System Architecture  As seen in figure 2, entire system is divided into 4 steps  000x  Data Collection: Data collection step collects event data from firewalls and log, behaviour, status information date, time, inbound/outbound packet, daemon log, user behaviour, process information etc.\ from anti-virus database, network device and system. Collected data is saved in big data appliance  000x  Data Processing: This step validates whether collected data satisfies certain requirements. Then key value pair is created and classified using No-SQL, Hadoop Mapreduce and etc. It is known that approximately 80 precent of time required for collecting and processing data using data mining is needed. For faster processing we introduce cloud or distributed system  000x  Data Analysis: Pre-processed data from previous step is analysed using prediction classification, association analysis, and unstructured data analysis to decide user behaviour, system status, packet integrity and misuse of file or system. Used mining technologies are explained in chapter 2  000x  Result: If attack or abnormal behaviours are detected, it alarms the administrator an d terminates. Moreover, we provide dashboard, management tools to monitor results in real time. Prediction information of analysed system is summarized and reported to the manager. Also configuration update, rule manipulation and deletion analysis pattern updates are done both automatically and passively  000G Figure 3  Phases of the CRISP-DM Process Model  Standard process for data mining techniques which are used for big data analysis was proposed by Chapman et al. in 2000[7 is is called CRISP-DM Process Model Proposed standard process is composed of business understanding, data understanding, data preparation ISBN 978-89-968650-3-2 271 February 16~19, 2014 ICACT2014 


modelling, evaluation, deployment. We analyse and give feedbacks according to this standard process We can predict ‘nowcast’ rather than forecast which a near future using big data analysis model we proposed. We expect to extract relation between behaviours and normal/abnormal patterns using big data analysis of logs  TABLE 1  B IG DATA ANALYSIS BASED APPLICATIONS  Applications Description Real-Time Monitoring From a variety of sources, data collection, management, and the state of the system in real time And, the attack by the application to track and predict or monitor users' behaviour Threat Intelligence Anomaly detection of threats and attack patterns to be able to date information on management Behaviour Profiling Observe the behaviour of the system and the user Tracking and  investigating  for suspicious packets or behaviours Data & User Monitoring Continuous monitoring for the protection of users and sensitive data Prevent misuse of data and computing resources Application Monitoring Continuous monitoring for the behaviours of applications and system processes Process behaviours can be an important factor in detecting malicious behaviour Analytics Linkage analysis for a variety of monitoring information Infers the possibili ty of an attack  However for applying multi-source data monitoring analysis technologies in the secu rity area, it requires real-time monitoring, context sensitive behaviour detection, and automatic analysis technologies In this paper we are not proposing effective parallel processing algorithm for real ti me analysis. Instead of using pattern matching or log analysis for predicting cyber-attacks we believe that we can extract valuable information previously unfound from data and status information collected from various sources by big data analysis Moreover, to apply and validate various analysis methodologies using big data, we need professional software and distributed system. In future works, we plan to research on how to implement proposed system and get results using real factors and analysis methodologies    IV   C ONCLUSIONS  Recent unknown attack s easily bypass existing se curity solutions by using encryption and obfuscation. Therefore new detection methods for reacting to such attacks are in need In this paper we proposed big data system model for reacting to previously unknown cyber threats and researched on the deduction of practical t echnologies. In future works following researches must be done  000x  Classification of data by context of intrusion detection 000x  Implementation of data relation analysis methodology and its abnormal behaviour detection strategy 000x  Quantitive and qualitive assessment of proposed model and performance evaluation  R EFERENCES    J. Feiman, “Hype Cycle for App lication Security, 2012”, Gartner Group, July, 2012   Advanced Persistent Threat: A De cade in Review”, Command Five Pty Ltd, June, 2011   K. Ingham and S. Forrest, “A Histor y and Survey Network Firewalls University of New Mexico, Tech. Rep., 2002   R. D. Pietro and L. V. Mancini, Intrusion detection systems, in: S Jajodia \(Series editor\, Handbook of A dvances in Information Security Springer, 2008   The OWASP\(Open Web Application Security Project\Web Application Firewall, Available: http://www.owasp.org   R. Magoulas and B. Lorica, “Intr oduction to Big Data”, Release 2.0 Sebastopol O’Reilly Media\, Feb, 2009   P. Chapman. et al, “CRISP-DM 1.0 – Step-by-step data mining guide http://www.crisp-dm.org \(2000 ISBN 978-89-968650-3-2 272 February 16~19, 2014 ICACT2014 


      


        


       


                       


9  4  3 2 8   7   3   A B C D @ A B E F G H D I F G H D I   A B C D  J K L M N M K O P Q M P R M M P P O M R K O J K Q M M M M O Q R K M O P K 


O S K S K O S M O L L R K O O Q O N S L R P O P R M S S N S K Q L O L Q Figure 2: True positive impacts for association rules Granger, and the combination of both 75 82%, then remains almost constant. Finally, the precision for the combination of the two techniques starts very high 100%, with, however, few links retrieved to ? 75%, and ?nally rises again to ? 82%. Overall, the combination of both techniques seems to exhibit the best precision/recall compromise, i.e., to start with a very high precision, but then to keep it as high as association rules The complementarity of the two techniques is even more evident when looking at Figure 2, which shows, for di?erent values of top-n, the number of true impacts found by Granger causality \(and not found by association rules association rules \(and not by Granger causality found by both techniques at the same time. This ?gure shows that the intersection between the two techniques is always lower \(from 7 vs 37 and 31 for top-100, up to 25 vs 50 and 56 for top-200 one technique only Finally, Figure 3 shows an excerpt of an impact graph highlighting impact relations identi?ed by association rules plain lines dotted lines bold lines related to Samba authentication \(auth_*.c responsible of handling errors providing requests 


to any connection to the Samba server dling user ids. As it can be noticed, auth_* ?les are strongly coupled, and exhibit dependencies highlighted by both techniques. Changes performed to auth_* ?les immediately impact on reply.c and on uid.c, as shown by relations identi?ed by association rules. Instead, the graph shows that changes are propagated only after a while to error.c: in fact the change impact relation is identi?ed by Granger causality only. For instance, on Aug 8, 2001 both auth_* ?les and reply.c \(revision 1.316 note \(smbd/auth server: Doco we want to use cli nt error here soon smbd/password.c management needs to be updated soon. This happened on Aug 27, 2001 \(commit note: . . . added automatic mapping between dos and nt error codes went a change \(to revision 1.6 The performed study su?ers of some threats to validity In particular, threats to internal validity, as this kind of impact analysis \(Granger test and its combination with as165 Figure 3: Excerpt of impact graph sociation rules signi?cant correlation between a change occurring to a ?le and future changes occurring to other ?les. Our approach is purely statistical, hence there is no guarantee to ensure source code change causality. Also, the study can su?er of threats to external validity, as this is only one, small preliminary study. Further, larger studies are desirable to better assess the performances and the scalability of the proposed approach 4. EMERGING RESEARCH DIRECTIONS Driven by bioinformatics, where the Granger causality test is largely used to derive causal relationships among different elements, such as genes and proteins, we have developed a novel change impact analysis method that uses the Granger causality test to learn impact relationships among software artifacts. The main idea of the method is to infer the mutual dependencies between software artifacts by measuring the statistical con?dence that the time series representing the history of changes of a software artifact can be used to predict the changes of another artifact. The problem is therefore posed as a statistical test, evaluating the quality 


of forecasting of a variable given another one In this paper the method has been compared with the application of association rules [9, 10], and the preliminary results suggest that the Granger causality test can be a viable approach to change impact analysis, as it complements existing approaches. As a matter of fact, while association rules capture co-changes, Granger causality helps learning consequent changes. While not shown in this paper for the sake of space, we have compared the results of the proposed impact analysis method against traditional methods based on static analysis, and also in this case we found that they are able to highlight complementary, yet useful, impact relationships. This opens the way towards an eclectic impact analysis approach that combines existing methods, to overcome the limitation of the individual methods, and provides software engineers with a richer set of information useful to assess the impact of a change There are several directions in which the work presented here can be expanded. Of course, a ?rst direction is the development of further empirical studies to fully understand advantages and limitation of the proposed method, to compare it with other \(traditional and to develop heuristics for improvement The application of Granger causality depends entirely on the appropriate selection of variables. In this paper we have used an impulsive \(0,1 in a snapshot. However, other variables should be explored for example the variation of some metric values. Furthermore, the method could be applied for object-oriented system, considering classes and methods instead of functions We are interested to compare the Granger causality approach against the dynamic Bayesian network inference, which is a well-known approach used to derive causal relationships. Finally, we are investigating the use of information theoretic approaches based on mutual information 5. REFERENCES 1] R. Agrawal, T. Imielinski, and A. N. Swami. Mining association rules between sets of items in large databases. In Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data Washington, D.C., May 26-28, 1993, pages 207216 ACM Press, 1993 


2] R. S. Arnold and S. A. Bohner. Impact analysis towards a framework for comparison. In Proceedings of the Conference on Software Maintenance, ICSM 1993 Montreal, Quebec, Canada, September 1993, pages 292301, 1993 3] G. Canfora and L. Cerulo. Impact analysis by mining software and change request repositories. In 11th IEEE International Symposium on Software Metrics METRICS 2005 page 29. IEEE Computer Society, 2005 4] C. W. J. Granger. Investigating causal relations by econometric models and cross-spectral methods Econometrica, 37\(3 5] J. D. Hamilton. Time Series Analysis. Princeton University Press, January 1994 6] A. Hindle, M. W. Godfrey, and R. C. Holt. Mining recurrent activities: Fourier analysis of change events In 31st International Conference on Software Engineering, ICSE 2009, May 16-24, 2009, Vancouver Canada, Companion Volume, pages 295298, 2009 7] J. Law and G. Rothermel. Whole program path-based dynamic impact analysis. In Proceedings of the 25th International Conference on Software Engineering May 3-10, 2003, Portland, Oregon, USA, pages 308318. IEEE Computer Society, 2003 8] N. D. Mukhopadhyay and S. Chatterjee. Causality and pathway search in microarray time series experiment. Bioinformatics, 23\(4 9] A. T. T. Ying, J. L. Wright, and S. Abrams. Source code that talks: an exploration of Eclipse task comments and their implication to repository mining In Proceedings of the 2005 International Workshop on Mining Software Repositories, MSR 2005, Saint Louis Missouri, USA, May 17, 2005. ACM, 2005 10] T. Zimmermann, P. Weisgerber, S. Diehl, and A. Zeller. Mining version histories to guide software changes. In ICSE 04: Proceedings of the 26th International Conference on Software Engineering pages 563572, 2004 166 


General Chair f!!\f  Organizing Chairs  f!!\f  f$% \f!!\f  Organizing Co-chairs f    f  f\f   f\f\f   f*!\f!\f.\f  f f  Program Committee Chairs  f\f\f   f!!\f  Publication Chair 0   


200 250 300  The size of dataset/10,000 R es po ns e tim e S    a 0 50 100 150 200  The size of dataset/10,000 R es po ns e tim e S    b 0 10 20 30 40 50 


60  The size of dataset/30,000 R es po ns e tim e S    c Fig. 9 The scalability of our algorithm compared with FP-growth  Paper [12] proposed a way to reduce times of scanning transaction database to reduce the cost of I/O IV. CONCLUSIONS AND FUTURE WORK This paper first discusses the theory of foundations and association rules and presents an association rules mining algorithm, namely, FP-growth algorithm. And then we propose an improved algorithm IFP-growth based on many association rules mining algorithms. At last we implement the algorithm we propose and compare it with algorithm FPgrowth algorithm. The experimental evaluation demonstrates its scalability is much better than algorithm FP-growth 177 Now, lets forecast something we want to do someday Firstly, we would parallelize our algorithm, because data mining needs massive computation, and a parallelable environment could high improve the performance of the algorithm; Secondly, we would apply our algorithm on much more datasets and study the run performance; At last, we would study the performance when the algorithm deal with other kinds of association rules  REFERENCES 1] S. Sumathi and S. N. Sivanandam. Introduction to Data Mining and its Applications, Springer, 2006 2] V. J. Hodge, J. Austin, A survey of outlier detection 


methodologies, Artificial Intelligence Review, 2004, 22 85-126 3] Han, J. and M. Kamber. Data Mining: Concepts and Techniques. Morgan Kaufmann, San. Francisco, 2000 4] Jianchao Han, Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases, Journal of Advanced Computational Intelligence and Intelligent Informatics 2006, 10\(3 5] Jiuyong Li, Hong Shen, Rodney Topor. Mining Informative Rule Set for Prediction. Journal of Intelligent Information Systems, 2004, 22\(2 6] Jianchao Han, and Mohsen Beheshti. Discovering Both Positive and Negative Fuzzy Association Rules in Large Transaction Databases. Journal of Advanced Computational Intelligence, 2006, 10\(3 7] Doug Burdick, Manuel Calimlim, Jason Flannick Johannes Gehrke, Tomi Yiu. MAFIA: A Maximal Frequent Itemset Algorithm. IEEE Transactions on Knowledge and Data Engineering, 2005, 17\(11 1504 8] Assaf Schuster, Ran Wolff, Dan Trock. A highperformance distributed algorithm for mining association rules. Knowledge and Information Systems, 2005, 7\(4 458-475 9] Mohammed J. Zaki. Mining Non-Redundant Association Rules. 2004, 9\(3 10] J.Han, J.Pei, Y.Yin, Mining frequent patterns without candidate generation, Proceedings ACM SIGMOD 2000 Dallas, TX, May 2000: 1-12 11] P.Viola, M.Jones. Rapid Object Detection Using A Boosted Cascade of Simple Features. Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 2001 12] Anthony K. H. Tung, Hongjun Lu, Jiawei Han, Ling FengJan. Efficient Mining of Intertransaction Association Rules. 2003, 154\(1 178 


For each vertex b in g form j forests body\(a, g, i s.t. bodyAnt\(a, g, i a, g, i with itemsets Ant\(b b and each subset of itemsets Ant\(b b in P\(a, g, j Assign to each leaf l of trees bodyAnt\(a, g, i bodyCons\(a, g, i a fresh variable Vm,M, m, M = size\(itemset\(l Assign to each leaf l of tree headAnt\(a, g, j the variable assigned to itemset l in some leaf of some tree bodyCons\(a, g, i TABLE II.  EXPERIMENTAL DATA Conf. #rules #pruned #dftrs PtC 0.5 6604 2985 1114 0.6 2697 2081 25 0.75 1867 1606 10 0.8 1266 1176 0 0.95 892 866 1 0.98 705 699 1 DSP 0.5 2473 1168 268 0.6 1696 869 64 0.75 1509 844 89 0.8 1290 1030 29 0.95 1032 889 15 0.98 759 723 1 Arry 0.5 770 492 82 0.6 520 353 60 0.75 472 327 39 0.8 408 287 22 0.95 361 255 25 0.98 314 243 30  Our induction algorithm has been launched for each combination of thresholds. Our scheme eliminates all redundant rules in the sense of [25, 31], i.e. those association rules that are not in the covers. All the meta-rule deductive schemes implicitly included in [25] and [31] are induced by our method. The percentage of pruning, thus, outperforms [25 


The results produced for k=3, support 0.25 and confidences between 0.7 and 0.99 are shown in Fig. 3, in terms of pruning percentage \(vertical axis when applied to low confidences \(from 0.7 to 0.9 The percentage of pruning achieved diminishes as the confidence is superior to 0.9. Nevertheless, the pruning is effective with confidence of 0.99 in the majority of cases Pruning at Support = 0.25 0,00 5,00 10,00 15,00 20,00 25,00 30,00 35,00 40,00 45,00 50,00 0,7 0,8 0,9 0,95 0,99 Confidence P ru n in g L e v e l Case 1 Case 2 Case 3  Figure 3.  Pruning experiences at support 0.25  V. DISCUSSION AND CHALLENGES It is important to discuss the technique presented here with focus on the purpose the technique pursues:  to produce semantic recommendation The reader should have noticed that the algorithm presented 


relies strongly on "choice". For instance, the algorithm chooses ears in the graph to form an order for elimination, and the choice is arbitrary. This strategy is essential to maintain low complexity \(polynomial practical. Nevertheless, a warned reader may conclude that this arbitrary choice implies that there are many compactions to produce and therefore the approach as a whole does not show to produce an optimal solution. And the reader is right in this conclusion. Since the goal is compaction, the search for an optimal solution can be bypassed provided a substantial level of pruning is achieved To complete the whole view, we describe how web service descriptions are complemented with the association rules as recommendations. In effect, under our scheme, the document describing the web service is augmented with a set of OWL/RDF/S triples that only incorporate the non-pruned rules with the format of Example 1, that is, the set ARmin of the compaction program obtained by our algorithm, together with the thresholds applied to the mining process and a registered URI of a registered description service. The assumptions and defeaters are not added to the web service description. If the associations encoded in the triples are not sufficient for the client \(a search engine, for instance widening of the response to the description service identified by the given URI, and then the assumptions and defeaters are produced. The reasoning task required for deriving all the implicitly published rules is client responsibility Notice that, under this scheme, the actual rules that appear as members of the set initial ARmin set are irrelevant; the only important issue is the size of the set The developed scheme also supports an extension of the algorithm that admits the assignment of priorities to rules and to itemsets, in order to allow the user to produce a more controlled program as output. Nonetheless, the importance of the extension has not been already tested, and therefore it is beyond the subject of the present paper It would be also interesting to design a scheme that supports queries where the client provides an itemset class and values for support and confidence and the engine produces a maximal class of inferred associated itemsets as a response. This scheme is also under development, so we have not discussed this aspect here 


VI. CONCLUSION In this paper, we have presented a defeasible logic framework for managing associations that helps in reducing the number of rules found in a set of discovered associations. We have presented an induction algorithm for inducing programs in our logic, made of assumption schemas, a reduced set of association rules and a set of counter-arguments to conclusions called defeaters, guaranteeing that every pruned rule can be effectively inferred from the output. Our approach outperform those of [17], because all reduction compactions presented there can be expressed and induced in our framework, and several other patterns, particular to the given datasets, can also be found. In addition, since a set of definite clauses can be obtained from the induced programs, the knowledge obtained can be modularly inserted in a richer inference engine Abduction can be also attempted, asking for justifications that explain the presence of certain association in the dataset The framework presented can be extended in several ways Admitting defeaters to appear in the head of assumption, to define user interest Admitting arithmetic expressions within assumptions for adjustment in pruning Admitting set formation patterns as itemset constants Extending the scope, to cover temporal association rules REFERENCES 1]  R. Agrawal, and R. Srikant: Fast algorithms for mining association rules In Proc. Intl Conf. Very Large Databases. \(1994 2]  A. V. Aho, J. E. Hopcroft, J. Ullman. The design and analysis of computer algorithms, Addison-Wesley, 1974 3]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher, A. Rock: A Family of Defeasible Reasoning Logics and its Implementation. ECAI 2000: 459-463 4]  G. Antoniou, D. Billington, G. Governatori, M. J. Maher: Representation results for defeasible logic. ACM Trans. Comput. Log. 2\(2 2001 5]  A. Basel, A. Mahafzah, M. Al-Badarneh: A new sampling technique for association rule mining, Journal of Information Science, Vol. 35, No. 3 358-376 \(2009 6]  R. Bayardo and R. Agrawal: Mining the Most Interesting Rules. In Proc of the Fifth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 145-154, \(1999 


7]  R. Bayardo, R. Agrawal, and D. Gunopulos: Constraint-based Rule Mining in Large, Dense Databases. Data Mining and Knowledge Discovery Journal, Vol. 4, Num-bers 2/3, 217-240. \(2000 8]  A. Berrado, G. Runger: Using metarules to organize and group discovered association rules. Data Mining and Knowledge Discovery Vol 14, Issue 3. \(2007 9]  S. Brin, R. Motwani, J. Ullman, and S. Tsur: Dynamic itemset counting and implication rules for market basket analysis. In Proc. ACMSIGMOD Intl Conf. Management of Data. \(1997 10] L. Cristofor and D.Simovici: Generating an nformative Cover for Association Rules. In ICDM 2002, Maebashi City, Japan. \(2002 11] Y. Fu and J. Han: Meta-rule Guided Mining of association rules in relational databases. In Proc. Intl Workshop on Knowledge Discovery and Deductive and Object-Oriented Databases. \(1995 12] B. Goethals, E. Hoekx, J. Van den Bussche: Mining tree queries in a graph. KDD: 61-69. \(2005 13] G. Governatori, D. H. Pham, S. Raboczi, A. Newman and S. Takur: On Extending RuleML for Modal Defeasible Logic. RuleML, LNCS 5321 89-103. \(2008  14] G. Governatori and A. Stranieri. Towards the application of association rules for defeasible rules discovery In Legal Knowledge and Information Systems, JURIX, IOS Press, 63-75. \(2001 15] J. Han, J. Pei and Y. Yin: Mining frequent patterns without candidate generation. In Proc. ACM-SIGMOD Intl Conf. Management of Data 2000 16] C. Hbert, B. Crmilleux: Optimized Rule Mining Through a Unified Framework for Interestingness Measures. DaWaK: LNCS 4081, 238247. \(2006 17] E. Hoekx, J. Van den Bussche: Mining for Tree-Query Associations in a Graph. ICDM 2006: 254-264 18] R. Huebner: Diversity-Based Interestingness Measures For Association Rule Mining. Proceedings of ASBBS Volume 16 Number 1, \(2009 19] B. Johnston, Guido Governatori: An algorithm for the induction of defeasible logic theories from databases. Proceedings of the 14th Australasian Database Conference, 75-83. \(2003 20] P. Kazienko: Mining Indirect Association Rules For Web Recommendation. Int. J. Appl. Math. Comput. Sci., Vol. 19, No. 1, 165 186. \(2009 21] M. Klemettinen, H. Mannila, P. Ronkainen, H. Toivonen, and A Verkamo: Finding interesting rules from large sets of discovered association rules. In Proc. 3rd Intl Conf. on Information and Knowledge 


Management. \(1994 22] M. J. Maher, A. Rock, G. Antoniou, D. Billington, T. Miller: Efficient Defeasible Reasoning Systems. International Journal on Artificial Intelligence Tools 10\(4 2001 23] C. Marinica, F. Guillet, and H. Briand: Post-Processing of Discovered Association Rules Using Ontologies. The Second International Workshop on Domain Driven Data Mining, Pisa, Italy \(2008 24] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal: Closed sets based discovery of small covers for association rules. In Proc. BDA'99 Conference, 361-381 \(1999 25] N. Pasquier, R. Taouil, I. Bastide, G. Stume, and  L. Lakhal: Generating a Condensed Representation for Association Rules. In Journal of Intelligent Information Systems, 24:1, 29-60 \(2005 26] P. Pothipruk, G. Governatori: ALE Defeasible Description Logic Australian Conference on Artificial Intelligence.  110-119 \(2006 27] J. Sandvig, B. Mobasher Robustness of collaborative recommendation based on association rule mining, Proceedings of the ACM Conference on Recommender Systems \(2007 28] W. Shen, K. Ong, B. Mitbander, and C. Zaniolo: Metaqueries for data mining. In Fayaad, U. et al. Eds. Advances in Knowledge Discovery and Data Mining. \(1996 29] I. Song, G. Governatori: Nested Rules in Defeasible Logic. RuleML LNCS 3791, 204-208 \(2005 30] H. Toivonen, M. Klemettinen, P. Ronkainer, K. Hatonen, and H Mannila: Pruning and grouping discovered association rules. In ECML Workshop on Statistics, Machine Learning and KDD. \(1995 31] M. Zaki: Generating Non-Redundant Association Rules. In Proc. of the Sixth ACMSIGKDD Intl Conf. on Knowledge Discovery and Data Mining, 34-43, \(2000 32] w3c. OWL Ontology Web Language Reference. In http://www.w3.org/TR/2004/REC-owl-ref-20040210 33] w3c. RDF/XML Syntax Specification. In: http://www.w3.org/TR/rdfsyntax-grammar 34] w3c. RDF Schema. In: http://www.w3.org/TR/rdf-schema      


 8   2  3\f            8  D    F  \b 1 8 & #J      b 1  1  4    2  


4 1    9  E 1  2 4 1    9 1   4      8 2  8 1  D 1        1 1  b 


     b b b b b  K            8          2 D 9   F  \b 1 8 ,+J  9 


     b 1     1 2  9 1  12 L 1   9  8       1  2      2   


     b b b b b  K            2  0 \b f  b\f      9       


  8 2   E 1   1     M13 31L 1    b  8E 1   1 #3\b?### 1  1     E 1   1 \b?###3        


1   1   b 1  2 2 18 2     8              1    2 \b 1    2  


    2          2   1 L 2 1   1   L 2 2    2 1  2        


    8  2H D \b A             2  2H D \b A 2 \f 3%\f  f   4%\f f !  , \f\b  C    2    2 


 6    3 1      253 6   1 L 2    6   1         f\b3\f       


               1     1     8 2    E       2  1   


     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



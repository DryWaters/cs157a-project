A Theoretical Framework for Assessing Eavesdro pping-Resistant Authentication Interfaces Bogdan Hoanca University of Alaska Anchorage Computer Information Systems Anchorage AK 99508 Email afbh@uaa.alaska.edu   Kenrick Mock University of Alaska Anchorage Computer Science Anchorage AK 99508 Email afkjm@uaa.alaska.edu    Abstract A simple theoretical framework is developed to evaluate the security and usability of eavesdroppingresistant authentication schemes. Such schemes strive to allow users to authenticate without disclosing the 
user s credentials to an eavesdropper, while using only standard computer hardware \(monitor keyboard and mouse\. We find that schemes based on shared secrets and standard computer hardware are unable to deliver real security advantages.  For all the schemes reported to date, an attacker can collect all the needed information within ten observations of successful authentications. Shared secret schemes can provide security only if the space of possible shared secrets is extensive enough to prevent an exhaustive search. In turn, this complexity of the shared secrets space is already limited by usability considerations, and cannot be increased further Thus, for truly user-friendly interfaces resistant to eavesdropping attacks, shared secrets must be combined with other authentication factors 
biometrics or special hardware  1. Introduction  Most computer authentication interfaces are based on a shared secret: a password that authenticates a given user name. This scheme is inexpensive and widely available because it relies on standard computer hardware: a monitor, a keyboard and a mouse. Despite its advantages, the scheme is also highly vulnerable to eavesdropping attacks The vulnerability of the traditional authentication interface arises because the user enters her password in cleartext at the interface. As the User, Ursula enters her username and password to authenticate to Victor, the Verifier, an Attacker, Anne, might be i watching over Ursula 
s shoulder, ii\ using a hardware key logger to monitor her key strokes, iii\sing a screen capture program to capture mouse clicks or iv capturing Ursula s credentials on a phishing web site APWG, 2008\uch attacks are known as peeping attacks, shoulder surfing attacks or eavesdropping attacks \(Hoanca & Mock, 2007\ce Anne has captured Ursula s user name and password, she has all the information identifying Ursula as herself Aside from capturing user authentication, an attacker can also mount man-in-the-middle attacks by hijacking a user session, without a need to uncover the user authentication information. Such attacks are 
more difficult to mount than simple eavesdropping but they are notoriously difficult to prevent. The theory in this paper is relevant only in the context of eavesdropping attacks that do not hijack a session but only capture user identifying information Given the ease of mounting eavesdropping attacks and the inherent vulnerability of the password scheme, the number of phishing attacks has been rising steadily. This in turn has led several researchers to propose authentication interfaces that use the same basic hardware, yet are better equipped to prevent Anne from carrying out such an attack 
Ideally, such an interface would allow Ursula to authenticate to Victor via a relatively short and cognitively simple process, but would prevent Anne from collecting sufficient information to impersonate Ursula, even after Anne has captured all the user input across several authentication sessions, and even after Anne uses ample computing power over lengthy periods of time processing the user input collected There are two ways in which the User s secret credentials can be protected. One way is to disclose to the Attacker only a portion \(ideally zero\ the shared secret, but never the entire information \(such 
schemes are known as zero-knowledge protocols The second approach is to make it time consuming to compute the shared secret, even if the Attacker has all the information needed \(such an approach relies on large NP-complete problems to construct one-way functions\All the proposed schemes purport to hide the shared secret, but they do not make it clear whether they i\ide part or all of the shared secret, ii make the shared secret difficult to find or iii In this paper we show that within a small number of observations all schemes disclose sufficient information for an Attacker to find the shared secret A prepared Attacker can gather as much information 
as the Verifier in any given session. As such, the ability of the User to preserve some shared secret with the Verifier is limited by the complexity of the shared secret and not by the complexity of the information exchanged in any given session. The analysis we present here is applicable to any type of authentication interface, using alphanumeric symbols, graphical interfaces or even complex interfaces involving sounds or video Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 1 978-0-7695-3450-3/09 $25.00 © 2009 IEEE 


We focus in this paper on systems that involve only an input device \(mouse or keyboard\d a standard monitor. The User is assumed to be nude  in that she does not need to carry around any special devices. The User is also bound by human cognitive and perceptive limitations The findings we report in this paper can be seen as the minimum capabilities of an authentication system. Any system involving biometrics or special hardware has the potential to be more secure than the baseline nude User system. Many assistive technologies can lead to interfaces that are highly resistant to eavesdropping attacks, for example using biometrics, authentication tokens \(recently including out-of-band signaling devices, e.g. a cell phone Bedworth & Allison, 2008\binations of these with shared secret authentication. The drawbacks of such authentication systems include higher cost, limited availability and privacy concerns In contrast with the nude and cognitively limited User, Anne, the Attacker, is able to use technology extensively, to capture all the information exchanged between Ursula and Victor, to store this information and to corr elate information captured across multiple authentication sessions. Anne also has the ability to use significant computing power over extended periods of time, because she needs not gain access to the User s credentials in real time Victor, the Verifier, is also able to use technology after all, Victor is in general a computer\t will be limited by the parameters of the user interface The next section reviews previous work, then Section 3 presents several definitions including a taxonomy of possible attacks. Section 4 presents the theoretical model. Section 5 applies the theory to published authentication interfaces and summarizes the main findings. Section 6 concludes the paper  2. Previous work  Authentication in the presence of eavesdropping attackers has already been tackled in numerous published papers. A detailed literature review of several approaches to combat eavesdropping attacks can be found in Tari, Ozok and Holden \(2006\While many papers are based on the use of special hardware, including screen filters \(Naor and Pinkas 1997\e-tracking hardware \(Kumar et al, 2007\or trusted browser extensions \(Ross et al, 2005\we focus on approaches that are feasible on an untrusted computer, with no special hardware. We assume a monitor and keyboard are generally available Matsumoto \(1996\ented the first theoretical basis for a Human-Computer Cryptography protocol Matsumoto outlines a theoretical framework that can be used to analyze such authentication protocols in a linear space and presents graphs of the probability of success for the attacker. He notes a tradeoff between the length of the shared secret, the length of the authentication session and the probability of success for the attacker. As practical examples, Matsumoto presents two different types of protocols, but both examples are over nonlinear spaces, and cannot be mapped onto his theory Hopper and Blum \(2002\so present several ideas of protocols that are highly resistant to eavesdropping attacks. They propose the concept of learning parity in the presence of noise as a way to introduce randomness in the interaction between the User and the Verifier, with the intent of confusing the Attacker. They point out that this is an NP hard problem, although the NP hardness is irrelevant when dealing with problems of a size that is computationally tractable More recently, a graphical implementation of a shoulder surfing resistant protocol was first proposed by Sobrado and Birget \(2002\d then detailed by Wiedenbeck et al. \(2006\e secret shared by Ursula and Victor consists of a series of graphical symbols, and Ursula authenticates by clicking anywhere inside the convex hull defined by the chosen graphical symbols. Anne cannot easily find out which symbols define the hull, because there are multiple possibilities for any given click point. The scheme is easy to understand in principle, but has several weaknesses. First, locating the symbols on the screen can be difficult, because several symbols look similar. Second, to avoid random guesses matching the required entry \(false positives\he authentication process needs to be lengthy. Third, even with a lengthy authentication process, the attacker has a relatively high chance of authenticating by randomly guessing at click points 1 The paper presents considerations on reducing the success of the Attacker, but not a rigorous analysis of the probabilities of success Several more published results approach the shoulder surfing problem by assuming rather arbitrary limitations on the Attacker s capabilities Tari, Ozok and Holden \(2006\ report on an extensive comparison of perceived and actual shoulder surfing capabilities of text versus graphical passwords, and include both strong and weak passwords in an   1 If an Attacker does not intend to break into one particular account, but rather, in any one of a large number of accounts, the attack may target a large number of accounts in parallel. By trying random password combinations for each of the accounts, such an attack will circumvent the lockout protection and will statistically succeed in breaking into a percentage of the accounts under attack Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 2 


experimental evaluation. Their attackers are human participants without any technological aids. As such visual ability and memory are principal limitations The results of the study might have been very different, had the attackers been allowed to video record the authentication sessions or to use key loggers, tools widely available to real attackers. Roth Richter and Freidinger \(2004\ent a protocol for entering Personal Identification Numbers \(PINs\ at Automated Teller Machines in a manner that is resistant against shoulder surfing by unaided human observers. They concede that cameras might be used to enhance the attacker s capabilities, and evaluate the capabilities of the protocol using the concept of shadow numbers  the set of PINs that could correspond to a given user input. They identify the same tradeoff between password complexity, length of the authentication session and probability of success for the attacker. Finally, a spy resistant keyboard presented in \(Tan, Keyani, and Czerwinski 2004\ also based on the cognitive limitations of the human observer, but would be easily defeated by an Attacker using a recording device Common to all of these protocols is a marked decrease in usability. All protocols require that users perform more complex cognitive tasks than simply remembering and typing a password, as in the familiar authentication approach. All protocols also take significantly longer than typing in a password Instead of a few seconds, most protocols take up to a few minutes to enter one s credentials. The increased complexity is likely to increase error rates, which will further increase the time it takes for users to authenticate. The question we ask \(and answer\n this paper is whether the extra efforts are worth the trouble, and whether any of the proposed protocols lead to reasonable robustness to eavesdropping attacks. Do they actually manage to hide some of the information in the shared secret  3. Definitions  This section describes formally the authentication interface. We introduce two alphabets one for the space of shared secrets and another one for the space of interface symbols actually exchanged by the User and the Verifier. We also discuss the mapping between the two spaces \(ideally, a one-way or difficult to invert mapping\inally, we consider possible types of attacks against such an interface  3.1. Authentication  interface   Let A be an alphabet of symbols that define the shared secret on which the authentication scheme is based. The symbols currently used in A are alphanumeric, image tiles, or points on an image. In the future, an authentication interface might involve Figure 1. Mapping from the space of shared secrets S to the space of interface symbols E  m E is the set of symbols that can be entered at the interface. Among the set m E there may be multiple symbols that will correctly authenticate the user in a given session \(the set of all the valid responses is m E he User can authenticate correctly by selecting any symbol from m E The actual user entered symbol is  e The randomness factor  ensures that the set m E is different from session to session, to prevent replay attacks E S R s  e E m E m Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 3 


users responding to sounds, tracking elements in a video or responding to cues in a story Let    p s s s s    2 1   p k A s k  1    be the string of symbols making up the secret shared between the User and the Verifier \(Fig. 1\me of the elements of the secret can be repeated \(i.e., there might be j i s s  for some values of i and j where p j i  1    Let p j j A A A A A A A S 1         be the set of all possible shared secrets p is the maximum number of symbols in the shared secret Let B be the alphabet of symbols that can be entered at the authentication interface. This needs not be the same as the alphabet forming the space of shared secrets A For example, the alphabet A might be a set of images, and the symbols to be entered at the interface might be numbers. The authentication protocol might display nine images from the alphabet A at a time, and might require the user to enter a number indicating how many of the images in the shared secret are currently displayed on the screen, as in the Passfaces approach \(Brostoff and Sasse, 2000 Using symbols from the alphabet B the User authenticates by selecting an entered symbol   r e e e e    2 1  with r i B e i  1    The entered symbol is in general an array with r elements in the notation above. Just as for the shared secret, we define the set of all possible sets of entered symbols as r j j B B B B B B B E 1         where r  is the maximum number of elements in the entered symbols the User can select at the interface The symbols that can be entered in the authentication process might be the entire set E or a subset of the interface alphabet E E m   m E might vary from session to session, or might be the same For graphical interfaces m E is the set of symbols displayed for the user to select \(e.g. faces in PassFaces\t interfaces, most often E E m   In general, there might be several valid symbols a user could select to authenticate at the interface \(for example, the user might be able to authenticate by clicking anywhere in a region on the screen\Let m m E E  be the set of all such valid symbols.  The inclusion is strict, otherwise any symbol would be valid and an attacker would be able to authenticate by selecting random symbols at the interface In practice m E must be a small subset of m E to reduce the probability of a false positive \(random guess\. If m E is a large subset of m E an attacker has a large probability of successfully authenticating by simply choosing a random symbol at the interface. In many types of authentication interfaces, the set m E will contain a single element \(i.e., there is one and only one correct entry to authenticate Let  be the mapping between the shared secret and the set of valid symbols             m m m E s e E e E at the interface. The user must apply this mapping to the shared secret to determine the set of valid symbols m E and then must select the entered symbol from m E The mapping  also includes a randomness factor  as well as the set of symbols that can be entered at the interface m E  The mapping depends on the set of symbols in m E  because the user will can only enter a symbol from m E i.e., the mapping should not map on a symbol from E that cannot be entered at the interface The randomness factor  must be different from session to session to prevent replay attacks, where the Attacker can simply reenter the same symbols she observed in an earlier session to authenticate in a later session. This randomness factor often consists of displaying the interface symbols m E in a random and different order every time the user needs to make a selection. In our analysis we assume a uniform distribution of the randomness factor. If the randomness factor is not random or not uniformly distributed, this can give the Attacker additional information, making it easier to carry out the attack The mapping  is described as one-way  although in practice it is just difficult to invert. In many applications requiring one-way mappings, the difficulty to invert is based on the large computational effort required to perform the mapping in a brute force attack. In the type of authentication schemes reviewed earlier in this paper, the cognitive limitations of the human user do not allow for the use of large computational effort requirements. The difficulty in inverting the mapping is simply based on the fact that for any observed entered symbol  r e e e e    2 1  there is a set m S of possible values of the shared secret which all map to the same entered symbol \(Fig. 2  m m S s E s e            The number of elements in m S needs only to be large enough that trying all of them is not practical. A lockout mechanism is built into most authentication interfaces and disables the account after a number \(35\ of unsuccessful attempts to login. This discourages the Attacker from trying out random guesses in hope of finding a match by sheer chance   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 4 


3.2. Taxonomy of attack types  There are two types of attacks Anne can mount against the authentication scheme. One type of attack is to guess the shared secret; if successful, this type of attack will give Anne full access to Ursula s online identity. We refer to this type or attack as strong  The other type of attack is to try to guess the appropriate entered symbol for only a given session We refer to this second type of attack as weak In traditional authentication schemes, the two attacks are entwined: the shared secret and the entered symbols are one and the same. For authentication schemes that are resistant to eavesdropping, the two types of attacks are distinct, although one may be more likely to succeed than the other  3.2.1 Weak attacks  The protection against weak attacks is based on using the randomness factor. As shown in Fig. 3, two different authentication sessions with two different randomness factors will result in randomly different sets of acceptable authentication symbols, and will most likely result in the User selecting different entered symbols. An Attacker who observed a session will have only a negligible chance of being able to use the same entered symbol to authenticate successfully in a subsequent session \(replay attack Replay attacks are more likely to succeed if there is a correlation between the mappings of successive authentication sessions, when knowledge of a previous m E will give the Attacker information about the distribution of a future m E A critical barrier against guessing attacks is the lockout mechanism which disables the account after a number of unsuccessful attempts  3.2.2. Strong attacks based on eavesdropping  A more complex type of attack that is more likely to succeed is to determine the shared secret based on several observations of user input. Having eavesdropped on the entered symbols for two or more successful authentication sessions, the Attacker can record the randomness factors and the entered symbols. She can then calculate offline the sets of possible values for the shared secrets that are consistent with the observed entered symbols. Once the Attacker has sufficient information, she can uniquely determine the shared secret and use it to authenticate in place of the user, without triggering the lockout mechanism. This attack has the highest likelihood of success and will be analyzed in detail in the rest of the paper  3.2.3. Design tradeoffs   The difficulty of guessing the shared secret increases with the number of symbols in the secret p  and with the number of symbols in the alphabet A in other words with the number of possible shared secrets in the space S At the same time, the usability of the authentication scheme decreases with the same factors, as the user needs to remember a longer password composed of a more complex set of symbols. Additionally, the more complex password will likely require a more complex cognitive effort to determine the symbols to be entered at the interface further reducing the usability of the scheme  Figure 2. Given an entered symbol  e corresponding to a successful authentication, the Attacker is able to determine the set m S of all possible values of the shared secret for that map on the observed entered symbol e  E S R s  e S m Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 5 


The robustness of the authentication interface to brute force attacks depends on the risk that the Attacker would be able to guess the correct set of symbols to be entered to authenticate. The robustness against such attacks increases with the number of symbols to be entered at the interface r and with the number of symbols in the set m E The usability of the scheme decreases with both of these measures because a larger number of authentication symbols takes longer to enter and also leads to higher error rates. A large number of symbols in m E also leads to longer authentication times and to higher error rates The robustness of the scheme is reduced if the set of valid entered symbols m E is a large fraction of m E because the chance of a random choice from m E to be in m E increases with the number of elements in m E Conversely, a larger m E leads to higher usability, because the User is more likely to locate an acceptable symbol if m E includes more choices  4. Theoretical framework for assessing robustness to eavesdropping attacks  4.1. Basic assumptions  In this work we make the basic assumption that the security of the authentication scheme is entirely based on the shared secret; there is no security through obscurity Kerkhoff's Principle\The Attacker knows exactly what the alphabet of symbols  A the maximum length of the shared secret p  the operation of the authentication process on the Verifier side, and has full access to the User input ample space to store several authentication sessions as well as full access to extensive computing power to process the stored session data. Any interface parameters that the attacker does not already know can be assumed to be part of the shared secret any for example, in the 2000 Hopper and Blum work, the shared secret would include both secret vectors, the secret and the noise generator  We also assume that the Attacker is able to distinguish between successful and unsuccessful authentication sessions. A protocol where a valid User is subject to random false positives and false negatives would greatly complicate the Attacker s work, but would also confuse and frustrate the User Two other important issues have been analyzed extensively elsewhere: whether the User is able to recall the shared secret \(Brostoff and Sasse, 2003 and whether the User is able to determine the correct entered symbols \(i.e., what is a reasonable cognitive load\. We do not make further mention on either of these two issues in the remainder of the paper  4.2. Formal results  In this section we develop the theoretical framework that quantifies the usability-security tradeoff. We define the false positive error as the probability that an attacker is able to randomly guess the shared secret or the entered symbol successfully The term does not imply that the interface will mistake an incorrect entered symbol as correct  Lemma 1  Given a single session of communication between the User and the Verifier, where the User proves her identity to the Verifier with probability of false positive error not to exceed P given a known set of all possible shared secrets S the Attacker is  Figure 3. As an attacker observes two or more authentication sessions, the space of possible shared secrets that could have led to the observed entered symbols shrinks. Eventually, the attacker is able to find out the shared secret as the intersection of all sets of possible shared secret values  E e 1 S R 1 s  S m1 S m2 R 2 e 2 E m1 E m2 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 


able to narrow down the location of the shared secret to a set with   S P  012 elements on average   S  denotes the number of elements in the set S   Proof  The probability of a false positive error in identifying the User is the probability that the User has randomly chosen a symbol from m E that happens to be in the set of valid symbols m E or equivalently a shared secret that happens to map into m E for a given session with randomness factor  The probability of this happening is       m m m E E S S P        On the other hand, having observed the entered symbol e the attacker is able to infer that the shared secret is in the set             m m E s e S s S of all possible shared secret values that map on the actual entered symbol. The space of possible values for the shared secret is thus reduced from the set S to the subset m S with     S P S m  012   elements   The result of the lemma above is true on average In general, the number of elements in the set m S will vary depending on the entered symbol e some entered symbols will correspond to more possible values of the shared secret than other entered symbols, e.g. Sobrado and Birget, 2005\or those relations that map each entered symbol to the same number of possible shared secrets, the result of the lemma will be exact, not just on average Another important observation is that the proof of the lemma is valid even if the entered symbol includes random user errors, as proposed in Hopper and Blum \(2000\ the protocol is such that the authentication allows for up to Z random errors among the elements of the entered symbol e this will result in a larger set m S Even if the user actually makes fewer errors in a given session, the set m S will necessarily include all the possible shared secrets that might match all but Z of the elements of the entered symbol e At the same time, the Verifier must be ready to accept as valid sessions with up to Z errors hence the probability of a false positive will also increase. The proof above does not need to assume that all the elements of the entered symbol e are correct, but only that the authentication is successful hence the lemma holds for any tolerance to errors Z   Lemma 2  Given k sessions of communication between the User and the Verifier, where the shared secret remains unchanged for all k sessions; given that in each session the User proves her identity to the Verifier with probability of false positive error not to exceed P given a set of possible shared secrets S the Attacker is able to narrow down the location of the shared secret to a subset with   S P k  012 elements  Proof  To conduct such an attack, the Attacker needs to capture and store the set of entered symbols j e and the randomness factors j  for each authentication session j of the k sessions captured. Let  j m S be the sets that map onto each of the entered symbols j e  The shared secret is in each of the  j m S sets, hence it will also be in the intersection     k j E s e S s S j j m j k j j m 1       1         Based on Lemma 1, the probability that the shared secret is in any given set  j m S is equal to the false positive probability P Because the randomness factor is different for each session, the sets  j m S are independently random distributed, so the probability that the shared secret is in the intersection of  j m S  will be the product of the probabilities that that shared secret is in each of the sets, i.e k P Hence the intersection set has   S P k  012 elements   Theorem 1  To gather sufficient information to uniquely determine the shared secret, the Attacker needs to capture      P S k o log   log sessions is the ceiling function, returning the smallest integer greater than the argument of the function  Proof  The proof is trivial when applying Lemma 2 The average number of possible shared secrets that match all the observed entered symbols over o k  captured sessions is 1     012 S P o k hence the actual shared secret can be determined exactly   The theorem above describes how many sessions the Attacker must capture to collect sufficient information to uniquely determine the shared secret It makes no claim about whether the Attacker has sufficient computing power at her disposal to actually determine the shared secret Most authentication schemes are based on NP complete or NP hard problems with a search space that is exponential with respect to the length of the shared secret. On the other hand, if the attacker has Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 


collected the needed number of sessions and if she has sufficient computing power to perform an exhaustive search in a reasonable amount of time, the difficulty of solving the problem is irrelevant We can now use the framework above to evaluate authentication interfaces proposed in the literature. For any of the proposed interfaces to be secure, they need to exhibit either a sufficient computational complexity or to require the capture of a sufficiently large number of sessions \(or both  5. Application of theory to reported authentication schemes  In this section we analyze a few particular cases of authentication procedures. We first evaluate how much computing power an attacker is likely to have available, then discuss the robustness of the proposed protocols in view of the theory we presented. We consider both the number of observations the scheme is able to withstand, as well as the time required for an exhaustive search of the space of shared secrets  5.1. What is sufficient computing power  An attacker having sufficient computing power to conduct exhaustive searches over the shared secret space is able to circumvent the NP hardness of the one-way mapping. Fortunately for the Attacker, the problem of searching for the shared secret values that could have led to a set of observed entered symbols is by its nature highly parallel, and can be farmed out to an army of computers in an efficient manner. The amount of data to be sent to the worker nodes in such an army would include the definition of the alphabets A and B and the list of observed entered symbols and randomness factors for the 5-10 eavesdropping sessions captured, a very small data set Such a brute force attack is greatly aided by technological progress. The computing power of devices is increasing as the cost of computing devices is decreasing. Even more, by using self replicating virus programs to take over unprotected computers attached to the Internet, Attackers can marshal the resources of armies of computer zombies to carry out nefarious activities for almost no cost to the Attacker In 2002 a 64 bit RC5 key was cracked in 1757 days in a distributed manner using donated processing power \(equivalent to 32,504 800MHz Apple PowerBook G4\g to Distributed.net \(2007 With a typical CPU speed of 1 GHz, an army of 10,000 zombies, assuming an admittedly optimistic processing speed of one shared secret evaluation per CPU cycle, today s Attackers would be able to process 18 10 shared secrets per day. The next section considers what the implications of this processing power are on several protocols proposed to date  5.2. Recommendations based on theoretical findings  As discussed in the introduction, the shared secret can be protected either by not disclosing sufficient information about it, or by making the shared secret computationally difficult to find from the disclosed information. Table 1 below summarizes results on the two considerations. To be able to realistically hide the shared secret, the schemes would need to withstand hundreds of repeated observations, for example in the case of daily use over a period of a few months, the standard recommended lifetime of a shared secret. None of the protocols reported to date are able to withstand more than ten observations without disclosing the full information about the shared secret to the Attacker Regarding the computational complexity, all but the Hopper and Blum scheme allow the Attacker to conduct a fast search of all the possible shared secrets. Armed with all the information about the shared secret and able to conduct an exhaustive search in less than an hour, the Attacker can uniquely locate the shared secret for all but the Hopper and Blum scheme. For this last scheme, the attacker is still able to capture all the information needed to identify the shared secret, but the complexity of the Reference or description  of possible shared secrets Probability of false positive of sessions needed to capture shared secret Time needed for exhaustive search Strong password  traditional N=10 4 10 1 6  1 N 1 0 Matsumoto, 1996 27 1/3 3 0 Sobrado and Birget, 2005 10 13 0.001  5 1 second Strong password  ideal  10 16 0.001  6 15 minutes Hopper and Blum, 2000 10 25 0.001  10 30,000 years No value given: using a conservative P 0.001 A strong password requires at least one digit, one symbol and one upper case letter Assuming some to be discovered eavesdropping-resistant scheme with excellent user friendly capabilities  Table 1. Robustness of authentication interfaces to eavesdropping attacks. A scheme is secure if the number of session needed to be captured and the time to perform an exhaustive search exceeds the attacker s resources Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 


search space will prevent her from actually locating the shared secret within a reasonable timeframe As illustrated in Table 1, the main result of the paper is that the security of the schemes is in the complexity of the space of shared secrets S not in information hiding. Information that can be gathered in fewer than ten repeated observations is not well hidden. Regardless of the type of one-way mapping the User s credentials can be easily compromised if the Attacker can complete an exhaustive search of the space of shared secrets S within a reasonable time frame. On the other hand, if S is sufficiently complex to prevent a brute force search in a reasonable amount of time, the Attacker is unable to determine the shared secret even though she may have all the information needed to uniquely identify it Another important result is that the amount of information transmitted by the User to the Verifier in any given session has no ultimate implications on the ability of the scheme to withstand repeated observations by the Attacker. A user could be asked to make very simple decisions \(binary choices select items among a large number of possibilities An interface with increased complexity of choice \(in the m E space\will be more resistant to guesses, but will not be more resistant to repeated eavesdropping attacks. The added complexity in m E  leads to a lower probability of false positive, but will also disclose the shared secret in fewer observations. Although, this appears to pose a valuable tradeoff, a closer analysis shows that this tradeoff is very shallow. For example decreasing the acceptable probability of false positives from 0.001 to 0.0001 in the example above will disclose a strong password in only 4 observations instead of 6. An Attacker who can capture 4 sessions will be equally able to capture 6 sessions if needed. Hence the tradeoff between probability of error and robustness to eavesdropping is not worth making. The best approach is to have the lowest probability of false positives, limited by the usability of the interface \(usability introduces a tradeoff that is worth considering, because increased complexity in the m E space leads to exponentially decreasing usability With these two conclusions in mind, we propose the following guidelines for devising an interface resistant to eavesdropping 1  Use a space of possible shared secrets as complex as the user can handle. The space should include at least 22 10 possible shared secrets \(tens of years of computing time for an exhaustive search 2  Use a one-way mapping as simple as possible. This mapping does nothing to hide information from the Attacker, so it can be designed only to maximize usability 3  Use an interface that requires as much identifying information as possible in one session, limited by the user s cognitive and speed abilities. The higher the amount of information exchanged, the lower the probability of false positives. The Attacker will receive more information in each captured session, but she will not be able to exhaustively search the space of shared secrets to make use of this information, if the space S is complex enough  Even by following the guidelines above, it is unlikely that the resulting scheme will be truly user friendly. All of the schemes analyzed above have serious usability issues, because they make the authentication process more complex and significantly more time consuming than the traditional passwords; yet they all provide minimal gains in robustness. To transcend the low usability and the low security a paradigm shift is needed There are three ways to allow both robustness to attacks and more user friendly interfaces 1  Invent a new type of interface that would allow the User to handle a much more complex space of shared secrets, without much more cognitive and memory effort than the current password scheme OR 2  Invent a new type of interface that would prevent the Attacker from using computing power to search the space of shared secrets Such schemes intended to prevent automated agents from impersonating human users have been used in other types of applications \(see Completely Automated Public Turing Test to Tell Computers and Humans Apart www.captcha.net R 3  Design interfaces that combine the shared secret with specialized hardware or biometrics. The added computing power that the User can carry in hardware tokens or in out of band authentication devices is a way to counteract the extensive computing power the Attacker has at her disposal. This can include the use of one-time passwords \(e.g transmitted over a cell phone or generated on-the-fly in a smart token  While we await innovations in 1 and 2 above, the only feasible solution for now is to focus on combing shared secrets with specialized hardware \(tokens, out of band devices or biometrics\s we mentioned before, this has the drawback of higher costs and more limited availability. Based on the theoretical Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 


framework we developed in this paper, the approach of combining only shared secrets and standard hardware is simply unable to deliver both resistance to eavesdropping attacks and reasonable user friendliness at the same time  6. Conclusion  We presented a theoretical framework that evaluates the robustness of protocols intended to be resistant to eavesdropping attacks. Such protocols can attempt to either not disclose information about the User s shared secret, or to make it difficult to locate the shared secret, even after collecting sufficient information about it. After reviewing protocols reported in the literature, we conclude that even the most robust protocols \(those to the point where usability is a concern\ are only able to withstand ten observations before the attacker has sufficient information to uncover the shared secret On the other hand, authentication interfaces that use complex shared secrets could be secure even if the Attacker has captured all the needed information to determine the shared secret.  Having collected the required number of sessions, the Attacker will now be limited by computing power, if the space of shared secrets is complex enough. The drawback of complex shared secrets is the exponentially decreasing usability of the resulting interface. As such, interfaces that are both secure and usable can only be devised by combining shared secrets with other authentication technologies \(biometrics or specialized hardware\ multiple factor authentication systems  7. References  APWG. \(2008\Phishing Activity Trends, January 2008. Retrieved June 11, 2008, from www.apwg.org/reports/apwg_report_jan_2008.pdf  Bedworth, M. and Allison, C. \(2008\periments with a Visual Probabilistic One-Time Password Authentication System Proc. SAM 2008   Brostoff, S., & Sasse, M. \(2000\re Passfaces more usable than passwords? A field trial investigation Proc. HCI 2000 pp. 405-424 Springer Verlag  Brostoff, S. and Sasse, M.  \(2003\"Ten strikes and you're out": Increasing the number of login attempts can improve password usability CHI 2003 Workshop on Human-Computer Interact. and Security Systems   Distributed.net. \(2007\Project RC5.  Retrieved Jan 27, 2008, from http://www.distributed.net/rc5  Hoanca, B. and Mock, K. \(2007 Phishing Attacks and Countermeasures: Implications for Enterprise Information Security in D. Khadraoui and F Herrmann \(Eds.\dvances in Enterprise Information Technology Security. IGI, Hershey, PA  Hopper, N. and Blum, M.  \(2000 A Secure HumanComputer Authentication Scheme CMU Tech Report CMU-CS-00-139  Kumar, M., Garfinkel, T., Boneh, D., and Winograd T.  \(2007\. Reducing shoulder-surfing by using gazebased password entry Proc. SOUPS 07 vol. 229 ACM Press, New York, NY, 13-19  Matsumoto, T. \(1996\uman-computer cryptography: An attempt 3rd ACM CCCS pp. 6875, New Delhi, March 1996  Naor, M.  and Pinkas, B. \(1997\isual authentication and identification. In Proc. Advances in Cryptology pp. 322 336  Ross, B., Jackson, C., Miyake, N., Boneh, D. and Mitchell, J.C. \(2005\ Stronger Password Authentication Using Browser Extensions, in Proc 14th Usenix Security   Roth, V., Richter, K., and Freidinger, R. \(2004 PIN-entry method resilient against shoulder surfing In Proceedings of the 11th ACM CCS 04 ACM Press, New York, NY, 236-245  Sobrado, L. and Birget, J.-C. \(2005 Shoulder surfing resistant graphical passwords Retrieved January 27, 2008, from http://clam.rutgers.edu/~birget/grPssw/srgp.pdf  Sobrado, L. and Birget, J.-C. \(2002\raphical passwords The Rutgers Scholar vol 4, 2002 Retrieved January 25, 2008 at http://rutgersscholar.rutgers.edu/volume04/sobrbirg/s obrbirg.htm  Tan, D. S., Keyani, P., and Czerwinski, M. \(2005 Spy-resistant keyboard: more secure password entry on public touch screen displays. In Proc  19th CHISIG ACM International Conference Proceeding Series, vol. 122, 1-10  Tari, F., Ozok, A. A., and Holden, S. H. \(2006 comparison of perceived and real shoulder-surfing risks between alphanumeric and graphical passwords Proc SOUPS '06 vol. 149. ACM Press, New York NY, 56-66  Wiedenbeck, S., Waters, J., Sobrado, L., and Birget J. \(2006\esign and evaluation of a shouldersurfing resistant graphical password scheme Proc AVI '06 ACM Press, New York, NY, 177-184 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


Test Environment 


Implant Application 1 Low level analog signal Stimulation Sensor interface Signal digitized and formatted Transmitter Application  receiver controller with MAC RF encoded packets of data Data packets organised into function Change response or cause direct stimulation 


Product Design and Manufacture 225 Work with end product manufacturer Each design is unique 225 No off the peg solution 225 Thorough testing during product development 225 Work with component suppliers 225 World class manufacturing capability 225 Post manufacture test and burn in 225 Reliable parts shipped on time NO SURPRISES NO CHANGES NOTHING EXCITINGI 


Module Encapsulated ZL70101 Crystal Matching network Antenna connection 


References 225 Krauss J D Antennas 2 nd Edition McGraw-Hili 1988 225 Yang G-Z Body Sensor Networks Springer 2005 225 Higgins H Implant Communication Made Real Body Sensor Networks Conference 2007 225 Sivard A et al Challenge of Designing In-body Communications Embedded System News 2004 225 Higgins H Human Body Implant Communication Making it Possible European Conference on Antennas and Propagation 2007 225 Hodgins D et al Healthy Aims Developing New Medical Implants and Diagnostic Equipment IEEE C5 Pervasive Computing January March 2008 225 Higgins H Implant Communications Out of the Lab and Into Patients lET Body-Centric Communication Conference London April 20 2009 225 Higgins H Body implant Communications Is It a Reality Antennas and Propagation for Body\255 Centric Wireless Communications lET/loP London April 24 2007 225 Higgins H Radio Frequency Technology and In-Body Communication Systems Implantable and Body Centric Conference Imperial College London 2005 225 Higgins H In-body Communications the Challenges and The Opportunities COST 2005 225 Rahmat-Samii Y and Kim J Implanted Antennas in Medical Wireless Communications Morgan  Claypool 2006 225 The Antenna Book 20th Edition American Radio Relay League ARRL 255 Main Street Newington CT,USA 225 Fujimoto K et al Small Antennas Research Studies Press 1967 225 Bancroft R Microstrip and Printed Antenna Design Noble Publishing 225 http://www.zarlink.com/zarlink/hs/82_ZL70101.htm 


Conclusions 225 Communication with very small implants is possible 225 The human body can both help and hinder communication 225 Power consumption is an issue for long term implants 225 The communication system antenna and implant should be designed together 225 There is no one size fits all solution 225 Transmission of data to and from an implant is practical and is being done and is making a difference to the lives of real patients 


Thank you Questions 


 18  Astronautical Congress Valencia, 2006 27  Bu reau  In tern atio n a l d e s Po ids et Mesures. \(2 008  August\SI Base Units. [On http://www.bipm.org/en/si/base_units   B IOGRAPHY  Author, Karl Strauss, has been employed by the Jet Propulsion Laboratory for over 22 years.  He has been in the Avionics Section from day One.  He is considered JPL\222s memory technology expert with projects ranging from hand-woven core memory \(for another employer\o high capacity solid state designs.  He managed the development of NASA\222s first Solid State Recorder, a DRAM-based 2 Gb design currently in use by the Cassini mission to Satu rn and the Chandra X-Ray observatory in Earth Orbit.  Karl was the founder, and seven-time chair of the IEEE NonVolatile Memory Technology Symposium, NVMTS, deciding that the various symposia conducted until then were too focused on one technology.  Karl is a Senior IEEE member and is active in the Nuclear and Plasma Scie nce Society, the Electron Device Society and the Aerospace Electronic Systems Society Karl is also an active member of SAE Karl thanks his wonderful wife of 28 years, Janet, for raising a spectacular family: three sons, Justin, Jeremy Jonathan.  Karl\222s passion is trains and is developing a model railroad based upon a four-day rail journey across Australia\222s Northern Outback   


 19 Bollobás, B. 2001. Random Graphs. Cambridge University Press; 2nd edition. 500pp  Cawley, G. C., B. L. C. Talbot, G. J. Janacek, and M. W Peck. 2006. Sparse Bayesian Ke rnel Survival Analysis for Modeling the Growth Domain of Microbial Pathogens  Chiang C. L. 1960. A stochastic study of life tables and its applications: I. Probability distribution of the biometric functions. Biometrics, 16:618-635  Cox,  D. R. 1972. Regression models and life tables J. R Stat. Soc. Ser. B 34:184-220  Cox, D. R. 1975.   Partial likelihood Biometrika 62:269276  Cox, D. R. & D. Oakes. 1984 Analysis of Survival Data  Chapman & Hall. London  Cressie, N. A. 1993 Statistics for Spatial Data John Wiley Sons. 900pp  Duchesne, T. 2005. Regression models for reliability given the usage accumulation history. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty Y. Armijo. pp.29-40. World Scientific, New Jersey  Eleuteri, A., R. Tagliaferri, L. Milano, G. Sansone, D D'Agostino, S. De Placido,  M. Laurentiis. 2003.  Survival analysis and neural networks. Proceedings of the International Joint Conference on Neural Networks, Vol. 4 20-24 July 2003 Page\(s\:2631 - 2636  Ellison, E., L. Linger, and M Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013, 1997  Fleming, T. R. & D. P. Harrington. 1991. Counting process and survival analysis. John Wiley & Sons. 429pp  Graver, J. and M. Sobel 2005. You may rely on the Reliability Polynomial for much more than you might think Communications in Statistics: Theory and Methods  34\(6\1411-1422  Graves, T. and M. Hamada. 2005. Bayesian methods for assessing system reliability: models and computation. In Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson, et al. pp.41-53  Grimmett, G. 2006 The Random-Cluster Model Springer  Grimmett, G. 1999 Percolation Springer  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis.  Springer. 481pp  Jin Z. 2005. Non-proportional semi-parametric regression models for censored data. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.279-292 World Scientific  Kalbfleisch, J. D. & R. L. Prentice. 1980 The Statistical Analysis of Failure Time Data John Wiley & Sons.  New York. 1980  Kalbfleisch, J. D. &  R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data.  Wiley-InterScience, 2nd ed 462pp  Lisboa, P. J. G. and H. Wong. 2001. Are neural networks best used to help logistic regression? Proceedings of International Joint Conference on Neural Networks, IJCNN 01. Volume 4, 15-19,  July 2001. Page\(s\:2472 - 2477 vol.4  Kauffman, R. J. and B. Wang. 2002. Duration in the Digital Economy. Proceedings of th e 36th Hawaii International Conference on System Sciences \(HICSS03\ Jan 2003  Kaplan, E. L. & P.  Meier.  1958.  Nonparametric estimation from incomplete observations J. Amer. Statist. Assoc  53:457-481  Klein, J. P. and P. K. Goel 1992. Survival Analysis: State of the Art.  Kluwer Academic Publishes. 450pp  Klein, J. P. and  M. L Moeschberger. 20 03. Survival analysis techniques for ce nsored and truncated data Springer  Krings, A. and Z. S. Ma. 2006.  "Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks MILCOM 2006, Military Communications Conference, 2325 October, 7 pages, 2006  Krings, A. W. 2008.  Survivable Systems.  in Information Assurance: Dependability and Security in Networked Systems Yi Qian, James Joshi, David Tipper, and Prashant Krishnamurthy, Morgan Kaufmann Publishers. \(in press  Lawless, J. F. 1982. Statistical models and methods for lifetime data.  John Wiley & Sons. 579pp  Lawless, J. F. 2003. Statistical models and methods for lifetime data.  John Wiley & Sons. 2nd ed. 630pp  Li, M. and P. Vitanyi. 1997. Introduction to  Kolmogorov Complexity and Its Applications. 2nd ed, Springer  Ma, Z. S. 1997.  Survival analysis and demography of Russian wheat aphid populations.  Ph.D dissertation, 307pp University of Idaho Moscow, Idaho, USA 


 20 Ma, Z. S., and E. J. Bechinski. 2008.  Developmental and Phenological Modeling of Russian Wheat Aphid Annals of Entomological Soc. Am In press  Ma, Z. S. and A. W. Krings. 2008a. The Competing Risks Analysis Approach to Reliability Survivability, and Prognostics and Health Management.  The 2008 IEEEAIAA AeroSpace Conference. BigSky, Montana, March 18, 2008. \(In Press, in the same volume  Ma, Z. S. and A. W. Krings 2008b. Multivariate Survival Analysis \(I\e Shared Frailty Approaches to Reliability and Dependence Modeling. The 2008 IEEE-AIAA AeroSpace Conference. BigSky Montana, March 1-8, 2008 In Press, in the same volume  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(II\ Multi-State Models in Biomedicine and Engineering Reliability. 2008 IEEE International Conference on Biomedical Engineering and Informatics BMEI 2008\27th-30th, 2008 Accepted   Mani, R., J. Drew, A. Betz, P. Datta. 1999. Statistics and Data Mining Techniques for Lifetime Value Modeling ACM Conf. on Knowledge Discovery and Data Mining  Mazzuchi, T. A., R Soyer., and R. V Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Meeker, W. Q. and L. A. Escobar. 1998. Statistical Methods for Reliability Data. Wiley-Interscience  Munson, J. C. 2003. Software Engineering Measurement Auerbach Publications  Nelson, W. 1969. Hazard plotting for incomplete failure data J. Qual. Tech 1:27-52  Nakagawa, T. 2006.  Shock and Damage Models in Reliability Theory. Springer  Osborn, B. 2005. Leveraging remote diagnostics data for predictive maintenance.   In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp. 353-363  Pena, E. A. and E. H. Slate. 2005. Dynamic modeling in reliability and survival analysis. In "Modern Statistical and Mathematical Methods in Reliability". Edited by A. Wilson N. Limnios, S. Kelly-McNulty, Y. Armijo. pp.55-71  Reineke, D. M., E. A. Pohl, and W. P. Murdock. 1998 Survival analysis and maintenance policies for a series system, with highly censore d data.  1998 Proceedings Annual Reliability and Maintainability Symposium. pp 182-188  Schabenberger, O. and C. A. Gotway. 2005. Statistical Methods for Spatial Data Analysis.  Chapman & Hall/CRC  Severini, T. A. 2000. Likelihood methods in statistics Oxford University Press  Shooman, M. L. 2002. Reliability of Computer Systems and Networks: Fault Tolerance, Analysis and Design. John Wiley and Sons. 551pp  Stillman, R. H. and M. S. Mack isack, B. Sharp, and C. Lee 1995. Case studies in survival analysis of overhead line components. IEE Conferen ce of the Reliability and Distribution Equipment. March 29-31, 1995. Conference Publication No. 406. pp210-215  Therneau, T. and P. Grambsch. 2000 Modeling Survival Data: Extending the Cox Model Springer  Wilson, A.  N. Limnios, S Kelly-McNulty, Y. Armijo 2005. Modern Statistical and Mathematical Methods in Reliability. World Scientific, New Jersey  Xie, M. 1991. Software Reliability Modeling. World Scientific Press    B IOGRAPHY   Zhanshan \(Sam\ Ma holds a Ph.D. in Entomology and is a Ph.D. candidate in Computer Science at the University of Idaho. He has published approximately 30 journal and 30 conference papers, mainly in the former field.  Prior to his recent return to academia, he worked as senior network/software engineers in software industry.  His current research interests include reliability and survivability of wireless sensor networks, fault tolerance survival analysis, evolutionary game theory, evolutionary computation and bioinformatics  Axel W. Krings is a professor of Computer Science at the University of Idaho.  He received his Ph.D. \(1993\ and M.S 1991\ degrees in Computer Science from the University of Nebraska - Lincoln, and his M.S. \(1982\ in Electrical Engineering from the FH-Aachen, Germany.  Dr. Krings has published extensively in the area of Computer Network Survivability, Security, Fault-Tolerance and Realtime Scheduling. In 2004/2005 he was a visiting professor at the Institut d'Informatique et Mathématiques Appliquées de Grenoble, at the Institut National Polytechnique de Grenoble, France.  His work has been funded by DoE/INL DoT/NIATT, DoD/OST and NIST 



A Dynamic Approach for Frequent Pattern Mining Using Transposition of Database   Sunil Joshi Department of Computer Applications Samrat Ashok Technological Institute Vidisha \(M.P.\dia E-mail: sunil.joshi05@gmail.com Dr. R. C. Jain Professor, Director Samrat Ashok Technological Institute Vidisha \(M.P.\dia E-mail: dr.rc.jain@gmail.com    Abstract an Important Problem in Data Mining in Various Fields like Medicine, Telecommunications and World Wide Web is Discovering Patterns. Frequent patterns mining is 
the focused research topic in association rule analysis Apriori algorithm is a classical algorithm of association rule mining. Lots of algorithms for mining association rules and their mutations are proposed on basis of Apriori Algorithm Most of the previous studies adopt Apriori-like algorithms which generate-and-test candidates and improving algorithm strategy and structure but no one concentrate on the structure of database. A simple approach is if we implement in Transposed database then result is very fast Recently, different works proposed a new way to mine patterns in transposed databases where a database with 
thousands of attributes but only tens of objects. In this case mining the transposed database runs through a smaller search space. In this paper, we systematically explore the search space of frequent patterns mining and represent database in transposed form. We develop an algorithm termed DFPMT—A Dynamic Approach for Frequent Patterns Mining Using Transposition of Database\ for mining frequent patterns which are based on Apriori algorithm and used Dynamic Approach like Longest Common Subsequence. The main distinguishing factors among the proposed schemes is the database stores in 
transposed form and in each iteration database is filter reduce by generating LCS of transaction id  for each pattern. Our solutions provide faster result. A quantitative exploration of these tradeoffs is conducted through an extensive experimental study on synthetic and real-life data sets Keywords- Longest Common Subsequence, Transposition of Database,Frequent Pattern mining I   I NTRODUCTION  Frequent Pattern Mining is most powerful problem in association mining. Most of the algorithms are based on algorithm is a classical algorithm of association rule 
mining [2, 3  L o t s  o f al gor i t hm s fo r m i ni ng a sso c i a t i o n  rules and their mutations are proposed on basis of Apriori Algorithm [2, 3, 4, 5, 6   M o s t  of  t h e pr ev i o u s  s t u d i e s  adopt Apriori-like algorithms, which generate-and-test candidates and improving algorithm strategy and structure Several modifications on apriori algorithm are focused on algorithm Strategy but no one-algorithm emphasis on representation of database. A simple approach is if we implement in Transposed database then result is very fast Recently, different works proposed a new way to mine patterns in transposed databases where a database with 
thousands of attributes but only tens of objects  In many example attribute are very large than objects or transaction In this case, mining the transposed database runs through a smaller search space. In apriori algorithm each phase is count the support of prune pattern candidate from database.  No one algorithm filters or reduces the database in each pass of apriori algorithm to count the support of prune pattern candidate from database. We propose a new dynamic algorithm for frequent pattern mining in which database represented in transposed form And for counting the support we find out by longest 
common subsequence approach and after finding pattern longest common subsequence is stored or update in database so that next time instead of whole transaction we search from these filter transaction string  II  FREQUENT  PATERN  MINING  Frequent Itemset Mining came from efforts to discover useful patterns in customers’ transaction databases. A customers’ transaction database is a sequence of transactions \(T = t1.  . . tn\, where each transaction is an itemset \(ti 004 I\. An itemset with k elements is called a k 
itemset. In the rest of the paper we make the \(realistic assumption that the items are from an ordered set, and transactions are stored as sorted itemsets. The support of an itemset X in T, denoted as suppT\(X\, is the number of those transactions that contain X, i.e. suppT\(X\ |{tj : X 004 tj}|. An itemset is frequent if its support is greater than a support threshold, originally denoted by min supp. The frequent itemset mining problem is to find all frequent itemset in a given transaction database   
2010 Second International Conference on Communication Software and Networks 978-0-7695-3961-4/10 $26.00 © 2010 IEEE DOI 10.1109/ICCSN.2010.15 498 


The first, and maybe the most important solution for finding frequent itemsets, is the APRIORI algorithm [5 Later faster and more sophisticated algorithms have been Suggested, most of them being modifications of APRIORI 5  T h er e f ore i f w e i m p r ove t h e A P R I O R I al gor i t h m  then we improve a whole family of algorithms. We assume that the reader is familiar with APRIORI [1, 2, 3, 4, 5, 6  an d w e tu rn ou r att e n t i o n t o  its  cen t r al  dat a s t ru c t u r e    Most of these algorithms adopt an Apriori-like method generates a candidate pattern by extending currently frequent pattern and then test the candidate. During this process, many infrequent patterns are generated  III  TRANSPOSITION  OF  DATABASE  To avoid confusion between rows \(or columns\ of the original database and rows \(columns\ of the “transposed database, we define a database as a relation between original and transposed representations of a database in Table-1. The attributes are A = {a1, a2, a3, a4} and the objects are O = {o1, o2, o3}. We use a string notation for object sets or itemsets, e.g., a1a3a4 denotes the itemset a1, a3, a4} and o2o3 denotes the object set {o2, o3}. This dataset is used in all the examples between two sets: a set of attributes and a set of objects  IV  D YNAMIC A PPROACH   The longest common subsequence problem is one of the common problems which can be solved efficiently using dynamic programming. “The Longest common subsequence problem is, we are given two sequences X=<x1,x2----------xn> and Y=<y1,y2---------ym> and wish to find a maximum length common subsequence of X and Y” for example : if X=<A,B,C,B,D,A,B> and Y=<B,D,C,A,B,A> then The sequence <B, C, B, A longest common subsequence. Let us define C [i, j t o be the length of an LCS of the sequences xi and yj. If either i=0 or j=0, one of the sequence has length 0, so the LCS has length 0. The Optimal substructure of the LCS Problem gives the recursive formula in fig.1  TABLE I  T RANSPOSITION OF D ATABASE  DATABASE  D  T RANSPOSED DATABASE  D T        000   1 1 1  0 max  1  1  0 if i or j C i j C i j if i j and xi yj cij ci j ifij andxi yj 000 000  000 000 000 000    000 000 000 000   002 000 000 000 000  Figure 1  Longest Common Subsequence Recursive Formula V  ALGORITHM   The mining algorithm works over the entire database file, first transpose the database and count the number of item and transaction string generated for each item. Sort the item numbers. Now apply Apriori like Algorithm in which first we calculate frequent pattern C1.it reduces un-frequent pattern and its transaction details also. For each pass we apply following sequence of operation until condition occurred. First generate the candidate pattern and prune by Apriori method. To count the support , instead of whole database for each pruned pattern we find longest common subsequence and length of  transaction string of pattern’s item and also stored new pattern and its transaction string so that next iteration we trace above string. To find longest common subsequence we used dynamic programming approach which faster then traditional approach. Write pruned pattern list with transaction string. So that in next pass we used this pattern list instead of all pattern list. An advantage of this approach is in each iteration database filtering and reduces so each iteration is faster then previous iteration  A  Algorithm DAPS \(Algorithm for Pruning with Support  I. Compute k-1 Subset of k-itemset II. Generate Itemset Transition string from Filter Transposed Database III. Computer LCS for each item in itemset using Transition string IV. If length of LCS 000 then itemset is frequent  B  Algorithm DFPMT \( Dynamic Approach for Frequent Patterns Mining Using Transposition of Database I  Convert Database in Transpose Form D T  II  Compute F1 of all Frequent Items III  C1:= D T Only Frequent Item row with Transition id string IV  K: =2 V  While Lk-1 000 do VI  Compute Ck of all candidate k-1 Itemsets New Algorithm which prune and count support using LCS VII  Compute Lk=DAPS \(Ck VIII  K:=K+1  Object Attribute Pattern Attribute Object Pattern O1 a1a2a3  a1 O1O2 O2 a1a2a3  a2 O1O2O3 O3 a2a3a4  a3 O1O2O3  a4 O3 
499 


   VI  EXPLANATION  WITH  EXAMPLE  WHICH  SUPPORT  THE  ARGUMENTS    Study the following transaction database A={A1,A2,A3,A4,A5,A6,A7,A8,A9>, Assume 0011 20 Since T contains 15 records, it means that an itemset that is supported by at least three transactions is a frequent set  TABLE II  GIVEN D ATASE T  A 1 A 2 A 3 A 4 A 5 A 6 A 7 A 8 A9 1 0 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0    TABLE III  T RANSPOSITION OF D ATABASE WITH T RANSACTION ID  Item Id Transaction id String Coun t 11,14 2 2 2,4,6,7,13,15 6 3 4,6,10,11,14,15 6 4 2,3,6,13 4 5 1,3,5,8,10,11,12,14 8 6 1,5,7,12,13 5 7 3,5,7,10,11,13,14 7 8 1,2,9,12 4 97,15 2   Now Apply Algorithm  1  Pass 1 TABLE IV  F REQUENT ITEM SET  Item Id Transaction id String Coun t 2 2,4,6,7,13,15 6 3 4,6,10,11,14,15 6 4 2,3,6,13 4 5 1,3,5,8,10,11,12,14 8 6 1,5,7,12,13 5 7 3,5,7,10,11,13,14 7 8 1,2,9,12 4  L1 :={ 2, 3, 4, 5, 6, 7, 8  2  Pass 2  Generate candidate for k=2  C2:={{2,3},{2,4},{2,5},{2,6},{2,7},{2,8},{3,4},{3,5},{3,6 3,7},{3,8},{4,5},{4,6},{4,7},{4,8},{5,6},{5,7},{5,8 6, 7}, {6, 8}, {7, 8  After Apply DAPS Algorithm TABLE V  R ESULT OF DAPS  A LGORITHM  Item Id Transaction id String Coun t 2,3 4, 6,15 3 2,4 2, 6,13 3 3,5 10,11,14 3 3,7 10,11,14 3 5,6 1,5,12 3 5,7 3,5,10,11,14 5 6,7 5,7,13 3  L2:= {\(2,3\,\(2,4\,\(3,5\,\(3,7\,\(5,6\,\(5,7\, \(6,7     
500 


3  Pass 3  Generate Candidate for k: = 3  C3:={{2,3,4},{3,5,7},{5,6,7  After Apply DAPS Algorithm  Item Id Transaction id String Coun t 3,5,7 10,11,14 3 5,6,7 5 1  L3 :={\( 3, 5, 7 L: =L1UL2UL3 VII  C ONCLUSION  Determining frequent objects \(item sets, episodes sequential Patterns\ one of the most important fields of data mining. It is well known that the way candidates are defined has great effect on running time and memory need and this is the reason for the large number of algorithms We presented a  new research trend on frequent pattern mining is expecting transpose representation to relieve current methods from the traditional bottleneck, providing scalability to massive  Data sets and improving response time. In order to mine patterns in databases with more columns than rows, we proposed a complete framework for the transposition: we gave the item set in the transposed database of the transposition of many classical transaction ID. Then we gave a strategy to use this framework to mine all the itemset satisfying. We used dynamic approach which is better than tradition approach for finding longest common subsequence. We also presented a new research trend on filtering the database in each iteration. Our implementation can be further improved if parallelism is used to store reduced pattern Further investigations are needed to clear the possibilities of this technique A CKNOWLEDGMENT  We thank Sh. Jitendra Agarwal and Sh. K K Shrivastava for discussing and giving us advice on its implementation  R EFERENCES  1  B. Jeudy and F. Rioult, Database transposition for constrained closed pattern mining, in: Proceedings of Third International Workshop on Knowledge Discovery in Inductive Databases KDID\o-located with ECML/PKDD, 2004 2  R. Agrawal, R. Srikant, Fast algorithms for mining association rules,In Proceedings of the 20th International Conference on Very Large Data Bases, 1994, pp. 487–499 3  J. Han, Research challenges for data mining in science and engineering. In NGDM 2007 4  R. Agrawal, R. Srikant, Mining sequential patterns, In Proceedings of the 11th International Conference on Data Engineering, 1995 pp. 3 5  A fast APRIORI implementation Ferenc Bodon 004  Informatics Laboratory, Computer and Automation Research Institute Hungarian Academy of Sciences H-1111 Budapest L´agym´anyosi u. 11, Hungary 6  B. Goethals. Survey on frequent pattern mining. Technical report Helsinki Institute for Information Technology,03 7  R. Agrawal and R. Srikant. Fast algorithms for mining association rules The International Conference on Very Large Databases  pages 487–499, 1994 8  Improving Frequent Patterns Mining by LFP XU Yusheng, MA Zhixin, CHEN Xiaoyun, LI Lian School of Information Science and Engineering Lanzhou University Lanzhou, China, 730000 email:{xuyusheng, mazhx, chenxy, lil}@lzu.edu.cn Tharam S Dillon School of Information System Curtin University Perth Australia 9  Finding Longest Increasing and Common Subsequences in Streaming Data David Liben-Nowell_ y dln@theory.lcs.mit.edu Erik Vee_ z env@cs.washington.edu An Zhu_ x anzhu@cs.stanford.edu November 26, 2003   R. Agrawal, T. Imielinski, and A. Swami. Mining association rules between sets of items in large databases In Proc. of the ACM SIGMOD Conference on Management of Data pages 207–216 1993   R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, and A. I Verkamo. Fast discovery of association rules. In Advances in Knowledge Discovery and Data Mining pages 307–328, 1996   R. Agrawal and R. Srikant. Mining sequential patterns. In P. S. Yu and A. L. P. Chen, editors Proc. 11th Int. Conf. Data Engineering ICDE pages 3–14. IEEE Press, 6–10 1995   F. Bodon and L. R´onyai. Trie: an alternative data structure for data mining algorithms to appear in Computers and Mathematics with Applications 2003   S. Brin, R. Motwani, J. D. Ullman, and S. Tsur. Dynamic itemset counting and implication rules for market basket data SIGMOD Record \(ACM Special Interest Group on Management of Data\26\(2\55 1997   D. W.-L. Cheung, J. Han, V. Ng, and C. Y. Wong. Maintenance of discovered association rules in large databases: An incremental updating technique. In ICDE pages 106–114, 1996   J. Han, J. Pei, and Y. Yin. Mining frequent patterns without candidate generation. In W. Chen, J. Naughton, and P. A Bernstein, editors 2000 ACM SIGMOD Intl. Conference onManagement of Data pages 1–12. ACM Press, 05 2000   R. Agarwal, C. Aggarwal, and V. V. V. Prasad: A Tree Projection Algorithm for Generation of Frequent Itemsets Journal of Parallel and Distributed Computing special issue on high performance data mining\, \(to appear\, 2000   R. Agrawal, T. Imielinski, and R. Srikant: Mining association rules between sets of items in large databases. SIGMOD, May 1993   D. Burdick, M. Calimlim, J. Gehrke. MAFIA: A maximal frequent itemset algorithm for transactional databases. In Proc. of 17th Int’l Conf. on Data Engineering, pp. 443-452, 2001   Efficient Mining of Weighted Frequent Pattern Ove Data Streams Farhan Ahmed,Tanbeer 2009    
501 


association rule to achieve similar success The Asanctuary near a school The key is that wild life priori algorithm attempts to derive from the data sanctuary and school are not associated but association rules of the form If Temple then Pond correlated It indicates the strength and direction of a where Temple and Pond stand for simple codes or text linear relationship between two random variables values items or the conjunction of codes and text That is in contrast denoting any relationship not values e.g if City=Chandigarh and State=Punjab necessarily linear then Risk=Low and Cleanliness=High here the logical conjunction before the then would be the City 5.1 Correlation Rule Approach and the logical conjunction following the then would Let us consider Map Image Datasets as observations be the State of the association rule For each dataset we need to calculate the Euclidean Distance and the chi square analysis values Therefore 4.2 Execution Steps we define Pass 1 Calculation of the Support Value Chi square method Observed Expected First we calculate the support value by scanning all 1 variables to determine the unique codes or text values Expected items found in the variables selected for the analysis Euclidian Distance=U\(\(x2 x1  y2 yl 2 In this initial pass the relative frequencies with which the individual codes or text values occur in each Let us take a sample data from the Figure 5 transaction will also be computed The probability that Sample A Lahore is a city in Pakistan a transaction contains a particular code or text value is f\(tag_id,x,y,RGB  CP031,230,60,00110011 called Support the Support value is also computed in Sample B Thar Desert in India consecutive passes through the data as the joint f\(tag_id,x,y,RGB DI023,87,120,1 1110000 probability relative frequency of co-occurrence of Testset asimageobject\(X,269,65,00110010 pairs triplets etc of codes or text values Using equation 1  2 we get the values stored in Pass 2 Calculation of the Confidence Value and Figure 6 So therefore we 0.12  a support value that is greater than some userdefined minimum support value Figure 6 Image Mining Database Build  a correlation value that is greater than some minimum correlation value will be retained The above image data set if analyzed with a bar chart we observe that the proposed approach works 5 PERFORMANCE ANALYSIS effectively well for small and medium test set range PERFORMANCE ANALYSIS but fails to have impact when the range increases The basic idea behind correlation analysis iS that the beod3sapsprtste association rule does not capture many interesting dependencies among items for finding a wild life 2009 IEEE International Advance Computing Conference IACC 2009 1547 denote it being a city Correlation Value 5.2 Building Image Mining Database After the initial pass through the data all items with a For improved performance advantages of different support value less than some predefined minimum features can be combined Several points of same type support value will be remembered for subsequent represent different settings for the feature The passes through the data Specifically the conditional distances between the points indicate correlations of probabilities will be computed for all pairs of codes or features That is points that are close together stand text values that have support values greater than the highly correlated features and points farther away minimum support value This conditional probability denote features with different characteristics that an observation of image object that contains a Secondary information for average temperature  code or text value X also contains a code or text value population density are considered Y is called the Confidence Value In addition a Tag Id Avg Temp Population Euclidean Chicorrelation value for a pair of codes or text values X Density Value Square Y is computed for the support value for that pair 1001 370 190 12 V14ue divided by the square root of the product of the LA001 20C 00 3.6 0.34 support values for X and Y After the second pass D1023 49C 00 6 0.56 through the data those pairs of codes or text values CA033 24C 69 70 0.09 that have the following CP031 320 70 15 0.43  a confidence value that is greater than some user-defined minimum confidence value LA004 120 00 5 0.65 LA012 300C 00 20 


This approach uses the minimum feature of an image 4.5 1 to build an image mining database In the process of image analysis and information extraction correlation algorithms are used to partition the image into regions X 3 gau ae ae e o_ 2.5 _related to the relevant areas according to the application criteria The mining process uses the E 1.5 features extracted to discover relevant patterns Association helps in understanding the map based o.s objects better The Proposed Model is left to be 0.5 implemented using IBM QBE and work needs to be 0 done 5 10 15 20 25 30 35 No of Test Set  E REFERENCES  Chi-square Figure 7 Chi Square values Vs Euclidean Values 1 A.OlivaandA.Torralba Modelingtheshapeofthe scene:A holistic representation of the spatial envelope lnt.J Comput Vision 42\(3 2001 6 PROPOSED QUERY MODEL 2 Chum J Philbin J Sivic M Isard and A Zisserman Total recall Automatic query expansion with a generative feature model for object retrieval In Proc ICCV 2007 The Query Model is based on IBM  s Query 3 D Comaniciu andP Meer.Mean shift:Arobust approach Management Facility QMF and the QBE version that toward feature space analysis IEEE Trans Pattern Anal it supports Version 2 Release 4 This explains how a Mach Intell 24\(5 2002 tabular interface can provide the expressive power of 4 J Hays and A A Efros Scene completion using millions of photographs ACMTransactionson Graphics SIGGRAPH relational calculus We use the domain relational 2007 26\(3 2007 calculus DRC in particular A user writes queries by 5 J.Kosecka andW Zhang Video compass.n ECCV 02 creating example tables QBE uses domain variables Proceedings of the 7th European Conference on Computer as in the DRC to create example tables The domain Vision-PartIV pages 476-490 2002 of a variable is determined by the column in which it 6 M Bar.The proactive brain using analogies and associa-tions of a variable iS determined by the colunm in which it to generate predictions Trends in Cognitive Sciences 11\(7 appears and variable symbols are prefixed with 2007 underscore to distinguish them from constants 7 N Snavely S M Seitz and R Szeliski Photo tourism exConstants including strings appear unquoted in ploring photo collections in 3d SIGGRAPH 25\(3 2006 contrast to SQL The fields that should appear in the 8 W Thompson,C.Valiquette,B Bennett,andK Sutherland contrast to SQL The fields that should appear in the Geometric reasoning for map-based localization Spatial answer are specified by using the command P which Cognition and Computation 1\(3 1999 stands for print The fields containing this command are analogous to the target-list in the SELECT clause of an SQL query It contains Tag-id average temperature Population density Euclidean distance Chi-square Values Where P  stands for Print _X,_Y,_Z  are the variables 0.14  constant that has a match Tag_id Avg.Temp Population ED Chi Density Square Method P._X P.IY P.-Z 0.14 Figure 8 Sample Query Based on QBE QBE is especially suited for queries that are not too complex and can be expressed in terms of a few tables 7 CONCLUSION  FUTURE WORK 11548 2009 IEEE Internactionalz Advance Computing Conference IACC 2009 


Acknowledgements Annals of Family Medicine Preventive Medicine Circulation Infrastruttura tecnologica del fascicolo sanitario elettronico CORE USENIX Symposium on Internet Technologies and Systems w.r.t Academic Medicine different sizes of  in order to have a comparable number of frequent itemsets mined by both we suitably set We presented a recommendation engine based on the combination of clustering and association rules to generate a predictive disease model The system uses the past medical history of patients to determine the diseases an individual could incur in the future Experimental results showed that the technique can be a viable approach to disease prediction Future works aims to compare our method with other proposals in literature and to perform a more extensive evaluation on large medical history data sets  R Moone y A Strehk J Ghosh Impact of similarity measures on web-page clustering In Proc of ACM Workshop on Web Information and Data Managment WIDM 32501 PLoS Computational Biology Data Mining and Knowledge Discovery Proc of the Int Conf on Information Technology in Bio and Medcial Informatics ITBAM\32510 Pattern Recognition A statistical Approach Proc of the 5th Berkeley Symposium vol 1 Proc of Principles of Data Mining and Knowledge Discovery PKDD\32502  pages 175\320187 2002  C A Hidalgo N Blumm A L Barab 253 asi and N A Christakis A dynamic network approach for the study of human phenotypes FPV FPV Introduction to Data Mining New Phytologist Proc of AAAI workshop on AI for Web Search T train Proc of the ACM Int Conf on Information and Knowledge Management CIKM\32508  Proc of ACM SIGMOD Conf on Management of Data SIGMOD\32593 and 0.01 for to 0.1 for  funded by Technological Innovation Department Presidenza del Consiglio dei Ministri Italy  pages 58\32064 2000  R Agra w al T  Imielinski and A N Sw ami Mining association rules between sets of items in large databases In  pages 207\320216 1993  D A Da vis N V  Cha wla N A Christakis and A L Barab 253 asi Time to CARE a collaborative engine for practical disease prediction  20:388\320415 2010  P  A De vijv er and J Kittler   Prentice-Hall London 1982  B Star\336eld et al Comodbidity Implications for the importance of primary care in 325case\325 managment  1\(1 2003  D A Da vis et al Predicting indi vidual disease risk based on medical history In  pages 769\320778 2008  I Lo wenste yn et al Can computerized risk pro\336les help patients improve their coronary risk the results of the coronary health assessment study  27\(5 1998  P  W  F  W ilson et al Prediction of coronary heart disease using risk factor categories  97:1837\3201847 1998  F  F olino C Pizzuti and M V entura A comorbidity network approach to predict disease risk In  pages 102\320109 2010  F  Giannotti C Gozzi and G Manco Clustering transactional data In  5\(4 2009  P  Jaccard The distrib ution of the 337ora of the alpine zone  11:37\32050 1912  J MacQueen Some methods for classi\336cation and analysis of multivariate observations In  pages 281\320297 1967  B Mobasher  H Dai T  Luo and M Nakag a w a Effective personalization based on association rule discovery from web usage data In  pages 9\32015 2001  J E Pitk o w and P  Pirolli Mining longest repeating subsequences to predict world wide web sur\336ng In  1999  U Shardanand and P  Maes Social informat ion 336ltering algorithms for automating word of mouth In  pages 210\320217 1995  R Sn yderman Prospecti v e medicine The ne xt health care transformation  78\(11 2003  K Steinhaeuser and N V  Cha wla A netw ork-based approach to understanding and predicting diseases In  2009  P  T an M Steinbach and V  K umar   Pearson International Edition 2006 12 Proc of ACM Conf on Human Factors in Computing Systems CHI\32595 Social Computing and Behavioral Modeling CORE This work has been partially supported by the project  Figure 6 clearly shows the better overall performances of  This de\336nitively proves that the specialization of the prediction models by means of clustering is meaningful 5 Conclusions References 


 Han J W a ng J Lu Y  and Tzv etk o v P  Mining Top-K Frequent Closed Patterns without Minimum Support In Proceedings of the IEEE international Conference on Data Mining 2002  L iu B Zhao K Benkler J a nd Xiao W Rule Interestingness Analysis Using OLAP Operations In Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining Philadelphia PA 2006  Meininger J C Liehr P  Mueller W H Chan W Smith G L and Portman R J Stress-Induced Alterations of Blood Pressure and 24 h Ambulatory Blood Pressure in Adolescents Blood Pressure Monitoring 4\(3-4 1999  Meininger J C Liehr P  Chan W Smith G and Mueller W H Developmental Gender and Ethnic Group Di\002erences in Moods and Ambulatory Blood Pressure in Adolescents Annals of Behavioral Medicine a Publication of the Society of Behavioral Medicine 28 1 10-9  P a dmanabhan B a nd T uzhilin A  A BeliefDriven Method for Discovering Unexpected Patterns In Proceedings of the 4th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining 1998  P admanabhan B and T uzhilin A Small is Beautiful Discovering the Minimal Set of Unexpected Patterns In Proceedings of the 6th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining Boston Massachusetts 2000  Pipino L  Lee Y a nd W a ng R Data Qualit y Assessment Communications of the ACM April 2002  Quillian M R Seman tic Memory  Seman tic Information Processing M Minsky ed MIT Press 1968  Sahar S On Incorp o rating Sub jectiv e In terestingness Into the Mining Process In Proceedings of the IEEE International Conference on Data Mining 2002  T a n P  N Kumar V  and Sriv a sta v a J Selecting the Right Interestingness Measure for Association Patterns In Proceedings of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining July 2002  Uni\223ed Medical Language System 2007 a v ailable at www.nlm.nih.gov/research/umls  W ang K Jiang Y and Lakshmanan L V.S Mining Unexpected Rules by Pushing User Dynamics In Proceedings of the 9th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining Washington D.C August 2003  W ebb G I Disco v ering Signi\223can t Rules In Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining Philadelphia PA,2006  Witten I H a nd F rank E Data Mining Practical Machine Learning Tools and Techniques 2nd edition Morgan Kaufmann San Francisco 2005  Xin D Cheng H  Y a n X a nd Han J Extracting Redundancy-Aware Top-k Patterns In Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining Philadelphia PA USA 2006 8 BBB 


              


   


                        






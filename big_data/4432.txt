2009 International Conference on Electrical Engineering and Informatics 5-7 August 2009, Selangor, Malaysia 978-1-4244-4913-2/09/$25.00 ©2009 IEEE AI-08 36  Scalable and Efficient Method for Mining Association Rules Wael A. AlZoubi, Azuraliza Abu Bakar, Khairuddin Omar System Management and Science Departme nt, National University of Malaysia Faculty of Information Science And Technology, Universiti Kebangsaan Malaysia, 43600 Bangi, Selangor 
Malaysia alzoubi_wael@yahoo.com  aab@ftsm.ukm.my  ko@ftsm.ukm.my  ABSTRACT Association rules mining \(ARM\gorithms have been extensively researched in the last decade. Therefore, numerous algorithms were proposed to discover frequent itemsets and then mine association rules. This paper will present an efficient ARM algorithm by proposing a new technique to generate association 
rules from a huge set of items, which depends on the concepts of clustering and graph data structure, this new algorithm will be named clustering and graph-based rule mining \(CGAR\. The CGAR method is to create a cluster table by scanning the database only once, and then clustering the transactions into clusters according to their length. The frequent 1-itemsets will be extracted directly by scanning the cluster table. To obtain frequent k 
itemsets, where k 2 we build directed graphs for each cluster in the case of very huge amount of transactions. This approach reduces main memory requirement since it considers only a small cluster at a time and hence it is scalable for any large size of the database. Experiments show that our algorithm outperforms other rule mining algorithms 1  
INTRODUCTION Data mining is a tool that supports research and allows new assertions to be made by disclosing previously undisclosed details in large amounts of data [11  On e o f th e m o st challenges in database mining is developing fast and efficient algorithms that can deal with large volume of data because most mining algorithms perform computation over the entire database and mostly the databases are very large Association rules mining is one of the most well studied 
data mining tasks. It discovers re lationships among attributes in different types of databases, producing if-then statements concerning attribute-values [2 w a s f i rstly in tro d u ced in  1  to discover association rules between items over basket data, an association rule describes the associations among items in which when some items are purchased in a transaction, the others are purchased, too. In order to find association rules, we need to discover all large or frequent itemsets from a large 
database of customer transactions. A large itemset is a set of items which appear often enough within the same transactions In this paper, we introduce an algorithm called CGAR which is fundamentally different from all the previous algorithms in the following points i  It reads the database of transaction only once to generate frequent 1-itemsets ii  It is scalable with all types of databases 
regardless to their size iii  It is as efficient as it requires less memory and CPU time to generate strong rules from the transaction database iv  It is easy to implement as it uses simple cluster table and a robust graph data structure 


  37  The rest of the paper is organized as follows. In Section 2, we provide a general definition of the problem of rule mining, in section 3, a concise explanation of rule mining algorithms and the relative researches of association rules are given, and then, in Section 4, we offer our algorithm, which we have called CGAR, and give an example of CGAR in Section 5. Section 6 contains the design of our experiments and the results returned; finally, in Section 7, we present our conclusions 2  Association Rule Problem Association rules, first introduced in 1993, are used to identify relationships among a set of items in a database, it was used in the sale transaction databases domain, and so there should be a set of m distinct items I = {I 1 I 2 I m  and a database of  transactions D where each transaction T has a unique identifier TID, and contains a set of items such that T  I An association rule is an implication of the form X Y, where X and Y are subsets of I, and they are disjoint that is, X  Y  X and Y are sets of items called itemsets. The rule X Y holds in the database D with confidence c if c of transactions in D that contain X also contain Y The rule X Y has support s in the transaction set D if s of transactions in D contain X  Y Given the database D the problem of mining association rules involves the generation of all association rules that have support and confidence greater than or equal to the user-specified minimum support and minimum confidence  3  Background Previous studies in data mining have presented efficient algorithms for discovering association rules. But the main problem in the first algorithms is the need to do multiple passes over the datasets to generate frequent itemsets. The Apriori association rule algorithm proposed by Agrawal and Srikant dis c ov er m ean in g f u l item s ets an d bu ild association rules within large databases, but a large number of the candidate itemsets are generated from single itemsets and this method also needs to perform contrasts against the whole database, level by level, in th e process of creating association rules. Performance is severely affected, as the database is repeatedly scanned to contrast each candidate itemset with the database. After Agrawal et al ed t h e A p ri ori  association rule, most association rules researchers have used Apriori-like candidate generated approaches, all of these methods focus on reducing the number of candidate itemsets and therefore reducing the number of database scans Different strategies were developed after that to improve the process of generation association rules, as in FPGrowth [8 h ich o u tp erf o rm s all can d i d a tes etg en eratio n and- test algorithms as it mines frequent patterns without candidate generation, but it still have problems in the case of no common prefixes within the data items. Another technique is the sampling algorithm which reduces the number of database scans to a single scan, but still wastes considerable time on candidate itemsets [5  th ird alg o rith m is th e d y n a m i c itemset count \(DIC\orithm o r f i n d in g larg e item s ets   which uses fewer passes over the data than classic algorithms and yet uses fewer candidate itemsets than methods based on sampling [5  ad d itio n  th e co lu m n w ise ap rio r i alg o rith m   an d th e treebas e d as s o ciation ru le alg o rith m 4 transformed the storage structure of the data, to reduce the time needed for database scans, improving overall efficiency Finally, the partition algorithm [7 f u rth e r im p r o v e efficiency, it does so by effectively reducing the number of database scans, however, considerable time is still wasted 


  38  scanning infrequent candidate itemsets. Pork et al. proposed an effective algorithm DHP \(direct hashing and pruning\ [3 fo r  the initial candidate set generation. This method efficiently controls the number of candidate 2-itemsets, pruning the size of database 4  Clustering and Graph-based Association Rule \(CGAR Although, the Cluster-based Association Rule \(CBAR algorithm [1 u tp erf o rm s A p rio r i alg o rith m as it scan s th e database only once, but the opportunity to enhance clusterbased algorithms still available by providing an efficient graph data structure to simplify the process of generating frequent kitemsets, where k 2  In this paper, we present a new algorithm called clustering and graph-based association rule \(CGAR\, for efficient association rules mining, which overcome the drawbacks of the previous algorithms The items should be given sequential numbers to simplify the process of building the graph; this must be taken in consideration as an important action before applying our proposed algorithm. CGAR scans the database of transactions only once to build the clustering table as a two-dimensional array where the columns represent items and the rows represent transactions’ IDs \(TIDs\. The contents of the table consist of 0 or 1 to indicate the absence or presence of an item in a transaction, respectively. After that, the bit vectors for each item will be ready and it is an easy process to determine the frequent 1 itemsets by counting the number of 1 s in each transaction, if it isn’t less than the minimum support threshold, it is considered as a frequent itemset and then be used in building the graph, otherwise, it will be discarded from further discussion as it is infrequent item. The second phase starts by reordering frequent 1-itemsets by providing each one with a sequential number to facilitate the process of constructing the graph, which is constructed by doing logical and operation between each pair of consecutive frequent 1itemsets item i item j i < j if the number of 1 s in the result is greater than or equal to minimum support threshold, a directed edge is drawn from item i to item j this operation is repeated for all frequent 1-itemset s. As the graph is completed the set of frequent 2-itemsets are generated, and it will be direct from the graph traversing to generate frequent k-itemsets, such as k 3 CGAR will deal with only one type of ARs, that is Boolean ARs 5  An Example of CGAR We provide an example to give an extra explanation to our proposed algorithm; the minimum support threshold is 45%. There are 18 transactions and 5 different items in the database. We assume – as in most of sequential rule mining algorithms – that the items are in lexicographical order. A transaction database example is shown in Table 1; we represent the items by letters rather than numbers to deal some worst cases, where the numbering step is required TID Items TID Items TID Items T 1  A, B, C T 7 C, E T 13  A, B, C, E T 2 B, C T 8  B, C, E T 14 C, D T 3 A, E T 9  A, B, C, D T 15  B, C, D T 4  A, C, D, E T 10 A, D T 16  A, D, E T 5 A, C T 11  A, B, D T 17  B, D, E T 6  A, C, E T 12 C, E T 18  A, C, D Table 1: an example of database of transactions 


  39  The first step, as we said, is scanning the database to determine the length of each transaction, the length means the number of items in a transaction, and at the same time assigning numbers to the items, item A will be given the number 1, item B the number 2 and so on. This will help us in both constructing the cluster table and building the graph, after that we don’t need to rescan the database, as we will move to deal with the clustering table that can be easily resided in the main memory In our example, the maximum transaction length is 4 and so, there will be at most four clusters. Since there are no transactions of length 1, the total number of clusters is 3 as shown in Table 2, the table contents are 0 s or 1 s to denote absence or existence of an item in a transaction, after constructing the table, each colu mn is the bit vector for the corresponding item, and so, no need to make further contrasts with the cluster table. These bit vectors are used in building the graph and determining the frequent 1-itemsets The bit vectors for the items are BV 1 011010011010101111 BV 2 100000010111010011 BV 3 101101111101001111 BV 4 000010100011111110 BV 5 010101001100110101   By counting the number of 1 s in each bit vector, we determine the support for each candidate itemset of length 1, as the following: support \({1}\55%, support \({2 support \({3}\, support \({4}\, and support \({5 0.45.Thus the frequent 1-itemsets are: {{1}, {3}, {4}, {5}} as their supports are not less than 45 


  40  The second step is started by making logical and   between each pair of frequent 1-itemsets, as we mentioned earlier in this paper, and by assigning 30% as a new value to the minimum support threshold, we found that the frequent 2itemsets will be: {{1, 3}, {1, 4}, {3, 5}}, and the graph is constructed by drawing an edge between each pair of frequent items, as in Figure 1   Figure 1: a simple directed graph to display frequent k-itemsets k 2  To determine frequent 3-itemsets, we traverse the graph as if there is a path among three nodes {i , j} and {j, k then the set {i, j, k} will be frequent 3-itemset. Here, in this example, {{1, 3, 5}} is the only frequent 3-itemsets. As there are no extra edges, the algorithm terminates In the standard situation, as the database contains hundreds of thousands of transactions and different items constructing only one graph is not practical, and so we suggested to construct different graphs for each cluster and find from this graph all frequent itemsets, then combine the subsets of frequent itemsets together to get the whole set of frequent itemsets, and this technique is scalable with all transactions databases of different sizes 6  Experimental Results To assess the efficiency of the proposed technique, we have implemented the CGAR, along with Apriori algorithm using Java programming language on a Pentium IV 1700 MHz PC with 512MB of available physical memory. The test databases are the standard datasets available to evaluate rule mining algorithms, they are: T10I4D100K and T40I10D100K We execute both algorithms, Apriori and CGAR, at various values of minimum support thresholds, as the number of frequent itemsets generated inversely proportional with the value of the minimum support. Figure 2 displays the average execution time in seconds to generate all frequent itemsets using CGAR and Apriori algorithm        Figure 2: a comparison between Apriori and CGAR The experimental results in Figure 2 show that the CGAR algorithm has better performance than Apriori in terms of the execution time. When there is an increase in the number and size of frequent itemsets discovered, i.e. reduction in the minimum support threshold, the performance gap between these algorithms is displayed in greater clearance 7  Conclusion In this paper we propose a new framework, which is scalable and efficient.  The entire database is divided into 1 3 5 4 Time Seconds  Minimum Support 


  41  partitions of variable sizes, each partition will be called a cluster.  Each cluster is consid ered one at a time by loading the first cluster into memory and calculating large itemsets and the corresponding support counts. Then the second cluster is considered similarly and the cumulative support count is calculated for the cumulative large itemsets. This process is continued for the entire set of clusters and finally we have the whole large itemsets and the corresponding cumulative support counts.  This approach reduces main memory requirement since it considers only a small cluster at a time and hence it is scalable for any large size of the database Experiments using two of the standard transaction databases available on the Internet, T10I4D100K and T40I10D100K, show that CGAR outperforms Apriori, a familiar and widely used association rule mining algorithm When there is a reduction in the value of the minimum support threshold, the performance gap between the algorithms becomes more evident References 1 uhJ i u a n T s ay J i un nY a n n Ch ia ng C B A R  an e f f i cie n t m e t h o d f o r  mining association rules, Knowledge-Based Systems 18 \(2005\105 2 R A g r a w a l  T   I m il ie ns ki, A  S w am i Mi ni ng as s o cia t io n r u l e s be tw e e n s e ts  of items in large databases, Proceedings of the ACM SIGMOD International Conference on Management of Data, Washington, DC, 1993 pp. 207–216 3  A y s e Oz el and H  A l tay  G venir  A n A l g o r ithm f o r Mi ni ng A s s o ciati o n  Rules Using Perfect Hashing and Database Pruning, \(2000  4  A g ra w a l R  S r ik ant   M i ni n g s e q u e nt ia l pa tt ern s  P r oc eed in gs of th e 11 th  International Conference on Data Engineering \(ICDE\, 1995 5 F  B e rz a l  J C  C u b e ro N M a rin   J M  Se rra n o  T B A R a n e ffi c i e n t me th od for association rule mining in relational databases, Elserier Data and Knowledge, Engineering 37 \(2001\ 47–64 6   Br i n R  Mo tw an i C. S i l v e r s t e i n, Be y o nd m a r k e t  bas k e t s  g e ne r a l i z i ng  association rules to correlations, ACM SIGMOD Conference on Management of Data, Tuscon, Arizona, 1997 pp. 265–276 7 s ho k S a v a s e r e E d w a r d O m ie ci ns k i a n d S h am ka n t N a v a t h e  A n E f f i cie n t  Algorithm for Mining Association Rules in large databases. 1995 8 a n, J P e i, J Y i n  Y  Min i ng f r e que nt P a tte r ns w i tho u t Ca nd i d a t e  Generation. In: ACM-SIGMOD, Dallas \(2000 9 h o w J ane Y e n an d A r be e  L  P  Che n A G r aphB a s e d A ppr o a c h f o r  Discovering Various Types of Association Rules, IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, VOL. 13, NO. 5 SEPTEMBER/OCTOBER 2001 10 D  W  C h e u ng J. H a n  V  T   N g A  W  F u Y  F u A f a st dis t r i bu te d  algorithm for mining association rules, Proceedings of International Conference on PDIS’96, Miami Beach, Florida, USA, 1996 11  Be n F r an kl in G e ne al og ical D a t a  Mi ni ng  2 0 0 6    


 F  To check the validity of association rules  E quatio n  1  is use d  as  it is done i n  th e  last column of  Figur e  7   G  Select one  of th e  rules which have Improvement  value more than   1     H  In case if there is another job asking to get the files  and the s e files are available in the same sites then  choose another rule to serve the new request  Otherwise  apply  Aprior i  algorithm for recent STTs  of  new replicas sites    VI I   I NTERPRETING THE  R ESULT S    This section means to explain how the association  rul e s work better than the traditional and random methods  As it is shown in  Figure 7 after applying  Aprior i  algorithm  we get  602  different rules which can be used to select the  best combination of replica sites   Let us explain Figure 7  in details    Rule #1: if Site\(s S 4  S 7  are selected then this implies  that site\(s S 3  can also be selected at the same time. This  rule has 100% confidence    In other words, it means if site  S 4   and  S 7  are selected to  work together to transfer the requested files, t h en this  implies site\(s  S 3  can also be selected to share the work at  the same time. This rule has confidence  100  This  particular rule has  confidence  of  100  meaning that  S 4  S 7   and  S 3  can be selected as a best set of replicas by  Replica  Manage r  to ge t  requested files. To compute the correlation  of this rule and see how far it is better than choosing the site  randomly, we use an Improvement equation     indicates that it has support of  26  transactions, meaning that in transaction  Single Trip  Time  Table  there are  2 6  concurrent uncongested trips of  S 4  S 7   i.e. these sites have similar network conditions in particular  time      indicates the total number of transactions  involving uncongested trips of  S 3   in  Rule 1  is equal to  174    This is a piece of a side information; it is not involved  in calculating the confidence or support for the rule itself       is the number of transactions where   S 4   S 7 as well as   S 3 has uncongested trips. In  Rule 1  it is equal  to  2 6       or   indicates how much  more likely we are to encounter  S 4  and  S 6  transaction if we  consider just those transactions where  S 3  S 5 and  S 8  have  uncongested trips. As compared to the entire population of  the transactions, it's t h e  confidenc e  divided by  support \(c   where the latter is expressed as a percentage   For  Rule 1 the  confidenc e is  100   support \(c  in  percentage   174/194\*100 = 89.6 9 So, th e    Lift ratio = 100/89.69.1 = 1.1   As it is clearly shown in  Figure 7  some r u les with  an improvement value less than one means this is an  unreliable rule. Whereas the rule with a value more than one  means this rule is better than random replica selection with  number of time equal to improvement value as it is shown in  Figure 8                   When improvement value is more than 1 it is better to use  EST to select replica sites, because it selects the sites able to  work simultaneously    I n  Figure  9  we sho w  the  comparison between EST and  traditional model using highest bandwidth a s  a criterion to  select the best replica. As we can observe our technique has  a better performance most of the times because it selects the  sites which have the stable links. In traditional method the  site which has the highest bandwidth does not always me a n  to be the best because sometimes this highest bandwidth  link can be congeste d   Let us declare more by the following  scenario  o f  Figure 1 0 suppose   S 0   be the computing site  and let   S 1  S 3   S 1 4   be replica sites  Red stars referring to  congested router s   Using traditional selection method the  file will be got from S14 since it has less number of Hops  routers\ and highest and also has highest bandwidth link         Figure 8. Improvement ratio for different rule s  Figure 9. Traditional selection strategy and ES T    
193 


               Using  ES T the replica   S 3    is selected as a best replica  because the link b etween  C S  and  R S  is uncongested     VII I   C ONCLUSIO N  In this paper we presented a dynamic replica  selection strategy that aims to adapt at ru n time its criteria to  flexible QoS binding contracts specified by the service  provider and/or the client. The adapta b ility feature  addressed by our replica selection strategy is inferred from  the observation that the basic metrics, which influence the  QoS that the user perceives when accessing a replica  depend directly on the application being replicated and on  the cli e nts\222 preferences. To reach this objective that, we  used   the concept of association rules of data mining  approach to the most stable links sites in order to reduce the  searching space the response time and network resources  consumed    A CKNOWLEDGEMENT S  Au t hors wish to express their sincere thanks to  Prof. Arun Agarwal, from GridLabs Department of  Computer and Information Sciences, University of  Hyderabad, India for providing all the infrastructural and  computational support required to carry out this work  His  academic suggestions to improve the quality of the work are  also highly appreciated and acknowledged   R EFERENCE S     M  Rashedur Rahma n   Ken Barke r   Reda Alhaj j    Replica  selection in grid environment:a dat a mining approac h    Distributed systems and grid computing \(DSGC\,pp: 695  226  700  2005    J. Gwertzman and M. Seltzer    The case for geographical  push  cashing  In Proceeding of the 5th Workshop on Hot ZTopic in  Operating Systems, 1995     R. Kavitha, I. Foster   Design and evaluation of replication  strategies for a high performance data gri d  in, Proceedings of  Computing and High Energy and, Nuclear P h ysics, 2001   S. Vazhkudai, J. Schopf, I. Foster   Predicting the performance of  wid e area data transfer s  in: 16th International PDPS, 2002   S. Vazhkudai, J. Schopf   Using regression techniques to predict  large data transfer s  in: Computing: Infrastru c ture and  Applications, The International Journal of High Performance  Computing Applications, IJHPCA , August, 2003   A. Abbas, Grid Computing    A Practical Guide to Technology  and  A PPLICATION S    2006   http://goc.pragm a grid.net/wiki/index.php/UoHy d   S. Vazhkudai, S Tuecke, I. Foster   Replica selection in the  globus data gri d  in: First IEEE/ACM International Conference  on Cluster Computing and the Grid, CCGrid 2001   J. Guyton and M. Schwartz   L o cating nearby copies of replicated  internet server s    In Proceeding of ACM SIGCOM M 222  95, 1995   A. Tirumala, J. Ferguson, Iperf 1.2   The TCP/UDP Bandwidth  Measurement Tool, 2002   R. Wolski, Dynamically forecasting network performance using  the Network Weat h er Service, Cluster Computing \(1998   Yunhong Gu, Robert L. Grossman   UDT: UD P based data  transfer for hig h speed wide area network s  Computer  Networks, Volume 51, Issue 7, 16 May  2007, Pages 1777 1799  Elsevier   R.M. Rahman, K. Barker, R. Alhajj   Predicting the performance  of GridFTP transfer s  in: Proceedings of IEEE Symposium of  Parallel and Distributed Systems, 2004, New Mexico, USA, p  238a   J. F. Kurose, K.W. Ross   Compute r  Networking A To p Down  Approach Featuring the Interne t 3rd edition   S. Venugopal, . R. Buyya,"The Gridbus Toolkit for Service  Oriented Grid and Utility Computing: An Overview and Status  Report"2004   R   Agrawal  T  Imielinski  A.Swami    Mining associatio n  rules  between sets of items in large database s  In: Proc. ACM  SIGMOD Intl. Conf. Management Data, 199 3  R  M Rahman, K Barker and R Alhajj   Replica selection  strategies in data gri d    Jou r nal of Parallel and Distributed  Computin g   Volume 68, Issue 1 2 Pages 156 1 1574, December  2008   A. Jaradat, R. Salleh and A. Abid   Imitating K Means to  Enhance Data Selectio n  Journal of Applied Sciences 9 \(19  356 9 3574, 2009, ISSN 181 2 5654, Asian Ne t work for Scientific  Informatio n 2009   S. Venugopal, . R. Buyya, K. Ramamohanarao, "A taxonomy of  Data Grids for distributed data sharing, management, and  processing". ACM Comput. Surv. 38, 1 \(Jun. 2006  AC M   New  York, NY, US A  http://www.resample.com/xlminer/help/Index.ht m  A   K Pujar i    Data mining technique s    Hyderabad : Universities  Press, 2002   G. Williams, M. Hegland and S. Roberts   A Data Mining  Tutoria l  IASTED International Conference on Parallel and  Distributed Computing and Networks P DCN\22298\ 14 December  199 8   T  Ceryen, and M. Kevin, 2005   Performance characterization of  decentralized algorithms for replica selection in dstributed object  system s  Proceedngs of 5th International Workshop on Software  and Performance, July 11  14, Palm a de Mallorca, Spain, pp  25 7 262    F  Corina, and M. Mesaac, 2003  A scalable replica selection  strategy based on flexible contract s  Proceedings of the 3rd  IEEE Workshop on Internet Applications, June 2 3 24, IEEE  Computer Society Washington, DC, USA p p: 9 5 99   R. M. almuttari, R. Wankar, A. Negi, C.R. Rao   Intelligent  Replica Selection Strategy for Data Gri d    In proceeding of the  1 0 t h  International conference on Parallel an d  Distributed  Proceedin g  Techniques and Applications  IEEE Computer  Society W a shington, DC  WorldComp2010, GCA2010   LasVega s   USA  Volume3  pp: 9 5 100  July 1 2 1 5 201 0   Cisco Distributed Director  http://www.cisco.com/warp/public/cc/pd/cxsr/dd/index.shtm l  M   Sayal, Y. Breitbart, P. Scheuermann, R  Vingralek   Selection  algorithms for replicated web server s  In Proceeding of the  Workshop on Internet Server Performance,1998   E. Zegura, M. Ammar, Z. Fei, and S. Bhattacharjee   Applicatio n layer anycasting: a se r ver selection architecture and  use in a replicated web servic e  IEEE/ACM Transactions on  Networking, vol. 8, no. 4, pp. 45 5 226 466, Aug. 2000     Figur e  10   Data Grid and their associated network geometr y   
194 


Application of Chaotic Particle Swarm Optimization Algorithm in Chinese Documents Classification 763 Dekun Tan Qualitative Simulation Based on Ranked Hyperreals 767 Shusaku Tsumoto Association Action Rules and Action Paths Triggered by Meta-actions 772 Angelina A. Tzacheva and Zbigniew W. Ras Research and Prediction on Nonlinear Network Flow of Mobile Short Message Based on Neural Network 777 Nianhong Wan, Jiyi Wang, and Xuerong Wang Pattern Matching with Flexible Wildcards and Recurring Characters 782 Haiping Wang, Fei Xie, Xuegang Hu, Peipei Li, and Xindong Wu Supplier Selection Based on Rough Sets and Analytic Hierarchy Process 787 Lei Wang, Jun Ye, and Tianrui Li The Covering Upper Approximation by Subcovering 791 Shiping Wang, William Zhu, and Peiyong Zhu Stochastic Synchronization of Non-identical Genetic Networks with Time Delay 794 Zhengxia Wang and Guodong Liu An Extensible Workflow Modeling Model Based on Ontology 798 Zhenwu Wang Interval Type-2 Fuzzy PI Controllers: Why They are More Robust 802 Dongrui Wu and Woei Wan Tan Improved K-Modes Clustering Method Based on Chi-square Statistics 808 Runxiu Wu Decision Rule Acquisition Algorithm Based on Association-Characteristic Information Granular Computing 812 JianFeng Xu, Lan Liu, GuangZuo Zheng, and Yao Zhang Constructing a Fast Algorithm for Multi-label Classification with Support Vector Data Description 817 Jianhua Xu Knowledge Operations in Neighborhood System 822 Xibei Yang and Tsau Young Lin An Evaluation Method Based on Combinatorial Judgement Matrix 826 Jun Ye and Lei Wang Generating Algorithm of Approximate Decision Rules and its Applications 830 Wang Yun and Wu-Zhi Qiang Parameter Selection of Support Vector Regression Based on Particle Swarm Optimization 834 Hu Zhang, Min Wang, and Xin-han Huang T-type Pseudo-BCI Algebras and T-type Pseudo-BCI Filters 839 Xiaohong Zhang, Yinfeng Lu, and Xiaoyan Mao A Vehicle License Plate Recognition Method Based on Neural Network 845 Xing-Wang Zhang, Xian-gui Liu, and Jia Zhao Author Index 849 
xiii 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        






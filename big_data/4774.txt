  
  


          


        


          


Input RFMP-tree RT       Output a complete set of RFM-patterns Method Call RFMP-growth\(RFMP-tree null  Procedure RFMP-growth  RT  call tree-growth  RT  null and get all RFT-patterns scan DB once to get Mscores of RFT-patterns output all RFM-patterns with their Mscores satisfying    Procedure tree-growth\(RT   foreach item a i in RFM-header do let a i s node link is b i  if b i  null then get b i s Rscore  Fscore and Tta by b i s node link structure if b i  Rscore   b i  Fscore  and b i  Tta  then output b i  generate pattern  a i   where Rscore  Fscore and   Tta are equal to a i s Rscore  Frscore and Tta recorded in RFMheader respectively construct  s conditional pattern base and  s conditional RFMP tree RT   if RT    then call tree-growth  RT      Figure 6 The RFMP-growth algorithm RFMP-tree can be constructed using the same steps of constructing RFMP-tree. We can perform the mining procedure recursively with the conditional RFMP-tree and get all of the RFT-patterns Here we give an example to show the tree growth procedure with considering only patterns with item D. Initially the input itemset  is null that we can traverse the RFMP-tree and generate all of the 1-patterns, including pattern {D By traversing the node-link structure, we can collect all the information of pattern {D}, and pattern {D} will be outputted since it satisfies the thresholds. The conditional pattern base of each 1-pattern is then constructed recursively. In this example we only show item D  s conditional pattern base in Fig. 7 While the complete pattern base of item D is constructed, we then construct Dês conditional RFMP tree based on its conditional pattern base, as shown in Fig. 8\(a\ In the conditional tree construction step, item B and C will be removed from conditional RFMP-tree since they do not satisfy the thresholds as shown in Fig. 8\(b\. After the tree growth complete, we can have all RFT-patterns which contain item D The RFT-patterns outputted from D  s conditional RFMP-tree are {D}, {DE}, {AD}, and {ADE To find out all of the RFM-patterns from RFT-patterns, we use the hash-tree structure, which is a widely used tree structure in Apriori-based algorithms, to store the RFT-patterns After inserting all RFT-patterns in the hash-tree, we scan the database and traverse the hash-tree for each transaction to check if the RFT-pattern is contained in the transaction. Each RFT-pattern  s Mscore value will be collected after the scan item conditional pattern base Conditional RFMP-tree D A: 0.456, 1, 236\\(E: 0.456, 1 236\\(B: 0.456, 1, 236 C: 0.778, 1 165 A: 1, 1, 135\\(E: 1, 1, 135 E: 0.778, 1, 165\}|D A: 1, 1 135\}|D Figure 7 Item Dês conditional pattern base and conditional RFMP tree  a\                                         \(b Figure 8 Item D s conditional RFMP-tree completes. For item D  s RFT-patterns as example, pattern {D and {AD} will be pruned since Mscore D 90   Mscore AD 65  Therefore, the RFM-patterns containing item D are {DE and {ADE V E XPERIMENTAL E VALUATION In this section, we perform a simulation study to empirically compare the proposed algorithm with traditional association rule method \(FP-growth\ All the algorithms are implemented in Java language and tested on a DualCore Pentium E2180-2.0 GHz Windows XP system with 2 gigabyte of main memory. The three synthetic datasets are generated by IBM Quest Data Generator. Table I lists the parameters used in the data generation algorithm and Table II shows the parameter settings in our experiments. Since the synthetic datasets does not contain purchase quantity, item price, and transaction time we generate all necessary information in the following way The quantity of each item in the transaction is randomly generated from 1 to 10. Each item  s price is randomly generated in log-normal distribution, ranging from 1 to 50,000 The transaction time interval is drawn from a uniform distribution raging from 1 to 24, i.e. each transaction time will be later than that of prior transaction at most 24 time units We also investigate a real-life dataset in our experiments This real-life dataset contained all sales data of a supermarket in Taiwan from 2002/7/31 to 2002/11/28. Each row in this dataset records item ID, item quantity, and item price. After we perform all necessary data preprocessing tasks, the dataset contains 108,162 transactions and 9,943 items As shown in table III, we have designed three threshold settings. The decay speed  is set to be 0.001 in all tests Besides, since t current can significantly influence the Rscore of each pattern, we set t current to be the same as the latest transaction time to enhance the influence of recency constraint Moreover, since the FP-growth considers frequency constraint only, the recency and monetary thresholds will be discarded TABLE I P ARAMETERS  D  Number of transactions  T  Average size of the transactions  I  Average size of the maximal potentially large itemsets N Number of items N p Number of patterns L p Average length of maximal pattern C Correlation between patterns 426 


TABLE II P ARAMETER S ETTINGS OF S YNTHETIC D ATASETS Name  D   T   I  N N p L p C SYN-1 100K 25 20 1K 10K 4 0.25 SYN-2 150K 25 20 1K 10K 4 0.25 SYN-3 150K 25 20 4K 10K 4 0.25 TABLE III P ARAMETER S ETTINGS OF T HRESHOLDS    S1 3.5 3 100K S2 4 3.5 120K S3 4.5 4 150K The first test we compare the total execution time with FPgrowth. For each threshold setting, the proposed algorithm spends 1.42 times more than FP-growth on average. This is a reasonable result since we need three database scans whereas FP-growth needs only two database scans to find complete set of patterns Next, we compare the number of patterns generated from RFMP-growth and FP-growth. All three threshold settings are considered here. As shown in table IV, we find that the number of patterns significantly decrease when three constraints are added. On average, our method prunes more than 55 percent of patterns. We further examine the revenues both two kinds of patterns can represent, and the result is promising. Although RFM-patterns retain less than 45 percent of patterns, the proportion of the revenue of RFM-patterns to that of traditional patterns is more than 64 percents. Moreover, we conduct the same test using real-life dataset. In Table V, the result show that our method outputs only 7 percent of traditional patterns but the revenue of these patterns is over 12 percents. In TABLE IV T HE P ROPORTION OF THE R EVENUE OF R FM PATTERNS TO THAT OF T RADITIONAL P ATTERNS S YNTHETIC D ATASETS   patterns  al tradition of   patterns RFM  of     patterns  aditional Revenue\(tr patterns M Revenue\(RF  S1 S2 S3 S1 S2 S3 SYN-1 47.21 42.96 39.34 74.99 71.31 64.62 SYN-2 55.13 55.33 52.23 77.42 80.46 77.21 SYN-3 35.16 35.90 32.91 62.12 43.52 28.93 TABLE V T HE P ROPORTION OF THE R EVENUE OF R FM PATTERNS TO THAT OF T RADITIONAL P ATTERNS R EAL LIFE D ATASETS   patterns  al tradition of   patterns RFM  of     patterns  aditional Revenue\(tr patterns M Revenue\(RF  R0.05-F1%-M10k 6.90 14.68 R0.05-F0.5%-M10k 6.69 10.26 R0.005-F0.5%-M10k 7.62 11.49 R0.005-F0.6%-M12k 6.98 11.39 summary, through setting recency, frequency, and monetary thresholds simultaneously, we can get more compact representative and useful patterns VI CONCLUSION In this study, we consider the concept of RFM analysis into frequent pattern mining. To truly reflect the spirit of RFM in the mining process, we first define RFM-patterns, which can dynamically give recency score to each transaction, and perform the concept of monetary similar to utility mining. To efficiently discover RFM-patterns, we propose a tree structure RFMP-tree\as well as the pattern growth method \(RFMPgrowth\o discover complete set of RFM-patterns Three synthetic datasets and a real-life dataset are used in experimental evaluation. The experimental results show that the proposed method can not only significantly reduce the size of outputted patterns, but also retain more meaningful results to users R EFERENCES 1 F Bo nc hi an d C L u cche s e   E x t e n di ng t h e s t ate o f t he a r t o f co ns tr a i n t based pattern discovery Data & Knowledge Engineering vol. 60, pp 377-399, 2007 2 J  Pei  J  Ha n and W  W a n g  Con s t rai n t ba s e d s e qu en ti a l pa tt ern mining: The pattern-growth methods Journal of Intelligent Information Systems vol. 28, pp. 133-160, 2007 3 A H u g h e s Strategic database marketing 3 ed.: McGraw-Hill Companies, 2005 4 F W u Y  S L e e  an d J N Y u   A n ad ap tiv e a p pr o ach f o r mo de l  selection with high stability," in Proceedings of International Joint Conference on e-Commerce, e-Administration, e-Society, and eEducation Bangkok, Thailand, 2008 5 G D o ng and J  L i  E f f icie n t m i ni ng o f e m e r g i ng pat t e r ns  D i s c o v e r i ng  trends and differences," in Proceedings of the 5th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining  San Diego, California, United States, 1999, pp. 43-52 6 Y L i u, W  k L i ao an d A  C h o u d h a r y  A t w o phase al g o r ithm f o r f a s t  discovery of high utility itemsets," in The 9th Pacific-Asia Conference on Knowledge Discovery and Data Mining Hanoi, Vietnam, 2005, pp 689-695 7 C F  A h me d, S  K  T a nbe e r B S J e o n g  and Y  K  L e e   A n e f f i cie n t  candidate pruning technique for high utility pattern mining," in 13th Pacific-Asia Conference on Knowledge and Data Mining Bangkok THAILAND, 2009, pp. 749-756 8 Y L  Che n a nd Y  H H u  C o n s t r a i n t bas e d s e q u e n t i al p a t t e r n m i ni ng   The consideration of recency and compactness Decision Support Systems vol. 42, pp. 1203-1215, 2006 9 Y L  Che n  M  H K u o  S  Y W u a nd K  T a ng  D is co v e r i ng r e ce ncy   frequency, and monetary \(RFM\ sequential patterns from customers purchasing data Electronic Commerce Research and Applications vol 8, pp. 241-251, 2009 10 J  H a n, J  P e i, Y  Y i n an d R Mao    M i n i n g f r e que n t p a t t e r ns w itho u t  candidate generation: A frequent-pattern tree approach Data Mining and Knowledge Discovery vol. 8, pp. 53-87, 2004 42 7 


   


 990 978-1-4244-6571-2/10/$26.00 ©2010 IEEE  IEEE EDUCON Education Engineering 2010 Ö The Future of Global Learning Engineering Education A pril 14-16, 2010, Madrid, SPAIN 


              


   


                        






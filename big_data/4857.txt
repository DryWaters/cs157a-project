Delivering Mark W Powell Thomas M Images for Mars Rover Science Planning Crockett Jason M Fox Joseph Joswig Jeffrey S Norris Khawaja Shams and Recaredo Jay Torres Jet Propulsion Laboratory/California Institute of Technology 4800 Oak Grove Drive Pasadena CA 91109 Email Mark.W.Powellgjpl.nasa.gov Abstract Mars rover images provide essential context for planning science activities 
This work describes a method for delivering Mars rover images to operations planners that is highly efficient and scalable Experimental results of various image compression strategies applied to rover images are given Next an adaptive level-of-detail tilebased delivery methodology for images is presented With a tile-aware image browsing application images of virtually limitless size may be 
distributed to participating scientists with great efficiency and thus provide a common collaborative context This work also describes advances in mosaicking rover images in support of operations planning 12 TABLE OF CONTENTS 1 INTRODUCTION  1 2 MARS ROVER CAMERAS 2 3 IMAGE DELIVERY 3 4 IMAGE MOSAICS 6 5 CONCLUSIONS 
 10 6 FUTURE WORK  10 REFERENCES  10 BIOGRAPHY  10 1 INTRODUCTION Many people have enjoyed seeing images taken by Mars rovers posted on websites such as those from the Spirit and Opportunity Mars Exploration Rovers MER available at http./marsrovrsJp1.nasa.gov However before the images are made 
widely available specialized processing must be performed to transform the original images into those which are suitable for viewing with a Web browser or other similar image viewing application One such transformation is quantization approximating the range of brightness in an actual scene a continuous function as a discrete set of brightness levels expressed 
in bits-per-channel Images commonly viewed on websites have 8 bits-per-channel of quantization In other words 8 bits are used to encode values in a range of brightness from dark to light in each color channel of the image For a grayscale image there is only one color channel whereas color images typically have 
three red green and blue Many Mars rover cameras 1 11-4244-1488-1/08/$25.00 
C 2008 IEEE 2IEEEAC paper 1190 Version 1 Updated October 24 2007 Figure 1-A post-traverse Front Hazcam image from Spirit Above stretched to maximum contrast in lit terrain Below stretched to maximum contrast in shadowed terrain capture images 
with higher fidelity quantization than conventional digital cameras and may use 12 bits-perchannel or higher fidelity High fidelity imaging is well-suited for onboard autonomy such as vision-guided obstacle avoidance that must be robust enough to work well over changing illumination conditions throughout the day Further this fidelity is also 1 


of the utmost importance when operators target science activities for a rover's robotic arm In order to safely and accurately deploy the arm and operate the science instruments on the end effector high-fidelity images are absolutely necessary One particular situation that is very common with the Mars Exploration Rovers is the need to plan in-situ science operations using the arm instruments sol Martian day immediately after a drive sol Often the drive will execute over a significant portion of a sol and then a context image for planning is captured Very often the image is taken near the end of the sol when the Sun is low in the sky which results in the rover deck casting a shadow over part of the terrain that is reachable by the arm instruments see Figure 1 It would be inefficient to wait until the next morning when illumination conditions are more favorable to capture this image because of the time required to fully transmit the image to Earth There are only a limited number of communication opportunities that relay data from the rovers to Earth via orbiters throughout the day Additionally although some rovers have a direct-to-Earth data transmission capability it is so much more costly in power required for transmission that it is now conventional for all rover data to be sent by orbiter relay Given all of these factors it is much more straightforward to capture context images for planning that have a quantization fidelity that is high enough to provide effective ranges of brightness in areas of both brightly-lit terrain and shadowed terrain It is therefore conventional to capture images for support of navigation and terrain interaction at 12-bit fidelity rather than 8-bit resulting in as high as 16X greater quantization fidelity to combat the problems introduced by diverse illumination conditions 2 MARS ROVER CAMERAS Mars Exploration RoverThe Mars Exploration Rovers each have 10 cameras 1 O 2 Front Hazard Avoidance Cameras Front Hazcams O 2 Rear Hazard Avoidance Cameras Rear Hazcams O 2 Navigation Cameras Navcams mastmounted O 2 Panoramic Cameras Pancams mastmounted O 1 Microscopic Imager MI arm-mounted O 1 Descent Camera All of the MER cameras are 1024x1024 resolution and 12bit-per-channel capable Images from all of the cameras are useful for characterizing the geology of the Martian surface at different scales Every image delivered by a rover provides valuable context for science planning Some images are purely diagnostic in nature such as to verify that an arm placement was successfully targeted Other images provide information about terrain morphology and appearance The Hazcams Navcams and Pancams are all stereo camera pairs that are used to derive terrain geometry Rover-relative geometric terrain models are used for obstacle avoidance navigation planning and instrument arm placement Images from the Pancams are most often taken to characterize the multispectral color appearance or high-resolution morphology of a terrain feature as part of a science investigation although the geometric models derived from these stereo images are sometimes used for high-precision targeting and terrain modeling for navigation in special cases Images taken by the MI are always part of science investigations Images from Pancam and MI that are designed for science are usually taken at 8 bits-perchannel with autoexposure to adapt for the current illumination conditions Although 12-bit imaging could be used for the science images it is often not practical to do so in light of constraints on the available data transmission bandwidth and onboard data storage limitations Imaging with 12 bits-per-channel is conventionally used for Hazcam and Navcam imaging taken in support of science targeting and terrain modeling for traverse planning in operations Image compression rescaling and cropping is performed on images from all the cameras as appropriate on a perimage basis to economize data storage and required bandwidth to return the data for science operations Each Descent Camera was used only during the descent phase of the mission just prior to landing and was disconnected from its respective rover prior to egress from the lander The Descent Camera images were used to assist in guiding the spacecraft safely to the surface as it slowed through the atmosphere These images were also useful in performing initial localization of the landing site in each rover's respective region of exploration Phoenix Mars Lander The Phoenix Mars Lander is designed to assess habitability of terrain in the Martian northern polar region Although not capable of mobility the Phoenix Robotic Arm requires stereo images for context to accurately target terrain sampling and analysis activities Like MER Phoenix has a mast-mounted stereo pair of cameras for mapping terrain geometry These Surface Stereo Imager cameras have similar resolution to the Pancam on MER and are 12 bit-per-channel capable The Robotic Arm operators will plan arm movement and soil interaction using imaging techniques inherited from MER operations Mars Science Laboratory The Mars Science Laboratory rover camera complement is similar to that of MER Like MER MSL will have Front Hazcams Rear Hazcams and mast-mounted Navcams Like MER MSL also has mastmounted science cameras called Mastcams with planned capabilities for color and high-resolution imaging that are equal to or better than the MER Pancams The MSL rover is also planned to have an arm-mounted camera named Mars 2 


Hand Lens Imager MAHLI that is equal to or better than its MER counterpart While the science camera complement may vary from MER in the current design the Hazcams and Navcams on MSL are identical in every way to their MER siblings Given this the imaging paradigms used on MER for operational targeting and navigation will have direct applicability to MSL Importantly the MSL science investigation team will be more diverse than that of MER both in scientific focus and in geographic location To collaborate effectively this diverse team will require an efficient mechanism for delivering contextual images for science planning to each of their home institutions across the globe image compression available with an adaptive level-ofdetail image delivery strategy which scales very well with larger images such as mosaics and high-resolution orbital images Image Compression Of the many image compression strategies available there are relatively few implementations that are well-suited for efficient delivery of Mars rover images to operations planners Lossy compressed images that faithfully reproduce the original image data will theoretically provide a superior delivery rate to losslessly compressed images owing to the relative reduction in size In practice experimental comparison of various lossless and lossy compression strategies applied to Mars rover images confirms this expectation Comparing lossless compression Figure 2-Examples of lossy compression applied to a MER Pancam image of a rock face Left JPEG compression showing blocky artifacts Right JPEG2000 compression showing degradation by blurring 3 IMAGE DELIVERY Planning the science activities for Mars rovers requires the use of images At a minimum the most recent images returned from the rovers are needed to evaluate the efficacy of the science most recently executed and often additional images can also be helpful in planning as added context When the team that plans these science activities is geographically distributed across several countries as is that of MER and MSL access to imagery over Internet connection is needed to make their collaboration effective To optimize the delivery of image data to every mission planning participant we have combined the most effective using PNG JPEG-LS and TIFF-LZW to lossy techniques like JPEG and JPEG2000 showed that depending on the technique lossy compression can result in data size reduction ranging from a factor of 3 to as much as 10 or more depending on what level of degradation of the image is tolerable Of the lossy image compression techniques available JPEG and JPEG2000 were compared JPEG2000 has two particular features that make it superior for encoding Mars rover images for distribution support for higher fidelity of quantization and more tolerable degradation of image quality While JPEG supports only 8 bit-per-channel image encoding JPEG2000 implementations support 16 bit-per-channel encoding which allows 12 bit-per-channel Mars rover images to be 3 


encoded without requantization JPEG2000 degrades the image differently than JPEG as the data size is progressively reduced While JPEG lossiness results in an image with blocky artifacts JPEG2000 will instead blur the image Figure 2 shows an example the difference in appearance between lossy JPEG and JPEG2000 This difference can be attributed to the dissimilar compression algorithms used Blocky image degradation is a characteristic of the Discrete Cosine Transform DCT used in JPEG compression while blurring is a result of the wavelet-based compression used in JPEG2000 The primary disadvantages of JPEG2000 compression are its lack of penetration into common imaging applications compared to JPEG and its high computational cost compared to JPEG Most web browsers either do not support viewing JPEG2000 encoded images or resulted in a slow adoption rate of this format in the industry While the higher computation cost of decoding JPEG2000 image data may be acceptable for contemporary desktop or laptop computer systems it is still a significant issue for mobile devices and embedded systems Tile-based delivery Many approaches to image delivery from a server to client applications deliver entire images at once This can be accomplished as a single file transfer from server to client and works well in some cases However if for any reason the available bandwidth does not support near-instantaneous delivery of the entire file then the client will experience a delay Some web browsers support interlaced GIF or PNG Figure 3-An Opportunity Pancam mosaic of total size 11280x4280 pixels containing 77 color images Tiles at six levels of detail are required to deliver this image to a viewer at any arbitrary size The yellow grid lines indicate the tiles required for each image require a plugin to support them At the time of this writing Adobe Photoshop still requires a plugin to read or write JPEG2000 encoded images The inability to import JPEG2000 images in commonly used applications has image delivery and render the parts of the image that have already transferred while the remaining parts are being delivered to try to mitigate the perceived delay at the client giving the user the impression of progress As Internet 4 IN 


speeds increased and JPEG compression used pervasively on the Web to make images very small in total data size this practice has fallen into disuse For video products streaming techniques are used to view frames that are available while new frames are being delivered The same principle can be applied to images that are large in size such as panoramas of rover images or high resolution orbital camera images If the total size of an image is much bigger than the size of the client's screen or the part of the screen used by an image browser application it is much more efficient to deliver only the image data that will fill their view instead of the entire image If a client application is designed to display images in pieces or tiles on demand then only the small screen To support viewing images at different scales it is necessary to produce image tiles at different scales or levels of detail Next we will describe a generalized adaptive level of detail tiling methodology Methodology For a given image of width w and height h and a given tile size nxn begin by cropping one tile starting in the upper-left pixel image coordinate 0 0 and crop one tile from the image Proceed along the top row of the image and crop tiles at n,0 2n,0 etc and stop when a tile is made that includes the last column of the image Proceed to row n and create a tile at coordinates O,n then follow row n as with the first row until all tiles for that row are complete Continue producing rows of tiles until the row of tiles that includes the last row of the image is produced All Figure 4-Cylindrical mosaic projection surface Images of the terrain near the rover project onto a plane oriented with the rover pitch and roll Images of the horizon project onto a hemisphere tiles needed to fill the application window are ever transferred from the server while unviewed tiles are ignored This sort of tiled image delivery technique is used in web-based mapping applications such as Yahoo Maps and Google Maps When paired with a tile-aware image viewing application tiled image delivery is a highly efficient and highly scalable technology For large images such as mosaics and maps it is not sufficient to tile the image only at its native resolution It is often necessary to view large images at smaller scales such as when displaying a large image entirely on a relatively of the tiles at the highest level of detail are now produced Rescale the original image to half of its original size or width w/2 and height hl2 and then repeat the previous tiling procedure to produce the second-highest level of detail Continue producing additional levels of detail rescaling the image each time to 12 its current size until the image fits entirely inside one tile This will provide tilings of the image that are suitable for any size of view in a client application Figure 3 shows an example of tiling a large panorama image at multiple levels of detail 5 


The choice of tile size is somewhat arbitrary so experimentation with different sizes under similar network server and client conditions may be useful For a Mars rover image viewer application running on conventional consumer laptop computers and commonly available network bandwidth both 100 Mbps wired and 54 Mbps wireless tile sizes of powers of 2 ranging from 64X64 to 1024X1024 were compared Experimental results indicate that tiles of size 256X256 result in the highest data delivery rate under the aforementioned conditions Rescaling tiled images with interpolation It is sometimes necessary to view images at scales higher than native resolution For example Mars rover images of terrain in the workspace of the arm often need to be zoomed in by a factor of 2 or more to carefully target in situ science instruments Tiled image delivery can introduce a quality problem for scaling up an image beyond native resolution with interpolation Scaling images with interpolation produces a much more faithful rendering of the image similar to the way that antialiasing produces more realistic computer graphics Scaling up an image to twice native resolution for example requires that the new image have twice as many rows and columns Simply copying adjacent pixel values to the new pixels in between the original rows and columns is called nearest-neighbor interpolation and other methods like bilinear interpolation which perform a weighted average of neighboring pixels provides superior results at higher computational cost Interpolation techniques like bilinear that consider a neighborhood of pixels will fail across tile boundaries If an application renders image tiles by drawing each tile abutting with its neighbors it can only interpolate over a neighborhood within each individual tile At tile boundaries the interpolation cannot be performed which results in artifacts all along the tile boundary There are two strategies for overcoming this problem The first strategy is to combine pixels from all tiles required to render one monolithic image and render it with interpolation This will allow interpolation to work correctly throughout the image but has a cost of duplicating all of the image data before rendering it Another strategy is to create a tiling of the image where each tile overlaps with its neighbor by one pixel on each side and render each tile as if it were two pixels smaller in each dimension by omitting the one-pixel border on each side This will allow the interpolation to work correctly within each tile even at the border since we provide the appropriate pixel data along the border to use when interpolating The cost of this technique is that there are two rows and columns of redundant pixel data in each tile that is delivered but this cost compares favorably with the aforementioned method of duplicating entire images in memory prior to rendering with interpolation 4 IMAGE MOSAICS Mosaics of Mars rover images are useful context for many science planning tasks such as high-resolution imaging multispectral observations and traverse planning Mosaics provide a more effective view of an entire terrain region than one can get by viewing single images in isolation or rapidly flipping through a collection of such images Mosaics simultaneously reproject multiple images onto a representation of the world to show everything at once from a given point of view Next we will look at two mosaicking methodologies in detail that are useful for visualizing collections of Mars rover images for science activity planning Cylindrical Mosaics Cylindrical projection is commonly used to mosaic together a series of images taken with a camera mounted on an articulating tripod or other similar pan-tilt platform This style of projection provides a rendering of an entire landscape in every direction at the same time This type of image is impossible to capture with either human eye or camera with the exception of panoramic cameras which are at the time of this writing not yet in widespread use Mars rover mast-mounted cameras are conventionally mounted on an articulating pan-tilt mast mechanism to allow them to capture a series of images of the landscape around the vehicle Cylindrical mosaics of such images provide essential context for selecting and prioritizing targets for remote science investigations and traverse planning To project images into a cylindrical mosaic a suitable projection surface is needed One such surface is illustrated in Figure 4 The terrain all around the rover can be approximated by a plane directly under the rover wheels rotated to match the attitude of the vehicle specifically its chassis pitch and roll The planar surface is generally suitable for projecting the images out to a radius of about 10 meters surrounding the rover At this transition the surface changes into a hemisphere that is centered over the rover such that the center lay on the ground plane The interior of the hemispherical surface is suitable to project images that point toward the horizon the sky or the ground relatively far away from the rover Images that overlap this transition may be projected partly on the hemisphere and partly on the ground plane to maintain a continuous mosaic image In order to map each image onto the projection surface a camera model for each image is used The camera model captures the intrinsic parameters of the optical system and the extrinsic parameters of the camera location and its rover-relative pan and tilt angles Camera models conventionally used with Mars rover cameras are described in 2 The camera model allows any pixel in an image to map to a 3D ray and any 3D position in camera-relative coordinates to map to a pixel We can use the latter mapping to project points on the projection surface into the various 6 


images in the collection If we iterate over the entire projection surface where there exists image coverage we can mosaic an image using the most appropriate brightness or color at every location We can guarantee no loss of resolution by sampling from points on the projection surface Examples of mosaics that were generated using this technique are shown in Figure 5 This strategy of mosaicking images is also applicable to an interactive mosaic viewing application The process of Figure 5-Examples of cylindrical mosaics of Mars rover images Above Pancam mosaic by Spirit in the Columbia Hills Center Pancam mosaic by Opportunity at Victoria Crater Below Pancam mosaic by Opportunity of Burns Cliff at Endurance Crater in increments of no less than the native per-pixel field of view of the camera For example for a camera with a 45\260 field of view and 1024X 1024 image resolution would have a 0.044 degree per-pixel field of view To further reduce any artifacts in the mosaic introduced in the resampling process interpolation can also be used to consider the weighted average over a neighborhood of pixels at each position mapping projection surface points to images can also be used to transform a mouse click position to a ray that intersects the projection surface at a point that can be mapped back to the pixel location in the original image that is identical to that used to build the mosaic This type of mapping is generally very useful and is specifically for correlating Mars rover image pixels to stereo range map 7 


locations These range map locations provide distance to features of the terrain in addition to orientation and can be used to very accurately target remote science instrument arm or traverse activities For interaction on mosaics to work reliably a heuristic is needed for maintaining the consistency of which images are on top of other images in cases of overlap Particularly in the case of Mars rover mosaics many images overlap other images For example a high-resolution cropped image of a specific area may fall within a low resolution image of a general area Also stereo image pairs can only produce stereo in the areas that each left-right image pair have in common leaving a strip along the left edge of the left-eye image where there is no stereo In order to produce a contiguous stereo range map of a large region a large enough overlap between adjacent images must be used In areas of overlapping images the solution as to which image a projection surface point maps to from that area is ambiguous In order to guarantee consistent behavior in an interactive application the images in the mosaic collection must be sorted into a particular order This ordering is first used to produce the mosaic image and then is adhered to when a user interactively selects a pixel in the mosaic so that the same corresponding pixel in the original image is given as the solution The actual sorting and selection heuristic can vary depending on the desired output Some useful guidelines in the case of Mars rover image collections include preferring more recent to less recent images and preferring higher resolution to lower resolution images A version of this mosaicking process was implemented for a science planning and image browsing application for MER operations called Maestro The implementation is superior to that of the earlier version of the software called the Science Activity Planner SAP described in 3,4 SAP was not originally designed for distributed use and so instead of tile-based delivery images were transferred to remote users entirely causing great delays Maestro was redesigned using the aforementioned tile-based delivery so that all images especially mosaics may be viewed far more rapidly The projection surface used for SAP was a sphere rather than a hemisphere on top of a ground plane that matched the rover pitch and roll Projections of images of the terrain were consistently not well-stitched together in SAP as the spherical surface model was often inappropriate for the terrain The planar surface works consistently well for Maestro for areas of flat or nearly flat ground with rocks of modest height The stitching of adjacent images in Maestro is still imperfect in some cases such as tall rocks tall near-vertical faces of objects such as a mound or wall or undulating terrain The previous implementation also used a nearest to center-of-projection shortcut method for selecting which image to project into a mosaic image and also in mosaic interaction This method performed suboptimally in some cases of image overlap sometimes mixing two overlapping images together in unintuitive ways The a priori image collection ordering method produces a more continuous and intuitive-looking mosaic image Cylindrical mosaics also provide a convenient forum for science group discussion and collaboration Many science planning discussions and strategy sessions are conducted in the context of a cylindrical mosaic map of the landscape Maps in general are widely used in Mars science investigations a fact which leads to another useful type of mosaic projection the overhead mosaic Overhead Mosaics Maps are essential for charting a Mars rover's many kilometers of traversal over large regions With the availability of orbital imagery from the Mars Reconnaissance Orbiter High Resolution Imaging Science Experiment MRO HiRISE we can now obtain maps from images captured from orbit at 0.5 meter per pixel resolution resolution enough to unambiguously see the rover and its tracks in the image To provide additional correlation of science observations made by the rovers in such maps it is useful to correlate images from MER Navcam and Pancam onto a map at resolution greater than HiRISE in these particular areas Such images are currently produced for MER operations using a projection surface that so distorts the size and shape of surface features that they are less than ideal for mapmaking A new methodology for producing overhead mosaics that are more suitable for maps has been developed that addresses the shortcomings of the current state of practice The current method projects all images taken from the rover onto a ground plane For terrain that is very close to the assumed ground plane this technique works well However often the most interesting surface features one wishes to correlate from rover image to orbital image are rocks When projected from above the area that corresponds to a given rock is on the average half-visible and half-invisible from the rover's point of view since the rover views a rock from the side and not the top Furthermore the area behind the rock that is obscured from the rover's point of view is similarly invisible Unfortunately when using the ground plane assumption over an area containing a rock and projecting onto a ground plane the image of the visible face of the rock is stretched over the area containing the visible rock area the invisible rock area and the invisible area behind the rock which distorts the size and shape of the rock and grossly misrepresents it on a map In order to faithfully reproduce terrain features on undulating terrain including rocks and other features of varying height the ground plane assumption must be discarded in favor of a more sophisticated surface model 8 


that is based on stereo range information Taken together all of the stereo range maps derived from stereo image pairs form a cloud of 3D points all around the rover that conform to the terrain surface We can derive a height map or elevation map from the stereo point cloud by creating an artificial grid in X northing and Y easting and letting the Z axis be elevation We can arbitrarily select the spacing horizontal and vertical grid to achieve the desired mosaic image resolution Early work in this area suggests that 0.01 collisions between multiple points that occupy the same grid cell the maximum elevation should be selected In undulating terrain it is important to preserve relatively large grid regions where no points are available such regions are often the invisible rock and terrain features from the rover's point of view that are the failing of the current state of practice Very small regions of a few contiguous cells or even single cells in the grid will sometimes occur due to failures in stereo correlation due to lack of sufficient Figure 6-Overhead mosaics of Opportunity Navcam images Above a mosaic based on a ground plane projection Below a mosaic based on an elevation map meter per pixel spacing is effective for Navcam elevation maps The overall size of the mosaic can be selected arbitrarily as well Empirical use of Navcam stereo data for targeting and navigation indicates a distance of 15 meters from the rover in any direction is the maximum beyond which the data becomes too sparse to derive an effective elevation map To create the elevation map the point cloud can be inspected one point at a time and the elevation value assigned to the X-Y grid cell in which it falls To resolve texture or other factors To fill in these very small regions with no data a median filter can be applied over the elevation map to assign the median elevation value of those in the local neighborhood to the cell Once assembled the elevation map is now usable as a mosaic projection surface A mosaic image the same size as the elevation map may be constructed by projecting the 3D point formed by the X-Y cell coordinates and the Z 9 


elevation value through the camera model into the original Navcam or Pancam image The corresponding color value at the pixel coordinates ideally an interpolated value is assigned to the mosaic image Figure 6 shows an example of such a mosaic When overlaid onto a HiRISE image this type of mosaic adds useful context including surface features observed by the rover as well as enabling the correlation of targets where observations made by other instruments in the rover science payload are located Further development and integration of this mosaicking methodology is currently underway at the time of this writing and will be further matured in the coming years leading up to Mars Science Laboratory operations 5 CONCLUSIONS Adaptive level-of-detail tile based delivery of images is now supporting operations of the MER and Phoenix missions The performance of this strategy has proven to be superior by orders of magnitude to the previous state of practice The original Science Activity Planner system required entire image collections to be transferred to remote users in order to browse mosaics The transfer time for Pancam image collections was typically on the order of 15 minutes or longer and the delay was compounded by Internet connections over very long distances such as across the United States or to other countries The coast-to-coast transfer time is now only a few seconds or less for each screen of tiles for the initial transfer Tiles are only transferred once and then stored in a local browser cache to prevent redundant transfers JPEG2000 image compression is being used to compress the tiled image data that is served to the science investigators The quality of this image compression has proven to be very suitable for Mars rover images and the performance superior to other formats such as JPEG and PNG The JJ2000 reference implementation for Java applications 5 has proven in practice to be a capable implementation for encoding and decoding JPEG2000 image data 6 FUTURE WORK Microsoft's HD Photo compression algorithm offers reduction in image size similar to JPEG2000 with a lower computational cost This technique may be an improvement over JPEG2000 encoding of Mars rover images although at the time of this writing it still lacks the multiplatform support that is required to serve a diverse community of science investigators If this limitation is overcome it would be worthwhile to experiment with HD Photo and quantify its performance when compared with JPEG2000 in quality size reduction and computational cost On July 31 2007 the Joint Photographic Experts Group and Microsoft announced that this compression technique was under consideration for a new JPEG standard tentatively titled JPEG XR 6 This will hopefully lead to a multiplatform implementation of this compression algorithm that could be applied to many domains such as Mars rover imaging REFERENCES 1 Justin N Maki Todd Litwin Mark Schwochert Ken Herkenhoff Operation and Performance of the Mars Exploration Rover Imaging System on the Martian Surface 2005 IEEE International Conference on Systems Man and Cybernetics October 10-12 2005 2 Y Yakimovsky and R Cunningham A system for extracting three-dimensional measurements from a stereo pair of tv cameras Computer Graphics and Image Processing vol 7 pp 195-210 1978 3 Jeffrey S Norris Mark W Powell Marsette A Vona Paul G Backes Justin V Wick Mars Exploration Rover Operations with the Science Activity Planner IEEE International Conference on Robotics and Automation April 2005 4 J S Norris M W Powell J M Fox K J Rabe I Shu Science Operations Interfaces for Mars Surface Exploration 2005 IEEE Conference on Systems Man and Cybernetics October 15-17 Big Island HI October 15 2005 5 JJ2000 JPEG2000 reference implementation of JPEG2000 http://jj2000.epfl.ch 6 Microsoft HD Photo press release ACKNOWLEDGEMENTS The research described in this publication was carried out at the Jet Propulsion Laboratory California Institute of Technology under a contract with the National Aeronautics and Space Administration BIOGRAPHY Mark Powell is a Senior Member of Technical Staff at the Jet Propulsion Laboratory Pasadena CA since 2001 He received his Ph.D in Computer Science and Engineering in 2000 from the University of South Florida Tampa His dissertation work was 10 


in the area of advanced illumination modeling color and range image processing applied to robotics and medical imaging and received the award for Outstanding Dissertation from the University of South Florida At JPL his area offocus is science data visualization and science planning for telerobotics He supported the 2004 Mars Exploration Rover MER mission operations as a Science Downlink Coordinator facilitating the timely downlink and analysis of science data from the rovers He received the NASA Software of the Year Award for his work on the Science Activity Planner science visualization and activity planning software used for MER operations He also received the Imager of the Year award from Advanced Imaging Magazine for his work on Maestro the publicly available version of the Science Activity Planner for MER Mark has been programming in Java and loving every minute of it since it was first used in web browsers in 1995 He his wife Nina and daughters Gwendolyn and Jacquelyn live in Tujunga CA Thomas Crockett started working at JPL in 2005 after completing his Bachelor of Science degree in Computer Science at the University of Arizona where he discovered an interest in graphics He joined the Maestro team in 2006 and began developing advanced image browsing capabilities that would be used by the MER Phoenix and MSL missions to view and smoothly navigate around very large images Recently he has been extending this work to tackle the problem of mapping and spatial browsing of the science data collected by a mission Jason Fox received his Masters of Science degree in Computer Science from Purdue University in the spring of 2003 At that time he began working for the NASA Jet Propulsion Laboratory in Pasadena California in the Planning Software Systems group Jason first worked on the Mars Exploration Rover MER mission performing verification and validation of the Activity Planning and Sequencing Subsystem's modeling infrastructure After the rovers  successful landing his role shifted to that of Tactical Activity Planner on the Integrated Sequencing Team and was responsible for the daily construction of the integrated rover activity plan After leaving MER Jason joined the Maestro team and began development on the science operations tool Maestro the successor to the Science Activity Planner co-winner of the NASA Software of the Year in 2004 In addition to Maestro he is also the JPL leadfor the Phoenix Science Interface tool that will support scientific operations of the Phoenix lander 2007 At JPL his areas of focus include collaborative distributed operations for Mars rovers and landers and science planning for telerobotics In his spare time Jason is in training for the Coeur d'Alene Ironman competition to be held in June 2008 Joseph Joswig received his Masters of Science degree in Computer Science from the University t o California Los Angeles in the Spring of 2005 He is a Software Engineer in the Planning Software Systems various~Gou flth NAssiAn Jeta ER heix n S and tchnolgy prjec Propul s inc Laboratiory in or wa ouedo eeorked fo mutherpast twoun softwaresysteyears asL aTLT moembe NS-ofnthe Cener K10 ove lso h Ma estrog thea Masupproting wrhafoue ondeveloping o a multi-robot gomnadcn roundste to support White Sands Missile Range Jeffporruisy isath Exportin ovrsorwhc supy ervisorwne of the 2004NASASofwareof te Plannn Awr.H softwarenl leadng te deelopentf operatlions system s for ah20 Mar SieneabratryRoerndaMars et Sofut r Cassni Satunian Orbter Mar Reco naisanc Orbter and.the.pirit an pportunityM....M ars Explratin.Roers-.fo.whih.thy.wre.c-winer.o.th 2004 NASA Software of the...Year...Award.....He..is..currently leading the develoment.of.the.uplinksystem.for.the.200 MarScencLaoraoryRovroandalvaiety Laofrlunry and Martian operations technology projects Jeff is a strong 11 


advocate for the application of agile development to Cora and has a lovely daughter Sara In his spare time methodologies and open source software in mission critical he likes to run marathons and continually bugs his friends applications He received Bachelor's and Masters degrees to join him in Computer Science from MIT and lives with his wife and two children near Pasadena CA Khawaja Shams joined the Planning Software Systems group at the NASA Jet Propulsion Laboratory in 2005 and he has since been focused on development of OSGI-based web services to enable Maestro's rich client applications His prior work experience includes employment at Malin Space Science Systems and the Internet Protocol Team at Nokia Mobile Phones Khawaja earned a Master's degree in Computer Sciencetfom Cornell University and a Bachelors degree in Computer Science from University of California San Diego Khawajaes current research interests include browser-based telemetry monitoring systems for robotics peer-to-peer systems and PESTful web based services memobern of Tathe a Uplaning edrsosbefrpann Sotwae systems itgropatigwtthsceetam an theadn Jth Pnieropliongemtruhtedyt a Laboratiory.o HER recer ived rton uis,h oe fomt bigaprofthe Ca Monaetoeabinthlasnfr woredME ponetiherueo the Sciencelanin sQfta sotae develsopingeoe frte asScec Lactivit PMLane and Seqene InHLTEgRatono Engineer constructing validating..and.veri.ying..and.bundling sequences used to command the MER rovers....He.moved onto being a Tactical Uplink Lead responsible for planning the sequences integratingwith the science team an softare.o Hey iorsalso a developer fortheMar.Scenc Lander MSL and the ATHLETE Robot project    investigating robots to be sent to the Moon Jay is married 12 


11 Xiao Yang L Haizhon S Choi 2004 Protection and Guarantee for Video and Voice Traffic in IEEE 802.1 le Wireless LANs INFOCOM 2004 Twenty-third Annual Joint Conference of the IEEE Computer and Communication Societies Volume 3 Issue 7-11 21522162 12 W Spearman J Martin A Distributed Adaptive Algorithm for QoS in 802.1 le Wireless Networks Proceedings of the 2007 International Symposium on Performance Evaluation of Computer and Telecommunication Systems SPECTS'07 San Diego CA July 2007 pp 379-386 13 Lim L.W Malik R Tan P.Y Apichaichalermwongse C Ando K Harada Y Panasonic Singapore Labs A QoS Scheduler for IEEE 802.1l e WLANs Consumer Communications and Networking Conference 2004 pp 199-204 14 V Vleeschauwer J Janssen G Petit and F Poppe Quality bounds for packetized voice transport Alcatel Tech Rep 1st Quarter 2000 15 ITU Series H Audiovisual and Multimedia Systems Infrastructure of audiovisual services Coding of moving video H.264 03/2005 International Telecommunication Union 12 BIOGRAPHY cooperative signal received his B.S Engineering from respectively processing and sensor networks He M.S and Ph.D degree in Electrical UCLA in 1993 1995 and 2000 Will Spearman is a Master's Candidate at Clemson University's School of Computing His work focuses on QoS in 802.cle and wireless networks His background includes a B.S in Psychology with a minor focus in Computer Science He currently is employed at Network Appliance Inc Dr Jim Martin is an Assistant Professor in the School of Computing at Clemson University His research interests include broadband access autonomic computing Internet protocols and network performance analysis He has received funding from NASA the Department of Justice BMW IBM and Cisco Dr Martin received his Ph.D from North Carolina State University Prior to joining Clemson Dr Martin was a consultant for Gartner and prior to that a software engineer for IBM Jay Gao joined the Jet Propulsion Laboratory in 2001 and is currently a senior research staff in the Communications Networks Group in the Telecommunication Research and Architecture section His research is primarily focused on space-based wireless communications and networking with emphasis on applications for the Mars Network He is currently conducting research for developing quality-of-service QoS protocols for the envisioned Interplanetary Network IPN and study optimization and protocols for deep space Ka-band communications He also supports requirements definition and interface design activities for the Department of Defense's Transformational Communications MilSatcom project and system engineering effort for NASA's Exploration System and Mission Directorate ESMD supporting the Constellation Program for return of human to the Moon and Mars Other research interests include optical-based sensorweb discrete event simulation of distributed communication/sensor systems energy efficient routing and self-organization algorithm for 13 


  14  Figure 5:  Site B1 Terrain horizon ma sk with 1 degree azimuth spacing  Figure 6:  Site B1 Terrain horizon mask with 1 de gree azimuth spacing, in e quatorial coordinates 


  15  Figure 7: Lunar South Pole Solar Illumination Yearly Average  Figure 8:  Lunar South Pole DTE Visibility Yearly Average 


  16  Figure 9: Lunar North Pole Sola r Illumination Yearly Average  Figure 10:  Lunar North Pole D TE Visibility Yearly Average 


  17  Figure 11: Site A1 Elevation Topography  Figure 12: Site A1 Yearly Average Solar Illumination and DTE visibility, Medium Resolution 


  18   Figure 13:  Site LB Te rrain Horizon Mask  Figure 14:  Theory and Computed values of Average Yearly Solar Illumination 


  19  Figure 15:  Theory and Computed values of Average Yearly DTE Communication  Figure 16:  Heliostat Mirror Design to Eliminate Cable Wrap 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



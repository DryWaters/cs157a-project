  1 Managing Complexity to Maximize Science Return Science Planning Lessons Learned from Cassini  Brian G. Paczkowski Jet Propulsion Laboratory California Institute of Technology 4800 Oak Grove Drive Pasadena, CA  91109-8099 818-393-7739 brian.g.paczkowski@jpl.nasa.gov Barbara Larsen Jet Propulsion Laboratory California Institute of Technology 4800 Oak Grove Drive Pasadena, CA  91109-8099 818-393-5864 barbara.s.larsen@jpl.nasa.gov Trina Ray Jet Propulsion Laboratory California Institute of Technology 4800 Oak Grove Drive Pasadena, CA  91109-8099 818-354-8655 trina.l.ray@jpl.nasa.gov  Abstract 227Cassini-Huygens ended its four-year prime mission on July 1, 2008. Significant challenges to 
developing and executing the science plan for the orbiter mission had to be overcome to return a wealth of science data from its tour of the Saturnian system. These operational challenges reflected the comple xity of the mission, of the tour, of the spacecraft, of its instruments, and of the ground system environment. This paper discusses in-depth the lessons learned from the science planning operations of Cassini including the multi-step uplink process designed to select, integrate and implement science observations Aspects of system engineeri ng, spacecraft design, spacecraft subsystems, flight hardware and software, ground software instrument and science operations that either facilitated or complicated science return are also addressed 12 T ABLE OF C 
ONTENTS  1  I NTRODUCTION 1  2  C ASSINI HUYGENS MISSION OVERVIEW 1  3  T HE C ASSINI S PACECRAFT 2  4  O PERATIONAL C HALLENGES 3  5  T HE M ISSION O 
PERATIONS S YSTEM 6  6  L ESSONS L EARNED 9  7  C ONCLUSION 11  8  A CKNOWLEDGEMENTS 12  R EFERENCES 12  B IOGRAPHY 13  1  I NTRODUCTION 
 During its four-year prime mission, the Cassini-Huygens mission team has made exciting scientific discoveries explored varied scientific questions, and collected quantities of high quality science data. Its instruments\222 capabilities well exceeded any previously us ed to explore deep space and the spacecraft has been an able workhorse Achieving these results, however, required that the mission operations team overcome several considerable challenges deriving from the complexities and constraints of such a large effort. Elaborating on the complexities that the operations team manages and describing the ground system 1  1 978-1-4244-2622-5/09 25.00 \2512009 IEEE 2 
IEEEAC paper 1590, Version 1 Updated 2008:12:14 and processes developed to facilitate that management provides insight into the co st of the mission\222s success Constructive ways in which future missions could mitigate the challenges Cassini faced during design should enable similar success at lower cost of operations 2  C ASSINI HUYGENS MISSION OVERVIEW  The Cassini-Huygens mission returned rich science from its four year prime mission. Its four year tour of the Saturnian system has been described as \223the most ambitious effort in planetary space exploration ever mounted.\224 3  A collaborative effort of NASA, ESA, and the Italian Space 
Agency  C a ssi ni Huy gens was l a unched on Oct ober 15 1997 on a Titan IV-B/Centaur launch vehicle. After a seven year, two billion mile voyage with two loops around the sun and four gravity-assist flybys of other planets including Earth, it entered orbit on July 1, 2004. During the long cruise phase, limited science was performed to checkout and characterize the instrument s. Further preparation came from science collection during the months of the Jupiter flyby, with closest approach on December 30, 2000. Shortly before arrival, the intensity of science observations stepped up with a Saturn approach phase and a targeted flyby of Phoebe on June 11, 2004. During the critical Saturn Orbit Insertion \(SOI\on July 1, 2004, Cassini made its closest approach to Saturn of the entire mission at an altitude of only 0.3 Saturn radii \(18,000 km\hrough a gap in a thinner region of Saturn's ring plane. The 76 orbits of 
the prime mission were varied to study the planet, its rings and its magnetosphere. To study Saturn\222s satellites, the spacecraft made 45 close flybys of Titan along with targeted flybys of the icy moons Phoebe, Hyperion, Dione, Rhea Iapetus and three of Enceladus. These and other moons were also observed on numerous non-targeted flybys for which no special maintenance of the trajectory was applied to achieving timing and geometry The Cassini orbiter also carried along the Huygens probe destined to probe Titan\222s atmosphere and land on Titan\222s surface. The probe was deployed on December 25, 2004 1  3 European Space Agen cy \(ESA http://www.esa.int/SPECIALS/Cassini Huygens/SEMMD2HHZTD_0.html 


  2 Three weeks later, on January 14, 2005, it entered Titan\222s atmosphere, then slowed its de scent with a series of three parachutes before landing. The probe sent measurements and images to Cassini for transmission to Earth The mission objectives incorporated diverse, multidisciplinary science goals. For the planet itself, the questions of interest concerned the atmosphere and composition, dynamical processes, and the internal structure and rotation. Analysis of the ring system was focused on the origin, the three-dimensional structure and composition dynamical processes, interrelations between the rings and the satellites, and dust and the micrometeoroid environment Titan, the largest moon in the solar system and the only one with an atmosphere, invited inquiry into its atmospheric composition, winds, and temper ature; its surface state and composition on a regional scale; the time variability of its clouds and hazes; and the source of its methane, an organic compound abundant in its atmos phere, lakes, and oceans For each of the icy moons, th e characteristics, geological histories, mechanisms of surf ace modification, and internal structure deserved observation Selecting a tour to achieve the competing objectives was one of the Cassini-Huygens team\222s early challenges. The equatorial orbits that use the least propellant\227the essential limitation on mission life\227do not provide for in-situ sampling of the whole of the magnetosphere, are ineffective for observing the rings, and do not allow for high resolution surface imaging of Titan away from the equator or occultations of Saturn or Titan atmosphere at high latitudes Constant short duration orbits strain the operations team with their intensity, but ar e the only way to reach the smaller inner satellites like Enceladus. Variable orbits greatly intensify the navigation effort, as does the desire to target specific satellites at specific aimpoints of latitude longitude, and altitude. Many cl ose encounters of Titan, the only body with sufficient mass to influence orbit control are required to rotate out of the ring plane, but must satisfy scientific objectives as well. Balancing achievement of the science objectives with spacecr aft resources and operational costs was a recurring theme in mission success 3  T HE C ASSINI S PACECRAFT  Among interplanetary spacecraft, Cassini-Huygens is remarkable for both its size and its complexity. Standing 6.8 m \(22 ft\gh, roughly 4 m \(13 ft\n diameter, it weighed over 6 tons when fully fueled \(Figure 1\ter is a three-axis stabili zed spacecraft, whose attitude control system includes three inertial reference units and a stellar reference unit. Pointing control is maintained either with reaction wheels or with thrusters. The propulsion system also includes a main engine asse mbly. Either the thrusters or the main engine can be used for the orbit trim maneuvers that keep Cassini on its refe rence trajectory The spacecraft communicates with Earth largely through one high gain antenna but also carries two low gain antennas. Three radioisotope thermal generato rs provide power. Data taken by the instruments is stored on two solid-state recorders with a capacity of 4 gigab its. The spacecraft utilizes the Deep Space Network to downlink, on average, over one gigabit of data daily The Cassini spacecraft, prio r to 1993, was originally configured with a high-precision scan platform for the optical remote sensing instruments and a fields and particles turntable \(see Figure 2 scan platform and turntable were removed during development due to cost considerations.   The scan platform and turntable would have decoupled the interactions between the high-gain Figure 2.  Ori g inal Cassini spacecraft confi g uration with scan platforms Figure 1. Final Cassini spacecraft configuration 


  3 antenna pointing, the pointing of the fields and particle instruments and the remote sensing instruments significantly reducing the complexity of mission operations Cassini\222s twelve science instruments are grouped into three categories: Optical Remote Sensing, Fields/Particles/Waves and Microwave Remote Sensing. Fi i d ent i f i e s t h e science instruments and the locations of the distributed operations center for each inst rument.  The Cassini mission required operations on a global s cale. In the final spacecraft configuration, the instruments are all mounted to the body of the spacecraft. As mentioned above and will be further described below, this poses the single greatest challenge to operational complexity. The optical remote sensing instruments are roughly co-aligned so they can often collect data collaboratively. With suitable choice of the secondary pointing axis, the MAPS \(Magnetosphere & Plasma Science\instruments can also be simultaneously observing In addition to diverse scientific intent, the instrument teams are spread across the globe The Huygens probe payload also carried multiple instruments. Each of the six was designed to perform a different function during the descent through Titan\222s atmosphere. Among the measurements collected were chemical composition, images over a wide spectral range sounds from a microphone, and the impact deceleration, the index of refraction, temperature, thermal conductivity, heat capacity, speed of sound, and dielectric constant of the liquid\ material at the impact site 4  O PERATIONAL C HALLENGES  To maximize the science return from the Cassini-Huygens Mission, a number of operational challenges had to be overcome. These stemmed from a multitude of factors including the richness of the tour, limitations of the spacecraft, the inherent di fficulties of deep space constrained budgets, and distributed operations Intense Science Planning Once selected, the Cassini-Huygens prime mission tour was rich in competing multi-disc iplinary science opportunities Realizing these opportunities pr esented challenges in both allocating the observing time and in preserving the precise timing over the long elapsed time from science selection to execution Fairly allocating observing time required intense advance planning that was complicated by the requirement for consensus among the various science voices. The Project Science Group had a hand in decisions down to the level of definition of science operations processes. Each of the instrument teams and each of th e science disciplines wanted to protect their scientific interests by participating in the science selection. To accommodate all of these concerns the science planning process was segmented along science discipline lines. Regular tel econferences, which required a significant commitment of scientists\222 time, were required to resolve the contested facets of science integration Assignment of pointing time was particularly contentious Figure 3.  Cassini Science Instrument Teams 


  4 The geometry of many of the opportunities such as flybys is unique. Competition for discipline ownership of the unique opportunities as well as selec tion of one observation over another when multiple opportunities occurred simultaneously meant extensive negotiation for control of pointing. Since virtually all observation time is allocated to some science purpose, various margin enforcement mechanisms were required to preserve the precise timing of unique observations over the long times needed to develop the commanding. Several forms of timing adjustment such as ground movable blocks, live movable blocks, and live updates had to be employed to preserve the science design until execution. A final type of challenge was the extensive coordination required for very special science opportunities such as the ring plane crossi ng after SOI or the Huygens Probe interactions. These employed critical command sequences that took work-years to develop  Constraints of Spacecraft Resources A second set of challenges arose from the limitations of the Cassini spacecraft in realizi ng the science of which its instruments are capable. The single biggest impediment to efficient operations was elimin ation of the scan platform With the instruments body mounted, science pointing is inseparable from spacecraft poin ting. The pointing needs of the optical remote sensing instruments are frequently incompatible with the pointing needs of the fields and particles instruments. An example of the challenges of finding a pointing solution that avoids instrument and spacecraft constraints is show n in Figure 4. The shaded areas show the regions of th e spacecraft pointing space that are unavailable due to either boresight or radiator viewing constraints. The clear regions of the chart represent the only spacecraft pointing for which there are no violations of instrument or spacecraft flight rules  The red dots in this example show the pointing that is acceptable to achieve the science for this particular observation. This type of analysis was required for all of the science observations in the science plan. Once an attitude is selected an additional challenge is designing a spacecraft science slew that successfully takes the spacecraf t to the specified attitude without also violating constraints during the slew path. This required a suite of science planning tools to easily identify these problems early in the planning process Pointing time for optical navigation must also be carved from the science observation periods. Opportunity observation time is in direct competition with earth-pointed time for telemetry and commanding. The need to specifically allocate earth pointed time introduces sensitivity to DSN allocations and results in competition between science and Navigation requirements for tracking and orbital trim maneuvers \(OTMs\eving science pointing in a fashion that protects vulnerable spacecraft components such as the SRU and IR coolers significantly complicates pointing design and absorbs additional observation time in the construction of safe turns Negotiating a timeline that satisfies competing science priorities, which does not compromise spacecraft or instrument health and safety, and which also completes all operations that require earth point requires substantial staff repeated and expensive validation, and a heavy load of interaction via both meetings and email and websites. With much of the science support distributed around the world only limited hours in each day \(7am to 1pm pacific time were practical for telecons Beyond pointing constraint s, limitations on spacecraft resources constrain the multi-disciplinary science approach of which the instruments are capable. Not all instruments can be powered on simultaneously so power consumption must be actively managed. The instruments can deliver more data than the bus can pick-up and can produce more data than the solid state reco rder can store. This requires constant management of telemetry pick-up rates. The solid state recorder can record more than can be downlinked to a DSN 34 meter station during a nominal pass so storage management via data policing is required to manage data volume and enforce allocations. The shortage of storage space precludes protecting anyt hing but high value data against transmission failures, and preserving even this requires manipulation of playback and record pointers Allocation of on-board memory for commanding also faced competing demands. Space for many simultaneous programs simplifies real-time adjustments and additions such as vector updates and OTMs and simplifies reuse of frequently used science constructs such as mosaics. On the other hand reserving large sequence space accommodates the entire sequence in one uplink. As the prime mission progressed, more active management of the reaction wheel rates was required to increase the likelihood that they would Figure 4. Pointing Constraint Example 


  5 survive to end of mission. Achieving desired rate profiles was possible with either workforce or frequent biases which consume hydrazine. As hydrazine is a prime consumable, this required repeated studies of the hydrazine budget, trading science parameters such as Titan flyby altitude against spacecraft health against operations budget Validating the command sequence for correct management of all these shared, contested resources required extensive ground software. Because flight rules to protect sensors and instruments against limitati ons of spacecraft design are complex, their development was costly and lagged operations need for software checks. Since no single tool could check all resources with reasonable performance interfaces and model consistency among the various tools required considerable system engineering Communication with a Distant Spacecraft The preponderance of recent near-earth missions has obscured the complexities of flying in the outer solar system. Communication is limited by the constraint mentioned earlier of being off-earth pointed during the science observation periods. Not even all of the earthpointed pass time is availabl e, however, because of the lengthy one way light time on the order of 1.25 hours. For example, satisfying Navigation\222s needs for six hours of two way tracking leads to a nominal pass time of nine hours Scheduling of sequence uplink radiation, real-time commands, and maneuvers must be squeezed into windows shortened at both beginning and end to allow for confirmation of communication Communication restrictions also affect monitoring of spacecraft health and safety. Si nce engineering data is not continuously available, it too must be stored in the limited on-board storage space Budget Constraints In addition to compromising the operability of the spacecraft, budget considerations resulted in deferred development of flight software and the ground system. Even when finally begun, constrained development budgets meant inadequate tool support was available when activity intensified. Development sche dules were not adequate to provide needed tools for science planning operations that preceded arrival at Saturn. Oper ational readiness tests were hampered by lack of ground system support. As operations expanded, solicitation of requirements for the next iteration of development then competed with on-going operations and initial development was still in progress when the need for improved models due to flight experience arose Specification of instrument flight rules was not completed in time to have those rules incorporated into tools that support creation of a conflict-free science plan. Essential operations were simply not feasible in light of missing ground system capabilities. To bri dge the gap, ad hoc tools were quickly developed outside the formal process. While contributing to early science data return, these lacked system engineering and formal validation leading to inconsistent results across tools. Maintenance was more difficult as a result of the missing formalism in development. Lack of user support documentation made training more difficult and turnover more costly Distributed Operations Respecting the instrument teams\222 desires to operate from their home institutions, Cassini-Huygens embarked on a brave experiment in distributed operations. In addition to the science trades and resource allocation issues that have already been described, the responsibility for command construction and validation from the instrument perspective was also dispersed. With the scan platform removed and all of the instruments consequently body mounted commanding the instrument to th e target of interest became spacecraft commanding. As a result, the science designers required an unanticipated depth of spacecraft knowledge and were intimately involved in the step by step sequence development process. The breadth of knowledge thus required has significantly lengthened the time it takes to fully qualify ops personnel. Each instrument team also had to be cognizant of the ways in which their commanding could harm other instruments or degrade other teams science. Extensive suites of flight rules were written to enforce this mutual respect, and then had to be provided in software to all the teams. The sequence development process became highly iterative because of detection of violations at the merged level that were not apparent to the science teams producing commands. For example excessive heating of the infrared coolers may result from cumulative heating over several observations no one of which exceeds the constraints. These iterations greatly expanded the implementation to execution ratio, so that six sequences were simultaneously in some phase of development or execution. To isolate the individually designed science observations from problems in neighboring observations designed by another team in another locale, the pointing concept employed the notion of a waypoint. Each observation began and ended its pointing control at this designated attitude so that if any one had to be removed the integrity of the others was unchanged Another challenge immediately evident as operations intensified was providing all the participants\227distributed across time zones and nationalities\227a universally accessible view of the current state of the science plan Meeting this need required the addition of a sophisticated web-accessible database, which while quite successful was a costly component of the Cassini ground system. Providing access to the operations syst em across national boundaries entailed a substantial investment to comply with ITAR restrictions The overlap in functionality between JPL and the distributed sites resulted in redundancy in ground systems which complicated update and evolution of the overall 


  6 system. More and complicated interfaces were required between applications in different systems, between players at different sites, and across networks and firewalls. With command production distributed, project software for pointing and sequence validation had to be made available to the instrument operations teams on a variety of platforms and extensive training in use of this software was required More dissonant voices weighed in on tool requirements and the Project Science Group played a disquieting role in process and ground system development Although the explosion of technology in the broader world of the Internet and telecommunications has made distributed operations possible, the mission operations system was challenged in communication, coordination, training ground system, and security. The scope and complexity of interfaces and coordination for sequence development validation, and execution incr eased dramatically. Also significant expansion in project IT capabilities was necessary to handle the expansion of web, email managements, and teleconferencing capabilities 5  T HE M ISSION O PERATIONS S YSTEM  Development Process The Cassini-Huygens mission environment represented a significant extension beyond the model of previous deep space missions with a JPL centered operations teams and its homogenous ground data system. Reflecting both the rapid advancement of technology and the distributed operations paradigm, Cassini operations depended on a set of integrated systems. The opera tions team members were not co-located. The ground system included remote users and remote machines, multiple system architectures, and fewer specialized operators. Devel opment was spread over more than a decade. [3 Unlike previous missions, the operations environment was by design, not done at launch. Pre-launch development was limited to team members and data system capabilities required for launch and minimal activity during cruise Other development, including all tour capabilities not needed for the flight system, was deferred until after launch as a cost saving measure. Deferred development was not limited to the ground system. Some flight system tour capabilities were also delayed. For example, the flight software for controlling the RWAs was not available until just before Jupiter flyby During the seven years of cruise, capabilities for tour such as science pointing design, f light rules for spacecraft and instrument protection, and on-board modules, e.g. mosaics for science observing, were slated for development Unfortunately, budgets continued to be constrained and did not reflect the growth in complexity due to distributed operations. Changes in requirements due to deletion of the scan platform took several years to be fully understood. The mismatch between requirements and staffing and funding profiles impeded the timely delivery of tools and limited the use of cruise for training and check-out. A number of ad hoc tools were also develope d, which provided essential capabilities for generation of c onflict-free science timelines but complicated interfaces a nd maintenance in the overall ground system. More than ninety tools were developed or adapted not including those resident solely in a PI-led instrument ground system. Not all of these survived the tour phase Once at Saturn, the developm ent teams were significantly reduced. Additional necessary capabilities were added on a best efforts basis. For example, a system was instituted to mirror the input files required by the software across all of the locations of its use and to control configuration on a sequence-by-sequence basis. Also, the Automated Sequence Processor \(ASP\was introduced to allow team members to command their instrument without intervention by the JPL sequence team. Maintenance and bug fixes required ongoing effort and both flight and ground software required updates to respond to discoveries in the Saturnian environment and to failures or degraded capabilities Uplink Process The uplink process produced an integrated, validated and uplinkable set of commands for all science and engineering activities for an entire sequence, which lasted approximately 40 days. Two broad steps were used to create this command-level sequence product: the Science Planning process and the Sequencing process. The key result of the Science Planning process is th e Science Operations Plan SOP\which is a two-fold product. First, the SOP is a highlevel plan of science and engineering activities with the allocation of the shared sp acecraft resources. Second, the SOP is also a command-level product containing the detailed commands for all of the shared spacecraft subsystems necessary to execu te the science plan. The SOP is delivered to the Sequencing process for final command generation and validation prio r to sequence radiation and execution. The steps in the Sc ience Planning process were Segmentation, Integration, Aftermarket, and SOP Update Note: The Aftermarket process is a term that had a specific history and meaning to the Cassini Mission and would warrant a whole section in itself. Suffice it to say that the Aftermarket process is the st ep in the process where the science plan can be re-integra ted to deal with changes in science intent or spacecr aft/instrument performance changes\gure 5 shows an overview of the Cassini uplink process flow Because of the inherent comple xity of the Cassini Mission the planning process began 4 years prior to the start of the prime mission. A high-level timeline with a description of the key steps in the uplink process, the people involved, and the goal of each step is shown in Table 1 The SOP development schedule called for the integration and 


  7 implementation step to be complete a few months after Saturn Orbit Insertion \(SOI\s product would then be archived and later updated prior to sequence execution. This schedule was driven by two factors: 1\he Project Science Group\222s desire to complete the bulk of the SOP before a significant amount of science da ta started to be received from the spacecraft due to worklo ad considerations, and 2 the level of complexity and validation of the sequences required a lengthy implementation processes Once sequence execution neared the archived SOP product was retrieved, dusted off, and updated to reflect changes to spacecraft or instrument perform ance, trajectory changes, or changes to science intent. This final sequencing step begins about 20 weeks before sequence execution. The long leadtime needed for these final steps in the process results in the Flight Team having to support up to 6 overlapping sequencing processes at one time. In this section we will discuss in detail each step in the uplink process Integration 227 After the Project Science Group selected the final prime mission Tour SOP integration began, in which the shared resources were ne gotiated and allocated to the science teams. The key shared resources of the Cassini spacecraft were pointing, data volume, and power. To facilitate the integration of a conflict free timeline, the four year Cassini tour was broken into more manageable pieces or segments. The segmentation process allocated pieces of the tour to the different science disciplines \(Rings, Saturn Titan, Icy Satellites, and the Magnetosphere\ased on the geometric opportunities available in the selected tour. The smaller segments made the integration process more manageable and made the negotiation process focused on a discipline or target. This allowed the science teams to organize themselves according to their specialties, interests and the capabilities of their instruments At this point, the segments were defined and allocated to the different target working teams \(disciplines\ integrate. The science, engineering and navigation teams entered their requests for observations or engineering events into the Cassini Information Management System \(CIMS\abase CIMS provided configuration management of the science plan throughout the life-cycle of the uplink process. These initial requests were the basis for the start of segment integration Producing a conflict free pointing timeline in some ways is very straightforward once the constraints are understood Some of the questions answered during integration were the following:  What are the pr imary and secondary spacecraft attitudes required for the observations? Do these attitudes satisfy the needs of all the instruments collecting data at that time? Are the radiators in any danger in this configuration And what turn times are requi red between the targets of interest? The science teams negotiated the pointing based on science priorities. Since there are five disciplines, twelve instruments, and three dozen targets of interest in the Saturnian system, keeping the science priorities clear inside any one segment was a challenge Disciplines needed to be aware of what was happening in other segments and the Project Scientist had to be cognizant of what was going on across all the segments. Th e integrated, conflict-free pointing profile was managed and maintained in the CIMS database Once a pointing profile was negotiated, appropriate telemetry modes, data volume and operational power modes were specified in the plan. After estimating the total amount of data volume to be stored on the SSRs, the science teams were asked to modify their requests to fit the total available space. The SSR could be cleared off only when the Cassini spacecraft was earth pointed, roughly 9 hours out of each Figure 5. Cassini Uplink Process Flow 


  8 24. Managing the load state of SSR between data acquisition and playback was one of the major tasks of the integration process. The n eed for a specialized SSR Management Tool \(SMT\ot anticipated during initial software development, but was recognized during the Jupiter flyby experience. Suffi cient resources were then allocated to create this tool for orbital operations The power modes were independent of the telemetry mode decisions and could be worked in parallel. One simplifying paradigm on Cassini was the predefinition of power envelopes, called opmodes, which were tested thoroughly once and then reused repeatedly Implementation 227 In SOP Implementation, the commands implementing the science plan\227pointing and other shared resources\227were generated, assembled, and checked. With body mounted instruments and distributed operations spacecraft pointing was implemented piecemeal by the owners of the pointing time. The collective body of command developers for a sequence was called the Sequence Virtual Team, which persisted only for the creation and execution of that sequence Although project software was supplied to generate and check commands, not all violations can be detected in isolation. So iteration was required to eliminate all flight rule and constraint violations. After merging the commanding from all producers, problems and errors were reported and corrections solicited by the Science Planning Virtual Team Lead. During this phase, less stringent configuration management was used to facilitate needed Update integrated plan based on new discoveries, science data analysis spacecraft/instrument performance changes, etc  Science Planning Science Community some Spacecraft, some Mission Planning Aftermarket update integrated plan 20 weeks before execution Sequencing  validate entire sequence SOP Update update  basic sequence design Implementation  validate basic sequence design Integration negotiate best science compromise Tour Design  maximize science opportunity What \(goals Details Who When 2 validation cycles to create a complete sequence with all commands in place; complexity of spacecraft and plans make this a challenge Sequence Lead Science Operations Spacecraft Team \(some Science Planning 10 weeks before execution A validation cycle to update the skeleton sequence to any updated science compromises and/or new discoveries Science Planning Science Operations Spacecraft Team, \(some Mission Planning 15 weeks before execution 2 validation cycles to get a \221flyable\222 skeleton sequence of the shared resources in place; distributed operations makes this a challenge Science Planning Science Operations Spacecraft Team \(some Mission Planning 2 years before PM Break up entire mission by science discipline and negotiate shared resources \(pointing, power telemetry, and data volume scan platform makes this a Science Planning Science Community some Spacecraft, some Mission Planning 4 years before PM Science experiment trade-offs navigation and uplink development capabilities Science Community Mission Planning \(some Spacecraft 10 years before Prime Mission Table 1. Cassini Uplink Development Timeline 


  9 corrections. With several concurrent development processes, ops personnel could be members of more than one virtual team simultaneously. Various strategies such as sequence specific email aliases and automated software configuration were devel oped to ease confusion from sequence to sequence Aftermarket and SOP Update 227Since the initial round of integration and implementation was begun two years before reaching Saturn, a two-step update phase was included to incorporate new discoveries, respond to instrument performance changes, and design to the latest navigation ephemerides. The record of planned activities from SOP was retained in the CIMS database. During Aftermarket, the previous integration was revisited and revised. SOP Update during which the commanding for pointing and for management of shared resources such as power and data volume was reworked and revalidated, followed Aftermarket Sequencing 227 The final sequence development phase Science and Sequence Update Process \(SSUP began 10 weeks before start of execu tion. The commanding carried forward from SOPU received its final refinements and validation. Instrument internal commanding was added during this stage of development, expanding the roster of participants as the focus shifted from science design to instrument operation. The vector commands for attitude control were also generated and merged into the sequence providing the first realistic estimate of sequence size Since the sequence contains tens of thousands of commands, ensuring its validity was laborious. Because the command sequence represents merged commanding from each of the instruments a nd from each of the spacecraft subsystems, configuration ma nagement was required to insure that all parties were aware of changes potentially impacting them and that no changes were made without appropriate validation. Late in this stage of development changes were restricted to those related to maintaining flight assets health and safety. Novel or particularly complex activities were simulated in one or more of the available testbeds. The highest fide lity modeling was accomplished with a hardware-in-the-loop simulator, the Integrated Test Laboratory \(ITL\with engineering versions of the flight processors and flight software the same as on-board the spacecraft Over the lengthy time to plan the activities and develop the commands, the precise timing of geometric opportunities sometimes shifted. Several constructs to accommodate those shifts were introduced. In the one employed during SSUP called a ground movable block, a cluster of observations was shifted together within a window to reflect a timing change in a key event such as closest approach to a body Execution 227Uplink of the background sequence and the loads of instrument expanded blocks required several DSN passes since the files were large and had to be verified once on board. Days that included other Earth-pointed activity such as OTMs were avoided. This expanded the overlap of the old and new background sequences over enough days that careful memory management was required to fit both in onboard memory. In some cases, the new sequence was too large and needed to be split in to two pieces with the second uplinked as the first piece neared completion Once the sequence was executi ng, additional real-time commands and mini-sequences were uplinked for timing adjustments, OTMs, and other engineering activities requiring state verification be fore issuance. Instrument internal commands could be also be uplinked directly without involvement of the sequence team at JPL using the Automated Sequence Processor \(ASP During execution, there were two ways of accommodating late changes to timing or geometry. One, a live moveable block, was similar to the ground version except that the size of the timing shift was not determined until after the sequence had begun executing. The other, called a live vector update, redirected the pointing in inertial space by redefining the vectors that control attitude. Although this was a straightforward mechanism for altering pointing in response to later, better knowledge of spacecraft position the process took several days and considerable effort. So extensive analysis was require d to carefully place potential updates where they could be most effective 6  L ESSONS L EARNED  Understanding the operational challenges to maximizing Cassini science return and the successful techniques employed in overcoming those challenges should be of value to other deep space science missions, including the next Outer Planets flagship mission. Some of the lessons cover design decisions, both those that facilitated operations and should be carried forward for future consideration and those that complicated operations and should be avoided Others reflect ways in which flight experience differed from expectations. The discussion with resulting recommendations for future missions is divided into three categories: flight system, ground system, and programmatic Flight System Operational modes 227 Spacecraft operational modes were used to define a limited number of power mode states for the instruments and engineering subsystems. The states were developed in conjunction with project science and the engineering office to enable synergistic and cooperative science data collection. The use of operational modes eliminated the need to perform unique thermal modeling on a sequence-by-sequence basis. The thermal and power configurations for each of th e limited number of operational modes were fully tested only once for operational use. As such, there was no need to va lidate and check the power and 


  10 thermal state of the spacecraft during sequence development. However, on a very limited number of occasions, unique power m odes were necessary to accomplish the science data acquisition plan. In these situations, thermal modeling was necessary during sequence development. The a priori restriction on the use of unique power modes was limited to 5% of the total power modes used throughout the mission. In reality, the operational experience was about 1 Telemetry Modes 227 The volume of science data from the instrument is a function of the science data pickup rates specified for each instrument The science instruments can easily exceed the total bandwid th capabilities for the flight system, so the maximum data pickup rates need to be limited depending on the acquisition of the science plan The Cassini mission restricted th e instrument data rates by developing a limited number of telemetry modes where the maximum data pickup rate for each instrument is specified Project science worked with the science teams to develop the data pickup rate for each telemetry mode based on the synergistic science data collection Memory Management 227 The on-board memory management for Cassini significantly simplifies the managing of backgrounds seque nces and mini-sequences The flight software has the capability to run 64 different programs \(sequence, delayed action commands, etc once. This significantly simplifies the development and coordination required for the live updates and OTM processes. Also, the on-board memory management allows for sequences that are too large to fit in the on-board memory to be split into pieces Guidance and Control 227 The AACS subsystem uses an Internal Vector Propagation \(IVP\for pointing the spacecraft at the science targets of interest. The ephemerides for the spacecraft and the various science targets are stored as polynomial vectors and propagated on board the spacecraft for easy retrieval a nd updating. This approach significantly simplifies the ability to perform live pointing vector updates during sequence execution when the spacecraft knowledge to better known. An update to a single vector, or a couple of vectors is all that is needed to correctly target upcoming science observations Command and Data Handling 227 The Command and Data Subsystem \(CDS features that simplified operations. Among these were onboard science instrument data policing, ability to remove bad solid-state recorder \(SSR\odules, and a variety of onboard science modules that control science pointing commands \(e.g., limb scans, ring tracking, mosaics\and their corresponding instrument triggers. One of the more powerful capabilities on-board th e spacecraft was the data policing, which controls the amount of science instrument data that can be recorded on-board the solid state \(SSR recorder. Once data volume wa s allocated to the science instrument teams on a daily basis in the planning process data policing prevented any team from using more data than allocated if compression or instrument internal commanding goes awry. This eliminates any need for ground intervention to prevent SSR overruns during sequence execution High-priority science playback 227 Insuring receipt of highpriority science data in the event of a DSN station problem requires a priori commanding in the background sequence for dual, playbacks of this data. This requires a considerable amount of planning and SSR pointer management and commanding to achieve the protection of this data. A filebased SSR, and/or a CCSDS File Delivery Protocol \(CFDP capability would have simplifie d the redundant playback of high-priority science data No Scan Platform 227 The lack of a scan platform significantly increased the operations complexity of the mission. Without a scan platform the pointing of the optical remote sensing instruments was coupled with the pointing of the fields and particles instruments. This more than doubled the competition for th e spacecraft pointing. In addition, the total number of pointing constraints \(radiators and boresights\ncreased, dramatically reducing the amount of the 4 002 steradians of the celestial sphere that is available for spacecraft pointing. Th is required significant negotiations of the spacecraft attitude, both primary and secondary, during the science integration and implementation process Navigation 227 The Cassini spacecraft is navigated to a specific B\267T and B\267R for each targeted flyby Fixing the targeted flyby tie points increased the overall delta-V required to fly the mission but significantly simplified the science operations involved with planning the science observations taken with 261 30 minutes from closest approach. The trajectory was allowed to deviate between the targeted flyby tie-points, which required pointing vector updates for science observations outside of the targeted flyby \(see Guidance and Control above for a discussion of live pointing vector updates Another simplified operational approach used by Cassini is the just-in-time development of the Orbit Trim Maneuvers OTMs\e OTMs are built using mini-sequences that are overlaid and executed during the earth-pointed downlink periods planned in the background sequence Ground System  Science Operations System 227 A critical planning tool used to enable distributed operations was the Cassini Information Management System \(CIMS\This tool uses a web-based interface to the Cassini database that contains the current state of the integrated scien ce and engineering plan. CIMS is used throughout the sequencing life cycle on the mission from initial planning through execution. This system allowed the science instrument teams from around the world 


  11 to request, review, and propose changes to the current state of the science plan Distributed Operations 227 Cassini distributed all aspects of the instrument operations to the science teams. Science Teams were required to develop the spacecraft commanding for pointing the spacecraft. Th is significantly complicated the interfaces and coordination required by the JPL science and sequencing teams. The distribution of internal instrument commanding and monitoring instrument health and safety worked well. Dedicated full-time operations personnel were required at all instrument sites. The liaison between the distributed sites and JPL required definition of a strong JPL Investigation Scientist \(i.e., Experiment Representative\le Distributed operations is a two-edged sword. Scientists personally worked operations and were better able to optimize for their science objectives. Their insight provided the feedback necessary to quickly respond to science discoveries in the science selection and uplink processes This allowed the operations team to capitalize on truly extraordinary opportunities to a degree not thought possible However, this was at the cost of doing science analysis and publishing science results Software Development 227 The Cassini mission deferred most of its ground software development until post launch. In fact, considerable effort was spent accelerating the development of the tools required to plan the Jupiter flyby observations in 2001. For the start of the science integration for Cassini\222s prime mission, many of the ground software planning tools were immature or unavailable. To compensate, homegrown tool development occurred at the instrument sites and within science planning. System engineering of these types of ground software tools was lacking. A better paradigm would have been to develop the operations and ground system\222s architecture, requirements models, and software to a level sufficient to support operations pre-launch. Sufficient project resources needed to be applied to Phase B/C/D development. The science planning tools should be developed to a sufficient level during these phases such that th ey can be used as part of evaluating the ground and flight system requirements and capabilities. Based on this evaluation, refinements could be made during cruise and throughout the mission to the unified ground and flight system architecture and software requirements Programmatic  Project Science 227The orbiter consists of 8 Principal Investigator \(PI\struments and 4 Facility Instrument with corresponding Team Leads. In a ddition, there are 5 different science discipline teams: Rings, Saturn, Titan, Icy Satellites and Magnetosphere. The Project Science leader ship needed to be highly involved in the tactical and strategic science planning activities. The consensus building culture used on Cassini was time consuming. The Project Science support staff should be funded adequately to allow the Project Scientist to participate in the integration process. Clear Project Science guidelines are very helpful Instruments 227 Instrument Flight Rule development must be mature pre-launch. Instruments should be designed to minimize impacts on the operations of the other instruments, e.g., radiator placement. Data compression internal to instruments is vital. For Cassini, the science instruments had internal sequencing memory for storing instrument commanding for upcoming sequence. This allowed the science teams th e ability to send real-time noninteractive instrument commands that bypass the sequencing process by using the Automated Sequence Processor \(ASP  In-flight Testing 227 The targeted gravity assist flybys provided a unique opportunity to exercise the ground system on realistic science data acquisition scenarios that simulates the operational environment during the Tour phase of the prime mission. This also had the advantage of providing the science instrument teams an opportunity to acquire useful science data for the purposes of instrument checkout and science data analysis. The in-flight exercises should use the processes, procedures, software, and ground system capabilities in the same manner, to the extent possible, as will be used during Tour and Orbital operations The entire flight team \(mission planning, science planning sequencing, spacecraft, naviga tion, and science teams should be fully engaged to provide the maximum benefit to the Project 7  C ONCLUSION  Even though Cassini was a NASA flagship mission maximizing the science return was a challenge to science planning operations. Decisions aimed at saving both prelaunch and operations costs added considerable complexity to both the spacecraft and the ground system. Among the key ones were removing the scan platform, opting for distributed operations rather than co-location, and delaying development of some flight software and most of the ground system until after launch Understanding the operational challenges to maximizing Cassini science return and the successful techniques employed to overcome those challenges as presented in this paper should be of value to other deep space science missions.  Future missions should carefully consider the following advice 200  Pay careful attention to operational scenarios in development cost saving decisions, both spacecraft and ground. Additional, more sophisticated commanding constructs may be required in operations to compensate for lack of spacecraft capabilities. Ground management of stressed or 


  12 degraded spacecraft components will be labor intensive   R EFERENCES    N. Vanderm ey and B G. Paczkowski 223The C a ssi ni Huygens Mission Overview,\224 2006 AIAA SpaceOps Conference Proceedings, June 19-26, 2006   Andrew M i shki n and B a rbara Larsen 223Im p l e m e nt i ng Distributed Operations: A Comparison of Two Deep Space Missions,\224 2006 AIAA SpaceOps Conference Proceedings, June 19-26, 2006 3 Barb ara Larsen 223Bu ilt Bu t No t Used Need ed  Bu t No t Built: Ground System Guidance Based On CassiniHuygens Experience,\224 2006 AIAA SpaceOps Conference Proceedings, June 19-26, 2006   Spi l k er, Li nda J \(edi t o r o  a R i nged Wold\224,NASA SP-533, 1997  Jennifer Long Maxwell, W illiam M Heventhal, III, and Shahram Javidnia, \223The Cassini-Huygens Sequence Development Process\224, 2006 AIAA SpaceOps Conference Proceedings, June 19-26, 2006   Paczkowski  B G, \223C assi ni Sci e nce Pl anni ng Process\224 2004 AIAA SpaceOps Conference Proceedings, May 17 21, 2004 200  Recognize that lack of margin in any resource required for science return will require compensatory staffing. Pr edefined, prevalidated options for resource management such a power modes can compensate. Tools that validate resource allocation are essential 200  Anticipate alternative costs for failing to meet MOS development schedules. The ground system needs to have reached sufficient maturity to support key operations tasks before those tasks commence 200  Distributed science operations introduces delays and complications to sequence development, which must be managed in science planning. System engineering will need to deal with overlap in and conflict between ground systems 200  Acknowledge that complexity in any form\227 spacecraft design, science objectives, MOS architecture\227may be managed to enhance science return but the science planning operations must be funded and structured to manage that complexity The processes to develop science commanding will be lengthy and highly iterative In the end, with an appropriate funding profile, adequate and timely staffing, and effective processes and tools all the facets of mission complexity can be managed to extract amazing science return 8  A CKNOWLEDGEMENTS  The authors would like to acknowledge the dedication and hard work done by the Cassini-Huygens Flight and Science Teams. Without their efforts the unrivaled science collected by the Cassini mission would not have been achieved This work was performed at the Jet Propulsion Laboratory California Institute of Technol ogy, under contract with the National Aeronautics and Space Administration  251 2008 California Institute of Technology. Government sponsorship acknowledged 


  13 B IOGRAPHY  Brian Paczkowski is currently the Deputy Section Manager of the Planning and Execution Section within the Systems and Software Division at JPL. Prior to that he spent 9 years as the Cassini Science Planning Manager responsible for the development and implementation of the Science Operations Plan. Prior to Cassini, he was the Science Planning and Operations Team Chief for the Galileo Mission to Jupiter. He has also been involved with the pre-launch development of the science instruments on Galileo, Comet Rendezvous and Asteroid Flyby \(CRAF\ and Cassini missions. He has a BS in Astronomy from Villanova University and did graduate studies in Astronomy at Ohio State University  Barbara Larsen  is the Mission Operations System Engineer for the Cassini Mission. She is also on the science planning staff and previously worked in system engineering for the Mission Sequence Subsystem. She has a MS in Mathematics from California State University Long Beach and a BS in Mathematics from USC Trina Ray  is currently the Titan Orbiter Science Team \(TOST\ co-chair and the Science System Engineer for the Project Scientist for Cassini. She has been working on the Cassini Mission since before launch as an instrument operations lead for the Radio Science Team, and then as part of the Science Planning Team supporting Titan integrati on and sequence development She has a MS in Astronomy from San Diego State University and a BS in Physics, Astronomy option from CSUN  


  14  


 15 7  B.-N. Vo and W.-K. Ma, \223The Gaussian Mixture Probability Hypothesis Density Filter,\224 IEEE Trans Signal Processing Vol. 54, pp. 4091-4104, November 2006 8  B. Ristic, S. Arulampalam, and N. Gordon Beyond the Kalman Filter Artech House, 2004 9  Y. Bar-Shalom, X. Rong Li, and T. Kirubarajan Estimation with Applications to Tracking and Navigation, New York: John Wiley & Sons, pg. 166 2001 10  X. R. Li, Z. Zhao, and V. P. Jilkov, \223Estimator\222s Credibility and Its Measures,\224 Proc. IFAC 15th World Congress Barcelona, Spain, July 2002 11  M. Mallick and S. Arulampalam, \223Comparison of Nonlinear Filtering Algorithms in Ground Moving Target Indicator \(GMTI Proc Signal and Data Processing of Small Targets San Diego, CA, August 4-7, 2003 12  M. Skolnik, Radar Handbook, New York: McGrawHill, 1990 13  A. Gelb, Editor Applied Optimal Estimation The MIT Press, 1974 14  B. D. O. Anderson and J. B. Moore Optimal Filtering  Prentice Hall, 1979 15  A. B. Poore, \223Multidimensional assignment formulation of data ass ociation problems arising from multitarget and multisensor tracking,\224 Computational Optimization and Applications Vol. 3, pp. 27\22657 1994 16  A. B. Poore and R. Robertson, \223A New multidimensional data association algorithm for multisensor-multitarget tracking,\224 Proc. SPIE, Signal and Data Processing of Small Targets Vol. 2561,  p 448-459, Oliver E. Drummond; Ed., Sep. 1995 17  K. R. Pattipati, T. Kirubarajan, and R. L. Popp, \223Survey of assignment techniques for multitarget tracking,\224 Proc  on Workshop on Estimation  Tracking, and Fusion: A Tribute to Yaakov Bar-Shalom Monterey CA, May 17, 2001 18  P. Burns, W.D. Blair, \223Multiple Hypothesis Tracker in the BMD Benchmark Simulation,\224 Proceedings of the 2004 Multitarget Tracking ONR Workshop, June 2004 19  H. Hotelling, \223The generalization of Student's ratio,\224 Ann. Math. Statist., Vol. 2, pp 360\226378, 1931 20  Blair, W. D., and Brandt-Pearce, M., \223Monopulse DOA Estimation for Two Unresolved Rayleigh Targets,\224 IEEE Transactions Aerospace Electronic Systems  Vol. AES-37, No. 2, April 2001, pp. 452-469 21  H. A. P.  Blom, and Y. Bar-Shalom, The Interacting Multiple Model algorithm for systems with Markovian switching coefficients IEEE Transactions on Au tomatic Control 33\(8  780-783, August, 1988 22  M. Kendall, A. Stuart, and J. K. Ord, The Advanced Theory of Statistics, Vol. 3, 4th Edition, New York Macmillan Publishing, pg. 290, 1983 23  T.M. Cover and P.E. Hart, Nearest Neighbor Pattern Classification, IEEE Trans. on Inf. Theory, Volume IT-13\(1 24  C.D. Papanicolopoulos, W.D. Blair, D.L. Sherman, M Brandt-Pearce, Use of a Rician Distribution for Modeling Aspect-Dependent RCS Amplitude and Scintillation Proc. IEEE Radar Conf 2007 25  W.D. Blair and M. Brandt-Pearce, Detection of multiple unresolved Rayleigh targets using quadrature monopulse measurements, Proc. 28th IEEE SSST March 1996, pp. 285-289 26  W.D. Blair and M. Brandt-Pearce, Monopulse Processing For Tracking Unresolved Targets NSWCDD/TR-97/167, Sept., 1997 27  W.D. Blair and M. Brandt-Pearce, Statistical Description of Monopulse Parameters for Tracking Rayleigh Targets  IEEE AES Transactions, Vol. 34 Issue 2,  April 1998, pp. 597-611 28  Jonker and Volgenant, A Shortest Augmenting Path Algorithm for Dense and Sparse Linear Assignment Problems, Computing, Vol. 38, 1987, pp. 325-340 29  V. Jain, L.M. Ehrman, and W.D. Blair, Estimating the DOA mean and variance of o ff-boresight targets using monopulse radar, IEEE Thirty-Eighth SSST Proceedings, 5-7 March 2006, pp. 85-88 30  Y. Bar-Shalom, T. Kirubarajan, and C. Gokberk 223Tracking with Classification-Aided Multiframe Data Association,\224 IEEE Trans. on Aerospace and Electronics Systems Vol. 41, pp. 868-878, July, 2005   


 16 B IOGRAPHY  Andy Register earned BS, MS, and Ph  D. degrees in Electrical Engineering from the Georgia Institute of Technology.  His doctoral research emphasized the simulation and realtime control of nonminimum phase mechanical systems.  Dr. Register has approximately 20 years of experience in R&D with his current employer, Georgia Tech, and product development at two early-phase startups. Dr. Register\222s work has been published in journals and conf erence proceedings relative to mechanical vibration, robotics, computer architecture programming techniques, and radar tracking.  More recently Dr. Register has b een developing advanced radar tracking algorithms and a software architecture for the MATLAB target-tracking benchmark.  This work led to the 2007 publication of his first book, \223A Guide to MATLAB Object Oriented Programming.\224  Mahendra Mallick is a Principal Research Scientist at the Georgia Tech Research Institute \(GTRI\. He has over 27 years of professional experience with employments at GTRI \(2008present\, Science Applications International Corporation \(SAIC Chief Scientist \(2007-2008\, Toyon Research Corporation, Chief Scientist 2005-2007\, Lockheed Martin ORINCON, Chief Scientist 2003-2005\, ALPHATECH Inc., Senior Research Scientist 1996-2002\, TASC, Principal MTS \(1985-96\, and Computer Sciences Corporation, MTS \(1981-85 Currently, he is working on multi-sensor and multi-target tracking and classification bas ed on multiple-hypothesis tracking, track-to-track association and fusion, distributed filtering and tracking, advanced nonlinear filtering algorithms, and track-before-detect \(TBD\ algorithms He received a Ph.D. degree in  Quantum Solid State Theory from the State University of New York at Albany in 1981 His graduate research was also based on Quantum Chemistry and Quantum Biophysics of large biological molecules. In 1987, he received an MS degree in Computer Science from the John Hopkins University He is a senior member of the IEEE and Associate Editor-inchief  of the Journal of Advances in Information Fusion of the International Society of Information Fusion \(ISIF\. He has organized and chaired special and regular sessions on target tracking and classific ation at the 2002, 2003, 2004 2006, 2007, and 2008 ISIF conferences. He was the chair of the International Program Committee and an invited speaker at the International Colloquium on Information Fusion \(ICIF '2007\, Xi\222an, China. He is a reviewer for the IEEE Transactions on Aerospa ce and Electronics Systems IEEE Transactions on Signal Pr ocessing, International Society of Information Fusion, IEEE Conference on Decision and Control, IEEE Radar Conference, IEEE Transactions on Systems, Man and Cybernetics, American Control Conference, European Signal Processing Journal and International Colloquium on Information Fusion ICIF '2007   William Dale Blair is a Principal Research Engineer at the Georgia Tech Research Institute in Atlanta, GA. He received the BS and MS degrees in electrical engineering from Tennessee Technological University in 1985 and 1987, and the Ph.D. degree in electrical engineering from the University of Virginia in 1998. From 1987 to 1990, he was with the Naval System Division of FMC Corporation in Dahlgren, Virginia. From 1990 to 1997, Dr Blair was with the Naval Surface Warfare Center, Dahlgren Division NSWCDD\ in Dahlgren, Virg inia. At NSWCDD, Dr Blair directed a real-time experiment that demonstrated that modern tracking algorithms can be used to improve the efficiency of phased array radars. Dr Blair is internationally recognized for conceptualizing and developing benchmarks for co mparison and evaluation of target tracking algorithms Dr Blair developed NSWC Tracking Benchmarks I and II and originated ONR/NSWC Tracking Benchmarks III and IV NSWC Tracking Benchmark II has been used in the United Kingdom France, Italy, and throughout the United States, and the results of the benchmark have been presented in numerous conference and journal articles. He joined the Georgia Institute of Technology as a Se nior Research Engineer in 1997 and was promoted to Principal Research Engineer in 2000. Dr Blair is co-editor of the Multitarg et-Multisensor Tracking: Applications and Advances III. He has coauthored 22 refereed journal articles, 16 refereed conference papers, 67 papers and reports, and two book chapters. Dr Blair's research interest include radar signal processing and control, resource allocation for multifunction radars, multisen sor resource allocation tracking maneuvering targets and multisensor integration and data fusion. His research at the University of Virginia involved monopulse tracking of unresolved targets. Dr Blair is the developer and coordinator of the short course Target Tracking in Sensor Systems for the Distance Learning and Professional Education Departmen t at the Georgia Institute of Technology. Recognition of Dr Blair as a technical expert has lead to his election to Fellow of the IEEE, his selection as the 2001 IEEE Y oung Radar Engineer of the Year, appointments of Editor for Radar Systems, Editor-InChief of the IEEE Transactions on Aerospace and Electronic Systems \(AES\, and Editor-in- Chief of the Journal for Advances in Information Fusion, and election to the Board of Governors of the IEEE AES Society,19982003, 2005-2007, and Board of Directors of the International Society of Information Fusion   


 17 Chris Burton received an Associate degree in electronic systems technology from the Community College of the Air force in 1984 and a BS in Electrical Engineering Technology from Northeastern University in 1983.  Prior to coming to the Georgia Institute of Technology \(GTRI\ in 2003, Chris was a BMEWS Radar hardware manager for the US Air Force and at MITRE and Xontech he was responsible for radar performance analysis of PAVE PAWS, BMEWS and PARCS UHF radar systems Chris is an accomplished radar-systems analyst familiar with all hardware and software aspects of missile-tracking radar systems with special expertise related to radar cueing/acquisition/tracking for ballistic missile defense ionospheric effects on UHF radar calibration and track accuracy, radar-to-radar handover, and the effects of enhanced PRF on radar tracking accuracy.  At GTRI, Chris is responsible for detailed analysis of ground-test and flight-test data and can be credited with improving radar calibration, energy management, track management, and atmospheric-effects compensation of Ballistic Missile Defense System radars   Paul D. Burns received his Bachelor of Science and Masters of Science in Electrical Engineering at Auburn University in 1992 and 1995 respectively. His Master\222s thesis research explored the utilization of cyclostationary statistics for performing phased array blind adaptive beamforming From 1995 to 2000 he was employed at Dynetics, Inc where he performed research and analysis in a wide variety of military radar applications, from air-to-air and air-toground pulse Doppler radar to large-scale, high power aperture ground based phased array radar, including in electronic attack and protection measures. Subsequently, he spent 3 years at MagnaCom, Inc, where he engaged in ballistic missile defense system simulation development and system-level studies for the Ground-based Midcourse defense \(GMD\ system. He joined GTRI in 2003, where he has performed target tracking algorithm research for BMD radar and supplied expertise in radar signal and data processing for the Missile Defense Agency and the Navy Integrated Warfare Systems 2.0 office.  Mr. Burns has written a number of papers in spatio-temporal signal processing, sensor registration and target tracking, and is currently pursuing a Ph.D. at the Georgia Institute of Technology  


  18 We plan to shift the file search and accessibility aspect outside of the IDL/Matlab/C++ code thereby treating it more as a processing \223engine\224. SciFlo\222s geoRegionQuery service can be used as a generic temporal and spatial search that returns a list of matching file URLs \(local file paths if the files are located on the same system geoRegionQuery service relies on a populated MySQL databases containing the list of indexed data files. We then also plan to leverage SciFlo\222s data crawler to index our staged merged NEWS Level 2 data products Improving Access to the A-Train Data Collection Currently, the NEWS task collects the various A-Train data products for merging using a mixture of manual downloading via SFTP and automated shell scripts. This semi-manual process can be automated into a serviceoriented architecture that can automatically access and download the various Level 2 instrument data from their respective data archive center. This will be simplified if more data centers support OPeNDAP, which will aid in data access. OPeNDAP will also allow us to selectively only download the measured properties of interest to the NEWS community for hydrology studies. Additionally OpenSearch, an open method using the REST-based service interface to perform searches can be made available to our staged A-Train data. Our various services such as averaging and subsetting can be modified to perform the OpenSearch to determine the location of the corresponding spatially and temporally relevant data to process. This exposed data via OpenSearch can also be made available as a search service for other external entities interested in our data as well Atom Service Casting We may explore Atom Service Casting to advertise our Web Services. Various services can be easily aggregated to create a catalog of services th at are published in RSS/Atom syndication feeds. This allows clients interested in accessing and using our data services to easily discover and find our WSDL URLs. Essentially, Atom Service Casting may be viewed as a more human-friendly approach to UDDI R EFERENCES   NASA and Energy and W a t e r cy cl e St udy NEW S website: http://www.nasa-news.org  R odgers, C  D., and B  J. C onnor \(2003 223Intercomparison of remote sounding instruments\224, J Geophys. Res., 108\(D3 doi:10.1029/2002JD002299  R ead, W G., Z. Shi ppony and W V. Sny d er \(2006 223The clear-sky unpolarized forward model for the EOS Aura microwave limb sounder \(MLS Transactions on Geosciences and Remote Sensing: The EOS Aura Mission, 44, 1367-1379  Schwartz, M. J., A. Lam b ert, G. L. Manney, W  G. Read N. J. Livesey, L. Froidevaux, C. O. Ao, P. F. Bernath, C D. Boone, R. E. Cofield, W. H. Daffer, B. J. Drouin, E. J Fetzer, R. A. Fuller, R. F. Jar not, J. H. Jiang, Y. B. Jiang B. W. Knosp, K. Krueger, J.-L. F. Li, M. G. Mlynczak, S Pawson, J. M. Russell III, M. L. Santee, W. V. Snyder, P C. Stek, R. P. Thurstans, A. M. Tompkins, P. A. Wagner K. A. Walker, J. W. Waters and D. L. Wu \(2008 223Validation of the Aura Microwave Limb Sounder temperature and geopotential height measurements\224, J Geophys. Res., 113, D15, D15S11  Read, W G., A. Lam b ert, J Bacmeister, R. E. Cofield, L E. Christensen, D. T. Cuddy, W. H. Daffer, B. J. Drouin E. Fetzer, L. Froidevaux, R. Fuller, R. Herman, R. F Jarnot, J. H. Jiang, Y. B. Jiang, K. Kelly, B. W. Knosp, L J. Kovalenko, N. J. Livesey, H.-C. Liu1, G. L. Manney H. M. Pickett, H. C. Pumphrey, K. H. Rosenlof, X Sabounchi, M. L. Santee, M. J. Schwartz, W. V. Snyder P. C. Stek, H. Su, L. L. Takacs1, R. P. Thurstans, H Voemel, P. A. Wagner, J. W. Waters, C. R. Webster, E M. Weinstock and D. L. Wu \(2007\icrowave Limb Sounder upper tropospheric and lower stratospheric H2O and relative humidity with respect to ice validation\224 J. Geophys. Res., 112, D24S35 doi:10.1029/2007JD008752  Fetzer, E. J., W  G. Read, D. W a liser, B. H. Kahn, B Tian, H. V\366mel, F. W. Irion, H. Su, A. Eldering, M. de la Torre Juarez, J. Jiang and V. Dang \(2008\omparison of upper tropospheric water vapor observations from the Microwave Limb Sounder and Atmospheric Infrared Sounder\224, J. Geophys. Res., accepted  B.N. Lawrence, R. Drach, B.E. Eaton, J. M. Gregory, S C. Hankin, R.K. Lowry, R.K. Rew, and K. E. Taylo 2006\aintaining and Advancing the CF Standard for Earth System Science Community Data\224. Whitepaper on the Future of CF Governance, Support, and Committees  NEW S Data Inform ation Center \(NDIC http://www.nasa-news.org/ndic 


  19   Schi ndl er, U., Di epenbroek, M 2006 aport a l based on Open Archives Initiative Protocols and Apache Lucene\224, EGU2006. SRef-ID:1607-7962/gra/EGU06-A03716 8] SciFlo, website: https://sci flo.jpl.nasa.gov/SciFloWiki 9 ern a, web s ite: h ttp tav ern a.so u r cefo r g e.n et  Java API for XM L W e b Services \(JAX-W S https://jax-ws.dev.java.net  Di st ri but ed R e source M a nagem e nt Appl i cat i on DRMAA\aa.org  Sun Gri d Engi ne, websi t e   http://gridengine.sunsource.net  W 3 C R ecom m e ndat i on for XM L-bi nary Opt i m i zed Packaging \(XOP\te: http://www.w3.org/TR/xop10  W 3 C R ecom m e ndat i on for SOAP M e ssage Transmission Optimization Mechanism \(MTOM website: http://www.w3.org/TR/soap12-mtom  W 3 C R ecom m e ndat i on for R e source R e present a t i on SOAP Header Block, website http://www.w3.org/TR/soap12-rep 16] OPeNDAP, website: http://opendap.org  Yang, M Q., Lee, H. K., Gal l a gher, J. \(2008 223Accessing HDF5 data via OPeNDAP\224. 24th Conference on IIPS  ISO 8601 t h e Int e rnat i onal St andard for t h e representation of dates and times http://www.w3.org/TR/NOTE-datetime 19] ITT IDL, website http://www.ittvis.com/ProductServices/IDL.aspx 20] Python suds, website: h ttps://fedorahosted.org/suds  The gSOAP Tool ki t for SOAP W e b Servi ces and XM LBased Applications, website http://www.cs.fsu.edu/~engelen/soap.html  C hou, P.A., T. Lookabaugh, and R M Gray 1989 223Entropy-constrained vector quantization\224, IEEE Trans on Acoustics, Speech, and Signal Processing, 37, 31-42  M acQueen, Jam e s B 1967 e m e t hods for classification and analysis of multivariate observations\224 Proc. Fifth Berkeley Symp Mathematical Statistics and Probability, 1, 281-296  C over, Thom as. and Joy A. Thom as, \223El e m e nt s of Information Theory\224, Wiley, New York. 1991  B r averm a n, Am y 2002 om pressi ng m a ssi ve geophysical datasets using vector quantization\224, J Computational and Graphical Statistics, 11, 1, 44-62 26 Brav erm a n  A, E. Fetzer, A. Eld e rin g  S. Nittel an d K Leung \(2003\i-streaming quantization for remotesensing data\224, Journal of Computational and Graphical Statistics, 41, 759-780  Fetzer, E. J., B. H. Lam b rigtsen, A. Eldering, H. H Aumann, and M. T. Chahine, \223Biases in total precipitable water vapor climatologies from Atmospheric Infrared Sounder and Advanced Microwave Scanning Radiometer\224, J. Geophys. Res., 111, D09S16 doi:10.1029/2005JD006598. 2006 28 SciFlo Scien tific Dataflo w  site https://sciflo.jpl.nasa.gov  Gi ovanni websi t e   http://disc.sci.gsfc.nasa.gov techlab/giovanni/index.shtml  NASA Eart h Sci e nce Dat a Sy st em s W o rki ng Groups website http://esdswg.gsfc.nasa.gov/index.html   M i n, Di Yu, C h en, Gong, \223Augm ent i ng t h e OGC W e b Processing Service with Message-based Asynchronous Notification\224, IEEE International Geoscience & Remote Sensing Symposium. 2008 B IOGRAPHY  Hook Hua is a member of the High Capability Computing and Modeling Group at the Jet Propulsion Laboratory. He is the Principle Investigator of the service-oriented work presented in this paper, which is used to study long-term and global-scale atmospheric trends. He is also currently involved on the design and development of Web Services-based distributed workflows of heterogeneous models for Observing System Simulation Experiments OSSE\ to analyze instrument models. Hook was also the lead in the development of an ontology know ledge base and expert system with reasoning to represent the various processing and data aspects of Interferometric Synthetic Aperture Radar processing. Hook has also been involved with Web Services and dynamic language enhancements for the Satellite Orbit Analysis Program \(SOAP\ tool.  His other current work includes technology-portfolio assessment, human-robotic task planning & scheduling optimization, temporal resource scheduling, and analysis He developed the software frameworks used for constrained optimization utilizing graph search, binary integer programming, and genetic algorith ms. Hook received a B.S in Computer Science from the University of California, Los  


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



Abstract 
When Data mining occurs on distributed data 
Weiwei Jing      Liusheng Huang    Yonglong Luo    Weijiang  Xu     Yifei Yao 
MOST Co-Key Laboratory of High Performance Computing and Its Application University of Science and Technology of China Hefei, Anhui 230027, China Fax: 86-551-3607431 ,   Tel: 86-551-3620553 wwjing@mail.ustc.edu.cn,     lshuang@ustc.edu.cn 
An Algorithm for Privacy-preserving Quantitative Association Rules Minin\g 
privacy of parties becomes great concerns. This paper considers the problem of mining quantitative association rules without revealing the private information of parties who compute jointly and share distributed data. The issue is an area of Privacy Preserving Data Mining \(PPDM\ research. Some researchers have considered the case of mining Boolean association rules; however, this method cannot be easily applied to quantitative rules mining A new Secure Set Union algorithm is proposed in this paper, which unifies the input sets of parties without revealing any element\222s owner and has lower time cost than existing algorithms. The new algorithm takes the 
advantages of both in privacy-preserving Boolean association rules mini ng and in privacy-preserving quantitative association mining. This paper also presents an algorithm for privacy-preserving quantitative association rules mining over horizontally portioned data, based on CF tree and secure sum algorithm. Besides, the analysis of the correctness, the security and the complexity of our algorithms are provided 
Quantitative association rule [1, 2] plays an important role in association rules. Most classical 
1. Introduction 
algorithms do not refer to privacy of parties\222 sharing distributed data though data mini ng over distributed data has been widely a pplied to practical setting with development of multi-party computation, and various   
Supported \(in part\ the National Grand Fundamental Research 973 Program of China \(Gra nt No. 2003CB317000 by the NSF of China \(Grant No. 60573171 
data owners wish to mine for global data without revealing any information of their own. Data mining in distributed setting without disclosing private information of different data owners is known as privacy-preserving data mi ning \(PPDM PPDM has many applica tions. For instance, different mobile net companies need PPDM, when they try to obtain some rules over global data without revealing their own 
In recent yeas, numerous algorithms for PPDM have been proposed in the literature Am ong them, Randomization m u lti-party computation m are two im portant PPDM approaches. One can find two classical methods of privacy-preserving association rul es mining in [5  One mines association rules on vertically partitioned data  based on a secure scalar product sub-protocol while the other mines on horizontally partitioned data   based on a secure set union sub-protocol. Also, the literature [7] presents an 
algorithm for privacypreserving Boolean association rules mining, based on randomized response theory. We observe that all the above algorithms are only concerned with Boolean association rules mining and they cannot be easily adapted to mining qua ntitative association rules. The reason is that quantitative attributes are numeric and have to be discretized, which need to learn the distribution of global data, while the distribution of local data of one party is not necessarily related to the global distribution. This 
paper considers how to get the global distribution wit hout revealing the local distribution. Obviously privacy-preserving Boolean association rules mining PPBARM take account of this problem. Although the generic method can securely solve any problem of Secure Multi-party Computation \(SMC\it is too expensive to use in data mining. A detailed discussion on generic me  


 Table 1 of a set of tuples  1   The semi-honest m ployed in the algorithm, which allows parties to arbitrarily analyze received data but requires parties to correctly run the algorithm The paper is organized as follows. Section 2 describes several definitions used in this paper. The new algorithm for secure set union is proposed in section 3. In section 4, we provide the algorithm for privacy-preserving quantitative association rules mining The number of tuples in the cluster is   denote the number of parties participating in computation, and assume 3 such as the Euclidean or Manhattan distance. The diameter If a rule concerns associations between the presence or absence of items, it is a Boolean association rule. If a rule describes associations between quantitative items or attributes, then it is a quantitative association  generalized quantitative association rules since this definition is considered to fit the quantitative properties and sem  In quantitative attributes are divided into clusters, sets consisting data points with close distance then they consider the association rules between these clusters is a relation over a relation schema and  is the average pairwise distance between tuples projected on and data volumes are large. Compared with it, our proposed algorithm does not relate the number of element encryptions with the number of parties in the following algorithm. This can be achieved by mixing up input elements and encrypting elements with RSA scheme, which is known as a famous public key encryption scheme The proposed algorithm for secure set union is illustrated in  1          11 denote a distance metric on values in the attribute set are disjoint. A rule hol ds with confidence    if X C on          The rule holds with support 0 and frequency threshold 0 X 0    is any subset of DB n X X d X X N N X t X t X S d N i N j j i X X C X r X d r n y Y Y x X X C C C C i X j Y c c C C C i X i j Y j i X i s s DB C C j Y j i X i i X i C i X C  n n n 2 Let 2 A cluster 2 A generalized quantitative association rule is an implication of the form and the dimension is   if 1 Note that the two thresholds on the cluster size and diameter can be used to restrict the quality of a cluster Definition 2.2 2 Where X X d X C d A new algorithm for secure set union is proposed in this paper, which is show n more efficient than the com algorithm  can be viewed as an essential sub-protocol for secure set union. One advantage is that it does prevent the disclosure of frequent item sets in PPBARM. The other is that the algorithm can be easily adapted to algorithms for quantitative association rules mining to securely compute global distribu tion. Then, this paper presents an algorithm for pr ivacy-preserving quantitative association rules mining based on CF-tree  and secure sum when the m odel of data sharing is horizontal The definition of data horizontally partitioned is that each party has identical attribute set and distinct attribute values. While data vertically partitioned deals with the case of distinct attribute set. In this paper only data horizontally partitioned is considered. Let defined on a set of attributes and   1 1 3. Secure set union Definition 2.1 Definition 2.3 2. Preliminaries 3.1. Algorithm n s r   0             Where   that satisfies the following for some density threshold times, where is the size of database, i.e., the total number of tuples where we name it as Algorithm 1 for easily referring latterly It can be shown that algorithm 1 meets the requirement: \(1\ine any element\222s is a set of tuples in which each tuple belongs to every is the number of parties. This will lead to huge computing cost when where all In this section we present a new algorithm for secure set union that has less number of element encryptions. This algorithm can be applied to our privacy-preserving quantitative association rules mining with less modification Secure set union is employed to compute the union of sets presented by different parties under the condition of not revealing any element\222s owner to other parties. The existing algorithm for secure set   encrypt every elem ent s C X  N i i t S 


into into computes decryptions and eliminates duplications, and then sends the set union  3.2  Step3:    For    1 Analysis Theorem 1 is denoted by On input n i n i n i S n i n i  mod 1    and then broadcast the result  n i n i n j A A View  j i p A E n j j i p A E j i i A j i p A E n j j i p A E j n j A A View each party each party each party as the output. We construct a simulator randomly and uniformly divides subsets, such that such that in the Step3, and then n i If algorithm 1 is applied to the literature the privacy-preserving Boolean association rules mining will be more efficient. For quantitative association rules, this only needs a little modification on Step4 Step5. Step5 can be deleted and modify Step4 as: for    1 mod 1 mod 1 mod 1 1  party 1 Step5 party 1  are regarded as messages received by party 1  messages received by party   Step4:    Decryption For    1  i.e     2 For every    n i to party that behaves as follows 1 divides computes decryptions and then sends decryptions to party 1. The modified Algorithm will become an algorithm for secure data collection and can be used as a sub-protocol of the following quantitative association rules mining is modified to be a new subset, denoted by outputs these encryptions 4   1  i.e., that the encrypted subset with the public key to party receives    mod 1 receives   1  receives Security Algorithm 1 securely computes the set union Proof An algorithm or protocol is said to be secure if there exists a simulator such that we can simulate the views of all parties on the known input and output, i.e the output of the simulator is computationally indistinguishable from the real views of the party in the algorithm or protocol. A detailed discussion on security can be found in [9 We consider the view of party we 1  belongs to each party Output 1   Algorithm 1    Step2:    Mixture and transmission For    1 1 sends    mod 1 Table1  secure set union  n i A n i i i A i i p i i A n j i j i A A j n j p i n i n i i j j A i i j i j i A A n i  j j A j j j i i A S S i i A n i i A j i i A j A j A j A S j A n j i A j S j S S Theorem 2 Correctness Algorithm 1 outputs a set union of all i A Proof j i p A E n j i j p A E n i n j owner, \(2\no party can learn how many elements any other party has because of random division in Step2 and \(3\ber of any element encryptions is at most one and is not related to the number of parties in Step2 party randomly and uniformly selects some elements in in which some pairs of elements may be the same 3 in Step2, then Two aspects of correctness should be considered, as follows 1 No element in all input sets is wrongly omitted 2 Any pair of elements in the output set is not identical In algorithm 1, only Step4 and Step5 are considered, since parties compute the set union in these two steps and they do not have any computations in the remaining ones In Step4, each party computes the union of decrypted sets, which lead to satisfaction of the first requirement of correctness. In fact, it is reasonable that the error is not considered if the computation occurs in decrypted data Likewise, in Step5 party 1 computes the union of decrypted data and in Step5 the computation satisfies the second requirement of correctness because it unites all elements and ensures that no pair of the same elements exists. Theorem1 follows randomly and uniformly divides and the output of simulator i j j i A subsets at random, i.e to party 1 Step5:   Party 1 computes the set union    into subsets, denoted by outputs them Considering the difference between     1 Each party and then adds them into denoted by     1 and computes encryptions    mod 1 Input sets. Each set, denoted by sends    mod 1 Step1:    Public keys announcement The public key of party 


This implies that any party can only access the output information and does not learn more information after executing algorithm 1 Theorem 2 follows old algorithm 1    1  1  computationally indistinguishable because of the property of the public key encryption scheme Therefore, the output of algotithm1 is not changed when the view of a party is replaced with the output of simulator 1 ber of elements by   1 The most important communication measure is the round complexity. Obviously, the number of rounds in algorithm 1 is linear with 3 Given the CF of a cluster, we can easily compute the diameter, the size, and the centroid of the cluster From the CFs of two clusters, the CF of their union can be derived. Hence, clusters can be combined and new points added to clusters using only the CFs [2 A CF tree is a height-balanced tree \(similar to a     times longer than our algorithm\222s  CF-tree S S n t n X i i i i i    We denote the size of every input set by     child j i p A E n j j i p A E n j j i p A E j j i p A E j i m N X t t C n i n i n O n i m i m O i m t O i m t O i m i m t O m t O We consider the communication complexity and the computational complexity of algorithm In this section, we present an algorithm for privacypreserving quantitative association rules mining An algorithm for quantitative association rules mining \(definition 2.3\includes two phases if it does not care about privacy: the first phase is to find the clusters and the second phase is to form rules that hold with confidence and support threshold. In the following algorithm, in order to securely find the clusters, we take advantage of the properties of CF-tree in the BIRCH me collection sub-protocol from modified algorithm 1 Secure sum forming association rules th child node and the CF where let the time of encrypting or decrypting an element be In the BIRCH me built for each quantitative attribute set that needs to be discretized. Since a node in a CF tree records the summary of the properties of the cluster, a single data point cannot be revealed in the CF tree. The summary information is called as a Clustering Feature \(CF\that contains the number of tuples, the linear sum of the tuples and the square sum of the tuples of the cluster 2]. The CF is defined as follows Definition 4 2 For a cluster    1 tree CF is the CF of We also implemented algorithm 1 and the literature  on an Intel Pentium 4 CPU 2.40GHz and Windows XP sp2 OS computer. We used RSA scheme in a crypto function library, Crypto++5.23. We assume that the size of an element is 512bits and the total number of parties is 3 illustrates our measurements of one party\222s computation time in these two algorithms  elem ents however, in our algorithm, each party just needs to encrypt part of all elements. Thus, as shown in Fig. 1 the running tim is about the child is a data pointer that points the as well as   1  N i N i i i X X t X t N C CF Our algorithm 1 Num.of all elements/Num.of parties Time\(s Figure 1 B 4. Privacy-preserving quantitative association rules mining 4.1 Complexity          11 2 In addition, the view of party 1 is different from the view of other parties and it cannot know any other element\222s owner because of the mixture in Step2, Step3 and Step4 Thus, it can be concluded that we can simulate the views of all the parties on the real input and output by constructing a simulator For every party, random choice runs at time   and encryption or decryption runs at time    Thus, the computation complexity of algorithm 1 is bounded by         and    mod 1 know that    mod 1 i.e   compared with    on a set of attributes Fig. 1: Party\222s computation time 


we select an initial diameter threshold  Therefore, testing support threshold for a cluster set is reduced to a comparison against a sum of local values. We can invoke a secure sum algorithm  DB   1 1 th child node. A Leaf node contains a list of [CF In order to securely find clusters over global data each party first builds CF trees for local data, which are adapted to the size of the local memory. In view of privacy, each sub-cluster of a leaf node should include more than two data points at least such that any attribute value is not directly recorded in a leaf node Then, every party sends the local leaf nodes to party 1 without disclosing any data owner and party 1 builds a CF tree on input all leaf nodes. We observe that, firstly any attribute value is not revealed because of the properties of CF tree, and that, secondly, any local CF tree is not revealed because of the secure collection Furthermore, the way of handling the outliers may be not changed, because we will refine the clusters on global data. Hence, it plays an important role in our algorithm to securely send leaf nodes to party 1 One method of secure data collection is to mix up and transmit the leaf nodes. Each party randomly and uniformly divides each local leaf node into X where the CF          See definition2.3 When we test the support threshold without revealing local support count, we have the following reduce that is sim except for input cluster sets sup  0 i i i i i i X i X d n i i n n y x Y Y X X C C C C c c C C C i j i X i Y j X i s s DB C C j i Y j X i s X X  if      1     1 the is the CF of the Party 1 invokes a classic Apriori algorithm for association rules mining on input the clusters. The following form of an association rule can be discovered by finding frequent cluster sets and generating rules from frequent cluster sets denotes a cluster set, and sup  if th sub-cluster. Actually, in a CF tree, the cluster derived from a node is the union of all sub-clusters derived from its child nodes. We note that the detail of single tuple is not recorded in a CF tree. A more detailed descrip For each attribute set factions and sends the denotes the support count for is small, a more secure method should be considered. We recall that algorithm 1 can be modified to securely collect data Hence, we can invoke the modified algorithm as a subprotocol to securely collect leaf nodes and each party\222s input in the sub-protocol is one leaf node. However the sub-protocol is not efficient because of introduction to encryption schemes. The trade-off between efficiency and security should be considered in order to choice a sound method of data collection Finally, we need to refine global clusters to avoid the undesirable effect of the skewed input order. In fact, exiting clustering algorithms for a set of data points can be readily adapted to work with a set of subclusters, each described by its CF vector Then the refined clusters can be found by party 1. In addition, we can refine the clusters further by scanning the global data, which is similar to the option phase in BIRCH method. We can first calculate the centroids of clusters that have been refined by applying existing clustering algorithms to a set of sub-clusters, and we regard these centroids as seeds. Secondly, each party scans the local set of tuples and redistributes the data points to its closest seed to obtain new clusters. At last party 1 securely collects the CF vectors representing the clusters and rebuilds a global CF tree. As a result we can obtain more refined global clusters without disclosure of information of every party n i i DB n i i X n i i DB s 0 and build a CF tree that holds with the threshold. If the memory is full, the tree should be reduced by increasing the diameter threshold and rebuilding the tree [2 1 sup  X s 1   sup     X i.e. the number of tuples , and each of them belongs to all clusters in Secure identifying clusters Secure forming rules 4.2 4.3 n i i i DB s X th sub-cluster that is derived from the th faction to party such that no party can learn all CF vectors of any leaf node of any other party. Then, all received data are transmitted to party 1 to build a global CF tree. Because of the mixture, party 1 does not know which party any CF vector belongs to The above method is efficient, though maybe it is not enough for security. Obviously, each party could obtain 1 It holds with confidence          and it holds supports data of other party. If 


  1 1 that have identical attribute set and distinct attribute values Support threshold do Build_CF_Tree do randomly and uniformly divides every leaf node into do sends received data to party 1 if 1 do Build _CF_Tree The party 1 builds a CF tree based on received data Step4:      Find further refined global clusters Step5:     Party 1 invokes the Apriori algorithm to form rules, and broadcasts them When testing thresholds, the parties invoke secure sum algorithm Input Correctness Quantitative association rules that hold with support and confidence thresholds can be discovered by algorithm 2 Proof Security Quantitative association rules are securely discovered by algorithm 2 Proof Table 2 0 without revealing the local support count. Likewise, we can securely check confidence threshold for a cluster set by a similar reduce and invoking the secure sum algorithm Furthermore, we can not directly check if a data point satisfies a quantitative association rule because every cluster is presented by its CF vector. However we can distribute a data point to its closest cluster by calculating the distance between the data point and the centroid of a cluster. As a result, we can check if a data point satisfies an association rule by calculating the distance n i DB s c y x Y Y X X C C C C i i DB i n j j i i  Output: Quantitative association rules  Step3:      For    1 parties have their own database  Step2:      For    1 The privacy of each party includes values of tuples and local data distribution. Algorithm 2 is considered to be secure if the privacy of each party is preserved. We analyze algorithm 2 step by step as follows No message is exchanged in the Step 1. The CF vectors for sub-clusters of leaf nodes are send in Step 2 We first observe that the CF vectors do not record the concrete value of any tuple, although the CF vectors record the summary of the properties of the cluster Hence the values of tuples are preserved by their owner. Secondly, the party that has received some CF vectors from other parties may learn some data distributions of other parties, although it can not obtain the full data distribution of any other party. This can be avoided by invoking secure collection sub-protocol if users prefer security to efficiency. Otherwise, users may trade security for efficiency. The building of CF trees in Step3 and Step4 utilizes CF vectors as input and party 1 that builds global CF trees does not know check if each party each party each party The aim of privacy-preserving quantitative association rules mining is to discover generalized quantitative association rules \(see definition 2.3 without revealing any information of the local data that includes values of local tuples, distribution of local data and the local count of a cluster. The algorithm is described in We have taken advantage of the BIRCH clustering method, the only difference between the BIRCH method and our clustering method is that our clustering program runs on distributed data. If the BIRCH method is much sensitive to the input order of data, our clustering method will fail on distributed data Fortunately, compared with other clustering methods the BIRCH me W e  consider algorithm 2 step by step as follows. In Step 1 and Step 2, all data points are presented by entities in leaf nodes and in Step 3 all entities are collected to party 1. Compared with the BIRCH method, the input data are disordered in the above steps such that the input order may be very different from the input order of the original BIRCH method when a global CF tree is built in Step 3. However, because the original BIRCH method is not sensitive to the input order, the CF tree building is correct in Step3. Even if the data collection in algorithm 2 leads to the skewed input order of CF tree building, the effect of the skewed input order will be avoided in Step 4. We invoke a classic method to form rules in Step5 and we can conclude that theorem 3 follows 4.4. Description and analysis n i n i n i 1   sup   Table 2: Algorithm 2 \(privacy-preserving quantitative association rules mining Theorem 3 Theorem 4 n i i i DB s X  Confidence threshold th faction to party factions and then sends the and is called algorithm 2 We analyze the correctness, the security and the complexity of algorithm 2 as follows hold with thresholds  Step1:      For    1 


6. References Transactions on Knowledge and Data Engineering Volume 16,  Issue 9 2002, 15\(3 206    J. Vaidy a, and C Clifton 223Privacy  Preserving Association Rule Mining in Vertically Partitioned Data\224 Morgan Kaufmann Publishers, 2000    T Zhang, R. Ramakrishnan, and M. Livny 223BIRCH An Efficient Data Clustering Method for very large Databases\224 N O N O January 2003. pp.1-7    Huang Liusheng, Chen Huaping, et al., \223A fast algorithm for mining association rules\224  where Dallas, TX USA, May 15-18 2000, pp.439-450    Y. Lindel, and B. Pinkas 223Privacy  preserving data mining\224 15\(6  China 2000, pp.619 \226 624 which party any CF vectors belongs to, hence in Step 3 and Step4 party 1 does not obtain any information of values of tuples or local data distribution. In Step 5 secure sum algorithm can check the support and confidence thresholds without revealing local count values. As a result, Quantitative association rules are securely discovered by algorithm 2 BIRCH can work with any given amount of memory and the I/O complexity is a little more than distributed data, algorithm 2 does not lose the advantage of BIRCH. The cost of building trees in party 1 is   log  2 This paper concerns the security of distributed quantitative association rules mining. We have presented an algorithm \(algorithm 2\mining quantitative association rules without revealing private information of parties on horizontally partitioned data As an important sub-protocol for both our algorithm and Boolean association rules mining, algorithm 1 is proposed for secure set union, which is employed to compute set union of input of all parties without disclosing data\222s owners. It has been shown that this algorithm for secure set union is more efficient than the algorithm The results of implementing of two algorithms are also provided. In algorithm 2, we have taken advantage of the properties of CF trees and utilized secure sum sub-protocol to prevent breach of privacy of parties when we mine quantitative association rules. In addition, the correction, the security and the complexity of the proposed algorithms are analyzed. Future works maybe focus on the measurements of efficiency and security or other secure questions of data mining    R. Srikant, and R. Agrawal, \223Mining Quantitative Association Rules in Large relational Tables\224 If encryption scheme is introduced, the cost of encryption is    N t O N M O L Complexity is the total number of all tuples. The cost of random division in algorithm 2 is   denotes the total number of attribute sets denotes the time of encrypting a message. The communication complexity is acceptable because we note that CF vectors just record the summary of the properties of clusters and the size of messages exchanged in algorithm 2 is limited by the amount of memory of each party, although the number of message exchanges seems   ACM Press Montreal, Quebec, Canada. June 1996, pp.1-12    R.J. Miller, and Y. Yang, \223Association Rules over Interval Data\224 Cloudcroft New Mexico, USA. ACM Press, Sept. 10-13, 2002 pp.13-22    J. Han , and M. Kamber Edmonton, Alberta Canada. July 23 - 26, 2002, pp.639-644  M Kantarcioglu and C Clifton 223Privacy preserving Distributed Mining of Association Rules on Horizontally Partitioned Data\224 2005, pp.900-903   A.C.Yao, \223Protocols for secure computations\224 1982, pp.160-164  Goldreich Cambridge University Press 2004    W Du, and Mikhail J. Atallah, \223Secure Multi-Party  Computation Problems and Their Applications: A Review and Open Problems\224 5. Conclusions Tucson, Arizona, United States, May 1997 pp.452-461    R. Agrawal, and R. Srikant, \223Privacy preserving data mining\224 In Proceedings of the 23rd Annual IEEE Symposium on Foundations of Computer Science Proc. of SIGKDD02 Proceedings of the 1996 ACM SIGMOD international conference on Management of data Proceedings of the 2000 ACM SIGMOD on Management of data The Foundations of Cryptography Volume 2, Basic Applications Proceedings of the 1996 ACM SIGMOD international conference on Management of data Journal of Cryptology Date Mining : Concepts and Techniques Journal of Computer Science and Technology 2002 Proceedings of the 1997 ACM SIGMOD international conference on Management of data M L N t NSPW\22201 ACM SIGKDD  Explorations 4\(2  IEEE Computer Society Press, Los Alamitos, Sept 2004 pp.1026 - 1037    Luo Yonglong , Huang Liusheng , Jing Weiwei  Yao yifei and Chen Guoliang , \223An algorithm for Privacypreserving Boolean Association Rule Mining\224   Montreal, Quebec, Canada, June 1996, pp.103-114    C. Clifton, M. Kantar cioglu, X. Lin, and M. Zhu 223Tools for privacy preserving Distributed Data Mining\224 is a threshold value for the size of internal nodes of a CF tree and ACTA ELECTRONICA SINICA where 33\(5 


optimizing the clustering in terms of number of clusters either this clustering is global or it is viewpoint-oriented Finally, we have proposed a new approach for knowledge extraction that takes benefit of the MultiSOM environment. In the patents analysis domain, such knowledge extraction capability is mandatory to mine precise information from patents. Our approach makes uses of the MultiSOM inter-map communication mechanism in combination with original measures of recall and precision for extracting rules from maps. Even if complementary experiment s must be done, our first results are very promising. Th ey tend to prove that the MultiSOM model represents a natural candidate to cope with the related problems of rule inflation, rule selection and computation time that are inherent to symbolic models References   Campanario, J   M. \(1995 orks To Study Networks of Scientific Journals ics  Vol. 33  No. 1, p. 23-40   Cherfi, H  200 4 e et r\351alisation d\220un s y st\350me d\220extraction de connaissances \340 partir de textes. Th\350se de l\220Universit\351 de Nancy 1, Henri Poincar\351   Jouve, O. \(19 99 Les nouvelles technologie de la recherche d\220information S\351minaire Documentation Paris  Ha mme r B Rec htie n A  Strickert, M., & Villmann, T 2002\extraction from self-organizing networks ICANN, Springer, 877-882   Hinton G. E 1989 Connection ist Learn ing Procedures Artificial Intelligence 40 p. 185-234   Kaski, S., Honkela, T Lagus K., & Kohonen, T 1998 WEBSOM-self organizing maps of document collections  Neurocomputing, vol. 21, pp. 101-117   Kohonen, T. \(1990 e Self-Organizing Map Proceedings of the IEEE 78 No 9, p. 1464-1480   Kohonen, T., Kaski, S Lagus K., Salo jrvi, J Honkela  J., Paatero, V., & Saarela, A. \(2000\ization of a massive document collection,  IEEE Transactions on Neural Networks   Lamirel, J-C. \(1995 ication d\220une approche symbolico-connexionniste pour la conception d\220un syst\350me documentaire hautement interactif, Th\350se de l\220Universit\351 de Nancy 1 Henri Poincar\351   Lamirel, J-C., Duclo y  J Oster, G. \(2000 browsing for information discovery in an iconographic context, In Conference Proceedings RIAO Paris, Vol. 2 p. 1657-1672   Lamirel J.C., To ussaint, Y., & A l Shehabi, S. \(2 003 Hybrid Classification Method for Database Contents FLAIRS Conference, p. 286-292   Lam irel J  C., Al Shehabi, S., Fr an\347ois, C  H o ffm ann M. \(2004\ quality estimators for analysis of documentary information: application to web mapping Scientometrics Vol. 60, No. 3, p. 445-462   Lam irel J.C., Al Shehabi, S., Fran\347ois, C., & Pol a nco, X 2004\compound approach based on elaborated neural network for Webometrics: an example issued from the EICSTES Project. Scientometrics, Vol. 61, No 3, p. 427-441   Lebar t, L Morineau A F\351nelon, J P. \(1982 Traitement des donn\351es statistiques Dunod, Paris France   Lin, X., Soergel, D., & March i o nini, G. \(1991  A SelfOrganizing Semantic Map for Information Retrieval, in Proceedings of the 4 th International SIGIR Conference on R&D in Information Retrieval 13-16 October Chicago, p. 262-269   Ontrup, J Ritter, H. \(2005  A hierar chically growing  hyperbolic self-organizing map for rapid structuring of large data sets. In Proceedings of 5th Workshop On SelfOrganizing Maps - WSOM 05, Paris 1 Panth\351onSorbonne University   Polanco, X., Lamirel, J.C F r an\347ois C  200 1 Using  Artificial Neural Networks for Mapping of Science and technology: A Multi self-organizing maps Approach Scientometrics, Vol. 51, N\260 1, pp. 267-292   Polanco, X., & Fran\347ois, C. \(20 00a Class Mapping or Visualization in Text Processing and Mining Dynamism and Stability in Knowledge Organization. Proceedings of the Sixth international ISKO Conference 10-13 July 2000, Toronto, Canada Edited by C. Beghtol, C. L. Howarth, N. J. Williamson Advances in Knowledge Organization 7, p. 359-365   Robertson, S E., & Sparck Jones, K 1976  Relevance Weighting of Search Terms Journal of the American Society for Information Science, 27:129\205146   Salton, G  19 71 The SMART Retrieval System Experiments in Automatic Document Processing Prentice Hall Inc., Englewood Cliffs, New Jersey   Simon, A., & Napoli, A. \(1999 oints in  an Object-based Representation System for Knowledge Discovery in Databases, Proceedings of IRI'99, Atlanta Geogia, S. Rubin editor, The International Society for Computers and Their Applications, ISCA, pages 104108   SOM papers, http://www cis.hut.fi/research som bibl   Toussaint, Y Lamirel, J.C., & d\220Aquin, M. \(2001 Combining Symbolic and Numeric Techniques for Database Content Analysis Proceedings of IEA01    Varsis, A., & Versino, C 199 2 Clustering of SocioEconomic Data with Kohonen Maps, In Proceedings of third International Workshop on Parallel Applications in Statistics and Economics Pragues, Czechoslovakia   W h ite, H. D Lin, X., & Mc Cain, K.W  19 98 Modes of Automated Domain Analysis Multidimensional Scaling vs Kohonen Feature Mapping of Information Science Authors, in Structures and Relations in Knowledge Organization. Proceeding of the Fifth International ISKO Conference Lille, 25-29 August 2000. Edited by W. Mustafa el Hadi, J. Maniez S.. A. Politt Advances in Knowledge Organization 6, p 57-63   Van Rijsbergen C J. \(1975  Information Retrieval  Butterworths, London, England Proceedings of the Fourth International Conference on Coordinated Multiple Views in Explor atory Visualization \(CMV\22206 ISBN-10: 0-7695-2605-5/06 $20.00 \251 2006  IEEE 


Figure 3 Example of a patent abstract with its generated multi-index. The multi-index that has been generated for the above patent abstract corresponds to the \223 Final indexation 224 field. The terms of the generated multi-index are prefixed by the name of the viewpoint to which they are associated: \223adv.\224 for the Advantages viewpoint, \223titre.\224 for the Title viewpoint, \223use.\224 for the Use viewpoint, \223soc.\224 for the Patentees viewpoint Patentees Title Use es GlobMin WEBSOM  WEBSOM  Number of indexed documents \(NID 1000 1000 745 624 1000 1000 Number of rough indexes generated \(NRI 73 605 252 231 1395 1395 Number of final indexes \(NFI 32 589 234 207 1075 1075 Numbers of map nodes with members \(/100 28 55 57 61 89 238 Table 1 Summary of the results of patent indexation and map building. Note that the NRI \(resp. NFI\ \223global viewpoint\224 are less than the sum of the NRIs \(resp. NFIs\ specific viewpoints \(i.e. 1089\ecause there are similar indexes occurring in different viewpoints Patentees Title Use es MSOM GlobMin WEBSOM  WEBSOM R 0,94 0,89 0,78 0,77 0,85 0,87 0,84 P 0,92 0,40 0,63 0,60 0,64 0,48 0,65 F 0,93 0,55 0,70 0,67 0,71 0,61 0,68 Table 2 Summary of the results of Quality, Recall and Precision evaluation. The nearer the different values are from 1, the better are the clustering results. The F value provides a synthesis of the results of R and P Proceedings of the Fourth International Conference on Coordinated Multiple Views in Explor atory Visualization \(CMV\22206 ISBN-10: 0-7695-2605-5/06 $20.00 \251 2006  IEEE 


Figure 4 Example of a generated map. Partial view of a topographic map of 10 x 10 nodes. The map is initially organized as a square 2D grid of nodes. The viewpoint chosen for the showed map is the Advantages viewpoint. The names of the clusters illustrate the topics \(considering the chosen viewpoint\ been highlighted by the learning. After the learning, the no des related to the same topics have been grouped into coherent areas thanks to the topographic properties of the map. The number of nodes of each area can then be considered as a good indicator of the topic weight in the database. Topics or areas near one to another represent related notions. For example, the \223 extending oil live 224 area shares some of its borders with the \223 black sludge control 224 area on the map. The proximity of these two areas illustrates the fact that oil duration strongly depends \of maintaining a low level of sludge in it. The surrounding circles represent the centers of gravity of the areas  1 2 3 Patentees Title Advantages Use 3 2 1 Figure 5 Example of exploitation of the inter-map communication mechanism. The analyst decision to activate the area corresponding to the TONEN CORP. company on the Patentees map and to propagate the activity to the thematic maps associated to the Use  Advantages and Title viewpoints corresponds to a "viewpoints crossing query" whose explicit formulation might look like: "I want to know which are the specific areas of competence \(concerning oil use, oil composition and expected advantages\". The MultiSOM application let him interactively find that TONEN CORP. company is a specialist of the lubrication of the automatic transmissions [arrow n\2602 on th r  this kind of lubrication sulfur-containing organo-molybdenum compound [arrow n advantages are to provide oil with a friction coefficient that is stable on a wide range of temperature [arro In this ca se, an inverted propagation fr om the target topics should be also used to verify that these topics only belong to TONEN CORP. areas of competence. The whiter is the color of a node representing a map cluster \(topic\ing activity Proceedings of the Fourth International Conference on Coordinated Multiple Views in Explor atory Visualization \(CMV\22206 ISBN-10: 0-7695-2605-5/06 $20.00 \251 2006  IEEE 


 Profile of topic Extending oil life Figure 6 Results of a WEBSOM-like global mapping of 10x10 nodes GlobMin The left part of the figure represents the WEBSOM-like mapping \(i.e. without viewpoint management\repre sents the description \(i.e. profile\ \223 extending oil life 224 WEBSOM global topic. Even if a strong relationship between \223 extending oil life 224 and \223 black sludge control 224 topics has been highlighted by the MultiSOM viewpoint-oriented clustering \(see map of figure 3 relationship has been lost by the WEBSOM-like clustering due to the noise of the global clustering \(this relationship do not ap pear neither in the above map, nor in the \223 extending oil life 224 topic profile Figure 7 Comparison between a 11x11 \223Use viewpoint\224 thematic map and a 16x16 \223Use viewpoint\224 thematic map through map extracts The 11x11 map extract is presented at the left, the 16x16 map extract is presented at the right. On the figure, the focus is gi ven 223 machine oil 224 topic. The comparison highlights, as an example, that the logical surrounding of this topic is more precisely defined in the 16x16 map \(optimal quality\n in the 11x11 map \(lower quality\n the 11x11 map, the topic \223 machine oil 224 has been derived in a more fuzzy scope topic named \223 machine and vehicles 224 Proceedings of the Fourth International Conference on Coordinated Multiple Views in Explor atory Visualization \(CMV\22206 ISBN-10: 0-7695-2605-5/06 $20.00 \251 2006  IEEE 


ANNEX: example of interactive dynamic multi-viewpoint analysis Dynamic analysis takes place main ly by using the inter-map communication mechan ism which makes it possible to bring to successful conclusion sets of topics deductions between differen t viewpoints chosen like investigation under-fields. This a nalyze is based on the generation of an initia l activity corresponding to the premises of the deduction to check. According to stages of analyze, this activity can itself be generated several manners by the analyst on one or more source map. If the activity generation is d irectly operated by analyst on a map, it corresponds then to broad a set of topics question. If the activity generation is operated indirectly by projection query on a map or by activation of documents group stored befo rehand in a collector of documents, it corresponds then to more targeted question, which can intervene in one second stage of the analyze The analyst interest is to hi ghlight the specific areas of competence of the Exxon company. On the simulation of analysis we develop on figure 7, we will consider two different viewpoints Patentees which will represent the source of the analysis and the Title viewpoint which will represent its destination The analyst starts the process of deduction by generating an initial activity on the main Exxon topic i.e. Exxon area gravity center\ of the Patentees viewpoint map. To obtain a broad set of potential deductions, he selects the Possibilistic mode of deduction 17  The activity generated by the inter-map  communication mechanism on the Title viewpoint map is focused in two different zone s of this map, corresponding to two potential results In the first active zone \(1\, the analyst makes use two different naming strateg ies to facilitate its interpretation namely a naming strategy based on the profile of the topics more generic\ and a naming strategy based on the profile of the best members \(i.e. patents\of the topics more specific\. These operations enable him to highlight that the Exxon company is specialized in a correlative way on topics: \215 marine diesel engine 216 215 surfactant system 216 and \215 basic calcium compound 216 The expert checks the correlation between these topics by consulting the patents associated to the topic 215 surfactant system 216 \(2\. The title of the patents already confirm him the problematic de tected by the application A thorough examination of th e contents of the documents will show him than the pur pose of use of surfactant containing calcium in add ition with the normal formula of oils is to protect the combustion chambers of the marine diesel engines against corrosion due to the absorption of air charged out of salt during their operation. The problem of protection of the marine engines against corrosion is sufficiently important to represent a field of investigation for an oil manufacturer like Exxon The construction of a query containing the single descriptor \215 surfactant system 216 \(3\ on the Title viewpoint will allow the analyst 1 To validate the correlation between 215 surfactant system 216 and \215 marine diesel engine 216 topics which will be interpreted by the fact that 215 surfactant system 216 is only associated with 215 marine diesel engine 216 2 To check the inverse deduction 215 surfactant system 000\306 Exxon 216 which will insure him that Exxon is the only company whose interest in the conception of \215 surfactant system 216 The result of the projection of the query on the Title viewpoint map \(4\ shows that the generated activity is peculiar to the logical topic area \215 marine diesel engine 216, which confirms th e first assumption Simultaneously with projection the documents that are relevant for the query are presented in a Collector \(5 The global activation of these documents allows analyst to initiate a new de duction.  Then, the result of this latter can be examined on the Patentees map. Like only the main Exxon topic has been activated \(6\, the second assumption of the an alyst is confirmed The second active zone \(7\ generated by the initial process of deduction will allow the analyst to observe that the second major field of activity of Exxon is the 215 biodegradable 216 oils. It will be able to also note that these oils are more specifically us ed for the lubrication of the two-stroke engines \(\215 two cycle engine 216\ that generally reject much unburned oil Probabilistic mode of deduction will allow him to check if the inverse deduction, namely, that Exxon is the only company to be worked on biodegradable oils, can be validated \(8\. This process will lead the analyst to conclude that 215 biodegradable 216 oil manufacturing is shared between Exxon and Mobil companies \(9\, which are the most important oil manufacturers A complementary use of negative activity setting on the \215 two cycle engine 216 topic \(10\ will show more precisely to the analyst that that Mobil company mainly focus on manufacturing of biodegradable oils for \215two stroke engines\216 and, in a complementary way, that Mobil company only focus on manufacturing of biodegradable oils for \215four stroke engines\216 \(11 The simulation of analysis presented here above shows clearly how the analyst can make use of the MultiSOM functionalities in order to highlight all the privileged activity fields of the Exxon company starting from a patents database related to engineering of oils Main functionality is inter-map communication. Multiple naming strategies, generation of queries and collection intermediate results that have been implemented complementary to inter-map communication also play an important role in the analysis process Proceedings of the Fourth International Conference on Coordinated Multiple Views in Explor atory Visualization \(CMV\22206 ISBN-10: 0-7695-2605-5/06 $20.00 \251 2006  IEEE 


     Activated area 1    Inverse validation 10 Categorical rejection Categorical choice Activity resulting from the inverse validation Result  28,6 and 17 11 Focalization Inverse validation Activity resulting from the inverse validation 9 Result 28,6% and 23 5 6 3 Legend  Viewpoint 215Patentees\216 Viewpoint 215Title\216  Projection resulting from the inverse validation Activated area 2 7 1 8 Analysis of deduction 2  4 Figure 8 Diagram of the analysis simulation Result 100 Proceedings of the Fourth International Conference on Coordinated Multiple Views in Explor atory Visualization \(CMV\22206 ISBN-10: 0-7695-2605-5/06 $20.00 \251 2006  IEEE 


per by Ganti et. al. [9] deals with the measurement of similarity \(or deviation, in the authors  vocabulary between decision trees, frequent itemsets and clusters Although this is already a powerful approach, it is not generic enough for our purpose. The most relevant research e?ort in the literature, concerning pattern management is found in the ?eld of inductive databases Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE meant as databases that, in addition to data, also contain patterns [10], [7]. Our approach di?ers from the inductive database one mainly in two ways. Firstly, while only association rules and string patterns are usually considered there and no attempt is made towards a general pattern model, in our approach no prede?ned pattern types are considered and the main focus lies in devising a general and extensible model for patterns Secondly, di?erently from [10], we claim that the peculiarities of patterns in terms of structure and behavior together with the characteristic of the expected workload on them, call for a logical separation between the database and the pattern-base in order to ensure e?cient handling of both raw data and patterns through dedicated management systems Finally, we remark that even if some languages have been proposed for pattern generation and retrieval 14, 11], they mainly deal with speci?c types of patterns \(in general, association rules sider the more general problem of de?ning safe and su?ciently expressive language for querying heterogeneous patterns 7. Conclusions and Future Work In this paper we have dealt with the issue of modelling and managing patterns in a database-like setting Our approach is enabled through a Pattern-Base Management System, enabling the storage, querying and management of interesting abstractions of data which we call patterns. In this paper, we have \(a de?ned the logical foundations for the global setting of PBMS management through a model that covers data patterns and intermediate mappings and \(b language issues for PBMS management. To this end we presented a pattern speci?cation language for pattern management along with safety constraints for its usage and introduced queries and query operators and identi?ed interesting query classes Several research issues remain open. First, it is an interesting topic to incorporate the notion of type and class hierarchies in the model [15]. Second, we have intentionally avoided a deep discussion of statistical measures in this paper: it is more than a trivial task to de?ne a generic ontology of statistical measures for any kind of patterns out of the various methodologies that exist \(general probabilities Dempster-Schafer, Bayesian Networks, etc. [16 nally, pattern-base management is not a mature technology: as a recent survey shows [6], it is quite cumbersome to leverage their functionality through objectrelational technology and therefore, their design and engineering is an interesting topic of research References 1] Common Warehouse Metamodel \(CWM http://www.omg.org/cwm, 2001 2] ISO SQL/MM Part 6. http://www.sql99.org/SC32/WG4/Progression Documents/FCD/fcddatamining-2001-05.pdf, 2001 3] Java Data Mining API http://www.jcp.org/jsr/detail/73.prt, 2003 4] Predictive Model Markup Language \(PMML http://www.dmg.org 


http://www.dmg.org pmmlspecs v2/pmml v2 0.html, 2003 5] S. Abiteboul and C. Beeri. The power of languages for the manipulation of complex values. VLDB Journal 4\(4  794, 1995 6] B. Catania, A. Maddalena, E. Bertino, I. Duci, and Y.Theodoridis. Towards abenchmark for patternbases http://dke.cti.gr/panda/index.htm, 2003 7] L. De Raedt. A perspective on inductive databases SIGKDD Explorations, 4\(2  77, 2002 8] M. Escobar-Molano, R. Hull, and D. Jacobs. Safety and translation of calculus queries with scalar functions. In Proceedings of PODS, pages 253  264. ACMPress, 1993 9] V. Ganti, R. Ramakrishnan, J. Gehrke, andW.-Y. Loh A framework for measuring distances in data characteristics. PODS, 1999 10] T. Imielinski and H. Mannila. A database perspective on knowledge discovery. Communications of the ACM 39\(11  64, 1996 11] T. Imielinski and A. Virmani. MSQL: A Query Language for Database Mining. Data Mining and Knowledge Discovery, 2\(4  408, 1999 12] P. Kanellakis, G. Kuper, and P. Revesz. Constraint QueryLanguages. Journal of Computer and SystemSciences, 51\(1  52, 1995 13] P. Lyman and H. R. Varian. How much information http://www.sims.berkeley.edu/how-much-info, 2000 14] R.Meo, G. Psaila, and S. Ceri. An Extension to SQL for Mining Association Rules. Data Mining and Knowledge DiscoveryM, 2\(2  224, 1999 15] S. Rizzi, E. Bertino, B. Catania, M. Golfarelli M. Halkidi, M. Terrovitis, P. Vassiliadis, M. Vazirgiannis, and E. Vrachnos. Towards a logical model for patterns. In Proceedings of ER 2003, 2003 16] A. Siblerschatz and A. Tuzhillin. What makes patterns interesting in knowledge discovery systems. IEEE TKDE, 8\(6  974, 1996 17] D. Suciu. Domain-independent queries on databases with external functions. In Proceedings ICDT, volume 893, pages 177  190, 1995 18] M.Terrovitis, P.Vassiliadis, S. Skadopoulos, E. Bertino B. Catania, and A. Maddalena. Modeling and language support for the management of patternbases. Technical Report TR-2004-2, National Technical University of Athens, 2004. Available at http://www.dblab.ece.ntua.gr/pubs Proceedings of the 16th International Conference on Scientific and Statistical Database  Management \(SSDBM  04 1099-3371/04 $ 20.00  2004 IEEE pre></body></html 


The reason of the hiding failure of SWA is the same in Fig.8 Notice the result at x = 0.7646 in Fig.14, because the hiding failure is occurred at the seeds of the sensitive patterns, a high weakness is produced As shown in Fig.15 and Fig.16, the misses cost and dissimil arity of our work decreases as RL2 increases. This is because the larger RL2 is, the less effect on non-sensitive patterns. Also weakness and dissimilarity of SWA are independent of RL2 5. Conclusion In the paper, a novel method improving the balance between sensitive knowledge protecting and discovery on frequent patte rns has been proposed. By setting entries of a sanitization matrix to appropriate values and multiplying the original database by the matrix with some probability policies, a sanitized database is gotten. Moreover, it can avoid F-I Attack absolutely when the confidence level given by users approximates to 1. The experimental results revealed that although misses cost and dissimilarity between the original and sanitized database of our process are little more than SWA, ours provide more safely protection than SWA. Unlike SWA, our sanitization process could not suffer from F-I Attack and the probability policies in our approach also take the minimum support into account, the users only need to decide the confidence level which affects the degree of patterns hiding 6. Reference 1] M. Atallah, E. Bertino, A. Elmagarmid, M. Ibrahim and V. Verykios Disclosure Limitation of Sensitive Rules", Proc. of IEEE Knowledge and Data Engineering Exchange Workshop 1999 2] R. Agrawal and R. Srikant. Fast algorithms for mining association rules. VLDB, Santiago, Chile, 1994 3] R. Agrawal and R. Srikant. Privacy preserving data mining. In ACM SIGMOD, Dallas, Texas, May 2000 4] E. Dasseni, V. Verykios, A. Elmagarmid and E. Bertino, Hiding Association Rules by Using Confidence and Support", Proc. of 4th Intl Information Hiding Workshop \(IHW 5] A. Evfimievski, J. Gehrke, and R. Srikant. Limiting Privacy Breac hed in privacy preserving data mining. SIGMOD/PODS, 2003 6] A. Evfimievski, R. Srikant, R. Agrawal, and J. Gehrke. Privacy preserving mining of association rules. KDD 2002 7] M. Kantarcioglu and C. Clifton. Privacy-preserving distributed mining of association rules on horizontally partitioned data. In ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery, June 2002 8] Guanling Lee, Chien-Yu Chang and Arbee L.P Chen. Hiding sensitive patterns in association rules mining. The 28th Annual International Computer Software and Applications Conference 9] Y. Lindell and B. Pinkas. Privacy Preserving Data mining. In CRYPTO, pages 36-54, 2000 10] S. R. M. Oliveira and O. R. Za  ane. Privacy Preserving Frequent Itemset Mining. In Proc. of IEEE ICDM  02 Workshop on Privacy Security, and Data Mining 11] S. R. M. Oliveira and O. R. Za  ane. Algorithms for Balancing Priv acy and Knowledge Discovery in Association Rule Mining. IDEAS  03 12] S. R. M. Oliveira and O. R. Za  ane. Protecting Sensitive Knowledge By Data Sanitization, ICDM  03 13] S. R. M. Oliveira, O. R. Za  ane and Y  cel Saygin. Secure Association Rule Sharing, PAKDD-04 14] Benny Pinks. Cryptographic Techniques For Privacy-Preserving D ata Mining. ACM SIGKDD Explorations Newsletter Vol. 4, Is. 2, 2002 15] S. J. Rizvi and J. R. Haritsa. Maintaining data privacy in association rule mining. VLDB, 2002 16] J. Vaidya and C. W. Clifton. Privacy preserving association rule mining in vertically partitioned data. KDD2002 17] Verykios, V.S.; Elmagarmid, A.K.; Bertino, E.; Saygin, Y.; Dasseni E. Association rule hiding. IEEE Transactions On Knowledge And Data Engineering, Vol. 16, No. 4, April 2004 Proceedings of the 29th Annual International Computer Software and Applications Conference  COMPSAC  05 0730-3157/05 $20.00  2005 IEEE pre></body></html 


pre></body></html 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



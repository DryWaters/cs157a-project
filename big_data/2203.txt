Abstract 
204Consumer demand information is very important for enterprises development, and also be the source of capture business opportunities. How to obtain Consumers information and further find its potential link is enterprise information systems major issues resolved. This paper applies data mining 
Knowledge Discovery in Enterprise Information System Application Li Lingyun Department of Computer Science & Technique Ludong University Yantai City, China LILY200499@126.COM Zhang Zhonglei Department of Computer Science & Technique Ludong University Yantai City, China Chonglychang@163.com 
technique to Enterprise, process the Enterprise collected data by SPSS crosstab and correlation analysis, then find the immanent rule of people need so that can supply the enterprise with the better support decision 
Keywords-component; Information System, Date Mining, SPSS Correlation 
I I NTRODUCTION Consumer demand is the leader of enterprise development if enterprises want to improve their competitiveness, in addition to their own enterprises should pay attention to the technical and management levels, there should be more focus on the present and future market demand. Collect the 
information, many enterprises now has realized the needs of the consumer feedback information systems management by the web technology, but many enterprises did not realize the intrinsic link between the information tap, so can bring greater support for enterprises decision-making Data mining, also known as knowledge discovery in the database, refers to extract implicit potential useful information and knowledge from a large quantity of incomplete, noise, and blurring, random data which people do not know in advance 1  Data mining method can usually be divided into two categories: The first category is statistical, and its\220 technology 
used probability analysis, relevance, cluster analysis and discriminated analysis; the other is machine learning in the artificial intelligence-based, through training and learning a large number of samples that need to set the mode or parameters II I SSUES RAISED As a new way to provide information, one of the characteristics of the consumer service of enterprise is guided by consumer demand. The services provided by the enterprise is not to allow the consumer to adapt, but information services should be the maximum from the needs of the consumer, based 
on "the interests of the consumer as the center" design services and improve service efficiency, reduce service costs, improve service quality, providing the consumer with the largest service efficiency. Therefore, the enterprise service is not just changes to the mode of service, but more important is information services awareness heightened and the concept of service innovation. Information consumer services need to attach importance to the principle of demand-oriented and then carry out all system construction and services work. To achieve this goal, information departments and the consumer must be interactive information on the consumer information needs 
study the real need of consumer.  At present this study has follows perspective 2  
200 
Establish consumer opinion collection mechanism First establishes the network system of collection consumer opinion. Uses the computer technology fully enables the different opinion of each aspect to reflect to the production consumer product department prompt and accurately. Secondly, each main body of consumer should establish information system, allocate specialized personnel to work professionally, so different views from the consumer can be reflected in different categories for policy-makers with timely and 
accurate decision-making signal. Final collection consumer views should be finalized as a management system 
200 
Uses the information architecture \(IA\ way to carry on the investigation and analysis Architecture of information act is to organize information and design information environment information space and information architecture to meet the information needs of users art and a science. The current method has been successfully applied to various construction sites, as a blueprint for the building site whether the site solution with the organization's business objectives, whether to meet the information needs of users 
200 
Data warehouse and data mining technology. For example, on the basis of analysis and study of the association rules and decision tree two commonly used data mining technology, apply the Apriori Algorithm 
978-1-4244-2108-4/08/$25.00  \251 2008 IEEE 
and other practical issues, such as in a series of indicators weighted analysis IA Information websites can be drawn after the customer satisfaction rankings 1 


A Multi-dimensional cross-table analysis B Correlation analysis method Multi-dimensional cross-table analysis showed that two or more variables joint frequency distribution table. It belongs to the scope of discrete multivariate analysis, cross-generation multi-dimensional or two-dimensional form, mainly used for the analysis of each thing and phenomenon\220s differences identify the inspection variables whether have relation. For example, to understand the different age levels and qualifications are concerned about the relationship between the content of the Information, the process can be used to form a two-dimensional tables. To show that different age groups, all education levels are concerned about the number of different frequency content distribution, correlation, and to choose suitable way to carry out inspection. Multi-dimensional crosstable analysis of the selected output variables can choose between the correlation coefficient table below on the related analysis and correlation coefficients brief 2 Analysis the data, define variables. For multiplechoice questions, define a variable for each topic Variables defined in table 2 T ABLE 2 VARIABLES AND VARIABLE VALUE TRANSFORMATION COMPARATIVE TABLES 200 ii ii xy xxyy xyy R It is not difficult to see that above analysis methods still remain in the surface of the problem, it did not reveal the intrinsic link of all factors. For example, we can\220t get the conclusions of the relationship between a certain age levels and corresponding choice, or whether different degree levels will affect their choice. Therefore, we study the information collected in-depth with the method of data mining, in a certain age conditions, analysis different degree and concerned problem intrinsic link by multi-dimensional cross-table specific steps are as follows 1.0 <Rxy <1, x and y that is right relevant if -1 <Rxy <0, that negative correlation between X and Y; and Rxy | closer to the 1, between the variables X and Y variables linear relationship is more remarkable. If Rxy closer to the 0, X and Y does not claimed related. When |Rxy | = 1, say X and Y completely related IV E XAMPLE OF DATA MINING TECHNOLOGY IN ENTERPRISE INFORMATION SERVICE APPLICATION Enterprise information management based on web improve its competitiveness and transparency greatly, also accumulated massive data, but it is far from decision-making, and forecast has not displayed effectiveness fully which its should have. For example each information website has similar nearly 215consumer opinion investigation\216 column, it is a very good way of understanding the consumer \217s demand, but looked from the website announcement investigation result, the conclusion also pauses in calculation the total to the single question, and the proportion and so on in the simple isolation analysis. Take one enterprise information net investigation as an example, investigates this enterprise products some indicators which consumer be concerned \(being possible to elect\, and mainly understands the populace demand and surveyor's basic document \(including age level, degree level occupation and so on The website has made the simple statistics to the questionnaire, for example the voting result of the age level the school record level and likes tour site shown in Table 1 T ABLE 1 ONE ENTERPRISE NET INVESTIGATION Establish data file after transformation, lists the partial data as shown in Table 3 No Problem Name Number x 1 2 3 4 5 Product quality Product Price Product Brand Cost Service quality 24566 2235 546 1235 1998 Under 18\2041 18~30\2042 30~50\2043 above 50\2044 Primary School\2041 Junior School\2042 High School\2043 University\2044 Product quality\2041 Product Price\2042 Product Brand\2043 Cost\2044 Service quality\2045 978-1-4244-2108-4/08/$25.00  \251 2008 IEEE 212\212 212\212 212  Age Degree Care Problem 22      of association rules and Decision Tree ID3 algorithm to enterprise data analysis, establish an Enterprise data analysis system based on data mining This article mainly discusses the application question of data mining in information computerization consumer service III D ATA MINING RESEARCH TECHNIQUE Between the objective things are interrelated and mutual influence and mutual restraint. Reflect the interconnected between things to a quantity, that is correlation between variables. For instance height and body weight, income and expense. The correlation analysis will find the latent rule that is valuable and description variable relates mutually from the data. Through several descriptions correlational dependence statistics may determine between the variable\220s connection close degree and linear correlation direction. Most commonly use is Pearson correlation coefficient, usually indicated with R If variables X and y carries on the observation, obtains a group of data: xi, yi \(i=l, 2, \203, n\ X and between Y the correlation coefficient formula is  x, y respectively is the xi, yi \(i=1,2,\203, n\ Arithmetic average value Where | Rxy 


Using the asymptotic standard error assuming the null hypothesis b Kendall's tau-b Kendall's tau-b Kendall's tau-b Kendall's tau-b first variable match the values of the second variable d  Conclusions analysis From the cross-table, we can see clearly the distribution among different age groups, degrees and concerned problem For example in the 18 to 30-year-old age group, a total of seven individuals, degrees for elementary school, junior school, high school and universities, including high school group has one person be interested in brand, one person be interested in quality. In a word, less than 30 years old age group be greater interest in brand and price, the result fits on young people interest. 30 to 50 years old and over the age of 50 are interested mainly concentrated in cost, reflect the adults to be pragmatic May see from the correlation coefficient table, in 4 different age levels, the correlation degree between the degree and corresponding concerned problem is high, the Pearson correlation coefficient is 0.067.The analysis result indicates that it has not obvious relevance between degree and its choice in other words, in identical age level, regardless of the high degree or low degree, their matter of concern is almost the same Moreover data mining has the strict with the data preparation, previous data preparation work is very important regarding the data mining success or failure, so request have to pay attention to the collection target comprehensive in collection data time, have to use certain method to cover the flaw data, This paper introduces the application technical mentality of data mining technology in the consumer electronic information affairs, and obtains an analysis result from small sample data, does not represent the actual situation, may expand the sample capacity in the practical application , then obtains a more accurate conclusion V CONCLUSIONS At present, the application of data mining in the enterprise consumer services is relatively small, this paper through data mining in one enterprise consumer information services application, the question of independence be linked together demonstrate the nature and potential link of the problem provide better decision-making information and support to the Information for the actual work, we can understand the actual needs of the consumer by these knowledge, enhance the accuracy and scientific decision-making of departments, better service to the people R EFERENCES   1 J i a w ei H a r t  M i ch el i n  K a mbe r o o o o 1 s Figure 1 Correlation Coefficient table 516 522 324 283 740 841 500 500 978-1-4244-2108-4/08/$25.00  \251 2008 IEEE Interval by Interval Interval by Interval Interval by Interval Interval by Interval Beijing: machine industry press 3 T ABLE 3 AFTER TRANSFORMATION DATA FORMS  PART  1 1 2 2 3 4 5 1 1 3 2 3 3 2 3 2 2 1 4 2 1 Not assuming the null hypothesis a Kappa Kappa Kappa Kappa Multi-dimensional cross-table analysis. Used the analysis of SPSS cross-table, select 20 samples randomly, the results as shown in Figure 1 Approx. T b age Gamma Gamma Gamma Gamma Age Degree Care Kappa statistics cannot be computed.They require a symmetric 2-way table in which the value Measure of Agreemen Measure of Agreemen Measure of Agreemen Measure of Agreemen Spearman Correlati Spearman Correlati Spearman Correlati Spearman Correlati N of Valid Cases N of Valid Cases N of Valid Cases N of Valid Cases Symmetric Measures Concept and technique of data mining[M Pearson's R Pearson's R Pearson's R Pearson's R 200 246 1.414 157 500 354 1.414 157 1.000 000 1.414 157 544 261 918 456 c 255 866 478 c  d 4 262 1.261 207 306 243 1.261 207 455 355 1.261 207 376 306 907 406 c 229 660 538 c  d 7 168 2.376 017 667 281 2.376 017 1.000 000 2.376 017 783 174 2.521 065 c 127 3.109 036 c  d 6 306 1.225 221 444 363 1.225 221 1.000 000 1.225 221 500 306 577 667 c 306 577 667 c  d 3 Kendall's tau-c Kendall's tau-c Kendall's tau-c Kendall's tau-c 2 3 4 Value Asymp Std. Error a Approx. Sig  Based on normal approximation c 2001 2 Shen g Y u  T h e A ppl i c a t i o n o f D a t a Mi ni n g i n G o ver n m e nt E l ect r o ni c  Public Service [J  J o ur n a l of I nf o r m at i on  an d 2007 7 8889 200 Ordinal by Ordinal Ordinal by Ordinal Ordinal by Ordinal Ordinal by Ordinal 


 4. Retrieval by cross-modal association rule  We re-rank the initial keyword-based search results with the cross-modal association rules in VAST system  to m a ticall y  As to t h es e ru les co n t ai n i ng  k e yw ord  Q j have the same D\(Q j  and D in formula \(6\nd \(7 the clusters in these rules can be sorted by their  confidence  in descending  order. The query process can be defined as fellows 1  A user enters a query keyword Q j  2  Run the plain textual ranked boolean query based on the keyword-based inverted index and get the initial retrieved images result D\(Q j   3  Look up the association rules table, if there exist the association rules containing the keyword Q j  like the formula \(5\en go on; else go to step 9 4  According to the confidence  of these rules, we order the clusters in these rules containing keyword Q j by their confidence  5  For the top-N initial retrieved images in D\(Q j   the images in the cluster with the largest confidence ranks first, then subsequently the images in the cluster with the second largest confidence, and the same is valid for the rest 6  The images within a cluster are ranked by EMD distance to the cluster centroid in ascending order 7  The images not in these clusters are put in the last by their original order 8  Get the re-ranked results based on 5\6\d 7 9  Return the result to user It can be seen from above that, if exists the association rule for Q j the images that both are contained in the clusters in corresponding rules and include the keyword Q j have higher rank. Otherwise the query process reduces to pure keyword search  5. Conclusions  We use the data mining technique to discover the cross-modal association rules between keyword and region-based image visual feature clusters in VAST  web image retrieval system r m e th od  seamlessly integrates the keyword and visual cluster and overcomes the drawback of RF method and online clustering method  References  1  H  J i n  R  H e  Z  L i a o  W  T a o  a n d Q  Z h a n g   A  Flexible and Extensible Framework for Web Image Retrieval System Proceedings of ICIW'06 2006, pp 193-198 2 M. L  K h e r f i D  Ziou, a n d A  Be rna r di I m a g e Re trie v a l  From the World Wide Web: Issues, Techniques, and Systems ACM Computing Surveys 36\(1\, Mar. 2004 pp. 35-67  W  Ni b l ack R Bar b er W  E q ui t z  et al   T h e QBIC  project: Querying images by content using color, texture and shape," Proceedings of SPIE Storage and Retrieval for Image and Video Databases, Feb. 1994, San Jose CA, pp. 203-207 4 A   W  M. S m eu ld ers, M. W o rrin g S. San t i n i, et al  Content-Based Image Retrieval at the End of the Early Years IEEE Trans. on Pattern Analysis and Machine Intelligence 22\(12\, Dec. 2000, pp. 1349-1380 5 M. O. Bin d e r b erg e r, S. Meh r otra, K. Chakrabarti, et al WebMARS: A multimedia search engine," Proceedings of the SPIE Electronic Imaging 2000: Internet Imaging 2000, San Jose, CA, pp. 23-28 6  M. L  K h e r f i D  Zi ou a n d A  A ndbe r n a r di  A tla s WISE: A Web-based image retrieval engine Proceedings of ICISP'03, 2003, Agadir, Morocco, pp 69-77 7  S. S  Ma r c o L a C a s c ia a nd Sta n Sc la r o f f   C o m bining  Textual and Visual Cues for Content-based Image Retrieval on the World Wide Web," Proc. of IEEE Workshop on Content-based Access of Image and Video Libraries, Jun. 1998  G  P a rk Y Baek an d H K L ee  M aj o r i t y B a sed  Ranking Approach in Web Image Retrieval," Proc. of CIVR'03, 2003, pp. 111-120 9 A   T o m b ros, R. V illa  R., a n d C J. V  Rijsbe rg e n  T he  effectiveness of query specific hierarchic clustering in information retrieval Information Processing Management 38\(4\, 2002, pp. 559-582 10  H.-J. L i a n d J.-K. W a ng  P re c i se im a g e re trie v a l on the  web with a clustering and results optimization," Proc. of ICWAPR '07, Nov. 2007, Beijing, China, pp. 188-193 1 E  Ch en g F  Ji n g  C Z h an g  et al   S earch Resu l t  Clustering Based Relevance Feedback for Web Image Retrival," Proc. of ICASSP'07, Apr. 2007, Case Western Reserve Univ., Cleveland, OH, pp. 961-964 12  E. D G e la sc a  J. D. G u z m a n S  G a ug litz e t a l   CORTINA: Searching a 10 Million + Images Database," Proc. of VLDB'07, Sep. 2007, Vienna Austria 13  M. W  Berr y  P  W a n g an d Y. Yan g  M in in g  longitudinal Web queries: Trends and patterns J Amer. Soc. Inform. Sci. Tech 54, 2003, pp. 743-758  
396 


 then it is considered that flying support belongs to ITVL x  w hereas if the weight of flying support is more towards ITVL y it will be considered as ITVL y support. However, if t he weight of flying support is equal between two ITVLs we will assume that flying support belongs to the ITVL from where the sequential pattern flying support has started   Fig. 3.  Standard and Flying Support  I 1\. Valid Interval Definition After discussing the flying support concept valid interval can be defined as: an interval \(ITVL\ is valid with reference to a given sequential pattern SP, if it satisfies the user defined parameters SD SW within the said ITVL and one of the following conditions is true  267  Standard Support is 001 min_supp 267  Standard Support + Flying Support 001 min_supp 267  Flying Support 001 min_supp  C. Longest Interval \(Problem Definition The problem to mine all the longest intervals can be defined as \223Suppose we have a database of events D and a sequential pattern SP  along with all its user defined parameters and also the user defined granularity The problem is to discover all the longest intervals satisfying the min_ilen parameter for each cycle D 1 D 2 D 3 205.D n 224  I Framework to Discover Longest Intervals Due to the temporal and inter-transactional characteristics of sequential patterns it is recognised that longest interval discovery will be quite an expensive process Consequently  it is important to devise different t echniques, which can help to scan the minimum amount of the database during the mining process Keeping in view the above consideration we decompose the problem of longest interval discovery into four sub-problems These sub problems are basically set of valid intervals with different length  267  Strictly Loose Seed Interval \(SLSI 267  Loose Seed Interval \(LSI 267  Seed Interval \(SI 267  Longest Interval \(LI                               Fig. 4.  Framework to Discover Longest Intervals  T wo main search techniques the Interval Validation Process IVP and the Process Switching Mechanism PSM are introduced here for the discovery of all the longest intervals in each cycle. The main objective of IVP is to confront the complexities which emerge due to the sequential/temporal nature of sequential patterns whereas PSM is devised to increase the efficiency of the mining process by only scanning relevant intervals from the database  I.1.\  IVP \(Interval Validation Process During different stages of the longest interval discovery process, PSM passes the C ITVL Current Interval\ to IVP to v erify if the C ITVL is valid or not \(Fig 4\. IVP first checks t he validity of C ITVL by counting standard support and then i f required it also counts the flying support to check C ITVL  v alidation.  IVP utilises DSCP \(Dynamic Support Counting Process during the standard support counting process for each data sequence DSCP scans only the minimum number of required data-sets from the database in order to find the support of a given sequential pattern\. This process continues until the counted support of the given SP is equal to min_supp parameter and IVP returns \223valid\224 to PSM or there is no data sequence left in C ITVL to check \(IVP returns 223 invalid\224 to PSM If after checking the standard support IVP retains \223invalid\224 against C ITVL then the flying support c oncept needs to be explored \(Fig 4  Algorithm IVP \(Interval Validation Process\ for standard ITVL stage=s_supp indicate different stages of IVP  i=1  counter to fetch next record CS=0  current support of given SP  CR  current record C_Supp  calculated Support RR   remaining records TR   total records if stage=s_supp then  IVP is in standard support stage  LR_ID LR C ITVL     Fetch the last record ID  Loop ITVL Y  Standard Support Flying Support ITVL X  Time Line 


  CR Fetch_Rec C ITVL i\  //to fetch data sequence   C_Supp DSCP CR, SP SD,SW    if  C_Supp<>0 then   CS=CS+C_Supp i=i+1 Add C Seq_Id Seq_List     else     i=i+1 end if if CS 001 min_supp*TR\ then return\(\223valid\224 else if \( \(min_supp * TR\-CS > RR\ or \(i > LR_ID  i=0 Store CS,Data_Struc   stage=\224f_f_supp\224 exit end if  end if if stage=\224complete\224 IVP on C ITVL is complete  exit end if  Fig. 5.  IVP Algorithm for standard support   I Flying Support Discovery Flying support can exist on both sides of C ITVL  T herefore first certain portions of C ITVL  and N ITVL  Next I nterval have to be scanned to find flying support of the given SP. We can call this ITVL as FF ITVL Forward Flying I nterval However after checking the FF ITVL  if C ITVL  is s till invalid then certain portions of C ITVL  and P ITVL   Previous Interval\ have to be scanned as well; we call such ITVL as BF ITVL Backward Flying Interval\ \(Fig 6                                Fig. 6.  Flying Intervals  O nce the FF ITVL is created, the next step is to find pattern s upport in it. Upon finding the flying support for C ITVL IVP a ggregates the support against C ITVL  in the data structure  Table 1 This aggregation depends on the weight of the discovered flying support For example if 70 of the weight is in C ITVL then current support is aggregated with 0 7. The process continues until the min_supp parameter is satisfied or the algorithm scans the last data sequence of FF ITVL   D ata Structure of IVP ITVL ID  ITVL STATUS  SUPPORT STATUS  CYCLE CAL SUPPORT  C ITVL  Valid I nvalid Standard Flying Both Cycle of the C ITVL  C alculated Support  After scanning the FF ITVL  if the min_supp parameter is n ot satisfied, then IVP will count flying support in BF ITVL  O nce the BF ITVL is created, the next step is to count pattern s upport in it Upon finding the flying support IVP aggregates the support against C ITVL  This process c ontinues until the min_supp parameter is satisfied or the algorithm scans the last data sequence of BF ITVL   I 2.\ PSM \(Process Switching Mechanism The main aim of implementing PSM is to scan only those intervals ITVLs which can be part of any longest interval This is done by switching the discovery process into different modes forward mode backward mode and jumping mode Switching of process modes depends on different scenarios during the discovery of SLSI LSI SI and LI  Let us first discuss the definitions of each subproblem  Strictly Loose Seed Interval \(SLSI An interval is a SLSI Strictly Loose Seed Interval with reference to a given  sequential pattern if and only if it is a valid interval and satisfies both the following conditions  267  SLSI is not surrounded by immediate valid intervals 267  SLSI is not a part of any LSI, SI or LI  Loose Seed Interval LSI  An interval is loose seed interval \(LSI\ with reference to a given sequential pattern if and only if, it satisfies all of the following conditions  267  At least first and last ITVLs of potential seed interval are valid 267  The distance between first and last valid interval of LSI is equal to min_ilen parameter 267  There is not a single invalid ITVL between first and last ITVLs of LSI  Seed Interval SI An interval is considered as seed interval \(SI\ with reference to a given sequential pattern if the length of consecutive valid interval is equal to min_ilen parameter  Longest Interval \(LI The longest interval definition was presented in section 4.2 In Fig 7 the longest interval is depicted as LI=\(ITVL 17 ITVL 18 ITVL 19 ITVL 20 ITVL 21   I 2.1\  PSM \(Process Switching Mechanism\ Algorithm The PSM algorithm starts in forward mode by undertaking the first problem, that is to find SLSI \(Strictly Loose Seed Interval\.  It scans the first ITVL to check if it is a valid interval  If IVP discovers that C ITVL  Current I nterval\ is invalid then the process simply moves to N ITVL   Next Interval and this process continues until PSM discovers SLSI or the process reaches the last ITVL of the said cycle \(Fig 8-a                                   Fig. 7.  Different stages of longest ITVL  However, if C ITVL is recognised as valid interval it means 


 that we have found the first SLSI. Upon finding the SLSI PSM undertakes the second sub-problem discovery of LSI According to the definition of LSI for any LSI at least first and last ITVL of potential loose SI have to be valid therefore PSM jumps to the last interval of the potential loose seed interval. The reason for this jump is in the following property of longest interval  267  The longest interval cannot be less than min_ilen and every ITVL within the longest interval has to be valid ITVL  Hence, if we found that ITVL 8 is invalid then there is no n eed to check the ITVLs between ITVL 4  to ITVL 7  since t hey cannot be part of any longest interval \(Fig 8-b  After jumping to the last ITVL of potential LSI PSM again passes the C ITVL to IVP to check if the ITVL is valid o r not. If it is recognised that C ITVL is invalid then it means c urrent SLSI cannot be a part of any longest interval Therefore PSM switches to forward mode by moving to the N ITVL  Next Interval and the process of searching the n ext Strictly Loose Seed Interval \(SLSI\ continues \(Fig 8c\.  However, if C ITVL is valid at this stage, that means we h ave found the first LSI Upon discovering the LSI PSM confronts the third sub-problem discovery of SI To discover SI, PSM has to scan the remaining ITVLs between first and last ITVL of the already discovered LSI Therefore PSM switches into backward mode and scans the ITVL, which is one ITVL previous than the C ITVL Fig 8 d  Validation of C ITVL is checked by IVP again. If C ITVL is i dentified as valid interval then the process of discovering the seed interval will continue  PSM will remain in backward mode and moves to the previous ITVLs one by one to check the validity of different ITVLs This process continues until PSM reaches the already discovered valid interval or it encounters an invalid interval \(Fig 8-e  During the process of discovering SI, if PSM encounters an invalid ITVL at any stage, then it does not have to check the rest of the ITVLs of LSI \(as this LSI cannot be part of any LI\. In this scenario, PSM assigns a new value to SLSI that is the last valid interval identified by PSM in \(see Fig 8-f new SLSI is assigned with ITVL 7 Now the process of d iscovering the next LSI proceeds again. According to the definition of LSI for any LSI at least the first and last ITVLs have to be valid therefore PSM jumps to the last interval of the potential loose seed interval. How long this jump will be depends on the min_ilen parameter If PSM continues in backward mode and reaches the already discovered ITVL then it means we have found a consecutive set of valid intervals whose length is equal to the min-ilen parameter which is the definition of SI In that scenario PSM jumps to the first ITVL after the last ITVL of current SI and the discovery process of LI proceeds \(Fig 8-g\.  In the Longest Interval \(LI\ discovery process PSM switches to forward mode to check the validity of the C ITVL However, if the C ITVL is identified as v alid interval then the seed interval is extended by this C ITVL  This process continues until PSM encounters an i nvalid ITVL or PSM reaches the last interval of the data set. Once PSM encounters an invalid ITVL the process of extending the seed interval terminates. The discovered LI is stored in the data structure and the PSM algorithm proceeds to the search of the next SLSI Fig 9 As we have to discover all the longest intervals for each cycle, the process given in Fig 4 is recursive and it will continue until all the longest intervals of each cycle are found D.  PIDeriver Algorithm for Periodic Interval Discovery Once all the longest intervals for each cycle are discovered with the above motioned approach we can straightforwardly implement the PIDeriver algorithm presented by Chen in 1  t o  d e r i v e  a l l  t h e  p e r i o d i c  t i m e  intervals for a given sequential pattern              Fig. 9.  Discovery process for LI V  INCREMENTAL  DATA  MINING M ining periodicity for sequential patterns is a time consuming process Maintaining the already discovered periodic patterns in the updated database is very important since new data may invalidate some of the discovered periodic patterns and new periodic patterns may emerge due to new data Assuming that the cyclicity granularity and sequential pattern of interest remain the same the approach presented in this paper to discover periodic time intervals for a specific SP can be used for incremental mining of periodic time intervals as well  The approach presented in this paper divides the main problem of finding the periodic time intervals into two sub-problems finding the longest interval for each cycle and discovery of periodic intervals by using already discovered longest intervals of each cycle  Since the second problem is purely based on mining results of first problem the discovered longest intervals in the previous data mining efforts can be used in an incremental data mining process. During the incremental data mining process the algorithm will only focus on finding the longest intervals from new data. However, due to the temporal nature of sequential patterns some portion of the old database will be used as well, the size of this is directly proportional to the user defined parameter of SD Sequence Duration Since finding the longest interval involves most of the processing and complexity during the process of periodic time interval discovery this approach will benefit the incremental data mining quite significantly VI.GENERALISED  MODEL  FOR  FRAMEWORK T he Generalised model GN shows the discovery process of all data filtration transformation discovery of 


 all longest intervals for each cycle and periodic time intervals Transition Z 1  represents the filtration process of t he time stamped database The process of data transformation is represented by transition Z 2  and the data s egmentation by transition Z 3 Transitions Z 4 and Z 5 show r espectively the Process Switching Mechanism \(PSM\ and Interval Validation Process IVP Transition Z 1  has the f ollowing form  Z 1 l 1 l 2 l 4 l 3 l 4 r 1    l 3  l 4  r 1  l 1  false True  l 2  false True  l 4  W 4_3  W 4_4  W 4_3 223The process of data filtration has finished\224 W 4_4 254 W 4_3  P lace l 1  corresponds to the entrance point for the s tamped database in the GN It is represented by one 002  token which enters the input place with initial characteristic 223a stamped database\224  In place l 2  enters 003  t oken with initial characteristic 223time period \(TP\\224   The 002  token simultaneously with the 003 1  token passes t hrough transition Z 1  and enter place l 4  This place c orresponds to the process of filtration The two tokens merge and form one new token with initial characteristic the result of the united characteristics of the tokens On each transition activation the new token passes through the transition and enters again place l 4  extending its c haracteristic with the current results of the filtration process. After the process finishes the final token moves to place l 3 obtaining as a characteristic 223 filtered database\224 Transition Z 2 has the following form  Z 2  l 3  l 5  l 7  l 6  l 7  r 2    l 6  l 7  r 2  l 3  f  alse True   l 5  f  alse  True  l 7  W 7_6  W 7_7  W 7_6 223The process of data transformation has finished\224 W 7_6 254 W 7_7   T he description of transition Z 2 functioning is similar to t he one of transition Z 1 As a joint place between transitions Z 1  and Z 2  place l 3  do not need any addition explanations T he tokens from place l 3  pass through the transition and e nter place l 7  which corresponds to the process of data t ransformation Place l 5  is an entrance point for the p arameter giving the sequential pattern SP which is represented by one 004  token 004  token enters the net with initial characteristic 223sequential pattern\224 The tokens from places l 3 and l 5 pass simultaneously to place l 7 merge and o btain join characteristic. This characteristic is extended on every transition activation by the current results of the transformation process. After the process finishes the final token moves to place l 6 obtaining as characteristic 223 sequence database\224 The process of data segmentation consists of three consecutive stages splitting into user defined cycles division into user interested granules and granulation according to user defined sequence duration parameter. The form of transition Z 3 is the following  Z 3 l 6 l 8 l 9 l 10 l 12 l 13 l 14 l 11 l 12 l 13 l 14 r 3    l 11  l 12  l 13  l 14   l 6  false true false false  l 8  false true false false r 3  l 9  false false true false  l 10  false false false true  l 12  false W 12_12  W 12_13  false  l 13  false false W 13_13  W 13_14   l 14  W 14_11  false false W 14_14  W12_12  223The process of database division into user defined cycles has not finished\224 W12_13  254 W12_12 W13_13  223The process of database granulation has not finished\224, W13_14 = \254 W13_13, W14_11 = \223The process of database segmentation has finished\224 W14_14  254 W14_11  In places l 8  l 9  and l 10  enter respectively one 005   006  and 007  token with initial characteristics 223cyclicity interval  \(CY\\224  223granularity interval GR\\224 and 223sequence duration SD\\224   At the first activation of the transition the two tokens from places l 6 and l 8 pass simultaneously through it, merge i nto one new token and enter place l 12 At the beginning the n ewly created token obtains composite characteristic It extends its characteristic on every pass through the transition and entering into place l 12  with the current state o f the process of database division into user defined cycles After this process finishes the resulting token simultaneously with the 006 token from place l 9 pass through t ransition Z 3 and enter into place l 13 In this process the two t okens merge into one token with initial characteristic the composition of the characteristics of the parent tokens. Like in the previous case the resulting token enters place l 13  e xtending its characteristic with the current state of the process until a granulated database is obtained. On the next step the obtained token enters place l 14 simultaneously with t he 007 token from place l 10 The two tokens unite each other m erging their characteristics The newly created token passes through transition Z 3 and enters place l 14 until a final g ranulated database is obtained On each entrance into place l 14 the token extends its characteristic with the current s tate of the process of database final granulation. At the end of this process the token moves to place l 11  with a c haracteristic 223segmented database\224 Transition Z 4 has the f ollowing form  Z 3 l 6 l 8 l 9 l 10 l 12 l 13 l 14 l 11 l 12 l 13 l 14 r 3    l 11  l 12  l 13  l 14   l 6  false true false false  l 8  false true false false r 3  l 9  false false true false  l 10  false false false true  l 12  false W 12_12  W 12_13  false  l 13  false false W 13_13  W 13_14   l 14  W 14_11  false false W 14_14  


 W 12_12   223The process of database division into user d efined cycles has not finished\224 W 12_13 254 W 12_12  W 13_13  223 The process of database granulation has not finished\224 W 13_14   254 W 13_13  W 14_11   223The process of database s egmentation has finished\224 W 14_14 254 W 14_11   I n places l 8  l 9  and l 10  enter respectively one 005   006  and 007  token with initial characteristics 223cyclicity interval  \(CY\\224  223granularity interval GR\\224 and 223sequence duration SD\\224   At the first activation of the transition the two tokens from places l 6 and l 8 pass simultaneously through it, merge i nto one new token and enter place l 12 At the beginning the n ewly created token obtains composite characteristic It extends its characteristic on every pass through the transition and entering into place l 12  with the current state o f the process of database division into user defined cycles After this process finishes the resulting token simultaneously with the 006 token from place l 9 pass through t ransition Z 3 and enter into place l 13 In this process the two t okens merge into one token with initial characteristic the composition of the characteristics of the parent tokens. Like in the previous case the resulting token enters place l 13  e xtending its characteristic with the current state of the process until a granulated database is obtained. On the next step the obtained token enters place l 14 simultaneously with t he 007 token from place l 10 The two tokens unite each other m erging their characteristics The newly created token passes through transition Z 3 and enters place l 14 until a final g ranulated database is obtained On each entrance into place l 14 the token extends its characteristic with the current s tate of the process of database final granulation. At the end of this process the token moves to place l 11  with a c haracteristic 223segmented database\224 Transition Z 4 has the f ollowing form  Z 4  l 11  l 17  l 18  l 19  l 15  l 16  l 17  l 18  r 4    l 15  l 16  l 17  l 18    l 11  t  rue false  False  false   r 4  l 17  f  alse  W 17_16  W 17_17  false    l 18  false false W 18_17  true   l 19  f  alse false  True  false   W 17_16   223The process of data segmentation has f inished\224 W 17_17   254 W 17_16  W 18_17   223The PSM has to j ump minimum length parameter steps\224  Initially in place l 18 enters one b  token with initial characteristic 223minimum interval length \(min_ilen\\224   The already segmented database from place l 11 pass i nterval ITVL by interval through transition Z 4  to place l 15 The token from place l 11 passes directly to place l 15 for v alidity check without obtaining any new characteristics The b token moves simultaneously with one of the tokens in place l 19  to place l 17  obtaining as characteristic t he current state of the process of the longest interval LI finding\224  At the end of this process the resulting tokens move to place l 16 and merge with the tokens from the same interval o btaining characteristic 223segments of the longest interval\224 The form of transition Z 5 is  Z 5  l 15  l 19  r 5    l 19   r 5  l 15  t  rue  VII  CONCLUSION  AND  FUTURE  WORK I n this paper the problem of finding the periodic time intervals for a given sequential pattern is addressed The approach presented in this paper divides the main problem into two sub-problems finding the longest intervals for each cycle and discovery of periodic time intervals by using the already discovered longest intervals of each cycle Almost all the data processing and complexity is covered during the process of finding the longest intervals Moreover the second problem is purely based on mining results from the first problem.  Therefore, in this paper we mainly focused on the problem to find all the longest intervals for each cycle To confront the above problem efficiently, we introduced two main search techniques IVP Interval Validation Process\ and PSM \(Process Switching Mechanism\.  In this paper we have presented an effective mining approach for finding all the periodic time intervals for a given sequential pattern. As a future work the process presented in this paper can be extended to find periodic time intervals for all the given sequential patterns in one database scan However to accomplish this task a more complex data-structure/memory management technique needs to be implemented REFERENCES 1  X  Chen and I. Petrounias, Mining Temporal Features in Association Rules, Proc. of PKDD\22299, Prague, Czech Republic, pp.295-300 2  Ozden B Ramaswamy S and Silberschatz A  Cyclic Association Rules in Proceedings of the 14 th   International C onference on Data Engineering 1998 Orlando Florida USA IEEE Computer Society 3  Han, J., Pei, J., and Yin, Y., Mining Segment-Wise Periodic Patterns in Time-Related Databases in Proceedings of the 4 th   International C onference on Knowledge Discovery and Data Mining, 1998: AAAI Press, Menlo Park 4  Yang J Wang W and Yu P.S Mining asynchronous periodic patterns in time series data in Proceedings of KDD 2000 p 275279 5  Huang K.-Y and Change C.-H Asynchronous periodic patterns mining in temporal databases in Proceedings of the International Conference on Databases and Applications DBA'04 2004 Innsbruck, Austria 6  Huang K.-Y and Change C.-H  Mining Periodic Patterns in Sequence Data In Proceedings of the 6th International Conference on Data Warehousing and Knowledge Discovery DaWaK 2004 Zaragoza, Spain: Springer 7  Yang J Wang W and Yu P.S Mining Surprising Periodic Patterns, in Data Mining and Knowledge Discovery, 2004 8 p. 253273 8  Lin W Orgun M.A and Williams G.J  An Overview of T emporal Data Mining in Proceedings of the 1st Australian Data Mining Workshop, 2002  9  C  hen X and Petrounias I  A Framework for Temporal Data Mining, in Proceedings of 9 th International Conference on Database a nd Expert Systems Applications DEXA'98 1998 Vienna Austria: Spring 


 Fig. 8. PSM \(Process Switching Mechanism Move to N ITVL Next Interval 1 2 3 4 5 Time Line Invalid ITVL   a\  SLSI discovery process \(forward mode continues  Jump to 8 th ITVL min_ilen=6 1 2 3 4 5 Time Line 6 7 8 b SLSI found \(process in jumping mode  M o v e  t o  N I T V L  t o  f i n d  n e x t S L S I  p ro c e s s  s w i t c h  t o f o r w a r d m o d e  1 2 3 4 5 T i m e  L i n e L a s t  S L S I f o u n d 6 7 8 9 I n v a l i d I T V L  c \  SLSI found but C ITVL is invalid   Backward Mode 1 2 3 4 5 Time Line LSI found 6 7 8 9 Valid ITVL d  LSI is found and process switches into backward mode   Backward Mode 1 2 3 4 5 Time Line LSI found 6 7 8 9   e\  LSI found- Seed Interval Discovery Process 1 2 3 4 5 Time Line 6 7 8 9 Invalid ITVL SLSI is assign new value of ITVL 7 and the p rocess of searching next LSI proceed again 12 11 10 13  f\  PSM encounters invalid ITVL during the search of SI  1 2 3 4 5 T ime L ine 6 7 8 9 SI Fo u n d D isco v ery p ro c ess o f L I p ro c eed s  g\  SI is found and PSM proceed for the discovery of LI   



A LEARNING RULE FOR FUZZY ASSOCIATIVE MEMORIES  Fan Junbo Jin Fan and Shi Yan Inst of Neural Networks  Information Techniques Southwest Jiaotong University Chengdu Sichuan 610031 P R China Abstract In this paper a learning rule for multiple pattern pairs in fuzzy associative memories FAMs with 
Max-Min composition units is presented, Under a certain condition the proposed rule can efficiently encode multiple fuzzy pattern pairs in a single FAM and perfect association of these pairs can be achieved The correctness of the proposed rule is proved and illustrative examples are given 1 Introduction It is well known that neural networks can efficiently model subjective phenomena such as perception image 
and memory while fuzzy logic is another powerful tool to model phenomena associated with perception and thinking In recent years several models that combine neural networks and fuzzy logic called fuzzy neural networks have been developed and widely applied to prospective fields such as control, pattern recognition decision making and expert systems[l 51 The FAM introduced by Kosko which involves Max-Min composition units is one 
of the most useful and important paradigms[l 21 Such a FAM is characterized by the subset recall when trained using the fuzzy Hebian rule The inability to reliably store more than one pair is its enssential drawback Some endeavors have given brith to overcoming this drawback Hirota and Pedrycz used a gradient descent algorithm with two-value derivatives under some constraints 
SI Authors of this paper ever suggested an iterative learning algorithm that employed a so called hill climbing search strategy to conduct connection weight adjustments However both algorithms may easily get struck at local minima of a defined index function although satisfactory performence of the trained FAM can usually be achieved We propose here another learning rule that employs a 
suitable fuzzy logical-implication operation different from the fuzzy Hebbian rule used by Kosko The proposed rule is capable of encoding multiple pattern pairs in the weight matrix of a FAM if there exists some weight matrix that properly forms the fuzzy relation between the input and output of the given pairs 2 FAMs with Max-Min Composition Units 
A FAM is designed to store p fuzzy  unit-interval valued 1 pattern pairs AI B1    Ap Bp in the weight matrix W where the kth pair is represented by the vectors Ak a  ai 1 and Bk   b bi 1 
respectively shou Id hold The topology of a FAM is shown in Fig 1 In the FAM with Max-Min composition units perfect association implies that eq  1 This work is partly supported by both the National Natural Science Foundation of the 863-High Technology Programme of China China and 4273 


where the symbol 0 denotes the Max-Min composition operation Generally there are two kinds of methods to find the weight matrix W One is to define a performence index for instance the sum of squared errors where bf and bj are the desired output and actual output of the jth adjustment is aimed at minimizing the index function[6 The other is pair  Ak Bk  into the matrix wk and then to superimpose the matri matrix W i.e W may be found using the following equation output unit We to encode the s es Wk s in a s gh t ngle ngle where the symbol  denotes some implication operation and  n  denotes a generalized superimposition  e.g maxima minima etc 1 Kosko adopted a fuzzy Hebbian  the minh implication Rc rule pointwise to encode the kth pair  Ak Bk  in the wk then superimposed the matrices Wks in a single matrix W by the maximum operation That is P k 1 wij  v WIj where the symbols V and A stand for the maximum and minimum operations respectively, and w ijs are components of the W Obviously, multiple pairs can not be reliably stored in the FAM An approach to overcoming the problem is that a bank of FAMs is used each of which seperately store only one pair But this results in consuming space of storage 3 The Proposed Learning Rule As usual, we wish to distributively and reliably store multiple fuzzy pattern pairs Ak Bk in a single FAM such that each Bk can be perfectly recalled when each corresponding A k is presented Instead of using the minimum implication Rc we associate here Bk with Ak usng the implication Rg and we replace the maximum superimposition by the minimum one 8s well In this way we obtain the following learning rule 4274 


In pointwise notation that is lbf if a  bf 1 otherwise wij  A P af  bf k 1 6 7 Obviously the complexity of the proposed learning rule is equivalent to the rule used by Kosko As we know there doesn't always exist the weight matrix of a FAM which makes eq  1 hold for arbitrary set of input-output pairs In other words these pairs have to satisfy a certain condition for the purpose of perfect association On the other hand even if there exists some desired weight matrix the Kosko's rule is not guaranteed to yield the desired matrix as shown in I 21 Based on analyzing the condition for existence of desired weight matrix we show below that the proposed learning rule can yield the desired matrix if it indeed exists Since the m units in the output layer of the FAM are independent one another we can consider only one output unit For the jth output unit, we have We define the following sets and value A bf if Gij  cp kt Gij Then the necessary and sufficient condition for existence of the desired weight vector that enables eq 8 to hold can be expressed a8 follows[81 t.J Sij K iC I 4275 1 5 


If there exists some weight vector enabling eq for all iE I By definition af\222  bf\222 or wij mi v  af\222 A wij   bf\222 This is obvious ilkdSij U Sij  K For any kt K a  bf or wij mij bf for iE I mij 2 bf or ajf  bf and mij  bf for all i as kE Si v ajf~wi  IV  ajf A wij 11 v   iE I ilkE Sij iI 8 to hold such that some k\222\200 K but k\222  Sij  bf\222 Hence we have bk\222  V aik\222 A wij iE I y a contradiction Vice versa assume that all i as kE Sij but a  b jk and  Hence if let wij  mij we have v ajf A mij This means that there exists a weight vector enabling eq 8 to hold So there exists a weight matrix W enabling eq 1 to ho if and only if eq  15 holds for any j The proposed learning rule expressed by eq 6 and 7 is in accordance with eq 13 From above analysis, we can conclude that the proposed rule can yield the desired weight matrix enabling eq 1 to hold if it exists ilkE Sij 4 Examples Two sets of fuzzy pattern pairs Datal and Data2  to be stored are shown in Tab 1 and 2 For Datal, we can obtain the weight matrix of the FAM using the proposed rule 0 6 0 5 1 0 0 9 1 0 0 5 16 w 0 4 0 5 0 4 0 4 0 6 0 4 1 The FAM with the above matrix can perfectly each output pattern Bk when presented with each input pattern Ak But the Kosko\222s rule produces the following weight matrix 0 9 0 7 0 6 0 9 0 7 0 7 w 0 6 0 6 0 6 0 6 0 6 0 6 1 With the matrix the trained FAM can not perfectly all pairs in Datal For DataZ two rules yield matrices 2 0 8 1 0 I 0 1 0 0 4 6 0 5 1 0 0 4 0 4 0 5 1 and 0 4 0 8 0 5 0 7 0 6 0 6 w 0 6 0 5 0 5 0 4 0 5 0 5 1 17 18 19 It is easy to confirm that eq 1 holds with eq 181 but it dosen\222t with the weight matrix eq 19 4276 


5 Conclusion A learning rule for multiple fuzzy pattern pairs in FAMs with Max-Min composition units is presented Under a certain condition, multiple pairs can be reliably stored in a single FAM and perfect associations can be achieved The correctness of the proposed rule is demonstrated Due to the simple complexity  the proposed rule may be much of use in the design of fuzzy systems where multiple inference rules need to be reliably stored References 11 Kosko B 1987 Fuzzy Associative Memories In Kandel A Ed  Fuzzy Expert Systems 21 Kosko B 1991 Neural Networks and Fuzzy Systems a dynamical systems approach to machine 31 Jin F FAN J B and TAN Y D 1991 Neural Networks and Neurocomputers I41 Fan J B Jin F and Yuan X  1992  A New Neuro- Fuzzy Network for Pattern 51 Fan J B Jin F and Shi Y 1992 A New Model of Fuzzy Associative Memories Proc 161 Hirota K and Pedrycz W 1991 Fuuzy Logic Neural Networks Design and Computations I71 Fan J B Jin F and Yuan X 1992 A Learning Algorithm for Multiple Fuzzy Pattern SI Saito T and Mukaidono M 1991 A Learning Algorithm for Max Min Network and Its Reading MA Addison-Wesley intelligence Principles and Applications Southwest Jiaotong University Press Classification, Proc of the ICIIPS\22292 Beij ing of the IJCNN\22292 Beijing Vol 3 Proc of the IJCNN\222 91 Singapore pair Associations, Proc of IJCNN\22292  Beijing 1 Vol 3 Application to Solve Fuzzy Relation Equation, Proc of the IFSA\22292 Bussels bl bj bm f f f Output Layer w Input Layer t P P al ai an Fig 1 The topology of a FAM Tab 1 Datal Tab 2 Data2 k Ak Bk k Ak Bk 1 0.7 0.2 0.4 0.6 0.3 0.8 0.6 0.4 2 0.9 0.4 0.5 1.0 0.7 0.0 0.9 0.6 3 0.3 0.6 0.4 0.5 0.2 0.9 0.5 0.5 4 0.1 0.7 0.4 0.7 0.7 0.7 0.7 0.6 5 0.3 0.6 0.4 0.8 0.2 0.4 0.8 0.5 6 0.7 0.9 0.6 0.1 0.7 0.4 0.7 0.6 7 0.8 0.1 0.6 0.5 0.4 0.3 0.6 0.4 1 0.1 0.9 0.5 0.4 0.5 0.6 0.8 0.5 2 0 3 0 2 0 4 0 3 0 6 0 4 0 6 0 4 3 0.9 0.2 0.2 0.1 0.3 0.0 0.3 0.6 4 0.4 0.0 0.4 0.7 0.4 0.1 0.7 0.4 5 0.8 0.2 0.2 0.1 0.0 0.2 0.2 0.6 6 0 4 0 1 0 5 0 3 0 2 0 9 0 5 0 5 7 0.5 0.2 0.0 0.3 0.2 0.6 0.4 0.5 4277 


Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


Figure 8 Visual interface for Moridou system Search EngineTest Page 0 UI 0 5 5 Keyword plealet Figure 9 Prototype system in hcterogeneous environment 283 


6 Conclusions We presented MAFIA an algorithm for finding maximal frequent itemsets Our experimental results demonstrate that MAFIA consistently outperforms Depthproject by a factor of three to five on average The breakdown of the algorithmic components showed parent-equivalence pruning and dynamic reordering were quite beneficial in reducing the search space while relative compressiodprojection of the vertical bitmaps dramatically cuts the cost of counting supports of itemsets and increases the vertical scalability of MAFIA Acknowledgements We thank Ramesh Agarwal and Charu Aggarwal for discussing Depthproject and giving us advise on its implementation We also thank Jayant R Haritsa for his insightful comments on the MAFIA algorithm and Jiawei Han for providing us the executable of the FP-Tree algorithm This research was partly supported by an IBM Faculty Development Award and by a grant from Microsoft Research References I R Agarwal C Aggarwal and V V V Prasad A Tree Projection Algorithm for Generation of Frequent Itemsets Journal of Parallel and Distributed Computing special issue on high performance data mining to appear 2000 2 R Agrawal T Imielinski and R Srikant Mining association rules between sets of items in large databases SIGMOD May 1993  R Agrawal R Srikant Fast Algorithms for Mining Association Rules Proc of the 20th Int Conference on Very Large Databases Santiago Chile, Sept 1994  R Agrawal H Mannila R Srikant H Toivonen and A 1 Verkamo Fast Discovery of Association Rules Advances in Knowledge Discovery and Data Mining Chapter 12 AAAVMIT Press 1995 5 C C Aggarwal P S Yu Mining Large Itemsets for Association Rules Data Engineering Bulletin 21 1 23-31 1 998 6 C C Aggarwal P S Yu Online Generation of Association Rules. ICDE 1998: 402-41 1 7 R J Bayardo Efficiently mining long patterns from databases SICMOD 1998: 85-93 8 R J Bayardo and R Agrawal Mining the Most Interesting Rules SIGKDD 1999 145-154 9 S Brin R Motwani J D Ullman and S Tsur Dynamic itemset counting and implication rules for market basket data SIGMOD Record ACM Special Interest Group on Management of Data 26\(2\1997 IO B Dunkel and N Soparkar Data Organization and access for efficient data mining ICDE 1999 l 11 V Ganti J E Gehrke and R Ramakrishnan DEMON Mining and Monitoring Evolving Data. ICDE 2000: 439-448  121 D Gunopulos H Mannila and S Saluja Discovering All Most Specific Sentences by Randomized Algorithms ICDT 1997: 215-229 I31 J Han J Pei and Y Yin Mining Frequent Pattems without Candidate Generation SIGMOD Conference 2000 1  12 I41 M Holsheimer M L Kersten H Mannila and H.Toivonen A Perspective on Databases and Data Mining I51 W Lee and S J Stolfo Data mining approaches for intrusion detection Proceedings of the 7th USENIX Securiry Symposium 1998 I61 D I Lin and Z M Kedem Pincer search A new algorithm for discovering the maximum frequent sets Proc of the 6th Int Conference on Extending Database Technology EDBT Valencia Spain 1998 17 J.-L Lin M.H Dunham Mining Association Rules: Anti Skew Algorithms ICDE 1998 486-493 IS B Mobasher N Jain E H Han and J Srivastava Web mining Pattem discovery from world wide web transactions Technical Report TR-96050 Department of Computer Science University of Minnesota, Minneapolis, 1996 19 J S Park M.-S Chen P S Yu An Effective Hash Based Algorithm for Mining Association Rules SIGMOD Conference 20 N Pasquier Y Bastide R Taouil and L Lakhal Discovering frequent closed itemsets for association rules ICDT 99 398-416, Jerusalem Israel January 1999 21 J Pei J Han and R Mao CLOSET An efficient algorithm for mining frequent closed itemsets Proc of ACM SIGMOD DMKD Workshop Dallas TX May 2000 22 R Rastogi and K Shim Mining Optimized Association Rules with Categorical and Numeric Attributes ICDE 1998 Orlando, Florida, February 1998 23 L Rigoutsos and A Floratos Combinatorial pattem discovery in biological sequences The Teiresias algorithm Bioinfomatics 14 1 1998 55-67 24 R Rymon Search through Systematic Set Enumeration Proc Of Third Int'l Conf On Principles of Knowledge Representation and Reasoning 539 550 I992 25 A Savasere E Omiecinski and S Navathe An efficient algorithm for mining association rules in large databases 21st VLDB Conference 1995 26 P Shenoy J R Haritsa S Sudarshan G Bhalotia M Bawa and D Shah: Turbo-charging Vertical Mining of Large Databases SIGMOD Conference 2000: 22-33 27 R Srikant R Agrawal Mining Generalized Association Rules VLDB 1995 407-419 28 H Toivonen Sampling Large Databases for Association Rules VLDB 1996 134-145 29 K Wang Y He J Han Mining Frequent Itemsets Using Support Constraints VLDB 2000 43-52 30 G I Webb OPUS An efficient admissible algorithm for unordered search Journal of Artificial Intelligence Research 31 L Yip K K Loo B Kao D Cheung and C.K Cheng Lgen A Lattice-Based Candidate Set Generation Algorithm for I/O Efficient Association Rule Mining PAKDD 99 Beijing 1999 32 M J Zaki Scalable Algorithms for Association Mining IEEE Transactions on Knowledge and Data Engineering Vol 12 No 3 pp 372-390 May/June 2000 33 M. J. Zaki and C Hsiao CHARM An efficient algorithm for closed association rule mining RPI Technical Report 99-10 1999 KDD 1995: 150-155 1995 175-186 3~45-83 1996 452 



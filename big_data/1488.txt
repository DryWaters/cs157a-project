ECE Department University of Connecticut Storrs CT 06269 ECE Department Carnegie Mellon University Pittsburgh PA 15213 Qualtech Systems Inc 100 Great Meadow Road Wethers\223eld CT 06109 
 Christian R Berger  Peter Willett  Mohammad Azam  and Sudipto Ghoshal 
1 2 1 3 3 1 2 3 
Comparison of Data Reduction Techniques Based on the Performance of SVM-type Classi\223ers Ramona Georgescu 
In this work we applied several techniques for data reduction to publicly available datasets with the goal of comparing how an increasing level of compression affects the performance of SVM-type classi\223ers We consistently attained correct rates in the neighborhood of 90 with the Principal Component Analysis PCA having a slight edge over the other data reduction methods PLS SRM and OMP One dataset proved to be hard to classify even in the case of no dimensionality reduction Also in this most challenging dataset performing PCA was considered to offer some advantages over the other compression techniques Based on our assessment data reduction appears a useful tool that can provide a signi\223cant reduction in signal processing load with 
Abstract\204 
acceptable loss in performance 
1 1 3 
T ABLE OF C ONTENTS 1I NTRODUCTION  
Data Reduction PCA PLS SRM OMP Classi\223cation SVM PSVM 
Keywords\204 
2D ATA R EDUCTION T ECHNIQUES  3C LASSIFIERS  4R ESULTS  
4 7 7 8 The recent advances in data collection and storage capabilities have led to information overload in many applications e.g on-line monitoring of spacecraft operations with time series data It is therefore desirable to perform data reduction before storage or transmission of data which can be lossy as not all features of data might be relevant 
R EFERENCES  B IOGRAPHY  
5C ONCLUSION  
1 I NTRODUCTION 
2010 IEEE 
Another motivation for our study is that in real systems the dimensionality of the acquired data is often lower than the space that it is measured in Reconstruction from low dimensional samples is needed and possible with varying degrees of accuracy Also in classi\223cation the dimensionality of the 
1 2 
25 00 
978-1-4244-3888-4/10 IEEEAC Paper 1557 Version 5 Updated January 23 2010 data needed to distinguish between different classes is a measure of the information loss that can be tolerated in lossy compression schemes 
 
c 
002 
In this paper we consider the setup in Figure 1 sensors acquire a large amount of data where each observation is often of high dimension by itself e.g ten to thirty dimensional The data is compressed for storage or transmission and reconstructed before performing classi\223cation We impose the constraint that each observation has to be stored or transmitted seperately which strongly limits the possibilities of data compression Since the data is of unknown structure we differentiate two cases i the codebook used for encoding is build based on a training subset of the data or ii the codebook is 223xed a priori without knowledge of any data For the 223rst case we employ Principal Component Analysis PCA and Partial Least Squares PLS while for the blind 
case we consider Structurally Random Matrices SRM and Orthogonal Matching Pursuit OMP We compare their performance on the classi\223cation of publicly available datasets where for classi\223cation we consider Support Vector Machines SVM and Proximal Support Vector Machines PSVM The experiments are performed on the Wisconsin Diagnostic Breast Cancer WDBC dataset the Ionosphere dataset both available at the Machine Learning Repository of University of California-Irvine and on the FD001 T urbof an Engine Degradation Simulation dataset provided by NASA References to relevant studies performed on these datasets can be found at and respecti v ely 3 
2 D ATA R EDUCTION 
T ECHNIQUES 
Principal Component Analysis 
PCA is an orthogonal linear transformation that converts the data to a new coordinate system such that the greatest variance by any projection of the data comes to lie on the 223rst coordinate called the 223rst principal component the second greatest variance on the second coordinate and so on PCA can be used for dimensionality reduction in a dataset by presumably retaining those characteristics of the dataset that contribute most to its variance i.e by keeping lowerorder principal components and ignoring higher-order ones 1 


 X Y Y 2 2 plsregress error n cov x X X S T L S L S T L S T L Y Comp S Comp L Comp S Comp L Comp s s s s T s s s s S S Comp S L S T L 327 and in the principal component space and 327 X s s 1 X X is a signal that after some linear transform can be represented by at most K 327 327 with the constraint that these components explain as much as possible the covariance between in the training set We pass the scores obtained on the training set to the chosen classi\223er along with the scores obtained for the testing set by projecting the observations in the testing set  w that contains the corresponding classes for the observations in  We used the p X X Y X d  1             K<<d space PLS is therefore a supervised learning technique while PCA belongs to unsupervised learning For a x data matrix X  Y  327 w K  can follo w t he PLS decomposition W e ha v e chosen not to take this approach and instead feed the results of the decomposition to a classi\223er X  in which each row represents an observation and each column represents a feature the PCA transformation is given by  e.g one could try predicting a person\220s weight modeled as  This linear model tries to 223nd the multidimensional direction in the  in which each row represents an observation and each column represents a feature and a  the PLS transformation is given by  on the loadings of the training set  1 where are the scores i.e a matrix of dimension are the loadings i.e a matrix of dimension 2 3 With being the number of components retained is a matrix of dimension is a matrix of dimension is of dimension is of dimension where and  In other words PLS 223nds components from is an orthonormal matrix while is neither orthogonal nor normalized The matrix constructed by the weight vectors  according to the formula space that explains the maximum multidimensional variance direction in the is a Xw,Y c Xw XW sparse signal X such that matrix X Y  Figure 1 X y y that are also relevant for p n n representing the extracted predictor scores and n 212 4 A regression step in which the decomposition of cov 327 X Yc y  Partial Least Squares Structurally Random Matrices y nonzero coef\223cients p and independent predictor variables  327  from their age and gender stored in  Several variants of PLS exist we used the SIMPLS form of PLS introduced by de Jong in which n n p n n n p n cov x x p X X  x   X denotes the sample covariance between the score vectors function in the Statistics Toolbox of MATLAB R2008a to implement PCA and calculate the scores and loadings of of PLS weights with the property that X function in the Statistics Toolbox of MATLAB R2008a to implement PCA and calculate the scores and loadings of the training set We project the observations in the testing set on the loadings obtained for the training set and thus obtain the scores for the testing set as the equation above suggests then we pass the scores obtained for the training set and the scores obtained for the testing set to the chosen classi\223er Y Y Y of length error      Sensors Dimensionality Reduction PCA, PLS SRM, OMP Bandlimited Channel Reconstruction of Sensor Data Classifier SVM, PSVM Shared Codebook X vector X c X X and and X      n  Y W 327   X  containing the predictor loadings Y that contains the principal component coef\223cients The loadings represent the 216axes\215 of the new coordinate system and the scores can be thought of as the coef\223cients corresponding to the new 216axes\215 We used the Y Y 327 002 002 002 princomp by performing a simultaneous decomposition of X y n W  and that represents  X p  data matrix is used to predict X X Y W PLS constructs a linear model that describes the relationship between dependent response variables  and A  According to compressed sensing theory  8 9 the signal can be e xactly reconstructed from its 2 002 n 1 x X Y Y  System diagram Such low-order components often contain the most important aspects of the data For a  PLS uses the nonlinear iterative partial least squares NIPALS algorithm to 223nd weight v ectors 327 


 a 032 D 002 a  MP is a greedy algorithm that at each iteration selects one column of M s a  1 2 1 2 2 1 2 0 OMP 2 j<p has been 223xed a priori the receiver/classi\223er can perform reconstruction of the observations so that they can be fed into the appropriate classi\223er 3 C LASSIFIERS d is a random projection or a random matrix of subgaussian i.i.d entries When an input signal x A A a w b A x x x x x x x and F as it gives real outputs and kept the same order coef\223cients for the training set and the testing set  the local randomizer is a y log 1 1 1 1 1 1 j 004 0 003 11 where the underde\223ned equation matrix Thus SRM is also a promising dimensionality reduction transform which can be shown to preserve all pairwise distances of high dimensional vectors to within an arbitrarily small factor We used the same R 002 y 212 212 212 212 212 d O orthonormal matrix whose absolute magnitude of all entries are on the order of r 002 212 003 nonzero rows and thus r A   arg max      arg min   R 327 P A 002 is a  032 p p p p p p p p p p p j p p d M DF R r  s r  a x A A y a x 8 The updated residual vector is computed as random diagonal matrix whose diagonal entries d as a product of three matrices is a r   A M x 1 that correlates best with the approximation residual from the previous iteration More speci\223cally at the 002 002  D 032 K d R D D p a a s a y 212 contains P not in the index set of all previously selected columns R  327 associated with F M r 002 a is chosen to have fast computation and ef\223cient implementation such as fast Fourier transform FFT discrete cosine transform DCT etc and   Then 032  f is given by Ax r y p and it is not of minimal length The Orthogonal Matching Pursuit OMP algorithm was constructed to address this issue At each step after a new column has been chosen according to Eq 7 the OMP algorithm recomputes the coef\223cients as follows 032 in practice 032 j 261 a d on the training set and the testing set which was 223xed a priori We chose the discrete cosine transform for weights also a vector The 3 as a matrix populated by i.i.d normal distributed random numbers We then run OMP for each observation in the training set and in the testing set For each observation we obtain a longer vector that contains a small number of nonzero entries The number of nonzero entries is speci\223ed such that dimensionality reduction is achieved Only the nonzero elements and their location are transmitted doubling the communication effort but achieving dimensionality reduction nonetheless Since ii ii d ii ii d th s p j h j p j p p s s s h s p s p p s s s p s sj s p s x s,p h s,p s,p h s,p s,p s 1 s h A being a point a vector and        212  y random projection of much lower dimension are i.i.d Bernoulli random variables with  are i.i.d binary random variables with  iteration the selected column  7 for  the element of  is found as follows 9 where we initialize may not give the minimal residual error This is because although is orthogonal to  it is not necessarily orthogonal to for calculated as in Eq 8 the residual vector is not orthogonal to the space spanned by for 10 is the Hermitian operator i.e the conjugate transpose of a matrix This equation essentially carries out the least squares minimization based on the set of columns chosen at each iteration However the rule of selecting the new column is the same as for the MP In our case we 223rst create is of large length for example a vectorized megapixel image using a random projection is clearly impractical as a huge amount of computational complexity and memory buffering is needed to compute the projection 003 Orthogonal Matching Pursuit Support Vector Machine a w 032 x d I x  327  a uniformly random downsampler is a matrix composed of nonzero rows of a random diagonal matrix whose diagonal entries F 6 where A compressed sensing algorithm 12 that can be recast as a dimensionality reduction method is Matching Pursuit MP MP 223nds a suboptimal solution to the problem of an adaptive approximation of a signal in a redundant set dictionary of functions It solves for  which means that with SVMs start with the goal of separating the data with a hyperplane and extends this to non-linear decision boundaries using a kernel The equation of a general hyperplane is with  1  O  Recently structurally random matices SRMs have been proposed as a fast and highly ef\223cient compressed sensing method that guarantees optimal performance We use the de\223nition of a structurally random matrix  When the set of columns chosen are not orthogonal the set of coef\223cients 5 where s 


003 x b b   x correct rate in all scenarios most of the time Therefore data reduction is highly recommended in some cases the approach being able to reduce 30 dimensions to 5 or less with negligible loss in performance More speci\223cally SRM and OMP display as expected a clear increase in correct rate with increasing number of re4 that achieve the best performance for each particular classi\223er-data reduction method combination are shown For OMP we set the number of rows of 002 0 0 j 2 3 1 3 w x x were 0.1 1 10 100 1000 The value of   Proximal Support Vector Machine Results on the WDBC Dataset x j 212 002 x 003  003 003 212 4 R ESULTS K 90 of one class and of the other class If the data are in fact separable in this way there is probably more than one way to do it Among the possible hyperplanes SVMs select the one where the distance from the hyperplane to the closest data points the 215margin\216 is as large as possible In practice it is unlikely that a line will exactly separate the data and even if a curved decision boundary does exactly separating the data is probably not desirable if the data has noise and outliers a smooth decision boundary that ignores a few data points is better than one that loops around the outliers Adding slack variables allows a point to be a small distance on the wrong side of the hyperplane without violating the problem constraints An optimization-based derivation of SVMs is presented in the tutorial in of the instances went to the training set and to the testing set Ten Monte Carlo runs were averaged for each scenario For both the nonlinear SVM and nonlinear PSVM we used a Gaussian Radial Basis Function RBF as a kernel described by 12 For all the data reduction methods we chose to do experiments with 2 5 10 15 20 25 and 30 components For OMP transmitting the nonzero elements and their position in the data obtained after executing the OMP doubles the communication effort and therefore the number of components retained becomes 4 10 20 30 The values we tried for tuning the standard deviation of the Gaussian RBF x i a approach b approach 003  The values we tried for to 100 to allow the algorithm enough 224exibility in calculating its solution It has to be noted that running OMP introduces a slight time delay compared to other methods that has to be taken into account when selecting a data reduction method Figure 2 were 0.1 1 5 10 25 50 PSVM requires tuning of parameter 003 and/or k k j j i  SVM approach vs PSVM approach hyperplane should separate the data so that w e  2 2 SVM classi\223es points by assigning them to one of two disjoint halfspaces In PSVM the separating planes are not bounding planes but can be thought of as proximal planes around which the points of each class are clustered and which are pushed as far apart as possible as seen in Figure 2 This formulation can also be interpreted as regularized least squares PSVM leads to a fast and simple algorithm for generating a linear or nonlinear classi\223er that only requires the solution of a single system of linear equations In contrast SVM solves a quadratic or linear program that requires considerably longer computational time Computational results on publicly available datasets indicate that the proximal SVM classi\223er has comparable test set correctness to that of SVM classi\223ers 14 Standardizing the data is reasonable when the variables are in different units or when the variance of the different columns is substantial Therefore the data was centered by subtracting off column means and also by dividing each column by its standard deviation The data was randomly split such that For a performance comparison between the various data reduction methods see Figures 3 and 4 All methods perform well allowing both classi\223ers to achieve over for all the x that gave the best performance with the linear SVM was also used for the nonlinear PSVM In the following 223gures plots for the for all the 002 2 A 


better 327  WDBC-SVM-Performance Comparison tained components converging to the 215no reduction\216 case when all dimensiones are retained On the contrary the PCA and PLS curves tend to be more 224at without an obvious connection between the number of retained dimensions and the correct classi\223cation rate Even more surprising in the case of linear SVM or PSVM classi\223ers applying PCA or PLS sometimes renders  WDBC-PSVM-Performance Comparison even for a linear classi\223er Dif\223culty was increased progressively by analyzing two other datasets  in all scenarios For a performance comparison between the various data reduction methods please refer to Figures 5 and 6 For both SVM and PSVM a nonlinear classi\223er shows a noticeable improvement over a linear classi\223er by approximately  5 002 additionally misclassi\223ed samples in the testing set In all scenarios SVM and PSVM can be considered to achieve similar classi\223cation correct rates For both classi\223ers the nonlinear version is slightly superior in performance to the linear version WDBC is an easy dataset to classify Figure 3 Figure 4 170 and a SVM b SVM a PSVM b PSVM 3 004 85 3 100 0 5 10 15 20 25 30 0.7 0.75 0.8 0.85 0.9 0.95 1 dimension correct rate  PCA PLS SRM OMP no reduction  0 5 10 15 20 25 30 0.7 0.75 0.8 0.85 0.9 0.95 1 dimension correct rate  PCA PLS SRM OMP no reduction  0 5 10 15 20 25 30 0.7 0.75 0.8 0.85 0.9 0.95 1 dimension correct rate  PCA PLS SRM OMP no reduction  0 5 10 15 20 25 30 0.7 0.75 0.8 0.85 0.9 0.95 1 dimension correct rate  PCA PLS SRM OMP no reduction   which were adjusted for tuning purposes PCA revealed that more principal components are needed to explain a certain variance in the Ionosphere dataset than in the case of the WDBC dataset Therefore it was expected that the Ionosphere dataset would be a more dif\223cult dataset to classify than the WDBC dataset This is re\224ected in slightly smaller classi\223cation correct rates on the average about Results on the Ionosphere Dataset performance than using the full data We can only speculate that this is connected to the suboptimality of the linear SVM/PSVM classi\223ers here being enhanced by the feature recognition property of PCA/PLS It should be also noted that a 5 5 decrease in correct rate as displayed by the PCA and PLS between maximum and minimum compression is equivalent in the case of the WDBC dataset to only 003 The same approach presented above for the WDBC dataset was used for the Ionosphere dataset with the exception of changes in the values of 


Figure 5 Figure 6  Ionosphere-SVM-Performance Comparison For all scenarios SVM and PSVM achieve comparable classi\223cation correct rates for each data reduction technique As in the case of WDBC PCA looks like a consistently good method for data reduction performing well over all levels of compression In the more dif\223cult to classify Ionosphere dataset PCA emerges more clearly as the most desired dimensionality reduction method For both the WDBC and the Ionosphere datasets applying data reduction techniques results in a small loss in performance while requiring considerably less computational resources when compared to applying no compression and thus using all available data for classi\223cation  Ionosphere-PSVM-Performance Comparison into training and test subsets Each time series is from a different engine but the data is considered to be from a 224eet of engines of the same type Each engine starts with different degrees of initial wear and manufacturing variation which is unknown to the user Included in the data are three operational settings that have a substantial effect on engine performance Each engine is operating normally at the start of each time series and develops a fault at some point during the series In the training set the fault grows in magnitude until system failure Therefore we considered the Remaining Useful Life RUL i.e the number of remaining operational cycles before failure to be zero at the end of each engine\220s time series and we populated the RUL vector associated with the time series by increasing the RUL by one cycle for each step backwards in time The PHM dataset was created as a time to failure problem but we chose to recast it as a classi\223cation problem In the test set the time series ends some time prior to system failure 6 a SVM b SVM a PSVM b PSVM 0 5 10 15 20 25 30 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 dimension correct rate    PCA PLS SRM OMP no reduction  0 5 10 15 20 25 30 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 dimension correct rate    PCA PLS SRM OMP no reduction  0 5 10 15 20 25 30 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1 dimension correct rate    PCA PLS SRM OMP no reduction  0 5 10 15 20 25 30 0.7 0.75 0.8 0.85 0.9 0.95 1 dimension correct rate    PCA PLS SRM OMP no reduction  We chose to label the FD001 Turbofan Engine Degradation Simulation dataset as the PHM dataset please see and we will refer to it as such The data consists of multiple multivariate time series divided Results on the PHM Dataset 


http://ti.arc.nasa.gov/project/prognostic-datarepository respectively Where as expected PCA and PLS outperform SRM and OMP as they optimize their data reduction based on a training data sest Still also SRM and OMP show little performance degradation especially in conjunction with the nonlinear SVM/PSVM and could be favorably if no training set is easily available before transmission In absolute performance PCA seemed to have a slight edge over the other data reduction methods SVM and PSVM were similar in performance in all cases with a nonlinear classi\223er showing an improvement by a small margin over a linear classi\223er with respect to correct rates at a certain level of compression better noticeable on the Ionosphere dataset A PCA together with a nonlinear SVM were chosen to be run on the last and most complex dataset PHM proved to be a hard-to-classify dataset even in the absence of dimensionality reduction Even in such a dif\223cult case PCA was considered worth applying Based on these assessments data reduction appears a useful tool that can provide a signi\223cant reduction resource requirements for storage or transmission with acceptable loss in performance A CKNOWLEDGEMENT R EFERENCES 90 Several techniques for data reduction PCA PLS SRM and OMP were applied to three datasets WDBC Ionosphere and PHM in an effort to analyze how their performance changes with the level of data compression The comparison of these techniques was based on how well the data can be classi\223ed by an SVM or PSVM linear and nonlinear versions for each at decreasing number of components retained On the This research was supported by  NNX08CD30P NASA STTR 2007 Phase I Data Reduction Techniques for Realtime Fault Detection and Diagnosis and Multiple Fault Inference with Imperfect Tests  A Asuncion and D J Ne wman UCI Machine Learning Repository University of California-Irvine School of Information and Computer Science 2007 2 Figure 7 Figure 8 0 2   5 C ONCLUSION  PHM Data Reduced by PCA to 2 Dimensions and an RUL vector is provided We expanded this vector in a similar manner by increasing the RUL by one cycle for each step backwards in time The RUL vector was then recast as the two classes needed for the svm For both the train set and the test set values in the RUL vector greater than the mean value of the RUL vector were considered to indicate class 1 i.e the engine is operating normally with the rest of the values indicating class 0 i.e the engine has suffered a fault The data is contaminated with sensor noise For denoising a median 223lter with a jumping window of length 15 is applied to each column in the data and the RUL vector All the training dataset was used for training and all the testing dataset was used for testing there was no randomness involved in the selection We chose to apply to PHM the data reduction method we deemed worked best for the other datasets PCA combined with the nonlinear version of SVM By looking at how the reduced data appears in 2D Figure 7 it can be observed that the data is very hard to classify even with a nonlinear classi\223er The plot gives us the intuition that increasing the number of retained components will decrease performance evident in Figure 8 These effects could be caused by the fact that the PHM dataset was designed as a regression problem and not as a classi\223cation problem  PCA Nonlinear SVM WDBC and Ionosphere datasets all methods consistently attained good correct rates in the neighborhood of 0 5 10 15 20 25 0.45 0.5 0.55 0.6 0.65 0.7 0.75 dimension correct rate PCA 95 0024 7 0022 0021 0020.5 0 0.5 1 1.5 0 \(training 1 \(training Support Vectors and 


Quantitative Sociology International perspectives on mathematical and statistical model building  A Sax ena K Goebel D Simon and N Eklund 215Damage Propagation Modeling for Aircraft Engine Run-toFailure Simulation,\216 Encyclopedia of Measurement and Statistics  Oct 2008  H W old 215P ath models with latent v ariables The NIPALS approach,\216  pp 307-357 Academic Press 1975  H Abdi 215P artial least square re gression PLS re gression\\216  pp 740\205744 Sage Publications 2007  S de Jong 215SIMPLS An alternati v e approach to partial least squares regression,\216  Vol 18 pp 251-263 Mar 1993  R Baraniuk 215Compressi v e sensing 216  Vol 24 No 4 pp 118-121 Jul 2007  E Candes J Romber g and T  T ao 215Rob ust uncertainty principles Exact signal reconstruction from highly incomplete frequency information,\216  Vol 52 No 12 pp 5406-5425 Feb 2006  D Donoho 215Compressed sensing 216  Vol 52 No 4 pp 1289-1306 Apr 2006  T  T  Do L Gan Y  Chen N Nguyen and T  D T ran 215Fast and Ef\223cient Dimensionality Reduction Using Structurally Random Matrices,\216  Apr 2009  J A T ropp and A C Gilbert 215Signal reco v ery from random measurements via orthogonal matching pursuit,\216  Vol 53 No 12 pp 4655-4666 Dec 2007  W  Li and J C Preisig 215Estimation of Rapidly T imeVarying Sparse Channels,\216  Vol 32 No 4 pp 927\205939 Oct 2007  J P  Le wis 215 A Short SVM Support V ector Machine Tutorial,\216   G Fung and O L Mangasarian 215Proximal Support Vector Machine Classi\223ers,\216  pp 77\20586 Aug 2001 Proc First Intl Conf on Prognostics and Health Management IEEE Journal of Oceanic Engineering Ramona Georgescu Christian Berger Christian Berger IEEE Transactions on Information Theory zilla/code.html Chemometrics and Intelligent Laboratory Systems Proc IEEE Intl Conf on Acoustics Speech and Signal Processing B IOGRAPHY  www.idiom.com received her B.As in Computer Science and Physics from Connecticut College in 2004 and her M.Sc degree in Electrical Engineering from Boston University in 2007 She is currently a PhD student in the Electrical and Computer Engineering department at the University of Connecticut Her research interests are in the area of statistical signal processing particularly target tracking data compression machine learning estimation and detection 005 IEEE Transactions on Information Theory was born in Heidelberg Germany on September 12 1979 He received the Dipl.-Ing degree in electrical engineering from the Universitt Karlsruhe TH Karlsruhe Germany in 2005 During this degree he also spent a semester with the National University of Singapore NUS Singapore where he took both undergraduate and graduate courses in electrical engineering He obtained his Ph.D degree in electrical engineering at the University of Connecticut UCONN Storrs and is currently a post-doctoral researcher at Carnegie Mellon University In summer 2006 he was as a Visiting Scientist with the Sensor Networks and Data Fusion Department FGAN Research Institute Wachtberg Germany He is presently a postdoctoral researcher at Carnegie Mellon University working on the ef\223cient mapping of signal processing and communication algorithms to practical computational hardware His research interests lie in the areas of communications and signal processing including distributed estimation in wireless sensor networks wireless positioning and synchronization underwater acoustic communications and networking was born in Heidelberg Germany on September 12 1979 He received the Dipl.-Ing degree in electrical engineering from the Universitt Karlsruhe TH Karlsruhe Germany in 2005 During this degree he also spent a semester with the National University of Singapore NUS Singapore where he took both undergraduate and graduate courses in electrical engineering He is currently working toward the Ph.D degree in electrical engineering at the University of Connecticut UCONN Storrs In summer 2006 he was as a Visiting Scientist with the Sensor Networks and Data Fusion Department FGAN Research Institute Wachtberg Germany He is presently a postdoctoral assistant at Carnegie Mellon University working on the ef\223cient mapping of signal processing and communication algorithms to practical computational hardware His research interests lie in the areas of communications and signal processing including dis8 IEEE Transactions on Information Theory Proc Seventh ACM SIGKDD Intl Conf on Knowledge Discovery and Data Mining IEEE Signal Processing Magazine 


received his BASc Engineering Science from the University of Toronto in 1982 and his PhD degree from Princeton University in 1986 He has been a faculty member at the University of Connecticut ever since and since 1998 has been a Professor He was awarded IEEE Fellow status effective 2003 His primary areas of research have been statistical signal processing detection machine learning data fusion and tracking He also has interests in and has published in the areas of change/abnormality detection optical pattern recognition communications and industrial/security condition monitoring He is editor-in-chief for IEEE Transactions on Aerospace and Electronic Systems and until recently was associate editor for three active journals IEEE Transactions on Aerospace and Electronic Systems for Data Fusion and Target Tracking and IEEE Transactions on Systems Man and Cybernetics parts A and B He is also associate editor for the IEEE AES Magazine associate editor for ISIF\220s electronic Journal of Advances in Information Fusion is a member of the editorial board of IEEE\220s Signal Processing Magazine and was 223rst editor of the AES Magazine\220s periodic Tutorial issues He has been a member of the IEEE AESS Board of Governors since 2003 He was General Co-Chair for the 2006 and 2008 ISIF/IEEE Fusion Conferences respectively in Florence Italy and in Cologne Germany tributed estimation in wireless sensor networks wireless positioning and synchronization underwater acoustic communications and networking Peter Willett Mohammad S Azam Sudipto Ghoshal received the B.Sc degree in Electrical and Electronic Engineering from Bangladesh University of Engineering and Technology Dhaka in 1997 the MS in Control and Communication Systems Engineering from the University of Connecticut in 2002 and the PhD from the University of Connecticut in 2006 Currently he is a research engineer with Qualtech Systems Inc His research interests are in the areas of diagnosis of power quality events fault diagnosis in complex safety-critical systems reliability analysis and analysis and optimization of large-scale systems is the Manager of Professional Services and a Principal Research Engineer at Qualtech Systems Inc QSI He received the B.Tech degree in Electrical Engineering from the Indian Institute of Technology Kharagpur India in 1989 the M.S and Ph.D degrees in Biomedical Engineering from the University of Connecticut Storrs in 1991 and 1997 respectively Dr Ghoshal\220s research primarily involves developing and implementing algorithms for a highly scalable compact diagnostic reasoning engine and architecting the test implementation module as part of the Remote Diagnostic Server framework He is a committee member of IEEE SCC20 Diagnostics and Maintenance subcommittee since 1991 He has published numerous journal and conference papers and has received several best paper awards in technical conferences He was one of the recipients of the of 2002 NASA Space Act Award for 215A Comprehensive Toolset for Model-based Health Monitoring and Diagnosis.\216 9 


result of actions by individuals and units within the organization. These actions of assimilation, in turn are stimulated or discouraged by an organizational milieu of norms, values, and rules. To the extent that assimilation of IT lies in the arena of rational choice of individuals, organizations may be able to foster assimilation by providing appropriate incentives Third, the quality of information resource management is positively associated with organizational assimilation of IT. The capacity of IT department in providing end-user support and enduser participation in IT project planning continue to Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6   be important in promoting the organizational assimilation of IT   6. References  1] A. Northrop, W. Dutton and K. Kraemer, ?The Management of Computer Applications in Local Government? Public Administration Review, 42\(3 2] A. Pinsonneault, and K.  L. Kraemer, ?Middle Management Downsizing: An Empirical Investigation of the Impact of Information Technology,? Management Science, 43\(5 3] A. Pinsonneault, and K. L. Kraemer, ?Exploring the Role of Information Technology in Organizational Downsizing: A Tale of Two American Cities Organization Science, 13\(2 4] B. Bozeman, and S. Bretschneider, ?Public Management Information Systems: Theory and Prescription,? Public Administration Review, Special Issue 1986, pp. 475-487 5] Beyer, J. and H. M. Trice, Implementing Change Alcoholism Polices in Work Organization. New York: Free Press, 1978 6] C. Ranganathan, Jasbir S. Dhaliwal, and Thopmson S. H. Teo, ?Assimilation and Diffusion of Web Technologies in Supply-Chain Management: An Examination of Key Drivers and Performance Impacts International Journal of Electronic Commerce 9\(1 pp.  127-161 7] Choi, Heungsuk, ?Infomatizing Korean Localities Coordination by the Central Leadership,? International Review of Public Administration 3\(2 8] Choi, Heungsuk, ?Reforming Government with Information Technology in South Korea,? Asian Journal of Political Science 11\(1  9] D. Chatterjee, R. Grewal, and V. Sambamurthy Shaping Up for E-Commerce: Institutional Enablers of the Organizational Assimilation of Web Technologies,? MIS Quarterly 26\(2 10] D. T. Bugler, and S. Bretschneider, ?Technology Push or Program Pull: Interest in New Information Technologies within Public Organizations,? In Public Management: The State of Art, Barry Bozeman \(ed Jossey-Bass, 1993 11] D. Davis,  ?Perceived Usefulness, Perceived Ease of Use, and User acceptance of Information Technology MIS Quarterly 13, 1989, pp. 319-339 12] D. Davis, R.P. Bagozzi, and P.R. Warshaw, ?User Acceptance of Computer Technology: A Comparison of Two Theoretical Models,? Management Science 35 1989,pp.  982-1002 13] F. Hull, and J. Hage, ?Organizing for Innovation Beyond Burns and Stalker?s Organic Type,? Sociology 16 1989, pp. 546-577 


14] H. Rebecca, ?An Information Infrastructure for Innovative Management of Government,? Public Administration Review 54\(6 15] H. Russell, and S. R. Carrico, ?Developing Capabilities to Use Information Strategically,? MIS Quarterly 12\(1 16] J. Perry and K. L. Kraemer,  ?Chief Executive Support and Innovation Adoption,? Administration and Society, 12\(2 17] J. R. Kimberly, and M. J. Evanisko Organizational, Environmental and Individual Impacts on Innovation,? Academy of Management Journal 24, 1981 pp. 689-713 18] M. Igbaria, ?End-User Computing Effectiveness: A Structure Equation Model,? Omega 18\(6 652 19] M. Jae Moon,  Application of Information Technology in State Procurement Management Pricewaterhouse Coopers Endowment for the Business of Government, 2002 20] M. Jae Moon and S. Bretschneider, ?Does Perception of Red Tape Constrain IT Innovativeness in Organizations: Unexpected Results from Simultaneous Equation Model and Implications,? Journal of Public Administration Research and Theory. 12\(2 291 21] Nedovic-Budic, Zorica and D. Godschalk, ?Human Factors in Adoption of Geographic Information Systems GIS Administration Review, 56\(6 22] Peled, Alon, ?Centralization or Diffusion? Two Tales of Online Government,? Administration and Society 32\(6 23] P. D. Collins, Hage, J. and Hull, F.M Organizational and technological predictors of change in automaticity. Academy of Management Journal 31\(3 pp.512?543 September 1988 24] Quinn, R. E. and Kimberly, J.R., Paradox, planning and perseverance: Guidelines for managerial practice, in Managing Organizational Transitions \(Kimberly, J. and Quinn, R. Eds 25] R. B. Cooper, and Zmud, R.W. IT implementation research: A technological diffusion approach. Management Science 36\(2  26] R. L. Daft, ?Bureaucratic versus Nonbureaucratic Structure and the Process of Innovation and Change,? in S Bachrach ed. Research in the Sociology of Organization vol. 1: 129-166. Greenwich, Conn.: JAI Press, 1982 27] Rainey, H. G, "Organization Structure, Design Technology, and Information Technology," In Understanding and Managing Public Organizations, C.A Jossey-Bass, 2003 28] R. G. Fichman and C. F. Kemerer,  ?The Assimilation of Software Process Innovation: An Organizational Learning Perspective,? Management Science 43\(10 29] Rogers, E. M, Diffusion of Innovations, New York The Free Press, 1995 30] S. Seneviratne, ?Information Technology and Organizational Change in the Public Sector,? In Information Technology and Computer Applications in Public Administration: Issues and Trends. Garson, David ed Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7   31] Seog-Yong, Kim et al.,  ?Public Employee?s Attitudes on Application of a Learning Organization to Public Sector,? Korean Public Administration Quarterly 17\(4 


17\(4 32] Seung-Hwan Myeong, ?The perceived impacts of information technologies on budget tasks in county government: Focusing on budget managers? perception and budget tasks? environments,?  Doctoral dissertation Syracuse University, 1996 33] Simon, H.  A, Models of Discovery, Dordrecht Holland: R. Reidel., 1977 34] Specht, Pamela,  ?The Impact of IT on Organization Performance in the Public Sector,? In Handbook of Public Information Systems. Garson, David ed 35] Trice, H. M., and Beyer, J. M. The Cultures of Work Organizations. Upper Saddle River, NJ: Prentice Hall 1993 36] V. Grover, and M. D. Goslar, ?The initiation adoption, and implementation of telecommunications technologies in U.S. organizations,? Journal of Management Information Systems 10\(1 163 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 pre></body></html 


managed. Although the provided methodology is flexible with respect to the level of detail, the decision to develop highly detailed RPBBs causes higher efforts for documenting processes. Further refinements of the methodology could address this issue by identifying typical sequences of components patterns basis of a semantic standardization of RPBBs using the comprehensive basis of 200 process models for the public sector. Consequently, such patterns will enable standardization of process fragments, too, and support a more efficient modeling \(cp. analogy-based construction [14 identification of typical process patterns is required Concluding previous discussions, the main strength of RPBB-based process documentation is the semantic standardization of models. This not only enables distributed modeling by heterogeneous user groups but also allows for the automation of analyses such as pattern-based mechanisms for plausibility and consistency check, performance measurement identification of organizational weaknesses and potentials for optimization \(organizational technology-driven, etc into other \(e.g. more technical or user-dependent notations and views [26]. However, automation approaches obviously require technical support Hence, a realization in form of a web-based prototype is currently progressing. On the one hand this prototype supports distributed process modeling with RPBBs implementing the idea of stepwise specialization via dynamic dialogues \(guided modeling semantic reasoning enables the pattern-based identification of organizational deficiencies weaknesses technologies The prototypical implementation allows for flexible modifications of existing RPBBs and for the extension with additional RPBBs and weakness pattern. It enables comprehensive testing and evaluation of the described approaches. Furthermore it supports the transfer of the developed methodologies to other domains and further associated adaptations and refinements. The underlying methodological foundation and the prototypical implementation thereby represent a rigorous as well as relevant contribution to the field of collaborative process modeling 6. Acknowledgement  The work published in this paper is partially funded by the European Commission \(E.C the PICTURE STREP. It does not represent the view of E.C. or the project consortium  7. Bibliography  1] O. Glassey: "A Case Study on Process Modelling Three Questions and Three Techniques", Decision Support Systems, Vol. 44, 2008, pp. 842-853  2] P. Green, M. Rosemann: "Integrated Process Modeling An Ontological Evalutation", Information Systems, Vol 25, 2000, pp. 73-87  3] B. Curtis, M.I. Kellner, J. Over: "Process Modeling Communications of the ACM, Vol. 35, 1992, pp. 75-90  4] B. List, B. Korherr: "An Evaluation of Conceptual Business Process Modelling Languages", in: Proceedings of the 21st Annual ACM Symposium on Applied 


of the 21st Annual ACM Symposium on Applied Computing \(SAC2006 ACM Press, New York, 2006, pp. 1532-1539  5] S. Lippe, U. Greiner, A. Barros: "A Survey on State of the Art to Facilitate Modelling of Cross-Organisational Business Processes", in: XML4BPM 2005, Proceedings of the 2nd GI Workshop XML4BPM - XML Interchange Formats for Business Process Management at 11th GI Conference BTW 2005. Gesellschaft f  r Informatik \(GI Bonn, Karlsruhe 2005, pp. 7-21  6] T.W. Malone, K. Crowston: "The interdisciplinary study of coordination", ACM Computing Surveys \(CSUR Vol. 26, 1994, pp. 87-119  7] C. Legner, K. Wende: "The Challenges of InterOrganizational Business Process Design - A Research Agenda", in: Proceedings of the 15th European Conference on Information Systems \(ECIS2007 Gallen, Switzerland. University of St. Gallen, St. Gallen 2007, pp. 106-118  8] O. Hanseth, E. Jacucci, M. Grisot, M. Aanestad Reflexive standardization: Side effects and complexity in standard making", MIS Quarterly, Vol. 30, 2006, pp. 564581  9] S.L. Schneberger, E.R. McLean: "The complexity cross: implications for practice", Communications of the ACM, Vol. 46, 2003, pp. 216-225  10] H.G. Rainey, R.W. Backoff, C.H. Levine: "Comparing Public and Private Organizations", Public Administration Review, Vol. 36, 1976, pp. 233-244  11] K.L. Schiflett, M. Zey: "Comparison of Characteristics of Private Product Producing Organizations and Public Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 Service Organizations", The Sociological Quarterly, Vol 31, 1990, pp. 569-583  12] L. Baacke, P. Rohner, R. Winter: "Aggregation of Reference Process Building Blocks to Improve Modeling in Public Administrations", in: Electronic Government, 6th International EGOV Conference, Proceedings of ongoing research, project contributions and workshops. Trauner Druck, Regensburg, Germany 2007, pp. 149-156  13] R. Sch  tte, T. Rotthowe: "The Guidelines of Modeling An Approach to Enhance the Quality in Information Models", in: ER 1998, pp. 240-254  14] J. vom Brocke: "Design Principles for Reference Modelling. Reusing Information Models by Means of Aggregation, Specialisation, Instantiation, and Analogy in: Fettke, P., Loos, P. \(eds Business Systems Analysis. Idea Group Publishing Hershey, PA, USA 2007, pp. 47-75  15] O. Thomas: "Understanding the Term Reference Model in Information Systems Research: History Literature Analysis and Explanation", in: Proceedings of the Workshop on Business Process Reference Models BPRM 2005 International Conference on Business Process Management BPM  16] P. Fettke, P. Loos, J. Zwicker: "Business Process Reference Models: Survey and Classification", in 


Reference Models: Survey and Classification", in Proceedings of the Workshop on Business Process Reference Models \(BPRM 2005 the Third International Conference on Business Process Management \(BPM  17] W.M.P. van der Aalst, A. Dreiling, F. Gottschalk, M Rosemann, M.H. Jansen-Vullers: "Configurable Process Models as a Basis for Reference Modeling", in Proceedings of the Workshop on Business Process Reference Models \(BPRM 2005 the Third International Conference on Business Process Management \(BPM  18] R. Knackstedt, C. Janiesch, R. T.: "Configuring Reference Models - An Integrated Approach for Transaction Processing and Decision Support", in Proceedings of the 8th International Conference on Enterprise Information Systems \(ICEIS 2006 135-143  19] F. Gottschalk, W.M.P. van der Aalst, M.H. JansenVullers: "Configurable Process Models - A Foundational Approach", in: Becker, J., Delfmann, P. \(eds Modeling - Efficient Information Systems Design Through Reuse of Information Models. Physica Verlag, Heidelberg 2007, pp. 59-77  20] A. Dreiling, M. Rosemann, W.M.P. van der Aalst, W Sadiq, S. Khan: "Model-Driven Process Configuration of Enterprise Systems", in: Wirtschaftsinformatik 2005 eEconomy, eGovernment, eSociety. Physica-Verlag Heidelberg 2005, pp. 687-706  21] C. Szyperski, D. Gruntz, S. Murer: Component Software: Beyond Object-Oriented Programming. Addison Wesley Longman, ACM Press New York 2002  22] D. Kratzig, K. B  nke, D. Slarna: Enterprise SOA Service-Oriented Architecture - Best Practices. Prentice Hall Professional Technical Reference, Upper Saddle River NJ 2004  23] T.H. Davenport, J.E. Short: "The New Industrial Engineering: Information Technology and Business Process Redesign", Sloan Management Review, Vol. 1990 pp. 11-27  24] S.T. March, G.G. Smith: "Design and natural science research on information technology", Decision Support Systems, Vol. 15, 1995, pp. 251-266  25] A.R. Hevner, S.T. March, J. Park, S. Ram: "Design Science in Information System Research", MIS Quarterly Vol. 28, 2004, pp. 75-101  26] L. Baacke, R. Fitterer, T. Mettler, P. Rohner: "A Methodology for ICT Impact Analysis Based on Semantic Process Models", in: Electronic Government, 7th International EGOV Conference, Proceedings of ongoing research, project contributions and workshops. Trauner Druck, Turin, Italy 2008, pp. 1-8  27] S. Brinkkemper: "Method Engineering: Engineering of Information Systems Development Methods and Tools Information and Software Technology, Vol. 38, 1996, pp 275-280  28] PICTURE \(Process Identification and Clustering for Transparency in Reorganising Public Administrations www.picture-eu.org, Specific Targeted Research Project 


STREP European Commission, 2006-2009  29] PICTURE: "Process Building Block Specification Deliverable 1.7 access 2007-04-10  30] S.A. White: Introduction to BPMN. IBM Corporation 2004  31] L. Baacke, R. Fitterer, P. Rohner: "Measuring Impacts of ICT on the Process Landscape of Public Administrations", in: Proceedings of the 3rd International Conference on e-Government \(ICEG2007 Quebec, Montreal, Canada 2007, pp. 21-30    Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


2 1 0 00                4 G ro w th 1  1 3 1 0 9 2 0 2 3 0 10  0 56                So ci ode m og ra ph ic c ha ra ct er is tic s 


s 5 A ge y ea rs   21 7 8 7 3 9 0 01 0 22  0 1 4 0 0 8              6 G en de r i s fe m al e2   0 2 4  0 0 6 0 0 2 0 00 0 0 3 0 10    


           7 C ur re nt ly n ot w or ki ng 2  0 0 5  0 0 8 0 04 0 04 0 0 1 0 16  0 16             8 C ur re nt ly in e du ca tio n2   0 6 


6 7  0 01 0 1 9 0 08  0 03 0 6 8 0 0 7 0 3 2           9 C ur re nt ly w or ki ng 2  0 2 8  0 03 0 18  0 1 1 0 0 3 0 64  0 00 0 1 4 0 8 9   


        10 E du ca tio n ac hi ev ed 3  3 5 7 1 5 2  0 04 0 02 0 2 1 0 1 2 0 16  0 02 0 1 6 0 13  0 0 6         11 D is pe ns ab le in co m e   


  21 0 9 2 72 7  0 14  0 0 1 0 09  0 08  0 2 0 0 00 0 0 4 0 18  0 1 6 0 0 1        In te rn et u sa ge                     


  12 A ct iv e in te rn et u sa ge 1  0 0 2 0 9 6 0 2 1 0 25  0 11  0 12  0 10  0 0 4 0 05  0 0 8 0 0 5 0 0 1 0 12        13 H ou rs o nl in e h ou rs 


rs   2 6 5 3 0 3  0 04 0 12  0 1 1 0 0 3 0 40  0 0 7 0 0 7 0 4 7 0 5 3 0 07  0 1 1 0 07       14 W illi ng ne ss to p ay 1  1 8 3 0 6 3  0 03 0 10 


10  0 07  0 08  0 0 2 0 0 4 0 0 1 0 01  0 00 0 0 5 0 14  0 04 0 05      G am e sp ec ifi c va ria bl es                      15 T en 


ur e w ee ks   2 8 2 3 5 2 0 2 6 0 31  0 0 9 0 01 0 12  0 0 4 0 02 0 0 9 0 0 9 0 07  0 02 0 13  0 08  0 0 4    16 C ro ss o ve r on o ffl in e 4  0 1 5 


5 1 1 1 0 1 9 0 11  0 13  0 18  0 2 0 0 1 4 0 0 7 0 14  0 1 1 0 0 4 0 08  0 15  0 0 5 0 01 0 07    17 S at is fa ct io n1   18 7 5 1 3 16  0 18  0 00 


00 0 44  0 52  0 1 4 0 0 3 0 02 0 07  0 0 9 0 1 4 0 10  0 08  0 0 6 0 09  0 0 1 0 13   18 C om m itm en t1  0 6 2 0 8 3 0 3 1 0 13  0 37  0 39  0 0 7 


7 0 0 6 0 02 0 03  0 0 4 0 1 3 0 14  0 17  0 0 5 0 09  0 07  0 19  0 58  S ou rc e O w n ca lc ul at io n N ot e N  1 3 89 o bs er va tio ns S ig ni fic an ce le ve ls 


ls  p  0 05 S D  S ta nd ar d de vi at io n 1 5 po in t L ik er t s ca le ra ng in g fro m 2 to 2  2 du m m y va ria bl e 3 o rd in al v ar ia bl e ra ng in g fro m v oc at io na l e du ca 


tio n to P h D 4 n um be r o f c on ta ct s   Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 



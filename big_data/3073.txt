Research on the Improved Frequent Predicate Algorithm in the Data Mi ning of Criminal Cases  Wang Chunyu, Wang Xuehua, Zhang Xujuan Department of Management  Dalian University of Technology wcy1969@hotmail.com  Abstract In order to find out the common features and general patterns in criminal cases, a new improved frequent predicate algorithm was proposed, with which multi-dimension association rules were drawn according to the minimum support and minimum confidence. This new algorithm was applied in the data mining model of criminal cases of Dalian Municipal Public Security Bureau  Index Terms - data mining, multi-dimensional association rules improved Aprior algorithm, criminal cases  I  I NTRODUCTION  As everybody knows, preventing and investigating crimes constitute an important part of the municipal public security system. How to make full use of the information relating cases in the past is a key issue. Therefore data mining of criminal cases is very important in order to find out the common features and the general patterns of these cases so as to provide information support for the decision makers and investigators of the present cases Assoc iation analysis is a very important model in data mining, from which association rules can be figured out. These association rules show common at tributes----conditions for the repeated occurrence of items within given data. If we can make use of the association analysis to find the association rules in criminal cases, for example under what conditions certain kinds of crimes tend to occur, we can provide effective information for the investigators. With this information support, the police can prevent the crimes from happening and after the crimes take place they will be able to solve the cases sooner and more easily. Some work has been done with the association analysis regarding the same personês committing different crimes b u t t h i s b e l o n g s  t o t h e s i n g l e di m e n s i o na l  analysis. In reality, the criminal cases database is more often than not an association database, which requires many predicates in order to get the association rules. This makes the criminal cases database multi-dimensional and multi-layered Thus we have to establish multi-dimensional association rules in order to track down the common features and general patterns of the criminal crimes  This paper has proposed an improved Aprior algorithm aimed at multi-dimensional association. This algorithm can help locate the frequent predicate sets, draw up the strong association rules and finally help track down the features and patterns of criminal cases. The feasibility of this model has been tested with the genuine data provided by Dalian Municipal Public Security Bureau. Detailed analysis has been carried out on the results derived  II  A SSOCIATION R ULES  Association rules are often used in the mining of the interesting association between the terms within the given data sets. The description of the basic questions in the association rules goes like this [2  to s e t I   i 1  i2    im as t h e s e t o f all  items. T\(transaction\ is defined to be the set of items, and in T  I, D is defined as the set of T\(transaction\. X is set to be the set for many items within I, thus if X  T, we can assume that T\(transaction\ includes X. The number of the items in the sets becomes the length of the sets. Assoc iation rules are implications like X  Y, with X  I  Y  I, and      The support of formula X  Y in D transaction database is the ratio between all the transaction numbers with X and Y to all the transaction numbers, which goes like support\(X  Y\, i.e support\(X  Y\ =|{T:X Y  T,T  D}|/|D|.  In formula X  Y the confidence in the transaction set is the  ratio between transaction numbers with X and Y to the transaction numbers with  X, which goes like confidence\(X  Y\, i.e. confidence X  Y\|{ {T:X Y  T,T  D }|/|{T:X  T,T  D}|. With a given D transaction set, the mining of association rules means finding out the association rules within which both the support and confidence are greater than the customer provided min-support  and min-confidence There are two steps in the association rules mining [3   A  Finding all the Frequent Item sets: according to our definition the frequency of these sets should be the same as the min-support numbers at least  B  Forming the strong association rules from the Frequent Item sets according to our definition, these rules must satisfy the min-support and min-confidence  III  A N I MPROVED F REQUENT P REDICATES A LGORITHM  The traditional Apriori algorithm [6-7 a ke s us e of   t h e  iterative method called layer-by-layer search. This method is to look for the Frequent Item set \(K+1\ with the use of K Frequent Item set \(within the set there are K items and the frequency of this K items is greater than the given ratio\. First find the set of Frequent Item set 1, which is named L1. L1will be used for the location of L2, and L2 will be for L3. The process will go on until we reach the end where we cannot find 978-1-4244-2184-8/08/$25.00 © 2008 IEEE 1531 Proceedings of the 2008 IEEE International Conference on Information and Automation June 20 -23, 2008, Zhangjiajie, China 


LK, i.e. K Frequent Item set. Every search for LK will need a scan of the transaction tables A  The improved Apriori  algorithm for use in the criminal cases In accord with the characteristics of the data of criminal cases, the improved Apriori algorithm has the following basic ideas The traditional model like a shopping basket has only one predicate çshoppingé, and this can be called a single dimension model. If more predicates appear, such as the crime types crime motifs, crime means etc, this will concern multiple dimensions. We can easily equal dimensions with predicates If we want to do a three-dimensional analysis, we should look for three predicates which have frequent co-existences in the same model, each of which should have its own value. All the sets of different predicates can be regarded as the original Boolean Set. In this way the original search for frequent item set will be changed to the search for frequent predicate sets The original scanning for the number of items will be changed to the scanning of data cube for number of predicates Based on the above idea, the improved algorithm can be illustrated as follows Algorithm: multi-dimensional frequent predicate set algorithm \(Apriori in data cube Input: n-dimensional data Cube \(d1,..., dn  count min-support Output: frequent predicate set Formula 1  L  L1 2  Each member of Dimension d i i=1,...,n\ constituting candidate 1-perdicate set called C1 3  Forming frequent 1-predicate set L 1 GenFrequent\(C 1  4  L=L L 1  5  For  k=2;k++;k<=n   1\Candidate k-predicate set C k GenCandidate\(L k 1 formed from frequent predicate set \(k-1 2 k GenFrequent\(C k formed from candidate k-predicate set 3\=L L k  6\utput L Function GenFrequent\(Ck\ refers to the formation of frequent predicate k-set from the candidate k-predicate set. The process is  1 k   2\ For \(Within the candidate k-predicate set, each one l=\(i 1 i k Here i k refers to the member before k dimension   1\upcount=n, in the dimensional cube \(i 1 i k  Sum,..., Sum\ matches the count in the check. Those not included in the candidate k-predicate set are substituted with Sum 2\upport=supcount/totalcount 3\ supportminsup THEN  L k L k  l  3\ Output L K  Function GenCandidate\(Lk-1\ refers to the formation of candidate k-predicate set Ck from frequent \(k-1\ predicate set The process goes 1 k   2\or  any two frequent predicate sets l 1 and l 2 within L k 1    1\ IF \(There are k-2 same items between l 1 and l 2 and item k-1 is  the dimension member from different dimensions\ THEN// terms for joining   c= l 1  l 2 join  IF all subsets in C belong to L k 1 THEN  C k C k  c 2\LSE Delete c //Pruning   3\ Output C k B  Producing strong association rules It is easy to form strong association rules after we find frequent predicate sets from the data cube. The reason is that to form strong association rules we must satisfy the minimum support and minimum confidence. Since the frequent predicate set already satisfies the minimum support, so what is needed now is to see its confidence. Confidence can be explained with the following formula, in which the conditional probability is expressed with the holding count of the predicate set  Confidence\(A  B P\(A|B Support_count\(A  B\/Support_count\(A In this formula, Support_count \(A  B\ is the transact count with item set A  B, while Support_count\(A\is the transact count with item set A. According to this formula, the association rules can be produced like: for each frequent item set 1, all nonempty subsets will be produced. For every nonempty subset s in 1, if Support_count\(l\/Support_count\(s\in_conf, then we get the output rule as çs  l-s  Here minimum confidence is the mini-confidence IV  T HE A PPLICATION OF T HE I MPROVED A PRIORI A LGORITHM TO T HE D ATA M INING IN C RIMINAL C ASES  A detailed description of the multi-dimensional rules model setting up process will be provided as TABLE I  A  Data cleaning  10 items are selected from the sample data and it is set as complete without any need for further cleaning. In the above list we only need crime time, so we delete year, month and date B  Concept hierarchy [4  Through sample data analysis, the types of crimes are set as classify attributes with murder, theft, robbery, rape; the crime areas are also set as classify attributes with area 1, 2, 3, 4, 5 Crime time is set as schema hierarchy with year, month , date 1532 


and  hour is set as concept hierarchy. For the sake of convenience, only hour level is chosen for study  C  Producing data cube [5  From the sample data, crime type, crime time and crime area  are chosen as the three dimensions for our data cube. Based on our concept hierarchy, a data cube can be produced as Fig.1 D  Producing frequent predicate set  With the sample data, we will explain how we can find frequent predicate set with the multi-dimensional frequent predicate set algorithm  Sample data set: \(Suppose the min-support holding count is 2\, show as Fig.2 T001{C1,T6,A1} T002{C2,T4,A3} T003{C3,T6,A3 T004{C1,T6,A1} T005{C3,T6,A5  T006{C2,T4,A3} T007{C4,T4,A4} T008{C2,T5,A5 T009{C1,T6,A1} T010{C2,T6,A5    Murder 1 6 012 00 2 0 012 00 0 012 00 4 012 00 4 012 00 8 012 00 8 012 00 12 012 00 12 012 00 1 6 012 00 2 0 012 00 24 012 00 Rape Sum Sum 015   One   two   three   four  five  sum Figure.1 Data cube   C1 L1  Predicate set  Support count  C1} 3 C2} 4 C3} 2 C4} 1 T1} 0 T2} 0 T3} 0 T4} 3 T5} 1 T6} 6 A1} 3 A2} 0 A3} 3 A4} 1 A5} 3 Predicate set Support count  C1} 3 C2} 4 C3} 2 T4} 3 T6} 6 A1} 3 A3} 3 A5} 3 scanning the data cube and finding every candidate count  comparing candidate support count and minsup count    TABLE I S AMPLE C RIMINAL C ASE D ATA  Case ID Types \(C Time \(T Area \(A Education \(E Status \(S Family \(F T001 Murder 1997-8-5 22 012 55 Area 1 Primary lower Poor T002 Theft 2000-6-9 14 012 10 Area 3 Junior high Middle lower Average T003 Robbery 1998-5-6 19 012 55 Area 3 Senior high Middle lower Average T004 Murder 2002-2-2 23 012 55 Area 1 Junior high lower Poor T005 Robbery 1999-2-8 22 012 45 Area 5 Senior high Middle Average T006 Theft 2004-12-31 12 012 05 Area 3 Primary Middle lower Average T007 Rape 2001-7-9 15 012 36 Area 4 Senior high lower Poor T008 Theft 1999-3-4 17 012 33 Area 5 Senior high Middle Average T009 Murder 2003-3-29 22 012 19 Area 1 Junior high Lower Poor T010 Theft 2005-5-8 23 012 35 Area 5 Senior high Middle Average 1533 


 C2 C2 L2 Predicate set  C1,T4 C1,T6 C1,A1 C1,A3 C1,A5 C2,T4 C2,T6 C2,A1 C2,A3 C2,A5 C3,T4 C3,T6 C3,A1 C3,A3 C3,A5 T4,A1 T4,A3 T4,A5 T6,A1 T6,A3 T6,A5 Predicate set  Support count  C1,T4} 0 C1,T6} 3 C1,A1} 3 C1,A3} 0 C1,A5} 0 C2,T4} 2 C2,T6} 1 C2,A1} 0 C2,A3} 2 C2,A5} 2 C3,T4} 0 C3,T6} 2 C3,A1} 0 C3,A3} 1 C3,A5} 1 T4,A1} 0 T4,A3} 2 T4,A5} 0 T6,A1} 3 T6,A3} 1 T6,A5} 2 Predicate set  Support count  C1,T6} 3 C1,A1} 3 C2,T4} 2 C2,A3} 2 C2,A5} 2 C3,T6} 2 T4,A3} 2 T6,A1} 3 T6,A5} 2 drawing candidate C2 from L1  scanning the data cube and finding every candidate count  comparing candidate support count and minsup count   Figure.2 Frequent predicate set   E  Producing criminal cases association rules from frequent predicate sets  Based on the method of producing strong association rules from the above model, weêll examine how to draw strong association rules from the sample data. The process goes like From the above frequent predicate sets l1={C1,T6,A1 l2={C2,T4,A3}. l1 has {C1,T6}{C1,A1}{T6,A1}{C1}{T6 A1}as the nonempty subsets while l2 has {C2,T4}{C2,A3 T4,A3}{C2}{T4}{A3} as the nonempty subsets. We only need to find the crime time, crime area to induce the association rules for crime types, so we can draw the following association rules with some subsets with support listed for each T6 A1  C1           confidence=3/3=100 T4 A3  C2           confidence=2/2=100 If the threshold of min-support is 70%, these two rules can be the output and both are strong association rules  F  Evaluation of the results From the strong association rules drawn from the sample data, we can get  20:00Ñ24:00  Area 1  murder  Support=20%,confidence=70   12:00ÑÑ16:00  Area 3   theft  Support=20%,confidence=70   Conclusion: There are more murders in Area 1 between 20:00-24:00, while Area 3 has more thefts during 12:00-16:00 Closer attention should be put to these two areas  V  T HE A PPLICATION AND C ONCLUSION  Based on statistics provided by a branch from Dalian Municipal Public Security Bureau, we draw 18629 records from 1999 to 2006. With the association analysis model set up here, we choose types, means, area, and motif as four dimensions to do our association analysis setting min-support=1%, min-cofidence=70%. The result shows  Frequent predicate sets   Burglary, coming through the window, into residential houses, for money and  property \( support 232   Burglary, treading out the path, into residential houses for money and property \(support 206   Burglary, choosing the target, into residential houses, for money and property \(support 205 Strong association rules    Burglary cases, for money and property, treading out the path \(283\residential houses cof=71   Burglary cases, for money and property, choosing the target \(264\esidential houses cof=75   Burglary cases, residential houses, choosing the target 225\ for money and property cof=89 1534 


  Burglary cases, residential houses, coming through the windows \(235\or money and property cof=85   Burglary cases, residential houses, treading out the path 260\ for money and property cof=77 From the above we can find out that  71% burglaries with the motif of getting some money and property by means of treading the path in advance will take place in residential houses, that 75% burglaries with the same motif by means of choosing the target will take place in residential houses, that for burglaries which take place in residential houses with the means of choosing the target first  89% of the criminals have the motif of getting some money and property, that for burglaries which take place in residential houses with the means of getting through the windows 85% of the criminals have the motif of getting some money and property and that for burglaries which take place in residential houses with the means of treading the path first, 77% of the criminals bear the motif of getting some money and property  If we find out in what months certain kinds of crimes happen and what their motifs are and what areas the criminals usually choose, this can greatly help the policemen break the cases For this reason we choose the dimension of time. The results go like this Frequent predicate sets: burglaries, residential houses choosing the target, the 2nd season Strong association rules: burglaries, residential houses, the 2nd season choosing the target cof=94 Because there is the time element, we can find the patterns and common features of these crimes by use of frequent predicate sets including burglaries, residential houses choosing the target, the 2nd season. These elements always appear at the same time. That is to say that in a certain area like Ganjingzi District of Dalian City, there are often burglaries in residential houses in the 2nd season every year by means of the criminalsê choosing the target first. The confidence for this strong association rules stands as high as 94%, which proves the reliability of the algorithm  C ONCLUSION  Tested with genuine statistics from local branches of Dalian Municipal Public Security Bureau, the improved algorithm based on Aprior proves feasible and reliable. We believe this will help the improvement of the data mining and information processing in the public security work  R EFERENCES  1  Agrawal R  Srikant R   Fast algorithms for mining association rules  Proc 20th Intê1 Conf Very Large Database  Santiago  Chile  September 1994 2  Fang Wangsheng Zhengjian Shao Liping, On the Algorithm based on Multi-Dimensional Rules, Computer and Digital Technology, vol. 32 pp.25-28. April 2004 3  Gao Xuedong  Wang Wenxian  Wusen, Data Cube Mining Based on Multidimensional Rules, Computer Engineering, vol. 14, pp. 74-76 August 2003 4  J Gray, A Bosworth, A Layman et al. Data cube: A relational aggregation operator generalizing group-by, cross-tab, and sub-totala.In:12th International Conference on Data Engineering, New Orleans,USA, pp 560-573. 1996 5  Jiawei Han, Micheline Kamber. Data mining concepts and techniques USA: Morgan Kaufmann Publishers, 2001 6  Jin guang,  Liu Shirong,  Li Rongqian,  Zhang Xinfeng. The Application of Data Mining in the Analysis of Criminal Behavior [J Ningbo University Journal \(Science Section\, vol.15, pp. 56-58, March 2002 7  R.Agrawal, T.Imielinski. Mining association rules between sets of items in large databases  Proc ACM SIGMOD Intê1 Conf Management of data  Washington DC  May 1993 1535 


 Very few ows are high throughput Most ows are short lived Almost all ows are mice  Most ows have an average packet size medium Most ows are packet mice Almost all bulk ows are medium throughput Almost all bulk TCP ows are short-lived  Fig 5 Simple on-line linguistic summary of the CRAWDAD-Fall03 NetFlow collection truth values between brackets of rules to analyze In particular we disregarded those rules with a low support or with a low condence truth value Many interesting rules were found for the NetFlow records analyzed We list as examples a selection of them  Most DNS request ows occur both during the day and at night are mice and short lived with condence 0.970 in the WIDE-F-1-Aug collection  Most ows at night are mice with condence 0.890 and Most ows during the day are mice with condence 0.998 in the CAIDA-OC48-0-Apr collection  Most SSH trafc occurs during the day and consists of short lived mice ows with condence 0.892 in the CRAWDAD-Fall03 collection Linguistic summaries provide a novel method to describe qualitative relations in NetFlow collections using natural language Thus by using association rules mining to nd relevant summaries we have a suitable method for addressing a problem related to ow analysis nding invariants in trafc what is known as one the major goals of Internet Science VI C ONCLUSIONS We have addressed network trafc analysis at the ow level from the perspective of linguistic summaries Two approaches for summarizing NetFlow collections have been developed 1 on-line summarization via a predened and congurable set of potential interesting protoforms and 2 discovery of hidden relevant summaries by means of association rules mining A tool that implements both approaches has been developed Experimental results for a set of benchmark NetFlow collections conrm linguistic summaries as an alternative look into network ow statistics useful for both network users and practitioners The method presented is a novel technique to generate simple and human-interpretable reports but also provides a promising technique for nding invariants in network trafc and advancing Internet Science This can be seen as a rst step towards natural language based knowledge discovery for Internet Science A CKNOWLEDGEMENT We acknowledge the MAWI Working Group from the Wide Integrated Distributed Environment WIDE project for k indly p ro viding their  o w collections and support We are also indebted to the Cooperative Association for Internet Data Analysis CAIDA for providing their OC48 data collection  Support f or CAID A  s O C48 Traces Dataset is provided by the National Science Foundation the US Department of Homeland Security DARPA Digital Envoy and CAIDA Members We used the Dartmouth/campus data set from t he Community Resource for Archiving Wireless Data CRAWDAD Our work has beneted from the use of measurement data collected on the Abilene network as part of the Abilene Observatory Project http://abilene.internet2.edu/observatory R EFERENCES  C ooperati v e Association f or Internet D ata Analysis CAID A V i sualization Tools http://www.caida.org/tools/visualization  J  S ommers P  B arford a nd W  W illinger  SPLA T  A V i sualization Tool for Mining Internet Measurements in 7 t h Passive and Ac t ive Ne t work Measuremen t Workshop  Mar 2006 pp 31ñ40  C  E stan S  S a v age and G  V ar guese  Automatically Inferring P a tterns of Resource Consumption in Network Trafc in SI G C OMM 200 3  Karlsruhe Germany Aug 2003 pp 137ñ148  R  R  Y ager   A N e w Approach to the S ummarization o f D ata  I n f orma t ion S ciences  vol 28 pp 69ñ86 1982   Database D isco v e ry Using F uzzy Sets  I n t erna t ional Journal o fI n t elligen tSy s t ems  vol 11 1996  J  K acprzyk and R  R  Y ager   Linguistic Summaries of Data Using Fuzzy Logic I n t erna t ional Journal o f General Sy s t ems  vol 30 no 2 pp 133ñ1504 Jan 2001  J  K acprzyk and S  Z adro  zny Linguistic database summaries and their protoforms Towards natural language based knowledge discovery tools I n f orma t ion S ciences  vol 173 no 4 Mar 2005   Cisco I OS NetFlo w  h ttp://www cisco.com/en/US/products/ps6601 products ios protocol group home.html Nov 2007  B  C laise e t al  Specication of the IPFIX Protocol for the Exchange of IP Trafc Flow Information Internet Engineering Task Force IPFIX Working Group Revision 26 Sep 2007 Internet Draft  S Shaluno v a nd B T eitelbaum TCP Use a nd Performance on Internet2 in A C M SI G C OMM I n t erne t Measuremen t Workshop San Francisco USA 2001  L A Zadeh A Computational A pproach to Fuzzy Quantiers i n Natural Languages C ompu t ers and Ma t hema t ics wi t h Applica t ions  vol 9 pp 149ñ184 1983  R R Y a ger   O n O rdered W eighted A v eraging O perators in Multicriteria Decision Making IEEE Transac t ions on Sy s t ems Man and Cy berne t ics  vol 18 pp 183ñ190  1988  L A Zadeh  A P rototype-Centered Approach to Adding Deduction Capability to Search Engines-the Concept of Protoform in F irs t I n t erna t ional IEEE Sy mposium on I n t elligen tSy s t ems vol.1,Sep 2002 pp 2ñ3   The concept o f a linguistic v a riable and its application t o approximate reasoning I n f orma t ion S ciences  vol 8 no 3 pp 199 249 1975  A Broido Y  Hyun R Gao and k c claf fy   Their Share Di v e rsity and Disparity in IP Trafc in 5 t h Passive and Ac t ive Measuremen t Workshop  PAM   Antibes Juan-Les-Pins France 2004 pp 113ñ125  M Delgado N Mar  n D S  anchez and M.-A Vila Fuzzy Association Rules General Model and Applications IEEE Transac t ions on F u zzy Sy s t ems  vol 11 no 2 pp 214ñ225 Apr 2003  J Kacprzyk and S  Zadro  zny Linguistic Summarization of Data Sets Using Association Rules in IEEE I n t erna t ional C on f erence on F u zzy Sy s t ems FUZZ IEEE  St Louis USA May 2003 pp 702  707  R Agra w al H Mannila R Srikant H T o i v onen and A  V erkamo Advances in Knowledge Discover y and Da t a Mining  American Association for Articial Intelligence 1996 Fast Discovery of Association Rules pp 307ñ328  M Fullmer e t al  ow-tools http://www.splintered.net/sw/owtools Nov 2007  W i dely Inte grated Distrib u ted En vironment  WIDE P roject MAWI Working Group Packet traces from wide backbone http://tracer.csl.sony.co.jp/mawi 2006  CAID A O C48 T race Project CAID A OC48 T r aces 200304-24 collection http://imdc.datcat.org/collection/1-0018N=CAIDA+OC48+Traces  D K o tz T  Henderson and I  A byzo v   CRA WD AD data set dartmouth/campus v 2007-02-08 Downloaded from http://crawdad.cs.dartmouth.edu/dartmouth/campus Feb 2007 624 2008 IEEE I n t erna t ional C on f erence on F u zzy Sy s t ems FUZZ 2008 


Since the attribute determination algorithm has determined that the attribute Sno in Table 0, the attribute Cno in Table 1, and the attributes <Sno Cno> in Table 2 embrace the double-connective association rule student\(Sno 010 1 course\(Cno 010 2 study\(Sno, Cno\he connective determination algorithm make the relational matrix shown in Fig. 4 according to the binary relationship table of Table 2   C1 C2 C3 C4 S1   T  T  F  F S2   T  F  T  F S3   T  F  F  F S4   F  T  F  F S5   T  F  F  T   Fig. 4 The relational matrix made from Table 2  Fig. 4 is made like this: Table 2 has the tuple S1, C1>, then at the cross of the row S1 and the column C1, a T is filled; Table 2 does not have tuple S1, C3>, then at the cross of the row S1 and the column C3, a F is filled Suppose the cardinality of student\(Sno\s M, in this example 5, i.e. S1 to S5; the cardinality of course\(Cno\n this example 4, i.e. C1 to C4 The algorithms for DCAR1 through DCAR6 are as follows The algorithm for DCAR1 If in Fig. 4 there is M*cf 1 rows, N*cf 2 columns submatrix, in which all elements are Ts, then DCAR1 holds The algorithm for DCAR2 If in Fig. 4 there is at least one column, in which there are at least M*cf 1 Ts, then DCAR2 holds The algorithm for DCAR3 If in Fig. 4 at least M*cf 1 rows have Ts, then DCAR3 holds The algorithm for DCAR4 If in Fig. 4 there is at least one row, in which there are at least N*cf 2 Ts, then DCAR4 holds The algorithm for DCAR5 If in Fig. 4 at least N*cf 2 columns have Ts, then DCAR5 holds The algorithm for DCAR6    DCAR6   DCAR3  DCAR5     DCAR2  DCAR4   DCAR1 Fig. 5 The complement lattice formed by DCAR1 through DCAR6 
277 
277 


000\003 000\\000L\000J\000\021\000\031\000\003\000\003\000&\000R\000Q\000Q\000H\000F\000W\000L\000Y\000H\000\003\000G\000H\000W\000H\000U\000P\000L\000Q\000D\000W\000L\000R\000Q\000\003\000D\000O\000J\000R\000U\000L\000W\000K\000P\000\003 Start Call DCAR1 000D\000O\000J\000R\000U\000L\000W\000K\000P  DCAR1 holds 002  Call DCAR2 000D\000O\000J\000R\000U\000L\000W\000K\000P  Output DCAR1,2,3,4,5,6 End DCAR2 holds 002  Output DCAR2,3,6 Call DCAR3 000D\000O\000J\000R\000U\000L\000W\000K\000P  DCAR3 holds 002  Output DCAR3,6 Call DCAR4 000D\000O\000J\000R\000U\000L\000W\000K\000P  DCAR4 holds 002  Call DCAR5 000D\000O\000J\000R\000U\000L\000W\000K\000P  Output DCAR4,5,6 End DCAR5 holds 002  Call DCAR6 000D\000O\000J\000R\000U\000L\000W\000K\000P  Output DCAR5,6 End DCAR6 holds 002  Output DCAR6 End Error Y N N Y Y N N Y Y N N Y 
278 
278 


If in Fig. 4 there is at least one T, then DCAR6 holds DCAR1 through DCAR6 forms a complement lattice shown in Fig. 5 In Fig. 5, the lower rule implies the upper rule That is, if DCARj is reachable from DCARi via an ascending path, and DCARi holds, then DCARj holds Because DCAR1 through DCAR6 satisfies Fig 5, their algorithms can be merged into one algorithm called connective determination algorithm, shown in Fig. 6 Suppose cf 1 80%, cf 2 75%. In Fig. 4, for the column of C1, there are M*cf 1 5*80%=4 elements whose values are T \(namely, S1, S2, S3, S5 Therefore, DCAR2: course\(Cno 004 1  student\(Sno 003 1  study\(Sno, Cno\olds. From Fig. 5, we know that DCAR3 and DCAR6 also hold. In Fig. 4, there are at least N*cf 2 4*75%=3 columns which have value T \(namely, in the column of C1 there is S1, in the column of C2 there is S1, in the column of C3 there is S2, in the column of C4 there is S5 therefore DCAR5: course\(Cno 003 1  student\(Sno 004 1  study\(Sno, Cno  VI. CONCLUDING REMARKS 1\ Double-connective association rule mining is different from single-connective association rule mining. The former mines the association among the primary keys of the two entity tables and the primary key of the binary relationship table. The latter mines the association between frequent item sets 2\. 4 is different from data cubes in data warehouses. The elements in Fig. 4 are T or F. The elements in the data cubes are data 3\The differences between double-connective association rule and database query are that, first, the query information in databases are predeterminate while the information to be mined by double-connective association rule is not predeterminate, it is implied. Secondly, database query needs to write SQL statements, while double-connective association rule mining is automatic. Thirdly, the information obtained by database query is quantitative, while the information obtained by double-connective association rule mining is qualitative such as ìfor manyî, ìthere are some  REFERENCES 1 Ji a w ei H a n   M i ch eli n e K a m b er   D a t a  M i n i n g C onc ep t s  a nd Techniques, Higher Education Press, Beijing, 2001, Morgan Kaufmann Publishers, 2000 2 A  G  Ha m i lt on  L o gi c for M a th em a t i c ia ns R evi s ed E d i t i o n   Cambridge University Press, 1988, Tsinghua University Press Beijing, 2003 3 X unw e i Z h o u   Br ie f I ntr o du c t io n  to  Mu t u al l y I nve r s is tic Logicî, 1999 European Summer Meeting of the Association for Symbolic Logic, Utrecht, The Netherlands, August 1-6 1999 4 u n w ei Zh ou F i r s t leve l exp l i c i t m u lt ip le i ndu ct i v e compositionî, 2005 Spring Meeting of the Association for Symbolic Logic, The Westin St. Francis Hotel, San Francisco CA. USA, March 25-26, 2005 5 A b rah a m S i lb ers c ha t z  Hen r y  F  Kort h  S S u da rs ha n Dat a b a s e  System Concepts \(Fourth Edition\, Higher Education Press Beijing, 2002, McGraw-Hill Companies, 2002  
279 
279 


support pruning gene expression classifier with an accurate and compact fuzzy rule base for microarray data analysis Biosystems vol 85 computationally challenging As training set sizes increase it is likely that these difficulties will also increase VI RELATED WORK While operating on a microarray dataset current CAR 1 2 3 4 and other pattern/rule 20 21 mining algorithms perform a pruned and/or compacted exponential search over either the space of gene subsets or the space of sample subsets Hence they are generally quite computationally expensive for datasets containing many training samples or genes as the case may be BSTC is explicitly related to CAR-based classifiers but requires no expensive CAR mining BSTC is also related to decision tree-based classifiers such as random forest 19 and C4.5 family 9 methods It is possible to represent any consistent set of boolean association rules as a decision tree and vice versa However it is generally unclear how the trees generated by current tree-based classifiers are related to high confidence/support CARs which are known to be particularly useful for microarray data 1 2 6 7 11 BSTC is explicitly related to and motivated by CAR-based methods To the best of our knowledge there is no previous work on mining/classifying with BARs of the form we consider here Perhaps the work closest to utilizing 100 BARs is the TOPRULES 22 miner TOP-RULES utilizes a data partitioning technique to compactly report itemlgene subsets which are unique to each class set Ci Hence TOP-RULES discovers all 100 confident CARs in a dataset However the method must utilize an emerging pattern mining algorithm such as MBD-LLBORDER 23 and so generally isn't polynomial time Also related to our BAR-based techniques are recent methods which mine gene expression training data for sets of fuzzy rules 24 25 Once obtained fuzzy rules can be used for classification in a manner analogous to CARs However the resulting fuzzy classifiers don't appear to be as accurate as standard classification methods such as SVM 25 VII CONCLUSIONS AND FUTURE WORK To address the computational difficulties involved with preclassification CAR mining see Tables IV and VI we developed a novel method which considers a larger subset of CAR-related boolean association rules BARs These rules can be compactly captured in a Boolean Structure Table BST which can then be used to produce a BST classifier called BSTC Comparison to the current leading CAR classifier RCBT on several benchmark microarray datasets shows that BSTC is competitive with RCBT's accuracy while avoiding the exponential costs incurred by CAR mining see Section VB Hence BSTC extends generalized CAR based methods to larger datasets then previously practical Furthermore unlike other association rule-based classifiers BSTC easily generalizes to multi-class gene expression datasets BSTC's worst case per-query classification time is worse then CAR-based methods after all exponential time CAR mining is completed O SlS CGl versus O Si CGi As future work we plan on investigating techniques to decrease this cost by carefully culling BST exclusion lists ACKNOWLEDGM[ENTS We thank Anthony K.H Tung and Xin Xu for sending us their discretized microarray data files and Top-k/RCBT executables This research was supported in part by NSF grant DMS-0510203 NIH grant I-U54-DA021519-OlAf and by the Michigan Technology Tri-Corridor grant GR687 Any opinions findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding agencies REFERENCES 1 G Cong K L Tan A K H Tung and X Xu Mining top-k covering rule Mining SDM 2002 5 R Agrawal T Imielinski and A Swami Mining associations between sets of items Y Ma Integrating classification and association rule mining KDD 1998 11 T McIntosh and S Chawla On discovery of maximal confident rules without pp 43-52 1999 24 S Vinterbo E Kim and L Ohno-Machado Small fuzzy and interpretable pp 165-176 2006 1071 pp 207-216 1993 6 G Dong pp 273-297 t995 9 pp 5-32 2001 20 W Li J R Quinlan Bagging boosting and c4.5 AAAI vol 1 V Vapnik Support-vector networks the best strategies for mining frequent closed itemsets KDD 2003 4 M Zaki and C Hsiao Charm L Wong Identifying good diagnostic genes or gene expression data SIGMOD 2005 2 G Cong A K H Tung X Xu F Pan and J Yang Farmer Finding interesting rule gene expression data by using the gene expression based classifiers BioiiiJcrmatics vol 21 l and Inrelligent Systenis IFIS 1993 16 Available at http://sdmc.i2r.a-star.edu.sg/rp 17 The dprep package http:/cran r-project org/doclpackages dprep pdfI 18 C Chang and C Lin Libsvm a library for support vector machines 2007 Online Available www.csie.ntu.edu.tw cjlin/papers/libsvm.pdf 19 L Breiimnan Random forests Maclh Learn vol 45 no 1 M Chen and H L Huang Interpretable X Zhang 7 J Li and pp 725-734 2002 8 C Cortes and Mac hine Learming vol 20 no 3 in microarray data SIGKDD Worikshop on Dtra Mining in Bioinfrrnatics BIOKDD 2005 12 R Agrawal and R Srikant Fast algorithms for mining association rules VLDB pp 1964-1970 2005 25 L Wong and J Li Caep Classification by aggregating emerging patterns Proc 2nd Iat Coif Discovery Scieice DS 1999 gene groups from pp 487-499 t994 13 Available ot http://www-personal umich edu/o markiwen 14 R Motwani and P Raghavan Randomized Algoriitlms Caim-bridge University Press 1995 15 S Sudarsky Fuzzy satisfiability Intl Conf on Industrial Fuzzy Contri J Han and J Pei Cmar Accurate and efficient classification based on multiple class-association rules ICDM 2001 21 F Rioult J F Boulicaut B Cremilleux and J Besson Using groups for groups in microarray datasets SIGMOD 2004 3 concept of emerging patterns BioinformJotics vol 18 transposition for pattern discovery from microarray data DMKD pp 73-79 2003 22 J Li X Zhang G Dong K Ramamohanarao and Q Sun Efficient mining of high confidence association rules without S Y Ho C H Hsieh H pp 725-730 1996 10 B Liu W Hsu and support thresholds Principles f Drata Mining aind Knowledge Discovery PKDD pp 406 411 1999 23 G Dong and J Li Efficient mining of emerging patterns discovering trends and differences KDD J Wang J Han and J Pei Closet Searching for An efficient algorithm for closed association rule mining Proc oJ the 2nd SIAM Int Con on Data in large databases SIGMOD 



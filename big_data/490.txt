 1  2230-7803-8870-4/05/$20.00 251 2005 IEEE\224  2  IEEEAC paper #2.0402 version 3, Updated December 22 2004  Telelogic\222s DOORS 256 requirements tracking tool evaluating affects of the results of those negotiations on the ability to achieve objectives originating at higher levels.  It also provides a succinct snapshot of those high level objectives \226 particularly important for high-level goals since there is often no objective algorithm to quantify the relative merits of the conflicting high-le vel goals.  For this case, the matrix provides a convenient notation for assessing and arbitrating the impact on equal-valued objects caused by changes in available mission resources  T ABLE OF C ONTENTS  1  I NTRODUCTION 1 2  O VERVIEW 2 3  B ASELINE CONTENTS AND RELATIONSHIPS 2 4  C ONSTRUCTION OF A COMPLETE STM...........................3 5  K EY PARAMETERS 4 6  S YSTEM E NGINEERING TOOL 4 7  A PPLICATION OF THE TRACEABILITY MATRIX 5 A   F ORMULATION STAGE 5 B   R EQUIREMENTS D EVELOPMENT PHASE 6 C   M ISSION I MPLEMENTATION PHASE 6 D   M ISSION O PERATIONS P HASE 6 E   O UTREACH 6 F   D ATA A RCHIVING AND MISSION DOCUMENTATION 6 G   F ORMATS AND OTHER PRACTICAL MATTERS 6 8  C ONCLUSIONS 6  1  I NTRODUCTION   A science mission proposal must be able to simply, and quickly explain the importance of mission goals and how those goals are implemented. The Science Traceability Matrix \(STM\rovides such an overview of what a Mission will accomplish and relates it to high-level objectives suggested by program architect ure statements such as the Academy of science decadal survey, NASA Roadmaps, or NASA Program Objectives. The STM provides a logical flow from these high level objectives through Mission objectives, measurement objectives, instrument requirements, spacecraft and system requirements to data products and eventual publications. It is the vehicle that summarizes the relationship between all these key elements and the one document that pr ovides the breadth and scope needed to perform high level trades effecting science outcome and overall design   1 Science Traceability James R. Weiss, William D. Smythe and Wenwen Lu California Institute of Technology\222s Jet Propulsion Laboratory 4800 Oak Grove Drive Pasadena, Ca 91109-8099 James.R.Weiss@jpl.nasa.gov, M/S 183-3 35, 818-354-5420; William.D.Smythe@jpl.nasa.gov, M/S 183-601, 818-354-3612 Wenwen.Lu@jpl.nasa.gov, M/S 238-600, 818-354-0004   Abstract 227Any comprehensive science mission 1,2 proposal must be able to simply explain why it is important to accomplish the goals of the mission and how it will be implemented. This can be accomplished through use of a Science traceability matrix, a co nstruct that is becoming a required component of all NASA science mission proposals The Science Traceability Matr ix \(STM\des the overview of what a Mission will accomplish relative to high-level objectives suggested through Academy of science surveys, NASA Roadmaps, or Program Objectives. It provides a logical flow from these high level objectives through mission objectives science objectives measurement objectives, m easurement requirements instrument requirements and spacecraft and system requirements to data products and eventual publications. It is the one document that shows the relationship between all these key elements and the one document that provides the breadth needed to perform and document high level trades effecting science outcome and overall design  The increasing detail in the requirements flow down represent results of considering underlying key parameters Some of the key parameters considered during requirements definition include: observation importance, ability to make a given measurement, constraints on all systems, number of measurements needed to comple te an observation objective complexity of required measurements, probability for success, measurement fidelity, data quality, community involvement, publishable findings, questions addressed Parameters underlying instrument definition include: data requirements, pointing constraints, stability requirements mounting constraints, thermal constraints, power constraints, mass, and volume  The STM can be used as a gauge to determine the completeness of the definition of a proposed mission If the matrix flows effortlessly fr om high level objective to publishable science result then it has been carefully laid out If the logic that ties one aspect to another is not clear then there is more work to be done prior to any proposal preparation  The science matrix provides a basis for negotiating lower level requirements \(typically tracked with tools such as  


Instrument Requirements Instrument Requirements  A good science traceability matr ix \(STM\he high level information needed to understand why a given proposal is relevant, what it purports to accomplish for science, how it intends to accomplish it, and what expected products and knowledge will resu lt from it's success. It also provides a template for trade studies by spelling out what is needed to accomplish any specific objective. If the objective is changed or the approach to achieving the objective is altered then the ripple effect is easy to determine for analysis and further iteration. For instance, if a particular instrument is not appropriate to achieve a given measurement objective then analysis of a lternate instrument approaches can be compared readily to measurement requirements to meet the obj ective. If analysis shows that the over-all intent of the objective cannot be met, then it becomes a driver on the re formulation of the mission Alternately, if a primary objective is decided to be overambitious, the resource savings regarding instrument spacecraft, and ground requirements changes are easy to determine. Additionally, the STM provides a tool for evaluating the scientific consequences of any reduction in objectives, yielding a clear indication of expected science return and establishing a new baseline for mission feasibility and importance. As a basic sy stems engineering tool, a good science traceability matrix provides requirements traceability from over-all mission and science objectives through expected delivered sc ience products thus a trade space for adjusting to changing mission capabilities requirements analysis, pe rformance analysis, cost evaluation, and assessment of mission design. The traceability matrix also has app licability through out the life cycle of the project, including mission formulation, proposal development and evaluation, im plementation risk analysis and requirement trades, development analysis, operations analysis, public education, and data archiving Science Products Science Products Measurement Requirements Measurement Requirements  2 The process of developing an STM provides a forum for proposers to develop and document sound rationales for the design and implementation of their mission.  The STM aids reviewers of a proposed mission by serving as a gauge to determine if a proposal is complete or not. If the matrix flows effortlessly from high-levels to publishable science result, then the science content of a mission has been carefully laid out. The logic that ties one aspect of the matrix to another is the key to its effectiveness and the parameter space by which key trades will be made.  Finally the STM has excellent potential for quickly determining the effects of low-level changes on high-level goals throughout the implementation and operation of a mission  2  O VERVIEW   Figure 1.  The contents of the science matrix include all science elements that affect resource trades for mission implementation \226which is not part of the STM is summarized in the bottom box of this figure Science traceability has become a required component of all NASA science mission proposals. A proposal containing a carefully constructed traceability matrix can clearly communicate that the proposal has been well thought out, is technically complete, and is well organized for review. In today's world of fierce competition and change it is important to convey this message as strongly as possible and to have proposed missions structured for adaptation to changing conditions. The sc ience traceability matrix approach provides al l these attributes  3  B ASELINE CONTENTS AND RELATIONSHIPS   A baseline STM contains tr aceability from high-level objectives, usually taken from Programmatic Road Maps and/or stated explicitly in a given Announcement of Opportunity \(AO\, and relates those high-level science objectives to measurement ob jectives, which, in turn quantify the observations nece ssary to acquire the needed data. In the simple case, each Measurement Objective is tied to a given Science Objective.   Practical cases often have a many-many relationship \(i.e. one science objective may require several measurement obj ectives and, conversely, one measurement objective may address several science objectives\ The Measurement Objectives are written in such a way as to indicate what is seen as important to achieving a given Science Objective e.g. \223Obtain magnetic moments \223 \(measurement objective\etter understand  Space Craft Requirements Ground System Requirements Mission Requirements Mission Operations Requirements Space Craft Requirements Ground System Requirements Mission Requirements Mission Operations Requirements Program Objectives Program Objectives Mission and Science Objectives Mission and Science Objectives Measurement Objectives Measurement Objectives 


when the relationshi le measurement may support several science objectives.  This potential many-m any relation can make it diffi cult to enumerate all flowdown succinctly.  Though there is a host of clever ways to multiplex the parent-child relationshi to the mission ob Fi s are flattened throu le of a fra ortin have multi uirements on s and uickl A sin lication.  To kee rehend aratel ure small, this particular example does not include the important re le science ob lanetar uirements for the uirements should be tracked se matrix formulation.  The sics.  Note the flow from the NASA roadma le su lementation such as bus and telemetr s, the matrix is easiest to com acecraft im pp h re y the fi eo  3 the internal structure of Ne ptune\224 \(science objective\. The measurement of internal structure may include measurements of  the gravity fi eld, the magnetic field, etc The Science Objective leads to one or more Measurement Objectives which in than drive the measurement requirements, which in turn set sensitivity and range requirements on the instruments and sensors. In this example to measure the gravity field you may require threeband propagation for radio science experiments or precision pointing knowledge to determine the direction of the magnetic fields. The flow-down dictates the instrument complement to be supported by the chosen spacecraft and ground system. The flow chart in figure 1 illustrates the relationship of the flow.  Note that high-level accommodation requirements, mission requirements, and ground system requirements ar e usually placed in separate constructs \(for a proposal\, to maintain brevity of the STM  4  C OMPLETING C ONSTRUCTION OF THE STM  After determining what the driving Science Objectives will be, and establishing Measurement Objectives needed to achieve the science objectives, one determines the measurement requirements to achieve the measurement objectives and the instrument set required to achieve those measurement requirements. Fo llowing forward with our previous example there is a requirement to perform radio science measurements but in order to improve upon our previous knowledge the gr avity moment measurement would have to be better than \(say\rder n \(n~12\is requires a certain circular orb it around the plan et along with both spacecraft and ground te lecom capabilities to achieve the desired measurement fidelity A circular orbit at a given height then becomes one of the mission accommodation requirements for radio science, as does the telecom configuration. Likewise, for each chosen instrument a set of measurement requirements would have to be established that specify the instrument performance as well as potentially\cr aft and ground requirements This establishes the traceability from Science Objectives to Measurement Objectives, to m easurement requirements, to instrument selection, to measurement requirement to instrument performance spec ifications, to spacecraft and ground requirements. The finishing touch for the STM includes expected data and science products \226 which can be used to validate the sizing of the data analysis and science Objective #1 Learn How the Sun's Family of planets and minor bodies originated Objective #2 Determine how the solar system evolved to its current diverse state Mission Objectives To determine the state, atmosphere and structure of "Planet" and the structures of it's satellites Science Objectives Measurement Objectives Measurement Requirements Instruments Instrument Requirements Data Products Planet measure gravity field Gravity moment to order 12 Radio 3 bands to recover propogation gravity moment of order n \(n~ 12 measure magnetic field Magnetic moment to order 14 Vector Magnetometer Resolution 0.1 nT mounting orientation to 10 arcsec magnetic moment of order n \(n~14 3. Magnetosphere structure, plasma dynamics and radiation belts measure magnetic field, charged particle and plasma waves over a large range of lattitudes, longitudes, and altitudes, and local time \( need to rotate the line of apsides 180o Field direction to 1 degree, field resolution 0.1 nT, continuity 95 magnetometer, plasma, low energy protons \(LEP magnetosphere map plasma spectrum proton spectrum Satellites multispectral IR imaging of surface Map full surface at 3 meters/pixel Mapping IR spectrometer SNR 30, ifov 0.5 mrad, FOV 8.5 degrees high resolution global coverage multispectral image data measure gravity field circular orbit, global coverage for 3 rotations, order 6 radio science gravity field map measure magnetic field circular orbit, global coverage for 3 rotations magnetometer 0.5 nT resolution magnetic field map measure surface topography 100m track spacing laser altimeter 30 meter spot size, 10 hz pulse, 1 nanosec gates topography map NASA Solar System Exploration Roadmap 2. Internal structure 1.  Characterization interior, surface structure activity and atmosphere  g p g y p y j g y g p h p j g g ravit y q p q p y g y g j y p g g p p q y p g p p g q p p y  data rates, fields of view, power, and operational requirements lanet and the satellite.  These different re ure 2:  Generic exam matrix for a orbiter.  In this extract the science ob ment of a science traceabilit ectives stated in an AO\ science objectives through to data product s.  This example illustrates se veral of the issues that arise durin ectives are eodes ective ma measurements and/or a sin field measurements have different measurement re but this can cause the matrix to row too large for clarit 


200  End-to-end system ability to make a given measurement 200  Minimum number of measurements needed to achieve a given science goal 200  Over-all complexity of each required measurement 200  Measurement fidelity to acquire the required science 200  Probability for making the successful measurement 200  Over-all data quantity and quality 200  Technology and implementation constraints 200  Key science questions to be addressed  Key parameters for instrument accomodation include  200  Pointing and stability requirements 200  Mounting and structure requirements 200  Thermal, power, mass, and volume constraints  For each of these key accommodation parameters there are implementation requirements that result in spacecraft and ground architecture drivers For data products there are formatting and delivery requirements; there are timing requirements regarding when the data was taken and when the data will be available fo r analysis.  There are also requirements pertaining to what information will be appended to the different data products consisting of pointing direction and stability, thermal and power conditions, a list of other instruments taking simultaneous data, and a host of other concerns all of which could cause conflicts and design considerations  Each instrument will have its own unique accommodation requirements as well. Examples of unique requirements include: magnetic cleanliness for magnetometers, radiation protection if orbiting Jupiter, reflected light for cameras and spectrometers, etc  Continuing the gravity m easurement example, the Traceability Matrix frag ment in figure 2 shows the result of considering key parameters: This example shows the top level driving objectives from the Solar System Exploration Roadmap as the rational for the mission followed by stepwise delineation of what is needed to accomplish these given objectives. For the science objective to determine the internal structure of the plan et, it is clear that specific measurements need to be made with qualified instruments capable of delivering the data quality and resolution desired along with the requirements th is approach would place on both the spacecraft and ground systems needed to carry it out. If all this is accommodated then there are specific resultant products that would be delivered to the appropriate science archive for distribution to scientist who would perform the required analysis and publish the papers that represent the findings   4 teams. The formation of the STM follows the flow summarized in figure 1  At JPL we are developing a tool to aid proposers in the development of a complete STM.  The tool uses databases containing information on what has flown in the past instruments, instrument performance, instrument requirements, spacecraft cap abilities, ground system choices, and science goals. The tool includes look-up tables describing available instruments, their performance capabilities, and their interface requirements as well as road maps, spacecraft and ground system overviews.  The tool is intended to provide proposers with rapid access to details of the components required to form the STM.  Establishing the logical and quantitative relationships between these components remains, of course, an exercise for mission proposers  5  K EY PARAMETERS   The STM requirements and objectives are based on assessment of key parameters underlying those requirements.  Some of these key parameters include  200  Relative importance of an observation to achieve the desired science 200  Data rate and volume requirements Figure 3 shows a more complete STM example based on a fictitious, but representative, Europa orbiter mission dedicated to the characterizati on of potential oceans. Instead of multiple objectives \(observations of both primary planet and its satellites\ the earlier example, this second mission has a single objective, Europa. Figure 3 clearly illustrates the \(common\ multiple relationship structure arising in STMs. Science objective 1A maps to 4 instruments \(altimeter, radar sounder, radio science and magnetometer\ngle instrument, e.g. the laser altimeter, could contribute to the measurements of surface topography \(1A\ and ch aracterization of surface morphology \(1C  There are also cross-dependencies among different requirements. In this example the performance of the laser altimeter correlates directly wi th the precision of the orbit determination, which is determined by the radio science requirements; the pointing stability requirements of NAC should agree with the altimeter pointing requirements; the data collection scenario for im aging is constrained by the resolution of the imagers and the telecom capability   6  S YSTEM E NGINEERING TOOL   Science traceability is becoming a required component of all NASA science mission proposals.   It has high utility in improving proposal organization, facilitating reviews, and in negotiating and documenting arbitration of mission implementation and resource utilization. What is required differs from discipline to discipline but the basic form of the science traceability matrix ha s been well established. A proposal containing a care fully constructed traceability 


and Science investigations science investigation a tool to assess alignment of proposed to flagship missions, can use the science traceability matr ix to summarize alignment with the stated mission goal s.  Typically, a program implementation plan \(PIP at accompanies an AO for a flagship mission will already include a STM, created by a mission development team and based on mission objectives and a strawman payload.  The proposed science investigation would typically demonstrate how elements in the matrix would be met or enhanced with this particular investigation and, perhaps, ho w the mission objectives can be enhanced  Technology development proposed mission Proposed missions NASA goal development  5 matrix can clearly communicat e that the mission proposal has been well thought out, is complete, and is well organized for the reviewer. In today\222s world of fierce competition and change, it is important to convey this message as strongly as possible, and to propose missions structured for adaptation for changing conditions and resource availability. The sc ience traceability matrix approach provides a ll these attributes  As a basic systems engineer ing tool, a good science traceability matrix pr ovides requirements traceability from overall mission and science objectives through expected delivered science products; thus providing a trade space for adjusting to changing mission capabilities, requirements analysis, performance analysis, cost evaluation, and assessment of mission feasibility. Fundamental to all mission development work is a straightforward means of evaluating the end-to-end system in terms of the effects on NASA and mission objectives, cost drivers, technology risks and system drivers. The science traceability matrix can be used to evaluate the consequences of system changes on science through analysis of resultant requirement modifications. Taking our previous example, if it is determined that the given spacecraft and ground configuration can produce the desired resolution yet the expense of doing so would be prohibitive then the effects of a reduction in capability on the measurement and science objectives can be assessed conveniently. Likewise if a given system configuration is determined to be insufficient to meet science objectives, the sc ience traceability matrix can be used to evaluate the cost-effectiveness of a range of possible upgrade alternatives each of which would be analyzed with respect to implementation feasibility, cost effectiveness and impact on the end-to-end system   7  A PPLICATION OF THE TRACEABILITY MATRIX   The traceability matrix has app lication throughout the lifecycle of a project, including formulation, proposal evaluation, implementation requirements development implementation, operations, public education, and data archiving.  The matrix is normally presented in several formats to improve the utility of the matrix to a particular application.  However, the underlying flow and content remain constant, as seen in the following descriptions of use of the matrix a. Formulation stage  The formulation stage of missions includes defining goals for NASA and NASA programs, defining missions that meet those goals, and defining science investigations that meet mission objectives.  This stage also includes proposing missions and science goals and assessing those proposals  Depending on the applicatio n, the science traceability matrix may be used as a tool to assess approaches to i  populate the matrix in a some what different way.  These applications provide specific t echnologies or specific goals and then assess a variety of potential missions that would utilize the technology or implement the goals.  In these cases, the traceability matrix is populated from existing databases of science needs \(typically from experts and literature\previous results, and existing and near-term technologies \(typically inform ation from previous missions and current technology program s\sultant matrices can then be used to compare the relative value of proposed new technologies or the feasibility of implementing specific goals.  At this point in time, the information used to populate matrices for these appli cations is relatively diffuse This results in a labor intensive, and time-consuming process to evaluate technologies and goals. There has been however, recent significant progress in forming summary databases of instrument capa bilities, characteristics, and applications, and developmental effort in forming similar summaries of NASA goals and mission goals, capabilities and results.  These can be used to both populate and assess STMs.  STMs populated from these databases cannot substitute for the value of using experts with current knowledge of the field to ev aluate goals and technologies but have the potential to provide both speed and scope for identifying which are most viable  with previously defined NASA program goals \(typical of Principal Investigator \(PI\ defined missions such as the NASA SMEX, Discovery, and New Frontiers programs\or as a tool to assess the alignment of a mplementing NASA programs near-term goals utilize the science traceability matrix to validate that the mission goals are consistent with long-term program goals \226 termed variously \223decadal surveys\224 and 223roadmaps\224 that have been delineated by national working groups populated with scientists representing a wide range of planetary and astrophysical disciplines.  The tool is also used to demonstrate \(and, for reviewers, validate\that the mission objectives can be achiev ed within the mission plan and payload capabilities and that the planned measurements represent significant advances over existing measurements  with previously defined mission goals \(typical of large flagship missions\or as a tool to assess the science utility of a proposed technology development demonstration and validation \(typically a New Millennium-class mission  


ich, in theory, provides the ability to assess the effects of changes on all subsystems.  The role of the STM in negotiations leading up to agreements on capabilities is to provide a useful notation for assessing and tracking the effects of these negotiations on mission, science, and measurement goals.  It also provides a convenient way to assess alternative approaches toward achieving a given goal c. Mission Implementation phase Mission implementation requirements development occurs early in phase B of a mission.  This is the mission stage when resources and design are matched with all of the elements of the science traceability matrix in detail.  It is very typical to discover at this stage, when sufficient resources are available to cal culate the implications of various science requirements for all subsystems and resources, that some performances could be improved within the given resource envelope, and that some requirements are simply unac hievable.  The requirements and capabilities are negotiated and typically entered into a requirements tracking tool \(such as DOORS During the implementation phas e of a mission, it is common to discover that th ere are insufficient re sources to implement all planned capabilities.  The STM can be particularly useful when these resource limits affect the basic science plan There are generally several science measurements of approximately equal priority and disparate value functions Changes in these measurements are generally assessed by criteria other than relative value, frequently in acrimonious debate.  The STM provides a tool that can be used to evaluate the effects of modi fying one or both of these measurements on mission and NASA goals \226 perhaps clarifying, focusing and ameliorating the duration of the debate over changes to the mission d. Mission Operations Phase The STM includes a column summarizing expected data products associated with each measurement.  This can be used as a basis for planning what types and how much data will be included in archives such as the Planetary Data System \(PDS\and tracking completion of the data deliveries  The content of the STM can also serve as a mission documentation tool.  Science traceability matrices contain the information required to succinctly describe the purpose and science implementation of prior missions.  It, in fact contains the mission and inst rumentation information in compact format, required to populate databases needed to assess planning and proposal for future missions g. Formats and other practical matters One of the largest challenges in developing a science traceability matrix is to place it in a form that is logical readable and rapidly comprehensible.  The challenge arises from the many-many \(rather than parent-child\ationships that are endemic to the STM content, and from the space limitations that are extant, particularly in proposals.  Many formats have been utilized to address this challenge in proposals, including indexing, mapping with color, separate but related tables and so on.  The page limitations typically imposed on proposals \(as well as workforce resource limits dictate against completely popul ating the matrix at the time of a proposal \226 even though most of the information is based on current knowable availa ble at that time.  The result of the space limitation on th e STM is unfortunate and perhaps should be changed for the proposal process, since historically there are insuffic ient workforce resources to update the STM in later phases of the mission.  The overall result is typically a longer, and more expensive than necessary, requirements development phase, higher difficulty in reallocating reso urces during the mission and operations phase, and inconsistency in documenting the mission during archiving  8  C ONCLUSIONS   A science traceability matrix provides a valuable tool for assessing both mission and systems engineering requirements. The science tr aceability matrix additionally provides a clear means for proposal evaluation and system resource trades. It is concise, complete, and straightforward The STM supports analysis fr om either a top down or bottoms up approach providing flexibility and end-to-end visibility. The effort to create a science traceability matrix is small compared to the benefits generated, including a quick means of determining mission feasibility, illustration of implementation complexity, clear presentation of potential advantages of an investigation, and a strong basis on which to perform resource trades. If fully implemented in the formulation stages of a mission, it has high potential for expediting the negotiation of level 3 requirements; resource trades during implementation and operation; and providing a concise summary of the mission for public outreach and 256  6 b. Requirements Development phase During the mission operations phase, changes to the science plan can arise from unforeseen resource changes \(such as budget reductions\ failures of subsystems, or unforeseen events \(weather and DSN outages\M can be used as a basis for negotiating sequencing and data return priorities in such cases e. Outreach The science traceability matr ix provides a compact overview of the purpose and implementation of a given mission.  While the notation is frequently too terse for public consumption, and the complexity of the matrix too high for presentation in its native state, it can provide an excellent basis for explaining the purpose and implementation of the project in outreach products  The STM can have similar utility in explaining the mission and inevitable mission changes, to program and higher-level managers charged with monitoring progress of the mission and with obtaining resources for future missions f. Data Archiving and mission documentation 


 7 mission archiving. Under the guidance of JPL\222s Team X a semi-automated form of this useful tool is being developed to fit a wide variety of missions types and applied to mission proposal development and evaluation  References  Announcement of Opportunity, New Frontiers Program 2003 and Missions of Opportunity, AO-03-OSS-03  RESEARCH OPPORTUNITIES IN SPACE SCIENCE \226 2003, \(ROSS-2003\NASA Announcements of Opportunity Soliciting Basic Research Proposals, NRA 03-OSS-01  Biography  Jim Weiss is the Chief Engineer for the Earth and Space Sciences Division at the Jet Propulsion Laboratory. In this role he serves as  Science Chair for JPL\222s Team X, Proposal Coordinator for Earth and Space Sciences, science systems engineer for the Division and Engineering representative for science to most high level engineering and mission development efforts. He served five years at NASA HQ as a Program manager developing science systems engineering approaches for distributed data systems, science support to missions, and advanced planning. He has held science support and science management positions on 17 different NASA flight missions serving as every thing from science coordinator to Program Manager. He has graduate degrees in both applied mathematics and systems engineering 


ure 3:  Exam Fi le, Science requirements A-C form the science floor \226 a reduction from the full A-E mission objectives.  The same instrument is used to address several mission objectives \(though with different performance requirements\d some mission obj ectives require more than one instrument for complete fulfillment Further, reduction of one available resource may aff ect the ability to achieve mission goals by different degrees.  The science tracea bility matrix is invalu able for summarizing and assessing these oftencomplex relationships a Orbiter mission.  In this exam le of a traceabilit 265 m; PRF 400 Hz; bandwidth 0.85 MHz; 3dB beam width: 20 o across/100 o along track footprint w/ 100 km orbit 35 km across/238 km along track; resolution vertical 10% of depth at depth; horizontal 1 to 2 km 2 orbital passes during Jupiter occultation ice shell depth map with 56% coverage internal structure and orbit determination gravitational love number k2\ to an accuracy +/-0.001 Radio Science radial position knowledge 1m; Non-radial position knowledge ~ 100m Doppler shift accuracy 0.1mm/s 2 weeks of observation gravity map with 90% coverage signature of global liquid water 0.03nT magnetic field strength variation magnetometer 3-axis ring core fluxgate magnetometer; range 1024 nT; sampling rate 40 Hz maximum 2 weeks of observation spatial and temporal varying magnetic field tracks B Characterize and locally map the surface composition especially compounds of interest to prebiotic chemistry Distribution of water ice bands, hydrated salt minerals, and trace constituents on the surface 900-3700nm spectral analysis of surface;5 nm spectral resolution, 512m 5km spatial resolution NIR Imaging Spectrometer spectral range: 900-3700 nm; spectral resolution 5nm \(560 channels\gh resolution mode at 512 m/pixel; survey mode factor of 10 summation\ at 5.12 km/pixel High resolution mode 0.5% per orbit during day time; 1 coverage; Survey mode: 25% per orbit day time; ~50 coverage hyper-spectral map with 50% coverage in survey mode 1% coverage in high spatial resolution 150m/pix & 2m/pix spatial resolution Imaging Camera monochromatic wide-angle camera and narrow-angle camera images WAC: 1.5 mrad ifov 1.31rad fov; 150-300 m/pixel at 100km; swath width 150km; NAC: 100 mrad ifov; 0.021 rad fov 2m/pixel at 100km; swath width 2km WAC: 15 images per orbit; NAC: 7 images per orbit surface map with 90% coverage at 150m resolution 1% coverage at 2m resolution 900-3700nm spectral analysis of surface;5 nm spectral resolution, 512m 5km spatial resolution NIR Imaging Spectrometer spectral range: 900-3700 nm; spectral resolution 5nm \(560 channels\gh resolution mode at 512 m/pixel; survey mode factor of 10 summation\ at 5.12 km/pixel High resolution mode 0.5% per orbit during day time; 1 coverage; Survey mode: 25% per orbit day time; ~50 covera g e hyper-spectral map with 50% coverage in survey mode 1% coverage in high spatial resolution surface topography to 0.3m laser altimeter frequency 10Hz, FoV 1mrad; 50m spot size footprint spacing between 100m to 2 km depending on scannin g 2 weeks  of observation topographic map with 90% coverage D Characterize the 3-D distribution of any subsurface liquid water Find ice/liquid water boundary 100m vertical resolution near surface,10% depth of depth radar sounder Frequency 50 MHz,\(6m in vacuum and 3.5m in ice pulse width 500mm; PRF 400 Hz; bandwidth 0.85 MHz; 3dB beam width: 20o across/100o along track footprint w/ 100 km orbit 35 km across/238 km along track; resolution vertical 10% of depth at depth; horizontal 1 to 2 km 2 orbital passes during Jupiter occultation ice shell depth map with 56% coverage Quantify magnitude of energy transferred to detectors by charged particles in Europan orbital environment Heavy Ion Counter Energetic Particle Detector Detect range 6-200 MeV nucleon; Time  resolution 0.7s ~ 2.0s; aperture angle: 0.436 rad narrow 0.803 rad wide model 2 days of observation energetic particle counts for Europa environment E. Characterize the radiation and magnetic field environment with spatial and temporal A Determine the radial structure of Europa, specifically the ice/water interface and ice shell structure C Understand the formation of surface features, including sites of recent or current activity, and identify candidate landing sites for future lander missions Characterize morphology and correlate with surface composition         8  Science Ob j ectives Measurement Ob j ectives Measurement Re q uirements Instruments Instrument Re q uirements Mission Re q uirements Data Products strength of ice shell 1m accuracy of tidal bulge;+/- 0.04 tidal love number \(h2 laser altimeter frequency 10Hz, FoV 1mrad; 50m spot size footprint spacing between 100m to 2 km depending on scannin g 2 weeks  of observation topographic map with 90% coverage radial structure of ice shell and depth to brittle/ductile transition 100m vertical resolution near surface,10% depth of depth radar sounder Frequency 50 MHz,\(6m in vacuum and 3.5m in ice pulse width 500 g p y p p matrix for a Euro 


ranges around 10  15 Once the increment is larger than the original size the overhead decreases very rapidly from 10 to 5 This is a very encouraging result because it shows that FUP not only can benefit update with small increment it actually works very well in the case of large increment 4.6 Performance in scaled-up databases Our last experiment is done in a scaled-up database The database is T10.I4.D1000.d10 which contains 1 million transactions The performance ratio between DHP and FUP in this scaled-up database ranges from 3 to 16 The result shows that the gain from FUP will in fact increase if the database becomes larger This shows that FUP is very adaptive to size increase and can be applied to very large databases 5 Discussion and Conclusions We studied an efficient fast incremental updating technique for maintenance of the association rules dis covered by database mining The developed method strives to determine the promising itemsets and hope less itemsets in the incremental portion and reduce the size of the candidate set to be searched against the original large database The method is implemented and its performance is studied and compared with the best algorithms for mining association rules studied so far The study shows that the proposed incremen tal updating technique has superior performance on database updates in comparison with direct mining from an updated database The incremental updating technique is applicable to the databases which allow frequent or occasional updates when new transaction data are added to a transaction database We have also investigated the cases of deletion and modification of a transaction database Recently there have been some interesting stud ies at finding multiple-level or generalized association rules in large transaction databases 6 111 The exten sion of our incremental updating technique for mainte nance of multiple-level or generalized association rules in transaction databases is an interesting topic for fu ture research References R Agrawal T Imielinski and A Swami Mining Association Rules between Sets of Items in Large Databases In Proc 1993 ACM-SIGMOD Int Conf Management of Data 207-216 May 1993 R Agrawal and R Srikant Fast algorithms for mining association rules. In Proc 1994 Int Conf Very Large Data Bases pages 487-499 Santiago Chile September 1994 D.W Cheung A W.-C Fu and J Han Knowledge discovery in databases A rule-based attribute-oriented approach In Proc 1994 Int 2221 Symp on Methodologies for Intelligent Systems pages 164-173 Charlotte North Carolina Octo ber 1994 U M Fayyad G Piatetsky-Shapiro P Smyth and R Uthurusamy Advances in Knowledge Dis covery and Data Mining AAAI/MIT Press 1995 J Han Y Cai and N Cercone Data driven discovery of quantitative rules in relational databases IEEE Trans. Knowledge and Data En gineering 5:29-40 1993 J Han and Y Fu Discovery of multiple-level association rules from large databases In Proc 1995 Int Conf Very Large Data Bases Zurich Switzerland Sept 1995 M Klemettinen H Mannila P Ronkainen H. Toivonen and A I Verkamo Finding inter esting rules from large sets of discovered associa tion rules In Proc 3rd Int\222I Conf on Informa tion and Knowledge Management pages 401-408 Gaithersburg Maryland Nov 1994 R Ng and J Han Efficient and effective cluster ing method for spatial data mining In Proc 1994 Int Conf Very Large Data Bases pages 144-155 Santiago Chile September 1994 J.S Park M.S Chen and P.S Yu An effec tive hash-based algorithm for mining association rules In Proc 1995 ACM-SIGMOD Int Conf Management of Daia San Jose CA May 1995 G Piatetsky-Shapiro and W J Frawley Knowl edge Discovery in Ratabases AAAI/MIT Press 1991 R Srikant and R Agrawal Mining generalized association rules In Proc 1995 Int Conf Very Large Data Bases Zurich Switzerland Sept 1995 114 


The disadvantage of this rule-oriented control strategy is that it imposes a restriction on the mixing of forward and backward chaining rules such that a forward chaining rule cannot read any data written by backward chaining rules STO87 To describe this problem let the following be a series of rules Ra to Rd and the resuls REa to REd derived by these rules Ra Rb Rc Rd DB  R  REb  R  REd Also let Ra and Rb be defined as backward chaining rules and Rc and Rd as forward chaining rules If the original database DB is updated rules Rc and Rd though they are forward chaining rules will not be triggered to update the result REd until someone requests the data of REb Thus REd may be iriconsistent with the base data To overcome this problem we use a result-oriented control strategy in which we specify for each result derived subdatabase whether it is to be pre-evaluated or post evaluated The same rule may follow the forward or backward chaining strategy depending on whether the derived subdatabae is to be pre or post-evaluated To illustrate by the example above assume that REd is defined as pre-evaluated and REb is defined as post evaluated Whenever the database DB is updated the rules Ra Rb Rc and Rd will be triggered in the forward chaining fashion to keep REM which is explicitly stored up-to-date REb on the other hand will be evaluated whenever a retrieval operation is issued against it In this case the rules Ra and Rb that derive REb are applied in the backward chaining fashion Thus Ra and Rb follow one control strategy when deriving RFxl and the other control straregy when deriving REb This technique offers more flexibility and alleviates the restriction in POSTGRES described above 7 Conclusion In this paper we have introduced the induced generalization association construct and presented a deductive rule-based language for object-oriented databases The world of subdatabases is closed under this language which facilitates defining inference chains in which each rule derives a new subdatabase based on the subdatabases derived by previous rules in the chain The transitive closure operation can be specified in our language in the form of looping rather than in a recursive form A result-oriented control strategy to be used as the underlying implementation technique has also been introduced in this paper ACKNOWLEDGEMENTS Research on the rule-based language was supported by the U.S West Advanced Technologies grant number UPN 88071315 Work on the Object-Oriented Query Language OQL was supported by the Navy Manufacturing Technology Program through the National Institute of Standards and Technology formerly the National Bureau of Standards grant number 60NANB4wO17 and by the National Science Foundation grant number DMC-8814989 The development efforts are supported by the Florida High Technology and Industry Council grant number UPN 85100316 BIBLIOGRAPHY ALA89a A.M Alashqur S.Y.W Su and H Lar OQL A Quy Language for Manipulating Object-onented Datah Accepted for Publication the 15th VLDB Int Con 1989 ALA89b A.M Alashqur A Query Model and Query and Knowledge Definition Langwi~es for Object-oriented Databases a Ph.D BAN87 BAT85 cER86 CHA84 COD79 DEL88 DIT86 HS87 FOR88 GAL84 HAM81 m7 JAR84 LAM89 MAI88 RAS88 STO87 SU89 TY88 U85 VAS84 Thesis Univedty if Florida 1989 Jay Banerjee et al Data Model Issues for Object-Oriented Aplications ACM Trans on Ofice Information Systems January 1987 D Batory and W Kim Modeling Concepts for VLSI CAD objects ACM TODS September 1985, pages 322-346 Stefan0 Ceri George Gottlob and Gio Wiederhold Interfacing Relational Databases and Prolog Efficiently Roc of the 1st Intl Con on Expert Database Systems 1986 C L Chang and A Walker PROSQL a PROLOG Programming Interface with SQLDS F'mxdngs of the 1st Intl Workshop on Expert Database Systems 1984 E Codd Extend~ng the Database Relational Model to Capture More Meaning ACM TODS Vol 4 No 4 1979 Lois ML Delcambre and James N Etheredge A self Controlling Interpreter for the relational Production Language Roceedings of ACM SIGMOD Conference on Management of Data 1988, pages 396403 KR Dimich Object-oriented Database Systems the Notion and Issues Roc of rhe Intl Workshop on Object-Oriented Database Systems califomia September 1986 D.H Fishman et al Iris An Object-Oriented Database Management System ACM Transaction on Oftixe Informarion Systems January 1987 Pages 4869 S Ford et al Zeitgeist Database support for object-oriented rogramming in the F  gs of the Second International Workshq on Object-oriented Database Systems 1988 Heme Gallaire Jack Mier and Jean-Marie Nicolas Logic and Databases A Deductive Approach ACM Computing Surveys June 1984 Pages 153-185 M Hammer and D McLeod Database Description with SDM A Semantic Associon Model ACM TODS Sepember 1981 R Hull and R King Semantic Database Modeling Survey Applications and Research Issues ACM Computing Surveys September 1987 Mauhias Jark Jim Clifford and Yannis Vassiliou An Optimizing hlog Front-End to a Relational Query System Roc of ACM SIGMOD Con on Management of Data 1984 H.M Lam S Su and A.M Alashqur Integrating the Concepts and Techniqws of Semantic Data Modeling and the Objectdented wradigm Roc of the 13th Intl Computex Software and ApptiCationS Conference COMSAC 89 1989 Christcphe de Maindreville and Eric Simon A Production Rule Based Approach to Deductive Databases Roc of the 4th Intl Con on Data Engineering California 1988 L Raschid and S.Y.W Su A Transaction-oriented Mechanism to Control Precessing in a Knowledge Base Management System Pmc of the Intl Con on Expert Database Systems 1988 Michael Stonebraker Eric Hanson and Chin-Heng Hong The Design of the POSTGRES Rules System Roc of the 3rd Intl Con on Data Engineering California 1987 S.Y.W Su V KrishnamurIhy and H Lam An Object oriented Semantic Association Model OsAM appearing in A.I in Indus&l Engineering and Manufacturing Theoretid Issues and Applications S Kumara et al eds American Institute of Industrial Engineering 1989 Frederick Ty G-OQL Graphics Interface to the Object Oriented Query Language OQL Master thesis University of Florida 1988 Jeffrey ullman Implementation of Logical Query Languages for Databases ACM TODS September 1985 Y Vassiliou J Clifford and M Jark Access to Specific Declarative Knowledge by Expert Systems The Impact of hg"'ning Decision Suppat Systems 1 1 1984 67 


 s_suppkey s_nationkey ps_partkey ps_suppkey ps_supplycost p_partkey p_name   l_partkey l_discount l_quantity l_orderkey l_suppkey l_extendedprice o_orderkey o_orderdate n_nationkey n_name p_partkey p_name   246\262 1 2 3 4 5 7 6 8 9 10,#11,#12,#13 14 15 16 17 18 1 2 Figure 11 Execution plan of TPC-D query 9 for transposed files 2 0 20 40 60 80 100 0 50 100 150 200 Time [s CPUusage NetSend NetRecv Disk 10 8 6 4 0 Throughput [MB/s CPU usage 8 9 10 13 Figure 12 Execution trace of TPC-D query 9 with transposed files 11 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


of I/O But the resulting speedup compared with the previous plans exceeds 2 which is quite satisfactory Table 3 shows the results of above right-deep rd left-deep ld and transposed file tp methods along with the reported results of other commercial systems for 100GB TPC-D query 9 Because our system lacks the software and maintenance price metrics the overall system price can\220t be determined accurately Hardware components themselves cost less than 0.5M We can observe that our system achieves fairly good performance Above all the execution time with the transposed files is twelve times as short as the most powerful commercial platform These results strongly support the effectiveness of the commodity PC based massively parallel relational database servers  System Exec Time Price Teradata on NCR 5100M 160 000 133MHz Pentium 20GB Main Memory 400 Disk Drives 953.3 17M Oracle 7 n DEC AlphaServer 8400 12 000 437MHz DECchip 21164 24GB Main Memory 84 Disk Drives 1884.9 1.3M Oracle 7 n SUN UE6000 24 000 167MHz UltraSPARC 5.3GB Main Memory 300 Disk Drives 2639.3 2.1M IBM DB2 PE on RS/6000 SP 306 96 000 112MHz PowerPC 604 24GB Main Memory 96 Disk Drives 2899.4 3.7M Oracle 7 n HP9000 EPS30 12 000 120MHz PA7150 3.75GB Main Memory 320 Disk Drives 7154.8 2.2M Our Pilot System 100 000 200MHz Pentium Pros 6.4GB Main Memory 100 Disk Drives rd 193.7 ld 177.2 tp 77.1 see text Table 3 Execution time of 100 GB TPC-D Q9 on several systems 12 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


4 Data mining 4.1 Association rule mining Data mining which is a recent hot research topic in the database field is a method of discovering useful information such as rules and previously unknown patterns existing behind data items It enables more effective utilization of transaction log data which have been just archived and abandoned Among the major applications of data mining is association rule mining so called 217\217basket analysis.\220\220 Each of the transaction data typically consists of a set of items bought in a transaction By analyzing them one can derive some association rule such as 217\21790 of the customers who buy both A and B also buy C.\220\220 In order to improve the quality of obtained rules a very large amount of transaction data have to be examined requiring quite a long time to complete First we introduce some basic concepts of association rule Let 000 000 001 000 1 001\000 2 001\002\002\002\001\000 000 002 be a set of items and 003 000 001 003 1 001\003 2 001\002\002\002\001\003 001 002 be a set of transactions where each transaction 003 002 is a set of items such that 003 002 004\000  n itemset 004 has support 005 in the transaction set 003 if 005  f transactions in 003 contain 004  here we denote 005 000 005\006\007\007\b\t 003 001 004 002 An association rule is an implication of the form 004 005 n  where 004\001 n 004 000  and 004 006 n 000 007  Each rule has two measures of value support and confidence  The support of the rule 004 005 n is 005\006\007\007\b\t 003 001 004 b n 002  The confidence 013 of the rule 004 005 n in the transaction set 003 means 013 of transactions in 003 that contain 004 also contain n  which can be written as 005\006\007\007\b\t 003 001 004 b n 002 f\005\006\007\007\b\t 003 001 004 002  For example let r 1 000 001 1 001 3 001 4 002  r 2 000 001 1 001 2 001 3 001 5 002  r 3 000 001 2 001 4 002  r 4 000 001 1 001 2 002  r 5 000 001 1 001 3 001 5 002 be the transaction database Let minimum  support and minimum confidence be 60 and 70 respectively First all itemsets that have support above the minimum support called large itemsets  are generated In this case the large itemsets are 001 1 002 001 001 2 002 001 001 3 002 001 001 1 001 3 002  Then for each large itemset 004  n association rule 004 t n 005 n 001 n 004 004 002 is derived if 005\006\007\007\b\t 003 001 004 002 f\005\006\007\007\b\t 003 001 004 t n 002 n minimum confidence  The results are 1 005 3 001 005\006\007\007\b\t 003 000 60 001 b\016\017 000\020\021\016\013\021 000 75 002 and 3 005 1 001 005\006\007\007\b\t 003 000 60 001 013\b\016\017 000\020\021\016\013\021 000 100 002  The most well known algorithm for association rule mining is the Apriori algorithm[1 We have studied several parallel algorithms for mining association based on Apriori One of these algorithms called HPA Hash Partitioned Apriori is discussed here Apriori first generates candidate itemsets and then scans the transaction database to determine whether each of the candidates satisfies the user specified minimum support and minimum confidence Using these results the next candidate itemsets are generated This continues until no itemset satisfies the minimum support and confidence The most naive parallelization of Apriori would copy the candidates over all the processing node and make each processing node scan the transaction database in parallel Although this works fine when the number of candidates is small enough to fit in the local memory of a single processing node memory space utilization efficiency of this method is very poor For large scale data mining the storage required for the candidates exceeds the available memory space of a processing node This causes memory overflow which results in significant performance degradation due to an excessive amount of extra I/Os HPA partitions the candidate itemsets among the processing nodes using a hash function as in the parallel hash join which eliminates broadcasting of all the transaction data and can reduce the comparison workload significantly Hence HPA works much better than the naive parallelization for large scale data mining The 022 th iteration pass 022  f the algorithm is as follows 1 Generate the candidate itemsets Each processing node generates new candidate itemsets from the large itemsets of the last  001 022 t 1 002 th iteration Each of the former itemsets contains 022 items while each of the latter itemsets contains 001 022 t 1 002 items They are called 022 itemsets and 001 022 t 1 002 itemsets respectively The processing node applies the hash function to each of the candidates to determine the destination node ID If the candidate is for the processing node itself it is inserted into the hash table otherwise it is discarded 13 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


 30 40 50 60 70 80 90 100 110 120 30 40 50 60 70 80 90 10 0 Execution Time [s Number of Nodes Figure 13 Execution time of HPA program pass 2 on PC cluster 2 Scan the transaction database and count the support count Each processing node reads the transaction database from its local disk 000 itemsets are generated from that transaction and the same hash function used in phase 1 s applied to each of them Each of the 000 itemsets is sent to certain processing node according the hash value For the itemsets received from the other nodes and those locally generated whose ID equals the node\220s ID the hash table is searched If hit its support count value is incremented 3 Determine the large itemset After reading all the transaction data each processing node can individually determine whether each candidate 000 itemset satisfy user-specified minimum support or not Each processing node sends large 000 itemsets to the coordinator where all the large 000 itemsets are gathered 4 Check the terminal condition If the large 000 itemsets are empty the algorithm terminates Otherwise the coordinator broadcasts large 000 itemsets to all the processing nodes and the algorithm enters the next iteration 4.2 Performance evaluation of HPA algorithm The HPA program explained above is implemented on our PC cluster Each node of the cluster has a transaction data file on its own hard disk Transaction data is produced using data generation program developed by Agrawal designating some parameters such as the number of transaction the number of different items and so on The produced data is divided by the number of nodes and copied to each node\220s hard disk The parameters used in the evaluation is as follows The number of transaction is 5,000,000 the number of different items is 5000 and minimum support is 0.7 The size of the data is about 400MBytes in total The message block size is set to be 16KBytes according to the results of communication characteristics of PC clusters discussed in previous section The disk I/O block size is 64KBytes which seems to be most suitable value for the system Note that the number of candidate itemset in pass 2 s substantially larger than for the other passes which relatively frequently occurs in association rules mining Therefore we have been careful to parallelize the program effectively especially in pass 2 so that unnecessary itemsets to count should not be generated 14 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


The execution time of the HPA program pass 2 is shown in figure 13 as the number of PCs is changed The maximum number of PCs used in this evaluation is 100 Reasonably good speedup is achieved in this application as the number of PCs is increased 5 Conclusion In this paper we presented performance evaluation of parallel database processing on an ATM connected 100 node PC cluster system The latest PCs enabled us to obtain over 110Mbps throughput in point-to-point communication on a 155Mbps ATM network even with the so-called 217\217heavy\220\220 TCP/IP This greatly helped in developing the system in a short period since we were absorbed in fixing many other problems Massively parallel computers now tend to be used in business applications as well as the conventional scientific computation Two major business applications decision support query processing and data mining were picked up and executed on the PC cluster The query processing environment was built using the results of our previous research the super database computer SDC project Performace evaluation results with a query of the standard TPC-D benchmark showed that our system achieved superior performance especially when transposed file organization was employed As for data mining we developed a parallel algorithm for mining association rules and implemented it on the PC cluster By utilizing aggregate memory of the system efficiently the system showed good speedup characteristics as the number of nodes increased The good price/performance ratio makes PC clusters very attractive and promising for parallel database processing applications All these facts support the effectiveness of the commodity PC based massively parallel database servers Acknowledgment This project is supported by NEDO New Energy and Industrial Technology Development Organization in Japan Hitachi Ltd technically helped us extensively for ATM related issues References  R Agrawal T Imielinski and A Swami Mining association rules between sets of items in large databases In Proceedings of ACM SIGMOD International Conference on Management of Data  pages 207--216 1993  R Agrawal and R Srikant Fast algorithms for mining association rules In Proceedings of International Conference on Very Large Data Bases  1994  A C Arpaci-Dusseau R H Arpaci-Dusseau D E Culler J M Hellerstein and D A Patterson High-performance sorting on Networks of Workstations In Proceedings of International Conference on Management of Data  pages 243--254 1997  D.S Batory On searching transposed files ACM TODS  4\(4 1979  P.A Boncz W Quak and M.L Kersten Monet and its geographical extensions A novel approach to high performance GIS processing In Proceedings of International Conference on Extending Database Technology  pages 147--166 1996 15 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


 R Carter and J Laroco Commodity clusters Performance comparison between PC\220s and workstations In Proceedings of IEEE International Symposium on High Performance Distributed Computing  pages 292--304 1995  D.J DeWitt and J Gray Parallel database systems  The future of high performance database systems Communications of the ACM  35\(6 1992  J Gray editor The Benchmark Handbook for Database and Transaction Processing Systems  Morgan Kaufmann Publishers 2nd edition 1993  J Heinanen Multiprotocol encapsulation over ATM adaptation layer 5 Technical Report RFC1483 1993  M Kitsuregawa M Nakano and M Takagi Query execution for large relations on Functional Disk System In Proceedings of International Conference on Data Engineering  5th pages 159--167 IEEE 1989  M Kitsuregawa and Y Ogawa Bucket Spreading Parallel Hash:A new parallel hash join method with robustness for data skew in Super Database Computer SDC In Proceedings of International Conference on Very Large Data Bases  16th pages 210--221 1990  M Laubach Classical IP and ARP over ATM Technical Report RFC1577 1994  D.A Schneider and D.J DeWitt Tradeoffs in processing complex join queries via hashing in multiprocessor database machines In Proceedings of International Conference on Very Large Data Bases  16th pages 469--480 1990  T Shintani and M Kitsuregawa Hash based parallel algorithms for mining association rules In Proceedings of IEEE International Conference on Parallel and Distributed Information Systems  pages 19--30 1996  T Sterling D Saverese D.J Becker B Fryxell and K Olson Communication overhead for space science applications on the Beowulf parallel workstaion In Proceedings of International Symposium on High Performance Distributed Computing  pages 23--30 1995  T Tamura M Nakamura M Kitsuregawa and Y Ogawa Implementation and performance evaluation of the parallel relational database server SDC-II In Proceedings of International Conference on Parallel Processing  25th pages I--212--I--221 1996  TPC TPC Benchmark 000\001 D Decision Support Standard Specification Revision 1.1 Transaction Processing Performance Council 1995 16 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


In accordance with 1910.97 and 1910.209 warning signs are required in microwave areas For work involving power line carrier systems this work is to be conducted according to requirements for work on energized lines Comments s APPA objects to the absolute requirement implied by the word ensure regarding exposure to microwave radiation and recommends revision of s l iii to read when an employee works in an area where electromagnetic radiation levels could exceed the levels specified in the radiation protection guide the employer shall institute measures designed to protect employees from accidental exposure to radiation levels greater than those permitted by that guide  I1 an employee must be stationed at the remote end of the rodding operation Before moving an energized cable it must be inspected for defects which might lead to a fault To prevent accidents from working on the wrong cable would require identification of the correct cable when multiple cables are present Would prohibit an employee from working in a manhole with an energized cable with a defect that could lead to a fault However if the cable cannot be deenergized while another cable is out employees may enter the manhole but must protect against failure by some means for example using a ballistics blanket wrapped around cable Requires bonding around opening in metal sheath while working on cable Underaround EIectrical Installations t Comments t This paragraph addresses safety for underground vaults and manholes The following requirements are contained in this section Ladders must be used in manholes and vaults greater than four feet deep and climbing on cables and hangers in these vaults is prohibited Equipment used to lower materials and tools in manholes must be capable of supporting the weight and should be checked for defects before use An employee in a manhole must have an attendant in the immediate vicinity with facilities greater than 250 volts energized An employee working alone is permitted to enter briefly for inspection housekeeping taking readings or similar assuming work could be done safely Duct rods must be inserted in the direction presenting the least hazard to employees and APPA recommends that OSHA rewrite section 7\regarding working with defective cables This rewrite would include the words shall be given a thorough inspection and a determination made as to whether they represent a hazard to personnel or representative of an impending fault As in Subsection \(e EEI proposes the addition of wording to cover training of employees in emergency rescue procedures and for providing and maintaining rescue equipment Substations U This paragraph covers work performed in substations and contains the following requirements Requires that enough space be provided around electrical equipment to allow ready and safe access for operation and maintenance of equipment OSHA's position A2-16 


is that this requirement is sufficiently performance oriented to meet the requirements for old installations according to the 1987 NEW Requires draw-out circuit breakers to be inserted and removed while in the open position and that if the design permits the control circuits be rendered inoperative while breakers are being inserted and removed stated in the Rules and requests that existing installations not be required to be modified to meet NESC APPA recommends that Section u 4 i which includes requirements for enclosing electric conductors and equipment to minimize unauthorized access to such equipment be modified to refer to only those areas which are accessible to the public Requires conductive fences around substations to be grounded Power Generation v Addresses guarding of energized parts  Fences screens, partitions or walls This section provides additional requirements and related work practices for power generating plants  Entrances locked or attended Special Conditions w  Warning signs posted  Live parts greater than 150 volts to be guarded or isolated by location or be insulated  Enclosures are to be according to the 1987 NESC Sections llOA and 124A1 and in 1993 NESC  Requires guarding of live parts except during an operation and maintenance function when guards are removed barriers must be installed to prevent employees in the area from contacting exposed live parts Requires employees who do not work regularly at the substation to report their presence Requires information to be communicated to employees during job briefings in accordance with Section \(c of the Rules Comments U APPA and EEI provide comments as follows Both believe that some older substations \(and power plants would not meet NESC as This paragraph proposes special conditions that are encountered during electric power generation, transmission and distribution work including the following Capacitors  Requires individual units in a rack to be short circuited and the rack grounded  Require lines with capacitors connected to be short circuited before being considered deenergized Current transformer secondaries may not be opened while energized and must be bridged if the CT circuit is opened Series street lighting circuits with open circuit voltages greater than 600 volts must be worked in accordance with Section q\or t and the series loop may be opened only after the source transformer is deenergized and isolated or after the loop is bridged to avoid open circuit condition Sufficient artificial light must be provided where insufficient naturals illumination is present to enable employee to work safely A2-17 


US Coast Guard approved personal floatation devices must be supplied and inspected where employees are engaged in work where there is danger of drowning Required employee protection in public work areas to include the following  Warning signs or flags and other traffic control devices  Barricades for additional protection to employees  Barricades around excavated areas  Warning lights at night prominently displayed Lines or equipment which may be sub to backfeed from cogeneration or other sources are to be worked as energized in accordance with the applicable paragraphs of the Rules Comments w APPA submits the following comments regarding this Special Conditions section Recommends that the wording regarding capacitors be modified to include a waiting period for five minutes prior to short circuiting and grounding in accordance with industry standards for discharging of capacitors For series street light circuits, recommends that language be added for bridging to either install a bypass conductor or by placement of grounds so that work occurs between the grounds Recommends modification of the section regarding personal floatation devices to not apply to work sites near fountains decorative ponds swimming pools or other bodies of water on residential and commercial property Definitions x This section of the proposed Rules includes definitions of terms Definitions particularly pertinent to understanding the proposal and which have not previously been included are listed as follows Authorized Employee  an employee to whom the authority and responsibility to perform a specific assignment has been given by the employer who can demonstrate by experience or training the ability to recognize potentially hazardous energy and its potential impact on the work place conditions and who has the knowledge to implement adequate methods and means for the control and isolation of such energy CZearance for Work  Authorization to perform specified work or permission to enter a restricted area Clearance from Hazard  Separation from energized lines or equipment Comments x The following summarizes the changes in some of the definitions which APPA recommends Add to the definition for authorized employee It the authorized employee may be an employee assigned to perform the work or assigned to provide the energy control and isolation function  Recommends that OSHA modify the definition for a line clearance tree trimmer to add the word qualified resulting in the complete designation as a qualified line clearance tree trimmer Recommends that OSHA modify the definition of qualified employee" to remove the word construction from the definition since it is felt that knowledge of construction procedures is beyond the scope of the proposed rule resulting in APPA's new A2-18 I 


wording as follows more knowledgeable in operation and hazards associated with electric power generation transmission and/or distribution equipment Recommends that OSHA add a definition for the word practicable and replace the word feasible with practicable wherever it appears in the proposed regulations and that practicable be further defined as capable of being accomplished by reasonably available and economic means OTHER ISSUES Clothing OSHA requested comments on the advisability of adopting requirements regarding the clothing worn by electric utility industry employees EEI has presented comments which indicates research is underway prior to establishing a standard for clothing to be worn by electric utility employees However EEI's position is that this standard has not developed to the extent that it could be included in the OSHA Rules Both APPA and EEI state that they would support a requirement that employers train employees regarding the proper type of clothing to wear to minimize hazards when working in the vicinity of exposed energized facilities Grandfathering Due to the anticipated cost impact on the utility industry of the proposed Rules requiring that existing installations be brought to the requirements of the proposed Rules both APPA and EEI propose that the final Rules include an omnibus grandfather provision This provision would exempt those selected types of facilities from modification to meet the new rules EEI states that if the grandfathering concept is incorporated that electric utility employees will not be deprived of proper protection They propose that employers be required to provide employees with a level of protection equivalent to that which the standard would require in those instances in which the utility does not choose to modify existing facilities to comply with the final standard Rubber Sleeves OSHA requests comments from the industry on whether it would be advisable to require rubber insulating sleeves when gloves are used on lines or equipment energized at more than a given voltage EEI states its position that utilities should continue to have the option of choosing rubber gloves or gloves and sleeves to protect employees when it is necessary to work closer to energized lines than the distances specified in the clearance tables Preemuting State Laws EEI requests that the final Rules be clear in their preempting state rules applicable to the operation and maintenance work rules for electric power systems. This is especially critical since some states now have existing laws which are more stringent than the proposed OSHA Rules Examples are 1 in California and Pennsylvania where electric utility linemen are prohibited from using rubber gloves to work on lines and equipment energized at more than certain voltages and 2 in California and Connecticut where the live line bare hand method of working on high voltage transmission systems is prohibited One utility Pacific Gas  Electric has obtained a variance from the California OSHA to perform live line bare-hand transmission maintenance work on an experimental basis Coiiflicts Between the Rilles and Part 1926 Subpart V Since many of the work procedures in construction work and operation and maintenance work are similar and difficult to distinguish between EEI requests that the final order be clear in establishing which rule has jurisdiction over such similar work areas A2-19 v 


IMPACTS ON COSTS AND ASSOCIATED BENEFITS In its introduction to the proposed rules OSHA has provided an estimate of the annual cost impact on the electric utility industry for the proposed des of approximately 20.7 million OSHA estimates that compliance with this proposed standard would annually prevent between 24 and 28 fatalities and 2,175 injuries per year The utilities which have responded to this proposed standard through their respective associations have questioned the claims both of the magnitude of the cost involved and the benefit to the industry in preventing fatalities and lost-time injuries Both EEI and APPA feel that the annual cost which OSHA estimates are significantly lower than would be realized in practice Factors which APPA and EEI feel were not properly addressed include the following OSHA has not accurately accounted for cost of potential retroactive impacts including retrofitting and modifying existing installations and equipment OSHA has not consistently implemented performance based provisions in proposed rules  many portions require specific approaches which would require utilities to replace procedures already in place with new procedures Estimates were based on an average size investor-owned utility of 2,800 employees and an average rural cooperative of 56 employees, which are not applicable to many smaller systems such as municipal systems OSHA has not adequately addressed the retraining which would be necessary with modifying long-established industry practices to be in accordance with the OSHA rules EEI claims that OSHA's proposed clearance requirements would not allow the use of established maintenance techniques for maintaining high voltage transmission systems and thus would require new techniques For an example of the cost which is estimated to be experienced as a result of the new Rules one of the EEI member companies has estimated that approximately 20,000 transmission towers would need to be modified to accommodate the required step bolts in the Rules at an estimated cost of 6,200,000 Additionally this same company estimates that the annual cost of retesting live line tools for its estimated 1,000 tools would be 265,000 Additionally, both EEI and APPA question the additional benefits which OSHA claims would result from implementation of the new Rules APPA questions the estimates of preventing an additional 24 to 28 fatalities annually and 2,175 injuries per year in that it fails to account for the fact that the industry has already implemented in large part safety measures which are incorporated in the Rules EEI and APPA also point out that many preventable injuries cannot be eliminated despite work rules enforcement and safety awareness campaigns since many such accidents which result in fatalities are due to employee being trained but not following the employer's training and policies PRESENT STATUS OF RULES According to information received from the OSHA office in February 1993 the final Rules are to be published no later than July 1993 and possibly as soon as March 1993 OSHA closed their receipt of comments in March 1991 and no further changes in the rules are thought possible A2-20 


CONCLUSION The OSHA 1910.269 which proposes to cover electric utility operation and maintenance work rules affects a multitude of working procedures as are summarized in this paper It is not possible at the present time to assess the final structure of the Rules as may be proposed in 1993 or subsequent years Since the comments from the utility associations APPA and EEI were made following the initial release of the proposed OSHA Rules in 1989 a significant amount of time has elapsed where other events have occurred which may affect the form of the final Rules The 1993 NESC went into effect in August 1992 and includes some of the requirements to which the commenters objected For example a significant requirement in the Part 4 of the 1993 NESC requires that rubber gloves be utilized on exposed energized parts of facilities operating at 50 to 300 volts This requirement is in conflict with EEl\222s proposed change to the OSHA Rules which would still allow working such secondary facilities without the use of rubber gloves Electric utilities are advised to review the January 31 1989 proposed operation and maintenance Rules as summarized in this paper and to review their procedures which would be affected by application of the Rules Many of the procedures proposed in the Rules provide valuable guidance in electric utilities\222 operation and maintenance activities Where the cost impact is not significant, it is recommended that utilities consider implementing such procedures in expectation of the Rules being published in the next few months Also it would be appropriate for electric utilities to review the 1993 edition of the NESC since there are portions of the Rules which have resulted in changes in the NESC These changes mainly occur in Part 4 Rules for the Operation of Electric Supply and Communications Lines and Equipment The concerns which the commenters have addressed regarding the cost impact and the resulting benefits experienced as a result of the promulgation of the Rules are real ones and must be addressed in the final Rules As a result this paper cannot present a conclusion regarding the full impact of the Rules The development of such Rules continue to be an ongoing matter and will undoubtedly require later analysis when the final rules are published A2-21 



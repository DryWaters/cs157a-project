An Association Rule Mining based Stock Market Recommender system Preeti Paranjape-Voditel  Dr.Umesh Deshpande Department of Computer Applications    Department of Computer Science and Engineering Shri Ramdeobaba Kamla Nehru Engineering College  Visvesvarayya National Institute of Technology Nagpur, India       Nagpur, India e-mail preetivoditel@gmail.com email uadeshpande@gmail.com   Abstract   We propose an Association Rule Mining \(ARM 
based Recommender system for the stock markets. Normally technical and fundamental analyses are a basis of prediction of stock price. Several systems exist for monitoring and prediction of stock prices. But these deal with individual stocks. They do not give the inter-relationship between stocks or their relationship with the stock market INDEX Our method uses ARM, fuzzy ARM, weighted fuzzy ARM ARM with time lags, fuzzy ARM with time lags and weighted fuzzy ARM with time lags to predict relationships between stocks, which is used as the basis for portfolio management and in recommendations for mutual funds  Keywords - recommender system, fuzzy ARM, time lags, fuzzy 
time lagged ARM, weighted fuzzy ARM, weighted fuzzy timelagged ARM I  I NTRODUCTION  Recommender systems are software applications that aim to support users in their decision making, where large information spaces are concerned. They effectively prune large information spaces and direct the users towards the items that best meet their needs and preferences. Such systems have an obvious appeal in an environment where the amount of on-line information vastly outstrips any individual’s capability to survey it [4 A Recommender system works from a specific type of information filtering system that attempts to recommend items that can of interest to the user. These information 
items can be films, television shows, books, images, web pages, music scores, stocks etc. Typically, a recommender system compares a user profile to some reference characteristics, and seeks to predict the 'rating' that a user would give to an item he had not yet considered. These characteristics may be from the information item \(the content-based approach\ser's social environment the collaborative filtering approach Typical applications of recommender systems are product finders, stock market predictors, shopping guides, etc Ratings are not always provided and that is when item based collaborative filtering of data such as purchase data stock market data, weblog data can be used Stock prices depend on various factors, the important 
ones being the market sentiment, performance of the industry, earning results and projected earnings, takeover or merger, introduction of a new product or introduction of an existing product into new markets, share buy-back announcements of dividends/bonuses, addition or removal from the index and such other factors leading to a positive or negative impact on the share price and the associated volumes Apart from the basic technical and fundamental analysis techniques used in stock market analysis and prediction soft computing methods based on Association Rule Mining, fuzzy logic, neural networks, genetic algorithms etc. are increasingly finding their place in understanding 
and predicting the financial markets Association rule discovery has been used with great success in domains such as market basket analysis but it finds an even wider domain of applications when used in combination with other classification and predictive approaches. We have used Association Rule Mining along with fuzzy classification methods to develop our Recommender system for the stock markets. It can be used for dynamic portfolio management and also in mutual funds The organization of the paper is as follows: Section II deals with the existing work in this domain, Section III describes the Recommender system, Section IV describes the fuzzy association rule generation, Section V deals 
with the weighted fuzzy association rule mining, Section VI describes weighted fuzzy time lagged association rule generation II  EXISTING  WORK  IN  THIS  DOMAIN Statistical methods for individual stocks like the Newton method [10  l o ga r i t h m i c r e gr e t a l go r i t h ms 1 1  e t c  ha ve  been used widely for portfolio management. But they deal with the price and volume of the stocks in calculating the gains or the losses for the portfolio A good amount of work has been done on predicting stock prices for individual stocks In 5], th e F P  
tree based frequent itemset mining to mine intertransaction association rules is used. The number of possible rules are limited using a sliding window. The Fuzzy logic based stock Trading System described in [3  used by the “KOLEGU” mutual fund applies certain constraints based on the fundamentals of the stock and then generates rules/recommendations for buying or selling. [2 s es te m p o r al d a ta m i n i n g to b u ild th e  Intelligent stock market assistant capable of suggesting to buy or sell stocks. It also takes into consideration the risk level, buying price and the need for cash 
2011 Second International Conference on Emerging Applications of Information Technology 978-0-7695-4329-1/11 $26.00 © 2011 IEEE DOI 10.1109/EAIT.2011.90 21 


In our Recommender System, the basic underlying theory is the generation of Association Rules. The Association Rules generated in our system are divided into the following categories: 1\tra-sector 2\ter-sector 3\imelagged 4\uzzy  5\uzzy time-lagged 6\ghted fuzzy 7\eighted fuzzy time-lagged. The Recommender System handles inter-day as well as intra-day associations. The generation of these rules and their role in recommendations will be discussed in the following sections III  DESCRIPTION  OF  THE  RECOMMENDER  SYSTEM The system mines relationships between items or scrips in our case, based on a support- confidence framework The system can be used for portfolio management where we assume an existing portfolio and it has to be managed with alternative replacement for scrips. It does not recommend the scrips in isolation but in relation to the other existing scrips. The objective is to show good returns. The user can input his own portfolio or if a portfolio has to be created, it is done by taking the amount to be invested from the user as input and one scrip from each sector is invested in The transaction files for this system were created by finding out the percentage rise/fall of a certain scrip from its previous trading day’s close. This was done for the 30scrip BSE SENSEX which comprises of the blue chip widely traded companies of the Bombay Stock Exchange Thus a transaction will contain all the scrips which have risen/fallen by more than some minimum amount. The above files were created for data for the past five years B. Generation of the Datasets Our dataset consists of the Bombay Stock Exchange BSE\sitive Index called the SENSEX scrips as the BSE-SENSEX is the barometer of the market behavior in the Indian markets. Also this can be easily extended to the National Stock Exchange \(NSE\ scrips The source of price-volume data is taken from the official End-Of-Day \(EOD\ Quotes for BSE India Stocks and Indices. It contains the BSE SENSEX information like the daily opening and closing price associated with the volume. From this data our dataset has been created. Each transaction in this dataset consists of all those scrips which have risen by a particular percentage over the previous close. This parameter can be defined by the user or by default this value is taken between 1 and 2% by our algorithm depending upon the type of dataset to be generated Stock markets, in India or in other countries, can be divided into sectors and the inter-sector and intra-sector relationships can be found. We have divided the SENSEX scrips into seven sectors according to their area of operation and also according to their weightage in the SENSEX as shown in Table1. The Inter-sector relationships between them help in understanding as to which sectors are independent of each other and which sectors have a precedent-antecedent relationship in terms of price rise/fall. In the Recommender system, if a sector scrip exists in the portfolio and the sector faces a slump, a negatively correlated scrip can be included. If a sector performs phenomenally well, more positively correlated scrips from that sector can be included SEC NO SCRIPS IN THE SECTOR SECTO R APPROXIMATE WEIGHTS AS PER SENSEX 1 ACC, BHEL DLF, Jaiprakash Ind,L&T, Tata Steel Cement Engineering Construction Steel 0.7+4.43+2.02+1.2 3+3.71+2.18=14.27  2 ONGC, Reliance Oi l 8.61+13.65=29.31 3 NTPC,  Rel.Infra Sterlite, Tata Power Power Metals 0.88+2.64+1.23=4 75 4 Bharti Airtel Infosys, Rel.Comm TCS, Wipro Telecom Computers 4.51+6.06+1.32+6 12+4.06=22.07 5 Grasim, HDFC HDFC Bank, ICICI Bank, SBI Diversifi ed, Finance Banks 1.01+2.94+3.15+4 05+4.98=16.13 6 Hero Honda M&M, Maruti Suzuki Tata Motors Auto  1.5+1.14+1.57+1.6 2=5.83 7 HUL ITC, Sun Pharma Personal Care Cigarettes 1.93+3.78+1.34=7 05 Table 1: Sectors with approximate weights in the SENSEX  The scrips of relevance can be generated from the database by finding the frequent itemsets and then discovering the rules for all itemsets above some minimum support threshold. We have used Dynamic Itemset Counting \(DIC e n e rating t h e f r equ e nt itemsets C. Generation of Association Rules The association rules between scrips are positively or negatively correlated. These rules recommend to buy stock2 if stock1 is bought, if stock1 and stock2 exhibit positive correlation. If a negative correlation exists between them a rise in stock1 can trigger a sell stock2 The same rules can be applied for intra-sector and intersector recommendations. In each sector, we have companies operating in similar areas: for example in cement, construction, Engineering and steel. They may operate in the same market and a rise in the market share of one may adversely affect the market share of the other In other circumstances some scrips may show a positive correlation and may rise together as a result of some news positively affecting the entire sector. Similar would be the case for inter-sector association rules The association rules so generated have been mined in different support and confidence frameworks Examples of Association rules generated are For support greater than 20% and confidence greater than 90 92.592590  :  incr HDFC ^  incr Rel Infra ^ incr Rel  Comm  ----> incr ICICI Bank 
22 


92.592590:decr BHEL ^ decr HDFCBank---->decr     ICICI Bank 93.589745:decr power,metals ^ decr cement, engineering construction,steel---->decr  diversified , Finance, Banks  For support greater than 30% and confidence greater than 60 Intra-sector rules 89.705879  : decr HDFC Bank ^ decr SBI ----> decr ICICI Bank 64.000000  : decr Rel Infra   ----> incr Hindalco  Inter-sector rules 100.000000 : decr power,metals  ----> decr cement engineering,  construction, steel  100.000000  : incr Oil ^  incr power,metals----> incr cement,engineering, construction, steel  87.012985  :  decr Oil ^ decr Telecom,computers  ----> decr Cement engineering, construction,    steel   86.826347 :decr Telecom,computers ^  decr diversified,Finance,Banks--->decr cement,engineering, construction, steel   These rules are generated which are transformed into buy or sell recommendations  D. Generation of rules with time lags We define a lag as that time after which we calculate the percentage of rise or fall for a particular scrip. This time can be the number of trading days, weeks or months. In our case we represent lag as the number of trading days There are certain patterns which may not be detected in transactions created on the basis of closing prices of each consecutive day. These patterns are such that they are observed after a particular time lag. Here lag refers to the number of days that have elapsed between the two closing prices. The rules that we have generated above are lag=1 rules.  Rules which are observed with a lag greater than 1 like a steady rise/fall, are missed out in these set of rules For example a steadily rising stock may rise 0.1-0.3 everyday and may show an increase of 1% after five days Hence if we calculate the percentage rise on every fifth day this stock will be included in the dataset For example two stocks can follow a pattern such that if stock1 rises on day1 then stock 2 follows stock1 on day3 with support and confidence greater than the threshold. So we say that stock2 follows stock1 with lag=3 To find these rules, frequent itemsets on the different lag datasets are found. Rules are generated on the individual frequent itemsets and only the strongest rules are chosen The days on which the strongest rules occur gives the time lag for that particular rule. That is we have rules of the form If time lag =3, decr SBI --- > incr ACC If time lag =4, incr HDFC^incr Rel Infra ---- >decr BHEL These rules will not be observed otherwise while considering the transactions on a day to day basis IV  FUZZY  ASSOCIATION  RULE  GENERATION Fuzzy Association Rule Mining \(FARM\s intended to address the crisp boundary problem encountered in traditional ARM Due to the crisp boundaries, some items on the boundary are missed out though they contribute significantly to relevant rules. FARM takes care of these items and reflects their contribution in the rules generated A  Creation of the fuzzy database In the earlier creation of the database a crisp boundary dictated the inclusion of an item in a transaction i.e if a scrip rose/fell by a particular amount it qualified to be included as an item in a transaction. But in the fuzzy database each item consists of a scrip with its membership value. The membership value lies between 0 and 1. A scrip is included as an item if it has risen/fallen by a value between a range of values. So an item in a fuzzy database is of the form <N,M>, where N is the scrip id and M is the membership function There can be various membership functions. For example let us consider the following fuzzy membership function for inclusion in the transact ion database we considered earlier M   =  1.0 for rise/fall >=2 0.8 for 1.8 <= rise/fall  <2 0.6  for 1.6 <=rise/fall <1.8 0.5  for 1.4 <=rise/fall <1.6 0.2  for 1.2 <=rise/fall <1.4 0.1 for 1.0<= rise/fall <1.2 0.0  for rise/fall <1.0 So each item in the fuzzy database is of the form <a, 0.5 b, 1.0> etc. where a, b correspond to the scrips and 0.5 1.0 are their membership values B  SUPPORT CALCULATION The support for a 1-itemset is simply the sum of the membership degree values  divided by the number of records in the database. The support for an n-itemset, for each record containing the itemset, is the sum of the products of the membership degree values in each record Thus for example if we have database records of the form c, 1.0 a,0.5> <b,0.5 a,0.5> <c, 0.5 a,0.5> <b, 0.5 The calculated support values will be a} = 0.375 c} = 0.375 a c} = 0.0625 b}=0.25 a b}=0.125 Therefore after the calculation of support for each item we can calculate the association rules by the earlier method itself The objective of fuzzy sets is that it discovers many hidden rules in transactions because fundamentally strong scrips show a gradual rise which is not captured in the crisp boundary support calculation as opposed t speculative scrips C  FUZZY TIME LAGGED ASSOCIATION RULES In crisp time-lagged association rules, the problem of some rules being missed out remains. This problem to some extent is minimized with the help of fuzzy time 
23 


lagged association rules. Here the time-lagged dataset is calculated in a similar manner as for the crisp dataset but the inclusion in the dataset is defined by the fuzzy function as also the support calculation. These give the additional rules not captured earlier V  WEIGHTED  FUZZY  ASSOCIATION  RULE  GENERATION The large number of frequent itemsets and association rules generated can be pruned using We have used weighted fuzzy association rule mining for assigning the weights to the 30 SENSEX scrips. These weights are assigned to determine the value of the SENSEX with rise/fall in particular scrips These weighted fuzzy datasets help in finding intertransaction association rules, inter-transaction association rules and also for predicting the value of the SENSEX as some scrips/sectors are more heavily weighted in the SENSEX than the others The fuzzy dataset created, as explained earlier, is associated with the weighting file A  SUPPORT CALCULATION For single itemsets, the support is the sum of the product calculation for each weighting/fuzzy membership pair For 2-itemsets and larger the support is the sum of the products of all the weightings and fuzzy membership calculations If data is as follows c, 1.0 a,0.25> <b,0.5 a,0.5> <c, 0.75 a,0.5> <b, 0.25> and the associated weighting file is 0.2 1.0 0.3 The support calculations would be as follows a} = \(\(0.25*0.2\ +\(0.5*0.2\ +\(0.5*0.2\\/4 = 0.0625 Similarly b}=0.1875 c}=0.13125 a,b}=\(\(0.25*0.2*0.5*1.0\+\(0.5*0.2*0.25*1.0\\/4=0.0125 Similarly a,c}=0.005625  B  WEIGHTED FUZZY TIME-LAGGED ASSOCIATION RULE GENERATION The creation of the dataset is similar. These weighed rules help in associating the rise/fall in the SENSEX with the time lags as these weights represent the approximate weights in the SENSEX VI  IMPLEMENTATION  OF  THE  RECOMMENDER  SYSTEM We assume that a portfolio has to be managed with the obvious intention of making a profit. The portfolio can already contain scrips which can be replaced and the portfolio restructured or the portfolio can be created by initializing it with the scrips from different sectors Then a time frame for monitoring is fixed. After periodic intervals association rules are generated and loss making stocks can be replaced by corresponding negatively correlated rising stocks of the same amount. The same is applicable to mutual funds Also inter-sector rules can help to switch sectors, if some sectors are expected to perform better than the others  Future direction of work The above techniques can be extended to generate predictive rules for intra-day trading and can help in recommending related stocks on an intra-day basis for trading Stream mining can be used to generate frequent itemsets and rules to trigger rules on an intra-day basis for recommendation. These rules can be new or those which are already existent. We have used the space saving algorithm using sliding windows to generate these frequent itemsets but have not generated the rules on the stream data  References  1  S.Brin, R., J Ullman, Shalom Tsur,”Dyanamic Itemset Counting and Implicaton Rules for Market Basket data”, SIGMOD Record volume 6, no 2, pages 255-264, June 1997 2  G. Marketos, K. Pediaditakis, Y. Theodoridis, B. Theodoulidis Intelligent Stock Market Assistant using Temporal Data Mining Proc. 10th Panhellenic Conference in Informatics PCI'05 Volos Greece, November 2005 3  Ashish Mangalampalli, Vikram Pudi “Fuzzy Association Rule Minng Algrithm for Fast and Efficient Performance on Very Large Datasets 4  P.Velvadivu and Dr. K.Duraisamy,”An Optimized Weighted Association Rule Mining on Dynamic Content”, IJCSI International Journal of Computer Science Issues, Vol 7, Issue 2 No.5, March 2010 5  Hitesh Chhinkaniwala, P.Santhi Thilagam, “InterTARM:FP-Treee based framework for mning Inter-Transaction associaton Rules from stock market data”, Internatonal Conference On Computer Science and Information Technology, 2008 6  Mark Grinblatt, Tobias Moskowitz “Predicting stock Price movements from past returns : The role of Consistency and TaxLoss Selling”, Journal of Financial Economics,71 \(2004\-579 7  K.Senthamarai Kannan, P.Sailpathi Sekhar, M.Mohamad Sathik,P.Arumugam, “Financial Stock Market Forecast Using Data Mining Techniques”, IMECS 2010, March 17-19, 2010, Hong Kong 8  Hameed Al-Qaheri, Aboul Ella Hassanien  and Ajith Abraham“Discovering Stock Price Prediction Rules using Rough Sets 9  Benjamin Wah, Minglun Qian, “Constrained formulations and algorithms for stock-price predictions using recurrent FIR neural networks”,Eighteenth National Conference on Artificial Intelligence, Edmonton, Canada, 211-216, 2002    Amit Agarwal, Elad Hazan, Satyen Kale, Robert E. Scapire Algorithms for Portfolio Management based on the Newton Method”, Proceedings of the 23 rd International Conference on Machine Learning, Pittsburgh, PA, 2006    Hazan . E, Kalai. A, Kale S  Agrawal A, “Logarithmic regret algorithms for online convex optimization”, 19 th Annual Conference on Learning Theory \(COLT\, 2006 
24 


cut to become a group of relatively small fragments of integrity. Based on this ch aracteristic,  in the general file system design document subparagraph \(File Stripping\ and file cache distributed storage strategy. Sub-media files will be stored on multiple servers can improve overall system performance, easier to achieve the various storage load balancing between nodes u ch as Fi gure 2 System of certain docume nts frequent high level visits, which is far greater than some of the other. Of all the server systems to save copies of all the documents is a simple, wo rkable solution, it is clear that the larger overhead, the pr ogram for the visit to the probability of a number of relatively small document is a waste of resources. To this end, the design of a redundancy document st orage strategy 1.x Through the above-mentioned data mining [7 a  result, it is not difficult to analyze statistics and are frequently accessed files. Based paper was the number of visits per hour for the frequency of visits recorded for the frequency of visits then if the larg er, is illustrated in these documents is to visit "hot spots" can be copied to mu ltiple servers. According to the frequency of visits to adjust the location of documents, making each server is basically the same value. This will not app ear on a server to store all the files are often visited, an d other servers on the file access probability are smaller. Monitor regularly get each server load, if we find that the value of comparison between the differences in wealth will start a process of adjusting the distribution of documents. For performance considerations, such adjustment can not in real time i f N i 1 i File _ N i i f 1 i f i f  EXPERIMENTAL AND TESTING   First of all, describe the experimental environment, a number of data files were ra ndomly distributed in more than one server, the documents themselves in terms of logic there is no correlation. In order to closer to the real application environment, using about 3-5M compressed audio files stored on each server 100 Using Python language write multi-threaded server program. The main process are responsible for monitoring the request, if a re quest arrived, then start a new thread for a subset of services, continue to monitor the main process. Services sub-threads through the link to read the overall table and buffer table documents on request information and the current server status information, and then give a response in accordance with the algorithm The client can be taken two ways to simulate the real visit farmers. One is by reading a document linked to triple, to be a need to access the documents, as well as the probability of the vis it. Subsequently, the client through a random proces s to the probability of access to files to the probability ij p  ij p j f 1  of random access a file. Another way what access to the real record of real farmer, to reproduce in the experiment, so as to achieve the purpose of the visit simulation farmers  5.1 ASSOCIATED DATA STRUCTURE  Triples visit to describe the current list of documents most likely continue to visit the next visit to the transfer of documents and its probability. Such linkages in the real environment will be to get through data mining and production, in other words, the purpose of data mining and the result is to generate and update the list of triples      ij j i p f f Am ong them is the representative of the current vi sit of the document is on behalf of most likely to vi sit a paper document is on behalf of the visit  followed the probability of accessing files Table 3 bel ow shows an example i f j f p ij i f j f File i File j Pij File_SVR_01_01 File_SVR_02_01 0.8 File_SVR_01_02 File_SVR_02_02 0.7 File_SVR_01_03 File_SVR_02_03 0.6  Table 3 File association Triples    
325 


5.2  B UFFER POOL DATA STRUCTURE  In order to more effectively manage the buffer zone we need to know what documents have been read into the buffer zone, the proportion of these documents and whether space is being used, such as basic information The definition of the following data structure used to describe the use of the buffer zone Algorithm 2 buffer class definition START class BufferPool def __init__ \(self  self.lock  threading.Lock   Mutex Semaphore self.pool  buffe r pool  def addToBuffer \(self, file\d into the buffer content self.lock.acquire \(\# critical region began  bufferBlock = \( 'name': filename, 'size': size, 'bytes bytes,' reference ': 0 File name, buffer size, the contents of the documents, citing a number of  self.lock.release \(\# end of critical region def readFromBuffer \(filename\ove the buffer content def isInBuffer \(filename\determine the file exists in the buffer zone END Each file is read into the buffer zone after which a new Buffer Block, in accordance with the above approach to the basic information into a buffer with Ikegami added. When the file is accessed by traversing the entire sequence can be informed of whether the document had been read into the buffer zone also need to modify the number of f iles, record the number of requests are visiting. Above modification and maintenance process between the mutually exclusive in order to control complicate d, we should introduce a semaphore mechanism, making all the modifications to the list of operations to keep pace 5.3  A NALYSIS OF EXPERIMENTAL RESULTS  Local tests, trials in this group, the client is located in a number of random requests for files on local disk the client records from the re quest sent to a file to receive the end of time interval. Tests were carried out twice, the first is not to take any strategy,  the second test is in the deployment of these strategies carried out by the server. Client, resp ectively, simulated 10 threads 20 threads, 30 threads, 40 threads and 50 concurrent threads on the circumstances. Abscissa in Figure 3 that the number of simultaneous threads, t hread-ordinate that the average response time. At the top of the curve is the first test results, the bottom of the curve is the result of the second test   Figure 3 results contrast map   From the data that the visit has not been preprocessing the request, with the concurrent degree of improvement in performance is obvious; and after a visit to the request of the forecast, the performance improved significantly 512M memory in a server network bottlenecks in the neglected cases, at the same time can support more than 20 concurrent requests, the numerical main memory size limit The next test of this group is in a real network environment, the client in accordance with the mining algorithm to sim u late the res u lts obtained acces s and the results compared with the random test algorithm. In this exper iment, the client simulated multicast mechanism, by reading a list of servers, each server to request the corresponding port. In practice this will be multicast protocols and multicast routers to achieve. Taking into account the request packet size compared with the response for the message can be ignored, so that the alternativ e test results will not be a visible impact. Experimental specific steps are below such as algorithm 3 3 Simulation Algorithm Client Access Step 1 client read associated ternary group, read the file list at the same time Step 2 program were randomly selected from a list of files in the document as a starting point to visit, a request to all servers Step 3 Process will read the list of associated tuples corresponding value, through a random process to the probability of visit tuples na med in a docu ment to the probability of random access a file Step 4 Repeat the process until the time they reach the required value, the end of the visit Figure 4 2 Gaussian curve representing the strategies mentioned in this article and random strategy to respond to the mean and variance, abscissa on behalf of the average probability density longitudinal coordinates  
326 


From the results can be seen that the dotted line without pretreatment client re sponse time, the mean is seconds  2.9254 1 variance is 1.2329 1  Solid line on behalf of a result of these algorithms to deal with the response time, the mean is seconds  2.5654 2 variance is 0.9690 2    Figure 4 based on the local multi-threaded concurrent access comparison   C ONCLUSION  The user needs is input Appl et through to the system Applet user to user demand Agent. Agent users in the analysis of the needs of users after the creation of data mining Agent for the task. Acco rding to the data mining tasks, moved to the local mach ine on data mining. In its move to the local machine, its management to create a local Agent to manage their own local registration, such as files data mining Agent migration in the local machine the local management of Agent will be removed. Data Mining Agent in accordance with the needs of the database data to a database of local Agent to issue requests for data, a database of local Agent, upon request, to query the database data, and return to the Data Mining Agen t. Data Mining Agent in the completion of the mission, the transfer request back-end data mining, the results will be re ported to the User Agent, User Agent that will result is a document or data sent to the formation of Applet chart shows  V  C ONCLUSION  Through all these experimental results and analysis, we can be seen after pretreatment of server response time curve given the mean and variance in the relatively small area. This article mentioned that the application of this strategy in response to the server speed and stability have improved larger Load balancing problem is th e building of agricultural information of one of the major problems in the research and analysis of the current popular ity of a variety of static and dynamic balance algorithm da ta mining-based load balancing method of thinking The use of historical records of the visit of the data mining results, so that the server has the ability to forecast the upcoming visit and make pretreatment. Papers on data mining methods and load balancing strategies were described and analyzed on the basis of tests and experiments, and achieved better results Of course, many cities in between the data access and synchronization will be implemented in specific operations also need to supplement the current strategy and modification A CKNOWLEDGMENT  In this paper, Anhui Province by the Office of Education Youth Education Fund, the subject of scientific research 2005jq1053\e corresponding author is Mei shen-xin R EFERENCES   Zhu Yongzhi. H e terogeneous Beo w ulf sy stem load balancing technology Research and Implementation. ,2008,7:60 Computer technology and development-62  h m for the practi ce of [M]. Beijing Higher Education Press, 2004   A high perform ance portable im ple m entation o f the m e ssage  l el Co m puting, 1996,22 \(6 828  mm i ng C, MPI and Ope n MP [M]. Beijin g Tsinghua University Press, 2005  W a ng Gang W a ng this y e ar  FNN and GAbased integr ation of data mining method. Computer technology and development ,2008,2:119125  i H Fukuda T, Shibata T et a1. Structure optim ization of Fuzzy Neural Network by Genetic Algorithm y Set s and Syste m s 1995,71 \(3\ :257-264  identification of sy stem s and its applications to modeling and cont rol on Systems, Man and Cybernetics, 1985,15 \(1\: l16-132   Li Yan g   hi gh Z h e n g g u an g L o r d Nic hol ls o f Birke n h ea d and inflammation. Based on neural networks and genetic algorithm data mining architecture Computer Engineering, 2004,30 \(6\55-15  
327 


 2173 


   2  6   &1   2   1      F  2 1 2  2                 6 


2  2  2 2  3   1       2 1              1  2   A 1 2  2 18- G        


f  3    2       6   1    2  2       2 2010 International Conference on Optoelectronics and Image Processing 978-0-7695-4252-2/10 $26.00  2010 IEEE DOI 10.1109/ICOIP.2010.250 251  2E  2  1     2   1   


     2 1  2  2     1  2      6     2 1 AA=A=H=A=A= \b\b !!\b   b\b HAA=A==HAA=A==\b !!\b \b  b\b HAA=A==HA=A= !! \b 1  2 b\b HAA=A==HA=A= !! \b b 2   1     


1    2   b\b HAA=A==HA=A= !!" \b b I  2 I#  2      1  2 b       2    2  18  C        6  2  


  1     D     1    2  f 9  2      2    6E    12    1    2 1&8   2   


  1 2      2   2    1      8  2        2 2   2 1       


  2   2 2   D                                


 7 .2     1    f    f      b b A b A b    2    2  2   1 1 2  81   


  18       6   G  6    1    6     0 1  1      1 1   6 


 2 \f 3%\f  f  f  f\b     2     2 1                 6    1  


   2    D    f 3\f             2           8 2   1 #-4 


     8 1        18    E 1  1          1   2   2 2 2      


        b b A252  b             8                


2        9    8         2 0     6  1      8 2  2  


 8   2  3\f            8  D    F  \b 1 8 & #J      b 1  1  4    2  


4 1    9  E 1  2 4 1    9 1   4      8 2  8 1  D 1        1 1  b 


     b b b b b  K            8          2 D 9   F  \b 1 8 ,+J  9 


     b 1     1 2  9 1  12 L 1   9  8       1  2      2   


     b b b b b  K            2  0 \b f  b\f      9       


  8 2   E 1   1     M13 31L 1    b  8E 1   1 #3\b?### 1  1     E 1   1 \b?###3        


1   1   b 1  2 2 18 2     8              1    2 \b 1    2  


    2          2   1 L 2 1   1   L 2 2    2 1  2        


    8  2H D \b A             2  2H D \b A 2 \f 3%\f  f   4%\f f !  , \f\b  C    2    2 


 6    3 1      253 6   1 L 2    6   1         f\b3\f       


               1     1     8 2    E       2  1   


     2 8    b 4      1 8             1 2     1  8 2  


1 9    8      2 1       1     2    8    2 3\f        


     8 D 4 9  F  \b 1 8 #J 9 1     2 1   2 #-@ 1   2 9  E 1   1   2 9      6  


    8  8   1  D 1         1 F  \b0         2 D    F  \b 1 8  9  


  1 9  1   E 1  2 9     1 1 F  \b       1    18   F   1    1 #-$+  \b  2 2  


1 D     1 #-$+.B- 0/:% .0             9 1      18    1 6     1 2  1  1  


1   6      2    1 2 E 8 D 1      1 2   1   1 #-4  #-@E     2  1  1  1       


 8     1          2 F    6   F  2   8    2 C<CC/C N\bO 5      


CD    b$44NO F P Q 6   2 b$$$ ,=\b\bA  A N,O 2 C C  b$$4N  92 2   f  9-\b$$4 B N?O  !-    91  2 1 HH111-18-N+O    -1 :3%   2     0-4 


     b N4O 2   2- \f  C b$@$ \b# >\b\b$3\b$N@O  f :.% 9 /9 \f    1  6  f 2  4   A254 


Advantages of Our M ethod Advantages of Our M ethod Exploit the memory v ertical data format utilizes slidin g windows to g form a much larger database to analyze  Flexibility in Choosing what to choose  Choosing what to choose to build the rules Computational and memory efficiency We have a team working only on this aspect 45 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 45 


Preliminary Results Intra transaction Relations Data rate simulator NH-134 Mb HOP PATH update \(Y/N Inference 11.5 Y Y 2 0.120 N N      Y   n 0.345 N NH134 Y/N   Inf 1 0.150 N N 2 0 120 Y N Inter transaction Relations 2 0  120 Y N       5 5.55 0.456 Y Relations  n 0.345 N N Nmap on DMRL nmap.org 


Anticipated Outcome Anticipated Outcome Develop algorithm capable of learning from a given heterogeneous diverse Develop algorithm capable of learning from a given heterogeneous diverse data ff Dynamic algorithmic f ramework designed to shi f t modalities and sampling rates based on complex logic Flexibility of integration into the Snort intrusion detection system 47 Associative IDS for NextGen Frameworks Dr S Dua LA Tech 47 


References References Aircraft Cockpit Image courtesy USAF http://www.faa.gov htt p   www.faa g ov  air traffic  technolo gy  p g  _ gy  Acharya R Dua S Du X Sree V Chua C K Automated Diagnosis of Glaucoma Using Texture and Higher Order Spectra Features To appear in IEEE Transactions on Information Technology in Biomedicine  Du X Dua S 2011 Cancer Prognosis Using Support Vector Regression in Imaging  Modality World Journal of Clinical Oncology 2  1   44 49 Du X Dua S 2010 Salient Frame Extraction Using Support Vector Regression and Motion Features pp 5 Proc of the National Aerospace and Electronics Conference July 14 16 2010 D M P D S 2010 Di i i ti Ft d Cl ifi ti Mthd f D essaue r  M  P  D ua S  2010  Di scr i m i na ti ve F ea t ures an d Cl ass ifi ca ti on M e th o d s f or Accurate Classification 1st ed vol 7704 pp 14 Bellingham WA Proceedings of SPIE Dessauer M P Dua S 2010 Low Resolution Vehicle Tracking using Dense and Reduced Local Gradient Features Maps 1st ed vol 7694 pp 8 Bellingham WA Proceedings of SPIE SPIE 


Acknowledgements Acknowledgements Fundin g A g encies  US 4 1 Million direct fundin g g g 4 g LA BoR NIH NSF AFRL AFOSR and NASA Research Team Samuel Kasimalla Brandy McKnight Dr Pradeep Chowriappa Connor Johnson Vasanth Nair Mihir Chowriappa  Connor Johnson  Vasanth Nair  Mihir Karnik Mohit Jain and Swadheen Songmen Associative IDS for NextGen Frameworks Dr S Dua LA Tech 49 All the respective Logos belong to their owners 


Rf d Rdi R e f erence d R ea di ngs Copyright of cover pages held by respective publishers 


Thank You Questions Thank You  Questions Dr Sumeet Dua E mail sdua@latech.edu Web http://dmrl.latech.edu Associative IDS for NextGen Frameworks Frameworks Dr S Dua LA Tech 51 Image Source roadtrafficsigns.com 



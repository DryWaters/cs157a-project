Parallel Mining of Association Rules from Text Databases on a Cluster of Workstations John D Holt and Soon M Chung  Dept of Computer Science and Engineering Wright State University Dayton Ohio 45435 USA Abstract In this paper we propose a new algorithm named Parallel Multipass with Inverted Hashing and Pruning PMIHP for mining association rules between words in text databases The characteristics of text databases are quite different from those of retail transaction databases and existing mining algorithms cannot handle text databases efﬁciently because of the large number of itemsets i.e sets of words that 
need to be counted The new PMIHP algorithm is a parallel version of our Multipass with Inverted Hashing and Pruning MIHP algorithm 13 whi c h w as s h o w n t o b e quite efﬁcient than other existing algorithms in the context of mining text databases The PMIHP algorithm reduces the overhead of communication between miners running on different processors because they are mining local databases asynchronously and prune the global candidates by using the Inverted Hashing and Pruning technique Compared with the well-known Count Distribution algorithm 2 PMIHP demons trates s uperior performance character istics for mining association rules in large text databases 
and when the minimum support level is low its speedup is superlinear as the number of processors increases These experiments were performed on a cluster of Linux workstations using a collection of Wall Street Journal articles Key words Parallel association rule mining text retrieval multipass inverted hashing and pruning cluster computing scalability 1 Introduction Mining association rules in transaction databases has been demonstrated to be useful and technically feasible in several application areas 3 p a rticu larly i n r etail sales Let  
This research was supported in part by LexisNexis NCR and Wright Brothers Institute WBI I   i 1 i 2 i m  be a set of items Let D beaset of transactions where each transaction T contains a set of items An association rule is an implication of the form X  Y where X I  Y I and X  Y   The association rule X  Y holds in the database D 
with conìdence c if c  of transactions in D that contain X also contain Y  The association rule X  Y has support s if s of transactions in D contain X  Y  Mining association rules is to nd all association rules that have support and conﬁdence greater than or equal to the user-speciﬁed minimum support called minsup  and minimum conﬁdence called minconf  respectively 1 F o r e xample beer and dis pos able diapers are items and 
beer  diapers is an association rule mined from the database if the co-occurrence rate of beer and disposable diapers in the same transaction is not less than minsup and the occurrence rate of diapers in the transactions containing beer is not less than minconf  The rst step in the discovery of association rules is to nd each set of items called itemset  that have cooccurrence rate above the minimum support An itemset with at least the minimum support is called a large itemset or a frequent itemset  In this paper the term frequent 
itemset will be used The size of an itemset represents the number of items contained in the itemset and an itemset containing k items will be called a k itemset For example  beer diapers  can be a frequent 2-itemset Finding all frequent itemsets is a very resource consuming task and has received a considerable amount of research effort in recent years The second step of forming the association rules from the frequent itemsets is straightforward as described in 1 F o r e v e ry frequent i t e ms et f  nd all non-empty subsets of f  For every such subset a  generate a rule of the 
form a   f  a  if the ratio of support f  to support a s at least minconf  The association rules mined from point-of-sale POS transaction databases can be used to predict the purchase behavior of customers In the case of text databases there are several uses of mined association rules between sets of words They can be used for building a statistical thesaurus 0-7695-2132-0/04/$17.00 \(C Proceedings of the 18th International Parallel and Distributed Processing Symposium \(IPDPSê04 


Consider the case that we have an association rule B  C  where B and C are words A search for documents containing C can be expanded by including B  This expansion will allow for nding documents using C that do not contain C as a term A closely related use is Latent Semantic Indexing where documents are considered close to each other if they share a sufﬁcient number of associations 9 Latent Semantic Indexing can be used to retrieve documents that do not have any terms in common with the original text search expression by adding documents to the query result set that are close to the documents in the original query result set Frequent itemsets mined from a text database may be useful in the task of document ranking The word frequency distribution of a text database can be very different from the item frequency distribution of a sales transaction database Additionally the number of unique words in a text database is signiﬁcantly larger than the number of unique items in a transaction database Finally the number of unique words in a typical document is much larger than the number of unique items in a transaction These differences make the existing algorithms such as Apriori 1 Di rect Has h i n g a nd P r uni ng DHP   14  a nd FP-Growth 10  i n e f f ecti v e in m i n i n g asso ciatio n r u l es in the text databases Considering the large number of candidate itemsets to be processed from very large text databases parallel association rule mining is quite essential In this paper we propose a new parallel association rule mining algorithm named Parallel Multipass with Inverted Hashing and Pruning PMIHP PMIHP is a parallel version of our sequential Multipass with Inverted Hashing and Pruning MIHP algorithm 13 whi c h w as s h o w n t o b e e f f ect i v e f or mi ni ng association rules in text databases especially when the minimum support level is low We implemented the proposed PMIHP on a cluster of Linux workstations and analyzed its performance using a collection of Wall Street Journal articles in the 1996 Text Research Collection TREC 16  The ne w algorithm demonstrates a superlinear speedup as the number of processors increases when the minimum support level is low PMIHP is also shown to be much faster than the Count Distribution algorithm 2  w h i ch is a p arallel v e rsio n o f t h e Apriori algorithm 2 Parallel Multipass with Inverted Hashing and Pruning PMIHP Algorithm The new Parallel Multipass with Inverted Hashing and Pruning PMIHP algorithm is a parallel version of the sequential Multipass with Inverted Hashing and Pruning MIHP algorithm The MIHP algorithm is based on the Multipass approach 11 an d t h e In v e rted Hash in g a n d Pruning IHP 12 t hat w e propos ed In PMIHP the Multipass approach reduces the required memory space at each processor by partitioning the frequent items and processing each partition separately Thus the number of candidate itemsets to be processed is limited at each instance The Inverted Hashing and Pruning is used to prune the local and global candidate itemsets at each processing node and it also allows each processing node to determine the other peer processing nodes to poll in order to collect the local support counts of each global candidate itemset The Multipass approach and the Inverted Hashing and Pruning are described in Section 2.1 and Section 2.2 respectively and the pseudo-code of the sequential MIHP algorithm is given in Section 2.3 2.1 Multipass Approach The Multipass algorithm partitions the frequent items and thus partition the candidate itemsets The partition size is selected to be small enough to t in the available memory of the processing node Each partition is then processed separately Each partition of items contains a fraction of the set of all items in the database so that the memory space required for counting the occurrences of the sets of items within a partition will be much less than the case of counting the occurrences of the sets of all the items in the database The Apriori algorithm 1 i s modi  e d t o b e t he Multipass-Apriori algorithm as follows 1 Count the occurrences of each item in the database to nd the frequent 1-itemsets 2 Partition the frequent 1-itemsets into p partitions P 1 P 2 P p  3 Use Apriori algorithm to nd all the frequent itemsets whose member items are in each partition in the order of P p P p  1 P 1  by scanning the database When partition P p is processed we can nd all the frequent itemsets whose member items are in P p  When the next partition P p  1 is processed we can nd all the frequent itemsets whose member items are in P p  1 and P p  This is because when P p  1 is processed the items in P p  1 are extended with the frequent itemsets we found from P p and then counted This procedure is continued until P 1 is processed Assume without loss of generality that the frequent 1itemsets or simply items are ordered lexically The frequent items are partitioned into p partitions P 1 P 2 P p  such that for every i<j  every item a  P i is less than every item b  P j  Thus the itemsets under consideration for some partition P i have a particular range of item preﬁxes Notice that if the partitions have the same number of items the potential number of itemsets that will be 0-7695-2132-0/04/$17.00 \(C Proceedings of the 18th International Parallel and Distributed Processing Symposium \(IPDPSê04 


formed by extending a lexically lower ordered partition will be larger than the potential number of itemsets from a lexically higher ordered partition Since the frequent items are ordered lexically it is important to process the partitions in sequence from the highest ordered one to the lowest ordered one This processing order is required to support the subset-infrequency based pruning of candidate itemsets Figure 1 shows an example of partitions where items 0 1 2 3 4 and 5 are frequent 1-itemsets and are partitioned into P 1 P 2 and P 3   0 1 2, 3, 4, 5 Itemsets that begin with Itemsets that begin with 3 Itemsets that begin with first 1 are processed second 0 are processed last 2, 3, or 4 are processed 6 frequent items in 3 partitions PP P 1 2 Figure 1 Partitioning a set of 6 frequent items for Multipass-Apriori When P 3 is being processed we consider only the candidate itemsets whose members are in  2  3  4  5   not including 0 and 1 Thus the number of candidates will be smaller compared to the case of considering all the frequent 1-itemsets Similarly when P 2 is processed item 0 is not considered and many of the candidate itemsets can be pruned Therefore it requires less memory space during the processing as one partition is processed at a time Suppose that  2  3  is the only frequent 2-itemset found as a result of processing the frequent items in partition P 3  When the next partition P 2 is being processed item 1 in P 2 is extended with each of the items in P 3 rst As a result we can nd some frequent 2-itemsets including item 1 Let’s assume that  1  2    1  3  and  1  5  are found frequent Then  1  2  and  1  3  are joined into  1  2  3  andwe need to check if  2  3  is also frequent to determine whether  1  2  3  is a candidate 3-itemset or not Since  2  3  was found frequent when P 3 was processed  1  2  3  becomes a candidate 3-itemset This e xplains why we need to process the last partition of frequent items rst On the other hand  1  2  5  and  1  3  5  are not candidate 3-itemsets because  2  5  and  3  5  were not found frequent In practice if the estimated number of candidate itemsets to be generated is small after processing a certain number of partitions then we can merge the remaining partitions into a single partition so that the number of database scans will be reduced 2.2 Inverted Hashing and Pruning IHP In the Inverted Hashing and Pruning algorithm a hash table named TID Hash Table THT is created for each item in the database When an item occurs in a transaction the transaction identiﬁer TID of this transaction is hashed to an entry of the THT of the item and the entry stores the number of transactions whose TIDs are hashed to that entry Thus the THT of each item can be generated as we count the occurrences of each item during the rst pass on the database After the rst pass we can remove the THTs of the items which are not contained in the set of frequent 1-itemsets and the THTs of the frequent 1-itemsets can be used to prune some of the candidate 2-itemsets In general after each pass k  1  we can remove the THT of each item that is not a member of any frequent k itemset and the remaining THTs can prune some of the candidate  k 1  itemsets Consider a transaction database with seven items A B C D E F and G Figure 2 shows the THTs of these items at the end of the rst pass In our example each THT has ve entries for illustration purpose Here we can see that item D occurred in ve transactions There were two TIDs hashed to 0 one TID hashed to 1 and two TIDs hashed to 4 ABCDEF G 0 1 3 4 5 0 4 3 0 0 2 2 0 2 3 5 5 0 2 0 2 1 0 0 1 0 0 5 3 6 5 2 0 0 0 0 3 1 1 1 Entries TID Hash Tables Items Figure 2 TID Hash Tables at the end of the rst pass If the minimum support count is 7 we can remove the THTs of the items B D E and F as shown in Figure 3 0-7695-2132-0/04/$17.00 \(C Proceedings of the 18th International Parallel and Distributed Processing Symposium \(IPDPSê04 


 ABC E F G 0 1 3 4 5 0 4 3 0 3 5 5 0 0 5 3 6 5 2 0 Entries TID Hash Tables Items D Figure 3 TID Hash Tables of frequent 1itemsets Only the items A C and G are frequent and are used to determine C 2  the set of candidate 2-itemsets As in the Apriori algorithm  A C    A G  and  C G  are generated as candidate 2-itemsets by pai ring the frequent 1-itemsets However in IHP we can eliminate  A G  from consideration by using the THTs of A and G Item A occurs in 12 transactions and item G occurs in 19 transactions However according to their THTs they can co-occur in at most 6 transactions Item G occurs in 5 transactions whose TIDs are hashed to 0 and item A occurs in no transactions that have such TIDs Thus none of those 5 transactions that contain G also contains A Item A occurs in 3 transactions whose TIDs are hashed to 1 and item G occurs in 6 transactions with those TIDs So in the set of transactions whose TIDs are hashed to 1 items A and G can co-occur at most 3 times The other THT entries corresponding to the TID hash values of 2 3 and 4 can be examined similarly and we can determine items A and G can co-occur in at most 6 transactions which is below the minimum support level In general for a candidate k itemset we can estimate its maximum possible support count by adding the minimum TID hash count of the k items at each entry of their THTs If the maximum possible support count is less than the required minimum support it is pruned from the candidate set 2.3 Multipass with Inverted Hashing Pruning MIHP Algorithm The MIHP algorithm is a combination of the MultipassApriori algorithm and the Inverted Hashing and Pruning described above and the details of MIHP is presented below 1 Database  set of transactions 2 Items  set of items 3 transaction   TID  x  x  Items   4 Comment Read the transactions and count the occurrences of each item and create a TID Hash Table THT for each item using a hash function h  5 foreach transaction t  Database do begin 6 foreach item x in t do begin 7 x.count  8 x.T HT  h  t.T ID     9 end 10 end 11 Comment F 1 is a set of frequent 1-itemsets 12 F 1   x  Items  x.count  Database  minsup   13 Partition F 1 into p partitions P 1 P 2 P p  14 Comment Process the partitions in the order of P p P p  1 P 1  15 for  m  p  m 0 m   do begin 16 Comment Find F k  the set of frequent k itemsets k  2  whose members are in partitions P m P m 1 P p  17 for  k 2 F k  1     k  do begin 18 Comment Initialize F k before P p is processed 19 if m  p then F k    20 Comment C k is the set of candidate k itemsets whose members are in P m P m 1 P p  21 Comment F k  1 012 F k  1 is the natural join of F k  1 and F k  1 on the rst k  2 items 22 C k  F k  1 012 F k  1  23 foreach k itemset x  C k do 24 if  y  y   k  1 subset of x and y   F k  1 25 then remove x from C k  26 Comment Prune the candidate k itemsets using the THTs 27 foreach k itemset x  C k do 28 if GetM axP ossibleCount  x    Database  29 minsup then remove x from C k  30 Comment Scan the transactions to count the occurrences of candidate k itemsets 31 foreach transaction t  Database do begin 32 foreach k itemset x in t do 33 if x  C k then x.count  34 end 35 F k  F k  x  C k  x.count  Database  minsup   36 end 37 end 38 Answer   k F k  The formation of the set of candidate itemsets can be done effectively when the items in each itemset are stored in a lexical order and itemsets are also lexically ordered As speciﬁed in line 22 candidate k itemsets for k  2 are obtained by performing the natural join operation F k  1 012 F k  1 on the rst k  2 items of the  k  1 itemsets in 0-7695-2132-0/04/$17.00 \(C Proceedings of the 18th International Parallel and Distributed Processing Symposium \(IPDPSê04 


F k  1  assuming that the items are lexically ordered in each itemset 1  F o r e x amp le if F 2 includes  A B  and  A C  then  A B C  is a potential candidate 3-itemset Then the potential candidate k itemsets are pruned in line 24 by using the property that all the  k  1 subsets of a frequent k itemset should be frequent  k  1 itemsets 1  T hi s i s t he subset-infrequency based pruning of the candidate itemsets Thus for  A B C  to be a candidate 3-itemset  B C  also should be a frequent 2-itemset To count the occurrences of the candidate itemsets efﬁciently as the transactions are scanned they can be stored in a hash tree where the hash value of each item occupies a level in the tree 1 Here GetM axP ossibleCount  x  returns the maximum number of transactions that may contain a k itemset x by using the THTs of the k items in x Let’sdenote the k items in x by x 1 x 2 x  k  Then GetM axP ossibleCount  x  can be deﬁned as follows GetM axP ossibleCount itemset x  begin k  size  x   MaxPossibleCount  0 for  j 0 j<size  THT  j  do MaxPossibleCount  min  x 1 T HT  j   x 2 T HT  j  x  k  T HT  j   return MaxPossibleCount end size  x  represents the number of items in the itemset x and size  THT  represents the number of entries in the THT For further performance improvement the MIHP algorithm is used together with the transaction trimming and pruning method proposed as a part of the DHP algorithm 14 The concept of t h e t rans act i o n t ri mmi ng and pruning is as follows During the k th pass on the database if an item is not a member of at least k candidate k itemsets within a transaction it can be removed from the transaction for the next pass transaction trimming because it cannot be a member of a candidate  k 1 itemset Moreover if a transaction doesn’t have at least k 1 candidate k itemsets it can be removed from the database transaction pruning because it cannot have a candidate  k 1 itemset It is convenient to use a slightly weaker form of the rule for MIHP The transaction trimming rule as stated is only applied to the items that are in the F 1 partition being processed The items that are not in the partition being processed are removed if they are not members of any candidate itemset during the current pass Also a transaction is pruned during the k th pass if it does not have at least k candidate k itemsets each of which contains one or more items from the current F 1 partition being processed Transaction trimming and pruning is synergistic with the candidate pruning by IHP 2.4 Parallel MIHP PMIHP Algorithm The Parallel MIHP algorithm is based upon the sequential MIHP algorithm The database is partitioned into almost equal-sized local databases one for each processing node and the MIHP algorithm is parallelized by three additional actions exchanging and merging of the local TID Hash Tables THTs of items between processing nodes to produce the global TID Hash Tables replicated in the processing nodes identifying the global candidate itemsets that are just locally frequent in at least one node but may have sufﬁcient global support and determining the global support of the global candidate itemsets and updating the list of global frequent itemsets The global THT of each item is just a linear cascade of the local THTs of the item instead of creating a separate global THT whose TID hash count is the sum of the local TID hash counts at each entry For an itemset to be globally frequent in the whole database it must be frequent in at least one local database If a local support count of an itemset is above the global minimum support count then it is recorded as a globally frequent itemset However if the local count of an itemset is above the local minimum support count but less than the global minimum support count then it is recorded as a global candidate itemset The major steps of the PMIHP algorithm are as follows 1 Every processing node counts the occurrences of each item in its local database and builds the local THTs 2 The local support counts and THTs of items are exchanged between processing nodes so that each processing node can obtain the global support counts of all items Each processing node then determines the set of globally frequent items and discard the local THTs of globally infrequent items The received local THTs of the items that are not local to the node are also discarded and each node creates the global THT of each local item by linearly cascading its local THTs created by the processing nodes 3 Every processing node partitions the frequent 1itemsets into the same p partitions P 1 P 2 P p as in the MIHP algorithm The number of partitions is determined such that the candidate itemsets for each partition would be resident in the main memory of processors It has been shown that the total execution time is not sensitive to the partition size unless it is too large 11 4 As in MIHP the partitions are processed one by one in the order of P p P p  1 P 1  by all the processing nodes That means all the processing nodes discover the globally frequent itemsets whose members are in 0-7695-2132-0/04/$17.00 \(C Proceedings of the 18th International Parallel and Distributed Processing Symposium \(IPDPSê04 


P p rst and then discover the globally frequent itemsets whose members are in P p  1 and P p  and so on until partition P 1 is processed 5 For each partition P i  1  i  p  each processing node uses MIHP algorithm to nd all the locally frequent itemsets from its local database Some of these itemsets may have sufﬁcient local support to be globally frequent as well The locally frequent itemsets that do not have sufﬁcient local support to be globally frequent are global candidate itemsets The global THTs are used to prune the global candidate itemsets by estimating their maximum global support counts as in MIHP When certain number of global candidate itemsets are accumulated at each node it requests other processing nodes to provide their local support counts of those global candidate itemsets The other processing nodes to be polled to obtain their local support counts for each global candidate itemset can be easily determined by checking the local THTs contributed by the other processing nodes in step 1 for the member items of the global candidate itemset Only the processing nodes that have a positive TID hash count for the global candidate itemset will be polled 6 The processing nodes exchange their lists of global frequent itemsets after all the partitions are processed To perform the communication between processing nodes efﬁciently we imposed a logical binary n cube structure on the processing nodes Then the processing nodes can exchange and merge the local information through increasingly higher dimensional links between them 5 In the n cube there are 2 n nodes and each node has n bit binary address Also each node has n neighbor nodes which are directly linked to that node through n different dimensional links For example there are 8 nodes in the 3-cube structure and node 000 2 is directly connected to 001 2  010 2 and 100 2 through a 1st-dimensional link a 2nddimensional link and a 3rd-dimensional link respectively Thus in the n cube all the nodes can exchange and merge their local information in n steps through each of the n different dimensional links When n 3  the three exchange and merge steps are step 1 node  012\012 0 2 and node  012\012 1 2 exchange and merge where 012 denotes a don’t-care bit step 2 node  012 0 012  2 and node  012 1 012  2 exchange and merge step 3 node 0 012\012  2 and node 1 012\012  2 exchange and merge It is neither necessary nor desirable to obtain the global support counts of the global candidate itemsets at the end of the processing of each partition P i  1  i  p  Instead when certain number of global candidate itemsets are accumulated at a node it can start polling the other processing nodes to obtain their local support counts of those global candidate itemsets As in MIHP transaction trimming and pruning can be used together with PMIHP However to provide the local support counts of global candidate itemsets each processing node cannot prune the item that can be a member of some global candidate itemset from the transactions in its local database Thus the frequency of polling between processing nodes to obtain the local support counts of the global candidate itemsets must b e balanced with the loss in efﬁciency caused by not trimming and pruning the transactions in the local databases 3 Performance Analysis of Parallel MIHP Some experimental tests have been done to evaluate the performance of PMIHP and to compare it with that of the Count Distribution CD algorithm 2  T he C ount Di s t ri b u tion algorithm is a parallel version of the Apriori algorithm In Count Distribution the database is partitioned and distributed over the processing nodes initially At each pass k  every node collects local counts of the same set of candidate k itemsets Then these count s are merged between processing nodes so that each node can identify the frequent k itemsets and generate the candidate  k 1 itemsets for the next pass To merge the local support counts of the candidate itemsets synchroniza tion between nodes is required at every pass and maintaining the same set of candidate itemsets in all the nodes is redundant We implemented PMIHP and Count Distribution on a Linux cluster with 9 nodes connected by a Fast Ethernet switch Eight of the nodes were used for parallel mining and one node was used as a management console Each node has a 800 MHz Pentium processor 512 Mbytes of memory and a 40 Gbytes disk drive Both PMIHP and Count Distribution were implemented in the Java language The Java virtual machine was the IBM JVM 1.1.8 for the Linux operating system with the just-intime JIT compiler enabled The interprocess communication was performed using the Java RMI Remote Method Invocation protocol For all of the tests the JVM memory for objects was constrained via the mx parameter to 416 Mbytes The initial heap size was set to 416 Mbytes via the ms parameter to control the effect of heap growth overhead on the performance The partition size used for the PMIHP was 100 frequent items and the global TID Hash Table THT size was 400 entries for each item As the global THT of each item is a linear cascade of its local THTs the local THT size for the 1-node case was 400 entries per item and was 50 entries per item for the 8-node case It has been shown that the sizes of the partitions and THT are not critical for the overall performance 12 The mining algorithms were e x ecuted on 1-node 2-node 4-node and 8-node conﬁgurations We used a 6-month sample of the Wall Street Jour0-7695-2132-0/04/$17.00 \(C Proceedings of the 18th International Parallel and Distributed Processing Symposium \(IPDPSê04 


nal published from April 2 1990 through September 28 1990 for the performance comparison between PMIHP and Count Distribution as well a s between MIHP and Apriori The sample contains 21,703 documents and 116,849 unique words We varied the minimum support level from 5 to 1.75 to measure its impact on the miners For PMIHP and Count Distribution the 6-month sample was sequentially distributed to the processing nodes by assigning the articles of 16 or 17 days to each node Figure 4 shows the total execution times of Apriori FPGrowth and MIHP and Figure 5 shows the total execution times of PMIHP and Count Distribution when both algorithms were run on 8 nodes The Apriori and Count Distribution algorithms were not able to run within the memory constraint of 416 Mbytes when the minimum support level is below 2 The memory requirement for the candidate itemsets is the limiting factor for both Apriori and Count Distribution MIHP has much better performance than Apriori because MIHP prunes many candidate itemsets by using the Inverted Hashing and Pruning and processes a limited number of candidate itemsets at a time based on the Multipass approach More performance analysis result of MIHP is available in 12 The FP-Growth algorithm performed well at the higher minimum support levels However its performance deteriorated at the 2 minimum support level The FP-tree becomes too large when the minimum support level is low and as a result the total execution time increases sharply Lower minimum support levels were not attempted As shown in Figure 5 PMIHP performs signiﬁcantly better than Count Distribution and the performance gain increases as the minimum support level decreases It is important to note that the minimum support levels were selected in this test such that the miners would run within the constraint of the main memory and thus eliminates the effect of paging upon the performance Comparing Figures 4 and 5 we can see that the speedup of Count Distribution over Apriori is fairly good When the minimum support level is 2 it is about 6 whereas the speedup of PMIHP over MIHP is about 4 However as we shall see below the speedup of PMIHP is quite good at a lower minimum support level of 0.15 Since the amount of computation increases rapidly as the minimum support level decreases the speedup improvement at low minimum support levels is quite encouraging To evaluate the effect of the number of processing nodes on the performance of PMIHP we used a 8-day sample of the Wall Street Journal starting from October 1 1991 There were 1,427 documents and 31,290 unique words We used a minimum support count of 2 documents i.e minimum support of 0.15 and a stop-word list from Fox 8  There were 12,828 frequent words The minimum support count of two documents was selected based upon the result  Apriori  FP-Growth  MIHP Minimum Support Time \(seconds              0 100000 200000 300000 400000 500000 5.00 4.00 3.00 2.00 1.75 Figure 4 Total execution time to nd all frequent itemsets in 21,703 documents  CD  PMIHP Minimum Support Time \(seconds          0 20000 40000 60000 80000 5.00 4.00 3.00 2.00 1.75 Figure 5 Total execution time to nd all frequent itemsets in 21,703 documents on 8 nodes of our experiments showing that low minimum support levels are required to use the frequent itemsets for document retrieval and ranking We did not stem the words but we monocased the words The database was assigned to the processing nodes sequentially by day For the 2-node case one node was assigned the articles of the rst 4 days and another node was assigned the articles of the last 4 days The assignments for the 4-node and 8-node cases were done in a similar manner These daily collections have a mean of 178 a standard deviation of 22.58 and a median of 174 documents Figure 6 shows the total execution time of PMIHP required to nd frequent 3-itemsets as the number of processing nodes changes and Figure 7 shows the corresponding speedup over the sequential processing We can see that the speedup increases as the number of processing nodes increases and the increasing rate is slightly higher than lin0-7695-2132-0/04/$17.00 \(C Proceedings of the 18th International Parallel and Distributed Processing Symposium \(IPDPSê04 


ear The speedup is 1.65 for the 2-node system indicating some degree of parallelization overhead mainly due to the interprocess communication to exchange the support count information The speedup is 3.76 for the 4-node system but the increasing rate of the speedup is 2.27 as the number of nodes is doubled from 2 to 4 As the number of nodes is doubled from 4 to 8 the increasing rate of the speedup is higher than linear again which indicates that PMIHP is quite scalable Number of Processors Time \(seconds 0 20000 40000 60000 80000 1 2 4 8 Figure 6 Total execution time of PMIHP to nd frequent 3-itemsets in 1,427 documents minsup  0.15 Number of Processors Speedup    0 2 4 6 8 2 4 8 Figure 7 Speedup of PMIHP minsup  0.15 The PMIHP algorithm has two main data mining activities counting the support of local candidate itemsets in the corresponding local database and counting the support of global candidate itemsets in multiple local databases These two activities are interleaved during the mining as the global support counting is invoked when the number of identiﬁed global candidate itemsets exceeds a certain number at each processing node which was set to 20,000 in our experiments To measure this global support counting time we reconﬁgured PMIHP to defer the global support counting of the global candidate itemsets at each node and synchronized the nodes before the start of the global support counting phase Figure 8 shows the global support counting time of the mining process with the logest run time among all the mining processes executed on different processing nodes Moreover we used the wall clock time to measure this global counting time hence it is an upper bound of the actual global support counting time of all the mining processes Comparing Figures 6 and 8 we can see that the 2-node case has a much longer global support counting phase than 4-node and 8-node cases The portion of the global support counting phase for the 2-node case is about 8 of the total execution time but it is about 4 for the 4-node case and about 3 for the 8-node case Thus the impact of the global support counting time on the overall speedup is very small and it is reduced further as the number of processing nodes increases Number of Processors Time \(seconds 0 1000 2000 3000 4000 2 4 8 Figure 8 Global support counting time to nd frequent 3-itemsets Since our processing environment does not provide the statistics for job accounting exact CPU time measurement was not feasible So we measured the average execution of a processing node using the wall clock time Figure 9 shows the average execution time of a node in the 1-node 2-node 4-node and 8-node conﬁgurations We can see that the 2-node case requires signiﬁcantly less average execution time per node than the 1-node case and as the number of processing nodes increases further the average execution time per node deceases more than linearly This result is completely consistent with the observed speedup values and also indicates that increased efﬁciency is behind the performance gain Since the identical PMIHP algorithm was executed on all of our system conﬁgurations the differences in execution time must be associated with some workload differences Figure 10 shows the average number of candidate 0-7695-2132-0/04/$17.00 \(C Proceedings of the 18th International Parallel and Distributed Processing Symposium \(IPDPSê04 


Number of Processors Time \(seconds 0 20000 40000 60000 80000 1 2 4 8 Figure 9 Average execution time per node to nd frequent 3-itemsets 2-itemsets processed by each node in our four different system conﬁgurations Note that the number of candidate 2itemsets for the 1-node case is approximately the same as the average number of candidate 2-itemsets for the 2-node case This result is consistent with the observed total and average execution times for the 1-node and 2-node cases There is signiﬁcant reduction in the average number of candidate 2-itemsets processed for the 4-node and 8-node cases over the 1-node and 2-node cases This result represents the nonuniform distribution of itemsets over the local databases as well as the effective reduction of the candidate itemsets by the Inverted Hashing and Pruning technique Number of Candidate 2-itemsets 0 100000 200000 300000 400000 MIHP 2-node PM IHP 4-node PM IHP 8-node PM IHP Figure 10 Average number of candidate 2itemsets per node Figure 11 shows the average number of candidate 3itemsets processed by each node We included the number of candidate 3-itemsets processed in Apriori to demonstrate the usefulness of the Inverted Hashing and Pruning The number of candidate 2-itemsets for Apriori was about 82 million which is why we did not show that in Figure 10 We can observe the same pattern of reduction in the candidates 3-itemsets as in the candidate 2-itemsets This reduction in the average number of candidate itemsets processed by each processing node may be the most clear explanation for the high increasing rate of the speedup observed as the number of processing nodes increases Number of Candidate 3-itemsets 0 200000 400000 600000 800000 Apriori MIHP 2-node PM IHP 4-node PM IHP 8-node P M IHP Figure 11 Average number of candidate 3itemsets per node We also ran a test with a larger database 8 weeks of the Wall Street Journal published from January 2 1991 through February 22 1991 February 23rd was a Wall Street Journal holiday There were 6,170 documents and 64,191 unique words of which 31,948 were frequent words at the minimum support level of 0.03 i.e 2 out of 6,170 documents The 1-node system required 845,702 seconds to nd 1,554,442 frequent 2-itemsets whereas the 8-node system required 33,183 seconds This performance represents a superliner speedup of 25.5 of the 8-node system over the 1-node system Thus we can conclude that the performance of PMIHP is quite scalable when the database is large and the minimum support level is low which is the case of high workload The 1-node case generated 16,174,357 candidate 2itemsets whereas the 8-node case generated 2,459,629 candidate 2-itemsets per node on the average The total number of candidate 2-itemsets counted by the 8 nodes were 19,677,031 which means that only 21.7 of the candidate 2-itemsets were counted at more than one processing node This implies that the distribution of words across the 8-week sample of the Wall Street Journal is quite skewed In the Count Distribution algorithm all the nodes count the same set of candidate itemsets in each pass over the database regardless of the distribution of items over the local databases On the other hand in our PMIHP algorithm not all candidate itemsets are counted at more than one node when the distribution of items over the local databases is not uniform Obviously the more skewed the data distribution the better the performance of PMIHP Cheung et al 4 propos ed s e v e ral approaches to partition the databas e 0-7695-2132-0/04/$17.00 \(C Proceedings of the 18th International Parallel and Distributed Processing Symposium \(IPDPSê04 


to achieve a high degree of skewness Text documents arranged in a chronological order do appear to have a high degree of skewness and beneﬁt the PMIHP algorithm 4 Conclusions The proposed Parallel Multipass with Inverted Hashing and Pruning PMIHP algorithm is a parallel version of our Multipass with Inverted Hashing and Pruning MIHP algorithm and it is effective for mining frequent itemsets in large text databases The Multipass approach reduces the required memory space at each processor by partitioning the frequent items and pro cessing each partition separately Thus the number of candidate itemsets to be processed is limited at each instance The Inverted Hashing and Pruning is used to prune the local and global candidate itemsets at each processing node and it also allows each processing node to determine the other peer processing nodes to poll in order to collect the local support counts of each global candidate itemset PMIHP distributes the workload to multiple processing nodes to reduce the total mining time without incurring much parallelization overhead The average number of candidate itemsets to be counted at each processing node is much smaller than the case of sequential mining while the time for the synchronization between processing nodes to exchange the count information for the global candidate itemsets is very small compared to the total execution time PMIHP is able to exploit the natural skewed distribution of words in text databases and demonstrates a superlinear speedup as the number of processing nodes increases It has a much better performance than well-known parallel Count Distribution algorithm 2 becaus e the a v erage number of candidate itemsets to be counted at each processing node is much smaller especially when the minimum support level is low Overall the performance of PMIHP is quite scalable even when the size of the text database is large and the minimum support level is low which is the case of high workload References  R  A gra w al and R  S r i kant   Fast Al gori t h ms for M i n i n g A ssociation Rules Proc of the 20th VLDB Conf  1994 pp 487–499  R Agra w a l and J C S hafer  Paral l e l M i n i n g o f A ssoci at i o n Rules IEEE Trans on Knowledge and Data Engineering  Vol 8 No 6 1996 pp 962–969 3 M  S  C hen J Han and P  S  Y u   Dat a Mi ni ng An Overview from a Database Perspective IEEE Trans on Knowledge and Data Engineering  Vol 8 No 6 1996 pp 866–883 4 D  W  C heung S  D L ee and Y  Xi ao  E f f ect of Dat a S k e w ness and Workload Balance in Parallel Data Mining IEEE Trans on Knowledge and Data Engineering  Vol 14 No 3 2002 pp 498–514 5 S  M  C hung and J Y ang  A Par al l e l D i s t r i b ut i v e J oi n A l gorithm for Cube-Connected Multiprocessors IEEE Trans on Parallel and Distributed Systems  Vol 7 No 2 1996 pp 127–137  R  F e l dman and H Hi rsh F i ndi ng Associ at i ons i n Col l ections of Text Machine Learning and Data Mining Methods and Applications  R Michalski I Bratko and M Kubat editors John Wiley and Sons 1998 pp 223–240  R F e l dman I Dagen and H  H i rsh Mi ni ng T e xt Usi n g Keyword Distributions Journal of Intelligent Information Systems  Vol 10 No 3 1998 pp 281–300  C  Fox L e x i cal Anal ysi s and S t opl i s t s   Inforamtion Retrieval Data Structures and Algorithms W.FrakesandR Baeza-Yates editors Prentice Hall 1992 pp 102–130 9 M  G or don and S  Dumai s Usi ng L a t e nt S e mant i c I nde xi ng for Literature Based Discovery Journal of the Amer Soc of Info Science  Vol 49 No 8 1998 pp 674–685  J Han J P e i  and Y  Y i n Mi n i n g F r equent Pat t e r n s w i t hout Candidate Generation Proc of ACM SIGMOD Intêl Conf on Management of Data  2000 pp 1–12  J D Holt and S  M Chung Multipass Algorithms for Mining Association Rules in Text Databases Knowledge and Information Systems  Vol 3 No 2 Springer-Verlag 2001 pp 168–183  J D Hol t and S  M C hung Mi ni ng Associ at i o n R ul es Using Inverted Hashing and Pruning Information Processing Letters  Vol 83 No 4 Elsevier Science 2002 pp 211–220  J D Hol t and S  M C hung Mi ni ng associ at i o n R ul es i n Text Databases Using Multipass with Inverted Hashing and Pruning Proc of the 14th IEEE Intêl Conf on Tools with Artiìcial Intelligence  2002 pp 49–56  J S  Park M S  C hen and P  S  Y u   Usi n g a Hash-B a sed Method with Transaction Trimming for Mining Association Rules IEEE Trans on Knowledge and Data Engineering  Vol 9 No 5 1997 pp 813–825  G  S a l t on Automatic Text Processing The Transformation Analysis and Retrieval of Information by Computer  Addison-Wesley Publishing 1988  E  M V oorhees and D K Harmon edi t o rs The Fifth Text Retrieval Conference  National Institute of Standards and Technology 1997  O R  Z a i a ne and M L  Ant o i ne C l assi f y i n g T e x t D ocuments by Associating Terms with Text Categories Proc of the 13th Australian Database Conf  2002 0-7695-2132-0/04/$17.00 \(C Proceedings of the 18th International Parallel and Distributed Processing Symposium \(IPDPSê04 


  11 could be improved by a simple modification of the feed by adding a small tuning vane to th e feed. Therefore, it can be stated that some improvement can be expected by modification of the feeds, and adaptation of the test antenna in such a way that surrounding Ku-band element are closed   Figure 28 Reflection coefficient of Ku-band stacked patch antenna element in dual-frequency antenna stack  Figure 29 shows the influence of the L-band slots on the return loss of the Ku-band antenna element. To this end, the four connectors of the L-band elements were alternately open and terminated by means of 50 loads. The deviations were measured with respect to the set-up where all connectors were terminated Apparently, the deviations are acceptable  Figure 29 Influence of L-band termination on return loss of Ku-band antenna element, with and without termination Figure 30 and Figure 31 show the isolation between the Lband and Ku-band elements in L-band and Ku-band respectively. To this end the S21-parameters have been measured. These figures reveal that the mutual coupling between the L-band and Ku-band elements is sufficiently small  Figure 30 Measured isolation between L-band and Ku-band antennas in L-band frequencies  Figure 31 Measured isolation between L-band and Ku-band antennas in Ku-band frequencies From these measurements it can be concluded that opportunities should be considered to improve the design of the dual-frequency antenna \(by optimizing the feeds of the Ku-band elements antenna and the measurement set-up \(closure of surrounding Ku-band ports and use of appropriate connectors for the open Ku-band ports 7  M ODIFIED DUAL FREQUENCY ANTENNA  In order to benefit the str ong points of the two separate designs as discussed in section 4, an alternative antenna is proposed that exploits the properties of a \221best of both worlds\222 solution employing ideas from both designs. The modified antenna possesses an aperture fed L-band patch of a similar form to first design, but situated towards the bottom of the stack. Ku band el ements are located within the L-band perforations and para sitic patches are situated above a foam spacer \(see Figure 32 and Figure 33\A measurement campaign is underway to assess the behaviour of this modified test antenna 


  12  Figure 32 Bottom view of dual frequency antenna tile with perforated L-band patc h in lower layer with Kuband patches  Figure 33 Layer stack with perforated L-band patch in lower layer with Ku-band patches  8  B EAM FORMING N ETWORK  A major keystone for the su ccess of phased array antenna onboard aircraft is the capability of steering the main beam in the direction of the geosta tionary satellites. This requires the inclusion of a broadband beam forming network. Beam steering can be realized by adding RF-phase shifters and LNA\222s to the antenna elements of the array. However traditional phase shifters in ge neral have a narrow band, and hence do not yield the re quired broadband capability Alternative technologies for broadband beam forming are switched beam networks \(using Butler matrices innovative designs for RF-compone nts such as phase shifter LNA components in \(M\IC technology, or beam forming by using opti cal ring resonators  The German SME IMST is involved in several projects for development of electronica lly steerable phased array antennas for satellite communication. In the NATALIA project \(New Automotive Track ing Antenna for Low-cost Innovative Applications\ ESA, IMST is investigating the possibility of realizing a compact costeffective solution for a recei ve-only full electronically steerable antenna for cars in Ku-band. This antenna is a planar array composed of approximately 150 patches circularly polarised by using a 90\260 hybrid, and arranged in a hexagonal fashion. Each patc h is equipped with a MMIC corechip containing a phase sh ifting unit, LNA and digital steering logic  In the Netherlands, a consortiu m \(consisting of University of Twente, Lionix BV, National Aerospace Laboratory NLR and Cyner Substrates developing in the national FlySmart project technology for a broadband optical beam forming network. For the steering of the beam of the conformal phased array a squi nt-free, continuously tunable mechanism is proposed that is based on a fully integrated optical beam forming network \(OBFN optical ring resonators \(ORRs as tunable delay elements. A narrowband continuously tunabl e optical TTD device is realized as a recirculating wa veguide coupled to a straight waveguide. This straight wave guide can behave as a bandpass filter with a periodic, bell-shaped tunable group delay response. The maximum group delay occurs at a tunable resonance frequency. A larger delay-bandwidth product can be achieved by cascading multiple ORR sections. A complete OBFN can be obtaine d by grouping several delays and combining elements in one optical circuit. Such an OBFN can be realized on a si ngle-chip. Electrical/Optical E/O O E by means of filter based single-sideband modulation suppressing the carrier lanced coherent optical detection. Further details of the optical beamforming network have been presented in Re The proof-ofconcept has been shown by manufacturing a chip for an 8x1 OBFN. Essential components of the OBFN are the optical modulators, which are used to modulate the light in the ORR system 9  C ONCLUSIONS  For enhanced communicati on on board aircraft, novel antenna systems with broa dband satellite-based capabilities are required. So far, existi ng L-band satellite based systems for communications are used primarily for passenger application \(APC\i nistrative communications AAC and now data are tending to evolve towards broadband dig ital applications \(Voice over IP\any studies are going on worldwide to employ Kuband TV geostationary sate llites for communication with mobile terminals on aircraft The inbound traffic is about 5 times higher than the outbound The inbound traffic requires the availability of a broadband Ku-band antenna in receive mode only. The outbound traffic services can be supplied by the Inmarsat SBB link, whic h requires the installation of an L-band transmit antenna. In order to avoid both the installation of L-band antenna and Ku-band antenna, the concept of a hybrid dual frequency antenna operating L 


  13 band and Ku-band with low aerodynamic profile has been investigated in this paper. Keyaspects of this research are 200  Design and testing dual-fre quency antenna elements operating in both L-band and Ku-band 200  Conformal aspects of Ku-band phased array antennas 200  Beam forming algorithms for planar and conformal phased array antennas Two designs for dual-frequency antenna tiles consisting of 8x8 Ku-band antenna elements and one L-band element The designs have been analysed by means of computer simulations. Both designs show promising performance both in L-band and Ku-band. The design with slotted Lband antenna has a resonant fre quency in receive mode with a bandwidth of about 1 GHz. The Ku-band antenna is a stacked patch configuration where a parasitic element is placed above a lower patch separated by dedicated space filler. The manufactured protot ype antennas indicate that the bandwidth is sufficiently large In order to be able to communicate with geostationary satellites also at high latitudes e.g. during inter-continental flights\stem should have sufficient performance at low elevation angles. The antenna Ku-band system is required to have a small beamwidth \(to discriminate between the satellite signals\gain 30 dB angles. The effects of these requirements on the size and positioning of the antenna on the aircraft fuselage have been investigated. These requirements can be best satisfi ed by installing two planar phased array antennas on both side s of the fuselage with at least 1600 Ku-band elements. Each element has two feed lines, one for each polarization Every feed line has to be connected to the beam formi ng network. This means that the connections cannot be routed to one of the four sides of the antenna. Instead the concept of vertical feed lines \(by means of vias in a sufficiently thick substrate recommended. These vertical f eed lines connect the L-band and Ku-band antenna elements in the upper layer with feed networks in multiple lower laye rs. This vertical feed line system was not available so far due to manufacturing problems The performances of one dua l-frequency antenna design have been investigated by manufacturing two test antennas without vertical feed line syst em. The first antenna contains only a multilayer structure with L-band slots and 8x8 Kuband stacked patches. The performances of the L-band slots and Ku-band stacked patches c ould be measured separately It was concluded that opportun ities should be considered to improve the design of the dual-frequency antenna \(by optimizing the feeds of the Ku-b and elements the dual frequency test-antenna and the measurement set-up More important, however, is the realization of a mechanically stable vertical feed line system, so that the properties of L-band and Ku-band elements can be measured adequately The second test antenna contains only a multilayer structure with 8x8 Ku-band stacked patches and a feed network with 8 combiners, where each comb iner coherently sums 8 antenna elements. In combination with a prototype 8x1 OBFN, a Ku-band phased arra y antenna is obtained of which the beam can be steered in one direction. This second test antenna is used to analyze the broadband properties of the 8x8 Ku-band antenna array and 8x1 OBFN. The measured performances of this antenna are presented in Ref   A CKNOWLEDGMENT  This work was part of the EU 6 th Framework project ANASTASIA., and the FlySmart project, supported by the Dutch Ministry of Economic A ffairs, SenterNovem project numbers ISO53030 The FlySmart project is part of the Eureka PIDEA  project SMART Cyner Substrates is acknowle dged for technical assistance during the fabrication of the prototype antennas 


  14 R EFERENCES  1  P. Jorna, H. Schippers, J. Verpoorte, \223Beam Synthesis for Conformal Array Antennas with Efficient Tapering\224 Proceedings of 5 th European Workshop on Conformal Antennas, Bristol, September 11-12, 2007 2  The Radio Regulations, editi on of 2004, contain the complete texts of the Radio Regulations as adopted by the World Radio-communication Conference \(Geneva WRC-95 tly revised and adopted by the World Radio-communication Conference WRC-97\RadioWRC2000\and the World Radio-communication Conference WRC-03 Resolutions, Recommendations and ITU-R Recommendations incorporat ed by reference 3  RECOMMENDATION ITU-R M.1643, Technical and operational requirements for ai rcraft earth stations of aeronautical mobile-satellite service including those using fixed satellite service network transponders in the band 14-14.5 GHz \(Earth-to-space 4  ETSI EN 302 186 v1.1.1 \(2004-01 Stations and Systems \(SES\onised European Norms for satellite mobile Aircraft Earth Stations AESs\the 11 12/14 GHz frequency bands covering essential requirement s under article 3.2 of the R&TTE directive 5  EUROCAE ED-14E; Environmental Conditions and Test procedures for Airbor ne Equipment, March 2005 6  F. Croq and D. M. Pozar, \223Millimeter wave design of wide-band aperture-coupled stacked microstrip antennas,\224 IEEE Trans. Antennas Propagation, vol. 39 pp. 1770\2261776, Dec. 1991 7  S. D. Targonski, R. B. Waterhouse, D. M. Pozar Design of wide-band aperture stacked patch microstrip antennas ", IEEE Transactions on Antennas and Propagation, vol. 46, no. 9, Sep. 1998, pp. 1245-1251 8  R. B. Waterhouse, "Design of probe-fed stacked patches", IEEE Transactions on Antennas and Propagation, vol. 47, no. 12, Dec. 1999, pp. 1780-1784 9  D.M. Pozar, S. D. Targonski, \223A shared aperture dualband dual-polarised microstrip array\224, IEEE Transactions on Antennas and Propagation,Vol. 49 no. 2,Feb. 2001, pp. 150-157 10  http://www.ansoft.com 11  J-F. Z\374rcher, F.E. Gardiol, \223Broadband patch antennas\224 Artech House, \(1995\N 0-89006-777-5 12  H. Schippers, J. Verpoorte, P. Jorna, A. Hulzinga, A Meijerink, C. G. H. Roeloffzen, L. Zhuang, D. A. I Marpaung, W. van Etten, R. G. Heideman, A. Leinse, A Borreman, M. Hoekman M. Wintels, \223Broadband Conformal Phased array with Optical Beamforming for Airborne Satellite Communication\224, Proc. of the IEEE Aerospace Conference, March 2008, Big Sky, Montana US 13  H. Schippers, J. Verpoorte, P. Jorna, A. Hulzinga, L Zhuang, A. Meijerink, C. G. H. Roeloffzen, D. A. I Marpaung, W. van Etten, R. G. Heideman, A. Leinse M. Wintels, \223Broadband Op tical Beam Forming for Airborne Phased Array An tenna\224, Proc. of the IEEE Aerospace Conference, March 2009, Big Sky, Montana US 


  15  B IOGRAPHIES  Harmen Schippers is senior scientist at the National Aerospace Laboratory NLR. He received his Ph. D. degree in applied mathematics from the University of Technology Delft in 1982. Since 1981 he has been employed at the National Aerospace laboratory NLR. He has research experience in computational methods for aero-eleastics, aeroacoustic and electromagnetic problems. His current research activities are development of technology for integration of smart antennas in aircraft structures, and development of computational tools for installed antenna analysis on aircraft and spacecraft  Jaco Verpoorte has more than 10 years research experience on antennas and propagation Electromagnetic compatibility \(EMC and radar and satellite navigation He is head of the EMC-laboratory of NLR. He is project manager on several projects concerning EMCanalysis and development of advanced airborne antennas    Adriaan Hulzinga received his BEng degree in electronics from the hogeschool Windesheim in Zwolle Since 1996 he has been employed at the National Aerospace laboratory \(NLR as a senior application engineer. He is involved in projects concerning antennas and Electromagnetic compatibility \(EMC  Pieter Jorna received the M.Sc degree in applied mathematics from the University of Twente in 1999 From 1999 to 2005 he was with the Laboratory of Electromagnetic Research at the University of Technology Delft. In 2005 he received the Ph.D. degree for his research on numerical computation of electromagnetic fields in strongly inhomogeneous media Since 2005 he is with the National Aerospace Laboratory NLR\ in the Netherlands as R&D engineer   Andrew Thain is a research engineer in the field of electromagnetic modelling of antennas. He specialises in the use of surface integral methods for the calculation of coupling and radiation patterns and works closely with Airbus on the topic of antenna positioning. He has experience in the field of electromagnetic modelling  Gilles Peres is head of the Electromagnetics group of EADS-IW He has a wide experience in computational EM modelling particularly the use of FDTD, integral and asymptotic techniques for antenna structure interactions. He has contributed with Airbus experts to the certification campaign of the A340/500 and A340/600. Dr Peres holds a PhD thesis from University of Toulouse \(1998\ on impulsive Electromagnetic Propagation effects through plasma   Hans van Gemeren has a BEng degree in electronics. From the beginning of Cyner substrates he is involved in development and production of prototyping and nonconventional Printed Circuit boards Working mainly for design and research centers Cyner got involved in many high tech projects and from this developed a great expertise in the use of different \(RF materials. In the FlySmart project Hans and his colleagues are able to do what they like most: In close cooperation with designers, creatively working on substrate solutions 


  16  


NIMBUS NOAA 8 NOAA 15 NPOESS Preparatory Project Orbital Maneuvering Vehicle Orbcomm Orbiting Carbon Observatory Orbiting Solar Observatory-8 Orbview 2 Orion 1 P78 Pas 4 Phoenix Pioneer P-30 Pioneer Venus Bus/Orbiter Small Probe and Large Probe Pioneer-I 0 Polar QuikSCAT Radarsat Reuven High Energy Solar Spectroscopic Imager REX-II Rosetta Instruments Sage III SAMPEX Satcom C3 Satcom C4 SBS 5 SCATHA Seastar SMART-1 SNOE Solar Dynamics Observatory Solar Maximum Mission Solar Mesosphere Explorer Solar Radiation and Climate Experiment Solar Terrestrial Relations Observatory Space Interferometry Mission Space Test Program Small Secondary Satellite 3 Spitzer Space Telescope SPOT 5A Stardust  Sample Return Capsule STEPO STEPI STEP3 STEP4 STRV ID Submillimeter Wave Astronomy Satellite Surfsat Surveyor Swift Gamma Ray Burst Exporer Synchronous Meterological Satellite-I TACSAT TACSAT 2 TDRS F7 Tellura Terra Terriers Tethered Satellite System Thermosphere Ionosphere Mesosphere Energetics and Dynamics TIMED TIROS-M TIROS-N TOMS-EP Total Ozone Mapping Spectrometer TOPEX TRACE Triana Tropical Rain Measuring Mission TSX-5 UFO I UFO 4 UFO 9 Ulysses Upper Atmosphere Research Satellite Vegetation Canopy Lidar VELA-IV Viking Viking Lander Viking Orbiter Voyager Wilkinson Microwave Anisotropy Probe WIND WIRE XMM X-Ray Timing Explorer XTE XSS-iO XSS-ii APPENDIX B FIELDS COLLECTED Mission Mission Scenario Mission Type Launch Year Launch Vehicle Bus Model Bus Config Bus Diameter Location Expected Life Flight Profile Flight Focus Technical Orbit Currency Total Cost Including Launch Unit Sat Costs Average Sat Cost Production Costs Launch Costs Operations Cost Orbit Weight Wet Weight Dry Weight Max Power EOL Power BOL Power  of Batts 17 


Batt Power Batt Type Stabilization Type Propulsion Mechanism  of Solar Panels  of Solar Cells Manufacturing Qty Satellites in Constellation On-Orbit Spares Channels Number of Bands Data Storage Processing Power Source type Block Name Thermal Control Material Type Level of Technology Known Inheritance Propulsion station keeping Number of Axes Ground Based Spares Pointing Accuracy APPENDIX C EXISTING MODELS Numerous models are today in use for estimating spacecraft cost Two of the most common are the NASA/Air Force Cost Model and the Aerospace Small Satellite Cost Model Here is a description of the NAFCOM model The NASA/Air Force Cost Model NAFCOM is a parametric estimating toolfor space hardware It is based on historical NASA and Air Force space projects and is primarily used in the very early phases of a development project NAFCOM can be used at the subsystem or component levels The database currently includes 122 missions including 76 unmanned earth orbiting 24 unmanned planetary 11 launch vehicles 8 manned 3 engines It uses parametric relationships to estimate subsystem or component level costs for any aerospace hardware including earth orbital spacecraft manned spacecraft launch vehicle upper stages liquid rocket engines scientific instruments or planetary spacecraft 7 And for the Aerospace Small Satellite Cost Model SSCM employs a parametric methodology for estimation of program cost and is best suited to the early conceptual development phase of a spacecraft program during which time the design is likely to be less mature and when cost and performance trades can be easily performed SSCM consists of a collection of cost-estimating relationships or CERs which estimate the costs of developing andproducing a spacecraft system with the following subsystems  Attitude Determination and Control Subsystem ADCS  Propulsion  Power  Telemetry Tracking  Command TT&C  Command  Data Handling C&DH  Structure  Thermal CERs were also developed for integration assembly and test IA&T program management PM and systems engineering SE and launch and orbital operations support LOOS Individual subsystem cost estimates are statistically rolled up to yield a cost-risk distribution which provides the estimator with a range of cost estimates andpercentiles 8 The SSCM was calibrated from over 100 post-1990 Earth-orbiting andplanetary missions REFERENCES 1 Lack of Disciplined Cost-Estimating Processes Hinders Effective Program Management GAO study 04-642 2 Jilla Cyrus D and Miller David W Satellite Design Past Present and Future International Journal of Small Satellite Engineering 12 February 1997 3 Bearden David A A Complexity Based Risk Assessment of Low-Cost Planetary Missions:When Is A Mission Too Fast and Too Cheap Fourth IAA International Conference On Low-Cost Planetary Missions JHU/APL MAY 2-5 2000 4 Kellogg Mahr and Lobbia An Analogy-based Method for Estimating the Costs of Spacecraft IEEEAC paper 1371 Version 4 5 Hoeting Jennifer A Methodology for Bayesian Model Averaging An Update f 6]btp/ewiieiao iiAaos 7 Keith Smith NASA/Air Force Cost Model Science Applications International Corporation 8 18 


BIOGRAPHIES Lee Fischman served as Principle Investigator for this project Lee is Senior Director of Development at Galorath Incorporated where he directs much of the new product development and research at the firm He developed SEER for Software  Hardware Integrations with Microsoft Project the Comparison Sizing tool COTS Software model in addition to various data mining information extraction and expert systems Previously he was a software designerlprogrammer in the New York financial industry Lee earned a BA from the University of Chicago and an MA from UCLA both in economics Mike Kimel carried out statistical work on the project Mike is an Economist for Galorath Inc in addition to maintaining his own quantitative consulting practice He has also taught Economics and Advanced Statistics at the Graziadio School of Business and Management at Pepperdine University run the Competitive Strategy group for a Fortune 500 Telecom Company and worked as a Consultant at PriceWaterhouse LLC now PriceWaterhouse-Coopers He earned a Ph.D in Economicsfrom UCLA Troy Masters programmed analytic methods and is integrating the Far Out model into its parent product SEER for Hardware previously SEER-H Troy is a Software Engineer with Galorath Incorporated where he has been the primary developer for a range ofproducts He earned a BS in computer science from UCLA David J Pine was our subject matter expert helping us assemble data and gain insight into technical trends Dave is retired after a 34-year career with the National Aeronautics and Space Administration NASA currently is a consultant to various government and industry entities While at NASA his organizations in the Office of the Chief Financial Officer and later at the IPAO at Langley Research Center were responsible for the conduct of major NASA program analyses and evaluations for the NASA Administrator and Deputy Administrator From early 1988 through the end of 1990 he was the Deputy Program Manager for the Hubble Space Telescope Program specifically responsible for the telescope operations and science support aspects of the program He earned a BS in Aerospace Engineering from the Polytechnic Institute of Brooklyn and a Masters of Engineering Administration from the George Washington University 19 


  20 Angeles, where he also received a B.S. in Applied Mathematics  Eric Fetzer is a Senior Member of the Technical Staff at the Jet Propulsion Laboratory, Pasadena, California specializing in satellite observations of the atmosphere.  His scientific interests include planetary boundary layer processes, tropical phenomena, upper tropospheric variability, and climatologies of temperature, water vapor and clouds.  His technical interests include analysis of large data sets, and of multi-sensor observations. He has over 20 peer-reviewed publications and given numerous scientific presentations, public lectures and media interviews about climate science. Eric received a B.A. in Physics from the University of California Berkeley, and a Ph.D. in Astrophysical, Planetary and Atmospheric Sciences from the University of Colorado, Boulder   Amy Braverman is a Senior Statistician at the Jet Propulsion Laboratory, California Institute of Technology She holds a B.A. in Economics from Swarthmore College an M.A. in Mathematics from UCLA, and a Ph.D. in Statistics also from UCLA. Prior to her current position in JPL's Science Data Understanding Group, she was a Caltech Post-doctoral Scholar at the Jet Propulsion Laboratory, and a Scientist in the Flight Sciences Experiments Section of the Science Division. Dr Braverman conducts research on information-theoretic methods for the analysis of massive data sets and streams statistical data fusion, high-dimensional data analysis, and statistical analysis for climate model evaluation and diagnosis. She has published in both the statistics and geoscience literature, and is active in both communities She is a member of the Multi-angle Imaging SpectroRadiometer Science Team, and serves as a member of the Atmospheric Infrared Sounder Science Integration Team. Her responsibilities on both missions include designing data reduction algorithms for massive, remote sensing data sets. Dr. Braverman also holds an appointment in the Department of Statistics at UCLA as Adjunct Associate Professor, and is active in UCLA\222s Center for Environmental Statistics. She is member of the Committee on Applied and Theoretical Statistics of the US National Academy of Science. She has refereed for the Journal of the American Statistical Association, the Journal of Computational and Gr aphical Statistics, IEEE Transactions on Geoscience and Remote Sensing, and the Journal of Applied Meteorology and Climatology Seungwon Lee is a senior member of the High Capability Computing and Modeling Group at Jet Propulsion Laboratory. She is conducti ng research on comet gas dynamics, nonlinear dynamics control, climate model parameterization, Earth science data analysis, parallel computing, and advanced numerical algorithms. She received her Ph.D in Physics fr om the Ohio State University and her M.S. and B.S. in Physics from the Seoul National University, Korea  Matthew Henderson is software engineer in the High Capability Computing and Mode ling group at JPL. His current work includes Web Services and Instrument Data Level 2 subsetting. He received a B.S. Computer Science from CSU Pomona, and is currently pursuing M.S Computer Science  Steven J. Lewis is a member of the Information System and Computer Science staff member at the Jet Propulsion Laboratory.  He received a BS in Mathematics from the University of California, Los Angeles in June 2001, and the MS and Ph.D. Degree from Claremont Graduate University in May 2004 and May 2007, respectively.  He worked as a post doctoral fellow at Keck Graduate Institute from June 2007 until he joined JPL in March of 2008.  During his graduate and post doctoral work, his studies focused on applications of Bayesian methods to hidden Markov models with particular interest and application to protein sequencing.  His work at JPL has focused on integrating web services into various programming platforms for the purposes of accessing NASA satellite data, as well as developing object tracking so ftware and contributing to image enhancement and restoration efforts Van Dang is a member of the Science Data Understanding Group at the Jet Propulsion Laboratory. She was responsible for the NEWS Level 2 processing that generated the formal merged Level 2 data from multiple A-Train instruments  Manuel de la Torre is a Physicist from the Universidad Complutense at Madrid \(Spain\. After finishing his Ph.D work at the University of Bayreuth \(Germany\ on pattern formation in turbulent flows and a 7 1/2 year stunt as Ass and Assoc. Prof. at the Escuela T\351cnica Superior de Ingenieros Aeron\341uticos in Madrid \(Spain\, he came to the Jet Propulsion Laboratory on a 1-year Sabatical leave in 1997 wanting to apply fundamental concepts of nonlinear systems and geophysical fluid dynamics to something that might be directly useful to soci ety. He discovered the JPL as a great place to achieve that goal and extende d his stay a bit longer, becoming Technical staff and working on different aspects of remote sensing, validation of satellite instruments, and data analysis of atmospheric processes and climate  



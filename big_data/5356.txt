Load Balancing approach for QoS management of multi-instance applications in Clouds Mohamed Mahmoud OULD DEYE Faculty of Science and Technology University Cheikh Anta Diop Dakar Senegal Email mohamed.oulddeye@ucad.edu.sn Yahya SLIMANI Institut Sup  erieur des Arts Multim  edia Universit  e de la Manouba Manouba Tunisie Email yahya.slimani@fst.rnu.tn Mbaye SENE Faculty of Science and Technology University Cheikh Anta Diop Dakar Senegal Email mbaye.sene@ucad.sn 
Abstract 
The success of the technology of cloud computing 
lies mainly in its business model of pay-as-you-go where users pay only for the resources really consumed However it is known that there is no warranty for the QoS that these resources will provide at runtime In this paper we suggest an approach to make load balancing more dynamic to better manage the QoS of multi-instance applications in the Clouds This approach is based on limiting the number of requests that at a given time can be effectively sent and stored in queues of virtual machines through a load balancer equipped with a queue for incoming user requests This limitation is intended on the one hand to allow requests to go on to the faster instances and on the other hand to better mitigate the effects of interference of sharing resources by the fact 
that a large part of the requests which were intended to instances that have become affected by degradation are still stored at the load balancer and can be allocated to non-affected instances or to new instances which will be created A performance study using the simulator CloudSim showed the gain that this approach can generate compared to classical approaches of load balancing 
I I NTRODUCTION Cloud architectures represent one of the most recent developments in computer systems This is a ne w model of computer systems where data and computation are processed and kept somewhere in a computer network which constitutes the clouds The latter refers to a set of data centers owned and 
Keywords Cloud Computing QoS Load Balancing Instance 
 
maintained by third parties They are very dynamic systems accessible on the Internet and are characterized by a very large computing and storage capacity From an architectural point of view they look like a new type of mainframe available on the Internet but they are distinguished primarily by the fact that their capacities are not limited as in the case of a mainframe but they give the illusion of the existence of an in“nity of resources through mechanism scalability and infrastructures distributed across the globe They are also distinguished by the diversity of services and resources provided ranging from simple computing power to the provision of an entire IT infrastructure The Clouds represent a technology that leverages the advancement of information technology and communication 
They constitute the evolution and exploitation of parallel and distributed systems capabilities such as Clusters and Grids  The y are the result of the e v olution of a wide range of technologies  the technologies related to hardw are architectures virtualization technologies the technologies for distributed architectures and also the technologies of the Internet They are considered by some researchers as a step towards the realization of the idea of having the computing power as a public service in the same way as water electricity and telephone are The idea of utility computing is to provide computing and/or storage according to the needs of users who are not concerned with the location where their data will be stored or their applications will be executed From an economic 
standpoint the Clouds allow to pay only the resources that are really consumed unlike the Grids There is no single de“nition for Clouds but most de“nitions refer to the provision of material resources software systems and applications as a service Buyaa et al in propose the following de“nition  There are three types of Clouds 1  which 
Public Cloud 
A Cloud is a type of parallel and distributed system consisting of a collection of inter-connected and virtualized computers that are dynamically provisioned and presented as one or more uni“ed computing resource\(s based on service-level agreements established through negotiation between the service provider and consumers 
is a computing architecture available to the general public over the Internet 2 
is also a computing architecture that provides hosted services to a limited number of people behind a rewall 3 is a composition of at least one private Cloud and at least one public Cloud We have also three main models of services that can be provided by a cloud Software as a Service is one that provides applications running on infrastructure of the Cloud An example of this model is Google Apps Platform as a Service is a service that provides a computing platform hosted on infrastructure of the Cloud The most famous example 
Private Cloud Hybrid Cloud SaaS PaaS 
of PaaS is Google App Engine Finally Infrastructure as a Service 
provides both computing resources and virtual machines Amazon is one of the main actors of IaaS Cloud Despite the many promises of Clouds systems their adoption in the business world is still hampered by some dif“culties One of these dif“culties that interest researchers users and providers of Clouds is the QoS management problem in the Clouds The QoS management in Clouds provides gains for different actors of Clouds For users the gain is to ensure the quality of the execution of their tasks in Clouds infrastructure 
IaaS 
2013 International Conference on Cloud Computing and Big Data 978-1-4799-2829-3/13 $26.00 © 2013 IEEE DOI 10.1109/CLOUDCOM-ASIA.2013.69 119 
2013 International Conference on Cloud Computing and Big Data 978-1-4799-2830-9/14 $31.00 © 2014 IEEE DOI 10.1109/CLOUDCOM-ASIA.2013.69 119 


which are often shared on a large scale From the point of view of infrastructure providers the gain is to remain competitive by offering the guarantee of a certain QoS but also by optimizing the use of resources by allocating only those which are necessary for a given user Indeed in current Clouds users are charged on the basis of the resources used or reserved and no guarantee is given about the QoS that these resources will provide at runtime Also in the case of contracts of SLA for Service Level Agreements non-violation of constraints is often provided through a resource over-provision policy which is determined for the worst case where a double de“cit is caused  an inef“cient use of infrastructure resources and increased costs billed to customers In reality the QoS management is at the same time confronted to the challenges of QoS managing of centralized and distributed systems but they are distinguished by the use of virtualization that involves the implicit sharing of physical resources and that have more accentuated these challenges The main challenges for the management or QoS guarantee in Clouds are  1 The estimation errors at the time of the design for the physical or virtual quantities of resources which are required to achieve a given level of application quality Indeed with many parameters CPU time memory resources I/O that are used during the execution of an application it is dif“cult or even impossible to accurately predict the optimal combination of resources to accomplish the execution with respect to a quality constraint such as the response time for example 2 The highly dynamic nature of these infrastructures where the advent of a certain unexpected behavior cannot be excluded such as for example the failure of a server or the loss of a network connection 3 The highly variable loads that characterize the applications of these systems social networks web hosting etc make it impossible to maintain a static allocation of resources and require the implementation of an adaptation policy of these allocations in order to maintain an acceptable level of performance 4 The phenomenon of performance interference which results from sharing some physical resources of the Cloud infrastructure and causes interference between the virtual machines that share the same physical servers In fact virtualization which is a main technical base for the Clouds offers a number of advantages such as the coexistence of multiple systems on a single physical machine and isolation of failures within each virtual machine ensuring the protection of other machines running on the same server However virtualization technology does not guarantee the isolation of performance which means that the performance of a virtual machine application may change due to the existence of other virtual machines on the same physical server In this dynamic and distributed environment one solution of QoS management must allow for ef“cient use of infrastructure resources relying on the one hand on effective mechanisms of adaptation of resource allocation and on the other hand on a predictive model to calculate at any time the amounts of resources that are to be reserved for responding to changes in the load intensity of existing services and applications or to ensure the QoS of new services deployed The other sections of the paper are organized as follows  In Section 2 we summarize some related works In Section 3 we present the proposed load balancing approach In Section 4 we discuss the simulation of our proposed approach and summarize the results Section 5 is the conclusion of this paper II R ELATED W ORKS The QoS management of applications and services in the Clouds are recently been of particular interest to researchers as evidenced by the increasing number of papers on the subject  8]…[14 In this section we brie”y present the most similar approaches to our proposal Li et al suggested a method for optimizing resources at runtime by using performance models in the development and deployment of applications of Clouds Their approach is based on a queue network model called LQN for Layered Queueing Network performance model where for each new deployed application a LQN model must be generated and maintained for predicting the effects of changes in resource allocations However this method may not be transparent to existing applications due to the fact that it is based on measurements that must be made in advance by the developer for the generation of LQN models Nathuji et al ha v e demonstrated that the performance of an application running in a Cloud environment can be signi“cantly affected by the presence of other virtual machines sharing the same physical server They present a framework Q-Cloud which must ensure that the performances experienced by applications are the same as those carried out in an environment without interference performance Their approach is to maintain a number of free resources called head-room on each physical server to compensate its affected virtual machines on the basis of a MIMO model Multi-Input MultiOutput capturing the relationship between resource allocation and QoS experienced by the virtual machines This approach unlike ours is not independent of the placement policy of virtual machines at the level of physical servers in the cloud infrastructure Calheiros et al proposed a pro visioning technique based on an admission controller of user requests That controller can accept or deny requests depending on the number of requests already submitted at the instances of each application Their technique is also based on a Workload analyzer to calculate the number of suitable instances for the incoming ow of requests Their proposal is more similar to ours except the fact that with our approach the capacity of instances are best used especially in case of performance degradation where instances unaffected by these degradations can be used to execute requests that were previously intended for affected or failing instances They also ignored the fact that the Clouds are generally remote systems and that the latency must be taken into account in performance calculation especially with the fact that the virtual machines in the Clouds can migrate from one datacenter to another without users noti“cation 
120 
120 


i i Qos i i Qos i i i i 
002 
  002 
A The Load Balancer 
III P ROPOSED A PPROACH In our proposed approach we place ourselves in the case of an Application Service Provider ASP who wants to enjoy the capabilities of IaaS Clouds type for the execution of its applications while providing a level of QoS to its users and at the same time optimizing resource costs that are billed by infrastructure providers of Clouds However the current Clouds do not offer performance guarantees but they have large capacities and can provide at any time any additional resources that are deemed necessary for the hosted applications in order to achieve some degree of performance In this case it belongs to the ASP to manage and adapt at runtime the resource reservation as are necessary to ensure their desired performance This choice has the advantage of being practical in the sense that it corresponds to the reality of Clouds and particularly to public Clouds which are black boxes and their users have no access to what happens either inside these systems or on their con“gurations This choice also allows the abstraction of internal technology of Clouds in favour of one independent solution that is portable for all types of Clouds However it should be noted that the QoS cannot be effectively guaranteed without the use of a placement policy of virtual machines capable of limiting the level of degradation that can be caused by the sharing of physical resources The main idea of our proposal comes from the fact that the sharing of physical resources in the Clouds can affect the performance of virtual machines and thus affect the QoS of the applications and services running on them On the basis of this observation we believe it is necessary to mitigate the effects of these degradations in order to guarantee QoS in the Clouds For this reason we propose a load balancer equipped with a queue allowing to temporarily keep some of the accepted requests before they are dispatched subsequently on the fastest instances see Figure 1  This way of doing aims to limit the number of requests that can be effectively stored at a given instance to a minimum However this minimum of requests that can be effectively stored must be chosen with the aim of ensuring an acceptable rate of use of virtual machines Limiting the number of requests that can be effectively stored in the queue of one instance has the advantage of  Increasing the chance that the incoming requests will be executed by the fastest instances and therefore to best exploit their capabilities Mitigating the effects of any degradation by the fact that a large part of the requests which were intended to instances that have become affected by degradation are still stored at the load balancer and can be allocated to non-affected instances or to new instances which will be created We propose a distributed architecture consisting of two major components  a Load Balancer and a Response Dispatcher The behavior of the system can be described as follows  First of all user requests are received by the Load Balancer which decides for each new request its acceptance or its rejection In case it accepts it it decides whether it is going to store it in its queue or send it directly to an instance Inturn the responses are received by the Response Dispatcher which forwards them Fig 1 Components of the proposed architecture to users Response Dispatcher monitors the service time and also the propagation time to the instances and informs the Load Balancer in case of change of these values Meanwhile the Load Balancer monitors the intensity of incoming requests and can create new instances if the arrival rate increases as it can remove some other otherwise However determining the number of instances to create or to remove depending on the traf“c intensity of user requests will be studied in a future work and its out of the scope of this paper As mentioned above the Load Balancer intercepts user requests and rejects those which their QoS may not be guaranteed To accept or reject a request the dispatcher maintains for each instance the maximum number of requests that this instance can take using the following equation  Where is the negotiated response time and is the propagation time to the instance and is the average service time of the instance  Upon receiving a request the Load Balancer checks if there is still an instance that can take it otherwise the request is rejected In other words if the number of requests that are in the system the Load Balancer and instances is smaller than that of   then the request is accepted otherwise it is rejected For an accepted request the Load Balancer decides whether to store it in its queue or to send it directly to an instance An accepted request is automatically stored on the Load Balancer if its queue is not empty If the queue of the Load Balancer is empty the query will be stored if no instances can take it immediately and in this case it is placed rst in the queue of the Load Balancer managed with the First-Come-First-Serve policy FCFS To check if there is an instance that can immediately take a new request that happens the Load Balancer is based on a indicator which is recalculated for each instance according to 
i N N T TP TS T TP i TS i N N N K i 
 2   
121 
121 


i i i i i i 
 003 002  
2 2 2 
i i i i i i i i i TP TS TP TS i i TP TS i i i i i i i i i i i i i i i i i i i 
002 002 002 
K N i K i i K i K N K K K if N N if  N K K T T TP i K K N N K KR i KR K OLDK if OLDK  K if OLDK K OLDK K 
its delay and its average service time This indicator must be fewer in number or equal to and means for each instance  the maximum number of requests that can be submitted and effectively stored in its queue In other words represents the length of the queue of instance  If the number of requests that are already present in an instance is fewer than then that instance can still store another request otherwise the queue of Load Balancer may be used especially if no other instance is available for that task In other words for each instance  there are requests that can be immediately stored on the instance and requests that can be stored on the Load balancer The indicator that we propose is obtained by the following equation This indicator gives the minimum number of requests needed to maximize the use rate of virtual machines To determine the appropriate value of  we considered the special strategy in which a single request is sent to a virtual machine Upon receiving response from this virtual machine a new request is sent to the same virtual machine see Figure 2 We found that in this special strategy the virtual machine is free for a time where  From this observation we found that to maximize the utilization rate of virtual machines it is suf“cient to just send on each instance  requests and when receiving a response from an instance zero one or more of requests stored on the Load Balancer can be sent to this instance Indeed upon receipt of each response the indicators and are updated to re”ect any change in the service time or propagation time Fig 2 Special strategy  single request on each instance The Response Dispatcher is the second component of our architecture and its function is to monitor the performance of different instances used Also as its name suggests it is the component that receives the responses from intances before they are transmitted to users Upon receipt of a response it recalculates the and indicators before they are sent to the Load Balancer It computes also the number of requests from the local queue of the Load Balancer that are to be sent against each response received from one instance with the following formula Where is the old value of IV S IMULATION To investigate the effectiveness of our proposal we have used the simulator CloudSim kno wn as the reference tool for the simulation of the cloud environment It is an extensible simulation framework that enables modeling and simulation of Cloud computing systems and their management policies.The general architecture of a CloudSim model consists of one or more brokers and one or more datacenters A Broker represents a client and can simulate the behavior of one or more users Datacenters represent the internal infrastructure of simulated Cloud The connection between a Broker and a Datacenter or between Dataceners can be de“ned with a connection speed and delay The CloudSim model that we have used is composed of a data center with 50 physical servers each of type Quad-Core of 1000 MIPS Millions of Instructions Per Second with 16GB of RAM The virtual machines used are each of type One-Core with 1000 MIPs and 2GB of RAM These virtual machines are distributed onto physical servers following a simple allocation policy that chooses as the host for a virtual machine the host with less Processing Elements in use This is the default policy of CloudSim for the allocation of VMs to physical servers and its choice was dictated by the fact that the placement of virtual machines is not the purpose of this work Also the allocation of processing cores to VMs is done on the basis of time-shared policies which means that at a given moment a core can be shared between multiple virtual machines if the load requires that This choice is also motivated by the fact that we want to simulate and see the effects of interference from sharing physical resources of studied approaches In our experiments we considered several incoming ows of user requests and for each ow we rst studied the case without resource sharing where our virtual machines are running only in the data center Then we studied the case with resource sharing where other users share with us the physical resources of the data center We simulated in particular cores shared between virtual machines through time-shared policies mode As rst ow of incoming requests we studied the ow shown in Figure 3 and which has been studied in the paper of 
B The Response Dispatcher A Simulation Set Up 
   1 1 1  2   1  0 
003 004 005 006 
122 
122 


 002 
Fig 3 Arrival rate of requests per second regular ow Calheiros et al There is a re gular o w whose arri v al rate 
r r R R R 002t T R R T r R rq R rq T s r T s 
   sin   400  700  200 1 
is computed by the following equation Where and are respectively the minimum and maximum number of requests of the simulation interval  This equation is evaluated every 5 seconds to vary the arrival rate  In our experiments we took and and the simulation time is  Second we considered the ow shown in Figure 4 whose intensity varies randomly every 5 seconds For this ow the arrival rate is chosen randomly between 400 and 700 requests/s We also considered independent requests which have an execution time that varies randomly between 100ms and 110ms The connection between the Brokers and Datacenters is de“ned with a debit of 10MB and a propagation delay of 60ms In all experiments the negotiated response time is  Fig 4 Arrival rate of requests per second random ow By way of comparison we implemented the load balancing approach of Caheiros with the dif ference that we considered the propagation delay in calculating the number of requests to accept For this approach all accepted requests are passed directly to virtual machines and no request is stored at the Load Balancer The QoS criteria of comparison that we have considered are the rate of rejected requests and the average response time In our simulations we studied with each ow of requests two con“gurations The rst con“guration with 50 VMs and the second with 100 VMs The simulation scenario for each ow and for each con“guration starts rst by an execution without sharing where our Broker runs only in the infrastructure In gures 5 to 12 this case is indicated by the label   Then another execution with shared resources but without sharing of cores i.e the number of all virtual machines is equal to the number of cores In gures 5 to 12 this case is indicated by the label   Finally we considered the sharing of cores through the creation of a number of virtual machines greater than the number of cores of all physical machines In this case some of our virtual machines undergo performance degradation due to sharing cores with those of other clients The simulated degradation here is the fact that a quad-core physical machine hosts ve virtual machines instead of four In gures 5 to 12 these cases are indicated by a label that indicates the number of virtual machines affected by the sharing cores   where N takes 5,10,20,30,40 and 50 for the rst con“guration and 10,20,40,60,80 and 100 VM in the second con“guration All results which are presented in Tables I and II show a high scalability of our approach Our proposal was better in all cases without resource sharing in terms of rate of rejected requests and also in terms of average response time and that with the two used ows With the regular ow the results are shown in Figure s5-8.The case without sharing is reported with the wording   On these Figures we can see that the approach of Calheiros has rejected 36 of requests received while our approach has rejected only 23 See Figure 5 and that with the same ow and the same number of virtual machines 50 MVs With 100 MVs that observation is also con“rmed with a rejected rate of 4 against 0 for our approach See Figure 7 With the random ow the results are illustrated in Figures 9 12 With this latter ow the con“guration with 50 MVs gave as rejected rate 30 to Calheiros approach against 14 for our proposal See Figure 9 and with the 100VMs con“guration there was a rate of 1 for the Calheiros approach against 0 for our approach See Figure 11 In the case with resource sharing our proposal has proved better even with a large number of virtual machines affected by degradations relative to the total number of the virtual machines used For example in the case with 50 VMs our approach remains the best even with 30 MVs affected among the 50 MVs used Similarly with 100 VMs our approach remains the best with 80 MVs affected among the 100 MVs used with the regular ow and also remains the best with 60 MVs affected in the case with the random ow A gap of 4 to 16 of rejected requests was recorded in favour of our approach compared to the approach of Calheiros in the case of 50 MVs Also in the case of 100 MVs a gap ranging from 1 to 11 of rejected requests has been realized in favor of our approach 
min max min sim min max sim min max sim Qos 
Without other clients With other clients N VM affected B Results Without other clients 
123 
123 


We can also see that our approach has achieved a rate of rejection in some cases with sharing of resources smaller than the rate of rejection of Calheiros approach in the case without sharing For example with the rst input ow regular ow and with 50 MVs Calheiros approach has rejected more than 36 of requests received in the case without sharing while our rejected rate is less than 36 in the case of sharing with 5 MVs affected Also with the second ow and 50 MVs Calheiros has rejected in the case without sharing more than 30.5 of received requests while our rate of rejection is less than of 30.5 in the case of sharing and with 5 MVs affected The same gain is more visible with the results of 100 MVs where we can see that the rejection rate of our approach in the case of sharing and with 40 MVs affected 0.1 with the regular ow and 0.2 with the random ow is smaller than the rate of rejection of Calheiros in the case without sharing 4 with the regular ow and 1 with the random ow Fig 5 Rate of rejected requests regular ow with 50 VMs Fig 6 Average response time regular ow with 50 VMs By cons where the vast majority of virtual machines are affected by degradation the Calheiros strategy proved more effective however such cases must be very rare with the use of placement policies of virtual machines in the Clouds V C ONCLUSION In this paper we proposed a new load balancing policy that takes into account the interference of performance which may affect the QoS of virtual machines in the Clouds Our proposal was more scalable and could signi“cantly reduce the rate of rejected requests in both cases with and without resource sharing We have shown that it is possible to reduce the rate of rejected requests through optimal use of capacities of virtual machines and we were able to mitigate the degradations of some virtual machines using other non-affected virtual machines without creating an additional burden However we intend to complete this work by the introduction of a policy to predict the evolution of the intensity of ow of requests to dynamically obtain the appropriate number of instances to create or maintain to meet the desired QoS Fig 7 Rate of rejected requests regular ow with 100 VMs Fig 8 Average response time regular ow with 100 VMs 
124 
124 


TABLE I R ESULTS OF THE CONFIGURATION WITH 50 MV S First con“guration with 50 MVs With regular ow With random ow Rate of rejected requests Average response time\(s Rate of rejected requests Average response time\(s Calheiros et al Our appr Calheiros et al Our appr Calheiros et al Our appr Calheiros et al Our appr Without other clients 36.38023087 23.04969705 0.414686277 0.383954839 30.52908630 14.25401522 0.413871682 0.365914836 With other clients 49.55860674 35.36702438 0.494716391 0.422682357 43.23516982 27.89241114 0.491096770 0.412797386 5 VM affected 50.14398848 35.80330511 0.500041940 0.422931257 43.85757646 30.17867435 0.495733101 0.424767758 10 VM affected 50.65051939 38.05842219 0.504730973 0.430043614 44.52896880 30.87415946 0.500986983 0.426256189 20 VM affected 51.79385649 41.14495834 0.515878981 0.428933452 45.76033502 34.63688761 0.509631907 0.431173803 30 VM affected 52.80606123 50.01885693 0.526049184 0.453064016 46.97537268 42.54755043 0.516578800 0.462713728 40 VM affected 53.83883575 60.69616347 0.536385729 0.513979239 48.17792377 54.84630163 0.522670341 0.533942976 50 VM affected 54.91017861 58.82332773 0.547408134 0.473514024 49.41217151 54.57348703 0.526906162 0.507099359 TABLE II R ESULTS OF THE CONFIGURATION WITH 100 MV S Second con“guration with 100 MVs With regular ow With random ow Rate of rejected requests Average response time\(s Rate of rejected requests Average response time\(s Calheiros et al Our appr Calheiros et al Our appr Calheiros et al Our appr Calheiros et al Our appr Without other clients 4.067291129 0.055704577 0.387953494 0.321167767 1.137324214 0.107584723 0.357782231 0.321221182 With other clients 8.521086325 0.095983271 0.426892019 0.325050584 2.528046719 0.049946212 0.378495964 0.330125478 10 VM affected 9.148405564 0.033422746 0.436156605 0.331177693 3.010219763 0.089326879 0.386489549 0.340561438 20 VM affected 10.04224978 0.035136733 0.444655287 0.338026920 3.532733979 0.172890733 0.392412819 0.346527213 40 VM affected 11.79565847 0.101125232 0.460891726 0.353294316 4.470185954 0.203626863 0.405603688 0.358656277 60 VM affected 13.51564442 4.190698193 0.476101863 0.389089878 5.534424466 2.200514830 0.418869920 0.400364617 80 VM affected 15.21677650 14.20123921 0.490738204 0.428358087 6.613070539 9.272706316 0.433567487 0.457040143 100 VM affected 16.96675722 28.69128523 0.505174113 0.487234262 7.815621638 22.97621792 0.449540143 0.502292300 Fig 9 Rate of rejected requests random ow with 50 VMs Fig 10 Average response time random ow with 50 VMs Fig 11 Rate of rejected requests random ow with 100 VMs Fig 12 Average response time random ow with 100 VMs 
125 
125 


R EFERENCES  A E Bork o Furht 
 Springer 2010  I T  F oster  Y  Zhao I Raicu and S Lu Cloud computing and grid computing 360-degree compared  vol abs/0901.0131 2009  A v ailable http://arxi v or g/abs/0901.0131  R Buyya J Brober g and A M Goscinski  Wiley Publishing 2011  R Buyya C S Y eo S V enugopal J Brober g and I Brandic Cloud computing and emerging IT platforms Vision hype and reality for delivering computing as the 5th utility  vol 25 no 6 pp 599…616 2009 A v ailable http://dx.doi.org/10.1016/j.future.2008.12.001  S Ferretti V  Ghini F  P anzieri M Pelle grini and E T urrini Qosaware clouds in  ser CLOUD 10 Washington DC USA IEEE Computer Society 2010 pp 321…328 A v ailable http://dx.doi.org/10.1109/CLOUD.2010.17  R N Calheiros R Ranjan and R Buyya V irtual machine provisioning based on analytical performance and QoS in cloud computing environments in  G R Gao and Y.-C Tseng Eds IEEE 2011 pp 295…304 A v ailable http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=6046213  Y  K oh R C Knauerhase P  Brett M Bo wman Z W en and C Pu  An analysis of performance interference effects in virtual environments in  IEEE Computer Society 2007 pp 200…209 A v ailable http://doi.ieeecomputersociety.org/10.1109/ISPASS.2007.363750  T  Cucinotta D Giani D F aggioli and F  Checconi Pro viding performance guarantees to virtual machines using real-time scheduling in  ser Lecture Notes in Computer Science M R Guarracino F Vivien J L Tr  aff M Cannataro M Danelutto A Hast F Perla A Kn  upfer B D Martino and M Alexander Eds vol 6586 Springer 2010 pp 657…664 A v ailable http://dx.doi.org/10.1007/978-3-642-21878-1  V  C Emeakaroha I Brandic M Maurer  and I Breskovic SLA-aware application deployment and resource allocation in clouds in  IEEE Computer Society 2011 pp 298…303 A v ailable http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=6032032  J Li J Chinneck M W oodside M Litoiu and G Iszlai Performance model driven qos guarantees and optimization in clouds in  ser CLOUD 09 Washington DC USA IEEE Computer Society 2009 pp 15…22  A v ailable http://dx.doi.or g/10.1109/CLOUD.2009.5071528  R Nathuji A Kansal and A Ghaf f arkhah Q-clouds managing performance interference effects for QoS-aware clouds in  C Morin and G Muller Eds ACM 2010 pp 237…250 Available http://doi.acm.org/10.1145/1755913.1755938  H N V an F  D T ran and J.-M Menaud SLA-a w are virtual resource management for cloud infrastructures in  IEEE Computer Society 2009 pp 357…362 A v ailable http://doi.ieeecomputersociety.org/10.1109/CIT.2009.109  Z W ang X T ang and X Luo Polic y-based SLA-aware cloud service provision framework in  IEEE 2011 pp 114…121 A v ailable http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=6088022  Q Zhu and G Agra w al Resource pro visioning with b udget constraints for adaptive applications in cloud environments in  S Hariri and K Keahey Eds ACM 2010 pp 304…307 Available http://doi.acm.org/10.1145/1851476.1851516  R N Calheiros R Ranjan A Beloglazo v  C A F  D Rose and R Buyya Cloudsim a toolkit for modeling and simulation of cloud computing environments and evaluation of resource provisioning algorithms  vol 41 no 1 pp 23…50 2011  A v ailable http://dx.doi.or g/10.1002/spe.995 
Handbook of Cloud Computing CoRR Cloud Computing Principles and Paradigms Future Generation Comp Syst Proceedings of the 2010 IEEE 3rd International Conference on Cloud Computing ICPP ISPASS Euro-Par Workshops COMPSAC Workshops Proceedings of the 2009 ICSE Workshop on Software Engineering Challenges of Cloud Computing EuroSys CIT 1 SKG HPDC Softw Pract Exper 
126 
126 


607 


608 


  11 that it will be able to meet all of the Van Allen Probes communications goals with its intended ground segments A CKNOWLEDGEMENTS  This work was performed with the support of the Radiation Belt Storm Probes mission under NASA\222s Living with a Star program. The authors would like to thank Rick Fitzgerald and Kim Cooper, Van Allen Probes project managers at JHU/APL for supporting this work. There are many at JHU/APL who contributed to the development and verification of the RF system. Significant technical contributions were made by: Christopher Haskins, Bob Wallis, Matthew Angert, Laurel Funk, Joe Sheehi, Wesley Millard, Norman Adams, Lloyd Ellis, Sheng Cheng, John Daniels, Phillip Huang, Avi Sharma, Carl Herrmann, David Jones, Brian Bubnash, Melanie Bell, Horace Malcom Michael Pavlick, Mark Bernacik, Christopher Deboy, Bob Bokulic, Sharon Ling, Albert Hong, Erik Hohlfeld, Judy Bitman, William Dove and Tony Garcia. Significant contributions were also made by the USN and TDRSS compatibility test teams  R EFERENCES  1 eck D. G.; Mau k  B  H.; Greb o w sk y  J  M.; Fo x  N J, \223The Living With a Star Radiation Belt Storm Probes Mission and Related Missions of Opportunity 224 American Geophysical Union, Fall Meeting 2006   h o rs k i y  A Y., Mauk B. H., Fox N. J Sibeck D G., Grebowsky, J. M., \223Radiation belt storm probes Resolving fundamental physics with practical consequences,\224 Journal of Atmospheric and SolarTerrestrial Physics Vol. 73, Issues 11-12, July 2011 Pages 1417-1424   S. Bu s h m a n M. Bu tler, R C o n d e, K. Fretz, C  Herrmann, A. Hill, R. Maurer, R. Nichols, G. Ottman M. Reid, G. Rogers, D. Srinivasan, J. Troll, B. Williams 223Radiation Belt Storm Probe Spacecraft and Impact of Environment on Spacecraft Design,\224 Proceedings of the 2012 IEEE Aerospace Conference, Big Sky Montana USA, March 3-10, 2012   opelan d D.J DeB o y C  C R o y s ter, D.W., Dov e  W.C., Srinivasan, D.K,. Bruzzi, J.R., Garcia, A., "The APL 18.3m station upgrade and its application to lunar missions," Aerospace Conference, 2010 IEEE , vol., no pp.1-10, 6-13 March 2010    Figure 10. FER/BER performance for all downlink modes for RF GSE, SCF, USN, and TDRSS 


  12  iv as a n D. K., A r ti s  D  A Bak er, R  B., Stil w e ll, R   K., Wallis, R. E., \223RF Communications Subsystem for the Radiation Belt Storm Probes,\224  Acta Astronautica vol 65, issue 11-12, December 2009, Pages 1639-1649   k i n s  C B., Mi llard, W P 223 M u l t i Ban d  So f t w a re Defined Radio for Spaceborne Communications Navigation, Radio Science, and Sensors,\224 2010 IEEE Aerospace Conference, March 2010  k i n s  C B., Mi llard, W P A d a m s  N. H Sri n i v a s a n  D. K., Angert, M. P., \223The Frontier Software-Defined Radio: Mission-Enabling, Multi-Band, Low-Power Performance,\224 61st  International Astronautical Congress IAC-10.B2.5.11, October 2011 8  Crowne, M.J.,  Haskins, C. B., Wallis, R. E.,  Royster D.W, \223Demonstrating TRL-6 on the JHU/APL Frontier Radio for the Radiation Belt Storm Probe mission,\224 2011 IEEE Aerospace Conference, March 2011  o ckw ood, M. K K i n n i s o n  J., F o x  N C o n d e, R  Driesman, A., \223Solar Probe Plus Mission Definition,\224 63rd  International Astronautical Congress, IAC 12.A3.5.2, October 2012   i t m a n J  223An I n D ept h  L o o k at t h e R a dio Freq u e n c y    Ground Support Equipment for the Radiation Belt Storm  Probes Mission,\223 IEEE Autotestcon, 2011, September 2011  d a m s  N.H., Bi t m a n J C opela n d D. J Sri n ivas a n  D  K.,  Garcia. A., \223RF Interference at Ground Stations Located in Populated Areas,\224 2013 IEEE Aerospace Conference, March 2013  B IOGRAPHY  Matthew J. Crowne is a member of the Senior Professional Staff of the RF Engineering group in JHU/APL\222s Space Department. He received his B.S from Johns Hopkins University in 2000 and his M.S. from the same university in 2009, both in electrical engineering Matthew joined JHU/APL in 2007 where he has been working on the development of radios for spaceflight communications systems. Prior to joining JHU/APL, he worked for Integrated Defense Systems Inc., where he developed solid state power amplifiers for electronic warfare and communication systems. Matthew was the integration and test lead for the Van Allen Probes RF communication system and is currently working on the Solar Probe Plus mission   Dipak K. Srinivasan is the supervisor of the RF Systems Engineering Section in the JHU/APL Space Department. He received his B.S. and M.Eng. in electrical engineering in 1999 and 2000 in electrical engineering from Cornell University, and an M.S. in applied physics from The Johns Hopkins University in 2003. Dipak joined the APL Space Department in 2000, where he has served as the lead RF Integration and Test Engineer for the CONTOUR and MESSENGER spacecraft and lead mission system verification engineer for the New Horizons project. He is currently the Lead RF Telecommunications Systems Engineer for the MESSENGER and Van Allen Probes missions and chairs technical sessions at the annual International Astronautical Congress  Darryl W. Royster is a member of the Senior Professional Staff in the RF Engineering Group at JHU/APL.  He led compatibility testing for the Van Allen Probes, STEREO, and MESSENGER missions.  Previously he was the System Engineer for the Satellite Communications Facility at JHU/ APL and the lead RF Integration and Test Engineer for the STEREO spacecraft.  Prior to joining the JHI/APL Space Department in 2001, Mr. Royster designed cellular and land mobile radio products for Ericsson, GE and Motorola.  He received his B.S. and M.S. in electrical engineering from Virginia Polytechnic Institute and State University in 1982 and 1984, respectively  Gregory L. Weaver joined the Senior Professional Staff of JHU/APL in 2003 and works within the RF Engineering Group of the Space Department.  He is a technologist with extensive background in the technical and business aspects of the frequency control industry and has held positions as a senior design engineer, technical manager and marketing strategist over a 25 year career history, including vice president positions with Bliley Technologies Inc. and the former Piezo Crystal Company. He received his M.S in Technology Management from the University of Pennsylvania in 1993 and his B.S. in Physics from Dickinson College in 1982.  He is a licensed professional engineer in the state of Pennsylvania, member of the IEEE and the UFFC Societ y.  He has contributed to the technical proceedings of the IEEE International Frequency Control Symposium, Precise Time and Time Interval Systems and Application Meeting and the European Frequency and Time Forum   


  13 Daniel Matlin is an Associate Professional Staff at JHU/APL and a member of the RF engineering group in the Space department.  He went through a dual Bachelors/Masters program at Johns Hopkins University graduating with his Bachelor of Science in Electrical Engineering in 2008 and his Masters of Science in Engineering from the Electrical Engineering department in 2009.  As a student he specialized in RF systems design.  Mr. Matlin started at the JHU/APL in February of 2010 and in his short time with the lab has been privileged to work on various tasks supporting the RBSP program, including supporting a successful launch and early operations.  Mr. Matlin assisted in the qualification testing for the flight DSP slices as well as the integrated flight transceivers.  He also carried out electrical testing and flight qualification of the newly designed Hypertronics stacking connectors as well as components and cables used for the RF subsystem  Nelli Mosavi is an EMC and RF Engineer in the JHU/APL Space Department, RF Systems Engineering section. She received a B.S. degree in Electrical Engineering from Oakland University Michigan in 2004 and an M.S. in Electrical Engineering from The Johns Hopkins University in 2010. She is currently working toward her Ph.D. at the University of Maryland Baltimore County. She joined APL in 2009 and has since been working on RF and EME issues on the Van Allen Probes mission. Nelli previously worked for SENTEL Corporation, General Motors, DENSO International, and Molex Automotive   


APPENDIX 3– RESULTS \(SEM I-PROFESSIONAL DSLRS     Run by TFDEA add-in ver 2.1 Frontier Type Orientation 2nd Goal Return to Scale Avg RoC Frontier Year MAD Dynamic OO Max CRS 1.124802 2008 1.394531 Input\(s Output\(s SOA products at Release SOA products on Frontier RoC contributors Release before forecast Release after forecast 22166527 DMU Name Date Efficiency_R Efficiency_F Effective Date Rate of Change Forecasted Date 1 Nikon D100 2002 1 1.66666667 2007.000000 1.107566 2 Olympus E1 2003 1 1.666666667 2007.000000 1.136219 3 Pentax *ist D 2003 1 1.358024691 2007.000000 1.079511 4 Nikon D20 0 2005 1 1.2 2007.000000 1.095445 5 Canon EOS 5D 2005 1 1.664796311 2007.730028 1.205269 6 Pentax K10D 2006 1 1 2006.000000  7Nikon D30 0 2007 1 1 2007.000000  8 Olympus E3 2007 1 1 2007.000000  9 Sony Alpha DSLR A70 0 2007 1 1 2007.000000  1 0 Nikon D70 0 2008 1.46 1.46 2007.000000  11 Canon EOS 5D Mark II 2008 1.065464119 1.065464119 2008.000000  12 Sony Alpha DSLR A90 0 2008 1 1 2008.000000  13 Olympus E3 0 2008 1.02 1.02 2007.000000  1 4 Pentax K20D 2008 1 1 2008.000000  15 Nikon D300s 2009 1.142857143 0.874450785 2007.000000  2008.140742 16 Canon EOS 7D 2009 1 0.754166667 2007.000000  2009.399022 17 Sony Alpha DSLR A85 0 2009 1 0.774820627 2008.000000  2010.169290 18 Pentax K-7 2009 1 0.772738276 2006.503130  2008.695302 19 Olympus E5 201 0 1.466133763 1.173333333 2007.000000   2 0 Pentax K-5 201 0 1.009024674 0.776190476 2007.000000  2009.15427 0 21 Nikon D80 0 2012 1 0.686950618 2008.000000  2011.192776 22 Canon EOS 5D Mark III 2012 1.115010291 0.930769231 2007.502755  2008.112786 23 Pentax K-5 II 2012 1 0.632075669 2006.839705  2010.740375 24 Sony Alpha SLT A99 2012 1.009662059 0.854117647 2007.640496  2008.981286 Results 2129 2013 Proceedings of PICMET '13: Technology Management for Emerging Technologies 



Sushil Jajodia  George Mason University Fairfax, VA, USA  jajodia@gmu.edu   Witold Litwin  Lamsade, UniversitÈ Paris Dauphine Paris, France  witold.litwin@dauphine.fr    
002 002  
002 
Key Recovery Using Noised Secret Sharing with Discounts Over Large Clouds 
Abstract 
 
Encryption key loss problem is Achillesês heel of cryptography. Key escrow helps, but favors disclosures. Schemes for recoverable encryption keys through noised secret sharing alleviate the dilemma Key owner escrows a specifically encrypted backup. The recovery needs a large cloud. Cloud cost, money trail should rarefy illegal attempts. We now propose noised secret sharing schemes supporting discounts.  The recovery request with discount code lowers the recovery complexity, easily by orders of magnitude. A smaller cloud may suffice for the same recovery timing Alternatively, same cloud may provide faster recovery etc.  Our schemes appear useful for users attracted to Big Data, but afraid of possibly humongous 
consequences of the key loss or data disclosure 
Keywords-clouds; big data; privacy; key recovery 
I INTRODUCTION Key recovery is a classical goal.  Key escrow, i.e entrusting a key copy with some \(escrow\agent, was proposed as a basic solution. The idea did not catch Key owners seem fearing the key disclosure, as source of irresistible temptations for some. More complex key escrow schemes, e.g., with recovery rights verification or through secondary encryption of the copy with the key entrusted to another party, are almost no noticeable in practice. See the related work section in [3  No t having key escr ow on th e oth er  
 
 
hand, exposes the data to the key loss, especially if the owner disappears with. Modern encryption schemes, e.g., AES, make data unrecoverable then The fear of key loss particularly concerns many users attracted to Big Data idea.  It is the common knowledge that safety and efficiency of related manipulations require the data outsourcing to some cloud. However, one knows well that most users are reluctant to outsource data in clear M a ny canêt  do it simply by law. Many pro may accept therefore the idea only if they may  encrypt  the  outsourcing A  homomorphic  code allows  in particular  for  the Thomas Schwarz Universidad CatÛlica del Uruguay Montevideo, Uruguay 
 tschwarz@ucu.edu.uy         arithmetic  calculations  over  the encrypted data directly\ in the cloud,  [6   T h is is a  strong ne ed  as  many  Big  Data  queries  use value expressions distributed in addition for efficient evaluation using Map-Reduce, [5  Even wit h all these to o ls  m a ny o r most of these users remain deterred up to now. Big Data may render indeed key loss consequences accordingly huge. It could worth years of work of many people. Vice versa, a misuse of an escrowed 
key copy may result in the cloud content disclosure This may lead to consequences of scale equally calamitous Schemes for 
  RE NS schemes in short appeared as a new solution to the dilemma a n d   h e k ey own er escr o w s a specif ica l ly  encry pt ed  backup. The brute-force key recovery, from the backup alone, is always feasible although intentionally hard. Its complexity, as measured by the number of instructions the recovery may need, is arbitrarily fixed by the owner, depending on the trust 
recoverable encryption through noised secret sharing 
in the escrow agent.  As the result, the recovery timing on the escrowês site \(node\ alone, should become impractical, e.g., should last dozens of days at least. This timing results from some key-owner defined integer 
called  providing   worst-case complexity Nevertheless, the actual maximal recovery time desired by the recovery requestor remains practical 
M backup \(encryption hardness O M   
The recovery uses a su fficiently large 
node cloud providing about linear  recovery speed-up Practical timing, e.g., in minutes, is expected to imply in thousands.  The escrow is not expected to maintain such a large cloud on premises.  Hiring it from some external provider is then is a necessity That one should be usually somehow costly and easily noticeable through numerous logs, money trailÉ.  One may expect illegal disclosure attempts e.g., by an escrow side insider, to rarefy. They may be 
NO M / N N 
SocialCom/PASSAT/BigData/EconCom/BioMedCom 2013 978-0-7695-5137-1/13 $26.00 © 2013 IEEE DOI 10.1109/SocialCom.2013.105 700 


q g 
002 002 
discount discounted recovery full-cost m m m m m m m m au finale static scalable k  k K O s s K s K s s O D D D D C hint h H s H  h s H s  H h  C M  match attempts H s h s s M   D  g M C M r s  r M C q I M r q q r s C r  g g M g M C r s p s p s p r  x noise I noise space f p base noise s noised s P p h M P s  M noise s f x x M 
0 and 1  0 Fig. 1a. It is the common knowledge that 0 XOR 1 Next 0  using some one-way hash function 0 and ii\impossible for good 0 1  0   sufficient to find the successful match. Also 0 0 and recalculates both shares accordingly. Next 0 i.e produces the integer 0 2 0  0 a 0 that is 0 
 
expected much less tempting than from a simple key copy We now extend known RE NS schemes with the concept of As the name suggests, a discount results from a code that lowers the recovery cost with respect to the brute-force one. The reduction is easily by orders of magnitude as it will appear. We speak then about the We furthermore rather designate the brute-force one from now on as the one. Technically, the code lowers the recovery complexity for both the worst and the average cases The code is an bit string 0,1É. The 0 tacitly means the no-discount request, i.e., the fullcost one. Otherwise, we expect 8 or 16 at most, in practice. With respect to the full-cost recovery, such codes lower both complexities respectively 256 for 8 and 64K times for 16 The minimal actual discount is for 1 and is 50 Accordingly, the discount may greatly reduce recovery timing and/or the cloud size and  the cloud cost for the requestor The code may appear to the key owner in some convenient form. The minimal discount requires only retaining that the code is even or odd. Otherwise, one choice may be a single 16b Unicode digit. Or, it can be one or two \(extended\ 8b ASCII digits Alternatively, one may choose 2 ˜ 4 hex digits, etc One expects such codes easy to retain, e.g., on a smartphone, or simply in memory. Especially, it should be very easy for the minimal discount. Recall that Europeans are routinely trained to keep in mind their 4-digit credit card codes. They are strongly advised not to store them anywhere, \(especially on the credit cards themselves The requestor sends the discount code to the escrow within the \(discounted\ recovery request. The code amends the processing of the otherwise always feasible full-cost recovery. For any given key, only specific codes lead to a discounted recovery.  Any discount provided triggers nevertheless a recovery attempt with the associated cost. An unsuccessful attempt also respects the requestorês timeline. It doubles however the average cost of the successful one. Finally, every code is granted successful only for one key. For any other one, it basically acts as purely\m guess of what should be the actual one.  With costly consequences, we just discussed All together tampering with a discount code should be infrequent Globally, we show below that for all these reasons discounts appear a highly useful capability for an RE NS scheme. The existing 2-share schemes generalize easily. The key remains çnever-losté, with illegal\osure cumbersome at will for the attacker. Yet, the legal recovery by the discount possessor remains cheap and thus practical. This combination is unique up to now for a key recovery scheme. Especially, it can greatly help the already mentioned potential Big Data users Below, we first define and analyze the RE NS  schemes with discounts using, so-called 2-share noised secret sharing. We generalize for this purpose the two related schemes defined in [2   These are tol d  respectively and and are analyzed further more in depth We de f ine the backup and the discount creation, then the discount-based recovery calculation. Next, we analyze the correctness, the complexity and the safety of the resulting schemes. Afterwards, we generalize the 2share recovery calculation to a 1 share one with 1 at key owner will. We show attractive property of such schemes. Next, we briefly address the related work and we finally conclude.  Space limitation forced us to evacuate all the figures we discuss into  II BACKUP CREATION Let be the key to backup, e.g. a 256b long AES key. The key owner or rather the ownerês client program, running on ownerês site, say in every case, first creates a usual 2-share secret, with shares say XOR  chooses some time e.g., 70 days is the intended recovery time at the escrowês site alone, assuming it a 1-node core\ configuration. The choice of value reflects Oês trust in the escrow service that that no \(illegal disclosure attempt occurs there.  Lower it is, higher should be After that, Fig. 1b defines the    e.g SHA 256  We recall that in practice \(i is unique for any such as the one mentioned, to calculate as  Next determines the backup hardness This parameter is the maximal number of     where each is a different integer that could be is the ownerês expectation of the number of match attempts that 1-node site may perform at most in time Next if there is no 1, 2É such that 2 then verifies whether the log 2  bit long suffix of is  If not, then chooses random  0  and sets up  i.e., substitutes as new suffix of calculates the bit-length of i.e., calculates an integer such that either log 2 when such value exists or  log 2  Then cuts off from  where denotes thus in fact the remaining prefix of    As i we c al l below each  a and is the Then  0É0 is the share while one. The naming comes from the backup representation of      makes hidden somewhere among different  shares, formed each as     0,1 1 Fig 
002 003 004 002 003 
701 


m m  m 
  
002 002 
 noise share space Q Q I M  s s x r s s  s P s s discount discount code m s m m discounted m m discount value m  discounted \(backup\ hardness, i.e M I I  M M r r r d r I  m m Au finale s s  s  s d d s d A Recovery Request P d P, R, d R R B Full-Cost Recovery m d  full-cost 
0 This happens iff 0   The backup 1  0 that could lower the recovery complexity. For instance, the key owner could observe that 0 is an odd integer. This would lower the complexity by 50%, as we show. We say that any such knowledge defines a 0  0 0000 0000 0110 1010ê. In Unicode the owner sees the 16b suffix above, qualifying for the discount code, as a single symbol èjê, hence we have 0  0  0 is an even integer. The owner retains as discount code representation for storage somewhere or simply for memory, the Unicode representation, i.e., èjê. Later, this same single character may represent either discount code: the 8blong 0 is even. At the minimum, the code 
 
1b The noise shares form the say with card card   Each is an integer, as we just said and can be  The only known way to find out is to attempt the match By the well-known properties of a good 1-way hash this one succeeds iff  sent to the escrow is the couple  Notice that, while the backup creation is quite similar to e fin i ti o n o f noi se s h ar es  differs. The rationale \(that we do not plan to address further here\ is a programmatically simpler discount calculation III DISCOUNT DEFINITION In [2 u ll-cost r ec o very, i.e   usi ng exclusively the backup as above defined, was the only capability of RE NS schemes defined there. One may nevertheless observe that the requestor could also forward with the backup request some prior knowledge of of 50% in this case More precisely, the key owner defines the discount for a given backup according to an RE NS  scheme, by choosing some For what follows, the code is simply an bit suffix of the noised share 0,1É.Fig. 2. The value of 0 tacitly means the no-discount request, i.e., the fullcost one. Otherwise, as we signaled already, we will talk about a recovery. We expect for the latter 8 or 16 at most in practice. We call the complexity reduction that the recovery with the code offers with respect to the fullcost. The analysis later on shows that the value of any bit long code is 2 for both, worst case and average complexities The reason for such value is the 2 times smaller the accordingly smaller maximal number of match attempts towards the successful one for sure. That discount with respect to characterizing the full-cost recovery, is due to smaller noise space That one becomes of size   2 Fig. 2. We will show it in the sections that follow. Notice nevertheless already that the suffix must be   for some noise   We expect accordingly in practice the reduction of the worst case, as well as of the average, complexity of up to 2 8  256 for 8 and 2 16 64K times for 16 Discount codes that short may appear to the key owner as a single 16b Unicode digit or as one or two extended\ 8b ASCII digits, or as 2 ˜ 4 hex digits One may expect them generally easy to retain, e.g., on a smartphone, or just in memory. Recall that Europeans are routinely trained to keep in mind their 4-digit credit card codes As the result that will appear, these codes may lower the recovery time 2 8 ˜ 16 times with respect to the full-cost timing for the same cloud size Alternatively, they may reduce the cloud size by the same value, while keeping the same timing. The discounted hardness also allows combining both reductions the discount decreases the cloud cost. Obviously, the necessary condition for a successful match attempt is that the noise share embeds the code provided.  The rationale for the discounted recovery algorithm we define in next section is to attempt matches only for such shares Ex. 1. Key ownerês client key encryption generates jê. In extended ASCII, the bits appear as two characters  jê, where denotes the NULL, i.e., è00ê character. Finally, the owner observes that 0110 1010ê in ASCII and the 16b-long 0000 0000 0110 1010ê. The owner may decide only when needed which discount to choose. The former will offer the discount value of 256 times, the latter will provide 64K times hardness reduction.  As 2 nd line protection against loosing even this simple code value, the owner retains that 0ê will still provide 50 discount, as it will appear. In the very last but not least, resort, the full-cost recovery is always feasible RECOVERY The escrow performs the recovery upon the legitimate request. How the escrow knows which request is legitimate is out of scope here.  Recovery schemes with discount discussed below reuse the scheme for full-cost only recovery defined in d  e r eco v e r y requ est  h as i n particular th e sa m e  form, augmented however with the discount code.  It is thus formally the tuple  s for the full-cost only recovery requ her e designates the desired maximal recovery time, e.g., 10 min. Recovery schem as well as t hos e belo w  consider then as the upper bound on recovery computation time over any cloud node used.  They thus fulfill the userês desire for sure provided the cloud overhead consisting of messaging, node allocation etc. times, is negligible If the request has no discount, i.e 0 in  the escrow proceeds with the recovery. The schemes in [2 then as th ey ar e, exce p t for the  
004 005 005 
702 


m 
002 002 
s  P d C coordinator s C static scalable f m m I N O N N N s  s  C Discounted Recovery m discounted recovery scheme d reduced d I x M M M d reduced x x d p s  p x d x H p x d H p r d h d I C M M m I M C M M N M R C N d N n n N n N  N N  base share f d f p d f f f f m M  x s H s h x  s s f x  n n s s s  C C x termination C s C s C m C s C  m  C s invalid d s m C C d 
0 1 In this way no cloud insider can disclose the recovered key With respect to the actual execution on the cloud managed by 0 1 0 0 0  1 and returns the recovered key to the requestor 0 or there is the failure of a cloud node or of the network connection between 0 a new cause may be the 0   The legitimate requestor made perhaps an error, or the discount came from an intruderÉ As before, the cause may be also a cloud failure, as for 
 
revised base noise share definitions.  The escrow forwards thus to some cloud node called with the exception of we recall now that [2 de f ines t w o basic schemes. We called them respectively and partitioning. The former was proposed for a homogenous cloud. The latter targets a heterogeneous one. Their common characteristic is that the recovery calculations attempt the matches over different noise shares  until the successful match. This one must occur, but attempts may possibly explore even every in Both schemes partition the attempts over nodes, with the linear speed-up   choice of value depends on the scheme. In both cases, it makes the recovery computation at each node fitting the time bound provided by the requestor, e.g 10 mins. As the result, the whole calculation fits this bound. Typically should be possibly in thousands as we discussed The cloud delivers the noised share found to the escrow. The escrow XORs it with and, finally delivers the key to the requestor The discounted recovery request differs from the full-cost one by additional presence of the discount code with 0.  The cloud uses then the that follows. Its rationale is that the noised share has to have as m-bit long suffix, Fig. 2 The only noise shares in the noise share space that could match must have the same suffix. The recovery processing should generate all and only such shares We say they form the noise share space. The prefixes of noises in these shares, preceding suffix in each noise, must form a subspace with noises 0,1 1 where is with cut off from its binary representation. We call it noise space One may explore only this space. The exploration should form for each visited noise the noise  It then should concatenate it then with prefix of to form noise share   belonging to the reduced noise share space, for the match attempt. The successful match occurs when for some          See Fig. 2 for j The exploration of may use either partitioning scheme for full-cost recovery in [2 or [3]. The det ai ls o f t h e  scheme we sketch now follow these considerations We explain it more and finalize its correctness proof afterwards 1 calculates  2 m  2 For 0, Step \(1\ defines the reduced noise space 0 we spoke about initiates the static or the scalable scheme for this space, i.e., uses instead of We recall that this step determines later in function of and  3 delivers to each of nodes the çusualé full-cost request for match attempts and the discount code  The delivery is direct for the static scheme, and may be indirect for the scalable one, [2   Th e scalab le  scheme determines progressively, while propagating the request for match attempts 4 Each node  with 0,1 1 for the static scheme and perhaps noncontiguous integers for in some [0  where 002  for the scalable one, one first calculates the  for the discounted recovery. According to what we have said, we define it as the smallest possible with the suffix i.e. we clearly have  0 Notice that generalizes for full-cost recovery, since  for 0 5 Next, using instead of M, every node calculates one after another every value of noise for which it should generate noise share for match attempt    For each used, each node calculates as   2 The noises used at each node depend on and on the distribution scheme used, in the same way as for the full-cost recovery Fig. 3 illustrates the issue that we address also in depth later in this section 6 As for the full-cost recovery, every node attempts the match for each If the match occurs, the node reports as the noised share to unless the node is itself. The node terminates the service then, freeing all the resources 7 Otherwise, the node continues the attempts. It does so until the last relevant or until the node receives the message from This one requests the node to terminate, i.e., to stop the service and free all the resources 8 Assuming the cloud finds in this way returns it to the escrow. The escrow XORs it with sends also out to the already mention termination message For the static scheme it may send it simply directly to every node. It may alternatively send indirectly to most of the nodes, through the direct send-out to a few selected ones only that propagate it further in parallel. For the scalable scheme, the latter strategy is usually the only possibility. Space limits prevent dealing with more details 9 For 0, i.e., the full-cost recovery must get and that node. One can reasonably expect such a failure to be very rare We thus avoid discussing here the related details Rules indicated for schemes without discount applies fully, besides 10 For 0 in contrast if does not get  that is different from the actual one in 0  cannot distinguish from the above scheme between the cases acts then as if 
          
703 


m m m m 
002 002 
C d  d C d d  C Discussion N M M M n n N x M x N n M N M N N M M M n n N x M x N n M N M N m  M N M N m m m M f p p m d C M M f p M M N n  x x x N x M x f s f  s f s p s f s p x x x N x s f s p s s s f  s p n x M x N n  d s d d C d m m A Correctness I f d  N   d I 
0 should normally be 1/1K. Everyoneês experience with PINs of credit cards, passwordsÉ, shows errors once every relatively few uses, perhaps once every couple of dozens at most. The invalid 
  
was invalid. The rationale is that this cause may be expected orders of magnitude more likely than the others reports to the escrow accordingly. It then terminates as discussed in Step 8 11 As the result, we expect the requestor to usually send a different The whole algorithm restarts. Very rarely, the requestor may confirm nevertheless as valid starts then a specific procedure. That one also restarts the recovery, but with additional features These discriminate for sure at termination time whether there is a failure or is invalid. The former case can still çhideé an invalid  In the latter case reports to the escrow again that informs the recovery requestor accordingly. There are various ways to design that procedure.  All should be nevertheless more complex, hence more expensive, than the basic one above. Again, we cannot address the related details here Fig. 3 and Ex. 2 below illustrate the discounted recovery algorithm. The figure shows the distributed partitioned noise and noise share spaces over nodes, for the discounted recovery using the static scheme and code èjê from Ex. 1. The total size of the noise space and that of the noise share space is now As for for the full-cost recovery in [2 u t  for here, a noise subspace on node  0,1 1 ; contains each and every noise  and such that mod  The size of each noise subspace is  or is  1. The sizes of noise share subspaces at each node are accordingly the same Fig. 3 and Ex. 2 illustrate the discounted recovery algorithm. The figure shows the distributed partitioned noise and noise share spaces over nodes for the discounted recovery using the static scheme and code èjê from Ex. 1. The total size of the noise space and that of the noise share space is now As for for the full-cost recovery in t f o r  here a noise subspace on node  0,1 1 ; contains each and every noise  and such that mo d  The size of each noise subspace is  or is  1. The sizes of noise share subspaces at each node are accordingly the same These sizes are in practice 2 times smaller for 0 than for and the same in [2 It is the sa m e  for with the same and 0 and in the algorithm above, generating then the full-cost recovery. At each node, the discounted recovery has accordingly 2 times less match attempts to perform at worst for any 0, than for 0. This property leads to new possibilities for the recovery requestor aiming at best advantage of a discount. We address these issues in Section 5 below Ex. 2 Consider 2 50 which should be rather typical. Suppose the noise shares 256b long, as an AES key. We have the base share \(for the full-cost recovery  0É.0000ê with some prefix and zero value suffix over 50 bits. Suppose further 2 and 01 calculates as 2 48 The base noise share for the discounted recovery is  0É00000000000|01ê. Suppose the use of the static scheme and that after the calculations for as in [2 f o r we have 1K, hence 0,1É1023  Node 0 attempts the matches for noises 0 1024 2048É, i.e., with each successive such that mod 0 and till the largest such  Each is multiplied by 2 2 then added to then node 0 attempts the match of the resulting noise share, etc In particular, node 0 always starts with the match attempt for   If no success, next attempt is for  1024*4 hence  0É010000000000|01 Then, if needed, there is the attempt for  2048*4 i.e  0É100000000000|01 etc. Likewise, node 1, attempts the match for noise 1. Then, may continue for 1025, 2045É., i.e where mod 1 and till the largest such M Node 1 starts thus with the attempt for  1*4 i.e  0É00000000001|01 Perhaps continues then for  1024*4 i.e  1025*4 that is for  0É10000000001|01ê etc. In general, as on Fig. 3, every node attempts in this way the matches for each and only  that yields mod   The scalable partitioning has a more complex rule see, e.g., [2 o r i t   With respect to Steps 10 & 11, the rationale for acting first as if was invalid is easy to see Assuming the use of a 1K-node cloud and the cloud sufficiently reliable to make a double failure among these nodes unlikely, the probability that a failure strikes just the node that should find case should thus happen dozens of times more often Next, observe that until the procedure in Step 11 the cloud acts in the same way for valid and invalid  There is no way for to distinguish between both upfront. An invalid will thus cost the requestor more. This feature is intentional, expected to curb the discount tampering The integer division è\\ê  by 2 amounts to bit right shift. Likewise, the multiplication by 2  performs the bit left shift. Dedicated shift functions may be faster than the arithmetic calculations. There are thus various ways to implement the algorithm we do not address further here IV ALGORITHM ANALYSIS Basically, it should appear that for every every  and every each RE NS schema under consideration generates for every the match attempts for all and only noise shares ending with in the noise share space generated by noise space Also, no such share should be generated twice. Finally, it should appear that the recovery always terminates 
 
704 


0 1 on the average 0 beyond the discount code, is pseudo\random. Hence, every noise share generated is again equally likely to be the noised one, under the same good 1-way hash assumption.  We thus have on the average the 1  Ex. 3 Consider the running example in [2 where  the encryption complexity is set up so that 1-node recovery would require up to prohibitive 70-days and 35 days on the average. To recover the key in 10 min at most instead, using the full-cost, a 10K-node wide cloud may do.  The actual cost could be 200 Consider that the owner retained our 8b discount code jê, as in Ex. 1 and Fig. 3 previously discussed. Now 40-node cloud may suffice for the same timing Alternatively, the same 10K cloud, delivers the discounted recovery in up to a couple of seconds. In both cases, the cost theoretically drops to less than 1 A 16b discount èjê would lower these figs accordingly further. The requestor could even recover the key at her/his own presumably single node, in about 2m1ins 0 beyond the discount code, is \(pseudo\andom and thus independent of the discount code value. Also, for a good 1-way hash as we suppose, each such value is equally likely to generate the matching 0 
002 002 
We skip the last part as quite obvious, at least in the absence of failures, here. The proof of the rest is rather easy to see from the figures and Ex. 2 We also skip the tedious details, referring the reader to i ally f o r the  scal able  sche m e The calculus of obviously calculates the number of noises in that terminates with  This is the size of  hence of In Step \(4\, each node calculates in the way that yields an integer being a noise share and such that \(i\ it ends with and \(ii\ is greater than or equal to By definition this is The loop at each node then attempts the matches using every noise handled by the node. It should be clear from Fig. 3 and the example that whatever is then and all the noises in are possibly explored and only once per noise. Hence are all the noise shares in and  cannot map a share beyond  The calculation of in Step \(4\ produces clearly for each the noise share ending with There cannot be such a share in the noise share space as well as in  missing from the distributed calculus. Also, one easily sees from Fig. 3 that no noise shares in may be generated twice whatever are the parameters there. Similar analysis holds for any partitioning that could be generated by the scalable scheme Finally, it is easy to see that the i.e., the rules for cloud service termination without a cloud failure, is also correct. Every node starting the attempts indeed terminates. It either gets the termination message from or terminates itself after all possible attempts. Next also terminates either by providing or by finding an invalid as we discussed in Step 10. Finally, the recovery cannot produce in practice for an invalid We prove this point in Section 4.3 below, as it rather concerns the safety An bit long decreases the recovery calculation complexity \(hardness\ 2 times in practice Respectively, we have  2 or the worst case and  2 For the full-cost recovery, the complexity could be measured basically by the number of noises to try out:  at most or on the average. Each noise may indeed trigger a match attempt. The computational cost of SHA256, as well as any other known good 1way hash function dominated additional operations required, at the start-up or termination etc. of the algorithms. We had thus basically the complexity of  in the worst case, for both static and scalable schemes For both schemes, the discounted recovery has at most noises to try out. This is 2 time smaller. On the other hand, the discounted recovery algorithm requires an additional initial calculation of Next, it requires the calculation of Finally, at each attempt, there is an additional multiplication by 2 However, it is the common knowledge that the cumulated computational cost of a few such operations is again negligible with respect to that of SHA256 or another good 1-way hash calculation Hence, we have basically the  worst case complexity, i.e., the  2 ne For the average case, we had under similar assumptions  2\ for the full-cost recovery. The reason was that both schemes enumerated all attempts till the successful one, while every noise, hence every noise share tried out, were equally likely to try out and succeed, provided a good 1-way hash, as we supposed. For the discounted recovery, every attempt uses again a different noise and at worst all noises noises are explored. The discount code is pseudo\random, hence every code is equally likely Also, the rest of  2 complexity hence  2 1 Knowledge of a discount code cannot lower the complexity of the requested backup under values  at worst and  2\n the average provided by our algorithm \(see below  Our algorithm enumerates all attempts till the successful one \(if any\. Every attempt uses a different noise among and, at worst, all noises noises are explored. The rest of Hence whatever is a given a discount code, one cannot calculate from it or otherwise any that could be less or more likely than any other possible. No method exists that would allow to attack the requested backup from its given discount, towards lowering the complexity under that of our algorithm 2 The recovery cannot produce in practice for an invalid  Indeed, any invalid say  here, is by definition different from the valid one Hence the 
m m m m m m m 
  
Proof M I d  I Q f d f f x N d M I Q H Q  s x d I I  Q termination protocol C C s 0 d s  d B Complexity m d O M O M Proof O M  M M f O M O M O M M s O M O M C Safety O M O M  Proof M M s f f s  d Proof d d   
  
705 


002 002 
s x d s  H s h d O M Proof d B d B O M B  Proof A Rationale s R R R O M r r  I I m p p R p R R R R k share noised secret sharing k k k  B Backup Creation O k D k O k s s k s k K s s s k s j j k  s s j p j r j r j size of the noise space M M O k h h k h H s j j match attempt x  H f j x h j j M D O throughput T M M D T / k M k M D k M  T k M O P P p 0 p kh 0 h kM O s k P K O d d d k d j  m s j C Recovery K  P d P, R, d s k N N N k M  T  R x x M x x d j d x x d j k H f j x H f j x d j h j j k k x R R T k Mê / N k Mê / N R T N N T 
0  0 was then noised resulting in the, so-called, 2-share noised secret sharing. Complexity analysis sketched above and discussed in depth in sh own th at the 2sh ar e  noised secret sharing noised secret sharing schemes for any given full-cost maximal recovery time 0  1 and 0 XOR 1 XOR 1  Each 0 above, namely 0  1 where j  1  1  0  1 he discount code, where every 
   
share it defines, namely p  is a noise share different of As we discussed already, chance of having then   are almost zero. Hence, in practice, no may ever lead to a successful match 3 Guessing a discount code does not lower the complexity of any backup under   See   4 A discount code for backup does not lower the complexity of any discounted recovery using for a different backup The latter remains   characterizing full-cost recovery of   The discount codes being pseudo-random it would be indeed like guessing in \(2 Property 3 means that the knowledge a discount code for a backup by the escrow, does not threaten any different backup at escrowês possession.  A discount code once used by the escrow is thus of no further utility V MULTI-SHARE NOISED SECRET SHARING The above discussed schemes used at the basis the 2-share secret sharing. Share  provide the expected \(full-cost\ecovery time E  equal to at most 2. The static scheme provides exactly that expected value, while the scalable one may provide slightly less. These values are immediate and easy to spot consequences of the  2 average full-cost complexity for the static scheme One rationale of these properties is a uniform distribution of the suffix or  of the noised share within or for 0. One consequence is that for any probability the recovery time may be over \(1 For instance for 10%, it would be at least 0.9 i.e., almost twice as big as the user could expect most likely. By the same token, it could be also under 0.1 The cloud costs would be in accordance. Some users may be expected to feel uneasy with such a relatively likely perspective of the almost double bill In turn, intruders may feel attracted to gamble over the uniformly likely perspective of the cheaper that on the average disclosure.   In both cases, there is room for schemes where is closer at will to E  will appear, this is the property of the 1 schemes we introduce now These schemes generalize the schemes above assimilated to 1, towards larger values  2,3,4É  We keep the notation from Section 2 and after, adding eventually obvious indices To start chooses and, as before, the prohibitive 1-node recovery time The rationale for besté choice of will appear soon. Next defines a usual 1\ Ö share secret with thus the random shares  XOR  0 1 ; has the same structure as   Every suffix is also as before adjusted to be under the if the need occurs. We provide soon the way to define that slightly differs from the previous one  computes then hints  or every A for any noise  to be performed during the recovery, will consist of the calculation    for specific  It may occur that all the noises and hints are explored for a successful full-cost recovery. To choose then conform to  starts with the measure or an estimate of the that is the number of 1-node match attempts per time unit basically a second. Then is chosen as   Indeed, for every there are  match attempts possible. Hence     Note that for 1 the choice is compatible with that above for the 2-share noised secret sharing.  Next forms that is now  ly sends out the couple  he backup retains also the vector  spans \(the same\ber of the suffix bits of its  To recover the legitimate user sends out the request  Escrow sends then to the cloud all the backup data except for The match attempts split over the cloud nodes, as before, Fig. 4, using the static or the scalable scheme. For the latter scheme, the coordinator defines as     The rationale is first that for every noise within the reduced noise space, i.e 0 1, the node in charge of attempting the matches for some  embedding i.e., for some within we have   has in fact such match attempts to generate These are all the attempts        for every 0 1. Notice that up to now we had 1 only, hence a single match attempt for every Next, to meet the bound, the node has to perform at most attempts, assuming that all the nodes provide the same throughput \(a homogeneous cloud\ other hand, with the already discussed hash partitioning, the node performs in practice  attempts. Hence, we have  003  The coordinator of the static scheme chooses the minimal possible that is the one above. The scalable scheme generates in a more involved way The cloud is supposed heterogeneous, we recall hence may vary among nodes. The calculus is then distributed among the nodes as we mentioned already 
   
706 


002 
002 002 
N y x h j s j  f j x s j s k K k k D Discussion O M k O Mê k  k R k k k  k k k  O M R k M R O k U U R R yR y k y k k d k code phrase k k k k d m m d d m 
1  2 scales up then exponentially with 
 
The finally generated is usually somehow larger than the size-optimal one, [2    Regardless of the partitioning scheme, every node attempts the matches for each assigned to it as already discussed. Every node determining for some i.e., encountering a successful match, reports the share   to the coordinator. Once the coordinator gets every expected it reports them to the escrow. That one performs the XORing of all of them with and sends the recovered secret, i.e to the user. As for 1 above, the full-cost recovery must normally \(without any cloud infrastructure failure\ed for every A discounted one accordingly always succeeds in practice for a valid discount code and always fails otherwise The recovery computation has obviously the maximal complexity  r every The average one is now    1\rdingly, the average recovery calculation time is   1 The value   1\ is known as the average value of the largest randomly chosen value in interval [0, 1 among such choices. Obviously it increases towards 1 with  For the 2-share noised secret sharing we match the already discussed values  2 and 2. For higher both raise up towards and respectively. For instance, if chooses a 6-share secret sharing, hence 5, and the recovery requestor expects a 5-minute recovery may choose 6 min Instead of choosing 10 min for a 2share only scheme. A perhaps up to 40% lower cloud bill in consequence. Also, the probability of the recovery time being within some fraction is now  instead of only for a 2-share only scheme.  Hence in our example, it is 10 5 instead of 10 1 only. One may expect thus to deter much more strongly any gambling temptations of an insider on the escrow site A possible inconvenient of a larger may be a times longer The key owner wishing to only memorize it, as one does it for the credit card, may have trouble for 3. A way out may be parts of a one-way hash of a That one should be for the owner, easy to remember or reconstruct. It should also be harder to crack by known tools than a full-cost recovery itself. This can result, as usual for passwords, from mix of letters, numbers and special characters. It could be as easy nevertheless as, e.g In Jan. 1950 my age was 3.5 yearsé.  For, say, 1B discount code per share and our 5, any five bytes of the hash could do. The generation of the pseudorandom shares should be amended consequently There are various easy ways to do it VI RELATED WORK The basis for the work above is the static and the scalable schemes i These sche m es use b oth  hash  part e proposes al so  an R E NS  scheme using the range partitioning. Our discounted recovery calculation may be expected applying to this scheme as well.  Another scheme i  multiple shares, i.e., it provides the 1 share noised secret sharing with 1, like we do in Section 5. However, whether that scheme may be generalized to support discounts is at present an open question Besides, we are not aware of any other related work specific to some kind of discounted recovery The work related to the noised secret schemes in general, including the overview of various proposals for key recovery, is extensively discussed in an d i e thus av oi d r e peatin g i t h e r e We onl y  notice however that a birdês eye view may assimilate a discount code to a particularly easy to use trapdoor decryption function of bit-length The çpower of successive functions for a key  VII CONCLUSION Discounts appear a potentially highly useful capability for an RE NS scheme. The existing 2-share schemes generalize towards discount management easily. The key becomes çnever-losté, with \(illegal disclosure cumbersome at will for the attacker and yet with cheap \(legal\practical recovery by the discount possessor. This combination, unique up to now for a key recovery scheme, has the potential to offset the current fears of key loss. On the one hand our schemes may help users managing sensitive data purely locally, but fearing key loss or data disclosure anyhow. On the other hand, they may aid those attracted by big data outsourcing. Who remained deterred up to now, by fears of accordingly big consequences of key loss, or, by perhaps equally calamitous consequences of cloud content disclosure With respect to the work in progress, we continue the analysis of our schemes. We further plan to extend it to other schemes in    1 e eting on C l o u d Secu r ity  G M U Mar ch 1112,2013. http://csis.gmu.edu/albanese/events/march-2013-cloudsecurity-meeting  Ja jodia  S Litw in W  Sch wa rz Th  S J Rec o v erab le Encryption through a Noised Secret over a Large Cloud. 5th Inl Conf. on Data Management in Cloud, Grid and P2P Systems Globe 2012 ure Notes in Comp. Sc  jodia  S L itwin W Sc hwa r z  Th  S J  R e c o verab le Encryption through a Noised Secret over a Large Cloud. Intl Journal on Large-Scale Data and Knowledge-Centered Systems TLDKS IX, LNCS 7980, 2013  jod i a, S Lit win W Schwa rz  T h S J Ke y Re cov e ry Using Noised Secret Sharing with Discounts and Large Clouds Lamsade Research Report. July 2013 http://www.lamsade.dauphine.fr/~litwin/cours98/CoursBD/Key%2 0Recovery%20with%20Discounts%20Res%20Rep.pdf  a, Red f ie ld C  Zeld ovich, N Balakrishnan, H. CryptDB: Protecting Confidentiality with Encrypted Query Processing. SOSP ê11, October 23Ö26, 2011 Cascais, Portugal  m ith, K How Practical Is Com putable Encry p t i on? In[1 
  
707 


Virtual Social Networks Analysis in Computational Social Network Analysis  ser Computer Communications and Networks A Abraham A.-E Hassanien and V Sn  ael Eds London Springer London 2010 ch 1 pp 3Ö25  J K orner  Fredman-k olmo s bounds and information theory   SIAM J Algebraic Discrete Methods  vol 7 no 4 pp 560Ö570 Oct 1986  T  Leighton and S Rao Multicommodity max-îo w min-cut theorems and their use in designing approximation algorithms J ACM  vol 46 no 6 pp 787Ö832 Nov 1999  M Bastian S He ymann and M Jacomy  Gephi An open source software for exploring and manipulating networks 2009  A.-L Barabasi and R Albert Emer gence of scaling in random networks Science  vol 286 no 5439 pp 509Ö512 1999 


application or middleware platform to collect request ows Thus it is much easier to deploy FChain in large-scale IaaS clouds Blacksheep correl a t e s t he change poi nt of s y s t em-l e v el metrics e.g cpu usage with the change in count of Hadoop application states i.e events extracted from logs of DataNodes and TaskTrackers to detect and diagnose the anomalies in a Hadoop cluster Kahuna-BB correl a t e s b l ack-box dat a system-level metrics and white-box data Hadoop console logs across different nodes of a MapReduce cluster to identify faulty nodes In comparison FChain is a black-box fault localization system which is application-agnostic without requiring any knowledge about the application internals We believe that FChain is more practical and attractive for IaaS cloud systems than previous white-box or gray-box techniques V C ONCLUSION In this paper we have presented FChain a robust blackbox online fault localization system for IaaS cloud computing infrastructures FChain can quickly pinpoint faulty components immediately after the performance anomaly is detected FChain provides a novel predictability-based abnormal change point selection scheme that can accurately identify the onset time of the abnormal behaviors at different components processing dynamic workloads FChain combines both the abnormal change propagation knowledge and the inter-component dependency information to achieve robust fault localization FChain can further remove false alarms by performing online validation We have implemented FChain on top of the Xen platform and conducted extensive experimental evaluation using IBM System S data stream processing system Hadoop and RUBiS online auction benchmark Our experimental results show that FC hain can achieve much higher accuracy i.e up to 90 higher precision and up to 20 higher recall than existing schemes FChain is light-weight and non-intrusive which makes it practical for large-scale IaaS cloud computing infrastructures A CKNOWLEDGMENT This work was sponsored in part by NSF CNS0915567 grant NSF CNS0915861 grant NSF CAREER Award CNS1149445 U.S Army Research Ofìce ARO under grant W911NF-10-1-0273 IBM Faculty Awards and Google Research Awards Any opinions expressed in this paper are those of the authors and do not necessarily reîect the views of NSF ARO or U.S Government The authors would like to thank the anonymous reviewers for their insightful comments R EFERENCES   A m azon E las tic Com pute Cloud  h ttp://a w s  a m azon com ec2   V i rtual c om puting lab  http://vcl ncs u  e du  P  Barham  A  D onnelly  R I s aacs  a nd R M o rtier   U s ing m agpie f or request extraction and workload modelling in 
 2004  M  Y  Chen A  A ccardi E  K icim an J  L lo yd D  P atters on A  F ox and E Brewer Path-based failure and evolution management in  2004  R F ons eca G  P o rter  R H  K atz S  S h enk e r  and I  S toica X T race A pervasive network tracing framework in  2007  I  Cohen M  G o lds z m i dt T  K elly  J  S ym ons  a nd J  S  Chas e Correlating Instrumentation Data to System States A Building Block for Automated Diagnosis and Control in  2004  I  C ohen S  Z h ang M  G o lds z m i dt J  S ym ons  T  K elly  a nd A  F ox Capturing indexing clustering and retrieving system history in  2005  S  D uan S  Bab u  a nd K  M unagala F a A s ys tem for a utom ating failure diagnosis in  2009  S  K andula R Mahajan P  V erkaik S  A garw al J  P a dhye a nd V  Bahl Detailed diagnosis in computer networks in  2009  A  J  O liner  A  V  K ulkarni and A  A ik en  U s ing c orrelated s u rpris e to infer shared inîuence in  2010  P  Bahl R Chandra A  G r eenber g  S  K andula D  A  M altz and M Zhang Towards highly reliable enterprise network services via inference of multi-level dependencies in  2007  Z  G ong X  G u  a nd J  W ilk es   P RE S S  P Redicti v e E las tic ReS ource Scaling for Cloud Systems in  2010  H  N guyen Y  T a n and X  G u P A L  P ropagation-a w are a nom aly localization for cloud hosted distributed applications in  2011  B Gedik H Andrade K L  W u P  S  Y u and M  D oo SP ADE  t he system s declarative stream processing engine in  2008  A pache H adoop S y s tem   http://hadoop apache  or g/co re   Rice uni v e rs ity bidding s y s tem   http://rubis  objectw eb  o r g   M Ben-Y e huda D  B reitgand M F actor  H  K o lodner  V  K r a v ts o v  and D Pelleg NAP a building blo ck for remediating performance bottlenecks via black box network analysis in  2009  Y  T a n X  G u  a nd H  W a ng  A dapti v e s ys tem anom aly prediction f or large-scale hosting infrastructures in  2010  D  L  M ills   A b rief his t ory o f N T P tim e m e m o irs o f a n i nternet timekeeper  2003  Y  T a n H  N guyen Z  S h en X  G u C V e nkatram ani and D  R ajan PREPARE Predictive Performance Anomaly Prevention for Virtualized Cloud Systems in  2012  M  Bas s e ville and I  V  N ikiforo v   Prentice-Hall Inc 1993  L  Cherkaso v a  K  O zonat N Mi J  S ym ons a nd E  Sm irni  Anom aly application change or workload change towards automated detection of application performance anomaly and change in  2008  P  Barham and e t al   X e n a nd the a rt of virtualization  i n  2003  T he ircache p roject  h ttp://www.ircache.net  H ttperf  h ttp://code google com  p htt p er f  S  K u llback  T h e ku llback-leibler distance  1987  X  Chen M  Z hang Z  M  M a o and P  B ahl  A utom ating n etw ork application dependency discovery experiences limitations and new solutions in  2008  M Y u  A  G reenber g  D  M altz J  Re xford L  Y u an S  K andula and C Kim Proìling network performance for multi-tier data center applications in  2011  M K  A guilera J  Mogul J  W iener  P  R e ynolds  a nd A  Muthitacharoen Performance debugging for distributed systems of black boxes in  2003  S  A g arw ala F  A l e g re K  S chw a n and J  M ehalingham  E 2E P r of A utomated end-to-end performance management for enterprise systems in  2007  P  Re ynolds  J  L  W iener  J  C M ogul M  K  A guilera and A  V ahdat  WAP5 black-box performance debugging for wide-area systems in  2006  R Apte L  Hu K  S chw a n and A  G hosh L ook W ho s T alking Discovering dependencies between virtual machines using cpu utilization in  2010  G Khanna I  L aguna F  A rshad an d S Bagchi Distr ibuted diagnosis of failures in a three tier e-commerce system in  2007  R R S a m b as i v an A  X  Z heng M  D e Ros a  E  K re v at S  W h itm an M Stroucken W Wang L Xu and G R Ganger Diagnosing performance changes by com paring request ows in  2011  J  T a n a nd P  N a ras i m h an  RA M S and B lackS h eep I nferring w h ite-box application behavior using black-box techniques CMU Tech Rep 2008  J  T a n X  P a n E  Marinelli S  K a vulya R  G andhi a nd P  N a ras i m h an Kahuna Problem diagnosis for mapreduce-based cloud computing environments in  2010 
OSDI NSDI NSDI OSDI SOSP ICDE SIGCOMM DSN SIGCOMM CNSM SLAML SIGMOD ICAC PODC Computer Communication Review ICDCS Detection of abrupt changes theory and application DSN SOSP The American Statistician OSDI NSDI SOSP DSN WWW HotCloud SRDS NSDI NOMS 
207 
30 
30 


A Global Solution COVERAGE North and South America EMEA and Asia White lines are flights in the masFlight platform from February 8, 2013 Yellow pins are weather stations feeding hour ly data to our platform Maps from Google Earth / masFlight masFlight tracks flights, airports and weather around the world  Global daily flight information capture  82,000 flights  350 airlines  1700 airports  Integrated weather data for 6,000 stations  Match weather to delays  Validate block forecasts at granular level  Add weather analytics to IRROPS review and scenario planning 


Example 1: Proposed FAA Tower Closures masFlight used big-data to link airport operations across three large data sets  Current and historical airline schedules  Raw Aircraft Situation Display to Industry \(ASDI\AA  Enhanced Traffic Management System Counts \(ETMS\Airport operations counts by type \(commercial, freight, etc TOWER CLOSINGS Dots indicate closures; Red dots have scheduled service Based on scheduled service March 1 7, 20 13; scheduled service includes scheduled charter flights, cargo flig hts, and passenger flights Dots  indicate  closures  Red  dots  have  scheduled  service Bas ed  o n sc h edu l ed  se rvi ce  M a r c h 1  7, 2013; scheduled se rvi ce includ es scheduled c harter fli g hts car g o fli g hts a nd passen g er fli g hts Findings: Proposed Tower Closings  From schedules database: 55 airports with scheduled passenger airline service  14 EAS Airports  From ASDI & ETMS: 10,600 weekly flights on a flight plan \(ex. VFR and local traffic  6,500 Part 91/125 weekly flights  4,100 Part 135/121 weekly flights  


Example 1: Big-Data Analytics Applied to ASDI and ETMS To Analyze Operations TOWER CLOSINGS  26 44 24 23 11 10 6 2 1 2 Up to 5 5-10 10-15 15-20 20-25 25-30 30-35 35-40 40-45 45 Count of Airports Average Number of Daily Operations with a Flight Plan Filed Distribution of Airports By Average Number of ìDailyî Impacted Flights Airports Affected by Tower Closures Source: ASDI radar data ñ Part 91 151 flying and Part 135/121 flying March 1-7, 2013; masFlight analysis Note: Average ìdailyì operations based on 5-day week 


Example 2: Aviation Safety Causal Factor For example, consider the following ASRS report \(ACN 1031837 Departing IAH in a 737-800 at about 17,000 FT, 11 m iles behind a 737-900 on the Junction departure over CUZZZ Intersection. Smooth air with wind on the nose bearing 275 degrees at 18 KTS We were suddenly in moderate chop which lasted 4 or 5 seconds then stopped and then resumed for another 4 or 5 seconds with a significant amount of ri ght rollingÖ I selected a max rate climb mode in the FMC in order to climb above the wake and flight path of the leading -900 We asked ATC for the type ahead of us and reported the wake encounter. The 900 was about 3,300 FT higher than we were  Synopsis  B737-800 First Officer reported wake encounter from preceding B737-900 with resultant roll and moderate chop What causal factors can be identified from this narrative that could be applied to future predictive applications CAUSAL FACTORS Data-mining algorithms can mine the text of safety reports to obtain specific data that can be used to analyze causal factors  


Example 2: Identifying Causal Factors CAUSAL FACTORS  Indicators ñ Data Element Methods ñ Identifying Context and Causes  Time of day  Date range \(month day  Aircraft type  Fix or coordinates  Originating airport  Destination airport  Weather notes We pinpoint the sequencing of flights on the IAH Junction Seven departure \(at CUZZZ\the specified wind conditions to find cases wher e a B737-900 at 20,000 feet precedes by 11 miles a B737-800 at 17,000 feet  Search related data sets including ASDI flight tracks, local traffic and congestion  Weather conditions for alter native causes \(winds aloft shear and convecti ve activity  Airline specific informati on \(repeated occurrence of event in aircraft type Big data gives us visibility into contextual factors even if specific data points are missing such as a specific date or route Big-data analytics gives us insight into unreported factors as well 


Example 3: Correlating Utilization and Delays  60 65 70 75 80 85 90 95 100 7 9 11 13 ONTIME DEPARTURE PERFORMANCE HOURS OF DAILY UTILIZATION 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Narrowbodies By Day of Week 60.0 70.0 80.0 90.0 100.0 7.0 9.0 11.0 13.0 Widebodies by Day of Week Daily Utilization vs. On-time Departures January 2013 System Operations Correlation Coefficient -0.53 Includes AA, AC, AS B6 F9, FL, NK, UA, US VX and WN SOURCE masFlight \(masflight.com COMPARING OTP AND UTILIZATION 


 6.2 6.0 5.8 5.8 5.2 4.9 LGB JFK BOS MCO DCA FLL JetBlue Focus Average Daily Deps per Gate Used UTILIZATION BY HUB Example 4: Daily Utilization of Gates, by Hub Big-data analysis of different carriers daily departures per gate used SOURCE masFlight \(masflight.com June 1 through August 31, 2012 Gates with minimum 1x daily use 7.7 7.4 7.2 6.2 6.1 5.8 3.8 3.6 ORD LAX SFO EWR DEN IAH IAD CLE United Airlines Hubs Average Daily Deps per Gate Used 7.8 6.4 5.5 5.4 5.3 4.4 4.3 4.0 SEA SAN PDX ANC SFO GEG LAX SJC Alaska Airlines Hubs Average Daily Deps per Gate Used 7.2 6.9 6.8 6.4 5.0 2.7 ORD DFW LAX LGA MIA JFK American Hubs Average Daily Deps per Gate Used 7.2 6.9 6.6 4.9 4.2 CLT DCA PHL PHX BOS US Airways Hubs Average Daily Deps per Gate Used 6.6 5.9 5.5 4.7 MCO BWI ATL MKE AirTran Hubs Average Daily Deps per Gate Used ne pe 


Conclusions for Big Data in Aviation  Big-data transforms operational and commercial problems that were practically unsolvable using discrete data and on-premises hardware  Big data offers new insight into existing data by centralizing data acquisition and consolidation in the cloud and mining data sets efficiently  There is a rich portfolio of information that can feed aviation data analytics  Flight position, schedules, airport/gate, weather and government data sets offer incredible insight into the underlying causes of aviation inefficiency  Excessive size of each set forces analysts to consider cloud based architectures to store, link and mine the underlying information  When structured, validated and linked these data sources become significantly more compelling for applied research than they are individually  Todayís cloud based technologies offer a solution CONCLUSIONS 


Conclusions:  Our Approach  masFlightís data warehouse and analysis methods provide a valuable example for others attempting to solve cloud based analytics of aviation data sets  masFlightís hybrid architecture, consolidating secure data feeds in on-premises server installations and feeding structured data into the cloud for distribution, addresses the unique format, security and scale requirements of the industry  masFlightís method is well suited for airline performance review competitive benchmarking, airport operations and schedule design and has demonstrated value in addressing real-world problems in airline and airport operations as well as government applications CONCLUSIONS 






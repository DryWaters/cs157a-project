Proceedings of tbe Second International\222Conference on Machine Learning and Cybernetics Wan 2-5 November 2003 APPLYING AI TECHNOLOGY AND ROUGH SET THEORY TO MINE ASSOCIATION RULES FOR SUPPORTING KNOWLEDGE MANAGEMENT ZHE AUANG WN-QUAN HU School of Management, Harbin Institute of Technology, Harbm 150001 China E-MAILhuangzhe2000@hotma1l com Abstract Knowledge management is fast becoming a commercial necessity for many organizations in order that they manage their intellectual assets 
and gain competitive advantage To maximize that advantage knowledge management needs to be available across the whole of the enterprise Before a knowledge management system can be built the knowledge that pervades the organization must he identified and recovered This paper applies artificial intelligence A0 techniques within traditional knowledge frameworks to mine association rules for supporting organizational knowledge management and decision making The mining procedure consists of two essential 
modules One is a clustering module based on a neural network a Self-organization Map SOM which performs grouping tasks on the tremendous number of database records The other is a rule extraction module applying rough set theory that can extract association rules for each homogeneous cluster and the relationships between different clusters A simple example is used for describing bow self-organizing map and rough set theory applied in this paper Keywords Knowledge management 
1 Introduction Data mining Self-organizing Map Rough set theory As we enter the new millennium we realize a shift in the business model from the ole static model based on hierarchic organizations towards a dynamic model built on top of continuously changing and knowledge-based organizations Knowledge management KM is emerging as the new growing interest that provides the mechanisms for systematically managing the knowledge that evolves with the enterprise Most large organizations have been experimenting with knowledge management with a view to improving profits being competitively innovative or simply to survive I1 Furthermore exploiting technology 
enables organizations to derive knowledge from data and information collected as the business proceeds It then may be exploited in decision-making product development 0-7803-786C2/03/$17.00 02003 IEEE human resource customer relationships the supply chain and so on Clearly knowledge management needs to infiltrate every aspect of the enterprise to improve business efficiency Before a knowledge management system can be built the knowledge that pervades the organization must be identified and recovered This paper applies artificial intelligence AI techniques within traditional knowledge frameworks to mine association rules for 
supporting organizational knowledge management and decision making Data mining is one of the most important techniques that can find potential useful knowledge such assignificant pattems and rules from databases in supporting of making better decisions The data mining tasks include association rules extracting, clustering, classifying forecasting and so on An association rule is represented as x a Y  where X and Yare a set of items. The rule means that the records in database that contain X tend to contain 
Y A good number of efficient algorithms for mining association rules have been proposed Clustering is a task of partitioning a population into a number of clusters or subgroups with similar features There are numerous clustering algorithms such as the k-means method the divisive methods the grid-based method the self-organizing map and so on Kiang Kulkarni and Tam\(2000 used SOM to group similar parts into part families to be manufactured Vellido lisboa, and Meehan\(I999 used SOM to cluster data and find the potential interest for on-line marketers Changchien and L~\(2001 used SOM 
and rough set theory to support on-line recommendation by customers and products fragmentation SOM networks have been successii~lly applied as a classification tool to various problem domains including speech recognition image data compression image or character recognition market segmentation customer targeting and medical diagnosis In this paper however, a neural network, a Self-organizing Map SOM will be applied to cluster the customer characters in order to discovery more knowledge and experiences to improve the quality and performance in the business management The 1820 


Proceedmgs of the Second International Conference on Machine Learning and Cybernetics Wan 2-5 November 2003 SOM network serves as a clustering tool that can group sale actions into appropriate categories based on the similarities in the characteristics of a given set of customer records It performs unsupervised training for group technology so it doesn't require the knowledge of the corresponding output for comparison and learning That is to say that the input pattems, during the process adjust their weights based on the lateral feedback.connections. The advantages of SOM network are good at transforming multi-dimensional inputs into a map of fewer dimensions and being easily used for classification of new entities into existing clusters without repeating the clustering process Thus it is very suitable for presenting the group distributions of the customer characters that are consisted of multiple attributes. But the drawback of SOM network is that it can't explain the clustering results specifically This paper for this reason combines the rough set theory to achieve the goal-mining the association rules to explain the meaning of each cluster and the relationships between of them Rough set theory clarities set-theoretic characteristics of the classes over combinatorial patterns of the attributes. This theory can be used to acquire some sets of attributes for classification and can also evaluate the degree of the attributes of database that are able to classify data It uses the lower and upper sets that proposed by Lin and Cercone in 1997 Several applications and extensions of the rough set theory have also been proposed The reason for success in knowledge acquisition is that the rough set theory offers opportunities to discover useful information in training examples Coming with more social problems existed in our country how to integrate the available resources well to solve the exist problems and detect the potential problems is a challenging work This paper therefore combine the strength of this two techniques to achieve the challenging task  more potential knowledge discovery in decision making product development human resource customer relationships, the supply chain and so on 2 Theory and Model 2.1 Self-Orgauizing Map SOM The basic SOM network has an input layer and an output layer When training data sets are fed into the network SOM will compute a winning node The winning node and neighborhood weights will he adjusted during learning training process until it converges to form clusters with similar properties The rules for clustering subgroups may be difficult to be defined but SOM offers the flexibility to decide the composition and the number of clusters based on the selected objective and subjective criteria such as  customer age, personality professional and so on Beyond this SOM network can he easily used for classification of new entities into existing clusters that the whole clustering process doesn't have to be repeated The groupings can thus be continually adjusted in quick response to the change of environment 2.2 Rough Set Theory The rough set theory is a new mathematical approach to imprecision vagueness and uncertainty The vague concepts were replaced by the precise concepts the lower and the upper approximation of the vague concepts Approximations are two basic operations 6 the rough set theory The idea can he presented in the following manner Let U he a universe A be a finite set of attributes B be a subset of A X be a subset of the universe and I be an equivalence relation on U called an indiscemible relation I\(B x  in short B\(x is an equivalence class containing an element x Let us define the two basic operations the B-lower and the B-upper approximations on sets in the rough set theory B*\(X x 1 B'\(X x E U  B\(x E X  4 2 We usually use the rough member ship function, called the confidence function to define approximations and the boundary region of a set The confidence function is defined as cF\(x  denotes the degrees of bow Where the element x belongs to the set X in view of the indiscemible relation I The confidence function of the lower and the upper approximation c be redefined respectively 3s follows B*\(X x E U CF\(X  I B'\(X  x E U  CF\(X  0 This paper applies the rough set theory to each cluster for finding out some rules for association explanation such as the characterization to the customers The purpose of the paper is mining more detail knowledge for managers making the best strategies in response to the changeable business environment 3 Knowledge discovery process Knowledge discovery is an interactive and iterative process involving several steps. Data mining is one of the 


Proceedings of the Second International Conference on Machine Learning and Cybernetics San 2-5 November 2003 steps in it Figure 1 shows the process of knowledge discovery while the data mining procedure is showed in Figure 2 In Figure 1 there are three procedures connected closely for achieving the goals Figure 1 Knowledge discovery procedure First managers select the target data set as the training data for the mining purpose and then to preprocess the selected data for the next procedure The data mining procedure then starts to search for interesting pattems by the clustering module and rule extraction module Afler the data mining of association rules the work of rules evaluation is performed to eliminate weak rule under the initial values created by the knowledge workers. The useful rules are stored with different presentation styles in the knowledge bases that may be the case bases, rule bases and so on They can be used as the strategies or some experiential laws in providing better recommendation and high-degree prediction In this paper we focus on clustering and association rules extraction in data mining tasks and following is the complete procedure of data mining for recommendation 3.1 Data preprocessing \(Step 1 Before proceeding to data mining on data set raw data must be preprocessed in order to decrease the mining time and facilitate the effectiveness The data preprocessing process consists of two modules: clearingkelection module and transformation module 1 Data clearing  selection module The users can retrieve data with constraints such as the range of an attribute for mining purposes The procedure involves integration of multiple databases removal of noises and handling of missing data fields 2 Data transformation module To have the same ranges, the target data should be normalized and/or scaled if it is necessary Since this paper uses a SOM network for data clustering the target data would be transformed to values ranged between 0 and I Here are two different formulas used to transform data a If attribute number then reponse-value  value  min\(attj max\(att  min\(att 6 Where response-valuejk is the normalized value for the fi attribute of record k min\(attj the minimum value of thefi attribute while max\(attj is he maximum value of the fi attribute and valuejk is thg original value of the 3 1822 


Proceedings of the Second International Conference on Machine Learning and Cybernetics xi 2-5 November 2003 contributes to each output node with a weight Insection 2 we show the flow chart for clustering. The SOM network attribute of record k b If attributenon-number then specific data trans formation scaling should be assigned by the user For instance, the data type of attribute job is character The user has to assign a normalized numerical response value to it Set initial confidence value I I j=D k=N I YDN j=D k=H 1 YDH 2,5,6 Generate result equivalence  1 Generate cause equivalence I radius rate converge error rate and so on After the training phase the weights are converged to the values that can be used to assign data items to their corresponding clusters For instance, the managers can choose two attributes for a certain production the degree of customer loyalty and the degree of necessary promotion as the SOM input nodes Table 1 presents a simple example of clustering results of sale actions where D is the degree of customer loyalty P is the degree of necessary promotion GID is a cluster number with special sales characteristics and ID is the sale action identification number Table 1 Records of sale actions Nnonnal H high Llow  Create new combinatorial rule nd compute confidence w Filter below initial confidence Ylllles Rules generation completed T Rules generation completed Figure2 The flow chart of implementing rough set 3.2 Data mining of association rules \(Step 2 2 Rule extraction module Rough set theory not only can extract association rules for each homogeneous cluster but also can find out the relationships for attributes among different clusters Figure 2 shows the steps of rule extraction module and their descriptions are as below a Set initial confidence value It is used to filter the lower and upper approximation rules unsatisfying the threshold value that is assigned by the users for holding the rules with high explainable abilities b Generate result equivalence classes Let X denote the result equivalence class that consists of a set of objects for cluster i Table 2 lists the clusters for a table sale actions X means that the sale action in this cluster is belonged to the degree A Table 2 Results equivalence classes When all attributes have the same measurement and ranges then the association rules extraction process is proceeding In this process the SOM network based clustering module starts first and then a rough set theory based Nle extraction module is employed to discovery association rules 1 Clustering module The SOM network is an unsupervised two-layer network proposed by Kobonen that can recognize a topological map from a random star&ing point In SOM network input nodes and output nodes are fully connected with each other Each input node c Generate case equivalence classes Let  denote the cause equivalence class that consists of a set of objects having a specific attribute j with value of k\(Ajd The Table 3 gives the case equivalence classes Table 3 Cause equivalence classes I AA I Y I 


Proceedings of the Second International Conference on Machine Learning and Cybernetics Wan 2-5 November 2003 YDL=\(~I TI YPN 2 j=P k=H YPH 4A6I YPI   1.3 d Create lower approximation rules Let Ap\(XJ denote the set of objects that have the same attribute values\(Ajk all contained in cluster i Here Eq.\(l is used to create lower approximation rules For example for XI   23 where GID  A Table 2 APN.\(X   2 satisfies the constraint so we have found a lower approximation rule which is 221RI If necessary promotion  N then GlD  A\222 Accordingly all the lower approximation rules can be found and the confidence of every lower approximation rule is 100 e Create upser approximation rules and compute confidences Let Ajk XJ denote the set of objects that have the same attribute values\(Aj only some but not all contained in cluster i Here Eq 2 and 3 are used to create upper approximation rules and to compute rules\222 confidences Continue with the previous example for GID  A contained by only some of the objects in YDH and YPH that are contained in XI Hence there are two upper approximation rules for XI which are 221R2 If customer loyalty  H then GlD  A\222 and 221R3 If necessary promotion  H then GID  A\222 Using.Eq 3 compute these two upper approximation rules\222 confidence. Here analysts can use the threshold value minimum confidence that are predetermined to decide which rules will be accepted The confidence for R2 is 2/3 and for R3 is 113 If the minimum confidence is set to 50 only R2 will he accepted U Figure 3 The combinatorial rules f Create new combinatorial rules This step considers two or more attributes to generate association rules. First we join each class in cause equivalence classes In the above example, Figure 3 displays the results of joins of APH with the other attribute degree of customer loyalty to find the combinatorial rules Oply one node ADH,pH*\(Xl that combines two classes ADH\(X and Api\(X1 that.is not empty 5 The confidence of ADH,PH*\(Xl therefore is calculated as follows CF\(ADH,pH*\(XI 7 11 0.33 1 Here we can define the confidence function of an n-attribute combinatorial rule nxk Nu4\(xl n  222 CI  Mi 7 So we create a new combinatorial rule 221R4 If customer loyalty  H and prompion  H  then GID  A CF  0.33\(equals to the CF\(APH XI 222 g Explain the characteristics of each cluster Rules iom RI to R4 are used to explain the meaning of cluster A In the above example the sale actions in cluster A have following characteristics 100 sale actions in cluster A need the promotion measure belonged to normal level about 1/3 sale actions in cluster A whose customer loyalty level is high and promotion need is high, and about 2/3 sale actions in cluster A whose degree of customer loyalty is high h Go to d to process the next equivalence class X and repeat until all the result equivalence classes are completed 3.3 Evaluation and presentation \(Step 3 After all related rules are created analysts can use evaluation module to eliminate unused or redundant rules in order to keep the most valuable rules in the knowledge bases that may be the case bases or/and rule bases for fnture use According to the sale characteristics \(quantity pattem and size in the sale action table and other potential associations of interesting attributes how to close a deal with a particular type of client or how to develop an 1824 


Proceedings of the Second International Conference on Machine Learning and Cybernetics Xi'an 2-5 November 2003 effective advertising campaign in the sale actions table we can create many rules with different purposes The managers retrieve these rules stored in the knowledge bases to determine the best decision making in all kinds of business areas 4 Conclusion This paper has briefly described how to integrate a neural network-SOM and rough set theory to discover association rules to support knowledge management Clustering module based on the SOM network separates the customers into clusters and a rule extraction module is used to characterize each cluster and explain the relationships  among different clusters These rules may help the managers to find out the useful measure to maintain old customers and develop new customers The data mining procedure can be use for offering the associations between customer relationships product development hq resource, the supply chain and so on However there is still space for the future research I I A tool with intelligent ability may be developed to dynamically include feedback and attributes for analysis 2 The clustering module based on the SOM network would be combined with tbe fuzzy concept to group uncertain or non-numerical data in order to discover the associations more close to the real environment 3 The analysis and development of the prototype may take into account more factors for future implementation Besides the more efficient association rules mining and filtering algorithms may also be the future work References George M Giaglis On the present and future of European research on knowledge and information management Proceeding of 24th Int Conf Information Technology Interfaces ITI 337-342,2002 Mastsuzawa H Fnkuda T Mining structured patterns from databases Proceeding 4th Pacific-Asia Conference on Knowledge Discovery and Data Mining 233-244,2000 Kim K S Han 1 The cluster-indexing method for cased reasoning using self-organizing maps and learning vector quantization for bond rating cases Expert Systems with Applications 21 147-156  2001 Kuo R J Chi S C Teng P W Generalized part family formation through fuzzy self-organizing feature map neural network Computer and Industrial Engineering 40 79-100,2001 5 Kiang M Y Extending the kohonen Self-organizing maps network for clustering analysis Computational Statistics and Data Analysis 38 161-180.2001 6 Vellido A Lisboa P J Meehan K Segmentation of the online shopping market using neural networks. Journal of Information Science and Engineering 14 843-862 1999 7 Changchien S W Lu T C Mining association rules procedure to support on-line recommendation by customers and products fragmentation Expert Systems with Applications 20 325-335,2001 SI Lin T Y Cercone N Rough Sets and data mining  analysis of imprecise data Kluwer Academic Publishers 1997 1825 


in Btree storage structure respectively The schemas of the relations are STUDENT logname c8 regno int advisor int, entry int year c2 scheme c6 uccacode c6 status cl examno int school c4 HOUSEHOLD hserno int persno int region c10 npersons int typaccm c10 bedrooms int centheat c4 ncars int ownrent c5 mortgage c4, cost int loan int The machine used was a 33Mhz SPARC-ELC with Ingres files held on a 2GB Fujitsu SCSI running synchronously Both relations are based on actual data used within the University Rules in our rules set were derived from the system by 12 91 The rule sets for each relation contained 50 rules The experiment was done for several thousand queries on both relations which was based on many observations using different featured rules in order to analyse the time saving using SQO For example if the rules contain any index attribute or not From our tests the following results were observed a For the both relations if the original query is refuted by any rule, the saving on average was 99.15 If the answer to the original query was found by one of the matching rules alone the saving on average was 99.53 b If the rule contained an indexed attribute the savings on average were up to 86.40 for 221STUDENT\222 and 83.52 for 221HOUSEHOLD\222 c In queries for which no indexed condition could be found, the saving on average was 6.39 for the relation 221STUDENT\222 and 1.94 for the relation 221HOUSEHOLD\222 The poorer result from the 221HOUSEHOLD\222 data was due to the lower number of instances per block compared with the 221STUDENT\222 relation 5 Conclusions This paper has described a fast query transformation process in SQO which constructs a near optimum query taking into account all matching rules The results are encouraging and promise large savings even when the rule set is large since transformation time is in linear function of rule set cardinality We are now extending our current work in statistics and knowledge discovery to address the issue of complex queries such as join queries and maintaining rules set 13 181 Acknowledgement We would like to thank John Ford  Tony Lawson in Computer Science Dept and Ken Miller  other personnel in the ESRC Data Archive at University of Essex Thanks also to Prof Tahir Sisman at Yildiz University for all his support during this research References I S Chakravarthy J Grant and J Minker 223Logic-based approach to semantic query optimisation\224 ACM on Database Systems Vol 15 No 2, 1990, pp. 162-207 2 K.C Chan and A.K.C Wong 223A statistical test for extracting classificatory knowledge form databases\224 Knowledge Discovery in Databases Ed The AAA1 Press 1991 pp 107-123 3 G Graefe and D Dewitt 223The EXODUS optimiser generator\224 In Proc of the 1987 ACM-SIGMOD Conf on Management of Data May 1987 pp 160-1711 4 J Han Y Cai and N Cercone 223Data-driven discovery of quantitative rules in relational databases\224 IEEE on Knowledge and Data Eng Vol5 no 1 Feb 1993 pp 29-40 5 C Hsu and C.A Knoblock, \223Rule induction for semantic query optimisation\224 In Proceedings of the Eleventh International Conf on Machine Learning 1994  I F Imam R S Michalski and L. Kerschberg 223Discovering attribute dependence in database by integrating symbolic learning and statistical analysis tests\224 Knowledge Discovery in Databases Workshop 1993 pp 264-275 7 J J King 223QUIST A system for semantic query optimisation in relational databases\224 In Proceeding of the 7 th VLDB Conference, Sept. 1981 pp 510-517 8 B G T Lowden 223An Approach to Multikey Sequencing in an equiprobable keyterm retrieval situation\224 Proceedings of the Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 1985 pp 92-96 9 B G T Lowden J Robinson and K Y Lim 223A semantic query optimiser using automatic rule derivation\224, Proc Fifth Annual Workshop on Information Technologies and Systems Netherlands, 68-76 December 1995 pp 68-76 lo L F Mackert and G M Lohman 223R optimizer validation and performance evaluation for local queries\224, Proc ACM-SIGMOD 1986 pp 84-95  111 G.Piatetsky-Shapiro and C Matheus 223Measuring data dependencies in large databases\224 Knowledge Discovery in Databases Workshop 1993 pp 162-173 12 A Sayli and B G T Lowden 223The use of statistics in semantic query optimisation\224, Thirteenth European Meeting on Cybernetics and Systems Research Vienna April 1996 pp 991-996 325 


 131 M SCHKOLNICK and P TIBERIO 223Estimating the cost of updates in a relational database\224 ACM Trans Database Systems 10,2 June 1985 pp 163-179  141 S Shekhar J Srivastava and S Dutta 223A formal model of trade-off between optimisation and execution costs in semantic query optimization\224 Proceedings of the 14th VLDB Conference Los Angeles, California, 1988 pp 457-467 15 S Shekhar B Hamidzadeh and A Kohli Learning transformation rules for semantic query optimisation a data driven approach. IEEE, 1993 pp 949-964 16 S.T Shenoy and Z.M Ozsoyoglu 223Design and implementation of semantic query optimiser\224 IEEE Transactions on Knowledge and Data Engineering Vol 1 No 3 Sept. 1989 pp 344-361 17 M.D Siegel E Sciore and S Salveter 223A method for automatic rule derivation to support semantic query optimisation\224 ACM Transactions on Database Systems Vol 17 No 4 Dec 1992, pp 563-600  181 C Yu and W Sun 223Automatic knowledge acquisition and maintenance for semantic query optimisation\224 IEEE Trans Knowl. Data Eng 1 3 Sept. 1989, pp 362-375 326 


of the query expression without ha ving the global view of the in ten tion There is a big c hance that the enco ded pro cedure ma y not b e the b est w a y to compute the rules dep ending on the database instance F urthermore as w e understand it their prop osals require p oten tially large n um ber of name generation for relations and attributes The names that are needed are usually database dep enden t and th us p ossibly cannot b e gathered at query time An additional pro cess needs to b e completed to gather those v ariables b efore actual computations can b egin 5  9 Optimization Issues While it w as in tellectually c hallenging to dev elop a declarativ e expression for asso ciation rule mining from deductiv e databases there are sev eral op en issues with great promises for resolution In the w orst case the least xp oin tneedsto generate n 2 tuples in the rst pass alone when the database size is n  Theoretically  this can happ en only when eac h transaction in the database pro duces an in tersection no de and when they are not related b y subset-sup erset relationship In the second pass w e need to do n 4 computations and so on The question no w is can w e a v oid generating and p erhaps scanning some of these com binations as they will not lead to useful in tersections F or example the no de b 0 3 in gure 11 is redundan t A signican t dierence with apriori lik e systems is that our system generates all the item sets top do wn in the lattice without taking their candidacy as a large item set in to consideration Apriori on the other hand do es not generate an y no de if their subsets are not large item sets themselv es and thereb y prunes a large set of no des Optimization tec hniques that exploit this so called an ti-monotonicit y prop ert y of item set lattices similar to apriori could mak e all the dierence in our setup The k ey issue w ould b e ho ww e push the selection threshold minim um supp ort inside the top do wn computation of the no des in the lattice in our metho d F or the momen t and for the sak e of this discussion let us consider a higher supp ort threshold of 60 for the database T of gure 9 No w the l-en v elop e will b e the one sho wn in ligh ter dashed lines in gure 11 and the no des under this line will b e the large item sets Notice that no ww eha v eto discard no des ad 2 0 and d 0 2 to o This raises the question is it p ossible to utilize the supp ort and condence thresholds pro vided in the query and prune candidates for in tersection an y further Ideas similar to magic sets transformation 3  24 ma y be b orro w ed to address this issue The only problem is that pruning of an y no de dep ends on its supp ort coun t whic h ma y come at a later stage By then all no des ma y already ha v e b een computed and th us pushing selection conditions inside aggregate op erator ma y b ecome non-trivial Sp ecial data structures and indexes ma y also aid in dev eloping faster metho ds to compute ecien t interse ction joins that w e ha v e utilized in this pap er W e lea v e these questions as op en issues that should be tak en up in the future F ortunately though there has been a v ast b o dy of researc h in optimizing Datalog programs including recursiv e programs suc h as the one w e ha v e used in this pap er and hence the new questions and researc h 5 Recall that their prop osal requires one to express the mining problem to the system using sev eral queries and up date statemen ts that utilizes information ab out the database con ten ts to ac hiev e its functionalit y  c hallenges that this prop osal raises for declarativ e mining ma y exploit some of these adv ances Needless to emphasize a declarativ e metho d preferably a formal one is desirable b ecause once w e understand the functioning of the system w e will then be able to select appropriate pro cedures dep ending on the instances to compute the seman tics of the program whic hw e kno wis in tended once w e establish the equiv alence of declarativ e and pro cedural seman tics of the system F ortunately  w e ha v e n umerous pro cedural metho ds for computing asso ciation rules whic h complemen t eac h other in terms of sp eed and database instances In fact that is what declarativ e systems or declarativit y buy us  a c hoice for the most ecien t and accurate pro cessing p ossible 10 Conclusion Our primary goal for this pap er has b een to demonstrate that mining asso ciation rules from an y rst-order kno wledge base is p ossible in a declarativ ew a y  without help from an y sp ecial to ols or mac hinery  and that w e can no wha v ea v ery in tuitiv e and simple program to do so W eha v esho wn that it is indeed p ossible to mine declarativ ekno wledge b y exploiting the existing mac hinery supp orted b ycon temp orary inference engines in programming languages e.g Prolog or kno wledge base systems e.g RelationLog XSB LD L  CORAL All w e require is that the engine b e able to supp ort set v alued terms grouping aggregate functions and set relational op erators for comparison functionalities whic hmostofthesesystemscurren tly supp ort W e ha v e also demonstrated that our formalism is grounded on a more mathematical foundation with formal prop erties on whic h the seman tics of the R ULES system rely  W e ha v e also raised sev eral op en issues related to eciency and query optimization whic h should b e our next order of business As future researc h w e plan to dev elop optimization tec hniques for mining queries that require non-trivial lo ok ahead and pruning tec hniques in aggregate functions The dev elopmen ts presen ted here also ha v e other signican t implications F or example it is no w p ossible to compute c hi square rules 4 using the building blo c ks pro vided b y our system Declarativ e computation of c hi square rules to our kno wledge has nev er b een attempted for the man y pro cedural concepts the computation of c hi square metho d relies on In a separate w ork 2 w e sho w that the coun ting metho d prop osed in this pap er can be eectiv ely utilized to generate the exp ectations needed in order to compute suc h rules rather easily  These are some of the issues w e plan to address in the near future The motiv ation imp ortance and the need for in tegrating data mining tec hnology with relational databases has b een addressed in sev eral articles suc h as 12  13 They con vincingly argue that without suc h in tegration data mining tec hnology ma y not nd itself in a viable p osition in the y ears to come T o b e a successful and feasible to ol for the analysis of business data in relational databases suc htec hnology m ust b e made a v ailable as part of database engines and as part of its declarativ e query language Our prop osal for declarativ e mining bears merit since it sheds ligh t on ho w rst order databases can be mined in a declarativ e and pro cedure indep enden t w a y so that the optimization issues can b e delegated to the underlying database engine Once suc h argumen ts are accepted sev eral systems 9 


related issues b ecome prime candidates for immediate atten tion F or example traditionally database systems supp orted declarativ e querying without the necessit y to care ab out the pro ceduralit y of the queries In this pap er w eha v e actually demonstrated that asso ciation rule mining can b e view ed as a Datalog query  It is immediate that a direct mapping from the Datalog expressions presen ted in this pap er to SQL can be dev elop ed with no problem at all W e can then rely on ecien t database pro cessing of the query in an optimized fashion Hence w ecomeclose to the essence of the visions expressed b y the leading database researc hers and practioners 12  References 1 Rak esh Agra w al and Ramakrishnan Srik an t F ast algorithms for mining asso ciation rules in large databases In VLDB  pages 487{499 1994 2 Anon ymous A declarativ e metho d for mining c hisquare rules from deductiv e databases T ec hnical rep ort Departmen t of Computer Science Anon ymous Univ ersit y USA F ebruary 2001 3 C Beeri and R Ramakrishnan On the po w er of magic In Pr o c e e dings of the 6th A CM Symp osium on Principles of Datab ase Systems  pages 269{283 1987 4 Sergey Brin Ra jeev Mot w ani and Craig Silv erstein Bey ond mark et bask ets Generalizing asso ciation rules to correlations In Pr o c A CM SIGMOD  pages 265 276 1997 5 D Chimen ti et al The LD L system protot yp e IEEE Journal on Data and Know le dge Engine ering  2\(1 90 1990 6 Jia w ei Han Jian P ei and Yiw en Yin Mining frequen t patterns without candidate generation In Pr o c A CM SIGMOD  pages 1{12 2000 7 Marcel Holsheimer Martin L Kersten Heikki Mannila and Hann uT oiv onen A p ersp ectiv e on databases and data mining In Pr o c of the sixth A CM SIGKDD Intl Conf  pages 150{155 Mon treal Queb ec 1995 8 Flip Korn Alexandros Labrinidis Y annis Kotidis and Christos F aloutsos Ratio rules A new paradigm for fast quan tiable data mining In Pr o c of 24th VLDB  pages 582{593 1998 9 Brian Len t Arun N Sw ami and Jennifer Widom Clustering asso ciation rules In Pr o c of the 3th ICDE  pages 220{231 1997 10 Mengc hi Liu Relationlog At yp ed extension to datalog with sets and tuples In John Llo yd editor Pr oc e e dings of the 12th International L o gic Pr o gr amming Symp osium  pages 83{97 P ortland Oregon Decem ber 1995 MIT Press 11 Rosa Meo Giusepp e Psaila and Stefano Ceri An extension to SQL for mining asso ciation rules Data Mining and Know le dge Disc overy  2\(2 1998 12 Amir Netz Sura jit Chaudh uri Je Bernhardt and Usama M F a yy ad In tegration of data mining with database tec hnology  In Pr o c e e dings of 26th VLDB  pages 719{722 2000 13 Amir Netz Sura jit Chaudh uri Usama M F a yy ad and Je Bernhardt In tegrating data mining with SQL databases In IEEE ICDE  2001 14 Ra ymond T Ng Laks V S Lakshmanan Jia w ei Han and Alex P ang Exploratory mining and pruning optimizations of constrained asso ciation rules In Pr o c A CM SIGMOD  pages 13{24 1998 15 Jong So o P ark Ming-Sy an Chen and Philip S Y u An eectiv e hash based algorithm for mining asso ciation rules In Pr o c A CM SIGMOD  pages 175{186 1995 16 Karthic k Ra jamani Alan Co x Bala Iy er and A tul Chadha Ecien t mining for asso ciation rules with relational database systems In Pr o c e e dings of the International Datab ase Engine ering and Applic ations Symp osium  pages 148{155 1999 17 R Ramakrishnan D Sriv asta v a and S Sudarshan CORAL  Con trol Relations and Logic In Pr o c of 18th VLDB Confer enc e  pages 238{250 1992 18 Konstan tinos F Sagonas T errance Swift and Da vid Scott W arren XSB as an ecien t deductiv e database engine In Pr o c of the A CM SIGMOD Intl Conf  pages 442{453 1994 19 Sunita Sara w agi Shib y Thomas and Rak esh Agra w al In tegrating mining with relational database systems Alternativ es and implications In Pr o c A CM SIGMOD  pages 343{354 1998 20 Ashok a Sa v asere Edw ard Omiecinski and Shamk an tB Nav athe An ecien t algorithm for mining asso ciation rules in large databases In Pr o c of 21th VLDB  pages 432{444 1995 21 Pradeep Sheno y  Ja y an t R Haritsa S Sudarshan Gaura v Bhalotia Ma y ank Ba w a and Dev a vrat Shah T urb o-c harging v ertical mining of large databases In A CM SIGMOD  pages 22{33 2000 22 Abraham Silb ersc hatz Henry F Korth and S Sudarshan Datab ase System Conc epts  McGra w-Hill third edition 1996 23 Shib y Thomas and Sunita Sara w agi Mining generalized asso ciation rules and sequen tial patterns using SQL queries In KDD  pages 344{348 1998 24 J D Ullman Principles of Datab ase and Know le dgeb ase Systems Part I II  Computer Science Press 1988 25 Mohammed J Zaki Generating non-redundan t association rules In Pr o c of the 6th A CM SIGKDD Intl Conf  Boston MA August 2000 1 0 


OM OM 006 OD8 01 012 014 016 018 02 022 False alarm demity Figure 9 Percentage of tracks lost within 200 seconds using three-scan assignment with PD  0.9 TI  O.ls Figure 11 T2  1.9s and T  Is ij  20 and 0  0.1 24 1 22  20  E fls 0  8l 16 0 n 14  12  0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 T1/12 PD Average track life of three-scan assignment with PD varying TI  0-ls T2  1.9s T  Is X  0.02 ij LO and   0.1 mareuvenng index Figure 12 Percentage of lost tracks of 4-D assipment in 200 seconds with maneuvering index varying X  0.01 Ti  0.1 T2  1.9s and T  IS PD  0.98 Figure 10 Percentage of lost tracks of 4-D assignment in 200 SeoDllCls with TI and T2 varying PD  0.98 X  0.02 q 20 and 0  0.1 4-1607 


Figure 13 Average gate size for Kalman filter Figure is relative as compared to nq and curves are parametrized by ij/r with unit-time between each pair of samples 1.2 Iy I 1.1 0.5 I A CRLB for he unifm samiina I  0.4 0.35 d 3 03 i7 3 0.25 0 0.M 0.04 0.06 008 0.1 0.12 0.14 0.16 0.18 0.2 False A!am DemW V I    Figure 14 CramerRao Lower Boundfor Mean Square Error of uniform and nonuniform sampling schemes with Ti  O.ls T2  1.9s T  IS PD  0.9 ij  5 and U  0.25 1 unifon sampling r-ls ked i non-uniform sampling loge inlewi I ti non-uniform sampling shod interva I 0.9 0.8 I Figure 15 MSE comparison of three-scan assignment with Ti and T2 varying I'D  1 X  0.01 ij  20 and U  0.1 4-1608 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



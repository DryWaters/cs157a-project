978-1-4244-5934-6/10/$26.00 ©2010 IEEE                                 191 2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery \(FSKD 2010 


192 


193 


194 


195 


Fig 5 Visualization of the future paths considered by the A controller Each read line shows a possible future trajectory for Mario taking the dynamic nature of the world into account not the case Instead a more accurate representation of the distance to the goal can be given by simulating the time required to reach the right border of the window Here the current speed of Mario is taken into account The quickest solution to get to the goal would then be to accelerate as fast as possible and taking the required time as a heuristic Similarly the previous distance of a node to the starting node is simply the time it took to reach the current node c Variable Optimisation While the A search algorithm is quite solid and guarantees optimality certain restrictions need to be put on its execution time to stay within the allowed 40ms for each game update These restrictions will likely lead to a non-optimal solution so careful testing has to be undertaken to ensure that the search terminates The 002rst restriction used was to stop looking for solutions when the time-limit had been reached and using the node with the best heuristic so far as a goal node The linear level design created by the level generator in In\002nite Mario favors this approach as it does not feature dead ends that would require back-tracking of suboptimal paths The requirement that the heuristic has to be admissible has also been relaxed A slightly overestimating heuristic increases the speed of the algorithm in expense of accurac In detail the estimation of the remaining distance can be multiplied with a factor w   1  Experimentation with different values for w  led to an optimal factor of w  1  11  Another factor that has an effect on the processing time required by A is the frequency of plan recalculation As mentioned above limited information requires a recalculation of the plan once new information becomes available i.e obstacles or enemies enter the window of visible information Experimentation indicated that the best balance between planning ahead and restarting the planning process to incorporate new information is given when the plan is recreated every two game updates Planning longer in advance occasionally led to reacting too late to previously unknown threats resulting in a lost life or slowdown of Mario B Other A*-based controllers Two other controllers were submitted that were based on the A algorithm One was submitted by Peter Lawford and the other by a team consisting of Andy Sloane Caleb Anderson and Peter Burns we will refer to this team with Andy's name in the score tables These submission were inspired by Robin's controller and used a similar overall approach but differed signi\002cantly in implementation C Other hand-coded controllers The majority of submitted controllers were hand-coded and did to our best knowledge not use any learning algorithms nor much internal simulation of the environment Most of these continuously run rightwards but use heuristics to decide when and how to jump Some were built on one of the standard heuristic controllers supplied with the competition software The following are very due to space limitations brief characterizations of each 1 Trond Ellingsen Rule-based controller Determines a 223danger level\224 of each gap or enemy and acts based on this 2 Sergio Lopez Rule-based Answers the questions 223should I jump?\224 and 223which type of jump?\224 heuristically by evaluating danger value and possible landing points 3 Spencer Schumann A standard reactive heuristic controller from the example software augmented with a calculation of desired jump length based on internal simulation of Mario's movement Incomplete tracking of enemy positions 4 Mario Perez Subsumption controller inspired by controllers used in behaviour-based robotics 5 Michal Tulacek Finite state machine with four states walk-forward  walk-backward  jump and jump-hole  6 Rafel Oliveira Reactive controller did not submit any documentation 7 Glenn Hartmann Based on an example controller Shoots continuously jumps whenever needed D Learning-based controllers A number of controllers were submitted that were developed using learning algorithms in one way or another These controllers exhibit a fascinating diversity still due to space considerations and paucity of submitted documentation also these controllers will only be described summarily 1 Matthew Erickson Controller represented as expression tree evolved with fairly standard crossover-heavy Genetic Programming using CompetitionScore as 002tness The tree evaluates to four boolean values left/right jump run and duck Nonterminal nodes where chosen among standard arithmetic and conditional functions The terminals were simple hard-coded feature detectors 2 Douglas Hawkins Based on a stack-based virtual machine evolved with a genetic algorithm 3 Alexandru Paler An intriguing combination of imitation learning based on data acquired from human playing and path-\002nding A is used to 002nd the route to the end of the screen the intermediate positions form inputs to a neural network trained on human playing which returns the number and type of key presses necessary to get there 


4 Sergey Polikarpov Based on the 223Cyberneuron\224 architecture 8 and trained with a form of reinforcement learning A number of action sequences are generated and each is associated with a neuron this neuron is penalized or rewarded depending on Mario's performance while the action sequence is being executed 5 Erek Speed Rule-based controller evolved with a GA Maps the whole observation space  22 002 22  onto the action space resulting in a genome of more than 100 Mb VII R ESULTS The 002rst phase of the competition was associated with the ICE-GIC conference in London and the results of the competition presented at the conference The results are presented in table I and show that Robin Baumgarten's controller performed best very closely followed by Peter Lawford's controller and closely followed by Andy Sloane et al.'s controller We also include a simple evolved neural network controller and a very simple hard-coded heuristic controller  ForwardJumpingAgent which was included with the competition software and served as inspiration for some of the competitors for comparison none of the agents that were not based on A outperformed the heuristic controller TABLE I R ESULTS OF THE ICE-GIC PHASE OF THE COMPETITION  Competitor progress ms/step Robin Baumgarten 17264 5.62 Peter Lawford 17261 6.99 Andy Sloane 16219 15.19 Sergio Lopez 12439 0.04 Mario Perez 8952 0.03 Rafael Oliveira 8251  Michael Tulacek 6668 0.03 Erek Speed 2896 0.03 Glenn Hartmann 1170 0.06 Evolved neural net 7805 0.04 ForwardJumpingAgent 9361 0.0007 The second phase of the competition was associated with the CIG conference in Milan Italy and the results presented there For this phase we had changed the scoring procedure as detailed in section IV-A A wise move as both Robin Baumgarten's and Peter Lawford's agent managed to 002nish all of the levels and Andy Sloane et al.'s came very close In compliance with our own rules Robin rather than Peter was declared the winner because of it being faster having more in-game time left at the of all levels It should be noted that Peter's controller was better at killing enemies though The best controller that was not based on A that of Trond Ellingsen scored less than half of the A agents The best agent developed using some form of learning or optimization that of Matthew Erickson was even further down the list This suggests a massive victory of classic AI approaches over CI techniques At least as long as one does not care much about computation time if score is divided by average time taken per time step the extremely simple heuristic ForwardJumpingAgent wins the competition 8 http://arxiv.org/abs/0907.0229 VIII D ISCUSSION AND ANALYSIS While the objective for the competitors was to design or learn a controller that played In\002nite Mario Bros as well as possible the objective for the organizers was to organize a competition that accurately tested the ef\002cacy of various controller representations and learning algorithms for controlling an agent in a platform game Here we remark on what we have learned in each of these respects using the software in your teaching and the future of the competition A AI for platform games By far the most surprising outcome of the competition was how well the A*-based controllers performed compared to all other controller architectures including controllers based on learning algorithms As A is a commonly used algorithm for path-\002nding in many types of commercial computer games e.g RTS and MMORPG games one could see this as a victory over 223classical\224 AI over more fancy CI techniques which are rarely used in the games industry However one could also observe that the type of levels generated by the level generator are much less demanding and deceiving than those found in the real Super Mario Bros games and other similar games All the levels could be cleared by constantly running right and jumping at the right moments there were no hidden objects and passages and in particular there were no dead ends that would require backtracking All the A*based agents consume considerably more processing time when in front of vertical walls where most action sequences would not lead to the right end of the screen suggesting that A would break down when faced with a dead end While the sort of search in game-state space that the A algorithm provides is likely to be an important component in any agent capable of playing arbitrary Mario levels it will likely need to be complemented by some other mechanism for higher-level planning and the architecture will probably bene\002t from tuning by e.g evolutionary algorithms Further the playing style exhibited by the A*-based agents is nothing like that exhibited by a human player the creepy exactness and absence of deliberation seems part of what made the YouTube video of Robin's agent so popular How to create a controller that can learn to play a platform game in a human-like style is an industrially relevant cf Demo Play  problem which has not been addressed by this competition B Competition organization Looking at the objectives enumerated in section IV we consider that the 002rst two objectives  ease of participation and transparency  have been ful\002lled the third  ease of 002nding a winner  could have been met better and that we largely failed at meeting the fourth  depth of challenge  Ease of participation was mainly achieved through having a simple web page simple interfaces and letting all competition software be open source Participation was greatly increased through the very successful media campaign built on social media Transparency was achieved through forcing all submissions to be open source and publishing them on 


TABLE II R ESULTS OF THE ICE-GIC PHASE OF THE COMPETITION  E XPLANATION OF THE ACRONYMS IN THE 223 APROACH 224 COLUMN  RB RULE BASED  GP GENETIC PROGRAMMING  NN NEURAL NETWORK  SM STATE MACHINE  L RS  LAYERED CONTROLLER  GA GENETIC ALGORITHM  Competitor approach progress levels time left kills mode Robin Baumgarten A 46564.8 40 4878 373 76 Peter Lawford A 46564.8 40 4841 421 69 Andy Sloane A 44735.5 38 4822 294 67 Trond Ellingsen RB 20599.2 11 5510 201 22 Sergio Lopez RB 18240.3 11 5119 83 17 Spencer Schumann RB 17010.5 8 6493 99 24 Matthew Erickson GP 12676.3 7 6017 80 37 Douglas Hawkins GP 12407.0 8 6190 90 32 Sergey Polikarpov NN 12203.3 3 6303 67 38 Mario Perez SM Lrs 12060.2 4 4497 170 23 Alexandru Paler NN A 7358.9 3 4401 69 43 Michael Tulacek SM 6571.8 3 5965 52 14 Rafael Oliveira RB 6314.2 1 6692 36 9 Glenn Hartmann RB 1060.0 0 1134 8 71 Erek Speed GA out of memory the web site after the end of the competition However many competitors did not describe their agents in detail In future competitions the structure of such descriptions should be speci\002ed and submissions that are not followed by satisfactory descriptions should be disquali\002ed C Using the Mario AI Competition in your own teaching The Mario AI Competition web page complete with the competition software rules and all submitted controllers will remain in place for the foreseeable future We actively encourage use of the rules and software for your own events and have noted that at least one local Mario AI Competition has already launched at UC San Diego Additionally the software is used for class projects in a number of AI courses around the world When organizing such events it is worth remembering that the existing Google Group and its archive can serve as a useful technical resource and that the result tables in this paper provide a useful point of reference We appreciate if any such events link back to the original Mario AI Competition web page and students are encouraged to submit their agents to the next iteration of the competition D Future competitions The 2010 Mario AI Championship like the 2009 competition uses a single website 9 but is divided into three tracks 1 The gameplay track Similarly to the 2009 competition this track is aimed at producing the controller that gets furthest on a sequence of levels However the competition software is modi\002ed so that some of the levels are substantially harder than the hardest levels in last year's competition 2 The learning track This track is similar to the gameplay track but favours controllers that perform online learning Each controller will be tested a large number e.g 1000  9 http://www.marioai.org of times on a single level but only the score on the last attempt will count The level will contain e.g hidden blocks shortcuts and dead ends Thus the scoring will reward controllers that learn the ins and outs of a particular level 3 The level generation track The level generation track differs substantially from the other tracks as what is tested is not controllers for the agent but level generators that create new Mario levels that should be fun for particular players The generated levels will be evaluated by letting a set of human game testers play them live at the competition event R EFERENCES  J T ogelius S M Lucas H Duc Thang J M Garibaldi T Nakashima C H Tan I Elhanany S Berant P Hingston R M MacCallum T Haferlach A Gowrisankar and P Burrow 223The 2007 ieee cec simulated car racing competition,\224 Genetic Programming and Evolvable Machines  2008 A v ailable http://dx.doi.org/10.1007/s10710-008-9063-0  D Loiacono J T ogelius P  L Lanzi L Kinnaird-Heether  S M Lucas M Simmerson D Perez R G Reynolds and Y Saez 223The WCCI 2008 simulated car racing competition,\224 in Proceedings of the IEEE Symposium on Computational Intelligence and Games  2008  J T ogelius S Karakao vskiy  J K outnik and J Schmidhuber  223Super mario evolution,\224 in Proceedings of IEEE Symposium on Computational Intelligence and Games CIG  2009  K Compton and M Mateas 223Procedural le v el design for platform games,\224 in Proceedings of the Arti\002cial Intelligence and Interactive Digital Entertainment International Conference AIIDE  2006  G Smith M T reanor  J Whitehead and M Mateas 223Rh ythm-based level generation for 2d platformers,\224 in Proceedings of the International Conference on Foundations of Digital Games  2009  C Pedersen J T ogelius and G Y annakakis 223Modeling player e xperience in super mario bros,\224 in Proceedings of IEEE Symposium on Computational Intelligence and Games CIG  2009  P  Hart N Nilsson and B Raphael 223A formal basis for the heuristic determination of minimum cost paths,\224 IEEE transactions on Systems Science and Cybernetics  vol 4 no 2 pp 100\226107 1968  I Millington and J Funge Arti\002cial Intelligence for Games  Morgan Kaufmann Pub 2009 


Application of Chaotic Particle Swarm Optimization Algorithm in Chinese Documents Classification 763 Dekun Tan Qualitative Simulation Based on Ranked Hyperreals 767 Shusaku Tsumoto Association Action Rules and Action Paths Triggered by Meta-actions 772 Angelina A. Tzacheva and Zbigniew W. Ras Research and Prediction on Nonlinear Network Flow of Mobile Short Message Based on Neural Network 777 Nianhong Wan, Jiyi Wang, and Xuerong Wang Pattern Matching with Flexible Wildcards and Recurring Characters 782 Haiping Wang, Fei Xie, Xuegang Hu, Peipei Li, and Xindong Wu Supplier Selection Based on Rough Sets and Analytic Hierarchy Process 787 Lei Wang, Jun Ye, and Tianrui Li The Covering Upper Approximation by Subcovering 791 Shiping Wang, William Zhu, and Peiyong Zhu Stochastic Synchronization of Non-identical Genetic Networks with Time Delay 794 Zhengxia Wang and Guodong Liu An Extensible Workflow Modeling Model Based on Ontology 798 Zhenwu Wang Interval Type-2 Fuzzy PI Controllers: Why They are More Robust 802 Dongrui Wu and Woei Wan Tan Improved K-Modes Clustering Method Based on Chi-square Statistics 808 Runxiu Wu Decision Rule Acquisition Algorithm Based on Association-Characteristic Information Granular Computing 812 JianFeng Xu, Lan Liu, GuangZuo Zheng, and Yao Zhang Constructing a Fast Algorithm for Multi-label Classification with Support Vector Data Description 817 Jianhua Xu Knowledge Operations in Neighborhood System 822 Xibei Yang and Tsau Young Lin An Evaluation Method Based on Combinatorial Judgement Matrix 826 Jun Ye and Lei Wang Generating Algorithm of Approximate Decision Rules and its Applications 830 Wang Yun and Wu-Zhi Qiang Parameter Selection of Support Vector Regression Based on Particle Swarm Optimization 834 Hu Zhang, Min Wang, and Xin-han Huang T-type Pseudo-BCI Algebras and T-type Pseudo-BCI Filters 839 Xiaohong Zhang, Yinfeng Lu, and Xiaoyan Mao A Vehicle License Plate Recognition Method Based on Neural Network 845 Xing-Wang Zhang, Xian-gui Liu, and Jia Zhao Author Index 849 
xiii 


   C4.2 Open GL has excellent documentation that could help the developer learn the platform with ease C4.3 Developer has very little ex perience in working with Open GL platform  For our case study, alternative B i.e. Adobe Director was the most favorable alternative amongst all the three. It catered to the reusability criteria quite well and aimed at meeting most of the desired operational requirements for the system   6. CONCLUSION & FUTURE WORK  The main contribution of this paper is to develop an approach for evaluating performance scores in MultiCriteria decision making using an intelligent computational argumentation network. The evaluation process requires us to identify performance scores in multi criteria decision making which are not obtained objectively and quantify the same by providing a strong rationale. In this way, deeper analysis can be achieved in reducing the uncertainty problem involved in Multi Criteria decision paradigm. As a part of our future work we plan on conducting a large scale empirical analysis of the argumentation system to validate its effectiveness   REFERENCES  1  L  P Am g o u d  U sin g  A r g u men ts f o r mak i n g an d  ex p lain in g  decisions Artificial Intelligence 173 413-436, \(2009 2 A  Boch m a n   C ollectiv e A r g u men tatio n    Proceedings of the Workshop on Non-Monotonic Reasoning 2002 3 G  R Bu y u k o zk an  Ev alu a tio n o f sof tware d e v e lo p m en t  projects using a fuzzy multi-criteria decision approach Mathematics and Computers in Simualtion 77 464-475, \(2008 4 M T  Chen   F u zzy MCD M A p p r o ach t o Selec t Serv ice  Provider The IEEE International Conference on Fuzzy 2003 5 J. Con k li n  an d  M. Beg e m a n   gIBIS: A Hypertext Tool for Exploratory Policy Discussion Transactions on Office Information Systems 6\(4\: 303  331, \(1988 6 B P  Duarte D e v elo p in g a p r o jec ts ev alu a tio n sy ste m based on multiple attribute value theroy Computer Operations Research 33 1488-1504, \(2006 7 E G  Fo rm an  T h e  A n a l y t ic Hier a rch y P r o cess A n  Exposition OR CHRONICLE 1999 8 M. L ease  an d J L  L i v e l y  Using an Issue Based Hypertext System to Capture Software LifeCycle Process Hypermedia  2\(1\, pp. 34  45, \(1990 9  P e id e L i u   E valu a tio n Mo d e l o f Custo m e r Satis f a c tio n o f  B2CE Commerce Based on Combin ation of Linguistic Variables and Fuzzy Triangular Numbers Eight ACIS International Conference on Software Engin eering, Artificial Intelligence Networking and Parallel Distributed Computing, \(pp 450-454 2007  10  X  F L i u   M an ag e m en t o f an In tellig e n t A r g u m e n tatio n  Network for a Web-Based Collaborative Engineering Design Environment Proceedings of the 2007 IEEE International Symposium on Collaborative Technologies and Systems,\(CTS 2007\, Orlando, Florida May 21-25, 2007 11 X. F L i u   A n In ternet Ba se d In tellig e n t A r g u m e n tatio n  System for Collaborative Engineering Design Proceedings of the 2006 IEEE International Symposium on Collaborative Technologies and Systems pp. 318-325\. Las Vegas, Nevada 2006 12 T  M A sub jec tiv e assess m e n t o f altern ativ e m ission  architectures for the human exploration of Mars at NASA using multicriteria decision making Computer and Operations Research 1147-1164, \(June 2004 13 A  N Mo n ireh  F u zzy De cisio n Ma k i n g b a se d o n  Relationship Analysis between Criteria Annual Meeting of the North American Fuzzy Information Processing Society 2005 14 N  P a p a d ias HERMES Su p p o rti n g A r g u m e n tative  Discourse in Multi Agent Decision Making Proceedings of the 15th National Conference on Artifical Intelligence \(AAAI-98  pp. 827-832\dison, WI: AAAI/MIT Press,  \(1998a 15  E. B T riantaph y llo u   T h e Im p act o f  Ag g r e g atin g Ben e f i t  and Cost Criteria in Four MCDA Methods IEEE Transactions on Engineering Management, Vol 52, No 2 May 2005 16 S  H T s a u r T h e Ev alu a tio n o f airlin e se rv ice q u a lity b y  fuzzy MCDM Tourism Management 107-115, \(2002 1 T  D W a n g  Develo p in g a f u zz y  T O P S IS app r o ach  b a sed  on subjective weights and objective weights Expert Systems with Applications 8980-8985, \(2009 18 L  A  Zadeh  F u z z y Sets   Information and Control 8  338-353, \(1965  152 


                        






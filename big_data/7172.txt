Measurements Ma y Gao y ehei z Ranasinghe y y Australia f damith.ranasinghe g adelaide.edu.au z Australia ehei@rmit.edu.au Abstract net applications ely cryptoemanating often 
olong an vide we ysical ariof capasignal to 
a sal a  we or the experimental PUFs erms  function I N introduced vices a 
industrial sectors Often tin y sensor nodes are tentacles of such a communicate information 3 Therefore the ablilhas paramount terms tradicrypto wfor securing can xtracted by a moti v ated attack er  
lightweight yed resource-constrained vices  A PUF e xtracts secrets on demand from the introduced and since xtracted  e  esponse  mathematically function PUF PUF same 
 when reliable actors cryptographic responses it is potential authenticaapplications 7 10 it is preferable to maximize to xity ersary  to where those 
from to response vironmental bits w used  particular as Rosenfeld al  Here the PUF tak es not in inputs with 
In Rajendran al g Ruhrmair al  17 selected temperature as a concept eality ysical channel 
2ND IEEE PERCOM Workshop On Security Privacy And Trust In The Internet o\f Things 2017 978-1-5090-4338-5/17/$31.00 \2512017 IEEE 


dominant sense  without algorithms temperature light sensing elect rical signals\227e g v oltage\227is more ersatile sound signals reliability illustrated securely signals as a sal xoltage\227 based PUFs Complementary  are potential sal architecture response oltage sensing to be transducers conse ute xpedite highly those a  ork the en related by alidation in sensing challenges eral future R D W K ysical in Rosenfeld al  002rst the eny data In Rajendran al micro-electro-mechanical simulation responses in second for Ruhrmair al  17 also e xamined demonstrated of eality concept protocols untrusted eri\002er approach er st to xperimental orks from measurements to temperature response the reork as is xternal viour   In 20 Sharif al oltages recon\002guring increase propose by secure quantities S E S G C T unreliagenerated query ferent Notably  vironmental temperature aluated response More bit r wide reproducible 2ND IEEE PERCOM Workshop On Security Privacy And Trust In The Internet o\f Things 2017 


OPUF this  of k o k O i and O j comparator All R Os are designed be function ariations not are counters If f i f j where f i and f j of O i O j will controlled input O reladetermining In O 1 higher O 3 O 1 than O 3 challenge bit c 3 O 1 O 3 produce bit r 3 comparing f 1 and f 3 response crosspoint of f 1 and f 3 227between V 2 and V 3 at p 2 bit r 3 bits r 1  r 2 and r 3 applied corresponding challenges c 1  c 2 and c 3 oltages by V 1  V 2  V 3 and V 4 bit c bit r the Os from response challenges the of r 3 when r 3 is oltage V 1 1 at of V 4  of r 3 of that r 3 003ips from V 1 to V 4 entional that f 1 and f 3 intersects between V 1 and V 4 crosspoint p 2 PUF of supply alue  the the e same xpect to 3 response R challenge C the as V 1  V H F S procan for ariations in consisting of 002 v e FPGAs Detailed in F or a gi v en  operating 25 016 C challenge condition wing aluation InterPQ-distance a PUF responses R PQ 1  R PQ 2 aphence D terPQ dist R PQ 1  R PQ 2  1 where R PQ 1  R PQ 2 o to  IntraPQ-distance a PUF responses R PQ  R PQ 0 using setting D traPQ dist R PQ  R PQ 0  2 2ND IEEE PERCOM Workshop On Security Privacy And Trust In The Internet o\f Things 2017 


where R PQ  R PQ 0 responses same setting disare Hamming FHD def-distance responses challenge across instance intra-distance o aluations chosen intra-distance PQ anted noise and ution both the interPQ-distance and ution B  p  interPQare  p terPQ and  p traPQ in the  p terPQ general of R PQ 1 6  R PQ 2 the  p traPQ of R PQ 6  R PQ 0 2 difset wer  p traPQ higher  p terPQ 227 only in capability challenges alue challenges vironmental between  p traPQ and  p terPQ  PQ of f 1 and f 2 range the response bits r 1 and cases be are more resimply eliable es oltage the unreliable approach responses challenge ference 001 f a response high foundation y  measureOs satisfying j f 000 197  MHz j  001 f generation the of 001 f as 001 f  increase between  p terPQ speci\002c alidation\227and  p traPQ ference between  p terPQ and  p traPQ of ference of  p terPQ and  p traPQ of 001 f wn signi\002cantly when the 001 f the  p traPQ and  p terPQ e between  p traPQ and  p terPQ distinguish V i 1  2 where V i 2 f 0  V  1  V  1  V  1  V  1  V g from V i 1  32  B eri\002er frequencies discompleted Capability PUF sensing phase PUF to OPUFs from  2ND IEEE PERCOM Workshop On Security Privacy And Trust In The Internet o\f Things 2017 


The  p terPQ and  p traPQ ferent 001 f 227 challenge and  p traPQ V 6  p terPQ and  p traPQ Unreliable   p traPQ and 001 f MHz the completed to pre v ent an adv ersary to oneused CRPs an one-time challengealues 27 the ferent on During comparing the challenges response R PQ j  j f 1 p g PQ j challenge C 227with response R PQ i response R PQ j where i  j response R PQ i challenge C 002nds responses R PQ j ed R PQ i  PQ i this rejected a response caused the I Q T  p terPQ D  p traPQ Y 001 f  EER  10 000 6 001 f MHz  p in traPQ  p terPQ n n EER F AR 003 FRR 003 3 9.68 623 29 000 6  00 000 6  27 2 12.04 380 19 000 6  03 000 6  04 1 16.88 397 35 000 6  03 000 6  10 0.5 25.80 244 33 000 6  01 000 6  21 0.3 31.00 167 31 000 6  04 000 6  02 the 003 indicates log 10  001  alue fering threshold n th This alse user PQ j PQ i  i 6  j c PQ i be speci\002c number FRR successful CRPs n  threshold n th er formally in 28 1 000 n th X i 0 022 n i 023  p traPQ  i 1 000  p traPQ   n 000 i   3  n th X i 0 022 n i 023  p terPQ  i 1 000  p terPQ   n 000 i   4 FRR as or eshold as n EER error as ate ork F or a discrete distrib ution an n EER FRR case n EER in n EER min n th f max f AR n th   FRR n th  gg  5 max f AR n EER   FRR n EER  g  6 of n 227minimal and n EER of ferent  p terPQ and  p traPQ that both  p terPQ and  p traPQ chosen 001 f e of challenges n as 001 f the challenge method 2ND IEEE PERCOM Workshop On Security Privacy And Trust In The Internet o\f Things 2017 


C N enwhere responses electrical sensor oltage of to that xperimental  i ying CRPs n to ving  p traPQ desirabale temperature changes more speci\002cly  from 000 20 016 C to 120 016 C and PUF strong PUF 30 or a re v erse/reusabl e fuzzy e xtractor 31 32 attacks A T Research wledge 201306070017 R S  T  S L 264 Adding 224 Computing  2012  T  Abera N Asokan L Da vi F  K oushanf ar  A P a v erd A.-R Sade ghi IoT in C 121  D C Ranasinghe K S Leong M L Ng D W  Engels and P  Cole in Information ocessing 7\22612  R T orrance and D James 223The state-of-the-art in IC re v erse engiin CHES  363\226381  B Gassend D Li m D Clark e M V an Dijk and S De v adas 223Iden\224 and Experience 1077\2261098 2004  D C Ranasinghe and P  H Cole 223Confronting security and pri v ac y in  s 2058\2262064  G E Suh and S De v adas 223Ph ysical unclonable functions for de vice in utomation C 9\22614  A B Alv arez W  Zhao and M Alioto 223S tatic ph ysically unclonable insta\224 cuits  2016  R Maes A V an Herre we ge and I V erbauwhede 223PUFKY A fully in aphic CHES 302\226319  Y  Gao G Li H Ma S F  Al-Sara wi O Ka v ehei D Abbott and D C auin Int orkshops  1\2266  D Lim 223Extracting secret k e ys from inte grated circuits 224 Master s thesis 2004  U Ruhrmair  J Solter  F  Sehnk e X Xu A Mahmoud V  Sto yano v a modeling 224 ensics Security 2013  G T  Beck er  223The g ap between promise and reality On the insecurity in Embedded CHES 535\226555  K Rosenfeld E Ga v as and R Karri 223Sensor ph ysical unclonable in e\(HOST 112\226117  J Rajendran J T ang and R Karri 223Securing pressure measurements in Systems ISCAS 1330\2261333  U R 250 Hilgers reality in and S&P 70\22685  U Ruehrmair  M Stutzmann J Finle y  C Jirauschek G Csaba P  Lugli for 13/250,534  B Fisch D Freund and M Naor  223Ph ysi cal zero-kno wledge proofs of in O pp 313\226336  S Katzenbeisser  250 G.-J recon\002g\224 Engineering pp 2011  S Sharif Mansouri and E Dubro v a 223Ring oscillator ph ysical unclonable in Computer ICCD 520\226521  Y  Gao D C Ranasinghe S F  Al-Sara wi O Ka v ehei and D Abysical 224 Reports 2015  M Roel 223Ph ysically unclonable functions Constructions properties and ersity 2012  D C Ranasinghe D Lim S De v adas D Abbott and P  H Cole 224 onics s 2005  A Mai ti J Casarona L McHale and P  Schaumont 223 A lar ge scale in e\(HOST 94\22699  M.-D Y u M Hiller  J Delv aux R So well S De v adas and I V er on 224 i-Scale Systems 2016  R Maes 223 An accurate probabilistic reliabili ty model for silicon PUFs 224 in CHES pp 73\22689  T  Xu D Li and M Potk onjak 223 Adapti v e characterization and emstatistical in C 76  D Lim J W  Lee B Gassend G E Suh M V an Dijk and S De v adas 224 e Syst 2005  Y  Cao L Zhang C.-H Chang and S Chen 223 A lo w-po wer h ybrid R O 224 IEEE Syst pp 2015  Y  Gao D C Ranasinghe S F  Al-Sara wi O Ka v ehei and D Abbott IEEE 2016  A V an Herre we ge S Katzenbeisser  R Maes R Peeters A.-R Sade ghi Enin Security 374\226 389  R Canetti B Fuller  O P aneth L Re yzin and A Smith 223Reusable in  YPT  117\226146 2ND IEEE PERCOM Workshop On Security Privacy And Trust In The Internet o\f Things 2017 


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination EEE   7  crafted-feature-based methods. However, the lack of seman tic information provided by the category labels cannot guarantee the best discrimination ability between classes because unsupervised feature learning methods do not make  formance, we still need to use labeled data to develop super vised feature learning methods, which will be reviewed below, to extract more powerful features s Most of the current state-of-the-art approaches generally feature representations. Especially in 2006, a breakthrough in deep feature   engineered features with trainable multilayer networks and impressive feature representation capability for a wide range of appli  13], [17], [45], [50], [82], [143]\226[158 On the one hand, in comparison with traditional hand crafted features that require a considerable amount of engi neering skill and domain expertise, deep learning features are automatically learned from data using a general-purpose learning procedure via deep-architecture neural networks This is the key advantage of deep learning methods. On the other hand, compared with aforementioned unsupervised shallow-struc tured models \(e.g., sparse coding that are composed of multiple processing layers can learn more powerful feature representations of data with multiple levels of abstraction [159]. In addition, deep feature learning methods have also turned out to be very good at discovering intricate structures and discriminative information hidden in high-dimensional data, and the features from toper lay ers of the deep neural network show semantic abstracting properties. All of these make deep features more applicable Currently, there exist a number of deep learning mod   convolutional neural networks \(CNNs   on. Limited by the space, here we mainly review two widely  deep learning methods 1  model that has been successfully applied for remote sens  of multiple layers of autoencoders in which the outputs of each layer are wired to the inputs of the successive layer. To   layer on raw input data to obtain parameters and transfer the raw data into an intermediate vector consisting of activa tions of the hidden units. Then, this process is repeated for subsequent layers by using the output of each layer as input the parameters for the remainder of the model. To obtain better results, after  to tune the parameters of all layers at the same time with a smaller learning rate. Compared to a single autoencoder as mentioned in the previous subsection, the feature repre  This can be easily explained: with the composition of multi ple autoencoder that each transforms the representation at one level \(starting with the raw input at a higher, slightly more abstract level, we can learn very powerful representations. This has been proven in literature 13], [134], [169]\226[171 2 CNNs are designed to process data that come in the form of multiple arrays, for example, a multispectral image composed of multiple 2-D arrays containing pixel  the impressive success of AlexNet [163], many representa   been proposed in the literature. There exist four key ideas behind CNNs that take advantage of the properties of natu ral signals, namely, local connections, shared weights, pool ing, and the use of many layers [159 The architecture of a typical CNN is structured as a series of layers 1   Convolutional layers: They are the most important  edges lines, and corners features \(such as structures objects, and shapes 2   Pooling layers: Typically, after each convolutional layer, there exist pooling layers that are created by computing some local nonlinear operation of a par ticular feature over a region of the image. This pro cess ensures that the same result can be obtained even when image features have small translations or  tion and detection 3   Normalization layers: They aim to improve generali zation inspired by inhibition schemes presented in the real neurons of the brain 4   Fully as  straints, they can better summarize the information  decision. As a fully connected layer occupies most of  vent this, the dropout method was employed   163 


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination 8   EEE  CNNs in various remote sensing applications, such as geo      For instance, to address the problem of object rotation vari ations, Cheng et al       explicitly enforces the feature representations of the train  each other. Castelluccio et al 152] and Nogueira et al       best performing strategy on small-scale data sets V   T  T   dedicated toward the construction of various data sets [9], [11], [17], [33], [38  tion. Despite the remarkable progress made so far, as we  all existing remote sensing image data sets have a number of of scene classes numbers the lack of scene variations and diversity, and the saturation  popular UC Merced data set with deep CNN features [82 These limitations have severely limited the development of new data-driven algorithms and also prohibited the wide use of deep learning methods because almost all deep learning models are required to be trained on large training data sets Under such a circumstance, proposing a large-scale data set with big image variations and diversity is highly desirable   which is a freely and publicly available benchmark data set 5 t                 data set. These 45 scene classes are as follows: airplane, air port, baseball diamond, basketball court, beach, bridge, chap     overpass, palace, parking lot, railway, railway station, rec   court, terrace, thermal power station, and wetland   form, including land-use and land-cover classes \(e.g., commer cial area, farmland, forest, industrial area, mountain, and resi    ice terns, some homogeneous with respect to texture, some homo geneous with respect to color, others not homogeneous at all t    includes 700 images with a size of 256     256 pixels in the red\226   except for the classes of island, lake, mountain, and snow         Earth by the superimposition of images obtained from satel       shows two samples of each class from this data set   1        and publicly available benchmark data set, which covers 31   500      


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination EEE   9 ig. 2 eathers anslation c 


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination 10   EEE     the state of the arts 2 image variations  system, be it human or machine. However, most of the existing data sets are not very rich in terms of image vari ations. On the contrary, our images were carefully selected condi tions, imaging conditions, and scales. Thus, for each scene category, our data set possesses much rich variations in translation, viewpoint, object pose and appearance, spatial resolution, illumination, background, occlusion, etc 3 Similarity Many top-performing methods built upon deep  accuracy on most of the existing data sets owing to their sim plicity, or rather the lack of variations and diversity. With this in mind, our new data set is rather challenging with high within-class diversity and between-class similarity. To of conditions  and rectan basket ball court and tennis court, and so on V   B  S    s        Color histograms histograms is almost the simplest handcrafted feature that has been   because of its simplicity. Each channel is quantized into  64 bins for a total histogram feature length of 192. The his tograms are normalized to have an L1 norm of one 2   frequencies of local patterns in subregions. For an image, it   N   neighbors: when the neighbor\222s value is bigger than the value of center pixel output 1, otherwise, output 0. This forms an   N   decimal  obtained by computing the histogram of the decimal num bers over the image and results in a feature vector with   2   N     dimensions. In our implementation, we set   N     8   hence 3      is then averaged over 16 nonoverlapping regions arranged on a   4 _  _  4   grid. The resulting image representation is a 512-dimensional feature vector 4  popular visual features during the last decade. Owing to its  widely used by the community for geographic image clas  a   Patch extraction: With an image as input, the out puts of this step are image patches. This step is implemented via sampling local areas of images in a dense or sparse manner b   Patch the outputs of this step are their feature descriptors such as the c   Codebook generation: The inputs of this step are feature and the output is a visual codebook. The codebook is usually formed by unsupervised   k   means clustering over all feature d   Feature encoding: Given feature descriptors and codebook as input, this step quantizes each feature descrip tor into a visual word in the codebook e   Feature pooling: This step pools encoded local descriptors into a global histogram representation for each image 5 SPM     then concatenates them to represent the image. In our implementation, we divide each image into   1 _  _  1   and   2 _  _  2    subregions. Thus, given a codebook with the size   K   we can obtain a   5 K   dimensional feature vector for each image by 6 LLC variation of sparse coding       


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination EEE   11 simply by   k   means clustering without optimization. Therefore  7  Krizhevsky et al and was the winner of ImageNet large-scale     layers follow both response normalization layers and the   employ nonsaturating neurons, GPU implementation of the  feature from the second fully connected layer, which results in a feature vector of 4096 dimensions 8     former one because of its simpler architecture and slightly   CNN feature was also extracted from the second fully con nected layer to obtain a feature vector of 4096 dimensions 9 GoogLeNet is another representa tive CNN architecture that achieved new state of the art for  The main hallmark of its architecture is the improved utili  carefully crafted design, the depth and width of the network were increased while keeping the computational budget con of  more spatial information; and b to over  inside has 12 times fewer parameters than AlexNet. In our work, we extracted the GoogLeNet CNN feature from the last pooling layer to form a feature vector of 1024 dimensions 10    obtain better performance without using any data augmenta      gress while not clobbering the initialization p To make a comprehensive evaluation, two training\226test ran domly split into 10% for training and 90% for testing \(70 training samples and 630 testing samples per class 20%\22680%: the data set was randomly divided into 20% for training and 80% for testing \(140 training samples and 560 testing samples per class   each image patch with the patch size set to be   16 _  _  16   pix els and the grid spacing to be 8 pixels to balance the speed of 86]. The sizes of visual codebooks were set to be 500, 1000 2000, and 5000, respectively, to study how they affected the  GoogLeNet model, which were pretrained on ImageNet  caffe/wiki/Model-Zoo for deep CNN feature extraction To further improve their generalization capability, we also  Table   2. All three CNN models were implemented on a PC       C     1        scene class by treating the images of the chosen class as posi  s There exist three widely used, standard evaluation met   able 2    


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination 2   EEE  which class they belong to, divided by the total number of   matrix is an informative table used to analyze all the errors and confu sions between different classes which is generated by count  test samples and accumulating the results in the table the same image number per class, so the value of overall accu this paper, we just used the metrics of overall accuracy and  addition, in order to obtain reliable results for the metrics of overall accuracy and confusion matrix, we repeated the and report the mean and standard deviation of the results ts            all based on these optimal parameter settings Tables 3\2266 show the overall accuracies of three hand crafted global features, three unsupervised feature learning  CNN features, respectively, under the training ratios of 10 and 20%. The following can be seen in Tables 3\2266 1   Handcrafted low-level features have the relatively    tures. Actually, they act as mid-level image features that are ig. 3 W+SPM, and  0%; and  able                 


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination EEE   13  hence provide more semantic and more robust represen  semantic gap 3   Deep CNN features outperform all handcrafted features and unsupervised feature learning methods in very big margins \(at least 30% performance improvement  This demonstrates the huge superiority of the current-dom inated deep learning methods in comparison with previous state-of-the-art methods   els, the accuracy was further boosted by at least six percent age points, resulting in the highest accuracy matrices of different methods under the training ratios of 10% and 20%, respec tively, where the entry in the   i   th row and   j   th column denotes the rate of test samples from the   i   as the   j   th class. Limited by the space, we here just report the confusion matrices with the highest overall accuracies selected from features unsupervised feature learning methods, CNN features, and  the following 1 per-class accuracies, unsupervised feature learning methods take the second place, and deep-learning-based CNN features have the highest per-class accuracies 2 sions happen between \223golf court\224 and \223meadow\224 because they are characterized by green color  relatively big confusions happen between \223church\224 and \223pal    may be deep-learning-based methods in combination with dis criminative attributes oriented methods such as [23 I   ON            ig. 4 6 6 


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination 14   EEE        future research    cover in a given region. In fact, the more recent develop    of social media especially the online photo sharing web  collecting sorts of information of ground objects from geo                   Earth using the \223what\224 and \223where\224 aspects of the infor  the ground photos uploaded by user hold higher resolu    additional information is in fact very useful for the classi    future work, we need to explore new methods and sys  information coming from social media and spatial tech     6 6 


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination EEE   15 S            2   H    EEE      3   L   e  EEE      4   P l  EEE        224  s      6   G d                   l 224        9   L gs         r  s        224          s          s       l  s       e         e r 224       7   Q  r 224            g h 224 s        d         h       1   J i l r         2   G  l e  224        l            e   t                6   A e 224        7   G  d n          a l  e         h s         264  264 l g  e                    f 224          e          h          n   s       n                  e         224  t 0    0   M   224    0        t     2   R             g   s      4   G g l e  224        5   G g   224  s   


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination 16   EEE   6   J  e d 224      7   J n l s  d 224           n 224 g      r 224        n d 224        l 224         n l       3   Y g l     s       4   Y   d y  s                 e 224 n P         224        d g 224 e       9   L d d    226       224         g  g      2   E l e  e                4   M  c s    s        224        y  m         e d  e        224       9   L t 224          T S       e  0     tr g s       l d 224         n  a       d n e      g 224 y         n y           s      x         0   H  n d a 224   0     e        2   O s  l n  s        n  S      4   L  n y 224 s       s        n 224 s                   e  g      9   L e s   s       s  g         e  e    


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination EEE   17      e  224         l  h          224 s      264  264 d e           224 h        g y         d e   a                e 224        r n            e       3   G   e   t  1     e  n        g 224       6   T   l 224        7   A e c 224        8   D            t         t         n o l      224 s       224 s         n  t  3         7    6   C e    g      7   G    n          n n 224          d 224  s          224  s      n  224 n e      2   L D e         224         e          r e  e        d    t      g 224        e          r   s       r 224           224 s      2   W    224 s        g e e          e       5   I  s        A  s   


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination 8   EEE     h  e       p 224 s       d 224 n          224        1   G t g  e      2   J  r n   t      l  224 s          e       5   I c 264  t 224         l                  8   Y e  l        9   D            0   M d  g  e       A 224         l e A v a i l a b l e  2    3   K    6 n  A v a i l a b l e  h t t p s   a r x i v o r g  7    4   G r  n   t       g     0      224 n a       g 224        n   s        e       f  ut        r   ut        l h a   s  0     p   t            nt       n  nt      l h   t                  f n l  0      n  o   5                224        n  t      n    s       l n  t       e n E t       224    1 


This article has been accepted for inclusion in a future issue of this j\ournal. Content is final as presented, with the exception of pagination EEE   19 S Gong Cheng om Xidian  in 2007 and the M.S. and technical  3   He is currently an Associate Professor with Northwestern Polytechnical University. His main research interests are computer vision and pat tern recognition ei Han ently techni ch The ersity cher at the Uni His omputer vision, multi and brain imaging analysis. He es such as IEEE T C t T IONS  ON P A t t T ERN  A A YSIS  AND M CHINE  I I N t T ELLIGENCE AMI I I N t T ER NA t T IONAL J OURNAL  OF  C C O m p MP U t T ER V ISION V T C t T IONS  ON  I I m M GE P SSING  TIP C C ONFERENCE  ON  C C O m p MP U t T ER V ISION  AND P A t t T ERN  R R OGNI t T ION VPR I I N t T ERNA t T IONAL  C C ONFERENCE  ON  C C O m p MP U t T ER V ISION V I I N t T ERNA t T IONAL J OIN t T  C C ONFER ENCE  ON  A A R t T IFICIAL  I I N t T ELLIGENCE IJCAI Prof. Han is an Associate Editor of the I E E E IEEE T RANSAC t T IONS  ON  H H U m M AN M ACHINE  S S YS t T E m M S  Neurocomputing   Processing and Machine Vision and Applications  u ently f  tor ests include emote sensing om e eas  international journal, including Neurocomputing Elsevier Cognitive  Computation Springer International Journal of Image and Graphics  World of Scientific 



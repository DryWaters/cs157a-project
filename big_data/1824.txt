  An Information Systems Design Theory for Integrated Requirements and Release Management Systems  Timo Käkölä & Mervi Koivulahti-Ojala   Jani Liimatainen  University of Jyväskyl    Accenture  40014 Jyväskyl 00101 Helsinki Finland Finland timokk, meelheko}@jyu.fi    jani.liimatainen@accenture.com  Abstract High-tech companies need to collect and analyze requirements and allocate them to appropriate product releases in market-driven product development. Development activities are typically scattered across multiple sites and involve multiple partners in different countries complicating requirements and release management. Fle 
xible, scalable, and secure groupware-based support for the activities provides substantial payoffs. Yet, the extant literature provides little theoretical guidance for designing and using requirements and release management systems in multi-site, multi-partner environments. This article develops the meta-requirements and a meta-design of an Information Systems Design Theory for the class of Requirements and Release Management Systems based on a case study in a global company and a literature review The theory is scalable to meet the needs of global companies but simple enough so small and medium sized com 
panies can also leverage it to implement requirements and release management solutions Keywords Global software development, Information systems design theory, Knowledge management, Release management, Requirements management, Software process improvement  1. Introduction  To succeed in the global markets of software-intensive products, high-tech companies need to shorten the cycle time of new product development \(NPD\hile improving product quality and service delivery and maintaining or 
reducing the total resources required [7;40   This concern can be dealt with \(1\ternally through strategies such as global software development, where development resources are distributed globally to reap cost benefits and address specific needs of geographically-defined markets an d s o f t w a re produ ct lin e eng i n e e ring and management, that is, the strategic acquisition creation, and reuse of software assets 2  externally by acquiring commercial off-the-shelf components and outsourcing software development, maintenance, and related services to best-in-class international 
outsourcing service providers \(IOSPs\ [11 A v i abl e  third strategy is to enact both strategies in parallel All the strategies require companies to effectively collect, analyze, and utilize requirements in their market-driven product development [1;22;23;26;45;48 T h i s i s particularly true during the earliest phases of NPD in which different stakeholders need to integrate their knowledge into product concepts that direct the internal personnel and the IOSPs during the downstream phases of NPD 2;8;21 A  w e llde f i n e d prod u c t concept is necessary to establish a viable product line architecture that can be shared across the products within the product line to enab 
le strategic reuse. Well-defined requirements, architectural interfaces, and product structures are prerequisites for assigning appropriately scoped projects to IOSPs for implementation [11  The achievement of such integration is complicated by several factors L a rg e am o u n t of requ ire m en t s ranging from abstract wishes to detailed technical solution proposals are created continuously. Development activities are scattered across many sites and partners in different countries, limiting possibilities for setting up face-toface meetings a n i zati on al ch ang e s  diff ere n ces in  organizational cultures, and divergent perceptions about 
the prospective product s mission may make it difficult to reach an agreement about the product definition A commonly enacted software product line governance model and a strategic product line roadmapping process need to be instituted to en sure the organization is ready for multi-site development [36;52 A ll site s s h o u l d u s e as  compatible processes, methodologies, tools, and terminology as possible to enact the governance m h e  roadmaps detail the planned evolutions of the product lines and products by explicating common and variable features and allocating the features to scheduled product 
releases and responsible development organizations  A critical component of the governance model is that all requirements are \(1\red in a repository to ensure they are neither missed nor overlooked and \(2\ubjected to effective filtering in order to prevent information overload [34;48 T h e rem a in i n g requ ire m en t s are t h e n re fined, specified, estimated in terms of cost and resource implications, prioritized, and allocated to product releases and development units. Flexible, scalable, and secure communication, coordination, and collaboration support Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 1 978-0-7695-3450-3/09 $25.00 © 2009 IEEE 


 for these activities poses a significant challenge with substantial payoffs Design theories, unlike other theories, support the achievement of goals [4;25;37;50 l s Wi dm e y er, an d  El Sawy [50, p. 37 u e th at t h e inf o r m at ion s y s t e m s  IS field has now matured to the point where there is a need for theory development based on paradigms endogenous to the area itself and call for information system design theories \(ISDT\ulfill that need. An ISDT is a prescriptive theory based on theoretical underpinnings which says how a design process can be carried out in a way which is both effective and feasible ibid, p. 37 Salo and Käk oun d th at g rou p w arebas e d  requirements management systems \(RMS\ need to be designed and used to redesign and enact the earliest phases of product development effectively in multi-site cross-functional organizations. They developed an ISDT for RMS in order \(1\acilitate endogenous theory development in the context of RMS research, \(2\elp RMS designers build successful RM systems, and \(3\o guide organizations in evaluating and deploying RMS Salo and Käk o u n d t h at th e be n e f i ts a f f o rded by  RMS were hampered if the RMS instances prescribed by the ISDT were not integrated with systems used in the downstream phases in order to provide transparent end-toend support throughout the product development lifecycle. For example, customer representatives responsible for entering requirements could not use RMS to follow-up if and when the requirements would be implemented lowering their interests in entering the requirements. The scope of the ISDT should thus be broadened to design systems that support the lifecycle more comprehensively This research focuses on integrating requirements management with release management. Release management is concerned with the identification, packaging, and delivery of product s elements i rrors requirements management in the other end of the NPD lifecycle ensuring that internal and external releases meet the specified and managed subset of\irements identified in the front end of NPD and agreed upon during release planning and product line roadmapping. Based on our extensive industrial experience and review of academic literature, we hypothesize that the theoretical validity and practical relevance of the ISDT for RMS can be enhanced most effectively by extending the ISDT to provide integrated support for requirements and release management Release planning must be conducted carefully and systematically and the release plans must be communicated clearly and in time upstream to the stakeholders responsible for the requirements and the product strategy and downstream to the internal and external service providers  Oth e rw i s e, it is dif f i cu lt f o r th e prov iders to schedule and synchronize their production activities to meet the requirements specified in the release plans. For example, requirements are unlikely to be measurable and the functional sizes of software releases cannot be estima if th e requ ir em ents are n o t li n k e d to releases implementing them. The extant literature provides little guidance for designing and deploying integrated Requirements and Release Management systems This article develops the product aspects of the ISDT for the class of Requirements and Release Management Systems \(RRMS\. It addresses the following research question: What are the necessary and sufficient properties of RRMS in a multi-site, multi-partner environment? The main contributions of the article are the meta-requirements of the ISDT and a meta-design that partially meets the meta-requirements. They are crystallized and validated based on \(1\e study in a global organization that deploys a RRMS instance \(hereafter, RRMS\for effective requirements and release management and \(2\re review in the areas of requirements management, release management, and process integration. The ISDT has been created based on the experiences in the global organization to ensure the meta-design is scalable. However, we have made every effort to simplify the meta-design so even small and medium sized organizations can leverage it to implement RRMS solutions  2. Research Method  A literature review was performed to develop preliminary meta-requirements and meta-design elements before the case study started. The review was essential to reduce bias induced by the single case study and ensure generalizability of the meta-requirements and the metadesign to maximum possible extent e n t i a l  m e t a design elements that according to the review were peculiar to the organization were eliminated RRMS was a proprietary Lotus Domino based application developed in the organization. It had been productized, that is, one RRMS design was used. Business units had been closely involved in designing the system from the beginning and become committed to using and further developing it. They considered RRMS highly malleable to changing business needs partly because the organization controlled RRMS and business units did not need to negotiate with external vendors when changes were needed. RRMS had been institutionalized across the organization by the time the study was started. It was used by all development projects and updated by more than 10 000 people. RRMS enabled the projects quickly to locate existing reusable assets, substantially increasing productivity. Details concerning the organization and RRMS are beyond the scope of the paper While there were many reasons why RRMS was successful in the organization, one reason is crucial from the viewpoint of creating the ISDT for RRMS: RRMS enabled the real-time transparency and management of NPD efforts organization-wide but it was well scoped, did not impose more control and order than was necessary, and enabled people to use other information systems they weProceedings of the 42nd Hawaii International Conference on System Sciences - 2009 2 


 re familiar with. For example, RRMS did not replace existing project and portfolio management and product line roadmapping systems, which require advanced algorithmic models \(e.g., what if-analyses, cost and effort estimation, optimization of inter-dependent releases\d visualization techniques. Software development processes and systems were not significantly affected either because software development was beyond the scope of RRMS Projects increasingly leveraged agile development practices. RRMS thus could not impose unnecessarily stringent control mechanisms on them. Only the inputs to and the deliverables of management and software development processes and systems were dealt with by RRMS. For example, if requirements in RRMS needed specific product or organizational models to make them understandable, the models in the modeling environments were linked directly to RRMS or, sometimes, imported to RRMS. The analysis of RRMS has helped us to scope the partial ISDT for RRMS appropriately Two authors, a doctoral student and a master s student in information systems research, worked full time in the organization during a 6 month study period. RRMS had become increasingly complex over the years when its designers had tried to meet the ongoing influx of new requirements. While its functionality had been documented well, the organization was keen to further develop it A current state analysis of RRMS was thus deemed necessary to better understand the limitations and possibilities Major RRMS design changes were not realized during the study. Authors had access to all relevant information and could interact with all people who had been involved with the RRMS design. They observed the use of RRMS analyzed documentation, and conducted six semistructured interviews with middle-level managers who had been involved with both process improvement and the design and use of RRMS  After  interviews were completed, interviewees were provided with interview transcripts and summaries. Interviewees reviewed the meta-requirements and proposed new ones that were added to the original set if all interviewees considered the proposed meta-requirements critical for RRMS. The proposed meta-requirements and meta-design were used in the organization for further development of the RRMS Interestingly, the people authors interviewed or otherwise interacted with could not specify academic papers influential during the RRMS design. They were experts with long organizational tenures and relied on theories-inus e loped prim a ril y th rough social interactions c.f  perien ces f r o m earlier pr o j ects an d ag ile development practices instead of academic papers or design theories. Authors thus became increasingly intrigued with how to build such a simple but scalable and effective ISDT for RRMS based on the case study that designers and managers in other organizations would be willing to use such a theory in addition to trial and error mechanisms and long-reinforced theories-in-use  3. Meta-Requirements  of  the ISDT for RRMS  This section presents the meta-requirements for the ISDT for RRMS. They are introduced by revising a framework of Salo and Käköl  T h e f r a m e w ork cons i dered meta-requirements in relation to three categories of services that RMS have to offer: \(1\munication, \(2 control and \(3\ange. Communication refers to the ability of RMS to disseminate requirements information within organization, including information about the rationale for RM and its relationships to external environment Support for control ensures that requirements are dealt with in accordance with approved principles and procedures. Support for change is needed because products, technologies and customers change and RMS must remain amenable to adjustments at all levels of RM activity  Table 1. A framework for categorizing the metarequirements of the ISDT for RRMS Communication Control Change Platform development Process Integration  Prioritization and valuation of requirements and the allocation of requirements into releases  Traceability  Single capture of information  Content ownership and accountability  Management and coordination  Creating and sharing of metrics information  Access rights and information security  Version management of requirement documents  Release replanning  Change management and impact analysis  Defining and maintaining the requirements baseline  Creation and reuse of reusable assets  Knowledge creating capacity  Process transparency  Providing information at the right level of detail  Providing high quality information  The three categories are valid for RRMS but two new ones are needed: \(4\latform-based product development and \(5\rocess integration. Platform is the physical implementation of the baseline entity that contains the common business requirements for all the derivative products the platform has been designed to support \(c.f., [6;38;39   ll cu s t o m er s p ecif i c pro du ct dev e lopm e n t occurs on top of the platform. Table 1 classifies all RRMS meta-requirements  3.1 Meta-Requirements in Support of Communication  Prioritization and valuation of requirements and the allocation of requirements into releases Requirements must be allocated into releases using requirement prioritization and valuation methods that enable the most crucial requirements to be implemented and released firs h e m e t h ods are t y picall y bas e d o n  trade-off analysis between the \(economic\alues and implementation costs and resource constraints associated with the requirements [9,p.140;19;52 h ey  n eed to ta k e  Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 3 


 into consideration that all stakeholders do not have the same relative importance and that each stakeholder may valuate each requirement very differently  According to interviews, customer involvement in valuation, prioritization and selection adds value to these processes Requirements can be prioritized to releases by communicating with customers and agreeing on what functionalities are wanted and on what timetable  Traceability The purpose of requirement management is to achieve complete traceability from customers via the organizational departments to delivery [22,p.69 T r acea b ilit y i m proves risk assessment, project scheduling and change control [23,p A ll in ter v i e w e e s ag reed th at traceabilit y  from requirements elicitation to product delivery is critical for RRMS success. Interviewees also suggested other needs for traceability \(e.g., linking components, errors and use cases\. But it is expensive to collect and manage traceability information [30,p  T h e f o llo w i n g trace ability meta-requirements should always be implemented  Ability to trace forward from requirement sources to requirements and from requirements to subsequent features and corresponding design elements and designs  Ability to forward trace from design elements to subsequent designs and backward from corresponding features to requiremen  Ability to trace from requirements directly to design entities and backwa   Ability to trace requirements dependen  Single capture of information RRMS instances should be the single capture points for requirements, ensuring that there is no redundant and inconsistent requirement information in the organization and that all requirements are handled appropriately in a single effective and transparent process reducing the risks of missing or forgetting requirements. RRMS should thus be \(1\ easy to use for occasional users in order to ensure that they enter the information and \(2\terfaced to partners systems to ensure that partners can create update, and review information as necessary  3.2 Meta-Requirements in Support of Control  Content ownership Requirements and release management activities should have appropriate owners. The main obstacles to successful requirements management are the lack of norms for project and requirements management o n t en t  ownership can be enhanced by assigning roles with clearly defined responsibilities to persons. For example, a set of requirements could be allocated to a requirement manager while particular releases could be assigned to a release manager. The role definitions and assignments improve accountability, enable evaluations of people with respect to their role expectations \(e.g., release managers may be evaluated based on the quality of releases they are responsible for\d can ensure that all agreed upon deliverables are delivered in time and meet the defined quality criteria. Role based management also facilitates organizational \(e.g., people may continue their work in their old roles in a new organization\ and individual level changes e.g., a new person takes responsibility of a role\3; 34  This meta-requirement can thus be used in personnel evaluation, process development, and quality control Management and coordination Flows of requirements are coordinated and requirements are allocated to releases through managerial activities and decisions. For example, decisions need to be taken concerning the acceptance of particular requirements to the development process and the maturity levels of the requirements. To allocate requirements to specific releases and implementation teams and track their progress, requirements are assigned different statuses. Interviewees commented this meta-requirement It should be possible to see from the tool who is responsible for certain parts of the process, who makes decisions concerning those parts what the timetables are, and what kind of documentation should be available  Creating and sharing of metrics information Measurement is an essential part of process management [14;29;33 i n e d and m e a s u r able obj ectiv es are needed to evaluate the current status and develop the process. Metrics information enables comparison of process effectiveness across projects and products over time \(e.g project portfolio and product line management Access rights and information security Access rights and information security policies are important in high-technology companies. Products are typically designed and implemented in complex networks of companies where competitors are also involved. RRMS must help ensure that partners do not access each other s sensitive information. Multiple partners can build competing products on top of a shared platform and thus need to share information about the platform but they should know nothing about each other s products and objectives  3.3 Meta-Requirements in Support of Change  Version management of requirement and release documents Versions of individual requirements and requirements specifications need to be controlled [53, p.26 h an g e  management and document version management processes must be in place to create and maintain requirement baselines. Requirement document version management is related to the general workflow management. However one interviewee emphasized that it is most useful in requirement development phase, not in later phases when the documents are relatively stable. Change management and version management processes should be aligned and agreed upon If the change is large, a new requirement can Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 4 


 be created or the old one can be changed via the change management process. In practice, we could use version management for small revisions. But if the changes are too large, change management needs to be used  Release re-planning When software development is market-driven release planning and requirement prioritization are parts of strategic product plan e leas e re p lann i n g is needed when, for example, the product strategy is changed. Release re-planning may be related to planning the release cycles and the scope, role and timing of each individual release project or to release project management \(i.e., the length, scope, and the number of iteration cycles of a project\hen individual release projects develop the product versions Change management and impact analysis A clearly defined change management process is needed to estimate impacts of possible changes and to control the changes made to the requirements and releases  Change management and impact analysis enable organizations to be aware of the influences of requirement changes on the resources and market situation Defining and maintaining the requirements baseline Baselining refers to the freezing of current agreed upon requirements. When the baseline decision has been made subsequent requirements are treated as change requests and compared to the baseline. If the requests are accepted they will enter product development through the change management process [34     3.4 Meta-Requirements for Platform Development  Creation and reuse of reusable assets Platforms are strategic organizational assets designed to be reusable and afford common features and predefined variation mechanisms through which mass-customized products can be created quickly and cost effectively  Platforms consist of assets such as requirements, design elements, components, and user interfaces that are often also reusable. RRMS should provide a comprehensive information model to describe the assets adequately and advanced search functionalities to help projects easily find assets suitable for their needs Knowledge creating capacity Knowledge creating capacity R R M S re f e rs to a  functionality which helps users to leverage information and the platform assets in novel and possibly unforeseen ways The following quote clarifies the matter Requirement management involves the identification and management of baselines and products [for strategic reuse  For example, w e co ul d s ee fr om the tool th at this  baseline is good for our purposes and we just have to change it from there and there in order to have a right configuration for our needs  Ideally, users should not have to manually check the suitability of baselines or products for strategic reuse RRMS should suggest alternative baselines and automatically rank them by taking the parameters and constraints imposed by the context of reuse into account. This is possible when a mature platform has been created  3.5 Meta-Requirements in Support of Process Integration  Process transparency RRMS should help make integrated requirements and release management processes transparent, that is, the stakeholders involved should be able to understand the results of their RRMS-mediated actions and deal with unexpected errors or coordination breakdowns quickly before expensive disruptions in routines and flaws in deliverables occu T r an sparen cy ca n be f a c ilitated b y sta n dardizing the terms and forms of information transfer One interviewee stated Process transparency is especially important in decisi on making situations. Another important situation is when someone cannot implement for example, a requirement in a given timetable  High quality information Organizations have to be able to base their requirements and release decisions on high quality \(i.e., accurate, specific, relevant, reliable, timely, and accessible\ormation  Tran s p aren t RR MS m e d iated proces s e s an d co m mitted and skillful people are crucial to ensure high quality. RRMS should also help users to identify which pieces of information are the most critical in each phase of the process, for example, by sending reminders and highlighting the required fields in the different phases Providing information at the right level of detail Appropriate granularity of information facilitates decision making and eliminates extraneous activities required to decompose or summarize information h e rig h t  level of detail depends on the situation. For example highly mature requirements and release management processes can leverage much more detailed \(quantitative information than immature processes. RRMS must incorporate and represent requirement- and release-related information in granularity levels that are useful for different process contexts and roles    4. A Meta-Design of the ISDT for RRMS This section first outlines a generic meta-design for RRMS based on the analyses of interview transcripts RRMS, and the literature review. It covers a subset of the meta-requirements specified in the previous section. The section concludes by explicating the linkages between the meta-requirements and the meta-design to validate the meta-design and to justify its scope  4.1 Information Model for Integrated Requirement Management and Release Management Process To design an effective requirement management and release management process, the information model for Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 5 


 the process must be defined. We have synthesized a simple but scalable model based on the literature review and a detailed examination of RRMS. The experts of the organization have reviewed and accepted the model. It consists of four entities used in the integrated process and links between and within the entities to enable traceability, hierarchical composition \(i.e., each entity can consist of any number of the same type of entities\d appropriate granularity of information \(Figure 1 Customer Requirement, Requirement, Feature and Release. Requirement and Release are the base entities The other two are derivatives of Requirement Customer Requirement is used for requirements from the external environment. Internal and external requirements are separated to meet the meta-requirements related to platform-based product development and information security. For example, customer requirements are business critical and can provide competitive advantage by enabling organizations to focus efforts on implementing the differentiating and high-value adding requirements. Access rights for them and for requirements have to be defined and enacted differently Requirement is used for internal requirements developed by internal product creation processes within an organization or a network of companies collaborating to create a joint platform for effective product development Requirement can thus be used for platform requirements related to the platform offering. In the platform context customer requirements are used as the basis for developing derivative product s on top of the platform Separation of Customer Requirement and Requirement also facilitates change management. Requirements can be changed only through negotiations with their originators Negotiations with external requirement suppliers are more challenging than with suppliers of internal requirements  Figure 1. Information model of the meta-design of the ISDT for RRMS  Features denote intended behaviors or properties of software-intensive systems. They are usually created and managed as hierarchical solutions to the problems Requirements identify h e solu tion s  m a y re f l ect, f o r ex a m p le, business processes, organizational structures, or product architectures. Feature is the largest entity in the information model containing the technical specification workflow planning, and implementation. By using Feature as a basis of implementation and technical specification, requirements become more manageable and there are clear traceability links to th e origins of Feature instances and to implementation phases, that is, specifications responsible teams, and realized pieces of software code Release is used to group the implemented features into manageable entities that are released. Releases can also be organized hierarchically into, for example, platform and product releases The relationships between entities are explained next Customer requirements are allocated to one or more requirements, which, in turn, are allocated to features. Highest level requirements are typically large scale systemlevel definitions of business problems. Dividing them into sub-problems enables more accurate project cost, schedule, and effort estimation and better workflow management. For example, one feature can be implemented by one team. Features describe implementable partial solutions to the business problems. Releases are comprehensive, valuable solutions consisting of releases and features  4.2 Generic Structures of Entities  This section introduces generic structures and attributes of the entities presented in the information model According to the ISDT, RRMS instances should include at least these structures and attributes to be effective  Requirement and Customer Requirement Table 3 presents the generic structure of Requirement and Customer Requirement by revising and elaborating on the work of Salo & Käk t each cla s s  within the structure is presented Description describes the intent of and justification for a requirement and a customer Requirement. Version indicates the version number of the document. Name and ID are used for identification and traceability Origin describes where the requirement comes from and when. For customer requirements the sources are external organizations. For requirements, sources are customer requirements and internal organizational units Categorization describes the parts \(i.e., platform, product, and responsible person\of the product and the development organization the requirement or customer requirement is related to. Product platform works as the base architecture for derivative products. Requirements and customer requirements will be linked to appropriate platforms and final products. Responsible persons further develop requirements and customer requirements Analysis is used to probe the implications of the requirement. Priority and customer value can be handled as one attribute, but organizations needing sophisticated valuation processes should divide them in two. Customer need is used to describe the detailed business case, which the requirement or customer requirement is trying to solve. If Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 6 


 there is a firm deadline by which the requirement needs to e.g in their products\e deadline must be made explicit. The total cost and effort need to be estimated [29 to d e ter m i ne whether the requirement is feasible from economic and schedule viewpoints. Risks associated with the \(customer requirement need to be assessed. Examples of requirement statuses include: New - Categorized Analyzed  For Review Approved / Rejected / Postponed   Workflow describes what should be done next to this requirement or customer requirement and by whom Customer requirements and requirements are allocated respectively, to requirements and features and responsible persons are assigned History is used to provide information about all prior changes and editors of requirements documents It  enables traceability and the development of organizational memory that is especially useful when routines break down unexpectedly and the reasons for the breakdowns must be found and eliminated to continue the effective execution of routines   Table 3. Generic Structure of Requirement and Customer Requirement Class Question Attributes Description  What is the requirement about Name ID Description Rationale Version Origin  Where does the requirement come from Author Source Date of creation Catego rization What parts of the p roduct and the development organization is the requirement related to Platform Product Responsible Person Analysis What are the implications of the requirement Status Priority Customer need Deadline for the customer need Customer value Risks Required effort Workflow What should be done to this requirement next By whom Allocation to Requirements/Features Assignment to Requirement/Feature responsible History What has been done to the requirement? When Information about all prior edits, editors, and changes  Feature Each class within the Feature-entity \(Table 4\ is presented in this section Description tells the intent of and justification for the Feature Origin indicates the author, date of creation, and Requirements from which the Feature is allocated Categorization links Features to products and/or product platforms and identifies the person having the feature responsibility. Because Feature is an entity for managing detailed implementation, it has an attribute containing traceability links to technical specifications, documentations and code. Features tend to have complex dependencies  a m ple, a f eat u r e m a y be i n corpo rated in to a  product only if its parent feature is also included Analysis contains the other attributes that Requirement and Customer Requirement have, with the exception of Customer value-attribute used to decide whether requirements or customer requirements should be implemented or not. The required work effo rt needs to be estimated to help teams in their work allocation and scheduling Workflow consists of detailed task descriptions together with traceability links to provide the guidelines for implementation work and to enable organizational learning through, for example, post-mortem analysis \(i.e., what was planned vs. realized\en starting the work Features are assigned to responsible teams or persons History tells what has been done to Feature, when and by whom  Table 4. Generic Structure of Feature Class Question Attributes Description  What is the feature about Name ID Description Rationale Version Origin  Where does the feature come from Author Source Requirements Date of creation Catego rization What parts of the p roduct and the development organization is the feature related to Platform Product Responsible Person Traceability links \(e.g documentation, code Analysis What are the implications of the feature Status Priority Customer need Risks Required work effort Workflow What should be done to this feature next By whom Task description Assignment to teams/persons Assignment to Release Date when Feature is ready for Release History What has been done to the feature? When Information about all prior edits, editors, and changes  Release Classes within the Release-entity \(Table 5\at need elaboration are explained in this section Description describes what the release is about. For example, a release may fix some specific quality Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 7 


 problems without providing new functionality In Origin Source Features attribute indicates which features are included in a release In Categorization a release is related to specific product platforms and/or products and has a responsible person Analysis describes the statuses of a release such as Planned Ready to be Released \(i.e., all features belonging to a release are ready Released  Because releases constitute manageable and releasable entities, the only Workflow related attribute tells the estimated release date. This information together with History is adequate for organizational learning and performance monitoring \(e.g., planned vs. actual release date  Table 5. Generic Structure of Release Class Question Attributes Description  What is the release about Name ID Description Version Origin  Where does the release come from Author Source Features Date of creation Catego rization What parts of the product and the development organization is the release related to Platform Product Responsible Person Analysis What are the implications of the release Status Priority Workflow What should be done to this release next? By whom Release date History What has been done to the release? When Information about all p rior edits, editors and changes  4.3 Validating and Scoping the Meta-Design by Analyzing how it Meets the Meta-Requirements  Prioritization and valuation of requirements and the allocation of requirements into releases  Prioritization and valuation of requirements is enabled by the entities Requirement and Customer Requirement Their attributes Priority and Customer Value are used to store and access the prioritization and valuation information in RRMS. The prioritization and valuation methods are not included in the meta-design for two reasons. First the literature provides hardly any methods that are generalizable and scalable to meet the needs of complex industrial environments where multiple interdependent releases of interdependent products and platforms are planned simultaneously econ d th e produ ct prog ra m s of the case organization used different prioritization methods and tools because they differed in size, duration, and product maturity. The meta-design ensures that RRMS can provide the information for using the methods and store and share the results organization-wide Allocation of requirements into releases is enabled transitively through features, that is, requirements and customer requirements are allocated to features, which are linked to releases. Releases provide implemented functionality and are thus linked to features directly Traceability The information model enables bi-directional traceability between entities through Origin- and Workflow-classes. In Customer Requirement and Requirement, Sourceattribute is used for backwa rd traceability and Allocation to Features-attribute enables forward traceability to features. Source Requirement- and Assignment to Releaseattributes of Feature enable, respectively, backward and forward traceability from features. Traceability links-attribute enables the traceability from Features to implementation specific documentation and software code Change management and impact analysis  Change management is facilitated by the History-class in all entities. Change requests can be considered as normal \(customer\irements, analyzed, linked to the respective existing requirements in RRMS that are within the scope of change, and implemented and released following the integrated requirement and release management process. Impact analysis is enabled by Categorization- and Analysis-classes. Platform- and Product-attributes show the organizational entities affected by each requirement and release. Customer value- and Required effort-attributes are used to decide the feasibility of implementing a \(customer\irement Content ownership  Content ownership is determined through the Categorization-class. The attribute Responsible Person explicitly defines the content ownership Accountability of experts responsible for release planning tasks  All entities have Responsible Person-attributes facilitating the accountability of experts. Each release thus has to specify who is responsible for planning, which features are released in which release. The meta-design does not detail the metrics that could be used for measuring performance. However, it can be used as a baseline for sophisticated measurement systems Management and coordination  The meta-design supports management and coordination, for example, by explicating the schedules imposed on various entities, the products and organizational units the entities are related to, and the workflows the entities are subjected to Version management of requirement documents  Description- and History-classes enable the version management of requirements \(and other entities\y respectively, numbering versions and showing the actors involved with each version and the actions taken Release re-planning  The individuals responsible for particular features and releases decide about release re-planning \(e.g., features belonging to a release cannot be released because they are unexpectedly delayed\ure and release documents Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 8 


 and bidirectional traceability links between them \(stored in Assignment to Release- and Source Features-attributes facilitate the implementation of the meta-requirement When there are numerous interdependencies between releases, between features, and between features and releases, the appropriate data stored in RRMS can be transferred into a release re-planning and optimization system c.f  o r an al y s is P r es cribin g t h e f e atures of su c h  systems is beyond the scope of the ISDT for RRMS because the systems are algorithmically complex, enable cost, effort and schedule estimation based on historical data [17 d o p erate on a h i g h e r le v e l of a n al y s is t h a n  RRMS where strategic and operational decisions \(e.g about the common features within and across the product lines\ken based on information in RRMS and other systems. Another IS design theory needs to be built for such systems and interfaced with the ISDT for RRMS  5. Conclusions and Future Research  This research focused on the RRMS-enabled multi-site and platform-based product development. It synthesized the meta-requirements and a partial meta-design of a simple but comprehensive and scalable ISDT for RRMS to help practitioners in both small and large organizations implement and evaluate RRMS solutions. The validity of the partial ISDT was enhanced by using methods such as the analysis of a RRMS instance in a case organization and by explicating the meta-requirements met by the meta-design. Due to space limitations, the design product effectiveness hypotheses of the ISDT \(clarifying the expected organizational benefits from using a RRMS instance derived from the class of RRMS\ have been beyond the scope of this article. The hypotheses are needed for the empirical validation of the theory in future research RRMS is expected to reduce resources needed in product development, shorten time-to-market by ensuring rightinformation is available at the right time for right people improve customer satisfaction by ensuring that requirements are transformed efficiently to product features and improve quality by minimizing the number of errors during development and easing up error tracking Future research is necessary to devise extensions to the ISDT. Possible extensions include \(1\trategic release management [46 t h a t t a ke s a m o r e st r a t e g i c a n d l o ng term view than release project management the ISDT deals with and \(2\e inclusion of a Component entity in the information model of the meta-design to help projects better find and reuse implementation level assets that meet their needs. Such a solution further improves the generalizability of the ISDT because platform organizations often combine both software and hardware in their assets. Our preliminary industrial experiences show that Component is useful especially if it describes how and when Component instances have been tested The single case study methodology may not provide a sound basis for generalization [54   T h e r e f o r e  ne w c a s e  studies and action research projects are necessary to make the ISDT more credible for IS designers and researchers Design science research leveraging the methods of action research e lps ex a m i n e t h e applicabilit y of t h e ISDT  by finding out to what extent organizations that want to acquire or design and implement RRMS systems can utilize the ISDT for those purposes. The ISDT can then be revised as necessary  6. References  1  Adelson, B. and Soloway, E. \(1985\he Role of Domain Experience in Software Design IEEE Transactions on Software Engineering, 11\(11\1351-1360 2  Akao, Y. \(1990\ An Introduction to Quality Function Deployment. In Akao, Y. \(ed.\Quality Function Deployment Integrating Customer Requirements into Product Design Productivity Press, 3-24 3  Argyris C. and Schon D.A. \(1995\. Organizational Learning II: Theory, Method, and Practice. Prentice Hall 4  Van Aken, J. E. \(2004\. Management Research Based on the Paradigm of the Design Sciences: The Quest for FieldTested and Grounded Technological Rules. Journal of Management Studies, 41\(2\9-246 5  Aubert B. A., Vandenbosch B. and Mignerat M. \(2003 Towards the Measurement of Process Integration. Proceedings of the Annual Conference of the Administrative Sciences Association of Canada. Halifax, Nova Scotia 6  Bosch, J. \(2002\. Maturity and Evolution in Software Product Lines:Approaches, Artefacts and Organization. Proceedings of the Second Software Product Line Conference \(SPLC2 Springer Lecture Notes in Computer Science, 257-271 7  Brown, S. L. and Eisenhardt, K.M. \(1995\. Product Development: Past Research, Present Findings, and Future Directions. Academy of Management Review, 20\(2\, 343-378 8  Burchill, G. and Fine, C.H. \(1997\ime versus Market Orientation in Product Concept Development: Empiricallybased Theory Generation. Management Science, 43\(4\465-478 9  Carlshamre P. \(2002\. Release Planning in Market-Driven Software Product Development: Provoking an Understanding Requirements Engineering, 7, 139-151 10  Carmel, E. and Agarwal, R. \(2001\. Tactical Approaches for Alleviating Distance in Global Software Development. IEEE Software, March/April, 22-29 11  Carmel, E. and Agarwal, R. \(2002\he Maturation of Offshore Sourcing of Information Technology Work. MIS Quarterly Executive, 1\(2\65-78 12  Ciborra, C. \(1996\. The Platform Organization: Recombining Strategies, Structures, and Surprises. Organization Science 7\(2\, 103-118 13  Curtis, B., Krasner, H. and Iscoe, N. \(1988\ Field Study of the Software Design Process for Large Scale Systems Communications of the ACM, 31\(11\ 1268-1287 14  Daskalantonakis, M.K. \(1992\. A Practical View of Software Measurement and Implementation Experiences within Motorola. IEEE Transactions on Software Engineering, 18\(11 998-1010 15  Davis, A. \(1992\ Software Requirements: Objects Functions, and States. Prentice Hall, Eaglewood Cliffs, NJ 16  El Sawy, O. \(1998\ding Your Own Business Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 


 Processes: The BPR Learning Book. New York: McGraw-Hill 17  Forselius, P. and Käkölä, T. \(2009\. An Information Systems Design Product Theory for Software Project Estimation and Measurement Systems.  Proceedings of HICSS-42. IEEE 18  Forsgren, P. and  Daugulis, A. \(1998\. Requirements Engineering In Control Center Procurement Projects: Practical Experiences from the Power Industry. Proceedings of the 3rd International Conference on Requirements Engineering. IEEE 19  Gilb, T. \(1998\ Principles of Software Engineering Management. Addison-Wesley, Reading, MA 20  Greer, D. and Ruhe, G. \(2004\. Software Release Planning an Evolutionary and Iterative Approach. Information and Software Technology, 46, 243-253 21  Griffin, A.J. and Hauser, J.R. \(1992\Patterns of Communication among Marketing, Engineering and Manufacturing, - a Comparison between Two New Product Teams. Management Science, 38\(3\360-372 22  Grynberg, A. and Goldin, L. \(2003\Product Management in Telecom Industry Using Requirements Management Process. Proceedings of IEEE International Conference on Software: Science, Technology and Engineering \(SwSTE '03 23  Halbleib, H. \(2004\quirements Management. Information Systems Management 21\(1\8-14 24  Herbsleb, J.D., Moitra, D. \(2001\. Guest Editors' Introduction:Global Software Development. IEEE Software,18\(2 16-20 25  Hevner, A.R., March, S.T., Park, J. and Ram, S. \(2004 Design Science in Information Systems Research. MIS Quarterly, 28\(1\75-105 26  Hrones, J.A. Jr., Jedrey, B.C. Jr. and Zaaf, D. \(1992 Defining global requirements with distributed QFD. Digital Technical Journal, 5\(4\46 http://www.hpl.hp.com/hpjournal/dtj/vol5num4/vol5num4art3.pdf  27  ISO \(2005\. ISO/IEC TR 19759. Software Engineering Guide to the Software Engineering Body of Knowledge SWEBOK\rnational Organization for Standardization http://www.iso.org  28  ISO \(2006\. ISO/IEC 14143 Information technology Software measurement -- Functional size measurement-Part 6 International Organization for Standardization http://www.iso.org  29  Jones, C. \(2008\. Applied Software Measurement, Third Edition. McGraw-Hill 30  Kotonya, G. and Sommerv ille, I. \(1998\. Re quirement Engineering: Processes and Techniques. John Wiley & Sons Ltd, England 31  Käkölä, T. \(2008\st Practices for International eSourcing of Software Products and Services. Proceedings of HICSS-41. IEEE 32  2006\oftware Product Lines: Research Issues in Engineering and Management. Springer 33  Käkölä, T. and Koota, K. \(1999\ual Information Systems: Supporting Organizational Working and Learning by Making Organizational Memory Transparent. Journal of Organizational Computing and Electronic Commerce, 9\(2&3\205-232 34  Käkölä, T. and Taalas, A. \(2008\Validating the Information Systems Design Theory for Dual Information Systems. Proceedings of the 29 th International Conference on Information Systems, Paris \(in press 35  Lehtola, L. and Kauppinen, M. \(2006\. Suitability of Requirements Prioritization Methods for Market-driven Software Product Development. Software Process Improvement and Practise, 11\(1\9 36  Van der Linden, F., Schmid, K. and  Rommes, E. \(2007 Software Product Lines in Action: The Best Industrial Practice in Product Line Engineering. Springer 37  Markus, M. L., Majchrzak, A., and  Gasser, L. \(2002 Design Theory for Systems That Support Emergent Knowledge Processes. MIS Quarterly, 26\(3\, 179-212 38  McGrath, M.E. \(2001\Product Strategy for HighTechnology Companies: How to Achieve Growth, Competitive Advantage, and Increased Profits. Second Edition, New York NY: McGraw-Hill 39  Meyer, M.H. and Lopez, L. \(1995\echnology Strategy in Software Products Company. The Journal of Product Innovation Management, 12\(4\, 294-306 40  Meyer, M.H. and Selinger, R. \(1998\Product Platforms in Software Development.Sloan Management Review,40\(1\1-74 41  O Reilly, C.A. \(1982\. Variations in decision makers use of information sources:The impact of quality and accessibility of information. Academy of Management Journal, 25\(4\56-771 42  Perry, D.E., Staudenmayer, N.A. and Votta, L.G. \(1994 People, Organizations, and Process Improvement. IEEE Software, 11\(4\, 36-45 43  Pohl, K., Böckle, G. and Van der Linden, F. \(2005 Software Product Line Engineering. Springer 44  Ramasubbu, N., Krishnan, M. S., Kompalli, P. \(2005\everaging Global Resources: A Process Maturity Framework for Managing Distributed Development.IEEE Software,22\(3\0-86 45  Regnell, B., Höst, M., Natt och Dag, J., Beremark, P. and Hjelm, T. \(2001\n Industrial Case Study on Distributed Prioritization in Market-Driven Requirement Engineering for Packaged Software. Requirements Engineering, 6\(1\ 51-62 46  Rautiainen, K., Lassenius, C., Vähäniitty, J, Pyhäjärvi, M and Vanhanen, J. \(2002\. A Tentative Framework for Managing Software Product Development in Small Companies Proceedings of the 35th Annual Hawaii In ternational Conference on System Sciences \(HICSS\409-3417 47  Ruhe, G. and Saliu, M. O. \(2005\. The Art and Science of Software Release Planning. IEEE Software, 22\(6\, 47-53 48  Salo, A. and Käkölä, T. \(2005\Groupware Support for Requirements Management in New Product Development. Journal of Organizational Computing and Electronic Commerce, 15\(4 253-284 49  Van De Ven, A.H. \(1986\. Central Problems in the Management of Innovation. Management Science, 32, 590-607 50  Walls, J. G., Widmeyer, G. R. and El Sawy, O. \(1992 Building an Information System Design Theory for Vigilant EIS. Information Systems Research, 3\(1\36-59 51  Walls, J.G., Widmayer, G.R. and El Sawy, O. \(2004 Assessing Information System Design Theory in Perspective How Useful was our 1992 Initial Rendition? Journal of Information Technology Theory and Application, 6\(2\, 44-58 52  Wesselius, J. \(2006\Strategic Scenario-Based Valuation of Product Line Roadmaps. In T. Käkölä & J.C. Dueñas \(Eds Software Product Lines: Research Issues in Engineering and Management, Springer, 53-89 53  Wiegers, K.E. \(2003\. Software Requirements: Practical Techniques for Gathering and Managing Requirements, 2 nd  edition. Microsoft Press, Washington 54  Yin, R.K. \(2003\. Case Study Research: Design and Methods, third edition. Sage Publications 55  Zhang, W., Mei, H. and Zhao, H. \(2006\. Feature-driven Requirement Dependency Analysis and High-level Software Design. Requirements Engineering, 11,:205 220 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 


 s K AU\ \(2.5 photons 15  s K 60  s K AU\ \(1.25 photons 60  PSF  s K 30  11 Det ect or array radius R cm Uncoded symbol-error probability, PSE Dat ar at e = 1 GBPS M = 4 PPM, 0.5 ns slots cm 1 b  R s b 120  s K AU\ \(1.8 photons 30 212  BER With only about 15 signal photons received at the greatest distance of 2.5 AU as shown in Fig. 14, the required BER of approximately 10 6 for communications links cannot be achieved with this high-rate code.  In this case, a lower code rate could be used, but at the cost of additional overhead The threshold of the simulated rate \275 code is less than 14 signal photons per pulse on the average in this highbackground environment \(152 background photons per slot at 10 degree SEP angle could achieve the required BER with a 26 meter receiver even at the greatest distances considered  Bound rate \275 Bound rate 7/8 Simulation rate \275 code Simulation rate 7/8 code Uncoded BER PSE = 2 M 1\ER M  Figure 15. Coded performance of M = 4 PPM with background level corresponding to optimized acceptance angle for 2 cm spot, rate \275 and 7/8 codes  Performance of the 10 meter Receiver Finally, we consider the 10 meter receiver option described in Section II.  The salient characteristics of this receiver design are smaller turbulence-limited FOV due to higher-quality optics, but also a much smaller collecting area of only 78.5 square meters. Therefore the 10 meter receiver collects a fraction 78.5/531 = 0.148 of the signal power collected by the 26 meter antenna, corresponding to 8.3 dB less signal energy.  However, due to higher quality optics the FOV can be reduced to 55 micro-radians \(roughly the turbulenceinduced limit at 10 degree SEP angle\yielding an effective spotsize of 0.5 cm at the Casse grain focus. The distribution of background intensities in th e focal-plane have been scaled by the ratio of the apertures for the two options enabling direct comparison of optimized performance  Uncoded performance of the 10 meter receiver design is shown in Fig. 16, for spacecraft distances of 0.87, 1.25, 1.8 and 2.5 AU respectively.  At the nominal distance of 1.25 AU, three performance curves with slightly different spot sizes are plotted on the same graph: red corresponds to 0.3 green to and 25.0  toblue,2.0 004 cm.  It is noteworthy that not much background is co llected with any of these spots to begin with, hence performance cannot be improved significantly by reducing th e spotsize for the 10 meter receiver option   s K  Figure 14.  Uncoded symbol-error probability performance of 26 meter receiver as a function of detector-plane acceptance angle, at distances of 0.87, 1 25, 1.8 and 2.5 AU: approximately 2 cm spot  Examples of the performance improvement afforded by coding are shown in Fig. 15, we re a 2 cm spot was assumed and uncoded BER bit error rate\the BER for two coded systems are shown: one a rate \275 code, the other a rate 7/8 code.  The rate \275 code is a \(15120, 7558\serially concatenated convolutional PPM code, whereas the rate 7/8  code is a \(8176, 7154\ code currently proposed as a CCSDS standard high-rate c ode.  Each of these codes utilizes iterative demodulation of the PPM symbols providing an additional gain of approximately 0.2 dB. Both of these codes have been implemented in FPGA, hence represent practical implementati ons that can be used with confidence to predict coded performance of the proposed optical receivers  It is evident that the more pow erful rate \275 code attains 7 dB coding gain over uncoded BER at error probabilities of interest to missions 6 10  PSF 004 AU\ \(0.87 photons 120 212 002 BER  7/8  code provides 4 dB of coding gain.  Also illustrated are bounds \(sometimes referred to as capacity bounds\on the BER derived from the converse to the coding theorem for rates \275 and 7/8 These provide a lower bound on achievable error probability for any codi ng scheme at a given rate Note that a simulated rate 7/8 code would require an average of more than 16 photons to reach 6 10  s K 15  s K R cm Average phot ons  R b 


b  R s  s K 88.8  12 Det ect or array radius R cm R cm Average phot ons Uncoded symbol-error probability, PSE  R b  s K AU\ \(2.5 photons 22.2  s K AU\ \(1.25 photons 88.8 b 8.17  PSF  s K Dat a-r at e = 1 GBPS M = 4 PPM, 0.5 ns slots cm 25.0  s K 004 0.2  0.25  0.3 cm  Figure 16.  Uncoded symbol-error probability performance of 10 meter receiver as a function of detector-plane acceptance angle, at distances of 0.87 1.25, 1.8 and 2.5 AU: approximately 0.4, 0.5 and 0.6 cm spots  It should also be noted that the uncoded error probabilities achieved by the 10 meter receiver are not quite as good as those of the 26 meter receiver at any distance, despite much better optical surface quality:  this is a direct consequence of the 8.3 dB loss in relative signal energy.  However, since the background energy at minimum symbol error probability is only about 2 phot ons on the average per slot coded performance nevertheless remains acceptable at moderate distances, as shown in Fig. 17  For the 10 meter receiver, the threshold for the rate \275 code is approximately 5 signal photons on the average and a little more than 8 photons for the rate 7/8 code, which means that acceptable performance can be achieved at intermediate distances of 1.25 AU or less with either code  However, if the less powerful rate 7/8 code was employed then the required performance could not be achieved at distances much greater than 1.25 AU, since more than 8 photons would be required to reach the coding threshold which however is not feasible with the 10 meter receiver design as can be seen in Fig. 16  7  S UMMARY AND C ONCLUSIONS  We have presented two different system concepts for hybrid RF/Optical receivers based on the DSN 34-meter antennas currently employed for deep space communications Although significantly di fferent in terms of opto-mechanical design,  the key features of these two concepts can be characterized as follows: th e 10 meter option utilizes highquality glass mirrors added to the main reflector of the 34 meter antenna to achieve an e quivalent collecting aperture of a 10 meter diameter optical receiver, with a narrow fieldof-view consistent with day time turbulence when pointing close to the sun \(approximately 55 micro-radians meter option makes use of the existing solid aluminum panels of the inner 26 meter of the antenna polished to optical smoothness, and is assu med to achieve a wider fieldof-view of  200-400 micro-radians due to larger surface figure errors Simulation rate \275 code Bound rate \275 Bound rate 7/8 Simulation rate 7/8 code Uncoded BER PSE = 2 M 1\ER M  Figure 17. Coded performance of M = 4 PPM with background level corresponding to optimized acceptance angle for 0.5 cm spot, rate \275 and 7/8 codes  A mathematical model of the optical communications system applicable to both concepts was developed consisting of a focal-plane array of photon-counting detectors, optical filter to limit background, and pointspread functions in the focal-p lane incorporating the surface figure errors of the two concep ts. Both spatial and temporal acquisition algorithms were considered, and it was shown that in the absence of bac kground radiation and with large detector arrays the maximum likelihood estimators took the form of simple centroiding ope rations. When the detector array was comparable in size to the PSF then edge-effects had to be considered, and several modifications were derived that ameliorated the bias caused by these edge effects  It was also found that unifo rmly distributed background introduced large biases into the centroid estimates for both pointing offset and temporal delay, requiring modifications to the original algorithms to overcome these effects  Finally, detector FOV was optimized for both design concepts to minimize PPM symbol-detection error probability in the presence of strong background characteristic of daytime operation when pointing close to the sun. Uncoded performance was evaluated assuming M 4 PPM and 1 GBPS data-rate, and it was shown that the 26 meter collecting aperture outperformed the 10 meter aperture despite its narrower F OV, since the larger aperture collected much more signal photons. Coded performance was also considered with op timized FOV, demonstrating that acceptable coded performance could be achieved with  s K 44.4  PSF 004 AU\ \(1.8 photons 44.4  s K 22.2 AU\ \(0.87 photons 8.17 


 13 either design for communications distances characteristic of nearby planets  Acknowledgment The research described in this paper was carried out at the Jet Pr opulsion Laboratory, California Institute of Technology, under contract with the National Aeronautics and Space Administration  The authors would like to thank Sabino Piazzolla of JPL for determining the effective sky radiance at 10 degrees SEP angle due to atmospheri c scattering and dust on the optics, used in the calculations in Section 6. The authors would also like to thank Philip Tsao for generating the SEP angle predicts for Mars in Figure 2    R EFERENCES   R  Gagliardi and S. Karp Optical Communications  John Wiley and Sons, New York, 1976 2] V. Vilnrotter, M Srinivasan, \223Adaptive Detector Arrays for Optical Communications R eceivers,\224 IEEE Transactions on Communications, Vol. 50, Issue 7, July 2002  V. Vilnrotter, \223Hy b rid R F Optical Communications via 34-m DSN Antennas,\224 IPN Progress Report 42-181, Jet Propulsion Laboratory, February  15, 2009     B IOGRAPHIES   Victor A. Vilnrotter  M'79, SM\22202 received his Ph.D. in electrical engineering and communications theory from the University of Southern California in 1978.  He joined Jet Propulsion Laboratory Pasadena, CA in 1979, where he is a Principal Engineer in the Communications Architectures and Research section. His interests include electronic compensation of large antennas with focal-plane arrays adaptive combining algorithms for large antenna arrays optical communications thr ough atmospheric turbulence the application of quantum communications to deep-space optical links, and the devel opment of uplink array calibration and tracking tec hnologies. He has published extensively in conferences and refereed journals, and has received numerous NASA awards for technical innovations         Daniel J. Hoppe M'79, SM\22200  received the B.S. and M.S. degrees in electrical engineering from the University of Wisconsin Madison in 1982 and 1983, and the Ph.D. degree also in electrical engineering, from the University of California Los Angeles in 1994. He is currently at the Jet Propulsion Laboratory where he is a principal engineer His efforts there involve electromagnetic analysis and design of microwave and optical devices for a number of ground-based and space-based applications. Dr. Hoppe has also been a visiting lecturer at UCLA since 1995. He was awarded the NASA Exceptional Service Medal in 1993, and in 1994 he was recognized as the outstanding Ph.D. student in the School of Engineering and Applied Science at UCLA Dr. Hoppe is a senior member of the IEEE, and has been awarded several U.S. patents  Bruce Moision received the B.S degree in Engineering from Harvey Mudd College in 1991. From 1991 to 1994 he was with Datatape, Inc. in Pasadena, CA. He received the Ph.D degree in Electrical and Computer Engineering from the University of California, San Diego, in 1999 During 2000 he held a postdoctoral position with the Mathematics of Communications Research Group at Lucent Technologies, Murray Hill, NJ, and has been a member of the technical staff at JPL since 2001. His work covers the areas of e rror control coding and signal processing for free-space optic al communications channels  Jeffrey R. Charles founded Versacorp\231 in 1983, while becoming self-educated in di sciplines required to design patented products and propr ietary technology, and participate in related produc t prototyping, production and distribution. Products incl uded multiple function flip mirrors for telescopes and surveillance instruments, and technology for 360 degree panoramic and full sphere imaging.  He presented many lectures, published several technical papers, and authored a Springer-Verlag book Jeff worked as a contractor at the Jet Propulsion Laboratory \(JPL\ from 1992 to 1995, then joined JPL as an employee in 2000, having operated Versacorp\231 in the interim.  He has been a memb er of two JPL flight project teams \(MER and COSMIC\.  His work interests include conceptual design, systems architecture, and innovations that reduce the cost of larg e aperture optical systems for ground based, airborne, and s pace based applications Since joining JPL, he has authored New Technology Reports and co-authored  papers published in conference proceedings and journals  


University Working Paper #15 18] DiMaggio P., Hargittai, Eszter, Celeste, Coral and Shafer, Steven. 2004. Digital Inequality From Unequal Access to Differentiated Use. In K Neckerman \(Ed Russell Sage Foundation: New York 19] Dixit, A. The Making of Economic Policy: A Transactions Cost Perspective. MIT Press Cambridge, MA, 1996 20] Downs, A. An Economic Theory of Democracy Harper Brothers: New York, 1957 21] Evans, P., Rueschmeyer, D., and T. Skocpol, eds Bringing the State Back In. Cambridge University Press, New York, 1985 22] Graham, C. ?The Economics of Happiness Insights on Globalization from a Novel Approach,? World Economics, v.6, No.3, JulySeptember 2005 23] __ ?Insights on Development from the Economics of Happiness,? World Bank Research Observer, 20\(2 24] Grindle, M. Going Local: Decentralization Democratization, and the Promise of Good Governance. Princeton University Press Princeton, 2007 25] Groves, R., Dillman, D., Eltidge, J., and R. Little Survey Nonresponse. John Wiley and Sons, New York, 2001 26] Hargittai E. 1999. Weaving the Western Web Explaining Differences in Internet Connectivity Among OECD Countries. Telecommunications Policy 23\(10/11 27] Hall, Peter. Cities of Tomorrow. Blackwell Publishing, Boston, 2002 28] Hargittai E. 2002. Second-Level Digital Divide Differences in People's Online Skills.First Monday 7\(4 http://firstmonday.org/issues/issue7_4/hargittai 29] Hayek, F. ?The Use of Knowledge in Society American Economic Review, XXXV, No. 4 September, 1945, pp. 519-30 30] Hayek, F. ?The Pretence of Knowledge,? in Lindbeck, A., ed Nobel Lectures, Economics 1969-1980, World Scientific Publishing Co Singapore, 1992 31] Heeks, R. 1999. Information and communication technologies, poverty, and development Development Informatics Working Paper Series Institute for Development Policy and Management. University of Manchester 32] Herrera, Y. Imagined Economies: The Sources of Russian Regionalism. Cambridge University Press, New York, 2005 33] Herz, B., &amp; G. Sperling. Evidence and policies from the developing world: What works in girls education. Executive summary. Council on Foreign Relations, New York, 2004 34] Hj  rland, Birger \(2007 Knowledge Organization. Annual Review of Information Science and Technology 41:367 405 35] Hj  rland, Birger \(2004 organization and the feasibility of universal solutions. Presented at the Eighth International ISKO Conference, London, July 13-16, 2004 36] Jenkins, R. Democratic Politics and Economic Reform in India. Cambridge University Press New York, 1999 37] Kanungo, S. 2004. On the emancipatory role of rural information systems. Information Technology and People. 17\(4 


Technology and People. 17\(4 38] Loegelin, M. 1992. Interformation et development: etude synthetique des lignes de force du discourse universitaire. Institut Universitaire de Technologie B, Department Carrieres de l?information et del al communication, Universite de Bourdeaux 39] Mai, J-E. "Likeness: A Pragmatic Approach" In Dynamism and Stability in Knowledge Organization.   Proceedings of the Sixth International ISKO Conference. Advances in Knowledge Organization, 7: 23-27, 2000 40] Mai, J-E. "The Concept of Subject: On Problems in Indexing" In Knowledge Organization for Information Retrieval.  Proceedings of the 6th Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 9 International Study Conference on Classification Research. 6: 60-67, 1997 41] Mas-Colell, A., Whinston,M., and J.Green Microeconomic Theory. Oxford University Press New York, 1995 42] Madon, S. and Sahay, S. 2002. An Informationbased Model of NGO-mediation for the Empowerment of Slum Dwellers in Bangalore The Information Society:18\(1 43] McCubbins, M., and T. Schwartz. ?Congressional Oversight Overlooked: Police Patrols vs. Fire Alarms,? American Journal of Political Science February 1984 44] McKenzie, D., and D. Mookherjee. ?Distributive Impact of Privatization in Latin America: An Overview of Evidence from Four Countries Economia, vol. 3, no. 2, Spring 2003, pp. 161218 45] Menou, M.J. 1985. An overview of social measures of information. Journal of the American Society of Information Science and Technology 36\(3 46] Oates, W. ?An Essay on Fiscal Federalism Journal of Economic Literature, 1999, 37, \(3 1120-1149 47] Olken, B. ?Revealed Community Equivalence Scales,? Journal of Public Economics 89 \(2005 545-566 48] Neuwirth, R., Shadow Cities: A Billion Squatters Routledge, London, 2006 49] Perlman, M., ?Political Purpose and National Accounts,? in Alonso, W. and P. Starr, eds. The Politics of Numbers, Russel Sage Foundation New York, 1987 50] Persson, T. ?Do Institutions Shape Economic Policy?? Econometrica, v.70, no.3, 2002 51] Puri, S.K. and Sahay, S. 2003. Participation through communicative action: A case study of GIS for addressing land/water management in India. Information Technology for Development vol 10: 179-199 52] Scott, J. Seeing Like a State: How Certain Schemes to Improve the Human Condition Have Failed. Yale University Press, New Haven, 1998 53] Seely-Brown, John. and S. Duguid. The Social Life of Information. Harvard Business Press Cambridge, 2002 54] Sen, A. Development as Freedom. Oxford University Press, New York, 1999 55] Somasundaram, L. personal correspondence Chennai, India, December 20, 2007 56] Srinivasan, R., Pepe, A., and Rodriguez, M Eliciting Cultural Ontologies: A comparison between Hierarchical Clustering Methods and Participatory Design Processes.?, under review 


57] Srinivasan, Ramesh, and Jeffrey Huang. "Fluid Ontologies for Digital Museums." International Journal of Digital Libraries.5 \(2005 58] Srinivasan, Ramesh. "Ethnomethodological Architectures: Information Systems Driven by Cultural and Community Visions." Journal of the American Society for Information Science and Technology 5.5 \(2007 59] ---. "Indigenous, Ethnic and Cultural Articulations of New Media." International Journal of Cultural Studies 9.4 \(2006 60] ---. "Where Community Voice and Information Society Intersect." The Information Society 22 2006 61] Star, Susan Leigh, and James R. Griesemer Institutional Ecology, 'Translations' and Boundary Objects: Amateurs and Professionals in Berkeley's Museum of Vertebrate Zoology, 190739." Social Studies of Science 19 \(1989 420 62] Starr, P, ?The Sociology of Official Statistics 63] Suchman, Lucy A. Human-Machine Reconfigurations: Plans and Situated Actions 2nd ed. ed. Cambridge: Cambridge University Press, 2006 64] ---. "Located Accountabilities in Technology Production." Scandanavian Journal of Information Systems 14.2 \(2002 65] Stepan, A. State and Society: Peru in Comparative Perspective. Princeton University Press, Princeton, NJ, 1978 66] Turban, E., Aronson, J., Lian, T., Sharda, R Decision Support and Business Intelligence Prentice-Hall, New Jersey, 2006 \(8th Edition 67] Ulman, J. Future Tendencies in Computer Science, Control and Applied Mathematics Springer-Verlag, Heidelberg, 1992 68] United Nations Human Development Report http://hdr.undp.org/en 69] Vernon, R., ?The Politics of Comparative Economic Statistics: Three Cultures and Three Cases,? in Alonso, W. and P. Starr, eds. The Politics of Numbers, New York, 1987 70] Warschauer, M. ?Reconceptualizing the Digital Divide,? First Monday, v.7, no.7, July 2002 71] ___. Demystifying the digital divide. Scientific American 289\(2 72] Watson-Verran, Helen, and Leon White. "Issues of Knowledge in the Policy of SelfDetermination for Aboriginal Australian Communities 73] Wallack, J.S., and N.K. Singh. ?Of Demolition Drives and Creative Destruction,? Indian Express, October 15, 2006 74] Wallack, J.S. ?Fire Alarms in Action: Making Sense of User Feedback on City Services in Karnataka, India,? under review, 2008 75] Wallack, J.S, and S. Nadhamuni, ?User Innovation and eGovernance Design forthcoming in Hidden Successes: Urban Reforms in India, MIT Press, Cambridge, MA 76] Ziegler, E., and J.S. Wallack, ?State Capacity m/s, UCSD, San Diego, 2008 77] Wallack, J.S., and T.N. Srinivasan. Federalism and Economic Reform. Cambridge University Press. Cambridge, 2006 Proceedings of the 42nd Hawaii International Conference on System Sciences - 2009 10 pre></body></html 


especially of computer networks, is often characterized by the multi-state performance degradations before reaching the complete failure. This multi-state nature of reliability has been increasingly recognized in recent years, and the most significant advances have been in the field of multistate reliability modeling \(Lisnianski and Levitin 2003                                                 4. STRATEGIC MODELING AND DYNAMIC   Box 3.3. Multivariate Survival Analysis  Dependence Mechanisms  Dependence is often the central focus of multivariate survival analysis, and together with censoring, they complicate survival analysis most significantly. Hougaard \(2000 three mechanisms of dependence: \(i ii iii Common events are equivalent to common mode failures in reliability analysis, for example, failure events due to accidents or natural disasters. The common risks mechanism describes the scenario that the individuals are dependent due to some common unobserved risks such as common genes in siblings or a bug in the operating system that may affect all software running on 


operating system that may affect all software running on it. The third mechanism, event-related mechanism refers to the phenomena that the actual event itself changes the risk, such as virus infection of a computer node Shared Frailty Modeling  Shared frailty theory occupies the central focus of multivariate survival analysis. The dominance is not accidental because frailty captures crucial but often directly unobservable \(latent random variables, which are attributable for dependence and variations. To some extent, dependence, variation randomness, and frailty all address some facets of multivariate failure events. The frailty theory provides a unique set of approaches to address the theoretical and practical issues related to those four concepts.  Similar to the fact that censoring is the trademark feature of survival analysis \(both univariate and multivariate frailty theory is the trademark of multivariate survival analysis. These two trademark properties, censoringhandling and frailty modeling, have made multivariate survival analysis a unique and indispensable mathematical tool for biomedical and public health research Multi-State Modeling  Multi-state has been developed concurrently in several fields in the last decade, including survival analysis \(Hougaard 2000 reliability \(Lisnianski and Levitin 2003 Commenges 1999 Huzurbazar 2006 multi-state modeling has been adopted to solve the domain specific problems, and the flow graph modeling offers a flexible and powerful approach to analyze multi-state models in general. Multi-State model is often formulated as Markov Process models. The transition probabilities in multi-states modeling are well defined by survivor functions \(Hougaard 2000 multi-state model is to estimate the state transition probabilities from hazards functions. multivariate system. According to Lisnianski and Levitin's \(2003 any systems that can have a finite number of performance rates are multi-state systems. Furthermore a system may consists of components which themselves could be multi-state subsystems 10 4. STRATEGIC LEVEL MODELING AND DYNAMIC HYBRID FAULT MODELS  Hybrid fault models are derived from agreement algorithms Lynch 1997 redundancy management in fault tolerance.  Therefore, the choice of hybrid fault models directly affects reliability analysis and fault tolerance. Despite the close ties between reliability and fault tolerance fields, Ma &amp; Krings \(2008e Ma 2008a with regard to the quantitative relationship between reliability analysis and hybrid fault models. To address the unrealistic assumption, they proposed a new concept  dynamic hybrid fault \(DHF mathematical tools \(survival analysis and evolutionary game theory modeling we first briefly describe the issues involved and summarize some of their key findings in Box 4.1  Agreement algorithms started out with the introduction of the Byzantine general problem by Pease et al. \(1980 Lamport \(1982 system are abstracted as generals of an army.  Loyal generals \(non-faulty components algorithm e.g., to attack or retreat while traitors \(or bad components others by sending conflicting messages. Because the focus of agreement algorithms is to reach agreement in the presence of faults and not on issues related to fail rates, the 


presence of faults and not on issues related to fail rates, the failure rate is often ignored or is implicitly assumed to be constant. In other words, the agreement algorithm, together with the assumptions about faults and their cardinality determines if agreement can be reached.  However, there is no direct link to the notion of real time in agreement algorithms or the associated hybrid fault models. This implies that agreement algorithms only specify whether or not an agreement can be reached, given a certain number of traitors, but they do not keep track of when the generals committed treason. Ignoring the notion of real time is appropriate in the study of agreement algorithms because they are only concerned with provable agreement even if the voting is dynamic \(multiple rounds of voting time is abstracted as rounds which are discrete and do not bear real-time values  The key issue is that the time \(in terms of rounds agreement algorithm or the hybrid fault models does not capture the process dynamics in terms of real time as needed in the analysis of reliability. When fault models are applied in analyzing a real-world system consisting of multiple components \(generals must be considered. Some generals may be loyal for their entire lifetimes; some may quickly become "corrupted;" still others may be loyal for long time but ultimately become  corrupted  Each of the generals may have different inhomogeneous not-constant function, ?i\(t generals  In most cases, the failure rate is completely ignored, and then the hybrid fault models are treated as static. For example, an engineer may claim that a system he designed will be able to tolerate 2 Byzantine faults, because the design has 7 redundant parts \(3m+1, m is the number of faults notion. In general, if we replace m with a time-dependent function m\(t t t-1 t t function of parts, then the statement becomes a timedependent predicate  In other cases, the consequences of different faults or failure modes can be hugely different. If a benign fault is replaced by a malicious fault, the consequence could be disastrous Without real-time notion, the dynamics of failure modes are never captured  From the above discussion, it is obvious that the lack of real-time notion in agreement algorithms and associated hybrid fault models is a critical issue of significant theoretic and practical implications, and the issue should not be ignored when agreement algorithms and hybrid fault models are applied to reliability analysis. To address this issue, Ma amp; Krings \(2008e, Ma 2008a fault \(DHF dynamic in two senses: the time-dependent failure rate and time-dependent failure modes  Actually, the issue is much more complex than what is briefly described above because the problem has two essential aspects.  The above brief introduction only reveals one aspect of the problem, i.e., the lack of real time notion This aspect is relatively straightforward to address and the proposed extension is to introduce time and covariate dependent failure hazard or survivor function \(see Box 3.1 The other aspect of the same problem arises when one tries to apply the new extension for reliability analysis. In other words, the extension with time and covariate dependent hazard function is necessary but not sufficient.  To integrate hybrid fault models or dynamic hybrid fault models reliability analysis requires the capability to simultaneously 


reliability analysis requires the capability to simultaneously process multiple failure behaviors with very different qualitative and quantitative properties. The term qualitative refers to the fault types, such as benign, symmetric asymmetric, or the transmissive and omissive Unfortunately, traditional reliability analysis cannot handle the above requirements. To achieve the flexibilities and capabilities to simultaneously quantify several types of failure behaviors required by hybrid fault models, and still to be capable of incorporating complex time-dependent failure rate represented with survival analysis models, Ma and Krings \(2008e, Ma 2008a game theory model to integrate dynamic hybrid fault models and reliability models \(represented with survival functions  Box 4.1 and 4.2 briefly describe the concepts involved in two aspects of dynamic hybrid fault \(DHF Detailed contents are referred to Ma &amp; Krings \(2008e, Ma 2008a 11                                                     


                                                Box 4.1. Agreement Algorithm Aspect of Dynamic Hybrid Fault Models: Time and Covariate Dependent Hazard Function Ma and Krings \(2008e, Ma 2008a the first aspect \(i.e., the lack of real time notion, or the agreement-algorithm side of the problem introduction of survival analysis. Specifically, time and covariate dependent survivor functions or hazard functions are utilized. In the following, I use the oral message version of the Byzantine general problem Lamport 1982 extension. The constraint of Byzantine general problem under oral message assumption \(Table 1 be replaced with the following model in the dynamic version 1 3 tmtN Further assuming that the survivor function of generals is S\(t|z    ztStNtN    ztStmtm m where N\(t t treacherous generals \(traitors S\(t|z t|z survivor functions for the total number of generals and 


survivor functions for the total number of generals and traitors, respectively.  z is the vector of covariates, and the conditional survivor functions can adopt parametric or semi-parametric covariate models such as Cox models. Obviously, the hybrid models now are not only time-dependent, but also covariate dependent.  The covariates can be any factors that affect the failures of generals. The above scheme conveniently transforms traditional hybrid fault models and their corresponding mathematical constraints for reaching agreement, into time and covariate dependent  The above models use Byzantine general problem with oral messages as an example, and the other constraints to reach agreement in hybrid fault models can be extended in the same manner.  In addition, the above models adopted discrete form, or difference equations Continuous model or differential equation can be adopted. Models similar to population dynamics can be utilized \(Ma and Bechinski 2008 field that studies the change of population numbers from generation to generation. The concept of population usually refers to animal, plant or human population Hallam &amp; Levin. 1986, Kingsland 1995, Kot 2001 Lande &amp; Engen, 2003 mathematical models such as expressed with survival analysis, populations of animals, Byzantine generals, or wireless sensor nodes, are essentially the same Therefore, the models in population dynamics theory can be used to replace above models to represent more complex systems. The population dynamics approach is particular convenient for the utilization of evolutionary game modeling, which is necessary for addressing the second aspect of the dynamic hybrid fault models Box 4.2. Reliability Aspect of Dynamic Hybrid Fault Models: Byzantine Generals Playing Evolutionary Games The solution to the first aspect \(Box 4.1 not sufficient to apply the DHF models to reliability or survivability analysis.  Ma and Krings \(2008e, Ma 2008a introduced evolutionary game theory \(EGT the second aspect of the problem  reliability aspect of dynamic hybrid fault models. With the Byzantine general problem as an example and they term the approach Byzantine Generals Playing Evolutionary Games  Basic Concepts in EGT  In EGT, game players are population individuals, game payoffs are the fitness of individuals, and strategies are evolved dynamically.  Similar to the Nash equilibrium in traditional game theory evolutionary stable strategy \(ESS both internal mutation and external perturbation.  The ESS can be mapped to the sustainable or survivable strategies. When mapping to the Byzantine general problem, players are the generals, and fitness or payoff of a game is mapped to reliability \(survivability sub-population of players, which can be represented with the hazard function or survival function introduced in the previous section.  The sub-populations can refer to groups of generals \(such as loyal general group or treacherous general group behaviors of generals, such as malicious vs. benign symmetric vs. asymmetric  Basic Mathematical Models for EGT  In literature mathematical models for evolutionary games can be as simple as simple algebraic equations or as complex as differential equation systems. For example, the so termed replicator dynamics model is actually the adaptation of population dynamics modeling for describing evolutionary games. Replicator dynamics describes evolution of the frequencies of strategies in a population. In evolutionary 


game theory, replicator dynamics is described with differential equations. For example, if a population consists of n types nEEE ,...,, 21 with frequencies 21 nxxx . The fitness xfi of iE will be a function of the population structure, or the vector 21 nxxxx Following the basic tenet of Darwinism, one may define the success as the difference between the fitness xfi of iE  and the average fitness   xfxxf ii of the population. The simplest replicator model can be defined as   xfxfxdtdx iii for .,...,2,1 ni =  The population nStx ?   where nS is a simplex, which is the space for population composition, is similar to mixed strategies in traditional games \(Hofbauer amp; Sigmund 1998, Vincent &amp; Brown 2005, Nowak 2006  12                                                  Box 4.3 included some additional comments on DHF models. The following is a summary for the potential benefits of introducing DHF models to reliability and PHM  i 


i models into time and covariate dependent dynamic counterparts  ii models and reliability analysis in a more realistic manner  iii level  whether or not functional components \(loyal generals diagnose correctly and take proper actions such as fault mask of failed components \(traitors asymmetric  iv survivability analysis. Evolutionary game modeling can derive sustainable or survivable strategies \(mapped from the ESS in EGT such as node failures such as security compromise level modeling in the so-called three-layer survivability analysis developed in Ma \(2008a this article  v offer an integrated architecture that unite reliability survivability, and fault tolerance, and the modeling approaches with survival analysis and evolutionary game theory implement this architecture. Finally, the dynamic hybrid fault models, when utilized to describe the survival of players in EGT, enhance the EGT's flexibility and power in modeling the survival and behaviors of the game players which should also be applicable to other problem domains where EGT is applicable  5. OPERATIONAL LEVEL MODELING AND DECISION-MAKING  5.1. Highlights of the Tactical and Strategic Levels  Let's first summarize what are obtainable at both tactical and strategic levels. The results at both tactical and strategic levels are precisely obtainable either via analytic or simulation optimization. With the term precisely, we mean that there is no need to assign subjective probabilities to UUUR events. This is possible because we try to assess the consequences of UUUR events \(tactical level ESS strategies \(strategic level time prediction of survivability. The following is a list of specific points. I use an assumed Wireless Sensor Network WSN  i of UUUR events: \(a actions which can be treated as censored events; \(b Cont' of Box 4.2 It can be shown that the replicator differential equations are equivalent to the classical population dynamics models such as Logistic differential equation and LotkaVolterra equation \(e.g., Kot 2001 Logistic equation, or the limited per capital growth rate is similar to the change rate of the fitness  xfxfi which can be represented with the hazard function or survivor functions introduced in the previous section on survival analysis.  This essentially connects the previous survival analysis modeling for lifetime and reliability with the EGT modeling. However, EGT provides additional modeling power beyond population dynamics or survival analysis approaches introduced in the previous section. The introduction of evolutionary theory makes the games played by a population evolvable. In other words, each player \(individual 


other words, each player \(individual agent and players interact with each other to evolve an optimized system Box 4.3. Additional Comments on DHF Models  The above introduced EGT models are very general given they are the system of ordinary differential equations. Furthermore, the choice of fitness function f\(x complexity to the differential equation system.  The system can easily be turned into system of nonlinear differential equations. The analytical solution to the models may be unobtainable when nonlinear differential equations are involved and simulation and/or numerical computation are often required  In the EGT modeling, Byzantine generals are the game players, and hybrid fault models are conveniently expressed as the strategies of players; the players may have different failure or communication behaviors Furthermore, players can be further divided into groups or subpopulations to formulate more complex network organizations. In the EGT modeling, reliability can be represented as the payoff \(fitness, the native term in EGT of the game. Because reliability function can be replaced by survivor function, survival analysis is seamlessly integrated into the EGT modeling. That is, let Byzantine generals play evolutionary games and their fitness reliability function  The evolutionary stable strategy \(ESS counterpart of Nash equilibrium in traditional games ESS corresponds to sustainable strategies, which are resistant to both internal mutations \(such as turning into treason generals or nodes such as security compromises represent survivable strategies and survivability in survivability analysis. Therefore, dynamic hybrid fault models, after the extension with EGT modeling, can be used to study both reliability and survivability 13 risks such as competing risks which can be described with CRA; \(c captured with the shard frailty.  We believe that these UUUR events are sufficiently general to capture the major factors/events in reliability, security and survivability whose occurrence probabilities are hard or impossible to obtain  Instead of trying to obtain the probabilities for these events which are infeasible in most occasions, we focus on analyzing the consequences of the events.  With survival analysis, it is possible to analyze the effects of these types of events on survivor functions. In addition, spatial frailty modeling can be utilized to capture the heterogeneity of risks in space, or the spatial distribution of risks \(Ma 2008a d UUUR events introduced previously. These approaches and models that deal with the effects of UUUR events form the core of tactical level modeling  To take advantage of the tactical level modeling approaches it is obviously necessary to stick to the survivor functions or hazard functions models. In other words, survival analysis can deal with UUUR events and offer every features reliability function provides, but reliability function cannot deal with UUUR events although survivor function and reliability function have the exactly same mathematical definition. This is the junction that survival analysis plays critical role in survivability analysis at tactical level. However, we 


recognize that it is infeasible to get a simple metric for survivability similar to reliability with tactical level modeling alone. Actually, up to this point, we are still vague for the measurement of survivability or a metric for survivability. We have not answered the question: what is our metric for survivability? We think that a precise or rigorous definition of survivability at tactical level is not feasible, due to the same reason we cited previously  the inability to determine the probabilities of UUUR events However, we consider it is very helpful to define a work definition for survivability at the tactical level  We therefore define the survivability at tactical level as a metric, Su\(t t function or reliability function with UUUR events considered. In the framework of three-layer survivability analysis, this metric is what we mean with the term survivability. The "metric" per se is not the focus of the three-layer survivability analysis. It is not very informative without the supports from the next two levels  strategic and operational models.  However, it is obvious that this metric sets a foundation to incorporate UUUR effects in the modeling at the next two levels  Due to the inadequacy of tactical level modeling, we proposed the next level approach  strategic level modeling for survivability. As expected, the tactical level is one foundation of strategic level modeling ii objectives: \(a affect survivability which survival analysis alone is not adequate to deal with; \(b survivability at tactical level is necessary but not sufficient for modeling survivability, we need to define what is meant with the term survivability at strategic level  With regard to \(a behaviors or modes which have very different consequences. These failure behaviors can be captured with hybrid fault models. However, the existing hybrid fault models in fault tolerance field are not adequate for applying to survivability analysis. There are two issues involved: one is the lack of real time notion in the constraints for hybrid fault models \(e.g., N&gt;3m+1 for Byzantine Generals problem synthesize the models after the real-time notions are introduced. The solution we proposed for the first issue is the dynamic hybrid fault models, which integrate survivor functions with traditional hybrid fault models. The solution we proposed for the second issue is the introduction of EGT modeling  With regard to \(b modeling our problem at strategic level, EGT modeling is essentially a powerful optimization algorithm.  One of the most important results from EGT modeling is the so-called evolutionary stable strategies \(ESS We map the ESS in EGT to survivable strategies in survivability analysis.   Therefore, at the strategic level, our work definition for survivability refers to the survivable strategies or sustainable strategies in the native term of EGT, which can be quantified with ESS  In addition to integrating dynamic hybrid fault models another advantage for introducing EGT modeling at strategic level is the flexibility for incorporating other node behaviors \(such as cooperative vs. non-cooperative those behaviors specified in standard hybrid fault models, as well as anthropocentric factors such as costs constraints  Without UUUR events, both tactical and strategic level 


Without UUUR events, both tactical and strategic level models default to regular reliability models. This implies that, in the absence of UUUR events, reliable strategies are sustainable or survivable.  This also implies that three-layer survivability analysis defaults to reliability analysis however, the three-layer approach does offer some significant advantages over traditional reliability analysis, as discussed in previous sections. Nevertheless, when UUUR events exist, reliable strategies and survivable strategies are different. This necessitates the next operational level modeling  5.2. Operational Level Modeling and Decision-Making  When UUUR events are involved, we cannot make real time predictions of survivability at tactical and strategic levels This implies that the implementations of survivable 14 strategies need additional measures that we develop in this section.  Box 5.1 explains the ideas involved with possibly the simplest example  Figure 4 is a diagram showing a simplified relationship between action threshold survivability \(TS survivability \(ES view since both TS and ES are multidimensional and dynamic in practice. Therefore, the sole purpose of the diagram is to illustrate the major concepts discussed above The blue curve is the survivability when survivable strategies specified by ESS are implemented at some point before time s.  The system is then guaranteed to hold survivability above ES. In contrary, if no ESS implemented before time s, then the system quickly falls below to the survivable level at around 40 time units  T i m e 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 1 0 0 Su rv iv ab ili ty M et ric S u t 0 . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 . 0 E S S  i s  I m p lm e n t e d N o  E S S  is  I m p lm e n t e d ts E S T S  Figure 4. A Diagram Showing the Relationship Between TS and ES, as well as timing of s and t, with s &lt; t  6. SUMMARY  The previous sections discussed the major building blocks 


The previous sections discussed the major building blocks for the new life-system inspired PHM architecture. This section first identifies a few minor aspects that have not been discussed explicitly but are necessary for the implementation of the architecture, and then we summarize the major building blocks in a diagram  6.1. Missing Components and Links  Optimization Objectives  Lifetime, reliability, fault tolerance, and survivability, especially the latter two, are application dependent. Generally, the optimization of reliability and survivability are consistent; in that maximization of reliability also implies maximization of survivability. However, when application detail is considered, optimization of lifetime is not necessarily consistent with the optimization of reliability. Consider the case of the monitoring sensor network as an example. The network reliability is also dependent on connectivity coverage, etc, besides network lifetime. What may be further complicated is the time factor. All of the network metrics are time-dependent. A paradoxical situation between lifetime and reliability could be that nodes never 'sleep                                                   


          Box 5.1 Operational Level Modeling  Assuming that the ESS solution for a monitoring sensor network can be expressed with the following simple algebraic conditions: survivability metric at tactical level SU = 0.7, Router-Nodes in the WSN &gt; 10%, Selfish Nodes &lt; 40%. Even with this extremely simplified scenario, the ESS strategies cannot be implemented because we do not know when the actions should be taken to warrant a sustainable system.  These conditions lack a correlation with real time  The inability to implement ESS is rooted in our inability to assign definite probabilities to UUUR events, which implies that we cannot predict when something sufficiently bad will jeopardize the system survivability What we need at the operational level is a scheme to ensure ESS strategy is in place in advance  The fundamental idea we use to implement the ESS strategy is to hedge against the UUUR events. The similar idea has been used in financial engineering and also in integrated pest management in entomology. This can be implemented with the following scheme  Let us define a pair of survivability metrics: one is the expected survivability \(ES threshold survivability or simply threshold survivability \(TS ES is equivalent to the survivability metric at tactical level. ES corresponds to ESS at strategic level, but they are not equivalent since ESS is strategy and ES is survivability. TS is the survivability metric value \(at tactical level and TS can be obtained from strategic level models. For example, TS = SU\(s t condition for the implementation of ESS. In other words, the implementation of strategies that ensures TS at time s will guarantee the future ES level at time t.  To make the implementation more reliable and convenient multiple dynamic TSs can be computed at time s1, s2 sk, with si &lt; t for all i.  These TS at times s1, s2, ..., sk should be monitored by some evaluation systems  Unlike tactical and strategic levels, the operational level modeling is approximate. The term "approximate means that we cannot predict the real time survivability or we do not know the exact time an action should be taken. Instead, the action is triggered when the monitored survivability metric SU\(r survivability \(TS scheme of TS and ES, we ensure the ES by taking preventative actions \(prescribed by ESS and triggered by the TS consequences of UUUR events  Figure 4 is a diagram showing the above concepts and the decision-making process involved 15 This wakefulness \(never 'sleep short period but at the expense of network lifetime. Of course, when the network is running out of lifetime, network reliability ultimately crashes. This example reminds us that 


reliability ultimately crashes. This example reminds us that multi-objective optimization should be the norm rather than exception  Constraints and Extensions  Many application specific factors and constraints are ignored in this article. For example, we mentioned about spatial heterogeneity of environment, but never present a mathematical description The spatial heterogeneity can be modeled with the so-called spatial frailty in multivariate survival analysis \(Ma 2008a  Evolutionary Algorithm  Evolutionary game modeling when implemented in simulation, can be conveniently implemented with an algorithm similar to Genetic Algorithms \(GA ESS in the evolutionary game model with simulation is very similar to GA. Dynamic populations, in which population size varies from generation to generation \(Ma &amp; Krings 2008f of node failures. Another issue to be addressed is the synchronous vs. asynchronous updating when topology is considered in the simulation. This update scheme can have profound influences on the results of the simulation. Results from cellular automata computing should be very useful for getting insights on the update issue  6.2. Summary and Perspective  To recapture the major points of the article, let us revisit Figure 3, which summarizes the principal modules of the proposed life-system inspired PHM architecture. The main inspiration from life systems is the notion of individuals and their assemblage, the population. Population is an emergent entity at the next level and it has emergent properties which we are often more concerned with. Survival analysis, which has become a de facto standard in biomedicine, is particularly suitable for modeling population, although it is equally appropriate at individual level. Therefore, survival analysis \(including competing risks analysis and multivariate survival analysis comprehensively in the context of PHM in a series of four papers presented at IEEE AeroSpace 2008 \(Ma &amp; Krings 2008a, b, c, &amp; d proposed architecture. Survival analysis constitutes the major mathematical tools for analyzing lifetime and reliability, and also forms the tactical level of the three-layer survivability analysis  Besides lifetime and reliability, two other major modules in Figure 3 are fault tolerance and survivability. To integrate fault tolerance into the PHM system, Dynamic Hybrid Fault DHF 2008e, Ma 2008a make real-time prediction of reliability more realistic and make real-time prediction of fault tolerance level possible DHF models also unite lifetime, reliability and fault tolerance under a unified modeling framework that consists of survival analysis and evolutionary game theory modeling  DHG models also form the partial foundation, or strategic level, for the three-layer survivability analysis. At the strategic level, the Evolutionary Stable Strategies \(ESS which is mapped to survivable or sustainable strategies, can be obtained from the evolutionary game theory based DHF models. When there is not any UUUR event involved reliability and survivability are consistent, and reliable strategies are survivable. In this case, the strategic level modeling up to this point is sufficient for the whole PHM system modeling, and there is no need for the next level  operational level modeling  When there are UUUR events in a PHM system, the 


When there are UUUR events in a PHM system, the inability to determine the occurrence probabilities of UUUR events makes the operational level modeling necessary Then the principle of hedging must be utilized to deal with the "hanging" uncertainty from UUUR events. In this case reliability strategies are not necessarily survivable strategies At the operational level modeling, a duo of survivability metrics, expected survivability \(ES survivability \(TS the survivable strategies \(ESS level are promptly implemented based on the decisionmaking rules specified with the duo of survivability metrics then the PHM system should be able to endure the consequences of potentially catastrophic UUUR events. Of course, to endure such catastrophic events, the cost may be prohibitively high, but the PHM system will, at least, warn decision-makers for the potentially huge costs.  It might be cheap to just let it fail  Figure 3 also shows several other modules, such as security safety, application systems \(such as Automatic Logistics CBM+, RCM, Life cycle cost management, Real-time warning and alert systems architectures, but we do not discuss in this paper. Generally the new architecture should be fully compatible with existing ones in incorporating these additional modules. One point we stressed is that PHM system can be an ideal place to enforce security policies. Enforcing security policies can be mandatory for PHM systems that demand high security and safety such as weapon systems or nuclear plant facilities.  This is because maintenance, even without human-initiated security breaches, can break the security policies if the maintenance is not planned and performed properly  In perspective, although I did not discuss software issues in this paper, the introduced approaches and models should provide sufficient tools for modeling software reliability and survivability with some additional extension. Given the critical importance of software to modern PHM systems, we present the following discussion on the potential extension to software domain. Specifically, two points should be noted: \(1 architecture to software should be a metric which can 16 replace the time notion in software reliability; I suggest that the Kolmogorov complexity \(e.g., Li and Vitanyi 1997 be a promising candidate \(Ma 2008a change is because software does not wear and calendar time for software reliability usually does not make much sense 2 software reliability modeling.  Extending to general survivability analysis is not a problem either. In this article I implicitly assume that reliability and survivability are positively correlated, or reliability is the foundation of survivability. This positive correlation does not have to be the case. A simplified example that illustrates this point is the 'limit order' in online stock trading, in which limit order can be used in either direction: that stock price is rising or falling.  The solution to allow negative or uncorrelated relationships between reliability and survivability are very straightforward, and the solutions are already identified in previous discussions. Specifically, multiple G-functions and multi-stage G-functions by Vincent and Brown \(2005 very feasible solution, because lifetime, reliability and survivability may simply be represented with multiple Gfunctions. Another potential solution is the accommodation of the potential conflicts between reliability and survivability with multi-objective GA algorithms, which I previously suggested to be used as updating algorithms in the optimization of evolutionary games  


 The integration of dynamic hybrid fault models with evolutionary game modeling allows one to incorporate more realistic and detailed failure \(or survival individual players in an evolutionary game. This is because dynamic hybrid fault models are supported by survival analysis modeling, e.g., time and covariate dependent hazard or survivor functions for individual players. If necessary, more complex survival analysis modeling including competing risks analysis and multivariate survival analysis, can be introduced.  Therefore, any field to which evolutionary game theory is applicable may benefit from the increased flexibility in modeling individual players.  Two particularly interesting fields are system biology and ecological modeling.  In the former field, dynamic hybrid fault models may find important applications in the study of biological networks \(such as gene, molecular, and cell networks 2008g conjecture that explains the redundancy in the universal genetic code with Byzantine general algorithm. In addition they conducted a comparative analysis of bio-robustness with engineering fault tolerance, for example, the strong similarity between network survivability and ecological stability \(Ma &amp; Krings 2008g survivability analysis can be applied for the study of survivals or extinctions of biological species under global climate changes \(Ma 2008b  In this paper, I have to ignore much of the details related to the implementation issues to present the overall architecture and major approaches clearly and concisely. To deal with the potential devils in the implementation details, a well funded research and development team is necessary to take advantages of the ideas presented here. On the positive side I do see the great potential to build an enterprise PHM software product if there is sufficient resource to complete the implementation. Given the enormous complexity associated with the PHM practice in modern engineering fields, it is nearly impossible to realize or even demonstrate the benefits of the architecture without the software implementation. The critical importance of PHM to mission critical engineering fields such as aerospace engineering, in turn, dictates the great value of such kind software product  6.3. Beyond PHM  Finally, I would like to raise two questions that may be interested in by researchers and engineers beyond PHM community. The first question is: what can PHM offer to other engineering disciplines? The second question is: what kinds of engineering fields benefit most from PHM? Here, I use the term PHM with the definition proposed by IEEE which is quoted in the introduction section of the paper  As to the first question, I suggest software engineering and survivability analysis are two fields where PHM can play significant roles. With software engineering, I refer to applying PHM principles and approaches for dealing with software reliability, quality assurance, and even software process management, rather than building PHM software mentioned in the previous subsection. For survivability analysis, borrowing the procedures and practices of PHM should be particularly helpful for expanding its role beyond its originating domain \(network systems that control critical national infrastructures is a strong advocate for the expansion of survivability analysis to PHM. Therefore, the interaction between PHM and survivability analysis should be bidirectional. Indeed, I see the close relationships between PHM, software engineering, and survivability as well-justified because they all share some critical issues including reliability survivability, security, and dependability  


 The answer to the second question is much more elusive and I cannot present a full answer without comparative analysis of several engineering fields where PHM has been actively practiced. Of course, it is obvious that fields which demand mission critical reliability and dependability also demand better PHM solutions. One additional observation I would like to make is that PHM seems to play more crucial roles for engineering practices that depend on the systematic records of 'historical' data, such as reliability data in airplane engine manufacturing, rather than on the information from ad hoc events.  This may explain the critical importance of PHM in aerospace engineering particularly in commercial airplane design and manufacturing.  For example, comparing the tasks to design and build a space shuttle vs. to design and manufacture commercial jumbo jets, PHM should be more critical in the latter task  17    Figure 2. States of a monitoring sensor node and its failure modes \(after Ma &amp; Krings 2008e     Figure 3. Core Modules and their Relationships of the Life System Inspired PHM Architecture    REFERENCES  Adamides, E. D., Y. A. Stamboulis, A. G. Varelis. 2004 Model-Based Assessment of Military Aircraft Engine Maintenance Systems Model-Based Assessment of Military Aircraft Engine Maintenance Systems. Journal of the Operational Research Society, Vol. 55, No. 9:957-967  Anderson, R. 2001. Security Engineering. Wiley  Anderson, R. 2008. Security Engineering. 2nd ed. Wiley  Bird, J. W., Hess, A. 2007.   Propulsion System Prognostics R&amp;D Through the Technical Cooperation Program Aerospace Conference, 2007 IEEE, 3-10 March 2007, 8pp  Bock, J. R., Brotherton, T., W., Gass, D. 2005. Ontogenetic reasoning system for autonomic logistics. Aerospace Conference, 2005 IEEE 5-12 March 2005.Digital Object Identifier 10.1109/AERO.2005.1559677  Brotherton, T., P. Grabill, D. Wroblewski, R. Friend, B Sotomayer, and J. Berry. 2002. A Testbed for Data Fusion for Engine Diagnostics and Prognostics. Proceedings of the 2002 IEEE Aerospace Conference  Brotherton, T.; Grabill, P.; Friend, R.; Sotomayer, B.; Berry J. 2003. A testbed for data fusion for helicopter diagnostics and prognostics. Aerospace Conference, 2003. Proceedings 2003 IEEE  Brown, E. R., N. N. McCollom, E-E. Moore, A. Hess. 2007 Prognostics and Health Management A Data-Driven Approach to Supporting the F-35 Lightning II. 2007 IEEE AeroSpace Conference  Byington, C.S.; Watson, M.J.; Bharadwaj, S.P. 2008 Automated Health Management for Gas Turbine Engine Accessory System Components. Aerospace Conference 2008 IEEE, DOI:10.1109/AERO.2008.4526610 


2008 IEEE, DOI:10.1109/AERO.2008.4526610 Environment Covariates &amp; Spatial Frailty Applications: AL; Life Cycle Mgmt; Real-Time Alerts CBM+, RCM, TLCSM; Secret Sharing and Shared Control 18 Chen, Y. Q., S. Cheng. 2005. Semi-parametric regression analysis of mean residual life with censored survival data Biometrika \(2005  29  Commenges, D. 1999. Multi-state models in Epidemiology Lifetime Data Analysis. 5:315-327  Cook, J. 2004. Contrasting Approaches to the Validation of Helicopter HUMS  A Military User  s Perspective Aerospace Conference, 2004 IEEE  Cook, J. 2007. Reducing Military Helicopter Maintenance Through Prognostics. Aerospace Conference, 2007 IEEE Digital Object Identifier 10.1109/AERO.2007.352830  Cox, D. R. 1972. Regression models and life tables.  J. R Stat. Soc. Ser. B. 34:184-220  Crowder, M. J.  2001. Classical Competing Risks. Chapman amp; Hall. 200pp  David, H. A. &amp; M. L. Moeschberger. 1978. The theory of competing risks. Macmillan Publishing, 103pp  Ellison, E., L. Linger, and M. Longstaff. 1997.  Survivable Network Systems: An Emerging Discipline, Carnegie Mellon, SEI, Technical Report CMU/SEI-97-TR-013  Hanski, I. 1999. Metapopulation Ecology. Oxford University Press  Hallam, T. G. and S. A. Levin. 1986. Mathematical Ecology. Biomathematics. Volume 17. Springer. 457pp  Hess, A., Fila, L. 2002.  The Joint Strike Fighter \(JSF concept: Potential impact on aging aircraft problems Aerospace Conference Proceedings, 2002. IEEE. Digital Object Identifier: 10.1109/AERO.2002.1036144  Hess, A., Calvello, G., T. Dabney. 2004. PHM a Key Enabler for the JSF Autonomic Logistics Support Concept. Aerospace Conference Proceedings, 2004. IEEE  Hofbauer, J. and K. Sigmund. 1998. Evolutionary Games and Population Dynamics. Cambridge University Press 323pp  Hougaard, P. 2000. Analysis of Multivariate Survival Data Springer. 560pp  Huzurbazar, A. V. 2006. Flow-graph model for multi-state time-to-event data. Wiley InterScience  Ibrahim, J. G., M. H. Chen and D. Sinha. 2005. Bayesian Survival Analysis. Springer. 481pp  Kacprzynski, G. J., Roemer, M. J., Hess, A. J. 2002. Health management system design: Development, simulation and cost/benefit optimization. IEEE Aerospace Conference Proceedings, 2002. DOI:10.1109/AERO.2002.1036148  Kalbfleisch, J. D., and R. L. Prentice, 2002. The Statistical Analysis of Failure Time Data. Wiley-InterScience, 2nd ed  Kalgren, P. W., Byington, C. S.   Roemer, M. J.  2006 Defining PHM, A Lexical Evolution of Maintenance and Logistics. Systems Readiness Technology Conference 


Logistics. Systems Readiness Technology Conference IEEE. DOI: 10.1109/AUTEST.2006.283685  Keller, K.; Baldwin, A.; Ofsthun, S.; Swearingen, K.; Vian J.; Wilmering, T.; Williams, Z. 2007. Health Management Engineering Environment and Open Integration Platform Aerospace Conference, 2007 IEEE, Digital Object Identifier 10.1109/AERO.2007.352919  Keller, K.; Sheahan, J.; Roach, J.; Casey, L.; Davis, G Flynn, F.; Perkinson, J.; Prestero, M. 2008. Power Conversion Prognostic Controller Implementation for Aeronautical Motor Drives. Aerospace Conference, 2008 IEEE. DOI:10.1109/AERO.2008.4526630  Klein, J. P. and M. L. Moeschberger. 2003. Survival analysis techniques for censored and truncated data Springer  Kingsland, S. E. 1995. Modeling Nature: Episodes in the History of Population Ecology. 2nd ed., University of Chicago Press, 315pp  Kot, M. 2001. Elements of Mathematical Ecology Cambridge University Press. 453pp  Krings, A. W. and Z. S. Ma. 2006. Fault-Models in Wireless Communication: Towards Survivable Ad Hoc Networks Military Communications Conference, 23-25 October, 7 pages, 2006  Lamport, L., R. Shostak and M. Pease. 1982. The Byzantine Generals Problem. ACM Transactions on Programming Languages and Systems, 4\(3  Lawless, J. F. 2003. Statistical models and methods for lifetime data. John Wiley &amp; Sons. 2nd ed  Line, J. K., Iyer, A. 2007. Electronic Prognostics Through Advanced Modeling Techniques. Aerospace Conference 2007 IEEE. DOI:10.1109/AERO.2007.352906  Lisnianski, A., Levitin, G. 2003. Multi-State System Reliability: Assessment, Optimization and Applications World Scientific  Liu, Y., and K. S. Trivedi. 2006. Survivability Quantification: The Analytical Modeling Approach, Int. J of Performability Engineering, Vol. 2, No 1, pp. 29-44  19 Luchinsky, D.G.; Osipov, V.V.; Smelyanskiy, V.N Timucin, D.A.; Uckun, S. 2008. Model Based IVHM System for the Solid Rocket Booster. Aerospace Conference, 2008 IEEE.DOI:10.1109/AERO.2008.4526644  Lynch, N. 1997. Distributed Algorithms. Morgan Kaufmann Press  Ma, Z. S. 1997. Demography and survival analysis of Russian wheat aphid. Ph.D. dissertation, Univ. of Idaho 306pp  Ma, Z. S. 2008a. New Approaches to Reliability and Survivability with Survival Analysis, Dynamic Hybrid Fault Models, and Evolutionary  Game Theory. Ph.D. dissertation Univ. of Idaho. 177pp  Ma, Z. S. 2008b. Survivability Analysis of Biological Species under Global Climate Changes: A New Distributed and Agent-based Simulation Architecture with Survival Analysis and Evolutionary Game Theory. The Sixth 


International Conference on Ecological Informatics. Dec 25, 2008. Cancun, Mexico  Ma, Z. S. and E. J. Bechinski. 2008. A Survival-Analysis based  Simulation Model for Russian Wheat Aphid Population Dynamics. Ecological Modeling, 216\(2 332  Ma, Z. S. and A. W. Krings. 2008a.  Survival Analysis Approach to Reliability Analysis and Prognostics and Health Management \(PHM  AIAA AeroSpace Conference, March 1-8, 2008, Big Sky, MT, 20pp  Ma, Z. S. and A. W. Krings. 2008b. Competing Risks Analysis of Reliability, Survivability, and Prognostics and Health Management \(PHM  AIAA AeroSpace Conference, March 1-8, 2008.  Big Sky, MT. 20pp  Ma, Z. S. and A. W. Krings. 2008c. Multivariate Survival Analysis \(I Dependence Modeling", Proc. IEEE  AIAA AeroSpace Conference, March 1-8, 2008, Big Sky, MT. 21pp  Ma, Z. S. and A. W. Krings., R. E. Hiromoto. 2008d Multivariate Survival Analysis \(II State Models in Biomedicine and Engineering Reliability IEEE International Conference of Biomedical Engineering and Informatics, BMEI 2008.  6 Pages  Ma, Z. S. and A. W. Krings. 2008e. Dynamic Hybrid Fault Models and their Applications to Wireless Sensor Networks WSNs Modeling, Analysis and Simulation of Wireless and Mobile Systems. \(ACM MSWiM 2008 Vancouver, Canada  Ma, Z. S. &amp; A. W. Krings. 2008f. Dynamic Populations in Genetic Algorithms. SIGAPP, the 23rd Annual ACM Symposium on Applied Computing, Ceara, Brazil, March 16-20, 2008. 5 Pages  Ma, Z. S. &amp; A. W. Krings. 2008g. Bio-Robustness and Fault Tolerance: A New Perspective on Reliable, Survivable and Evolvable Network Systems, Proc. IEEE  AIAA AeroSpace Conference, March 1-8, Big Sky, MT, 2008. 20 Pages  Ma, Z. S.  and A. W. Krings. 2009. Insect Sensory Systems Inspired Computing and Communications.  Ad Hoc Networks 7\(4  MacConnell, J.H. 2008. Structural Health Management and Structural Design: An Unbridgeable Gap? 2008 IEEE Aerospace Conference, DOI:10.1109/AERO.2008.4526613  MacConnell, J.H. 2007. ISHM &amp; Design: A review of the benefits of the ideal ISHM system. Aerospace Conference 2007 IEEE. DOI:10.1109/AERO.2007.352834  Marshall A. W., I. Olkin. 1967. A Multivariate Exponential Distribution. Journal of the American Statistical Association, 62\(317 Mar., 1967  Martinussen, T. and T. H. Scheike. 2006. Dynamic Regression Models for Survival Data. Springer. 466pp  Mazzuchi, T. A., R. Soyer., and R. V. Spring. 1989. The proportional hazards model in reliability. IEEE Proceedings of Annual Reliability and Maintainability Symposium pp.252-256  Millar, R.C., Mazzuchi, T.A. &amp; Sarkani, S., 2007. A Survey of Advanced Methods for Analysis and Modeling of 


of Advanced Methods for Analysis and Modeling of Propulsion System", GT2007-27218, ASME Turbo Expo 2007, May 14-17, Montreal, Canada  Millar, Richard C., "Non-parametric Analysis of a Complex Propulsion System Data Base", Ph.D. Dissertation, George Washington University, June 2007  Millar, R. C. 2007. A Systems Engineering Approach to PHM for Military Aircraft Propulsion Systems. Aerospace Conference, 2007 IEEE. DOI:10.1109/AERO.2007.352840  Millar, R. C. 2008.  The Role of Reliability Data Bases in Deploying CBM+, RCM and PHM with TLCSM Aerospace Conference, 2008 IEEE, 1-8 March 2008. Digital Object Identifier: 10.1109/AERO.2008.4526633  Nowak, M. 2006. Evolutionary Dynamics: Exploring the Equations of Life. Harvard University Press. 363pp  Oakes, D. &amp; Dasu, T. 1990. A note on residual life Biometrika 77, 409  10  Pintilie, M. 2006. Competing Risks: A Practical Perspective.  Wiley. 224pp  20 Smith, M. J., C. S. Byington. 2006. Layered Classification for Improved Diagnostic Isolation in Drivetrain Components. 2006 IEEE AeroSpace Conference  Therneau, T. and P. Grambsch. 2000. Modeling Survival Data: Extending the Cox Model. Springer  Vincent, T. L. and J. L. Brown. 2005. Evolutionary Game Theory, Natural Selection and Darwinian Dynamics Cambridge University Press. 382pp  Wang. J., T. Yu, W. Wang. 2008. Research on Prognostic Health Management \(PHM on Flight Data. 2008 Int. Conf. on Condition Monitoring and Diagnosis, Beijing, China, April 21-24, 2008. 5pp  Zhang, S., R. Kang, X. He, and M. G. Pecht. 2008. China  s Efforts in Prognostics and Health Management. IEEE Trans. on Components and Packaging Technologies 31\(2             BIOGRAPHY  Zhanshan \(Sam scientist and earned the terminal degrees in both fields in 1997 and 2008, respectively. He has published more than 60 peer-refereed journal and conference papers, among which approximately 40 are journal papers and more than a third are in computer science.  Prior to his recent return to academia, he worked as senior network/software engineers in semiconductor and software industry. His current research interests include: reliability, dependability and fault tolerance of distributed and software systems behavioral and cognitive ecology inspired pervasive and 


behavioral and cognitive ecology inspired pervasive and resilient computing; evolutionary &amp; rendezvous search games; evolutionary computation &amp; machine learning bioinformatics &amp; ecoinformatics                 pre></body></html 



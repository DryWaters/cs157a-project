Mining Fuzzy Sequential Patterns from Multiple-Item Transactions Tzung-Pei Hong, Kuie-Ying Lin and Shyue-Liang Wang Department of Information Management I-Shou University Kaohsiung, 84008 Taiwan ROC  tphong, m883331m slwang}, @isu.edu.tw Abstract Transaction data in real-world applications usually consist of quantitative values so designing a sophisticated data-mining algorithm able to deal with various types of data presents a challenge to workers in this research field Since sequential patterns are also very important for real-world applications this paper thus focuses 
on finding fuzzy sequential patterns from quantitative data A new mining algorithm is proposed which integrates the fuzzy-set concepts and the AprioriAll algorithm It first transforms quantitative values in transactions into linguistic terms, then filters them to find sequential patterns by modifying the AprioriAll mining algorithm Each quantitative item uses only the linguistic term with the maximum cardinality in later mining processes thus making the number of fuzzy regions to be processed the same as the number of the original items The patterns mined out thus exhibit the sequential quantitative 
regularity in databases and can be used to provide some suggestions to appropriate supervisors Keywords data mining fuzzy set quantitative data sequential pattern transaction 1 Introduction Among the topics of data mining finding useful sequential patterns is very interesting A sequential pattern is an expression X Y where Xis a set of items and Y is another set of items It means in the set of transactions if a customer buys 
all the items in X at some time, then he will buy all the items in Y at some other time with a high probability It is thus concerned with inter-transaction patterns which are ordered itemsets In the past several mining algorithms for finding sequential patterns were proposed Most of them however focused on binary valued transaction data. Since transaction data in real-world applications usually consist of quantitative values designing a sophisticated data-mining algorithm able to deal with various types of data presents a challenge to workers in this research 
field In this paper we thus propose a fuzzy mining algorithm to find fuzzy sequential patterns from quantitative data The proposed algorithm integrates the fuzzy-set concepts and the AprioriAll algorithm SI It first transforms quantitative values in transactions into linguistic terms then filters them to find sequential patterns by modifying the AprioriAll mining algorithm The next quantitative transactions of a customer can thus be predicted according to hidher previous transactions The patterns mined out thus exhibit the sequential quantitative regularity in databases and can 
be used to provide some suggestions to appropriate supervisors 2 Review of Agrawal et al.\222s data-mining algorithms The goal of data mining is to discover important associations among items such that the presence of some items in a transaction or for a customer will imply the presence of some other items To achieve this purpose Agrawal and his co-workers proposed several mining algorithms based on the concept of large itemsets to find association rules or sequential pattems in transaction 
data l-51 In addition to proposing methods for mining association rules from transactions of binary values Agrawal et al also proposed a method SI for mining association rules from those with quantitative and categorical attributes Agrawal and Srikant also proposed the AprioriAll mining algorithm for finding sequential patterns from transaction data 5 Five phases are included in this algorithm In the first phase the database D is sorted with customer-id as the major key and transaction-time as 
the minor key This phase thus converts the original transaction database into a database of customer sequences In the second phase the set of all large itemsets are found In the third phase each large itemsets are mapped to a contiguous integer In the fourth phase the set of integers mapped are used to find the desired sequences In the fifth phase the maximal sequences are then derived among the set of 0-7803-7@78-3/0U$10.00 C IEEE Page 1317 


large sequences CID Transaction Time 1 May5 99 1 May 17 99 2 May 13'99 2 May19'99 2 May21 99 3 May7'99 3 May 15 99 4 May11 99 3 Review of Fuzzy Set Concepts purchased items B92 C,3 E,3 DS B72 C,4 D,9 A,7 B98 D,7 E,9 B,l C,3 Fuzzy set theory was first proposed by Zadeh in 1965 9 Fuzzy set theory is primarily concerned with quantifying and reasoning using natural language in which words can have ambiguous meanings This can be thought of as an extension of traditional crisp sets in which each element must either be in or not in a set Formally the process by which individuals from a universal set X are determined to be either members or non-members of a crisp set can be defined by a characteristic or discrimination finction 9 For a give crisp set A this tinction assigns a value p x to every x E X such that 1 if and only if XEA 0 if and only if xeA Thus. the function maps elements of the universal set to the set containing 0 and 1 This kind of function can be generalized such that the values assigned to the elements of the universal set fall within specified ranges, referred to as the membership grades of these elements in the set Larger values denote higher degrees of set membership Such a function is called the membership function PA by which a fuzzy set A is usually defined This function is represented by PA X+[O,11 where 0 I denotes the interval of real numbers from 0 to I inclusive. The function can also be generalized to any real interval instead of O,l A special notation is often used in the literature to represent fuzzy sets Assume that XI to x are the elements in fuzzy set A and U to are respectively their grades of membership in A A is then usually represented as follows A=/X 1x1 2 x2 U Ix An a-cut of a fuzzy set A is a crisp set A that contains all elements in the universal set X with membership grades in A greater than or equal to a specified value of a This definition can be written as The scalar cardinal of a fuzzy set A defined on a finite universal set X is the summation of the  membership grades of all the elements of X in A Thus Among operations on fuzzy sets are the basic and commonly used complementation union and intersection as proposed by Zadeh 1 The complementation of a fizzy set A is denoted by TA and the membership function of 1 A is given by PYA x l-PA 9 v X\200X 2 The intersection of two fuzzy sets A and B is denoted by A n B and the membership function of A n B is given by 3 The union of hzzy sets A and B is denoted by A U B and the membership finction of A U B is given by The above fuzzy operations will be used in the proposed mining algorithm to find linguistic association rules 4 The Approach with An Example In this section an example is given to illustrate the proposed mining algorithm for fuzzy sequential pattems This is a simple example to show how the proposed algorithm can be used to generate interesting sequential pattems for customers purchase behavior according to historical data The data set including 16 transactions, is shown in Table 1 0-7803-7078-3/0V$10.00 C IEEE Page 1318 


May25 22199 1 B,3 C,5 There are five kinds of products A B C D and E in this example Each transaction includes a CID\(customer ID transaction time and some purchased items Each item is represented by a tuple item name item amount The data set in Table 1 is then grouped by customers\222 transaction time Results are shown in Table 2 Table 2 The data set grouped by customers ICIDI Items and Ouantities 1 Assume the fuzzy membership functions for the product quantities are shown in Figure 1 01 6   Number of item Figure 1  The membership functions used in this example In this example, the quantities purchased are divided into three fuzzy regions Low Middle and High Thus three fuzzy membership values are produced for each transaction according to the predefined membership functions For the transaction data in Table I the proposed mining algorithm proceeds as follows STEP 1 Transform the quantitative values of each transaction datum into hzzy sets Take the product B bought by customer 1 as an example The quantity \2232\224 is converted into a fuzzy set O.S/Low+O.2/Middle+O.O/High using the given membership functions Figure 1 This step is repeated for the other items and customers and the results are shown in Table 3 The notation item.term is called a fuzzy region Table 3 The fuzzy sets are in this example STEP 2 Calculate the scalar cardinality of each item in each customer\222s transaction data as the count value Here the maximum operator is used for the same region of the item in a customer\222s transaction data Take the region D.Middle as an example Its scalar cardinality  0.0  mar\(0.8,0.4  0.8  0.8  1.0  1 O  4.4 This step is repeated for the other regions and the results are shown in Table 4 STEP 3 The fuzzy region with the highest count among the three possible regions for each item is found Take item A as an example Its count is 0.0 for Low 0.8 for Middle and 0.2 for High Since the count for Middle is the highest among the three counts the region Middle is thus used to represent the item A in later mining processes This step is repeated for the other items. Thus 223Low\223 is chosen for B 223Middle\224 is chosen for C and 0 and 223Highli is chosen E STEP 4 The count of any region selected in STEP 3 is checked against the predefined minimum support value a  Assume a is set at 2 in this example Since the count values of BLOW C.Midde D.Middle and E High are larger than 2 these items are put in L STEP 5 Set FI STEP 6 Generate the candidate set C from L C2 is 0-7803-7078-3/0lf$l0.00 C IEEE Page 1319 


first generated from L as follows B.Low CMiddle B LOH D Middlej B Low E High C Middle D.Middle CMiddle E High\\(D.Middle E High Customer 1 3 1 0.8 0.0 2 0.8 0.4 3 0.0 0.0 STEP 7 Do the following substeps for each newly formed candidate itemset a Calculate the fuzzy membership value of the candidate itemset in each customer\222s transaction datum. Here, the minimum operator is used for the intersection Take B.Low C.Midd1e as an example Its membership value for Customer I is calculated as min\(0.8 0.4 The results for the other customers are shown in Table 5 I 3 0.0 0.4 0.0 iddle b Calculate the scalar cardinality count of each candidate 2-itemset in the transaction data Results for this example are shown in Table 6 I 1 I 0.0 I 0.0 I 0.0 Table 6 The fuzzy counts of the itemsets in C I I Itemset I Count B Low CMiddle I 2.6 Customer 3 I 1 0.0 0.0 2 0.8 0.8 3 0.0 0.0 B Low D Middle  3 I 0.0 0.8 0.0 c Check whether these counts are larger than or equal to the predefined minimum support value 2 Two itemsets including B Low C Middle D.Middle E.High are thus kept in L2 Customer 1 3 I  I STEP 8 IF L is null then do the next step otherwise, set r+l and repeat STEPS 6 to 8 Since L2 is not null in the example r=r+l=2 STEPS 6 to 8 are then repeated to find L3 C is first generated from L2 but no itemsets can be formed for C L3 is thus an empty set STEP 9 then begins I  3 I STEP 9 The large itemsets are mapped to contiguous integers and these integers are put in L The results are shown in Table 7 2 I 0.8 I 0.8 3 I 0.0 I 0.0 Table 7 The large itemsets mapped to contiguous integers I 0.8 I 0.0 STEP 10 Set z=1 STEP 11 Generate the candidate set Cz+I from L2 C2 is first generated from LI as follows I I I 2 6 Note that the same combinations with different orders are thought of as different 2 Ill I  3 01  j 6 F-5 0 6 STEP 12 Do the following substeps for each newly formed candidate sequence a Calculate the fizzy membership value of the candidate sequence in each transaction datum Here the minimum operator is used for the intersection Take I 3 as an examples Its membership value for Customer 1 is calculated as min\(0.8 O.O since no item 3 appears after item I The results for the other customers are shown in Table 8 and Table 9  0.6 0.0 0.0 31 1.0 0.6 0.6 The results for the other 2-sequences can be derived in similar fashion b Calculate the scalar cardinality count of each candidate 2-sequences in the transaction data Results for this example are shown in Table 10 0-7803-7078-3/0l/$10.00 C IEEE Page 1320 


Sequences Count Sequences Count I I 0.0 2 2 1.0 I 2 I 4 2 3 1 o r\(2 111 0.0 3 2 2.4 c Check whether these counts are larger than or equal to the predefined minimum support value 2 Three sequences, including 3 I 6 I 3 2 are thus kept in L2 STEP 13 IF L is null then do the next step otherwise, set r=r+l and repeat STEPS 11 to 13 Since Lz is not null in the example r+l=2 STEPs 11 to 13 are then repeated to find L3 C is first generated from L2 but no sequences are formed for C3 L3 is thus an empty set STEP 14 then begins STEP 14 Check whether the pattems are redundant pattern Since the sequence 3 IJJ which is D.Middle B Low belongs to 6 I which is D.Middle E High B.Low the pattern D.Middle B.Loiv,J is then deleted in this example The following two sequential pattems are thus output to users Table 1 1  The final sequential pattems and their codes The two sequential patterns above are thus output as meta-knowledge concerning the given transactions 5 Conclusion In this paper we have proposed a novel data-mining algorithm which can process transaction data with quantitative values and discover interesting sequential patterns among them The patterns can thus predict what products and quantities will be bought next for a customer and can be used to provide some suggestions to appropriate supervisors Although the proposed method works well in data mining for quantitative values it is just a beginning There is still much work to be done in this field Our method assumes that the membership functions are known in advance In 6 71 we also proposed some fuzzy learning methods to automatically derive the membership functions In the future we will attempt to dynamically adjust the membership functions in the proposed mining algorithm 222to avoid the bottleneck of membership function acquisition We will also attempt to design specific data-mining models for various problem domains References I R Agrawal T Imielinksi and A Swami, \223Mining association rules between sets of items in large database,\221\221 The I993 ACM SIGMOD Confirence Washington DC USA 1993 2 R Agrawal T Imielinksi and A Swami, \223Database mining a performance perspective,\224 IEEE Transactions on Knowledge and Data Engineering 131 R Agrawal R Srikant and Q Vu 223Mining association rules with item constraints,\224 The Third International Conference on Knowledge Discovery in Databases and Data Mining Newport Beach California, August 1997 4 R Agrawal and R Srikant 223Fast algorithm for mining association rules,\224 The International Conference on Yery Large Data Bases 1994 pp 5 R Agrawal R Srikant 224Mining Sequential Patterns\224 Proc of the Int\221l Conference on Data Engineering ICDE Taipei, Taiwan March 1995 6 T P Hong and J B Chen 223Finding relevant attributes and membership functions,\224 Fuzzy Sets and Sysrems Vol 103 No 3 1999 pp 389-404 7 T P Hong and C Y Lee 223Induction of fizzy rules and membership functions from training examples,\223 Fwry Sets and Systems Vol 84, 1996 pp 33-47 8 R Srikant and R Agrawal, \223Mining quantitative association rules in large relational tables,\224 The I996 ACM SIGMOD International Conference on Management of Data Monreal, Canada, June 1996 9 H J Zimmermann Fuzzy Set Theory and Its Applications Kluwer Academic Publisher, Boston 1991 Vol 5 NO 6 1993 pp 9 14-925 487-499 pp 1-12 0-7803-7@78-3/0l/$l0.00 C IEEE Page 1321 


algorithm we proposed is suitable for this kind of databases For databases that need to be updated frequently and satisfy the characteristics listed in section 2 the referenced-binary compression gives an efficiency way to compress the databases When a database is updated, we do not need to scan the old database every time With the help of the itemsets file that stored the large itemsets of an old database we can decrease the workload of finding large itemsets for association rules With the referenced-binary compression the storage space the efficiency of analyzing or finding the association rules from the statistical database will be improved REFERENCE J Ziv and A.Lempe1 A universal algorithm for sequential data compression IEEE Transactions on Information Theory Vol IT 23 No 3 May 1977 pp.337-343 J.Ziv and A Lempel Compression of individual sequences via variable rate coding IEEE Transactions on Information Theory Vol IT-24 No 5 September 1978 pp 530 535 C.E Shannon 223A Mathematical Theory of Communication,\224 Bell System Technical J Vol 27 No 3 pp379-423 1948 T.Bell I.H Witten, and J.G Cleary Modeling for test compression ACM Computing Surveys Vo1.32  No.4 December 1989 pp 557-589 J.L Bentley D.D Sleator R.E Tarjan and V.K Wei A locally adaptive data compression algorithm Communications of the ACM Vol 29 No 4 April 1986 pp 320 330 W.K Ng and C.V Ravishankar 223Data Compression System and Methods Representing Records as Differences between Sorted Domain Ordinals Representing Fields Values,\223 U.S Patent No 5,603,022 Feb 1997 Wee Keong Ng Chinya V Ravishankar 223Block-Oriented Compression Techniques for Large Statistical Databases\224 IEEE Trransactions on Knowledge and Data Engineering Vol 9 No 2 pp314-328 March  April 1997 T.A Welch 223A Technique for High Performance Data Compression\224 Computer Vol 17 no 6 pp 8-19 June 1984 W.K Ng and C.V Ravishankar, \223Attribute Enumerative Coding A Compression Technique for Tuple Data Structures,\224 Proc Fourth Data Compression Conf p.461  Snowbird Utah Mar 29-3 I 1994 W.K Ng and C.V Ravishankar 223A Physical Storage Model for Efficiency Statistical Query Proceedings,\224 Proc Seventh IEEE Int\222l Working Conf Statistical and Scientific databases, pp 97-106 Charlottesville Va Sep 28-80 1994 W.K Ng and C.V Ravishankar 223Relational Database Compression Using Augmented Vector Quantization,\224 Proc 1 Ith IEEE Int\222l conf. Data Eng pp 540-549 Taipei, Taiwan March 6-10 1995 Rakesh Agrawal and Ramakrishnan Srikant 223Fast Algorithms for Mining Association Rules\224 Proceedings of the 20 VLDB Conference Santiago pp 487-499 Chile 1994 0-7803-7078-3/Ol/$lO.@l C IEEE Page 446 


Table 4 Running times in seconds for synthetic data sets We omitted parameter combinations where 11  12'1 because transaction size is too small for potential frequent subgraphs A dash in the table means we had to abort the computation for the set of parameters because of either memory exhaustion or taking too long time N 111 12'1 335 10 20 40 355 10 20 40 3 7 10 20 3 10 10 20 143 434 RunningTime[sec u=2 u=1 12 22 30 40 112 390 18 32 51 102 189 736 66 4512 5817  6110  1953  40  8290    20 40 255 10 20 2 7 10 20 2 10 10 20 U  2 10 16 20 35     27 52 25 1 2246   40  557 6203   40      20 20 I88 10 10 190 20 40 ime[secl U  1 17 25 40 98 18 51 119 246 816 I506 3199   53 71 196 279 N 111 IT1 u=2 u=l 10 16 28 20 34 38 RunningTime[sec u=2 I u=1 10 20 40 4055 10 20 40 40 7 10 20 40 40 10 10 20 27 44 44 47 84 89 20 28  29 60 55 131 177 234 197 1236 861 5273 2456 9183 9687    3271 10520 20 5 5 10 single bonding type. Essentially with U  lo this dataset becomes similar to the synthetic datasets where N  2 3.3 Summary of Discussions We summarize the characteristics of FSG performance First FSG works better on graph datasets with more edge and vertex labels During both candidate generation and frequency counting what FSG essentially does is to solve graph or subgraph isomorphism Without labels assigned determining isomorphism of graphs is more difficult to solve because we can not use labeling information as con straints to narrow down the search space of vertex mapping We can confirm it by comparing the results in Table 4 with various values of the number of edge and vertex labels N Second, the running time depends heavily on the size of frequent subgraphs to be discovered If input transactions contain many large frequent patterns such as more than 10 edges the situation corresponds to the parameter setting of 111  10 where FSG will not be likely to finish its compu tation in a reasonable amount of time The same thing hap pened with the chemical dataset with a support threshold less than 10 If we compare Figure 3\(a and Figure 3\(b we notice the running time increases at a higher rate than the number of discovered subgraphs does as we decrease the minimum support With a lower support criteria we start getting larger frequent subgraphs and both candidate generation and frequency counting become much more ex pensive On the other hand as for the cases of 111  5 in 10 19 20 51 u=2 u=1 10 20 25 20 40 20 7 10 48 117 182 233 193 804 Table 4 FSG runs fast The result of the chemical dataset is consistent with it For example if we use U  10 for the chemical dataset FSG spends 28 seconds to get 882 fre quent subgraphs in total The largest frequent graphs among them have 11 edges, and there are only 10 such frequent 11 subgraphs discovered Another important factor is the size of a transaction If the average size of transactions becomes large, frequency counting by subgraph isomorphism becomes expensive re gardless of the size of candidate subgraphs. Traditional fre quent itemset finding algorithms are free from this problem They can perform frequency counting simply by taking the intersection of itemsets and transactions As of the number of transactions FSG requires running time proportional to the size of inputs under the same set of parameters This is the same as frequent itemset discovery algorithms 4 Conclusion In this paper we presented an algorithm FSG for finding frequently occurring subgraphs in large graph databases that can be used to discover recurrent patterns in scientific, spatial and relational datasets Our experimen tal evaluation shows that FSG can scale reasonably well to very large graph databases provided that graphs contain a sufficiently many different labels of edges and vertices 319 


8000 7000  6000 25000 I 000 3000 2000 1000 a i     a Minimum support o and running time 25001 b Minimum support U and the number of discovered fre quent subgraphs Figure 3 Performance with the chemical compound dataset Acknowledgment We deeply thank Professor Takashi Washio Professor Hiroshi Motoda and their research group at the Institute of Scientific and Industrial Research Osaka University and Mr Akihiro Inokuchi at Tokyo Research Laboratory IBM Japan Ltd for providing the source code of AGM and use ful comments References l R C Agarwal C C Aggarwal V V V Prasad and V Crestana A tree projection algorithm for generation of large itemsets for association rules IBM Research Report RC21341 1998 2 R Agrawal and R Srikant Fast algorithms for mining as sociation rules In Proc the 20th VLDB pages 487-499 Morgan Kaufmann 1994 3 R Agrawal and R Srikant Mining sequential patterns In Proc the Ilth ICDE pages 3-14 IEEE Press, 1995 4 R N Chittimoori, L B Holder, and D J Cook Applying the SUBDUE substructure discovery system to the chemical toxicity domain In Proc the 12th Int Florida AI Research Society ConJ pages 90-94 1999 5 L Dehaspe H Toivonen, and R D King Finding frequent substructures in chemical compounds In Proc the 4th ACM SIGKDD KDD-98 pages 30-36 AAA1 Press 1998 6 D Dupplaw and P H Lewis Content-based image retrieval with scale-spaced object trees In Proc SPIE Storage and Retrieval for Media Databases volume 3972 pages 253 261,2000 7 S Fortin The graph isomorphism problem Technical Re port TR96-20 Department of Computing Science, Univer sity of Alberta, 1996 8 M R Carey and D S Johnson Computers and Intractabil ity A Guide to the Theory of NP-Completeness W H Free man and Company New York 1979 9 J Han J Pei, and Y Yin Mining frequent patterns without candidate generation In Proc ACM SIGMOD 2000 0 lo L Holder, D Cook and S Djoko. Substructure discovery in the SUBDUE system In Proc the Workshop on Knowledge Discovery in Databases pages 169-1 80 1994 I I A Inokuchi T Washio, and H Motoda An apriori-based al gorithm for mining frequent substructures from graph data In Proc PKDD'OO pages 13-23,2000 12 H Kalviainen and E Oja Comparisons of attributed graph matching algorithms for computer vision In Proc. STEP-90 Finnish ArtiJicial Intelligence Symposium pages 354-368 1990 13 M Kuramochi and G. Karypis Frequent subgraph discov ery Technical Report 01-028 Department of Computer Sci ence University of Minnesota, 2001 I41 D A L. Piriyakumar and P Levi An efficient A based algorithm for optimal graph matching applied to computer vision In GRWSIA-98 1998  151 http://oldwww.comlab.ox.ac.uk/oucVgroups/machlearn I61 R C Read and D G Corneil The graph isomorph disease Journal of Graph Theory 1:339-363 1977  171 A Srinivasan, R D King S Muggleton and M J E Stern berg Carcinogenesis predictions using ILP In Proc the 7th Int Workshop on Inductive Logic Programming volume 1297, pages 273-287 Springer-Verlag, Berlin 1997  181 A Srinivasan, R. D. King S H Muggleton and M Stern berg The predictive toxicology evaluation challenge In Proc the 15th IJCAI pages 1-6 Morgan-Kaufmann 1997 19 J R Ullman An algorithm for subgraph isomorphism Journal ofthe ACM 23\(1 1976 20 K Yoshida and H Motoda CLIP: Concept learning from in ference patterns Artificial Intelligence 75 1 1995  M J Zaki Scalable algorithms for association mining Knowledge and Data Engineering 12\(2 22 M J Zaki and K Gouda Fast vertical mining using diffsets Technical Report 01-1 Department of Computer Science Rensselaer Polytechnic Institute 2001 23 M J Zaki and C.-J. Hsiao CHARM An efficient algorithm for closed association rule mining,. Technical Report 99-10 Department of Computer Science Rensselaer Polytechnic Institute 1999 320 


In Figures 10 and 11 we see MAFIA is approximately four to five times faster than Depthproject on both the Connect-4 and Mushroom datasets for all support levels tested down to 10 support in Connect-4 and 0.1 in Mushroom For Connect-4 the increased efficiency of itemset generation and support counting in MAFIA versus Depthproject explains the improvement Connect 4 contains an order of magnitude more transactions than the other two datasets 67,557 transactions amplifying the MAFIA advantage in generation and counting For Mushroom the improvement is best explained by how often parent-equivalence pruning PEP holds especially for the lowest supports tested The dramatic effect PEP has on reducing the number of itemsets generated and counted is shown in Table 1 The entries in the table are the reduction factors due to PEP in the presence of all other pruning methods for the first eight levels of the tree The reduction factor is defined as  itemsets counted at depth k without PEP   itemsets counted at depth k with PEP In the first four levels Mushroom has the greatest reduction in number of itemsets generated and counted This leads to a much greater reduction in the overall search space than for the other datasets since the reduction is so great at highest levels of the tree In Figure 12 we see that MAFIA is only a factor of two better than Depthproject on the dataset Chess The extremely low number of transactions in Chess 3196 transactions and the small number of frequent 1-items at low supports only 54 at lowest tested support muted the factors that MAFIA relies on to improve over Depthproject Table 1 shows the reduction in itemsets using PEP for Chess was about an order of magnitude lower compared to the other two data sets for all depths To test the counting conjecture we ran an experiment that vertically scaled the Chess dataset and fixed the support at 50 This keeps the search space constant while varying only the generation and counting efficiency differences between MAFIA and Depthproject The result is shown in Figure 13 We notice both algorithms scale linearly with the database size but MAFIA is about five times faster than Depthproject Similar results were found for the other datasets as well Thus we see MAFIA scales very well with the number of transactions 5.3 Effects Of Compression To isolate the effect of the compression schema on performance experiments with varying rebuilding threshold values we conducted The most interesting result is on a scaled version of Connect-4, displayed in Figure 14 The Connect-4 dataset was scaled vertically three times so the total number of transactions is approximately 200,000 Three different values for rebuilding-threshold were used 0 corresponding to no compression 1 compression immediately and all subsequent operations performed on compressed bitmaps\and an optimized value determined empirically We see for higher supports above 40 compression has a negligible effect but at the lowest supports compression can be quite beneficial e.g at 10 support compression yields an improvement factor of 3.6 However the small difference between compressing immediately and finding an optimal compression point is not so easily explained The greatest savings here is only 11 at the lowest support of Conenct-4 tested We performed another experiment where the support was fixed and the Connect-4 dataset was scaled vertically The results appear in Figure 15 The x-axis shows the scale up factor while the y-axis displays the running times We can see that the optimal compression scales the best For many transactions \(over IO6 the optimal re/-threshold outperforms compressing everywhere by approximately 35 In any case both forms of compression scale much better than no compression Compression on Scaled ConnectAdata Compression Scaleup Connectldata ALL COMP 0 5 10 15 20 25 30 100 90 80 70 60 50 40 30 20 10 0 Min Support  Scaleup Factor Figure 14 Figure 15 45 1 


6 Conclusions We presented MAFIA an algorithm for finding maximal frequent itemsets Our experimental results demonstrate that MAFIA consistently outperforms Depthproject by a factor of three to five on average The breakdown of the algorithmic components showed parent-equivalence pruning and dynamic reordering were quite beneficial in reducing the search space while relative compressiodprojection of the vertical bitmaps dramatically cuts the cost of counting supports of itemsets and increases the vertical scalability of MAFIA Acknowledgements We thank Ramesh Agarwal and Charu Aggarwal for discussing Depthproject and giving us advise on its implementation We also thank Jayant R Haritsa for his insightful comments on the MAFIA algorithm and Jiawei Han for providing us the executable of the FP-Tree algorithm This research was partly supported by an IBM Faculty Development Award and by a grant from Microsoft Research References I R Agarwal C Aggarwal and V V V Prasad A Tree Projection Algorithm for Generation of Frequent Itemsets Journal of Parallel and Distributed Computing special issue on high performance data mining to appear 2000 2 R Agrawal T Imielinski and R Srikant Mining association rules between sets of items in large databases SIGMOD May 1993  R Agrawal R Srikant Fast Algorithms for Mining Association Rules Proc of the 20th Int Conference on Very Large Databases Santiago Chile, Sept 1994  R Agrawal H Mannila R Srikant H Toivonen and A 1 Verkamo Fast Discovery of Association Rules Advances in Knowledge Discovery and Data Mining Chapter 12 AAAVMIT Press 1995 5 C C Aggarwal P S Yu Mining Large Itemsets for Association Rules Data Engineering Bulletin 21 1 23-31 1 998 6 C C Aggarwal P S Yu Online Generation of Association Rules. ICDE 1998: 402-41 1 7 R J Bayardo Efficiently mining long patterns from databases SICMOD 1998: 85-93 8 R J Bayardo and R Agrawal Mining the Most Interesting Rules SIGKDD 1999 145-154 9 S Brin R Motwani J D Ullman and S Tsur Dynamic itemset counting and implication rules for market basket data SIGMOD Record ACM Special Interest Group on Management of Data 26\(2\1997 IO B Dunkel and N Soparkar Data Organization and access for efficient data mining ICDE 1999 l 11 V Ganti J E Gehrke and R Ramakrishnan DEMON Mining and Monitoring Evolving Data. ICDE 2000: 439-448  121 D Gunopulos H Mannila and S Saluja Discovering All Most Specific Sentences by Randomized Algorithms ICDT 1997: 215-229 I31 J Han J Pei and Y Yin Mining Frequent Pattems without Candidate Generation SIGMOD Conference 2000 1  12 I41 M Holsheimer M L Kersten H Mannila and H.Toivonen A Perspective on Databases and Data Mining I51 W Lee and S J Stolfo Data mining approaches for intrusion detection Proceedings of the 7th USENIX Securiry Symposium 1998 I61 D I Lin and Z M Kedem Pincer search A new algorithm for discovering the maximum frequent sets Proc of the 6th Int Conference on Extending Database Technology EDBT Valencia Spain 1998 17 J.-L Lin M.H Dunham Mining Association Rules: Anti Skew Algorithms ICDE 1998 486-493 IS B Mobasher N Jain E H Han and J Srivastava Web mining Pattem discovery from world wide web transactions Technical Report TR-96050 Department of Computer Science University of Minnesota, Minneapolis, 1996 19 J S Park M.-S Chen P S Yu An Effective Hash Based Algorithm for Mining Association Rules SIGMOD Conference 20 N Pasquier Y Bastide R Taouil and L Lakhal Discovering frequent closed itemsets for association rules ICDT 99 398-416, Jerusalem Israel January 1999 21 J Pei J Han and R Mao CLOSET An efficient algorithm for mining frequent closed itemsets Proc of ACM SIGMOD DMKD Workshop Dallas TX May 2000 22 R Rastogi and K Shim Mining Optimized Association Rules with Categorical and Numeric Attributes ICDE 1998 Orlando, Florida, February 1998 23 L Rigoutsos and A Floratos Combinatorial pattem discovery in biological sequences The Teiresias algorithm Bioinfomatics 14 1 1998 55-67 24 R Rymon Search through Systematic Set Enumeration Proc Of Third Int'l Conf On Principles of Knowledge Representation and Reasoning 539 550 I992 25 A Savasere E Omiecinski and S Navathe An efficient algorithm for mining association rules in large databases 21st VLDB Conference 1995 26 P Shenoy J R Haritsa S Sudarshan G Bhalotia M Bawa and D Shah: Turbo-charging Vertical Mining of Large Databases SIGMOD Conference 2000: 22-33 27 R Srikant R Agrawal Mining Generalized Association Rules VLDB 1995 407-419 28 H Toivonen Sampling Large Databases for Association Rules VLDB 1996 134-145 29 K Wang Y He J Han Mining Frequent Itemsets Using Support Constraints VLDB 2000 43-52 30 G I Webb OPUS An efficient admissible algorithm for unordered search Journal of Artificial Intelligence Research 31 L Yip K K Loo B Kao D Cheung and C.K Cheng Lgen A Lattice-Based Candidate Set Generation Algorithm for I/O Efficient Association Rule Mining PAKDD 99 Beijing 1999 32 M J Zaki Scalable Algorithms for Association Mining IEEE Transactions on Knowledge and Data Engineering Vol 12 No 3 pp 372-390 May/June 2000 33 M. J. Zaki and C Hsiao CHARM An efficient algorithm for closed association rule mining RPI Technical Report 99-10 1999 KDD 1995: 150-155 1995 175-186 3~45-83 1996 452 



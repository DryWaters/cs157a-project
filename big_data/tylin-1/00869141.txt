Performance Evaluation of Distributed Algorithms for Mining Association Rules on Workstation Cluster Toniohiro Shiniomura and Susuniu Shibusawa Department of Computer and Information Sciences Faculty of Engineering Ibaraki University st960,388satsuki cis ibaraki ac jp sibusawaQcis ibaraki ac jp Abstract The mining of association rules is one of the database mining techniques used to extract useful in formation from large quantities of data Finding as sociation rules however requires that the transaction database be scanned 
repeatedly and we need to handle very large amounts of transaction data This requires an incredibly large amount of computation time There have therefore been many attempt.9 to speed-up database mining by using parallel computers Recent improve ments in the performance of PCs and workstations WSs and the recent dissemination of network tech nology have made parallel processing distributed within computer clusters an attractive alternative to parallel computers In this paper we describe two new algorithms effec tive for 
parallel processing distributed in a WS clu.9 ter environment One is an algorithm in which the size of data transmitted between WSs is smaller than that of the former algorithm The other is an algo rithm that reduces the number of scan processings at each node by dividing data and that uses shift opera tions for data communication We have implemented these algorithms on a WS cluster and have evaluated their performance 1 Introduction The amount 
of data accumulated by enterprises and individuals has recently become enormous This is a re sult of the development of such computer technologies as microprocessors storage devices and computer net works Database mining is one of the methods used to search large databases for useful information such as rules or previously unknown relations between data items One of the most important fields in database 0-7695-077 1 9/OO 10.00 0 2000 EEE mining is the discovery of 
association rules inferred from transaction databases An association rule im plies certain association relationships among sets of items and several algorithms for the mining of associ ation rules have been proposed\(1 2 3 Some of them are parallel algorithms used to process large quantities of data efficiently by distributing the processing among the nodes of parallel computers 14 5 61 On the other hand the performance of the proces sors in PCs and WSs has advanced 
rapidly and the prices of PCs and WSs has fallen Furthermore the dissemination of network technologies has also reduced the cost of using high-performance networks As a re sult parallel processing distributed among PC and WS clusters has become an attractive alternative to parallel computers This paper describes new distributed algorithms ef fective on WS clusters and evaluate their performance One is the Count Communication CC algorithm that transfers small amounts of data between nodes and uses 
broadcast operations The other is the Shift algo rithm which reduces the number of scan processings needed at each node by dividing data and which uses shift operations for data communication We also im plemented these algorithms on an SR2201 distributed memory parallel computer and compared their commu nication cost and search cost in that environment with the corresponding costs in the cluster environment The rest of the paper is organized as follows Section 2 gives an overview of the 
mining of association rules and of the Apriori algorithm on which our parallel algo rithms are based Section 3 describes an earlier nonpar titioned Apriori algorithm and also describes the CC and Shift algorithms Section 4 describes the experi mental environment and Section 5 presents the results of the performance measurements Section 6 discusses the experimental results and Section 7 concludes by very briefly summarizing its results and mentioning some future work we intend to do ourselves 361 


2 The mining of association rules Association rules show relationships between items or itemsets For example consider the following rule 221\221SO\221 of customers who purchase bread and butter also purchase milk.\222\222 This association rule may be used for actually digging up the combination pattern of pur chase items through an analysis of POS point-of-sales systems at retail stores The results of such an analysis can be used when planning advertisements the layout of items at various stores and so on Since association rules cannot be found without scanning the transaction database repeatedly the mining of association rules in curs a very high processing load and a large execution time 2.1 Association rules We first review some basic concepts of association rules here Let I  il i2    im be a set of items and let D  tl tz    tn be a set of transactions each of which consists of a set of items such that T E I We say each transaction T contains a set of items S if X I The itemset S has support s  s  support\(X  in the transaction set D if s of transactions in D contain X An association rule is an implication of the form S  Y where X\222 c I,E\222 c I and X-nl\222  Q Each rule has two measures of value support and confidence The support of rule X Y is support\(X U Y The confidence c of the rule X  Y in the transaction set D means c of transactions in D that contain X also contain Y That is SUppOTt\(X U E\222 Lpp0?.t\(X confidence\(X  Y x 100 1 When mining association rules we need to find all the rules that satisfy the user-specified minimum sup port and minimum confidence This can be decom posed into two subproblems Find all sets of items itemsets whose support is greater than the user-specified minimum support Itemsets which satisfy the minimum support are called large itemsets Generate from these itemsets the association rules whose confidence is greater than the user-specified minimum confidence 2.2 Apriori algorithm One of the algorithms most widely in the mining of association rules is the Apriori algorithm for finding all large itemsets l The first pass of the algorithm simply counts the number of item occurrences to deter mine the large itemsets having one item called large 1-itemsets A subsequent pass say pass k consists of two phases First the large itemsets found in the k  1 pass are used to generate candidate itemsets produced by combining of the large k  1 Then the database is scanned to determine the support of these candidate itemsets For all passes k  1 the algorithm works as follows 1 Generate the candidate k-itemsets using the large k  1\created at the end of pass k  1 2 Scan the transaction database and count the num ber of occurrences of the candidate k-itemsets and compute support 3 Let the large k-itemsets be candidate k-itemsets which satisfy the minimum support 4 The procedure terminates if the large itemset is empty Otherwise k  k  1 and go to step 1 3 Parallel algorithms 3.1 Former parallel algorithms Several researchers have proposed parallel algc rithms which execute the Apriori algorithm shown in Section 2.2 4 5 61 Assuming that transactions are evenly partitioned into each node in advance, these par allel algorithms use the following four steps to find the large itemsets 1 Each node generates the candidate k-itemsets by using the large k  1\created at the end of pass k  1 and copied into each node 2 Each node counts the number of occurrences of the candidate k-itemsets using its local transactions 3 All node\222s local counts are gathered merged and checked to determine whether or not the minimum support condition is satisfied 4 If large k-itemset is empty the algorithm termi nates Otherwise k  k 1 the large itemsets are copied into each node and go to step 2231.\224 Next we introduce the earlier non-partitioned Apri ori NPA algorithm which uses the notation in Table 1 In this algorithm the candidate itemsets are copied over all the nodes Each node counts the number of 362 


k-itemset Lk Ck Cl I j-th node 1 The local transaction datasets of the 03 An itemset having k items Set of all large k-itemsets Set of all candidate k-itemsets The local candidate E-itemsets of the Xi occurrences of itemsets using its local transactions and one node gets global counts and the large itemsets by merging local counts The processing of pass k is as follows j-th node The number of occurrences of the can didate k-itemsets at the i-th node Each node generates the candidate k-itemsets Cb by using the large k  1 L\(k-l created at the end of pass k  1 and copied into each node Each node counts the number Xk of occurrences of the candidate k-itemsets by scanning the local transactions All node's local counts are gathered merged and checked to determine whether or not the minimum support condition is satisfied Those for which the condition is satisfied are large k-itemsets Lk If large k-itemset Lh is empty the algorithm ter minates Otherwise k  k  1 the large itemsets are copied into each node and go to step 9 A problem with the algorithm is that the number of scans increases when there are many candidate item sets 3.2 Algorithms for cluster-based parallel dis tributed systems Since algorithms mining association rules process the mining of large itemsets from candidate itemsets they need to refer to large itemsets of the previous step frequently Therefore the search cost becomes very large And when this processing is executed in par allel the communication cost becomes very large The former NPA parallel algorithm reduces the communi cation cost by copying all of the large itemsets of the previous step into each node Then each node executes the same operation individually and generates candi date itemsets locally These algorithms are applicable to parallel comput ers whose communication between processors is fast Communication delay becomes a problem when they are executed on cluster-based parallel distributed sys tems where nodes are PCs or WSs connected via Eth ernet We developed two algorithms to reduce the com munication cost and evaluated them on a cluster-based environment 3.2.1 Count communication algorithm The Count Communication\(CC\algorithm does not broad cast the large itemsets to all the nodes but instead broadcasts the global counts because data size is smaller Each node has the large itemsets which sat isfy user-specified minimum support The processing of pass k in CC algorithm is as follows 1 Each node generates the candidate k-itemsets Ck by using the large k  1 L\(k-l created at the end of pass k  1 and copied into each node 2 Each node counts the number of occurrences of the candidate k-itemsets using its local transac tions 3 All node local counts are gathered and merged at one node and the global count Sk is broadcasted to all the other nodes 4 Each node checks to determine whether or not the candidate k-itemsets in Ck satisfy the user specified minimum support 5 If large k-itemset Lk is empty the algorithm ter minates Otherwise k  k  1 and go to step 1 candidate D  Figure 1 CC Algorithm 3.2.2 Shift algorithm When transmitting transac tion databases Shift algorithm does not execute broad cast operations but instead does shift operations The processing of pass k in Shift is as follows 363 


1 Each node generates the candidate k-itemsets Ci by using the large k  1 L\(k-1 created at the end of pass k  1 and the candidate k itemsets Ck are partitioned into each node 2 Each node counts the number Xi of occurrences of the candidate k-itemsets using its local trans actions and shifts the transaction database Dj to the next node The transactions transmitted from other nodes are executed similarly 3 After scanning all the transaction data each node determine individually whether or not the candi date k-itemsets C satisfy the user-specified mini mum support 4 If large k-itemset Lk is empty the algorithm termi nates Otherwise k  k 1 and the large itemsets are copied into each node and go to step 1 Table 2 Variables variable interpretation CAN Size of candidate itemsets Size of counts Number of transactions Number of nodes CC Algorithm This algorithm broadcasts only the counts There fore the amount of communication MFc in pass k is as follows Figure 2 Shift Algorithm 3.3 Cost analysis This section analyzes the communication cost and the search cost for the NPA CC and Shift algorithms 3.3.1 Communication cost analysis The com munication cost is the total amount of data which are transmitted among nodes in one pass of the mining of association rules NP.4 Algorithm This algorithm incurs communication costs when counts are merged and when the large itemsets are broadcasted The amount of communication Mrp4 in pass k is as follows ivIfP4  LARk X P  1  nk 2 This equation and the following equations in this subsection use the variables listed in Table 2 Shift Algorithm This algorithm transmits data when shifting all transaction data and merging counts The amount of communication in pass k is as follows Since the count size is less than the size of large item sets or the size of all transactions the amount of com munication iWF is smaller than L%f2p4 and Mfhift 3.3.2.Search cost analysis The search cost is the total amount of data which are searched at all nodes in one pass of the mining of association rules Paral lel algorithms generate candidate itemsets using large itemsets search the candidate itemsets in transaction databases and count the number of candidate item sets NPA Algorithm In this algorithm each node computes the all can didate itemsets and one node generates the large itemsets The search cost SrPA in pass k is as follows SFp4  c.4ivk X P f L.4Rk 5 CC Algorithm In this algorithm each node computes the all can didate itemsets and all nodes generate the large itemsets The search cost SEc in pass k is as fol lows sFc  C-AXk X P 4 L-4Rk X P  c.4Lvk f L.4Rk X P 6 364 


Shift Algorithm This algorithm computes the candidate itemsets partitioned into each node and one node generates large itemsets The search cost Sfhift in pass k is as follows CAXk q'ft  x P  L4Rk P  C-4iVk t L.4Rk  7 The search cost Szhif is smaller than SrP and S,Cc And because each node computes the all candi date itemsets and all nodes generate the large itemsets in CC algorithm SFc is greater than either ScPA or Sfhift Since each node executes the search processing at almost the same time the search cost does not show the computation time of each algorithm 4 Experiments 4.1 Experiment environments We implemented the NPA CC, and Shift algorithms on a WS cluster and on the parallel computer SR2201 WS cluster Our U'S cluster comprised thirty-two 5OOMHz Al pha 21164 WSs connected via a 100Mbps Ethernet LAN Parallel computer SR2201 The SR2201 is a distributed-memory parallel com puter which nodes are connected via high-speed three-dimensional crossbar switch networks We used a SR2201 with 16 nodes 4.2 Programming environments We implemented the algorithms by using C-based XIPI Message Passing Interface programming li braries The MPI was designed for efficient and re liable communication and it can be implemented on many platforms 4.3 Execution of parallel algorithms We used transaction datasets comprising 10000 transactions the average length of the transactions was 5 and the number of items was 50 With the similar ity of POS ID we used natural numbers as items of transactions The datasets were partitioned into each node In the experiments reported in this paper we varied the number of transactions the minimum support and the number of nodes The experiment was executed 10 times for a pair of fixed values of the number of transactions the minimum support and the number of nodes and the minimum execution time was reported 5 Performance evaluation 5.1. Relation between execution time and min imum support In Figure 3 the execution time of the three algo rithms is plotted against the minimum support These results were obtained on the WS cluster when the num ber of nodes was 8 and the number of transactions was 5000 It shows that when the minimum support is NPA __ cc   Shin  4.5 3 t 0 I 1 1.2 1.4 1.6 1.8 2 2.2 2.4 minimum suppott Figure 3 The execution time vs minimum support small, Shift algorithm is superior to NPA and CC algo rithms It also shows that when the minimum support is small the execution times for NPA and CC rapidly increases On the other hand the execution time for Shift does not increase as rapidly as do the execution times for NPA and CC 5.2 Relation between execution time and the number of transactions The execution time and the communication time for three algorithms are plotted against the number of transactions in Figure 4 These results were obtained on the U'S cluster when the number of nodes were 8 and the minimum support was 1 This figure also contains the exection time of a sequential algorithm The execution time for each parallel algorithm is plot ted in Figure 5 as a percentage of the execution time for the corresponding sequential algorithm Figure 4 365 


18 Number of nodes 2 4 8 Number of nodes 2 4 8 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 amount of transaction WS cluster NPA CC Shift 0.148 0.117 0.258 2.180 2.180 0.766 1.855 1.855 0.469 SR2201 0.369 0.356 0.889 0.385 0.385 1.114 0.378 0.378 0.842 Figure 4 The execution time and the commu nication time vs the number of transactions 3 140 160 i Shin  cc  i _  20 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 number of transactions Figure 5 The ratio of the execution time for each parallel algorithm to the execution time for corresponding sequential algorithm shows that the execution time and the communication time for all algorithms increase in proportion to the number of transactions The execution time for the Shift is shorter than those for the other algorithms The advantage of parallelization is evident when the number of transactions is more than 2500 Figure 5 shows that the ratio of the execution time of a parallel algorithm to that of a sequential algorithm decreases as the number of transactions increase 5.3 Relation between execution time and the number of nodes The execution time and the communication time of three parallel algorithms on the WS cluster when the number of transactions was 5000 and the minimum support was 1 are plotted in Figure 6 against the number of nodes For all algorithms the execution time 6 5 4 I3 _ E 2 1 0 2 4 8 16 32 number of nodes Figure 6 The execution time and the commu nication time vs the number of nodes decreases when the number of nodes increases, whereas the communication time increases when the number of nodes increases The performance of Shift algorithm is the best and there is little difference between the performances of the NPA and CC algorithms 5.4 Results on the parallel computer The execution time and the communication time of the three algorithms running on the parallel computer when the number of transactions was 5000 and the min imum support was 1 is plotted in Figure 7 against the number of nodes The communication times for three algorithms running on the 11's cluster and on the par allel computer are listed along with the numbers of nodes in Table 3 Table 3 shows that the communication times for NPA and CC algorithms are shorter on the parallel computer than they are in the WS cluster environment 366 


NPA  1 EO 1 number of nodes Figure 7 The execution time and the commu nication time on the SR2201 On the other hand, the communication time for Shift algorithms is shorter on the WS cluster than that on the SR2201 6 Discussions 6.1 Execution on a workstation cluster The execution times for NP.4 and CC algorithms increase rapidly with a decrease in the minimum sup port This is because the number of candidate itemsets increases when the minimum support decreases and these algorithms scan the all candidate itemsets in the transaction database at each node But because the Shift algorithm partitions the candidate itemsets into each node the execution time of scanning is shorter than that for the other algorithms and does not in crease as rapidly when the minimum support decreases The execution times for all algorithms increase with an increase in the number of transactions and the ra tio of the execution time of each parallel algorithm to the execution time of the corresponding sequential al gorithm decreases with an increase in the number of transactions This ratio for the Shift algorithm reaches a minimum value when the number of transactions is 4000 and the algorithm converges more rapidly than the other algorithms The execution times for all algorithms decreases with an increase in the number of nodes The re duction of the communication time in Shift operations seems to be due to the scanning processing and com munication processing being executed asynchronously Because data are searched in parallel and all amounts of searched data are almost the same for all these al gorithms CPU processing time which is the difference of the communication time from the execution time is almost the same for all algorithms Our cost analysis showed that the amount of com munication was smallest for the CC algorithms but the execution times for NPA and CC algorithms were almost the same in our experiments This seems to be because that the size of data used in our experiment is not so large 6.2 Execution on the parallel computer The execution times for all algorithms were much longer on the parallel computer than that were in the WS cluster environment We think this is because amount of CPU memory available on the parallel com puter was insufficient On the other hand the com munication time was more stable on the parallel com puter and the time for communication between nodes is shorter on the parallel computer In other words the ratio of the communication time to the execution time is large in a WS cluster environment and the commu nication time has a great influence on the execution time In the WS cluster environment the communication time for the Shift algorithm which uses shift opera tions is less than that for the CC algorithm which uses broadcast operations On the other hand, the commu nication time for the Shift algorithm on the parallel computer is lager than that for the CC algorithm The Shift algorithm is therefore effective in a LVS cluster environment that can execute shift operations rapidly 7 Conclusion The distributed algorithms proposed in this pa per are effective when parallel processing distributed throughout clustered computers is used to mine databases for association rules When we implemented these algorithms on a SVS cluster and on a parallel com puter so that we could evaluate their performance we found that the Shift algorithm was the most effective when there was a large number of candidate itemsets and processor nodes in the WS cluster environment This is because the ratio of communication time to ex ecution time is large in a WS cluster environment and the communication time therefore has a great influence on the execution time We intend to perform more analysis about the com munication cost between nodes We also intend to per form further experiments with large size data which are used at companies and institutes We also intend to develop a new algorithm to share the loads among nodes because real data are often distributed unevenly 367 


References 141 111 121 31 R Agrawd and R Srikant 223Fast Algorithms for Mining Association Rules,\224 Proc of Int\222l Conf on Very Large Data Bases pp.487-499 1994 R Srikant and R Agrawal 223hslining Generalized Asso ciation Rules,\224 Proc of Int\222l Conf on Very Large Data Bases pp.407-419 1995 N Megiddo and R Srikant 223Discovering Predictive As sociation Rules,\224 Proc ofthe 4th Int\222l Conf on Knowl edge Discovery an Databeses and Data Mining 1998 I51 161 E.H Han G Karypis and V Kuniar 223Scalable par allel data mining for association rules;\224 Proc of ACM SIGMOD Int\222l Conf pp.277-288 1997 T Shintani and M Kitsuregawa 223Iniplenientation of Parallel Mining Association Rules and their Evalua tion,\224 JSPP\22296 pp.97-104 June 1996 L Harada N Akaboshi K Ogihara and R Take 223Par allel Algorithm with Load Balancing for Mining Associ ation Rules,\224 IEZCE Trans on Info and Syst V-ol.J82 D-1 No.1 pp.70-81 January 1999 368 


In Figures 10 and 11 we see MAFIA is approximately four to five times faster than Depthproject on both the Connect-4 and Mushroom datasets for all support levels tested down to 10 support in Connect-4 and 0.1 in Mushroom For Connect-4 the increased efficiency of itemset generation and support counting in MAFIA versus Depthproject explains the improvement Connect 4 contains an order of magnitude more transactions than the other two datasets 67,557 transactions amplifying the MAFIA advantage in generation and counting For Mushroom the improvement is best explained by how often parent-equivalence pruning PEP holds especially for the lowest supports tested The dramatic effect PEP has on reducing the number of itemsets generated and counted is shown in Table 1 The entries in the table are the reduction factors due to PEP in the presence of all other pruning methods for the first eight levels of the tree The reduction factor is defined as  itemsets counted at depth k without PEP   itemsets counted at depth k with PEP In the first four levels Mushroom has the greatest reduction in number of itemsets generated and counted This leads to a much greater reduction in the overall search space than for the other datasets since the reduction is so great at highest levels of the tree In Figure 12 we see that MAFIA is only a factor of two better than Depthproject on the dataset Chess The extremely low number of transactions in Chess 3196 transactions and the small number of frequent 1-items at low supports only 54 at lowest tested support muted the factors that MAFIA relies on to improve over Depthproject Table 1 shows the reduction in itemsets using PEP for Chess was about an order of magnitude lower compared to the other two data sets for all depths To test the counting conjecture we ran an experiment that vertically scaled the Chess dataset and fixed the support at 50 This keeps the search space constant while varying only the generation and counting efficiency differences between MAFIA and Depthproject The result is shown in Figure 13 We notice both algorithms scale linearly with the database size but MAFIA is about five times faster than Depthproject Similar results were found for the other datasets as well Thus we see MAFIA scales very well with the number of transactions 5.3 Effects Of Compression To isolate the effect of the compression schema on performance experiments with varying rebuilding threshold values we conducted The most interesting result is on a scaled version of Connect-4, displayed in Figure 14 The Connect-4 dataset was scaled vertically three times so the total number of transactions is approximately 200,000 Three different values for rebuilding-threshold were used 0 corresponding to no compression 1 compression immediately and all subsequent operations performed on compressed bitmaps\and an optimized value determined empirically We see for higher supports above 40 compression has a negligible effect but at the lowest supports compression can be quite beneficial e.g at 10 support compression yields an improvement factor of 3.6 However the small difference between compressing immediately and finding an optimal compression point is not so easily explained The greatest savings here is only 11 at the lowest support of Conenct-4 tested We performed another experiment where the support was fixed and the Connect-4 dataset was scaled vertically The results appear in Figure 15 The x-axis shows the scale up factor while the y-axis displays the running times We can see that the optimal compression scales the best For many transactions \(over IO6 the optimal re/-threshold outperforms compressing everywhere by approximately 35 In any case both forms of compression scale much better than no compression Compression on Scaled ConnectAdata Compression Scaleup Connectldata ALL COMP 0 5 10 15 20 25 30 100 90 80 70 60 50 40 30 20 10 0 Min Support  Scaleup Factor Figure 14 Figure 15 45 1 


6 Conclusions We presented MAFIA an algorithm for finding maximal frequent itemsets Our experimental results demonstrate that MAFIA consistently outperforms Depthproject by a factor of three to five on average The breakdown of the algorithmic components showed parent-equivalence pruning and dynamic reordering were quite beneficial in reducing the search space while relative compressiodprojection of the vertical bitmaps dramatically cuts the cost of counting supports of itemsets and increases the vertical scalability of MAFIA Acknowledgements We thank Ramesh Agarwal and Charu Aggarwal for discussing Depthproject and giving us advise on its implementation We also thank Jayant R Haritsa for his insightful comments on the MAFIA algorithm and Jiawei Han for providing us the executable of the FP-Tree algorithm This research was partly supported by an IBM Faculty Development Award and by a grant from Microsoft Research References I R Agarwal C Aggarwal and V V V Prasad A Tree Projection Algorithm for Generation of Frequent Itemsets Journal of Parallel and Distributed Computing special issue on high performance data mining to appear 2000 2 R Agrawal T Imielinski and R Srikant Mining association rules between sets of items in large databases SIGMOD May 1993  R Agrawal R Srikant Fast Algorithms for Mining Association Rules Proc of the 20th Int Conference on Very Large Databases Santiago Chile, Sept 1994  R Agrawal H Mannila R Srikant H Toivonen and A 1 Verkamo Fast Discovery of Association Rules Advances in Knowledge Discovery and Data Mining Chapter 12 AAAVMIT Press 1995 5 C C Aggarwal P S Yu Mining Large Itemsets for Association Rules Data Engineering Bulletin 21 1 23-31 1 998 6 C C Aggarwal P S Yu Online Generation of Association Rules. ICDE 1998: 402-41 1 7 R J Bayardo Efficiently mining long patterns from databases SICMOD 1998: 85-93 8 R J Bayardo and R Agrawal Mining the Most Interesting Rules SIGKDD 1999 145-154 9 S Brin R Motwani J D Ullman and S Tsur Dynamic itemset counting and implication rules for market basket data SIGMOD Record ACM Special Interest Group on Management of Data 26\(2\1997 IO B Dunkel and N Soparkar Data Organization and access for efficient data mining ICDE 1999 l 11 V Ganti J E Gehrke and R Ramakrishnan DEMON Mining and Monitoring Evolving Data. ICDE 2000: 439-448  121 D Gunopulos H Mannila and S Saluja Discovering All Most Specific Sentences by Randomized Algorithms ICDT 1997: 215-229 I31 J Han J Pei and Y Yin Mining Frequent Pattems without Candidate Generation SIGMOD Conference 2000 1  12 I41 M Holsheimer M L Kersten H Mannila and H.Toivonen A Perspective on Databases and Data Mining I51 W Lee and S J Stolfo Data mining approaches for intrusion detection Proceedings of the 7th USENIX Securiry Symposium 1998 I61 D I Lin and Z M Kedem Pincer search A new algorithm for discovering the maximum frequent sets Proc of the 6th Int Conference on Extending Database Technology EDBT Valencia Spain 1998 17 J.-L Lin M.H Dunham Mining Association Rules: Anti Skew Algorithms ICDE 1998 486-493 IS B Mobasher N Jain E H Han and J Srivastava Web mining Pattem discovery from world wide web transactions Technical Report TR-96050 Department of Computer Science University of Minnesota, Minneapolis, 1996 19 J S Park M.-S Chen P S Yu An Effective Hash Based Algorithm for Mining Association Rules SIGMOD Conference 20 N Pasquier Y Bastide R Taouil and L Lakhal Discovering frequent closed itemsets for association rules ICDT 99 398-416, Jerusalem Israel January 1999 21 J Pei J Han and R Mao CLOSET An efficient algorithm for mining frequent closed itemsets Proc of ACM SIGMOD DMKD Workshop Dallas TX May 2000 22 R Rastogi and K Shim Mining Optimized Association Rules with Categorical and Numeric Attributes ICDE 1998 Orlando, Florida, February 1998 23 L Rigoutsos and A Floratos Combinatorial pattem discovery in biological sequences The Teiresias algorithm Bioinfomatics 14 1 1998 55-67 24 R Rymon Search through Systematic Set Enumeration Proc Of Third Int'l Conf On Principles of Knowledge Representation and Reasoning 539 550 I992 25 A Savasere E Omiecinski and S Navathe An efficient algorithm for mining association rules in large databases 21st VLDB Conference 1995 26 P Shenoy J R Haritsa S Sudarshan G Bhalotia M Bawa and D Shah: Turbo-charging Vertical Mining of Large Databases SIGMOD Conference 2000: 22-33 27 R Srikant R Agrawal Mining Generalized Association Rules VLDB 1995 407-419 28 H Toivonen Sampling Large Databases for Association Rules VLDB 1996 134-145 29 K Wang Y He J Han Mining Frequent Itemsets Using Support Constraints VLDB 2000 43-52 30 G I Webb OPUS An efficient admissible algorithm for unordered search Journal of Artificial Intelligence Research 31 L Yip K K Loo B Kao D Cheung and C.K Cheng Lgen A Lattice-Based Candidate Set Generation Algorithm for I/O Efficient Association Rule Mining PAKDD 99 Beijing 1999 32 M J Zaki Scalable Algorithms for Association Mining IEEE Transactions on Knowledge and Data Engineering Vol 12 No 3 pp 372-390 May/June 2000 33 M. J. Zaki and C Hsiao CHARM An efficient algorithm for closed association rule mining RPI Technical Report 99-10 1999 KDD 1995: 150-155 1995 175-186 3~45-83 1996 452 



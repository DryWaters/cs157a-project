PERFORMANCE EVALUATION OF A FUZZY DATA ASSOCIATION ALGORITHM FOR MULTITARGET TRACKING MTT SUN EILMIN N SUNDARARAJAN P SARATCHANDRAN School of Electrical  Electronic Eiigiiieer ing Nanyaiig Technological Universitv Singapore 639798 ABSTRACT In this paper a perfonnaiice coniparisoii of a recently developet1 fuzzy data association dgorithiii for Multi targot Tra.cking\(MTT\with the well kiiowii Joint Prob abilistic Data Associa.tion\( .JPDA algoritliiii is 
presented In this sclienic ii fiizzy logic iiiiiltiph. iiiotlels algorithm is const,riictetI first It uses tliffereiit txget iiiodels like coiist,ant vtdocity coiist,ant acceleration etc to de scribe all tlie st,at,rs of the svstein A Kalniaii filter is set up for eacli niotlel to t:st,inia.te t,lieir states The fiua.1 statme estiniate is a weiglitecl mcrage of the inodel contlitioiir:cI estiina.t,es with the fuzzy reasoning Based 011 t,liis 
a.lgorit1iiii an\(1 aftcr cmistructing the corre spoiidiiig rille set a fuzzy lata associa.tion algorithrn is tlcvcloperl wliicli iises full st?\\t,es prior knowledge and experience Tlie simulation scenario coiisiders both the fuzzy and JPDA algorithins for tracking two and four targc%s in it two tliiiieiisional setting Based on the siniiilat,ion resnlts tlie a.clvwt,wges aiid disaclvanta.ges of 1\t,hc i.pproa.c:lies for MTT are presented Keywords 
Multitarget Tracking Fuzzy System Kalriian Filkr Data Association 1 INTRODUCTION However since JPDA is based on Bayesian theory it is difficult to introduce full sta.tes and other prior knowl edge which can help solving the associatioii problem inore accurately Furtlierniore the number of possi ble hvpotheses t,hat associate different returns to the targets under consideration increase rapidly with t,he iiiiinbrr of ret,urns Also the presence of clutters 
in crease tlie complexity further Tlie complexity prob leni in JPDA/IMM is significant for a number of tar gets in moderately dense cliitt,er aiitl results in coiiibi natorial explosion of computations To solve some of the difficulties in the JPDA/IA/lAI a fuzzy logic approach for MTT was developed recentlg[-l In this inethod a fiizzy logic iniiltiple model algorithm is constructed to act as the filter In 
this algorithni the hlarkoviaii switching wliich is used in IMM is re placed by fuzzy rules Based 011 this algorithm and after constructiiig the corresponding rule set a fuzzy data association algorithii is developed which can use full states prior knowledge and experience This irn plies that in the fuzzy association algorithm we can not only use the observation states but also use other states which caii 
not be iiieasured In this pa.per it perforiiiance comparison between the fuzzy algorithm and JPDA/IMM algorithms using siiiiulatioii studies is highlighted Tlie simulation sce nario considers tlie two algorithns for tracking two ant1 four targets in a two dimensional setting Based on the siiiiulation results the advantages and disadvantages of both the appronclies for A4TT are discussed Tlie p;p is orga.niscd as follows 
Section 2 in t,rotluc:c:s th uiultiple iiiotlel algorithni lxised 011 fumy logic Sect,ion 3 prcsents the solution to data associa tion by in~~~i~iis of fuzzy reasoning Siniulatioii results are presciit.et1 iii section 4 wliicli compare the perfor iiiance of the these two algorithni Conchiding reiiiarks based on this study is summarized in section 5 0-7803-6262-4/00/$\22210.00 c 2000 IEEE 716 IL 


2 FUZZY MULTIPLE MODEL ALGORITHM For tracking multiple targets several models are pos tulated and a Kalman filter is set up for each model to estimate their states Final state estimate is a weighted average of the model-conditioned estimates with fuzzy reasoning Consider the state equation and measurement equa tion based on j  th model Z\(k  HXj\(k  V,\(k 2 where Xj\(k  j\(k k k is a 3 x 1 state vec tor Z\(k denotes the measurement sequence through time k Wj\(k is the white noise its covariance is Qj V k is Gaussian noise its covariance is R The initial state is assumed to be Gaussian and uncorrelated with the process and measurement noises.@j and H are the state transform and measurement matrices and they are assumed to be known In this paper H  lo 01 We use three models they are CV\(constant velocity 1T I 1 CA constant acceleration and adaptive CA mode1,which use the same state trans form matrix as CA model but it can change it's co variance Q3 at filtering process[5 Based on the j  th model the Kalman filter is given as follows Xj\(k  l/k  cPjX;\(k/k 3 rj\(k  1  Z\(k  1  HXj\(k  l/k residual 5 Kj\(k  1  Pj\(k  l/k k  1  7 Pj\(k  l/k  1  I  Kj\(k  l k  l/k 9 Where X:\(k/k P:\(k/k are the mixed initial con dition for model-matched filter j at time k Xj\(k/k Pj\(k/k are the state estimates and its covariance in mode-match filter j at time k X\(k/k P\(k/k are the combined state estimate and its covariance To get the weight of the j-th model with fuzzy rea soning we define two fuzzy sets Assuming there are m models,we define the universe U as U  1,2    nz At first we define fuzzy sets Ai\(i  1,2   nz as where we think the model j is valid At step k the model j's membership function is defined as  Q 1=J mEl otherwise where a E O,l  1,2    nz Next we define the fuzzy set B as that set where the model j\(j  1,2,.-.,m matches the measured track At step k the model j's membership function is defined as where Ci  cm I=1 p~%k\(l k-l l q\(k is residual vec tor which can get from the equation 5 The value of relates to covariance matrix of measurement noise The value of p~k\(j is adaptive by itself in the tacking process We can also choose other functions for p~k To make this clear,the above definition are illus trated for a case of 2 models,i  1,2 if there are 2 models then Xj\(k  l/k  1  Xj\(k  l/k  Kj\(k  l k  1 8 717 


Now the wliole fuzzy multiple niodel algorithiii is givcii by the following 4 steps Step 1 Use the fuzzy reasoniiig tjo get the mixed initial condit,ion for inodel-inat.cl~c.d filter j froni tlie coiitlitioii of last stq rule m If model 111 is valid,aiid matches the real move ments mode then P:\(X-/k  P,,,\(k/k  i.7,L\(k/k  2,0\(k/k i&,\(k/k  23k/k By reasoning we caii get P:\(k/k as follows Rule database 1 For the case of 2 models rule 1 If model 1 is valid,and inatclies the real move iiieiits iiiode then i.,O\(k/k  k/k rule 2 If model 2 is valid,and matches the real move ments inotle tllell y\(k/k  l\(k/k rule m If no del 111 is valid,and mat,ches tlie real iiiove nierlt,s 111otle then i?\(k/k  Z,,\(k/k By rexoning we caii get 2y\(k/k as follows For t.lic case of 2 niotlels Step 2 Filtering When we get P:\(k/k and i.,O\(k/k by using the rule database we introdnce them to each filter as tlie input Then we can start the filter Based on the j  th mo$el the filtering can obtain the state es timation X3 k  l/k  l calculating covariance P,\(k  l/k  1 Step 3 using the t?j\(k  l the pB\(kS1 is calcu lated with equation 2 P/\\&\(l LBk\(l  i,\(k/k P..l.>k\(l  P5k\(l  P.-l?k\(2  PBk\(2 i!\(k/k  bLA~li\(1  PBk\(1  PAzk\(2  PBk\(2 L/l,k\(2 LBk\(2 i..l\(k/k Step 4 Now we can get tlie output of the system as follows Firstly we define the rule datahe 3 and 4  Rule database 3 Rule database2 rule rule rule 1 if model 1 matches the real movements mode then X\(k  l/k  1  Xl\(k  l/k  1 t,lien X\(k  l/k  1  XZ\(k  I/~C  1 rule 2 if model 2 iiiatclies the real inoveiiients mode rule m if iiiotlt4 111 iiiatclies t.he real iiioveiiieiits inode tlIP11 k\(k  l/k  1  7,\(k  l/k  1 so 718 


Rule database 4 rule 1 if model 1 matches the real movements node then P\(k  l/k  1  PI k  l/k  1  XI k  l/k  1  X\(k  l/k  l  Xl k  l/k  1  X\(k  l/k  l 1p  1  X\(k  l/k  l  X2\(k  l/k  1  X\(k  l/k  1 rule 2 if model 2 matches the real movements mode then P\(k+l/k+l  P2\(k+l/k+l movements mode then P\(k+l/k+l  Pm\(k+l/k+l l  Xm\(k  l/k  1  X\(k  l/k  l 1  Xj\(k  l/k  1  X\(k  l/k  l  XJk  l/k  1  X\(k  l/k  1 then P\(k+l/k+l  g\(li+l j k+l/k The full fuzzy model algorithm is described in Fig ure 1 i=l i=2 1=3 Figure 1 THE FUZZY MULTIPLE MODEL ALGO RITHM 3 FUZZY ASSOCIATION ALGORITHM In the multiple target environment there are many radar returns Some of them belong to the existed tar gets, some belong to the new target and others belong to the false alarm So at first we must associate the correct radar returns with the correct target tracks then we can start the data association The state and measurement equation are the same as section 11 At first we calculate the mixed residual and resid ual covariance of the i measurements for target t using the following equation m Pt\(k/k 1  m PL"B\(k+,,\(j k  I Xj\(k/k  1  Xt\(k/k  l X'jt\(k/k  1  Xt\(k/k  1 j=1 vi k  zi k  HXt k/k  1 21 St\(k  HPt\(k/k  l  R 22 we will define the statist,ical distance pi between the ith measurement and the target t p k  I k k k 23 Then we define the fuzzy sets,At B C D At\(t  1,2   T  The current measurement Zi\(k is valid for target t It's membership function is where 7t  a27rm Bj is defined as that case when the statistical distance pi matches the real distance between the target t and the measurement Zi Its membership function is fBt\(zZ\(k  ex&p:\(k 25 Cj is defined as that case when the statistical velocity matches the real velocity between the target t and the measurement Zi Its membership function is fc,\(Zi\(k  ezp\(-IZi\(k  Xt\(k l/k  1 X"k  l/k  1  X"k  l/k  1 For D based on following 5 cases five fuzzy sets D1 D2, D3, D4 D5 are defined Case D1 if Zi\(k valid for only one target Case D2 if Zi\(k is valid for in targets,and for these m targets there is only one measurement like the IC and each of these m targets has one or more other measurements Case D3 if IC is valid for m targets and for these m targets there is only one target like the Zi\(k n targets of these have only this measurements Case D4 in Case C for the other targets Case D5 if there are 1 valid Zi\(k for m targets For fuzzy sets Dl,D2,D3,04,D5 their membership function is defined as follows 1 Case D1 Case D2 fD\(ZZ\(k  4 Case D3 Case D5 l/m  ym-l CseD4 Where a b is in 0 11 and a is larger than b Now we give the algorithm as follows 719 


1 Using tlie above estimator we get the prrtlictetl state it\(k/k  1  NP\(k/k  1 2 Calciilate tlie statistic distance to every target for all t11e nleJaSllrelllellt 3 Ca.lculate the residual vector of k for target t by it's inembership in every fuzzy set 4 For target t\(t  1 2  T calculate the residual vector V,\(k T is the number of all target where rnk is the number of observat,ion 5 For txget t if no observation is valid for it we define jA\(k  1 else k  0 then modify the update equation as follows P\(k/k  P\(k/k  I  P\(k k/k P'\(k/k   k k/k  1  f"\(k 1   k k k k 7121 P k kl m A UT Kt  i=l 4 PERFORMANCE EVALUATION STUD IES In this section a pcrforiiiance evaluation of the pro posed fuzzy dgoritliiii and tlie JPDA/IMM algorithms is presented using simulation studies Three cliffererit tracking sceiia.rios are considered for t,liis evaluation In tlie first scenazio two targets with tlie trajectories as in Fig are studied In scenario 2 for the same two t,iirgt>ts tlic tra,ject.ories are niatle close as in Fig.3 a.iit1 tlic pc~foriii;r.nce cwilu;i.t.ctf In the tliirtl and last sm nario 4 t,argct,s with tlicir trnject,ories as in Fig.4 are iiscd for waliiakioii In the IPDA/IMM a.lgorit1iin aiid also iii the fuzzy iiiult,iplc niotltd dgorithis tlirce estha.t,ors using Kaliiiaii filtcrs bascd 011 thee different models as givtm bclow are iistttl Tlie niodels are based on coiistaiit velocity CV constant, acceleration CA and adaptlive ccel tmition models In all cases only the position inea.sure iurnt is considerecl and tlie measurenlent iiiatrix H is of t,he form H  I 0 01 Also t,ht perforinance is evalu ated for bath low 01  0.5*0.001.42  0.2*0.001 heavy clutter density enviroii1nent.s c  5  0.001 Scenario 1 Figure 2 sliows the designed crossing targets tra jectory with the angle between t,lieni being 12 degree Measurement noise covariance R\(k is taken as 100ni Both the two targets have a constant acceleration  Figure 2 A Designed two Targets Trajectory Table 1 displays the computation time tJ Mean Error RIIE of position velocity and acceleration and also the Root Mean Square Error s\(RMSE In the IOW noise case the computatioiial time of the fuzzy ap proach\( with no prior knowledge has 5 improvement over the JPDA/IMM Also it's accuracy is slightly better When the noise becomes heavy the fuzzy ap proacli with no prior knowledge has a small improve ment Sine there are more false measurements now the performance improves when one uses prior knowledge In the case with prior knowledge the fuzzy algorithm is 20 faster than JPDA/IhdM with a 10 improvement in accuracy So for this scenario the fuzzy approach is obviously better tliaii JPDA/IMM Scenario 2 For this scenario the designed trajectories for the two closing targets are shown in Figure 3 Table 2 present the perforniance coin parisoii between fuzzy and JPDA algorithnis Based on tlie results in t,lie table it can be seen that for the low noise case tlie fuzzy a.pproach\(wit1i no prior knowletlg Iias about 13 iin proveinent in the computation t,iiiic  Thc accuracy of the fimy also is bctter t,han JPDA/IMM by about 7 Wlien tlie noise becoiiies heavv t,he fiizzy approach no prior knowledge\shows a better performance It is faster than JPDA/IMR/I by 4 ut1 more accurate tliaii JPDA/IMM by 11 Meanwhile if we use prior knowledge it is faster than JPDA/IMM by 11 and 


more accurate by 13 Hence in this case also the fuzzy approach gives a better performance especially with prior knowledge This implies that when there are more clutter if we can have a good prior knowledge to delete some false measurement we call get a better performance than JPDA/IMM with a short computa tion time TiW4 Figure 3 The two closing targets trajectory Scenario 3 For the case of four targets with trajectories as in Fig 4 the tables 3 show the computation time and measurement errors For this case from Table 3 it can be seen that the fuzzy approach\(n0 prior knowledge has 22 improvement in computation time with sini ilar accuracy of JPDA/IMM But for this case when we use prior knowledge the performance of fuzzy ap proach is worse than that without prior knowledge though it is still better than JPDA/IMM The rea son for this is tha.t in this case it\222s difficult to get a good knowledge about the target movement and hence it costs more in computation time to judge the false measurement But this can not delete more false mea surements efficiently 5 CONCLUSION In this paper a new data association method based on fuzzy logic for multi target tracking is presented briefly Then we study the performance of the pro posed fuzzy algorithm under different tracking scenar ios and compare its performance with the well known JPDA/IMM algorithm Based on the results it can be seen that since the proposed method uses fuzzy rules One gets a better performance and also with a reduc tion in computation time if the prior information is correct. From the simulation studies it is evident that using fuzzy logic in the problem of multitarget track ing is good because it is faster than JPDA/IMM with similar accuracies of JPDA/IMM 6 REFERENCES l Bar-Shalom Y and Fortmann,T.E 223Tracking and Data Association\224  San Diego CA Academic Press 1988 2 Bar-Shalom,Y.,and Blom,H.A.P.,\224 The Interact ing Multiple Model Algorithm for Systems with Markovian Switching Coefficients\224 IEEE Trans Auto ControZ,August 1988,AC-33,\(8 3 Fortmann T E Bar-Shalom Y Scheffe M., \224Mul titarget Tracking Using Joint Probabilistic Data Association,\224 Proceedings of 19th IEEE Confer ence on Decision and Control,l980 pp.807-812 4 Sun Ermin N Sundararajan P Saratchandran 223A Fuzzy Data Association Algorithm for Mul titarget Tracking\224 Proc of the IASTED Con ference INTELLIGENT SYSTEMS AND CON TROL Santa Barbara CA Oct 1999 pp 358 363 J x bl d 1 6 8 to 12 I4 DL Figure 4 The designed four targets trajectory 72 1 


J P D A  INi I Fiizzv LDD~~~~\(IIO r knowletlrre Y 2 I  I 1 I I I I Fwzy approach\(ase prior knowledge I 0.93 I 47.1466 I 23.0605 I 4.3040 I 55.0092 I 29.0196 I 5.4095 Heavv clutter density:O8 tc\(s RlE RRlSE 0.99 46.7850 24.7152 4.8812 56.2047 30.2474 6.1732 0.94 47.1758 23.0776 4.3086 56.0614 29.0778 5.4115 position velocity a.cceleration range velocity a.cceleratioii I I t,.\(s I ME RMSE I JPDA/IMM Fiizzy approaoh\(no prior knowledge Fiizzy appro:di\(iise prior kiiowledge  I position velocity acceleration range velocity acceleration 2.97 49.7531 2G.193G 4.7523 61.2427 31.2217 5.8483 2.8 46.4865 23.2966 4.0272 55.6216 28.4997 5.1521 2.3 44.8416 22.7543 3.8979 55.0781 27.8942 4.9742 Talde 2 Perforniaiicc rctsiilts of the two closiiig targets t,rajc:ctory  Sccnario 2 I Low clutter tleiisitv:Z,2 1 tc\(s JPDAIIRIM 0.88 Fuzzy approach\(i1o prior knowledge 0.77 Fuzzy approach iise prior knowledge 0.77 hl E RPvISE positioii velocity acceleratioii range velocity acceleration 45.9345 22.9096 6.1831 54.2089 27.1368 7.5803 42.6891 20.2555 5.2934 51.0272 24.0387 6.7836 42.6863 20.2535 45.2927 51.0242 24.0362 6.7830 I I   VI Fuzzy approach\(iise prior knowledge I 1.32 I 38.7124 I 17.2556 I 4.6226 I 47.1013 I 20.5742 1 6.1345 JPDA IniIil4 Tahltl 3 Perforinaiiw rcsiilts of the four targets tra jcxtory  Sccuario 3 Low clutter t1ensity:Q 1 ME RRlSE tc\(s  LIE RMSE 1.49 44.4631 I 19.2321 I 5.4672 I 53.7401 I 22.5871 I G.7661 position I velocity I acceleration I range I velocity I acceleration IPDAjlhlhI Fiizzy ppro;dl\(l~o prior kiiowledge Fiizxy approach its prior kiiowlt.tlgc 722 Y 9.61 40.7579 17.5418 3.3000 51.2755 22.3194 3.57133 7.47 40.5722 17.5955 2.3882 51.2046 22.3905 3.6687 7.80 40.7402 17.4981 2.2520 50.9210 22.1230 3.2879 


 001 034\001 f\017\016\003\b\007\005\017\013\001 A?\001 2\021\005\036\005\026!\001 004\017\030\026\037\b\004\016\001 b\004\001 027\\035\004\026\006\006\005\021 \001 020\b\036\007\037\017\004\026\001 020\r"\006\024\006\007\026\030\001 002\023\017\006\006\005\036\005\032\017\007\005\b\021\001 t\026\032\003\021\005:\r\026\006B\013\001 B\n\r\005\b\004$\t n\013\t 023%\034\006\002\007\034\t 004\b&\t 023\n\013\006#\004\005\002\017\t I\b\023\034\001 86\013\001 E\b\001 8\013\001 035\017 \026\006\001 8%\001 034\001 8 001 020\034\001=\017\021\032\b\004\005!\005\006\013\001@\034\001\020\034\001=\005\007\032\003\026\023\023\013\001\002\034\001D\b\004\004\026\006\013\001O\034\001\002\003\026\021\001\017\021!\001\027\034\001 D\034\001 017\021\006\021\026\004\013\001 A2\006\005\021 \001 r\007\b\030\017\007\005\032\001 002\023\r\006\007\026\004\005\021 \001 007\b\001 022\004\b!\r\032\026\001 5\005 \003.\f\026#\026\023\001\020\024\006\007\026\030\001F\004 \017\021\005\006\017\007\005\b\021\006\001\b\036\001\020\b\r\004\032\026\001\002\b!\026B\013\001 025\005\n\032 035 006\033 t t n\005-\034\033\n\003\t 025\005\n"\005\004\007\t 020\b&\002\005\034\006\004\b&\016\b"\t 3<C\022\002\001 74\013\001 027\027\027\001\002\b\030\035\034\001\020\b\032\034\001\022\004\026\006\006\013\001%//7\013\001\035\035\034\0011+.+8\034\001 1 001 034\001 I\b\021\001 017\024\004\003\017\r\006\026\004\001 017\021!\001 034=\034\001 I\017\021\006\013\001 025\005\n"\005\004\007\t 020\b&\002\005\034\006\004\b&\016\b"\t C\t t 023\r\005'\002 013\001 t\026\032\003\021\005\032\017\023\001 D\026\035\b\004\007\001 002\020./1.%*,\013\001 026\035\007\034\001 b\036\001 002\b\030\035\r\007\026\004\001 020\032\005\026\021\032\026\013\001 002\b\023\023\b\004\017!\b\001 020\007\017\007\026\001 2\021\005#\026\004\006\005\007\024\013\001 r \r\006\007\001%//1\034\001  001 t\034=\034\001 022\005 \b\006\016\005\013\001 025\005\004\032\006\016\032\004$\t 023\n\013\006#\004\005\002\t 021\004\016\b\006\002\b\004\b\032\0028\t 027\002\034\006\t 025\005\004\032\006\016\032\002\034\t 013\n\005\t 021\004\b\004"\016\b"\t n\r\005\t 023\n\013\006#\004\005\002\t\022\b'\002\034\006\007\002\b\006 013\001C\005\023\026\024\001 002\b\030\035\r\007\026\004\001\022\r"\023\005\006\003\005\021 \013\001%//6\034\001 6 001 M\034\001 017\004\007\005\035\005\013\001 M\034\001 M\b\021\007\b \005\017\021\021\005\006\001 017\021!\001 034\001 017#\017!!\017\007\013\001 H?\004\032\003\005\007\026\032\007\r\004\017\023\001 026\006\005 \021\001 D\026\032\b#\026\004\024\001 2\006\005\021 \001 017\007\017\001 005\021\005\021 \001 t\026\032\003\021\005:\r\026\0060\013 t t b&\t r\005\n\003\002\004\b\t n\005-\016\b"\t f\n\b\013 023\n\013\006#\004\005\002\t 021\004\016\b\006\002\b\004\b\032\002\t 002\002\b"\016\b\002\002\005\016\b"\t 3\002\020=D\001 4\013\001 027\027\027\001\002\b\030\035\034\001\020\b\032\034\001\022\004\026\006\006\013\001*,,,\013\001\035\035\034\001%*/.%1,\034\001  001 034\001 020\b\030\030\026\004#\005\023\023\026\013\001 023\n\013\006#\004\005\002\t b"\016\b\002\002\005\016\b 013\001 6\007\003\001 026!\005\007\005\b\021\013\001 5\017\004\023\b\037\013\001?!!\005\006\b\021.C\026\006\023\026\024\013\001*,,%\034\001 7 001 034\001 t\005\035\013\001 K?\001 020\r\004#\026\024\001 b\036\001 022\004\b \004\017\030\001 020\023\005\032\005\021 \001 t\026\032\003\021\005:\r\026\006K\013\001 t\026\032\003\021\005\032\017\023\001 D\026\035\b\004\007\001 002\020.D/187\013\001 002\026\021\007\004\r\030\001 b\b\004\001C\005\006\016\r\021!\026\001\026\021\001 021\036\b\004\030\017\007\005\032\017\013\001?\030\006\007\026\004!\017\030\013\001%//1\034\001  001 002\034\001 t\n\b\004\007\n\005\006\013\001 E\034\001 b\023!\013\001 022\034J\034\001 f\017\024\025\026\023\023\001 017\021!\001 M\034\001 026\021\021\026\007\007\013\001 A\(\004\b\030\001 020\024\006\007\026\030\001 002\b\030\035\004\026\003\026\021\006\005\b\021\001 007\b\001 022\004\b \004\017\030\001 002\b\030\035\004\026\003\026\021\006\005\b\021B\013\001 025\005\n\032 022,,,\t 035\006\033\t 022\b\0063$\t f\n\007\003\r\006\002\005\t 023\n\013\006#\004\005\002\t 003\003$\016\032\004\006\016\n\b\034\t f\n\b\013 0013\002F=\022\020?\002\001,*4\013\001<\027\027\027\001\002\b\030\035\034\001\020\b\032\034\001\022\004\026\006\006\013\001*,,*\013\001\035\035\034\001 1*&.18*\034\001  001 b\004\007\n\005\006\001\017\021!\001\022\034J\034\001\f\017\024\025\026\023\023\013\001A2\006\005\021 \001;\017\007\017\001=\005\021\005\021 \001\007\b\001?\006\006\026\006\006\001 026\001 D\026\023\005\017"\005\023\005\007\024B\013\001 023\r\003\003 025\005\n\032 022,,,\t 037;\006\033\t 022\b\0063$\t 023%\007\003\n\034\016\r\007\t 023\n\013\006#\004\005\002\t 002$\016\004\(\016$\016\006%\t b"\016\b\002\002\005\016\b 001 3<\020\020D\027*,,%4\013\001<\027\027\027\001\002\b\030\035\034\001\020\b\032\034\001\022\004\026\006\006\013\001*,,%\013\001\035\035\034\001**%.**8\034\001  001 002\034\001 t\n\b\004\007\n\005\006\001 017\021!\001 022\034J\034\001 f\017\024\025\026\023\023\013\001 A\027\\035\026\004\007\001 017\005\021\007\017\005\021\026\004\0060\001 020\007\004\017\007\026 \005\026\006\001 017\021!\001 E\026\026!\006\001 037\003\026\021\001 2\021!\026\004\006\007\017\021!\005\021 \001 020\b\036\007\037\017\004\026\031\001 001 P\r\017\023\005\007\017\007\005#\026\001\027\030\035\005\004\005\032\017\023\001\020\007\r!\024B\013\001 025\005\n\032\\022,,,\t\031\006\033\t*\034\016\0044\025\004\032\016\013\016\032\t 023\n\013\006#\004\005\002\t,\b"\016\b\002\002\005\016\b"\t\f\n\b\013 0013?\022\020\027\002\001*,,%4\013\001<\027\027\027\001\002\b\030\035\034\001 020\b\032\034\001\022\004\026\006\006\013\001*,,%\013\001\035\035\034\001*7%.*7&\034\001  001 5\034\001\t\b\005#\b\021\026\021\013\001A\020\017\030\035\023\005\021 \001\f\017\004 \026\001;\017\007\017"\017\006\026\006\001\036\b\004\001?\006\006\b\032\005\017\007\005\b\021\001 D\r\023\026\006B\013\001 025\005\n\032  b t 022\b\0063$\t f\n\b\013 002\005%\t 004\005"\002\t 001\004\006\004\(\004\034\002\034\t 3I\f;@\001/64\013\001%//6\013\001\035\035\034\001%81.%1+\034\001 8 001 I\034\001\t\025\026\004\035\b\006\001\017\021!\001D\034\0015\b\023\007\013\001A\020\b\036\007\037\017\004\026\001@\b\007\004\024\b\023\b \024\031\001?\r\007\b\030\017\007\005\032\001 002\023\r\006\007\026\004\005\021 \001\b\036\001\020\b\036\007\037\017\004\026\001\020\024\006\007\026\030\006B\013\001 025\005\n\032\D 006\033 t\022\b\0063$\t@\n\005-\034\033\n\003\t 001\004\006\004\(\004\034\002\t,\030\003\002\005\006\t\023%\034\006\002\007\034\t*\003\003$\016\032\004\006\016\n\b\034 0013;\027Q?\001/74\013\001<\027\027\027\001 002\b\030\035\034\001\020\b\032\034\001\022\004\026\006\006\013\001%//7\013\001\035\035\034\0017%%.7%7\034\001 1 001 t\034\001 034\001 C\005  \026\004\007\006\013\001 A2\006\005\021 \001 002\023\r\006\007\026\004\005\021 \001 023 \b\004\005\007\003\030\006\001 005\021\001 f\026 \017\032\024\001 020\024\006\007\026\030\006\001 D\026\030\b!\r\023\017\004\005\025\017\007\005\b\021B\013\001 025\005\n\032 E\006\033\t n\005-\016\b"\t f\n\b\013 002'\002\005\034\002\t b"\016\b\002\002\005\016\b"\t 3C\002D\027\001 4\013\001 027\027\027\001 002\b\030\035\034\001 020\b\032\034\001 022\004\026\006\006\013\001%//&\013\001\035\035\034\00188.18\034\001  001 034J\034\001R\017\016\005\013\001\020\034\001\022\017\004\007\003\017\006\017\004\017\007\003\024\013\001=\034\001F \005\003\017\004\017\001\017\021!\001C\034\001\f\005\013\001AE\026\037\001 023 \b\004\005\007\003\030\006\001 001 017\006\007\001 005\006\032\b#\026\004\024\001 b\036\001 006\006\b\032\005\017\007\005\b\021\001 D\r\023\026\006B\013\001 025\005\n\032 n\013\t 006\033\002\t 9 005 t 022\b\0063$\t f\n\b\013 b\n#$\002&"\002\t 001\016\034\032\n'\002\005%\t 001\004\006\004\(\004\034\002\034\t\004\b&\t\001\004\006\004\t\021\016\b\016\b 013\001%//&\013\001\035\035\034\001*78.*76\034\001 001 Proceedings of the 11 th IEEE International Workshop on Program Comprehension \(IWPC\22203 1092-8138/03 $17.00 \251 2003 IEEE 


FIGURE 5 Execution time and rules returned versus minimum coverage for the various algorithms FIGURE 6 Execution time of dense_0002 as minconf is varied for both data-sets. Minimum coverage is fixed at 5% on pums and 1% on connect-4 FIGURE 7 Maximum confidence rule mined from each data-set for a given level of minimum coverage   1 10 100 1000 10000 100000 0 10 20 30 40 50 60 70 80 90 Execution time \(sec Minimum Coverage connect-4 apriori_c  dense_0002   dense_002   dense_02    1 10 100 1000 10000 100000 1e+06 0 10 20 30 40 50 60 70 80 90 Number of Rules Minimum Coverage connect-4 apriori_c  dense_0002   dense_002   dense_02    1 10 100 1000 10000 100000 0 10 20 30 40 50 60 70 80 90 Execution Time \(sec Minimum Coverage pums apriori_c  dense_0002   dense_002   dense_02    1 10 100 1000 10000 100000 1e+06 1e+07 0 10 20 30 40 50 60 70 80 90 Number of Rules Minimum Coverage pums apriori_c  dense_0002   dense_002   dense_02    0 500 1000 1500 2000 2500 3000 3500 20 25 30 35 40 45 50 55 60 65 Execution time \(sec minconf pums  connect-4  1 10 100 1000 10000 100000 1e+06 20 25 30 35 40 45 50 55 60 65 Number of Rules minconf pums  connect-4    0 10 20 30 40 50 60 70 80 90 100 0 10 20 30 40 50 60 70 80 90 100 Highest Rule Confidence Minimum Coverage pums  connect-4 


8.2  Effects of minimum confidence The next experiment \(Figure 6\ws the effect of varying minconf while fixing minimp and minsup to very low values. With connect-4, we used a minimum coverage of 1%, and with pums, a minimum coverage of 5%. Minimp was set to .0002 with both data-sets. As can be extrapolated from the previous figures, the number of rules meeting these weak minimp and minsup constraints would be enormous As a result, with these constraints alone, Dense-Miner exceeds the available memory of our machine The efficiency of Dense-Miner when minimum confidence is specified shows that it is effectively exploiting the confidence constraint to prune the set of rules explored. We were unable to use lower settings of minconf than those plotted because of the large number of rules. As minconf is increased beyond the point at which fewer than 100,000 rules are returned, the run-time of Dense-Miner rapidly falls to around 500 seconds on both data-sets 8.3  Summary of experimental findings These experiments demonstrate that Dense-Miner, in contrast to approaches based on finding frequent itemsets achieves good performance on highly dense data even when the input constraints are set conservatively. Minsup can be set low \(which is necessary to find high confidence rules as can minimp and minconf \(if it is set at all\This characteristic of our algorithm is important for the end-user who may not know how to set these parameters properly. Low default values can be automatically specified by the system so that all potentially useful rules are produced. Refinements of the default settings can then be made by the user to tailor this result. In general, the execution time required by Dense-Miner correlates strongly with the number of rules that satisfy all of the specified constraints 9.     Conclusions We have shown how Dense-Miner exploits rule constraints to efficiently mine consequent-constrained rules from large and dense data-sets, even at low supports. Unlike previous approaches, Dense-Miner exploits constraints such as minimum confidence \(or alternatively, minimum lift or conviction\ and a new constraint called minimum improvement during the mining phase. The minimum improvement constraint prunes any rule that does not offer a significant predictive advantage over its proper sub-rules. This increases efficiency of the algorithm, but more importantly it presents the user with a concise set of predictive rules that are easy to comprehend because every condition of each rule strongly contributes to its predictive ability The primary contribution of Dense-Miner with respect to its implementation is its search-space pruning strategy which consists of the three critical components: \(1\functions that allow the algorithm to flexibly compute bounds on confidence, improvement, and support of any rule derivable from a given node in the search tree; \(2\proaches for reusing support information gathered during previous database passes within these functions to allow pruning of nodes before they are processed; and \(3\ item-ordering heuristic that ensures there are plenty of pruning opportunities. In principle, these ideas can be retargeted to exploit other constraints in place of or in addition to those already described We lastly described a rule post-processor that DenseMiner uses to fully enforce the minimum improvement constraint. This post-processor is useful on its own for determining the improvement value of every rule in an arbitrary set of rules, as well as associating with each rule its proper sub-rule with the highest confidence. Improvement can then be used to rank the rules, and the sub-rules used to potentially simplify, generalize, and improve the predictive ability of the original rule set References 1 w a l  R.; Im ie lin ski  T   a n d S w a m i, A. 1 9 9 3   M i n i ng As so ciations between Sets of Items in Massive Databases. In Proc of the 1993 ACM-SIGMOD Int\222l Conf. on Management of Data 207-216 2 raw a l R.; M a n n ila, H Sri k an t  R T o i v o n en  H.; an d  Verkamo, A. I. 1996. Fast Discovery of Association Rules. In Advances in Knowledge Discovery and Data Mining AAAI Press, 307-328 3 K Ma ng a n a r is S a n d Sri k a n t, R 19 97  P a rtia l Cl a ssif i cation using Association Rules. In Proc. of the 3rd Int'l Conference on Knowledge Discovery in Databases and Data Mining 115-118 4 a rd o  R. J 1 9 9 8  Ef f i c i en tly Min i n g  Lo n g  P a ttern s fro m  Databases. In Proc. of the 1998 ACM-SIGMOD Int\222l Conf. on Management of Data 85-93 5  Mi c h ae l J. A a n d  Lin o f f G  S 1 9 9 7  Data Mining Techniques for Marketing, Sales and Customer Support John Wiley & Sons, Inc 6 Bri n, S  M o t w a n i, R.; Ullm a n J.; a n d  Tsu r S. 19 9 7 Dyn a m i c  Itemset Counting and Implication Rules for Market Basket Data. In Proc. of the 1997 ACM-SIGMOD Int\222l Conf. on the Management of Data 255-264 7 h e n  W   W   1 9 9 5 F a st Ef fecti v e Ru le In d u ctio n   In  Proc. of the 12th Int\222l Conf. on Machine Learning 115-123 8 In tern atio n a l Bu sin e s s Mac h in e s   1 9 9 6  IBM Intelligent Miner User\222s Guide Version 1, Release 1 9 m e t tin e n M   Ma nn ila  P  Ro nk a i ne n  P   a n d V e rk a m o  A  I. 1994. Finding Interesting Rules from Large Sets of Discovered Association Rules. In Proc. of the Third Int\222l Conf. on Information and Knowledge Management 401-407 10  Ng   R  T    L a k s hm ana n   V   S    Ha n  J   an d P a ng A  1 9 9 8   Exploratory Mining and Pruning Optimizations of Constrained Association Rules. In Proc of the 1998 ACM-SIGMOD Int\222l Conf. on the Management of Data 13-24 11 Ry mo n  R 1 9 9 2   Search  t h ro u g h Sy s t e m atic S e t En u m era tion. In Proc. of Third Int\222l Conf. on Principles of Knowledge Representation and Reasoning 539-550 1  Sha f e r  J  A g r a w a l R   an d Me ht a M 19 98  SPR I N T   A  Scalable Parallel Classifier for Data-Mining. In Proc. of the 22nd Conf. on Very Large Data-Bases 544-555 13  S m y t he P  and  Go od man   R  M 19 92 An I n f o r m at i o n Th eo retic Approach to Rule Induction from Databases IEEE Transactions on Knowledge and Data Engineering 4\(4\:301316 14  S r i k a n t   R    V u  Q an d Ag r a w a l  R  19 97 M i ni ng  A ssoc i a tion Rules with Item Constraints. In Proc. of the Third Int'l Conf. on Knowledge Discovery in Databases and Data Mining 67-73 15 W e bb, G. I 1 9 9 5 OP U S An Ef f i c i e n t Adm i ssible Algo rit h m for Unordered Search. In Journal of Artificial Intelligence Research 3:431-465 


It can also be added to cell CrossSales.3\(PC, printer one_year,\205 5  Distributed and Incremental Rule Mining There exist two ways to deal with association rules 267  Static that is, to extract a group of rules from a snapshot, or a history, of data and use "as is 267  Dynamic that is, to evolve rules from time to time using newly available data We mine association rules from an e-commerce data warehouse holding transaction data. The data flows in continuously and is processed daily Mining association rules dynamically has the following benefits 267  223Real-time\224 data mining, that is, the rules are drawn from the latest transactions for reflecting the current commercial trends 267  Multilevel knowledge abstraction, which requires summarizing multiple partial results. For example association rules on the month or year basis cannot be concluded from daily mining results. In fact multilevel mining is incremental in nature 267  For scalability, incremental and distributed mining has become a practical choice Figure 3: Distributed rule mining Incremental association rule mining requires combining partial results. It is easy to see that the confidence and support of multiple rules may not be combined directly. This is why we treat them as \223views\224 and only maintain the association cube, the population cube and the base cube that can be updated from each new copy of volume cube. Below, we discuss several cases to show how a GDOS can mine association rules by incorporating the partial results computed at LDOSs 267  The first case is to sum up volume-cubes generated at multiple LDOSs. Let C v,i be the volume-cube generated at LDOS i The volume-cube generated at the GDOS by combining the volume-cubes fed from these LDOSs is 345   n i i v v C C 1  The association rules are then generated at the GDOS from the centralized C v  214  The second case is to mine local rules with distinct bases at participating LDOSs, resulting in a local association cube C a,I a local population cube C p,I  and a local base cube C b,i at each LDOS. At the GDOS, multiple association cubes, population cubes and base cubes sent from the LDOSs are simply combined, resulting in a summarized association cube and a summarized population cube, as 345   n i i a a C C 1   345   n i i p p C C 1  and 345   n i i b b C C 1  The corresponding confidence cube and support cube can then be derived as described earlier. Cross-sale association rules generated from distinct customers belong to this case In general, it is inappropriate to directly combine association cubes that cover areas a 1 205, a k to cover a larger area a In the given example, this is because association cubes record counts of customers that satisfy   customer product merchant time area Doe TV Dept Store 98Q1 California Doe VCR Dept Store 98Q1 California customer product merchant time area Doe VCR Sears 5-Feb-98 San Francisco Joe PC OfficeMax 7-Feb-98 San Francisco customer product merchant time area Doe TV Fry's 3-Jan-98 San Jose Smith Radio Kmart 14-Jan-98 San Jose Association   population      base          confidence      support cube               cube                cube         cube                cube LDOS LDOS GDOS 


the association condition, and the sets of customers contained in a 1 205, a k are not mutually disjoint. This can be seen in the following examples 214  A customer who bought A and B in both San Jose and San Francisco which are covered by different LDOSs , contributes a count to the rule covering each city, but has only one count, not two, for the rule A  336  B covering California 214  A customer \(e.g. Doe in Figure 3\who bought a TV in San Jose, but a VCR in San Francisco, is not countable for the cross-sale association rule TV  336 VCR covering any of these cities, but countable for the rule covering California. This is illustrated in Figure 3 6  Conclusions In order to scale-up association rule mining in ecommerce, we have developed a distributed and cooperative data-warehouse/OLAP infrastructure. This infrastructure allows us to generate association rules with enhanced expressive power, by combining information of discrete commercial activities from different geographic areas, different merchants and over different time periods. In this paper we have introduced scoped association rules  association rules with conjoint items and functional association rules as useful extensions to association rules The proposed infrastructure has been designed and prototyped at HP Labs to support business intelligence applications in e-commerce. Our preliminary results validate the scalability and maintainability of this infrastructure, and the power of the enhanced multilevel and multidimensional association rules. In this paper we did not discuss privacy control in customer profiling However, we did address this issue in our design by incorporating support for the P3P protocol [1 i n  ou r data warehouse. We plan to integrate this framework with a commercial e-commerce system References 1  Sameet Agarwal, Rakesh Agrawal, Prasad Deshpande Ashish Gupta, Jeffrey F. Naughton, Raghu Ramakrishnan, Sunita Sarawagi, "On the Computation of Multidimensional Aggregates", 506-521, Proc. VLDB'96 1996 2  Surajit Chaudhuri and Umesh Dayal, \223An Overview of Data Warehousing and OLAP Technology\224, SIGMOD Record Vol \(26\ No \(1\ 1996 3  Qiming Chen, Umesh Dayal, Meichun Hsu 223 OLAPbased Scalable Profiling of Customer Behavior\224, Proc. Of 1 st International Conference on Data Warehousing and Knowledge Discovery \(DAWAK99\, 1999, Italy 4  Hector Garcia-Molina, Wilburt Labio, Jun Yang Expiring Data in a Warehouse", Proc. VLDB'98, 1998 5  J. Han, S. Chee, and J. Y. Chiang, "Issues for On-Line Analytical Mining of Data Warehouses", SIGMOD'98 Workshop on Research Issues on Data Mining and Knowledge Discovery \(DMKD'98\ , USA, 1998 6  J. Han, "OLAP Mining: An Integration of OLAP with Data Mining", Proc. IFIP Conference on Data Semantics DS-7\, Switzerland, 1997 7  Raymond T. Ng, Laks V.S. Lakshmanan, Jiawei Han Alex Pang, "Exploratory Mining and Pruning Optimizations of Constrained Associations Rules", Proc ACM-SIGMOD'98, 1998 8  Torben Bach Pedersen, Christian S. Jensen Multidimensional Data Modeling for Complex Data Proc. ICDE'99, 1999 9  Sunita Sarawagi, Shiby Thomas, Rakesh Agrawal Integrating Association Rule Mining with Relational Database Systems: Alternatives and Implications", Proc ACM-SIGMOD'98, 1998   Hannu Toivonen, "Sampling Large Databases for Association Rules", 134-145, Proc. VLDB'96, 1996   Dick Tsur, Jeffrey D. Ullman, Serge Abiteboul, Chris Clifton, Rajeev Motwani, Svetlozar Nestorov, Arnon Rosenthal, "Query Flocks: A Generalization of Association-Rule Mining" Proc. ACM-SIGMOD'98 1998   P3P Architecture Working Group, \223General Overview of the P3P Architecture\224, P3P-arch-971022 http://www.w3.org/TR/WD-P3P.arch.html 1997 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



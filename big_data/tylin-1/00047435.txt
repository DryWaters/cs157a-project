SIMULATIONS OF CONPOSIT A SUPRA-CONNECTIONIST ARCHITECTURE FOR COMMONSENSE REASONING John A Barnden Computing Research Laboratory New Mexico State University Box 3CRL Las Cruces NM 88003 ABSTRACT A computational architecture called 223Conposit\224 is outlined Conposit manipulates very-short-term complex symbolic data structures of types that are useful in high-level cogni tive tasks such as commonsense reasoning planning and natural language understanding Conposit can be straightfor wardly implemented as a large neuralkonnectionist network and therefore provides a way of bridging the 
gap between high-level cognitive information processing and neural net works Conposit\222s data structures are, essentially temporary configurations of symbol Occurrences in a 2D array of regis ters Each register is implementable as a neural subnetwork whose activation pattem realizes the symbol occurrence The data structures are manipulated by condition-action rules that are realizable as further neural subnetworks attached to the array In simulations, Conposit has performed symbolic pro cessing of types previously found difficult for connectionist/neural networks This paper concentrates on a version of Conposit simulated on the Massively Parallel Pro 
cessor embodying core aspects of Johnson-Laird\222s mental model theory of human syllogistic reasoning This version illustrates Conposit\222s power and flexibility, which arises from unusual data-structure encoding techniques called 221\221Relative Position Encoding\224 and 223Pattem-Similarity Association\224 Keywords Cognitive Modeling Commonsense Reasoning Connectionism Neural Network Knowledge Representation Syllogism Mental Model INTRODUCTION The challenge presented to connectionism by high-level cog nitive processing  which includes commonsense reason ing planning and some aspects of natural language under standing  is gaining increasing recognition The main technical 
difficulties are listed in Refs 1-4 7 8 and else where in the connectionist literature and include the well known variable-binding problem and the problem of account ing for complex temporary, novel data structures Ref 6 reports experiments with a version of Conposit that incorporates production rules for commonsense reason ing one of which can be paraphrased as IF a person X loves a person Y who THEN X is jealous of Z loves a person Z different 
from X This exercises Conposit\222s handling of variable bindings The version of Conposit described below engages in a particular type of commonsense reasoning namely syllogistic reasoning by embodying some core aspects of the Johnson Laird\222s \223mental model\224 theory \(Refs 9-12 The main goal of the work was to verify that the techniques developed for other types of processing in Conposit \(Refs 4-7 were flexi ble enough to be extended in a natud way to the distinctly different type of processing required by the mental model theory  
and in fact no new features have had to be added Conposit is currently concemed only with short-term processing: there is no adaptive learning capability at present and long-term memory consists entirely of the fixed set of condition-action rules but see the suggestions in Refs 4,7 for a long-term memory of data structures It is closer to the 223localist\224 than to the 221\221distributed\224 end of the spectrum of connectionist systems BRIEF SKETCH OF CONPOSIT Conposit is currently defined as a computational architecture whose components 
can be straightforwardly implemented in connectionist terms Details are reported in Ref 7 or Ref 4 for an earlier formulation In Conposit a 223Relative-Position Encoding\224 technique is used as the foundation for complex short-term data struc tures These reside in a 32x32 array of registers This array is called the configuration matrix CM The values in registers are usually rapidly changing Each register can be implemented as a small connectionist subnet 
that holds a dynamically changing activity pattem implementing the register\222s value and that is connected to neighboring regis ters and other components A register\222s value consists of a 223symbol\224 and a vector of binary 223highlighting flag\224 values A symbol may have a specific representational function such as denoting a particu lar person or a particular type of relationship among people Any symbol can be placed in any register and all registers 311 CH2649-2/89/0000/0311$01 OO 0 1988 IEEE 


have the same set of highlighting flags Temporary srruc ture is encoded mainly in the adjacency relationships among values in CM registers For instance if a register contains a symbol denoting the class of all possible situations in which one person loves another and has a certain highlight ing flag in the ON state then any adjacent register that has another specific highlighting flag ON is deemed to represent temporarily, a specific loving situation See for example the representation of the proposition that John loves Mary in the upper portion of Figure 1 which shows an 8 x 8 region of the CM Figure 1 223Bill believes that John loves Mary.\224 Each square stands for a register and capitalized words and letters stand for symbols The word JOHN stands for a symbol denoting a particular person John known to the sys tem The LOVE symbol denotes the class of all conceivable loving situations The L symbol may be ignored for now The registers with no symbol shown contain a null symbol that does not denote anything The denotations of symbols are considered to be borrowed by the registers they occur in at any moment a register containing a non-null symbol denotes what that symbol denotes Hence, in the figure there are registers that  temporarily  denote John Mary and the love-situations class The other signs within squares show ON states of highlighting flags, which in this example are all referred to by the names of colors An 221r\222 indicates that the register is red-highlighted i.e the red flag is currently on similarly 221g\222 for green heart sign for white and spade sign for black One important function for highlighting is to help specify the representational relation ships temporarily holding between adjacent registers For instance a white-highlighted register is deemed to denote a member of the class denoted by any neighboring black highlighted register Therefore the upper white register in the figure denotes some love situation Further if a register denotes a love situation then any adjacent red register \(here the one containing JOHN\denotes the \223lover\224 and any adja cent green one here, the one containing MARY\denotes the 223lovee\224 Note that the absolute positions of the symbols and highlighting states are irrelevant, as are the directions of the adjacency relationships Complex data structures can be split up into pieces by a shared-symbol association technique Shared-symbol associ ation relies on the stipulation that two registers containing the same symbol are considered to represent the same entity The real power comes from the sharing of variable-like 223unassigned symbols\224 By appearing within a data struc ture an unassigned symbol can be viewed as having a tem porary denotation dictated by the role of the symbol in the structure The letter 221L\222 in Figure 1 indicates an unassigned symbol which temporarily comes to name the hypothetical loving situation by being in the white-highlighted register in the loving-subconfiguration The Figure shows how the pro position that Bill believes that John loves Mary can be encoded by two separate register-value subconfigurations that are linked by the sharing of the L symbol In this shared-symbol association technique two or more registers contain the same symbol and to that extent contain similar activity patterns at the connectionist level of description The notion of similarity here is simple and all or-none i.e not graded but other versions of the technique could be based on more sophisticated and perhaps graded notions of similarity of connectionist activity patterns Shared-symbol association is thus a simple instance of the class of 223Pattern-Similarity Association\224 techniques which are discussed briefly in Ref 6 The processing of the short-term data structures in the CM is performed by internal 223circuitry\224 i.e system com ponents that are mapped straightforwardly into a connection ist implementation mediating mainly neighbor-neighbor interaction within the CM, and external \223circuitry\224 outside the CM but attached to it The extemal circuitry embodies 223hardwired\224 condition-action processing rules Rules can detect particular configurations of symbols and highlighting states in the CM by means of highly parallel detection circui try that involves further two-dimensional register arrays iso morphic to the CM Refs 4,7 and can in response send complex sequences of signals to the CM A rule can embody conditionals testing the CM state, loops and a sim ple, form of non-recursive routine calling A rule operates on the CM in a highly SIMD register-local, parallel fashion each action on the CM is performed by sending to each register an identical 223command signal\224 in parallel, whereu pon different registers change state differently according to their own current states and those of their immediate neigh bors A command signal can have one of a number of effects such as making each register that has specified highlighting flags ON or OFF change the states of some flags and/or accept a new symbol value andor broadcast its symbol value 312 


to the other registers via a central relay station attached to the CM and called the Parallel Distributor It is also possi ble for a signal only to have an effect on a single randomly chosen register with specified highlighting, rather than on each such register A command signal may also require that for a register to respond either some or all of its neighboring registers be in a specified highlighting state Refs 4 7 detail how the signals can be used to process data structures and in particular, to find free space for and then create new data structures in the CM A tentative mapping of the model to connectionist net works that appear to be biologically reasonable is sketched in Refs 4 7 In particular, it is suggested that the CM could be realized as a localized group of thin cortical columns It is this suggestion that motivates the choice of dimension two and size 32x32 for the CM see Ref 4 A non-biological version of the approach could be based on a CM of other dimensions and sizes JOHNSON-LAIRD AND SYLLOGISMS Consider the syllogism Some chemists are beekeepers All beekeepers are householders Therefore some chemists are householders To simplify a little Johnson-Laird maintains that we make such a syllogistic inference by constructing a mental model of the form illustrated in Figure 2 Figure 2 A Johnson-Laird syllogistic mental model This mental model is an abstract data structure made up of 223tokens\224 shown by the capital letters and identity links between tokens shown by the equality signs There is an arbitrarily selected number of tokens C standing for chemists An arbitrarily selected proper non-empty subset are related by identity links to beekeeper tokens B and all beekeeper tokens are so linked to householder tokens H The parentheses in the figure indicate that the enclosed tokens are optional The conclusion that some chemists are household ers arises from noticing that some chemist tokens are linked by chains of equality tokens to householder tokens There is much arbitrariness in the construction of a mental model For instance the number of tokens in a particular model is arbitrarily chosen as is the number marked as optional There is also leeway in how the links are placed The mental model serves as a sort of internalized highly abstract \223exam ple\224 situation conforming to the premises of the English syllogism Naturally the \223conclusion\224 read off from a men tal model might merely be an artifact of the particular exam ple it embodies and therefore be invalid In response to this Johnson-Laird postulates that the system attempts to con struct several different mental models conforming to the premises in an attempt to falsify any particular putative con clusion before outputing it The attempted-falsification pro cess will fail in the present case but should succeed if in the above syllogism contained 223some beekeepers\224 rather than 223all beekepers\224 Johnson-Laird\222s theory is able to explain certain syl logistic preferences difficulties and errors exhibited by human subjects He does not specify any implementation of mental models in neural net terms JOHNSON-LAIRD SYLLOGISTIC REASONING IN CONPOSIT Conposit straightforwardly represents mental models and constructs them from propositional CM subconfigurations that encode syllogism premises I have not yet addressed the following aspects of Johnson-Laird\222s approach i the understanding or generation of natural language ii a thorough attempted-falsification process  the current Con posit is given the conclusion and merely checks its validity with a single model randomly generated from the premises or iii negative premises and conclusions 223no X are Y\224 and 223some X are not Y\224 which require special representa tional and processing features The correction of the last two deficiencies is not difficult however and will be described elsewhere Figure 3 shows the CM version of a syllogistic model derived from the premises in the Section 3 syllogism The CHMS BKRS and HHS symbols denote the classes of all conceivable chemists beekeepers and householders respec tively The X1 to X7 are distinct unassigned symbols Each Johnson-Laird \223person token\224 is implemented as a pair of adjacent CM registers one of which the black one tem porarily represents a class of person and the other of which the white one, containing an Xi symbol represents a partic ular though indefinite member of the class Recall the use of whiteblack adjacent highlighting in the love-situation representation in Figure 1 Each Xi symbol is thereby con sidered to denote a person for the time being The Figure shows the person tokens positioned in a regimented way but in the actual simulation they are randomly positioned in the CM and the white-highlighted register in each pair is a random neighbor of the black register The function of Johnson-Laird\222s identity links is taken over by symbol sharing, which is therefore being used for its standard func tion of making different CM registers represent the same thing In the figure an 221s\222 indicates special highlighting sig nifying that the token is optional 313 


Figure 3 CM version of a syllogistic mental model The mental model in Figure 3 is constructed from representations, analogous to the one for John loving Mary in Figure 1 of the two premises of the syllogism These prem ise representations are shown at the bottom left and bottom middle of Figure 4 Conposit is also given a propositional representation for the syllogism\222s conclusion \(bottom right of Figure 4 and checks that the mental model is consistent with this given conclusion The OLAP and SUBC symbols denote the classes of all conceivable class-overlap situations and subclass situations respectively The lST 2ND and 3RD symbols are arbitrary, distinct unassigned symbols None of these five symbols is dedicated to syllogistic reasoning The registers containing 1ST denote the situation of chemists overlapping with beekeepers i.e of some chemists being beekeepers The registers containing 2ND and 3RD are analogously interpreted The construction of the mental model has two main phases A hardwired rule called Rule-Some detects the subconfiguration for the first premise Figure 4 botttom left and constructs, in a another part of the CM the chemist and beekeeper tokens in Figure 3 It creates randomly many chemist tokens six on average then constructs beekeeper tokens using the same unassigned symbols as in a random subset of the chemist tokens and finally randomly con structs three extra beekeeper tokens on average Another similar, rule called Rule-All detects the subconfiguration for the second premise and constructs some householder tokens with the same unassigned symbols as in the beekeeper tokens and then constructs some extra householder tokens Finally RuleSome comes into play again by detecting the subconfiguration for the conclusion \(bottom right of illustra tion and checking that there is at least one chemist token and householder token sharing a symbol In cases where the conclusion is invalid such as in the amended Section 3 Figure 4 The statement of the syllogism displayed in the text example\Conposit sometimes does and sometimes does not construct a mental model consistent with the conclusion because of the randomness It would be mvial to get Con posit to repeat the whole process in an attempt to randomly alight on a falsifying model Rule-Some and Rule-All work with any classes in syllo gisms not just the chemist beekeeper and householder classes There is no replication of rule circuitry for the dif ferent classes Achievement of this effect in a more standard type of connectionist system would cause considerable difficulty Ref 4 describes versions of Rule-Some and Rule-All in complete detail That paper also describes the rule Note-Next that fires three times, once in response to each of the propositional CM subconfigurations at the top of Figure 4 These state the order in which the premise subconfigurations are to be considered The THEN symbol denotes the class of all conceivable succession situations Note-Next moves highlighting of two special sorts around in the CM with the result that Rule-Some and Rule-AN are mg gered in the right order RuleSome checks the conclusion in our example as fol lows It marks all the white registers in chemist and house holder tokens with special highlighting flags 223member-of-class1 224 and 223member-of-class2\224 respec tively Part of this marking process is to spread such highlighting to all registers with the same symbol All that is left to do is to detect the presence of some register marked with both 223member-of-class1 224 and 223member-of-class2\224 We have here a traditional marker passing process but work ing over highly temporary data structures 314 


Simulation Results Elapsed simulated time depends on values for signal-travel distances signal-travel speeds and combinatorial-logic delays e.g within CM registers that are based on broad assumptions about how Conposit could be realized as a bio logically reasonable neural net Ref 4 rather than just as an abstract connectionist net The main parameter values are as follows distance between rule circuitry and the CM 50mm long distance transmission speed lO"/ms basic time for register's response to a signal lOms overhead of random register selection 5ms The values of the last two parameters listed appeal to fast non-spike inter-neural communication in local circuits see Ref 4 for a discussion Notice the long distance of 5 cen timeters between CM and rule circuitry The lO"/ms value appears to be about the maximum speed for transmisison of neural impulses over long distances in cortex The following average timings were observed over one set of twelve experiments conducted one syllogism per experiment processing of a whole syllogism 2526ms detection phase of a rule 98ms a Note-Nat execution 76ms a Rule-SomelAll execution on first premise 905111s a Rule-SomelAll execution on second premise 602ms 18Oms a Rule-SomelAIl execution on conclusion CONCLUSION The average syllogism-processing time of about 2.5 seconds seems small enough to be psychologically realistic It is hard to discern timings for human syllogistic reasoning in Johnson-Laird's experimental reports partly because of the need for a natural language understanding phase The experi ments all appear to have allowed a time much longer than two and a half seconds E.g in the experiments of Ref 11 subjects were given either ten seconds or as long as they liked According to figures of Bara personal communica tion the faster human subjects work a simple syllogism in a time comparable to the two and a half seconds needed by Conposit It is probably not biologically plausible for rules like Rule-Some and Rule-All to be hardwired as in the current Conposit version partly because of the difficulty of seeing how the rule circuitry could be developed on the basis of The power and flexibility of Conposit arises from its Relative-Position Encoding and Pattern-Similarity Association techniques for encoding data structures These techniques arc unusual for connectionism, although the are loosely related to methods found elsewhere see Ref 6 ACKNOWLEDGMENTS This research is being supported in part by USAF under grant AFOSR-88-0215 and by NASA through the MPP Working Group REFERENCES 1 Barnden J.A On association techniques in neural representation schemes Procs 5th Conf of the Cogni tive Science Sociery Rochester NY 1983 2 Barnden J.A On short-term information processing in connectionist theories Cognition and Brain Theory 7 l 1984 3 Bamden J.A Diagrammatic short-term information processing by neural mechanisms Cognition and Brain Theory 7 3&4 1985 4 Bamden J.A Complex cognitive information processing a computational architecture with a connec tionist implementation Tech Rep 21 1 Computer Sci ence Dept., Indiana University 1986 5 Barnden J.A Simulation of an array-based neural net model In Proceedings of the First Symposium on the Frontiers of Massively Parallel Scientific Computation 8 9 NASA Conference Publication 2478 1987 Bamden J.A The right of free association relative position encoding for connectionist data structures Procs 10th Annual Conf of the Cognitive Science Soc Hillsdale N.J Lawrence Erlbaum 1988 Barnden J.A The power of some unusual connectionist data-structuring techniques In J.A Barnden  J.B Pollack Eds Advances in Connectionist and Neural Computation Theory Vol I Norwood N.J Ablex to appear Dyer M.G Symbolic NeuroEngineering and natural language processing: a multilevel research approach In J.A Barnden  J.B Pollack Eds Advances in Con nectionist and Neural Computation Theory Vol 1 Nor wood N.J Ablex to appear Johnson-Laird P.N Mental models Harvard Univer sity Press: Cambridge Mass 1983 experience However the basic Processing techniques 10 Johnson-hird P.N Reasoning by rule or model Procs 10th Annual Conf of the Cognitive Science Soc developed will be central also in more realistic systems in Hillsdale N.J Lawrence Erlbaum 1988 which a high-level production rule such as Rule-Some would itself be a data structure in one of a possibly large set of Cognition 16 l pp.1-61 1984 tion individual rule execution could be faster because of CMs \(Refs 4,7 In such systems which are under investiga N  Bars B.G Syllogistic inference faster subconfiguration creation, and because there would be the possibility of massive parallelism among rules in dif 12 Johnson-Laird P.N Oakhill J  Bull D Children's syllogistic reasoning The Quaterly J of Experimental ferent CMs Psych., 38A 35-58 1986 315 


because the use of the same system makes the comparisons more impartial Due to space restrictions we only include the results of the unordered algorithms The results of the CN2-SD algorithm were computed using both the multi plicative weights with y  0.5 0.7 0.9 and the additive weights Results withy  0.7 are not listed as they are al ways between those of 7  0.5 and y  0.9 as expected All other parameters of the CN2 algorithm were set to their de fault values bean-size  5 significance-threshold  99 Table 2 Area under the ROC curve with stan dard deviation AUC  sd for different vari ants of the unordered algorithm using 10-fold stratified cross-validation 3.5 and on CN2-WRAcc with a factor of 2 Note however that rules obtained with additive weights and multiplicative weights with high y are highly overlapping due to the rela tively modest decrease of example weights In addition there is also a substantial increase in the av erage likelihood ratio while the ratios achieved by CNZ standard are already significant at the 99 level this is fur ther pushed up by CNZ-SD with maximum values achieved by additive weights An interesting question to be verified with further experiments is whether the weighted versions of the CN2 algorithm improve the significance of the in duced subgroups also in the case when.CN2 rules are in duced without applying the significance test In summary CNZ-SD produces substantially smaller rule sets, where individual rules have higher coverage and sig nificance Table 3 Average size 9 coverage CVC and llkelihood ratio LHR of rules for different versions of the unordered algorithm induced from the entire data sets We also compared the sizes of the rule sets, average rule coverage, and the likelihd ratio of rules computed from the entire data sets not using cross-validation Table 3 compares CNZ-SD with CN2-standard and CN2-WRAcc in terms of the size of the rule set S is the number of rules in a rule set, including the default rule\average rule coverage CVG is computed as the averaged percentage of covered positive and negative examples per rule and likelihood ra tio\222 per rule The experimental results show that CN2-SD achieves im provements across the board In terms of AUC, the smallest improvement is achieved by additive weights and slightly better improvements of 34 are by multiplicative weights On the other hand additive weights result in ahout 2 times less rules on average than multiplicative weights and 6.5 times less rules than CNZ-standard Average rule coverage is also optimal for additive weights, improving on the av erage the coverage of CN2-standard rules with a factor of 222The likelihood ralio is used in CNZ for testing the significance of Ihs induced tule 141 For Iwo-class problems this stalislic is distributed ap prorimalely as xz wilh one degree of freedom Finally we illustrate our approach in the ROC space by means of the results on the Australian data set Fig ure 1 The solid lines in this graph indicate the ROC curves obtained by CN2-SD and CN2-standard evaluated with AUC-Method-2 i.e probabilistic classification with overlapping tules the top line \(squares for CN2-SD with additive weights, and the bottom line \(triangles for CNZ standard CN2-standard finds many more rules than CN2 SD which leads to overfitting as the ROC curve is mostly below the diagonal For illustrative purposes we also include positive and negative convex hulls constructed from individual sub groups using AUC-Method-l dotted lines The points on the X and Y-axes close to the origin are all small purely positive and negative subgroups found by CN2-standard that do not contribute to the convex hull \(presumably these are the rules that lead to poor performance using probabilis tic classification Using AUC-Method-l we can remove 271 


those overly specific subgroups leading to reasonable posi tive and negative convex hulls Notice, however that CNZ SD still improves on CN2-standard after removing redun dant subgroups Figure 1 Example ROC curves on the Aus tralian data set: solid curvesfor AUC-Method 2 and dotted positive and negative convex hulls for AUC-Method-1 squares for CNZ-SD with additive weights and triangles for CN2 standard 5 Related work Various rule evaluation measures and heuristics have been studied for subgroup discovery IO 241 aimed at bal ancing the size of a group referred to as factor g with its distributional unusualness \(referred to as factor p The properties of functions that combine these two factors have been extensively studied the so-called 221p-g-space\221 lo An alternative measure q   was proposed in 13 for expert-guided subgroup discovery in the TPIFP space aimed at minimizing the number of false positives FP and maximizing true positives TP guided by generalization pa rameter par Besides such 221objective\222 measures of interest ingness some 221subjective\222 measure of interestingness of a discovered pattern can be taken into the account such as ac tionability 221a pattern is interesting if the user can do some thing with it to his or her advantage\222 and unexpectedness 221a pattern is interesting to the user if it is surprising to the user\222 211 Instance weights play an important role in boosting I21 and alternating decision trees 20 Instance weights have been used also in variants of the covering algorithm imple mented in rule learning approaches such as SLIPPER 6 RL 1151 and DAIRY 191 A variant of the weighted cover ing algorithm has been used also in the context of subgroup discovery for rule subset selection 13 6 Conclusions We have presented a novel approach to adapting stan dard classification rule learning to subgroup discovery To this end we have appropriately adapted the covering algo rithm the search heuristics, the probabilistic classification and the performance measure Experimental results on 17 UCI data sets demonstrate that CNZ-SD produces substan tially smaller rule sets where individual rules have higher coverage and significance These three factors are important for subgroup discovery smaller size enables better under standing. higher coverage means larger support, and higher significance means that rules describe discovered subgroups that are significantly different from the entire population We have evaluated the results of CN2-SD also in terms of AUC-Method-2 and shown insignificant increase in terms of the area under the ROC curve In further work we will evaluate the results also by using AUC-Method-1 where each subgroup establishes a sepa rate point in the ROC space and compare the results with the MIDOS subgroup discovery algorithm We plan to in vestigate the behavior of CN2-SD also in multi-class prob lems An interesting question to he verified with further ex periments, is whether the weighted versions of the CN2 al gorithm improve the significance of the induced subgroups also in the case when CN2 rules are induced without ap plying the significance test Finally we plan to use the CNZ-SD subgroup discovery algorithm for solving practical problems in which expert evaluations of induced subgroup descriptions is of ultimate interest Acknowledgements Thanks to Dragan Gamberger for joint work on the weighted covering algorithm and JosC Hernbdez-Orallo and Cesar Ferr-Ramirez for joint work on AUC The work reported in this paper was supported by the Slovenian Min istry of Education Science and Sport the IST-1999-11495 project Data Mining and Decision Support for Business Competitiveness A European Virtual Enterprise and the British Council project Partnership in Science PSP-IS Refer en c e s l R Agrawal H Mannila R Srikant H Toivonen, and A.I Verkamo Fast discovery of association rules In U.M Fayyad G Piatetski-Shapiro P Smyth and R Uthurusamy editors, Advances in Knowledge Discov ery and Data Mining 307-328 AAA1 Press 1996 2 B Cestnik Estimating probabilities: A crucial task in machine learning In L Aiello editor Proc of rhe 9rh European Conference on Artificial Inrelligence 147 149. Pitman 1990 272 


3 P Clark and R. Boswell Rule induction with CNZ Some recent improvements. In Y Kodratoff editor Pmc of rhe 5rh European Working Session on Learn ing 151-163 Springer, 1991 141 P Clark and T Niblett The CNZ induction algorithm Machine Learning 3\(4 261-283 1989 5 W.W Cohen 1995 Fast effective rule induction. In Pmc of rhe 12th Intermrional Conference on Ma chine Learning 115-123 Morgan Kaufmann, 1995 161 W.W Cohen and Y Singer A simple fast and ef fective rule learner In Pmc of AAAI/lAAI 335 342. American Association for Artificial Intelligence 1999 171 S Dieroski B. Cestnik, and 1 Petrovski. \(1993 Us ing the m-estimate in rule induction Journal of Compuring andlnformarion Technology 1\(1 46 1993 8 U.M Fayyad and K.B Irani K.B Multi-interval dis cretisation of continuous-valued attributes for classi fication learning In R Bajcsy editor Pmc of the 13th Inrernarioml Joint Conference on Artificial In telligence 1022-1027 Morgan Kaufmann 1993 19 D Hsu 0 Etzioni and S Soderland A redundant cov ering algorithm applied to text classification In Pmc of the AAA1 Workshop on Learning from Tar Cate gorization American Association for Artificial Intel ligence, 1998 IO W Klosgen. Explora A multipattern and multistrat egy discovery assistant In U.M Fayyad G Piatetski Shapiro P Smyth and R Uthurusamy editors Ad vances in Knowledge Discovery and Data Mining 249-271 MITPress 1996 1111 C Fem-Ramirez P.A Flach and 1 Hemandez Orallo. Learning decision trees using the area under the ROC curve In Pmc of the 19th Internarional Conference on Machine Learning 139-146 Morgan Kaufmann 2002 I21 Y Freund and R.E Shapire. Experiments with a new boosting algorithm In Pmc of the 13th International Conference on Machine Learning 148-156 Morgan Kaufmann 1996 13 D Gamberger and N LavraE Descriptive induction through subgroup discovery A case study in a medi cal domain In Pmc of the 19th Internarional Confer ence on Machine Learning 163-170 Morgan Kauf mann 2002 I41 N Lavraf P Flach and B Zupan Rule evaluation measures A unifying view In Pmc of the 9th Inter national Workshop on Inducrive Logic Pmgramming 74-185 Springer 1999 I51 Y Lee B.G. Buchanan, and J.M. Aronis Knowledge based learning in exploratory science Learning rules to predict rodent carcinogenicity Machine Learning 30 217-240 1998 I61 R.S Michalski 1 Mozeti I Hong and N LavraE The multi-purpose incremental learning system AQl5 and its testing application on three medical domains In Pmc 5th National Conference on Artificial Inrelli gence 104-1045 Morgan Kaufmann, 1986 I71 P.M Murphy and D.W Aha UCI repos itory of chine learning databases http://www.ics.uci edurmleamiMLRepository.html Irvine CA University of California Department of Information and Computer Science 1994 I81 F Provost andT Fawcett Robust classification forim precise environments Machine Learning 42\(3 203 231,2001 I91 R.L Rivest Learning decision lists Machine Learn ing 2\(3 229-246 1987 201 R.E Schapire and Y Singer Improved boosting algo rithms using confidence-rated predictions In Pmc of the 11th Conference on Computational Learning The ory 80-91 ACM Press 1998  A Silbenchatz and A Tuehilin On subjective mea sures of interestingness in knowledge discovery In Pmc of the Isr Internarional Conference on Knowl edge Discovery and Data Mining 275-281 1995 1221 L Todorovski P Flach and N Lavraf Predictive performance of weighted relative accuracy In D.A Zighed 1 Komorowski, and J Zytkow, editors Pmc of the 4rh European Conference on Principles of Data Mining and Knowledge Discovery 255-264 Springer 2000 231 I.H. Witten and E Frank Data Mining: PracricalMa chine Learning Tools and Techniques wirh Java Imple mentations Morgan Kaufmann 1999 24 S Wrobel An algorithm for multi-relational discov ery of subgroups In Pmc of the 1st European Sym posium on Principles of Data Mining and Knowledge Discovery 78-87 Springer. 1997 273 


association-cube, base-cube and population-cube are derived from the volume cube; the confidence-cube is derived from the association cube and population cube and the support-cube is derived from the associationcube and base-cube. The slices of these cubes shown in Figure 2 correspond to the same list of values in dimension merchant, time, area and customer_group  Multidimensional and multilevel rules Representing association rules by cubes and underlying cubes by hierarchical dimensions, naturally supports multidimensional and multilevel rules. Also these rules are well organized and can be easily queried  First, the cells of an association cube with different dimension values are related to association rule instances in different scopes. In the association cube CrossSales cell CrossSales product \221A\222, product2 \221B\222  customer_group 221engineer\222, merchant \221Sears\222, area \221Los Angeles\222, time 221Jan98\222 represents the following multidimensional rule x 316 Customers: buy_product\(x, \221A\222 336 buy_product\(x,\221B\222  275 customer_group = \221engineer\222, merchant = \221Sears\222, area 221Los  Angeles\222, time =  \221Jan98\222 If this cell has value 4500, and the corresponding cell in the population cube has value 10000, then this rule has confidence 0.45 Next as the cubes representing rules can have hierarchical dimensions, they represent not only multidimensional but also multi-level association rules. For example, the following cells CrossSales\(product \221A\222, product2 \221B\222, customer_group 221engineer\222, merchant \221Sears\222, area \221 California 222, time 221Jan98\222 CrossSales\(product \221A\222, product2 \221B\222, customer_group 221engineer\222, merchant \221Sears\222, area \221 California 222, time 221 Year98 222 represent association rules at different area levels \(i.e the city level and the state level\d different time levels \(i.e., the month level, the year level x 316 Customers: buy_product\(x, \221A\222 336 buy_product\(x, \221B\222  275 customer_group = \221engineer\222, merchant =  \221Sears\222, area 221 California 222, time =  \221Jan98\222 x 316 Customers: buy_product\(x, \221A\222 336 buy_product\(x, \221B\222  275 customer_group = \221engineer\222, merchant =  \221Sears\222, area 221 California 222, time =  \221 Year98 222 The cell CrossSales\(product \221A\222, product2 \221B\222,  customer_group 221top\222, merchant \221top\222, area \221top\222,  time \221top\222 represents the customer-based cross-sale association rule for all customers, merchants, areas, and times in the given range of these dimensions, expressed as x 316 Customers: buy_product\(x, \221A\222 336 buy_product\(x, \221B\222 4.3  Generating Association Rule Related Cubes The basic task of our OLAP based association rule mining framework, either at the GDOS or at an LDOS is to convert a volume cube i.e. the cube representing the purchase volumes of customers dimensioned by product  area etc, into an association cube a base cube and a population cube These cubes are then used to derive the confidence cube and the support cube of multidimensional association rule instances. The following general steps are involved in cross-sale association rule mining 267  Roll up the volume cube SaleUnits by aggregating it along merchant, time, area dimensions 267  Derive cube NumOfBuyers from SaleUnits based on the antecedent condition SaleUnits 0 267  Populate cube NumOfShoppers by the counts of customers dimensioned by merchant, area  time not by product\at satisfy the antecedent conditions 267  Derive cube CrossSales from SaleUnits based on the association conditions SaleUnits  product  p 1  0 and SaleUnits  product2  p 2 0 267  Derive cube Confidence and cube Support using cell-wise operations 214  Confidence = CrossSales  NumOfBuyers 214  Support  CrossSales  NumOfShoppers  Cubes Confidence  Support  CrossSales are dimensioned by product  product2 customer_group,merchant  time, area NumOfBuyers is dimensioned by product  customer_group, merchant time, area  NumOfShoppers is dimensioned by customer_group, merchant  time, area Rules with confidence and support that exceed specified thresholds  may be considered interesting 4.4. Rules with Conjoint Items Cubes with conjoint dimensions can be used to represent refined multidimensional association rules For example, using OLAP, we can derive association rules across time  Time-variant or temporal association rules such as 


x 316 Customers buy_product\(x,\222 A\222, \221 Jan98\222  336 buy _product\(x, \221B\222, \221 Feb98\222   275 area = \221Los Angeles\222 can be used to answer such questions as \223 How are  the sales of B in Feb98  associated with the sales of A in Jan98 224 The items in this rule are value pairs of dimensions product and time In order to specify this kind of association rule we introduce a conjoint dimension product, time and mirror it with dimension product2, time2 This allows a cell in the association cube to cross two time values. Accordingly, the cubes related to association rule mining are defined as follows Association cube  CrossSales.2 \(<product, time>, <product2, time2 customer_group, merchant, area  Population cube  NumOfBuyers.2  \(<product, time>, customer_group merchant, area Base cube  NumOfShoppers.2  \( customer_group, merchant, area Confidence cube Confidence.2 \(<product, time>, <product2, time2 customer_group, merchant, area Support  cube  Support.2  product, time>, <product2, time2 customer_group, merchant, area  The steps for generating these cubes are similar to the ones described before. The major differences are that a cell is dimensioned by, besides others product, time and product2, time2 and the template of the association condition is  SaleUnit s  product p 1 time t 1  0 and  SaleUnits  product2 p 2 time2 t 2  0 where, in any instance of this condition, the time expressed by the value of time2 is not contained in the time expressed by the value of time The template of the antecedent condition is SaleUnits   product p 1 time t 1  0 In general, other dimensions such as area may be added to the conjoint dimensions to specify more refined rules 4.5. Functional Association Rules A multidimensional association rule is functional if its predicates include variables, and the variables in the consequent are functions of those in the antecedent.  For example, functional association rules can be used to answer the following questions, where a_month and a_year are variables q  What is the percentage of people in California who buy a printer in the next month after they bought a PC x 316 Customer buy_product\(x, \221PC\222, a_ month 336 buy_product\(x, \221printer\222, a_month+1  275 area = \221California\222 q  What is the percentage of people who buy a printer within the year when they bought a PC  x 316 Customer: buy_product\(x, \221PC\222, a_ year 336 buy_product\(x, \221printer\222, a_year 275 area = \221California\222 To be distinct, we call the association rules that are not functional as instance association rules; e.g x 316 Customer: buy_product\(x,\222 PC\222, \221Jan98\222 336 buy_product\(x,\222 printer\222, \221Feb98\222  275 area =  \221California\222 Time variant, functional association rules can be derived from time variant, instance association rules through cube restructuring. Let us introduce a new dimension time_delta that has values one_day, two_day 205, at the day level, and values one_month, two_month, \205, at the month level, etc. Then, let us consider the following functional association rule related cubes Association cube  CrossSales.3 \(product, product2, customer_group merchant, area, time_delta  Population cube  NumOfBuyers.3 \(product, customer_group, merchant area Base cube  NumOfShoppers.3 \( customer_group, merchant, area Confidence cube  Confidence.3 \(product, product2, customer_group merchant, area, time_delta Support cube  Support.3 \(product, product2, customer_group, merchant area, time_delta The association cube CrossSales.3  can be constructed from CrossSales.2   The cell values of CrossSales.2  in the selected time and time2 ranges are added to the corresponding cells of CrossSales.3 For example, the count value in cell  CrossSales.2\(<PC, Jan98>, <printer, Feb98>\205 is added to cell \(bin CrossSales.3\(PC, printer, one_month,\205 


It can also be added to cell CrossSales.3\(PC, printer one_year,\205 5  Distributed and Incremental Rule Mining There exist two ways to deal with association rules 267  Static that is, to extract a group of rules from a snapshot, or a history, of data and use "as is 267  Dynamic that is, to evolve rules from time to time using newly available data We mine association rules from an e-commerce data warehouse holding transaction data. The data flows in continuously and is processed daily Mining association rules dynamically has the following benefits 267  223Real-time\224 data mining, that is, the rules are drawn from the latest transactions for reflecting the current commercial trends 267  Multilevel knowledge abstraction, which requires summarizing multiple partial results. For example association rules on the month or year basis cannot be concluded from daily mining results. In fact multilevel mining is incremental in nature 267  For scalability, incremental and distributed mining has become a practical choice Figure 3: Distributed rule mining Incremental association rule mining requires combining partial results. It is easy to see that the confidence and support of multiple rules may not be combined directly. This is why we treat them as \223views\224 and only maintain the association cube, the population cube and the base cube that can be updated from each new copy of volume cube. Below, we discuss several cases to show how a GDOS can mine association rules by incorporating the partial results computed at LDOSs 267  The first case is to sum up volume-cubes generated at multiple LDOSs. Let C v,i be the volume-cube generated at LDOS i The volume-cube generated at the GDOS by combining the volume-cubes fed from these LDOSs is 345   n i i v v C C 1  The association rules are then generated at the GDOS from the centralized C v  214  The second case is to mine local rules with distinct bases at participating LDOSs, resulting in a local association cube C a,I a local population cube C p,I  and a local base cube C b,i at each LDOS. At the GDOS, multiple association cubes, population cubes and base cubes sent from the LDOSs are simply combined, resulting in a summarized association cube and a summarized population cube, as 345   n i i a a C C 1   345   n i i p p C C 1  and 345   n i i b b C C 1  The corresponding confidence cube and support cube can then be derived as described earlier. Cross-sale association rules generated from distinct customers belong to this case In general, it is inappropriate to directly combine association cubes that cover areas a 1 205, a k to cover a larger area a In the given example, this is because association cubes record counts of customers that satisfy   customer product merchant time area Doe TV Dept Store 98Q1 California Doe VCR Dept Store 98Q1 California customer product merchant time area Doe VCR Sears 5-Feb-98 San Francisco Joe PC OfficeMax 7-Feb-98 San Francisco customer product merchant time area Doe TV Fry's 3-Jan-98 San Jose Smith Radio Kmart 14-Jan-98 San Jose Association   population      base          confidence      support cube               cube                cube         cube                cube LDOS LDOS GDOS 


the association condition, and the sets of customers contained in a 1 205, a k are not mutually disjoint. This can be seen in the following examples 214  A customer who bought A and B in both San Jose and San Francisco which are covered by different LDOSs , contributes a count to the rule covering each city, but has only one count, not two, for the rule A  336  B covering California 214  A customer \(e.g. Doe in Figure 3\who bought a TV in San Jose, but a VCR in San Francisco, is not countable for the cross-sale association rule TV  336 VCR covering any of these cities, but countable for the rule covering California. This is illustrated in Figure 3 6  Conclusions In order to scale-up association rule mining in ecommerce, we have developed a distributed and cooperative data-warehouse/OLAP infrastructure. This infrastructure allows us to generate association rules with enhanced expressive power, by combining information of discrete commercial activities from different geographic areas, different merchants and over different time periods. In this paper we have introduced scoped association rules  association rules with conjoint items and functional association rules as useful extensions to association rules The proposed infrastructure has been designed and prototyped at HP Labs to support business intelligence applications in e-commerce. Our preliminary results validate the scalability and maintainability of this infrastructure, and the power of the enhanced multilevel and multidimensional association rules. In this paper we did not discuss privacy control in customer profiling However, we did address this issue in our design by incorporating support for the P3P protocol [1 i n  ou r data warehouse. We plan to integrate this framework with a commercial e-commerce system References 1  Sameet Agarwal, Rakesh Agrawal, Prasad Deshpande Ashish Gupta, Jeffrey F. Naughton, Raghu Ramakrishnan, Sunita Sarawagi, "On the Computation of Multidimensional Aggregates", 506-521, Proc. VLDB'96 1996 2  Surajit Chaudhuri and Umesh Dayal, \223An Overview of Data Warehousing and OLAP Technology\224, SIGMOD Record Vol \(26\ No \(1\ 1996 3  Qiming Chen, Umesh Dayal, Meichun Hsu 223 OLAPbased Scalable Profiling of Customer Behavior\224, Proc. Of 1 st International Conference on Data Warehousing and Knowledge Discovery \(DAWAK99\, 1999, Italy 4  Hector Garcia-Molina, Wilburt Labio, Jun Yang Expiring Data in a Warehouse", Proc. VLDB'98, 1998 5  J. Han, S. Chee, and J. Y. Chiang, "Issues for On-Line Analytical Mining of Data Warehouses", SIGMOD'98 Workshop on Research Issues on Data Mining and Knowledge Discovery \(DMKD'98\ , USA, 1998 6  J. Han, "OLAP Mining: An Integration of OLAP with Data Mining", Proc. IFIP Conference on Data Semantics DS-7\, Switzerland, 1997 7  Raymond T. Ng, Laks V.S. Lakshmanan, Jiawei Han Alex Pang, "Exploratory Mining and Pruning Optimizations of Constrained Associations Rules", Proc ACM-SIGMOD'98, 1998 8  Torben Bach Pedersen, Christian S. Jensen Multidimensional Data Modeling for Complex Data Proc. ICDE'99, 1999 9  Sunita Sarawagi, Shiby Thomas, Rakesh Agrawal Integrating Association Rule Mining with Relational Database Systems: Alternatives and Implications", Proc ACM-SIGMOD'98, 1998   Hannu Toivonen, "Sampling Large Databases for Association Rules", 134-145, Proc. VLDB'96, 1996   Dick Tsur, Jeffrey D. Ullman, Serge Abiteboul, Chris Clifton, Rajeev Motwani, Svetlozar Nestorov, Arnon Rosenthal, "Query Flocks: A Generalization of Association-Rule Mining" Proc. ACM-SIGMOD'98 1998   P3P Architecture Working Group, \223General Overview of the P3P Architecture\224, P3P-arch-971022 http://www.w3.org/TR/WD-P3P.arch.html 1997 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



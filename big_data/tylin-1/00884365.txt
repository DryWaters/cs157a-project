Dynamic rule graph drawing by genetic search Pascale Kuntz Remi Lehn Henri Briand Abstract The recent importance given to the integration of the user in a KDD process which gives him the oppor tunity to direct his mining towards his specific own needs requires the development of new highly interactive visual ization tools For graph based representation of discovered knowledge this means that layout algorithms must dynam ically take modifications into account In this paper we present a genetic approach to draw a series of layered di rected graphs which model relationships between associa tion rules We develop new problem-specific genetic oper ators and show that genetic algorithms are well-adapted to solve a multiobjective problem  meeting static aesthetic requirements such as minimizing arc crosses and preserving the 223user\222s mental map\224 when a transformation 
is interac tively performed on the graph Experimental results are presented on several randomly generated series of graphs Kegwords Computational Cybernetics Data Mining and Knowledge Discovery I INTRODUCTION OGETHER with chart graphics and maps network T diagrams or graphs are one of the most popular graph ical forms used for information presentation They can be used at the same time as theoretical models and as vi sualization supports They often allow access to complex abstract structures without getting bogged down in the mathematical detail I For such reasons graphs are well adapted to visually represent relationships between rules extracted from large datasets Since open problems on visualization set in the last decade have been identified 2 great efforts have been rnade in graphical database query interfaces 
and represen tations of multidimensional data and today several tools integrate graph models e.g 3 4  However with the development of more and more efficient knowledge extrac tion algorithms and of human-centered approaches 5 new needs are coming to light in the mining and post-treatment phases of a KDD process 6 We here restrict ourselves to non-supervised approach es of rule extraction for which different graph models have been proposed in the literature Let 0 be the set of objects of a database described by a finite set I of items For pure ly logical rules i.e without any counter-examples Galois lattices 7 have known a renewed interest in combinatorial data analysis for the search of 
implications in binary data SI In this case each node is a particular pair composed of a subset of 0 and a subset of I and the set of pairs is partially ordered by the standard set inclusion relation ap plied to 0 and I It can be represented by a Hasse diagram where arcs represent the inclusion relation Unfortunately determining a Galois lattice along with its Hasse diagram is a computationally difficult problem and the visual repre sentation become inextricable for numerous items An ex IRIN Universite de Nantes Rue Christian Paw 44300 Nantes France Remi.LehnQirin.univ-nantas.fr tension of this model to the search of 223quasi-implications\224 where the strict inclusion is replaced by a statistical 
mea sure has been recently proposed 191 but experiments only deal with small size data sets at the moment In ot,her common rule representation models the graph\222s nodes aro just itemsets which correspond to premises and conclusions of the rules and an arc directly represents an implicat,iori relation whose validity is assessed by a quality measure lo More sophisticated approaches are inspired by hier archical classification algorithms and represent, iinplicat ion relationships by hierarchical trees ll Whatever the selected model is in the vast majorit of the applications a layout of the rule graph is a kind of final synthesis obtained after a complex data proc line It is considered as an appropriate vizualisation sui port to 
give an insight into results that would be more difficult to get from looking at long lists of alpha-numericill characters From the algorithmical point of view for th layout problem the vertex and arc sets are given as inpiit in accordance with the model and a drawing satisfying some intelligibility criteria is furnished as output This is refered to as a static drawing problem However t,hr rc cent importance given to the integration of the user in I KDD process which gives him the opportunity to dirert his mining towards his own needs requires the development of new highly interactive visualization tools For graphs, this means that layout algorithms must take into account mod ifications e.g insertions or deletions of nodes and arcsj dynamically 
at different time scales Generally speaking, numerous efficient graph drawing a gorithms have been proposed for many criteria la but few of them take the interactivity with the user irit,o account 13 If a modification is performed the algu rithm runs again and produces a new drawing which inav be thoroughly different from the previous one As noticed by Papakostas et a1 14 223this is a waste of human re sources to continually re-analyse the entire drawing aiid also of computational resources to re-computed the entire layout after each modification\224 And in the context of da ta mining these limitations may become a real obstacle important changes between two consecutive layouts in a dynamical rule extraction process 
where nodes and arcs can be added depending on user requests highly disturb the interpretation task This is the reason why such a pro cess must be associated with a drawing method which pre serves the 223user\222s mental map\224 as much as possible More formally this problem can be set as a multi-objective prob lem produce at each step t a layout L Gt of the graph Gt t,hat satisfies common readability requirements as for instance arc crossings minimization and so that L Gt re mains 223similar\224 to the layout L\(Gt-l of the graph GtPl proposed at the previous step 0-7803-6583-6/00/$10.00 0 2000 IEEE 248 1 


In this paper we develop a genetic algorithm \(GA based approach for dynamically drawing a directed graph mod el of association rules simpler than a Galois lattice GAS are stochastic global search methods that have proven to be efficient for many combinatorial optimization problems In particular several authors have reported promising ap plications of GAS or Evolutionary Algorithms for different static drawing problems of directed graphs  16 17 1181 1191 Here we develop new problem-specific genetic operators for the layered drawing of our rule graph model and show that GAS are particularly well-adapted for the dynamic layout problem Due to their intrinsic parallelism thcv compute a set of potentially good solutions and indi 1 ectly allow to solve our multi-objective problem the set of potential solutions is generated with GA oplerators ac cording to fitness function which measure aesthetics and a layout is chosen among them according to its resemblance to a previous layout 11 MODELING OF THE PROBLEM Each subset Xi often called itemset of I is iIssociated with a unique subset ti of 0 is the set of objects for which every item of Xi is present For instance Xi  i1,24,25 associated with the subset Ei  012,042,0791,0~44 means that 012 042 0791 and 03~~4 are the only objects of 0 for which il i4 and i5 are all present Although our model may be generalized to more complex data we here restrict ourselves to binary I tsms I The r.nle graph model Here a rule graph is an acyclic directional graph G  1.1 4 where each vertex of V is an potentially interesting itmiset aid each arc of A represents a significant implica tion between two itemsets Formally a vertex is a subset of I iiid there exists an arc between two vertices X and X\221 if t.lit1 lule S  Y\222  X is valid according to statistical mea i:rt-:s For instance if X  i4,i7 and X\222  i4,i~,ig an arc between X and X\222 corresponds to the association role Lt A i7  ig iVe have developed a user-driven algorithm for the asso c.i;ition rule extraction where a series of graph Gt is generatcd dynamically by the requests of the user. Rough ly speaking at each step t the user selects a vertex associated with an itemset he is focusing on, and the in t.cresting associated rules are automatically generated by a rriodified local version of the well-known A Priori algorithm 1201 t,he precise description of the process and its cognitive foridations are far beyond the scope of this paper and we refer to I211 for details Then a new graph Gt+l is drawn to update the knowledge The process starts with a dis crete graph Go which only contains vertices representing itemsets of cardinality one often present in the database in other words items common to numerous objects and stops at a step T fixed by the user with a graph GT which contains all the rules discovered during the process  2482 Luyers fh=4J Fig 1 Layered drawing of the rule graph B Intelligibility requirements jor the graph layout A property always required for drawing graphs which model abstract concepts is intelligibility This covers phys ical constraints of the drawing support and zsthetic crite ria Aesthetics are closely linked to the application they specify graphic properties that should help the reader to understand and remember the information represented in the graph In our case polyline drawings with vertices arranged in vertical layers are well adapted The vertex set V is par titioned into h subsets associaited with h layers L1  Lh so that for any arc X,X\222 E A where X is placed on Li and X\221 on Lj then i  j In the model each layer is as sociated with a degree of preckion in the knowledge state layers on the left correspond to general descriptions made by small itemsets whereas layers on the right correspond to more specific descriptions Fig 1 Thus vertices are here supposed to be pre-assigned to the layers and graphs are supposed to be acyclic In addition to this drawing convention readability cri teria often defined by combinatorial optimization goals must be specified One of the most sensitive criterion for the interpretation is the number of arc crossings Note that the general problem of minimizing arc crossings is NP complete and remains so even for the layered digraph draw ing where the crossing number depends on the ordering of the vertices within each layer only 23 In order to avoid long lines which can create confusion we also consider the minimization of the sum of the arc lengths These two constraints are here treated separately a GA generates a vertex ordering on each layer which tends to minimize arc crossings and a classical hill-climbing local ly adjusts the vertex coordinates to minimize arc lenghts C Dynamic integration One major difficulty is to propose a pragmatic definition of the intuitive concept of 223mental map\222s stability\224 when interpreting a layout In the general case let us denote by P the set of points of a geometric space 5\222 which repre sents the vertices of a graph G on a layout L\(G and let T be a function which transforms P into another represen tation P\222 of the same graph Eades et al 24 propose a definition of the stability which depends on the choice of an equivalence relation E on the set of the finite S sub 


sets the transformation T preserves the representation P if P P\221  T\(P They give different pragmatic defini tions of one of which is based on order equivalences P and P\222 have the same 223orthogonal ordering\224 if the relative positions of each each pair of points are the same in given directions e.g up down, left right In this paper we adapt this notion to the comparison of the layouts of different graphs Gt and Gt+l obtained at consecutive steps We only take into account the number of vertex permutations between two layouts as this criterion is the most sensitive for the interpretation Let i?k resp ck be the number of vertex couples on layer k whose order has changed resp not changed between L\(Gt and L\(Gt+l The two layouts are compared via a dissimilarity coefficient A A\(L\(Gt Gt+l  1  izk And Pt Z Pt+i if A\(L\(Gt Gt+i  0 111 A GENETIC BASED APPROACH GAS work with a population of potential solutions which stochastically evolves by means of three basic operators selection recombination and mutation And when de signing a GA the proper choice of the solution coding and the genetic operators is of the utmost importance as it can have a significant influence on the optimization process In the following we therefore discuss coding and associated operators in more details A Solution coding and selection To simplify the drawing problem a classical representa tion is previously made so that the graph is 223proper\224 i.e each arc is incident to vertices placed on two adjacent layers only This is easily achieved by inserting so-called dummy vertices an arc incident to vertices X and X\221 respectively placed on layers k and k\222 so that Ik  IC\221  1 is transformed into a path of Ik  k\222l arcs using k  k\221l-1 dummy vertices circles on figure 1 Moreover a set of possible positions numbered downwards is associated with each layer Hence the problem consists in defining a permutation fJk on each Lk where x is the rank of X on Lk so that the total arc crossing number is minimized Although for most graph drawing applications the po tential solutions are coded by a string of the real coordi nates of the vertex positions an ordinal representation is more appropriate here A genotype codes the vertex ranks for each layer one after the other the ranks of the n1 ver tices of L1 are placed on the left in the genotype then the ranks of the 122 vertices of LZ are added to it and so on In the classical GA scheme e.g 25 the initial pop ulation is randomly chosen and every subsequent genera tion is built from the current one with the genetic opera tors An alternative consists in initializing the process by a small population which increases by insertion of new solu tions created by a reproduction mechanism and whose evo lution is controled by an 223aging\224 threshold only solutions recent enough can be selected for reproduction Experi mental comparisons have led us to prefer this alternative and to select an initial population with genotypes whose vertex ordering fits different depth first searchs of the graph a directed one starting with vertices having a null inferior half-degree a backward one starting with vertices with a null superior half-degree  This tends to initilialize the exploration with potentially suitable solutions The selection is determined by a classical roulette wheel based on the fitness function In order to compare the crossing numbers of different layouts without knowledge of a maximal bound the fitness is here defined by 2-f\(L\(c where f\(L G is the number of arc crossings in the layout L GI B Mutation Four mutation operators are applied according to a prob ability and to ensure that the genotype codes a valid solu tion each mutation operator is local and can modify genes of a unique layer randomly chosen at each time Two of them are common local search operators in permuta tion problems the random local permutation and the 2 opt The two other are problem-specific and are inspired by drawing heuristics 26 Permutation based on vertex degrees As a permu tation with few neighbors disturbs the drawing usually less than a permutation with highly connected vertices local permutations for vertices with small degrees are favored The choice of two vertices to be exchanged depends on a probability inversely proportional to their degrees Permutation based on median This permutation stemmed from one of the most common heuristic applied to the 2-layer drawing problem which aims at placing a vertex on one layer Li,i=1,2 in front of the 223middle\224 \(which can be a median\222 or a barycenter of its neighbors on Lj,j This attemps to minimize arc length locally and contributes to a better drawing The transposition of this idea to the per mutation scheme consists in selecting a vertex X randomly on a layer Lk and exchanging its rank with the rank of the vertex of Lk which is the closest to the middle of the me dian of the successors of X on Lk+l and of the median of its precedessors on Lk-1 More formally the classical def inition of the median must be adapted here The median of a vertex X on Lk is the vertex of Lk whose rank in the order defined by Tk is the closest to where deg-\(X resp deg+\(X is the number of X pre decessors resp successors and nk is the vertex number on Lk For instance let us consider a vertex X at rank 1 on Lk with 5 predecessors on Lk-1 at respective ranks 1 3 5 6 8 and 3 successors on Lk-1 at respective ranks 3 5 and 6 Fig 2 If nk-1  8 nk  4 and nk+1  6 then formula 1 equals 2.7 and consequently the vertex X is swapped with the vertex at rank 3 on Lk 221For real coordinates on each vertical layer, the median of the pre decessors of a vertex is the y-coordinate s.t half of the y-coordinates of the predecessor are greater and the other half are smaller 2483 


Lk-l 4 I a Original layout 27 arc crossings Lk-l 222 4+1 b Permutation of U with the vertex on its median position  12 arc crossings Fig 2 Permutation based on median Generally speaking the impact of each of these muta tion operators depends on the graph properties In case of few dummy vertices the local permutation combined with 2-opt gives good results whereas in the opposit,e case -i.e when arcs are greater and vertex degrees are heterogeneous more specific operators noticeably improve the results As for dynamic drawing these properties are not known a pri ora and may evolve during the mining process we here keep all of the operators with a fixed activating probabili ty at each step 0.02 for local permutation 0.01 for 2-opt 0.04 for permutation based on vertex degrees and 0.08 for permutation based on median C Crossover It is well-known that the main difficulty for ordinal cod ings is to define a crossover which guarantees a feasible so lution Here, two genotypes are selected and the crossover is applied on one layer Lk randomly chosen we have com pared two specialized crossover operators which have been previously applied to problems encoded as permutation  refered to as 223ordering GA\224  we refer to 27 for a de scription Order Crossover l OC1 and Partia\222lly Mapped Crossover PMX And to avoid side effects as for instance the recombination of two identical genotypes which leads to a new different one we have included the variants proposed in  Figure 3 shows the evolution of the fitness with each operator for the same computational time The time required by the PMX compared to OC1 acts as a brake upon the search space exploration here The number of generations obtained with OC1 is about three time superi or to PMX and profits of PMX in the optimization process are Quickly overtaken Let us remark that PMX has been 92 t 96 3 98 LE I 100 102 104 106 inn 223I canstant time  60 s wallclock time  Fig 3 Comparison with OC1 and IPMX crossover operators evolu tion of average fitness for 100 drawings of a random 50 edges/40 vertices/lO layers digraph Due to these results we here retain the following defi nition of OC1 An interval I of random size is selected on the layer Lk of the first genotype and I is duplicated in the offspring\222s genotype at the same place This one is completed by genes of the second genotype which are not in I by starting at the end of I and by following the second genotype\222s order For instance let us suppose that the first \(resp the second genotype contains the sequence i4  il  i2  i5  i3  i6 resp il  iz  i4  26  25  23 for the layer Lk If I  i2  is  i3 then the layer Lk of the offspring contains i4  i6  iz-.iS-i3-il The other layers are either the same as the first genotype or the same as the second genotype according to it random choice  D Dynamic constraint The stability constraint between two consecutive layouts is not introduced right from the start but from a certain size TI of the graph Up to n,9 fixed here at 20 vertices only fitness f is taken into account in the optimization process Indeed when graphs axe small the user can record the whole of the information and cope with changes easily Moreover at the begininning of the mining process there are few extracted rules and the 223shapes\224 of the associated Eraphs are not well defined I Let t be the step of the drawing L\(Gt of the graph with n vertices At t  1 new vertkes are added The GA de scribed above runs during a fixed number of generations in order to maximize f and we denote by P;+l the last popu lation obtained The dissimilarity A is computed between each layout of Pt;l and L\(G and among the IC fixed here at 20 closest layouts the one with the largest fitness is selected developed for Traveling Salesman Problems of large sizes in particular whereas in our case the complexity lies in the relationships between layers and each layer is limited to about 70 vertices for readability requirements In the coding when a vertex is added a new place is allocated on each genotype a:nd a rank is added for the new vertex For arc addition the only change is concerned with the fitness whose value is calculated again 2484 


I\222 I 18 16 14   12 0 3 10  4 18 56 2 0 IO 20 30 40 50 60 70 80 graph evolurion  number o/arc 0 Fig 4 Comparison with a graph drawing algorithm based on classi cal GA operators average values of 20 drawings of a random 45 edresi31 vertices/6 lavers diarauh Fig 5 Comparison of the fitness values at each step for the select.ed layouts and the best ones according to the fitness average value on 10 runs on the same serie of graphs 223I I\223 _.I Iv EXPERIMENTAL RESULTS In order to prove the interest of our new problem-specific GA operators we first compare results obtained on \223static\224 graphs to those obtained with basic GA operators applied to a real coding of vertex positions on each layer 29 Fig ure 4 shows the fitness values obtained for the same com putation time 60 seconds wallclock time on 20 drawings of a random graph Figure 6 illustrates the integration of the dynamic con straint Two consecutive layouts L Gt-1 and L Gt are presented one vertex and six arcs are added on Gt And figure 7 describes a typical situation of the multi-objective optimization At each step t vertex and arcs are randomly added to the previous graph Gt-l The initial graph Go is reduced to a single random arc At each t the GA tends to maintain a layout L G very close to the previous one L\(Gt-l as long as possible But at a certain step t too many changes in the graph have been performed and the layouts close to the previous one L Gt I  become unac ceptable according to the fitness they disappear and leave their places with other potential solutions The evolution of the dissimilarities A\(L Gt-l L G between selected layouts higlights \223peaks\224 and 223holes\224 which are explained by this double optimization process Let us notice that this phenomenon is closely linked to the parameter values which govern the evolution in particular it softens when the size of the population decreases When we compare the evolutions of the fitness of the selected layout L Gt i.e the layout which minimizes A\(L*\(Gt-I Gt and of the best layout Lf\(Gt ac cording to the fitness i.e the layout which maximizes f we see that both curves follow a similar evolution with the Lf  Gt fitness obviously better than or equal to the L*\(Gt one V CONCLUSION In this paper we presented a graph model well-adapted to interactive association rule visualization and we devel oped a genetic algorithm for the dynamical drawing of layered directed graphs We showed that ordering coding and problem-specific operators inspired by classical dram ing heuristics and permutation problems significantly in prove previous results obtained with a classical schenie Numerical tests allow us to think that GAS are very strong candidate to solve this class of drawing problems Our al gorithm is now included in a rule mining software 1301 and first experiments on real databases from marketing and hu man resources highlight the information gain obtained in the extraction process with such a visualization support Future work includes further evaluations that need tlo de termine which dissimilarities are most appropriate for mod eling the user mental map\222s stability Additional experi ments are also necessary to better understand the impact of constraint\222s stability on the search space In particular we are applying an approach coming for multidimensional scaling to discover resemblance relationships between lay outs within a same population REFERENCES l 2 W Buntine 223Graphical models for discovering knowledge,\224 In Fayyad et al 311 pp 59-82 L Treinish, D.M Butler D.M H Senay G.G Grinstein and S.T Bryson 223Grand challenge in visualization software,\224 in Proc Visualization 1992 pp 366-371 Boston Mass M.P Consens and A.O Mendelzon 223Hy a hypergraph-based query and visualization system,\224 in Proc ACM SIGMOD Int Conf on Management of Data 1993 pp 511-516 4 R.A Becker S.G Eick and G.J Wills 223Visualizing network data,\224 IEEE lhns on Visualizations and Graphics vol 1 no J.R Brachman and T Anand 223The process of knowledge dis covery in databases a human-centered approach,\224 In Fayyad 3 1 pp 16-28 1995 5  223I et a1.-[31 pp 37-58 W.J F\222rawley G Piatetsky-Shapiro and C.J Matheus 223Knowl edge discovery in databases an overview,\224 in Knowledse Dis 6 covery in Databases pp 1-27 AAA1 Press 1991 7 G Birkoff Lattice Theory A.M.S 1967 81 V Duquenne, \223Latticial structures in data analysis,\224 Theoretical Computer Science vol. 217, no 2, pp 407-436 1999 9 J M Bernard and S Poitrenaud 223Multivariate Bayesian im plicative analysis for a binary questionnaire  quasi-implications and simplified Galois lattice,\224 1999 lo M Klemettinen H Mannila H Toivonen P Ronkainen and I Verkamo 223Finding interesting rules from large sets of dis covered association rules,\224 in Proc of the 3rd Int Conf on 2485 


Fig 6 Graph updating with dynamic constraint  on this fig ure 1 vertex and 6 arcs have been added vertex and its incident arcs L\(Gt is darker and L\(Gt--1 is lighter A L Gt-i L Gt  2 Fig 7 Typical situation of the multi-objective optimization for dynamical layouts liilorination and Knowledge Management 1994 pp 401-407 ACM Press ll R Gras H Briand, and P Peter 223Structuration sets with im plication intensity,\224 in Proc of the Int Conf on Ordinal and Symbolzc Data Analysis 1996 pp 147-156 I G Di Battista P Eades R Tamassia, and I.-G Tollis Graph drawing  Algorithms for the visualization of gmphs Prentice Itall 1999 1131 R.-F Cohen G Di Battista R Tamassia 1.43 Tollis and P Bertolazzi 223A framework for dynamic graph drawing,\224 in Proc of A CM Symposium on Computational Geometry 1992 pp 261-270 ACM Press 1141 A Papakostas J.-M Six and I.-G Tollis 223Experimental and theoretical results in interactive orthogonal graph drawing,\224 in Proc Graph Drawing\22296 1997 vol 1190 of Lect Notes in Comp Sc pp 371-386 Springer Verlag 15 L.J Groves Z Michalewicz P.V Elia and C.Z Janikow 223Ge netic algorithms for drawing directed graphs,\224 in Proc of the 5th Int. Symp on Methodologies for Intelligent Systems 1990 pp 268-276 Elsevier IS T Masui, \223Graphic object layout with interactive genetic algo rithms,\224 in Proc of the 1992 IEEE Work on Visual Langages 2486 1992 pp 74-80 IEEE Computer Soc Press 17 E Makinen and M Sieranta 223Genetic algorithms for drawing bipartite graphs,\224 Int J of Comput. Math vol 53 no 3-4 pp 18 A Ochoa and A Rosete 223Automatic graph drawing by genetic search,\224 in Proc of the 11th Int Conf on CAD CAM Robotics and Manufactories of the Fui!ure 1995 pp 982-987 19 J Utech J Branke H Schmeck and P Eades 223An evolutionary algorithm for drawing directed graphs,\224 in Proc of the Int Conf on Imaging Science Systems and Technology 1998 pp 154-160 CSREA Press 20 R Agrawal H Mannila R Srikant H Toivonen and A.-I Verkamo 223Fast discovery of association rules,\224 In Fayyad et al 21 P Kuntz F Guillet R Lehn and H Briand 223A user-driven process for mining association rules,\224 in to appear in Proc of Principles and Practice of Knowledge Discovery in Databases 2000 Springer-Verlag 22 H Purchase 223Which aesthetic has the greatest effect on human understanding 224 in Proc Gmph Dmwing\22297  Lect Notes in Comp. Sc 1997 vol 1353 pp 248-261 Springer Verlag 23 P Eades and N Wormald, \223Edge crossings in drawings of bipar tite graphs,\224 Algorithmica vol 11 pp 379-403 1994 24 P Eades W Lai K Misue and K Sugiyama 223Preserving the mental map of a diagram,\224 in Proc of Compugmphics 1991 25 D.-E Goldberg Genetic Algorithms in Search Optimization and Machine Learning Addison-Wesley 1989 26 E.R Gansner E Koutsofios S.C North and K.P Vo 223A tech nique for drawing directed graphs,\224 IEEE 2\224s Soft Eng vol 27 H Kargupta, K. Deb and D Goldberg, \223Ordering genetic algo rithms and deception,\224 in Proc Parallel Problem Solving from Nature 1992 vol 2 pp 47-56 Elsevier Sc 28 D Whitley and N Yoo 223Modeling simple genetic algorithms for permutation problems,\224 in thdations of Genetic Algorithms Ill Morgan Kaufmann 1995 29 F Guillet P Kuntz and R Lehn 223A genetic algorithm for vi sualizing networks of association rules,\224 in Proc of the 12th Int Conf on Industrial and Engineering App AI and Expert Sys 1999 pp 145-154 Lect Notes in Comp Sc Springer-Verlag 30 R Lehn F Guillet and P Kuntz 223Felix an interactive rule mining interface in a kdd process,\224 in Proc of the 10th Mini Euro Conference Human Centered Processes ENST Bretagne France 1999 pp 169-174 31 U.M Fayyad G Piatetsky-Sapiro and P Smyth Eds Ad vances in Knowledge Discovety and Data Mining AAA1 Press 1996 157-166 1994 31 pp 307-328 pp 24-33 19 pp 214-230 1993 


Frequent episode Meaning  service  http  flag  S 0  dst host  victim    service  http  flag  S 0  dst host  victim    service  http  flag  S 0  dst host  victim  0  93  0  03  2 93 of the time after two http connections with S 0 003ag are made to host victim  within 2 seconds from the 002rst of these two the third similar connection is made and this pattern occurs in 3 of the data Table 6 Example Intrusion Pattern in 12  t o s upport t he i t e rat i v e procedure o f p at t e rn mi ning and comparison feature construction from patterns and model building and evaluation In each iteration we choose a different data mining strategy regarding the choices of axis and reference features These choices are limited among the 223essential\224 features see Section 3.2 that is service  dst host  src dst or src port  Since intrusions are generally targeted to some victim host\(s in the network the system starts with service and dst host  5 Experiments We participated in the DARPA Intrusion Detection Evaluation Program prepared and managed by MIT Lincoln Labs The objective of this study was to survey and evaluate the state of the art in research in intrusion detection A standard set of extensively gathered audit data which includes a wide variety of intrusions simulated in a military network environment is provided by DARPA Each participating site was required to build intrusion detection models or tweak their existing system parameters using the training data and send the results i.e detected intrusions on the test data back to DARPA for performance evaluation We report our experience here 5.1 The DARPA data We were provided with about 4 gigabytes of compressed tcpdump data of 7 weeks of network traf\002c This data can be processed into about 5 million of connection records of about 100 bytes each The data contains content i.e the data portion of every packet transmitted between hosts inside and outside a simulated military base BSM audit data from one UNIX Solaris host for some network sessions were also provided Four main categories of attacks were simulated they are 017 DOS denial-of-service for example ping-of-death teardrop smurf syn 003ood etc 017 R2L unauthorized access from a remote machine for example guessing password 017 U2R unauthorized access to local superuser privileges by a local unprivileged user for example various of buffer over\003ow attacks 017 PROBING surveillance and probing for example port-scan ping-sweep etc In addition there were anomalous user behavior such as 223a manager becomes i.e behaves like a system administrator\224 5.1.1 Data Pre-processing We used Bro as the packet 002ltering and reassembling engine We extended Bro to handle ICMP packets and made changes to its packet fragment inspection modules since it crashed when processing data that contains teardrop or ping-of-death attacks We implemented a Bro 223connection 002nished\224 event handler to output a summarized record for each connection Each connection record includes these 223intrinsic\224 features its time  duration  service  src host  dst h ost  src port  wrong fragment fragmentation error e.g fragment size is not multiple of 8 bytes or the offsets are overlapped etc flag how the connection is established and terminated We used Bro event handlers to examine the telnet sessions and extract the shell commands of the users We further pre-processed the shell commands by replacing timestamps with am pm and nt for night and eliminated the input i.e contents of edit and sendmail commands and kept only the 002lename extensions Table 3 shows examples of the processed command data These shell command records were used for user anomaly detection to be discussedinSection5.3 5.2 Misuse Detection The training data from DARPA includes 223list 002les\224 that identify the timestamp source host and port destination host and port and the name of each attack We used this information to select intrusion data to perform pattern mining and feature construction and to label each connection record with 223normal\224 or an attack type to create training data for building classi\002cation models Since the amount of audit data is huge for example some days have several millions of connection records due 7 


to the nasty DOS attacks we did not aggregate all the connection records into a single training data set Instead we extracted all the connection records that fall within a surrounding time window of plus and minus 5 minutes of the whole duration of each attack to create a data set for each attack type We also randomly extracted sequences of normal connections records to create the normal data set 5.2.1 Manual and Automatic Feature Construction Following the feature construction approach described in Section 4 for each attack type e.g syn 003ood port-scan etc we performed pattern mining and comparison using its intrusion data set and the normal data set We constructed appropriate features according to the intrusion only patterns Here we summarize the temporal and statistical features automatically constructed by our system 017 The 223 same host 224 feature that examine only the connections in the past 2 seconds that have the same destination host as the current connection 226 the count of such connections the percentage of connections that have the same service as the current one the percentage of different services the percentage of the S0 003ag and the percentage of the REJ i.e rejected connection 003ag 017 The 223same service\224 features that examine only the connections in the past 2 seconds that have the same service as the current connection 226 the count of such connections the percentage of different destination hosts the percentage of the S0 003ag and the percentage of the REJ 003ag We call these the time-based 223traf\002c\224 features for connection records There are several 223slow\224 PROBING attacks that scan the hosts or ports using a much larger time interval than 2 seconds for example one in every minute As a result these attacks did not produce intrusion only patterns with the time window of 2 seconds We sorted these connection records by the destination hosts and applied the same pattern mining and feature construction process In stead of using a time window of 2 seconds we now used a 223connection\224 window of 100 connections and constructed a mirror set of 223host-based traf\002c\224 features as the timebased 223traf\002c\224 features We discovered that unlike most of the DOS and PROBING attacks the R2L and U2R attacks don't have any 223intrusion only\224 frequent patterns This is because most of the DOS and PROBING attacks involve sending a lot of connections to some host\(s in a very short period of time and therefore can have frequent sequential patterns that are different from the normal traf\002c The R2L and U2R attacks are embedded in the data portions of the packets and normally involve only a single connection Therefore it is unlikely that they can have any unique frequent traf\002c patterns In other words our automatic feature construction process failed to produce any features for these attacks After studying the outcome of this mining process we focussed our attention to the content of the connections In the Bro event handlers we added functions that inspect data exchanges of interactive TCP connections e.g telnet ftp smtp etc These functions assign values to a set of 223content\224 features to indicate whether the data contents suggest suspicious behavior These features are number of failed logins successfully logged in or not whether logged in as root whether a root shell is obtained whether a su command is attempted and succeeded number of access to access control 002les e.g 223/etc/passwd\224 223.rhosts\224 number of compromised states on the destination host e.g 002le/path 223not found\224 errors and 223Jump to\224 instructions etc number of hot indicators e.g access to system directories creation and execution of programs etc and number of outbound connections during a ftp session Our approach here is to include an extensive set of indicators and then let classi\002cation programs decide which minimal set of discriminating features should be used to identify intrusions 5.2.2 Detection Models It is evident that different categories of intrusions require different sets of constructed features in order to be detected We therefore built classi\002cation models using different feature sets 017 The 223traf\002c\224 model each connection record contains the 223intrinsic\224 and the 223traf\002c\224 features Table 7 shows some example labeled connection records The resultant RIPPER classi\002er detects the DOS and PROBING attacks Table 8 shows some example RIPPER rules 017 The host-based 223traf\002c\224 model each connection record contains the 223intrinsic\224 and the host-based 223traf\002c\224 features The resultant RIPPER classi\002ers detect the slow PROBING attacks 017 The 223content\224 model each connection record contains the 223intrinsic\224 and the 223content\224 features Table 1 shows some example labeled connection records The resultant RIPPER classi\002er detects the R2L and U2R attacks Table 2 shows some example RIPPER rules These classi\002cation models each specialize to a certain type of intrusion We then constructed a meta-level classi\002er to combine these detection models Each meta-level training record consists of four features the three predictions each from one of the base models plus the true class label i.e 223normal\224 and an attack type RIPPER was then 8 


label service 003ag host count srv count host REJ  host diff srv  duration  normal ecr i SF 1 1 0 1 0  smurf ecr i SF 350 350 0 0 0  satan user-level REJ 231 1 85 89 0  normal http SF 1 0 0 1 3           Table 7 Example 223Traf\002c\224 Connection Records RIPPER rule Meaning smurf service=ecr i host count 025 5  host srv count 025 5  If the service is icmp echo request and for the past 2 seconds the number of connections that have the same destination host as the current one is at least 5 and the number of connections that have the same service as the current one is at least 5 then this is a smurf attack a DOS attack satan host REJ  025 83  host diff srv  025 87  If for the connections in the past 2 seconds that have same the destination host as the current connection the percentage of rejected connections are at least 83 and the percentage of different services is at least 87 then this is a satan attack a PROBING attack Table 8 Example RIPPER Rules for DOS and PROBING attacks applied to learn the rules that combine the evidence from the 223traf\002c\224 host-based 223traf\002c\224 and 223content\224 classi\002ers to make a 002nal prediction on a connection The resulting meta-level rules basically use the predictions from the 223content\224 model to detect R2L and U2R attacks and the combination of 223traf\002c\224 and host-based 223traf\002c\224 models to detect the DOS and fast and slow PROBING attacks That is the meta-classi\002er predicts a connection as an attack of R2L or U2R whenever the 223content\224 model does so and an attack of DOS or PROBING whenever the 223traf\002c\224 model does so or whenever the 223traf\002c\224 model predicts 223normal\224 but the host-based model predicts a PROBING attack Model  of features  of rules  of features in records in rules content 22 55 11 traf\002c 20 26 4 9 host traf\002c 14 8 1 5 Table 9 Model Complexities Table 9 summarizes the complexity of the base models in terms of the number of features in a connection record the number of RIPPER rules produced and the number of distinct features actually used in the rules The numbers in bold for example 9  indicate the number of automatically constructed temporal and statistical features being used in the RIPPER rules We see that for both the 223traf\002c\224 and host-based 223traf\002c\224 models our feature construction process contribute the majority of the features We should point out that not all features in the connection records were selected by RIPPER This is because RIPPER like most classi\002cation algorithms has a built-in 223feature selection\224 process to select the most discriminating and generalizable features according to their statistical signi\002cance and performance e.g in a hold-out test dataset that simulates the 223unseen/future\224 data Because of the large amount of audit data a human expert is not able to manually gather and test various statistics and thus tend to do a poor job in selecting the features As a result hand crafted 223signature\224 rules tend to be very speci\002c to a small intrusion data set Alternative classi\002cation algorithms that compute underlying probability distributions may indeed require all features be evaluated in their resultant models A crucial issue here is the tradeoff between model accuracy and model cost The RIPPER output indicates that some features are irrelevant and hence we need not compute these at run-time thus reducing the cost of detection This is the subject matter of our ongoing research 5.2.3 Results We report the performance of our detection models as evaluated by MIT Lincoln Labs We trained our intrusion detection models i.e the base models and the meta-level classi\002er using the 7 weeks of labeled data and used them to make predictions on the 2 weeks of unlabeled test data i.e we were not told which connection is an attack The test data contains a total of 38 attack types with 14 types in test data only i.e our models were not trained with instances 9 


  0 10 20 30 40 50 60 70 0 0.05 0.1 0.15 0.2 Detection Rate False Alarm Rate Columbia  Group1   Group2   Group3  a DOS   0 10 20 30 40 50 60 70 80 90 100 0 0.05 0.1 0.15 0.2 Detection Rate False Alarm Rate Columbia  Group1   Group2   Group3  b PROBING   0 10 20 30 40 50 60 70 80 0 0.05 0.1 0.15 0.2 Detection Rate False Alarm Rate Columbia U2R  Group3 U2R   Group3 R2L   Group1 R2L   Columbia R2L  c U2R and R2L   0 10 20 30 40 50 60 70 0 0.05 0.1 0.15 0.2 Detection Rate False Alarm Rate Columbia  Group1   Group3  d Overall Figure 1 ROC Curves on Detection Rates and False Alarm Rates of these attack types Figure 1 shows the ROC curves of the detection models by attack categories as well as on all intrusions In each of these ROC plots the x-axis is the false alarm rate calculated as the percentage of normal connections classi\002ed as an intrusion the y-axis is the detection rate calculated as the percentage of intrusions detected A data point in the upper left corner corresponds to optimal performance i.e high detection rate with low false alarm rate We compare here our models with other participants denoted as Group 1 through 3 in the DARPA evaluation program The tested systems produced binary output hence the ROC's are not continuous These plots are duplicated from the presentation slides of a report given by Lincoln Labs in a DARPA PI meeting The slides can be viewed on line via http://www.cs.columbia.edu 230 sal/JAM/PROJECT/MIT/mitindex.html These participating groups used knowledge engineering approaches to build their intrusion detection models We can see from the 002gure that our detection model has the best overall performance and in all but one attack category our model is one of the best two However it is also clear that all models performed very poorly on R2L attacks For all intrusions an overall detection rate of below 70 is hardly satisfactory in a mission critical environment Category Old New DOS 79.9 24.3 PROBING 97.0 96.7 U2R 75.0 81.8 R2L 60.0 5.9 Overall 80.2 37.7 Table 10 Comparing Detection Rates in  on Old and New Attacks 10 


Although our models were intended for misuse detection we had hoped that the features we constructed would be general enough so that the models can detect new variations of the known intrusions Table 10 compares the detection rates of old intrusions and new intrusions Here new intrusions refer to those that did not have corresponding instances in the training data We see that our models were able to detect a large percentage of new PROBING and U2R attacks but not as effective for new DOS and R2L attacks 5.2.4 Discussion PROBING attacks have relatively limited variance because they all involve making connections to a large number of hosts or ports in a given time frame Likewise the outcome of all U2R attacks is that a root shell is obtained without legitimate means e.g login as root su to root etc Thus for these two categories of attacks given some representative instances in the training data our data mining system was able to construct features that capture their general behavior patterns As a result our detection models can detect a high percentage of old and new PROBING and U2R attacks On the other hand DOS and R2L have a wide variety of behavior because they exploit the weaknesses of a large number of different network or system services The features constructed based on the available attack instances are very specialized to the known attack types Our detection models therefore missed a large number of new DOS and R2L attacks The results here are not entirely surprising since our models are misuse detection models We need to use anomaly detection models on network traf\002c or system programs to guard against the new and diversi\002ed attacks Anomaly detection is much more challenging than misuse detection For example we need to 002rst decide whether we should build normal pro\002le for each network service or a group of services and for each host or a groups of hosts The feature construction process will likely to be more complex since unlike a relatively small number of 223intrusion only\224 patterns normal network traf\002c can have a large number of variations Network anomaly detection is an important problem and an active area of research 5.3 User Anomaly Detection 223Insiders\224 misusing their privileges can be hard to detect since they don't normally need to break-in and IDSs and security personnel tend to focus on guarding outside attacks Insider problems are some of the most vexing problems for security personnel Indeed who checks the checkers i.e the person to whom the IDS reports It is often very dif\002cult to classify a single event by a user as normal or abnormal because the unpredictable nature of most people A user's actions during a login session needs to be studied as a whole to determine whether he or she is behaving normally Our initial exploratory approach is to mine the frequent patterns from user command data and merge or add the patterns into an aggregate set to form the normal usage pro\002le of a user A new pattern can be merged with an old pattern if they have the same left-hand-sides and right-hand-sides their support values are within a 5 of each other and their con\002dence values are also within 5 of each other To analyze a user login session we mine the frequent patterns from the sequence of commands during this session This new pattern set is compared with the pro\002le pattern set and a similarity score is assigned Assume that the new set has n patterns and among them there are m patterns that have 223matches\224 i.e rules that they can be merged with in the pro\002le pattern set then the similarity score is simply m n  Obviously a higher similarity score means a higher likelihood that the user's behavior agrees with his or her historical pro\002le User Normal Activities sysadm logs in as root cats the password 002le and runs commands such as top programmer1 writes public domain C code use a vi editor compiles the C code reads and sends mail and executes unix commands programmer2 a similar user pro\002le but works in afternoons and evenings secretary edits latex 002les runs latex reads mail and sends mail manager1 reads and sends mail manager2 reads mail Table 11 User Descriptions The DARPA data also includes user anomaly data to evaluate anomaly detection systems Table 11 describes the consistent behavior of the 6 users for anomaly analysis Note that since we were the only group that performed anomaly detection on the test data Lincoln Labs did not evaluate our results We report our experiments on the training data here We apply our frequent episode algorithms to the command data from each login session of the same user with command as the axis feature and w 5 i.e we look for patterns within the range of 5 consecutive commands to mine the frequent sequential patterns on the associations among user commands their arguments time segments and hosts We treat the 002rst 4 weeks as a data gathering period during which we simply merge the patterns into each user's pro\002les Each user has 3 pro\002les one for the ac11 


User Anomaly Description programmer2 logs in from beta secretary logs in at night sysadm logs in from jupiter programmer1 becomes a secretary secretary becomes a manager programmer1 logs in at night sysadm becomes a programmer manager1 becomes a sysadm manager2 logs in from pluto Table 12 User Anomaly Description User Normal Anomaly programmer2 0.58 0.79 0.00 secretary  1  1  0.00 sysadm 0.84 0.95 0.00 programmer1 0.31 1.00 0.04 secretary 0.41 0.98 0.17 programmer1  1  1  0.00 sysadm 0.64 0.95 0.00 manager1 0.57 1.00 0.00 manager2 1.00 1.00 0.00 Table 13 Similarity with User's Own Pro\002le tivities of each time segment am pm and nt We treat the 5th week as the training period during which we compare the patterns from each session to the pro\002le of the time segment We record the normal range of the similarity scores during this week The data in the 6th week has some user anomalies as described in Table 12 For each of the anomalous sessions we compare its patterns against the original user's pro\002le and then compare the resulting similarity score against the recorded normal range of the same time segment In Table 13 the column labeled 223Normal\224 is the range of similarity of each user against his or her own pro\002le as recorded during the 5th week A 1 here means that the user did not login during the time segment in the 5th week The column 223Anomaly\224 is the similarity measure of the anomalous session described Table 12 We see that all anomalous sessions can be clearly detected since their similarity scores are much smaller than the normal range For example when the sysadm becomes programmer see Table 12 his/her patterns have zero matches with the sysadm's pro\002le while for the whole 5th week the pm similarity scores are in the range of 0.64 to 0.95 Unfortunately formal evaluation statistics are not available to determine the error rates of this approach However this initial test indicates a path worthy of future study 6 Related Work Network intrusion detection has been an on-going research area 17  M ore r ecent s ystems e g B ro 18   NFR 6  a n d EMERALD  1 9  a ll mad e e x ten s ib ility th eir primary design goals Our research focuses on automatic methods for constructing intrusion detection models The meta-learning mechanism is designed to automate the extention process of IDSs We share the same views discussed in 20 t h at an ID S s houl d b e b ui l t us i n g s t a ndard components We believe that the operating system and networking community should be responsible for building a robust 223Event\224 box In 10  a l gori t h ms for a nal y zi ng us er s h el l c ommands and detecting anomalies were discussed The basic idea is to 002rst collapse the multi-column shell commands into a single stream of strings and then string matching techniques and consideration of 223concept drift\224 are used to build and update user pro\002les We believe that our extended frequent episodes algorithm is a superior approach because it considers both the association among commands and arguments and the frequent sequential patterns of such associations 7 Conclusions and Future Directions In this paper we outline a data mining framework for constructing intrusion detection models The key idea is to apply data mining programs to audit data to compute misuse and anomaly detection models according to the observed behavior in the data To facilitate adaptability and extensibility we propose the use of meta-learning as a means to construct a combined model that incorporate evidence from multiple lightweight base models This mechanism makes it feasible to introduce new ID components in an existing IDS possibly without signi\002cant re-engineering We extend the basic association rules and frequent episodes algorithms to accommodate the special requirements in analyzing audit data Our experiments show that the frequent patterns mined from audit data can be used as reliable user anomaly detection models and as guidelines for selecting temporal statistical features to build effective classi\002cation models Results from the 1998 DARPA Intrusion Detection Evaluation Program showed our detection models performed as well as the best systems built using the manual knowledge engineering approaches Our future work includes developing network anomaly detection strategies and devising a mechanical procedure to translate our automatically learned detection rules into modules for real-time IDSs A preliminary project in collaboration with NFR has just started 12 


8 Acknowledgments We wish to thank our colleagues at Columbia University Chris Park Wei Fan and Andreas Prodromidis for their help and encouragement References 1 R  A g r a w a l  T  I m i e lin sk i a n d A  S w a m i  M in in g a sso c i a tion rules between sets of items in large databases In Proceedings of the ACM SIGMOD Conference on Management of Data  pages 207\226216 1993 2 P  K  C han a nd S  J S t ol f o  T o w ar d p ar al l e l a nd di st r i b u t e d learning by meta-learning In AAAI Workshop in Knowledge Discovery in Databases  pages 227\226240 1993 3 W  W  C ohen Fast ef f ect i v e r ul e i nduct i on I n Machine Learning the 12th International Conference  Lake Taho CA 1995 Morgan Kaufmann 4 U  F ayyad G P i at et sk yS h api r o and P  S myt h  T he KDD process of extracting useful knowledge from volumes of data Communications of the ACM  39\(11\:27\22634 November 1996 5 K  I l gun R  A K e mmer e r  and P  A  P or r a s S t at e t r a nsition analysis A rule-based intrusion detection approach IEEE Transactions on Software Engineering  21\(3\:181\226 199 March 1995 6 N  F  R  I n c  N etw o rk 003ig h t reco rd er  h ttp www n fr co m  1997 7 V  J acobson C  L e r e s and S  M cC anne t cpdump a v ai l a bl e via anonymous ftp to ftp.ee.lbl.gov June 1989 8 C  K o  G Fin k  a n d K  L e v itt Au to m a te d d e t e c tio n o f v u l nerabilities in privileged programs by execution monitoring In Proceedings of the 10th Annual Computer Security Applications Conference  pages 134\226144 December 1994 9 S  K umar and E  H  S paf f or d A s of t w ar e a r c hi t ect ur e t o support misuse intrusion detection In Proceedings of the 18th National Information Security Conference  pages 194\226 204 1995  T  L a ne and C  E  B r odl e y  S equence m at chi n g a nd l ear ni ng in anomaly detection for computer security In AAAI Workshop AI Approaches to Fraud Detection and Risk Management  pages 43\22649 AAAI Press July 1997  W  L e e a nd S  J S t ol f o  D at a m i n i n g a ppr oaches f o r i nt r u sion detection In Proceedings of the 7th USENIX Security Symposium  San Antonio TX January 1998  W  L ee S  J S t ol f o  a nd K W  Mok Mi ni ng i n a d at a\003 o w environment Experience in intrusion detection submitted for publication March 1999  T  L unt  D et ect i n g i nt r uder s i n comput er syst ems I n Proceedings of the 1993 Conference on Auditing and Computer Technology  1993  T  L unt  A  T amar u F  Gi l h am R  J agannat h an P  N eumann H Javitz A Valdes and T Garvey A real-time intrusion detection expert system IDES 002nal technical report Technical report Computer Science Laboratory SRI International Menlo Park California February 1992  H Manni l a and H  T oi v onen Di sco v e r i ng gener a l i zed episodes using minimal occurrences In Proceedings of the 2nd International Conference on Knowledge Discovery in Databases and Data Mining  Portland Oregon August 1996  H Manni l a  H  T oi v onen and A  I  V er kamo D i s co vering frequent episodes in sequences In Proceedings of the 1st International Conference on Knowledge Discovery in Databases and Data Mining  Montreal Canada August 1995  B M ukherjee L T  Heberlein and K  N  L e v itt Netw ork intrusion detection IEEE Network  May/June 1994  V  Paxon B r o  A syst em f o r d et ect i n g n et w o r k i n t r uder s in real-time In Proceedings of the 7th USENIX Security Symposium  San Antonio TX 1998  P  A P o r r a s a nd P  G Neumann E m er al d E v ent m oni t o r i ng enabling responses to anomalous live disturbances In National Information Systems Security Conference  Baltimore MD October 1997  S  S t ai nf or dC h en C ommon i nt r u si on det ect i o n f r a me w o r k  http://seclab.cs.ucdavis.edu/cidf  S  J S t ol f o  A  L  P r odr omi d i s  S  T sel e pi s W  L ee D W  Fan and P K Chan JAM Java agents for meta-learning over distributed databases In Proceedings of the 3rd International Conference on Knowledge Discovery and Data Mining  pages 74\22681 Newport Beach CA August 1997 AAAI Press  S unS of t  Mount ai n V i e w  C A  SunSHIELD Basic Security Module Guide  13 


 30 40 50 60 70 80 90 100 110 120 30 40 50 60 70 80 90 10 0 Execution Time [s Number of Nodes Figure 13 Execution time of HPA program pass 2 on PC cluster 2 Scan the transaction database and count the support count Each processing node reads the transaction database from its local disk 000 itemsets are generated from that transaction and the same hash function used in phase 1 s applied to each of them Each of the 000 itemsets is sent to certain processing node according the hash value For the itemsets received from the other nodes and those locally generated whose ID equals the node\220s ID the hash table is searched If hit its support count value is incremented 3 Determine the large itemset After reading all the transaction data each processing node can individually determine whether each candidate 000 itemset satisfy user-specified minimum support or not Each processing node sends large 000 itemsets to the coordinator where all the large 000 itemsets are gathered 4 Check the terminal condition If the large 000 itemsets are empty the algorithm terminates Otherwise the coordinator broadcasts large 000 itemsets to all the processing nodes and the algorithm enters the next iteration 4.2 Performance evaluation of HPA algorithm The HPA program explained above is implemented on our PC cluster Each node of the cluster has a transaction data file on its own hard disk Transaction data is produced using data generation program developed by Agrawal designating some parameters such as the number of transaction the number of different items and so on The produced data is divided by the number of nodes and copied to each node\220s hard disk The parameters used in the evaluation is as follows The number of transaction is 5,000,000 the number of different items is 5000 and minimum support is 0.7 The size of the data is about 400MBytes in total The message block size is set to be 16KBytes according to the results of communication characteristics of PC clusters discussed in previous section The disk I/O block size is 64KBytes which seems to be most suitable value for the system Note that the number of candidate itemset in pass 2 s substantially larger than for the other passes which relatively frequently occurs in association rules mining Therefore we have been careful to parallelize the program effectively especially in pass 2 so that unnecessary itemsets to count should not be generated 14 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


The execution time of the HPA program pass 2 is shown in figure 13 as the number of PCs is changed The maximum number of PCs used in this evaluation is 100 Reasonably good speedup is achieved in this application as the number of PCs is increased 5 Conclusion In this paper we presented performance evaluation of parallel database processing on an ATM connected 100 node PC cluster system The latest PCs enabled us to obtain over 110Mbps throughput in point-to-point communication on a 155Mbps ATM network even with the so-called 217\217heavy\220\220 TCP/IP This greatly helped in developing the system in a short period since we were absorbed in fixing many other problems Massively parallel computers now tend to be used in business applications as well as the conventional scientific computation Two major business applications decision support query processing and data mining were picked up and executed on the PC cluster The query processing environment was built using the results of our previous research the super database computer SDC project Performace evaluation results with a query of the standard TPC-D benchmark showed that our system achieved superior performance especially when transposed file organization was employed As for data mining we developed a parallel algorithm for mining association rules and implemented it on the PC cluster By utilizing aggregate memory of the system efficiently the system showed good speedup characteristics as the number of nodes increased The good price/performance ratio makes PC clusters very attractive and promising for parallel database processing applications All these facts support the effectiveness of the commodity PC based massively parallel database servers Acknowledgment This project is supported by NEDO New Energy and Industrial Technology Development Organization in Japan Hitachi Ltd technically helped us extensively for ATM related issues References  R Agrawal T Imielinski and A Swami Mining association rules between sets of items in large databases In Proceedings of ACM SIGMOD International Conference on Management of Data  pages 207--216 1993  R Agrawal and R Srikant Fast algorithms for mining association rules In Proceedings of International Conference on Very Large Data Bases  1994  A C Arpaci-Dusseau R H Arpaci-Dusseau D E Culler J M Hellerstein and D A Patterson High-performance sorting on Networks of Workstations In Proceedings of International Conference on Management of Data  pages 243--254 1997  D.S Batory On searching transposed files ACM TODS  4\(4 1979  P.A Boncz W Quak and M.L Kersten Monet and its geographical extensions A novel approach to high performance GIS processing In Proceedings of International Conference on Extending Database Technology  pages 147--166 1996 15 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


 R Carter and J Laroco Commodity clusters Performance comparison between PC\220s and workstations In Proceedings of IEEE International Symposium on High Performance Distributed Computing  pages 292--304 1995  D.J DeWitt and J Gray Parallel database systems  The future of high performance database systems Communications of the ACM  35\(6 1992  J Gray editor The Benchmark Handbook for Database and Transaction Processing Systems  Morgan Kaufmann Publishers 2nd edition 1993  J Heinanen Multiprotocol encapsulation over ATM adaptation layer 5 Technical Report RFC1483 1993  M Kitsuregawa M Nakano and M Takagi Query execution for large relations on Functional Disk System In Proceedings of International Conference on Data Engineering  5th pages 159--167 IEEE 1989  M Kitsuregawa and Y Ogawa Bucket Spreading Parallel Hash:A new parallel hash join method with robustness for data skew in Super Database Computer SDC In Proceedings of International Conference on Very Large Data Bases  16th pages 210--221 1990  M Laubach Classical IP and ARP over ATM Technical Report RFC1577 1994  D.A Schneider and D.J DeWitt Tradeoffs in processing complex join queries via hashing in multiprocessor database machines In Proceedings of International Conference on Very Large Data Bases  16th pages 469--480 1990  T Shintani and M Kitsuregawa Hash based parallel algorithms for mining association rules In Proceedings of IEEE International Conference on Parallel and Distributed Information Systems  pages 19--30 1996  T Sterling D Saverese D.J Becker B Fryxell and K Olson Communication overhead for space science applications on the Beowulf parallel workstaion In Proceedings of International Symposium on High Performance Distributed Computing  pages 23--30 1995  T Tamura M Nakamura M Kitsuregawa and Y Ogawa Implementation and performance evaluation of the parallel relational database server SDC-II In Proceedings of International Conference on Parallel Processing  25th pages I--212--I--221 1996  TPC TPC Benchmark 000\001 D Decision Support Standard Specification Revision 1.1 Transaction Processing Performance Council 1995 16 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


In accordance with 1910.97 and 1910.209 warning signs are required in microwave areas For work involving power line carrier systems this work is to be conducted according to requirements for work on energized lines Comments s APPA objects to the absolute requirement implied by the word ensure regarding exposure to microwave radiation and recommends revision of s l iii to read when an employee works in an area where electromagnetic radiation levels could exceed the levels specified in the radiation protection guide the employer shall institute measures designed to protect employees from accidental exposure to radiation levels greater than those permitted by that guide  I1 an employee must be stationed at the remote end of the rodding operation Before moving an energized cable it must be inspected for defects which might lead to a fault To prevent accidents from working on the wrong cable would require identification of the correct cable when multiple cables are present Would prohibit an employee from working in a manhole with an energized cable with a defect that could lead to a fault However if the cable cannot be deenergized while another cable is out employees may enter the manhole but must protect against failure by some means for example using a ballistics blanket wrapped around cable Requires bonding around opening in metal sheath while working on cable Underaround EIectrical Installations t Comments t This paragraph addresses safety for underground vaults and manholes The following requirements are contained in this section Ladders must be used in manholes and vaults greater than four feet deep and climbing on cables and hangers in these vaults is prohibited Equipment used to lower materials and tools in manholes must be capable of supporting the weight and should be checked for defects before use An employee in a manhole must have an attendant in the immediate vicinity with facilities greater than 250 volts energized An employee working alone is permitted to enter briefly for inspection housekeeping taking readings or similar assuming work could be done safely Duct rods must be inserted in the direction presenting the least hazard to employees and APPA recommends that OSHA rewrite section 7\regarding working with defective cables This rewrite would include the words shall be given a thorough inspection and a determination made as to whether they represent a hazard to personnel or representative of an impending fault As in Subsection \(e EEI proposes the addition of wording to cover training of employees in emergency rescue procedures and for providing and maintaining rescue equipment Substations U This paragraph covers work performed in substations and contains the following requirements Requires that enough space be provided around electrical equipment to allow ready and safe access for operation and maintenance of equipment OSHA's position A2-16 


is that this requirement is sufficiently performance oriented to meet the requirements for old installations according to the 1987 NEW Requires draw-out circuit breakers to be inserted and removed while in the open position and that if the design permits the control circuits be rendered inoperative while breakers are being inserted and removed stated in the Rules and requests that existing installations not be required to be modified to meet NESC APPA recommends that Section u 4 i which includes requirements for enclosing electric conductors and equipment to minimize unauthorized access to such equipment be modified to refer to only those areas which are accessible to the public Requires conductive fences around substations to be grounded Power Generation v Addresses guarding of energized parts  Fences screens, partitions or walls This section provides additional requirements and related work practices for power generating plants  Entrances locked or attended Special Conditions w  Warning signs posted  Live parts greater than 150 volts to be guarded or isolated by location or be insulated  Enclosures are to be according to the 1987 NESC Sections llOA and 124A1 and in 1993 NESC  Requires guarding of live parts except during an operation and maintenance function when guards are removed barriers must be installed to prevent employees in the area from contacting exposed live parts Requires employees who do not work regularly at the substation to report their presence Requires information to be communicated to employees during job briefings in accordance with Section \(c of the Rules Comments U APPA and EEI provide comments as follows Both believe that some older substations \(and power plants would not meet NESC as This paragraph proposes special conditions that are encountered during electric power generation, transmission and distribution work including the following Capacitors  Requires individual units in a rack to be short circuited and the rack grounded  Require lines with capacitors connected to be short circuited before being considered deenergized Current transformer secondaries may not be opened while energized and must be bridged if the CT circuit is opened Series street lighting circuits with open circuit voltages greater than 600 volts must be worked in accordance with Section q\or t and the series loop may be opened only after the source transformer is deenergized and isolated or after the loop is bridged to avoid open circuit condition Sufficient artificial light must be provided where insufficient naturals illumination is present to enable employee to work safely A2-17 


US Coast Guard approved personal floatation devices must be supplied and inspected where employees are engaged in work where there is danger of drowning Required employee protection in public work areas to include the following  Warning signs or flags and other traffic control devices  Barricades for additional protection to employees  Barricades around excavated areas  Warning lights at night prominently displayed Lines or equipment which may be sub to backfeed from cogeneration or other sources are to be worked as energized in accordance with the applicable paragraphs of the Rules Comments w APPA submits the following comments regarding this Special Conditions section Recommends that the wording regarding capacitors be modified to include a waiting period for five minutes prior to short circuiting and grounding in accordance with industry standards for discharging of capacitors For series street light circuits, recommends that language be added for bridging to either install a bypass conductor or by placement of grounds so that work occurs between the grounds Recommends modification of the section regarding personal floatation devices to not apply to work sites near fountains decorative ponds swimming pools or other bodies of water on residential and commercial property Definitions x This section of the proposed Rules includes definitions of terms Definitions particularly pertinent to understanding the proposal and which have not previously been included are listed as follows Authorized Employee  an employee to whom the authority and responsibility to perform a specific assignment has been given by the employer who can demonstrate by experience or training the ability to recognize potentially hazardous energy and its potential impact on the work place conditions and who has the knowledge to implement adequate methods and means for the control and isolation of such energy CZearance for Work  Authorization to perform specified work or permission to enter a restricted area Clearance from Hazard  Separation from energized lines or equipment Comments x The following summarizes the changes in some of the definitions which APPA recommends Add to the definition for authorized employee It the authorized employee may be an employee assigned to perform the work or assigned to provide the energy control and isolation function  Recommends that OSHA modify the definition for a line clearance tree trimmer to add the word qualified resulting in the complete designation as a qualified line clearance tree trimmer Recommends that OSHA modify the definition of qualified employee" to remove the word construction from the definition since it is felt that knowledge of construction procedures is beyond the scope of the proposed rule resulting in APPA's new A2-18 I 


wording as follows more knowledgeable in operation and hazards associated with electric power generation transmission and/or distribution equipment Recommends that OSHA add a definition for the word practicable and replace the word feasible with practicable wherever it appears in the proposed regulations and that practicable be further defined as capable of being accomplished by reasonably available and economic means OTHER ISSUES Clothing OSHA requested comments on the advisability of adopting requirements regarding the clothing worn by electric utility industry employees EEI has presented comments which indicates research is underway prior to establishing a standard for clothing to be worn by electric utility employees However EEI's position is that this standard has not developed to the extent that it could be included in the OSHA Rules Both APPA and EEI state that they would support a requirement that employers train employees regarding the proper type of clothing to wear to minimize hazards when working in the vicinity of exposed energized facilities Grandfathering Due to the anticipated cost impact on the utility industry of the proposed Rules requiring that existing installations be brought to the requirements of the proposed Rules both APPA and EEI propose that the final Rules include an omnibus grandfather provision This provision would exempt those selected types of facilities from modification to meet the new rules EEI states that if the grandfathering concept is incorporated that electric utility employees will not be deprived of proper protection They propose that employers be required to provide employees with a level of protection equivalent to that which the standard would require in those instances in which the utility does not choose to modify existing facilities to comply with the final standard Rubber Sleeves OSHA requests comments from the industry on whether it would be advisable to require rubber insulating sleeves when gloves are used on lines or equipment energized at more than a given voltage EEI states its position that utilities should continue to have the option of choosing rubber gloves or gloves and sleeves to protect employees when it is necessary to work closer to energized lines than the distances specified in the clearance tables Preemuting State Laws EEI requests that the final Rules be clear in their preempting state rules applicable to the operation and maintenance work rules for electric power systems. This is especially critical since some states now have existing laws which are more stringent than the proposed OSHA Rules Examples are 1 in California and Pennsylvania where electric utility linemen are prohibited from using rubber gloves to work on lines and equipment energized at more than certain voltages and 2 in California and Connecticut where the live line bare hand method of working on high voltage transmission systems is prohibited One utility Pacific Gas  Electric has obtained a variance from the California OSHA to perform live line bare-hand transmission maintenance work on an experimental basis Coiiflicts Between the Rilles and Part 1926 Subpart V Since many of the work procedures in construction work and operation and maintenance work are similar and difficult to distinguish between EEI requests that the final order be clear in establishing which rule has jurisdiction over such similar work areas A2-19 v 


IMPACTS ON COSTS AND ASSOCIATED BENEFITS In its introduction to the proposed rules OSHA has provided an estimate of the annual cost impact on the electric utility industry for the proposed des of approximately 20.7 million OSHA estimates that compliance with this proposed standard would annually prevent between 24 and 28 fatalities and 2,175 injuries per year The utilities which have responded to this proposed standard through their respective associations have questioned the claims both of the magnitude of the cost involved and the benefit to the industry in preventing fatalities and lost-time injuries Both EEI and APPA feel that the annual cost which OSHA estimates are significantly lower than would be realized in practice Factors which APPA and EEI feel were not properly addressed include the following OSHA has not accurately accounted for cost of potential retroactive impacts including retrofitting and modifying existing installations and equipment OSHA has not consistently implemented performance based provisions in proposed rules  many portions require specific approaches which would require utilities to replace procedures already in place with new procedures Estimates were based on an average size investor-owned utility of 2,800 employees and an average rural cooperative of 56 employees, which are not applicable to many smaller systems such as municipal systems OSHA has not adequately addressed the retraining which would be necessary with modifying long-established industry practices to be in accordance with the OSHA rules EEI claims that OSHA's proposed clearance requirements would not allow the use of established maintenance techniques for maintaining high voltage transmission systems and thus would require new techniques For an example of the cost which is estimated to be experienced as a result of the new Rules one of the EEI member companies has estimated that approximately 20,000 transmission towers would need to be modified to accommodate the required step bolts in the Rules at an estimated cost of 6,200,000 Additionally this same company estimates that the annual cost of retesting live line tools for its estimated 1,000 tools would be 265,000 Additionally, both EEI and APPA question the additional benefits which OSHA claims would result from implementation of the new Rules APPA questions the estimates of preventing an additional 24 to 28 fatalities annually and 2,175 injuries per year in that it fails to account for the fact that the industry has already implemented in large part safety measures which are incorporated in the Rules EEI and APPA also point out that many preventable injuries cannot be eliminated despite work rules enforcement and safety awareness campaigns since many such accidents which result in fatalities are due to employee being trained but not following the employer's training and policies PRESENT STATUS OF RULES According to information received from the OSHA office in February 1993 the final Rules are to be published no later than July 1993 and possibly as soon as March 1993 OSHA closed their receipt of comments in March 1991 and no further changes in the rules are thought possible A2-20 


CONCLUSION The OSHA 1910.269 which proposes to cover electric utility operation and maintenance work rules affects a multitude of working procedures as are summarized in this paper It is not possible at the present time to assess the final structure of the Rules as may be proposed in 1993 or subsequent years Since the comments from the utility associations APPA and EEI were made following the initial release of the proposed OSHA Rules in 1989 a significant amount of time has elapsed where other events have occurred which may affect the form of the final Rules The 1993 NESC went into effect in August 1992 and includes some of the requirements to which the commenters objected For example a significant requirement in the Part 4 of the 1993 NESC requires that rubber gloves be utilized on exposed energized parts of facilities operating at 50 to 300 volts This requirement is in conflict with EEl\222s proposed change to the OSHA Rules which would still allow working such secondary facilities without the use of rubber gloves Electric utilities are advised to review the January 31 1989 proposed operation and maintenance Rules as summarized in this paper and to review their procedures which would be affected by application of the Rules Many of the procedures proposed in the Rules provide valuable guidance in electric utilities\222 operation and maintenance activities Where the cost impact is not significant, it is recommended that utilities consider implementing such procedures in expectation of the Rules being published in the next few months Also it would be appropriate for electric utilities to review the 1993 edition of the NESC since there are portions of the Rules which have resulted in changes in the NESC These changes mainly occur in Part 4 Rules for the Operation of Electric Supply and Communications Lines and Equipment The concerns which the commenters have addressed regarding the cost impact and the resulting benefits experienced as a result of the promulgation of the Rules are real ones and must be addressed in the final Rules As a result this paper cannot present a conclusion regarding the full impact of the Rules The development of such Rules continue to be an ongoing matter and will undoubtedly require later analysis when the final rules are published A2-21 



Proceedings of the First International Conference on Machine Learning and Cybernetics Beijing 45 November 2002 MINING FREQUENT ITEMSETS WITH TOUGH CONSTRAINTS LEI JIA REN-QING PEI SONG-QIAN ZHANG School of Mechatronics and Automation,Shanghai University,Shanghai,China E-MAIL jialei7829@hotmail.com prq44@botmail.com zhangsongqian2002@hotmail.com Abstract In order to efficiently sift the useful ones through a large number of mined rules the constraint-based mining is introduced Two large clssses of constraints-monotone constraints and succinct constraints 
have been investigated However, the problem of frequent itemsets mining with tough constraints has not been solved because of the complexity of the constraints In this paper we propose two methods which use the order as the pre-proeess to solve this problem The first method is to push the tough constraints deeply inside the candidate generation-and-test approach such as Apriori. The second is to combine the constraints with the the pattern growth methods such as FP-tree Keywords 
Data mining Association rules Frequent item-sets Tough constraints 1 Introduction Data mining is to efficiently discover interesting rules from large collections of data The problem of mining association rules 1,2.31 have been the subject of numerous studies The standard frame of mining association rules is S C\(Support-Confidence Firstly we have to find the frequent item sets whose support is above preset min support then we calculate the ratio of the confidence If the ratio is above the preset min-confidence, the rule is what we want to find After determining the frequent item 
sets, the solution to calculate the confidence ratio is rather straightforward So we focus on how to find the frequent itemsets efficiently However frequent pattern mining often generates a very large number of frequent itemsets and rules We have to sift through them to find the rules we are interested in This is complicated and difficult work Recently some researchers have proposed the frequent itemsets mining with constraints 14 Using the constraints we can put our focus on the part of the database where we want to mine then find the useful rules The constraints that we often use can 
be sorted into three kinds through the assemble function Distributive such as count mount max min Algebraic such as average standard-deviation Holistic such as median mode From the property, the constraints can also be classified into three kinds: Monotone include monotone and Anti monotone Succinct and Neither monotone nor succinct Tough Constraint Monotone constraints have the property if the itemsets at the level m satisfy the constraints the superset of the itemsets at the level m+l also satisfy the constraints. Anti monotone constraints have the property if the itemsets at the level m don't satisfy the constraints the superset of the itemsets at the level m+l also don't satisfy 
the constraints If we can explicitly and precisely generate all the itemsets satisfying the constraints we call the constraints succinct constraints However for the neither monotone nor succinct constraints it is difficult to be put it into the usual algorithms so we call it Tough constraints In paper 51 the researchers have already studied the frequent itemsets mining with monotone and succinct constraints However toward the Tough constraints he propose to convert it to weaker constraints It cannot solve the problem completely In paper 61 the researchers have brought forward the notion Convertible Constraints They convert the tough 
constraints to monotone and succinct constraints through ordering the data at first Let us introduce the concept of prefix E.g a is the prefix of ad and ad is the p~fix of adg Suppose we have the items a,d,g,s,j,l and set a=30, d=10 g=15 s=O j=20,1=5 choose avg S 25 as the constraint We can easily find the constraint is tough if the items are placed in this order.'But if we re-order the items in descendent order the constraint has been converted to monotone So we conclude that after careful pre-process such as re-order the items tough constraints 
can he converted to monotone constraint There have been many algorithms developed for fast mining of frequent patterns which can be classified into two categories The first category is"candidate generation and-test approach such as Apriori The second category is pattern-growth methods such as FI-tree In this paper we will study how to use the algorithms that belongs to the two categories to solve the problem of mining frequent itemsets with Tough constraints 2 Using the generation-and-test approach to mine frequent itemsets with Tough constraints 0-7803-7508-4/02/$17.00 a002 IEEE 459 


Proceedtq of the First International Conference on Machine Learning and Cybernetics Beijing 45 November 2002 new=Generate\( I-item seed.db new I I Return target Fig new=Generate Litem filter and Select\(new target+=Select\(seed Return target 0 Figure 2 The classical gertcLauuLl-a,u-Lest approach is Apriori Algorithm When we use it to mine frequent itemsets with Tough constraints we have two choice. Firstly we can use the original Apriori Algorithm to mine the fresuent itemsets then test,them with the constraints Figurel The other is to push the Tough constraints deeply into the Apriori Algorithm Figure2 Beacause the Apriori Algorithm satisfies the i-monotone property we can convert the Tough constraints at first then it can combine with the Apriori Algorithm If we use the first choice we will mine a lot of useless frequent itemsets In order to decrease the waste ratio and increase the efficiency we choose the second one in this paper Suppose we have an may of items I=[a,b,c,d,e,f,g,h and transaction databases Table 2 we assume the minSup=2 and set the number to the item \(Table I Table 1 Item la b IC Id le If lg I h Val 140 10 1-20 1 10 1-30 130 120 1-10 Table 2 Transaction I Items in transaction 1 After ordering the item in value-descending order and test it with the minSup we get the table 3 Suppose the Tough constraint is avg SI 325 After the order we find it has been converted to anti-monotone Table 3 in transaction a,f,d,b,c 40 Level 1  The candidate 1-itemset satisfies avg S 325 is a and f After the minSup test, we conclude the frequent itemsets satisfy the constraints at level-1 is are and f Level-2 According the Apriori Algorithm af must be the frequent itemsets We also have to add the intersection of the frequent itemsets and the unfrequent itemsets at the previous level Although g,d,b,c and e are not frequent itemset at level-I the intersection between them and a or f may be the frequent one at level-2 After generating the intersection we can use the anti-monotone property when we test them with the constraint We find ag and ad satisfy the constraint, but ab doesn't So we don't need to consider ac and ae they cannot be frequent one according the anti-monotone property We also find fg satisfies and fd doesn't so we stop the generation After the minSnp test We conclude the frequent itemsets satisfy the constraints at level-2 are ad and fg Level-3 460 


According to the method we propose when we find the frequent itemsets at level-2 we can find afd is what we want to find Finally we elicit the frequent itemsets in table 3 which satisfy the constraints and pre-set minSup are a,f,af,ad,fg and afd This idea can also be used on the Tough constraints can be converted to monotone constraint Thus we propose the TCA Algorithm Tough Constraint based Apriori Algorithm Input T[l]\(After order\MinSup Tough Constraint Output frequent itemsets 1 Ll=[large 1-itemsets 2 L1=l L1 n Constraintl TCA Algorithm   4 T[Z]=get_filtered\(T[l L1 5 for\(k=Z;Lk-l Q;k Ck'=apriori_gen\(Lk 1 6 7 ck=\(Lk-i Li if\(Tough Constraint is anti-monotone after order  8 9 Ck=test Ck according to the anti-monotone IO 9 IO Ck=Ck'+Ck 13 forall transactions tE T[21 14 Ct=subset\(Ck,t 15 forall candidates CE Ct do 16 c.count 17 end 18 Lk=\(c\200 Cklc.count2MinSup 19 end propew if\(Tougb Constraint is monotone after order Ck=test Ck according to the monotone property AosweF U kLk 3 Using the pattern-growth approach to mine frequent itemsets with Tough constraints The principle of the pattern-growth approach is that we don't have to generate the candidate itemsets We can use structure such as tree 71 or some hyper-structure to mine the frequent itemsets We can also push the constraint deep into this approach This method is efficient not only because we don't generate the candidate frequent itemstes but also that we can make full use of the anti-monotone property when we generate the frequent itemsets with the constraints But we need more pre-process We also use the same data array and constraints that we use in section 2 After re-order we can find b cannot be in the frequent itemsets because the average between it and the max one a doesn't satisfy the constraints. Accordint to the anti-monotone property c and e are all be deleted when we constmct the pattern-growth stmcture According to FP-tree Algorithm 17 we can get the frequent itemsets through the FP-tree \(figure3 n zI g    z f2 g:2 Proceedings of the First International Conference on Machine Learning and Cybernetics Beijing 4-5 November 2002 461 g,,,g--g,,,g  c:l __ c 1 e 1 e 1 N I We use the real line if they are in the same embranchment and the broken line for the same item in the different embranchment We need not to consider the pattern under the bold real line We can get the conditional FP-tree Table 4 and the frequent itemsets \(Table 5 Table 4 I Item I conditional pattern I conditional FP I base tree d  a:2,f2  f l,g I   a:2,f3  f  a:2 f2J  f2 Jlg m Table 5 I length  Frequent-itemsets  I A m At last we can test with the constraint avg 2 225 We get the frequent itemsets satisfy the Tough constraint and the minSup are a,f,af,ad,afd,fg We can find after the careful pre-process the Waste ratio is small 


Proceedings of the First International Conference on Machine Learning and Cybernetics Beijing 4-5 November 2002 4 Concksions It is a complicated and difficult work to sift the useful knowledge through a very large number of frequent itemsets and rules So we introduce to mine the frequent itemsets with constraints It will help us to focus on the part of the databases where we are interested Some researchers have studied the frequent itemsets mining with monotone and succinct constraints However toward the Tough constraints they haven't solved it completely In this paper we use the generation-and-test approach and the pattern growth approach to solve the puzzle After introducing the mining with constraints the user will have opportunity to join the mining course which is really a black-box The user can find the useful rules directly Although many researchers have already devoted to this field a lot of questions have not been solved, such as mining with multi-constraints and mining with multi support multi-constraints. We will explore these problems I References l R Agrawal T Imielinski ASwami Mining association rules between sets of items in large databases. SIGMOD 93,pp 207-216 2 R.Agrawal R.Srikant Fast slgorithms for mining association rules VLDB 94,pp 487-499  J.Han Y.Fu Discovery of multiple-level association rules from large databases VLDB 95,pp 420-431 4 R.Srikant, Q.Vu R.Agrawa1 Mining associstion rules with item constraints In Proc 1997 Int Conf Knowledge Discovery and Data mining KD D97 pages67-73, NewBeach CA Aug 1997 5 R.Ng,L.V.S.Lakshmanan,J.Han A.Pang Explor-atory mining and pruning optimizations of con-strained associations rules In Proc 1998 ACM-SIGMOD Int Conf. Management of Data SIG MOD98 pages 13 24,Seattle WA,June 1998 61 J.Pei J.Han L.V.S.Lakshmanan Mining frequent itemsets with convertible constraints In ICD E'OI pages 323-332 7 J.Han,J Pei Y.Yin Mining frqGent patterns without candidate generation In SIGMODOO pages 1-12 8 J.Pei,J.Han H.Lu S,Nishio et,al H-Mine Hyper Structure Mining of frequent Patterns in Large Databases Proc.2001 1nt.Conf On Data Mining ICDMOl San Jose CA Nov.2001 462 


ROOT/Publications/Article/Journal/@publisher ROOT/Publications/Article/Conference/@name HEAD  ROOT/Award/@society EXTRACTING RULES WITH SUPPORT  0.1 AND CONFIDENCE  0.2 HEAD  ROOT/Author WHERE ROOT//@year  2001 EXTRACTING RULES WITH SUPPORT  0.1 AND CONFIDENCE  0.2 AND SOME a IN BODY SATISFIES not\(empty\(//People/*/PersonalInfo/Name[=$a Example 5 In XML there is a slight distinction between the document data and the document structure Accordingly with XMINE we can intermix data and structural information in the same mining task As an example consider the problem of discovering which kinds of awards may influence the career i.e best correlates with the specific position of the members of the department This mining task can be expressed through the following statement The WHERE clause has an obvious side effect on the generated rules since all the publications that do not satisfy the condition are pruned before rule generation Therefore the resulting context is a subset of the previous one and both support and confidence take different values Note that the WHERE clause is just a filtering condition not a constraints This means that the WHERE clause must be considered before the association rules are generated Example 3 So far we presented rules in which the head and body fragment sets are defined by the same path expressions and thus pertain to the same domain The next example shows instead rules mining collaborations extracting authors when they publish papers on the same topic This means that the rule HEAD will be extracted from the Author elements and the rule BODY from the Keyword elements A proper association between authors and keywords imposes that the ROOT be set as /People Publications all publications X MINE RULE IN document\(.www.atlantis.edu/research.xml FOR ROOT IN People LET BODY  ROOT/Award/@society HEAD  ROOT/name EXTRACTING RULES WITH SUPPORT  0.1 AND CONFIDENCE  0.2 Note that the the positions covered by the members are expressed as different tagnames that are related to the document structure and not as regular data In order to compactly denote all career of a Department's member the HEAD definition exploits the XPath name step that extract the tagname of the items to which it is applied This feature is particularly relevant when the mining activity is addressed arbitrary tags in arbitrary positions e.g when documents describe the same application domain with different Dills Additional Features There are other features of X MINE that are not discussed here Probably the most relevant is the GROUP BY clause that can be use to restructure the source data when these do not allow the specification of adequate rule context We refer the reader to 6 5 for further details X MINE RULE IN document\(nwww.atlantis.edu/research.xmln FOR ROOT IN People/*/Publications LET BODY  ROOT/Author HEAD  ROOT/Keyword EXTRACTING RULES WITH SUPPORT  0.1 AND CONFIDENCE  0.2 AND count BODY  2 5. Support and Confidence for XML Association Rules Since the intrinsic meaning of the task is to find collaborations an obvious restriction to the generated rules is that they should contain at least two authors in the body and this is expressed by the generic XQuery predicate count BODY\>=2, in addition to predicates defining the minimum support and confidence Example 4 The next example shows the use of several path expressions We want to discover the associations between publications and awards looking for which type of publication is mostly related to which kind of award Since the publishers are represented as attributes in Journal elements and as PCDATA content in Books while the conterence types are stored as name attributes the BODY fragment set is the set union of the nodes which three different path expressions evaluate to Before we can discuss how the first prototype of X MINE has been implemented we must define how the support and the confidence values of an XML association rule are computed Let XR be the set of XPath expressions specified in the ROOT section XB be the set of XPath expressions specified in the BODY section XH be the set of XPath expressions specified in the HEAD section XI be XB UXH In particular let us focus on the simple case in which the BODY and the HEAD sections have identical sets of XPath expressions XI  XB XH as in the initial examples in Section 4 Let value be a function that given an XPath expression p and an XML document d returns the set of XML fragments XMINE RULE IN document\("www.atlantis.edu/research.xml FOR ROOT IN People LET BODY  ROOT/Publications/Book/Publisher 61 Proceedings of the 14th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI\22202 1082-3409/02 $17.00 \251 2002 IEEE 


in d identified by p Let satisfy be a function that given an XML fragment f and an XQuery where clause w returns one if f satisfies w zero otherwise Let contains be a function that given an XML fragment x and an XML fragment y, returns one if x contains y, zero otherwise First we compute the set F'D as the collection of all the XML fragments defined by the XPath expressions in XR, more formally overall process is illustrated in Figure 4 In the initial preprocessing step illustrated in Figure 4 with arrows from 1 to 4 the X MINE statement is processed to generate a representation of the XML mining problem as a relational table R which can subsequently elaborated by a known association rule mining algorithm Then in the following mining step association rules are extracted from R; during this phase the constraints specified in the EXTRACTING RULES clause are exploited by the mining algorithm Figure 4 arrow labeled 5 In the final post processing step the association rules extracted from relation R are finally mapped into the XML representation Figure 4 arrow labeled 6  F'1 U value\(p,d pEXR Likewise we compute the set F I as the collection of XML fragments that are defined by the XPath expressions in XI Preprocessing First the sets Fq and F I see Section 5 are generated Figure 6 arrow from 1 to 3 These sets contain the XML fragments addressed by the XPath expressions specified in the clauses ROOT \(Fq HEAD, and BODY \(F I In general this step could be implemented by any of the available XPath interpreters in our case we use the Java implementation ofXalan Then the sets F and F containing the XML fragments in Fq\and FI which satisfy the WHERE clause are generated This step is implemented on the top of the Xalan interpreter of Xpath Note that since there is no XQuery interpreter currently available our initial implementation supports only basic WHERE conditions mainly based on XPath expressions such as ROOT//@year=2001 With the sets F and F the relational table R is generatt;d as follows F  U value\(p,d pEXl We now define F and F by filtering the sets Fv and F through the XQuery where clause w specified in the WHERE section F and F are defined as follows F  I I I E Fv I satis.fy\(I w  F  I I I E F 1\\.\\'atis.fy\(I w From the definitions of F and F it is now possible to compute thefrequency of an itemsetX X E F as follows ECEF~ n/EXcontains C , I freq\(X F  IFbl Given the function freq it is then possible to extract frequent XML itemsets from an XML document Therefore it is possible to extract the association rules as specified in the X MINE statement Note that all the three functions used to define the jreq are available or easy to implement In particular the function value can be directly implemented by any of the available XPath interpreter e.g Xalan The function satisfy can be implemented by an XPath interpreter if the conditions in the WHERE clause are simple enough by an XQuery interpreter when this will become available The function contains can be again easily implemented on top of an XPath interpreter see Section 6 R has as many attributes i.e columns as is the numberofXML fragments in F i.e R C 0 l}IFIi R has as many tuples i.e rows as the number of fragments in F i.e R  TI TIF~I for every XML fragment Ci E F and every XML fragmentfj E F a tuple Ti E R Ti Ti,I...ri,IFll is defined as Ti,j contains\(ci,fj From Section 5 we recall that the function contains\(ci,fj returns one if the fragment Ci contains f j Note that the current implementations of XPath do not provide any method to check whether a fragment appear in another fragment Accordingly in our prototype the function contains is implemented on the top of the XPath interpreter as follows Given two fragments Ci and fj their textual representation is generated exploiting the functionalities of the XPath interpreter Then it is checked whether the textual representation of fj actually appear in the textual representation of Ci; if it does, one is returned otherwise zero This solution is indeed computationally expensive but on the other hand the comparison ofXML fragments is one of the major open issues in the XML community Thus it might be possible in the future to reduce the complexity of this phase through some advanced technique introduced in the next versions of 6. The Architecture of X MINE X MINE has been devised as an extension of the XML Query language and therefore it could be easily implemented on the top of an. XQuery interpreter However because of the lack of a robust XQuery execution environment the current implementation is built on the coupling of the Xalan XPath interpreter and an algorithm to extract association rules from relational data The XMINE prototype has been implemented as a three-step process namely preprocessing mining and postprocessing The 62 Proceedings of the 14th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI\22202 1082-3409/02 $17.00 \251 2002 IEEE 


 SOIIrt\273XMl~nt u XJlINE RULE  I I INdoc-nt c U FOR ROOT IN  LET    3 Itereddoal..nt WRDE 2 D EXTRACTING RULES WITB SUPPORT AHD CONFIDENCE jJ I8IaticxIalllPl8lent8tion EJ 5 J 8IIodItiIIn8s EJ 8 jJ XMl asmaoon rulos D 1     Figure 4 The architecture of the X MINE prototype which have been memorized during the preprocessing such as the correspondence between the XML fragments in F and F and the attributes in R is exploited in order to print an XML version of the association rules generated through the Apriori algorithm XPath and XQuery Finally the constraints specified in the EXTRACTING clause are represented so to be exploited by the association rule mining algorithm in the next phase Figure 6, arrow from 4 Mining With the table R and the constraints extracted from the EXTRACTING RULE clause in the previous phase, association rules are extracted Figure 6 arrow from 5 In the initial implementation presented here this phase is based on the plain Apriori algorithm Note that among the many constraints which might be specified our implementation currently considers only constraints concerning the composition of the rules e.g., the number of items in the rule head or body the minimum support and tlle minimum confidence In fact some compJex constraints e.g those described in  are currently not possible with a tabular representationbut they would require mining the XML association rules directly from the DOM Document Object Model representation DOM offers a platfonn-and language-neutral API Application Programming Interface allowing programs to dynamically access and update the content structure and style of the documents Recently we decided to implement this mining step by using MINE RULE since it allows a better specification of complex constraints The new version of X MINE is still under implementation 7 Notes on the Implementation The X MINE prototype has been implemented in Java on the top of the Xalan XPath 1.0 interpreter and DOM the mining phase was initially implemented with the plain Java implementation available in Weka Efficiency has not been of our main concern in developing the initial implementation of X MINE However the first experiments of use are good thanks to the excellent performance of the Xalan XPath interpreter In addition our initial experiments suggests that the preprocessing and postprocessing steps are reasonably fast with respect to the central mining phase Our first experiments conducted on some simple bibliographic XML documents obtained by using BibTeXML showed that in general association rule mining is quite a complex task if compared to the simple preprocessing needed to produce the relational representation needed for mining More specifically in our initial experiments we noted that preprocessing and postprocessing together required less than the 20 of the overall computing time Note however that since the structure of source documents was quite simple with respect to that of most Postprocessing In the final step \(depicted in Figure 6 with arrow 6 association rules extracted from relational data are mapped into the XML representation Here the information 63 Proceedings of the 14th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI\22202 1082-3409/02 $17.00 \251 2002 IEEE 


XML documents these preliminary results surely lack of generality These considerations suggest that an efficient execution of X MINE statements is feasible with current technology as long as the statement includes only XPath expressions or basic XQuery WHERE conditions Our three-step process which exploits an intermediate relational representation allowed us to implement a basic prototype smoothly On the other hand the lack of a robust XQuery execution environment does not allow us to compute the complex predicates supported by the X MINE syntax on a native XML representation The implementation we presented here \(see also leaves many open issues which must be addressed to have a fully functional and efficient implementation of the X MINE operator We believe that the most important open issue regards the support evaluation which should be used to extract association rules from XML documents There are currently no XQuery interpreters to be used in filtering XML fragments and although XPath processors are quite advanced they do not yet provide all the required functionalities either Many of these functionalities should be included in the new XPath 2.0 version while some operations needed for advanced options are still not defined but are still requirements of the W3C consortium Therefore many required computation must be coded directly on the raw DOM representation of the documents e.g the filtering of WHERE clauses which causes some computational overhead Note that in our prototype we implemented some of these functionalities on the top of DOM and XPath 1.0 Xalan interpreter however we do not plan to implement all the functionalities needed by X MINE. In fact we expect reliable XPath 2.0 and XQuery execution environments to be available in the very near future Acknowledgments In this work the authors have been supported by the consortium on discovering knowledge with Inductive Queries clnQ of the EU-IST Programme Contract no IST2000-26469 The authors wish to thank Roberto Carnevale for his implementation of the first X MINE prototype References 8. CONCLUSIONS In this paper we overviewed the X MINE operator a tool we have devised to extract association rules trom native XML data Although this research provides a good starting point there are still many open issues for future researcheven within the work presented in this paper Additionally association rules from XML data could be extended to the case of episode rules A more general question is how to consider and connect all available metadata-not only the XML Dm or schema information but also RDF metadata and DAML+OIL format ontologies-for a specific mining task in a specific domain This additional metadata provides enhanced possibilities to constrain the mining queries both automatically and manually but it also increases the complexity and thus poses lots of new requirements for the data mining query language  consortium on discovering knowledge with Inductive Queries clnQ http://www.cinq-project.org  BibTeXML an XML representation of BibTeX http://www.bibtexml.org  WEKA www.cs.waikato.ac.nz/ml/weka  R Agrawal T Imielinski and A Swami Mining association rules between sets of items iri large databases In P Buneman and S Jajodia editors Proceedings of ACM SIGMOD Conference on Management of Data SIGMOD'9 pages 207 216 ACM May 1993  D Braga A Campi S Ceri M Klemettinen and P L Lanzi Discovering interesting information in xml data with association rules Technical Report 2002-15 Dipartimento di Elettronica e Informazione Politecnico di Milano 2002  D Braga A Campi M Klemettinen and P L Lanzi Mining association rules from xml data In Proceedings of the 41h International Conference on Data Warehousing and Knowledge Discovery DaWaK 2002 September 4-6 Aixen-Provence France 2002 accepted  R Camevale Algoritmi per stemming ed estrazione di regole di associazione su documenti xml Master's thesis Apr 2002 Master thesis supervised by Marco Colombetti and Pier Luca Lanzi available in Italian  D M Group PMML 2.0 Predictive Model Markup Language http://www.dmg.org,Aug.2001  H Mannila H Toivonen and A I Verkamo Discovering frequent episodes in sequences In U M Fayyad and R Uthurusamy editors Proceedings of the First Intemational Conference on Knowledge Discovery and Data Mining KDD'95 pages 210 215 AAAI Press 1995  R Meo G Psaila and S Ceri An extension to SQL for mining association rules Data Mining and Knowledge Discovery 2\(2 224 1998  The Apache Software Foundation The Apache XML Project http xml apache org/xalan-j   World Wide Web Consortium Extensible Markup Language XML Version 1.0 W3C Recommendation http://www.w3c.org/xml/,Feb.1998  World Wide Web Consortium XML Path Language XPath Version 1.0 W3C Recommendation http://www.w3c.org/tr/xpath/,Nov.1999  World Wide Web Consortium XQuery 1.0 An XML Query Language W3C Working Draft http://www.w3.org/TR/2001/WD-xquery-20011220 Dec.2001 64 Proceedings of the 14th IEEE International Conference on Tools with Artificial Intelligence \(ICTAI\22202 1082-3409/02 $17.00 \251 2002 IEEE 


In Figures 10 and 11 we see MAFIA is approximately four to five times faster than Depthproject on both the Connect-4 and Mushroom datasets for all support levels tested down to 10 support in Connect-4 and 0.1 in Mushroom For Connect-4 the increased efficiency of itemset generation and support counting in MAFIA versus Depthproject explains the improvement Connect 4 contains an order of magnitude more transactions than the other two datasets 67,557 transactions amplifying the MAFIA advantage in generation and counting For Mushroom the improvement is best explained by how often parent-equivalence pruning PEP holds especially for the lowest supports tested The dramatic effect PEP has on reducing the number of itemsets generated and counted is shown in Table 1 The entries in the table are the reduction factors due to PEP in the presence of all other pruning methods for the first eight levels of the tree The reduction factor is defined as  itemsets counted at depth k without PEP   itemsets counted at depth k with PEP In the first four levels Mushroom has the greatest reduction in number of itemsets generated and counted This leads to a much greater reduction in the overall search space than for the other datasets since the reduction is so great at highest levels of the tree In Figure 12 we see that MAFIA is only a factor of two better than Depthproject on the dataset Chess The extremely low number of transactions in Chess 3196 transactions and the small number of frequent 1-items at low supports only 54 at lowest tested support muted the factors that MAFIA relies on to improve over Depthproject Table 1 shows the reduction in itemsets using PEP for Chess was about an order of magnitude lower compared to the other two data sets for all depths To test the counting conjecture we ran an experiment that vertically scaled the Chess dataset and fixed the support at 50 This keeps the search space constant while varying only the generation and counting efficiency differences between MAFIA and Depthproject The result is shown in Figure 13 We notice both algorithms scale linearly with the database size but MAFIA is about five times faster than Depthproject Similar results were found for the other datasets as well Thus we see MAFIA scales very well with the number of transactions 5.3 Effects Of Compression To isolate the effect of the compression schema on performance experiments with varying rebuilding threshold values we conducted The most interesting result is on a scaled version of Connect-4, displayed in Figure 14 The Connect-4 dataset was scaled vertically three times so the total number of transactions is approximately 200,000 Three different values for rebuilding-threshold were used 0 corresponding to no compression 1 compression immediately and all subsequent operations performed on compressed bitmaps\and an optimized value determined empirically We see for higher supports above 40 compression has a negligible effect but at the lowest supports compression can be quite beneficial e.g at 10 support compression yields an improvement factor of 3.6 However the small difference between compressing immediately and finding an optimal compression point is not so easily explained The greatest savings here is only 11 at the lowest support of Conenct-4 tested We performed another experiment where the support was fixed and the Connect-4 dataset was scaled vertically The results appear in Figure 15 The x-axis shows the scale up factor while the y-axis displays the running times We can see that the optimal compression scales the best For many transactions \(over IO6 the optimal re/-threshold outperforms compressing everywhere by approximately 35 In any case both forms of compression scale much better than no compression Compression on Scaled ConnectAdata Compression Scaleup Connectldata ALL COMP 0 5 10 15 20 25 30 100 90 80 70 60 50 40 30 20 10 0 Min Support  Scaleup Factor Figure 14 Figure 15 45 1 


6 Conclusions We presented MAFIA an algorithm for finding maximal frequent itemsets Our experimental results demonstrate that MAFIA consistently outperforms Depthproject by a factor of three to five on average The breakdown of the algorithmic components showed parent-equivalence pruning and dynamic reordering were quite beneficial in reducing the search space while relative compressiodprojection of the vertical bitmaps dramatically cuts the cost of counting supports of itemsets and increases the vertical scalability of MAFIA Acknowledgements We thank Ramesh Agarwal and Charu Aggarwal for discussing Depthproject and giving us advise on its implementation We also thank Jayant R Haritsa for his insightful comments on the MAFIA algorithm and Jiawei Han for providing us the executable of the FP-Tree algorithm This research was partly supported by an IBM Faculty Development Award and by a grant from Microsoft Research References I R Agarwal C Aggarwal and V V V Prasad A Tree Projection Algorithm for Generation of Frequent Itemsets Journal of Parallel and Distributed Computing special issue on high performance data mining to appear 2000 2 R Agrawal T Imielinski and R Srikant Mining association rules between sets of items in large databases SIGMOD May 1993  R Agrawal R Srikant Fast Algorithms for Mining Association Rules Proc of the 20th Int Conference on Very Large Databases Santiago Chile, Sept 1994  R Agrawal H Mannila R Srikant H Toivonen and A 1 Verkamo Fast Discovery of Association Rules Advances in Knowledge Discovery and Data Mining Chapter 12 AAAVMIT Press 1995 5 C C Aggarwal P S Yu Mining Large Itemsets for Association Rules Data Engineering Bulletin 21 1 23-31 1 998 6 C C Aggarwal P S Yu Online Generation of Association Rules. ICDE 1998: 402-41 1 7 R J Bayardo Efficiently mining long patterns from databases SICMOD 1998: 85-93 8 R J Bayardo and R Agrawal Mining the Most Interesting Rules SIGKDD 1999 145-154 9 S Brin R Motwani J D Ullman and S Tsur Dynamic itemset counting and implication rules for market basket data SIGMOD Record ACM Special Interest Group on Management of Data 26\(2\1997 IO B Dunkel and N Soparkar Data Organization and access for efficient data mining ICDE 1999 l 11 V Ganti J E Gehrke and R Ramakrishnan DEMON Mining and Monitoring Evolving Data. ICDE 2000: 439-448  121 D Gunopulos H Mannila and S Saluja Discovering All Most Specific Sentences by Randomized Algorithms ICDT 1997: 215-229 I31 J Han J Pei and Y Yin Mining Frequent Pattems without Candidate Generation SIGMOD Conference 2000 1  12 I41 M Holsheimer M L Kersten H Mannila and H.Toivonen A Perspective on Databases and Data Mining I51 W Lee and S J Stolfo Data mining approaches for intrusion detection Proceedings of the 7th USENIX Securiry Symposium 1998 I61 D I Lin and Z M Kedem Pincer search A new algorithm for discovering the maximum frequent sets Proc of the 6th Int Conference on Extending Database Technology EDBT Valencia Spain 1998 17 J.-L Lin M.H Dunham Mining Association Rules: Anti Skew Algorithms ICDE 1998 486-493 IS B Mobasher N Jain E H Han and J Srivastava Web mining Pattem discovery from world wide web transactions Technical Report TR-96050 Department of Computer Science University of Minnesota, Minneapolis, 1996 19 J S Park M.-S Chen P S Yu An Effective Hash Based Algorithm for Mining Association Rules SIGMOD Conference 20 N Pasquier Y Bastide R Taouil and L Lakhal Discovering frequent closed itemsets for association rules ICDT 99 398-416, Jerusalem Israel January 1999 21 J Pei J Han and R Mao CLOSET An efficient algorithm for mining frequent closed itemsets Proc of ACM SIGMOD DMKD Workshop Dallas TX May 2000 22 R Rastogi and K Shim Mining Optimized Association Rules with Categorical and Numeric Attributes ICDE 1998 Orlando, Florida, February 1998 23 L Rigoutsos and A Floratos Combinatorial pattem discovery in biological sequences The Teiresias algorithm Bioinfomatics 14 1 1998 55-67 24 R Rymon Search through Systematic Set Enumeration Proc Of Third Int'l Conf On Principles of Knowledge Representation and Reasoning 539 550 I992 25 A Savasere E Omiecinski and S Navathe An efficient algorithm for mining association rules in large databases 21st VLDB Conference 1995 26 P Shenoy J R Haritsa S Sudarshan G Bhalotia M Bawa and D Shah: Turbo-charging Vertical Mining of Large Databases SIGMOD Conference 2000: 22-33 27 R Srikant R Agrawal Mining Generalized Association Rules VLDB 1995 407-419 28 H Toivonen Sampling Large Databases for Association Rules VLDB 1996 134-145 29 K Wang Y He J Han Mining Frequent Itemsets Using Support Constraints VLDB 2000 43-52 30 G I Webb OPUS An efficient admissible algorithm for unordered search Journal of Artificial Intelligence Research 31 L Yip K K Loo B Kao D Cheung and C.K Cheng Lgen A Lattice-Based Candidate Set Generation Algorithm for I/O Efficient Association Rule Mining PAKDD 99 Beijing 1999 32 M J Zaki Scalable Algorithms for Association Mining IEEE Transactions on Knowledge and Data Engineering Vol 12 No 3 pp 372-390 May/June 2000 33 M. J. Zaki and C Hsiao CHARM An efficient algorithm for closed association rule mining RPI Technical Report 99-10 1999 KDD 1995: 150-155 1995 175-186 3~45-83 1996 452 



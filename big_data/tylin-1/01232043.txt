Enhancing Web Access Using Data Mining Techniques Alejandro A Vaisman Gabriel Dandretta Mariela Sapia University of Toronto Universidad de Belgrano Universidad de Belgrano avaisman@cs.toronto.edu datta@ub.edu.ar mpsapia@ìbertel.com.ar Abstract In this paper we study data mining techniques as tools for reducing the time needed to access web pages in the environment of a corporation where users connect to the Internet through a proxy server We add a data mining server to the traditional web architecture This server computes using sequential patterns the pages likely to 
be requested by the users taking into account their web access history Then the server loads these pages into the proxyês cache in order to have them available when they are actually asked for We describe our implementation and the results obtained showing that the average access time to a web page can be dramatically reduced using this technique Further we also implemented our proposal using simple association rules showing that sequential patterns result in a smaller and more accurate set 
of rules as a consequence of taking into account the order of the requests Finally we discuss the differences with other prefetching proposals 1 Introduction An important goal for Internet service providers is to increase web surìng speed This requirement can be satisìed either with higher bandwidths\(at the expense of higher costs or implementing technological solutions like intelligent algorithms for web page access and caching In this work we study the use of data mining 5 techniques association rules and sequential patterns al 
though the model supports any other technique in order to predict the web pages likely to be accessed by an Internet user in the environment of a corporation where all the users access the Internet thr ough a proxy server We developed a system that loads those pages in the proxy serverês cache while users may be performing another task Thus when users actually ask for a certain page they will have it readily available We also present the results of a series of experiments showing that using this approach the average response time can be reduced by 
a factor up to six We address in detail problems overlooked in similar proposals like the requests that cannot be considered for analysis or the need for data preprocessing A distinctive characteristic of our proposal is the use of sequential patterns for prefetching instead of plain association rules With this approach we take into account the order in which pages are visited reducing storage needs and bandwidth usage In order to validate this hypothesis we also developed a rule engine that 
uses plain association rules and compare the results Let us consider the following situation Mary logs on to Internet every day for checking the news She usually visits the web sites of two newspapers The Globe  Mail www.theglobeandmail.com and the Toronto Star\(www.thestar.com She checks the nance section of the rst newspaper www.globeinvestor.com and then the weather forecast www.theglobeandmail.com/weather If she has enough time she visits the Toronto Starês web site However generally she only has time 
for visiting the Globe  Mailês web site In this setting using simple association rules would yield the rules visits\(Mary,globeandmail  visits\(Mary,thestar  visits\(Mary thestar  visits\(Mary,globeandmail we omit the intermediate pages that would also appear Thus even if Mary will not be able to visit the Toronto Starês home page the system preloads these pages in the cache with the consequence of storage and bandwidth misuse On the other hand using sequential patterns will yield a sequence visits\(Mary,globeandmail visits\(Mary,investor visits\(Mary weather These rules will better account for the 
real activity of Mary on the Internet and the system in this case will not preload pages that are not likely to be requested The generated rules are used by the Page loader for caching pages in advance Figure 1 shows the general system architecture The rule generator gets Proceedings of the 14th International Workshop on Database and Expert Systems Applications \(DEXAê03 1529-4188/03 $17.00 © 2003 IEEE 


                Web Log Proxy Server Rule Generator Page Loader URLs to preload Session Information Requested URLs Rules to use Actions Generated rules Internet GET<obj Cache replacement algorithm Cache Association Rules Sequential Patterns or Rules Figure 1 Data mining proxy architecture data from the proxyês log and generates the association rules or sequential patterns which are stored in the knowledge base This base is read by the page loader which stores the rules in the cache of the proxy server using the proxyês repl acement algorithm The remainder of the paper is organized as follows In Section 2 we comment previous work in the eld In Section 3 we describe the systemês architecture and give details of the implementation In Section 4 we present the tests performed We conclude in Section 5 2 Background Data mining re fe rs t o t h e e xt ra c t i o n o f know l edge from large databases We are interested in using data mining algorithms over data stored in a proxy serverês log In particular we will adapt the well-known Apriori 1 a nd AprioriAll  a l gori t h m s  d e v e l ope d b y Agrawal et al  for discovering Association Rules and Sequential Patterns respectively Our work ts into the so-called Web Usage Mining deìned as the process of using data mining techniques on data requested by the users  Ma ny w orks a pproa c h e d t h e s ubj e c t of w e b caching from different points of view Schechter et al  i n t roduc e d t h e u s e of pa t h pro l e s f or pre di c t i n g http requests However they limit to study the algorithmês behavior with synthetic data and neither present a complete system using the algorithm nor consider real world limitations Fan et al 4 p re s e nt a t e c h nique called proxy-initiated prefetching and a prediction algorithm based on the Prediction-by-Partial-Matching data compressor Their implementation unlike our proposal requires modifying the browsers at the client side Nanopoulos et al 8 a l s o i nt roduc e p re fe t c hi ng s c he m a s  They use association rules for predicting user access sending hints to the clients from the server A work by Lan et al  pre s e nt s a s t ra t e gy s i m i l a r t o t he one a dopt e d in our work although their study is limited to measure hit ratios and trafìc increase without any further consideration of the requirements of an implementation in a realworld environment and they do not account for order of the visits to web pages Web logs and proxy servers We will assume an environment in which a user is accessing the Internet from an Intranet through a proxy server A proxy server could be seen as a mediator between a Local Area Network LAN and the Internet such that only one IP address is needed for connecting any number of workstations to the Internet An important feature of a proxy server is its cacheês capacity In general the higher this cache the better the performance The data mining algorithm which produces the rules used to predict future user behavior takes as input data reîecting previous user activity These data can be obtained mainly from two alternative sources a data stored in the local cache b data stored in the proxy server log containing all the objects accessed by the client machines in the Intranet Alt hough option a allows using the Application Program Interfaces APIs in a Wi ndows environment it requires installing an application in every client machine On the other hand option b only requires installing an application on the server but it does not allow using the system APIs We have chosen alternative b for our project and developed an interface allowing interaction between the proxy server and the data mining algorithm Web usage mining although promising for enhancing web usage performance has some drawbacks there is no safe way of knowing when a session begins and ends there is no access to the information residing in a client machineês cache information may be incorrect if a page is relocated or a server renamed or eliminated 3 System Architecture Figure 2 depicts the detailed system architecture At a high level of abstraction we can see the data mining server as a standard proxy server to which two modules are added one for discovering the sequential patterns or association rules from the userês navigation history and the other for loading the proxy serverês cache with the pages likely to be requested by the user obtained from the rule base The transaction pre-processor lters out records in the log of the proxy server see below for details It was written in Transact-SQL a language for writing Stored Procedures in MS SQL Server The data mining algorithm takes as input data in the ltered log and generates rules of the form URL1  URL2  or rules including the userês identiìcation Proceedings of the 14th International Workshop on Database and Expert Systems Applications \(DEXAê03 1529-4188/03 $17.00 © 2003 IEEE 


                               Data Mining Algorithm Pre-processed Transaction Log Proxy Server Log Cache Page Loader Internet Intranet Transaction Pre-processor Server Proxy Sequential Patterns or Association Rules Rules Figure 2 Detailed System Architecture if the conìguration of the proxy server allows it  v.g userA,URL1  userA,URL2  If the proxy server is conìgured to accept a nonymous connections only IP addresses are supported The page loader loads web pages into the proxy serverês cache It was wr itten in Java and implements the connection between the data mining and proxy servers The Page Loader can interact with any cache replacing scheme The system works as follows users request web pages through the LAN\(Intranet The users requests are stored in the proxy serverês log implemented as a relational database The transaction pre-processor lters out the records in the log which will not be useful for further processing thus a new transaction log is generated holding the records which will be used as input for the data mining algorithm The algorithm is run periodically and the sequential patterns are found as we already explained URLs are the items of the transactions used by the algorithms The Page loader keeps the cache contents updated loading the pages from the URLs appearing on the discovered sequences When a user requests a page satisfying a rule in the rule base  i.e a URL belonging to a sequence or matching the left side of some rule if association rules are used the proxy server does not need to go to the Internet for the page because it will be in the proxyês cache Data Pre-processing Not every tuple in the web log will be useful for being processed by the data mining algorithm The reasons for ltering out these useless tuples are two-fold speeding up the data mining algorithm and preventing the generation of erroneous information For instance dynamically generated pages\(like ASP or PHP pages are not considered because they cannot be stored in the cache Thus taking their addresses into account will negatively affect performance Further we will only consider user requests successfully completed carried out using the HTTP protocol The system only considers tuples in the web log which represent a successfully retrieved object Incomplete tuples tuples with missing information are discarded Requests posed by automatic agents do not represent userês behavior because they are triggered automatically Thus considering them may generate wrong rules The eld ClientAgent in the log tuple allows detecting these kinds of requests the client program identiìer must contain the keyword Mozilla  Finally the system will only consider objects retrieved via the HTTP protocol Data Mining Process We implemented the AprioriAll algorithm 2 as an S Q L S er v e r S t o r e d P r o ced u r e D e tails of this algorithm can be found in the references In order to measure the effect of taking into account the order in which pages are visited we also implemented the Apriori algorithm 1  Th e p ar amet er s support and conìdence are deìned in the usual way A sequence is an ordered set of itemsets S  S  S n  Each item is an URL address The support of a sequential pattern is the number of sequences containing the pattern The AprioriAll algorithm applies the well-known Apriori property to sequences if a pattern of size k is not frequent i.e its support is less than the minimum support then no subset of this pattern can be frequent Communication between the proxy and mining servers As we were only interested in supporting objects in the WWW and not every service available v.g news mail video streaming we only needed a proxy server supporting the HTTP protocol Thus we worked with Microsoftês Proxy Server 2.0 3 MS P roxy S e rve r 2.0 supports two kinds of web log formats text les and database tables SQL Server or MSAccess We chose the latter avoiding parsing the strings in the text le when processing the web log A typical log record has twenty-two elds from which the following ones were used in our implementation a ClientIP stores the IP address of the client making the request b ClientUserName holds the name of the user in the Windows NT network making the request c DestHost the name of the remote site accessed d Protocol indicates if the object was accessed via HTTP or FTP e Uri the complete URL of the accessed object We provide a way for establishing a bidirectional connection between the proxy and mining servers such that the latter can access the data generated by the proxy server and the pages likely to be visited by the user can be loaded in advance in the proxyês cache in order to be available when they are requested Proceedings of the 14th International Workshop on Database and Expert Systems Applications \(DEXAê03 1529-4188/03 $17.00 © 2003 IEEE 


4 Experiments The tests we performed on the system aimed at a determining how support affects the results of the process in order to deìne the best values for this system parameter b discovering user trends and preferences and their impact over the system c evaluating how the addition of the data mining server inîuences the systemês performance They were conducted on a computer with an AMD K6-2 processor with a processor speed of 500Mhz hosting both applications client and server The installed applications on the server side were Microsoft Windows NT 4.0 Server Service Packs 4 5 y 6 Microsoft SQL Server 2000 and Microsoft Proxy Server 2.0 on the client side we had an Internet Explorer 5.0 browser Two other computers hold browser clients The data set was collected from the log of a proxy server in a school in Argentina Data cover a month of activity and the database holds 60.538 records from which we obtained 109 transactions We also performed tests with synthetic data with the following parameters 100 transactions up to 25 different URLs per transaction and 25 different URLs in the data set with an average of 15 URLs per transaction The transactions occurred between 9 A.M and 6 P.M When tests started the serverês cache was already loaded We performed six kinds of tests Test 1 measures how support affects the number of generated rules This test was run 3 times with support values of 1 2 and 3 Test 2 measures how support affects the time needed for generating the rules The tests were run in a way analogous to test 1 In test 3 the goal pursued was nding out how many times in a day the same site is accessed by a user In test 4 we measure the number of accesses to the Internet as a function of the time of the day The results allow deìning which are the best times in the day for running the rule generator  i.e the moments in which activity is low Test 5 categorizes the requests made to the proxy server In order to measure the systemês applicability we needed to test the number of requests valid for analysis  i.e the ones which will be the input to the data mining algorithm Test 6 measures the systemês performance The test compares page access time with the data mining server activated against the access time obtained with the standard architecture Client latency with prediction was measured in the following way rst information on past requests was stored in the proxy serverês log and ltered Then the data mining algorithm was executed every twentyìve minutes generating the rules Every ve minutes the page loader module scanned the rule base in order to store the pages in the cache After this stage we registered the web page access times Support Sequential patterns Association rules 1 214\(13 173 2 32\(2 98 3 3\(1 6 Figure 3 Comparing sequential patterns and association rules Discussion of Results Werantests#1and#2with sequential patterns and simple association rules for the latter using only synthetic data Figure 3 shows the results in terms of the number of rules that were generated We can see that as support increases the number of generated rules decreases Between parentheses we show the results using real data for sequential patterns We also measured the time needed for generating the sequential patterns and association rules not only their number In this case simple association rules take less time to compute than sequential patterns except for rules with low support 1 The latter occurs b ecause the number of iterations of the AprioriAll algorithm was lower than in of association rules the paths were of length less than 3 Regarding the characteristics of the data sets our tests showed that 62 of the sites are accessed only once in a day and eight percent of the sites are accessed more than ve times in a day Thus users in this site make requests through search engines in order to satisfy onetime needs For synthetic data 80 of the pages are accessed more than ve times If we compare with real data and perform a correlation with the number of generated rules it is clear that this is the reason for having much more rules when using synthetic data Thus the largest the number of repeated accesses to the same pages the largest the number of rules that are generated and the largest the beneìt of sequential patterns over simple association rules Finally an important aspect affecting the systemês performance is the way users access the Internet because low demand periods are suitable for rule updating As it was expected the demand peaks between 11:00 a.m and 12:00 a.m and between 3:00 p.m and 6:00 p.m Results for Test 5 show that only 53 percent of the requests are suitable for being included in the transaction set over which data mining techniques can be applied However we must consider that within these 53 percent there is another 40 percent of dynamically generated pages which cannot be stored in the cache Figure 5 shows that on the average the access time is reduced in a factor of six from 600 msec to 100 msec proving the effectiveness of the page prediction process Measuring average access time instead of hit ratios has Proceedings of the 14th International Workshop on Database and Expert Systems Applications \(DEXAê03 1529-4188/03 $17.00 © 2003 IEEE 


      Figure 4 Distribution of request results                                      Figure 5 Performance the advantage of considering the real impact over the users of the issues mentioned above Moreover given that 85 percent of the requested sites are local  i.e sites within Argentina the improvement can be higher when the percent of requested foreign sites increases 5 Conclusion and Future Work In this paper we have presented a system in which we added a data mining proxy to the traditional web architecture This new server using data mining techniques predicts\(based on previous accesses stored in the proxyês log the pages likely to be requested by users in an Intranet located behind a proxy server and loads these pages into the proxyês cache We performed several tests on the prototype with promising results which we discussed We compared the use of sequential patterns against simple association rules concluding that the latter reduce the number of generated rules saving storage space and bandwidth usage Our solution does not prevent the use of other proposals for cache management which exploit semantic information and addresses in detail problems not covered in other works concerning user activity and data pre-processing which have impact over the nal system performance References 1 R  A gr aw al and R  Sr i kant  F ast al gor i t h m s f o r m i n ing association rules in large databases In 20th International Conference on Very Large Databases  pages 487 499 Santiago de Chile 1994 2 R  A gr aw al and R  Sr i kant  M i n i n g s equent i a l p at terns:generalization and performance improvements In Proceedings of EDBTê96  pages 3Ö17 Avignon France 1996 3 M  C or por at i on Planning an Effective Proxy Server Conìguration  Technet 2000 4 L  F an P  C ao W  L i n and Q  Jacobson W e b p r e f e t c hing between low-bandwidth clients and proxies Potentials and performance In Proceedings of SIGMETRICS 99  pages 178Ö187 1999 5 J  H an and M  K a m ber  Data Mining Concepts and Techniques  Morgan Kaufmann Publishers 2001 6 B  L an B  B r essan B  O o i  and Y  T a y  M aki ng w e b servers pushier In Proceedings of WEBKDDê99  pages 112Ö125 San Diego CA 1999 7 B  M obasher  R  C ool ey  a nd J Sr i v ast ava A u t o m a t i c per sonalization based on web usage mining Communications of ACM 43\(8 pages 142-151  2000 8 A  N anopoul os D  K a t sar os and Y  M anol opoul os E f fective prediction of web user access In Proceedings of WEBKDDê01  San Francisco CA 2001 9 S  S checht er  M  K r i shnan and M  Sm i t h  U si ng pat h proìles to predict http requests In Seventh International World Wide Web Conference  pages 457Ö467 Brisbane Australia 1998 Proceedings of the 14th International Workshop on Database and Expert Systems Applications \(DEXAê03 1529-4188/03 $17.00 © 2003 IEEE 


0 BD 0 BC CD AD P  P 1 0 BC I I BE2 OCE2 2 P  P,+P BF CF EF AD 3 BD 3 DF 3 Aner I SI scan dambars D c ha\\c candidatc ilcmsels  rclatke suppon  30  BS Collo~~s 8\224 8\224 C\224 C\224 E\224 F\224 iBC\222.\222 BF\224 CE\224 C\224 BC\221 222 E\224 CE\224 Aner 2nd scam databarc D ne hac frequent Ilcmscts rclal~~e ruppon  30 as Colloar IB\222.\222 B\224 C\224 C\224 E\224 F\224 BC\224 BF\224 CE\224 Figure 3 Frequent temporal itemsets genera tion for mining general temporal association rules by PPM counts of potential candidate 2-itemsets are recorded of type Q and type p From Figure 3 it is noted that since there are also 4 transactions in Pz the filtering thresh old of those itemsets carried out from the previous phase that become type CY candidate itemsets in this phase is 4  4  0.31  3 and that of newly identified candidate itemsets \(i.e type h\222 candidate itemsets is r4  0.31  2 It can be seen that we have 3 candidate itemsets in C2 after the processing of partition P2 and one of them is of type Q and two of them are of type p Finally, partition P3 is processed by algorithm PPM The resulting candidate 2-itemsets are C2   BC CE BF as shown in Figure 3 Note that though appearing in the pre vious phase P2 itemset DE is removed from C once P3 is taken into account since its occurrence count does not meet the filtering threshold then i.e 2  3 However we do have one new itemset i.e BF which joins the C2 as a type p candidate itemset Consequently we have 3 can didate 2-itemsets generated by PPM and two of them are of type Q and one of them is of type p Note that only 3 candidate 2-itemsets are generated by PPM After generating C2 from the first scan of database db1,3 we employ the scan reduction technique  131 and use C2 to generate Ck Ic  2,3  m where C is the candidate lust-itemsets Instead of generating C3 from LZ  L2 a C2 generated by PPM can be used to generate the candidate 3-itemsets and its sequential Ck-l can be utilized to gener ate Ck Clearly a CA generated from Cz  Cz instead of from L2  L2 will have a size greater than IC31 where C3 is generated from L2  L2 However since the IC2 I generated by PPM is very close to the theoretical minimum i.e 1,521 the IC41 is not much larger than IC31 Similarly the ICkl is close to Ch Since C2  BC,CE,BF no candidate Ic-itemset is generated in this example where Ic 2 3 Thus Ck  BC CE BF and all CL can be stored in main memory Then we can find Lks Ic  1,2  m together when the second scan of the database db1v3 is performed Note that those generated itemsets Ck  BC CE BF are termed to be the candidate maximal temporal itemsets TIS i.e BC1l3 CE2?3 and BF3l3 with a maximal ex hibition period of each candidate Before we process the second scan of the database db1t3 to generate L~s all candidate SIs of candidate TIS can be propagated based on Property 1 and then added into Ck For instance as shown in Figure 3 both candidate 1-itemsets B193 and C173 are derived from BC\22233 Moreover since BC1l3 for example is a candidate 2-itemset, its subsets i.e and C1l3 should potentially be candidate itemsets As a result 9 candidate itemsets i.e as shown in Figure 3 are generated Note that since there is no candidate TI Ic-itemset k 2 2 containing A or D in this example Ai?3 and Dil3 1 5 i 5 3 are not necessary to be taken as SI itemsets for generating general temporal association rules In other words we can skip them from the set of candidate itemsets 7;s Finally all occurrence counts of CLs can be calculated by the second database scan Note that itemsets BC1l3 BF3l3 and CE2,3 are termed as frequent TIS while B3>3 C1v3 C2l3 E2t3 and F333 are frequent SIs in this example As shown in Figure 3 after all frequent TI and SI item sets are identified the corresponding general temporal as sociation rules can be derived in a straightforward man ner Explicitly the general temporal association rule of X  Y XY holds if conf X  Y XY   min-con f 133 B3,3 c1,3 c2,3 E~J F3,3 1,3,~~3,3 C~2,3 I 4 Experimental Studies To assess the performance of algorithm PPM we per formed several experiments on a computer with a CPU clock rate of 450 MHz and 512 MB of main memory The methods used to generate synthetic data are described in Section 4.1 The performance comparison of PPM and Apriori is presented in Section 4.2 Results on scaleup experiments are presented in Section 4.3 342 


4.1 Generation of synthetic workload 500 8 400 s 2 300 i h E 4 200 0 s 100 W o For obtaining reliable experimental results the method to generate synthetic transactions we employed in this study is similar to the ones used in prior works 2 131 These transactions mimic the publication items in a publication database Each database consists of ID1 transactions and on the average, each transaction has IT1 items To simu late the characteristic of the exhibition period in each item transaction items are uniformly distributed into database 73 with a random selection In accordance with the exhibition periods of items database 2 is divided into n partitions Ta ble 2 summarizes the meanings of various parameters used in the experiments The mean of the correlation level is set to 0.25 for our experiments. Without loss of generality we use the notation Tx  Iy  Dm to represent a database in which D  m thousands IT1  x and 111  y We compare relative performance of Apriori and PPM    T 10-14-DI 00    Apriori A PPM   i    ____  _     I 1731 I Number of transactions in the database  ____   1 IT1 I Average size of the transactions  1 I I Average size of the maximal frequent itemsets ILI 1 Number of maximal potentially frequent itemsets N I Number of items IP;I I Number of transactions in the Dartition database Pi Table 2 Meanings of various parameters 4.2 Relative performance We first conducted several experiments to evaluate the relative performance of Apriori and PPM Since the ex  perimental results are consistent for various values of n ILI and N for interest of space we only report the results on ILI  2000 and N  10000 in the following experiments Figure 4 shows the relative execution times for both two algorithms as the minimum support threshold is decreased from 1 support to 0.1 support. When the support thresh old is high there are only a limited number of frequent item sets produced. However as the support threshold decreases the performance difference becomes prominent in that PPM significantly outperforms Apriori Explicitly PPM is in orders of magnitude faster than Apriori and the margin grows as the minimum support threshold decreases 4.3 Scaleup performance In this experiment we examine the scaleup performance of algorithm PPM The scale-up results for different se lected datasets are obtained. Figure 5 shows the scaleup per formance of algorithm PPM as the values of ID1 increase 0.1 0.3 0.5 0.7 0.9 Minimum Support  g2400 E1800 i i v 20-16-D 100  Appriori A PPM I Figure 4 Relative performance studies Three different minimum supports are considered We ob tained the results for the dataset T10  I4  Dm when the number of customers increases from 100,000 to one mil lion The execution times are normalized with respect to the times for the 100,000 transactions dataset in the Fig ure 5 Note that as shown in Figure 5 the execution time only slightly increases with the growth of the database size showing good scalability of PPM 5 Conclusion In this paper we not only explored a new model of mining general temporal association rules i.e X  Y XY in a publication database but also developed algorithm PPM to generate the temporal association rules as well as conducted related performance studies Un der PPM the cumulative information of mining previous partitions is selectively carried over toward the generation of candidate itemsets for the subsequent partitions Algo rithm PPM is particularly powerful for efficient mining for a publication-like transaction database, such as bookstore transaction databases video rental store records library book rental records and transactions in electronic com merce One extension to our proposed model in this paper is to mine general temporal association rules with different 343 


9 2 1 100 300 500 700 900 ID transaction number K Figure 5 Scaleup performance of PPM start and end points of items This is an interesting yet chal lenging issue since the levelwise property does not hold in this situation, and will be a matter of future research 6 Acknowledgment The authors are supported in part by the Ministry of Ed ucation Project No 89-E-FA06-2-4-7 and the National Sci ence Council Project No NSC 89-2219-E-002-028 and NSC 89-22 18-E-002-028, Taiwan, Republic of China References I R Agrawal T Imielinski and A Swami Mining Association Rules between Sets of Items in Large Databases Proc of ACM SIGMOD pages 207-216 May 1993 2 R. Agrawal and R. Srikant Fast Algorithms for Min ing Association Rules in Large Databases Proc of the 20th International Conference on Very Large Data Bases pages 478-499 September 1994 3 J.M. Ale and G. Rossi An Approach to Discovering Temporal Association Rules ACMSymposium on Ap plied Computing 2000 4 M.4 Chen J Han and P S.Yu Data Mining An Overview from Database Perspective IEEE Transac tions on Knowledge and Data Engineering 8\(6 883, December 1996 5 X Chen and I Petr Discovering Temporal Associa tion Rules: Algorithms, Language and System Proc of 2000 Int Con on Data Engineering 2000 6 D Cheung J Han V Ng and C.Y Wong Main tenance of Discovered Association Rules in Large Databases An Incremental Updating Technique Proc of 1996 Int'l Conj on Data Engineering pages 106-1 14, February 1996 7 J Han and Y Fu Discovery of Multiple-Level Asso ciation Rules from Large Databases Proc of the 21th International Conference on Very Large Data Bases pages 420-431 September 1995 8 J Han J Pei, and Y Yin Mining Frequent Patterns without Candidate Generation Proc of 2000 ACM SIGMOD Int Con on Management of Data pages 486-493 May 2000 9 J Hipp U Giintzer and G Nakhaeizadeh Algo rithms for association rule mining  a general survey and comparison SIGKDD Explorations 2 1 July 2000 Sliding Window Filtering An Efficient Algorithm for Incre mental Mining Proc of the ACM 10th Intern I Conf on Information and Knowledge Management Novem ber 200 1 Mining Association Rules Anti-Skew Algorithms Proc of 1998 Int'l Conj on Data Engineering pages 486-493 1998 12 B Liu W Hsu and Y Ma Mining Association Rules with Multiple Minimum Supports Proc of I999 Int Con on Knowledge Discovery and Data Mining Au gust 1999 13 J.-S Park M.-S. Chen, and P S Yu Using a Hash Based Method with Transaction Trimming for Mining Association Rules IEEE Transactions on Knowledge and Data Engineering 9\(5 13-825 October 1997 14 R Srikant and R Agrawal Mining Generalized As sociation Rules Proc of the 21th International Con ference on Very Large Data Bases pages 407-419 September 1995  151 R. Srikant and R Agrawal Mining quantitative asso ciation rules in large relational tables Proc of I996 ACM-SIGMOD Con on Management of Data 1996  161 A K H Tung J Han, L V S Lakshmanan, and R T Ng Constraint-Based Clustering in Large Databases Proc of 2001 Int Conj on Database Theory January 2001  171 K Wang Y He, and J Han. Mining Frequent Itemsets Using Support Constraints Proc of2000 Int Con on Very Large Data Bases September 2000 18 C Yang U Fayyad and P Bradley Efficient dis covery of error-tolerant frequent itemsets in high di mensions The Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Min ing 200 1 lo C.-H Lee C.-R Lin and M.-S Chen ll J.-L Lin and M.H Dunham 344 


n I31 41 51 61 71 8 I 9 Graph diameter q5\(SCCn Average number of lateral links E Average number of MI local links MI\(loc Average number of MB local links MB\(Zoc I Graph size n  1 e n I 12 I 72 I 480 I 3,600 I 30,240 I 282,240 I 2,903,040 6 8 16 19 1.500 2.583 3.683 4.783 0.667 1.500 3.200 5.000 0.833 1.222 1.925 2.337 1.500 3.000 Average number of local links L Average distance d\(SCC 2.722 5.125 7.337 5.306 8.808 12.121 Table 1 Average distance of SCC graphs under minimal routing 300000 250000 g 200000 3 E L 150000   100000 50000 0 erage number of MB local links is concerned. Also observe that for 3 5 n 5 4 the greedy routing algorithm performs as well as the minimal routing algorithm Besides, our re sults indicate that the performance of these algorithms is quite similar for 5 5 n 5 9 which makes the less complex greedy routing algorithm particularly attractive Average costs of paths produced by the three routing al gorithms are summarized in Table 2 The random routing algorithm has a complexity of O\(n and performs reason ably well on the average Utilization of such an algorithm may however result in variations in the average cost of routes up to the worst-case values shown in Table 2  Minimal routing  andom rout. \(worst case     n 3 Minimal Greedy Random routing rout rout Theor Simul Worst-case 3.000 3.000 3.000 3.084 3.167 I1 I I I I I 4 5 I I I I I 5.306 5.305 5.500 5.514 5.694 8.808 8.812 9.261 9.264 9.775 Table 2 Average costs vs routing algorithms Figure 6 shows distribution curves comparing the three routing algorithms in the case of an SCC graph A point 01 NI in one of these curves indicates that the corre sponding routing algorithm will compute a route of cost DI to the identity for NI nodes in the SCC graph The aver age distribution for the random routing algorithm is shown but the results for that algorithm may actually vary from the minimal to the worst-case distributioncurves due to the non deterministic nature of the algorithm It is also interesting to observe that the greedy routing algorithm provides a dis tribution curve which is close to that of the minimal routing algorithm presenting however a smaller complexity 6 Considerations on wormhole routing 3 In this section we briefly describe how the algorithms presented in the paper cam be combined with wormhole routing 6 which is a popular switching technique used in parallel computers All three algorithms can be used with wormhole routing when implemented as source-based routing algorithms  111 In source-based routing tlhe source node selects the entire path before sending the packet Because the processing delay for the routing algorithm is incurred only at the source node it adds only once to the communication latency and can be viewed as part of the start-up latency Source-based routing however has two disadvantages 1 each packet must carry complete information about its path in the header which increases the packet length and 2 the path cannot be changed while the packet is being routed which precludes incorporating adaptivity into the routing algorithm Distributed routing eliminates the disadvantages of source-based routing by invoking the routing algorithm in each node to which the packet is forwarded ll Thus the decision on whether a packet should be delivered to the local processor or forwarded on an outgoing link is done 451 


locally by the routing circuit of a node Because the routing algorithm is invoked multiple times while a packet is being routed the routing decision must be taken as fast as pos sible From this viewpoint it is important that the routing algorithm can be easily and efficiently rendered in hardware which favors the random routing algorithm over the greedy and minimal routing algorithms Besides being the most complex algorithm discussed in this paper the minimal routing algorithm includes a feature which precludes its distributed implementation in associa tion with wormhole routing namely its backtracking mech anism Distributed versions of the random and greedy al gorithms, however, can be used in combination with worm hole routing A near-minimal distributed routing algorithm which supports wormhole routing can be obtained by re moving the backtracking mechanism from Alg 3 Such an algorithm is likely to have computational complexity and average cost that lie between those of the greedy and the minimal routing algorithm Due to its non-deterministic nature the random routing algorithm also seems to be a good candidate for SCC net works employing distributed adaptive routing  1 I Adap tivity is desirable for example if the routing algorithm must dynamically respond to network conditions such as conges tion and faults Some degree of adaptivity is also possible in the greedy and minimal routing algorithms which in some cases can decide between paths of equal cost 7 Conclusion This paper compared the average cost and the complex ity of three different routing algorithms for the SCC graph We divided routes into three components \(lateral links MI local links and MB local links and showed that only the number of MB local links may be affected by the routing algorithm being considered Exact expressions for the aver age number of lateral links and the average number of MI local links were presented Also an upper bound for the average number of MZ local links was derived considering a random routing algorithm As a result a tight upper bound on the average distance of the SCC graph was obtained Simulation results for a random a greedy and a minimal routing algorithm were presented and compared with theo retical values The complexity of the proposed algorithms is respectively O\(n O\(n2 and O\(n3 where n is the dimensionality of the SCC grap.h The results under mini mal routing produce exact numerical values for the average distance of SCC for 3 5 n 5 9 Results for the greedy algorithm match those of the min imal algorithm for 3 2 n 5 4 The greedy algorithm also performs close to minimality for 5 5 n 5 9 and is an in teresting choice due to its O\(n2 complexity The random routing algorithm has an O\(n complexity and performs fairly well on the average but may introduce additional MB local links in the route under worst-case conditions Finally we discussed how each of the routing algorithms can be used in association with the wormhole routing switch ing technique Directions for future research in this area in clude an evaluation of requirements for deadlock avoidance e.g number of virtual channels References l S B Akers,D. HarelandB Krishnamurthy,\223TheStarGraph An Attractive Altemative to the n-Cube,\224 Proc Int\222l Con Pal Proc 1987 pp 393-400 2 M M Azevedo N Bagherzadeh and S Latifi 223Broadcasting Algorithms for the Star-Connected Cycles Interconnection Network,\224 J Pal Dist Comp 25,209-222 1995 3 M M Azevedo N Bagherzadeh and S Latifi 223Embed ding Meshes in the Star-Connected Cycles Interconnection Network,\224 to appear in Math Mod. and Sci Comp 4 M M Azevedo N Bagherzadeh and S Latifi 223Fault Diameter of the Star-Connected Cycles Interconnection Net work,\224 Proc 28th Annual Hawaii Int\222l Con5 Sys Sci Vol 11 Jan. 3-6 1995 pp 469-478 SI W.-K Chen M F M Stallmann andE E Gehringer 223Hy percube Embedding Heuristics An Evaluation,\224 Int\222l J Pal Prog Vol 18 No 6 1989 pp 505-549 6 W J Dally and C I Seitz 223The Torus Routing Chip,\224 Dist Comp Vol 1 No 4 1986 pp 187-196 7 K Day and A Tripathi,\223A Comparative Study ofTopologica1 Properties of Hypercubes and Star Graphs,\224 IEEE Trans. Pal Dist Sys Vol 5 No 1 Jan. 1994 pp 31-38 8 D E Knuth The Art of Computer Programming Vol I Addison-Wesley 1968 pp 73 pp 176-177 9 S Latifi 223Parallel Dimension Permutations on Star Graph,\224 IFIP Trans A Comp Sei Tech 1993 A23 pp 191-201 lo S Latifi M M Azevedo and N Bagherzadeh 223The Star Connected Cycles A Fixed-Degree Interconnection Net work for Parallel Processing,\224 Proc Int\222l Con5 Pal Proc  1 11 L M Ni and P K McKinley 223A Survey of Wormhole Rout ing Techniques in Direct Routing Techniques,\224 Computer Feb 1993 pp 62-76  121 E P Preparata and J Vuillemin 223The Cube-Connected Cy cles A Versatile Network for Parallel Computation,\224 Comm ACM Vol 24 No 5 May 1981 pp 300-309  131 Y Saad and M H Schultz 223Topological Properties of Hy percubes,\224IEEE Trans Comp Vol 37 No 7 July 1988 pp 14 S Shoari and N Baghenadeh 223computation of the Fast Fourier Transform on the Star-Connected Cycle Network,\224 to appear in Comp  Elec. Engl 1996 15 P Vadapalli and P K Srimani 221\223ho Different Families of Fixed Degree Regular Cayley Networks,\224 Proc Int\222l Phoenix Con Comp Comm Mar 28-31,1995 pp 263-269 1993 Vol 1 pp 91-95 867-872 452 


It can also be added to cell CrossSales.3\(PC, printer one_year,\205 5  Distributed and Incremental Rule Mining There exist two ways to deal with association rules 267  Static that is, to extract a group of rules from a snapshot, or a history, of data and use "as is 267  Dynamic that is, to evolve rules from time to time using newly available data We mine association rules from an e-commerce data warehouse holding transaction data. The data flows in continuously and is processed daily Mining association rules dynamically has the following benefits 267  223Real-time\224 data mining, that is, the rules are drawn from the latest transactions for reflecting the current commercial trends 267  Multilevel knowledge abstraction, which requires summarizing multiple partial results. For example association rules on the month or year basis cannot be concluded from daily mining results. In fact multilevel mining is incremental in nature 267  For scalability, incremental and distributed mining has become a practical choice Figure 3: Distributed rule mining Incremental association rule mining requires combining partial results. It is easy to see that the confidence and support of multiple rules may not be combined directly. This is why we treat them as \223views\224 and only maintain the association cube, the population cube and the base cube that can be updated from each new copy of volume cube. Below, we discuss several cases to show how a GDOS can mine association rules by incorporating the partial results computed at LDOSs 267  The first case is to sum up volume-cubes generated at multiple LDOSs. Let C v,i be the volume-cube generated at LDOS i The volume-cube generated at the GDOS by combining the volume-cubes fed from these LDOSs is 345   n i i v v C C 1  The association rules are then generated at the GDOS from the centralized C v  214  The second case is to mine local rules with distinct bases at participating LDOSs, resulting in a local association cube C a,I a local population cube C p,I  and a local base cube C b,i at each LDOS. At the GDOS, multiple association cubes, population cubes and base cubes sent from the LDOSs are simply combined, resulting in a summarized association cube and a summarized population cube, as 345   n i i a a C C 1   345   n i i p p C C 1  and 345   n i i b b C C 1  The corresponding confidence cube and support cube can then be derived as described earlier. Cross-sale association rules generated from distinct customers belong to this case In general, it is inappropriate to directly combine association cubes that cover areas a 1 205, a k to cover a larger area a In the given example, this is because association cubes record counts of customers that satisfy   customer product merchant time area Doe TV Dept Store 98Q1 California Doe VCR Dept Store 98Q1 California customer product merchant time area Doe VCR Sears 5-Feb-98 San Francisco Joe PC OfficeMax 7-Feb-98 San Francisco customer product merchant time area Doe TV Fry's 3-Jan-98 San Jose Smith Radio Kmart 14-Jan-98 San Jose Association   population      base          confidence      support cube               cube                cube         cube                cube LDOS LDOS GDOS 


the association condition, and the sets of customers contained in a 1 205, a k are not mutually disjoint. This can be seen in the following examples 214  A customer who bought A and B in both San Jose and San Francisco which are covered by different LDOSs , contributes a count to the rule covering each city, but has only one count, not two, for the rule A  336  B covering California 214  A customer \(e.g. Doe in Figure 3\who bought a TV in San Jose, but a VCR in San Francisco, is not countable for the cross-sale association rule TV  336 VCR covering any of these cities, but countable for the rule covering California. This is illustrated in Figure 3 6  Conclusions In order to scale-up association rule mining in ecommerce, we have developed a distributed and cooperative data-warehouse/OLAP infrastructure. This infrastructure allows us to generate association rules with enhanced expressive power, by combining information of discrete commercial activities from different geographic areas, different merchants and over different time periods. In this paper we have introduced scoped association rules  association rules with conjoint items and functional association rules as useful extensions to association rules The proposed infrastructure has been designed and prototyped at HP Labs to support business intelligence applications in e-commerce. Our preliminary results validate the scalability and maintainability of this infrastructure, and the power of the enhanced multilevel and multidimensional association rules. In this paper we did not discuss privacy control in customer profiling However, we did address this issue in our design by incorporating support for the P3P protocol [1 i n  ou r data warehouse. We plan to integrate this framework with a commercial e-commerce system References 1  Sameet Agarwal, Rakesh Agrawal, Prasad Deshpande Ashish Gupta, Jeffrey F. Naughton, Raghu Ramakrishnan, Sunita Sarawagi, "On the Computation of Multidimensional Aggregates", 506-521, Proc. VLDB'96 1996 2  Surajit Chaudhuri and Umesh Dayal, \223An Overview of Data Warehousing and OLAP Technology\224, SIGMOD Record Vol \(26\ No \(1\ 1996 3  Qiming Chen, Umesh Dayal, Meichun Hsu 223 OLAPbased Scalable Profiling of Customer Behavior\224, Proc. Of 1 st International Conference on Data Warehousing and Knowledge Discovery \(DAWAK99\, 1999, Italy 4  Hector Garcia-Molina, Wilburt Labio, Jun Yang Expiring Data in a Warehouse", Proc. VLDB'98, 1998 5  J. Han, S. Chee, and J. Y. Chiang, "Issues for On-Line Analytical Mining of Data Warehouses", SIGMOD'98 Workshop on Research Issues on Data Mining and Knowledge Discovery \(DMKD'98\ , USA, 1998 6  J. Han, "OLAP Mining: An Integration of OLAP with Data Mining", Proc. IFIP Conference on Data Semantics DS-7\, Switzerland, 1997 7  Raymond T. Ng, Laks V.S. Lakshmanan, Jiawei Han Alex Pang, "Exploratory Mining and Pruning Optimizations of Constrained Associations Rules", Proc ACM-SIGMOD'98, 1998 8  Torben Bach Pedersen, Christian S. Jensen Multidimensional Data Modeling for Complex Data Proc. ICDE'99, 1999 9  Sunita Sarawagi, Shiby Thomas, Rakesh Agrawal Integrating Association Rule Mining with Relational Database Systems: Alternatives and Implications", Proc ACM-SIGMOD'98, 1998   Hannu Toivonen, "Sampling Large Databases for Association Rules", 134-145, Proc. VLDB'96, 1996   Dick Tsur, Jeffrey D. Ullman, Serge Abiteboul, Chris Clifton, Rajeev Motwani, Svetlozar Nestorov, Arnon Rosenthal, "Query Flocks: A Generalization of Association-Rule Mining" Proc. ACM-SIGMOD'98 1998   P3P Architecture Working Group, \223General Overview of the P3P Architecture\224, P3P-arch-971022 http://www.w3.org/TR/WD-P3P.arch.html 1997 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



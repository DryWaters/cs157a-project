A Data Mining Methodology and Its Application to Semi-Automatic Knowledge Acquisition Mika Klemettinen Heikki Mannila Hannu Toivonen Dept of Computer Science Dept of Computer Science University of Helsinki University of Helsinki University of Helsinki P.O.Box 26 FIN-00014 P.O.Box 26 FIN-00014 P.O.Box 26 FIN-00014 Helsinki Finland Helsinki Finland Helsinki Finland mklemett Ocs Helsinki FI mannilaecs Helsinki FI 
htoivone@cs.Helsinki.FI Dept of Computer Science Abstract We antroduce a methodology for knowledge dascou ery an databases li'DD where one first dascouers large collectzons of patterns at once and then performs an teractauely retraeves subsets of the collectaon of pat terns The proposed methodology suats such KDD formalasms as assocaatzon and epzsode rules where large collections of potentaally anterestang rules can be found eficzently We present methods 
that support anteractwe explor ation of large collectzons of rules Wath these methods the user can flexably specafy the focus of anterest and also ateratzuely refine at We haue zmplemented our methodology an the TASA system whach dascouers patterns an telecommunzcatzon alarm databases In this paper we gave concrete ex amples of how to use frequent patterns an the construc taon of alarm correlation expert systems 1 Introduction Data mining 
and knowledge discovery KDD is a promising approach for semi-automatic knowledge ac quisition from large masses of existing data In KDD one typically wants to find a small collection of in teresting e.g strong useful surprising or valuable patterns rules etc that occur or hold in the data Consider as an example the task of fault management in telecommunication networks The networks produce large amounts of alarm information which must be analyzed and interpreted before faults can be located So-called 
alarm correlation systems see e g 6 81 are expert systems for analysis of alarm data They are quite popular but acquiring all the knowledge ne cessary for constructing an alarm correlation system for a network and its elements is difficult The com plexity and diversity of network elements and the large variation in the patterns of alarm occurrences pose ser ious problems for network management experts trying to build a correlation model Moreover characteristics of the alarm flow change often, as new equipment and software releases 
are added to the network On the other hand large amounts of alarms are available so the area is potentially good for KDD application Most knowledge discovery systems prune and rank the set of discovered patterns during the search for the patterns We adopt a different approach We use methods that locate all rules from a given class that satisfy certain simple frequency constraints Dis covered rules are not pruned automatically but the user has explicit control over the operations on 
a rule set This way the user can always be sure that the view on the data is in a sense complete the system has not put aside any rules automatically Our approach is based on two simple facts 0 Iteration is essential in KDD It can be hard or even impossible to specify beforehand what is interesting or relevant 0 Pattern generation from very large data sets is time consuming Efficient algorithms exist but the pattern extraction phase still is 
a barrier for smooth interaction We propose a KDD process where emphasis is on 1 In the pattern discovery phase find all potentially interesting patterns according to some rather loose criteria 2 Provide flexible methods in the presentation phase for iteratively and interactively creating different views to the discovered patterns Preprocessing and transformation steps are typic ally needed before patterns can be discovered Fig two central phases 0-8186-8147-0197 $10.00  1997 IEEE 670 


Figure 1 The KDD process model ure 1 A goal of our model is to avoid repeating the time consuming phases of preprocessing, transforma tion and discovery We have implemented our methodology in the TASA system 7 which discovers patterns in telecommunica tion alarm databases and provides tools for interactive identification of the relevant patterns The rest of this paper is organized as follows In Section 2 we briefly discuss two motivating ex amples and give the basic properties of the knowledge discovery methods we have employed The methodo logy is described in Section 3 Then in Section 4 we concentrate on the pattern presentation phase of our KDD process In Section 5 we summarize our exper iences in applying the methodology in building alarm correlation systems Finally, Section 6 is a short con clusion Related work KDD process and methodology have been discussed in 3 4 51 where the importance of interaction and iteration is also underlined The iter ation covers however either the whole process or at least the pattern discovery and presentation phases To the best of our knowledge none of the exist ing KDD systems supports the methodology proposed here For instance in Explora 9 49er El61 and Ke fir 1111 the user can interactively change the focus but that requires a new pattern discovery Additionally the approach of discovering all patterns can be contras ted with numerous methods e.g in machine learning which aim directly at more focused discovery and pro duce one or at most few patterns that match the given problem specification These methods usually require that the searched or learned subject is described quite carefully in advance 2 Examples of Application Domains In this section we outline first a very simple ap plication domain student enrollment data and then discuss in more detail a significantly harder case the analysis of telecommunications alarm data 2.1 Student Enrollment Data The first simple case study concerns association rules l in the student enrollment database of courses in computer science at the University of Helsinki In the course enrollement database we may find an asso ciation rule IF Introduction to Unix THEN Programming in C WITH conf\(0.84 freq\(0.34 The rule states that 84 of the students that have taken 223Introduction to Unix\224 also have taken 223Pro gramming in C\224  and that 34 of all the students ac tually have taken both courses More formally an as sociation rule is an expression X  Y where X and Y are sets of predicates Given a set of students, the con fidence of such rule is the conditional probability with which predicates in Y are satisfied by a tuple in the database given that predicates in X are satisfied The rule is called frequent if its frequency exeeds a user given threshold i.e if all the predicates in XUY occur together at least a user-specified minimum number of times The goal in analyzing student enrollment data is to obtain accurate and useful information about the inter relationships between enrollments to various courses Such relationships can be valuable e.g for expert sys tems aimed at planning curriculums and allocating re sources 2.2 Telecommunication Alarm Data The other case study which deals with a more in teresting knowledge acquisition effort handles rules derived from episodes 14 in telecommunication net work alarm sequences A telecommunication alarm database contains event data from a number of inter connected components such as switches Alarms are produced by the components to report abnormal situ ations There are typically thousands of alarms a day and they are of thousands of different types Telecommunication networks are growing fast in size and complexity and at the same time their man agement is becoming more difficult The task of identi fying and correcting faults in telecommunication net works is a critical task of network management Thus the techniques of alarm correlation  automatic filter ing of redundant alarms identification of faults and suggestions for corrective actions  are valuable We adopt the following view to alarm correlation similar to the one taken e.g in 8 Abstractly the 671 


input to a correlation system is an ordered alarm se quence An alarm consists of time sender and alarm message fields The time is recorded by the sender typically at a granularity of one second The sender of the alarm can be identified at the level of e.g a network element The alarm message contains all the available information about the problem A correlation pattern describes a situation that can be recognized in an alarm sequence within a time win dow of a given length Typically a correlation pattern is an expression on the set of active alarms of e.g the last five minutes Correlation patterns are construc ted as logical combinations of alarm predicates alarm predicates are derived from the fields of alarm mes sages by constructing boolean-valued assertions If in a given window there is a set of alarms that matches the correlation pattern then the set is said to be an occurrence of the pattern Associated with each cor relation pattern is a correlation action which is to be executed when there is an occurrence of the corres ponding pattern in a window Constructing an alarm correlation system for a net work and its elements is however difficult Both net works a.nd network elements evolve qiiickly over time so a correlation system is never complete It also takes time for the experts to learn new correlations and to modify existing ones KDD methods can be used in constructing a cor relation system The central idea is to discover recur rent patterns of alarms that are potentially useful in the specification of correlation patterns A discovered pattern can be for instance a set of alarms that oc curs frequently within a time window of a given width or a pattern can state that a certain alarm tends to be followed by another alarm from the same sender Episode rules and episodes la 141 are a modific ation of the concept of association rules and frequent sets applied to sequential data e.g telecommunica tion alarms An episode rule is a rule of the form1 IF link alarm link jailure THEN high fault rate WITH 201 C401 conf 0.23 freq\(246/1056 which tells us that in 23 per cent of the cases where link alarm and link failure occurred within 20 seconds also high fault rate occurred within 40 seconds Moreover in the data the left-hand side oc curred 1 056 times and in 246 cases it was followed by the right-hand side within the given time windows An episode is parallel if there is no requirement for The actual predicates occurring in the example rules have been changed the order of the events within the time window and serzal if the events are required to occur in a certain order In general we are not interested in rules with a negligible confidence e.g less than 20 per cent; it is typical to select only those rules with a confidence ex ceeding a given confidence threshold For finding all potentially interesting episode rules in a given event scquencc, the nccessary parameters are the frequency threshold a set of window sizes which may be used in the episode rules and the confidence threshold The method that we have used to discover frequent epis odes and cpisodc rules in our data is described in la In summary our scenario for building alarm correl ation systems is the following see Figure 2 0 First a large database of alarms is analyzed off line and connections between sets of alarms are discovered automatically 0 Then for the construction of an alarm correlation system the network management specialists have at hand a collection of alarm patterns which they can use in specifying the alarm correlation system 0 In the final step the correlation rules are applied in real-time fault identification 3 The Methodology KDD is an iterative process and requires interac tion with the user A general KDD process adap ted from 5 consists of several phases and iteration between them \(Figure 1 Our methodology gives spe cial roles to the pattern discovery and pattern present ation phases of the KDD process In our approach large collections of patterns are discovered at once Then iterative information retrieval methods are used to give flexible views to the discovered patterns The emphasis in our methodology is in the pattern present ation part where interesting information is searched for iteratively, without repeating the time consuming pattern discovery phase In the first two phases of the whole process the raw data is collected and prepared into a suitable form for the pattern discovery A general overview of the data can be produced at this phase Attributes identified mi irrelevant are removed and potentially useful new attributes can be derived The preprocessing in our methodology does not however mean that one expli citly defines interestingness as in some other method ologies All relcvant background knowledge should be taken advantage of For instancc in the case of teleeommu nication alarm data attributes can be derived to con tain, e.g information about the network topology 672 


Automatic Discovery Methods PattemdRules 9 n Domain Expertise JU 2  Figure 2 An alarm correlation model using discovered alarm patterns In the pattern discovery phase all potentially inter esting patterns are generated from the data set The rather loose criteria for interestingness can be e.g frequency, prevention of taking rarely occurring phe nomena into account or strength of the patterns The user specifies the following parameters for the discovery of the rules using TASA The alarm predicates are given by the user For episode rules, the type of the alarm and the sender of the alarm are the most typical predicates For association rules in turn much larger predicate classes are useful In the case of episodes the user specifies whether serial or parallel episodes are searched for For episode rules the user also supplies a set of time bounds with which the rules are construc ted Our fault management experts have typically preferred time windows ranging from 5 seconds to 10 minutes For both episode and association rules a fre quency threshold is given by the user The meth ods output all episode and association rules spe cified by the parameters above whose frequency exceeds or is equal to the user-specified threshold For both episode and association rules the user also specifies a confidence threshold The al gorithms then output all episode and association rules whose confidence is at least equal to the threshold The discovery method produces each episode rule and association rule satisfying the above conditions The conditions are typically quite loose so large amounts of rules are discovered For each rule TASA outputs the confidence and the frequency and an es timate of the statistical significance of the rule Example 1 The course enrollment database consists of registration information of 1 066 students who had registered for at least two courses There are 2 010 association rules that match at least 11 students i.e the frequency threshold is 0.01 There are 6 715 rules that match at least 6 students In contrast in the alarm sequence containing 43 478 alarms from a period of 10 days, there are 5 498 serial episode rules that hold with a frequency threshold of 10 absolute value with a maximum time bound of 60 seconds There are 1 497 association rules between attribute values of individual alarms that match at least 435 alarms i.e frequency threshold as 0.1 0 The goal of the methodology is that returning to the pattern discovery phase is needed as seldom as possible It is realistic to expect however that the algorithms need to be run several times Parameter settings may need adjustment or errors in the data cleaning phase may be revealed so that returning to the first phase of the process is necessary The basic idea  iteration in the pattern presenta tion phase  can be applied to formalisms that have certain properties The desired focus is not known definitely in ad vance There is an algorithm that can produce all pat terns from a class of potentially interesting pat terns The time requirement for discovering all po tentially interesting patterns is not considerably 673 


longer than if the discovery was focused to a small subset of the potentially interesting patterns There are several KDD formalisms that fit in this setting Association rule l 21 and episode rule la 141 algorithms can efficiently discover thousands of rules from relatively simple databases A formal treatment of the setting of discovering all interesting sentences and an analysis of a general algorithm can be found in 13 The presentation of discovered knowledge is a main part of our methodology In this phase the relevant patterns should be located from large collections of potentially interesting patterns The problem of locat ing a small set of truly relevant information is a gen eric problem in data mining while formal statistical criteria for strength and significance of the discovered items abound, it is much harder to know which parts of the discovered knowledge really are useful for the user Finally the discovered knowledge has to be under stood and applied e.g in an expert system The role of the KDD system is to provide appropriate tools for displaying and browsing the knowledge methods for expressing the desired focus and to support iterative specification of the focus 4 Presentation of Rules As a result of the pattern discovery phase of our KDD process model all patterns matching the spe cified criteria are produced All the patterns are however not supposed to be interesting to a partic ular user or in a particular situation Discovered rules can fail to be interesting for several reasons 0 A rule can correspond to prior knowledge or expectations For example, it can be known from the implementation that if an element sends an alarm A it will also send an explanatory alarm B 0 A rule can refer to uninteresting attrib utes or attribute combinations E.g a rule containing low priority alarms may be non interesting and the user would like to filter out all such rules e Rules can be redundant For example rule b below has no additional predictive power re garding the course 223Unix Platform\224 over rule a and could be pruned as redundant a IF Data Communzcatzons Programmzng zn C THEN Unzs Platform WITH conf\(0.14 freq\(0.03 b IF Data Communicatzons Programmzng zn C Introductzon to Unzx THEN Unzs Platform WITH conf\(0.14 freq\(0.03 The aim of the presentation phase of our method ology is to support efficient interactive and focused views to the rules In this section we present meth ods for exploring large sets of association and episode rules The ideas of this section can be best applied on large unstructured sets of rules and other similar simple pattern formalisms Three types of operations are useful in processing a large collection of rules 0 Pruning reduction of the number of rules e Sorting ranking of rules according e.g to stat e Structuring organization of the rules e.g., to istical significance and clusters or hierarchies Obvious pruning and sorting criteria for association and episode rules are rule confidence frequency and statistical significance. Rules can be pruned by setting thresholds on these properties Examples of the effect of threshold-value based pruning with alarm data are presented in Figure 3 Templates lo pattern expressions that describe the form of rules that are to be selected or rejected are one way of focusing the view to a large space of rules A template is an expression Ai   Ak  Ak+i  A where each Ai is either an attribute name a class name or an expression C or C where C is a class name.\222 Here C and C correspond to one or more and zero or more instances of the class C respectively A rule matches a template if the rule can be considered to be an instance of the pattern The order of the compon ents in the templates has no significance if the attribute order in the rules is not significant association rules and parallel episode rules With templates the user can explicitly specify both what is interesting and what is not To be interesting, a rule has to match a select ive template If a rule however matches an unselective template it is considered uninteresting To be presen ted to the user a rule must be considered interesting 222A can also be a regular expression 674 


0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Conlience threshold 5ooo 4ow 3ow ZWO tow t00 200 3M 4cQ 5w MM 700 800 900 Frequency threshold absolute values Figure 3 thresholds to the number of rules in alarm data Effect of rule confidence and frequency  i.e. match one of the selective templates  and it must not be uninteresting  i.e. not match with any of the unselective templates Example 2 In our example domain of computer sci ence course enrollment the courses are divided into three classes basic undergraduate and graduate courses In addition all courses belong to the parent class 221any course 222 Thus we have such generalizations as an Figure 4 Using the selective template a below the user obtains a number of rules with at least a graduate course on the IF part and the course 223Design and Analysis of Algorithms\224 on the THEN part Examples of such rules are b e and d Of the 2 OiO rules in the example database there are 15 rules that match the above specifications and have confidence of 0.2 or more and frequency of 0.01 or more This sort of rules give an idea of what the stu dents do in addition to taking 223Design and Analysis of Algorithms\224 and the discovered rules can be util ized when planning the course Note that here the IF THEN structure implies no temporal order a IF Graduate Course Any Course Deszgn and Analyszs of Algorzthms Introduction to Computers Deszgn and Analyszs of Algorzthms THEN b IF Compzlers THEN WITH conf\(0.16 freq\(0.01 c IF Neural Networks Data Communzcatzons Deszgn and Analyszs of Algorzthms THEN WITH conf\(0.33 freq\(0.01 d IF User Interfaces Informatzon Systems Deszgn and Analysis of Algorzthms THEN WITH conf\(0.02 freq\(0.10 The user may consader some of the resultang rules un anterestang such as b ancludang baszc courses By addang an unselectave template wath 223Basac Course\224 and 2212ny Course*\224 on the IFpart and 223Any Course 224 on the THENpart the user can filter out all rules wath  a basac course on the left-hand sade This technique is surprisingly powerful For ex ample background knowledge about the normal cur ricula of computer science studies can be taken into account by using templates that unselect all rules that correspond to the normal course of studies Example 3 As an example of how the system can be used in case of alarm data consider the follow ing cenario Assume the network manager has used TASA to discover episode rules for the past i0 days The manager knows that during that period, a device AA-16 caused serious problems and loss of money First he selects all rules that have AA-16 an the THEN part thus traceing alarms that potentially have some causal relationship with the problem in consider ation The number of such rules is however large 1 848 The network manager decides to restrict the THEN part to only contain one alarm The number of selected rules is still large 901 so he adds an unselective tem plate to remove all rules with devices from the same network area indicated by the first two characters in the device identificator here AA which he knows by experience not to have any effect to each other The number of rules is still large 240 rules so he further tightens the scope and adds a further selective template to get rules with at most two alarms on the IF part and confidence of at least 75 The resulting rule set contains 19 rules from the 5 498 original ones By browsing the resulting rules he finally finds alarms which indicate that the problems with device AA-16 had been caused by high fault rate in a similar nearby device 0 3The device name and the situation are fictional but the numbers reflect actual results and the effect of our methods 675 


Any Course introduction lntmductian Programming Information Artificial Programming Unix Data Design and Analysis User Neural Compilers tu Computers to Unix in rascal Systems Intelligence in C Platform Communications of Algon\222thms Interfaces Nehvorkr Figure 4 Course hierarchy It should be noted that sometimes considerable amounts of rules remain even when the user has found the desired focus with the described methods Automatic pruning sorting and structuring methods should at this point be available for invocation by the user especially for removal of redundancy see e.g 15 for rule covers statistical methods and cluster ing 5 Application Experience TASA has been in prototype iise in foiir telecom munication companies since the beginning of 1995 and experiences are encouraging A telecommunica tion network manager can use episode rules as correl ation patterns after possibly editing them and assign ing them appropriate correlation actions Discovered patterns can be used for filtering uninformative alarms for combining alarms to construct hypothesis of faults or for prediction of faults Episode and association rules are also useful for providing different views to the analyzed alarms as in Example 3 Although the discovery algorithms are not directly applicable for on-line analysis TASA has turned out to be useful also in network surveillance The analysis can be rerun or augmented e.g every day or every hour Recent patterns may point to yet unnoticed problems in the network The fault management experts in the telecommunic ation companies have found the approach and TASA useful in, e.g 0 finding long-term, rather frequently occurring de 0 creating an overview of a short-term alarm se 0 evaluating the alarm data base consistency and pendencies quence and correctness On the other hand many of the rules discovered by TASA are deemed trivial by the network managers Luckily much of the trivial knowledge can be ex pressed and removed with templates Example 4 Consider an alarm correlation system which operates in real time and is also able to handle delayed alarms and slightly inaccurate time stamps In the correlation patterns delays are handled with a spe cial wait function Episode and assocaataon rules can be applaed an this system in a rather straightforward way The episode rule IF THEB high fault rate WITH SI SO conf\(0.70 freq\(700/1000 link alarm  link failure discovered by TASA can be coded in the system as fol lows  if 223alarm type  link alarm\224 then start time wait until \223alarm type  link failure\224 or LLtime  5 sec\224 f 223alarm type  link failure\224 then display warning \223high fault rate with 70 probability in 60 sec\224 else forward the original alarm That is if a link alarm occurs and a link failure follows within 5 seconds the rule right-hand side information is sent and the original alarms are suppressed If a link failure does not follow 221wzthin 5 seconds the 07.2 ginal link ularm is forwarded The correlation procedure can be enhanced using as sociation rules For example assume that we have de tccted that if the alarm type is link alarm the time of the day is ofice hours and alarm severity is I then with probability of 95 the alarming element type is BS After expert evaluation of the rule we know that such alarms from network elements of type BS can be ignored However if an element of any other type sends that alarm it is an interesting one The following correlation function removes such alarms  if 223alarm type  link alarm\224 and 223office hours\224 and 223severity  1\224 and 221\221element type  BS\224 then exit forward the original alarm 0 Unexpected but useful dependencies have been found e.g between network elements which are not immediately connected in the network topology Be ginning from the first tests discovered rules have been applied in alarm correlation systems 676 


6 Conclusion We have described a knowledge discovery method ology that can be used to automate knowledge acquis ition The methodology has the following two distinct ive characteristics 1 a large collection of potentially relevant rules is discovered at once and 2 different views can be formed on the discovered rules iteratively and interactively The motivation is that after the dis covery of all potentially interesting rules iteration is very efficient As an example application area we descibed tele communication networks alarm data The flow of alarms should be correlated automatically to a more in telligible form in order to facilitate identification and correction of faults Unfortunately the construction of an alarm correlation system requires a lot of both expertise and time and is a process that never is com plete Our experience in this field with both association and episode rules supports the claim that the meth odology is useful in practice For formalisms stronger than association and episode rules strong focus in the pattern discovery phase may be essential for keeping the computation tractable For well-defined problems this is probably fine but for exploring regularities in large data sets the interaction may be cumbersome References 1 R Agrawal T Imielinski and A Swami Mining as sociation rules between sets of items in large data bases In Proceedings of AGM SIGMOD Conference on Management of Data SIGMOD\22293 pp 207  216 May 1993 a R Agrawal H Mannila R Srikant H Toivonen and I Verkamo Fast discovery of association rules. In Advances in Knowledge Discovery and Data Mining pp 307  328 AAAI Press Menlo Park CA 1996 31 R Brachman and T Anand The process of know ledge discovery in databases A first sketch. In Know ledge Discovery in Databases, Papers from the 1994 AAA I Workshop IcDD\22294 July 1994 4 U Fayyad G Piatetsky-Shapiro and P Smyth The KDD process for extracting useful knowledge from volumes of data Communications of the ACM 39\(11  34 November 1996 5 U Fayyad G Piatetsky-Shapiro and P Smyth From data mining to knowledge discovery An overview In Advances in Knowledge Discovery and Data Mining pp 1-34 AAA1 Press Menlo Park CA 1996 6 R Goodman B Ambrose H Latin and C Ulmer Noaa  an expert system managing the telephone network In Integrated Network Management IV pp 316  327 Chapman  Hall London 1995 7 K Hatonen M Klemettinen H Mannila P Ronkainen and H Toivonen Knowledge discov ery from telecommunication network alarm data bases In 12th Int\222l Conference on Data Engineering ICDE\22296 pp 115  122 New Orleans Louisiana February 1996 SI G Jakobson and M. Weissman Alarm correlation. In IEEE Network 7\(6  59 November 1993 9 W Kloesgen Efficient discovery of interesting state ments in databases Journal of Intelligent Informa tion Systems 4\( 1  69 1995 lo M Klemettinen H Mannila P Ronkainen H Toivonen and I Verkamo Finding interesting rules from large sets of discovered association rules In Pro ceedings of the Third Int\222l Conference on Information and Knowledge Management CIKM\22294 pp 401  407 Gaithersburg MD November 1994 ACM 111 C Matheus G Piatetsky-Shapiro and D McNeill Selecting and reporting what is interesting In Ad vances in Knowledge Discovery and Data Mining pp 495  515 AAA1 Press Menlo Park CA 1996 121 H Mannila and H Toivonen Discovering generalized episodes using minimal occurrences In Proceedings of the Second Int\222l Conference on Knowledge Discovery and Data Mining \(KDD\22296 pp 146  151 Portland Oregon August 1996 AAAI Press 13 H Mannila and H Toivonen On an algorithm for finding all interesting sentences In Cybernetics and Systems Volume II The Thirteenth European Meet ing on Cybernetics and Systems Research pages 973  978 Vienna Austria April 1996 Austrian Society for Cybernetic Studies 14 H Mannila H Toivonen and I Verkamo Discov ering frequent episodes in sequences In Proceedings of the First Int\222l Conference on Knowledge Discovery and Data Mining I<DD\22295 pp 210  215 Montreal Canada August 1995 AAA1 Press 15 H Toivonen M Klemettinen P Ronkainen K Hatonen and H Mannila Pruning and grouping of discovered association rules In Workshop Notes of the ECML-95 Workshop on Statistics Machine Learning and Knowledge Discovery in Databases pp 47  52 Heraklion Greece April 1995 MLnet 16 R Zembowicz and J Zytkow From contingency tables to various forms of knowledge in databases In Advances in Knowledge Discovery and Data Mining pp 329  349 AAAI Press Menlo Park CA 1996 677 


In Figures 10 and 11 we see MAFIA is approximately four to five times faster than Depthproject on both the Connect-4 and Mushroom datasets for all support levels tested down to 10 support in Connect-4 and 0.1 in Mushroom For Connect-4 the increased efficiency of itemset generation and support counting in MAFIA versus Depthproject explains the improvement Connect 4 contains an order of magnitude more transactions than the other two datasets 67,557 transactions amplifying the MAFIA advantage in generation and counting For Mushroom the improvement is best explained by how often parent-equivalence pruning PEP holds especially for the lowest supports tested The dramatic effect PEP has on reducing the number of itemsets generated and counted is shown in Table 1 The entries in the table are the reduction factors due to PEP in the presence of all other pruning methods for the first eight levels of the tree The reduction factor is defined as  itemsets counted at depth k without PEP   itemsets counted at depth k with PEP In the first four levels Mushroom has the greatest reduction in number of itemsets generated and counted This leads to a much greater reduction in the overall search space than for the other datasets since the reduction is so great at highest levels of the tree In Figure 12 we see that MAFIA is only a factor of two better than Depthproject on the dataset Chess The extremely low number of transactions in Chess 3196 transactions and the small number of frequent 1-items at low supports only 54 at lowest tested support muted the factors that MAFIA relies on to improve over Depthproject Table 1 shows the reduction in itemsets using PEP for Chess was about an order of magnitude lower compared to the other two data sets for all depths To test the counting conjecture we ran an experiment that vertically scaled the Chess dataset and fixed the support at 50 This keeps the search space constant while varying only the generation and counting efficiency differences between MAFIA and Depthproject The result is shown in Figure 13 We notice both algorithms scale linearly with the database size but MAFIA is about five times faster than Depthproject Similar results were found for the other datasets as well Thus we see MAFIA scales very well with the number of transactions 5.3 Effects Of Compression To isolate the effect of the compression schema on performance experiments with varying rebuilding threshold values we conducted The most interesting result is on a scaled version of Connect-4, displayed in Figure 14 The Connect-4 dataset was scaled vertically three times so the total number of transactions is approximately 200,000 Three different values for rebuilding-threshold were used 0 corresponding to no compression 1 compression immediately and all subsequent operations performed on compressed bitmaps\and an optimized value determined empirically We see for higher supports above 40 compression has a negligible effect but at the lowest supports compression can be quite beneficial e.g at 10 support compression yields an improvement factor of 3.6 However the small difference between compressing immediately and finding an optimal compression point is not so easily explained The greatest savings here is only 11 at the lowest support of Conenct-4 tested We performed another experiment where the support was fixed and the Connect-4 dataset was scaled vertically The results appear in Figure 15 The x-axis shows the scale up factor while the y-axis displays the running times We can see that the optimal compression scales the best For many transactions \(over IO6 the optimal re/-threshold outperforms compressing everywhere by approximately 35 In any case both forms of compression scale much better than no compression Compression on Scaled ConnectAdata Compression Scaleup Connectldata ALL COMP 0 5 10 15 20 25 30 100 90 80 70 60 50 40 30 20 10 0 Min Support  Scaleup Factor Figure 14 Figure 15 45 1 


6 Conclusions We presented MAFIA an algorithm for finding maximal frequent itemsets Our experimental results demonstrate that MAFIA consistently outperforms Depthproject by a factor of three to five on average The breakdown of the algorithmic components showed parent-equivalence pruning and dynamic reordering were quite beneficial in reducing the search space while relative compressiodprojection of the vertical bitmaps dramatically cuts the cost of counting supports of itemsets and increases the vertical scalability of MAFIA Acknowledgements We thank Ramesh Agarwal and Charu Aggarwal for discussing Depthproject and giving us advise on its implementation We also thank Jayant R Haritsa for his insightful comments on the MAFIA algorithm and Jiawei Han for providing us the executable of the FP-Tree algorithm This research was partly supported by an IBM Faculty Development Award and by a grant from Microsoft Research References I R Agarwal C Aggarwal and V V V Prasad A Tree Projection Algorithm for Generation of Frequent Itemsets Journal of Parallel and Distributed Computing special issue on high performance data mining to appear 2000 2 R Agrawal T Imielinski and R Srikant Mining association rules between sets of items in large databases SIGMOD May 1993  R Agrawal R Srikant Fast Algorithms for Mining Association Rules Proc of the 20th Int Conference on Very Large Databases Santiago Chile, Sept 1994  R Agrawal H Mannila R Srikant H Toivonen and A 1 Verkamo Fast Discovery of Association Rules Advances in Knowledge Discovery and Data Mining Chapter 12 AAAVMIT Press 1995 5 C C Aggarwal P S Yu Mining Large Itemsets for Association Rules Data Engineering Bulletin 21 1 23-31 1 998 6 C C Aggarwal P S Yu Online Generation of Association Rules. ICDE 1998: 402-41 1 7 R J Bayardo Efficiently mining long patterns from databases SICMOD 1998: 85-93 8 R J Bayardo and R Agrawal Mining the Most Interesting Rules SIGKDD 1999 145-154 9 S Brin R Motwani J D Ullman and S Tsur Dynamic itemset counting and implication rules for market basket data SIGMOD Record ACM Special Interest Group on Management of Data 26\(2\1997 IO B Dunkel and N Soparkar Data Organization and access for efficient data mining ICDE 1999 l 11 V Ganti J E Gehrke and R Ramakrishnan DEMON Mining and Monitoring Evolving Data. ICDE 2000: 439-448  121 D Gunopulos H Mannila and S Saluja Discovering All Most Specific Sentences by Randomized Algorithms ICDT 1997: 215-229 I31 J Han J Pei and Y Yin Mining Frequent Pattems without Candidate Generation SIGMOD Conference 2000 1  12 I41 M Holsheimer M L Kersten H Mannila and H.Toivonen A Perspective on Databases and Data Mining I51 W Lee and S J Stolfo Data mining approaches for intrusion detection Proceedings of the 7th USENIX Securiry Symposium 1998 I61 D I Lin and Z M Kedem Pincer search A new algorithm for discovering the maximum frequent sets Proc of the 6th Int Conference on Extending Database Technology EDBT Valencia Spain 1998 17 J.-L Lin M.H Dunham Mining Association Rules: Anti Skew Algorithms ICDE 1998 486-493 IS B Mobasher N Jain E H Han and J Srivastava Web mining Pattem discovery from world wide web transactions Technical Report TR-96050 Department of Computer Science University of Minnesota, Minneapolis, 1996 19 J S Park M.-S Chen P S Yu An Effective Hash Based Algorithm for Mining Association Rules SIGMOD Conference 20 N Pasquier Y Bastide R Taouil and L Lakhal Discovering frequent closed itemsets for association rules ICDT 99 398-416, Jerusalem Israel January 1999 21 J Pei J Han and R Mao CLOSET An efficient algorithm for mining frequent closed itemsets Proc of ACM SIGMOD DMKD Workshop Dallas TX May 2000 22 R Rastogi and K Shim Mining Optimized Association Rules with Categorical and Numeric Attributes ICDE 1998 Orlando, Florida, February 1998 23 L Rigoutsos and A Floratos Combinatorial pattem discovery in biological sequences The Teiresias algorithm Bioinfomatics 14 1 1998 55-67 24 R Rymon Search through Systematic Set Enumeration Proc Of Third Int'l Conf On Principles of Knowledge Representation and Reasoning 539 550 I992 25 A Savasere E Omiecinski and S Navathe An efficient algorithm for mining association rules in large databases 21st VLDB Conference 1995 26 P Shenoy J R Haritsa S Sudarshan G Bhalotia M Bawa and D Shah: Turbo-charging Vertical Mining of Large Databases SIGMOD Conference 2000: 22-33 27 R Srikant R Agrawal Mining Generalized Association Rules VLDB 1995 407-419 28 H Toivonen Sampling Large Databases for Association Rules VLDB 1996 134-145 29 K Wang Y He J Han Mining Frequent Itemsets Using Support Constraints VLDB 2000 43-52 30 G I Webb OPUS An efficient admissible algorithm for unordered search Journal of Artificial Intelligence Research 31 L Yip K K Loo B Kao D Cheung and C.K Cheng Lgen A Lattice-Based Candidate Set Generation Algorithm for I/O Efficient Association Rule Mining PAKDD 99 Beijing 1999 32 M J Zaki Scalable Algorithms for Association Mining IEEE Transactions on Knowledge and Data Engineering Vol 12 No 3 pp 372-390 May/June 2000 33 M. J. Zaki and C Hsiao CHARM An efficient algorithm for closed association rule mining RPI Technical Report 99-10 1999 KDD 1995: 150-155 1995 175-186 3~45-83 1996 452 



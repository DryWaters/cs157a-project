1999 Third International Conference on Knowledge-Based Intelligent Information Engineeing Systems 31 Aug-I Sept 1999 Adelaide Australia A Data Structure for Dynamic Data Mining Akihiro KITADAT Tetsuya MURAI and Yoshiharu SAT0 Division of Systems and Information Engineering Graduate School of Engineering Hokkaido University Kita 13 Nishi 8 Kita-ku Sapporo 060-8628 JAPAN quitada murahiko ysato}@main.eng.hokudai.ad.jp Keywords  
Data mining Association rules Online mining Binary trees Abstract A new data structure for online data mining using binary tree is proposed Two experiments using syn thetic data show efffectiveness of the method of data mining based on the proposed data structure 1 Introduction The recent progress of computer technology pro vides a method of analyzing a massive number of transaction data in database 
systems Such direc tion has provoked various ways of KDD Knowl edge Discovery and Data mining and among them a mining of the so-called association ruZes[l obtains the wide-spread recognition as one of most active themes of data mining and several algo rithms like AIS[l and the Apriori[2 However these algorithms do not serve for the recent requirement of online mining of associa tion rules where a set 
of transactions is frequently updated.For the purpose Aggarwal et a1.[3 pro posed a method based on the adjacency lattice The purpose of this paper is to show that fur ther improvement of the adjacency lattice to bi nary tree structure enables us to perform more effective online mining of rules with two experi ments using synthetic data  Mr Kitada's current address Solutions Devel opment COE Systems Headquarters NTT DATA CORPORATION 
Kayabacho Tower Bidg 21-2 Shinkawa 1-chome Chuo-ku Tokyo 104-0033 JAPAN quitada@mua.biglobe.ne.jp 2 Association Rules Let Z be a finite set of items A subset in Z is called an itemset Any itemset can be a possible transaction A database V is defined as a set of transactions For an itemset X\(S I its degree of support 
s\(X is defined by where I  I is a size of a set Definition 1 Agrawal et 1 An association rule is an implication of the form X  Y where X and Y are itemsets with X n Y  0 2 An association rule X 3 Y holds in V with confidence 
c 0 5 c 5 1 iflc  w 3 An association rule X  Y has a degree of support s 0 5 s 5 1 in V ifs  s\(X U Y Mining of association rules is actually performed by generating all rules that have certain minimum support minsup and minimum confidence min 
conf that a user specifies The problem of finding all association rules that satisfy user-specified minimum support and confi dence consists of the following two-steps  Step 1 Find all itemsets X such that s\(X 2 minsup Such itemsets are called large itemsets Let C.D be the set of large itemsets given V 0-7803-5578-4l99/$10.0001999 IEEE 53 0 


1999 Third International Conference on Knowledge-Based Intelligent Information Engineeing Systems 31 Aug I Sept 1999 Adelaide, Australia Step 2 For each itemset L E Lv find a pair such that as a rule X*L\\X for any X L Step 1 requires much time when the size of D is massive So the central problem of mining associ ation rules is to make rapid algorithms of finding all itemsets 3 Previous Works 3.1 Apriori Agrawal et a1.[2 proposed the Apriori algorithm for finding large itemsets The first step in Apriori is to count the number of occurrences of each item and to find all large-1-itemsets whose degree of support is above minsup The kth step consists of the following two parts 1 Generate the candidate itemsets ck ushg the large itemsets in I found in the k  1 step 2 Calculate s\(X for each candidate itemset in ck 3 The set Lk of large itemsets in the Kth step is defined as the set of candidate itemsets X whose degree of support s\(X is at least min sup Finally the set L of large itemsets is defined by Figure 1 shows an example of the Apriori dge rithm I 20  7 Figure 1 An example of the Apriori algorithm where minsup=0.02  Figure 2 An example of adjacency lattice 3.2 Adjacency Lattice We can easily understand that the Apriori algo rithm actually constitutes a structure of lattice In fact Aggarwal et al.[3 revealed the effectiveness of using the so-called adjacency lattice for online generation of association rules by referring degrees of support for each large itemsets on the lattice structure where each node represent a candidate large itemset 4 The Proposed Data Struc ture In Aggrawal's method in general there are plural passes to reach a node large itemset when refer 531 


1999 Third International Conference on Knowledge-Based Intelligent Information Engineeing Systems 31 Aug-IU Sept 1999 Adelaide Australia Pointer for the next node when Pointer for the next node when Item name  the current one is considered  the current node is skipped  Degree of support I 9 T thetic Data ___-_____  The following two experiments were performed to compare the proposed method with the Apriori Static database First we consider a static i*O f t NULL Figure 5 Binary tree structure Figure 4 Data structure of nodes ring its degree of support So it would be easier to deal with the structure if there is a unique pass to reach each node For example by introducing an order relation between nodes the adjacency lat tice in Figure 2 is reduced to the tree structure shown in Figure 3 More precisely when we introduce the data structure of nodes shown in Figure 4 the ad cency lattice in Figure 2 can be represented as the binary tree structure in Figure 5 By the binary tree structure we do not have to retain all relationship between nodes saving memory capacity For example in order to refer ABCD we can take the pass NULL f At B t Ct D Similarly to refer BCD we can take NULL f A B f C f D Figure 6 the running time of the Airport in creases inversely proportional to degrees of support while that of the proposed method is almost constant So we can conclude the proposed method is effective in cases of lower degrees of support Dynamic database Secondly we consider a dynamic database case where a set of transac tions is updated As shown in Figure 7 the running time of the Apriori is directly propor tional to the size of a set of transactions since it must recompute from the beginning when ever updating On the other hand, the run ning time of the proposed method is almost constant because it has only to make a small change on a part of its binary tree structure with respect to updated transactions 6 Concluding Remarks In this paper we showed that the effectiveness of The running time of referring nodes is bounded binary tree structure in online association rules 532 


1999 Third International Conference on Knowledge-Based Intelligent Information Engineeing Systems 3 1 Aug-I Sept 1999 Adelaide Australia The proposed method   Aprioni  14 12 10 h 8 3  J I I t c   4 8 4 4 2 e __ n 20 15 10 5 Degrees of support  Figure 6 Static database Size of a set of transactions Figure 7 Dynamic database in data mining by two experiments with synthetic data The size of memory in the proposed method is reduced compared with the method using the adjacency lattice Nevertheless the proposed method requires 2max\(lTI nodes for the maximum size of transactions max\(lTI so further improve ment should be done in future task References R Agrawal T Imielinski and A Swami Mining Association Rules between Sets of Items in Large Databases Proceedings of ACM SIGMOD Conference on Management of Data, pp 207-216 1993 R Agrawal H Manila R Srikant H Toivonen and A I Verkamo Fast Discov ery of Association Rules in U M Fayyad, G Platetsky-Shapiro P Smyth and R Uthu rusamy eds Advances in Knowledge Dis covery and Data Mining AAA1 Press  The MIT Press pp 307-328 1996 C C Aggarwd and S Y Philip Online Gen eration of Association Rules Proceedings of the International Conference on Data Engi neering, pp 402-411 1998 533 


Dslsyt T25110010K TZSIZOolWK mk110.p8m10t 4Wk,30~p16mlt 120q8mlk I connect4 I Publicly available dM~e dsmaset wiul 130 items aod about 60K trmsactionr The maximal wansaction size is 45 I DeretipliO\224 Syntheticdamserwith IK items and IOKvanractions[ll Theave~g~sizeofmnraclionsirZS,andtheaveragesi2eofulemaximal tentirlly frequent itemsls is IO Synthetic dataset with IOK ilem and IWK Uansaclims Ill The average size of lmsaclions is 25 and ule average size of the maximal potentially frequent itemsets is 20 IOK iiemr and 4WK manractions The werage size of iraninctions is IO and ule average size of the maximal p~ienlidly hrqucnr itemsets is 8 Synthetic damel created with Ute IBM dalarer generator SI IK item and 4WK BansaELions The average size of transa~tionr is 30 and ule average si2 of Le maximal pxen~ially frequent itemsets is 16 Synthetic dalaret created with the IBM dalasl generator 151 With ais notation we identify a series of synuleue datael5 chanietenzed by IK iems The average msaelion ice is 20 and he weram size of maximal otentially frequent itemreis is 8 The numberof msactioni is varied for scaling maruremnis hblicly avnilable sparse dafarei also known as Gmrllr 497 i~m and 59K an~actioni conmining click-swam data from an e-commprcewebsire gazeile.com BMS candidate is likely to include several of these most frequent items we avoid repeatedly intersecting the identical seg ments of the corresponding vectors This technique may save a lot of work because 1 the intersection of identical vector segments is done once 2 the identical segments are usually very large, and 3 long candidate itemsets presum ably contains several of these most frequent items The plots reported in Figure 2 show the effectiveness of the heuristic optimizations discussed above in reducing the average number of hitwise and operations needed to in tersect a pair of bit-vectors In particular Figure 2.\(a re gards the sparse BMS dataset mined with support threshold s  0.06 while Figure 2.\(b regards the dense dataset connect-4 mined with support threshold s  80 In both cases we plotted the per-iteration cost of each bit-vector in tersection in terms of hitwise and operations when either our heuristic optimizations are adopted or not The two plots show that our optimizations for both sparse and dense datasets have the effect of reducing the intersection cost up to an order of magnitude Note that when no optimizations are employed the curves exactly plot the bit-vector length in words Finally from the plot reported in Figure 2.\(a we can also note the effect of the pruning technique used on sparse datasets Pruning has the effect of reducing the length of the hit-vectors as execution progresses On the other hand when datasets are dense the vertical dataset is not pruned so that the length of bit-vectors remains the same for all the DCI iterations 3 ParDCl In the following we describe the different paralleliza tion techniques exploited for the counting and intersection based phases of ParDCI the parallel version of DCI Since our target architecture is a cluster of SMP nodes in both phases we distinguish between inrra-node and inrer-node levels of parallelism At the inter-node level we used the message-passing paradigm through the MF\222I communica tion library while at the intra-node level we exploited multi threading through the Posix Thread library. A Count Disrri burion approach is adopted to parallelize the counting-based phase, while the intersection-based phase exploits a very ef fective Condidore Distriburion approach 4 The counting-based phase At the inter-node level the dataset is statically split in a number of partitions equal to the number of SMP nodes available The size of partitions depend on the relative powers of nodes At each iteration k an identical copy of ck is independently generated by each node Then each node p reads blocks of transactions from its own dataset partition vp,k performs subset count ing and writes pruned transactions to vp,k+l At the end of the iteration an all-reduce operation is performed to update the counters associated to all candidates of Ck and all the nodes produce an identical set Fk At the intra-node level each node uses a pool of threads each holding a private set of counters associated with candi dates They have the task of checking in parallel candidate itemsets against chunks of transactions read from Dp,k At the end of each iteration a global reduction of coun ters take place, and a copy of Fk is produced on each node The intersection-based phase During the intersection based phase a Candidate Distribution approach is adopted at both the inter- and intra-node levels This pardlelization schema makes the parallel nodes completely independent inter-node communications are no longer needed for all the following iterations of ParDCI 342 


  1 J 1   I Figure 3 Total execution times for DCI Apriori and FP-growth on various datasets as a function of the support threshold Let us first consider the inter-node level and suppose that the intersection-based phase is started at iteration  1 Therefore at iteration the various nodes build on-the-fly the bit-vectors representing their own in-core portions of the vertical dataset Before starting the intersection-based phase, the partial vertical datasets are broadcast to obtain a complete replication of the whole vertical dataset on each node The frequent set Fx i.e the set computed in the last counting-based iteration is then partitioned on the ba sis of itemset prefixes A disjoint partition Fp,x of Fx is thus assigned to each node p where U Fp,x  Fp It is worth remarking that this partitioning entails a Candidate Distribution schema for all the following iterations, accord ing to which each node p will be able to generate a unique CE k  k independently of all the other nodes where C,P Ckp  0 ifp  p andU,CE  Cb At the intra-node level a similar Candidate Distribution approach is employed but at a finer granularity by using dynamic scheduling to ensure load balancing 4 Experimental Results The DCI algorithm is currently available in two versions a MS-Windows one and a Linux one ParDCI which ex ploits the MPICH MPI and thepthread libraries, is currently available only for the Linux platform We used the MS Windows version of DCI to compare its performance with other FSC algorithms For test comparisons we used the FP-growth algorithm1 and the Christian Borgelt's imple mentation of Apriori2 For the sequential tests we used a Windows-"I workstation equipped with a Pentium II 350 MHz processor 256 MB of RAM memory and a SCSI 2 disk For testing ParDCl performance we employed a small cluster of three Pentium II 233MHz 2-way SMPs, for a total of six processors Each SMP is equipped with 256 MBytes of main memory and a SCSI disk. For the tests we used both synthetic and real datasets by varying the mini mum support threshold s The characteristics of the datasets used are reported in Table 1 DCI performances and comparisons Figure 3 reports the total execution times obtained running Apriori FP growth and our sequential DCI algorithm on some datasets described in Table 1 as a function of the support'Ihreshold s In all the tests conducted DCI outperforms FP-growth with speedups up to 8 Of course DCI also remarkably out performs Apriori in some cases for more than one order of magnitude For connect-4, the dense dataset, the curve of Apriori is not shown due to the relatively too long execu tion times. Note that accordingly to 17 on the real-world sparse dataset BMS \(also known as Gazelle Apriori turned out to be faster than FP-growth To overcome such had per formance results on sparse datasets, the same authors of FP growth recently proposed a new pattern-growth algorithm H-mine  By comparing our experimental results with We adrnowledge Pmf Jiawei Han for kindly providing us the latesf http://f"zzy.CS.uni-magdeburg.de/-borgelt fully optimized binary version of FP-growth 343 


the published execution times on the BMS dataset we de duced that DCI is also faster than H-mine. For s  0.06 we obtained an execution time of about 7 sec while H mine completes in about 40 sec on a faster machine The encouraging results obtained with DCI are due lo both the efficiency of the counting method exploited during early iterations and the effectiveness of the intersection based approach used when the pruned vertical dataset fits into the main memory For only a dataset namely T25IIODlOK FP-growth turns out to be slightly faster than DCI for s  0.1 The cause of this behavior is the size of C which in this specific case results much larger than the final size of F3 Hence DCI has to carry out a lot of useless work to determine the suppon of many candidate itemsets which will eventually result to be not frequent In this case FP-growth is faster than DCI since it does not require can 11102 a 01 e I umbr*il.-dr,"mml a bpd Mnepl>l an 2  i f  I81 I L  2-~-4 LP 1 2 i 8 P  LL--,/&L P-..I_-_ 8 YB-t    13*e  72 am2 m.1 OI 3.8 2 4T I 0 Figure 4 Total execution times of a DCI and b FP-growth on datasets in the series t20.p8mlk s  0.5 on a PC equipped with different RAM sizes as a function of the num ber of transactions ranging from 1OOK to 2M We also tested the scale-up behavior of DCI when both the size of the dataset and the size of RAM installed in the PC vary The datasets employed for these tests belong to the series t20$3mlk see Table I mined with support thresh old s  0.5 while the available RAM was changed from 64MB to 512MB by physically plugging additional mem ory into the PC main hoard Figure 4.\(a and 4.\(h plot several curves representing the execution times of DCI and FP-growth respectively as a function of the number of transactions contained in the dataset processed Each curve plotted refers to a series of tests conducted with the same F'C equipped with a different amount of memory As it can be seen from Figure 4.\(a DCI scales linearly also on ma chines with a few memory Due to its adaptiveness and the use of efficient out-of-core techniques it is able to modify its behavior in function of the features of the dataset mined and the computational resources available For example in the tests conducted with the largest dataset containing two millions of transactions the in-core intersection-based phase was started at the sixth iteration when only 64MB of RAM were available, and at the third iteration when the available memory was 512MB On'the other hand the re sults reponed in Figure 4.\(h show that FP-growth requires much more memory than DCI and is not able to adapt itself to memory availability For example in the tests conducted with 64MB of RAM FP-growth requires less than 30 sec onds to mine the dataset with 2OOk transactions but when we double the size of the dataset to 400k transactions FP growth execution time becomes 1303 seconds more than 40 times higher due to an heavy page swapping activity e in1 a I I lam   a   1  P   ____   L   8 111111 N F-...a b Figure 5 a Dense dataset connect-4 completion times of DCI and ParDCl vary ing the minimum support threshold b Speedup for sparse datasets 1000K 2000K and 3000K with s  1.5 Performance evaluation of ParDCI We evaluated ParDCl on both dense and sparse datasets First we com pared the performance of DCI and ParDCl on the dense dataset connect-4 for which we obtained very good speedups Figure 5.\(a\plots total execution times as func tions of the support thresholds s ParDCI-2 corresponds to the pure multithread version running on a single 2-way SMP while ParDCI-4 and ParDCI-6 also exploit inter node parallelism and run respectively on two and three 2-way SMPs For what regard sparse datasets we used 344 


the synthetic dataset series identified as t50-pp32mlk in Table 1 We varied the total number of transactions from looOk to 3000k In the following we will identify the vari ous synthetic datasets on the basis of their number of trans actions i.e IOOOk 2000k. and 3000k. Figure 54b plots the speedups obtained on the three synthetic datasets for a given support threshold s  1.5 as a function of the number of processors used. Consider that since our cluster is com posed of three 2-way SMPs we mapped tasks on processors always using the minimum number of SPMP nodes e.g when we used 4 processors we actually employed 2 SMP nodes This implies that experiments performed on either 1 or 2 processors actually have identical memory and disk resources available, whereas the execution on 4 processors benefit from a double amount of such resources Accord ing to the tests above ParDCl showed a speedup that in some cases is close to the optimal one Considering the re sults obtained with one or two processors, one can note that the slope of the speedup curve is relatively worse than its theoretical limit due to resource sharing and thread imple mentation overheads at the inter-node level Nevertheless when additional SMPs are employed the slope of the curve improves The strategies adopted for partitioning dataset and candidates on ow homogeneous cluster of SMPs suf ficed for balancing the workload. In our tests we observed a very limited imbalance The differences in the execution times of the first and last node to end execution were always below the 0.5 5 Conclusions DCI uses different approaches for extracting frequent patterns counting-based during the first iterations and intersection-based for the following ones Adaptiveness and resource awareness are the main innovative features of the algorithm On the basis of the characteristics of the dataset mined DCI chooses at run-time which optimiza tion to adopt for reducing the cost of mining. Dataset prun ing and effective out-of-core techniques are exploited dur ing the counting-based phase, while the intersection-based phase works in core, and is staned only when the pruned dataset can fit into the main memory As a result our algo rithm can manage efficiently also on machines with limited physical memory very large datasets from which due to the different correlations among items, either short or long frequent patterns can be mined The experimental evaluations demonstrated that DCI significantly outperforms Apriori and FP-growth on both synthetic and real-world datasets. In many cases the perfor mance improvements are impressive Moreover ParDCI the parallel version of DCI exhibits excellent scaleups and speedups on our homogeneous cluster of SMPs The va riety of datasets used and the large amount of tests con ducted permit us to state that the performances of DCI are not influenced by dataset characteristics and that our optimizations are very effective and general To share our efforts with the data mining community we made the DCI binary code available for research purposes at http:IIwww.miles.cnuce.cnr.it/-.palmerildatam/oCI References Ill R.C.Aganval.C.C.Aggwal,andV.V.V.Prasad ATreePmjection Algorithm for Generation of Frequent Itemsets JPDC 2MK Special Issue on High Performance Data Mining 2 R C. Aganual C C. Agganual and V.V.V Basad Oepth first gen eration of long patterns In Pmc ofrhe 61h ACM SlCKDD In Conf on Knowledge Discovery and Dolo Mining pages 108-1 18,2000 3 R Agawal H Mannila R Srikant H Toivonen and A Inkeri Verkamo Fast Discovery of Association Rules in Large Databases In Advances in Knowledge Discovery and Dam Mining pages 307-328 AAA1 Press 1996 4 R Agrawd and J C Shafer Parallel mining of association ruler IEEE TKDE 8:962-969,996 151 R Aerawal and R Srikant Fast Aleorithms for Minine Association  I I I Rules in Large Databases In Pmc ofrhc 201h VIDE Conf pages 487499 1994 161 R Baraglia D Laforenma S Orlando P Palmerini and R Perego Implementation issues in the design of U0 intensive data mining ap plications on dusters of workstations In Pmc offhe 3rd HPDM Workhop IPDPS-Zwo Cnncun Mexico pages 350-357 LNCS I80 Spinger-Verlag 2wO 7 Y Bastide R Tamil N Pwquier G Stumme and L Lakhal Min ing frequent patterns with counting inference ACM SICKDD Erplo rations Newslemr 2\(2 December 200 81 R J Bayardo Jr Efficiently Mining Long Patterns from Databases In Pm ofths ACM SIGMOD Inr Conf on Managamen ofDara pager 85-93 Seattle. Washington USA 1998 191 Brian Dunkel and Nandit Soparkar. Data organization and access for efficient data mining In Pmc ofrhe 151h lm Conf on Dam Engi neering pages 522-529 Sydney Ausualia 1999 IEEE Computer Society IO E H Ha G Karypis and Kumar V Scalable Parallel Data Mining for Association Rules IEEE TKDE 12\(3 MayNune 2000 I I J Ha I Pei. and Y Yin Mining Frequent Patterns without Candi dale Generation In Pmc ofrhe ACM SICMOD Inc Conf on Mon q.gpmen o/Do:a pages 1-12 Dallas. Texas USA 2WO I21 S Orlando P Palmerini and R Perego Enhancing the Apriori Al gorithm for Frequent Set Counting In Pmc oflhr jrd Inf Con on Dam Warehousing and Knowledge D;xove DaWaK 28331 INCS 2114.pages71-82.Munich.Germany.2001 I31 J S Park M.-S Chen and P S Yu An Effective Hash Based Al gorilhm far Mining Association Rules In Pmc ofrhr 1995 ACM SIGMODlnt Conf on Mnna~rmmtnfDnro pages 175-186 1995 1141 1 Pei I Ha H. Lu S Nishio and D Tang S amd Yang H-Mine Hyper-Structure Mining of Frequent Patterns in Large Databases In Pmc ofrhe 2001 IEEE ICDM CO San Jose CA USA 2001 IS A Savasere E. Omiecinski and S B Navathe An Efficient Algo rithm for Mining Association Rules in Large Databases In Pmc of the Zlfh VLDB Conf pages 432444 Zurich. Switzerland 1995 I61 M J Ui Scalable algorithms for association mining IEEE TKDE 12:372-390 MayNune 2000 171 Z Zheng R Kohavi and L Mason Real World Performance of Association Rule Algorithms In Pmc ofKDD-28331 201 345 


n I31 41 51 61 71 8 I 9 Graph diameter q5\(SCCn Average number of lateral links E Average number of MI local links MI\(loc Average number of MB local links MB\(Zoc I Graph size n  1 e n I 12 I 72 I 480 I 3,600 I 30,240 I 282,240 I 2,903,040 6 8 16 19 1.500 2.583 3.683 4.783 0.667 1.500 3.200 5.000 0.833 1.222 1.925 2.337 1.500 3.000 Average number of local links L Average distance d\(SCC 2.722 5.125 7.337 5.306 8.808 12.121 Table 1 Average distance of SCC graphs under minimal routing 300000 250000 g 200000 3 E L 150000   100000 50000 0 erage number of MB local links is concerned. Also observe that for 3 5 n 5 4 the greedy routing algorithm performs as well as the minimal routing algorithm Besides, our re sults indicate that the performance of these algorithms is quite similar for 5 5 n 5 9 which makes the less complex greedy routing algorithm particularly attractive Average costs of paths produced by the three routing al gorithms are summarized in Table 2 The random routing algorithm has a complexity of O\(n and performs reason ably well on the average Utilization of such an algorithm may however result in variations in the average cost of routes up to the worst-case values shown in Table 2  Minimal routing  andom rout. \(worst case     n 3 Minimal Greedy Random routing rout rout Theor Simul Worst-case 3.000 3.000 3.000 3.084 3.167 I1 I I I I I 4 5 I I I I I 5.306 5.305 5.500 5.514 5.694 8.808 8.812 9.261 9.264 9.775 Table 2 Average costs vs routing algorithms Figure 6 shows distribution curves comparing the three routing algorithms in the case of an SCC graph A point 01 NI in one of these curves indicates that the corre sponding routing algorithm will compute a route of cost DI to the identity for NI nodes in the SCC graph The aver age distribution for the random routing algorithm is shown but the results for that algorithm may actually vary from the minimal to the worst-case distributioncurves due to the non deterministic nature of the algorithm It is also interesting to observe that the greedy routing algorithm provides a dis tribution curve which is close to that of the minimal routing algorithm presenting however a smaller complexity 6 Considerations on wormhole routing 3 In this section we briefly describe how the algorithms presented in the paper cam be combined with wormhole routing 6 which is a popular switching technique used in parallel computers All three algorithms can be used with wormhole routing when implemented as source-based routing algorithms  111 In source-based routing tlhe source node selects the entire path before sending the packet Because the processing delay for the routing algorithm is incurred only at the source node it adds only once to the communication latency and can be viewed as part of the start-up latency Source-based routing however has two disadvantages 1 each packet must carry complete information about its path in the header which increases the packet length and 2 the path cannot be changed while the packet is being routed which precludes incorporating adaptivity into the routing algorithm Distributed routing eliminates the disadvantages of source-based routing by invoking the routing algorithm in each node to which the packet is forwarded ll Thus the decision on whether a packet should be delivered to the local processor or forwarded on an outgoing link is done 451 


locally by the routing circuit of a node Because the routing algorithm is invoked multiple times while a packet is being routed the routing decision must be taken as fast as pos sible From this viewpoint it is important that the routing algorithm can be easily and efficiently rendered in hardware which favors the random routing algorithm over the greedy and minimal routing algorithms Besides being the most complex algorithm discussed in this paper the minimal routing algorithm includes a feature which precludes its distributed implementation in associa tion with wormhole routing namely its backtracking mech anism Distributed versions of the random and greedy al gorithms, however, can be used in combination with worm hole routing A near-minimal distributed routing algorithm which supports wormhole routing can be obtained by re moving the backtracking mechanism from Alg 3 Such an algorithm is likely to have computational complexity and average cost that lie between those of the greedy and the minimal routing algorithm Due to its non-deterministic nature the random routing algorithm also seems to be a good candidate for SCC net works employing distributed adaptive routing  1 I Adap tivity is desirable for example if the routing algorithm must dynamically respond to network conditions such as conges tion and faults Some degree of adaptivity is also possible in the greedy and minimal routing algorithms which in some cases can decide between paths of equal cost 7 Conclusion This paper compared the average cost and the complex ity of three different routing algorithms for the SCC graph We divided routes into three components \(lateral links MI local links and MB local links and showed that only the number of MB local links may be affected by the routing algorithm being considered Exact expressions for the aver age number of lateral links and the average number of MI local links were presented Also an upper bound for the average number of MZ local links was derived considering a random routing algorithm As a result a tight upper bound on the average distance of the SCC graph was obtained Simulation results for a random a greedy and a minimal routing algorithm were presented and compared with theo retical values The complexity of the proposed algorithms is respectively O\(n O\(n2 and O\(n3 where n is the dimensionality of the SCC grap.h The results under mini mal routing produce exact numerical values for the average distance of SCC for 3 5 n 5 9 Results for the greedy algorithm match those of the min imal algorithm for 3 2 n 5 4 The greedy algorithm also performs close to minimality for 5 5 n 5 9 and is an in teresting choice due to its O\(n2 complexity The random routing algorithm has an O\(n complexity and performs fairly well on the average but may introduce additional MB local links in the route under worst-case conditions Finally we discussed how each of the routing algorithms can be used in association with the wormhole routing switch ing technique Directions for future research in this area in clude an evaluation of requirements for deadlock avoidance e.g number of virtual channels References l S B Akers,D. HarelandB Krishnamurthy,\223TheStarGraph An Attractive Altemative to the n-Cube,\224 Proc Int\222l Con Pal Proc 1987 pp 393-400 2 M M Azevedo N Bagherzadeh and S Latifi 223Broadcasting Algorithms for the Star-Connected Cycles Interconnection Network,\224 J Pal Dist Comp 25,209-222 1995 3 M M Azevedo N Bagherzadeh and S Latifi 223Embed ding Meshes in the Star-Connected Cycles Interconnection Network,\224 to appear in Math Mod. and Sci Comp 4 M M Azevedo N Bagherzadeh and S Latifi 223Fault Diameter of the Star-Connected Cycles Interconnection Net work,\224 Proc 28th Annual Hawaii Int\222l Con5 Sys Sci Vol 11 Jan. 3-6 1995 pp 469-478 SI W.-K Chen M F M Stallmann andE E Gehringer 223Hy percube Embedding Heuristics An Evaluation,\224 Int\222l J Pal Prog Vol 18 No 6 1989 pp 505-549 6 W J Dally and C I Seitz 223The Torus Routing Chip,\224 Dist Comp Vol 1 No 4 1986 pp 187-196 7 K Day and A Tripathi,\223A Comparative Study ofTopologica1 Properties of Hypercubes and Star Graphs,\224 IEEE Trans. Pal Dist Sys Vol 5 No 1 Jan. 1994 pp 31-38 8 D E Knuth The Art of Computer Programming Vol I Addison-Wesley 1968 pp 73 pp 176-177 9 S Latifi 223Parallel Dimension Permutations on Star Graph,\224 IFIP Trans A Comp Sei Tech 1993 A23 pp 191-201 lo S Latifi M M Azevedo and N Bagherzadeh 223The Star Connected Cycles A Fixed-Degree Interconnection Net work for Parallel Processing,\224 Proc Int\222l Con5 Pal Proc  1 11 L M Ni and P K McKinley 223A Survey of Wormhole Rout ing Techniques in Direct Routing Techniques,\224 Computer Feb 1993 pp 62-76  121 E P Preparata and J Vuillemin 223The Cube-Connected Cy cles A Versatile Network for Parallel Computation,\224 Comm ACM Vol 24 No 5 May 1981 pp 300-309  131 Y Saad and M H Schultz 223Topological Properties of Hy percubes,\224IEEE Trans Comp Vol 37 No 7 July 1988 pp 14 S Shoari and N Baghenadeh 223computation of the Fast Fourier Transform on the Star-Connected Cycle Network,\224 to appear in Comp  Elec. Engl 1996 15 P Vadapalli and P K Srimani 221\223ho Different Families of Fixed Degree Regular Cayley Networks,\224 Proc Int\222l Phoenix Con Comp Comm Mar 28-31,1995 pp 263-269 1993 Vol 1 pp 91-95 867-872 452 


It can also be added to cell CrossSales.3\(PC, printer one_year,\205 5  Distributed and Incremental Rule Mining There exist two ways to deal with association rules 267  Static that is, to extract a group of rules from a snapshot, or a history, of data and use "as is 267  Dynamic that is, to evolve rules from time to time using newly available data We mine association rules from an e-commerce data warehouse holding transaction data. The data flows in continuously and is processed daily Mining association rules dynamically has the following benefits 267  223Real-time\224 data mining, that is, the rules are drawn from the latest transactions for reflecting the current commercial trends 267  Multilevel knowledge abstraction, which requires summarizing multiple partial results. For example association rules on the month or year basis cannot be concluded from daily mining results. In fact multilevel mining is incremental in nature 267  For scalability, incremental and distributed mining has become a practical choice Figure 3: Distributed rule mining Incremental association rule mining requires combining partial results. It is easy to see that the confidence and support of multiple rules may not be combined directly. This is why we treat them as \223views\224 and only maintain the association cube, the population cube and the base cube that can be updated from each new copy of volume cube. Below, we discuss several cases to show how a GDOS can mine association rules by incorporating the partial results computed at LDOSs 267  The first case is to sum up volume-cubes generated at multiple LDOSs. Let C v,i be the volume-cube generated at LDOS i The volume-cube generated at the GDOS by combining the volume-cubes fed from these LDOSs is 345   n i i v v C C 1  The association rules are then generated at the GDOS from the centralized C v  214  The second case is to mine local rules with distinct bases at participating LDOSs, resulting in a local association cube C a,I a local population cube C p,I  and a local base cube C b,i at each LDOS. At the GDOS, multiple association cubes, population cubes and base cubes sent from the LDOSs are simply combined, resulting in a summarized association cube and a summarized population cube, as 345   n i i a a C C 1   345   n i i p p C C 1  and 345   n i i b b C C 1  The corresponding confidence cube and support cube can then be derived as described earlier. Cross-sale association rules generated from distinct customers belong to this case In general, it is inappropriate to directly combine association cubes that cover areas a 1 205, a k to cover a larger area a In the given example, this is because association cubes record counts of customers that satisfy   customer product merchant time area Doe TV Dept Store 98Q1 California Doe VCR Dept Store 98Q1 California customer product merchant time area Doe VCR Sears 5-Feb-98 San Francisco Joe PC OfficeMax 7-Feb-98 San Francisco customer product merchant time area Doe TV Fry's 3-Jan-98 San Jose Smith Radio Kmart 14-Jan-98 San Jose Association   population      base          confidence      support cube               cube                cube         cube                cube LDOS LDOS GDOS 


the association condition, and the sets of customers contained in a 1 205, a k are not mutually disjoint. This can be seen in the following examples 214  A customer who bought A and B in both San Jose and San Francisco which are covered by different LDOSs , contributes a count to the rule covering each city, but has only one count, not two, for the rule A  336  B covering California 214  A customer \(e.g. Doe in Figure 3\who bought a TV in San Jose, but a VCR in San Francisco, is not countable for the cross-sale association rule TV  336 VCR covering any of these cities, but countable for the rule covering California. This is illustrated in Figure 3 6  Conclusions In order to scale-up association rule mining in ecommerce, we have developed a distributed and cooperative data-warehouse/OLAP infrastructure. This infrastructure allows us to generate association rules with enhanced expressive power, by combining information of discrete commercial activities from different geographic areas, different merchants and over different time periods. In this paper we have introduced scoped association rules  association rules with conjoint items and functional association rules as useful extensions to association rules The proposed infrastructure has been designed and prototyped at HP Labs to support business intelligence applications in e-commerce. Our preliminary results validate the scalability and maintainability of this infrastructure, and the power of the enhanced multilevel and multidimensional association rules. In this paper we did not discuss privacy control in customer profiling However, we did address this issue in our design by incorporating support for the P3P protocol [1 i n  ou r data warehouse. We plan to integrate this framework with a commercial e-commerce system References 1  Sameet Agarwal, Rakesh Agrawal, Prasad Deshpande Ashish Gupta, Jeffrey F. Naughton, Raghu Ramakrishnan, Sunita Sarawagi, "On the Computation of Multidimensional Aggregates", 506-521, Proc. VLDB'96 1996 2  Surajit Chaudhuri and Umesh Dayal, \223An Overview of Data Warehousing and OLAP Technology\224, SIGMOD Record Vol \(26\ No \(1\ 1996 3  Qiming Chen, Umesh Dayal, Meichun Hsu 223 OLAPbased Scalable Profiling of Customer Behavior\224, Proc. Of 1 st International Conference on Data Warehousing and Knowledge Discovery \(DAWAK99\, 1999, Italy 4  Hector Garcia-Molina, Wilburt Labio, Jun Yang Expiring Data in a Warehouse", Proc. VLDB'98, 1998 5  J. Han, S. Chee, and J. Y. Chiang, "Issues for On-Line Analytical Mining of Data Warehouses", SIGMOD'98 Workshop on Research Issues on Data Mining and Knowledge Discovery \(DMKD'98\ , USA, 1998 6  J. Han, "OLAP Mining: An Integration of OLAP with Data Mining", Proc. IFIP Conference on Data Semantics DS-7\, Switzerland, 1997 7  Raymond T. Ng, Laks V.S. Lakshmanan, Jiawei Han Alex Pang, "Exploratory Mining and Pruning Optimizations of Constrained Associations Rules", Proc ACM-SIGMOD'98, 1998 8  Torben Bach Pedersen, Christian S. Jensen Multidimensional Data Modeling for Complex Data Proc. ICDE'99, 1999 9  Sunita Sarawagi, Shiby Thomas, Rakesh Agrawal Integrating Association Rule Mining with Relational Database Systems: Alternatives and Implications", Proc ACM-SIGMOD'98, 1998   Hannu Toivonen, "Sampling Large Databases for Association Rules", 134-145, Proc. VLDB'96, 1996   Dick Tsur, Jeffrey D. Ullman, Serge Abiteboul, Chris Clifton, Rajeev Motwani, Svetlozar Nestorov, Arnon Rosenthal, "Query Flocks: A Generalization of Association-Rule Mining" Proc. ACM-SIGMOD'98 1998   P3P Architecture Working Group, \223General Overview of the P3P Architecture\224, P3P-arch-971022 http://www.w3.org/TR/WD-P3P.arch.html 1997 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



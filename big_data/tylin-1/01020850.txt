Proceedings of the 4 World Congress on Intelligent Control and Automation June 10-14 2002 Shanghai P.R.China 1569 Research and Analysis of Multi-dimensional Association Rules Mining Feng Qin Xuebing Yang Computer Science Departmen of Anhui Polyrechnic University .Anhui Ma'ah shan 243002 I E-mail:fqinOahul,edu.cn Abstract This paper proposes two data cube based multi-dimensional association rules mining algorithms which integrate the classical association rules mining algorithm with data cube technology and presents the differences in inining efficiency between two algorithm  Keywords Data Mining Association Rules, Multi-dimensional Analysis iWJ%%B$&"R55j c  pc    T  A TitS:kJ1&lS%3 L  22&,3%1L 213002 g C~BS-f~~Cb~~#j~EW~~4~~7qA~~~~Z A 7 Fj+++5~14tS-f~+&+~&~%~#j 8 PX&"!t&BZFi X+H~~a~CW~f~~W++BZFlb W.t*irLTsCI.N&4ci 7 O4trrtH si B%aB KW*XBd tR5M 


I570 Praceedings of the 6 World Congress on Intelligent Control and Automation June 1U-14 2002 Shanghai P.R.China I 2 CI  y C1.d  I 3 4 Repeal E I-itemset ZTi H i L,=gen-frequent I Cl k=k+l  E k-itemsets flZ C,=gen-candidate\(k.L 512 k-itemsets H L,=gen-frequent k.C L=L U L Until L,=O  gen_frequent\(k.C C a$QZ Function gen-frequent\(k,C r$R%L L   for each candidate I={ilri2  i EC do frequency=k iLifi.li6Y@l q WJZ%\(i,,i2  ik support=frequency/totalcount if\(support>min-supp then I P$fiXI oh count I 17 f L,=L,U I 3  gen-candidate\(k.L M k-I  MEIfi k-itemset E.fI!Z C Function gen_candidate\(k,L C   for each item II E LL for each item I,EL  if\(1,Lj 12G k-2 kiFJmlnR,R.H@fi 


Proceedines of the 4 World Conmess on Intellieent Control and Automation June 10-14 2lHl2 Shanehai P.R.China 1571 


h I I 


Dataset Breast-wisc Car Cmc Covtype Crx German Glass Image Kr-vs-kp Mushroom Nursery Promoters Sonar Splice Rt FIRST 50.1 f 0.5 61.7 f 7.0 63.7 f 4.1 64.4 f 3.8 75.0 f 4.3 67.1 f 4.9 70.1 f 9.1 86.0 f 4.1 52.9 f 3.9 53.4 f 2.5 93.7 f 0.4 47.1 f 20.6 57.0 f 11.0 45.9 f 2.5 RAND 69.9 f 6.8 74.0 f 2.7 63.2 f 3.8 69.0 f 1.9 70.0 f 7.5 58.2 f 4.7 68.4 f 10.1 88.8 f 2.1 66.2 f 3.0 90.1 f 1.8 90.2 f 0.6 51.8 f 12.6 48.3 f 11.2 57.8 f 2.3 htion strategies 11 Numberc WVOTE 94.7 f 3.4 94.3 f 1.4 63.9 f 4.0 73.3 f 1.5 90.2 f 4.2 71.9 f 4.9 71.7 f 10.5 92.3 f 1.6 88.8 f 2.4 99.9 f 0.1 96.0 f 0.3 83.5 f 16.2 65.8 f 12.8 87.3  1.6 Generated 306.5 107.6 196.6 1416.6 758.5 807.5 183.7 811.4 2328.3 2362.2 606.6 7432.2 10075.7 8406.8 LFPR 97.6 f 1.3 92.3 f 1.7 63.7 f 4.2 72.9 f 2.1 83.9 f 5.1 66.2 f 5.3 71.2 f 10.0 93.3 f 1.4 92.6 f 1.5 100.0 f 0.0 97.1 f 0.2 72.6 f 13.3 59.4 f 13.7 74.6 f 2.2 rules Fired 112.3 6.6 3.2 32.2 69.8 36.0 35.0 66.2 340.0 131.7 12.1 334.0 1869.2 214.9 VOTE 95.1 f 2.6 71.2 f 4.5 61.9 f 4.3 66.6 f 1.8 88.4 f 5.0 62.3 f 5.6 74.4 f 10.0 80.9 f 2.4 84.8 f 3.3 99.4 f 0.1 93.6 f 0.6 76.8 f 14.4 63.5  12.4 70.6 f 2.8 Table 1 Mean and standard deviation of AUCs using RL rules with various resolution strategies. The final two columns give the average number of rules generated and the average number of rules fired on each instance RL 3 is a MetaDENDRAL-style rule learner that per forms a general-to-specific search of the space of conjunc tive rules This type of rule-space search is described in de tail by Webb  181 RL uses a beam search for rules whose coverage and confidence are above user-defined thresholds In the experiments reported here a beamsize of 100 was used along with rule constraints of confidence greater than 0.60 coverage greater than two instances and no more than four conjuncts per rule A Laplace corrected version of the confidence equation was used, to compensate for small sam ple sizes With its default settings RL only finds rules that cover examples not previously covered by other rules In these experiments, RL was allowed to generate redundant rules in order to experiment with the effects of rule overlap It is important to note that, unlike C4.5rules RL does not try to produce a rule set that maximizes classification accuracy  4.2 Datasets Fourteen data sets were selected from the UCI Reposi tory  11 In general, datasets were avoided that had extreme class skews since the purpose of this paper is not to exper iment with learning under skewed distributions Datasets were chosen that could produce reasonable performance with standard rule learners Each experiment reported below was performed using 10-fold cross-validation on the datasets Means and stan dard deviations of the experimental results are given For readability AUCs are reported as percentages of the total possible so they range from 0 to 100 instead of 0 to 1 4.3 The effect of resolution strategy Tables 1 and 2 show the effect of different rule resolution strategies using rules from RL and C4.5rules respectively Several observations can be made from these results From the last two columns in each table we can see that RL gen erated far more rules for each dataset than C4.Srules did in some cases by one or two orders of magnitude Also the number of rules fired on average per instance is far greater for RL than for C4.5rules indicating that rule contention is considerably higher for the rule sets created by RL Nei ther result is surprising The RL parameters were chosen so that it would generate a large number of overlapping rules resulting in high contention On the other hand C4.5rules begins with a set of mutually exclusive rules although rules can overlap after conjunct deletion they will not otherwise conflict The results of this contention are seen in the effect of the resolution strategy There is little difference between reso lution strategies with the C4.5rules results because there is little contention to resolve The RL results in Table 1 show much greater variability The differences between resolution strategies are eval uated more carefully in Table 3 in which they are com pared in pairs using the mean AUC for each dataset shown in Table 1 Results are given for both the Sign Test which ignores difference magnitudes and the Wilcoxon Matched-Pair Signed-Ranks Test which takes magnitude into account Each test result is the probability that the first strategy is indistinguishable from the second in per formance RAND and FIRST both perform poorly and are indeed virtually indistinguishable in performance Uni 135 


Dataset Breast-wisc Car Cmc Covtype Crx German Glass Image Kr-vs-kp Mushroom Nursery Promoters Sonar Splice WVOTE 97.4 f 3.6 98.3 f 0.7 66.5 f 4.9 82.2 f 1.4 90.1 f 3.4 67.9 f 9.6 75.7 f 5.9 99.0 f 0.5 99.7 f 0.2 100.0 f 0.0 99.8 f 0.1 88.4 f 12.8 77.8 f 13.7 97.2 f 0.7 RAND 96.6 f 3.2 97.6 f 0.7 66.1 f 5.4 81.5 f 1.2 89.1 f 3.7 68.2 f 9.0 76.9 f 5.0 99.0 f 0.5 99.7 f 0.2 100.0 f 0.0 99.7 f 0.1 89.2 f 10.0 77.7 f 11.6 97.1 f 0.7 Generated 8.2 78.6 39.1 63.5 12.9 23.4 12.2 28.6 26.3 11.5 336.8 8.0 9.1 76.2 Resolution strate Pair RAND vs FIRST RAND vs VOTE RAND vs LFPR RAND vs WVOTE FIRST vs LFPR FIRST vs VOTE FIRST 97.6 f 3.0 98.4 f 0.7 66.8 f 5.0 83.1 f 1.5 90.9 f 2.6 68.1 f 9.7 77.1 f 5.2 99.1 f 0.5 99.9 f 0.1 100.0 f 0.0 99.8 f 0.1 89.4 f 10.6 78.2 f 12.3 97.5 f 0.6 Wins-Ties-Losses 8-0-6 4-0 IO 0-0 14 0-0 14 1-0-13 4-0 IO LFPR 97.5 f 2.9 98.4 f 0.7 66.6 f 5.2 82.6 f 1.4 89.2 f 4.2 67.6 f 10.1 77.1 f 5.2 99.1  0.5 99.9 f 0.1 100.0 f 0.0 99.8 f 0.0 89.9 f 11.2 77.7 f 10.9 97.4 f 0.6 11 Number of rules es VOTE 95.8 f 2.9 96.3 f 0.8 67.0 f 2.6 80.3 f 1.2 84.7 f 3.3 67.7 f 8.4 75.8 f 8.7 98.0 f 0.5 99.5 f 0.4 99.8 f 0.0 99.6 f 0.1 88.9 f 9.9 76.4 f 11.2 97.2 f 0.8 Fired 2.2 1.3 1.2 1.6 1.9 1.1 1 o 1.5 1.9 1.2 1.6 1.2 1.3 2.3 Table 2 Mean and standard deviation of AUCs using C4.5rules with various resolution strategies The final two columns give the average number of rules generated and the average number of rules fired on each instance form unweighted voting VOTE\performs better The two measures that take rule statistics into account LFPR and WVOTE perform best of all WVOTE appears to have an advantage over LFPR in these domains but the difference is statistically inconclusive FIRST vs WVOTE 1 0-0 14 LFPR vs VOTE 11 10-0-4 LFPR vs WVOTE 11 5-0-9 VOTEvsWVOTE 11 2-0 12 Sign test 0.79 1 0.000 0.180 0.000 0.002 0.180 0.000 0.180 0.424 0.013 WMPSR test 0.194 0.000 0.01 1 0.000 0.000 0.013 0.000 0.194 0.153 0.003 Table 3 Pairwise comparisons of the results of resolution strategies from Table 1  4.4 Benefits of instance scoring Another question is whether instance scoring is useful Perhaps the classification done by C4.5rules is already suf ficient to provide good performance over the entire ROC space To evaluate this hypothesis the AUC performance of the C4.5rules was measured as if the rules were evalu ated directly for classification; that is as if they were inter preted by the consultr program that comes with C4.5 This evaluation produces a single \223accuracy point\224 in ROC space This constitutes an ROC curve whose area can be measured If probabilistic interpretation of rules has bene fits for predictiveness we might expect a situation as shown in Figure IC where classifier B probabilistic has a larger area than classifier A discrete Figure 2 shows ROC curves from a C4.5rules rule set on the Covtype domain Discrete classification yields an FP rate of 13 and a TP rate of 70 Connecting this point to 0,O and 1,l yields an ROC 223curve\224 with flat sides If the same rules are used for instance scoring a curve of greater area can be produced as shown in the figure. At the accuracy point the two strategies are close in performance but elsewhere in ROC space the instance scoring strategy exhibits a substantial predictive advantage This can be seen in the 223bowing out\224 of the scoring curve, which has greater area than the discrete classification curve This means that as conditions change away from the accuracy point e.g the class distribution becomes skewed or one type of error becomes more costly instance scoring will have a definite advantage Table 4 compares these AUCs across the UCI domains 223AUC using consultr\224 is the AUC from discrete classifi cation and 223AUC using WVOTE\224 is the AUC using in stance scoring with WVOTE On nearly every dataset the WVOTE AUC exceeds the corresponding AUC that would result from direct classification The results pass both the Sign and Wilcoxon tests at p  05 This demonstrates that using rules to score instances results in a measurable predic tive benefit over what would be realized from interpreting them as direct classification rules 136 


1 0.8 0   0.6 P 0   U m n 2 0.4 b 0.2 Dataset Breast-wisc Car Cmc Covtype Crx German Glass Image Kr-vs-kp Mushroom Nursery Promoters Sonar Splice i Instance scoring WVOTE  Discrete classification  AUC using consultr 95.6 f 3.4 95.3 f 2.2 65.1 f 2.7 76.0 f 2.7 85.6 f 4.8 64.4 f 3.4 74.4 f 7.5 97.7 f 0.7 99.6 f 0.4 100.0 f 0.0 98.8 f 0.3 90.1 f 11.0 73.9 f 6.8 94.8 f 1.3 I I I I 1 0 0.2 0.4 0.6 0.8 1 False positive rate Figure 2 ROC curves of the Covtype domain 4.5 Comparison with Naive Bayes Finally, how well do rules perform against other proba bility estimation techniques Rules have various desirable qualities such as modularity and intelligibility but these qualities are shared by other model classes as well such as Naive Bayes and linear threshold units How do rules compare Table 5 shows ROC performance of Naive Bayes\222 and rules from C4.5rules using WVOTE resolution In general rules appear to perform better than simple Naive Bayes This observation passes a Sign test p  0.05 though it does not pass the Wilcoxon test at an acceptable level It is possible that more complex model classes such as decision tree ensembles 8 211 or neural networks 14 would produce better probability estimates than rules do However these model classes are more complex and ex pensive and lack some of the appealing characteristics of classification rules 5 Discussion and Future Work This paper has demonstrated that rules commonly used for direct classification can also be used effectively for probability estimation In fact when used this way their predictive performance increases In general they are com petitive with a simple probability estimation method such as Naive Bayes It is likely that further experimentation with the rule generation methods would result in better absolute performance from rules 221Because Naive Bayes is representationally equivalent to a linear threshold unit, no separate test was done AUC using WVOTE 97.3 f 3.6 98.3 f 0.7 66.4 f 4.9 82.2 f 1.4 90.2 f 3.4 68.4 f 9.9 75.5 f 6.0 99.0 f 0.5 99.7 f 0.2 100.0 f 0.0 99.8 f 1 88.9 f 13 76.9 f 14 97.2 f 0.7 Table 4 Comparisons of AUCs under direct classification 223AUC using consultr\224\and un der instance scoring \(\223AUC using WVOTE\224 Several important issues have been left unaddressed in this paper Even when rule generation is efficient and effective, clas sification performance can benefit from rule selection and this is an area of ongoing work Wilkins and Ma  191 proved that optimal rule selection is NP-hard because overlapping rules can have \223sociopathic\224 interactions; therefore practi cal rule selection techniques must be heuristic The field of machine learning would benefit from a systematic study of heuristic rule selection methods The experiments in this paper employed two standard rule learning methods, C4.5rules and RL but neither was designed to maximize AUC performance An open ques tion is how rule generation should be altered to produce rule with good AUC performance Various ideas have been proposed, such as starting with a high confidence bias and dynamically adjusting it based on feedback from AUC per formance To our knowledge no such research has been seriously pursued Finally a related issue is how best to learn rules when one or more classes is rare Induction under skewed distri butions is an important open issue in machine learning that has received attention recently The datasets used in this study were chosen to be fairly balanced in order to sidestep this issue so that off-the-shelf rule induction methods could be used Research on other model classes with skewed data sets should provide valuable insights on rule induction as well 137 


Dataset Breast-wisc Car Cmc Covtype Crx German Glass Image Kr-vs-kp Mushroom Nursery Promoters Sonar Splice AUC Naive Bayes 93.1 f 5.5 92.3 f 2.2 64.1 f 5.8 81.5 f 2.4 87.6 f 4.3 77.1 f 4.5 74.0 f 8.7 95.6 f 0.9 95.1 f 0.8 99.8 f 0.1 98.0 f 0.2 97.7 f 4.0 76.1 f 13.0 99.2 f 0.6 AUC C4.5rules 97.3 f 3.6 98.3 f 0.7 66.4 f 4.9 82.2 f 1.4 90.2 f 3.4 68.4 f 9.9 75.5 3z 6.0 99.0 f 0.5 99.7 f 0.2 100.0 f 0.0 99.8 f 1 88.9 f 13 76.9 f 14.3 97.2 f 7 Table 5 Probability estimation Naive Bayes versus rules from C4.5rules using WVOTE 6 Acknowledgments Discussions with Foster Provost were helpful in clari fying some rule learning issues Two anonymous review ers provided valuable comments I thank Ross Quinlan for making C4.5 and C4.5rules available for non-commercial use I thank Foster Provost for making the RL program available and I thank the Weka project 20 for making their software available Much open source software was used in this work I wish to thank the authors and maintainers of XEmacs TEX ET Per1 and its many user-contributed packages and the Free Software Foundation's GNU Project Scripts for the Sign and Wilcoxon tests were written by Rob van Son References I C Blake and C Merz UCI repository of machine leam ing databases 1998 http www.ics.uci.edu mlearn/MLRepository.html 2 A P Bradley The use of the area under the ROC curve in the evaluation of machine learning algorithms Pattern Recognition 30\(7 1145-1 159 1997 3 S Clearwater and E Provost RL4 A tool for knowledge based induction In Proceedings of the Second International IEEE Conference on Tools for Artijcial Intelligence pages 24-30 IEEE CS Press 1990 4 J P Egan Signal Detection Theory and ROC Analwis Se ries in Cognitition and Perception Academic Press New York 1975 5 T Fawcett and E Provost Activity monitoring Noticing interesting changes in behavior In Chaudhuri and Madi gan editors Proceedings on the Fifrh ACM SIGKDD In ternational Conference on Knowledge Discovery and Data Mining pages 53-62 San Diego CA Aug 1999 6 A Freitas Understanding the crucial differences between classification and discovery of association rules  a position paper KDD Explorations 2 1 June 2000 7 J A Hanley and B J McNeil The meaning and use of the area under a receiver operating characteristic \(ROC curve Radiology 143:29-36 1982 8 F Provost and P Domingos Well-trained PETS: Improving probability estimation trees CeDER Working Paper IS-00 04 Stem School of Business New York University NY NY 10012,2001 U F Provost and T Fawcett Analysis and visualization of classifier performance Comparison under imprecise class and cost distributions In Proceedings of the Third Interna tional Conference on Knowledge Discoven and Data Min ing KDD-97 pages 43-48 Menlo Park CA 1997 AAA1 Press IO E Provost and T Fawcett Robust classification for impre cise environments Machine Learning 42\(3 1 Mar 2001  1 I E Provost T Fawcett and R Kohavi The case against accuracy estimation for comparing induction algorithms In J Shavlik editor Proceedings of the Fifteenth Interna tional Conference on Machine Learning pages 445453 San Francisco CA 1998 Morgan Kaufmann  121 J R Quinlan C4.5 Prograinsfor inachine learning Mor gan Kaufmann 1993 I31 R L Rivest Learning decision lists Machine Learning I41 S Santini and D A Bimbo Recurrent neural networks can be trained to be maximum a posteriori probability classifiers Neural Networks 8 1 1995 I51 A. Srinivasan Note on the location of optimal classifiers in n-dimensional ROC space Technical Report PRG-TR-2-99 Oxford University Computing Laboratory Oxford England 1999  161 J Swets. Measuring the accuracy of diagnostic systems Sci ence 240:1285-1293 1988  171 J A Swets, R M Dawes and J Monahan Better decisions through science Scientrjc American 283:82-87 October 2000 18 G Webb OPUS An efficient admissible algorithm for un ordered search Journal of Artificial Intelligence Research 3:383417 1995 19 D C Wilkins and Y Ma The refinement of probabilistic rule sets sociopathic interactions ArtiJcial Intelligence 20 1 Witten and E Frank Data mining Practicnl ma chine learning tools and techniques with Java implemen tations Morgan Kaufmann San Francisco 2000 Soft ware available from http: //www.cs.waikato.ac nz  ml weka   21 B. Zadrozny and C Elkan Learning and making decisions when costs and probabilities are both unknown In Proceed ings of KDD-2001 pages 204-213 Aug 2001 2:229-246 1987 70 1-32 1994 138 


I Plenary Panel Session J Future Directions in Database Research  456 Chair Surajit Chaudhuri Microsoft Corporation Panelists Hector Garcia-Molina Stanford University Hank Korth, Bell Laboratories Guy Lohman IBM Almaden Research Center David Lomet Microsoft Research David Maier Oregon Graduate Institute I Session 14 Query Processing in Spatial Databases I Chair Sharma Chakravarthy University of Florida Processing Incremental Multidimensional Range Queries in a Direct Manipulation Visual Query Environment  458 High Dimensional Similarity Joins Algorithms and Performance Evaluation  466 S Hibino and E Rundensteiner N Koudas and K.C Sevcik Y Theodoridis E Stefanakis and T Sellis Cost Models for Join Queries in Spatial Databases  476 Mining Association Rules Anti-Skew Algorithms  486 J.-L Lin and M.H Dunham Mining for Strong Negative Associations in a Large Database of Customer Transactions  494 A Savasere E Omiecinski and S Navathe Mining Optimized Association Rules with Categorical and Numeric Attributes  503 R Rastogi and K Shim Chair: Anoop Singhal AT&T Laboratories S Venkataraman J.F Naughton and M Livny Remote Load-Sensitive Caching for Multi-Server Database Systems  514 DB-MAN A Distributed Database System Based on Database Migration in ATM Networks  522 T Hara K Harumoto M Tsukamoto and S Nishio S Banerjee and P.K Chrysanthis Network Latency Optimizations in Distributed Database Systems  532 I Session 17 Visualization of Multimedia Data I Chair Tiziana Catarci, Universita di Roma 223La Sapienza\224 W Chang D Murthy A Zhang and T.F Syeda-Mahmood Global Integration of Visual Databases  542 X 


The Alps at Your Fingertips Virtual Reality and Geoinformation Systeps  550 R Pajarola l Ohler P Stucki K Szabo and P Widmayer C Baral G. Gonzalez and T.C Son Design and Implementation of Display Specifications for Multimedia Answers  558 1 Session 18 Management of Objects I Chair: Arbee Chen National Tsing Hua University P Boncz A.N Wilschut, and M.L. Kersten C Zou B Salzberg, and R Ladin 0 Wolfson S Chamberlain S Dao L Jiang, and G. Mendei Flattening an Object Algebra to Provide Performance  568 Back to the Future Dynamic Hierarchical Clustering  578 Cost and Imprecision in Modeling the Position of Moving Objects  588 ROL A Prototype for Deductive and Object-Oriented Databases  598 A Graphical Editor for the Conceptual Design of Business Rules  599 The Active HYpermedia Delivery System AHYDS using the M Liu W Yu M Guo and R Shan P Lang W Obermair W Kraus and T Thalhammer PHASME Application-Oriented DBMS  600 F Andres and K. Ono S Chakravarthy and R Le S Mudumbai K Shah A Sheth K Parasuraman and C Bertram ECA Rule Support for Distributed Heterogeneous Environments  601 ZEBRA Image Access System  602 Author Index  603 xi 


11  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02  data bindings domain-specific metric for assessing module interrelationship  interface errors errors arising out of interfacing software modules  Porter90 Predicting software  faults 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 From decision trees to association rules  Classifiers  223this and this\224 goes with that \223class\224  conclusions \(RHS\ limited to one class attribute  target very well defined  Association rules  223this and this\224 goes with \223that and that\224  conclusions \(RHS\ may be any number of attributes  But no overlap LHS and RHS  target wide open  Treatment learning  223this and this\224 goes with \223less bad and more good\224  223less\224,  \223more\224: compared to baseline  223bad\224, \223good\224: weighted classes Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


12  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Association rule learning  www.amazon.com  Customers who bought this book also bought  The Naked Sun by Isaac Asimov  The Caves of Steel by Isaac Asimov  I, Robot by Isaac Asimov  Robots and Empire by Isaac Asimov 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Support and confidence  Examples = D , containing items I  1: Bread, Milk 2: Beer Diaper Bread, Eggs 3: Beer Coke, Diaper Milk 4: Beer Bread, Diaper Milk 5: Coke, Bread, Diaper Milk  LHS  RHS = {Diaper,Milk  Beer  Support       =   | LHS U RHS|  / | D |       = 2/5 = 0.4  Confidence  =   | LHS U RHS |  / | LHS |    = 2/3 = 0.66  Support-based pruningreject rules with s < mins  Check support before checking confidence Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


13  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Example of supportbased pruning 4 Bread 1 Eggs 4 Diaper 3 Beer 4 Milk 2 Coke Count 1Item 3 Beer,Diaper 3 Milk, Diaper 2 Milk,Beer 3 Bread, Diaper 2 Bread,Beer 3 Bread,Milk Count 2Item 2 Milk, Diaper Beer 3 Bread,Milk Diaper Count 3Item Support-based pruning 225 Min support =3 Ignore subsets of items of size N 225 only if N-1 support > min-support Without pruning 6 C 1  6 C 2  6 C 3 41 With pruning: 6 + 6 + 2 = 14 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Classifiers versus Association rules \(again  Classifiers  Assume entire example set can fit into RAM  Association rule learners  can handle very big data sets  Agraw  t he APRIORI alg o r i t h m   very large data sets  10,000,000 examples  843MB Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


14  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 The Data Mining Desiderata Bradley  Require one scan \(or less\ of the database if possible  On-line \223anytime\224 behavior  223best\224 is always available, with status information on progress, expected remaining time, etc. provided  Suspendable, stoppable, resumable  incremental  progress saved to resume a stopped job  Ability to incrementally incorporate additional data with existing models efficiently  Work within confines of a given limited RAM buffer  Ooops, good-bye traditional classifiers e.g. C4.5  Argued against by some  223Memory is cheap\224: [W A R2 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Conf1  outlo o k overc a s t   1 0   82  40    84  40   4 0 0  Treatment learning sunny, 85 86 false none \(2 1 2 sunny, 80 90 true none sunny, 72 95 false none rain 65 70 true,          none rain, 71 96 true none rain 70  false some \(2 2 4 rain, 68 80 false,  some rain, 75 80 false some sunny,      69 70 false lots    \(2 3 8 sunny,      75 70 true lots overcast,     83  false lots overcast,     64  true lots overcast,     72  true lots overcast,     81 75 false lots outlook temp humidity wind hours on course A good attribute range 225 More frequent in good that bad 225 Weighted by 223distance\224good to bad 225 Normalized by total count 225 Summed for all good/bad class pairs Lots  none Lots  some Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


15  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 sunny, 85 86 false none \(2 1 2 sunny, 80 90 true none sunny, 72 95 false none rain 65 70 true,           none rain, 71 96 true none rain 70  false some \(2 2 4 rain, 68 80 false,  some rain, 75 80 false some sunny,      69 70 false lots    \(2 3 8 sunny,      75 70 true lots overcast,     83  false lots overcast,     64  true lots overcast,     72  true lots overcast,     81 75 false lots 0 1 2 3 attribute ranges with deltaf 4-2024681 conf1 225 treatments 002 attribute.range.conf1 > X 225 treatments|=N 225TAR2 = O\(2 N  225 fails for large N outlook temp humidity wind hours on course Conf1  outlo o k overc a s t   1 0   82  40    84  40   4 0 0  Lots  none Lots  some 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Treatments for golf 0 1 2 3 4 none some lots I f outl ook o verc as t Th en l o t s o f go l f  4 4  0 Least monitor watch the humidityalert if rising over 90 Least change pick a vacation location with overcast weather I f h u m i d i t y  90  97 Th en l o t s o f go l f  1 4  0 1 2 3 none some lots 0 1 2 3 4 5 6 none some lots If n o ch an ge Th en l o t s o f go l f  6 6 3 5  3  Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


16  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 6.7 <= RM < 9.8 And 12.6 <= Ptratio 15.9 BEST ACTION 0.6 <= NOX < 1.9 and 17.16 <= LSTAT < 39 WORST ACTION BASELINE 500 examples  of bad--, bad, ok, good Stop staring at the scenery and tell me where to steer or what to dodge 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Require overall require2 require3 require5 require4     action1 action1, action2, action3,  \205   Cost,    Benefit 1 Y              Y             N,        \205   23200,  250 2           N              N             Y ,       \205   11400,  150 205..       \205             \205            \205        \205   \205         \205 action2 fault2 fault3 fault1 JPL requirements Feather&Menzie Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


17  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study 99 proposed actions for deep space satellite design; 2 99 10 30 options Each row is one project plan action1, action2, action3,  \205   Cost,    Benefit 1 Y              Y             N,        \205   23200,  250 2           N              N             Y ,       \205   11400,  150 205..       \205             \205            \205        \205   \205         \205 Learnt 225 Do 16 225 Don\222t do 14 225 Ignore 66 options 225 c.f. genetic algorithms Each dot  is one randomly generated project plan 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Pr of tampering 0.02 Pr of fire 0.01 Pr of smoke  given [fi  0.90 Pr of smoke  given [fi  0.01 Pr of report given [exodus=ye 0.75 Pr of report given [exodus=no 0.01 Pr of exodus given [alarm=yes 0.88 Pr of exodus given [alarm=no 0.001 etc tampering fire alarm smoke exodus run away report hello, operator I want to report a fire 0.02 0.01 Use Bayesian analysis to update probabilities given new information Use Bayesian analysis to update probabilities given new information Bayesian Tuning Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


18  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 tampering fire alarm smoke NO exodus report YES 0.50 was 0.02 0.03 was 0.01 Q1: What if there is a report, but no smoke Q1: What if there is a report, but no smoke Q2: What if there is a report, and smoke Q2: What if there is a report, and smoke tampering fire alarm smoke YES exodus 0.03 was 0.02 0.97 was 0.01 report YES Example from : [Poole98   p37 1 Source = http:// www.swi.psy.uva.nl/projects/SWI-Prolog/download.html http://www.cs.ubc.ca/spider/poole/ci/code.tar.gz Files    = code/acp/bnet.pl code/acp/bnet_t1.pl Bayesian Tuning 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Non-na\357ve model bayesian network Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


19  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Low testing effort EXPLAINS 1\ some observed operational defects  and 2\ low pre-release defects 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02  Ancestors  ancestor\(X,Y\:-parent\(X,Y  ancestor\(X,Y\:-parent\(X,Z\ancestor\(Z,Y  Lists  member\(X,[X|Z   member\(X,[Y|Z me mb er X Z   append X X   append\([X|X Y s X Z s  a ppe nd X s Ys Z s  Example Example action action hypothesis hypothesis p\(b,[b add clause p\(X,Y   specialize p\(X,[V p\(x,[a specialize p\(X,[X p\(b,[a add clause p\(X,[X p\(X,[V p\(X W Inductive Logic Programming Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


20  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 East-West trains 1. TRAINS GOING EAST 2. TRAINS GOING WEST 1 2 3 4 5 1 2 3 4 5 1. TRAINS GOING EAST 2. TRAINS GOING WEST 1 2 3 4 5 1 2 3 4 5 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 ILP representation  Example eastbound\(t1  Background theory car\(t1,c1\      car\(t1,c2\       car\(t1,c3\.      car\(t1,c4 rectangle\(c1\  rectangle\(c2\     rectangle\(c3\.   rectangle\(c4 short\(c1\      long\(c2\.          short\(c3\       long\(c4 none\(c1\.        none\(c2\.          peaked\(c3\.      none\(c4 two_wheels\(c1\  three_wheels\(c2\two_wheels\(c3\two_wheels\(c4 load\(c1,l1\.     load\(c2,l2\       load\(c3,l3\    load\(c4,l4 circle\(l1\      hexagon\(l2\       triangle\(l3\    rectangle\(l4 one_load\(l1\  one_load\(l2\.      one_load\(l3\    three_loads\(l4  Output ne\(C Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


21  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Predicting Correctness Almei NewID CN2 C4.5 C4.5_rule FOIL Accuracy 52 54 66 68 73 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 FOIL\222s best rule high\(A executable\(A,B maximum_statement_nesting_depth\(A,C lines_of_comments\(A,B commentsdivsize\(A,E n1\(A,F n2\(A,G less_or_equal\(E,F not less_or_equal\(B,G C <> 4 C <> 43 less_or_equal\(C,D High faults when comment density <= #operators and executable statements > #operators and max nesting <= number of lines of comments and max nesting is not 4 or 43 High faults when comment density <= #operators and executable statements > #operators and max nesting <= number of lines of comments and max nesting is not 4 or 43 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


22  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Inside  some learners  neural nets  genetic algorithms  decision tree learners  association rule learners  treatment learners  bayesian tuning  inductive logic programming 225 sub-symbolic locally guided descent symbolic, global search 225 recursive diversity reduction 225 this goes with that CLASS 225 this goes with that 225 asses 225 a little model goes a long way 225 Horn clauses  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case studies predicting effort \(45 predicting faults \(51 model-based ML \(54 early lifecycle project planning \(60 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


23  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study How can we estimate earlier in the life cycle  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Predicting development times in months\Srinivasan95 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


24  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Bayes for effort Chulani99  The COCOMO-II project  Open-source software cost estimation  Reuse vs effort XH : multiple product lines VH : across product lines H : across program N : across project L  : none  Regression over data from 83 software projects  Regression conflicted with \223Delphi values\224  Tune regression values using Delphi expectations 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5 1.6 Low N H VH XH Delphi Regression Adjusted Da ta   reus e low e rs effo r t Ex pe ct e d  reus e incre a se  effo r t    251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 COCOMO-II \(1998\COCOMO-II \(1997 Pred\(30 Pred\(25 Pred\(20 Pred\(X 52 49 46 83 projects 63 59 54 161 projects 7561 68 55 63 48 161 projectsbased on Bayesian 161 projectsbased on Delphi Percentage of estimated effort within X of actual Conclusion data + delphi tuning\a Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


25  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Neural Network Count the wi dge ts in the I n te r f ace to es ti m a te e f f o r t  Labels Edit Boxes Grid Boxes Check Boxes Buttons 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Neural Network Subsystem Pred\(25 MARE Buyer Admin 80 17.6 Buyer Client 80 14.6 Distribution Server 20 96.7 Supplier Client 90 12.2  12 Different Widgets Counted and associated with effort Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


26  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study: Predicting software 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Predicting software  faults Khoshgoftaar99 Whi c h d o g s di d not ba r k  225 42 attri b ute s  in dat a s e t 225 Only 6 in the l e arnt th e o ry Diffe re nt attri b ute s than b e fore 225 223c au se s f a u l t 224  do m a in s pec i f i c 225 Me thod for fin d ing fa ult s  gen e r a l Whi c h d o g s di d not ba r k  225 42 attri b ute s  in dat a s e t 225 Only 6 in the l e arnt th e o ry Diffe re nt attri b ute s than b e fore 225 223c au se s f a u l t 224  do m a in s pec i f i c 225 Me thod for fin d ing fa ult s  gen e r a l Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


27  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Issue of generality  Specific conclusions may not apply to general projects  Proposal one  Intra-project learning  Lessons should generalize across the same developer methodology, application and tool set  Proposal two  Inter-project learning  Need larger training set  COCOMOII uses 161 projects  Note: two = N * one Khoshgoft good bad Tia bad good  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Model-based ML Bratko89,Pearc Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


28  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Model-based ML simple e.g sum\(X,  Y Z sum   sum   sum\(0 0 0 sum 0  sum 0  sum\(0   sum\(0   sum  Any sum  Any if X >0 X\222=      if X < 0 0 if X= 0  switch\(State,Volts,Amps switch\(on,       0,     Any switch\(off,      Any,   0 blub\(Mode,Light,Volts,Amps bulb\(blown,dark, Any 0 bulb\(ok,     light   bulb\(ok,    light   bulb\(ok,    dark 0 0 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 A qualitative circuit go  :tell\('circ.data'\ go1, told go1 :functor\(X,circuit,9\ forall\(X, example\(X example\(circuit\(Sw1,Sw2,Sw3,B1,B2,B3,L1,L2,L3\classification\(B1,B2,B3,Class format\('~a,~a,~a,~a,~a,~a,~a~n Sw1,Sw2,Sw3,L1,L2,L3,Class  classification\(B1, B2, B3,Class needs 2 our of three bulbs working classification\( ok, ok, B3,   good classification\( ok, B2, ok,   good classification\( B1, ok, ok,   good classification\( B1, B2, B3,   bad Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


29  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Results from > 700 examples circ.names good,bad switch1: on, off switch2: on, off switch3: on, off bulb1: light, dark bulb2: light, dark bulb3: light, dark Command line c4.5 -f circ -m 2 W a t c hing bulb1 tells us th e rest Insight f ul  Or dull W a t c hing bulb1 tells us th e rest Insight f ul  Or dull 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 More Model-based ML Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


30  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 ca n we r e v i s i t thos e warranti e s   Run 1 35,000 tions  Learn 1  Run 2 if Sw2c=off then 3264 tions  Learn 2  Run 2 if Sw2c=off n then 648 tions  Learn 3 Ca n\222t clos e  Sw3c warranty issu es No b u d g e t  for e x p e ns i v e ha rd wa r e 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 3 \223tunings\224 5 SLOC guesstimates 150,000 runs Treatments for software projects Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


31  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 flex=1 pmat=3 sced=2 rest anything from kc1 150,000 runs 150,000 runs Treatments for software projects \(ii 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 pmat=2 acap=2 sced=2 rest anything from kc1 30,000 runs 30,000 runs Treatments for software projects \(iii Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


32  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 ons discussion \(64 downloads \(69 further reading \(71 references \(72 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Will you try ML  Have we motivated you  Will you rush home and do ML on your data  Clearly  ML algorithms work  Caution  you may find it harder than you think Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


33  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Many ways to learn numerous case studies but there is still a problem Theme Learning is a solved problem \(sort of Data collecting and modeling is not 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Be warned match your ML goals to your software process level Project metrics coarse-grain conclusions Product metrics product learning Process metrics process learning Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


34  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Also, match your tool to task Task ML Tool Assembly line robot deciding what to reject Decision tree learner Repair robot trying to do the least to fix the rejected parts Treatment learner Predicting the life of a robot Neural Network Optimizing the assembly line Genetic Algorithm If clustering when no classes iation rule learning If simple background knowledge Bayesian If complex relational background knowledge ILP 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Have we learnt enough  Not yet  But wait Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


35  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Cost = $0  WEKA  E.g. http://www.cs.waikato.ac.nz/~ml/weka/: ML in JAVA 003 decision tree inducers,rule learners, naive Bayes, decision tables locally weighted regression  GDB_Net  http://nas.cl.uh.edu/boetticher/gdb_net.zip  TAR2  http://www.ece.ubc.ca/twiki/bin/view/Softeng/TreatmentLearner  APRIORI  http://fuzzy.cs.uni-magd eburg.de/~borgelt/apriori/apriori.html#download  And many others  E.g. ML  A public domain \223C\224 library of common algorithms  Naive Bayes, ID3, MC4 , Decision Tables ,   Holte's OneR CN2,\205  http://www.sgi.com/tech/mlc/utils.html 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Cost > $0  C4.5  Comes with the book Quinlan  C5.0  http://www.rulequest.com/download.html  Microsoft SQL SERVER 2000\231  Comes with numerous machine learning tools  Proprietary algorithms  Etc  223data mining\224 \223commercial software\224 in Google  3,340 links  223data mining consultancy\224 in Google  850 links Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


36  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Further reading  Mendonca  great rev i e w art i cl e on ML  Large list of available tools  All the things you can do with a decision tree [Menzies0  Treatment learning: [Menzies01a  Michalski\222s excellent survey of ML types [Michalski  Neural nets: [Boetticher01  Special issue SEKE journal, knowledge discovery Morasca99  Inductive logic programming [Bergadano95,Cohen95  Come by IJCAI 2011 and I\222ll tell you all about it\222s applications  Genetic algorithms: [Goldberg8  Bayesian learning [Cheeseman88 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 References  Agrawal  Agrawal, R., and T.Imeilinski and A.Swami \223Mining Association Rules between Sets of Items in Large Databases,\224 Proceedings of the 1993 ACM SIGMOD Conference Washington DC, USA  Bergadan  Bergadano, F., and D.Gunetti Inductive Logic Programming: From Machine Learning to Software Engineering The MIT Press, 1995  B  Berry, M. J. A., and G., Linoff Data Mining For Marketing, Sales, and Customer Support John Wiley Sons, Inc., New York, 1997  Boetticher01  Boetticher, G., "An Assessment of Metric Contribution in the Construction of a Neural Network-Based Effort Estimator Second International Workshop on Soft Computing Applied to Software Engineering  Enschade, NL, 2001 Available from http://nas.cl.uh.edu/boetticher/publications.html  Boetticher01  Boetticher, G., "Using Machine Learning to Predict Project Effort: Empirical Case Studies in Data-Starved Domains First International Workshop on Model-based Requirements Engineering San Diego, 2001 Available from http://nas.cl.uh.edu/boetticher/publications.html  Bradley  Bradley, P., U. Fayyad, and C. Reina. \223Scaling clustering algorithms to large databases\224. In KDD'98  B  Bratko, I., I. Mozetic, and N. Lavrac KARDIO: a Study in Deep and Qualitative Knowledge for Expert Systems MIT Press, 1989  Breim  Breiman, L., J. Friedman, R. Olshen, C. Stone, \223Classification and Regression Trees,\224 Wadsworth International Group, 1984 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


37  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 References  Burgess  Burgess, C.J., and Martin Lefley. \223Can genetic programming improve software effort estimation? A comparative evaluation,\224 Information and Software Technology er 2001  Cheesem  P. Cheeseman, D. Freeman, J. Kelly, M. Self, J. Stutz, and W. Taylor. \223Autoclass: a bayesian classification system,\224 In Proceedings of the Fifth International Conference on Machine Learning  Morgan Kaufman, 1988  Chulani  S.Chulani,  B. Boehm, and B. Steece 223Bayesian analysis of empirical software engineering cost models,\224 IEEE Transaction on Software Engineering 25\(4\ly/August  1999  Cohe  W. W. Cohen, \223Inductive specification recovery: Understanding software by learning  from example behaviors,\224 Automated Software Engineering 2:107-129, 1995  DeJon  DeJong, K.A., and Spears, W.M. "An Analysis of the Interacting Roles of Population Size and Crossover in Genetic Algorithms Proc. First Workshop Parallel Problem Solving from Nature  Springer-Verlag, Berlin, 1990  Dietteric  Dietterich, T. G., \223Machine Learning  Research: Four Current Directions,\224 AI Magazine 18 \(4\97 Pp. 97-136. Available from ftp://ftp.cs.orst.edu/pub/tgd/papers/aimag-survey.ps.gz  s  Feather, M.S., and T. Menzies: \223Converging on the Optimal Attainment of Requirements IEEE Joint Conference On Requirements Engineering  ICRE'02 and  RE'02 9-13th September, University of Essen, Germany, 2002. Available from http://tim.menzies.com/pdf/02re02.pdf 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 References  Fenton00  Fenton, N., and  M. Neil \223Software Metrics: A Roadmap,\224 International Conference on Software Engineering, 2000. Available from http://www.dcs.qmul.ac.uk/~norman/papers/metrics_roadmap.pdf  Goldberg  Goldberg, D.E Genetic Algorithms in Search, Optimization, and Machine Learning Addison-Wesley Reading, Massachusetts, 1989  Khoshgoftaar  Khoshgoftaar, T.M., and E.B. Allen. \223Model software quality with classification trees,\224 in H. Pham, editor 223Recent Advances in Reliability and Quality  Engineering\224, World Scientific, 1999  Mendonc  Mendonca, M., and N.L. Sunderhaft, \223Mining Software Engineering Data: A Survey,\224 A DACS State-ofthe-Art Report September 1999. Available from http://www.dacs.dtic.mil/techs/datamining  Menzie  Menzies, T., \223Practical Machine Learning for Software Engineering and Knowledge Engineering,\224 ftware Engineering and Knowledge Engineering volume 1, 2001\vailable from http://tim.menzies.com/pdf/00ml.pdf  Menzies01a  Menzies, T., and Y. Hu, \223Reusing models for requirements engineering,\224 First International Workshop on Model-based Requirements Engineering 2001. Available from http://tim.menzies.com/pdf/01reusere.pdf  Menzies01b  Menzies, T., and Y. Hu, \223Constraining discussions in requirements engineering,\224 First International Workshop on Model-based Requirements Engineering San Diego, 2001. Available from http://tim.menzies.com/pdf/01lesstalk.pdf  Menzie  Menzies. T., and J. Kiper, \223Better reasoning about software engineering activities,\224 Automated Software Engineering 2001. Available from http://tim.menzies.com/pdf/01ml4re.pdf Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


38  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02  Michalski90   Michalski, R.S., \223Toward a unified theory of learning,\224  In B.G. Buchanan and D.C. Wilkins, editors 223Reading in Knowledge  Acquisition and Learning\224, pages 7--38. Morgan Kaufmann, 1993  Mitchell  Mitchell, T Machine Learning McGraw-Hill, 1997  Morasca99  Morasca, S., and Gunther Ruhe, Guest editors' introduction of the Special issue on \223Knowledge Discovery from Software Engineering Data,\224 International Journal of Software Engineering and Knowledge Engineering October, 1999  Pearce  Pearce, D., \223The induction of fault diagnosis systems from qualitative models,\224 in Proc. AAAI-88 1988  Poole9  Poole, D. L.,  A. K. Mackworth, and R. G. Goebel Computational Intelligence: A Logical Approach  Oxford University Press, New York, 1998  Porter9  Porter, A.A., and R.W. Selby  \223Empirically guided software development using metric-based classification trees,\224 IEEE Software Pp. 46-54, March 1990  Quinla  Quinlan, R C4.5: Programs for Machine Learning Morgan Kaufman, 1992  Srinivasa  Srinivasan, K., and D. Fisher,  \223Machine learning approaches to estimating software development effort,\224 IEEE Transactions on Software Engi neering Pp. 126-137, February 1995  Tian9  Tian, J., and M.V. Zelkowitz 223Complexity measure evaluation and selection,\224 IEEE Transactions on Software Engineering 21\(8\p. 641-649,  August 1995  Webb0  Webb, G., \223Efficient search for association rules,\224 Proceeding of KDD-2000 Boston, MA,  2000  Zhang0  Zhang, Du, \223Applying Machine Learning Algorithms in Software Development,\224 Modelling Software System Structures in a fastly moving scenario Santa Margherita Ligure, Italy, 2000 References Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 



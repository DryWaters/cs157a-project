Mining Molecular Fragments Finding Relevant Substructures of Molecules Christian Borgelt Michael R Berthold School of Computer Science Universiq of Mugdeburg Universitiitsplutz 2 0-39106 Magdeburg, Germany Data Analysis Research Lab Tripos Inc 601 Gateway Blvd Suite 720 South San Francisco, CA 94080 USA e-mail horgelt@iws.cs.uni-magdeburg.de e-mail berthold@tripos.com Abstract We presenr an algorithm 10 Jind fragments in a ser of molecules rhat help to discriminate beween dif/erent classes oJ for instance 
activih in a drug discovep context instead of carving our U brurerforce search our method generates fragments by embedding rhein in all appropriare molecules in parallel arid prunes the search free based on a local order of the atoms and bonds which resulrs in sub stantially faster search by eliminaring the need for freqoenr compurarionall expensive reembeddings arid by suppress ing redirndanr search We prove the usefulness of our al gorithm by demonstraring rhe discoven 
of activiryrelated groups of chemical compounds in the well-knonw National Cancer lnsriture s HIV-screenbig doraset 1 Introduction Many data mining tasks in bioinformatics consist in ana lyzing large collections of molecules with the goal to find some regularity among molecules of a specific class Possi ble applications are manifold One example is drug discov ery where the biologist wants to find new drug candidates based on experimental evidence of activity against a cer tain disease gathered by screening hundreds of thousands of molecules A second more recent emphasis comes from chemical 
synthesis success prediction, where the goal is to find molecular features that inhibit the desired reaction Current approaches to find regularities among molecules are often based on so-called descriptors. which usually con sist of thousands of binary features representing some times in a hashed manner\certain substructures of interests such as aromatic rings or some other predefined small group of atoms 141 Other descriotors model Dairwise atom dis rive similarity measures based on transformations of these graphs were also proposed 191 However, such notions of similarity hased on a particular descriptor with a corre 
sponding metric only model limited aspects of molecular similarity well Therefore altempts to directly extract rel evant substructures from a collection of molecules are of persistent interest Recently an approach was presented that finds linear frag ments 7 i.e chains of atoms using an algorithm similar to the well-known Apriori association rule mining method I However the restriction to linear fragments is limiting in many real-world applications, since substructures of inter est often contain rings or branching points Nevertheless the idea to use an association rule mining algorithm by re garding the molecules as a set of nodes \(instead of 
the usual bit sets has sparked considerable interest A more recent approach 5 finds arbitrary connected substructures by de riving canonical labels for each graph The search is again based on the Apriori algorithm and hence still relies on frequent reembeddings of fragments in order to determine valid intermediate candidates throughout the search In this paper we present an algorithm that also finds ar bitrary connected substructures but avoids frequent reem beddings by using a different search strategy The algo rithm maintains parallel embeddings of a fragment into all 
molecules throughout the growth process and exploits a lo cal order of the atoms and bonds of a fragment to prune the search tree which results in faster search and allows for a restricted depth first search algorithm similar to the Eclat association rule mining algorithm IZ We first present the main algorithm followed by adiscus sion of results obtained on the HN-screening dataset from the National Cancer Institute  1 I and conclude with a brief discussion of possible extensions of our method  lances or 
3D molecule arrangements Prediction algorithms then simply use a distance function on these descriptors to define similarity between molecules More sophisticated algorithms attempt to find boolean combinations of some of these features that are related to different classes IO Approaches that try to regard molecules as graphs and de 2 The Induction Algorithm In this section we describe our algorithm by developing it from algorithms for the well-known task of association rule induction We start by reviewing the search schemes for fre 0-7695-1754-4102 17.00 Q 2002 IEEE 51 


3 Figure I A search tree for five items a,b,c,d,e quent itemsets in Section 2.1 and then transfer their ideas to the more complicated case of finding molecular substruc tures in Section 2.2 In Section 2.3 we describe how our algorithm prunes the search tree based on a local order of the atoms and bonds of a fragment In section 2.4 we dis cuss a simple example and in Section 2.5 we study why it is impossible to avoid all redundant search Finally in Sec tions 2.6 and 2.7 we describe how to embed core structures to start the search from and how to find contrast structures that distinguish between groups of molecules 2.1 Association Rules and Frequent Itemsets The induction of association rules is a powerful method for market basker analysis which aims at finding regularities in the shopping behavior of customers of supermarkets mail order companies on-line shops and the like With it one tries to find sets of products that are frequently bought to gether so that from the presence of certain products in a shopping cart one can infer with a high probability that certain other products are present The main difference to our task of finding frequent substructures of molecules is that in market basket analysis we have only simple seis of irems to deal with while in molecular substructure analy sis we have to take the chemical connectivity i.e. the bonds connecting individual atoms, into account as well The best-known association rule algorithms are Apriori I and Eclat 12 Both work in two steps First thefre quent itemsets often misleadingly called large iremsers are determined These are sets of items that have at least a given minimum support i.e occur in at least a given percentage of all transactions In the second step association rules are generated from these frequent itemsets Here we focus on the first step because we are not concerned with generating rules However, research in association rule induction usu ally does the same because finding the frequent itemsets accounts for the greater part of the processing time In order to find frequent itemsets one has to count the transactions different itemsets are contained in This task consists in traversing a tree like the one shown in Figure 1 and determining the values of the counters in its nodes Each box represents a counter The edge labels on a path from the root to a node indicate the common part of the itemsets for which there are counters in that node The tree is unbalanced because we are dealing with sets not sequences abc for instance is the same as bca and thus only one of these counters is needed Mathematically the search tree is a substructure of the subset lattice having ex actly one path to any itemset In addition both Apriori and Eclat exploit the simple observation that no superset of an infrequent itemset can be frequent This observation can he used to further prune the tree because all counters for item sets having an infrequent subset can be discarded The main differences between Apriori and Eclat are how they traverse this tree and how they determine the counter values Apriori does a breadth first search and determines the support of an itemset by explicit subset tests on the trans actions An efficient implementation can use a data struc ture like the tree shown in Figure 1 to store the counters 2 31 However, the need to build a data structure like this can also be a severe disadvantage as it can consume a lot of memory Furthermore the subset tests can he costly On the other hand, Eclat does a depth first search and de termines the support of an itemset by intersecting the trans action lists for two subsets. the union of which is the item set The advantage is that not all counters have to be kept in memory especially if one allows for some unnecessary tests which could be avoided only by checking all subsets A disadvantage is that several transaction lists have to be kept in memory at the same time-lists that can he very long especially for small itemsets More sophisticated ap proaches try to combine the advantages using Apriori for the first levels of the tree \(usually only 2 or 3 and Eclat as soon as the transaction lists are short enough 12,6 2.2 Frequent Substructures of Molecules In order to capture the bond structure of molecules we model them as attributed graphs in which each vertex rep resents an atom and each edgc a bond between atoms Each vertex carries attributes that indicate the atom type i.e the chemical element a possible charge and whether it is part of an aromatic ring Each edge carries an attribute that indi cates the bond type \(single. double triple or aromatic Our goal is to find substructures that have a certain min imum support in a given set of molecules i.e are part of at least a certain percentage of the molecules However in order to restrict the search space we consider only con necred subsrrucrures i.e graphs having only one connected component For most applications, this restriction is harm less because connected substructures are most often exactly what is desired We do not constrain the connectivity of the graph in any other way The graphs may be chains or trees or may contain an arbitrary number of cycles With this we go beyond 71 who considered only lineur subsrrucrures i.e., simple chains of atoms without branches Such simple chains are rarely sufficient in real-world applications Most naturally the search is carried out by traversing a tree of fragments of molecules similar to the tree of item sets shown in figure 1 The root of the tree is the core struc ture to start from which for now we assume to be a sin gle atom more complex cores are discussed below Going 52 


down one level in.the search tree means to extend a sub structure by a bond \(and maybe an atom if the bond does not close a ring just like going down in the tree shown in Figure 1 means adding an item to an itemset That is with a single atom at the root of the tree the root level contains the substructures with no bonds, the second level those with one bond, the third level those with two bonds and so on As indicated above, there are basically two ways in which the search tree can be traversed We can use either a breadth first search and explicit subset tests Apriori or a depth first search and intersections of transaction lists Eclat\For our task the Eclat approach is clearly preferable because the disadvantages of the Apriori approach become consid erably more severe: Even subset tests can be costly but sub structure tests which consist mathematically in checking whether a given attributed graph is a subgraph of another at tributed graph, are extremely costly Furthermore the num ber of small SubStNCtureS 1 to 4 atoms can be enormous so that even storing only the topmost levels of the tree can require a prohibitively large amount of memory Of course the Eclat approach also suffers because the transaction lists are now lists of embeddings of a subsuuc ture into the given molecules Since there can be several em beddings of the same substructure into one molecule these lists tend to get longer This drawback can make it necessary to start from a reasonably sized core structure see below To be more specific our algorithm searches as follows The given core structure is embedded into all molecules resulting in a list of embeddings Each embedding consists of references into a molecule that point out the atoms and bonds that form the substructure Remember that a list of embeddings may contain several embeddings for the same molecule if the molecule contains the substructure in more than one place or if the substructure is symmetric In a second step each embedding is extended in every possible way This is done by adding all bonds in the cor responding molecule that start from an atom already in the embedding to ensure connectedness and of course to re duce the number of bonds that have to be considered\This may or may not involve adding the atom the bond leads to because this atom may or may not be part of the embed ding already More technically by following the references of an embedding the atoms and bonds of the corresponding molecule are marked and only unmarked bonds emanating from marked atoms are considered as possible extensions The resulting extended embeddings are then sorted into equivalence classes each of which represents a new sub structure This sorting is very simple because only the added bond and maybe the added atom have to be com pared In our implementation we use a hash table and an array of lists of embeddings to sort the extensions. The hash table associates an embedding with an array index, using a hash code that is computed from the type of the bond that was added in the preceding step the position in the sub structure of the atom it starts from and the position and the type of the atom it leads to After all extended embed dings have been processed each may element contains the list of embeddings of a new substructure. Each of these new substructures corresponds to a child node in the search tree each of which is then processed in turn by searching recur sively on the list of embeddings corresponding to it 2.3 Search Tree Pruning Of course, subtrees of the search tree can be pruned if they refer to substructures not having enough support i.e if too few molecules are referred to in the associated list of em beddings We call this support based pruning We may also prune the search tree if a user-defined threshold for the number of atoms in a fragment has been reached We call this size based pruning However when we reviewed the search for frequent itemsets we also considered a third type of pruning, which we refer to as structuralpruning It is re sponsible for the unbalancedness of the search tree shown in Figure 1 As pointed out above we do not need a counter for bca because it is the same itemset as abc Structural pruning ensures that every itemset is considered in one branch only even though adding items in different orders can yield the same itemset. In the following we consider how such struc tural pruning can be done in the search for frequent sub structures of molecules because obviously adding bonds in different orders can result in the same substructure In order to find a structural pruning scheme let us ana lyze the structural pruning of the itemset tree in more detail Figure 1 shows the basic idea very clearly The items are ordered which is indicated by the symbols a b etc This order is of course, arbitrary But once it is fixed, the item sets processed in a node can be Constructed as follows: Ex tend the set of items used as edge labels on the path to the node with an item following the last edge label Consider for example, the second node on the third level count from top to bottom and from left to right The path to this node has labels a and c Therefore the set a c has lo be ex tended by items following c i.e by d and e Consequently there are counters for the sets a c d and a c e in this node The same holds for any other node Obviously, this scheme fixes an order in which items can be added and thus each itemset can be reached only in one possible way We organize the nodes of the search tree for molecular substructures in a very similar way The main difference is that we cannot define a global order of the atoms of the molecules, which would correspond directly to the order of the items Rather we number the atoms in a substructure and record how a substructure was constructed in order to constrain its extensions The number we assign to an atom reflects the step in which it was added That is the core atom is numbered 0 the atom added with the first bond is numbered 1 and so on Note that this number does not tell anything about the type of the atom as two completely dif ferent atoms may receive the same number, simply because they were added in the same step 53 


Figure 2 A set of six example molecules Whenever an embedding is extended we record in the resulting extension the number of the atom from which the added bond started When the extended embedding is to be extended itself we consider only bonds that start from atoms having numbers no less than this recorded number That is only the atom extended in the preceding step and atoms added later than this atom can be the starting point of a new bond This rule is directly analogous to the rule that only items following the item added last may be added to an itemset. With this simple scheme we immediately avoid that two bonds call them A and B which start from different atoms are added in the order A B in one branch of the search tree and in the order B A in another Since either the atom A starts from or the atom B starts from must have a smaller number one of the orders is ruled out However two or more bonds can start from the same atom Therefore we also have to define an order on bonds so that we do not add two different bonds A and B that start from the same atom in the order A B in one branch of the search tree and in the order BI A in another This order on bonds is of course arbitrary In our implementa tion single bonds precede aromatic bonds which precede double bonds which precede triple bonds Finally within extensions by bonds of the same type starting from the same atom the order is determined by 1 whether the atom the bond leads to is already in the substructure or not and 2 the type of this atom To take care of the bond type etc., we record in each embedding which bond was added last The above rules provide us with a structural pruning scheme but unfortunately this scheme is not perfect and making it perfect would be very expensive computationally The problem is that we do not have any precedence rule for two bonds of the same type starting from an atom with the same number and leading to atoms of the same type and that it is not possible to give any precedence rule for this case that is based exclusively on locally available in formation We consider the problems that result from this imperfection and our solution below, but think it advisable to precede this consideration by an illustrative example of the search process as we defined it up to now 2.4 An Illustrative Example As an illustration we consider how our algorithm finds the frequent substructures of the six example molecules shown Figure 3 The search tree for the six molecule ex ample The tables below the fragments indicate the numbers of embeddings per molecule in Figure 2 staning from a sulfur atom We use a minimum support of 50 i.e a substructure must occur in at least three of the six molecules to qualify as frequent First the sulfur atom is embedded into the six molecules This results in six embeddings one for each molecule which form the root of the search tree \(see Figure 3 the ta ble in the root node records that there is one embedding for each molecule Then the embeddings are extended in all possible ways which leads to the four different substruc tures shown on the second level i.e S-C S-N S-0 S=N These substructures are ordered, from left to right as they are considered by our algorithm i.e extensions by sin gle bonds precede extensions by double bonds. and within extensions by bonds of the same type the element type of the atom a bond leads to determines the order Note that there are two embeddings of S-C into both the molecules b and c and two embeddings of S-0 into the molecule a In the third step the extensions of the substructure S-C are constructed This leads to the first five substructures on the third level i.e C-S-C C-S-N C-S-0 C-S=N and C-C-S Again the order of these substructures, from left to right reflects the order in which they are consid ered. Since we search depth first, the next substructure to be extended is C-s-C.2 However, this substructure does not have enough support and therefore the subtree is pruned The substructure C-S-N is considered next etc How ever we confine ourselves to pointing out situations in which specific aspects of our method become obvious Ef fects of the structural pruning can be seen for instance at the fragment C-S-N which does not have a child in which a second carbon atom is attached to the sulfur atom The reason is that the extension by the bond to the nitrogen atom rules out all single bonds leading to atoms of a type preced ing nitrogen like carbon Similarly C-S=N does not have children with another atom attached to the sulfur atom by a single bond not even an oxygen atom which follows ni trogen in the periodic table of elements The reason is that 54 


3 C-S-N 3 50 3 50 5 83  1 C-S-N 2 C-C-S-N 4 C-S-0 5 C-S=N 6 C-S 4 67 3 50 6 100 Figure 4 The six frequent substructures that are found in the ex ample in the order in which they are generated a double bond succeeds a single bond and thus the exten sion by the double bond to the nitrogen atom rules out all single bonds emanating from the sulfur atom Finally, the structure C-C-S has no children at all even though it has enough support The reason is that in this substructure a bond was added to the carbon atom adjacent to the sulfur atom This carbon atom is numbered 1 and thus no bonds can be added to the sulfur atom. which has number 0 Only the carbon atoms can be starting points of a new bond, but there are no such bonds in the molecules a b and d During the recursive search all frequent substructures en countered are recorded The resulting set of six frequent substructures together with their absolute and relative sup pon is shown in Figure 4 Note that C-C-S is not re poned because it has the same support,as its superstruc tureC-C-S-N Likewise 0-S-N S=N,and Sarenotre ported This example makes it clear that our algorithm can find arbitrary substructures even though it does not show how cyclic S~NC~UES are treated Unfortunately search trees for cyclic structures are too big to be depicted here 2.5 Incomplete Structural Pruning We indicated above that our structural pruning is not per fect In order to understand the problems that can arise con sider two molecules A and B with the common substruc ture N-C-S-C-0 We try to find this substructure starting from the sulfur atom Since the two bonds emanating from the sulfur atom are equivalent, we have no precedence rule and thus the order in which they are added to an embedding depends on the order in which they occur in the correspond ing molecule Suppose that in molecule A the bond going to the left precedes the bond going to the right while in molecule B it is the other way round As a consequence, in embeddings into molecule A the left carbon atom will pre cede the right one while in embeddings into molecule B it will be the other way round Now consider the substruc ture C-S-C and its extensions In molecule A the carbon numbered 1 the left one will be extended by adding the nitrogen atom and thus the oxygen atom can be added in the next step to the carbon on the right, which is numbered 2 resulting in the full substructure However in molecule B the nitrogen atom has to be added by extending the carbon atom numbered 2 again the left one in embeddings into molecule B the right carbon is numbered I Hence it is not possible to add the oxygen atom in the next step because this would mean adding a bond starting at an atom with a lower number than the atom extended in the preceding step Therefore the common substructure is not found This ex ample also shows that it does not help to look 223one step ahead\224 to the next atom, because there could be arbitrarily long equivalent chains, which differ only at the ends If however we accept to reach identical substructures in different branches of the search tree in cases like this we can correct the imperfection of our structural pruning Whenever we have extended an embedding by following a bond we allow adding an equivalent bond in the next step regardless of whether it precedes or succeeds in the corre sponding molecule the bond added in the preceding step This relaxation explains why there are two embeddings of the substructure C-S-C into both the molecules b and c of our example In one embedding the left carbon atom is num bered 1 and the one at the bottom is numbered 2 while in the other it is the other way round cf Figure 2 Note that considering the same substructure several times cannot lead to wrong results only to multiple reporting of the same substructure Multiple reponing however can be suppressed by maintaining a list of frequent substruc tures and suppressing new ones that are identical to already known ones It is more important that the missing rule for equivalent bonds can lead to considerable redundant search in certain structures, especially molecules containing one or more aromatic rings We are currently trying to tackle this problem by collapsing rings into special vertices However it should be noted that even if we could amend the weakness of our structural pruning we would still be unable to guarantee that each substructure is considered in only one branch If for instance some substructure X can be embedded twice into some molecules and if there are fre quent substructures that contain both embeddings \(and thus X twice\then these substructures can be grown from either embedding If the connection between the two embeddings of X is not symmetric, the same substructure is reached in two different branches of the search tree in this case Obvi ously, there is no simple way to avoid such situations 2.6 Embedding a Core Structure Up to now we assumed that we start the search from a sin gle atom This usually works fairly well as long as this atom is rare in the molecules IO work on For example sulfur or phosphorus are often good starting points in biochemical applications while starting with carbon is a bad idea Ev ery organic molecule contains several carbon atoms often twenty or more and thus we end up with an already very high number of embeddings of the initial atom As a conse quence the algorithm is likely to run out of memory before reaching substructures of reasonable size However if we cannot start from a rare element it is sometimes possible to specify a core-for instance an aro matic ring with one or two side chains-from which the 55 


search can be started Provided the core structure is specific enough, there are only few at best only one embedding per molecule so that the list of embeddings is short While it is trivial to embed a single atom into a molecule embedding a core structure can be much more difficult In our implementation we rely on the following simple obser vation Embedding a core structure is the same as finding a common substructure of the molecule and the core that is as big as the core itself This leads to the idea to grow a sub structure into both the core and the molecule until it com pletely covers the core. That is we do a substructure search for the core and the molecule starting from an arbitrary atom of the core and requiring a support of 100 i.e both the core and the molecule must contain the substructure In addition, we can restrict the search to one embedding of a substructure into the core at all times since we know that it must he completely covered in the end For the molecule however we must consider all possible embeddings Note that the same mechanism of growing a substructure into two molecules can also be used for substructure tests as they are needed to suppress multiple reporting of the same fragment see above as well as reporting redundant frag ments fragments that are substructures of some other frag ment and have the same support as this fragment 2.7 Finding Contrast Structures Our approach to find frequent substructures can easily be extended to find contrasf sfrucfures that is substructures that are frequent in a predefined subset of the molecules and infrequent in the complement of this subset Finding con trast structures requires two parameters a minimum sup prt for the focus subset and a maximum support for the complement The search is carried out in exactly the same way as described above The only difference is that two support numbers are determined one for the focus subset and one for the complement Only the support in the focus subset is used to prune the search tree The support in the complement determines whether a frequent substructure is recorded or not thus filtering out those substructures that do not satisfy the requirements for a contrast structure 3 Experimental Results We applied the presented approach to a number of confi dential data sets with substantial success In order to be able to report results in more detail we used a well-known publicly available dataset from the National Cancer Insti tute the DTP AIDS Antiviral Screen dataset This screen utilized a soluble formazan assay to measure protection of human CEM cells from HIV-1 infection Full details were published in I I Compounds able to provide at least 50 protection to the CEM cells were retested Compounds that provided at least 50 protection on retest were listed as moderately active CM Compounds that reproducibly Atom C Carbon 0 Oxygen N Nitroeen CA CM and CI 325 100.0 36828 99.95 311 95.7 33029 89.64 276  84.9 29234 \(79.34 224  S Sulfur 11 143 44.0 I 10926 29.65   I1 I Se Selenium 11 6  1.9 1 132 0.36 Table I Some single-atom fragments occurring in molecules of the HIV database, together with their Occurrence frequencies provided 100 protection were listed as confirmed active CA\Compounds not meeting these criteria were listed as confirmed inactive CI Available online 8 are screening results and chemical structural data on compounds that are not covered by a confidentiality agreement Available are 41,316 compounds of which we used 37,171 Out of these a total of 325 belongs to class CA 877 are of class CM and the remaining 35,969 are of class CI NCI lists 75 known active compounds which are grouped into seven classes I Azido Pyrimidines 2 Natural Prod ucts or Antibiotics 3 Benzodiazepines, Thiazolobenzim idazoles and related Compounds 4 Pyrimidine Nucleo sides 5 Dyes and Polyanions 6 Heavy Metal Com pounds. and 7 Purine Nucleosides As described above, our molecular fragment mining al gorithm requires a seed fragment which may be empty For the HIV dataset an empty core results in numerous em beddings of trivial fragments such as single carbon atoms or small combinations of carbon atoms only However fragments of interest contain at least one non-carbon atom which enabled us to seed the algorithm using the remaining atoms The list of atoms can be obtained through various methods We simply started from an empty core restricted the fragment size to one atom, and ran our molecular frag ment miner. Parts of the resulting list of atoms together with their occurrence frequencies are listed in Table I Obviously due to space constraints we cannot report in detail about seeding the algorithm with each of these atoms In the following we therefore concentrate on a few exper iments to demonstrate how the proposed method picks out relevant fragments in some of these groups 3.1 Nitrogen based Fragments First we focus on compounds containing a nitrogen atom We used a minimum support of 15.0 for compounds of class CA and a maximum support of 0.1 for the comple ment\222 classes CM and CI 171 fragments were generated 3Thresholds were selected %p-down\224 i.e starting with large rellings that quickly resulted in no reponed fragmens the thresholds were subne quentially lowered until a small number of fragments was reponed 56 


Fragment 1 Fraamenl2 Fragment 3 CA 17.75 CA 17.75 CA 22.46 Ct/CM 0.061 CI/CM 0.062 CI/CM 0.092 Fragment 1 CA 11.0 Fragment 2 CA 11.9 CVCM 0.3 CVCM 0.4 Figure 7 The two largest fragments with a sulfur atom These fragments are common to I I of the 13 Dyes and Polyanions Figure 5 The three largest fragments containing a nitrogen atom Fraamenl 1 639762 CM 254064 MO2670 NIN:N A 0 A N:N Figure 6 One pmicular compound 254064 along with a repre sentative of the normal structure \(#602670 within approximately 20 minutes The three largest frag ments found are shown in Figure 5 Note how the first two fragments have essentially the same coverage The only difference is one additional com pound of class CI that contains fragment 2 In this com pound the three nitrogen atoms are connected to the 4 carbon-oxygen ring through an intermediate carbon This results in a fragment where the carbon connected to the three nitrogen atoms is part of a ring in all cases but one which prevents the search algorithm from closing the ring The ring was closed in the first fragment however, result ing in one less inactive compound being covered Figure 6 shows this specific compound along with another compound of class CA that exhibits the more typical structure The third fragments coverage is substantially different even though its structure is almost identical The only differ ence is the double bond between two carbons that closes the second ring in the fint fragment which is missing in Frag ment 3 However some active compounds have a single bond instead of a double bond between these carbons and hence not closing this ring results in a slightly smaller frag ment with a much higher coverage This fragment success fully picks out compounds of class Azido Pyrimidines a well-known inhibitor of HIV-I Below we will discuss how softening the matching criteria allows us to tolerate such small differences between otherwise identical fragments which makes this approach also more useful for chemists who tend lo regard such structures as similar 3.2 Sulfur based Fragments Next we seeded the algorithm with a sulfur atom We chose the thresholds support=lO% and complement=O.S which We used a Java implemenlalion of our algorithm on a lGhz Xeon Dual-Rocerror machine with IGB of main memory uringjrel.3.1 639763 CM a d t1639767 CA Fragment 2 639764 CI Q freq CA 33.3 freq CI/CM 3.0 a I It639772 CA Figure 8 Fragments left and corresponding compounds right containing a Selenium atom The two compounds of class CA are members of the group of Heavy Metal Compounds generated a list of 122 fragments in under one minute The first two which also happen to be the largest ones with 18 atoms and 19 bonds resp are shown in Figure 7 Note how these two fragments differ only in the loca tion of the SO3 group Both fragments exhibit a lift of well above 25 and pick out 1 I of the 13 molecules listed as Dyes and Polyanions We miss only two of the remaining Dyes and Polyanions \(it9617 and #65849 which contain uncom mon structures for this family of compounds 3.3 Selenium based Fragments An interesting effect of the current method to find fragments can he seen when seeding the algorithm with a Selenium atom Se Figure 8 left shows the two fragments that are found for a minimum support of 30 and a maximum complement support of 5 Clearly the first fragment is sufficient to pick out all 7 compounds from the database shown on the right of Fig ure 8 However, the second fragment covers one compound less 639766 and tries to complete the aromatic ring in both directions in parallel This results in a conflict with the nitrogen atom in compound 639766 and a fragment which is neither a subset of the other fragment nor has exactly the same coverage For our algorithm these two fragments are therefore unique and are not pruned 57 


single bond  aromatic bond single bOnd  aromatic bDnd d CBO Figure 9 Two fragments extracted from a sei of steroids On the left, single and aromatic bonds were treated as different bond types. on the right they were treated as the same bond type 3.4 Treatment of Aromatic Bonds An important aspect of molecular fragment mining is the treatment of aromatic rings Since ammaticity is not clearly defined and can be modeled differently i.e explicit aro matic bonds vs alternating single and double bonds it is desirable to be able to take it into account throughout the mining process itself We achieve this by modeling aro matic bonds as either single or double bonds with a flag that indicates aromaticity This allows us to choose to ignore this flag during mining and hence to find fragments that contain either aromatic or single resp double bonds The following example illustrates why this is desirable Using a small set of steroid compounds we derived frag ments that occur in ail of them support=100%\using the standard algorithm Figure 9 left shows the correspond ing fragment Note how only two rings with an incomplete third ring are discovered of the four ring structure that is typical for steroids However if we model aromatic bonds as single+flag and allow the algorithm to ignore this flag the resulting fragment contains all four rings see Figure 9 right For some steroids this fourth ring consists of sin gle bonds while others have an aromatic ring at this posi tion However most chemists still regard this as the same 4 ring structure Such selective 223tolerance\224 against some mis matches can therefore make the presented algorithm more useful for real applications 4 Conclusions We presented an algorithm to find relevant molecular frag ments in large chemical structure databases The algorithm allows us to focus on fragments that help to discriminate be tween different classes of molecules The underlying search method, which is based on a depth first search with struc tural pruning makes it possible to find such fragments effi ciently without the need for frequent reembeddings of frag ment candidates, which is a known problem of previously reponed approaches We have shown how the proposed method finds relevant fragments using data from a well known HIV-screening compound database The extracted fragments successfully model several of the activity classes known for this dataset Future work will focus on making the presented approach more meaningful for the underlying application In partic ular finding fragments that match exactly is not of prime interest to chemists As demonstrate above some types of ring structures are considered functionally equivalent which should be taken into account by the search algorithm as well We are currently exploring ways to include such 223fuzziness\224 into the underlying search algorithm directly References I R Agrawal T Imielienski and A Swami. Mining Associa tion Rules between Sets of Items in Large Databases Pmc Con on Management of Data 207-216 ACM Press New York NY USA 1993 Apriori  Finding Association Rules with the Apriori Algorithm free computer software under the GLPL http://fuzzy.cs.uni-magdeburg.de/borgeltiapriori 31 C Borgelt and R Kruse Induction of Association Rules Apriori Implementation Proc 14th Con on Computational Statistics \(COMPSTATJ Berlin Germany 2002 4 R.D Clark Relative and Absolute Diversity Analysis of Combinatorial Libraries Combinatorial Library Design and Evaluation 337-362 Dekker New York NY USA 2001 SI M Desphande M Kuramochi and G Karypis Automated Approaches for Classifying Structures Proc Workhop on Doto Mining in Bioinformatics BioKDD 11-18,2002 6 1 Hipp A Myka, R Wirth and U Giintzer A New Algo rithm for Faster Mining of Generalized Association Rules Proc 2nd Europ Symp on Principles of Data Mining and Knowledge Discovery fPKDD.98 Names France 74-82 LNAl 1510 Springer, Heidelberg Germany 1998 17 S Kramer L de Raedt and C Helma Molecular Feature Mining in HIV Data Pmc 7th In Cu.!f on Knowledge Dis covery and Data Mining fKDD-2JO Son Francisco CA 136-143 ACM Press New York NY USA 2001  C Borgelt 8 http:lldlp.nci.nih.gov/doc~aids/aid~.dat~.ht~l 191 I W Raymond E I Gardiner and P Willett. Heuristics for Similarity Searching of Chemical Graphs using a Maximum Common Edge Subgraph Algorithm Journal of Chemical Information ond Computer Sciences 42\(2 Amer ican Chemical Society Columbus, OH USA 2002 IO W J Streich and R Franke Topological Phmacophores New Methods and Their Application to a Set of Anti malarials Parl 1 The Methods LOGANA and LOCON Quant Strct.-Act Relat.,4:13-18 I Wiley  Sons.Chich ester United Kingdom 1985 Ill 0 Weislow R Kiser D Fine J Bader R Shoemaker and M Boyd New Soluble Formazan Assay for HIV-I Cytopathic Effects Application to High Flux Screening of Synthetic and Natural Products for AIDS Antiviral Activity Journal of the Notional Cancer Institute 81577-586 Ox ford University Press Oxford United Kingdom 1989 1121 M Zaki S Panhasarathy M Ogihara and W Li New Al gorithms for Fast Discovery of Association Rules Proc 3rd Inr Con on Knon,ledge Discovery and Data Mining KDD\22297J 283-296 AAA1 Press Menlo Park, CA USA 1997 58 


   0 100 200 300 400 500 600 700 800 65 70 75 80 85 90 95 100 Confidence threshold Execution time \(sec    0 100 200 300 400 500 600 700 800 65 70 75 80 85 90 95 100 Similarity threshold Execution time \(sec Wlog WlogP plinkF plinkT News dicD   0 50 100 150 200 65 70 75 80 85 90 95 100 Confidence Threshold Memory \(MB    0 50 100 150 200 65 70 75 80 85 90 95 100 Similarity Threshold Memory \(MB Wlog WlogP plinkF plinkT News dicD a b g h   e plinkT 0 100 200 300 400 500 600 700 65 70 75 80 85 90 95 100 Confidence threshold Time \(sec   c Wlog 0 100 200 300 400 500 600 700 65 70 75 80 85 90 95 100 Confidence threshold Time \(sec   f plinkT 0 100 200 300 400 500 600 700 65 70 75 80 85 90 95 100 Similarity threshold Time \(sec     d Wlog 0 100 200 300 400 500 600 700 65 70 75 80 85 90 95 100 Similarity threshold Time \(sec 100-bitmap 100%-base 100%-bitmap 100%-base Pre-scaning    i NewsP 0 50 100 150 200 65 70 75 80 85 90 95 100 Confidence threshold Time \(sec DMC-imp a-priori K-Min    j NewsP 0 50 100 150 200 65 70 75 80 85 90 95 100 Similarity threshold Time \(sec DMC-sim a-priori Min-Hash Figure 6 Experimental results 


polgar -> international polgar -> old polgar -> judit polgar -> champion polgar -> youngest polgar -> chess polgar -> kasparov polgar -> men polgar -> highest polgar -> top polgar -> soviet polgar -> players polgar -> federation polgar -> player polgar -> ranked polgar -> grandmaster polgar -> garri  j udit -> soviet j udit -> hungary kasparov -> chess kasparov -> game kasparov -> champion grandmaster -> soviet grandmaster -> champion grandmaster -> chess garri -> chess garri -> kasparov garri -> soviet garri -> championship garri -> champion Figure 7 Sample rules the memory optimization techniques for DMC and MinHash will not improve their performance signi\002cantly Fig 6\(i and j show the execution times of these algorithms The K-Min algorithm is a variant algorithm of Min-Hash  which can extract implication rules instead of similarity rules However it could not extract complete sets of true rules therefore we plotted the execution time when the number of false negatives was less than 10 The other algorithms including Min-Hash for 002nding similarity rules could extract complete sets of true rules In this experiment a-priori is best for 002nding implication rules with 75%-or-less con\002dence threshold and Min-Hash is best for 002nding similarity rules with 70%or-less similarity threshold respectively However the DMC algorithms are best for 002nding both implication and similarity rules with high threshold 6.3 Extracted rules Text-mining by using extracted implication rules with low-support pruning is one of the interesting applications for our algorithms Fig 7 shows sample rules we extracted from News with an 85 con\002dence threshold and with a support pruning less than 5 These rules are extracted by selecting all rules related to keyword Polgar and its successors recursively This set of rules indicates information about Miss Judit Polgar who is 12-years-old has been ranked No 1 in the women's world chess 7 Conclusion and future works We presented two new algorithms DMC-imp and DMCsim  for 002nding implication and similarity rules Our algorithms do not use support pruning but use con\002dence or similarity pruning which reduces the memory size signi\002cantly We also proposed the other pruning techniques row re-ordering  100%-rule pruning  columndensity pruning and maximum-hits pruning  In order to evaluate the performance of the algorithms we used 4 sets of data Web-access logs Web-page-link graph news documents and a dictionary The algorithms have been implemented on a Sun Ultra 2  2 002 200 MHz 256MB memory workstation According to the experimental results our algorithms can be executed in a reasonable time The algorithms that proposed previously can not execute on our data sets since the algorithms required more than 256MB memory Therefore we compared performance by using the News data sets by pruning by using support threshold 35 so that all counters for a-priori can 002t in main memory The comparison results shows that DMC-imp can execute 1.7 times faster than a-priori  and 1.9 times faster than K-Min  and that DMC-sim can execute 5.9 times faster than apriori  and 1.7 times faster than Min-Hash  in case of an 85 threshold The followings are future research topics 017 Our algorithm can not extract rules among more than two columns while a-priori can do so However by grouping similarity and implication rules as showed in Sec 6.3 we can get useful groups of rules among more than two columns This idea can be applied to other data sets which generates more interesting rules 017 The memory requirement for News with less than 80 con\002dence threshold exceeds 256MB To be scalable this algorithm a parallel algorithm based on a divideand-conquer technique such as FDM 6 f or a-priori  is necessary References 1 R  A g r a w al T  I mielin sk i an d A  S w a mi M in in g Association Rules Between Sets of Items in Large Databases In Proceedings of the ACM SIGMOD Conference on Management of Data 1993 pp 207\226 216  R  A gra w al and R  S ri kant  F as t A l gori t h ms for Mining Association Rules In Proceedings of the 20th 


International Conference on Very Large Databases 1994  R  J  B ayardo J r  R  A gra w al and D  G unopul os  Constraint-Based Rule Mining in Large Dense Databases In Proceedings of the 15th International Conference on Data Engineering 1999 pp 188\226197 4 S  B rin  R Mo tw an i J.D Ullman  a n d S Tsu r  Dynamic itemset counting and implication rules for market basket data In Proceedings of the ACM SIGMOD Conference on Management of Data 1997 pp 255\226264  A  B roder  On the r esemblance and c ontainment of documents In Compression and Complexity of Sequences SEQUENCES'97  1998 pp 21\22629  D  W  C heung J  H a n V  T  N g  e t a l  A Fast Distributed Algorithm for Mining Association Rules In Proceedings of Conference on Parallel and Distributed Information Systems 1996 pp 31\22642 7 E  C o h e n  Size-Estimatio n F rame w o rk with Applications to Transitive Closure and Reachability Journal of Computer and System Sciences 55 1997 441\226453 8 E  C o h e n  M Datar  S Fu jiw ara A Gio n i s et al Finding Interesting Associations without Support Pruning In Proceedings of the 16th International Conference on Data Engineering  2000  R O D uda and P E H art Pattern Classi\002cation and Scene Analysis  A Wiley-Interscience Publication New York 1973  A  G i oni s  P  Indyk and R  M ot w a ni  S i m i l a ri t y Search in High Dimensions via Hashing In Proceedings of the 25th International Conference on Very Large Databases 1999 11 D Go ld b e r g  D  Nich o l s B.M Ok i an d D  T erry  Using collaborative 002ltering to weave an information tapestry Communications of the ACM 55 1991 1\226 19  S  G uha R  R as t ogi  a nd K  S h i m  C U R E A n Ef\002cient Clustering Algorithm for Large Databases In Proceedings of the ACM-SIGMOD International Conference on Management of Data 1998 pp 73\22684  R  Mot w ani a nd P  R a gha v a n Randomized Algorithms Cambridge University Press 1995  J  S  P a rk M S  C hen and P S  Y u A n ef fect i v e hash-based algorithm for mining association rules In Proceedings of the ACM SIGMOD Conference on Management of Data 1995 pp 175\226186  P r oj ect G u t e nber g  http:..www.gutenberg.net  1999  N Shi v akumar and H  G arcia-Molina B u ilding a Scalable and Accurate Copy Detection Mechanism In Proceedings of the 3rd International Conference on the Theory and Practice of Digital Libraries  1996  H.R  V a rian and P  R esnick E ds C A C M S pecial Issue on Recommender Systems Communications of the ACM 40 1997 


User Anomaly Description programmer2 logs in from beta secretary logs in at night sysadm logs in from jupiter programmer1 becomes a secretary secretary becomes a manager programmer1 logs in at night sysadm becomes a programmer manager1 becomes a sysadm manager2 logs in from pluto Table 12 User Anomaly Description User Normal Anomaly programmer2 0.58 0.79 0.00 secretary  1  1  0.00 sysadm 0.84 0.95 0.00 programmer1 0.31 1.00 0.04 secretary 0.41 0.98 0.17 programmer1  1  1  0.00 sysadm 0.64 0.95 0.00 manager1 0.57 1.00 0.00 manager2 1.00 1.00 0.00 Table 13 Similarity with User's Own Pro\002le tivities of each time segment am pm and nt We treat the 5th week as the training period during which we compare the patterns from each session to the pro\002le of the time segment We record the normal range of the similarity scores during this week The data in the 6th week has some user anomalies as described in Table 12 For each of the anomalous sessions we compare its patterns against the original user's pro\002le and then compare the resulting similarity score against the recorded normal range of the same time segment In Table 13 the column labeled 223Normal\224 is the range of similarity of each user against his or her own pro\002le as recorded during the 5th week A 1 here means that the user did not login during the time segment in the 5th week The column 223Anomaly\224 is the similarity measure of the anomalous session described Table 12 We see that all anomalous sessions can be clearly detected since their similarity scores are much smaller than the normal range For example when the sysadm becomes programmer see Table 12 his/her patterns have zero matches with the sysadm's pro\002le while for the whole 5th week the pm similarity scores are in the range of 0.64 to 0.95 Unfortunately formal evaluation statistics are not available to determine the error rates of this approach However this initial test indicates a path worthy of future study 6 Related Work Network intrusion detection has been an on-going research area 17  M ore r ecent s ystems e g B ro 18   NFR 6  a n d EMERALD  1 9  a ll mad e e x ten s ib ility th eir primary design goals Our research focuses on automatic methods for constructing intrusion detection models The meta-learning mechanism is designed to automate the extention process of IDSs We share the same views discussed in 20 t h at an ID S s houl d b e b ui l t us i n g s t a ndard components We believe that the operating system and networking community should be responsible for building a robust 223Event\224 box In 10  a l gori t h ms for a nal y zi ng us er s h el l c ommands and detecting anomalies were discussed The basic idea is to 002rst collapse the multi-column shell commands into a single stream of strings and then string matching techniques and consideration of 223concept drift\224 are used to build and update user pro\002les We believe that our extended frequent episodes algorithm is a superior approach because it considers both the association among commands and arguments and the frequent sequential patterns of such associations 7 Conclusions and Future Directions In this paper we outline a data mining framework for constructing intrusion detection models The key idea is to apply data mining programs to audit data to compute misuse and anomaly detection models according to the observed behavior in the data To facilitate adaptability and extensibility we propose the use of meta-learning as a means to construct a combined model that incorporate evidence from multiple lightweight base models This mechanism makes it feasible to introduce new ID components in an existing IDS possibly without signi\002cant re-engineering We extend the basic association rules and frequent episodes algorithms to accommodate the special requirements in analyzing audit data Our experiments show that the frequent patterns mined from audit data can be used as reliable user anomaly detection models and as guidelines for selecting temporal statistical features to build effective classi\002cation models Results from the 1998 DARPA Intrusion Detection Evaluation Program showed our detection models performed as well as the best systems built using the manual knowledge engineering approaches Our future work includes developing network anomaly detection strategies and devising a mechanical procedure to translate our automatically learned detection rules into modules for real-time IDSs A preliminary project in collaboration with NFR has just started 12 


8 Acknowledgments We wish to thank our colleagues at Columbia University Chris Park Wei Fan and Andreas Prodromidis for their help and encouragement References 1 R  A g r a w a l  T  I m i e lin sk i a n d A  S w a m i  M in in g a sso c i a tion rules between sets of items in large databases In Proceedings of the ACM SIGMOD Conference on Management of Data  pages 207\226216 1993 2 P  K  C han a nd S  J S t ol f o  T o w ar d p ar al l e l a nd di st r i b u t e d learning by meta-learning In AAAI Workshop in Knowledge Discovery in Databases  pages 227\226240 1993 3 W  W  C ohen Fast ef f ect i v e r ul e i nduct i on I n Machine Learning the 12th International Conference  Lake Taho CA 1995 Morgan Kaufmann 4 U  F ayyad G P i at et sk yS h api r o and P  S myt h  T he KDD process of extracting useful knowledge from volumes of data Communications of the ACM  39\(11\:27\22634 November 1996 5 K  I l gun R  A K e mmer e r  and P  A  P or r a s S t at e t r a nsition analysis A rule-based intrusion detection approach IEEE Transactions on Software Engineering  21\(3\:181\226 199 March 1995 6 N  F  R  I n c  N etw o rk 003ig h t reco rd er  h ttp www n fr co m  1997 7 V  J acobson C  L e r e s and S  M cC anne t cpdump a v ai l a bl e via anonymous ftp to ftp.ee.lbl.gov June 1989 8 C  K o  G Fin k  a n d K  L e v itt Au to m a te d d e t e c tio n o f v u l nerabilities in privileged programs by execution monitoring In Proceedings of the 10th Annual Computer Security Applications Conference  pages 134\226144 December 1994 9 S  K umar and E  H  S paf f or d A s of t w ar e a r c hi t ect ur e t o support misuse intrusion detection In Proceedings of the 18th National Information Security Conference  pages 194\226 204 1995  T  L a ne and C  E  B r odl e y  S equence m at chi n g a nd l ear ni ng in anomaly detection for computer security In AAAI Workshop AI Approaches to Fraud Detection and Risk Management  pages 43\22649 AAAI Press July 1997  W  L e e a nd S  J S t ol f o  D at a m i n i n g a ppr oaches f o r i nt r u sion detection In Proceedings of the 7th USENIX Security Symposium  San Antonio TX January 1998  W  L ee S  J S t ol f o  a nd K W  Mok Mi ni ng i n a d at a\003 o w environment Experience in intrusion detection submitted for publication March 1999  T  L unt  D et ect i n g i nt r uder s i n comput er syst ems I n Proceedings of the 1993 Conference on Auditing and Computer Technology  1993  T  L unt  A  T amar u F  Gi l h am R  J agannat h an P  N eumann H Javitz A Valdes and T Garvey A real-time intrusion detection expert system IDES 002nal technical report Technical report Computer Science Laboratory SRI International Menlo Park California February 1992  H Manni l a and H  T oi v onen Di sco v e r i ng gener a l i zed episodes using minimal occurrences In Proceedings of the 2nd International Conference on Knowledge Discovery in Databases and Data Mining  Portland Oregon August 1996  H Manni l a  H  T oi v onen and A  I  V er kamo D i s co vering frequent episodes in sequences In Proceedings of the 1st International Conference on Knowledge Discovery in Databases and Data Mining  Montreal Canada August 1995  B M ukherjee L T  Heberlein and K  N  L e v itt Netw ork intrusion detection IEEE Network  May/June 1994  V  Paxon B r o  A syst em f o r d et ect i n g n et w o r k i n t r uder s in real-time In Proceedings of the 7th USENIX Security Symposium  San Antonio TX 1998  P  A P o r r a s a nd P  G Neumann E m er al d E v ent m oni t o r i ng enabling responses to anomalous live disturbances In National Information Systems Security Conference  Baltimore MD October 1997  S  S t ai nf or dC h en C ommon i nt r u si on det ect i o n f r a me w o r k  http://seclab.cs.ucdavis.edu/cidf  S  J S t ol f o  A  L  P r odr omi d i s  S  T sel e pi s W  L ee D W  Fan and P K Chan JAM Java agents for meta-learning over distributed databases In Proceedings of the 3rd International Conference on Knowledge Discovery and Data Mining  pages 74\22681 Newport Beach CA August 1997 AAAI Press  S unS of t  Mount ai n V i e w  C A  SunSHIELD Basic Security Module Guide  13 


 30 40 50 60 70 80 90 100 110 120 30 40 50 60 70 80 90 10 0 Execution Time [s Number of Nodes Figure 13 Execution time of HPA program pass 2 on PC cluster 2 Scan the transaction database and count the support count Each processing node reads the transaction database from its local disk 000 itemsets are generated from that transaction and the same hash function used in phase 1 s applied to each of them Each of the 000 itemsets is sent to certain processing node according the hash value For the itemsets received from the other nodes and those locally generated whose ID equals the node\220s ID the hash table is searched If hit its support count value is incremented 3 Determine the large itemset After reading all the transaction data each processing node can individually determine whether each candidate 000 itemset satisfy user-specified minimum support or not Each processing node sends large 000 itemsets to the coordinator where all the large 000 itemsets are gathered 4 Check the terminal condition If the large 000 itemsets are empty the algorithm terminates Otherwise the coordinator broadcasts large 000 itemsets to all the processing nodes and the algorithm enters the next iteration 4.2 Performance evaluation of HPA algorithm The HPA program explained above is implemented on our PC cluster Each node of the cluster has a transaction data file on its own hard disk Transaction data is produced using data generation program developed by Agrawal designating some parameters such as the number of transaction the number of different items and so on The produced data is divided by the number of nodes and copied to each node\220s hard disk The parameters used in the evaluation is as follows The number of transaction is 5,000,000 the number of different items is 5000 and minimum support is 0.7 The size of the data is about 400MBytes in total The message block size is set to be 16KBytes according to the results of communication characteristics of PC clusters discussed in previous section The disk I/O block size is 64KBytes which seems to be most suitable value for the system Note that the number of candidate itemset in pass 2 s substantially larger than for the other passes which relatively frequently occurs in association rules mining Therefore we have been careful to parallelize the program effectively especially in pass 2 so that unnecessary itemsets to count should not be generated 14 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


The execution time of the HPA program pass 2 is shown in figure 13 as the number of PCs is changed The maximum number of PCs used in this evaluation is 100 Reasonably good speedup is achieved in this application as the number of PCs is increased 5 Conclusion In this paper we presented performance evaluation of parallel database processing on an ATM connected 100 node PC cluster system The latest PCs enabled us to obtain over 110Mbps throughput in point-to-point communication on a 155Mbps ATM network even with the so-called 217\217heavy\220\220 TCP/IP This greatly helped in developing the system in a short period since we were absorbed in fixing many other problems Massively parallel computers now tend to be used in business applications as well as the conventional scientific computation Two major business applications decision support query processing and data mining were picked up and executed on the PC cluster The query processing environment was built using the results of our previous research the super database computer SDC project Performace evaluation results with a query of the standard TPC-D benchmark showed that our system achieved superior performance especially when transposed file organization was employed As for data mining we developed a parallel algorithm for mining association rules and implemented it on the PC cluster By utilizing aggregate memory of the system efficiently the system showed good speedup characteristics as the number of nodes increased The good price/performance ratio makes PC clusters very attractive and promising for parallel database processing applications All these facts support the effectiveness of the commodity PC based massively parallel database servers Acknowledgment This project is supported by NEDO New Energy and Industrial Technology Development Organization in Japan Hitachi Ltd technically helped us extensively for ATM related issues References  R Agrawal T Imielinski and A Swami Mining association rules between sets of items in large databases In Proceedings of ACM SIGMOD International Conference on Management of Data  pages 207--216 1993  R Agrawal and R Srikant Fast algorithms for mining association rules In Proceedings of International Conference on Very Large Data Bases  1994  A C Arpaci-Dusseau R H Arpaci-Dusseau D E Culler J M Hellerstein and D A Patterson High-performance sorting on Networks of Workstations In Proceedings of International Conference on Management of Data  pages 243--254 1997  D.S Batory On searching transposed files ACM TODS  4\(4 1979  P.A Boncz W Quak and M.L Kersten Monet and its geographical extensions A novel approach to high performance GIS processing In Proceedings of International Conference on Extending Database Technology  pages 147--166 1996 15 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


 R Carter and J Laroco Commodity clusters Performance comparison between PC\220s and workstations In Proceedings of IEEE International Symposium on High Performance Distributed Computing  pages 292--304 1995  D.J DeWitt and J Gray Parallel database systems  The future of high performance database systems Communications of the ACM  35\(6 1992  J Gray editor The Benchmark Handbook for Database and Transaction Processing Systems  Morgan Kaufmann Publishers 2nd edition 1993  J Heinanen Multiprotocol encapsulation over ATM adaptation layer 5 Technical Report RFC1483 1993  M Kitsuregawa M Nakano and M Takagi Query execution for large relations on Functional Disk System In Proceedings of International Conference on Data Engineering  5th pages 159--167 IEEE 1989  M Kitsuregawa and Y Ogawa Bucket Spreading Parallel Hash:A new parallel hash join method with robustness for data skew in Super Database Computer SDC In Proceedings of International Conference on Very Large Data Bases  16th pages 210--221 1990  M Laubach Classical IP and ARP over ATM Technical Report RFC1577 1994  D.A Schneider and D.J DeWitt Tradeoffs in processing complex join queries via hashing in multiprocessor database machines In Proceedings of International Conference on Very Large Data Bases  16th pages 469--480 1990  T Shintani and M Kitsuregawa Hash based parallel algorithms for mining association rules In Proceedings of IEEE International Conference on Parallel and Distributed Information Systems  pages 19--30 1996  T Sterling D Saverese D.J Becker B Fryxell and K Olson Communication overhead for space science applications on the Beowulf parallel workstaion In Proceedings of International Symposium on High Performance Distributed Computing  pages 23--30 1995  T Tamura M Nakamura M Kitsuregawa and Y Ogawa Implementation and performance evaluation of the parallel relational database server SDC-II In Proceedings of International Conference on Parallel Processing  25th pages I--212--I--221 1996  TPC TPC Benchmark 000\001 D Decision Support Standard Specification Revision 1.1 Transaction Processing Performance Council 1995 16 Proceedings of the ACM/IEEE SC97 Conference \(SC\22297 0-89791-985-8/97 $ 17.00 \251 1997 IEEE 


In accordance with 1910.97 and 1910.209 warning signs are required in microwave areas For work involving power line carrier systems this work is to be conducted according to requirements for work on energized lines Comments s APPA objects to the absolute requirement implied by the word ensure regarding exposure to microwave radiation and recommends revision of s l iii to read when an employee works in an area where electromagnetic radiation levels could exceed the levels specified in the radiation protection guide the employer shall institute measures designed to protect employees from accidental exposure to radiation levels greater than those permitted by that guide  I1 an employee must be stationed at the remote end of the rodding operation Before moving an energized cable it must be inspected for defects which might lead to a fault To prevent accidents from working on the wrong cable would require identification of the correct cable when multiple cables are present Would prohibit an employee from working in a manhole with an energized cable with a defect that could lead to a fault However if the cable cannot be deenergized while another cable is out employees may enter the manhole but must protect against failure by some means for example using a ballistics blanket wrapped around cable Requires bonding around opening in metal sheath while working on cable Underaround EIectrical Installations t Comments t This paragraph addresses safety for underground vaults and manholes The following requirements are contained in this section Ladders must be used in manholes and vaults greater than four feet deep and climbing on cables and hangers in these vaults is prohibited Equipment used to lower materials and tools in manholes must be capable of supporting the weight and should be checked for defects before use An employee in a manhole must have an attendant in the immediate vicinity with facilities greater than 250 volts energized An employee working alone is permitted to enter briefly for inspection housekeeping taking readings or similar assuming work could be done safely Duct rods must be inserted in the direction presenting the least hazard to employees and APPA recommends that OSHA rewrite section 7\regarding working with defective cables This rewrite would include the words shall be given a thorough inspection and a determination made as to whether they represent a hazard to personnel or representative of an impending fault As in Subsection \(e EEI proposes the addition of wording to cover training of employees in emergency rescue procedures and for providing and maintaining rescue equipment Substations U This paragraph covers work performed in substations and contains the following requirements Requires that enough space be provided around electrical equipment to allow ready and safe access for operation and maintenance of equipment OSHA's position A2-16 


is that this requirement is sufficiently performance oriented to meet the requirements for old installations according to the 1987 NEW Requires draw-out circuit breakers to be inserted and removed while in the open position and that if the design permits the control circuits be rendered inoperative while breakers are being inserted and removed stated in the Rules and requests that existing installations not be required to be modified to meet NESC APPA recommends that Section u 4 i which includes requirements for enclosing electric conductors and equipment to minimize unauthorized access to such equipment be modified to refer to only those areas which are accessible to the public Requires conductive fences around substations to be grounded Power Generation v Addresses guarding of energized parts  Fences screens, partitions or walls This section provides additional requirements and related work practices for power generating plants  Entrances locked or attended Special Conditions w  Warning signs posted  Live parts greater than 150 volts to be guarded or isolated by location or be insulated  Enclosures are to be according to the 1987 NESC Sections llOA and 124A1 and in 1993 NESC  Requires guarding of live parts except during an operation and maintenance function when guards are removed barriers must be installed to prevent employees in the area from contacting exposed live parts Requires employees who do not work regularly at the substation to report their presence Requires information to be communicated to employees during job briefings in accordance with Section \(c of the Rules Comments U APPA and EEI provide comments as follows Both believe that some older substations \(and power plants would not meet NESC as This paragraph proposes special conditions that are encountered during electric power generation, transmission and distribution work including the following Capacitors  Requires individual units in a rack to be short circuited and the rack grounded  Require lines with capacitors connected to be short circuited before being considered deenergized Current transformer secondaries may not be opened while energized and must be bridged if the CT circuit is opened Series street lighting circuits with open circuit voltages greater than 600 volts must be worked in accordance with Section q\or t and the series loop may be opened only after the source transformer is deenergized and isolated or after the loop is bridged to avoid open circuit condition Sufficient artificial light must be provided where insufficient naturals illumination is present to enable employee to work safely A2-17 


US Coast Guard approved personal floatation devices must be supplied and inspected where employees are engaged in work where there is danger of drowning Required employee protection in public work areas to include the following  Warning signs or flags and other traffic control devices  Barricades for additional protection to employees  Barricades around excavated areas  Warning lights at night prominently displayed Lines or equipment which may be sub to backfeed from cogeneration or other sources are to be worked as energized in accordance with the applicable paragraphs of the Rules Comments w APPA submits the following comments regarding this Special Conditions section Recommends that the wording regarding capacitors be modified to include a waiting period for five minutes prior to short circuiting and grounding in accordance with industry standards for discharging of capacitors For series street light circuits, recommends that language be added for bridging to either install a bypass conductor or by placement of grounds so that work occurs between the grounds Recommends modification of the section regarding personal floatation devices to not apply to work sites near fountains decorative ponds swimming pools or other bodies of water on residential and commercial property Definitions x This section of the proposed Rules includes definitions of terms Definitions particularly pertinent to understanding the proposal and which have not previously been included are listed as follows Authorized Employee  an employee to whom the authority and responsibility to perform a specific assignment has been given by the employer who can demonstrate by experience or training the ability to recognize potentially hazardous energy and its potential impact on the work place conditions and who has the knowledge to implement adequate methods and means for the control and isolation of such energy CZearance for Work  Authorization to perform specified work or permission to enter a restricted area Clearance from Hazard  Separation from energized lines or equipment Comments x The following summarizes the changes in some of the definitions which APPA recommends Add to the definition for authorized employee It the authorized employee may be an employee assigned to perform the work or assigned to provide the energy control and isolation function  Recommends that OSHA modify the definition for a line clearance tree trimmer to add the word qualified resulting in the complete designation as a qualified line clearance tree trimmer Recommends that OSHA modify the definition of qualified employee" to remove the word construction from the definition since it is felt that knowledge of construction procedures is beyond the scope of the proposed rule resulting in APPA's new A2-18 I 


wording as follows more knowledgeable in operation and hazards associated with electric power generation transmission and/or distribution equipment Recommends that OSHA add a definition for the word practicable and replace the word feasible with practicable wherever it appears in the proposed regulations and that practicable be further defined as capable of being accomplished by reasonably available and economic means OTHER ISSUES Clothing OSHA requested comments on the advisability of adopting requirements regarding the clothing worn by electric utility industry employees EEI has presented comments which indicates research is underway prior to establishing a standard for clothing to be worn by electric utility employees However EEI's position is that this standard has not developed to the extent that it could be included in the OSHA Rules Both APPA and EEI state that they would support a requirement that employers train employees regarding the proper type of clothing to wear to minimize hazards when working in the vicinity of exposed energized facilities Grandfathering Due to the anticipated cost impact on the utility industry of the proposed Rules requiring that existing installations be brought to the requirements of the proposed Rules both APPA and EEI propose that the final Rules include an omnibus grandfather provision This provision would exempt those selected types of facilities from modification to meet the new rules EEI states that if the grandfathering concept is incorporated that electric utility employees will not be deprived of proper protection They propose that employers be required to provide employees with a level of protection equivalent to that which the standard would require in those instances in which the utility does not choose to modify existing facilities to comply with the final standard Rubber Sleeves OSHA requests comments from the industry on whether it would be advisable to require rubber insulating sleeves when gloves are used on lines or equipment energized at more than a given voltage EEI states its position that utilities should continue to have the option of choosing rubber gloves or gloves and sleeves to protect employees when it is necessary to work closer to energized lines than the distances specified in the clearance tables Preemuting State Laws EEI requests that the final Rules be clear in their preempting state rules applicable to the operation and maintenance work rules for electric power systems. This is especially critical since some states now have existing laws which are more stringent than the proposed OSHA Rules Examples are 1 in California and Pennsylvania where electric utility linemen are prohibited from using rubber gloves to work on lines and equipment energized at more than certain voltages and 2 in California and Connecticut where the live line bare hand method of working on high voltage transmission systems is prohibited One utility Pacific Gas  Electric has obtained a variance from the California OSHA to perform live line bare-hand transmission maintenance work on an experimental basis Coiiflicts Between the Rilles and Part 1926 Subpart V Since many of the work procedures in construction work and operation and maintenance work are similar and difficult to distinguish between EEI requests that the final order be clear in establishing which rule has jurisdiction over such similar work areas A2-19 v 


IMPACTS ON COSTS AND ASSOCIATED BENEFITS In its introduction to the proposed rules OSHA has provided an estimate of the annual cost impact on the electric utility industry for the proposed des of approximately 20.7 million OSHA estimates that compliance with this proposed standard would annually prevent between 24 and 28 fatalities and 2,175 injuries per year The utilities which have responded to this proposed standard through their respective associations have questioned the claims both of the magnitude of the cost involved and the benefit to the industry in preventing fatalities and lost-time injuries Both EEI and APPA feel that the annual cost which OSHA estimates are significantly lower than would be realized in practice Factors which APPA and EEI feel were not properly addressed include the following OSHA has not accurately accounted for cost of potential retroactive impacts including retrofitting and modifying existing installations and equipment OSHA has not consistently implemented performance based provisions in proposed rules  many portions require specific approaches which would require utilities to replace procedures already in place with new procedures Estimates were based on an average size investor-owned utility of 2,800 employees and an average rural cooperative of 56 employees, which are not applicable to many smaller systems such as municipal systems OSHA has not adequately addressed the retraining which would be necessary with modifying long-established industry practices to be in accordance with the OSHA rules EEI claims that OSHA's proposed clearance requirements would not allow the use of established maintenance techniques for maintaining high voltage transmission systems and thus would require new techniques For an example of the cost which is estimated to be experienced as a result of the new Rules one of the EEI member companies has estimated that approximately 20,000 transmission towers would need to be modified to accommodate the required step bolts in the Rules at an estimated cost of 6,200,000 Additionally this same company estimates that the annual cost of retesting live line tools for its estimated 1,000 tools would be 265,000 Additionally, both EEI and APPA question the additional benefits which OSHA claims would result from implementation of the new Rules APPA questions the estimates of preventing an additional 24 to 28 fatalities annually and 2,175 injuries per year in that it fails to account for the fact that the industry has already implemented in large part safety measures which are incorporated in the Rules EEI and APPA also point out that many preventable injuries cannot be eliminated despite work rules enforcement and safety awareness campaigns since many such accidents which result in fatalities are due to employee being trained but not following the employer's training and policies PRESENT STATUS OF RULES According to information received from the OSHA office in February 1993 the final Rules are to be published no later than July 1993 and possibly as soon as March 1993 OSHA closed their receipt of comments in March 1991 and no further changes in the rules are thought possible A2-20 


CONCLUSION The OSHA 1910.269 which proposes to cover electric utility operation and maintenance work rules affects a multitude of working procedures as are summarized in this paper It is not possible at the present time to assess the final structure of the Rules as may be proposed in 1993 or subsequent years Since the comments from the utility associations APPA and EEI were made following the initial release of the proposed OSHA Rules in 1989 a significant amount of time has elapsed where other events have occurred which may affect the form of the final Rules The 1993 NESC went into effect in August 1992 and includes some of the requirements to which the commenters objected For example a significant requirement in the Part 4 of the 1993 NESC requires that rubber gloves be utilized on exposed energized parts of facilities operating at 50 to 300 volts This requirement is in conflict with EEl\222s proposed change to the OSHA Rules which would still allow working such secondary facilities without the use of rubber gloves Electric utilities are advised to review the January 31 1989 proposed operation and maintenance Rules as summarized in this paper and to review their procedures which would be affected by application of the Rules Many of the procedures proposed in the Rules provide valuable guidance in electric utilities\222 operation and maintenance activities Where the cost impact is not significant, it is recommended that utilities consider implementing such procedures in expectation of the Rules being published in the next few months Also it would be appropriate for electric utilities to review the 1993 edition of the NESC since there are portions of the Rules which have resulted in changes in the NESC These changes mainly occur in Part 4 Rules for the Operation of Electric Supply and Communications Lines and Equipment The concerns which the commenters have addressed regarding the cost impact and the resulting benefits experienced as a result of the promulgation of the Rules are real ones and must be addressed in the final Rules As a result this paper cannot present a conclusion regarding the full impact of the Rules The development of such Rules continue to be an ongoing matter and will undoubtedly require later analysis when the final rules are published A2-21 



Mining Market Value Functions for Targeted Marketing Y.Y Yao Department of Computer Science University of Regina Regina, Saskatchewan, Canada S4S OA2 yyao@cs.uregina.ca Abstract Targeted marketing typically involves the ident$cation of customers or products having potential market values We propose a linear model for solving this problem by draw ing and extending results from information retrieval It is assumed that each object is represented by values of aJinite set of attributes A market value function which is a linear combination of utility functions on attribute values, is 
used to rank objects Several methods are examined for mining market value functions The main advantage of the model is that one can rank objects of interest according to their market values instead of classifying the objects The the oretical results reported in this paper establish a basis on which further studies and experimental evaluation can be carried out 1 Introduction The problem of targeted marketing typically involves the identification of customers or products having poten tial market values It is an important area of applications for data mining 
6 Standard data mining techniques may be applied for the purpose of targeted marketing For ex ample one may use association rules mined from a large transaction dataset for targeted marketing  11 If a strong association between two sets of items A and B is observed i.e a customer buying A tends to buy B it may be bene ficial to send advertisement of B or recommend items B to customers buying A In fact 
using association rule to promote related products is a common practice of targeted marketing Consider now another type of targeted marketing prob lem. Suppose there is a health club that needs to expand its operation by attracting more members Assume that each existing member is described by a finite set of attributes It is natural to examine existing members in order to iden tify their common features Information about the health Ning Zhong Department of Information Engineering Maebashi Institute of Technology Maebashi-City 371-08 16 Japan zhong @maebashi-it.ac.jp club may be sent to non-members who share 
the same fea tures of members or similar to members Other examples include promotion of special types of phone services and marketing of different classes of credit cards In this case we explore the relationships similarities between people objects based on their attribute values The underlying assumption is that similar type of people tend to make sim ilar decisions and to choose similar services Techniques for mining association rules may not be directly applicable to this type of targeted marketing Other techniques from machine learning and data 
mining such as learning char acteristic rules classification rules, discriminant rules, and peculiarity rules may be applied 3 8 20 21 221 The mined rules characterizing members can be used to decide if a non-member is likely to join the club and thus war rant sending soliciting materials However there may be some difficulties with these techniques One may produce too many or too few rules The selection of a good set of rules may not be an easy task Furthermore the use of the derived rules may produce too many or too 
few potential new members In this paper we present an alternative solution for the above targeted marketing problem by extending results from information retrieval  12 131 The main task of an in formation retrieval system is to identify useful information items The ideas developed for information retrieval can be used to identify objects having potential market value In contract to commonly used data mining approaches for dis covering rules one may attempt to discover market value functions or discriminant functions For the health club example a market value function measures the degree to 
which a potential new member is similar to a typical exist ing member The idea is very similar to cased-based reason ing SI Existing members are considered as cases against which potential members are compared Based on the val ues of the market value function one may rank all potential members according to their likelihood of joining the club A cut-off point of the ranked list may be chosen based on var ious criteria such as financial constraints To some extent 0-7695-1372-7/01 $10.00 0 2001 IEEE 517 


the use of market value function resolves some of the dif ficulties with rule-based approaches. Moreover, the market value function can be easily updated when new information is available Some of the advantages of the proposed method are sum marized below The parlicular targeted marketing problem is formulated as a modified classical information retrieval problem Many results from information retrieval can be immediately applied The use of market value functions en ables us to produce a ranked list, which may provide more flexibilities in some targeted marketing problems A clear interpretation of the linear market value functions is pre sented. Practical estimation methods for the needed param eters are suggested. Results \(feedback\from earlier targeted marketing may also be used to modify the market value function The rest of the paper is organized as follows In Sec tion 2 we formally state the problem and investigate the form and interpretation of the proposed market value func tion A market value function is a linear \(weighted com bination of a set of utility functions, one for each attribute Each attribute is considered to be one piece of information and the utility of a particular attribute value states the con tribution made by that attribute The weight of an attribute represents its relative importance The market value func tion therefore provides it weighted summation of contribu tion In Section 3 we discuss the problem of estimating utility functions and weights of attributes The utility of an attribute value is determined by the number of existing members having the value The weight of an attribute de pends on the distribution of attribute values among exist ing members An information-theoretic measure is used to compute the weights With these initial estimations one may produce a ranked list and select some top ranked ele ments for a test run For example, invitation letter may be sent to top ranked non-members Based on the response one may modify the weights of the market value function and utility functions 2 A Linear Model for Targeted Marketing We describe the proposed model for targeted marketing by focusing on the issues of knowledge representation and computation of market values More specifically we as sume that each object is represented by its values on a finite set of attributes We further assume that market values of objects can be computed using a linear market value func tion Thus we may consider the proposed model to be a linear model, which is related to but different from the lin ear model for information retrieval Let U be a finite universe of objects Elements of U may be customers or products we are interested in market oriented decision making The universe U is divided into three pair-wise disjoint classes i.e U  P U N U D The sets P N and D are called positive negative and don't know instances, respectively Take the earlier health club example P is the set of current members N is the set of people who had previously refused to join the club and D is the set of the rest The set N may be empty A targeted marketing problem may be defined as finding elements from D and possitdy from N that are similar to elements in P and possibly dissimilar to elements in N In other words we want to identify elements from D and N that are more likely to become new members of P We are interested in finding a market value function so that elements of D can be ranked acc.ordingly Information about objects in a finite universe is given by an information table 7 191 The rows of the table corre spond to objects of the universe, the columns correspond to attributes and each cell is the value of an object with respect to an attribute Formally an information table is a quadruple S  U,At Va I U E At I 1 a E At where U is a finite nonempty set of objects At is a finite nonempty set of attributes V is a nonempty set of values for a E At I  U  V is an information function for a E At Each information function I is a total function that maps an object of U to exactly one value in V An information table represents all available information and knowledge Objects are only perceived, observed or measured by using a finite number of properties 7 A straightforward solution for the targeted marketing problem is the mining of characteristic rules for both P and N or discriminant rules for differentiating elements of P and N The mined rules can then be used to classify ele ments of D There are extensive studies on such techniques Some of the difficulties with this straightforward solution have been mentioned in the Introduction We therefore fo cus our attention on an alternative approach A market value function is a real-valued function from the universe to the set of real numbers T  U  9 In the context of information retrieval the values of T represent the potential usefulness or relevance of documents with respect to a query According to the values of T documents are ranked. For the targeted marketing problem a market value function ranks objects according to their potential market values. For the health club example a market value function ranks people according to their likelihood of becoming a member of the health club The likelihood may be estimated based on its similarity to a typical member of P 518 


In this paper we study the simplest form of market value functions i.e the linear discriminant functions Let U  V  8 be a utility function defined on V for an attribute a E At The utility U may be positive, negative or zero For v E V if u,\(v  0 and I,\(z  v i.e ua\(Ia\(z  0 then attribute a has a positive contribution to the overall market value of z If U I z  0 then a has a negative contribution If u,\(I,\(z  0 then a has no contribution The pool of contributions from all attributes is computed by a linear market value function of the following form   Wa%\(Ia 1 200At where w is the weight of attribute a Similarly the weight w may be positive negative and zero Attributes with larger weights absolute value are more important and at tributes with weights close to zero are not important The overall market value of z is a weighted combination of util ities of all attributes By using a linear market value func tion, we have implicitly assumed that contributions made by individual attributes are independent Such an assumption is commonly known as utility independence assumption. Im plications of utility independence assumption can be found in literature of multi-criteria decision making 2 3 Mining Market Value Functions The potential usefulness and effectiveness of the pro posed model depends on, to a large extent the estimation of the individual utility functions and the attribute weights i.e the coefficients of the linear market value function This section investigates various methods for estimating and mining market value functions The estimation of utility functions draws from probabilistic models of information retrieval lo 11 161 The estimation of attribute weights is based on information-theoretic measures of attribute impor tance 9 14 15 17 181 3.1 Utility functions Utility functions can be defined based on either the pos itive instances or both positive and negative instances 3.1.1 Estimation from positive instances There are several situations that require the estimation of market value function from only positive examples It may happen that the negative examples are not available Al though negative examples may be available, they should be used very cautiously For example, people who are not in a health club or previous refused to join perhaps will join the club Thus one should not rule out the possibility that people similar to them may join the club In other words we use positive examples for including potential new members and we do not use negative examples to exclude potential new members It may also happen that one can easily find a regularity structure\explaining why an element belongs to P and cannot find a structure explaining why an element does not belong to P as there may be a great diversity of reasons for the latter Consider an attribute a E At taking its value from V For v E V let m\(a  1 P  m\(v 1 P be the subset of P defined by m\(v I P  z E U J 2 E P,I,\(z  U 2 It consists of elements from P whose value on a is v Let m\(v 1 P denotes the cardinality of the set m\(v I P For two values v,v\222 E V if Im\(w 1 P   Im\(v\222 I P then more elements from P having v as their value than those having U\222 as their value. Intuitively one may say that an ob ject having v as its value is more likely to belong to P than another element having w\222 as its value Based on merely attribute a for two elements z,y E U with I,\(z  v l,\(y  v\222 and Jm\(v 1 P  1m\(v\222 I P we may say that the market value of z is more than that of y This sug gests that the value of the utility function U  V  Fz at v E V should be propositional to the size of the set m\(v I P We therefore choose the following utility func tion The values of U are between 0 and PI which is based on a simple counting of elements having the value v in P The set of elements P may be considered to be a sub population of U One may also use a probabilistic version of the utility function 224,U  Pr\(a  221U I P  Pr\(v 1 P 4 IPI PI  Im\(v I P     Since PI is a constant independent of any attribute U and U will produce the same result in the linear model In general, one would expect an attribute to contribute more towards the market value of an element if its value is concentrated in the sub-population P This can be done by comparing the conditional probability Pr\(v 1 P and the unconditional probability Pr\(a  v  Pr   Im\(v I VI 222 where m\(v  z E U 1 I,\(z  U 6 519 


For simplicity we assume that m\(v  8 otherwise we can delete v from V The corresponding utility can be defined by If U  1 the value U is concentrated more on the sub population P if U",IJ  1 the value U is not concentrated on P One would expect a positive contribution for the for mer case and a negative contribution for the latter case To achieve this we use the logarithm transformation of as follows It follows that U  0 if and only if uz\(w  1 u",w  0 if and only if U  1 and U  0 if and only if U  1 In practical situation it may happen that m\(w I P  0 The utility function is not defined In this case we may use the point-5 formula as was done in information retrieval  101 This implicitly assumed that there is a notional sample of size one divided equally into P and N The quantity lUl/lPl is a constant independent of any attribute and will not effect the ranking It can there fore be removed from the utility function and the value Im\(v I P  can be used 3.1.2 With both positive and negative instances we have two sub populations P and N The estimation methods presented earlier can be modified to take into consideration of the dis tribution of attribute values in both P and N For an attribute value w E V it contributes more or pos itively to the market value of an object if w appears more in the sub-population P than in the sub-population N other wise it contributes less negatively, to the market value of the object Similar to utility functions and U we define two new utility functions Estimation from positive and negative instances where m\(w 1 N  z E U I z E N,I,\(z  w 12 The point-5 formula of U is given by 13 Im\(w I P  0.5 INI  0.5 Im\(v I N  0.5   0.5 4132  log Since P and N are disjoint subsets of U the new utility functions are not a simple replacement of U by N in U and U The ratio INI/IPI is a constant independent of any attribute it can be removed from the utility functions 3.2 Attribute weighting For the computation of attribute weights we adopt information-theoretic measures  17 181 For an attribute a its Shannon entropy Np\(a in the population P is defined by  where Pr 1 P denotes the probability distribution of at tribute values in P We define 0 log 0 to be 0 by extending function z log z to the origin by continuity The entropy is a nonnegative function i.e Hp\(u 2 0 It may be inter preted as a measure of the information content of or the uncertainty about a random variable a taking values from V The entropy reaches the maximum value log IV I for the uniform distribution i.e Pr\(w  l/IVal for all w E V The minimum entropy value 0 is obtained when the distribu tion focuses on a particular vaIue vo i.e Pr\(v0 1 P  1 and Pr\(w 1 P  0 for all v E V and II  IIO One may also interpret the entropy value as representing the de gree of structuredness or diversity of a probability distribu tion 9 141 A lower entropy value indicates a higher degree of struc turedness If an attribute has a lower entropy value we can say that the distribution of its values is uneven in the pop ulation P Thus the attribute may be more informative in predicating if an object belongs to P On the other hand an attribute with a larger entropy is less informative as the values of the attribute a are distributed more evenly in P A measure for weighting attributes can be designed so that it is inversely proportional to the entropy value An attribute weighting formula, adopted from information retrieval  171 is given below Clearly 0 I wk 5 1 We have also assumed that IV,l  1 Otherwise every object would have the same value on the attribute a and there is no point in using this attribute 5 20 


The entropy of attribute a in the entire population U is H\(a  H\(Pr   Pr\(v log Pr\(w 16 V\200Va It reflects the structuredness of the distribution of a's values in U For a more informative attribute we would expect that it shows less structuredness in U than in the subpopulation P We may use another weighting formula involving both Hp\(a and H\(a given by The weight 1 5 wi 5 1 gives the change of entropy values as we move from the entire population to a sub population A positive value suggests that attribute a shows more structuredness in P than in U and a negative value suggests the reverse It can also be seen that wi is a spe cial case of w where H\(a takes the maximum value of The well known Kullback Leibler divergence measure 1 Val offers another attribute weighting formula 4 w  D\(Pr I P  18 It measures the degree of deviation of the probability dis tribution Pr I P from the distribution Pr From an information-theoretic point of view the divergence can be interpreted as the difference between the information con tained in distribution Pr I P and that contained in Pr about Pr I P The measure is nonnegative i.e  0 This quantity becomes minimum 0 if Pr\(v I P  Pr\(w for all w E V The maximum value is realized when Pr\(w0 I P  1 for a particular WO for which Pr\(w0 is the smallest  141 We can also use both positive and negative instances for attribute weighting An attribute is informative if sub populations P and N are different from each other from the view point of the attribute In this case, we have three sub-populations P N and P U N Let Hp\(a a and Hpu~\(a denote the entropy values of attribute a in the three sub-populations, respectively If distributions of attribute values in P and N are similar, then both of them should be similar to the distribution in PUN We would ex pect a small difference of entropy values of a in P N and PUN On the other hand if distributions of attribute values in P and N are different, we would expect a large differ ence For this purpose we adopt the following weighting formula where Xp  AN  1 The second term in the formula is the average of entropy values in two sub-populations P and N For any attribute value v we have Pr\(w I P U N  XpPr\(?J I P  XNPr\(v 1 N 20 Since x log x is a concave function the Jensen inequal ity immediately implies that the lower bound of w is 0 i.e w 2 0 It reaches the minimum value 0 when the two distributions in P and N are identical It can also be shown that wt reaches the maximum value A log Xp  AN log A if the distributions are totally direrent namely Pr\(w I P  0 whenever Pr\(v I N  0 and Pr\(w I P  0 whenever Pr\(v 1 N  0 In terms of Kullback Leibler divergence tu can be ex pressed by  151 Wt  XpD\(Pr I P  21 vD\(Pr I N  The weighting formula w uses the first term of tu Thus w is an expected divergence considering two sub populations It may be considered as a more generalized version of w The entropy function is determined by only probability values in a probability distribution It is independent of how these probability values are assigned to different attributes Different probability distribution may produce the same en tropy value For instance the following distributions pro duce the same entropy value although they are totally dif ferent distributions Pr\(v1 I P  0.5 PT\('u I P  0.5 Pr\(vg I P  0.0 Pr\(7J4 I P  0.0 Pr\(V1 I N  0.0 PT\(VQ I N  0.5 PT\(Q I N  0.0 PT\(w I N  0.5 The difference between Hp\(a and U cannot tell us if P and N are similar based on attribute a This mainly stems from the fact that there is no inherent relationships between probability distributions Pr I P and Pr I N On the other hand the proposed measures wi and wt do not suffer from this problem In those formulas we use probability distributions from related populations 4 Conclusion Targeted marketing is a potentially important area of ap plications for data mining There are different types of targeted marketing problems While standard data mining techniques are useful for some new techniques are needed for others In this paper we focused on a targeted mar keting problem characterized by identifying potential new JL 1 


members based on the characteristics of existing members For this type of targeted marketing problems approaches for mining characteristic rules or classification rules may not be entirely suitable A linear model has been proposed in which the market values of potential new members is computed by a linear combination of utility functions on at tribute values. Our approach is obtained by adopting results from disciplines such as information retrieval case-based reasoning, and multi-criteria decision making We have focused our attention on the formal develop ment of the proposed linear model The interpretation of linear market value functions was given based on intuitive arguments Various methods for estimating parameters of market value functions were suggested They are based on probability related interpretations of utility functions and information-theoretic measures for attributes weight ing Each of the suggested methods seems intuitively ap pealing and captures different aspects of our perception of the utilities of attribute values and importance of attributes Many market value functions can be obtained by using dif ferent combinations of utility functions and weighting for mula The theoretical investigation is only the first step to wards the specific type of targeted marketing It may be dif ficult to judge which of them are better based solely on the oretical argument The effectiveness of the proposed model and various methods for estimating parameters need to be evaluated using real world examples The approach presented in this paper is different from and complementary to commonly used data mining ap proaches for mining rules It is important to realize that data mining is much application oriented, and different ap proaches need to be explored for different problems References l Agrawal R Imielinski T and Swami A Min ing association rules between sets of items in large databases Proceedings of the ACM SIGMOD Intema tional Conference on the Management of Data 207 216,1993 2 Fishburn P.C Seven independence concepts and con tinuous multiattribute utility functions Journal of Mathematical Psychology 11,294-327 1974 3 Han J Cai Y and Cercone, N. Data-driven discov ery of quantitative rules in relational databases IEEE Transaction on Knowledge and Data Engineering 5 29-40 1993 4 Kullback S and Leibler R.A On information and sufficiency Annals of Mathematical Statistics 22,79 86 1951 5 Leake D.B Case-Based Reasoning AAA1 Press 1996 6 Ling, C.X. and Li C Data mining for direct market ing: problems and solutions Proceedings of KDD\22298 7 Pawlak Z Rough Sets, Theoretical Aspects of Reason ing about Data Kluwer Academic Publishers Dor drecht 1 99 1 8 Quinlan J.R C4.5 Programs for Machine Learning Morgan Kaufmann 1993 9 Rao C.R Diversity and dissimilarity coefficients a unified approach Theoretical Population Biology 21 lo Robertson S.E On relevance weight estimation and query expansion Journal of Documentation 42 182 188 1986 ll Robertson S.E and Sparck Jones K Relevance weighting of search terms Journal of the American Society-for Information Science 27 129-146,1976 12 Salton G and McGill M.H Introduction to Mod em Infcirmation Retrieval McGraw-Hill New York 1983 131 Sparck Jones K. and Willett P Readings in Informa tion Retrieval Morgan Kaufmann 1997 141 Watanabe S Pattern recognition as a quest for min imum entropy Pattern Recognition 13 38 1-387 1981 151 Wong 9.K.M and Yao Y.Y A probability distribution model for information retrieval Information Process ing and Management 2539-53,1989 16 Wong S.K.M and Yao Y.Y A generalized binary probabilistic independence model Journal of the Americon Society for Information Science 41 324 329,1990  171 Wong S.K.M. and Yao Y.Y An information-theoretic measure of term specificity Journal of the American Society for Information Science 43 54-6 1 1992 18 Yao Y.Y Wong S.K.M and Butz C.J On information-theoretic measures of attribute impor tance Proceedings of PAKDD\22299 133-137, 1999 19 Yao Y.Y and Zhong N Granular computing using information tables, manuscript 1999 20 Zhong N Dong J.Z and Ohsuga S A hybrid ap proach to rule discovery in databases Information Sci ences 4n International Journal 126,99-127,2000 21 Zhong N Dong J.Z and Ohsuga S Rule discov ery by soft induction techniques Neurocomputing An International Journal 36 171-204,2001 22 Zhong N Yao Y.Y and Ohsuga S Peculiarity ori ented multi-database mining in J Zytkow and Jan Rauch eds Principles of Data Mining and Knowl edge Discovery LNAI 1704 Springer 136-146,1999 73-79 1998 24-43, 1982 522 


in Btree storage structure respectively The schemas of the relations are STUDENT logname c8 regno int advisor int, entry int year c2 scheme c6 uccacode c6 status cl examno int school c4 HOUSEHOLD hserno int persno int region c10 npersons int typaccm c10 bedrooms int centheat c4 ncars int ownrent c5 mortgage c4, cost int loan int The machine used was a 33Mhz SPARC-ELC with Ingres files held on a 2GB Fujitsu SCSI running synchronously Both relations are based on actual data used within the University Rules in our rules set were derived from the system by 12 91 The rule sets for each relation contained 50 rules The experiment was done for several thousand queries on both relations which was based on many observations using different featured rules in order to analyse the time saving using SQO For example if the rules contain any index attribute or not From our tests the following results were observed a For the both relations if the original query is refuted by any rule, the saving on average was 99.15 If the answer to the original query was found by one of the matching rules alone the saving on average was 99.53 b If the rule contained an indexed attribute the savings on average were up to 86.40 for 221STUDENT\222 and 83.52 for 221HOUSEHOLD\222 c In queries for which no indexed condition could be found, the saving on average was 6.39 for the relation 221STUDENT\222 and 1.94 for the relation 221HOUSEHOLD\222 The poorer result from the 221HOUSEHOLD\222 data was due to the lower number of instances per block compared with the 221STUDENT\222 relation 5 Conclusions This paper has described a fast query transformation process in SQO which constructs a near optimum query taking into account all matching rules The results are encouraging and promise large savings even when the rule set is large since transformation time is in linear function of rule set cardinality We are now extending our current work in statistics and knowledge discovery to address the issue of complex queries such as join queries and maintaining rules set 13 181 Acknowledgement We would like to thank John Ford  Tony Lawson in Computer Science Dept and Ken Miller  other personnel in the ESRC Data Archive at University of Essex Thanks also to Prof Tahir Sisman at Yildiz University for all his support during this research References I S Chakravarthy J Grant and J Minker 223Logic-based approach to semantic query optimisation\224 ACM on Database Systems Vol 15 No 2, 1990, pp. 162-207 2 K.C Chan and A.K.C Wong 223A statistical test for extracting classificatory knowledge form databases\224 Knowledge Discovery in Databases Ed The AAA1 Press 1991 pp 107-123 3 G Graefe and D Dewitt 223The EXODUS optimiser generator\224 In Proc of the 1987 ACM-SIGMOD Conf on Management of Data May 1987 pp 160-1711 4 J Han Y Cai and N Cercone 223Data-driven discovery of quantitative rules in relational databases\224 IEEE on Knowledge and Data Eng Vol5 no 1 Feb 1993 pp 29-40 5 C Hsu and C.A Knoblock, \223Rule induction for semantic query optimisation\224 In Proceedings of the Eleventh International Conf on Machine Learning 1994  I F Imam R S Michalski and L. Kerschberg 223Discovering attribute dependence in database by integrating symbolic learning and statistical analysis tests\224 Knowledge Discovery in Databases Workshop 1993 pp 264-275 7 J J King 223QUIST A system for semantic query optimisation in relational databases\224 In Proceeding of the 7 th VLDB Conference, Sept. 1981 pp 510-517 8 B G T Lowden 223An Approach to Multikey Sequencing in an equiprobable keyterm retrieval situation\224 Proceedings of the Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 1985 pp 92-96 9 B G T Lowden J Robinson and K Y Lim 223A semantic query optimiser using automatic rule derivation\224, Proc Fifth Annual Workshop on Information Technologies and Systems Netherlands, 68-76 December 1995 pp 68-76 lo L F Mackert and G M Lohman 223R optimizer validation and performance evaluation for local queries\224, Proc ACM-SIGMOD 1986 pp 84-95  111 G.Piatetsky-Shapiro and C Matheus 223Measuring data dependencies in large databases\224 Knowledge Discovery in Databases Workshop 1993 pp 162-173 12 A Sayli and B G T Lowden 223The use of statistics in semantic query optimisation\224, Thirteenth European Meeting on Cybernetics and Systems Research Vienna April 1996 pp 991-996 325 


 131 M SCHKOLNICK and P TIBERIO 223Estimating the cost of updates in a relational database\224 ACM Trans Database Systems 10,2 June 1985 pp 163-179  141 S Shekhar J Srivastava and S Dutta 223A formal model of trade-off between optimisation and execution costs in semantic query optimization\224 Proceedings of the 14th VLDB Conference Los Angeles, California, 1988 pp 457-467 15 S Shekhar B Hamidzadeh and A Kohli Learning transformation rules for semantic query optimisation a data driven approach. IEEE, 1993 pp 949-964 16 S.T Shenoy and Z.M Ozsoyoglu 223Design and implementation of semantic query optimiser\224 IEEE Transactions on Knowledge and Data Engineering Vol 1 No 3 Sept. 1989 pp 344-361 17 M.D Siegel E Sciore and S Salveter 223A method for automatic rule derivation to support semantic query optimisation\224 ACM Transactions on Database Systems Vol 17 No 4 Dec 1992, pp 563-600  181 C Yu and W Sun 223Automatic knowledge acquisition and maintenance for semantic query optimisation\224 IEEE Trans Knowl. Data Eng 1 3 Sept. 1989, pp 362-375 326 


of the query expression without ha ving the global view of the in ten tion There is a big c hance that the enco ded pro cedure ma y not b e the b est w a y to compute the rules dep ending on the database instance F urthermore as w e understand it their prop osals require p oten tially large n um ber of name generation for relations and attributes The names that are needed are usually database dep enden t and th us p ossibly cannot b e gathered at query time An additional pro cess needs to b e completed to gather those v ariables b efore actual computations can b egin 5  9 Optimization Issues While it w as in tellectually c hallenging to dev elop a declarativ e expression for asso ciation rule mining from deductiv e databases there are sev eral op en issues with great promises for resolution In the w orst case the least xp oin tneedsto generate n 2 tuples in the rst pass alone when the database size is n  Theoretically  this can happ en only when eac h transaction in the database pro duces an in tersection no de and when they are not related b y subset-sup erset relationship In the second pass w e need to do n 4 computations and so on The question no w is can w e a v oid generating and p erhaps scanning some of these com binations as they will not lead to useful in tersections F or example the no de b 0 3 in gure 11 is redundan t A signican t dierence with apriori lik e systems is that our system generates all the item sets top do wn in the lattice without taking their candidacy as a large item set in to consideration Apriori on the other hand do es not generate an y no de if their subsets are not large item sets themselv es and thereb y prunes a large set of no des Optimization tec hniques that exploit this so called an ti-monotonicit y prop ert y of item set lattices similar to apriori could mak e all the dierence in our setup The k ey issue w ould b e ho ww e push the selection threshold minim um supp ort inside the top do wn computation of the no des in the lattice in our metho d F or the momen t and for the sak e of this discussion let us consider a higher supp ort threshold of 60 for the database T of gure 9 No w the l-en v elop e will b e the one sho wn in ligh ter dashed lines in gure 11 and the no des under this line will b e the large item sets Notice that no ww eha v eto discard no des ad 2 0 and d 0 2 to o This raises the question is it p ossible to utilize the supp ort and condence thresholds pro vided in the query and prune candidates for in tersection an y further Ideas similar to magic sets transformation 3  24 ma y be b orro w ed to address this issue The only problem is that pruning of an y no de dep ends on its supp ort coun t whic h ma y come at a later stage By then all no des ma y already ha v e b een computed and th us pushing selection conditions inside aggregate op erator ma y b ecome non-trivial Sp ecial data structures and indexes ma y also aid in dev eloping faster metho ds to compute ecien t interse ction joins that w e ha v e utilized in this pap er W e lea v e these questions as op en issues that should be tak en up in the future F ortunately though there has been a v ast b o dy of researc h in optimizing Datalog programs including recursiv e programs suc h as the one w e ha v e used in this pap er and hence the new questions and researc h 5 Recall that their prop osal requires one to express the mining problem to the system using sev eral queries and up date statemen ts that utilizes information ab out the database con ten ts to ac hiev e its functionalit y  c hallenges that this prop osal raises for declarativ e mining ma y exploit some of these adv ances Needless to emphasize a declarativ e metho d preferably a formal one is desirable b ecause once w e understand the functioning of the system w e will then be able to select appropriate pro cedures dep ending on the instances to compute the seman tics of the program whic hw e kno wis in tended once w e establish the equiv alence of declarativ e and pro cedural seman tics of the system F ortunately  w e ha v e n umerous pro cedural metho ds for computing asso ciation rules whic h complemen t eac h other in terms of sp eed and database instances In fact that is what declarativ e systems or declarativit y buy us  a c hoice for the most ecien t and accurate pro cessing p ossible 10 Conclusion Our primary goal for this pap er has b een to demonstrate that mining asso ciation rules from an y rst-order kno wledge base is p ossible in a declarativ ew a y  without help from an y sp ecial to ols or mac hinery  and that w e can no wha v ea v ery in tuitiv e and simple program to do so W eha v esho wn that it is indeed p ossible to mine declarativ ekno wledge b y exploiting the existing mac hinery supp orted b ycon temp orary inference engines in programming languages e.g Prolog or kno wledge base systems e.g RelationLog XSB LD L  CORAL All w e require is that the engine b e able to supp ort set v alued terms grouping aggregate functions and set relational op erators for comparison functionalities whic hmostofthesesystemscurren tly supp ort W e ha v e also demonstrated that our formalism is grounded on a more mathematical foundation with formal prop erties on whic h the seman tics of the R ULES system rely  W e ha v e also raised sev eral op en issues related to eciency and query optimization whic h should b e our next order of business As future researc h w e plan to dev elop optimization tec hniques for mining queries that require non-trivial lo ok ahead and pruning tec hniques in aggregate functions The dev elopmen ts presen ted here also ha v e other signican t implications F or example it is no w p ossible to compute c hi square rules 4 using the building blo c ks pro vided b y our system Declarativ e computation of c hi square rules to our kno wledge has nev er b een attempted for the man y pro cedural concepts the computation of c hi square metho d relies on In a separate w ork 2 w e sho w that the coun ting metho d prop osed in this pap er can be eectiv ely utilized to generate the exp ectations needed in order to compute suc h rules rather easily  These are some of the issues w e plan to address in the near future The motiv ation imp ortance and the need for in tegrating data mining tec hnology with relational databases has b een addressed in sev eral articles suc h as 12  13 They con vincingly argue that without suc h in tegration data mining tec hnology ma y not nd itself in a viable p osition in the y ears to come T o b e a successful and feasible to ol for the analysis of business data in relational databases suc htec hnology m ust b e made a v ailable as part of database engines and as part of its declarativ e query language Our prop osal for declarativ e mining bears merit since it sheds ligh t on ho w rst order databases can be mined in a declarativ e and pro cedure indep enden t w a y so that the optimization issues can b e delegated to the underlying database engine Once suc h argumen ts are accepted sev eral systems 9 


related issues b ecome prime candidates for immediate atten tion F or example traditionally database systems supp orted declarativ e querying without the necessit y to care ab out the pro ceduralit y of the queries In this pap er w eha v e actually demonstrated that asso ciation rule mining can b e view ed as a Datalog query  It is immediate that a direct mapping from the Datalog expressions presen ted in this pap er to SQL can be dev elop ed with no problem at all W e can then rely on ecien t database pro cessing of the query in an optimized fashion Hence w ecomeclose to the essence of the visions expressed b y the leading database researc hers and practioners 12  References 1 Rak esh Agra w al and Ramakrishnan Srik an t F ast algorithms for mining asso ciation rules in large databases In VLDB  pages 487{499 1994 2 Anon ymous A declarativ e metho d for mining c hisquare rules from deductiv e databases T ec hnical rep ort Departmen t of Computer Science Anon ymous Univ ersit y USA F ebruary 2001 3 C Beeri and R Ramakrishnan On the po w er of magic In Pr o c e e dings of the 6th A CM Symp osium on Principles of Datab ase Systems  pages 269{283 1987 4 Sergey Brin Ra jeev Mot w ani and Craig Silv erstein Bey ond mark et bask ets Generalizing asso ciation rules to correlations In Pr o c A CM SIGMOD  pages 265 276 1997 5 D Chimen ti et al The LD L system protot yp e IEEE Journal on Data and Know le dge Engine ering  2\(1 90 1990 6 Jia w ei Han Jian P ei and Yiw en Yin Mining frequen t patterns without candidate generation In Pr o c A CM SIGMOD  pages 1{12 2000 7 Marcel Holsheimer Martin L Kersten Heikki Mannila and Hann uT oiv onen A p ersp ectiv e on databases and data mining In Pr o c of the sixth A CM SIGKDD Intl Conf  pages 150{155 Mon treal Queb ec 1995 8 Flip Korn Alexandros Labrinidis Y annis Kotidis and Christos F aloutsos Ratio rules A new paradigm for fast quan tiable data mining In Pr o c of 24th VLDB  pages 582{593 1998 9 Brian Len t Arun N Sw ami and Jennifer Widom Clustering asso ciation rules In Pr o c of the 3th ICDE  pages 220{231 1997 10 Mengc hi Liu Relationlog At yp ed extension to datalog with sets and tuples In John Llo yd editor Pr oc e e dings of the 12th International L o gic Pr o gr amming Symp osium  pages 83{97 P ortland Oregon Decem ber 1995 MIT Press 11 Rosa Meo Giusepp e Psaila and Stefano Ceri An extension to SQL for mining asso ciation rules Data Mining and Know le dge Disc overy  2\(2 1998 12 Amir Netz Sura jit Chaudh uri Je Bernhardt and Usama M F a yy ad In tegration of data mining with database tec hnology  In Pr o c e e dings of 26th VLDB  pages 719{722 2000 13 Amir Netz Sura jit Chaudh uri Usama M F a yy ad and Je Bernhardt In tegrating data mining with SQL databases In IEEE ICDE  2001 14 Ra ymond T Ng Laks V S Lakshmanan Jia w ei Han and Alex P ang Exploratory mining and pruning optimizations of constrained asso ciation rules In Pr o c A CM SIGMOD  pages 13{24 1998 15 Jong So o P ark Ming-Sy an Chen and Philip S Y u An eectiv e hash based algorithm for mining asso ciation rules In Pr o c A CM SIGMOD  pages 175{186 1995 16 Karthic k Ra jamani Alan Co x Bala Iy er and A tul Chadha Ecien t mining for asso ciation rules with relational database systems In Pr o c e e dings of the International Datab ase Engine ering and Applic ations Symp osium  pages 148{155 1999 17 R Ramakrishnan D Sriv asta v a and S Sudarshan CORAL  Con trol Relations and Logic In Pr o c of 18th VLDB Confer enc e  pages 238{250 1992 18 Konstan tinos F Sagonas T errance Swift and Da vid Scott W arren XSB as an ecien t deductiv e database engine In Pr o c of the A CM SIGMOD Intl Conf  pages 442{453 1994 19 Sunita Sara w agi Shib y Thomas and Rak esh Agra w al In tegrating mining with relational database systems Alternativ es and implications In Pr o c A CM SIGMOD  pages 343{354 1998 20 Ashok a Sa v asere Edw ard Omiecinski and Shamk an tB Nav athe An ecien t algorithm for mining asso ciation rules in large databases In Pr o c of 21th VLDB  pages 432{444 1995 21 Pradeep Sheno y  Ja y an t R Haritsa S Sudarshan Gaura v Bhalotia Ma y ank Ba w a and Dev a vrat Shah T urb o-c harging v ertical mining of large databases In A CM SIGMOD  pages 22{33 2000 22 Abraham Silb ersc hatz Henry F Korth and S Sudarshan Datab ase System Conc epts  McGra w-Hill third edition 1996 23 Shib y Thomas and Sunita Sara w agi Mining generalized asso ciation rules and sequen tial patterns using SQL queries In KDD  pages 344{348 1998 24 J D Ullman Principles of Datab ase and Know le dgeb ase Systems Part I II  Computer Science Press 1988 25 Mohammed J Zaki Generating non-redundan t association rules In Pr o c of the 6th A CM SIGKDD Intl Conf  Boston MA August 2000 1 0 


OM OM 006 OD8 01 012 014 016 018 02 022 False alarm demity Figure 9 Percentage of tracks lost within 200 seconds using three-scan assignment with PD  0.9 TI  O.ls Figure 11 T2  1.9s and T  Is ij  20 and 0  0.1 24 1 22  20  E fls 0  8l 16 0 n 14  12  0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 T1/12 PD Average track life of three-scan assignment with PD varying TI  0-ls T2  1.9s T  Is X  0.02 ij LO and   0.1 mareuvenng index Figure 12 Percentage of lost tracks of 4-D assipment in 200 seconds with maneuvering index varying X  0.01 Ti  0.1 T2  1.9s and T  IS PD  0.98 Figure 10 Percentage of lost tracks of 4-D assignment in 200 SeoDllCls with TI and T2 varying PD  0.98 X  0.02 q 20 and 0  0.1 4-1607 


Figure 13 Average gate size for Kalman filter Figure is relative as compared to nq and curves are parametrized by ij/r with unit-time between each pair of samples 1.2 Iy I 1.1 0.5 I A CRLB for he unifm samiina I  0.4 0.35 d 3 03 i7 3 0.25 0 0.M 0.04 0.06 008 0.1 0.12 0.14 0.16 0.18 0.2 False A!am DemW V I    Figure 14 CramerRao Lower Boundfor Mean Square Error of uniform and nonuniform sampling schemes with Ti  O.ls T2  1.9s T  IS PD  0.9 ij  5 and U  0.25 1 unifon sampling r-ls ked i non-uniform sampling loge inlewi I ti non-uniform sampling shod interva I 0.9 0.8 I Figure 15 MSE comparison of three-scan assignment with Ti and T2 varying I'D  1 X  0.01 ij  20 and U  0.1 4-1608 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



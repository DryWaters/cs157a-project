Data mining machine learning statistics and databases Heikki Mannilat Department of Computer Science University of Helsinki FIN-0 00 14 Helsinki Finland URL:http://nnn.cs.helsinki.fi/~mannila E-mail Heikki  MannilaQcs  helsinki  f i Abstract Knowledge discovery in databases and data min ing aim at semiautomatic tools for the analysis of large data sets We give an overview of the area and present some of the research issues especially from the database angle 1 Introduction 
Knowledge discovery in databases KDD often called data mining aims at the discovery of useful information from large collections of data The dis covered knowledge can be rules describing properties of the data frequently occurring patterns clusterings of the objects in the database etc Data mining has in the 1990\222s emerged as visible research and develop ment area; both in industry and in science there seems to be a lack of methods for efficient analysis of large data sets Current technology makes it fairly easy to collect data but data analysis tends to be slow and expen sive 
There is a suspicion that there might be nuggets of useful information hiding in the masses of unan alyzed or underanalyzed data and therefore semiau tomatic methods for locating interesting information from data would be useful There are several success ful applications of data mining See 9 for a recent overview of the area This paper gives a short discussion of some of the database-oriented research issues in knowledge discov ery We start in Section 2 by briefly discussing the KDD process basic data mining techniques and list ing some prominent applications Section 
3 discusses the role of machine learning and statistics in KDD and data mining In Section 4 we move to the role of databases in knowledge discovery by looking at a simple example of data mining, namely the problem of discovering association rules We present a simple algorithm for this task and show in Section 5 how the same ideas can be used for other types of data too Section 6 moves to a generic data mining algorithm and discusses some of the architectural issues in data mining systems Based on these ideas 
we consider in Part of this work was done while the author was visiting the Max Planck Institut fiir Informatik in Saarbriicken Ger many Work supported by the Academy of Finland and by the Alexander von Humboldt Stiftung Section 7 the possibilities of specifying KDD tasks in a high level language and compiling these specifica tions to efficient discovery algorithms Section 8 con siders the possibilities of representing large data sets by smaller condensed representations and Section 9 is a short conclusion 2 The KDD process The goal 
of knowledge discovery is to obtain useful knowledge from large collections of data Such a task is inherently interactive and iterative one cannot ex pect to obtain useful knowledge simply by pushing a lot of data to a black box The user of a KDD sys tem has to have a solid understanding of the domain in order to select the right subsets of data suitable classes of patterns and good criteria for interesting ness of the patterns Thus KDD systems should be seen as a interactive tools not as automatic analysis systems Discovering knowledge from data should therefore 
be seen as a process containing several steps 1 understanding the domain 2 preparing the data set 3 discovering patterns data mining 4 postprocessing of discovered patterns, and 5 putting the results into use See 8 for a slightly different process model and ex cellent discussion Understanding the domain of the data is naturally a prerequisite for extracting anything useful the user of a KDD system has to have some sort of under standing about the application area before any valu able information can be obtained On the other 
hand if very good human experts exist for a domain it can be hard for semiautomatic tools to obtain any novel information This can be the case in fairly stable do mains where the humans have had time to achieve expertise even in the details of the data A possi ble example occurs in some areas of retailing where the products and customer profiles can stay about the same for longer periods of time The easiest appli cation areas for KDD seem to be ones where general 0-8186-7264-1196 05.00 0 1996 IEEE 2 


human experts can be found but the actual microlevel properties of the data are changing This seems to be the case in e.g telecommunications where the oper ators of the networks have a fairly good overview of the systems characteristics but changes and updates in equipment and software mean that actual expertise in the details of the data is more difficult to obtain Preparation of the data set involves selection of the data sources integration of heterogeneous data clean ing the data from errors assessing noise, dealing with missing values etc This step can easily take up to 80  of the time needed for the whole KDD process this is not surprising since the difficulties in data integra tion are well known The pattern discovery plhase in KDD is the step where the interesting and frequently occurring pat terns are discovered from the data In this paper we follow the terminology introduced in 8 data mining refers to the pattern discovery part of knowledge dis covery Elsewhere especially in industry data mining is often used as a synonym for KDD The data mining step can use various techniques from statistics and machine learning such as rule learning decision tree induction clustering, inductive logic programming etc The emphasis in data min ing research is mostly on efficient discovery of fairly simple patterns The KDD process does not stop when patterns have been discovered The user has to be able to under stand what has been discovered to view the data and patterns simultaneously contrast the discovered pat terns with background knowledge etc Postprocessing of discovered knowledge involves steps such as further selection or ordering of patterns visualization etc Some approaches to KDD methodology put a heavy emphasis on postprocessing The KDD process is necessarily iterative the re sults of a data mining step can show that some changes should be made to the data set formation step post processing of patterns can cause the user to look for some slightly modified types of patterns etc Efficient support for such iteration is one important develop ment topic in KDD Prominent applications of KDD include health care data financial applications and scientific data 26 191 One of the more spectacular applications is the SKICAT system 7 which operates on 3 terabytes of image data producing a classification of approxi mately 2 billion sky objects into a few classes The task is obviously impossible to do manually Using example classifications provided by the users the sys tem learns classification rules that are able to do the categorization accurately and fast In industry the success of KDD is partly related to the rise of the concepts of data warehousing and on-line analytical processing OLAP These strate gies for the storage and processing of the accumulated data in an organization have become popular in recent years KDD and data mining can be viewed as ways of realizing some of the goals of data warehousing and OLAP 3 Data mining machine learning and statistics Data mining combines methods and tools from at least three areas machine learning statistics and databases Indeed one can sometimes hear the fol lowing comments 0 Data mining is just machine learning 0 Data mining is just statistics 0 What does data mining have to do with In this section we discuss briefly the first two points the rest of the paper is devoted to a discussion on the third point The close links between machine learning statis tics and data mining are fairly obvious All three ar eas aim at locating interesting regularities patterns or concepts from empirical data The exact relation ships of these areas have been subject to some debate Machine learning methods form the core of data mining decision tree learning or rule induction is one of the main components of several data mining algo rithms There are also some differences however The emphasis on the process of knowledge discov ery is one large parts of machine learning literature concentrate on just the learning or induction step al though exceptions of course exist The next difference concerns the relative roles of concepts and data It seems to me that most ma chine learning research assumes there is something to be learned i.e that there is an underlying interesting concept or mechanism that produces the data The data can be corrupted by noise errors etc but still the idea is that there is an interesting concept at the bottom In knowledge discovery on the other hand the data is the primary thing and one does not neces sarily assume that there would be any sensible struc ture behind the data For example, in analyzing retail sales data the data is what it is and the users are not interested in obtaining a full understanding of it useful nuggets of information are sufficient Of course this difference is not absolute A third difference is related to the goals KDD sys tems typically have fairly modest aims in terms of the complexity of the obtained knowledge Whereas parts of machine learning research aim at learning things that are difficult for humans to do most of the work in KDD aims at finding knowledge that a competent data analyst would in principle be able to find if he/she had the time This distinction is particularly evident when one compares the area of machine discovery to knowledge discovery An often cited difference between KDD and ma chine learning is the amount of data Traditionally machine learning research has concentrated on looking at data sets containing hundreds or thousands of ex amples while KDD applications consider larger data sets I\222m not sure how significant this distinction is however some machine learning work has been done on huge data sets and KDD methods can be a use ful even on small data collections Furthermore, the databases 3 


essential source of complexity in data mining is typi cally not the number of objects in the database but rather the number of attributes the number of pos sible patterns typically grows at least exponentially in the number of attributes This growth is the real source ofdifficulty not the number of objects in the database Summarizing machine learning is at the core of KDD but there are differences between the areas In statistics the term data mining has been used for a long time often in slightly derogatory fashion as re ferring to data analysis without clearly formulated hy potheses A more fashionable term is ezploratory data analysis EDA 29 which stressed the supremacy of data as guiding the analysis process KDD and EDA have very similar aims and methods According to the interesting statistical perspective on KDD by Elder and Pregibon 6 the focus of statis tics has gradually moved from model estimation to model selection Instead of looking for the parameter values that make a model fit the data well also the model structure is part of the search process This trend fits the goals of KDD nicely one does not want to fix the model structure in advance The recent ad vances in say Markov chain Monte Carlo MCMC methods make it possible to consider far larger model spaces than previously In addition to these tech niques the KDD community has lots to learn from statistics e.g in the handling of uncertainty The main differercz between KDD and statistics is perhaps in the extensive use of machine learning meth ods in KDD in the volume of data and in the role of computational complexity issues in KDD For ex ample even MCMC methods have difficulties in han dling tens of thousands of parameter values; some sort of combinatorial preprocessing is needed to make the model selection task tractable It seems that such combinations of methods can be useful combinato rial techniques are used to prune the search space and statistical methods are used to explore the remaining parts in great detail atabases and data mining What is the role of databases in data mining Database management systems are systems especially developed for the storage and flexible retrieval of large masses of structured data so in principle they should be suited for KDD including data mining In the remaining sections of this paper we dis cuss some issues that are connected with the use of database management systems in KDD applications We introduce the issues by considering first a simple data mining problem and then generalizing it The problem we consider is finding association rules from binary data Assume we have a set R  AI   Ap of binary attributes i.e., the domain of each A is 0 l A relation r  tl   in over the schema R is a matrix with columns R and n rows each row being a vector of length p of 0\222s and 1\222s An association rule l about T is an expression of the form X 3 B where X C R and B E R  X The intuitive meaning of the rule is that if a row of the matrix T has a 1 in each column of X then the row tends to have a 1 also in column B Examples of data where association rules might be applicable include the following A student database at a university rows corre spond to students columns to courses and a 1 in entry s c indicates that the student s has taken course c m Data collected from bar-code readers in super markets columns correspond to products and each row corresponds to the set of items pur chased at one time m A database of publications the rows and columns both correspond to publications and p,p\222  1 means that publication p refers to publication p\222 A set of measurements about the behavior of a bunch of systems say exchanges in a telephone network The columns correspond to the presence or absence of certain conditions and each row correspond to a measurement if entry m c is 1 then at measurement m condition c was present Given W C R we denote by s\(W r the frequency of W in T the fraction of rows of r that have a 1 in each column of W The frequency of the rule X  B in T is defined to be s\(X U B r and the confidence of the rule is i\(X U B r X r In discovery of association rules the task is to find all rules X  B such that the frequency of the rule is at least a given threshold U and the confidence of the rule is at least another threshold 8 In large retailing applications the number of rows might be 10\221 or even lo7 and the number of columns around 5000 The fre quency threshold U typically is around lo-\222  The confidence threshold 8 can be anything from 0 to 1 From such a database one might obtain hundreds or thousands of association rules Of course one has to be careful in assigning any statistical significance to findings obtained from such methods Note that there is no predefined limit on the num ber of attributes of the left-hand side X of an associa tion rule X 3 B this is important so that unexpected associations are not ruled out before the processing starts It also means that the search space of the rules has exponential size in the number of attributes of the input relation Handling this requires some care for the algorithms but there is a simple way of pruning the search space We call a subset X C R frequent in r if s\(X r 2 U Once all frequent sets of r are known finding the association rules is easy Namely for each frequent set X and each B E X verify whether the rule X\\{B j B has sufficiently high confidence How can one find all frequent sets X This can be done in a multitude of ways I 2 12 14 281 A typical approach I 21 is to use that fact that all subsets of a frequent set are also frequent First find all frequent sets of size 1 by reading the data once and recording the number of times each at tribute A occurs Then form candidate sets of size 2 by 4 


taking all pairs B C of attributes such that B and C both are frequent The frequency of the candidate sets is again evaluated against the database Once fre quent sets of size 2 are known candidate sets of size 3 can be formed; these are sets B C D such that B C B D and C D are all frequent This process is continued until no more candidate sets can be formed C  A}I I A E R 3  0 while C  0 do As an algorithm the process is as follows 3\222  the sets X E C that are frequent add F\222 to 3 C  new candidate sets generated from F\222 od The algorithm has to read the database at most K 1 times where K is the size ofthe largest frequent set In the applications K is small typically at most 10 so the number of passes through1 the data is reasonable Note that there are at least frequent sets thus if K is much larger than 10 the output of the frequent set algorithm gets quite big There still might be only few interesting association rules however A modification of the above method is obtained by computing for each frequent set X the subrela tion rx C T consisting of those TOWS t E r such that t[A  1 for all A E X Then it is easy to see that for example T{A,B,C  A n r{B,c Thus the re lation rx for a set X of size IC can be obtained from the relations rxt and rx\224 where X\222  X  A and X\223  X  B for some A B E X with A  B This method has the advantage that rows that do not con tribute to any frequent set willl not be inspected more than once For comparisons of the two approaches see 2 14 281 The algorithms described above work quite nicely on large input relations Their running time is ap proximately OINF where N  np is the size of the input and F is the size of the output the sum of the sizes of the frequent sets This is nearly linear and the algorithms seem to scale nicely to tens of millions of examples The only case when they fail is when the output is too large i.e there are too many fre quent sets but in that case the whole task is not very sensible The methods for finding frequent sets are simple they are based on one nice but simple observation subsets of frequent sets must be frequent and use straightforward implementation techniques A naive implementation of the algorithms on top of a relational database system would be easy we need to pose to the database management system queries of the form 223What is s\({Al   Ak r or in SQL select count from r t where t[Al  1 and  aind t[Ak  1 221This is actuallynot quite true: the running time is O\(NF\222 where F\222 is the sum of the sizes of the frequent sets and the sets in the candidate collection C during the operation of the algorithm 24 The number of such queries can be large if there are thousands of frequent sets there will be thousands of queries The overhead in performing the queries on an ordinary dbms would probably be prohibitive The customized algorithms described above are able to evaluate masses of such queries reasonably ef ficiently for several reasons First all the queries are very simple and have the same general form thus there is no need to compile each query individually Second the algorithms that make repeated passes through the data evaluate a large collection of queries during a single pass Third, the algorithm that build the relations rx for frequent sets X use the results of previous queries to avoid looking at the whole data for each query 5 Application finding episodes from sequences The basic ideas of the algorithm for finding associ ation rules are fairly widely applicable In this section we describe an application of the same ideas to tRe problem of finding repeated episodes in sequences of events Consider a sequence of events e,t where e is the type of the event and t is the time when the event occurred Such data is routinely collected in e.g telecommunication networks process monitoring quality control user interface studies and epidemi ology There is an extensive statistical literature on how such data can be analyzed but most methods are suited only for small numbers of event types For example a telecommunications network alarm database is used to collect all the notifications about abnormal situations in the nt.vxk V-2 number of event types is around 200 and there are 1000-10000 alarms per day 13 As a first step in analyzing such data one can try to find which event types occur frequently close together Denoting by E the set of all event types an epzsode cp is a partially ordered set of elements from E An episode might e.g state that events of type A and B occur in either order before an event of type C Given an alarm sequence r  el,tI   en a slzce rt of r of width W consists of those events ex tz of r such that t 5 t 5 t  W An episode cp OCCILTS in rt if there are events in Tt corresponding to the event types of p and they occur in an order respecting the partial order of p An episode is frequent if it occurs in sufficiently many slices of the original sequence How to find all episodes from a long sequence of events Using the same idea as before we first locate frequent episodes of size 1 then use these to generate candidate episodes of size 2 verify these against the data generate candidate episodes of size 3 etc The algorithm can be further improved by using incremen tal recognition of episodes see 25 for details and 22 for extensions The results are good the algorithms are efficient and using them one can find easily com prehensible results about the combinations of event types that occur together 5 


6 A generic data mining algorithm and architecture A fairly large class of data mining tasks can be de scribed as the search for interesting and frequently oc curring patterns from the data That is we are given a class P of patterns or sentences that describe proper ties of the data and we can specify whether a pattern p E P occurs frequently enough and is otherwise in teresting That is the generic data mining task is to find the set PI\(d,P  p E P 1 p occurs sufficiently often in d and p is interesting This point of view has either implicitly or explicitly been used in discovering integrity constraints from databases in inductive logic programming and in ma chine learning 4 5 18 19 201 some theoretical results can be found in 24 and a suggested logical formalism in IT For association rules the pattern class is the set of all rules of the form X  B and a rule is interesting if its confidence is sufficiently high For finding episodes the patterns are the episodes and there need not be any interestingness criterion The algorithm given above can be generalized to finding Pl\(d P as follows C  initial patterns from P while C  0 do for each p E C 3  3 U p E.C 1 p is sufficiently frequent in d C  new candidates generated from 3 find the number of occurrences of p in d od output interesting patterns from 3 In addition to discovering association rules or fre quent episodes istantiations of this algorithm include finding keys of relations 21 hill-climbing searches for best descriptions 15 191 etc In hill-climbing the set C will contain only the neighbors of the current 223most interesting\224 pattern For other strategies a possible problem with this algorithm is that the test for inter estingness is applied only at the end If there are lots of frequent but uninteresting patterns the algorithm will use a lot of time inspecting these The generic algorithm suggests a data mining sys tem architecture consisting of a discovery module and a database management system The discovery mod ule sends queries to the database and the database answers The queries are typically of the form 223How many objects in the database match p\224 where p is a possibly interesting pattern; the database answers by giving the count If implemented naively this architecture leads to slow operations To achieve anything resembling the efficiency of tailored solutions the database manage ment system should be able to utilize the strong simi larities between the queries generated by the discovery module The view of data mining as locating frequently occurring and interesting patterns from data sug gests that data mining can benefit from the exten sive research done in the area of combinatorial pattern matching see e.g IO 7 Towards higher-level data mining Currently data mining research and development consists mainly of isolated applications Among oth ers Imielinski 16 has eloquently argued that data mining is today at the same state as data manage ment was in the 1960\222s then all data management applications were ad hoc only the advent of the re lational model and powerful query languages made it possible to develop applications fast e Consequently data mining would need a similar theoretical frame work The approach of computing Pl\(d P presented in the previous section provides one possible framework A data mining task could be given by specifying the class P and the interestingness predicate That is the user of a KDD system makes a pattern query Mim icking the behavior of an ordinary dbms the KDD system compiles and optimizes the pattern query and executes it by searching for the patterns that satisfy the user\222s specifications and have sufficient frequency in the data As an example consider the simple case of mining for association rules in a course enrollment database The user might say that he/she is interested only in rules that have the 223Data Management\224 course on the left-hand side This restriction can be utilized in the algorithm for finding frequent sets only candidate sets that contain 223Data Management\224 need to be consid ered Developing methods for such pattern queries and their optimization is currently one of the most inter esting research topics in data mining So far even the simple techniques such as the above have not been suf ficiently studied It is not clear how far one can get by using such methods but the possible payoff is large In addition to developing query processing strate gies for data mining applications changes in the un derlying storage model can also have a strong effect on the performance A very interesting experiment in this direction is the work on the Monet database server developed at CWI in the Netherlands by Martin Ker sten and others 15 31 The Monet system is based on the vertical partitioning of the relations a relation with k attributes is decomposed into IC relations each with two attributes the OID and one of the origi nal attributes The system is built on the extensive use of main memory has an extensible set of basic operations and supports shared-memory parallelism Experiments with Monet on data mining applications have produced quite good results 15 141 8 Condensed representations We remarked in Section 2 that KDD is an iterative process Once a data mining algorithm has been used to discover potentially interesting patterns the user often wants to view these patterns in different ways have a look at the actual data visualize the patterns 6 


etc A typical phenomenon is also that some pattern p looks interesting and the user wants to evaluate other patterns that closely resemble p In implementing such queries, caching of previous results is obviously useful Still having to go back to the original data each time the user wants some more information seems some what wastful Similarly in the generic data mining algorithm presented in Section 6 the frequency and interestingness of each pattern are verified against the database It would be faster to look at some sort of short representation of the data Given a structure d E ID and a class of patterns P a condensed representation for d and P is a data structure that makes it possible to answer queries of the form 223HOW many times does p E P occur in d\224 approximately correctly and more efficiently than by looking at d itself A simple example of a condensed representation is obtained by taking a sample from the data by count ing the occurrences of the pattern in the sample, one gets an approximation of the number of occurrences in the original data Another less obvious example is given by the collection of frequent sets of a 0-1 val ued relation 23 the collection of frequent sets can be used to give approximate answers to arbitrary boolean queries about the data even though the frequent sets represent only conjunctive concepts The data cube I13 can also be viewed as a condensed representation for a class of queries Similarly in computational ge ometry the notion of an approximation 27 is closely related Developing condensed representations for various classes of patterns seems a promising way of improving the effectiveness of data mining algorithms Whether this approach is generally useful is still open 9 Concluding remarks Data mining and knowledge discovery are currently quite popular and there is lots of hype around As the area is partly a mixture of techniques from different fields there is also the danger of reinventing old bad solutions We summarize some of the database related re search directions 1 Development of pattern query specification lan guages and techniques for optimizing pattern queries 2 Condensed representations for various classes of pat terns 3 Caching strategies for processing strongly related queries 4 Combinations of data mining and statistical tech 5 Using background knowledge e.g metadata in 6 Tools for selecting grouping and visualizing dis niques the KDD process covered knowledge Acknowledgements Discussions with Tomasz Imielinski Willi Kloes gen Arno Siebes and Stefan Wrobel have been most useful Pirjo Ronkainen and Hannu Toivonen provided comments on an earlier version References l R Agrawal T Imielinski and A Swami Min ing association rules between sets of items in large databases In Proceedings of ACM SIG MOD Conference on Management of Data SIG MOD\22293 pages 207  216 May 1993 2 R Agrawal H Mannila R. Srikant H Toivonen and A I Verkamo Fast discovery of association rules In U M Fayyad G Piatetsky-Shapiro P Smyth and R. Uthurusamy editors Advances in Knowledge Discovery and Data Mining pages 307  328 AAAI Press Menlo Park, CA 1996 3 P A Boncz W Quak and M L Kersten Monet and its geographical extensions a novel approach to high-performance GIS processing In EDBT\22296 1996 To appear 4 L De Raedt and M Bruynooghe A theory of clausal discovery In Proceedings of the Thir teenth International Joint Conference on Artifi cial Intelligence IJCAI-93 pages 1058  1053 ChambCry France 1993 Morgan Kaufmann First-order jk clausal theories are PAC-learnable Artificial In telligence 70:375  392 1994 6 J Elder IV and D Pregibon A statistical per spective on knowledge discovery in databases In U M Fayyad G Piatetsky-Shapiro P Smyth and R Uthurusamy editors Advances in Knowl edge Discovery and Data Mining pages 83  113 AAAI Press Menlo Park, CA 1996 7 U M Fayyad S G Djorgovski aid N Weir Automating the analysis and cataloging of sky surveys In U M Fayyad G Piatetsky-Shapiro P Smyth and R Uthurusamy editors Advances in Knowledge Discovery and Data Mining pages 471  494 AAAI Press Menlo Park CA 1996 8 U M Fayyad G Piatetsky-Shapiro and P Smyth From data mining to knowledge discov ery An overview In U M Fayyad, G Piatetsky Shapiro P Smyth and R Uthurusamy editors Advances in Knowledge Discovery and Data Min ing pages 1 34 AAAI Press Menlo Park, CA 1996 9 U M Fayyad G Piatetsky-Shapiro P Smyth and R Uthurusamy, editors Advances in Knowl edge Discovery and Data Mining AAAI Press Menlo Park, CA 1996 6th Annual Symposium on Combinatorial Pattern Matching CPM 95  Espoo Finland July 1995 volume 5 L De Raedt and S Dieroski lo Z Galil and E Ukkonen editors 7 


937 of Lecture Notes in Computer Science Berlin 1995 Springer J Gray A Bosworth A Layman and H Pira hesh Data Cube A relational aggregation op erator generalizing group-by cross-tab and sub totals In 12th International Conference on Data Engineering ICDE\22296 pages 152  159 New Orleans Louisiana Feb 1996 J Han and Y Fu Discovery of multiple-level as sociation rules from large databases In Proceed ings of the 21st International Conference on Very Large Data Bases VLDB\22295 pages 420  431 Zurich Swizerland 1995 K Hatonen M Klemettinen H Mannila P Ronkainen and H Toivonen Knowledge dis covery from telecommunication network alarm databases In 12th International Conference on Data Engineering ICDE 22296 pages 115  122 New Orleans Louisiana Feb 1996 M Holsheimer M Kersten H Mannila and H Toivonen A perspective on databases and data mining In Proceedings of the First Inter national Conference on Knowledge Discovery and Data Mining KDD\22295 pages 150  155 Mon treal Canada Aug 1995 M. Holsheimer M Kersten and A Siebes Data surveyor Searching the nuggets in parallel In U M Fayyad G Piatetsky-Shapiro P Smyth and R Uthurusamy, editors Advances in Knowl edge Discovery and Data Mining pages 447  467 AAAI Press Menlo Park, CA 1996 T Imielinski A database view on data mining Invited talk at the KDD\22295 conference M Jaeger H Mannila and E Weydert Data mining as selective theory extraction in proba bilistic logic In SIGMOD\22296 Data Mining Work shop 1996 To appear J.-U Kietz and S Wrobel Controlling the com plexity of learning in logic through syntactic and task-oriented models In S Muggleton editor Inductive Logic Programming pages 335  359 Academic Press London 1992 W Kloesgen statements in databases Infurmation Systems 4\(1  69 1995 H Mannila and K.-J Raiha Design by example An application of Armstrong relations Journal of Computer and System Sciences 33\(2  141 1986 Efficient discovery of interesting Journal of Intelligent H Mannila and K.-J Raiha Design of Relational Databases Addison-Wesley Publishing Company Wokingham UK 1992 22 H Mannila and H. Toivonen Discovering gener alized episodes using minimal occurrences Tech nical Report C-1996-12 University of Helsinki Department of Computer Science March 1996 23 H Mannila and H Toivonen. Multiple uses of fre quent sets and condensed representations Tech nical Report C-1996-13 University of Helsinki Department of Computer Science March 1996 24 H Mannila and H Toivonen On an algorithm for finding all interesting sentences In Cybernetics and Systems Research 22296 Vienna Austria Apr 1996 To appear 1251 H Mannila H Toivonen and A I Verkamo Discovering frequent episodes in sequences In Proceedings of the First International Confer ence on Knowledge Discovery and Data Mining KDD\22295 pages 210  215 Montreal Canada Aug 1995 26 C J Matheus G Piatetsky-Shapiro and D Mc Neill Selecting and reporting what is interesting In U M Fayyad G Piatetsky-Shapiro P Smyth and R Uthurusamy, editors Advances in Knowl edge Discovery and Data Mining pages 495  515 AAAI Press Menlo Park CA 1996 27 K Mulmuley Computational Geometry An Introduction Through Randomized Algorithms Prentice Hall New York 1993 28 A Savasere E Omiecinski and S Navathe An efficient algorithm for mining association rules in large databases In Proceedings of the tist Inter national Conference on Very Large Data Bases VLDB\222951 pages 432  444, Zurich Swizerland 1995 29 J W Tukey Exploratory Data Analysis Addison-Wesley Publishing Company Reading MA 1977 8 


Hei kki Mannila Biographical Summary Heikki Mannila is a professor of computer science at the University of Helsinki where he also obtained his Ph.D in 1985 Since then he has been an associate professor at the Universities of Tampere and Helsinki a visiting professor at the Technical University of Vienna, and a guest researcher at the Max Planck Institut fur Informatik in Saarbrucken He has also worked at the National Public Health Institution in Helsinki as well as being an industry consultant His research interests include data mining machine learning database design and text databases He is the co-author of the book Design of Relational Databases Addison Wesley\and he has been the author of numerous articles on algorithms, databases machine learning and data mining He is one of the editors-in-chief of the new scientific journal \223Data Mining and Knowledge Discovery.\224 9 


Figure 7 Correlations between query con straints and new indexed constraint the index attribute may have different ranges We iden tify all possible constraint introduction solutions as follows Algorithm For each constraint on the index attribute CO.Roj Step 1 find the least expensive association from a query constraint to i.e find the incoming link C~.R  CO.Roj with the fewest exceptions For exam ple if the cardinalities of El     E5 are nl   n5 and n4 5 nz _ n3 then the least expensive association for CO.R is c6.b  CO.R~,\(E  E4 Step 2 filter out all the exceptions that do not satisfy at least one of the query constraints C1.Rl    C12 We do not need to test the exceptions for the antecedent of the corresponding rule since they satisfy it by definition The constraint introduction solutions identified in our example are the following  Introduced Constraints Exceptions ele t El Cz.n,\(e    C12.nl2\(e el  E4 C1.h e    C5.nS e C~.R e     C12.nll e ele  E5 C1.nl e     C5.nS e C~.R e    C12.n12 e CO.Rol CO.RO2 CO.RO3 5 Optimizing OQL queries In the previous sections a series of algorithms were given to find a collection of constraint elimination or con straint introduction solutions In this section we show how the original query is transformed to its optimized form using the optimal solution. Consider the OQL query select x fromExtentX as x where C~.R and   and Cn 5.1 Heuristic H1 Let  Cil   Ci,},Ei  be the maintained con straints and the exceptions of a solution i Only the main tained constraints of the optimization solution should be tested on the objects of the whole extent however all the constraints should be tested on the exception cases and the objects that satisfy the maintained constraints but not the ones omitted should be removed from the result Hence the original query should be converted to the following one select x from Extent2 as x where Cil and   and Ci except Ei If we assume that tests on the query constraints take roughly the same time, the optimal solution is the one with fewest exceptions Ei 5.2 Heuristic H2 Let  Co.Roi Ei  be the index constraint and the corre sponding exceptions of a constraint introduction solution Instead of testing the query constraints C1.~l    C,.R on the entire extent Extent X we apply them only on the re sults of the subquery select x from Extent2 as x 40 where CO.R Since Co.Roi is a constraint on a cluster index attribute, the select operation is expected to be quite fast The original query is transformed to its more efficient form select x from 90 as x where Cl and    and C union Ei The exceptions Ei are merged to the result because they satisfy the query constraints but not the new index con straint Co.Roi Since the union operation is relatively cheap the optimal solution is the one that introduces the index con straint with the highest selectivity 6 Discussion We now look at two different scenarios and estimate the extent to which heuristics H1 and H2 speed up query exe cution The Jirst scenario concerns frequently executed queries Assume that the association rules which are used by algo rithm 3 are not modified We may optimize a query once at compilation time then execute its optimized form It is worth optimizing provided that the execution time of the optimized query is less than the execution time of the orig inal query For heuristic H1 this happens only if the time 132 


saved by omitting some constraints is greater than the time needed to remove the exceptions from the result except operation The more the eliminated constraints and the fewer the exceptions the better the optimization As one of the referees pointed out, the time saved by the elimina tion of constraints is CPU-related Since query execution is dominated by data access time this optimization is not expected to alter performance significantly It would help only in contexts rich in associations with few exceptions in which users express many constraints in their queries Heuristic H2 is expected to bring more significant ben efits Firstly, this optimization involves a union operation which is much cheaper than the except operation used in H1 Secondly instead of retrieving all the objects of an extent from the database we need only look at the subset retrieved through an indexed constraint Hence we save a considerable amount of data access time, spending a negli gible amount of CPU time in evaluating the additional con straint The second scenario concerns queries which are exe cuted only once In this case the time required for opti mization is significant. This time depends on the algorithm that finds associations between relaxed constraints and tight constraints \(see section 3 since this is the most expensive step in the optimization process This algorithm finds paths in a directed graph, and combines the exceptions associated with each edge of the path to derive the total exceptions for the path. Therefore its complexity is a function of i the av erage number of exceptions in the existing association rules and ii the number of different constraints found in the an tecedents and the consequents of the rules We have already implemented the algorithms for apply ing H1 the next step is to implement the corresponding al gorithms for H2 This should not be difficult since the main algorithm  finding associations between rule constraints  is common to the two heuristics We intend to set up an experimental model in order to evaluate H1 and H2 in the scenarios discussed above 7 Conclusion The use of association rules for query optimization is rel evant to both relational and object-oriented database sys tems There has been a lot of research on generating asso ciation rules and maintaining them in the presence of up dates Research has also focused on finding heuristics that take advantage of rules in order to optimize a query Most of this work 2 31 has considered integrity rules rather than association rules with exceptions Semantic optimiza tion heuristics were also applied without considering indi rect associations In this paper we implement algorithms that apply two optimization heuristics presented by Siegel et al taking account of both exceptions and indirect asso ciations We show how to use these heuristics to optimize an OQL query The complexity of the optimization process is closely related to the complexity of the constraint graph which represents the set of association rules in the data It also depends on the number of exceptions associated with each rule We have designed an experimental framework to evaluate the two optimization techniques both in the con text of queries repeated frequently over a period of time, and in the context of ad-hoc queries executed once only The re sults of this experimental work will be presented in a later paper 8 Acknowledgements We are grateful to the anonymous referees who read the paper carefully and critically and made many helpful suggestions Agathoniki Trigoni is supported by a scholar ship from the Greek Scholarships Foundation and is deeply obliged to the National Bank of Greece References I R Agrawal T Imielinski and A Swami Mining asso ciation rules between sets of items in large databases In Proceedings of the 1993 ACM SIGMOD Intl Conference on Management oj data pages 207-2 16 1993 2 U Chakravarthy J Grant and J Minker Logic-based ap proach to semantic query optimization ACM Transactions on Database Systems 15\(2 162-207 1990 3 J Grant, J.Gryz J Minker and L Raschid. Semantic query optimization for object databases In ICDE pages 444-453 1997 4 R Miller and Y Yang Association rules over interval data In ACM SIGMOD 1997 5 J Park An effective hash-based algorithm for mining asso ciation rules In ACM SIGMOD pages 175-186 1995 6 M Siegel E Sciore and S Salveter A method for auto matic rule derivation to support semantic query optimiza tion ACM Transactions on Database Systems 17\(4 600 December 1992 7 R Srikant and R Agrawal Mining quantitative association rules in large relational tables In ACM SIGMOD Intl Con ference on Management ojdata pages 1-12 1996 8 D Tsur J Ullman S Abiteboul C Clifton R Motwani S Nestorov and A Rosenthal Query flocks a general ization of association-rule mining In ACM SIGMOD Intl Conference on Management of data pages 1-12 1998 Intelligent query answering in deductive and object-oriented databases In Fourth ACM Intl Conference on Information and Knowledge Management pages 244 251 1994 IO S Yoon 1 Song and E Park Semantic query processing in object-oriented databases using deductive approach In Intl Conference on information and knowledge management pages 150-157 1995 9 S Yoon 133 



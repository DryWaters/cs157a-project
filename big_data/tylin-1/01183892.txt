Speed-up Iterative Frequent Itemset Mining with Constraint Changes Gao Cong Bing Liu School of Computing National University of Singapore Singapore 1 17543 E-mail conggao hub comp.nus.edu.sg Abstract Mining of frequenr iremsels is a fundamental dara mining rask Pasr research has proposed mny efficient algorirhms for rhe purpose Recent work also highlighred the imporrance of using consrrainrs Io focus rhe mining process ro mine only rhose relevanr itemsets In pracrice data mining is ofren an inrerocrive and irerative process The user 
rypicallv changes constraints and runs rhe mining algorirhm many rimes before sarisjed wirh rhe fi~l resulrs This inreracrive process is very rime consuming Exisring mining olgorirhms are unable ro rake advanrage of rhis iterative process lo use previous mining resulrs ro speed up rhe currenr mining process This resulrs in enormous WaSre in rime and in compurarion In rhis papsr we propose an efficient rechnique 10 urifize previous mining results ro improve rhe eficiency of currenr mining when consrrainrs ore changed We firsr inrroduce the concepr of tree 
boundav ro summarize the useful informorion avoilable from previous mining We rhen show rhar the free boundary provides an gffecrive and efficienr framework for rhe new mining The proposed technique has been implemenred in the conrexrs of rwo existing frequent iremser mining algorirhms FP-tree and Tree Projection Erperimenr resulrs on horh syntheric and real Ire darasers show rhnr rhe proposed approach achieves dromaric saving in compurarion 1 Introduction Frequent itemset mining plays an essential role in mining association rules 131 correlations sequential patterns maximal patterns 4 etc Although many 
efficient algorithms 13 16 1 91 have been developed mining of frequent itemsets remains to be a time consuming process IO especially when the data size is large To make the matter worse in most practical applications the user often needs to run the mining algorithm many times before satisfied with the final results In each prxess the user typically changes some parameters or constraints Considering a mining task with only the minimum supporr constraint also called the frequency constraint the user may initially set the minimum support lo 5 and a mining algorithm After inspecting the returned 0-7695-1754-4/02 17.00 0 2002 
IEEE 107 results she finds that 5 is too high She then decides to reduce the minimum suppon to 3 and runs the algorithm again Usually this process is repeated many times before she is satisfied with the final mining results This interactive and iterative mining process is very time consuming Mining the dataset from scratch in each iteration is clearly inefficient because a large portion of the computation from previous mining is repeated in the new mining process This results in enormous waste in computation and time So far limited work has been done to address this problem and to the best of our knowledge there 
is still no effective and efficient solution In recent years many constraints apan from the traditional suppon and confidence constraints are introduced into frequent itemset mining in order to find only those relevant itemsets 13 IO 121 On one hand these additional constraints give the user more freedom to express hisher preferences On the other hand, however it often prolongs the mining process because Ihe user may want to see the results of various combinations of constraint changes by running the mining algorithm more times This makes mining using previous results for efficiency even more imponant Constraint changes can mean righrening consrrainrs and 
relaxing consrrainrs Let us use an example to start the discussion Example Consider that one sets the constraint that the average price of the items in an itemset is less than 100 in the old mining process for a market basket problem After inspecting the mining results one finds that the results are not satisfactory There are possible two reasons 1 100 is too low many useful itemsets may not be discovered and 2 100 is too high too many itemsets are generated One may wish to change the average price to 150 or to 80 for the new mining The question is 223can we make 
use of the results from the old mining to speed up the new mining?\224 It is straightfonvard to answer pan of the question i.e when constraints are righzened the solution space is reduced e.g when the average price of frequent itemsets is decreased To obtain the new set of frequent itemsets under the new constraints we can simply check the frequent itemsets from the old mining to filter out those itemsets that do not satisfy the new constraints This filtering process is sufficient because the set of new frequent itemsets is only a subset of the old set When constraints are relared the solution space is 


expanded the problem becomes non-trivial as re-running the mining algorithm is needed to find those additional frequent itemsets For instance in the above example when the average price of frequent itemsets is increased more itemsets may be generated The problem becomes even more complicated when multiple constraints are changed at the same time The objective of this work is to study how to make use of the previous mining results to speed up re-mining when constraints are changed In this paper we propose a novel technique to solve this problem Using the relaxation of frequency constraint the decrease of minimum support as an example we first propose the concept of free bounday to summarize and to reorganize the previous mining results We then show that the additional frequent itemsets can be generated in the new mining process by extending only the itemsets on the free boundav without re-generating the frequent itemsets produced in the previous mining note that our tree boundary based technique is quite different from the incremental mining approaches based on negative border The proposed technique has been implemented in the contexts of two frequent itemset mining algorithms FP tree 191 and Tree Projection I This results in two augmented itemset mining algorithms RM-FP re-mining using FP-tree and RM-TP re-mining using Tree Projection Extensive experiments on both synthetic data and real-life data show that RM-FP and RM-TP dramatically outperform FP-tree and Tree Projection algorithm respectively Finally we also address how the proposed technique can be applied to handle the changes of other types of constraints given in previous studies  13 10 121 2 Related work Frequent itemset mining has been studied extensively in the past e.g in 3 16 1.9 15 4.51 Most current algorithms are variations of the Apriori algorithm 131 They use support-based generate-and-test approach to find all the frequent itemsets Recently some tree-based algorithms were also proposed e.g the FP-tree algorithm 191 which is based on the frequent pattern tree and Tree Projection algorithm I which is based on the lexicographic tree Both algorithms do not strictly follow the Apriori-like candidate generate-and-test approach and were shown to be more efficient than the Apriori algorithm 3 Since  I31 first introduced item constraints to produce only those useful itemsets, many other types of constraints have been integrated into itemset mining algorithms IO 121 Although many efficient algorithms for mining frequent itemsets with constraints exist user interaction is at the minimum level To remedy this situation IO proposes to establish breakpoints in the mining process to accept user feedback to guide the mining Furthermore online association rule mining also allows the user to increase minimum suppon during the mining process 121 However 121 does not allow decreasing of minimum support Similarly the suppon threshold used in Ill for incremental and interactive sequence pattern mining can also be increased but not decreased The closely related work to ours is the incremental mining where the concept of negative border proposed in I611 is utilized to update the mining results when additional data becomes available 14 15 8 Ill A negative border consists of all the itemsets that are candidates of the Apriori algorithm that do not have sufficient support Although the methods in 14 15 81 only need one scan of the updated dataset they could not avoid the disadvantage of negative border i.e maintaining a negative border is very memory consuming and is not well adapted for very large databases I I The approach in 14 15 81 seemingly can be adapted for handling constraint relaxation  151 actually mentions the possibility but no detailed algorithm is proposed However one significant shortcoming of the approach is that generating candidates under new constraints using the negative border under old constraints usually result in over-generation of a huge number of useless candidates This makes the approach in  14 15 81 impractical for our constraint relaxation problem for large datasets especially when the minimum support is low For example if 10\222 frequent itemsets are obtained given minimum support of 1 and 50 I-itemsets become frequent after minimum support is reduced to 0.9 the number of candidate itemsets generated using the above approach is 2s0-l  10\224 even if we do not consider the expansions of I frequent itemsets themselves This is clearly impractical FUP in 161 is another incremental mining method that follows the Apriori framework FW is not for mining with constraint changes If it is applied to our task it basically re-runs the Apriori algorithm without re-counting the supports of those itemsets generated previously they still need to be re-generated The computation saving is thus very limited if any because of some overheads see 7 for more details 3 Problem statement Let I be the set of all items and r be a transaction database Each transaction in r consists of a subset of items in 1 Let S r 0 be an itemset The supporl of S denoted by Supporr\(S is defined as in 31 Given a minimum support MinSup an itemset S is frequenl in rif Supporr\(S 2 MinSup With a transaction set r and a MinSup the problem of frequenl ilemsel mining is to find the complete set of frequent itemsets in C Constraints can be imposed on both itemset S itself and its attributes e.g price type etc in frequent itemset mining There are many types of constraints that can be imposed on frequent itemset mining Four categories of 108 


constraints anti-monotone monotone succinct and convertible constraints have been effectively integrated into some mining algorithms IO 121 Iterative mining of frequent iternsets with constrain changes Given a transaction database K the whole process of iterative and interactive mining of frequent ilemsels with constraint changes is captured with the following iterative steps I 2 run the mining algorithm 3 specify the initial set of constraints SC check the returned results to determine whether they are satisfactory If so the mining process ends Otherwise the user changes one or more constraints in SC including deletion and addition of constraints and the process then goes to 2 I and 3 will not be discussed further in the paper as it is the user\222s responsibility to devise and to change constraints Our objective is to design a framework for the mining algorithm in 2 so that it is able to leverage on the mining results from the previous mining iteration to improve the efficiency of the current mining and consequently speed up the whole data mining process Conslrainl changes Change of a constraint includes two cases 1 Tighten the constraint The solution space is reduced For example when the minimum support is increased 2 Relax the constraint The solution space is expanded. For example the minimum suppon is decreased Constrain1 changes mean changes to one or several constraints in a set of predefined constraints The changes cover deletion or addition of constraints Adding a new constraint corresponds to tightening the constraint while deleting an existing constraint corresponds to relaxing the constraint As discussed earlier if a constraint Cis tightened to C the set of itemsets that satisfy the new constraint C\222is only a subset of the itemsets that satisfy the old constraint C Thus the set of itemsets that satisfy C\222can be obtained by filtering the set of itemsets that satisfy C The challenge comes when a constraint C is relaxed to C The set of itemsets that satisfy the old constraint Cis only a subset of ihe itemsets that satisfy the new constraint C The problem is how to efficiently discover the set of itemsets F that satisfy the new constraint C\221but not the old constraint C The rest of the paper focuses on this problem We also study how to utilize the previous mining results to efficiently discover the set of itemsets when multiple constraints are changed at the same time 4 The proposed technique We use the minimum support constraint as an example to present the proposed technique for finding the set of itemsets F that satisfy the new but not the old minimum support when the minimum support is reduced relaxed from one mining process to the next The relaxation problems of the other constraints can be solved within the proposed framework to be discussed in Section 7 although the technical details may vary Let MinSup be the minimum support used in the previous or old mining and MinSup be the relaxed or new minimum suppon This section first introduces the useful information that can be obtained from the previous mining process using a tree-based itemset mining framework The reason that we use a tree-based framework will become clear later We then describe a method to represent the old information for the purpose of mining under MinSup Next we present a nayve approach and the proposed technique for discovering the set of itemsets F that are frequent under MinSup but not MinSup,~d 4.1 Useful information from previous mining After running a mining algorithm using MinSup we find the set of frequent itemsets One byproduct of the process is the set of itemsets that are checked against MinSupOld supports are counted but are not frequent Let 4 be the set of frequent itemsets under MinSup and Lg be the set of itemsets that are counted but found infrequent the byproduct Although all frequent itemset mining algorithms generate the same set 4 the set of infrequent itemsets L6 checked in the process varies according to algorithms Algorithms such as those in 4 1 91 do not strictly follow the candidate generation of Apriori-like algorithms 3 16 IO Instead they are based on some kinds of tree We classify these algorithms as tree-based algorithms Tree-based algorithms will count the support of an itemset S  i i2  ik if two proper subsets of S namely S  i  ik.2,ik.,J and i  ib2.ill.arefrequent We use tree-based mining algorithms as the underlying mining framework of our proposed technique because tree based mining algorithms give us sufficient information while Apriori-like algorithms do not see the end of the Section 1,9 also show that tree-based algorithms are actually more efficient in many cases As in I we use a lexicographic tree to represent the set of frequent itemsets 4 Given the set of items I it is assumed that a lexicographic order R exists among the items in 1 The order R is important for efficiency and for the organization of mining results We use the notation i CL j to denote that item i occurs lexicographically earlier than j Definition 4.1 Lexicographic Tree A node in a lexicographic tree corresponds to a frequent itemset The root of the tree corresponds to the null itemset We extend Definition 4.1 to also represent those itemsets in Lf with a lexicogaphic tree An example lexicographic tree is shown in Figure 1 Those nodes enclosed in circles are frequent itemsets under MinSup 109 


but not MinSupOu which ate in F Those nodes enclosed by dotted squares are the itemsets in L that are not frequent under either MinSupOu or MinSup The other nodes are itemsets that are frequent under both MinSup,u and MinSup Let P and Q be two itemsets and Q be the parent of P Definition 4.2 Tree Extensions A frequent I extension of an itemset such that the last item is the contributor to the extension is called a tree extension The list of tree extensions of a node P is denoted by E\(P Figure 1 A lexicographic tree In Figure 1 under MinSupou the list of tree extensions of node 3 E\(3  4,6 Delinition 4.3 Candidate Extensions The list of candidate extensions of a node P is defined to be those items in E\(Q that occur lexicographically after the node P We denote the list by C\(P Note that E\(P is a subset of CP Items in C\(P are possible frequent extensions of P Under MinSup the tree extensions of null node E\(nul1  c3.4 5 6.7 note that 2 is not frequent under MinSup,,d and the candidate extensions of node 3 C\(3  4,5,6,7 4.2 Extensions of lexicographic tree This subsection extends the lexicographic tree with some new conceptions. which will be used in our proposed technique Definition 4.4 Infrequent Borders If a I-extension i of iternset Pis not frequent i is called an infrequent border The list of infrequent borders of a node P is denoted by IB\(P We have the relationship IB\(P  C\(P  E\(P In Figure I under MinSupou the infrequent borders of node 3 R\(3  5,7 Definition 4.5 New Tree Extensions If itemset P U i i E B\(P becomes frequent after MinSup is reduced from MinSup to MinSup i is called a new tree extension of node P w.r.1 MinSup The list of new tree extensions of node P W.T.I MinSup is denoted by NTE\(P In Fiaure I the list of new tree extensions of node 3  w.r.1 MinSup,,,NTE\(3  5,7 For any frequent itemset P can be null under MinSup its tree exfernions E\(P and infrequenf borders R\(P are stored for mining under MinSup Its new tree extensions NTE\(P w.r.1 MinSup can be obtained by checking the list of infrequent borders of P B\(P Under MinSupOu the set of tree exlensions of all frequent tree nodes makes up 4 and the set of infrequent borders of all frequent nodes in the tree makes up Lw 4.3 A naive approach With the two sets 4 and Lb from the mining under MinSup,u we first look at a naive approach to making use of previous mining results for the new mining We then present the proposed approach based on tree boundary The naive approach checks all itemsets in L,and Lfone by one to find the change of their candidate extensions under MinSup and to extend them to obtain the complete set F in which itemsets are frequent under MinSup hut not MinSup Figure 2\(a shows the children itemsets of null node and the children itemsets of itemset 3 in the naive approach To make the figure manageable we assume that itemset 3 8 is frequent under MinSup but 4 81 5 8 6.81 and 7,8 are not Candidate extensions of each node are shown under the node in Figure 2\(a The only saving in the new mining is that we can utilize the count information saved previously for those itemsets in band Lv However this saving in computation is very limited in a tree-based algorithm Thus the computation is basically the same as re-mining from scratch In tree-based algorithms the main computation co'lres from the generation of projected transactions for each node Project transactions for an itemset S are the set of transactions containing S Tree-based algorithms use this sub transaction set for counting support and for all subsequent itemset containing S generations This naive approach still requires the same computation to generate the projected transactions as running a tree-based algorithm from scratch For instance in Figure 2\(a\we still need to create projected transactions for 3 to count the support for itemset 3 8 although the supports of its other children itemsets 3 4 3 51 3 6 and 3 7 are known previously the projected transactions for 3 are also used to generate the projected transactions for children itemsets of 13 Similar computation is required for creating projected transactions for 21 3 41 51 6 and 7 Another shortcoming of the naive approach is that it cannot avoid re-generating itemsets in I because they need to be extended in the new mining For example in Figure 2\(a\itemsets 3 4 5 6 and 7 still need to be generated to check whether item 8 is in their tree extensions although their supports are already counted in previous mining 110 


a The naive approach b Our approach with lreeboundary Figure 2 Pam of mining results under MinSup Based on the above discussion we see that saving by the naive approach is limited It is thus not efficient 4.4 The proposed approach Definition 4.6 Tree Boundary A tree boundaly w.r.r MinSup is defined to be the set of itemsets TB  rb I rb E Lg Supporr\(rb 5 MinSup where Lg is the set of counted but infrequent itemsets under MinSup,,d and Supporr\(rb is the supporr of itemset fb For example the itemsets on the dotted line shown in Figure I make up the free boundary w.r.1 MinSup Itemsets I and 3 4 6 are not in TB although they are in Lf because they are not frequent under MinSup Our proposed approach discovers the complete se1 of F by extending only the itemsets on the free boundary The basic idea is to eliminate the effect of MinSup decrease on itemsets in L i.e no itemset will he extended if it has been extended in previous mining This is achieved by changing the order of rree exrensions of every node including the null node in L,\(under MinSup,,d Let S be null node or any itemset in Lp Tree extensions of S under MinSup denoted by E contains two parts tree extensions of S under MinSupOM EoIASp e.g., EOld\(3  4,6 and new tree extensions of S w.T MinSup NTE\(S e.g hTE\(3  5.7 We change the item order of E.,\(S as follows move items from the new tree extensions hTE\(S to the front of the old tree extensions of S under MinSupOl Eo For example in Figure I we change the tree extensions of null under MinSup from 4 3,4,5 6.7.8 to 2 8 3 4,5,6.7 With the new ordering for a child itemset of S such that S  S U il where i E E&,SJ S E 4 the candidare exlensions of S are the same under MinSup and MinSup For a child itemset of S such that S  Sou 1 where i E hTE\(S the candidare exrensions of S consists of I those items j such that i Sj where j E hTE\(S and 2 those items j j E E Due to the re-ordering candidate extensions of the itemsets in L are not affected For instance after we change the tree extensions of null node under MinSup into 2 8 3 4 5 6 7 the tree extensions of itemsets 31 41 51 61 and 7 under MinSup are the same with those under MinSup,,d The tree extensions of itemset 8 become 3 4 5 6 7 from 0 under MinSup We compute the projected transactions for itemset 8 to decide whether items 3,4,5,6 and 7 are tree extensions of 81 There is no need to compute projected transactions for 31 41 51 6 and 71 they were computed in previous mining Another example is given in Figure 2\(b which shows the corresponding pan of Figure 2\(a in our approach After we change the order of tme exieiisions of null node there is no need to extend itemsets 3 41 5 6 and 71 with 8 We change tree extensions of itemset 3 from 4 5 6 7 to 5 7 4 6 The candidate extensions of node 3 5 are 4 6 7 The candidate extensions of node 13 71 are 4 6 As a result we only need to compute projected transactions for itemsets 3 5 1 and 3 7 which are not computed in previous mining\while the naive approach needs to compute projected transactions for itemsets 3,41 3.51 3.61 and 3.7 Notice that those itemsets on the rree boundary whose candidate extensions are empty can be removed from the free boundary e.g itemsee 4,5,7 and 5.7 in Figure 1 Let us summarize the advantages of our free boundary based extension with ordering change I Our approach is able to avoid the computation of counting the suppons of itemsets in 4 and L We do not re-generate the itemsets in L to extend them in,the new mining process 2 Our approach is able to avoid the generation of projected transactions that were done in previous mining while the naive approach is unable to The ordering change is the key of our technique It also brings some additional benefits when integrating tree based algorithms with free boundary Refer to 7 Now let us prove the correctness and completeness of free boundary approach 111 


Property 4.1 Given free boundary TB w.r.f MinSup extending the itemsets in TB is able to generate the complete set of itemsets F frequent under MinSup but not MinSupOld Interested readers can refer to  for proof Remark In Apriori-like algorithms previous mining results under MinSup do not provide sufficient information to build the free boundary for re-mining under MinSup Moreover even if we could build a free boundary Apriori-like algorithms could not be easily modified to extend itemsels on free boundary to discover F Interested readen can refer to 71 for proof 5 Tree boundary based re-mining We realized the proposed technique using the FP-tree frequent itemset mining and the Tree Projection algorithms The algorithm using FP-tree is called Re Mining using FP-tree \(in short RM-FP and the algorithm using Tree Projection is called RM-TP Re-Mining using Tree Projection Interested readers can refer to 7 for the algorithms RM-FP and RM-TP 6 Experimental evaluation This section presents performance comparison of FP tree algorithm with RM-FP on both synthetic and real-life data sets The comparison of Tree Projection algorithm with RM-TP achieves similar results and is given in 171 All experiments are performed on a 750-Mhz Pentium PC with 512 MB main memory running on Microsoft Windows 2000 All the programs are written in Microsoft Visual C 6.0 The synthetic datasets were generated using the procedure described in 31 We repori experiments results on two synthetic datasets One is T25.120.DZOOk 191 with IK items which is denoted as D1 In D1 the average transaction size and the average maximal potentially frequent itemset size are 25 and 20 respectively The number of transactions is 2M The other dataset is T20.16.DIOOk 3 also with IK items denoted as D2 We also tested our approaches on two real-life datasets obtained from the UC-lrvine Machine Learning Database Repository\(hnp:Ilwwwicsuci.edu/-mleamlM1  One is the Connecr-4 dataset the other is the Mushroom dataset Figures 3 and 5 show the comparisons of RM-FP with F\200-tree algorithm on datasets DI and Connect-4 In the curves for RM-FP the CPU time for each point except the first point is obtained by running RM-FP with the value of that point as MinSup based on the previous mining results under MinSupou just before that point For example in Figure 3 the CPU time of RM-FP at MinSup  1.75 is based on the old mining results with MinSupOl  2 and the CPU time for RM-FP at Midup  1.5 is based on the old mining results with MinSup,,,I  1.75 and so on Note that when MinSup of RM-FP is the same as MinSupOld of the previous mining e.g at MinSup  2 in Figure 3 the extra running time of RM-FP against FP-tree shows the overhead of RM-FP to output itemsets in 4 The time is very small as shown in Figures 3-9 The results on D2 and Mushroom are not shown due to space limitations Actually readers can see them based on Figures 7 and 9 From Figures 3 and 5 we observe that RM-FP is able to save more than 40 running time of FP-tree in each iteration The saving is very significant in practice In fact RM-FP can achieve even better results if the decrease of MinSup is smaller in each iteration as shown in Figure 4 In Figure 4 the MinSup is reduced by 10 each time \(the decrease is smaller than that in Figures 3 and 5 At each point, again RM-FP is run based on the mining results of the previous point except for 2 In each iteration we can save more than 70 of the running time More performance curves on datasets DI D2 Mushroom and Connecr-4 are given in Figure 6 7 8 and 9 respectively In Figure 6 RM-FP was run based on the initial mining results of the FP-tree algorithm with MinSupOm  2 1.5 and 0.75 In each case a few decreased MinSup values are used In Figure 7 RM-FP was run based on the mining results of MinSup  2 I and 0.5 In Figure 8 RM-FP was Nn based on the mining results of MinSup  60 50 and 45 we use very high minimum suppon because the dataset is very dense In Figure 9 RM-FP was mn based on the mining results at MinSupOld  2 I and 0.5 In each of these figures we show results with different MinSup values All the experiments show that RM-FP consistently outperfoms the FP-tree algorithm even when MinSup drops to a very low level from a very high level. Using the same initial old\mining results we observe that the lower the MinSup is in the new mining the smaller is the percentage of saving in computation This is clear because the number of frequent itemsets at MinSup is much larger than the number of itemsets in L,from old mining For example for D2 the discovered frequent itemsets at 2 is 381 while the number at 0.15 is 558.834 However in practice the user typically will not reduce the MinSup so drastically from one mining process to the next For example in most cases it is quite unlikely that the user uses MinSup  2 first and then changes it to MinSup  0.15 suddenly for the next mining. Instead the decrease each time is usually small as in the cases of Figures 3.4 and 5 Note that in Figure 9 RM-FP based on I support takes more time than RM-FP based on 2 support at MinSup  0.75 This is because the time used to check previous mining results offsets pan of the benefit from utilizing previous mining results when the previous mining results are very large 112 


 him F E 0 20  i  I O I 1 0.71 0.5 0.3 0.2 0.1 The scalability experiments are conducted by increasing the number of transactions on dataset DI As shown in Figure IO both FP-tree and RM-FP have linear scalability with the number of transactions but RM-FP is more scalable 7 Application to other constraints This section shows that the proposed approach is also applicable to discovering the set F when any other single or multiple constraints are changed The detailed techniques for handing changes of these constraints differ We only present methods for dealinn with the channe of 7.1 Dealing with Individual Constraint Changes We discuss the methods for discovering the set F when a single constraint is changed Method 1 Filtering previous mining results The set F can be obtained by filtering previous results in the following two cases I tightening of a constraint of any kind 2 relaxation of a convertible monotone or monotone constraint Method 2 Tree boundary based re-mining This method as discussed in Section 4 applies to the relaxation of a convertible anti-monotone or anti monotone constraint although it is a bit different when individuai constraints and multiple ckaints intuitl'vely Interested readers may refer to our technical report 7 for additional details and examples applying 10 anti-monotone c&traint relaxation due to the special property of convertible constraints 7 Method 3 Simpler tree boundary based re-mining Tree boundav in this method is easier to devise than 113 


that for Method 2 and usually contains only I-itemsets It applies to the relaxation of a succinct and anti-monotone constraint or a succinct and monotone constraint When one of such constraints is relaxed it can be dealt with as follows Let E\(nul1 be the list of frequent items that satisfy the old constraint By checking the old mining results we first find the list of frequent items NTE\(nul1 that satisfy the new constraint hut not the old constraint Itemsets made of individual items in NTE\(nul1 make up the tree boundary Table 1 Handling the change of two combined constraints 7.2 Dealing with multiple constraint changes Although users usually change one constraint at a time to see the effect of the change it is also possible that multiple constraints are changed at the same time Table 1 shows the methods for discovering  F when two constraints are changed at the same time Most of the combined cases can be handled by combining the approaches to handling the change of individual constraints For example tightening a succinct  anti monotone constraint and relaxing a succinct  monotone constraint requires Method I handling the tightening and 3 handling the relaxation Interested readers can refer to 7 for the meanings of those exceptional cases including 223Adapted 223Violates\224, \223Depends\224 and 223-\224 Finally, when more than two constraints are changed at the same time they can be handled by combining the methods for their respective changes in consideration of the exceptional cases in table I 8 Conclusions Practical data mining is often a highly interactive and iterative process Users change constraints and tun the mining algorithm many times before satisfied with the final results. Current mining algorithms are unable to take advantage of the previous mining results to speed up the new mining process Motivated by this problem and using the minimum support constraint as an example this paper first proposed the concept of tree boundary to summarize and reorganize the previous mining results It then presents an effective and efficient framework for re-mining under the reduced minimum suppon Experiment results demonstrate that the proposed technique is highly effective Finally we also show that when any other individual constraint is changed or multiple constraints are changed at the same time the new set of frequent itemsets can also he mined efficiently using the proposed technique References I R Aganval C Agganual and V Prasad A Tree Projection algorithm for generation of frequent iemsets In 1 Pdlel and Distributed Computing 2000 2 C Agganval and P Yu Online generation of association N~S In Proc of 14\224 ICDE 1998 3 R Agrawal and R Srikanf Fast algorithm for mining msociation rules In Roc of the 20\224 VLDB 1994 4 R I Bayardo Efficiently mining long patterns from database In Pmc of the SIGMOD 1998 151 A Bykowski C Rigotti A condensed represenlation to find frequent patterns In Proc of PODS 2001 61 D W Cheung J Han V Ng and C.Y Wong Maintenance of discovered association rules in large databases An incremental updating technique In Pm of ICDE 1996 7 G Cong B Liu Interactive mining of frequent itemsets with constraint changes. Technical report National Univ of Singapore 2002 E R Wldman Y Aumann A Amir. and H Manila Efficient algorithm for discovering frequent sds in incremental databases In Zna SIGMOD workshop DMKD 1997 9 J Han 1 Pei and Y.Yin Mining Frequent Panerns without Candidate Generation In SIGMOD ZWO IO R Ng L.V.S Lakshrnanan, J.Han, and A.Pang Exploratory mining and pruning optimizations of constrained associatian rules In Proc of SIGMOD, 1998 I I S Pmhasmfhy M J Zaki M Ogihara and S Dwarkadas Incremental and interactive sequence mining In Pmc of the 8th CIKM Kansas City MO USA November 1999 I21 J Pei 1 Han and L.V.S.Lakshmanan Mining frequent itemsets with convertible constraints In Pm ICDE 2001 I31 R Srikant Q Vu and R Agrawd Mining associalion tules with item constraints In Pm of KDD CA 1997 I41 S Thomas S Chakravmhy Incremental mining of constrained associations In HiPCZWO I51 S Thomas S Bodagala K Alsabti and S Ranka An efficient algorithm for the incremental updation of association rules in large databases In hoc KDD 1997  161 H Toivonen Sampling large databases for association rules In hoc of the 22th VLDB 1996 114 


of the query expression without ha ving the global view of the in ten tion There is a big c hance that the enco ded pro cedure ma y not b e the b est w a y to compute the rules dep ending on the database instance F urthermore as w e understand it their prop osals require p oten tially large n um ber of name generation for relations and attributes The names that are needed are usually database dep enden t and th us p ossibly cannot b e gathered at query time An additional pro cess needs to b e completed to gather those v ariables b efore actual computations can b egin 5  9 Optimization Issues While it w as in tellectually c hallenging to dev elop a declarativ e expression for asso ciation rule mining from deductiv e databases there are sev eral op en issues with great promises for resolution In the w orst case the least xp oin tneedsto generate n 2 tuples in the rst pass alone when the database size is n  Theoretically  this can happ en only when eac h transaction in the database pro duces an in tersection no de and when they are not related b y subset-sup erset relationship In the second pass w e need to do n 4 computations and so on The question no w is can w e a v oid generating and p erhaps scanning some of these com binations as they will not lead to useful in tersections F or example the no de b 0 3 in gure 11 is redundan t A signican t dierence with apriori lik e systems is that our system generates all the item sets top do wn in the lattice without taking their candidacy as a large item set in to consideration Apriori on the other hand do es not generate an y no de if their subsets are not large item sets themselv es and thereb y prunes a large set of no des Optimization tec hniques that exploit this so called an ti-monotonicit y prop ert y of item set lattices similar to apriori could mak e all the dierence in our setup The k ey issue w ould b e ho ww e push the selection threshold minim um supp ort inside the top do wn computation of the no des in the lattice in our metho d F or the momen t and for the sak e of this discussion let us consider a higher supp ort threshold of 60 for the database T of gure 9 No w the l-en v elop e will b e the one sho wn in ligh ter dashed lines in gure 11 and the no des under this line will b e the large item sets Notice that no ww eha v eto discard no des ad 2 0 and d 0 2 to o This raises the question is it p ossible to utilize the supp ort and condence thresholds pro vided in the query and prune candidates for in tersection an y further Ideas similar to magic sets transformation 3  24 ma y be b orro w ed to address this issue The only problem is that pruning of an y no de dep ends on its supp ort coun t whic h ma y come at a later stage By then all no des ma y already ha v e b een computed and th us pushing selection conditions inside aggregate op erator ma y b ecome non-trivial Sp ecial data structures and indexes ma y also aid in dev eloping faster metho ds to compute ecien t interse ction joins that w e ha v e utilized in this pap er W e lea v e these questions as op en issues that should be tak en up in the future F ortunately though there has been a v ast b o dy of researc h in optimizing Datalog programs including recursiv e programs suc h as the one w e ha v e used in this pap er and hence the new questions and researc h 5 Recall that their prop osal requires one to express the mining problem to the system using sev eral queries and up date statemen ts that utilizes information ab out the database con ten ts to ac hiev e its functionalit y  c hallenges that this prop osal raises for declarativ e mining ma y exploit some of these adv ances Needless to emphasize a declarativ e metho d preferably a formal one is desirable b ecause once w e understand the functioning of the system w e will then be able to select appropriate pro cedures dep ending on the instances to compute the seman tics of the program whic hw e kno wis in tended once w e establish the equiv alence of declarativ e and pro cedural seman tics of the system F ortunately  w e ha v e n umerous pro cedural metho ds for computing asso ciation rules whic h complemen t eac h other in terms of sp eed and database instances In fact that is what declarativ e systems or declarativit y buy us  a c hoice for the most ecien t and accurate pro cessing p ossible 10 Conclusion Our primary goal for this pap er has b een to demonstrate that mining asso ciation rules from an y rst-order kno wledge base is p ossible in a declarativ ew a y  without help from an y sp ecial to ols or mac hinery  and that w e can no wha v ea v ery in tuitiv e and simple program to do so W eha v esho wn that it is indeed p ossible to mine declarativ ekno wledge b y exploiting the existing mac hinery supp orted b ycon temp orary inference engines in programming languages e.g Prolog or kno wledge base systems e.g RelationLog XSB LD L  CORAL All w e require is that the engine b e able to supp ort set v alued terms grouping aggregate functions and set relational op erators for comparison functionalities whic hmostofthesesystemscurren tly supp ort W e ha v e also demonstrated that our formalism is grounded on a more mathematical foundation with formal prop erties on whic h the seman tics of the R ULES system rely  W e ha v e also raised sev eral op en issues related to eciency and query optimization whic h should b e our next order of business As future researc h w e plan to dev elop optimization tec hniques for mining queries that require non-trivial lo ok ahead and pruning tec hniques in aggregate functions The dev elopmen ts presen ted here also ha v e other signican t implications F or example it is no w p ossible to compute c hi square rules 4 using the building blo c ks pro vided b y our system Declarativ e computation of c hi square rules to our kno wledge has nev er b een attempted for the man y pro cedural concepts the computation of c hi square metho d relies on In a separate w ork 2 w e sho w that the coun ting metho d prop osed in this pap er can be eectiv ely utilized to generate the exp ectations needed in order to compute suc h rules rather easily  These are some of the issues w e plan to address in the near future The motiv ation imp ortance and the need for in tegrating data mining tec hnology with relational databases has b een addressed in sev eral articles suc h as 12  13 They con vincingly argue that without suc h in tegration data mining tec hnology ma y not nd itself in a viable p osition in the y ears to come T o b e a successful and feasible to ol for the analysis of business data in relational databases suc htec hnology m ust b e made a v ailable as part of database engines and as part of its declarativ e query language Our prop osal for declarativ e mining bears merit since it sheds ligh t on ho w rst order databases can be mined in a declarativ e and pro cedure indep enden t w a y so that the optimization issues can b e delegated to the underlying database engine Once suc h argumen ts are accepted sev eral systems 9 


related issues b ecome prime candidates for immediate atten tion F or example traditionally database systems supp orted declarativ e querying without the necessit y to care ab out the pro ceduralit y of the queries In this pap er w eha v e actually demonstrated that asso ciation rule mining can b e view ed as a Datalog query  It is immediate that a direct mapping from the Datalog expressions presen ted in this pap er to SQL can be dev elop ed with no problem at all W e can then rely on ecien t database pro cessing of the query in an optimized fashion Hence w ecomeclose to the essence of the visions expressed b y the leading database researc hers and practioners 12  References 1 Rak esh Agra w al and Ramakrishnan Srik an t F ast algorithms for mining asso ciation rules in large databases In VLDB  pages 487{499 1994 2 Anon ymous A declarativ e metho d for mining c hisquare rules from deductiv e databases T ec hnical rep ort Departmen t of Computer Science Anon ymous Univ ersit y USA F ebruary 2001 3 C Beeri and R Ramakrishnan On the po w er of magic In Pr o c e e dings of the 6th A CM Symp osium on Principles of Datab ase Systems  pages 269{283 1987 4 Sergey Brin Ra jeev Mot w ani and Craig Silv erstein Bey ond mark et bask ets Generalizing asso ciation rules to correlations In Pr o c A CM SIGMOD  pages 265 276 1997 5 D Chimen ti et al The LD L system protot yp e IEEE Journal on Data and Know le dge Engine ering  2\(1 90 1990 6 Jia w ei Han Jian P ei and Yiw en Yin Mining frequen t patterns without candidate generation In Pr o c A CM SIGMOD  pages 1{12 2000 7 Marcel Holsheimer Martin L Kersten Heikki Mannila and Hann uT oiv onen A p ersp ectiv e on databases and data mining In Pr o c of the sixth A CM SIGKDD Intl Conf  pages 150{155 Mon treal Queb ec 1995 8 Flip Korn Alexandros Labrinidis Y annis Kotidis and Christos F aloutsos Ratio rules A new paradigm for fast quan tiable data mining In Pr o c of 24th VLDB  pages 582{593 1998 9 Brian Len t Arun N Sw ami and Jennifer Widom Clustering asso ciation rules In Pr o c of the 3th ICDE  pages 220{231 1997 10 Mengc hi Liu Relationlog At yp ed extension to datalog with sets and tuples In John Llo yd editor Pr oc e e dings of the 12th International L o gic Pr o gr amming Symp osium  pages 83{97 P ortland Oregon Decem ber 1995 MIT Press 11 Rosa Meo Giusepp e Psaila and Stefano Ceri An extension to SQL for mining asso ciation rules Data Mining and Know le dge Disc overy  2\(2 1998 12 Amir Netz Sura jit Chaudh uri Je Bernhardt and Usama M F a yy ad In tegration of data mining with database tec hnology  In Pr o c e e dings of 26th VLDB  pages 719{722 2000 13 Amir Netz Sura jit Chaudh uri Usama M F a yy ad and Je Bernhardt In tegrating data mining with SQL databases In IEEE ICDE  2001 14 Ra ymond T Ng Laks V S Lakshmanan Jia w ei Han and Alex P ang Exploratory mining and pruning optimizations of constrained asso ciation rules In Pr o c A CM SIGMOD  pages 13{24 1998 15 Jong So o P ark Ming-Sy an Chen and Philip S Y u An eectiv e hash based algorithm for mining asso ciation rules In Pr o c A CM SIGMOD  pages 175{186 1995 16 Karthic k Ra jamani Alan Co x Bala Iy er and A tul Chadha Ecien t mining for asso ciation rules with relational database systems In Pr o c e e dings of the International Datab ase Engine ering and Applic ations Symp osium  pages 148{155 1999 17 R Ramakrishnan D Sriv asta v a and S Sudarshan CORAL  Con trol Relations and Logic In Pr o c of 18th VLDB Confer enc e  pages 238{250 1992 18 Konstan tinos F Sagonas T errance Swift and Da vid Scott W arren XSB as an ecien t deductiv e database engine In Pr o c of the A CM SIGMOD Intl Conf  pages 442{453 1994 19 Sunita Sara w agi Shib y Thomas and Rak esh Agra w al In tegrating mining with relational database systems Alternativ es and implications In Pr o c A CM SIGMOD  pages 343{354 1998 20 Ashok a Sa v asere Edw ard Omiecinski and Shamk an tB Nav athe An ecien t algorithm for mining asso ciation rules in large databases In Pr o c of 21th VLDB  pages 432{444 1995 21 Pradeep Sheno y  Ja y an t R Haritsa S Sudarshan Gaura v Bhalotia Ma y ank Ba w a and Dev a vrat Shah T urb o-c harging v ertical mining of large databases In A CM SIGMOD  pages 22{33 2000 22 Abraham Silb ersc hatz Henry F Korth and S Sudarshan Datab ase System Conc epts  McGra w-Hill third edition 1996 23 Shib y Thomas and Sunita Sara w agi Mining generalized asso ciation rules and sequen tial patterns using SQL queries In KDD  pages 344{348 1998 24 J D Ullman Principles of Datab ase and Know le dgeb ase Systems Part I II  Computer Science Press 1988 25 Mohammed J Zaki Generating non-redundan t association rules In Pr o c of the 6th A CM SIGKDD Intl Conf  Boston MA August 2000 1 0 


OM OM 006 OD8 01 012 014 016 018 02 022 False alarm demity Figure 9 Percentage of tracks lost within 200 seconds using three-scan assignment with PD  0.9 TI  O.ls Figure 11 T2  1.9s and T  Is ij  20 and 0  0.1 24 1 22  20  E fls 0  8l 16 0 n 14  12  0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 T1/12 PD Average track life of three-scan assignment with PD varying TI  0-ls T2  1.9s T  Is X  0.02 ij LO and   0.1 mareuvenng index Figure 12 Percentage of lost tracks of 4-D assipment in 200 seconds with maneuvering index varying X  0.01 Ti  0.1 T2  1.9s and T  IS PD  0.98 Figure 10 Percentage of lost tracks of 4-D assignment in 200 SeoDllCls with TI and T2 varying PD  0.98 X  0.02 q 20 and 0  0.1 4-1607 


Figure 13 Average gate size for Kalman filter Figure is relative as compared to nq and curves are parametrized by ij/r with unit-time between each pair of samples 1.2 Iy I 1.1 0.5 I A CRLB for he unifm samiina I  0.4 0.35 d 3 03 i7 3 0.25 0 0.M 0.04 0.06 008 0.1 0.12 0.14 0.16 0.18 0.2 False A!am DemW V I    Figure 14 CramerRao Lower Boundfor Mean Square Error of uniform and nonuniform sampling schemes with Ti  O.ls T2  1.9s T  IS PD  0.9 ij  5 and U  0.25 1 unifon sampling r-ls ked i non-uniform sampling loge inlewi I ti non-uniform sampling shod interva I 0.9 0.8 I Figure 15 MSE comparison of three-scan assignment with Ti and T2 varying I'D  1 X  0.01 ij  20 and U  0.1 4-1608 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



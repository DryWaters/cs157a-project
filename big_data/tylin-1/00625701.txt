A Fast Transformation Method to Semantic Query Optimisation Ayla Sayli and Barry Lowden University of Essex Dept of Computer Science Wivenhoe Park Colchester CO4 3SQ Essex UK saylia  essex.ac uk lowdb  essex.ac.uk Abstract Semantic query optimisation is a comparatively recent approach for the transformation of a given query into equivalent alternative queries using matching rules in order to select an optimum query 
based on the costs of executing of these alternative queries. The most important aspect of this optimisation approach is that this resultant query can be processed more eflciently than the original query This paper describes how a near optimal alternative query may be found in far less time than existing approaches The method uses the concept of a 221search ratio\222 associated with each matching rule The search ratio of a matching rule is based on the cost of the antecedent and consequent conditions of 
the rule This cost is related to the number of instances in the database determined by these conditions This knowledge about the number of instances is available and can be recorded when the rules are first derived. We then compare search ratios of rules to select the most restrictive rules for the construction of a near optimum query The technique works eflciently regardless of the number of matching rules since resources are not used to construct all alternative queries This means that transformation and selection costs are minimised in our system 
It is hoped that this method will prove a viable alternative to the expensive optimisation process normally associated with semantic query optimisation 1 Introduction Semantic Query Optimisation SQO uses rules to transform a query into equivalent alternative queries According to costs of these alternative queries, one of the queries may be selected as an optimum query that has the same result set but can be processed more cheaply than the original query 3 71 In general there are four main stages in SQO 1\representing the given query 
in a query language such as SQL 2 query optimisation 3 automatic rule derivation for a given query and 4 maintaining rules This last stage is the subject of a forthcoming paper by the authors Automatic rule generation has been tackled by many researchers and is the process of deriving association rules from the data itself. Such rules hold for a given state of the database, as opposed to say integrity constraints which are true for any state of the database Approaches 
may be classified as heuristic-based systems  171 logic-based systems  11 graph-based systems  161 and data-driven systems 4 15 5 9 121 Research shows however that there is a serious problem in terms of the varying quality and sheer volume of the rules derived For example a heuristics based system can be used to learn all possible rules using heuristics cheaply and easily but this can lead to a very 
large rules set since the rules are derived automatically regardless of their quality Data-driven systems may be used for learning currently relevant rules but the increasing size of the rule set still remains a problem 2 6 111 The second stage query optimisation is less well researched in the literature the most significant work already having been referenced above In EXODUS by 3 statistical methods are employed known as the cumulative arithmetic average method and cumulative geometric average method. These are 
used with a sliding factor to calculate costs of alternative queries which is given a constant value equal to 0.5 on the basis that if the same query runs again the cost should be half using matching rules where a matching rule is one whose antecedent matches a query condition However in reality this may not be attainable unless special circumstances occur such as a given query is refuted the 319 0-8186-8114-4/97 10.00 0 1997 IEEE 


answer set is found using a matching rule or the matching rules contain index attributes Another issue often overlooked is that in fact the optimisation cost usually comprises the transformation cost together with the selection cost lo 14 91 Clearly we need to consider the combined costs of these processes together with the execution cost of the optimum query when computing the overall savings The paper by 14 is realistic in this regard but is based on a small number of transformation rules providing a limited range of alternative queries Our method is based on notion of a search ratio associated with each rule in that this number shows how effective this rule is in restricting the given query for a given database In order to do this we keep the number of instances associated with the antecedent and consequent conditions of the rule and the total number of the instances of the rule relation as a cost variable when we derive the rule It is then possible to identify the most effective rules to construct the optimum query according to their search ratios using the knowledge which is kept in the rules set This means that we avoid the need to construct all possible alternative queries as is the case with traditional approaches In Section 2 we first give the optimisation method of the traditional approaches and then present the cost estimation function to show how the search ratio is determined for each matching rule In section 3 examples of the method are given using a model relation Finally in Section 4, results of our experiments using the method are given 2 An Approximation Method to Semantic Query Optimisation Using knowledge to guide any process in SQO is essential where learning optimisation and rule maintenance can be made more intelligent and practical In our system we rank the matching rules according to their search ratios For a rule W+Z assuming that Wcost is the search cost to find the tuples identified by the antecedent condition W and Zcost is the search cost to find the tuples identified by the consequent condition Z a search ratio represents the saving if Z is used instead of W which can be formalised as Wcost  Zcost Wcost That is this search ratio is used to compare our saving of using Z against W in order to determine a rule's effectiveness when used in query transformation 2.1 Traditional Semantic Query Optimisation Method In general SQO takes a given query in a language such as SQL QUEL or variant of the algebra or calculus and adopts one of a number of different approaches to represent the query Secondly each Original Condition OC from the query is checked for matching rules in a rules set. Thirdly matching rules are used to transform the given query into alternative queries Fourthly all alternative queries are compared according to their costs in order to select the optimum query If there is no matching rule for an OC the latter may be used to initiate an automatic rule derivation process The method is shown in Figure 1 where the search space contains the alternative queries which are syntactically different from each other but semantically equivalent. This means that they can be used to retrieve the same answer set as the original query In the figure we do not show alternative queries which use the same rules but in a different order For example in the case of using R1 and R2 Qn+l can be constructed using the orders  R1 R2 or R2 R1  Original Query v Representation of the given query in a query language 1 Unmatched Rules Rules  Matching Process for OCs  Rule Derivation Process 4 Cost ___ Comparing 2  1 Estimation Alternative Queries t Selection Process t Qo Figure 1 Traditional Semantic Query Optimisation Method However problems arise if the number of matching rules increases since the number of alternative queries also grows making the process expensive and inefficient even considering only the queries which are syntactically different from each other but semantically equivalent to the original query. Moreover assuming that the antecedent conditions of these matching rules are the same as the conditions of the given query and n is the number of distinct antecedent conditions then the number of the possible alternative queries using the rules in Figure 1 is  2n  1  If we consider all possible alternative queries 320 


including these with a simple reordering of the same conditions then the number can be found using the x=n n formula  C   Another area of difficulty is estimating the costs of these queries which must take into account both the cost of transformation and query selection Although the method by 1141 is of interest it is not realistic for large numbers of matching rules Also most research on optimisation techniques tends to be based on statistical information in the system catalogue For example, INGRES uses 221optimizedb\222 to analyse table data to estimate needed information \(e.g. total number of tuples in a table number of distinct values of the index attribute of a column etc However there is little research on the time taken to produce these statistics in relation to the optimisation time for a query Our method provides a practical solution to those problems as given in the following section n-x  x=l 2.2 A Fast Transformation Method For Semantic Query Optimisation The method is illustrated in Figure 2 SQL is chosen as a query language to represent the given query Next the conditions of the given query are matched with the antecedent condition of corresponding rules  121 Moreover we also check the matching rules to determine whether they imply other matching rules For example assume a matching rule is found W->Z we then can use Z in the matching process as well as W which may be used to find a rule such as Z->V. This step can be seen as a loop which terminates when all matching rules are found If there are no matching rules the condition may be used to derive a new rule to be used with subsequent queries A further check is then made to find out if the antecedent condition of any matching rule provides an immediate response to the query and finally whether there is refutation In case of such queries whose answers are found with no further need for optimisation SQO clearly provides major savings If the query remains unanswered then in our approach the optimiser enters a loop to estimate costs of antecedent and consequent conditions of all matching rules According to the costs the matching rules are divided into two groups X and Y X contains matching rules where the consequent condition is less expensive to evaluate than the antecedent condition. The remainder of the rules are kept in the second group Y We then order the rules in the X using their search ratios A condition list may be generated from the consequents of rules in X The rules in Y may now be used to eliminate any expensive conditions. The result is a near optimum query Qo which is semantically equivalent to the original Original Query Representation of the Given Query in a Query Language 4 t Taking Ocs t Unmatched Rules Rule Rules Set Matching Process for OCs Derivation Matched Rules Process 1 Checking for Refutation the answer is NULL No t Deriving the Answer if Possible  the answer is shown No Estimating costs of the matching rules rt.;;1 t h 1 Ordering the Conditions in C According to their Search Ratios t Constructing the Condition list 4 Adding OCs to the Condition List if OCs are not already in the List Eliminating expensive conditions in the condition list Constructing Qo using the condition list t t t Executing Qo the answer is shown Figure 2 A Fast Transformation Method for Semantic Query Optimisation Our method is very efficient when there are a large number of rules in the rule set It is not limited by the number of rules as in traditional approaches lo 14 91 since it does not generate all possible alternative queries to select the optimum It is also very practical and fast because it is not dependent on any specific statistical information from the system catalogue The transformation algorithm is shown below and the process of cost estimation referred to in the algorithm is described in the next section Linear Ouery Transformation Algorithm Ri  all matching rules  i:l 2  n as Rl R2  Rn The syntax for one of the matching rules W+Z W presents the antecedent condition of the rule 321 


Z presents the consequent condition of the rule Zlength Length of the consequent attribute value  Wlength Length of the antecedent attribute value Zinsnum Number of instances that can be identified by Z Winsnum Number of instances that can be identified by W Zindex If the consequent attribute of the first rule is an index Windex If the antecedent attribute of the first rule is an index attribute it is equal to 1 Otherwise it is equal to 0 zero attribute it is equal to 1 Otherwise it is equal to 0 zero INGRES Data Types Range Length char The length of thc  These values are computed as a by-product of the initial rule generation process They are therefore provided with the rule 128 to +127 32,768 to  32,767 2,147,483,648 to  2,147,483,647 10**38 to 10**38 7 decimal precision 10**38 to 10**38 17decimalprecision Step 1 Estimate costs of antecedent conditions and costs of consequent conditions of all matching rules attribute value 1 byte 2 byte 4 byte 4 byte 8 byte cost\(Windex, Zindex, Winsnum, Zinsnum Wlength, Zlength Wcost Zcost Step 2 Divide the matching rules into two groups X and Y if\(Ri->Wcost  Ri->Zcost else Ri goes into X Ri goes into Y Step 3 Order all rules i 1 2  k in X according to their search ratios a Calculate search ratios using Ri.search-ratio=\(Ri->Wcost  Ri->Zcost b Order Ri according to Risearch-ratio Step 4 Construct a condition list using the ordered rules Step 5 Add OCs to the condition list if OCs are not already in the list Step 6 Eliminate any expensive condition in the condition list using Y Step 7 Construct a near optimum query Qo using the condition list Step 8 Execute Qo 2.2.1 Cost Estimation In this section we show how the number of instances identified by the antecedent condition of a matching rule and the consequent condition of the rule can be used to estimate an approximate cost saving using statistical methods As mentioned before the number of instances and the total number of the tuples in a table are available when the rule was initially derived 12 Assuming the number of instances of a condition is R the approximate number of disk blocks retrieved A for the R instances can be found using Function 1 where B is the total number of disk blocks in the database SI 1 R A  B*\(l-\(l-l/B  This assumes a random distribution of tuple instances across the relation space and 100 block packing density If the condition is not indexed then it is necessary to calculate the number of disk blocks to be searched in order to retrieve A blocks out of the total Moreover since there is no information about the location of the A blocks we assume that C sequential blocks must be searched to retrieve the R instances where A*\(B+l A+1 c 2 The number of tuples searched is therefore Number-of-tuples z C  N 3a where N is the number of tuples per block However if the consequent attribute is an indexed attribute the optimiser only searches the number of the instances located in A blocks as follows Number-of-tuples  A  N 3b Our cost approximation may then be extended to predict the number of byte comparisons as shown in 4 COMPARISON-COST  Number-of-tuples  Length 4 where Length is the size of the condition attribute length in bytes This will depend on the implementation but typically, for INGRES Table 1 can be used P 322 


Function 4 can be used to evaluate the search ratio for each matching rule since the number of instances is known at the time of rule generation In the following section we give some examples to illustrate how the method works in practice using a model database 221DEPARTMENT\222 Rule No W  Z WinsnunJZinsnum R1 Dcode=\221ACCT\222+Dname=\221Accounting\222 130 FO  3 Examples of the Optimisation Method Our examples are based on a model 221DEPARTMENT\222 relation which has 240 instances and 5 different attributes Dcode char\(41 Dname char 12 Project integer Manager char\(4 Location char 15 and assumes initially that the system has 8 rules in the rules set These rules are shown in Table 2 with their associated number of instances within the 221DEPARTMENT\222 relation 221Project\222 is an indexed attribute of the relation Row length is 40 bytes and a disk block can hold 12 tuples Total disk blocks B  20 2:Dcode=\221ACCT\222 Manager  221AI\222 130 180 3:Dname  221Marketine\2224\222roiect  7 I40 I60 I IR8:Project>7+Location= \221London\222 160 1150 I Example 1 Assume that we are _looking for all information in the 221DEPARTMENT\222 relation where Dcode  221ACCT\222 This query can be represented in SQL as  Q1 select  from DEPARTMENT where Dcode  221ACCT\222 In our system we match the single query condition against antecedent conditions in our rules set From Table 2 two rules below can be used to transform the given query R1 Dcode=\221ACCT\222+Dname=\221Accounting\222 130 bo R2 Dcode=\221ACCT\222 Manager=\221Al\222 130 180 There is no rule to cause refutation of the given query and the answer of the query can not be found using matching rules alone so the optimiser enters a loop to calculate costs of both the antecedent condition and the consequent condition for each associated rule and then ranks them For R1 the antecedent condition is W1 the length of the comparison value of the condition is Wlength  4 the number of instances identified by W1 is Winsnum  30 and the condition does not contain any indexed attributes thus Windex  0 The consequent condition is Z1 Zlength  10 Zinsnum  40 and Zindex  0 The optimiser then proceeds to the cost estimation process as follows a Function 1 is used to compute approximately how many disk blocks need to be retrieved for the antecedent condition R 30 A  B*\(l--\(l-l/B  20  1  1  11 20  15.70 b\Since the antecedent attribute is not indexed we determine the expected number of disk blocks which need to be searched to retrieve the A blocks using Function 2 A  B  1 15.70  20  1 E 19.74 I  C  A+l 15.70  1 c Using Function 3a the number of tuples can be found as follows Number-of-tuples E C  N I 19.74  12 I 236.91 d Using Function 4 the number of bytes to be compared for the condition Wcost  Number-of-tuples  Length  236.91  4  947.66 For the consequent condition the calculation is similar Using Function 1 the approximate number of blocks retrieved can be found R 40 A B*\(l-\(l-l/B  i 20  1  1  1  20  17.42 Since the consequent attribute is not indexed we determine the expected number of disk blocks to be searched using Function 2 A  B  1 C  A+l 17.42  20  1 E 19.86   17.42  I The number of the tuples is found as follows 323 


Number-of-tuples E C  N z 19.86  12 I 238.326 We then estimate the number of bytes to be compared for the condition Zcost  Number-of-tuples  Length  238.326  10  2383.26 The cost of the antecedent condition of the rule is less than the cost of the consequent condition of the rule so the rule is added into Y For rule R2 Wcost and Zcost can be found in a similar way to the first rule; Wcost  947.66 Zcost  479.6. The cost of the antecedent condition of the rule is higher than the consequent of the rule so the rule is added into X Since a query condition is the antecedent condition of R2 whose consequent is Manager  221Al\222 this latter is added into the condition list. At this stage a check is made to eliminate any conditions in the list which can be matched with the consequents of rules in Y Using R1 in Y it is not possible to eliminate any rules in the list  The optimisation process is completed with the construction of the near optimum query as below Qo select  from DEPARTMENT where Manager  221Al\222 and Dcode  221ACCT\222 This resultant query is more efficient to execute than the original Example 2 Assume that we are looking for all information in the 221DEPARTMENT\222 relation where Dname  221Marketing\222 This query can be represented in SQL as  42 select  from DEPARTMENT where Dname=\222Marketing\222 Comparing the conditions of the given query the following matching rules can be found estimate the costs of both antecedents and consequents of the rules. These costs can be seen in the following table where the first row shows costs of antecedent conditions and the second row shows that of consequent conditions R3 R4, R5 and R7 are added into X R6 and R8 are added into Y We then order all rules in X according to their search ratios that is R3 R4 R7 and R5 The condition list is constructed taking the consequent conditions of the ordered group as 221Project  7\222 221Project  12 221Manager  221M3\224 and Dcode  221MKTG\222 Then the OC 221Dname  221Marketing\224 is added to the condition list because it does not exist in X as a consequent condition The optimiser then determines whether there are any rules in Y where the consequent condition of the rule is in the condition list Using R6 it is possible to eliminate the condition 221Dname  221Marketing\224 from the condition list knowing the antecedent condition of the rule is less expensive than the consequent condition and already exists in the list Finally the near optimum query can be constructed as Qo select  from DEPARTMENT where Project  7 and Project  12 and Manager  221M3\222 and Dcode  221MKTG\222 It is possible to see from the given examples that our method is straight forward to apply even where there is a large number of matching rules In our system the optimiser selects the most restrictive rules in order to construct the near optimum query We also minimise the overall effort required since it is not necessary to construct all alternative queries Our experimental results in the following section show that the method is viable 4 Computational Results R3:Dname=\221Marketing\222-+Projecb7 140 I 60 R4:Dname 221Marketin&+Proiect 12 140 I 200 Y RS:Dname=\221Marketing\222+Dcode=\221MKTG\222 I 40 I 40 R6:Dcode=\221MKTG\222+Dname=\221Marketing\222 140 I 40 R7:Dname=\221Marketing\222-+Manager=\221M3\222 I 40 I 100 R8:Project>7 Location=\221London\222 160 I 150 It may be seen that no rule causes a refutation of the given query or may be used to find the answer to the query As mentioned before, the optimiser enters a loop to The two relations in our database were a 5861 instance relation 221STUDENT\222 provided by the Student Administration Office at Essex University and a 27266 instance relation 221HOUSEHOLD\222 which was created from the 221General Household Survey Data, GN: 33124 Study number 3170 Year 1993-1994\222 Survey data was provided by the ESRC Data Archive at the University The row length was 43 bytes for 221STUDENT\222 and 71 bytes for 221HOUSEHOLD\222 The total number of blocks was 248 for 221STUDENT\222 and 6139 for 221HOUSEHOLD\222 324 


in Btree storage structure respectively The schemas of the relations are STUDENT logname c8 regno int advisor int, entry int year c2 scheme c6 uccacode c6 status cl examno int school c4 HOUSEHOLD hserno int persno int region c10 npersons int typaccm c10 bedrooms int centheat c4 ncars int ownrent c5 mortgage c4, cost int loan int The machine used was a 33Mhz SPARC-ELC with Ingres files held on a 2GB Fujitsu SCSI running synchronously Both relations are based on actual data used within the University Rules in our rules set were derived from the system by 12 91 The rule sets for each relation contained 50 rules The experiment was done for several thousand queries on both relations which was based on many observations using different featured rules in order to analyse the time saving using SQO For example if the rules contain any index attribute or not From our tests the following results were observed a For the both relations if the original query is refuted by any rule, the saving on average was 99.15 If the answer to the original query was found by one of the matching rules alone the saving on average was 99.53 b If the rule contained an indexed attribute the savings on average were up to 86.40 for 221STUDENT\222 and 83.52 for 221HOUSEHOLD\222 c In queries for which no indexed condition could be found, the saving on average was 6.39 for the relation 221STUDENT\222 and 1.94 for the relation 221HOUSEHOLD\222 The poorer result from the 221HOUSEHOLD\222 data was due to the lower number of instances per block compared with the 221STUDENT\222 relation 5 Conclusions This paper has described a fast query transformation process in SQO which constructs a near optimum query taking into account all matching rules The results are encouraging and promise large savings even when the rule set is large since transformation time is in linear function of rule set cardinality We are now extending our current work in statistics and knowledge discovery to address the issue of complex queries such as join queries and maintaining rules set 13 181 Acknowledgement We would like to thank John Ford  Tony Lawson in Computer Science Dept and Ken Miller  other personnel in the ESRC Data Archive at University of Essex Thanks also to Prof Tahir Sisman at Yildiz University for all his support during this research References I S Chakravarthy J Grant and J Minker 223Logic-based approach to semantic query optimisation\224 ACM on Database Systems Vol 15 No 2, 1990, pp. 162-207 2 K.C Chan and A.K.C Wong 223A statistical test for extracting classificatory knowledge form databases\224 Knowledge Discovery in Databases Ed The AAA1 Press 1991 pp 107-123 3 G Graefe and D Dewitt 223The EXODUS optimiser generator\224 In Proc of the 1987 ACM-SIGMOD Conf on Management of Data May 1987 pp 160-1711 4 J Han Y Cai and N Cercone 223Data-driven discovery of quantitative rules in relational databases\224 IEEE on Knowledge and Data Eng Vol5 no 1 Feb 1993 pp 29-40 5 C Hsu and C.A Knoblock, \223Rule induction for semantic query optimisation\224 In Proceedings of the Eleventh International Conf on Machine Learning 1994  I F Imam R S Michalski and L. Kerschberg 223Discovering attribute dependence in database by integrating symbolic learning and statistical analysis tests\224 Knowledge Discovery in Databases Workshop 1993 pp 264-275 7 J J King 223QUIST A system for semantic query optimisation in relational databases\224 In Proceeding of the 7 th VLDB Conference, Sept. 1981 pp 510-517 8 B G T Lowden 223An Approach to Multikey Sequencing in an equiprobable keyterm retrieval situation\224 Proceedings of the Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, 1985 pp 92-96 9 B G T Lowden J Robinson and K Y Lim 223A semantic query optimiser using automatic rule derivation\224, Proc Fifth Annual Workshop on Information Technologies and Systems Netherlands, 68-76 December 1995 pp 68-76 lo L F Mackert and G M Lohman 223R optimizer validation and performance evaluation for local queries\224, Proc ACM-SIGMOD 1986 pp 84-95  111 G.Piatetsky-Shapiro and C Matheus 223Measuring data dependencies in large databases\224 Knowledge Discovery in Databases Workshop 1993 pp 162-173 12 A Sayli and B G T Lowden 223The use of statistics in semantic query optimisation\224, Thirteenth European Meeting on Cybernetics and Systems Research Vienna April 1996 pp 991-996 325 


 131 M SCHKOLNICK and P TIBERIO 223Estimating the cost of updates in a relational database\224 ACM Trans Database Systems 10,2 June 1985 pp 163-179  141 S Shekhar J Srivastava and S Dutta 223A formal model of trade-off between optimisation and execution costs in semantic query optimization\224 Proceedings of the 14th VLDB Conference Los Angeles, California, 1988 pp 457-467 15 S Shekhar B Hamidzadeh and A Kohli Learning transformation rules for semantic query optimisation a data driven approach. IEEE, 1993 pp 949-964 16 S.T Shenoy and Z.M Ozsoyoglu 223Design and implementation of semantic query optimiser\224 IEEE Transactions on Knowledge and Data Engineering Vol 1 No 3 Sept. 1989 pp 344-361 17 M.D Siegel E Sciore and S Salveter 223A method for automatic rule derivation to support semantic query optimisation\224 ACM Transactions on Database Systems Vol 17 No 4 Dec 1992, pp 563-600  181 C Yu and W Sun 223Automatic knowledge acquisition and maintenance for semantic query optimisation\224 IEEE Trans Knowl. Data Eng 1 3 Sept. 1989, pp 362-375 326 


of the query expression without ha ving the global view of the in ten tion There is a big c hance that the enco ded pro cedure ma y not b e the b est w a y to compute the rules dep ending on the database instance F urthermore as w e understand it their prop osals require p oten tially large n um ber of name generation for relations and attributes The names that are needed are usually database dep enden t and th us p ossibly cannot b e gathered at query time An additional pro cess needs to b e completed to gather those v ariables b efore actual computations can b egin 5  9 Optimization Issues While it w as in tellectually c hallenging to dev elop a declarativ e expression for asso ciation rule mining from deductiv e databases there are sev eral op en issues with great promises for resolution In the w orst case the least xp oin tneedsto generate n 2 tuples in the rst pass alone when the database size is n  Theoretically  this can happ en only when eac h transaction in the database pro duces an in tersection no de and when they are not related b y subset-sup erset relationship In the second pass w e need to do n 4 computations and so on The question no w is can w e a v oid generating and p erhaps scanning some of these com binations as they will not lead to useful in tersections F or example the no de b 0 3 in gure 11 is redundan t A signican t dierence with apriori lik e systems is that our system generates all the item sets top do wn in the lattice without taking their candidacy as a large item set in to consideration Apriori on the other hand do es not generate an y no de if their subsets are not large item sets themselv es and thereb y prunes a large set of no des Optimization tec hniques that exploit this so called an ti-monotonicit y prop ert y of item set lattices similar to apriori could mak e all the dierence in our setup The k ey issue w ould b e ho ww e push the selection threshold minim um supp ort inside the top do wn computation of the no des in the lattice in our metho d F or the momen t and for the sak e of this discussion let us consider a higher supp ort threshold of 60 for the database T of gure 9 No w the l-en v elop e will b e the one sho wn in ligh ter dashed lines in gure 11 and the no des under this line will b e the large item sets Notice that no ww eha v eto discard no des ad 2 0 and d 0 2 to o This raises the question is it p ossible to utilize the supp ort and condence thresholds pro vided in the query and prune candidates for in tersection an y further Ideas similar to magic sets transformation 3  24 ma y be b orro w ed to address this issue The only problem is that pruning of an y no de dep ends on its supp ort coun t whic h ma y come at a later stage By then all no des ma y already ha v e b een computed and th us pushing selection conditions inside aggregate op erator ma y b ecome non-trivial Sp ecial data structures and indexes ma y also aid in dev eloping faster metho ds to compute ecien t interse ction joins that w e ha v e utilized in this pap er W e lea v e these questions as op en issues that should be tak en up in the future F ortunately though there has been a v ast b o dy of researc h in optimizing Datalog programs including recursiv e programs suc h as the one w e ha v e used in this pap er and hence the new questions and researc h 5 Recall that their prop osal requires one to express the mining problem to the system using sev eral queries and up date statemen ts that utilizes information ab out the database con ten ts to ac hiev e its functionalit y  c hallenges that this prop osal raises for declarativ e mining ma y exploit some of these adv ances Needless to emphasize a declarativ e metho d preferably a formal one is desirable b ecause once w e understand the functioning of the system w e will then be able to select appropriate pro cedures dep ending on the instances to compute the seman tics of the program whic hw e kno wis in tended once w e establish the equiv alence of declarativ e and pro cedural seman tics of the system F ortunately  w e ha v e n umerous pro cedural metho ds for computing asso ciation rules whic h complemen t eac h other in terms of sp eed and database instances In fact that is what declarativ e systems or declarativit y buy us  a c hoice for the most ecien t and accurate pro cessing p ossible 10 Conclusion Our primary goal for this pap er has b een to demonstrate that mining asso ciation rules from an y rst-order kno wledge base is p ossible in a declarativ ew a y  without help from an y sp ecial to ols or mac hinery  and that w e can no wha v ea v ery in tuitiv e and simple program to do so W eha v esho wn that it is indeed p ossible to mine declarativ ekno wledge b y exploiting the existing mac hinery supp orted b ycon temp orary inference engines in programming languages e.g Prolog or kno wledge base systems e.g RelationLog XSB LD L  CORAL All w e require is that the engine b e able to supp ort set v alued terms grouping aggregate functions and set relational op erators for comparison functionalities whic hmostofthesesystemscurren tly supp ort W e ha v e also demonstrated that our formalism is grounded on a more mathematical foundation with formal prop erties on whic h the seman tics of the R ULES system rely  W e ha v e also raised sev eral op en issues related to eciency and query optimization whic h should b e our next order of business As future researc h w e plan to dev elop optimization tec hniques for mining queries that require non-trivial lo ok ahead and pruning tec hniques in aggregate functions The dev elopmen ts presen ted here also ha v e other signican t implications F or example it is no w p ossible to compute c hi square rules 4 using the building blo c ks pro vided b y our system Declarativ e computation of c hi square rules to our kno wledge has nev er b een attempted for the man y pro cedural concepts the computation of c hi square metho d relies on In a separate w ork 2 w e sho w that the coun ting metho d prop osed in this pap er can be eectiv ely utilized to generate the exp ectations needed in order to compute suc h rules rather easily  These are some of the issues w e plan to address in the near future The motiv ation imp ortance and the need for in tegrating data mining tec hnology with relational databases has b een addressed in sev eral articles suc h as 12  13 They con vincingly argue that without suc h in tegration data mining tec hnology ma y not nd itself in a viable p osition in the y ears to come T o b e a successful and feasible to ol for the analysis of business data in relational databases suc htec hnology m ust b e made a v ailable as part of database engines and as part of its declarativ e query language Our prop osal for declarativ e mining bears merit since it sheds ligh t on ho w rst order databases can be mined in a declarativ e and pro cedure indep enden t w a y so that the optimization issues can b e delegated to the underlying database engine Once suc h argumen ts are accepted sev eral systems 9 


related issues b ecome prime candidates for immediate atten tion F or example traditionally database systems supp orted declarativ e querying without the necessit y to care ab out the pro ceduralit y of the queries In this pap er w eha v e actually demonstrated that asso ciation rule mining can b e view ed as a Datalog query  It is immediate that a direct mapping from the Datalog expressions presen ted in this pap er to SQL can be dev elop ed with no problem at all W e can then rely on ecien t database pro cessing of the query in an optimized fashion Hence w ecomeclose to the essence of the visions expressed b y the leading database researc hers and practioners 12  References 1 Rak esh Agra w al and Ramakrishnan Srik an t F ast algorithms for mining asso ciation rules in large databases In VLDB  pages 487{499 1994 2 Anon ymous A declarativ e metho d for mining c hisquare rules from deductiv e databases T ec hnical rep ort Departmen t of Computer Science Anon ymous Univ ersit y USA F ebruary 2001 3 C Beeri and R Ramakrishnan On the po w er of magic In Pr o c e e dings of the 6th A CM Symp osium on Principles of Datab ase Systems  pages 269{283 1987 4 Sergey Brin Ra jeev Mot w ani and Craig Silv erstein Bey ond mark et bask ets Generalizing asso ciation rules to correlations In Pr o c A CM SIGMOD  pages 265 276 1997 5 D Chimen ti et al The LD L system protot yp e IEEE Journal on Data and Know le dge Engine ering  2\(1 90 1990 6 Jia w ei Han Jian P ei and Yiw en Yin Mining frequen t patterns without candidate generation In Pr o c A CM SIGMOD  pages 1{12 2000 7 Marcel Holsheimer Martin L Kersten Heikki Mannila and Hann uT oiv onen A p ersp ectiv e on databases and data mining In Pr o c of the sixth A CM SIGKDD Intl Conf  pages 150{155 Mon treal Queb ec 1995 8 Flip Korn Alexandros Labrinidis Y annis Kotidis and Christos F aloutsos Ratio rules A new paradigm for fast quan tiable data mining In Pr o c of 24th VLDB  pages 582{593 1998 9 Brian Len t Arun N Sw ami and Jennifer Widom Clustering asso ciation rules In Pr o c of the 3th ICDE  pages 220{231 1997 10 Mengc hi Liu Relationlog At yp ed extension to datalog with sets and tuples In John Llo yd editor Pr oc e e dings of the 12th International L o gic Pr o gr amming Symp osium  pages 83{97 P ortland Oregon Decem ber 1995 MIT Press 11 Rosa Meo Giusepp e Psaila and Stefano Ceri An extension to SQL for mining asso ciation rules Data Mining and Know le dge Disc overy  2\(2 1998 12 Amir Netz Sura jit Chaudh uri Je Bernhardt and Usama M F a yy ad In tegration of data mining with database tec hnology  In Pr o c e e dings of 26th VLDB  pages 719{722 2000 13 Amir Netz Sura jit Chaudh uri Usama M F a yy ad and Je Bernhardt In tegrating data mining with SQL databases In IEEE ICDE  2001 14 Ra ymond T Ng Laks V S Lakshmanan Jia w ei Han and Alex P ang Exploratory mining and pruning optimizations of constrained asso ciation rules In Pr o c A CM SIGMOD  pages 13{24 1998 15 Jong So o P ark Ming-Sy an Chen and Philip S Y u An eectiv e hash based algorithm for mining asso ciation rules In Pr o c A CM SIGMOD  pages 175{186 1995 16 Karthic k Ra jamani Alan Co x Bala Iy er and A tul Chadha Ecien t mining for asso ciation rules with relational database systems In Pr o c e e dings of the International Datab ase Engine ering and Applic ations Symp osium  pages 148{155 1999 17 R Ramakrishnan D Sriv asta v a and S Sudarshan CORAL  Con trol Relations and Logic In Pr o c of 18th VLDB Confer enc e  pages 238{250 1992 18 Konstan tinos F Sagonas T errance Swift and Da vid Scott W arren XSB as an ecien t deductiv e database engine In Pr o c of the A CM SIGMOD Intl Conf  pages 442{453 1994 19 Sunita Sara w agi Shib y Thomas and Rak esh Agra w al In tegrating mining with relational database systems Alternativ es and implications In Pr o c A CM SIGMOD  pages 343{354 1998 20 Ashok a Sa v asere Edw ard Omiecinski and Shamk an tB Nav athe An ecien t algorithm for mining asso ciation rules in large databases In Pr o c of 21th VLDB  pages 432{444 1995 21 Pradeep Sheno y  Ja y an t R Haritsa S Sudarshan Gaura v Bhalotia Ma y ank Ba w a and Dev a vrat Shah T urb o-c harging v ertical mining of large databases In A CM SIGMOD  pages 22{33 2000 22 Abraham Silb ersc hatz Henry F Korth and S Sudarshan Datab ase System Conc epts  McGra w-Hill third edition 1996 23 Shib y Thomas and Sunita Sara w agi Mining generalized asso ciation rules and sequen tial patterns using SQL queries In KDD  pages 344{348 1998 24 J D Ullman Principles of Datab ase and Know le dgeb ase Systems Part I II  Computer Science Press 1988 25 Mohammed J Zaki Generating non-redundan t association rules In Pr o c of the 6th A CM SIGKDD Intl Conf  Boston MA August 2000 1 0 


OM OM 006 OD8 01 012 014 016 018 02 022 False alarm demity Figure 9 Percentage of tracks lost within 200 seconds using three-scan assignment with PD  0.9 TI  O.ls Figure 11 T2  1.9s and T  Is ij  20 and 0  0.1 24 1 22  20  E fls 0  8l 16 0 n 14  12  0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 T1/12 PD Average track life of three-scan assignment with PD varying TI  0-ls T2  1.9s T  Is X  0.02 ij LO and   0.1 mareuvenng index Figure 12 Percentage of lost tracks of 4-D assipment in 200 seconds with maneuvering index varying X  0.01 Ti  0.1 T2  1.9s and T  IS PD  0.98 Figure 10 Percentage of lost tracks of 4-D assignment in 200 SeoDllCls with TI and T2 varying PD  0.98 X  0.02 q 20 and 0  0.1 4-1607 


Figure 13 Average gate size for Kalman filter Figure is relative as compared to nq and curves are parametrized by ij/r with unit-time between each pair of samples 1.2 Iy I 1.1 0.5 I A CRLB for he unifm samiina I  0.4 0.35 d 3 03 i7 3 0.25 0 0.M 0.04 0.06 008 0.1 0.12 0.14 0.16 0.18 0.2 False A!am DemW V I    Figure 14 CramerRao Lower Boundfor Mean Square Error of uniform and nonuniform sampling schemes with Ti  O.ls T2  1.9s T  IS PD  0.9 ij  5 and U  0.25 1 unifon sampling r-ls ked i non-uniform sampling loge inlewi I ti non-uniform sampling shod interva I 0.9 0.8 I Figure 15 MSE comparison of three-scan assignment with Ti and T2 varying I'D  1 X  0.01 ij  20 and U  0.1 4-1608 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



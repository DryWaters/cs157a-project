A Clustering Algorithm with Genetically Optimized Membership Functions for Fuzzy Association Rules Mining 0-7803-781 0-5/03/$17.00 02003 IEEE 881 The IEEE International Conference on Fuzzy Systems Mehmet KAYA Department of Computer Engineering Firat University 23119 Elazlg Turkey kaya@firat.edu.tr Abstract-In this paper we propose Genetic Algorithms GAS based clustering method which dynamically adjusts the fuzzy sets to provide maximum profit within an interval of user specified minimum support values This is achieved by tuning lhe base values of the membership functions for each quantitative attribute so as to maximize the sum of large iicnaetb in a certain iuterval of 
minimum support values To the hi%t uf our knuuledee thi is the lint effort in this dirrction I_ To support our claim we compare the proposed GAS-based approach with a CURE-based approach Experimental results on synthetic transactions show that the proposed clustering method exhibits a good performance over CURE-based approach in term of the number of produced large itemsets and interesting association rules I INTRODUCTION Early research on association rules mining concentrated on boolean association rules mining l which is concerned only with whether an item is present in a transaction or not, without considering its quantity. However quantity is a very useful piece 
of information. However the problem of discovering association rules from quantitative attributes is a relatively difficult task which has received the attention of several research groups It is difficult because determining reasonable intervals for unknown quantitative attributes is not an easy task Clustering is one of the techniques employed recently to overcome this problem Earlier approaches developed for quantitative association rules mining require discretizing domains of quantitative attributes into intervals which may not be concise and meaningful enough for human users to easily obtain nontrivial knowledge from the discovered rules In other words they introduced a major problem which is caused by the shalp boundaty between intervals Explicitly existing quantitative mining algorithms either ignore or over-emphasize elements near the boundary of an interval Instead of using sharp boundary intervals some work has recently been done on 
the use of fuzzy sets in discovering association rules for quantitative attributes However in existing approaches fuzzy sets are either supplied by an expert or determined by applying an existing known clustering algorithm The former is not realistic in general because it is extremely hard for an expert to specify fuzzy sets in a dynamic environment On the other hand approaches that applied classical clustering algorithms to decide on fuzzy sets have not led to satisfactory results They have not considered the optimization of membership functions Motivated by this we contribute to the ongoing research by proposing a clustering method that employs GAS for the automatic optimization of membership functions used in discovering fuzzy quantitative association rules. GAS are general purpose search algorithms that 
use principles inspired by natural genetic populations to generate solutions to complicated search problems 7 1 I Reda ALHAJJ ADSA Lab Department of Computer Science University of Calgary Calgary, Alberta Canada al hajj  cpsc.ucalgary.ca In our approach the base values of membership functions for each quantitative attribute are tuned by GAS in order to maximize the number of large itemsets in a certain interval of minimum suppon values So we defined a fitness function in terms of large itemsets and minimum support Experimental results on synthetic transactions show that when membership functions optimized according to an interval of lower minimum support values are applied to another interval of near-higher minimum support values they do not show a 
sharp difference Also we have demonstrated the superiority of the proposed GAS-based approach over other existing clustering-based automated approaches in terms of the number of produced large itemsets and interesting association rules In particular we compared our approach with a CURE-based approach, as CURE is considered as one of the most efficient clustering method The rest of this paper is organized as follows Section I1 includes an overview of the related work Fuzzy quantitative association rules are defined in Section II Our approach of utilizing GAS to optimize membership functions is described in Section IV Fuzzy association rules mining is discussed in Section V Experimental results are presented in Section VI Section VI1 is the conclusions 11 
RELATED WORK Fuzzy association rules are also easily understandable to humans because of the linguistic terms associated with fuzzy sets In addition to fuzziness researchers proposed different approaches to overcome the sharp boundary problem. However we have not encountered in the literature any approach that employs GAS as presented in this paper So the rest of this section is dedicated to cover the existing different approaches to deal with the sharp boundary problem Srikant and Agrawal 21 used qui-depth partitioning to mine quantitative rules hey separate intervals by their relative ordering and quantities equally. Miller and Yang applied Birch clustering 18 to identify intervals and proposed a distance based association rules mining to improve the semantics of intervals. Lent et al I71 
presented a geometrjc-based algorithm to perform the clustering in numerical attributes They showed that clustering is a possible solution to figure out meaningful regions and support the discovery of association NleS Another trend to deal with the problem is based on fuzzy theory In contrast to quantitative clustering fuzzy linguistic based approaches focus on qualitative filtering Yager 23 introduced fuzzy linguistic summaries Hirota and Pedrycz IO 201 proposed a context sensitive fuzzy clustering method based on fuzzy C-means to construct rule-based models. However the context-sensitive Fuzzy C-means method cannot deal with data consisting of both numerical and categorical attributes To solve the qualitative knowledge discovery problem Au and Chan 141 employed fuzzy linguistic terms to relational databases with 


numerical and categorical attributes Later they proposed the F MACS method 3 to discover fuzzy association rules They utilized adjacent difference analysis and fuzziness in finding the minimum support and confidence instead of having them supplied by a user They determine both positive and negative associations Fu et al 6 proposed an automated method to find fuzzy sets for the mining of fuzzy association rules their method is based on CLARANS clustering algorithm 191 Hong et al 121 proposed an algorithm that integrates fuzzy set concepts and Apriori mining algorithm to find interesting fuzzy association rules from given transaction data In another paper Hong et al 13 proposed definitions for the support and confidence of fuzzy membership grade and designed a data mining approach based on fuzzy sets to find association rules consistent with linguistic terms of human knowledge. Gyenesei 9 presented two different methods for mining fuzzy quantitative association rules namely without normalization and with normalization The experiments of Gyenesei showed that the numbers of large itemsets and interesting rules found by the fuzzy method are larger than the discrete method defined by Srikant and Agrawal 211 Ishibuchi et al 14 illustrated fuzzy versions of confidence and support that can be used to evaluate each association rule The authors employed these measures of fuzzy rules for function approximation and pattern classification problems Wang and Bridges 22 used GAS to tune membership functions of the fuzzy sets used for intrusion detection system in mining fuzzy association rules Chien et al 51 proposed an efficient hierarchical clustering algorithm based on variation of density to solve the problem of internal partitioning Finally in a previous step of our ongoing research on data mining we developed an efficient approach to automatically specify fuzzy sets based on CURE clustering algorithm 15 111 FUZZY ASSOCIATION RULES Let T=[t q  t be a database of transactions each transaction tj represents the j-th tuple in T We use I={if i2  im to represent all attributes items that appear in r each attribute ik may have a binary categorical or quantitative underlying domain 4 Besides each quantitative attribute ik is associated with several fuzzy sets Explicitly it is possible to define some fuzzy sets for attribute ik with a membership function per fuzzy set such that each value of attribute it qualifies to be in one or more of the fuzzy sets specified for ik The degree of membership of each value of attribute ik in any of its fuzzy sets is directly based on the evaluation of the membership function of the particular fuzzy set with the value of ix as input Let F  If   I t be a set of 1 fuzzy sets associated with ik Membership function of fuzzy set L.,\222 denoted P is a mapping from the domain of it into the interval 0,I Formally yI D 40.11 and the obtained value fdfalls in the interval 0,11 with the lower bound 2230\224 strictly indicates 223not a member\224 while the upper bound 223I\224 indicated 223total membership\224 All the other values between 0 and 1 exclusive specify a 223partial membership\224 degree So given a database of transactions T irs set of attributes I and the fuzzy sets associated with quantitative attributes in I Note that each transaction fj contains values of some attributes from I and each quantitative attribute in I has two or more corresponding fuzzy sets he target is to find out some interesting and potentially useful regularities i.e fuzzy association rules with enough support and high confidence We use the following form for fuzzy association rules 161 If X={xf,x2  x isA=lf,.h  f then Y={yi y2  yql is B=k 82  gql Here X and Yare disjoint sets of attributes called itemsets i.e xC yc,and XnY=$k A and B contain the fuzzy sets associated with corresponding attributes in X and Y respectively i.e.,h is the set of fuzzy sets related to attributexi and gj is the set of fuzzy sets related to attribute y Finally for a rule to be interesting it should have enough support and high confidence value, larger than user specified thresholds IV EMPLOYING GENETIC ALGORITHMS TO OPnMIZE MEMBERSHIP FLINCnONS In general GAS are applied to spaces that are too large to he exhaustively searched They have had a great measure of success in search and optimization problems The reason for a great part of their success is their adaptation i.e their ability to exploit the information accumulated about an initially unknown search space in order to bias subsequent searches into useful subspaces GAS offer a valid approach to problems requiring efficient and effective search techniques The rest of this section is organized as follows The encoding of chromosomes is presented in Section A The fitness function is described in Section B The selection process is discussed in Section C A Chromosome Encoding Our target in using GAS is to cluster the values of quantitative attributes into fuzzy sets with respect to a given fitness evaluation criteria For this purpose each individual represents the base values of membership functions of a quantitative attribute in the database In our experiments we used membership functions in triangular shape because it is in general the most appropriate shape and the most widely used in fuzzy systems To illustrate this consider a quantitative attribute ik and assume it has 3 corresponding fuzzy sets. Three fuzzy sets are assumed because it is in general the most common case encountered in real world applications However in the experiments presented in Section VI we considered 2,3 and 4 fuzzy sets U Fig I Membership functions and base variables of attribute ik Membership functions for attribute ik and their base variables are shown in Figure 1 Each base variable takes finite values For instance the search space of base value 6 lies between the minimum and maximum values of attribute ik denoted MD I and max\(D I respectively Enumerated next are the search intervals of all the base values and intersection point R of attribute ik 882 The IEEE International Conference on Fuzzy Systems 


e min\(D Q,N 8  1~"Q I 11 b Imin\(D I b I  m\(4.11 6  rww  4 11 So based on the assumption of having 3 fuzzy sets per attribute as it is the case with attribute ik a chromosome consisting of the base lengths and the intersection points is represented in the following form 2 b:b:R,b,, b bI2b R b:b bL b Rcb:b We use real-valued coding where chromosomes are represented as floating point numbers and their genes are the real parameters These chromosomes form the input to the fitness function described in the next section B Fitness Evaluation The fitness function measures the goodness of an individual in a given population It is one of the key issues to a successful GA simply because the main task in a GA is to optimize a fitness function Consequently the fitness function should be carefully set by considering all factors that play important role in optimizing the problem under investigation Every new population generated in the process is evaluated with respect to the fitness function The evaluation process is a main source to providing the mechanism for evaluating the status of each chromosome it is an important link between the GA and the system I 2 lurr U Fig 2 The correlation between large itemxts and minimum support values The fimess function accepts a decoded chromosome and produces an objective.value as a measure of the performance of the input chromosome The aim of the GA employed in this study is to maximize the integral of the curve that correlates large itemsets and minimum'support values in a given interval as shown in Figure 2 Consequently the fitness function of the GA used in this study is calculated as follows flrnerr  ZC suplil rmn supli  II izemreirli 11 where n is the number of iterations in a given interval of minimum support values C Selecrion Process During each generation individuals with higher fitness values survive while those with lower fitness values are destroyed In other words individuals who are strong according to parent selection policy are candidates to form a new population Parent selection mimics the survival of the best individuals in the given population Many selection procedures are currently in use However Holland's original fitness-proportionate selection is one of the 3.2 simplest selection procedures Ill So we used this selection policy in our experiments Letfiiness\(x.t\and Avgfifnesslf be, respectively the fitness of individual x and the average fitness of the population during evolution phase f Then the usage value of individual x as a rn~sjr\(i.0 parent is s,\(x  After selecting chromosomes with respect to the evaluation function genetic operators such as crossover and mutation are applied to these individuals Crossover refers to information exchange between individuals in a population in order to produce new individuals The idea behind the crossover operation utilized in our study is as follows It takes as input 2 individuals, selects a random point and exchanges the subindividuals behind the selected point Since the lengths of chromosomes are very long the multi-point crossover strategy was used with the crossover points determined randomly On the other hand mutation means a random change in the information of an individual It is very important for populations It is an operation that defines a local or global variation in an individual Mutation is traditionally performed in order to increase the diversity of the genetic information Otherwise after several generations the diversity of the chromosomes decreases and some chunks of the chromosomes may end up being the same for all population members and the information they contain may not evolve further A probability test determines whether a mutation will be carried out or not The probability of mutation depends on the following condition average fitness of new generation average fitness of old generation Since the initial population can be a subset of all possible solutions, an important bit of each chromosome may be inverted i.e 0 appears as 1 or vice versa Crossover may not solve this and mutation is inevitable for the solution Finally the whole GAS process employed in this study can be summarized as follows After generating each individual in the initial population the executed GA includes the following steps 1 population size N and generate initial chromosomes 2 the number of frequent itemsets according to current 3 each chromosome based on the fitness function 4 selection crossover and mutation 5 not end-test go to step 2 otherwise stop and retum the Ihe test in step 5 depends on the values retumed by the fitness function The fittest chromosomes are selected to form the next generation and the manipulation process is repeated until no significant improvement of the population is observed AqJfmss I chromosomes best chromosome V MINING FUZZY ASSOCIATION RULES After tuning the membership functions in each generation according to the adjusted base values the process of mining fuzzy association rules is executed However while adjusting membership functions of attribute ik by GAS each value of ik intersects with one or more of the membership functions devoted to ik Therefore membership functions do not generally have a uniform structure Having this in mind, attribute ik undergoes a normalization process which is mainly a transformation that at33 The IEEE International Conference on Fuzzy Systems 


leads to a total contribution of 1.0 for attribute ik The normalization is done as follows where I represents the maximum number of fuzzy sets related to attribute ik t\(f,,'.f.k represents the membership degree in the j-th fuzzy set for the value of attribute it in transaction f To generate fuzzy association rules all sets of items that have a support above a user specified threshold should be determined first Itemsets with at least a minimum support are called frequent or large itemsets The process alternates between the generation of candidate and frequent itemsets until large itemsets are identified The following formula is used to calculate the fuzzy support value of itemset Z and its corresponding set of fuzzy sets F denoted Sd  where IT1 is the number of transactions in database T This way all large itemsets are located and identified and the membership functions have been adjusted by GAS in a way that maximizes the sum of large itemsets in a certain interval of minimum support values So the problem of mining all fuzzy association rules converts into generating each ple whose confidence is larger than the user specified minimum confidence Explicitly each large itemset, denoted L is used in deriving all association rules L-S for each ScL The strong association rules discovered are chosen from among all the generated possible association rules by considering only rules with confidence over a pre-specified minimum confidence However all of these rules are not interesting enough to be presented to the user. Whether a rule is interesting or not can be judged either subjectively or objectively Ultimately only the user can judge if a given rule is interesting or not and this judgment being subjective may differ from one user to another However objective interestingness criterion based on the statistics behind the data can be used as one step towards the goal of weeding out uninteresting rules VI EXPERIMENTAL RESULTS We conducted three sets of experiments in order to analyze the effectiveness of the proposed GA-based clustering method Further, the superiority of our approach has been demonstrated by a comparison with our other approach 1151 where we adjusted fuzzy sets using CURE clustering algorithm E As CURE is concemed, its input parameters are: first the input data set D containing IDI-values in n-dimensional space where ID1 is the number of values in the database and n is the number of attributes and second the desired number of clusters k Starting with individual values as individual clusters at each step the closest pair of clusters are merged to form a new cluster The process is repeated until only k clusters are left This way the values of each attribute in the database are distributed into k cluster The centroids of the k clusters are the set of midpoints of the fuzzy sets for the corresponding attribute All experiments were conducted on a Pentium El 1.4GHz CPU with 512 MB of memory and running Windows 2000 As experimental data a synthetic SALES database with 6 attributes and 10K transactions was generated using a randomized transaction generation algorithm. Further in all the experiments conducted in this study, the GA process started with a population of 60 individuals and the results of the 400th generation of the developed GAS program are given next in this section. Finally it is worth mentioning that as the per attribute number of fuzzy sets is concemed three different cases, namely 2 3 and 4 fuzzy sets denoted FS2 FS3 and FS4 respectively, have beeo considered in all the conducted experiments The first set of experiments is dedicated to maximize the integral of the curve that correlates large itemsets and minimum support values within the two intervals and 15,251 The reason for choosing these intervals is that larger number of large itemsets is found with lower minimum support values. This way the sensitivity of the membership functions to be adjusted increases In these experiments, the value of n was set to 10 and the GA process was executed for each integer value between 5 and 15 as well as between 15 and 25 inclusive The results are reported in Figures 3-6 v"""m Fig 3 Number of large itemsets found by GA and CURE fox different values of minimum support 4.x 150 I I 302 6 2 m 2i  i IO I 16 li IS I9 20 I n 11 U U MlrvMmEvppn 19 Fig 4 Comparison of the solutions found by GA with respect to the two intervals 15,151 and 15,25 I 6 1 I P 10 I I I I I Mnun svppon rb Fig 5 The solutions found in case the membership functions adjusted by GA according to the interval 15,25 of minimum suppolr values are applied to the interval 5,151 The numbers of large itemsets produced by applying each of CURE and GA within the interval 15,151 of minimum support values have been reflected into the curves plotted in Figure 3 004 The IEEE International Conference on Fuzzy Systems 


where it can be easily seen that GA-based method outperforms CURE-based approach except for small minimum support values of FS2 Funher, the number of large itemsets found with respect to both methods decreases as the minimum support value increases Also the number of large itemsets is directly proportional to the'number of fuzzy sets However as the minimum support value increases the difference in the number of itemsets produced for different numbers of fuzzy sets becomes smaller Finally the decrease in the number of large itemsets becomes sharper as the number of fuzzy sets increases 150 t  6 110 j m  Im  i  I30 i 50 I I6 I7 II 19 20 21 12 11 2 2 Minimnlsvnnnn 1 Fig 6 Applying the membership functions adjusted by CURE to the interval 115,251 Figure 4 shows the case of how the membership functions optimized by GA according to the interval 5,15 of minimum support values exhibit in the interval 115,251 Figure 4 also gives the best solutions curves found by GA within the interval 15,25 of minimum support values It can be easily observed from Figure 4 that.as the number of fuzzy sets increases the difference between each two solutions that correspond to the same number of fuzzy sets but with respect to different intervals increases. The direction of this increase in the difference depends on the considered minimum support values For small minimum suppon values, the solutions found according to the interval 5,15 produce more large itemsets This can be easily observed by comparing each solution in Figure 3 with the solution that employs the same number of fuzzy sets in Figure 5 which gives the solutions obtained in case that the membership functions adjusted according to the interval 15,25 of minimum support values are applied to the interval 15,151 However, this advantage moves in favor of the solutions found according to the interval 15,25 as the support value increases This latter case is obvious from Figure 4 Finally plotted in Figure 6 are the numbers of large itemsets found by applying CURE in the interval 115,251 of minimum suppon values Here it should he noted that CURE finds the ranges of fuzzy sets independent from minimum suppon values The second set of experiments is dedicated to investigate the correlation between minimum confidence and the number of interesting association rules discovered with different numbers of fuzzy sets and within the two intervals 5,15 and 15,251 of minimum support values. The results obtained by employing GA are shown in Figure 7 and Figure 8 with the minimum suppon value set to 8 and 20 respectively; the results of the CURE based approach for the same two minimum suppon values are reported in Figure 9 From Figure 7 it can be easily seen that by considering the Same number of fuzzy sets in each of the two intervals the number of association rules discovered within the interval 5,15 is larger than the number of association rules discovered within 1w1 A  the interval 115,251 for small values of minimum confidence However as the minimum Confidence increases the number of discovered association rules decreases and each pair of solutions that employ the same number of fuzzy sets get close to each other. This can be easily observed by looking at the right hand side of Figure 7 and at all of Figure 8 FS2\(88 ii--FS2\(208 dr-FSJ\(XCa CFSqZWr 0-FS3\(8 FSXZW L o 0.z 01 011 04 041 05 01 0 MinimmConfidence Fig 7 Number of association rules found by GA according to the two intervals 5,15 and 15,251 minimum suppon set to 8 01 I 0 3 a c I 55 6 Mwmum Colddrncs Fig 9 The relationship between the number of association rules and the solutions found by CURE with both minimum suppon values The decrease in the number of discovered association rules becomes sharper as the number of fuzzy sets involved in the process increases Further for each pair of solutions that correspond to the same number of fuzzy sets there is a value of minimum confidence after which the number of association rules discovered within the interval 5,151 exceeds the number of association rules discovered within the interval 15,25 This can be easily seen by looking at the right hand side of Figure 8 Finally comparing the curves plotted in Figure 9 with those plotted in Figure 7 and Figure 8 it can be stated that under the 885 The IEEE International Conference on Fuzzy Systems 


same conditions GA-based approach produces more fuzzy association rules than CURE-based approach 6 n value 8 10 Fig IO The values of fitness obtained with respect to fferent n values me last experiment shows the effectiveness of the value of n As the value of n increases in a constant interval the execution time of the GA-based method also increases However since the sensitivity of membership functions enhances a more suitable clustering is handled with a higher value of n Fitness values obtained with respect to 4 different n values in the interval 5,151 of minimum support values are given in Figure 10 As the number of fuzzy sets used in the process increases, the value of the fitness increases as well. Also the value of the fitness decreases along with an increase in the value of n this is quite consistent with our intuition At the end, the number of fuzzy sets to consider depends on the application it is in general accepted as three fuzzy sets for most applications Also the choice of the method to adapt is also based on the expectations of the application under consideration However optimizing membership functions by GAS-based method is in general more effective VII CONCLUSIONS In this study we proposed a clustering approach to solve the problem of interval partitioning in favor of the maximum number of large itemsets within a particular interval of minimum support values The main achievement of the proposed approach is employing GAS to dynamically adjust and optimize membership functions in an interval of user-specified minimum support values We realized that the CA-based method is completely dependent on the specified interval of minimum support values. In order to show its superiority we compared the proposed approach with a CURE-based approach The conducted experiments showed that in general fuzzy sets optimized by GA produce larger solutions and hence more interesting rules than a clustering algorithm based approach In this study, we also observed that membership functions adjusted by GA according to intervals of lower minimum support values produce larger number of large itemsets and hence large number of interesting association rules compared to those optimized in an interval of near-higher minimum support values. However if the former membership functions are used in the latter interval when comparing the membership functions adjusted according to the latter interval the difference between these two solutions is not very sharp For this reason although it requires larger execution time after a certain number of transactions it is recommended to consider membership functions adjusted and optimized by using CA in an interval of smaller minimum support values REFERENCES I R Agrawal T hielinski and A Swami 223Mining association mles between sets of items in large databases,\224 Proc of ACM SICMOD pp.207-216 1993 2 A Arslan and M Kaya 223Determination of Fuzzy Logic Membership Functions using Genetic Algorithms,\224 Fuzzy Sets and Systems Vol.ll8 No.2, pp.297-306 2001 3 W.H Au and K.C.C Chan 223An Effective Algorithm\222for Discovering Fuzzy Rules in Relational Databases,\224 Proc of IEEEICFS pp.1314-1319, 1998  K.C.C Chan and W.H Au 223Mining Fuzzy Association Rules,\224 Proc ofACM CIKMl Las Vegas pp.209-215, 1997 5 B.C Chien Z.L Lin and T.P Hong 223An Efficient Clustering Algorithm for Mining Fuzzy Quantitative Association Rules,\224 IFSA World Congress  NAFIPS Vo1.3 pp.1306-131 I 2001 6 A.W.C Fu et al 223Finding Fuzzy Sets for the Mining of Association Rules for Numerical Attributes,\224 Proc of ISIDEL pp.263-268 Oct 1998 7 D.E Goldberg Genetic Algorithm in Search Optimizarion and Machine Learning Addison-Wesley, Reading MA 1989 SI S Guha R Rastogi and K Shim 223CURE An Efficient Clustering Algorithm for Large Databases,\224 Information Systems Vo1.26 No.1 pp.35-58 2001 9 A Gyenesei 223A Fuzzy Approach for Mining Quantitative Association Rules,\224 TUCS Technical Report No.336.2000 IO K Hirota and W Pedrycz 223Linguistic Data Mining and Fuzzy Modelling,\224 Pror of IEEE ICFS V01.2 pp 1448-1496, 1996 I I J.H. Holland Adaptation in Natural and Artificial System The MI Press, Cambridge MA MF Press edition 1992 1121 T.P Hong C.S Kuo and S.C Chi 223A fuzzy data mining algorithm for quantitative values,\224 Proc of ICKBIIES pp.480 483 1999 I31 T.P Hong C.S Kuo and S.C Chi 223Mining Association Rules from Quantitative Data,\224 Intelligent Data Analysis Vo1.3 pp.363-376, 1999 I41 H Ishibuchi T Nakashima and T Yamamoto 224Fuzzy Association Rules for Handling Continuous Attributes,\224 Proc ofIEEElSIE pp.l18-121,2001 I51 M Kaya R Albajl F Polat and A Arslan 223Efficient Automated Mining of Fuzzy Association Rules,\224 Proc of DEXA 2002 I61 C.M Kuok A.W Fu and M.H Wong 223Mining fuzzy association des in databases,\224 SICMOD Record Vol 17 No.1 pp.41-46 1998 I71 B Lent A Swami and 1 Widom 223Clustering Association Rules,\224 Proc of IEEEICDE pp.220-231 1997 IS R.J Miller and Y Yang 223Association Rules over Interval Data,\224 Proceedings of the ACM SICMOD pp.452461 1997 I91 R Ng and I Han 223Efficient and effective clustering methcds for spatial data mining,\224 Proc of VLDB 1994 20 W Pedrycz 223Fuzzy Sets Technology in Knowledge Discovery,\224 Fuzzy Sets and Systems 98 pp.279-290, 1998 ZI R Srikant and R Agrawal 223Mining quantitative association rules in large relational tables,\224 Proc of ACM SICMOD pp.1 12 1996 22 W Wang and S.M Bridges, \223Genetic Algorithm Optimization of Membership Functions for Mining Fuzzy Association Rules,\224 Proc oflCFIT pp.131-134.2000 23 R.R. Yager, \224Fuzzy Summaries in Database Mining,\224 Proc of ICAIA pp.265-269 1995 24 L.A Zadeh 223Fuzzy Sets.\224 Information and Control Vo1.8 pp.338-353, 1965 886 The IEEE International Conference on Fuzzy Systems 


007\003\026\001 017\035\035\004\b\017\032\003\001 017\021!\001 007\003\026\001 007\b\b\023\001 005\021\001 035\017\004\007\005\032\r\023\017\004\013\001 007\003\017\007\001 006\003\b\r\023!\001 026\001 035\026\004\036\b\004\030\026!\001 005\021\001 b\004!\026\004\001 007\b\001 017\032\003\005\026#\026\001 017\001 032\b\030\035\023\026\007\026\001 006\b\023\r\007\005\b\021\001 007\b\001 007\003\026\001 035\004\b"\023\026\030\001 b\036\001 006\b\r\004\032\026\001 032\b!\026\001 001 t\003\026\006\026\001 005\030\035\004\b#\026\030\026\021\007\006\001 005\021\032\023\r!\026\031\001 003 001 024\002\034\006\016\b"\t n\006\033\002\005\t 004$"\n\005\016\006\033\007\034\t 013\n\005\t 007\016\b\016\b"\t 004\034\034\n\032\016\004\006\016\n\b\t 005\r$\002\034 034\001 003\005\016\n\005\016 001 037\017\006\001 006\026\023\026\032\007\026!\001 007\b\001 026\001 007\003\026\001 017\006\026\001 017\023 \b\004\005\007\003\030\001 036\b\004\001 026\006\005 \021\005\021 \001 007\003\026\001 007\b\b\023\034\001 5\b\037\026#\026\004\013\001 005\007\001 037\b\r\023!\001 026\001 032\003\017\023\023\026\021 \005\021 \001 007\b\001 r\006\026\001\b\007\003\026\004\001\017\023 \b\004\005\007\003\030\006\001\036\b\004\001\030\005\021\005\021 \001\017\006\006\b\032\005\017\007\005\b\021\001\004\r\023\026\006\001\007\003\017\007\001\030\017\024\001 035\026\004\036\b\004\030\001 026:\r\017\023\023\024\001 037\026\023\023\001 b\004\001 026#\026\021\001 026\007\007\026\004\001 007\003\017\021\001 035\004\005\b\004\005\013\001 026\006\035\026\032\005\017\023\023\024\001 005\021\001 032\017\006\026\006\001 037\005\007\003\001 026\004\024\001 023\017\004 \026\001 017\007\017"\017\006\026\006\034\001 t\003\005\006\001 032\b\030\035\017\004\017\007\005#\026\001 017\006\006\026\006\006\030\026\021\007\001 032\b\r\023!\001 004\026\006\r\023\007\001 005\021\001 017\001 b\b\023\006\026\007\001 036\b\004\001 030\005\021\005\021 \001\004\r\023\026\006\034\001\001 003 001 6\n\005\007\004\006\016\n\b\t\n\013\t\004\t7\r\004\b\006\016\006\004\006\016'\002\t\\016\b\003\r\006\t\007\n&\002 034\001 t\003\026\001!\017\007\017\001\030\b!\026\023\001\035\004\b\035\b\006\026!\001\005\021\001\007\003\005\006\001\030\026\007\003\b!\001\005\006\001:\r\017\023\005\007\017\007\005#\026\034\001 001 035\b\006\006\005"\023\026\001 026\021\003\017\021\032\026\030\026\021\007\001 037\b\r\023!\001 026\001 007\003\026\001 036\b\004\030\017\007\005\b\021\001 b\036\001 017\001 r\017\021\007\005\007\017\007\005#\026\001!\017\007\017\001\030\b!\026\023\034\001\020\r\032\003\001\017\001\030\b!\026\023\001\037\b\r\023!\001"\026\001\004\005\032\003\026\004\001\017\006\001 005\007\001 032\b\r\023!\001 032\017\035\007\r\004\026\001 005\021\036\b\004\030\017\007\005\b\021\001 021\b\007\001 b\021\023\024\001 036\b\004\001 007\003\026\001 026\\005\006\007\026\021\032\026G\017"\006\026\021\032\026\001\b\036\001\032\b!\026\001\005\007\026\030\006\001\005\021\001"\023\b\032\016\006\013\001"\r\007\001\017\023\006\b\001\036\b\004\001\007\003\026\001 021\r\030"\026\004\001\b\036\001\005\007\026\030\001\b\032\032\r\004\004\026\021\032\026\006\001\005\021\006\005!\026\001"\023\b\032\016\006\034\001\(\b\004\001\026\\017\030\035\023\026\001\017\001 004\r\023\026\001\b\036\001\007\003\026\001\036\b\004\030\001 016\006\002\007*8\t 9\t 001 t 016\006\002\007\0278\t t 0\t  001\037\b\r\023!\001 030\026\017\021\031\001A\005\036\001\005\007\026\030?\001\b\032\032\r\004\006\0018\001\007\005\030\026\006\001\007\003\026\021\001\005\007\026\030@\001\b\032\032\r\004\006\001*\001\r\035\001\007\b\001 001 007\005\030\026\006B\034\001 C\026\001 006\003\b\r\023!\001 021\b\007\026\001 007\003\017\007\001 017!\b\035\007\005\b\021\001 b\036\001 001 021\007\005\007\017\007\005#\026\001 017\007\017\001 030\b!\026\023\001 004\026:\r\005\004\026\006\001 017\021\001 017\023 \b\004\005\007\003\030\001 007\003\017\007\001 032\017\021\001 035\004\b!\r\032\026\001 017\021!\001 035\004\b\032\026\006\006\001:\r\017\021\007\005\007\017\007\005#\026\001\017\006\006\b\032\005\017\007\005\b\021\001\004\r\023\026\006\034\001 003 001 r\006\n\007\004\006\016\032\t&\002\005\016'\004\006\016\n\b\t\n\013\t\016\b\003\r\006\t&\004\006\004 034\001 t\003\026\001 035\004\b\035\b\006\026!\001 030\026\007\003\b!\001 017\006\006\r\030\026\006\001 007\003\026\001 026\\005\006\007\026\021\032\026\001 b\036\001 005\021\035\r\007\001 017\007\017\001 036\004\b\030\001 006\b\r\004\032\026\001 032\b!\026\013\001 037\003\005\032\003\001 032\017\021\001 026\001 026\\007\004\017\032\007\026!\001 026\005\007\003\026\004\001 030\017\021\r\017\023\023\024\001\b\004\001\017\r\007\b\030\017\007\005\032\017\023\023\024\034\0015\b\037\026#\026\004\013\001\005\021\001\004\026\017\023\001\032\b\021!\005\007\005\b\021\006\013\001\005\007\001 005\006\001\005\030\035\b\006\006\005"\023\026\001\007\b\001\030\017\021\r\017\023\023\024\001\032\004\026\017\007\026\001\005\021\035\r\007\001!\017\007\017\001\036\004\b\030\001\035\004\b \004\017\030\006\001 032\b\021\006\005\006\007\005\021 \001\b\036\001\007\003\b\r\006\017\021!\006\001\fF\002\034\001\027#\026\021\001\036\b\004\001\006\030\017\023\023\026\004\001\035\004\b \004\017\030\006\013\001 007\003\005\006\001\007\017\006\016\001\005\006\001\007\005\030\026\001\032\b\021\006\r\030\005\021 \034\001\t\003\r\006\013\001\005\021\001\b\004!\026\004\001\007\b\001\035\004\b#\005!\026\001\017\021\001 005\021\007\026 \004\017\007\026!\001\006\b\023\r\007\005\b\021\001\007\b\001\006\b\r\004\032\026\001\032\b!\026\001\017\021\017\023\024\006\005\006\013\001\007\003\026\001\017\r\007\b\030\017\007\005\032\001 032\004\026\017\007\005\b\021\001 b\036\001 005\021\035\r\007\001 017\007\017\001 006\003\b\r\023!\001 026\001 005\021\032\b\004\035\b\004\017\007\026!\001 005\021\001 007\003\026\001 004\026\006\026\021\007\001\035\004\b\007\b\007\024\035\026\001\007\b\b\023\001\005\006\001\026:\r\005\035\035\026!\001\037\005\007\003\001 017\001\006\b\r\004\032\026\001\032\b!\026\001\017\021\017\023\024\006\026\004\001\037\003\005\032\003\001\032\017\021\001\026\\007\004\017\032\007\001!\017\007\017\001\036\004\b\030\001\006\b\r\004\032\026\001 032\b!\026\001\b\004\001\026#\026\021\001\007\003\026\001\b\r\007\032\b\030\026\001\b\036\001\017\001\035\017\004\006\026\004\034\001 003 001 6\r\005\006\033\002\005\t\006\002\034\006\016\b"\t\n\b\t$\004\005"\002\005\t\003\005\n"\005\004\007\034 034\001 I\017\023\005!\017\007\005\b\021\001\007\026\006\007\006\001\037\026\004\026\001\026\\026\032\r\007\026!\001\b\021\001\035\004\b \004\017\030\006\001\032\b\021\007\017\005\021\005\021 \001 r\035\001 007\b\001 001 023\005\021\026\006\001 b\036\001 032\b!\026\034\001 021\001 b\004!\026\004\001 007\b\001 017\032\003\005\026#\026\001 017\001 026\007\007\026\004\001 026#\017\023\r\017\007\005\b\021\001 b\036\001 007\003\026\001 035\004\b!\r\032\026!\001 004\026\006\r\023\007\006\013\001 030\b\004\026\001 007\026\006\007\006\001 006\003\b\r\023!\001 026\001 035\026\004\036\b\004\030\026!\001 b\021\001 023\017\004 \026\004\001 035\004\b \004\017\030\006\034\001 5\b\037\026#\026\004\013\001 005\021\001 b\004!\026\004\001 007\b\001 035\004\b\032\026\026!\001 007\b\001 007\003\026\006\026\001 007\026\006\007\006\013\001 007\003\026\001 035\004\026#\005\b\r\006\001 026\021\003\017\021\032\026\030\026\021\007\001 006\003\b\r\023!\001 026\001\005\030\035\023\026\030\026\021\007\026!\001\036\005\004\006\007\013\001\006\b\001\017\006\001\007\b\001 \026\007\001\007\003\026\001\005\021\035\r\007\001!\017\007\017\001\036\004\b\030\001\007\003\026\006\026\001 035\004\b \004\017\030\006\001\017\r\007\b\030\017\007\005\032\017\023\023\024\034\001 003 001 023\n\r\005\032\002\t\032\n&\002\t\004\b\004$%\034\016\034\t\004\006\t\006\033\002\t\034\006\004\006\002\007\002\b\006\t$\002'\002 034\001 006\001 035\004\026#\005\b\r\006\023\024\001 030\026\021\007\005\b\021\026!\001 023\b\032\016\001 026\021\007\005\007\005\026\006\001 032\017\021\001 026\001 026\005\007\003\026\004\001 030\b!\r\023\026\006\001 3\036\r\021\032\007\005\b\021\006\013\001 032\023\017\006\006\026\006\013\001 035\004\b\032\026!\r\004\026\0064\001 b\004\001 006\005\021 \023\026\001 006\007\017\007\026\030\026\021\007\006\034\001 2\035\001 007\b\001 021\b\037\013\001 007\003\026\001 006\r  \026\006\007\026!\001 017\035\035\004\b\017\032\003\001 032\b\021\032\026\021\007\004\017\007\026!\001 b\021\001 017\001 030\b!\026\023\001 032\b\021\006\005\006\007\005\021 \001 b\036\001 030\b!\r\023\026\006\001 021!\001 003\026\001 r\023\007\005\030\017\007\026\001 017\005\030\001 037\017\006\001 007\b\001 032\004\026\017\007\026\001 035\004\b \004\017\030\001 026\032\b\030\035\b\006\005\007\005\b\021\001 005\021\001 004\b\r\035\006\001 032\b\021\007\017\005\021\005\021 \001 005\021\007\026\004\032\b\021\021\026\032\007\026!\001 030\b!\r\023\026\006\034\001 F\021\001 007\003\026\001 b\007\003\026\004\001 003\017\021!\013\001 007\003\026\001 007\b\b\023\001 032\017\021\001 017\023\006\b\001 026\001 r\006\026!\001 005\021\001 b\004!\026\004\001 007\b\001 035\026\004\036\b\004\030\001 017\001 006\b\r\004\032\026\001\032\b!\026\001\017\021\017\023\024\006\005\006\001\005\021\001\007\003\026\001\006\007\017\007\026\030\026\021\007\001\023\026#\026\023\034\001\t\b\001!\b\001\006\b\013\001\007\003\026\001 005\021\035\r\007\001 017\007\017\001 006\003\b\r\023!\001 032\b\021\006\005\006\007\001 b\036\001 004\026\032\b\004!\006\001 004\026\035\004\026\006\026\021\007\005\021 \001 006\007\017\007\026\030\026\021\007\006\001 017\021!\001 007\003\026\001 036\005\021\017\023\001 004\026\006\r\023\007\006\001 037\005\023\023\001 035\004\b!\r\032\026\001 004\b\r\035\006\001 b\036\001 004\026\023\017\007\026!\001 006\007\017\007\026\030\026\021\007\006\034\001 t\003\005\006\001 016\005\021!\001 b\036\001 006\001 005\006\001 036\r\023\013\001 037\003\026\021\001 023\b\032\017\023\001\035\017\004\007\006\001\b\036\001\017\001\035\004\b \004\017\030\001\021\026\026!\001\007\b\001"\026\001\r\021!\026\004\006\007\b\b!\034\001 001 027\020\031\020\013\020\b\004\020\022\001 001  001 D\034\001 004\017\037\017\023\013\001 t\034\001 030\005\026\023\005\021\006\016\005\001 017\021!\001 034\001 020\037\017\030\005\013\001 A=\005\021\005\021 \001 006\006\b\032\005\017\007\005\b\021\001 D\r\023\026\006\001 026\007\037\026\026\021\001 026\007\006\001 b\036\001 001 005\021\001 f\017\004 \026\001 017\007\017"\017\006\026\006B\013\001 025\005\n\032 n\013\t 006\033\002\t f\021\t 023\0221\021\026\001\t f\n\b\013\002\005\002\b\032\002\t n\b\t 021\004\b\004"\002\007\002\b\006\t\n\013\t\001\004\006\004 013\001%//8\013\001\035\035\034\001*,&.*%6\034\001  001 D\034\001 004\017\037\017\023\001 017\021!\001 D\034\001 020\004\005\016\017\021\007\013\001 A\(\017\006\007\001 023 \b\004\005\007\003\030\006\001 036\b\004\001 005\021\005\021 \001 006\006\b\032\005\017\007\005\b\021\001 D\r\023\026\006B\013\001 025\005\n\032 036 006\033 t 022\b\0063$\t f\n\b\013 002\005%\t 004\005"\002\t 001\004\006\004\027\004\034\002\034 0013I\f;@\001/14\013\001%//1\013\001\035\035\034\00117&.1//\034\001 8 001 E\034\001 021:\r\026\007\005\023\001 017\021!\001 t\034\001 002\034\001 f\026\007\003"\004\005! \026\013\001 A\027\\035\026\004\005\030\026\021\007\006\001 037\005\007\003\001 002\023\r\006\007\026\004\005\021 \001\017\006\001\017\001\020\b\036\007\037\017\004\026\001D\026\030\b!\r\023\017\004\005\025\017\007\005\b\021\001\030\026\007\003\b!B\013\001 025\005\n\032 035 006\033 t@\n\005-\016\b"\t\f\n\b\013\+\002'\002\005\034\002\t,\b"\016\b\002\002\005\016\b 0013C\002D\027\001//4\013\001<\027\027\027\001 002\b\030\035\034\001\020\b\032\034\001\022\004\026\006\006\013\001F\032\007\034\001%///\013\001\035\035\034\001*8+.*++\034\001 1 001 001\(\034\001 017\023\030\017\006\013\001 5\034\001 C\026\004\007\025\001 017\021!\001 J\034\001 020\005\021 \026\004\013\001 K2\021!\026\004\006\007\017\021!\005\021 \001 022\004\b \004\017\030\001 2\021!\026\004\006\007\017\021!\005\021 K\013\001 022\004\b\032\034\001 7\007\003\001 021\007L\023\001 C\b\004\016\006\003\b\035\001 022\004\b \004\017\030\001 002\b\030\035\004\026\003\026\021\006\005\b\021\001 3<C\022\002\001 4\013\001 027\027\027\001 002\b\030\035\034\001 020\b\032\034\001 022\004\026\006\006\013\001*,,,\013\001\035\035\034\001*+6\034\001  001 001\027\034\001 r\004!\013\001 034\001 r\021\004\b\013\001 K\027#\017\023\r\017\007\005\021 \001 007\003\026\001 2\006\026\001 b\036\001 b\030\005\021\017\021\032\026\001 t\004\026\026\006\001\036\b\004\001\002\001\017\021!\001\002F@F\fK\013\001\022\004\b\032\026\026!\005\021 \006\001\b\036\001\007\003\026\001<\021\007\026\004\021\017\007\005\b\021\017\023\001 002\b\021\036\026\004\026\021\032\026\001 b\021\001 020\b\036\007\037\017\004\026\001 017\005\021\007\026\021\017\021\032\026\013\001 F\\036\b\004!\013\001 027\021 \023\017\021!\013\001 r \r\006\007\001 8,.\020\026\035\007\026\030"\026\004\001 8\013\001 013\001 027\027\027\001 002\b\030\035\r\007\026\004\001 020\b\032\005\026\007\024\001 022\004\026\006\006\013\001%///\013\001<\020@E\001,&6/+,,%6%\013\001\035\035\034\0011,%.1%,\034\001 6 001 001>\034\001 002\017\021\036\b\004\017\013\001 034\001 002\005\030\005\007\005\023\026\013\001 034\001 026\001 f\r\032\005\017\013\001 034?\034\001 005\001 f\r\032\032\017\013\001 A;\026\032\b\030\035\b\006\005\021 \001 023\026 \017\032\024\001 001 005\021\007\b\001 b"\n\026\032\007\006\031\001 021\001 026\032\023\026\032\007\005\032\001 017\035\035\004\b\017\032\003B\013\001 021\036\b\004\030\017\007\005\b\021\001 017\021!\001 020\b\036\007\037\017\004\026\001 t\026\032\003\021\b\023\b \024\013\001 I\b\023\034\001 18\013\001*,,%\013\001\035\035\0011,%.1%*\034\001  001 M\034\001 002\003\026\021\013\001 002\034\001 t\n\b\004\007\n\005\006\001 017\021!\001 022\034J\034\001 f\017\024\025\026\023\023\013\001 A?\001 026\007\003\b!\001 036\b\004\001 f\026 \017\032\024\001 020\024\006\007\026\030\006\001 017\005\021\007\026\021\017\021\032\026\001 024\001 005\021\005\021 \001 017\007\017\001 027\\007\004\017\032\007\026!\001 036\004\b\030\001 020\b\r\004\032\026\001 002\b!\026B\013\001 f\004\034\002\t 034\006\r&\016\002\034\t n\013\t 022,,,\t 035 006\033 t r\005\n\003\002\004\b\t f\n\b\013 023\n\013\006#\004\005\002\t 021\004\016\b\006\002\b\004\b\032\002\t 004\b&\t 002\002\b"\016\b\002\002\005\016\b 001 3\002\020=D\001 4\013\001<\027\027\027\001\002\b\030\035\034\001\020\b\032\034\001\022\004\026\006\006\013\001*,,*\013\001\035\035\034\001+1.6,\034\001 7 001 002\034=\034\001 026\001 F\032\017\001 017\021!\001 034\f\001 002\017\004#\026\004\013\001 A<!\026\021\007\005\036\005\032\017\007\005\b\021\001 b\036\001 017\007\017\001 002\b\003\026\006\005#\026\001 020\r"\006\024\006\007\026\030\006\001 2\006\005\021 \001 017\007\017\001 005\021\005\021 \001 t\026\032\003\021\005:\r\026\006B\013\001 025\005\n\032\\022\b\0063$\t\f\n\b\013\\023\n\013\006#\004\005\002\t\021\004\016\b\006\002\b\004\b\032\002\t 3<\002\020=\001/74\013\001<\027\027\027\001 002\b\030\035\034\001\020\b\032\034\001\022\004\026\006\006\013\001%//7\013\001\035\035\034%6.*8\034\001  001 001M\034\001 027\004!N\006\001 017\021!\001 5\034=\034\001 020\021\026\026!\013\001 A\022\017\004\007\005\017\023\001 002\b\030\035\004\026\003\026\021\006\005\b\021\001 b\036\001 002\b\030\035\023\026\\001 022\004\b \004\017\030\006\001 3\026\021\b\r \003\001 007\b\001 035\026\004\036\b\004\030\001 030\017\005\021\007\026\021\017\021\032\0264B\013\001 025\005\n\032\t\035\006\033\t\022\b\0063$\t@\n\005-\034\033\n\003\t\025\005\n"\005\004\007\t\f\n\007\003\005\002\033\002\b\034\016\n\b 0013<C\022\002\001 74\013\001<\027\027\027\001\002\b\030\035\034\001\020\b\032\034\001\022\004\026\006\006\013\001%//7\013\001\035\035\034\001/7.%,+\034\001  001 001?\034D\034\001 017\006\b\023\005\021\b\001 017\021!\001 034\001 I\005\006\017  \005\b\013\001 A<\030\035\004\b#\005\021 \001 020\b\036\007\037\017\004\026\001 002\b\030\035\004\026\003\026\021\006\005\b\021\001 007\003\004\b\r \003\001 017\021\001 001 026\021!\026\021\032\024\001 t\004\017\032\026\004B\013\001 025\005\n\032\A 006\033 t@\n\005-\034\033\n\003\t\025\005\n"\005\004\007\t\020\b&\002\005\034\006\004\b&\016\b"\t 3<C\022\002\001//4\013\001<\027\027\027\001\002\b\030\035\034\001\020\b\032\034\001\022\004\026\006\006\013\001%///\034\001  001 0012\034\001=\034\001\(\017\024\024\017!\013\001>\034\001\022\005\017\007\026\007\006\016\024.\020\003\017\035\005\004\b\001\017\021!\001\022\034\001\020\030\024\007\003\034\001A\(\004\b\030\001 017\007\017\001 005\021\005\021 \001 007\b\001M\021\b\037\023\026! \026\001;\005\006\032\b#\026\004\024\031\001?\021\001F#\026\004#\005\026\037B\013\001\005\021\001 004\b\032\002\034\t 016\b\t b\n#$\002&"\002\t 001\016\034\032\n'\002\005%\t 004\b&\t 001\004\006\004\t 021\016\b\016\b 013\001 001\022\004\026\006\006\013\001 6\034\001 Proceedings of the 11 th IEEE International Workshop on Program Comprehension \(IWPC\22203 1092-8138/03 $17.00 \251 2003 IEEE 


 001 034\001 f\017\016\003\b\007\005\017\013\001 A?\001 2\021\005\036\005\026!\001 004\017\030\026\037\b\004\016\001 b\004\001 027\\035\004\026\006\006\005\021 \001 020\b\036\007\037\017\004\026\001 020\r"\006\024\006\007\026\030\001 002\023\017\006\006\005\036\005\032\017\007\005\b\021\001 t\026\032\003\021\005:\r\026\006B\013\001 B\n\r\005\b\004$\t n\013\t 023%\034\006\002\007\034\t 004\b&\t 023\n\013\006#\004\005\002\017\t I\b\023\034\001 86\013\001 E\b\001 8\013\001 035\017 \026\006\001 8%\001 034\001 8 001 020\034\001=\017\021\032\b\004\005!\005\006\013\001@\034\001\020\034\001=\005\007\032\003\026\023\023\013\001\002\034\001D\b\004\004\026\006\013\001O\034\001\002\003\026\021\001\017\021!\001\027\034\001 D\034\001 017\021\006\021\026\004\013\001 A2\006\005\021 \001 r\007\b\030\017\007\005\032\001 002\023\r\006\007\026\004\005\021 \001 007\b\001 022\004\b!\r\032\026\001 5\005 \003.\f\026#\026\023\001\020\024\006\007\026\030\001F\004 \017\021\005\006\017\007\005\b\021\006\001\b\036\001\020\b\r\004\032\026\001\002\b!\026B\013\001 025\005\n\032 035 006\033 t t n\005-\034\033\n\003\t 025\005\n"\005\004\007\t 020\b&\002\005\034\006\004\b&\016\b"\t 3<C\022\002\001 74\013\001 027\027\027\001\002\b\030\035\034\001\020\b\032\034\001\022\004\026\006\006\013\001%//7\013\001\035\035\034\0011+.+8\034\001 1 001 034\001 I\b\021\001 017\024\004\003\017\r\006\026\004\001 017\021!\001 034=\034\001 I\017\021\006\013\001 025\005\n"\005\004\007\t 020\b&\002\005\034\006\004\b&\016\b"\t C\t t 023\r\005'\002 013\001 t\026\032\003\021\005\032\017\023\001 D\026\035\b\004\007\001 002\020./1.%*,\013\001 026\035\007\034\001 b\036\001 002\b\030\035\r\007\026\004\001 020\032\005\026\021\032\026\013\001 002\b\023\023\b\004\017!\b\001 020\007\017\007\026\001 2\021\005#\026\004\006\005\007\024\013\001 r \r\006\007\001%//1\034\001  001 t\034=\034\001 022\005 \b\006\016\005\013\001 025\005\004\032\006\016\032\004$\t 023\n\013\006#\004\005\002\t 021\004\016\b\006\002\b\004\b\032\0028\t 027\002\034\006\t 025\005\004\032\006\016\032\002\034\t 013\n\005\t 021\004\b\004"\016\b"\t n\r\005\t 023\n\013\006#\004\005\002\t\022\b'\002\034\006\007\002\b\006 013\001C\005\023\026\024\001 002\b\030\035\r\007\026\004\001\022\r"\023\005\006\003\005\021 \013\001%//6\034\001 6 001 M\034\001 017\004\007\005\035\005\013\001 M\034\001 M\b\021\007\b \005\017\021\021\005\006\001 017\021!\001 034\001 017#\017!!\017\007\013\001 H?\004\032\003\005\007\026\032\007\r\004\017\023\001 026\006\005 \021\001 D\026\032\b#\026\004\024\001 2\006\005\021 \001 017\007\017\001 005\021\005\021 \001 t\026\032\003\021\005:\r\026\0060\013 t t b&\t r\005\n\003\002\004\b\t n\005-\016\b"\t f\n\b\013 023\n\013\006#\004\005\002\t 021\004\016\b\006\002\b\004\b\032\002\t 002\002\b"\016\b\002\002\005\016\b"\t 3\002\020=D\001 4\013\001 027\027\027\001\002\b\030\035\034\001\020\b\032\034\001\022\004\026\006\006\013\001*,,,\013\001\035\035\034\001%*/.%1,\034\001  001 034\001 020\b\030\030\026\004#\005\023\023\026\013\001 023\n\013\006#\004\005\002\t b"\016\b\002\002\005\016\b 013\001 6\007\003\001 026!\005\007\005\b\021\013\001 5\017\004\023\b\037\013\001?!!\005\006\b\021.C\026\006\023\026\024\013\001*,,%\034\001 7 001 034\001 t\005\035\013\001 K?\001 020\r\004#\026\024\001 b\036\001 022\004\b \004\017\030\001 020\023\005\032\005\021 \001 t\026\032\003\021\005:\r\026\006K\013\001 t\026\032\003\021\005\032\017\023\001 D\026\035\b\004\007\001 002\020.D/187\013\001 002\026\021\007\004\r\030\001 b\b\004\001C\005\006\016\r\021!\026\001\026\021\001 021\036\b\004\030\017\007\005\032\017\013\001?\030\006\007\026\004!\017\030\013\001%//1\034\001  001 002\034\001 t\n\b\004\007\n\005\006\013\001 E\034\001 b\023!\013\001 022\034J\034\001 f\017\024\025\026\023\023\001 017\021!\001 M\034\001 026\021\021\026\007\007\013\001 A\(\004\b\030\001 020\024\006\007\026\030\001 002\b\030\035\004\026\003\026\021\006\005\b\021\001 007\b\001 022\004\b \004\017\030\001 002\b\030\035\004\026\003\026\021\006\005\b\021B\013\001 025\005\n\032 022,,,\t 035\006\033\t 022\b\0063$\t f\n\007\003\r\006\002\005\t 023\n\013\006#\004\005\002\t 003\003$\016\032\004\006\016\n\b\034\t f\n\b\013 0013\002F=\022\020?\002\001,*4\013\001<\027\027\027\001\002\b\030\035\034\001\020\b\032\034\001\022\004\026\006\006\013\001*,,*\013\001\035\035\034\001 1*&.18*\034\001  001 b\004\007\n\005\006\001\017\021!\001\022\034J\034\001\f\017\024\025\026\023\023\013\001A2\006\005\021 \001;\017\007\017\001=\005\021\005\021 \001\007\b\001?\006\006\026\006\006\001 026\001 D\026\023\005\017"\005\023\005\007\024B\013\001 023\r\003\003 025\005\n\032 022,,,\t 037;\006\033\t 022\b\0063$\t 023%\007\003\n\034\016\r\007\t 023\n\013\006#\004\005\002\t 002$\016\004\(\016$\016\006%\t b"\016\b\002\002\005\016\b 001 3<\020\020D\027*,,%4\013\001<\027\027\027\001\002\b\030\035\034\001\020\b\032\034\001\022\004\026\006\006\013\001*,,%\013\001\035\035\034\001**%.**8\034\001  001 002\034\001 t\n\b\004\007\n\005\006\001 017\021!\001 022\034J\034\001 f\017\024\025\026\023\023\013\001 A\027\\035\026\004\007\001 017\005\021\007\017\005\021\026\004\0060\001 020\007\004\017\007\026 \005\026\006\001 017\021!\001 E\026\026!\006\001 037\003\026\021\001 2\021!\026\004\006\007\017\021!\005\021 \001 020\b\036\007\037\017\004\026\031\001 001 P\r\017\023\005\007\017\007\005#\026\001\027\030\035\005\004\005\032\017\023\001\020\007\r!\024B\013\001 025\005\n\032\\022,,,\t\031\006\033\t*\034\016\0044\025\004\032\016\013\016\032\t 023\n\013\006#\004\005\002\t,\b"\016\b\002\002\005\016\b"\t\f\n\b\013 0013?\022\020\027\002\001*,,%4\013\001<\027\027\027\001\002\b\030\035\034\001 020\b\032\034\001\022\004\026\006\006\013\001*,,%\013\001\035\035\034\001*7%.*7&\034\001  001 5\034\001\t\b\005#\b\021\026\021\013\001A\020\017\030\035\023\005\021 \001\f\017\004 \026\001;\017\007\017"\017\006\026\006\001\036\b\004\001?\006\006\b\032\005\017\007\005\b\021\001 D\r\023\026\006B\013\001 025\005\n\032  b t 022\b\0063$\t f\n\b\013 002\005%\t 004\005"\002\t 001\004\006\004\(\004\034\002\034\t 3I\f;@\001/64\013\001%//6\013\001\035\035\034\001%81.%1+\034\001 8 001 I\034\001\t\025\026\004\035\b\006\001\017\021!\001D\034\0015\b\023\007\013\001A\020\b\036\007\037\017\004\026\001@\b\007\004\024\b\023\b \024\031\001?\r\007\b\030\017\007\005\032\001 002\023\r\006\007\026\004\005\021 \001\b\036\001\020\b\036\007\037\017\004\026\001\020\024\006\007\026\030\006B\013\001 025\005\n\032\D 006\033 t\022\b\0063$\t@\n\005-\034\033\n\003\t 001\004\006\004\(\004\034\002\t,\030\003\002\005\006\t\023%\034\006\002\007\034\t*\003\003$\016\032\004\006\016\n\b\034 0013;\027Q?\001/74\013\001<\027\027\027\001 002\b\030\035\034\001\020\b\032\034\001\022\004\026\006\006\013\001%//7\013\001\035\035\034\0017%%.7%7\034\001 1 001 t\034\001 034\001 C\005  \026\004\007\006\013\001 A2\006\005\021 \001 002\023\r\006\007\026\004\005\021 \001 023 \b\004\005\007\003\030\006\001 005\021\001 f\026 \017\032\024\001 020\024\006\007\026\030\006\001 D\026\030\b!\r\023\017\004\005\025\017\007\005\b\021B\013\001 025\005\n\032 E\006\033\t n\005-\016\b"\t f\n\b\013 002'\002\005\034\002\t b"\016\b\002\002\005\016\b"\t 3C\002D\027\001 4\013\001 027\027\027\001 002\b\030\035\034\001 020\b\032\034\001 022\004\026\006\006\013\001%//&\013\001\035\035\034\00188.18\034\001  001 034J\034\001R\017\016\005\013\001\020\034\001\022\017\004\007\003\017\006\017\004\017\007\003\024\013\001=\034\001F \005\003\017\004\017\001\017\021!\001C\034\001\f\005\013\001AE\026\037\001 023 \b\004\005\007\003\030\006\001 001 017\006\007\001 005\006\032\b#\026\004\024\001 b\036\001 006\006\b\032\005\017\007\005\b\021\001 D\r\023\026\006B\013\001 025\005\n\032 n\013\t 006\033\002\t 9 005 t 022\b\0063$\t f\n\b\013 b\n#$\002&"\002\t 001\016\034\032\n'\002\005%\t 001\004\006\004\(\004\034\002\034\t\004\b&\t\001\004\006\004\t\021\016\b\016\b 013\001%//&\013\001\035\035\034\001*78.*76\034\001 001 Proceedings of the 11 th IEEE International Workshop on Program Comprehension \(IWPC\22203 1092-8138/03 $17.00 \251 2003 IEEE 


FIGURE 5 Execution time and rules returned versus minimum coverage for the various algorithms FIGURE 6 Execution time of dense_0002 as minconf is varied for both data-sets. Minimum coverage is fixed at 5% on pums and 1% on connect-4 FIGURE 7 Maximum confidence rule mined from each data-set for a given level of minimum coverage   1 10 100 1000 10000 100000 0 10 20 30 40 50 60 70 80 90 Execution time \(sec Minimum Coverage connect-4 apriori_c  dense_0002   dense_002   dense_02    1 10 100 1000 10000 100000 1e+06 0 10 20 30 40 50 60 70 80 90 Number of Rules Minimum Coverage connect-4 apriori_c  dense_0002   dense_002   dense_02    1 10 100 1000 10000 100000 0 10 20 30 40 50 60 70 80 90 Execution Time \(sec Minimum Coverage pums apriori_c  dense_0002   dense_002   dense_02    1 10 100 1000 10000 100000 1e+06 1e+07 0 10 20 30 40 50 60 70 80 90 Number of Rules Minimum Coverage pums apriori_c  dense_0002   dense_002   dense_02    0 500 1000 1500 2000 2500 3000 3500 20 25 30 35 40 45 50 55 60 65 Execution time \(sec minconf pums  connect-4  1 10 100 1000 10000 100000 1e+06 20 25 30 35 40 45 50 55 60 65 Number of Rules minconf pums  connect-4    0 10 20 30 40 50 60 70 80 90 100 0 10 20 30 40 50 60 70 80 90 100 Highest Rule Confidence Minimum Coverage pums  connect-4 


8.2  Effects of minimum confidence The next experiment \(Figure 6\ws the effect of varying minconf while fixing minimp and minsup to very low values. With connect-4, we used a minimum coverage of 1%, and with pums, a minimum coverage of 5%. Minimp was set to .0002 with both data-sets. As can be extrapolated from the previous figures, the number of rules meeting these weak minimp and minsup constraints would be enormous As a result, with these constraints alone, Dense-Miner exceeds the available memory of our machine The efficiency of Dense-Miner when minimum confidence is specified shows that it is effectively exploiting the confidence constraint to prune the set of rules explored. We were unable to use lower settings of minconf than those plotted because of the large number of rules. As minconf is increased beyond the point at which fewer than 100,000 rules are returned, the run-time of Dense-Miner rapidly falls to around 500 seconds on both data-sets 8.3  Summary of experimental findings These experiments demonstrate that Dense-Miner, in contrast to approaches based on finding frequent itemsets achieves good performance on highly dense data even when the input constraints are set conservatively. Minsup can be set low \(which is necessary to find high confidence rules as can minimp and minconf \(if it is set at all\This characteristic of our algorithm is important for the end-user who may not know how to set these parameters properly. Low default values can be automatically specified by the system so that all potentially useful rules are produced. Refinements of the default settings can then be made by the user to tailor this result. In general, the execution time required by Dense-Miner correlates strongly with the number of rules that satisfy all of the specified constraints 9.     Conclusions We have shown how Dense-Miner exploits rule constraints to efficiently mine consequent-constrained rules from large and dense data-sets, even at low supports. Unlike previous approaches, Dense-Miner exploits constraints such as minimum confidence \(or alternatively, minimum lift or conviction\ and a new constraint called minimum improvement during the mining phase. The minimum improvement constraint prunes any rule that does not offer a significant predictive advantage over its proper sub-rules. This increases efficiency of the algorithm, but more importantly it presents the user with a concise set of predictive rules that are easy to comprehend because every condition of each rule strongly contributes to its predictive ability The primary contribution of Dense-Miner with respect to its implementation is its search-space pruning strategy which consists of the three critical components: \(1\functions that allow the algorithm to flexibly compute bounds on confidence, improvement, and support of any rule derivable from a given node in the search tree; \(2\proaches for reusing support information gathered during previous database passes within these functions to allow pruning of nodes before they are processed; and \(3\ item-ordering heuristic that ensures there are plenty of pruning opportunities. In principle, these ideas can be retargeted to exploit other constraints in place of or in addition to those already described We lastly described a rule post-processor that DenseMiner uses to fully enforce the minimum improvement constraint. This post-processor is useful on its own for determining the improvement value of every rule in an arbitrary set of rules, as well as associating with each rule its proper sub-rule with the highest confidence. Improvement can then be used to rank the rules, and the sub-rules used to potentially simplify, generalize, and improve the predictive ability of the original rule set References 1 w a l  R.; Im ie lin ski  T   a n d S w a m i, A. 1 9 9 3   M i n i ng As so ciations between Sets of Items in Massive Databases. In Proc of the 1993 ACM-SIGMOD Int\222l Conf. on Management of Data 207-216 2 raw a l R.; M a n n ila, H Sri k an t  R T o i v o n en  H.; an d  Verkamo, A. I. 1996. Fast Discovery of Association Rules. In Advances in Knowledge Discovery and Data Mining AAAI Press, 307-328 3 K Ma ng a n a r is S a n d Sri k a n t, R 19 97  P a rtia l Cl a ssif i cation using Association Rules. In Proc. of the 3rd Int'l Conference on Knowledge Discovery in Databases and Data Mining 115-118 4 a rd o  R. J 1 9 9 8  Ef f i c i en tly Min i n g  Lo n g  P a ttern s fro m  Databases. In Proc. of the 1998 ACM-SIGMOD Int\222l Conf. on Management of Data 85-93 5  Mi c h ae l J. A a n d  Lin o f f G  S 1 9 9 7  Data Mining Techniques for Marketing, Sales and Customer Support John Wiley & Sons, Inc 6 Bri n, S  M o t w a n i, R.; Ullm a n J.; a n d  Tsu r S. 19 9 7 Dyn a m i c  Itemset Counting and Implication Rules for Market Basket Data. In Proc. of the 1997 ACM-SIGMOD Int\222l Conf. on the Management of Data 255-264 7 h e n  W   W   1 9 9 5 F a st Ef fecti v e Ru le In d u ctio n   In  Proc. of the 12th Int\222l Conf. on Machine Learning 115-123 8 In tern atio n a l Bu sin e s s Mac h in e s   1 9 9 6  IBM Intelligent Miner User\222s Guide Version 1, Release 1 9 m e t tin e n M   Ma nn ila  P  Ro nk a i ne n  P   a n d V e rk a m o  A  I. 1994. Finding Interesting Rules from Large Sets of Discovered Association Rules. In Proc. of the Third Int\222l Conf. on Information and Knowledge Management 401-407 10  Ng   R  T    L a k s hm ana n   V   S    Ha n  J   an d P a ng A  1 9 9 8   Exploratory Mining and Pruning Optimizations of Constrained Association Rules. In Proc of the 1998 ACM-SIGMOD Int\222l Conf. on the Management of Data 13-24 11 Ry mo n  R 1 9 9 2   Search  t h ro u g h Sy s t e m atic S e t En u m era tion. In Proc. of Third Int\222l Conf. on Principles of Knowledge Representation and Reasoning 539-550 1  Sha f e r  J  A g r a w a l R   an d Me ht a M 19 98  SPR I N T   A  Scalable Parallel Classifier for Data-Mining. In Proc. of the 22nd Conf. on Very Large Data-Bases 544-555 13  S m y t he P  and  Go od man   R  M 19 92 An I n f o r m at i o n Th eo retic Approach to Rule Induction from Databases IEEE Transactions on Knowledge and Data Engineering 4\(4\:301316 14  S r i k a n t   R    V u  Q an d Ag r a w a l  R  19 97 M i ni ng  A ssoc i a tion Rules with Item Constraints. In Proc. of the Third Int'l Conf. on Knowledge Discovery in Databases and Data Mining 67-73 15 W e bb, G. I 1 9 9 5 OP U S An Ef f i c i e n t Adm i ssible Algo rit h m for Unordered Search. In Journal of Artificial Intelligence Research 3:431-465 


It can also be added to cell CrossSales.3\(PC, printer one_year,\205 5  Distributed and Incremental Rule Mining There exist two ways to deal with association rules 267  Static that is, to extract a group of rules from a snapshot, or a history, of data and use "as is 267  Dynamic that is, to evolve rules from time to time using newly available data We mine association rules from an e-commerce data warehouse holding transaction data. The data flows in continuously and is processed daily Mining association rules dynamically has the following benefits 267  223Real-time\224 data mining, that is, the rules are drawn from the latest transactions for reflecting the current commercial trends 267  Multilevel knowledge abstraction, which requires summarizing multiple partial results. For example association rules on the month or year basis cannot be concluded from daily mining results. In fact multilevel mining is incremental in nature 267  For scalability, incremental and distributed mining has become a practical choice Figure 3: Distributed rule mining Incremental association rule mining requires combining partial results. It is easy to see that the confidence and support of multiple rules may not be combined directly. This is why we treat them as \223views\224 and only maintain the association cube, the population cube and the base cube that can be updated from each new copy of volume cube. Below, we discuss several cases to show how a GDOS can mine association rules by incorporating the partial results computed at LDOSs 267  The first case is to sum up volume-cubes generated at multiple LDOSs. Let C v,i be the volume-cube generated at LDOS i The volume-cube generated at the GDOS by combining the volume-cubes fed from these LDOSs is 345   n i i v v C C 1  The association rules are then generated at the GDOS from the centralized C v  214  The second case is to mine local rules with distinct bases at participating LDOSs, resulting in a local association cube C a,I a local population cube C p,I  and a local base cube C b,i at each LDOS. At the GDOS, multiple association cubes, population cubes and base cubes sent from the LDOSs are simply combined, resulting in a summarized association cube and a summarized population cube, as 345   n i i a a C C 1   345   n i i p p C C 1  and 345   n i i b b C C 1  The corresponding confidence cube and support cube can then be derived as described earlier. Cross-sale association rules generated from distinct customers belong to this case In general, it is inappropriate to directly combine association cubes that cover areas a 1 205, a k to cover a larger area a In the given example, this is because association cubes record counts of customers that satisfy   customer product merchant time area Doe TV Dept Store 98Q1 California Doe VCR Dept Store 98Q1 California customer product merchant time area Doe VCR Sears 5-Feb-98 San Francisco Joe PC OfficeMax 7-Feb-98 San Francisco customer product merchant time area Doe TV Fry's 3-Jan-98 San Jose Smith Radio Kmart 14-Jan-98 San Jose Association   population      base          confidence      support cube               cube                cube         cube                cube LDOS LDOS GDOS 


the association condition, and the sets of customers contained in a 1 205, a k are not mutually disjoint. This can be seen in the following examples 214  A customer who bought A and B in both San Jose and San Francisco which are covered by different LDOSs , contributes a count to the rule covering each city, but has only one count, not two, for the rule A  336  B covering California 214  A customer \(e.g. Doe in Figure 3\who bought a TV in San Jose, but a VCR in San Francisco, is not countable for the cross-sale association rule TV  336 VCR covering any of these cities, but countable for the rule covering California. This is illustrated in Figure 3 6  Conclusions In order to scale-up association rule mining in ecommerce, we have developed a distributed and cooperative data-warehouse/OLAP infrastructure. This infrastructure allows us to generate association rules with enhanced expressive power, by combining information of discrete commercial activities from different geographic areas, different merchants and over different time periods. In this paper we have introduced scoped association rules  association rules with conjoint items and functional association rules as useful extensions to association rules The proposed infrastructure has been designed and prototyped at HP Labs to support business intelligence applications in e-commerce. Our preliminary results validate the scalability and maintainability of this infrastructure, and the power of the enhanced multilevel and multidimensional association rules. In this paper we did not discuss privacy control in customer profiling However, we did address this issue in our design by incorporating support for the P3P protocol [1 i n  ou r data warehouse. We plan to integrate this framework with a commercial e-commerce system References 1  Sameet Agarwal, Rakesh Agrawal, Prasad Deshpande Ashish Gupta, Jeffrey F. Naughton, Raghu Ramakrishnan, Sunita Sarawagi, "On the Computation of Multidimensional Aggregates", 506-521, Proc. VLDB'96 1996 2  Surajit Chaudhuri and Umesh Dayal, \223An Overview of Data Warehousing and OLAP Technology\224, SIGMOD Record Vol \(26\ No \(1\ 1996 3  Qiming Chen, Umesh Dayal, Meichun Hsu 223 OLAPbased Scalable Profiling of Customer Behavior\224, Proc. Of 1 st International Conference on Data Warehousing and Knowledge Discovery \(DAWAK99\, 1999, Italy 4  Hector Garcia-Molina, Wilburt Labio, Jun Yang Expiring Data in a Warehouse", Proc. VLDB'98, 1998 5  J. Han, S. Chee, and J. Y. Chiang, "Issues for On-Line Analytical Mining of Data Warehouses", SIGMOD'98 Workshop on Research Issues on Data Mining and Knowledge Discovery \(DMKD'98\ , USA, 1998 6  J. Han, "OLAP Mining: An Integration of OLAP with Data Mining", Proc. IFIP Conference on Data Semantics DS-7\, Switzerland, 1997 7  Raymond T. Ng, Laks V.S. Lakshmanan, Jiawei Han Alex Pang, "Exploratory Mining and Pruning Optimizations of Constrained Associations Rules", Proc ACM-SIGMOD'98, 1998 8  Torben Bach Pedersen, Christian S. Jensen Multidimensional Data Modeling for Complex Data Proc. ICDE'99, 1999 9  Sunita Sarawagi, Shiby Thomas, Rakesh Agrawal Integrating Association Rule Mining with Relational Database Systems: Alternatives and Implications", Proc ACM-SIGMOD'98, 1998   Hannu Toivonen, "Sampling Large Databases for Association Rules", 134-145, Proc. VLDB'96, 1996   Dick Tsur, Jeffrey D. Ullman, Serge Abiteboul, Chris Clifton, Rajeev Motwani, Svetlozar Nestorov, Arnon Rosenthal, "Query Flocks: A Generalization of Association-Rule Mining" Proc. ACM-SIGMOD'98 1998   P3P Architecture Working Group, \223General Overview of the P3P Architecture\224, P3P-arch-971022 http://www.w3.org/TR/WD-P3P.arch.html 1997 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



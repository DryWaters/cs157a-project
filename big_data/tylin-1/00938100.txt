Mining Free Itemsets under Constraints Jean-Franqois Boulicaut Baptiste Jeudy Institut National des Sciences Appliqukes de Lyon Laboratoire d\222hgtnierie des Systkmes d\222hformation Biitiment 501 F-6962 1 Villeurbanne cedex France  Jean-Francois.Boulicaut,Baptiste Jeudy   1isi.insa-lyon.fr Abstract Computing frequent itemsets and their frequencies from large boolean matrices e.g to derive association rules has been one of the hot topics in data mining Levelwise 
algorithms \(e.g the APRIORI algorithm\have been proved effective for frequent itemset mining from sparse data. How eve6 in many practical applications, the computation turns to be intractable for the user-given frequency threshold and the lack of focus leads to huge collections of frequent item sets The last three years two promising issues have been investigated: the use of user dejined constraints and closed sets mining To the best of our knowledge, combining these two frameworks has 
not been studied yet In this papes we show that the benejit of these two approaches can be com bined into levelwise algorithms An experimental validation related to the discovery of association rules with negations is reported 1 Introduction One of the obvious hot topics of data mining research in the past years has been frequent set discovery from large boolean matrices \(millions of rows and hundreds of columns\It concerns the discovery of sets of columns that 
are true within a same row often enough The user defines the desired frequency threshold and when every frequent itemset has to be found with its frequency \(for instance when association rules  13 are to be derived\it gives rise to challenging algorithmic issues due to the exponential size of the search space Levelwise algorithms, e.g., the well-know APRIORI al gorithm 2 have been proved effective for frequent itemset mining when the matrix is sparse and the data is lowly cor related A prototypical application domain where it works is the popular basket analysis problem. However, in most of 
the other applications we know the extraction is not always tractable for the user-given frequency thresholds. This hap pens when the data is dense andlor highly correlated, i.e when the number of frequent itemsets explodes Further more, even if it is tractable the size of the output can be huge and is often larger than the size of the original data The lack of focus leads to huge collections of frequent item sets from which too many uninteresting patterns or rules will be derived During the last three years, two promising issues have been investigated to tackle these problems First 
one can assume that only a subset of the collection of frequent itemsets is interesting it leads to constraint based extraction of the frequent itemsets 18 13 10 71 These studies have considered various kinds of constraints including 223syntactic\224 constraints e.g an item must not appear in the itemsets and constraints related to the so called objective measures of itemset interestingness \(e.g the itemsets must be frequent\Using constraints enables to decrease the size 
of the output while improving user guid ance The problem is to 223push\224 efficiently the constraint checking step during itemset extraction, i.e not to apply a simple 223generate and test\224 strategy Nice results have been discovered concerning the so-called anti-monotone succinct and monotone constraints  13,7 i.e a wide range of constraints This framework has been also studied for other kinds of properties like rules  101 or correlations 9 Another promising approach concerns the condensed representation offrequent itemsets  113 The intuition is that 
instead of mining all the frequent patterns one can extract a particular subset of the frequent pattern collection such that it is possible to regenerate from it the whole collection Ideally, this subset is much smaller than the original col lection and can be extracted more efficiently while allow ing a fast regeneration of the whole collection of frequent patterns Several researchers have investigated the use of closed frequent sets as a valuable condensed representation 15,4,6 17 191 322 1098-8068/01$10.00 0 2001 IEEE 


To the best of our knowledge combining these two frameworks has not been studied yet In this paper we show that the benefit of these two ap proaches can be combined into levelwise algorithms. Doing so new mining tasks can be considered like frequent itemset mining for low frequency thresholds or the discovery of fre quent generalized itemsets sets that combine positive and negative items An experimental validation related to the discovery of association rules with negations is reported In Section 2 we recall the APRIORI algorithm and out line the effective processing for anti-monotone constraints In Section 3 we discuss the use of monotone constraints in order to get effective levelwise algorithms for a rather wide class of constraints In Section 4 we revisit the CLOSE al gorithm  151 that computes closed frequent sets and we dis cuss its extension towards the constraint-based discovery of itemsets. Section 5 points out a practical validation of this combined framework and Section 6 is a short conclusion ti t2 t3 t4 t5 te T 2 Understanding the effective use of con straints in APRIORI-like algorithms ABCD AC AC ABCD BC ABC 2.1 Problem settings and notations We consider transactional databases Given a finite set Items of symbols \(denoted by capital letters Items A,B,C  a transaction t is a subset of Items A transactional database T is a finite and non empty multi set T  tl,tz  tn of transactions An itemset is a subset of Items and a k-itemset is an itemset of size k A transaction t supports an itemset S iff S t The support denoted Support\(S of an itemset S is the multiset of all transactions of T that support S e.g Support  T The frequency of an itemset S is defined by F\(S  ISupport\(S 0  where 1.1 denote the cardinal ity of the multiset \(each transaction is counted with its mul tiplicity An itemset S is y-frequent in T if F\(S 2 y Figure 1 provides an example of a transactional database and the supports and the frequencies of some itemsets No tice that we often use a string notations for sets, e.g AB for A B Itemset A B AB AC CD ACD Figure 1 Supports and frequencies of some itemsets in a transactional database T A PR IOR I algorithm 1 Cf  Itemsl Lo  0 2 k  1 3 while Ci  8 do 4 5 6 7 k:=k+1 8 output Li I Phase 1  candidate safe pruning ck  safe-pruning-on\(Ci I  Phase 2  frequency constraint  it needs a data scan Phase 3  candidate generation for level k+l CiS1  generateapTiori Lk  SATC Ck I od  Definition 1 constraint If7 denotes the set of all trans actional databases and 21tems the set of all itemsets a con straint C is a predicate over 21tems x 7 We say tNat an itemset S E 21tems satisfies a constraint C in the database T E 7 iff C\(S T  true When it is clear from the con text we write C\(S Given a subset I of Items we de fine SATc\(I  S E I S satisfies C SATc denotes SATc 21tems Let CfTeq\(S 5 F\(S 2 y be the constraint that is true iff S is y-frequent in T Example 1 Consider the dataset of Figure 1 where Items A B C D rf Cfreq specijies that an itemset must be O.6-frequent then SATc  A B C AC BC Assume that Cslze\(S z SI 5 2 and Cmtss\(S z B  S then SATC~,~~~C  A C,D AC,AD CD while SATC~~~,AC,,,,AC  A Cl AC Definition 2 constrained itemset mining task Given a transactional database T and a constraint C the con strained itemset mining task is the computation of the col lection of the itemsets that verify C i.e SATc together with theirfrequencies It provides Rc   S F S  S E SATc 2.2 Sketching the APRIORI algorithm  We consider an abstract definition of the APRIORI algo-8 rithm 2 to support our discussion on the effective use of1 constraints. This algorithm performs the constrained item  set mining task when C is CfTeq In this algorithm and in the following ones the fre  quency of the itemsets are not explicit for the sake of clarity e.g Line 5 of the algorithm should be Lk   S,F\(S S E SATc Ck since APRIORI outputs the frequency of each frequent itemset 323 


APRIORI is a levelwise exploration of the lattice of item sets w.r.t set inclusion During the first pass when k  l it computes frequent 1-itemsets and then it gen erates candidate 2-itemsets from frequent 1 itemsets In the second pass \(k  2 it prunes some candidate 2-itemsets those that contain an infrequent subset it computes their frequencies and it generates candidate 3-itemsets from fre quent 2-itemsets  Ci denotes the k-itemsets that can be frequent Dur ing Phase 1 some of these k-itemsets are pruned safe pruning-on\(Ci I eliminates the candidates for which a subset of length k is not frequent. This can be justi fied by the so-called APRIORI trick if S is not frequent, ev ery superset of S is not frequent and S can be safely pruned During Phase 2 a database scan is performed to compute the frequency of the candidate itemsets. The frequent ones are stored in Ck together with their frequencies In Phase 3 frequent k-itemsets are used to compute can didate k  1-itemsets generateapTzoTL  provides the candidates by fusion of two elements from Lk that share the same k  1 first items generateapTioTz U B where A B E  A and B share the k  1 first items in lexicographic order This generation procedure is the key of the efficiency of the algorithm: it ensures that large por tions of the itemset lattice are pruned and that no frequent itemset is missed r Example 2 Let us focus on an extract from the execution of APRIORI on the data of Figure I with a frequency threshold y  0.5 At Iteration 2 k  2 Phase 2 one can verify that L2  AB, AC AD BC CD Then Phase 3 provides the collection of candidates Ci  ABC ABD ACD BCD is not generated since BD  132 and therefore BCD cannot be fre quent At Iteration 3 Phase 1 the pruning step provides C3  ABC ACD since BD  L2 and therefore ABD cannot be frequent It can be proved by induction on k that APRIORI is cor rect and complete, i.e U Li  SATctpeq 2.3 Effective use of anti-monotone constraints It is well-known that the completeness of APRIORI i.e it does not prune any frequent itemset\relies on the anti monotonicity of CfTeq Definition 3 Anti-monotonicity An anti-monotone con straint is a constraint C such that for all itemsets s s 5 E S A S satisfies C  S satisfies C Notice that a disjunction or a conjunction of monotone constraints is an anti-monotone constraint anti 324 Example3 CfTeq C\(S z A  S S 5 A,B,C and S fl A,B,C  0 are examples of anti-monotone con straints Many other anti-monotone constraints are pre sented in 13 Let Cam be an anti-monotone constraint eventually in cluding CfTeq i.e Cam could contain Cfreq or not if S does not satisfy Cam every superset of S does not sat isfy Cam Therefore if Step 5 of the APRIORI algo rithm is replaced by Lk  SATc,,\(Ci it is still cor rect and complete It means that APRIORI can be used to mine constrained itemsets when the given constraint is anti monotone 3 Testing Monotone Constraints If the effective use of anti-monotone constraints is easy to understand, it is far more complex in the general case In other terms given an arbitrary constraint C it is not possi ble to use it in APRIORI by simply replacing Step 5 with Lk  sATc\(Ck Doing this leads to the loss of the com pleteness of APRIORI Indeed, there is two problems the generation step and the pruning step The generation step must be complete, i.e., it must not miss any itemset satisfy ing C and also the pruning step \(Phase 1 must be correct i.e it must not prune an itemset that verify the constraint Example4 Assume the constraint is C\(S 3 C E S The itemset ABC should be generated by generateapTzoTz from AB and AC but since C\(AB  false ABC is not generated whereas C\(ABC  true If the constraint is C\(S E A E S The itemset ABC is then correctly generated by generateapTzoTz from AB and AC but since C\(BC  false ABC is incorrectly pruned whereas C\(ABC  true To overcome these problems we propose a generation procedure and a pruning procedure which allow to push conjunctions of anti-monotone and monotone constraints i.e when C can be written as Cam A C A monotone con straint C is the negation of an anti-monotone constraint and it motivates the notation for C The main prop erty of a monotone constraint is S 2 Items C,\(S is true 3 VS 3 S C,\(S is true Example 5 Continuing our running example  A,B,c,D c S and S n A,B,c  0 are monotone constraints Assuming that items in S are correlated is monotone too 9 Generation procedure The next theorem gives a new complete generation procedure when the constraint is the conjunction of a monotone and an anti-monotone con straint We use the concept of-negative border 12 If Cam 


denotes an anti-monotone constraint adzam is the collec tion of the minimal-\(w.r.t. the set inclusion\itemsets that do not satisfy Cam Let us now consider two generating procedures generate  A U-B where A E Ck and is-a 1-itemset and generate  A U B where A B Lk Notice that a naive algorithm that computes generatez will produce many duplicates \(see SI Our new generation procedure is denoted generate and is defined by the next theorem Theorem 1 Assume C  Cam A lCbm and ms  MaxsEad SI Ifgenerate is dejined by  generate  13dFAm n Items1 and for k 2 1 ifk  ms generate  generatel ifk  ms generate  generate ifk  ms generate  generate then this candidate generation procedure is complete and ensures that every candidate itemset veri,fies CL The fact that every candidate itemset verify C  iCh makes useless any verification of this constraint after the candidate generation step  Cam Bd am f Itemsk+l Safe pruning procedure Let us now introduce a correct and complete pruning algorithm Pruning algorithm prune for all S E C and for all S\222 C S such that IS\222  k do if S\222 Ck and C,\(S\221  true then delete S from Ci+l od Theorem 2 The pruning algorithm prune is correct and complete This algorithm is correct because it does not prune any itemset that verify C  Cam A C Its completeness means that if an itemset is not pruned then every proper subset ofJhat itemset verify Cam Intuitively it is not possible to prune more itemsets without affecting the completeness Generic algorithm We can now give a generic algorithm for a constraint C  Cam,A C  Cam A 4!hm using the structure of APRIORI and our procedures generate and pruning generic algorithm 1 Cf Bd n Items1  Lo  0 2 k  1 3 while C  0 do 4 am Phase 1  candidate safe pruning ck  pruning,\(Ci Lk-1 5 6 7 k:=k+1 8 output Li Phase 2 anti-monotone constraint checking 13k  SATcam Ck Phase 3  candidate generation for level k+l Ci+l  generate od Note that it is not necessary to check C during Phase 2 since Theorem 1 ensures that every generated itemset verifies it Related work Our generic algorithm is inspired by sev eral algorithms 18 8 131 and can be considered as a gen eralization of them Conjunctions of monotone and anti monotone constraints encompass every kind of constraints that have been 223pushed\224 inside a levelwise algorithm \(an other kind of interesting constraint the convertible con straints  161 can be pushed in depth-first exploration algo rithms The framework of succinct constraints introduced in  allows to find an effective generation procedure i.e an effective computation of the negative border adzLm of Theorem 1 4 Revisiting the CLOSE Algorithm It is now interesting to revisit the algorithms CLOSE  Charm 19 and MIN-EX  These algorithms com pute frequent closed itemsets i.e condensed representa tions of frequent itemsets They allow tractable frequent itemset extractions from dense and highly-correlated data i.e tractable extractions for thresholds on which APRIORI is clearly intractable 4.1 How CLOSE algorithm has been defined so far The APRIORI algorithm explores the itemset lattice to find all the frequent itemsets However the number of fre quent itemsets can be exponential in the size of Items If the size of Items is n the size of the itemset lattice is 2 and many of these itemsets can be frequent for the given frequency threshold This is the case in highly-correlated data like for instance census data The CLOSE algorithm \(and related algorithms\operates on a different lattice: the closed itemset lattice Definition 4 closed itemset lattice The closure of an itemset S denoted by closure\(S is the maximal for set inclusion\superset of S which has the same support as S A closed itemset is an itemset that is equal to its closure The set of closed itemset is a lattice called the closed itemset lattice 325 


In CLOSE the exploration of this lattice is done in a lev AB closure\(B Therefore ChTe,\(AB is true If gC AC BC DAC ABC where the notation ABC means that CL AB is true and that closure\(AB  ABC elwise manner like APRIORI gorithms comes from the fact that this lattice is generally several order of magnitude smaller than the itemset lattice These algorithms output the set of frequent closed item sets. Frequent closed itemsets are interesting for several rea sons The efficiency of these al the frequency threshold is y  1/2 SATC~,~~~C _ _ Notice that when the closure of an itemset X is a proper superset of X say Y it means that an association rule X  0 0 0 4.2 they are far less numerous than frequent itemsets \(and therefore faster to compute, easier to store and manip ulate if necessary it is possible to generate efficiently all fre quent itemsets \(and their frequencies\from the closed ones it is possible to derive non redundant association rules directly from closed frequent itemsets without generating all frequent non-closed ones see e.g r19,141 A new constraint We show how to consider the CLOSE algorithm as an exploration of the classical itemset lattice with a new con straint e Then in Section 4.3 we will be able to use this constraint in our generic algorithm together with other constraints and therefore achieve constrained free-set min ing We first define a constraint C  Definition 5 A constraint for CLOSE CbTee\(S E S\222 C S  S g closure\(S\222 The itemsets which verify this constraint are exactly the O-free sets introduced in 161 and it motivates the chosen name of the constraint Definition 6 Free itemsets Free itemsets are itemsets that are not included in any closure of their proper sub-set Equivalently free itemsets are itemsets that vertfy ehTee A fundamental property of free itemesets is that no logi cal rule \(i.e., association rule with a confidence of 1 holds between their attributes In other words if X is a free item set then there does not exist two distinct subset Y and 2 of X with 2  0 such that the rule Y  2 has a confidence of 1 Also, the frequency of itemsets that are not free can be inferred from the frequency of free itemsets 6 Example 6 Let us compute closure\(AB on our running example Items A and B are simultaneously in transac tions I 4 and 6 We notice that item C is the only other item that is also present in these three transactions thus closure\(AB  ABC We also have closure\(A  AC and closure\(B  BC so AB closure\(A and Yholds with confidence 1 In other terms it means that the more you have such correlations in your data, the less you have free itemsets and thus the less you have to count for frequencies when looking for frequent itemsets Proposition 1 The eh constraint is anti-monotone This constraint is another example of an anti-monotone constraint which needs a database pass to be checked a database pass is needed to compute the closure of an item set Checking this constraint seems expensive if the clo sure of every subset of S has to be computed We can use an equivalent constraint CF 3 s\222 C s A Is\221  JSJ  1  S closure\(S\222 The equivalence means that ehTee S is true iff CFree\(S is true So we only need the closure of every subset of S of size Is  1 We are now able to test the constraint on s E I for each S\222 c S such that IS\222I  IS  1 we must know closure\(S\222 In the CLOSE algorithm, the closure of each candidate itemset of size k and its frequency are computed during the database pass at level k If the closure of S\222 is not computed it means that S\221 does not verify CfTeq A CF i.e an anti-monotone constraint and therefore S cannot verify CfTep A CF Finally, either the closure of S\222 is known and we can check if S closure\(S\222 or it is not known and it means that Cfreq\(S A CF~~~\(S is false. This strategy which uses the anti-monotonicity of eh enables to test the constraint with only a little extra cost during the database pass  4.3 Incorporating constraints Now it seems straightforward to search for itemsets which verify a constraint C  CF A C A C using the generic algorithm since CF is anti-monotone How ever, there are two problems. First \(due to C the closures of some candidates of level IC are not computed thus making the Cpree checking impossible at level k  1 it is not possible to check if an itemset of size k  1 is included in the closure of one of its proper subset Second we loose an important property of CLOSE SATc,,eeAc will no longer enables to compute SATc,,Ac Assume we replace eh with ChreeAC S S\222 C S A C,\(S\221  S g closure\(S\222 and CF with S closure\(S\221 Then we have the following theorem CF~~~AC S f S\222 C S A JS\222J  IS  1 A C,\(S\222  326 


Theorem 3 The constraints CFreeAC and Ckree,,c are equivalent and anti-monotone. The set SATC,,AC can be eflciently computed using the same method as in CLOSE using SATcFVeeAcm C,,,,~C i.e the output of the generic algorithm with the Constraint c  CFTeeAC A cam A Cm This theorem means that we can find free-itemsets that verify conjunctions of anti-monotone and monotone con straints 4.4 MIN-EX algorithm The MIN-EX algorithm is an extension of the CLOSE al gorithm 4 The concept of closure is extended, providing new possibilities for pruning However we must trade this efficiency improvement against precision the frequency of the frequent itemsets are only known within and bounded error If 6 is an integer let closures\(S be the maxi mal for the set inclusion\superset Y of S such that for every item A E Y  S ISupport\(S U A is at least Support\(S  6 with 6  0 it is the same closure op erator than CLOSE i.e closure0  closure Larger values of S leads to more efficiency improvement and larger errors on the frequencies of itemsets By replacing this new closure operator in the definition of CF we define Cs-Free and C&-FTeeAC and Theorem 3 is true with these new constraints The sets that fulfill C~-F are the so called free sets from 6 Here again one can say that the more you have almost logical association rules that hold in your data rules with confidence close to 1 since only 6 ex ceptions are allowed\the less you have free sets It has been shown that when the frequency of a frequent itemset is approximated by using the frequency of a free set, the error on frequency can remain very low in practice 6  5 An experimental validation We consider an experiment motivated by the search for association rules with negations 5 Only some results con cerning the discovery of generalized sets from with associ ation rules with negations are derived\are given here Notations Let Items  A B  be a finite set of sym bols called the positive items and a set Items of same car dinality as Items whose elements are denotedx B  and called the negative items Given a transactional database 7 over Items let us define a complemented transactional database over Items  Items U Items as follows for a given transaction t E 7 we add to t negative items cor responding to positive items not present in t Generalized itemsets are subsets of Items and can contain positive and negative items Constraints We want to extract frequent itemsets Cf that do not involve only negative items Calpp Calpp\(S is true when S involves at least p positive items This is obviously a monotone constraint First experiments have shown that it was interesting to relax such a monotone con straint i.e accepting more sets in order to give rise to more pruning see 5 for a complete discussion Follow ing that guideline instead of Calpp we used the constraint This constraint enforces gt least p positive attributes a monotone constraint er gt most legative attribute an anti-monotone constraint Let us introduce the collection of constraints that have Calppoamln  Calpp V Camln cdl Cfrep A C&FreeAC A Callpoamln Cd2 Cfreq A C6-FreeACm A Cal2poamln cd3  cf rep A C6-FreeACm A Cal3poamln With these constraints we are able to compare different approaches  e using only the frequency constraint e using the frequency constraint and Calppoamln con e using CfTeg and Calppoamln in conjunction with straint with p  1 2 3 Cfl Cfa and Cf3 CFreeAC or Cd-FreeAC  Datasets We studied the use of these constraints on two dataset The first one is a benchmark the so-called mush room data This dataset is a binary matrix of 8124 rows Each row contains 23 discrete attributes Theses attributes are binarized into exclusive attribute-value pairs This leads to a binary matrix with 119 columns and 23 2231\224 per row When encoding negative items it leads to a matrix with 238 columns whose each row contains 119 2231\224 The second dataset is from the French national institute of statistics INSEE In this dataset each row represents a French town and each column represents a kind of ser vice e.g., bank, insurance company etc a 2231\224 in 223bank\224 column means that there is at least one bank in the town In this dataset, there are about 37000 rows and 59 columns with an average number of 2231\224 per row of 4 When encod ing negative items, it leads to a matrix with 118 columns whose each row contains 59 2231\224 The former dataset is quite small but it is known to be tough due to the high correlation between the attributes and 327 


its density for positive attributes The latter dataset is larger but it is sparse 4 2231\224 per row on average for positive attributes and less correlated. These two different datasets let us compare our approach on different types of datasets Indeed the results show a great difference between these two experiments Experiments The experiments were conducted on a 500 MHz Pentium I11 with 768 MB of memory The value of the frequency threshold y is changed over experiments in order to observe the trend. Logarithmically scaled axes are used The value of the 6 parameter in the Cd-FTee con straint is set to 200 for the mushroom database and to 100 for the INSEE database in this latter database there was only a slight difference in execution time between 6  100 and 6  200 but 6  100 gives more accurate results as explained in Section 4.4 100000 10000 1000 100 Time sec vs Frequency threshold 10 0.2 03 0.4 0 5 0.6 0 7 0.8 0.9 1 Cdl  Cd3  Cf2 t Cd2   Cfl 8 Cf3 Figure 2 Mining generalized sets from mush room dataset Figure 2 shows the results of the experiments on the mushroom dataset with the constraints cfl Cf2 Cf3 Cdl cd2 and Cd3 The extractions using the other constraints Cfreq C1 C2 and C3 were intractable even at high fre quency threshold 95 and with the strongest requirement on the number of positive items C3 On this dataset the use of C~--F~~~~C as opposed to C~--F~~~AC clearly im proves the results With Cf3 a frequency threshold of 65 is reached whereas using Cd3 allows to reach a frequency of 20 within about the same time. Finally on the mushroom dataset CfTes combined with the most favorable case of Calpp still leads to an intractable extraction CfTeq combined with Only C~-F or CFTee does not allow mining at low threshold even with Callp i.e cdl and Cjl we only reach 60 Therefore to mine at reasonable frequency thresholds the conjunction of both techniques \(using constraints on item sets with the Calppoamln family of constraints and 101 ing for 6-free-sets with CFTeeAC or Cd-FreeAC appears mandatory Time sec vs Frequency threshold 10000  mx J I 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 Cd2  Cf2 c2 t Cd3   Cf3 e c3 e Figure 3 Mining generalized sets from INSEE dataset Figure 3 shows the results of the experiments on the IN SEE dataset With the constraints CfTeq C1 Cfl and cdl it is not possible to reach a frequency threshold less than 34 For this frequency threshold, there is only one frequent pos itive attribute. This means that all the itemsets mined at this threshold are composed of the same positive attribute and several negative ones On this dataset we notice that the Cf family of con straint is surprisingly less efficient than the less constrain ing C family We analyzed the output of the algorithm and found that almost no logical rule association rule with a confidence of 1 holds in this dataset The optimization of Cf over C is based on the presence of these rules Even if the use of 6-free-sets \(with Cd2 or Cd3 does not allow to mine at significantly lower thresholds however it speeds up the extraction by an order of magnitude with re spect to C2 or C3 at lower frequency thresholds Finally with this dataset too the approach turns to be valuable 6 Conclusion We study itemset mining under constraints within level wise algorithms Several interesting results have been al ready published the last three years, e.g., about the effective use of anti-monotone constraints or the interest of mono tone constraints The generic algorithm we give in this pa per is a simple generalization of several related algorithms 328 


and enable to emphasize the potential of optimization when considering conjunctions of anti-monotone and monotone constraints Furthermore we provide new results concern ing the computation of free sets under constraints We dis cussed under which conditions it was possible to extend an algorithm like CLOSE for an effective use of constraints An experimental validation has confirmed the added-value of this approach A recent work uses a different approach and proposes to mine frequent itemsets without candidate generation 17 Integrating this new algorithm within our study seems promising Furthermore, frequent sets discovery, and more generally data mining is not limited to independent min ing tasks or queries Knowledge discovery in databases is an iterative process and there are still lots of work to do to optimize sequences of queries There is a major trade-off between fully optimizing each individual query and finding a strategy that makes use of previous mined patterns 8 31 This strategy may be less effective for the first queries but may win for long sequences of related queries i.e the way people actually proceed Acknowledgement The authors thank Artur Bykowski for his contribution to the experimental validation References l R Agrawal T Imielinski and A. Swami Mining associa tion rules between sets of items in large databases In Pro ceedings of ACM SIGMOD Conference on Management of Data SIGMOD\22293 pages 207  216 Washington D.C USA May 1993. ACM  2 R Agrawal H Mannila R Srikant H Toivonen, and A I Verkamo Fast discovery of association rules In Advances in Knowledge Discovery and Data Mining pages 307  328 AAAI Press, Menlo Park CA 1996  E Baralis and G Psaila Incremental refinement of min ing queries In Proceedings of the First International Con ference on Data Warehousing and Knowledge Discovery DaWaK\22299 volume 1676 of Lecture Notes in Computer Science pages 173  182 Florence I Sept 1999. Springer Verlag 4 J.-F Boulicaut and A Bykowski. Frequent closures as a con cise representation for binary data mining In Proceedings of the Fourth PacifAsia Conference on Knowledge Discov ery and Data Mining PAKDD\222OO volume 1805 of Lecture Notes in ArtiJcial Intelligence pages 62  73 Kyoto JP Apr 2000. Springer-Verlag 5 J.-F Boulicaut A Bykowski and B. Jeudy Mining asso ciation rules with negations Technical report, INSA Lyon LISI, F-69621 Villeurbanne Nov 2000 6 J.-F Boulicaut A Bykowski and C Rigotti Approxima tion of frequency queries by mean of free-sets In Proceed ings of the Fourth European Conference on Principles and Practice of Knowledge Discovery in Databases PKDD 22200 volume 1910 of Lecture Notes in ArtiJicial Intelligence pages 75  85 Lyon F Sept 2000. Springer-Verlag  J.-F Boulicaut and B. Jeudy Using constraint for itemset mining should we prune or not In Proceedings Bases de Donne\221es Avange\221es\224 BDA\222OO pages 221  237 Blois F Oct 2000 8 B Goethals and J van den Bussche On implementing interactive association rule mining In Proceedings of the ACM SIGMOD Workshop on Research Issues in Data Min ing and Knowledge Discovery DMKD\22299J Philadelphia USA, May 30 1999 9 G. Grahne L V S Lakshmanan and X Wang Efficient mining of constrained correlated sets In Proc ICDE 2000 pages 512  521 San Diego, USA, 2000 lo L V Lakshmanan R Ng J Han and A Pang Opti mization of constrained frequent set queries with 2-variable constraints In Proceedings of ACM SIGMOD Conference on Management of Data SIGMOD\22299 pages 157  168 Philadelphia, USA, 1999 ACM Press l 13 H. Mannila and H Toivonen. Multiple uses of frequent sets and condensed representations In Proceedings of rhe Sec ond International Conference on Knowledge Discovery and Data Mining KDD\22296 pages 189  194 Portland USA Aug 1996. AAAI Press 12 H Mannila and H Toivonen Levelwise search and bor ders of theories in knowledge discovery Data Mining and Knowledge Discovery 1\(3 258, 1997 13 R Ng L V Lakshmanan J Han, and A. Pang. Exploratory mining and pruning optimizations of constrained associa tions rules. In Proceedings of ACM SIGMOD Conference on Management of Data SIGMOD\22298 pages 13  24 Seattle Washington USA 1998 ACM Press 14 N Pasquier Y Bastide R Taouil, and L Lakhal Closed set based discovery of small covers for association rules In Proc BDA\22299 pages 361  381, Bordeaux, F, Oct 1999 15 N Pasquier Y Bastide R Taouil, and L Lakhal Efficient mining of association rules using closed itemset lattices In formation Systems 24\(1  46 Jan 1999 16 J Pei, J Han and L V S Lakshmanan Mining frequent itemsets with convertible constraints In Proc ICDE\22201 Heidelberg, Germany, 2001 17 J. Pei J Han, and R Mao CLOSET an efficient algorithm for mining frequent closed itemsets In Proceedings of the ACM SIGMOD Workshop on Research Issues in Data Min ing and Knowledge Discovery DMKD\222OO Dallas, USA May 2000  181 R Srikant Q Vu and R Agrawal. Mining association rules with item constraints In Proceedings of the Third Interna tional Conference on Knowledge Discovery and Data Min ing KDD\22297 pages 67  73 Newport Beach California USA 1997. AAAI Press  M J Zaki Generating non-redundant association rules In Proc KDD\222OO pages 34  43 Boston USA 2000 329 


In Figures 10 and 11 we see MAFIA is approximately four to five times faster than Depthproject on both the Connect-4 and Mushroom datasets for all support levels tested down to 10 support in Connect-4 and 0.1 in Mushroom For Connect-4 the increased efficiency of itemset generation and support counting in MAFIA versus Depthproject explains the improvement Connect 4 contains an order of magnitude more transactions than the other two datasets 67,557 transactions amplifying the MAFIA advantage in generation and counting For Mushroom the improvement is best explained by how often parent-equivalence pruning PEP holds especially for the lowest supports tested The dramatic effect PEP has on reducing the number of itemsets generated and counted is shown in Table 1 The entries in the table are the reduction factors due to PEP in the presence of all other pruning methods for the first eight levels of the tree The reduction factor is defined as  itemsets counted at depth k without PEP   itemsets counted at depth k with PEP In the first four levels Mushroom has the greatest reduction in number of itemsets generated and counted This leads to a much greater reduction in the overall search space than for the other datasets since the reduction is so great at highest levels of the tree In Figure 12 we see that MAFIA is only a factor of two better than Depthproject on the dataset Chess The extremely low number of transactions in Chess 3196 transactions and the small number of frequent 1-items at low supports only 54 at lowest tested support muted the factors that MAFIA relies on to improve over Depthproject Table 1 shows the reduction in itemsets using PEP for Chess was about an order of magnitude lower compared to the other two data sets for all depths To test the counting conjecture we ran an experiment that vertically scaled the Chess dataset and fixed the support at 50 This keeps the search space constant while varying only the generation and counting efficiency differences between MAFIA and Depthproject The result is shown in Figure 13 We notice both algorithms scale linearly with the database size but MAFIA is about five times faster than Depthproject Similar results were found for the other datasets as well Thus we see MAFIA scales very well with the number of transactions 5.3 Effects Of Compression To isolate the effect of the compression schema on performance experiments with varying rebuilding threshold values we conducted The most interesting result is on a scaled version of Connect-4, displayed in Figure 14 The Connect-4 dataset was scaled vertically three times so the total number of transactions is approximately 200,000 Three different values for rebuilding-threshold were used 0 corresponding to no compression 1 compression immediately and all subsequent operations performed on compressed bitmaps\and an optimized value determined empirically We see for higher supports above 40 compression has a negligible effect but at the lowest supports compression can be quite beneficial e.g at 10 support compression yields an improvement factor of 3.6 However the small difference between compressing immediately and finding an optimal compression point is not so easily explained The greatest savings here is only 11 at the lowest support of Conenct-4 tested We performed another experiment where the support was fixed and the Connect-4 dataset was scaled vertically The results appear in Figure 15 The x-axis shows the scale up factor while the y-axis displays the running times We can see that the optimal compression scales the best For many transactions \(over IO6 the optimal re/-threshold outperforms compressing everywhere by approximately 35 In any case both forms of compression scale much better than no compression Compression on Scaled ConnectAdata Compression Scaleup Connectldata ALL COMP 0 5 10 15 20 25 30 100 90 80 70 60 50 40 30 20 10 0 Min Support  Scaleup Factor Figure 14 Figure 15 45 1 


6 Conclusions We presented MAFIA an algorithm for finding maximal frequent itemsets Our experimental results demonstrate that MAFIA consistently outperforms Depthproject by a factor of three to five on average The breakdown of the algorithmic components showed parent-equivalence pruning and dynamic reordering were quite beneficial in reducing the search space while relative compressiodprojection of the vertical bitmaps dramatically cuts the cost of counting supports of itemsets and increases the vertical scalability of MAFIA Acknowledgements We thank Ramesh Agarwal and Charu Aggarwal for discussing Depthproject and giving us advise on its implementation We also thank Jayant R Haritsa for his insightful comments on the MAFIA algorithm and Jiawei Han for providing us the executable of the FP-Tree algorithm This research was partly supported by an IBM Faculty Development Award and by a grant from Microsoft Research References I R Agarwal C Aggarwal and V V V Prasad A Tree Projection Algorithm for Generation of Frequent Itemsets Journal of Parallel and Distributed Computing special issue on high performance data mining to appear 2000 2 R Agrawal T Imielinski and R Srikant Mining association rules between sets of items in large databases SIGMOD May 1993  R Agrawal R Srikant Fast Algorithms for Mining Association Rules Proc of the 20th Int Conference on Very Large Databases Santiago Chile, Sept 1994  R Agrawal H Mannila R Srikant H Toivonen and A 1 Verkamo Fast Discovery of Association Rules Advances in Knowledge Discovery and Data Mining Chapter 12 AAAVMIT Press 1995 5 C C Aggarwal P S Yu Mining Large Itemsets for Association Rules Data Engineering Bulletin 21 1 23-31 1 998 6 C C Aggarwal P S Yu Online Generation of Association Rules. ICDE 1998: 402-41 1 7 R J Bayardo Efficiently mining long patterns from databases SICMOD 1998: 85-93 8 R J Bayardo and R Agrawal Mining the Most Interesting Rules SIGKDD 1999 145-154 9 S Brin R Motwani J D Ullman and S Tsur Dynamic itemset counting and implication rules for market basket data SIGMOD Record ACM Special Interest Group on Management of Data 26\(2\1997 IO B Dunkel and N Soparkar Data Organization and access for efficient data mining ICDE 1999 l 11 V Ganti J E Gehrke and R Ramakrishnan DEMON Mining and Monitoring Evolving Data. ICDE 2000: 439-448  121 D Gunopulos H Mannila and S Saluja Discovering All Most Specific Sentences by Randomized Algorithms ICDT 1997: 215-229 I31 J Han J Pei and Y Yin Mining Frequent Pattems without Candidate Generation SIGMOD Conference 2000 1  12 I41 M Holsheimer M L Kersten H Mannila and H.Toivonen A Perspective on Databases and Data Mining I51 W Lee and S J Stolfo Data mining approaches for intrusion detection Proceedings of the 7th USENIX Securiry Symposium 1998 I61 D I Lin and Z M Kedem Pincer search A new algorithm for discovering the maximum frequent sets Proc of the 6th Int Conference on Extending Database Technology EDBT Valencia Spain 1998 17 J.-L Lin M.H Dunham Mining Association Rules: Anti Skew Algorithms ICDE 1998 486-493 IS B Mobasher N Jain E H Han and J Srivastava Web mining Pattem discovery from world wide web transactions Technical Report TR-96050 Department of Computer Science University of Minnesota, Minneapolis, 1996 19 J S Park M.-S Chen P S Yu An Effective Hash Based Algorithm for Mining Association Rules SIGMOD Conference 20 N Pasquier Y Bastide R Taouil and L Lakhal Discovering frequent closed itemsets for association rules ICDT 99 398-416, Jerusalem Israel January 1999 21 J Pei J Han and R Mao CLOSET An efficient algorithm for mining frequent closed itemsets Proc of ACM SIGMOD DMKD Workshop Dallas TX May 2000 22 R Rastogi and K Shim Mining Optimized Association Rules with Categorical and Numeric Attributes ICDE 1998 Orlando, Florida, February 1998 23 L Rigoutsos and A Floratos Combinatorial pattem discovery in biological sequences The Teiresias algorithm Bioinfomatics 14 1 1998 55-67 24 R Rymon Search through Systematic Set Enumeration Proc Of Third Int'l Conf On Principles of Knowledge Representation and Reasoning 539 550 I992 25 A Savasere E Omiecinski and S Navathe An efficient algorithm for mining association rules in large databases 21st VLDB Conference 1995 26 P Shenoy J R Haritsa S Sudarshan G Bhalotia M Bawa and D Shah: Turbo-charging Vertical Mining of Large Databases SIGMOD Conference 2000: 22-33 27 R Srikant R Agrawal Mining Generalized Association Rules VLDB 1995 407-419 28 H Toivonen Sampling Large Databases for Association Rules VLDB 1996 134-145 29 K Wang Y He J Han Mining Frequent Itemsets Using Support Constraints VLDB 2000 43-52 30 G I Webb OPUS An efficient admissible algorithm for unordered search Journal of Artificial Intelligence Research 31 L Yip K K Loo B Kao D Cheung and C.K Cheng Lgen A Lattice-Based Candidate Set Generation Algorithm for I/O Efficient Association Rule Mining PAKDD 99 Beijing 1999 32 M J Zaki Scalable Algorithms for Association Mining IEEE Transactions on Knowledge and Data Engineering Vol 12 No 3 pp 372-390 May/June 2000 33 M. J. Zaki and C Hsiao CHARM An efficient algorithm for closed association rule mining RPI Technical Report 99-10 1999 KDD 1995: 150-155 1995 175-186 3~45-83 1996 452 



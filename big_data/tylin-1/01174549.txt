Proceedmgs of the First International Conference on Machine Learning and Cybernetics Beijing 4-5 November 2002 PRODUCT HIERARCHY-BASED CUSTOMER PROFILESFOR ELECTRONIC COMMERCE RECOMMENDATION LI NIU XIAO-WE1 YAN'b CHENG-QI ZHANG b SHI-CHAO ZHANG  a'School of Mathematics and Computer, Guangxi Normal University, Guilin PRC  Faculty of Information Technology University of Technology, Sydney, Australia E-MAIL niulimail@263.net xyan chengqi, zhangsc it.uts.edu.au Abstract Personalized service is becoming a key strategy in electropic commerce Traditional personalization 
techniques such as collaborative filtering and rule-based method have many drawbacks including lack of scalability reliance on subjective user rating or static profiles and the inability to capture a richer set of semantic relationships among objects In this paper we present a new approach, building customer profies based on product hierarchy for more effective personalization in electronic commerce We divide each customer profde into three parts: basic profile, preference profile and rule profie Based on the customer profiles two kinds of recommendations 
can be generated which are interest recommendation and association recommendation We also propose a special data structure Profile Tree for effective searching and matching In terms of our method customer profiles can be constructed online and realtime recommendations can be implemented In the end we conduct experiments to validate our methods using real data Keywords Personalization Recommendation system Customer profile Data mining 1 Introduction In recent years E-commerce has been growing 
fast More and more companies are providing services on the Web A report from Forrest Research showed that B2C business to customer\retail spending was US$20.3 billion in 1999 and estimated to grow US$144 billion by 2003 Literature argues that companies need to shift from the old world of mass production where standardized products homogeneous markets, and long product life and development cycles were the rules to the new world where "variety and customization supplant the standardized products When it comes to E-commerce, personalization techniques are the pivotal forces for that change Personalization is a fairly wide topic including 
adaptive websites targeting Web recommendation systems etc Its goals are to provide customers with what they want or need without requiring them to ask for it explicitly 3*41 In order to achieve its goals understanding customer behaviors deeply is necessary As for E-commerce personalization is mainly about recommendation system which can be used for recommending products to customers according to their preferences In general, most recommendation techniques fall in three fields rules-based recommendation collaborative filtering recommendation, and learning agent recommendation techniques Rules-based recommendation needs domain experts to specify rules based on user demographics or static profiles which 
are collected through a registration process by explicitly asking a series of questions In terms of these static customer profiles marketers can know customers preferences related with products and then recommend specific products to specific customers 51 Collaborative filtering technique is deriving from information filtering which is relative to information retrieval IR In IR given a query, the system returns the contents matching the query requirements by searching the information source As for information filtering given the information objects the task is to deliver them to users according to their preferences In collaborative filtering recommendation two methods 
are prevailing which are user-based collaborative filtering and item-based collaborative filtering 6 I Both methods need customers rating scores about products which are explicitly given by the users User-based collaborative filtering first search the rating score database to generate the K neighbors of the active customer which have the similar opinions with the active customer Then the recommendation of the active customer can be generated according to the history purchase records of k neighbors User-based collaborative filtering system is simple and easy to be implemented However its high latency in giving predictions for active user can be a very serious drawback in systems 
with a large number of requests that should be processed in real time Item-based collaborative filtering can improve the performance of user-based method by bridging the sparsity of data r71 The main idea is to analyze the user-item representation matrix to identify relations between different items and than to use these relations to compute the prediction score for a given user-item pair Their methods can produce recommendation sets more rapidly without computing neighbors of active customer Both user-based collaborative filtering and item-based filtering rely on subjective customer rating score about 0-7803-7508-4/02/$17.00 02002 IEEE 1075 


products Hence, the inaccuracy and sparsity of data always accompany them Moreover with the growth of customers and products, the scalability of those algorithms is also a serious problem Learning agent recommendation technique a non intrusive personalization can be expected to deal with the problems of traditional recommendation techniques It employs many methods such as data mining machine learning and statistics etc to capture customer behavior data After data analysis customers are modeled by creating their profiles From customer profiles the preferences of each customer can be known and recommendation sets for customers can be generated Customer profiles are the most important component of learning-based recommendation system Many approaches have been proposed to construct customer profiles Web objects \(Web pages, images, sound etc\accessed by a customer often provide important information about the customer's interests Web objects also have relations with their URLs Literature 9 101 proposed effective methods to model Web objects and customer profiles based on vector space model An example of customer profile is abj WI cobj WQ  cob w Where wi is the weight of Web object obji which can be measured in terms of several methods, for example by the time consumption or frequencies of objects Based on content-based filtering techniques literature l 13 describes each user as a vector of document category Such user characterizations are then used to find user communities based on a projected clustering scheme Their approaches overcome some drawbacks of static profiles Data mining is an effective technique to extract interesting knowledge from database Literature 12 131 discussed some approaches to build customer profiles by using association rule mining I2 gave the concept of profile association rule and detailed its mining algorithms based on R-Tree defined a customer profile as factual profile and behavioral profile Behavioral profile can include association rules mined from transaction database These customer profiles mainly consisted of association rules based on customer purchase history Some methods were also given to validate thousands of original rules very effectively In this paper we present such a method building customer profiles based on product hierarchy for more effective personalization in electronic commerce We divide each customer profile into three parts basic profile learned from customer demographic data preference profile learned from behavioral data and rule profile mainly referring to association rules Based on customer profiles, two kinds of recommendations can be generated which are interest recommendation and association recommendation We also propose a special data structure that is Profile Tree for effective searching and matching In terms of our method, customer profiles can be constructed online and real time recommendation can be implemented In the end we conduct experiments to validate our methods using real data 2 Constructing customer profiles 2.1 Definition of business data 2.1.1 Customer data There are many types of data about customer such as demographics, clickstream, purchase data call center data etc We classify these data into two categories basic datu and behavior datu Each part describes a customer from a specific view as shown in Figure 1 Proceedings of the First International Conference on Machine Learning and Cybernetics Beijing 4-5 November 2002 1076 Customer Data clickstream call center data marketing data  Fig.l Customer Data Customer basic data can be obtained from registration process or other data service departments In general basic data show who the customer is as well as the basic characters of the customer. These data are much more static than behavior data and they are independent from the behaviors between customer and E-commerce Website Basic data are useful for recommendation generation For example a customer's sex and age can be used for cosmetic recommendations In our method, customer basic data are used to build customer basic profiles, which will be detailed in next section Behavior data derive from customer purchase history and visitor clickstream They also can be obtained from customer call center data and marketing campaign data etc Behavior data are generated when the behaviors between customer and Website happen. Most of customer behavior data have relations with products that the customer likes Thus they are important for recommendation system and we use them to construct customer profiles 2.1.2 Product hierarchy Product hierarchy is an instance of concept hierarchy A concept hierarchy defines a map sequence which maps lower level concepts to higher level concepts. For example in a location hierarchy a map sequence can bellstreet  city province country of which every concept e.g street can be mapped to a higher level concept e.g city unless it is the highest level concept\(namely country The more detailed discussion about concept hierarchy can be found in 8 


Proceedings of the First International Conference on Machine Learning and Cybernetics Beijing 4-5 November 2002 I Book Drink Electronic Art inance Science iquor Syrup Spirit IBeer lWine Fig.2 Product Hierarchy Note the leaf nodes are products and they are not shown here In order to learn a customer's preferences on products we use product hierarchy. Figure 2 gives us an example of a product hierarchy presented as a tree Each node is a product category, each product is a leaf node and the root of the tree is Product Customer behavior data can tell us which type of products a customer likes while product hierarchy gives us a detailed or global view of a specific product So we combine customer behavior data with product hierarchy to learn a customer's preferences and construct his or her profile 2.2 Definition of customer profile The following features are necessary or very useful in E commerce recommendation applications 1 Completely describing the customer's characters on shopping 2 Having uniform presentation with products in order to compute the similarity between a customer and a product easily 3\Dynamic and incremental 4 Supporting realtime recommendation Accordingly we define a customer profile as shown in Figure 3 I Customer Prufde Fig.3 Customer Profile A static profile is stable or changes very slowly during a long period It can be constructed based on customer basic data, which possibly includes a customer's name, sex, age job salary etc With respect to static profile dynamic profile can be built and updated in real time which is on the basis of customer behavior data. Because a customer may show continuous and diverse behavior in a period the profile based on customer behavior data must be dynamic such that it can reflect the specific preferences of the customer in a specific period And with time on it can be incrementally updated Dynamic profile has two parts preference profile and rule profile. The former contains information about which types of products a customer likes. For example Amy likes accounting books of which prices arrange from 40 to 120 while her dresses often cost no less than 500 The later of dynamic profile is made up of rules mined from customer behavior data using data mining methods such as association rule mining clustering classification etc For instance if it is Mother's Day Tom will buy Chopin's music CD for his mother We adopt the techniques proposed in  131 to construct customer rule profile We name those recommendations based on static profile and preference profile as preference recommendation and those based on rule profile as rule recommendation 2.3 Incremental learning Customer preferences are the explicit description of a customer's shopping habits. We build customer preference profiles by using clustering and vector space model techniques on the basis of customer behavior data e.g purchase history In a product hierarchy \(referring to Figure 2\each node represents a product category and each category has some specific attributes For example the root node product may has attributes of price, brand manufacture, discount In Figure 2 node product has three children node Book Drink and Electronic Because of the inheritance each child node retains the whole attributes of its parent and also may bring some new attributes The child node, Book, has price, brand, manufacture and discount, inherited from its parent and has its own attributes of content, author, page number etc. Each concrete product lies in the bottom of tree namely leaf node More examples are shown in Figure 4 Product ProductID SubTableID Title Relation Price Brand Manufacturer ProduceDate, Discount Electronic ProductlD Title Price Brand, Manufacturer ProduceDate Discount Voltage AC/DC Power Color, Weight Aduiovisual ProductID Title Price Brand, Manufacturer ProduceDate Discount Voltage AC/DC Power Color Weight SoundEffect Cellphone ProductID Title Price Brand Manufacturer, ProduceDate Discount Voltage ACDC Power Color Weight sizeonch MinimumRatedStandbyTime\(hour 1077 


Proceedings of the First International Conference on Machine Learning and Cybernetics Beijing 4-5 November 2002 MinimumRatedTakTime BatteryType\(hour ChargingTime\(hour Network Type Fig.4 Examples of Inheritance of Product Attributes All of product attributes can be divided into two types numerical and literal Numerical attributes can include price book page number discount etc while literal attributes may include brand, manufacture, book content etc Based on product hierarchy, all products can be classified into specific category. From each node, we can obtain the view of a preference of a customer. Because the leaf nodes are specific products we can extract customer preferences about their parents from customer purchase histories We define customer preference in terms of product or product category\attributes So the customer preference has the same presentation with products. That is Customer Preference  Where Ti is a taste of the preference We define a taste as the subpreference of a customer preference, which has the more particular description about a customer. For example Accounting Book is a customer preference, while "Price Title", "Authors" etc, are all tastes of Accounting Book wi is the weight of Ti  which is specified by experts From numerical product attributes we extract tastes by using clustering techniques Thus the attributes are grouped into clusters For example the price attribute of an accounting book can be 49.00 and the price taste of a preference can be a number range, e.g 30 851 For literal attributes we use vector space model to present customer tastes. That is Taste  U wl>,<t2 WZ  t w,>I Where ti is a taste term representing a subvector of this taste vector and wi is its weight After standard vector operation under one specific category multiple products literal attributes can be aggregated. Thus the literal tastes can be built According to the above discussions we give the completed representation of customer profile based on XML as follows TI WI T2 w2>1 e Tn wP Customer Profile Preference Tastel value weight mastel Tastez value weight Taste2 Taste value, weight masten  Preference  Preference Tastel value, weight Tastel  Tasted value, weight Taste2 Taste value, weight dlasten2  Preference Preference  Tastel value, weight Tastel Taste value, weight </Taste  Taste value weight Taste Preference Customer Profile Note that the customer static profile can also be represented as this model and the rule profile is not included here The method of constructing customer profiles is an incremental process When a customer has new purchase records his or her profile can be updated and it is unnecessary to redo the whole job Furthermore, the task of updating profile is fairly easy and can be conducted in real time 3 Profiietree We define a type of data structure to store customer profiles which is named as Profile Tree As will be showed in this section a profile tree can contain the completed information of a customer profile, and also it is based on product hierarchy Furthermore profile tree supports for realtime recommendation by providing rapid indexing and profile computing  a  An example of a profile tree  b  Node structure Fig 5 Profile Tree In Section 2.3 we have discussed how to learn a customer's preferences based on product hierarchy. These customer preferences are learned directly from customer purchase records, which are leaf nodes in a profile tree After obtaining these leaf nodes the higher level nodes can be deduced by aggregating preferences based on product hierarchy The aggregation regulations are 1 Only those preferences which have the same parent can be aggregated, and the result is their parent's preference 2 When a preference is to be aggregated with another only the same tastes can be aggregated and the result is tastes of their parent's preference If a taste of one 1 078 


Proceedings of the First International Conference on Machine Learning and Cybernetics Beijing 4-5 November 2002 Atmbutes Product Purchase Records  Customer Purchase Records  Leaf Node preference has no matching taste in another preference it will be deleted 3 The method of taste aggregating is alike with that of learning preferences \(see Section 2.3 15 130 16 4 Product recommendation The goal of the recommendation system is to generate a recommendation set for active customer of which the products most closely match active customer profile In our method both customer profiles and products are represented as the same model So it is fairly convenient to compute the similarity between a customer profile and a product Preference  TI twl T2 twz  T twn Product  41 awl Az aw2  A awn If Ti\(Ai has numerical value Ti vl v2 and Ai v the similarity between Ti and Ai can be computed by 12v-v v I Tastesimilarity  I v2 v1 If it has literal value then Ti  tl tw1 tz twz  The similarity between Ti and Ai can be calculated by the et twn CUI awl 2 wp  a awn following Cosine function 2 tw x awi  Tastesimilarity  i=l  i=l i=l So the similarity of preference and product is  TasteSimilarity x tasteweight In the end the recommendation set for active customer can be obtained by RecommendationSet   Product I PreferenceSimilarity t where t is a threshold of preference similarity PreferenceSimilarity n i=l 5 Experiments The dataset is extracted from http://www.amazon.com http://www prime. wines corn http://www.needmorebeer.com http://www.cornwellcoffee.com From these Web sites we construct a product hierarchy Based on this product hierarchy we set up a virtual Web store Then 11 persons are invited to the experiments as customers and everyone generates about 15-30 purchase records on different products. The main parameters of the dataset are listed in Table 1 Table 1 Dataset Nodes of Product Hierarchy Tree I 87 Leaf Nodes I 58 Products I233 Customers I 11 Based on the approaches denoted in previous sections we implement a system prototype to construct customers profiles In order to check the incremental learning of our approaches we select different number of purchase records First we use 8-10 records to construct the original profiles and then add 5-7 records into database to update customer profiles An example of customer profiles constructed by our prototype is listed below Preference1D:lO PreferenceName: AccountingBook Preference Weight 0.26 TasteNwn I1 TasteName  TasteType  Tastevalue  Tasteweight Title O/NULUO Price U45.5-84.3 0.1 Manufacturer ONULL  0.05 Discount UO 7/0.1 Content O/Fimncia,O.5.Accounting,0.3,Accounting Practices,O.Z  0.4 Author O/Charles W Mulford.O.4,Raig D Shoulders.0.2 Eugene E Comiskey,O.Z Robert J Freemn,O.Z 0.05 Pagecount 1/305-407/0.02 Edition O/Hardcover,O.7, Paperback,O.3  0.01 6 Conclusions In this paper we define business data and customer profile based on product hierarchy for E-commerce recommendation application Especially we analyze the differences between preference profile and de profile, and propose an incremental approach to construct customer preference profiles In the end we conduct experiment to validate our methods There are several problems we need to investigate further. These issues include  more customer behavior data should be used, especially the clickstream, because the Web clickstream contains very important information about how a customer likes products  Web content mining techniques can be employed to extract customer preferences  more reco,mendation experiments and the comparisons with other techniques such as user-based and item-based collaborative filtering, should be conducted in details References l Eric Schmitt Harley Manniny Yolanda Paul and Sadaf Roshan Commerce Software Takes Off Forrester Report, March 2000 Joe Pine Mass Customization 1993 2 1079 


Proceedings of the First International Conference on Machine Learning and Cybernetics Beijing 4-5 November 2002 r31 r41 51 61 71 P31 91 B Mittal and W Lassar The Role of Personalization in Service Encounters. Journal of Retailing, 72 l 95 125,1996 Mulvenma M.D Annual S.S and Buchner A.G Personalization on the Net Using Web Mining Communication of the ACM, 43\(8 122-125,2000 Y.-F Kuo L.-S Chen Personalization Technology Application to Internet Content Provider Expert Systems with Applications 21\(2001\203-215 Jonathan L Herlocker Joseph A Konstan AI Borachers and John Riedl An Algorithmic Framework for Performing Collaborative Filtering SIGlR\22299 Badnal Sarwar George Karypis, Joseph Konstan, and John Riedl Item-based Collaborative Filtering Recommendation Algorightms. WWW10, Hongkong ACM, 1-5 May 2001 Jiawei Han, Micheline Kamber. Data miningconcepts and Techniques. Morgan kanfmam Press, 2001 C.-H Lee Y.-H Kim P.-K Rhee Web Personalization Expert with Combining Collaborative Filtering and Association Rule Mining Technique Expert System with Applications, 21\(2001\131-137 lo Bamshad Mobasher Hoghum Dai TaoLuo Yuqing Sun and JiangZhu Integrating Web Usage and Content Mining for More Effective Personalization ll Kang-Lun Wu Cham C. Aggawal, and Philip S Yu Personalization with Dynamic Profile. 2001 IEEE  Chan C Aggarwal Zheng Sun and Philip S Yu Online Algorithms for Finding Profile Association Rules. CIKM\22298  131 Gediminas Adomavicius and Alexander Tuzbilin Using Data Mining Methods to Build Customer Profiles IEEE Computer, 2001 1080 


References 1 A garw al, R., Aggarw al, C., an d Prasad V., A tree projection algorithm for generation of frequent itemsets. In Proceedings of High Performance Data Mining Workshop Puerto Rico, 1999 2 A graw al R an d Srikan t, R F a st al go rith ms f o r mining association rules In Proceedings of the 20 th VLDB conference pp. 487-499, Santiago Chile, 1994 3 B uc hne r  A  a nd M u l v e nna M   D  D i sc ov e r i n g internet marketing intelligence through online analytical Web usage mining SIGMOD Record  4\ 27, 1999 4 C har n iak  E  Statistical language learning MIT Press, 1996 5 C l i f t o n, C a n d Co ol e y R., T opCa t  da t a  m i ni ng for topic identification in a text corpus. In Proceedings of the 3rd European Conference of Principles and Practice of Knowledge Discovery in Databases Prague, Czech Republic, 1999 6  Coole y  R M obasher  B., an d Sr iv astav a J., Data preparation for mining World Wide Web browsing patterns Journal of Knowledge and Information Systems 1\ 1, 1999 7 C hen, M  S Par k J. S a nd Y u  P S  Data mining for path traversal patterns in a Web environment In Proceedings of 16th International Conference on Distributed Computing Systems  1996 8 Han, E H, Bole y  D., Gini, M Gr oss R   Hastings, K., Karypis, G., Kumar, V., and Mobasher, B., More, J., Document categorization and query generation on the World Wide Web using WebACE Journal of Artificial Intelligence Review January 1999 9 Her lock er  J K onstan, J., B o r c her s, A., Rie d l, J  An algorithmic framework for performing collaborative filtering. To appear in Proceedings of the 1999 Conference on Research and Development in Information Retrieval August 1999 10 Han, E H, K a r y pis, G., K u m a r  V., and M o basher  B., Clustering based on association rule hypergraphs. In Proccedings of SIGMOD\22297 Workshop on Research Issues in Data Mining and Knowledge Discovery \(DMKD\22297 May 1997 11 Han, E H, K a r y pis, G., K u m a r  V., and M o basher  B., Hypergraph based clustering in highdimensional data sets: a summary of results IEEE Bulletin of the Technical Committee on Data Engineering 21\ 1, March 1998 12 Jo ach im s T F r eitag  D., Mitch e ll T   WebWatcher: A Tour Guide for the World Wide Web. In Proceedings of the International Joint Conference in AI \(IJCAI97 August 1997 1 L i eb e r man   H Letizia: an agen t th at assists W e b browsing. In Proceedings of the 14 th International Joint Conference in AI \(IJCAI95 AAAI Press Menlo Park, California, 1995 14 Nasr a oui O F r i g ui, H., Jos h i, A., K r ishnap u r a m  R., Mining Web access logs using relational competitive fuzzy clustering. To appear in the Proceedings of the Eight International Fuzzy Systems Association World Congress August 1999 15 Pe r k ow i t z M  a nd E t z i oni O A d a p t i v e W e b sites: automaticlly synthesizing Web pages. In Proceedings of Fifteenth National Conference on Artificial Intelligence Madison, WI, 1998 16 Sp ilio p o u l o u  M a n d  F a u l stich  L  C., W U M: A Web Utilization Miner In Proceedings of EDBT Workshop WebDB98 Valencia, Spain, LNCS 1590, Springer Verlag, 1999 17 Sc he c h t e r  S., K r i s hna n, M a nd Sm i t h M  D   Using path profiles to predict HTTP requests. In Proceedings of 7th International World Wide Web Conference Brisbane, Australia, 1998 1 Sh ard a n a n d   U., Maes, P So cial inf o rmatio n filtering: algorithms for automating "word of mouth." In Proceedings of the ACM CHI Conference 1995 1 Sh ah ab i C., Zarkesh  A. M Ad i b i J  and  Sh ah V., Knowledge discovery from users Web-page navigation. In Proceedings of Workshop on Research Issues in Data Engineering  Birmingham, England, 1997 2 Yan  T  Jaco b s en M Garcia-Mo lin a, H., Da y a l U., From user access patterns to dynamic hypertext linking. In Proceedings of the 5 th International World Wide Web Conference, Paris France, 1996 


results are shown in Table 4 6 Conclusions mem \(M mem M associative classification 1 efficiency at handling huge Table 4 The comparison of CBA and CMAR on main memory usage Dataset Auto Hypo Ion0 Sick Please note that in this experiment we disable the lim itation of number of rules in CBA In such a setting CBA and CMAR generate all the rules necessary for classifica tion and thus are compared in a fair base From the table one can see that on average CMAR achieves 77.12 sav ing on main memory usage The saving in main memory usage can be explained from two apsects First CMAR uses CR-tree The compactness of CR-tree brings significant gain in storing a large set of rules where many items in the rules can be shared On the other hand CR-free is also an index structure of rules Before a rule is inserted into a CR-tree CMAR checks if there is a general rule or some more specific rules in the tree If so related pruning is pursued immediately Such a pruning techique also contributes to the saving of main memory To test the scalability of CMAR we compare the run time of CBA and CMAR on six data sets The results are shown in Figure 5 Again we disable the limit on number of rules in CBA In the experiments CBA spends a large portion of runtime on YO  attr  cls  rec CBA runtime CMAR runtime 25 7 205 612s 408s 25 2 3163 92s 19s 34 2 351 150s 89s 29 2 2800 74s 13s Sonar I 60 I 2  208 1 226s 145s Table 5 The runtime of CBA and CMAR As can be seen from the table CMAR is faster than CBA in many cases Please be note that the machine we use for testing is with relatively small size of main memory 128M Both CBA and CMAR can be expected running significantly faster if more main memory is available racy 2 it prunes rules effectively based on confidence correlation and database coverage and 3 its efficiency is achieved by extension of an efficient frequent pat tern mining method FP-growth construction of a class distribution-associated FP-tree and applying a CR-tree structure to store and retrieve mined association rules effi ciently Our experiments on 26 databases in UCI machine learning database repository show that CMAR is consis tent highly effective at classification of various kinds of databases and has better average classification accuracy in comparison with CBA and C4.5 and is more efficient and scalable than other associative classification methods References I R Agrawal and R Srikant Fast algorithms for mining as 2 P Clark and T Niblett The CN2 induction algorithm Ma 3 G Dong X Zhang L Wong and J Li Caep Classifi sociation rules In VLDB\22294 Chile Sept 1994 chine Learning 3:261-283,1989 cation by aggregating emerging patterns In DS\22299 LNCS I72 I Japan Dec 1999 4 R Duda and P Hart Pattern Classification and Scene Anal ysis John Wiley  Sons 1973 5 J Han J Pei and Y Yin Mining frequent patterns without candidate generation In SIGMOD\222OO Dallas TX May 2000 6 B Lent A Swami, and J Widom Clustering association rules In ICDE\22297 England April 1997 7 W Li Classification based on multiple association rules M.Sc Thesis Simon Fraser University April 2001 8 T.-S Lim W.-Y Loh and Y.-S Shih A comparison of prediction accuracy complexity and training time of thirty-three old and new classification algorithms Machine Learning 39,2000 9 B Liu W Hsu and Y Ma Integrating classification and association rule mining In KDD\22298 New York NY Aug 1998 IO J R Quinlan C4.5 Programs forkfachine Learning Mor gan Kaufmann 1993 I I K. Wang S Zhou and Y He Growing decision tree on support-less association rules In KDD\222OO Boston MA Aug 2000 376 


of the query expression without ha ving the global view of the in ten tion There is a big c hance that the enco ded pro cedure ma y not b e the b est w a y to compute the rules dep ending on the database instance F urthermore as w e understand it their prop osals require p oten tially large n um ber of name generation for relations and attributes The names that are needed are usually database dep enden t and th us p ossibly cannot b e gathered at query time An additional pro cess needs to b e completed to gather those v ariables b efore actual computations can b egin 5  9 Optimization Issues While it w as in tellectually c hallenging to dev elop a declarativ e expression for asso ciation rule mining from deductiv e databases there are sev eral op en issues with great promises for resolution In the w orst case the least xp oin tneedsto generate n 2 tuples in the rst pass alone when the database size is n  Theoretically  this can happ en only when eac h transaction in the database pro duces an in tersection no de and when they are not related b y subset-sup erset relationship In the second pass w e need to do n 4 computations and so on The question no w is can w e a v oid generating and p erhaps scanning some of these com binations as they will not lead to useful in tersections F or example the no de b 0 3 in gure 11 is redundan t A signican t dierence with apriori lik e systems is that our system generates all the item sets top do wn in the lattice without taking their candidacy as a large item set in to consideration Apriori on the other hand do es not generate an y no de if their subsets are not large item sets themselv es and thereb y prunes a large set of no des Optimization tec hniques that exploit this so called an ti-monotonicit y prop ert y of item set lattices similar to apriori could mak e all the dierence in our setup The k ey issue w ould b e ho ww e push the selection threshold minim um supp ort inside the top do wn computation of the no des in the lattice in our metho d F or the momen t and for the sak e of this discussion let us consider a higher supp ort threshold of 60 for the database T of gure 9 No w the l-en v elop e will b e the one sho wn in ligh ter dashed lines in gure 11 and the no des under this line will b e the large item sets Notice that no ww eha v eto discard no des ad 2 0 and d 0 2 to o This raises the question is it p ossible to utilize the supp ort and condence thresholds pro vided in the query and prune candidates for in tersection an y further Ideas similar to magic sets transformation 3  24 ma y be b orro w ed to address this issue The only problem is that pruning of an y no de dep ends on its supp ort coun t whic h ma y come at a later stage By then all no des ma y already ha v e b een computed and th us pushing selection conditions inside aggregate op erator ma y b ecome non-trivial Sp ecial data structures and indexes ma y also aid in dev eloping faster metho ds to compute ecien t interse ction joins that w e ha v e utilized in this pap er W e lea v e these questions as op en issues that should be tak en up in the future F ortunately though there has been a v ast b o dy of researc h in optimizing Datalog programs including recursiv e programs suc h as the one w e ha v e used in this pap er and hence the new questions and researc h 5 Recall that their prop osal requires one to express the mining problem to the system using sev eral queries and up date statemen ts that utilizes information ab out the database con ten ts to ac hiev e its functionalit y  c hallenges that this prop osal raises for declarativ e mining ma y exploit some of these adv ances Needless to emphasize a declarativ e metho d preferably a formal one is desirable b ecause once w e understand the functioning of the system w e will then be able to select appropriate pro cedures dep ending on the instances to compute the seman tics of the program whic hw e kno wis in tended once w e establish the equiv alence of declarativ e and pro cedural seman tics of the system F ortunately  w e ha v e n umerous pro cedural metho ds for computing asso ciation rules whic h complemen t eac h other in terms of sp eed and database instances In fact that is what declarativ e systems or declarativit y buy us  a c hoice for the most ecien t and accurate pro cessing p ossible 10 Conclusion Our primary goal for this pap er has b een to demonstrate that mining asso ciation rules from an y rst-order kno wledge base is p ossible in a declarativ ew a y  without help from an y sp ecial to ols or mac hinery  and that w e can no wha v ea v ery in tuitiv e and simple program to do so W eha v esho wn that it is indeed p ossible to mine declarativ ekno wledge b y exploiting the existing mac hinery supp orted b ycon temp orary inference engines in programming languages e.g Prolog or kno wledge base systems e.g RelationLog XSB LD L  CORAL All w e require is that the engine b e able to supp ort set v alued terms grouping aggregate functions and set relational op erators for comparison functionalities whic hmostofthesesystemscurren tly supp ort W e ha v e also demonstrated that our formalism is grounded on a more mathematical foundation with formal prop erties on whic h the seman tics of the R ULES system rely  W e ha v e also raised sev eral op en issues related to eciency and query optimization whic h should b e our next order of business As future researc h w e plan to dev elop optimization tec hniques for mining queries that require non-trivial lo ok ahead and pruning tec hniques in aggregate functions The dev elopmen ts presen ted here also ha v e other signican t implications F or example it is no w p ossible to compute c hi square rules 4 using the building blo c ks pro vided b y our system Declarativ e computation of c hi square rules to our kno wledge has nev er b een attempted for the man y pro cedural concepts the computation of c hi square metho d relies on In a separate w ork 2 w e sho w that the coun ting metho d prop osed in this pap er can be eectiv ely utilized to generate the exp ectations needed in order to compute suc h rules rather easily  These are some of the issues w e plan to address in the near future The motiv ation imp ortance and the need for in tegrating data mining tec hnology with relational databases has b een addressed in sev eral articles suc h as 12  13 They con vincingly argue that without suc h in tegration data mining tec hnology ma y not nd itself in a viable p osition in the y ears to come T o b e a successful and feasible to ol for the analysis of business data in relational databases suc htec hnology m ust b e made a v ailable as part of database engines and as part of its declarativ e query language Our prop osal for declarativ e mining bears merit since it sheds ligh t on ho w rst order databases can be mined in a declarativ e and pro cedure indep enden t w a y so that the optimization issues can b e delegated to the underlying database engine Once suc h argumen ts are accepted sev eral systems 9 


related issues b ecome prime candidates for immediate atten tion F or example traditionally database systems supp orted declarativ e querying without the necessit y to care ab out the pro ceduralit y of the queries In this pap er w eha v e actually demonstrated that asso ciation rule mining can b e view ed as a Datalog query  It is immediate that a direct mapping from the Datalog expressions presen ted in this pap er to SQL can be dev elop ed with no problem at all W e can then rely on ecien t database pro cessing of the query in an optimized fashion Hence w ecomeclose to the essence of the visions expressed b y the leading database researc hers and practioners 12  References 1 Rak esh Agra w al and Ramakrishnan Srik an t F ast algorithms for mining asso ciation rules in large databases In VLDB  pages 487{499 1994 2 Anon ymous A declarativ e metho d for mining c hisquare rules from deductiv e databases T ec hnical rep ort Departmen t of Computer Science Anon ymous Univ ersit y USA F ebruary 2001 3 C Beeri and R Ramakrishnan On the po w er of magic In Pr o c e e dings of the 6th A CM Symp osium on Principles of Datab ase Systems  pages 269{283 1987 4 Sergey Brin Ra jeev Mot w ani and Craig Silv erstein Bey ond mark et bask ets Generalizing asso ciation rules to correlations In Pr o c A CM SIGMOD  pages 265 276 1997 5 D Chimen ti et al The LD L system protot yp e IEEE Journal on Data and Know le dge Engine ering  2\(1 90 1990 6 Jia w ei Han Jian P ei and Yiw en Yin Mining frequen t patterns without candidate generation In Pr o c A CM SIGMOD  pages 1{12 2000 7 Marcel Holsheimer Martin L Kersten Heikki Mannila and Hann uT oiv onen A p ersp ectiv e on databases and data mining In Pr o c of the sixth A CM SIGKDD Intl Conf  pages 150{155 Mon treal Queb ec 1995 8 Flip Korn Alexandros Labrinidis Y annis Kotidis and Christos F aloutsos Ratio rules A new paradigm for fast quan tiable data mining In Pr o c of 24th VLDB  pages 582{593 1998 9 Brian Len t Arun N Sw ami and Jennifer Widom Clustering asso ciation rules In Pr o c of the 3th ICDE  pages 220{231 1997 10 Mengc hi Liu Relationlog At yp ed extension to datalog with sets and tuples In John Llo yd editor Pr oc e e dings of the 12th International L o gic Pr o gr amming Symp osium  pages 83{97 P ortland Oregon Decem ber 1995 MIT Press 11 Rosa Meo Giusepp e Psaila and Stefano Ceri An extension to SQL for mining asso ciation rules Data Mining and Know le dge Disc overy  2\(2 1998 12 Amir Netz Sura jit Chaudh uri Je Bernhardt and Usama M F a yy ad In tegration of data mining with database tec hnology  In Pr o c e e dings of 26th VLDB  pages 719{722 2000 13 Amir Netz Sura jit Chaudh uri Usama M F a yy ad and Je Bernhardt In tegrating data mining with SQL databases In IEEE ICDE  2001 14 Ra ymond T Ng Laks V S Lakshmanan Jia w ei Han and Alex P ang Exploratory mining and pruning optimizations of constrained asso ciation rules In Pr o c A CM SIGMOD  pages 13{24 1998 15 Jong So o P ark Ming-Sy an Chen and Philip S Y u An eectiv e hash based algorithm for mining asso ciation rules In Pr o c A CM SIGMOD  pages 175{186 1995 16 Karthic k Ra jamani Alan Co x Bala Iy er and A tul Chadha Ecien t mining for asso ciation rules with relational database systems In Pr o c e e dings of the International Datab ase Engine ering and Applic ations Symp osium  pages 148{155 1999 17 R Ramakrishnan D Sriv asta v a and S Sudarshan CORAL  Con trol Relations and Logic In Pr o c of 18th VLDB Confer enc e  pages 238{250 1992 18 Konstan tinos F Sagonas T errance Swift and Da vid Scott W arren XSB as an ecien t deductiv e database engine In Pr o c of the A CM SIGMOD Intl Conf  pages 442{453 1994 19 Sunita Sara w agi Shib y Thomas and Rak esh Agra w al In tegrating mining with relational database systems Alternativ es and implications In Pr o c A CM SIGMOD  pages 343{354 1998 20 Ashok a Sa v asere Edw ard Omiecinski and Shamk an tB Nav athe An ecien t algorithm for mining asso ciation rules in large databases In Pr o c of 21th VLDB  pages 432{444 1995 21 Pradeep Sheno y  Ja y an t R Haritsa S Sudarshan Gaura v Bhalotia Ma y ank Ba w a and Dev a vrat Shah T urb o-c harging v ertical mining of large databases In A CM SIGMOD  pages 22{33 2000 22 Abraham Silb ersc hatz Henry F Korth and S Sudarshan Datab ase System Conc epts  McGra w-Hill third edition 1996 23 Shib y Thomas and Sunita Sara w agi Mining generalized asso ciation rules and sequen tial patterns using SQL queries In KDD  pages 344{348 1998 24 J D Ullman Principles of Datab ase and Know le dgeb ase Systems Part I II  Computer Science Press 1988 25 Mohammed J Zaki Generating non-redundan t association rules In Pr o c of the 6th A CM SIGKDD Intl Conf  Boston MA August 2000 1 0 


OM OM 006 OD8 01 012 014 016 018 02 022 False alarm demity Figure 9 Percentage of tracks lost within 200 seconds using three-scan assignment with PD  0.9 TI  O.ls Figure 11 T2  1.9s and T  Is ij  20 and 0  0.1 24 1 22  20  E fls 0  8l 16 0 n 14  12  0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 T1/12 PD Average track life of three-scan assignment with PD varying TI  0-ls T2  1.9s T  Is X  0.02 ij LO and   0.1 mareuvenng index Figure 12 Percentage of lost tracks of 4-D assipment in 200 seconds with maneuvering index varying X  0.01 Ti  0.1 T2  1.9s and T  IS PD  0.98 Figure 10 Percentage of lost tracks of 4-D assignment in 200 SeoDllCls with TI and T2 varying PD  0.98 X  0.02 q 20 and 0  0.1 4-1607 


Figure 13 Average gate size for Kalman filter Figure is relative as compared to nq and curves are parametrized by ij/r with unit-time between each pair of samples 1.2 Iy I 1.1 0.5 I A CRLB for he unifm samiina I  0.4 0.35 d 3 03 i7 3 0.25 0 0.M 0.04 0.06 008 0.1 0.12 0.14 0.16 0.18 0.2 False A!am DemW V I    Figure 14 CramerRao Lower Boundfor Mean Square Error of uniform and nonuniform sampling schemes with Ti  O.ls T2  1.9s T  IS PD  0.9 ij  5 and U  0.25 1 unifon sampling r-ls ked i non-uniform sampling loge inlewi I ti non-uniform sampling shod interva I 0.9 0.8 I Figure 15 MSE comparison of three-scan assignment with Ti and T2 varying I'D  1 X  0.01 ij  20 and U  0.1 4-1608 


Plenary Panel Session 30 XML Databases   Moderator: Michael Carey, IBM Almaden Research Center USA Panelists Adam Bosworth, Microsoft Corporation USA David De Witt University of Wisconsin-Madison, USA Alon Levy University of Washington USA Bruce Lindsay IBM Almaden Research Center USA Jennifer Widom Stanford University USA Demo Session 1 Web Query Optimizer  661 V Zadorozhny L Bright L Raschid T Urhan and M Vidal ReQueSS: Relational Querying of Semi-structured Data  664 R Sunderraman The IDEAL Approach to Internet-Based Negotiation for E-Business  666 J Hammer C Huang Y Huang C Pluempitiwiriyawej M Lee H Li L Wang Y Liu and S Su READY A High Performance Event Notification Service  668 R Gruber B Krishnamurthy, and E Panagos A Multimedia Information Server with Mixed Workload Scheduling  670 G Nerjes DISIMA An Object-Oriented Approach to Developing an Image Database System  672 V Oria T Ozsu P Iglinski B Xu and L Cheng Demo Session 2 The Collaboration Management Infrastructure  677 H Schuster D Baker A Cichocki D Georgakopoulos and M Rusinkiewicz Assisting the Integration of Taxonomic Data The LITCHI Toolkit  679 I Sutherland J Robinson S Brandt A Jones S Embury W Gray R White and F Bisby TheaterLoc: Using Information Integration Technology to Rapidly Build Virtual Applications  681 G. Barish Y.4 Chen D Dipasquo, C Knoblock S Minton I Muslea and C Shahabi Lineage Tracing in a Data Warehousing System  683 Y Cui and J Widom xiii 


The Mentor-Lite Prototype A Light-Weight Workflow Management System  685 J Weissenfels M Gillmann 0 Roth, G Shegalov and W Wonner Location Prediction and Queries for Tracking Moving Objects  687 0 Wolfson B Xu and S Chamberlain Semiorder Database for Complex Activity Recognition in Multi-Sensory Environments  689 S Bhonsle A Gupta S Santini and R Jain Tutorial 1 Web Information Retrieval  693 M Henzinger Tutorial 2 Mobile and Wireless Database Access for Pervasive Computing  694 P Chrysanthis and E Pitoura Tutorial 3 Data Mining with Decision Trees  696 J Gehrke Tutorial 4 Directories Managing Data for Networked Applications  697 D Srivastava Tutorial 5 Indexing High-Dimensional Spaces Database Support for Next Decade\222s Applications  698 S Berchtold and D Keim xiv 


 T5.I2.D100K T10.I4.D100K T15.I4.D100K T10.I6.D400K T10.I6.D800K T10.I6.D1600K Optimizations across Databases 5 0 5 10 15 20 25 30 35 40 45 Improvement COMP TREE COMP-TREE 1 2 4 8 1 2 4 8 1 2 4 8 2 4 8 2 4 8 1 2 4 8 Processors Databases Figure 5 Effect of Computation and Hash Tree Balancing good as the COMP optimization The reason that the hash tree balancing is not suf\336cient to offset inherent load imbalance in the candidate generation in this case The most effective approach is to apply both optimizations at the same time COMP-TREE The combined effect is suf\336cient to push the improvements in the 40 range in the multiple-processor case On 1 processor only hash tree balancing is bene\336cial since computation balancing only adds extra cost 5.4 Short-circuited Subset Checking Figure 6 shows the improvement due to the short-circuited subset checking optimization with respect to the unoptimized version The unoptimized version is the Apriori algorithm due to Agrawal et al 5 The results are presented for dif ferent number of processors across dif ferent databases The results indicate that while there is some improvement for databases with small transaction sizes the optimization is most effective when the transaction size is large In this case we get improvements of around 25 r the unoptimized version To gain further insight into this optimization consider 336gure 7 It shows the percentage improvement obtained per iteration on applying this optimization on the T20.I6.D100K database It shows results only for the uni-processor case r similar results were obtained on more processors We observe that as the iteration k increases there is more opportunity for shortcircuiting the subset checking and we get increasing bene\336ts of up to 60 The improvements start to fall off t the high end where the number of candidates becomes small resulting in a small hash tree and less opportunity for short-circuiting It becomes clear that is an extremely effective 15 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 T5.I2.D100K T10.I6.D800K T15.I4.D100K T20.I6.D100K procs across Databases 0 5 10 15 20 25 Improvement 1 2 4 8 Figure 6 Effect of Short-circuited Subset Checking 23456789101112 Iterations 0 10 20 30 40 50 60 improvement T20.I6.D100K Figure 7  Improvement per Iteration  proc   16 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


optimization for larger transaction sizes and in cases where there are large number of candidate k itemsets 6 Conclusions In this paper e presented a parallel implementation of the Apriori algorithm on the SGI Power Challenge shared memory multi-processor We also discussed a set of optimizations which include optimized join and pruning computation balancing for candidate generation hash tree balancing and short-circuited subset checking We then presented experimental results on each of these Improvements of more than 40 were obtained for the computation and hash tree balancing The short-circuiting optimization was found to be extremely effective for databases with large transaction sizes Finally we reported the parallel performance of the algorithm While we d good speed-up we observed a need for parallel I/O techniques for further performance gains References  R Agra wal T  Imielinski and A Swami Database mining A performance perspecti v e  I n IEEE Trans on Knowledge and Data Engg  pages 5\(6 1993  R Agra wal T  Imielinski and A Swami Mining association rules between sets of items in lar ge databases In Proc M SIGMOD Intl Conf Management of Data  May 1993  R Agra wal H Mannila R Srikant H T o i v onen and A I V erkamo F ast disco v ery of association rules In U F et al editor Advances in Knowledge Discovery and Data Mining  MIT Press 1996  R Agra wal and J Shafer  P arallel mining of association rules design implementation and e xperience Technical Report RJ10004 IBM Almaden Research Center San Jose CA 95120 Jan 1996  R Agra wal and R Srikant F ast algorithms for mining association rules In Proc 20th VLDB Conf  Sept 1994  M Cierniak W  Li and M J Zaki Loop scheduling for heterogeneity  I n 4th IEEE Intl Symposium on High-Performance Distributed Computing also as URCS-TR 540 CS Dept Univ f Rochester  Aug 1995  M Holsheimer  M  K ersten H Mannila and H T o i v onen A perspecti v e on databases and data mining In 1st Intl Conf Knowledge Discovery and Data Mining  Aug 1995  M Houtsma and A Swami Set-oriented mining of association rules In RJ 9567  IBM Almaden Oct 1993  H Mannila H T o i v onen and I V erkamo Ef 336cient algorithms for disco v ering association rules In AAAI Wkshp Knowledge Discovery in Databases  July 1994  J S P ark M Chen and P  S Y u  A n e f fecti v e hash based algorithm for mining association rules In Proc M SIGMOD Intl Conf Management of Data  May 1995 17 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 


 J S P ark M Chen and P  S Y u  E f 336cient parallel data mining for association rules T echnical Report RC20156 IBM T J Watson Research Center Aug 1995  G Piatetsk y-Shapiro Disco v ery  presentation and analysis of strong rules In G P S et al editor  KDD  AAAI Press 1991  A Sa v asere E Omiecinski and S Na v athe An ef 336cient algorithm for mining association rules in large databases In Proc 21st VLDB Conf  1995  M J Zaki M Ogihara S P arthasarathy  and W  Li P arallel data mining for association rules on shared-memory multi-processors Technical Report 618 Department of Computer Science University of Rochester 618 1996 18 Proceedings of the 1996 ACM/IEEE Conference on Supercomputing \(SC\22296 0-89791-854-1/96 $ 10.00 ACM 



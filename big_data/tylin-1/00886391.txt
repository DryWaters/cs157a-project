Mining Fuzzy Association Rules with Weighted Items Joyce Shu Yue Eric Tsang Absfruct-In most models of mining fuzzy association rules the items are considered to have equal importance Due to the diverse human\222s interestingness and preference to items, such models do not work well in many situations To improve such models we propose a method in this paper to mine fuzzy association rules with weighted items One of the major problems in the research of data mining is 
the development of good measures of interestingness of discovered rules In this paper the weighted support and weighted confidence for fuzzy association rules are defined The Kohonen self-organized mapping is used to fuzzify the numerical attributes into linguistic terms A new fuzzy association rules mining algorithm which generalizes the popular Apriori Gen large itemset based algorithm is developed. The advantages of the new algorithm are shown by testing it on a census database with 5000 transaction records Index Tenns-Data mining fuzzy association rules linguistic terms weighted items 
I INTRODUCTION long with the development of database techniques a A huge quantity of large-scale databases have been created in many fields As we know the automation of business transactions produces a deluge of data because even simple transactions like telephone calls shopping trips medical tests and consumer product warranty registrations are recorded in a computer How can we explore this mountain of raw data The objective of data mining is to extract and discover the valuable information in that data  
hidden gold Before we design a data mining system to support decision making we have to know how This work is supported by Hong Kong Research Grant Council\222s grant no. GV762 Joyce Shu Yue is now with the Department of Computing the Hong Kong Polytechnic University Hung Hom Kowloon Hong Kong telephone 852-2766-7312 email csyshu@comp.polyu.edu.hk on leave from the Harbin Institute of Technology, Harbin, China Eric Tsang is with the Department of Computing, the Hong Kong Polytechnic University Hung Hum Kowloon Hong Kong telephone 852-2766-7245 email csetsang@comp.polyu.edu.hk Daniel S Yeung is 
with the Department of Computing the Hong Kong Polytechnic University Hung Hum Kowloon Hong Kong telephone: 852-2766-7263 email csdaniel@comp.polyu.edu.hk Daming Shi is with the Department of Computing the Hong Kong Polytechnic University Hung Hum Kowloon Hong Kong telephone 852-2766-7312 Daniel Yeung Daming Shi people make decision Some sociologists carried out investigations into 60 highly successful California enterprise managers These managers were asked how they make the business decision Everyone answered they used the combination of their intuition and the data No one said they make decision based 
on data alone Mining fuzzy association rules is an important approach in data mining research area Despite many technical breakthroughs some drawbacks still exist They are These methods proposed in  1 2 3 41 often generate a very large number of rules most of which are trival or irrelevant Consider the following patterns in an adult data set cRelationship:H[usband 3 cSex:Male with support  0.4 and confidence  1 O We have seen this pattern may be 
obvious to any person and hence represents little added value  In other works l 2 3 41 all items \(or attributes in database are treated uniformly An item that is of interest to one user may be of no interest to another user For example, facing the adult information selected by a census of the United States in 1990 Table I a pretty girl might be more interested in the attribut\222e \223occupation\224 than the other attribute when she is selecting a boyfriend. But 
if you are an insurance consultant, the 223age\224 should be the most important attribute in all items For different targets different association rules or large itemsets are discovered by using the same mining system in the same database The importance of the attributes is not only an important measure of interestingness but also a way to permit users to control the mining results by taking some specific action 0-7803-6583-6/001$10.00 0 2000 IEEE 1906 


Table 1 Adult Record In this paper we focus on using the definition of weights to describe the importance of the attributes with respect to the user's intuition and integrate the options into mining fuzzy association rule algorithm This paper is organized as follows In Section 2 the related works on the mining fuzzy association rules and studies on the interestingness are outlined Section 3 investigates the definitions and methodology of mining fuzzy association rules with weighted attributes Section 4 shows the experimental results The last section concludes the paper 11 LITERATURE REVIEW 2.1 Fuzzy association rule mining problem Discovering the quantitative association rules is a major step on mining association rules. Fuzzy set theory is more and more frequently used in intelligent systems So instead of using discrete ranges of quantitative attribute values 4 SI 9 and  101 proposed using relevant fuzzy subsets specified by the user for the discovery of association rules In this part, two attempts in the approach are introduced Map the quantitative attributes to fuzzy sets. And then follow the framework of Apriori Gen Algorithm 4 5 91 and modify the detail steps of the algorithm Such as the measure of support and confidence A novel technique called FARM is used to mine fuzzy association rules for quantitative values  101 FARM is an efficient solution for a special case that user-supplied thresholds are hard to determine They pointed out a new way towards intelligent data mining systems These approaches have two advantages 1 Using fuzzy set concept the discovered rules are more understandable to human As fuzzy sets provide a smooth transition between member and non-member of a set it is better than the partition method 2 In real world applications transaction data are usually composed of quantitative values Designing a sophisticated data-mining algorithm to deal with different types of data turns to be a challenge in this research topic When going back to see how people make decisions we find no one make decision based on data alone. All of the previous works haven't provided the facility of dealing with the intuition of users for mining fuzzy association rules 2.2 Mining problem of association rules with weighted items Weight of items is a set of values given by user to quantify the intuition of users The definition can be found in 6 The weights are used to reflect the importance of attributes by eliciting users beliefs based on the domain knowledge Definition I The weighted support of a rule X a Y is f Definition 2 A k-itemset X is called a large itemset if the weighted support of such itemset is no less than the minimum weighted support \(wminsup\threshold,or Definition 3 The weighted confidence of the association rule X 3 Y is 111 MINING USER-DRIVEN FUZZY ASSOCIATION RULES WITH WEIGHTED A'ITRIBUTES 3.1 Definitions This is a generalized version of association rule mining problem called fuzzy weighted association rule mining which includes the mining problems mentioned in Section 2.1 The notation of weighted items is used to represent the importance of individual items the 1907 


weighted support and weighted confidence are considered We formulate our mining problem as follows The explanation of item-weights. Given a set of items  i  i     in   a weight W is assigned to each item i with 0 I wj 5 1 to indicate the degree of importance of the item i where j  1,2,-..,n These weights will be used in computing the weighted support Equations 1 and 2 and the weighted confidence Equation 3 to mine some more interesting fuzzy association rules One may argue that after deleting the entries of items with small weights and letting the big weights equal to 1 the existing mining methodology can be copied In fact this simple attempt to handle this problem is not fit for our situation As pointed out in paper an interesting fuzzy association rule for a heavy weighted items may also consist of low weighted items The explanation of item vector fk,,fk,,.'*,fk 1 where each element fk 1 I i I m which corresponds to a column of the fuzzified table is a membership function defined on the space of all records The weighted support of the item vector x is defined as where N is the number of all records Given two item vectors X   fk  f e fkml  and Y  gp gpI  gP  the weighted support and the confidence for the fuzzy association rule X 3 Y are defined as and 6 Support\(X  Y support X W Confidence X a Y  where N is the number of all records This section is classified into two parts The first part is to fuzzify each numerical attribute for the initial data set into several linguistic terms specified by their membership functions B,ased on the linguistic terms generated in first part the second part provides a fuzzy association rule generation algorithm which contains two steps a find the set of all frequent item vectors with weighted support over a threshold and b generate all fuzzy association rules with weighted confidence over the minimum confidence 3.2 Fuzzifying numerical attribute into linguistic terms This is a process of fuzziFying numerical numbers into linguistic terms which is often used to reduce information overload in hurnan decision making process The numerical salary for example may be perceived in linguistic terms as high average and low One way of determining membership functions of these linguistic terms is by expert opinion or by people's perception Yet another way is by statistical methods ll Fuzzy clustering based on self-organized learning can also be used to generate membership functions  121 What follows is an algorithm for generating certain type of membership functions Let X be the considered data set We intend to cluster X into k linguistic terms Ti j 1 2  k For simplicity we assume the type of membership to be triangular Each linguistic term Ti will have the triangular membership functions as follows Uj X uj Uj j X<'j+l X  x-uj uj Uj j-l X<'j I jek 0 x 5 I Figure 1 Membership functions of the linguistic terms 1908 


Each pair of adjacent membership functions crosses at Input A set of n transaction data each with m attribute the membership value of 0.5 The only parameters needed values a set of membership functions a predefined to be determined are the k centers u,,u An minimum weighted support value wminsup and a effective method to determine these centers is the Kohonen predefined weighted confidence value wminconf feature maps algorithm  At the initial time k centers are set to be distributed evenly on the range of X Let A  a a2  ak 1 Output A set of fuzzy association rules Algorithm FWAL 1 2 F Mapping D 3 4 Main Algorithm wminsup wminconi D F W find all frequent itemvector of length 1 L1   2 I x E A,n  1 and W-Support\(X 2wminsup  5 c database F 6 for k  2 Lk f  k do begin 7 x,A CxEX~iniIx-u,I A ck FWAL\(Lk 11 generate new candidate b 8 itemvectors The centers will be adjusted iteratively Each iteration consists of three steps 1 randomly take a value x from X denoted by x[n 2 search for an integer m such that Ix[nl-a,[n]l in~lx[nl-a~[n]l 3 put a,[n+l]=a,[n]+a\(x[n]-a,[n and keep other centers unchanged where n is the iteration time and a is the learning rate The iteration ends when d\(X,A converges  9 c  10 for all entries FE E do begin 11 I determine candidate itemvectors in the tuple t identified by F  TID 12 c  2 E c I g[lI.g[21  g[k 11 I  0   g[k-2].g[k]\(f 1 13 for all candidates E c do 14 15 if c  b then ck  F.TlD C   16 end 17 SumX  g[11.g[21.....g[kl\(t IISumX is used for evaluating W-Support 2  Lk   2 E C I W-Support 2  2 wminsup 18 end 19 Answer 3.3 Algorithm for generating fuzzy association rules with weighted items uk 221k In this section, the weighted concept is used in the fuzzy version of the Apriori data-mining algorithm to discover interesting association rules from numerical values An algorithm for mining weighted fuzzy association rules has the following inputs and outputs The problem of mining fuzzy association rules can be decomposed into the following three steps 1 Map crisp values and fuzzy terms of each categorical attribute into consecutive integers 2 Use the extended Apriori Algorithm FWAL to discover frequent itemvectors where a frequent itemvector has at least minimum weighted support From the frequent itemvectors, generate all association rules that have at least minimum weighted confidence 3 The subroutines are outlined as follows Mapping D To begin with the set of the transactions must be accepted and transformed to the fuzzy membership grade with the range from 0 to 1 for each attribute of each fuzzy concept which is done in the Mapping procedure FWAL Lk.1 Generate the candidate set Ck from Lk The framework of FWAL is similar to the Apriori Algorithm except that two regions belonging to the same attribute cannot simultaneously exist in an itemset in C 1909 


IV DEMONSTRATIONS This section gives a case study of the adult data selected by a census of the United States in 1990 Table 1 in section 1 to illustrate how the mining user-driven fuzzy association rules technique works to deal with different discovery tasks 8 Data Source and systems We selected 10000 transaction records as our testing data set In our example data six attributes i.e income education level sex age marital status and relationship with others in family are taken into account 8 Weighted Items There are two sets of weighted items for the six attributes given by two users in the following table Table 2 Edu Marital Relatio I Sex I Age I Status I n-shio I level Income I 0.9 I 0.7 1 0.5 I 0.3 I 0.2 I 0.1 I 1 0.2 I 0.3 I 0.5 I 0.7 I 0.9 User  I 0.1 I Table 2 The weights given by different users 8 Process and Results To facilitate users we designed an interactive system shown in the figure 2 User can select the weight values from 0 to 1 according their experience or intuition 2230\222 means the attribute will be neglected and 223I\224 means the most interesting attribute for the user \(shown in Figure 2 Mining bunon Weight Inputs area Figure 2 User Interface A performance study is carried out for the two algorithms unweighted mining fuzzy association rules algorithms proposed in 4 and mining weighted fuzzy association rules algorithm FWAL introduced in this paper We found that different rules could be discovered according to the two set of weights input by user 1 and user 2 in Table 2 These results are presented in Figure 3 in which Figure a shows the percentage structure of each attribute in rules discovered by unweighted algorithm b the percentage structure of each attribute in the discovered rules using the FWAL algoril hm 0 I Ib Figure 3 Visual Generalization Results 1910 


In the result the number of rules having attributes with heavy weights is much more than the number of rules having attributes with light weights Obviously we use the algorithm to obtain the interesting rules from the user\222s point of view V CONCLUSION In this paper the FWAL algorithm is proposed to discover fuzzy association rules based on the users\222 intuitive We derived a new algorithm with which uninteresting large itemsets are pruned during the mining process and which enables us to generate the interesting large itemsets with fewer passes and higher speed In the future we will attempt to use the algorithm in financial data analysis such as stock movement prediction In the previous mining association rules methods market daily trading quotations should be restructured in a distinct way that is similar to supermarket transaction records only based on one of the three attributes share-turnover share-price-change or share volume In fact when an expert forecasts moving trend of stock he or she uses three kinds of information for individual share performance They are 223share-price-change\224 223share volume\224 and 223share-turnover\224 No matter how we based on turnover or share price change to transfer the quotations of the most active shares into transaction panel we fail to integrate the information to forecast the stock movement The method of mining weighted fuzzy association rules can help us to solve the problem 31 41 VI REFERENCES R Agrawal, T. Imielinski and A Swami Mining association rules between sets of items in large databases In SIGMOD pages 207-216, Washington D.C May 1993 R Agrawal and R Srikant Fast algorithms for mining association rules in large databases In 20th lntemutional Conference on Very Large Databases Santiago Chile Sept. 1994 R Srikant and R Agrawal Mining quantitative association rules in large relational tables The I996 ACM SIGMOD lntemational Conference on Management of Datu Monreal Canada June 1996, pages 1-12 Chan Man Kuok, Ada Fu and Man Hon Wong. Mining fuzzy association rules in databases In SIGMOD Record Volume 27, Number 1 pages 41-46, March 1998 Tzeng-Pei Hong Chan-Sheng Kuo and Sheng-Chai Chi A Fuzzy Data Mining algorithm for Quantitative Values The Third lntemutional Conference on Knowledge-Bused lnrelligent Information Engineering Sysiems 3 1 Aug-1 Sept 1999, Adelaide, Australia 6 C.H Cai Ada W.C Fu C.H Cheng and W.W Kwong Mining association rules with Weighted Items In Databuse Engineering and Applicutions Syttipposium Proceedings IDEAS\221PR Internaticmul pages 68-77 1998 71 C.C Agganval P.S Yu Data mining techniques for associations clustering and classification In Third Pucific Asia Conjerence PAKDD-99 Beijing, China, April 1999 U.M Fayyad G Piatetsky-Shapiro P Symth Overview of data mining and knowledge discovery In Knowledge Discovery and Datu Mining AAAlpress P1-36 1996 181 9 Weining Zhang Mining Fuzzy Quantitative Association Rules In Pruceeding of the I I\224\222 IEEE Intemarionul Conference on TOO~S with Arti$ciul Intelligence Pages 99 102, 1999 IO Keith C C. Chan and Wai-Ho Au Mining Fuzzy Association Rules In Proceeding of the 6\223 lnfemutionul Conference on ltnformution and Knciwledge Munugemetit Pages 209-2 15 1997 I I M. R Civanlar and H J Trussell, \223Constructing membership functions using statistical data,\224 In Fuuy Sets und System vol 18, pp.1-14 1986  121 222r Kohonen, \223Self-Oganization and Associate Memory,\222\222 Springer, Berlin 1988 191 1 


NPA  1 EO 1 number of nodes Figure 7 The execution time and the commu nication time on the SR2201 On the other hand, the communication time for Shift algorithms is shorter on the WS cluster than that on the SR2201 6 Discussions 6.1 Execution on a workstation cluster The execution times for NP.4 and CC algorithms increase rapidly with a decrease in the minimum sup port This is because the number of candidate itemsets increases when the minimum support decreases and these algorithms scan the all candidate itemsets in the transaction database at each node But because the Shift algorithm partitions the candidate itemsets into each node the execution time of scanning is shorter than that for the other algorithms and does not in crease as rapidly when the minimum support decreases The execution times for all algorithms increase with an increase in the number of transactions and the ra tio of the execution time of each parallel algorithm to the execution time of the corresponding sequential al gorithm decreases with an increase in the number of transactions This ratio for the Shift algorithm reaches a minimum value when the number of transactions is 4000 and the algorithm converges more rapidly than the other algorithms The execution times for all algorithms decreases with an increase in the number of nodes The re duction of the communication time in Shift operations seems to be due to the scanning processing and com munication processing being executed asynchronously Because data are searched in parallel and all amounts of searched data are almost the same for all these al gorithms CPU processing time which is the difference of the communication time from the execution time is almost the same for all algorithms Our cost analysis showed that the amount of com munication was smallest for the CC algorithms but the execution times for NPA and CC algorithms were almost the same in our experiments This seems to be because that the size of data used in our experiment is not so large 6.2 Execution on the parallel computer The execution times for all algorithms were much longer on the parallel computer than that were in the WS cluster environment We think this is because amount of CPU memory available on the parallel com puter was insufficient On the other hand the com munication time was more stable on the parallel com puter and the time for communication between nodes is shorter on the parallel computer In other words the ratio of the communication time to the execution time is large in a WS cluster environment and the commu nication time has a great influence on the execution time In the WS cluster environment the communication time for the Shift algorithm which uses shift opera tions is less than that for the CC algorithm which uses broadcast operations On the other hand, the commu nication time for the Shift algorithm on the parallel computer is lager than that for the CC algorithm The Shift algorithm is therefore effective in a LVS cluster environment that can execute shift operations rapidly 7 Conclusion The distributed algorithms proposed in this pa per are effective when parallel processing distributed throughout clustered computers is used to mine databases for association rules When we implemented these algorithms on a SVS cluster and on a parallel com puter so that we could evaluate their performance we found that the Shift algorithm was the most effective when there was a large number of candidate itemsets and processor nodes in the WS cluster environment This is because the ratio of communication time to ex ecution time is large in a WS cluster environment and the communication time therefore has a great influence on the execution time We intend to perform more analysis about the com munication cost between nodes We also intend to per form further experiments with large size data which are used at companies and institutes We also intend to develop a new algorithm to share the loads among nodes because real data are often distributed unevenly 367 


References 141 111 121 31 R Agrawd and R Srikant 223Fast Algorithms for Mining Association Rules,\224 Proc of Int\222l Conf on Very Large Data Bases pp.487-499 1994 R Srikant and R Agrawal 223hslining Generalized Asso ciation Rules,\224 Proc of Int\222l Conf on Very Large Data Bases pp.407-419 1995 N Megiddo and R Srikant 223Discovering Predictive As sociation Rules,\224 Proc ofthe 4th Int\222l Conf on Knowl edge Discovery an Databeses and Data Mining 1998 I51 161 E.H Han G Karypis and V Kuniar 223Scalable par allel data mining for association rules;\224 Proc of ACM SIGMOD Int\222l Conf pp.277-288 1997 T Shintani and M Kitsuregawa 223Iniplenientation of Parallel Mining Association Rules and their Evalua tion,\224 JSPP\22296 pp.97-104 June 1996 L Harada N Akaboshi K Ogihara and R Take 223Par allel Algorithm with Load Balancing for Mining Associ ation Rules,\224 IEZCE Trans on Info and Syst V-ol.J82 D-1 No.1 pp.70-81 January 1999 368 


In Figures 10 and 11 we see MAFIA is approximately four to five times faster than Depthproject on both the Connect-4 and Mushroom datasets for all support levels tested down to 10 support in Connect-4 and 0.1 in Mushroom For Connect-4 the increased efficiency of itemset generation and support counting in MAFIA versus Depthproject explains the improvement Connect 4 contains an order of magnitude more transactions than the other two datasets 67,557 transactions amplifying the MAFIA advantage in generation and counting For Mushroom the improvement is best explained by how often parent-equivalence pruning PEP holds especially for the lowest supports tested The dramatic effect PEP has on reducing the number of itemsets generated and counted is shown in Table 1 The entries in the table are the reduction factors due to PEP in the presence of all other pruning methods for the first eight levels of the tree The reduction factor is defined as  itemsets counted at depth k without PEP   itemsets counted at depth k with PEP In the first four levels Mushroom has the greatest reduction in number of itemsets generated and counted This leads to a much greater reduction in the overall search space than for the other datasets since the reduction is so great at highest levels of the tree In Figure 12 we see that MAFIA is only a factor of two better than Depthproject on the dataset Chess The extremely low number of transactions in Chess 3196 transactions and the small number of frequent 1-items at low supports only 54 at lowest tested support muted the factors that MAFIA relies on to improve over Depthproject Table 1 shows the reduction in itemsets using PEP for Chess was about an order of magnitude lower compared to the other two data sets for all depths To test the counting conjecture we ran an experiment that vertically scaled the Chess dataset and fixed the support at 50 This keeps the search space constant while varying only the generation and counting efficiency differences between MAFIA and Depthproject The result is shown in Figure 13 We notice both algorithms scale linearly with the database size but MAFIA is about five times faster than Depthproject Similar results were found for the other datasets as well Thus we see MAFIA scales very well with the number of transactions 5.3 Effects Of Compression To isolate the effect of the compression schema on performance experiments with varying rebuilding threshold values we conducted The most interesting result is on a scaled version of Connect-4, displayed in Figure 14 The Connect-4 dataset was scaled vertically three times so the total number of transactions is approximately 200,000 Three different values for rebuilding-threshold were used 0 corresponding to no compression 1 compression immediately and all subsequent operations performed on compressed bitmaps\and an optimized value determined empirically We see for higher supports above 40 compression has a negligible effect but at the lowest supports compression can be quite beneficial e.g at 10 support compression yields an improvement factor of 3.6 However the small difference between compressing immediately and finding an optimal compression point is not so easily explained The greatest savings here is only 11 at the lowest support of Conenct-4 tested We performed another experiment where the support was fixed and the Connect-4 dataset was scaled vertically The results appear in Figure 15 The x-axis shows the scale up factor while the y-axis displays the running times We can see that the optimal compression scales the best For many transactions \(over IO6 the optimal re/-threshold outperforms compressing everywhere by approximately 35 In any case both forms of compression scale much better than no compression Compression on Scaled ConnectAdata Compression Scaleup Connectldata ALL COMP 0 5 10 15 20 25 30 100 90 80 70 60 50 40 30 20 10 0 Min Support  Scaleup Factor Figure 14 Figure 15 45 1 


6 Conclusions We presented MAFIA an algorithm for finding maximal frequent itemsets Our experimental results demonstrate that MAFIA consistently outperforms Depthproject by a factor of three to five on average The breakdown of the algorithmic components showed parent-equivalence pruning and dynamic reordering were quite beneficial in reducing the search space while relative compressiodprojection of the vertical bitmaps dramatically cuts the cost of counting supports of itemsets and increases the vertical scalability of MAFIA Acknowledgements We thank Ramesh Agarwal and Charu Aggarwal for discussing Depthproject and giving us advise on its implementation We also thank Jayant R Haritsa for his insightful comments on the MAFIA algorithm and Jiawei Han for providing us the executable of the FP-Tree algorithm This research was partly supported by an IBM Faculty Development Award and by a grant from Microsoft Research References I R Agarwal C Aggarwal and V V V Prasad A Tree Projection Algorithm for Generation of Frequent Itemsets Journal of Parallel and Distributed Computing special issue on high performance data mining to appear 2000 2 R Agrawal T Imielinski and R Srikant Mining association rules between sets of items in large databases SIGMOD May 1993  R Agrawal R Srikant Fast Algorithms for Mining Association Rules Proc of the 20th Int Conference on Very Large Databases Santiago Chile, Sept 1994  R Agrawal H Mannila R Srikant H Toivonen and A 1 Verkamo Fast Discovery of Association Rules Advances in Knowledge Discovery and Data Mining Chapter 12 AAAVMIT Press 1995 5 C C Aggarwal P S Yu Mining Large Itemsets for Association Rules Data Engineering Bulletin 21 1 23-31 1 998 6 C C Aggarwal P S Yu Online Generation of Association Rules. ICDE 1998: 402-41 1 7 R J Bayardo Efficiently mining long patterns from databases SICMOD 1998: 85-93 8 R J Bayardo and R Agrawal Mining the Most Interesting Rules SIGKDD 1999 145-154 9 S Brin R Motwani J D Ullman and S Tsur Dynamic itemset counting and implication rules for market basket data SIGMOD Record ACM Special Interest Group on Management of Data 26\(2\1997 IO B Dunkel and N Soparkar Data Organization and access for efficient data mining ICDE 1999 l 11 V Ganti J E Gehrke and R Ramakrishnan DEMON Mining and Monitoring Evolving Data. ICDE 2000: 439-448  121 D Gunopulos H Mannila and S Saluja Discovering All Most Specific Sentences by Randomized Algorithms ICDT 1997: 215-229 I31 J Han J Pei and Y Yin Mining Frequent Pattems without Candidate Generation SIGMOD Conference 2000 1  12 I41 M Holsheimer M L Kersten H Mannila and H.Toivonen A Perspective on Databases and Data Mining I51 W Lee and S J Stolfo Data mining approaches for intrusion detection Proceedings of the 7th USENIX Securiry Symposium 1998 I61 D I Lin and Z M Kedem Pincer search A new algorithm for discovering the maximum frequent sets Proc of the 6th Int Conference on Extending Database Technology EDBT Valencia Spain 1998 17 J.-L Lin M.H Dunham Mining Association Rules: Anti Skew Algorithms ICDE 1998 486-493 IS B Mobasher N Jain E H Han and J Srivastava Web mining Pattem discovery from world wide web transactions Technical Report TR-96050 Department of Computer Science University of Minnesota, Minneapolis, 1996 19 J S Park M.-S Chen P S Yu An Effective Hash Based Algorithm for Mining Association Rules SIGMOD Conference 20 N Pasquier Y Bastide R Taouil and L Lakhal Discovering frequent closed itemsets for association rules ICDT 99 398-416, Jerusalem Israel January 1999 21 J Pei J Han and R Mao CLOSET An efficient algorithm for mining frequent closed itemsets Proc of ACM SIGMOD DMKD Workshop Dallas TX May 2000 22 R Rastogi and K Shim Mining Optimized Association Rules with Categorical and Numeric Attributes ICDE 1998 Orlando, Florida, February 1998 23 L Rigoutsos and A Floratos Combinatorial pattem discovery in biological sequences The Teiresias algorithm Bioinfomatics 14 1 1998 55-67 24 R Rymon Search through Systematic Set Enumeration Proc Of Third Int'l Conf On Principles of Knowledge Representation and Reasoning 539 550 I992 25 A Savasere E Omiecinski and S Navathe An efficient algorithm for mining association rules in large databases 21st VLDB Conference 1995 26 P Shenoy J R Haritsa S Sudarshan G Bhalotia M Bawa and D Shah: Turbo-charging Vertical Mining of Large Databases SIGMOD Conference 2000: 22-33 27 R Srikant R Agrawal Mining Generalized Association Rules VLDB 1995 407-419 28 H Toivonen Sampling Large Databases for Association Rules VLDB 1996 134-145 29 K Wang Y He J Han Mining Frequent Itemsets Using Support Constraints VLDB 2000 43-52 30 G I Webb OPUS An efficient admissible algorithm for unordered search Journal of Artificial Intelligence Research 31 L Yip K K Loo B Kao D Cheung and C.K Cheng Lgen A Lattice-Based Candidate Set Generation Algorithm for I/O Efficient Association Rule Mining PAKDD 99 Beijing 1999 32 M J Zaki Scalable Algorithms for Association Mining IEEE Transactions on Knowledge and Data Engineering Vol 12 No 3 pp 372-390 May/June 2000 33 M. J. Zaki and C Hsiao CHARM An efficient algorithm for closed association rule mining RPI Technical Report 99-10 1999 KDD 1995: 150-155 1995 175-186 3~45-83 1996 452 



Proceedings ofthe 2003 Systems and Information Engineering Design Symposium Matthew H Jones Barbara E Tawney and X Preston White Jr e A GRAPH-BASED ALGORITHM FOR FREQUENT CLOSED ITEMSETS MINING Li Li Donghai Zhai Fan Jin School of Computer and Communication Engineering Southwest Jiaotong University Chengdu 610031 P.RCHINA ABSTRACT Frequent itemsets mining plays an essential role in data mining but it often generates a large number of redundant itemsets that reduce the efficiency of the mining 
task Fre quent closed itemsets are subset of frequent itemsets, but they contain all information of fiequent itemsets The most existing methods of frequent closed itemset mining are ap riori-based The efficiency of those methods is limited to the repeated database scan and the candidate set genera tion This paper proposes a graph-based algorithm for  ing frequent closed itemsets called GFCG Graph-based Frequent Closed itemset Generation The new algorithm constructs an association graph to represent the frequent relationship between items and recursively generates fre quent closed itemset based on that graph It scans the data 
base for only two times and avoids candidate set genera tion GFCG outperforms apriori-based algorithm in experiment study and shows good performance both in speed and scale up properties 1 INTRODUCTION Frequent itemsets mining plays an essential role in mining associations rules RAgrawl 1994 Brin 1997 H Mannila 1997 partial periodicity J.Han 1999 episodes H.Mannila 1997\and many other important data mining areas Let I i,...i be the set of items D-=\(Tl T2...Tn be the transaction database T it[l  n be 
a record of transaction it consisted of items from I Let S be an item set S={ii i 2000 The support of S recorded as szrpp A\221 is the rate of the transactions that contain itemset S If the support of S is not less than the minimum support thresh 014 S is called frequent itemset However it is well lmown that mining task often gener ates large number of frequent itemsets which reduces the efficiency 
of association rules mining or other tasks Instead of mining the complete set of frequent itemsets we can mine the frequent closed itemsets The frequent closed itemsets contain all infomation of frequent itemset and have the same power as frequent itemsets It WiLl lirgely reduce the number of redundant itemset and in crease the efficiency of mining task For example, suppose a database contains only the same two transaction Tl=\(il i2  ilm and T2={il i2  ilao The minimum support threshold is 2 2Im-1 fiequent item 
sets will be generated. They are 223til iz  ilw il i2 is ilm  il i2  ilw}\224 But the only one frequent closed itemset will be generated It is 223{il i _ ilw}\224 Delinition 1 SI and S are two itemsets SI SI is cov ered by S if and only if any transaction that contains SI also contains S recorded as SIilSz Lemmal let 
SI S S3 be itemsets if SlPS2and S2S3 then SIOS3 Rational Let transaction f contains SI For SIPS2 t also contains S2 for Os so f also contains S3 From definition 1 SIOS Definition 2 S is a itemset if there does not exist itemset S\221 SOS\221 i.e S not covered by any itemset, then S is a closed itemset if the support of S is not less than the 
minimum support threshold then S is a frequent closed itemset Lemma 2 S is a frequent itemset but not closed Then there exists a frequent closed itemset S\221 Sils\221 Rational S is not closed from definition 2 there exists an itemset SI SE!S1 If SI is a closed itemset then from supp Sl 9 SI is a frequent closed itemset If S is not closed for the same reason there exists an itemset Szr SIB 19 


Li Zhai and Jin Sz Since the length of itemsets is limited we can find itemset S S,.,OS from lemma 1 SOS Lemma 3 S is a frequent itemset and then S is a frequent closed itemset if and only if S is not covered by any other frequent closed itemset Rational 1 is a frequent closed itemset and then S is not covered by any itemsets So it is not covered by any frequent closed itemsets 2 is a frequent itemset If S is not closed from lemma 2 there must exists a frequent closed itemset that cover it That contlct to the condition When the concept of frequent closed itemset is intro duced the mining task is substantially reduced The num ber of the frequent itemsets generated in that example is 2Iw-1, but the number of frequent closed itemset is 1 That frequent closed itemset is  il i2    ilw and it contains all information of frequent itemset So the frequent closed itemset mining is very important to association rules min ing or some other tasks The most method for the fiequent closed itemsets min ing are apriori-based such as A-close Nicolas Pasquier 1999 The efficiencies of those methods are limited to the bottleneck of repeated database scan and the candidate set generation This paper studies the efficient mining of frequent closed itemsets in large databases, and proposes a new al gorithm, called GFCG Nicolas Pasquier propose an Apri ori-based mining algorithm called A-close Nicolas Pas quia 1999\Algorithm A-close is taken as comparison in this paper. From the performance study the new algorithm shows good performance both in speed and scale up prop e 2 TIIE FREQUENT CLOSED ITEMSET MINING ALGOFUTHM GFCG 2.1 The construction of graph The algorithm GFCG adopts the structure of bit-vector Every frequent item has a corresponding bit-vector The number of bits in each bit-vector equals to the number of transactions in the database The GFCG scans the database for the first time to find the frequent items and initiates a bit-vector for every frequent item AU bits in bit-vector are set to 0 Then the algorithm scans the database for the sec ond time At this time the GFCG algorithm sets every bit in bit-vector If one frequent item appears in kth transaction then the kth bit of its bit-vector was set to 1 Then the GFCG algorithm does not scan the database anymore The notation of bit-vector corresponding to the frequent item i is BV The number of 1s in BV equals to the sup port of i For example considering the database in table I each record is a TID itemset pair where the TID records the identifier of the corresponding transaction, and the itemset records the items purchased in that transaction Table 1  A database of Transaction Itemset r 245 400 135 145 Let the minimum support threshold be 2 The fie quent items in the database are items 1,2,3,4 5 The corresponding bit-vectors are BV1=\(O1O1 l BV2 10 loo BV3 01 OlO BV 1010 l BV5=\(101 11 Property 1 The support of the itemsetni iz  iLOis the number of 1 s in BV,,ABV,~A  ABV  where the notation 223A\224 is the logical AND operation When the bit-vectors have been initiated it is not nec essary to scan the database anymore In the graph construc tion phase GFCG algorithm constructs an association paph to indicate the relationships between frequent items For the association graph if the number of 1s in BV,dV  i  j according to an order L of frequent items is not less than the minimum support threshold a directed edge from item i to item j is constructed, which is recorded as i 3 j The edge between i j means the itemset  i j is a frequent 2-itemset Let the order be L={1,2,3,4,5 the association graph for the above example is shown in figure 1 and the frequent 2-items are  1,3}, {1,5 2,4 2,5 4,5 BVI 01011 l BV*\(10100 BV3=\(01010 Figure 1 The Association Graph 20 


Li Zhai 2.2 The generation of frequent closed itemsets When the graph has been constructed the frequent closed itemsets can be mined recursively based on the bit-vectors and the association graph The following lemmas are pro posed Lemma 4  il iz   ik is a Sequent itemset If there is no association edge starting from item ik to item 21 then il iz   ik u can't be frequent itemset proomBecause there is no association edge starting Som item ik to item 21 ik u is not frequent itemset From the property of apriori any itemset that contains infkequent itemset can't be fiequent itemset So i2i2  iku can't be frequent itemset According to lemma 4 if we want to extend the fre quent k-itemset il i2 6 to frequent \(k+l we only need to check those items that at the end of edge start ing from item  Let 11 be one of such item and the number of 1s in BV,l BVa A...A BV,r A BV is not less than minimum support threshold then il i  ik uf is also a fiequent itemset. Take the database in table 1 as example 12 4 is a Sequent itemset, and there is directed edge start ing from item 4 to item 5 We check the number of 1s in BVIz I 5 The number of 1 s in BVfz I 5 is 2 not less than the minimum support threshold so 2 4 5 is a frequent itemset Definition 3 L is an order of fiequent items AU the items in frequent itemsets are sorted according to the order L f il i _ ik is a fiequent itemset Then the set of frequent itemset Si{s I s={il i  ik}u\(il jz  jl i jm I<m<k 1 n<l 1 is called tbe cluster of itemsets that have the same prefix S''={S 1 s={il iz  ik}U\(i i,>j,l<rn<k 2 is called the extended itemset cluster off Obviously S,'Es hold Lemma 5 I={i  ik is a set of frequent items All the frequent itemsets S can be represented as s=s#Ius12u US 3 wbere the S,k is the cluster of itemsets that have the same prefix ik ProoE Since the items in each frequent itemset are sorted according to order L then all frequent itemsets can be clas sified according to the 6rst item Each class can be repre sented as S I Lemma 6 f il iz  4 is a frequent itemset S can be represented as S'US u  in 1 i n  k 4 and Jin ProoE Same as the proof of lemma 5 S can be classified according to the item that follows the f immediately u<i 15 n  k According to lemma 5 and lemma 6 we can 6nd out all of the frequent itemsets recursively Lemma 7 Sl={iliZ  ik is a frequent itemset. support of SI is SI S2={il iz  ik u is a frequent itemset. support of S is 6 If Q then S1=\(il iz  ik can't be frequent closed itemset Proof Let P=\(pl,p2 pa bethe set oftransactionsthat contains S SI qz ___ qD be the set of transactions that contains S Since the transactions that contain must contain SI Qd Q hold For Q we have P=Q That is to say any transaction that contains SI must contains Sz From the deIinition of frequent closed itemset il iZ  ik can't be frequent closed itemset Based on the above discussions the GFCG algorithm is described in the following programs AlgorithmOGFCG InputOdatabase D Support thre8hold minsup outputOAl1 of the frequent closed itemset C GFCGI D minsup C C  4 F  4 F  CreateFreWentItemS D  F minsup  CreateBitvectOr ID F CreateGraph\(F1 for all items i EF MineSamePrefixFreq lii BV  i.count C  CreateFrequentItemS D  F  minsup  N is number of transactions F  4 for j=1 jiN  j+t  for all items i in jth transaction 1 i.cOunt   F=\(i I i is an item and i.COUnt minsupJ CreateBitVector\(D F for all items i in F for j-1 jrN  j 1  allocate BV and set all bit in BV5 to 0 for all items i in jth transaction  set the jth bit of BV to 1  CreateGraph IF 1 let L be an order of the items in F for all frequent items i SF for all frequent item j EF i  j if number of 1 in BV nBV  then i.link.add\(j\//create edge i-j  BV is the bit vector of I nsvp is the support Of I MinesamePrefixFreq I BV naYpp C 21 


Li Zhai and Jin BOO5 COvered=FALSE for all j jsi.link  T I 223\(j  BV,\222=BV Bvl  let nneuauPp he the number Of 1s in BVr,i let i be the last item in itemset I  if nn.x,upe L minsup  if nn-supp  nsnm 1  covered TRUE  1 MineSamePrefixFreq\(7 BVI\222 nneurvpp C  1  if coveced=FALSE 1 if  I is not covered by f f C 1 C\221iCUI  1 The pnrpose of using the parameter BVI and nW in function MineSamePrefixFreq is to acquire the bit-vector and the support of itemset Z\222s extension conveniently Us ing the two parameters we can avoid generating bit-vector and support of new itemset from the beginning From lemma 5 and lemma 6, we know that GFCG al gorithm can finds out all frequent closed itemsets through the method of MineSamePrefixFreq Let the order of the frequent closed itemsets be found out be L Z={i i2 6 is the frequent itemset current find Sbefmis the set of itemset before Z in L Sa is the set of itemsets after Z in L Lemma 8 Let S be the extended itemset cluster of Z then there does not exist frequent itemset I that covers Z PE Si if and only if, there does not exist PI that covers Z P\222E Sa Proof  1 the way that GFCG finds frequent itemsets we have the relationship Stah 2 th&e exists a kquent closed itemset PIES I\222 covers Z then PIES Sf is the cluster of itemsets that have the same prefix Z Let P\222={it i2  ik 1~0\2221 j  jl then P={il i2 ik j  Ztoo rd That conflict to the fact that there does not exist frequent itemset P that covers Z F E Si Lemma 9 Algorithm GFCG can finds out all frequent closed itemsets PrwfOFrom the lemma 3 itemset Z is a frequent closed itemset if and only if Z not covered by any other frequent closed itemset. That means Z is neither covered by any fre quent closed itemset in S nor covered by any frequent closed itemset in Sa From lemma 8 if Z is not covered by any itemset of extended itemset cluster of Z we can say Z is not covered by any frequent closed itemset in In function MineSamePrefixFreq\222s 3th step we set the vari able \223coveres\222 to FALSE in loth step if Z is covered by any itemset of the extended itemset cluster of I then set the variable 223covered\224 to TRUE Z can\222t be frequent closed itemset equals to the current set of frequent closed itemsets C that have been found out If we can confirm that Z not covered by any itemset of C Z is frequent closed itemset From the discussion above GFCG can finds out all the frequent closed itemset 3 EXPERIMENT EVALUATION AND PERFORM ANCE STUDY In this section we present a performance comparison be tween the GFCG algorithtn and the Apriori-based algo rithm A-close AU of the experiments are performed on 300MHz PC machine with 12s megabytes main memory nmning on Microsoft Windows Me AU the programs are ulitten in Microsofti Visual C++6.0 The data set used for performance study include one real data set and two syn thetic data sets. The real data set is the Traditional Chinese Medicine TChQ database which has 1378 prescription records, each prescription has several drugs The synthetic data sets are generated using the procedure described in R.Agrawl 1994 The parameters of the synthetic data sets are described in table 1 We first test the speed property of the two algorithms on the real and synthetic data set by changing the minimum support threshold The results of the experiments are shown in figure 2,3 and 4 Then we test the scale up property of the two algorithms by fixing the minimum support threshold to specified value I and changing the size of the data set The results of the experi ments are shown in figure 5 From the above mentioned performance study we can see that GFCG algorithm has good performance both in speed and scale-up property The good performance of GFCG comes from the fol lowing reasons Firstly GFCG adopts de technique of bit vector which substantially compresses the information of the transaction database. Secondly the construction of as sociation graph makes the algorithm avoid candidate set generation The generation of new fiequent closed itemset can be guided by the association graph efficiently Fur thermore by the construction of graph the times of data base scan are substantially reduced Only twice database scans are needed. Finally the concept of extended itemset cluster also reduces the search space when judge weather one frequent itemset is closed Table 2 The Parameter of s thetic data set Parameter T10.14.D5K T20.16.DlOK Total item 1000 1000 Number of transaction 5K 1 OK W Avera e len 4 CONCLUSION For the task of mining frequent closed itemset this paper proposes a graph-based algorithm named GFCG The new algorithm adopts the technique of bit-vector and constructs an association graph to represent the frequent relationships  22 


Li, Zhai, and Jin between Sequent items The GFCG generates Sequent closed itemset based on that association graph GFCG also introduces the concept of extended itemset cluster which largely reduces the search space The experiment evalua tion and performance study on real data set and synthetic data set show that the new algorithm outperforms aprimi based algorithm and has good performance both in speed and scale up property Figure 2 Performance study on TCM database Figure 3 Performance study on T20.16.DIOK data set Figure 4 Performance study on T10.14.DSKdata set s  4        1 0 12 3 4 5 6 7 8 s 10 Il"mb.rd*..nmlon Ili Figure 5 Scales up property study REFERENCE RAgrawl and R.Srikant Fast Algorithm for Mining Association Rules. In Proc 1994 Int ConJ Veiy Large Data Base In VLDB'94 page 487-499 Santiago Chile September 1994 S Brin R Motwani and C Silverstein. Beyond market basket Generalizing association rules to correlations In SIGMOD'97 page 265-276,1997 H Mannila H Toivonen and A I Verkamo Efficient al gorithms for discovering association rules In Proc  AAA1'94 Warbhop Knowledge Discovery in Database KDD'94 pages 181-192 Seattle WA July 1994 J.Hm G.Dong and Y.Yin Efficient mining of partial pe riodic patterns in time series database. In Proc 1999 int.ConJ Data Engineering \(ICDE 99 pages 106 115 Sydney Australia, April 1999 H.Mannila, H Toivonen, and A 1 Verkamo. Discovery of frequent episodes in event sequences Data Mining and Knowledge Discovery page 259-289 1997 Nicolas Pasquier Yves Bastide Ra Taouil and Lot6 Lakhal Discovering Sequent closed itemsets for asso ciation rules  In Proceedings of the 7 International Conference on Database Theoty page 398-416 1999 AUTHOR BIOGRAPHlES LI LI is graduated student in Institute of Neural Network and Information Technology of Southwest Jiaotong Uni versity P.R.CHINA His research focuses on Rough set theory combinatorial optimization and data mining He can be contacted by e-mail at itaiylili 1 hi.corn DONG-HAI ZHAl is graduated student in Institute of Neural Network and Information Technology of Southwest Jiaotong University P.R.CHNA His research focuses on fuzzy inference, neural network combinatorial optimiza 23 


Li Zhai and Jin tion He can be contacted by e-mail at rli;tidl@ymh.riel zh~idon~liai~,~;s~n3.cotn.cii FAN JlN is the director of Institute of Neural Network and Information Technology Southwest Jiaotong Univer sity P.R.CHINA His research focuses on combinatorial coding combinatorial optimization neural network com putational intelligence He can be contacted by e-mail at fmj in'sc.cninfo.iit.t.~ii 24 


following table Pro\223t Range Proportion Pro\223t Range Proportion 0-$0.1 2.03 5-$10 10.43 0.1-$1 25.05 10-$100 7.75 1-$5 54.59 100-$400 0.15 7.3 Results r Synthetic Data In the 223rst experiment we have the same setup as in 26 but the pro\223t follows lognormal distribution The result is shown in Figure 2 In the 223gure it is noted that the pro\223tability lines for MPIS Alg QP and HAP are overlapping and the execution-time line for HAP is slightly greater than that for naive For pro\223tability we observe that for the data set the naive approach gives the lowest pro\223tability among all algorithms This is because the naive approach does not consider any cross-selling effect Naturally the pro\223tabilities of all algorithms increase when the number of items selected increases From the graph of the execution time against the selection size the execution time of MPIS Alg increases from 0 selection reaching a maximum when about half the items are selected and then decreases afterwards Here the execution time depends on two factors The 223rst factor is related to the complexity of each iteration If there are more items to be selected the bene\223t calculation is more complex and updates to the bene\223t are more likely The initial increase is related to the 223rst factor The second factor is related to the number of iterations in the algorithm When 000  the number of items selected increases the number of items to be removed in the iteration step decreases Thus the number of iterations decreases if 000 is large compared with 001  The 223rst factor is dominant when the selection is below 50 but the second factor becomes dominant when the selection is larger than 50 The quadratic programming approach QP used in the chosen Solver uses a variant of the Simplex method to determine a easible region and then uses the methods described in 13 to 223nd the solution As the approach uses an iterative step based on e current state to determine the next step the execution time is quite 224uctuating as the execution time is mainly dependent on the problem or which state the algorithm is in HAP is an iterative approach to 223nd the authority weight of each item The formula for the update of the authority weight is in the form 002 000 003\002 where 002 is a vector of dimension 001 representing the authority weight of 001 items and 003 is an 001 000 001 matrix used in HAP to update the authority weight In our experiment we observed that the authority weights converge rapidly QP takes the longest execution time compared with other algorithms Naive gives the shortest execution time as there are only simple operations HAP gives the second shortest execution time for this small synthetic data set We note that the number of iterations involved are quite small MPIS Alg has the second greatest execution time but it scales much better with increasing number of items where it can outform HAP many folds see the next subsection 7.4 Results r Real Data Set With the drug store data set we have conducted similar experiments as with the synthetic data However the Quadratic Programming QP Solver 1 does not handl e m ore t han 2000 variables In the real data set there are 26,128 variables i.e items hence it is not possible to experiment with our QP tool The results of the experiments are shown in Figure 3 In the results HAP gives the lowest pro\223tability The reason is as follows In the dataset there are some items with zero-pro\223t and high authority weight described in Section 3 yielding a low estimated total pro\223t of the item selection Suppose item 004 000 has zero pro\223t it is likely a good buy and hence can lead to high support If there are suf\223cient number of purchases of other item says item 004 001  with item 004 000 and if item 004 000 usually occur in e transactions containing item 004 001  the con\223dence of the rule 004 001 001 004 000 is quite high This creates a high authority weight for item 004 000  Items like 004 000 would lead to smaller profitability for HAP MPIS Alg gives a greater pro\223tability than naive approach in the real data set For instance if 000 000\001\002 005 003\002\001  the difference in pro\223tabilities between these two approaches is 2 In the real data set the l pro\223t is equal to 1,006,970 The difference in 2 pro\223tability corresponds to 20,139.4 which is a signi\223cant value If J=8709 the difference in pro\223tabilities between the two approaches is about 8 which corresponds to 80,557.6 On average the execution time of HAP is 6.5 times slower than MPIS Alg when the problem size is large HAP requires 6 days to 223nd the item selection while MPIS Alg requires about 1 day to 223nd the solution Since item selection is typically performed once in a while only when a store should update the types of products it carries the execution time is acceptable Though the naive method is much faster the pro\223t gain consideration from MPIS Alg would make it the better choice for an application The execution time of HAP increases signi\223cantly when the number of items increases compared with MPIS Alg In HAP a cross-selling matrix 006 is updated iteratively The matrix is of the order 001 000 001  For the real data set 001 000 001\004 005 005\001\006 and 001 000 will be very large Let 002 be e 001 000 005 vector representing the authority weight of each item In HAP there is a process to update 003\002 iteratively where 003 000 006 002 006 Thismatrix multiplication of matrix 003 with vector 002 is highly costly Let us consider the memory required for matrix 003  If double data type 8 bytes is used for storage of each entry then the matrix requires a memory size of about 5.08GB If 224oat data type 4 bytes is required then about 2.5GB memory is required This large matrix cannot 223t into the physical memory g a t of disk accesses for virtual memory Since the matrix 003 is sparse a hash data structure can be used so that only non-zero entries are stored We have adopted the hash structure for the real data set and fouud that less than 5MB memory is needed Our results in Figure 3 are based on this enhanced hashing approach However the computatio n with this reduced size is still very massive We have also tried other sets of experiments where not all Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


the items are considered but only those above a minimum support threshold of 0.05 or 0.1 are considered However the resulting pro\223tabilities are much lower than those shown in Figure 3 For instance if J  500 and min-support  0.05 the pro\223tability of naive and MPIS Alg is about 1.3 But if all items are considered the pro\223tability of those approaches is about 25 This is explained by the existence of items that generate h pro\223ts but which are not purchased frequently enough to be counted given the support thresholds  Na ve i Na ve i Figure 2 The Synthetic Data Set Na ve i Na ve i Figure 3 The drug store data set 8 Conclusion One of the applications of association rule the maximalpro\223t item selection problem with cross-selling effect MPIS is discussed in this paper We propose a modeling by the loss rule which is used in the formulation of the total pro\223t of the item selection We propose both a quadratic programming approach and a heuristical approach to solve the MPIS problem We show by experiments that these methods are ef\223cient and highly effective We believe that much future work can be done The heuristical method can be enhanced with known methodologies such as hill climbing Expert knowledge can be included in the methods and the de\223nition of the problem can be changed in different ways to re\224ect different user environments Acknowledgements We would like to thank M.Y Su for his generous help in providing the source codes for the HAP solution and his other advices We also thank Ping Quin of DBMiner Technology for providing the real dataset This research is supported by the Hong Kong RGC Earmarked Grant UGC REF.CUHK 4179/01E References 1 F ro n tlin e s y s tems so lv er  h ttp www so lv er co m 2 R  A gr a w al  I bm synt het i c dat a gener at or  http://www.almaden.ibm.com/cs/quest/syndata.html 3 R  A g r a w al T  I milien s k i  a n d Sw ami M i n i n g asso ciatio n r u l es between sets of items in large databases In SIGMOD  1993  R  A gra w al and R  S r i kant  F ast al gori t h ms for m i n i n g a ssoci ation es In VLDB  1994  J  E  B easl e y  H euri st i c al gori t h ms for t he unconst rai ned bi nary quadratic programming problem In chnical report the Management School Imperial College London  Dec 1998  T  B l i s chok E v ery t ransact i o n t el l s a s t o ry  I n Chain Store Age Executive with Shopping Center Age 1 3  pages 50\20557 1995 7 T  B r i j s  B  G oet hal s  G  S wi nnen K V a nhoof  a nd G W e t s  A data mining framework for optimal product selection in retail supermarket data The generalized profset model In SIGKDD  2000 8 T  B r i j s  G  S wi nnen K V a nhoof  a nd G W e t s  U si ng associ ation rules for product assortment decisions A case study In SIGKDD  1999  M R Gare y and D S  Johnson Computers and intractability A guide to the theory of np-completeness In Freeman  1979  J Han J P e i  and Y  Y i n Mi ni ng f r e quent pat t e r n s w i t hout candidate generation In SIGMOD  2000  S  Hedber g T h e dat a gol d r ush I n BYTE October  pages 83\205 99 1995  Hiller and L ieber man Introduction to operations research In McGraw Hill Seventh Edition  2001 13 B V  Ho h e n b a lk e n  A 223n ite a l g o r ith m t o m a x imiz e c e r ta in pseudoconcave functions on polytopes In Mathematical Programming 8  1975  R  Hor s t  P  M Par dal os and N  V  T hoai  I nt r oduct i o n t o global optimization In Kluwer Academic Publishers Second Edition  2000  J C  Hul l  Opt i ons fut u res and o t her deri v a t i v es In Prentice Hall International Inc 3rd Edition  1997  L  D Iasemi di s P  Pardal os J C S ack el l ares and D S  S h i au Quadratic binary programming and dynamical system approach to determine the predictability of epileptic seizures In Journal of Combinatorial Optimization Kluwer Academic  pages 9\20526 2001  J Kl ei nber g C  Papadi mi t r i ou and P  R agha v a n A m i c r o economic view of data mining In Knowledge Discovery Journal  1998  J M Kl ei nber g Aut hor i t a t i v e sour ces i n a hyper l i n k e d e n v i ronment In Proc ACM-SIAM Symp on Discrete Algorithms  1998 Also in JACM 46:5 1999  S  J L e on L i near al gebr a w i t h appl i cat i ons I n Prentice Hall Fifth Edition  1998 20 J Lu o  K R P a ttip ati an d P K W illett A s u b o p timal s o f t d ecision pda method for binary quadratic programming In Proc of the IEEE Systems Man and Cybernetics Conference  2001  H Manni l a  M et hods and pr obl ems i n dat a mi ni ng I n Proc of Int Conf on Database Theory  1997  H Manni l a  H  T oi v onen and A I  V e r kamo E f 223 c i ent al gorithms for discovering association rules In KDD  1994  V  S a f r ono v a nd M Par ashar  O pt i m i z i n g w eb ser v e r s usi n g page rank prefetching for lustered accesses In World Wide Web Internet and b Information Systems Volume 5 Number 1  2002  S  S a hni  C omput at i onal l y r e l a t e d p r obl ems I n SIAM J Comput 3  pages 262\205279 1974 25 J Ullman  L ectu re n o t es o n search in g t h e web  h ttp wwwdb.stanford.edu ullman/mining/mining.html  K W a ng and M Y  S u  I t e m sel ect i o n b y 216 hubaut hor i t y 216 p r o 223 t ranking In SIGKDD  2002 Proceedings of the Third IEEE Internati onal Conference on Data Mining \(ICDM\22203 0-7695-1978-4/03 $ 17.00 \251 2003 IEEE 


I Plenary Panel Session J Future Directions in Database Research  456 Chair Surajit Chaudhuri Microsoft Corporation Panelists Hector Garcia-Molina Stanford University Hank Korth, Bell Laboratories Guy Lohman IBM Almaden Research Center David Lomet Microsoft Research David Maier Oregon Graduate Institute I Session 14 Query Processing in Spatial Databases I Chair Sharma Chakravarthy University of Florida Processing Incremental Multidimensional Range Queries in a Direct Manipulation Visual Query Environment  458 High Dimensional Similarity Joins Algorithms and Performance Evaluation  466 S Hibino and E Rundensteiner N Koudas and K.C Sevcik Y Theodoridis E Stefanakis and T Sellis Cost Models for Join Queries in Spatial Databases  476 Mining Association Rules Anti-Skew Algorithms  486 J.-L Lin and M.H Dunham Mining for Strong Negative Associations in a Large Database of Customer Transactions  494 A Savasere E Omiecinski and S Navathe Mining Optimized Association Rules with Categorical and Numeric Attributes  503 R Rastogi and K Shim Chair: Anoop Singhal AT&T Laboratories S Venkataraman J.F Naughton and M Livny Remote Load-Sensitive Caching for Multi-Server Database Systems  514 DB-MAN A Distributed Database System Based on Database Migration in ATM Networks  522 T Hara K Harumoto M Tsukamoto and S Nishio S Banerjee and P.K Chrysanthis Network Latency Optimizations in Distributed Database Systems  532 I Session 17 Visualization of Multimedia Data I Chair Tiziana Catarci, Universita di Roma 223La Sapienza\224 W Chang D Murthy A Zhang and T.F Syeda-Mahmood Global Integration of Visual Databases  542 X 


The Alps at Your Fingertips Virtual Reality and Geoinformation Systeps  550 R Pajarola l Ohler P Stucki K Szabo and P Widmayer C Baral G. Gonzalez and T.C Son Design and Implementation of Display Specifications for Multimedia Answers  558 1 Session 18 Management of Objects I Chair: Arbee Chen National Tsing Hua University P Boncz A.N Wilschut, and M.L. Kersten C Zou B Salzberg, and R Ladin 0 Wolfson S Chamberlain S Dao L Jiang, and G. Mendei Flattening an Object Algebra to Provide Performance  568 Back to the Future Dynamic Hierarchical Clustering  578 Cost and Imprecision in Modeling the Position of Moving Objects  588 ROL A Prototype for Deductive and Object-Oriented Databases  598 A Graphical Editor for the Conceptual Design of Business Rules  599 The Active HYpermedia Delivery System AHYDS using the M Liu W Yu M Guo and R Shan P Lang W Obermair W Kraus and T Thalhammer PHASME Application-Oriented DBMS  600 F Andres and K. Ono S Chakravarthy and R Le S Mudumbai K Shah A Sheth K Parasuraman and C Bertram ECA Rule Support for Distributed Heterogeneous Environments  601 ZEBRA Image Access System  602 Author Index  603 xi 


11  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02  data bindings domain-specific metric for assessing module interrelationship  interface errors errors arising out of interfacing software modules  Porter90 Predicting software  faults 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 From decision trees to association rules  Classifiers  223this and this\224 goes with that \223class\224  conclusions \(RHS\ limited to one class attribute  target very well defined  Association rules  223this and this\224 goes with \223that and that\224  conclusions \(RHS\ may be any number of attributes  But no overlap LHS and RHS  target wide open  Treatment learning  223this and this\224 goes with \223less bad and more good\224  223less\224,  \223more\224: compared to baseline  223bad\224, \223good\224: weighted classes Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


12  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Association rule learning  www.amazon.com  Customers who bought this book also bought  The Naked Sun by Isaac Asimov  The Caves of Steel by Isaac Asimov  I, Robot by Isaac Asimov  Robots and Empire by Isaac Asimov 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Support and confidence  Examples = D , containing items I  1: Bread, Milk 2: Beer Diaper Bread, Eggs 3: Beer Coke, Diaper Milk 4: Beer Bread, Diaper Milk 5: Coke, Bread, Diaper Milk  LHS  RHS = {Diaper,Milk  Beer  Support       =   | LHS U RHS|  / | D |       = 2/5 = 0.4  Confidence  =   | LHS U RHS |  / | LHS |    = 2/3 = 0.66  Support-based pruningreject rules with s < mins  Check support before checking confidence Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


13  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Example of supportbased pruning 4 Bread 1 Eggs 4 Diaper 3 Beer 4 Milk 2 Coke Count 1Item 3 Beer,Diaper 3 Milk, Diaper 2 Milk,Beer 3 Bread, Diaper 2 Bread,Beer 3 Bread,Milk Count 2Item 2 Milk, Diaper Beer 3 Bread,Milk Diaper Count 3Item Support-based pruning 225 Min support =3 Ignore subsets of items of size N 225 only if N-1 support > min-support Without pruning 6 C 1  6 C 2  6 C 3 41 With pruning: 6 + 6 + 2 = 14 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Classifiers versus Association rules \(again  Classifiers  Assume entire example set can fit into RAM  Association rule learners  can handle very big data sets  Agraw  t he APRIORI alg o r i t h m   very large data sets  10,000,000 examples  843MB Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


14  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 The Data Mining Desiderata Bradley  Require one scan \(or less\ of the database if possible  On-line \223anytime\224 behavior  223best\224 is always available, with status information on progress, expected remaining time, etc. provided  Suspendable, stoppable, resumable  incremental  progress saved to resume a stopped job  Ability to incrementally incorporate additional data with existing models efficiently  Work within confines of a given limited RAM buffer  Ooops, good-bye traditional classifiers e.g. C4.5  Argued against by some  223Memory is cheap\224: [W A R2 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Conf1  outlo o k overc a s t   1 0   82  40    84  40   4 0 0  Treatment learning sunny, 85 86 false none \(2 1 2 sunny, 80 90 true none sunny, 72 95 false none rain 65 70 true,          none rain, 71 96 true none rain 70  false some \(2 2 4 rain, 68 80 false,  some rain, 75 80 false some sunny,      69 70 false lots    \(2 3 8 sunny,      75 70 true lots overcast,     83  false lots overcast,     64  true lots overcast,     72  true lots overcast,     81 75 false lots outlook temp humidity wind hours on course A good attribute range 225 More frequent in good that bad 225 Weighted by 223distance\224good to bad 225 Normalized by total count 225 Summed for all good/bad class pairs Lots  none Lots  some Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


15  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 sunny, 85 86 false none \(2 1 2 sunny, 80 90 true none sunny, 72 95 false none rain 65 70 true,           none rain, 71 96 true none rain 70  false some \(2 2 4 rain, 68 80 false,  some rain, 75 80 false some sunny,      69 70 false lots    \(2 3 8 sunny,      75 70 true lots overcast,     83  false lots overcast,     64  true lots overcast,     72  true lots overcast,     81 75 false lots 0 1 2 3 attribute ranges with deltaf 4-2024681 conf1 225 treatments 002 attribute.range.conf1 > X 225 treatments|=N 225TAR2 = O\(2 N  225 fails for large N outlook temp humidity wind hours on course Conf1  outlo o k overc a s t   1 0   82  40    84  40   4 0 0  Lots  none Lots  some 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Treatments for golf 0 1 2 3 4 none some lots I f outl ook o verc as t Th en l o t s o f go l f  4 4  0 Least monitor watch the humidityalert if rising over 90 Least change pick a vacation location with overcast weather I f h u m i d i t y  90  97 Th en l o t s o f go l f  1 4  0 1 2 3 none some lots 0 1 2 3 4 5 6 none some lots If n o ch an ge Th en l o t s o f go l f  6 6 3 5  3  Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


16  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 6.7 <= RM < 9.8 And 12.6 <= Ptratio 15.9 BEST ACTION 0.6 <= NOX < 1.9 and 17.16 <= LSTAT < 39 WORST ACTION BASELINE 500 examples  of bad--, bad, ok, good Stop staring at the scenery and tell me where to steer or what to dodge 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Require overall require2 require3 require5 require4     action1 action1, action2, action3,  \205   Cost,    Benefit 1 Y              Y             N,        \205   23200,  250 2           N              N             Y ,       \205   11400,  150 205..       \205             \205            \205        \205   \205         \205 action2 fault2 fault3 fault1 JPL requirements Feather&Menzie Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


17  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study 99 proposed actions for deep space satellite design; 2 99 10 30 options Each row is one project plan action1, action2, action3,  \205   Cost,    Benefit 1 Y              Y             N,        \205   23200,  250 2           N              N             Y ,       \205   11400,  150 205..       \205             \205            \205        \205   \205         \205 Learnt 225 Do 16 225 Don\222t do 14 225 Ignore 66 options 225 c.f. genetic algorithms Each dot  is one randomly generated project plan 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Pr of tampering 0.02 Pr of fire 0.01 Pr of smoke  given [fi  0.90 Pr of smoke  given [fi  0.01 Pr of report given [exodus=ye 0.75 Pr of report given [exodus=no 0.01 Pr of exodus given [alarm=yes 0.88 Pr of exodus given [alarm=no 0.001 etc tampering fire alarm smoke exodus run away report hello, operator I want to report a fire 0.02 0.01 Use Bayesian analysis to update probabilities given new information Use Bayesian analysis to update probabilities given new information Bayesian Tuning Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


18  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 tampering fire alarm smoke NO exodus report YES 0.50 was 0.02 0.03 was 0.01 Q1: What if there is a report, but no smoke Q1: What if there is a report, but no smoke Q2: What if there is a report, and smoke Q2: What if there is a report, and smoke tampering fire alarm smoke YES exodus 0.03 was 0.02 0.97 was 0.01 report YES Example from : [Poole98   p37 1 Source = http:// www.swi.psy.uva.nl/projects/SWI-Prolog/download.html http://www.cs.ubc.ca/spider/poole/ci/code.tar.gz Files    = code/acp/bnet.pl code/acp/bnet_t1.pl Bayesian Tuning 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Non-na\357ve model bayesian network Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


19  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Low testing effort EXPLAINS 1\ some observed operational defects  and 2\ low pre-release defects 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02  Ancestors  ancestor\(X,Y\:-parent\(X,Y  ancestor\(X,Y\:-parent\(X,Z\ancestor\(Z,Y  Lists  member\(X,[X|Z   member\(X,[Y|Z me mb er X Z   append X X   append\([X|X Y s X Z s  a ppe nd X s Ys Z s  Example Example action action hypothesis hypothesis p\(b,[b add clause p\(X,Y   specialize p\(X,[V p\(x,[a specialize p\(X,[X p\(b,[a add clause p\(X,[X p\(X,[V p\(X W Inductive Logic Programming Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


20  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 East-West trains 1. TRAINS GOING EAST 2. TRAINS GOING WEST 1 2 3 4 5 1 2 3 4 5 1. TRAINS GOING EAST 2. TRAINS GOING WEST 1 2 3 4 5 1 2 3 4 5 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 ILP representation  Example eastbound\(t1  Background theory car\(t1,c1\      car\(t1,c2\       car\(t1,c3\.      car\(t1,c4 rectangle\(c1\  rectangle\(c2\     rectangle\(c3\.   rectangle\(c4 short\(c1\      long\(c2\.          short\(c3\       long\(c4 none\(c1\.        none\(c2\.          peaked\(c3\.      none\(c4 two_wheels\(c1\  three_wheels\(c2\two_wheels\(c3\two_wheels\(c4 load\(c1,l1\.     load\(c2,l2\       load\(c3,l3\    load\(c4,l4 circle\(l1\      hexagon\(l2\       triangle\(l3\    rectangle\(l4 one_load\(l1\  one_load\(l2\.      one_load\(l3\    three_loads\(l4  Output ne\(C Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


21  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Predicting Correctness Almei NewID CN2 C4.5 C4.5_rule FOIL Accuracy 52 54 66 68 73 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 FOIL\222s best rule high\(A executable\(A,B maximum_statement_nesting_depth\(A,C lines_of_comments\(A,B commentsdivsize\(A,E n1\(A,F n2\(A,G less_or_equal\(E,F not less_or_equal\(B,G C <> 4 C <> 43 less_or_equal\(C,D High faults when comment density <= #operators and executable statements > #operators and max nesting <= number of lines of comments and max nesting is not 4 or 43 High faults when comment density <= #operators and executable statements > #operators and max nesting <= number of lines of comments and max nesting is not 4 or 43 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


22  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Inside  some learners  neural nets  genetic algorithms  decision tree learners  association rule learners  treatment learners  bayesian tuning  inductive logic programming 225 sub-symbolic locally guided descent symbolic, global search 225 recursive diversity reduction 225 this goes with that CLASS 225 this goes with that 225 asses 225 a little model goes a long way 225 Horn clauses  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case studies predicting effort \(45 predicting faults \(51 model-based ML \(54 early lifecycle project planning \(60 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


23  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study How can we estimate earlier in the life cycle  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Predicting development times in months\Srinivasan95 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


24  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Bayes for effort Chulani99  The COCOMO-II project  Open-source software cost estimation  Reuse vs effort XH : multiple product lines VH : across product lines H : across program N : across project L  : none  Regression over data from 83 software projects  Regression conflicted with \223Delphi values\224  Tune regression values using Delphi expectations 0.8 0.9 1 1.1 1.2 1.3 1.4 1.5 1.6 Low N H VH XH Delphi Regression Adjusted Da ta   reus e low e rs effo r t Ex pe ct e d  reus e incre a se  effo r t    251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 COCOMO-II \(1998\COCOMO-II \(1997 Pred\(30 Pred\(25 Pred\(20 Pred\(X 52 49 46 83 projects 63 59 54 161 projects 7561 68 55 63 48 161 projectsbased on Bayesian 161 projectsbased on Delphi Percentage of estimated effort within X of actual Conclusion data + delphi tuning\a Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


25  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Neural Network Count the wi dge ts in the I n te r f ace to es ti m a te e f f o r t  Labels Edit Boxes Grid Boxes Check Boxes Buttons 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Neural Network Subsystem Pred\(25 MARE Buyer Admin 80 17.6 Buyer Client 80 14.6 Distribution Server 20 96.7 Supplier Client 90 12.2  12 Different Widgets Counted and associated with effort Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


26  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Case study: Predicting software 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Predicting software  faults Khoshgoftaar99 Whi c h d o g s di d not ba r k  225 42 attri b ute s  in dat a s e t 225 Only 6 in the l e arnt th e o ry Diffe re nt attri b ute s than b e fore 225 223c au se s f a u l t 224  do m a in s pec i f i c 225 Me thod for fin d ing fa ult s  gen e r a l Whi c h d o g s di d not ba r k  225 42 attri b ute s  in dat a s e t 225 Only 6 in the l e arnt th e o ry Diffe re nt attri b ute s than b e fore 225 223c au se s f a u l t 224  do m a in s pec i f i c 225 Me thod for fin d ing fa ult s  gen e r a l Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


27  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Issue of generality  Specific conclusions may not apply to general projects  Proposal one  Intra-project learning  Lessons should generalize across the same developer methodology, application and tool set  Proposal two  Inter-project learning  Need larger training set  COCOMOII uses 161 projects  Note: two = N * one Khoshgoft good bad Tia bad good  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Model-based ML Bratko89,Pearc Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


28  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Model-based ML simple e.g sum\(X,  Y Z sum   sum   sum\(0 0 0 sum 0  sum 0  sum\(0   sum\(0   sum  Any sum  Any if X >0 X\222=      if X < 0 0 if X= 0  switch\(State,Volts,Amps switch\(on,       0,     Any switch\(off,      Any,   0 blub\(Mode,Light,Volts,Amps bulb\(blown,dark, Any 0 bulb\(ok,     light   bulb\(ok,    light   bulb\(ok,    dark 0 0 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 A qualitative circuit go  :tell\('circ.data'\ go1, told go1 :functor\(X,circuit,9\ forall\(X, example\(X example\(circuit\(Sw1,Sw2,Sw3,B1,B2,B3,L1,L2,L3\classification\(B1,B2,B3,Class format\('~a,~a,~a,~a,~a,~a,~a~n Sw1,Sw2,Sw3,L1,L2,L3,Class  classification\(B1, B2, B3,Class needs 2 our of three bulbs working classification\( ok, ok, B3,   good classification\( ok, B2, ok,   good classification\( B1, ok, ok,   good classification\( B1, B2, B3,   bad Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


29  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Results from > 700 examples circ.names good,bad switch1: on, off switch2: on, off switch3: on, off bulb1: light, dark bulb2: light, dark bulb3: light, dark Command line c4.5 -f circ -m 2 W a t c hing bulb1 tells us th e rest Insight f ul  Or dull W a t c hing bulb1 tells us th e rest Insight f ul  Or dull 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 More Model-based ML Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


30  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 ca n we r e v i s i t thos e warranti e s   Run 1 35,000 tions  Learn 1  Run 2 if Sw2c=off then 3264 tions  Learn 2  Run 2 if Sw2c=off n then 648 tions  Learn 3 Ca n\222t clos e  Sw3c warranty issu es No b u d g e t  for e x p e ns i v e ha rd wa r e 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 3 \223tunings\224 5 SLOC guesstimates 150,000 runs Treatments for software projects Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


31  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 flex=1 pmat=3 sced=2 rest anything from kc1 150,000 runs 150,000 runs Treatments for software projects \(ii 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 pmat=2 acap=2 sced=2 rest anything from kc1 30,000 runs 30,000 runs Treatments for software projects \(iii Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


32  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 ons discussion \(64 downloads \(69 further reading \(71 references \(72 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Will you try ML  Have we motivated you  Will you rush home and do ML on your data  Clearly  ML algorithms work  Caution  you may find it harder than you think Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


33  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Many ways to learn numerous case studies but there is still a problem Theme Learning is a solved problem \(sort of Data collecting and modeling is not 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Be warned match your ML goals to your software process level Project metrics coarse-grain conclusions Product metrics product learning Process metrics process learning Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


34  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Also, match your tool to task Task ML Tool Assembly line robot deciding what to reject Decision tree learner Repair robot trying to do the least to fix the rejected parts Treatment learner Predicting the life of a robot Neural Network Optimizing the assembly line Genetic Algorithm If clustering when no classes iation rule learning If simple background knowledge Bayesian If complex relational background knowledge ILP 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Have we learnt enough  Not yet  But wait Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


35  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Cost = $0  WEKA  E.g. http://www.cs.waikato.ac.nz/~ml/weka/: ML in JAVA 003 decision tree inducers,rule learners, naive Bayes, decision tables locally weighted regression  GDB_Net  http://nas.cl.uh.edu/boetticher/gdb_net.zip  TAR2  http://www.ece.ubc.ca/twiki/bin/view/Softeng/TreatmentLearner  APRIORI  http://fuzzy.cs.uni-magd eburg.de/~borgelt/apriori/apriori.html#download  And many others  E.g. ML  A public domain \223C\224 library of common algorithms  Naive Bayes, ID3, MC4 , Decision Tables ,   Holte's OneR CN2,\205  http://www.sgi.com/tech/mlc/utils.html 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Cost > $0  C4.5  Comes with the book Quinlan  C5.0  http://www.rulequest.com/download.html  Microsoft SQL SERVER 2000\231  Comes with numerous machine learning tools  Proprietary algorithms  Etc  223data mining\224 \223commercial software\224 in Google  3,340 links  223data mining consultancy\224 in Google  850 links Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


36  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 Further reading  Mendonca  great rev i e w art i cl e on ML  Large list of available tools  All the things you can do with a decision tree [Menzies0  Treatment learning: [Menzies01a  Michalski\222s excellent survey of ML types [Michalski  Neural nets: [Boetticher01  Special issue SEKE journal, knowledge discovery Morasca99  Inductive logic programming [Bergadano95,Cohen95  Come by IJCAI 2011 and I\222ll tell you all about it\222s applications  Genetic algorithms: [Goldberg8  Bayesian learning [Cheeseman88 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 References  Agrawal  Agrawal, R., and T.Imeilinski and A.Swami \223Mining Association Rules between Sets of Items in Large Databases,\224 Proceedings of the 1993 ACM SIGMOD Conference Washington DC, USA  Bergadan  Bergadano, F., and D.Gunetti Inductive Logic Programming: From Machine Learning to Software Engineering The MIT Press, 1995  B  Berry, M. J. A., and G., Linoff Data Mining For Marketing, Sales, and Customer Support John Wiley Sons, Inc., New York, 1997  Boetticher01  Boetticher, G., "An Assessment of Metric Contribution in the Construction of a Neural Network-Based Effort Estimator Second International Workshop on Soft Computing Applied to Software Engineering  Enschade, NL, 2001 Available from http://nas.cl.uh.edu/boetticher/publications.html  Boetticher01  Boetticher, G., "Using Machine Learning to Predict Project Effort: Empirical Case Studies in Data-Starved Domains First International Workshop on Model-based Requirements Engineering San Diego, 2001 Available from http://nas.cl.uh.edu/boetticher/publications.html  Bradley  Bradley, P., U. Fayyad, and C. Reina. \223Scaling clustering algorithms to large databases\224. In KDD'98  B  Bratko, I., I. Mozetic, and N. Lavrac KARDIO: a Study in Deep and Qualitative Knowledge for Expert Systems MIT Press, 1989  Breim  Breiman, L., J. Friedman, R. Olshen, C. Stone, \223Classification and Regression Trees,\224 Wadsworth International Group, 1984 Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


37  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 References  Burgess  Burgess, C.J., and Martin Lefley. \223Can genetic programming improve software effort estimation? A comparative evaluation,\224 Information and Software Technology er 2001  Cheesem  P. Cheeseman, D. Freeman, J. Kelly, M. Self, J. Stutz, and W. Taylor. \223Autoclass: a bayesian classification system,\224 In Proceedings of the Fifth International Conference on Machine Learning  Morgan Kaufman, 1988  Chulani  S.Chulani,  B. Boehm, and B. Steece 223Bayesian analysis of empirical software engineering cost models,\224 IEEE Transaction on Software Engineering 25\(4\ly/August  1999  Cohe  W. W. Cohen, \223Inductive specification recovery: Understanding software by learning  from example behaviors,\224 Automated Software Engineering 2:107-129, 1995  DeJon  DeJong, K.A., and Spears, W.M. "An Analysis of the Interacting Roles of Population Size and Crossover in Genetic Algorithms Proc. First Workshop Parallel Problem Solving from Nature  Springer-Verlag, Berlin, 1990  Dietteric  Dietterich, T. G., \223Machine Learning  Research: Four Current Directions,\224 AI Magazine 18 \(4\97 Pp. 97-136. Available from ftp://ftp.cs.orst.edu/pub/tgd/papers/aimag-survey.ps.gz  s  Feather, M.S., and T. Menzies: \223Converging on the Optimal Attainment of Requirements IEEE Joint Conference On Requirements Engineering  ICRE'02 and  RE'02 9-13th September, University of Essen, Germany, 2002. Available from http://tim.menzies.com/pdf/02re02.pdf 251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02 References  Fenton00  Fenton, N., and  M. Neil \223Software Metrics: A Roadmap,\224 International Conference on Software Engineering, 2000. Available from http://www.dcs.qmul.ac.uk/~norman/papers/metrics_roadmap.pdf  Goldberg  Goldberg, D.E Genetic Algorithms in Search, Optimization, and Machine Learning Addison-Wesley Reading, Massachusetts, 1989  Khoshgoftaar  Khoshgoftaar, T.M., and E.B. Allen. \223Model software quality with classification trees,\224 in H. Pham, editor 223Recent Advances in Reliability and Quality  Engineering\224, World Scientific, 1999  Mendonc  Mendonca, M., and N.L. Sunderhaft, \223Mining Software Engineering Data: A Survey,\224 A DACS State-ofthe-Art Report September 1999. Available from http://www.dacs.dtic.mil/techs/datamining  Menzie  Menzies, T., \223Practical Machine Learning for Software Engineering and Knowledge Engineering,\224 ftware Engineering and Knowledge Engineering volume 1, 2001\vailable from http://tim.menzies.com/pdf/00ml.pdf  Menzies01a  Menzies, T., and Y. Hu, \223Reusing models for requirements engineering,\224 First International Workshop on Model-based Requirements Engineering 2001. Available from http://tim.menzies.com/pdf/01reusere.pdf  Menzies01b  Menzies, T., and Y. Hu, \223Constraining discussions in requirements engineering,\224 First International Workshop on Model-based Requirements Engineering San Diego, 2001. Available from http://tim.menzies.com/pdf/01lesstalk.pdf  Menzie  Menzies. T., and J. Kiper, \223Better reasoning about software engineering activities,\224 Automated Software Engineering 2001. Available from http://tim.menzies.com/pdf/01ml4re.pdf Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


38  251 2002 Tim Menzies, Gary D. Boetticher Page  SEW-27 Tutorials '02  Michalski90   Michalski, R.S., \223Toward a unified theory of learning,\224  In B.G. Buchanan and D.C. Wilkins, editors 223Reading in Knowledge  Acquisition and Learning\224, pages 7--38. Morgan Kaufmann, 1993  Mitchell  Mitchell, T Machine Learning McGraw-Hill, 1997  Morasca99  Morasca, S., and Gunther Ruhe, Guest editors' introduction of the Special issue on \223Knowledge Discovery from Software Engineering Data,\224 International Journal of Software Engineering and Knowledge Engineering October, 1999  Pearce  Pearce, D., \223The induction of fault diagnosis systems from qualitative models,\224 in Proc. AAAI-88 1988  Poole9  Poole, D. L.,  A. K. Mackworth, and R. G. Goebel Computational Intelligence: A Logical Approach  Oxford University Press, New York, 1998  Porter9  Porter, A.A., and R.W. Selby  \223Empirically guided software development using metric-based classification trees,\224 IEEE Software Pp. 46-54, March 1990  Quinla  Quinlan, R C4.5: Programs for Machine Learning Morgan Kaufman, 1992  Srinivasa  Srinivasan, K., and D. Fisher,  \223Machine learning approaches to estimating software development effort,\224 IEEE Transactions on Software Engi neering Pp. 126-137, February 1995  Tian9  Tian, J., and M.V. Zelkowitz 223Complexity measure evaluation and selection,\224 IEEE Transactions on Software Engineering 21\(8\p. 641-649,  August 1995  Webb0  Webb, G., \223Efficient search for association rules,\224 Proceeding of KDD-2000 Boston, MA,  2000  Zhang0  Zhang, Du, \223Applying Machine Learning Algorithms in Software Development,\224 Modelling Software System Structures in a fastly moving scenario Santa Margherita Ligure, Italy, 2000 References Proceedings of the 27th Annual NASA Goddard Software Engineering Workshop \226 Tutorial Notes \(SEW\22202 0-7695-1854-0/02 $17.00 \251 2002 IEEE 


